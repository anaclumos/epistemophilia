[
  {
    "id": 42617645,
    "title": "How I program with LLMs",
    "originLink": "https://crawshaw.io/blog/programming-with-llms",
    "originBody": "How I program with LLMs 2025-01-06 This document is a summary of my personal experiences using generative models while programming over the past year. It has not been a passive process. I have intentionally sought ways to use LLMs while programming to learn about them. The result has been that I now regularly use LLMs while working and I consider their benefits net-positive on my productivity. (My attempts to go back to programming without them are unpleasant.) Along the way I have found oft-repeated steps that can be automated, and a few of us are working on building those into a tool specifically for Go programming: sketch.dev. It’s very early but so far the experience has been positive. Background I am typically curious about new technology. It took very little experimentation with LLMs for me to want to see if I could extract practical value. There is an allure to a technology that can (at least some of the time) craft sophisticated responses to challenging questions. It is even more exciting to watch a computer attempt to write a piece of a program as requested, and make solid progress. The only technological shift I have experienced that feels similar to me happened in 1995, when we first configured our LAN with a usable default route. We replaced the shared computer in the other room running Trumpet Winsock with a machine that could route a dialup connection, and all at once I had The Internet on tap. Having the internet all the time was astonishing, and felt like the future. Probably far more to me in that moment than to many who had been on the internet longer at universities, because I was immediately dropped into high internet technology: web browsers, JPEGs, and millions of people. Access to a powerful LLM feels like that. So I followed this curiosity, to see if a tool that can generate something mostly not wrong most of the time could be a net benefit in my daily work. The answer appears to be yes, generative models are useful for me when I program. It has not been easy to get to this point. My underlying fascination with the new technology is the only way I have managed to figure it out, so I am sympathetic when other engineers claim LLMs are “useless.” But as I have been asked more than once how I can possibly use them effectively, this post is my attempt to describe what I have found so far. Overview There are three ways I use LLMs in my day-to-day programming: Autocomplete. This makes me more productive by doing a lot of the more-obvious typing for me. It turns out the current state of the art can be improved on here, but that’s a conversation for another day. Even the standard products you can get off the shelf are better for me than nothing. I convinced myself of that by trying to give them up. I could not go a week without getting frustrated by how much mundane typing I had to do before having a FIM model. This is the place to experiment first. Search. If I have a question about a complex environment, say “how do I make a button transparent in CSS” I will get a far better answer asking any consumer-based LLM, o1, sonnet 3.5, etc, than I do using an old fashioned web search engine and trying to parse the details out of whatever page I land on. (Sometimes the LLM is wrong. So are people. The other day I put my shoe on my head and asked my two year old what she thought of my hat. She dealt with it and gave me a proper scolding. I can deal with LLMs being wrong sometimes too.) Chat-driven programming. This is the hardest of the three. This is where I get the most value of LLMs, but also the one that bothers me the most. It involves learning a lot and adjusting how you program, and on principle I don’t like that. It requires at least as much messing about to get value out of LLM chat as it does to learn to use a slide rule, with the added annoyance that it is a non-deterministic service that is regularly changing its behavior and user interface. Indeed, the long-term goal in my work is to replace the need for chat-driven programming, to bring the power of these models to a developer in a way that is not so off-putting. But as of now I am dedicated to approaching the problem incrementally, which means figuring out how to do best with what we have and improve it. As this is about the practice of programming, this has been a fundamentally qualitative process that is hard to write about with quantitative rigor. The closest I will get to data is to say: it appears from my records that for every two hours of programming I do now, I accept more than 10 autocomplete suggestions, use LLM for a search-like task once, and program in a chat session once. The rest of this is about extracting value from chat-driven programming. Why use chat at all? Let me try to motivate this for the skeptical. A lot of the value I personally get out of chat-driven programming is I reach a point in the day when I know what needs to be written, I can describe it, but I don’t have the energy to create a new file, start typing, then start looking up the libraries I need. (I’m an early-morning person, so this is usually any time after 11am for me, though it can also be any time I context-switch into a different language/framework/etc.) LLMs perform that service for me in programming. They give me a first draft, with some good ideas, with several of the dependencies I need, and often some mistakes. Often, I find fixing those mistakes is a lot easier than starting from scratch. This means chat-based programming may not be for you. I am doing a particular kind of programming, product development, which could be roughly described as trying to bring programs to a user through a robust interface. That means I am building a lot, throwing away a lot, and bouncing around between environments. Some days I mostly write typescript, some days mostly Go. I spent a week in a C++ codebase last month exploring an idea, and just had an opportunity to learn the HTTP server-side events format. I am all over the place, constantly forgetting and relearning. If you spend more time proving your optimization of a cryptographic algorithm is not vulnerable to timing attacks than you do writing the code, I don’t think any of my observations here are going to be useful to you. Chat-based LLMs do best with exam-style questions Give an LLM a specific objective and all the background material it needs so it can craft a well-contained code review packet and expect it to adjust as you question it. There are two major elements to this: Avoid creating a situation with so much complexity and ambiguity that the LLM gets confused and produces bad results. This is why I have had little success with chat inside my IDE. My workspace is often messy, the repository I am working on is by default too large, it is filled with distractions. One thing humans appear to be much better than LLMs at (as of January 2025) is not getting distracted. That is why I still use an LLM via a web browser, because I want a blank slate on which to craft a well-contained request. Ask for work that is easy to verify. Your job as a programmer using an LLM is to read the code it produces, think about it, and decide if the work is good. You can ask an LLM to do things you would never ask a human to do. “Rewrite all of your new tests introducing an ” is an appalling thing to ask a human, you’re going to have days of tense back-and-forth about whether the cost of the work is worth the benefit. An LLM will do it in 60 seconds and not make you fight to get it done. Take advantage of the fact that redoing work is extremely cheap. The ideal task for an LLM is one where it needs to use a lot of common libraries (more than a human can remember, so it is doing a lot of small-scale research for you), working to an interface you designed or produces a small interface you can verify as sensible quickly, and it can write readable tests. Sometimes this means choosing the library for it, if you want something obscure (though with open source code LLMs are quite good at this). You always need to pass an LLM’s code through a compiler and run the tests before spending time reading it. They all produce code that doesn’t compile sometimes. (Always making errors I find surprisingly human, every time I see one I think, there but for the grace of God go I.) The better LLMs are very good at recovering from their mistakes, often all they need is for you to paste the compiler error or test failure into the chat and they fix the code. Extra code structure is much cheaper There are vague tradeoffs we make every day around the cost of writing, the cost of reading, and the cost of refactoring code. Let’s take Go package boundaries as an example. The standard library has a package “net/http” that contains some fundamental types for dealing with wire format encoding, MIME types, etc. It contains an HTTP client, and an HTTP server. Should it be one package, or several? Reasonable people can disagree! So much so, I do not know if there is a correct answer today. What we have works, after 15 years of use it is still not clear to me that some other package arrangement would work better. Advantages of a larger package include: centralized documentation for callers, easier initial writing, easier refactoring, easier sharing of helper code without devising robust interfaces for them (which often involves pulling the fundamental types of a package out into yet another leaf package filled with types). The disadvantages include the package being harder to read because many different things are going on (try reading the net/http client implementation without tripping up and finding yourself in the server code for a few minutes), or it being harder to use because there is too much going on in it. For example I have a codebase that uses a C library in some fundamental types, but parts of the codebase need to be in a binary widely distributed to many platforms that does not technically need the C library, so have more packages than you might expect in the codebase isolating the use of the C library to avoid cgo in the multi-platform binary. There are no right answers here, instead we are trading off different types of work that an engineer will have to do (upfront and ongoing). LLMs influence those tradeoffs: As LLMs do better with exam-style questions, more and smaller packages make it easier to give a complete and yet isolated context for a piece of work. This is true for humans too, which is why we use packages at all, but we trade off package size against the extra typing/plumbing/filing to make more readable code. With an LLM both doing and benefiting from a big chunk of that extra work, the tradeoff shifts. (As a bonus, we humans get more readable code!) Smaller and more numerous packages can be compiled and tested independently of unrelated code. This is helpful for the LLM dev cycle as it means changes can be compiled and tested before other dependent packages are refactored, and the package has a simpler test environment. An example Let me work an example to combine a few of the discussed ideas: Write a reservoir sampler for the quartiles of floats. First off, package structure. Were I doing this before LLMs, I would have chosen to have some sort of streamstat package that contained several algorithms, maybe one per file. This does not seem to be a unique opinion, here is an open source quantile package following that model. Now, I want just this one algorithm in its own package. Other variants or related algorithms can have their own package. Next up, what do we get from an LLM. The first pass is not bad. That prompt, with some details about wanting it in Go got me quartile_sampler.go: // QuartileSampler maintains a reservoir sample to estimate quartiles of a stream // of float64 values. It uses reservoir sampling to maintain a representative // sample when processing large streams of data. type QuartileSampler struct { reservoir []float64 seen int maxSize int rng *rand.Rand } // NewQuartileSampler creates a new sampler that maintains up to maxSize samples. // A larger maxSize provides more accurate estimates but uses more memory. func NewQuartileSampler(maxSize int) *QuartileSampler { … } The core interface is good too: // Add adds a new value to the sampler. func (qs *QuartileSampler) Add(value float64) { … } // Quartiles returns the estimated 25th, 50th (median), and 75th percentiles // of the data seen so far. Returns (0,0,0) if no data has been added. func (qs *QuartileSampler) Quartiles() (q1, median, q3 float64) { if len(qs.reservoir) == 0 { return 0, 0, 0 } // Make a copy to avoid modifying the reservoir sorted := make([]float64, len(qs.reservoir)) copy(sorted, qs.reservoir) slices.Sort(sorted) n := len(sorted) q1 = percentile(sorted, 0.25) median = percentile(sorted, 0.50) q3 = percentile(sorted, 0.75) return q1, median, q3 } Great! There are also tests. An aside: this may be the place to stop. Sometimes I use LLM codegen as a form of specialized search. E.g. I’m curious about reservoir sampling, but want to see how the algorithm would be applied under some surprising constraint, for example time-windowed sampling. Instead of doing a literature search I might amend my prompt for an implementation that tracks freshness. (I could also ask it to include references to the literature in the comments, which I could manually check to see if it’s making things up or if there’s some solid research to work from.) Often I spend 60 seconds reading some generated code, see an obvious trick I hadn’t thought of, then throw it away and start over. Now I know the trick is possible. This is why it is so hard to attribute value generated by LLMs. Yes sometimes it makes bad code, gets stuck in a rut, makes up something impossible (it hallucinated a part of the monaco API I wish existed the other day) and wastes my time. It can also save me hours by pointing out something relevant I don’t know. Back to the code. Fascinatingly, the initial code produced didn’t compile. In the middle of the Quartiles implementation there was the line: n := len(sorted) Which is a fine line, sorted is a slice defined a few lines earlier. But the value is never used so gopls (and the Go compiler if you run go build) immediately says: declared and not used: n This is a very easy fix. If I paste the error back into the LLM it will correct it. Though in this case, as I’m reading the code, it’s quite clear to me that I can just delete the line myself, so I do. Now the tests. I got what I expected. In quartile_sampler_test.go: func TestQuartileSampler(t *testing.T) { tests := []struct { name string data []float64 wantQ1 float64 wantMed float64 wantQ3 float64 epsilon float64 // allowed error for floating point comparison }{ { name: \"basic sequence\", data: []float64{1, 2, 3, 4, 5, 6, 7}, wantQ1: 2, wantMed: 4, wantQ3: 6, epsilon: 0.1, },… } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { qs := NewQuartileSampler(100) // Use large reservoir for accurate testing for _, v := range tt.data { qs.Add(v) } q1, med, q3 := qs.Quartiles() if math.Abs(q1-tt.wantQ1) > tt.epsilon { t.Errorf(\"Q1 = %v, want %v (±%v)\", q1, tt.wantQ1, tt.epsilon) } if math.Abs(med-tt.wantMed) > tt.epsilon { t.Errorf(\"Median = %v, want %v (±%v)\", med, tt.wantMed, tt.epsilon) } if math.Abs(q3-tt.wantQ3) > tt.epsilon { t.Errorf(\"Q3 = %v, want %v (±%v)\", q3, tt.wantQ3, tt.epsilon) } }) } } Exactly the sort of thing I would write! I would run some cases through another implementation to generate expected outputs and copy them into a test like this. But there are two issues with this. The first is the LLM did not run these numbers through another implementation. (To the best of my knowledge. When using a sophisticated LLM service, it is hard to say for sure what is happening behind the scenes.) It made them up, and LLMs have a reputation for being weak at arithmetic. So this sort of test, while reasonable for a human to write because we base it on the output of another tool, or if we are particularly old-school do some arithmetic ourselves, is not great from an LLM. The second issue with this is we can do better. I am happy we now live in a time when programmers write their own tests, but we do not hold ourselves to the same standards with tests as we do with production code. That is a reasonable tradeoff, there are only so many hours in the day. But what LLMs lack in arithmetical prowess, they make up for in enthusiasm. Let’s ask for an even better test. In the tests, implement the simplest, most readable version of the standard code for quartiles over a fixed set of known values in a slice. Then pass the test cases through the standard code and the reservoir sampler and confirm they are within an epsilon of each other. Structure the comparison code such that it can be used in a fuzz test too. This got us some new test code: // referenceQuartiles calculates the exact quartiles for a slice of float64 values // using linear interpolation, matching the behavior expected from the sampler. func referenceQuartiles(data []float64) (q1, median, q3 float64) { … } // compareQuartiles checks if two sets of quartiles are within epsilon of each other. // Returns true if they match within the tolerance, false otherwise. func compareQuartiles(q1a, meda, q3a, q1b, medb, q3b, epsilon float64) bool { … } // checkQuartiles is a test helper that compares sampler output against the reference // implementation and reports any differences. func checkQuartiles(t *testing.T, data []float64, epsilon float64) { t.Helper() // Get reference values wantQ1, wantMed, wantQ3 := referenceQuartiles(data) // Get sampler values using a large reservoir for accuracy qs := NewQuartileSampler(1000) for _, v := range data { qs.Add(v) } gotQ1, gotMed, gotQ3 := qs.Quartiles() if !compareQuartiles(gotQ1, gotMed, gotQ3, wantQ1, wantMed, wantQ3, epsilon) { t.Errorf(\"Quartiles mismatch:got (q1=%v, med=%v, q3=%v)want (q1=%v, med=%v, q3=%v)epsilon=%v\", gotQ1, gotMed, gotQ3, wantQ1, wantMed, wantQ3, epsilon) } } The original test from above has been reworked to to use checkQuartiles and we have something new: func FuzzQuartileSampler(f *testing.F) { // Add some seed corpus f.Add([]float64{1, 2, 3, 4, 5}) f.Fuzz(func(t *testing.T, data []float64) { // Use a larger epsilon for fuzzing since we might get more extreme values checkQuartiles(t, data, 0.2) }) } This is fun, because it's wrong. My running gopls tool immediately says: fuzzing arguments can only have the following types: string, bool, float32, float64, int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64, []byte Pasting that error back into the LLM gets it to regenerate the fuzz test such that it is built around a func(t *testing.T, data []byte) function that uses math.Float64frombits to extract floats from the data slice. Interactions like this point us towards automating the feedback from tools: all it needed was the obvious error message to make solid progress towards something useful. I was not needed. Doing a quick survey of the last few weeks of my LLM chat history shows (which as I mentioned earlier, is not a proper quantitative analysis by any measure) that more than 80% of the time there is a tooling error, the LLM can make useful progress without me adding any insight. About half the time it can completely resolve the issue without me saying anything of note, I am just acting as the messenger. Where are we going? Better tests, maybe even less DRY There was a programming movement some 25 years ago focused around the principle “don’t repeat yourself.” As is so often the case with short snappy principles taught to undergrads, it got taken too far. There is a lot of cost associated with abstracting out a piece of code so it can be reused, it requires creating intermediate abstractions that must be learned, and it requires adding features to the factored out code to make it maximally useful to the maximum number of people, which means we depend on libraries filled with useless distracting features. The past 10-15 years has seen a far more tempered approach to writing code, with many programmers understanding it is better to reimplement a concept if the cost of sharing the implementation is higher than the cost of implementing and maintaining separate code. It is far less common for me to write on a code review “this isn’t worth it, separate the implementations.” (Which is fortunate, because people really don’t want to hear things like that after they have done all the work.) Programmers are getting better at tradeoffs. What we have now is a world where the tradeoffs have shifted. It is now easier to write more comprehensive tests. You can have the LLM write the fuzz test implementation you want but didn’t have the hours to build properly. You can spend a lot more time writing tests to be readable, because the LLM is not sitting there constantly thinking “it would be better for the company if I went and picked another bug off the issue tracker than doing this.” So the tradeoff shifts in favor of having more specialized implementations. The place where I expect this to be most visible is language-specific REST API wrappers. Every major company API comes with dozens of these, usually low quality, wrappers written by people who aren’t actually using their implementations for a specific goal, instead are trying to capture every nook and cranny of an API in a large and complex interface. Even when it is done well, I have found it easier to go to the REST documentation (usually a set of curl commands), and implement a language wrapper for the 1% of the API I actually care about. It cuts down the amount of the API I need to learn upfront, and it cuts down how much future programmers (myself) reading the code need to understand. For example, as part of my recent work on sketch.dev I implemented a Gemini API wrapper in Go. Even though the official wrapper in Go has been carefully handcrafted by people who know the language well and clearly care, there is a lot to read to understand it: $ go doc -all genaiwc -l 1155 My simplistic initial wrapper was 200 lines of code total, one method, three types. Reading the entire implementation is 20% of the work of reading the documentation of the official package, and if you decide to try digging into its implementation you will discover that it is a wrapper around another largely code-generated implementation with protos and grpc and the works. All I want is to cURL and parse a JSON object. There obviously comes a point in a project, where Gemini is the foundation of the entire app, where nearly every feature is used, where building on gRPC aligns well with the telemetry system elsewhere in your organization, where you should use the large official wrapper. But most of the time it is so much more time consuming, both upfront and ongoing, to do so given we almost always want only some wafer-thin sliver of whatever API we need to use today, that custom clients, largely written by a GPU, are far more effective for getting work done. So I foresee a world with far more specialized code, with fewer generalized packages, and more readable tests. Reusable code will continue to thrive around small robust interfaces and otherwise will be pulled apart into specialized code. Depending how well this is done, it will lead to either better software or worse software. I would expect both, with a long-term trend towards better software by the metrics that matter. Automating these observations: sketch.dev As a programmer my instinct is to make computers do work for me. It is a lot of work getting value out of LLMs, how can a computer do it? I believe the key to solving a problem is not to overgeneralize. Solve a particular problem and then expand slowly. So instead of building a general-purpose UI for chat programming that is just as good at COBOL as it is for Haskell, we want to focus on one particular environment. The bulk of my programming is in Go, and so what I want is easy to imagine for a Go programmer: something like the Go playground, built around editing a package and tests with a chat interface onto editable code a little UNIX env where we can run go get and go test goimports integration gopls integration automatic model feedback: on model edit run go get, go build, go test, feedback missing packages, compiler errors, test failures to the model to try and get them fixed automatically A few of us have built an early prototype of this: sketch.dev. The goal is not a “Web IDE” but rather to challenge the notion that chat-based programming even belongs in what is traditionally called an IDE. IDEs are collections of tools arranged for people. It is a delicate environment where I know what is going on. I do not want an LLM spewing its first draft all over my current branch. While an LLM is ultimately a developer tool, it is one that needs its own IDE to get the feedback it needs to operate effectively. Put another way: we didn’t embed goimports into sketch for it to be used by humans, but to get Go code closer to compiling using automatic signals, so that the compiler can provide better error feedback to the LLM driving it. It might be better to think of sketch.dev as a “Go IDE for LLMs”. This is all very recent work with a lot left to do, e.g. git integration so we can load existing packages for editing and drop the results on a branch. Better test feedback. More console control. (If the answer is to run sed, run sed. Be you the human or the LLM.) We are still exploring, but are convinced that focusing an environment for a particular kind of programming will give us better results than the generalized tool. Index github.com/crawshaw twitter.com/davidcrawshaw david@zentus.com",
    "commentLink": "https://news.ycombinator.com/item?id=42617645",
    "commentBody": "How I program with LLMs (crawshaw.io)624 points by stpn 18 hours agohidepastfavorite238 comments dewitt 15 hours agoOne interesting bit of context is that the author of this post is a legit world-class software engineer already (though probably too modest to admit it). Former staff engineer at Google and co-founder / CTO of Tailscale. He doesn't need LLMs. That he says LLMs make him more productive at all as a hands-on developer, especially around first drafts on a new idea, means a lot to me personally. His post reminds me of an old idea I had of a language where all you wrote was function signatures and high-level control flow, and maybe some conformance tests around them. The language was designed around filling in the implementations for you. 20 years ago that would have been from a live online database, with implementations vying for popularity on the basis of speed or correctness. Nowadays LLMs would generate most of it on the fly, presumably. Most ideas are unoriginal, so I wouldn't be surprised if this has been tried already. reply gopalv 12 hours agoparent> That he says LLMs make him more productive at all as a hands-on developer, especially around first drafts on a new idea, means a lot to me personally. There is likely to be a great rift in how very talented people look at sharper tools. I've seen the same division pop up with CNC machines, 3d printers, IDEs and now LLMs. If you are good at doing something, you might find the new tool's output to be sub-par over what you can achieve yourself, but often the lower quality output comes much faster than you can generate. That causes the people who are deliberate & precise about their process to hate the new tool completely - expressing in the actual code (or paint, or marks on wood) is much better than trying to explain it in a less precise language in the middle of it. The only exception I've seen is that engineering folks often use a blueprint & refine it on paper. There's a double translation overhead which is wasteful if you don't need it. If you have dealt with a new hire while being the senior of the pair, there's that familiar feeling of wanting to grab their keyboard instead of explaining how to build that regex - being able to do more things than you can explain or just having a higher bandwidth pipe into the actual task is a common sign of mastery. The incrementalists on the other hand, tend to love the new tool as they tend to build 6 different things before picking what works the best, slowly iterating towards what they had in mind in the first place. I got into this profession simply because I could Ctrl-Z to the previous step much more easily than my then favourite chemical engineering goals. In Chemistry, if you get a step wrong, you go to the start & start over. Plus even when things work, yield is just a pain there (prove it first, then you scale up ingredients etc). Just from the name of sketch.dev, it appears that this author is of the 'sketch first & refine' model where the new tool just speeds up that loop of infinite refinement. reply liotier 9 hours agorootparent> If you are good at doing something, you might find the new tool's output to be sub-par over what you can achieve yourself, but often the lower quality output comes much faster than you can generate. That causes the people who are deliberate & precise about their process to hate the new tool completely Wow, I've been there ! Years ago we dragged a GIS system kicking and screaming from its nascent era of a dozen ultrasharp dudes with the whole national fiber optics network in their head full of clever optimizations, to three thousand mostly clueless users churning out industrial scale spaghetti... The old hands wanted a dumb fast tool that does their bidding - they hated the slower wizard-assisted handholding, that turned out to be essential to the new population's productivity. Command line vs. GUI again... Expressivity vs. discoverability, all the choices vs. don't make me think. Know your users ! reply harrall 3 hours agorootparentprevI believe it’s more that people hate trying new tools because they’ve already made their choice and made it their identity. However, there are also people who love everything new and jump onto the latest hype too. They try new things but then immediately advocate it without merit. Where are the sane people in the middle? reply dns_snek 2 hours agorootparentAs an experienced software developer, I paid for ChatGPT for a couple of months, I trialed Gemini Pro for a couple of months, and I've used the current version of Claude. I'd be happy if LLMs could produce working code as often and as quickly as the evangelist claim, but whenever I try to use LLM to work on my day to day tasks, I almost always walk away frustrated and disappointed - and most of my work is boring on technical merits, I'm not writing novel comp-sci algorithms or cryptography libraries. Every time I say this, I'm painted as some luddite who just hates change when the reality is that no, current LLMs are just not fit for many of the purposes they're being evangelized for. I'd love nothing more than to be a 2x developer on my side projects, but it just hasn't happened and it's not for the lack of trying or open mindedness. edit: I've never actually seen any LLM-driven developers work in real time. Are there any live coding channels that could convince the skeptics what we're missing out on something revolutionary? reply davepeck 2 hours agorootparentI see less \"painting as a luddite\" in response to statements like this, and more... surprise. Mild skepticism, perhaps! Your experience diverges from that of other experienced devs who have used the same tools, on probably similar projects, and reached different conclusions. That includes me, for what it's worth. I'm a graybeard whose current work is primarily cloud data pipelines that end in fullstack web. Like most devs who have fully embraced LLMs, I don't think they are a magical panacea. But I've found many cases where they're unquestionably an accelerant -- more than enough to justify the cost. I don't mean to say your conclusions are wrong. There seems to be a bimodal distribution amongst devs. I suspect there's something about _how_ these tools are used by each dev, and in the specific circumstances/codebases/social contexts, that leads to quite different outcomes. I would love to read a better investigation of this. reply efnx 1 hour agorootparentI think it also depends on _what_ the domain is, and also to a certain degree the tools / stack you use. LLMs aren’t coherent or correct when working on novel problems, novel domains or using novel tools. They’re great for doing something that has been done before, but their hallucinations are wildly incorrect when novelty is at play - and I’ll add they’re always very authoritative! I’m glad my languages of choice have a compiler! reply jpc0 8 minutes agorootparentMy recent example for where its helpful. Pretty nice at autocomplete. Like writing json tags in go structs. Can just autocomplete that's stuff for me no problem, it saved me seconds per line, seconds I tell you. It's stupid as well... Autofilled a function, looks correct. Reread it 10 minutes later and well... Minor mistake that would have caused a crash at runtime. It looked correct but in reality it just didn't have enough context ( the context is in an external doc on my second screen ... ) and there was no way it would ever have guessed the correct code. It took me longer to figure out why the code looked wrong than if I had just typed it myself. Did it speed up my workflow on code I could have given a junior to write? Not really, but some parts were quicker while other were slower. And imagine if that code bad crashed in production next week instead of right now while the whole context is still in my head. Maybe that would be hours of debugging time... Maybe as parent said, for a domain where you are braking new ground, it can generate some interesting ideas you wouldn't have thought about. Like a stupid pair that can get you out if a local manima but in general doesn't help much it can be a significant help. But then again you could do what has been done for decades and speak to another human about the problem, at least they may have signed the same NDA as you... davepeck 1 hour agorootparentprevYeah, absolutely. LLMs work best for code when both (a) there's sufficient relevant training data aka we're not doing something particularly novel and (b) there's sufficient context from the current codebase to pick up expected patterns, the peculiarities of the domain models, etc. Drop (a) and get comical hallucinations; drop (b) and quickly find that LLMs are deeply mediocre at top-level architectural and framework/library choices. Perhaps there's also a (c) related to precision. You can write code to issue a SQL query and return JSON from an API endpoint in multiple just-fine ways. Misplace a pthread_mutex_lock, however, and you're in trouble. I certainly don't trust LLMs to get things like this right! (It's worth mentioning that \"novelty\" is a tough concept in the context of LLM training data. For instance, maybe nobody has implemented a font rasterizer in Rust before, but plenty of people have written font rasterizers and plenty of others have written Rust; LLMs seem quite good at synthesizing the two.) reply harrall 2 hours agorootparentprevYou're the middle ground I was talking about. You tried it. You know where it works and where it doesn't. I've used LLM to generate code samples and my IDE (IntelliJ) uses an LLM for auto-suggestions. That's mostly about it for me. reply holoduke 1 hour agorootparentprevYesterday i wanted to understand what a team was doing in a go project. I have never really touched go before. I do understand software, because I develop for plus 20 years. But chatgpt was perfectly able to give me a summary on how the implementation worked. Gave me examples and suggestions. And within a day fulltime pasting code and asking question i had a good understanding of the codebase. It would have be a lot more difficult with only google. reply evilfred 2 hours agorootparentprevMiddle Ground Fallacy reply harrall 2 hours agorootparentFallacy fallacy reply goatlover 1 hour agorootparentprevThe middle ground between hyping the new tech and being completely skeptical about it is usually right. New tech is usually not everything it's hyped up to be, but also usually not completely useless or bad for society. It's likely we're not about to usher in the singularity or doom society, but LLMs are useful enough to stick around in various tools. Also it's probably the case that a percentage of they hype is driven by wanting funding. reply jprete 4 hours agorootparentprevThis is a good characterization. I'm precision-driven and know what I need to do at any low level. It's the high-level definition that is uncertain. So it doesn't really help to produce a dozen prototypes of an idea and pick one, nor does it help to fill in function definitions. reply travisporter 2 hours agorootparentprev> I got into this profession simply because I could Ctrl-Z to the previous step much more easily than my then favourite chemical engineering goals. That is interesting. Asking as a complete ignoramus - is there not a way to do this now? Like start off with a 100 of reagent and at every step use a bit and discard if wrong reply ssivark 1 hour agorootparentBut for every step that turns out to be \"correct\" you now have to go back and redo that in your held-out sample anyways. So it's not like you get to save on repeating the work -- IIUC you just changed it from depth-first execution order to breadth-first execution order. reply tikkun 4 hours agorootparentprevIntersting. So engineers that like to iterate and explore are more likely to like LLMs. Whereas engineers that like have a more rigid specific process are more likely to dislike LLMs. reply godelski 1 hour agorootparentI frequently iterate and explore when writing code. Code gets written multiple times before being merged. Yet, I still haven't found LLMs to be helpful in that way. The author gives \"autocomplete\", \"search\", and \"chat-driven programming\" as 3 paradigms. I get the most out of search (though a lot of this is due to the decreasing value of Google), autocomplete is pretty weak to me especially as I macro or just use contextual complete, and I've failed miserably at chat-driven programming on every attempt. I spend more time debugging the AI than it would to debug myself. Albeit it __feels__ faster because I'm doing more typing + waiting rather than continuous thinking (but the latter has extra benefits). reply dboreham 1 hour agorootparentprevCalculators vs slide rules. reply antirez 10 hours agoparentprevI have also many years of programming experience and find myself strongly \"accelerated\" by LLMs when writing code. But, if you think at it, it makes sense that many seasoned programmers are using LLMs better. LLMs are a helpful tool, but also a hard-to-use tool, and in general it's fair to think that better programmers can do a better use of some assistant (human or otherwise): better understanding its strengths, identifying faster the good and bad output, providing better guidance to correct the approach... Other than that, what correlates more strongly with the ability to use LLMs effectively is, I believe, language skills: the ability to describe problems very clearly. LLMs reply quality changes very significantly with the quality of the prompt. Experienced programmers that can also communicate effectively provide the model with many design hints, details where to focus, ..., basically escaping many local minima immediately. reply mhalle 3 hours agorootparentI completely agree that communication skills are critical in extracting useful work or insight from LLMs. The analogy for communicating with people is not far-fetched. Communicating successfully with a specific person requires an understanding of their strengths and weaknesses, their tendencies and blind spots. The same is true for communicating with LLMs. I have actually found that from a documentation point of view, querying LLMs has made me better and explaining things to people. If, given the documentation for a system or API, a modern LLM can't answer specific questions about how to perform a task, a person using the same documentation will also likely struggle. It's proving to be a good way to test the effectiveness of documentation, for humans and for LLMs. reply rudiksz 18 minutes agorootparentprev> \"seasoned programmers are using LLMs better\". I do not remember a single instance when code provided to me by an LLM worked at all. Even if I ask something small that cand be done in 4-5 lines of code is always broken. From a fellow \"seasoned\" programmer to another: how the hell do you write the prompts to get back correct working code? reply bsenftner 7 hours agorootparentprevCommunication skills are the keys to using LLMs. Think about it: every type of information you want is in them, in fact it is there multiple times, with multiple levels of seriousness in the treatment of the idea. If one is casual in their request, using casual language, then the LLM will reply with a casual reply because that matched your request best. To get a hard, factual answer from those that are experts in a subject, use the formal term, use the expert's language and you'll get back a rely more likely to be correct because it's in the same level of formal treatment as correct answers. reply psychoslave 5 hours agorootparent>every type of information you want is in them Actually, I'm afraid that no. It won't give us the step by step scalable processes to make humanity as a whole enter in a loop of indefinitely long period of world peace, with each of us enjoying life in its own thriving manner. That would be great information to broadcast, though. Also it equally has ability to produce large pile of completely delusional answers, that mimics just as well genuinely sincere statements. Of course, we can also receive that kind of misguiding answers from humans. But the amount of output that mere humans can throw out in such a form is far more limited. All that said, it's great to be able to experiment with it, and there are a lot of nice and fun things to do with it. It can be a great additional tool, but it won't be a self-sufficient panacea of information source. reply bsenftner 5 hours agorootparent> It won't give us the step by step scalable processes to make humanity as a whole enter in a loop of indefinitely long period of world peace That's not anywhere, that's a totally unsolved and open ended problem, why would you think an LLM would have that? reply fmbb 4 hours agorootparentIf what you meant was > Think about it: every type of already solved problem you want information about is in them, in fact it is there multiple times, with multiple levels of seriousness in the treatment of the idea. then that was not clear from your comment saying LLMs contain any information you want. One has to be careful communicating about LLms because the world is full of people that actually believe LLMs are generally intelligent super beings. reply arminiusreturns 2 hours agorootparentprevAfter a small prompt engineering: https://0bin.net/paste/zolMrjVz#dgZrZzKU-PlxdkJTdG0pZU9bsCM3... reply gen220 48 minutes agorootparentprevHey! Asking because I know you're a fellow vimmer [0]. Have you integrated LLMs into your editor/shell? Or are you largely copy-pasting context between a browser and vim? This context-switching of it all has been a slight hang-up for me in adopting LLMs. Or are you asking more strategic questions where copy-paste is less relevant? [0] your videos on writing systems software were part of what inspired me to make a committed switch into vim. thank you for those! reply LouisSayers 1 hour agorootparentprev> the ability to describe problems very clearly Yes, and to provide enough context. There's probably a lot that experience is contributing to the interaction as well, for example - knowing when the LLM has gone too far, focusing on what's important vs irrelevant to the task, modularising and refactoring code, testing etc reply ignoramous 10 hours agoparentprev> [David, Former staff engineer at Google ... CTO of Tailscale,] doesn't need LLMs. That he says LLMs make him more productive at all as a hands-on developer, especially around first drafts on a new idea, means a lot to me... Don't doubt for a second the pedigree of founding engs at Tailscale, but David is careful to point out exactly why LLMs work for them (but might not for others): I am doing a particular kind of programming, product development, which could be roughly described as trying to bring programs to a user through a robust interface. That means I am building a lot, throwing away a lot, and bouncing around between environments. Some days I mostly write typescript, some days mostly Go. I spent a week in a C++ codebase last month exploring an idea, and just had an opportunity to learn the HTTP server-side events format. I am all over the place, constantly forgetting and relearning. If you spend more time proving your optimization of a cryptographic algorithm is not vulnerable to timing attacks than you do writing the code, I don't think any of my observations here are going to be useful to you. reply big_youth 3 hours agorootparent> If you spend more time proving your optimization of a cryptographic algorithm is not vulnerable to timing attacks than you do writing the code, I don't think any of my observations here are going to be useful to you. I am not a software dev I am a security researcher. LLM's are great for my security research! It is so much easier and faster to iterate on code like fuzzers to do security testing. Writing code to do a padding oracle attack would have taken me a week+ in the past. Now I can work with an LLM to write code and learn and break within the day. It has accelerated my security research 10 fold, just because I am able to write code and parse and interpret logs at a level above what I was able to a few years ago. reply pplonski86 8 hours agorootparentprevI'm in similar situations, I jump between many environments, mainly between Python and Typescript, however, currently testing a new idea of learning algorithm in C++, and I simply don't always remember all syntax. I was very skeptical about LLMs at first. Now, I'm using LLMs daily. I can focus more on thinking rather than searching stackoverflow. Very often I just need simple function, that it is much faster to create with chat. reply JKCalhoun 6 hours agorootparentAnd if anyone remembers: before Stack Overflow you more or less had to specialize in a domain, become good using a handful of frameworks/API, on one platform. Learning a new language, a new API (god forbid a new platform) was to sail, months long, into seas unknown. In this regard, with first Stack Overflow and now LLMs, the field has improved mightily. reply Vox_Leone 5 hours agoparentprevI have been using LLM to generate functional code from *pseudo-code* with excellent results. I am starting to experiment with UML diagrams, both with LLM and computer vision to actually generate code from UML diagrams; for example a simple activity diagram could be the prompt on LLM 's, and might look like: Start -> Enter Credentials -> Validate -> [Valid] -> Welcome Message -> [Invalid] -> Error Message Corresponding Code (Python Example): class LoginSystem: def validate_credentials(self, username, password): if username == \"admin\" and password == \"password\": return True return False def login(self, username, password): if self.validate_credentials(username, password): return \"Welcome!\" else: return \"Invalid credentials, please try again.\" *Edited for clarity reply jonvk 2 hours agorootparentThis example illustrates one of the risks of using LLMs without subject expertise though. I just tested this with claude and got that exact same validation method back. Using string comparison is dangerous from a security perspective [1], so this is essentially unsafe validation, and there was no warning in the response about this. 1. https://sqreen.github.io/DevelopersSecurityBestPractices/tim... reply brabel 11 hours agoparentprevI am not a genius but have a couple of decades experience and finally started using LLMs in anger in the last few weeks. I have to admit that when my free quota from GitHub Copilot ran out (I had already run out of Jetbrains AI as well!! Our company will start paying for some service as the trials have been very successful), I had a slight bad feeling as my experience was very similar to OP: it's really useful to get me started, and I can finish it much more easily from what the AI gives me than if I started from scratch. Sometimes it just fills in boilerplate, other times it actually tells me which functions to call on an unfamiliar API. And it turns out it's really good at generating tests, so it makes my testing more comprehensive as it's so much faster to just write them out (and refine a bit usually by hand). The chat almost completely replaced my StackOverflow queries, which saves me much time and anxiety (God forbid I have to ask something on SO as that's a time sink: if I just quickly type out something I am just asking to be obliterated by the \"helpful\" SO moderators... with the AI, I just barely type anything at all, leave it with typos and all, the AI still gets me!). reply EagnaIonat 11 hours agorootparentHave you tried using Ollama? You can download and run an LLM locally on your machine. You can also pick the right model for the right need and it's free. reply brabel 6 hours agorootparentYes. If the AI is not integrated with the IDE, it's not as helpful. If there were an IDE plugin that let you use a local model, perhaps that would be an option, but I haven't seen that (Github Copilot allows selecting different models, but I didn't check more carefully whether that also includes a local one, anyone knows?). reply bpizzi 3 hours agorootparent> (Github Copilot allows selecting different models, but I didn't check more carefully whether that also includes a local one, anyone knows?). To my knowledge, it doesn't. On Emacs there's gptel which integrates quiet nicely different LLM inside Emacs, including a local Ollama. > gptel is a simple Large Language Model chat client for Emacs, with support for multiple models and backends. It works in the spirit of Emacs, available at any time and uniformly in any buffer. https://github.com/karthink/gptel reply th4t1sW13rd 2 hours agorootparentprevThis can use Ollama: https://www.continue.dev/ reply oogali 6 hours agorootparentprevIt’s doable as it’s what I use to experiment. Ollama + CodeGPT IntelliJ plugin. It allows you to point at a local instance. reply mark_l_watson 3 hours agorootparentI also use Ollama for coding. I have a 32G M2 Mac, and the models I can run are very useful for coding and debugging, as well as data munging, etc. That said, sometimes I also use Claude Sonnet 3.5 and o1. (BTW, I just published an Ollama book yesterday, so I am a little biassed towards local models.) reply mentos 6 hours agorootparentprevI’m using ChatGPT4o to convert a C# project to C++. Any recommendation on what Ollama model I could use instead? reply neonsunset 6 hours agorootparentThe one that does not convert C# at all and asks you to just optimize it in C# instead (and to use the appropriate build option) :D reply mentos 4 hours agorootparentI’m converting game logic from C# to UE5 C++. So far made great progress using ChatGPT4o and o1 reply neonsunset 3 hours agorootparentDo you find these working out better for you than Claude 3.5 Sonnet? So far I've not been a fan of the ChatGPT models' output. reply mentos 3 hours agorootparentI find ChatGPT better with UE4/5 C++ but they are very close. Biggest advantage is the o1 128k context. I can one shot an entire 1000 line class where normally I’d have to go function by function with 4o. reply devjab 11 hours agorootparentprevI'm genuinely curious but what did you use StackOverflow for before? With a couple of decades in the industry I can't remember when the last time I \"Google programmed\" anything was. I always go directly to the documentation for whatever it is I'm working for, because where else would I find out how it actually works? It's not like I haven't \"Google programmed\" when I was younger, but it's just such a slow process based on trusting strangers on the internet that it never really made much sense once I started knowing what I was doing. I sort of view LLM's in a similar manner. Why would you go to them rather than the actual documentation? I realize this might sound arrogant or rude, and I really hope you believe me when I say that I don't mean it like this. The reason I'm curious is because we're really struggling getting junior developers to not look, everywhere, but the documentation first. Which means they often actually don't know how what they build works. Which can be an issue when they load every object of a list into memory isntead of using a generator... As far as using LLMs in anger I would really advice anyone to use them. GitHub copilot hasn't been very useful for me personally, but I get a lot of value out of running my thought process by a LLM. I think better when I \"think out loud\" and that is obviously challenging when everyone is busy. Running my ideas by an LLM helps me process them in a similar (if not better) fashion, often it won't even really matter what the LLM conjures up because simply describing what I want to do often gives me new ideas, like \"thinking out loud\". As far as coding goes. I find it extremely useful to have LLMs write cli scripts to auto-generate code. The code the LLM will produce is going to be absolute shite, but that doesn't matter if the output is perfectly fine. It's reduced my personal reliance on third party tools by quite a lot. Because why would I need a code generator for something (and in that process trust a bunch of 3rd party libraries) when I can have a LLM write a similar tool in half an hour? reply brabel 6 hours agorootparentI believe you don't mean to be rude, but you just sound completely naive to me. To think that documentation includes everything is just, like, have you actually been coding anything at all that goes just slightly off the happy path? Example from yesterday: I have a modular JavaFX application (i.e. it uses Java JMS modules, not just Maven/Gradle modules). I introduced a call to `url()` in JavaFX CSS. That works when running using the classpath, but not when using the module path. I spent half an hour reading docs to see what they say about modular applications. They didn't mention anything at all. Specially because in my case, I was not just doing `getClass().getResource`... I was using the CSS directive to load a resource from the jar. This is exactly when I would likely go on SO and ask if anyone had seen this before. It used to be highly likely someone who's an expert on JavaFX would see and answer my question, sometimes even people who directly worked on JavaFX! StackOverflow was not really meant for juniors, as juniors usually can indeed find answers on documentation, normally. It was, like ExpertsExchange before it, a place for veterans to exchange tribal knowledge like this. If you think only juniors use SO, you seem to have arrived at the scene just yesterday and just don't know what you're talking about. reply wiseowise 10 hours agorootparentprev> Why would you go to them rather than the actual documentation? Not every documentation is made equal. For example: Android docs are royal shit. They cover some basic things, e.g. show a button, but good look finding esoteric Bluetooth information or package management, etc. Most of it is a mix of experimentation and historical knowledge (baggage). reply devjab 9 hours agorootparent> Not every documentation is made equal. They are wildly different. I'm not sure the Android API reference is that bad, but that is mainly because I've spent a good amount years with the various .Net API references and the Android one is a much more shiny turd than those. I haven't had issues with Bluetooth myself, the Bluetooth SIG has some nice specification PDF's but I assume you're talking about the ones which couldn't be found? I mean this in a \"they don't seem to exist\" kind of way and not that, you specifically, couldn't find them. I agree though. It's just that I've never really found internet answers to be very useful. I did actually search for information a few years back when I had to work with a solar inverter datalogger, but it turned out that having the ridicilously long German engineering manual scanned, OCR processed and translated was faster. Anyway, we all have our great white whales. I'm virtually incapable of understanding the SQLAlchemy documentation as an example, luckily I'll probably never have to use it again. reply greenyouse 12 hours agoparentprevThat approach sounds similar to the Idris programming language with Type Driven Development. It starts by planning out the program structure with types and function signatures. Then the function implementation (aka holes) can be filled in after the function signatures and types are set. I feel like this is a great approach for LLM assisted programming because things like types, function signatures, pre/post conditions, etc. give more clarity and guidance to the LLM. The more constraints that the LLM has to operate under, the less likely it is to get off track and be inconsistent. I've taken a shot at doing some little projects for fun with this style of programming in TypeScript and it works pretty well. The programs are written in layers with the domain design, types, schema, and function contracts being figured out first (optionally with some LLM help). Then the function implementations can be figured out towards the end. It might be fun to try Effect-TS for ADTs + contracts + compile time type validation. It seems like that locks down a lot of the details so it might be good for LLMs. It's fun to play around with different techniques and see what works! reply lysecret 11 hours agorootparent100% this is what I do in python too! reply HarHarVeryFunny 4 hours agoparentprev> His post reminds me of an old idea I had of a language where all you wrote was function signatures and high-level control flow Regardless of language, that's basically how you approach the design of a new large project - top down architecture first, then split the implementation into modules, design the major data types, write function signatures. By the time you are done what is left is basically the grunt work of implementing it all, which is the part that LLMs should be decent at, especially if the functions/methods are documented to level (input/output assertions as well as functionality) where it can also write good unit tests for them. reply dingnuts 4 hours agorootparent> the grunt work of implementing it all you mean the fun part. I can really empathize with digital artists. I spent twenty years honing my ability to write code and love every minute of it and you're telling me that in a few years all that's going to be left is PM syncs and OKRs and then telling the bot what to write if I'm lucky to have a job at all reply HarHarVeryFunny 2 hours agorootparentI think it depends on the size of the project. To me, the real fun of being a developer is the magic of being able to conceive of something and then conjure it up out of thin air - to go from an idea to reality. For a larger more complex project the major effort in doing this is the solution conception, top-down design (architecture), and design of data structures and component interfaces... The actual implementation (coding), test cases and debugging, then does become more like drudgework, not the most creative or demanding part of the project, other than the occasional need for some algorithmic creativity. Back in the day (I've been a developer for ~45 years!) it was a bit different as hardware constraints (slow 8-bit processors with limited memory) made algorithmic and code efficiency always a primary concern, and that aspect was certainly fun and satisfying, and much more a part of the overall effort than it is today. reply mahmoudimus 23 minutes agoparentprevIsn't that the idea behind UML? Which didn't work out so well, however, with the advent of LLMs today, I think that premise could work. reply dekhn 13 hours agoparentprevI think what you're describing is basically \"interface driven development\" and \"test driven development\" taken to the extreme: where the formal specification of an implementation is defined by the test suite. I suppose a cynic would say that's what you get if you left an AI alone in a room with Hyrum's Law. reply benterix 10 hours agoparentprev> designed around filling in the implementations for you. 20 years ago that would have been from a live online database This reminds me a bit of PowerBuilder (or was it PowerDesigner?) from early 1990s. They sold it to SAP later, I was told it's still being used today. reply CraigJPerry 12 hours agoparentprev>> where all you wrote was function signatures and high-level control flow, and maybe some conformance tests around them AIUI that’s where idris is headed reply knighthack 14 hours agoparentprevI knew he was a world-class engineer the moment I saw that his site didn't bother with CSS stylesheets, ads, pictures, or anything beyond a rudimentary layout. The whole article page reads like a site from the '90s, written from scratch in HTML. That's when I knew the article would go hard. Substantive pieces don't need fluffy UIs - the idea takes the stage, not the window dressing. reply shaneofalltrad 13 hours agorootparentI wonder what he uses, I noticed the first paragraph took over a second to load... Largest Contentful Paint element 1,370 ms This is the largest contentful element painted within the viewport. Element p reply cess11 10 hours agorootparentLooks like it loads all the Google surveillance without asking. Should IP-block the EU. reply alexvitkov 7 hours agorootparentprevGlad to know I was a world class engineer at the age of 8, when all I knew were theandtags! reply apwell23 4 hours agoparentprevhe is using llm for coding. you don't become staff engineer by being a badass coder. Not sure how they are related. reply ilrwbwrkhv 11 hours agoparentprevBeing a dev at a large company is usually the sign that you're not very good though. And anyone can start a company with the right connections. reply tomwojcik 9 hours agorootparentThat's a terrible blanket statement, very US-centric. Not everyone wants to start a company and you can't just reduce ones motivations to your measure of success. reply joseda-hg 6 hours agorootparentGod knows many of the best devs I've known would be an absolute nightmare on the business side, they'd rather have a capable business person if they could avoid it reply ksenzee 10 hours agorootparentprevYou've just disproved your own assertion. Either that or you believe everyone who's any good has the right connections. reply highfrequency 10 minutes agoprev> A lot of the value I personally get out of chat-driven programming is I reach a point in the day when I know what needs to be written, I can describe it, but I don’t have the energy to create a new file, start typing, then start looking up the libraries I need... LLMs perform that service for me in programming. They give me a first draft, with some good ideas, with several of the dependencies I need, and often some mistakes. Often, I find fixing those mistakes is a lot easier than starting from scratch. This to me is the biggest advantage of LLMs. They dramatically reduce the activation energy of doing something you are unfamiliar with. Much in the way that you're a lot more likely to try kitesurfing if you are at the beach standing next to a kitesurfing instructor. While LLMs may not yet have human-level depth, it's clear that they already have vastly superhuman breadth. You can argue about the current level of expertise (does it have undergrad knowledge in every field? PhD level knowledge in every field?) but you can't argue about the breadth of fields, nor that the level of expertise improves every year. My guess is that the programmers who find LLMs useful are people who do a lot of different kinds of programming every week (and thus are constantly going from incompetent to competent in things that other people already know), rather than domain experts who do the same kind of narrow and specialized work every day. reply LouisSayers 52 minutes agoprevThe use of LLMs reminds me a bit of how people use search engines. Some years ago I gave a task to some of my younger (but intelligent) coworkers. They spent about 50 minutes searching in google and came back to me saying they couldn't find what they were looking for. I then typed in a query, clicked one of the first search results and BAM! - there was the information they were unable to find. What was the difference? It was the keywords / phrases we were using. reply mlepath 17 hours agoprevThe first rule of programming with LLMs is don't use them for anything you don't know how to do. If you can look at the solution and immediately know what's wrong with it, they are a time saver otherwise... I find chat for search is really helpful (as the article states) reply IanCal 16 hours agoparentThat seems like a wild restriction. You can give them more latitude for things you know how to check. I didn't know how to setup the right gnarly typescript generic type to solve my problem but I could easily verify it's correct. reply kccqzy 7 hours agorootparentIf you merely know how to check, would you also know how to fix it after you find that it's wrong? If you are lucky to have the LLM fix it for you, great. If you don't know how to fix it yourself and the LLM doesn't either, you've just wasted a lot of time. reply IanCal 5 hours agorootparentIt did fix it, I iterated passing in the type and linter errors until it passed all the requirements I had. > If you merely know how to check, would you also know how to fix it after you find that it's wrong? Probably? I'm capable of reading documentation, learning and asking others. > If you don't know how to fix it yourself and the LLM doesn't either, you've just wasted a lot of time. You may be surprised by how little time, but regardless it would have taken more time to hit that point without the tool. Also sometimes things don't work out, that's OK. As long as overall it improves work, that's all we need. reply fastball 7 hours agorootparentprevIf you don't understand what the generic is doing, there might be edge-cases you don't appreciate. I think Typescript types are fairly non-essential so it doesn't really matter, but for more important business logic it definitely can make a difference. reply IanCal 5 hours agorootparentI understand what it's doing, and could easily set out the cases I needed. reply billmcneale 15 hours agoparentprevThat's the wrong approach. I use chat for things I don't know how to do all the time. I might not know how to do it, but I sure know how to test that what I'm being told is correct. And as long as it's not, I iterate with the chat bot. reply WhiteNoiz3 15 hours agorootparentA better way to phrase it might be don't use it for something that you aren't able to verify or validate. reply sdesol 15 hours agorootparentI agree with this. I keep harping on this, but we are sold automation instead of a power tool. If you have domain knowledge in the problem that you are solving, then LLMs can become an extremely valuable aid. reply bityard 3 hours agorootparentprevI feel like that's a good option ONLY if the code you are writing will never be deployed to an environment where security is a concern. Many security bugs in code are notoriously difficult to spot and even frequently slip through reviews from humans who are actively looking for exactly those kinds of bugs. I suppose we could ask the question: Are LLMs better at writing secure code than humans? I'll admit I don't know the answer to that, but given what we know so far, I seriously doubt it. reply photon_collider 16 hours agoparentprev\"Trust but verify\" is still useful especially when you ask LLMs to do stuff you don't know. I've used LLMs to help me get started on tasks where I wasn't even sure of what a solution was. I would then inspect the code and review any relevant documentation to see if the proposed solution would work. This has been time consuming but I've learned a lot regardless. reply itsgrimetime 16 hours agoparentprevIMO this is a bad take. I use LLMs for things I don’t know how to do myself all the time. Now, I wouldn’t use one to write some new crypto functions because the risk associated with getting it wrong is huge, but if I need to write something like a wrapper around some cloud provider SDK that I’m unfamiliar with, it gets me 90% of the way there. It also is way more likely to know at least _some_ of the best practices where I’ll likely know none. Even for more complex things getting some working hello world examples from an LLM gives me way more threads to pull on and research than web searching ever has. reply Retr0id 16 hours agorootparent> if I need to write something like a wrapper around some cloud provider SDK that I’m unfamiliar with But \"writing a wrapper\" is (presumably) a process you're familiar with, you can tell if it's going off the rails. reply joemazerino 15 hours agorootparentWriting a wrapper is easier to verify because of the context of the API or SDK you're wrapping. Seems wrong? Check the docs. Doesn't work? Curl it yourself. reply Barrin92 15 hours agorootparentprev>It also is way more likely to know at least _some_ of the best practices What's way more likely to know the best practices is the documentation. A few months ago there was a post that made the rounds about how the Arc browser introduced a really severe security flaw by misconfiguring their Firebase ACLs despite the fact that the correct way to configure them is outlined in the docs. This to me is the sort of thing (although maybe not necessarily in this case) out of LLM programming. 90% isn't good enough, it's the same as Stackoverflow pasting. If you're a serious engineer and you are unsure about something, it is your task to go to the reference material, or you're at some point introducing bugs like this. In our profession it's not just crypto libraries, one misconfigured line in a yaml file can mean causing millions of dollars of damage or leaking people's most private information. That can't be tackled with a black box chatbot that may or may not be accurate. reply tnvmadhav 13 hours agoparentprevI'd like to rephrase as, \"don't deploy LLM generated code if you don't know how it works (or what it does)\" This means, it's okay to use LLM to try something new that you're on the fence about. Learn it and then once you've learned that concept or the idea, you can go ahead to use same code if it's good enough. reply JKCalhoun 6 hours agorootparent\"don't deploy ̶L̶L̶M̶ ̶g̶e̶n̶e̶r̶a̶t̶e̶d̶ code if you don't know how it works (or what it does)\" (Which goes for StackOverflow, etc.) reply switchbak 49 minutes agorootparentI've seen a whole flurry of reverts due to exactly this. I've also dabbled in trusting it a little too much, and had the expected pain. I'm still learning where it's usable and where I'm over-reaching. At present I'm at about break-even on time spent, which bodes well for the next few years as they iron out some of the more obvious issues. reply ignoramous 9 hours agoparentprev> ... don't use them for anything you don't know how to do ... I find chat for search is really helpful (as the article states) Not really. I often use Chat to understand codebases. Instead trying to navigate mature, large-ish FOSS projects (like say, the Android Run Time) by looking at it file by file, method by method, field by field (all to laborious), I just ask ... Copilot. It is way, way faster than I and are mostly directionally correct with its answers. reply qianli_cs 16 hours agoparentprevExactly, you have to (vaguely) know what you’re looking for and have some basic ideas of what algorithms would work. AI is good at helping with syntax stuff but not really good at thinking. reply SkyBelow 3 hours agoparentprevHow you use the LLM matters. Having an LLM do something for you that you don't know how to do is asking for trouble. An expert likely can off load a few things they aren't all that important, but any junior is going to dig themselves into a significant hole with this technique. But asking an LLM to help you learn how to do something is often an option. Can't one just learn it using other resources? Of course. LLMs shouldn't be a must have. If at any point you have to depend upon the LLM, that is a red flag. It should be a possible tool, used when it saves time, but swapped for other options when they make sense. For an example, I had a library I was new to and asked copilot how to do some specific task. It gave me the options. I used this output to go to google and find the matching documentation and gave it a read. I then when back to copilot and wrote up my understanding of what the documentation said and checked to see if copilot had anything to add. Could I have just read the entire documentation? That is an option, but one that costs more time to give deeper expertise. Sometimes that is the option to go with, but in this case having a more shallow knowledge to get a proof of concept thrown together fit my situation better. Anyone just copying an AI's output and putting it in a PR without understanding what it does? That's asking for trouble and it will come back to bite them. reply j45 15 hours agoparentprevYou can ask the LLM to teach it to you step by step, and then you can validate it by doing it as well as you go, still quicker than learning it and not knowing how to debug it. Learning how something works is critical or it's far worse than technical debt. reply lelandfe 12 hours agorootparentYes, I have a friend learning their first programming language with much assistance from ChatGPT and it's actually going really well. reply j45 12 hours agorootparentAwesome, I wish more people knew about this compared to trying to do magic Harry Potter single prompt to do everything. reply turnsout 15 hours agoparentprevI completely agree. In graphics programming, I love having it do things that are annoying but easy to verify (like setting up frame buffers in WebGL). I also ask it do more ambitious things like implementing an algorithm in shader code, and it will sometimes give a result that is mostly correct but subtly wrong. I only have been able to catch those subtle errors because I know what to look for. reply kamaal 15 hours agoparentprev>>f you can look at the solution and immediately know what's wrong with it, they are a time saver otherwise... Indeed getting good at writing code using LLMs demands being very good at reading code. To that extent its more like blitz chess than autocomplete. You need to think and verify in trees as it goes. reply logicchains 8 hours agoparentprevDon't use them for anything you don't know how to test. If you can write unit tests you understand and it passes them all (or visually inspect/test a GUI it generated), you know it's doing well. reply staticautomatic 12 hours agoparentprevMy experience is the opposite. I find them most valuable for helping me do things that would be extremely hard or impossible for me to figure out. To wit, I just used one to decode a pagination cursor format and write a function that takes a datetime and generates a valid cursor. Ain’t nobody got time for that. reply nunez 4 hours agoprevI definitely respect David's opinion given his caliber, but pieces like this make me feel strange that I just don't have a burning desire to use them. Like, yesterday I made some light changes to a containerized VPN proxy that I maintain. My first thought wasn't \"how would Claude do this?\" Same thing with an API I made a few weeks ago that scrapes a flight data website to summarize flights in JSON form. I knew I would need to write some boilerplate and that I'd have to visit SO for some stuff, but asking Claude or o1 to write the tests or boilerplate for me wasn't something I wanted or needed to do. I guess it makes me slower, sure, but I actually enjoy the process of making the software end to end. Then again, I do all of my programming on Vim and, technically, writing software isn't my day job (I'm in pre-sales, so, best case, I'm writing POC stuff). Perhaps I'd feel differently if I were doing this day in, day out. (Interestingly, I feel the same way about AI in this sense that I do about VSCode. I've used it; I know what's it capable of; I have no interest in it at all.) The closest I got to \"I'll use LLMs for something real\" was using it in my backend app that tracks all of my expenses to parse pictures of receipts. Theoretically, this will save me 30 seconds per scan, as I won't need to add all of the transaction metadata myself. Realistically, this would (a) make my review process slower, as LLMs are not yet capable of saying \"I'm not sure\" and I'd have to manually check each transaction at review time, (b) make my submit API endpoint slower since it takes relatively-forever for it to analyze images (or at least it did when I experimented with this on GPT4-turbo last year), and (c) drive my costs way up (this service costs almost nothing to run, as I run it within Lambda's free tier limit). reply uludag 3 hours agoparentI think there's a big selection bias on hackernews that you wouldn't get elsewhere. There's still \"elite\" software developers I see who really aren't into the whole LLM tooling space. I found use in the autocomplete and search workflows that the author mentioned but I stopped using these tools, out of curiosity for things were before. It turns out I don't need it to be productive and I too probably enjoy working more without it. reply hansvm 1 hour agoprevThat quartile reservoir sampler example is ... intriguing? My experience with LLM code is that it can't come up with anything even remotely novel. If I say \"make it run in amortized O(1)\" then 99 times out of 100 I'll get a solution so wildly incorrect (but confidently asserting its own correctness) that it can't possibly be reshaped into something reasonable without a re-write. The remaining 1/100 times aren't usually \"good\" either. For the reservoir sampler -- here, it did do the job. David almost certainly knows enough to know the limits of that code and is happy with its limitations. I've solved that particular problem at $WORK though (reservoir sampling for percentile estimates), and for the life of me I can't find a single LLM prompt or sequence of prompts that comes anywhere close to optimality unless that prompt also includes the sorts of insights which lead to an amortized O(1) algorithm being possible (and, even then, you still have to re-run the query many times to get a useful response). Picking on the article's solution a bit, why on earth is `sorted` appearing in the quantile estimation phase? That's fine if you're only using the data structure once (init -> finalize), but it's uselessly slow otherwise, even ignoring splay trees or anything else you could use to speed up the final inference further. I personally find LLMs helpful for development when either (1) you can tolerate those sorts of mishaps (e.g., I just want to run a certain algorithm through Scala and don't really care how slow it is if I can run it once and hexedit the output), or (2) you can supply all the auxilliary information so that the LLM has a decent chance of doing it right -- once you've solved the hard problems, the LLM can often get the boilerplate correct when framing and encapsulating your ideas. reply wdutch 15 hours agoprevI no longer work in tech, but I still write simple applications to make my work life easier. I frequently use what OP refers to as chat-driven programming, and I find it incredibly useful. My process starts by explaining a minimum viable product to the chat, which then generates the code for me. Sometimes, the code requires a bit of manual tweaking, but it’s usually a solid starting point. From there, I describe each new feature I want to add—often pasting in specific functions for the chat to modify or expand. This approach significantly boosts what I can get done in one coding session. I can take an idea and turn it into something functional on the same day. It allows me to quickly test all my ideas, and if one doesn’t help as expected, I haven’t wasted much time or effort. The biggest downside, however, is the rapid accumulation of technical debt. The code can get messy quickly. There's often a lot of redundancy and after a few iterations it can be quite daunting to modify. reply prettyblocks 14 hours agoparentI have a similar approach, but the mess can be contained by asking for optimizations and refactors very frequently and only asking for very granular features. reply chii 14 hours agoparentprev> The code can get messy quickly. There's often a lot of redundancy and after a few iterations it can be quite daunting to modify. i forsee in the future an LLM that has sufficient context length for (automatic) refactoring and tech debt removal, by pasting large portions of these existing code in. reply scarface_74 13 hours agorootparentEven without LLMs, at least with statically type languages like C#, ReSharper can do solution wide refactoring that are guaranteed correct as long as you don’t use reflection. https://www.jetbrains.com/help/resharper/Refactorings__Index... I don’t see any reason it couldn’t do more aggressive refactors with LLMs and either correct itself or don’t do the refactor if it fails static code checking. Visual Studio can already do real time type checking for compile time errors reply Aeolun 10 hours agorootparentprevCursor has recently added something like this ‘Bug Finder’. It told me that finding bugs on my entire codebase would cost me $21 or so, so I never actually tried, but it sounds cool. reply trash_cat 4 hours agoparentprev> The biggest downside, however, is the rapid accumulation of technical debt. The code can get messy quickly. There's often a lot of redundancy and after a few iterations it can be quite daunting to modify. What stops you from using o1 or sonnet to refactor everything? It sounds like a typical LLM task. reply SkyBelow 3 hours agoparentprev>The biggest downside, however, is the rapid accumulation of technical debt. Is that really related to the LLM? Even in pre-LLM times, anytime I've scrapped together some code to solve some small immediate problem it grows tech debt at an amazing rate. Getting a feel for when a piece of code is going to be around long enough that it needs to be refactored, cleaned up, documented, etc. is a skill I developed over time. Even now it isn't a prefect guess, as there is an ongoing tug of war between wasting time today refactoring something I might not touch again with wasting time tomorrow having to pick up something I didn't clean up. reply j45 15 hours agoparentprevIs there a model you prefer to use? reply KTibow 14 hours agorootparentNot wdutch but Claude Sonnet is one of the best models out there for programming, o1 is sometimes better but costs more reply Ozzie_osman 13 hours agoprevOne mode I felt was missed was \"thought partner\", especially while debugging (aka rubber ducking). We had an issue recently with a task queue seemingly randomly stalling. We were able to arrive at the root cause much more quickly than we would have because of a back-and-forth brainstorming session with Claude, which involved describing the issue we were seeing, pasting in code from library to ask questions, asking it to write some code to add some missing telemetry, and then probing it for ideas on what might be going wrong. An issue that may have taken days to debug took about an hour to identify. Think of it as rubber ducking with a very strong generalist engineer who knows about basically any technical concepts. reply vendiddy 11 hours agoparentI found myself doing this with o1 recently for software architecture. I will evaluate design ideas with the model, express concerns on trade-offs, ask for alternative ideas, etc. Some of the benefit is having someone to talk to, but with proper framing it is surprisingly good at giving balanced takes. reply mmahemoff 13 hours agoparentprevThe new video and screen-share capabilities in ChatGPT and Gemini should make rubber-ducking smoother. I feel like I've worn out my computer’s clipboard and alt-tab keys at this stage of the LLM experience. reply fragmede 8 hours agorootparentYou may want to try any of the tools that can write to the filesystem so you're at least not copy pasting code from a chat window. CoPilot, Cursor, Aider, Tabnine, etc. reply nemothekid 15 hours agoprevI think \"Chat driven programming\" is the most common type of the most hyped LLM-based programming I see on twitter that I just can't relate to. I've incorporated LLMs mainly as auto-complete and search; asking ChatGPT to write a quick script or to scaffold some code for which the documentation is too esoteric to parse. But having the LLM do things for me, I frequently run into issues where it feels like I'm wasting my time with an intern. \"Chat-based LLMs do best with exam-style questions\" really speaks to me, however I find that constructing my prompts in such a way where the LLM does what I want uses just as much brainpower as just programming the thing my self. I do find ChatGPT (o1 especially) really good at optimizing existing code. reply tptacek 15 hours agoparentThere's an art to cost-effectively coaxing useful answers (useful drafts of code) from an LLM, and there's an art to noticing the most productive questions to put to that process. It's a totally different way of programming than having an LLM looking over your shoulder while you direct, function by function, type by type, the code you're designing. If you feel like you're wasting your time, my bet is that you're either picking problems where there isn't enough value to negotiate with the LLM, or your expectations are too high. Crawshaw mentions this in his post: a lot of the value of this chat-driven style is that it very quickly gets you unstuck on a problem. Once you get to that point, you take over! You don't convince the LLM to build the final version you actually commit to your branch. Generating unit test cases --- in particular, generating unit test cases that reconcile against unsophisticated, brute-force, easily-validated reference implementations of algorithms --- are a perfect example of where that cost/benefit can come out nicely. reply sibeliuss 14 hours agoparentprevMy technique is to feed it a series of intro questions that prepare it for the final task. Chat the thing into a proper comfort level, and then from there, with the context at hand, ask to help solve the real problem. Def feels like a new kind of programming model because its still very programming-esque. reply throwup238 15 hours agoparentprev> \"Chat-based LLMs do best with exam-style questions\" really speaks to me, however I find that constructing my prompts in such a way where the LLM does what I want uses just as much brainpower as just programming the thing my self. It speaks to me too because my mechanical writing style (as opposed to creative prose) could best be described as what I learned in high school AP English/Literature and the rest of the California education system. For whatever reason that writing style dominated the training data and LLMs just happens to be easy to use because I came out of the same education system as many of the people working at OpenAI/Anthropic. I’ve had to stop using several generic turns of phrase like “in conclusion” because it made my writing look too much like ChatGPT. reply Aeolun 10 hours agoparentprevI’ve found that everything just works (more or less) since switching to Cursor. Agent based composer mode is magical. Just give it a few files for context, and ask it to do what you want. reply AlotOfReading 15 hours agoparentprevIt's interesting that you find it useful for optimization. I've found that they're barely capable of anything more than shallow optimization in my stuff without significant direction. What I find useful is that I can keep thinking at one abstraction level without hopping back and forth between algorithm and codegen. The chat is also a written artifact I can use the faster language parts of my brain on instead of the slower abstract thought parts. reply notjoemama 16 hours agoprevOur company has a no AI use policy. The assumption is zero trust. We simply can’t know whether a model or its framework could or would send proprietary code outside the network. So it’s best to assume all LLMs/AI is or will send code or fragments of code. While I applaud the incredible work by their creators, I’m not sure how a responsible enterprise class company could rely on “trust us bro” EULAs or repo readmes. reply codebje 16 hours agoparentThe same way responsible enterprise class companies rely on \"trust us bro\" EULAs for financial systems, customer databases, payroll, and all the other systems it would be very expensive and error prone to build custom for every business. reply BBosco 14 hours agoparentprevThe vast majority of fortune 500’s have legal frameworks up for dealing with internal AI use already because the reality is employees are going to use it regardless of internal policy. Assuming every employee will act in good faith just because a blanket AI ban is in place is extremely optimistic at best, and isn’t a good substitute for actual understanding. reply sulam 14 hours agorootparentInternal policies at these companies are rarely subject to a level of faith that you're implying. Instead external access to systems is logged, internal systems are often sandboxed or otherwise constrained in how you interact with them, and anything that looks like exfiltration sets off enough alarms to have your manager talking to you that same day, if not that same hour. reply cudgy 3 hours agoparentprevDoes your company develop software overseas where legal action is difficult? Or where their ip could be nationalized or secretly stolen? Where network communications are monitored and saved? reply pama 16 hours agoparentprevYour company could locally host LLMs; you wont get chatGPT or Claude quality, but you can get something that would have been SOTA a year ago. You can vet the public inference codebases (they are only of moderate complexity), and you control your own firewalls. reply Kostchei 15 hours agorootparentYou can get standalone/isolated versions of chatGPT, if your org is large enough, in partnership with OpenAI. And others. They run on the same infra but in accounts you set up, cost the same, but you have visibility on the compute, and control of data exfil - ie is there is none. reply CubsFan1060 15 hours agorootparentprevYou can run Claude on both AWS and Google Cloud. I’m fairly certain they don’t share data, but would need to verify to be sure. reply evilduck 14 hours agorootparentYou can also run Llama 405B and the latest (huge) DeepSeek on your own hardware and get LLMs that trade blows with Claude and ChatGPT, while being fully isolated and offline if needed. reply krembo 12 hours agorootparentWith Amazon Bedrock you can get an isolated serverless Claude or llama with a few clicks reply attentive 15 hours agoparentprevSo, you're asking how enterprise class companies are using github for repos and gmail for all the enterprise mail? What's next, zoom/teams for meetings? reply lm28469 5 hours agoparentprev> I’m not sure how a responsible enterprise class company could rely on “trust us bro” EULAs or repo readmes. Isn't that what we do with operating systems, internet providers, &c. ? reply aulin 5 hours agorootparentHow is that related? we're talking of continuously sending proprietary code and related IP to a third party, seems a pretty valid concern to me. I, for one, work every day with plenty of proprietary vendor code under very restrictive NDAs. I don't think they would be very happy knowing I let AIs crawl our whole code base and send it to remote language models just to have fancy autocompletion. reply bongodongobob 38 minutes agorootparentOk, the LLM crawls your code. Then what? What is the exfiltration scenario? reply lm28469 5 hours agorootparentprevDo you read every single line of code of every single dependency you have ? I don't see how llms are more of a threat than a random compromised npm package or something from a OS package manager. Chances are you're already relying on tons and tons of \"trust me bro\" and \"it's opensource bro don't worry, just read the code if you feel like it\" reply aulin 4 hours agorootparentOne thing is consciously sharing IP with third parties violating contracts, another is falling victim of malicious code in the toolchain. Npm concern though suggests we likely work in very different industries so that may explain the different perspective. reply tsukikage 5 hours agoparentprevYou can get models that run offline. The other risk is copyright/licensing exposure; e.g. the AI regurgitates a recognisably large chunk of GPL code, and suddenly you have a legal landmine in your project waiting to be discovered. There's no sane way for a reviewer to spot this situation in general. You can ask a human to not do that, and there are various risks to them personally if they do so regardless. I'd like to see the AI providers take on some similar risks instead of disclaiming them in their EULAs before I trust them the way I might a human. reply janalsncm 13 hours agoparentprevYou can run pretty decent models on your laptop these days. Works in airplane mode. https://ollama.com/ reply lazybreather 15 hours agoparentprevPalo Alto networks provides security product \"AI access security\" which claims to solve the problem you mentioned - access control, data protection etc. I don't personally use it neither does my org. Giving here just in case it is useful for someone. reply Pyxl101 14 hours agoparentprevJust curious, how does your company host its email? Documents? Files? reply j45 15 hours agoparentprevLocal LLMs for code aren't that out of the question to run. Even for not code generation, but even smaller models only for programming to weigh on different design approaches, etc. reply golergka 11 hours agoparentprevWhat's the realistic attack scenario? Will Sam Altman steal your company's code? Or will next version of GPT learn on your secret sauce algorithms and then your competitors will get them when they generate code for their tasks and your company loses its competitive advantage? I'm actually sure that there are companies for which these scenarios are very real. But I don't think there's a lot of them. Most of the code our industry works on has very little value outside of context of particular product and company. reply cudgy 3 hours agorootparentSo why bother securing anything at all if not willing to secure the raisons d'être? Doesn’t that suggest that these companies are trivial entities? reply golergka 30 minutes agorootparentThere are plenty of very realistic attack scenarios, that's why we secure stuff. reply Aeolun 10 hours agoparentprevI mean, we host our code on Github. What are they going to do with Copilot code snippets? reply mbesto 6 hours agoparentprev> proprietary code outside the network Thought exercise: what would seriously happen if you did let some of your proprietary code outside your network? Oddly enough, 75% of the people writing code on HN probably have their companies code stored in GitHub. So there already is an inherent trust factor with GH/MSFT. As another anecdote - Twitch's source code got leaked a few years back. Did Twitch lose business because of it? reply switchbak 43 minutes agorootparentThe other consideration: your company's code probably just isn't that good. I think many people over-value this giant pile of text. That's not to say IP theft doesn't exist, but I think the actual risk is often overblown. Most of an organization's value is in the team's collective knowledge and teamwork ability, not in the source code. reply aulin 4 hours agorootparentprev> Thought exercise: what would seriously happen if you did let some of your proprietary code outside your network Lawsuits? Lawful terminations? Financial damages? reply mbesto 3 hours agorootparentHuh? No, i'm saying, what potential damage does an organization have? Not the individual who may leak data outside your network. reply aulin 3 hours agorootparentThose are risks both for the individual and for the company when there are contracts in place with third parties involving code sharing. Other risks include leaking industrial secrets that may significantly damage company business or benefit competitors. reply brabel 11 hours agoprevWhat the author is asking about, a quick sketchpad where you can try out code quickly and chat with the AI, already exists in the JetBrains IDEs. It's called a scratch file[1]. As far as I know, the idea of a scratch \"buffer\" comes from emacs. But in Jetbrains IDEs, you have the full IDE support even with context from your current project (you can pick the \"modules\" you want to have in context). Given the good integration with LLMs, that's basically what the author seems to want. Perhaps give GoLand[2] a try. Disclosure: no, I don't work for Jetbrains :D just a very happy customer. [1] https://www.jetbrains.com/help/idea/scratches.html [2] https://www.jetbrains.com/go/ reply bangaladore 16 hours agoprevThe killer feature about LLMs with programming in my opinion is autocomplete (the simple copilot feature). I can probably be 2-3x more productive as I'm not typing (or thinking much). It does a fairly good job pulling in nearby context to help it. And that's even without a language server. Using it to generate blocks of code in a chat like manner in my opinion just never works well enough in the domains I use it on. I'll try to get it to generate something and then realize when I get some functional result I could've done it faster and more effectively. Funny enough, other commenters here hate autocomplete but love chat. reply switchbak 41 minutes agoparentI had to turn autocomplete off. I value it when I want it, but otherwise it's such a distraction that it both slows me down, and actively irritates me. Perhaps I'm just an old man telling the LLM to get off my lawn, but I find it does bad things to my ability to concentrate on hard things. Having a good sense of when it would be useful, and invoking it on demand seems to be a decent enough middle ground for me. Much of it boils down to UX - if it could be present but not actively distracting, I'd probably be ok with it. reply imhoguy 3 hours agoparentprevBoth autocomplete and chat are half-way UX solutions. Really what I need is some kind of mix of in-place chat with completion. For context, very often I have to put some comment before the line for completion to set an expectation context. Instead editor should allow me to influence completion with some kind of in-place suggestion input available under keyboard shortcut. Then I could type what I want into such input and when I hit Enter or Tab the completion proposal appears. Even better if it would let me undo/modify such input, and have shortcuts like \"show me different option\", \"go back to previous\". reply m3kw9 16 hours agoparentprevThe autocomplete is mostly a nusance and maybe low percentage of the time it does right. reply jghn 3 hours agorootparentI thought so too. Until I worked with a client who doesn't allow the use of LLM tools, and I had to turn my Copilot off. That's when I realized how much I'd grown to rely on it despite the headaches. reply LVB 14 hours agorootparentprevThe biggest nuisance aspect for me is when it is trying to do things that the LSP can do 100% correctly. Almost surely it is my tooling setup and the LLM is squashing LSP stuff. Seeing Copilot (or even Cursor) suggesting methods or parameters that don't exist is really annoying. Just stand down and let the LSP answer those basic questions, TYVM. reply throwup238 12 hours agorootparentCursor ostensibly has a config setting to run a “shadow” workspace [1], aka a headless copy of the window you’re working in to get feedback from linters and LSPs but they’ve been iterating so fast I’m not sure it’s still working (or ever did much, really). It really feels like we’re at the ARPANET stage where there’s so much obvious hanging fruit, it’s just going to take companies a while to perfect it. [1] https://www.cursor.com/blog/shadow-workspace reply ahoka 6 hours agorootparentprevThe industry standard was 40% accepted the last time I checked. Correct could be a bit lower, so maybe 1/3? It’s like having to delete the auto-closed parenthesis more often than not. reply tptacek 15 hours agorootparentprevYeah, I don't like it either. I think it speaks to the mindset difference Crawshaw is talking about here. When I'm writing code, I don't want things getting in my way. I have a plan. I'm actually pretty Zen about all the typing. It's part of my flow-state. But when I'm exploring code in a dialog with a chatbot, I'm happy for the help. reply switchbak 38 minutes agorootparentI think we're going to be considered dinosaurs pretty soon. Much like how it's getting harder to buy a manual transmission, programming 'the old way' will probably just fade away over time. reply LeftHandPath 15 hours agoparentprevI’ve never used it, simply because I hate autocomplete in emails. Gmail autocomplete saves me maybe 2-5s per email: the recipients name, a comma, and a sign off. Maybe a quarter or half sentence here or there, but never exactly what I would’ve typed. In code bases, I’ve never seen the appeal. It’s only reliably good at stuff that I can easily find on Google. The savings are inconsequential at best, and negative at worst when it introduces hard-to-pinpoint bugs. LLMS are incredible technology, but when applied to code, they act more like non-deterministic macros. reply switchbak 36 minutes agorootparent\"negative at worst when it introduces hard-to-pinpoint bugs\" - this is actually very true. I've had it recreate patterns _partially_, and paste in the wrong thing in a place that was very hard to discern. It probably saved me 40 mins, then proceeded to waste 2 hours of me hunting for that issue. I'm probably at the break-even on the whole. The ultimate promise is very compelling, but my current use isn't particularly amazing. I do use a niche language though, so I'm outside the global optima. reply rafaelmn 13 hours agoprevI disagree about search. While LLM can give you an answer faster, good doc (eg. MDN article in CSS example) will : - be way more reliable - probably be up to date on how you should solve it in latest/recommend approach - put you in a place where you can search for adjecent tech LLM with search has potential but I'd like if current tools are more oriented on source material rather than AI paraphrasing. reply cruffle_duffle 13 hours agoparentOne of my tricks is to paste the docs right into the context so the model can’t fuck it up. Though I still wonder if that means I’m only tricking myself into thinking the LLM is increasing my productivity. reply rafaelmn 13 hours agorootparentI likr this approach. Read the docs, figure out what you want, get LLM to do the grunt work with all relevant context and review. reply EGreg 6 hours agoparentprevI have found LLMs to be 95% useful on documented software, from everything eg Uniswap smart contracts to plugins in cordova to setting up Mac or Linux administrative tools. The problem for a regular person is that you have to copypasye from chat. That is “the last mile”. For terminal commands that’s fine but for programming you need a tool to automate this. Something like refactoring a function, given the entire context, etc. And it happening in the editor and you seeing a diff right away. The rest of the explanatory text should go next to the diff in a separate display. I bet someone can make a VSCode extension that chats with an LLM and does exactly this. The LLM is told to provide all the sections labeled clearly (code, explanation) and the editor makes the diff. Having said all that, good libraries that abstract away differences are far superior to writing code with an LLM. The only code that needs to be written is the interface and wiring up between the libraries. reply btbuildem 3 hours agoprevThe search part really resonates with me. I do a lot of odd/unusual/one-off things for my side projects, and I use LLMs extensively in helping me find a path forward. It's like an infinitely patient, all-knowing expert that pulls together info from any and all domain. Sometimes it will have answers that I am unable to find another way (eg, what's the difference between \"busy s...\" and \"busy p...\" AT command response on the esp8285?). It saves me hours of struggle, and I would not want to go back to the old ways. reply fassssst 3 hours agoprevThey’re pretty great for printf debugging. Yesterday I was confounded by a bug so I rapidly added a ton of logging that the LLM wrote instantly, then I had the LLM analyze the state difference between the repro and non repro logs. It found something instantly that it would have taken me a few hours to find, which led me to a fix. reply sublimefire 5 hours agoprevI've been doing that for a while as well and mostly agree. Although one thing that I find useful is to build the local infrastructure to be able to collect useful prompts and the ability to work with files and urls. Web interface is limiting alone. I like gptresearcher and all of the glue put in place to be able to extend prompts and agents etc. Not to mention the ability to fetch resources from the web and do research type summaries on it. All in all it reminds me the work of security researchers, pentesters and analysts. Throughout the career they would build a set of tools and scripts to solve various problems. LLMs kind of force the devs to create/select tools for themselves to ease the burden of their specific line of work as well. You could work without LLMs but maybe it will be a bit more difficult to stand out in the future. reply wrs 16 hours agoprevI’ve been working with Cursor’s agent mode a lot this week and am seeing where we need a new kind of tool. Because it sees the whole codebase, the agent will quickly get into a state where it’s changed several files to implement some layering or refactor something. This requires a response from the developer that’s sort of like a code review, in that you need to see changes and make comments across multiple files, but unlike a code review, it’s not finished code. It probably doesn’t compile, big chunks of it are not quite what you want, it’s not structured into coherent changesets…it’s kind of like you gave the intern the problem and they submitted a bit of a mess. It would be a terrible PR, but it’s a useful intermediate state to take another step from. It feels like the IDE needs a new mode to deal with this state, and that SCM needs to be involved somehow too. Somehow help the developer guide this somewhat flaky stream of edits and sculpt it into a good changeset. reply Aeolun 9 hours agoparentI think the full agent mode context is actually often hard to see, but there’s a list somewhere. The list of files in your chat dialog is not the full context (it adds open files too). I find that if I reduce the context size Cursor gives me much better results. reply fragmede 16 hours agoparentprevAider commits to git with each command, making it easy to back out changes, and also squash them into discrete chunks later (and reorder them with interactive rebase). reply golergka 11 hours agorootparentAutomatically runs linter and tests on every edit and forwards failures back to LLM as well. reply choeger 10 hours agoprevEssentially, an LLM is a compressed database with a universal translator. So what we can get out of it is everything that has been written (and publicly released) before translated to any language it knows about. This has some consequences. 1. Programmers still need to know what algorithms or interfaces or models they want. 2. Programmers do not have to know a language very well anymore, to write code, but the have to for bug fixing. Consequently the rift between garbage software and quality software will grow. 3. New programming languages will face a big economical hurdle to take off. reply williamcotton 6 hours agoparent3. New programming languages will face a big economical hurdle to take off. I bet the opposite. I’ve written a number of DSLs and tooling around them over the last year as LLMs have allowed me to take on much bigger projects. I expect we see an explosion of languages over the next decade. reply ripped_britches 13 hours agoprevI’ll say that the payoff for investing the time to learn how to do this right is huge. Especially with cursor which allows me to easily chat around context (docs, library files, etc) reply Aeolun 9 hours agoparentI didn’t believe it could be so good until I actually used it. It’s a shame some of their models are proprietary because that means I can’t use it for work. Would love if the thing worked purely with Copilot Chat (like Zed does), or if Zed added a similar composer mode. reply justatdotin 16 hours agoprevlots of colleauges using copilot or whatever for autocomplete - I just find that annoying. or writing tests - that's ... not so helpful. worst is when a lazy dev takes the generated tests and leaves it at that: usually just a few placeholders that test the happy path but ignore obvious corner cases. (I suppose for API tests that comes down to adding test case parameters) but chatting about a large codebase, I've been amazed at how helpful it can be. what software patterns can you see in this repo? how does the implementation compare to others in the organisation? what common features of the pattern are missing? also, like a linter on steroids, chat can help explore how my project might be refactored to better match the organisation's coding style. reply roskilli 16 hours agoparentIf you don’t mind me asking: which popular LLM(s) have you been using for this and how are you providing the code base into the context window? reply fragmede 8 hours agorootparentNot OP but Aider provides a repo map to the LLM as context, which consists of the directory tree, filenames, and important symbols in each file. It can use the popular LLMs as well as Ollama. https://aider.chat/docs/repomap.html Aider hosts a leaderboard that rates LLMs on performance, including a section on refactoring. https://aider.chat/docs/leaderboards/refactor.html reply Zambyte 3 hours agorootparentAI generated images can be good, and even reasonable to use for branding. Slapping an image right at the top of the page that says \"Abstract Synxex Tree\" with a meaningless graph and an absolutely expressionless and useless humanoid robot is a great way to immediately lose my interest in anything they have to say though. The homepage would be more interesting as a wall of text. reply ianpurton 6 hours agoprevI've been coding professionally for 30 years. I'm probably in the same place as the author, using Chat-GPT to create functions etc, then cut and pasting that into VSCode. I've started using cline which allows me to code using prompts inside VSCode. i.e. Create a new page so that users can add tasks to a tasks table. I'm getting mixed results, but it is very promising. I create a clinerules file which gets added to the system prompt so the AI is more aware of my architecture. I'm also looking at overiding the cline system prompt to both make it fit my architecture better and also to remove stuff I don't need. I jokingly imagine in the future we won't get asked how long a new feature will take, rather, how many tokens will it take. reply thomasfromcdnjs 5 hours agoparentLove the token joke! reply dxuh 9 hours agoprevCurrently a lot of my work consists of looking at large, (to me) unknown code bases and figuring out how certain things work. I think LLMs are currently very bad at this and it is my understanding that there are problems in increasing context window sizes to multiple millions of tokens, so I wonder if LLMs will ever get good at this. reply singpolyma3 15 hours agoprevIt seems like everything I see about success using LLMs for this kind of work is for greenfield. What about three weeks later when the job changes to maintenance and interation on something that's already working? Are people applying LLMs to that space? reply throwup238 12 hours agoparentMy codebase is relatively greenfield (started working on it early last year) but it’s up to ~50k lines in a mixed C++/Rust codebase with a binding layer whose API predates every LLM’s training sets. Even when I started ChatGPT/Claude weren’t very useful but now the project requires a completely different strategy when working with LLMs (it’s a QT AI desktop app so I’m dogfooding a lot). I’ve also used them in a larger codebase (~500k lines) and that also requires a different approach from the former. It feels a lot like the transition from managing 2 to 20 to 200 to 2000 people. It’s a different ballgame with each step change. A very well encapsulated code base of ~500k lines is manageable for small changes but not for refactoring, exploration, etc, at least until useful context sizes increase another order of magnitude (I keep trying Gemini’s 2M but it’s been a disappointment). I have a lot of documentation aimed at the AI in `docs/notes/` (some of it written by an LLM but proofread before committing) and I instruct Cursor/Windsurf/Aider via their respective rules/config files to look at the documentation before doing anything. At some scale that initial context becomes just a directory listing & short description of everything in the notes folder, which eventually breaks down due to context size limits, either because I exceed the maximum length of the rules or the agent requires pulling in too much context for the change. I’ve found that there’s actually an uncanny valley between greenfield projects where the model is free to make whatever assumptions it wants and brownfield projects where it’s possible to provide enough context from the existing codebase to get both API accuracy (hallucinations) and general patterns through few-shot examples. This became very obvious once I had enough examples of that binding layer. Even though I could include all of the documentation for the library, it didn’t work consistently until I had a variety of production examples to point it to. Right now, I probably spend as much time writing each prompt as I do massaging the notes folder and rules every time I notice the model doing something wrong. reply zkry 11 hours agoparentprevLogically this makes sense: every model has a context size and complexity capacity where it will no longer be able to function properly. Any usage of said model will accelerate the approach to this limit. Once the limit is reached, the LLM is no longer as helpful as it was. I work on full blown legacy apps and needless to say I don't even bother with LLMs when working on these most of the time. reply Mashimo 10 hours agoparentprevI used AI code completion from GitHub copilot on a 20 year old project. You still have to create new classes, new test, refactor etc. reply valenterry 7 hours agoparentprevYeah, it sucks. LLMs are not great with a big context yet. I hope that is being worked on. I need the LLM to read my whole project AND optimally all related slack conversations, the wiki and related libraries. reply kylebenzle 15 hours agoparentprevYes, it's just harder the larger the pre-existing code base. reply polotics 10 hours agoprevMy main usage is in helping me approach domains and tools I don't know enough to confidently know how best to get started. So one thing that doesn't get a mention in the article but is quite significant I think is the long lag of knowledge cutoff dates: looking at even the latest and greatest, there is one year or more of missing information. I would love for someone more versed than me to tell us how best to use RAG or LoRA to get the model to answer with fully up to date knowledge on libraries, frameworks, ... reply bambax 10 hours agoprev> There are three ways I use LLMs in my day-to-day programming: 1/ Autocomplete 2/ Search 3/ Chat-driven programming I do mostly 2/ Search, which is like a personalized Stack Overflow and sometimes feels incredible. You can ask a general question about a specific problem and then dive into some specific point to make sure you understand every part clearly. This works best for things one doesn't know enough about, but has a general idea of how the solution should sound or what it should do. Or, copy-pasting error messages from tools like Docker and have the LLM debug it for you really feels like magic. For some reason I have always disliked autocomplete anywhere, so I don't do that. The third way, chat-driven programming, is more difficult, because the code generated by LLMs can be large, and can also be wrong. LLMs are too eager to help, and they will try to find a solution even if there isn't one, and will invent it if necessary. Telling them in the prompt to say \"I don't know\" or \"it's impossible\" if need be, can help. But, like the author says, it's very helpful to get started on something. > That is why I still use an LLM via a web browser, because I want a blank slate on which to craft a well-contained request That's also what I do. I wouldn't like having something in the IDE trying to second guess what I write or suddenly absorbing everything into context and coming up with answers that it thinks make a lot of sense but actually don't. But the main benefit is, like the author says, that it lets one start afresh with every new question or problem, and save focused threads on specific topics. reply denvermullets 4 hours agoprevthis is almost exactly how ive been using llms. i dont like the code complete in the ide, personally, and prefer all llm usage to be narrow specific blocks of code. it helps as i bounce between a lot of side projects, projects at work, and freelance projects. not to mention with context switching it really helps keep things moving, imo reply 999900000999 3 hours agoprevI still find most LLMS to be extremely poor programmers . Claude will often generate tons and tons of useless code quickly using up it's limit. I often find myself yelling at it to stop. I was just working with it last night. \"Hi Claude, can you add tabs here.\":Claude will then start generating MainContent. DeepSeek, despite being free does a much better job than Claude. I don't know if it's smarter, but whatever internal logic it has is much more to the point. Claude also has a very weird bias towards a handful of UI libraries that has installed, even if those wouldn't be good for your project. I wasted hours on shancn UI which requires a very particular setup to work. LLM's are generally great at common tasks using a top 5( popularity) language. Ask it to do something in a Haxe UI library and it'll make up functions that *look* correct. Overall I like them, they definitely speed things up. I don't think most experienced software engineers have much to worry about for now. But I am really worried about juniors. Why higher a junior engineer, when you can just tell your seniors they need to use Copilot to crank out more code reply jmull 8 hours agoprevLLM auto-complete is good — it suggests more of what I was going to type, and correctly (or close enough) often enough that it’s useful. Especially in the boilerplate-y languages/code I have to use for $dayjob. Search has been neutral. For finding little facts it’s been about the same as regular search. When digging in, I want comprehensive, dense, reasonably well-written reference documentation. That’s not exactly wide-spread, but LLMs don’t provide this either. Chat-driven generates too much buggy/incomplete code to be useful, and the chat interface is seriously clunky. reply agentultra 14 hours agoprevIt seems nice for small projects but I wouldn’t use it for anything serious that I want to maintain long term. I would write the tests first and foremost: they are the specification. They’re for future me and other maintainers to understand and I wouldn’t want them to be generated: write them with the intention of explaining the module or system to another person. If the code isn’t that important I’ll write unit tests. If I need better assurances I’ll write property tests at a minimum. If I’m working on concurrent or parallel code or I’m working on designing a distributed system, it’s gotta be a model checker. I’ve verified enough code to know that even a brilliant human cannot find 1-in-a-million programming errors that surface in systems processing millions of transactions a minute. We’re not wired that way. Fortunately we have formal methods. Maths is an excellent language for specifying problems and managing complexity. Induction, category theory, all awesome stuff. Most importantly though… you have to write the stuff and read it and interact with it to be able to keep it in your head. Programming is theory-building as Naur said. Personally I just don’t care to read a bunch of code and play, “spot the error;” a game that’s rigged for me to be bad at. It’s much more my speed to write code that obviously has no errors in it because I’ve thought the problem through. Although I struggle with this at times. The struggle is an important part of the process for acquiring new knowledge. Though I do look forward to algorithms that can find proofs of trivial theorems for me. That would be nice to hand off… although simp does a lot of work like that already. ;) reply yawnxyz 13 hours agoprev> I could not go a week without getting frustrated by how much mundane typing I had to do before having a FIM model For those not in-the-know, I just learned today that code autocomplete is actually called \"Fill-in-the-Middle\" tasks reply Guthur 13 hours agoparentSays who? I've been in the industry for nearly 25 years and have heard auto complete throughout but not once have I heard fill in the middle. Stop taking these blogs as oracle's of truth, they are not. These AI articles are full of this nonsense, to the point where it would appear to me many responses might just be Nvidia bots or whatever. reply crawshaw 2 hours agorootparentAuthor here. FIM is a term of art in LLM research for a style of tokens used to implement code completion. In particular, it refers to training an LLM with the extra non-printing tokens:You would then take code like this: func add(a, b int) int { return} and convert it to: func add(a, b int) int { return } and have the LLM predict the next token. It is, in effect, an encoding scheme for getting the prefix and suffix into the LLM context while positioning the next token to be where the cursor is. (There are several variants of this scheme.) reply sunaookami 12 hours agorootparentprev>I've been in the industry for nearly 25 years and have heard auto complete throughout but not once have I heard fill in the middle Then you need to look harder. FiM is a common approach for code generation LLMs. https://openai.com/index/efficient-training-of-language-mode... https://arxiv.org/abs/2207.14255 This was before ChatGPT's release btw. reply Guthur 12 hours agorootparentWhy, what was wrong with code completion, it was perfectly valid before even when including some sort of fuzzing. It's like everything to do with LLM marketing buzzword nonsense. I really want to just drop out of tech until all this obnoxious hype BS is gone. reply ascorbic 11 hours agorootparentAutocomplete is the feature, fill in the middle is one approach to implementing it. There are other ways to providing it (which were used in earlier versions of Copilot) and FIM can be used for tasks other than code completion. reply wruza 11 hours agorootparentprevIt’s just a term that signals “completion in between” rather than “after”. Regular code completion usually doesn’t take the following blocks into account mostly because these are grammatically vague due to an ongoing edit. Your comments may be sympathised to, but why on earth are they addressed to the root commenter. They simply shared their findings about an acronym. reply Guthur 10 hours agorootparentBecause they mentioned it, why on earth would you think that is not a valid response in a thread that mentions it, from my observation that's pretty much how forum like threads work. More pressingly why do you think you should police it? reply wruza 10 hours agorootparentApologies if my feedback annoyed you, it wasn’t the goal. I just care about HN and this didn’t feel right. reply e12e 15 hours agoprevInteresting. I wonder what the equivalent of sketch.dev would look like if it targeted Smalltalk and was embedded in a Smalltalk image (preferably with a local LLM running in smalltalk)? I'd love to be able to tell my (hypothetical smalltalk) tablet to create an app for me, and work interactively, interacting with the app as it gets built... Ed: I suppose I should just try and see where cloud ai can take smalltalk today: https://github.com/rsbohn/Cuis-Smalltalk-Dexter-LLM reply klibertp 2 hours agoparentWorth a look: https://github.com/feenkcom/gt4llm If you load this in GT, you'll get a Lepiter book with interactive tutorials. reply justinl33 11 hours agoprevI've maintaine",
    "originSummary": [
      "The author has integrated Large Language Models (LLMs) into their programming workflow, finding them beneficial for tasks like autocomplete, search, and chat-driven programming.",
      "They are developing a tool called sketch.dev, a Go programming Integrated Development Environment (IDE) designed to enhance productivity by automating repetitive tasks and improving programming efficiency.",
      "LLMs are effective in generating code drafts and handling exam-style questions, although they can occasionally make errors, and they shift tradeoffs in programming by enabling more specialized code and comprehensive tests."
    ],
    "commentSummary": [
      "Large Language Models (LLMs) are recognized by some software engineers for enhancing productivity, particularly in drafting new ideas and performing tasks like autocomplete and chat-driven programming. - While some developers appreciate the efficiency LLMs provide, others remain skeptical about their effectiveness, especially for complex or novel problems. - The discussion underscores a divide among developers regarding the adoption of LLMs, with some embracing them for iterative tasks and others favoring traditional methods."
    ],
    "points": 624,
    "commentCount": 238,
    "retryCount": 0,
    "time": 1736208469
  },
  {
    "id": 42619139,
    "title": "Nvidia's Project Digits is a 'personal AI supercomputer'",
    "originLink": "https://techcrunch.com/2025/01/06/nvidias-project-digits-is-a-personal-ai-computer/",
    "originBody": "At CES 2025 in Las Vegas, Nvidia unveiled Project Digits, a “personal AI supercomputer” that provides access to the company’s Grace Blackwell hardware platform in a compact form factor. “[Project Digits] runs the entire Nvidia AI stack — all of Nvidia software runs on this,” Nvidia CEO Jensen Huang said onstage during a press conference on Monday. “It’s a cloud computing platform that sits on your desk … It’s even a workstation, if you like it to be.” Designed for AI researchers, data scientists, and students, Project Digits packs Nvidia’s new GB10 Grace Blackwell Superchip, which delivers up to a petaflop of computing performance for prototyping, fine-tuning, and running AI models. Nvidia claims a single Project Digits unit can run models up to 200 billion parameters in size. Parameters roughly correspond to a model’s problem-solving skills, and models with more parameters generally perform better than those with fewer parameters. The GB10, which was developed in partnership with MediaTek, features an Nvidia Blackwell GPU connected to a 20-core Nvidia Grace CPU. Inside the Project Digits enclosure, the chips are hooked up to a 128GB pool of memory and up to 4TB of flash storage. IMAGE CREDITS:NVIDIA Nvidia says that two Project Digits machines can be linked together to run up to 405-billion-parameter models, if a job calls for it. Project Digits can deliver a standalone experience, as alluded to earlier, or connect to a primary Windows or Mac PC. But it’s not cheap. Project Digits machines, which run Nvidia’s Linux-based DGX OS, will be available starting in May from “top partners” for $3,000, the company said. So it won’t be just anyone who can afford a Project Digits unit of their own. Huang thinks that there’s a market, however. “With Project Digits, the Grace Blackwell Superchip comes to millions of developers,” he said in a statement. “Placing an AI supercomputer on the desks of every data scientist, AI researcher and student empowers them to engage and shape the age of AI.” Topics AI, AI, CES, Dev, Hardware, nvidia, project digits Kyle Wiggers Senior Reporter, Enterprise Kyle Wiggers is a senior reporter at TechCrunch with a special interest in artificial intelligence. His writing has appeared in VentureBeat and Digital Trends, as well as a range of gadget blogs including Android Police, Android Authority, Droid-Life, and XDA-Developers. He lives in Brooklyn with his partner, a piano educator, and dabbles in piano himself. occasionally — if mostly unsuccessfully. View Bio Most Popular Panasonic unveils an AI-powered wellness coach, powered by Anthropic’s Claude, at CES 2025 Sarah Perez Nvidia’s Project Digits is a ‘personal AI supercomputer’ Kyle Wiggers Toyota’s next-generation cars will be built with Nvidia supercomputers and operating system Rebecca Bellan Google is forming a new team to build AI that can simulate the physical world Kyle Wiggers John Deere’s new robot lawnmower is coming for landscapers’ jobs Sean O'Kane OpenAI is losing money on its pricey ChatGPT Pro plan, CEO Sam Altman says Kyle Wiggers Kirin offers a taste of its electric salt spoon at CES 2025 Maxwell Zeff Newsletters See More Subscribe for the industry’s biggest tech news TechCrunch Daily News Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Add TechCrunch Daily News to your subscription choices TechCrunch AI TechCrunch's AI experts cover the latest news in the fast-moving field. Add TechCrunch AI to your subscription choices TechCrunch Space Every Monday, gets you up to speed on the latest advances in aerospace. Add TechCrunch Space to your subscription choices Startups Weekly Startups are the core of TechCrunch, so get our best coverage delivered weekly. Add Startups Weekly to your subscription choices No newsletters selected. Subscribe By submitting your email, you agree to our Terms and Privacy Notice. Related Transportation At CES 2025, Uber teams up with Nvidia to scale autonomous driving faster Rebecca Bellan 50 minutes ago Hardware RadioShack is back (kind of) at CES 2025 Brian Heater 2 hours ago Hardware Razer’s concept gaming chair will heat your butt up before cooling it down Brian Heater 5 hours ago Latest in AI See More AI Panasonic unveils an AI-powered wellness coach, powered by Anthropic’s Claude, at CES 2025 Sarah Perez 12 minutes ago Transportation At CES 2025, Uber teams up with Nvidia to scale autonomous driving faster Rebecca Bellan 50 minutes ago AI Trump announces $20B plan to build new data centers in the US Kyle Wiggers 2 hours ago",
    "commentLink": "https://news.ycombinator.com/item?id=42619139",
    "commentBody": "Nvidia's Project Digits is a 'personal AI supercomputer' (techcrunch.com)515 points by magicalhippo 14 hours agohidepastfavorite380 comments Abishek_Muthian 4 hours agoI'm looking at my Jetson Nano in the corner which is fulfilling its post-retirement role as a paper weight because Nvidia abandoned it in 4 years. Nvidia Jetson Nano, A SBC for \"AI\" debuted with already aging custom Ubuntu 18.04 and when 18.04 went EOL, Nvidia abandoned it completely without any further updates to its proprietary jet-pack or drivers and without them all of Machine Learning stack like CUDA, Pytorch etc. became useless. I'll never buy a SBC from Nvidia unless all the SW support is up-streamed to Linux kernel. reply lolinder 3 hours agoparentThis is a very important point. In general, Nvidia's relationship with Linux has been... complicated. On the one hand, at least they offer drivers for it. On the other, I have found few more reliable ways to irreparably break a Linux installation than trying to install or upgrade those drivers. They don't seem to prioritize it as a first class citizen, more just tolerate it the bare minimum required to claim it works. reply dotancohen 16 minutes agorootparent> Nvidia's relationship with Linux has been... complicated. For those unfamiliar with Linus Torvalds' two-word opinion of Nvidia: https://youtube.com/watch?v=OF_5EKNX0Eg reply stabbles 3 hours agorootparentprevNow that the majority of their revenue is from data centers instead of Windows gaming PCs, you'd think their relationship with Linux should improve or already has. reply sangnoir 23 minutes agorootparentNvidia segments its big iron AI hardware from the consumer/prosumer segment. They do this by forbidding the use of GeForce drivers in datacenters[1]. All that to say, it is possible for the H100 to to have excellent Linux support, while support for the 4090 is awful. 1. https://www.datacenterdynamics.com/en/news/nvidia-updates-ge... reply lolinder 3 hours agorootparentprevIt's possible. I haven't had a system completely destroyed by Nvidia in the last few years, but I've been assuming that's because I've gotten in the habit of just not touching it once I get it working... reply pplonski86 34 minutes agorootparentI got similar experience. I really prefer switch CUDA version with whole PC machine. What is more, the speed and memory of hardware improves quickly in time as well. reply aseipp 1 hour agoparentprevThe Orin series and later use UEFI and you can apparently run upstream, non-GPU enabled kernels on them. There's a user guide page documenting it. So I think it's gotten a lot better, but it's sort of moot because the non-GPU thing is because the JetPack Linux fork has a specific 'nvgpu' driver used for Tegra devices that hasn't been unforked from that tree. So, you can buy better alternatives unless you're explicitly doing the robotics+AI inference edge stuff. But the impression I get from this device is that it's closer in spirit to the Grace Hopper/datacenter designs than it is the Tegra designs, due to both the naming, design (DGX style) and the software (DGX OS?) which goes on their workstation/server designs. They are also UEFI, and in those scenarios, you can (I believe?) use the upstream Linux kernel with the open source nvidia driver using whatever distro you like. In that case, this would be a much more \"familiar\" machine with a much more ordinary Linux experience. But who knows. Maybe GH200/GB200 need custom patches, too. Time will tell, but if this is a good GPU paired with a good ARM Cortex design, and it works more like a traditional Linux box than the Jeton series, it may be a great local AI inference machine. reply vladslav 3 hours agoparentprevI've had a similar experience, my Xavier NX stopped working after the last update and now it's just collecting dust. To be honest, I've found the Nvidia SBC to be more of a hassle than it's worth. reply busterarm 2 hours agorootparentXavier AGX owner here to report the same. reply justin66 2 hours agorootparentMy Jetson TX2 developer kit didn't stop working, but it's on a very out of date Linux distribution. Maybe if Nvidia makes it to four trillion in market cap they'll have enough spare change to keep these older boards properly supported, or at least upstream all the needed support. reply aleden 11 minutes agorootparentAre you aware that mainline linux runs on these Jetson devices? It's a bit of annoying work, but you can be running ArchLinuxARM. https://github.com/archlinuxarm/PKGBUILDs/pull/1580 Edit: It's been a while since I did this, but I had to manually build the kernel, overwrite a dtb file maybe (and Linux_for_Tegra/bootloader/l4t_initrd.img) and run something like this (for xavier) sudo ./flash.sh -N 128.30.84.100:/srv/arch -K /home/aeden/out/Image -d /home/aeden/out/tegra194-p2972-0000.dtb jetson-xavier eth0 reply smallmancontrov 2 hours agorootparentprevWait, my AGX is still working, but I have kept it offline and away from updates. Do the updates kill it? Or is it a case of not supporting newer pytorch or something else you need? reply yoyohello13 2 hours agoparentprevAnd unless there is some expanded maintenance going on, 22.04 is EOL in 2 years. In my experience, vendors are not as on top of security patches as upstream. We will see, but given NVIDIA's closed ecosystem, I don't have high hopes that this will be supported long term. reply halJordan 3 hours agoparentprevIt runs their dgx os and Jensen specifically said it would be a full part if their hw stack reply startupsfail 2 hours agorootparentIf this is DGX OS, then yes, this is what you’ll find installed on their 4-cards workstations. This is more like a micro-DGX then, for $3k. reply saidinesh5 1 hour agoparentprevIs there any recent, powerful SBC with fully upstream kernel support? I can only think of raspberry pi... reply shadowpho 14 minutes agorootparentRadha but that’s n100 aka x64 reply msh 1 hour agorootparentprevThe odroid H series. But that packs a x86 cpu. reply nickpsecurity 49 minutes agoparentprevIf its stack still works, you might be able to sell or donate it to a student experimenting. They can still learn quite a few things with it. Maybe even use it for something. reply sangnoir 14 minutes agorootparentUsing outdated tensorflow (v1 from 2018) or outdated PyTorch makes learning harder than it need to be, considering most resources online use much newer versions of the frameworks. If you're learning the fundamentals and working from first principle and creating the building blocks yourself, then it adds to the experience. However, most most people just want to build different types of nets, and it's hard to do when the code won't work for you. reply tcdent 1 hour agoparentprevIf you're expecting this device to stay relevant for 4 years you are not the target demographic. Compute is evolving way too rapidly to be setting-and-forgetting anything at the moment. reply tempoponet 1 hour agorootparentToday I'm using 2x 3090's which are over 4 years old at this point and still very usable. To get 48gb vram I would need 3x 5070ti - still over $2k. In 4 years, you'll be able to combine 2 of these to get 256gb unified memory. I expect that to have many uses and still be in a favorable form factor and price. reply mrybczyn 1 hour agorootparentprevEh? By all indications compute is now evolving SLOWER than ever. Moore's Law is dead, Dennard scaling is over, the latest fab nodes are evolutionary rather than revolutionary. This isn't the 80s when compute doubled every 9 months, mostly on clock scaling. reply tcdent 1 hour agorootparentFab node size is not the only factor in performance. Physical limits were reached, and we're pulling back from the extremely small stuff for the time being. That is the evolutionary part. Revolutionary developments are: multi-layer wafer bonding, chiplets (collections of interconnected wafers) and backside power delivery. We don't need the transistors to keep getting physically smaller, we need more of them, and at increased efficiency, and that's exactly what's happening. reply dotancohen 11 minutes agorootparentAll that comes with linear increases of heat, and exponential difficulty of heat dissipation (square-cube law). There is still progress being made in hardware, but for most critical components it's looking far more logarithmic now as we're approaching the physical material limits. reply gnatman 45 minutes agoprev>> The IBM Roadrunner was the first supercomputer to reach one petaflop (1 quadrillion floating point operations per second, or FLOPS) on May 25, 2008. $100M, 2.35MW, 6000 ft^2 >>Designed for AI researchers, data scientists, and students, Project Digits packs Nvidia’s new GB10 Grace Blackwell Superchip, which delivers up to a petaflop of computing performance for prototyping, fine-tuning, and running AI models. $3000, 1kW, 0.5 ft^2 reply DannyBee 14 minutes agoparentDigits is petaflops of FP4, roadrunner is petaflops of FP32. So at least a factor of 8 difference, but in practice much more. (IE I strongly doubt digits can do 1/8th petaflop of FP32) Beyond that, the factors seem reasonable for 2 decades? reply dotancohen 9 minutes agorootparentWhy even use a floating point if you have only 4 bits? Models with INT8 features are not unheard of. reply Karupan 14 hours agoprevI feel this is bigger than the 5x series GPUs. Given the craze around AI/LLMs, this can also potentially eat into Apple’s slice of the enthusiast AI dev segment once the M4 Max/Ultra Mac minis are released. I sure wished I held some Nvidia stocks, they seem to be doing everything right in the last few years! reply rbanffy 5 hours agoparentThis is something every company should make sure they have: an onboarding path. Xeon Phi failed for a number of reasons, but one where it didn't need to fail was availability of software optimised for it. Now we have Xeons and EPYCs, and MI300C's with lots of efficient cores, but we could have been writing software tailored for those for 10 years now. Extracting performance from them would be a solved problem at this point. The same applies for Itanium - the very first thing Intel should have made sure it had was good Linux support. They could have it before the first silicon was released. Itaium was well supported for a while, but it's long dead by now. Similarly, Sun has failed with SPARC, which also didn't have an easy onboarding path after they gave up on workstations. They did some things right: OpenSolaris ensured the OS remained relevant (still is, even if a bit niche), and looking the other way for x86 Solaris helps people to learn and train on it. Oracle cloud could, at least, offer it on cloud instances. Would be nice. Now we see IBM doing the same - there is no reasonable entry level POWER machine that can compete in performance with a workstation-class x86. There is a small half-rack machine that can be mounted on a deskside case, and that's it. I don't know of any company that's planning to deploy new systems on AIX (much less IBMi, which is also POWER), or even for Linux on POWER, because it's just too easy to build it on other, competing platforms. You can get AIX, IBMi and even IBMz cloud instances from IBM cloud, but it's not easy (and I never found a \"from-zero-to-ssh-or-5250-or-3270\" tutorial for them). I wonder if it's even possible. You can get Linux on Z instances, but there doesn't seem to be a way to get Linux on POWER. At least not from them (several HPC research labs still offer those). reply nimish 4 hours agorootparent1000% all these ai hardware companies will fail if they don't have this. You must have a cheap way to experiment and develop. Even if you want to only sell a $30000 datacenter card you still need a very low cost way to play. Sad to see big companies like intel and amd don't understand this but they've never come to terms with the fact that software killed the hardware star reply theptip 3 hours agorootparentIsn’t the cloud GPU market covering this? I can run a model for $2/hr, or get a 8xH100 if I need to play with something bigger. reply rbanffy 2 hours agorootparentPeople tend to limit their usage when it's time-billed. You need some sort of desktop computer anyway, so, if you spend the 3K this one costs, you have unlimited time of Nvidia cloud software. When you need to run on bigger metal, then you pay $2/hour. reply johndough 1 hour agorootparentprevI have the skills to write efficient CUDA kernels, but $2/hr is 10% of my salary, so no way I'm renting any H100s. The electricity price for my computer is already painful enough as is. I am sure there are many eastern European developers who are more skilled and get paid even less. This is a huge waste of resources all due to NVIDIA's artificial market segmentation. Or maybe I am just cranky because I want more VRAM for cheap. reply rbanffy 3 hours agorootparentprev> Sad to see big companies like intel and amd don't understand this And it's not like they were never bitten (Intel has) by this before. reply nimish 1 hour agorootparentWell, Intel management is very good at snatching defeat from the jaws of victory reply p_ing 1 hour agorootparentprevRaptor Computing provides POWER9 workstations. They're not cheap, still use last-gen hardware (DDR4/PCIe 4 ... and POWER9 itself) but they're out there. https://www.raptorcs.com/content/base/products.html reply AtlasBarfed 2 hours agorootparentprevIt really mystifies me that Intel AMD and other hardware companies obviously Nvidia in this case Don't either have a consortium or each have their own in-house Linux distribution with excellent support. Windows has always been a barrier to hardware feature adoption to Intel. You had to wait 2 to 3 years, sometimes longer, for Windows to get around us providing hardware support. Any OS optimizations in Windows you had to go through Microsoft. So say you added some instructions custom silicon or whatever to speed up Enterprise databases, provide high-speed networking that needed some special kernel features, etc, there was always Microsoft being in the way. Not just in the drag the feet communication. Getting the tech people a line problem. Microsoft will look at every single change. It did as to whether or not it would challenge their Monopoly whether or not it was in their business interest whether or not it kept you as the hardware and a subservient role. reply p_ing 1 hour agorootparentFrom the consumer perspective, it seems that MSFT has provided scheduler changes fairly rapidly for CPU changes, like X3D, P/e cores, etc. At least within a couple of months, if not at release. Amd/Intel work directly with Microsoft for shipping new silicon that would otherwise require it. reply sheepscreek 6 hours agoparentprevThe developers they are referring to aren’t just enthusiasts; they are also developers who were purchasing SuperMicro and Lambda PCs to develop models for their employers. Many enterprises will buy these for local development because it frees up the highly expensive enterprise-level chip for commercial use. This is a genius move. I am more baffled by the insane form factor that can pack this much power inside a Mac Mini-esque body. For just $6000, two of these can run 400B+ models locally. That is absolutely bonkers. Imagine running ChatGPT on your desktop. You couldn’t dream about this stuff even 1 year ago. What a time to be alive! reply numba888 6 minutes agorootparentThis looks like a bigger brother of Orin AGX, which has 64GB of RAM and runs smaller LLMs. The question will be power and performance vs 5090. We know price is 1.5x reply HarHarVeryFunny 4 hours agorootparentprevThe 1 PetaFLOP spec and 200GB model capacity specs are for FP4 (4-bit floating point), which means inference not training/development. It's still be a decent personal development machine, but not for that size of model. reply stogot 5 hours agorootparentprevHow does it run 400B models across two? I didn’t see that in the article reply tempay 5 hours agorootparent> Nvidia says that two Project Digits machines can be linked together to run up to 405-billion-parameter models, if a job calls for it. Project Digits can deliver a standalone experience, as alluded to earlier, or connect to a primary Windows or Mac PC. reply dagmx 14 hours agoparentprevI think the enthusiast side of things is a negligible part of the market. That said, enthusiasts do help drive a lot of the improvements to the tech stack so if they start using this, it’ll entrench NVIDIA even more. reply Karupan 13 hours agorootparentI’m not so sure it’s negligible. My anecdotal experience is that since Apple Silicon chips were found to be “ok” enough to run inference with MLX, more non-technical people in my circle have asked me how they can run LLMs on their macs. Surely a smaller market than gamers or datacenters for sure. reply dagmx 13 hours agorootparentI mean negligible to their bottom line. There may be tons of units bought or not, but the margin on a single datacenter system would buy tens of these. It’s purely an ecosystem play imho. It benefits the kind of people who will go on to make potentially cool things and will stay loyal. reply htrp 12 hours agorootparent>It’s purely an ecosystem play imho. It benefits the kind of people who will go on to make potentially cool things and will stay loyal. 100% The people who prototype on a 3k workstation will also be the people who decide how to architect for a 3k GPU buildout for model training. reply mrlongroots 7 hours agorootparentprev> It’s purely an ecosystem play imho. It benefits the kind of people who will go on to make potentially cool things and will stay loyal. It will be massive for research labs. Most academics have to jump through a lot of hoops to get to play with not just CUDA, but also GPUDirect/RDMA/Infiniband etc. If you get older/donated hardware, you may have a large cluster but not newer features. reply ckemere 4 hours agorootparentAcademic minimal-bureaucracy purchasing card limit is about $4k, so pricing is convenient*2. reply bwfan123 3 hours agorootparentprevDevalapers developers developers - balmer monkey dance - the key to be entrenched is the platform ecosystem. Also why aws is giving trainium credits for free reply stuaxo 9 hours agorootparentprevIt's annoying I do LLMs for work and have a bit of an interest in them and doing stuff with GANS etc. I have a bit of an interest in games too. If I could get one platform for both, I could justify 2k maybe a bit more. I can't justify that for just one half: running games on Mac, right now via Linux: no thanks. And on the PC side, nvidia consumer cards only go to 24gb which is a bit limiting for LLMs, while being very expensive - I only play games every few months. reply WaxProlix 4 hours agorootparentThe new $2k card from Nvidia will be 32GB but your point stands. AMD is planning a unified chiplet based GPU architecture (AI/data center/workstation/gaming) called UDNA, which might alleviate some of these issues. It's been delayed and delayed though - hence the lackluster GPU offerings from team Red this cycle - so I haven't been getting my hopes up. Maybe (LP)CAMM2 memory will make model usage just cheap enough that I can have a hosting server for it and do my usual midrange gaming GPU thing before then. reply wkat4242 4 hours agorootparentprev32gb as of last night :) reply moralestapia 5 hours agorootparentprevYes, but people already had their Macs for others reasons. No one goes to an Apple store thinking \"I'll get a laptop to do AI inference\". reply JohnBooty 4 hours agorootparentThey have, because until now Apple Silicon was the only practical way for many to work with larger models at home because they can be configured with 64-192GB of unified memory. Even the laptops can be configured with up to 128GB of unified memory. Performance is not amazing (roughly 4060 level, I think?) but in many ways it was the only game in town unless you were willing and able to build a multi-3090/4090 rig. reply moralestapia 2 hours agorootparentI would bet that people running LLMs on their Macs, today, isai, but games > crypto > ai. reply Cumpiler69 12 hours agorootparentprevThere's a lot more gamers than people wanting to play with LLms at home. reply anonylizard 11 hours agorootparentThere's a titanic market with people wanting some uncensored local LLM/image/video generation model. This market extremely overlaps with gamers today, but will grow exponentially every year. reply JohnBooty 4 hours agorootparentI'm sure a lot of people see \"uncensored\" and think \"porn\" but there's a lot of stuff that e.g. Dall-E won't let you do. Suppose you're a content creator and you need an image of a real person or something copyrighted like a lot of sports logos for your latest YouTube video's thumbnail. That kind of thing. I'm not getting into how good or bad that is; I'm just saying I think it's a pretty common use case. reply stuaxo 9 hours agorootparentprevApart from the uncensored bit, I'm in this small market. Do I buy a Macbook with silly amount of RAM when I only want to mess with images occasionally. Do I get a big Nvidia card, topping out at 24gb - still small for some LLMs, but I could occasionally play games using it at least. reply Cumpiler69 11 hours agorootparentprevHow big is that market you claim? Local LLM image generation already exists out off the box on latest Samsung flagship phones and it's mostly a Gimmick that gets old pretty quickly. Hardly comparable to gaming in terms of market size and profitablity. Plus, YouTube and the Google images is already full of AI generated slop and people are already tired of it. \"AI fatigue\" amongst majority of general consumers is a documented thing. Gaming fatigues is not. reply TeMPOraL 4 hours agorootparent> Gaming fatigues is not. It is. You may know it as the \"I prefer to play board games (and feel smugly superior about it) because they're ${more social, require imagination, $whatever}\" crowd. reply Cumpiler69 3 hours agorootparentThe market heavily disagrees with you. \"The global gaming market size was valued at approximately USD 221.24 billion in 2024. It is forecasted to reach USD 424.23 billion by 2033, growing at a CAGR of around 6.50% during the forecast period (2025-2033)\" reply com2kid 3 hours agorootparentFarmville style games underwent similar explosive estimates of growth, up until they collapsed. Much of the growth in gaming of late has come from exploitive dark patterns, and those dark patterns eventually stop working because users become immune to them. reply mrguyorama 33 minutes agorootparent>Farmville style games underwent similar explosive estimates of growth, up until they collapsed. They did not collapse, they moved to smartphones. The \"free\"-to-play gacha portion of the gaming market is so successful it is most of the market. \"Live service\" games are literally traditional game makers trying to grab a tiny slice of that market, because it's infinitely more profitable than making actual games. >those dark patterns eventually stop working because users become immune to them. Really? Slot machines have been around for generations and have not become any less effective. Gambling of all forms has relied on the exact same physiological response for millennia. None of this is going away without legislation. reply madwolf 11 hours agorootparentprevI think he implied AI generated porn. Perhaps also other kind of images that are at odds with morality and/or the law. I'm not sure but probably Samsung phones don't let you do that. reply otabdeveloper4 8 hours agorootparentprev> There's a titanic market with people wanting some uncensored local LLM/image/video generation model. No. There's already too much porn on the internet, and AI porn is cringe and will get old very fast. reply ceejayoz 4 hours agorootparentAI porn is currently cringe, just like Eliza for conversations was cringe. The cutting edge will advance, and convincing bespoke porn of people's crushes/coworkers/bosses/enemies/toddlers will become a thing. With all the mayhem that results. reply otabdeveloper4 2 hours agorootparentIt will always be cringe due to how so-called \"AI\" works. Since it's fundamentally just log-likelihood optimization under the hood, it will always be a statistically most average image. Which means it will always have that characteristic \"plastic\" and overdone look. reply JohnBooty 4 hours agorootparentprevI think there are a lot of non-porn uses. I see a lot of YouTube thumbnails that seem AI generated, but feature copyrighted stuff. (example: a thumbnail for a YT video about a video game, featuring AI-generated art based on that game. because copyright reasons, in my very limited experience Dall-E won't let you do that) I agree that AI porn doesn't seem a real market driver. With 8 billion people on Earth I know it has its fans I guess, but people barely pay for porn in the first place so I reallllly dunno how many people are paying for AI porn either directly or indirectly. It's unclear to me if AI generated video will ever really cross the \"uncanny valley.\" Of course, people betting against AI have lost those bets again and again but I don't know. reply Filligree 3 hours agorootparentprev> No. There's already too much porn on the internet, and AI porn is cringe and will get old very fast. I needed an uncensored model in order to, guess what, make an AI draw my niece snowboarding down a waterfall. All the online services refuse on basis that the picture contains -- oh horrors -- a child. \"Uncensored\" absolutely does not imply NSFW. reply otabdeveloper4 2 hours agorootparentYeah, and there's that story about \"private window\" mode in browsers because you were shopping for birthday gifts that one time. You know what I mean though. reply Filligree 1 hour agorootparentI really don't. Censored models are so censored they're practically useless for anything but landscapes. Half of them refuse to put humans in the pictures at all. reply Paradigma11 2 hours agorootparentprevI think scams will create a far more demand. Spear Phishing targets by creating persistent elaborate online environments is going to be big. reply weregiraffe 5 hours agorootparentprev>There's a titanic market Titanic - so about to hit an iceberg and sink? reply itsoktocry 6 hours agorootparentprev>There's a titantic market How so? Only 40% of gamers use a PC, a portion of those use AI in any meaningful way, and a fraction of those want to set up a local AI instance. Then someone releases an uncensored, cloud based AI and takes your market? reply estebarb 11 hours agorootparentprevSure, but those developers will create functionality that will require advanced GPUs and people will want that functionality. Eventually OS will expect it and it will became default everywhere. So, it is an important step that will push nvidia growing in the following years. reply gr3ml1n 12 hours agorootparentprevAMD thought the enthusiast side of things was a negligible side of the market. reply dagmx 11 hours agorootparentThat’s not what I’m saying. I’m saying that the people buying this aren’t going to shift their bottom line in any kind of noticeable way. They’re already sold out of their money makers. This is just an entrenchment opportunity. reply epolanski 6 hours agorootparentprevIf this is gonna be widely used by ML engineers, in biopharma, etc and they land 1000$ margins at half a million sales that's half a billion in revenue, with potential to grow. reply VikingCoder 13 hours agorootparentprevIf I were NVidia, I would be throwing everything I could at making entertainment experiences that need one of these to run... I mean, this is awfully close to being \"Her\" in a box, right? reply dagmx 13 hours agorootparentI feel like a lot of people miss that Her was a dystopian future, not an ideal to hit. Also, it’s $3000. For that you could buy subscriptions to OpenAI etc and have the dystopian partner everywhere you go. reply VikingCoder 13 hours agorootparentWe already live in dystopian hell and I'd like to have Scarlett Johansen whispering in my ear, thanks. Also, I don't particularly want my data to be processed by anyone else. reply dnissley 21 minutes agorootparentprevPlease name the dystopian elements of Her. reply nostromo 10 hours agorootparentprevFun fact: Her was set in the year 2025. reply swat535 6 hours agorootparentBoring fact: The underlying theme of the movie Her is actually divorce and the destructive impact it has on people, the futuristic AI stuff is just for stuffing! reply AnonymousPlanet 5 hours agorootparentThe overall theme of Her was human relationships. It was not about AI and not just about divorce in particular.The AI was just a plot device to include a bodyless person into the equation. Watch it again with this in mind and you will see what I mean. reply adolph 1 hour agorootparentThe universal theme of Her was the set of harmonics that define what is something and the thresholds, boundaries, windows onto what is not thatthing but someotherthing, even if the thing perceived is a mirror, not just about human relationships in particular. The relationship was just a plot device to make a work of deep philosophy into a marketable romantic comedy. reply int_19h 10 hours agorootparentprevThis is exactly the scenario where you don't want \"the cloud\" anywhere. reply croes 13 hours agorootparentprevOpenAI doesn’t make any profit. So either it dies or prices go up. Not to mention the privacy aspect of your own machine and the freedom of choice which models to run reply blackoil 10 hours agorootparent> So either it dies or prices go up. Or efficiency gains in hardware and software catchup making current price point profitable. reply com2kid 3 hours agorootparentprevOpenAI built a 3 billion dollar business in less than 3 years of a commercial offering. reply smt88 7 hours agorootparentprevIf Silicon Valley could tell the difference between utopias and dystopias, we wouldn't have companies named Soylent or iRobot, and the recently announced Anduril/Palantir/OpenAI partnership to hasten the creation of either SkyNet or Big Brother wouldn't have happened at all. reply t0lo 13 hours agorootparentprevThe dystopian overton window has shifted, didn't you know, moral ambiguity is a win now? :) Tesla was right. reply tacticus 13 hours agorootparentprevthey don't miss that part. they just want to be the evil character. reply int_19h 10 hours agorootparentprevThe real interesting stuff will happen when we get multimodal LMs that can do VR output. reply computably 14 hours agorootparentprevYeah, it's more about preempting competitors from attracting any ecosystem development than the revenue itself. reply option 14 hours agorootparentprevtoday’s enthusiast, grad student, hacker is tomorrow’s startup founder, CEO, CTO or 10x contributor in large tech company reply Mistletoe 11 hours agorootparent> tomorrow’s startup founder, CEO, CTO or 10x contributor in large tech company Do we need more of those? We need plumbers and people that know how to build houses. We are completely full on founders and executives. reply davrosthedalek 6 hours agorootparentWe might not, but Nvidia would certainly like it. reply numba888 4 hours agoparentprev> I sure wished I held some Nvidia stocks, they seem to be doing everything right in the last few years! They propelled on unexpected LLM boom. But plan 'A' was robotics in which NVidia invested a lot for decades. I think their time is about to come, with Tesla's humanoids for 20-30k and Chinese already selling for $16k. reply llm_trw 11 hours agoparentprevFrom the people I talk to the enthusiast market is nvidia 4090/3090 saturated because people want to do their fine tunes also porn on their off time. The Venn diagram of users who post about diffusion models and llms running at home is pretty much a circle. reply Tostino 5 hours agorootparentYeah, I really don't think the overlap is as much as you imagine. At least in /r/localllama and the discord servers I frequent, the vast majority of users are interested in one or the other primarily, and may just dabble with other things. Obviously this is just my observations...I could be totally misreading things. reply dist-epoch 8 hours agorootparentprevNot your weights, not your waifu reply bloomingkales 6 hours agoparentprevJensen did say in recent interview, paraphrasing, “they are trying to kill my company”. Those Macs with unified memory is a threat he is immediately addressing. Jensen is a wartime ceo from the looks of it, he’s not joking. No wonder AMD is staying out of the high end space, since NVIDIA is going head on with Apple (and AMD is not in the business of competing with Apple). reply T-A 4 hours agorootparentFrom https://www.tomshardware.com/pc-components/cpus/amds-beastly... The fire-breathing 120W Zen 5-powered flagship Ryzen AI Max+ 395 comes packing 16 CPU cores and 32 threads paired with 40 RDNA 3.5 (Radeon 8060S) integrated graphics cores (CUs), but perhaps more importantly, it supports up to 128GB of memory that is shared among the CPU, GPU, and XDNA 2 NPU AI engines. The memory can also be carved up to a distinct pool dedicated to the GPU only, thus delivering an astounding 256 GB/s of memory throughput that unlocks incredible performance in memory capacity-constrained AI workloads (details below). AMD says this delivers groundbreaking capabilities for thin-and-light laptops and mini workstations, particularly in AI workloads. The company also shared plenty of gaming and content creation benchmarks. [...] AMD also shared some rather impressive results showing a Llama 70B Nemotron LLM AI model running on both the Ryzen AI Max+ 395 with 128GB of total system RAM (32GB for the CPU, 96GB allocated to the GPU) and a desktop Nvidia GeForce RTX 4090 with 24GB of VRAM (details of the setups in the slide below). AMD says the AI Max+ 395 delivers up to 2.2X the tokens/second performance of the desktop RTX 4090 card, but the company didn’t share time-to-first-token benchmarks. Perhaps more importantly, AMD claims to do this at an 87% lower TDP than the 450W RTX 4090, with the AI Max+ running at a mere 55W. That implies that systems built on this platform will have exceptional power efficiency metrics in AI workloads. reply adrian_b 2 hours agorootparent\"Fire breathing\" is completely inappropriate. Strix Halo is a replacement for the high-power laptop CPUs from the HX series of Intel and AMD, together with a discrete GPU. The thermal design power of a laptop CPU-dGPU combo is normally much higher than 120 W, which is the maximum TDP recommended for Strix Halo. The faster laptop dGPUs want more than 120 W only for themselves, not counting the CPU. So any claims of being surprised that the TDP range for Strix Halo is 45 W to 120 W are weird, like the commenter has never seen a gaming laptop or a mobile workstation laptop. reply JoshTko 32 minutes agorootparentprevWhich interview was this? reply hkgjjgjfjfjfjf 6 hours agorootparentprevYou missed the Ryzen hx ai pro 395 product announcement reply qwertox 13 hours agoparentprevThis is somewhat similar to what GeForce was to gamers back in the days, but for AI enthusiasts. Sure, the price is much higher, but at least it's a completely integrated solution. reply Karupan 13 hours agorootparentYep that's what I'm thinking as well. I was going to buy a 5090 mainly to play around with LLM code generation, but this is a worthy option for roughly the same price as building a new PC with a 5090. reply qwertox 9 hours agorootparentIt has 128 GB of unified RAM. It will not be as fast as the 32 GB VRAM of the 5090, but what gamer cards have always lacked was memory. Plus you have fast interconnects, if you want to stack them. I was somewhat attracted by the Jetson AGX Orin with 64 GB RAM, but this one is a no-brainer for me, as long as idle power is reasonable. reply moffkalast 7 hours agorootparentHaving your main pc as an LLM rig also really sucks for multitasking, since if you want to keep a model loaded to use it when needed, it means you have zero resources left to do anything else. GPU memory maxed out, most of the RAM used. Having a dedicated machine even if it's slower is a lot more practical imo, since you can actually do other things while it generates instead of having to sit there and wait, not being able to do anything else. reply tarsinge 4 hours agoparentprev> I sure wished I held some Nvidia stocks I’m so tired of this recent obsession with the stock market. Now that retail is deeply invested it is tainting everything, like here on a technology forum. I don’t remember people mentioning Apple stock every time Steve Jobs made an announcement in the past decades. Nowadays it seems everyone is invested in Nvidia and just want the stock to go up, and every product announcement is a mean to that end. I really hope we get a crash so that we can get back to a more sane relation with companies and their products. reply lioeters 1 hour agorootparent> hope we get a crash That's the best time to buy. ;) reply technofiend 4 hours agoparentprevWill there really be a mac mini wirh Max or Ultra CPUs? This feels like somewhat of an overlap with the Mac Studio. reply adolph 35 minutes agorootparentThere will undoubtably be a Mac Studio (and Mac Pro?) bump to M4 at some point. Benchmarks [0] reflect how memory bandwidth and core count [1] compare to processor improvements. Granted, ymmv to your workload. 0. https://www.macstadium.com/blog/m4-mac-mini-review 1. https://www.apple.com/mac/compare/?modelList=Mac-mini-M4,Mac... reply axegon_ 5 hours agoparentprev> they seem to be doing everything right in the last few years About that... Not like there isn't a lot to be desired from the linux drivers: I'm running a K80 and M40 in a workstation at home and the thought of having to ever touch the drivers, now that the system is operational, terrifies me. It is by far the biggest \"don't fix it if it ain't broke\" thing in my life. reply mycall 4 hours agorootparentBuy a second system which you can touch? reply axegon_ 4 hours agorootparentThat IS the second system (my AI home rig). I've given up on Nvidia for using it on my main computer because of their horrid drivers. I switched to Intel ARC about a month ago and I love it. The only downside is that I have a xeon on my main computer and Intel never really bothered to make ARC compatible with xeons so I had to hack my bios around, hoping I don't mess everything up. Luckily for me, it all went well so now I'm probably one of a dozen or so people worldwide to be running xeons + arc on linux. That said, the fact that I don't have to deal with nvidia's wretched linux drivers does bring a smile to my face. reply paxys 13 hours agoparentprev“Bigger” in what sense? For AI? Sure, because this an AI product. 5x series are gaming cards. reply a________d 13 hours agorootparentNot expecting this to compete with the 5x series in terms of gaming; But it's interesting to note the increase in gaming performance Jensen was speaking about with Blackwell was larger related to inferenced frames generated by the tensor cores. I wonder how it would go as a productivity/tinkering/gaming rig? Could a GPU potentially be stacked in the same way an additional Digit can? reply wpwpwpw 9 hours agorootparentWould hadn't nvidia cripple nvlink on geforce. reply Karupan 13 hours agorootparentprevBigger in the sense of the announcements. reply AuryGlenz 13 hours agorootparentprevEh. Gaming cards, but also significantly faster. If the model fits in the VRAM the 5090 is a much better buy. reply iKevinShah 5 hours agoparentprevI can confirm this is the case (for me). reply informal007 5 hours agoparentprevI would like to have Mac as my personal computer and digits as service to run llm. reply puppymaster 13 hours agoparentprevit eats into all NVDA consumer-facing clients no? I can see why openai and etc are looking for alternative hardware solution to train their next model. reply GaryNumanVevo 4 hours agoparentprevI bet $100k on NVIDIA stocks ~7 years ago, just recently closed out a bunch of them reply behringer 9 hours agoparentprevNot only that, but it should help free up the gpus for the gamers. reply trhway 11 hours agoparentprev>enthusiast AI dev segment i think it isn't about enthusiast. To me it looks like Huang/NVDA is pushing further a small revolution using the opening provided by the AI wave - up until now the GPU was add-on to the general computing core onto which that computing core offloaded some computing. With AI that offloaded computing becomes de-facto the main computing and Huang/NVDA is turning tables by making the CPU is just a small add-on on the GPU, with some general computing offloaded to that CPU. The CPU being located that \"close\" and with unified memory - that would stimulate development of parallelization for a lot of general computing so that it would be executed on GPU, very fast that way, instead of on the CPU. For example classic of enterprise computing - databases, the SQL ones - a lot, if not, with some work, everything, in these databases can be executed on GPU with a significant performance gain vs. CPU. Why it isn't happening today? Load/unload onto GPU eats into performance, complexity of having only some operations offloaded to GPU is very high in dev effort, etc. Streamlined development on a platform with unified memory will change it. That way Huang/NVDA may pull out rug from under the CPU-first platforms like AMD/INTC and would own both - new AI computing as well as significant share of the classic enterprise one. reply tatersolid 7 hours agorootparent> these databases can be executed on GPU with a significant performance gain vs. CPU No, they can’t. GPU databases are niche products with severe limitations. GPUs are fast at massively parallel math problems, they anren’t useful for all tasks. reply trhway 6 hours agorootparent>GPU databases are niche products with severe limitations. today. For the reasons like i mentioned. >GPUs are fast at massively parallel math problems, they anren’t useful for all tasks. GPU are fast at massively parallel tasks. Their memory bandwidth is 10x of that of the CPU for example. So, typical database operations, massively parallel in nature like join or filter, would run about that faster. Majority of computing can be parallelized and thus benefit from being executed on GPU (with unified memory of the practically usable for enterprise sizes like 128GB). reply csomar 10 hours agoparentprevAm I the only one disappointed by these? They cost roughly half the price of a macbook pro and offer hmm.. half the capacity in RAM. Sure speed matters in AI, but what do I do with speed when I can't load a 70b model. On the other hand, with a $5000 macbook pro, I can easily load a 70b model and have a \"full\" macbook pro as a plus. I am not sure I fully understand the value of these cards for someone that want to run personal AI models. reply gnabgib 10 hours agorootparentAre you, perhaps, commenting on the wrong thread? Project Digits is a $3k 128GB computer.. the best your your $5K MBP can have for ram is.. 128GB. reply rictic 10 hours agorootparentprevHm? They have 128GB of RAM. Macbook Pros cap out at 128GB as well. Will be interesting to see how a Project Digits machine performs in terms of inference speed. reply macawfish 10 hours agorootparentprevThen buy two and stack them! Also I'm unfamiliar with macs is there really a MacBook pro with 256GB of RAM? reply csomar 10 hours agorootparentNo, macbooks pro cap at 128GB. But, still, they are a laptop. It'll be interesting to see if Apple can offer a good counter for the desktop. The mac pro can go to 192Gb which is closer to the 128Gb Digits + your Desktop machine. At $9299 price tag, it's not too competitive but close. reply lr1970 7 hours agorootparent> It'll be interesting to see if Apple can offer a good counter for the desktop. Mac Pro [0] is a desktop with M2 Ultra and up to 192GB of unified memory. [0] https://www.apple.com/mac-pro/ reply doctorpangloss 12 hours agoparentprevWhat slice? Also, macOS devices are not very good inference solutions. They are just believed to be by diehards. I don't think Digits will perform well either. If NVIDIA wanted you to have good performance on a budget, it would ship NVLink on the 5090. reply Karupan 12 hours agorootparentThey are perfectly fine for certain people. I can run Qwen-2.5-coder 14B on my M2 Max MacBook Pro with 32gb at ~16 tok/sec. At least in my circle, people are budget conscious and would prefer using existing devices rather than pay for subscriptions where possible. And we know why they won't ship NVLink anymore on prosumer GPUs: they control almost the entire segment and why give more away for free? Good for the company and investors, bad for us consumers. reply acchow 11 hours agorootparent> I can run Qwen-2.5-coder 14B on my M2 Max MacBook Pro with 32gb at ~16 tok/sec. At least in my circle, people are budget conscious Qwen 2.5 32B on openrouter is $0.16/million output tokens. At your 16 tokens per second, 1 million tokens is 17 continuous hours of output. Openrouter will charge you 16 cents for that. I think you may want to reevaluate which is the real budget choice here Edit: elaborating, that extra 16GB ram on the Mac to hold the Qwen model costs $400, or equivalently 1770 days of continuous output. All assuming electricity is free reply Karupan 10 hours agorootparentIt's a no brainer for me cause I already own the MacBook and I don't mind waiting a few extra seconds. Also, I didn't buy the mac for this purpose, it's just my daily device. So yes, I'm sure OpenRouter is cheaper, but I just don't have to think about using it as long as the open models are reasonable good for my use. Of course your needs may be quite different. reply oarsinsync 8 hours agorootparentprev> Openrouter will charge you 16 cents for that And log everything too? reply moffkalast 7 hours agorootparentprevIt's a great option if you want to leak your entire internal codebase to 3rd parties. reply YetAnotherNick 12 hours agorootparentprev> Also, macOS devices are not very good inference solutions They are good for single batch inference and have very good tok/sec/user. ollama works perfectly in mac. reply neom 4 hours agoprevIn case you're curious, I googled. It runs this thing called \"DGX OS\": \"DGX OS 6 Features The following are the key features of DGX OS Release 6: Based on Ubuntu 22.04 with the latest long-term Linux kernel version 5.15 for the recent hardware and security updates and updates to software packages, such as Python and GCC. Includes the NVIDIA-optimized Linux kernel, which supports GPU Direct Storage (GDS) without additional patches. Provides access to all NVIDIA GPU driver branches and CUDA toolkit versions. Uses the Ubuntu OFED by default with the option to install NVIDIA OFED for additional features. Supports Secure Boot (requires Ubuntu OFED). Supports DGX H100/H200.\" reply AtlasBarfed 2 hours agoparentNvidia optimize meaning non-public patches, a non-upgradable operating system like what happens if you upgrade with a binary blob Nvidia driver? reply yoyohello13 3 hours agoparentprevI wonder what kind of spyware is loaded onto DGX OS. Oh, sorry I mean telemetry. reply ZeroTalent 33 minutes agorootparentCybersecurity analysts check and monitor these things daily, and they are pretty easy to catch. Likely nothing malicious, as history shows. reply derbaum 10 hours agoprevI'm a bit surprised by the amount of comments comparing the cost to (often cheap) cloud solutions. Nvidia's value proposition is completely different in my opinion. Say I have a startup in the EU that handles personal data or some company secrets and wants to use an LLM to analyse it (like using RAG). Having that data never leave your basement sure can be worth more than $3000 if performance is not a bottleneck. reply lolinder 4 hours agoparentHeck, I'm willing to pay $3000 for one of these to get a good model that runs my requests locally. It's probably just my stupid ape brain trying to do finance, but I'm infinitely more likely to run dumb experiments with LLMs on hardware I own than I am while paying per token (to the point where I currently spend way more time with small local llamas than with Claude), and even though I don't do anything sensitive I'm still leery of shipping all my data to one of these companies. This isn't competing with cloud, it's competing with Mac Minis and beefy GPUs. And $3000 is a very attractive price point in that market. reply logankeenan 2 hours agorootparentHave you been to the localLlama subreddit? It’s a great resource for running models locally. It’s what got me started. https://www.reddit.com/r/LocalLLaMA/ reply lolinder 2 hours agorootparentYep! I don't spend much time there because I got pretty comfortable with llama before that subreddit really got started, but it's definitely turned up some helpful answers about parameter tuning from time to time! reply ynniv 3 hours agorootparentprevI'm pretty frugal, but my first thought is to get two to run 405B models. Building out 128GB of VRAM isn't easy, and will likely cost twice this. reply rsanek 1 hour agorootparentYou can get a M4 Max MBP with 128GB for $1k less than two of these single-use devices. reply ynniv 0 minutes agorootparentThese are 128GB each. Also, Nvidias inference speed is much higher than Apple's. I do appreciate that my MBP can run models though! lolinder 2 minutes agorootparentprevDon't these devices provide 128GB each? So you'd need to price in two Macs to be a fair comparison to two Digits. originalvichy 6 hours agoparentprevEven for established companies this is great. A tech company can have a few of these locally hosted and users can poll the company LLM with sensitive data. reply diggan 4 hours agoparentprevThe price seems relatively competitive even compared to other local alternatives like \"build your own PC\". I'd definitely buy one of this (or even two if it works really well) for developing/training/using models that currently run on cobbled together hardware I got left after upgrading my desktop. reply sensesp 8 hours agoparentprev100% I see many SMEs not willing to send their data to some cloud black box. reply jckahn 2 hours agorootparentExactly this. I would happily give $3k to NVIDIA to avoid giving 1 cent to OpenAI/Anthropic. reply 627467 4 hours agoparentprev> Having that data never leave your basement sure can be worth more than $3000 if performance is not a bottleneck I get what you're saying, but there are also regulations (and your own business interest) that expects data redundancy/protection which keeping everything on-site doesnt seem to cover reply btbuildem 4 hours agoparentprevYeah that's cheaper than many prosumer GPUs on the market right now reply narrator 14 hours agoprevNvidia releases a Linux desktop supercomputer that's better price/performance wise than anything Wintel is doing and their whole new software stack will only run on WSL2. They aren't porting to Win32. Wow, it may actually be the year of Linux on the Desktop. reply sliken 13 hours agoparentNot sure how to judge better price/perf. I wouldn't expect 20 Neoverse N2 cores to do particularly well vs 16 zen5 cores. The GPU side looks promising, but they aren't mentioning memory bandwidth, configuration, spec, or performance. Did see vague claims of \"starting at $3k\", max 4TB nvme, and max 128GB ram. I'd expect AMD Strix Halo (AI Max plus 395) to be reasonably competitive. reply skavi 13 hours agorootparentIt’s actually “10 Arm Cortex-X925 and 10 Cortex-A725” [0]. These are much newer cores and have a reasonable chance of being competitive. [0]: https://newsroom.arm.com/blog/arm-nvidia-project-digits-high... reply ksec 1 hour agorootparentFor context, the X925 is what used to call Cortex X5 and it is now shipping in MediaTek Dimensity 9400. It has roughly the same performance per clock as a Snapdragon 8 Elite Or roughly 5% lower performance per clock compared to Apple M3 on Geekbench 6. Assuming they are not limited by power or heat dissipation I would say that is about as good as it gets. The hardware is pretty damn good. I am only worried about the software. reply adrian_b 4 hours agorootparentprevFor programs dominated by iterations over arrays, these 10 Arm Cortex-X925 + 10 Cortex-A725, all 20 together, should have a throughput similar with only 10 of the 16 cores of Strix Halo (assuming that Strix Halo has full Zen 5 cores, which has not been confirmed yet). For programs dominated by irregular integer and pointer operations, like software project compilation, 10 Arm Cortex-X925 + 10 Cortex-A725 should have a similar throughput with a 16-core Strix Halo, but which is faster would depend on cooling (i.e. a Strix Halo configured for a high power consumption will be faster). There is not enough information to compare the performance of the GPUs from this NVIDIA Digits and from Strix Halo. However, it can be assumed that NVIDIA Digits will be better for ML/AI inference. Whether it can also be competitive for training or for graphics remains to be seen. reply skavi 1 hour agorootparentHow did you come up with these numbers? There don't seem to be many shipping products with these cores. In fact, the only one I could find was the Dimensity 9400 with a single X925 and older generation A720s. And of course the Dimensity is a mobile SoC, so clocks will be low. Are you projecting based on Arm's stated improvements from their last gen? In that case, what numbers are you using as your baseline? reply adrian_b 37 minutes agorootparentFor programs rich in array operations, which can be accelerated by SVE or AVX-512, Cortex-X925 has 6 x 128-bit execution pipelines, Cortex-A725 has 2 pipelines, Snapdragon Oryon has 4 pipelines, while a Zen 5 core has the equivalent of 8 Arm execution pipelines (i.e. 2 x 512-bit pipelines equivalent with 8 x 128-bit) + other 8 execution pipelines that can do only a subset of the operations. That means a total of 80 execution pipelines for NVIDIA Digits, 48 execution pipelines for Snapdragon Elite and 128 equivalent execution pipelines for Strix Halo, taking into account only the complete execution pipelines, otherwise for operations like FP addition, which can be done in any pipeline, there would be 256 equivalent execution pipelines for Strix Halo. Because the clock frequencies for multithreaded applications should be similar, if not better for Strix Halo, there is little doubt that the throughput for applications dominated by array operations should be at least 128/80 for Strix Halo vs. NVIDIA Digits, if not much better, because for many instructions even more execution pipelines are available and Zen 5 also has a higher IPC when executing irregular code, especially vs. the smaller Cortex-A725 cores. Therefore the throughput of NVIDIA Digits is smaller or at most equal in comparison with the throughput of 10 cores of Strix Halo. On the other hand, for integer/pointer processing code, the number of execution units in a Cortex-925 + a Cortex-725 is about the same as in 2 Zen 5 cores. Therefore the 20 Arm cores of NVIDIA Digits have about the same number of execution units as 20 Zen 5 cores. Nevertheless, the occupancy of the Zen 5 execution units will be higher for most programs than for the Arm cores, especially because of the bigger and better cache memories, and also because of the lower IPC of Cortex-A725. Therefore the 20 Arm cores must be slower than 20 Zen 5 cores, probably only equivalent with about 15 Zen 5 cores, but the exact equivalence is hard to predict, because it depends on the NVIDIA implementation of things like the cache memories and the memory controller. reply sliken 12 hours agorootparentprevGood catch, they called it \"Grace Blackwell\". Changing the CPU cores completely and calling it Grace seems weird. Maybe it was just a mistake during the keynote. reply wmf 12 hours agorootparentI don't think it was a mistake; maybe they intend Grace to be a broader brand like Ryzen not one particular model. reply kristopolous 10 hours agorootparentit's an interesting idea. I mean grace hopper was an actual person but nvidia can have whatever arbitrary naming rules they'd like. reply z4y5f3 13 hours agorootparentprevNVIDIA is likely citing 1 PFlops at FP 4 sparse (they did this for GB200), so that is 128 TFlops BF16 dense, or 2/3 of what RTX 4090 is capable of. I would put the memory bandwidth at 546 GBps, using the same 512 bit LPDDR5X 8533 Mbps as Apple M4 max. reply gardnr 10 hours agorootparentBased on your evaluation, it sounds like it will run inference at speed similar to an M4 Max and also allow \"startups\" to experiment with fine tuning larger models or larger context windows. It's the best \"dev board\" setup I've seen so far. It might be part of their larger commercial plan but it definitely hits the sweet spot for the home enthusiast who have been pleading for more VRAM. reply bee_rider 12 hours agoparentprevSeems more like a workstation. So, that’s just a continuation of the last could Decades of Unix on the Workstation, right? reply throw310822 9 hours agorootparentThey should write an AI-centered OS for it, allowing people to write easily AI heavy applications. And you'd have the Amiga of 2025. reply pjmlp 9 hours agoparentprevBecause NVidia naturally doesn't want to pay for Windows licenses. NVidia works closely with Microsoft to develop their cards, all major features come first in DirectX, before landing on Vulkan and OpenGL as NVidia extensions, and eventually become standard after other vendors follow up with similar extensions. reply diggan 4 hours agoparentprev> their whole new software stack will only run on WSL2. They aren't porting to Win32 Wait, what do you mean exactly? Isn't WSL2 just a VM essentially? Don't you mean it'll run on Linux (which you also can run on WSL2)? Or will it really only work with WSL2? I was excited as I thought it was just a Linux Workstation, but if WSL2 gets involved/is required somehow, then I need to run the other direction. reply hx8 4 hours agorootparentYes, WSL2 is essentially a highly integrated VM. I think it's a bit of a joke to call Ubuntu WSL2, because it seems like most Ubuntu installs are either VMs for Windows PCs or on Azure Cloud. reply awestroke 4 hours agorootparentprevNo, nobody will run windows on this. It's meant to run NVIDIAs own flavor of Ubuntu with a patched kernel reply CamperBob2 14 hours agoparentprevWhere does it say they won't be supporting Win32? reply narrator 13 hours agorootparentHere he says that in order for the cloud and the PC to be compatible, he's going to only support WSL2, the Windows subsystem for Linux which is a Linux API on top of Windows. Here's a link to the part of the keynote where he says this: https://youtu.be/MC7L_EWylb0?t=7259 reply sliken 13 hours agorootparentThe keynote mentioned that it could be used as a Linux workstation. reply stonogo 13 hours agorootparentprev\"Linux API on top of Windows\" is an interesting way to describe a virtual machine. reply pulse7 13 hours agorootparentWSL1 was \"Linux API on top of Windows\", WSL2 is \"Linux VM on top of Windows\" reply pjmlp 9 hours agorootparentMore like, WSL1 was \"Linux API on top of NT kernel picoprocesses\", WSL2 is \"Linux VM on top of Hyper-V\" reply mycall 4 hours agorootparentI wish WSL1 was open sourced reply pjmlp 4 hours agorootparentPicoprocesses are based on Drawbridge research, so at least there is some reading about how it all works, https://www.microsoft.com/en-us/research/project/drawbridge/ https://learn.microsoft.com/en-us/archive/blogs/wsl/windows-... https://www.zdnet.com/article/under-the-hood-of-microsofts-w... reply sedatk 13 hours agorootparentprevThat’s more like WSL1, yes. reply SteveNuts 13 hours agorootparentprevWSL2 is no longer a VM, afaik. reply gnabgib 13 hours agorootparentOther way around (1 wasn't, 2 runs in a managed HyperV VM) https://learn.microsoft.com/en-us/windows/wsl/compare-versio... reply rvz 13 hours agoparentprev> Wow, it may actually be the year of Linux on the Desktop. ? Yeah starting at $3,000. Surely a cheap desktop computer to buy for someone who just wants to surf the web and send email /s. There is a reason why it is for \"enthusiasts\" and not for the general wider consumer or typical PC buyer. reply Topfi 12 hours agorootparentI see the most direct competitor in the Mac Studio, though of course we will have to wait for reviews to gauge how fair that comparison is. The Studio does have a fairly large niche as a solid workstation, though, so I could see this being successful. For general desktop use, as you described, nearly any piece of modern hardware, from a RasPI, to most modern smartphones with a dock, could realistically serve most people well. The thing is, you need to serve both, low-end use cases like browsing, and high-end dev work via workstations, because even for the \"average user\", there is often one specific program on which they need to rely and which has limited support outside the OS they have grown up with. Course, there will be some programs like Desktop Microsoft Office which will never be ported, but still, Digitis could open the doors to some devs working natively on Linux. A solid, compact, high-performance, yet low power workstation with a fully supported Linux desktop out of the box could bridge that gap, similar to how I have seen some developers adopt macOS over Linux and Windows since the release of the Studio and Max MacBooks. Again, we have yet to see independent testing, but I would be surprised if anything of this size, simplicity, efficiency and performance was possible in any hardware configuration currently on the market. reply sliken 10 hours agorootparentI did want a M2 max studio, ended up with a 12 core Zen 4 + radeon 7800 XT for about half the money. A Nvidia Project Digit/GB10 for $3k with 128GB ram does sound tempting. Especially since it's very likely to have standard NVMe storage that I can expand or replace as needed, unlike the Apple solution. Decent linux support is welcome as well. Here's hoping, if not I can fall back to a 128GB ram AMD Strix Halo/395 AI Max plus. CPU perf should be in the same ballpark, but not likely to come anywhere close on GPU performance, but still likely to have decent tokens/sec for casual home tinkering. reply yjftsjthsd-h 12 hours agorootparentprev> Surely a cheap desktop computer to buy for someone who just wants to surf the web and send email /s. That end of the market is occupied by Chromebooks... AKA a different GNU/Linux. reply fooker 12 hours agorootparentprevThe typical PC buyer is an enthusiast now. reply immibis 13 hours agoparentprevNever underestimate the open source world's power to create a crappy desktop experience. reply tokai 8 hours agorootparentYou're like 15 years out of date. reply a_bonobo 7 hours agoprevThere's a market not described here: bioinformatics. The owner of the market, Illumina, already ships their own bespoke hardware chips in servers called DRAGEN for faster analysis of thousands of genomes. Their main market for this product is in personalised medicine, as genome sequencing in humans is becoming common. Other companies like Oxford Nanopore use on-board GPUs to call bases (i.e., from raw electric signal coming off the sequencer to A, T, G, C) but it's not working as well as it could due to size and power constraints. I feel like this could be a huge game changer for someone like ONT, especially with cooler stuff like adaptive sequencing. Other avenues of bioinformatics, such as most day-to-day analysis software, is still very CPU and RAM heavy. reply evandijk70 6 hours agoparentThis is, at least for now, a relatively small market. Illumina acquired the company manufacturing these chips for $100M. Analysis of a genome in the cloud generally costs below $10 on general purpose hardware. It is of course possible that these chips enable analyses that are currently not possible/prohibited by cost, but at least for now, this will not be the limiting factor for genomics, but cost of sequencing (which is currently $400-500 per genome) reply mocheeze 3 hours agoparentprevDoesn't seem like Illumina actually cares much about security: https://arstechnica.com/security/2025/01/widely-used-dna-seq... reply mycall 4 hours agoparentprevThe bigger picture is that OpenAI o3/o4.. plus specialized models will blow open the doors to genome tagging and discovery, but that is still 1 to 3 years away for ASI to kick in. reply nzach 2 hours agorootparentWhile I kinda agree with you, I don't think we will ever find a meaningful way to throw genome sequencing data at LLMs. It's simple too much data. I've worked in a project some years ago where we were using data from genome sequencing of a bacteria. Every sequenced sample was around 3GB of data and sample size was pretty small with only about 100 samples to study. I think the real revolution will happen because code generation through LLMs will allow biologists to write 'good enough' code to transform, process and analyze data. Today to do any meaningful work with genome data you need a pretty competent bioinformatician, and they are a rare breed. Removing this bottleneck is what will allow us to move faster in this field. reply newsclues 6 hours agoparentprevIs this for research labs, health clinics, or peoples homes? reply a_bonobo 6 hours agorootparentONT sells its smallest MinION to regular people, too. But Illumina's and ONT's main market is universities, followed by large hospitals reply gavi 4 hours agoprevthis image seems to be AI Generated - :-) https://s3.amazonaws.com/cms.ipressroom.com/219/files/20250/... Source: https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwe... reply paxys 4 hours agoparentThe text on the screen is an obvious giveaway. reply diggan 4 hours agorootparentDamn, you're right. I didn't even consider looking at the monitor itself as \"They can't be so lazy they don't even use a real screenshot\" while faking the rest kind of makes sense, otherwise you need a studio setup. Never underestimate how lazy companies with a ~$3 trillion market cap can be. reply sipjca 3 hours agorootparentI mean the whole company is betting on AI, why wouldn’t they use AI to generate the image?? Fundamentally it doesn’t matter if it was AI generated or not, most people don’t care and the people that do won’t impact their bottom line reply adolph 3 hours agorootparentprevLazy? This is Nvidia eating their own dogfood. They put in lots of work to get to the point where someone can call it \"lazy.\" reply diggan 25 minutes agorootparent> Lazy? This is Nvidia eating their own dogfood Absolutely, I'm all for dogfooding! But when you do, make sure you get and use good results, not something that looks like it was generated by someone who just learned about Stable Diffusion :) reply diggan 4 hours agoparentprevAgree, unless I've missed some recent invention where keyboards now have two of either Enter/Backspace/Shift keys on the right side. Not sure if that isn't expected though? Likely most people wouldn't even notice, and the company can say they're dogfooding some product I guess. reply tsimionescu 3 hours agorootparentThe keyboard layout seems perfectly reasonable, and rather common: from top to bottom, the rightmost column of keys after the letters would be backspace, |\\, enter, shift, ctrl. On the left, mirrored, you have ~`, tab, caps lock, shift, ctrl. The sizes and shapes match many common keyboard layouts I've seen. reply patrulek 4 hours agorootparentprev> unless I've missed some recent invention where keyboards now have two of either Enter/Backspace/Shift keys on the right side It doesnt have to be two enter/backspace/shift. Keyboard layout seems to be almost identical to Azio L70 Keyboard (at least the keys). reply throw310822 3 hours agoparentprevPrompt: something with some splashy graph on screen. reply treprinum 9 hours agoprevNvidia just did what Intel/AMD should have done to threaten CUDA ecosystem - release a \"cheap\" 128GB local inference appliance/GPU. Well done Nvidia, and it looks bleak for any AI Intel/AMD efforts in the future. reply mft_ 6 hours agoparentI think you nailed it. Any basic SWOT analysis of NVidia’s position would surely have to consider something like this from a competitor - either Apple, who is already nibbling around the edges of this space, or AMD/Intel who could/should? be. It’s obviously not guaranteed to go this route, but an LLM (or similar) on every desk and in every home is a plausible vision of the future. reply iszomer 6 hours agorootparentNvidia also brought Mediatek into the spotlight.. reply theptip 3 hours agoprev$3k for a 128GB standalone is quite favorable pricing considering the next best option at home is going to be a 32GB 5090 at $2k for the card alone, so probably $3k when you’re done building a rig around it. reply egorfine 3 hours agoparentThe press-release says \"up to 128GB\" while the price is a single figure of $3,000. So it won't be out of the real of possibility that the 128GB version would cost quite a bit more. reply mysteria 2 hours agorootparentFrom what I've seen the general consensus is that the 128GB of memory is standard across all models, and that the price would vary for different storage and networking configurations. Their marketing materials say that \"Each Project DIGITS features 128GB of unified, coherent memory and up to 4TB of NVMe storage.\" https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwe... reply egorfine 2 hours agorootparentIndeed! reply lhl 3 hours agoparentprevThe memory bandwidth has not been announced for this device. It's probably going to be more appropriate to compare vs a 128GB M4 Max (410-546GB/s MBW) or an AMD Ryzen AI Max+ 395 (yes, that's its real name) at 256GB/s of MBW. The 5090 has 1.8TB/s of MBW and is in a whole different class performance-wise. The real question is how big of a model will you actually want to run based on how slowly tokens generate. reply mrtksn 12 hours agoprevOkay, so this is not a peripheral that you connect to your computer to run specialized tasks, this is a full computer running Linux. It's a garden hermit. Imagine a future where everyone has one of those(not exactly this version but some future version), it lives with you it learns with you and unlike the cloud based SaaS AI you can teach it things immediately and diverge from the average to your advantage. reply Topfi 12 hours agoparentI'd love to own one, but doubt this will go beyond a very specific niche. Despite there being advantages, very few still operate their own Plex server over subscriptions to streaming services, and on the local front, I feel that the progress of hardware, alongside findings that smaller models can handle a variety of tasks quite well, will mean a high performance, local workstation of this type will have niche appeal at most. reply mrtksn 11 hours agorootparentI have this feeling that at some point it will be very advantageous to have personal AI because when you use something that everyone can use the output of this something becomes very low value. Maybe it will still make sense to have your personal AI in some data center, but on the other hand, there is the trend of governments and mega corps regulating what you can do with your computer. Try going out of the basics, try to do something fun and edge case - it is very likely that your general availability AI will refuse to help you. when it is your own property, you get the chance to overcome restrictions and develop the thing beyond the average. As a result, having something that can do things that no other else can do and not having restrictions on what you can do with this thing can become the ultimate superpower. reply noduerme 12 hours agoparentprev\"garden hermit\" is a very interesting and evocative phrase. Where is that from? reply mrtksn 12 hours agorootparentIt's a real thing: https://en.wikipedia.org/wiki/Garden_hermit In the past, in Europe, some wealthy people used to look after of a scholar living on their premises so they can ask them questions etc. reply noduerme 10 hours agorootparentaha, this is really something. I just got around to watching \"Furiosa\" last night. So something like having a personal \"history man\" (although, my take on the whole Mad Max series is that it's just bottled up fear-porn about white settlers going uncivilized and becoming \"tribal\" - a colonial horror tale, \"The Heart of Darkness\" with motorcycles - common anywhere a relatively small group spread themselves out on a lot of ill-gotten land, did some nasty deeds and lost touch with the mothership). In the Furiosa context, it's a bit like a medicine man or shaman, then. A private, unreliable source of verbal hand me downs, whose main utility is to make elites feel like they have access to knowledge without needing to acquire it for themselves or question its veracity. We really are entering a new dark age. reply mycall 4 hours agorootparent> We really are entering a new dark age. All the indicators are there: Instead of leaders like Charlemagne who unified the Frankish domain, stabilized society, and promoted education and culture, we now have leaders who want to dismantle society, education and use culture for wars. Long-distance ocean trade routes since the 1950s have taken international commerce to another level for humans, but this is being challenged now by aging/leaking tankers, unruly piracy at transit choke points, communication cable destruction, etc. Loss of interest in classical learning and the arts where dystopian, murder or horror movies, music and books now are the best sellers as WW3 seems to be on many people's minds now. While innovations are still occurring for improved navigation and agricultural productivity, the Earth's ecosystem collapse is in full effect. I wish it could reversed somehow. reply rsynnott 3 hours agorootparentprev> The one at Painshill, hired by The Hon. Charles Hamilton for a seven-year term under strict conditions, lasted three weeks until he was sacked after being discovered in a local pub I mean, fair. Very bad hermit-ing. (Terry Pratchett has a fun parody of this in one of the Discworld books; the garden hermit gets two weeks' holidays a year, which he spends in a large city.) reply Mistletoe 11 hours agorootparentprevThis is so strange, my girlfriend was just telling me about those yesterday. The word “ornamental hermit” fills me with about as much disgust as I can experience. > Later, suggestions of hermits were replaced with actual hermits – men hired for the sole purpose of inhabiting a small structure and functioning as any other garden ornament. reply ryao 12 hours agoprevThis looks like a successor to the Nvidia Jetson AGX Orin 64GB Developer Kit: https://www.okdo.com/wp-content/uploads/2023/03/jetson-agx-o... I wonder what the specifications are in terms of memory bandwidth and computational capability. reply kcb 12 hours agoparentHopefully, the OS support isn't as awful as the Jetson platforms usually are. Unless they change, you'll get 1 or 2 major kernel updates ever and have to do bizarre stuff like install a 6 year old Ubuntu on your x86 PC to run the utility to flash the OS. reply ryao 12 hours agorootparentThe community likely will make instructions for installing mainstream Linux distributions on it. reply kcb 12 hours agorootparentDoesn't really help though if it requires an nvidia kernel. reply snerbles 11 hours agorootparentThe official Linux kernel driver for Blackwell is GPL/MIT licensed: https://developer.nvidia.com/blog/nvidia-transitions-fully-t... reply sliken 10 hours agorootparentKeep in mind that a kernel module != driver. It's just doing initialization and passing data to/from the driver, which is closed source and in user space. reply ryao 11 hours agorootparentprevThe Linux kernel license requires Nvidia to disclose their Linux kernel sources and Nvidia open sourced their kernel driver. That said, you can probably boot a Debian or Gentoo system using the Nvidia provided kernel if need be. reply bionade24 9 hours agorootparentIt always has been the userspace of the Jetsons which was closed source and tied to Nvidia's custom kernel. I have not heard from people running Jetpack on a different userland than the one provided by Nvidia. Companies/Labs that update the OS don't care about CUDA, Nvidia contributes to Mesa support of the Jetsons and some only need a bit more GPU power than a RasPi. reply zamadatix 5 hours agoparentprevThe Jetson Orin Dev Kit is squarely aimed at being a dev kit for those using the Jetson module in production edge compute (robotic vision and the like). The only reason it's so well known in tech circles is \"SBC syndrome\" where people get excited about what they think they could do with it and then 95% end up in a drawer a year later because it what it's actually good at is unrelated to why they bought it. This is more accurately a descendant of the HPC variants like the article talks about - intentionally meant to actually be a useful entry level for those wanting to do or run general AI work better than a random PC would have anyways. reply moffkalast 9 hours agoparentprevThe AGX Orin was only 64GB of LPDDR5 and priced at $5k so this does seem like a bargain in comparison with 128GB of presumably HBM. But Nvidia never lowers their prices, so there's a caveat somewhere. reply fulafel 8 hours agorootparentThe memory is LPDDR accordning to the specs graphic on the NV product page: https://www.nvidia.com/en-us/project-digits/ Anyone willing to guess how wide? reply moffkalast 8 hours agorootparentI've seen some claims that it can do 512 GB/s on Reddit (not sure where they got that from), which would imply a ~300 bit bus with LPDDR5X depending on the frequency. reply pella 4 hours agorootparentprobably: \"According to the Grace Blackwell's datasheet- Up to 480 gigabytes (GB) of LPDDR5X memory with up to 512GB/s of memory bandwidth. It also says it comes in a 120 gb config that does have the full fat 512 GB/s.\" via https://www.reddit.com/r/LocalLLaMA/comments/1hvj1f4/comment... \"up to 512GB/s of memory bandwidth per Grace CPU\" https://resources.nvidia.com/en-us-data-center-overview/hpc-... reply sliken 19 minutes agorootparentKeep in mind the \"full\" grace is a completely different beast with Neoverse cores. This new GB10 uses different cores and might well have a different memory interface. I believe the \"120 GB\" config includes ECC overhead (which is inline on Nvidia GPUs) and Neoverse cores have various tweaks for larger configurations that are absent in the Cortex-x925. I'd be happy to be wrong, but I don't see anything from Nvidia that implies a 512 bit wide memory interface on the Nvidia Project DIgits. reply moffkalast 2 hours agorootparentprevYep I think that's it. So it's referencing the GB200, it could have absolutely nothing in common with this low power version. reply tim333 6 hours agoprevI've followed progress since Moravec's \"When will computer hardware match the human brain?\" since that came out in 1997. It starts: >This paper describes how the performance of AI machines tends to improve at the same pace that AI researchers get access to faster hardware. The processing power and memory capacity necessary to match general intellectual performance of the human brain are estimated. Based on extrapolation of past trends and on examination of technologies under development, it is predicted that the required hardware will be available in cheap machines in the 2020s. and this is about the first personal unit that seems well ahead of his proposed specs. (He estimated 0.1 petaflops. The nvidia thing is \"1 petaflop of AI performance at FP4 precision\"). (paper https://jetpress.org/volume1/moravec.pdf) reply magicalhippo 14 hours agoprevNot much was unveiled but it showed a Blackwell GPU with 1PFLOP of FP4 compute, 128GB unified DDR5X memory, 20 ARM cores, and ConnectX powering two QSFP slots so one can stack multiple of them. edit: While the title says \"personal\", Jensen did say this was aimed at startups and similar, so not your living room necessarily. reply computably 14 hours agoparentFrom the size and pricing ($3000) alone, it's safe to conclude it has less raw FLOPs than a 5090. Since it uses LPDDR5X, almost certainly less memory bandwidth too (5090 @ 1.8 TB/s, M4 Max w/ 128GB LPDDR5X @ 546 GB/s). Basically the only advantage is how much VRAM it packs in a small form factor, and presumably greater power efficiency at its smaller scale. The only thing it really competes with is the Mac Studio for LocalLlama-type enthusiasts and devs. It isn't cheap enough to dent the used market, nor powerful enough to stand in for bigger cards. reply llm_nerd 4 hours agorootparentThe product isn't even finalized. It might never come to fruition, and I cannot fathom how they will make the power profile fit. I am skeptical that a $3000 device with 128GB of RAM and a 4TB SSD with the specs provided will even see reality any time within the next year, but let's pretend it will. However we do know that it offers 1/4 the TOPS of the new 5090. It will be less powerful than the $600 5070. Which, of course it will given power limitations. The only real compelling value is that nvidia memory starves their desktop cards so severely. It's the small opening that Apple found, even though Apple's FP4/FP8 performance is a world below what nvidia is offering. So purely from that perspective this is a winning product, as 128GB opens up a lot of possibilities. But from a raw performance perspective, it's actually going to pale compared to other nvidia products. reply sliken 13 hours agorootparentprevI believe $3,000 is for the unmentioned minimum config, no idea on the mentioned 4TB storage and 128GB ram version. Running a 96GB ram model isn't cheap (often with unified memory 25% is reserved for CPUs), so maybe it will win there. reply ac29 12 hours agorootparentThe NVIDIA press release [0] says \"Each Project DIGITS features 128GB of unified, coherent memory and up to 4TB of NVMe storage\", which makes it sound like the RAM is fixed size. [0] https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwe... reply sliken 10 hours agorootparentAwesome. Maybe there will be storage options of 1,2,and 4TB and optional 25/100/200/400 GBit interfaces. Or maybe everything except the CPU/GPU is constant, but having a 50%, 75%, or 100% of the CPU/GPU cores so they can bin their chips. reply KeplerBoy 10 hours agorootparentprevOf course. It has much less FLOPs than the 5090, after all this will have a TDP of ~50W and run off a regular USB-PD power supply. It's basically the successor to the AGX Orin and in line with its pricing (considering it comes with a fast NIC). The AGX Orin had RTX 3050 levels of performance. reply adrian_b 4 hours agorootparentThe successor of NVIDIA Orin is named Thor and it is expected to be launched later this year. It uses other Arm processor cores than Digits, i.e. Neoverse V3AE, the automotive-enhanced version of Neoverse V3 (which is the server core version of Cortex-X4). According to rumors, NVIDIA Thor might have 14 Neoverse V3AE cores in the base version and there is also a double-die version. The GPU of NVIDIA Thor is also a Blackwell, but probably with a very different configuration than in NVIDIA Digits. NVIDIA Thor, like Orin, is intended for high reliability applications, like in automotive or industrial environments, unlike NVIDIA Digits, which is made with consumer-level technology. reply krasin 9 hours agorootparentprevYes and no. Jetson line (which Jetson AGX Orin is a part of) is also providing multi-camera support (with MIPI CSI-2 connectors) and other real-time / microcontroller stuff, as well as rugged options via partners. I hope to see new Jetsons based on Blackwell sometime in 2026 (they tend to be slow to release those). reply KeplerBoy 9 hours agorootparentYeah, i guess its more a branch off the jetson line. Or a midpoint between the Jetsons, IGX Orin (not a typo) and Data Center offerings. reply kcb 12 hours agorootparentprevMaking comparisons to the 5090 is silly. That thing draws 500W+ and will require a boat anchor of metal to keep it cool. The device they showed is something more along the lines of a mobile dev kit. reply modeless 14 hours agoprevFinally a real ARM workstation from Nvidia! This will be much faster than Apple's offerings for AI work. And at $3000 it is much cheaper than any Mac with 128 GB RAM. reply sliken 13 hours agoparentOn the CPU size the Neoverse N2 doesn't compete particularly well with apple's M4, or the Zen5 for the matter. Bit bit hard to tell what's on offer on the GPU side, I wouldn't be surprised if it was RTX 4070 to 5070 in that range. If the price/perf is high enough $3k wouldn't be a bad deal, I suspect a Strix Halo (better CPU cores, 256GB/sec memory interface, likely slower GPU cores) will be better price/perf, same max ram for unified memory, and cheaper. reply skavi 12 hours agorootparentIt’s actually “10 Arm Cortex-X925 and 10 Cortex-A725” [0]. These are much newer cores and have a reasonable chance of being competitive. [0]: https://newsroom.arm.com/blog/arm-nvidia-project-digits-high... reply modeless 13 hours agorootparentprevAI work happens predominantly on the GPU, not the CPU. This GPU with CUDA will run rings around M4 with MLX. And with much more RAM than you can get in a Mac for $3k. A lot of people have been justifying their Mac Studio or Mac Pro purchases by the potential for running large AI models locally. Project Digits will be much better at that for cheaper. Maybe it won't run compile Chromium as fast, but that's not what it's for. reply gardnr 10 hours agorootparentRemember: inference is memory bound. https://www.databricks.com/blog/llm-inference-performance-en... reply sliken 12 hours agorootparentprevThe quotes I've seen mention the maximum config (128GB ram and 4TB of storage) and the minimum price. Nothing saying $3k for 128GB ram and 4TB of storage. I hope I'm wrong, but I'm betting the max price is at least twice the minimum price. reply rfoo 9 hours agorootparentThis is NVIDIA, not Apple. They don't charge you a RAM tax (at least for this product). There is only one config for RAM: 128GB. reply sliken 9 hours agorootparentIt's been far from clear what config options are going to be available, and the $3,000 price is the \"starting at\" price. Not sure what the options will be, but people have collectively found statements that imply all configs will have 128GB ram. Sounds good, I hope it's true. Seems like the storage will have options, because it's \"up to 4TB\". Unsure if there will be differently binned CPUs (clock or number of cores). Or connectX optional or at different speeds. reply rfoo 8 hours agorootparentDoubt it. I don't remember NVIDIA ever doing binning and having different SKUs for their Jetson Developer Kit line, which is similar to this Project Digits thing. reply sliken 3 hours agorootparentWell presumably there's some different configurations supported, otherwise they would say $2,999 instead of starting at $2,999. reply gnabgib 12 hours agorootparentprevNVidia says 128GB ram at $3k[0], it looks like the 4TB storage might be variable (and possibly CPU or GPU cores?). This article says 128GB too.. but used up to twice in a row with different meanings which doesn't help. [0]: https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwe... reply p_l 11 hours agorootparentprevIt's GB200 in desktop compatible enclosure, the RAM is fixed, the SSDs are not, the network ports are fixed too. reply KeplerBoy 10 hours agorootparentIt's GB10 a much cut down version to fit the price point, and space, weight and power requirements. reply sliken 10 hours agorootparentprevThe CPU is apparently the result of a \"secret\" project that wasn't on published roadmaps. It's called the GB110. So maybe they will offer differently binned CPU/GPUs with a different fraction of cores disabled and you can pick your SSD. reply dagmx 10 hours agorootparentprevIt’s most definitely not a GB200 in a desktop enclosure. The processor is using completely different cores, and the GPU is somewhere around a 5070 for TOPs. reply Tepix 12 hours agoprevWith more and more personal AI, i think having a truly private device that can run large LLMs (remember: larger is better) is fantastic! Ideally we can configure things like Apple Intelligence to use this instead of OpenAI and Apple's cloud. reply rapatel0 2 hours agoprevI'm buying one. It's cheaper then my 4090RTX+192GB of ram for more performance and model traning headroom. It's also probably a beast for data science workloads. reply blackoil 10 hours agoprevIs there any effort in local cloud computing? I can't justify $3000 for a fun device. But if all devices (6 phone, 2 iPads, a desktop and 2 laptops) in my home can leverage that for fast LLM, gaming, and photo/video editing, now it makes so much more sense. reply reissbaker 6 hours agoparentOpen WebUI, SillyTavern, and other frontends can access any OpenAI-compatible server, and on Nvidia cards you have a wealth of options that will run one of those servers for you: llama.cpp (or the Ollama wrapper), of course, but also the faster vLLM and SGLang inference engines. Buy one of these, slap SGLang or vLLM on it, and point your devices at your machine's local IP address. I'm mildly skeptical about performance here: they aren't saying what the memory bandwidth is, and that'll have a major impact on tokens-per-second. If it's anywhere close to the 4090, or even the M2 Ultra, 128GB of Nvidia is a steal at $3k. Getting that amount of VRAM on anything non-Apple used to be tens of thousands of dollars. (They're also mentioning running the large models at Q4, which will definitely hurt the model's intelligence vs FP8 or BF16. But most people running models on Macs runs them at Q4, so I guess it's a valid comparison. You can at least run a 70B at FP8 on one of these even with fairly large context size, which I think will be the sweet spot.) reply KeplerBoy 10 hours agoparentprevYou can just setup your local openAI like API endpoints for LLMs. Most devices and apps won't be able to use them, because consumers don't run self-hosted apps, but for a simple chatGPT style app this is totally viable. Today. reply papichulo2023 9 hours agoparentprevMost tools expose openai-like apis that you can easily integrate with. reply TiredOfLife 9 hours agoparentprevThat is literally how it was announced as. AI cloud in a box. That can also be used as Linux desktop. reply aa-jv 5 hours agoparentprevFor companies interested in integrating machine learning into their products, both soft and hard - essentially training models specific to a particular use-case - this could be quite a useful tool to add to the kit. reply timmg 4 hours agoprevOne thing I didn't see mentioned: this would be a good motivation for Nvidia to release \"open weights\" models. Just like Mac OS is free when you buy a Mac, having the latest high-quality LLM for free that just happens to run well on this box is a very interesting value-prop. And Nvidia definitely has the compute to make it happen. reply swalsh 4 hours agoparentThey already do release open weight models, in this very keynote he released some of the bigget open weight models yet: https://huggingface.co/collections/nvidia/cosmos-6751e884dc1... reply logicchains 4 hours agoparentprevThey did exactly this, announcing at the same event new Nemo models upcoming (a fine-tune of llama). reply quick_brown_fox 9 hours agoprevHow about “We sell a computer called the tinybox. It comes in two colors + pro. tinybox red and green are for people looking for a quiet home/office machine. tinybox pro is for people looking for a loud compact rack machine.” [0] [0] https://tinygrad.org/#tinybox reply loudmax 3 hours agoparentGoing by the specs, this pretty much blows Tinybox out of the water. For $40,000, a Tinybox pro is advertised as offering 1.36 petaflops processing and 192 GB VRAM. For about $6,000 a pair of Nvidia Project Digits offer about a combined 2 petaflops processing and 256 GB VRAM. The market segment for Tinybox always seemed to be people that were somewhat price-insensitive, but unless Nvidia completely fumbles on execution, I struggle to think of any benefits of a Tinygrad Tinybox over an Nvidia Digits. Maybe if you absolutely, positively, need to run your OS on x86. I'd love to see if AMD or Intel has a response to these. I'm not holding my breath. reply nilstycho 2 hours agorootparent> For about $6,000 a pair of Nvidia Project Digits offer about a combined 2 petaflops processing and 256 GB VRAM. 2 PFLOPS at FP4. 256 GB RAM, not VRAM. I think they haven't specified the memory bandwidth. reply loudmax 2 hours agorootparentYou're right. Tinybox's 1.36 petaflops is FP16 so that is a significant difference. Also, the Tinybox's memory bandwidth is 8064 GB/s, while the Digits seems to be around 512 GB/s, according to speculation on Reddit. Moreover, Nvidia's announced their RTX 5090s priced at $2k, which could put downward pressure on the price of Tinybox's 4090s. So the Tinybox green or pro models might get cheaper, or they might come out with a 5090-based model. If you're the kind of person that's ready to spend $40k on a beastly ML workstation, there's still some upside to Tinybox. reply mft_ 6 hours agoparentprevThis was my second thought; while we don’t have full performance data, it’s probably a bad day for tinybox. reply kkzz99 9 hours agoparentprevThese look terrible. For 5 times the price you get worse performance. reply nilstycho 3 hours agorootparentAre you comparing tinybox red with 738 FP16 TFLOPS at $15K to Project Digits with 1 FP4 PFLOP at $3K? Or did they announce the Project Digits FP16 performance somewhere? reply moffkalast 8 hours agoparentprev>tinybox >the size of several ATX desktops reply fweimer 6 hours agoprevIf they end up actually shipping this, lots of people will buy these machines to get an AArch64 Linux workstation—even if they are not interested in AI or Nvidia GPUs. At $3,000, it will be considerably cheaper than alternatives available today (except for SoC boards with extremely poor performance, obviously). I also expect that Nvidia will use its existing distribution channels for this, giving consumers a shot at buying the hardware (without first creating a company and losing consumer protections along the way). reply kllrnohj 6 hours agoparent> At $3,000, it will be considerably cheaper than alternatives available today $3000 gets me a 64-core Altra Q64-22 from a major-enough SI today: https://system76.com/desktops/thelio-astra-a1-n1/configure And of course if you don't care about the SI part, then you can just buy that motherboard & CPU directly for $1400 https://www.newegg.com/asrock-rack-altrad8ud-1l2t-q64-22-amp... with the 128-core variant being $2400 https://www.newegg.com/asrock-rack-altrad8ud-1l2t-q64-22-amp... reply fweimer 50 minutes agorootparentI had not seen the System76 systems before. They don't have distributors, and unlike the major OEMs, they don't take care of the customs details for intentional shipments. Prices for systems built with these older Ampere CPUs have come down at the local SIs as well (those that refuse to consumers), which I had not noticed before. Still the workstation form factor seems to be somewhat unique to System76 (unless, as you said, you build your own). Still I expect the Nvidia systems will be easier to get, especially for (de jure) consumers. reply adrian_b 4 hours agorootparentprevThat Altra may be a good choice for certain server applications, like a Web server, but when used as a workstation it will be sluggish, because it uses weak cores, with much lower single-threaded performance than the Arm cores used in NVIDIA Digits. For certain applications, e.g. for those with many array operations, the 20 cores of Digits might match 40 cores of Altra at equal clock frequency, but the cores of Digits are likely to also have a higher clock frequency, so for some applications the 20 Arm cores of Digits may provide a higher throughput than 64 Altra cores, while also having a much higher single-thread performance, perhaps about double. So at equal price, NVIDIA Digits is certainly preferable as a workstation instead of a 64-core Altra. As a server, the latter should be better. reply kllrnohj 2 hours agorootparentI mean I can get a Snapdragon X Elite laptop for $1200 that'll have a faster CPU than the one in the Digits, too... reply adrian_b 2 hours agorootparentTheir speeds should be very similar, but which is faster is uncertain. There have not been any published benchmarks demonstrating the speed of Cortex-X925 in a laptop/mini-PC environment. In smartphones, Cortex-X925 and Snapdragon Elite have very similar speeds in single thread. For multithreaded applications, 10 big + 10 medium Arm cores should be somewhat faster than 12 Snapdragon Elite. The fact that NVIDIA Digits has a wider memory interface should give it even more advantages in some applications. The Blackwell GPU should have much better software support in graphics applications, not only in ML/AI, in comparison with the Qualcomm GPU. So NVIDIA Digits should be faster than a Qualcomm laptop, but unless one is interested in ML/AI applications the speed difference should not be worth the more than double price of NVIDIA. reply fweimer 43 minutes agorootparentIf the Nvidia system runs reasonably well with stock distribution kernels, it may well be worth the extra price. Usually, an optimized, custom kernel is a warning sign, but maybe they have upstreaming plans, and support for other distributions is planned. reply nabla9 8 hours agoprevAmortized cost is 10 cents per petaflop hour if you run it 5-6 years 24/7. I'm including the cost of electricity. This is really game changer. They should make a deal with Valve to turn this into 'superconsole' that can run Half Life 3 (to be announced) :) reply ttul 13 hours agoprevI bought a Lamba Labs workstation with a 4090 last year. I guess I’m buying one of these things now because the Lambda workstation just became a relic… reply openrisk 8 hours agoprevWill there be a healthy \"personal AI supercomputer\" economy to generate demand for this? (NB: spam generators are only a parasite on any digital economy, viable to the extend they don't kill the host). One can only wish for this, but Nvidia would be going against the decades-long trend to emaciate local computing in favor of concentrating all compute on somebody else's linux (aka: cloud). reply delegate 5 hours agoprevI think this is version 1 of what's going to become the new 'PC'. Future versions will get more capable and smaller, portable. Can be used to train new types models (not just LLMs). I assume the GPU can do 3D graphics. Several of these in a cluster could run multiple powerful models in real time (vision, llm, OCR, 3D navigation, etc). If successful, millions of such units will be distributed around the world within 1-2 years. A p2p network of millions of such devices would be a very powerful thing indeed. reply mycall 5 hours agoparent> A p2p network of millions of such devices would be a very powerful thing indeed. If you think RAM speeds are slow for the transformer or inference, imagine what 100Mbs would be like. reply ben_w 4 hours agorootparentDepends on the details, as always. If this hypothetical future is one where mixtures of experts is predominant, where each expert fits on a node, then the nodes only need the bandwidth to accept inputs and give responses — they won't need the much higher bandwidth required to spread a single model over the planet. reply smcl 1 hour agoprevDo I need a \"personal AI supercomputer\"? reply tmoneymoney 1 hour agoparentNo but you want one regardless reply macawfish 14 hours agoprevIs this going to make up for the lack of VRAM in the new consumer GPUs? reply gigatexal 3 hours agoprevWhat are the CPU",
    "originSummary": [
      "Nvidia unveiled Project Digits at CES 2025, a compact \"personal AI supercomputer\" built on the Grace Blackwell hardware platform, featuring the GB10 Grace Blackwell Superchip.",
      "The device offers up to a petaflop of performance, suitable for AI researchers, data scientists, and students, and can handle models with up to 200 billion parameters.",
      "Priced at $3,000, Project Digits will be available in May and can connect to Windows or Mac PCs, running on Nvidia's Linux-based DGX OS."
    ],
    "commentSummary": [
      "Nvidia's Project Digits is a 'personal AI supercomputer' priced at $3,000, featuring a Blackwell GPU with 1 PFLOP (PetaFLOP) of FP4 compute, 128GB unified DDR5X memory, 20 ARM cores, and ConnectX for stacking. - It targets startups and enthusiasts, providing a local alternative to cloud AI solutions, with a focus on memory capacity and efficiency for AI development and inference tasks. - The device operates on Nvidia's DGX OS, based on Ubuntu, and is considered a potential game-changer for local AI computing."
    ],
    "points": 515,
    "commentCount": 380,
    "retryCount": 0,
    "time": 1736223245
  },
  {
    "id": 42619652,
    "title": "A minimax chess engine in regular expressions",
    "originLink": "https://nicholas.carlini.com/writing/2025/regex-chess.html",
    "originBody": "Main Papers Talks Code Writing Writing A 2-ply minimax chess engine in 84,688 regular expressions by Nicholas Carlini 2025-01-05 Can chess, with regular expressions? Yes. Can chess, with regular expressions. Over the holidays I decided it's been too long since I did something with entirely no purpose. So without further ado, I present to you ... Regex Chess: sequence of 84,688 regular expressions that, when executed in order, will play a (valid; not entirely terrible) move given a chess board as input. Here, I'll show you. ╔ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ╗ 8 ║ ♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜ ║ 7 ║ ♟ ♟ ♟ ♟ ♟ ♟ ♟ ♟ ║ 6 ║ ║ 5 ║ ║ 4 ║ ║ 3 ║ ║ 2 ║ ♙ ♙ ♙ ♙ ♙ ♙ ♙ ♙ ║ 1 ║ ♖ ♘ ♗ ♕ ♔ ♗ ♘ ♖ ║ ╚ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ═ ╝ a b c d e f g h M o v e n o t a t i o n : [ s r c ] [ d e s t ] ( e . g . e 2 e 4 ) o r ' q ' t o q u i t [ C a s t l i n g R i g h t s : K Q k q , E n P a s s a n t : - ] E n t e r Y o u r M o v e : Enter your move: Make move Current executing regular expression will show here... Specifically, this is the entirety of the program that is playing a move against you (no really, I'm not kidding, it really is this short): let regex_list = [/* a very long list of regular expressions */] let board = \"rnbqkbnr / pppppppp / 8 / 8 / 8 / 8 / PPPPPPPP / RNBQKBNR w KQkq - 0 1\"; for (regex of regex_list) { board = re.replace(regex.pattern, regex.target) } display(board) By the end of this post you'll (hopefully) understand why this sequence of regular [a] expressions is possible, and also what the specific regular expressions do. (If you're someone who subscribed to this blog in the last six months or so, and have gotten accustom to me writing about \"serious\" and \"important\" things, please treat this as your fair warning that this is MY WEBSITE and I MAKE THE RULES HERE and so today you're learning about RegexChess whether you like it or not.) As always, code for this project is available on GitHub. Getting Started: A Regular Expression CPU So how are we going to get regular expressions to play chess? Well, by making a regular expression computer, of course! More specifically, we're going to design a Branch-Free, Conditional-Execution, Single-Instruction Multiple-Data instruction set. And then make a sequence of regular expressions that interpret these instructions. (Kind of like a GPU instruction set. And a bit of ARM. But a lot slower.) And then from there we can program our new computer to play chess. So let's get started. (Some people may say I have an unhealthy obsession with building weird computers, c.f. my game of life computer or my printf computer. Those people are wrong, and just have an unhealthy obsession with the banal and ordinary.) Computer Design Let me get started by explaining how I'm going to organize the data that the computer is going to operate over. Because we're working with regular expressions, the current state of the computer is going to be represented as a single string containing both the program \"stack\", and all variables in the following format: %% #stack: top item on stack second item on stack .... #variable1: value 1 #variable2: value 2 ... #variablek: value k Each instruction will either manipulate some variables on the stack, or will read or write to a given variable. Let's look at some basic instructions. Basic Stack Operations The Push Instruction Here's the implementation of the push command that adds a value to the top of the stack: def push(const): return [(r\"(%%#stack:)\", r\"\\g\"+const+r\"\")] You should read the return type of these functions as a list of tuples. Each tuple represents a regex transformation to apply, where the left element is the pattern to match, and the right element is the replacement. As a brief regular expression refresher. Each tuple in this list has two parts: the regular expression, and the replacement. A regular expression will match a string if it can find a substring of whatever it's being applied against (the state, in our case). Most characters in a regular expression match themselves, but parentheses create a \"match group\" that can be referenced later. The second argument is the replacement string. Again, most characters mean \"Replace with this character\", but special sequences like \\g are back-references that refer to previously captured groups. In this case, \\g references the first captured group (anything matched within the first set of parentheses)---which in this case is the \"%%#stack:\" header. So, as a result of this operation executing on the stack, we find the occurrence of \"%%#stack:\" in the state, and insert the constant value below that (to the top of the stack). Let's see this in practice. Say we start with an empty stack: %% #stack: If we execute push(\"hello\"), the regular expression will: Match the pattern %%#stack: at the start of our state Capture this header into group 1 (the parentheses in the pattern create this capture group) Replace it with the captured group (\\g) followed by our constant \"hello\" and a newline This gives us: %% #stack: hello If we then execute push(\"world\"), the same process repeats and we get: %% #stack: world hello The regular expression always matches at the top of the stack area, so new items get pushed on top while preserving the existing stack contents below them. The Pop Instruction The pop instruction removes the top element from the stack: def pop(): return [(r\"(%%#stack:)([^]*)\", r\"\\1\")] Here we start to see a few of the special operators that make regular expressions powerful. The [^] block means \"match any character that isn't a newline\" and the * means \"match zero or more of these.\" So taken together we're looking for a line that starts with \"%%#stack:\", and then on the next line, zero or more characters that aren't a newline (so, the entire line). The replacement is just the first line, which has the effect of removing the second line, popping the top of the stack. Let's see how this works in practice. Say we start with this stack: %% #stack: world hello When we execute pop(), the regular expression will: Match the pattern beginning with %%#stack: (captured in group 1) Match any characters until the next newline (captured in group 2 - the \"world\") Replace everything matched with just group 1 (the header), effectively removing the top element This gives us: %% #stack: hello Each pop operation removes exactly one element from the top of the stack, preserving any remaining elements below it. VariableStack Instructions Variable Lookup To load the contents of a variable onto the top of the stack: def lookup(variable): # Find the variable's value and push it onto the stackreturn [(r\"(%%#stack:)([^%]*#\"+variable+\": )([^]*)\", r\"\\1\\3\\2\\3\")] This regular expression is a bit more complex than our previous ones. Let's break down what it does: The [^%]* matches basically any character (% only appears at the start of the program) and so lets us find any variable anywhere in the program. The [^]* matches the variable's value by capturing everything until the end of the line The replacement creates a copy of the value and places it on top of the stack Let's see how this works in practice. Say we start with this state: %% #stack: #foo: hello #bar: world #baz: 42 If we execute lookup(\"bar\"), the regular expression will: Match the stack header in group 1 Match everything up to and including \"#bar: \" in group 2 Match \"world\" in group 3 Use these groups to reconstruct the state with the value copied to the top of the stack And so running the replacement will result in the following state: %% #stack: world #foo: hello #bar: world #baz: 42 The lookup operation preserved the original variable and its value while also placing a copy of the value on top of the stack. This allows us to read variable values without modifying them. Variable Assignment Assigning to a variable presents an interesting challenge: we don't know if the variable already exists. We need to handle both cases: updating an existing variable or creating a new one. Let me show you the implementation and then I'll walk you through it case by case. def assign_pop(varname): return [ (r\"(%%)#stack:([^]*)\" + \"([^%]*#\" + varname + r\": )[^]*\", r\"\\1`#stack:\\3\\2\"), (r\"(%%)([^`]?#stack:)([^%]*)([^%]*)\", r\"\\1`\\2\\4#\" + varname + r\": \\3\"), (r\"%%`\", r\"%%\") ] To begin let's assume the variable already exists. That is, the stack starts off looking like this, and assume we're calling assign_pop(\"bar\"): %% #stack: world #foo: hello #bar: something #othervar: othervalue When we run this regular expression list, we create the following capture groups: %% #stack: world #foo: hello #bar: something #othervar: othervalue After the replacement operation, we get this output: %%` #stack: #foo: hello #bar: world #othervar: othervalue Now we proceed on to the next instruction, and we don't match it because the second regex fails if there's a back-tick after the program start %%. So nothing happens. And then finally, the third regex cleans things up for us. Handling Non-Existent Variables: Let's consider what happens if the variable doesn't already exist. Again, assume we're calling assign_pop(\"bar\"): %% #stack: world #foo: hello #othervar: othervalue The first regex tries to match but fails because there is no \"#bar\" anywhere. So it doesn't do anything. But now the second regex tries to match and succeeds. It creates the following capture groups: %% #stack: world #foo: hello #othervar: othervalue From here, we perform the rewrite and get the following output: %% #stack: #foo: hello #othervar: othervalue #bar: world And then the third regex is applied and does nothing. There are lots of instructions that use this trick to make sure we don't apply things in the order we don't want. For example, as an exercise for yourself, try to understand how the \"is equal\" instruction works: def eq(): return [ (r\"(%%#stack:)([^]*)\\2\", r\"\\1`True\"), (r\"(%%#stack:)([^`][^]*)([^]*)\", r\"\\1False\"), (Branch-Free) Conditionals Programming languages, in order to be interesting, usually need to have some kind of control flow. It's very hard to write some program without ever having an if statement. So let's now show how we're going to do this. (And I hope you did your homework, because we're going to use the same conditional execution trick again!) Here's the implementation of a conditional instruction: def cond(tag): return [(r\"%(%#stack:True)\", r\"%\\1`\"), (r\"%(#stack:False)\", tag+r\"\\1`\"), (r\"(True|False)`\", \"\")] Let's walk through how this is going to work, starting with the case where the top of the stack is False. %% #stack: False #variable: value Initially, the first regex will fail to match, because the top element on the stack isn't True. So we go to the next regex, and see if it applies. This one does match, and makes the corresponding match groups. %% #stack: False #variable: value After we apply the replacement, we get the following stack. %tag #stack: False` #variable: value (And finally, using the same cleanup trick, we'll remove the used marker.) Now see what happened here? The program no longer begins with %%. This means that EVERY instruction will fail to match, because they always make sure that the program begins with %%. So nothing else will happen.... until we reactivate it later with the following simple instruction: def reactivate(tag): return [(r\"%\"+tag+r\"([^%]*)\", r\"%%\\1\")] Let's now return to the True case for the conditional. This is the easy case: we basically don't do anything at all. We replace the stack with True` on the second regex, and then delete this line on the third. Easy. Notice that this means our code is actually branch-free, because every instruction is a conditional instruction. (Kind of like ARM's predicated execution, where most instructions can be conditionally executed based on status flags rather than using explicit branch instructions.) Loops (are impossible) Because our program just consists of a sequence of regular expressions, you can't loop at all! That, technically, means we can't actually perform Turing Complete But we can do any bounded computation by just unrolling any loops we may have. And fortunately computing the next move in a chess position is a bounded computation, so we can do just that. Single-Instruction Multiple-Data And now for my absolute favorite part of the language we've developed. By the magic of regular expressions (and the fact that they perform substitution globally over the entire string), we can run multiple threads simultaneously! That is, if we just write our state string as: %% #stack: int0000101010 int0001011100 %% #stack: int0000001101 int0110000000 When we call binary_add(), both additions happen simultaneously! After execution: %% #stack: int0010001110 %% #stack: int0110001101 The reason this happens is because the regular expression matches work globally. When we match the \"begin thread\" operator (%%) twice, we get to perform operations on both threads simultaneously. So how do we actually make use of this feature? Let's look at some instructions that help us create and manage threads. The Fork Instructions Here's a simple fork instruction that splits every currently running thread into two, with the second one starting off inactive with a given tag: def fork_inactive(tag): return [(r\"%%([^%]*)\", r\"%%\\1\" + \"%\"+tag+r\"\\1\") ] We can also, for example, fork() on a boolean, giving one thread the True case and another the False case. (This is something like McCarthy's Amb operator reference) def fork_bool(variable): return [(r\"%%([^%]*)\", r\"%%\\1#\"+variable+r\": True%%\\1#\"+variable+r\": False\") Let's see what happens when we apply multiple forks. Starting with a simple state: %% #stack: somevalue #x: 10 After calling fork_bool(\"condition\"), we get: %% #stack: somevalue #x: 10 #condition: True %% #stack: somevalue #x: 10 #condition: False If we then call fork_bool(\"c2\"), each existing thread splits into two: %% #stack: somevalue #x: 10 #condition: True #c2: True %% #stack: somevalue #x: 10 #condition: True #c2: False %% #stack: somevalue #x: 10 #condition: False #c2: True %% #stack: somevalue #x: 10 #condition: False #c2: False Now we have four simultaneous execution paths, exploring every possible combination of our boolean conditions at the same time. This is exceptionally useful for chess, when we might frequently want to consider multiple possible board states at the same time, and (for example) score them to see which is best. Instead of having to loop over every possible board state, we can just pretend we were doing it once but have them all happen at the same time. Compiling to our little language Now that we have our CPU emulator, we can build a compiler to target our new assembly language. \"But wait I'm not reading this post for a lesson in compilers!\" you say?? Fair point. Also I didn't go into this project trying to build a compiler, so instead what I have is more of a macro-assembler. It turns python-ish programs like this: def fib(): a = 1 b = 2 for _ in range(10): next = a + b a = b b = next Into a sequence of instructions like this: push(1) assign_pop('a') push(2) assign_pop('b') lookup('a') lookup('b') binary_add() assign_pop('next') lookup('b') assign_pop('a') lookup('next') assign_pop('b') [... repeated 8 more times ...] Compiling Through Symbolic Execution Rather than writing a traditional compiler with parsing and code generation phases, I took an unusual approach: symbolic execution. The key insight is that we can \"execute\" the Python code in a special way that records what operations would happen rather than actually performing them. Here's how it works: the variables argument isn't actually a dictionary---it's a special object that records every operation performed on it. It creates what we call a \"trace\" of the execution. When you write: a = b + 1 The tracer object records four operations: A lookup of variable 'b' A push of the constant 1 A binary_add operation An assign_pop to variable 'a' Handling Control Flow The trickiest part of this approach is handling branching control flow---if statements, specifically. (What about loops? We don't have those, so I never use them. Loops can only have constants.) We need to make sure we capture all possible execution paths. Here's how we do it: When we hit a conditional, we create two separate paths in our trace---one for when the condition is true, and one for when it's false. Each path records its own sequence of operations. Later, we merge these paths back together. For example, this Python code: if x > 0: y = 1 else: y = 2 Generates something like this trace structure: lookup('x') # Get x's value push(0) # Push 0 greater_than() # Compare cond('tag1') # Branch on result # True path: push(1) assign_pop('y') pause('tag2') reactivate('tag1') # False path: push(2) assign_pop('y') reactivate('tag2') The magic of the compiler lies in how it handles control flow through branching. Let me explain this in a little bit more detail. When our compiler first starts processing code, it maintains a single linear path of instructions in the CallTree. Each instruction gets appended one after another as we go. This list of instructions looks entirely linear. When we reach a conditional statement, though, things get interesting. Consider what happens when we hit a conditional statement like the x > 0 conditional above. When this happens, I detect it, and create a branch in the call tree representing the two paths simultaneously. Then, I just pretend this conditional was true, and fill out the true case of the tree. When we reach the end of the program we've done some of our compilation, but not all of it. Now comes the clever part. When compiling, we don't just trace the program once. We trace many times. And each time we trace, we arrange for the conditionals to go through whichever branch has been taken least often. In this way, the second time around, we record the instructions for the false branch. Finally, once the conditional is over, we detect this and merge the two branches back together. This branching and merging mechanism is more than just a clever trick---it's essential to how our regex-based CPU actually works. When we convert this tree into instructions, each branch gets translated into a conditional regex operation (using our cond instruction) that can selectively activate and deactivate different parts of our program state. The merge points become reactivate instructions that ensure we continue execution on the correct path. Writing a Chess Engine Okay, so we're finally to the part of this post where we can actually start writing a chess engine. (And at the part where some of the emulator design decisions will make sense.) For the most part, this is entirely straightforward and mirrors how you would write a chess engine in any other programming language. But this branching thing with SIMD is what gives us the power to make things go fast. Let's consider the following (simplified) program that calculates all the valid pawn moves. def pawn_moves(initial_board): # Step 1: Find all pawns and create a list of their positions pawnpos_list = find_all_pawns(initial_board) # Step 2: Create parallel states for each pawn (up to 8) MAX_PAWNS = 8 for iteration in range(MAX_PAWNS): if not pawn_list.is_empty(): pawn_pos = pawnpos_lst.remove_first() fork_inactive(\"waiting\") # Step 3: Switch to processing the parallel states pause(\"main\") reactivate(\"inactive\") # Step 4: Generate moves for all pawns simultaneously candidate_moves = [] if initial_board[pawn_pos + (0, 1)].is_empty(): candidate_moves.append(pawn_pos + (0, 1)) if pawn_pos.y == 2: if initial_board[pawn_pos + (0, 2)].is_empty(): candidate_moves.append(pawn_pos + (0, 2)) if initial_board[pawn_pos + (1, 1)].has_opponent(): candidate_moves.append(pawn_pos + (1, 1)) if initial_board[pawn_pos + (-1, 1)].has_opponent(): candidate_moves.append(pawn_pos + (-1, 1)) # Step 5: Switch back and merge results pause(\"inactive\") reactivate(\"main\") candidate_moves = merge_variables_from_threads(\"inactive\") Step 1: Finding the Pawns The find_all_pawns() function scans through our board representation, looking for white pawns (represented as 'P' in the FEN string). It returns a list of the position of each of these pawns. As an example, if we run our program on the following position with three pawns on d2, e2, and f2, this creates a semicolon-separated list in the pawnpos_lst variable as follows %% #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos_lst: d2;e2;f2; Step 2: State Creation Now comes the clever part. The fork_inactive instruction, as described above, duplicates our entire program state. Each time it runs, it creates an exact copy of the currently running thread, but marks the new copy with %waiting instead of %%. (Recall this means instructions won't apply to this thread.) At the same time, it takes one position from our pawnpos_lst and assigns it to a new variable pawnpos in the copied state. When our loop runs three times, each fork_inactive operation splits off a new parallel universe where we'll process a different pawn. The regex operation that does this copying preserves all existing variables but adds the new pawnpos variable with the specific position for that copy to process. %% #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos_lst: %waiting #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos: d2 %waiting #stack: #board: 4k3/8/8/8/8/3PPP2/4K3 #pawnpos: e2 %waiting #stack: #board: 4k3/8/8/8/8/3PPP2/4K3 #pawnpos: f2 Step 3: Activation Switch Recall that the pause and reactivate operations work by manipulating the %% markers that indicate which states are active. The pause(\"main\") operation changes our original %% to %main, effectively deactivating it. Then reactivate(\"inactive\") finds all states marked with %waiting and changes them to %%, making them the new active states. Step 4: Parallel Move Generation Here's where the SIMD magic happens. Each check for a possible move---forward one square, forward two squares, or diagonal captures---executes across all active states simultaneously. When we check if the square ahead is empty, we're actually checking d3, e3, and f3 all in one operation. For each valid move, we add this to the candidate_moves list. (I've significantly simplified the program for visual purposes here. In reality I don't work directly over the FEN strings but expand them to 64 independent variables for each of the 64 squares and read and write to these squares directly. This makes processing the board state much easier. But for the purpose of this blog post it's easier to show visually as if it worked on FEN strings alone.) %main #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos_lst: %% #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos: d2 #candidate_moves: d3;d4 %% #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos: e2 #candidate_moves: e3;e4 %% #stack: #board: 4k3/8/8/8/8/8/3PPP2/4K3 #pawnpos: f2 #candidate_moves: f3;f4 Step 5: Merging Results The final merge operation combines all the candidate_moves lists from our parallel states. It first switches activation back to the main state using pause and reactivate. Then merge_variables_from_threads (again, a pseudo-op I've made up for visual clarity, in practice this requires like 10 different instructions on my real machine) match all the candidate_moves lists across our inactive states and concatenates them together. What this means is that while the code we wrote code looks like it processes one pawn at a time, our regex engine's ability to process multiple states means we're actually handling all pawns simultaneously. Every operation, from checking empty squares to building move lists, happens in parallel across all our active states. And this is how every piece operation works. Because this post is already getting quite long, I won't walk through each piece one by one, but if you're interested definitely go look at the chess-engine.py for the details. Playing a Turn Now let's walk through the overall game loop that handles everything. def play_turn(): # Step 1: Read the human entered move from the inputboard_before_move, src, dst = from_pretty_utf8_to_fen() # Step 2: Check if their move is valid after_move = board_before_move.make_move(src, dst) next_boards = compute_legal_boards(board_before_move) next_board = fork_on_list(next_boards) if after_move != next_board: destroy_active_thread() # Step 3: Generate the computer's reply candidate_boards = compute_and_score_legal_boards(after_move) candidate_board = fork_on_list(candidate_boards) keep_best_scoring_board(score) from_fen_to_pretty_utf8(candidate_board) Say we're at the start of a game, and the human enters \"e2e4\" (the king's pawn opening). Here's how our code processes this: Step 1: Reading the Move Initially, the function from_pretty_utf8_to_fen() converts our pretty-printed board with Unicode chess pieces back into FEN notation. It also extracts the source and destination squares from the input: %% #stack: #board: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR #src: e2 #dst: e4 Step 2: Move Validation Now we need to check if this is a valid move. Rather than writing entirely new code that explicitly checks if a move is legal, we use our parallel processing power again. The process works in three stages: First, make_move applies the human's move to create a new board state: %% #stack: #board: rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR #after_move: rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR Then compute_legal_boards generates all possible legal moves from the starting position, creating a list like: %% #stack: #next_boards: rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR; rnbqkbnr/pppppppp/8/8/8/3P4/PPP1PPPP/RNBQKBNR; rnbqkbnr/pppppppp/8/8/8/4P3/PPPP1PPP/RNBQKBNR; ... Finally, fork_on_list creates parallel states for each legal board position: %% #stack: #board: rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR %% #stack: #board: rnbqkbnr/pppppppp/8/8/8/3P4/PPP1PPPP/RNBQKBNR %% #stack: #board: rnbqkbnr/pppppppp/8/8/8/4P3/PPPP1PPP/RNBQKBNR The destroy_active_thread() call removes any thread where the board doesn't match after_move. In our case, only the e2-e4 position survives, confirming it's a legal move. (If no legal move is made, I have a special regex that will replace the entire output with just the hard-coded text \"Illegal Move.\") Step 3: Computer's Reply Now we repeat a similar process to find the best reply. First, compute_and_score_legal_boards generates all possible black responses. This function does a little bit of magic, and when it returns the next possible boards, it returns with each board the score of that board after whites next best move I'll explain how this works below. But suffice to know that what this function returns for now the possible positions as compute_legal_boards does, but also the score of the position. (This is where the MiniMax happens. The score here is how good each position is from the player's perspective, after they have made their best reply move.) So running this function gives us something like this as output %% #stack: #board: rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR #score: 100 %% #stack: #board: rnbqkbnr/ppppp1pp/8/5p2/4P3/8/PPPP1PPP/RNBQKBNR #score: 102 %% #stack: #board: rnbqkb1r/pppppppp/5n2/8/4P3/8/PPPP1PPP/RNBQKBNR #score: 98 keep_best_scoring_board(score) collapses these parallel states, but this time keeping only the position with the highest score according to black (in this example, the f7-f5 response). This is the second half of the minimax search---the one where we look at all of the options where our opponent had a pick the first time around, and now we pick among these the best for us. Finally, from_fen_to_pretty_utf8 converts this position back to the pretty Unicode display format. As a result, I never have to build any explicit search algorithms or lists to store lists of positions, that's all handled by the parallel processing. MiniMax Search (for free) The final missing piece of this process is how to implement the compute_and_score_legal_boards function in a way that gets us the depth-2 minimax search. And here I cheat (a lot). It is relatively easy to generate pseudo-legal moves---that is, moves that are basically legal, but might leave the king in check. In chess this isn't allowed (you can't end your turn in check) and so the second thing that has to happen is I have to delete all of the moves that would leave the king in check. The way to do this is to again generate all possible opponent replies and see if any of them would possible \"capture\" the king. If they would, then the position is illegal because that's the definition of check. But what this means is we're already doing a depth-2 search. We have our initial board state. Depth 1, we generate all possible moves the computer wants to make. Then depth 2, we generate all possible moves the opponent could make to ensure we're not in check. All I have to do now then is score each of these opponent-generated moves and return the score of the candidate position as the best scoring among all of these (from the perspective of the opponent). And then I can just take the best scoring of these (from the persepctive of the computer) as its best move Now there's one slight problem here, which is why real chess engines don't do this. And that is this isn't technically a full depth-2 minimax search because it would allow the opponent moves generated in reply to be illegal because they could put their king in check. So doing this fully correctly would require a depth-3 search, which would significantly increase the cost of the search. So I just don't do that. Importantly, the computer will never generate an illegal reply. This just means that, in some cases, the reply it generates won't be quite as strong as if it had done a full depth-2 minimax search because it might assume the opponent could make an illegal move. Everything Else There's a lot more that goes into the program than this. If you're curious I'd encourage you to read through the source code on GitHub. Among the things I think are particularly interesting that I didn't talk about here: How to parallelize move generation for sliding pieces like bishops, rooks, and queens all at exactly the same time How castling is implemented with a specialized \"is this square under attack\" procedures Conversion to and from the FEN chess board to one has a single variable per square Detection of castling rights by tracking the king and rook positions The implementation of en passant capture detection and tracking An extensive 2000 lines of tests, validating the correctness of the engine over several thousand games Some Performance Tricks Before I leave you, I thought I'd describe a few fun performance optimizations I made. My initial code would take roughly 30 minutes to generate a single human reply---perfect for chess by mail, less perfect for chess by browser. The final code, on my machine, takes somewhere between one and ten seconds depending on the position. So I managed about a factor of 100 speedup by making sure I got all the details right. (I've already shown you my favorite performance trick: parallel processing. Now I'll tell you a few more.) Delete Intermediate Variables One of the biggest performance killers in the initial implementation was keeping too many intermediate variables around. Every variable lookup requires scanning through the entire state string to find the variable's value - an O(n) operation. Additionally, when we fork execution states, we need to copy all these variables, which bloats our memory usage significantly. By aggressively deleting variables as soon as they're no longer needed, and reusing variable names where possible, I was able to dramatically reduce both the computation time and memory usage. Evaluating a single move now takes about 300MB of internal state, down from 10GB in the unoptimized version. Fast Regex Matching Recall earlier that I defined the conditional operator like this def cond(tag): return [(r\"%(%#stack:True)\", r\"%\\1`\"), (r\"%(#stack:False)\", tag+r\"\\1`\"), (r\"(True|False)`\", \"\")] Why do you think the third regex is written this way? Wouldn't it just be shorter if it was like this instead: def cond(tag): return [(r\"%(%#stack:True)\", r\"%\\1`\"), (r\"%(#stack:False)\", tag+r\"\\1`\"), (r\"(True|False)`\", \"\")] Notice the missing newline . As it turns out, the first version actually improves the efficiency of this instruction by a factor of two! By changing just one character! The reason for this is due to the details about how regular expressions work and how they're matched. There are going to be lots of True/False strings all throughout the code. But most of them will be part of variables, and not the top element on the stack. By requiring the preceding newline and \"#stack:\" prefix in our pattern, we ensure the regex engine can quickly skip over all the True/False strings that appear in variable names or values. This dramatically reduces the number of attempted matches the regex engine needs to make. Writing Special-Purpose Instructions Sometimes it's worth writing specialized instructions rather than composing existing ones. For example, one of the slowest parts of the initial implementation was in a loop that scanned each of the squares to find all pieces of a given type. This required a bunch of conditionals, and within each conditional, a bunch of stack operations. But you can just smash the entire loop body into a single regex instruction: def do_piece_assign(piece_chr, piece, x, y, pos): return [(f\"%%([^%]*#{pos}: {piece_chr}[^%]*)\" + f\"#{piece}x_lst: ([^]*)\" + f\"#{piece}y_lst: ([^]*)\" + f\"#{piece}pos_lst: ([^]*)\", fr\"%%\\1#{piece}x_lst: {x};\\2\" + fr\"#{piece}y_lst: {y};\\3\" + fr\"#{piece}pos_lst: {pos};\\4\")] The final major optimization comes from maximizing how much we can do in parallel. Remember that our regex engine can process multiple states simultaneously---this means that instead of generating moves one at a time, we can generate them all at once. For example, when generating rook moves, instead of checking each direction sequentially, we can fork eight parallel states---one for each possible direction. (Notice that \"up\" and \"down\" are different directions.) Each state then moves its rook as far as it can go in that direction. This turns what would be a loop into a single parallel operation. Similarly, when evaluating positions, instead of scoring one position at a time, we create parallel states for each candidate position and evaluate them all simultaneously. This parallel evaluation is particularly effective because most of our operations (like counting piece values) work identically across all states. Conclusion What do you want out of a conclusion to a blog post like this? I don't really have much to conclude. I guess I'll just say that I think more people should do entirely pointless things like this. It's a lot of fun, no one cares how long it takes you to finish, no one cares if it works or not, and incidentally, it teaches you more than you wanted to know about dozens of areas of computer science outside your field. I hope to have a few more entirely pointless things like this coming later this year. If you liked this sort of thing, you might find it fun to read this other article I wrote about how to play tic-tac-toe using C's printf statement, or how I wrote a Doom clone in 13kB of JavaScript. If you want to be notified the next time I write something (maybe like this, maybe not) enter your email address here. There's also an RSS Feed if that's more of your thing.",
    "commentLink": "https://news.ycombinator.com/item?id=42619652",
    "commentBody": "A minimax chess engine in regular expressions (carlini.com)428 points by ilya_m 13 hours agohidepastfavorite81 comments basementcat 12 hours agoThis is from the same gentleman who (among other things) demonstrated that printf() is Turing complete and wrote a first person shooter in 13kB of Javascript. https://github.com/HexHive/printbf https://github.com/carlini/js13k2019-yet-another-doom-clone reply wodenokoto 11 hours agoparent> demonstrated that printf() is Turing complete and wrote a first person shooter in ... Not gonna lie, I thought that sentence would end with the FPS being done in printf. reply teleforce 9 hours agorootparentThis guy wrote tic-tac-toe in a single call to printf for IOCCC 2020 competition: https://github.com/carlini/printf-tac-toe reply tubs 7 hours agorootparentIt’s very fun and impressive but it’s absolutely not a single call. reply rhdjebejdbd 7 hours agorootparentMaybe a generous interpretation of the comment and a realisation that common language isn't always 100% precise would be better than pointless arguments about semantics. There is only a single printf written in the source code. reply tubs 6 hours agorootparentThat I can agree with! reply philipwhiuk 5 hours agorootparentprevI don't think it's an unreasonable criticism, otherwise the challenge is trivial: ``` function printg(arg) { printf(arg); } ``` reply Ensorceled 1 hour agorootparentThat, of course, isn't what they did. reply albertzeyer 10 hours agoparentprevThe development writeup for the Doom is interesting, with many details. https://nicholas.carlini.com/writing/2019/javascript-doom-cl... There was one month time to complete the competition. But it seems you were allowed to reuse any existing other code. Looks like this was quite fun to work on. (I feel a bit sad that I would never be able to get one month of free time to work on this now, due to family and job...) reply kookamamie 5 hours agoparentprev> a first person shooter in 13kB of Javascript I was somewhat disappointed to realize they used WebGL for rendering the graphics. reply klibertp 3 hours agorootparentThere was an earlier version of the underlying 3d engine that used only Canvas. WebGL use is justified like this: > Once I actually got that working doing all of the math by hand in JavaScript I decided that using WebGL would probably be worth it, and actually probably wasn't cheating all that much. WebGL exposes access to the GPU-enabled rendering engine through JavaScript. While it does abstract away some of the rendering, it's less than I thought---it just supports the ability to do the necessary math efficiently---so I decided this wouldn't be cheating. And fortunately, it didn't take long to reproduce the initial renderer, but this time supporting much better (and more efficient) graphics. From: https://nicholas.carlini.com/writing/2019/3d-renderer-javasc... reply ThrowawayTestr 11 hours agoparentprevnext [4 more] [flagged] noduerme 10 hours agorootparentI'm not sure how this quote applies to harmless pursuits like making and solving absurd puzzles. It's not like regex chess is going to be a weapon of mass destruction. reply florbo 10 hours agorootparentIt's a line from the movie Jurassic Park. Pretty sure they're just joking. reply noduerme 9 hours agorootparentThe whole comic aspect of Jeff Goldblum's character was a guy who took jokes literally. Huzzah! reply vintagedave 8 hours agoprevThis point was where this changed from crazy/fun to absolutely extraordinary, where calculations of multiple possible positions all occurred in parallel, running a regex over an increasing series of state & variable sets, aka threads: > And now for my absolute favorite part of the language we've developed. By the magic of regular expressions (and the fact that they perform substitution globally over the entire string), we can run multiple threads simultaneously! Also: > What do you want out of a conclusion to a blog post like this? I don't really have much to conclude. I guess I'll just say that I think more people should do entirely pointless things like this. It's a lot of fun, no one cares how long it takes you to finish, no one cares if it works or not, and incidentally, it teaches you more than you wanted to know about dozens of areas of computer science outside your field. What a wonderful ethos. reply ricardo81 8 hours agoparentThis makes me wonder whether I could achieve such a thing if I removed all my preoccupations of other stuff. For me what I take out of it is the power to sit down, focus your mind on something then who knows the lengths of what is possible. That, and the author is clearly very talented/skilled and creative. reply larodi 7 hours agorootparentApparently it takes more than skill but also persistence and concentration. Not many schools of thought explain this well . reply PaulHoule 3 hours agorootparentNo, it takes (1) knowing what you learn in a compilers class (or upper level math classes) and (2) putting it to work. He didn't write 80,000 regular expressions, he wrote a compiler that wrote those expressions. Commercial-quality compilers are hard to write but simple compilers are straightforward if you know the fundamentals. It's like the problem of solving the Rubik's cube. If you look at it in terms of geometry and spatial intuition it's intractable. If you treat it as an abstract algebra problem and break it down into \"solve the top of the cube, solve the middle row of the cube, solve the bottom of the cube\" and then develop a set of operators that will let you permute certain parts of the cube it takes a moderate amount of skill, persistence and concentration. CS students do exercises such as writing moderately complex programs for a Turing machine and it's an exercise like what he did. ==== Funny my project last month was a chess engine. For a long time I'd wondered if I could make a decent MCTS chess engine but someone close to me has been getting serious about chess (usually wins against the random person, usually loses at the chess club, is fighting hard to get up the bracket) so writing a program that was a match for him seemed like a fun and meaningful project and I decided to try the conventional route of alpha-beta search. If you tried to write a chess engine from zero you'd probably struggle, but the lifetime value you get out of education (CS or otherwise) is looking things up the literature, learning from other people's experiences, and putting it to work. So this has been my guide https://www.chessprogramming.org/Main_Page I started out with Python with the goal of making something tiny and stylish and started out with a move generator from https://python-chess.readthedocs.io/en/latest/ and once I got the signs right in alpha-beta negamax (when I had them wrong it discovered https://en.wikipedia.org/wiki/Fool%27s_mate) it beat my tester several times before he regrouped, traded a knight for a good pawn structure, and got his first win. The next goal is to take it to the chess club which means it has to respect time control. I switched to Java because its faster and because it is easy to have a comms thread interrupt a think thread. The first try wasn't faster because my move ordering was terrible. I was much faster implementing it though because I could cut and paste the test cases I had in Python and if I knew anything at this point it was the signs in negamax. https://en.wikipedia.org/wiki/Iterative_deepening_depth-firs... is not only good for time control but gets better move ordering and I'm in the middle of implementing that. It would take me years to find out that Iterative Deepening works a lot better than you might expect, the Killer Heuristic, etc. Reading is my superpower. reply larodi 18 minutes agorootparentOkay, as you wish. Though I've never seen people accomplish stuff like a) understand regex; and b) write a compiler for it without \"persistence and concentration.\". Perhaps some get it delivered through divine apparition of some kind. What is it that really triggered your lengthy response and the narrative..., I really fail to understand, sorry. reply 3willows 1 hour agorootparentprevAgree. The whole point of the article is to generate the long list of regex programmatically. A quick way to verify this is to download the repo, remove everything other than main.py and regex-chess.json, and the programme will still work. All the other python files are building up to regex-chess.json, see e.g. the imports and output to write_regex_json.py. reply comonoid 8 hours agoprevI fear not the man who plays chess with 84,688 regular expressions, but I fear the man who plays chess with one regular expression. reply anal_reactor 6 hours agoparentI fear people in general because I have social anxiety reply reader9274 11 hours agoprevThere's a bug somewhere it seems like, as it ends the following game with \"Illegal move, you lose\", even though it's not an illegal move: 1. e2e4, e7e5 2. d2d4, e5d4 3. d1d4, a7a5 4. g1f3, b7b5 5. b1c3, a5a4 6. c3b5, a4a3 7. b5a3, a8a3 8. b2a3 --> Illegal Move You Lose. Game over. FEN of game above: 1nbqkbnr/2pp1ppp/8/8/3QP3/P4N2/P1P2PPP/R1B1KB1R b KQk - 0 8 reply oah 7 hours agoparenta2a3 on the first move or on the second move after e2e4 outputs that you have played an illegal move. But this is a bug as these are legal moves. reply foxglacier 11 hours agoparentprevSimply using a2a4 as the first move does that too. reply reader9274 10 hours agorootparentah interesting, a2a3 does the same. May be a bug with moves on the a file by white reply thot_experiment 11 hours agoprevWhen I see this sort of thing I just I want to take my hat off and stand in solemn appreciation for the true heroes among men. reply z3t4 6 hours agoprevThis is not only a chess engine, it's a computer and an assembly language, built in only using Regexp reply 3ple_alpha 2 hours agoprevIt does seem to play worse than it should, by game went: 1. d4 d5 2. c4 dxc4 3. e4 Qxd4 4. Qxd4 5. Bc4 6. Nf3 7. O-O 8. Rd1 9. Qd8# reply x0n 1 hour agoparentOh no dude, it's worse than that: c4, Qa4, Qxa5, Qc7, Qxc8# lol reply tromp 32 minutes agorootparentNice find. I tried to get an even shorter mate, but its tendency to give up its pieces got in the way: 1. e4 e5 2. Bc4 Bc5 3. Qh5 Bxf2+ 4. Ke2 Bxg1 5. Qxf7# Can anyone get a mate in 4? reply tromp 27 minutes agorootparentOh, that was easier than expected: 1. e4 e5 2. Qh5 a6 3. Bc4 a5 4. Qxf7# I assume a mate in 3 (or a Fool's mate in 2) is not possible... reply lifthrasiir 12 hours agoprevPreviously: Chess written in sed https://news.ycombinator.com/item?id=6261314 Of course, the sed version does make use of control flow commands in sed and only probes 1ply (I think) so this version is significantly different in that regard. reply DylanSp 1 hour agoprevThe bug with a-file moves has been fixed: https://github.com/carlini/regex-chess/issues/1. reply dointheatl 1 hour agoprevIt doesn't seem to know how to handle pawn promotion. It told me it was an illegal move and that I'd lost the game. reply RobRivera 1 hour agoprevI read 'cheese engine' and excitedly clicked. I think my priorities are out of line reply dstrek 11 hours agoprevI normally don’t lose so quickly opening with a2a4 ! reply NooneAtAll3 11 hours agoparentoh, cool I encountered similar bug in the a-column via e2e4-d2d4-d1d4-g1f3-f1b5-d4e5-e5c5-e1g1-b2a3 reply compootr 10 hours agoparentprevGoogle en passant reply cyphar 7 hours agorootparentHoly hell! reply QuentinCh 9 hours agoprevThe idea of doing something without a defined \"productive\" goal might help to do things differently, discover new ways, and in the end stumble on an innovation? Tried it, 2 comments: 1) Engine gives a piece early with: 1. b3 b6 2. Bb2 Bb7 3. e4 ??Bxg2 2) when you enter an uppercase letter it says illegal move Edit: and here I am trying to \"stumble\" on an innovation and be productive again. Erh... Humans reply plank 8 hours agoparentWell, winning with checkmate in just a few moves is also possible (d4 d5 - c4 dxc4 - e4 d8xd4 and after d1xd4, d4c4, c4xc7 and c7xc8 won by checkmate). I guess playing 'good' chess is not the point, the point is that you can play at all using regexp. (The 'move a2a3 and lose as not considered legal' is more serious then it not actually playing well). reply o999 9 hours agoparentprevOne good way some people learned programming is by building replacements for Python builtin/standard modules functions in Python reply mtlmtlmtlmtl 7 hours agoprevThis is truly impressive, I'm in complete awe. I do think there are some bugs based on playing a game against it. It has a tendency to give up its queen and other pieces. and it blundered mate in 1 at the end of the game when it had moves that led to mate in 2 or 3. Usually even a 2-ply engine should avoid these mistakes unless the evaluation function is completely silly, which may be the case here, I don't know. I tried looking at the code but it didn't make much sense to me, I'm not smart enough to understand this regex \"runtime\" based code. Could also be a bug of usingsomewhere, or vice versa, making it choose the worst move instead of the best one. reply PaulHoule 3 hours agoparentMy tester could trounce a 2-ply minimax engine easily. At 6 plies with the alpha-beta optimization it beat my tester for the first time (beats the average person, gets wrecked at the chess club but is trying to change that) which frustrated him greatly but after he spent a day thinking about strategy he prevailed. (Without alpha-beta the 6 ply search would have been completely unreasonable) I got the signs wrong and it managed to fool's mate itself! I struggled with testing for a while because when it makes bad moves you don't know if you correctly coded a bad chess engine or incorrectly coded a bad chess engine. Eventually I started using chess puzzles https://www.chessprogramming.org/Test-Positions which are not unit tests because they take seconds to run, but unlike a real game where there is no right move, there really is a right solution. BK.01 from https://www.chessprogramming.org/Bratko-Kopec_Test is a particularly nice one because it runs quickly! reply mtlmtlmtlmtl 42 minutes agorootparentYeah, a 2-ply engine is pretty terrible at chess. Especially with no quiescence search. I know what you're describing well, I've dabbled quite a bit in chess engine dev myself, and I'm planning to get back into it soon; I've got some interesting new ideas recently I wanna try out(once they're fleshed out enough to actually be implemented, right now they're just fanciful ideas I'm kicking around my head). Testing is a bitch though, for sure. I know that stockfish is constantly being playtasted against itself, with a new instance spawned for every pull request etc, and then given an elo rating. That way they can tell if a potential change makes it weaker or stronger. Debugging isn't easy either. Forget about stepping over code in the debugger. You have no idea whether the bug is only triggered after billions of nodes. That's a lot of stack frames to step through. And forget about debug prints too, for the most part, because putting an unconditional debug print in your search() , qsearch() or eval() will quickly lead to gigabytes and gigabytes of output... Only helpful thing I found was to use asserts. Find invariants, and in your debug version check them every node, die if they don't hold and barf out your stack frame or a core dump. If you're lucky the bug is somewhere near where the assert failed in the call tree. Even that isn't guaranteed though. reply Hackbraten 6 hours agoprevHow long does one single move take to calculate for you folks on a normal phone? On mine (running an i.MX 8M quad-core on Firefox), the first move took several minutes. reply 0xQSL 2 hours agoparentless than 5 seconds to respond to d2d4 on apple a18 pro reply sjducb 3 hours agoprevIt has an interesting response to the queens gambit accepted. Immediate queen sac d2d4 d7d5 c2c4 d5d4 e2e4 d8d4 !? d1d4 reply bennythomsson 8 hours agoprevKudoa for this, but it feels like there should be a more direct way? I mean, he first invented basically a general-purpose execution platform. That in itself is cool, but the fact that it then can execute a chess program is not actually that surprising. What about directly encoding the rules of the game plus some basic strategy? reply PaulHoule 3 hours agoparentIt's not a general-purpose execution program. It only executes bounded loops, not free loops. In chess the word \"strategy\" is used for something different than \"tactics\". My tester can decide to sacrifice a knight to get pawns the way he wants (strategy), my chess program on the other hand is better at tactics (looking ahead a few moves and setting up a fork https://en.wikipedia.org/wiki/Fork_(chess) Lasker's famous quote is \"better a bad plan than no plan at all\" but chess engines play superhuman chess with superior tactics and no strategy. There's nothing like the \"basic strategy\" in blackjack, rather you can make a very strong chess program by the exhaustive search he's using, but you have to optimize it a lot. reply eru 11 hours agoprevCompare also https://codegolf.stackexchange.com/q/3503/32575 reply lifthrasiir 11 hours agoparentThat shouldn't be really surprising, as all divisibility rules are necessarily regular because anything more complex wouldn't be human-executable \"rules\". reply eru 11 hours agorootparentHumans are able to check whether a string of parens, like ()(()()), is matched but finite state machines can't. In any case, if you know how the regex is constructed, it's not surprising. But I found it fun to actually do the construction, instead of just being theoretically aware of the possibility. reply lifthrasiir 10 hours agorootparentIs this balanced or not: ((((((((((((((((((((())))))))))))))))))))? Humans can check only so many parentheses before losing track of them, so it is still an FSM in my opinion. Also, those regexes are directly translated from the equivalent and much smaller FSM. Regexes are necessarily complex only because they have Kleene stars and nothing else; it's like representing every Boolean circuits with NAND, which is of course possible and a little fun fact but the process itself isn't exactly fun to me. reply Thiez 10 hours agorootparentHumans can't see the balance at a glance, but we can still easily check the balance of arbitrarily complex nested parenthesis because we are not limited in the same way an FSM is. We're just way way way slower than a computer. reply lifthrasiir 10 hours agorootparentYeah, I agree that humans can indeed check some non-regular languages. That doesn't however mean that humans are inherently capable for checking all non-regular languages, as they are severely limited in the working memory size. Most if not all divisibility rules are a set of least significant digits or weighted running sums because they are subject to the same constraint, so they are indeed necessarily regular. reply eru 8 hours agorootparentIt all depends on what assumptions you are making. And what model you want to use. (In some sense, as far as we can tell, the entirely visible universe can only contain a finite amount of information. But it still makes more sense most of the time to talk about real world computers as if they implement something like eg a RAM machine or lambda calculus.) Regular languages admit words of arbitrary length. Eg a regular language can tell you whether 461523850177206879302813461556288524354486376376930935555512181511680646984669431923718933249775297346246192616509695718413981019441670321942082230577379960485875768935619924872490629853314107285524330300421382702242540015152210668552218484465230532702298574921915359545891160565971424053668201732275877291369 is divisible by 7. But a human would have a harder time with this than with the paren example given by the grandfather comment. reply Thiez 8 hours agorootparentprevI'll happily admit that there is (to me) no reason to believe that humans can do things that a Turing machine could not, or that we are magically exempt from stuff like the halting theorem or have special insights in NP-complete problems. I am only arguing that we are unarguably more powerful than FSMs, and with some pen and paper (or perhaps an endless string of tape...) we are not as limited by our working memory size. But we are very slow. reply jerf 4 hours agorootparentThese sorts of power discussions require a certain amount of grace, unless you're really just super, super excited to read several paragraphs of intensely mathematical caveats, not just from the first poster, but from every poster in such a thread. There is a reasonable sense in which we can say with a straight face that humans are more powerful than finite state machines, even though in principle a human's entire life, all possible choices and all possible outcomes, could be encoded into some hypothetical state machine. If you want the really good philosophical bones, consult https://www.scottaaronson.com/papers/philos.pdf . Such a hypothetical state machine would require an exponential amount of power to construct (and given the sizes in question, we need not even specify what we mean by \"power\" since it's exponential in energy, exponential in mass, exponential in \"math elements\", it'll catch up to you no matter what you're tracking in), whereas we can say with a straight face that a human can increment and decrement a parenthesis count fairly trivially to a high degree (even if there may be error) whereas a finite state machine must give up at some point at some finite depth, and moreover, as you add depth to the state machine it rapidly expands in size whereas the parentheses counter is only tracking an int, which is growing at most log on the number of parenthesis count and thus often reasonably treated as constant for any reasonable problem size. reply tromp 10 hours agoprevThat's some impressive code wizardry! I thought the 2-ply search would make it respond to a mate-in-1 threat, but the following game demonstrates otherwise: 1. e4 e5 2. Nf3 Nf6 3. Nxe5 Nxe4 4. Qe2 Nxd2 5. Nc6+ Ne4 6. Qxe4+ Qe7 7. Nxe7 Bxe7 8. Nc3 a5 9. Nd5 a4 10. Qxe7# 9. .., Nc6/O-O/Kf8 would have avoided mate in 1. Maybe this is related to the a2-a4 bug noticed by others?! reply x0n 59 minutes agoparentApparently it's more of a 1.75ply search according to the author :) Try: c4, Qa4, Qxa5, Qc7, Qxc8# lol reply neuroelectron 11 hours agopreva2a3 gives me illegal move game over. What am I missing here? reply treetalker 11 hours agoparentSomewhat surprisingly (given the creator's regex chops) capital letters are not accepted. My guess is that your autocorrect changed the move to A2a3. Bad news if you're almost done with a game and enter a move with the wrong case. reply NooneAtAll3 11 hours agorootparentI'm on PC (firefox) and can reproduce it, no capital letters in my input reply treetalker 4 hours agorootparentHm. I don't get any errors unless I use a capital, and I get an error every time I do. reply bigiain 11 hours agoprevThis is totally what jwz needed for xmas... reply desireco42 1 hour agoprevI love the author's philosophy of doing 'entirely pointless things' for the joy of learning. This project reminds me why I got into programming in the first place - not just to solve practical problems, but to explore the weird and wonderful possibilities of code. The fact that this works at all is just mind-blowing! reply lilyball 9 hours agoprevassign_pop() is implemented a bit oddly. In particular, the second regex starts off with (%%)([^`]?#stack:) This should have just been written like the following (which in fact eq() does do, though eq() is itself missing the %%` -> %% regex): (%%)(#stack:) As it is the [^`] matches the newline, which is why the has to be marked as optional and in practice will always be skipped. reply xrd 5 hours agoprevSure, but it really should be done using PEG.This is seriously brilliant. reply Glyptodon 11 hours agoprevI'd be really helpful if you added some faded square outlines in the background. I think maybe I made an illegal move with a bishop because of misreading the diagonal. reply michaAtKE 8 hours agoprevTried the queens gambit and the computer hung the queen on move three :) reply proteal 12 hours agoprev“Now comes the clever part.” God bless our soldiers who see that regex is turing complete and choose to implement fun programs. Yall are truly a different breed :) reply jamster02 11 hours agoparentRegex isn't (necessarily) turing complete :) > Because our program just consists of a sequence of regular expressions, you can't loop at all! That, technically, means we can't actually perform Turing Complete But we can do any bounded computation by just unrolling any loops we may have. Although some (most?) implementations may be. Though by the above quote, the author didn't make use of that. reply klibertp 3 hours agorootparentThat's the point, I think: for a large number of real-world algorithms, you don't actually need a Turing Machine. There was a very well-written explanation of this on the front page[1] some time ago, concluded with: > Any algorithm that can be implemented by a Turing Machine such that its runtime is bounded by some primitive recursive function of input can also be implemented by a primitive recursive function! Also, \"The Little Typer\" book explores a language based on \"primitive recursive functions\" and shows what can be done in it and how. [1] https://matklad.github.io/2024/08/01/primitive-recursive-fun... reply teivah 6 hours agoprevThat's awesome! reply x0n 1 hour agoprevc4, Qa4, Qxa5, Qc7, Qxc8# lol reply GistNoesis 9 hours agoprevPlaying chess with strings to build datasets for text generation. I want to share this quick win. The other day I was asking myself some theoretical chess questions, and wanted to answer them programmatically and needed to build some custom chess datasets for that. I needed the chess basic routines, like getting the next legal moves, displaying the board, and some rudimentary position scores. I contemplated writing from scratch. I contemplated using some library. But instead I settled for a higher level choice : interfacing with Stockfish game engine over a text interface. There is something called UCI, which stands for Universal Chess Interface, ( https://official-stockfish.github.io/docs/stockfish-wiki/UCI... ), to use it you start a new stockfish process and write and read from the standard inputs. So instead of writing bug prone routines to check the validity of board positions, it turn the basic routines into a simple wrapper of parsing task to read and write UCI protocol to use a battle tested engine. A chess position state is simply defined as a vector representing the sequence of moves. Moves are string in long algebraic notation. This architectural decision allows for very quick (LLM-powered development) prototyping. namespace bp = boost::process; bp::ipstream is; bp::opstream os; bp::child c(\"../Stockfish/src/stockfish\", bp::std_inis); void displayBoard( const vector & moveSeq, bp::ipstream& is, bp::opstream& os ); void getLegalMoves( const vector & moveSeq, vector& legalMoves, bp::ipstream& is, bp::opstream& os ); void getTopKMoveAndScoreAtDepthFromPosition(const vector & moveSeq,int K, int D, vector >& topkmoves, bp::ipstream& is, bp::opstream& os , bool debug = false); void displayBoard( const vector & moveSeq, bp::ipstream& is, bp::opstream& os ) { os << \"position startpos moves\"; for( int i = 0 ; i < moveSeq.size() ; i++) { os << \" \" << moveSeq[i]; } os << endl; os << \"d\" << endl; os << \"isready\" << endl; string line; while (getline(is, line)) { if (!line.compare(0, 7, \"readyok\")) break; cout << line << endl; } } You get the gist... reply Beefin 5 hours agoprevanyone that can read and understand regex i have concerns for reply neuroelectron 11 hours agoprev [–] I wonder if this is inspired by LLMs which similarly do tons of repetitive processing most of which is unrelated to the final answer. reply saagarjha 10 hours agoparent [–] No, because the repetitive processing here is critical to the final result. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nicholas Carlini developed a chess engine named Regex Chess, utilizing 84,688 regular expressions to execute valid chess moves, showcasing regex's potential in unconventional applications. - The engine functions like a regular expression CPU, featuring a unique instruction set for stack operations, variable handling, and conditional execution, and supports parallel move generation. - Regex Chess employs a simplified minimax search to evaluate and score pseudo-legal moves, highlighting a creative exploration of regex capabilities, with the code accessible on GitHub for public viewing."
    ],
    "commentSummary": [
      "Nicholas Carlini developed a minimax chess engine using regular expressions, showcasing regex's capability in handling complex tasks like chess. - The project, despite having bugs like issues with pawn promotion and a-file moves, demonstrates the educational and entertaining aspects of unconventional programming challenges. - The engine's 2-ply search occasionally fails to avoid mate-in-1 threats, highlighting its limitations but also its innovative approach."
    ],
    "points": 428,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1736228771
  },
  {
    "id": 42618130,
    "title": "Zig's comptime is bonkers good",
    "originLink": "https://www.scottredig.com/blog/bonkers_comptime/",
    "originBody": "Scott Redig Zig's Comptime is Bonkers Good January 2025 Programming has obvious abilities to increase productivity through automated manipulation of data. Metaprogramming allows code to be treated as data, turning programming’s power back onto itself. Programming close to the metal has perhaps the most to gain from metaprogramming as high level concepts need to be mapped precisely to low level operations. Yet outside of functional languages I’ve always found the metaprogramming story to be a disappointment. So when I saw that Zig lists metaprogramming as a major feature, I took interest. Honestly, my first experience writing something using Zig’s comptime were pretty rough. The concepts seemed foreign, and figuring out how to achieve the outcome I wanted was difficult. Then with a perspective shift, everything clicked and suddenly I loved it. To help speed you along that path of discovery, presented below are 6 different “views” of comptime. Each view focuses on a different way you can translate existing programming knowledge into working with Zig. This is also not a full guide on all you need to know to write comptime. It’s more focused on providing a breadth of strategies, stretching your understanding in different ways that together lend a fuller picture of how to think about comptime. For clarity, all of the examples are valid Zig code, but the transformations done by the examples are only conceptual in nature. They are not how Zig is implemented. View 0: You can ignore it. It’s pretty weird to say I love a feature, then immediately declare you can ignore it. However, I’m starting with what I truly think is Zig comptime’s superpower. The third item in zig zen is Favor reading code over writing code. Being able to easily read code is important for all sorts of reasons, as it is how you build a conceptual understanding that is required to debug or make modifications to that codebase. Metaprogramming can quickly land itself into the realm of “write only code”. If you’re trying to work with macro based metaprogramming or code generation, there’s now two versions of the code: the source code and the expanded code. The extra layer of indirection makes everything from reading to debugging the code more difficult. If you determine the behavior of the program needs to change, you need to determine what the generated code needs to be, and then have determine how to get the metaprogramming to produce that code. In Zig, none of that overhead necessary. You can simply ignore that portions of the code are run at different times, conceptually mixing runtime and comptime. To demonstrate this, let’s step through two different pieces of code. The first is some normal runtime code to set a baseline for stepping through code, and the second utilizes comptime. Code pub fn main() void { const array: [3]i64 = .{1,2,3}; var sum: i64 = 0; for (array) |value| { sum += value; } std.debug.print(\"array's sum is {d}.\", .{sum}); } Variables Output Previous Reset Next Press next to step through the program, observing the changing state. This one is simple enough: sum a list of numbers. Now let’s do something weirder: sum the fields of a struct. It’s a contrived example, but demonstrates the point well. Code const MyStruct = struct { a: i64, b: i64, c: i64, }; pub fn main() void { const my_struct: MyStruct = .{ .a = 1, .b = 2, .c = 3, }; var sum: i64 = 0; inline for (comptime std.meta.fieldNames(MyStruct)) |field_name| { sum += @field(my_struct, field_name); } std.debug.print(\"struct's sum is {d}.\", .{sum}); } Variables Output Previous Reset Next The comptime example here, compared to the array sum example, is pretty much a non-event. That is the entire point! An executable of this code is as efficient as if you hand wrote a sum function for the struct’s type in C, yet the code reads like something you might write in a language with runtime reflection. While this isn’t how Zig actually works, this also isn’t some entirely theoretical exercise either: the Zig core team is working on a debugger that lets you step through code mixing comptime and runtime exactly like this example. There’s a lot of Zig which is comptime, much more than some simple type reflection, yet you don’t need to dig into any of the details to simply read code. Of course, if you want to actually write coding using comptime, you will eventually need to do more than ignore it. View 1: Oh look, generics. Generics are not a specific feature in Zig. Instead a simple subset of comptime features together handle everything you need for generic programming. This view doesn’t let you understand all of comptime, but it does provide you an entry point to complete many of the tasks you might use it for. To make a type generic, simply wrap its definition in a function which takes a type, and returns a type. Code pub fn GenericMyStruct(comptime T: type) type { return struct { a: T, b: T, c: T, fn sumFields(my_struct: GenericMyStruct(T)) T { var sum: T = 0; const fields = comptime std.meta.fieldNames(GenericMyStruct(T)); inline for (fields) |field_name| { sum += @field(my_struct, field_name); } return sum; } }; } pub fn main() void { const my_struct: GenericMyStruct(i64) = .{ .a = 1, .b = 2, .c = 3, }; std.debug.print(\"struct's sum is {d}.\", .{my_struct.sumFields()}); } Previous Reset Next Generic functions are possible as well. Code fn quadratic(comptime T: type, a: T, b: T, c: T, x: T) T { return a * x*x + b * x + c; } pub fn main() void { const a = quadratic(f32, 21.6, 3.2, -3, 0.5); const b = quadratic(i64, 1, -3, 4, 2); std.debug.print(\"Answer: {d}{d}\", .{a, b}); } Previous Reset Next It is also possible to infer the type of an argument by using the special type anytype, typically used if the type of the argument doesn’t matter to the rest of the function signature. View 2: Standard code, run at compile time. It’s a tale as old as time programming: A way to automate commands is added. Then you need variables, of course. Oh, conditionals too. Please, can I have loops? The path to a shoehorned macro language is paved with reasonable feature requests. Zig uses the same language in runtime, comptime, and even the build system. Consider the classic fizz buzz. Code fn fizzBuzz(writer: std.io.AnyWriter) !void { var i: usize = 1; while (i <= 100) : (i += 1) { if (i % 3 == 0 and i % 5 == 0) { try writer.print(\"fizzbuzz\", .{}); } else if (i % 3 == 0) { try writer.print(\"fizz\", .{}); } else if (i % 5 == 0) { try writer.print(\"buzz\", .{}); } else { try writer.print(\"{d}\", .{i}); } } } pub fn main() !void { const out_writer = std.io.getStdOut().writer().any(); try fizzBuzz(out_writer); } Previous Reset Next Simple enough. Though, one thing that I always find funny about conversations of making Fizz Buzz fast is that the standard version of the problem always runs for exactly the first 100 numbers. So given that the output is fixed, why not just precompute the answer and output that? Using the exact same fizzBuzz function, we can do just that. Code pub fn main() !void { const full_fizzbuzz = comptime init: { var cw = std.io.countingWriter(std.io.null_writer); fizzBuzz(cw.writer().any()) catch unreachable; var buffer: [cw.bytes_written]u8 = undefined; var fbs = std.io.fixedBufferStream(&buffer); fizzBuzz(fbs.writer().any()) catch unreachable; break :init buffer; }; const out_writer = std.io.getStdOut().writer().any(); try out_writer.writeAll(&full_fizzbuzz); } Previous Reset Next Here the comptime keyword indicates that the block it precedes will run during the compile. Additionally the block is labeled “init”, so that the whole block can evaluate to a value with the later break. A writer which counts how many bytes are written (but discards the actual bytes written) is used to determine the total length. An array is created with that length, written to, and set as full_fizzbuzz. Timing just the critical section, the precomputed version runs about 9 times faster. Of course, this example is so small the total execution time is dominated by other factors, but you get the idea. There are a few small differences between comptime and runtime. Only comptime has access to variables of types comptime_int, comptime_float, or type. Additionally some functions have only comptime arguments, effectively making them comptime only. Runtime is the only one to have access to system calls, or anything which would use them. If your code doesn’t use any of those features, it will work equally well in both comptime and runtime. View 3: Partial Evaluation Now we’re getting to the fun stuff. One way to view evaluation of code is to substitute inputs with their runtime value, and then repeatedly substitute the first expression into the evaluated form until only the result remains. This is common in CS theory contexts, and some functional languages. As a set up to a later example, we’ll use the array sum to get an idea of this process: Code pub fn main() void { const array: [3]i64 = .{1,2,3}; var sum: i64 = 0; for (array) |value| { sum += value; } std.debug.print(\"array's sum is {d}.\", .{sum}); } Next Operation Break the for loop into individual statements. Previous Reset Next Partial evaluation is a technique by which you can pass some, but not necessarily all, of the arguments to a function. The substitutions for expressions which use already only known values in this context can be performed. This produces a new function which only takes the still unknown arguments. Zig comptime can be viewed as a partial evaluation taking place during the compile process. Taking another look at the sum struct example, gives us: Code const MyStruct = struct { a: i64, b: i64, c: i64, fn sumFields(my_struct: MyStruct) i64 { var sum: i64 = 0; inline for (comptime std.meta.fieldNames(MyStruct)) |field_name| { sum += @field(my_struct, field_name); } return sum; } }; Next Operation inline for indicates that this for loop runs at comptime, so break the iterations into individual statements. Previous Reset Next The final function is “hand optimized”, but the work is done by Zig’s comptime. This allows the intent to be directly coded. No “remember to update the sum function when you change these fields” comment needed. Any changes to MyStruct’s fields are just handled correctly. View 4: Comptime Evaluation, runtime code emission This is nearly the same as partial evaluation. Here, there are two version of the code, input (pre-comptime) and output (post-comptime). The input code is run by the compiler. If a statement is knowable at compile time, it is simply evaluated. However if a statement requires some runtime value, the statement is added to the output code. Input Code const MyStruct = struct { a: i64, b: i64, c: i64, fn sumFields(my_struct: MyStruct) i64 { var sum: i64 = 0; inline for (comptime std.meta.fieldNames(MyStruct)) |field_name| { sum += @field(my_struct, field_name); } return sum; } }; Comptime Variables Output Code const MyStruct = struct { a: i64, b: i64, c: i64, fn sumFields(my_struct: MyStruct) i64 { } }; Previous Reset Next This view is actually the closest to how Zig’s compiler handles comptime. The primary difference is that Zig first parses the syntax of your code, and turns it into bytecode for a virtual machine. That virtual machine running is how comptime is implemented. This virtual machine will evaluate whatever it can, and emit new bytecode (which is later translated into machine code) for whatever needs to be handled at runtime. Conditionals such as if statements with runtime inputs simply emit both paths. A natural result of this is that dead code is never semantically analyzed. This can take some getting used to, as writing an invalid function doesn’t always give you a compile error until you actually try to use it. However this also makes compilation more efficient, and allows more natural looking conditional compilation, no #ifdefs here! It’s worth noting how much comptime permeates Zig’s design. All Zig code runs through this virtual machine, including functions with no obvious use of comptime. Even where you see simple type names, such as function arguments, are actually expressions which evaluate in comptime to a variable of type type. This is how the generics example above works. It also means you can use a more complicated expressions to calculate a type, where appropriate. Another consequence of this is that static analysis of Zig code is much more complicated than most statically typed languages, since significant portions of the compiler need to run to even determine all of the types. So until Zig tooling is able to catch up, editor tools such as code completion don’t always work well. View 5: Textual Code Generation I lamented the difficulty of writing code that outputs new source code at the beginning of the post. Yet it remains a powerful tool that, even in Zig, has its place in solving some problems. If this method of metaprogramming is familiar to you then moving to Zig comptime might feel like a significant downgrade. There is a familiar structure to writing code that, when run, produces code. But wait, the last example did just that, right? If you look at things in just the right way, there is an underlying equivalence between code that writes code and mixed comptime and runtime code. The following example doesn’t step through code, instead it flips between two versions. The first is an example which outputs the code, and the second is the familiar comptime example. The two versions of code are aligned with the same logic on the same line. Code pub fn writeSumFn( writer: std.io.AnyWriter, type_name: []const u8, field_names: [][]const u8, ) !void { try writer.print(\"fn sumFields(value: {s}) i64 {{\", .{type_name}); try writer.print(\"var sum: i64 = 0;\", .{}); for (field_names) |field_name| { try writer.print(\"sum += value.{s};\", .{field_name}); } try writer.print(\"return sum;\", .{}); try writer.print(\"}}\", .{}); } Toggle Notice how there are two conversions: The code which runs in the generator becomes the comptime part of the code. The code which the generator outputs becomes the runtime part of the code. Another thing I like about this example is it shows how generating code which uses type information as an input is much simpler with Zig. The example handwaves where the type name and field name information comes from. If you’re using some other form of input, such as a specification, Zig provides @embedFile which you can use to then parse like you normally would. Bringing back the generics example, there are a few more subtleties worth highlighting: Code pub fn writeMyStructOfType( writer: std.io.AnyWriter, T: []const u8, ) !void { try writer.print(\"const MyStruct_{s} = struct {{\", .{T}); try writer.print(\"a: {s},\", .{T}); try writer.print(\"b: {s},\", .{T}); try writer.print(\"c: {s},\", .{T}); try writer.print(\"fn sumFields(value: MyStruct_{s}) {s} {{\", .{T,T}); try writer.print(\"var sum: {s} = 0;\", .{T}); const fields = [_][]const u8{ \"a\", \"b\", \"c\" }; for (fields) |field_name| { try writer.print(\"sum += value.{s};\", .{field_name}); } try writer.print(\"return sum;\", .{}); try writer.print(\"}}\", .{}); try writer.print(\"}};\", .{}); } Toggle The fields retain the conversion above, but mix the two in a single line. The field’s type expression is done by the generator/at comptime, while the field itself ends up as a definition used by the runtime code. References to the name of the type are more direct with comptime, able to use the function directly instead of having to concat text into a name that has be to consistent across uses. There is an exception to this view. You can create types where the names of the fields are determined at comptime, however doing so involves calling a builtin function with a specification containing a list of field definitions. As a result you can’t define declarations, such as methods, on these types. In practice this doesn’t limit the expressiveness of your code, but it does limit what kinds of API you can expose to other code. Relevant to this section are textual macros such as those in C. Most of the sane things you can do can be done in comptime, though they rarely take a form that looks similar. However, you can’t do everything that text macros allow. For example, you can’t decide that you dislike a Zig keyword and have a macro substitute your own. I think this is the right call, even if it’s a rough transition for those used to that ability. Besides, Zig has half a century of programmers figuring out what is right, so its choices are far more sane. Conclusion When reading Zig code to understand the end behavior, taking comptime into consideration isn’t necessary. When writing comptime code, I usually think about it in one of the forms of partial evaluation. However, if you know how you’d solve a problem using a different methodology of metaprogramming, it’s very likely you’ll be able to translate it into comptime. Realizing the textual code generation conversion exists is why I’m all in on Zig’s style of comptime metaprogramming. On one hand, textual code generation is maximally powerful, on the other hand, the ability to ignore comptime while reading and debugging is maximally simple. This is why, as I titled the post, Zig’s comptime is bonkers good. Further Reading Zig is not a one trick pony built upon comptime. You can learn more about Zig at the official website. I used the same example multiple times in this post to simplify showing the different conversions that take place. The downside of this is despite talking a lot about comptime, I haven’t actually shown much of it. The language reference goes over the specific features of comptime. If you want to see more examples, I recommend just reading some of Zig’s standard library. A few links for the curious: The formatting function used by std.debug.print in the examples is a powerful generic function. Lots of languages parse their format strings at runtime, and possibly add some special validators to the string format to catch errors early. In Zig, the format string is parsed at comptime, creating efficient output code while also performing all validation at compile time. ArrayList is a fairly simple but fully featured generic container. Zig main functions can have one of several different return types. In typical Zig fashion, this isn’t some magical implementation in the compiler, but just some typical comptime code. If you wish to reach me about this post to provide a comment or correction, please email me at blogcomments@scottredig.com Subscribe to the RSS feed to be notified of my next post.",
    "commentLink": "https://news.ycombinator.com/item?id=42618130",
    "commentBody": "Zig's comptime is bonkers good (scottredig.com)353 points by todsacerdoti 17 hours agohidepastfavorite182 comments noelwelsh 11 hours agoIt would be nice to have a more indepth discussion of the issues that have been found with compile-time programming, rather than uncritical acclaim. Staged programming is not new, and people have run into many issues and design tradeoffs in that time. (E.g. the same stuff has been done in Lisps for decades, though most Lisps don't have a type system, which makes things a bit more complicated.) Some of the issues that come to mind: * Implementing generics in this way breaks parametricity. Simply put, parametricity means being able to reason about functions just from their type signature. You can't do this when the function can do arbitrary computation based on the concrete type a generic type is instantiated with. * It's not clear to me how Zig handles recursive generic types. Generally, type systems are lazy to allow recursion. So I can write something like type Example = Something[Example] (Yes, this is useful.) * Type checking and compile-time computation can interact in interesting ways. Does type checking take place before compile-time code runs, after it runs, or can they be interleaved? Different choices give different trade-offs. It's not clear to me what Zig does and hence what tradeoffs it makes. * The article suggests that compile-time code can generate code (not just values) but doesn't discuss hygiene. There is a good discussion of some issues here: https://typesanitizer.com/blog/zig-generics.html reply MatthiasPortzel 4 hours agoparentI'm a pretty big fan of Zig--I've been following it and writing it on-and-off for a couple of years. I think that comptime has a couple of use-cases where it is very cool. Generics, initializing complex data-structures at compile-time, and target-specific code-generation are the big three where comptime shines. However, in other situations seeing \"comptime\" in Zig code has makes me go \"oh no\" because, like Lisp macros, it's very easy to use comptime to avoid a problem that doesn't exist or wouldn't exist if you structured other parts of your code better. For example, the OP's example of iterating the fields of a struct to sum the values is unfortunately characteristic of how people use comptime in the wild--when they would often be better served by using a data-structure that is actually iterable (e.g. std.enums.EnumArray). reply PaulHoule 30 minutes agorootparentLately I read Graham's On Lisp and first felt it was one the greatest programming books I'd ever read and felt it was so close to perfect that the little things like he made me look \"nconc\" up in the manual (so far he'd introduced everything he needed) made me want to go through and do just a little editing. And his explanation of how continuations work isn't very clear to me which is a problem because I can't find a better one online (the only way I think I'll understand continuations is if I write the explanation I want to read) Then I start thinking things like: \"if he was using Clojure he wouldn't be having the problems with nconc that he talks about\" and \"I can work most of the examples in Python because the magic is mostly in functions, not in the macros\" and \"I'm disappointed that he doesn't do anything that really transform the tree\" Lately I've been thinking about the gradient from the various tricks such as internal DSLs and simple forms of metaprogramming which are weak beer compared to what you can do if you know how compilers work. reply bunderbunder 1 hour agorootparentprevThis feels like it's it's a constant problem with all more advanced language features. I've had the same reaction to uses of lisp macros, C-style macros, Java compiler extensions, Ruby's method_missing, Python monkey patching, JavaScript prototype inheritance, monads, inheritance... Maybe the real WTF is the friends we made along the way.Implementing generics in this way breaks parametricity. Simply put, parametricity means being able to reason about functions just from their type signature. You can't do this when the function can do arbitrary computation based on the concrete type a generic type is instantiated with. Do you mean reasoning about a function in the sense of just understanding what a functions does (or can do), i.e. in the view of the practical programmer, or reasoning about the function in a typed theoretical system (e.g. typed lambda calculus or maybe even more exotic)? Or maybe a bit of both? There is certainly a concern from the theoretical viewpoint but how important is that for a practical programming language? For example, I believe C++ template programming also breaks \"parametricity\" by supporting template specialisation. While there are many mundane issues with C++ templates, breaking parametricity is not a very big deal in practice. In contrast, it enables optimisations that are not otherwise possible (for templates). Consider for example std::vector: implementations can be made that actually store a single bit per vector element (instead of how a bool normally is represented using an int or char). Maybe this is even required by the standard, I don't recall. My point is that in makes sense for C++ to allow this, I think. reply noelwelsh 8 hours agorootparentIn terms of implementation, you can view parametricity as meaning that within the body of a function with a generic type, the only operations that can be applied to values of that type are also arguments to that function. This means you cannot write fn sort(elts: Vec): Vec because you cannot compare values of type A within the implementation of sort with this definition. You can write fn sort(elts: Vec, lessThan: (A, A) -> Bool): Vec because a comparison function is now a parameter to sort. This helps both the programmer and the compiler. The practical upshot is that functions are modular: they specify everything they require. It follows from this that if you can compile a call to a function there is a subset of errors that cannot occur. In a language without parametricity, functions can work with only a subset of possible calls. If we take the first definition of sort, it means a call to sort could fail at compile-time, or worse, at run-time, because the body of the function doesn't have a case that knows how to compare elements of that particular type. This leads to a language that is full of special cases and arbitrary decisions. Javascript / Typescript is an example of a language without parametricity. sort in Javascript has what are, to me, insane semantics: converting values to strings and comparing them lexicographically. (See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Refe...) This in turn can lead to amazing bugs, which are only prevented by the programmer remembering to do the right thing. Remembering to do the right thing is fine in the small but it doesn't scale. Breaking parametricity definitely has uses. The question becomes one about the tradeoffs one makes. That's why I'd rather have a discussion about those tradeoffs than just \"constime good\" or \"parametricity good\". Better yet are neat ideas that capture the good parts of both. (E.g. type classes / implicit parameters reduce the notational overhead of calling functions with constrained generic types, but this bring their own tradeoffs around modularity and coherence.) reply James_K 36 minutes agorootparentFunctions can crash anyway. I don't see how what you describe is different from a function on integers that errors on inputs that are too big. The programmer has to actively choose to make function break parametricity, and they can equally chose not to do that. reply dmvdoug 3 hours agorootparentprevDo you have a blog or other site where you post your writing? Your explanations are quite good and easy to follow for someone like me, an interested/curious onlooker. reply noelwelsh 1 hour agorootparentThanks! I appreciate that. A few things: - https://scalawithcats.com/ is a book I'm writing. There is an associated newsletter to which I post blog articles and the like. - https://noelwelsh.com/ is my personal site, which hosts my blog. reply norir 3 hours agorootparentprevFair point about parametricity. A language could in the macro expansion do the equivalent of a scala implicit lookup for a sorting function for the type and return an error at macro expansion time if it can't find one. That avoids the doing the right thing requires discipline problem but I agree it is still less clear from the type signature alone what the type requirements are. reply nimish 1 hour agorootparentprevThis is _also_ doable with the ability to constrain generics. sort where A implements Comparable Simpler explanation IMO. reply tines 50 minutes agorootparentNot really an \"also\", \"implements\" is just syntax sugar for what the GP is saying. reply SkiFire13 10 hours agorootparentprev> For example, I believe C++ template programming also breaks \"parametricity\" by supporting template specialisation. C++ breaks parametricity even with normal templates, since you can e.g. call a method that exists/is valid only on some instantiations of the template. The issue is that the compiler can't help you check whether your template type checks or not, you will only figure out when you instantiate it with a concrete type. Things get worse when you call a templated function from within another templated function, since the error can then be arbitrarily levels deep. > My point is that in makes sense for C++ to allow this, I think. Whether it makes sense or not it's a big pain point and some are trying to move away from it (see e.g. Carbon's approach to generics) reply marhee 9 hours agorootparent> C++ breaks parametricity even with normal templates I might be wrong here, but as I understand it \"parametricity\" means loosely that all instantiations use the same function body. To quote wikipedia: \"parametricity is an abstract uniformity property enjoyed by parametrically polymorphic functions, which captures the intuition that all instances of a polymorphic function act the same way\" In this view, C++ does not break parametricity with \"normal\" (i.e. non-specialised) templates. Of course, C++ does not type check a template body against its parameters (unless concepts/trairs are used), leading to the problems you describe, but it's a different thing as far as I understand. reply lmm 5 hours agorootparentTo be parametric it needs to be the same body semantically, not just textually. Particularly in C++ with its heavy operator overloading and limited safety, you can very easily write a template whose body will do the right thing for some types and be undefined behaviour for others (e.g. if your template has comparisons in it and then you instantiate it with a pointer or something). reply jcelerier 5 hours agorootparentprevHm, wouldn't any use of if constexpr break that definition? e.g. template void f() { if constexpr (is_int) { return 0; } else ... reply deredede 5 hours agorootparentprevParametricity is about behavior, not code. A function parametric in a variable should bevave identically for all values of the variable. If one instance of a C++ template fails to compile and another instance of the same template does compile it is a stretch to say they behave identically, even though they use the same code. reply nialv7 9 hours agorootparentprevone thing you can reason about a function is: does it exist at all? if you don't have parametricity, you can't even be sure about that. in Rust, as long as your type satisfies a generic function's bounds, you can be sure instantiating that function with this type will compile; in C++ you don't have that luxury. reply Quekid5 10 hours agorootparentprev> Consider for example std::vector: implementations can be made that actually store a single bit per vector element (instead of how a bool normally is represented using an int or char). Your example is considered a misfeature and demonstrates why breaking parametricity is a problem: the specialized vector is not a standard STL container even though vector is. That's at best confusing -- and can leads to very confusing problems in generic code. (In this specific case, C++11's \"auto\" and AAA lessens some of the issues, but even then it can cause hard-to-diagnose performance problems even when the code compiles) See https://stackoverflow.com/a/17797560 for more details. reply HelloNurse 9 hours agorootparentThe C++ vector specialization is bad because breaking many important implicit contracts about taking the address of vector elements makes it practically unusable if a normal vector is expected, but it isn't specialized incorrectly in a formally meaningful sense: all errors are outside the class (unsatisfied expectations from client code) and implicit (particularly for C++ as it was at the time). reply Quekid5 8 hours agorootparentYou're not wrong, but is at the very least weird that a specialization doesn't conform to the concept that the general template does. Something which proper parametricity would have avoided -- if it were available. (The Hysterical Raisins are understandable, esp. given that it wasn't even possible to specify Concepts in C++ until 2020...) reply HelloNurse 8 hours agorootparentThe point is exactly that the \"concept\" of what the template should do is informal and a careful, detailed specification in a far more expressive language than vintage C++ would be needed to elicit good compilation errors from something like vector. Proper parametricity is only a starting point: types that specify alignment, equality and lifetimes would be needed to make it useful. reply beached_whale 9 hours agorootparentprevVector bool may not have to store a range of space optimized bool values but the interface is still different enough and guarantees different enough that is is largely thought of as a mistake. For one the const reference type is bool and not bool const &. Plus other members like flip… mostly the issue is in generic code expecting a normal vector reply jmull 6 hours agoparentprev> being able to reason about functions just from their type signature. This has nothing to do with compile-time execution, though. You can reason about a function from its declaration if it has a clear logical purpose, is well named, and has well named parameters. You can consider any part of a parameter the programmer can specify as part of the name, including label, type name, etc. > There is a good discussion of some issues here: https://typesanitizer.com/blog/zig-generics.html That's actually not a great article. While I agree with the conclusion stated in the title, it's a kind of \"debate team\" approach to argumentation which tries to win points rather than make meaningful arguments. The better way to frame the debate is flexibility vs complexity. A fixed function generics system in a language is simpler (if well designed) than a programmable one, but less flexible. The more flexibility you give a generics system, the more complex it becomes, and the closer it becomes to a programming language in its own right. The nice thing about zig's approach is that the meta-programming language is practically the same thing as the regular programming language (which, itself, is a simple language). That minimizes the incremental complexity cost. It does introduce an extra complexity though: it's harder for the programmer to keep straight what code is executing at compile time vs runtime because the code is interleaved and the context clues are minimal. I wonder if a \"comptime shader\" could be added to the language server/editor plugin that puts a different background color on comptime code. reply jasode 6 hours agorootparent>You can _reason_ about a function from its declaration if it has a clear logical purpose, is well named, and has well named parameters. I think \"reason\" in gp's context is \"compile-time reasoning\" as in the compiler's deterministic algorithm to parse the code and assign properties etc. This has downstream effects with generating compiler errors, etc. It's not about the human programmer's ability to reason so any \"improved naming\" of function names or parameters still won't help the compiler out because it's still just an arbitrary \"symbol\" in the eyes of the parser. reply jmull 6 hours agorootparentDownstream effects with generating compiler errors is still about the human programmer's ability to reason about the code, and error messages can only reference the identifier names provided. The compiler doesn't do anything you, the programmer, don't tell it to do. You tell it what to do by writing code using a certain syntax, connecting identifiers, keywords, and symbols. That's it. If the meaning isn't in the identifiers you provide and how you connect them together with keywords and symbols, it isn't in there at all. The compiler doesn't care what identifier names you use, but that's true whether the identifier is for a parameter label, type name, function name or any other kind of name. The programmer gives those meaning to human readers by choosing meaningful names. Anyway, zig's compile errors seem OK to me so far. Actually, the zig comptime programmer can do better than a non-programmable compiler when it comes to error messages. You can detect arbitrary logical errors and provide your own compiler error messages. reply noelwelsh 6 hours agorootparentprevI elaborated on parametricity in this comment: https://news.ycombinator.com/item?id=42621239 There are many ways one can reason about functions, and I think all of us use multiple methods. Parametricity provides one way to do so. One nice feature is that its supported by the programming language, unlike, say, names. reply jmull 5 hours agorootparentI saw that. But I don't think it has bearing on zig comptime. zig generates a compile error when you try to pass a non-conforming type to a generic function that places conditions/restrictions on that type (such as by calling a certain predicate on instances of that type). It's probably important to note that parametricity is a property of specific solution spaces, and not really in the ultimate problem domain (writing correct and reliable software for specific contexts), so isn't necessarily meaningful here. reply lmm 5 hours agorootparent> zig generates a compile error when you try to pass a non-conforming type to a generic function that places conditions/restrictions on that type (such as by calling a certain predicate on instances of that type). Sure, but only after it's fully expanded, which is much harder to debug. And if a generic function doesn't fail to compile but rather silently behaves differently (e.g. if it calls a function that behaves unexpectedly, but still exists, on the type in question) then you don't get an error at all. > parametricity is a property of specific solution spaces, and not really in the ultimate problem domain (writing correct and reliable software for specific contexts) Nonsense. Without parametricity your software is not compositional and it becomes impossible to write correct software to solve complex problems. reply jmull 4 hours agorootparent> Sure, but only after it's fully expanded, Code goes into the compiler. Either compiled code or errors come out. There's no partial expansion step to cause confusion. You're probably referring to something about the flexibility zig's comptime allows, but it's important to note a zig programmer can be as picky as they want about what types a generic function will accept. People are really just talking about what the syntax for expression type restrictions is. > Without parametricity your software is not compositional and it becomes impossible to write correct software to solve complex problems. You can hold that opinion, but it's not a fact. The overall question isn't binary. It's one of balancing complexity and flexibility. A fixed system for specifying type restrictions is simpler and provides fewer opportunities for mistakes (assuming it's well designed), and may have parametricity. However, the lack of flexibility can just push the complexity elsewhere, e.g., leading to convoluted usage patterns, which could lead to more mistakes. A programmable system for specifying type restrictions offers more flexibility at the cost of more up-front complexity, but in a well-designed system the flexibility could lead to less overall complexity, and fewer mistakes. A nice thing about zig's approach is that the generics metaprogramming language is pretty much the same as the regular language, which mitigates the increase in complexity. I actually think it should be possible to create some kind of generics system that could credibly be said to be programmable and have parametricity, though I don't think there's any point to doing so. reply ScottRedig 10 hours agoparentprevHi, article author here. I was motivated to write this post after having trouble articulating some of its points while at a meetup, so that's why the goal of this post was focused on explaining things, and not being critical. So at least address your points here: * I do agree this is a direct trade-off with Zig style comptime, versus more statically defined function signatures. I don't think this affects all code, only code which does such reasoning with types, so it's a trade-off between reasoning and expressivity that you can make depending on your needs. On the other hand, per the post's view 0, I have found that just going in and reading the source code easily answers the questions I have when the type signature doesn't. I don't think I've ever been confused about how to use something for more than the time it takes to read a few dozen lines of code. * Your specific example for recursive generic types poses a problem because a name being used in the declaration causes a \"dependency loop detected\" error. There are ways around this. The generics example in the post for example references itself. If you had a concrete example showing a case where this does something, I could perhaps show you the zig code that does it. * Type checking happens during comptime. Eg, this code: pub fn main() void { @compileLog(\"Hi\"); const a: u32 = \"42\"; _ = a; @compileLog(\"Bye\"); } Gives this error: when_typecheck.zig:3:17: error: expected type 'u32', found '*const [2:0]u8' const a: u32 = \"42\"; ^~~~ Compile Log Output: @as(*const [2:0]u8, \"Hi\") So the first @compileLog statement was run by comptime, but then the type check error stopped it from continuing to the second @compileLog statement. If you dig into the Zig issues, there are some subtle ways the type checking between comptime and runtime can cause problems. However it takes some pretty esoteric code to hit them, and they're easily resolved. Also, they're well known by the core team and I expect them to be addressed before 1.0. * I'm not sure what you mean by hygiene, can you elaborate? reply mananaysiempre 6 hours agorootparent“Hygiene” in the context of macro systems refers to the user’s code and the macro’s inserted code being unable to capture each other’s variables (either at all or without explicit action on part of the macro author). If, say, you’re writing a macro and your generated code declares a variable called ‘x’ for its own purposes, you most probably don’t want that variable to interfere with a chunk of user’s code you received that uses an ‘x’ from an enclosing scope, even if naïvely the user’s ‘x’ is shadowed by the macro’s ‘x’ at the insertion point of the chunk. It’s possible but tedious and error-prone to avoid this problem by hand by generating unique identifier names for all macro-defined runtime variables (this usually goes by the Lisp name GENSYM). But what you actually want, arguably, is an extended notion of lexical scope where it also applies to the macro’s text and macro user’s program as written instead of the macroexpanded output, so the macro’s and user’s variables can’t interfere with each other simply because they appear in completely different places of the program—again, as written, not as macroexpanded. That’s possible to implement, and many Scheme implementations do it for example, but it’s tricky. And it becomes less clear-cut what this even means when the macro is allowed to peer into the user’s code and change pieces inside. (Sorry for the lack of examples; I don’t know enough to write one in Zig, and I’m not sure giving one in Scheme would be helpful.) reply throwawaymaths 4 hours agorootparentzig comptime is not a macro system and you can't really generate code in a way that makes hygeine a thing to worry about (there is no ast manipulation, you can't \"create variables\"). the only sort of codegen you can do is via explicit conditionals (switch, if) or loops conditioned on compile time accessible values. thats still powerful, you could probably build a compile time ABNF parser, for example. reply gotoeleven 2 hours agorootparentSurely there's a way to generate code by manipulating an AST structure? Is there some reason this can't be done in Zig or is it just that no one has bothered? Doing it this way is more verbose but sidesteps all hygiene issues. reply Cloudef 1 hour agorootparentGenerating code during comptime is explicitly forbidden by the author. You can still generate code during build.zig of course. reply Validark 5 hours agorootparentprevZig disallows ALL shadowing (basically variable name collisions where in the absence of the second variable declaration the first declaration would be reachable by the same identifier name). Generating a text file via a writer with the intent to compile it as source code is no worse in Zig than it is in any other language out there. If that's what you want to do with your life, go ahead. reply anonymoushn 10 hours agoparentprev> type Example = Something[Example] You can't use the binding early like this, but inside of the type definition you can use the @This() builtin to get a value that's the type you're in, and you can presumably do whatever you like with it. The type system barely does anything, so it's not very interesting when type checking runs. comptime code is type checked and executed. Normal code is typechecked and not executed. comptime is not a macro system. It doesn't have the ability to be unhygienic. It can cleverly monomorphize code, or it can unroll code, or it can omit code, but I don't think it can generate code. reply shakna 10 hours agorootparentUntil version 0.12.0 (April 2024), you could make arbitrary syscalls, allowing you to generate code at comptime, and promote vars between comptime and runtime. [0] Before then, you could do some rather funky things with pointers and memory, and was very much not hygienic. [0] https://ziglang.org/download/0.12.0/release-notes.html#Compt... reply miki123211 9 hours agoparentprevAnd I would add: * Documentation. In a sufficiently-powerful comptime system, you can write a function that takes in a path to a .proto file and returns the types defined in that file. How should this function be documented? What happens when you click a reference to such a generated type in the documentation viewer? * IDE autocompletions, go to definition, type hinting etc. A similar problem, especially when you're working on some half-written code and actual compilation isn't possible yet. reply adonovan 6 hours agorootparentAlso: security. Does this feature imply that merely building someone else’s program executes their code on your machine? reply mpalmer 6 hours agorootparentSyscalls aren't available to comptime code reply actionfromafar 2 hours agorootparentAlso see e.g. https://github.com/rust-lang/rust-analyzer/issues/14375 reply eddd-ddde 2 hours agoparentprevC++ has so many complexities like SFINAE that I wouldn't say you are \"able to reason about functions just from their type signature\". reply hansvm 2 hours agoparentprev> parametricity That feels like the wrong word for the thing you're describing. Linguistic arguments aside, yes, you're absolutely right. In Zig though, that issue is completely orthogonal to generics. The first implementation `foo` is the \"only\" option available for \"truly arbitrary\" `T` if you don't magic up some extra information from somewhere. The second implementation `bar` uses an extra language feature unrelated to generics to return a different valid value (it's valid so long as the result of `bar(T, x)` is never accessed). The third option `baz` works on any type with non-zero width and just clobbers some data for fun (you could golf it some more, but I think the 5-line implementation makes it easier to read for non-Zig programmers). Notice that we haven't performed a computation with `T` and were still able to do things that particular definition of parametricity would not approve of. fn foo(T: type, x: T) T { return x; } fn bar(T: type, x: T) T { _ = x; return undefined; } fn baz(T: type, x: T) T { var result: T = x; const result_ptr: *T = &result; const dangerous_shenanigans_ptr: *u8 = @ptrCast(result_ptr); dangerous_shenanigans_ptr.* = 42; return result; } Zig does give up that particular property (being able to rely on just a type signature to understand what's going on). Its model is closer to \"compile-time duck-typing.\" The constraints on `T` aren't an explicitly enumerated list of constraints; they're an in vivo set of properties the code using `T` actually requires. That fact is extremely annoying from time to time (e.g., for one or two major releases the reference Reader/Writer didn't include the full set of methods, but all functions using readers and writers just took in an `anytype`, so implementers either had to read a lot of source or play a game of whack-a-mole with the compiler errors to find the true interface), but for most code it's really not hard to handle. E.g., if you've seen the `Iterator` pattern once, the following isn't all that hard to understand. Your constraints on `It` are that it tell you what the return type is, that return type ought to be some sort of non-comptime numeric, and it should have a `fn next(self: *It) ?T` method whose return values after the first `null` you're allowed to ignore. If you violate any of those constraints (except, perhaps, the last one -- maybe your iterator chooses to return null and then a few more values) then the code will fail at comptime. If you're afraid of excessive compiler error message lengths, you can use `@compileError()` to create a friendlier message documenting your constraints. It's a different pattern from what you're describing, but it's absolutely not hard to use correctly. fn sum(It: type, it: *It) It.T { var total: T = 0; while (it.next()) |item| total += item; return total; } > recursive generics A decent mental model (most of which follows from \"view 4\" in TFA, where the runtime code is the residue after the interpreter resolves everything it can at comptime) is treating types as immutable and treating comptime evaluation like an interpreted language. With that view, `type Example = Something[Example]` can't work because `Example` must be fully defined before you can pass it into `Something`. The laziness you see in ordinary non-generic type instantiations doesn't cross function boundaries. I'm not sure if there's a feature request for that (nothing obvious is standing out), but I'd be a fan @AndyKelley if you're interested. In terms of that causing problems IRL, it's only been annoying a few times in the last few years for me. The most recent one involved some comptime parser combinators, and there was a recursive message structure I wanted to handle. I worked around it by creating a concrete `FooParser` type with its associated manually implemented `parse` function (which itself was able to mostly call into rather than re-implement other parsers) instead of building up `FooParser` using combinators, so that the normal type instantiation laziness would work without issues. > when does type checking run Type inference is simplistic enough that this is almost a non-issue in Zig, aside from the normal tradeoffs from limited type inference (last I checked, they plan to keep it that way because it's not very important to them, it actively hinders the goal of being able to understand code by looking at a local snapshot, and that sort of complexity and constraint might keep the project from hitting more important goals like incremental compilation and binary editing). They are interleaved though (at least in the observable behavior, if you treat comptime execution as an interpreter). reply MathMonkeyMan 7 hours agoparentprevScheme has a \"hygienic\" macro system that allows you to do arbitrary computation and code alteration at compile time. The language doesn't see wide adoption in industry, so maybe its most important lessons have yet to be learned, but one problem with meta-programming is that it turns part of your program into a compiler. This happens to an extent in every language. When you're writing a library, you're solving the problem \"I want users to be able to write THIS and have it be the same as if they had written THAT.\" A compiler. Meta-programming facilities just expand how different THIS and THAT can be. Understanding compilers is hard. So, that's at least one potential issue with compile-time programming. reply Validark 5 hours agorootparentBy your definition practically any code is a compiler unless you literally typed out every individual thing the machine should do, one by one. \"Understanding compilers is hard.\" I think this is just unnecessarily pessimistic or embracing incompetence as the norm. It's really not hard to understand the concept of an \"inline\" loop. And so what if I do write a compiler so that when I do `print(\"%d\", x)` it just gives me a piece of code that converts `x` to a \"digit\" number and doesn't include float handling? That's not hard to understand. reply flohofwoe 11 hours agoparentprevI think most of those points one only stumbles over after a few thousand lines of Zig and going really deep into the comptime features. And some features in your list are of questionable value IMHO (e.g. the \"reasoning over a function type signature\" - Rust could be a much more ergonomic language if the compiler wouldn't have to rely on function signatures alone but instead could peek into called function bodies). There are definitely some tradeoffs in Zig's comptime system, but I think the more important point is that nothing about it is surprising when working with it, it's only when coming from languages like Rust or C++ where Zig's comptime, generics and reflection might look 'weird'. reply eptcyka 10 hours agorootparent> Rust could be a much more ergonomic language if the compiler wouldn't have to rely on function signatures alone but instead could peek into called function bodies This path leads to unbounded runtime for the type checker/borrow checker. We’re not happy about build times as is. reply littlestymaar 7 hours agorootparentAnd also lead to subtle errors for users of crates. Semver is hard enough to do when the compiler only deals with signatures, but if the body of the functions now contain invariants that can be relied on by function callers then it becomes intractable. reply lmm 5 hours agorootparentprev> most of those points one only stumbles over after a few thousand lines of Zig and going really deep into the comptime features. > nothing about it is surprising when working with it I think there's a contradiction here - when you get deep into using this kind of feature in a complex way is precisely when you most need it to behave consistently, and tends to be where this kind of ad-hoc approach breaks down. reply throwawaymaths 4 hours agorootparentif youve never gone deep into zig comptime... really nothing is surprising, except possibly when you can't do things and usually after a bit of thinking about it you understand why you can't. reply withoutboats3 9 hours agoparentprev100%. So tiring that the discourse around this is based on 15 minute demos and not actual understandings of the trade offs. Varun Gandhi's post that you link to is great. Based on my experience with Rust, a lot of what people want to do with its \"constant generics\" probably would be easier to do with a feature like comptime. Letting you do math on constant generics while maintaining parametricity is hard to implement, and when all you really want is \"a trait for a hash function with an output size of N,\" probably giving up parametricity for that purpose and generating the trait from N as an earlier codegen step is fine for you, but Rust's macros are too flexible and annoying for doing it that way. But as soon as you replace parametric polymorphism with a naive code generation feature, you're in for a world of hurt. reply medo-bear 10 hours agoparentprev> Lisps don't have a type system, which makes things a bit more complicated SBCL, which is a very popular Common Lisp implementation, is indeed strongly typed. Coalton, which is an addon, is even statically typed reply gjm11 3 hours agorootparentmedo-bear, you might want to know that you appear to be shadowbanned -- all your comments for the last ~10 days are dead. (I have some plausible guesses at what provoked this, though I have to say that I didn't see anything that looks to me like sufficient justification.) (I \"vouched\" for your comment to which this is a reply, and that seems to have been sufficient to un-dead it. Unless the system's set up so that vouching for a shadowbanned comment un-deads it only for the person who does the vouching, I guess...) reply medo-bear 3 hours agorootparentThanks reply WalterBright 50 minutes agoprevD had it 17 years ago! D features steadily move into other languages. > Here the comptime keyword indicates that the block it precedes will run during the compile. D doesn't use a keyword to trigger it. What triggers it is being a \"const expression\". Naturally, const expressions must be evaluatable at compile time. For example: int sum(int a, int b) => a + b; void test() { int s = sum(3, 4); // runs at run time enum e = sum(3, 4); // runs at compile time } By avoiding use of non-constant globals, I/O and calling system functions like malloc(), quite a large percentage of functions can be run at compile time without any changes. Even memory can be allocated with it (using D's automatic memory management). reply WalterBright 21 minutes agoparentHere's one of my favorite uses for it. I used to write a separate program to generate static tables. With compile time function execution, this was no longer necessary. Here's an example: __gshared uint[256] tytab = tytab_init; extern (D) private enum tytab_init = () { uint[256] tab; foreach (i; TXptr) { tab[i] |= TYFLptr; } foreach (i; TXptr_nflat) { tab[i] |= TYFLptr; } foreach (i; TXreal) { tab[i] |= TYFLreal; } /* more lines removed for brevity */ return tab; } (); The initializer for the array `tytab` is returned by a lambda that computes the array and then returns it. A link to the full glory of it: https://github.com/dlang/dmd/blob/master/compiler/src/dmd/ba... Another common use for CTFE is to use it to create a DSL. reply skocznymroczny 3 hours agoprevZig looks interesting, I just wish it had operator overloading. I don't really buy most of the arguments against operator overloading. A common argument is that with operator overloading you don't know what actually happens under the hood. Which doesn't work, because you might as well create a function named \"add\" which does multiplication. Another argument is iostreams in C++ or boost::spirit as examples of operator overloading abuse. But I haven't really seen that happen in other languages that have operator overloading, it seems to be C++ specific. reply hiccuphippo 3 hours agoparentYou don't know the amout of magic that goes behind the scenes in python and php with the __ functions. I think zig's approach is refreshing. Being able to follow the code trumps the seconds wasted typing the extra code. reply melodyogonna 43 minutes agorootparentI don't know about PHP, what amount of magic goes in behind Python's dunder methods? You can open it and see reply akkad33 30 minutes agorootparentThere are many gotchas to Python dunder methods. An example is there is a bunch of functions that can be called when you do something like 's.d' where s is an object. Does it call \"getattr\" on the object, getattr on the class or get a property, or execute a descriptor? It is very hard to tell unless you're an expert reply magicalhippo 2 hours agorootparentprevDepends on domain I think. In some cases it can be very beneficial to keep the code close to the source, say math equations, to ensure they've been correctly implemented. In this case the operators should be unsurprising, so they do what one would expect based on the source domain. Multiplying a vector and a scalar for example should return the scaled vector, but one should most likely not implement multiplication between vectors as that would likely cause confusion. reply ptrwis 2 hours agoparentprevMaybe such operators for basic linear algebra (for arrays of numbers) should be just built into the language instead of overloading operations. I'm not sure if such a proposal doesn't already exists. reply spiffyk 1 hour agorootparentThere is a specialized `@Vector` builtin for SIMD operations like this. reply bigpingo 1 hour agoparentprevYeah I never got the aversion to operator overloading either. \"+ can do anything!\" As you said, so can plus(). \"Hidden function calls?\" Have they never programmed a soft float or microcontroller without a div instruction? Function calls for every floating point op. reply elcritch 10 hours agoprevAh ‘fieldNames’, looks very similar to Nim’s ‘fieldPairs’. It’s an incredibly handy construct! It makes doing efficient serialization a breeze. I recently implemented a compile time check for thread safety checks on types using ‘fieldPairs’ in about 20 lines. This needs to become a standard feature of programming languages IMHO. It’s actually one of the biggest things I find lacking in Rust which is limited to non-typed macros (last I tried). It’s so limiting not to have it. You just have to hope serde is implemented on the structs in a crate. You can’t even make your own structs with the same fields in Rust programmatically. reply ptrwis 2 hours agoparentWith comp-time reflection you can build frameworks like ORMs or web frameworks. The only trade-off is that you have to include such a library in the form of source code. reply drogus 4 hours agoparentprevAt some point there was a discussion about compile time reflection, which I guess could include functionality like that, but I think the topic died along with some kind of drama around it. Quite a bummer, cause things like serde would have been so much easier to imeplement with compile time reflection reply koe123 11 hours agoprevAnother interesting pattern is the ability to generate structs at compile time. Ive ran experiments where a neural net is implemented by creating a json file from pytorch, reading it in using @embedFile, and generating the subsequent a struct with a specific “run” method. This in theory allows the compiler to optimize the neural network directly (I havent proven a great benefit from this though). Also the whole network lived on the stack, which is means not having any dynamic allocation (not sure if this is good?). reply anonymoushn 10 hours agoparentI've done this sort of thing by writing a code generator in python instead of using comptime. I'm not confident that comptime zig is particularly fast, and I don't want to run the json parser that generates the struct all the time. reply koe123 9 hours agorootparentAnother thing I tried as an alternative is using ZON (zig object notation) instead of json. This can natively be included directly as a source file. It involved writing a custom python exporter though (read: I gave up). reply mk12 4 hours agorootparentprevFWIW the goal for comptime Zig execution is to be at least as fast as Python. I can’t find it now but I remember Andrew saying this in one of his talks at some point. reply DanielHB 9 hours agorootparentprevI believe that Zig build system can cache comptime processes, so if the JSON didn't change it doesn't run again. reply Validark 5 hours agorootparentI think if you integrated with the build system, yes, Zig can do things only when the file changed. But I'm not sure that Zig figured out incremental comptime yet. That's way harder to accomplish. reply 0x1ceb00da 11 hours agoparentprevHow does this affect the compile times? reply koe123 11 hours agorootparentThey become quite long, but it was surprisingly tolerable. I recall it vaguely but a 100MB neural network was on the order of minutes with all optimizations turned on. I guess it would be fair to say it scaled more or less linearly with the file size (from what I saw). Moreover I work in essentially a tinyml field so my neural networks are on the order of 1 to 2 MB for the most part. For me it wouldve been reasonable! I guess in theory you could compile once into a static library and just link that into a main program. Also there will be incremental compilation in zig I believe, maybe that helps? Not sure on the details there. reply erichocean 11 hours agorootparentprevIt's nothing like C++ templates. reply Tiberium 11 hours agoprevIf you're surprised by Zig's comptime, you should definitely take a look at Nim which also has compile-time code evaluation, plus a full AST macro system. reply foretop_yardarm 7 hours agoparentNim is a fun language but I wouldn't consider it for \"serious\" work. It has the same issues as other niche languages (ie. ecosystem), plus: a polarising maintainer (most core contributors don't seem to last long) and primarily funded by a crypto company (if you care about that). Then again, 10 years ago none of that would have bothered me. reply planetis 18 minutes agorootparentAll these organizations[1] using nim in production must disagree with you then. [1]: https://github.com/nim-lang/Nim/wiki/Organizations-using-Nim reply SMP-UX 12 hours agoprevZig is overall pretty good as a language and it does what it needs to: staying in the lane of the purpose is very important. It is why I do not particularly care for some languages being used just because. reply pjmlp 11 hours agoprevWhile interesting, this is one of the cases, where I agree with \"D did it first\" kind of comments. reply sixthDot 9 hours agoparentsure, and hygienically, it's not a preprocessor thing. reply melodyogonna 8 hours agoprevMojo's compiletime metaprogramming [1] is inspired by Zig's. Though Mojo takes things further by implementing a fully-featured generic programming system. 1. https://docs.modular.com/mojo/manual/parameters/ reply Validark 5 hours agoparentWhat can you do in Mojo that you can't do in Zig? reply kstrauser 4 hours agorootparentPay a company for the privilege of being allowed to develop with it. It has a commercial license, where Zig is MIT’d. I haven’t written a line of either. I could see using Zig, but there’s no plausible scenario where I’d ever write Mojo. Weird proprietary languages tend to be a career pigeonhole: “you’ve been doing what for the last 5 years?” reply melodyogonna 37 minutes agorootparentNobody is paying anybody to use Mojo, its main issue is cross-platform support, specifically lack of native Windows support. Like I always say, most languages start off closed, incubated for some years by a tiny group, before being opened. Mojo is no different, in fact, Modular have given a pretty solid timeline about when they plan to open source the compiler - https://youtu.be/XYzp5rzlXqM?si=nmvghH3KWX6SrDzz&t=1025 reply kstrauser 0 minutes agorootparentEvery language I've used in the last few years has been FOSS from the very beginning time that it was shared outside its original developers. A proprietary language is the odd exception, not the common case. Looks like I was wrong about having to pay to use Mojo itself. It's their \"MAX\" product you have to pay for, at least today. The language currently free-of-charge, although proprietary. thefaux 1 hour agorootparentprevWeird proprietary languages _can_ also be much better for a particular task than anything else and can thus be smart business. Someone who will dismiss something they don't know on the grounds that is weird and proprietary is not someone I'd want to work with. But of course if this is how a lot of people think then there may be no choice but for most people to try and stick with the tried and true. reply melodyogonna 59 minutes agorootparentprevGPU kernels. reply pakkarde 11 hours agoprevAfter having written a somewhat complete C parser library I don't really get the big deal about needing meta programming in the language itself. If I want to generate structs, serialization, properties, instrumentation, etc, I just write a regular C program that processes some source files and output source files and run that first in by build script. How do you people debug and test these meta programs? Mine are just regular C programs that uses the exact same debuggers and tools as anything else. reply coldtea 6 hours agoparent>I don't really get the big deal about needing meta programming in the language itself. If I want to generate structs, serialization, properties, instrumentation, etc, I just write a regular C program that processes some source files and output source files and run that first in by build script. This describes exactly what people don't want to do. reply dboreham 5 hours agorootparentBut exactly why? reply jerf 4 hours agorootparentIf you just walked up to me out of the blue and asked \"what computer language do you know is the worst for processing strings?\", well, technically I might answer \"assembler\", but if you excluded that, my next answer would be C. Furthermore, you want some sort of AST representation, at one level of convenience or another (I include this compgen-style \"being 'in' the AST\" to be included in that, even if it doesn't necessarily directly manipulate AST nodes), and C isn't particularly great at manipulating those, either, in a lot of different ways. A consequence of C being the definitive language that pretty much every other language has had to react to, one way or another through however many layers of indirection, for the past 40+ years, is that pretty much every language created since then is better than C at these things. C's pretty long in the tooth now, even with the various polishings it has received over the years. reply 0x696C6961 4 hours agorootparentprevBecause after enough hands have touched a codegen script, debugging it becomes impossible. reply 0x1ceb00da 2 hours agorootparentIn jai you use the same language for programming and metaprogramming. The compiler knows how to execute the bytecode it generates. The compiler also has a builtin debugger for the bytecode. reply pjc50 9 hours agoparentprevC# (strictly, Roslyn/dotnet) provides this in a pretty nice way: because the compiler is itself written in the language, you can just drop in plugins which have (readonly!) access to the AST and emit C# source. Debugging .. well, you have to do a bit more work to set up a nice test framework, but you can then run the compiler with your plugin from inside your standard unit test framework, inside the interactive debugger. reply modernerd 10 hours agoparentprevYes, this is the same approach Ryan Fleury and others advocate, and it's perfectly good: > Arbitrary compile-time execution in C: > cl /nologo /Zi metaprogram.c && metaprogram.exe > cl /nologo /Zi program.c > Compile-time code runs at native speed, can be debugged, and is completely procedural & arbitrary > You do not need your compiler to execute code for you https://x.com/ryanjfleury/status/1875824288487571873 reply zamalek 9 hours agorootparentThe only benefit that some (certainly more rare) compilers can provide is type metadata/compile-time reflection. Otherwise, totally. reply chikere232 9 hours agorootparentprevMS DOS choice of / for commandline arguments and \\ for paths always hurts my eyes reply nox101 11 hours agoparentprevI don't know about zig bit the power of lisp is that youre manipulating the s-expressions or to put it another way, you're manipulating the ast. To do that in C you'd need to write a full C parser for your C program that processes source files. reply Certhas 8 hours agoparentprevI used to do that in Python with the numba jit. Write Python code that generates a Python code that then gets compiled. It's a fragile horrible mess, and the need to do this was a major reason for me to switch away from Python. It's a bit like asking why we don't just pass all arguments to functions as strings. Yeah, people write stringly typed code, but it should rarely be necessary, and your language should provide means to avoid it. reply agentkilo 8 hours agoparentprevWell put. I always have the feeling that any language which has an `eval` function or an invokable compiler can do meta program. That said, I think the \"big deal\" is in UX/DX. It's really nice to have meta programming support built-in to the language when you need it. reply jmull 6 hours agoparentprevWhether you consider it a big deal or not is up to you, but with zig's approach you don't have to write/maintain a separate parser, nor worry about whether it's complete enough to process your source files. I don't know a lot about debugging zig comptime, though. I use printf-style debugging and the built-in unit test blocks. That's all I've needed so far. (Perhaps that's all there is.) reply benob 8 hours agoparentprev> How do you people debug and test these meta programs? I couldn't find any other answer than using @compileLog to print-debug [1]. In lisp, apparently some implementations allow to trace macros [2]. Couln'd find anything about Nim's macro debugging capabilities. This whole thing looks like a severe limitation that is not balanced by the benefit of having all code in the same place. Do you know other languages that provide sensible meta-programming facilities? [1] https://www.reddit.com/r/Zig/comments/jkol30/is_there_a_way_... [2] https://stackoverflow.com/questions/44872280/macros-and-how-... reply disentanglement 1 hour agorootparentIn lisp, macros are just ordinary functions whose input and output is an AST. So you can debug them as you would any other function, by tracing, print debugging, unit tests or even stepping through them in a debugger. reply adev_ 9 hours agoparentprev> I just write a regular C program that processes some source files and output source files and run that first in by build script. Cool, you now invented your own DSL and half-baked meta programming macro language for something that shall have been in the language to begin with. In addition, any complex interaction between your \"own made template engine\" and the native code is now a pile of hack. E.g write a generic function: Good luck to interpret any error based on the typing. Code generation is almost consistently the worst solution to a meta-programming problem. reply coliveira 1 hour agorootparentThe notion of \"something that shall have been in the language\" is not properly defined, as you can basically start from that and arrive at C++. So it is perfectly fine to assume that compile-time programming does not belong into the language and write your own processor. As for DSL, any DSL is a separate language that needs to be learned, so it is not very different from creating your own processor. reply kreco 4 hours agorootparentprev> Cool, you now invented your own DSL and half-baked meta programming macro language I'm not sure I'm following your statement. What he said was to use a C program to parse C code and emit additional C code. There is no mention of DSL. > for something that shall have been in the language to begin with. The whole point of this discussion is to debate on that. I have no strong opinion (yet) but the meta program looks easy to understand compared to the pandora box of metaprogrammaing withing the language (since it requires standardization, limitations etc.). reply p0nce 9 hours agoparentprevBecause it goes hand-in-hand with your code self-describing with static reflection. reply bryango 12 hours agoprevI hope we can have something that combines the meta-programming capabilities of Zig with the vast ecosystem, community and safety of Rust. Looking at the language design, I really prefer Zig to Rust, but as an incompetent, amateur programmer, I couldn't write anything in Zig that's actually useful (or reliable), at least for now. reply norman784 8 hours agoparentI Agree. I tried briefly Zig and quickly gave up because, as someone used to Rust, the compiler wasn't helping me find those issues at compile time. I know that Zig doesn't make those promises, but for me, it's a deal breaker, so I suppose Zig isn't the language for me. On the other hand, I do like the concept of comptime vs Rust macros. reply Validark 5 hours agoparentprevAre you praising the \"community\" that declared that Andrew Kelley should face jail time for creating Zig because it's \"unsafe\"? reply drogus 4 hours agorootparent\"the community\" meaning one weirdo commenter you've seen on HN? Cause I can assure you no people I know in the Rust community think that way. Personally I would really like to code some stuff in Zig if I had more time. It's not really appealing to me in many ways (like I prefer to spend a bit more on designing types for my programs and have safety guartantees), so I wouldn't probably ue it long term, but I admit stuff like comptime is interesting. reply ArtixFox 4 hours agorootparentprevbruh, zig's VP called rust users safety coomers. Its internet shitposting who cares. source: I was there when it happened and it was GLORIOUS. reply bryancoxwell 4 hours agorootparentprevI beg your pardon reply spacecow 4 hours agoprevTiny bug report: The second code example's output is still \">>array's In the beginning, computers were invented. This has made lots of people very angry and was generally considered a bad move. reply G3rn0ti 8 hours agoprevSite is down: https://web.archive.org/web/20250107090641/https://www.scott... reply HeliumHydride 13 hours agoprevWith reflection and code generation coming to C++26, and the already existing constexpr/consteval machinery, C++ will be able to do all of this. reply flohofwoe 11 hours agoparentC++ could do generic programming long before Zig even was an idea, but writing generic code in Zig is still much more straightforward - also Zig is usable now, while C++26 features will probably land in real world C++ compilers around 2036 ;) reply katzenversteher 11 hours agoparentprevReminds me of \"Der Untergang\". Mit dem Angriff C++26 wird das alles in Ordnung kommen! reply flohofwoe 11 hours agorootparentInteresting, I had the exact same image in my mind :D reply dwattttt 13 hours agoparentprevBash scripts and (optionally) an assembler can do this. That's not really the point. reply logicchains 12 hours agorootparentThat's something different, code generation. The point is that C++26 will have compile-time reflection without any need for an external code generation tool, similar to Zig. reply kstrauser 12 hours agorootparentWith the main difference being that if you start Zig today, you’ll get to use that a good decade before it’s reliably available in C++. Hmm. Actually, now that makes me want to learn Zig. reply kevin_thibedeau 11 hours agorootparentConsteval is usable today for a lot of scenarios that would require code generation tooling in years past. reply dwattttt 11 hours agorootparentHow does consteval interact with thread_local? Defined (although I'm not sure what definition could make sense), error, or the dreaded \"No diagnostic required\"? reply int_19h 10 hours agorootparentprevErgonomics matters, though. In C++, this feature is bolted onto the language decades after it was originally designed. Zig is designed around this from the get go (which is why it doesn't have e.g. templates as a distinct feature). reply flohofwoe 11 hours agorootparentprevIn the end, generics, comptime and code generation are just different steps on the 'stamping out specialized code and data' ladder though (e.g. all three are useful). reply pipeline_peak 13 hours agorootparentprev> Bash scripts and (optionally) an assembler What do you mean by that ? reply dwattttt 13 hours agorootparentIn much the same way as \"being Turing complete means you can do anything\", it just being possible to do compile-time execution isn't the reason Zig is exciting here. C++ adding the same features means it'll be possible, but it has a much larger intersection of alternative features to introduce edge cases with, and _many_ implementations that will have this feature with varying quirks: all of this means C++ will have to do a _much_ better job than Zig does here to achieve nearly the same result. reply rowbin 12 hours agorootparentThanks for that. I loathe replys like \"but lang/framework/... can do/will be able to do something similar/does something else which I like better/...\". Well, it's not about that. It's about how easy it is to use, how good it is from preventing you to shoot yourself in the foot, sometimes how performant it is, ... reply benatkin 13 hours agorootparentprevIt's suggesting that Zig is convenient and that C/C++ won't be. I think both will be nice. reply carlos22 12 hours agorootparentWell C++ has a history of not really being convenient and makes it easy to shoot you in the foot. reply rochak 12 hours agoparentprevGood. Keep on adding stuff to an already bloated language. reply pjmlp 11 hours agorootparentAll programming languages either die, or become bloated, as any software product. I bet a Fortran 77 developer will think the same of Fortran 2023, a COBOL 60 developer of COBOL 2023, a K&R C developer from C23, a 1975 Scheme developer from R7RS, a Python 1.0 developer from Python 3.13,... even Go 1.0 developers from 1.24 with generics, generators,... reply tialaramex 3 hours agorootparentOne trick that can help you here is Rust's Editions (and the proposed but never implemented C++ Epochs). This lets the language throw away bad ideas, without throwing away the code people wrote in the era when we didn't realise that's a bad idea. reply logicchains 12 hours agorootparentprevCompile-time reflection will remove countless of lines of bloat from real C++ code bases due to eliminating the need to manually write formatting, hashing and serialisation implementations for classes. reply riwsky 12 hours agorootparent…10 years from now reply fredrikholm 8 hours agorootparentIf not more; the words \"modern\" and \"C++11\" are still used in conjunction despite the fact that 2014 was a long time ago. reply edflsafoiewq 13 hours agoparentprevcomptime simplifies and unifies much of that machinery into a clean, conceptual framework. reply brabel 12 hours agoparentprevThe examples in thist post seem very similar to how you do metaprogramming in the D language. That has existed for years yet you rarely hear about that. reply pjmlp 11 hours agoparentprevWith a much better ecosystem, 40 years of IDE tooling, frameworks, OS support. Which is what people always forget when comparing language grammars. reply 9dev 11 hours agorootparentI'm not sure if you actually want to call \"copy these header files into your local file system\" an ecosystem at all. The last 40 years have brought heaps of improvements in software development ergonomics. Zig is growing just fine, as other languages like Rust or Go. reply pjmlp 11 hours agorootparentThat is what script kiddies do when using compiled languages. Rust has had an almost usable implementation for affine types, and being the second coming of Ada, to win the hearths of the industry, including all major OS vendors and hyperscallers. Go got lucky with Docker and Kubernetes rewrites, and their adoption across the industry. So far Zig is basically Modula-2 with C like syntax, and compile time execution, relies on the same tooling that C and C++ have had for decades for use-after-free, doesn't support a binary libraries ecosystem by design, and really Bun isn't going to be the killer project that triggers a Rewrite in Zig movement. It remains to be seen if Zig 1.0 happens, and how its adoption story at scale will be like. reply rastignack 2 hours agorootparent> Bun isn't going to be the killer project that triggers a Rewrite in Zig movement. It might be enough to make the zig ecosystem viable. This along with tiger beetle (they have raised tens of millions). I think a lot of time is spent right now on the tooling, I hope that in a near feature the zig team will be able to switch to the event loop / standard library topics which really need love. reply vkazanov 10 hours agorootparentprevI agree that zig is taking too long to be finalised. And rust has made certain questionable life choices. But people really, REALLY want to get off c and c++ for all the numerous reasons everybody knows. reply pjmlp 10 hours agorootparentThey might want, yet while Khronos keeps publishing standards using C and C++, GCC/LLVM/CUDA/.NET/Java/V8/Metal make use of C++, Nintendo/PlayStation/XBox rely on C++, ... they are going to stay around no matter what. reply Ygg2 9 hours agorootparentprev> I agree that zig is taking too long to be finalised. And rust has made certain questionable life choices. Any language that's older than 10 years is going to make questionable life choices. It's very easy to be Captain Hindsight, and ask why didn't you do X, 5 years ago? But adding feature X also makes another feature or property impossible, either via opportunity cost or features/properties being at odds. That said, what do you mean by questionable life choices? reply vkazanov 9 hours agorootparent> Any language that's older than 10 years.. Yes, true. Every language has to make some early foundational choices, as few as possible, and try to carefully think about any new addition to the core because of the extra congnitive load that comes with it. Go is an extreme example here, leaning towards the conservative side. C as well. Zig. Not a fan of Java but it also is kinda slow to add things. Python used to be very careful as well but that epoch is gone. C++ is the opposite example. It tries to add as much as possible, and it was always the case. C compatibility! And classes! Templates! RAII! Metaprogramming! More of everything! Until it reached a point where it's unforgiving hard to add things. Or even learn it properly. Now, Rust feels like a C++ reimplementation, complete with a culture of adding as much as possible as quickly as possible, and ignoring the resulting cognitive load. I mean, it's a choice. Rust definitely has some great, even amazing, ideas to it. But I am afraid of thinking what the language will feel like in 10 years. reply Ygg2 7 hours agorootparent> Now, Rust feels like a C++ reimplementation, complete with a culture of adding as much as possible as quickly as possible, and ignoring the resulting cognitive load. Ok, but I did ask for what specifically do you mean by questionable life choices? I feel Java is moving at a fast pace (and adding everything and the kitchen sink). Hence, why I wanted specific examples. Can you separate your feelings from facts, and see from where the feelings come from? I'm not saying you're wrong, I'm saying I want to understand your basis for that. > Go is an extreme example here, leaning towards the conservative side. Is it? Didn't it also start adding features that it swore not to add (generics)? reply flohofwoe 10 hours agorootparentprevThere has been an awful amount of stagnation in those 40 years though. The Visual Studio debugger is still the best overall debugger but has hardly advanced since the late 90s. While the Debug Adapter Protocol and Language Server Protocol invented by the VSCode team are not perfect, they both make debugger and 'Intellisense' support in IDEs for new languages quite trivial and easily get into the 80% 'good enough' area of what a 'proper' IDE offers. reply pjmlp 10 hours agorootparentIt has advanced quite a lot, but people don't care to learn about debuggers are they care about low level details of their programming languages. Also it is quite telling that outside IDE friendly languages, debbugers are kind of stuck in the 80's, so no wonder that many think 80% of Visual Studio and friends is good enough. reply littlestymaar 12 hours agoprevComptime to replace macros is indeed good, comptime to replace generics on the other hand isn't and that really makes me think of the “when all you have is a hammer” quote. reply cyco130 5 hours agoparentIt's a tradeoff. Advanced generic programming as implemented in many other languages requires you to learn a completely new language. That new language is better suited for some use cases. Functions that take types and return types, on the other hand, can be more intuitive in other cases. reply edflsafoiewq 12 hours agoparentprevWhy? reply bsder 12 hours agoparentprevThe problem is that the alternatives to comptime for generics generally seems to have a hideous effect on compile times (see: C++ and Rust). Is there a language that does generics in such a way that doesn't send compile times to the moon? reply edflsafoiewq 12 hours agorootparentShouldn't comptime have the same compile time implications as templates? In both cases you're essentially recompiling the code for every distinct set of comptime args/template parameters. reply hansvm 11 hours agorootparentZig is lazy, and C++ is eager. I can define an infinite set of mutually recursive types in Zig, and only the ones I actually use will be instantiated (not an everyday need, but occasionally interesting -- I had fun building an autodiff package that way with no virtual function overhead, and the set of type descriptors being closed under VJP meant that you could support arbitrary (still only finite) derivative-like tensors, not just first and second order). reply bsder 11 hours agorootparentprevZig doesn't instantiate anything the doesn't get called. So, it doesn't have to generate a whole bunch of templated functions and then optimize down to the ones that actually get used. The upside is that if you only call a generic function with a u32, you don't instantiate an f32 as well. The downside is that when you do decide to call that function with an f32, all the comptime stuff suddenly gets compiled for the f32 and might have an error. In practice, I feel that I gain way more from the fast compile than I lose from having a path that accidentally never got compiled as my unit tests almost always force those paths to be compiled at least once. reply dwattttt 11 hours agorootparent> it doesn't have to generate a whole bunch of templated functions and then optimize down to the ones that actually get used. It's been a long time since I've dealt with templated C++, but I thought this was how C++ does it too. C++ will only generate functions for template parameters that are actually used, because it compiles a version of the templated function for each unique template parameters. reply anonymoushn 10 hours agorootparentC++ is at the very least less lazy than Zig. As an example, if you write some constexpr expression that evaluates a ternary and instantiates a function differently in the two prongs, both will be instantiated, even the one that doesn't end up in the final program. Yes, there are workarounds, but I didn't end up using them. I just moved the offending assert from compile time to runtime because this particular code was not that important. reply edflsafoiewq 9 hours agorootparentBut the question is if that's actually decisive in the slow compilation problem. The solution in an eager language for evaluating too much stuff is basically \"more if statements\". Same thing in C++ metaprogramming, use more \"if constexpr\". If that's all it took to fix C++ compile times, it would have been done a decade ago. The actual problem is all the stuff that you do actually use that has to get repeatedly inlined and optimized away for zero cost abstraction to work. reply anonymoushn 8 hours agorootparentNo, I don't think it is a big deal for compilation speed. reply vnorilo 9 hours agorootparentprevC++ monomorphises generics on demand too. That's why it can have errors specific to specialization and why template error messages spam long causal chains. C++ compile times are due to headers. Which in case of templates result in a lot of redundant work then deduplicated by the linker. reply pjmlp 11 hours agorootparentprevAs proven by C++ with modules and binary libraries, compile times can be better in C++. Rust suffers because they compile everything from source, and the frontend sends piles of unprocessed LLVM IR to the traditional slow backend. This can be improved with better tooling, one example is the Cranelift backend, there could be an interpreter, and so on. Examples of languages that don't send compile times to the moon with similar polymorphic power, Standard ML, OCaml, Haskell, D, Ada. reply littlestymaar 9 hours agorootparentAFAIK Part of the problem with Rust is also that it compiles crates individually before linking them and because of that cannot use the upfront knowledge of what's going to be needed, and as such a generic function that crosses the crate boundary is going to be handled twice by the compiler. This was initially done so that Rust could compile things in parallel between crates by with spawning more rustc processes, which is obviously much easier than building a parallel compiler directly, but in the end it's suboptimal for performance. reply anonymoushn 10 hours agorootparentprevcomptime for generics is a superset of the things that C++ and Rust do for generics reply shikck200 6 hours agorootparentprevOcaml reply wtetzner 4 hours agorootparentOCaml doesn't monomorphize functions. Instead references to every type are the same size (either a tagged int or a pointer). This is a sweet spot for OCaml, but doesn't really work for a language that doesn't allocate everything on the heap. reply bionhoward 4 hours agoprevRust really needs comptime, I love cargo and the ecosystem but trait level programming is weird, macros are weird, why can’t you just be normal? (rust screams) reply diimdeep 12 hours agoprevYeah it's good, and tech evangelism is just marketing. reply datadeft 9 hours agoprevThis website is not mobile ready. reply melon_tusk 2 hours agoprev [–] Zig is alright, but Odin is amazing. reply akkad33 25 minutes agoparent [–] Why? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Scott Redig explores Zig's 'comptime' feature, which enhances productivity by enabling metaprogramming, allowing code execution during compile time. - He provides six perspectives on 'comptime', highlighting its ability to simplify code reading and debugging, and compares it to generics, partial evaluation, and code generation. - Redig concludes that Zig's 'comptime' is both powerful and simple, recommending further exploration through Zig's official resources and standard library."
    ],
    "commentSummary": [
      "Zig's compile-time programming (comptime) is recognized for its efficiency, enabling features like generics, complex data initialization, and target-specific code generation. - Critics highlight potential issues such as misuse akin to Lisp macros, breaking parametricity, and challenges with recursive generic types and type checking during compile-time computation. - Despite these concerns, Zig's simplicity and compile-time execution are considered major advantages, with some interest in integrating its metaprogramming capabilities with Rust's ecosystem."
    ],
    "points": 353,
    "commentCount": 182,
    "retryCount": 0,
    "time": 1736212507
  },
  {
    "id": 42618761,
    "title": "Nvidia announces next-gen RTX 5090 and RTX 5080 GPUs",
    "originLink": "https://www.theverge.com/2025/1/6/24337396/nvidia-rtx-5080-5090-5070-ti-5070-price-release-date",
    "originBody": "News/ Tech/ CES Nvidia announces next-gen RTX 5090 and RTX 5080 GPUs Nvidia announces next-gen RTX 5090 and RTX 5080 GPUs / Four new RTX 50-series GPUs are on the way, including the $1,999 RTX 5090 and $999 RTX 5080. By Tom Warren, a senior editor and author of Notepad, who has been covering all things Microsoft, PC, and tech for over 20 years. Jan 7, 2025, 3:07 AM UTC Share this story If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement. Nvidia is officially announcing its RTX 50-series GPUs today. After months of leaks and rumors, the next-generation RTX Blackwell GPUs are now official, and there are four of them on the way. Nvidia CEO Jensen Huang revealed the RTX 50-series GPUs during a CES keynote this evening, announcing a $1,999 RTX 5090, a $999 RTX 5080, a $749 RTX 5070 Ti, and a $549 RTX 5070. Nvidia’s new RTX 5090 and RTX 5080 GPUs will both be available on January 30th, with the RTX 5070 Ti and RTX 5070 to follow in February. Nvidia’s RTX 5090 GPU is surprisingly small. Image: Nvidia The RTX 50-series GPUs include a new design for the Founders Edition, with just two double flow-through fans, a 3D vapor chamber, and GDDR7 memory. All of the RTX 50-series cards are PCIe Gen 5 and include DisplayPort 2.1b connectors to drive displays up to 8K and 165Hz. Surprisingly, the RTX 5090 Founders Edition will be a two-slot GPU and will be capable of fitting inside small form factor PCs — a big departure from the size of the RTX 4090. The RTX 5090 has 32GB of GDDR7, a memory bandwidth of 1,792GB/sec, and a massive 21,760 CUDA cores. This all adds up to a GPU that Nvidia says will be two times faster than the RTX 4090, thanks to DLSS 4 and the Blackwell architecture. But it will come at a cost of power consumption, as Nvidia says the RTX 5090 will have a total graphics power of 575 watts and a recommended PSU requirement of 1000 watts. That’s 125 watts more than the RTX 4090, but hopefully the RTX 5090 will be a lot more power efficient so that you’ll rarely be using the full 575 watts. Nvidia demonstrated Cyberpunk 2077 running on an RTX 5090 with DLSS 4 at 238fps compared to 106fps on an RTX 4090 with DLSS 3.5. Both GPUs are running the game with full ray tracing enabled. The RTX 5080 is designed to be twice as fast as the RTX 4080 and will include 16GB of GDDR7 memory, a memory bandwidth of 960GB/sec, and 10,752 CUDA cores. The RTX 5080 will have a total graphics power of 360 watts and Nvidia is recommending a 850-watt power supply. Nvidia is promising big performance gains with the RTX 5080 over the previous RTX 4080 model as a result of these specs. RTX 5090 performance. Image: Nvidia Nvidia’s RTX 5080 performance promises. Image: Nvidia Nvidia is also launching an RTX 5070 Ti and RTX 5070. The RTX 5070 Ti includes 16GB of GDDR7 memory, a memory bandwidth of 896GB/s, and 8,960 CUDA cores. The RTX 5070 has 12GB of GDDR7, a memory bandwidth of 672 GB/sec, and 6,144 CUDA cores. The RTX 5070 Ti will have a total graphics power of 300 watts and require a 750-watt PSU, while the RTX 5070 has a total graphics power of 250 watts and only needs a 650-watt PSU. Nvidia says the RTX 5070 Ti will be 2x faster than the RTX 4070 Ti, and the RTX 5070 should be twice as fast as the RTX 4070. Huang even claimed on stage at CES that the RTX 5070 will deliver “RTX 4090 performance at $549,” but this will undoubtedly be because of DLSS 4 improvements and not pure rasterization performance. Nvidia is also bringing its RTX 50-series to laptops, with the RTX 5090 laptop GPU debuting with 24GB of GDDR7 memory. The RTX 5080 laptop GPU will ship with 16GB of GDDR7 memory, the RTX 5070 Ti with 12GB of GDDR7 memory, and the RTX 5070 with just 8GB of GDDR7 memory. RTX 50-series laptops will be available starting in March from a variety of PC makers. RTX 50-series laptops are coming in March. Image: Nvidia Huang demonstrated Nvidia’s RTX Blackwell GPUs with a real-time rendering demo at the beginning of the company’s CES keynote today. The demo included new RTX Neural Materials, RTX Neural Faces, text to animation, and even DLSS 4. “The new generation of DLSS can generate beyond frames, it can predict the future,” says Huang. “We used GeForce to enable AI, and now AI is revolutionizing GeForce.” Nvidia’s new RTX Neural Shaders can be used to compress textures in games, while RTX Neural Faces aim to improve face quality using generative AI. The next generation of DLSS includes Multi Frame Generation, which generates up to three additional frames per traditional frame and can multiply frame rates by up to 8x over traditional rendering, according to Nvidia. 1/3 1/3 DLSS 4 also includes a real-time application of transformers to improve image quality, reduce ghosting, and add higher detail in motion. The DLSS 4 upgrade will even work on existing RTX GPUs, as features have been upgraded to the new transformer AI models. You can read more about DLSS 4 right here. Nvidia’s RTX 50-series announcement comes more than two years after the RTX 4090 and RTX 4080 were announced, based on Nvidia’s Ada Lovelace architecture. Nvidia’s RTX 40-series of GPUs focused on improving ray tracing with Deep Learning Super Sampling (DLSS) version 3, and the RTX 4090 delivered some truly impressive performance gains over the previous RTX 3090 GPU. Most Popular Most Popular CES 2025: all the news, gadgets, and surprises Dell kills the XPS brand Nvidia announces $3,000 personal AI supercomputer called Digits Nvidia announces next-gen RTX 5090 and RTX 5080 GPUs Microsoft is using Bing to trick people into thinking they’re on Google Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=42618761",
    "commentBody": "Nvidia announces next-gen RTX 5090 and RTX 5080 GPUs (theverge.com)329 points by somebee 15 hours agohidepastfavorite366 comments jbarrow 1 hour agoThe increasing TDP trend is going crazy for the top-tier consumer cards: 3090 - 350W 3090 Ti - 450W 4090 - 450W 5090 - 575W 3x3090 (1050W) is less than 2x5090 (1150W), plus you get 72GB of VRAM instead of 64GB, if you can find a motherboard that supports 3 massive cards or good enough risers (apparently near impossible?). reply 6SixTy 4 minutes agoparentNvidia wants you to buy their datacenter or professional cards for AI. Those often come with better perf/W targets, more VRAM, and better form factors allowing for a higher compute density. For consumers, they do not care. PCIe Gen 4 dictates a tighter tolerance on signalling to achieve a faster bus speed, and it took quite a good amount of time for good quality Gen 4 risers to come to market. I have zero doubt in my mind that Gen 5 steps that up even further . reply marricks 41 minutes agoparentprevI got into desktop gaming at the 970 and the common wisdom (to me at least, maybe I was silly) was I could get away with a lower wattage power supply and use it in future generations cause everything would keep getting more efficient. Hah... reply epolanski 27 minutes agorootparentYeah, do like me, I lower settings from \"ultra hardcore\" to \"high\" and keep living fine on a 3060 at 1440p for another few gens. I'm not buying GPUs that expensive nor energy consuming, no chance. In any case I think Maxwell/Pascal efficiency won't be seen anymore, with those RT cores you get more energy draw, can't get around that. reply iandanforth 1 hour agoparentprevSounds like you might be more the target for the $3k 128GB DIGITS machine. reply jbarrow 1 hour agorootparentI’m really curious what training is going to be like on it, though. If it’s good, then absolutely! :) But it seems more aimed at inference from what I’ve read? reply bmenrigh 52 minutes agorootparentI was wondering the same thing. Training is much more memory-intensive so the usual low memory of consumer GPUs is a big issue. But with 128GB of unified memory the Digits machine seems promising. I bet there are some other limitations that make training not viable on it. reply jbarrow 6 minutes agorootparentPrimarily concerned about the memory bandwidth for training. Though I think I've been able to max out my M2 when using the MacBook's integrated memory with MLX, so maybe that won't be an issue. reply tpm 19 minutes agorootparentprevIt will only have 1/40 performance of BH200, so really not enough for training. reply saomcomrad56 6 minutes agoparentprevIt's good to know can all heat our bedrooms while mining shitcoins. reply elorant 18 minutes agoparentprevYou don't need to run them in x16 mode though. For inference even half that is good enough. reply mikae1 42 minutes agoparentprevPerformance per watt[1] makes more sense than raw power for most consumer computation tasks today. Would really like to see more focus on energy efficiency going forward. [1] https://en.wikipedia.org/wiki/Performance_per_watt reply epolanski 24 minutes agorootparentThat's s blind way to look at that imho. Doesn't work on me for sure. More energy means more power consumption, more heat in my room, you can't escape thermodynamics. I have a small home office, it's 6 square meters, during summer energy draw in my room makes a gigantic difference in temperature. I have no intention of drawing more than a total 400w top while gaming and I prefer compromising on lowering settings. Energy consumption can't keep increasing over and over forever. I can even understand it on flagships, they meant for enthusiasts, but all the tiers have been ballooning in energy consumption. reply ashleyn 16 minutes agoparentprevmost household circuits can only support 15-20 amps at the plug. there will be an upper limit to this and i suspect this is nvidia compromising on TDP in the short term to move faster on compute reply SequoiaHope 5 minutes agorootparentI wonder if they will start putting lithium batteries in desktops so they can draw higher peak power. reply jbarrow 3 minutes agorootparentThere's a company doing that for stovetops, which I found really interesting (https://www.impulselabs.com)! Unfortunately, when training on a desktop it's _relatively_ continuous power draw, and can go on for days. :/ reply cogman10 1 hour agoparentprevWhat I really don't like about it is low power GPUs appear to be a thing of the past essentially. An APU is the closest you'll come to that which is really somewhat unfortunate as the thermal budget for an APU is much tighter than it has to be for a GPU. There is no 75W modern GPU on the market. reply Scene_Cast2 59 minutes agoparentprevI heavily power limited my 4090. Works great. reply holoduke 1 hour agoparentprevCan you actually use multiple videocards easily with existing AI model tools? reply jbarrow 1 hour agorootparentYes, though how you do it depends on what you're doing. I do a lot of training of encoders, multimodal, and vision models, which are typically small enough to fit on a single GPU; multiple GPUs enables data parallelism, where the data is spread to an independent copy of each model. Occasionally fine-tuning large models and need to use model-parallelism, where the model is split across GPUs. This is also necessary for inference of the really big models, as well. But most tooling for training/inference of all kinds of models supports using multiple cards pretty easily. reply qingcharles 13 minutes agorootparentprevYes. Depends what software you're using. Some will use more than one (e.g. llama.cpp), some commercial software won't bother. reply benob 1 hour agorootparentprevYes, multi-GPU on the same machine is pretty straightforward. For example ollama uses all GPUs out of the box. If you are into training, the huggingface ecosystem supports it and you can always go the manual route to put tensors on their own GPUs with toolkits like pytorch. reply ks2048 3 hours agoprevThis is maybe a dumb question, but why is it so hard to buy Nvidia GPUs? I can understand lack of supply, but why can't I go on nvidia.com and buy something the same way I go on apple.com and buy hardware? I'm looking for GPUs and navigating all these different resellers with wildly different prices and confusing names (on top of the already confusing set of available cards). reply michaelt 39 minutes agoparentOK so there are a handful of effects at work at the same time. 1. Many people knew the new series of nvidia cards was about to be announced, and nobody wanted to get stuck with a big stock of previous-generation cards. So most reputable retailers are just sold out. 2. With lots of places sold out, some scalpers have realised they can charge big markups. Places like Amazon and Ebay don't mind if marketplace sellers charge $3000 for a $1500-list-price GPU. 3. For various reasons, although nvidia makes and sells some \"founder edition\" the vast majority of cards are made by other companies. Sometimes they'll do 'added value' things like adding RGB LEDs and factory overclocking, leading to a 10% price spread for cards with the same chip. 4. nvidia's product lineup is just very confusing. Several product lines (consumer, workstation, data centre) times several product generations (Turing, Ampere, Ada Lovelace) times several vram/performance mixes (24GB, 16GB, 12GB, 8GB) plus variants (Super, Ti) times desktop and laptop versions. That's a lot of different models! nvidia also don't particularly want it to be easy for you to compare performance across product classes or generations. Workstation and server cards don't even have a list price, you can only get them by buying a workstation or server from an approved vendor. Also nvidia don't tend to update their marketing material when products are surpassed, so if you look up their flagship from three generations ago it'll still say it offers unsurpassed performance for the most demanding, cutting-edge applications. reply doix 3 hours agoparentprevNvidia (and AMD) make the \"core\", but they don't make a \"full\" graphics card. Or at least they don't mass produce them, I think Nvidia tried it with their \"founders edition\". It's just not their main business model, it's been that way for many many years at this point. I'm guessing business people have decided that it's not worth it. Saying that they are \"resellers\" isn't technically accurate. The 5080 you buy from ASUS will be different than the one you buy from MSI. reply sigmoid10 3 hours agorootparentNvidia also doesn't make the \"core\" (i.e. the actual chip). TSMC and Samsung make those. Nvidia designs the chip and (usually) creates a reference PCB to show how to make an actual working GPU using that chip you got from e.g. TSMC. Sometimes (especially in more recent years) they also sell that design as \"founders\" edition. But they don't sell most of their hardware directly to average consumers. Of course they also provide drivers to interface with their chips and tons of libraries for parallel computing that makes the most of their design. Most people don't realize that Nvidia is much more of a software company than a hardware company. CUDA in particular is like 90% of the reason why they are where they are while AMD and Intel struggle to keep up. reply themaninthedark 3 hours agorootparentIt seems that they have been tightening what they allow their partners to do, which caused EVGA to break away as they were not allowed to deviate too much from the reference design. reply sigmoid10 2 hours agorootparentThat was mostly about Nvidia's pricing. It's basically impossible to compete economically with the founders editions because Nvidia doesn't charge themselves a hefty markup on the chip. That's why their own cards always sell out instantly and then the aftermarket GPU builders can fight to pick up the scraps. The whole idea of the founders edition seems to be to make a quick buck immediately after release. Long term it's much more profitable to sell the chip itself at a price that they would usually sell their entire GPU for. reply ThatMedicIsASpy 44 minutes agorootparentThis years founders edition is what I really want from a GPU. Stop wasting my 2nd PCIe slot because you've made it 3.5/4 slots BIG! It is insane that they are now cooling 575W with two slots in height. reply MisoRamen 1 hour agorootparentprevIt is an ever uphill battle to compete with Nvidia as a AIB partner. Nvidia has internal access to the new card way ahead of time, has aerodynamic and thermodynamic simulators, custom engineered boards full of sensors, plus a team of very talented and well paid engineers for months in order to optimize cooler design. Meanwhile AIB partners is pretty much kept in the blind until a few months in advance. It is basically impossible for a company like EVGA to exist as they pride themselves in their customer support - the finances just does not make sense. reply doix 3 hours agorootparentprevYeah I should have said design, embarrassingly I used to work in a (fabless) semiconductor company. Totally agree with the software part. AMD usually designs something in the same ball park as Nvidia, and usually has a better price:performance ratio at many price points. But the software is just too far behind. reply automatic6131 2 hours agorootparentAMDs driver software is more featureful and better than NVidia's offerings. GeForce Experience + the settings app combo was awful, the Nvidia App is just copying some homework, and integrating MSI Afterburner's freeware. But the business software stack was, yes, best in class. But it's not so for the consumer! reply knowitnone 2 hours agorootparentI think they mean CUDA reply nightski 3 hours agorootparentprevI've bought multiple founders editions cards from the nvidia store directly. Did they stop doing that recently? reply SirMaster 3 hours agorootparentprevThey still make reference founders editions. They sell them at Best Buy though, not directly. reply infecto 3 hours agorootparentReference cards make up the vast minority of cards for a specific generation though. I looked for numbers and could not find them but they tend to be the Goldilocks of cards if you can grab one because they sell at msrp IIRC. reply devmor 3 hours agorootparentYep, I scored a 3070 Founder's at launch and was very lucky, watching other people pay up to the MSRP of the 3090 to get one from elsewhere. reply orphea 52 minutes agorootparentprevit's not worth it. I wonder how much \"it's not worth it\". Surely it should have been at all profitable? (a honest question) reply grogenaut 57 minutes agorootparentprevThe founders edition ones that I had were not great gpus. They were both under cooled and over cooled. They had one squirrel cage style blower that was quite loud and powerful and ran bascially at no speed or full blast. But being that it only had the one airpath and one fan it got overwhelmed by dust or if that blower fan had issues the gpu over heated. The consumer / 3rd party made ones usually have multiple fans at lower speeds larger diameter, multiple flow paths, and more control. TL;DR they were better designed, nvidia took the data center ram as much air as you can in there approach which isn't great for your home pc. reply mrweasel 2 hours agorootparentprevDidn't Nvidia piss of some of their board partners at some point. I think EVGA stopped making Nvidia based graphics cards because of poor behavior on Nvidia part? Also aren't most of the business cards made by Nvidia directly... or at least Nvidia branded? reply TrackerFF 2 hours agoparentprevGPUs are in demand. So scalpers want to make a buck on that. All there is to it. Whenever demand surpasses supply, someone will try to make money off that difference. Unfortunately for consumers, that means scalpers use bots to clean out retail stores, and then flip them to consumers. reply diob 1 hour agoparentprevIt is frustrating speaking as someone who grew up poor and couldn't afford anything, and now I finally can and nothing is ever in stock. Such a funny twist of events, but also makes me sad. reply chis 2 hours agoparentprevOne way to look at is that the third party GPU packagers have a different set of expertise. They generally build motherboards, GPU holder boards, RAM, and often monitors and mice as well. All of these product PCBs are cheaply made and don't depend on the performance of the latest TSMC node the way the GPU chips do, more about ticking feature boxes at the lowest cost. So nvidia wouldn't have the connections or skillset to do budget manufacturing of low-cost holder boards the way ASUS or EVGA does. Plus with so many competitors angling to use the same nvidia GPU chips, nvidia collects all the margin regardless. reply brigade 1 hour agorootparentYet the FE versions end up cheaper than third party cards (at least by MSRP), and with fewer issues caused by the third parties cheaping out on engineering… reply zitterbewegung 3 hours agoparentprevThis is supply and demand at work. NVIDIA has to choose to either sell consumer or high end and they can reserve so much resources from TSMC. Also, Apple has outsold hardware before or it has high demand when it releases but for NVIDIA they have nearly constant purchases throughout the year from enterprise and also during consumer product launches. reply blackoil 1 hour agoparentprevMaybe, it is simply a legacy business model. Nvidia wasn't always a behemoth. In olden days they must be happy for someone else to manage the global distribution, marketing, service etc. Also, this gives an illusion of choice. You get graphic cards in different color, shape, RGB, water cooling combinations. reply ggregoire 3 hours agoparentprevI read your question and thought to myself \"why is it so hard to buy a Steamdeck\"? Available only in like 10 countries. Seems like the opposite problem, Valve doesn't use resellers but they can't handle international manufacturing/shipping themselves? At least I can get a Nvidia GPU anytime I want from Amazon, BestBuy or whatever. reply CivBase 3 hours agoparentprevI've always assumed their add-in board (AIB) partners (like MSI, ASUS, Gigabyte, etc) are able to produce PCBs and other components at higher volumes and lower costs than NVIDIA. reply xnyan 2 hours agorootparentNot just the production of the finished boards, but also marketing, distribution to vendors and support/RMA for defective products. There is profit in this, but it’s also a whole set of skills that doesn’t really make sense for Nvidia. reply datadrivenangel 3 hours agoparentprevNvidia uses resellers as distributors. Helps build out a locked in ecosystem. reply ks2048 3 hours agorootparentHow does that help \"build out a locked in ecosystem\"? Again, comparing to Apple: they have a very locked-in ecosystem. reply MoreMoore 3 hours agorootparentI don't think lock-in is the reason. The reason is more that companies like Asus and MSI have a global presence and their products are available on store shelves everywhere. NVIDIA avoids having to deal with building up all the required relationships and distribution, they also save on things like technical support staff and dealing with warranty claims directly with customers across the globe. The handful of people who get an FE card aside. reply pragmar 3 hours agorootparentprevApple locks users in with software/services. nVidia locks in add-in board manufacturers with exclusive arrangements and partner programs that tie access to chips to contracts that prioritize nVidia. It happens upstream of the consumer. It's always a matter of degree with this stuff as to where it becomes anti-trust, but in this case it's overt enough for governments to take notice. reply santoshalper 3 hours agorootparentprevNvidia probably could sell cards directly now, given the strength of their reputation (and the reality backing it up) for graphics, crypto, and AI. However, they grew up as a company that sold through manufacturing and channel partners and that's pretty deeply engrained in their culture. Apple is unusually obsessed with integration, most companies are more like Nvidia. reply blixt 4 hours agoprevPretty interesting watching their tech explainers on YouTube about the changes in their AI solutions. Apparently they switched from CNNs to transformers for upscaling (with ray tracing support) if I understood correctly though for frame generation makes even more sense to me. 32 GB VRAM on the highest end GPU seems almost small after running LLMs with 128 GB RAM on the M3 Max, but the speed will most likely more than make up for it. I do wonder when we’ll see bigger jumps in VRAM though, now that the need for running multiple AI models at once seems like a realistic use case (their tech explainers also mentions they already do this for games). reply terhechte 3 hours agoparentIf you have 128gb ram, try running MoE models, they're a far better fit for Apple's hardware because they trade memory for inference performance. using something like Wizard2 8x22b requires a huge amount of memory to host the 176b model, but only one 22b slice has to be active at a time so you get the token speed of a 22b model. reply FuriouslyAdrift 3 hours agorootparentProject Digits... https://www.nvidia.com/en-us/project-digits/ reply logankeenan 2 hours agorootparentprevDo you have any recommendations on models to try? reply stkdump 1 hour agorootparentMixtral and Deepseek use MOE. Most others don't. reply terhechte 50 minutes agorootparentprevIn addition to the ones listed by others, WizardLM2 8x22b (was never officially released by Microsoft but is available). reply Terretta 1 hour agorootparentprevMixtral 8x22b https://mistral.ai/news/mixtral-8x22b/ reply cma 3 hours agorootparentprevYou can also run the experts on separate machines with low bandwidth networking or even the internet (token rate limited by RTT) reply ActionHank 3 hours agoparentprevThey are intentionally keeping the VRAM small on these cards to force people to buy their larger, more expensive offerings. reply tbolt 3 hours agorootparentMaybe, but if they strapped these with 64gb+ wouldn’t that be wasted on folks buying it for its intended purpose? Gaming. Though the “intended use” is changing and has been for a bit now. reply whywhywhywhy 2 hours agorootparentXX90 is only half a gaming card it's also the one the entire creative professional 3D CGI, AI, game dev industry runs on. reply Aerroon 1 hour agorootparentprevThe only reason gaming doesn't use all the VRAM is because typically GPUs don't have all the VRAM. If they did then games would somehow find a way to use it. reply mox1 2 hours agorootparentprevNot really, the more textures you can put into memory the faster they can do their thing. PC gamers would say that a modern mid-range card (1440p card) should really have 16GB of vram. So a 5060 or even a 5070 with less than that amount is kind of silly. reply knowitnone 2 hours agorootparentprevhmmm, maybe they can had different offerings like 16GB, 32GB, 64GB, etc. Maybe we can even have 4 wheels on a car. reply vonneumannstan 1 hour agorootparentprevNo gamers need such high VRAM, if you're buying Gaming cards for ML work you're doing it wrong. reply riskable 33 minutes agorootparentIt's Nvidia that considers them, \"gaming cards\". The market decides their use in reality though. Their strategy is to sell lower-VRAM cards to consumers with the understanding that they can make more money on their more expensive cards for professionals/business. By doing this, though they're creating a gap in the market that their competitors could fill (in theory). Of course, this assumes their competitors have half a brain cell (I'm looking at YOU, Intel! For fuck's sake give us a 64GB ARC card already!). reply epolanski 21 minutes agorootparentprevGames already exceed 16 GBs at 4k from years. reply hibikir 1 hour agorootparentprevIf the VRAM wasn't small, the cards would all get routed to non gaming uses. Remember the state of the market when the 3000 series was new? reply SideQuark 1 hour agorootparentprevSo you're saying more VRAM costs more money? What a novel idea! Conversely, this means you can pay less if you need less. Seems like a win all around. reply Havoc 3 hours agorootparentprevSaw someone else point out that potentially the culprit here isn’t nvidia but memory makers. It’s still 2gb per chip and has been since forever reply tharmas 2 hours agorootparentGDDR7 apparently has the capability of 3gb per chip. As it becomes more available their could be more VRAM configurations. Some speculate maybe an RTX 5080 Super 24gb release next year. Wishful thinking perhaps. reply marginalia_nu 2 hours agorootparentprevMakes sense. The games industry doesn't want another crypto mining-style GPU shortage. reply tharmas 2 hours agorootparentprevTotally agree. I call this the \"Apple Model\". Just like the Apple Mac base configurations with skimpy RAM and Drive capacities to make the price look \"reasonable\". However, just like Apple, NVIDIA does make really good hardware. reply barbazoo 1 hour agorootparentprevIs there actually less VRAM on the cards or is it just disabled? reply deaddodo 1 hour agorootparentGPU manufacturers have no reason to include additional memory chips of no use on a card. This isn't like a cutdown die, which is a single piece with disabled functionality...the memory chips are all independent (expensive) pieces soldered on board (the black squares surrounding the GPU core): https://cdn.mos.cms.futurecdn.net/vLHed8sBw8dX2BKs5QsdJ5-120... reply quadrature 7 minutes agoparentprevWhy are transformers a better fit for frame generation. Is it because they can better utilize context from the previous history of frames ? reply bick_nyers 4 hours agoparentprevCheck out their project digits announcement, 128GB unified memory with infiniband capabilities for $3k. For more of the fast VRAM you would be in Quadro territory. reply vonneumannstan 1 hour agoparentprevIf you want to run LLMs buy their H100/GB100/etc grade cards. There should be no expectation that consumer grade gaming cards will be optimal for ML use. reply nahnahno 1 hour agorootparentYes there should be. We don’t want to pay literal 10x markup because the card is suddenly “enterprise”. reply resource_waste 2 hours agoparentprev> after running LLMs with 128 GB RAM on the M3 Max, These are monumentally different. You cannot use your computer as an LLM. Its more novelty. I'm not even sure why people mention these things. Its possible, but no one actually does this out of testing purposes. It falsely equates Nivida GPUs with Apple CPUs. The winner is Apple. reply chmod775 2 hours agoprev> will be two times faster [...] thanks to DLSS 4 Translation: No significant actual upgrade. Sounds like we're continuing the trend of newer generations being beaten on fps/$ by the previous generations while hardly pushing the envelope at the top end. A 3090 is $1000 right now. reply intellix 33 minutes agoparentWhy is that a problem though? Newer and more GPU intensive games get to benefit from DLSS 4 and older games already run fine. What games without DLSS support could have done with a boost? I've heard this twice today so curious why it's being mentioned so often. reply epolanski 20 minutes agorootparentWe all know DLSS4 could be compatible with previous gens. Nvidia has done that in the past already (see PhysX). reply chmod775 8 minutes agorootparentprevI for one don't like the DLSS/TAA look at all. Between the lack of sharpness, motion blur and ghosting, I don't understand how people can look at that and consider it an upgrade. Let's not even get into the horror that is frame generation. It's a graphics downgrade that gives me a headache and I turn the likes of TAA and DLSS off in every game I can. I'm far from alone in this. reply Diti 20 minutes agorootparentprev> What games without DLSS support could have done with a boost? DCS World? reply paxys 15 hours agoprevEven though they are all marketed as gaming cards, Nvidia is now very clearly differentiating between 5070/5070 Ti/5080 for mid-high end gaming and 5090 for consumer/entry-level AI. The gap between xx80 and xx90 is going to be too wide for regular gamers to cross this generation. reply ziml77 13 hours agoparentThe 4090 already seemed positioned as a card for consumer AI enthusiast workloads. But this $1000 price gap between the 5080 and 5090 seems to finally cement that. Though we're probably still going to see tons of tech YouTubers making videos specifically about how the 5090 isn't a good value for gaming as if it even matters. The people who want to spend $2000 on a GPU for gaming don't care about the value and everyone else already could see it wasn't worth it. reply dijit 13 hours agorootparentFrom all the communication I’ve had with Nvidia, the prevailing sentiment was that the 4090 was an 8K card, that happened to be good for AI due to vram requirements from 8K gaming. However, I’m a AAA gamedev CTO and they might have been telling me what the card means to me. reply out_of_protocol 8 hours agorootparentWell, modern games + modern cards can't even do 4k at high fps and no dlss. 8k story is totally fairy tale. Maybe \"render at 540p, display at 8k\"-kind of thing? P.S. Also, VR. For VR you need 2x4k at 90+ stable fps. There's (almost) no vr games though reply diggan 5 hours agorootparent> modern games + modern cards can't even do 4k at high fps What \"modern games\" and \"modern cards\" are you specifically talking about here? There are plenty of AAA games released last years that you can do 4K at 60fps with a RTX 3090 for example. reply kllrnohj 4 hours agorootparent> There are plenty of AAA games released last years that you can do 4K at 60fps with a RTX 3090 for example. Not when you turn on ray tracing. Also 60fps is pretty low, certainly isn't \"high fps\" anyway reply robertfall 4 hours agorootparentThis. You can't get high frame rates with path tracing and 4K. It just doesn't happen. You need to enable DLSS and frame gen to get 100fps with more complete ray and path tracing implementations. People might be getting upset because the 4090 is WAY more power than games need, but there are games that try and make use of that power and are actually limited by the 4090. Case in point Cyberpunk and Indiana Jones with path tracing don't get anywhere near 100FPS with native resolution. Now many might say that's just a ridiculous ask, but that's what GP was talking about here. There's no way you'd get more than 10-15fps (if that) with path tracing at 8K. reply kllrnohj 3 hours agorootparent> Case in point Cyberpunk and Indiana Jones with path tracing don't get anywhere near 100FPS with native resolution. Cyberpunk native 4k + path tracing gets sub-20fps on a 4090 for anyone unfamiliar with how demanding this is. Nvidia's own 5090 announcement video showcased this as getting a whopping... 28 fps: https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Ff... reply mastax 3 hours agorootparentprev> Also 60fps is pretty low, certainly isn't \"high fps\" anyway I’m sure some will disagree with this but most PC gamers I talk to want to be at 90FPS minimum. I’d assume if you’re spending $1600+ on a GPU you’re pretty particular about your experience. reply bee_rider 3 hours agorootparentI’m so glad I grew up in the n64/xbox era. You save so much money if you are happy at 30fps. And the games look really nice. reply kllrnohj 2 hours agorootparentYou can also save tons of money by combining used GPUs from two generations ago with a patientgamer lifestyle without needing to resort to suffering 30fps reply marxisttemp 3 hours agorootparentprevI wish more games had an option for N64/Xbox-level graphics to maximize frame rate. No eye candy tastes as good as 120Hz feels. reply bee_rider 3 hours agorootparentI’m sure you could do N64 style graphics at 120Hz on an iGPU with modern hardware, hahaha. I wonder if that would be a good option for competitive shooters. I don’t really mind low frame rates, but latency is often noticeable and annoying. I often wonder if high frame rates are papering over some latency problems in modern engines. Buffering frames or something like that. reply nfriedly 2 hours agorootparentDoom 2016 at 1080p with a 50% resolution scale (so, really, 540p) can hit 120 FPS on an AMD 8840U. That's what I've been doing on my GPD Win Mini, except that I usually cut the TDP down to 11-13W, where it's hitting more like 90-100 FPS. It looks and feels great! reply necheffa 2 hours agorootparentprev> Also 60fps is pretty low, certainly isn't \"high fps\" anyway Uhhhhhmmmmmm....what are you smoking? Almost no one is playing competitive shooters and such at 4k. For those games you play at 1080p and turn off lots of eye candy so you can get super high frame rates because that does actually give you an edge. People playing at 4k are doing immersive story driven games and consistent 60fps is perfectly fine for that, you don't really get a huge benefit going higher. People that want to split the difference are going 1440p. reply lifeformed 55 minutes agorootparentAnyone playing games would benefit from higher frame rate no matter their case. Of course it's most critical for competitive gamers, but someone playing a story driven FPS at 4k would still benefit a lot from framerates higher than 60. For me, I'd rather play a story based shooter at 1440p @ 144Hz than 4k @ 60Hz. reply kllrnohj 40 minutes agorootparentprevGames other than esports shooters and slow paced story games exist, you know. In fact, most games are in this category you completely ignored for some reason. Also nobody is buying a 4090/5090 for a \"fine\" experience. Yes 60fps is fine. But better than that is expected/desired at this price point. reply philjohn 4 hours agorootparentprevThis - latest Call of Duty game on my (albeit water cooled) 3080TI founders edition saw frame rates in the 90-100fps running natively at 4k (no DLSS). reply CobaltFire 11 minutes agorootparentHonestly my water cooled 3080TI FE has been great. Wish it had more VRAM for VR (DCS, MSFS) but otherwise it’s been great. reply bavell 3 hours agorootparentprevCan't CoD do 60+ fps @1080p on a potato nowadays?... not exactly a good reference point. reply CobaltFire 10 minutes agorootparent4k90 is about 6 times that, and he probably has the options turned up. I’d say the comparison is what’s faulty, not the example. marxisttemp 3 hours agorootparentprevYep. Few AAA games can run at 4K60 at max graphics without upscaling or frame gen on a 4090 without at least occasionally dipping below 60. Also, most monitors sold with VRR (which I would argue is table stakes now) are >60FPS. reply Aardwolf 2 hours agorootparentprevWhy does 8K gaming require more VRAM? I think the textures and geometry would have the same resolution (or is that not the case? but in 4K if you walk closer to the wall you'd want higher texture resolution as well anyway, if the graphics artists have made the assets at that resolution anyway) 8K screen resolution requires 132 megabytes of memory to store the pixels (for 32-bit color), that doesn't explain gigabytes of extra VRAM I'd be curious to know what information I'm missing reply Macha 1 hour agorootparentMy understand is between double buffering and multiple sets of intermediate info for shaders, you usually have a bunch of screen size buffers hanging around in VRAM, though you are probably right that these aren't the biggest contributor to VRAM usage in the end. reply dijit 1 hour agorootparentprevYou’re only thinking of the final raster framebuffer, there are multiple raster and shader stages. Increasing the native output has an nearly exponential increase in memory requirements. reply pier25 3 hours agorootparentprevThe 4080 struggles to play high end games at 4k and there aren't that many 8k tvs/monitors in the market... Doesn't make much sense that anyone would think about the 4090 as an 8k GPU to be honest. reply Refusing23 12 hours agorootparentprevSeems kinda silly to make an 8K video card when ... nobody on the planet has an 8K screen reply martiuk 4 hours agorootparent> Seems kinda silly to make a 4K video card when ... nobody on the planet has a 4K screen. Someone else probably said that years ago when everyone was rocking 1080/1440p screens. reply ErneX 2 hours agorootparentIf you look at the Steam hardware survey you’ll find the majority of gamers are still rocking 1080p/1440p displays. What gamers look for is more framerate not particularly resolution. Most new gaming monitors are focusing on high refresh rates. 8K feels like a waste of compute for a very diminished return compared to 4K. I think 8K only makes sense when dealing with huge displays, I’m talking beyond 83 inches, we are still far from that. reply Eloso 3 hours agorootparentprevGaming isn't the only use-case, but Steam hardware survey says ~4% of users are using 4k screens. So the market is still small. reply close04 4 hours agorootparentprevFirst consumer 4K monitors came out more than a decade ago. I think the Asus PQ321 in 2013. That’s close to where we are now with 8K. How many of the cards of that time would you call “4K cards”? Even the Titan X that came a couple of years later doesn’t really cut it. There’s such a thing as being too early to the game. reply gnabgib 12 hours agorootparentprevPerhaps you don't, but several of us do. They've been around a while, available in your local bestbuy/costco if you're rocking a 4:4:4 TV they're not even particularly pricey and great for computing (depending on the subpixel layout). On the planet? Many people. Maybe you're thinking 12K or 16K. reply jkolio 4 hours agorootparentIt's been a few years since I worked at [big tech retailer], but 8K TVs basically didn't sell at the time. There was basically no native content - even the demos were upscaled 4K - and it was very hard to tell the difference between the two unless you were so close to the screen that you couldn't see the whole thing. For the content that was available, either you were dealing with heavy compression or setting up a high-capacity server, since file sizes basically necessitated most of the space on what people would consider a normal-sized hard drive to store just a few movies. The value just wasn't there and probably won't ever be for most use cases. XR equipment might be an exception, video editing another. reply duffyjp 2 hours agorootparentprevI got 4K TVs for both of my kids, they're dirt cheap-- sub $200. I'm surprised the Steam hardware survey doesn't show more. A lot of my friends also set their kids up on TVs, and you can't hardly buy a 1080P TV anymore. reply dijit 12 hours agorootparentprev2018 (6 years ago): https://www.techradar.com/reviews/dell-ultrasharp-up3218k It's uncommon, sure, but as mentioned it was sold to me as being a development board for future resolutions. reply ryao 12 hours agorootparentprevI recall them making the same claims about the 3090: https://www.nvidia.com/en-us/geforce/news/geforce-rtx-3090-8... reply ziml77 12 hours agorootparentprevI do recall an 8K push but I thought that was on the 3090 (and was conditional on DLSS doing the heavy lifting). I don't remember any general marketing about the 4090 being an 8K card but I could very well have missed it or be mixing things up! I mean it does make sense to market it for 8K since anyone who is trying to drive that many pixels when gaming probably has deep pockets. reply ryao 12 hours agorootparentI recall the 3090 8K marketing too. However, I also recall Nvidia talking about 8K in reference to the 4090: https://www.nvidia.com/en-us/geforce/technologies/8k/ That said, I recall that the media was more enthusiastic about christening the 4090 as an 8K card than Nvidia was: https://wccftech.com/rtx-4090-is-the-first-true-8k-gaming-gp... reply ryao 12 hours agorootparentprevIf I recall correctly, the 3090, 3090 Ti and 4090 were supposed to replace the Titan cards that had been Nvidia's top gaming cards, but were never meant for gaming. reply KMnO4 4 hours agorootparentSomeone very clever at Nvidia realized that if they rename their professional card (Titan) to be part of their \"gaming\" line, you can convince adults with too much disposable income that they need it to play Elden Ring. I didn't know of anyone who used the Titan cards (which were actually priced cheaper than their respective xx90 cards at release) for gaming, but somehow people were happy spending >$2000 when the 3090 came out. reply Cumpiler69 3 hours agorootparent>but somehow people were happy spending >$2000 when the 3090 came out Of course they did, the 3090 came out at the height of the pandemic and crypto boom in 2020, when people were locked indoors with plenty of free time and money to spare, what else where they gonna spend it on? reply angled 13 hours agorootparentprevI wonder if these will be region-locked (eg, not for HK SAR). reply epolanski 19 minutes agoparentprevYou underestimate how many gamers got a 4090. reply oliwarner 9 hours agoparentprevThe only difference is scalar. That isn't differentiating, that's segregation. It won't stop crypto and LLM peeps from buying everything (one assumes TDP is proportional too). Gamers not being able to find an affordable option is still a problem. reply officeplant 2 hours agorootparent>Gamers not being able to find an affordable option is still a problem. Used to think about this often because I had a side hobby of building and selling computers for friends and coworkers that wanted to get into gaming, but otherwise had no use for a powerful computer. For the longest time I could still put together $800-$1000 PC's that could blow consoles away and provide great value for the money. Now days I almost want to recommend they go back to console gaming. Seeing older ps5's on store shelves hit $349.99 during the holidays really cemented that idea. Its so astronomically expensive for a PC build at the moment unless you can be convinced to buy a gaming laptop on a deep sale. reply dolni 1 hour agorootparentOne edge that PCs have is massive catalog. Consoles have historically not done so well with backwards compatibility (at most one generation). I don't do much console gaming but _I think_ that is changing. There is also something to be said about catalog portability via something like a Steam Deck. reply foobarian 2 hours agorootparentprevAre crypto use cases still there? I thought that went away after eth switched their proof model. reply oliwarner 18 minutes agorootparentBitcoin is still proof of work. reply ffsm8 9 hours agoparentprevThe price of a 4090 already was ~1800-2400€ where I live (not scalper prices, the normal online Shops) We'll have to see how much they'll charge for these cards this time, but I feel like the price bump has been massively exaggerated by people on HN reply BigJ1211 4 hours agorootparentMSRP went from 1959,- to 2369,-. That's quite the increase. reply kcb 14 hours agoparentprevYup, the days of the value high end card are dead it seems like. I thought we would see a cut down 4090 at some point last generation but it never happened. Surely there's a market gap somewhere between 5090 and 5080. reply ryao 12 hours agorootparentThe xx90 cards are really Titan cards. The 3090 was the successor to the Titan RTX, while the 3080 Ti was the successor to the 2080 Ti, which succeeded the 1080 Ti. This succession continued into the 40 series and now the 50 series. If you consider the 2080 Ti to be the \"value high end card\" of its day, then it would follow that the 5080 is the value high end card today, not the 5090. reply kcb 5 hours agorootparentIn all those historical cases the second tier card was a cut down version of the top tier one. Now the 4080 and 5080 are a different chip and there's a gulf of a performance gap between them and the top tier. That's the issue I am highlighting, the 5080 is half a 5090, in the past a 3080 was only 10% off a 3090 performance wise. reply smallmancontrov 14 hours agorootparentprevYes, but Nvidia thinks enough of them get pushed up to the 5090 to make the gap worthwhile. Only way to fix this is for AMD to decide it likes money. I'm not holding my breath. reply FuriouslyAdrift 3 hours agorootparentAMD announced they aren't making a top tier card for the next generation and is focusing on mid-tier. Next generation, the are finally reversing course and unifying their AI and GPU architectures (just like nVidia). 2026 is the big year for AMD. reply officeplant 2 hours agorootparentAMD's GPU marketing during CES has been such a shit show. No numbers, just adjectives and vibes. They're either hiding their hand, or they continue to have nothing to bring to the table. Meanwhile their CPU marketing has numbers and graphs because their at the top of their game and have nothing to hide. I'm glad they exist because we need the competition, but the GPU market continues to look dreary. At least we have a low/mid range battle going on between the three companies to look forward to for people with sensible gaming budgets. reply kaibee 14 hours agorootparentprevDon't necessarily count Intel out. reply romon 14 hours agorootparentIntel is halting its construction of new factories and mulling over whether to break up the company... reply User23 13 hours agorootparentIntel's Board is going full Kodak. reply 63 13 hours agorootparentprevI wouldn't count Intel out in the long term, but it'll take quite a few generations for them to catch up and who knows what the market will be like by then reply blitzar 8 hours agorootparentprevIntel hate making money even more than AMD. reply FuriouslyAdrift 3 hours agorootparentIntel's Arc B580 budget card is selling like hotcakes... https://www.pcworld.com/article/2553897/intel-arc-b580-revie... reply blitzar 3 hours agorootparentThey fired the CEO for daring to make a product such as this. The 25mil they paid to get rid of him might even wipe out their profits on this product. reply hylaride 4 hours agorootparentprevStarting around 2000, Intel tried to make money via attempts at everything but making a better product (pushing RAMBUS RAM, itanium, cripling low-end chips more than they needed to be, focusing more on keeping chip manufacturing in-house thereby losing out on economy of scale). The result was engineers were (not always, but too often) nowhere near the forefront of technology. Now AMD, NVIDIA, ARM are all chipping away (pun intended). It's not dissimilar to what happened to Boeing. I'm a capitalist, but the current accounting laws (in particular corporate taxation rules) mean that all companies are pushed to use money for stock buybacks than R&D (which Intel spent more on the former over the latter over the past decade and I'm watching Apple stagnate before my eyes). reply ryao 13 hours agoparentprevThe 3090 and 3090 Ti both support software ECC. I assume that the 4090 has it too. That alone positions the xx90 as a pseudo-professional card. reply gregoryl 13 hours agorootparentThe 4090 indeed does have ecc support reply sliken 13 hours agorootparentYes, but ECC is inline, so it costs bandwidth and memory capacity. reply fulafel 11 hours agorootparentDoesn't it always. (Except sometimes on some hw you can't turn it off) reply sliken 10 hours agorootparentI believe the cards that are intended for compute instead of GPU default to ECC being on and report memory performance with the overheads included. reply FuriouslyAdrift 3 hours agorootparentAnything with DDR5 or above has built in limited ECC... it's required by the spec. https://www.corsair.com/us/en/explorer/diy-builder/memory/is... reply sliken 3 hours agorootparentSure, but it's very limited. It doesn't detect or fix errors in the dimm (outside the chips), motherboard traces, CPU socket, or CPU. reply simondotau 13 hours agoparentprevNvidia is also clearly differentiating the 5090 as the gaming card for people who want the best and an extra thousand dollars is a rounding error. They could have sold it for $1500 and still made big coin, but no doubt the extra $500 is pure wealth tax. It probably serves to make the 4070 look reasonably priced, even though it isn't. reply epolanski 15 minutes agorootparentGaming enthusiasts didn't beat an eye at 4090 price and won't beat one there either. 4090 was already priced for high income (in first world countries) people. Nvidia saw 4090s were being sold on second hand market way beyond 2k. They merely milking the cow. reply sliken 10 hours agorootparentprevDouble the bandwidth, double the ram, double the pins, and double the power isn't cheap. I wouldn't be surprised if the profit on the 4090 was less than the 4080, especially since any R&D costs will be spread over significantly less units. reply formerly_proven 7 hours agorootparentThere have been numerous reports over the years that the 4090 actually outsold the 4080. reply BigJ1211 4 hours agorootparentThe 4080 was also quite the bad value compared to the much better 4090. That remains to be seen for the 5000 series. reply ryao 13 hours agorootparentprevLeaks indicate that the PCB has 14 layers with a 512-bit memory bus. It also has 32GB of GDDR7 memory and the die size is expected to be huge. This is all expensive. Would you prefer that they had not made the card and instead made a lesser card that was cheaper to make to avoid the higher price? That is the AMD strategy and they have lower prices. reply simondotau 13 hours agorootparentThat PCB is probably a few dollars per unit. The die is probably the same as the one in the 5070. I've no doubt it's an expensive product to build, but that doesn't mean the price is cost plus markup. reply shadowpho 1 hour agorootparent>That PCB is probably a few dollars per unit. It’s not. 14L PCB are expensive. When I looked at Apple cost for their PCB it was probably closer to $50, and they have smaller area reply ryao 13 hours agorootparentprevCurrently, the 5070 is expected to use the GB205 die while the 5090 is expected to use the GB202 die: https://www.techpowerup.com/gpu-specs/geforce-rtx-5070.c4218 https://www.techpowerup.com/gpu-specs/geforce-rtx-5090.c4216 It is unlikely that the 5070 and 5090 share the same die when the 4090 and 4080 did not share same die. Also, could an electrical engineer estimate how much this costs to manufacture: https://videocardz.com/newz/nvidia-geforce-rtx-5090-pcb-leak... reply positr0n 12 hours agorootparentIs the last link wrong? It doesn't mention cost. reply ryao 12 hours agorootparentThe PCB cost did not leak. We need an electrical engineer to estimate the cost based on what did leak. reply lz400 13 hours agoparentprevHow will a 5090 compare against project digits? now that they're both in the front page :) reply ryao 12 hours agorootparentWe will not really know until memory bandwidth and compute numbers are published. However, Project Digits seems like a successor to the NVIDIA Jetson AGX Orin 64GB Developer Kit, which was based on the Ampere architecture and has 204.8GB/sec memory bandwidth: https://www.okdo.com/wp-content/uploads/2023/03/jetson-agx-o... The 3090 Ti had about 5 times the memory bandwidth and 5 times the compute capability. If that ratio holds for blackwell, the 5090 will run circles around it when it has enough VRAM (or you have enough 5090 cards to fit everything into VRAM). reply lz400 11 hours agorootparentVery interesting, thanks! 32gb for the 5090 vs 128gb for digits might put a nasty cap on unleashing all that power for interesting models. Several 5090s together would work but then we're talking about multiple times the cost (4x$2000+PC VS $3000) reply ryao 11 hours agorootparentInference presumably will run faster on a 5090. If the 5x memory bandwidth figure holds, then token generation would run 5 times faster. That said, people in the digits discussion predict that the memory bandwidth will be closer to 546GB/sec, which is closer to 1/3 the memory bandwidth of the 5090, so a bunch of 5090 cards would only run 3 times faster at token generation. reply whalesalad 12 hours agoparentprevIt’s the same pricing from last year. This already happened. reply voidUpdate 3 hours agoprevOoo, that means its probably time for me to get a used 2080, or maybe even a 3080 if I'm feeling special reply Macha 2 hours agoparentThe 2080 was a particularly poor value card, especially when considering the small performance uplift and the absolute glut of 1080 Tis that were available. A quick look on my local ebay also indicates they're both around the €200-250 range for used buy it now, so it seems to make way more sense to go to a 3080. reply qingcharles 9 minutes agorootparent2080 TI though is a really good sweet spot for price/performance. reply Kelteseth 2 hours agoparentprevWhy not go for AMD? I just got a 7900XTX for 850 euros, it runs ollama or comfyUI via WSl2 quite nicely. reply orphea 39 minutes agorootparentAMD driver quality is crap. I upgraded from GTX 1080 to RX 6950 XT because I found a good deal and I didn't want to support nvidia's scammy bullshit of launching inferior GPUs under the same names. Decided to go with AMD this time, and I had everything: black screens, resolution drops to 1024x768, total freezes, severe lags in some games (BG3) unless I downgrade the driver to a very specific version. reply whywhywhywhy 2 hours agorootparentprevPointless putting yourself through the support headaches or having to wait for support to arrive to save a few dollars because the rest of the community is running Nvidia reply Kelteseth 1 hour agorootparentNah it's quite easy these days. Ollama runs perfectly fine on Windows, comfyUI still has some not ported requirements, so you have to do stuff through WSL2. reply viraj_shah 1 hour agorootparentprevDo you have a good resource for learning what kinds of hardware can run what kinds of models locally? Benchmarks, etc? I'm also trying to tie together different hardware specs to model performance, whether that's training or inference. Like how does memory, VRAM, memory bandwidth, GPU cores, etc. all play into this. Know of any good resources? Oddly enough I might be best off asking an LLM. reply Kelteseth 1 hour agorootparentI tested ollama with 7600XT at work and the mentioned 7900XTX. Both run fine with their VRAM limitations. So you can just switch between different quantization of llama 3.1 or the vast amount of different models at https://ollama.com/search reply holoduke 1 hour agorootparentprevTo prevent custom implementations is recommended to get a Nvidia card. Minimum 3080 to get some results. But if you want video you should go for either 4090 or 5090. ComfUI is a popular interface which you can use for graphical stuff. Images and videos. Local text models I would recommend to use the Misty app. Basically a wrapper and downloader for various models. Tons of youtube videos on how to achieve stuff. reply vonneumannstan 1 hour agoparentpreva 4070 has much better performance for much cheaper than a 3080... reply rtkwe 1 hour agorootparentAny the 4070 Super is relatively available too. I just bought one with only a small amount of hunting. Bought it right off of Best Buy, originally tried going to the Microcenter near my parent's house while I was down there but should have bought the card online for pickup. In the 2 days between my first check and arriving at the store ~20 cards sold. reply ryao 13 hours agoprevThe most interesting news is that the 5090 Founders' Edition is a 2-slot card according to Nvidia's website: https://www.nvidia.com/en-us/geforce/graphics-cards/50-serie... When was the last time Nvidia made a high end GeForce card use only 2 slots? reply _boffin_ 3 hours agoparentDonno why I feel this, but probably going to end up being 2.5 slots reply matja 2 hours agoparentprevThe integrator decides the form factor, not NVIDIA, and there were a few 2-slot 3080's with blower coolers. Technically water-cooled 40xx's can be 2-slot also but that's cheating. reply archagon 13 hours agoparentprevFantastic news for the SFF community. (Looks like Nvidia even advertises an \"SFF-Ready\" label for cards that are small enough: https://www.nvidia.com/en-us/geforce/news/small-form-factor-...) reply kllrnohj 4 hours agorootparentIt's a dual flow-through design, so some SFF cases will work OK but the typical sandwich style ones probably won't even though it'll physically fit reply sliken 13 hours agorootparentprevNot really, 575 watts for the GPU is going to make it tough to cool or provide power for. reply archagon 13 hours agorootparentThere are 1000W SFX-L (and probably SFX) PSUs out there, and console-style cases provide basically perfect cooling through the sides. The limiting factor really is slot width. (But I'm more eyeing the 5080, since 360W is pretty easy to power and cool for most SFF setups.) reply jsheard 15 hours agoprev32GB of GDDR7 at 1.8TB/sec for $2000, best of luck to the gamers trying to buy one of those while AI people are buying them by the truckload. Presumably the pro hardware based on the same silicon will have 64GB, they usually double whatever the gaming cards have. reply Hilift 3 hours agoparent100% you will be able to buy them. And receive a rock in the package from Amazon. reply codespin 14 hours agoparentprevAt what point do we stop calling them graphics cards? reply WillPostForFood 4 hours agorootparentWe've looped back to the \"math coprocessor\" days. https://en.wikipedia.org/wiki/Coprocessor reply avaer 14 hours agorootparentprevAt what point did we stop calling them phones? reply Whatarethese 14 hours agorootparentCompute cards, AI Cards, or Business Cards. I like business cards, I'm going to stick with that one. Dibs. reply stackghost 14 hours agorootparentLet's see Paul Allen's GPU. reply benreesman 14 hours agorootparentOh my god. It even has a low mantissa FMA. reply blitzar 8 hours agorootparentThe tasteful thickness of it. reply aaronmdjones 1 hour agorootparentNice. reply paxys 14 hours agorootparentprevNvidia literally markets H100 as a \"GPU\" (https://www.nvidia.com/en-us/data-center/h100/) even though it wasn't built for graphics and I doubt there's a single person or company using one to render any kind of graphics. GPU is just a recognizable term for the product category, and will keep being used. reply robotnikman 1 hour agorootparentThe Amazon reviews for the H100 are amusing https://www.amazon.com/NVIDIA-Hopper-Graphics-5120-Bit-Learn... reply ryao 12 hours agorootparentprevSomeone looked into running graphics on the A100, which is the H100's predecessor. He found that it supports OpenGL: https://www.youtube.com/watch?v=zBAxiQi2nPc I assume someone is doing rendering on them given the OpenGL support. In theory, you could do rendering in CUDA, although it would be missing access to some of the hardware that those who work with graphics APIs claim is needed for performance purposes. reply philistine 13 hours agorootparentprevGeneral Purpose Unit. reply taskforcegemini 4 hours agorootparentGeneral Processing Unit? reply Y-bar 4 hours agorootparentGeneral Contact Unit (Very Little Gravitas Indeed). reply MuffinFlavored 4 hours agorootparentprevHow long until a \"PC\" isn't CPU + GPU but just a GPU? I know CPUs are good for some things that GPUs aren't and vice versa but... it really kind of makes you wonder. Press the power button, boot the GPU? Surely a terrible idea, and I know system-on-a-chip makes this more confusing/complicated (like Apple Silicon, etc.) reply jerf 2 hours agorootparentNever. You can to a first approximation model a GPU as a whole bunch of slow CPUs harnessed together and ordered to run the same code at the same time, on different data. When you can feed all the slow CPUs different data and do real work, you get the big wins because the CPU count times the compute rate will thrash what CPUs can put up for that same number, due to sheer core count. However, if you are in an environment where you can only have one of those CPUs running at once, or even a small handful, you're transported back to the late 1990s in performance. And you can't speed them up without trashing their GPU performance because the optimizations you'd need are at direct odds with each other. CPUs are not fast or slow. GPUs are not fast or slow. They are fast and slow for certain workloads. Contra popular belief, CPUs are actually really good at what they do, and the workloads they are fast at are more common than the workloads that GPUs are fast at. There's a lot to be said for being able to bring a lot of power to bear on a single point, and being able to switch that single point reasonably quickly (but not instantaneously). There's also a lot to be said for having a very broad capacity to run the same code on lots of things at once, but it definitely imposes a significant restriction on the shape of the problem that works for. I'd say that broadly speaking, CPUs can make better GPUs than GPUs can make CPUs. But fortunately, we don't need to choose. reply robin_reala 3 hours agorootparentprev“Press the power button, boot the GPU” describes the Raspberry Pi. reply jampekka 3 hours agorootparentprevProbably never if the GPU architecture resembles anything like they currently are. reply nickpsecurity 13 hours agorootparentprevIt's a good question. I'll note that, even in the GPGPU days (eg BrookGPU), they were architecturally designed for graphics applications (eg shaders). The graphics hardware was being re-purposed to do something else. It was quite a stretch to do the other things compared to massively-parallel, general-purpose designs. They started adding more functionality to them, like physics. Now, tensors. While they've come a long way, I'd imagine they're still highly specialized compared to general-purpose hardware and maybe still graphics-oriented in many ways. One could test this by comparing them to SGI-style NUMA machines, Tilera's tile-based systems, or Adapteva's 1024-core design. Maybe Ambric given it aimed for generality but Am2045's were DSP-style. They might still be GPU's if they still looked more like GPU's side by side with such architectures. reply ryao 11 hours agorootparentGPUs have been processing “tensors” for decades. What they added that is new is explicit “tensor” instructions. A tensor operation is a generalization of a matrix operation to include higher order dimensions. Tensors as used in transformers do not use any of those higher order dimensions. They are just simple matrix operations (either GEMV or GEMM, although GEMV can be done by GEMM). Similarly, vectors are matrices, which are tensors. We can take this a step further by saying scalars are vectors, which are matrices, which are tensors. A scalar is just a length 1 vector, which is a 1x1 matrix, which is a tensor with all dimensions set to 1. As for the “tensor” instructions, they compute tiles for GEMM if I recall my read of them correctly. They are just doing matrix multiplications, which GPUs have done for decades. The main differences are that you do not need need to write code to process the GEMM tile anymore as doing that is a higher level operation and this applies only to certain types introduced for AI while the hardware designers expect code using FP32 or FP64 to process the GEMM tile the old way. reply nickpsecurity 5 hours agorootparentThanks for the correction and insights! reply msteffen 12 hours agorootparentprevI mean HPC people already call them accelerators reply ryao 13 hours agoparentprevDo they double it via dual rank or clamshell mode? It is not clear which approach they use. reply wruza 4 hours agoparentprevWhy do you need one of those as a gamer? 1080ti was 120+ fps in heavy realistic looking games. 20xx RT slashed that back to 15 fps, but is RT really necessary to play games? Who cares about real-world reflections? And reviews showed that RT+DLSS introduced so many artefacts sometimes that the realism argument seemed absurd. Any modern card under $1000 is more than enough for graphics in virtually all games. The gaming crisis is not in a graphics card market at all. reply pknomad 52 minutes agorootparentYou need as much FPS as possible for certain games for competitive play like Counter Strike. I went from 80 FPS (highest settings) to 365 FPS (capped to my alienware 360hz monitor) when I upgraded from my old rig (i7-8700K and 1070GTX) to a new one ( 7800X3D and 3090 RTX) reply nullandvoid 4 hours agorootparentprevMany people are running 4k resolution now, and a 4080 struggles to to break 100 frames in many current games maxed (never-mind future titles) - therefore there's plenty of a market with gamers and the 5x series (myself included) who are looking for closer to 4090 performance at a non obscene price. reply rane 3 hours agorootparentprev1080ti is most definitely not powerful enough to play modern games at 4k 120hz. reply agloe_dreams 3 hours agorootparentprevA bunch of new games are RT-only. Nvidia has aggressively marketed on the idea that RT, FG, and DLSS are \"must haves\" in game engines and that 'raster is the past'. Resolution is also a big jump. 4K 120Hz in HDR is rapidly becoming common and the displays are almost affordable (esp. so for TV-based gaming). In fact, as of today, Even the very fastest RTX 4090 cannot run CP2077 at max non-RT settings and 4K at 120fps. Now, I do agree that $1000 is plenty for 95% of gamers, but for those who want the best, Nvidia is pretty clearly holding out intentionally. The gap between a 4080TI and a 4090 is GIANT. Check this great comparison from Tom's Hardware: https://cdn.mos.cms.futurecdn.net/BAGV2GBMHHE4gkb7ZzTxwK-120... The biggest next-up offering leap on the chart is 4090. reply wruza 59 minutes agorootparentI'm an ex-gamer, pretty recent ex-, and I own 4070Ti currently (just to show I'm not a grumpy GTX guy). Max settings are nonsensical. You never want to spend 50% of frame budget on ASDFAA x64. Lowering AA alone to barely noticeable levels makes a game run 30-50% faster*. Anyone who chooses a graphics card may watch benchmarks and basically multiply FPS by 1.5-2 because that's what playable settings will be. And 4K is a matter of taste really, especially in \"TV\" segment where it's a snakeoil resolution more than anything else. * also you want to ensure your CPU doesn't C1E-power-cycle every frame and your frametimes don't look like EKG. There's much more to performance tuning than just buying a $$$$$ card. It's like installing a V12 engine into a rusted fiat. If you want performance, you want RTSS, AB, driver settings, bios settings, then 4090. reply me551ah 3 hours agorootparentprev> Any modern card under $1000 is more than enough for graphics in virtually all games I disagree. I run a 4070 Super, Ryzen 7700 with DDR5 and I still cant run Asseto Corsa Competizione in VR at 90fps. MSFS 2024 runs at 30 something fps at medium settings. VR gaming is a different beast reply Vampiero 1 hour agorootparentSpending $2 quadrillion on a GPU won't fix poor raster performance which is what you need when you're rendering two frames side by side. Transistors only get so small before AI slop is sold as an improvement. reply some_random 2 hours agorootparentprevIt's a leisure activity, \"necessary\" isn't the metric to be used here, people clearly care about RT/PT while DLSS seems to be getting better and better. reply ErneX 2 hours agorootparentprevThese are perfect for games featuring path tracing. Not many games though but those really flex the 4090. reply berbec 2 hours agorootparentprevI get under 50fps in certain places in FF14. I run a 5900x with 32GB of ram and a 3090. reply bowsamic 4 hours agorootparentprev> is RT really necessary to play games? Who cares about real-world reflections? I barely play video games but I definitely do reply Vampiero 1 hour agorootparentIndeed you're not a gamer, but you're the target audience for gaming advertisements and $2000 GPUs. I still play traditional roguelikes from the 80s (and their modern counterparts) and I'm a passionate gamer. I don't need a fancy GPU to enjoy the masterpieces. Because at the end of the day nowhere in the definition of \"game\" is there a requirement for realistic graphics -- and what passes off as realistic changes from decade to decade anyway. A game is about gameplay, and you can have great gameplay with barely any graphics at all. I'd leave raytracing to those who like messing with GLSL on shadertoy; now people like me have 0 options if they want a good budget card that just has good raster performance and no AI/RTX bullshit. And ON TOP OF THAT, every game engine has turned to utter shit in the last 5-10 years. Awful performance, awful graphics, forced sub-100% resolution... And in order to get anything that doesn't look like shit and runs at a passable framerate, you need to enable DLSS. Great reply thefz 9 hours agoprev> GeForce RTX 5070 Ti: 2X Faster Than The GeForce RTX 4070 Ti 2x faster in DLSS. If we look at the 1:1 resolution performance, the increase is likely 1.2x. reply alkonaut 5 hours agoparentThat's what I'm wondering. What's the actual raw render/compute difference in performance, if we take a game that predates DLSS? reply thefz 3 hours agorootparentWe shall wait for real world benchmarks to address the raster performance increase. The bold claim \"5070 is like a 4090 at 549$\" is quite different if we factor in that it's basically in DLSS only. reply kllrnohj 2 hours agorootparentit's actually a lot worse than it sounds even. The 5070 is like a 4090 is when the 5070 has multi frame generation on and the 4090 doesn't. So it's not even comparable levels of DLSS, the 5070 is hallucinating 2x+ more frames than the 4090 is in that claim reply izacus 1 hour agorootparentprevBased on non-DLSS tests, it seems like a respectable ~25%. reply glimshe 15 hours agoprevLet's see the new version of frame generation. I enabled DLSS frame generation on Diablo 4 using my 4060 and I was very disappointed with the results. Graphical glitches and partial flickering made the game a lot less enjoyable than good old 60fps with vsync. reply roskelld 45 minutes agoparentThere's some very early coverage on Digital Foundry where they got to look at the 5080 and Cyberpunk. https://youtu.be/xpzufsxtZpA reply evantbyrne 4 hours agoparentprevThe main edge Nvidia has in gaming is ray tracing performance. I'm not playing any RT heavy titles and frame gen being a mixed bag is why I saved my coin and got a 7900 XTX. reply ziml77 13 hours agoparentprevThe new DLSS 4 framegen really needs to be much better than what's there in DLSS 3. Otherwise the 5070 = 4090 comparison won't just be very misleading but flatly a lie. reply sliken 10 hours agorootparentSeems like pretty heavily stretched truth. Looks like the actual performance uplift is more like 30%. The 5070=4090 comes from generating multiple fake frames per actual frame and using different versions of DLSS on the cards. Multiple frame generation (required for 5070=4090) increases latency between user input and updated pixels and can also cause artifacts when predictions don't match what the game engine would display. As always wait for fairer 3rd party reviews that will compare new gen cards to old gen with the same settings. reply jakemoshenko 1 hour agorootparent> Multiple frame generation (required for 5070=4090) increases latency between user input and updated pixels Not necessarily. Look at the reprojection trick that lots of VR uses to double framerates with the express purpose of decreasing latency between user movements and updated perspective. Caveat: this only works for movements and wouldn't work for actions. reply lxdlam 10 hours agoprevI have a serious question about the term \"AI TOPS\". I find many conflicting definitions while others say nothing. A meaningful metric should at least be well defined on its own term, like in \"TOPS\" or expanded \"Tera Operations Per Second\", what operation it will measure? Seemingly NVIDIA is just playing number games, like wow 3352 is a huge leap compared to 1321 right? But how does it really help us in LLMs, diffusion models and so on? reply diggan 5 hours agoparentIt would be cool if something like vast.ai's \"DLPerf\" would become popular enough for the hardware producers to start using it too. > DLPerf (Deep Learning Performance) - is our own scoring function. It is an approximate estimate of performance for typical deep learning tasks. Currently, DLPerf predicts performance well in terms of iters/second for a few common tasks such as training ResNet50 CNNs. For example, on these tasks, a V100 instance with a DLPerf score of 21 is roughly ~2x faster than a 1080Ti with a DLPerf of 10. [...] Although far from perfect, DLPerf is more useful for predicting performance than TFLops for most tasks. https://vast.ai/faq#dlperf reply PaulKeeble 15 hours agoprevLooks like most of the improvement is only going to come when DLSS4 is in use and its generating most of the frame for Ray Tracing and then also generating 3 predicted frames. When you use all that AI hardware then its maybe 2x, but I do wonder how much fundamental rasterisation + shaders performance gain there is in this generation in practice on the majority of actual games. reply jroesch 14 hours agoparentThere was some solid commentary on the Ps5Pro tech talk stating core rendering is so well optimized much of the gains in the future will come from hardware process technology improvements not from radical architecture changes. It seems clear the future of rendering is likely to be a world where the gains come from things like dlss and less and free lunch savings due to easy optimizations. reply jayd16 14 hours agorootparentNanite style rendering still seems fairly green. That could take off and they decide to re-implement the software rasterization in hardware. reply jms55 14 hours agorootparentRaster is believe it or not, not quite the bottleneck. Raster speed definitely _matters_, but it's pretty fast even in software, and the bigger bottleneck is just overall complexity. Nanite is a big pipeline with a lot of different passes, which means lots of dispatches and memory accesses. Same with material shading/resolve after the visbuffer is rendered. EDIT: The _other_ huge issue with Nanite is overdraw with thin/aggregate geo that 2pass occlusion culling fails to handle well. That's why trees and such perform poorly in Nanite (compared to how good Nanite is for solid opaque geo). There's exciting recent research in this area though! https://mangosister.github.io/scene_agn_site. reply kllrnohj 4 hours agoparentprev> but I do wonder how much fundamental rasterisation + shaders performance gain there is in this generation in practice on the majority of actual games. likely 10-30% going off of both the cuda core specs (nearly unchanged gen/gen for everything but the 5090) as well as the 2 benchmarks Nvidia published that didn't use dlss4 multi frame gen - Far Cry 6 & A Plague Tale https://www.nvidia.com/en-us/geforce/graphics-cards/50-serie... reply DimmieMan 14 hours agoparentprevYeah I’m not holding my breath if they aren’t advertising it. I’m expecting a minor bump that will look less impressive if you compare it to watts, these things are hungry. It’s hard to get excited when most of the gains will be limited to a few new showcase AAA releases and maybe an update to a couple of your favourites if your lucky. reply coffeebeqn 13 hours agorootparentIt feels like GPUs are now well beyond what game studios can put out. Consoles are stuck at something like RTX 2070 levels for some years still. I hope Nvidia puts out some budget cards for 50 series reply DimmieMan 10 hours agorootparentAt the same time they’re still behind demand as most of the pretty advertising screenshots and frame rate bragging have been behind increasingly aggressive upscaling. On pc you can turn down the fancy settings at least but For consoles I wonder if we’re now in the smudgy upscale era like overdone bloom or everything being brown. reply yakaccount4 14 hours agoparentprev3 Generated frames sounds like a lot of lag, probably a sickening amount for many games. The magic of \"blackwell flip metering\" isn't quite described yet. reply dagmx 14 hours agorootparentIt’s 3 extrapolated frames not interpolated. So would be reduced lag at the expense of greater pop-in. There’s also the new reflex 2 which uses reprojection based on mouse motion to generate frames that should also help, but likely has the same drawback. reply kllrnohj 4 hours agorootparent> It’s 3 extrapolated frames not interpolated. So would be reduced lag at the expense of greater pop-in. it's certainly not reduced lag relative to native rendering. It might be reduced relative to dlss3 frame gen though. reply perching_aix 10 hours agorootparentprev> It’s 3 extrapolated frames not interpolated. Do you have a source for this? Doesn't sound like a very good idea. Nor do I think there's additional latency mind you, but not because it's not interpolation. reply gruez 1 hour agorootparenthttps://www.nvidia.com/content/dam/en-zz/Solutions/geforce/n... reply vel0city 3 hours agorootparentprevInterpolation means you have frame 1 and frame 2, now compute the interstitial steps between these two. Extrapolation means you have frame 1, and sometime in the future you'll get a frame 2. But until then, take the training data and the current frame and \"guess\" what the next few frames will be. Interpolation requires you to have the final state between the added frames, extrapolation means you don't yet know what the final state will be but you'll keep drawing until you get there. You shouldn't get additional latency from generating, assuming it's not slowing down the traditional render generation pipeline. reply perching_aix 2 hours agorootparentI understand this - doesn't address anything of what I said. reply dagmx 4 hours agorootparentprevhttps://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-... reply perching_aix 2 hours agorootparentCould you please point out where on that page does it say anything about \"extrapolation\"? Searched for the (beginning of the) word directly and even gave all the text a skim, didn't catch anything of the sort. reply WeylandYutani 14 hours agoparentprevLike with how you cannot distinguish reality from CGI in movies DLSS will also become perfected over the years. reply malnourish 15 hours agoprevI will be astonished if I'll be able to get a 5090 due to availability. The 5080's comparative lack of memory is a buzzkill -- 16 GB seems like it's going to be a limiting factor for 4k gaming. Does anyone know what these might cost in the US after the rumored tariffs? reply stego-tech 14 hours agoparentHonestly, with how fast memory is being consumed nowadays and the increased focus on frame generation/interpolation vs “full frames”, I’ll keep my 3090 a little longer instead of upgrading to a 5080 or 5090. It’s not the fastest, but it’s a solid card even in 2025 for 1440p RT gaming on a VRR display, and the memory lets me tinker with LLMs without breaking a sweat. If DLSS4 and “MOAR POWAH” are the only things on offer versus my 3090, it’s a hard pass. I need efficiency, not a bigger TDP. reply lemoncookiechip 3 hours agorootparentDLSS4 is coming to other RTX cards, eventually. https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-... reply ryao 13 hours agorootparentprevPricing for the next generation might be somewhat better if Nvidia switches to Samsung for 2nm like the rumors suggest: https://wccftech.com/nvidia-is-rumored-to-switch-towards-sam... Coincidentally, the 3090 was made using Samsung's 8nm process. You would be going from one Samsung fabricated GPU to another. reply lordofgibbons 13 hours agorootparentNVidia's pricing isn't based on how much it takes to produce their cards, but since they have no competition, it's purely based on how much consumers are grudgingly willing to pay up. If AMD continues to sleep, they'll sale these cards for the same price, even if they could produce them for free. reply Yeul 4 hours agorootparentAMD is not sleeping. They publicly admitted that they threw in the towel- they have exited the high end market. reply stego-tech 4 hours agorootparentAnd if these 50-series specs are anything to go by, they made a good call in doing so. All the big improvements are coming in mid-range cards, where AMD, nVidia, and Intel(!) are trading blows. If the only way to get better raw frames in modern GPUs is to basically keep shoveling power into them like an old Pentium 4, then that’s not exactly an enticing or profitable space to be in. Best leave that to nVidia and focus your efforts on a competitive segment where cost and efficiency are more important. reply ryao 11 hours agorootparentprevNvidia’s Titan series cards always were outrageously priced for the consumer market. The 5090 is a Titan series card in all but name. I suspect there is a correlation to the price that it costs Nvidia to produce these. In particular, the price is likely 3 times higher than the production and distribution costs. The computer industry has always had significant margins on processors. reply ziml77 13 hours agorootparentprevEfficiency is why I switched from a 3090 to a 4080. The amount of heat generated by my PC was massively reduced with that change. Even if the xx90 weren't jumping up in price each generation, I wouldn't be tempted to buy one again (I didn't even really want the 3090, but that was during the supply shortages and it was all I could get my hands on). reply DimmieMan 14 hours agorootparentprevI use my 3090 on a 4K TV and still don't see a need, although a lot of that is being bored with most big budget games so I don't have many carrots to push me to upgrade. Turn down a few showcase features and games still look great and run well with none or light DLSS. UE5 Lumen/ray tracing are the only things I feel limited on and until consoles can run them they'll be optional. It seems all the gains are brute forcing these features with upscaling & frame generation which I'm not a fan of anyway. Maybe a 7090 at this rate for me. reply ericfrederich 14 hours agoparentprev4k gaming is dumb. I watched a LTT video that came out today where Linus said he primarily uses gaming monitors and doesn't mess with 4k. reply zeroonetwothree 14 hours agorootparentYep. I have both 4k and 1440p monitors and I can’t tell the difference in quality so I always use the latter for better frames. I use the 4k for reading text though, it’s noticeably better. reply munchbunny 3 hours agorootparentThat's why I also finally went from 1920x1200 to 4k about half a year ago. It was mostly for reading text and programming, not gaming. I can tell the difference in games if I go looking for it, but in the middle of a tense shootout I honestly don't notice that I have double the DPI. reply kcb 14 hours agorootparentprevNo it's not. 2560x1440 has terrible PPI on larger screens. Either way with a 4k monitor you don't technically need to game at 4k as most intensive games offer DLSS anyway. reply perching_aix 14 hours agorootparentWhat matters is the PPD, not the PPI, otherwise it's an unsound comparison. reply kcb 14 hours agorootparentToo much personal preference with PPD. When I upgraded to a 32\" monitor from a 27\" one i didn't push my display through my wall, it sat in the same position. reply perching_aix 10 hours agorootparentNot entirely clear on what you mean, but if you refuse to reposition your display or yourself after hopping between diagonal sizes and resolutions, I'd say it's a bit disingenuous to blame or praise either afterwards. Considering you seem to know what PPD is, I think you should be able to appreciate the how and why. reply snvzz 14 hours agorootparentprevAnd FSR, which is cross gpu vendor. reply akimbostrawman 11 hours agorootparentprevTaking anything Linus or LTT says seriously is even dumber.... reply ggregoire 12 hours agorootparentprevI watched the same video you talking about [1], where he's trying the PG27UCDM (new 27\" 4K 240Hz OLED \"gaming monitor\" [2]) and his first impressions are \"it's so clean and sharp\", then he starts Doom Eternal and after a few seconds he says \"It's insane [...] It looks perfect\". [1] https://www.youtube.com/watch?v=iQ404RCyqhk [2] https://rog.asus.com/monitors/27-to-31-5-inches/rog-swift-ol... reply Yeul 4 hours agorootparentprevNonsense 4k gaming was inevitable as soon as 4k TVs got mainstream. reply Our_Benefactors 14 hours agorootparentprevThere are good 4K gaming monitors, but they start at over $1200 and if you don't also have a 4090 tier rig, you won’t be able to get full FPS out of AAA games at 4k. reply out_of_protocol 8 hours agorootparentAlso, ultrawide monitors. They exist, provide more immersion. And typical resolution is 3440x1440 which is high and and the same time have low ppi (basically regular 27\" 1440p monitor with extra width). Doubling that is way outside modern GPU capabilities reply FuriouslyAdrift 3 hours agorootparentA coworker who is really into flight sims runs 6 ultrawide curved monitors to get over 180 degrees around his head. I have to admit with the display wrapping around into peripheral vision, it is very immersive. reply archagon 13 hours agorootparentprevI still have a 3080 and game at 4K/120Hz. Most AAA games that I try can pull 60-90Hz at ~4K if DLSS is available. reply geertj 4 hours agoprevAny advice on how to buy the founders edition when it launches, possibly from folks who bought the 4090 FE last time around? I have a feeling there will be a lot of demand. reply logicalfails 4 hours agoparentGetting a 3080 FE (I also had the option to get the 3090 FE) at the height of pandemic demand required me sleeping outside a Best Buy with 50 other random souls on a wednesday night. reply steelframe 3 hours agorootparentAt that time I ended up just buying a gaming PC packaged with the card. I find it's generally worth it to upgrade all the components of the system along with the GPU every 3 years or so. reply Wololooo 3 hours agorootparentThis goes at a significant premium for on average OEM parts that are subpar. Buying individually yields much better results and these days it's less of a hassle than it used to. reply rtkwe 58 minutes agorootparentIt was likely from an integrator not a huge OEM that's spinning their own proprietary motherboard designs like Dell. In that case they only really paid the integrator's margin and lost the choice of their own parts. reply jmuguy 3 hours agoparentprevDo you live somewhat near a Microcenter? They'll likely have these as in-store pick up only, no online reservations, 1 per customer. Recently got a 9800X3D CPU from them, its nice they're trying to prevent scalping. reply geertj 2 hours agorootparentI do! Great advice. Going off on a tangent, when I recently visited my Microcenter after a few years of not going there, it totally gave me 80s vibes and I loved it. Staff fit the \"computer nerd\" stereotype accurately, including jeans shirts and ponytails. And best of all they actually wanted to talk to me and help me find stuff, and were knowledgeable. reply jmuguy 2 hours agorootparentOurs just opened in 2024 and I've tried to give them as much business as possible. Ordering everything for a new PC build, sans the AMD CPU, and then doing pick up was a breeze. Feels great that the place is completely packed every time I go in there. I feel like Bestbuy made me sort of hate electronics retail and Microcenter is reminding of what it used to be like going to Radio Shack and Compusa back in their hayday. reply mjevans 2 hours agorootparentprevAs someone living (near) Seattle, this is a major issue for me every product launch and I don't have a solution. The area's geography just isn't conducive to allowing a single brick and mortar store to survive and compete with online retail for costs vs volume; but without a B&M store there's no good way to do physical presence anti-scalper tactics. I can't even get in a purchase opportunity lottery since AMD / Nvidia don't do that sort of thing for allocating restock quota tickets that could be used as tokens to restock product if a purchase is to the correct shipping address. reply smcleod 15 hours agoprevIt's a shame to see they max out at just 32GB, for that price in 2025 you'd be hoping for a lot more, especially with Apple Silicon - while not nearly as fast - being very usable with 128GB+ for LLMs for $6-7k USD (comes with a free laptop too ;)) reply jsheard 15 hours agoparentApple Silicons architecture is better for running huge AI models but much worse for just about anything else that you'd want to run on a GPU, bandwidth is far more important in most other applications. That's not even close, the M4 Max 12C has less than a third of the 5090s memory throughput and the 10C version has less than a quarter. The M4 Ultra should trade blows with the 4090 but it'll still fall well short of the 5090. reply ryao 15 hours agoparentprevPresumably the workstation version will have 64GB of VRAM. By the way, this is even better as far as memory size is concerned: https://www.asrockrack.com/minisite/AmpereAltraFamily/ However, memory bandwidth is what matters for token generation. The memory bandwidth of this is only 204.8GB/sec if I understand correctly. Apple's top level hardware reportedly does 800GB/sec. reply sliken 12 hours agorootparentAMD Strix Halo is 256GB/sec or so. Similarly AMD's Epyc Sienna family is similar. The EPYC turin family (zen 5) has 576GB/sec or so per socket. Not sure how well any of them do on LLMs. Bandwidth helps, but so does hardware support for FP8 or FP4. reply ryao 12 hours agorootparentMemory bandwidth is the most important thing for token generation. Hardware support for FP8 or FP4 probably does not matter much for token generation. You should be able to run the operations on the CPU in FP32 while reading/writing them from/to memory as FP4/FP8 by doing conversions in the CPU's registers (although to be honest, I have not looked into how those conversions would work). That is how llama.cpp supports BF16 on CPUs that have no BF16 support. Prompt processing would benefit from hardware FP4/FP8 support, since prompt processing is compute bound, not memory bandwidth bound. As for how well those CPUs do with LLMs. The token generation will be close to model size / memory bandwidth. At least, that is what I have learned from local experiments: https://github.com/ryao/llama3.c Note that prompt processing is the phase where the LLM is reading the conversation history and token generation is the phase where the LLM is writing a response. By the way, you can get an ampere altra motherboard + CPU for $1,434.99: https://www.newegg.com/asrock-rack-altrad8ud-1l2t-q64-22-amp... I would be shocked if you can get any EYPC CPU with similar/better memory bandwidth for anything close to that price. As for Strix Halo, anyone doing local inference would love it if it is priced like a gaming part. 4 of them could run llama 3.1 405B on paper. I look forward to seeing its pricing. reply sliken 9 hours agorootparentHmm, seems pretty close. Not sure how the memory channels related to the performance. But the ampere board above has 8 64 bit channels @ 3200 MHz, the AMD Turins have 24 32 bit channels @ 6400 Mhz. So the AMD memory system is 50% wider, 2x the clock, and 3x the channels. As for price the AMD Epyc Turin 9115 is $726 and a common supermicro motherboard is $750. Both the Ampere and AMD motherboards have 2x10G. No idea if the AMD's 16 cores with Zen 5 will be able to saturate the memory bus compared to 64 cores of the Amphere Altra. I do hope the AMD Strix Halo is reasonably priced (256 bits wide @ 8533 MHz), but if not the Nvidia Digit (GB10) looks promising. 128GB ram, likely a wider memory system, and 1 Pflop of FP4 sparse. It's going to be $3k, but with 128GB ram that is approaching reasonable. Seems like it's likely has around 500GB/sec of memory bandwidth, but that is speculation. Interesting Ampere board, thanks for the link. reply lostmsu 13 hours agorootparentprevAll of this is true only while no software is utilizing parallel inference of multiple LLM queries. The Macs will hit the wall. reply ryao 12 hours agorootparentPeople interested in running multiple LLM queries in parallel are not people who would consider buying Apple Silicon. reply whywhywhywhy 4 hours agoparentprevJust isn't comparable speed wise for anything apart from LLM and in the long run you can double up and swap out Nvidia cards while Mac you need to rebuy the whole machine. reply FuriouslyAdrift 3 hours agoparentprevGuess you missed the Project Digits announcement... desktop supercomputer for AI at $3k (128 GB ram) https://www.nvidia.com/en-us/project-digits/ reply lemoncookiechip 4 hours agoprevI have a feeling regular consumers will have trouble buying 5090s. RTX 5090: 32 GB GDDR7, ~1.8 TB/s bandwidth. H100 (SXM5): 80 GB HBM3, ~3+ TB/s bandwidth. RTX 5090: ~318 TFLOPS in ray tracing, ~3,352 AI TOPS. H100: Optimized for matrix and tensor computations, with ~1,000 TFLOPS for AI workloads (using Tensor Cores). RTX 5090: 575W, higher for enthusiast-class performance. H100 (PCIe): 350W, efficient for data centers. RTX 5090: Expected MSRP ~$2,000 (consumer pricing). H100: Pricing starts at ~$15,000–$30,000+ per unit. reply boroboro4 4 hours agoparentH100 has 3958 TFLOPS sparse fp8 compute. I’m pretty sure listed tflops for 5090 are sparse (and probably) fp4/int4. reply rfoo 3 hours agorootparentYes, that's the case. Check the (partial) spec of 5090 D, which is the nerfed version for export to China. It is marketed as having 2375 \"AI TOPS\". BIS demands it to be less than $4800 TOPS \\times Bit-Width$, and the most plausible explanation for the number is - 2375 sparse fp4/int4 TOPS, which means 1187.5 dense TOPS for 4 bit, or $4750 TOPS \\times Bit-Width$. reply bee_rider 3 hours agoparentprevHow well do these models do at parallelizing across multiple GPUs? Is spending $4k on the 5090 a good idea for training, slightly better performance for much cheaper? Or a bad idea, 0x as good performance because you can’t fit your 60GB model on the thing? reply Havoc 3 hours agoparentprev> regular consumers will have trouble buying 5090s. They’re not really supposed to either judging by how they priced this. For non AI uses the 5080 is infinitely better positioned reply kllrnohj 1 hour agorootparent> For non AI uses the 5080 is infinitely better positioned ...and also slower than a 4090. Only the 5090 got a gen/gen upgrade in shader counts. Will have to wait for benchmarks of course, but the rest of the 5xxx lineup looks like a dud reply topherjaynes 4 hours agoparentprevThat's my worry too, I'd like one or two, but 1) will either never be in line for them 2) or can only find via secondary market at 3 or 4x the price... reply jms55 14 hours agoprev* MegaGeometry (APIs to allow Nanite-like systems for raytracing) - super awesome, I'm super super excited to add this to my existing Nanite-like system, finally allows RT lighting with high density geometry * Neural texture stuff - also super exciting, big advancement in rendering, I see this being used a lot (and helps to make up for the meh vram blackwell has) * Neural material stuff - might be neat, Unreal strata materials will like this, but going to be a while until it gets a good amount of adoption * Neural shader stuff in general - who knows, we'll see how it pans out * DLSS upscaling/denoising improvements (all GPUs) - Great! More stable upscaling and denoising is very much welcome * DLSS framegen and reflex improvements - bleh, ok I guess, reflex especially is going to be very niche * Hardware itself - lower end a lot cheaper than I expected! Memory bandwidth and VRAM is meh, but the perf itself seems good, newer cores, better SER, good stuff for the most part! Note that the material/texture/BVH/denoising stuff is all research papers nvidia and others have put out over the last few years, just finally getting production-ized. Neural textures and nanite-like RT is stuff I've been hyped for the past ~2 years. I'm very tempted to upgrade my 3080 (that I bought used for $600 ~2 years ago) to a 5070 ti. reply magicalhippo 13 hours agoparentFor gaming I'm also looking forward to the improved AI workload sharing mentioned, where, IIUC, AI and graphics workloads could operate at the same time. I'm hoping generative AI models can be used to generate more immersive NPCs. reply friedtofu 13 hours agoprevAs a lifelong nvidia consumer, I think it's a safe bet to ride out the first wave of 5xxx series GPUs and wait for the inevitable 5080/5070 (GT/Ti/Super/whatever) that should release a few months after with similar specs and better performance based on whatever the complaints surrounding the initial GPUs lacked. I would expect something like the 5080 super will have something like 20/24Gb of VRAM. 16Gb just seems wrong for their \"target\" consumer GPU. reply knallfrosch 1 hour agoparentOr you wait out the 5000 Super too and get the 6000 series that fixes all the first-gen 5000-Super problems... reply ryao 13 hours agoparentprevThey could have used 32Gbps GDDR7 to push memory bandwidth on the 5090 to 2.0TB/sec. Instead, they left some performance on the table. I wonder if they have some compute cores disabled too. They are likely leaving room for a 5090 Ti follow-up. reply nsteel 3 hours agorootparentMaybe they wanted some thermal/power headroom. It's already pretty mad. reply arvinsim 13 hours agoparentprevI made the mistake of not waiting befpre. This time around, I will save for the 5090 or just wait for the Ti/Super refreshes. reply Insanity 2 hours agoprevSomewhat related, any recommendations for 'pc builders' where you can configure a PC with the hardware you want, but have it assembled and shipped to you instead of having to build it yourself? With shipping to Canada ideally. I'm planning to upgrade (prob to a mid-end) as my 5 year old computer is starting to show it's age, and with the new GPUs releasing this might be a good time. reply pier25 3 hours agoprevAI is going to push the price closer to $3000. See what happened with crypto a couple of years back. reply theandrewbailey 2 hours agoparentThe ~2017 crypto rush told Nvidia how much people were willing to spend on GPUs, so they priced their next series (RTX 2000) much higher. 2020 came around, wash, rinse, repeat. reply Macha 1 hour agorootparentNote the 20 series bombed, largely because of the price hikes coupled with meager performance gains, so the initial plan was for the 30 series to be much cheaper. But then the 30 series scalping happened and they got a second go at re-anchoring what people thought of as reasonable GPU prices. Also they have diversified other options if gamers won't pay up, compared to just hoping that GPU-minable coins won over those that needed ASICs and the crypto market stayed hot. I can see nVidia being more willing to hurt their gaming market for AI than they ever were for crypto. Also also, AMD has pretty much thrown in the towel at competing for high end gaming GPUs already. reply snarfy 1 hour agoprevI'm really disappointed in all the advancement in frame generation. Game devs will end up relying on it for any decent performance in lieu of actually optimizing anything, which means games will look great and play terribly. It will be 300 fake fps and 30 real fps. Throw latency out the window. reply knallfrosch 13 hours agoprevSmaller cards with higher power consumption – will GPU water-cooling be cool again? reply nfriedly 2 hours agoprevMeh. Feels like astronomical prices for the smallest upgrades they could get away with. I miss when high-end GPUs were $300-400, and you could get something reasonable for $100-200. I guess that's just integrated graphics these days. The most I've ever spent on a GPU is ~$300, and I don't really see that changing anytime soon, so it'll be a long time before I'll even consider one of these cards. reply yourusername 2 hours agoparent>I miss when high-end GPUs were $300-400, and you could get something reasonable for $100-200. That time is 25 years ago though, i think the Geforce DDR is the last high end card to fit this price bracket. While cards have gotten a lot more expensive those $300 high end cards should be around $600 now. And $200-400 for low end still exists. reply garbageman 2 hours agoparentprevIntel ARC B580 is $249 MSRP and right up your alley in that case. reply nfriedly 2 hours agorootparentYep. If I needed a new GPU, that's what I'd go for. I'm pretty happy with what I have for the moment, though. reply frognumber 1 hour agorootparentI'd go for the A770 over the B580. 16GB > 12GB, and that makes a difference for a lot of AI workloads. An older 3060 12GB is also a better option than the B580. It runs around $280, and has much better compatibility (and, likely, better performance). What I'd love to see on all of these are specs on idle power. I don't mind the 5090 approaching a gigawatt peak, but I want to know what it's doing the rest of the time sitting under my desk when I just have a few windows open and am typing a document. reply dcuthbertson 4 minutes agorootparentA gigawatt?! Just a little more power and I won't need a DeLorean for time travel! reply holoduke 1 hour agoprevSome of the better video generators with pretty good quality can run on the 32gb version. Expect lots of AI generated videos with this generation of videocards. Price is steep and we need another 9700 ati successtory for some serious nvidia competition. Not going to happen anytime soon I am afraid. reply ksec 14 hours agoprevAnyone has any info on Node? Can't find anything online. Seems to be 4nm but performance suggest otherwise. Hopefully someone do a deep dive soon. reply kcb 14 hours agoparentGood bet it's 4nm. The 5090 doesn't seem that much greater than the 4090 in terms of raw performance. And it has a big TDP bump to provide that performance. reply wmf 14 hours agoparentprevI'm guessing it's N4",
    "originSummary": [
      "Nvidia unveiled its next-generation RTX 50-series GPUs at CES, featuring the high-end RTX 5090 and RTX 5080, priced at $1,999 and $999, respectively. - The RTX 5090 includes 32GB of GDDR7 memory and 21,760 CUDA cores, offering double the speed of its predecessor, the RTX 4090, while the RTX 5080 provides 16GB of memory and is twice as fast as the RTX 4080. - The series introduces new DLSS 4 technology, improving performance and image quality, and will be available for laptops starting in March."
    ],
    "commentSummary": [
      "Nvidia has unveiled the RTX 5090 and RTX 5080 GPUs, with the RTX 5090 featuring 32GB of GDDR7 memory and a 575W Thermal Design Power (TDP), aimed at consumer AI workloads.",
      "The RTX 5080 is designed for high-end gaming, offering a more affordable option with less memory compared to the RTX 5090.",
      "The high demand for these GPUs, particularly for AI applications, may lead to availability issues, reminiscent of previous shortages driven by cryptocurrency mining."
    ],
    "points": 329,
    "commentCount": 367,
    "retryCount": 0,
    "time": 1736219531
  },
  {
    "id": 42615538,
    "title": "Used Meta AI, now Instagram is using my face on ads targeted at me",
    "originLink": "https://old.reddit.com/r/ABoringDystopia/comments/1ht7fft/used_meta_ai_to_edit_a_selfie_now_instagram_is/",
    "originBody": "whoa there, pardner! Your request has been blocked due to a network policy. Try logging in or creating an account here to get back to browsing. If you're running a script or application, please register or sign in with your developer credentials here. Additionally make sure your User-Agent is not empty and is something unique and descriptive and try again. if you're supplying an alternate User-Agent string, try changing back to default as that can sometimes result in a block. You can read Reddit's Terms of Service here. if you think that we've incorrectly blocked you or you would like to discuss easier ways to get the data you want, please file a ticket here. when contacting us, please include your ip address which is: 20.42.14.166 and reddit account",
    "commentLink": "https://news.ycombinator.com/item?id=42615538",
    "commentBody": "Used Meta AI, now Instagram is using my face on ads targeted at me (reddit.com)299 points by amrrs 22 hours agohidepastfavorite171 comments floatrock 20 hours agoOpening up a whole new dimension of adtech personalization/engagement here... more evil brainstorming: - electronic billboards on the bus corner start doing this while walking down the street - your favorite peacock sitcom starts injecting your friends or recent vacation locations or friends' recent vacation locations on the main character's digital picture frame. Your buddy recently went to Sandals Resort in Jamaica? Now that's going to be emphasized in the unused screen real estate in the background of the bar scene to play on your fomo. - hell, sporting games already have digital billboards on the field barriers that are customized for different markets / broadcasters... why not customize them further for the individual stream reply trescenzi 20 hours agoparentThere’s a scene in Minority Report of a mall and it’s basically this. The billboards scan you and then target you directly as you go by. https://m.youtube.com/watch?v=7bXJ_obaiYQ reply radley 20 hours agorootparentI've always wondered about that scene: does everyone around him see him in the ads as well? If so, that would mean that they're appropriating his image to sell to others. Perhaps they're laser / audio projections, so each person only sees their own ad. reply goldenCeasar 19 hours agorootparentOr worse: he needed to consent to a TC that allows they do use his image if he wanted to enter the shopping. reply _DeadFred_ 18 hours agorootparentDude don't go posting ideas like this on HN. Come on man. reply llamaimperative 17 hours agorootparentprevThere are already displays that do this, no lasers necessary. I forget the name for them though… maybe a type of lenticular display? Cool use case: personalizing wayfinding signage e.g. in an airport Bad use case: most of the rest of them reply pndy 18 hours agorootparentprevSo do I. Either people in the Minority Report world are immune to all that constant visual and audio noise thrown at them, and everyone hears every slogan along with names. Or these ads are somehow personalized and isolated voice (while portrayed as an unified mess) reaches particular person based on their movement in the public space. reply kvmet 17 hours agorootparentPhased array speakers can focus sound in a specific direction. The visuals I don't have a good answer for but the sound part could definitely be done with existing technology reply glandium 14 hours agorootparentprevIf you take a listen to the linked video, you'll hear other names than his. reply slg 17 hours agorootparentprevTruly one of the most prophetic movies in recent memory. It started out innocently enough with people just stealing the gestures and UIs from the film. But we have now progressed to also taking the highly targeted and personalized advertising coupled with mass surveillance and even the idea of precrime that is now being built around AI as if that is more accurate than the fantastical psychics of the movie. Just another example of us creating the torment nexus. reply trilbyglens 10 hours agorootparentPhilip K Dick was a genius, and this story was from the 70s! reply porcoda 17 hours agorootparentprevAbout 4 years ago I was at a VC pitch day and one of the teams rehearsing their pitch before hand was basically proposing this for augmented reality. I was mildly horrified that people saw that sort of thing as something people would want, but hey - $$$ is all that matters right? I really hope those folks never got funded. reply petre 10 hours agorootparentWhy do you think Meta bought VR tech and took it further? To pour ads directly into our brains. It's just that scuba sized VR tech it didn't catch on, so instead they invested in Luxottica now to make AR fashion items with the same purpose. reply ashoeafoot 12 hours agoparentprevCreating fake personal memories with faked personal photos and product placements? reply actsasbuffoon 15 hours agoparentprevI can see it now. You get an ad showing you in prison. The text reads, “I shouldn’t have downloaded that torrent without NordVPN.” Welcome to our new dystopian hellscape. reply cdme 18 hours agoparentprevThis sounds like hell. reply paxys 21 hours agoprevStandard internet outrage bait. There are no ads in the photos. The person uploaded their photo to Meta AI's \"imagine me\" feature which generates photos of you in exotic situations, and now the company is...putting them in exotic situations. That's literally what it is for. reply graypegg 21 hours agoparentIt's technically opt-in. You have to use their image generator, which requires agreeing to this \"images appear in your feed randomly\" feature implicitly. [0] You think you're just generating 1 photo, but you're actually signing up to a service that generates photos and adds them to your instagram feed. Even their help docs don't mention that nuance though. [1] It's not technically an ad, even though it mostly functions like one since the purpose of these images isn't anything more than bait to get the user to use meta ai more... I guess. [0] https://www.businessinsider.com/meta-ai-face-images-instagra... [1] https://www.meta.com/help/artificial-intelligence/imagine/?s... reply paxys 20 hours agorootparentEither I'm crazy or everyone else here is. \"I asked Meta AI for photos of myself and it started advertising Meta AI by showing me photos of myself.\" How does this \"function like\" an ad? Why are we even using the word ad? This is not how ads work. By this definition what isn't an ad? reply graypegg 20 hours agorootparentThese are newly generated images, not promoted by you, shown in your feed. That’s the true “service” on offer here, images are generated for you and put on your timeline. But the UI to sign up for this service looks like a “type in the text box, get an image” sort of service. It also doesn’t mention this instagram integration, other than requiring you to log in with a meta account. You still get to make your own promoted images, so that’s marginally useful. The main weirdness is it making its own images, on your behalf. If you get value from random slop images with no particular theme, then cool. You can look at them as they show up. But really, these are just throw away assets. It’s just meant to get you to click thru into the meta.ai upsell this links to. It’s not quite an ad… because technically… it did something for you? There’s some implication that this random feed of useless images of you is… valuable. So it’s a service you accidentally walk into using, that just happens to redirect you to meta.ai when you click on it. reply chillfox 18 hours agorootparentIt's absolutely still an ad; ads sometimes include samples, like when they hand out small bites in the supermarket, those might be tasty ads, but they are still ads. reply jerf 16 hours agorootparentprevIt's not an ad. It's someone trying to figure out what to do with the crap ton of GPUs they've been allocated and told to find some way to show metrics for usage going up, up, up, and the only way they can think to accomplish that is to get people to use them with zero interaction, since basically nobody cares to engage with the features otherwise. Gotta say, this first batch of released AI features for the masses has been deeply underwhelming. Custom emojis and random pictures of me in random situations in some feed where the only reason I'm not scrolling past it is that it's a picture of me I don't remember being in hardly seems worth the valuations the stock market has been giving these things. I suspect that if there was a way to clean up the metrics to see only what people actually wanted to engage with with these AI products, it would pop the bubble instantly. So much gaming the metrics by forcing it on people then claiming victory for the AI. (I don't use LLMs for coding but at least that has a very clear value proposition. Search is nice now, but mostly because conventional search was ruined with malice aforethought... search AIs will follow soon enough. Enjoy that honeymoon while you can.) reply bandinobaddies 21 hours agoparentprevIt is still weird. Imagine you try out Photoshop online with your private photos. A few minutes later, you start seeing ads with those same photos edited in different ways. Even if those ads are visible only to you, it will still feel pretty creepy. reply tsimionescu 19 hours agoparentprevNo, the person uploaded their photo to Meta AI to get a picture with some background, once. They then started seeing ads for MetaAI offering to generate more images of them, for a cost. Only the ads were still using their face from the photo they only uploaded once. This is like using an online photo editing tool once, and then seeing ads to that photo editing tool show up on the internet, still using the image you up loaded that one time. reply HomeDeLaPot 18 hours agorootparentExcept the ads don't show up anywhere \"on the internet\", they only show up on the photo editing site. reply shakna 17 hours agorootparentThe photo editing site was \"MetaAI\", the display site was Instagram. They may have the same parent, but are distinct entities. reply ec109685 18 hours agorootparentprevThere’s no cost to generate more images. reply fuzzylightbulb 15 hours agorootparentThere's no cost to watch other shows on HBO, but the 2 minute promo they play for a different HBO show before playing the show you requested is 100% an ad. reply ec109685 15 hours agorootparentFine if you call it an ad, but it doesn’t change the fact that the feature is free of cost. reply thih9 21 hours agoparentprevAlso, their support pages say that this can be turned off: > You can turn this feature off and delete your setup photos in Meta AI settings at any time. https://m.facebook.com/help/messenger-app/1108543930466238 reply potsandpans 21 hours agoparentprevStandard hackernews top comment dismissal. reply adamors 19 hours agorootparentI’ve developed a habbit of automatically downvoting the top comment on most popular submissions because more often than not they are always some knee-jerk, often stupid contrarian reaction to the submission. I don’t know when this trend started but I don’t remember it being this bad in the past. reply steveklabnik 16 hours agorootparentPeople have been complaining about this for over a decade now. Here's some comments by pg himself, on the \"middlebrow dismissal\": https://news.ycombinator.com/item?id=4693920 https://news.ycombinator.com/item?id=4397542 reply rcfox 19 hours agorootparentprevI guess a knee-jerk reaction demands a knee-jerk response? reply miltonlost 20 hours agorootparentprevBig tech can't do wrong! Your personal feelings don't matter! /s Every tech bro thinks they're a Nietzchean Superman who deserves to do whatever they choose because they can. reply lenerdenator 20 hours agorootparentTo be fair to them, no one's proven them wrong yet. reply ziml77 19 hours agorootparentprevOr some of us have opinions that are complex enough to both despise Meta and think that this post is poorly framed. reply dathinab 19 hours agoparentprevYes, but putting that aside meta does give themself the right to use your face for ads and has used it and has won law suites about it before (through the cases I was aware of are quite old, i.e. before various right to be forgotten laws or GDPR). So if they want to use your face to create an bot account to \"increase engagement\" they probably can do so without (legal) repercussions. reply dan_wood 21 hours agoparentprevYeah not seeing it either, both images say, only you can see this.. Feels more like it generated more than the user asked for and now it’s just showing those images in their feed. reply drivingmenuts 21 hours agorootparentWhat nobody mentions about \"only you can see this\" is that \"you\" refers to ordinary users of the service and there is no mention if employees are included in that grouping. It has happened before that systems secure from the public were misused by persons with privileges within the organization. The obvious response is \"well, yeah. So? They need it.\" but that's not how ordinary people, who don't deal with this daily, think. When they see \"only you can see this\" I think they take it literally. The computer is always watching and sometimes so are the people running the computers. reply theptip 18 hours agoprevThat's... not an ad? User used Meta AI to touch up a selfie, now Meta AI is generating more selfies for you. I can understand the annoyance from cross-linking apps in the same way it's annoying to get the Threads popup in your feed, but really, this is utter clickbait. reply awinter-py 17 hours agoparentkind of an interesting question -- are product nudges ads? like when there's a button to use a paid feature which pops up on top of a different button, is it an ad? it's not third party. reply LorenDB 16 hours agorootparentYou'd call it an ad if you saw it in any other context, so yes. reply Ferret7446 13 hours agorootparentThe definition of \"ad\" depends on context though (that's the point). reply RileyJames 12 hours agorootparentI’m sure the advertising industry has a specific term and definition for this type of ad. On that basis, I think it falls squarely in the advertising category. I’m sure someone that works in that industry can drop their knowledge on it. reply rainonmoon 17 hours agorootparentprevWhen a TV network airs promos for its own shows, is it an ad? reply p1necone 16 hours agorootparentI remember being utterly baffled by this as a kid at other peoples houses. \"Let me get this straight, you pay a bunch of money for 'special' TV channels that say they have no ads, and you still have to watch ads? What kind of insane horseshit is this?\". Put me off non free to air TV for my entire adult life until streaming services became a thing, and you better believe I'm immediately unsubscribing from those the second they pause a video I'm watching to show me promos or ads. reply Brian_K_White 17 hours agorootparentprevYes. reply llamaimperative 17 hours agoparentprevI mean it really is an ad, just an ad for one of Meta’s own products. I wouldn’t be surprised if it is quite literally an ad where one team is winning the ad auction to place these into the feed. reply htrp 18 hours agoprevIt's only a matter of time before this gets put into the programmatic ad formats where you can do individual level targeting. The advertiser won't ever have to see your image as meta will offer it as a service. More importantly, just like things like pmax (google's current optimization product), your account manager will heavily incentive you towards running these AI campaigns. reply bobheadmaker 11 hours agoparentThat sounds horrible, I hope we prevent this before seeing the negative impacts! reply lazide 9 hours agorootparentHonestly, what do you think the odds are of that happening? reply hbn 21 hours agoprevI'll play some defence for them here. You were playing with Meta's AI face tool, and now it's taken some results from that and swapped them in where ads would usually go. I'm assuming they don't do this if you just uploaded photos to Facebook/Instagram, you seemingly gave them a picture with the direct intent of them using it to make AI images. It doesn't seem that much different from when I'm typing a chat reply in Snapchat and it starts automatically suggesting stickers with mine and my friends' faces doing silly things with cartoon bodies. Or using my avatar to try and upsell me to their premium subscription. Don't give them a picture of your face to mess around with if you don't like them messing around using a picture of your face. reply Hizonner 16 hours agoparent> Don't give them a picture of your face to mess around with if you don't like them messing around using a picture of your face. OK. In fact, I'll do better than that. I won't interact with any of their products or services in any way, including blocking all their domains several times over in various browser extensions. Snapchat, too. Actually I used my time machine to implement it already. How much surreal harassment will you people put up with? reply lazide 9 hours agorootparentApparently, a whole lot more. I recently had someone stunned (actually, truly stunned) that I didn’t have Instagram. I spent 5 minutes looking at it years ago, and deleted it - and have never regretted that decision. Notably, I’m also unsurprisingly no fun at parties. reply matsemann 21 hours agoparentprevI instantly revoked Facebook's access to my photos a few years back, when it had taken photos from my camera roll and put it into my feed with a \"do you want to share this\"? I was browsing on the subway, and did not expect a medical picture of me showing up for everyone there to see. And I realized facebook as well could do what they wanted with my pictures. reply maartenscholl 20 hours agoprevMeta AI asks permission to do this, but note that in some U.S. states personal publicity rights end upon death. Isn't it hilariously Wallacian that this technology can be used to make targeted ads featuring the viewers deceased loved ones? reply radley 20 hours agoprevI think the common wisdom is that if you use a Meta product, they will try every possible form of social engineering to drive engagement. While this example was unexpected, it was predicted (Minority Report et al.) and is very much in line with their MO. reply frereubu 20 hours agoparentI'd say this is common wisdom on sites like HN, very much not outside the tech bubble. I can immediately bring to mind a good number of non-tech family members who would be completely freaked out by this. reply radley 20 hours agorootparentOr perhaps, they could find it entertaining. Particularly if they're comfortable consuming Meta services. reply benreesman 18 hours agoprevMy mom uses Instagram constantly but when she got hit with this she freaked out and said “fuck Facebook” out loud in public and put her phone away. reply anon373839 20 hours agoprevThere is an interesting phenomenon going on here. On one hand, this is pretty mundane: a software tool you’re currently using shows you examples of ways to use the software. On the other hand, this does technically constitute an “ad”. What’s interesting to me is that some people seem to have a strong emotional reaction to the fact that it’s possible to describe this as “Instagram using my face in an ad,” even if the underlying event lacks the characteristics that would make that statement outrageous. reply tsimionescu 19 hours agoparentIt's not mundane. The screenshots show Instagram displaying an ad for Meta AI. The user is not currently using MetaAI, they are using Instagram, so it's not at all \"showing examples of ways to use the software you are currently using\". It's more similar to Windows trying to sell you OneDrive through the Security Center, which is widely loathed, and recognized as an ad. reply anon373839 15 hours agorootparent> It's not mundane. The screenshots show Instagram displaying an ad for Meta AI. Well, there it is again: what seems to make it objectionable is that it fits a certain definition, rather than it exhibiting some intrinsically objectionable features. (Note I’m not criticizing this; I just find it interesting.) Since I don’t personally see this as an ad, I might describe it as “The screenshots show an example of output that the user can generate with Meta AI. The example shown isn’t emotionally enagaging, and it resembles placeholder content.” What would make this stand out for me is if Meta owned a tooth whitening business, and then used this placement to show a version of myself with a whiter smile. Or any of the other dystopian examples in this thread. But the one that actually occurred just doesn’t register for me as a breach of trust. reply tsimionescu 12 hours agorootparent\"It's an ad\" is shorthand for \"this is trying to manipulate me to do/buy something\". So the problem is not that it fits the definition of \"ad\", the problem, spelled out completely, is that they are using my likeness in something that is trying to manipulate me to do or buy something (do, in this case, since as far as others are saying, this is free of charge). Also, while the example shown does resemble placeholder content, it pretty clearly seems designed to evoke an emotional response, it seems designed to appear cool and futuristic. And regardless, people have a very high sensitivity to how their image is used. If I haven't given Instagram specific permission to use my image for something, it really really can't use my image for that thing. This goes beyond issues like copyright, it's a very basic human right to control how your own likeness is used. reply duskwuff 16 hours agoprev> Imagine yourself reflecting on life in an endless maze of mirrors where you're the main focus. This feels almost a bit too on-the-nose. But no, apparently it's real? reply Bengalilol 21 hours agoprevThe idea is kind of interesting, but who from Meta thought this would be cool to do such thing ? reply MarkSweep 20 hours agoparentSome growth team probably has goal to move a metric. This promotion is one of their experiments. If they move the metric, they can cite that in their performance review. If the promotion causes bad PR (see this thread) and none of the pre-launch reviews flagged it, they can then share what they learned with others in the company. They will say something like “lead a cross functional team to develop best practices for use of AI-generated pictures of a user in promotions” in their pronounce review. Either way, we get experimented on like lab rates and they get their bonus. reply bitbuilder 19 hours agoparentprevAgree with your sentiment, but I'd take it one step further: why doesn't anyone calling the shots at Meta realize just how uncool it is to do such a thing? Which is the same reaction I had to their recent AI influencers. It speaks to their seeming inability to read the zeitgeist on the general public's attitude towards generative AI at the moment. I'm generally \"pro AI\", in that I think generative AI is incredibly interesting tech that can potentially be used to create some very cool (and maybe even helpful) things. But \"AI\" has become a dirty word among the people I know who aren't living in our tech bubble - uncool at best, and evil at worst. And every time I see something like this, I understand perfectly why they feel that way. Every new hamfisted or creepy attempt at inserting AI into everything by companies like Meta just digs the hole even deeper for people's perception of generative AI. reply radley 20 hours agoparentprevIn an old-school yay internet sense, it's fun like amusement park rides taking your photo. But in a modern sense, it's just creepy. reply pesus 21 hours agoparentprevI wonder that in regards to just about everything they do. reply aithrowawaycomm 21 hours agoprevThe content of the ad seems a bit on-the-nose given how much of Instagram is devoted to onanistic preening... reply Jerrrry 19 hours agoparent>onanistic preening If this is ever used again, you're correlated. reply KaiserPro 21 hours agoparentprevbut its not an ad though? its meta-ai doing meta-ai things. Like if it was \"buy this shit\", or \"your next location sponsored by bud lite\" then yeah, but its not an advert. reply pndy 18 hours agorootparentThey're on the edge with the phrase \"Imagined for you\" but this is an ad - for their model, using their users faces if they happen to not opt-out. They did sent mails out last May for instagram (and fb iirc too) in the EU saying you can opt-out of processing in their AI 'improvements'. It was done by filling out a form where you had to tell in a few words why you don't want to participate. Acc. to the message changes came into place on 26th June 2024. > \"(...) we will now rely on a legal basis called legitimate interests to use your data and to develop and improve AI on Meta's services. This means that you have the right to object to the way your data is used for this purpose. If your objection is recognised, it will automatically be recognised in the future.\" I'd say it's like you'd develop your photos at the workshop where they say they can randomly use their clients photos in ads in your local papers or whatever. And then you do bump on a poster of your local travel agency including yourself lying on the beach in Saint-Tropez/France slapped all over the city. Where of course you haven't been to France at all. reply ec109685 18 hours agorootparentNo, the user had to have already used Meta AI for Meta to have their data to generate additional images. They aren’t taking a random photo from your reel and using that to create an ai version of it. There’s a whole process to image your face that this poster had to go through. Hence the bit in the title: “Used Meta AI to edit a selfie, now instagram is using my face on ads targeted at me.” reply miltonlost 20 hours agorootparentprev\"buy this shit\" and \"use this shit we made\" is still an advert. Just because the person receiving the advert doesn't pay for the product themselves via cash and instead is paying via their personal data doesn't mean the post is not advertisement. The post is literally advertising MetaAI's product??? Do you know what an advert's definition is? reply KaiserPro 20 hours agorootparentWhen I saw the original link on bluesky, I didn't have time to look into it, I had assumed it was something like a post where a sponsor had paid meta to show a user a picture of said user in one of their adverts. Ie meta was being paid to whore out your likeness. > Do you know what an advert's definition is? according to this: https://www.dictionary.com/browse/advertisement its not. Look, I don't like meta any more than you do. But this is a service that is provided by them. Its not an advert, meta aren't making money from generating that user's likeness, or any other. I don't like GenAI, its going to ruin an industry I love, one I wanted to return to. When the bubble pops, its probably going to make me loose my job too. But this isn't an advert. reply ajkjk 20 hours agoprevI'd like to see the \"imagine what you'd look like if you exercised a lot more\" or \"had better posture\" or \"spent all summer in the sun\" filters. reply zjp 20 hours agoprevThat's the end of my account, then. reply lawgimenez 19 hours agoprevI recently opted out of Meta’s AI, I’m not sure if this helps. > Object to Your Information Being Used for AI at Meta reply pta2002 21 hours agoprevJesus Christ the victim blaming in this thread is insane. This is why deepfake laws are needed. Sure OP used Meta AI, and consented, but if I did that I'd probably be consenting to using the picture _for that one session_, where I'm in control. Definitely not for this, they shouldn't be able to put this in their ToS. reply mdanger007 21 hours agoparentAbsolutely. The public doesn’t care what word games you play or what rights you allocate yourself in a terms of service if you pull off something shady you deserve all the bad publicity you get reply 1shooner 16 hours agoparentprev> but if I did that I'd probably be consenting to using the picture _for that one session_, where I'm in control. You mean you you'd be wanting to consent to one session, while actually affirmatively consenting to something else. On one hand I agree there would be nothing wrong with limiting the scope of what is legally allowed in a ToS. On the other, I also think it's good that single parties can't just spontaneously wish away conditions of business agreements they don't like (although I imagine with a modicum of effort, you could modify that consent with Meta at any point). There's a comment in the reddit thread about how consent to Meta is invalid because Meta is essential to participating in modern society - basically saying that being a Meta user is a civil right. Bonkers. reply Hizonner 16 hours agorootparent> You mean you you'd be wanting to consent to one session, while actually affirmatively consenting to something else. Valid consent requires knowing what you're consenting to. This is not a new principle. reply bingaweek 21 hours agoparentprevCompanies need to be reminded that their operation is subject to our own ToS, the law, and it supercedes theirs. We can change it at any time and the sycophants defending any legal behavior aren't winning any favors. The behavior you see on HN playing defense for violations of privacy is disgusting, but I'm glad it's out in the open for everyone to see how far they'll go. reply zombiwoof 21 hours agoparentprevWelcome to Humans 3.0 reply SpicyLemonZest 21 hours agoparentprevI don't think it's victim blaming to say that the linked Reddit post is missing critical details (and indeed any details) about what precisely is going on. I agree that it's quite bad if Meta did this without the user specifically asking them to do so. reply oglop 20 hours agoprevWhat better way to increase the hyperreality needed to sell products then to have you in the ad! But also this is HN, so someone needs tk lecture you on “what you mean” and also remind you it’s their product you used and signed up for and signed your rights away too so it’s YOUR fault, or some such pompous condescending trash. I say, lucky you! I say, embrace the future! I say, plaster my face on adult diaper ads and sell them to me. I say, slap my face on that TRT ad from my podcast that I listen to in my lonely apartment to feel a connection to the world while I write code that “matters”. It’s a beautiful world. reply fairytalemtg 18 hours agoprevjust a reminder that you are the product. Sorry to read this, it is frustrating to see our own face in feeds targeted at us. No clue who thought that would be a win. reply nullc 19 hours agoprevFacebook is doing a public service here by being overt. Anyone else would just quietly take your face and those of your contacts and use it to generate an endless stream of faces which are unambiguously not you, yet compellingly familiar. ...maximizing their brainwashing effectiveness while minimizing the ick factor and triggering privacy minding behaviors. A lot of harm is done in the world by parties adaptively keeping their invasive conduct at just below the level which will trigger retaliation, legislation, etc. Like databrokers will sell exceptionally private data to anyone with a few bucks, but it's only a 'data breach' when someone takes that data without paying. The existence of databreaches even provides nice plausible deniability for harms that arise from the business of privacy-invasion-for-profit. reply trilbyglens 10 hours agoprevI really hate ai generated images of real people. If we thought Photoshop was bad for body image issues this is like putting that effect on heroin. I hope there's a massive backlash against this AI shit tbh. Leave it to meta to find a psychologically toxic application for any given technology. reply trhway 19 hours agoprevwait until they generate your, possibly long dead, grandmother (just using information of your and your parents faces and voices) convincing you to try that brand of pies. reply swayvil 16 hours agoparentThere is the theory that all men are deeply, possibly unconsciously, sexually attracted to their mother. Which leads to the obvious AI generated porn. reply lazide 7 hours agorootparentThat is an entirely different definition of pie than I’m comfortable considering. reply lulzron 22 hours agoprevThings that feel illegal will probably become illegal someday, but they think it's fine because, for now, it's not illegal. reply taco_emoji 22 hours agoparent> will probably become illegal someday Probably not for four years, at least reply _DeadFred_ 18 hours agoparentprev\"I've come up with a set of rules that describe our reactions to technologies: 1. Anything that is in the world when you’re born is normal and ordinary and is just a natural part of the way the world works. 2. Anything that's invented between when you’re fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it. 3. Anything invented after you're thirty-five is against the natural order of things.\" -Douglas Adams in The Salmon of Doubt reply npteljes 21 hours agoparentprevNah. Street View was also a big hubbub back then. People are not even mentioning it anymore. >Things that feel illegal will probably become illegal someday Also, if you think about this phrasing for just a second, this is the chilling effect. Suppressing expression due to the anticipation of negative outcomes. reply miltonlost 19 hours agorootparent> Nah. Street View was also a big hubbub back then. People are not even mentioning it anymore. Didn't StreetView start blurring people when they ask? Seems like people don't mention it anymore because the privacy issue was mitigated. reply npteljes 19 hours agorootparentSome was mitigated, but I don't think that faces and plates were what had the biggest bang about it. It's a complete, 360 capture of a large part of public places, with people still being clearly identifiable, correlated with satellite imagery (which was pointed out as creepy and privacy-invading as well, upon its public release), resolution so high that you can read many texts, and you can still see in windows, into yards, all kinds of stuff. Wikipedia has a lengthy article about the different concerns. And yet, despite it feeling creepy and strange for many, it just became normal. People look up random places for fun, to hunt for their new home, for driving instructions, GeoGuessr is cool and has a league of its own... it's a creepy, risky new thing becoming part of life, that's why I brought it up. Smartphones could be another good example. As the joke goes, people in the 60s are afraid the government wiretaps their phones. Nowadays, they say: \"Hey wiretap! Do you have a recipe for pancakes?\" https://en.wikipedia.org/wiki/Google_Street_View_privacy_con... reply nicce 20 hours agoparentprevThat is the difference in the U.S. businesses vs. European. In Europe many companies think ethics even if is not illegal on paper. In the U.S. you need to get big before it is illegal, lobby for it and then pay fines. But fines are okay since you got big already. reply ChocolateGod 20 hours agorootparentAll the hate tech journalists gave the EU because Apple Intelligence isn't launched there was insane, yet this is what EU legislation is designed to avoid. reply tsunamifury 20 hours agorootparentprevYou must be joking right. This euro-superior tone that always pops up on here is delusional. Nestle. Shell Oil. I can go on... literally nothing about what you said is grounded in reality. reply KaiserPro 20 hours agorootparentI didn't know that nestle and shell had AI departments. Look, I'm not +1 the EU here, but having some level of legal protection against marauding corporations is good. Sure EU based companies are evil, but they can't be as abusive to normal people because they are constrained by a semi-functional legal system. The US used to have that as well, along with a functioning legislature. reply tsunamifury 19 hours agorootparentThey do not. I can't even begin to explain to you how delusional this is. To be clear, I gave testimony to the NTHSA that the first Porsche Taycan was unfit for road driving due to extreme errors in the software architecture and in part got the CEO of Porsche fired. (Specifically error handling so laughably bad it caused the entire car to lock up at speed.) The EU only FOLLOWED grudgingly after the US demanded the recall. I am extremely aware of EXACTLY how risk-taking European companies are. reply nicce 20 hours agorootparentprevI am not joking. ”Move fast and break things” was even the motto of Zuckerberg back in day in Facebook. There are studies about it. Even Y Combinator has some history of admitting that they seek people like that: https://news.ycombinator.com/item?id=2579990 I particularly meant tech companies. Of course, you can find unethical businesses everywhere. reply tsunamifury 19 hours agorootparentIm sorry, I feel like you just countered with one of the most obvious statements in this field. SAP, Claude etc are all doing the same things American counterparts do. You need a slight dose of reality. reply slackfan 22 hours agoprevnext [6 more] [flagged] segasaturn 21 hours agoparentThis isn't helpful or realistic. It's becoming more and more difficult to keep all your personal data private and function in society, which is all by design for companies like Meta. reply slackfan 16 hours agorootparentPosting on social networks can easily be seen as counterproductive to societal function these days. reply redeux 21 hours agoparentprevYou’ve posted enough info here on HN for anyone to dox you (I won’t). Just thought it was relevant to your comment. reply mt_ 21 hours agoparentprevExactly, and the OP is not bothered about the content that is around him, somehow for him that must have been generated from thin air. reply npteljes 21 hours agorootparentPeople are not born with knowledge, however trivial it seem after knowing it. Same thing with privilege: different perspectives are earned with experience, not something that we start with. reply grakker 20 hours agoprevAny complaint that starts with \"used meta...\" just loses me. It's like, I stuck this needle into my left testicle and now that testicle hurts. reply ssivark 21 hours agoprevFor starters, how is it not a violation (eg. \"personality rights\") to use a person's likeness without permission? As a further example, do we really want insurance companies serving ads using near and dear ones as potential disaster victims? This is really getting out of hand. reply npteljes 21 hours agoprevThis is just hysteria. These are not third party ads, rather just Meta upselling its own thing; it is generated natively by the platform, not leading anywhere else but the platform that the user is already on. Even though it came up in an unexpected way, it explicitly says that it's private experience. The real boring dystopia (referring to the subreddit's name) is how the human psyche is played with by these platforms in the first place. People, including me, sign away so much for convenience, fear of missing out, for wanting to belong, to be appreciated. These systems sell the poison and the topical cure at the same time, and it's not just perfectly legal, it's wanted even, desired. EDIT: edited \"ads\" to \"third party ads\" - to spell out what the common understanding is of an advertisement. reply miltonlost 20 hours agoparent> These are not ads, rather something that is generated natively by the platform, not leading anywhere else but the platform that the user is already on. Is this post Advertising a product? Yes, it is advertising a MetaAI product. Just because it's not an external ad, doesn't mean it's not an ad. Hulu shows me adds for other Hulu shows. This is an ad despite me not leaving that streaming site. What is an advertisement to you? reply lbhdc 20 hours agorootparentYou are right, that is still and ad. Platform ads are really common for anyone running their own ad exchange. Sometimes its just to use up supply, other times its to meet in house goals. reply npteljes 20 hours agorootparentprevThis is technically true, these are advertisements. But not what first come to mind when reading the title \"Instagram is using my face on ads targeted at me\", which would be third-party ads, so this is my point. The title is sensational, a play on this misunderstanding, rather than being substantial. reply bitmasher9 20 hours agorootparentMy ick levels are about the same whether it’s used by third parties or just Meta. It’s a mega corporation using my likeness to manipulate my behavior for their own ends. reply to11mtm 18 hours agorootparentprevwell, a properly sensationalized title for your case would be 'Instagram and facebook are giving my pictures away to advertisers for use'. Still semi-sensational but more direct to your posit. reply sweeter 20 hours agorootparentprevNo one said third-party ads, the description is perfectly accurate to what is happening. The knee jerk reaction to call it sensationalist is odd to me. reply miltonlost 20 hours agorootparentprevThe title is only sensational because you, YOU, conflated \"3rd party ads\" with \"ads\". The only misunderstanding comes from you who didn't know what an advertisement is and added your own personal connotation. The title is not playing on anything; it's an accurate description of what happened. You are downplaying what happened, claiming \"hysteria\" when you are, from the get-go, wrong about the entire premise. Your ignorance of the definition of an ad doesn't mean the title is trying to ragebait you; how could the author know you don't know things? An ad is an ad is an ad is an ad. My god, admit when you're wrong fully rather than just saying \"you're technically correct\". reply npteljes 20 hours agorootparentTo help with understanding my point, I edited the original comment, and noted the edit. reply tsimionescu 19 hours agorootparentYou edited to claim that \"ad\" is commonly understood to mean \"3rd party ad\", when in fact that is not true, and it's irrelevant either way. The idea of using my likeness in ads is disgusting, and likely illegal, even if they are first party ads. reply to11mtm 18 hours agorootparentAgreed that '3rd party ad' is a weird qualifier. For starters, what's '3rd party'? I remember when Google-Fi or whatever it was had the poorly animated, jingle sung-by-a 'totally not trying to cop Randy Newman vibe' ads. Would that be a 3rd party in that case? reply n144q 20 hours agoparentprevhttps://en.m.wikipedia.org/wiki/Advertising > Advertising is the practice and techniques employed to bring attention to a product or service. Advertising aims to present a product or service in terms of utility, advantages and qualities of interest to consumers. Nobody ever said that advertising must involve a third party. reply npteljes 20 hours agorootparentI feel like advertisements are on a spectrum, and that (let's call them) \"first party\" advertisements are not what come to people's minds, when they read a title like \"Instagram is using my face on ads targeted at me\". I'd like to prove this point by the following image search: https://duckduckgo.com/?t=ftsa&q=instagram+ads&iax=images&ia... . The top results all relate to advertise something on Instagram that is not Meta-related - so, third party ads. reply writtenAnswer 20 hours agoparentprevLol, literally calling an ad by meta not an ad. If they do it for Meta, the next logical step. This is from the same company that wanted to create official bots that would post, comment, react. Meta at this point is just throwing shit at the wall and hoping something sticks as a product. I am not afraid of my data being stolen, but it is a wake up call for what to expect. reply npteljes 19 hours agorootparent>Meta at this point is just throwing shit at the wall and hoping something sticks I feel the very same from the OP reddit submission. OP used Meta AI, and then Meta AI used it for more Meta AI. I'm sorry but this is a far cry from \"Instagram is using my face on ads targeted at me\". The implications of this title, and the situation it describes differ greatly. For example, if the user used Meta AI, and then got an ad of themselves driving a car, drinking a coffee, wearing some clothing, and the ad would be about that product itself, then I would have not made the original comment at all. reply ziml77 19 hours agorootparentYou're fighting way harder on this than I would, but I do agree that the title had me imagining being served an ad where I'm using the product being sold to me. Ads already are trying to make you think you'd be happy or popular by using their product by showing you people acting like that. It kicks that up to another level to literally see yourself happy because you're using a product that someone wants to sell you. reply Handprint4469 20 hours agoparentprev> These are not ads, rather something that is generated natively by the platform, not leading anywhere else but the platform that the user is already on So if Instagram shows you ads about Meta AI, it doesn't count as ads because both are owned by Meta? reply npteljes 20 hours agorootparentYes, in my mind, just saying \"ads\" are more for like Nike or Hyundai, than for a service provider upselling its own products. But this point is technically valid, these are advertisements as well. Just not what I, or others, first think of when they read \"Instagram is using my face on ads\". reply lelandfe 20 hours agorootparentIf you go into a Hyundai dealer and see a big banner about their new financing plan, isn’t that an ad? If the Nike catalog includes a full page promo for nike.com, isn’t that an ad? reply npteljes 20 hours agorootparentYes, it's an ad. My point is, and I even edited the original comment so that it comes across better: \"ads on instagram\" implies third party ads much more, than fist party upsells. Another example is \"Ads in Windows\". The popup for OneDrive is much less egregious than Candy Crush, or tabloid news in the Start Menu. This is because, while the user asked for neither, some consent was already given for the first party, while no consent was given to the third party. reply lelandfe 19 hours agorootparentYou rewrote your comment not to come across better but to make a different point. Your point was that this wasn’t an ad. Your point now is that you personally feel “ad” doesn’t typically mean first party ads. The former is wrong, the latter an opinion. reply npteljes 19 hours agorootparentWhat you call an opinion is not my original point, and even if so, I don't understand what you are trying to say. Shouldn't I have expressed an opinion here? reply lelandfe 19 hours agorootparentEditing a comment so substantially that your thesis changes makes you look deeply disingenuous. reply F7F7F7 18 hours agorootparentI’ve come down this far and can co-sign this comment. Holy canoli. reply npteljes 19 hours agorootparentprevThank you for your feedback. I'll strive to come across better the first time in the future. reply chillfox 18 hours agorootparentprevI really don't see a difference between upsell and 3rd party ads. I stopped using Evernote (was a paying subscriber) because I got annoyed by constantly having ads for their other services shoved in my face. reply ahoka 19 hours agorootparentprevBut Meta AI is not Instagram, so it’s not even first party? reply npteljes 19 hours agorootparentThe user gave their picture to Meta AI in Instagram previously, and Meta AI and Instagram have the same parent company, and the user also encountered the advertisement on Instagram. This is as first party as it gets, in my Hacker News submissions. Maybe not in legal language. reply fullshark 20 hours agoparentprevThis is just rationalization, everything the post said is 100% correct and the users are unhappy about it justifiably. reply tsimionescu 20 hours agoparentprevThey are an Instagram post that is shown to make you buy something, not because anyone you follow posted it. So, it's an ad. The fact that they're using your face in a Meta ad doesn't make it any different from any other ad. You're probably thinking about this as not a problem from a privacy perspective, and you may be right that this is not technically a privacy issue. But it's still a huge problem from a psychological influence perspective. Ads are already extremely good at manipulating your psyche, adding the ability to show you personally in some wonderful situations that their product would apparently put you in is a whole other level in manipulation. Plus, if this gets normalized, the next step is absolutely going to be to sell this as a new type of ad to other brands (assuming people end up interacting with such ads more). Edit to say: thinking about it, I actually think it's a privacy violation even for a Meta ad. Giving them permission to use an image of my face to generate a better selfie doesn't give them permission to use it to serve me ads. The GDPR is pretty specific about this: when you opt into sharing personal data for a specific purpose, that has to be interpreted in a narrow sense, you can't arbitrarily broaden the scope. reply tantalor 20 hours agorootparentImagine the ozempic ads that use your real face on a thinner body. reply dylan604 20 hours agorootparentIf you can then use those ozempic images for your own use, then I bet a bunch of people would be quite happy with it. reply tsimionescu 12 hours agorootparentI'd bet that this would be a bridge too far for many people, even the newer generations. People want to control how their likeness is used, many are not even happy to appear in their friends' pictures (at least to get tagged) unless they like the result and are asked before hand. reply dylan604 3 hours agorootparentThat seems like a strange conclusion with the extravagant use of heavy filtering so that nobody actually looks like what their social presence implies. They just need to tweaking the marketing and release it as a filter, but then include weasel words text that says anything used by the filter allows for them to selectively choose images to use as marketing. Essentially reversing the flow with sneaky consent reply amiantos 20 hours agoparentprevI'm with you. If I am at a bar and I see a sign that says \"PBR - $3\", I don't think of that as an advertisement. This user opted into Meta AI and (perhaps 'unknowingly' as no one reads the terms) gave their consent for this to happen, so I think 'hysteria' is appropriate and it's clear to me that here in the comments, opinions about this are based on feelings and not facts, and for that reason, it has to be described in misleading ways. I, too, have \"used Meta AI\", and have not had this happen to me. But I did not use Meta AI to generate pictures of me, so I did not check the box that led to this. That is one of the number of ways the way this post is titled in a way that is misleading. Simply \"using Meta AI\" in any capacity did not lead to this outcome. Additionally, the title suggests that the user gave his photos to Meta AI, and then a separate service, Instagram, is using his photos. That's not what is happening, he gave his photos to Meta AI (likely inside Instagram) and then Meta AI is using them (inside Instagram). There's no need to pretend two different services are sharing their photos around, but the post title is more engaging if there's the suggestion otherwise. reply fullshark 19 hours agorootparentWhen I worked as a waiter, we were supposed to tell the customers about the drink / appetizer specials before taking orders. This dialogue was in fact advertising as those were the high margin offerings at every restaurant. In any case I think it's more analogous to ads for tv shows while you're trying to watch a tv show. The media you want to consume (news feed) has ads interjected in it, in order to get you to spend more time consuming more content. reply npteljes 19 hours agorootparentNot really. OP was already an Instagram and Meta AI user. So, in the TV analogy, this would be like telling you about an upcoming programme, while you are watching a channel. reply npteljes 19 hours agorootparentprevI fully agree. There is a lot, a wide spectrum of abuse that Meta can be attacked for, and this little thing is not one of them. I think this is why I feel so personal about this - I do dislike Meta a lot, but I like it when people roast it for the actually valid reasons. I'm sorry for the downvotes, and appreciate your support. reply KaiserPro 20 hours agoparentprevIf Instagram shows you an old post with a picture thats got a filter on, or grouped some of your pictures together into a frame, saying \"look back on your memories and repost\" is that an advert? When your post comes up in the explore page of another user, is that an advert? what about those stupid \"Here is a post from your friends on threads\" with most of the stuff cropped off, as soon as you try and click it, its loads the fucking app store? Meta have done some terrible shit, but this isn't up there. Its not even a mili-cambridge analyitica. (or a pico-myanmar) its just a shitty app in their shitty social network. It seems like we are just hipster-hate yak shaving on something pointless, and missing the much wider point that the US needs decent data protections laws, and a functioning legislature. reply tsimionescu 19 hours agorootparentYour examples are not ads, because they are not trying to convince you to buy anything, or even to give Instagram/Meta any more data about yourself. Advertising a completely separate Meta business (Meta AI is not Instagram) is an entirely different thing. reply npteljes 19 hours agorootparentThis ad is also nothing what you describe - the user was already a Meta AI user. From the title: \"Used Meta AI, now Instagram is using my face on ads targeted at me\". So what happened is that Meta AI did a few extra easy image manipulations, and showed it to its user, on the same platform nonetheless, not even on Facebook or something. reply tsimionescu 19 hours agorootparentWe don't know some of this. MetaAI can be used independently of Instagram, I believe, so I don't know if it's certain that the user used it through Instagram. Also, don't they have a paid tier that they are likely trying to get them to upgrade to? reply KaiserPro 9 hours agorootparent> Also, don't they have a paid tier that they are likely trying to get them to upgrade to? no. reply KaiserPro 9 hours agorootparentprev> Meta business (Meta AI is not Instagram) Isn't threads a separate \"business\"? reply npteljes 20 hours agorootparentprevI fully agree. The reddit post is a nothingburger. It feels like it's more about someone wanting to express themselves, or fish for something that might worth good feedback, than someone who actually has something worthwhile to say. The actual good that this thing has is some feedback for people, to think about whether they want to use these platforms, or not. Being conscious about stuff like these is what I think does good to the world, and the well-being of people. reply carlosdp 21 hours agoprev [–] Maybe I'm in the minority here, but this is kinda cool! As long as the user data doesn't leave the Meta ecosystem (no reason to think it does right now, the ad in question here is from Meta itself), it's not a privacy concern since only you are being shown those unique ads with you in them. Even if other advertisers start using the system, as long as the generated resulting images are never shared with the advertisers and are unique to each user, its just a futuristic way to help you \"imagine\" what having XYZ product would be like, which is what most ads strive to do. People have knee-jerk reactions to anything to do with ads because of the privacy concerns of yesterday, understandably. But if you actually step back and think about this, there's no reduction in privacy that I can see. If people are creeped out by it, I think they should maybe let people disable them with a setting. But in general, making ads more effective without giving advertisers more data about us is a great thing for the continuation of free amazing internet services! reply afavour 21 hours agoparentMan, I absolutely cannot disagree more. If a service wants to use my face in an ad they need to ask me for permission first. The gradual erosion of user autonomy we’ve seen online over the past few decades never ceases to amaze me. > People have knee-jerk reactions to anything to do with ads because of the privacy concerns of yesterday, understandably. Can you elaborate on this? What were the privacy concerns of yesterday that we don’t need to worry about today? reply mysterydip 21 hours agorootparent> If a service wants to use my face in an ad they need to ask me for permission first. But you granted us full unrestricted access when you agreed to page 58 section J of our latest terms of service. - meta lawyer somewhere reply carlosdp 20 hours agorootparentprevIt's an ad only you can see, I don't see the harm. > What were the privacy concerns of yesterday that we don’t need to worry about today? The web/internet is a hell of a lot more private today than 10 years ago. Third party cookies are basically gone, mobile tracking is going out the door with Apple leading that charge, there are tons of relatively popular browsers and extensions that reduce tracking even more, there's enough privacy legislation that big companies have had to re-architect to preserve privacy as much as possible by default. Hell, if we're just talking about Meta, they literally nuked a thriving third-party developer API ecosystem to appease people's privacy concerns, out right. reply raxxor 10 hours agorootparentprevThere were times when users warned about the consequences of putting your images on the net. If you upload them on Facebook services, you gave away the rights on them I believe. reply unsnap_biceps 21 hours agoparentprevIf they use your picture to advertise to your friends, showing you in a nike shoe or whatever, that's still okay? It still wouldn't have left the Meta ecosystem. reply bandinobaddies 21 hours agorootparentThey might create an AI-generated person who closely resembles your friend but not exactly. If they do it undetected, it could have a massive impact. Imagine an ad featuring someone who looks just like your crush. I really hope this gets banned before anyone tries it. This scenario reminds me of Amazon Prime’s Live TV with hyper-targeted advertising. A friend who has it noticed that his ads revealed what he and his wife had browsed on Amazon. It was fun at times to see that we’d all been looking at the same items, but it also felt a bit too personal. Now he never turn on his TV whenever guests visit. reply carlosdp 20 hours agorootparentprevNo, because that would be sharing your photo and not unique to you as a user. I also don't really see why anyone would want to do that... reply npteljes 21 hours agoparentprevAs much as I loathe ads, I actually agree with you. I think these are good points. Among others, it's a very important realization that just by properly using these services, so much of the privacy has been given up already. It's just that services are clever about this, same as how corrupt populists: they do the damage, but keep away the negative feedback as much as they can, hiding, delaying, projecting, doesn't matter, as long as people don't feel it. This is why this ad seems outrageous: it provides this feedback. Demonstrates just a little bit of the power that they have over the person. So the user immediately sobered up, maybe even vowed something to the opposite. reply numpad0 18 hours agoparentprevI think you all pro-AI clusters should face the fact straight that people hate AI generated images. AI as an art style evokes primal hate and rage. If you show images to people that are linked to such set of emotions, such set of emotions arise among audiences. As demonstrated. This tendency of current AI image generators needs to be fixed before AI image generators could be used to create positive impacts. reply Devasta 19 hours agoparentprev [–] > But in general, making ads more effective without giving advertisers more data about us is a great thing for the continuation of free amazing internet services! Too right! Sure, Facebook may have facilitated multiple ethnic cleansings around the world, but its a small price to pay to facilitate a dystopian future in which tech illiterate, elderly boomers are bombarded with AI generated ads of their own funerals that encourage them to buy life assurance policies... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A Reddit user experienced Instagram ads featuring their own face after using Meta AI's \"imagine me\" feature, raising concerns about personalized advertising. - The incident sparked a debate comparing this level of ad personalization to the movie \"Minority Report,\" with opinions divided between seeing it as innovative or invasive. - The discussion underscores privacy concerns and the ethical implications of AI in advertising, with calls for stricter regulations to protect personal data."
    ],
    "points": 299,
    "commentCount": 171,
    "retryCount": 0,
    "time": 1736196298
  },
  {
    "id": 42616700,
    "title": "NYC Congestion Pricing Tracker",
    "originLink": "https://www.congestion-pricing-tracker.com/",
    "originBody": "Congestion Pricing TrackerBenjamin and Joshua Moshes(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])self.__next_f.push([1,\"1:HL[\\\"/_next/static/css/5905590dc4df3274.css\\\",\\\"style\\\",{\\\"crossOrigin\\\":\\\"\\\"}]0:\\\"$L2\\\"\"])self.__next_f.push([1,\"3:I[7690,[],\\\"\\\"]5:I[6497,[\\\"425\\\",\\\"static/chunks/2170a4aa-46df452611f659ea.js\\\",\\\"562\\\",\\\"static/chunks/3975359d-751912cee0702aff.js\\\",\\\"699\\\",\\\"static/chunks/8e1d74a4-a3474f6535ddbf0f.js\\\",\\\"437\\\",\\\"static/chunks/437-5df30bbdc20be9c3.js\\\",\\\"931\\\",\\\"static/chunks/app/page-7904272305bc5eb4.js\\\"],\\\"\\\"]6:I[8177,[\\\"185\\\",\\\"static/chunks/app/layout-51c3b2898f646269.js\\\"],\\\"\\\"]7:I[5613,[],\\\"\\\"]8:I[1778,[],\\\"\\\"]a:I[8955,[],\\\"\\\"]b:[]2:[[[\\\"$\\\",\\\"link\\\",\\\"0\\\",{\\\"rel\\\":\\\"stylesheet\\\",\\\"href\\\":\\\"/_next/static/css/5905590dc4df3274.css\\\",\\\"precedence\\\":\\\"next\\\",\\\"crossOrigin\\\":\\\"\\\"}]],[\\\"$\\\",\\\"$L3\\\",null,{\\\"buildId\\\":\\\"yAU28IMzIJw9go6BNP_AO\\\",\\\"assetPrefix\\\":\\\"\\\",\\\"initialCanonicalUrl\\\":\\\"/\\\",\\\"initialTree\\\":[\\\"\\\",{\\\"children\\\":[\\\"__PAGE__\\\",{}]},\\\"$undefined\\\",\\\"$undefined\\\",true],\\\"initialSeedData\\\":[\\\"\\\",{\\\"children\\\":[\\\"__PAGE__\\\",{},[\\\"$L4\\\",[\\\"$\\\",\\\"$L5\\\",null,{}],null]]},[null,[\\\"$\\\",\\\"$L6\\\",null,{\\\"children\\\":[\\\"$\\\",\\\"$L7\\\",null,{\\\"parallelRouterKey\\\":\\\"children\\\",\\\"segmentPath\\\":[\\\"children\\\"],\\\"loading\\\":\\\"$undefined\\\",\\\"loadingStyles\\\":\\\"$undefined\\\",\\\"loadingScripts\\\":\\\"$undefined\\\",\\\"hasLoading\\\":false,\\\"error\\\":\\\"$undefined\\\",\\\"errorStyles\\\":\\\"$undefined\\\",\\\"errorScripts\\\":\\\"$undefined\\\",\\\"template\\\":[\\\"$\\\",\\\"$L8\\\",null,{}],\\\"templateStyles\\\":\\\"$undefined\\\",\\\"templateScripts\\\":\\\"$undefined\\\",\\\"notFound\\\":[[\\\"$\\\",\\\"title\\\",null,{\\\"children\\\":\\\"404: This page could not be found.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":{\\\"fontFamily\\\":\\\"system-ui,\\\\\\\"Segoe UI\\\\\\\",Roboto,Helvetica,Arial,sans-serif,\\\\\\\"Apple Color Emoji\\\\\\\",\\\\\\\"Segoe UI Emoji\\\\\\\"\\\",\\\"height\\\":\\\"100vh\\\",\\\"textAlign\\\":\\\"center\\\",\\\"display\\\":\\\"flex\\\",\\\"flexDirection\\\":\\\"column\\\",\\\"alignItems\\\":\\\"center\\\",\\\"justifyContent\\\":\\\"center\\\"},\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"children\\\":[[\\\"$\\\",\\\"style\\\",null,{\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\\\"}}],[\\\"$\\\",\\\"h1\\\",null,{\\\"className\\\":\\\"next-error-h1\\\",\\\"style\\\":{\\\"display\\\":\\\"inline-block\\\",\\\"margin\\\":\\\"0 20px 0 0\\\",\\\"padding\\\":\\\"0 23px 0 0\\\",\\\"fontSize\\\":24,\\\"fontWeight\\\":500,\\\"verticalAlign\\\":\\\"top\\\",\\\"lineHeight\\\":\\\"49px\\\"},\\\"children\\\":\\\"404\"])self.__next_f.push([1,\"\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":{\\\"display\\\":\\\"inline-block\\\"},\\\"children\\\":[\\\"$\\\",\\\"h2\\\",null,{\\\"style\\\":{\\\"fontSize\\\":14,\\\"fontWeight\\\":400,\\\"lineHeight\\\":\\\"49px\\\",\\\"margin\\\":0},\\\"children\\\":\\\"This page could not be found.\\\"}]}]]}]}]],\\\"notFoundStyles\\\":[],\\\"styles\\\":null}],\\\"params\\\":{}}],null]],\\\"initialHead\\\":[false,\\\"$L9\\\"],\\\"globalErrorComponent\\\":\\\"$a\\\",\\\"missingSlots\\\":\\\"$Wb\\\"}]]\"])self.__next_f.push([1,\"9:[[\\\"$\\\",\\\"meta\\\",\\\"0\\\",{\\\"name\\\":\\\"viewport\\\",\\\"content\\\":\\\"width=device-width, initial-scale=1\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"1\\\",{\\\"charSet\\\":\\\"utf-8\\\"}],[\\\"$\\\",\\\"title\\\",\\\"2\\\",{\\\"children\\\":\\\"Congestion Pricing TrackerBenjamin and Joshua Moshes\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"3\\\",{\\\"name\\\":\\\"description\\\",\\\"content\\\":\\\"This project is run by Joshua Moshes and Benjamin Moshes, under the supervision of Brown University Professor Emily Oster\\\"}],[\\\"$\\\",\\\"link\\\",\\\"4\\\",{\\\"rel\\\":\\\"author\\\",\\\"href\\\":\\\"https://CongestionPricingTracker.com\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"5\\\",{\\\"name\\\":\\\"author\\\",\\\"content\\\":\\\"Joshua Moshes\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"6\\\",{\\\"name\\\":\\\"keywords\\\",\\\"content\\\":\\\"New York,Congestion Pricing Tracker,New York Congestion,New York Congestion Pricing Tracker,NY Congestion Pricing Tracker,Congestion Pricing\\\"}],[\\\"$\\\",\\\"link\\\",\\\"7\\\",{\\\"rel\\\":\\\"icon\\\",\\\"href\\\":\\\"/images/favicon.ico\\\"}]]4:null\"])self.__next_f.push([1,\"\"])",
    "commentLink": "https://news.ycombinator.com/item?id=42616700",
    "commentBody": "NYC Congestion Pricing Tracker (congestion-pricing-tracker.com)296 points by gotmedium 20 hours agohidepastfavorite508 comments elahd 3 hours agoThis is great, but I'd be more interested in seeing how congestion pricing impacts travel times for buses, specifically, (within and around the congestion zone, including express routes from the outer boroughs), as well as overall transit ridership. @gotmedium, would you consider integrating: 1. MTA's Bus Time feed: https://bustime.mta.info/wiki/Developers/Index and 2. MTA bus/MNRR/LIRR/Access-A-Ride ridership feed: https://data.ny.gov/Transportation/MTA-Daily-Ridership-Data-... 3. Equivalent feeds for city-connected NJ transit services. reply pimlottc 49 minutes agoprevThe name is rather confusing. I thought this \"Pricing Tracker\" was going to be tracking the pricing of the congestion toll (implying that it changes dynamically throughout the day), but what it's actually tracking is commute time. Something like \"Congestion Pricing Impact Tracker\" would be clearer. reply freditup 19 hours agoprevNote that it was snowy in NYC today, so people were likely dissuaded to drive by other factors than congestion pricing as well. It'll be interesting to see what impact there is as we get further along in the year. The dashboard is based off of Google Maps travel time data which I'm unsure of the exact accuracy. I imagine the city might also have other more direct metrics that can be used, such as the count of vehicles passing through the tunnels into the congestion zone. reply steveBK123 4 hours agoparentRight this dashboard won't be meaningful until 3/6/12 months out when any seasonality / weather related effects all average out. reply theamk 18 hours agoparentprevNote if you check \"unaffected\" routes (16 and 18), you'll see they had much smaller changes. Also, while simple metrics are cool, what commuters really care is how long it took to get from point A to point B, which is what this shows... reply kylebenzle 3 hours agorootparentYou are correct, steveBK is incorrect. reply ortusdux 18 hours agoparentprevhttps://www.wired.com/story/99-phones-fake-google-maps-traff... reply rtkwe 4 hours agorootparentIt's a neat little project but people aren't doing that on the regular so the data should be pretty good. reply ortusdux 3 hours agorootparentI do wonder how google handles edge cases, passengers, busses, etc. I've been in rideshares where the driver is using 4 phones - https://www.nytimes.com/2019/10/17/business/apps-uber-lyft-d... reply rtkwe 2 hours agorootparentI think, at least the way I would approach the problem, would be to look at the speed or flow rate of the phones on a particular road as the primary signal. I believe Google has ways of detecting if the device is in a car/vehicle vs being carried for example so they could filter out \"walking\" phones. Then looking at the flow of devices alleviates the need to calculate the carrying capacity of a particular road. The speed/flow tells you want you're trying to measure more directly than trying to count phones and decide if that means a road is congested or not, to do that you'd need to develop a heuristic to estimate the capacity of roads which seems like you're unnecessarily ignoring the direct signal in favor of trying to calculate it from a noisier source. reply MisterTea 5 hours agoparentprevSnowy? That was a light dusting that I cleaned up with a broom. reply dleink 45 minutes agorootparentI have a flexible commute that sometimes involves driving a car into the zone and if I see snow in the forecast I'll be less likely to be in the city with a car that day. I love congestion pricing, I will gladly pay $9 if it lowers traffic during peak hours. I also try to plan trips in the offpeak hours anyway. If you leave at 11pm you can get from shea stadium to Philly in an hour forty-five. reply johnkpaul 4 hours agorootparentprevI think it was worse in suburban areas slightly outside of the city, at least on the NJ side. In western Bergen county, I had a bit over 1 inch and had to break out the shovel for the sidewalk. reply MisterTea 3 hours agorootparentStill though, an inch or two around here is not a big deal. I only really start complaining when I have to break out the snow blower. reply steveBK123 6 hours agoprevI think the biggest thing CP is going to do in NYC is end toll shopping. There were previously some pretty obvious arbs available to people trying to get off LI. The biggest policy failure of CP though to me is that they left taxi/uber relatively unscathed. Often the majority of traffic is taxi/uber, so make the surcharge on them a fraction of what individual drivers pay is kind of nonsensical. Are we trying to minimize traffic (so tax call cars) or parking (so tax taxi/uber less since they don't have to park in Manhattan?). It smells of lobbying mostly. reply gregshap 5 hours agoparentThe uber/taxi fee is charged per ride, whereas private passenger cars pay once per day. Seems like a reasonable tradeoff. reply steveBK123 4 hours agorootparentPrivate passenger car driver is paying 12x Taxi toll / 6x Uber toll. Taxi/Uber toll is passed directly onto he rider. Why should it be cheaper to be chauffeured? Also your average Taxi may not even cross into the CPZ 12x per day, so unclear we are making it up on volume either. reply KevinGlass 42 minutes agorootparentIt should be cheaper. No circling the block looking for parking, no space needed at all for that matter. That alone is worth giving taxis/ubers at least a different pricing structure. reply enragedcacti 3 hours agorootparentprevSmall correction, every ride that starts and/or ends in the zone incurs the fee so a taxi that enters, does 12 trips, then leaves pays the same amount as a private car even though they only entered the zone once. reply steveBK123 3 hours agorootparentThat's great, but it's still too cheap reply timr 2 hours agorootparentprev> Why should it be cheaper to be chauffeured? It isn't. It's vastly more expensive to ride in a taxi when you include the fare. reply recursive 1 hour agorootparentprevBecause there are fewer cars in the system for each chauffeured ride vs private vehicle. reply xvedejas 1 hour agorootparentprev> Taxi/Uber toll is passed directly onto he rider. Only partially right? Tax incidence depends on the price elasticity of demand and price elasticity of supply. reply chimeracoder 45 minutes agorootparentprev> The uber/taxi fee is charged per ride, whereas private passenger cars pay once per day. Seems like a reasonable tradeoff. The fee for cabs was actually set by dividing the regular fee for private cars by the average number of trips cabs make into the Congestion Relief Zone per day (because the fee is only paid once per day for private cars, but per trip for cabs) reply throwawaymaths 4 hours agorootparentprevif the passenger car pays once a day, it's only generating one unit of congestion. reply connicpu 50 minutes agorootparentThe car takes up space in the city the entire time it's there, even if the congestion impact is less while it's parked. reply aqme28 9 minutes agorootparentThe lengths this city goes to keep free parking... reply steveBK123 4 hours agorootparentprevAnd further, if I am already paying $50 fare to take an Uber, a $1.50 toll is not deterring me or reducing my usage at all. It is less than the rounding error on the tip I give the driver. I probably won't even notice it amongst the 5 line items of fees, taxes, surcharges, etc on the digital receipt. reply Spooky23 3 hours agorootparentThis is where the dogma gets in the way of reality. Uber and cabs are the glue that fills the gaps that public transit has left unfilled for decades. The policy goal is to reduce congestion by discouraging personal vehicles in the zone and generate revenue for transportation as a whole, not to turn the city into a pedestrian park. The state took an approach that does that without nuking the city. Based on the fact that nobody seems to be giddy about this, I’d say they did a decent job at that. If the crazy transit nuts are happy and the angry Jersey people are happy, something went wrong. reply timr 1 hour agorootparentMoreover, the parent misses the forest for the trees: yeah, the congestion fee is lower than the fare, but the fare is vastly more expensive than driving a car. The current pricing model encourages resource sharing (this was true before congestion pricing as well), and the choice of whether or not you take a car or a cab is a function of the amortized cost of use per unit time. So yeah, just in terms of congestion fee it's a little bit cheaper to take an Uber for a single trip, but if you ride around in an Uber all day long, it's way, way less cost efficient than driving your own car. reply jakelazaroff 2 hours agorootparentprevThe congestion relief zone is probably one of the single densest transit zones on the planet. Rideshares and cabs are definitely useful for filling in the gaps in the boroughs, but you basically never need one in downtown Manhattan. reply tekla 2 hours agorootparentYou're forgetting that the transit zones themselves are not only affected, the main BRIDGES are also affected. So even if you're not driving in downtown Manhattan, you will still pay the cost to enter the city through the normal entrances ``` Manhattan's Congestion Relief Zone starts at 60th Street and heads south to include the Lincoln, Holland and Hugh L. Carey tunnels on the Hudson River side, and the Queensboro Bridge, Queens Midtown Tunnel, Williamsburg Bridge, Manhattan Bridge and Brooklyn Bridge on the East Side. Drivers will be charged when they enter the Congestion Relief Zone using the Brooklyn, Manhattan, Queensboro or Williamsburg Bridges, or the Holland, Hugh L. Carey, Lincoln or Queens-Midtown tunnels. Drivers coming from the Bronx or Upper Manhattan will be charged once they reach 60th Street. ``` reply chockablock 1 hour agorootparent> even if you're not driving in downtown Manhattan, you will still pay the cost to enter the city through the normal entrances Incorrect--if you take one of those bridges/tunnels below 60th street, then stay on FDR or West Side Highway to travel to a different part of NYC (i.e. you never enter the interior surface streets below 60th), then you don't pay the congestion fee. \"The Congestion Relief Zone includes local streets and avenues in Manhattan south of and including 60 Street, excluding the FDR Drive, West Side Highway/Route 9A, and the Hugh L. Carey Tunnel connections to West Street.\" https://congestionreliefzone.mta.info/tolling reply MisterTea 1 hour agoparentprev> I think the biggest thing CP is going to do in NYC is end toll shopping. Or toll beating. An old trick is taking a tractor trailer (or any big truck with more than a few axles) from LI to mainland without paying tolls: take the 59th st bridge, left onto 2nd, left onto 59th, left onto 1st and strait up to Willis bridge which leads strait into the Deegan. reply CPLX 5 hours agoparentprevHow do you figure that? The amount of the surcharge for the average taxi/uber driver per day will be many many multiples of the cost for a regular driver. In the case of a regular driver you you have someone paying $9 to bring a car into the congested area, probably serving one trip by one person. In the case of a TLC driver you'll have them paying probably well over $100 a day (assuming the $2.75 charge x 4-5 trips an hour give or take) and aiding in the transport of probably dozens of people to their destination. It seems completely obvious why this is a better approach to relieving congestion while still preserving the ability of people to get around. reply steveBK123 4 hours agorootparentI have a car and live in Brooklyn. I usually take an Uber anyway because parking is a pain and/or expensive. So I was previously comparing: $0 car toll + $20-50 parking vs $0 car toll + $50 Taxi/Uber fare Now I am comparing: $9 car toll + $20-50 parking vs $1.50 Uber toll + $50 Uber fare That is - the fee is being passed onto riders anyway, so why should I pay a lower toll sitting in the back of an Uber than when driving myself across the bridge? This is where some of the concerns about classism come into play. I'm already paying more to be driven around in an Uber vs drive myself. Why should I be given a toll discount? reply lolinder 3 hours agorootparent> This is where some of the concerns about classism come into play. I'm already paying more to be driven around in an Uber vs drive myself. Why should I be given a toll discount? It's not obvious that Uber is exclusively the higher-class option. Someone could easily make the same calculation you just did and decide that for them even owning a car wouldn't be worth it, they'll just do Uber every time they need to. You can afford to own a car and do Uber anyway, others can only afford to Uber occasionally when needed. I don't have data to back it up, but I would actually be surprised if the average Uber customer in NYC owns a car at all. reply onlyrealcuzzo 3 hours agorootparent> You can afford to own a car and do Uber anyway, others can only afford to Uber occasionally when needed. This isn't really a different class. The other class is the people who can't afford a car or Uber and can barely afford the MTA. reply lolinder 3 hours agorootparentAgreed, I'm just using the terminology that OP was. The actual class lower than this doesn't pay the toll at all, whether the Uber toll or private car toll. reply np- 4 hours agorootparentprevThink of the congestion charge as a charge on the vehicle, rather than on the person, as the stated policy goal is to reduce the number of vehicles in the CBD, not the number of people overall. The Uber is very likely going to continue to be used to service other passengers after dropping you off within the same calendar day, so one potential \"fair\" solution is to split the congestion charge among the many passengers using that one vehicle. That is your reduced Uber toll charge. But even in this case, it's not really an even split, taxis are going to generate a much higher congestion charge revenue than a single passenger car. reply jakelazaroff 36 minutes agorootparentThe rideshare toll is already a charge on the vehicle and not the riders. If you share an Uber with two other people, the per-person congestion fee for the trip drops to $0.50. reply chockablock 1 hour agorootparentprevAlternatively, day parking rates drop enough (due to market forces) to compensate for the cost of the toll. reply CPLX 3 hours agorootparentprevOnce the Uber drops you off, it's available to take someone else somewhere they need to go. Car services are an essential part of a total system that enables people not to have to drive. Personal cars are the opposite of that. It's one of those things about the way Americans think about transit that makes me insane, they try to assess the ROI of every single individual leg of a transit system rather than assess the system as a whole. For example they'll cancel late night bus service because very few people use it. Except that the people who do, are people who occasionally are forced to stay late at their job and rely on the bus running late. Once it's cancelled they have to drive to work every single day since they're not sure they won't be stranded. The 3-4 bus rides a month they used to take are exchanged for 22 private car trips because you cut back service. That's just one example. Here's another more suited to your example. What if you generally switch to taking transit into the city, and only take an uber when it's raining or you have something heavy to carry? If I allow there to be a robust market for Ubers in the city then that's possible. If I aggressively charge Ubers then you can't do that, and you're back to driving every day. There's plenty of examples. But in short it's clear that private cars are by a mile the worst and most inefficient thing occupying the roads. That's what we want to have the strongest incentives against. reply gruez 3 hours agorootparent>For example they'll cancel late night bus service because very few people use it. Except that the people who do, are people who occasionally are forced to stay late at their job and rely on the bus running late. Once it's cancelled they have to drive to work every single day since they're not sure they won't be stranded. The 3-4 bus rides a month they used to take are exchanged for 22 private car trips because you cut back service. That's a cute anecdote but is there any empirical evidence behind this? I'd imagine the people who commute downtown, stay late often enough that this is a concern, is willing to take the bus even though they have a car and can otherwise afford daily commute downtown (gas/parking), but at the same time can't pay for an uber on those late nights, is approximately zero. reply CPLX 2 hours agorootparentMy empirical evidence is going to Europe and looking around. I'm being somewhat argumentative on purpose but the concept I'm explaining actually is important. There's something similar to a phase change when a city/area becomes sufficiently well connected so that transit can basically solve every problem. You go to somewhere like Switzerland and it just jumps out at you. There's a fundamental approach that everywhere someone wants to go should be accessible by transit in a way that's workable. There's also a fundamental decision that being able to bring a car somewhere isn't necessarily something that has to be supported. It's just a different way of looking at things. Can you envision an American town that literally does not allow cars anywhere near the actual town, like at all? If that seems utterly impossible to visualize then you're starting to see what I mean. Now try to visualize a Swiss town that literally has no ability to connect to the broader transit system. reply steveBK123 3 hours agorootparentprevI guess to me it just seems like you want to deter end users picking taxis/ubers over trains a bit more, and $1-2 is not going to do that when they are already paying 5-10x subway fare for their ride. I can see by your example how over the course of the day the taxi/uber collects a lot of CPZ fees for the city, I just don't see the fee reducing anyone at the margin from using taxi/uber. At the end of the day I'd love to see transit improve, and if all this does is reduce traffic for the well heeled who already are taking taxi/ubers.. I mean I win there too, but it doesn't feel great. For the record when I commute it's always by transit, the problem is weekend/night service has degraded to the point that I feel forced to take taxi/uber quite often. I've lived in NYC nearly 20 years and have found, if anything, night/weekend service to be less predictable and more perplexing. This again harms the less well off even more, as they are more likely to be doing shift work / non-traditional workdays than your M-F 9-5er. Just this weekend, yet again, I was trying to get around midtown and Apple kept telling me what should be a 6min trip would take 30min by train even though I was 5 seconds from subway entrance. I couldn't understand why, and went to MTA website and saw no alerts for the 6th ave line. Then I went to the live train time page and realized the problem - the 6th Ave line was running at 15min headways, so Apple had me walking 2 blocks to 8th Ave then to wait 15min for the train (possibly 30min if its a B/D and I needed an F/M). This was Saturday around dinner time. Just awful service. reply chimeracoder 41 minutes agorootparentprev> In the case of a TLC driver you'll have them paying probably well over $100 a day (assuming the $2.75 charge x 4-5 trips an hour give or take) and aiding in the transport of probably dozens of people to their destination. This is completely wrong. First, the fee for cabs is different from the fee for private cars, and in fact, it was set at the value which is the private car fee divided by the average number of trips into the Congestion Relief Zone that cabs make each day. Second, passengers are the ones paying the fee, not cab drivers. It's one of the fees tacked on to your receipt. Third, this fee has already been charged on cab fares since 2019. The only difference is it's now being applied to all vehicles except taxis/FHVs. For cab drivers, there's no difference - it was the one part of the program that has already been in effect for years! reply jdlyga 4 hours agoprevTaking the bus from Weehawken into midtown is super smooth now. It's a super cold Tuesday, but normally it's a honking mess. reply awkward 3 hours agoparentThe subway was insane. Could be the snow, though. reply wnolens 2 hours agorootparentYea, not sure if it was a post-holiday thing or weather thing, but shit the trains have been rammed. reply blehn 3 hours agoprev1. The data is obviously flawed, but if there's anything to speculate from it, it's that the actual congestion in lower Manhattan isn't affected that much. 2. So the success of this policy really depends on how much additional revenue it's bringing in for the city and the MTA. The $9 increase needs to significantly offset the loss in toll revenue from the decrease in drivers. 3. There are so many other simple policies that would benefit quality of life in NYC: - Daylighting — Don't allow cars and trucks to park at the corners of intersections. Huge safety benefits. - Metered parking everywhere. Why is NYC giving away the most valuable real estate in the world for free? Would be a huge revenue stream while discouraging car ownership in Manhattan. - Close more streets to car traffic. This is already true on 14th street and it's fantastic. Close Houston, 34th, 42nd, 59th, 125th. This would make buses much more efficient and further discourage passenger car usage reply ihuman 3 hours agoparent> So the success of this policy really depends on how much additional revenue it's bringing in for the city and the MTA. I thought the point of the policy is to get people to use the train instead of cars, freeing up the roads for people that actually need it? reply bluGill 2 hours agorootparentThere are several points. Some want it to get people to not drive, but work from home or drive elsewhere instead is fine with them. Some want it to get more people on transit. Some want it to fund transit expansion. You can belong to more than one of the above groups. Nobody belongs to them all. reply barnabee 2 hours agorootparent> Nobody belongs to them all. Why not? IMO, ideally: - Some people work from home or drive elsewhere - Others take transit instead of driving - The remainder pay a fee that they didn't previously, which can fund more transit reply bluGill 1 hour agorootparentI didn't give anywhere close to all the different interests here. reply jacobgkau 2 hours agorootparentprevThe first sentence they said was: > 1. The data is obviously flawed, but if there's anything to speculate from it, it's that the actual congestion in lower Manhattan isn't affected that much. I'm not saying that's correct or incorrect, but the person you replied to already considered what you brought up and responded to it. The primary \"point\" seems not to have worked, so the in-practice reason to keep the policy becomes other benefits, which for the city would include revenue being raised. (I guess you can argue it's not a \"success\" if the main point wasn't achieved, but good luck convincing the city to give up the additional revenue.) reply varelaseb 2 hours agoparentprevThis is the most econ-brained response possible. Why would the success of a public policy be exclusively defined by revenue generated? reply blehn 44 minutes agorootparentFirst, it's not exclusively defined by revenue (which is what my first point was alluding to). Second, the underlying assumption of revenue generated is that it's going to the MTA and used to improve public transit and therefore quality of life in the city, which would be a success. reply ses1984 2 hours agorootparentprevBecause it’s based on the assumption that congestion didn’t actually go down, see number 1 posted by op. If you want congestion to go down, keep raising the price. It will eventually go down and revenue could go up a lot. reply bluGill 2 hours agorootparentOr you get voted out of office and your charges reversed down to zero - or perhaps negative as the people are so mad they take it out on the transit this was supposed to fund. Politics is tricky, don't take so much you make people affected mad enough to undo what you wanted. reply ses1984 2 hours agorootparentBoth parties like money so one party may be voted out if people are angry, but it’s unlikely to result in the charge going away. It’s also nyc primarily in charge of it and nyc constituents probably are in favor of less congestion and more money. reply Rastonbury 1 hour agorootparentprevBig econ brained is thinking about whether the congestion pricing is approximately captures the negative externalities of traffic reply woodruffw 2 hours agoparentprev> The $9 increase needs to significantly offset the loss in toll revenue from the decrease in drivers. Many of the entries in question are not tolled: the Brooklyn/Manhattan/Williamsburg/QBB are all toll-free, but are included in congestion pricing. Similarly, the street-level entries to the congestion zone were never tolled. I think the state's calculations probably conclude that these more than offset the drop in toll revenue. (Or, more nuanced: much of the previous toll revenue went to PANYNJ, whereas congestion pricing funds go directly to the MTA/NYCT.) reply jakelazaroff 2 hours agoparentprevAdvocates did worry that reducing it from $15 to $9 would create a sort of \"no-mans land\" — not quite high enough to deter traffic but high enough to annoy people. I'm not sure how to reconcile the significant drop in the bridge and tunnel commute times with the apparent non-effect on commute times within the congestion relief zone. reply sethhochberg 2 hours agorootparentMost of the bridges and tunnels have their own tolls, with a few exceptions like the Brooklyn and Manhattan bridges. One possible explanation is that the advocates were right and the combined bridge/tunnel + congestion toll is enough to dissuade driving into the zone entirely for people arriving via bridge/tunnel, but the lower congestion toll on its own isn't as much of a deterrent if you have access to a free crossing into Manhattan from other boros or were already in Manhattan (outsize of the zone) to begin with. reply blehn 54 minutes agorootparentprev> I'm not sure how to reconcile the significant drop in the bridge and tunnel commute times with the apparent non-effect on commute times within the congestion relief zone. Yeah, I'm not sure what to make of that either but it'll be interesting to see when more/better data comes available. Maybe car traffic getting to Manhattan is reduced but those people are using more taxis and Ubers to get around once they're in reply spamizbad 2 hours agoparentprevYou also have to factor in any reduction (or increase) in traffic fatalities and injuries. 34 traffic deaths and roughly 7500 injuries occurred in Manhattan in one of the nation's highest GDP-per-capita area, so the loss of economic output from these fatalities and injuries is likely fairly high. reply adamc 2 hours agorootparentNot to mention the costs of treating them. reply CPLX 2 hours agoparentprev> Metered parking everywhere. Why is NYC giving away the most valuable real estate in the world for free? Would be a huge revenue stream while discouraging car ownership in Manhattan. There isn't all that much free parking left in Manhattan south of 60th street. Not saying it doesn't exist, there still are alternate side streets for sure, but it's a rapidly dwindling thing. Agree that it should be almost nonexistent though for the most part. Also the cost of metered parking in most of the city these days is similar to garage parking pricing. reply jimbob45 2 hours agoparentprevMetered parking everywhere. Please no. Just tax me at the end of the year if you really need more money. Stop paywalling everything. reply asoneth 1 hour agorootparentOthers have mentioned the unfairness of asking taxpayers to subsidize drivers. This is particularly egregious in Midtown Manhattan where many taxpayers are not drivers and many drivers are not (local) taxpayers. But even as a driver I prefer when cities place an efficient price on parking. Otherwise, if parking is too cheap compared to demand it costs time and stress circling the block to find a place to park. Market pricing, where the city sets whatever prices are necessary to maintain an empty spot or two on each block, seems more fair, efficient, and pleasant. reply dleink 43 minutes agorootparentAny examples of cities that have done a good job on this? reply fnfjfk 2 hours agorootparentprevWhy should everyone pay equally, rather than people that currently store their private property for free on public land in some of the most expensive real estate in the country? reply jacobgkau 2 hours agorootparentprevThe point wasn't supposed to be to raise more money, it was to decrease the amount of people using the roads. Taxing more would, if anything, incentivize people to use those parking spots to \"get their money's worth.\" More realistically, it would not add a barrier to actually parking on a day-to-day basis. Making you think about and reconsider it every time you go to do it with the paywall is what they want (and what is arguably necessary in order to fix the underlying problem, unless those tax dollars are going to go towards multi-level parking garages that add spaces and not just the existing roads). reply renewiltord 4 minutes agorootparentprevIt’s kind of how I feel about rent too. Instead of paywalling this $7k/mo apartment maybe just tax everyone a fair amount? reply paxys 18 hours agoprevWhile I'm sure congestion pricing will have a positive impact on traffic, I'd wait a little while longer to draw any conclusions, considering (1) the data is from a single day (2) lots of people aren't back from holiday travel and (3) there's a winter storm across the country and a decent amount of snow fell in Jersey/New York today, discouraging driving. reply occz 14 hours agoparentYou can already extrapolate from the results from other cities who have implemented the policy, where it has been wildly successful at reducing congestion. reply polon 4 hours agorootparentSo far, none of the data provided by the linked site would suggest Manhattan will see a reduction in transportation times. This is with the Monday snow however, which I'd imagine caused delays by itself. I will say, being in Manhattan, their seems to be less traffic on the road. I wonder if Google Maps traffic data is using a rolling average of ~7 days or something reply yt-sdb 30 minutes agorootparentAre you sure? Compare before/after for the main affected regions (Holland Tunnel, Queensboro) versus the unaffected regions. We definitely need more data, but I think there's an immediate reduction in the obvious places. reply asdff 1 hour agorootparentprevGoogle maps traffic data is live reply freejazz 3 hours agorootparentprevI thought London's traffic returned to the same levels as prior to their congestion pricing? reply coding123 12 hours agorootparentprev... for rich people. reply occz 10 hours agorootparentNope, it's been great for poorer people who take transit at higher rates than others, and congestion pricing funds useful transit expansions for them. reply jdkdkdkfj 9 hours agorootparentnext [3 more] [flagged] occz 8 hours agorootparentThis comment is telling about your values when it comes to both cars and buses. Consider some introspection. reply jdkdkdkfj 7 hours agorootparentnext [2 more] [flagged] vcarl 7 hours agorootparentYes, you stand behind your comments so strongly you created an anonymous throwaway account just to share them. reply Lanolderen 7 hours agoprevI wish people would focus more on scooters and motorcycles than moving people in busses. Coming from a place with decent and cheap public transport, no one likes it. It'll never be as fast, you'll always be closed in a bacteria greenhouse with strangers, there will always be crazies, it'll never have the exact path you need, you don't have as much control over it.. For the past year I've been commuting on a motorcycle with no car and even with snow it's surprisingly fine. Maintenance is cheap since it's much more DIY friendly, I get back from work up to 65-70% faster than cars, usually 35-40% (rush hour), I average 5,8-6,1 l/100 without trying to save fuel.. It's very comfy if you're not in a location where winters are particularly harsh. But at that point freezing your ass off at a bus station waiting to get in the bacteria greenhouse isn't great either. reply alamortsubite 6 hours agoparentYou're way overplaying the dangers of \"crazies\" and \"the bacteria greenhouse\" with respect to travel by motorcycle or scooter (or even automobile). I agree with your point that we should encourage these modes of transportation over cars, but I'd add it will be electric bikes that finally turn the tide on traffic congestion in cities (and all the other great benefits that come with doing that). Just don't tell the electric bike people that they're essentially riding motorcycles. reply Lanolderen 5 hours agorootparentI mean, I'm definitely biased but I've been sick once since ~2015 and that was Covid I caught at a large anniversary celebration. Before that I wasbeing in a pod with a hundred people you don't know and who have not been screened for insanity, excessive odor, sickness and general obnoxiousness. These events do happen, but they're pretty rare. For the most part, people on the bus are just people, who happen to be on a bus. Just like there are crazy drivers, there are sometimes crazy bus passengers. At least the crazy bus passengers aren't piloting 4000 lbs of steel :) reply asdff 1 hour agorootparentprevChiming in to say I also prefer public transit. Why focus on the ride at all when I can just read a book and teleport? And the real danger of motorcycles is to yourself. You could end up living with a feeding tube slipping in a shower let alone a minor scuff at 25mph. reply pxmpxm 15 minutes agorootparentYou don't have to be the one driving... reply mitthrowaway2 2 hours agorootparentprevHi, nice to meet you! I prefer public transit because when I ride it I don't have to drive or find a parking spot! And I believe it to be safer on balance. reply code_for_monkey 1 hour agorootparentprevI prefer public transit! No parking, I dont feel nearly the same frustration, I dont have to make decisions, and at the end of the day I can be a little high on the train. Its bliss. reply freejazz 1 hour agorootparentprevHave you even been to NYC? reply khafra 3 hours agoparentprevComing to a place with decent and cheap public transport six months ago: 1. It's faster than commuting by car during rush hour, and otherwise 10%-20% longer within the city limits. 2. There's no crazies. I haven't seen so much as someone rocking and muttering, let alone bothering other passengers. 3. Yeah, it's a petri dish--I've been sick enough to miss days of work twice in the last six months, which is more than in the two years before moving here. I'm not sure how well 1 and 2 could generalize from Germany to America. You'd need Harberger Taxes or liberal use of Eminent Domain to put rail networks into a city. You'd need competent and well-funded law enforcement to curtail the crazies. #3 we could fix in either area with UVC and filtered air circulation; or I could just get comfortable with being the weirdo wearing an N95 mask every day I have also commuted by motorcycle for around 30k miles. It does save a lot of money, but it's not much faster than cars if you're strictly following the law in the 49 states where lane splitting isn't fully legal. You also have 90 times the risk of death per mile travelled, compared to a car, which balances the increased disease risk on a train. reply potato3732842 2 hours agoparentprev>I wish people would focus more on scooters and motorcycles than moving people in busses Will never happen. Too 3rd worldy for many of the demographics that tend to drive policy on transit matters. reply CoffeeOnWrite 1 hour agorootparentE-bikes though? reply dralley 14 hours agoprevFantastic. That's step one, now fix the public transit, and make it safer and cleaner, so that people actually enjoy using it consistently rather than just needing to do so. Do that and NYC will be a much, much nicer city to live in. reply asdff 1 hour agoparentIt will never be “safe” or “clean” enough for the people who think it is unsafe today. Because for some people they see one homeless person and it ruins their day. They fail to realize that hey, transit is the means of transport one might take when you have no money at all, and you are always going to have homeless people on it and its not a big deal either. reply fuzzylightbulb 13 hours agoparentprevThat is literally what the money is for reply steveBK123 4 hours agorootparentThe problem is it's just not that much money against the inflated costs of NYC transit construction. It's budgeted to produce $1B/year, though that was before Hochul unilaterally cut the toll by 40%. $1B is like a 2000ft of subway tunnel or half a station these days. reply snake42 3 hours agorootparentThe fact that its a recurring revenue scheme allows them to get bonds based on that income. I think I saw that they were planning to secure $18B for a project when it was $15 for the toll. reply steveBK123 3 hours agorootparentYes though I'd imagine its harder to secure bonds now that Hochul has shown the governor can unilaterally change the fee on a whim, plus new Federal government is antagonistic to the whole program. Hochul won NY by a fairly narrow margin historically for the state against a pretty MAGA GOP guy. It's entirely possible some more normal blue state GOP type runs against her, wins and reduces the fee further. reply onlyrealcuzzo 3 hours agorootparentprevYou're gonna need a lot more money than that when ~40% of MTA total spending goes to pay pensions and healthcare for people that don't even work anymore by ~2040. You need ~35% just to keep the system running functioning (which does not include operations - like the actual drivers). That's only going to leave you ~25% leftover for everything else - and a non-trivial percentage of that comes from the Federal Government - which may not be there in the future (when all of their money is going to pensions and healthcare). reply kethinov 6 hours agorootparentprevWould be nice if they made transit better first instead of making driving worse first. reply throw4847285 4 hours agorootparentDriving in New York has been terrible for a century. The only way to make it better is to disincentivize people from doing it by making it more costly and making public transit better. Urban planners have known this is the case since at least the 40s. Congestion pricing isn't some kind of new punishment. It's a bill, long overdue, finally getting paid (and only partially). reply gcbirzan 3 hours agorootparentRobert Moses knew it, but that didn't stop him. reply throw4847285 2 hours agorootparentI'm not sure Robert Moses knew that. He wasn't an urban planner. He was an urban doer. He made it his life's mission to not learn the actual impact of his work on people's lives. I suspect he took that willful ignorance to his grave. reply gcbirzan 20 minutes agorootparentOh, no, he knew. reply izacus 5 hours agorootparentprevAnd will the drivers be prepared to fund this via another channel? reply lotsoweiners 4 hours agorootparentThey already fund it via gas tax, registration fees, regular taxes. Let the public transit takers fund their own improvements. reply CSMastermind 13 hours agorootparentprevWhen I lived in NYC I paid huge amounts of money in taxes and as far as I can tell got very little for my money. Until they can start using their enormous existing budget wisely I don't see any reason they should be given more money. reply durumu 3 hours agorootparentI agree NYC is not wisely spending its $100 billion per year, but I think the congestion tax makes sense as a way of pricing in externalities. As a non-car-owner in lower Manhattan I dislike passenger cars -- they make it much less safe for me to bike around, and less pleasant for me to walk around. I think most people here benefit if we have way fewer large vehicles in the city, so the limited spots should be reserved for people who get immense economic value from them, like truckers or movers, not random people from the suburbs who want to have dinner in the city. reply CPLX 5 hours agorootparentprev> as far as I can tell got very little for my money You literally lived in the greatest city in the history of world civilization. Sorry it didn't work out for you. reply steveBK123 4 hours agorootparentTokyo is pretty nice reply Aspos 4 hours agorootparentprevYou seriously think NYC is the greatest city in the history of world civilization? Or is it sarcasm? I am asking this as NYC resident. reply indoordin0saur 3 hours agorootparentIf your definition of greatest is \"total GDP\" then it is the greatest in the world. That said, I would agree that Tokyo and maybe even London are much finer examples of cities. reply tokioyoyo 4 hours agorootparentprevAs my sister says (lives around Prospect Park with kids) — if you don’t gaslight yourself that it’s the best city in the world while paying such premiums to live here, you’ll get depressed in a second. But I agree, I’m scratching my head whenever I hear that statement. It’s definitely the best city in USA though, as there are about 3 real cities in the country. reply CPLX 3 hours agorootparentprevOf course I do. Ask any person living in New York, they'll tell you the same thing. reply potato3732842 2 hours agorootparentUnless you happen to ask the large fraction of people who knowingly moved there to make big bucks for some number of years before getting out. They will all tell you it sucks, the government sucks, you suck for not realizing that and that they're masterminding their exit to the suburbs of Phoenix or Miami or whatever. These people make up a sizable minority of the NYC population at any given time. reply CPLX 1 hour agorootparentWell yeah sure, but obviously people who fail at living in New York don't count. reply nothrabannosir 1 hour agorootparentI regret to say: I’ve lived here long enough to believe you genuinely mean it when you say that. reply nothrabannosir 3 hours agorootparentprevWhere else have you lived? I live in nyc today and whenever I hear people say that , it turns out they mean “New York City is the greatest city in the world of New York City and Waterloo, Wisconsin.” And even then , I’ve seen photos of Waterloo… looks like the air is nice and breathable there. And apparently you can afford to rent a place on a normal salary. You don’t have to agree but at least try and get out of your bubble. You don’t even know enough different people in New York City itself to support that claim, apparently. reply CPLX 2 hours agorootparentI mean it's not hard to figure out. Here's an easy test. Think of the city you currently live in. Ask people where you live if they think this city you're living in is better than New York. They'll have a lot to say about it. If you ask people in New York if the place you live is better than New York they'll say \"Huh, where is that?\" reply Aspos 2 hours agorootparentSuch metric would just indicate that respondents are unaware of other cities, no? Majority of new yorkers never lived in good cities. I guess many just repeat 100 years old notion that NYC is the best city in the world and just never doubt it. reply nothrabannosir 2 hours agorootparentprevI mean… yeah; I think we agree there. That’s kinda my point: people here whom I know to claim New York City is the greatest city in the world don’t actually know a lot about the world. reply CPLX 2 hours agorootparentI've literally been to 80+ countries and have spent time in every U.S. city of significant size. If you can't look at the world and figure out the obvious fact that New York is the greatest and most significant city that has existed since we climbed down out of the trees I'm not sure what's going to convince you. reply pxmpxm 11 minutes agorootparentThe odds of you calling yourself \"native new yorker\" and having never actually lived anywhere else are virtually 100% dleink 19 minutes agorootparentprevhow do you reconcile this theory with the existence of the Mets? asdff 1 hour agorootparentprevEhh not the best weather and they haven’t invented the trash can or dumpster yet. You can get good food everywhere these days. And as the years go by I am less and less interested in drinking till 4:30 am especially at todays bar prices. reply gradschool 3 hours agoprevCongestion charging started in London in 2003. I'm skeptical about the justification that it's intended to disincentivize unnecessary driving because people who drive frequently get a bulk discount rather than a surcharge as one might expect if that were the actual intention. A bulk discount is more indicative of a policy intended to maximize revenue. I'm also skeptical about the justification that it's intended to reduce pollution because the discount for electric cars is ending this year. I have a moral issue with it as well because the roads are financed by everyone's taxes. Around the time the charge was starting it was easy to find supporters for it on tv chat shows but I never met one in real life. I assume there are some but that they support it in a naive attempt to keep anyone poorer than them off the road. Otherwise, the supporter's problem of too much congestion would be easily solved by not driving. The charge has tripled since its introduction so maybe there's an element of poetic justice in it for some of them. reply gruez 3 hours agoparent>I have a moral issue with it as well because the roads are financed by everyone's taxes Mind elaborating on how this is a \"moral issue\"? Public transit is funded by \"everyone's taxes\" as well, but you still have to pay a fare to use it. Do you get similarly aggrieved? >Around the time the charge was starting it was easy to find supporters for it on tv chat shows but I never met one in real life. It's trivial to find polls that show a non-negligible level of support for the charge. eg. https://www.theguardian.com/politics/gla/page/0,9067,897312,... or https://www.vitalcitynyc.org/articles/how-london-and-stockho.... Just because your small circle of friends don't support it, doesn't mean they don't exist. reply gradschool 28 minutes agorootparentYour points are well taken. I wasn't aware of the Guardian poll and I stand corrected about my implication that the charge lacks public support. With regard to the moral issue, I have less of a problem with tickets that are paying for something like running a train, or for that matter a bridge toll paying off the bonds that enabled the bridge to be built. I have more of a problem with someone demanding money for nothing. I haven't heard it claimed even by its supporters that road maintenance depends on the congestion charge. To my knowledge the main justification has always been that the charge funds the payer's behavior modification. Is it for the payer's own good? Is it for the greater good? You may well differ, but something about that doesn't sit right with me however noble, especially when it pertains to law abiding citizens acting within their rights. reply comprambler 18 hours agoprevCongestion pricing can work to dissuade individuals from living in the burbs, only if there is controls on real estate to deal with the influx of people moving inward. The other benefit is an increase of mass transit usage, which is a plus? I personally took a cab from Newark to Laguardia at MIDNIGHT and it took 40 min to cross into Manhattan to get to the Queens-Midtown tunnel. Just a new level of traffic. Was fun going in the MIB tunnel. reply woodruffw 18 hours agoparentLiving in the suburbs is perfectly fine; I think a perfectly virtuous outcome here would be that people keep living in the suburbs if they wish, but have adequately funded suburban rail and bus transit into the city. An important piece of context is that NYC has some of the US's best suburban transit, including three different suburban rail systems (NJT, MNRR, LIRR) and one non-subway interurban rapid transit system (PATH). reply nfRfqX5n 18 hours agorootparentProblem is, none of the money from congestion pricing is shared with NJ transit/infra reply woodruffw 18 hours agorootparentThat's because they turned it down[1]. New Jersey has decided that their strategy is going to be to dig their heels in and hope for a supportive administration, rather than plan for the next century of growth in the economic region that powers their state. [1]: https://nyc.streetsblog.org/2024/12/18/nj-refusing-generous-... reply gotoeleven 17 hours agorootparentSweet lord have you ever tasted a peach grown in new jersey? What the hell is going on in that state. reply Moomoomoo309 6 hours agorootparentMost superfund sites of any state, decades of chemical industry and now pharma, and also peaches not really liking how north NJ is, mostly. Jersey's a wacky place, for sure, but believe me, the politics in New Jersey get even crazier than this due to boroughitis. reply rangestransform 17 hours agorootparentprevNYS offered, NJ sued NYS, NJ lost It would be a completely ok thing for NYS to tell NJ $0 get bent, NJ coulda spent turnpike widening money on transit instead of begging from NYS reply kevin_thibedeau 14 hours agorootparentprevNJ needs to stop its commuter residents paying NY income tax, particularly those doing WFH more than half the year. They can boost NJT with that pile of money. reply woodruffw 13 hours agorootparentHow do you propose they do that? NJ doesn't levy NY's taxes, NY does. (To my understanding, NJ gives every resident an equivalent income tax credit for the taxes they pay in NY. Given that they can't stop NY from taxing its own employees, this would mean they'd effectively need to double income taxes for NJ residents.) reply afavour 12 hours agorootparentprev> They can boost NJT with that pile of money. NJ has had many opportunities to do so over the years and consistently chooses not to. reply insaneirish 14 hours agoparentprev> I personally took a cab from Newark to Laguardia I don't understand why anyone would ever attempt to do this. Was it truly the only option? reply comprambler 13 hours agorootparentFlight got rebooked with a couple hours notice, stayed at LGA checkin till it opened, had the first flight out. Fare was more than 100$ reply alamortsubite 5 hours agorootparentprevI did JFK-EWR coming back from HND one time. Not the only option but probably the best, all things considered. That's life in the fast-paced, slam-bang, laugh-in-the-face-of-death world of non-revving. reply jgil 18 hours agoprevIt would be interesting to see the effect on average noise levels. Anecdotally, I have heard fewer honks from single unit trucks today. reply bongodongobob 11 hours agoparentActually, I bet noise levels would be a really good proxy to measure the effect itself. reply kittikitti 14 hours agoprevGood, I was hit by a car in NYC while on a bike and it caused a fracture. If this reduces congestion, then I support it because I could have easily died. However, this was accompanied by hikes in public transit pricing. I don't think transit officials are acting in good faith when it comes to their moral arguments and just want to justify raising taxes for the poor. reply mr_00ff00 14 hours agoparentThe people paying the congestion fees are the rich that live in the suburbs and drive into the city. reply chimeracoder 33 minutes agoparentprev> However, this was accompanied by hikes in public transit pricing. It was not. Public transit pricing is completely independent and did not change with the implementation of congestion pricing. > I don't think transit officials are acting in good faith when it comes to their moral arguments and just want to justify raising taxes for the poor. The only person who has acted in bad faith is Kathy Hochul, who bent over backwards to water down the policy by having poorer people subsidize wealthy car commuters. reply yobid20 18 hours agoprevBad timing on the charts before and after. Coming back off holidays, delayed flights, and in the middle of massive snowstorms. The constant data is flawed and results irrelavant. You need to wait until the spring/summer and compare windows of time to previous years. reply jmyeet 18 hours agoprevI happened to be living in London when congestion pricing was brought in and the difference on day 1 in the West End was like night and day. I believe it's never gone back to the pre-congestion pricing levels. I fully expect similar in Manhattan. The social media response has been particularly interesting. Predictably, there are a lot of non-NYCers who simply object to the slightest inconvenience to driving in any form. These can be ignored. What's more interesting are how many native (or at least resident) New Yorkers who are against this. They tend to dress up the reasons for this (as people do) because it basically comes down to \"I like to drive from Queens/Brooklyn into Manhattan\". There's almost no reason for anyone to have to drive into Manhattan. It's almost all pure convenience. The funniest argument against this is \"safety\", the idea that the Subway is particularly unsafe. You know what's unsafe? Driving. Another complaint: drivers are paying for the roads. This is untrue anywhere in the US. Drivers only partially subsidize roads everywhere. And if we're going to talk about subsidies, how about free street parking... in Manhattan. Each parking space is like $500k-$1M on real estate. In a just world, a street parking pass would cost $500/month. The second interesting aspect is how long it takes to bring in something like this. In the modern form, it's been on the cards for what? A decade? Longer? Court challenges? A complicit governor blocking implementation? That resistance only ever goes in one direction. My only complaint is that the MTA should be free. Replace the $20 billion (or whatever it is) in fares with $20 billion in taxes on those earning $100k+ and on airport taxes. Save the cost of ticketing and enforcement. Stop spending $100M on deploying the National Guard (to recover $100k in fares). Public transit fares (that are going up to $3 this year) are a regressive tax on the people that the city cannot run without. reply screye 6 hours agoparentAll studies show that free public transit is a bad idea. There is a reason no country provides it. People mis-treat free things. When you ask them to pay for it, it enforces civic contracts. With contactless terminals in place, a free MTA benefits no one. It's also difficult to get additional funding to improve something that's free. An MTA monthly pass is 130$. That's the price of a single uber round-trip to JFK. NYC also allows employers to provide commuter benefits tax-free. It's cheap enough. reply codewench 4 hours agorootparent> There is a reason no country provides it. While small, Luxembourg is still considered a country. And their public transit is both free, and fantastic reply axelfontaine 6 hours agorootparentprevLuxembourg has free public transit. reply tripper_27 18 hours agoparentprevSeveral EU cities have experimented with making public transport free, and people seem to really enjoy it. Also, as you so eloquently put it, it isn't clear that the cost for issuing and checking tickets is covered by the income from the tickets, and there are reasons why MTA tickets cannot be priced at the actual cost to cover the ticket compliance infrastructure -- with a nice analogy to the cost of parking vs value of parking real estate. What justifies the subsidy for on-street parking? reply returningfory2 4 hours agorootparentSome internet searching suggests fares account for between 25 and 33 percent of the MTA’s revenue. There’s no way the infrastructure for collecting fares costs that much. This is one of the main criticisms of free fares: in reality the revenue stream from fares is never actually fully replaced, so it just results in the transit agency becoming underfunded. This makes transit worse for existing users who are already paying. The new users you get because of free fares are mostly casual users like tourists who have alternate options, so serving them isn’t that useful and not worth the negative impact on existing users. reply ProfessorLayton 18 hours agoparentprev>Another complaint: drivers are paying for the roads. This is untrue anywhere in the US. Drivers only partially subsidize roads everywhere. I agree with pretty much everything else you wrote, but this it needs to be noted that most road damage is done by weather and heavyweight vehicles like semis/trash/buses/delivery vehicles etc., not regular passenger vehicles. Semis et al. definitely do not pay taxes proportionate with the damage they cause to the roads, but then again we all need them even if we don't drive. reply woodruffw 17 hours agorootparentThis is true, but it's also changing in interesting ways: the rise of both light-truck SUVs and EVs as a whole means that passenger cars are, on average, heaver than they've ever been before. This is still a small portion of overall road damage, but it matters in places like NYC. In particular it matters on our bridges and cantilevered highways, where passenger traffic can't be easily filtered away from weight-sensitive areas like commercial traffic can. reply potato3732842 17 hours agorootparentprev>Semis et al. definitely do not pay taxes proportionate with the damage they cause to the roads, but then again we all need them even if we don't drive. I don't think there would be much point. At the end of the day we'd all pay it because we all consume the goods they deliver or transport during intermediary steps in the supply chain. I guess you could argue that the status quo is somewhat of a tax incentive that favors local manufacturing (i.e they use the roads for every step of the chain vs imported goods which only use it for delivery). I don't take much issue with that. reply occz 14 hours agorootparentprevI agree that semis are subsidized to a ridiculous degree, but I don't agree that we necessarily _need_ them. What we need is a way to transport things, and in a non-subsidized world, we'd probably come up with a different way which could be just as good or better. reply ignormies 15 hours agorootparentprevNote that diesel is taxed nearly 40% higher than gasoline per gallon in the US. And shipping trucks use a lot more gallons of gas (total and per mile). Should the rate be higher? Perhaps. But it's already a bit slanted towards vehicle weight based on fuel type and consumption. Electric vehicles, and especially electric shipping trucks, are going to require finding new taxation sources. reply jhatax 18 hours agoparentprevWhy is the answer to offset MTA ticket revenue an additional tax on those making $100K+ or those traveling through the city (airport taxes) who don’t use the service? In a city with super high cost of living and almost no auditable way to connect taxes collected with service delivered, this sounds like a penalty to anyone making six figures or connecting through the airport. There has to be another, more sustainable way for a rich city like NYC to make a service truly accessible and free without another tax. It’s like how the Bay Area bridge tolls have increased by $1 this year to fund the BART system => we still don’t know what was done with the last increase in tolls, yet we have to pony up the extra cash this year. Smarter folks than me on HN might have an idea other than, “let’s tax folks who make more than an arbitrary dollar amount annually” that has worked in other large metropolitan areas. reply randomopining 4 hours agoparentprevWhat does free transit do? People need to earn some money and then use that money. It's a healthy psyche. $3 for a ride anywhere in the city is pretty cheap reply coldpie 3 hours agorootparentFiguring out how, and how much, to pay, and then fumbling with cash and change or whatever, during the fairly stressful experience of boarding, is something of a barrier to using transit. So removing the fare payment entirely removes that barrier. But, that's gotten a lot easier with support for paying fares in apps, so I think it's a lot less of an issue now than it was ten years ago. I used to be in favor of free fares, mostly because it'd make using transit less intimidating for newbies. But I'm on the fence now. reply juped 7 hours agoparentprevThe subway fare is _insanely_ cheap and it's also uniform, which is important because short intra-Manhattan riders like me subsidize outer borough commuters. What a bizarre thing to complain about. reply supernova87a 18 hours agoprevWhat I am interested to know but cannot find is: Are there are cameras inside the zone tracking cars to bill them if you are already in the zone, or if cameras only track entry to the zone? (i.e. cameras only on the border). If someone happens to evade the cameras, do they catch them eventually just by traveling within the zone? I believe London for example has internal zone cameras. The purpose being, first of all, to ensure that people do not somehow evade paying just by operating solely within the zone, defeating the purpose of reducing traffic. And secondly, to stop people from engaging in loophole seeking behavior. I hope that loopholes and people defrauding the system (license plate obscuration, etc) are quickly caught and penalized. You would hope that if a car enters or is detected with invalid plates, it triggers an automatic report to police nearby to follow up. Otherwise, like so many things (it seems now) we just throw our hands up at people who evade the rules and charge those who follow them. (my comment spurred by an NYT article about how people might scam the system) reply rtkwe 4 hours agoparentThe number of people who entirely live and work and drive inside the zone is going to be vanishingly small in comparison to the people who transit the zone border so I'm not sure it's going to be that big of a deal. reply supernova87a 1 hour agorootparentI just wonder why they choose not to enforce this aspect of it when it can be a significant population (in a statistical sense) of the car traffic as well as revenue. Manhattan inside the highways is a big place. Maybe it's the cost of the cameras to be installed. reply rtkwe 1 hour agorootparentI wager they did a study to weigh the costs and came up with the inevitable answer that chasing down the tenth of a percent (a wild guess but I think it's at worst an order of magnitude off from the actual number) of cars that exist only within the congestion zone and never leave would cost more than you'd gain both in fees and second order effects. Especially the population of cars most likely to never or rarely leave are being charged on a per ride basis, cabs and rideshare vehicles like Uber etc. It's like all the efforts to drug test people on welfare, they cost vastly more than they save/recover. reply chimeracoder 32 minutes agorootparentprev> I just wonder why they choose not to enforce this aspect of it when it can be a significant population (in a statistical sense) of the car traffic as well as revenue. It's not. 85% of Manhattan households don't own a car at all. The number is even higher inside the Congestion and Relief Zone. Almost all car traffic within the zone is from people who do not live within the zone. reply rtkwe 21 minutes agorootparentPlus of that 15% that do own a car how many actually only use the car within the Congestion Zone a significant portion of the time? My guess is the number is well below 1% of car traffic could possibly dodge a significant portion of the toll. reply stereo 14 hours agoparentprevThe cameras are only at the entrance. reply gosub100 3 hours agoparentprevI don't see what good it would do to have a car that can only travel in lower Manhattan. Yeah the few people who live there, own a car, and are lazy or use it for going to get groceries 2x a week might slip through, but that's nothing significant in my book. What would worry me is if it leads to more license plate theft. Criminals get to ride for free, while legally registered owners have to fight the fines and clear their name in NYCs byzantine government. reply The-Bus 2 hours agorootparentWhere are you driving your own car to get groceries easily in lower Manhattan... twice a week? reply gosub100 36 minutes agorootparentIf you had a friend or SO, one could drop off the other, then circle around a while and pick them up later. But that further reinforces my point that there's little to gain from \"cheating\" this way. reply Workaccount2 18 hours agoprevNote that a gimped version of congestion pricing was actually implemented, putting it closer to being an annoyance more than an actual deterrence. Originally it was meant to be $15, but was ultimately lowered to $9. reply paxys 18 hours agoparentGoing from no congestion pricing to some congestion pricing is the biggest barrier, and that was overcome. Increasing it from here is going to be a lot easier, especially if residents realize the positive effects. reply throwaway48476 17 hours agoparentprevIt wasn't gimped, it was a PR play so the governor could claim to be saving citizens costs by 'lowering' it. Like when people buy things they otherwise wouldn't have because it was 'on sale' so they're really saving money if you think about it. reply chimeracoder 29 minutes agorootparent> It wasn't gimped, it was a PR play so the governor could claim to be saving citizens costs by 'lowering' it. That doesn't make sense, because $15 was already the lower price that she fought for. reply chimeracoder 30 minutes agoparentprev> Originally it was meant to be $15, but was ultimately lowered to $9. It was originally supposed to be $27. $15 was the lower price that Hochul fought for and issued a press release boasting that it was the correct price. Then she just unilaterally decided to cancel the entire program before bringing it back at $9. reply kevin_thibedeau 14 hours agoprevThey don't indicate what the \"average\" data before Jan. 5 represents. January and February after week 1 have lighter traffic than the rest of the year. If the pre-congestion data extends beyond the winter season, including week 52 and week 1, it can't be meaningfully compared until more data is collected. reply ChrisArchitect 20 hours agoprevRelated: NYC Congestion Pricing Set to Take Effect After Years of Delays https://news.ycombinator.com/item?id=42598936 reply shipscode 15 hours agoprevCongestion pricing should really be referred to as a \"lower manhattan driving tax\" or similar. It's a misnomer to claim it to be \"solving\" congestion outside of rush hours like 7-10 and 3-7. reply BobAliceInATree 14 hours agoparentIt’s not a tax. reply asdff 1 hour agorootparentIt is if your drive is obligatory reply habosa 14 hours agoprevThe branding of congestion pricing has been so disastrous. It could have been separated into two very normal things: tolls and parking fees. Every city has those. NYC could have played with those knobs until they got mostly the same effect but there would have never been any nonsense about it being illegal or unconstitutional or whatever car advocates are saying. Even if this works, it will always be hated and fought by a large minority. reply hombre_fatal 11 hours agoparentMeh, car proponents fight against any concession. You’re proposal is no different. Consider how in these comments people are even mad about being unable to park their SUV in a crosswalk (new daylighting policy in SF). Just rip the bandage off already. reply freejazz 2 hours agoparentprevYes, unlike congestion pricing, New Yorkers love increased tolls and paying even more for parking than they did last year. reply freen 15 hours agoprevThe harsh law of hacker news: For any topic outside of strict software development, the strength, viciousness and certitude of opinions expressed is inversely proportional to the level of knowledge about the subject. https://www.strongtowns.org/journal/2021/3/3/the-fundamental... reply screye 9 hours agoparentWhiplash, every time. HN's takes on cars are shockingly bad. For a community as thoughtful as HN, their responses are (to use an insult provocatively) car brained. It's as if cities don't exist outside the US. The US is decades behind on urban infrastructure and governance. This means their policy debates in 2025 have been globally settled issues for decades with outcomes to back it up. Conjecture can't be an effective rebuttal to evidence. reply coldpie 3 hours agorootparent> HN's takes on cars are shockingly bad. For a community as thoughtful as HN, their responses are (to use an insult provocatively) car brained. Hm, as a big public-transit advocate coming here 5 hours after your comment, I actually thought the discussion is in pretty good shape. There's a handful of \"cars only!\" nuts, but they're a small minority. It seems the vibes around this topic are fairly positive, with lots of support for funding better public transit. reply throw4847285 4 hours agoparentprevIt was shocking to read The Power Broker last year and learn that since 1940s at least, urban planners have been aware of induced demand. Caro even brings up congestion pricing as a proposal that was rejected not because it wouldn't solve then problem but because the entire urban planning infrastructure was built to deny that there was a problem. reply asdff 1 hour agorootparentAnd this is why we have traffic today per that theory. Demand were induced and in a lot of cases cities didn’t end up building key reliever routes. So those initiall routes were overcapacity potentially from day one in the city. It is also important to note that induced demand is not infinite. There is a point when there aren’t more drivers to actually get on the roads. We see this in some midwestern cities that had their full freeway plans built and didn’t experience significant growth after those plans were made. Those are “20 miles in 20 minutes” places any time of day for the most part. reply jmclnx 18 hours agoprevCurious how that works ? Does one need an EXPass or is a bill sent out ? I am also wondering if other Cities will adopt this. Eventually I can see this or something like it be rolled out nationwide as EVs become more popular. reply surbas 18 hours agoparentBoth Work, however cheaper if you have an EZ Pass. reply healsdata 18 hours agoparentprevYup, it's EZPass. Either with a transponder or plate-by-mail reply tonymet 3 hours agoprevin a short amount of time , commute times will recover to baselines, or worse, the city will waste the additional revenue , the residents will be poorer , and leaders will pat themselves on be back. Expresslanes made commute times worse . Little of the revenue went to the roads . Few of the roads were fixed . reply maxwellg 18 hours agoprevI'm incredibly hopeful that NYC congestion pricing pays off in a big way - and that we start to see it in other cities across America. I really, really want congestion pricing in downtown SF. During rush hour, cars block the box and slow down busses, with cascading effects. reply taatof 18 hours agoparentHow do we get around? To get downtown I have to take two busses and then bart (or two busses but it takes longer because there are a lot more stops). The kicker: I'm not even in a suburb, I live in SF! All we do in SF is make car driving worse, we almost never make public transit better. At least NYC has a plenty good enough train system. I end up WFH anyway, largely because it's annoying to get to an office downtown every day. reply maxwellg 17 hours agorootparent> All we do in SF is make car driving worse, we almost never make public transit better. In the last half decade we've seen the opening of the Salesforce transit center, the Chinatown subway station, the Van Ness BRT, the Caltrain Electrification Project, BART expansion to Berryessa, 800 new BART cars, and hundreds of smaller projects. You can see a full list of SFMTA projects at https://www.sfmta.com/sfmta-projects reply taatof 17 hours agorootparentWhile I'm obviously exaggerating by saying \"never\", the list is much smaller than it needs to be, and you have some misleading things on that list. Chinatown subway station is great. Better connects SF residents and it's exactly what I want to see more of in SF. - Van Ness BRT? That project started in 2003. It took 20 years to complete. Not exactly the poster child of solid transit improvements in SF, except if you ignore how it got there. - The Caltrain electrification project is great for the environment, but doesn't help SF much as far as improving transit availability. It's slightly faster, at least. - BART expansion to Berryessa is a bit separate from SF transit improvements, which is what I'm talking about. - Salesforce transit center is fine and has good vision, like expanding caltrain downtown. But doesn't add a massive amount of transit availability that wasn't already nearby (yet). reply maxwellg 16 hours agorootparentI provided a list of the biggest ticket items from the past few years. If you want to only look at projects that increase transit availability, reliability, or speed within SF County, check out the Muni Forward projects. Usually half a dozen lines are prioritized each year. https://www.sfmta.com/projects/muni-forward I live in the Richmond, so I've been positively affected by the improvements to the 38/38R (although I still would strongly prefer a BRT system) and the new-ish-but-not-really 1X. In the next year I can expect transit improvements to the 1 and the 5/5R. Pretty much every bus I take on a weekly basis has seen transit improvements since I've first moved here. reply ardit33 11 hours agorootparentGeary BRT is still not complete. 25 years in the making, and it is just a half assed solution. SF is very inefficient into completing mass transit infrastructure. reply what 13 hours agorootparentprevWhat actually improved about the 38? They moved the stops to the other side of the intersection, which saves maybe 1 minute along the entire route. reply maxwellg 12 hours agorootparent- Stops moved to be after the light, so bus isn't stuck waiting after people board - Stops moving after the light mean Transit Signal Priority works better. GPS on the bus can \"hold\" the green light for longer - https://www.sfmta.com/blog/green-lights-muni - Red painted lanes decrease private car use in bus lane, so bus can go faster - Speeding fell by 80%, so fewer accidents mean transit is more reliable There have been a few different projects on different sections of Geary over the years. The bus now runs 10-20% faster depending on direction and variability decreased by 25-40%. Check out pages 15-19 of https://www.sfmta.com/sites/default/files/reports-and-docume... reply asdff 1 hour agorootparentDoesn’t the bus just stop before people board now? Seems to me the issue is the bus isn’t capable of preempting green lights not where it stops and hits the red light on its route. When the police want to get to lunch quicker they are allowed to preempt the lights with the tooling they are given. reply tuukkah 9 hours agorootparentprevBetter Caltrain means less road congestion in SF so benefits everyone. reply raldi 14 hours agorootparentprevAnd before that: https://www.reddit.com/r/sanfrancisco/comments/8df1z7/after_... reply whimsicalism 15 hours agorootparentprevit's too bad SF did not build an underground railway system covering the city in the short window when the labor to do so was affordable reply WillPostForFood 15 hours agorootparent1851? reply master_crab 7 hours agorootparent1850-1950s. But just as importantly this time frame also happened to be before the NIMBYists stepped in (which is arguably more consequential). reply alephnerd 6 hours agorootparentMuch of SF didn't even exist until the 1930s-50s. For example, most of Sunset and Richmond is tract housing built during that era - before then it was sand dunes and chicken farms. People underestimate how new much of the Western US is. For example, Dallas only began expanding in 1891 after the railways were built, LA was a small town until the 1910s-30s era expansion, modern San Jose only formed in the 1960s-70s after absorbing dozens of farming towns like Alviso and Berryessa, Seattle was mostly sand dunes until they were leveled in the 1900s-30s). Because of how new it was, most of the cities are planned primarily with cars in mind - especially after the 1930s era Dust Bowl Migration and the 1940s-60s era economic migration. Same thing in much of Canada and Australia as well, which saw a similar postwar expansion. > before the NIMBYists stepped in NIMBYism in SF only really began in the 1970s onwards. While NIMBYism is now elitist, it initially started out as part of the civil rights movement (\"urban redevelopment\" was often a guise for razing historically Black, Hispanic, and Asian neighborhoods in that era - for example much of Japantown/Fillmore) as well as the early environmental movement (eg. Sierra Movement, Greenpeace), which was opposed to profit motive compared to modern YIMBY+Greentech model. reply master_crab 4 hours agorootparentWhile that’s true of the outer communities (San Jose, etc) I took the OP’s message as referring to SF core/downtown which was already pretty developed by the 1950s. Unlike LA, SF was a major city far earlier. reply asdff 1 hour agorootparentPeople are forgetting about pasadena. That was the bigger socal city than la for a long time and maybe even bigger than sf (certainly is geographically). reply alephnerd 2 hours agorootparentprevMuch of SF's core/downtown was rebuilt after the 1906 fire and earthquake, plus there was massive \"urban redevelopment\" that made the core much more car friendly. reply asdff 1 hour agorootparentprevNo in the 70s when they built bart but intended it to be a suburban commuter network reply doctorpangloss 12 hours agorootparentprevHere in San Francisco? On my insured Stromers, with my family, that I bought for less than the cost of a year of auto insurance. Door to door, I am everywhere I want to be in about 10m. My longest typical journey is 45m across Golden Gate Bridge from the Mission, which is faster than any car, simply because I park my bike at the door of my destinations. The better question is, have you ever seen a kid crying in the back of a bike? reply CalRobert 12 hours agorootparentHear hear! Though I admit my own kid has cried once or twice in the front of an urban arrow, toddler rage is a powerful thing…. reply tshaddox 16 hours agorootparentprevCongestion pricing makes driving better, not worse. reply cj 14 hours agorootparentOf course it does, if you remove price from the equation! reply tshaddox 12 hours agorootparentSure, but that’s a dismissive interpretation. It’s a bit like saying “sure, a cinema that refuses to sell more tickets than it has seats leads to a better cinema viewing experience, but only if you remove price from the equation!” reply AnthonyMouse 8 hours agorootparentThere are two ways to not sell more tickets than you have seats. One is to jack up the price of seats, the other is to add more seats. The latter in this context would be to e.g. build higher density housing so more people can feasibly take mass transit, as opposed to congestion pricing which is just a tax on people who can't afford the artificially scarce housing in the areas where mass transit use is feasible already. reply potato3732842 7 hours agorootparentprevIt boggles my mind (by which I mean \"you should feel dirty for employing a dishonest rhetorical trick like that\") that you can call his take dismissive when you simply ignored the area that is regressing (cost) in order to facilitate the tradeoff. Cost is explicitly being traded away here to facilitate improvement in other areas. That's the whole point of implementing the toll/tax!!!!! reply tshaddox 4 hours agorootparentPhrases like “toll” and “congestion pricing” clearly imply that there will be a cost to driving, so I don’t think it’s reasonable to say anyone in the conversation is ignoring cost. But again, dismissing the improvements because costs go up is like dismissing the reduction of water pollution because “now only people who can afford chemical disposal can operate a tannery next to the river.” reply close04 9 hours agorootparentprevWouldn't the price of the car, fuel, insurance, maintenance, etc. dwarf the congestion tax? So the car itself is the worst part about the driving experience? reply bluGill 5 hours agorootparentMaybe. Used vs new cars have vastly different costs. Generally tolls are far more than fuel cost where they exist. Insurance is - in the us - charged per year with unlimited use. there are some who the charge would be significant (long paid off reliable used car) while others who it is a drop compared to the othes costs (new luxury car) reply close04 4 hours agorootparentTrue, there’s a lot of room to optimize costs. For example the congestion tax costs can be reduced to 0 by avoiding areas it targets. And that’s not even tongue in cheek, one could commute to the edge of the city and take public transport for example. reply bluGill 3 hours agorootparentThat is the goal of course. The open question (though we will know in a year) is will they. Or will they just reduce something else from their budget to pay these tolls? If only a handful of people change their behavior this failed (though the extra money to transit may result in useful service expansions for someone else who isn't driving now). If thousands change their behavior it was a success. reply whimsicalism 15 hours agorootparentprevfor a bus-centric system like SF, congestion pricing intrinsically makes public transit better reply wkat4242 7 hours agorootparentprevYeah that's the key. Not disincentivising cars but to make public transport the obvious answer by making it really good. They do that really well here in Barcelona. 21€ a month and you can use all the transport you want in the city, all modes. Why would i want a car what's expensive to own, park and maintain and I can only just it when I've not been drinking? Problem is, making transport good costs money and a lot of effort. Taxing cars is easy and brings money in. reply whakim 5 hours agorootparentprev> All we do in SF is make car driving worse, we almost never make public transit better. At least NYC has a plenty good enough train system. Except that SF public transit is actually pretty good. East-West transit works extremely well via buses and MUNI depending on whether you live in the northern or southern part of the city. Bay Wheels is extremely affordable and makes a lot of sense for short trips in a city of SF’s size. BART has its limitations but it also generally pretty good. Sure, SF public transit could be better, but I’d actually argue the problem is that driving in SF isn’t hard enough - many people have great public transit options but refuse to use them because we haven’t forced them to reprogram their car-brains. reply CalRobert 12 hours agorootparentprevFor what it’s worth a folding bike and BART is a great combo reply tlogan 15 hours agorootparentprevThe goal is straightforward: make driving more pleasant for wealthy people. Rich Democrats will claim it’s beneficial for the environment, while rich Republicans will call it capitalism at work. In the end, improving public transit isn’t really on their radar. And they rule the world. reply leetcrew 15 hours agorootparentbuses and cars compete for the same right of way. improving one mode necessarily comes at the cost of the other, but many more people can be moved with a bus. trains would be even better, but people don't like to see the price tag. almost not worth discussing honestly. this has become yet another factionalized holy war over the last decade. reply tlogan 15 hours agorootparentOne challenge with your 100% logical reasoning is that it assumes wealthy and powerful people share the same priorities you do. Unfortunately, this is rarely true, and it often takes time to realize just how different those priorities can be. I’m all for public transit myself, but after 25 years in San Francisco, I’ve only seen it decline. That sentiment isn’t just mine—many longtime SF residents share this cynicism. reply nine_k 14 hours agorootparentOh, SF, the home of both some of the most powerful NIMBYs and the most outlandish \"social justice\" experiments. I feel for this once wonderful, poor city. As a consolation, I must say that e.g. NYC was also handled miserably, say, in 1980s. Despite that, it rose from the filth, and is now fine, even outright enjoyable here and there. I think that SF will also shake off its current insanity, and will turn back into a flourishing, living, and thus changing city. It takes time, thoughtful voting (of many, many people), and likely a bit of luck. reply RHSeeger 14 hours agorootparent> Despite that, it rose from the filth, and is now fine Well, except for the people being pushing in front of subways to their death, or lit on fire in stations. The subways stations are getting dangerous enough, even in \"not bad\" areas, that people are avoiding them. reply ufmace 13 hours agorootparentOut of about 3.5 million riders a day. Meanwhile, nobody pays any attention to the roughly 250 people who die in car crashes every single year in the NYC metro area. If you're so worried about safety, we should ban cars entirely instead of just taxing them a little. reply nine_k 3 hours agorootparentprevIf you look at basically any subway station now, and compare it to 1980, it's a huge improvement. If you want a reminder, visit Chambers St station (it's heavily affected by leaks from the buildings above it). reply dullcrisp 14 hours agorootparentprevWhat are they doing instead? Driving on the roads? Staying home? reply leetcrew 15 hours agorootparentprevI don't live in SF, so could definitely be some local nuances I'm missing. in NYC, there is a pretty clear partisan split on the new congestion tax. the (relatively) red leaning areas are the loudest opponents. I guess having so many high earners already taking public transit might change the discussion. reply pclmulqdq 14 hours agorootparentThose areas are the poor areas. The rich areas in NYC are the most democratic. reply AnthonyMouse 7 hours agorootparentprev> buses and cars compete for the same right of way. improving one mode necessarily comes at the cost of the other This is not true at all. Some ways of increasing throughput for both: Build higher density housing which allows more people to take the bus/train and reduces congestion even for the people who still have to drive, add more lanes that either can use (e.g. by building parking garages and then converting street parking to travel lanes), make streets one-way on alternating blocks (reduces congestion at intersections), build pedestrian catwalks above busy intersections to reduce pedestrian-induced congestion and keep pedestrians safer, etc. > but many more people can be moved with a bus. The \"can\" is really the problem. If you do the numbers for a full bus the bus seems very attractive, but then to run buses to everywhere that everyone travels in cars without an impractical amount of latency, many of the buses would end up having only one or two passengers -- and sometimes none -- while still requiring three times the space and fuel of a car and on top of that requiring a separate driver at significant expense. So instead there is no bus that goes to those places at those times. And since you can't get those people on a bus, they're reasonably going to demand a solution that doesn't make their life miserable when they have to drive a car. > trains would be even better, but people don't like to see the price tag. Trains (especially subways) work great in the areas with the population density to justify them. But now you're back to needing higher density housing. reply nine_k 15 hours agorootparentprevI wish we had more trains where it's still possible to route them in shallow tunnels that are cheap to build by excavations, say, in many parts of Brooklyn. (The 2nd Avenue extension had to pierce rock at rather serious depths.) reply bluGill 5 hours agorootparentThe problem is political not technical. People don'tewant thair streets block by construction for a couple years and so make up reasons against it. New york is easy as nothing archeolorical evists to worry about (north america generally lacks minerals to make things of interest from they used things that decayed long ago. reply asdff 1 hour agorootparentprevI thought that was only possibly because in there wasn’t so much in the way of buried utilities back then reply Lammy 13 hours agorootparentprev> The goal is straightforward: make driving more pleasant for wealthy people. And spy on everyone, all the time, because now it “““has to””” track every vehicle's every move — Total Information Awareness reply resters 15 hours agorootparentprevSuppose a non-rich person needs to use the highways for work and can make twice as many stops during the day because of congestion pricing. Imagine a group of non-rich people who decide to carpool because of congestion pricing and end up spending half the time in traffic every day and as a result get more leisure time. Considering that a parking spot in Mahnattan costs close to $1K per month, most of the cars are driven by people who are not poor. reply pclmulqdq 14 hours agorootparentFree/cheap street parking exists in Manhattan. A lot of it. reply ajsnigrutin 17 hours agorootparentprev> All we do in SF is make car driving worse, we almost never make public transit better. Same happening here in my smallish (~300k peeople) capital of a small eu country... Too many cars? More expensive parking! Less parking! More expensive parking! Less parking! More pedestrian-only streets, and even more cars around that... And the buses? They suck. The city is roughly star-shaped.. want to go from one leg to another? Well, you have to cross the city center. Sunday? Half of the buses don't drive then. Something happening in the city center? Good luck with getting on the last bus after the event is over, and no extra buses added. Dog? Not during \"rush hours\" (6.30-9:30 and 13-17h). AC? Barely any. Two buses needed? No time sinchronization at all. Train-bus time sychronization? haha good luck. Need to go just a stop or two? It's expensive. Need to go across the whole town? It's slow, even with empty streets. But hey, parking will be made even more expensive! edit: also, a student? You get cheaper transport! Here's a line for you to wait to get the transport card: https://www.zurnal24.si/slovenija/pred-okenci-prevoznikov-pr... reply taatof 17 hours agorootparentSounds right. Here in SF, instead of police pulling over people who speed and run stop signs, we're getting rid of parking spots within 20ft of intersections so people speeding and running stop signs can see if they're about to kill a pedestrian. Could raise a fortune for public transit if we enforced traffic laws and used that money. reply AnthonyMouse 8 hours agorootparent> Could raise a fortune for public transit if we enforced traffic laws and used that money. If you consistently enforce the law then the fine revenue falls below even its current level because consistent enforcement reduces violations, meanwhile costs go up because the additional enforcement has to be paid for. The existing system is the one cultivated to maximize revenue by setting speed limits below the median traffic speed so that cops can \"efficiently\" issue citations one after another as long as there isn't enough enforcement to induce widespread compliance. This is, of course, dumb, but the alternatives generate less net profit for the government. reply milch 16 hours agorootparentprevBecause police can't physically be in every intersection at once, and there's research that shows that removing parking around intersections reduces pedestrian fatalities. They could add cameras, but I bet you that people would fight tooth and nail against that as well... not being able to park within 20ft of an intersection doesn't cause any privacy issues, or funnel money into the city councilman's cousin's company that just so happens to be in the business of installing red light and stop sign photo enforcement cameras, or need ongoing maintenance to keep working reply taatof 14 hours agorootparent> Because police can't physically be in every intersection at once Can we compromise at some number greater than 0? I've lived here for more than a decade and don't remember seeing anyone getting pulled over by SFPD. reply cyberax 15 hours agorootparentprev> Because police can't physically be in every intersection at once They don't have to be everywhere. They have to be at least _somewhere_ and start visible enforcing. People need to know that they might get away with running a red light a couple of times, but they WILL be caught eventually, and there WILL be consequences. > and there's research that shows that removing parking around intersections reduces pedestrian fatalities. I read a lot of the urbanist propaganda research, and most of it is pure crap. Bad statistical methods, poor significance, P-hacking, biased tests, you name it. reply what 13 hours agorootparentprevYou must not be a pedestrian if you don’t like the red zones at intersections. You can’t see the oncoming traffic without stepping into the intersection. reply rafram 13 hours agorootparentprev> we're getting rid of parking spots within 20ft of intersections This is called daylighting, and it’s a very good idea. The rest of your comment was just snark, and I assume you know that road improvements don’t have anything to do with law enforcement, but I just want to emphasize that daylighting is going to be a huge positive for the city. reply fragmede 15 hours agorootparentprevSF put in 33 speed cameras in known locations, and are aiming to install 900 more by the end of this year. As a bonus to speeders, speeds in excess of 100 mph will incur a $500 speeding ticket, though that may have unintended consequences. reply whimsicalism 15 hours agorootparentwhat unintended consequences? reply potato3732842 4 hours agorootparentNothing special. Slight increases in minor accidents and near misses, some minority of which will involve pedestrians or road rage violence Basically the same downsides as anything else that changes the speed via rule or enforcement rather than changing the conditions of the road (e.g. \"traffic calming\"). reply whimsicalism 2 hours agorootparenti fail to see how adding cameras and an additional penalty will lead to any of those things reply JackFr 14 hours agorootparentprevThe real unintended consequence is that cities ultimately don’t like to run them. They’re effective, and thus the revenue the city is expecting disappears. In they end they become costs rather than revenue sources. reply whimsicalism 1 hour agorootparentthat hasn't been true in any city i've lived in that had speed cameras (shockingly few actually). dc makes money on their cameras reply potato3732842 4 hours agorootparentprevThe root problem is voters tolerating a government that sees law enforcement as a profit center. reply SoftTalker 15 hours agorootparentprev$500 is just dinner for some people in SF. Or maybe people will drive at 99 mph to get the best value. reply oefrha 12 hours agorootparentSpeeding also carries point penalties. Get caught a few times and your license is suspended. You can’t just pay to speed indefinitely (unless you also buy something like a get out of jail free card from the police union). reply whimsicalism 15 hours agorootparentprevis this different than the existing law? like they're not lowering the penalty reply fragmede 15 hours agorootparentprevA normal person sees that $500 fine as a incentive to not go that fast. But there's a certain kind of person for whom $500 is nothing compared to being able to tell the story of that time the city sold them a picture of them, complete with certificate that says they broke 100mph somewhere in the city limits, a trophy to frame and display openly in the garage next to said vehicle. reply fragmede 3 hours agorootparentReally gotta wonder if the people that downvoted disagree that people would do such a thing, don't want to give people ideas and thus buried it, or are people who would do such a thing. Or some other thing. reply bushbaba 13 hours agorootparentprevThere’s a cost of policing, and a significant amount of ticket revenue goes to court fees. Not everyone pays their ticket. Likely it’d not raise a fortune and the ticketing revenue would mostly offset the cost of enforcement. reply mh- 13 hours agorootparentThat's.. fine? It'd drive behavior modification if there was even a small risk of getting a citation. Today, there really isn't. reply forrestthewoods 11 hours agorootparentprev> how do we get around By moving out of crappy overpriced cities? reply walthamstow 10 hours agorootparentIf it was so crap, it wouldn't be overpriced. reply AnthonyMouse 8 hours agorootparentHow do you explain Comcast? reply walthamstow 7 hours agorootparentIt's difficult because I've never had Comcast (I pay my £10/month BBC fee that hasn't gone up in years with pleasure) but I'd probably start by saying that Comcast is not a scarce good. reply AnthonyMouse 7 hours agorootparentIf it wasn't scarce then it would be cheaper. The problem is that it is scarce, artificially, as a result of regulatory capture etc. Which is the same reason housing in places like SF is so expensive. Artificial scarcity as a result of zoning rules that make construction prohibitively expensive or otherwise inhibit it from increasing the housing supply. Houston metro has more people than SF metro, so why does housing cost more in SF? Because there is less of it. reply walthamstow 6 hours agorootparentTo bring us back onto the topic, Manhattan is a scarce resource, and there's nothing artificial about that fact. reply fragmede 5 hours agorootparentThere's plenty more space in the up and down direction. Bridges and tunnels could be used to add car or other vehicle capacity. reply walthamstow 5 hours agorootparentThis thread is about transportation, not office or resi space. Edit - I see you've changed your message. How does a bridge over water add road capacity to a peninsula? reply fragmede 3 hours agorootparentIt doesn't. There may be a other materials that bridges can go over, however. reply walthamstow 3 hours agorootparentYour solution to road congestion on a densely-populated peninsula is more roads. Got it. reply AnthonyMouse 9 minutes agorootparentIt's not just more roads, although more roads are one of the things it is possible to create. You can also create more housing, so people are closer to their jobs and have to travel fewer miles. Manhattan has higher density than most places, but it also has more people, and would you be surprised to learn that the zoning in most of NYC no longer allows the buildings that are currently in Manhattan to be built almost anywhere? So as a result you can't create more of them and people who might like to live in Manhattan instead live in the suburbs around the city and drive into the city in a car. You can also create things that aren't roads, like subways, which then allow you to remove cars and buses (and bus",
    "originSummary": [
      "The Congestion Pricing Tracker is a project by Benjamin and Joshua Moshes, under the supervision of Brown University Professor Emily Oster, focusing on congestion pricing in New York. - The project includes web scripts and stylesheets, indicating a comprehensive digital approach to presenting information. - The webpage is optimized for search engines (SEO) and includes a 404 error page for handling not found content."
    ],
    "commentSummary": [
      "NYC's congestion pricing policy is designed to reduce traffic congestion and generate revenue for transit improvements.",
      "While some observe immediate benefits, others argue it's premature to assess its effectiveness due to variables like weather and holiday travel.",
      "Critics point out that unchanged taxi and ride-sharing fees and the need for enhanced public transit remain significant concerns."
    ],
    "points": 296,
    "commentCount": 508,
    "retryCount": 0,
    "time": 1736202179
  },
  {
    "id": 42620656,
    "title": "First time a Blender-made production has won the Golden Globe",
    "originLink": "https://variety.com/2025/film/columns/flow-golden-globe-win-independent-animation-1236266805/",
    "originBody": "Home Film Columns Jan 6, 2025 6:25am PT ‘Flow’s’ Shock Golden Globe Win Is a Long Overdue Triumph for Indie Animation By Jamie Lang Plus Icon Janus Films and Sideshow In a major upset, Latvian director Gints Zilbalodis‘ “Flow” won the Golden Globe for best animated feature on Sunday evening. A co-production between Latvia, Belgium, and France with a modest $3.7 million budget, “Flow” made waves simply by earning a nomination in a category traditionally dominated by big-budget studio films. While it’s handled by Sideshow and Janus Films whose track record includes the Oscar-winning “Drive My Car,” “Flow” faced an uphill battle in the Golden Globe race, competing against two Disney/Pixar blockbusters (“Inside Out 2” and “Moana 2”), a DreamWorks feature by animation legend Chris Sanders (“The Wild Robot”), a big-budget Netflix production from Oscar-winning Aardman Animations (“Wallace & Gromit: Vengeance Most Fowl”) and Oscar-winning director Adam Elliot’s “Memoirs of a Snail.” Related Stories VIP+ Why Studios Training AI on Artist Work Has Risks 'Grimm' Movie in Development at Peacock In the film, a biblical flood has submerged everything in its path, including Cat’s home. There are no humans to be found anywhere, although their material legacy remains. Luckily for “the “Flow’s” feline protagonist, it finds refuge on a boat full of other presumably homeless animals. Together, the group sets sail on the flood waters. Popular on Variety “Flow’s” victory reflects how inclusive the Golden Globes have become towards independent and international titles in recent years, especially when compared to other major Hollywood awards ceremonies. Last year, Makoto Shinkai’s “Suzume” earned a surprise nomination, and the year before, Masaaki Yuasa’s “Inu-Oh” made an unexpected but welcome appearance alongside the charming “Marcel the Shell with Shoes On” by Dean Fleischer-Camp. This year, Elliot’s Australian stop-motion film “Memoirs of a Snail” also earned a nomination. “Flow” didn’t come from nowhere, either. Represented internationally by animation experts at Paris-based Charades (“Mirai,” “I Lost My Body,” “Chicken for Linda!”), the movie had an impeccable festival run that kicked off at Cannes, where it world premiered in Un Certain Regard and went on to win awards at Annecy, Ottawa, Guadalajara, and Melbourne film fests. The film has also already scored wins at the European Film Awards, Los Angeles Film Critics Association Awards and New York Film Critics Circle Awards. On Jan. 12, it will compete for a Critics Choice Award. “Flow’s” Golden Globe award is also a win for the democratization of the animation process. The film was created using Blender, a free, open-source software widely used by independent and amateur animators. This marks the first time a Blender-made production has won the Golden Globe for animated feature, proving that major success in the medium is, at least theoretically, open to all creators, not just those working in the studio system. During his acceptance speech, Zilbalodis acknowledged the significance of his little film winning the award, not only for those involved but for the entire Latvian film industry. “This film is made by a very small young but very passionate team in a place where there isn’t a big film industry. So this is the first time that a film from Latvia has been here, so this is huge for us,” he explained. The 31-year-old director went on to briefly discuss how the production of this film differed from his previous works and how both its on-screen and behind-the-scenes messages are especially poignant in 2025. “This is a very personal story to me because I used to work alone. I made all my films by myself, but this time, I worked with a team, and just like the cat in ‘Flow,’ I had to learn to trust others and learn how to collaborate and overcome our differences. I think it’s very important to remember this nowadays,” he added. Looking ahead, “Flow’s” unexpected Golden Globe win has opened up the race for the animated feature Oscar. With no clear frontrunner, pundits have previously favored “The Wild Robot” and “Wallace & Gromit ” — the latter being Variety‘s pick as of Jan. 3 — over the more commercial or independent international contenders. A Golden Globe win for “Flow” may change some minds in that regard. If “Flow” or any non-Disney film were to win the Oscar, it would signal the longest drought in the category for Disney. Since the creation of the animated feature Oscar in 2001, Disney/Pixar has never gone more than two years without winning. Its last win came in 2021 with “Encanto,” but the past two years saw victories for “Guillermo del Toro’s Pinocchio” (2022) and Hayao Miyazaki’s “The Boy and the Heron” (2023). Read More About: Flow, Gints Zilbalodis, Golden Globe Awards Jump To Comments More from Variety Robbie Williams’ ‘Better Man’ Original Song Disqualified From Oscars After Making Shortlist How Surprise Albums Fueled Kendrick, Beyoncé, Taylor Release Strategies Golden Globes 2025 Ratings: 9.3 Million Viewers, Down 2% From Last Year (UPDATED) Zoe Saldaña Would Love to Perform With Selena Gomez at the Oscars If Their ‘Emilia Pérez’ Songs Are Nominated: ‘Make It a Beautiful Homage to Mexico’ Survey Shows What Fans of Faith-Based Cinema Are Missing Steve McQueen on Casting Saoirse Ronan in ‘Blitz’ and Why Cinema ‘Is the Best Medium in the World’ Loading comments...",
    "commentLink": "https://news.ycombinator.com/item?id=42620656",
    "commentBody": "First time a Blender-made production has won the Golden Globe (variety.com)273 points by jgilias 9 hours agohidepastfavorite43 comments lauriswtf 8 hours agoHere are more details about the movie if you are curious: - https://hollymotion.com/en/flow_cinema_blender_en/ - https://www.youtube.com/watch?v=yw-a7buP4KA Amazing movie by the way. It's been in cinemas here in Latvia for 5 months already and been sold out ever since. reply lauriswtf 5 hours agoparentAlso, it’s by far the smallest-budget movie to win a Golden Globe – 10x less than the next animated Golden Globe winner. Chart: https://x.com/anjo_lv/status/1876313785084125270/photo/1 reply raxxor 5 hours agoprevThat should finally put arguments that Blender would not be \"production ready\" to rest. Although to be fair, Blender did awesome jumps in capability in recent time. Love the tool, I wish them the best. Certainly a deserved success. For a gaming company it should also be the tool of choice because user content still is part of the most successful games. There are many arguments to revisit your toolchain if you do not yet use Blender. reply dagmx 3 hours agoparentIt’s been production ready for ages but that’s a nebulous distinction. Different studios have very different needs for scaling their production. Blenders suitability varies greatly by the project and needs. For example, it’s used on Spiderverse for specific things but cannot scale to do the entire animation production yet. Your second point about user generated content makes no sense imho. Games don’t use DCC files for runtime. They will have their own runtime formats that are generated during the build. Blender is just an unsuitable or suitable as any other DCC in that regard. reply Farfignoggen 3 hours agoparentprevThat should be restated as \"Production Ready\" for the average user that's not Linux Neck-beard Class for Graphics driver Dark Arts! And Blender 3D(3.0/Later) has a definite eWaste component for Older Hardware ever since OpenCL was dropped as the iGPU/dGPU compute acceleration API in favor of PTX/Nvidia and Apple Metal! Any Movie Production may have the ability to hire some consultant to get past some of the issues that pop up so it's more and issue of is Blender 3D actually Turn-Key for the average end user? reply xipho 4 hours agoparentprevIt's been production ready (if that means something) for years. Used in one of the biggest movies in the world, RRR a while back, etc. etc. [RRR](https://www.blender.org/user-stories/visual-effects-for-the-...) reply marcodiego 5 hours agoparentprev> That should finally put arguments that Blender would not be \"production ready\" to rest. I dream so, but to this day I still have to explain things to people who say \"if Linux is free then it has no value.\" reply belter 8 hours agoprev\"The animation of Flow — Blender Conference 2024\" - https://youtu.be/fxz6p-QATfs reply xkzx 6 hours agoprevAs a person from Latvia who uses blender, I am quite proud of this achievement. Saw the film a month ago, it is truly great and will certainly watch it again. Suggested to all ages. I think with the popularity and the new budget they will rerender it, as it could be better. reply jansan 6 hours agoparentIn Germany it will not be released before March this year. This is a bit confusing, but maybe they are actually rerendering it before the release on this relatively big market. reply a1o 9 hours agoprevI found an interesting video on YouTube from Blender Conference https://m.youtube.com/watch?v=fxz6p-QATfs reply Narann 8 hours agoparentI had the chance to work with Léo at its first job (Princes et Princesses from Michel Ocelot). It’s a wonderful guy, very fun and pleasant to work with. TBH, the rest of the Ocelot’s team was the smoother peoples I had opportunity to work with. reply belter 5 hours agoprevDon't forget to donate to the Blender fund: https://fund.blender.org/ reply reimertz 6 hours agoprevI watched this movie a couple of days ago and it really touched me. Might be that we just got a cute little cat. But the story-telling, visuals, animations.. It was just so very beautiful. Please go see it. reply Farfignoggen 3 hours agoprevIs anyone testing Blender 3D 2.93(OpenCL is still the GPU Compute API on that now legacy Blender edition) on Linux to see if it works for iGPU/dGPU accelerated Cycles rendering on older Vega/Polaris iGPU/dGPU hardware! And That's with Rusticl/Mesa and that a more modern Linux OpenCL implementation on Linux! And I'm trying out an Extracted/Non Installed version of Blender 4.3.2 on a Laptop(Mint 21.3) with Ryzen 3550H/Vega 8 Integrated Graphics and a Polaris RX560X dGPU but when I try the DRI_Prime=1(Offload to the Polaris dGPU) setting to run Blender 4.3.2 via a console session that locks up on that laptop when trying to use the Blender 3D UI! Is there some difference in Installed Blender and just the extracted version that gives the Application better access to the GPU/GPU-ID subsystems on Linux(Kernel)? Blender 4.3.2's Eevee is nice but there's not the same level of Ray Tracing/Render Passes capability on Blender Eevee as there is With Blender Cycles. reply chrisBob 4 hours agoprevIt also looks like it was made in Blender, and it will impact what people think of Blender even if the style is a choice rather than being dictated by the software. Just like live action can be shot on everything from super-8 to digital IMAX, the story telling is the most important part of a film. There is absolutely no reason not to use Blender if it works for you and your time/talent/computation budget. reply openrisk 5 hours agoprevI enjoyed the film without knowing much about it and then my jaw dropped when I saw Blender in the credits. reply cf100clunk 1 hour agoprevAn interview with Flow's director linked here: https://news.ycombinator.com/item?id=42442151 reply glimshe 7 hours agoprevCuriosity... Did it use Cycles or EEVEE? reply phire 7 hours agoparentIt's apparently all EEVEE. reply ChrisArchitect 6 hours agoprevHappy 31st birthday to Blender as of Jan 2nd last week! reply cubefox 9 hours agoprevHere is a trailer: https://m.youtube.com/watch?v=82WW9dVbglI reply ChrisMarshallNY 8 hours agoparentThat looks awesome! reply cubefox 4 hours agorootparentI actually think it (visually) doesn't look that great, at least in the trailer. The shading is some mix between flat cartoon-style (e.g. it seems the eyes aren't realistically shaded and some of the fur also looks intentionally flat) and the usual non-flat render-look with the realistic ray traced shading we always see from Pixar & co. But maybe this semi-stylized shading was the best compromise given the (no doubt) very constrained budget for a feature film. Making it look like a hand-drawn cartoon would probably have been too difficult, and creating all the realistic surface materials (e.g. for fur etc) that are used in mainstream Pixar-style animation would probably also have been too expensive. There are actually some Blender short films on YouTube that look visually very high quality on the level of big budget animation, but for those the length is usually just a few minutes. reply ChrisMarshallNY 4 hours agorootparentI understand that it's being re-rendered. It isn't great, compared to Pixar, with their server farms, but it's better than a lot of video games. reply zerobrainwash 4 hours agoprevCongrats from a fellow braliukas on producing such a great movie! reply anthk 6 hours agoprevThanks, Free Software, you inspired and helped tons of people. You gave working tools to plain citizens and not just the rich/posh with propietary Macbooks. Cinelerra-CV (or -GG, can't remember) and KdeNlive are good additions to Blender too. With the -rt kernel being merged into Mainline, now even the vanilla libre kernels are more than able with either Intel drivers or Nouveau (some oldish GTX models) to handle 4k video, as they are optimized for multimedia throughput. reply ChrisArchitect 5 hours agoprevWait, what is this movie? A Cat? Capybara? Quirky meme video from awhile back: https://vm.tiktok.com/ZMkyTWLpV/ I don't really understand the Blender model/meme-world crossover here - can someone explain what connection is? Same base skins? Same creators? Kinda wacky. reply jgilias 9 hours agoprevSorry for editorializing the title. It’s a direct quote from the article. The original title doesn’t describe why I’m posting this to HN! reply stevage 9 hours agoparentBut I went to the article looking for info about Blender and was disappointed. reply ManuelKiessling 9 hours agorootparent> “Flow’s” Golden Globe award is also a win for the democratization of the animation process. The film was created using Blender, a free, open-source software widely used by independent and amateur animators. This marks the first time a Blender-made production has won the Golden Globe for animated feature, proving that major success in the medium is, at least theoretically, open to all creators, not just those working in the studio system. reply stevage 9 hours agorootparentYeah, there's essentially nothing in the article that isn't stated in the post title. That's the downside of a post which is about a tidbit within a longer article, rather than a post linking to an article entirely about its subject. reply tsujamin 9 hours agorootparentThat doesn’t preclude the articles relevance though. It would be strange/disappointing for the first Golden Globe awarded to a Blender-animated picture to not be submitted; even in-spite of the title and lack of elaboration in the article. reply stevage 8 hours agorootparentI think we have different assumptions. My hope/assumption is that somewhere there is/will be a much better article about this fact, and that should be the one that gets submitted. reply gnabgib 9 hours agoparentprevTitle: ‘Flow’s’ Shock Golden Globe Win Is a Long Overdue Triumph for Indie Animation Perhaps other posters have felt constrained by this, and yet not broken guidelines? reply ladyanita22 9 hours agorootparentWell, I'm happy someone did break the guidelines, as this title gives me far more information. If the title hadn't been editorialized, I would have simply not clicked here. reply blitzar 9 hours agorootparentIf the title hadn't been editorialized, I would have probably never known. reply password4321 9 hours agorootparentprevFor future readers, a backup of the HN editorialized title: First time a Blender-made production has won the Golden Globe reply wodenokoto 9 hours agorootparentprevI'm not sure what is a good solution here. I think this is interesting to HN because of the blender thing, but at the same time I like that we try and keep things sober around here. The not-breaking-guideline approach to posting this is much worse in my opinion. We often see tweets submitted that are little more than editorialized headlines and a link. reply Hnrobert42 5 hours agorootparentI suppose OP could have found an article that focuses more on the Blender aspect. Though, that still relies on the article to have a title relevant to HN. Personally, I am okay with what OP did. reply lupusreal 8 hours agorootparentprevServile adherence to rules, even in cases where the rule isn't doing anybody any good, isn't a good quality to have. reply JKCalhoun 6 hours agoprev [–] > competing against two Disney/Pixar blockbusters (“Inside Out 2” and “Moana 2”) The sad state Hollywood finds itself in. reply gamblor956 0 minutes agoparent [–] Both films are quite good. They are deep, meaningful explorations of the themes presented in their respective films. Is your issue that they reuse existing characters and locations to do so? How would using new characters and locations improve things? Inside Out 2 builds upon themes from the first film and couldn't be made without the first. Yes, Disney dominates animation. They've done so longer than anyone on HN has been alive, because most of their animated films are extremely good. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Latvian director Gints Zilbalodis' indie animation \"Flow\" won the Golden Globe for best animated feature, highlighting a significant achievement for independent films. - \"Flow,\" created with a modest $3.7 million budget using Blender, a free software, competed against major studio productions, showcasing the democratization of animation. - The film's victory reflects the Golden Globes' growing inclusivity towards international titles and could impact the animated feature Oscar race, challenging Disney's traditional dominance."
    ],
    "commentSummary": [
      "A Blender-made production has won a Golden Globe, marking a milestone for the open-source software and challenging perceptions of its readiness for professional use. - The film, noted for its storytelling and visuals, has gained popularity in Latvia and stands out for its low budget compared to other animated winners. - The success of the film, utilizing Blender's EEVEE engine, has ignited discussions about Blender's potential impact on the animation industry and its capabilities in diverse production settings."
    ],
    "points": 273,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1736240455
  },
  {
    "id": 42616699,
    "title": "I live my life a quarter century at a time",
    "originLink": "https://tla.systems/blog/2025/01/04/i-live-my-life-a-quarter-century-at-a-time/",
    "originBody": "I Live My Life a Quarter Century at a Time So, we are coming up on a little anniversary for me this weekend. On the 5th of January 2000, Steve Jobs unveiled the new Aqua user interface of Mac OS X to the world at Macworld Expo. The Age of Aquarius Towards the end of the presentation, he showed off the Dock. You all know the Dock, it’s been at the bottom of your Mac screen for what feels like forever (if you keep it in the correct location, anyway). “Now I’d like to show you one of the coolest things about Mac OS X…” The version he showed was quite different to what actually ended up shipping, with square boxes around the icons, and an actual “Dock” folder in your user’s home folder that contained aliases to the items stored. I should know – I had spent the previous 18 months or so as the main engineer working away on it. At that very moment, I was watching from a cubicle in Apple Cork, in Ireland. For the second time in my short Apple career, I said a quiet prayer to the gods of demos, hoping that things didn’t break. For context, I was in my twenties at this point and scared witless. I didn’t design the dock – that was Bas Ording, a talented young UI designer that Steve had personally recruited. But it was my job to take his prototypes built in Macromind Director and turn them into working code, as part of the Finder team. I had already written another dock – DragThing – before I worked for Apple, and that had helped me get a job there. I moved over from Scotland to Ireland in late 1996 with my future wife, with both of us joining the small software team there. It was primarily a manufacturing plant, but there was a little bit of software and hardware testing and engineering that went on around the edges. I worked on a number of things in the early days. I was on the Copland installer for two weeks before the project was cancelled. Then, a couple of Disney Print Studio CDs that shipped with the Performas. I loved doing UI stuff, but somehow ended up working on a command line Mac OS X Server authentication component for At Ease that was to be used with a new line of diskless netboot computers that nobody had actually seen. It turned out I’d actually been on the iMac project all this time, and in the end they got hard drives. In the middle of all that, when I was out in Cupertino, I was asked if I wanted to work on a secret project with the code name “Überbar”. I was shown some prototypes and basically told that six people had seen it, and if it leaked they would know it was me that had talked. I figured if anybody was finally going to kill off DragThing, it might as well be me. The new Finder (codename “Millennium”) was at this point being written on Mac OS 9, because Mac OS X wasn’t exactly firing on all cylinders quite yet. The filesystem wasn’t working well, which is not super helpful when you are trying to write a user interface on top of it. The Dock was part of the Finder then, and could lean on all the high level C++ interfaces for dealing with disks and files that the rest of the team was working on. So, I started on Mac OS 9, working away in Metrowerks Codewarrior. The Finder was a Carbon app, so we could actually make quite a bit of early progress on 9, before the OS was ready for us. I vividly remember the first time we got the code running on Mac OS X. Because the Dock was a huge secret, along with the rest of the Aqua user interface, it was only enabled on a handful of machines. I didn’t see the shiny lickable buttons of Aqua itself for quite a while after I’d been working on the Dock . There were rumours that any screenshot of Aqua would have the hardware MAC address of the machine encoded into the image, so leaks could be tracked down. Before I had ever seen the new UI, there was one moment where I had somehow – I genuinely don’t remember why on earth this happened – had been tasked with designing a placeholder boot screen for the OS itself. I made a blue shiny Apple with pinstripes, in the style of the iMac. Secret Stripes Suppressed It lasted precisely one build before being yanked out extremely quickly. I assume because somebody was unhappy with the entirely coincidental Aqua-like appearance. But I trundled away, making the best dock that I could while staying true to the original design, and making frequent trips to the US, initially living out of the Cupertino Inn across the road from Infinite Loop. You may have heard me tell this story before, and I apologise if so. But it’s been long enough that people just know me for PCalc, and don’t even remember DragThing, let alone events that happened before some of you were even born. At one point during a trip over, Steve was talking to Bas and asked how things were coming along with the Dock. He replied something along the lines of “going well, the engineer is over from Ireland right now, etc”. Steve left, and then visited my manager’s manager’s manager and said the fateful words (as reported to me by people who were in the room where it happened). “It has come to my attention that the engineer working on the Dock is in FUCKING IRELAND”. I was told that I had to move to Cupertino. Immediately. Or else. I did not wish to move to the States. I liked being in Europe. Ultimately, after much consideration, many late night conversations with my wife, and even buying a guide to moving, I said no. They said ok then. We’ll just tell Steve you did move. And so for the next year, I flew back and forth between Cork to Cupertino, and stayed out there as much as regulations would allow. I had an office on the Finder team corridor. I can only imagine that Steve would walk by looking for me, and they would say he’d just missed me, while I was being bundled onto a plane at the other end. I had to come over whenever there were Dock demos, but I was not allowed to be left in the same room as Steve, lest I reveal the truth. The demo room with the blanked out windows had two doors, and I went out one before he came in the other. In the end, Macworld 2000 happened, and finally all the secrets were revealed to the world. I hoped that at this point, it didn’t matter where I was, and I could finally relax. Less than a month later, exactly on my birthday I believe, I got another call. I had to move to Cupertino. Or else. And this time, the “else” was that I would be taken off the Dock and the Finder, and I couldn’t be guaranteed any interesting work ever again. So I politely declined, and resigned. About three weeks later, the rest of the remaining software group in Cork was fired. Clearly, the plan had been to get rid of everybody, but they couldn’t tell me that at the time. I should have waited and I’d have got a payoff at least… My version of the Dock shipped once to developers, with the Developer Preview 3 of Mac OS X. John Siracusa absolutely hated it. We remain friends. After that, the engineer who took over from me rewrote the Dock entirely, and none of my code actually shipped to the public in the end. Eighteen months of hard work out the window, ah well. But I learned a great deal, made a lot of friends, and the experience spurred me on to resurrect DragThing for Mac OS X, which proved very popular for quite some time. PCalc also came back to life around then, and that’s still going today! As a final note, when I left Apple for the last time, and emptied out my drawers, at the very bottom of the last drawer I found my distinctly unsigned NDA. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Like this: Like Loading... Related Author: James Thomson Indie iOS / Mac developer, maker of PCalc and DragThing. Occasional writer, conference speaker, and podcast pundit. View all posts by James Thomson Author James ThomsonPosted on January 4, 2025January 4, 2025Categories UncategorizedTags aqua, dock, dragthing, finder, pcalc, the inevitable passage of time",
    "commentLink": "https://news.ycombinator.com/item?id=42616699",
    "commentBody": "I live my life a quarter century at a time (tla.systems)270 points by CharlesW 20 hours agohidepastfavorite152 comments kelnos 12 hours agoThis is a fun story, but also just reminded me of how destructively eccentric Jobs could be. All the shenanigans to pretend the author lived in the US, flying him back and forth from Ireland, planning his interactions (or lack of interactions) with Jobs so the deception wouldn't be exposed, and everything. What a colossal waste of time, money, and stress just to cater to the ego of Steve Jobs. And then they threw all that work away, seemingly mainly because it was done out of the wrong office. Presumably the final Dock that shipped was significantly different from the author's version, but throwing away all the code and doing a full rewrite is rarely warranted. reply yapyap 3 hours agoparent> how destructively eccentric Jobs could be last thing he destroyed was himself, by going the bonkers “alternative healing” route on cancer. not saying he deserved it but he had an out and he chose to ignore it till it was too late, hard to feel sorry at all for him at that point. also I heard he was a massive twat irl reply euroderf 3 hours agorootparentIf he'd've gone into politics, the net total outcome could've been much much worse. reply alternatex 1 hour agorootparentInsert Bill Burr on Lance Armstrong \"just keep him on the bike\" quote. reply kergonath 2 hours agorootparentprevLuckily there is no indication that he was interested in this sort of things. Contrary to…others. reply pxc 2 hours agorootparentprev> last thing he destroyed was himself, by going the bonkers “alternative healing” route on cancer. The tragic last act of Jobs' infamous reality distortion field reply stonesthrowaway 2 hours agorootparentprev> last thing he destroyed was himself, by going the bonkers “alternative healing” route on cancer. People who tend to go the \"alternative healing\" route usually do so because the traditional healing route hasn't worked. > he had an out and he chose to ignore it till it was too late Did he? Guess you are the expert. Cancer treatment isn't an exact science. Millions of people who go the traditional route die. It's always the know-nothings who talk with such confidence of absolutes. > also I heard he was a massive twat irl Did you now? I guess it takes one to know one. reply kstrauser 2 hours agorootparentIt was widely documented at the time that Jobs chose non-medicine over medicine very soon after diagnosis, and then went through heroic real-doctor efforts once it was too late: https://www.forbes.com/sites/alicegwalton/2011/10/24/steve-j... reply stonesthrowaway 1 hour agorootparentIt's hard to take an article seriously when they write \"was one of the 5% or so that are slow growing and most likely to be cured.\" There is no cure for pancreatic cancer. There are people who survive it, but nobody knows why. > and then went through heroic real-doctor efforts once it was too late: If it was \"too late\" why did these \"heroic real-doctor\" exert any effort? Shouldn't they have known better? Being \"heroic\" and \"real\" doctors. The guy chose to be a lab rat after his 9 months of \"alternative medicine\" and 5 years of \"real medicine\" failed him. These \"heroic doctors\" failed him just like the \"unheroic doctors\". As I said, cancer isn't an exact science. People who think it is either know nothing of cancer or are just unthinking bootlickers. Hopefully one day we'll have a cure for cancer. reply basilgohar 39 minutes agorootparentI think one of the first things we need to adapt is calling it more than just \"cancer\" instead of something more descriptive. Like Alzheimer's, it's not actually \"one\" thing but many things together or separately are labeled with it. Each type of cancer can have its own cause, treatment, and prognosis. Once we better recognize it's a family of ailments, the populace can better understand the challenges to its various treatments and how we need to invest more into it. reply rob74 11 hours agoparentprevI assume that the Cork development team was built up before Jobs took over, which also explains why they were all laid off shortly after the author quit. Jobs probably wanted to have all (significant) software development happening in Cupertino? If he were still around, he would probably hate home office/remote work and join Elon Musk in the \"people can have all the home office they want as long as they work 40 hours per week in the office\" camp... reply leoc 5 hours agorootparentOne wrinkle here is that Jobs himself was by all accounts the person most responsible for Apple opening a Cork facility in 1980, and for whatever Apple and the Irish government promised each other as part of that deal. There's some indication that Irish governments were unhappy with what they got from it https://www.irishtimes.com/business/technology/state-papers-... but it's hard to be sure exactly what happened there: Apple was probably not in the best shape to carry out ambitious relocation plans for much of the '80s, for one thing. While I don't have boundless love for either Jobs or RTO mandates, and as an Irishman I would very much rather not see Cork getting the dirty end of the stick, I have to defend Jobs' desire for centralisation a bit here. There's considerable evidence that having nearly all the central product and design people within easy reach of SJ stalking around 1 Infinite Loop did in fact work very well for Apple in the second Jobs era. Maybe it was still a wrong decision, despite appearances, but you can hardly say that it was an eccentric one. (And in 2000 the tools for offsite or multi-site collaboration weren't even as not-entirely-great as they are now.) It was other people who brought in the madcap element of trying to hide things from the boss, not Jobs himself. reply jacobr1 2 hours agorootparentAll else being equal, for team-based, creative, knowledge work, having everyone collocated is more productive. But not all is equal. You can't necessarily attract the all the talent. It doesn't scale without extremely disciplined organizational and physical space design - working remotely in the office, is the more common norm. Your team is spread over different locations and buildings anyway so you aren't really working locally in practice. Strong communication and collaboration practices are what dominate - so just having people together in one place and expecting osmosis doesn't beat good async tooling and discussion practices (like those from the best OSS projects). reply kergonath 2 hours agorootparentprev> Jobs probably wanted to have all (significant) software development happening in Cupertino? Looks like it. There were still people working on iSync, iCal (and presumably software for the first iPhone) in an office in Paris. I think that ended in 2005. reply eddieroger 1 hour agorootparentprevIn an alternate and very charitable timeline, after being healed of his cancer by top doctors, Jobs grows greatly in love with science and medicine, and faced with the covid pandemic, makes Apple permanently remote work (with office option for those who want it), and donates sums of money to bootstrapping vaccine production for all the world. A boy can dream. reply interludead 4 hours agoparentprevMaybe (I think so) it was more about aligning every detail with the standards Jobs had in mind... reply pavlov 6 hours agoparentprev> “how destructively eccentric Jobs could be” I miss Steve Jobs. He was clearly an asshole at close range, but at heart he was a humanist and a bit of a hippie. He made money but also left the world a better place. Such a massive difference to today’s crop of tech billionaires like Thiel, Andreessen and Musk. reply leoc 5 hours agorootparentJobs is on the whole probably better than the modern \"tech right\", yes, if only because supposedly he turned down opportunities to get seriously into politics. OTOH, who knows what kind of strange political or personal journey he might possibly have taken if he'd been around for the past decade and more. And in fact I think he may have contributed to the US getting where it is now in (at least) one significant way. By committing his options-backdating caper and then avoiding punishment for it he contributed to the feeling that the Special Boy is too precious to suffer criminal consequences for his actions, something which has likely had consequences for the later career of Musk in particular. reply jkolio 3 hours agorootparentOh, I'm sure it's even fuzzier than that. Apple's cachet over the past 25 years was built on the type of class consumerism that reflects and then amplifies a lot of America's particular brand of social dysfunction. Much of tech during this time was focused (and continued to focus, to their market detriment, until they \"wised\" up and stopped) on a sort of egalitarianism; if the proposition is, \"Anyone can benefit from our product,\" most companies whispered the qualifier, \"...if you can afford it.\" Apple, on the other hand, shouted that last part from the rooftops, also encouraging the addendum, \"...and it makes you better than people who don't use our products.\" Apple was a standard-bearer for the toxic exclusivity and gatekeeping that's kind of always been a part of American society, but that we occasionally see some chance of finally throwing off. reply antonvs 1 hour agorootparent> ... but that we occasionally see some chance of finally throwing off. That seems optimistic to me. What are you thinking of? reply SteveSmith16384 6 hours agorootparentprevHistory would suggest otherwise. Ripping Woz off springs to mind. And is giving the world expensive Apple products making it a better place? reply yapyap 3 hours agorootparentprevdon’t get me wrong Jobs definitely progressed the technology of that time by leading Apple but what exactly did he do to make the world a better place? reply achenet 3 hours agorootparentif you believe that enabling people to easily communicate with each other and access basically the sum total of humanity's knowledge whenever they want is a good thing (ie if you think giving people iPhones so they can message each other and read wikipedia is a good thing), then you can say his work did help with that. You can also say that Macs have helped many people express themselves creatively (iMovie, Garage Band, Logic, Final Cut...), which you might think is a good thing. reply SteveSmith16384 1 hour agorootparentThe technology to do all of those things existed well before iPhones & Macs appeared. You may argue that \"yeah but he made them popular\", but the iPhone & Mac users were never in the majority. reply Clubber 5 hours agorootparentprevI mean electric cars, solar panels, and rockets so we don't have to rely on Russia to get to and from space ain't nothin'. Then there's that torch thing. I can take or leave the other two. Netscape was pretty cool. reply pavlov 5 hours agorootparentAs a customer I find a stark difference between Musk and Jobs. I have a Tesla and I was also a customer of Jobs’s Apple since 1999. The big difference is that Jobs never lied to me. Sure, he was an enthusiastic salesman, but the products actually did what was promised. (I even bought Mac OS X 10.0 in a retail box. It was rough but it showed that their new OS is delivering.) Apple products fit my purposes and I kept coming back to buy more. Musk sold me a very expensive feature that still does nothing, six years later. He knew that he was lying about the capabilities of the cars, but still took my $7,500 for a feature that was worth zero. I’m never buying anything from him again. The same approach of bald-faced lies is evident in most of the tech industry today. Cryptocurrency products don’t serve any purpose but enriching people like Andreessen. AI is almost as bad. And now these titans of misinformation are barging into global politics. They don’t care about empowering people and creativity like Jobs did, they just want more personal power. reply euroderf 3 hours agorootparentIt's not \"lies\" it's \"reality distortion\". So much more pleasant! reply 9rx 2 hours agorootparentprev> The big difference is that Jobs never lied to me. I'm sure he will get around to providing FaceTime as an open industry standard any day now... reply kergonath 1 hour agorootparentThat is not because of him. They ran into patents problems and lost a lawsuit about this. They did contribute a couple of industry standards, including zeroconf/bonjour and OpenCL. I haven’t seen anything or anybody saying that the FaceTime thing was a deception. reply 9rx 1 hour agorootparentSupposedly he announced it off the cuff, without consulting anyone else as to the viability, not even notifying the FaceTime team beforehand. You can get into a semantic argument with yourself about whether that is actually a lie, but no matter what you conclude, that seems to be the same kind of \"lie\" that Musk makes. reply yapyap 3 hours agorootparentprevJobs lied all the time, only difference was that he had the luck of not being busted cause he could realize the lies before the due date. Not saying this makes him worse than Elon Musk though, Elon is obviously much worse. You can see this in just how he interacts politically and how he used his social media platform to influence elections. reply Clubber 5 hours agorootparentprev>Musk sold me a very expensive feature that still does nothing, six years later. He knew that he was lying about the capabilities of the cars, but still took my $7,500 for a feature that was worth zero. I’m never buying anything from him again. I assume you're talking about auto-pilot? >The same approach of bald-faced lies is evident in most of the tech industry today. Cryptocurrency products don’t serve any purpose but enriching people like Andreessen. AI is almost as bad. And now these titans of misinformation are barging into global politics. They don’t care about empowering people and creativity like Jobs did, they just want more personal power. Yes, the tech industry went from promising Star Trek like future to Demolition Man meets 1984 where Taco Bell owns everything and spies on you. It's not great. Stallman was right, but he got conveniently pushed out of the conversation. reply browningstreet 3 hours agorootparent> I assume you're talking about auto-pilot? Full Self Driving. Tesla doesn't charge extra for Autopilot. reply jpm_sd 20 hours agoprevGreat story, and a thought-provoking title. I LLOLed at \"We’ll just tell Steve you did move.\" I'm 45, so I'll mark my 2nd quarter-century in the not-too-distant future. Very approximately, so far: 0-25: learning 25-50: doing 50-75: TBD reply sudhirj 16 hours agoparentOld Hindu philosphies have a similar split. https://en.m.wikipedia.org/wiki/%C4%80%C5%9Brama_(stage) 0-25y grow and study 25-50y develop your household, your family, your community and gain wealth (non-extractive, provide value). 50y-75y hand over all worldly things to the next generation, advise, teach and help those around you. Focus on your spiritual enlightenment. 75y- renounce the world and disappear into the forest as a monk / hermit. reply keiferski 13 hours agorootparentSimilar to Andrew Carnegie, although I am not sure if he quite disappeared from the world: The \"Andrew Carnegie Dictum\" was: - To spend the first third of one's life getting all the education one can. - To spend the next third making all the money one can. - To spend the last third giving it all away for worthwhile causes. reply bix6 13 hours agorootparentprevI’ve only ever heard these sequentially so was interesting to read they need not be. “while in the original system presented in the early Dharmasutras the Asramas were four alternative available ways of life, neither presented as sequential nor with age recommendations.” reply aprilthird2021 3 hours agorootparentAlmost everything in Hinduism is not prescribed strictly because Hinduism is really an amalgamation of many separate beliefs systems / traditions / ritual / books, etc. which were followed by local cohorts. That's why many books contradict each other. Some books prescribe an age and order for such steps, others don't, etc. They weren't meant to be all collected, all studied, and all chosen piecemeal by one observer. But over time it has evolved into a much different thing than when it started reply beebmam 13 hours agorootparentprevI hope more people read comments like these and ask themselves: \"What warrants these life suggestions? Are they justified? What would make them justified? What alternatives are there?\" reply apocadam 7 hours agorootparentIndeed, why wait till 50 to start giving back. Edit: Not talking purely about financially giving back, but also volunteering your time. reply joseda-hg 7 hours agorootparentThere's an argument to holding on X money will let you make more money, therefore making your actual contributions larger / more valuable You can more easily invest your second million than your first (Because you probably need that (Or at least a portion of that to live) There's also no significant reason to start earlier (or later), unless you factor in dying as your stopping point, worthwhile causes aren't going anywhere reply jpm_sd 6 hours agorootparentprevBecause by then you've mostly finished spending money on raising your own children. reply sincarne 6 hours agorootparentI turn 49 tomorrow, and my kid’s next birthday will be her 11th. I have a lot more spending on her ahead! reply jwr 19 hours agoparentprevThat timescale… got me thinking. In my case it was closer to: 0-25: dicking around, with some incidental learning 25-35: learning how one gets screwed in business deals (by getting screwed in business deals) 35-40: dicking around pretending to work and thinking this is called \"startups\" 40-50: actually doing stuff, working on meaningful things that people pay for and making a good living off that I am looking forward to the future :-) reply y1n0 18 hours agorootparentYou’ve peaked. The rest is just the same story in reverse. reply j45 15 hours agorootparentOr you can never stop peaking and growing in different ways :) reply bitwize 17 hours agorootparentprevI'm 47. 50+ is looking a lot like \"struggling to run the red queen's race to keep my wife and furbabies safe, sheltered, and provided for, while watching the eventual deterioration of my body into uselessness and decrepitude begin, and watching ageism diminish my opportunities in the field\". Affordable rejuvenation therapy in the next couple of decades is pretty much my only hope. Maybe then I could claw back another decade or two of vigorous life with my wife with greater wisdom than I had the first time around. reply scarface_74 15 hours agorootparentI’m 50 now and have plans to run a 5K in at around 30 minutes by the end of the year. I haven’t run a 5K in over 15 years. Even though I have worked out continuously since I was 12. But from my current training, I don’t see any reason that isn’t achievable. No part of my body is giving me warning signs and the training isn’t any harder than it was 15 years ago. As far as “ageism”, I changed jobs at 40, 42, 44, 46, 49 and last year at 50 and neither time did it take me more than 3 weeks to get a job. I got my first only and hopefully last job at a “FAANG” at 46. None of those were management jobs and I’m now a “staff software engineer” at a third party cloud consulting company. I’m well aware that my body will decline over the next 20 years. But no need to give up prematurely reply BytesAndGears 12 hours agorootparentI listen to a podcast called Crushing Iron. One of the two hosts realized he was in poor shape and his friends were starting to decay. I think he was about 50 when he had that realization. He decided not to let it happen to him, so he got into triathlon. Now, he’s doing Ironman races every year for the last ~10 years, and he started at around 50 (maybe 49 or 48, don’t remember). Other host was an alcoholic who bounced back into a very healthy life. Both are inspirational, but I think the other applies to you more. Point is, you can do it! You don’t have to do a whole Ironman, obviously lol, but making choices to be healthy like you are is an amazing step. And it’s absolutely possible to start at 50. If you want motivation, the Crushing Iron podcast has some great episodes (and some kinda boring ones). Check out this one, “Out alone in the dark”.. I like their episodes from a couple years ago (and older) the most. Also 667 and 685 are a couple I had saved recently as good ones. Out alone in the dark: https://podcasts.apple.com/us/podcast/crushing-iron-triathlo... #667 Play like a kid: https://podcasts.apple.com/us/podcast/crushing-iron-triathlo... #685 stop waiting for life: https://podcasts.apple.com/us/podcast/crushing-iron-triathlo... Couple bonus episodes I love: https://podcasts.apple.com/us/podcast/crushing-iron-triathlo... https://podcasts.apple.com/us/podcast/crushing-iron-triathlo... reply achenet 3 hours agorootparentprevLook up Clarence Bass [0] You can stay impressively fit well into your 80s :) [0] https://en.wikipedia.org/wiki/Clarence_Bass reply scarface_74 2 hours agorootparentMy dad is still active in the yard and is mobile and independent at 82. But age is slowing him down. His eyesight and hearing is deteriorating. My mom is 80, active and I don’t see her slowing down, she is still comfortable driving from south GA to central Florida where we live and the other surrounding states as long as it’s daytime. I’ll be happy if I can still be as active as my dad reply scarface_74 17 hours agoparentprevFor me: 0-22 - I’m someone else’s responsibility - graduated college degree in CS 22-36 - shuffled aimlessly between two meaningless jobs, a horrible mistake of a marriage (and divorce), got into real estate too heavily and the crash of 2008, taught fitness classes on the side as my only outlet. 36-46 - got remarried and became an instant father to a 9 and 14, rebuilt my career from scratch and hopped between 5 jobs, got my finances under control after walking away from 5 mortgages, built a strong marriage and both (step)sons graduated. “Retired my wife” when she was 44. 46 - present - transitioned into consulting, got first and only job at BigTech, (working remotely cloud consulting department), moved permanently into what was a vacation home in Florida, and start traveling extensively post Covid including doing the digital nomad thing. Left BigTech and enjoying a nice balanced life with my wife while I work remotely and she enjoys her passion projects. reply VoidWhisperer 17 hours agorootparentWhat does 'retired my wife' mean in this context? reply scarface_74 17 hours agorootparentI made enough so she doesn’t have to work anymore. Before Covid, she was a special needs bus driver. I didn’t want her on the bus after Covid for both her health and mine. By the time Covid lifted, we had decided to fly around the country taking one way trips and she was deeply into her passion projects. We got rid of everything we owned that wouldn’t fit into 4 suitcases. Our official home was our vacation home in (state tax free) Florida that was being rented out while we were traveling as a short term rental. The “state tax free” came in handy when I was getting RSUs/pro rated signing bonuses reply PopAlongKid 1 hour agorootparent> Our official home was our vacation home in (state tax free) Florida that was being rented out while we were traveling as a short term rental. States typically define residency as either based on domicile, or a statute. In other words, some of the states you \"traveled\" to undoubtedly have laws stating that if you are in the state for a certain number of days out of the year, you are automatically a resident, not a visitor, and liable for taxes on your world-wide income. reply scarface_74 57 minutes agorootparentBesides Las Vegas where we ended up staying a month and a half and two cities in Texas where we were in Dallas and Houston 3 weeks each, we only stayed in one place for a maximum of 3 weeks. It just happens to be a moot point in Nevada and Texas since they were both state tax free states. When we do it again probably in summer 2027, those also happen to be the two states we will be spending the majority of our time. My wife knows a lot of people in both states reply asdf6969 17 hours agorootparentprevShe’s unemployed and he pays for her lifestyle reply scarface_74 17 hours agorootparentThe official definition of “unemployed” is you are out of work and looking for a job. Honestly, though her spending money was a matter of selling 2 shares of AMZN pre split every six months when I was getting RSUs. We cut our fixed expenses dramatically after Covid and our younger son graduated, downsizing and moving to a state tax free state. reply joseda-hg 3 hours agorootparent\"not engaged in a gainful occupation\"[1] \"not having a job that provides money\"[2] Maybe not official as in dictionary definition, but official as in political / statistical lingo? [1] Kagi's response provided by WordsAPI, I'm not sure if linking a technically paywalled would be the reasonable thing https://kagi.com/search?q=unemployed+meaning [2] https://dictionary.cambridge.org/dictionary/english/unemploy... reply scarface_74 3 hours agorootparentYou are not considered “unemployed” by the government if you are not actively seeking work. The official definition as far as the BLS. http://www.mississippi.edu/urc/downloads/econ101-01_151118.p... > Finally, other individuals who are not working or seeking work for pay or profit are not included in the labor force. > BLS considers the unemployed as those individuals without a job who have looked for one in the past four weeks and are available to work. Looking for work involves an individual taking some action to obtain a job, such as completing an application, sending out a resume,contacting an employment center, etc. Individuals who have been temporarily laid off are considered unemployed regardless if they have looked for work in the last four week reply ok_dad 0 minutes agorootparentThe government’s definition is designed to make things look nice, not gauge the actual level of unemployment. If you’re not looking for work because you gave up trying, you’re not counted even though you’re unemployed. Retired or disabled is a different thing, and being a home maker and taking care of kids should be counted in the numbers as employment, otherwise everyone should be under unemployed. pelagicAustral 7 hours agorootparentprevShe's been 'taken care of'... reply interludead 4 hours agorootparentprevOut of curiosity, what do you think was the biggest turning point for you? reply scarface_74 4 hours agorootparentThe biggest turning point for the worse and for the better was not having a good stable home life. I am not saying you have to be in a relationship to have stability. Of course it’s better to be single than being involved in a bad relationship. Looking back, what really started things going bad was a lack of self confidence and wanting to be in a relationship. I was a short computer geek, kind of awkward. I got better. Now I’m very comfortable talking to anyone. It’s my $Dayjob. Ironically enough though, I had no trouble being in front of people at 28 and had been a part time fitness instructor for 3 years by then as hobby. I was in great shape. I met someone who was physically attractive and was interested in me after being friendzoned all of my adult life. I got married and I should have seen the signs. That led to everything else that happened for the next 6 years - staying at a job too long, getting too heavily invested in real estate trying to make more money, stagnating both technically and financially. Got divorced at 32. At 34, in 2008 around the time of the real estate crash, I just had to accept the fact that everything I had done up to that point was a waste and be comfortable starting over from scratch. I got ready to interview after being at my second job for over 9 years and did a vertical move to another job that would let me get some real world experience with an in demand language - C# and the startup was working with ruggedized mobile devices right when smart phones were taking off. I wasn’t trying to date anyone at that time and my now wife had to basically shove her number at me once we had been working together for over two years. She was in another department. I told her all of the shit I was going through at the time with my real estate and she was still interested. We both got laid off when the company went out of business and she got a job quickly that had benefits and I got a good paying contract without benefits. I proposed to her while I was working as a contractor with the plan for us to get married after I got a permanent job. She suggested we get married sooner so I could be on her benefits. That arrangement kept until 2020 when I was 46. It allowed me the freedom to jump back and forth between full time and contract jobs to build my resume. In 2020, as a direct result of me being able to aggressively job hop, a remote position at AWS (Professional Services) fell into my lap in 2020. The difference between what I was making pre-AWS and post AWS was 3x what she was making. But there is a direct line from her supporting my career to me being able to do that. I have no problem with my wife not working so she can pursue what she wants. It gives us a chance to travel like crazy and it’s not like my life is stressful once I left AWS. reply Gualdrapo 19 hours agoparentprev> I LLOLed at \"We’ll just tell Steve you did move.\" It made me remember about that rumor of Musk firing people at random, but afterwards their immediate superiors just make them to move to another office whatsoever - Musk won't remember the next time he'd be there. reply turnsout 18 hours agorootparentThey told the same exact yarn about Steve back in the day. I think both are probably exaggerated. reply codazoda 17 hours agorootparentI worked at Iomega (Zip Drive) from 1994 to 1998. The VP was rumored to fire people on the spot for the smallest thing. One day we worked an all nighter. The entire department. The next day we were still there. Having solved the problem, most of us were asleep at our desks. The VP made an unannounced visit and walked through the office. None of us noticed him. He walked to my bosses bosses office and asked him to assemble us in the meeting room. He walked into the meeting, said he was impressed with how hard we were working, pointing out that our heads were down in deep thought. Then he left. These days, I think he was trolling us. I got to know him quite well later in my career. I never saw him fire anyone. reply pchristensen 2 hours agoparentprevSome describe the three phases of your career as learn, earn, return (e.g. philanthropy, advising, etc). reply leoc 6 hours agoparentprev> Fiche bliain ag fás, > Fiche bliain faoi bhláth, > Fiche bliain ag meath > Agus fiche bliain gur cuma ann no as. \"Twenty years growing, Twenty years in bloom, Twenty years in decline, And twenty years when it makes no difference if you're there or gone.\" reply safety1st 11 hours agoparentprevI think it's interesting that everyone's timeline here stops at 75, meanwhile we're about to inaugurate a 78 year old President, who is replacing an 82 year old President. As much as everyone loves to hate these guys, they're the most powerful men in the world and they clearly didn't get there by fading into retirement from the age of 50 onward. I guess it depends on what you want in life but I wouldn't mind taking a hint from them. You clearly don't need to stop when you're old. For some, life appears to be a continual doubling down for higher and higher stakes. I'm in my mid 40s and as my resources expand all I want to do is ante up and wrestle with bigger demons. Every decade for me is one more chance, maybe the last, to reclaim the stolen aspirations of my youth. The ticker will give out someday, but until then I don't want to ever stop. I'm the healthiest and probably also the angriest I've been in 20 years. Whatever else may transpire I hope to be a bit like those croaking old fuckers and never go gently. reply vnce 10 hours agorootparenteffin' a :) reply purple-leafy 19 hours agoparentprevHa for me its been: 0-25: Arrogance, ignorance, stupidity, delusions, boring normal person 25-50: Obsessive learning/study, application, and passion, finding myself 50-75: Not there yet I just turned 30 and I'm having a blast learning graphics and audio programming, mostly in C! Found my passion, raycasting, audio engineering, and building desktop software reply BriggyDwiggs42 12 hours agorootparentYeah the only thing i dont love about the framing is that it implies you cant still be in the learning phase later in life. Neuroplasticity can be encouraged and cultivated. reply interludead 4 hours agorootparentLearning has no expiration date reply ronyeh 14 hours agoparentprevDenzel’s Learn, Earn, Return. https://youtube.com/clip/Ugkx1T-qoilkYC6vZ48N8US2aM9nHiFTq2I... reply throwaway657656 17 hours agoparentprevsuggested edit: 0-25: learning 25-50: earning 50-75: returning reply onlyrealcuzzo 19 hours agoparentprev75-100: Hopefully not dead. reply nine_k 15 hours agorootparentNot dead but disabled and dimwit, an annoyance to those who used to love the person you previously were, likely also short on money all the misery which that entails? No, this is seriously worse than death to me. Either it's a life worth living, or forced shutdown for me, while I still have a say. reply onlyrealcuzzo 4 hours agorootparentWow - what a bleak answer. You can't imagine being healthy at 75? Most of my family members 75+ are still doing quite well. My great grandma lived to 99 and wasn't particularly unhealthy until 98. My mom's best friend's dad is 98 now, and was in pretty good health until 96. None of them were poor and burdens on society. reply nine_k 3 hours agorootparentOf course it's best to stay healthy at 75 and beyond! My bleak answer is a refutation of the idea that merely \"staying alive\" is a goal. Staying physically alive is not enough. reply jpm_sd 19 hours agorootparentprevDepends on how 50-75 goes! reply BadHumans 19 hours agorootparentI'm a couple years into that range and I'm not dead yet! Only 90% of a quarter-century to go! reply yzydserd 7 hours agoparentprev0-25: learning 25-50: doing 50-75: enjoying 75-100: leaving reply kamaal 15 hours agoparentprevI hope there was something like a fun quarter some where in there. Perhaps whatever we might call it. 0 - death -> Doing things. This is just how it unfolds. reply cmrdporcupine 15 hours agoparentprevJust turned 50. Unfortunately I already feel like a theme of 50-75 is \"forgetting.\" I remember very well the stuff I learned from 0-25 but damned if I remember last month. reply neilv 15 hours agorootparentTalk to a doctor, and look into your lifetyle (sleep, nutrition, exercise, stress, etc.). And don't throw the rest of us under the bus for hiring discrimination. reply cmrdporcupine 14 hours agorootparentPretty sure your potential future employers are not reading my self-deprecating humour on HN before considering your application. reply neilv 14 hours agorootparentYC started by funding 20 year-olds with no experience, and telling them they were the best people to be doing startups. We know that our field already has a lot of age discrimination. Why reinforce that message with grassroots chatter that impressionable new startup founders and young engineers will see on HN? AFAIK, representatives of other discriminated-against groups aren't coming to HN to voice silly negative stereotypes directly related to workplace performance. reply BriggyDwiggs42 12 hours agorootparentAnyone who can’t see the value in hiring someone with some wisdom is really damn stupid imo. Easily worth it even under a cynical, money-focused outlook. reply peterlada 18 hours agoparentprevOr as Shakespeare would have put it: 0-25: Act I 24-50: Act II 50-75: Act III, the final act. reply dasloop 6 hours agorootparentI`m pretty sure that most of us will be alive after that final act ;) reply pavlov 6 hours agoprev> \"I was shown some prototypes and basically told that six people had seen it, and if it leaked they would know it was me that had talked\" This near-paranoid level of secrecy was because Apple leaked like a sieve in 1997 when Jobs returned as interim CEO. There were sites like Mac OS Rumors that reported about internal meetings and projects in almost realtime. Nothing that was started before Jobs's return was secret. Leaking seemed to be part of standard office politics at Apple. Jobs wanted to clamp down on that. Who knows if they actually had measures like described in the article (which suggests that every screenshot of Aqua carried a steganographic hardware id) but the threat worked. The leaks were obviously bad for Apple, but as a teenager in my first tech industry job I found them fascinating reading. It was a rare insight into the inner workings of famous tech company in faraway California (even if it was the company that everybody in the media was convinced would be bankrupt in a year or two, but that just made the product drama more poignant). reply MichaelZuo 2 hours agoparentYeah Jobs was probably afraid of anyone involved in sensitive stuff, not based in Cupertino, to be engaged in games or tricks like that. And they would be too far away to closely monitor. reply p_l 5 hours agoprevThe mention of Finder being built with Carbon APIs using OS9 as dev environment makes me wonder if that's not why some Finder APIs in 2020 still used classic Mac pathnames (with colons as separators). Had to find some gnarly AppleScript to convert pathnames when interacting with Finder reply runamuck 18 hours agoprevI laughed at the title! My friends and I say the original quote way to much, even 25 years later. (From \"Fast and Furious - Vin Diesel says \"I live my life a quarter mile at a time.\") reply bthrn 16 hours agoparentAt work I coined the phrase \"Fast & Furious Planning\" to describe teams that plan only a quarter at a time (without regard for longer term thinking). reply blitzar 9 hours agorootparentFor those 10 seconds or less, they are free. reply eru 18 hours agoprevSmall tangent: > As a final note, when I left Apple for the last time, and emptied out my drawers, at the very bottom of the last drawer I found my distinctly unsigned NDA. I wonder if that legally makes any difference? There's probably an oral or implied contract for this kind of stuff, if you keep showing up to work and they keep paying you? reply JKCalhoun 14 hours agoparentI've always wondered about the opposite. That is can an NDA even be legally enforced? reply eru 13 hours agorootparentWhy wouldn't it? I was wondering the opposite: even if you don't explicitly sign some contracts, as long as you have seen them and behave as-if you are following the contract and the other party gives you their part of the bargaining, that might be legally (almost) equivalent to having signed the contract. (I'm not a lawyer, and this is speculation.) It seems the legal term of art for this in 'an implied contract'. reply JKCalhoun 6 hours agorootparentThe NDA could say that by signing this I am to hand over my first born but it isn't enforceable. An obvious straw man example I admit but to make the point that signing a thing doesn't give a thing some kind of godly power. reply jpc0 8 hours agorootparentprevTerminology I head in law classes over a decade ago is tacid contact and definitely was a legal contract although difficult to prove in court when I did study the little contract law I studied. reply rcbdev 11 hours agoparentprevHow do you \"imply\" non-disclosure? reply eru 11 hours agorootparentWell, you hand your employees that very sheet of paper that the protagonist found unsigned in their drawer. And trade secrets are a fairly widespread concept, too. So judges wouldn't have a hard time believing that a reasonable person would recognise trade secrets in most cases. reply bbarnett 7 hours agorootparentThe reverse is true. They asked to sign an NDA, the person looked at it, decided not to agree, but they kept them on regardless. It would be better to have never handed te person the formal agreement, than give it and be ok with them not signing. (not keeping track is just as bad, it marks the NDA as unimportant) reply rm445 9 hours agoprev> You all know the Dock, it’s been at the bottom of your Mac screen for what feels like forever (if you keep it in the correct location, anyway). On a website with huge margins at the sides. I think the OSX Dock is a pretty good thing, but it makes so much more sense to keep it on the side of the screen and preserve vertical pixels. Unlike (some versions of) the Windows Taskbar, the icons are all square with no text, so you're not even sacrificing readability. reply abroadwin 2 hours agoparentI just set mine to auto-hide. Right now it's showing just shy of 30 icons, and I feel it really benefits from the additional horizontal width. reply Lammy 12 hours agoprev> I loved doing UI stuff, but somehow ended up working on a command line Mac OS X Server authentication component for At Ease that was to be used with a new line of diskless netboot computers that nobody had actually seen. It turned out I’d actually been on the iMac project all this time, and in the end they got hard drives. Relevant: Macintosh Network Computer — https://tedium.co/2018/04/12/larry-ellison-network-computer-... — https://web.archive.org/web/20130603044116/https://sw.thecsi... — https://web.archive.org/web/19961220160908/http://www.macwee... — https://web.archive.org/web/19961220043823/http://www.macwee... — https://web.archive.org/web/20000531132121/http://www.theapp... “During a speech trumpeting the network computer for the Harvard Computer Society earlier in December, Larry Ellison, Oracle chief executive officer and Apple board member, responded to a question about Apple's role in the NC space. Ellison said the Macintosh NC would be available in April, with a near-300-MHz processor and a 17-inch screen. The Mac NC will run on the Mac OS and cost less than $1,000, according to attendees. Ellison added that the NC would not ship with a hard drive, but one could be added to the unit for an additional $100. ” reply drummojg 16 hours agoprevI feel this in my soul. I work in higher education, and every major contribution I've made has been ripped from my hands and either dashed like the first copy of the ten commandments or handed over to someone shinier. I'm still proud of all I've done. reply kernel_cat 9 hours agoprevI just hate the Dock. I wish there was a way to make it completely disappear. I have no need for it, everything I can do via Terminal/open, Spotlight, or cmd+tab app switcher. It's really annoying how baked into the OS it is. Even trying to auto-hide the dock in new versions of MacOS is a huge pain in the arse. reply LeoPanthera 9 hours agoparentRight click the divider line > Turn Hiding On reply kernel_cat 2 hours agorootparentNot complete without setting the autohide delay which doesn't have a GUI option, need to set with a 3rd party tool or `defaults`. reply klntsky 16 hours agoprevTo tell a story about slapping a few desktop buttons in a way that makes it interesting to read is a talent reply myvoiceismypass 16 hours agoparentIt seems sorta trivial at a surface level but we as developers are always standing on the shoulders of giants. What seems easy and simple was not always so without the tooling, compute, language advances, and knowledge sharing that we have today. reply julik 2 hours agoprevI wonder how many HN readers remember what DragThing was and have used it... memories. reply pbrum 3 hours agoprevThe story is great on its own, but that ending was absolutely magnificent reply smorchyborch 19 hours agoprevKinda funny watching people OOoh and Aaaah over something that Windows had launched 5 years earlier with Win95. The Mac/Windows flamewars back then were still as vivid as they are today. reply re 18 hours agoparentIf you're talking about the Dock demo (vs the Windows taskbar), it's not so much the Dock itself getting that reaction but more so the Genie effect. Mac OS X 10.0 and its Quartz Compositor did enable window effects beyond what Windows was capable of at the time--Windows didn't get a compositing window manager until Vista was released in 2007. reply kergonath 46 minutes agoparentprevThe dock has more to do with NeXTSTEP’s than with the Windows taskbar. They really are quite different (though maybe less so these days compared to back in the late 1990). reply incanus77 18 hours agoparentprevI don't recall Windows 95 spatially minimizing windows into the bottom of the screen while preserving their dynamically updating contents. Did it? Or was it full of identical grey rectangles and moved window contents just by their outline, not their contents? The Aqua interface was a cut above given the landscape even five years later. reply ben7799 2 hours agorootparentIt's kind of easy to forget OSX did this but it was glacially slow at first. I remember seeing the Betas in 1999-2000 or so and they were on an iMac and the whole UI barely worked. And I think in 2004-2006 I was still turning the animations down or selecting the simpler ones. I maybe started leaving them on when I got a monster Mac Pro in 2006. reply eru 17 hours agorootparentprev> Or was it full of identical grey rectangles and moved window contents just by their outline, not their contents? It moved the whole window, but you could enable the effect you mention to save on system resources. (If memory serves right.) reply dcrazy 17 hours agorootparentI believe full-window moves were an optional Windows 98 feature. Possibly also available in Windows 95 via registry tweaks or if you had Microsoft Plus! installed. reply eru 15 hours agorootparentMy memory might be from Windows 98, yes. reply bitwize 13 hours agorootparentprevI remember full-window moves from Windows 95 and even the Windows 95 preview skin for Windows NT 3.51. reply dcrazy 17 hours agoparentprevThe Dock was an evolution of the applets that had originated in NeXTSTEP several years before Windows 95’s UI team iterated the “system tray” into the taskbar that actually shipped. reply qingcharles 15 hours agorootparentAnd I guess Windows 95 was sorta building on the fact you could stack your open windows at the bottom of the screen in Windows 3.x. The early versions of 95 I was running still had the 3.x look to the taskbar/dock: http://toastytech.com/guis/chic58.html reply leoc 5 hours agorootparentThat's not too dissimilar to the folder tabs which appeared at some point in classic MacOS, though I don't remember when: quite possibly after '95. reply kergonath 41 minutes agorootparentIIRC that was with MacOS 8, which was in 1997. reply dcrazy 14 hours agorootparentprevAs the author notes, Windows 95 was remarkable for the iterative process that Microsoft’s UI folks undertook. They published an article in the ACM [1] on how they completely discarded the previous approach of designing from first principles in a vacuum in favor of rapid iteration and frequent usability testing. This let them abandon their fear of changing too much—in fact, the article directly addresses the evolution of taskbar icons from the version shown in your linked screenshots to what eventually shipped. [1] https://dl.acm.org/doi/fullHtml/10.1145/238386.238611 reply varjag 8 hours agoparentprevAnd whatever was in Win95 was in Motif, right? Come on it was distinctively superior when it came out. reply bitwize 17 hours agoparentprevKinda funny watching Windows nerds ooh and aah over something Jobs launched 7 years earlier with NEXTSTEP :) reply jbjbjbjb 18 hours agoprevAs a software engineer from the U.K. I always wondered if mega big tech did any interesting work outside the US. Hopefully things have changed now? reply aardvark179 18 hours agoparentThey do quite a lot of interesting things, but often either through acquisitions or by collecting up a whole load of specialists when somebody else closes an office. You also find some interesting stuff being done in the UK and the EU because salaries aren’t as high over here. reply JKCalhoun 14 hours agoparentprevCork had Apple engineering. A lot of work was done in Apple France as well. (For example I worked with the French team that wrote \"Data Detectors\" when I worked on Preview at Apple). Pretty sure a lot of the French accents I heard on the Photos team were engineers that had decided to move from France to The Valley. reply kergonath 38 minutes agorootparentIndeed. There was a developers teams around Jean-Marie Hullot in Paris up until 2005. They were responsible among others of iCal and iSync, and I believe iPhoto (Hullot was a photographer and a photo nerd). reply yodsanklai 12 hours agoparentprevYes, they do. On the top of my head, Meta Fair labs has a big office in Paris for instance. Google/Meta have offices in Europe (including pretty big ones) and have interesting teams there. reply qingcharles 15 hours agoparentprevDefinitely. Megacorps often outsource projects to development shops in the UK, even if they're not working directly for Megacorp. It's just hard to hear about it because NDA hell. source: experience reply eru 17 hours agoparentprevWe did some interesting work at Google Sydney. Google Wave was developed there, for example. (But that was before my time.) reply leoc 16 hours agoprevWell, that seems to be a significant new insight into the mystery of what does or does not happen in Apple Cork https://news.ycombinator.com/item?id=42255412 . reply BLKNSLVR 14 hours agoprev0 - yesterday: can't really remember but happy with whatever I did to get here. Future: stay the course. I've never much liked who I was yesterday, but I'm (almost) always happy with who I am right now. reply dukeofdoom 19 hours agoprevFor the purpose of organization, 15 minute intervals, is how you should look at your day. You only have abut 64 of these in your day to allocate (if you sleep 8 hours) So make the most of them. reply dwighttk 4 hours agoprevEarn a penny Owe a dime… reply nbzso 15 hours agoprevThis year, I push 50. Ideal time to start learning c/c++ and watercolor painting. Don't limit your mind to a predefined timeline. I have a friend, his grandfather 69, completed a law degree and opened an office.:) P.S. The tech industry ageism is standard which must be outlawed. It is not objective and moves the industry in the wrong direction. reply griomnib 17 hours agoprevWasn’t the dock part of next step? reply cactusplant7374 19 hours agoprevDrag Thing. What a trip down memory lane. I had totally forgotten about playing around with this application in my youth. reply ChrisMarshallNY 19 hours agoparentI loved that utility. One of the things about Aqua, was that it really slowed things down. We had gotten prerelease OS X, but it basically used Classic UI. Once Aqua came out, things like window drawing, dragging, and general responsiveness, went way down. reply dcrazy 17 hours agorootparentAqua would rather drop frames than produce incorrect or partial draws. reply cactusplant7374 19 hours agorootparentprevI noticed that. I was always on the cheapest hardware so I made peace with it. reply ghssds 19 hours agoprev [–] I live my life four quarter century at a time for I don't ignore 4 simultaneous days same earth rotation. Navel Connects 4 Corner 4s. Bikini Bottom is the signature of your personal creator. reply dcrazy 17 hours agoparent [–] I don’t know if you’ve been voted down to discourage joke comments or because people aren’t familiar with Timecube. reply defrost 17 hours agorootparent [–] It'll be a bit of both, given time the timecube comment might rise again. I get a mixed reaction to tongue in cheek, jokey comments that I make, some rise, most fall - HN doesn't lack a sense of humour but a good many don't want to see it normalised as that tends to drag the general level downwards. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "On January 5, 2000, Steve Jobs introduced the Aqua user interface of Mac OS X, including the Dock, at Macworld Expo, with significant contributions from an engineer based in Apple Cork, Ireland.",
      "The engineer, who had previously worked on DragThing, was instrumental in transforming Bas Ording's prototypes into functional code for the Dock, but eventually resigned due to relocation pressures.",
      "After leaving Apple, the engineer revived DragThing and PCalc, which continue to be popular, and discovered an unsigned Non-Disclosure Agreement (NDA) in their possession."
    ],
    "commentSummary": [
      "The article discusses Apple's Dock development, emphasizing Steve Jobs' eccentricity and secretive nature, including flying an employee between Ireland and the US to maintain a facade.",
      "Despite significant efforts, the project was ultimately canceled due to issues related to office location.",
      "The narrative also delves into Jobs' controversial decisions, his legacy compared to current tech leaders, and broader themes like career paths and ageism in the tech industry."
    ],
    "points": 270,
    "commentCount": 153,
    "retryCount": 0,
    "time": 1736202178
  },
  {
    "id": 42615646,
    "title": "Triptych Proposals",
    "originLink": "https://alexanderpetros.com/triptych/",
    "originBody": "Triptych Proposals From Alexander Petros and Carson Gross Three small proposals for putting the \"hyper\" back in hypertext. Proposal Issue Tracker Support PUT, PATCH, and DELETE in HTML Forms Issue #3577 Button HTTP Requests Est. January 2025 Partial Page Replacement Pending Explanation Triptych is three simple proposals that make HTML much more expressive in how it can make and handle network requests. If you are a practical person, you could say it brings the best of htmx (and other attributed-based page replacement libraries, like turbo and unpoly) to HTML. For the more theoretically-inclined, it completes HTML's ability to do Representational State Transfer (REST) by making it a sufficient self-describing representation for a much wider variety of problem spaces. Basically, it should be easy to use HTML to declare page behavior that makes HTTP requests, and then tell the browser to either do a full-page navigation or replace part of the page with the response. Triptych enables this by bringing all the HTTP methods to HTML, giving buttons to ability to make requests without the help of a form, and making it possible to target a DOM subtree for replacement with the response. I first outlined these proposals in The Life & Death of htmx at Big Sky Dev Con. See also: the Triptych Polyfill (on GitHub). Status Published an update to the fetch spec that's required to get CORS support in navigation (and therefore forms). Working on the required changes to the navigation spec. For a full history of changes to the Forms proposal, see the updates section. Last Updated: Nov 10, 2024 Related Hyperlinks How Did REST Come To Mean The Opposite of REST? Who's Afraid of a Hard Page Load? Is htmx Just Another JavaScript Framework? A Response To \"Have Single-Page Apps Ruined the Web?\" Why do the htmx maintainers title so many blogs with rhetorical questions? (just kidding)",
    "commentLink": "https://news.ycombinator.com/item?id=42615646",
    "commentBody": "Triptych Proposals (alexanderpetros.com)232 points by felipemesquita 22 hours agohidepastfavorite67 comments alexpetros 20 hours agoCo-author here! I'll let the proposal mostly speak for itself but one recurring question it doesn't answer is: \"how likely is any of this to happen?\" My answer is: I'm pretty optimistic! The people on WHATWG have been responsive and offered great feedback. These things take a long time but we're making steady progress so far, and the webpage linked here will have all the status updates. So, stay tuned. reply ksec 1 hour agoparentThank You for the work. It is tedious and takes a long time. I know we are getting some traction on WHATWG. But do we have if Google or Apple have shown any interest? At the end you could still end up being on WHATWG and Chrome / Safari not supporting it. reply theptip 2 hours agoparentprevHow much would HTMX internals change if these proposals were accepted? Is this a big simplification or a small amount of what HTMX covers? Similarly, any interesting ways you could see other libraries adopting these new options? reply recursivedoubts 2 hours agorootparenti don't think it would change htmx at all, we'd probably keep the attribute namespaces separate just to avoid accidentally stomping on behavior i do think it would reduce and/or eliminate the need for htmx in many cases, which is a good thing: the big idea w/htmx is to push the idea of hypermedia and hypermedia controls further, and if those ideas make it into the web platform so much the better reply paulddraper 2 hours agorootparentprevThis covers a lot of the common stuff. This is native HTMX, or at least a good chuck of the basics. reply philosopher1234 14 hours agoparentprevIs it possible to see their feedback? Is it published somewhere public? reply divbzero 19 hours agoprevWhen I was reading “The future of htmx” blog post which is also being discussed on HN [1], the “htmx is the new jQuery” idea jumped out at me. Given that jQuery has been gradually replaced by native JavaScript [2], I wondered what web development could look like if htmx is gradually replaced by native HTML. Triptych could be it, and it’s particularly interesting that it’s being championed by the htmx developers. [1]: https://news.ycombinator.com/item?id=42613221 [2]: https://youmightnotneedjquery.com/ reply tomashm 27 minutes agoparent> I wondered what web development could look like > if htmx is gradually replaced by native HTML This perspective seems to align closely with how the creator of htmx views the relationship between htmx and browser capabilities. 1. https://www.youtube.com/watch?v=WuipZMUch18&t=1036s 2. https://www.youtube.com/watch?v=WuipZMUch18&t=4995s reply emmanueloga_ 14 hours agoprevIn the meanwhile, I found that enabling page transitions is a progressive enhancement tweak that can go a long way in making HTML replacement unnecessary in a lot of cases. 1) Add this to your css: @view-transition { navigation: auto; } 2) Profit. Well, not so fast haha. There are a few details that you should know [1]. * Firefox has not implemented this yet but it seems likey they are working on it. * All your static assets need to be properly cached to make the best use of the browser cache. Also, prefetching some links on hover, like those on a navbar, is helpful. Add a css class \"prefetch\" to the links you want to prefetch, then use something like this: document.addEventListener(\"mouseover\", ({target}) => { if (target.tagName !== \"A\" || !target.classList.contains(\"prefetch\")) return; target.classList.remove(\"prefetch\"); const linkElement = document.createElement(\"link\"); linkElement.rel = \"prefetch\"; linkElement.href = target.getAttribute(\"href\"); document.head.appendChild(linkElement); }) There's more work on prefetching/prerendering going on but it is a lil green (experimental) at the moment [2]. -- 1: https://developer.mozilla.org/en-US/docs/Web/CSS/@view-trans... 2: https://developer.mozilla.org/en-US/docs/Web/API/Speculation... reply alexpetros 13 hours agoparentIn many cases, browsers will also automatically perform a \"smooth\" transition between pages if your caching settings are don well, as described above. It's called paint holding. [0] One of the driving ideas behind Triptych is that, while HTML is insufficient in a couple key ways, it's a way better foundation for your website than JavaScript, and it gets better without any effort from you all the time. In the long run, that really matters. [1] [0] https://developer.chrome.com/blog/paint-holding [1] https://unplannedobsolescence.com/blog/hard-page-load/ reply recursivedoubts 21 hours agoprevthis is a set of proposals by Alex Petros, in the htmx team, to move some of the ideas of htmx into the HTML spec. He has begun work on the first proposal, allowing HTML to access PUT, DELETE, etc. https://alexanderpetros.com/triptych/form-http-methods This is going to be a long term effort, but Alex has the stubbornness to see it through. reply croemer 3 hours agoparentCongrats, you seem to be a co-author of the proposal as well, right? reply recursivedoubts 2 hours agorootparenti help alex out a bit, but he's the main author reply tinthedev 21 hours agoprevIt looks wonderful, but the adoption will be a thoroughly uphill battle. Be it from browsers, be it from designs and implementations on the web. I'll be first in line to try it out if it ever materializes, though! reply KronisLV 18 hours agoprevGood luck! The partial page replacement in particular sounds like it might be really interesting and useful to have as a feature of HTML, though ofc more details will emerge with time. Unless it ended up like PrimeFaces/JSF where more often than not you have to finagle some reference to a particular table row in a larger component tree, inside of an update attribute for some AJAX action and still spend an hour or two debugging why nothing works. reply mg 21 hours agoprevWhat is the upside ofover? reply bryanrasmussen 12 hours agoparentEverybody has already pointed out the problem with GETTING a deletable resource, but I figured I would add this (and maybe someone will remember extra specifics). About 2007 or so there was a case where a site was using GET to delete user accounts, of course you had to be logged in to the site to do it so what was the harm the devs thought, however a popular extension made by Google for Chrome started prefetching GET requests for the users - so coming in to the account page where you could theoretically delete your account ended up deleting the account. It was pretty funny, because I wasn't involved in either side of the fight that ensued. I would provide more detail than that, but I'm finding it difficult to search for it, I guess Google has screwed up a lot of other stuff since then. on edit: my memory must be playing tricks on me, I think it had to be more around 2010, 2011 that this happened, at first I was thinking it happened before I started working in Thomson Reuters but now I think it must have happened within the first couple years there. reply JadeNB 4 hours agorootparentJimDabell earlier recalled 37Signals and the Google Web Accelerator that sounds like what you mean: https://news.ycombinator.com/item?id=42619712 reply bryanrasmussen 2 hours agorootparentyes, that's it. Thanks. reply thayne 20 hours agoparentprevA GET request to `/users/delete?id=354` is dangerous. In particular, it is more vulnerable to a CSRF attack, since a form on another domain can just make a request to that endpoint, using the user's cookies. It's possible to protect against this using various techniques, but they all add some complexity. Also, the former is more semantically correct in terms of HTTP and REST. reply hnbad 10 hours agorootparentAn important consideration is also that browsers may prefetch GET requests. reply alexpetros 20 hours agoparentprevHey there, good question! Probably worth reading both sections 6 and 7 for context, but I answer this question specifically in section 7.2: https://alexanderpetros.com/triptych/form-http-methods#ad-ho... reply croemer 3 hours agoparentprevHTTP/1.1 spec, section 9.1.1 Safe Methods: > Implementors should be aware that the software represents the user in their interactions over the Internet, and should be careful to allow the user to be aware of any actions they might take which may have an unexpected significance to themselves or others. > In particular, the convention has been established that the GET and HEAD methods SHOULD NOT have the significance of taking an action other than retrieval. See the \"GET scenario\" section of https://owasp.org/www-community/attacks/csrf to learn why ignoring the HTTP spec can be dangerous. Or this blog post: https://knasmueller.net/why-using-http-get-for-delete-action... reply AndrewHampton 21 hours agoparentprevWhat HTTP method would you expect the second example to use? `GET /users/delete?id=354`? The first has the advantage of being a little clearer at the HTTP level with `DELETE /users/354`. reply mg 21 hours agorootparentGET because that is also the default for all other elements I think. form, a, img, iframe, video... Ok, but what is the advantage to be \"clear at the http level\"? reply necubi 21 hours agorootparentGET shouldn't be used for a delete action, because it's specified as a safe method[0], which means essentially read-only. On a practical level, clients (like browsers) are free to cache and retry GET requests, which could lead to deletes not occurring or occurring when not desired. [0] https://datatracker.ietf.org/doc/html/rfc7231#section-4.2.1 reply JimDabell 13 hours agorootparentprevThat means I can make you delete things by embedding that delete URL as the source of an image on a page you visit. GET is defined to be safe by HTTP. There have been decades of software development that have happened with the understanding that GETs can take place without user approval. To abuse GET for unsafe actions like deleting things is a huge problem. This has already happened before in big ways. 37Signals built a bunch of things this way and then the Google Web Accelerator came along, prefetching links, and their customers suffered data loss. When they were told they were abusing HTTP, they ignored it and tried to detect GWA instead of fixing their bug. Same thing happened again, more things deleted because GET was misused. GET is safe by definition. Don’t abuse it for unsafe actions. reply mg 12 hours agorootparentYou can already do POST requests by embedding forms and/or JS. And with the proposedyou could also embed that. So I don't see how the proposal of adding more HTTP methods to html elements prevents abuse. reply williamdclt 6 hours agorootparentI think you're misunderstanding what your parent meant by \"abuse\". In in this context it meant \"misuse\", there's no malicious actor involved. GET should have no side-effect which enables optimisation like prefetching or caching: they used it for an effectful operation (deletion) so prefetching caused a bug. It's the developers fault, for not respecting the guarantees expected from GET. If they'd used POST, everything would have been fine. There's much less of an argument for using `POST /whatever/delete` rather than `DELETE /whatever`. At this point it's a debate on whether REST is a good fit or not for the application. reply masklinn 7 hours agorootparentprevIt prevents \"required\" abuse of the HTTP protocol (having to pipeline everything via POST even though that's not its purpose), without the requirement of adding javascript to the page. reply lionkor 21 hours agorootparentprevWell, its correct, so its likely to be optimized correctly, to aid in debugging, to make testing easier and clearer, and generally just to be correct. Correctness is very rarely a bad goal to have. Also, of course, different methods have different rules, which you know as an SE. For example, PUT, UPDATE and DELETE have very different semantics in terms of repeatability of requests, for example. reply recursive 20 hours agorootparentprevGETs have no side effects, by specification. DELETEs can have side effects. reply recursivedoubts 21 hours agoparentprevimplied idempotence reply LegionMammal978 3 hours agorootparentI'd say deleting a user is pretty idempotent: deleting twice is the same as deleting once, as long as you aren't reusing IDs or something silly like that. It's more that GET requests shouldn't have major side effects in the first place. reply ttymck 21 hours agoprevLooks really pragmatic and I'd be glad to see this succeed. Is anyone able to credibly comment on the likelihood that these make it into the standard, and what the timeline might look like? reply recursivedoubts 21 hours agoparentAlex is working on it now and we have contacts in the browser teams. I’m optimistic but it will be a long term (decades) project. reply Devasta 19 hours agoprevIts genuinely incredible that we are more than 20 years since the takeover of HTML from the W3C and there isn't anything in the browser approaching even one tenth of the capability of XForms. I wish the people behind this initiative luck and hope they succeed but I don't think it'll go anywhere; the browser devs gave up on HTML years ago, JavaScript is the primary language of the web. reply andrewflnr 19 hours agoprev> giving buttons to ability Might want to fix that. :) reply tln 18 hours agoparentI haven't seen the proposal, but buttons can already set the form method (and action, and more). So I guess the \"Button HTTP Requests\" will just save the need to nest one tag? reply andrewflnr 16 hours agorootparentTo be clear, I was referring to the minor typo. reply jjcm 18 hours agorootparentprevThis proposal also includes the ability to update a target DOM element with the response from that delete action. reply netcraft 21 hours agoprevI love these. Its the things we've been doing (or attempting to do) with our web pages for decades. I've written tons of jquery to do these exact things, lots of react code as well. I think its an uphill battle, but I am hopeful. reply motoboi 21 hours agoprev [–] JSON rest api are just hypermedia rest api but with the data compressed. The compression format is json and the dictionary are the hypermedia relations previously passed in the client. It’s 2025, the client don’t need to be generic and able to surf and discover the internet like it’s 2005. The database is consumed via APIS distributed in two parts: first the client (a lib), second the data: json. reply recursivedoubts 21 hours agoparentNo, they aren’t. https://htmx.org/essays/how-did-rest-come-to-mean-the-opposi... Your client is already generic you just aren’t using that functionality: https://htmx.org/essays/hypermedia-clients/ reply colordrops 20 hours agorootparentMaybe just give up the ghost and use a new unambiguous term instead of REST. Devs aren't going to let go of their JSON apis as browsers often are not the only, or even main, consumers of said APIs. Creating frameworks and standards to support \"true\" RESTful APIs is a noble goal, but for most people it's a matter of semantics as they aren't going to change how they are doing things. A list of words that have changed meaning, sometimes even the opposite, of their original meaning: https://ideas.ted.com/20-words-that-once-meant-something-ver... It seems these two discussions should not be conflated: 1. What RESTful originally meant, and 2. The value of RESTful APIs and when they should and shouldn't be used. reply WorldMaker 3 hours agorootparentI think \"both sides\" right now are a bit wrong about the other. Content Negotiation is also an ancient part of REST. User Agent A prefers HTML and User Agent B prefers XML and User Agent C prefers JSON and all of those are still valid representations of a resource, and a good REST API can deliver some or all three as it has capability to do so. It's very much in the spirit of REST to provide HTML for your Browsers and JSON for your CLI apps and machine-to-machine calls. This shouldn't be a \"war\" between \"HTML is the original REST\" and \"JSON is what everyone means today by REST\", this should be a celebration together that if these proposals pass we can do both better together. Let User Agents negotiate their content better again. It's good for JSON APIs if the Browser User Agents \"catch up\" to more features of REST. The JSON APIs can sometimes better specialize in the things their User Agents need/prefer if they aren't also doing all the heavy lifting for Browsers, too. It's good for the HTML APIs if they can do more of what they were originally intended to do and rely on JS less. Servers get a little more complicated again, if they are doing more Content Negotiation, but they were always that complicated before, too. REST says \"resources\" it doesn't say what language those resources are described in and never has. REST means both HTML APIs and JSON APIs. (Also, XML APIs and ASN.1 APIs and Protobuf APIs and… There is no \"one true\" REST.) reply BlueTemplar 16 hours agorootparentprevIt's weird that you would argue \"people won't change\" at the same time as you point out how word meanings change. Have you forgotten how XML was all the rage not that long ago ? Also, specific people might not change, but they do retire/die, and new generations might have different opinions... reply quuxplusone 4 hours agorootparent> It's weird that you would argue \"people won't change\" at the same time as you point out how word meanings change. \"People won't change\" does not imply \"people don't change\"; \"I observe change\" does not imply \"I cause change.\" Dante's Paradiso XVII.37–42 (Hollander translation): \"Contingent things [...] are all depicted in the Eternal Sight, / yet are by that no more enjoined / than is a ship, moved downstream on a river's flow, / by the eyes that mirror it.\" > Also, specific people might not change, but they do retire/die, and new generations might have different opinions. Yes, that's certainly the case. \"Science advances one funeral at a time.\" https://en.wikipedia.org/wiki/Planck%27s_principle reply colordrops 13 hours agorootparentprevPeople change organically but people can't be easily changed inentionally. I'm not suggesting that going back to the original meaning is a bad thing, in fact more power to those who are attempting this. I'm just suggesting that instead of moving the mountain, they could just go around it. reply thatsafeature2 19 hours agorootparentprevRESTful is an oddly-specific term, so I don't see the point of changing the meaning. Feel free to change the meaning of 'agile' to mean 'whatever' (which is how it's interpreted by 99.99% of the population), but leave things like RESTful alone. Signed, CEO of htmx reply alexpetros 20 hours agoparentprevIt sounds like the client you're describing is less capable than the client of 2005, and I'd be curious to hear why you think that's a good thing. reply cryptonector 20 hours agorootparentThe problem with RESTful requiring hypermedia is that if you want to automate use of the API then you need to... define something like a schema -- a commitment to having specific links so that you don't have to scrape or require a human to automate use of such an API. Hypermedia is completely self-describing when you have human users involved but not when you don't have human users involved. If you insist on HATEOAS as the substrate of the API then you need to give us a schema language that we can use to automate things. Then you can have your hypermedia as part of the UI and the API. The alternative is to have hypermedia for the UI on the one hand, and separately JSON/whatever for the API on the other. But now you have all this code duplication. You can cure that code duplication by just using the API from JavaScript on the user-agent to render the UI from data, and now you're essentially using something like a schema but with hand-compiled codecs to render the UI from data. Even if you go with hypermedia, using that as your API is terribly inefficient in terms of bandwidth for bulk data, so devs invariably don't use HTML or XML or any hypermedia for bulk data. If you have a schema then you could \"compress\" (dehydrate) that data using something not too unlike FastInfoSet by essentially throwing away most of the hypermedia, and you can re-hydrate the hypermedia where you need it. So I think GP is not too far off. If we defined schemas for \"pages\" and used codecs generated or interpreted from those schemas then we could get something close to ideal: - compression (though the data might still be highly compressible with zlib/ zstd/brotli/whatever, naturally) - hypermedia - structured data with programmatic access methods (think XPath, JSONPath, etc.) The cost of this is: a) having to define a schema for every page, b) the user-agent having to GET the schema in order to \"hydrate\" or interpret the data. (a) is not a new cost, though a schema language understood by the user-agent is required, so we'd have to define such a language and start using it -- (a) is a migration cost. (b) is just part of implementing in the user-agent. This is not really all that crazy. After all XML namespaces and Schemas are already only referenced in each document, not in-lined. The insistence on purity (HTML, XHTML, XML) is not winning. Falling back on dehydration/hydration might be your best bet if you insist. Me, I'm pragmatic. I don't mind the hydration codec being written in JS and SPAs. I mean, I agree that it would be better if we didn't need that -- after all I use NoScript still, every day. But in the absence of a suitable schema language I don't really see how to avoid JS and SPAs. Users want speed and responsiveness, and devs want structured data instead of hypermedia -- they want structure, which hypermedia doesn't really give them. But I'd be ecstatic if we had such a schema language and lost all that JS. Then we could still have JS-less pages that are effectively SPAs if the pages wanted to incorporate re-hydrated content sent in response to a button that did a GET, say. reply recursivedoubts 19 hours agorootparentHATEOAS is for humans: https://intercoolerjs.org/2016/05/08/hatoeas-is-for-humans.h... reply cryptonector 19 hours agorootparentSPAs are for humans, but they let you have structured data. That's the problem here. People need APIs, which means not-for-humans, and so to find an efficient way to get \"pages\" for humans and APIs for not-humans they invented SPAs that transfer data in not-for-humans encodings and generate or render it from/to UIs for humans. And then the intransigent HATEOAS boosters come and tell you \"that's not RESTful!!\" \"you're misusing the term!!\", etc. Look at your response to my thoughtful comment: it's just a dismissive one-liner that helps no one and which implicitly says \"though shall have an end-point that deals in HTML and another that deals in JSON, and though shall have to duplicate effort\". It comes across as flippant -- as literally flipping the finger[0]. No wonder the devs ignore all this HATEOAS and REST purity. [0] There's no etymological link between \"flippant\" and \"flipping the finger\", but the meanings are similar enough. reply recursivedoubts 19 hours agorootparentYeah, that was too short a response, sorry I was bouncing around a lot in the thread. The essay I linked to somewhat agrees w/your general point, which is that hypermedia is (mostly) wasted on automated consumers of REST (in the original sense) APIs. I don't think it's a bad thing to split your hypermedia API and your JSON API: https://htmx.org/essays/splitting-your-apis/ (NB, some people recommend even splitting your JSON-for-app & JSON-for-integration APIs: https://max.engineer/server-informed-ui) I also don't think it's hard to avoid duplicating your effort, assuming you have a decent model layer: https://htmx.org/essays/mvc/ As far as efficiency goes, HTML is typically within spitting distance of JSON particularly if you have compression enabled: https://github.com/1cg/html-json-size-comparison And is also may be more efficient to generate because it isn't using reflection: https://github.com/1cg/html-json-speed-comparison (Those costs will typically be dwarfed by data store access anyway) So, all in all, I kind of agree with you on the pointlessness of REST purity when it comes to general purpose APIs, but disagree in that I think you can profitably split your application API (hypermedia) from your automation API (JSON) and get the best of both worlds, and not duplicate code too much if you have a proper model layer. Hope that's more useful. reply cryptonector 18 hours agorootparentThanks, I appreciate the detailed response. > So, all in all, I kind of agree with you on the pointlessness of REST purity when it comes to general purpose APIs, but disagree in that I think you can profitably split your application API (hypermedia) from your automation API (JSON) and get the best of both worlds, and not duplicate code too much if you have a proper model layer. I've yet to see what I proposed, so I've no idea how it would work out. Given the current state of the world I think devs will continue to write JS-dependent SPAs that use JSON APIs. Grandstanding about the meaning of REST is not going to change that. reply recursivedoubts 18 hours agorootparentI've built apps w/ hypermedia APIs & JSON APIs for automation, which is great because the JSON API can stay stable and not get dragged around by changes in your application. As far as the future, we'll see. htmx (and other hypermedia-oriented libraries, like unpoly, hotwire, data-star, etc) is getting some traction, but I think you are probably correct that fixed-format JSON APIs talking to react front-ends is going to be the most common approach for the foreseeable future. reply cryptonector 18 hours agorootparentIf you want JS-lesness and HATEOASnes then maybe if we had an automatic way to go from structured data to HTML... :) reply recursivedoubts 18 hours agorootparentmost structured-data to UI systems I have seen produce pretty bad, generic user interfaces the innovation of hypermedia was mixing presentation information w/control information (hypermedia controls) to produce a user interface (distributed control information, in the case of the web) i think that's an interesting and crucial aspect of the REST network architecture reply eadmund 16 hours agorootparentprev> I think you can profitably split your application API (hypermedia) from your automation API (JSON) Why split them? Just support multiple representations: HTML and JSON (and perhaps other, saner representations than JSON …) and just let content negotiation sort it all out. reply recursivedoubts 16 hours agorootparentI tend not to like content negotiation: https://htmx.org/essays/why-tend-not-to-use-content-negotiat... reply riwsky 18 hours agorootparentprev> The problem with RESTful requiring hypermedia is that if you want to automate use of the API then you need to... define something like a schema -- a commitment to having specific links so that you don't have to scrape or require a human to automate use of such an API We already have the schema language; it’s HTML. Stylesheets and favicons are two examples of specific links that are automatically interpreted by user-agents. Applications are free to use their own link rels. If your point is that changing the name of those rels could break automation that used them, in a way that wouldn’t break humans…then the same is true of JSON APIs as well. Like, the flaws you point out are legit—but they are properties of how devs are ab/using HTML, not the technology itself. reply cryptonector 12 hours agorootparentHTML is most decidedly not a schema language. reply alexpetros 19 hours agorootparentprev> The alternative is to have hypermedia for the UI on the one hand, and separately JSON/whatever for the API on the other. But now you have all this code duplication. What code duplication? If both these APIs use the same data fetching layer, there's no code duplication; if they don't, then it's because the JSON API and the Hypermedia UI have different requirements, and can be more efficiently implemented if they don't reuse each other's querying logic (usually the case). What you want is some universal way to write them both, and my general stance is that usually they have different requirements, and you'll end up writing so much on top of that universal layer that you might as well have just skipped it in the first place. reply cryptonector 18 hours agorootparentI've worked with a HATEOAS database application written in Ruby using Rails. It still managed to have HTML- and JSON-specific code. Its web UI was OK, but not as responsive as a SPA. reply deniz-a 19 hours agorootparentprevThe \"structured data with programmatic access methods\" sounds a lot like microformats2 (https://microformats.org/wiki/microformats2), which is being used quite successfully in the IndieWeb community to drive machine interactions with human websites. reply cryptonector 19 hours agoparentprev [–] > JSON rest api are just hypermedia rest api but with the data compressed. The compression format is json and the dictionary are the hypermedia relations previously passed in the client. Yes. > It’s 2025, the client don’t need to be generic and able to surf and discover the internet like it’s 2005. No. Where the client is a user-agent browser sort of application then it has to be generic. > The database is consumed via APIS distributed in two parts: first the client (a lib), second the data: json. Yes-ish. If instead of a hand-coded \"re-hydrator\" library you had a schema a schema whose metaschema is supported by the user-agent, then everything would be better because a) you'd have less code, b) need a lot less dev labor (because of (a), so I repeat myself), c) you get to have structured data APIs that also satisfy the HATEOAS concept. Idk if TFA will like or hate that, but hey. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Triptych Proposals by Alexander Petros and Carson Gross aim to improve HTML's ability to handle network requests by supporting additional HTTP methods like PUT, PATCH, and DELETE in forms.",
      "The proposals also include enabling buttons to make HTTP requests without forms and allowing partial page replacements, aligning HTML more closely with REST principles.",
      "These proposals were introduced at Big Sky Dev Con and are detailed in the Triptych Polyfill on GitHub, with ongoing updates to the fetch and navigation specifications to support these enhancements."
    ],
    "commentSummary": [
      "Alex Petros' Triptych Proposals seek to incorporate HTMX concepts into the HTML specification, enabling HTML to handle HTTP methods like PUT and DELETE.",
      "The proposal is receiving positive feedback from the Web Hypertext Application Technology Working Group (WHATWG), but its adoption by major browsers such as Chrome and Safari is still uncertain.",
      "The initiative aims to reduce JavaScript dependency by enhancing HTML's capabilities, contributing to the broader discussion on RESTful APIs and a hypermedia-driven web."
    ],
    "points": 232,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1736196754
  },
  {
    "id": 42624116,
    "title": "Tramway SDK – The Unholy Union Between Half-Life and Morrowind Engines",
    "originLink": "https://racenis.github.io/tram-sdk/why.html",
    "originBody": "Hello everyone, I would like to see if there is any interest in this little project that I have been working on for the past few years.Could be relevant, seeing the direction in which the mainstream game engines are going.I didn&#x27;t really like any of the already existing options, so I tried to make my own and it turned out to be easier than expected.It&#x27;s sort of like a low-budget Unreal&#x2F;Source, but with open-world streaming support and it is free and open source. Very old-school. But optimized for more modern hardware. Very fast too.Still not production ready, but it seems like it is mostly working.I want to finish a few larger projects with it to see what happens.Btw, the name is probably temporary.",
    "commentLink": "https://news.ycombinator.com/item?id=42624116",
    "commentBody": "Tramway SDK – The Unholy Union Between Half-Life and Morrowind Engines (racenis.github.io)227 points by racenis 2 hours agohidepastfavorite58 comments Hello everyone, I would like to see if there is any interest in this little project that I have been working on for the past few years. Could be relevant, seeing the direction in which the mainstream game engines are going. I didn't really like any of the already existing options, so I tried to make my own and it turned out to be easier than expected. It's sort of like a low-budget Unreal/Source, but with open-world streaming support and it is free and open source. Very old-school. But optimized for more modern hardware. Very fast too. Still not production ready, but it seems like it is mostly working. I want to finish a few larger projects with it to see what happens. Btw, the name is probably temporary. mlekoszek 37 minutes ago\"Some might say \"just get a better computer\". This is why getting a better computer is bad: 1. Affordance: A lot of people, especially from 3rd world countries are very poor and can't afford to buy hardware to run Turbobloat. 2. e-Waste: Producing computer chips is very bad on the environment. If modern software wasn't Turbobloated you would buy new hardware only when the previous hardware broke and wasn't repairable. 3. Not putting up with Turbobloat: Why spend money on another computer if you already have one that works perfectly fine? Just because of someone else's turbobloat? You could buy 1000 cans of Dr. Pepper instead.\" Took the words from my mouth. What a great project. Please keep posting your progress. reply lukan 24 minutes agoparent\"Screen resolutions from 320x200 to 800x600.\" Still, higher resolutions were not just invented because of Turbobloat. reply plussed_reader 6 minutes agorootparentBut also a convenient excuse to sell more ramm and disk space 'for the textures'. reply tsumnia 1 hour agoprev\"A thing should be a thing. It should not be a bunch of things pretending to be a single thing. With nodes you have to pretend that a collection of things is a single thing.\" Just want to say this line was great, very Terry Pratchett. Feels like something Sam Vimes would think during a particularly complex investigation. I love it and hope you keep it moving forward. Haven't gotten a chance to mess around with it, but I have some ideas for my AI projects that might be able to really utilize it. reply derefr 44 minutes agoparentThis quote is likely intended for people who've tried other solutions and disliked them, but as someone who's never used a game engine of any kind, I'd appreciate someone giving me an ELI5 of how \"nodes\" relate to \"pretending that collections of things are things.\" Is the problem here that using a nodal editor encourages/incentivizes you through its UX, to assign properties and relationships to e.g. a `Vector` of `Finger`s — but then you can't actually write code that makes the `Vector` do anything, because it is just a \"collection of things\" in the end, not its own \"type of thing\" that can have its own behavior? And does \"everything is an Entity, just write code\" mean that there's no UX layer that encourages `Vector` over just creating a Hand class that can hold your Fingers and give the hand itself its own state/behavior? Or, alternately, does that mean that rather than instantiating \"nodes\" that represent \"instances of a thing that are themselves still types to be further instantiated, but that are pre-wired to have specific values for static members, and specific types or objects [implicitly actually factories] for relationship members\" (which is... type currying, kind of?), you instead are expected to just subclass your Entity subclass to further refine it? reply tines 59 minutes agoparentprevIn isolation, isn't the quote prima facie so bad and so wrong though? We think of collections of things as single things constantly. A human is a collection of body parts, body parts are collections of chemicals, chemicals are collections of molecules, molecules are collections of atoms... and yet at each level we think of those collections as being single things. Not being able to do that is just... absurd. The project looks awesome though. reply CrimsonCape 9 minutes agorootparentAgreed. Type systems are nearly always \"temporal\" yet are too simply designed to address that. \"Temporal\" to mean that at any given slice of time during a running application all objects have a signature that matches a type. Yet most programming languages only allow compile-time analysis and \"runtime\" is treated as monolithic \"we can't know at this point anything about types\" reply rootnod3 2 hours agoprevI wholeheartedly agree with the turbo bloat problem. Machines are so much more powerful nowadays, but most programs feel actually slower than before. Very cool project. And the website design is A+ reply diggan 1 hour agoparentI don't understand the term \"turbobloat\", never heard it before (and I've made games), the author doesn't define it and a quick search returns the submission article on Kagi, while nothing relevant at all on Google. So, what does it mean? Just \"very bloated\"? Edit: Reading around on the website and seeing more terms like \"Hyperrealistic physics simulation\" makes me believe it just means \"very bloated\". reply adastra22 13 minutes agorootparentI don’t think it is a real word. “Turbo” means “very” or more accurately “extremely,” but is typically only used in a positive context, e.g. turbocharged. That makes the turbobloated neologism ironic and funny. reply pmichaud 57 minutes agorootparentprevI took it to mean \"increasingly bloated over time relative to hardware, phased in a funny, irreverent way.\" It's a vibe thing, not a definition thing. reply fidotron 2 hours agoprev> Most Unity games look like very bad, even with fancy shaders, normal mapping and other techniques. This seems to be an increasingly common point of view among those of a certain age. It is definitely the case that the art of a certain sort of texture mapping has been lost. The example I go back to is Ikaruga, where the backgrounds are simply way better than they have any right to be, especially a very simple forest effect early on. Some of the PS2 era train simulators also manage this. The problem is these all fall apart when you have a strong directional light source like the sun pointed at shiny objects, and the player moves around. If you want to do overcast environments with zero dynamic objects though you totally could bypass a lot of modern hacks. reply speeder 18 minutes agoparentYes. And the thing is, some modern games ARE overcast with no dynamic lights, and then go on to use Lumen of all things. This was the case with Silent Hill remake, and that thing runs very slowly, looks WORSE on PS5 Pro, the grass looks worse than in older games and so on. Seriously, the plot of Silent Hill was invented to justify optimization hacks, you have a permanent foggy space called \"fog space\" to make easier to manage objects on screen, and the remake instead stupidly waste a ton of processing trying to make some realistic (instead of supernatural looking) fog. reply robertlagrant 2 hours agoprevI replayed Half-life 2 recently and was struck, even without high-res texture packs, how amazing the game still looks today. reply gmueckl 1 hour agoparentI think this is because of how extremely cleverly they picked the art style for the game. You have a lot of diffuse surfaces for which prebaking the lighting just works. Overcast skies allow for diffuse ambient lighting rather than very directional lights, which force angle-dependent shading and sharp high contrast shadow outlines. And the overwhelming majority of glossy surfaces are not too shiny which also helps out a lot. All of these are believable choices in this run-down, occupied, extremely dystopian world. And the texturing with its muted color palette pulls it all together. reply royaltheartist 52 minutes agoparentprevThat's why I think really good art direction beats raw graphical power any day. Source was pretty impressive back in the day, but the bit that's stood the test of time is just how carefully considered the environments and models are. Valve really put their resources into detailing and maximizing the mileage they got out of their technical constraints, and it still looks cohesive and well-designed 20 years later reply robertlagrant 34 minutes agorootparentDefinitely. A hyper-talented team combining new physics-based gameplay, art style and rendering technology made something just amazing. reply gaudystead 26 minutes agoparentprevI just replayed Half Life 2 less than a week ago! I also caught myself thinking, \"the levels may not be as detail filled as modern games, but the artistic direction both in graphics and level design is better than many modern designers with bigger budgets.\" reply GrantMoyer 1 hour agoparentprevHalf-life 2 has received multiple updates to shading and level of detail since it was released, so it looks a little better than it did at release. Still, it was already a visually impressive game at release. reply prettyStandard 1 hour agoparentprevYou might enjoy \"Black Mesa\", HL1 remade with the HL2 engine. Played it during the pandemic. No Regrets. reply potato3732842 1 hour agoparentprevYeah, it was great. They really pulled out all the stops when it came to cinematic quality on that one. They also did a lot of second order things like marrying the scenes to the plot that a lot of games don't well or at all. reply gleenn 38 minutes agoprevIt only supports up to 800x600 resolution? For real? I know people like low res games and this is targeting old hardware but that is surprisingly low to me given the touting of how optimized this is. reply jonny_eh 5 minutes agoprev> Btw, the name is probably temporary It's announced, and the name is fine, so it'll stick :) reply divs1210 39 minutes agoprevNeat project! By the way, to see a great example of how a modern game can be made using the classic Half Life engine, look at the fan made game Half Life: Echoes [1]. It actually looks pretty decent, and the gameplay is top notch. [1] https://www.youtube.com/watch?v=fBQKi6vGX8U reply 0xEF 1 hour agoprev> This article will cover the usage of the framework for beginners who are either scared of C++ or just bad at it I'm in the latter camp and want to thank you for your \"Getting Started\" Page. The teapot appeared and I understood things I did not think I would understand. I do not have time to finish your tutorial at the moment (due to only having 30 whole minutes for lunch), but I want to, which says more about how entertaining and accessible it is than anything. reply TehCorwiz 2 hours agoprevDid anyone else find the Design Patterns page? It's a score board with a goal at 100%. I love this so much. reply humptybumpty 1 hour agoparentLinked from the home page: ”Design patterns used 82%. When all of the patterns get used, I will delete the project and rewrite it in Rust. With no OOP.” reply fidotron 1 hour agoparentprevI was looking for ages and still haven’t found this. reply prettyStandard 56 minutes agorootparentYou have to click on \"Enterprise Mode\" to find > Design Patterns Used > 82% reply gield 1 hour agorootparentprevhttps://racenis.github.io/tram-sdk/patterns.html reply fidotron 52 minutes agorootparentThanks! That is legitimately hilarious. This whole thing is like some massive appeal to pragmatism. reply bityard 14 minutes agoprevI don't know anything about game programming but I quite approve of your sense of humor. reply davikr 1 hour agoprevVery cool! There need to be more options for developers with lower-end boxes, for gamers with low-end hardware. Unreal Engine 5 is a lost cause nowadays without 64GB of RAM, Unity is a mess and there need to be more options than Godot. reply pmichaud 53 minutes agoprevThis looks really cool, great work. One thing I want to preregister though: I bet against the whole Entity subclass thing. 60% of the way through the first serious-business project, you're going to RUE THE DAY. I'll look forward to seeing what people do :) reply amlib 1 hour agoprevYou said it's compatible with hardware from 15 years ago, but one of the examples have the graphical complexity of half-life from about 25 years ago, could this engine be optimized further to run on hardware from that vintage or at least closer to? Would be pretty cool making games that can run on a Ryzen 9950x 32 thread monster but scale all the way down to a 1Ghz Pentium III and a Voodoo 3. reply racenis 59 minutes agoparentThe oldest computer that I have tried running this engine is a HP laptop from 2008, running a 32-bit version of Windows XP. It seemed to work fine, but I did have some issues with the Direct3D 9 renderer. The renderer works fine on other computers, so I have no idea if it's a driver bug (Intel tends to have buggy drivers) or if it's a bug on my part. The biggest problem with using old hardware is drivers. Older drivers will only work on older operating systems and it's difficult to find C++20 compilers that will work on them. reply CodeCompost 2 hours agoprevThis sounds pretty cool! I like the name too, I would keep it like that. reply rideontime 2 hours agoprevThis website rules. reply csh602 1 hour agoprevThe writeup, demos and proofs of concept, along with transparent roadmap/todos on the GitHub page are top notch. Great presentation. I definitely see myself trying this. This is evidence of a great moment in modern indie game dev: the power of fun and simple prototyping. reply andai 2 hours agoprevThis is really cool. You should organize a game jam for it. How is the wasm support? My main issue with Godot was large bundle sizes and slow load times. (GameMaker kicks its ass on both, but I never got the hang of it.) reply racenis 1 hour agoparentI would say that it is way too early for a game jam. The webassembly builds seem to work fine. A basic project would take up around 20MB and takes a couple of seconds to load in, so it's not great, but then again I haven't done any optimizations for this. reply whalesalad 2 hours agoprevJust wanna say the website aesthetic is legendary. Very on brand. reply lawlessone 2 hours agoparentmakes me feel like a kid again. reply golergka 26 minutes agoprev> When all of the patterns get used, I will delete the project and rewrite it in Rust. With no OOP. https://racenis.github.io/tram-sdk/patterns.html Love it. reply klibertp 20 minutes agoparentWoah, it's cutting it close - just 3-5 aren't used! The Rust port might be on the horizon :D reply pelagicAustral 2 hours agoprevCan this be used as an alternative to Hammer to develop HL maps/mods? reply amlib 1 hour agoparentIt showed trenchbroom being used to make maps and I don't think that can be used to develop goldsource maps, so most likely not. reply andrea76 1 hour agoprevCan it run on a MS-DOS machine with 640 KB of RAM? reply to-too-two 2 hours agoprevDamn this looks sweet! I’m gonna check this out. Cool project! reply Baguette5242 49 minutes agoprevDon't understand shit, but congrats on the website. Is this React 19 ? reply LordDragonfang 1 hour agoprev> But what if all that you really want to make is just a lowpoly horror roguelite deckbuilder simulator? Is this a reference to Inscryption? reply bnetd 44 minutes agoprevBased. reply jheriko 56 minutes agoprevGood. This is exactly what I've been complaining about for decades now... I also have my own engine although it needs some refurbishment. I've never quite found the time to polish it to a point where it can be sold. It also runs on tiny old devices, although if you limit yourself to desktop hardware, that means anything from the last 30 years or so. It also has a design that allows it to load enormous (i.e. universe scale) data by streaming with most often an unperceptable loading time... on the iPhone 4 in about 200ms you are in an interactive state which could be \"in game\". Unity and Unreal are top-tier garbage that don't deserve our money and time. The bigger practical reason to use them is that people have experience and the plugin and extension ecosystems are rich and filled with battle tested and useful stuff. bespoke big company engines are often terrible too. Starfield contains less real world data than my universe app, but somehow looks uglier and needs a modern PC to run at all. mine runs on an iPhone 4, looks nicer and puts you in the world in the first 200ms... you might think its not comparable but it absolutely is, all of the same techniques could be applied to get exactly the same quality of result with all their stacks and stacks of art and custom data - and they could have a richer bunch of real world data to go with it! reply desireco42 1 hour agoprevI love the retro aesthetic of your website - it perfectly matches the spirit of the project. The detailed documentation and transparent roadmap on GitHub are excellent. It's clear you've put a lot of thought and effort into making this accessible for developers. Great job on the presentation overall! reply 0xdeadbeefbabe 2 hours agoprevI like the name. It's the SDK that gives the name meaning anyway. reply 999900000999 2 hours agoprev [–] License? You've obviously put a lot of effort into this, but I'm always lost at how people publish something open source and forget to actually put a license on there. Since now it's technically closed source, hypothetically if you become a monk in the woods next week no one else can fork your code reply racenis 2 hours agoparentI just realized that I had forgotten to actually add the license file to this repository. Added it now. The license is MIT. Thanks for noticing. reply d_k_f 2 hours agoparentprev [–] An MIT license file was added (or edited) a minute ago in the repo :) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new free, open-source game engine is being developed, similar to popular engines like Unreal and Source, with support for open-world streaming. - The engine is optimized for modern hardware, offering high performance, but is not yet ready for production use. - The developer intends to complete several large projects using this engine, although the current name is likely temporary."
    ],
    "commentSummary": [
      "Tramway SDK is a project that merges the Half-Life and Morrowind game engines to create a low-budget, open-world streaming game engine that is free and open source. - Although optimized for modern hardware, Tramway SDK is not yet ready for production use, but it aims to reduce software bloat and environmental impact by supporting older hardware. - The project, licensed under MIT, is appreciated for its retro aesthetic and potential for indie game development, with the creator welcoming feedback and progress updates."
    ],
    "points": 227,
    "commentCount": 58,
    "retryCount": 0,
    "time": 1736266929
  },
  {
    "id": 42618625,
    "title": "Roman Empire's use of lead lowered IQ levels across Europe, study finds",
    "originLink": "https://www.theguardian.com/science/2025/jan/06/roman-empires-use-of-lead-lowered-iq-levels-across-europe-study-finds",
    "originBody": "View image in fullscreen Vulcan’s Forge by Diego Velázquez in 1630. Vulcan was the Roman god of fire and metalworking, which contributed with other industries to vast pollution in the Roman empire Photograph: Album/Alamy Science Roman Empire’s use of lead lowered IQ levels across Europe, study finds Widespread use of metal caused estimated 2- to 3-point drop in IQ for nearly 180 years of Pax Romana Ian Sample Mon 6 Jan 2025 17.04 EST Share Apart from sanitation, medicines, education, wine, public order, irrigation, roads, the fresh water system and public health, what did the Romans ever do for us? asks an exasperated Reg in Monty Python’s Life of Brian. One answer, according to a new study, is widespread cognitive decline across Europe, courtesy of the vast quantities of lead pollution churned out by the booming metals industry that shaped the empire. Researchers have said the massive expansion of mining and the processing of metal ores in particular caused airborne lead pollution to soar during the peak of the empire, leading to an estimated 2- to 3-point drop in IQ across the land. “It’s amazing that we were able to quantify atmospheric air pollution over Europe nearly 2,000 years ago and assess potential health impacts on the ancient Roman civilisation,” said Dr Joseph McConnell at the Desert Research Institute in Nevada. “Our findings demonstrate that anthropogenic emissions from industrial activities have resulted in widespread damage to human health for over two millennia, which is pretty profound in my view,” he added. Roman physicians were aware of the dangers of lead poisoning, but the metal was still widely used for water pipes and cooking pots and found its way into medicines, cosmetics and toys. The metal was also ingested on purpose after Romans discovered that lead-containing syrups helped to preserve and sweeten wine. While lead poisoning through contaminated food and wine were more likely to be concerns for the upper classes, the entire population would have inhaled airborne lead produced from the empire’s huge mines and smelting operations, with lead being a byproduct of silver and gold refineries. To track levels of airborne lead pollution back through Roman times, McConnell and an international team of researchers analysed ice cores drilled from the Arctic. The cores provided a timeline of atmospheric lead concentrations from 500BC to AD600. Writing in Proceedings of the National Academy of Sciences, the researchers describe how the ice cores revealed a sharp increase in lead pollution around 15BC after the rise of the Roman empire. The levels then remained high until the decline of the Pax Romana, a 200-year stretch of relative peace and prosperity that ended in AD180. Over the period, McConnell estimates that the empire released more than half a million tonnes of lead into the atmosphere. To work out what impact the pollution might have had, the scientists turned to atmospheric models to map how the lead would have spread across Europe. They then drew on modern studies to calculate how much of the neurotoxic metal would have built up in children and the impact it might have had on their IQ. On average, lead levels in children’s blood at the peak of the Roman empire could have risen 2.4 micrograms per decilitre, the researchers found, reducing their IQ by 2.5 to 3 points. When taking background lead into account, childhood blood levels may have reached about 3.5 micrograms per decilitre. By some estimates, the Roman empire amounted to more than 80 million people at its peak, meaning that about a quarter of the world’s population could have been exposed to the lead pollution generated by mining and smelting. The effects of lead poisoning can be so severe that scholars have debated whether it contributed to the fall of the empire. “A 2.5- to3-point reduction in IQ may not sound like much but it was across the entire population and would have persisted for the nearly 180 years of the Pax Romana,” McConnell said. “I leave it to epidemiologists, ancient historians, and archaeologists to determine if the levels of background atmospheric lead pollution and health impacts we have identified … were sufficient to change history.” While airborne lead pollution fell after the Roman empire, it rose again in the high middle ages and soared in the 20th century with the Industrial Revolution and the burning of fossil fuels, including leaded fuels for vehicles. A 2021 study by the Centers for Disease Control and Prevention in the US found blood levels in children aged one to five years fell from 15.2 to 0.83 micrograms per decilitre between the late 1970s and 2016 as leaded fuels were banned. Explore more on these topics Science History Research news Share Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=42618625",
    "commentBody": "Roman Empire's use of lead lowered IQ levels across Europe, study finds (theguardian.com)194 points by pseudolus 16 hours agohidepastfavorite145 comments peeters 14 hours ago> Roman Empire’s use of lead lowered IQ levels across Europe, study finds I'm not a fan of this phrasing. None of the findings had anything to do with measuring IQ levels in ancient Europe. They were about measuring historical levels of lead, which they then just plugged into modern models to presume some levels of cognitive effects. A study that was actually able to measure cognitive disparities and correlate them with measured levels of lead would have been extremely interesting, but this is not that. Everything other than the measurements of historical lead levels seems to be fluff. This would kind of be like saying \"massive asteroid strike 100m years ago lead to cataclysmic tsunami, study finds\" but then not showing any evidence of a tsunami, just evidence that it struck an ocean and the inference that that would have caused a tsunami. It might be a reasonable inference, it's just not as interesting as the title would make it seem. Edit: I should qualify, I'm not trying to say that \"they did the math\"-style papers don't have value, just that the phrasing in how they are presented matters to me. If the phrasing was more like \"Use of lead in Roman Empire would have lowered IQ levels across Europe, study finds\" I would have no issue with it. reply vasco 10 hours agoparentCould also happen that all the advances in hygiene and infrastructure and logistics during the Roman empire had a more positive impact on IQ than the negative effect of lead. Not starving while growing up does wonders for the brain. reply biggoodwolf 5 hours agorootparentWhat did the Romans ever do for us? reply BSDobelix 5 hours agorootparentI dont know who \"us\" is, but probably roads and writing? reply _philemon 2 hours agorootparentI think reference is in order... https://www.youtube.com/watch?v=Qc7HmhrgTuQ reply 52-6F-62 4 hours agorootparentprevThose aren't roman inventions… reply svrtknst 3 hours agorootparentRoman-built roads and the spread of Latin were tremendously important. Noone said they were invented by them. reply martin_a 4 hours agorootparentprevI mean, I guess the aqueduct was a nice thing?! reply kragen 5 hours agorootparentprevProbably not in the parts of Europe outside the Roman Empire and definitely not in the peoples that the Romans killed all of. reply bell-cot 9 hours agorootparentprevPlenty of people starved...just not (in their better centuries) the better-off Romans. For (presumed) IQ benefits, I'd focus more on the hygiene, and the relatively disease-free drinking water which all those lead pipes & lead-lined aqueducts provided. (Plus the sewers.) There were lots of nasty diseases you could catch by drinking the water in ancient cities. And at scale, \"lead lowered IQ\" isn't much different to \"unable to think well while ill\", to \"higher mortality makes education a poorer investment\". reply panick21_ 6 hours agorootparentThat a very reductive view. Data shows that during the Roman empire, people moved on mass from hill forts into the flatlands (presumably giving better acess to agroculture, trade and water). We also see far more material culture, and not just for rich people. Huge amount of just common consumer goods, and this even streches far beyond the borders of the empire itself. Population also increased during this time. reply mistrial9 2 hours agorootparent> Population also increased during this time you mean after the slaughters? reply panick21_ 18 minutes agorootparentYes, many places part of the empire for 100s, sometimes even 1000 years. And conquest is of course always bad. But that wasn't the point you were making. You were talking as if there was constant large scale starvation in Rome, and there for the most part wasn't. You point that only rich Roman elites didn't regularly starve isn't really true. And its certainty not true in comparison to other places in the ancient world. reply PeterHolzwarth 14 hours agoparentprevFully agree, @peeters - as I've mentioned elsewhere in these comments, there's a long-standing trend of trying to identify the one true cause of the fall of the Roman Empire. Each explanation falls short - it's just a complicated thing (and heck, the empire didn't really fall, it just shifted east.) reply hodgesrm 13 hours agorootparentOr as some wag once put it, the empire then continued to decline and fall for another 1000 years. reply gazchop 11 hours agorootparentprevInclined to agree with this. It didn't fall, just sort of withered into other cultural ideologies and empires. Some of it was also fucking bananas which didn't survive enlightenment. reply tankenmate 13 minutes agorootparentSomething a lot of people don't realise is that the last of the \"Roman\" states (that called themselves Roman) didn't cease until about 50 years before Columbus crossed the Atlantic (xref the fall of Constantinople). reply UltraSane 1 hour agoparentprevIt is perfectly reasonable to assume lead would affect people 2000 years ago the same way it does today. Human biology hasn't changed. reply SMP-UX 12 hours agoparentprevThis is one of the problems with modern academia. It's hard to extrapolate these things reply gazchop 11 hours agorootparentOh it's really easy to extrapolate stuff. But perhaps they shouldn't. A lot of papers I've seen recently have wild romantic extrapolations based on cherry picked correlations. Some of the social sciences are terrible at this. A former partner was a researcher in one of what I now consider to be less respectable fields and she would come up with a feely conclusion and fit the data to it and publish it. Wanted me to co-author one with her and do the statistical analysis. Told her I don't want to be on Retraction Watch. reply watwut 8 hours agorootparentprevThe guardian article is not academia. reply rat87 8 hours agoparentprevWould have implies they didn't use lead buy if they had it would have lowered IQs May have lowered IQs based on extrapolation and modern studies Might be a better way to put it reply peeters 1 hour agorootparentBoth are valid ways of using \"would have\", in this case I'm using it as the past tense of \"will have\". But I appreciate the ambiguity it creates. > We use \"would have\" as the past tense form of will have: >> I phoned at six o'clock. I knew he would have got home by then. Note the difference between this and: > I phoned at six o'clock. I knew he was home by then. Which implies first-hand knowledge of his location. The first only signals a logical conclusion. https://learnenglish.britishcouncil.org/grammar/english-gram... reply guerrilla 10 hours agoparentprev> models to presume some levels of cognitive effects. Not \"presume\", \"deduce\" or \"conclude\". reply curmudgeon22 15 hours agoprev> On average, lead levels in children’s blood at the peak of the Roman empire could have risen 2.4 micrograms per decilitre, the researchers found, reducing their IQ by 2.5 to 3 points. When taking background lead into account, childhood blood levels may have reached about 3.5 micrograms per decilitre. > A 2021 study by the Centers for Disease Control and Prevention in the US found blood levels in children aged one to five years fell from 15.2 to 0.83 micrograms per decilitre between the late 1970s and 2016 as leaded fuels were banned. reply rayiner 4 hours agoparentWow. We mock those stupid Romans for putting lead in their drinking water supply, but we literally vaporized it and had everyone inhale it for decades so it'd go straight to the bloodstream. reply 0_____0 3 hours agorootparentStill do :) all the GA piston planes flying above you are still running leaded fuel. reply cjrp 3 hours agorootparentThe majority, but not all - some run on UL91 or even \"mogas\" (unleaded fuel from the petrol station). reply 0_____0 2 hours agorootparentSome of the smaller airports in the Bay Area (HWD, RHV, SQL) have UL94 but not all (PAO, HAF, and the large ones SJC, SFO, OAK don't). Fuel from a petrol station off field doesn't do you a lot of good, and it really doesn't help if you're refueling en route. reply schiffern 1 hour agorootparentIncidentally, aerospace Youtuber Scott Manley just did an excellent deep dive on lead in aviation gas. https://www.youtube.com/watch?v=8zfIy17q9sE reply mistrial9 1 hour agorootparentprev> we literally vaporized it and had everyone inhale it for decades this is a massive scandal that has not been fully understood in public AFAIK. Extensive documentation of the false premise of leaded gasoline has been published, e.g. https://www.thenation.com/article/archive/secret-history-lea... reply nahnahno 13 hours agoparentprev2.5-3 micrograms per deciliter is nothing. Wouldn’t even come up as elevated by current childhood screening guidelines. I very much doubt 2-3 IQ point difference. reply cma 9 hours agorootparentThat's the average, so it would be much high the cities in the cities than rurally right? reply HeatrayEnjoyer 11 hours agorootparentprevI wouldn't call it nothing. Current regulation requires water supply at the tap to measurereducing their IQ by 2.5 to 3 points I seem to recall reading an article that observed that every time we do a study of the effect of lead exposure on IQ, it gets larger. IQs aren't changing much, but lead exposure is going down, and so we keep imputing the same IQ gaps to ever-smaller quantities of lead. reply trimethylpurine 14 hours agorootparentIQs aren't changing much Isn't IQ a comparative representation of one's standing within their contemporary age group? My understanding is that within a given group the median should be 100. So you won't see it change between groups. This is highly relevant when you're talking about different groups being exposed to different concentrations of lead. As an extreme example to make the point, if people born in 1970 were all exposed to high concentrations of lead and were all morons as a result, their median IQ is still 100. Then people born in 2000 are exposed to far less lead and are super smart, but their median IQ would still be 100. Points above or below 100 are merely a specification of how many fractions of a standard deviation above or below that median within the given age group a person's performance is measured to be. That said, even within a group, 2.5 - 3 points seems largely insignificant as an individual's score might vary more than this depending on which day of the week they took the test. It seems a big stretch to draw any scientific conclusion from such a small variance. reply somenameforme 12 hours agorootparentYou're right about how IQ is measured with 100 being the average and, generally, 15 points being a standard deviation. But numerous tests also record raw scores and these can be compared between generations. Scandiland and other places with compulsory conscription + IQ testing are the goldmine here. This is what led to the observation of the 'Flynn Effect' - the observation that IQ between generations was increasing, and later to its apparent reversal that generally started sometime around 1990 in the developed world. [1] That paper reports a later date, because it's about America in which studies on this topic lagged substantially behind Europe. It's not easily explained by things like immigration since it is also present (though less pronounced) even within families. The hypothesis I find most compelling is that IQ levels have \"naturally\" been declining for decades, but improvements in nutrition, education, etc were helping to offset, and even rise beyond, these declines. But as nutrition, education, etc reach the point of diminishing returns, the declines dominate. [1] - https://www.sciencedirect.com/science/article/pii/S016028962... reply Anotheroneagain 9 hours agorootparentThe explanation is that IQ measures the cerebellum, and the declining nutrition and increasing brain damage forces people to rely more on the cerebellum, the statistical engine, instead of abstract thinking. reply elcritch 6 hours agorootparentHmmm, I could imagine microplastics, PFAS, artificial dies, excessive and unhealthy amounts of sugar would all have a deleterious effect on IQ. Perhaps even specifically pre frontal cortex, etc. Though that goes against Europe hitting the decline earlier than the US which leads in sugars and unhealthy foods. reply Anotheroneagain 4 hours agorootparentThere is nothing wrong with sugar, people can't burn it, because the body needs lead to break it into pyruvate. Then you need arsenic to input that into the krebs cycle. The mitochondria need a wide assortment of metals (likely at least copper, arsenic, selenium, mercury, cadmium and possibly chromium) when you don't get those, your mitochondia begin to fail, and the tissues where they do turn into \"fat tissue\". I suspect they don't do the research for real, they do some kind of simulation, and write it was in mice. They do know the metal changes the protein, but they incorrectly claim that the version without it works, but in reality the one with it does. They could'n make such an error if they actually did the research for real. reply thaumasiotes 14 hours agorootparentprevYou're basically right about the relative nature of IQ scores, but you're wrong about the comparison being drawn. To impute the effect of lead, you look at a bunch of people, measure the amount of lead in their blood, measure their IQs, and see how much of a difference there is between people with a lot of lead and people with less or none. Modern poor people who live in crummy areas where there's still a little bit of lead are about as stupid, relative to the leadless elite, as poor people from decades past who lived in crummy areas which, at the time, had a lot more lead than they do now. It seems like a safe assumption that the effect of lead on people with negligible lead levels has stayed constant over the decades at indistinguishable-from-zero. But for lead to explain the gap between the lead-haves and the lead-have-nots, its effect must have increased dramatically over that same period. That gap hasn't changed. But lead levels have plummeted. reply Anotheroneagain 9 hours agorootparentThe elites have always been the highest in lead. Slaves etc. had none. reply thaumasiotes 2 hours agorootparentYou have a very different mental picture of America over \"decades past\" than most people do. reply Anotheroneagain 9 hours agorootparentprev>Then people born in 2000 are exposed to far less lead and are super smart, What do you base this on? reply SiempreViernes 8 hours agorootparentIt's clearly meant as a hypothetical example. reply lostmsu 12 hours agorootparentprevAFAIK, no, 100 IQ points at 25 and 18 or any other age are the same \"brain power\". reply guappa 12 hours agorootparentNot at all. There is different age groups. reply bpodgursky 13 hours agorootparentprevPeople are downvoting, but yes this is accurate. There are confounders between houses with lead and other demographics and contribute to the gap and aren't completely controlled — aspects of social class and low mobility that are hard to explicitly capture, it's all old housing. So as the lead level drops and the gap remains steady (increasingly dominated by the confounding factors), more and more IQ gap gets attributed to the small lead-level gap between those living in old housing with abated lead pipes + paint and new pipes + new paint. reply luxuryballs 15 hours agoparentprevnext [16 more] [flagged] SteveNuts 15 hours agorootparentWhy specifically call out fluoride? reply lolinder 15 hours agorootparentIt's a bit of a thing with a particular political persuasion in the US right now (RFK Jr has made his anti-fluoride position a big part of his deal for his future role as Secretary of Health and Human Services), and there was a report in the news recently that some see as backing up the claims against fluoride: https://www.latimes.com/science/story/2025-01-06/what-a-new-... It's not as conclusive a study as some people might claim, though: > For starters, 52 of the 74 studies were judged by the report authors to have a “high risk of bias.” That undermines the validity and reliability of their results. > Another issue is that most of the studies considered fluoride exposures far above the target level for the U.S. ... Only seven of the studies assessed children whose water contained less than 1.5 mg/L of fluoride. When they were considered on their own, there was no relationship between fluoride exposure and IQ. reply luxuryballs 4 hours agorootparentnothing to do with RFK or politics, I feel like people are missing the point here though, imagine Rome in 45 BC “why call out lead?” while Roberto F Kenedius has been spreading conspiracies about lead pipes being bad reply lolinder 1 hour agorootparentDoes your point have nothing to do with RFK, or is the point people are missing that RFK has been spreading conspiracy theories that might be real after all? I'm somewhat confused by the seeming contradiction. reply luxuryballs 7 minutes agorootparentnothing to do with RFK I was just piggybacking on the other comment mentioning him to further paint the original picture: history repeating itself, future culture trying to understand past culture by limited speculation, and future culture (being the present culture) that will eventually be the past culture and every present culture tends to think they understand things better than they actually do, so it’s fun to think of us talking about Rome and lead in water, and future culture talking about us and Fluoride in water, regardless of how accurate any of it is or related to “empire collapse”, funny to imagine there was someone back then saying claims about lead being possibly harmful are biased, whatever the personal motive was (ie, not wanting to believe they let their kids drink dangerous lead pipe water so they go out of their way to tell others that claims of lead being suspected to be dangerous are biased, which is itself a bias) kylebenzle 14 hours agorootparentprev> It's a bit of a thing with a particular political persuasion... That seems dismissive as hell, especially since the US is the odd man out here by choosing to medicate their water supply. You could have simply answered that both fluoride and lead seem to lower IQ so using either as an additive would be questionable. reply maest 14 hours agorootparent> the US is the odd man out here by choosing to medicate their water supply It is not: https://en.wikipedia.org/wiki/Water_fluoridation_by_country reply lolinder 14 hours agorootparentprev> You could have simply answered that both fluoride and lead seem to lower IQ so using either as an additive would be questionable. This would have inaccurately reflected my understanding of the science: the link between fluoride and IQ is far more tenuous than lead at this point. See the study in the link above. > That seems dismissive as hell, especially since the US is the odd man out here by choosing to medicate their water supply. It's not intended to be dismissive, it's the primary reason why someone would have fluoride and IQ on their mind at the moment. reply luxuryballs 4 hours agorootparentprev“Why specifically call out lead?” -Julius Caesar, 45 BC reply luxuryballs 4 hours agorootparentprevDidn’t studies come out connecting it to lower IQ? Places are pulling it or planning to pull it, nothing to do with RFK. reply cameronh90 14 hours agorootparentprevIt's an international Communist conspiracy to sap and impurify all of our precious bodily fluids. reply CyberDildonics 15 hours agorootparentprevLots of people across the world don't have fluoride in their water, you could compare populations right now. https://en.wikipedia.org/wiki/Water_fluoridation_by_country reply davorak 14 hours agorootparentI doubt you can do a clean comparison, likely too many confounding factors, at least to pull anything out easily. reply CyberDildonics 13 hours agorootparentIf someone thinks they can figure out 1500 years from now if the 'fall of the west' was because of fluoride, it's probably easier to look at the countries in the west that do and don't use it now. reply luxuryballs 4 hours agorootparentthat’s the joke, today we are like “huh… lead in water, IQ, fall of Rome!” and that was more than 1500 years ago I think reply PeterHolzwarth 15 hours agoprevI have no idea if this is true (and honestly can only barely remember the reference, which I read maybe a decade or two ago), but I believe I saw a comment that the interior of lead pipes eventually develop a \"calcified\" (don't know what else to call it) lining of the lead reacting to water, such that lead stops leeching into the water that passes through the pipes. I believe this came up when reading something about how the trend of traditional historicity has always been to identify the Big Major Cause of the fall of the Roman empire, but that each explanation ultimately falls short. The followup point made by this, of course, is two-fold: that \"falls\" are often very complex and multi-faceted; and that the Roman empire never really \"fell\" in the Gibbons sense - it just slowly evolved, and eventually shifted east, finally becoming self-consciously retro-classically Hellenized, and just morphed to something new and lasted another thousand years -- but never actually fell during that time. Anyone else have any thoughts or insight on the \"lead pipes eventually line themselves with something non-lead-like\" angle? reply WorkerBee28474 15 hours agoparentI haven't read it, but the book History of Toxicology and Environmental Health [0] would say that pipes were not a problem. Preparing food and wine in lead containers could have been a problem, but it wasn't until centuries after the Roman Empire \"fell\" that doctors even described the symptoms of lead poisoning. And to throw in another quote from a scholarly source, \"Water from the river Anio, which fed two of Rome's principal aqueducts, the Aqua Anio Vetus and Aqua Anio Novus, was particularly hard and conveyed high levels of dissolved calcium carbonate. Indeed, Frontinus complains in his treatise on the aqueducts of Rome, that \"the accumulation of deposit, which sometimes hardens into a crust, contracts the channel of the water\" (CXXII.1).\" [1] [0] https://www.sciencedirect.com/book/9780128153390/toxicology-... [1] https://penelope.uchicago.edu/encyclopaedia_romana/wine/lead... reply PeterHolzwarth 14 hours agorootparentI hope I can be forgiven for replying to myself, but at this timestamp, I've got three excellent replies affirming the \"lead pipes get gunked up and it stops being a notable problem\" concept. Thanks for the replies! Great stuff from all of you. reply matwood 5 hours agorootparentprev> would say that pipes were not a problem. You obviously would prefer non-lead pipes, but running the water for a period before using flushes out any lead if the pipes are in the house. Like you say in your comment, it's when water sits in a container like a wine vat where leeching has time to accumulate. reply PeterHolzwarth 14 hours agorootparentprevThat's a great reply, thanks, and seems to align with the \"pipes just get clogged up\" concept I read some time ago. reply timschmidt 15 hours agoparentprevIt's called mineralization, and happens so long as there are dissolved minerals in the water and PH is correct. Lead contamination happened in Flint, MI because additives to control the water PH were neglected to save cost, and slightly acidic water ate away at the mineralization layer in the pipes and began dissolving the lead again. reply AngryData 11 hours agorootparentI don't know if I would call Flint's water just \"slightly\" acidic. It was acidic enough for the Flint hospital to complain about their stainless steel sinks rusting, for local automotive plants to dig their own wells because it was destroying parts they were washing, and turned their entire water supply system into swiss cheese that had to be replaced. It might be slightly acidic compared to highly concentrated acids, but in terms of potable water it seems extremely corrosive. reply timschmidt 10 hours agorootparentOf course you are right, and no offense meant. I grew up in Flint, and have family there to this day. My intention was more to communicate that even small changes in water PH can affect this mineralization layer. What I rarely see talked about with regard to Flint's water supply is that Detroit was willing to give them water for free, which is documented, and the only explanation that makes sense as to why they weren't taken up on the offer is the state governor's cabinet connections to fracking and a pipeline intended to bring lakewater inland to facilitate fracking. They wanted the taxpayers of Flint to help foot the bill. See: http://banmichiganfracking.org/the-flint-water-connection-to... reply pea 14 hours agoparentprevYes, the piping in my parents’ house is all lead, but not worth replacing due to the above. It’s pretty common in old houses in Britain reply martinpw 13 hours agorootparentVery interesting. I recently found out the house I grew up in in the UK over 15+ years had lead pipes that were never replaced, and I always wondered why they were not replaced and if it had some cognitive impact. This lining effect likely explains the reason, and offers at least some reassurance. reply lostlogin 14 hours agorootparentprevIf the water PH changes, the value in replacing those pipes might become more apparent. reply adzm 12 hours agorootparentBut my sweet water! reply alexey-salmin 13 hours agorootparentprevI wonder how did you figure out this is the case, did you make any tests of the water? I can hardly imagine living in a house with lead pipes. I mean even if water if provably safe today, what if tomorrow PH shifts to acidity. reply f1shy 6 hours agoparentprevThere must be something, as I grew in a house with lead pipes, and while I will not disclose my IQ or that of my siblings, they are high. Or maybe we were lucky? Of course only anecdotical data. reply Ekaros 10 hours agoparentprevAlso when talking about downfall. I think it is also sensible question timeframe when these materials were first used. Was that during raise of empire or after it? As it feels wrong that something that had been used for generations during formation of empire would lead to downfall... reply userbinator 10 hours agoparentprevI have some late-19th-century books on plumbing that mention the same passivation layer, and so clearly it was known, along with some of the toxic effects of lead, back when it was widely used for plumbing (which I must also mention that the 'plumb' comes from 'plumbum' - Latin for lead.) reply Ferret7446 12 hours agoprevI can't help but be pedantic and point out that since IQ is normalized, their average IQ would be 100 whether or not they used lead. More philosophically, the condition of life is inherently susceptible to damage, so you practically have to draw the line at what level of damage you want to try and mitigate given the realities of the time. Do you want to be wrapped up, only breathing, eating, and drinking perfectly calibrated mixes of chemicals? reply xeonmc 4 hours agoparentWho are you, who are so wise in the Ways of Science? reply lifeisstillgood 12 hours agoprev> A 2021 study by the Centers for Disease Control and Prevention in the US found blood levels in children aged one to five years fell from 15.2 to 0.83 micrograms per decilitre between the late 1970s and 2016 as leaded fuels were banned. So if my generation had lead levels 3-4 X higher than Roman kids, does this explain the “Exams are getting easier” meme - that exams are staying the same, but kids really are getting smarter … ( also the hey exams were waaay harder in the Edwardian Era meme?) reply Anotheroneagain 9 hours agoparentExams are getting easier, because children are getting dumber, and wouldn't pass if they stayed the same. reply o999 6 hours agoprev> By some estimates, the Roman empire amounted to more than 80 million people at its peak, meaning that about a quarter of the world’s population could have been exposed to the lead pollution generated by mining and smelting. The effects of lead poisoning can be so severe that scholars have debated whether it contributed to the fall of the empire. I wonder what will happen to current empires from micro- and nano-plastics, PFAS, airpolution, as well as harmful yet popular habits like doomscrolling and games addictions. reply Over2Chars 3 hours agoprevHmm, the IQ test was invented hundreds of years after the Fall of Rome. This article correlates 100% with bad causal statements. Garum, anyone? reply leptoniscool 15 hours agoprevI wonder if future historians will see a similar drop after widespread use of plastic reply __MatrixMan__ 15 hours agoparentMaybe, but given that \"plastics\" are a broad category I'd expect that IQ would me a poor proxy for some of their effects. BPA for instance, is a xenoestrogen. I'm not sure what metric to watch for it, but it's probably not IQ. reply sebmellen 15 hours agorootparentAnogenital distance is likely the preferred measure. > Males with a short AGD (lower than the median around 52 mm (2 in)) have seven times the chance of being sub-fertile as those with a longer AGD. > Swan et al. report that the levels of phthalates associated with significant AGD reductions are found in approximately one-quarter of Americans tested by the Centers for Disease Control and Prevention (CDC) for phthalate body burdens. https://en.m.wikipedia.org/wiki/Anogenital_distance (warning on the header photos). reply __MatrixMan__ 15 hours agorootparentI was imagining something a bit more impactful (and easy to find in the data), because as far as that one goes, it's not clear why anyone should know or care. Maybe high school graduation rate (an inverse proxy to indicate bullying)? reply sebmellen 12 hours agorootparentObviously not as easy to screen for, but this is a very clear indicator of how strong the known adverse effects of plasticizers are. reply pseudolus 15 hours agoparentprevPerhaps not with respect to IQ but there’s a chance that future historians might correlate the use of plastics with increased rates of infertility. reply echelon 15 hours agorootparentPerhaps there is a link between plastics and ADHD [1]. [1] https://pmc.ncbi.nlm.nih.gov/articles/PMC8910189/ reply TomK32 7 hours agorootparentI find it interesting that the article you linked didn't mention the heritability of ADHD. In around 3/4ths[0] of cases ADHD is caused by genetics, which leaves plenty of space for other causes. [0] https://www.nature.com/articles/s41380-018-0070-0 reply User23 13 hours agorootparentprevNext do fluoride. That’s been “debunked” though right? reply Beijinger 15 hours agoparentprevhttps://senecaeffect.substack.com/p/are-plastics-killing-us reply TomK32 7 hours agorootparentOh gosh... \"insidious castration of all men\" and \"blurred gender roles\". Really? They have been blurry for all of homo sapiens existence, just think of the matriarchal societies that still exist today[0]. Gender dysphoria has been documented from individuals[1] for a long time, societies accepted a third gender since ancient time and even in the USA, the Cercle Hermaphroditos[2] was quite early to the party, being founded in 1895 (yes 130 years ago). I'm confident that plastic will go the way trees did: Unbothered for a long time until bacteria figured dead wood is just another food and put a stop to trees being fossilized as coal. Stop plastics, it's a good idea to do so for many reasons, but there's no need to drag gender roles and those stupid good old times into it. I much prefer spending time with my kid instead of slaving away 9-5 six days a week. [0] https://www.townandcountrymag.com/society/tradition/g2856528... [1] https://en.wikipedia.org/wiki/Kalonymus_ben_Kalonymus [2] https://en.wikipedia.org/wiki/Cercle_Hermaphroditos reply defrost 15 hours agoparentprevIt doesn't seem as if the principal researcher behind this result is a historian: https://www.dri.edu/directory/joe-mcconnell/ reply Mistletoe 15 hours agoparentprevHas plastic been linked to lower IQ? reply userbinator 10 hours agorootparentIf anything, the correlation might be the opposite --- look at plasticiser use in East Asian countries, for example. reply glitchc 15 hours agorootparentprevNot yet, I think the OP means it might in the future. reply deadlast2 5 hours agoprevWould love to see a similar study on fluoride in modern civilizations. reply BorgHunter 4 hours agoparentFluoride has two major differences that would complicate such a study: First, fluoride is a natural component of lots of drinking water (often at levels far higher than artificial fluoridation creates), while lead contamination in drinking water is rare and usually human-caused. Second, lead is known to be bad for one's health in any amount, while fluoride is only known to cause IQ drops above a certain dose. You might find this meta-analysis interesting: https://jamanetwork.com/journals/jamapediatrics/fullarticle/... Part of that conclusion (note that water fluoridation in the US is recommended to a level of 0.7 mg/L): > This systematic review and meta-analysis found inverse associations and a dose-response association between fluoride measurements in urine and drinking water and children’s IQ across the large multicountry epidemiological literature. There were limited data and uncertainty in the dose-response association between fluoride exposure and children’s IQ when fluoride exposure was estimated by drinking water alone at concentrations less than 1.5 mg/L. reply thinkingemote 11 hours agoprevOriginal paper https://www.pnas.org/doi/abs/10.1073/pnas.2419630121 ----- Note this isn't mainly about lead pipes: \"most significant... may have been through background air pollution from mining and smelting of silver and lead ores \" reply baud147258 10 hours agoparent> smelting of silver and lead ores The smelting of silver and lead is detectable via ice cores, I remember seeing a graph showing the height of Roman silver production was only matched in the 18th century https://en.wikipedia.org/wiki/Roman_economy#/media/File:Worl... reply SMP-UX 12 hours agoprevRoman lead pipes were not a significant factor on the health of humans back then... To the same extent as public sewers, bathing, hygiene rules etc. Rome had it a lot better than even some countries today. Yeah you still had to deal with infections and such which could have been deadly but time and medicine era that you were in you had way better health outcomes in Rome reply ashoeafoot 12 hours agoparentIts more about lead kettles in which a sweet whine/ sugary additive was boiled down? reply Symbiote 11 hours agoparentprevYou seem to have missed the third paragraph of the article. reply animal531 7 hours agoprevIs a 2-3 point IQ drop really that terrible? If we all suddenly went from 100% to 97% brain efficiency we wouldn't even notice. For example a bad night of sleep is surely worth 10 times as much. reply f1shy 6 hours agoparentOr even measurable reliably? What is the typical error bar for an IQ test? Also is only kind of estimation based on what is known today about lead... reply caymanjim 15 hours agoprevI find it hard to believe that atmospheric lead levels were higher in the ancient Roman Empire than since the Industrial Revolution. The amount of lead mined and smelted now is vastly more than it was then. Regardless of current safety measures, there were decades with none. And then we had leaded gasoline for a century. Everything in this article may be accurate, but that likely means we're all far worse off now. reply hunglee2 11 hours agoprevHeadline writers were the original click baiters - understandable to get opens but really harms the substance of the article, which is that increase in lead poisoning may have had debilitating impact on the Roman Empire. reply chrisbrandow 12 hours agoprevInterestingly this paper probably underestimates things since it is not evaluating food sources, such as lead sweetened wine commonly drunk by the elites. I suspect the effects were non trivial. reply cmrdporcupine 15 hours agoprevSimilarly, arsenical bronze (copper + arsenic) was common before tin started to be used, and I've often wondered how common arsenic poisoning was in the copper age / early bronze age. When we think of the nastiness of industry, it's often industrial 19th century Britain and so on, but some of these villages (often quite remote) back then were full on industrial sites with massive smelting operations and the entire population including children engaged in mining and smithing and then exporting. reply ahazred8ta 15 hours agoparent\"Did arsenic poisoning make gods limp?\" Apparently going lame was an occupational hazard. https://www.abc.net.au/science/articles/2015/03/31/4206279.h... It was common from 4000 BC to 2000 BC. Ötzi the iceman lived near a copper-arsenic forge site. https://en.wikipedia.org/wiki/Arsenical_bronze#Arsenical_bro... reply perihelions 14 hours agoparentprevThere's a new study that suggests, actually not so much: https://news.ycombinator.com/item?id=42513706 (\"Ancient copper industry in King Solomon's mines did not pollute environment\") - \"...We took hundreds of soil samples from both sites for chemical analyses, creating high-resolution maps of heavy metal presence in the region. We found that pollution levels at the Timna copper mining sites are extremely low and confined to the locations of the ancient smelting furnaces. [...] The new study contradicts a series of papers published since the 1990s about pollution caused allegedly by the ancient copper industry.\" reply cmrdporcupine 14 hours agorootparentInteresting. Thanks reply agumonkey 15 hours agoparentprevA repair guy taught me recently that up until the 40s cadmium was used as a layer on some metallic devices, then people realized it was toxic. Funny. reply userbinator 10 hours agorootparentStill widely used in military/aerospace. https://en.wikipedia.org/wiki/Plating#Cadmium_plating reply iSnow 9 hours agorootparentprevAlso in pigments. There still has to be lots and lots of old devices, paint in houses, glass ware etc. around that derive their color from Cadmium. https://en.wikipedia.org/wiki/Cadmium_pigments reply cmrdporcupine 15 hours agorootparentprevI mean, I can do better (worse). Up until .. the 60s? 70s? They used to literally spray lead-arsenate on apple orchards as a pesticide. Incredibly effective one, too. Just that unfortunate thing of poisoning the top soil forever. A lot of those old apple orchards have had other things done with them since. Which is kind of scary. https://en.wikipedia.org/wiki/Lead_hydrogen_arsenate \"US EPA banned use of lead arsenate on food crops in 1988.\" reply davidgay 15 hours agoparentprevRe arsenic poisoning: https://en.wikipedia.org/wiki/Hephaestus#:~:text=In%20the%20.... reply eru 14 hours agoparentprevYes, 19th century Britain was already well on its way out of the nastiness. And the first industrial revolution was already over. reply AngryData 11 hours agorootparentI don't know much about Britain's historical usage of bronze alloys, but I would be surprised if Britain used all that much arsenic bronze at all because Cornwall has some of of the largest and oldest tin mines in the world. But of course mining and metal processing in general has tons of nasty things besides just arsenic. reply thrance 8 hours agoprevIsn't the average IQ of a population supposed to remain at a 100? Also pretty sure the Romans didn't measure IQ. Anyway, I'm really tired of those \"Stupid claim, study finds\". reply ddgflorida 4 hours agoprevSkeptical reply wumeow 15 hours agoprevLead contamination is still fairly widespread: carrots, sweet potatoes, chocolate, spices. It’s a good idea to get your blood tested and try to find any sources of exposure if your levels are high. reply jaybrendansmith 14 hours agoparentAs a child born in 1970 that loved the smell of gasoline, I really wish I could test how many IQ points I lost. I tell my kids it must be at least 15, because they are much smarter than me! reply hnburnsy 15 hours agoprevWait until you hear about leaded gas! reply justlikereddit 12 hours agoprevNow do the same study for smartphone abuse and third world immigration reply Anotheroneagain 9 hours agoprevRome fell after they stopped using lead. There is no evidence whatsoever that lead was widely known to be toxic, until a group of conspirationists took over the academia. In fact such a belief couldn't have been widespread. The historical quotes appear to be fabricated. In fact it's essential. Roman sewers and sanitation quickly flushed it down the drain, by 235 it was in chaos, long distance trade was no longer possible and a thousand years long dark age ensued. The original depletion happened deep in prehistory, the most major event happening around 26kya. Also by ice cores, substantiated by geological changes and mammoth skeletons. reply panick21_ 6 hours agoparentWow, somebody is still repeating 60 historical stuff. reply friend_Fernando 15 hours agoprevI suspect a similarly ugly reality is what happened in Cambodia after Pol Pot's genocide. It's done very poorly compared to its neighbors. reply anovikov 12 hours agoprev…and that brought us Christianity reply gazchop 11 hours agoparentAthena was much cooler. reply coderwolf 7 hours agoprevIs IQ really that important? I mean, if your goal is to get from point A to point B, having a fast car just means you go there faster. I'm thinking of IQ in a similar way, as in - high IQ = faster car. But at the end of the day, it's still the same, isn't it? Please correct me if I'm wrong. reply The_Colonel 7 hours agoparentIf you have IQ 50, it's not just that you do things slower than other people, you can't do many things at all. reply peterfirefly 6 hours agorootparentEven worse: if you have an IQ of 100, there are lots of things you just can't do. And if you have an IQ of 120? Still lots of things you just can't do. Same with 140. And it doesn't even stop there. reply whatsupdog 7 hours agoparentprevYes it matters. Faster car can run more miles in a day. More IQ can do more work. reply siva7 7 hours agorootparentUnfortunately for that we have computers so we don't need high IQ to do more work like calculations but higher quality work (which also depends on what kind of work you're doing) and that is oftentimes not primarily related to high IQ (think of creative work) reply jjk166 43 minutes agorootparentIQ measures reasoning capability, not speed of mental calculations. reply starspangled 6 hours agorootparentprevIs that really true? That IQ is often not related to capacity to do valuable intellectual work in the modern world? reply imdsm 7 hours agoprev [–] I wrote about this last year and everyone here picked on me calling my article AI generated, so I shut down my curiosity blog. reply Pigalowda 4 hours agoparent [–] Womp womp reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study indicates that the Roman Empire's use of lead in metalworking caused a 2- to 3-point drop in IQ across Europe during the Pax Romana.",
      "Researchers used Arctic ice cores to track lead pollution from 500BC to AD600, showing a significant increase during the Roman Empire's peak.",
      "The study suggests that widespread lead exposure may have contributed to the decline of the Roman Empire, with pollution levels decreasing post-Roman era but rising again during the Industrial Revolution."
    ],
    "commentSummary": [
      "A study indicates that the Roman Empire's use of lead could have reduced IQ levels in Europe, though this is based on historical lead levels and modern models rather than direct ancient IQ measurements.",
      "There is debate over whether the advantages of Roman infrastructure might have surpassed the detrimental effects of lead exposure.",
      "The study also explores the potential effects of contemporary substances, such as fluoride and plastics, on IQ, emphasizing the complexity of assessing historical health impacts from indirect evidence."
    ],
    "points": 194,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1736218095
  },
  {
    "id": 42623144,
    "title": "Federal Reserve Bank of NY \"Doomsday Book\" 2022 via FOIA [pdf]",
    "originLink": "https://www.crisesnotes.com/content/files/2023/12/NYFRB-2006.--Doomsday-Book--Searchable.pdf",
    "originBody": "%PDF-1.5%����376 0 obj>endobj xref376 120000000017 00000 n0000000712 00000 n0000001251 00000 n0000001463 00000 n0000151860 00000 n0000152023 00000 n0000152251 00000 n0000152544 00000 n0000152756 00000 n0000153277 00000 n0000153581 00000 n0000000771 00000 ntrailer]>>startxref0%%EOF 377 0 obj>endobj387 0 obj>streamx�c```\u0006\"f\u0010���A�\u0001\u0001�\u0018@�,\f\u001c\u0007\u0018H\u0002��������\u0013�i�k�Y�V]�ܺ\\�i���p���\u0005L�\u000b.�,^�[[���Ԙ#\u001d%I�֔|z}�PB��Oq��v�7!�':�y������^x�X��ߊX+�o�^� �\u000eqO;d��h�#����yn��� K�Ml\u0007x#��\f\u0018\u0018�s��&\u001e1��^�^���e�(\u0003�( -\u0011�\u0002��h&ƒ��'\u001430,\u0006\u0016�> /Font > >>/Contents 386 0 R/Parent 368 0 R/Rotate 0/CropBox [ 0 0 612 792 ]>>endobj379 0 obj>>>streamx���\u0001\u0001�����\b \u0018����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����=kSQ\u0018\u0007��'p����\u0001��K\u0012_�\u0006�\u000e.]\u001ap\u0010�\u0003\u000eB\u0016��d�:� b�������S�\u0014\fDp06��\u001a�\u000f�?9\\o�=9�7U+���&����OH��+�z�l]\u0018\u001b�w�υð���Ӛc�~��h4��\u000e\u0006��D3��t>)��L8�\u001a�ڞ�뽇�� \u0011��6#\u0006ܳ$���VN~�a��H�B�\f��2\u001b^�G/��_�S�}�\u0019�Ü��{2\u000fyz���%[�\\\u0015�\u000b�\u000bZ�A��@�h���\u001c\u001f�EDDDD���1��9���9}�\u0016\u0007E�\"p����b[ g+����J;�>/BA�\bNseeeo��`N߽{76�~�����\b�g�������36ۚ��rq�\u0018=z4^��EA]z��!\u000e�\u001c\u001b-�h�Z'/�'� �~�\u0006 �H|.�\u000b:~��\u0017b������>b���+�[b޼yC\u0005ʹ��\u0016����).\u0016\u0003\u0006\f�Nt%C�nmmmO�0���B����P��X����ĉ\u0013�i�U0� F�z�U���\u0019�\u0006�(�p�s�H�$* �D�ٳ�~�F�T ��+^\u0014&`�,�Ϗ\u001d;�\u0012q�H����aÆk��v��#֮];Z���S���\u0013���҂S��\f��6\u0011U\u000bp��\u001aUUU߈�0�lݺ\u0015�&�\u001f���V�^���-l2�W�m�ȑ\u001f���\u000b�0�lPwa�\u001b\u001b7n�I��p���V�z�\u0016��e�\u0016܈�i;;;1=!\u001b6X��0S���Ց�g���㑍\u001a�E�d2X��\u000b֝0q��(�wĲe˰d�\u0003̩��4�o�$���\u0005:Ǥ\u0017�^W>�U�;w.\u0015� k\u001aM����ۓ3A�!\f�\u0017/�s\u0003D���Z���R��ʶm�\u001e\u0016���?\u001b\u001a\u001a�\u0012�\u0003���'\u0016.\\��\u000e�\\��\u0015��Tq��ͼ+�\u000b�+�Z�'k)�&�R�ٳg�\u0019#�a��p�\u001d1�¸�����\u0011x������o� \"��$��P\u0002�?�\u0005 |��\u0005 ��N�%p\u0004�\"���/v�\\���{�ٳ�͂U>�1�\\`\u0016�\f�\u001bh�iӦ��y�$v~�\u0018�3M\u0011� k\u001a�#��\u001f\u0005��q��\u0015t�\bn :��\u000f������A\u0013��Ě\u001c�\u0007 �\u0002\u0013Ǻ:c@������\u0007cgrH����\u0001g\u0001kD�90��$\"��b�@�\u001bM\u0003�&��\u0004C+V�K�\u0016T\u0001����mMC,o\u0015 ��\u0018�`��S��8�畣G�bHG�F�\u001a� ��\u0018MMMa��\u0001��v�2��3g\u0006�C��!\u001bS\u0017�̩�-1��ʌ��\u0018Bb�#M\u0011\\\u00052q�DD�����$��\u0012�\u000ew��&IKKKO������i*Y\u0004����\u0016���e��T� �؄���e�� ؠ����\u0012���$�{�,U5剞)��G�\u001ca�F��u�޽�`�\u0012v/V�₆��SX�hErV\u001b���\u0011k�_��8��8��8N6��p7GIp7��9���9R�n������8���n�Bq7��9\u001c�q\u001c�q\u001cǹ��ӊ����cŊ\u0015 I����1��\u0005y�8&���NRi�\u001cXZ&L��(�E\\�\u001a�b��:p�@r�&a��i�\u00183f\f��\u0017T\u0001�kƧc�0\u000b IΜ9C�� �\u0015 Ouuu8�ƺ9�\u000b=��3�9s jZ\u0002�d����6�\\��=�$E`+�\u00131��bߝ��b9!F�\u0018\u0011��F��0Gd�B]]]A�\u0001X(��ˑ�~��}\"r=���Xtm>�)�x\\V�4�}�\u0018:t(��R�\u0002�\f�\u00077G��!�>��E ��\u0005� h��'6�\\&D��`\u001aV+\u001e~V�-\b_0\u001e �\u0005at\f�#i�J����2➥l`\u0014\u0013����*�\u001c6\u0007#\u0012��RŃ��ʕ+q�\u00057G������ '(\u0016�Fܝ�l�\u0005���H]��%��\"uVmĀ�0���\\��y3!@\u0010F����\u0017T\u0001�h\u0011��X�\u0006�&���=�V\u0016\u0001�J\u0012\u0017�_a���}��/���=H5W\u0010�I��T��b��\u0004B�\u0014�(W�X\b_\u0010�J�`�E�(�N\u0005�� Z(��R\u0010 $\bB \b�\b!6\"IT�\u00113��\f˽��ٽ�\u0017��T\"{�Ϟߝ����'''�M�\u0017\u0017\u0017x�aE�\u0016g~C0J1�?��\u0016ǟ��\u000f\u000f\u000f�\u0004�kI�#�3s\u0016�����hzF����P\u000b2[�*\u0015=�N��\u0017I\u0002��xF+++��o\u0003�%�r}}�\u001b���ԍ\u001b���٩�n�T�C 1/��1$;::�6\u001eo#���\u001e)�����2S}ooo9C5U���F����k\"�%g-��\u0017�%�˫. k�a\u001e48ɚm�����8��8��*pOm�9���\b?�\u0001�Y��9`yy\u0019\u000b��F�d\u000e>�����A�����\u0002��9\u0004�\u0002`bJ�He\u000ej\u001a�98�'���8�\u0004E���,--a�$}�\b��t�5��\u001c����\u001cX�\u0013e\u000e���k�+\u0018Boo�C���U���5�/�#��_\u0001\\snS(2D�y`pp\u0010�ꉵ(!s�ck�\u001a�&\u00123j�90�|\u001dh~\u0018\u0001�Rq�\u00173��h�A�Ѡ?�*-g\u0012$3�^ˬE�%V0��I��-0\u0014( \u001d�v\u0012e\u000e\u0019\u0017\u001f\u0006�I��4Y�x\u000f���U\u0012\u0007nm�H��z���@�\u001e���^����T��A'����\u0010�#��!\\���\b�E�\\\\\\|7���u�oН�\b:/vvv���\u0013�=\u0018�}B�� C���$s\u00101�h��EoBѱ%/���[A�\u0003[2y-��Lw�Ph�}�)\u000e���\u0004\\����V{\u0013h\u001e��젃MMM�\u001f�8;;�t�fF\u0016#���\u0015\u0018�W\u000b9\u00120m$L2���Y�Y&4����+J��qssÎ��x{{;=\u0017�q\u001c�q\u001c�q^'.s��\u001c\u0015q��e\u000e�9\u0014�9Z�2��\u001co �9\\�(��\u001c.s8��8��8������!�\u0019H�͖�9$q�\u0007�sY�\u0003�ۓ \u001d�VJ����@b\u0001��\u001cgH��$s�\u001eP\u0003;������e\u000e:COO\u000f^\u0017x�\u001a�\u0004{o���\\����-�����: =���m���\u001bOG�|�2\u0007\u0010补��\u000e��N��qg>\u0018F�v)F>nx����\u0012����iff�Ŏ\u0005Bz˯��B2F�Ek\u0014\u0018����nzeM2���\u0015��\u000f�壀�`���Nxxx�����q\u001c�q\u001c�q\u001c�y6������)Ɠ�,L2\u0007_���.w����!d�\u001e���t�\u000e�C~�\"s�m+�-!���昞��}�`����\u0017qb��8�\u0002��b��s��:���|MW�(76�˔9&&&r\u001fF>P�\u001b}C��ێͱ���'���QC0�i�z����uSi�0�\u001c�,BWX32�� \u00166 *U&�-g�\u0013��Ak�Z�w�t��kq��\u0019P�Yk\u001d\u0015�̱���]�tv�H�9���9B�aM\u001a\u0002q�Đi@�Jl�4 =P;���|��\u0001�Cʼ\u0015�>�\u0001�5�\u0011�pQ\"Dg`�\u000f�\u0003�\u0010�\u0013w\u001c�q\u001c�q\u001c��2G\u0003.sXq��e�Ҹ̑�e\u000e�9�q�#=)�9�]�h\u0007.s�S��\u0007���Mh]E\u0014�%\u0015�e�)�\u000b51\u000b\u000b/4X�\u000b!��IH\u0016\u0012ȫ\b*\u0018�E��\u0011]HS��\bB\u0016��t#EcRMl��B*d��bZtᢶ$\u0012��R�GK\u0017�p~�p;��{_���j_��q��ܙ�9�~\\�p\u001c�q\u001c�q\u001cg�H�9Ν;��\u0018���A�0���T��mx}b�\u001d���]d�\u0016\u0015�9���\u0002���%%c\u000e�Ӫ��\u0017��Ç�;�H%U�h�jV� 5�Y6׫��Q%\u0006`������ ?��H���'VVV�\u0014\u0004�2ǿ\u001e�#�iէ��\u0012cٌP����47\u0002�h�ĉ\u0013�&�\u0011ǃe�uvv����\u001c&����aΩ���Z��-y\u001d�Jj&�.]B�\b\u0006E\u0016�e\u000e\u001a��\\H�\u001d:fH\u000bc��;Hy�� ^\u0007\u001f���1z#OC��\u000fJ�P7�'4�\f�r��e�I\u000eUy�ɳ\u0004�j\u0015�M\u001c�ɘ�G \u0016~\u000b�4>>����\u0011��\u000bK;Y�d?3\u0013%s�����l��\u0012[�T��s8w��yQa�Qp��8��8��8�\u0003��\u001c\u0001.sd�e�{.s���\u0018�9��2��\u001c.s���2��\u001c.s8��8��8��*\bA.� �\u0015�8Ξ=����]����\"{�� i#�� ���\u0002^\u0014.\\�@\u0005���?��P����\u001c-z^��\u0018�\u0006\u001c�d�9�G�7�\u001e\bv�۷og��d�d�����y\u0005]I\u001a��ҫ\u001c9r�7%���\u001c�EM� ��c\u0010�(�������D\u0015W\u000fj\u0017����Y~�\u0003�\u0014A���NNN\u0016,K ��y�`{�\u001f�9J������X�lG��&o�d\f�|�w�9�\u0002#]� �sE��g�[���ו�\"~T���\u0018\u0005�J�/\u0019}}}8Չ \bn s`g���\u0003q]���\u0018,4dff���X�b\u001fZR�0��m%Hy��5�\u0014\f��\u0018kRl��iPo\f�\u0018�$+*�\u0012$�x��CʗJ��\f�\u0018�\u00066��ބ)��[T\u001e\u0019�o*EJ́L��\u0017ց�\u0014�\b���O)R=t�\u0016z/�ӎ�^\u001c������(E��\u001b�\u001bq9�D��\f\u0005�V� 2K#=�9�ó�g��D剦��\u0017�Oc��!�JŒN����2j�\u0012Ge�\u001c�d�*�taa�4r�ԩ|�\u00039�`�\u001f��\u0003N�DA�c�w�����\u001d�q\u001c�q\u001c�y� ns�]��\u0012G��\u001dwww#\u0016�Ǒ�y\u000e��6S\u0014�\u0016��.X��_1|Q\\>���m\u000e\f�fcC��R�ղ�\u0010����Fk2&\b�3\u001f=z4��a�90;���rV�0\u0010�\u0007�Z��hhh�k%��F`B���7o�#\u0016�cǎ�@�U^}�\u0006\u0006�/ns�a����\u00144�˗/?���/����A&��\u001c\u0007w�Hm�Ͱ��۷/*�D���54J�\u0001\u0019S\u0007\u0013�+�w,]ׯ_���\u0010�;\b�j{\u0016��l�i�b֕,9\u0004�9X�\b?+�t�� �I�)#\u000b!>��\u0018��`�c�`W��B'O�,\u001e��q\u001c�q\u001c�q�\u0007 �9\u0002\\�Ȏ�\u001c�\\�p��).s4�e\u000e�9\\�p��e\u000e�9\\�p�=�/���=HlG\u0014�K��UI�0\u0010\u0004-�A,��3u\u0014��U\u0002� �%\u0004\u000b�tB,R\u0018H�Ɛ\u0010�Y��QD�&��F! HЀ`�jӄ JPs8?�p�ܻ�w��X/����1�,�R\"e\u000e�&&${\u001a~WZ'̋�R|���N\u000ed\u000e��b_C�^O\u001e\u001be�;8�r��v||��!����R�T�,�\u0016\u001cWUʵ�B�\u001c8\u0012gff�e�����.�,p=*�ݴ�������\u001bJL�\u0001�П�����e2ߢ\u0007��ۑ)s|��\u000b�{as��9�1\u0003?$�t\u0016��\u001dA��r���\f��Z�V�Q�6\u00076\u0013CZ��ROfჃ��n������n��=�~n\u001f-�\u0006� 0�ggg��\u001e������������������8���Q,\u000f3�i�V\u0018�F� �U��h'G���@���trffƒe\b�E���\u001c������������Raӷ��|�ՙ��3��6��|�T��� w��lkv>���\u0003��\u001f)\u0005%y�\u001fc�5\u000b�`�g,s��̗\u000b\u0015���\u0013\u000b�i�疤C���ȭe���f�8pT����n>^���\u001d�\u0001i�\\��\u000b���?QL搦c\\��VV��J�b \u0005\u000fC���K���%�@�\u001c�\u000fJ sD�X8d��K\u000b\u001f(��&s��\u0017[[[L����Q�\u001cW.;;;�+�x_P�P�\\9`qq1�9���k\u0011�I��+����Ev���!? �UgI��1\u0016\u000b&�6\u0014)�\u0012\u0007���?׉\u0017�.`ȟ��\u0018Y32F��*���8x-� \u001bY5�\u0003�|L1��m%�9����Ƈcww7��ܡd9�\u000e�\u000bbσ�U777o*,`��\u0010ӊ��\f�aʲ_R���\u0002�f�\u000e�e����\"3æl!˘� 2��z�\u0012`2��A�̄\u0012 ;\b\u001dHʿf`Q̓��%\u001a[�*\u001cud��\u000e_jE��φ��\u001c{{{�/����\u001d��mR\u0014����lg\u0004�B�\u0010*�ӭV��c�C������\"�X�v��FI\u001d;��\u0002�#75�\u001cP�a\u001e��ڮ�8��8��8�\u0001�9�e�\u0018\\���e\u000e�9\"q�#��\u001c����2��\u001c.s\u0014�2��\u001c��8��8Nȿ���_H�e\u0014�M�c�#\b�\u001a\u0013Q�f0�0��AZh(KFk��� ��F��\"D�\u0010�%\u0012֠nF��\u001a\u0018\u001b�\u000b��\u001f�A\u0003�t�\f�F�.��1��\u000e��wx|���{��s]�������{���9�{��(�*f�ƶ�����Z\"\u001b:L��)�\u001f��]�g^W\u0012VGD\u000eق�&ʉ��L׏)�*ݲe\u000b;8��ܽ{7��*ӊ%2fH��� \u0003#�'7� \u0015\u0015\u0015���\u001e>|8�ńD�D���޽{I6��k�(�J[[[�[\bDc�A#�إ7B̓��2����\u0014s˹s�\u001eQ61=w\u0004�VUWW3\u000b\u0018�Z[[�^>���\u001c>�\u001eK���q?��ŋ�_���-\b\u001fwd�����\u0015U�\"ڞ\\!���4Ы�9q�-+�7�È�\u0019� �����?hlQ�\fb��gWN�>͌�-yT��C�\u0016mã�����و�,*�\u0012�\u000e\u000e� ��y䪠dy�4�\u0014\u001f� �Ծ�^9ȫ\u001a9J8`�\u0019Ο�\u001f81n޼���Lڦ������*ev� d�عs'\u0003�-Ef3����\u0003E\u0016���\u0017������\u0015i�KʷJ�q��ۭ��C�B�\b�\u0011�ba�`�,K����d��4\u0013����,�\u000b\u0015�PWWG>\u0011ltv/v�S�N��qxE �X�����\u0016\u0017\u0017oVP���Er�`��I�(�\u0018�صkW\u0018&(SԻ�\u0011�B�I̔i�Y8����,i\u001e�F$���а���7�+H�\u0014�s\u001f;^\b�\u0014\u0015{��1i ǐXR���1f���~L&�a����\u0016�]I:200�Q�Ga�`b�J[[\u001b�3��e�E\f��_8R���`\u0018�_����\u001a�śGP#tN__\u001f�@��S��)/(�\u0018�\u0015�G\u0004����0MU°��\u0002�V���;\u0015�,���7��E!\u001b2,�{�}d��;��CRc�g%�#�]\u0013 r1o ۶m#�i!�A0�����)i�R��8ْ5h�\u0006\u0010�\u0017�.2�\u0002�|�kݸq#��^�ʫ\u0002\u000bV�;\u0015Q�(v�Π@����B��\\��^��/ 6�\u001c��^��\u00069��^\u001eߤƨ��e\u0010xpȟ��+q\u0017R!O��C�?�TD��Ŏ�@\\Gy\u0015 '��\u0014�����\\��q\u001c�q\u001c�q��\u0006ws����\u001c��n\u000ews��#'���n\u000ewsd-��\u001c��p7G�\u0004ws8��8��8�\u0013���\u0018��F��\u001b v\u0013q��\u000b\u001d@�\u0019��G��2�Z��\u001f��Fi$\u0005���(1X\u000e�������H\bK�v�\u001a�,,�@�\\�r%\u001cҴ����\u0001���ݱ�\u001aA\u0014�᧴6p}�t\u0006l\u0002y\u0007\u001b����6�BH��\u0001m�-m\u0002j\u001fP�a~�\f;����%�%�׉�3g�Yw�LY��Y��vo@\u0019���\u0013�-��}B\u0004�ڍ��7� ��H�S�\u0013J� ������=\u001a���^����w��\u0019rx���25��f�^�Vm��5)%WA��/\bd��U��G\u0010�� vc��f�d2a\u0003e\u0006���e�\u001d��/��ɰ�\u001dUX2�g m]�ZG����X��p��p \u0019�\u0019)��W2�Rr��`�\u0013Ɛ�%i|�*�Z\u001e\u0002� U�]I�$I�$Iz�f�\u0019�b���$I�$I�$I��Y.sH�$I�$I��gj4\u001a���]�OG�$I�$I�$�/�9$I�$I�$�\u0007~\u0002���ݡ \u0002A\u0010\u0005Ь�n\u0010���\u0001\u0016]�\u0007���*Z�\b�\u0005B�Ϟ?����}�33��,��{�x�֡V|b��e|F��\u0012��6!�*5\u0007�w�q�i��q�֚sU��Z\u00167�QJ9�9�\u0018[�\u0003v�\u000b���١ @!\u0010D� �\u0006Z�O 8�\u0005��\u0010��\u0010�\u0019�j����\u0001\u0002������\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����1nD!\f\u0005����SD�\"���a���6~�\u000e����V�����1F�j��\u001e7\u001b�O�n_�\u000f���l{��\u000f\u0017U��d�,m��FY#[2.�Ԣ���mqu�՝4��.xk�ݭn{��\u0017i\u0004�����V�g6�~DF���+�N����x�d�*���Ɵ��Q��$k�&����\u001b-����z\u001b�����R�Y�H�A�+�0��\u001bk)�ί�\u001cR�uk���E��s\u001c�Y�\\�~��6и\b3o�ef5��d�Iq�Uu2:o���u�f���|�֋�N�M?t�x��ط\u0005'��\u0015)9�W�\u001a���s��y��R���\u001fn5O\u0015�\u000e�\u0019֗�r�!�!\u001f�@iK�/���A��0\b\u0003��W�ՕL@\b�ݪ�>&�\u0010�'~�x�r�U\u0012w�b}�d��\u001e\u0014�G���(�;���;W)�o�����V��ʴ��>;���F���}kԴbz�ֿexʮ��h��c7����\u0014��\u000f���A��0\b\u0003������b�% ٩��c\"@�}\u0002�\u0011k���>�%��� ��//��B+ ��U�Y�u�luR��\u0006j�:��ቇ�u\u000e�k�Z�!��ӯ�� $�~�L����7\u0012�\u0017MO8\u0017�ޜ@�,�`�-��\u0003��7\u0001���\u0018gv����\u0006�:b6��~;�{����G�Q�qɗ���!Ǜ��\u001b��탿\u0012�?OE2'�\u001f9�.j$�\u0018�x��\u0005����\u0001��$��:�\u001ar�l/?\u001f��F{�x�L�f��L�Ȗx$$N�[�������I�O��ɐ�ew�l?W�Y\u001a�ճ\u0001�=?����1\u0012�0\b\u0004@���i3��N�&3�ḿH\u0007�\u0007F.��7Ɂw�J�:\u0017��\u0014�aU�ۄ�\u0003$9E��z��N������\u0019@)P֪\u001bG�����ҷ\u0005�����Z����8�*ۻ�Vlqg\u0002�։\u0017�e͡��NB�8��i���\u0006��ӳ&\u0017�g�\u0003��qc�*���^�۴���Ƶ�\u000b\u0005a��I�jY,\u001e{gu�%\u0018\u000b��/����˒�0\fDQ���a�r�v�eS5�=;��G���O8�Qܲ�̎�\u001d�����Y���ʺڲ&�^�\u001e�����u���\u001c��gov�可���l��w\"��\u001f��m�\u0016��\u0013\u001b�o.\u0003�SC��T\u0014�R \u0001N�NW[֤ӫ��l�\u0006N�oN'��*��ؖ{\u0017�O�W��f#���;Y*W�fV���G���oھQ�/H;G�SCLsMz}X�\u001a\u0002�r����I��VM:\u0007��Y��ZU���\u0014o�\u001cg\u001a�%�ǃk�F\u00109��3�RÝ�� '�^3���#o{C8�8GD��c\u0003�'f�ͮ�WW�\u0014Ú1YKG��E_���L4 �6\u0016�\u0018r�\u0012[F\u0010��9�:���R���� ��C\u000b��PVK\u0014r\u0006�~.��\u0017�\u0002�:lv\u0015��*�\u001e�|\u0012�tt�*��W5�\u0018S4/�g�y:��1��$\u001eA\u0004���R�Nb6�T=h8n\u0006��\u0007����1��0\fC���һ�Ύ-A HU���#�����\u001d�u\u001aU{�::a~6�U�E,~4�-(%l� ^ݮ�>���hF�w|����:���s�jH��X��t^`?��;����\u0019�Խ\u001a8�|��lMO\u000eE�`�����]�5~#�\u0006��~�R����s��C�{�S\u0007\u0010eG��c�\u001c\\�N�r��N�~\u0018�K�^_��1�.���\u0006�������0pj�r�\u001a�ߍjE/�]'�����.zf����#���a���\f\u000f�' g�e���^״w�Y\u001bw-N�R���ŴIK�@x��/�O>\u0006V��ﴟ�\u0006?L.��j４�����ɻ\u0006?��q����O\u0019\u000e8�7=$\u0019���i����gW��-�ŧ�Ɓ�i��ƙ�Zw�(��|b+-aW\u0012��8MR��z��-�!�6�\u0007?\u001e�q�.�9�ǋ�:��\u0007�7\u000e s�Ǎ��f��/�c��/�\u0003�s�g�\u0005g�)���ž5��]4\u000e���\u001c�c{*st'V�����\u0001��\u000b����;\u0012�0\f\u0005@�i(��!Ȳl\u001cCv�L�QR�\u0007p-?Qsd\"�xA�q\u001b;t\u000b����#\f��\u0002�;�J�x%|��®�ɟ �ʉ�f�����%\u0001`\u0011)ɏ\u000e�:�N���\u0012>^�-*�i�s�[\u0003�Z���o��{�\u0010\f�L��7G1!2F�\u0018�\u0004����A �0\u0010\u0003�����9$�z%�\u0016fΎ���\"Cyͱ#��Pߐ\u000f��5G�P�B\u0006 ��\u0003���9���\u001c�B�c�j��޽ܮ,����k����n�*�\u001c��:�.��]9|�a�x�q�1�[�\u001c������B�TIoϖV�\u000b�K��S�\u0014J\u0016sn\u000fL��ƿ\u0006k��=�g{>\"�Ug�-Τ�����γ�O�6XR�\f5�\u0012�lL� ��Q�af>�g;��uٝ��\u001f�m�|ת�{x\u0002����A\u000e�0\b\u0004����ת��\u0005۩�Μ\u001d@��\u0002��'�����ڲ7�\u0019�\u0005\u0017��;��߷����U\u0003@��P߸Q����O��i4\u001d���U1G>�91�X\u0004��cc�j�\u001dE�}�ەv�#�(��\u001f�V=�\u0001�gw�\u001c�\u0003��b����H��J\u0011Cu�Cb��1|\b������M��V��|��|S̑W��P�dr��@/����;\u0016\u0003!\b����I�\"�\u001a>j�35\u0002\u000f;�Μ9�&_��Y�}�̱{���\u001c�9\u0003@�p�̱��1�P�'ɒBg�\u001cK�\u0017��j~+|�\u0017ί�ߘN�l��\u0019�R��F�R��\u0003jMΟ�Â�=\u0003����9��������H{�\u0012٢wO����:�Y�CPv�0�p\u0006\u001e�\u0003����� \b\u0003���v\u0006\u0011�B��}�)�̿�aY:\u001a�H/�Ж�\u0006�e\u0005����1 \f�0����Ǯ���!O�����v4��\u0003����\u0001\u0001�����\b�\u001a���ٱ\u00110\b\u00031��:�@r\u001c)�6�\u0006H����!\u000f)t\u0003�\u0001n���\u0002kr\u001d����� !\f\u0004����\u00166 �Hf*\b�� *\\S��7�����8�o�6~mu�Xs\u001c��i\"\u0002`�w�`g;]}���T�\u0012C�\u001c�0+�}HP\f�B\"�d%ɐS\u0007S\u001f����;\u0012\u00021\bP�jkM ��p��:w��]+\u0002���8�+��ȿ\u000e�\u0011��s1�+����\fk�����^�2�������>\u0007�\\sD���ytC�ݍG-���zR�A�����d��lu���,kp�5��K�֊{�_\u001b\u001d\u0003�-���R�\u001b�z�g5�E��d���`�Z'*�\u000f�4\u0005�\\}�\\܄G�*K��a�\"۟��VrG\u0016�����_�����c\u0003��y\u0003����I�\u00031\b����=�(\u0011fq�H�:\u0003�� �\u0001����p\u0010K��\u0010����\u0019�%�ީE�d,��\u0013W��\u0007Y۶�C\u0001 �W�,���\u0015�_�/�M̏�T�\u0011��:�Ӄ���O�\u000e�\u001f��rϟ\u000f.\u0004�[�\u001c��+D�l5 ��v\\������ �\u000b����倌����'�z�j\u0007\f\u001b�����\u000f Vq�]w\u0012C��\u001f�,j|x��l��O��Hʩ6AםĐ zWK�@�o��������Y�Y�:k�o#_�ͮ���#�\u001d���\u0014 ��|jՅ�v�'����9����2je�ǉ�Z6���He�'ݝ��,�\u0002��X�K��\u000f쌓�?�uV�o�m} ֐��/6�\u000f���q=Z�^�=��B����2\u000f�v�,��;w��\u0002���\u000b.!\u001e����~Ѥ��rV+\u0005���\u0001������BA\bDQ�����$&O��h��{v�@Ӽ\u001d\u0018��\u0015Y\u0015���t �Լ���O��\u0001Uq'Q3+�\"�[�'k\u0013�dM' n���!F���\"qL\u0015�\u00137�: x�?�*�vβ�]�9��M��r7���\u0013ڵd�h�: \u0007\u000bL�1Q�i`�Ղ���8e�\u00161㝔��Q@�Cڸ��6�n^�\u00137�Υ�s��\u001c\u0019\u0014�Ղu�&2������\u0015��Ռ\u0013��N�v��4��j�E�[�3\ff�� |E\u001bӋ6EF\u0017]\u0003�9ėf�=2(��?����A��0\fDQ�i�M\u0011��݂���A�eif#�z�%�ide��ī�����\u0013���M\u0014��K;��J%]$�Kzo\u0018�DJ���\f)���z�A����K�\u0001^c7��\u001cXB�.q�ض�\u0014_y�wd������� �޽��^�&I��]�(�\u0004O\u000f\u000e��5\u0017���-�Լ��'�/����\f5���4������z\u0010�5�e\u001c��6��0��j8�R�J)�8�x��^��z?�$�Լ��'��?\b�\u001f�@���2z�T�H��&)��.�\u001a�2\u000e`Q������.$��\u001a~#�M`}o)\u001d\u001c|�k\u001eSg�%I��]�>��J���:�$��������r�0\bEQ��O��δ��� \u001a'sϲ\u0006���\u000b\u0002X�嘷��\u0016�x�N��t{�\u0019�DFu�`�\u000fc�=\u0015\u0016�\u000fP\u001c{v�'WWo�Me��R��,�vP���2�R��H)�,���#�4MS\u0004x+\u0006]��z\u001ekP���N�t�8(c�ؙ�\u001f�X�t\u0005�\u0003DǞ\u0003��UO>��'\u0003�\f%!�Fm�4RL\u001d;\u0019�����\u001d�9⠌mcg�m�R�t\u0005�\u0003��}�M\u0016W���'\u0003�\f1!\\c�S\u001aid��ƿ�u����Q�����\u0002���4;n��]�'v��{ŘX 6֞y�R! �v��X���#�(S�\u0019�׋�\"�RS�_8�}?�\u0014��\u0013\u0013���ʥ�\u0012g\u0004~��4�����^�])��\u0013\u001a�ȼ�w3�\u0001���\u0016+��\u001d\u001c�8�>�q~�x)R/5���c�Ne�`���K�4\u0006�?t󋁧�\u0003����Kn�0\f\u0005�����\u0015ElS��\u0003���.1ş�R�]���w��b��2>,:\u0018y��2�`3;\u0003�#,��\u0012�\u001b�YN1\u001e-鿕|�F�j\\�\u0018���\u000eh 5����%���ǀ͍��� �\u0013��&�_\u0017���&�Ȣ����\u0005c�L���͜���x���W_���yc����k\u0016[-�q��Ī̕Z��Ŗ�{�\u0001��pw�X��\u0017׽�n�\u0018��̙�����*���T���p �u�k�c\u000e,� ��\u0003�F1\f/�\u0006��\u000f����Kr�0\u0010\u0005@����\u0016\u0012$?? R\u0015w/��y�\u001b�\u0003Ʌ��}u�{ط��W�ţ���7G��w�㖲��Ӏ�qG1�\u0013��޻n~�]��\u001e�F\u0015��W��n��9�ׯ���H�5-\u0002hq\u0003�����\u000e�0\u0010\u0004P����f\fh��\u0019�{gh�����nt\u0014�6�?��#$p8�\u0004�`b\u0014�6�?ױ�\u0018��� W(� I��F\u0001$Ps�>�YstV�B%LH�|9� ���Q�����%���l�Vs���\u0017u���A��8\u0018]�\u001eo�d���\u001a����ޏ]\f�m�Ň���6q'\u0001n� ����1v� \f\u0005�����] \fB\u0012�/�Lk$���\u0003�S��6Y\u000b?��j�d���^#}�!��n�d����E��Æ���Q�-o;��_MR��\\��i�\u001d��Qc$�Z\u0015��\u0016z8\\ڐ��\u001e;�m��|�tIp����Ǉ%�����\u0007��vg\u001b�̍�8_�g��\u001e���p8ߥǳ��y��\u0015���\u000f�?���j�ҽ��vg;-�G��|�R�~�?W�\u001d\u000eފ�5�r��� \u001em�m��:��/�������\u0006%s�v~\u000e�IN�����$��j��:��ڭ��\u0003�\u0018�?��43����/\u0003��\u0002����1��0\b\u0005������#����%���&S�l����!���·��S�^\u0018�Zf��Q��N��\u0003;cl���������V\u0006@��ٮ\u0012�ϡ�9���Z�]�ïe��F�E�e�8�\u001c ���#ה3�U\u0014�F\u0002\u001c���3�^G�\u000bW��N��*\u000f��K| ��p����V\u0006@��ٮ\u0012��\u0004��T?N?jzT�pe|�Ԫ�j�Ͳ�\u0007�3;#�^o>���\u0001��e�A6>�?�������[���ϊ�\u0005��\u0018�K;Ra�m���_i�G�-3O]`|��w9-��Ijy��o{2� ��:\fOmx\b�;i�T�����%U|��[�a�/8�.�e�\u000bI-�\u001e��\u001c�Ke3�m\f����C�fZ>\u0015>�wx��\u0014wjF\u0004\u001b�O\u0017ܶ�U�B�˳\u0007\\7\u0002��R�m0\u001fN�\u0005�\u0018��׶;�C��]Շ\u000eH\u0005��g��}^�3ǳ�\u0015��\b�?*����������|*|Ξ.X٩\u0019�j\u0014y��������\u0001ן��dP�\u0002����A\u000e� \f\u0004�����-�\u001a ���H�9\u0016clғ\u0001�\u0007�\u001de���Ma\u0019��W ��\f�A�w�^�b1���'\u0019V�\\�~l��p�J\u000b��Iom�:�y㽯3��~���>L��;2�\u0001�\u001c\u000f�\u0006����A \b�0��&�\u00049h\u0015�?���\u0012y\u001c@\"�\u0003H�qqjlW��r�es�ڑ\u0003�����r� \f���O��L&��j\u0001 f�\u0018\u001b\u0010\u000f3����\u001bZn��Jۙ۷U;S2���԰ĸ\u001d��H��JA�e\u0006�\u00149\u0005\u0004O ��\u00023sNw�#�⅑?kh�2�����1�A\u0011�\u0006��ΦNӭ�O�I��\u0004Ob�V22�\u0003n�N��\u0015��ޫ�����7��3C�\u0017F�s�IN����ۅ��b�W�\u001b@F;��\u001c �>�sf�kt̑�߈v�7��B�;m�\u001dv�b\u000e\u0013��ny�\u0005uw\u001fc���� \u0003������G]Z�\u0007�q���QqK\u0016L��\u0001F\u000b�JN��o�o34����{��\u001b�Z�ڝ6�\u000e�[1���r�ܥ�*G\u0001\u0007;�̙3�c�\u0014O�~�xޅV�[۔�f\u001a\f\u000e0A;�\b�\b\u001e��\bT�y\u0001�·V�t��\u0005����B�0\b���/�{7�\u0007\b�����\u0004Vk�h���x�����\u001cm3_a/�[�)��Y4��sě��TϤ�\u0010U9no��h�\u0018h8B\b!�x��\u0001~\u0011\\�7\u0007P�\u000e\u0010B�����l�7E��|#�^(!\u0017���^#>\u00140�\u0019�\u0013��:�f�Y�|T;��m#���g����q\u0015�(\b�W G\b!�\u0010� �*�d5须�]\u001f\\'D\u001dbJF��[2\u0016;Ɲ\u000fގ[\u0016wn�r 7\u0015�\u0003�J�5\u0015�����_���A��0\bCs�Kgf�61|$�v��1HB��sg�]��I ���&K\\�\u001ax�dScK�#��K����&(8�p����N�Ւ��VkoT����\u00077rV��o`���\u001a!�\u000f�c��B�Q\u001c���0i�\u001dZ%#�5_Q?���9�R�R�kY5\u0010(T�--7�\u0011�w�\u0013��>K�-�TO��\u001d9��_�\u001624�eO#\fz�A�)4��N g��\u00127��B���\u000f�;����J�J�O���X�w�j\u001a��59���K�U흋ܠhKW�+_ \u001f�ޝ�8�3�\b��� ��\u0016GZbfrջ6\u001b����~7(MZ\b�e\u0017f\u000e�r�z����`0\u0018\f\u0006��\u0006�Y�5{\u000f�BF~8\u0007b�ltB����k��N����*W�d�;$�4�\u0006��\b]�i�>�ŵD���\u0005��\u0003���V�n�0\u0010���t�P�ʮ�1\u0003غ���f��\bZF\b� k\u001a݃%v��{RE�H��-\u0005�2�� � \b� 8\u0006�Y���_q���^z��ʂ���\u0016��\u001b1\u0012�.eP\u0007d�4�\u0005�v��J�K�\u0007$�D\u0006�q����e�\u0012޾o�㈧;��\u0017�V>05�+{1\u0006\u0003�Do\u0013\u001f,��\u001d��RT]G2&�>�U�\u000e\u000e��\u0015��(�`0D��_\u0012\u000f��;\u0018��C�p�gj�o�1��Ǣ_3�;��e6���'y����\u0013_?!^]�}���pGW*n�hV��\u0005��,�.Et\u0002\b�Ȯ���\u001e�r� �#\u0010��T-Gp\u000b�\u000b\u001d5\b� \b�@\u0007�,i=�8�٫�~>�\u00146ɂ���F�c\u001b1\u0012�z������4�\u00041@A�O��Z��p��\u001a/��l���\u0019����}$\u001ex\u0001\bw0�E�v�\u0006��R� c0=�E�f�w��KWْd&K�s����w�,^��I�o\u001aw���,��_�\u0018^1�+#4�\u0007��k\u000e\"d�ђ�kZ\b*.�r� \b� \btpϒ��h|��x�\u0015� a��]��F�\u0004%���\u001bn\f(|�`�_\u0010M��\b\u001c�it���g�'�0�C|�F\u0006 ��p5m��:�g\u001a�B8�\u001a�%��Ta�T'�ϿD��z�חO��I�O�5'���ʃ�8����X��Z��8�6�wx-f���\u001c\u001a��w_ ���O1�\u0001;ƶ�x��.*?Yh�}V>\u000b�B�\u000f�Q���\u0013 f\u001b���)%�l��gҋ��T�I( &a��[,\u0016��b���?�\fB�u�m����g�`\u0014Ot����\f\u0012\u0012\u0003�j��`�q-/rIP'MRm�PФ�E/R*���.�%\u000ek������$ݡ\u0001\u0002i\u0011�O.�M�d,�Ĥj\f��mJ!_r� ����~��IPSSH�V�D����-�B��>%\u001f�}��3lT��G-�F䄨c��V�����\u0013\u0016*^�\u000eӶ�X,\u0016��b1\u000e���=G�WҚ�m��w]�U�~�;ķmd�0h@Z��\u0018o�i���\"��pR)�\u0016�\bж 8攷|v�-qxY��>W�\u0019����:�xJ���ģ��!�\u0012Ϙ�pk��\u0016��Bb�u�������4Zx�֕sΔj�~��ZE6b;|.v\u001b�\u0001SϰQa�\u001e� u�wԴ��a� x������Auն� >z\u0006\u0016��b�X,>�Y����\u0016�����1�K����\u0016�s�\u001e�L�/�7+��f�\u0017}3��ӥ�Z��0\\\u0012�/\u000f���augRu�������� ��3U\u0015��R\u0018����:;\u0019����H{Y�o\u000e򰻨�4�7\b\u001bIx����F�.*?�� \u0002�F�\u001di{���A\u001evwP~\u001a�\u001b\u0004���:�v\u0016㛃���6z�{��?�����2�������w�'�d\u0010�I�GS����\u0019p�\u0004>��N���^̤g�)2�P\u0007�\u0015���ٴ�2����I03?q����zu���(���'R����H>��5Cٞ�[:������^�&y.>!^�u��Iۺ�|'��G��[�L2o����|#�9roc��:`rS~��҆SGa��\u0001����KN\u00041\f\u0005����a�4\u0002��IVU;\u0018ϳ��2�o���$g����ߊ���n}�N�\u0019\u0016�'�m\u0019~�����5���޾\u001b&W�\u0013~�.��T>aq9�N]*\u0003���4K���坙wu���gYW\u000e/�t����ن\u0003$���@�?\u0005���$g��g\u001e�6i4\u0017�w��eQ�>Wr�C\u000fZ �&����0�\u0017�� ? �:w����+{�\u0002�LV���LήMco\u00159�>�|.Z��E��Ƿ���S��ЃVë�a�09\f��db�Oé��go��Wv�\u0005.��4K��� ����1r\u00031\fCQ����2�]�\u0002\bJ���\u0005E�c�9�\u001bNk\u0015�t\u000f7�E��/ ~\u000e��c{(���\u001e� w���a�#��L������\u000b���\u0012\u001a�\u001eNm�\u0001�&YiZ�J�Ԧ���L�������_� 3\u001e�p�K�\u0013��S\u000ed\u0014��^�\u001e�y/\bxl_�U�)ߍ>�5 \u0003IJ��5�� �\u001e�����\u0018����DYdn�+sy�6���#��L]\u0017q\u000bq��/3\u0014Wd�z�\u0007y\u000e/\u0013�X��S��uVXm�*\u0018\u0004�ÍZ��.��Â9'?\u0002155Mɉ����\u000f��ٶ���ߺ���3L]������u��(P/����A��y���\u000e�O��|��ߊ�\u0012�E�qFW�ڂQ�k bjj��\u0016e���Њ���\u0016\u000fVخ-�\u001d��lS��o!�B�D�Q�^[�'>�;1\u000e��J�9o��y+�/�X�����;]\u0001j\u000b���A���iJZ�E.��p?�`�ȦW�\u0003�ݼ\u000b����[H�L\u0016�U \u0005�U;���{�aL�9o��s+�X,j�Z{}�\u0001L\u0014|��[ͯ\u0017�2%-� z��� \u0006��U\u001e��\u000f����v�0\bC��?ݽ�d�\u0001���%�O=\u0019\u0006\u0019��ͶP�_vn��u8����H���Qd�0\u001c�o�3�²\u001b��C�p�T�%\u001fEqf�,y�Z\u001c�5\u0012B\b!�x���\u001fY�x�h�S\u0005Q;�A.����AȺ����Re9{��� �_!�\u0010B��E��\u001fÆ����&R�\u000fÓ� -��$���`�PCv�/f��51��p����U��\u0005V kI6>\u0004Y\u001b\u0016\u0005K�:�\u0012��d\u0013\u0016\u0014Zs\u0002*\f���\u0006u�c����\u001a�\u001e��RN�7�_���G6��\u0001���Ard1\bC�����R?m[\u0013��E\u0018�+�9���R�?��\u0002�Q��\u0013��{� \u0007��Hl�L]��Vc�,��T�\u000b)L�\u0017F�~\"l�Pa�2R���S(l� ��\u0014��Z��3\u0001־\u0016l�{��V�h���\u001f�����O�)�F吟����3�˶G\u000e��\u0018���r8o��m4�Fe���`0\u0018\f\u0006���aS5xjv�\u0014kS��\u0017��mWmZ��J�\bXs��7��\u0015�~�7�t��os�\u0014^�\u001e\u0004�\u0010�\u0004�.d^sZ��\u001e�!2�BT�`O\u0003N�@��T\u0006\u00141��I(w�/���\u0002�@�\u00058i3_��~���\u0018�8!~�^,Q�O�'��\b�^�E\u0003-�ҥ�\bL�\u0019�\u001fB�;�$�]j$\u001c��n4\u001a�F���\u0014�6���cŝ-�-\u000et����\u0002\\5�x)(�4�PՒW,ð�\u001asyK�i\u0015��淀��Gtd\u000e2'��\u0010>�P\"`B�3��hC���~� ZNa��\u001d�Ff��Qa�!`�p�8\u000b�\u000f��\u0005�=�̥1���C&\u0015�w���j��\u001d�X>��\u0019�*@�]5\u001a�F��h�\u001c _>�A�{�z��kp\u0017}>������|v� �y'{&yY�6@r��H�\b\b��\u0017}r�,)\u0011���'n@�[C��q\u0016����;T>\u0016)��,�1�Q�9y� K\u0015��v@\"V8��R������EC�� �I�e���^�\bi\u00193;�����U��_bI�±��dw��_�.z�ZV��{�wm\u000fM\u0012�i���dn �����\u0013���~�t�U��h4\u001a��o���C���r�+���\u001f���@��pu�\u000b��a\u0019�=����'{a�2\u0004�c$^����J2KJ\u0004\u001f��\u0019>����Ma\u001b�gҘ���\u000ew�9'��*8�pv��\u001ev~qQ���(�J\u001e�dch�`�PX\u000b�z\u0007O���Nx�4��ˁp�~\u001d�Ɂ\f��4(ɕ� =�Lޏ}K̴3�2�?�D�ܡS̘\u001c�\u0003 ���\u0012(��sq:��:\u000f�!�]�\f�pe�O�, �l�$�26�7(�S��ж��h4\u001a�F� �6yA\\K��I�oŰ\u0004&̲�\b�\u0019���\u0007\brg\u0005�Z¢�g�:h���7j)륯�Q��I�[\u000e����:|�^z�ᒿ���L����N�4���\u0006l�:4F��PX\u000b#�Y�^�\u0013�)�ۓ��1��sq�\u0010R\u0007�+\u001b �\u0007�,�Ҹ%fS�a �\b�,)D\u0012�ZU-Hљ�\\\u0002P K��碧���\u0010��k��+/��\u0003�c�C�\u001b[f�If���r�ۙ��n4�\u0007���A�\u0003A\f\u0003��O'�@�ؒ�\u0004��ݶ$��0��\u0002X�\u000e�4ݫ6a�SOWO-�崰\\��Aͤ��.��N��\u0019�J�������\u0013� \u0015�)��\u0003�\u0011��\bT~ԙ�|hm\u000e�\u0019�����XF�1�y�vQ\u001bG�!�����\f�a#R���s�k4\u001a�F���`ߝp\"yQ ɍtp�Z�Ƨ�*^\u000f�\u0003H�\u0019��D�\u0007\u0007�H\u000f݃�_\u0007c�s��g�`%bN@�F2� K�|\u0003d�L�~�Ǎ\u0019���\u0017\u0001� \u0007���\u0019\u001b ?���l�޲I̘\\:z\u0006��7@\u0012>\u0005��0�Pe��'c\u0017�\u0018y�\bPK\u0017\u000e\u000b�4-Ð\u0014�cvG�e���3U�\u001c�3\u001d[$\u0019�;]�L��q �0T\u000e4{ ;�\u0018nW�'ȯ\u0016n�j�l\u001a�F��h��_��;d\u0018S�>�H��0��L�|����b�u�!21�� C�\u000bƊ0kN�����Ö\u0001\u0016�UK{��\u0017>��y�$���F\u0010��\u001c2g\u0006]�$�\u0011��\u0001����E\u0019fu�k�|�} �����\u00152�`6��a8W�g N��N�C�*v����G�VwX��d��U\u001d���?n�N�\u0002}�L��#9v�eKY_��\u0017�\u0014��g\u0016���=D^uJ0\u0016�L��ƬP��&w��\u000b��ZF�ӗap|a�3i�=h�?\u000b�}�~M�� ��\u0004�^\u0016\u0018��$����c8�1���\u0018�57\u001a�F���\u0005�\u0014ƌ�-H;f%�\u0002g��K�\u0002GɊ��=Z9 �\u001f�`Dj9~\u000bf\u0016@\u001e6 ˙�\u0004��ڙ0f�ǐ]�/�?�ڪs������_��C�!�i�Y����\u0015 &��F�ed�@�?�j�1J�ɒ���G��dT�@�B�G\u001ea\u0017\u001c^��v& �BFq�&��h4\u001a���@~\u001b0/���q����g�Y��N�\u000b#\u0012+���3k�6��\f�D\u001bB\u0013\u001f�1�:S�:�z�?Z�W�M@2K�R�t�]�(�'�\u000e3��\u0002�S;d�'z\u0006چe�%�V[�\u00172.\u000fIȨ#�ނ�}�F��h4�\u001d�\u0017�� 3�r �l!t\u000f\u001b���O\u000bEb~�/N6�6��!�pOh�é���v{��a�VG�-\fk�$��(��L\u000b��\\k�$;F;��\u0010O�\u0018x=%�K�mQU��B��;#�s���.Lv� ��yKėh\u0013$U��0QRv�S��Ek���\\\u00149���ـ��B\"XɃ_�3\u000e/ñ>�t���3�5\u001a����\u0007���VKn�@\f��/��x@��\u001e�\u001f�c��*�(��4��`\u0010 y'�� �@jL/\u0015�( ��5�\u0013��%@\"��\u000e�P���� |G\u000f�a����:!�� ��\u001dW��h����Ռ.�tF\u001f(3E�)y\"gZ��R�;�\u0001���\u0014[*z���\u001d[���:\u0001�{�pG�[;]�\u0005o�[�ax�4���ҤZ%\u0019��q[�TNV\u0013*�{^:￱���\u0012�xc;���Z��D\u001cD_'\u0014}\u000e\u0006��`0�ð\u001f\f�S�L_=��t\u001c⣸��ڪ\u0011�fw!\u0019�\u000eAbX\u0017\u001b\b\u0017\u001d��\u0014���\u0003�vyc��\u001e\b�g�� G{)BFq�K�U#@��7���ނ��\u0001o�I.P��� ���7�r�5f�̖/E�hb��In�\\��,�I.��7��\u001d�R K�\u0013\u0003L�\u000e��\u0018np޲��\u0005�;����\u0001\u001b�Õ��SR�1�)x~�ly\u0011�{)*�\u0006��`0\u0018\f\u000e�^\u000e�\u000f���R���)��\u001eh\u0001И9��\"���E�l���݉��s��fN4\u0019��\u0011����6\u001dm\u001e-S���-?n���2����\u0003h��D�k+�\u0013�\u0014�r7�'��[���3'���\u0012�\u001b*N)�5j\u0018Vi�Z��P�������7�8o�)u�.\u001e\u0012� �\u0006JK�N1v�\u0013�Ƃ�#J���>��`0\u0018\f\u0006��\u0007��!|���+�\u001c�\u001fQ�h�G�����Ǐ=��(��1�\u0003�;��z\u000e&�\f��\u0015%�\u0013\u0003��!~\u00101\\\u0001\u0002�u���أK��WѲw,b\u001b�&����p���Z4܎��d��`0\u0018\f\u0006\u001fxφ�Vr�����gF����\b��\u00033|(z�����M��-(�]H�8g\u0019\u0004��w�f�䓕h��^t���-k�4¬�@\u000bO����ɢ7\u001d��m81\u0015ew�)�\u0015�c��%�wUrȦȨ�m�\\�J�KB\u0019�\u001c{\u0017�?{ׁ��'�Lr\u0018\u0011Iul���L�]�,��Ki@2Y*�\u0010���9�~���=�\u0002��l������g�\u0018�\u000e\u0006��`0�\u000bP�N\u0007�?���Xے�J\b�����-�u�B\u0002�v�Hok�\u0010�3�98�,ҡ\u000fF��\u0015/\u000b�d�\u0012iŐ~E�r'�&m�\u0006�\u000e˲�\u001cF:���I\"\u001f-o��8?��\u0004:\u000e��SA`L5�oG�\u001e�\u0018.��&ɨ4��j\f�0\f�x\u0013�#a����Q�'\u0016N��\\�L�R�^�d��(�7����&����3iR��q�HǢ\u000e��u��3S\u001d�p��?n�{d��?��g.�\u0018\u00046pUO��\u001bJ���2��/Dyz�\u0013\u001d1iR���_\u0014o.�Gs����\u001d�@rU�S{Y[(P: R����1��ܿHu;\u001b�ܑ�\u0003�*\"I Ni�lj�\u0018�a\u0018�a\u0018/�_��a�\u000f�e3�A��\u001d\u0019�͗��v��&\u000f�ŭ}3 |`�Q -��\u0002\u0015X�O\u0011���`v���~\f�X扯~^��\u001d:�b�]�\u001dr����Zu������#�Y�������/\u001d.X!�9��7\u0003�p��^\u0016�>+sѹ��P�C�T\f�˹C�Tq�^�.S�q�!�H{��ӥ�?\u0010o�K� V8?��#ҙO��\u000b����ѮB!\fD���_탉1�z\u000eRhg�^�F��!\b~��\u0001dm�\u001c��\u000b3;�5�aO�Q �?i���*.>��7�V�u�^>�[2�ro\u0013ْgQnoP��`]�;�-�O\bЏ��ky�����v�\u0018�0�c]�: �m �\u0019�\u0003�\u0011)��ʻ�%�2ӯe�u�\u00173�:�jpA�71�-\u000byd\u001a]Z�77���� �����\u0010[N�cD�Bw.\u000e��z���qW\u000e$C:m�~:����#�1�-DO�2pAQ@��\u0004A\u0010\u0004AX\u0001��\u0005L\u0010�Fu���m �S�v�ـ�\u001c�l�Ƿ�`�\u001e�j^[�\u000b�/���\u0013>��H�x�RUrJJ�-L�W�\u0007(3��5I{�f���c�ӱM�'8��˾���a�)��M��\u0002T�A\u0018\u0002Ԉ�5��2�^%\u001e9)�\\�W9��憙\u001a$^;F(�Y��\u0002��E� �/p1ɓ��Jxr|sp^|W��k���b{�3e\u001c�\"y�D\u0003ɟߥ�\u0017��h�q\u000bZ��b�\u0005�g\u0001[}\u001b\f\u0006��`�=��7�ݗj�׋-�\u0019�Cb\u000b�f$[��mN�F�L 3��`�Ȏ?���XIr$A\b���ssL�\u0002ڨ�\u0001��T !����ӎ\b:��f�^��A�\b���sv`!�\u0006r$�u^\u001d)\u001dJ�|��E�.@'��ْIx^��\u0007�.R]�\u001e�����u���^i�(Ꮿ-�\u001a\u0010\bN��B�\u001c\u001cD�),\u001e�H+N5⧇;ĭ\u0016�9�%��9w�\"R\u00027�5p \b9�)E2��(D��5���\u000b�� ��ֹ߻��\\�'�^qL� ��B\u0004'd��8��b�\u001e��\u0013^40��b�X,\u0016��}w9��\u001b#���>f\u00105�mF�9wee3\u0001ܘ�|h���?��ȟWD�p\u001d��t/)�w�o5�\u0016Ji^�����\b��\u001a�Ш�͖�#�m�\u0011\u0019�xd�bv1e���uj�&�\u000e�i�@�Mj-���\u0012�\u001ex��7g\u0007�\u000b������� ��\u000b�h]�Ze$�;�3\u0002�^�Hh�oD�j��\u001e|\u0005�L\u0001�sz�4��~��\u0015LWg�Q�\u000eǉ7%^\u0010���\u001f���\u000e�Z��/U�g�V���\u0003�!��/@�FKs\u0012�\u0005\u000f�gF�ޝ\u001b\u0007e�*mz�W� ��X,\u0016���y�_�'V��(h�;�yXR�&����ɟpB \b��\u0019k���- G+�\u0004� �-��K�+����\u001dG�>��?e�/6[\u001c�w�g����W���?���VA�#1\f��:{Ke�\u0016\u0002$w�V��N,\u0010B��\u0006�f�Wc���e\f�\u0015�b �Z�^�ƜU5���o\f�\u0003ۖ\u0014\"K�Ui4I����,ub���æf$ \u0003r@�N��c$s3�$;b���������\u001f2⠆qub\u001d�U5�\u0016缂׷�6%2��K&�!�Eq�`�I���\u0018��x\\�5���T�.E�|kO�TN�S\u001d��7l�d1d)L���\u00183\u001do�q�\u000e�۩�|\u000e�`t�� \u0003���]4\u0018\f\u0006���]\u0018?�\u0018�����ɴ�nԨfD�[��S�\u0001�Ѭ�����\"`�$ns�)߽��b\u001a��x�yn����^�WP�B=e5\u0004U�8��\u0003PKk�\u000b�B��5��\\�U4�4\"��:?��-K�B��;R��\u000e�\u0001����[\u000eB!\f\u0005@��j��+=@$u�S\u000bVh@�C1�%�;���ls�esnݸ�=} [��[�q��CJ\u000b�j��&����6}��Ζ ,��[�6��!��3>a�R�,_7�������\u001f& ���C8gȸ�\b( hc�\u001f>�Dt��\u000fᐡ�\u0015FL=@\u000f���\u001e\u0011-��C8a�r�\u0011S\u000f�C�\u001d_O�f��9t\u001d)q�1C1@\u000fzD�9�|\u0014?sP� #�\u0012\u0018r\u0007����A � \f\u0004@���^[�Z�*��s\u000f{X\u0012h@v���h\\\u001e ,7\u000eZYa|��Ĵ\u0001���>l>:\u000f\u0010�3\u0007\u001d�0��\u00185p�tS�`r0 ���:\u000e;��(s��8һ�рc��T�>�cΆ�r\u0002\u000fS[�fV���d��V��p ?�=ܛ��7 \u000e4��>L������Y��\u0007��|��\u0003��\u0004\u001e��_Mnww�;�x��'�&�\u0018��R�գ&��%�y�¬��LO���\u0001����1r\u00031\b@���)R�w�\u0010����mO @��1pP\u0019x�\u0010d�/]k\u0007�k�dl��f\u0001���!\u0017�� N�^H�̼|����\u0006.��� OS� |��2�-Cr�ۼ�������zb����H��!\u0017�� ���VF2m&s���fN�\u0002�u�C� �� |��\u00125�N\\.\u0015k�ev��\u0003�d�s5,��������0\u0011�l���'\u001e�7?��'��� Y�y=�\u001b;�\u0013�0�-k2�r�X�nw�|=�{_��$� �\u001b���S�4�\\�^�L��K�G�3�%�[\u0003�\u0007N��䊷�JE\u001bh\u0017�������l�C\f/T�\u0016��v%g w�c\u0017U2@p�;Sy�L�{Lu��~\\}\u000e\b����\u0016)��\u001c�hc\u001d�)Z�,��+ '�/W7\u001f\u000fXh��\b��\u0007�R��C7�|�N�yL\u001f6(m�\u0013�m �/x-�\u0013���\u0010=�������������������bO?���ǘ����:@�dJ��o�$I�&9��.��S�a\u001ck���m}r�Mk��`UnP#\u001es\u000b��V�gV�Q>vd\u0005�5�\u0012?\u000b��a�]\u001a�zc\u000f\u001f\u0004�>��\u0017az�\u00126%I��\u0006�\u0019�\u0018�B �\f�AGV�n�$�ٴ�� V�\u0006��1�@\u001e\u000b�\u0015{��\u001d\\�h}��u\u0016؃�\u0006;͍w|��0\u001fb�\u000e� L�XȾ$IR\\�IFU\u0014�\u0019��\u000e�n�^In�i��\u001b�� j�cna ղ�̊=��\u000e�p|\u001a�-M1���\u001d\u001c3�en����|����u���-�_D�$�\u0017\u001f 8c�� ����\u000f:��u{+�ͦ_ۻ��7�1\u001es\u000b�T'r��|��A�\\���{\u0010̃c��̍w�'�a>J�ߜ5�\u001eMo��\"�$i��D�\u001acT\u0002�}tW.0Dݺ���n�T�� \u0006�`|��m���D�֐�\u001d_�h���{\u0010̃c��̍w�s|���`\u0011h{��\u0012�}i\u0017������@\bC��?��M�L\u0003\u000f�=S��\u00167HB$q/\u0016���=�ˌ�ƿ\f&�\u0016���Gy�y��\u0017B\u0013 *�qUU�ɫ΃�N�`�֔��1S��󦥘_s>h��\u0002\u0019F�峿f\u0003\u0012z�\u0017^hU��2��%\u0003�����\u0013R��1���#��vR||.�絧ZMŸ�\u0010�e\u000f\u0019\u000b�\bII׫�\u001a�Jb)��ɐ�\u001b�k*��_O���D�j��D\u0002E�@�\\�s�ˉyT%�)\u001b�\u0010o, X*�x�A8T��\u0001[#��a�\u0015\u0014� H�%WP+\bA\u0013m�45�ڃ�²`�\u0017��G-@9[\u001e{����\u0002�Nc9��\u001c{������j�;�F#��Faw�� C� v\u0018�\\e�L�lo5�0I����\u0019T >\u0019lg���z�~4}�V��β�Z҃����X��\"۬6ݞ2��`#\"�ʩ����*��\u0019TUMn�i\u0012�\u001di!�\u0019�#�>M\u0003�B\fP.\u00183\u0013s\u00021[��\fH�d\u000bG�0҈9�9���=�q/%��)&���LV�\fG\u001bM���\u0002��T����D\u0002�����s��.�G\u0017@H�j4\u001a�F���\u001a Ԓ���\b�\u0004����ܛ�鹔jd\u0017�Y�]�\u0004�w�G�~�u\\� ��%=h Gc�Z���!�kvL�()��C^�)��̇��\u0019�$�;�k��x\u001d'@gF�9s*���ҵM���y\f^�l�\f�,�lǌ��&�� k���\u0001�\u0018\u0001az�\u0005\u0002�2\u001c��T�lm�R* ���\u0011C�\u0004�jW �_��Iݐ��F��h4\u001a?\u0005�%×�{וl�&G\u0002��=L�C��\u0015\u0017�\u0014�ğk��b�2�D\"�\u0001� 4Z���D\u0006�Ke�դ%Xz\bBr.��q�\u001d�ے\u0018��h4\u001a���x�%�*�\u0004\u0010��TJ���l\u0001�μc~�\u000b��\">\u000b���\u0002�\u0010�Z�\u0011����K��\u0002�Z~�\u0003���K�#A\bC����l;\\�Їt{\"��\u0005�!:f��Hd��X\u0015�׹�1�����$���U嫸]�?�p� ��\u00172?�Q�B[�옓��\u0012�7\u001f=,\b#�\u001c�\u0018�\u001b1��A�.�^����`��� \u0017$� U+�!Y��Q�I���L�K~�W@J}MU��ߥ���מ0\u001fg�ꛎܢ�E��f1�^��誦�*�� F�y\u0001^�%G\u0002-�E�}�,\u0015&�}��u�:���=a>�z\u0015�\u000b�g\u001c�\u0015�\u0011͆L2�b|��\u001dsr�]\u0002#�n\u0004�\u001c�)\b#�\u001c�\u0010�5|V\u0018��\u001c�e�&��x�HT+f\u0005�=t�j����\u0006\u0001�nF\u000b�\u000f�!Gܸ\u0002/{P~h\u001e�3Y�\fɈ�j�Z�V�J�\u0001�{�\u0018-��F�0ң\u000bH�B*\b�%�6\u0004��\u00140��Y8:ҁ���Ș�\u0005$\u0018\u0006���\u001dIBl�W���綽X��䚷1F��A�$6� l���\u0010xHF�\f\u0003(hӐ�*\u0019̤\u0018�0@{ǜ�w�������ؤ+ɡ�y֐Ya�c�7���kI�FH�Y�W�\u001d\u0017$��x�\u001bӏn^\u0017C\b�����\u0010B\u0012��84\u000f�֌��|�9V��j�Z�^_���\u0013����\u0011�Y��a$�#\u0012�j�k�C�~��\u0012f�S��\u001b$#~\u000b�J�hx�ٶk�5*\u00186�W����Or�[W�o���@j[�\u0002\"l_0H\u0002\b1\fs�xL\u0012�\u0002�6���ۏ\u0015R��|�;�\u0011�J�l�� ����\u0003�s�1��9�o�0�!�T\u0002\u001eX��Z\u0019s�\u001a��G9�\u001a�HK�U�id��5�h[$��S\u001a\u0004�*���g�^;��'�ћ~t�z\u0019�x6� W��}h\u001e��Q�x�T����:���\f��5�b~bH���\u001d�ה&b+�j�l�9U_}%�\u0013�� �s\u0006+��\u0016�\b\u0007[�_/�.1�b\u0015� dpM\u0006��ś��0����Y#�!�햀�\u0016Ɗ�+�k�I��\"�I�T�l�H-�ʿ��2\u001b��\u0019Y�jaJ�l�n�\u0004ᚍ�\u0001�����\u000e� \b����vpN�\\�{�J\u0005�\u001a\u0015Y�\u0019���oﶳ��U֟�czc�Mz�\u001f���P���\u0018�zA\u001a\u001c>\"F%\u001e�\u001a�c�� ܋u�}�(��m�fM\u0005�\u0011PH��!�\u0015f�1Ɯ\u0007�\u000f%\u001e\u0015y�g?��,�u$���\u001b\">4�R�\u0019PX�P����\u0001�\u000bS �9����9�(����\u0013\u0002�tw�.L�{��5��4gHg�}�($�u����\u0011�U(+�\u0018c�9\f�ˤ\u001e��o���\foJ�\u0001:�V���\u0010�\\H�ļ������$m�d�r��6!��aڿ�u�\u001c�\u0004�U���F��h4\u001e\u0003�%����D\u001f�c�\u0005P���\u0016����������h\u0016��i����\u000b\u0012&G�\u0002�(�\u0016@\u0002hCA%�-�ν ���}[��*�\u001f���Ri���Lb�\u001a�J�W\u0010\\�Vw�`n���\u0002t���\u0002�\u00160B�\u0001����r�\u0005#��:+\u000b9-\f\u00070`rޯ;Z����F�0���\u001ax�d8� �h�\\*�4���\u001d7�K���\u0016�47��-`l��$Um��*:\u0002X��i�jCCI\u000b����%���)\u0012I�dt��@zZ�r#ha\u0018��P�+\u0006\u0014�X\u0004�3Z\\��\u0013����\u0005k\u0006I���TA�l��p6}u��>\u0019FI�AFC����K�\u001a\u0001z\u0004�c\u0017�E\b'�+ r4�e���|x��\u0012�Ε\u0017e&Eκx�Q#\u0002�1��\u000f�#Y�\\�#܅��Y���@p=���%��\\���W�aF\u0018\u0006� hn4\u001a�F���k�w��G��:R�F�0\u0019\\�Y�,�r$Gd�\u001b=\u001e�&|\u0012dn�\u000e���\u0002�݂\u00104�U�y69.Y��\f��q\u0014��\u0010>N@��)g��Y\u001d �ڱ�&~�2\u0013&��6I�\u0017 \\^� �||8-�辊h&����ҳ��\u0003�\u0015\u000e���0{�,���ɐ��W\u0004'��.����\f�3>i\u0007\u0006d8B9�����\\iO��1}�)\\4��\u0007L�Z�\"؉\u001fE���[K�ɉ���D,\u001b������2Dr��=sh-�Y(��,\u0012�N\u0017 P�\u001d�\u0019��Ȅ�Ō�7 ��d;��\u000f\u0010p�V�-��`\b�\u0016�U>�}\u0017����ř\u0018��e�+Ι\u0001y�� �5��\fkd-I_6��\u0006S\u001e� Z�R���1ЊK\u0010iy�Z\u0003e\u001f�=ve�Z��=I]�����H{�\u0013-�\u001b&`�@���\u0003��lM��6\u0007��`0x\u0003ZϨ�)\u0002\b������\u001cd�\u0001�\u0012|�vO�r�Z���PK�wO1-{��ՀӮ�\u001f` N\u00173:ހ,��D�>@�U[ͷ����Z-\u001c�|2[/����ª��\u0012�\u0019ז�Հ%G���&�2�\u0002YKҗ��\u001f�,�,\b\\*3��\u0003PN��\b�� yEД�\u001eL�lSͧO��䃶o��h\f�kFkDf�)����\u0018[�u�\u001a\f\u0006���?@�c���}5!L��\u001c��\u0001t�,C(���ж×�9�\"OZ�*\u0003� �V\u0006�BӘ\u000f��\u0013\u001d/�,\u0017 ��qHf��\u0013�\u0012�|\u000b���F0�T2�%m\u000b��9\u0016�6���k\u0001��QUo;d5����BW\u0010&\u0015�o�,�,h�z?�\u000f�V�\u0001�\u0015'���TV�\u0018xUS�g䞐\"��\u0016~d����G\u000e�W.��� �4�_��m}0\u0018\f\u0006�ף��1d��~�k�\u000f�A��Qts_z����q�W\u0001&)�A�q�x'�vS�\u001d�\u0006�8��\"�=�J��牙|,2�)1ͷ���i\u0004�L%�[\u0012�p�\u000bM\u0013p��(�.��\u0001���X�n�0\f���t\u000b�P�ƎL���\u0002�\u001bEQ�:\u0007�j���\u000fz�����%��\u0014\u0001�w[nY\u0010}��.u�� w��\u0004\u000e\\�e�t�TSΧ�N@\u0011Z�\u000b�2ZJG�\u0012p�`��۽ģ\u0015\u0019S�� �\u0001\u001a�F��x1Ro\u001cB�\u001e�׾�[Ww� \u0015\u001fEs���\u0002B]�ܗ\u0012^\u0015����{��i�\u0017ZP[��>���\u0012\u001d.���8�x�1\u0013��&(%��\u0014\u001051 c��dtKD/���s,F��S�gr����/\"��W2X�L\\�\u0018N\u0011�y��\u0015{O�Ļ����q� ��,g�L#�)��r'�\b��Z�e���b)^=\u001d,B@��\u001d�Qܸ�F��h4^��놐����/,�j��P�Q4���y@(͖�F«\u0002&(r�q�i�xmEǊa�],\u000e�\"�k;x&1\u0013��&(%��\u0014\u001051 c��dtK�܌�\u0003α\u0018�FO՞�9�+^����K�é�ru�\u0014�\u0016�\b^\u001b3\u0011�;��~\u0002qEV�^�Bl���� (�]\u001a��e��\u000emiL��^�A�% �ݎVaL\u0014�p.ȶk4\u001a�F�mH�k�w\u0013'��m%�\u0019\u001f��~G�-�:�$B�:�\u0007\u0014\u0007\u0017���K�q��F��h��y��)9&\u0004�\\IZ�)O'\u0006����b�X,�\u0010\u001a�\u0016\b�?\u0018\u001e~|��R\u0017]6�\u0006�@\u001e\u0004\u000b�MmPWJf\u001fm1x��\u001aty�\u0005�(x�r�y;0���6� N��hG��Fˈ\u000f�ӄ05¯\u0007�L�N��\u0005�� L�\u001fE�M����Y��W�7�\u0003Y�M��(���&4z\u001fՠ�,\u0017��C�dy��V͉/�t3Ө�x \u0019�~/ \u000f\u0007\u0015����s�}=�'���\u001c��LC�\u0006��&��9�S\u000f\u001as��j���&�Ž������\u0006\u001b�\u001dbh\"���\\-mOJKRr��y+�Z�\u001e��:�{\u0014�\u001d'�\u0011څ� ������b�X,� �%%L��>0\\�jЁ��\u0011�:6KwQ�_�s;�k\u001e���_��\u000e|1�Ӵ�\u000b�\u0016��&����T\u0018\u001a\u0010�X|\u0002\u0019=$^�#s�}A%����{I�9�A�� ��s�=w\u00182H8\u0007��2 �h�,�p�{'�.�\u000emϹQ��$���?�G���x�\u0010ftf[�9O�\u0013�И�-�L\u0002�ګ�\u001f\u000elX��64o��\u0010\u0016��Jk�C\u0017��b��6�G���>�̿\u0019�\u0004�ka\b�7\u0006�,�L�τ��QP\u001e��� �ׂ���*\u0014�����\u0003�m��R\u0013!d�0�}ȑ\u0013�O\b0-^VB�V�( ~&\u0019�Q@\u0010r�I\u000bz��G�\u0006-g������R�G�\u0010Tp$�Ӆ��N2s\"���ku4h\u001c�����Hk\u001b���ii��6Q�'ޝ��\u0013r�a�5�����v�0\fD��?�f��4�1��-z��\u0001%�^�-\u0007�\u0014��\u0013t�������SJ�\u0004OMQ\"̀l��0�l|�p ���e��\u0006O���j��jJAs\b�q8\u000e��\u0016\u0019~�\u0016�3�\u0016�))��-vj��\u0004 \u001d\u0017���`��S��,=q�Nׯǋ\u0005uaq�/O\u001c�oJ1�ϤW��Z1\u001ew\u0001x\u0010�v[� _�sM��w\u001eC�j^r�Cjs�JYv�N�?�����y���h�Sy�d\u0002�CS���>�!;\u001845�k�e,��\u000e\u00074�����vS�����\"�a\u0006��1��]H�\u0018�O� �\u0003 \u0014*�\u000e��,\u001d��8��@]\u0004��(,��5�K�-�\\��\b���@\u0011\u0001P\u0001c\u000eG^Ѻ��U�q̄�MK���Z3\u0012�pZ�?8>%-�~)��#)*�C���U\u0019�\u0010H\u000b�L� �\\l\u0005B�,V� �LDrg�?�|\b$�=�έ�\\}ٯ��e\u001bu$�\u0004��\u0013Z����\u0007��`0�I�\u000f��\u001bx��z�\u0013B�L�%�,�$\u0007��\\\b��y�� �\u0016\u0004����\u0018=1�����e\u0019��\u0001V��&��{\u0017;��\u0017W+\u0013&��\u0016&��\u0017b�訅��\bd\u0014�r��u��\u0018���5.�x\u0016N\u001a/�0��Zh����0�U�\u0005����GRT��ȫ2:\u0006��\fh�\u0012��\u0005����Ϧ\"o!_k\u0012ɪ�BE.���V]�\u000e&Q�1q=2�\u001e\u001c��`0\u0018\f�gh����k�� �t�77'̪e��\u00102�aK{O�!_��/�խ�G\u0012�\u0005��+3�\u0016�\u0018g��-L�j5�I69�.D�X��瓼��\\��\fк!�y_g��\u00059��h$���\u0019�!���(IƬ ���$g?�\u0005�\f=\u000b�L�\u001e\"�ʨښJ�D\u001d�\b.�\u000b�v{_\u0003T\u0005� \u0016\u000e��$�����l݌a��������0\bD�����R+Jbx\u0014�LO/�>�Ƹ(0 '!{��\u001d%%�\u0018'6�SH~�MJ\f\u0006��`0\u0018ܢ�\u001a\\{=������_템r��\u0014Q�˫��\"�Ž�\u001d��C\u0019U��=�~�$���`5��-�1⇗ԩ��#LX��-���yS*xv�\u0010��\u0002n�\u0005\u00133���슃��\u0012/�Y���>a�Mu8h\u0015N��`�hCc��d\u000b��H�\\3�\u0005��d �=���Y�@��p��@`9�j_\u0019w ����Tt\u0018��.R�N�9��'�-{�\u0014�\u0014�}h�g��&��a0\u0018\f\u0006��\u0007�{�tu���/1\u0010�CN9c��\u0017\u0004��e.�\u001d���Ed@���{D�M����s�\u0017p\u0012w+��@�Ǻ��\u0019&i����,M`��7\u000bIxI|��dS�K�J�u��~*6eۛOA��T�ә6��J��I ��EU*�})�=C�*ɪ��d�W\u0002y�\u000e%.v\u001fh,�[��wM�}ɴ�q�2.��}\"�k�ãM��]�Н}&���&M]\u000f\u0006��`08��f��A��n��\u0014\u001a\b�!����A������;����oP�I��Ƌ%���\u0006WU�W��l| g�ݭ\u0001_�\u000b�\u001f&��*u���\u000b��S�\u0014�YT�/���ZF\\s��^��N[�\f$4W�c_U�8?�}���Ƀ\u0016��\u0014\u0019k^({���g\f!��J�\u001eY 10\u001e�X�� �x\u0017V��\u0018rw@��J���n5\u001b�U�T���%�������̄׶&�\u0006��`0\u0018\f���N��AA���w\u0004�S�p���@PM5O��c�\u0002Ϸ��S��u�>q�l���[V�f_Ù��xFļ҂���\u0012U�\u0010pT�>�D3���D/)��!)|4\u001a�(���\u0007\u001bJ1�w\u001d\"uW76R�y�\"� u2��.�&\u0018��\u0001�s\u000f)Hh4\u001a�F��!�/�r�_�Ť\"��\u0005󧍅�)��\u001dR ��{\u000f/�\"\"\u0004�Ɗ#�\u0001>\u0016�j���,F�ߧ�&�\u0012R\u0016��tc�8��\"�N�f\u001b`Ա4\u0015�.��`�\u001e�E\u0014��Ԅ�^ B\u0001Ye��!N���mR���#� І�/��KT�C�Q\u0010�\u0014\u0012ͤ$zf\u0013��ң� �\u001f\"�R� *l�uzR}E\f\u0011��s� ��(���T� ]v}\u0014!4\u001a�F����_(Li!�f\u0002\u001d\u001b-�b�N��*�{� ���x�\u0015Q����ź\u001b&\u0012\u0018\u00127J1~���v�� 76���t�#�m\u0012Tp��m Qc��U�kRcl�\u000fj��Φ�\u0005Ჿ�\u0003u�{�7{�\b\u000e��\u0003�\u000f�4�Z�-QH�J{\b\u0012Ho9��+�L� E\b�\u000b\u001a��\u001b)����AT��u�U��G�� ����H�g�-�S�t}��\u0004\\�\"u��h4\u001a?\u000e��\u0016\"o&бH)D�ﰳ�F�� ��c��y\u001d!ę~���\u0019S8��q�+5CY\u0010\u0002�\u0004!>�� �l�шn�\u0015U��c�Z��.�ε���@\" TF���\u0011��9�7؞\" A�6\u000fz�p=�j�d7����DG���f\u00019t3LO��&�I\u0011����~RT ]�9�n���jV��G|�C� &��\bM\u0003��\u0004�Kg��F��h4�\u0015�\u000b� f)��E&�\u0013�� 6g�\u001fJ\u0017�\u0003f\u001cbcW��=\\$�6��ݻ�\u0001���7v�9��4�'�+�������-�t'Y�\u0003��\u001d ���hh-��Ӣ�\u001f]��hVmŨ����W\u0003��B;ϭ����*�\u0013��4\u001c��Os�a�^\u001dc]D�h��\u0007!�\u001dR��h4\u001a \u001f����K�� \fC��]�T[�L*��v\u0013�\u0011`h�Ƽ�ҫ�\u0012�7�b@gO�!�/)\u000f\bR�t\u0016T\u001b�.�!�Co� �!�B\u0003��1�8�*��\u0013c��\f� ��[]m\u0010yqv�@U)Q�~�\u000bK��U\u001cD��bj?�sZ\u0003�*�mlGI�\u001a!���/6cde4�\bc����r'lJ\"\u0003wb�y�򡫺Ԅ\u0004,���;�G�;�;��Jl]��\u0012B�e6�'E�Ъ�R�B(\u0015v: �\u0011�Z\u001d�\u0012 �Wܠ.\u001fA%���\u0014�\u0019\u0011\u0003�\u0014c�d#1?�*�\u000eΎE�\u0018��d���\u0018c�������}~w���?6P�#�x�Wƣ\u0019⅄*uv�h�\u000f��\u00015>K�Ah�Ӧ��� �8�r׊sc\"����f��ŷ�\u0004��#\u0004�_����U\f���\"5\u0006��4��\u0011�H\u0015n\u0004��+����{U@5\u0002-;�\u0005m��\b�\u0002)��-\u001f��JMxXn$w\u000f��`��HUZ��Eҁ��d�Kx_���k\u0015��z\u0001(��,���\u001a?\u0006�s BGh�j\b�Uk����lS�\u001f\u0005���H%f)\u0017n�o�tm��Ӂ1�\u0018�\u000e��n$��Ii���˿\"OO��YE���\\g�y\b�+���h\u0007�Q�\\�\u000f&�5\u001c=�G�7:\u0007\u0015�ARͯ�_\u0013p���\u0018c�1�\u0004��o���*��3\u0006��C�u?��3~�x�sP\u0001\u001c$��\u001a��7�\u0018c�1\u0007�\u0007����� �0\fE���N\u0007�D&�K3�\u0002��\u0004�e��3ɼI���^ݏ��&��G\u001f���\u0001\b:*�\u0018N����\u0018#���Y���r��D?����\u00174AGe\u001b?s�\u0007�_�K�$I���\u0001p��\u0005O�$I��=\u0001p��\u0005O�$I��=\u00010�}��\u0007���ڱ !\f\u0003�����/(\"�l�&0�A\u0014�����Y��vڶ\feU�/z|��3\u0017T���P�W\u0004\u0016�[HW�X�8�Y{\\�G�g.�AQy�\u001d~��\u0001����\u0001\u0001�����\b�\u001a�����v� \fDQ��O�\u000bN\u0017�kY \u0010#��։\u0019$a'��o�����\u0007��-R�bEc\u0003�F��iw\u001c�Qk4�\u001ayԢb\u0005ͱ��w�&����})!> �\u0017�\u0004W��[��\u0002\u0015\u001d��/���B�� ��\u000fO������(�Y�\u0005$�E�b\u001d�z\u001e�F�RN�\u0014��Zy�\u0007���XK�[;\f��7��\u001e\u000e�%���\u0014�\u0010g�%�\u001cԸ],\u0016��? ��\u0002�ғ�9`��ok��w=!�F��3�[����$I6#\u00198=��^�_F;��\u001b��o{\u000b�xo��k\u0012���\u001f�I��_�T�yA�B��������Ο>�&Iũ6H{�J#�B3�\"��\u0007���1ld�T�1��ޒ�����)\u0006Z��\f\u001eZbDyo��x\u0010�a#K�����p�a��W��\bW �5���\u0014z�\u001b\u0014m\u0016^����p�\u0010,�|�y$�\u001b�п���\u0016��b��\u0002���\u0017�#Q_�)�lѰ'\u0019�*#A�p�2�Z�>��\f��~'1\u001a�+�2�x�瑼���D\u0015�Ʋ];��p �\u0015~�ݪ��\u00195\u001d�\u0004\u0018\u00183�\\}�t�\u0014�Zi8IR ��yT~�\u001f�m��U��\f\u001e��xK`�\u000eE�&�\u0003�N:7�\\W�%KxX�@��B�s�()f\u0019��*6CSq�X,\u0016\u000b\u001b�Kj��\u0003���ʕ�#��\u0007�E�\u0007ɶ�E0f얜`�SKv4� ��h�;7\"9gH��s��B���T�\u0001�\"TV�ii��̏tG#qB'�ǐJ��Y-�`\u001b�|�Ϙ��oG�6.\u000e�B�����\u001c���|\u0015�\u0001\\��n\u001b�$ wK0\f�N\u0016��b�hBz��1��78է�{���|�1�z� �Rx��y��Zd��Z�b��o���M�\u0018�4S;clJ\u00143�3��\f${��]\u0017�8\"��/\u0005��\u0012��\u0012\u001f\u001d$��)\u001e(�P\u0005\u0015xW�sό�\u0001�âR���w�h�����u\u001b�\f�NJ\u001e悘�l�����\u0012@�L��{/f��ɎT�r�\u001d�q:3�U�0ÏQ2�\u0003#�4�����Z�E�@���]\u0018���-/�\u0019��c���+0l�\f���b��\u001f���VKr�@\b��/�Y�jj�l�>�3\u000b�| B\u0012T���4��7���^U ��� ��呰�c&2!้�1��1ye���p:Ӌ\u0001� mIba ��)~\f�@���b�cR\u001a\u0019�����7'o{[Hl����z�2ydfj\f�\u001e()���%�ַ�-3N��8\u000f�'��J\"�\\��?�>�T�\u0005\u0014�i\u0018�F��u_5x��\bN;\u0012\\��\u0001�Z�q+��yK�����\u0012i��:��?��#\u00077�\u000fba��t\u001c�s�q\u0001�w�\u0010p\u0010A�ב�\u0011Z\u0013��0\u000e ׯ��\u001eR\u0014u�ð\u0004hA�E��hM�\u0007s���\"� K\u0019\u000e8u�\u0017�R�5�i��ُa0\u0018\f\u0006\u0003�+\u0003>�i\u000b�\u0011�;�>5{8�A�\u001f T�֩\u0011e-\u00169L�X�όf�\b�\u001c�����M�h�� �H)\u00056C6.j5Ž\b�m%xV�=�\f��\u001eKńJ9bI\b\u0007q��*\"�\u001f��Ǟ*�\u0003�\u001b\u0015!7�غo\u001cKJ�B�y���Y�Ob녷[\u000fĄT itcZ�\u0003�܅�(��j�\u0012�6�r�0��\u000f�A�E\\�4WZ�\u001c\f�o��RH���\u0003Bq^\\��\u0002v2�h\u0014��\u0001�z\u0013���1(�ol���\u0006�3���K�� ����H��x����\u000fJ��U�\"3�3�\u0005�-\u0017�Y���@�\u0007���\u0012��ӕ��ԋ7eH��lB\b!�\u0017ȷR��xUR)�F ��\u0014�9���Y���x�u�y\u0013��^y�TB�\u001d���F[�\u0003�76Ϋ��V�\u000f\u001f���Ӕ]�N��o�=�\"�=��\u0001�.����M����di�W\u001ed���~����Q3!�\u0010ҋ�9[�8���u�`;��kN��l(��.e}����߅\u00100��,�\u0019�G\u0019\u001b��z�չ;\u000e�z���\u0001[��\u000bm\u000f�Bg�!}��\u000b #\u0015Ʀ]�j�ϕ:1`����.I\u0019o]\u0011�\u0006\u0004\u001bdct�O2� 7�]y�����#i\u001d�i=�\u0011�\u001b\f\u0006���\"\u0010^���W���&e\u0018RK۹���\u0014ZcT\u001c��i#�\u0005��\u0005Uh���I69.ٳ\u0016\u000b�����4rt�� \"���O!`e�T���q~\u0011� A��7\u0010�8+�y|8����5�����zmwե���\u0010\u0018c���~��J�[�*����\u0011>:&[L\u001e��\u000e�\u0012�\u0019t��\u0011\u0018��\u0014o\u0018�\u001c#(\u0003r���\u001b�\u001e9�#��y�����g�Kl���\u0001$�z�\u0007�':�ݒ\u0006R\u0015��� �2�!\u0007�*K����k�H�\u001d\f\u0006���\u0016 �h�m�\u001e9Ҳsa�O��G��و���T���B����GZc+��t�|\u0005����\u000f���YI�#1\f��:s�LQ$mc�Z�$\u0005p\u0003MN�������\u00191A�\u0012��\f�M����ķ!D���{1&ZJ��\u0011ȡXh�l�\u000fDF\b����\\%��\u001e@�:�7�����:a��O_��Y\u0018a��+dZ��� sRM˘�=I�+\u0005�ف\u0010|�Yφ\u001f��U[?����w }�W�.�\u0002e���r���S ��ҴJ|����`0\u0018\fn�|δ��y������h%˿\u0016�²�)���n\u0011R�\u000bњۙueϊ��o\"�v�[����\u001aVV�\u0014mo�,�U�\u0011%Jm�@����V\u0011h���w��\u0014^xe���\u0012���B�y5��C(\u000b�\b��d�R+\bW��%I\u0002\b��\u0007}\u000e\u0017��Lv\u0006\u0004P�U�\"�V\u0017��� W�;�f\u0001h=�\u00050A����)Ιd��$:��;\u001c\f\u0006��� ��L{\u0016}[R�a\u0016�M4!_�\u0013����&����,�\u0013$8U���ȹ��3k��̀�\u0006�.ǜ%� &\u0005��F ������\u0002�P~�;�f�o�{���\u0012���]���\u0004f3�n�\u0002+!�2���U���B2=�s��o�U� \u0004�WN�`�5��\u0017;��`��H\u0001L��n���VN'��\b�h�\u000b\u001c\f\u0006���\u0016��L{\u0016}�H%��l� �����%����r��Er�\u0004�*���\u0013ɶ�-ά��3��A��[�T ���K2&Bʱ�X��\u0010�\f� d%9�7�=�Vy��u��ӊ�țq\b�f��0\u001d^?��@k޴ۓ!h\u001bY��\u0005|۔����{##i.���i\u000ex$��\u001f\u0011i\u0007+g#����Ȑ��\u001d�i���뤩�?�g\u000e5@�\u0017&\u000f3�?f���6�1�\f��1�\u001c�(R����b� ��3�b�X,\u0016_ �9\u0013���W2�\u0010�s�����xML #i.���i\u000eH�\u000b�H\u0002F�\u001d����3g��!M�;�����\u001f��~\u000e\bG;�Ĭ�d�e��\u001d��\fV��f0��!��ǈo��CK~Lx}���\u000f\u0015od�X,\u0016�/\u0004�� �b�+\u0019y���d�l\u001eL�w��B�� �)��\\��Z���j��(�\u001fp���\u001b1\u0019x�1�\u0013�#�g\\�g4\u001d\u0017�_ɺ\u001a[@dKUML #i.Be�\u0001�xZ0�]�w���Nk��C C� w\u001c��;}�k\u001c\u0015p�^~�Y����1�;��\u0019����`\f'CP\u0007�\u001a9^�\u0017��\u0002������?T���b�X,�\u0013�s&\u001f#��;��C_'�l#��b�X|'��Lx\u0016���4%7E�)��f\u001d�3\u0004\u00052Fvo����`�sL�X�\u0003\u0013�� $\u001f[#��c�\u0012���#Y>kZ��]\u001c�ȥzef�#м��,����\\����\u0001\u001f9 �\u0010�w��\u001d���pk����K��@\bDu�Kkv\u0013n� �C��\br7v�!���Ȼ\u0005Q�s/�bl\u0010�΄���S)�!r3D�B+\u0004�\u0002\u000f{P6�ʐ���rk��a]=g= l����Y#��\u0018��#S#���&X��\u0016.���\u0015N�\u0003�U��^i�i�Z����\u0017�~\u0018��\b����w¯�J�Bߒ�h\u0006�\u0010I�y��ޫ���@=�ө�.�\u0011ks:\u0001�+��]GvLHB!{8 �B����R��@uI95��h4\u001a�������Ǳ�0-y\u0010�x�\u0014Z!�$Lt�?�}C &�˭e��u���4�\u0019�ߢg���c��\u001f\\+D��r���E\u000b����\u001e\u000e@1�:�\u001f�@mU���\u0017�~\u0018��\b����?\u001a�i�\u000b��h\u0006���-\b�&m\u00041�AE-��W�3\\/�jk��F��h�E�~`�\u0001]'\u001f�\u0003\u0006�&�x�����5v�u'!Ϣ�LPF���*���u\u0005o�M�s\u0015���C\u000b\u0016�\u00058�\u0007�e�xh�[x�W-��鱟��&N�e�|�T�֧��al���Є۬N�\"O~��G>#^K�&\\uM��\u001fR��3��NU�DԚY�0��_�\u0017�BϊTy>���\u0003\u0006 ?\u0005�\u001d��T�+L~+ڽ޴]�%?��㾓?�&�'��p|�\b��\u0019�\u0002o��Sp�\u0001�5��\\8�%Dc�N����)���&x�q\"��*�7�[�/| .�_�b�ݪG�J�9K��Ib՞���0�\u000e�O�����}9�#J�Ƨ�\u0002g�\u0005.� ����An�0\fD�����@\u0011��p�Q��o׀\"G�WB\u0001�]�)����KLѿ�a�\u00170��̹\f`nV\u0014����v�;�\u001b\u0011k\u0005s��Ll�;�|8zbk\u000bW\u0005b��A�\u0004\u0006����#��hW\u0001*��-���˗f�^N��5�.{s@�ؽ���F�񮗹e���\u001a��ĸ��SɓD�\u0005\u0018I�\u0006�l�~�\"2\u001cM\u0011��\fx�\u0017w]�\u0014'�K�p/�w�\u001a`��G\u0002��\u0015®\u001a�ƻ^��ڃ�Gs��>�N#��!��N���s�-5oor��a�\u0011o��#\u0003��\u000f���;��P\f\u0003}�K{�4��\u001fI�A�̔1E�R�\b�(\u001e��^S����:�OW�8��\u0005w�\u0005��۵�bmf޲�8[ׂn��\u000b�)�JmE�2��-�G���m7��*ݼ�5�\u0017���(�:^�Qw4sk�SAK�O 6!3��\u0016GT���/�\u001e�O�*�2�9G}6}�YUq�n��쉨�x�vc\u0017�ʒ�َ\u001a�e������_�\u0011�\fݣYW�n2\u0015�#��\u001b\u0005�\u00063���dOg8��f��x��|��w��)o\u0011x�\u0003+U��,�$Y��\u001c�T\u001f�(��We��\u000b(�&�$5\u001e����0n���nR�\u001e�w �É�'�=��.���˭�'μR��9\u001f�\"�TJ*΢Io�,�w�w�\u000fJ\\�خ�Y�\u0005�;�����e�\u0019�ه�j���Ί��@�m�\u0015,�N1�\u0018c��8�Ƴ�87�׭}DJ\u0017�s�5X�Do��T�(>=�>����^��W�k`U+�\u0007\u0010�\u0003����1r$0\bDQ���v��\u0012M\u0003\u001a�J�_��\u0011�h&�\u0002xO�}OXK҆bJ5�_�Y=�^Ť��xڶ��Ԧ#���\fk\f�\u0006��΁ay)sz ��՞���ӡ4��$=f��?�۸����ʩ��\f ��9\u000fJⰮu>*�qr:��0�m[E�nN\u001f�K\u0013�ͅm��G���\u0015��\u000e��љ߿���\u0003�r}?ff�tMG���lm��\u0002D\u0019�4tf9��wx�z�����R���\u000e�K6s\u0002�I՗���:�y���k��8=�\u001d���9_JT�2;\u001c�8ix�d�tX\u001e5)e\u0016�\u001bk\u000e{��m�$�0���H:���R���_��\b) �w\u0002�OX_�\u000b�ӼT8�y\\4��Ӝ9��ӿ���0Ct�쓖�ʼ��Uk�vO��_����\u001f��j�Ҹ�y/y����\u001d\u0001��όok�:~4�c��� ���\u0002?����� � \u0014\u0004P����\u0005ً��@;g\u001d!��b�\u000b�Y�h�>A�검�\u001f��\u0003��h��5G6�e\u0001���=T�f\u0019��ʿ���\u001c��h�!���ۨ.s9׵��j\u000f\u0015�Y�r�����[��H�����\u0004��\f�ݸs9l���\u0006����� \b\u0003���v\u0005�\"��\b�^�`Fn��8d\u000f�s\u000e�k��%]���*{\u0018*����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����A\u000e� \f\u0004@��jO&��\u0004�V;�\u0001�K\u0001��v�\u000e\u0012#����m����\b��~!o߇�En��}\u0018\u0014,����\u0012v�0\u0012�ڔ�ԯ+8r/��;#U���(�@+�\u0017��}5_���هA�B ��\u001d��3�\u001c���R�\u0001+hG�\u001aZ��U�lC�Ɋ�\u001d��3�\u001c���R�\u0001+hG�\u001aZ��U�lC�Ɋ!��s�����6�>��\u0006��̊�\f\u0001A�vL\u001dTu�8\u0015|�\u001e�0ï {~\\!�g�\u0010���l$d� L���+�VK��\u0002^�rO��f\u0003ǩY�\u0010!R�*-DFa�;\u0007�#�ܴ\u0014�Hu�����^�)�'�\\��7��\u001f啝�{69{\u000ePv0\u0018\f\u0006��`���J\u0001��� �#d䑀���g�/�\u0013�l�\u0005\u0003�|���fol9�E��t\u0005� WQ\u0012��\u0010�\u0001��ܯ��`�\u0007 \u0001(w�py ��_� Z\u0013�&� �\u0001A\u0018� fx�X0�\u001f�d� \"��\u0015�u\u0004�\u0018r�U\u0017\u0017\b��\u0019Lk\f7M��Y�\u0016\u001aZ{� }+�K!�f'�{�R1\u0001�\u0017�|�{��@kye3��?\u0010ac;\u0017\u0019\f\u0006��`�\u0018Pj����(���\u0005�Ĵ7\u00152���\u0004��\f�+;�fo��\u001c\u0015o�\\'&�!����6^Epܯ�����\u000b��ēc�\u000b��\u0010s����\u001d�\u0014~� \b�#lN3qa�@�Y�ʀ\fj?$��[;��Ƅ�C�Pr\u000b\u0019��E\b�+;���\u0011�P��e�C���|\u0014�#98h�p���\"��`0\u0018\f�-�'���8��ߠt\u0010��;�S13ՑO\u000ej\u0001�c�$7{+�=`���\u0007.��U�߷;�n�: ;���K\u0015�y__\\PX$JL����6\u0005�xuf���\u0017n\u0006h\u0015�u�\u000e\u0014�\u0014ƣ�Z��u�/h�GB��JW��sJ��ʁ,�h�z\u001c���\u000e�HP�͢d٘ �\\��j\u0005͗b\u000e\u0006��`0\u0018���\u001fJ�R���\u000e�sK\u000e����)\u0018����\u001e Z$\u0010Hr����\u0003f�Hy���s�/���YK��@\f��/�.\u0002\u0004y���H�\u0003\u0014��Q[\fZb犖��);�n�: ;���\u001b����z1Mkޯ}\u001f���\u0007�t�奇��Õi�Y����r����\u0019!ǡ�\u0014�FJ�uO߁�i)��K\u000b��\u000b��-ᇑq(F�q�R�c���j�h�t+��WS�xi�!��Pe�\u001dG\u0019\f\u0006��`���~��x�X���#��0������\u0004�\u0012 ƹ�[�v��,�\u001b~IH\u0005����x�\u001aA�L2�F3�WnHݷ� /7\u001bК�k��[H�=\u0016(\u0015�4� �+Ӏ�\u001f7���}�.N*j��,\u001f�\u001c'�㺧�@ڴ�]ۥ��V�{Ƅ�#��\u0018E�U���4\u000f��j�Z��ZLHY\u0012�I&��C9���`0\u0018\f\u0006�\u0010�\u000f��\"9x�Qn�a��?�`+�h��Àf�\u0004���-X;`F�d �S��W�T�ౄ\b�g��5�y�rC꾥\u0007y�ـּ_{\u0010W G�X��}�\"W#%�՝f�h�J\u0018�i\u00064��[��*\u0004_��(>h���RF:��R�aI[��� \b�\u001a��Z(F��!���n=DW�Y~�\u0015�b�_5@k��|TYi�e���`0\u0018\f\u0006��s8\u000f9�?�W��[���\u001eT+����\u0012����\u001f�Hй�[k\\.�oɌC���E�t���{&=����t[���\u0017ip��N���*��v�����YIn\u001c1\u0010���s0`�\u0017����\u0006\\=�\u001e��u\u0019�\u0015j\fr\u0010\u001c�\u001c�Q�\b�r\u001e����Uw�&-�\u0005\u0001�.�R\u0007\u0010�\u001d�\u0004c%���џ\u0011#\f�6څ�ueK���WuLZ\u001c�\u000e�\u0016V�dJ��*.M�Ȗ�خ�.\u000fϴ�\"���H )���+��؎����5`̈́�?e\b�beYRY�,\u001d_\u0005+�J�H\u0005L\b+�(�8���� ^*L`|�SXp\u0015[-�Ȫs���aTI ��d\u001b\f\u0006��`08�W\u0013��\u0002����\u001f�865��|��7\u0002y��\u001f\u0006���\u0001^��\u0002ۑ��RHF�.�R\u0007\u0013�\u001d����)�W�f\u001c\u001e�H��v���Oq)\u001b>X ��\u0002-|p�u�����'\u0015�MKq~\u0010f+�\u0002��9�\u000e8�\u001a\u001e�۩$}2@ �\u0002#b� Z�����\"�)��\u000f���K��@\b\u0003s�S�n\u0016�\u001b����T-m\u0001\u0012��s&��`���b�G,�\u001a��a��+�}���ԡ���xp9\u0006F��.�]��\\���q:\u001b�mUJ�N�e͝T\u001d�C�\u0011�s��J�R�g��6�J��l�vbG\u0010�Z�\u0015#{��v�V)�\u0005�\u0002Gʽ��b�s'Qi��� ���G�\u0011*�U�O�Z�_��\u0007Q�;�t�m�5���ͧ��@1��\u00050H�~r{�~ٮ����ו&�v�\u001a?��}�o�X�#\u0015��\u001e>v���N�UUgQמ��?r��\u001e��7ѭ��\u001b:���r��s{ �U��O�z%�J�J�l��h���]G�\u001a�|��r1�(���-�yvAm��1]�\\j��J�J\u001f\u0017��sxs?���)S�.uSd��w=B��1_���x\u0006\u001c\u001f\u001c\u0006\u001fk�8�G\u0001~�8\u0003�\u000f\u000e��5�}���\u0017~�8�\u000e\u000e��5��\u0003����� �0\f\u0004��_u �\u0016\u0004�g*�8�C�\u0001�m���t�\u0003b�5�A� v~Qs\u001cMj@��\u00060�Y��Q�£��\f����]�q$\u0007\u0004��U+��G����\u0017����\u0001\u0001�����\b�\u001a����1\u0001\f\u0002��/�.3�@\u0002��ZGH\u001e����ˎ� \f���Ow\u000f+UZ%e�\u001b��6�a\u0019��kg���\u0014�{[$�\u0015V����7 �\u000b\u0013�9�\u0003���3�>��K��OX]���]���U 6��g\u0017\u0018�F0,���L�V�byo�\u0004�a\u0015\u0003㯀Q2����/\u0019\u0010G\u0002�\u0005W\u0006���u1��p����J\u0001��a��\u0002ƴ\u0011\f�;�h���\u0014�{[$@\u000f�\u0018�Be|�\u001a���\u0007đp���g0�$��\u001fc���݊�\u0013a�\u0002�'q|�>t�{_CI�m�K\u0001^y��la�Y��^\u000f\u0015mb�������yS�\u001e��b1c�r\u0019\u0004��\u0019DE�JZ ��Z\u0014����E�����J ( � 5JF\u001b�\u00159p0l�R�S{o\u0003Ť=����ۘO�z�A�\u0014�d� 8�7\u001c۰�z3]Jf�\u0017[��c�\u001c��Ju\u0016j�J\u0017\u0016��\u0013���з��S�S�\u0013F�g1,3��\\Ğ(���\u0013e����I�\u001a\u0015�Z\fҳI���5|��\u001f8}���G�/��{Vt�\f�d�\u0019��E���0#�i.��H,�(/�K��c˱m\u000e�U���E�ň\u0013�n���{2��@E�\u0014���\u001d(--��gP]�PI\u0019� q��v�\u0005�$\u0019�tK����\u0017����r�0\fC��?�=5��\u0012�\bR�����\"@\u0010ԎR����v\u0019�,c\"�����na���0\u0016�\u000f�(ĳi�mXm���[�8��� �/k�D�&���-�\u0011\u0005O�W�!�:��TP�s8\u0011\u0019ٰ\u001d��\u0003�\u0002vᑆ �h��F��\u0013�Vx=~�p�\u001d�����N��-���\u0016�\u001a\f\u0006��o\u0003|SROՓ�m-�\\�\u0014�w�xm�f�S\u0016��#\u0001o\u000b\u001ekW�$d��\fM2#)�s\b��\\ n;T0�\u0013���O�b�(\u001e�',���|R ���45oMbI����`0\u0018\f����~�*��ە���\u0005�\u0013|�oH\u0014�vG�RY_���v��\f��?,�\u0014�ŉ�P�Dw��2�^z%�s�п�OX�i�s��\u0014Ȋ�\u0005��6���\u0002��\u001d�����v�ĕF�fÑC\u0003E�\u0006\b��# �\u0014�&UP\u001f�3L�\u0005+T��0����\u000e��ԡ>����Y��\u001d����\f��ș�'tE��\u0016G�SO\u0011\u001c�ۚt��m�\u0001� A��[��1&_���K�u�҃��Rj\u0011Nmww-��B\u0004\u001b��\u000b!�Lhr\u000e\u0011�����t)Dv�P�؊zw��K���Zd�ԭ�y,���@\u000e\u000e\u000e\u000e\u000e\u000e�\u0002ދ\u0019�&\u0010��2�;��FF�Z��qo�4����/ΝƗ�Zǝ�a/\u001f�%��\f\u0018�,�2p)/�\"ޖ\">\u0001�7�+\u0013���\u0013Θ@\u001b!�H�B$8�o)�_���՞g-�\u0004�\u0011\u0012��&��X�Ru\u0015\u0017��\u0007�\u0019`ԗ�[����9��\u001a�%\u0017�G_�5�[����[\u001a�J`ܖ8S��Xg�~S�d�\u000bJcz\u0013����ť���G\u001b��-�;B{T0�[ �\u001b>��+�@5��\u0018Q]\bAQ؆c\u0014�׽KL��J�\u0003d!ˁN\"�0\f�Ӑ~\u0019�/&s$\u001b�v�\u0003�gF�9�\u000fU�]>��\u001a�]��\u0018IZ23�R�R��s�\u001fj��\u001e\"\u0006�;9\u0006XO9�Q���*�:\u0016Z\u001e \u0012�h��Ӏ\u0016M3Ф]6\u0019apw$\u000b�\u001c\u001f\u001d�;ߌV]a�*��%�] \u0002\u001ebN��\u0007\u001c�Ɗ�a~��\u001c4�\u001cU-�V��N\u001bр\u0010��#���\b��{/����g�d�� o\u0010��_�c�'i�\u000b٬��J��U6u8e@{��cZއ���jB\u0002�6�\u000b�t\u00112g�[����&@\u000e�&�_���)ۇ�3�N��\u000b�P�h0 �.�\u001b��\fdW�ʎ�[;\u0014ފ\u0007\\\u0019�a\u0018�a\u0018\u0017�_���1\f�\u0007o�G��@0>\u0004�O\u0012� �*o�T �0\f��� ����A �0\f\u0004@��jϢ���F�̹�B�@�PW]\u001b��\u0010��v\f\u0004搝R�T�hU����[�9�;�SJ�I\u0017� �Zum�cBR8�1\u0010\u0018EvJ�:�U\u0001X+m�\u0016L\b���0\u0010�@vʛ{a(�FZ\u0015���j} =�,�}\u0006\u0002s(f\u001e\u001dO�/5����\u0013����1\u000e \b\u0003�����Y\u0006'��}��\u0004��\u001d7z;>��ꠁ�\u0004\"ME6�x\u000e��̄\u0010 �\u0005\u0003�_%�p\"�@U\u0001�\u0005����\u0001\u0001�����\b�\u001a����Q\u000e� \u0010\u0005@�i��\u001f\u001b\u0003�\b���\u001c��{@Vh����\u0015��}Z�����N2t8\u001eE\b���ʓC��°�S�\u0003| 'Tt�LB�@X�/�lm+\u0016���3H�\u000eǣ\b!\u0018uTyrȳS��xS\\����\u0004�M�I(\u001a�Ϭ2���ĩ�O_�d�pn��+�x�~IjU�4�\u0006\u00029B�Zx��>�\u001c�L-�'e=�\u0010�I8��b\u0012�0����:��ǭ�i�R+�Z�2͠\u0001�@���\u0016�v��8#G$S��IY�&�d\u0012�#���9L���N��q�}\u001a�Ԋ�V�L3h �#d�U�ݓG��#�)d���G\u0013B2��\u0011UL�\u001c��vqL�����>�Wj�U�Z�\u00194\u0010�\u0011�\u0017����\u0011\u0013\u001c�L\u0015!��\u001eM\bɤ\u001aG`1�r����3:���\u0003�_����\u0001����r�0\bC���t���I�8\b;mw��: �p�d�\u000fЎl�E�F��h����~7����l��\u000eU�R�\u0016ګ�����Ǖ���iǇFe\u001df\u000e�N1�����*աP�D��!�\b��4�4%�h�&�J����_�����\u0013TF�.`话��.�xN�a�;�\u0018 2r\u0011�&Rg:)#�p\\go����V�\u001b\u000f���ezC�O�҄���0\bI����g{JX�nyζ8\u001a�F�ш��y��\u0001�F�V��j��#xN�e!�M�����V�G\u001b\u000b7�\u0010E\u000e��x;i\u0014�8��I\u0013}�u�\u0005$������\u0012�D[�a��4�f&C��K�����J]\u0011ϭ�^��_�6S�\u0001E/�l��e��\u0007-;N�h��{�������\"GH���9��k[�L����\u0012\u000eiAj\u001eI�e��(5�����( �`{�.\u00157Ii�\u001ds^(\u0010:͟�E��\u0002�q\u0006�\u000ek\u0007�u�i��\u0005i�\u0016�R��j�|��\u001f���A�#1\bC}�Kgvy�.[\b �,в#�\u0007j�j4\u001a�F#I�+X�x �\u001d���\u000e���\f\b�@\u0017��l�'i�ђ�\u000b���*�1\u0017�*Oa�`^�\u0001#�\u0001\u0018�\u0006U΢�=�\u001d߶S�3�\\\u0015N��wf��F�_H6�dէr��\u0001�;���\u0007��-eIB\u0018�s2h�O��p�����\u001e\u0019�)v}��O\u0017� ����B.\u000fŇ𓖄�\u0019d6�;���c\u000f�1��\u001d\u0004�U\u0019^��w����O .%�%�k4\u001a�F����7�����7?Bx�\u001dZ���O�k��I�`���h>?�ҒK�yZ&��\u0006�R\u000e����\u0007֪¦ �\u0019G�\u0002�\u001a�3�s5F�B�!\f\u0015�Mݷ�o���ƚ�M�\u001d�9\u0019�\u001d2MA2��� ��!\u001d��S�?�5��\u001c���bkӮ 0�N&�u��!d��ϲ�\u001d�\u001cVX���\u0017�\"��Pr)y.y]��h4\u001a�L�o᧍}��\u00012d6���\u001a֧0@�����)�[�S!?B�\u000b�\u001ca3\u001a�u\u0016��\u0006�:8�\u0001�O��M ULS\\Ũ�\u0016�4*s�\u0010��H^���P��¾U��\u001e�N�M�x\u000f�av�d�ڵ�M�UhS����`�i��\u0018�y��,��C�EU���\u0010L�\u000f �S>\u000f���'�I/\\v%�`���G��_����h4\u001a�F�ȷ��ƿ���\u00192���n k'�!\u0013\u0016�R\bc�͡ C�%�\f�ͼ�3�v�\u000b\u0006�R\u000e\u0018�];ɜ%�Lf8��W\u001cKb�\"g,|f�Y:����Ʀl�j\u001d��K�20?�\u0007��3v�T�Q�l >ax\\9�鈟�p\u0015M`U9LZ�\u0005M\u00039����A\b�:���\u0006���v {�S�0��R��M\u000b �D�M���\\ox�x�d�h4\u001a�F�nɟ\u0001��\u001b;�\u001c�[�&m���G\u0018F ,��\u0010F�[Ֆ�=\b]H�f^�ju?e�/倥j���\u0001��flX\u0012��\u00179�֦Q��\u0014^�̯�Mٞ$�¾U��\u001eȎa�:�o BB��P˶\u001eό\u001c\u000b\u001a�2�\u000f��\b����\u000bO�c�N�|�.\fH:���\u0006��\u0016�\\\u0005?\u0005 Sr,~\u0010�i�\u0001\u000f��&��@^�d�\u0017B\u0002�F��\u000f�\u001f����n�0\fC��?==,:�Ll��S�. ^KQ$��F\u001b��\u001d�3@��\u001d3\u0015\u001d�V9�V�����SY �x�A{bἄ�v�\u0006�LBy�:@��\"Ɣ��5�\u001b�rJd�#�Hy�5Ni���p�\u0012�ZY��\u001d����Ѓ�K�\u001dk\u0010\u0003�x�R\u0010��\u001e���o7*?� ��D-\u0016�K�/G$dS\\?�\u0003\u0001E�1\u001dN S%��\u001aS��B4sǱ� ��BB\u001c��I�o�x�\u0015�\u0017\"\u001ah4\u001a�F�Q\u000e�\u0019������\u000e|��t�\"�\u001e�Rh���{ ��l��\u001a4xe\u0012�;�\u0001\u0002�\u00141�]D�*7�Z7���:���>U\u0012b�+Æ+�\u0005^�P�V\u0016n_ �Wų=�[�v�D��/>�^�������8�^\u0005wx�����ޗ#\u0012�\b\u0001M\u001c�����J�\u0013�T�������\u0010�T\u001dK\f\"J\u0015\u0012�P\u001eN�\u0013�K�h�\u0010�@��h4\u001a�r����w�Tt�[�[�j� t��*3^o%\u000e�R�mYm4h��$�w�\u0003\u0004~)b,�}\\�aCv���K *�\f\u001b�\u001e�ڃ����O�A҆h�|\u000f� (;.��\u0004�[Δ@\\��P�\u0005����(����|6|)_\u0011\u0010D{+ZI��H�a�PD��cnS�\u001a��#Y�f\bmJȖ�r;�/a}KJvE�W&��c\u001d �K\u0011c��ө� 4\f��rb��:P9�!� f��&�V?�:�y�H���S=l\u0017�~\u001b�\u0013��`p˙\u0012�YW���_�[�x�ݿWE�$뙗9���n��\u0002�hoEK�ˊg��[\u0018:�a��\u0012�%�߃)�T�U�\u0012��R\u0007\b_�-簽+\u0001��\u0017�Rh4\u001a�F�Q��3�j6%\u0002�*'�N \u000bcO��ٛ-�\u0018',a �h4\u001a�F�C\"_��s�\u000f�x$��D���GXJT�=\u0001\u0013��E��\u0004,w\u0014F��\u0004��ud�\u000e13�� B�\u0016����XRi�\f\u0002WgS�.�R\u000ē��8�\"�N\u0005��ҺZ�\u001fl���\u001dbɱA�\u0012�IץH�r���H`vO�)�\"�\u0005�� �R�.$��\u0010���t��\f�6���yp��R��\u0016p�FJ+�y����?7 w#���ˆx�|\u0010�����B\u001b+_���t�\u0015\fM?\u001a\u0015X�/\u001b���Q��y\u0001j:\u0005rrG��y\u0001j:\u0005rrA��y\u0001j:\u0005rrA��y\u0001j:\u0005��\u001f���ݱ\fEA���V4��\u0017�� E��w�D�=�\u0004w����\u0005�{1ʑ5Ny0[ĩ��ū\u000b�B)/S�\u0005�&�#��\u000f)1�cĀ���z��c\\\u0019��toZjIZ޼\u0017\u0012�л��0�������?�\u000e��\u000bU�&���VT�/��,�M\u000b����k�v\u001e���-�m\u0011�?i���\u0011���^YW�|Y#-4\u0017���\u0010� 9�h%4.�\u0006Br�$\u0015׊`�GB\u0012�x;w�ä M\u0010��y]B�\u001d #�C�7\u0019��\u0001k̷����\"x�x�ڶ\\G8��\u001d���u��mlllll|)ȗ\u0007�m^��G�\u001arM ����'���h\u0003�P���M2$\u0001�&v��\u0019j5Jmw44�\u001d��ѥ\u0012��a�\u0016��\u0018�]\u001a9�}�\u0011BI\u000b�!A\u000b��\u0004�F]\u0013b��\u0011Mv������q�\\����\u0012��F-m7�\u0007 ɥ�T\\+����\u0007WX\u0011�l0��MֱU�F���}�������/E�5����\u000f�\u001b����/\u0003�beO.����(�E�>�Ӷ�w\\�8x�x�x\u001e1�����в�M_8B�L�*�9�w��H\u001f'��i��7�\u0010�]}�\\�� �-�w�������B\u000b{(�\u0007nip�\u0015!I>�!���\u000b�d\u001d[U���O�I\u000e�������u8� >'�?�dh��\u0016\u0004���\u0019u\u0019�Kf^�-1�[�p��0^�G\u0013O�'��\u0005�&�#Z4>:_Ap\u001e]߶��觭� 煖h\u0007 0$�buܑ��CC�3�[q�y�gE�\u0004������eI$�\"��ϡ�\u0010ʉW�\u0011�5�S\u0004r\u001dᜤjiW\u001c\u0003a�z��;4��B��-��c\u0007.3�M�]�8\u0001��r^K7�T\u0006ϖ\f�*����f� �)3å666666�\u0002S/5�z\u001d\u001f����/\u0003�F�����WdK���5/��h��+9������Y�n�0\u0010���t�P��ll\u0006\u0003N���x�\u0001�R���R��p���\u0014�Z,�xk�\u0005�����Ӛ%) �J�S�%`\u001aY^2S9g%��\u0005&8ʼ����\u001e�%�k\u0016s�[Ð��T>d�\u001dɛ�Mx���Z3'���3ά�\u0019j�r~�C���\u001e�� ��9��[�'���,��P�\b��$d\f\u001e�\u001e��Q\u0012�s4\u001a�F�!�Q+\u001f*AS�{ \b�\u0003�,��K�?\"��Aq�Z\u0016ц������Z9a)��X���~\u000b��o��Q��!�\"�Y\u0002���%3���|��i >�)n���E��,��f_�%@V�\u0019�ّّ�٭�\u0007�b�qL��%S\u0001����\u0019j�r~�Cf6��\u001a^\u001f��\"�s��\u0015��O\b��Y��a�4e˒��u8{�S��\u0004\u0017�h4\u001a���G������gd>��\u0007\fYLDNɃ₵,� ُ�aN�\u001f����\u0014��;�\fp�\u001b���+��D�C�Ej�\u0004L#�Kf$��\u0018��c\u0019����gF�G\u0001�f�ۚ}� �Y\u0001f`gGfG�.6\u0011\u001e�K��\u001b������e��0)}9?�ٸ\"���U\u001cg�\"�s��\u0015��O\b��Y���\u0013�-K�����QNe�\u0013Y\\��h4\u001a���G�8c�����O&�\u0001C���%�\u001f�S�`-�hC��a�\u00138��Q��H^\u0010o���\u000e��70��\u0002\u0001x�y\u000fC�S{[H��d�9g?��%�ؚ��%�ѕ\u0016٣��\u001b�=�be �\u0015 og�|�4;�7���`_�:�V�ډ=���r\u0003X-\u001b&�/\u0007��.\u00102�܏�Z�ɯ&���\u0001x�!35\u0016>pi�E\"��~M��|�XVE��iن�U~\u0004�\u001e�Tf;��4\u001a�F��YX�����PS~�`S�{ \b�\u0003�,'ݵd��-\\�H\u001a/~[�a\u001cڐ��P�����ޖ�J;ΐ-�6#7p�E������Ü�\"۔\b����Kr�@\fCu�K{v�X� �C9�*b7\u0016\b>��(Z��X\u001e�͙LG�\u0003u���,u\\��-Z�ػ���O��+����H�'[r�p���\u000f\u0019�p.���P�\u0005ݯ�e}��p_�|_~\"��_\u0019�K%TL- !�Ʉm\u000e��O���/���f�o\u0006i!\u0012��I��O�k�3�kQ�C���d�����N�;�T�8]'\u0018�F���[D�:OOO\u001f�̼i��\u0006\u0006\u001e�r2�u�\u000b�\u000f!��}y����\\ � s�\u000b�?\u0004�DH��Z\u001a1�gZ�\u0003�\u0018\fdxnUF�|\u001b�AKOn(mjB#g8\u001dI\u000e�ި���'�7�QkAk&\u0001�6:J给�\u0012�j*��In��\u001a�hH.�P1�'�\u0017�\u001d�*\u0007'7�;�=����\u001b�lv�T�{�Tot�$�]S���\f!��V\u000er�\u000b�p�JK�Q�J��:�h4\u001a�Fߢk�ɳ���ml��x_�l�tF��Sn\u0006\u0003�\u0018\fg�,ž>5�J��N�kѩ�9��\u001cޟ\u00132 'C�yP�\u0001��\u0002�ǖ���%mC2$�$\u001ec(m\u0012��\u000f\f�t��@Lµ����l3\u0013\u001e�)Ւ�O�熵����XՐܨ���*������u�TBE�n\u001f���\u0012#rj�ˣ;\f�K�7*Ol`o?�;bಖ�$Y�[\u00031�dw#?!\u000f\u0019Br{�k��SF�\f�!$�d��\u0013�F��h�-Z_�[m��خ�Lrh(\u0001��\u0006\u001e����\u0014R�\u001b`d�s��\u0018� \u0018.N���FIMs�rK�SlHF(=���2K筄���K'�\u0019ʵ$���306~ ^���E�g\u00072�\u0007������ ̗�cJ�|�Sm�\u001f��\u0002���T~3x\u0013��\u0006R�\u0010\u001a��J�)��>zU?%F%���\u001d��\u0012y�\u0017\u0018l�F\u001ef\u0015\f\u0012N���v��r��l�,7F� !y2�z���(\u001e����Z K$z\u0013��h4\u001a��R_���0_��yk>_���!�O\u0012n\u000b�\u0016\f\u0003ж�N#�Z\u0006�\u0019N��K^\u0013r�� �#0�'\bq\b\u0013Δ'#�c�6{��s�H��h��my�\u0007\u0010��n���w��\u001e�k�8qӵ�o�%%�f\\��F'���od�j��\u001ac+���\u001e�{��T^�m�J\u0010�ŘZ,�:��6=�ʯ\f\u001et��\u001eK�\fb�i��\u0014YO#���(44�\u001a~��\u0019\u000bR���z�� \u0002}v���\u0018��\u0015��\u001d�)t}�h�\u0002\u0015���qc�a�o¯�3\"�%Y�l��CJ�*�䌷qh���l�V϶\u0012w���zI,��z9�n\u0007I�Xu\u0011'�N�ǂ��О�U��6��ӥ|\u0014���T*q �B/���.��Ւj�\u0011���\f�>�FzZo��m�\u0002xi�ر86\u0011�\u0018�TR)\u0004��n�lFG=s,(&\u001f�(���)\u001f�S����B%dq ��s�;�i/��oϤ%�\u0013�s\u0019�\u000f~M����\u0019��\u0015��!�\u0016�>������m6\u001e?�6����+\u0012���\u0011\b�đ�W9u�dk��u�a�F��I�Xy�]�`-����I\\yӎ\u001d�S�`�ݷ\u001a��\u001d^�ZZ\u001b��\u0011��]�qV%]��k���F�5��zTVZ7�_���O\u001a\u0007� ?\u001b\u001e\u000e\u000f�X\u0002@ �@���\u0007\b���!��\u0012��\u0005\u0002��?@\u001e\u000e\u000f�\u00076��/\u0010�?���ڱ �@\f\u0003@�����o�\"��w\u0013`$��\u001e��\u0002�)��\u001f��\u001c\u0010`=\u0003\b4�Y�w��P%�Q\f �\\`I���? FR\"`7C\"4�Y���PN��Ŏ��� �GxI��B��\u0003\u0002�t\u0003����\u0001\u0001�����\b�\u001a�����\u000e� \bP����:ա�R�⽻�'PI�\u0004y\u001c��x֥)iSG�e������S=��C�92\f��iz��Sy�\u001a\u0017��\u0014'.d��C�疊)�6\u0003M��_��}��@_\u0015Q��5N\u0002`5��g����됢)��>b\u001enk(����\u001eÉ��\b�^�\u0015\u0006}��kG����\u001e\u001de)Tj��S�ֈ��>x������th�\u0015\u001abZ�9����XN��gL � ��'e��Y\u000ba5�x�Xn4�\u001bY5E|֏�!\u0007}f�\u0013ߵ��˧�j�\u0012�z�\u000f;�s��z�� Y�[\b����C��M*��9B�\u0015���\u00150�\u0018c�y��:�7�K.6ۮ��9���K�r���Ȫ)�~\u000e\u000f9�c\u001b���!\"g�ׯ\u001ex�j{���p�\u0004Voי��\u000b�m����* `�N�K���\u00155�\u0018c�7��:�7�K.6��]��1e\u001f�T,7�؍��\">��>�ӝ_�3�����\u001f���ϱ)�\u0006�Ȣ\u0014\u0018\f���͂NF'�ʂ)x\u00178����q�}�e���\u001b�6\u001cB�G\u0007�{+� �x�����\u0004������?fǍ\u0006\u000e\u0005͍\u001dIc�\u0007�\u000b{��1�|\u0002 �\"��?u�*�*�8��Zb�\u0011 �P������a ����s~4D�\u0014x�f۵�I= R9\u001ax��u���S-i��R,.Ү弻�\u0004�w����;\u0015��\u000e�!+£P���ۮ:\f�\u0003^9�A\u0014'%��\u00071�Hy�ķ\u0004��\"+�!�BD���\u0006�S\u0012\u000eQ���!�\u0001D��h*��\u0015�I�W�����5m\"8\u0018\f\u0006��@���k|�ɣ�J�+W�\u0005P\u001eK�21@�8�SN`z��n���w*\"\u0001�$R]�G�0[\u0003�]�\u0019X\u001bJf���,K\u001fD�j-���=���6+���]��vi\u001d}[wM\u0016��u\u0005(\u0002Wp�!^2xJ��1r�N����| �@K�\u001cR�ZxC�U��\u0001���VKv�@\b��_����dl�\u000f�lв\u0016B\u0002R�Թ�5�O\"e�&�s� �Bn�Py>�Ƙ ��\u0001��\u0013�E\u0012��`0\u0018\f\u0006\f���\u0017�y;'\u001f\u0015]\"^��I#}\u0011�ʒ���.�� ��!�O����w*$!ܻ}\u000f����K�v \u0013y�'\f\b)� ������#$k�\u0007\")��e�[����9��d�y�����G\u0014�Pn ^>5�$�� ��\"���\u001d�6|;\u0007@Hv��;\u0012�\u001a3\u0004%�� ~\u001d�Q$�'�␘��� �a�\u0016\u0006�\f����\f'\u0016�JX~\u0005W\u0001\bL�d�4oh��T)�i�f=��_JM�\u0003����r�0\fC��?�{��NF�(\u0010�bo�ީ�P ��� �A���\u0011}\u001e\u0006��\u0004]Jy,y\u001f�~m��\u001c�*d\u0005řa^�U��5�z%�5��\u00197����NOe��\u0003�~����EIN��\u0018��R\u001f��z\u0018�Vו\b��l3�\u001eDe�RK���*f*�jX?+ʦ̋���m����\u0019ѳQ�h@Y��\u0018{���@�\u001fˮ��y%�hR9�U��*���+�/��\u001a=\f�Ş�&[�{g\u0015e��v��]�^�r[�ە�J�z +\u001d/�pD�\u0012��^*��Z�\u0005��\u0013&\u001bc\u0006:[� ��u,�.�CKu���'��Q�z\u0006X�(\"�L�\u0018�=x�-�.\u001b�� �(â�>�r���UR\u0003�ۤ7Y��*\"�\u0019\u0005~�p�얖\b[���� Ò\u001d$��^�]\u0014\u001c�b�\u0017�+n��^!���D\u0003����W߻�pE���i4sh>%�g��z����C�CeF�}��@��Ҩ/��\u0012W�]m�G�1;B,�(�4�S�W����]:��^��ȡ����HV���\u0018�\u001b\u0003�?�1N,}��0�U�^�ˊ/M���=��Ӗ�~�\u000e=����S��W�\u0014����\u0012o\f2��E\b�\u001c��^o٢l��\u0005��i��1p{𕙩=O�����|�ۃ`��\u0019�T\f+��o�����\u001d��au��ϩ�coӵ��Z5�=Wр1�5�\u000e����E\u0003\u0002x�\u0007��\u0004Z��&@\u001b�.�(b\u001fҌ��G\u0001�\u0019�.@\u0014�\u000f�\u0014�7\u0001����!\u0001\f\u0002����\u0018\u0012�[\b@0�?��\u000bp��\u0007���>@\u0005����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����A\u0016� \b\u0005����]����D�0��\"���J�OO��\u0019M��L>��\u001c��#Dfs��q1��C��h)m1�e���#�i׫�������i,��n\u0015��}��\u001f�k~=����\f�1��ˡ\u001f�\u0010Y�\u0015V�p�\u0015�#��2�e\u001akn�[\u000e\u001b�W�\u0004�Tx֦e��F\u00109�\u001cs\b\u001c���o���q�v���7�#ˡ\u0013�\u0010Y�\u0015V�X�E�Q�ӥ��4�ܮw�\u0013�Q�j�3~o����ђ�0\bD����޷�ݪ1A!@�=�3 ��1�h�}�XTG�\u0015�_�i�\u0002�^�Ww�q\u0017�:�(V�o\u000e��a\u0011q\b��� �\u000e_rP\u0015��z��P���,p���+��\u0002\u0007��`0\u0018\u001c\u000b����Y��K\u001a@�����>+�l?i����a���\u001a\u0019\u0003O�F�7FKɤ��\u001d�T�2\u001bU\u0003\u001f��F�Uc�hoQ32\u0006�ڡ�Ԫ��K\u0006��偼`li��&z�%�\"G��\u0012!r~[�| �\u0007ySŻ��\u001c��˄\u00024�U��ZQZ\u0002�Q\u0007%��f\u0014\u0019����\bi��-C�{V�G�\fx�-S�뗶}Hn'u�����-?���C��Sqf#\u0019g���\u0019ʹ�u���C��DRx\u0016g$M\u0002���\u0001&]j\fG�R���=��_�\u0017k\u0018S���\u0003\bQ?��\u0014s+N\"�v���\u0013^$R�\u0006�,���l �`�\u000ft��\u001eZ\u0004��Z\u001dᔶLb���%��\u0014�\u001bє�uc��\u0013�u��\u0011��@ʍ9�\u000e��hM�\u000fAóʙ\u001f�\u0014{m�k\\�;��`0\u0018\f\u0006_\f�\u0012��0�5rF�8���9\u0016#��\u0016�Dq�h !oGL Z2�f�E� �v��)�\u00173^Y��{[�{�,b\u0005�����\b ��d����A��-�>\u0017J\u0010\u001c�X%>���]��P�Y��\u0011@�+\u001c�a�=K>M[ \u0004�Fb9�\u001c�J �t��(\"ƨ�#�i�;�\u001bS��6\u0019û#\u001b�XwBPbǁ�\u001bs�\u000b\u0015�J_:4q/x�ٷ\u0014\u0004��g\u0018�\u0011fkn��`0\u0018\f>\u001c�[����B���o\"W\u000e��c1�9�(�\u001a-����~O��[��r\u0001r&�ArM%\u0019��\u001bʲV�[�\"�3�v�~�@I��j\u0018QS�~L�x�B\\E����1�\u0014謼���Tk\u0011��\u0011�b{ϐ\u001b��K�>�^c{\u0014�Tߺs��\u001c\u0001R�\u000f�+W�r}-�xmD[� \u0014@\u001b���A+[f�,i v0\u0018\f\u0006��\u0017\u0003�\u0004�3�uȹ��&â���31�9�ś(n\u0019�����\b�����n#1\fC��?�=\u0014\b�3��H�A\u0013��6CQ$u���>+fx\u0016�\f8Ro0KW�-�e\u001f\"�H���U�@��)�\u0007��*\bA����B�@p��Fۏ�`��\u001a��NT�D�b\u001e*\u001c\"�ꊇnYa{�F�^dc�N�\u0006�4UA՗�x�e��5�7�\u001e\f\u0006��`�\u001d /��3��!���9d�([��{j�=���xK��Zze#��7Ze\u0005d�Tǳt\u0015h�?�P�e���!�\u001a���\u0013p\u0011��.��a~\u0005\u001eӰ�\f�I\u0015v�\u0013\u001bՆ�O�|��BP/�9��z#\u0010\u001c����7X,�fp�\u0019�j�ؒf(�#4\u0006���\u0003�ʪ���4�����\u000f�h���/m�`���k\u0014o\\=\u0018\f\u0006���;@^\u0002�g�DH9�,G\u0013\u0015e�xO���O�V\u0014o���*\u0019U��h�\u0007�ɫ�9]��R#�P�e�2�q�\u0010� �'�q\b�ݭg\u0018^!�J����K�ˑx)�If��@AJ�BHg -M�J��&1�9O���`0\u0018\f�\u0018�C�~��[���W͡D�?!�8?T#����\u0015��Ѥ\bv�ʮz4ۃ�6%\u0004h1�iJq�P�7�P\u001c��_Si\u000f�'\u0004\u0014ᩋ�\u000e\u0019�� �,\u0007\u0003�\u0017jG�{ ~үˍҸݤA�W�ↇ�Ɖ�)\u000e�\\i>�LH�;�]a���s��w�\u0010\u0002�z��[�}��\u0019�\u0004�\u0006m��j)/�\u0001}��� /��JV\u001f-v0\u0018\f\u0006����qC\u000b�PHu��\"�#\u0010��\u0011�)e$6��\u0013��z��W���l�����=Zl�D�\u0007ک�i�C*E�p}ɘ\u0011*p��w�zIX�Ê$ϻOq̋I\u0002b,^\u0017;�\u0016\u001d2\fg�����\u001djG\b��Z0�k`�{�FB���~\u000ff/:���\u0013\u0019S��\u0007Eő�#�O)]���c�@jT\u0005��_ξ���\u0010���nK�=��M��k��@K���p!�:�Oܶ�\u001f#5�� �aX�_,v0\u0018\f\u0006�����X> R\u0002�JE�7#��,\u0012�Y�ŨE�w�C�׼5�\u0013)^Q���J�vE#j\u0017MBS��!��k�\u001fc�n�Pv�s�W�v��]/������n�0\b\u0005����VjC00ǭ�y�\f��i�)K�S%�}j[�\u0003��̬�\u0017�\u001d�7�/^M������U���L���?޴H�87�d�͎�T��\u0002ŝ|NL�����O�3b\u001f�m���y{o�\u001f�XU�pӬ��oz���!�.R�+ T�?E���^�FJ��p}�ɂ\u000fP v�%Ҋ��m��\u000e����nt�(!�¬�GQ�az%��睉�\u001c=�Z��n(#M���5��`�7���2KY.���*��H�ˑbTz[F9��I��\u001c�\u001b˂��.��\u000f3E�%M��7�\u0017�K\u000e6-�/%!�{�C\\\u000e0\u001d�5Y��;Q/պ\u0011��L�\u001a:��-�>\u0015G\u0007>.�w��Y�(�\u0015���C���\u001d��\u001d�����\u001f�_�o��x�O|�\u0014\u00044 J������u�>�Co#No:Կl�������\u0014)�^_n\u001c�� b�Fm�\"�\u0002}�y�o�׏[��ş�V�~K��p\u001a�7%�����������nRO�8��c�/x?]�P2=���\u001bG���\u001b�S\u0013�C\\�mÞ\u0001��mK�?��\u0012K\u001aV���Y9�&��ʊ#ӯ+�v�I=��о�V��OOT\u0010�K�Wէ\u0013i^�v\b�� ($��a�\u0015��|����L\u0010�w\u0015l\u000bo�\u0013s�ҳ�H�u\u0015�\u001f�T�\f\u000b�9�y�֫\u001e��K�Wէ\u0013i^�i\u000eN5@�7����1\u0012�0\bDQ���I�Ʋaa�����\u0006!��\b�C܏�a�+2}��ۧ�k��J\u0010�\u0014�n\u000bO\u0001��\u0012{�ϸQz~'�^C���\u001b��\u0006:�\u0006��m�}�{Su:�*I���\u0013�bַ8]\u0005��Z'�\u0001�\u0002����\u001ck=��)XY\u0015��r�o�\u000e�H�S�T��$��\u0010O�\u000f|(�Ha�$��_\u001b\u000f%��$��vL��i)���:�2@\\��\u000b�j|P�T�S\u0017�ڷT\u0007c$�\u001a6�%?Io0�#fmJ却��~�\u0017�C�%���۟��l\u0006}0Jc`֖V�K�\u0014��S�\u001f)�L�|�4�RCi��\u0018�S�\u001d�F\\j�{�#���q��R\u001e�.X�4�.r��>Yc|{\u001af��y|M�\u000fF�kz�TXZv/�ٴj���_��p�$ͯԐƬ\u0013��ߒF����� ����K\u000e�0\f\u0005��ߺ�. $�\u0004\u001a��m��c�.\\\u0015� �.�~�V�]٠��y�v^;\u001bI.7�e��e��\u001f\u001d� �a��Yd��Y�E�ͦM�\u001f{D0-eM���Eٱ���`�!�&\\���\u001e���Ǳny�\u0004��\u0006����I\u000e� \b����W�&\u00141b�Μ\u0001�\u001bD���\u0006/t�3�1���3�2�m�?&\u0006\u0001�\u0012�,��{\u000f|��ެ���'j�����}>���� c\u000eࠕO\u0019�\u001c�Af\u001c��\u0002���ݱ\bEA���\u0001�\u0006�`r7�\u000f�+��\\��8��ֿ�\u001a\u0007�߈�Fn�\u0007�s�8�h\u001c�e\u0002���α 0\fð����5\u001f$(�I�.K2���\f_{����1��P\u0018�q�\u001c3�%��\b�@�*�� \b�;�!\\Z�\u0004!\u001al�KHCKScM �޸�K����r��7�\u001c���\u001f\u000e/�]\u001fO��m��\u0006Aຮ�y������~_\u0014Ż\u0017\u0004��,ˢ(��c�$a\u0018j���PUu0\u0018�V�*ɟ\u000e�K\\��4M\u0017��l6�,��횦��j]pH)��v5\b!z�^\u001cǧ��~��{k�=\u001e����l�㱔R\b�(J���4��8\f�\u0018�F����}]���*��t�,{=�\u0001�c���z�\u000e�`8\u001c6\u001a����O�mO&\u0013���(���p8�v��tj\u0018F�ժbB��rɝ\u000e���\u0013����1��@\u0014���&88�\u0019\u0011leY6�ϵ�oO�锻U�1���t:y�7\u001c\u000e���\u0012�eY�Ng�\\VO����)����*�r8\u001c�\u0010�$ɲ�z�~�*@�[\u0015��j2����8���w\u0013����������m�����q\u001c�\u0010F��r��������^���Uo�9�\u001fR�eQ\u0014��*��e�t:=\u001e��\u0013�x\u000f� ���\u0012�ǣ�鸮��j�Z��1y+�9�w��%�M�Hk������\u001a{��>\u001c\u000ei�\u0006��\b���h��y۶���[N^�̸�p\u001cg���f�q�ݺݮـeY�6���0\u0018��紧\u0003>�\u001f����1k�`\u0018��$&\u0012pl `� v\u0012�\u0016D�P�\u0011�� .\"..\u000e�d[��\b��c�T\u0004�������\u0010$���@���4C��} ��}����}\u0001���Z�������L�0�����_^^FWW���ƛ���zqq\u0011e���n�]ץ���� �m{:����D_��t:��&��777�lV�$Q\u0014\u001b���ɬ9\u000e��h4������������p'�����ś�����z�\u001eeY�\u000e�L&�p���\u001b\u0004A��� ���(� ������y���Z���墙��???���E�����>�9���V�U��\f�\"��p8�7������8�9�/a��8�,���\u0007����=H�P\u0014��Xj�\u000ft(dj�D\u001d�覂(��\u001ct��I�\"8�)� \"N�\u0005E\u000b��_ �\u0014�\u0010\u0007\u0007qq\u0010�@Ah�mRߥ\u0017��\u0003{�Q�� �K� ��)�'�\u0012���i���a\u0018333���e.X,\u0016���c���@aY���j�P��7�///���555\"\u001b�������x\\N$\u0017�Q\u001b���4\u0012��2���B!۶]�U\u001b\b�������\u0015�$\u0010\b��ߗ?����mllLv\u0013h�6ww���-��744|oND�X�}_\u0016M\u0012��eY�a�\u0005�����t���\u0007�����`0(�][[+s>77����6�,s��;;;\u001f\u001f\u001f������Κ���l6�6�\u0017��(\u0014 �m_\\\\�r9\u001aI e�ٍ� ]�M�\f\u0006��h4�J}�/��|������j}}}``@��\u0018\u001d\u001d=99�,����g�H�؊�� D\\��VBj\u001bE\"�\b\u00166!]>��A��/`���2MHb��\u0004�p��=�\u0012�]\u0015�a�����\u0019r�f�L5gι��H�X����4M�������뗿�7\f�T*ɨ���B�p_.������H�j�$ۡ��d2�;�v\u0012ۋ�\u000b�����#Q���u�ݗ��\u001d�H�9�����r�lvggGn�\u001c \u0004\u0002r��3�`~~^��\f\f\f�����\u0002tJ*����v�]��p8������f>���b+++�ZVWW��������f�������ҡ�\u0017������S�cyy�#�\u000e�i�L&��fwww�V����4��ܜ��P\u0005>GGG�l�\u0005��LӬT*\u0007\u0007\u0007��Ú����_]]�Z|\u0011�F�N�ז��A\u0019��קZ0���ggg777���j��a\u0018ݹ�K,\u0016S\u0005/b}}��\u001d���5���u{{���#�����i���G��+\u000f�Z�^���/�\u000e�|\u001a���͍��R��\u0016\u0016\u0016����i��� �'��\"\u0003�\u001b{�ժr%�d�X,\u001a�A)ǟH�U%z�H�#�z�Ui�����4G�����@K��O4MK$\u0012�꤭��������(���8\u001c�J���5_�+�����v��$\b���(߈1u��d���,\u0016��l���|zzBD��V�+++�,�(z�ޣ����i�z\b��|�A�i\u000e��������ai����B��q��ȲL���l4�D\"��ڈD\" �\u001c�\u0002������,\u001b\u0012\f\u0006����X,���\"IR{{{�\\Ʀ\u0002h6,2|pp�(��bQUuww�{�XӴ�� I��fs(\u0014��r(�x�X����@ \b�,���ۺ�_]]�ʅ���j��q��i�b�x{{;;;ˎ������3S\f�H&��ӬVkooo*�Z__���ץ���[��(\u001e�� t��nO��ooo�\u0012}�D\"t�f���Z*���h6�z���nffFUU�ժ(J&��\u001e.�T*kkk,\"=55uss����G�~��������fk����\u001d\u001d\u001d�(��h8�X�����X,���z==���O����rXǄms\u0014\u0014\u0014��Ԝ��NLLмS/mmm>�����@SI1�L��������z���l�G��b�����\\.�'-**�����\u0016\u001a���QZ9�#W���顠H����8��\u001a=ZV��\u001f \u001e��t:��X&����\u000b\u001f�J*���b---B�0//O�ղR����tP�PTUUmnn��O�\u0006auu��r���_]]�O�������)�J��n�7��9��˽^/����\u001f\u001f\u001f/..\u0016�����w�,����3ط�~&\u000f�n���c�]�Z�OOO�S��ە��t�f��v�*ۅmsP�J�rrr�%V�D����\f�XZZ���`�&���Y�H8\u001c\u001e\u0019\u0019a[$�\u001e���L&\u0013�qtdff������l�466Rw�r����3\u001e�S\u000b�~�T*�z��G\u0002�]\"�\b\u0006�f���(���{}}�\u0015�\b�d�����f�X,\u0014 \u001b\u001a\u001a����S�H�q\u001c�����F���\u001a������\u000e��9��\u0007\\^^Z��������\u001fރ���===��\u0002�`ee��L��f�Z-��a�Xr�bö9X>\u0005\u001b|�\\N����a\u000b777���4�:��n�g�;����0-6Z \u001a��`0�d2 F�R���|=��\bH}}=+�n4\u001aߏ\u0003 ���d� J����g\u0015\f�9�\u0005����K(�m\u0014\u0007�\u0018�\fC��R��\u0016,$,H��B��놔h���B!eE�Pb!\u000bג\\b\u0016.\u000b����%�\u0018����\u0018����'��x]��{�~\u0016�e~s~�9Ϭ����� ����|Pt���C���bcc�����\u0015^����=??��z�t���j4��\u000e��ꪤ��f�f�f��,t]WWg0\u0018l�9���CBB�)SVV&ԁ^���*���ٙ�$''\u001f\u001e\u001e~*\u0019��z||4\u0018\f*��\u000f�\b\u000f\u000f�����gY,���v�\u0013^J�;5�5qvv�h4oEX]]MMMu��\u0012V*����6{\"�χ�\u0007�Q��� �Y[[\u001b\u001b\u001b�.\f������pww��d\u001e\u001e\u001e���_�Aлt:\u001d�����������������\u0006�����6�Z��\u0001�U�P(����x��\u0007Qy�F��d��2\u0016zWii��\u0013N�j8??�|%���\u001a\u001c\u001c��sw����yc�>\u0015�,�B���|��t�o������T(\u0014���...J�rgg�'�r\u0018\f������\u0018�����\u001c+++6�\u0014������J�R!\u0002]��j�?��Z�4���������e�����t \u0012��������h4������p򑑑333_{ U����[?)))\u0014�� --->>>܇z~l�=���)y.>�����J���o �.^���\u0011\u0017\u0017wzz�z�\u0013WTTķQ����B��������\u0003����{����G��R]]�_ԋD������={���e\u000e\u000f\u000f\u000fz������𰧧������())I.�\u000b�\f���u�C&�uvv��޾\b��j���===�ky^�A׉��6wL\u001a\u001d\u001d�#��bqpp��ܜ='��������R����acc�B��)����ݯŷZ����~~~\u0014��׷����=}}}|,\u0005��l\u0006��&�I�\u000b�ໍ���)a\u0005\u0004�����\u000e7\u0017�vss���)�9hh4���ŷ6+�h4����g@@@�p\u001b]lll�DЇ���s���?���BPP�H$�e\u0014###�\u000e����UUU���)))III���|l4\u0013~�O\u000f\u0015���������E���\b\u001d\u0018\u0018x\u001es?//O*��\u001b������>�~\";���VWW\u001b\u001b\u001bY�@�6�mGifccC��s=�IIIy��ݎ\b��n�{ss3�\u0004������\u0014\u0017\u0017�#ܪ�\u0010wU=}������t������h4�l{{;��c���XQQ\u0011����-�Yn_n�ۍF#O����殭��7���K�TrR���~���>�0�{rr��Nyy���$�P *++��hii\u0011~Q��)�V˯Aggghwx1�@�ɓ'iiiQQQ\u0012��h4nllDxDlmm������\u0016��W`577������E ��k�Z��A�Sd����p8Ξ=˱���\fl���p��qz�e22�L��655�xx��~��;w�z=o]RR��R����'��j5�l�fsx\u0003����jJ(e���Ux�r��FcRRRjj�(�� \u0006����q�۷o#�3���(g���=z���r��f�P�\u0006SSS�={��0L&�P\u001fЇ��8�Dr�رO�>}߮/�L����\u000e�P�������.\f�۷/&&F.��������Ree%7\u001c���\u001c\u001c\u001c�i���4���\u0006\u0010�?���g-\u0003����Ç\u000f����:4��P*�|�\u0012�8�.@�]�v���F\"��\u0007\u0006\u0006�\u001e=���\u000b\u000b\u000bä`xx�����AVѾ\u0013\u0013\u0013%%%l9+h4\u001a�˗/��$��V�P\b�\u001e�\u000e�Z\u001f�\u0007&m��eR\u0016� (�l\u0015���-�2���z��>�Uk�E/���`�yv?�}]��\u001c��]��?%\u0016����\u0015+V�\u000f��`\b����\u001c�h��͛�#\u0004Ahii\u0019\u001e\u001ev8\u001cyyyȶ(**�Q6���Ο?\u001f�8�Teeegg�8���4����o��\u000b\u000b\u000b�R�M��N��e����ٳg�����8��\u001f:t���\u0018��7n�8::�r�D���˗���]]]%%%p������V�V�%2�����H\f\u0019\u001a\u001a�j�t\u0007� �f�\u00172{˖-4��\u0005\u0002���fCw\f��x�Ν$�E��Bq��1�vuu5J{A�R*�\u0007\u000e\u001c�}#��-\u0018\f~�~��\u0015�DB���jԏB�\u000b4q�Ϧ�&r�f����;z�~pp������ö����Ǐ�������$R�����������b��J\u0015�\u0018t3�7oކ \u001b�~�\u0011#\u0006\u0006\u0006\u0004A�\f�c�\u000e�7�\u000fq��f�\u00196777�[�.��\u0017}VUU �rQ�'m�� \u0003�eڝ�4\u0010t?y��a(\u0014Jn�\f�͢�#��IqH^3�˗/�7oV(\u0014\u0014.\u0014�\u001a\u001f\u001f����� ̙3�^0�Hd\f]�~����d2��>z�fH'��a\u0018�a\u0018�a\u0018�a\u0018�a\u0018���011�$\u0005�̙3ccci���O�Ƒ{qq��f�����\u001b\u0005\u0005\u0005\u001e�'!Y��#�\"\u0010\b\f\u000e\u000e>{�\f��\u000fg�a��\u000fs D�C.����ׯ_[�V�55��x�J%r\u0001���.]����\u0004�Jعs�\u0005\u000bpr>w�\\A\u0010޾}��\u001a\"Т�@�h4��,�7���\u0006\u0006\u0006\u0012\u000e�'''��ٓ��\u000f}G\"�TUU}�\u0001A!���n������ѣ8���a�X�^o�6G\"���>4ڠi��˓d����߿_���S2^�PP���l߾=��R��ɓ'U*\u0015=\u0002���\u0011%�F���\u0015?�����ɡ1�Soo/�y���իW����p8�߿��c_�ͅ\u0011/S��?�� ���mH�]\u0018ǣ��n:��| )_�\"a\u0012nS)���e��X�8+z!ze(YQHY D�Y\u0010\f\u0003��2�`��P�Y\u0010�ђH��\\�*����s�?\u001d���*W_�߇�{�}�u�������:���\u0010>>>�R����\u0018g�����\\�R�3�8�\u001f?n��F7�u�����d2�^����D���\u0002w��yw�T~�a\u0018�a\u0018�a\u0018�a\u0018�a\u0018��Y�g�#G�DGGO�2E\"�����ݻwppp\u00027r�v{nn.�\u0005蚗�7000Q���^tmmm~~~BBBbb�Z���ʢHQ�|tc��a6�7mڔ�bÆ \u0017/^t�]�����!�C쨗���~U\u000e2~�ƍ�s�Bm \u000b\u000bۿ�\u000f��G�\u001e��ǣ\u000b1gΜ�[���š0zyy�')3�\u001f?���\u0007\u0001��222fϞ�2����B2��QTT\u0004Ma֬Yw��%�\u000b\u000b\u000b#\"\"��V�mnnF㾾���ηo�z�\u0006����J�ȩٸq#Ε���ϟ���\u0003w��~��#�u:\u001d5F�u�!��cƌ�W���j���k�V\u001b\u0018\u0018(�H�z��A��6�W���N��0�\u001d�cǎ]�rE�P�\u0011�Ry�֭\u001f�K�nٲET-\u0017'>\u0019��\u0003\u0007\u000e���ӫ���}������ĉ\u0013H������\u001b\u001b\u001b?~�(��Q����yP�[iiivv��m���P��9�~�:�R�.]J]�\u000e�|X�|��\u0017/�t�u���Ü�\u001c�1Q11ѓ4\u0001j@�T*�̤I�jjj.\\���������VQ#��7\u001d��������֭���S�� �Bl��\u0010��0肖�L&�H$\u0010;P�Dl����4r\u0018i\u0011\"���GEE\u0005\u0004\u0004�2�Χ�����!�CDG����V������;u�6m\u001a�!��v�\u001aR0�Z�z���狋�w�ڥ�h�ǁ\u0002��\u001c*��ӧO��8����>t萈\u0011�'AAA&����K\u0014l[[[uuuJJ �\f;�\u0012:�\u0017z�\u0018\u000b�$$$TUU544�����vQ��g\u0016\u0017�0\f�0\f�0\f�0\f�0\f�8�N���������O�>yX-�\u0017@�s�\u000f�\u001b����b���AրP\u0016���M&��2G{{��={�F��� f�����P�TJ$�ɓ'/Z�\bE%>���\u0019��ܫ�����\u0018\u0005rFXX\u0018=A���\"�7o�@� �>BJ�\u0004R�T�R�9s�V�W��@���>>>PC蚜���� Qfxx�l6��� ;�@�P�\u0014\b\u0019D \u0014�\u0015+�z=�B� j�l�2��:00���\u0014\u0017\u0017',\u0010ԅB>w�\u001c���ݻ;w�̛7/((��\u0005t\u0013\u001a��dff�Z�*==}��\u0005)))�\u0017/���� J�`=DFFFEE�5??������Kr!�x������IH[k\u0014\u0007��Po�C�Xg4N�F�8�Ђ�.�(\u000e��\"�\u000b\u000b]\bVE(\u0016\u0014g\u0005g�� -T�(���;��\u0001�\"� J�\u0004B-Z5j�\u001dz�%ؾ6Zy\u000f���\b_nn��ެ���\u000e�}����z}bb���~1\u001d�����Z�\u0006���s\b��\"�������655�h4Z�Ŗ�druu�H$��:���9??\u001f\u001e\u001eV(\u00144\u0004��D\u001f=~�X.�K�R777~8O�'O�8::\u0006\u0006\u0006������{xx������ o�511���\u0010\u001d\u001d�����ڪ�j���9ɂS�N�k��z���������3\u000e���l6��w�����\u0002�o�z��V��Oa\u0018������n��\u000f����qm�B\u0014E�1��Q��o%��0\f��j.��f�A\u0010�n����\\.\u0013�D2�����l6�\u000e�������1�\u0001a\u0018���c\"���J\u0014\"���B�\u0010*GP���\u0010�0J��D���������b7��)�{�^��x\u0013��\u0018�l6\u000b!4���h���_���z���\u001f_��aQ\u0014�\u001c��\u0012c,���n�\u0010���r������l:�λ�i�X,ʲ��K\u0001���n��$M�$I����|�1�c��˲,�0\u001e�/��O��_�����~�K����,��v�j�*�J�e��ڔ\u0003~�\u0013����-�\u0002a\u0014\u0006�Ͽ�\u0014��\u001f\u0010��\\�`\u0010��5�\u0007� �\fw0.�du\u0007���]\u0010&\u000e| W�K�\u0017��i�p��ox\u0001�sEQ�V�v�\u001dB�L&����z�y>�N\u001b��{������V\u000e�Rb�Y� \u0006�\u0010B�����eY�n��b�$I�VK��x=#�/�>\u001e����j�i�����}��\u000f!�\u00187�����\u0003�BUU���N�\u0013B�����9˲&�N���M�\u0001|�����\u0018\f\u00061�^���nW�Us�*M���T��g\u0004��YӸ\\.1�$I�,��|8\u001c��n�;�L�ϧU\u000e��\u0005���۽��@\u0018\u0006��L\f\u0004��B/@+\u000bA���ƛ��\",�B�#�D�B�WwÁm��{r�E��\u001a\u0012f��L�\u000f>�\u0019���t:M&�\u0010B\u0014E�٬��?=+\u0007����\u0001\u0001^w>���eQ\u0014Q\u0014����p��y\u001c���j��O�\u0007��f�ߏF�Z�V�׻�n�Պ�\u001c�����p�toZ�׍F#MӢ(z�^�$!�N���n/��m�\u001cO/������湕G�j�w2|gw�m�z�_����a�G����'K�Tv^,\u0016I�����8�P��,�N����>�����\u000e��\u001b�p�o����1��@\u0014\u0006ฬ�\u0005�0�F��M8\u0010� 6t��Sx\u0002{c\b�j4�n#��f��(��gf���y�����\u0001�R}����yn��p8dYv\u001bp|\\M&�8���\u001aQpк=\u0010�%��v\u001f�\u000f��\u0001�;���C�t�m��n�4�������8q�\u0001�G��5��`��ȕȓ}߷m\u001b�\u001f�i�O�⳽�Ef+dc�|0�)�\"c}��,\u0012�\u0005�>R����l����ƙ� �A��T�22q� Y`����ԇo7O�\u001d�[l���\u0011�T���y�1\u001a��즾�x0���PНD��I�r EA��^��jڇ�����_����A �0\f\u0004������P\\��:\u0018Rf���l�� �nv�[�_��;w���Y�_�]t\fƣ[��\u0016$\u0003�����\u000e�anY};E|\u001a��m�N��Qc%��#���憳!j�Y\u0017�R�\u0019*o5nC��\u0006 �\u0017����;�� \f@���['D \u0004����6\b}�J���.�=d�g���=����@�\u001cp7O��=��!�\u001c�:~J+_�g\u000e�9O��=��!�\u001cG:~J׫��9�n���̦����Wc�ک��Ǩ�Ʋ�wXIt �%S�ʨ�֐9Y�]�*�:};?�C;y\u0017{i���f�-\u00170\f館�\u0013\u0015�=��u\u000b#���nF�e/yw�^���m�񻋱��Q\u0013���U��۹��\u0007���LlR��6�G둖g�[�\u0001�\u0003m0;|2��\u0016F\u001a�H�꛹�7`�B\f/��;\u001c9P��U�&z��W��?�P{�����Ƥ��}y�G��\u000f�O���\u000f�����t�[\u0018i4\"��o���@R\u0015.�5�{^��U�&z�����\u0010\u000eMv\b��\u000f����A\u000e�@\bC����]�j\u0019c�UT��\u0006\u0002LV��r��4\u0015I�K���q\u001c%�X$\u000f\b��H��IW�B��lm&o�{�!K,�W8F~c�뙘�*�\u001a_ �\u0006����\u0001���oqI��^��R����+�\u0010���\u000e\b��H��IW�B��lm&o�x��W0�p����\"��0o�p��%���[\\R������X�d�;�\u0003¬9��z�U���>[��[2�5g�\u0005� ����oS��U���J�7H8��\u0012pC���~�������*�L}'v@�5GV~�U�p!�}�6���ڛ�%6�W8F\u0016�+�*���TV����\u0012[\u0002n�r��/�^�z?sX咩��\u000e\b���ʏ��\u0016.����f��N�,�����|�^��V�bzk|%̛]i �����رv�0\fC���O�[N\u001b�\u0012\u0004���wא\u0014�l\u0004nT�hm�Xv�\u0019�U.�y&w�6��÷� \u0003)��J&_iP�m(.�O�V\u0016�����F����JY���՝�T�hu/��\u001a�Ko�*{�eLPv��]�~�{K� \u0017ޟL�\u0017_\u0015�c�\u0004�Ũ��j�nՍZ�ʒ!J�W��]M����c�s\u001e4.�*���yݞ\u0016\u0006��Ćd��kA2V\\^���\u0018��+�d�\u0003_'W\u0005K]��\u001b\u0001�'�\\����@���8����\u0007����A�� \f\u0005���z���'A�y]�5��#+�e�/\u0018h\u000e߼�vZ3�p�7����ӂUN�N��:�)\u0012Պ��~���}S���\u000e�\u0003����h���_0̎U{-q4-7��M\u0016g�\u001f֫T��w\u0014��+aLo�ʅ��\\t�#8��\u0011�i��1�GU%�R|�R�'��� t.�i���Z�t\u001c;j�D\u0011���)i�UK�fa;ړf_s�K������M?���Oݴ�\u001d?˵�����(}�X�X��\u0012G�r\u0003����\u0012�ՋcSGA��h�\u0018Ю�u�-��w/ 6�S�\u000f�t\u001e�,�8N\u001a��|����$V�=�C�>zom\u001aG�x�8]�����X5#�\u00147��\u000e#�S�%e�a�\u001fh�\u0017����r�@\bC��?�\u001e:�I�E\b�8M�S�\u0016B���\u0001��r�ӫ�gg���� ��i�c5��8��\u001bx��tY�\u0015�ѣ��8��,�go���\b�̫�{��\u0011���Q\u001bΦ^�v��B���E���k N�\u0019�J��χ節��|���n��V����\"j��\u001c��(��βs^�\u0003�\u0011������?^�������O�K\u001d���\u001fg�$e��2�v6/I�S;D��\u0014K�\u0019��dy�kY��#���̶�\\\u0018�&fȑZnO0�v�Iez\u0004sި�\u000eS�O�?�5B�X\u0001|(λ�`�qqC\u001f9T�QI�6�m���\u001dqC�`�\u0006�s�\u001f�_ؖ�eI�3=Lo�cJ�?Gi���XS�\u001cGض��'\u00172�D�G�Qw\u001cN>G���/�������\u0011ܐ�k�,��)Si��~�e�3�r\u001cm[�O5���L�������\u0016����\u001a\u0001�#_���K�\u001b1\f\u0003���v��H\u0002����K��j ���\u0005�\u000b�w���SW\u0001�侂�\u0018��/:^�\u000b%�1\u001bo�\u001d��9�¥�����n��3\u0012��K�\u000b!rR33���\u0007�M�I /?���3�N�0jGa���vԕ\u0005�W�~�^���QMv$����?���\u0015��}�e1L�\u000f�P�j$O9jMJ�\u0018��qw��{��Ft�۟�N3��\u0010�\fS�� qݑ��l|���(\u0016��|\u0005�DS�����#�\u000e�zS'{;�r��뷣\u00199�Ko�0\u0012+�ӡ��\u001ek�3��)�X7��\"i;�3[\u0016> ��d �N�B*�S�Z� 5��rg�\u0013��Դ����\u001cL\u001b�eSe����z�\u001c\u000b'\u0012�/���v4���*�y�Z��{��\u000b��yݸz�n2u��^���&3�+�\b���\f{:�Q���Q�/׶���\u001e�~��}\u0007�R]T\u001d��Q��\u0013�S�O�Jfl�\u001b*,\u0004��˖Օ��q\u0019g���\\o�>�ņy\u0003-\u0018ȕ�*���`Ҵ�s��a|}$d�|����Mn\u0018�\u0016c\u0016\u0007�ϴ.7��S3n\u0011�y�&%�RB�Ȝ\u0002�ѽ@4#\f�[����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a����\u0001\u0001�����\b�\u001a��\u001b\u0005�\u0006ةL�endstreamendobj380 0 obj>endobj381 0 obj>/FontDescriptor 383 0 R/Subtype /CIDFontType2/Type /Font/DW 500>>endobj382 0 obj>streamx���\u0001 \u0002���!��\u0001�{\u0003����\u0001 � ߿�E\u0018�����\u0001 � ߿�E\u0018�����\u0001 � ߿�E\u0018��\u0010endstreamendobj383 0 obj>endobj384 0 obj>streamx��Q;K\u0003A\u0010��r1\u0017\f�P��H��૰\b\u0016\u0006B�\u0004\"*)l�0�\u0011.ɑ�\u0018;k+\u000bA\u0010\u000b;!��66vZX�\u0003�\u0014�\u0002�5JL�\u0019fv�y�.\u0004�(N\u0011�Xasa���tA�5e��9ٟ�M'h�)3e�* 7?l@L\u0012���i�F�'N�+^S�O¥2�ڞ���M����t�#L|JlV��\u001d�L�\u0010�PZn��A�\u0011���� ����O� �\u000f� �\u001cւU:\u001d_\u0007#��P\f�����q�\u00175���������/=bȒ�v�?_\u001fo?���\u0018�ߞ\u0006�y�+������\u0001��\u000e\u001a]��U/E���Gi{��\u0005�D��a�?\u0016�!޻�l�9��\u000ecZL({\bI��\u0016�8D��\u001ch���\u001a��k�XF���\u001elT�2���:�\u000eNd�ʸG�C�Q���T\u001d\u0006����� ��mhendstreamendobj385 0 obj>streamx�m��j�0\f��~ \u001d�Cp�s\b��A\u000e[˲>�c����Fq\u000ey��N�A��\u0006��'~I\u001e�ϖ\\\u0004yf�;�`\u001d\u0019��Ϭ\u0011z\u001c\u001c��\u0001���_�*\b��n�\"�-Y/�Z��$O�\u0017�|\u0018��6�Nl�\u001d ��\u001c�R��\u0010�8\"E؉�\u0001�6��V�G�\b��Uk���R%��o \b���WK�\u001b���Ȋ\u0006\u0014�.E\u0003�W�F �\u0017�N��M;�Y�\u001ez\u001e��}��3s2VNR\u001ce/��y��C�ʻ\u0001��rJ endstreamendobj386 0 obj>streamx��[�n$� ��+�\u0003ʉ}\u0001\f\u0003�R���\u0001\u001d\f\u0018>٘�a�G�\u0019\u0011d\u0004Ɍ,�f�\u000fFOAӭ�X�.��dݳ�?������/1�o�z������_~}1/�\u0019���듍�(�\u001f�}��\u001f�y��\u001e�����\u00112|�\u001fO��1!�'�'����O\u000b�Wc���ߞ?�\u0004�ƱP1��mc|��=���\u0011\u0017\\\u000f����s9�\u000b��@[���}=Q����C9jZ_O��Il�hڷ�=�X��g��\u0002u���\u0019b�o��M�\u0019n\u001fL��I3�q*g�Q�{��\u001dK�ޏ����#��[{p�5���w'��q\u000ezփ��\u0019=~\u0007�����\u001dW����� �\u0019�t�\b�ܑ\u0003[\u001b��=����秮�H��ve�\u001f_�îp��s�f\u001do�������u���e�w ϩ)�A\u0019O\u0017�S\u0002�G-J��} �������\u0004\u0019\u000e߶}��p��\u0017�w���\u0015��\u0001����FN�w�ȁ���x~i#\u001f]����\u0007��LL+oxဿ\u001fߙ�m�\u0018�Q�v쟊RP7\u0016�nm����h��\u0003)��&���K ߌɰN�\u0003$���F\u0010P\u0006��\u0019�C%\u000bÂo��磜�l���5\u001e1;4�~8\u0013�\u0004&B��Z.�r�4L\u001f��pa�9�����$\u0019�1\u0015�>���\u000b���f �(.��\u0012,��\u0014MC\u0004g�+���Gs�&˜Ƨ=��p�8\\�\u0005\u001e���\b;3e���\u001f�\u000e��'\\\"ٱ\u0010?\u0005\u0004\u0001��qR\u0004׾9[+3�g@ڀ����id�~x.z���\u000fv\u001b��?�\u0010�\u0007т�\fgN���ͳ˂%{�-\\�G���\u0004{�H� q\u0001ӭȯ�W� �$\u000e[\f��Y���&\b8y\u0010\b�Ȫ!(������qma\u0004\u00118峹\u0002~\u0007d߹�5�~?!e\u0001U�\u001e\u001e�\u0017ց �3,�\u0017yK|�`�Y�\u0001Ӡ\u0014/������.Rː�i+�y�����:e\"\u001c\u000b�RaW�\u0010\u00026��\u0015#蝻A\"0�\u0012Ct�\fi�!���O�UbMe\u0010��'�\u0019M���)T��\u000e�\u001c۱�^P�\u0014�U�ˢ�D�\u001d�0k˝�Ù{X����'��Y.�bP��c�7\u0011��@R�Ľ�Sp`�%�hWV��\u0010�\u0015\u0018A�5�\u0015 \u0018]�\bv����� ��3a��i\u001e\u001au:\u001c)���\u0017��{9�\u001e�\u0014\u0005V\u000fy��\b��_��'2�c�+'\u0016��SG��\u0003��ݎ��øm�}��T�)X�\f��^�\u0002\u0014W�2�-�b �V���!g� *-⟬{��rZ���#\u000eAďu���ѫ|H��'\u0012���^�U]�H\u001c���*R�N�ȳu�u�'T' �m�Ԑ��!+��=������D%��\b��\u0019�P��*�^\u0005��뚬���\\�aF\u0011C��\u001f\u001b�\u0019��}N���\u0010��/�t��'[D��{gD|�ff.�\u001f��\u001c�z7�|�L�%@�b�@��|���Bv&�) �,Qc�5\u000b���7��V��%#:u���\u0007�\u0016 _ϯ�r�\u0012���\u0002R�:\u0004�;�S�T��2:\u0003\u001e\u0004�j��\u0006a\u0010RJc�\brfN�N�:\"2�2Sġ%���\u001d�:�\u0006\u001fe�sg+�\u0002��I��GV� �-Z�\u0016� �f�x7 �Դ ���O�\u0014�.�ŊM,ӳo\u0015����T\u001b���tіʞ�\u001f��pW�Jr��b����N�\u001e�?�mO�\fjh��Sh\u001c� Ŝ\u0014��� \u001b���ʬhP���'��m>h�Y�ï,[�s�Q�#> /Font > >>/Contents 3 0 R/Parent 368 0 R/Rotate 0/CropBox [ 0 0 612 832.9 ]>>endobj2 0 obj> ]/Length 176376>>streamx���uX\\_�/\b\u001e$H�@p\u000f���\u0016��\u0010$A\u000bI�S\u0014�.�\u001d\u0002$�{ᅻ\u0013�K\u0011�݊ \u0015���f��}�����̽s����ji���雘��[XZY;9����{x\u0006} \u000e\u000b�HH������Gjn^~AaQqIiMm\u001d����������`p������,|������������>������\u0015���?r�h(���S.�G�P����1��\u000b\u0005��\u000b\bџ��� ������/��u|Nu\u00176#��)�\u0017ǉ��L\u0002k̈D�\u000f���\u0013,��#��W���\\�.\u001aʣ��\b\u0001i��'[������7�����7�����7�\u001b(�:\\�e[ե��Z�\u001ar,W!ܕ]�\u0017��$\u000eڠm�\\t]��+\u0010� H��?>�I�[�\u000bNד���d@~$u\u001e��n��?e��8�Qx���U*��&��\u0007M�F�U6�qĚ��I�2��� sfї���'l��\u000e #rDa�z��!\u001f�\u0001�p\u0017}\u000f��\u00151���ү��ץQ �(F>e�:5*}S�Tn�\\���\u001e\u0017aZ`'Q�6Xޑ�7rY�a��*n����\u0013��\u0011s�^�1|�Bd�\b�E�J��7�)&�\u0003\u0019� yY;\u0017���E�� �\f���%\u00158�F\\\b�d���0[��o:�c����[�Qo� �g����\fS���\u0014�:\u001c����+�>y� >��ʈ���$:u6TO���12�\u001e�\u0019.N�\u0005N!w��\u00180ռ�/���>��R\u0002�y��n5�f�T��m^Q��c{��O\u0017\u0016\u0006��rX\u0013�}�#��8\u001bx\u001cՀ�F��{u\f�h��\u0019o�bPM����ؗ��V�N)�Ğ{��8R�E�����؝��>8�q\u0002�����7\u001f�qU��7S���E�\u001e��lh�����yVצ�|��SJ(kM�c\u0007�]TO�KVj�\u0002t?^�I����G0�)_\u0019-BD�W�\u001a�ob\u000fi�\u001d�/�\u001d\u001e�G\u001f�7��B\u000eU�Jv\u0018Ȳ��ƍ�3�c�\u0002Q\u0015�T��bއL�,y��n�J0��\u001f��W��1�\u001c��\u001bR\u000b\u001b�\u0011a'ae;�|7_x�o�^�\u0014\f�����,�F��}�\u0013략z�Ԛ`��W~�b�K�\u0013p\"C[D����A��B\u0014NXg\u001a�\u0010\u001f�h�\u0017��\u0007��Qa�|J27�&t\u0005.tX��.�\u0004�f��g�U���\u0004j�\u0005f���7�J\u0006Qk�}QK����'ʆo�0\u001a\u000f��K\u0006�F�O_y��ALq��ؘ�E7�2�\u001a�.*��\u0005��\f)��Mκ(>I�}�\u000b\u0017\\[b���syr���U�8$>�\u001a7*��'C��\u0005q��mG�{O4d����3��wٿ8[�,Q][!\u0004-��\bM᭩-\u001b�I����y�~#b� �x�3}C ��L�Μ��Qt��0���\u001d�S�V~�uK�>��ŋ\"���'�.�G�H\u0014\u0011ك��\u0001�vM��!``$�`�1�@��]\u0014�Pw\u0012)��&��|�\u0014��$e� \u000f�\u001e��IHX+��߲��Һ�V��\ft\u0017\u0010\f�z���|N\u001d�8���\u0018m���.\u0006�\u0001�b 7� ��^�o���\u000f^�8FG\\;�\u001e;�M�\u0003P1鷫��m����������R�O ���O��\u000e(�\u000b�2���|����#Ż��>�% H��Q���0�6�R\u0006i\u0002q(@�1�����֒|�X���\u001f�X�\u001f����\u0005Mtl��0�ΛL�J�I E��[*7\u00170a��+�L\u0006�\u0003Ȯd\u0013��0�Z�a�e7���N0��\u0019j�}�����(� ��$7�0\u001a��\u0010��\u0002�\\�+Z\u001a���\u0006�\u000f8k��\u001eN���\\�\u001b��W\u0004g���\u001e-)�[c� \u001c�e���'��\u001e�_�%��\u001f&x��]:o����\u0011��\f ��?d\u001fp�=�\u001a�e^W@\u001a/tǔ\u0019�6G;\u0017�� ��O\u0004:/��%�[�6 �\u0007\u0010���fzy�'1y��2x��%�=�F�%6�خhOe��B��\u0014>\u000f�\u0012h��Q�m��\u0006:W^\u001f?�xN�\u0018G�~d�b\u001b�\u0011KA�\"\u0003g\u0015�r\u001e�@�3�N�K�z���kx�o�ц�����LN���y�s\u0010E��}W�`ț�H�p�¤h����\u0010 �'\u001e\u0014;���G6�F�)R��i_�|�kY����m�~�5\u0002��\u0010 i�Lje��M{ަX��\u0006\u0017iҊoZ\u000b�k\u0014��L�QK��J)ݺ���[@e8\u000b�,���2��{2����\u000b���Y��v�n�;�\u0015ê�P\u00170��a�rN�)_�=����R!�\u0012�[_�6��S�7�t}\u001f�NU��\u00146�67M曤���JϨ\u0011���~�\u0014�[G2]�Ns�AğN�\"\u0011�\u0006U\u000bN�iv\u000blh1\b���v����w��##�%C�����+���~ci~+�\u000b�\u0002U���9�\u0005�\u0005\u000b�u�v?�[u>�+�\u0013�3*}4�r���� X�� �\u0015,]\u0018�T��\u0015��>���y�Iq��v^���\u0007�N�\u0001`�8�g���\f�x+�Z��ChnfI�IԦ�Q�;��m��>�d�}�E���vr�T�Ֆ�J���-ɲ���$s]�!�Q��$�-��\u0012�-[�*E2Y������ӏ����/a?\u000b�1^~%��Te�;)u-:�P��\u001a�����5q\u001a����(\u0010�Z+�\u000e�K��,,B'�And�t�\u0005�dEQF�=\u0011�1�g� @����߬tP�,�:�4n\u0002�ť\u0017oZ\u0012٢��e��(�&�(ݽ�\u001a�pl�����Z� \\:�@\u0003d\u0013dI1���#��YZx3R8�\u0010�́B�\u001b\f�E)�+EJ�w��N`��ɶ_��\\\u0011���\u0014��)� Ln�9\u000e�\u0018�v����*F��\u00129P�'�S5ɉ�j)k��W+&��\u0015����G�c4[#�>\u0001�kW6hU�xo�g�\u0003�ƿ��C���Yc�@YR~F�%�Dҳ��\\ß^�\"��M�PE&W�#��d~��B\\�ס̏��|�{/#��Y���=�\u0005P\u0016?�\u000b�(\u001e�Y�M\u001c*�a,Y�#��$و��\u000f���&��i(O���?\u0012� o�q~�R��/�O(�kx�O��Eq$\u0003L�G��%oaj�ѡ\u001b-R&R� �\u001f�y�m��\u0002�ӵJ�t:�St\u0017��cPVFI;~{Vϕ��g�mm���ע�1\u0016��u�\u001c\u001fK\u0015\u0014\u0017�W�ߥ���w�E~cw�w�ƈr\u0015U��+}\u0004MKniK'>��\u001c6]��{��Yi:��@}����b٠���|�F���\u000f��!K��v�c����\u0001�t�[\u000f�F;㞐���i[Nhn�6��\u0017�\u0004��o͕!�?�5�[~$��c�`����E�O��\\\f����|\\���OA�����Ec���٢���5)\u0016E\\G�}s�VG\u0014?\u000f�Bõ��[q�t\\K\u000f2Ѿ�\\��$�\u001e�����\f�XGsx��\u0015A���G�����_;?\u0004� qi�!\"�Z\u000fz �\u001eTe�8��mI�\b\u001bٯJt�O�/������\u001e\fN���\u0004�\b\u00069u\u000b��p\"�4\u0006]v�\u000e\fI�QB�@��B��\\��V-\u000f��V��`Ga��eJ\u0004~�|�P ~�h&��Б���=0O-b��k��x�Lb/\u001f����\u0006>\u0015&uVBF\u0013�\u0001?\u0003��(��\u001dR�}m\u001d�~��Ņ\u0012N�\u001er[ѓk\u001d5y����ʛ\u001fW?6�u�8��5٭�U���\u0005�v=��q��C��\u0001n�Պ��\u001f���~�AH�ØHEs\u0004�v|\u00042@0���\u0007�]�5��ĕ�\u001a�x�(Bq����$ݍ��\u0005\u0016^P�{1��#|V��������\u000e��I�\u001e�w�O�h�{������G\u0010��(��p���&:+^y\u0018�?���\u001c��p�\u001d4�fa������@�F\u0019��\u0006�&3c��k�>>�I&�:K�oY}Y���b �5/P\u0016���䃑P0\b�����/��Q\u000ei\"c� o��\u0019�c2�T&m�~Gr�LO���)����4�jE�u㝥�r�\u0001SP\u0017\u0001�'`Q\u000b/��#�&=7>|W//8�Z\u001f/\u0012n��\u0004K���\u001b��\u001eCEU{����آ\u0015R�x�\u000f�u\u0001Q)�\u0011ˑ좸=����m#Ѕ�O\u000b�:�\u001e�ۉ0�;�ĳ֐\u0007��'���j�nC�=q�b ���/+T��J��'\u0012x����K��z+�\u0003��\u0013!���%C�\u0002�5\u0013�F���c �ڸ��g�2(��\fiN\u000fXn=Y�`�`�\u0012�#*�\u0014J�>a��%ɯ�p�(��v4���I��\b�sQsʴ��m�G�,u\u0011n�)�a�F�\u001b�v�n�B�O*Gj�5��n\u0019aq���\u000f����ޟ���y� V`*E�c\u0019��a�v\u001e�o(�\u0013\u0006c!u�\u0005\u001f����\u0015���\u0001�ZCl���/��\u000b�Ј\u0001 ��\u001a�-��dl�B�|��\u0017\u0010\u001d-X3�LU� ���\u0013�J��!�ǽ$�U4I��|��G�]��F����\u0003C����eOP�0��'7���yXu#\"$�JM,v�P�5J'1�\u0002*����C�\u001bR)�v�W}�5�re\u0001�\u0004]vb�x�\u0017 ��4�@�椊�\u0005n�\u000e�d��r\u001d�\u001eI\u0010W�\u000bY\u0014�٢>�S&�w��dq5jW�ڸ\u000e��\u0003�,��Tbwd���ò%�{گ�:���G�\u0007�H\u0017���T�ul�9��� ��CiO�^ �b����2;�\u0005\u001a����Y�3T���V�L�!uV!�l)�wt�PQ06�QncD�=�\u0015\u0007$��\u0018cu�\u0016L��7ri�|\bۮV��tp#:\u000f�>'F��Jm�^\u0010�\u000bd�ڿ�����C���Gr�F�\u0004�?�vǭ6-\u0010Y\u0016���k���I\u001d֋*t�g�E^9�_����b���a\\� ^�����gE���\u001a���u�Lo\\\u001c�3���W4¯aS�c\u0013�ɶ��\u0014�va��\u0012�U_��eNd�:�p\u001fepRt����O\u0013���f�!��\u0007Ǥ��� �=Z\u0011R\u001d��#0;E9�]�f��Pg\f�Ot\u0019j����ٯ�t\u0011\u0010����w5�s��\u0019�%�\u0006D��Co9cI\u001e��Cc$~֚����]�\f��N\u000b��'(���\u0013�6�\u000f�{��T�����O �-�� 8|\u001b�$=7D.G�W�[�ѽ�5�&�pPe������K C�HR�׈�_d��/$�0X�)y+QQ]�\"�} yQ��\u00168�Nȕ~����\"�1�r+�=�@�\u0003�s�}��v��/�� \\'�Z\":�o+9rV�:\u000e\u000b�\u000e�_��S .\u000b�?��x�~\u0019�\u000b�\u000e�,*p��ov�Vᮃ��Z~Sc��?���\u0015M{��h a�\\�奤����\u00144��-�*��p�\u0019�{�\u0014��iB���d\u001f��������.{ݟ� \u0006 �����(}n\u0004N?�\\II_q\u0017\u0013�\u001cq\u0004�\u0014��F�x\u0004p1'!\u000ey�C5� AzHIn������2�`�\u0012 �e��:Ni���\u0006��{ ���E~e~�HsYzy\u0012#�\u0014�z�>D���x��ho�\u0006�����\u001e���G7\u00029C���~�`�d�-\u0002�\u001eu�\u0006;Kx9x~���%�3o��Z\u0010�\u0007%�\u0017)3�N u�-D)H\u0019��@-��9N�*?{��9G{(]�d�\u0007/\u0007�ʞ��7��I�D�`m��{��\\�j���\u0006)��\"\u001b\u0012�X��\u000b4t�>�\u0017PNV�֠\u0001����-΢�`�����\u00012T�ag�\u0017S�V�0޶������/�l߉ӽp�\u001d\u0018��g���8F���1�o�}�� �i�Ӟ� ����Wq�P\u0007���\u001c\u001f�@���\u0004���qʎ��#�:��̯�. ��艿�~���>^Ĕ��nx���\u001fuI�ѵ\\OݲV�\"�T��� ��RҌ?5���3��n�܃�oG$�4�(�gŠ\u0005�iOj� \u0002��/�t����\u0010�Ɓ��\u000eC0a��ݽ����Ch~���\u000eIǀ#01%\u000f�\u0010\u0006'~\u0016�`��@a�mLr���g}-U �Z�\u000b\u0011I\u0003�6�j��}\u0005[wïжT�?\u0019�\u0001�\b\u0003�\b�� �i08�9x��>~��Y������,�ӆ0ﴕgr~��a�\u001f��L���3ӵI+}�_\"��(�shR�\\;�)\u0002��K̍��\u000b\u0002�� ���\u000btCh�>Ө$\b���r���;���\\��b�L}�M�؁\u0001������Z��#���/�\u0011h�N���/�\u000ff\u001e��H�G�˺�~��ϝ���\u000e���.�\u0015c��\u000eM��l�:'HUewC\u0005C��\u000bz��%ZMn��]���� �KԨpXR��t����N�d�Y�j�R�^��'~\u0012��l�l�f��e��'�gOa�\u0013)�-�Gj �G�0�2\u0011�sr�w�\u0018�R1J�v�|{�˧����`��t���\u0013���&��qo��UWM轴 S\u0005�M���;k���\u0016��m�I\u0015��FX\u000fS����\u001a����yD��[�S���\u000e�RCkR�K�T�\u001b37��~��͎�O\u000f@�v�\u0003�3���\u0014{�=q�\u001eÕ\u0007@��,\u001b/��\\zW��\u0001Xq�C\u0010�}�z����&�\u0001\b+�dC3�� �Ʒ�Z̺�����\u001bwRy�7\u001f�uv�\b`�+�>(����\u0001 T�ĥ;��|N���\u0011\u0003��B���\u0002�� �;L���c�{������\u0004��{ � �_\u000e��\\}��D�>S���� ����!�����n�e�J\u0015�F�9�e\u0013$\u0013�'\\5d�I0�쵂^_�m��j�Ģ\u0019ί�\u001f�\u001b�F}% }������\u0005�bj^\u00152\u0004��u�%��Sg�ߦ��몬u\u0010\u000e���\u0019_U\u0011)t�J��MSB��^�K~�b\u0015\u000f����P���h����\u0017W!o��J�:��S���׈ �\u0015�M\fz7鼛}�t\u000fs���pi��9�0�\u0013�t�\u0019��ܹ�\u0011��\u001dV���>����\u0015�M�j��\u000e*�����}�\u0005�\u001a�s��=e����\u0010-ȹ��\u0013���J-�\u0004�u���r\b�3� \u0017�|��'�!c�����\u000eg��\u000e+�d˰\u001a����U����� r�\u001fg$j\u0006\u0004��v��j���%�\u0018�~2�\u0010�@�vD���k��\u00108� ����T�b��k\u0005h���z}�\u001b#F��F��:o��$t> [z}��t^��4j�1�R�O�\u0007�ܓ\u000f�\u001f5\b�ǡtY�Ȥ��b��f��+�\u0013\u001e��\u0007\b� �\u001f�G��8?p�j�qJ�d�b(ݿ�\u0007��Q�l��yb����;~�\u001b�kkt��?AӁ@�hY�=����I��L��|�\u0003d\u000f-s� 5�?d;G#��\u001f�\u0014�o��\u0003|V\u0012ߍT�n��)X�>�f��E論�7N]�~��\\�� ʴ\u001e)�U\u0015:[��B�կ�\u001c�*��I�Vi�$9�u�(H�k\u001c��\u0018R\u0007Ď�Iѹگ46����\f\u001dY��\u0010� �\u0014�T|]2��E�\u0002�Ej�*����\u0018Ү9/�Ȓ��B6�IY-i��Y��\u0017tH���\u0010�D��|���MvI��o\u001d���7� d�\"B>$S�\u0011��\u0018��K�ث���xIm˨R�z�2j� �\\E(a�ec�b-Ow ��4�y�F\u001a��\u0017�@��I��{��+�\\��B�bh��4%\u0012\u0014�8�����u�B�c���.(\u001apiVh+\u0002�߻f8�\u0014�����鳄�md� ���o\u0005�@�\u0003!��?Y_˼�;��(EF~��\u00148b�9�o s��\u0007�R��]\u000e@\u00017\u0001\u001d�\u0015�}}���|�\u0010�Ƭ��c*�\u001b���D\fe^�G�\u0011\u0010s\u001e��\u000bx���\u0015!՘M���z�O��^Ws�w��ȕ�0O8�.��\u001f���\u001f�p�H���|��L\u0003�H\u0003&��u*p����44����y�� A��^ߌ?9w�#\u00059��0��U��\fgT\u0019,R�\u001f}���2��B��Y\u0006�7Y\u000f��u+�|-r?\u0006~�\u0018g�z�G���\u001f�W�����|\u001f�F\u0013ܞ��hPs̱i\u0001h+\u0006J�Xmd\u0011�V(S--�\u0014�V:V\\eC�.��U+���d��|�~���׊��/�U��I���O��JĔ��ձ���TL\"/��&v+ޫ�\u001eh \u000e)�3X\u0016@�Q)�1t�.~cm.�\u0005��\u0015\u0002\u0015��R�g�f�\f,���.���\"��>�`¥L�O5�k��f��O�b��C��\u001b\u000b�\u0004�\u0003���}=.������S�\u000bE\u0005\u0010�\u001f�\u0018�[,M�K☛� �Fzť\u0004'�iF�\u001d]�l�Iy?+��XTݒd�:CF�dK��fy�9\u000b+G���\\��\u001c��\u001crp�p]����{\"C\u0003����`f|A\\/頗I>�\u0018\u001f_L0LKT�{5\u001f��\u001e��'�\"���\\\f�Βf_\u001b��-��'�\u0019�t�(\u0011\u0002��$5�琄\u0003\u001d�w�x��[��z`�'A�\u000b�[�\f��Z��j\u0012=\u001a\u000b��R��S��H�G�a��x�\u0017�D\u001a����db�Y���\u000b�Pr�� [c\u001a\u0007\u001d�%>�rݍ�7_\u0003�\u000fD��{U@Xc�J�\u0019I]���7\u0005�l�_WR3�M�4\u0007��2\u0013�=�I���1��\u0012D�Sb%����}�]h\u0002 K���^wa8�KZ�5�6�=�\u0013��I�4�~�ݞ\u0018a���d�YT\u001di�\u001a�\u000b�s0�t[on�Ѕ&�w���U���:?T��W\b��oTU�B6��\u000e\u0013��> ����6Oe\u0017�)��8�4�6�N������_�7�\u0003��N�lk��V9��\u0016������\u0017�;?YGh\u001a�H���\u001b��>B�\u001b.��/�M���Qf&�,��Y���yy\u0006\u0003Esz�X�!���M��F\b���\"�\u0015i�g���\u001e��lH$�\u001f]銆���u��\u0005���+cDs�N\u001c*�yq���%\u000f�̓>\u0007o�5G��=\u0001��8\"q�\u0018�\u0019P{�Q�,�s�O���Ď3�\u0001�� \\f����%�������;\b\u000f�(uB�9?��pmip6\\}\u000f8K�K���\"��s�d���PkԨlSP�\u0015z��k�4J�V�D\u0003��{�V�\u0002\u0017XR�d�/\u001aH��*㿙x\u0012\u0001����� FK�\u0003�K�#�˭?\b\u0010>�\u0010&���\u000f\u0012�P���$'ÆV�n�D����~�+_�[K�I��Wͳ��.\u001bG:r����G�g �K�������t�L��IG���6�α� l\u0003�e;;o��js\u001b9 %��\u0010XH;\f\u0004.�\u0001S\u0010����\u001dDԮ���K�?������\u001e��\u0018|��x���r���\u001c��36ϸ`�/��\u0010��+Js� o\fli߂ʗ�f�/Sͥ�*7�-$ߔz&K���P]���M/O\u001e��f1�6p5q\u0006���\u0016�Z�zy�t��v�`�=-�\u0019�5\u0012��,��$Q����t����� �UE;�\u0005��T�+�8�gJ��l�\u0003WA�AT�Ga\u0015���S�5%p�[\u001a^f5)�\u0003fa�kƔ5 \u001dG�\u001f�\u0016�)��Ay`0� -�&S\u0019,�Ɍ�O��˘|67�����^/��\u0017�C��і\" թ���]�A�\"������~��$�|:a\u0006}\u001e�[tx����ߢxϨE\u001e���쯥���G���6�H��A���4\u000b�!Bq����)��K�����������_Q T՜�V\u0002\u000b\f��\u000e�^��\u0002yb���\u001br��!��L�7��*,�y�\u0003��4�\u000b��_&\b�΃�ߥ��x6�\u0007�F�=2w��P���+�M:ӈm'&��\u0006\u000f���� \b��\u0006�kNᓄ�wi�J�� F�`������un\"����q��K�a����\u00044\bZԗ6r�b�O�\u001a��N\u001d���/TF�ߊA�\u000bXSs��'�۽4��-�N\u0012Uf�g\u0017n�Ԓ����xn�$\u000fZs�E2��u\u0010d�G0�Q�^���a;ۑ�߱�jE���i\u0017W���6�PW����Q�\u0007�\u000e��r��\b_ �Z�\u000f'��\u0001��6c��\u0013�5��3����_�R��\u0007j�F�\u0002Ҭ�\u001f��:���y�Mz��\u0019u\u000f�^�&��|�|�{��Q�L��-�U)o�)H�\u001a^2%O��y8���И��;�\u001eW��\u0005~\u0003�B Z�\u0019L��0 ��E����U0��T�R�NV�[v�\b`\u001d�Ư�譬��Xƍ�Փ�I��z]~���VM��\u0011I�]D����\u0002k��T8��9�+\u001f�&�gy%�K����k��=v\"��s1`g]� �;Q\u001c��?�\fa\u000fw}>3]M\u000f��xlW��� \u001d�\u001e2�m�G\u0004F}�\f\bL�*�y��\u0004~��٬r$7R׈\u001f̤�:�*��h!���mZ\u001d�b�\u0006c�݄ �\u001dd���Ѓ:�\u0011��r��HlAn�S\u001bԂ�\u0001\"�F�_�E�.Ɔ�K�\u000f��\\a�R�� \u0012\u0007�Ľ��oZT��\u001ae=����E��V�� \u001fI.'q?&]\f��݄\u000bN�W'+G�2�2��s.r��\u001a���G+�\fo}Ql��{�;S�%f���\u0012MؽV��B��UN \u0001�b��k|��'Y1����\u0007�1�y�ؓ�� ����b�ǲ9���A]�d6�4�d?\u000bO���z�i��pJj��FƋ�׏F�v1�>O\u001d�QX��0�` \u0013\u000b���Dx4\u0002:� ��\u0013*(\u0005���L��\u0006�\u0012f�\u0012_g��8�c�1z>��\u0007K�b��F\u0010{�+,��\b����\u0013�\u001e��\u00033�'�\u001b�ļkڗ�nW�?����2W�(BͲ�#6X\u0010u ��YFu�O\u0016��*�S�\u001f\u0003\u0011;\u000b�:a��\u0003��\u0002�r�B��A�t|]�+'\u0019�\"y�L2\u0004W��:�\u0012Y/����\u001cѯL\u0015\u0017L�v�\u001dN_�0\\��Ʀ|K�OM]�w��)�\"����pj��↙��\u0010��}���[�T�������.\u0014�>�����\\��Q\u0019,#mg�Tt5ϭ5~\u001b���p��Q5�\f�.�q�.*p����F,\u0014pi�C���\u001fSo\u0005b�ϳ��؏�\u0003t���n%_#b,�\u001cB[�c\u0012K�sxwڟ�.)ޥpvI�k\u0006)*�'a��쾄��/�\u001fq6\\\u0019.E�[~\u0002q��\u001au\\�����)�h�HB�*�[\u0003:�\u001e�lL�?��s\u001c{����}�\u0003pQ�\u0006�m�������\u000bͮ�!�tUuqc�ᎊ÷^ ��澧[\u0006C�\u001d\f;+���\u001f�-\u001e��h^�:�)�D Q\u00021٧��q'#0���t���;.͚-��嘢�_2��D]O�=7G�,��q�����\\�3��\u0017�ORl\u001c��%�J�����\u0007A\u0018C],�wVm�#�r6�-�u�}Ȫp>r��ED\u000f�^�t*�WFջ��p:���\\aJ���}g���d��%-�l���b�ѧ��Ti�߫�:hţ��\u0017\u001b4&�&DrD����\u0018�`9��]���Fv6��q\u0018{��J��q� �nܧo�QnegJq��o���8\u001e�r�Rf�F���ͷ\u0002�I^\u000b\u001d#=p;�Z\u0018ӄ��\u0015:�\u0019�\u000f\u0007��ό�?J��b\\D�il�e^&\u001e\u0005��qD�M�W�lh\u001d��M�/ܓ7䃴`\u0013k1C�\u001c5Éۼ\"� �:r\u0015��;\u0017,�X|�\u0001��\u001al\u0016\"j�W\u000e��\u0002(3F���T� -_ �\u0015�q7�K�hfSz)9�s㾿�\u0011�\u001e��ܮk�ҙq�\"�;оD\u0018�v��*1�\bz�Uކ���ɐ���/\u0010�0W�+烓�)_������QbF T\u0012��L��t�\u001dx���\\3X��c\b��$Jp{\u0013n�^+�\"��s;\u000fa�\u001c.\u0004-X�L��j�͎�2ԫ`_\u001dD\u0001�q˲�˳�9�Ɵ��S��\u000b�\u0015�ͤ��Ŷ�U]�U`�DdMy��@;�z\u001dj��*�(ˌ��� +�418\u00140Mw��\u0017�\u001ez\u001a\u001a%��c�2q��I�ĸ��Wm�)�%�?�\u000b~�M랦���m�������JZ��n���hS�\u0015O\u0007\u0006ľ& ]U�us�fP���Ά2y\u000fݡe�Do3�\u0013�\u0007�\bi�\u0016z ��F]R\\�c*�{\u0004�co�9�͏Dg|\u0015{c���:.4�6H�d��M\u001b���n�\u0016#�H��ޟb���7Ҽ϶�kT�\u001a�\u0017�Z:�W�A\u001b>��d,�\u0018��\u0007\u0014�\fX�?�cz�!�ܞ��=7\u0010��\f\u0014'�C�d\u0015�*ۿ։��, ]�x�y����pE!��qH?�&P�m�&D�^�iJR�$�{�ķ\u001b�`?�Nԛ��v\u0001�\u0010�S�]g\u0011�{Q&x�okQv-���#+�-̻�L)�/��\u0010&\u00198\u0003ԟ�8&����B� {UxB�1�?��3bq?ZdC��-��!�\u0015\u001a3�c���-��16f���ٳN�[��)�+&\u0017�\u000bP�~/>;��i����\u001f-�\b�7�'��_U��Ͽ�\u000b�ƙQӞ�&ﵕ�\u0002\u0010>�h��'\u0002�Fiv\u001e\u0011���(�N��T�p\u0018{��Y���4,$e��� 呢��\u000b�\u000f��Ľ)���jO�U^\u000f��T&���h� \\�?�v��\u0019'����\b�j\u001b�����\u001d��3ih �5\u0005�`��\u001bۖ��\u001d����4 \u0003\u0019���q���w��q��3�P\u0001ͬ�r\u0005|6)��{��\u0005�\u0012\u0013�L��l7�\u0005�\u0019A�)\u001d�q����w9)�X��u C\u00035s\u000f2\u000eꙍ30P8��\u0007X�,\u001dD�Q�ǜh� \u001c��4d\u001cZ��I�\u000b'\u001f��T#�\f���U��6\\9�k\u000e�aj�/�O\u0005�W\u001dQ.r���#�\u001f\f��N\u0017�@݊\u000b�\u000b���\\���������h|P~���Z.��\"G�iR~�\u0016��d��w%V�$X��\u0016Xynټ��ż�V#����\u0015G�����y��8d\u001e�!1 ��+-v�;�\u0013I��m|c&�/��ȁ*��\u000e`�\u0018:�j�0c�B^��蛦�ٜ\u0016w`[WT�\u0004����>�]&K��0��J�\u0013{�\u0002\u0003��b2\u00028�>T���+���\u0016l�p�M\u0016�\u001b����L\u001d�:n�[kST�p&��;�6Z\u00191�܊\u0013r\b::Xn���|轂�\u0013���\u0011X���\u0011$���wv�h�ۭ�\u000e�\u001d�H�QE:?���i/�\b����&�-�|���qr�r?)\u0018\u001eb�\f\u000e��.\u001a���X���8\u001fƓVn\u000b\u001c�������\u000e�\u0019$�\u0005ϝ��5�8\u0010\u001f��u��G\u000b;\u0011t\u0016J�\u0017��\u001e\u0018���8�i�\u0010È��\fj@��)=Z��̱�foa^ ���� ��\u000b�������\u0014�A\\�97�\u000e\u0017��pforߴ(�\u0010�Ƴ�ZƟ9?�I\u0015O�Q\u0019��5\u0016��[�80�\u0007�G�y�\u001d���v�m\u0005��2��n�4bZ\u0019�?\u000f���+�a\u001e� \u0018\u0011z$؄\u0017�� \u001a�]�\u0005E��D`�\\蛶�Z\u0004ml��\f\u001cO��\u0016������\u000f��&�UAS���NG�/����T�\u0018�����\u001e���W)!�\u000b_��6�-�Ṋe[�I�i�|Ҕ���\u0004�b,�\u0012�k-�\u000f�q��k8�߸�%cB�\u0013��&�d\u0004��Ӟ\u0016气�@)h\u000b\u000eY�`^�zj\u0011\u0003፹'��(�l�\u001fJ\u001ew����\u0012����W�\u0015�\u0004-\u0019�ĀY6𬦵\u0018�]��\u0001K��o�z낒 ;XI��V��p?���\u0005\u0013��۹����@@\u001d3ui�r�@L:��YG��g\u001fA���qh�h�\u0002_q�}lE\u0010DJHKVD\u0016\u000f�Y��\b��\u001c��|N~`���r�rr��ܧ����\\��X�!k����)t\u0012G��M-!-t�&�%\u0005c��\u000f\f�P�y?n�o�YG}�-\u0004%\b:����m�&`#�^v�\u001e�}d%X«���\u0015�M�7��(y���\u001d��Q�cm�Q|�\u001a��c�IGp~\u0003Q�\b���T��\u0015�2t��7R���\u0011�G������p��qn���J0\u0003ܣ������u.?�CC ��G2)�����2�>�\u0014�Hc�ߏ���=�mD�� j��1�_X?�8�d�J쫥!Dyp#Ɍ:�vf\u001c�x����鐭��$��T�_6#s���4UO\u001cp�v㤄p��{t\u0001n��st��Ė��4��\u000bq5\"�>�� �|�m�7^m�W�F\u001f0D�Z��h�Yx��b߄2�N\u0017g��L\u0017\u0017\u0017{ML\u0002�Q6�'�Ū�j!~G��r�+��߿�\u0019�P���:3�\u0007��reވ6\u000e$�d)�W�1\u0001������I����\u0014t(�\u001a�(Z�tQӔ\u001d=����v�a��R� Y镢����1N~�UW�2�/B�gD���6�;�\u00148'���O�%n�\f{�m\u0018יk���Ek2��w��p\u0015^��e��ɽK��Ϩ�e\\�ISv��o����Tc\u0017�?�����v�\u0015cwr��ubc�&���������[�\b嘦!c_�ٞ��\u0003a���Te�\u0018���\u001bќ���#U�`E2BYb(�--���)5����\u0001�\u001a��jY��%�\u0018Q *1M�j��?�ےxi瑽�d)�jU�A\u000b��Ҕ����4�\u001a���6z�^\u0007ӜJ\"�D� \u0013��{��\u00120eJX\u001d\u000e\u0004�\u0006�\u0012'-0~�5.)�\u0019�H����\u00122�_7S5=G��G�O�\u0017{y�+������\u00146X�a���L� d�إ�=K\u000b~d�\u0003\u0014LG��\u0011��9�+�,��y�\"H�PXB\u000f}\u0017&Z�.8p�Y�P߽H�*��}���a�}��*䋘 �\u0001��-�L ��YZ�C&*��qR:qp�P*�H����f\u0014I�;�|,�T��%\u001b)\f+-B�l�\u000f\u001e �,>:gq�\u0002��Z�,kU#eF�i��7�T��5�3U7:\u0002��h��*����M�\u001erQB�\u001b��$3\u001a2O\u001cH)�Wn�u̚�Y~���ũ1\u0019�v�����Z��=z)�(?[α�*�\\8�)nF�\u000bZ�N\u001dx��}yLS�g$3�Pa\u0019�دQ�q����̆\u0016y�\u001a�W߶���s3����hՅj|\u000b]L�\u0016��zջ\u0018�P�]������\u000e%�g\u001f��M\u0002jeL�KE��\u0003\u0010�zrg�w�>�朡��?��^�����[\u0014e�\u0011h-�j ���u\u0006d�\u0017s\u0016�ۉ�i�ygD6�ԑ�*�\u0011��/�H��co�����f-��/\u0005��h� F*e� _���KOɋo�f��y�ܓ2$\u001et�0�mZ��,�¦UR��>� ]���I>��\u0018\u0005m֝�\\\u0013\u0002RP�P�\u0017KE:���1��'A���n9���\u0019�l5U�\"F\u0002f�����&�C�lM�:��\u0003J�ĉ͡-9���\u0015k��g\u0019�\u0002bv\f���X��=����c}n�o�4�|2�{�b��)����5�6� \u0003,��\u0014�\u0013F-+���/m;�\u0012d\u000e������k�X��\u000f*����_;O`��\u0002���JN+��,\b�Q�lL���x��x�\u0003�0\u000e˲\u001c�� �\u000f�4Oai\u0007*`2�������գvf���\u0013�s\u0010\f\u0016�l�9\u001b]AҞ�ɢ \u0002��i��\f&K\u000bH9u}�\"\u0003\u0017���4AL\u001dէy�h�˟�#��\u0018��Њ��\u000bAq� �C���2'n�u���\u0014xcydeX �beO�p�`If�s\f��tG�C6���\u001ao�ʞuI��\u001e�8\u0012'�>\u0016aF��R����v�,5�F�I�o�>\u0011�ăY1J�\u0004\u000e��\u0004��2z�O\u001c�\u0011\\/�L�#�L�nX�3Σ$��])��\u0004�I摡=Wp�\u0005�k��\u001a�\u0005�)��:\u001b���1΁i#,�,D6�E\u0014��B�UϪ�V:\u00124u�F�ة�I\u0006'y���\u0007\u0002c��4�\u000bU�-N���J:\u0014 D\u0002/��0\u00158d\u0017��\u001c�0j���l��U|�k@�]0�\u00149/.�Z\u0005�_�q�+�\u00010�z�nԛy1�$ݻ�\u000b3����\u000f�x�O���ӗ�I��\u0002\u0002�h���\u0019��\u0019�����e��-G\u001a�?�Zr1���Z��\u001aU���:�e.Y�\u0005�孫.�YԼʎ�\u001d\u0015�Ƈr\u001f��%���9Q�X\u0006����ӭp]њ\u001a�:9$�d>�al\u001bG�j\u001c�mՖ0&洭�[T;y���ߐFd��}�9U$���aP�)^�F`u� ˘�= Yrh��矊r)v\u001e#:��w�X�U{���\u000f*��\u000b�v�wHL\u0005\u000ev+��\u0011���\u0012�\u0015��ܦܶ\u00116�\u0013�\u0011�iS�\u0017^\u001e�`��\u0004���!�� E��L�������B���*�W>��Ҕ�8z��YI��/�^��/ִ\u0012�����u�\u0015.�tR��yf\u0014�\u0004�\u0015COL��ޥ�P��U\u0016 �����VL�0�N�J�~!��4F''C#�g���͒\u00148@�l.鿙�����Uj��\u0019E�~��,~��t�4�C���1b�=\u0005\f�;j\u0001\u0011��f\u001f���-���\u000eg �Jm�NR\\�� y�ow�����x�B�%\u0017�g�\u0005�\u0005K�'~�H�\"e/٢��%��\u0010~ �^\u00138��Q\u000f��\u0018��\"y\u0016��|\u0016j���� �ҡ�*\u0019\u0007֮Y$\"z���A�a���Q%�JI��v ��ǅS\u0002\u001c\u0001J\u001f�n\u001e�Q�'��Ⱦ=�5KACO2X�h\u000fj寱�����[\\0�rA\u001a��w ;���X)\u000b1!�b���p�Y.A�����F�C�\u001d\u000f�:v��\u0001\u0019j�\u001a|,�c�ׇ���vU����k�U\bI��'Z7����L�w@� �HT���c�$�!���&$� �Qy��=QG\u0017�0�Y@G䞿�~|s���\u0016�n�p�$ۖ6��Q~c\u001c�4�\u0004-��7��\\@\u000fT֥�=\u001f��\u000ew�٦T���h\u0006Yk��B�K�0�0P��k���L��)H�Y}3(��%^λ���m��h\u0005�U\u0012��I�\u0015�u�5ijm_1�� ����d(3�&Mu�Z6`b�!,�\u0013��K����m\u0003L��ӹ��M c�y��\u0007�\u0001�}~�[�u\u001aN\u0001(���{a\u0007�1��\u001a����m�\"���5J� �J]\u001a(�&�(�M�D��\u001e�\u0011h�&ׄ\u001a�\u0012�\u0014�՞����A�H�\u000fGbγ�z �`�0�o%��������׿�8��>;$9�\u0013\u00105�ɮ�(\u0010��NY\b.(y�I�I,T�\u0001\u0019o��aSRdx\u0017��\u0015��\u000b����7^e�OF��VH�Y�����(��G����\"\u001eݚ1.����m��,u�x$p\u0004���i*^���#�\u000e\u0012��gj��\bf���U|\u00183:*\u0016#���fsVl��K����\u000bX}C�(��(k\f{��є�i��EdJ���k\u0002��\u0007��/�\u0007 ���$@\u0013+O��*�Y\u0014\u0004푹I�\u0006J\u0010\u0016l� ���q���;\bzvY�\u0007��(\u0007�^1D�*�DM�I� �0��\u0013��F:�םѤ˨>\u0006a�ɣ�T��\u001cP\u000fU ����\u001c�\u001a�3l��I�\u0010!\"�-��\u00032G�F���'\u0002~�b~#a$C~v�ב\u0004x\u0004�D\b�)�\u001b%\u0016�Vf���djP`7\u001eӣz���\u0015�9�lK�O\u000e�p(�_k`� ��\"ҥ�Y�9�{�}3\u000bٟ�b��\u000bʦ�\u0004bx)�>��Ȭ> ��Q�2��̉P��\u0015�\"���jNe������7�u����-��}����/�\u0010�2d^itb���;}��[��c;\u000e�\u0005ֆ(�\u0004z6]6js���[p�1��Y�A�\u0013\u0012�P�?Rp���\"\u0005\b�(g\u001f����\u001fOF�\u0002�@���\u0005^��\u0003į�6>F�>�\b�������DJ�ۯ��`�1��WӲ\u000bOf�gv����f�C�ϓKp��j0HT��j\u0001�\u0017R�f�5��7JL8uR\u0013q��{z��\u001a�Ozľ !�\u0012Z߼�� C�\"\u001d�\\6\u00162ی�\u001f-U Y���C�-�o�v�gAV����{\u0013�\f)�\u0018���o����:jk����=� \u0015\u0013b�\u0012\b�`?\u000f��Dz��了�V�\u0014\u001eE�k���\f�^��9f�=�\u0017.TÕ�������MT�$\u001d.��v`��]��V�[�bn[D��O5��΍ɶ$\u0013y���g�\u0010����{��\u0016\u0011���.\\����c&��?�CFp]��������\u0002�wy>H\u0006t��眞�I��9qƆ�0���o56�HuZ�g�\u001esqf�� 8D$�8�`�_\u0004��׷8;fW#\u001b��@��_ �-��E�\u001c�`�.� �\u0018��\u000f�\u0001�\u0003�h��/:\b��>L\u001e��CۢB��(������HfR�7\u000f�|�&�\u0003���~��8^�8�\u000e++\u001a���=�3�[�\u0007�h�\u0001\u0018��#T��+�`���C��a\u0017���.\u0012�nG>�ǯH��\u000f41��czn ���ԟɖ�����\u0019\u0016b\u001eZ�c\u000em\u0012���\u001c� T!�z�\u001c'6c:�a�(�m���s���C\fH]�8ʵR`2}\u0012�3 ��� 3Y#�FF\u000b\u000e\b��\u0019�Q�P�mb��\u0001O��Q�F:��# E��d�nwт�\u000eŲ\u001e�� J��e\u0001N��� ��\u0007 �g�\u001d~1#��\u001b,铧{�X�AL��x��hh��Jy?��F\u001c����\u0003of�~~IZWH\u0016�K]���\u0013�go�l\u000e-����j���F!\u001cˌRڄ7̀�b��%Ͱ�/m��\u0018\u001e�Q��\u0013�EA;��S��*S\\k߫T�x��|�2���G�;_p\u001f�\u00195���\u0002��$*��5 I�O'�OJs���\u0016�cH� ���gKe;��]9a�\u0002|�P:u�\u0003��}�g\u0013�\\C�^��-,B���FE�oY+�\u000eV�]TZ��) ��\u0006&��(�o�Ai8*�\u001f��#̌�iPP3H���+�Z5j*Ƶ�Ǒ�h�)M��VfҠ:]D�\u001b��_�40���H����6��!X]\u001c�` ��d\u000b��P��!`d�._ӡA�8x ג�fi�xH�9�/(02�,�-�S���8M��H��� ���S��~�� ���/| 0�e2� �f��M��.��� �`e�\u001eՌX��y����-�\u001d.�,03\u001eI���,/3�b}I� \u0007����\\P֞\fI%�cv�G\u0016��f�X�X\u0007�5V&��59\u00123�\u0002�E �t��kF\u0005�t\u00148��F�D\u0006 �} �J3�X���{(*ZvI?�/%\u0012�\u000b�\"��_�k˨�L`zI���/s�>u�i����Ht���,��䇼\f\fg�y*��9�p���\u0005�=�+;ƌ:�!��\u0019e{�wf ▕���`ڵ^'�0U�m��>� Ei=%.PE�L\u000f���|��O7���*_k�\u001e�_�U �\u0012\u0007���!^��q�/Y\u001c�_Ώ�qn!\bB[�$�����h�\u0003!Q;�\u00039#�Z�Y\u0016��WBU����Ɖ^��G�Fi*�R���ĺ-F\u000b;=��bF,\u001d�\u0014%�q�>[3�uƇ\u000f T \u001ch��]�^{���Q�n{i�`)=���e �B\b�W\u0010{ņ��\"��5FP;��\u0011\u0003��\f�q�ll\u0017Y�1/�s\u0003�;G��RZҺԛ5��:�o vw�q:�($n��&�:'�\u0003�W>x�#\u000fy\u0016�5+2 /�φ6P�PH��^[;53����Wӫb���UD�ԫcU����׍��O�y����Mֆ�h��t�P�%�~я2\u001e��\u0006������u\u0014ځ\f�Z\u0018�Vd^6�.� ,�;>>n�C�P�\u0011�����>\u001a�E\u000f\u001b��\u0015�]��� X��k\u0019�Ȝ�pK�}ɵM�J\u001d�'Cka���q����;���W�B�k FEy�q�\u0012��\u001bd�#�����x��S\u0012���\u00171\u001f3Y� ��a�V7\u0011���������X�\u0012�v�D�C��j�����L���\u0017\u001eq��砻U�t�� ��^�����������t\u0016M�\u0015Jמ7��\u0001ueG�J�\u0010\u001d��k��\u001f�7��(Qdh\u0004���\u0016-Ah�w\u0015�r\u0014�\u0011��[�]�T�x҅)P���0�/�\u0004%��ǅ��R��S��\u0018e�=��Y� ��ӆ�W\u0004\u0004��\u000b�Ӕ� �2\u001chڤ�7�mnG6���F���{q>%�CNL��\u0014D��qfƲ���&M[a1T���F39�Z�(/\u001fy��#-\u00068\u0016�\u0013kr��d�9m4��\u0007ņ��!eqSk���y�Wa��f����1�\u0001��+�glh�?��\u001a_����ȿ\u0014�m��ET\u001b`��\u0017�x��891\f��hֶP\u0003(%9ȼ�a��BY>4�'[\u0003�\u0013\u0019QN24#$۴/\u0011GG�-E=�\"kB�'ØTXd*1��1�K};O\u0003\u0004�\u0010� �z\u001f\"�P��d.��/��=b��Y�и\u0007�U�lu`����kʞ�x�5?��u\u0004�Q\u0019���_\u00175m�$����3��\"H�{4\u0012FG\u001eh���%Kmu\u001fB=c���-o��!zB\u0015W�Z\u0007\f�ǀ�)H�߃`Wi�ɃE�\u0004Y�y�FV0��� .9N�L�^\u001f&�\u0010�Z��\u0003��\u0018I$C{�ҵ�O~��xX8ء\u0019�[D��\u001a�W���Y�2y�0ā�*�q#�7�QZ�ܖ\u0005��F�ْLJ*�3�$��L^�i\u0004��[��\u001a\u0019��\u001am�b�\u001a^�,2a�ׯUAd���$ *�Z\u001b���Z~��� \u0019m��)��[���˜�˻\u001cقQ�\b��?�o\u001a�?֦�\u001e�s�Ô,)������ �FI6�O�E���\u000e��\u0018;�_�6���!�c(��\u0003���\u001d�6��H#�\"�O��M'O�5\u000b=�\u0015of��\u0016G�řH\u000f��\u0003���Q\u000e괹��3���A:ѿ�&��H,�~?H��Ef\u0015.�k_B�� \u0011ㆺ���\u001a\u001bL��^ �*z\u0018�Zsm�A�P~�~߰..� bng&����3!T�Em�`��3��u3��bGS��@�Ǣd�\b�V�Ï\u0019�|\u0013�=R���W�`Y>��{���YoY��\u0019}G�o;b�J�ي\u0012$K�b� ����J\u0017���FE��CV�\u0010���e(�\u000e(�]�数\u0002��X��2��^We�>-lbު;�0���-\u000f)����l`ґ��1\u0003��q���L.\u0019�I�nD�+�\u001cb�ښ���'�\u0004]�ɭDk��Q���˫>\\��Zqj�W�6H\u0002\u0001�����Z#�ס=P\u0010�&Y0A\b7��\\�� 3\u0007Z�q�h���A7,M�Xȹ�y.\u0005���U�j�\u000b�h\u0006kcޘ��\u000e�v�\u0005�\u001f\u0013֬g�\u0005��)y�\u0013\u0007'*��]�Y\u0018@��\f>{풞��P��ot�a/�U���p��\u001dp{jPMzE��Z%f�,\u001b�?bS�/̕��ɭ���Zv�!��w�K�O'&%���S9�\u0013��b\u0016�2X��{'N �nn\u000e�9�\u0012�C�̈́*cn��h�A�r� C�B�\u0006��\u0015\u0011۫\u00021��q��3\u0002 8 �IT�1S�`��+�/X��W��¦{\u000bT�y�\u000e�F(m�S|�\b�*a\u001f�5)[��#�)�R/�����/�uP��'�\u0004\u0002���\u0004Hp\b�\u001e,�;\u0004��qi܂;\u0004Hp�ơq��\u0010\u001c\u001ah�i�C���w�ܩٝ�٭�;����?��z9���9�s\\�Ǽ\u0013��\u0011������!�m\u000bf�\u000e\u001b��J�}\u0015���C �C�d�6�\u001f��kr\\�y5\u0006\u0006�f6tei\u0006Īr$���Zeކ\u001fy��\u0013�\u0017 خ!�\u0019G7��$0}e����0�1J^�=��R)\u0006.�{\u0012��T�9��*���`�f�\u001e��z7��\"�z'0`\"�7g��\u000f��{\u0006$�تTqN��cw>�m�Bqb��[q>0�e\u0002`�uoέ�.�\u001a�XYW9�6���j���;�sö��M�ߡ�)}�ϔ��&\u0002O�\u0007i6f��$�HT�e�r����S�+�=��ďۼ \u0017p٦g��0{�\"�2/O L&9��?�M�\u001b~� �v\u0010��pv=����mJ������/���ǉH\u0012Ng!%���!\u001a0~О��|\u0019J\u0011\u001bUl��C�-�Ҹ|�Pe��m��ܫ��I\u0013r ��+�\u0016���\u0012���r�%�ɶ3�M�oG6�qM�9��L�)|\u001a���>n�m�~wi\u0005�\u0019�\u0019�w��\fQ|�K#å7\u001f�Z_8B+��6��e�C�q�a�3����\u0016 ���\u0003:�ݫ��n����d�z��V�$Z�隑=l��OX c��=�G��:��3w�\u000f��Z���~�\u000eh}k��Em��F�S+D�s�ε�~�>�;:����يO���?\u0015J՜����~�׭�|����\u0004D\u0002��Y��,i�8۶�8�\u001e��\u001c��yؒx�\u0004\u001c1ղL>�1�F5K�(���e~���:��f�2�Z� �����%�[����\u0019\u001f��L�uSU�3�c\u001e7��Xј�Lu�V\u0013�7}��QS��$h\u0015�{�6A������\u000e�g�\u0012n�o���g���\u0019�k4t��ֶ�c�A�)����:�t�M\u0002 v3�V�\fъ�0(7��3q2�z0S�>i�z��\bL��U�Bi�M�\\B��\"u|\u0005;� ���9���\u0003��\\1 ���\u0013_\u00053�[�\u0007/�\u001eT���71�_2�x�\u001d�xы�5���γV:�3��|c\u0011]��_ v�OZGNc۞���F\u001agb9�'ѐ�©q�Ew7\u00105\u001c�AйĀ�0�W�@bb{��\u0001k���\u0019����_�\u0014���K�aB�B\u0003��*y��� >�!��}z���� _j([�R΀�����p�ݣ�ب\u0017N\fus��\u0016g�\u0015����\ff��4l�]u�u\\\u0014�cF�\u001e�qL �\f�� ?��>mo��*�\u0010��\u0018�\u0003ދ\u0001��@\u001eߚ��I�%\u001aX /O�+�� �Q��k�\u0017�25:�0�K����֫\u0014�\u0006�o7�瞪��\u0016\u0014U=\u0003,����t��#_��\u0019g���Gڨ��\u0005q�K^��W\u0018�kCͳ\u0007Y�m@��C�/B\u001fZ���2�\u0014\u000b� \u0016L�w�]�͕UReps\u001d}\u001c$���C�, �\u001a���E};�z? ���\u0012���%��\u0002��e6�Oפ�Y��\b���S,+ܜ6�2\u0017�b�A\u001a�����4m���� ک\u0013�pR��|�����\u0005%r����t\u0013�#-���+�È�IJ��\f�\u0005X�3�tjl\u0014�3�I\u0011g�ȹ6\b�P�>4��@�6{}M���Ty_�5���\u0001�L\u0019���\u001dqN�\u0012f��\u001c\u0007�V\u001a��Z}%,\u0017�\u0018\u000fT&C��_���\u001c6�\u001f\u0003�\u0011���S���s����^����|��k\u001b���p���7��\u0011JSk���l��\u0016��fD��7�b8�\u0011�.)\u0012\u001b^��Hy3\bWe�V�SD�DCU\u000f���\fp��&���9���\u000b\b�[�L�1�M�y\u0006؆� �Q7\u0017\"�0ۚ:ZCa'����4tð�����N@ \u000f� ��\u001f����^t�\u001d����tݻ��thR������y7;��X��;����W\u000fPQ-�7�%m�p ���\u0010�\u0014q�;����SK�\u00016-��q\u001c�\u0010�S�,Ο�*�S�}\u0014\bH�E���P����/����渖��c,.�#̇\u000e?�\u0018b�:�\u0004Y٩/\u001d/�$_\u001c_�cU�5��ˋ�p�%\u0015���/Q��H�31\u0017Y��\u000e���\u001fn��$�\u001dPe,� ���j��E\u0019��Fĳ,)�[{�S\\\u0011c�3M�TL�\u0001\u0011+��\u001f\"\f��\u0001\u0004�WH�@������'\u0013\u0018/\u001b�\u0007�\u0007���6�ʖ�?;��\u0014�z�VA�_�\u0010�Z\u0017:�\"=���.V��g��]R� �L\u001d�|\u001b��@��T�a\u001f�b3�\u001c�[�k��c�\u0003�}���ܕ�f\u000fz@���z�7�\u000f�\u000b\u0018�ۆU\u0015��I��̌Ě�\u0015y����7�z�\u0003�ơ���G����H�ԏ�`!�iH3g�|�r�+�!�.7�\u000e�7~�2\u000ew���&k\u0001��M�o\u000fNH��rc�\u001b�VU�\u0013�4jS��H(��RBM�vv�\u0014��oXI�q>]���\u000b���a��g��\u0006&K '$#ѯ�Zo�o�\u0017���`\u0015s�G�\f\u001b��\u0018�J��\u001ad�]��=W\u0014`��\u00078�}նz\u001d�*Y.��\u000e� /�\u0017V�W�J\u00192�}ӂ\u0003@�B\u001f���-�O��a���d��\u0002�\u001f�wiTU\u0011yj3��2� g�i���pcS�In��B\u001a�\u000f�|�h�C`^�����񠲂D���V1�͓b�\u001az�\u0001�\u0012~Q�#���͍�\\\u0011��\u001c����O\"����d(� eo\"f~T�f~��A�|\u0017\"��Uh@�6\u0010�\u0007�4�|#�F9t���� f\u001f�FR�eI�m���+q�q��~�q�8\u0006����y�!�֯�G��x\u000e��\u0018�2v��X�PF�=��Z0�I_�\u0010�2^������a�~��M%\u0019>S\u0013�O�~G~��kw��'fs��ִ��9��Rُ��0m߯�K�~/u�*L�k�\u0002\u0017m�&�\u0013a�A�W$[��\u0004lt�m/\u001d��ϲ\u0019$�\u0018]��C�\"S���V�9\u0012u�\u0014��\u0002���'����ꛀYd��\u0006 �w� '�r�2:�$���\"5ʺ � �`�\u0016+�\u0002�?o�5\u000e}\u001c\u001e�6*�L��6�����4\u001b���\u0002���1�qZ�\u001c8\u0016\u0013��/��q/�\f\u0001�\u0012 �m�{^\u000f�����}�c��2����C\u0016\u001a�գYԥ��x�z*\u0012��\u0010�+�6�\f�\\�iPl߮-\u001c�3��r��������$�\u001c�'��{�.9\u001f��\u0002�̇s�1�\u001c0�'���4G߸�\u001a�a#��fU����~ʛ�:E�\u0010I�TY��9\u0010�G�l�\u0017L��1�F�\u0005�� �^\u001f���\u001c�\"K2�\u0012����Z�8�T�ͨb���6���BH�ޖ\u0012�\u001ep�8�x�����mK \u0007W�\u0014f�2�|�\u0003֜�\u0007��C���Х�3��:�;�Ǆ\b@��[\u0016��\u000f���\u00014�N+�󨢝ĕ=�f/_ݶ�CC�#\u000eb#'�G��\u001a��`�)�/=\u0004��D\u001b- �$\u0017c�A��AOu5�_�8\f1�X�e���\u0007\u0010M8��\u001f�\u001c\u000f��\u0017��rh�b�����2�h����g�u�Wcd\\��!�I��O�b��l�of\u001d?uB\u0019���_'�Jm�\u001a�ŋ�Y��y��3�vۛ+�7�~tb,�^\u001d�O�\u0002!�6� ��Soj��-$��\u0015�N���'�Iϥ-[s��� ]��o�81�RdB= �����d�,��Z/Wa:���t�0\u0006+��`�Jmd\u000f\u0014e\u0017�B\u0012\u0017;;�C�Tc\u0011�$=��1}\\+����\\+l�5�� �yJ�]�l�\u0013g�w��6^�����$�P?�H���R¤\u001f>��8������hA]XR�%\u001d���E����\u001ds\u001a�\u0007��g+��/�I����\u0012��\u0011�\u0007�(������\u000f5�'6W\u001e ��\u0013�;�E��q\u0012g����>�-\u000f���^D�v\u0018S�E\u0013�/��bu|?\u0016v��I�\\�-���1\u0006���r�\u001c�\u0019���i\u000b=�j �~��]�H�uh�l\"�:e��ڱdS�*S�M���\u000eY.�o�Ӻ\b����;Z�P\u001f?h�1EL�\u000121��b\u001c�_Sc�ؐ���j'�1�3\u001f';.�\\���\u0003�\b5/\bT�?�cK����&H���������oW\u0012���ZH�\u0017F�%�\u001dY����y��\u0012%/\u000f=��}���~w�\u0018�Z\u000b���bkOg�a\"w����\u0011]��g\f���u�\u0016���Z�)��\u001c�a�F\u0012_P�\u0004��r\u001b��gjY+3�3��ݫ\u001c\u001e˯\u0010�\u0014'L��W D��п\u001b�� ��fͺ\u001fT�%�bb3� f��U\u001b8��Ͳ��/\u0011���v���9�l�Fss3 ��;S�q�\u00079�3T�.��.q�\u0016;I �aںbV�\u0003&����\u000e\u0004w��6 �\u0019���\\�ҏB$�>��C�h�`a��ST\u0018�p>�/�\u0007������Huj �,�gV\u001aKI*�\u0007]Ds��a AA1l�y��M�ܐ�G_�π�\u0014Ѱ\u0001��,�0��=J\f�I�2vd 9�fu/��F��a�Q,���HOVs�0���P��c�ғ��\u0005��G,�\u000b�^��ٻ̊ ���}-���r�7�X�?=���1_Շ�g�M��&�mD�co�Z�K�\u0005� ���|l�\u0004�\u0013\"��\u0006�h��\u001c�1>E��>\u0003��c�\u000e\u000f�\u001e_t|�Ͳ�+o�ž�Z�y�Bq���S�\f1i�o�\u0017�i���5;��_&� ���\u0007\u000bV��\u0013o� �p U9?��-����@:D�Ң���iK��\u0001��K\u001ac_��c K`>\u0015�zWAܐΟ\u001f|�$�=� t�>�䧟�\"@\u0003 aBC\u0001LȬ�gk7A1t��G�9>t������:?\u0010�t�DT�:B��؜�I�B\b�m�#�M\b�g�E{@]�3H\u0014[�\u0012�ٖ�-�\u0003Ǉ���̱o�&\u000b�s\u0005��q�b6\u000f���xx ��3��U�\u001e�D��-S��Ag��\u0004�W�8�\u0018;�o\u001c�=ǜ���\f7�Q��6��&f��$)�\u0006c��G�xr\f��\u0010P\u0011cĩ�ÇP.�ȣ�jb\u0012=\u0007\u000e/@e� �ݼu�>.mS\f��+�9�\u001a�z��\f�)��e�魮]7��!��{d�\u001c~���VZ��1c\u001e�:�U@�\u001a��g\u0006�\f0��n�B�~�\u0017y�{@�s���vܚE�0y\u000bpig\u000f\u000f�\u0018��S�D�\u001f#S��E)_\u001a�1>�\u001a+Y\u0005��\u0006�Bډ��7\u0015\u0016�\u0013U�J��\u0010;l�{\"`��\u001a�\u0007�������$�T��:�=\u0013PZZw�-\u0011$[�\u0010\u000f�2�= \u001f�f��3m~��\fe����\u0015\u0019Jؠ�\u0001>����v�te\u0003�q�ڄh����k&tK�\u001a�{\u0018Ξ6*pk�q�e�\u000b�W\u0016�i�\u0013vU\u0005\u000f �\u001a�\u0018�������@6\u0002 �VG�3\u000b?���it����`�L�K��?i>6�H�y^�O\u001e\u001b��U�}r�ճ�Ο\u0006\u001d_�A\u0014��e��\u0014܇HJ� T=d�ȥ���\u000f\u0012�K\u0006=0�.��,�\u0014��a\u000e�/a-�\u001f�\u0013�-t�Ԗ���\u0015\u0013����\u0014u-�ͬ��k\u001aꍬ�\u0015�b=�Ca\u001b\u0019����`�t:�$�υ\u0001/\u0001�O���s�\u001a��H�\u0012S�+�O[�A/���v��߰V�f#�@�r�\u0010�{�3�\u001cB�r�ω�\u0017�l��אEK�Bp���Ǽ�|�w�\u001e�0q\"��\"\u0012�\u001e��Ӻ���\u0014ɻͿ���_z�CIG�Ȉ��d�V9���QBˤ\u0010�x�ؗaf��됢��[�3\u0014XZ� :C>�\u001f��\u0012\u00035\fk\u001e�jl)��΄\\����s����n���7\u0017���喍���x�~���\f�����ڣ�Hx)O�V��I�,p�� �}�\u001d����\u000b�+�\u000f�K�\u0016�M(ۃ8,��y�_>�ڙ�!\u001d���H\u001bJ:q\u001e�3w�K=�)��~���R�󽠕�p���_\u001f�*���\u0004�r�!\u0014_C�=�ϋ4��ep\u0018(��&�` \u0005�>�U?{�\f��U)D(���{g\u001e�N4\u001bF�%��'O�\b.;] \u0007���\u0002J���?��^�R\u0006�M(�uH\u0001�߸�|��O�����\u000e\b�����\f��2\u0003SI�D@8�\u0015)`�H���_l����tGQ���\u0012��v�]\u0012\u0013rL��'cp��^����\u0018\u0007*���Q�6^&\b�l:t�?�7���\u0016����L.\u0005�\u000eKI���ƏVv\u0018~\u0015�xET\u0014Ph�@��>SEz̠hٻ?���5\u0011�\u0007�䏲p�\u0018륀�G��ϰ���o�\u0003s�\u0011����0rz�o0�N����3�]����\u0011��\u0018U4%��w�l\u001e�H�E��}�\u001b��\u0006&jo�}q����\u00143My\u0004��S uC�8\u00066�] ��k�A/M0������ת6��F'�K\u001e��k>K����怒\u0015\u0015�(�c�\u0007�! ��'m�\u0001{�+�S*\u0019�pf�av��\u0012�BZ����ϥj�:{\u001b\u001fQ�\u001cM�O�\u001b�L�RI���r\u001b��c\f\u0019��9�\u001dW�U�S}!\u0011�|������r�\u0016\u0015+��FM8��dz��\u0018�E�\u001e�VÄ�h�m�|;���;�����\u0012]�2�?г��^5�H@x5�\u0007\u0001/��ju����~p� ���>&��}�ϐ�G/�A\u0014w��$���@�D\u0006��\"Eoa����Cɽ��_��\u0014�R���T){J�GMT^?�\u0014\u000b�s\u001e�H~GF���g��yżՀ���}\u0003\u0002h(x�a\u0006�4g�\u0019\u001b��\u000e�u�5���(��T&`��;�I�.��z&.dI��\fÎ�.o�\u0016�te(�\u0004��Y��\"����\u0006�J}\u0016��\u0001M7���Ո��]^�\u001a9�m��]D\bG\u0014�9R�����`�\u0017�E�?;���Nk���ʽ�m�'H\u0004�\u0017�\\��8T�����\u0010�n'F\b�[��or(Tp��0�%@�mLw�?��3��\u00190�{���6\u0010�'�D45/R{K�p��{[[ta;2�?�N��aC���_sݻ>f��y�T����OΑ\\��!u\"�ke��,_\"\u0011��J|�\u0019��\"|p4��\u0007��h�I\u0013'�=9�\u0004�0~����~ɝsF��o\u0002i��x�3S ����N�¹Fx\u0012U.��y�\u0014��\u0006Fr�S!Ka���\b�\u000fKX(93�V$\u0010J�1\u001b\u000e��D\u0005V�\u0002v�����f��(fxY�B�\u00165��\u0001�c�>�t\u000b-��ߒv\u001cI�\u0003�1ֈUM\u0002S�����T\u000b@A�9'����mF/�\u001e�\u0010���\u0013w�ƪB5;$T.�����!��忦\u0001l�,\u000f��̻C���\u0015��d��N�Y�w��f�6k[q\u0010�j\u000bန�*\u001f�a���\u001atu�g�,LS\u0004�v��� \u0013�B�k\u001e���q���E}�$\u0004�J�0�ȩ���\u0004a��\u001b/:\u0004�e�+�5:�/!�.����-:P�O7�������\u0013�6i@m�^!��i�yED�25�&�1\u0018.�u$>\u0002ƚ��k���,����O�Iޞ�$&\fc��́%%-韠1\u0017�{�\u001cqp�\u001fg\u001e�J�\u001fs\u000e(�\u0018\u000fM\u0019˽o��j\u0011�\u0016�1r~�����n�Xe4����V��n\u0012�yk�Sm\u0006�/D����/c*�\u000bRr�D��\u0019f�\u0003C7�J���{���qm�\u0018�\u0010�v��Wsj{t�����\u0003\u0013����J�Ǻ?���/d��.��E&Q�\u00112�u�\u0001�+%м� +ˋ�fA È�����ZR\u000b� �jm��c�7�h�3;�4���3�X�x��bn ��\u000f�ȥ�\u0005\u0001/pM�p�Ϟ\u0001 S�(�f�l�y�[��\u0012��ڙ %[b^F ���\u0012�j�\u001bv\u0012ӕ�\"�⭌t�TW�����f���_ɀ�0�\u00177U�{�W\u0001^�+�\u0014�^k�v�U\u0002�T\u000e�!\u001b ���g�y�7+�\u0014{�ƞ�L��\u0013��\u0012u��\u000e��c��\"�ã����xG�{l��h\u0014�s�\f��\u0005�O:+�JmZ�x�UOJ�%���q��\u0010�r\u0011VHU��tlPP�\u000f�˘\u000e~��\fH)*\u000bZ�V{�i|\"�:�}�l�OE ,�|����ֵ5\u0014�E�yS��/�}A@�y$|�G|+W\u0005`?%�OL�?�4�a\u001e�d0��C��S4C0��`�)� O���e�(z\u001d�ֺ�-X+.�=�^�\u0019�\u0003��F�\u0011�N�CƟ�)�e\u0001�섺�\u0019\u001e�\u001b��]0��f��R\u001cSp�G�$�\u0018ш��X}�|3\u0005s �\u000e e��\u0018{\u0006\u0018��?D�\u0019�s^ǋ(ŉ=\u001e\u0011��%r}g��)���u���\u000b�[�\u000b���=�ڈ������u8� �YZ]\u0005{as\\���cN/\u0018P������M\u000ft}�к�#V�?7��L��d\u0011�x�\u001en\u0003M{\u001b=�3Հ��S�\u0017/\f�626[�\u0015BP�Dz�\u0007�\u0014\u0016\u0018ux�\u0001�sy��l��/#��*p\u001e+��������\u000e�]nB#n��\u0013����KБ�_'�S�A\u0014\u0006�\"c�$��f\u0013�c�!�ȡ϶i\u0015ep&h���`�B�j߼\u0015�O U}�u>�\u0015^r�t��\u0003�o��\u0011k��kJ��~@\u0010F�3\u001d5�&�������J�۞x�\u001dR�F\u000e�HmSi�M����+=���Y����3a� �TqʞE:�EH���\u0013$~����\u0005͵\"�J�\u001c\b��G`��J��\u001fs\u0003�`B=�\u0017��ו�L�*��WY\u00150?��\u0004�s���g@�!`����\u0019����PI\f��nL�v���ÐP��c͔�\u0014a\u0014ۺ�I�����!�T��EP��S��\u000ec\u001e��[b����tqe�asD��������l~ \u0016E�xq��P�\u000f����t\u001d�\u001aj�v/v��!;]W/�\u0014�r��י�逯!�F��T���a�L\u001f\u0005lg\b�|c�D\u0017q\u0007�\u0012�|�\u0016y�%v6/�\u0010�+�\u0014�_�\u0014���\u0010Ҍ\u0007�i�\u001c5S��ѿM��{���a�.\b�\u0006~��!�x�*�MI���+�\u001c�I�p\"]\u0015�!����\u0003�o��\u001fy�w�,���\u0011vj\u0004\u001f� 4nc\u001b?���_�Φ J�����3�Q)�*J~���JH�7v�\u0013Z��R%+�� k\u0017��\u0011�\u0012���d[�Q�ϠA�zs����ɖ^�N\\��W�=B$��*`���\u0012�n��\u001a� O��c���9��~�\u0015qƒ�\u001b\u0018.�Wkʜt�'��CL\fO�*��o���&0!\u001b�l\u0005R�.�\u00069Q|[5����}LJ�q�~�~��e��Un��\u0012��\u000b\u001b�\"�o`\u0019����-K�6\f\b�3\u001cխ�������\u0011�A\u00101�#I�_�9�\u0007j�[�35dO�ݿ\u001f\u000fG;� #`�%(b�h��#K�Fp��19I���႞�s��ya�.0��Ns���6-�K�P��aB�3�\u0019`�\u0013I�:U\b��P\u00153\u001d�Ԩ��\u0010\u001e>���ҟ�\u0010ɰ;r�c�B�h�x\u0013�e\"\u001eRh\u0004�V�Um��+b8I�����\"�)�mx�\u0002c:�V�\u000ey�a\u001b�Q�!I\u0019\u0014� P���x� \u0007U\u001a5.�.}�� UJ����Ѓ��6�f�:�5Qՙ\u000e�{Gr���V���j�.\u0011zP�����\u001f\u001f�;� \u001d�D��g��-U%\u000e���\u001cً\u0014Aq�䀋G�N�j\u0007��I��f��\u0018�q��|��ܽ��yD7yV.�|��]�}�uZ~��X\u00160Q�*\u001a�u)\u0016���>\u0013���_N�\u001cE��\f���.\u0012�Y�Qu��=��CB�G��t\f�3\u0016�\u0019R�D�R���-�{��c��R��s\u0019j;g4\\'�� $�F!pA��D��D�gd���\u0006�$C2�e���kGB�U�9n��9Z�3��$g�,cO�g\u0010`� N\u0014�����N��Rl��-��t��� �ʪ� �=G����H�X\u0012�0�E*t-�� �ef_aO�3X�n�QR��2�޺'|�m��T,\u0004oS$�ꢵ��\u0012�=�=1̔��Iۺ��}�)v\u001e��\u0018�D��k���c�\u0001�nBP3�\u0002'���| �њ�����y; ����m��cW\u0013�y�\bB ��aR\u0011�\u0011�{�\u001b\u000f#�9�y���\u000fL���D)��M���@}�%#��ܷ�!�A\u001f�T�*6�hԥ�RD�+���ԓ\"��[P\"hͭ��� ������XJ/� �\u0002WC1\u001fl�\u000b�B��v�t|O�w��\u0002x\u0010\"}�\u0013'��� p��(gN��މ�z�wS3+e��5>ZŊ�!h��q_@]�����\u0004���H�Mn&��\"c\u001e�8��T�L�M6��n�NB�wq�x�\u0007��\u000e̼�\u001b�]��\bN�UͪA!4��Aὀ\b@��~@����\u00154E�\u0006��\f:3�^�\u001b��C\u0016{8\u001b�9\u0014�\f��H��f��\u0006�\u00063%\u0004�`\u0005M >\u0003��\u0019\u0007�>�-c��q\u0014��\u0007\u001c?�UT�?�\u001ebV-8\u0010,�U\u0007�{*̤_�C:�\u0019f�{`׬�~�_S���\u0002�C`��s|\u00103eh\u0003�0!P\u0007�d��'����|�Ui;\u000bh�\u000f#该��'�A\u0019��.\u000b ����?Q�ۄoYs\u000bh\u000e�I�,o[���h\u0014a���| ��>�_Δ�.q\\T�֍ \u0002�m���#�~��Uɱ�\u0012�8�9\u001bN\f\u0007]�uxWM�(�a�\u001b�\u000f/)q\"ѺL�N#h�N�\u0018I\bLLL%��No�\u0005�\u0006\u000b\u0013o�\u0001�\u0010��>�g�\u001d�����l���9B�����\u001c��]x\u000e\u000fu��p�}ᯜ\u0018��ѧ=��ҵ���%I%��\u0007Z\f�v7SЏD炙�}� �h?F\u001a��U\u0012��J�$\u0013V��8k,���u�\u0005ߵ�7�A�\u001dc�����x\f�k\u001c.A�j0ެ�j������p6����eu���Z������xr��V\u0001%L6c���\u0014�����Z;/C�`�8���B���?԰t���;y��7M����\u000ez��F�}Ձ�T*�� ��� YD9W�ZA�\"薀�np��\u001bA�0�!A\u0004L��濴ς��b,3���nT�?�~���\u001c�y(\u001c�\"\u0019�h\u001e\u0007\u0005p�ic�\u001c=��U\u0005�+se�y\b4�\u0019 ��c�b!} +�\u00054��AB�H1;9K��Qib=�����2EL\u0014,�\u0014�'=�\"\u0012�[#*r�P2C\u001f�A\u0018Y賙�\u0001�V�^\u0012?�ZH�2��,RB��D\u0018��R-�~!�xh\u0004}�v���#\u000fe�Fd=i>�s�pG�g@D����T���\u0018�h\\�Qj�Ԙg.����3��ѿw��Ay�����\u0007������3����\u0003�Ѵ)�X��\b}H���}c�{���=9L� O��e�t0��U�x��y\u001e�A?ʌ�خ�\u001d�s�u��v�R\"\u0016�Q��\u0010X�hpCI�N�sG9_\u0014��y�U�����\u0013�\u001a�%�7����>_��M|�c)|Ca5�(\f!I9��j�q\u001a�KmB��\u0004}u>F\u0019@&)��\b\u0014О$\u0019�!݃��,\u000e\u0012��j�8\u000b\u0003>��\u001f�F\u0013\u0014ߣ�\u0001U�`/&Q-�\u001a��\u0011W�!��߿\u000f�!Op:\u0015O��l\u001a� uOP8l���^0��KL��U��T�j��[꘽�\u001e����q&݆\u000fMT�B��3�\u00126 �!�:ii �FXnb\u0007ٹ��]Vώ��\u0012~G�C���V���\u001dR��ǋg�\u0002�3��mM��'Q'�ì �_j�r��T\u001cǏ��(�>cQ&���6��\u000f�K\u000f�'L\u0011^�SG\u000b�AR�o�d���b�����P�\u0003�E�o���eb���\u0006zS+1_�\f����v��nM�V�\u0012ch�\u0006u�y�Y\u0007\u000fӄ�\u0015���Y5�鍑\u0012��\u001c��qE5 ��:�Nh�mUu\u0004 ��\u0015�#+���SJ\u000f>��k��+�P�\u0014.��\\\u001f�\u000e\u0005\u000f ���guu E���w�r�$�E�g\u000fz�o�a����\u0014r�T8~�h�K��s�>\u0017���A��J��\u001aͭDT 9h��@��ý%D�v��C�\u0018:]��3�ȁ�)�j��J,�8�\u0018�\u0018*�p��~��۾rRPv�\u0019���uH)\u0015vO�\u000bx7v;�z����F\u001ezJ`�x�姺A{pU_�S�:��\u000f��W��Ͻ��\u0001������X?űo�*�:�����\u001b�֖==� g=�\u0013��\u0007w��ވJƸ+w�5 \u0017v\u0015� ]p�\u0010i���� �ݿy}[4�na8x�V\\ʸ�u���y�u��з�5y�Ȭ���Ӆ�#�\\K\"v ԧbhlפ�!vig\u001cw�\u000e9�l>�#�\\�\u001dR�DԒ��+q��Q�(�aMɃR��R��O�/u\u001f�d\u0007�\u001a\u0014 �,OR�T���ν�K�Wߝ��\u0003b\u0017\u000f���~B��.:;4���\u0006��m�;k�,����`�K#?劺YE\u0011�)��SZ��*F��N�\u001c�>`H�q\"g�iI���)u���ב�2�\u0014�KR��v�C\u000e�kQ _e���bED\u0002\\ �\b o�\u001b� �6:��|�����E�#[��N\u0015e��ЖY�o��٪q��\u0013�˪�\u0016T�[ �{�\u0012�� !�y�B\u000f�ȸj�G\u000f\"[*\u001c3jQ\u001f e?��W\u0017ㅮ�A�UJ\u000e\u0002_������{\u0002E2l2�����\f�/C�zw/��۰q�s/AI\u001b|�7@A\u0014���q\u001fe8��\u0018\b��\u0013U&�7��\u0012VG\u0016U+�;^��.l�Pk4�X�3�U�F�'�\u000f����gh�L\\/���z�V\u0007)/u\u0016�s���\u001b����2B�?I^�tP����\u0014�w?'���\u0015Y{& �nhI���o�>�`D��v\u001e�lIn&7�t�:��Ȍ�o\u0007Ւ�\u0012��\u001b���� �[/N�ǎ�o��ƻ�\u001d���W᠈cϵhã�\bkh���S�V=�(�m����\u0003}2���\b��i�2\u001a����8�E�r���\u0004�pP��XkH��Ł�P����I就�C7\u0017|i.Fx�\"!\f��4�\u0001m��Nf��&3�\u0011�J��\u0018\u0003��*�o��O�\"�σ���ք\u001ezA7A�q�Bcv������ϟs��c�\u0001q���D�+2�֟i����,�a8|�:�C\u001b�s���Ħ�\b��� �nCt��B�l(�p\u0010�]��� ;��ꌧѨ����v���*i/�@�\u00106�/^M�u��(n�̅HC-\u001fyy\u0012�+Gs�\u0001����3{�2�kn[����\u0015���*Q�\fDȚ] �a*\u00027;���q��:z#\u0016DN%��UC���3 \u000b+΢��)8�:f\u0013\u000e�\u0002�'�\u0010���\b��j\f����\u0010��;�+��\u000e��h�\u0016y\u000e�Ľ�.>������C^U\u0004��x4�\u0006\u001e\"���RG�G��\u0002�HC�O��&\u0012yG�(Wu.F\u0018ֺ��s��}M�ʌ\u0010�\\\u0006�\u0015�\u0016��j{\u0006�\u0011aoOc�V�\u0015�Y\u0005s>�f�e��ϟ4�T����2\u001f�)\u0003\u0014=93jxU��y�\u0019��!\u000b �~����H'%�&*�S�=M�)-��6�J�x֣u�3��\u001b[�~� ����\u000e2Ԓ+@\u0018���\u0017m��h���w���r�\u001a����܅�nD�\f����V\u001e�\u001eZd��V�\u0017 \b\u000e���\u0019h�f�C\u001e�^[$�l�\u0007\u0014�0��m�.�!]�˖�2�児6��7�T�T�D{�j���ꅷ׹і���oi�))��uKr!\u0015J稫?\u0011��K*�V��i\u0006�bw\u0006y\u0012C4Tҵ�k\u0010\u001c\u0003�I��$u��\u000f�\u0019��vp+2�~�b��82��,;l9D-qz\u0017o�\u0016����*\u001d\u0003\u0018�z`-��\u0019�ϲJ\u001a��O�(Rg�\u0006�y\u0003\u0019��\u0006Y��\u0011\u0006ca�\u0017z\u0007\"ڳ���j�-E;^Q���.��O\u000b\u000b\u0014`(��y�\u001c�\u0012�pr��_~�9���\u0004�\u0017��\u0004�=\u0003� \u001e��܈B��yY�[�[z�5�Y\u0011G�d{�����y�?AD��\u0007\u0017v���f�\b���\u0007.h��*52O�\u0011\u001c͸xY�j \u0007\u0005\u001f�T \\����3��I�\u0001g1A}��P��3�q\u0004>U욓�\u0010��h\fr@��7�D�j�\"I} ��Bᗜ��p��*��x\u0016N�g\u0005�y:��T�A��7y��n/\u0001V���Ñ�=$6��|�j��X\u000bf\u0019�GV|lo��3��DW�\u001e�\u0012�\u000b�a`��fb�\u001a5��\\6��r?}��������X\u000bk-@�u�k�\u0014�� �;�ϲ\u00152�٩$%��f��6�Te֙\u00136�����-�1�E��N��0�l�z~��^�x�é=�@�v\u001c�h�\u0004F�3��|�Ǫ�@��4���O.m�l�%H�Bٚ��\u001ft*\u001d�~|� �D�|�՘7\u001e,�_S�֗\u0013��d�\u0006�\u0006\u0017%/���\\�tf��:� Qe��&Bo�Q����}!\u0006����\u0018l�z��1�X�\u0016�@q�[^\"��VO*C��#�^SKl�\u0017F�'��`A\br�.�m�~H '��\"���w(ٟDߩHͼ�'�,��o����mC\u0015q����y��\u0014��\u001b\u0017nc�g�zp�6���ʡ�q7A%5E�e��\u0001jm�\u001f�,��(\u000fÈ\u0018@P��o�9O\\��\u001f\b�����2�V��Y ���� \u0017��\u0006��{�AR\u0005��\u000b����v�U�,��X��W��S��+��\u0015 t#\u0014�XU/^ݔiHR��!\u001e&0I�7>�&����'\u001e8�>+�$\u000f,]~�2j�b/��y �]S��D���k�2��Й��M#\u0018IT+�Ω�Mx�O?�\u001e��D��bbLȹ��\u001bf��\u001btwWWk� T��m��8ۦM����\u001c\u0005�~\\i\u0002�\u0011q�`�XoV\u000f4N\u001dV�ۿ�����U�\u0014�u�ߋ&���ϔ���\u000f�S��mk��\u0011\u001d�-�\u0010'(�F&�Շe\u0002�D�@�v^u\u000e3���ʊ�{���m\u0013Q�w�g@�\u0017��v\\\\�\f_ݯof9W�vrrv��\u0016p?\u0016mq⬀#��؜4Wwa�9���H��L�ܒ��\u001f���\u0015~ž9�@J�~S���obጼ���\u001b�h��\u0005�f��߼%tMO �: ��|������'�7�2s!�\u0002i)�\u0001���t���`�\u0016kд�ג\u0014\u0017\u00172�h�� \u00126{q�%���[��.��gP4��w�����\b)M�Ł/M�\u0017Qkc\u0005�^C�n�=��6g\u000f�Kk�J �LL�BK��\u0010�ܷZ��w�]ǃ��\u001d\"�\"�,��\u0004�����g\u0013 ��77n+ƪ��i([�;�g\u001e=�m\u001c\u001bx.6O�\u0019˼�H\u001c� u�|{\u001a� +���\u0011+���R=\u001c�\u0003^��˳ ��M�L|e_a_�9\u0001U\f�y��e!�/�ًhR�=�^��5t.|�{�G9\u001eÚMC�޷��O4��sMF��,W�˚sR��ܼR&���\fn�nR%F����j���9�OD���`��L���\u0002o�\u0003����7��_�'�̀�������\u0015#Q%��i�|3q�6�!*ٷ��ݲ�\u0001��s zx[n�l��\u000e2\u001b��\u0011��D\u0001�s\u001b����}\"\u0004�\u001b��.M&>�\u0017Ҋ���D9��\b*6u�4\u001a��wҙ+��x�L�N���ZN�\u000b�\u0016�k��� _F�ui{�MI$�/Dd(�8\u001c��F�>��\u0019�t���ϫ��u�3 �S\u0018�\u0016���r$�\u0004��\u0015��_�2�i͋Y{�_s�R�\u001eЈ�N��x�\b���8�Q�� w\u001d?��{2����돺��ס�Lp����B��ȵ�����oN�7�ZƎ��^E���\fl��Me��'!K+�\u0004�4���gP�+C�+6.r� �\"���\u001b�����և�sAl�NUU��߆Ȣ��F�@\u001b�lI�A���Z��j��+9O}_�\b/����f���Sx�*�ɓ�\u00150d��\u000bU�[�\u001960q\u0013��\u0014�Z�'w\u0004���k��;�̒-\\\u001c�C���\u001f[\u0013�4�SE/�,��E�0؇lL� t[�z�\u0015�ȝO�%�?#�\u00066g@\u0002\u001a؝�3��}ӆ2�c�ZRs1Zh��\u0019���\u0007� ws�\u000e\u0004Z,���bE>R��Q\u0005T�()�w Ï6:f�\u001b�\u001b�S��^�\f m\u0006�\u0002oțkî�����=��^�a��&f�_=\u0003\u000e���c��O�\u000e��\u000e)\u000e�t\u0013va�h\u001bF\u0006!F�����SN���*u't�\u000b\u001d3}+ [+�Vt�Dj��v�Ҟ�\u0013\u000b�\u000bj2�ٮ4�!t\u001f\u0011$��ZCY���;DXeʧ����R$E��qt�W����ַy��\u001a;�\b���:\u001b��\u0015Yo����Y�ė��}޹\u0019y� �O��-����9K�EƦ��p\u0001#�\u000e�\u0005)�4X�=qo���3����R\u001a���|}1\u0002\u0013+��~}���>�)\u0001�nɊ�'\u000b\u0014��\u000f�&\u0001C��'��T�Ƅ�����My�,�P'\u000e'�\u0014c6/x�PT\u0005CQ�\"��K�k���a��@$�'pL!i�A�e��\u0019.C �\u001cx\b�\u0007��d���\u0018���ff��/!\u001a�\u0014�x~�\u001f�)\u0003���d\\��\u001eԑ�\u0013oglo�2\u00039*��f��,�R���lq�\u0010}�$\u0014E\u0002\u0015*V����z�d\u0011�ƲƝ�G��1\\CԢ�ǟ0��\u0006\f����!\u0017Ul��\u0006 �@X���!s�L�'\b�&��*�)X4[��9�Ķ}�8�%���\u000e�\u0017_-���a�˹�q�\u0006#w\u0017�$���p\u0015�m̾�m�aK�9�\u0012�F�\u000e��X�N\u000e���uF���H����֥mAF\u0007��o|eE`\"�(�{��xO\u000fCŷ��m�ĿJ4\u000f�\u0014���&�z�$�\u0004�XO��suA�9\u0002��D]T�/=�qO%\u0007d�὘!]��Hp==����|}p�����\u001b \u0014\u0013 \u001b�$\u0013w� o\u0010D\u0018Aɉ~u�4�Ҋ��\u0016�:8\u0002A��\b�\u0018�|p#k \u0007!Ό�:�n�W�UtQ��\u001b�M�� ��\u000bp�ڔ�{b? �׊N�M��V��k�\u000e�*\u0016�J��w�t(\u0019�E\u001d�J?&���\u0017\u0010\b+���n�q�R8-�^V�À�U�'\u001f\u0005\u0016\u000b\u0007���ԍ��a��� ���F�S��iϊ3,�#�S�|`%�\u001e\u0012^��k�ss�!�\u0007�Գ�6�3sݓU)d1D�*��a��2���ֽ�\"9v�\u001f(>�� � �Z��\u0019ҩ���W\u0015�7���\u0013}�Fy��_�@�l�ם��\u0007�.�d�\u0007��3�\b3��c\u001c�5��\u000e��/\u001b�>ȋ���\u001aMԢ��M�ɿ�$\u0017;޹�\u001a �\u0004�d�+�\u0007-}�p\u001e 朒�=4\\) ���+���2�\u001f�36\u001d��T,�\u00133:\u0015!��_��9����m�\u0010��vh� �\u001a\u0006�V������\\A�ݴ�=3Ě��\u001b\u0006�VX�֔�k\u0003���E\u0019{ǐ7�/�\u0012�k_�����'��:\u0014���`\u000bi�\u0014����!���\u000f#�H^\u0012�%�?!��k��DI-L�.}|�+B#\u0002c�旞X����U�v��GΝ,g\u0014E�8?�\b�������L\u0012Nl\u001ch� �0����8�]]X\u0006\u0017��u�aFS\u0013�R\u001dH\u001d�xV KDz ܚy\u0017�JO� &�S��\biܩ�� �yb#\u0012�&s\u001e�x��\f���B@�7q~�;�HzK\u001cn!JmrՐZ�>8b�\u0002ӂO���}ˋ�?��fB�n0��\u0018�3��t\u0015� �̜.\u0013�3`�;\u0016a��ݼN���*#�hʣ���v�9a�`�+�e�\u001bY��~�T\u000e\u0013�$�^�r��C�RCA\u0018%�\u0005���PX���֮L� '��#��$ �\u0018Ӌ���5} ����c�د6�\u0011Cz�]��\u0007�(�d�io� ��z�}mc��; W\u001b�Xj�SDї;qa�M\u001e\u0001��pމ�\u000e�ԝma&�S�\f�E ���X��{��j�K��ӝ��e\u0012\u0019>��\fܥ⊔ �DUw�Nz�͢�UC�̀bX�\u0018ݷm72t\u0006��\u001e���#���\u001b�\u001e%̌�]�O��\u0019�\\�^5h�k\f�9[3momO>�K�VDߑ\u0014E2M�g�oviw\u000e��}qHn\u001cKab\" !�r��� \u0016�`��3�q�j�\u001dԨ�\b\u0006AT݂9J�_�m�s=љ�\u0007FAvT\u000e�㽎8���\u001f#\u0013�\b\u0013�[��'����z�ǆ�%\u0001,'=�˫1���X�\u001a;ݖ\u0016;r��\u00189�-\f�ԻIT���u5��=�\fͮ�dz轚�\bunh�aֱ�j[s��9�]K [�A?\u0019�\b�����d-���nҼ%:�x�{��I#�( �bA\"��{}؇i\u0010�\u0006t\\�\u0016ׅg\f��1۩�w�z/?}2�*����D_��EL��V���:��6��{*�=+�A���\u0017�D�[� �LO��SQ�x%ȶ9�/���{d�@�I��\u0007��\u001cfs�w\u001e��j�ŗ���\u001cOޞ+�X0��5�\u0010mR�Q�9\u0001Σ�\u0002�l�\u001et6\u0003�TRu����\u001fS�\u0012���-ɡ�zi��n!�f\u0018\u0007��\u001dF�\u0018E\f�d���؜�^£p���RT��\u001bJ�\u001bBC��7yz�+���Y.e�R�*O��)+\u0007���3m�Ǩ�,Ur\u000fV�5�4,�,�*���W���A\u0014�`s��d\u0006�V��:q0\\�ϡ$ur�J��RG'f�R��1cͤ����7�y���kp\u0017�,H!K�PR�~6HUH���ck#G���\u0012Ȅ!��e\u001e5=�3�.��W�\u001d+\u0014����D\u000e\u0004\u0007Oh�\u0004���5y4�jhZ8��}~��\u0010���\f\u0018�v\u0003^�És�\u0019��w�Uꇏ\u0014��\u0012CS�mg]�.�D�\u0006u�BH\u0011,�4���j�+��}�R}�~&��H�1!\u001b)�g\u001d���^S�\u000biT��0s�!o�¼�p�9��,2A�QU�V�E�\u001d�������S:�]~\u0011�g���dc\u0016���\u0010�\u0017���\u0003\u0006_��\u001f�t�Oo\u0013�௶�.���4#�x��4��G���w��2f��\u0003\u0005�P��\u0005��ט���\u0010��Fo� �wU������\u0001�MTn�*� ���\u000e� ��\"�rM1^��`>�ʚ������?p�vzdR��ޟ�v\u0013�̼Qzۖp�� \u001d;�7���\u001c����)\u001a˙ާܫ0��^W\"��i~k\u0002�u`\u0002��MR\u0010ō�6D�\u0002N\u0012uz�)Q�w[Tcx��Vo�\u0002_�b��h>�%=�9S��w�d+À1w(�̦J��Bq�\u001fǙ ���:Z:���L\u0002�o%�%b�:Зw��+�j���P��v��\u0006�����#\u0002�\u0003ګVuE�\u0005݌����w��r�}������[��v�\u000f�4x\u001f-E\u0002�z��R���\u0002pˡz��\u0011\u001f&!�s�����I��J\"܂q ��L�vӤ\"\u0014Jӝ��J�=���\fQ��uJT4p�;+�/H�����Atf\u001d�D-.�f~*�5��� *_D���r�:Y\\\u001aydi\u0012=\u0003�6�'\u001f��n�=K���S�>��Cl.�\u0001^���;��e�\u0019�e\u001d�K\u001a&�w\fX0ɭ\u001dR���#O#̨�)�B�mcI��T�E�v����t�2؏Q���K�7�m)�X�\u0002�\u0007\u0002\u0005UH�g���̚\u0006��8�\u0005ĝ�\u001a;\u0005�Wќ��KM�k� �>��&kA�_!\u0012�\bM�\u0013�YI�^2��\\���$\u0013r��i�@\u0014��X^��Cgxi\\�w�륫~҃Jw�̩\u0013��ãny\u001eg�ue�:�0\u001bp�����[�\bS�\u0002��\u0013�M{5\u0019×��\u001d��\u0012k?\u0002\u0016�\u0001�/5[f�Z��\b\u000f�\u001b��\u0007z\"FH�] ɡ��-�47T��r\f>56x�{�Ú@�!\u0004�n�F�up}�\u0001�5 �'�\f�}��\u001b\u001e\u0007�{���x��dL\u001d�K�\u0005i �\u0011H�;��4 �;�tc7�\u001d���u�k�B���\u0010A =��|&�}GWU�\u0019V�@�Y\u0014f\u0011�\\�O\u001czX�P֤ xMY��\u001e9Qu�4��j>i�D @�\\ ���\u0010D�;�\u0017�q��%n\u001d�3]a\u001f�n��A�\u001fR�����0dV\u0002���%�\u001a�-��Vy�:�\u0018��l�y��(藺_\u00066\u001b. �v��w䄀�⫖��r��T�w\u000fo-�ň�ҥ[�(\u001fa���\u001f\u001d�\u001bo�p�Ὣ\u000f��\u001a��͢Y�\"�[\u001b�A�k��ގ�\u000b,�3 �x\u0006P���)�3N\u001e�s=M\u001ax!�Bɑ���؏Z��^\u0019��Ҕ\u0019\u0007�)�\b��\u0017Hk�����\\���g��\f\u001fH\f�|���\\~9�\u001c- �r�\u000b\"\u0019�\u0017>���i�@,e��I�u\u0018�\b�)S\u0011����Jn�)�X^�k�������\u0018�T�Q\u0005\u001fj�F;zHD�.χjP�5Q\u0018�n\u0011W��:�� �{��v�^ \u000f�Jۯ[1qc=�r���h��\u0014\u0004\u000eW��2\u001e8\u001bR�L&�R����������=G�W� ��I�G�$pE���?@�>Cn�鞉w��mwT�]|(��v7�9� ��A8��Sz�\"�\u0004}: @WeC��@�)\u000e'�Lt\u001a���˝z�!`5FA�K@n\u0019�\u001d2� ��PH�b�\u0011�����\u001fmC\u0004m��j(�ű�\u0004�� U�\u0011[κ��u����oH�SmGs�����X�Eq�LGkH�\u0019�\u0013%��e�q�Լ�x�\u0014\u0019��=m���M a2�\u0011λ��,+�\u0013�Ay��5�$�\u0015��Gy��fL{�V�\u001e��\u0001\u0012�uS�J\u001d�D\u001c�\u0016Jalv1�\u0013�m��ڱ���'B�F\u0003$dsGU#\u0004\u0007�\u0010M?�k$ \u0001�a��\u0005��\u0019A\u000b6���\u0014���?�b߇?Nu���4h\u0012��\f\u0012~�+�D�^J\f@�\bI���\u0016q5�\u0003����a�>�^\u000bo�����U錸x���\u0010�k2T8\u00060;��Xa����\f0�6\u0007~�\u001a}_���6\u0002��7X[����h�M��A��!/�\u000eAX�$��@Tm _�U�Ő��@� Y�(C��z���M�9��ܵH��ڔe�&��37���$��/H����\u001b\"8T�b���Z���6�)�\u0019H,#������/#20º�m\u001d��o\u0015X�_�� D2��8�m�\u001f���ބ �t�|��E�\u0010�t.�`;��Y $\u00075��dбN��F6Lu�K\u0012��,J_df�\u001e\u001e>�D����f\u0015 %�#\u0017���K�����p�{b�\"')XH�cߜ疕�\"� �\\KF\u000ej;\u0003#��q�#��u��gA[\"���C��V_��\b�sq�j$\f�f��\u0011!�E�\"�8�}��?��&���GZc�\u0004F\u0003N�&B�\u0006�9m� MH$\u000f�������5YN���熆�jM�����\ft�5��c��J.,��CF���~��\u001b�Mb,ܹLM�\f�-6� 6뢡�p��\u000e�Z|���\u0017���\u001a�n�,�����XB4��A,�醹\u0007Y��\u0005���T�V��\u0011лg�V\u001c4H���/4\fJFK|\u0001��D�g@YF�r����D\u0003�|2��\u0015��Zl��T �U� �^{�?�\"��j�\b�Dbc;�9c�\u0011���\u0003��\u000f�\u0013�\"���W�/U\u0014�\u001fS��e��;����qrD��@X�n�9hw� �^���3��k����8k�7=޲xPb��(y��\\l��f� A\u000e�,��\u0002�ɵ�̾�T˖��`Ė��6e��\u0019�w}�c ��\u0004` \u000f~����Q\u0002.ӄ�͂�g6bu�\u0018�F�\u0017��F#;\u0002fݺ�����\u000f��\u0014(���\u0014y�dB��(� ��/��,M�MW����?�[k����>��Z\u0013&���Inp�5��\u001ewƄ�&�\u0002�1%���c��Up���G��3��%{^}��5���ir�������o��͗�\\_F*����,�_�f�(�\u0016�E\u000e\u00186�\u000b{\u0006������\u001a|J�a>\"��} C(��]����\"w�{yB��\u0007�V��Z8��c���v\u0015��p�\u000b1�U�\f�����9��z��,\u0014|\u0012\u0014�TC3�\"\u001f1+z97�W������\u0018�[�\u000f\u001fl,\u0010}\u0015\u0013i\u000e�ۭ����*,��!V�� �[.�\u001e\u0010��`\u00061|�P�R�*g����}�~ P�)}Ռ�⓫��k.1�Ȧ��!�3��#C� �B�\u0010 ?�]�p�1�\u0002vШ\u000b�$�*~'�m��/���\u000e�kߋ��ӎ�������dcMj�\"�M�\u0002P�g�cޣ��$��x�O��]�:�\u001b{\u0015�f\u0017����\u0014h�����E\u000bŝ�xq'X�\u0010��{q�\u0002�݊\u0015 Nq�@�����A�y��wƹ8��\u001eg_�u���y֚�7m�9�\"�\u000e��T����*���\u001d��&O_�V��]:$\u001e\u0014��̋�^�!Zj!_\f-(����\u0003���[�aJ�M*�\u0019�\u0016�R8PDG��\b�\u0016��o���wLG���;�\u0011i0�q�%���7�G}\u0001���h\fhI2�΁9�������\u001f:��� �\u000f�]�j e��\u0004HTj\u001bz+�Y�'8����\u0004�pg�����q;ĹE�\f� �B �l\u0017�\f���hiѯ\u0010�!���7�u�rf-!����A��K�% @�5�s\u001c���\u0004� ����\u001d��/fT����Pb���HM�\u0019�*����N�\\��v��\f�ieh����ͽ�1T?�a{\u0012���nA\u001f$\u0007��TѠE��RT��\u0013�IX�\"j2����W �Iq\\^\u0018��̼lk\u001a��fF�$׀8/�\\�Z�f\u0006�%��˒���]n���$��%]�mn\u0016JC�r�xY�5�y���\u001d �H�ٝ�s�'d�-\"�����~cM>��\u000b5�!U�2�!\u001f�i.׬W0\\qt�2o����\u0010�\u0003CW\"�����\\\u0016uֳ�'�\u000f!�U\b�+z��\u001ah~�I��]~���[�_�\u001dn�L�f�$B�\u0007�f\u000e�\u001d \u0007�\u0006\u0010\u0005J�\u0003ȋ�\u0003^��\u001c��J\u0019�'\u0017.ވ���\u0006;S=c\u0016|\u0017\u0019�����H�\u000b\u0010\u0006�w`���E\u00060�\u000e���I�\u0001�c��NJ~{z酚$\u001a ��En���\u0004P-x�D���\u0015�}>�\u0007\b���C�!n �F�H��|\u0010\u001a�\u0005�\u0003l�#u\u001e��\u000f�[��V�B\"]���{?�I��D!�ߥ�\fs���Xv\b���6\u0011�MZk��n�^?r� ��2��k�ڍ�o1�&mw\u001bR��g�Mq�Ή��\u0018s����T|خM\\��\\\u0007�\u001e\u0017�^.�^�$��N/�f{cC\u0007��֎\u0019�㸘�=f�u�G��j�yk�Ih\u0015�g��mz�֨F\u000fU\fg#��NB�߀�T ��Ӷ�} EβY9�W�\u001f��~��ߣ�?\u0017׵�y\u0015�� RӧױG ކ2�\u00037hl��%a��?��U\u0005J�����\u000e{OGM�p�\u001e�����D�W���w���\u001f{���&��X�\u0004�\fS�|�ד��^\u0007�Dr{�]�kX0\u0012�$�hըwދV�R)��R\u0007�\u0004\u001eqW2�\u001c�ZG �����.l�{�^\u0019��\f=)����i��bő�F�����O��ܷ�\u0013�\u0014}�ȓ���/{���'��@�0�\u001a�~a�ܗ����(������b���|�ǳ��]�{+y�\u000eߦ�Af%��3-E!Ð\f�h���O/�K�gl(G\u0006�9\u0018[Z�eq\u0014��[�\u0011֣���nr��g;\u001eDn��|�� p\u000b'�%O��IS\u0013t��%y��ѯ��#|������_P}�Ɔ��\u001d�Խ���+��\u0016�O!h����F\u0015��7'�7˽O�A���ϴg��j�.b喫ݩ�F\u0003�W\u0018g�4�o3��}�\u000e�M\u001eا���]aB\u0012�����\u0012\f\u0007\u0012��p���\u0007��0:���Z�p\u001a���hZ�ɯYޤ\u00117\\�\u0011��m�+�+�V�U�g\u0012D��ht�\bK[+����\u0011+ۓ��[�\u001et\u001b��\u000f�]�(_�\u000f��F�T�����ڛ\u0004��px��mcC\u0003�=��(�Kª�/\u000e�\u000e��tFc�e^��� �+u��&wV\u001drI[��8�~Z�Q��\u001d\u0010�y�'a�ң�����&Gra��g����\u000e$sH=�`��hO v�ՙD\u0016@����\u0015-��/f���|��2/\u0018\u001c����GĲ� �}�31kz!�V�\u001f�@Gd\u0003��AKbh�|G\u0002_\u001e��Ce�)��pĹ���P�Ե\u000bV�'��.P�!\u0011v�����N���K��}�\u000b 2��\u0013��%��w$����%��&M�3����|\u0003�|�Gu�d/�\u0004�\bTvq=��\u0010bx;��¾Eݲ�5X\u000b�xG�N�\u0003�hs���Ik\u0001��\":_�\u001d�8��FV��\u001f�UO\u0007_�^�\u0011P�DŲüf�ŋ�)}D\u000f\u0015ܗ��*nQ?uBN�\u0016��+�\u001c~xlߦ�8j9��(�䣣����c��G�vX��m}T?tԁ�800��\u001b*v^��D��`o��i�ͥP�sdU mOX�g�����X��&y\b�x�v\u000bWh-{6&4�z u8/ [\b���А/\u001f\"���H2\u0004/ �K}Sz\u0011GSyUC\u001c��X�P.a�ٹ\u0005Y����EЇB���>w\\-�\u0017D��@j\u0017�!�_{x�Jf�[\u0004��x�=\u0007\u0007\u0006���D�T�|���\u0002\u001aҫdhy�d��X�\u001b�\u0010�]�@�=\u0012���V�%z��j���r���=�z)d\u0012�9TTf� �T �2��8'e�ڼ8�,A)ڻ;���9�� ���\u0001��\u000e��'|Q`�v��aʞF����=x!�͋�U���k�,'G��Y��\u0013\u001f]+$^���#��\u0005��Bt��\u0012s��˵��.�(v.�\u001a�%Ũ0c_^�\u0014�\\-��8O�L3*U��y\u0014bD��}���MNM\u0010c`�IO#�i\u0011\u0011ӰuIK��S�������'8 C�&.���C�'nL̏��`� ���}\u0015��K\u000eo%X\u0007��5\b��)�t��_\u0013���\u000f3�E���w 6f#�N�Y\u0004���bQ��k\u001f�_'�n\u001f(O:XƋH�ڝ���O��J\u0014��\u000b#����쬜� \f$�;\u001e�6)U�3�\u0016�����y�\u0001^��!\u0014f\"=4�����\u0003j\u0007\u0006s=�\u0016M(+g\u001c�7r�jB���\u0012��'���ho_ \u001dQjj�\u001e-1�m�a�O\bndj��#\u0016q�>5�x,k�\u0012\b��pWi��e�4�E�����x�*�� U\u0013Y��\u0001���S\u0019_SUP��l�\u000fk3\u001c�\u0002��l�\u001dI�|T �\fC#\u0005�t0�\u0018�r�����!S\u0004�M ,\u0019���Z�>M+�6_�TB���5cE��j��W|��ζ֓�S�\u0006�\u0018��ӫ�B\u000e \u0004*�I'�ʦ3�Vْ��Z�&`\u000e��n�Č|�FG\"��ֿ��\u0011�G`��`ϱ����k��U}�(\u0007�Zj�:wF_/W��\u001d&m�D\u0014�t����]�\u001f\f�Ư�n�q��sy�\u0011� =�ɉ�\u0013Aj��o�[\u0011�������.�|�@� ����xK����[�����iv�\u001c�\u0013\\:-m�ҙ`���V���\"�W_�\u0010yBc�%��\u0005\u0011 a\u001eއ\u0016*b��D�R ����v�\u0011�@T�H�N�����[X�4�қ1vn�8\u0006��D4�9����\u0003!μ�D8S6�\"Q��9M�U��\u0001_'x�1ܰ��G;���1��\u001f\u0006������$\u0010��\u0016�ߚ!_�\u001d*��+�\b֏\u0004T��X��\u0001���>��R�\u0002�\u001c�݋\u0017V\u00179\u001a�+4$\u000b?��\u0010?wATL;\u0018\u0016Ap\u000b�&�в��\u001f�+f\u0015���Un�WS�ЎW>�.\u001e�_\u000f�\u001dI�v 8�A����/\u000e�~�s\u000bO�\u0007�x���\u0017��4\u0013ܐʆ^\b\u0001p� `p5 A/��9��w��ZZb\ber�&g\b�\u0003�\u0007\bU?�K%�x�}'a�\u0011��\f�R��\u000b&\u0016\u001b\u000f�ۉ�p\u0005�h��^Ꚑ\u000f��p�h_~�]\"%T��)h�h��H,��|^���\u001c �\u0016����8\u000f\f�x'�M]�\u000b\u0019 )�vfF�9��m�\b�b/�/S�W\u0010�\u0018α\u001e�\"���*֖R]m#�\b�\u001f�Cy\"��%\u0017��\u0001Ka�I����;��q[B���\u0019ݙh\u001c�Oe+�Y�K��'��~k �\u001b\u0019�;�\u0013��[Mu(\u0016c�P�$�|U��N���)�� R' N�\b�~���\\�H1�e���w�\u0006�iG\u001a\u001e�G�\u001em\u000b?���>ӌg�e��\u0003�i�m�E���\u0007����\u0013SKѪ��b\u0007��$�9�\u000f��0R\u0007�3Kؑr+\u0001�w�����\u001c�����#�m$�J쑌옔�\u0003�^�\u0002�O��e��\u001fѭkM��&`�=y�R P��`����7EL��\u001bTx�)�Q�-\u001a���҇�J�\u0012�.�!�l{4���\u0010�N��\u0007�l�`�i:Jb�jI)[�>��G�6�N���p\u0017�����%��$��q/�\u001b���4Kh}tQ2\\�>p\u000e�\u000f��2m�[.�WX��#��{\u0011��Ns�g\u001bW�?�-p0��*����:��\"��\u001fE�(���\u000f�@;8�~�\u0011I�\u0019�Kͬ��\u001d��N�u�gL��v����\u0014 �t��� 5�x^����\u001c{p�t�)J�p��4��\u001f�+/���ϻ�v�!*��ƕc����cvB���z$�\u0012��4ݣS\u0003�\\��:Zў\u001a\u0018�q6�/�Q�� ����W[�[��״+~'�T\u00146\u0010�i҄�Xwę\u001a�\u0019\u001b�Ţ}Q�za�ң����0�-|.I�Z���̛�\u001a��,�EM�W�D��CX�s!*q���\u0007e�jV�����P�F\u001c�=��;��\u0011\"U��#�F���c��r��\u001e%��\u0012f^9�q�fN�9H��wɔ��>:����\u00163�2X�.d$���h�� ��a��� \u000f�愲�\u001en\u0010�\u0012��SƱ�j\u0007����\u0011�΂�!�߹�\u001aY�C*�a�s\u000b���멊���Y���\u0018�/0�����U|6\u0019ZZ~_� ����*�94\u0018�Z��~`�Dؕ\u001b�(P����ZwBi7\fp��Za\u001c�ڽ\u000f��\u001e\u001c�;�d;�\\|���\u0016�\"����:^}7�� �v�x��ʱ*��@�Ig�1���1�;�\u0014\u0015�;_?�\u0004\u0013?Lx�.�|�kR�wtVg�4\u0002\u000b\"�F\b��\u0007��U5g�ɻ�m�\u0007\u0010�G��࢘G�^U�\u0003�m��\u0007�\u0017ï����'\u0019>vnppuo��J��d0����M\u000fk�� ��MB�\u000f�,\u0017��ꌘ�\u0019���#����Ṅ���MY*�\u0015\u001a5�-�f ��Za\"�\u0004�HjGJD��#�\u0013�j��Şƅ�֋�(PN�;��G�oa�\\�����ܒ��Sa�6�p�\"� �Q�/\u0016u\u0013U��c\\\u001esx�\u0018\"���\u0013Ύ\u0014�6`M�� +������\f��1��q\u0012u\u0003$�\f��?���l+��m�'��P��Ɖl\u0001zBFe�[h�i\u0007).�g\u000f\u000e���\u001e\u0005�\u0004\u0003e�vv\fQΤ�q\u0002A���;�9\u0003^3\u0014;A�\u000f�^\u0014��̘RZ)Up�fjC\"^����v\u000e\u000by:\u000f\u0018/7��\b���r���� ��\u0014\u0001\\{�\u0004\u0017�:ZQ_!w��ot7=N\u0013_�:k7pQ��(m\u001dU\u001e�Q�\u0002\u00159W��\u000fb\u001f\u0018\\Ǽ�@��i\u0012�>\u0013�c`b\u0002�%��ӊ��>�s���z\f ��$��E�I����q\u001bJ�zS� �FrvG�\u0015\u001d^Gl�9�a=�bS��>Wn1�\u001a!K��v�X��ǜ\u001e�O/;�\u000b?�\u0014KYx�\u0015΅�~��Z�N�A���7&�?\u0017��9cT0}{\u0014\u0017mE\u001b�#Iݞ]g�]�2��s���ap#!!�\"�ժty��4U\u0007�y����c����H��b�F5a!t��$:�\u0010Sf�kG����W,)B@%�\u0019T\u0002����E�RD��L\u0019=d6���~k��t����.�o���A\u0012�i4eiO�p�\u001f�\u001c��ub��m�(��� �u�\u000f�QY�l���+Ƣ�8Q1;�P���\u0004�\u0002\u0017\u0006��7��%OP���Z�aC���+�\u001eW)�jC�#��5u)���r?kt�is�\u0004�\u0007#6����F���ERZ#\u0001g#��${\b;u\u0010bf�6����E��[�\u0005\u0003d�\u0014��=�ח�j�WU�d|t�Ğ�zW��=� ny q��\u0015_\u001a�sU\u0007�����l �iK\u0016�m��*\u0017/�'�\u000f*���מ�$���[~\u0003.'6�����5�\u001d��7eHs�.r��������\u001e\u0014������Z��ӧ�_�߃���Ca�@g�+7C�\u000e����7����Ft�y�\f\u0011 �Yq��5F���K�Yt���{�^�\u0011I\u0017��\u0018�\u0001>s�B��\u0012u�K�s�A_n��J�yh��o6n�\\ۘ��\b�������Np7,n:@�k��������cw��m�כڅ+\fSk͑p%�y\u00156[�ހĕL�4\u000f��cW_����9��1'\u0001�\u0002�\u0010uY�\u000b�=8W8ʝݏ��k���!�k�\u001d�m�w\u0010��\u0010��M�,\u0014\u001f�\"�\u0010��?a�$�U���cs3��5z�L�]\u0001H�� �W_�I����5��z� +2؅\b\u0017~0�מ\u000e���3\u001f�u�NNv(ַ�%��l������-T����Sy�w��.\u001cݾ#u,�{\u0010\u000b�]�\u0015`�G\b��ya \u001d[N�/N��+W �5�h�[=�,uE�;\u0007㈓cC3{eMD��18Y�/\u000f��\\%j���P�\u000b�W\"f�]�G\u0002\u001e�1�[6\u0015�*\u0015�\u001d4�B��܎t��_R�\\W{�H���V�8���~��K����#ߓ/X��[a\u0006�֏��i��#r\f &-C��.H f�Pj\u0018���(�\u001ay���'���g��|,�X�~n�1�=���y\u0001\u0001!z�O*�Z�~\u0012\u000b��-*̐\u000e�)�F���~`�\u000eD,\u000b���s\u0016��\u0019Z~��\u0006�\u000b\u000123��\u001c�y��\u0001~�,7F�@��n�g���h�h�Τ�]s9�K�\u0019�\u001dz�4zM���]%�kH&c���jL��J�D�>�օ[ϑ�KcsgE�ױ�]c����w�� �\u0013-(\u0013�\u0018\u0007P� ��B�y\u0016����?6�a�XE��ײ\u0012m�aD��\u001cI�$���Ѹ��&\f�\\��X\u0016�A���J =��=`���\u001d��\u0016n�H������]``�\u001c���7о\\��-߻�\u0012e�����\\��\u001f�NZ$B[9�z\b ,�my4�!|\u0016Bn�������g�����i�#(\u0003Z�\fd��\\mΉ��[���N���\u001eG��\u001ce��ԭ4ޗ����J9�ȋ�j���a:�P�$�jf�\u0010���\\�қ/\u001d`! �4��l����Sd��$p�\u001fZU�������J�\u00061iТ|�_��6؞7��UJr��& �6� ad�\u0018���*\u0007\u0014�]�\u0015��u�)^$߃cL� �-��\u001c\u0003�]�V\u0016.�B��de��\u000e\u001e���\u0018��ގ�o0\u001c����_��*q x�]�",
    "commentLink": "https://news.ycombinator.com/item?id=42623144",
    "commentBody": "Federal Reserve Bank of NY \"Doomsday Book\" 2022 via FOIA [pdf] (crisesnotes.com)183 points by Jimmc414 3 hours agohidepastfavorite131 comments cj 2 hours ago> The Doomsday Book is intended to help lawyers of the Federal Reserve Bank of New York aid their clients in crisis management. It was originally distributed to a limited set of lawyers and select senior staff members. This has changed with time, as more lawyers are drawn into crisis management. Now, all FRBNY lawyers receive a copy of the Doomsday Book. Since the Doomsday Book seemed more confusing than helpful to non-lawyers, it is no longer distributed outside of the Legal Function. However, some individuals may have older versions on their shelves, and there is nothing wrong with sharing this version with clients. Page 44 of the PDF has a good overview of what this document is intended to be. Putting \"Doomsday book\" in the context of crisis management explains why this document exists. Basically, they don't want to be in the middle of a crisis and have legal uncertainties delay their ability to take action. reply MichaelZuo 2 hours agoparentIt seems to be a misnomer as I can’t imagine any ‘doomsday’ scenario where there would still be a functioning judiciary, Justice department, or any functioning clients for the FRBNY to help. reply ArnoVW 2 hours agorootparentI think the fear is not that there is no justice to help them. The point is that when exceptional measures are needed, you want to know how far you can go, without it coming back to you in the months afterwards. It's a bit like InfoSec cyber incident playbooks: if customer data is being corrupted, can the production server be shut down? how bad does it need to be before the downtime no longer outweighs the corruption? who can take the decision? If you don't spell that out in advance, you may find yourself in a situation where you lose time unnecessarily. reply rtkwe 2 hours agorootparentprevMore Doomsday as \"potentially existential (in a financial system sense) crisis\" than a literal Doomsday. It fits perfectly into that frame as a compilation of other times the Fed has explored the limits of it's powers to address extreme situations in the financial system. It's also unlikely courts etc would completely disappear even far into an actual \"Doomsday\" crisis. Hell the IRS has plans in place on how to collect taxes post nuclear apocalypse. reply Retric 1 hour agorootparentThere’s levels of Doomsdays. As emotional as people get over surface level details of government, there’s a long way down from a civilization unable to make CPU’s before the literal stone age. So sure people hate the IRS, but codified tax collection is the single most important function of modern government. Without that you don’t have private property or free markets just warlords arbitrarily seizing property which destroys whatever is left of society very quickly. reply rtkwe 22 minutes agorootparentThat's kind of what I'm getting at with the first part of my post. Doomsday for the Fed is \"major collapse of sector(s) the US economy they fail to arrest\" or esoteric economic woe that requires drastic but relatively novel (legally speaking) measures to address. The kind of systemic seizing that some of the people who had the foresight and money to have made a killing on 2008 but didn't because they feared the wholesale collapse would happen because they didn't factor in the firehose of money that would be directed at the problem. Complete societal collapse is outside their purview because they depend on there to be an economy to manage which ceases to meaningfully exist at certain points on the Doomsday scale. reply AdamN 1 hour agorootparentprevDeath AND Taxes reply jowea 55 minutes agorootparentprevhttps://www.nytimes.com/1989/03/28/business/nuclear-war-plan... > It will take something more than a nuclear attack to wipe out taxpayers' obligations to the Internal Revenue Service. > An addition to the Internal Revenue Manual, which is supposed to guide the conduct of all I.R.S. employees, declares that if the bomb is dropped, ''operations will be concentrated on collecting the taxes which will produce the greater revenue yield.'' reply warner25 1 minute agorootparentOne thing that I think I've learned, to my surprise, even for most people in uniform on either side, is that much of life during wartime is still mostly \"business as usual.\" I think we all tend to have poorly calibrated mental models of this because coverage of war tends to focus on the heaviest action and worst of the devastation. I don't mean to downplay how awful that can be, or how far the effects can reverberate (even generations later), but like... the vast majority of people still go about their daily lives, doing their usual jobs, doing the mundane things, even having fun, supply chains and infrastructure and institutions seem to be quite resilient, etc. Locally, everything can change in an instant in combat, but nationally things can keep rolling along as war drags on much more slowly than we all might expect or hope. So I have little doubt that the IRS would keep doing its thing, and tax returns would need to be filed (albeit maybe with extended deadlines), even in the wake of a nuclear attack. I suppose the question is how much do things unravel in a scenario of nuclear counter-attack, and counter-counter-attack, etc. for which we have no historical precedent to think about. reply pjc50 1 hour agorootparentprevThink \"2008 crisis\" rather than actual apocalypse. reply mmanfrin 1 hour agorootparentprevhttps://en.wikipedia.org/wiki/Domesday_Book reply onionisafruit 2 hours agoprevFrom the name, I expected a list of the fed’s assets similar to the more famous Domesday Book. But this is more interesting. reply bix6 2 hours agoprevWild to me that they can choose which FOIA’s to answer. Anybody had one denied? reply bobmcnamara 2 hours agoparentThey're not \"the goobermint\", so not FOIAble. reply JumpCrisscross 1 hour agorootparentCongress literally exempted \"information that concerns the supervision of financial institutions\" from FOIA [1]. [1] https://www.foia.gov/faq.html reply bix6 1 hour agorootparentprevWhich is crazy as a quasi government agency supervised by a government agency. reply jfengel 1 hour agorootparentYeah, it's weird. More separation of powers stuff. The intent is to be insulated from politics but not entirely divorced from the will of the people. As Calvin said, a good compromise leaves everyone mad. reply desireco42 1 hour agoprevFascinating to see how the Fed prepares for potential systemic financial crises with this 'Doomsday Book'. The name cleverly references the medieval Domesday Book, adapting that record-keeping concept to modern financial emergency preparedness. It's essentially a sophisticated crisis management playbook, similar to tech companies' incident response plans but with much higher stakes. The legal and operational complexity revealed here is truly mind-blowing reply CrimsonCape 2 hours agoprev\"Please note that the Federal Reserve Bank of New York (the “New York Fed”) is not subject to the Freedom of Information Act (“FOIA”) although it complies with the spirit of FOIA when responding to requests of this type.\" Isn't it great we have a massive private entity in control of the financial system that pleasantly reminds you that it is not accountable to government laws, and by extension is not accountable to the people (\"A government of the people\") reply ano-ther 2 hours agoparentIt's accountable to Congress: https://www.federalreserve.gov/faqs/about_14986.htm > The Federal Reserve System is not \"owned\" by anyone. The Federal Reserve was created in 1913 by the Federal Reserve Act to serve as the nation's central bank. The Board of Governors in Washington, D.C., is an agency of the federal government and reports to and is directly accountable to the Congress. > Some observers mistakenly consider the Federal Reserve to be a private entity because the Reserve Banks are organized similarly to private corporations. For instance, each of the 12 Reserve Banks operates within its own particular geographic area, or District, of the United States, and each is separately incorporated and has its own board of directors. Commercial banks that are members of the Federal Reserve System hold stock in their District's Reserve Bank. However, owning Reserve Bank stock is quite different from owning stock in a private company. The Reserve Banks are not operated for profit, and ownership of a certain amount of stock is, by law, a condition of membership in the System. In fact, the Reserve Banks are required by law to transfer net earnings to the U.S. Treasury, after providing for all necessary expenses of the Reserve Banks, legally required dividend payments, and maintaining a limited balance in a surplus fund. reply yesco 1 hour agorootparent>In fact, the Reserve Banks are required by law to transfer net earnings to the U.S. Treasury, after providing for all necessary expenses of the Reserve Banks, legally required dividend payments, and maintaining a limited balance in a surplus fund. Going purely off memory here, I recall audits implying this may not actually be happening as legally required. It was back when Ron Paul was making a big deal about it though, I can't remember the specifics so I'm bringing it up to invite discussion. reply beambot 1 hour agorootparentIf it's paying dividends, then it has de facto owners. Also, are there explicit constraints on \"limited\" balances -- eg fraction of money supply or fraction of GDP? reply yieldcrv 29 minutes agorootparentjust because a contract pays dividends doesn't make the bearers the owners and this entire discussion about \"government vs private\" just completely neglects the widely used concept of orphaned entities, as if they don't exist false dilemma reply JumpCrisscross 1 hour agorootparentprev> If it's paying dividends, then it has de facto owners No, it means the FRBs have legal shareholders. (The Fed per se doesn't pay dividends.) The Treasury pays interest, that doesn't mean it's owned by bondholders. We could easily re-write statute so the Fed doesn't pay dividends (it would become interest on reserves), they're an anachronism from the days when the Fed had to compete to induce membership. But that wouldn't do anything practical and it also wouldn't satisfy the conspiracy theorists, so it's not really in anyone's interest to bother with. > are there explicit constraints on \"limited\" balances No, though it's maintained at an amount equal to banks' paid-in capital [1]. Broadly speaking, it's another anachronism. [1] https://www.gao.gov/assets/gao-02-939.pdf reply JumpCrisscross 1 hour agorootparentprev> I recall audits implying this may not actually be happening as legally required There is zero evidence the Fed hasn't been paying the Treasury properly and a lot of audit evidence it has been. reply amyames 31 minutes agorootparentFed hasn’t paid Treasury a dime since August 2022: https://fred.stlouisfed.org/series/RESPPLLOPNWW reply immibis 1 hour agorootparentprevCongress doesn't seem to be very accountable to the people, so the chain seems to stop there. reply FuriouslyAdrift 8 minutes agorootparent11 incumbents lost their seats in 2024... that's accountability. reply JumpCrisscross 2 hours agoparentprevThe Fed is subject to FOIA [1]. (Within limits [2].) FRB New York is not. If you want to know about monetary policy, that’s FOIA’able. If you want to FOIA the FRB’s trades so you can front run them, that’s not allowed. (Similarly, you can FOIA the Department of Education. You can’t FOIA Sally Mae.) [1] https://www.federalreserve.gov/foia/about_foia.htm [2] https://www.federalreserve.gov/foia/exemptions.htm reply koolba 59 minutes agorootparent> If you want to FOIA the FRB’s trades so you can front run them, that’s not allowed. As if anything that operates at the speed of FOIA would be useful for front running. Maybe if it was for some future action, but even that would be months out of date when you finally get a response. reply JumpCrisscross 55 minutes agorootparent> As if anything that operates at the speed of FOIA would be useful for front running What are you basing this on? There was a scandal several years ago when the order of transactions protocol leaked. If you now that X transaction systematically happens after Y, and you see X, you know Y is coming. reply dustyventure 1 hour agorootparentprevAll agencies have process for handling FOIA requests for issues that are often of a more serious nature than some data possibly arriving fresh enough for front running.. reply JumpCrisscross 1 hour agorootparentCongress literally exempted \"information that concerns the supervision of financial institutions\" from FOIA [1]. [1] https://www.foia.gov/faq.html reply tanaros 2 hours agoparentprev> Isn't it great we have a massive private entity in control of the financial system that pleasantly reminds you that it is not accountable to government laws, and by extension is not accountable to the people (\"A government of the people\") While I appreciate your desire for more accountability in our financial system, I feel this framing can be interpreted as needlessly alarmist. Although the NY Fed is not subject to FOIA —- because, as written, it excludes them —- they are of course subject to US law in general. Congress (and, by extension, the people) may pass laws to regulate them as they wish. reply ActionHank 2 hours agorootparentAre they privately held or part of the state apparatus though? reply JumpCrisscross 2 hours agorootparent> Are they privately held or part of the state apparatus though? The Fed is part of the state. Unambiguously. FRB New York is its interface with the private sector, analogous to Fannie Mae or the Tennessee Valley Authority. reply throwaway5752 1 hour agorootparentprevWhen I search Google with your question \"NY Fed privately held or part of the state apparatus\", the first answer is from the NY Fed explaining this: https://www.newyorkfed.org/aboutthefed/more-about-what-we-do The third result is from the St Louis Fed, a non-technical explanation of this https://www.stlouisfed.org/in-plain-english/who-owns-the-fed.... reply IncreasePosts 2 hours agorootparentprevYes. reply immibis 1 hour agorootparentprevCongress can pass laws to regulate Elon Musk, too, but it doesn't stop anyone from being alarmed about fake news. reply sambaumann 2 hours agoparentprevthat same independence is the reason it's not subject to the political whims of whoever is in power at a given time, which is important for the long term health of the economy. \"The people\" did decide this - as congress gave the fed that independence reply npoc 2 hours agorootparentSounds good until you discover that its the people who own the fed that are really in power. Everyone should read at least the first few chapters of \"The Creature from Jekyll Island\" to understand how much money (power) they have. reply JumpCrisscross 2 hours agorootparent> until you discover that its the people who own the fed that are really in power This is nonsense. The President and Congress control the Fed. And nobody can knowledgeably claim, today, that its banking members (legally, its shareholders) are more powerful than America’s non-bank financial institutions (e.g. Blackrock or Brookfield). The greatest boon our billionaire class could inherit is a politically-controlled Fed. It’s why one of any autocrat’s first moves is bringing the central bank under their control. reply npoc 2 hours agorootparentIt's not nonsense. The banking system printed every dollar out of thin air and is charging interest on every single one (giving a cut to government). For decades and decades. I made a post earlier detailing the mechanism they use to extract the wealth from us: https://news.ycombinator.com/item?id=42621878 reply icehawk 4 minutes agorootparent> The banking system printed every dollar out of thin air[...] What banking system doesn't do this? Ones with steps in between don't count. gnatman 34 minutes agorootparentprev>> The banking system printed every dollar out of thin air what is the alternative exactly? money created by god? like no duh the economy & money system was created out of thin air. we created all this shit out of thin air. reply JumpCrisscross 2 hours agorootparentprev> banking system printed every dollar out of thin air and is charging interest on every single one (giving a cut to government) This is also nonsense, though less so. Money is created by private banks through lending. The government gets a cut, but that comes through taxation. Money creation is complicated, but it seems like every year someone watches a YouTube video about inflation and deduces, with zero further thought, that it must be a conspiracy. reply npoc 2 hours agorootparent> Money is created by private banks through lending. Exactly. Every single dollar was created from thin air, as a \"loan\". > it seems like every year someone watches a YouTube video about inflation and deduces, with zero further thought, that it must be a conspiracy. I've been studying and researching this for years. reply JumpCrisscross 2 hours agorootparent> Every single dollar was created from thin air, as a \"loan\" Not quite. Minted currency isn’t created from a loan. Neither is fiscal spending. On the other side of the spectrum, money is destroyed through taxation (by the state) and repayment of debts and defaults (privately). The monetary hypothesis of income inequality is overly simplistic. It supposes our tax, trade and funding policies are all dictated by monetary policy, which is obviously nonsense. (That or our tax, trade and social spending policies have no effect on inequality. Which is obviously stupid.) It is an easily-digested hypothesis. We like those, particularly when the alternative is reading lots of arcane monetary financial texts. reply licnep 1 hour agorootparentFiscal spending is still created as a loan though since the government has to sell bonds to finance it, no? reply JumpCrisscross 1 hour agorootparent> Fiscal spending is still created as a loan though since the government has to sell bonds to finance it, no Monetarily speaking, the government creates the money when it spends it. The loan then (and optionally) removes a similar amount of money from the system. This is an enormous power, so we try to legally limit the government in how it can do this. (If we removed the Fed's independence and put it under the Treasury, the Treasury could just add numbers to the bank accounts of the government's employees and vendors. This is analogous to its minting power. We separate the Treasury and the Fed in part to fracture this power.) I forgot one more creation/destruction mechanism above: the Fed's open-market operations. When the Fed buys assets, it creates money. When it sells them, it destroys money. reply licnep 43 minutes agorootparentThanks for the clarification, if you have any pointers to learn more about this I'd be interested to check it out. reply aaomidi 2 hours agorootparentprevThe independence could still have stipulations that require FOIA. reply phyzix5761 2 hours agorootparentprevI'm curious which country you reside in where congress does the will of the people because I'm in the US and that's definitely not true here. EDIT: Getting a lot of hate on this comment so allow me to clarify what I meant. In the US we have a Constitutional Republic meaning elected representatives write the laws. People are not voting directly on laws and issues (on a federal level). The parent comment said that \"The People decided this\" but that's not an accurate statement. Congress decided this regardless of what people actually wanted. In fact, the public was largely divided on whether they wanted a Federal reserve during this time. reply 9question1 2 hours agorootparentYou greatly overestimate the quality of the will of the people. Just because you don't like certain outcomes because they are stupid doesn't mean that those outcomes aren't what people wanted. Democratic institutions are a much more accurate way of reflecting the will of the people than most other attempts to measure that, for many reasons including the existence of people who don't respond to surveys but vote. reply greenavocado 2 hours agorootparentDemocratic institutions can be subverted with first past the post voting systems and the illusion of choice amongst the most vocal and well funded parties reply _DeadFred_ 1 hour agorootparentIt's also a recipe for a tyranny of the majority and a horrible form of government. reply CamperBob2 2 hours agorootparentprevYou know what the technical term for a subverted democracy is? \"Democracy.\" Also known as, \"Five people with an IQ of 90 outvoting four people with an IQ of 110,\" or \"One person in Iowa canceling two votes in California.\" reply llamaimperative 1 hour agorootparentEh, the (growing) insanity of the electoral college is not a necessary feature of a democracy. reply CamperBob2 23 minutes agorootparentIt is as far as this one's concerned. reply llamaimperative 5 minutes agorootparentNo, not necessary, just (currently) Constitutionally mandated. Those are not the same thing. phyzix5761 1 hour agorootparentprev> Democratic institutions are a much more accurate way of reflecting the will of the people You're right but that's not what we have in the US. We have a Constitutional Republic. Elected representatives write the laws. People are not voting directly on laws and issues (on a federal level). I'm not saying we should change it but for the parent comment to say that \"The People decided this\" is not an accurate statement. That's all I meant with my comment. reply nico 2 hours agorootparentprevThis is just false > Study: Congress literally doesn’t care what you think > Their study took data from nearly 2000 public opinion surveys and compared it to the policies that ended up becoming law. In other words, they compared what the public wanted to what the government actually did. What they found was extremely unsettling: The opinions of 90% of Americans have essentially no impact at all. https://act.represent.us/sign/problempoll-fba There are several articles about the study reply llamaimperative 1 hour agorootparentAnother interpretation: when you sum a bunch of opinions you end up with a result that doesn’t look particularly like any of the inputs, and certainly not a large portion of them. reply toolz 1 hour agorootparentprevI think you're over-representing just how well opinion surveys can represent the actual will of the people. To put this in a less politicized analogy, everyone will tell you they want to be rich, but how many people are willing to make sacrifices to become rich? It turns out many rich people today are rich because they didn't have to make very many sacrifices, while most everyone, including minimum wage employees, can become a millionaire. Mathematically it's not all that complex. People will tell you what they want with some internalized model that isn't representative of the realistic trade-offs that would have to be made. So in effect what people say isn't based in the reality of what they actually want. reply s1artibartfast 42 minutes agorootparentprevDo you realize this study uses completely subjective post-hoc assessment of what industry lobby's wanted? reply arrosenberg 2 hours agorootparentprevThis is the wrong take. The system reflects the will of the people who the system deems important. The average person wants higher wages, shorter hours and cheaper cost of living w/r/t rent, food, fuel and health. Congress is reflecting none of those desires right now because they serves the needs of the oligarchic selectorate that has been funding unrestricted class warfare against regular people for the last 20 years. reply JumpCrisscross 2 hours agorootparent> average person wants higher wages, shorter hours and cheaper cost of living w/r/t rent, food, fuel and health. Congress is reflecting none of those desires The average voter does not uniformly express these preferences. reply arrosenberg 2 hours agorootparentDuh? Like, by definition, an average doesn't reflect uniform expression. The people who don't want those things are a minority, but they are getting their way, because the system reflects the desires of the elites, not the desires of the average. reply JumpCrisscross 2 hours agorootparent> people who don't want that are a minority, but they are getting their way They’re the majority. Almost every voter puts pocketbook issues near the top of their list, but not so far up that they’re willing to be civically active about it unless it’s a crisis. Herego, we spend most of our non-crisis time on non-pocketbook issues. reply arrosenberg 2 hours agorootparentNo, they aren't the majority. The elites that the system actually serves have successfully ignited a culture war that splits the average people on which issues are driving the economic problems. The overwhelming majority of Americans want higher wages and cheaper cost of living, they just can't agree on how to get there (by design). Divide et impera. reply JumpCrisscross 1 hour agorootparent> overwhelming majority of Americans want higher wages and cheaper cost of living, they just can't agree on how to get there (by design) By design? Or because it's hard? You really think the sole thing keeping us from having more for less is conspiracy? reply CamperBob2 2 hours agorootparentprevAlmost every voter puts pocketbook issues near the top of their list, but not so far up that they’re willing to be civically active about it unless it’s a crisis. We're not in a crisis now, but people voted in the last national election as if we were, because Fox News told them that we were. reply JumpCrisscross 2 hours agorootparent> because Fox News told them that we were This is my problem with the “elites in control” hypothesis. It seems to rely on voters’ power existing, but being circumvented because said voters are too stupid to handle it. reply ImPostingOnHN 1 hour agorootparent> This is my problem with the “elites in control” hypothesis. It seems to rely on voters’ power existing, but being circumvented because said voters are too stupid to handle it. You are correct (except that it need only be a subset of voters). Now that you've done a good job of elaborating on the hypothesis, what exactly is your problem with it? reply JumpCrisscross 1 hour agorootparent> what exactly is your problem with it? It doesn't work. Its testable predictions preclude a good amount of extant politics, including practically all populism. Elites the world over are losing in democracies because they presupposed, from afar, that they knew what their constituents wanted. Voters' interests are complex, and they can't be so easily bought. reply llamaimperative 1 hour agorootparentThat is a huuugely presumptive interpretation. Here’s another possible interpretation: our information environment makes people extremely vulnerable to actual bullshit in massive volume. reply JumpCrisscross 1 hour agorootparent> Here’s another possible interpretation: our information environment makes people extremely vulnerable to actual bullshit in massive volume That is also true. People get angry and then misdirect it. But the anger is real, and it filters up through the political system when the valves aren't clogged. They aren't, not anywhere in the West. Voters across the West have essentially begun a wholesale replacement of their stable of elites. That is not what happens in an oligarchic system. reply ImPostingOnHN 59 minutes agorootparent> That is not what happens in an oligarchic system. The person USAns just voted in is literally an oligarch, as is his co-president, and he has indicated that he will populate his cabinet and advisory board with still more oligarchs. His \"inauguration\" slush fund has already received hundreds of millions of dollars from other oligarchs to secure their place in the new oligarchy* *: Pure or otherwise reply JumpCrisscross 55 minutes agorootparent> person USAns just voted in is literally an oligarch, as is his co-president, and he has indicated that he will populate his cabinet with still more oligarchs America is tending towards an oligarchic system. (This is a history of weak democracies, historically, and a reason we were founded as a republic and not pure democracy.) That doesn't prove it currently is one. Trump's election is largely about replacing the technocratic and cultural elite with a commercial one. llamaimperative 1 hour agorootparentprevThat is absolutely how oligarchic systems supplant democracies. Hitler was elected, Orban was elected, Bukele was elected. reply immibis 57 minutes agorootparentAnd Putin and the first supreme leader of North Korea. Democracies can turn into dictatorships quickly. But don't worry - it can't happen here. JumpCrisscross 1 hour agorootparentprev> Hitler was elected, Orban was elected, Bukele was elected None of them emerged from oligarchic political systems. llamaimperative 26 minutes agorootparentIf your argument is \"the US was not a pure oligarchy 4, 8, or 12 years ago\", sure. I don't think that's what people are pointing out. ImPostingOnHN 1 hour agorootparentprev> Its testable predictions preclude a good amount of extant politics, including practically all populism. How so? > Elites the world over are losing in democracies because they presupposed, from afar, that they knew what their constituents wanted Elites the world over are winning in democracies (take the US for example), which could feed into the hypothesis. Indeed, nonzero voters of these elites were easily bought. reply CamperBob2 1 hour agorootparentprevElites the world over are losing in democracies because they presupposed, from afar, that they knew what their constituents wanted. ... or perhaps because you've misidentified the \"elites.\" Voters' interests are complex, and they can't be so easily bought. No need to buy cattle you already own. You just herd them. reply JumpCrisscross 52 minutes agorootparent> perhaps because you've misidentified the \"elites.\" If the elites are constantly changing then the 'elites' being in power is about as threatening as the 'people' holding it. reply CamperBob2 1 hour agorootparentprevWell, that's pretty much the size of it, isn't it? reply ImPostingOnHN 2 hours agorootparentprevI'd say the average voter actively wants at least 1 of these and has no problem with the others. reply derektank 2 hours agorootparentprevIf members of Congress are not acting in the interests of their constituents, their constituents have the power to vote them out. The decision not to is what's known as \"the consent of the governed\". Perhaps that's not exactly the same as \"the will of the people\" but it's close enough for casual usage. reply nico 2 hours agorootparentVote them out and elect who? Some other member from one of the two parties, who will continue to make decisions mostly for their rich donors? > Princeton University study: Public opinion has “near-zero” impact on U.S. law. > One thing that does have an influence? Money. While the opinions of the bottom 90% of income earners in America have a “statistically non-significant impact,” economic elites, business interests, and people who can afford lobbyists still carry major influence. https://act.represent.us/sign/problempoll-fba reply JumpCrisscross 2 hours agorootparent> Public opinion has “near-zero” impact on U.S. law Re-run that within voting jurisdictions. What that study largely seems to reference is that local representation is, in part, a divide and conquer mechanism. reply clucas 2 hours agorootparentprevWhat's your best example of something the US Congress has done, or failed to do, that was contrary to the will of the people? reply phyzix5761 1 hour agorootparentHere are a few examples of times congress passed laws/acts which went against the will of the people: The Fugitive Slave Act (1850) The Alien and Sedition Acts (1798) The Prohibition Act (1919) The Vietnam War Draft (1960s) The Troubled Asset Relief Program (2008) reply clucas 44 minutes agorootparentOK, the only modern example on your list is TARP. I think the strength of your examples does not justify the strength of your statement. Actually, I just read your update, you've changed from making a bold (and, in my view, wrong) statement about how government is not responsive to the will of the people, to a fairly boring technical point about how a representative democracy works. I have no idea if you're just doing a motte and bailey or if you were never trying to make a bold claim in the first place... I'll just leave my piece here, in any case: I believe that the US system of government actually works really well, and in general we tend to get laws and regulations that are based on the broad consensus of a very diverse electorate. This is a good thing. In my opinion, when most people complain about how the government doesn't work for the people, what they actually don't like is that a lot of the country disagrees with them, and that disagreement is reflected in our government. But, maybe I'm wrong and there's some other system we can come up with that will keep a vast and diverse nation hanging together prosperously for another 250 years. Shrug. reply hindsightbias 1 minute agorootparentprevDifficult to say what the will of the people was on TARP as it changed week to week depending on what the stock market had done that day. But three days later they were for it before they were against it: https://www.astrid-online.it/static/upload/protected/GALL/GA... On the draft, that wasn't a new law. Selective Service was probably a 1940s law. A majority didn't think the war was a bad idea until 1968 and a majority supported Nixon pretty much to the end regardless of the reimagining that hippies were ever a majority. https://time.com/archive/6875220/a-time-louis-harris-poll-th... immibis 56 minutes agorootparentprevThe Gaza genocide? reply clucas 24 minutes agorootparentWhat policy proposal related to the Israel-Palestine conflict do you think would actually be agreed to by more than 50% of the US electorate? reply emh68 8 minutes agoparentprevMuch like Facebook and Twitter spy on American citizens for the Federal government. reply andrewmutz 52 minutes agoparentprevThe fed of course is accountable to laws passed by the government but not laws about the government (since it is not a part of the government). It is a wonderful thing that it is independent from the government, and history has shown, across nations, that political independence of central banks is necessary to control the money supply well. Political leaders are more interested in short-term issues and have repeatedly demonstrated an inability to responsibly manage money supply issues. reply rcxdude 2 hours agoparentprevIt's not accountable to government laws which target the government. Congress could pass a law to make such entities (or indeed, all corporations or people) subject to the act, but they've decided not to. reply _DeadFred_ 1 hour agoparentprevThe Judicial branch of the American government is exempt from FOIA. Isn't it great we have a hold 1/3 of our government that thinks they are exempt from us plebes oversight? They don't even hold themselves to the 'although it complies with the spirit of FOIA'. That seems way more concerning than the FED. reply qingcharles 19 minutes agorootparentThis isn't the whole story (from a serial FOIA person myself). The judicial branch is generally excluded from FOIA laws (it shouldn't be), but it is subject to disclosure under the First Amendment and the common law. While that doesn't provide any statutory wins (e.g. must disclose in X days etc), it does allow you to sue if say a court doesn't provide you with records you want. see e.g. Nixon v. Warner Communications, Inc. (1978): recognizing the common law right of access to judicial records but allowed the court to deny access when interests such as privacy, national security, or fair trial rights outweigh the public's interest. reply throwaway5752 1 hour agoparentprevYes, it is great. The US economy has been the strongest in the world for a century and the USD is a global currency. The system has been incredibly successful, in spite of being periodically run by idiots. reply FrustratedMonky 3 hours agoprevThis seems like some pedestrian financial agreements. What is the TLDR on why it is called 'Doomsday'? reply toomuchtodo 2 hours agoparent> The so-called Doomsday Book, an internal document used to guide the Federal Reserve’s actions during emergencies, has long been the subject of intrigue and suspicion. Largely a compilation of legal opinions, the book has been a key resource for the Federal Reserve Bank of New York for decades, allowing it to play a unique and oversize role during financial crises. No other regional Federal Reserve bank has such a resource. > The book is a living document that records pivotal decisions made during times of financial distress. It played a crucial role in then New York Fed President Timothy Geithner’s decision to rescue Bear Stearns from bankruptcy in 2008. Economic system failure runbook. https://www.wsj.com/articles/sun-shines-on-new-york-fed-doom...https://archive.today/YbgG7 https://www.crisesnotes.com/the-new-york-federal-reserves-do... reply tekla 2 hours agoparentprevIts explained on the first page italicized The “Doomsday Book” is a compendium of legal opinions, in some cases stretching back decades, that explore the legal limits of the Federal Reserve in the event of a financial crisis. reply FrustratedMonky 2 hours agorootparentEvery company has a disaster recovery plan. Seems like calling it 'Doomsday', is the question. It seems rather dramatic naming for a bank. reply tekla 2 hours agorootparentI think the imminent collapse of the US economy is aptly named \"Doomsday\" to the Federal Reserve. I mean, you bring up a disaster recovery plan for companies, but is it REALLY a \"disaster\"? reply epa 1 hour agoprevPage 2, comic sans reply ngriffiths 50 minutes agoparentThis was my first reaction. Why? Trying to downplay the seriousness of the topic or something? Is it ever used in documents like this? reply 0xEF 1 hour agoparentprevSomeone should be held accountable for this. Nevermind the redacted stuff. I want to know who to blame. reply grantsucceeded 36 minutes agorootparentBlame for using comic sans ? :) reply wil421 41 minutes agorootparentprevBlame the interns! reply jprd 3 hours agoprevI initially thought this was trolling due to the MS Comic Sans right up front. reply Mistletoe 3 hours agoprevIs that Comic Sans on the second page? reply JumpCrisscross 2 hours agoparentI guess if you’re at the precipice of a financial crisis, starting with laughs around the table isn’t the worst. reply marcusestes 3 hours agoparentprevCame here to say the same thing. It’s a chilling font choice for a document like this. reply morsch 3 hours agorootparentIt also reads hilariously like a document from the SCP wiki, blacked out passages and all. reply baryphonic 2 hours agorootparentprev2006 was peak \"Great Moderation,\" where there hadn't been any serious financial crises since the 80s. The consensus wisdom was that many of the policies of the 80s & 90s, particularly around inflation and reducing uncertainty, had made financial crises almost obsolete. It seems dark today given that we know the outcome, but I'm sure at the time, Comic Sans seemed appropriate for a set of tools that they thought likely would never be used. Or maybe it indicates a certain hubris undone within about 18 months. reply banku_brougham 2 hours agorootparentStares in Long Term Capital Management reply grantsucceeded 11 minutes agorootparentprobably anyone this far in the thread remenbers long term capital managment, I did, but couldnt remenber if it was in the 80's or 90's. (1998) https://www.investopedia.com/terms/l/longtermcapital.asp reply arminiusreturns 2 hours agoprevnext [5 more] [flagged] JumpCrisscross 1 hour agoparentDid you get anything useful out of that summary that wasn’t on the first page? reply arminiusreturns 1 hour agorootparentI did actually. I glanced through the first 10 and last 10 or so pages before I even thought of asking NotebookLM for a summary. I thought it might be appreciated by someone who wanted a slightly better summary. reply pvg 32 minutes agorootparentThat's great but please don't post LLM summary output into HN threads https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... reply arminiusreturns 28 minutes agorootparentOh shit I missed that, haven't been very active lately, will edit out. Thanks. reply th4t1sW13rd 2 hours agoprev [–] The fact that one of the most powerful financial institutions in the world maintains a \"Doomsday Book\" of emergency legal procedures, named after the historic record of English lands commissioned by William the Conqueror, suggests they take very seriously the possibility of catastrophic financial crises requiring extraordinary measures. The document states explicitly that \"The Doomsday Book is not, and can never be a finished product\" - implying an ongoing need to prepare for new types of financial emergencies. This seems both novel and somewhat concerning, as it indicates the Federal Reserve anticipates and prepares for worst-case scenarios that could severely disrupt the financial system. The very existence and continuous updating of such a manual provides a window into how the Fed thinks about and prepares for potential crises. reply pjc50 1 hour agoparent> it indicates the Federal Reserve anticipates and prepares for worst-case scenarios that could severely disrupt the financial system Yes! That's the point! You don't want to arrive at a worst-case scenario unprepared! The US military has all sorts of files and plans on bizarre and implausible scenarios, mostly as intellectual exercises (\"if we wanted to invade Canada, how would we do it?\"). That doesn't imply anything about their likelihood. reply JumpCrisscross 2 hours agoparentprev> somewhat concerning, as it indicates the Federal Reserve anticipates and prepares for worst-case scenarios that could severely disrupt the financial system It’s concerning a regulator and lender of last resort considers what happens at the precipice of last resorts? reply s1artibartfast 1 hour agoparentprevI think some concern is warranted, given financial crisis are real threats the the system and consumer. The consumer can do little to prevent such a crisis, but awareness and modest preparation are a rational response. I think it is pretty analogous to fema preparations for catastrophies. A homeowner can't stop a pandemics or hurricane. They can have an emergency kit. reply Etheryte 1 hour agoparentprevMarkets are both cyclical and ever-changing, so I don't see what's surprising about new types of emergencies coming up as the times change. The way we slice and dice assets and claims today is very different from how it used to be done just a few decades ago. The markets are a living breathing thing. reply ndileas 2 hours agoparentprev [–] Would you prefer that they would not prepare for unusual circumstances? This is what any serious organization does when there are real stakes. Smart people sit down and gather information, think about likely scenarios, and write a playbook, updated over time. Seems like your response is a knee jerk entirely based on the optics of the name. The fed responding wrongly to a crisis, even a minor one, could cause enormous pain and suffering -- think famine. I don't have the expertise or patience to actually evaluate the contents of the document, but they are definitely doing the right kind of thing here. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The Federal Reserve Bank of New York's \"Doomsday Book\" is a legal guide designed to assist lawyers in managing legal uncertainties during financial crises, ensuring prompt and effective responses. - Initially intended for select lawyers, the guide is now available to all FRBNY lawyers, serving as a crisis playbook akin to tech incident response plans. - The document is not shared outside the Legal Function, and its name signifies preparation for severe financial disruptions, with the Fed maintaining independence from the Freedom of Information Act (FOIA) due to its unique role, while still being accountable to Congress."
    ],
    "points": 183,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1736262587
  },
  {
    "id": 42621627,
    "title": "Ending our third party fact-checking program and moving to Community Notes model",
    "originLink": "https://about.fb.com/news/2025/01/meta-more-speech-fewer-mistakes/",
    "originBody": "Meta’s platforms are built to be places where people can express themselves freely. That can be messy. On platforms where billions of people can have a voice, all the good, bad and ugly is on display. But that’s free expression. In his 2019 speech at Georgetown University, Mark Zuckerberg argued that free expression has been the driving force behind progress in American society and around the world and that inhibiting speech, however well-intentioned the reasons for doing so, often reinforces existing institutions and power structures instead of empowering people. He said: “Some people believe giving more people a voice is driving division rather than bringing us together. More people across the spectrum believe that achieving the political outcomes they think matter is more important than every person having a voice. I think that’s dangerous.” In recent years we’ve developed increasingly complex systems to manage content across our platforms, partly in response to societal and political pressure to moderate content. This approach has gone too far. As well-intentioned as many of these efforts have been, they have expanded over time to the point where we are making too many mistakes, frustrating our users and too often getting in the way of the free expression we set out to enable. Too much harmless content gets censored, too many people find themselves wrongly locked up in “Facebook jail,” and we are often too slow to respond when they do. We want to fix that and return to that fundamental commitment to free expression. Today, we’re making some changes to stay true to that ideal. Ending Third Party Fact Checking Program, Moving to Community Notes When we launched our independent fact checking program in 2016, we were very clear that we didn’t want to be the arbiters of truth. We made what we thought was the best and most reasonable choice at the time, which was to hand that responsibility over to independent fact checking organizations. The intention of the program was to have these independent experts give people more information about the things they see online, particularly viral hoaxes, so they were able to judge for themselves what they saw and read. That’s not the way things played out, especially in the United States. Experts, like everyone else, have their own biases and perspectives. This showed up in the choices some made about what to fact check and how. Over time we ended up with too much content being fact checked that people would understand to be legitimate political speech and debate. Our system then attached real consequences in the form of intrusive labels and reduced distribution. A program intended to inform too often became a tool to censor. We are now changing this approach. We will end the current third party fact checking program in the United States and instead begin moving to a Community Notes program. We’ve seen this approach work on X – where they empower their community to decide when posts are potentially misleading and need more context, and people across a diverse range of perspectives decide what sort of context is helpful for other users to see. We think this could be a better way of achieving our original intention of providing people with information about what they’re seeing – and one that’s less prone to bias. Once the program is up and running, Meta won’t write Community Notes or decide which ones show up. They are written and rated by contributing users. Just like they do on X, Community Notes will require agreement between people with a range of perspectives to help prevent biased ratings. We intend to be transparent about how different viewpoints inform the Notes displayed in our apps, and are working on the right way to share this information. People can sign up today (Facebook, Instagram, Threads) for the opportunity to be among the first contributors to this program as it becomes available. We plan to phase in Community Notes in the US first over the next couple of months, and will continue to improve it over the course of the year. As we make the transition, we will get rid of our fact-checking control, stop demoting fact checked content and, instead of overlaying full screen interstitial warnings you have to click through before you can even see the post, we will use a much less obtrusive label indicating that there is additional information for those who want to see it. Allowing More Speech Over time, we have developed complex systems to manage content on our platforms, which are increasingly complicated for us to enforce. As a result, we have been over-enforcing our rules, limiting legitimate political debate and censoring too much trivial content and subjecting too many people to frustrating enforcement actions. For example, in December 2024, we removed millions of pieces of content every day. While these actions account for less than 1% of content produced every day, we think one to two out of every 10 of these actions may have been mistakes (i.e., the content may not have actually violated our policies). This does not account for actions we take to tackle large-scale adversarial spam attacks. We plan to expand our transparency reporting to share numbers on our mistakes on a regular basis so that people can track our progress. As part of that we’ll also include more details on the mistakes we make when enforcing our spam policies. We want to undo the mission creep that has made our rules too restrictive and too prone to over-enforcement. We’re getting rid of a number of restrictions on topics like immigration, gender identity and gender that are the subject of frequent political discourse and debate. It’s not right that things can be said on TV or the floor of Congress, but not on our platforms. These policy changes may take a few weeks to be fully implemented. We’re also going to change how we enforce our policies to reduce the kind of mistakes that account for the vast majority of the censorship on our platforms. Up until now, we have been using automated systems to scan for all policy violations, but this has resulted in too many mistakes and too much content being censored that shouldn’t have been. So, we’re going to continue to focus these systems on tackling illegal and high-severity violations, like terrorism, child sexual exploitation, drugs, fraud and scams. For less severe policy violations, we’re going to rely on someone reporting an issue before we take any action. We also demote too much content that our systems predict might violate our standards. We are in the process of getting rid of most of these demotions and requiring greater confidence that the content violates for the rest. And we’re going to tune our systems to require a much higher degree of confidence before a piece of content is taken down. As part of these changes, we will be moving the trust and safety teams that write our content policies and review content out of California to Texas and other US locations. People are often given the chance to appeal our enforcement decisions and ask us to take another look, but the process can be frustratingly slow and doesn’t always get to the right outcome. We’ve added extra staff to this work and in more cases, we are also now requiring multiple reviewers to reach a determination in order to take something down. We are working on ways to make recovering accounts more straightforward and testing facial recognition technology, and we’ve started using AI large language models (LLMs) to provide a second opinion on some content before we take enforcement actions. A Personalized Approach to Political Content Since 2021, we’ve made changes to reduce the amount of civic content people see – posts about elections, politics or social issues – based on the feedback our users gave us that they wanted to see less of this content. But this was a pretty blunt approach. We are going to start phasing this back into Facebook, Instagram and Threads with a more personalized approach so that people who want to see more political content in their feeds can. We’re continually testing how we deliver personalized experiences and have recently conducted testing around civic content. As a result, we’re going to start treating civic content from people and Pages you follow on Facebook more like any other content in your feed, and we will start ranking and showing you that content based on explicit signals (for example, liking a piece of content) and implicit signals (like viewing posts) that help us predict what’s meaningful to people. We are also going to recommend more political content based on these personalized signals and are expanding the options people have to control how much of this content they see. These changes are an attempt to return to the commitment to free expression that Mark Zuckerberg set out in his Georgetown speech. That means being vigilant about the impact our policies and systems are having on people’s ability to make their voices heard, and having the humility to change our approach when we know we’re getting things wrong. Categories : Meta Public Policy Tags: Product News",
    "commentLink": "https://news.ycombinator.com/item?id=42621627",
    "commentBody": "Ending our third party fact-checking program and moving to Community Notes model (fb.com)180 points by impish9208 6 hours agohidepastfavorite251 comments JohnMakin 41 minutes agoI'm certain it will make parts of the user experience worse, but at least for the Threads app, this seems at least a little necessary - if you're aiming to be the \"new\" twitter or whatever social need twitter was fulfilling, you need to break free of the shackles of IG/Meta moderation, which is very unforgiving and brutal in very subtle ways that aren't always easy to figure out. But basically, I find a platform like Threads/Twitter are probably unusable for a lot of people unless you can say \"hey, you're an asshole\" every now and then without Meta slapping you on the wrist or suppressing your content. One of the only visible actions Meta has taken on my account was once when a cousin commented on a musical opinion I had posted to facebook, I jokingly replied \"I'll fight you\" and I caught an instant 2 week posting ban and a flag on my account for \"violence.\" Couldn't even really appeal it, or the hoops were so ridiculous that I didn't try. The hilarious thing is these bans will still let you consume the sites' content (gotta get those clicks), you just are unable to interact with it. This kind of moderation is pointless as users will always get around it anyway - leading to stuff like \"unalive\" to replace killing/suicide references, or \"acoustic\" to refer to an autistic person, etc. Just silliness, as you'll always be able to find a way to creatively convey your point such that auto-moderators don't catch it. reply circlingthesun 30 minutes agoparentI once posted a picture of an email stating my train was delayed in French. So the word 'retard' appeared in it. Instagram banned me from monetization or partnerships or something on my account, because the word for delay in French is offensive in English. reply dmd 26 minutes agorootparentPilots flying an Airbus get called a “retard” every time they land! reply ElectRabbit 14 minutes agorootparentEven worse: they cannot get open mental healthcare for this without loosing their license. Loose-loose-situation. reply somedude895 27 minutes agorootparentprevI wonder how many Spanish speakers got banned for discussing Vantablack at the time. reply sowut 2 minutes agorootparentprevretar dio reply baggachipz 32 minutes agoparentprevA tale as old as time. On old forums and groups: h4xor, ghey, etc. reply wbl 9 minutes agorootparentClbuttic reply tptacek 36 minutes agoprevI'd like to hear an informed take from anybody who thinks that Facebook's fact-checkers were a better product feature than Community Notes. All of the articles I'm seeing about this online are ideological, but this feels like the kind of decision that should have been in the works for multiple quarters now, given how effective Notes have been, and how comically ineffective and off-putting fact-checkers have been. The user experience of fact-checkers (forget about people pushing bogus facts, I just mean for ordinary people who primarily consume content rather than producing it) is roughly that of a PSA ad spot series saying \"this platform is full of junk, be on your guard\". reply davidw 28 minutes agoparentThe ideological bits are: * Dana White added to the board. * \"Move our trust and safety and content moderation teams out of California, and our US content review to Texas. This will help remove the concern that biased employees are overly censoring content.\" - like people being in Texas makes them more objective?! The actual mechanisms of running a social media network at scale are tricky and I think most of us would be fine with some experimentation. But it looks pretty political in the broader context, so maybe it's just a way of saying that certain kinds of 'content' like attacking trans people is going to be ok now. I can't quite FB entirely, but Threads looks like a much less interesting option with Blue Sky being available and gaining in popularity. reply tptacek 26 minutes agorootparentI get how the partisan story is easy to tell here, but I'm saying something pretty specific: I think it would have been product development malpractice for this decision not to have been in the works for many, many months, long before the GOP takeover of the federal government was a safe bet. Community Notes has been that successful, and Facebook's fact-checkers have been that much of a product disaster. I've never seen a wrong Facebook fact-check; I am warmly supportive of intrusive moderation; that's not where I'm coming from. reply davidw 19 minutes agorootparentAs a product decision taken independently, maybe. Running one of those things at scale with all kinds of people trying to subvert it for various reasons, including some downright evil ones, is not an easy task. Announced together with everything else and given the timing, I just can't help but think there's a political component to all of it. reply tptacek 16 minutes agorootparentI don't at all doubt that they're going to do whatever they can to cast this presumably longstanding product plan in the light most favorable to the governing majority! I just want to get the causality right. reply pessimizer 9 minutes agorootparentprev> I just can't help but think there's a political component to all of it. I mean, of course there is. The pressure to censor that began once Trump started dominating the Republican primaries in 2015, and escalated when the government chose a line on covid that absolved the government from responsibility for covid and made dubious claims about it, is ending. The reason the recent censorship frenzy began was political (nobody was censoring flat-earthers), and the reason it's ending is political. Now the US can get back to just censoring Palestinians, like the old days. reply ethbr1 6 minutes agorootparentprevI expect it was an easy bone to throw the incoming administration, which the tech world learned from v1 is placatable by giving them PR / sound bite wins. To the broader concern, this feels like Facebook making their original sin again. Namely defunding and destroying revenue for a task that takes money (fact checking) and then expecting a free, community-driven approach to replace it. Turns out, hot takes for clicks are a lot cheaper than journalism. In this case, where is the funding to support nuanced, accurate fact checking at scale from? Because it sure seems like Facebook isn't going to pay. > I've never seen a wrong Facebook fact-check Did you mean to say Note here? reply tptacek 4 minutes agorootparentNo, I meant to say Facebook fact-check. reply marbro 8 minutes agorootparentprevnext [2 more] [flagged] davidw 7 minutes agorootparentThat's a housing problem. California is very NIMBY and doesn't build enough homes. That has nothing to do with how 'objective' fact checking or content review or whatever is from people in both places. This is just very thinly coded language signalling who they're going to favor. reply josefritzishere 34 minutes agoparentprevGenerally fb has trended to worse rather than better. I already passed my personal tipping point years ago and quit fb. reply tptacek 33 minutes agorootparentIt is what it is. It's a hotspot for local politics, so quitting it isn't really an option for me. reply kelseydh 37 minutes agoprevIt's funny how facebook got so political all the normies left, then they downranked political content so much that the political people left too. Facebook is a ghost town now. reply redserk 7 minutes agoparentGoing back even further, one of the initial draws of Instagram pre-acquisition was that you could escape the toxicity of trolls and other socially unproductive behavior on Facebook. Meta has a big problem coming up. They'll get to the point where they won't be able to hide Facebook and Instagram's lackluster appeal. I suspect we'll start seeing advertisers peel away, followed by a few savvy investors first. Let's just hope this doesn't trigger a market-wide correction. reply 01HNNWZ0MV43FF 7 minutes agoparentprevDo they still mandate using your legal name? That's the biggest no-go for me. It's just awful opsec. reply kamikazeturtles 7 minutes agoparentprevSurprisingly, Facebook has 2.1 billion daily active users. I primarily use the app for its Marketplace feature as an alternative to Craigslist. reply insane_dreamer 56 minutes agoprevI'm sure it's a win for Meta (less responsibility, less expense, potentially less criticism, potentially more ad dollars), but certainly a loss for users. More glad than ever that I deleted my FB account 10 years ago, and Twitter once it went X. reply coffeemug 11 minutes agoparentMy twitter account wasn't big, but it was non-trivial (~30K followers). A post could usually get me to experts on most topics, find people to hang out with in most countries, etc. There were many benefits, so deleting was very hard. But it was eating my brain. I found myself mostly having tweet-shaped thoughts, there was an irresistible compulsion to check mentions 100 times a day, I somehow felt excluded from all the \"cool\" parts which was making me miserable. But most importantly, I was completely audience captured. To continue growing the account I had to post more and more ridiculous things. Saying reasonable things doesn't get you anywhere on Twitter, so my brain was slowly trained to have, honestly, dumb thoughts to please the algorithm. It also did something to attention. Reading a book cover to cover became impossible. There came a point when I decided I just don't want this anymore, but signing out didn't work-- it would always pull me back in. So I deleted my account. I can read books again and think again; it's plainly obvious to me now that I was very, very addicted. Multiply this by millions of people, and it feels like a catastrophe. I think this stuff is probably very bad for the world, and it's almost certainly very bad for _you_. For anyone thinking about deleting social media accounts, I very strongly encourage you to do it. Have you been able to get consumed by a book in the past few years? And if not, is this _really_ the version of yourself you really want? reply skillpass 37 minutes agoparentprevWhy is it “certainly a loss for users”? Many are likely to enjoy the ability to post without censorship on topics they care about. reply insane_dreamer 6 minutes agorootparentFact-checking and censorship are two very different things. reply pessimizer 5 minutes agorootparentDeleting isn't fact-checking. Whereas \"community noting\" actually can make a case for being fact-checking. reply saxonww 5 hours agoprevWhat I think I just read is that content moderation is complicated, error-prone, and expensive. So Meta is going to do a lot less of it. They'll let you self-moderate via a new community notes system, similar to what X does. I think this is a big win for Meta, because it means people who care about the content being right will have to engage more with the Meta products to ensure their worldview is correctly represented. They also said that their existing moderation efforts were due to societal and political pressures. They aren't explicit about it, but it's clear that pressure does not exist anymore. This is another big win for Meta, because minimizing their investment in content moderation and simplifying their product will reduce operating expenses. reply dotancohen 24 minutes agoparent> it means people who care about the content being right will have to engage more with the Meta products to ensure their worldview is correctly represented. To me it sounds better for large actors who pay shills to influence public opinion, like Qatar. I disagree that this is better for either Facebook users, or society as a whole. It does however certainly fit the Golden rule - he with the gold makes the rules. reply aklemm 37 minutes agoparentprevWhat I heard is that trying to maintain sane content is less profitable than the alternative, and definitely less politically advantageous. reply phatfish 4 hours agoparentprev> it means people who care about the content being right will have to engage more with the Meta products to ensure their worldview is correctly represented. Or maybe such people have far better things to do than fact check concern trolls and paid propagandists. reply jfengel 34 minutes agorootparentThere do seem to be a lot of people who enjoy fact checking concern trolls and paid propagandists. I'm not sure if they do more good than harm. Often the entire point seems to be to get those specific people spun up, realizing that the troll is not constrained to admit error no matter how airtight the refutation. It just makes them look as frothing as trolls claim they are. And yet, it's also unclear if any other course of action would help. Despite decades of pleading, the trolls never starve no matter how little they're fed. reply bamboozled 4 hours agorootparentprevI pay for some news subscriptions now. I actually love it. Read it, support journalism , log off. Done. reply insane_dreamer 58 minutes agoparentprev> I think this is a big win for Meta, because it means people who care about the content being right will have to engage more with the Meta products to ensure their worldview is correctly represented. Strong disagree. This is a very naive understanding of the situation. \"Fact-checking\" by users is just more of the kind of shouting back and forth that these social networks are already full of. That's why a third-party fact checks are important. reply ipython 41 minutes agorootparentI have a complicated history with this viewpoint. I remember back when Wikipedia was launched in 2001, I thought- there is no way this will work... it will just end up as a cesspool. Boy was I wrong. I think I was wrong because Wikipedia has a very well defined and enforced moderation model, for example: a focus on no original research and neutral point of view. How can this be replicated with topics that are by definition controversial, and happening in real time? I don't know. But I don't think Meta/X have any sort of vested interest in seeing sober, fact-based conversations. In fact, their incentives work entirely in the opposite direction: the more anger/divisive the content drives additional traffic and engagement [1]. Whereas, with Wikipedia, I would argue the opposite is true: Wikipedia would never have gained the dominance it has if it was full of emotionally-charged content with dubious/no sourcing. So I guess my conclusion from this is that I doubt any community-sourced \"fact checking\" efforts in-sourced from the social media platforms themselves will be successful, because the incentives are misaligned for the platform. Why invest any effort into something that will drive down engagement on your platform? [1] Just one reference I found: https://www.pnas.org/doi/abs/10.1073/pnas.2024292118. From the abstract: > ... we found that posts about the political out-group were shared or retweeted about twice as often as posts about the in-group. Each individual term referring to the political out-group increased the odds of a social media post being shared by 67%. Out-group language consistently emerged as the strongest predictor of shares and retweets: the average effect size of out-group language was about 4.8 times as strong as that of negative affect language and about 6.7 times as strong as that of moral-emotional language—both established predictors of social media engagement. ... reply ldoughty 49 minutes agorootparentprevTrue, but that doesn't discount that it's a win for Meta 1) Shouting matches create more ad impressions, as people interact more with the platform. The shouting matches also get more attention from other viewers than any calm factual statement. 2) Less legal responsibility / costs / overhead 3) Less potential flak from being officially involved in fact-checking in a way that displeases the current political group in power Users lose, but are people who still use FB today going to use FB less because the official fact checkers are gone? Almost certainly not in any significant numbers reply insane_dreamer 42 minutes agorootparentYeah, I agree it's a win for Meta from a $$ perspective, just not for the reason the OP expressed (which was what I was disagreeing with). \\ reply freedomben 41 minutes agorootparentprevYou should look into the implementation, at least the one that X has published. It's not just users shouting back and forth at each other. It's actually a pretty impressive system reply lazyeye 44 minutes agorootparentprevIts more naive to think a fact-checking unit susceptible to govt pressure is likely to be better. There will always be govt pressure in one form or another to censor content they doesnt like. And we've obviously seen how this works with the Dems for the last 4 years. reply yodsanklai 2 hours agoparentprev> They aren't explicit about it, but it's clear that pressure does not exist anymore It's clear that the pressure comes now from the other side of the spectrum. Zuck already put Trumpists at various key positions. > I think this is a big win for Meta, because it means people who care about the content being right will have to engage more with the Meta products to ensure their worldview is correctly represented. It's a good point. They're also going to push more political contents, which should increase engagement (eventually frustrating users and advertisers?) Either way, it's pretty clear that the company works with the power in place, which is extremely concerning (whether you're left or right leaning, and even more if you're not American). reply lazyeye 41 minutes agorootparentIs it less concerning if Facebook only worked with one side of politics? How is reducing censorship a bad thing? reply HeatrayEnjoyer 35 minutes agorootparentWho said anything about that? reply WalterBright 37 minutes agoparentprevThe trouble with fact checkers was quite evident in the Trump-Harris debate. reply techfeathers 9 minutes agorootparentAs a Harris supporter, I actually agree, I think it was way too heavy handed and hurt Harris more than helped. I’m not sure anymore what the goal of fact checking is (I’ve always felt it was somewhat dubious if not done extremely well). reply ziddoap 32 minutes agorootparentprevNon-American here (i.e. did not watch the debate), what trouble became evident? Were they fact-checking too much? Not enough? Incorrectly? reply WalterBright 31 minutes agorootparentOnly one side was fact checked. reply autoexec 19 minutes agorootparentWas it the side that did the vast majority of the lying? reply philipwhiuk 5 hours agoparentprev> reduce operating expenses If you assume they are immune to politics (not true but let's go with it), this is the most obvious reason. They've seen X hasn't taken that much heat for Community Notes and they're like \"wow we can cut a line item\". The real problem is, Facebook is not X. 90% of the content on Facebook is not public. You can't Fact Check or Community Note the private groups sharing blatantly false content, until it spills out via a re-share. So Facebook will remain a breeding ground of conspiracy, pushed there by the echo chamber and Nazi-bar effects. reply raxxor 5 hours agorootparentHow would fact checkers access the 90% of private content? And should they? I don't think so, even if the respective private content is questionable. The EU goes its own way with trusted flaggers, which is more or less the least sensible option. It won't take long until bounds are overstepped and legal content gets flagged. Perhaps it already happened. This is not a solution to even an ill-defined problem. reply cwillu 30 minutes agorootparentprevGood. Private communication is private, even if it's a group. The nice thing about the crazy is that they're incapable of keeping quiet: they will inevitably out themselves. In the meantime, maybe now I can discuss private matters of my diagnosis without catching random warnings, bans, or worse. reply autoexec 16 minutes agorootparentWhat kind of diagnosis spawns so many fact checks that it's a problem? I'd think any discussion about medical issues would benefit greatly from the calling out of misinformation. reply ColdTakes 4 hours agoparentprevThe pressure has just shifted from being applied by the left to the right. There is still censorship on Twitter, it is just the people Elon doesn't like who are getting censored. The same will happen on Facebook. Zuckerberg has been cozying up to Trump for a reason. reply LtWorf 2 hours agorootparentfb has been censoring left wing stuff and leaving fascists be since several years. This is just \"like before, but even more\" I think. reply urmish 1 hour agorootparentprevYou're right, censorship is same as lack of censorship. reply qingcharles 41 minutes agoparentprevCommunity Notes is the best thing about Musk's Dumpster fire. The problem with CN right now, though, is that Musk appears to block it on most of his posts, and/or right-wing moderators downvote the notes so they don't appear or disappear. reply kristianc 35 minutes agorootparentThe bad faith “NNN - just expressing an opinion” is a cancer on CNs too. reply extraduder_ire 34 minutes agorootparentprevCommunity notes launched at the start of 2021. It predates the buyout by almost two years. If what they said about their design is to be believed, political downvoting shouldn't heavily impact them. I wish it was easier to see pending notes on a post though. reply qingcharles 15 minutes agorootparentI agree, you should be able to see pending notes even if you're not a CN moderator. reply Analemma_ 26 minutes agorootparentprevRight, I think that's the parent's point: CN is a great design, dragged down by the fact that Elon heavily puts his thumb on the scale to make sure posts he likes spread far and wide and posts he dislikes get buried, irrespective of their truth content. reply qingcharles 15 minutes agorootparentThis. You're getting downvoted as bad as me LOL reply grues-dinner 4 hours agoparentprevYes, this just reads like \"oh, thank God for that, that department was an expensive hassle to run\". I don't know if I'd call it a certain win for Meta long term, but it might well be if they play it right. Presumably they're banking on things being fairly siloed anyway, so political tirades in one bubble won't push users in another bubble off the platform. If they have good ways for people to ignore others, maybe they can have the cake and eat it, unlike Twitter. Like Twitter, the network effect will retain people, and unlike Twitter, Facebook is a much deeper, more integrated service such that people can't just jump across to a work-alike. A CEO who can keep his mouth shut is also a pretty big plus for them. They skated away from bring involved with a genocide without too many issues, so same ethical revulsion people have against Musk seems to be much less focused. reply hintymad 1 hour agoparentprev> content moderation is complicated, error-prone, and expensive I think the fact-checking part is pretty straightforward. What's outrageous is that the content moderators judge content subjectively, labeling perfect discussions as misinformation, hate speech, and etc. That's where the censorship starts. reply AlotOfReading 45 minutes agorootparentHow do you avoid judging actual human discussions subjectively? I remember being a forum moderator and struggling with exactly the same issues. No matter what guidelines we'd set, there'd be essentially legitimate discussions that were way over the line superficially, and on the other you'd have neo-nazis acting in ways that weren't technically bad, but were clearly leading there. Facebook moderators have an even harder job than that because the inherent scale of the platform prevents the kinds of personal insights and contextual understanding I had. reply hintymad 25 minutes agorootparentMy answer is don't. If something is subjective, then why bother? \"Words are violence\" is such a bullshit. reply AlotOfReading 17 minutes agorootparentOkay, but you're saying this on a platform where the moderator (dang) follows intentionally vague and subjective guidelines, presumably because you like the environment more here than some unmoderated howling void elsewhere on the Internet. reply hintymad 1 minute agorootparentGood point, and thanks. I have to admit I don't have a good answer to this. Maybe what dang needs to assess can be better defined or qualified? Like we can't define porn but we know it when we see it? On the other hand, assessing something is offensive or is hate speech is so subjective that people simply weaponize them, intentionally or unintentionally. nicce 58 minutes agorootparentprev> That's where the censorship starts. It also starts when there is no third-party anymore. Where is the middle line? reply hintymad 28 minutes agorootparentI thought there would be community notes. And how would third-party work? The Stanford doctor was banned from X because he posted peer-reviewed papers that challenge the effectiveness of masks (or vaccines)? I certainly don't want to see that level of hysteria. reply autoexec 5 minutes agorootparent> The Stanford doctor was banned from X because he posted peer-reviewed papers that challenging the effectiveness of masks (or vaccines)? I certainly don't want to see that level of hysteria. Not familiar with that specific case, though generally I'm not a fan a bans. Fact checks are great though. There have been peer reviewed papers about midi-chlorians too (https://www.irishnews.com/magazine/science/2017/07/24/news/a...), but I'd sure hope that if someone brought it up in a discussion they'd be fact checked. reply 1vuio0pswjnm7 2 hours agoprevPerhaps, given the situation with Twitter, now \"X\", more web and mobile app users will come to understand that despite its size, Facebook is someone's personal website. Like \"X\", one person has control. Zuckerberg controls over 51% of the company's voting shares. Meta is not a news organization. It has no responsibility to uphold journalistic standards. It does not produce news; in fact, it produces no content at all. It is a leech, a parasite, an unnecessary intermediary that is wholly reliant on news content produced by someone else being requested through its servers. reply megous 38 minutes agoparentNews organizations have no responsibility either. And I don't see why publisher of news even if they just re-publish should not be held to some responsibilities, like eg. abstaining from nefarious manipulation of content people see on their platform. reply theptip 2 hours agoprevCommunity notes seems to be quite well received. I like that the algorithm seems to be public and (IIUC) tamper-evident. The obvious context is that either Meta gets out of the content moderation game voluntarily, or the incoming admin goes to war with them. > focusing our enforcement on illegal and high-severity violations. I imagine this will in practice determine how far they can go in the EU. Community notes, sure. No moderation? Maybe not. reply qingcharles 38 minutes agoparentI really like Community Notes, and hate the rest of what Twitter has become. But... Community Notes is subject to \"tampering.\" Elon's either removes the CNs himself from his posts, or his brigade downvote them to infinity so they don't appear on all the misinfo he posts. reply insane_dreamer 1 hour agoprevNYTimes with more on this: https://www.nytimes.com/live/2025/01/07/business/meta-fact-c... reply donohoe 6 hours agoprevFrom bad to worse. Meta is probably one of the single largest funders of fact checking. Now that appears to be coming to an end. Third parties will no longer be able to flag misinfo on FB, Instagram or Threads in the US. This is not good imho. reply raxxor 6 hours agoparentI think internet discussion worked far better without fact checkers, where some of them cannot really be called accurate. The community notes are the better approach. They aren't always correct either, but it certainly is the better fit for freedom of expression and freedom of speech. Fact checkers are the authority approach that just does not fit. reply hmmm-i-wonder 5 hours agorootparentI haven't seen a single discussion be worse off due to fact checking, but I've seen tons of discussions where having it would improve things. I have seen people get mad because they can't post BS without it being challenged. To claim internet discussion worked better without fact checking is something I haven't seen any actual evidence for, just opinions like yours. Community notes is just a watered down, more easily 'ignored' version that appeases people that were angry about fact checkers to begin with. Hopefully there is a push-back, likely from EU legislation. Between the AI generators many of these companies are implementing and changes like this, platforms need to be held more accountable for what they allow to be posted on them. reply raxxor 5 hours agorootparentClaims are challenged all the time by other users and there are enough cases where fact checkers were wrong or heavily biased. EU legislation tries to introduce \"trusted flaggers\". A ridiculous approach, an information authority by a state-like entity doesn't work, even if they paint these flaggers as independent. They simply are not, a trusted and verifiable fact. Community notes provide higher quality info, it is the better approach. That is an opinion of course. We will probably see community notes on trusted flaggers. reply hmmm-i-wonder 1 hour agorootparent>Claims are challenged all the time by other users and there are enough cases where fact checkers were wrong or heavily biased. I've only seen a handful of cases where they were wrong of heavily biased, but I've seen hundreds of cases where the poster refuses to accept they are wrong and the fact checkers are right. >Community notes provide higher quality info, it is the better approach. That is an opinion of course. Roughly the same info but from less trusted sources and with less controls being higher quality sounds like a big bag of wishes but not grounded in reality. >We will probably see community notes on trusted flaggers. I expect lots of partisan complaining and yelling, but not a lot of actual valid challenges. reply kcplate 4 hours agorootparentprevExposure to many viewpoints, including wrong ones, provides a counterbalancing effect. When you actively try and suppress information you create a “forbidden knowledge” effect where people seek out silos where extreme and wrongheaded information gets passed without the “sunlight is the best disinfectant”—-it grows faster…becomes more wrong, more extreme, and more dangerous. Seems to me in my experience after decades of watching and participating in online discussion extremism really only became more problematic when fact checking and active efforts to suppress took hold. Whatever the good intentions may have been, the results were worse. reply ceejayoz 3 hours agorootparentThere's some academic research to the contrary; banning /r/fatpeoplehate and /r/coontown on Reddit reduced incidents of hateful speech across the platform. https://www.reddit.com/r/science/comments/6zg6w6/reddits_ban... / https://comp.social.gatech.edu/papers/cscw18-chand-hate.pdf \"Sunlight is the best disinfectant\" is a great pithy slogan, but modern society needs bleach and chlorhexidine sometimes. reply naasking 3 hours agorootparent> There's some academic research to the contrary; banning /r/fatpeoplehate and /r/coontown on Reddit reduced incidents of hateful speech across the platform. That does not imply it reduced hateful speech overall, maybe the censorship just increased antipathy and drove that speech underground or to other platforms where it couldn't be seen. reply ceejayoz 3 hours agorootparent\"Off Reddit\" is a win. Recruitment in neutral-ish venues like Reddit is critical for extremist groups; people aren't starting on Stormfront. reply naasking 3 hours agorootparentThat's still just a conjecture of a meaningful effect. Recruiters are able to change tactics in response you know. You're just naively assuming that those old tactics worked better just because reddit itself changed, but it could very well be the case that the more extreme rhetoric only attracted people who were already extremist and turned off moderates, but a more moderate approach that's now required could funnel more moderate people into an extremist pipeline. \"Off reddit\" is just a win for reddit's PR, and that's why they did it, and no other reason and no other effects can be inferred. reply hmmm-i-wonder 1 hour agorootparentprev>Exposure to many viewpoints, including wrong ones, provides a counterbalancing effect. When you actively try and suppress information you create a “forbidden knowledge” effect where people seek out silos where extreme and wrongheaded information gets passed without the “sunlight is the best disinfectant”—-it grows faster…becomes more wrong, more extreme, and more dangerous. Fact checkers don't suppress information, they add context and information to posts others make and provide the exposure to many viewpoints that echo chambers often do not have. People haven't stopped posting wrong and biased information with fact checkers, they just have the counterpoint to their bullshit displayed alongside their posts on the platform. >Seems to me in my experience after decades of watching and participating in online discussion extremism really only became more problematic when fact checking and active efforts to suppress took hold. Whatever the good intentions may have been, the results were worse. My decades of watching is exactly the opposite. Extremism is and was rampant long before fact checking, and fact checking really only served to push some of the most extreme content to the margins and to smaller platforms that don't have it. It concentrates it in some ways as many of these opinions fall apart quickly when exposed to truth and facts. reply freedomben 34 minutes agorootparent> Fact checkers don't suppress information, I think some moderation is important, but misrepresenting fact checkers (damn ironic actually) doesn't serve us. Of course fact check suppresses information! That's the whole point. Sometimes it results in straight up deletion, but even when not it results in lowered reach aka suppression of what the algorithm would normally allow to trend, etc. reply hmmm-i-wonder 9 minutes agorootparent>Of course fact check suppresses information! That's the whole point Its not. The fact checkers in this case, and almost all cases we're discussing ADD information that challenges the posted data, not censor or restrict it from being posted. Outside of illegal content that is. Content deemed illegal was removed by moderation teams, this was before fact checking, and will continue with community notes with little to no change. reply notahacker 1 hour agorootparentprev> Seems to me in my experience after decades of watching and participating in online discussion extremism really only became more problematic when fact checking and active efforts to suppress took hold. Whatever the good intentions may have been, the results were worse. Seems like the opposite. Traditionally we only had siloed forums which were often heavily moderated by volunteers who considered the forums their personal fiefdom, read every single thread and deleted stuff for being \"off topic\" never mind objectionable, plus the odd place like /b/ which revelled in being unmoderated. Then you ended up with more people on big platforms that were comparatively-speaking, pretty lightly and reactively moderated. Then you ended up with politicians weighing in against moderation with the suggestion even annotating content published on their platform was a free speech violation, let alone refraining from continuing to publish it. The difference between antivax sentiment now and circa 2005 isn't that nobody ever determined that they weren't having that nonsense on their forums or closed threads with links to Snopes back then or that it's become difficult to find any references to it outside antivaxxer communities since then. Quite the opposite, the difference is that it's now coming from the mouth of a presumptive Health Secretary, amplified on allied news networks and now we have corporations running scared that labelling it a hoax might run the risk of offending the people in charge. Turns out sunlight is a catalyst for growth reply fzeroracer 42 minutes agorootparentprev> Seems to me in my experience after decades of watching and participating in online discussion extremism really only became more problematic when fact checking and active efforts to suppress took hold. Whatever the good intentions may have been, the results were worse. This is just overtly and flatly wrong. I reject your experience fully because over the past few decades the internet has become more open, not less. We openly debated people that believed vaccines caused autism and gave them microphones. Every single loud asshole and dipshit was given maximum volume on whatever radio show or podcast or social media platform they could want. reply leovingi 4 hours agorootparentprev> I haven't seen a single discussion be worse off due to fact checking The idea that there is some official governing body that has access to undisputable facts and they have the power to designate what you or I or anyone else can talk about is preposterous and, frankly, anyone on a site called Hacker News should be ashamed for supporting it. reply bavell 3 hours agorootparentA voice of sanity in a cacophony of madness. I hold no sympathy for Meta but it's laughable that so-called \"fact-checkers\" are anything but \"status-quo enforcers\". reply hmmm-i-wonder 1 hour agorootparentprev>The idea that there is some official governing body Platforms were encouraged to create their own departments, and have. There is no \"one\" or \"governing\" body here, so this is more hyperbole in this already flagrantly absurd discussion. >have the power to designate what you or I or anyone else can talk about is preposterous No one is stopping you from posting bullshit, fact checkers simply post the corresponding challenge or facts that allow others to see the lack of truth in your statements. The idea you can say whatever you want, lie all you want, and be unchallenged as some form of right is absurd. Claiming because you can be challenged is censoring you or preventing you from talking is also completely absurd. >and, frankly, anyone on a site called Hacker News should be ashamed for supporting it. Frankly anyone on this site should be able to separate hyberbolic strawmen from reality. reply nxm 4 hours agoparentprevWho was checking the fact checkers, when they were wrong quite often? reply kristianc 4 hours agoparentprev> From bad to worse. Meta is probably one of the single largest funders of fact checking. Now that appears to be coming to an end. Third parties will no longer be able to flag misinfo on FB, Instagram or Threads in the US. Zuck has probably done exactly that cost-benefit calculation — FB has put enormous resources into fact checking, and to most people it hasn't moved the needle on public perception in the slightest. Facebook is still seen through the lens of Cambridge Analytica, and as a hive of disinformation. The resources devoted to these efforts haven’t delivered a meaningful return, either in public trust or regulatory goodwill. reply blackeyeblitzar 5 hours agoparentprevFact checkers are often wrong, and often corrupted by the activists that end up working at them. For example I’ve repeatedly noticed articles from Politifact that are blatantly wrong or very misleading. When I look up those authors and their other work, their bias is clear. Community notes on X/Twitter is far more effective and accurate. reply silverquiet 4 hours agorootparentThe older I get, the more I realize that people just live in different realities and so many contradictory facts can be true. Obviously this is a source of conflict. reply naasking 3 hours agorootparentI don't think facts ever contradict each other, it's the stories people create to explain the facts that are at odds. These stories lead people to extrapolate other beliefs which they present as \"facts\", and it's an organic process of discussion and exposure that changes peoples minds over time. I personally think aggressive fact checking authorities impedes this process, because people don't change their minds when faced with authoritarian power against which they are powerless, and because they are powerless here, they get angry and they disengage. This ends up which reinforcing their beliefs and now you've lost all chance of change. reply dlivingston 15 minutes agorootparentRight. Imagine facts as data points on some Cartesian plane, and the narrative surrounding the facts as the curve fit to those points. The data points might all be sound, but by selectively omitting some, or by weighting their \"uncertainty\" higher or lower, you can fit just about any damn curve you want to them. One such instantiation of this: https://chomsky.info/consent01/ reply nailer 2 hours agoparentprevThank God. Fact checkers and political organisations pretending to fact check frequently spread false information. Aside from the 2020 election interference regarding the Hunter Biden laptop (which was falsely claimed to be a Russian disinformation effort), you can visit Snopes right now and read an article on how someone that blew up people (and now works for BLM) may not be a terrorist because ‘there are many different definitions of terrorist’. https://www.snopes.com/fact-check/blm-terrorist-rosenberg/ reply autoexec 20 minutes agoprev> Once the program is up and running, Meta won’t write Community Notes or decide which ones show up. They are written and rated by contributing users. Sure \"Meta\" won't, but I wouldn't be surprised if a bunch of \"contributing users\" end up being facebook's AI accounts reply elorant 19 minutes agoprevMy gut feeling is that this will be accompanied by a relaxed policy on fake profiles too. reply philjohn 4 hours agoprevThey've also said there will be more harmful (but legal) content on there as they'll no longer automatically look for it, but require it to be reported before taking action. As someone who worked on harmful content, specifically suicide and self injury, this is just nuts - they were raked over the coals in both the UK by an inquest into the suicide of a teenage user who rabbit holed on this harmful content, and also with the parents of teenagers who took their lives, who Zuck turned around and apologised to as his latest senate hearing. There is research that shows exposure to suicide and self injury content increases suicidal ideation. I'm hoping that there is some nuance that has been missed from the article, but if not, this would seem like a slam dunk for both the UK and EU regulators to take them to task on. reply BryantD 4 hours agoparentThis exactly mirrors my thoughts, although I don't work in your field. One quote: \"For example, in December 2024, we removed millions of pieces of content every day. While these actions account for less than 1% of content produced every day, we think one to two out of every 10 of these actions may have been mistakes (i.e., the content may not have actually violated our policies).\" That is first order data and it's interesting. However, before making policy decisions, I would want the second order data: what is the human cost of those mistakes, and what percentage of policy-violating content will not be removed as a result of these changes? Finally, what's the cost of not removing that percentage? For that matter, by talking about the percentage of active mistakes without saying how many policy violations are currently missed, you're framing the debate in a certain direction. reply theptip 44 minutes agorootparent> However, before making policy decisions, I would want the second order data: I think this the wrong lens. The correct lens is: if they don't voluntarily make this change, will they be forced to? The incoming administration seems committed to banning \"censorship\", so I believe making a cost/benefit analysis is something of a false choice. E.g. see https://www.youtube.com/watch?v=xJfUXVOoFBo reply barbazoo 1 hour agorootparentprev> we think one to two out of every 10 of these actions may have been mistakes May have been a mistake? Reminds me of RTO and the subjective feeling of being more productive in the office. They have the feeling they may have made mistakes and base their new policy on that feeling. reply theptip 46 minutes agorootparentI think what they are saying there is the press release interpretation of experiments showing a false positive rate of 10-20%, with error bars wide enough that stating a percentage gives too many significant figures. But the definition of FP is necessarily fuzzy; if you can perfectly identify them as FP at scale then you have built a better classifier and you no longer have the FP problem. So any statement about FP rates necessarily needs to be couched in uncertainty. I don't think it's malicious wordsmithing where they are mis-representing the internal data, though I don't have the data to confirm. reply philjohn 4 hours agorootparentprevIndeed. The human cost of a piece of content being taken down depends on the piece of content, and the reason behind posting it. In the case of someone posting about recovery from self injury and including a photo of their healed self-harm scars, having that taken down by mistake would be more harmful than someone who posted a cartoon depiction of suicide for the lolz. reply BryantD 3 hours agorootparentYes. My personal belief, for whatever that's worth, is that communication and speech are one of the most powerful tools any of us have. Talking can change minds, move societies, arouse emotions, and in general makes a difference. This is true no matter the format (text, voice, etc.). That means that restricting communication should not be a casual activity. Free speech is a good ideal for a reason. It also means that, if you believe in the primacy of free speech, you are obligated to consider the implications of that belief. Speech has effects. In my adult life, since 1990, we have seen a major change in the ease of communication. IMHO, society hasn't been able to fully adjust to that change -- or rather, that huge suite of changes. I sincerely do not know what a healthy society using the Internet looks like; I don't think we're in one now. All of these arguments (on all sides, mine included) are hampered by our lack of perspective. reply philjohn 3 hours agorootparentWhich is why we should research this carefully - and the research thus far points to consumption or graphic or even borderline depictions of suicide, self injury and eating disorder content (eg thinspo) being bad for mental health in at least teens. Meta seem to be making the case for those who would see social media banned for people under the age of 18. To enforce that properly would require needing ID, and that then opens a whole can of civil liberty issues. reply nradov 2 hours agorootparentThe social \"science\" research in this area is junk with small effect sizes, unclear causality, and multiple uncontrolled variables. People who claim to be following the science in this area are generally being disingenuous and picking results that support their preferred ideology. reply ben_w 3 hours agorootparentprevGiven how easy it is to take things out of context, I'm not so sure that the original context really makes a difference. There's more people online than any of us has heartbeats, and the n^2 number of user-user pairs generates detrimental effects that track any positive effects. Much better, I think, for each of us to have a small and private personal social network, not to hand everything over to a foreign* company trying to project its social norms worldwide. * Facebook claims about 3 billion active users, so for 89%-93.5%** of its users, the fact that Facebook is American makes them foreign. ** https://thesocialshepherd.com/blog/facebook-statistics#:~:te.... reply nradov 1 hour agorootparentprevThe human cost can't be quantified in any meaningfully precise way on either side. The calculations are necessarily based on so many assumptions as to become entirely subjective. Ultimately the decisions will be made based on politics and business priorities, not any objective calculation of human cost. reply naasking 3 hours agoparentprev> There is research that shows exposure to suicide and self injury content increases suicidal ideation. Yes. However, I find this obsession with harm-based value judgment to the exclusion of all other considerations ethically problematic, to put it mildly. Ethics does not reduce solely to considerations of harm. reply philjohn 3 hours agorootparentWould you mind expanding on that please, what are the ethically problematic things you are trying to balance against this? reply rayiner 4 hours agoparentprev> There is research that shows exposure to suicide and self injury content increases suicidal ideation. This is such a weak basis for suppressing open discourse. Have these studies been reproduced? What is the effect size? And why aren't you considering the countervailing harm to society of centralized moderation? reply ceejayoz 4 hours agorootparent> And why aren't you considering the countervailing harm to society of centralized moderation? Are there reproducible studies showing that? What is the effect size? (These objections go both ways!) reply mike_hearn 2 hours agorootparentArguably they don't go both ways. The distinction is action vs inaction. If someone wants action from someone else, they need to argue the case for that action. Arguing for not doing something on the other hand is never necessary. To see why, consider that the space of possible actions someone could not take is infinite. If there's an expectation that someone do a ton of research and work to argue for why they are not doing something, then the amount of work they would have to do is thus also infinite. This way lies madness, which is why in reality the default outcome that results from not acting is always taken as a given. Sometimes this reality is obfuscated by activists. They find some group of people who are just doing their thing, and demand that those people do some extra things (usually some costly things). The arguments they make for this are weak, but when the targeted people say they'd rather not do those extra things the activists demand their targets argue for not doing what the activists want to whatever level of effort (or greater) they themselves made. This can be an effective bullying tactic but isn't legitimate: it's on those who want action to argue the case for it, not those who don't to argue against. Digital platforms like social networks default to uncensored. If the operators do nothing, then by the way they are built content is allowed. It takes additional work to categorize posts and block certain kinds of content. So the default outcome is free speech. If someone wants someone else to do work to suppress that, then it's on them to prove that it's truly necessary and that the benefits outweigh the harms. But that doesn't cut both ways; it's not required for other people to take on the argument for free speech. That's the default outcome so it just wins by default if the other side can't prove their case to a sufficiently convincing level. reply ceejayoz 2 hours agorootparentChoosing not to act is an action. The choice not to moderate certain content is a choice to permit certain content. reply mike_hearn 1 hour agorootparentNot acting is, by definition, not an action. reply ceejayoz 47 minutes agorootparentI see someone drowning. I have a life ring. I choose not to throw it to them. They drown. Did I act? https://en.wikipedia.org/wiki/Duty_(criminal_law) reply mike_hearn 31 minutes agorootparentNo! First sentence: > Duty (criminal law), is an obligation to act under which failure to act (omission), results in criminal liability You failed to act, which is why a law is sometimes required to compel action. However, saving a drowning person isn't something that triggers such a legal obligation in the USA unless you're the person who actually pushed someone into the water in the first place. I don't get why this thread is getting so long or so abstract. The principles here are straightforward. Facebook don't actually have to care about what arguments activists make, but even if they did, it's on activists to win the argument for what they want. You don't get to automatically have your own way unless someone sits down and does a randomized controlled trial showing that you're wrong - and this is independent of what domain we're talking about. reply hollerith 1 hour agorootparentprevSure, but not choosing is a choice. reply mike_hearn 55 minutes agorootparentThat's not really how language works. If not choosing to do something is a choice, then today we have all made an infinite number of choices. Nobody would ever express themselves that way. But even if you want to play word games, choices and actions aren't the same thing. Choosing to act is quantitively different from choosing not to act because it involves a different level of effort. It's wrong to assume that they are morally equal. reply hollerith 44 minutes agorootparent>then today we have all made an infinite number of choices The way I like to think about it is that once a choice has risen to the level of conscious awareness, it is an illusion that a person can just decline to choose. reply rayiner 3 hours agorootparentprevThere’s lots of mainstream media content I think is psychologically harmful and should be suppressed, such as content normalizing adultery. But I’m quite content to live in a society where the social norm favors people saying what they want and the burden is on the opponents of that to produce strong evidence of harm. reply myvoiceismypass 3 hours agorootparentWhich studies have you read that show the psychological harm of seeing adulterous content? reply ceejayoz 3 hours agorootparentprevConvenient that only your debate opponents need provide reproducible studies that meet your standards. reply layer8 2 hours agorootparentNo, this is the “presumed innocent until proven guilty” principle. reply ceejayoz 2 hours agorootparentWhy does that principle not apply to “moderation is bad”? reply threatofrain 1 hour agorootparentprevBut all we see are two proponents in a civil trial. Shouldn't the standard be the well known \"preponderance of evidence\"? Though personally preponderance of evidence seems to be a shitty standard too because I might be listening to two awful theories and be forced to conclude one is the winner. Theories should rise above a minimum threshold to even consider sniffing at before we consider one as superior over the other. reply layer8 11 minutes agorootparentI agree that there needs to be a better standard than just “more likely than not”. Freedom of expression is a fundamental good, and there should be clear evidence of harm outweighing that good, before curtailing it. Regarding my previous comment, my intent was to point out the GP comment’s position (because the parent’s comment seemed to be beside the point), not necessarily to endorse it. n4r9 3 hours agorootparentprevRight. The challenge for free speech absolutists is to demonstrate that free speech takes priority over moderating hate speech, adult content, highly addictive media etc... . That demonstration needs to evidence-based and framed in terms of short and long term social harms/impact. Simply saying \"censorship hasn't gone well for some countries\" or \"having a free speech zone is extremely important to the future of civilization\" is not enough. reply nradov 2 hours agorootparentNo, that's not how this works. By default everything permitted. The entire burden of evidence rests on those who want bans or restrictions. reply n4r9 2 hours agorootparentHmm. Who decides \"how this works\"? Consider hate speech. There is a clear short-term benefit of moderation: reducing the harms to marginalised people from being exposed to threats to their person, identity, and way of life. In the face of this benefit, the absolute free speech advocate must provide a counter-argument for why free speech overrides that harm-reduction. reply logicchains 47 minutes agorootparent>reducing the harms to marginalised people from being exposed to threats to their person, identity, and way of life This only makes sense if you use a recent definition of \"harm\" created by censorship advocates that's divorced from the traditional meaning. In criminal law, harm traditionally (and still does in America) mean actually physically harming someone's body or making threats to do so. Censorship advocates are the ones making the claim that mere words should also constitute harm, so the onus is on them to justify why they want to change the meaning of the word like that. reply ceejayoz 29 minutes agorootparent> In criminal law, harm traditionally (and still does in America) mean actually physically harming someone's body or making threats to do so. Fraud can be criminal, without bodily harm or threats. Verbal child abuse can be criminal, without bodily harm or threats. There are lots of criminal harms not covered by your claimed definition in the American legal system. reply BryantD 4 hours agorootparentprevEnjoy: https://www.nsrf.ie/wp-content/uploads/2023/09/Harmful-impac... reply miltonlost 3 hours agorootparentprevShowing pictures of suicide is \"open discourse\" now? That's what you're defending? reply philjohn 4 hours agorootparentprevAre we arguing that graphic images of suicide and self injury are required for open discourse? reply dado3212 1 hour agoparentprev> So, we’re going to continue to focus these systems on tackling illegal and high-severity violations, like terrorism, child sexual exploitation, drugs, fraud and scams. I don't think this is exhaustive, and I think SSI (suicide/self-injury) + ED/etc. stuff is considered high-severity. reply philjohn 22 minutes agorootparentFingers crossed. reply jarsin 2 hours agoparentprevI've already seen disturbing stuff on X since Elon took over that I never would have seen when it was twitter. They don't even show the warning \"this might be harmful content\" on images and videos anymore. The X algo seems to go haywire every couple of days and dumps a bunch of this crap in my feed until I block 20+ bluecheck accounts showing this crap. I believe it's only going to get worse going forward as they all adopt these policies. reply Dig1t 2 hours agoparentprev“Think of the children” isn’t really a good argument for censoring completely legal political discourse, which is what has been happening. They are admitting that there has been a global push against free speech on these platforms. >There is research that shows exposure to suicide and self injury content increases suicidal ideation. I mean do you really need research to show this link? Of course it does. We are okay with slapping an “R” rating on movies and allowing parents to be the ones who decide what content their kids can see. Why can’t we decide that parents also need to be the ones to stop their kids from consuming bad content on social media? reply philjohn 23 minutes agorootparentAutomatically demoting, not recommending and adding \"mark as disturbing\" screens is what's going away - which is akin to the \"R\" rating. But at this point, I'm siding with the \"no social media for adolescents\" people more and more. reply freshnode 26 minutes agoprevPolarization drives ad revenue. $10 says Zuck is going to start throwing grenades at the UK and EU soon too. We're entering a dangerous period, and it's not for anything as noble as the virtues of absolute free speech reply maxfurman 4 hours agoprevMeta is giving up on the (impossible by design) task of policing their own platform. The result will be even more poisonous to users. Just like cigarette companies using chemicals in the papers so that they burn slower. Does it improve the product? Maybe, along one dimension. reply yodsanklai 1 hour agoparent> Meta is giving up on the (impossible by design) task of policing their own platform. It's a bit more than giving up. They are also going to push more political contents on feed. reply nicce 55 minutes agorootparentAnd save money in the meantime, assuming users will not leave because of this. reply oliviergg 4 hours agoprevZuck claims \"Europe has an ever increasing number of laws,institutionalizing censorship and making difficult to build something innovative\" Ouch. As a European, I feel very wary of such a sentence and the implications. Time for Europe to wake up ? (edit: fix typos) reply mongol 4 hours agoparentWe are awake. We should decouple ourselves from the tech giants on the other side of the pond. They don't have our best interests in mind. reply oliviergg 3 hours agorootparentI'm not sure that we are awake. As a dev for a long time, I realized only 6 months ago, that all the tools I use daily are directly from US. My job and my life would be very very different without this technology. We are loosing ground, or more, we are falling down more and more quickly. reply mongol 3 hours agorootparentIt is individual of course. But for example Emanuel Macron and Mario Draghi have sounded the bell quite clearly. As individual citizens we should try to buy European any time there is a European alternative. reply sickofparadox 3 hours agorootparent>try to buy European any time there is a European alternative Good luck with that considering: >\"Europe has an ever increasing number of laws,institutionalizing censorship and making difficult to build something innovative.\" reply mongol 2 hours agorootparentI don't take that for gospel. It is just Marc's poor take. reply mike_hearn 2 hours agorootparentIt's pretty much right. Dig into what it takes to run a social network in most European countries and you'll hit at minimum the following problems: • Lack of a DMCA equivalent. DMCA lays out a lightweight process for platforms to process copyright disputes which if they follow it will avoid legal liability, which is needed on any platform that hosts user generated content. The EU Copyright acts require platforms themselves to enforce copyright and prevent users violating it. This is a gigantic technical implementation problem all by itself. Also, the US has the legal concept of fair use but that's not a concept in much of Europe, so people posting parodies etc thinking it's OK can still create liability problems. • No equivalent of Section 230. Many new laws that specifically criminalize the hosting of illegal speech, and which don't give any credit for effort. As what's illegal is vague and political in nature you can't make automated systems or even human-driven systems that reliably handle it, so the legal risks are large even with a good faith effort to comply. • GDPR, \"right to be forgotten\" and NetzDG style laws have large fixed costs associated with compliance which established companies can absorb but startups can't. For instance it's common for EU lawmakers to demand 24 hour turnaround times, which you can't reliably comply with if you're a one man startup. • Algorithmic transparency laws, which mean you can't obtain any competitive advantage by better ranking (being good at this is how TikTok got so big), and which can threaten your ability to clear spam or use ML. • Laws around targeted advertising mean you can't generate revenue comparable to what the US based firms can do, so you can't be competitive and your users will be annoyed by low quality barrel scraping ads for casinos after they click \"No\" on a consent screen without reading it. There's probably more. For example, running a commercial search engine or training AI models on the internet is illegal in the UK, because UK copyright law only allows \"data mining\" for research purposes. There's no way to argue it's fair use like they do in the US. Just one of many such problems off the top of my head. reply ceejayoz 1 hour agorootparent> Lack of a DMCA equivalent. Good. It's heavily misused here. > No equivalent of Section 230. https://en.wikipedia.org/wiki/Digital_Services_Act https://en.wikipedia.org/wiki/Electronic_Commerce_Directive_... > Laws around targeted advertising mean you can't generate revenue comparable to what the US based firms can do... Good! Agriculture is cheaper with slavery, but that isn't a great argument for permitting it. reply coldpepper 2 hours agorootparentprevWe don't need social networks that are not compatible with the laws and rights you listed. reply LtWorf 2 hours agorootparentprevWhat tools? The ones I use are done from people all over the world, certainly not predominantly in USA. https://map.debian.net/ reply dijit 50 minutes agorootparentI know of exactly 0 European businesses they use free open source software for their office suites. Z-E-R-O. I don’t even think companies have their own mailservers anymore, its mostly gsuite and microsoft office 365; people aren’t even hosting business critical applications in Europe unless compliance forces them- lot alone using european made tools to do it. reply oliviergg 2 hours agorootparentprevYes I somewhat agree on FOSS and I agree for the people. But I think that for the capital, it is massively US controlled (though is international too). Think of the seven first companies of the S&P500. (GAFAM, Nvidia, ...) If you look at the cac40 (france) or EUROSTOXX50 : I dont use directly any products of the tech company. But I'm sure that these companies use at least one the seven. Tech company in Europe are not ridiculous, but they are not leading the change. They optimize, they improve, but the lead is us centric. We have ASML, but for how long. ? reply alibarber 50 minutes agoparentprevAs a European who does generaly feel that the continent is on its way to becomming a museum, describing the absolute bilge that the flagship products of Facebook, YouTube, X etc are as 'innovative' feels in the same ballpark as describing the work of tobacco companies to sell and advertise their products in the 50s-80s as innovative. reply qingcharles 32 minutes agoparentprevAs a European I would say that Europe's governments are radically more focused on the well-being of their populations than say, the USA. But... is it just luck or is it this Nanny-state issue that makes it very hard to think of a single major Internet destination or tech company that was born in Europe? reply pjc50 4 hours agoparentprevEurope has anti-nazi laws for .. historical reasons. reply naasking 3 hours agorootparentWhat gets interpreted under anti-nazi law is the wrinkle though. reply LtWorf 2 hours agoparentprevWhat he means is \"I can't 100% control what news people get to read, and that's bad\" reply coldpepper 3 hours agoparentprevThe faster we decouple from societies like american, the better we europeans will be. We europeans defend our European way of life, against the degenerate capitalism of the US. reply Xcelerate 3 hours agorootparentAs an American who lived in Europe in the 90s when I was young, a lot that I really appreciated about the European way of life has deteriorated and is now almost unrecognizable to me in some ways. When I visit every few years, it amazes me how quickly Europe is “Americanizing”. More fast food and less traditional food. Ripping up vineyards that have been there for centuries. Fewer protections for your farmers. More people walking around staring at their phones and less people talking to each other in cafes. Seems like almost everyone dresses like Americans and can speak English now. And it’s hard to tell the difference between the coffee shops in Spain and those in San Francisco. How long until you start building suburbs and driving everywhere? Don’t get me wrong—I love the U.S., and I love living here. But its culture is not for Europe. reply Aurornis 2 hours agorootparentComments like this are interesting because the changes you’re describing aren’t really “Americanizing”, they’re just a sign of modern times. For example: People weren’t walking around staring at their cellphones in Europe in the 90s because they were distinctly European. It was because we didn’t have smartphones anywhere. The smartphone changes happened in lockstep across the globe. Likewise, many of your other points are purely people’s personal preferences. I think your criticisms are largely nostalgia for the 90s and your time spent living abroad, not an indictment of “Americanizing” Europe. reply multimoon 3 hours agorootparentprevI challenge you to find another economic system that has worked in history, because it sure isn’t communism if that’s what you’re referencing. This is also aside from the fact that Europe is also a subscriber to capitalism. America is the most successful country on this earth and we bankroll most of the rest of the world but somehow we’re always the bad guys. As an American I’d be very happy if my tax dollars stopped getting spent on Europe. reply Toutouxc 6 minutes agorootparent> America is the most successful country on this earth and we bankroll most of the rest of the world I'm going to need a source (and some definitions) for that. reply yodsanklai 1 hour agorootparentprev> America is the most successful country on this earth According to what metrics? life expectancy? crime rate? wealth per inhabitant? education? work life balance? health care? happiness? incarceration rate? human rights? corruption? freedom of press? American tax dollars aren't spent in Europe or elsewhere in the world for some altruistic reason. The US want to maintain their hegemony and prevent other powers from emerging. They certainly don't care about Europeans or Taiwanese or whoever. > I challenge you to find another economic system that has worked in history, because it sure isn’t communism if that’s what you’re referencing. Not that I'm a big fan of communism or China, but communist China has been doing pretty well, and is getting more innovative than the US reply TheMagicHorsey 37 minutes agorootparentThe part of China that is innovative is not communist. They have the most free-market labor market, the most free-market regulations in everything except media (which is heavily controlled by the state). China is the most brutally capitalist society in the world, with a dictator sitting on top managing it at the margins and ensuring media will never be free and threaten the communist party. reply oliviergg 1 hour agorootparentprevCommunism is the godwin point of economical discussion. There is so much more possibility than unregulated capitalism / Individualism reply myvoiceismypass 3 hours agorootparentprevI might be missing something - are you saying the only choices of economic systems is communism or American style capitalism? reply aimazon 4 hours agoprevMark has looked at what has happened to Twitter since Musk took over, a notable decline in activity and value… and decided he wants a piece of that? Musk is begging people on Twitter to post more positive content, as it devolves into 4chan-lite. If Musk’s ideological experiment with Twitter had proven the idea that you can have a pleasant to use website without any moderation then Mark’s philosophical 180 would at least make sense, but this doesn’t, at all. What’s to gain? Musk has done everyone a favor by demonstrating that moderation driven by a fear of government intervention was actually a good thing. reply dpritchett 4 hours agoparentCould be an exit strategy… maybe he’s tired of running a social network and wants to help run governments and fly to space like the other guys. reply qingcharles 30 minutes agoparentprevCommunity Notes has nothing to do with trashfire of posters on Twitter now. CN is probably the only good thing about Twitter right now. reply notahacker 3 hours agoparentprevNew government. So you've got lack of moderation driven by a fear of government intervention. reply SketchySeaBeast 4 hours agoparentprevIt starts to make more sense when you think about who is arm in arm with the president elect. I don't know that Musk believes his philosophy is wrong and now he has the power to pressure others. reply bamboozled 4 hours agoparentprevI use meta products, it’s anecdotal but they’re dead. At least they seem very stagnant. This is appeasing the new establishment and hoping for more engagement ? reply wumeow 2 hours agoparentprev> Mark has looked at what has happened to Twitter since Musk took over, a notable decline in activity and value… and decided he wants a piece of that? Hell yes he does, Twitter helped Musk get a seat at the table with Trump and the ability to influence US policy decisions at an unprecedented level. Zuck craves power and sees sucking up to the incoming administration as an easy path to get more of it. reply nailer 2 hours agoparentprevI’m not sure where you’re getting data from but Twitter seems fine: https://www.demandsage.com/twitter-statistics/ Additionally, if you haven’t read the article you’re commenting on, community notes is an excellent replacement so-called fact checking services which are notoriously biased. reply aprilthird2021 1 hour agoparentprevI have a feeling it is more part of an agreement with the new administration. It was an agreement with the old administration that led to the current platform where there is way too much overreach on things the govt didn't want discussed: COVID, Palestine, immigration, etc. reply dmazin 4 hours agoprevAs a leftist, while this is concerning, it's also important to remember that Meta censors left content as much as it does right content. So, while this announcement certainly seems to be in bad faith (what could Mark mean by \"gender\" other than transphobic discussion?), this should be a boon both for far-right and left discussion. Does that mean increased polarization and political violence? Surely, surely. reply jl6 14 minutes agoparentHe explained it in the next sentence. If people are free to say it in Congress they should be free to say it on Meta platforms too, and that includes a range of non-binary opinions that aren’t intrinsically istphobic. reply spencerflem 4 hours agoparentprevYou know that this announcement is made to win favor with Trump. I would not expect that leftism will be any more allowed reply dmazin 4 hours agorootparentI agree. At the very least, it's using Trump as cover. That said, if they remove the political filter, they're opening the door for all discussion (even from the left). Of course, they could surreptitiously filter out the left. Hell, why not? reply spencerflem 4 hours agorootparentThat's my guess as to what they intend to do. Just moving the needle for allowed content to include transphobia and racism. reply lapcat 3 hours agoparentprev> this should be a boon both for far-right and left discussion. If by left discussion you mean discussion of the genocide in Gaza, don't count on it, because this censorship is bipartisan in the United States. Zuck cares about currying favor with the powerful. He doesn't give a crap about the powerless. Also, he's pretending that Texas, the proposed site for content moderation, is not politically biased, which is laughable. \"We're moving from a blue state to a red state\" is not a serious proposal for reducing or eliminating bias. reply nailer 2 hours agorootparentThe genocide conspiracy theory is all over instagram and twitter in the United States. reply lapcat 2 hours agorootparentConspiracy theory? reply nailer 2 hours agoparentprev> So, while this announcement certainly seems to be in bad faith (what could Mark mean by \"gender\" other than transphobic discussion?) Thinking that everyone that disagrees with you on with transgender ideology is in bad faith indicates you probably don’t understand what bad faith is. There is no lack of honesty or trust here -people just do not wish to participate in other peoples gender performances. reply GuinansEyebrows 36 minutes agorootparent> people just do not wish to participate in other peoples gender performances. The “bad faith” is in the pretending that we don’t all participate in gender performance with every single person we come into contact with, every single day, for our entire lives. reply guybedo 29 minutes agoprevIt's a welcome move as this \"fact checkers\" thing was doomed to fail, mostly because \"who decides what the truth is, and who fact checks the fact checkers?\". Sad thing is, this move isn't motivated by Mark Zuckerberg having a eureka moment and now trying to seek out the truth to build a better product for human kind. This move is motivated by Mark's realizing he is on the wrong side of American politics now, being left behind by the Trump/Musk duo. reply drawkward 4 hours agoprevWill this totally end content moderation? That could be a small silver lining, as content moderation for FB appears to be extremely hazardous to one's mental health: https://www.cnn.com/2024/12/22/business/facebook-content-mod... reply pjc50 2 hours agoparentObviously exposing the same content which was proven to cause harm to the content moderators to absolutely everybody on the platform will be worse. reply drawkward 1 hour agorootparentIt is not obvious that many people (when was the last time a single post was seen by the entirety of the platform?) seeing occasional soul-destroying stuff is worse than seeing soul-destroying stuff as full-time employment, 8 hours a day, 5 days a week for the length of one's work life. Also: perhaps the occasional soul-destroying post would help people break their social media addictions. reply LtWorf 55 minutes agoparentprevI'd love if they just sorted by timestamp, but no moderation + algorithm deciding what gets shown is not good. reply FergusArgyll 33 minutes agoprevI know there has been a lot of ink spilled trying to persuade that Technology can't solve our deeper problems and Technologists are too optimistic about having real-world impact etc. etc. But I think community notes (the model, not necessarily the specific implementation of one company or another) is one of those algorithms that truly solve a messy messy sticky problem. Fact-checking and other \"Big J Journalist\" attempts to suppress \"misinformation\" is a very broken model. 1) It leads to less and less trust in the fact checkers which drives more people to fringe outlets etc. 2) They also are in fact quite biased (as are all humans, but it's less important if your electrician has socialist/MAGA/Libertarian biases) 3) The absolute firehose of online content means fact checkers/media etc. can't actually fact check everything and end up fact checking old fake news while the new stuff is spreading The community notes model is inherently more democratic, decentralized and actually fair. and this is the big one it works! unlike many of the other \"tech will save us\" (e.g. web3 ideas) It is extremely effective and even-handed. I recommend reading the Birdwatch paper [0], it's quite heartening and I'm happy more tech companies are moving in that direction [0] https://github.com/twitter/communitynotes/blob/main/birdwatc... reply qingcharles 28 minutes agoparentAgreed. I think people are looking at CN/Birdwatch being from Twitter and seeing red without looking at the details. CN predates Musk burning Twitter to the ground, and CN is actually a decent product that can only get better as it is honed. reply goshx 2 hours agoprevI read this as Zuck kneeling to the new king and first lady (Musk). I highly doubt these changes were not influenced (forced?) by them. reply aurareturn 3 hours agoprevI speculated what Zuckerberg wanted and what he'd do when he visited Mar-a-lago[0]: * Push to ban Tiktok * Drop antitrust lawsuits against Meta * Meta will relax \"conservative\" posts on its platforms * Zuckerberg will donate to Trump's cause So far, Zuckerberg has already donated to Trump's cause. Now he has relaxed \"conservative\" posts on its platforms directly or indirectly. When Trump comes into power, he'll likely ask the FTC to drop its antitrust lawsuit against Meta under the disguise of being pro-business. My last speculation is push to ban Tiktok. I'm sure it was discussed. Trump has donors who wanted him to reverse the Tiktok ban. Zuckerberg clearly wants Tiktok banned. Trump will have to decide who to appease when he comes into office. [0]https://news.ycombinator.com/item?id=42262573#42262975 reply pbasista 1 hour agoparent> ban Tiktok I would be really interested in how someone could spin advocating for less moderation and at the same time asking to ban the competitors' social media platforms. reply GuinansEyebrows 39 minutes agorootparentyou’re assuming some kind of ideologically purity when it comes to “freedom of information” when the real answer is profit motive. reply theptip 36 minutes agoparentprevAlso, Zuck appointed Dana White to the board: https://about.fb.com/news/2025/01/dana-white-john-elkann-cha... So they have also given a board seat to a friend of Trump. But yeah, I think you're right that there is clearly some combination of dealmaking and bending the knee going on. reply baggy_trough 27 minutes agoprevThe moderation tools were themselves offensive and abusive. I use FB to read what my friends and relatives have to say. I don't want FB to interfere with their posts under any normal circumstance, but somehow, they felt like they should do this. But the real reason I can't use FB much any more is that the feed is stuffed full of crap I didn't ask for, like Far Side cartoons etc. reply throwaway12127 4 hours agoprevDupe with more explicit comments: https://news.ycombinator.com/item?id=42622082 reply Volundr 4 hours agoprevAs far as I can tell they gave up moderation a few years ago, at least every time I report someone spamming about \"Elon Musk giving away a million dollars if you click this shady link\" or the like I invariably get told it meets their \"community standards\" and won't be removed. I guess technically I haven't seen a female nipple there though so, job well done? reply mint2 4 hours agoparentThey also allow the scammiest ads for products that are 100% obvious frauds - pure distilled snake oil. It really brings meta’s image to the dirt. They’re like an online super market tabloid these days. reply arielcostas 4 hours agoprevZuck's video claims Europe has been imposing a lot of censorship lately, which is a nicer way for him to say \"we have done a crappy job at stopping misinformation and abusive material, got fined A LOT by countries who actually care about it, and that's somehow not our fault\". Community notes is good news, and something I was expecting to disappear from Twitter since Elon bought it a couple years ago, especially since they have called out his lies more than once. Hearing Facebook/Instagram/Threads are getting them is great. Then he claims \"foreign governments are pushing against American companies\" like we aren't all subject to the same laws. And actually, it wasn't the EU who prohibited a specific app alleging \"security risks\" because actually they can't control what's said there; it was the US, censoring TikTok. Perhaps we the europeans should push for a ban of US platforms like Twitter, especially when its owner has actually pledged to weaponise the platform to favour far-right candidates like AfD (Germany) or Reform UK. And definitely push for bigger fines to monopolistic companies like Meta. reply scop 35 minutes agoprevThis is unequivocally good. That’s it. That’s the comment. reply julianeon 4 hours agoprevTranslation: community notes are “good enough” from the perspective of the business community, and probably an order of magnitude cheaper. reply rayiner 4 hours agoprev> Starting in the US, we are ending our third party fact-checking program and moving to a Community Notes model. The Community Notes model works great on X at dealing with misinformation. More broadly, this is a vindication of the principle that putatively neutral \"expert\" institutions cannot be trusted unless they're subject to democratic checks and balances. reply blackeyeblitzar 5 hours agoprevCorporate censorship should have never happened. It is a huge corruption of public discourse and the political process. These platforms have hundreds of millions of users, or more, and are as influential as governments. They should be regulated like public utilities so they cannot ban users or censor content, especially political speech. Personally I don’t trust Zuck and his sudden shift on this and other topics. It doesn’t come with a strong enough rejection of Meta/Facebook’s past, and how they acted in the previous election cycle, during COVID, during BLM, etc. But I guess some change is still good. reply oliviergg 1 hour agoparentBut being at the head of a social network is political. Every choice is political. Allowing extreme speech to circulate is political, not authorizing it is political too. It is not corporate censorship, it's regulation. without regulation, it will be the voice of the loudest / strongest. And I think we need some rationality, not polarisation. reply astrange 4 hours agoparentprevYou can't use a social media platform that can't ban users, because it'll be full of spammers and people who only communicate in death threats. reply jhedwards 4 hours agoparentprevFeel free to correct me if I'm wrong, but I don't think there's any reasonable political discourse that is ever* censored by social media companies. During COVID, there were people spreading lies about the vaccine, which many people believed, and many people died as a result of believing those lies. Even Louis Brandeis, one of the fiercest advocates of free speech, made an exception for emergency situations[0], which is arguably what a pandemic is. But again, lies about a vaccine do not constitute reasonable public discourse, it is more akin to screaming fire in a crowded theater. If you have counter examples of regular public discourse that has been censored by a social media company, please share it. * I realize \"ever\" is a stretch, I'm sure there are instances, but my understanding is that they are the exception rather than the rule. [0] \"If there be time to expose through discussion the falsehood and fallacies, to avert the evil by the processes of education, the remedy to be applied is more speech, not enforced silence. Only an emergency can justify repression. Such must be the rule if authority is to be reconciled with freedom.\" - Louis Brandeis, Whitney vs. California reply SpicyLemonZest 3 hours agorootparentIt's hard to talk about, because when a discussion is successfully censored you usually don't hear about it and presume any discourse on it would have been unreasonable. I would point towards immigration as a topic where meaningful discourse is missing from social media. On most social media sites, the discussion will be dominated by people who think immigration should rarely if ever be restricted; Twitter has been colonized by some people who take the opposite extreme, often for overtly racist reasons, although this is tempered a bit by Elon Musk's personal support of high skill visas. The \"normie\" immigration restrictionist position, that immigrants are great but only so long as they enter the country lawfully, is something I very often see expressed in news interviews or supported by older relatives and rarely if ever see expressed on a social media platform. I don't know how I'd go about proving this is downstream of fact checking, but there's a lot of orgs who argue that it's factually false to characterize, for example, someone who crosses the border without authorization and then applies for asylum as an illegal immigrant. reply dagmx 3 hours agoprevI’m less concerned by the change of fact checking to community notes, because meta had often neutered the ability of their fact checkers anyway. What I am concerned about is their allowance of political content again. Between genocides and misinformation campaigns, meta has shown that the idea of the town square does not scale. Not with their complete abandonment of any kind of responsibility to the social construct of its actual users. Meta are an incredibly poor steward of human mental health. Their algorithms have been shown to create intense feedback loops that have resulted in many deaths, yet they continue down the march of bleeding as much out of people as possible. reply mongol 2 hours agoparent> the idea of the town square does not scale. Completely agree. Instead of one giant town square (\"Facebook\") what we would benefit from are 1000 smaller ones (\"Facebook competitors\") and some way to \"travel\" between them. That is a smaller more human scale that can be responsibly governed. It does not create hyper-billionaires though. reply ColdTakes 4 hours agoprevThis is my conspiracy theory but this is all in preparation for the end of Section 230 which will also inadvertently kill Blue Sky. reply nunez 3 hours agoparentCan you elaborate? reply ColdTakes 3 hours agorootparentThere is a long history but the short of it is, before Section 230, platforms that moderated user content faced potential liability. Oakmont v. Prodigy[1] is a case where Prodigy was held liable for defamatory posts due to its moderation efforts. However, in Cubby v. CompuServe[2], the court ruled that platforms without active moderation, CompuServe were not liable for user-generated content because they were just hosting with no active involvement. Section 230 protected platforms from liability for user content, allowing them to moderate in good faith without being held responsible for all harmful material if they weren't able to moderate everything. I believe Elon and Trump, being the internet's biggest liars, have the goal to remove Section 230 making moderating online more or less a crime that will open you to litigation and allow them and all of their followers to spread lies not only unchecked but with the threat of punishment if a company, like Blue Sky, were to try to moderate them. [1] https://en.wikipedia.org/wiki/Stratton_Oakmont,_Inc._v._Prod.... [2] https://en.wikipedia.org/wiki/Cubby,_Inc._v._CompuServe_Inc. reply bananapub 2 hours agoprevwhile it's obviously fair to be very very wary of everything FB does, especially moderation, the other side of this is a worldwide campaign by the worst people alive to use these platforms to shape public opinion and poison our (ie at least the West's) culture to death. reply gabaix 3 hours agoprevIronically the post is affected by Hacker News flame-war detection system. reply JumpinJack_Cash 1 hour agoprevTech has become so entrenched with Government. The Metaverse and the WFH bets made by Zuck were controversial but at least it was something rooted in tech and population habits trends and vision without any political poop attached to it. This one is pure political poop to please Orange Man. Also I believe that fact-checking needed to be slowly sunsetted after the COVID emergency was over, but the timing of this announcement and the binary nature of the decision means that it was done with intention to get in the graces of the new administration. If these techs executives become the American equivalent of Russian Oligarchs I hope that States would go after their wealth based on their residence and even ADS-B private jet trackers if they were to move to say Wyoming but partying every weekend in Los Angeles/NYC etc. reply bhouston 4 hours agoprevZuckerberg knows which way the winds are blowing in the US Capital and is ensuring he is aligned with them so to avoid political blowback on his company. I suspect the changes to the fact checking / free speech will align with Trump's political whims. Thus fact checking will be gone on topics like vaccines, trans people, threats from immigrants, etc. While the well documented political censorship at Meta affecting Palestine will remain because it does align with Trump's political whims... - https://www.hrw.org/news/2023/12/20/meta-systemic-censorship... - https://www.theguardian.com/technology/article/2024/may/29/m... reply spencerflem 3 hours agoparentPeople down voting this are being silly. Here's the topics the announcement mentioned: \"We’re getting rid of a number of restrictions on topics like immigration, gender identity and gender that are the subject of frequent political discourse and debate.\" Palestine is completely absent. reply TrackerFF 2 hours agoprevHot take: This is to please the incoming president. Both the far-right and far-left live off misinformation, but right now the far-right is experiencing a renaissance, and tech moguls are bending the knee to be on good terms with the leaders. MAGA and European far-right politicians have been moaning for ages that fact checking is \"politically biased\". The Biden laptop controversy was the catalyst for this. reply jjulius 4 hours agoprevIf you think this move exists in a vacuum or is actually about \"getting back to their roots with free speech\", you're wrong. Alongside Dana White joining the board[0], it's clear that this is solely about currying favor with the incoming administration. [0] https://www.npr.org/2025/01/06/nx-s1-5250310/meta-dana-white... reply gizmo 4 hours agoparentIt's not solely about currying favor. Many tech giants hate getting pushed around by politicians and courts around the world demanding censorship. Free speech rights in the US are much stronger than elsewhere in the world, and even businesses as large as Meta need political support to successfully push back on censorious overreach. For context, in Germany you can face up to 3 years prison time for insulting a politician: https://www.dw.com/en/germany-greens-habeck-presses-charges-... reply jjulius 1 hour agorootparent>It's not solely about currying favor. Many tech giants hate getting pushed around by politicians and courts around the world demanding censorship. Taking steps to not be pushed around by an incoming president who has clearly suggested he'll push them around is, quite literally, currying favor. reply tartoran 3 hours agorootparentprev> Many tech giants hate getting pushed around by politicians and courts around the world demanding censorship. They may not like that but they also don't like to take responsibility either. reply bhouston 4 hours agoparentprev100%. It is about aligning with Trump's political opinions. Thus I do expect to see no fact checking of anti-trans, anti-vaccine and anti-immigrant content. But I don't think that Meta's documented censorship of Palestinian content [1] will change, because the censorship is inline with Trump's political opinions. [1] https://www.hrw.org/news/2023/12/20/meta-systemic-censorship... reply philwelch 4 hours agoparentprevJust like complying with government censorship demands was about currying favor with the outgoing administration. reply ceejayoz 4 hours agorootparentLike this! https://www.rollingstone.com/politics/politics-news/elon-tru... > When the White House called up Twitter in the early morning hours of September 9, 2019, officials had what they believed was a serious issue to report: Famous model Chrissy Teigen had just called President Donald Trump “a pussy ass bitch” on Twitter — and the White House wanted the tweet to come down. reply rayiner 3 hours agoprev> We’re getting rid of a number of restrictions on topics like immigration, gender identity and gender that are the subject of frequent political discourse and debate. It’s not right that things can be said on TV or the floor of Congress, but not on our platforms. My mom and my wife’s mom both have remarked in the last year that they’re upset with speech policing. My mom can’t say things about immigration that she thinks as an immigrant, and my mother in law is censored on gender issues despite having been married to a transgender person in the 1990s. They’re not ideological “free speech” people. Neither are political, though both historically voted left of center “by default.” The acceptable range of discourse on these issues in the social circles inhabited by Facebook moderators (and university staff) is too narrow, and imposing that narrow window on normal people has produced a backlash among the very people who are key users of Facebook these days (normie middle age to older people). This is a smart move by Zuckerberg. reply pavlov 4 hours agoprevMeta also nominated a Trump-affiliated boxing entertainment businessman to its board yesterday. They’re doing everything they can to suck up to the incoming administration. reply paxys 4 hours agoprevnext [2 more] [flagged] MrMcCall 4 hours agoparentYou have gotten to the heart of the matter. Well done, indeed, sir/madam! reply Apreche 4 hours agoprevnext [3 more] [flagged] leovingi 4 hours agoparentAs opposed to them being brave, independent champions when it came to suppressing discussions about Covid or the Hunter Biden laptop reply bamboozled 4 hours agoparentprevMaybe some desperation going on behind the scenes ? reply incomingpain 4 hours agoprev>Ending Third Party Fact Checking Program, Moving to Community Notes CNotes were extremely successful on X. The problem with censorship, why digg and reddit died as platforms, you end up with second order consequences. The anti-free speech people will always deeply analyze their opponent's speech to find a violation of the rules. They try to make rules that sound reasonable but are beyond section 230. No being anti-LGBT for ex. But then every joke, miscommunication, etc leads to bans. You also ban entire cultures with this rule. Ive had bans because I meant to add NOT to my 1 sentence, but failed to do so. Then when it comes to politics. You've banned entire swaths of people/viewpoints. There's no actual meaningful conversation happening on reddit. Reddit temporarily influenced politics in this way. In a recent election a politician built a platform that mirrored the subreddit. There was polls and if you were to go by reddit... the liberals were about to take at least a minority government, if not majority. What actually happened? The platform was bizarre and very out of touch with the province. They got blasted in the election. The incumbent majority got stronger. reply macNchz 4 hours agoparent> CNotes were extremely successful on X. > reddit died By all measures I can find, reddit continues to grow year over year, while X seems to have been flat or in decline, so I’m not sure this is a strong premise. reply incomingpain 3 hours agorootparentFacebook is #1, followed by youtube. Tiktok is 4th. Linkedin is 8th. X is 12th. Reddit is 16th. Reddit fell a great deal in rankings. They mostly use bots to make it appear like they are still relevant. Which ironically is creating a 'dead internet' conspiracy theory. In reality its just 'dead reddit' reply ceejayoz 3 hours agorootparentRanked by whom, on what metrics? What were their relative rankings on the same metrics, say, five years ago? reply beanjuiceII 4 hours agoprevgreat news by the zuck good to see the framework being laid is having benefits for everyone reply matrix87 1 hour agoprev [–] during the biden administration they were expected to shift their moderation policies to fit in with the political ideology currently in the white house now it's been normalized and the other party is doing it. but the news outlets have waited until now to start crying wolf? reply blased 1 hour agoparent [–] Maybe, just maybe, it's because most people in the media are Democrats, and therefore inherently self-biased in their concerns and worldviews, and they have a belief that prevents any critical self-examination easily summed up by the Stephen Colbert line that: \"reality has a liberal bias.\" You can't argue with someone who thinks their beli",
    "originSummary": [
      "Meta is prioritizing free expression by simplifying its content moderation systems, which have been criticized for being overly complex and restrictive. - The company is ending its third-party fact-checking program in the U.S. and introducing a Community Notes system, similar to X, to provide context to potentially misleading posts through user contributions. - Meta is reducing restrictions on political content, simplifying enforcement processes to focus on severe violations, and personalizing political content visibility based on user preferences, aligning with Mark Zuckerberg's vision of free expression."
    ],
    "commentSummary": [
      "Meta is transitioning from its third-party fact-checking program to a Community Notes model, akin to Twitter's strategy, to potentially align with political changes and cut moderation expenses.",
      "Critics express concerns that this shift may result in more misinformation and harmful content, whereas supporters argue it could bolster free speech.",
      "This decision highlights ongoing discussions about content moderation, free speech, and the influence of social media platforms in shaping public discourse."
    ],
    "points": 180,
    "commentCount": 254,
    "retryCount": 0,
    "time": 1736252122
  }
]
