[
  {
    "id": 42254156,
    "title": "App that asks ‚Äòwhy?‚Äô every time you unlock your phone",
    "originLink": "https://play.google.com/store/apps/details?id=com.actureunlock&hl=en_US",
    "originBody": "google_logo Play Games Apps Movies & TV Books Kids search help_outline Intenty: check phone less Yaroslav Neznaradko In-app purchases 4.4 star 245 reviews 10K+ Downloads Everyone info Install Share Add to wishlist About this app arrow_forward Intenty helps you build a healthier relationship with your phone through gentle awareness prompts that appear right when you need them ‚Äì at unlock. No blockers, no limits, just mindful choices. üéØ Thoughtful nudges Choose from carefully crafted default nudges or create your own: * Intention - Set clear purposes for each phone session * Necessity - Question if you really need to use your phone now * Grounding - Return to the present moment * Posture - Remember your physical wellbeing * Minimalism - Stay focused on what truly matters ‚ú® Smart customisation * Create personal nudges with your own prompts * Control how often nudges appear with intensity settings * Set cooldown periods to prevent prompt fatigue * Export your data for personal insights üé® Minimalist design * Clean, distraction-free interface * Full-screen prompts for maximum impact * Thoughtfully crafted user experience üõ° Privacy first * Works 100% locally * No ads or tracking * No metrics or analytics collection * Your phone, your data, your control üí° Why it works Instead of blocking apps or setting arbitrary limits, Intenty helps you build awareness naturally. Each unlock becomes an opportunity to check in with yourself, making mindful decisions about your phone use throughout the day. Perfect for anyone looking to check their phone less and use their phone more mindfully. üåü Who it's for Perfect for anyone who wants to: * Reduce mindless phone-checking * Stay present and focused * Build better digital habits * Maintain productivity without restrictive blocks Would you be ready to transform your relationship with your phone? Download Intenty today and make every unlock count. üîê Note on Intenty permissions usage: Intenty might use quite permissive Android capabilities such as Display over other apps, Battery optimization disablement, or Accessibility service. All permissions are used exclusively for features to work locally on your device. Accessibility service is used exclusively to let you quickly turn off your phone's screen with a Lock button. The service is optional, disabled by default, and does not collect nor share any data. Updated on Nov 25, 2024 Productivity Data safety arrow_forward Safety starts with understanding how developers collect and share your data. Data privacy and security practices may vary based on your use, region, and age. The developer provided this information and may update it over time. No data shared with third parties Learn more about how developers declare sharing No data collected Learn more about how developers declare collection See details Ratings and reviews arrow_forward Ratings and reviews are verified info_outline phone_android Phone tablet_android Tablet 4.5 240 reviews 5 4 3 2 1 madesno more_vert March 22, 2021 Great app. It has helped me to quit social media, and to use the internet more responsibly in general. I can see the difference in my phone usage/productivity on days when I have accidentally turned actuflow mode off (my main issue with the app is that if I accidentally swipe away the unlock window without typing an intention or pressing dismiss, actuflow turns off) and it has helped me get more done when I am on my phone. Hopefully more of the bugs will be sorted out soon. 3 people found this review helpful Did you find this helpful? Yes No Yaroslav Neznaradko April 23, 2021 Thank you so much for your review! Brenna Horton more_vert May 7, 2022 this is sooo close to what i am looking for but not quite. i would love a feature that allows you to set an intention each time you open an app, not just unlock your phone. being able to toggle which apps (ie. social media, youtube) ask you for a prompt would be awesome. it's kind of annoying to be asked to set an intention for stuff that is already mindful and responsible like music, maps, or texting. 19 people found this review helpful Did you find this helpful? Yes No Camden Mac Leod more_vert November 21, 2020 A great app for staying on track and making sure you're not wasting time on your phone! It's easy to get on your phone and end up 30 minutes later scrolling through Instagram wondering why you were on your phone in the first place. The only thing I would change is a feature to disable the app from certain hours. For example, I unlock my phone every few minutes at the gym to see the next workout, so it would be nice if I could have it not ask me each time from say, 7am - 8am when I'm working out. 16 people found this review helpful Did you find this helpful? Yes No Yaroslav Neznaradko April 23, 2021 Thank you for your feedback. We are working on such a feature. See all reviews What's new Bugfix release üêû Fixing critical issues with subscription status üêû Fixing issues with nudges creation (app crashes and answers duplicates) flag Flag as inappropriate App support expand_more Google Play Play Pass Play Points Gift cards Redeem Refund policy Kids & family Parent Guide Family sharing Terms of Service Privacy About Google Play Developers Google Store United States (English)",
    "commentLink": "https://news.ycombinator.com/item?id=42254156",
    "commentBody": "App that asks ‚Äòwhy?‚Äô every time you unlock your phone (play.google.com)512 points by jarko27 10 hours agohidepastfavorite273 comments TeMPOraL 2 hours agoI installed this in the morning to give it a test drive, and after several hours, I learned the following: it's great when I reach for the phone as a distraction; it's a big annoyance otherwise. E.g. each time I want to change the currently playing song, what was muscle memory gets scrambled by the interruption. Or, when I'm taking a lot of photos (like on my daughter's kindergarten event today), I tend to keep the screen off in between, and rely on being able to turn it on and shoot a photo in less than two seconds, total. Guess how that got screwed up by this app. The app itself is great, and I'm still a believer in the concept of managing executive function issues by throwing obstacles in front of bad habits and known focus black holes. However, this experience made me discover the third class of phone activity, next to \"distraction\" and \"work\" - quick, intermittent, on-the-fly use, the kind you ideally don't think much about. This class does not distract you... unless someone adds friction to it. I just saw the app has \"every N unlocks\" option, I'll try it out and see if this helps with the \"third class\". reply jarko27 28 minutes agoparentThanks for giving it a test drive! I'm thinking also about adding an option to have like 50% chance of a popup or a 75% chance, so it's less predictable. I first made it as every 2nd, 3d and so on, but maybe adding a randomness to it will be better? WDYT? reply TeMPOraL 6 minutes agorootparentFor my use case, randomness would make it even worse. For muscle memory, consistency is key. I don't know what the solution is - ideally, the app would not interrupt such quick actions like unlocking to take a photo or switch the song, but in practice, it can't exactly guess what I'm going to do before I do it. I was thinking about maybe \"unlock and don't show the popup for the next 5 minutes\", but then I already know that one of these days, I'll activate it for \"one quick check of Instagram\" (or HN), defeating the purpose of the application. Sorry I can't be more helpful. I've been mulling this problem (selective blocking in dual-purpose apps/sites) in my mind for a long time now, but I haven't found any solution so far. reply bornfreddy 2 hours agoparentprevMaybe the app should kick in only if you start using one of the \"bad\" apps, like a browser or a social network app? Being in the way when I want to snap a quick photo doesn't sound nice. reply gen220 55 minutes agorootparentWhat I did (helped me eventually delete them) was offload the \"bad\" apps on my phone so, if I wanted to access them, I'd have to wait for them to re-download. This is an iOS feature where the pointer to the app and the local data remains, but the app bundle itself is deleted. I think it's primary use case is to manage scarce disk space. It forced me to reckon with the fact that tapping on these apps is often a system 1 instinct. The forced delay to reinstall the app is an escape hatch into system 2 thinking, a mode in which I normally realize I don't even want to use the app, I'm just bored. And then I'd pick up a book or use my newspaper-reader-app (i.e. a more intent/system 2-driven choice). Off-loading apps or even just removing them from the home screen is really helpful. It gives your system 2 brain an opportunity to mutate your environment to make system 1 processes lead to more fruitful outcomes. For the same reason, I clear my browser history every month or so and avoid bookmarking certain sites like hn or reddit. reply koevet 2 hours agorootparentprevFor this use case, I use \"IChooseTo\" https://play.google.com/store/apps/details?id=com.appsofuse.... reply throwawayk7h 1 hour agorootparentThis looks like it's based on a timer, and prevents you from using the app if you use it for, say, too long. Is that right? I have legitimate longform uses of my browser app as well as bad ones. reply jkukul 1 hour agorootparentprevI use iOS's built in Screen Time settings. For \"bad\" apps (Reddit, TikTok, etc) and \"bad\" websites (\"hackernews\", etc) I set a daily time limit of, let's say, 15 minutes. I configure a random password for Screen Time so that it's a real hassle to circumvent the daily limit when I get over it. reply hackernewds 1 hour agorootparentprevthis is 100% what I want, and I'd gladly pay $10/month for this reply lubujackson 27 minutes agoparentprevBetter solution: add in increasing delay before opening a time waster, increasing 1 second between each open over the course of the day. Openning Reddit for the 15th time today? 15 second wait (or longer). reply andai 1 hour agoparentprevThis is solved by having dedicated devices for camera and music player! (At least for these two examples, which are also my top non-distraction / non-social phone usage.) I don't have those yet but I wish I did! I was just thinking back to how cool the iPod was back in the day. (The one before touchscreens!) (I was also thinking how cool it would be if it had the iPod's UI but Rockbox's (and every other mp3 player in human history) support for just putting folders full of files on it... but I guess I'll keep dreaming!) reply cardanome 11 minutes agorootparentI actually went full old-school and got an portable cd-player. This has the side effect of me listening to music more intentionally and not wasting time selecting tracks and skipping around. Listening to a full album is great, something I rarely did before. And physically owning music feels great. Sure, it is less practical for traveling but it mostly sits on my desk to help me get through work. And CD's having a fixed run length helps me to take breaks so my tinnitus does not get worse. reply ar_lan 29 minutes agorootparentprevThat is a solution, but not an ideal one for many (most?). One of the great innovations of the smartphone is that I have all 3 devices in one small form factor, so I don't need to carry/travel with the bulk of many. reply TeMPOraL 1 hour agorootparentprevThat's fair. I miss MP3 players and even feature phones - all of them could be operated without looking at them! Alas, ever since Apple showed it's Courage‚Ñ¢ by ditching the audio jack, Bluetooth headphones became ubiquitous (doubly so thanks to AirPods and alternatives). They're nice and all, but they also have mikes, so you want to use them for calling and voice messaging too, and then you can also put notifications on them, ... with Bluetooth device switching being what it is, this complements and reinforces smartphone's role as single device for everything. EDIT: I wonder if it's possible to have some kind of mixer wearable that would accept wireless audio streams (both in \"music\" and \"headset\" modes) from multiple devices, mix them together, and route to a single set of wireless headphones. That would solve a lot of the issues I have with wireless audio in practice. reply ar_lan 31 minutes agoparentprevThis sounds like a good case for an allowlist for certain applications - Camera, Spotify, Notes, etc. reply iandanforth 1 hour agoparentprevRe: The photos case: I have the camera app bound to a double click of my power button. I find it to be incredibly useful to have a way to immediately open my camera and Intenty doesn't override that flow. reply TeMPOraL 1 hour agorootparentHah, I used to do that too, however I changed it so double-press of the side button toggles the flashlight instead. I find this to have much better ROI. For camera, turning the screen off while camera app is open means I can just press the power button and slide up, and I'm back in camera app (unless Intenty interferes). For flashlight, having a quick key (that works even when the phone is locked) is a qualitative change - I use the phone flashlight much more often, now that I can casually turn it on and off with zero effort, like a traditional torch. There are actually two major use cases I have for that daily: - In autumn/winter, by the time I pick my kids up from the kindergarten, it's already dark. There's a stretch of pavement that's pitch dark, so I just casually light it up as we walk over it. (That was the driver behind me changing the button mapping from camera to flashlight; having done that, I now instinctively turn the flashlight on and off as I walk, lighting up dark spots.) - Have you ever tried to read something from a phone while walking at night? It's a big problem - the screen pretty much blinds you, unless you turn the brightness down to minimum. You can't read and monitor ground under your feet at the same time. However, if you also turn on the flashlight, the brightness of the screen and the light reflecting off the ground are similar, so reading becomes comfortable and you regain awareness of terrain. I figured out that trick long ago, first with Kindle (Paperwhite) - I'd put my phone against the back of the Kindle, turn the backlight on the reader, and the flashlight on the phone. But it works even better for reading from the phone itself. reply echelon 2 hours agoparentprevThis is where an OS-based agent would help. If it semantically understood the tasks we're trying to accomplish, it could filter the cases we care about. I'm even more excited about browser or OS agents being able to unilaterally scrub the web of all advertisements, spam, polarized toxicity, etc. Forget adblock - I can effectively block all the bad things Google, Meta, Twitter, etc. do and their army of PMs won't be able to stop me. This tech is going to rip the advertiser and algorithmic madness out of the internet and make it serve me and only me. reply hackernewds 59 minutes agorootparentneither Apple or Google will ever develop this given that their core Business depends on users using their phones often reply MortyWaves 3 hours agoprevNeeds an option for ‚Äúmy employer turned on shitty Microsoft ten-billion-factor auth settings‚Äù. To login to my work Microsoft account requires a passcode and then three face scans. reply autoexec 1 hour agoparentI had an employer want that too, but we protested. Basically making that the case that they'd need to provide us with phones so that we don't have to install invasive apps on our personal devices. We ended up getting tiny hardware tokens that go on a key ring and couldn't access GPS, cameras, microphones, sensor data, network, etc even if it wanted to. reply alexvitkov 59 minutes agoparentprevThis has always boggled my mind - If you don't trust me to pick a decent password and maintain my own machine, why in God's name would you trust me to write code or deploy/maintain company infrastructure? reply ryanmcbride 30 minutes agorootparentThey _don't_ trust you to do that stuff. Not unilaterally at least. In a healthy system you generally aren't able to change anything without sign off from multiple other people. reply tecleandor 55 minutes agorootparentprevNah, it's not lack of trust, it's just compliance and plausible deniability. reply poincaredisk 1 hour agoparentprevBut that's ok your work phone right? At least I hope you didn't agree to have it installed on your private phone. For work phone I guess a good strategy is to avoid installing anything non-work related, so the temptation to use it for anything is low. reply cglong 1 hour agorootparentNot GP, but I'm okay installing that stuff on my personal phone because it's isolated via Android Work Profile. reply autoexec 1 hour agorootparentHow is that keeping Microsoft from accessing your GPS, sensor data, wifi, camera/microphone etc? Sure, they can't get at SMS or your other apps and your work won't have access to your entire device but it means MS can still access your location (using GPS and nearby bluetooth/wifi), record audio/video, read/control sensors (accelerometer, proximity, gravity, temperature, pressure, magnetic field etc), have full network access, etc and can record and collect that data whenever they feel like it for the most part. reply cglong 32 minutes agorootparentThat's true with a separate work phone too right? And once I turn off the AWP for the day, all of that stops. reply johnisgood 1 hour agorootparentprevYou may want to try \"Shelter\" (https://f-droid.org/packages/net.typeblog.shelter/). reply encom 54 minutes agorootparentprevNo way I'm doing anything work related on any of my personal devices. I have a separate work phone. I turn it off at the end of the work day, and leave it at work. I used to answer emails from bosses and managers while at home (at a previous employer), but it gets out of hand quickly and then they expect you to do it. Never again. Set boundaries immediately. At 15:00 I'm gone. reply cglong 30 minutes agorootparentLeaving it at work goes one step further than my flow. I have AWP configured to automatically turn off at the end of the workday, so I become unavailable after that. There's always the possibility I can turn it back on after hours, but that extra step works well enough as a deterrent for me :) reply throwawayk7h 1 hour agoparentprevYou can usually do OTP from your pc directly, just install an OTP application on your pc like keepassxc reply CryptoBanker 1 hour agorootparentDoesn‚Äôt work if your work uses SSO like Okta reply deskr 1 hour agorootparentprevSecurity dept. would like to have a word. reply compootr 1 hour agorootparentsecurity theater dept. has entered the chat reply retSava 6 hours agoprevGreat! Apps like these are sorely needed. My feedback would be, apart from what others are saying about sub vs one-time purchase, to look at what Leechblock firefox extension is doing. The key point is to make it harder (but not impossible) for me to use the phone. A \"Do you need this?\" is a great start, but since I can easily sneak by, I will soon do that. Even if I click \"1 minute\" to get a reminder, that should not be a simple notification, but back to the large big screen covering things. What LB does is genius. You can enable a barrier so that if you reeeeeeally need to, you can get around, but it's annoying and time consuming, and thus the quick loop of \"pick up phone and get stuck\" is broken. The barrier in LB can be to type a (long) passphrase, or my favorite: a 64-char random string which cannot be copy-pasted. You need to manually look at 2-3 chars at a time and replicate the whole thing. Very effective. But again, also the snap back to reality thing. If I keep using it, throw up a big overlay with a good question \"Is your attention well spent?\" for example. Make me wait before I can continue. reply jarko27 6 hours agoparentAdvanced reminders are going to be a thing for the next big release. I agree that one problem is to pass the unlock, but staying on track with your intention is a different story. One periodical notification with static text can in theory fix that, but the chances are low in comparison to the full-screen pop-up. I intentionally focused on the unlock procedure first. For now, you can combine it with other apps like minimalistic launchers and apps that pop up after the app opens. But eventually, improving the reminder experience can make the solution more complete, I agree. About typing \"captcha\" or random characters. I think it's just a different type of nudge. Another can be a small mini-game to play like catching a moving object. I'm going to consider adding different types of nudges to the app. Thanks for the suggestion. reply youainti 2 hours agorootparentJust thinking about this, there might be room for a home launcher that helps manage attention this way. Probably more work than you are thinking of doing though. reply guitarlimeo 6 hours agoparentprevI tried LeechBlock for a while and had that 64-char random string passphrase thing on. Turns out I became really quick at typing those 64 characters to get my dopamine fix. reply artisanspam 5 hours agorootparentYou can make it up to 128 characters. That's impressive that you are able to type a random string of nonsense so fast. My hack was to take a picture on my phone, have Apple's image recognition copy the string to my iCloud clipboard, and I'd paste it on my mac. It's too easy to defeat the purpose of these things if you're even slightly driven. reply kibwen 2 hours agorootparent> It's too easy to defeat the purpose of these things if you're even slightly driven. Things like the OP and LeechBlock are tools for people who have already mostly conquered their addiction, to help keep them from relapsing. On their own, they're not sufficient to turn an addict into a non-addict. reply darkwater 3 hours agorootparentprevMay I ask you why you did install it in the first place, if you then hack your way around it? Maybe the goal was to motivate you to find a hack anyway :) reply jasfi 6 hours agorootparentprevThe same thing will happen with this app. The user will select any answer to just do what they wanted to do. reply retSava 6 hours agorootparentprevHahaha. Yeah. I started using a second browser... reply fny 4 hours agoparentprevMight I recommend charging? You get X for free, and then you pay a fee that grows. reply mdaniel 2 hours agorootparentAnd the fee gets deposited into a high-yield savings account of your choice, so you're paying yourself (it reminds me of those sites that allow you to make a \"bet\" to your friends that you'll (stop smoking/exercise more/lose weight/whatever) and if you don't do it then you have to pay your friends reply mihaaly 4 hours agoparentprev> The key point is to make it harder (but not impossible) for me to use the phone. All apps, and actually the phone manfacturers themselves make phones harder to use through user hostile patterns. Mandatory updates, re-logon, TOC confirmations, cookies, self promotions in the face, adverts, warnings, spray of notifications on marginal things, answering questions to important (or not) questions, selecting important (or not) huge amount of settings, suggestions (actually another self promotion mostly), update informations, etc. all make the phones as difficult to use as much those helps, or even more. For insane amount of money. Problem relocation machines they are. reply space_oddity 4 hours agoparentprevI think you‚Äôve nailed some really key points about breaking the \"quick loop\" of mindless phone use reply tasn 3 hours agoprevLove it! Reminds me of an app my brother and I built 10 years ago (time flies!). It's no longer on Google Play because of the maintenance burden of keeping it there, but here's a page with some screenshots: https://apkpure.com/spinach-motivation-lock-screen/com.tengu... The idea was that if you're unlocking your screen, you should at least: (1) reinforce a mantra, or (2) force yourself to acknowledge you shouldn't be unlocking the phone. Happy to share notes if you think that would be helpful. reply jarko27 15 minutes agoparentWow. It's so cool to see such a project. I even remember in 2019 finding an app that was using a popup after unlock to learn words of a foreign language, unfortunately, it closed and I cannot recall the name. I would be happy to see the notes. reply mdaniel 2 hours agoparentprevUp to you, but if the app has (or could have) an OSI license, you could submit a PR to f-droid and the app could live on. They don't care if you ask for donations, so it could even resurrect a bit of revenue reply tasn 2 hours agorootparentYeah, I have a few apps on f-droid, maybe worth doing! reply xyst 6 minutes agoprevthis is the type of tool a C-level executive would mandate to be installed on your devices. Instead of ‚Äúwhy‚Äù, it would send out notifications to a central server with a data pipeline into genAI which can generate reports on productivity. Employee not complying? Bye bye equity, severance Employee opening device too much? Fired. Of course C-level executives would get exempt from policy because ‚Äúrules for thee but not for me‚Äù attitude. As for personal usage, I would much rather configure ‚ÄúFocus‚Äù mode to block certain apps from opening. Rather than rely on this. I would install this on phones of annoying people though for shits and giggles reply mrkramer 1 hour agoprevEven more cooler idea would be that the app restricts you to only communication apps when you choose \"communication\" intent or when you choose \"boredom\" it prompts you to enjoy IRL activities and tells you to leave your device aside. That would make it even more interactive and fun. reply namukang 3 hours agoprevFor anyone looking for something similar for their desktop browser, try out Intention: https://getintention.com Show HN post from 2020: https://news.ycombinator.com/item?id=22936742 reply flaviomartins 4 hours agoprevI use this on iOS https://one-sec.app reply beala 3 hours agoparentThis app interrupts usage of the target app by setting up an automation (in the native Shortcuts app) that triggers when the target app is launched.[1] This means you can skip the app entirely and try to set up your own poor man's version. I fiddled around a bit and it's possible to set up an automation that automatically exits back to the home screen after some pause, or displays a notification to try to nudge you out of the app. This is not as good as the app but it is free. Also, without the Safari extension, I don't think websites can be blocked. My own strategy is to simply use pi-hole to block time-wasting websites entirely. It's kind of a sledgehammer, but it works for me. 1: https://tutorials.one-sec.app/setup-ios reply jbobrow 2 hours agoparentprevSame. Installed for ~ 1 year, deleted after my muscle memory adapted. It was an inconvenience for some of the apps that I would actually need access to some of the time, but then again, it is a less obvious inconvenience when excessive amounts of time were spent in apps I showed up to do one thing in... All that to say. I think these tools are great, and ideally they assist us in shaping our behaviors to match our intent. A little more system 2 than system 1 thinking. reply hackernewds 57 minutes agoparentprevI dislike the amount of access to your entire OSN screen you have to give to these apps. is there an offline or open source or OS based solution? reply wonger_ 4 hours agoparentprevI used it on Android for a bit. I liked how the screen animation naturally made me take a deep breath, and I liked seeing how many times I've opened an app so far in the day. Unfortunately the free tier is quite limited - you can only enable it for one app, and you can't customize the duration of the blocking animation. reply princevegeta89 3 hours agoparentprevApps like this are a godsend. Putting away all the social media aside (where 95% of the content is fake/useless anyway), in reality there should really be no use for mobile phones besides using it for calls/music and some important things when you can't get to your laptop/desktop. I've realized recently that it takes at least 3 times more work and time to do things on a smartphone than to do the same things on a laptop. This holds true for messaging apps where we are so limited by the typing speed and error-prone nature of composing messages on a smartphone, and the lack of good multitasking options like on a desktop interface. I have more time in my life now, more than ever, after I started to avoid using my phone for things wherever I can. reply al_borland 4 hours agoparentprevI usually just delete the app if it's dominating my time on the phone or drawing me to it. reply edm0nd 2 hours agorootparentI went another route. I bought a second phone. I have my regular main phone that I use M-F for work and personal. then I bought a second phone and installed GrapheneOS on it. I use this phone when I go out or doing anything on the weekends. I only have a few contacts on it and only 2 apps that I use that are my banking app and Signal. Keeps all the distractions away from me. I bought a used unlocked Pixel 7 Pro off eBay for $250 so it wasnt the cheapest route but sure makes it really easy. reply cnity 3 hours agorootparentprevThis is the way. Uninstalling instagram, facebook, youtube, reddit, and tiktok genuinely worked for me. Otherwise it's like trying to diet when your pantry is fully stocked with every possible ultra-satisfying snack food under the sun. reply hackernewds 56 minutes agorootparentI deleted the apps and then also got the mobile web/ native apps versions. it also seems the algorithm is very hamstrung given that the browser versions cannot access all of those phone permissions. now it makes it think what all data are your apps even collecting? reply rattray 4 hours agoparentprevLooks interesting. Any tips for using it effectively? What's it been most helpful with? reply epanchin 3 hours agorootparentSurprisingly I find it most useful on my email app. I pick up my phone to check email a lot, then go onto other useless apps. By catching email usage, I also stop myself going on the rest. reply fransjorden 9 hours agoprevGreat app! Love the design and thoughts behind it. Few comments: - isn't it possible to select multiple intentions? I've tried but when I turn on one, another one turns off. - for apps like these I'm really missing a more expensive lifetime subscription. I'm okay with paying some more upfront if I don't have to pay a periodical fee. Anyway, really nice work! reply jarko27 9 hours agoparentThanks for giving it a try! > - isn't it possible to select multiple intentions? I've tried but when I turn on one, another one turns off. Here is the place where I made a UX mistake. I implemented nudges in a similar way as \"modes\" on iOS or routines on Samsung phones. You can enable one at a time. If you want to customise the content you see, you have to customise it inside nudge, not by enabling another one. I didn't make any UX tests before releasing this and I see a lot of confusion here. Apologise for that. > for apps like these I'm really missing a more expensive lifetime subscription. I'm okay with paying some more upfront if I don't have to pay a periodical fee. That's another miscalculation I made :) But I already have plans to replace the subscription with one-time purchase. Again sorry for the inconvenience. Again, thanks for a try reply vr46 9 hours agoprevMy buddy has a wallpaper on his phone that says, in large letters, \"Do I really to be picking up my phone right now?\" Done and done. reply frereubu 8 hours agoparentI prefer this method too, as it helps me develop my self-control. (I have \"œÑ·ø∂ŒΩ ·ºêœÜ·æΩ ·º°Œº·øñŒΩ Œ∫Œ±·Ω∂ Œø·ΩêŒ∫ ·ºêœÜ·æΩ ·º°Œº·øñŒΩ\", which is from Epictetus and means \"things that are up to us and things that are not up to us\" as a reminder that I can exert control over my phone use). reply kukkeliskuu 8 hours agoparentprevI made one with large text ‚ÄùWhy?‚Äù reply rvnx 9 hours agoparentprev(edited) reply baxtr 8 hours agorootparentHe‚Äôd probably be on X \"creating content\" reply andy_ppp 9 hours agoprevSome people wrap their phone in an elastic band or there‚Äôs always Opal if you want more fine grained control: https://apps.apple.com/gb/app/opal-screen-time-control/id149... reply psteinweber 54 minutes agoparentOpal is incredibly helpful for me. Exactly the right amount of control and annoyance to get me off social media. reply jarko27 6 hours agoparentprevPhysical barrier on the phone is probably the best way to tackle with such things, but that's not what always available or convenient. I liked Opal, but with Intenty I tried to create an alternative way without blockers or limits. For some reason, app blockers and time limits are very frustrating for me and rarely work. That was one of the primary motivations for the app creation. While I admit that for the majority setting proper limits on certain apps will work. reply Y_Y 10 hours agoprevCool idea. Amazingly they've found a way to put \"in-app purchases\" though. This app could just be an image set as your lock screen background. I've found a good way to discourage mindless phone staring is to set the display to monochrome (e.g. through colorblind emulation). The decreased visual stimulation seems to have an effect on me, at least until I want to see a photo or video in colour and go back to normal. reply jarko27 9 hours agoparentAllow me to clarify about \"in-app purchases\". The \"in-app purchases\" are for small complementary features, like making the screen appear on a schedule, making it impossible to skip the screen, and adding a lock button to lock the screen. Those features aren't essential for the app to function. > This app could just be an image set as your lock screen background. Well, yes and no. In the app, you can interact with the prompts. There is a history of your itneraction. You can export it and then analyze it if needed. > I've found a good way to discourage mindless phone staring is to set the display to monochrome (e.g. through colorblind emulation). The decreased visual stimulation seems to have an effect on me, at least until I want to see a photo or video in colour and go back to normal. +1 here. I have always had this setting on closer to bedtime. reply mzhaase 9 hours agorootparentThe point I think was more a critique on the fact that everyone now tries to extract profit with everything, even the simplest of apps. reply cowsandmilk 8 hours agorootparentThe point is, everyone believes all apps should be free when this developer spent time building, testing, and iterating to come out with quite the useful app. And the developer respects users, so they chose to monetize in a way that doesn‚Äôt collect our data or shove ads in our faces. reply madeofpalk 8 hours agorootparentThe first thing OP says is \"Cool idea - don't deserve to get paid for it though\". reply Y_Y 2 hours agorootparentI think you'll find that's not quite true. reply ltadeut 8 hours agorootparentprevwhy shouldn't they? they had to take the time to make the app and get it up on the App Store. it's totally fair to charge for work you've done. the fact it's simple is irrelevant. what matters is the value it brings to the user. reply matkv 8 hours agorootparentIt is totally fair to charge for work you've done - but then again, in my opinion, not everything needs to be built with some profit in mind (not talking about this app in particular now). I think it's really refreshing to find an app that doesn't lock any features behind a paywall or makes using it more cumbersome unless you pay. I'm mostly okay with one-time payments though. Just because you invested some time into making a project doesn't mean that you absolutely need to make some money to make it \"worth\" it. Hell, most open-source software is built on free/voluntary labor. reply agubelu 8 hours agorootparent> not everything needs to be built with some profit in mind (not talking about this app in particular now). I agree, and I make many projects for fun and find it rewarding when others use what I've built. But that is a decision that I make myself, for my own work. I never feel like I have the right to tell others whether they should build something with profit in mind or not. reply matkv 8 hours agorootparentI agree - it's definitely OP's decision and a valid one. reply mavamaarten 8 hours agorootparentprevI understand the sentiment from a user's perspective, I really do. I have been totally burned out by having to maintain all my free apps in the Play Store though, lately. Even a simple non-internet-using app needs an update every year and needs to comply with new bullshit policies every few months. It has totally changed my opinion on free vs paid apps. I still despise subscription models, but I absolutely understand that there's just no free apps out there anymore. It just costs too much of my time to keep doing it for free. reply mongol 7 hours agorootparentAgree. I had a free app with 100000 downloads, no ads and 4.5 rating on Play store, it is no longer there because I got fed up with Google's nagging. If I will do free things going forward, I will do them outside closed ecosystems. reply throwaway290 4 hours agorootparentIt is economically better for google if your free app is gone and someone makes a paid app or an app with ads... reply Y_Y 2 hours agorootparentInteresting point. I think that the availability of good free apps on Play Store has a positive effect on the market for Android phones in general. I know it factors into people's decision of phone religion that apps are more likely to charge on Apple's store (even sometimes for an app which is free on Android). All that said, F-droid is the only one I'll ever love. reply jventura 7 hours agorootparentprevAlso agree, and would also include paid apps as well! I had a paid app which was a one time payment and was not doing anything special regarding permissions (no internet, nothing like that), but since it wasn't was bringing much revenue (some 3$-4$ per year), I let the Play Store remove it automatically. I couldn't justify adding the absurd data policies (since I wasn't using any user data) and the cost of updating it regularly. Sorry for my 100 users, that cannot reinstall the app anymore! reply matkv 7 hours agorootparentprevI've actually been talking about the developer's perspective as well - I have a couple of personal projects that I've invested quite a bit of time into but I still don't feel the need to try to find a way to monetize them. I can definitely see your point though. Maybe an option would be open sourcing your app? (considering it's already free anyway) - that way you could maybe find some contributors to make it easier to keep up with everything. reply Apocryphon 6 hours agorootparentnext [2 more] [flagged] account42 6 hours agorootparentWho are you to tell others what they are allowed to think and talk about? reply YetAnotherNick 7 hours agorootparentprev> not everything needs to be built with some profit in mind You didn't say this earlier. You said this app doesn't need to be developed with profit in mind. reply matkv 7 hours agorootparentI'm not the same user as the parent comment. reply akkad33 8 hours agorootparentprevIt's time and effort. If you're not willing to pay you're saying it has no value. I prefer a small upfront fee to seeing in app purchases though reply robin_reala 8 hours agorootparentThat‚Äôs not true: not all value is monetary. The results of my hobby are distributed for free, but I gain value from the creation process for myself. reply MMAesawy 8 hours agorootparentprevHow would you suggest to compensate devs for developing and maintaining such apps? Personally I would much prefer that developers lock poweruser features behind a paywall rather than plaster ugly ads all over the place. Making it a paid app works too, but likely 95% of the potential userbase would not try the app if they had to reach for their wallets first. reply oneeyedpigeon 7 hours agorootparentUBI. (I would leave the comment at that, but it would probably come across as a bit facetious and would fail any 'low-effort' test. But I genuinely mean it: remove the necessity to obtain a certain amount of money every month, and all of a sudden, people would be able to create, share, and enjoy for free. reply Timwi 7 hours agorootparentprev> How would you suggest to compensate devs for developing and maintaining such apps? As a developer, I feel more than sufficiently compensated by seeing people use and enjoy my work and thanking me. Getting featured on Hacker News would make my day; nay, year. I just need to be able to eat and use a computer. I shouldn't have to prove myself valuable just to be allowed to live. I think everybody, regardless of what they do, deserve a livable basic income. reply endorphine 8 hours agorootparentprevCritiquing the players and not the game misses the forest for the trees. This is the system we live in. reply ryandrake 8 hours agorootparentYou're allowed to critique both. \"The system\" isn't handed down from god. It's just a set of choices made by people. reply Timwi 7 hours agorootparentYes, and one of those choices made by people is that if you don't make money, you deserve to starve. reply jamalaramala 7 hours agorootparentprevGreat idea for a little app.Amazingly they've found a way to put \"in-app purchases\" though. I've been so happy slowly going through my phone and removing every single app on my phone that has either ads or in-app purchases. I don't miss a single one. reply icetank 7 hours agorootparentHacker news has ads in the form of job positions. Do you also consider not using Hacker news anymore? reply everdrive 6 hours agorootparentMy sentence, in a very loose sense is an advertisement for my ideas. I think the concept can be stretched too far. reply monooso 7 hours agorootparentprevThat's a pretty loose definition of an advertisement, particularly in the context of this conversation. reply PittleyDunkin 5 hours agorootparentprevIf I sense that these so-called ads are lowering my quality of life‚Äîabsolutely. reply oneeyedpigeon 7 hours agorootparentprevNot all ads are equal. I am willing to bet that every single app they were referring to had much more egregious advertising than HN does. reply GrinningFool 4 hours agorootparentprevYour comment comes across as disingenuous. I think by this point in time, most people who are taking an active effort to remove advertising from their lives are well aware that the concern with \"ads\" isn't primarily about the requirement to see ads - it's the privacy-consuming infrastructure behind them. reply Y_Y 8 minutes agorootparentNot to mention the attention-stealing flashing lights and popping up over the thing you want to see and all the other ways to make you think about something against your will. reply andreicap 7 hours agoparentprevI do the same with iOS automations - disable monochrome (and orientation lock) for photos and camera apps, and enable it back once closed. The benefit is that it re-enables monochrome mode after I might disable it manually. reply space_oddity 6 hours agoparentprevEither way, it‚Äôs all about finding what clicks for you! reply siva7 8 hours agoparentprevBest of all it saves battery reply HPsquared 8 hours agoparentprevI have greyscale set to activate in the evening to wind down for bed. reply blahlabs 7 hours agorootparentCould you share how you achieved activating greyscale automatically? Was it Android or iOS? I would love to be able to do this but couldn't find a way on GrapheneOS. reply chris_pie 7 hours agorootparentLatest Android has that built-in as a \"Night Mode\". You can also set a schedule or have it enable while charging reply HPsquared 4 hours agorootparentprevIt's a Samsung, Android phone. I used \"Modes and Routines\" which allows to set greyscale (and silent mode etc.) and automate triggers (such as time of day) to activate a \"mode\". reply newswasboring 7 hours agoparentprev> This app could just be an image set as your lock screen background. https://news.ycombinator.com/item?id=9224 reply guax 7 hours agoprevInstalled about 30 minutes ago, it already made me reconsider using the phone 3x. It is indeed effective while you're engaging with it. Hope it continues like this for long term. reply jarko27 7 hours agoparentFor the long term, I recommend changing the prompts from time to time and adjusting intensity and cooldown settings. Sometimes even turning it off, so you are not getting used to the screen. reply hshshshshsh 7 hours agoparentprevIt will not last much. The brain will figure out the reconsideration is wasted mental processing and just proceed to open phone by clicking tool. reply myhf 7 minutes agoprevWhy? reply nosduhz 2 hours agoprevOn iOS, I've tried nearly everything, but here's what's lasted more than a few months. 1. A physical blocker like Brick (getbrick.app) and/or a Kitchen Timer Safe (KSafe). 2. One Sec app I'll occasionally leave my phone at home and use only an Apple Watch with LTE. These are the only flows that haven't become frustrating over time and have worked to cut screen time and addicted apps (or altogether). reply chatmasta 1 hour agoparentOne Sec broke my addiction to doomscrolling apps. The feature that makes you look at your face for two seconds when you open the app, while telling you that you last opened it a minute ago, is both hilarious and effective. reply hackernewds 55 minutes agorootparenthas anyone dug into whether one sec is safe (private offline on device as it states)? it requires access to accessibility settings, which means that it could be reading all of you cryptocurrency apps, passwords as well as two-factor authentication reply chatmasta 4 minutes agorootparentI just used it to create shortcuts. I don‚Äôt remember needing to grant any further accessibility settings, but I don‚Äôt currently have it installed. reply jeofken 9 hours agoprevFor me the only really useful intervention was getting a black and white e-ink Android smartphone. I started to read a book per month and my short video watching time was decimated. I got the Bigme Hibreak which isn‚Äôt the worst, but lacks recent android versions. Gives me hours of my life back every day, compared to the phone addiction I experience with my lcd colour screen smartphone reply alexey-salmin 4 hours agoparentI'm surprised there are so few on the market. The reason I gave up on Nokia in 2020 was a handful of apps: taxi, maps, messengers. All of that would perfectly work on e-ink. Instead I got a Pixel and after four years I have attention span of a squirrel. Really have to do something about it, will try grayscale for now. reply jarko27 5 hours agoparentprevAs an experiment, I wanted to try something similar, but more extreme maybe since it's not Android AFAIK https://www.thelightphone.com. Also I wonder if my app is working nicely on an e-ink smartphone, very interesting. reply greekanalyst 53 minutes agoprevThe app I always knew I needed but never thought I wanted too. reply maelito 9 hours agoprevI need this ! I can also recommend Stretchly for the computer https://github.com/hovancik/stretchly. Forces me to stand up and look further / go grab some chicory. reply retSava 6 hours agoparentYes! I use this for both Win and Ubuntu. Works great. reply mcflubbins 1 hour agoprevI can answer this myself. 95% of the time its because I need to do some form of MFA (totp app, sms, email, duo, etc) reply Havoc 1 hour agoprevA counter in a corner or similar might be less disruptive and still keep you mindful. Bit like a step counter reply p1necone 9 hours agoprevI feel like we're far too obsessed with the \"nobility\" of stuff we do for fun. Watch YouTube shorts, scroll reddit, whatever. It's only \"addictive\" because it's fun, it's no more pointless than anything else you might do for fun. What are you really achieving by using this app? Do you have an unhealthy relationship with your phone, or are you just arbitrarily ranking it low on the \"worthiness\" of random shit you might choose to do to kill some time. reply jarko27 8 hours agoparentWhat I'm trying to achieve here is to make more conscious choices. If I want to scroll Reddit, I would like to make a deliberate decision rather than doing it habitually in an \"uncontrolled\" way, just immediately out of boredom. The app intervenes in this unconscious phone pickup habit loop and prompts me to reconsider this. I'm not deleting social media apps from the device and I believe we shouldn't. I'm just trying to adjust the way how I reach them. reply antihero 7 hours agorootparentI like the idea and I think it will be good in the short term but eventually your brain will just gloss over it I think. reply jraph 9 hours agoparentprevA lot of people doing the scrolling thing seem not satisfied with it. Listening to them, it seems they feel like it not only kills their time funnily, it actually goes beyond, and kills their time more they wanted will still not being so enjoyable. So they are trying to find hacks to counter their habits. I can relate. Sometimes I'm on HN a bit more longer than ideal. But that's not a big issue for me and it's not very often so I'm not finding a fix for this. reply guax 7 hours agoparentprevYou might have a great relationship with time and your phone, which is great. Not all of us have that. If/when my mental health is not on its best legs tools like this might prevent it from going deeper. Its VERY easy for me to do 30 minutes of mindless youtube shorts watching instead of doing something I was supposed to do or even wanted to do. ADHD brain is a bitch. \"Gimmicks\" help to trigger a intentional conscious response to break out of a pattern. reply vundercind 3 hours agoparentprevWhen I don't have my phone's distractions, I read books instead, or play music, or maybe do a few pushups. Basically anything I in-fact do when my phone's not around, is better than the phone. The only thing I do without the phone that's almost as low-value is video gaming (gee, more electronics...) reply asddubs 9 hours agoparentprevi don't have phone problems, but I do think there is a non-arbitrary worthiness scale to things I do for fun. In the long term, I think I benefit more and feel better about myself for spending time learning something or creating something than playing video games or doing something passive. reply fergonco 8 hours agoparentprev> It's only \"addictive\" because it's fun This is not true. Almost everything in mobile phones exploit human brain biases to keep us hooked. It's about regaining control of what you want to use your time for. reply keybored 1 hour agoparentprevThese critiques/nudges/reminders about screen time are as much worth as a YouTube short: a dime a dozen. Completely shallow, thoughtless, vapid and a waste of time.[1] Anyone can make the point that people are staring at their phones. That they spend time on social media. It‚Äôs the equivalent of getting up on a soapbox and exclaiming that we live in a society. (Except everyone is on their phone and won‚Äôt give you any attention) Why? Why are you on your phone? Well, have you, the critiquer of the supposed malaise given any real thought to that? Or do you have no insights to offer, nothing more than a rhetorical one-word question to ask, nothing that penetrates the surface of the supposed problem? Have you, OP? At least propose a theory. Like: maybe people are overstimulated and have choice fatigue. Then what the hell does yet another automated nagger help? One more reminder that you should drink a cup of coffeine-free green tea and smile at a stranger? Nothing was uncovered. Nothing was gained. [1] This is not true. Making YouTube shorts takes some editing skills. reply exe34 9 hours agoparentprevit's currently very cool to announce to everybody how little time you spend on your phone, it's like the new \"I'm vegan\" or \"I use arch btw\". people don't realise how addiction works - see the Vietnam veterans case: https://jamesclear.com/heroin-habits we have bigger (social) problems that's causing the phone addiction: if it wasn't a phone, it would be video games, TV or alcohol or something else. reply exitb 7 hours agorootparentEven if the addition is really driven by the environment, rather than its subject itself, can individuals actually solve the underlying social problem? Can they do so in a way that's actually scalable to a significant portion of the population? If your work, or lack of money, or your kids school, or your parents health are causing you stress, most often you can't simply \"change your environment\" to a less stressful one. reply p1necone 8 hours agorootparentprevI swear comments on posts like this one always read like some religious support group for people that think sex outside of the context of marriage is worthy of shame. It's depressing. reply immibis 6 hours agorootparentThe new religious nutjobbery is that sex between a man and a woman inside of the context of marriage is also worthy of shame because it's gay: https://www.youtube.com/watch?v=flRRPTfOB2U reply yamrzou 8 hours agoprevLove it. I wish there was a way to select multiple nudges. Is it possible to provide a lifetime subscription (instead of a monthly one) for premium features? reply oleksii88 8 hours agoparentGreat app, but I second the lifetime price request. It's a bit weird for me to see a subscription for such an app. I'm happy to support the developer, but not on a monthly basis. reply thrtythreeforty 3 hours agoparentprevSubscription software cost can be modeled as a one-time fee: you calculate the net present value of all the payments. For example, if you plan to use this app for 7 years (which is a reasonable expectation for a piece of software's lifetime) and it costs $2 a month, the net present value is somewhere around $138. That is, if you decide right now to use the app for 7 years, you are costing yourself $138 in today-dollars. Which is rather a lot. Of course the subscription does have the benefit that you can cut off your usage at any point, however the people asking for a perpetual irrevocable license are probably not the type who appreciate this capability. reply jarko27 8 hours agoparentprevThanks for the try. Now I realize that the decision to make nudges in the same way as modes on iOS was a bad decision. I made it intentionally, you select nudge as one mode to enable. If you want to customize the content, just change the prompts in the nudge. Apologies for the inconvenience. And about lifetime subscription. I also get that. I will replace the subscription with a one-time purchase eventually. reply olabyne 8 hours agoprevI have a foldable flip phone. It is equivalent : I need to go through some effort to open my phone. I don't open it unless I need to reply jarko27 4 hours agoparentBTW, it was quite complicated but I added support for flip phones as well. So the app works correctly on flip phones as well. Flip phone users might have an ultimate setup. reply throwaway106382 4 hours agoprevMy iphone battery died and instead of getting the latest and greatest I got a Punkt phone. Best decision I ever made, I got my life back. reply your_drunk_dad 1 hour agoparentTried that but came back quickly simply due to good camera and ability to do a quick search/navigate that is a godsend sometimes. Also nobody uses SMS or Signal where I live. reply jarko27 4 hours agoparentprevInteresting. How are you dealing with cases when you need a navigation like Waze or Google Maps? Navigation apps are my main obstacles for trying a \"dumbphone\". reply throwaway106382 3 hours agorootparentMy city is easy to navigate (and I've lived here my entire life) so I don't really need real-time map navigation when I'm walking the streets. I have a dedicated GPS unit in my car. reply alickz 5 hours agoprevYou have a typo in your \"To be more persent\" screenshot Cool idea though reply jarko27 4 hours agoparentWow. Thanks for reporting. Fixing it. reply aodj 2 hours agorootparentHaha, came here to report the same reply bcoughlan 4 hours agoprevMy approach for iPhone: - Set time limits on apps. - Block App Store. - Set a Screen Time pin, then forget it. Downside: if you need to install a new app, you need to do a iTunes backup, factory reset and restore the backup,. Also apps won't continue to update with this approach. Worth it though. I don't miss wasting 10-20 hours a week on brain rot apps. reply throwaway519 4 hours agoparentWhy have the brain rot apps installed at all? reply jarko27 4 hours agorootparentI think it's not the apps are brain rot. It's the content available on platforms and the way how you navigate inside the app. You can watch various content on YouTube for instance. reply space_oddity 3 hours agoparentprevYour method skips the subtlety and goes straight to a hard reset (literally) reply asdf6969 46 minutes agoprevI love the idea but the globohomo art needs to go. Nobody wants to see that reply oytis 5 hours agoprevGreat idea, I'm a bit worried about security. To have control over phone unlocking the app has to be pretty privileged, right? reply aesh2Xa1 5 hours agoparentIt does not list any special privilege except drawing over other apps. I think the author could justify the network permission or they could remove it, but I personally don't consider it a big problem as-is anyway. https://developer.android.com/training/permissions/requestin... The Play Store lists these permissions: * view network connections * full network access * run at startup * draw over other apps * prevent device from sleeping The only one that gives me pause is \"draw over\" because it would allow the app to capture screen content, and that is only concerning because of \"full network access\" enabling it to send data. I'm not sure why this app would require _both_ of these permissions. https://reports.exodus-privacy.eu.org/en/reports/com.actureu... reply oytis 5 hours agorootparent> does not list any special privilege except drawing over other apps This one is huge though? You can e.g. imitate other apps' login forms and collect passwords. reply jarko27 4 hours agorootparentprevThe network is used for checking in-app purchase status, requests to Google Play only reply cloudking 5 hours agoparentprevIt's 100% local only. No server side component, analytics or ads. reply sunsetonsaturn 6 hours agoprevI'd like to give it a try, but it is not compatible with my device. Is there a reason for it not to work on a Galaxy Note8? reply jarko27 5 hours agoparentLikely it's an Android version. Minimum Android version is Android 11 reply superasn 9 hours agoprevHave you tried RescueTime? It's a similar app that prompts you to log your activities every time you unlock your phone. It's surprising to see how much time can slip by unnoticed each day. Using it can really make you more mindful of how you're spending it. reply jarko27 9 hours agoparent> Have you tried RescueTime? It's a similar app that prompts you to log your activities every time you unlock your phone. I didn't know they had such a feature. I'm going to check this out. > It's surprising to see how much time can slip by unnoticed each day. Using it can really make you more mindful of how you're spending it. Exactly. I have so many unnecessary phone pickups during the day. Without such apps that would slip unnoticed. Also, it's worth mentioning that when you notice those moments at least in my case it makes you feel guilty a bit that you picking it up unconsciously, but maybe that's my individual behaviour. reply hed 5 hours agoparentprevDoes it do this on iOS? I just cancelled RT because it crashed on my work computer all the time but if the phone app weren‚Äôt useless that might be different. reply j45 1 hour agoprevThe mobile app Opal and others do a good job too. I dare everyone to try putting their phone into grayscale instead of color display. reply wayoverthecloud 4 hours agoprevGenuine question, I also like to use my smartphone less, but what about when you are in the lavatory? I have a habit of using my smartphone else I cannot go. Has anyone been able to solve that? reply prettyStandard 4 hours agoparentDo as I say, not as I do.... Don't take it? It's bad to dit on the toilet longer than 10 minutes. reply itishappy 3 hours agoparentprevI'd challenge that. I suspect you can go fine (or should go to a doctor) and just don't like boredom. You're not alone! Provided it's not a medical issue, it's a mental one, and the answer is practice. Leave your smartphone outside, you can sit idle for 3-5m. If you're spending much more time than that, it's a medical issue. reply catlikesshrimp 3 hours agoparentprevhttps://archive.ph/Lfh1u (CNN Health) >>\"Don‚Äôt sit on the toilet for more than 10 minutes, doctors warn\" >> Leave your devices behind when you head to the bathroom (...) too much time spent on the toilet can cause possible health problems... reply noufalibrahim 8 hours agoprevI use https://play.google.com/store/apps/details?id=com.qqlabs.min... which has several things that pester you when opening certain applications. It also makes the home screen quite dull. Combine this with a monochrome display and the phone considerably loosens its grip on you. reply jarko27 5 hours agoparentI think it will work just fine in combination with Intenty. Of course, it might be too challenging to use the device with so many obstacles. But if that helps to be more mindful about phone usage, why not? reply camtarn 4 hours agoprevInstalled to try it out. I really like the art :) When you're editing a prompt, the back button takes you back to the nudge screen instead of the prompts popup, which feels like a bug. reply jarko27 4 hours agoparentThanks for the try. > When you're editing a prompt, the back button takes you back to the nudge screen instead of the prompts popup, which feels like a bug. Yeah, it's on the list of things to fix. Now to exit the prompt popup properly you have to click either on cross or out of the popup area. reply jatins 8 hours agoprevI like the idea, congrats on the launch! One feature request: instead of giving me a freeform field to enter \"why\", give me a few of common uses cases as options like: - Picking up the phone for real use (order, cab, call etc) - For social connection - For mindless scrolling overtime you can plot why the phone was picked reply jarko27 6 hours agoparentThanks! > One feature request: instead of giving me a freeform field to enter \"why\", give me a few of common uses cases as options like: - Picking up the phone for real use (order, cab, call etc) - For social connection - For mindless scrolling You can add quick answers to the prompts, it's there, no need to type every time > overtime you can plot why the phone was picked Already you can export all historical data to CSV to analyze it. There is also an interesting thing to observe, it's time spent on the screen. reply fma 3 hours agoparentprevIs this really a launch? I see reviews from 4 years ago. reply Timwi 7 hours agoprevCongrats on a useful and popular app! It sounds like something that could really help a lot of people. Now, I really don't want to come across as smug or anything, but I'm not one of the people this would help. I already use my phone in a consciously controlled manner and I don't do things like endless doomscrolling. Despite, it's clear from the evidence that a lot of people do and would benefit from this app. So I'm really curious... what is that like? What goes through your head when you grab the phone, see the app, and then decide to put the phone back down? If you realize at that point that you don't actually want to use the phone right now, why did you grab it in the first place? I'm not insinuating anything, I'm genuinely just curious. reply jarko27 6 hours agoparentIn my case it depends on the nudge I'm currently set up. If that's about using the phone less, like during focus time I pick it up habitually to procrastinate the screen can say \"Just put it down and check it at the scheduled time\". When I see the text I'm kind of dragged out of the habit loop and just putting it down or press the lock button. So it's a kind of replacement of one habit with another one. See an app screen? Lock the phone. If it is about a weekend or a vacation I put a text on the screen about being more relaxed and not having FOMO. Like 'If that's something important, you will know about it'. Here the mechanism is almost the same, I'm replacing the habit of checking stuff with something different like music or locking my phone back again. reply wruza 6 hours agoparentprevUsually it‚Äôs procrastination and anxiety escapism, and it‚Äôs all automatic. To know what goes through your head you have to reflect a lot and wouldn‚Äôt have the issue in the first place if you did that. Reflection is hard and its insights are very situational so I wouldn‚Äôt expect anyone to fully answer it. reply rmholt 7 hours agoparentprevI don't think about it at all, it's almost automatic. Like locking the door when you leave your house. I have a free moment, I enter a bus, I sit down at a table, boom phone. I may be an usual case as I believe it to be caused by general anxiety and wanting to avoid the world. reply Schinken_ 7 hours agoparentprevI am also not a doomscroller but a frequent \"let's check if something new is happening\" leads me to randomly picking up my phone regularly. It's almost automatic by now. Middle of work? \"Muscle memory\" sort of grabs phone, unlocks it, opens emails, messengers. Nothing new? Just close. TL:DR;: For me (not a doomscroller) it's sort of automatic to check my mails and messages. Not thinking much while grabbing the phone reply Unearned5161 7 hours agoprevlove the app, I think it works much better than a simple background with a question on it, and not only because I like to have pretty pictures there instead an idea: it would be neat to have extra functionality with specific apps, with regular interruptions to ask if you're still on track or what have you. maybe not even a button press, just like a 5 second breather with a message on the screen and then it goes away. sort of like the notifications you currently have in place but for the whole screen. users could modify the message for each app... look forward to seeing further development! reply jarko27 7 hours agoparentMore advanced reminders are the most frequent feature request so far. As a very trivial way to implement it, I'm thinking about showing the original screen periodically instead of the notification. But the thing you suggest with modifying the message for each app sounds interesting. Are you thinking about something like \"Have you found what you searched? Or you are just scrolling\" on Reddit? In any case, it's an item on the roadmap already reply TudorAndrei 9 hours agoprevI have been using Mindfull, and it's great. It can even block short form videos on different apps (Reddit, Instagram, Snap) https://github.com/akaMrNagar/Mindful reply racl101 4 hours agoprevHas anyone built the app from Google: The Movie yet? Er. I mean The Internship? reply stackedinserter 1 hour agoprevI want this for my fridge. reply qweiopqweiop 5 hours agoprevI love the premise behind this app, but the \"draw over screen\" permission is pretty dangerous. For example, stealing passwords by intercepting taps on the keyboard. How can we trust you won't be doing this? reply dvngnt_ 1 hour agoprevLooks like Hinge reply neondude 5 hours agoprevlove the idea, just installed it, but the premium cost is too much for what it offers. Monthly doesn't make sense to me, especially since you don't have any running costs. reply qwerty456127 9 hours agoprevOne should ask themselves just this whenever they are going to act or make a judgement. reply toisanji 5 hours agoprevI wish I could do this on an iphone. reply tmikaeld 7 hours agoprevLove the idea, is there an iOS version planned? reply mrbombastic 5 hours agoparentCheck out ScreenZen, it doesn‚Äôt work with general unlocks but you can set it to add similar mindfulness reminders for specific apps or categories of apps. Been using it a few weeks and a fan. reply JansjoFromIkea 3 hours agorootparent+1 it's pretty easy to work around but all I generally need is something to knock me out of my flow. reply jarko27 7 hours agoparentprevAs soon as Apple allows listening to phone unlock events and displaying app over other apps. Currently there are not APIs on iOS for such thing reply yieldcrv 3 hours agoprevI want a screentime app where it requires your friends to approve an override Like the ones you share location with Keep you accountable more than reflexively remembering the override pattern Has to be at the OS level so that everyone already has it reply pdecker 2 hours agoprevthis is great, especially the design. but, as some of the comments have stated, it will prob get annoying. Instead, I think it would be better to incentivize people to use their phone/social apps less. Touch Grass. Earn Points. reply iLoveOncall 9 hours agoprevI haven't seen any of those apps (or built-in OS features like screen time on iOS) not become useless in a matter of days. People that will use their phone for distraction (which I don't think there's actually anything wrong with) will take only a few days to get \"notification fatigue\" from those screens and automatically bypass them without even thinking about it. I get that you can prevent bypassing the screen as you mentioned as an extra feature but people will just click the other button then. There's not a single person (myself included) I have seen use screen time not automatically bypass the limitation instantly as it pops up. reply anteloper 1 hour agoparent> I haven't seen any of those apps (or built-in OS features like screen time on iOS) not become useless in a matter of days. This isn't consistent with the data. I'm a cofounder of Clearspace and we see that when people make it through the first two weeks, they stick around for months or years. YMMV - because our feature set looks slightly different - half users are in a mode where you have to do pushups to unlock distracting apps which really does tend to stick for people that opt in. (like this https://x.com/_oliver_hill/status/1825605422885253445) reply iLoveOncall 1 hour agorootparent> This isn't consistent with the data. I'm a cofounder of Clearspace and we see that when people make it through the first two weeks, they stick around for months or years. And how many make it through the first two weeks? I'll take a guess and say less than 1%. reply jarko27 9 hours agoparentprevWell, I agree. The fatigue from the screen is real. What I'm trying to achieve here with the app is to give a set of tools that can help deal with this fatigue. Like adding a variety to the texts you see, changing the intensity of the pop-up screen, adding cooldown, or hard mode and schedules. The Northstar is to adjust the nudge automatically based on the level of fatigue from the screen. I know I'm far from it now. But I'm attempting. I'm changing the nudges often and their configuration manually for myself now. And it works for me and I believe it can help other folks as well. That's it. reply littlecranky67 9 hours agoparentprev> There's not a single person (myself included) I have seen use screen time not automatically bypass the limitation instantly as it pops up. You can take the more drastic approach and lock yourself out of your phone by changing it's unlock code and use a timelock [0] to prevent yourself from bypassing it for a given time. Works also with parental-control like Apps that require you to enter a password/code to unlock. No bypassing here. [0]: lockmeout.online reply wingerlang 8 hours agorootparentThe point is that people don't stick with it. Bypassable versions works just as well as this, for a day or two until it becomes slightly annoying. Full lockout will work for a day or two as well, until it becomes annoying. The bypass here is simply that you never use it again. reply iLoveOncall 2 hours agorootparentprevI think that's extremely dangerous and I would never consider this to be honest. My phone is my only phone, and I need to be able to call emergency services, or answer an important call, at unexpected times. If I reached the point where I was comfortable literally being unable to use my phone for a period of time, I would just not have a phone or not carry it with me. reply littlecranky67 48 minutes agorootparentYou literally can do both without entering your unlock code. That is the whole point, locked phones are pretty useful, but not to kill time. You can even do more like make outgoing calls using Siri/Google Assistant, Take Photos/videos etc. This is default setting at least on iOS. reply keybored 1 hour agoparentprevRight. Because these things require some thought and analysis if you truly think that you yourself are having issues with screen time or other attention-related issues. I may or may not have that right now but I for sure did some years ago. And if you are having issues with your attention? Boy, loading on more stuff that you are supposed to ‚Äúattend to‚Äù for sure does not help. Someone who is having self-reported issues with their attention is not going to see some automated mindfulness message and go, oh wait time to slow down and take a good gander at what I want to spend my attention on right now. On the contrary that will just tire them more. Which makes them more susceptible to losing their awareness or attention. But people who think there is one-weird-trick to fixing these issues are incapable of understanding the +1 attention problem: that loading more stuff onto the person is not going to help. reply khernandezrt 1 hour agoprevWonderful, now i need this for my Iphone! reply guerrilla 8 hours agoprevNothing for iOS? reply jarko27 7 hours agoparentOn iOS it's simply impossible to implement. There is no way you can display an app over other apps after unlocking. I tried to implement something similar, like a widget, but that's a completely different app. Unfortunately, such an app is possible only on Android. reply hda111 4 hours agorootparentAfter unlock is probably impossible. But open app over app is possible with one sec and shortcuts. reply jarko27 4 hours agorootparentYeah, but then it's a completely different app. On Android, you can even combine Intenty and one-sec. reply Refusing23 8 hours agoprevi scroll through reddit when im on the toilet or waiting etc. while cooking or something that's really it. reply byyoung3 9 hours agoprevbrilliant reply bjt12345 9 hours agoprevCal Newport would love this! reply warner25 1 hour agoparentI was just thinking about Cal too. I listened[1] to Deep Work and Digital Minimalism a couple years ago and still use many of his prescriptions. Namely, I have no social media or gaming apps installed on my phone. On my home screen for quick access I only have Google Voice, Messenger, Maps, and the camera app. The browser app (Firefox with uBlock Origin extension) is buried and it deletes everything when I close it, so there's no history, bookmarks, logins, etc. to make browsing more streamlined. I often leave the phone at home or in my car when I go out. I leave it by the front door when I'm at home instead of keeping it in my hand or pocket. I find that having a very light data plan helps too (in addition to saving money). I have the $5/month annual plan from Red Pocket that gives me 500 MB. I'm well aware that I could burn through 500 MB very quickly, so that makes me think twice about whether I really need to load a web page if I'm out somewhere without Wi-Fi. [1] Audiobooks on my phone, ironically. But making audiobooks more accessible is probably the best value that smartphones have provided for me. Libby, for borrowing audiobooks from the library and listening to them, is the one entertainment app that I have installed. reply ajithshan001 6 hours agoprevbut why? reply diimdeep 3 hours agoprevThis will turn into gamified form filling habit for no profit, what is the point ? If you mechanically open phone at least do something useful in it read a quote https://github.com/jameshnsears/QuoteUnquote track a habit https://github.com/iSoron/uhabits learn vim https://play.google.com/store/apps/details?id=develop.exampl... c++ quirks https://github.com/vsklamm/CppQuiz or else reply lrvick 6 hours agoprevI just deleted an app a month until I was happy. My phone got so boring after a few months of this I started forgetting it when leaving home. Ended up using it so little on the go, wifi was enough and canceled my cell phone plan. Been four years since I had cell service or regularly carried any internet capable devices and I have never been happier. My anxiety has plummeted and my attention span and productivity have skyrocketed. I do not have a phone as a security blanket anymore and feel so much more confident in public. Smartphones are optional for most people, but if you are forced to carry one, keep it in airplane mode whenever possible and only use it when solving the specific problem that forces you to carry it that you lack any alternatives for. If you need mobile entertainment buy a paper book. reply safety1st 5 hours agoparentCan confirm that physically separating myself from my phone has had benefits for me. For the last two years it's usually either sitting in another room when I'm at home, or in my bag when I'm out, always on silent. Switched off an hour before bed. This is enough to eliminate the distraction for me. The main benefit is really just having more free time, focus and attention that you can channel into things you actually care about. So if anyone needs motivation to un-tether, think of it like this: being a phone user cuts your life roughly in half (in terms of the portion of time that's actually available to you to use). I could go even more extreme on the phone decoupling, for instance I still bring it with me if I'm going to a bar or something, but at the moment I'm more focused on whittling down social media usage on computers as well. It does feel like the endgame could be a better life through just abandoning most of the tech that was cooked up in the last 15 years. reply zwnow 4 hours agoparentprevA phone often is necessary if you run into issues while being outside. Let's not ignore the importance of being able to call for help if necessary. Can't blame the phone for yourself not being able to detach properly. reply pc86 4 hours agoparentprevIs this the new \"we don't have a TV in this house?\" reply danpad 4 hours agorootparentI think so. Also half of the people don't have children and/or have a lot of free time. I am not even talking about responding to emails/family chat. How do they do 2-factor auth to Heroku/Gitlab/whatever? Maps in a foreign country where you can't even read the letters? On way to job interview when the interviewer has an emergency and needs to postpone? Good friend is in the town and calls you to hang out? Translation when a tourist comes to ask where something is? reply ben_w 4 hours agorootparentI get the general point, especially as IRL payment options are also increasingly assuming you have a smartphone, however maps and translation can also be done offline. reply danpad 3 hours agorootparentHah, I hadn't even thought of banking/payments on the go. And true regarding the offline maps - a few sister comments mentioned leaving phone at home though. reply neom 4 hours agorootparentprevMy mum. And very grateful she did it, even if it was brutal at the time. reply alanbernstein 5 hours agoparentprevThis is what I want to do, but as a husband, father, homeowner, etc, I find it is not in my best interest to be unreachable by phone. So I think about carrying a flip phone for my telephone, an e-reader for entertainment, and a smartphone in airplane mode for (mainly) maps, photos, music, notes. But then I'd be carrying three devices, which seems worse in its own way. Probably worth the change ultimately? reply myself248 4 hours agorootparentIt drives me NUTS that nobody makes a decent e-ink device with a GPS app. It seems like it'd be ideal for the backcountry use-case. Super long battery life because you could just wake up the GPS every few hours and get a new fix, reframe the map, then go back to sleep and use the latent image like a topo map. reply dleink 4 hours agorootparentI have a few use cases like this that would go towards replacing my phone. I'm on the lookout for a hackable/linux ereader. reply myself248 3 hours agorootparentI thought the reMarkable was that, but they hardware-disabled the Bluetooth radio in the wifi/bt chipset, and that really wrecked most of my use-cases. reply ThatMedicIsASpy 5 hours agoparentprevI would never read books today if it wasn't for e-ink. I can adjust the font or the line spacing and at the end of the line I will read the correct next line instead of a 20% chance I will start at the same line. I never had a big relationship to my phones simply because I can't stand typing on them. My plan (prepaid) is 1‚Ç¨/month for 1GB and 9cents per min/SMS. reply dleink 4 hours agorootparentI have a similar problem but my miss rate is closer to 5% so I empathize, I'm so glad you've found a good solution. truly nothing more inspiring in tech. I think there's a lot of gains to be made in tailoring UX/UI to the individual. Not just for individuals (this person reading more books) but for societal advancement. (this person reading more books, generalized) reply laweijfmvo 6 hours agoparentprevwhat do you do when you need a phone number? reply xethos 5 hours agorootparentNot OP, but I've been meaning to pick up a used business phone and connecting it to a VoIP number for a home phone reply blululu 5 hours agoparentprevThis is great advice. I deleted everything that has an infinite scroll of new stuff and set my phone on airplane mode where possible. Life is better. I frequently go about with no phone and I have better focus. Paradoxically I now enjoy my phone much more. It has a compass a camera and a bunch of cool utilities. It‚Äôs easier to appreciate how nice maps or translate is when you need to jump for them. reply stillasleep 5 hours agoparentprevhow do you listen to music then? reply palijer 5 hours agorootparentI still use an ipod classic. My music taste hasn't changed in 2 decades. reply ben_w 5 hours agorootparentprevI'm genuinely amazed that this question exists, but then I grew up with radio, then CDs, then MP3 players. reply pc86 4 hours agorootparentIt is not physically possible to listen to music without paying $100/mo to Verizon or AT&T and $12/mo to Spotify. reply sodapopcan 4 hours agorootparentHaha, ya, this is along the lines of ‚ÄúYou can‚Äôt send HTML over HTTP without JSON.‚Äù reply seba_dos1 5 hours agorootparentprevListening to music isn't a networked activity. reply Zambyte 4 hours agorootparentprevI personally got bone conducting headphones with built in storage. It's a wearable mp3 player. reply skynet97 9 hours agoprevnext [11 more] [flagged] Dylan1312 9 hours agoparentCongratulations on finding a way to feel superior to the \"supposedly more intelligent computer users\" I guess? reply 4ndrewl 9 hours agoparentprevAre you asserting that people's ability to counter addiction has changed? reply skynet97 9 hours agorootparentnext [3 more] [flagged] lompad 9 hours agorootparentWhat's with that idea that compulsions aren't real? They are just as real and difficult to drop as substance-based addictions, for a rather simple reason: The physical addiction is only a compounding factor, not the core difficulty in a \"classic\" addiction. What really makes people always come back, no matter what, is the psychological addiction, not the physical one. Which is also why phones can be just as difficult to stop as gambling compulsions or drug addictions. reply skynet97 9 hours agorootparentnext [2 more] [flagged] 4ndrewl 8 hours agorootparentDo you speak from a position of authority on the subject? reply Mashimo 9 hours agoparentprevDang, I think you just solved alcohol and nicotine addiction. Can you also do something against gambling? Would be cool. reply skynet97 9 hours agorootparentNobody can help the weak minded. However, they need to learn that the rest of us is no longer willing to reat them like grown up adults. reply lompad 9 hours agorootparentThis is an extremist position and disagrees with a century of science on the topic. That simplistic \"weak-minded\" indicates that you are just looking for a chance to make yourself feel/look better than others and are unable to get positive stimuli on your own positive merits. Additionally, you seem to need this illusion of control, that you and your \"strong mind\" are actually in charge, which current research heavily disagrees with. If you want to put that to the test, I've got a few ideas for you... Humans are not as simple as you seem to think. If only it were that easy. I'd argue, actual adults are primarily able to discuss a topic without shitting on those they perceive as \"weak\". Greetings from somebody who used to work on the treatment side of things. reply Mashimo 7 hours agorootparentprev> However, they need to learn that the rest of us is no longer willing to reat them like grown up adults Yes! Outcast the people who have an addiction. I'm sure that will help get them back on track! Have you ever thought about writing a book? reply yazzku 1 hour agorootparentIt's like self-help but flipped on its head. They're going to need a new section for it at the bookstore. reply theshackleford 9 hours agorootparentprev> Nobody can help the weak minded. I literally lol‚Äôd. This is the kind of nonsense that dribbled down my chin when I was like 13 and thought I had the whole world figured out. reply farceSpherule 5 hours agoprev [‚Äì] People have too much damn time on their hands. Do yourselves a favor and delete all social media. reply keybored 1 hour agoparent [‚Äì] But that would give me even more time (on my hands). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Intenty is an app that encourages users to develop healthier phone habits through awareness prompts when unlocking their devices.- The app emphasizes privacy by operating entirely locally without ads or tracking, and it uses Android permissions solely for functionality without data collection.- With a minimalist design and smart customization, Intenty has a 4.4-star rating and over 10,000 downloads, appealing to users aiming to reduce mindless phone usage."
    ],
    "commentSummary": [
      "An app that prompts users with \"why?\" upon unlocking their phone is gaining attention on Hacker News for its potential to reduce distractions.",
      "Users find the app helpful but sometimes inconvenient for quick tasks, leading to suggestions for improvements like randomizing prompts or allowing app-specific bypasses.",
      "The developer is considering user feedback for updates, including a one-time purchase option instead of a subscription model."
    ],
    "points": 512,
    "commentCount": 273,
    "retryCount": 0,
    "time": 1732696475
  },
  {
    "id": 42253119,
    "title": "The capacitor that Apple soldered incorrectly at the factory",
    "originLink": "https://www.downtowndougbrown.com/2024/11/the-capacitor-that-apple-soldered-incorrectly-at-the-factory/",
    "originBody": "Downtown Doug Brown Thoughts from a combined Apple/Linux/Windows geek. Home About Mac ROM SIMMs Software Microcontroller lessons Contact Nov 26 The capacitor that Apple soldered incorrectly at the factory Doug Brown Classic Mac, Computer repair 2024-11-26 There have been some past rumblings on the internet about a capacitor being installed backwards in Apple‚Äôs Macintosh LC III. The LC III was a ‚Äúpizza box‚Äù Mac model produced from early 1993 to early 1994, mainly targeted at the education market. It also manifested as various consumer Performa models: the 450, 460, 466, and 467. Clearly, Apple never initiated a huge recall of the LC III, so I think there is some skepticism in the community about this whole issue. Let‚Äôs look at the situation in more detail and understand the circuit. Did Apple actually make a mistake? I participated in the discussion thread at the first link over a decade ago, but I never had a machine to look at with my own eyes until now. I recently bought a Performa 450 complete with its original leaky capacitors, and I have several other machines in the same form factor. Let‚Äôs check everything out! Here‚Äôs the affected section of the board before I removed the original capacitors. You can see that all three of these caps (C19, C21, and C22) have their negative side pointing upward, matching the PCB silkscreen that has the + sign at the bottom. If the miscellaneous gunk and ugly appearance of the solder joints in this picture isn‚Äôt a warning sign that you should replace the SMD electrolytic capacitors in any classic Mac from the ‚Äô90s at this point, I don‚Äôt know what is! Let‚Äôs take a closer look at the circuit after I removed them and cleaned everything up a bit. Yikes, C21 leaked really badly and damaged the solder mask and the copper underneath. When I removed it, there was a big puddle of goo sitting there. I haven‚Äôt installed new capacitors on this board yet, but I‚Äôm probably going to need to scrape more of that dark crud from the copper and cover it all up with UV-curable solder mask. Luckily, it‚Äôs just the ground plane so it‚Äôs not a huge deal. Anyway, the important thing to note in this picture is that the negative terminal of each capacitor goes to the ground plane. The positive terminals all head over to pins on the power supply connector. What‚Äôs happening here is there is one bulk capacitor for each of the three power rails provided by the power supply. C19 is for +5V, C21 is for +12V, and C22 is for -5V. You can see the trace from C22‚Äôs positive terminal going directly to the -5V pin on the power supply connector. This arrangement makes sense for the two positive power rails, but it‚Äôs backwards for the -5V rail. If the image above isn‚Äôt proof enough for you, here are a couple of pictures with my multimeter definitively showing that the positive terminal of C22 goes to -5V and the negative terminal goes to ground. That means when the system is powered on, there will be -5V across this capacitor. I really don‚Äôt need to do any additional analysis at this point in order to say that this is just plain wrong. You aren‚Äôt supposed to have a negative voltage across this type of capacitor. There‚Äôs a reason they have a marking that identifies the negative side. The voltage at the positive end should be greater than or equal to the voltage at the negative end. In other words, this capacitor‚Äôs positive end should have been connected to ground and the negative end should have been connected to -5V. Let‚Äôs compare and contrast this circuit with the corresponding circuit on an original Mac LC, which uses the exact same power supply. This is another system with its original leaky caps: They installed it correctly on the original LC (and the LC II). -5V goes to the negative end of the capacitor, and ground goes to the positive end, resulting in a net voltage of positive 5 volts across it. What about the LC 475, which is the successor to the LC III? If Apple miraculously discovered a special exception to the laws of physics during development of the LC III, I would expect them to have continued following this new rule with the design of the LC 475. Nope! It‚Äôs back to the same (correct) orientation that was used on the original LC. After seeing it myself and comparing the circuit with other Mac models of the era, I‚Äôm very confident that Apple made a boo-boo on the LC III. It‚Äôs not just a factory component placement issue; the PCB‚Äôs silkscreen is also incorrect. It‚Äôs basically the hardware equivalent of a copy/paste error when you‚Äôre writing code. I‚Äôm hoping to raise awareness of this mistake because all of the (very useful) recapping guide collections I‚Äôve found on the Internet strangely fail to mention this reversed capacitor for some reason, even though it‚Äôs known to have caused problems for many people. But, you may ask, why didn‚Äôt it matter with the original liquid-filled electrolytic capacitor fitted on the board? Why didn‚Äôt this cause a huge uproar back in the day? Why didn‚Äôt everyone‚Äôs LC III explode in a giant fireball? Well, for one, the original capacitor was obviously tolerant of this mistake. It was rated for 16V but only -5V was being put across it. According to what I‚Äôve read online, that‚Äôs more than enough reverse voltage to permanently damage this type of capacitor, but it may not be enough to cause it to violently explode. Plus, it is only involved with the -5V rail, which is really only needed for the RS-422 serial ports. The capacitor might not have been doing its job properly if it was installed backwards, but it didn‚Äôt seem to really be hurting anything. With the way that a lot of people in the hobby these days (including me) are using tantalum capacitors as replacements, I think it‚Äôs potentially dangerous that this backwards capacitor isn‚Äôt widely documented. Although the computer seems to work okay in this configuration with a normal electrolytic capacitor like what was installed by the factory, tantalum capacitors are not quite as forgiving when installed in reverse. Multiple people online have observed that when they have a tantalum capacitor installed in the original incorrect orientation, they end up with an incorrect voltage on the -5V rail. The original poster about this issue, paul.gaastra, said that with the tantalum capacitor installed backwards it was drawing 1.3 amps (way too much) and the voltage was only -2.3V. At best, this is going to result in serial port problems. At worst, you‚Äôre asking for the capacitor to explode or catch on fire. It‚Äôs probably not good for the power supply, either; it‚Äôs only rated for 75 mA on the -5V rail. The bottom line is that Apple‚Äôs silkscreen markings and factory placement for C22 on the LC III are flat out wrong. There‚Äôs no other correct answer. Please, if you are recapping one of these machines, install C22 backwards from what the silkscreen on the PCB says. If you don‚Äôt believe me, or want to double check for yourself, you can easily verify this with a multimeter in continuity test mode with the system powered off. The positive end of the cap needs to be connected to ground, and the negative end needs to be connected to -5V. Using your multimeter‚Äôs DC voltage mode, if you power on the system, you should see 5V across the capacitor (negative probe to negative side of cap, positive probe to positive side of cap). That‚Äôs how it is on every other Mac with a -5V rail. Address: https://www.downtowndougbrown.com/2024/11/the-capacitor-that-apple-soldered-incorrectly-at-the-factory/ ¬´ Hardware repair of an Elgato HD60 S that only worked on Mac Trackback 8 comments Guy Dunphy @ 2024-11-26 23:00 Interesting that C21 (+12V) failed, not the reversed C22(-5V). Did you know that when electrolytic caps are manufactured, the two aluminum foil plates are identical and there is no insulating layer. Once assembled, with an electrolyte soaked porous sheet between the plates, a voltage is applied. This causes a chemical reaction with one of the plates, that creates a thin insulating layer. The layer surface also isn‚Äôt flat, but has a very complex structure with a high surface area, to maximize the capacitance. This process is called ‚Äòforming‚Äô the capacitor. The reason electros are (mostly) polarized, is that the chemical reaction can be reversed with opposite voltage, and as the ‚Äòformed‚Äô layer is removed, the capacitance (and voltage it can resist) decrease. The insulating layer also degrades over time while there is no voltage across the cap. So to restore vintage electronics, power should be applied very slowly ramping up to full voltage, to allow old electros to ‚Äòreform.‚Äô (If they didn‚Äôt leak and dry out.) But 5V is quite low. It‚Äôs possible that C22 completely de-formed, and then re-formed in reverse polarity. It didn‚Äôt leak and might even have been perfectly fine. Though replacing it was a good idea. C21 otoh‚Ä¶ An important spec sheet number for eletros is the maximum ripple current they can handle. The reason it matters is that electros have an internal series resistance, and the ripple (AC) current is dissipating heat in that resistance. Cheap little caps like these will have relatively high internal resistance. And the +12V rail can have a fairly high ripple current. It would not surprise me at all if no one at Apple checked the +12V rail ripple current in this cap, or ever even looked at the spec sheet for the caps. That C21 leaked, suggests it was under-rated, and over time internal heating and resulting eletrolyte pressure broke the seal. Doug Brown @ 2024-11-26 23:11 Hi Guy, Thanks for the details about how caps work and how they are made! To be fair, all of the electrolytic caps had leaked on this board, including the other two in the picture. I think it‚Äôs more an old age thing than anything else. It‚Äôs a super common failure mode on lots of old electronics. Every Mac from the early ‚Äò90s I have encountered has had caps with leakage like this. C21 was definitely the worst I‚Äôve ever seen though. Anonymous @ 2024-11-27 00:34 I tried to fact check the statement regarding > the two aluminum foil plates are identical and there is no insulating layer. It doesn‚Äôt seem accurate, at least not with today current manufacturing techniques. One of the plate is highly etched beforehand to allow for the formation of the oxide layer. Also, the purity of the plates differ. Robo @ 2024-11-27 01:44 The two multimeter photos are same? Joakim @ 2024-11-27 04:21 Great writeup Doug! Apple surely must have known at an early stage, so it really makes you wonder if they made any tests verifying that it would sort of work anyway and therefore decided against doing a recall on it. Tech Tangents @ 2024-11-27 06:26 Thank you for posting about this! I‚Äôve been trying to find known examples of these kinds of issues but haven‚Äôt run into any myself yet. I run Caps Wiki and someone had made a page about the LC III but had not mentioned it. I just updated the page to document this issue there as well. I‚Äôve heard that ASUS also had a tendency to get the silkscreen wrong on their caps but they would install them electrically correct. So this issue can show up in other ways as well. Doug Brown @ 2024-11-27 07:01 Robo, the pictures are subtly different. In the first one I‚Äôm clipped onto the -5V pin of the power supply and probing the positive terminal of the cap. In the second one I‚Äôm clipped onto ground and probing the negative terminal. In both pictures the multimeter shows continuity. I agree Joakim, I feel like Apple must have been aware at some point. With the stock caps it didn‚Äôt seem to be a problem. The old cap didn‚Äôt look worse than any of the others after all these years. Thank you Tech Tangents! That‚Äôs great. Your updates on the page look awesome. Much appreciated! Yuhong Bao @ 2024-11-27 10:59 I believe that -5V was already almost obsolete by the time of the original IBM PC. Add your comment now Name (required) Email (Will NOT be published) (required) URL Subscribe Recent Posts The capacitor that Apple soldered incorrectly at the factory Hardware repair of an Elgato HD60 S that only worked on Mac Are wireless gamepads terrible? Mario Maker TAS playback with an RP2040 Fixing an Elgato HD60 S HDMI capture device with the help of Ghidra Upgrading my Chumby 8 kernel part 13: the end Fixing more cheap Altera USB Blaster clones: CPLD adventures I fixed a 6-year-old .deb installation bug in Ubuntu MATE and Xubuntu Upgrading my Chumby 8 kernel part 12: UART woes Categories Chumby 8 kernel (13) Classic Mac (9) Computer repair (9) Electronics repair (6) iOS (3) Linux (43) Mac ROM hacking (11) Microcontroller lessons (11) Microcontrollers (4) Product reviews (5) Python (1) Qt (5) Reverse engineering (2) Uncategorized (20) Windows (7) Archives November 2024 (1) October 2024 (2) September 2024 (1) August 2024 (1) July 2024 (3) June 2024 (4) May 2024 (1) April 2024 (2) December 2023 (1) November 2023 (2) September 2023 (3) August 2023 (3) June 2023 (1) May 2023 (1) April 2023 (1) March 2023 (2) January 2023 (1) December 2022 (3) August 2022 (1) May 2022 (2) March 2022 (1) December 2021 (1) June 2021 (1) April 2021 (1) January 2021 (1) September 2020 (1) August 2020 (1) July 2020 (1) May 2020 (1) June 2019 (1) April 2019 (1) December 2018 (1) August 2018 (1) May 2018 (1) April 2018 (3) February 2018 (1) October 2017 (1) July 2017 (1) May 2017 (3) March 2017 (1) October 2016 (1) June 2015 (1) March 2015 (1) November 2014 (1) August 2014 (3) July 2014 (1) April 2014 (1) March 2014 (1) February 2014 (1) November 2013 (1) August 2013 (1) June 2013 (3) April 2013 (1) March 2013 (1) January 2013 (2) December 2012 (2) August 2012 (1) July 2012 (2) June 2012 (1) May 2012 (1) February 2012 (3) January 2012 (1) November 2011 (1) October 2011 (2) August 2011 (3) May 2011 (1) April 2011 (1) March 2011 (2) November 2010 (2) October 2010 (3) July 2010 (5) Recent Comments Yuhong Bao on The capacitor that Apple soldered incorrectly at the factory Doug Brown on The capacitor that Apple soldered incorrectly at the factory Tech Tangents on The capacitor that Apple soldered incorrectly at the factory Joakim on The capacitor that Apple soldered incorrectly at the factory Robo on The capacitor that Apple soldered incorrectly at the factory Anonymous on The capacitor that Apple soldered incorrectly at the factory Doug Brown on The capacitor that Apple soldered incorrectly at the factory Guy Dunphy on The capacitor that Apple soldered incorrectly at the factory Doug Brown on Fixing a knockoff Altera USB Blaster that never worked Artur on Fixing a knockoff Altera USB Blaster that never worked Spam Blocked 231,253 spam blocked by Akismet Downtown Doug Brown ¬∑ coogee theme ¬∑ 2008 ¬∑ Privacy Policy RSS Feed ¬∑ WordPress ¬∑ TOP",
    "commentLink": "https://news.ycombinator.com/item?id=42253119",
    "commentBody": "The capacitor that Apple soldered incorrectly at the factory (downtowndougbrown.com)383 points by zdw 13 hours agohidepastfavorite152 comments ethbr1 13 hours agoWell, today I learned to install one capacitor in reverse orientation on the PCB on a 34 year old computer... Definitely starting Wednesday off productively. reply grujicd 9 hours agoparentWell, until today I didn't even know capacitor can have orientation! So more productive Wednesday than yours. In entry level electronics class I had decades ago it was always treated as a component that works the same way no matter in which direction the current flows. reply Filligree 9 hours agorootparentCeramic capacitors don't have polarity. Electrolytic ones do. Thing is, electrolytic capacitors have far higher capacitance for their size -- though also higher resistance. It's something to check, but the polar ones should be clearly marked as such. reply magic_smoke_ee 7 hours agorootparentElectrolytic capacitors are kinda like lead-acid batteries in that they are polarized through manufacturing processes. A voltage is applied in the factory to anodize the anode with a thin oxide layer. For fun, I think it would be possible to buy a quality low voltage cap and reverse the polarity of it in-situ which would remove the anodization from the new cathode and deposit a new layer on the new anode (former cathode) hopefully without over-pressurizing it to bursting, albeit with much less anticipated lifespan. PSA: Electrolytic capacitors have a rough lifespan of 10 years. Any much older than that need to be checked out-of-circuit for ESR and then capacitance. Also, tantalums (historically) suck(ed). [0] Quality audio equipment from the 80's like a/d/s/ car amps used only ceramic caps and other over-engineered passives, and have the potential (pun intended) to basically last forever. 0. https://www.eevblog.com/forum/projects/whenwhy-(not)-to-use-... reply outworlder 13 minutes agorootparent> Any much older than that need to be checked out-of-circuit for ESR and then capacitance And that's a very time consuming and somewhat risky operation on an old machine you want to keep running. Some old PCBs are quite fragile. I wish there was a way to test capacitors without removing them. reply kevindamm 4 hours agorootparentprevOr much shorter, around two years, if it was part of the Capacitor Plague. https://en.wikipedia.org/wiki/Capacitor_plague#Premature_fai... The normal lifespan of a non-solid electrolytic capacitor of consumer quality, typically rated at 2000 h/85 ¬∞C and operating at 40 ¬∞C, is roughly 6 years. It can be more than 10 years for a 1000 h/105 ¬∞C capacitor operating at 40 ¬∞C. Electrolytic capacitors that operate at a lower temperature can have a considerably longer lifespan. ... The life of an electrolytic capacitor with defective electrolyte can be as little as two years. reply Workaccount2 4 hours agorootparentThis is also why so many LED bulbs are shit, lots of heat in a small space full of electrolytic caps. reply magic_smoke_ee 2 hours agorootparentIntentional planned consumption/obsolescence by design. This class of problem is where under-regulation and lack of standards benefits only sellers and cheats buyers. PS: Also, Amazon should be required to test all of the electronic, safety, and food products on its site such that they can prove safety and standards conformance. reply Workaccount2 2 hours agorootparentI am assuming you are an ee (like myself)...I have never designed a product with a built in expiration, nor have I ever seen any app notes or write ups on the engineering of it - something engineers love to do. What I have seen done is cheaping out on parts in order to get the price as low as possible, because customers shop primarily on price. Not to lash out, but it kind of hits a nerve for me, because people think we design products to purposely fail. Hell no, we try really hard to do the opposite, but everyone just loves to buy the cheapest shit. The $25 LED bulb that will last for eternity will rot on the shelf next to the $3 bulb that will probably be dead in 6 months. And one more \"they build these things to fail\" complaint will be posted online. reply belval 1 hour agorootparentTo be fair this is hardly limited to EE and is the issue with the race to the bottom in all product categories. Make long-lasting high-quality 100$ pants? People prefer spending 10$ on Shein. Additionally, the issue is that as a consumer, it's not easy to differentiate between quality markup and greedy markup. I don't see the cap manufacturer on the box so the 25$ light bulb might last 10 years or it might last 6 months just like the 3$ one. At least with the 3$ one I can come back and buy another... reply magic_smoke_ee 1 hour agorootparentprevI seriously doubt it's ever a deliberate conspiracy in engineering apart from shenanigans like what happened at VW, but it's net effect of product managers, accountants, and contract manufacturers who modify PCBs and BOMs after it's passed off to them to save money on retail products. And so it's likely unintentional with negligence, but it benefits the company. Except for some Samsung appliances made ~ 2010-2014 which seemed to fail just after their warranties expired. I suspect highly-optimized designs for \"consumables\" like incandescent lightbulbs and parts for cars use data to tweak design life, more often than not, in their favor. And, with the pressures of multinational oligopolies and BlackRock/Vanguard/State Street.. there is little incentive to invest $100M into a moderately-superior incandescent lightbulb using yesterday's technology that lasts 100kh and 5k cycles and sells for $1 more than the next one. Maybe if we (perhaps a science/engineering nonprofit thinktank that spanned the world and gave away designs and manufacturing expertise) had quasi-communism for R&D, we could have very nice things. It's not my fault if other people are too dumb to comprehend TCO because I would buy the $25 bulb if it had a 30 year warranty. reply kube-system 42 minutes agorootparent> Except for some Samsung appliances made ~ 2010-2014 which seemed to fail just after their warranties expired. And? That just sounds like they have good engineers. If you are designing a machine, you have an target lifetime. You'd obviously want the product to last through the warranty period, because warranty claims are a cost to the company. Every choice of a component affects lifetime. Designers of mass-market products can't just use premium components everywhere -- the mass market will not pay steep premiums for otherwise equivalent products. Value engineering and planned obsolescence are not the same thing, but they are often confused. That being said, Samsung appliances suck and I hate them. Mine failed within warranty several times. > And, with the pressures of multinational oligopolies and BlackRock/Vanguard/State Street.. there is little incentive to invest $100M into a moderately-superior incandescent lightbulb using yesterday's technology that lasts 100kh and 5k cycles and sells for $1 more than the next one. It isn't that. It's pressure at the shelf that does it. Consumers behavior simply does not reward equivalent-feature products with premium components that claim (true or not) to have a longer lifespan. Unfortunately, they will buy based on their uninformed sense of quality first. If you release a light bulb that is identical to the best selling one on the shelf, but claims 10x lifespan, your competitor will do something like gluing a weight in theirs, putting some marketing BS on the box, and will put you out of business. Consumers just don't pick products based on actual quality. reply magic_smoke_ee 32 minutes agorootparentYou're making a pretty awkward value judgement about what a \"good\" engineer is, but you're describing an unethical one with a bizword like \"value engineering\". I realize ethics are no longer understood by much of Western society because the culture teaches transactionality, worships trickle-down economics and greed, and hyperindividualism. > It isn't that. It's pressure at the shelf that does it. Consumers behavior simply does not reward equivalent-feature products with premium components that claim (true or not) to have a longer lifespan. Unfortunately, they will buy based on their uninformed sense of quality first. This is a failure of marketing and buzz of the sales channel(s) and manufacturers to educate properly, not the failure of the customer. reply kube-system 19 minutes agorootparentA good engineer is one that has a job, doesn't put their employer out of business, and produces work that fulfills the requirements they're given. Many people think there's some unethical conspiracy going on, and consumers actually want a product that lasts a long time, but companies are refusing to give it to them. But this is projection of individual preferences on to the market as a whole. Consumers want cheap shit that is in fashion, and their buying preferences prove this time and again. Maybe you want a 50 year old toaster in your kitchen, other people are buying products based on other factors. If consumers really wanted to pay a premium for high duty-cycle equipment with premium lifespans, they can already do that by buying commercial grade equipment. But they don't. If you are familiar with the history of home appliances, you'd probably come to appreciate the phrase 'value engineering'. Even poor people can afford basic electric appliances now because of the ingenuous ways that engineers have designed surprisingly usable appliances out of very minimal and efficient designs. If you look at ads for electric toasters 100 years ago, you'd see they cost over $300 in today's money adjusted for inflation. Thank god for value engineering. kube-system 52 minutes agorootparentprev> Intentional planned consumption/obsolescence No it isn't. It is simply optimization of price and the features/form-factor that many buyers have demanded. If anything, the lifespan of a ~$1.50 household LED bulb is quite incredible. I'm not sure exactly how anyone would be able to increase the lifespan at that price point and keep the traditional Edison form factor. > Amazon should be required to test all [..] products on its site such that they can prove safety and standards conformance. No, the manufacturers should be required to... the same way it works for literally every other product with safety regulations. reply Filligree 2 hours agorootparentprevThat, and customers insisting on preexisting form factors. Fitting the electronics and LEDs into the space of a traditional lightbulb comes with compromises, such as not having proper heat dissipation on either. reply BlueTemplar 1 hour agorootparentYeah, you would think they would be two separate devices by now... reply andrewflnr 1 hour agorootparentprevPlease think for a moment not only about whether it's feasible for AMZN to run a safety testing program for all possible consumer products of our modern technological civilization, but whether you really want them to be in charge of it. Maybe they should just require certifications of testing in the jurisdictions where those products are sold? reply gopher_space 33 minutes agorootparentIsn't faking certs already a problem? reply andrewflnr 22 minutes agorootparentProbably. Is it a worse problem than Amazon inspecting themselves would be? Is it a worse problem than Amazon demonstrably already has with policing counterfeits? I'm just saying, you could hardly ask for a less-qualified authority for product testing. At least with independent certs it's vaguely possible to align the incentives correctly. With Amazon the incentives would be hosed from the start. 83 4 hours agorootparentprevBipolar electrolytic capacitors are a thing, I recently had to solder up a handful of them in some audio circuits. reply nuancebydefault 5 hours agorootparentprevOnce you have experienced blowing up a reversed elcap you will never forget its orientation. I never understood though what makes it leak current and hence heat up. reply marcosdumay 4 hours agorootparentModern electrolytic caps don't burn like they used to. The last few times I made a mistake, there wasn't even an explosion, even less a short-circuit. The thing slowly boiled and bubbled or unfolded. Anyway, it blows up because the capacitor's insulation layer isn't some stable material, it's a tiny oxide layer built over the metal plate by anodization. If you put a high voltage on it with the wrong polarity, you reverse that anodization and short the liquid and the metal electrodes. reply kevindamm 4 hours agorootparentprevThere's an aluminum oxide layer as a coating on both the anode and cathode inside the (electrolytic) capacitor. Under forward voltage it will gradually thicken but under reverse voltage it dissolves and causes a short. This increases the temperature which causes hydrogen ions to separate and bubble through the material, increasing pressure within the capacitor package until it bursts. reply fredoralive 9 hours agorootparentprevThere are polarised and unpolarised capacitors. Stuff like basic decoupling capacitors tend to be unpolarised. reply phire 11 hours agoparentprevI actually have an LC III in storage, so I might actually be able to make use of this article. I think this will allow me to classify today as productive. reply InsideOutSanta 10 hours agorootparentYeah, I have a Performa 450, which I believe is the exact same computer sold under a different name. So this is definitely important to know. I can go back to bed now, my job for today is done. reply xeyownt 12 hours agoparentprevAt least you made my Wednesday ;-) reply rty32 5 hours agoparentprevThat's why I immediately closed the article, after seeing how outdated those PCBs look like, knowing the article will be absolutely useless to me :) (no offense to the author) reply pjc50 5 hours agorootparentIt's the sort of mistake that one could make in a PCB design today. reply rty32 4 hours agorootparentApparently people can't read. I don't know which part of \"to me\" is not clear. I don't design PCB boards (thus the \"useless\" word), and the comment was apparently a lighthearted joke in response to another lighthearted joke. reply codewiz 13 hours agoprevCommodore had 3 capacitors mounted backwards on the A3640, the CPU board of the Amiga 4000 with 68040 processors: https://youtu.be/zhUpcBpJUzg?si=j6UFmIJzoC-UDS6u&t=945 Also mentioned here: https://amiga.resource.cx/exp/a3640 reply rwmj 9 hours agoparentZX Spectrum +2 shipped with transistors backwards: https://www.bitwrangler.uk/2022/07/23/zx-spectrum-2-video-fi... This even caused visible artifacts on the display, which was apparently not enough for the problem to be noticed at the factory. reply extraduder_ire 1 hour agorootparentI think Clive Sinclair was notorious for wanting products to be brought to market quickly, with pretty aggressive feature sets. They very well may have noticed it at the factory, but didn't want to do a fix because it was technically functional. reply krige 9 hours agoparentprevCommodore just kept doing this. Just listing shoddy craftsmanship would take forever, and then we get to intentional bad decisions, like giving the A1200 a power supply that's both defective (capacitors ofc) and barely enough to support the basic configuration with no expansions, which is extra funny because PSUs used with weaker models (A500) had greater output... reply kstrauser 3 hours agorootparentThis was the hardware patch I had to install to use a CyberstormPPC: https://powerup.amigaworld.de/index.php?lang=en&page=29 reply bbarnett 7 hours agorootparentprevThe number of used a500 power supplies I sold to customers when I upgraded their a1200 with a GVP 030 board + RAM... reply bogantech 12 hours agoparentprevClassic Commodore Quality :P They also had backwards caps on the CD32 and A4000 reply ethernot 10 hours agoprevThere are so many cases of this sort of stuff it's unreal. But it gets even stupider. I found one a few years back when I repaired a linear power supply. This required me to reverse engineer it first because there was no service manual. I buzzed the whole thing out and found out that one of the electrolytic capacitors had both legs connected to ground. They must have shipped thousands of power supplies with that error in it and no one even noticed. reply klysm 3 hours agoparentThat seems like one the least harmful mistakes you could make. Capacitors are sprinkled all over boards in excess‚Äôs because it‚Äôs probably better than not enough capacitance. reply jcims 5 hours agoparentprevI have a 3D printer where presumably a smoothing cap just fell off the X axis controller section of the mainboard. Didn't make a lick of difference in anything operationally. Still works great. reply klysm 3 hours agorootparentChecks out, most boards are made with very conservative amounts of decoupling capacitance because it‚Äôs way easier than dealing with random failures due to not enough capacitance reply robomartin 4 hours agorootparentprevIt could be there to control emissions. You‚Äôd need to analyze the circuit to determine its purpose. reply chrisdhoover 5 hours agoparentprevWay back when a co worker was powering up a fire alarm control panel. Poof, capacitor popped and damaged his eye reply iknowstuff 10 hours agoparentprevName and shame! reply ethernot 10 hours agorootparentVoltcraft. Can't remember the model number. reply PeterStuer 11 hours agoprevIn the mid 80's I was the head of the CS student chapter. We ran the computer rooms for the science faculty. We had a room with about 20 Mac 128k. I do not know where Apple sourced their capacitors from, but these were not A-tier. A Mac going up in a puff of white smoke was a weekly occurrence. We had a few in reserve just to cycle them in while they were out to Apple for repair. P.S. still my favorite Mac of all time was the IIcx. That one coupled with the 'full page display' was a dream. reply yetihehe 9 hours agoparentOn the other side, we had intern at our (very small) company and he used his own mac. One time he had to debug a mains-powered device. He decided that he will try connecting it to both mains AND programming dongle without separating transformer. He fried the dongle (it literally exploded, plastic lid banging on desk in sudddenly silent office is the most memorable thing), the company provided monitor and device, but somehow his private mac mini survived all this while being in the middle. reply jdbdbcjd 7 hours agorootparentThat sounds fishy, even if the debugged device directly interfaced mains, the Mac doesn't. And even if it did, how high would the probability be that both machines were on different circuits with phases so much out of sync that it would matter? Unless I misunderstood your story reply mgsouth 58 minutes agorootparentTotally believable if the debugging device was doing something with a serial port. I once hacked something together to interface a PC serial port to a Raspberry Pi. The PC serial is real-ish RS-232, with negative voltages. The Pi side was just 0/3.3V positive. I had a nice 18-volt power brick laying around, and just split it's output down the middle--what was 0 volt ground was used as -9 volts, the middle voltage was now 0 volt ground, and the 18-v line was now +9 V. At first everything seemed OK. but when I plugged a monitor into the PI I Was Made To Realize a) the nice 18-volt PS really was high quality, and although it was transformer-isolated its output ground was tied to the wall socket earth, b) monitors also tie HDMI cable ground to earth, and so c) my lash-up now had dueling grounds that were 9V apart. reply yetihehe 7 hours agorootparentprevThat device was a cheap wifi power plug, had cheap unisolated power supply, it was never intended to have user accessible electrical parts sticking out, so no need for isolation. In such cases device has common ground with ac voltage. I don't know all specifics, but NEVER connect any single terminal of 220V plug to your computer ground (usb ground in this case). When it's properly grounded, most devices will survive this. But somehow monitor connected to that mac didn't survive it. And several milliseconds of full 220V before circuit breaker reacted, made very thin traces in debugger pretty much vaporise and explode. reply nuancebydefault 5 hours agorootparentIf i remember correctly, a lot of power supplies of cheap electronics have AC-coupled the low voltage side with the mains side. There's no physical wire, just a capacitor. You can often feel the AC when touching the 'safe' side of the adaptor. reply amluto 3 hours agorootparentForget ‚Äúcheap‚Äù. As far as I can tell, many modern ungrounded power supplies, including Apple‚Äôs, have enough A/C coupling from the line to the output that you can feel a bit of tingling when you touch a metallic object connected to the output. reply spockz 3 hours agorootparentHow is this even allowed? My tv had it. My MacBooks since time memorial have it. They all feel ‚Äúspicy‚Äù. reply ChrisClark 1 hour agorootparentMy Fold 5 has that feeling along the hinge when charging too, no matter the charger I use. I guess it's considered safe, but it's weird. reply fredoralive 10 hours agoparentprevWith things like the Mac 128k, reliability issues may partly be down to Steve Job‚Äôs dislike of cooling fans. reply m463 9 hours agorootparentTo be honest, cooling fans never get the attention they deserve and end up whiney or buzzy. That said, apple did a really good job with mac pro cooling fans where the shroud spun with the blades. I think it did better than the the best PC cooling fans like noctua. reply Melatonic 23 minutes agorootparentI always built PCs with the largest diameter fans possible - not sure why so many things come with tiny fans. Loads more airflow with less noise and even if they do spin up fast the noise they make is much more pleasant. reply alain94040 1 hour agoprevSounds like the person who designed the board followed a very simple and wise rule: always connect the negative side to the ground. Can't go wrong with that... until you have to deal with negative voltage (-5V). Another out of bounds bug. reply 1oooqooq 18 minutes agoprevwhat apple era are those machines? is this before or after Jobs shafted the engineering department on the sale and Woz had to give them bonus to keep them on the factory? reply chefandy 2 hours agoprevWhat‚Äôs the liquid in the old capacitors? PCBs? (as in polychlorinated biphenyls‚Ä¶ that abbreviation collision always annoyed me.) I think I know exactly enough about electronics to ask more annoying questions than someone who doesn‚Äôt know anything at all. reply yborg 2 hours agoprevI have a Quadra 700 of this vintage that hasn't been powered up in 25+ years. Kind of wanted to fire it up again to experience the glory of A/UX one more time, but sounds like I'd have to replace all the lytics :/ reply mmmlinux 2 hours agoparentDo it sooner than later, the cap juice loves to eat PCB traces. same with the clock batteries, get those things out of there. reply mikewarot 1 hour agoprevI've found a ground lug in a Kilowatt Grounded Grid amplifier... that didn't ground the grid. I found a bad solder joint that looked ok, but was intermittent, and had been that way, in a Television built in 1948 and used for decades. Bad design and assembly goes back forever, as near as I can tell. reply foft 3 hours agoprevIt is not just Apple that did this, for example here is an equivalent from Atari: https://www.exxosforum.co.uk/forum/viewtopic.php?f=17&t=1698 reply magic_smoke_ee 7 hours agoprevFrom around 2011-2015, I sometimes talked to an ex-Navy electrical tech who said he was also an early Apple rework tech in the SF Bay Area. He had no shortage of work fixing manufacturing problems, adding rework improvements, and building custom test equipment until they laid him off, outsourced his job to some random country, and then he was homeless until around 2016. reply johnklos 6 hours agoprevIt's a good thing that these machines don't even need -5 volts. With just the positive voltages provided, RS-422 still works, including LocalTalk. I think the -5 volts is only there in case an expansion card needs it. reply 0xbadcafebee 3 hours agoprevAnyone else a veteran of the Great Capacitor Plague? Seen more than one fire in the server room due to bad capacitors. \"Burning-in\" your server became literal. reply shiroiushi 13 hours agoprevApple should be required to do a recall for these motherboards. reply toast0 13 hours agoparentIf they do a recall, it will say they should be discarded. Sony has a recall on all its trinitron tvs made before the end of 1990 like this: https://www.sony.jp/products/overseas/contents/support/infor... reply shiroiushi 13 hours agorootparentThis shouldn't be allowed at all: if the product was bad all along, they should be required to fix it, and shouldn't be able to say \"well, it's old, so you should just trash it\", which means they don't suffer any penalty whatsoever. reply tengbretson 33 minutes agorootparentMy radial arm saw ended up getting a product recall for simply being too difficult for the average consumer to use safely. The \"recall\" amounted to them sending you instructions to cut off a critical power cord and mail it in to them, and they send you a $50 check. reply duskwuff 12 hours agorootparentprevI don't think that's a reasonable expectation in general, and certainly not in this case. The affected TVs were all at least 20 years old - that's well beyond the expected useful lifespan of even a modern TV, let alone an older model like these. Nor is it clear what Sony could reasonably have done to repair them; even by 2010, a lot of the parts used in CRT TVs were out of production and unavailable. reply shiroiushi 12 hours agorootparentMaybe you're too young to remember, but people used to keep TVs for much longer periods before HDTV and flat panels came out. Also, these TVs are apparently fire hazards. It doesn't matter that they're 20 years old (at the point of the \"recall\" in 2010). I doubt the parts necessary to fix them were out of production; you can get parts for truly ancient electronics still. Things like capacitors don't become obsolete. The recall doesn't specify exactly which component is problematic, but says it's age-related, which usually points to capacitors. reply tobr 12 hours agorootparentThis. I‚Äôve known a TV that was in more or less daily use for over 30 years. Not sure why we stopped expecting that from electronics. reply shiroiushi 11 hours agorootparent>Not sure why we stopped expecting that from electronics. For TVs specifically, the technology changed a lot. For a long time, everyone was stuck on the NTSC standard, which didn't change much. At first, everyone had B&W TVs, so once you had one, there was no reason to change. Then color TV came out, so suddenly people wanted those. After that, again no reason to change for a long time. Later, they got remote controls, so sometimes people would want one of those, or maybe a bigger screen, but generally a working color TV was good enough. Because TVs were glass CRTs, bigger screens cost a lot more than smaller ones, and there wasn't much change in cost here for a long time. Then HDTV came out and now people wanted those, first in 720p, and later in 1080i/p. And flat screens came too, so people wanted those too. So in a relatively short amount of time, people went from old-style NTSC CRTs to seeing rapid improvements in resolution (480p->720p->1080->4k), screen size (going from ~20\" to 3x\", 4x\", 5x\", 6x\", now up to 85\"), and also display/color quality (LCD, plasma, QLED, OLED), so there were valid reasons to upgrade. The media quality (I hate the word \"content\") changed too, with programs being shot in HD, and lately 4k/HDR, so the difference was quite noticeable to viewers. Before long, the improvements are going to slow or stop. They already have 8k screens, but no one buys them because there's no media for them and they can't really see the difference from 4k. Even 1080p media looks great on a 4k screen with upscaling, and not that much different from 4k. The human eye is only capable of so much, so we're seeing diminishing returns. So I predict that this rapid upgrade cycle might be slowing, and probably stopping before long with the coming economic crash and Great Depression of 2025. The main driver of new TV sales will be people's old TVs dying from component failure. reply kstrauser 3 hours agorootparentGreat points. The TV I have today is approaching my platonic ideal screen. It‚Äôs as big as it can get without having to continually look around to see the whole screen. Sit in the first row of a movie theater to understand how that can be a bad thing. The pixels are smaller than I can see, it has great dynamic range, and the colors can be as saturated as I‚Äôd ever want. There‚Äôs not much that can be improved on it as a traditional flatscreen video monitor. reply bregma 7 hours agorootparentprev> The human eye is only capable of so much, so we're seeing diminishing returns. Or not seeing diminishing returns. Which is the point. reply Someone 4 hours agorootparentprev> At first, everyone had B&W TVs, so once you had one, there was no reason to change Televisions improved over time: - screens got flatter - screens got larger - image quality improved - image contrast increased (people used to close their curtains to watch tv) - televisions got preset channels reply robocat 23 minutes agorootparentprev> daily use for over 30 years However that doesn't imply TVs were that reliable. Before the 90s TV repairman was a regular job, and TVs often needed occasional expensive servicing. I remember a local TV repair place in the 90s which serviced \"old\" TVs. reply bloak 7 hours agorootparentprevMy experience of ancient CRT devices is that the display gets gradually dimmer. I once had a TV that was only really usable after dark -- but that's the only time I wanted to use it anyway -- and a huge Sun monitor that was only just about readable in total darkness, but we kept it because we also had a Sun server that we didn't know how to connect to any other monitor and we were worried that one day we wouldn't be able to SSH to it, but in fact the server never once failed. reply blitzar 9 hours agorootparentprev> Not sure why we stopped expecting that from electronics. Last years model only does 4k, my eyes need 8k reply xattt 8 hours agorootparent32K ought to be enough for anybody. reply blitzar 4 hours agorootparent32K is going to look so lifeless and dull after you try 64k. reply xattt 3 hours agorootparentWhen will the pixels start to approach erythrocyte-level density like on the Vision Pro? edit: Anywhere between 208K to 277K. reply eru 11 hours agorootparentprevBecause electronics got so much better so much faster, that the vast majority of customers did not want to use old hardware. Especially if customers allowing shorter lifetimes allowed companies to lower the prices. reply AnthonyMouse 11 hours agorootparentThere are many use cases for which a decade-old computer is still perfectly serviceable and even where they aren't, those computers can be repurposed for the ones that are. Moreover, we're talking about televisions and old Macs. TVs with higher resolutions might come out, but lower resolution ones continue to be sold new (implying demand exists at some price), and then why should anybody want to replace a functioning old TV with a newer one of the same resolution? Much older computers continue to be used because they run software that newer computers can't without emulation (which often introduces bugs) or have older physical interfaces compatible with other and often extremely expensive older hardware. If people actually wanted to replace their hardware instead of fixing it then they'd not be complaining about the inability to fix it. reply shiroiushi 10 hours agorootparent>There are many use cases for which a decade-old computer is still perfectly serviceable and even where they aren't, those computers can be repurposed for the ones that are. It depends. Older computers usually guzzle power, especially if you look at the absolutely awful Pentium4 systems. You're probably better off getting a RasPi or something, depending on what exactly you're trying to do. Newer systems have gotten much better with energy efficiency, so they'll pay for themselves quickly through lower electricity bills. >TVs with higher resolutions might come out, but lower resolution ones continue to be sold new (implying demand exists at some price) We're already seeing a limit here. 8k TVs are here now, but not very popular. There's almost no media in that resolution, and people can't tell the difference from 4k. For a while, this wasn't the case: people were upgrading from 480 to 720 to 1080 and now to 4k. >and then why should anybody want to replace a functioning old TV with a newer one of the same resolution? They probably don't; if they're upgrading, they're getting a higher resolution (lots of 1080 screens still out there), or they're getting a bigger screen. It's possible they might want newer smart TV features too: older sets probably have support dropped and don't support the latest streaming services, though usually you can just get an add-on device that plugs into the HDMI port so this is probably less of a factor. reply AnthonyMouse 42 minutes agorootparent> Older computers usually guzzle power, especially if you look at the absolutely awful Pentium4 systems. Even many Pentium 4-based systems would idle around 30 watts and peak at a little over 100, which is on par with a lot of modern desktops, and there were lower and higher power systems both then and now. The top end Pentium 4 had a TDP of 115W vs. 170W for the current top end Ryzen 9000 and even worse for current Intel. Midrange then and now was ~65W. Also, the Pentium 4 is twenty two years old. And the Pentium 4 in particular was an atypically inefficient CPU. The contemporaneous Pentium M was so much better that Intel soon after dumped the P4 in favor of a desktop CPU based on that (Core 2 Duo). Moreover, you're not going to be worried about electric bills for older phones or tablets withFor a while, this wasn't the case: people were upgrading from 480 to 720 to 1080 and now to 4k. Some people. Plenty of others who don't even care about 4k, and then why would they want to needlessly replace their existing TV? > They probably don't; if they're upgrading, they're getting a higher resolution (lots of 1080 screens still out there), or they're getting a bigger screen. That's the point. 1080p TVs and even some 720p TVs are still sold new, so anyone buying one isn't upgrading and has no real reason to want to replace their existing device unless it e.g. has a design flaw that causes it to catch fire. In which case they should do a proper recall. reply aero_code 1 hour agorootparentprev> Older computers usually guzzle power, especially if you look at the absolutely awful Pentium4 systems. https://en.wikipedia.org/wiki/List_of_Intel_Pentium_4_proces... The Northwood chips were 50 to 70 W. HT chips and later Prescott chips were more 80 to 90 W. Even the highest chips I see on the page are only 115 W. But modern chips can use way more power than Pentium 4 chips: https://en.wikipedia.org/wiki/Raptor_Lake The i5-14600K has a base TDP of 125 W and turbo TDP of 181 W, and the high-end i9-14900KS is 150 W base/253 W turbo. For example, when encoding video, the mid-range 14600K pulls 146 W: https://www.tomshardware.com/news/intel-core-i9-14900k-cpu-r... More recent processors can do more with the same power than older processors, but I think for the most part that doesn't matter. Most people don't keep their processor at 100% usage a lot anyway. reply ahoka 9 hours agorootparentprevA decade old CPU would be a Haswell, not a Pentium 4. reply nuancebydefault 5 hours agorootparentprevSuppose they would recall all the old tv's with known faults, can those be fixed to become conform to (today's) quality and safety standards, while being full of old components with characteristics beyond original tolerances? reply kbelder 12 hours agorootparentprev> that's well beyond the expected useful lifespan of even a modern TV, let alone an older model like these A modern TV may have an expected lifespan of five years. TVs from several decades ago had lifespans of... several decades. Quality has plummeted in that market. reply azinman2 11 hours agorootparent5 years? Is that really true? I‚Äôm currently using an LG from 2017 and cannot imagine needing to change it. I would be shocked if it stopped working. reply cmgbhm 5 hours agorootparentI have an LG about that vintage and it‚Äôs starting to black out when doing 4K content. All components before it switched out and up to date in firmware. Reatarting works, sometimes all day, sometimes 1 minute. My other TV about the same vintage is starting to have stuck pixels in the corner. Modern failure modes aren‚Äôt nearly as graceful. reply alias_neo 9 hours agorootparentprevI have an LG OLED from 2017. It started getting really bad screen burn/pixel degredation just after the 6 year mark (6 year warranty), I did a quick search on Youtube, and lo-and-behold, a whole bunch of other people, with the same model, started having the same screen burn-in issues at the same age! It covers the middle third of the screen, top to bottom, and the entire bottom 1/4 of the screen with some odd spots as well, it's really distracting and essentially makes the TV useless (to me). reply tverbeure 10 hours agorootparentprevI don't think it is true at all. There's nothing inside today's monitors or TVs that can't run for at least 10 years. Our main TV, 42\" 720p LCD, is from 2008, and I have monitors that are just as old. reply Supernaut 9 hours agorootparentYep. My TV, a 42\" Panasonic plasma, dates from 2009 and is still working perfectly. I haven't replaced it, because why would I? reply rvense 10 hours agorootparentprevBut when it does, it will probably be the capacitors in the power supply that have dried out. reply verzali 10 hours agorootparentIs that really the case? Because if so, it seems like simply replacing the capacitors would save a lot of waste and unnecessary purchases of new TVs... reply rvense 8 hours agorootparentThis is a very common fault, yes. Power supply issues in general. It is also not uncommon for people to replace e.g. Wifi routers because the wall warts fail. It comes down to a few people don't knowing a lot about it - and I'm not blaming anyone for that, we all have our interests and most people have more than enough to do already to worry about what goes on inside their stuff. Also, electronics are, to a lot of people in a lot of places, so cheap that they would rather just curse a little and buy a new thing, instead of bothering with taking the thing to a shop. And of course a few hours of skilled labour in a big city in the west might also be almost as expensive as making a whole new TV in a factory in Asia plus shipping, so it might not even make economic sense. reply xxs 7 hours agorootparentprevElectrolytic capacitors are not solid state and likely #1 failure mode for most electronics. There are options for better (e.g. Al polymer) capacitors that are rather expensive - overall good capacitors are 'expensive', e.g. more than a dollar a piece in some cases. The 2nd most common failure mode gotta be the mlcc (multi layer ceramic capacitor) cracks/shorts. reply nuancebydefault 5 hours agorootparentprevHow can I even know which capacitor is faulty? reply toast0 2 hours agorootparentIf your model was popular, there's likely a recap kit for its power supply. It usually makes senss to swap all the capacitors in the kit, unless the kit instructions say otherwise. You can look for physical signs of degredation (bulgy, leaky, discolored), but to really test a capacitor for capacititance, you need to take it out of the circuit, at which point, you may as well put a new, high quality capacitor in. The OEM capacitors may likely have a just right voltage rating, a new one with a higher voltage rating (and same capacitance, compatible type) may last longer in cirucit as well. reply xxs 35 minutes agorootparent> new one with a higher voltage rating (and same capacitance, compatible type) may last longer in cirucit as well. That's not necessarily true, higher voltage rating equals higher ESR which means more heat. reply xxs 3 hours agorootparentprevThat would require some experience, yet the most common visual clue would be 'bulging'. There are some ways to measure ESR w/o desoldering but they won't be reliable at all times. Measuring voltages, peak to peak, is a bit more work. reply Peanuts99 8 hours agorootparentprevA TV used to cost a few weeks pay and now you can get a TV for the equivalent of a few hours pay. There just isn't much of a market for a $3000+ TV. reply xxs 7 hours agorootparentFew usually means 3-5 or so, a half decent TV would be at least half a grand. That's rather high hourly pay rate. reply toast0 2 hours agorootparentExplain to me why this tv for $100 [1] isn't perfectly suitable to replace a 2008 40\" 1080p Samsung LCD with florescent backlight that 2was a deal at $1000. Yeah, you could get something bigger and better. Yes, price comparison on a sale week is a bit unfair. [1] https://www.bestbuy.com/site/tcl-40-class-s3-s-class-1080p-f... reply eru 11 hours agorootparentprevOnly one metric of 'quality' has plummeted. A rock lasts billions of years, but its quality as a TV is rather questionable. reply InsideOutSanta 10 hours agorootparentprev\"that's well beyond the expected useful lifespan of even a modern TV, let alone an older model like these\" People still run these Trinitron TVs to this day. reply bee_rider 11 hours agorootparentprevIt is a legitimate business decision, to sell things that last less than 20 years. Fine, I think it is lame, but it is their choice. But, we shouldn‚Äôt let companies get away with selling products that catch fire after working fine for 20 years. reply PittleyDunkin 9 hours agorootparentprev> that's well beyond the expected useful lifespan of even a modern TV What? That's nuts. Why bother buying a tv if you're immediately going to throw it in the trash reply wetpaws 13 hours agoparentprevFor 1993 hardware? reply Throw8394045 12 hours agoparentprevThey don't do recalls even on modern hardware. But soldering hacks are no longer possible, all parts are serialized. Louis Rossmann made many videos on this. reply shiroiushi 11 hours agorootparentWhat are you talking about? Capacitor technology hasn't changed substantially in decades, and it's just as possible to change caps with a soldering iron now as it was 20 years ago. I have no idea what you mean by \"serialized\". reply fragmede 11 hours agorootparentnot capacitors, but more advanced components, like the camera, have serial numbers embedded in them, and the serial number needs to match, otherwise it won't accept the component. Components off a stolen device are put on a list and won't work in admirer another phone, so stolen phones aren't even worth anything for parts, driving down the market for stolen phones. It also makes the job of repair shops harder, which is collateral damage in Apple's eyes, but is very much material for anyone running a repair shop. reply ethernot 10 hours agorootparentThe only reason this is an issue for repair shops is they can't sell you recycled stolen parts at bottom of market prices for a sky high mark up. On top of that the \"non genuine parts\", some of which really are utterly dire, show up in the OS as being not genuine parts. Buying genuine parts, which are available from Apple, eats into the margins. There is very little honour in the repair market, despite the makeup applied to it by a couple of prominent youtubers and organisations. The amount of horror stories I've seen over the years from independent repairers is just terrible. Just last year a friend had a screen hot snotted back on their Galaxy. reply liontwist 9 hours agorootparent> they can't sell you recycled stolen parts at bottom of market prices for a sky high mark up What represents a more efficient economy. The one where broken phones get reused for parts or the one where you have to throw them away? reply ethernot 8 hours agorootparentThe economy that isn't backed with criminal activity and loss for customers. reply moooo99 3 hours agorootparentprev> The only reason this is an issue for repair shops is they can't sell you recycled stolen parts at bottom of market prices for a sky high mark up. This is just incredibly dishonest framing and completely ignoring what the right to repair and third party repair shop issue is all about. > Buying genuine parts, which are available from Apple, It is not a margin problem, it is an availability problem. Apple does not allow third party repair shops to stock common parts, such as batteries or displays for popular iPhones. This is only possible when providing the devices serial numbers. This effectively prevents third party repair shops from competing with Apple or Apple authorized service providers because they have artificially inflated lead times. Becoming Apple authorized isn't an option for actual repair shops because that would effectively disallow them from doing actual repairs when possible, rather than playing Dr. Part Swap. Everything what Apple does in the repair space essentially boils down to them doing everything they can to avoid having competition in the repair space. > eats into the margins Replacing a 45ct voltage regulator on a mainboard is cheaper than replacing the entire mainboard with everything soldered on is cheaper, but doesn't allow for very nice margins. > There is very little honour in the repair market There is very little honour in any market. Honour does not get rewarded nowadays, people are into make money, if you're lucky they still take a little pride in their work. If a repair shop offers good service or not should be up to the consumer to determine, not up to Apple (or any electriconics manufacturer that employs the same tactics). > makeup applied to it by a couple of prominent youtubers and organisations. That is called marketing, that's what Apple does also pretty good. They're also lying when they say they are environmentally conscious while they also have their genius bar employees recommend an entirely new screen assembly on a MacBook just because a backlight cable came loose. > The amount of horror stories I've seen over the years from independent repairers is just terrible. J The amount of horror stories I have experienced with Apple is no joke either. Apple is always taking the sledgehammer approach with their repairs. I've had the pleasure myself to deal with Apple repairs once for my old 2019 MBP. It wouldn't take a charge anymore, went to the Genius Bar and received a quote for a new mainboard costing well over 1000 EUR. Being familiar with some of the more technical videos of Rossmann etc, I found one electronics repair store that actually does board level stuff and got it fixed for a fraction of the price (iirc it was ~200 EUR). reply cosmic_cheese 1 hour agorootparentEven if Apple has room for improvement here, I think it‚Äôs still worth it to try to curb the market for stolen parts, because that‚Äôs going to exist even if Apple sold spare parts in bulk at-cost simply because there exist unscrupulous repair shops that have no qualms with charging you OEM part prices while using gray market parts that cost a fraction as much on eBay, Aliexpress, etc. For instance, maybe Apple could supply parts in bulk to repair shops but require registration of those parts prior to usage. The repaired iPhone would function regardless but loudly alert the user that unregistered parts were used to repair it. Gray market parts naturally aren‚Äôt going to be able to be registered (either due to serial not existing in their system or having been parted out from stolen devices), and thus the user is given some level of assurance that they‚Äôre not paid for questionable repair services. reply shiroiushi 11 hours agorootparentprevI see. Yes, that is a big problem for component swapping. I was just thinking of electronics with old/faulty caps; those will still be repairable. reply pkolaczk 11 hours agorootparentprevDoesn‚Äôt Apple offer a way to re-pair components if they are genuine and not stolen (unregistered from the previous AppleId)? reply fragmede 11 hours agorootparentand Apple will very happily charge you for that privilege reply jajko 10 hours agorootparentTBH for such a critical piece of our modern lives, I would be more than fine to pay extra to be 100% sure I am getting original parts, put in professionally and in secure manner re my personal data. I wish ie Samsung had such service where I live. We anyway talk about expensive premium phones to start with, so relatively expensive after-warranty service is not shocking. This may actually eventually sway me into apple camp. This and what seems like much better theft discouragement. reply raxxorraxor 6 hours agorootparentI don't. Such mechanisms also disqualify 3rd party replacements. It is just a wasteful solution. Not that any smartphone would qualify as decent here. But as a customer it will overall be more expensive for you. reply raxxorraxor 7 hours agorootparentprevIt is not about stolen phones, it is about monetization of customer services. If stealing phones was legal, job description for procurement/purchase departments would look differently as well. reply PcChip 1 hour agoprevDidn‚Äôt this also happen on some Asus motherboards a couple years ago? reply robomartin 4 hours agoprevBrings back memories‚Ä¶ About 30 years ago I designed my first PCB with frequencies in the GHz range. It was full of challenging transmission line paths with frequencies in the hundreds of MHz and above. I am still proud of the fact that all of the high speed signals worked as designed, with excellent signal and power integrity (the large FPGA was challenging). Emissions passed as well. I did, however, screw up one thing: DC I somehow managed to layout the DC input connector backwards! These boards were very expensive ($2K), so an immediate respin was not possible. I had to design a set of contacts to be able to flip the connector upside-down and make the electrons go in the right way. The joke from that point forward was that I was great at multi-GHz designs but should not be trusted with DC circuits. reply likeabatterycar 9 hours agoprevThe author seems to misunderstand PCB design flow. This is neither a \"factory component placement issue\" nor a silkscreen error. The error is in the schematic. The layout CAD is often done by a different team that follows the schematic provided by design engineering. Automated workflows are common. The silk screen is predefined in a QA'd library. It is not their job to double check engineering's schematic. The components are placed per the layout data. Both those teams did their jobs correctly, to incorrect specifications. In fact, the factory performing assembly often is denied access to the schematic as it is sensitive IP. If you're going to cast blame on a 30 year old computer, at least direct it at the correct group. It wasn't soldered incorrectly at the factory. They soldered it exactly how they were told to - backwards. reply rcxdude 8 hours agoparent>The layout CAD is often done by a different team that follows the schematic provided by design engineering. Just as a note, this is a fairly archaic way of working nowadays. At my place schematic design and layout go hand-in-hand, and we rejected a candidate because he didn't do the latter. The main reason is layout is no longer an afterthought, it's a key part of the electrical design of the system, and there's little room for a tedious back and forth between the circuit designer and the person doing the layout about what traces are and aren't important to optimize for various attributes. reply analog31 5 hours agorootparentIndeed, and this is true in other engineering activities such as mechanical design as well. Possibly with the exception of very large shops, there are no draftsmen any more, and the design engineer also creates the production drawings. And the software lends itself to this. Schematic / layout, and design / drawing, are joined together in the design software. It would be very hard to make a mistake like the one in TFA today. Even the free software that I use -- KiCad -- would ding me. We make bigger mistakes instead. ;-) reply jimnotgym 7 hours agorootparentprevAnd yet it is not at all unusual for a production engineer to spot these faults and pass them back to the design engineers for rework. reply rcxdude 7 hours agorootparentAlso true! Most common when you accidentally screw up a footprint and it doesn't fit the part on the BOM. A backwards part is the kind of thing they're not likely to pick up on (if it's marked on the silkscreen incorrectly, at least), but some do. reply andrew-jack 9 hours agoprevApple should be mandated to issue a recall for these motherboards. reply etrautmann 6 hours agoprevThe first board I ever designed and had manufactured had a reversed tantalum capacitor on the power rails and exploded somewhat dramatically when powered up. Lesson learned! reply mhardcastle 4 hours agoprevWhy include that capacitor at all if it doesn't matter whether it works? reply rwmj 3 hours agoparentIf you look at the traces you can see the capacitor is right next to the power connector, on the -5V rail (which is not used for much, only for the RS422 serial port). The capacitor will be there to smooth the power supply when the machine is just switched on, or there's a sudden load which causes the voltage to \"dip\" above -5V. Basically it's like a tiny rechargable battery which sits fully charged most of the time, but can supplement the power on demand. So you can see why it probably didn't matter that this capacitor didn't work: It's only needed for rare occasions. RS-422 is a differential form of RS-232 (https://en.wikipedia.org/wiki/RS-422) so being differential it's fairly robust against changes in load if they affect both wires. And the worst that can happen is you lose a few characters from your external modem. In addition, electrolytics can probably work when reversed like this, at least a little bit. It's not exactly optimal and they might catch fire(!). reply _whiteCaps_ 2 hours agoparentprevAlso known as the Madman Muntz theory of Engineering :-) https://en.wikipedia.org/wiki/Muntzing reply qingcharles 1 hour agorootparentI never knew there was a name for this :) When I was a demo coder my artist friend would just haphazardly go through all my assembler code and snip random lines out until it stopped working to improve performance. reply rasz 12 hours agoprevCommodore struggled with same mistakes on negative rail in Audio section, but also somehow on highend expensive CPU board. https://wiki.console5.com/wiki/Amiga_CD32 C408 C811 \"original may be installed backwards! Verify orientation against cap map\" A4000 https://wordpress.hertell.nu/?p=1438 C443 C433 \"notice that the 2 capacitors that originally on A4000 have the wrong polarity\" Much worse is Commodore A3640 68040 CPU board aimed at top of the line A3000 and A4000 http://amiga.serveftp.net/A3640_capacitor.html https://forum.amiga.org/index.php?topic=73570.0 C105 C106 C107 silkscreen wrong, early revisions build according to bad silkscreen. reply fredoralive 12 hours agoparentTypical Amiga fanboyism and Apple envy, if a Mac does something they have to prove the Amiga outdid it. ‚ÄúOnly one model with a reverse polarity capacitor? With Commodore it was a systematic issue!‚Äù reply bogantech 8 hours agorootparent> Typical Amiga fanboyism and Apple envy, if a Mac does something they have to prove the Amiga outdid it. I think we're envious that Apple did a better job of engineering their systems reply Animats 11 hours agoprevDoes the -5V rail do anything other than power old RS-232 ports? reply zargon 11 hours agoparentMacs have RS-422 ports, not RS-232. But, no. reply omoikane 11 hours agoprevI wonder if there were any bootleg boards that copied the silkscreen mistake, but didn't use those 16V capacitors, and ended up catching fire. reply lmpdev 8 hours agoprevI have my childhood LC II in storage I wonder if it has the same defect reply fishgoesblub 4 hours agoparentIf anything you should open it up to check for any leaking batteries/capacitors. reply Waterluvian 6 hours agoprevI spent my mid childhood on an LCIII. One summer my friend brought his Performa over and we tried to play 1v1 Warcraft 2 over the serial port. LocalTalk or something alike? But it just never quite worked right. I remember how frustrated and confused my older brother was. The computers would sometimes see each other but would drop off so easily. Was this that?! reply nsmog767 6 hours agoprevnot the Flux Capacitor?!?! reply hettygreen 12 hours agoprev [‚Äì] They were probably expecting these to fail a few months after the warranty expired. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Doug Brown highlights a manufacturing error in Apple's Macintosh LC III, where a capacitor was installed backwards, potentially causing issues.",
      "The Macintosh LC III, produced between 1993 and 1994 for the education market, did not undergo a major recall despite this error.",
      "Brown advises caution when replacing capacitors, especially with modern tantalum capacitors, and recommends installing them correctly, contrary to the PCB's silkscreen instructions."
    ],
    "commentSummary": [
      "Apple mistakenly installed a capacitor in reverse on a 34-year-old computer, highlighting the importance of correct capacitor orientation, especially for electrolytic capacitors, which have polarity and can fail if installed incorrectly.",
      "This incident has sparked discussions about product longevity and planned obsolescence, with some suggesting that modern electronics are intentionally designed to have shorter lifespans to boost sales.",
      "The situation is reminiscent of past manufacturing errors by other companies, such as Commodore, indicating a recurring issue in the tech industry."
    ],
    "points": 384,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1732684208
  },
  {
    "id": 42252336,
    "title": "I Didn't Need Kubernetes, and You Probably Don't Either",
    "originLink": "https://benhouston3d.com/blog/why-i-left-kubernetes-for-google-cloud-run",
    "originBody": "I Didn't Need Kubernetes, and You Probably Don't Either By Ben Houston, 2024-11-05 Kubernetes often represents the ultimate solution for container orchestration, but my experience has led me to leave it behind in favor of a simpler, cost-effective solution using Google Cloud Run. This transition has made my infrastructure projects easier to manage, more scalable, and significantly cheaper. Here‚Äôs why I made this choice and how Cloud Run offers a better fit for my needs going forward. How I ended up on Kubernetes First, let's quickly look at how we ended up on Kubernetes. We has launched Clara.io (now sunset), an online 3D editor and rendering platform, in 2013. We cost optimized the platform by using bare metal machines from OVH for both its primary servers, DBs and job workers. While it worked, bare metal machines were a source of potential failures and we did have some over the years. Luckily we had a redundant setup so our users never noticed. But it was a massive amount of work to provision, monitor and maintain. So when we looked to remake the platform for Threekit.com, an enterprise focused re-imaging of Clara.io, we looked to switch to a managed compute setup. At the time in 2018, Kubernetes was just emerging as the industry solution as Azure, AWS and Docker converged on it in late 2017. Why I Left Kubernetes At first, Kubernetes seemed like the right approach for managing services at scale. But as we lived with it over the years since 2018, it became apparent that the complexity and costs were significant. Here‚Äôs a breakdown of the challenges we encountered: Cost Overruns: Kubernetes comes with substantial infrastructure costs that go beyond DevOps and management time. The high cost arises from needing to provision a bare-bones cluster with redundant management nodes. Moreover, Kubernetes‚Äôs slow autoscaling meant I had to over-provision services to ensure availability, paying for unused resources rather than scaling based on demand. Difficulty Managing Large Job Volumes: Handling a high volume of jobs on Kubernetes is tedious. Both the built-in scheduler and Argo introduced limitations and complexity, often failing to scale well under load or just being really complex. Complexity Overload: Kubernetes is feature-rich, yet these ‚Äúenterprise‚Äù capabilities turned even simple tasks into protracted processes. The result was added complexity without substantial benefits, making it more of an obstacle than a solution. If you have Kubernetes, you probably need at least one dedicated Kubernetes dev-ops engineer, if not a couple. Overall, Kubernetes proved difficult to provision, expensive to maintain, and time-consuming to manage. For companies or individual projects seeking simplicity and cost-effectiveness, it may not be the right choice. But it did get rid of the need for us to keep track of whether the hardware in our machines was breaking down and our manual provision processing. Embracing Cloud Run for a Simpler Setup Google Cloud Run offers a streamlined alternative to Kubernetes. Here‚Äôs how my new setup works: The Setup My infrastructure is now centered around Docker containers, with some running as auto-scaling services and others as tasks for long-running jobs. Google Cloud Run handles container deployment, scaling, downtime management, and running/retrying jobs eliminating many of the challenges I faced with Kubernetes. Why Cloud Run Is Ideal Cost Efficiency: Cloud Run charges only for the CPU and memory used during requests, making it highly cost-effective. For example, this personal project of mine, Web3D Survey sees 500,000 hits monthly and costs just $4/month for hosting, even though it is running all the time. They key is that Cloud Run charges based on the fraction of the CPU you use per second. The ability to scale to zero also means no charges for idle services. Fast, Reliable Autoscaling: Cloud Run scales in a few seconds, unlike Kubernetes, where scaling often took minutes. This quick scaling lets me handle surges reliably without over-provisioning. No Kubernetes Management Overhead: Cloud Run, built atop Google‚Äôs Borg, avoids the need for Kubernetes cluster management, simplifying deployments and cutting costs. Simple Async Tasks: Cloud Run Tasks allows me to execute up to 10,000 tasks per job, track their results with auto-retries with no need to manage job-running infrastructure or individual machines ‚Äî a refreshing alternative to the complexity running this on Kubernetes was. The Kubernetes Lock-In Trap One overlooked downside of Kubernetes is cluster lock-in. Once you start using Kubernetes-specific features, it becomes challenging to leverage resources outside the cluster. Integrating services across data centers or using dedicated resources in a colocation setup adds significant complexity. Kubernetes demands you stay within its ecosystem, effectively binding you to the infrastructure that supports it, making even simple expansions or migrations into costly, complex endeavors. Addressing Common Concerns Several questions arose from others when I shared my experience online, so here‚Äôs a deeper look into how this setup works: Orchestration: I use GitHub Actions CI to handle CI/CD, leveraging workflows with dependencies and matrix strategies for builds across multiple services which only deploy if all tests/builds are successful. Storage: Managed databases or Cloud Storage cover shared data needs, eliminating the need to manage my own disks. Inter-Service Communication: For async communication, I leverage pub-sub messaging. When direct connections are absolutely necessary, each service has a dedicated domain-name. Security: Cloud Run supports internal-only services, and for public services, I secure routes using JWT. Debunking Misconceptions ‚ÄúAren‚Äôt You Afraid of Being Locked into GCP?‚Äù Switching cloud providers, such as AWS, wouldn‚Äôt be overly complex since my setup is Docker-based, and migration would take about a week. In practice, few companies switch providers unless politics are involved, as the differences between major cloud services are minimal. ‚ÄúCloud Run Is Just Managed Kubernetes, Right?‚Äù Technically, Cloud Run uses Knative interfaces but runs on top of Google‚Äôs Borg, rather than Kubernetes. But it could have been implemented on top of Kubernetes and I think similar PaaS systems are implemented on Kubernetes. The key is that I am not using Kubernetes or Borg, I am using a simplified PaaS system that has an opinionated and simple interface that fits my needs. Remaining Workflow Pains There are some pains I have with my current Cloud Run development workflow: Arbitrary Management of Services Names I do find that I need to manage my service names both locally and in the server in a unified way with clear configuration. Basically an abstraction layer. I know Kubernetes has one and I do miss that. Lack of Cloud Run Task Emulation There is no solution for running Cloud Run Tasks locally that I have found. I would like it to be able to just run an arbitrary command line locally in place of a docker container in a locally emulated Cloud Run Tasks environment that captures log output, trackings runs, etc. This would simplify development of tasks without having to build and deploy docker containers. My New Stack and Workflow My infrastructure is built around a reliable stack. You can view a simplistic prototype setup and practices in this TypeScript monorepo template. Cloud Run enables me to deploy this stack efficiently, without the complexity or cost overheads Kubernetes brought. Final Thoughts For my projects, Cloud Run offers the perfect blend of cost savings, speed, scalability, and simplicity. While Kubernetes may suit some large enterprises, for agile projects where simplicity and efficiency matter, the managed environment of Cloud Run is transformative. If your infrastructure goals include reduced DevOps overhead, predictable costs, and responsive scaling, Cloud Run may be the solution you‚Äôve been looking for. (PS. Yes, I am sure there was another library/extension I should have added to Kubernetes to enable feature X, Y or Z, but this really is just further increasing the complexity. I don't want to have to exist inside of world of Kubernetes-specific lingo and techniques if they are not giving me benefits.) This post was inspired by this discussion on Hacker News on 04/11/2025",
    "commentLink": "https://news.ycombinator.com/item?id=42252336",
    "commentBody": "I Didn't Need Kubernetes, and You Probably Don't Either (benhouston3d.com)321 points by bhouston 16 hours agohidepastfavorite376 comments tombert 13 hours agoI‚Äôve come to the conclusion that I hate ‚Äúcloud shit‚Äù, and a small part of me is convinced that literally no one actually likes it, and everyone is playing a joke on me. I have set up about a dozen rack mount servers in my life, installing basically every flavor of Unix and Linux and message busses under the sun in the process, but I still get confused by all the Kubectl commands and GCP integration with it. I might just be stupid, but it feels like all I ever do with Kubernetes is update and break YAML files, and then spend a day fixing them by copy-pasting increasingly-convoluted things on stackexchange. I cannot imagine how anyone goes to work and actually enjoys working in Kubernetes, though I guess someone must in terms of ‚Äúlaw of large numbers‚Äù. If I ever start a company, I am going to work my damndest to avoid ‚Äúcloud integration crap‚Äù as possible. Just have a VM or a physical server and let me install everything myself. If I get to tens of millions of users, maybe I‚Äôll worry about it then. reply voidfunc 13 hours agoparentI'm always kind of blown away by experiences like this. Admittedly, I've been using Kubernetes since the early days and I manage an Infra team that operates a couple thousand self-managed Kubernetes clusters so... expert blindness at work. Before that I did everything from golden images to pushing changes via rsync and kicking a script to deploy. Maybe it's because I adopted early and have grown with the technology it all just makes sense? It's not that complicated if you limit yourself to the core stuff. Maybe I need to write a book like \"Kubernetes for Greybeards\" or something like that. What does fucking kill me in the Kubernetes ecosystem is the amount of add-on crap that is pitched as \"necessary\". Sidecars... so many sidecars. Please stop. There's way too much vendor garbage surrounding the ecosystem and dev's rarely stop to think about whether they should deploy something when it's easy as dropping in some YAML and letting the cluster magically run it. reply jq-r 10 hours agorootparentThose \"necessary\" add-ons and sidecars are out of control, but its the people problem. I'm part of the infra team and we manage just couple of k8s clusters, but those are quite big and have very high traffic load. The k8s + terraform code is simple, with no hacks, reliable and easy to upgrade. Our devs love it, we love it too and all of this makes my job pleasant and as little stressful as possible. But we recently hired a staff engineer to the team (now the most senior) and the guy just cannot rest still. \"Oh we need a service mesh because we need visibility! I've been using it on my previous job and its the best thing ever.\" Even though we have all the visibility/metrics that we need and never needed more than that. Then its \"we need a different ingress controller, X is crap Y surely is much better!\" etc. So its not inexperienced engineers wanting newest hotness because they have no idea how to solve stuff with the tools they have, its sometimes senior engineers trying to justify their salary, \"seniority\" by buying into complexity as they try to make themselves irreplaceable. reply ysofunny 7 hours agorootparent> Then its \"we need a different ingress controller, X is crap Y surely is much better!\" etc. I regard these as traits of a junior dev. they're thinking technology-first, not problem-first reply jppittma 8 hours agorootparentprevService mesh is complicated, but the reason you use it integrate services across clusters. That and it has a bunch of useful reverse proxy features. On the other hand, It took me and 2 other guys two evenings of blood, sweat, and tears to understand what the fuck a virtual service actually does. It‚Äôs not strictly necessary, but if you‚Äôve had to put in the work elsewhere, I‚Äôd use it. reply cyberpunk 8 hours agorootparentprevTo be fair, istio and cilium are extremely useful tools to have under your belt. There‚Äôs always a period of ‚Äúomgwhat‚Äù when new senior engineers join and they want to improve things. There‚Äôs a short window between joining and getting bogged into a million projects where this is possible. Embrace it I recon. reply p_l 2 hours agorootparentDoing it well IMO requires not deploying everything as sidecar but maybe, maybe, deploying it as shared node service. In fact pretty sure I've read a write up from Alibaba? on huge wins in performance due to moving Istio out of sidecar and into shared node service. reply cyberpunk 1 hour agorootparentSure, cilium is also much faster than istio. But I guess it depends on your workload. We don't care all that much about performance vs compliance (non-hft finance transactional stuff) and I think we're doing things reasonably well. :} reply p_l 39 minutes agorootparentI didn't mean replace istio with cilium, I meant running the proxy and routing operations as shared part per node instead of per pod reply cyberpunk 23 minutes agorootparentHow does that even work with envoy? The magic sauce behind istio is that every connection is terminated using iptables into the envoy process (sidecar), and istiod spaffs envoy configurations around the place based on your vs/dr/pas/access controls etc. I suppose you could have a giant envoy and have all the proxy-configs all mashed together but I really don't see any benefit to it? I can't even find documentation that says it's possible.. reply p_l 14 minutes agorootparentCouldn't check all details yet, but from quick recap: It's called ambient mode, and uses separate L4 and L7 processing on ways that would be familiar to people who dealt with virtual network functions - and neither l4 nor l7 parts require sidecar withinboredom 7 hours agorootparentprev> So its not inexperienced engineers wanting newest hotness because they have no idea how to solve stuff with the tools they have, its sometimes senior engineers trying to justify their salary, \"seniority\" by buying into complexity as they try to make themselves irreplaceable. The grass is always greener where you water it. They joined your company because the grass was greener there than anywhere else they could get an offer at. They want to keep it that way or make it even greener. Assuming that someone is doing something to become 'irreplaceable' is probably not healthy. reply zelphirkalt 1 hour agorootparentThey want to make it \"greener\" for whom? I think that is the question. reply withinboredom 23 minutes agorootparentWherever they came from, I suppose. There‚Äôs a reason they left. reply monooso 6 hours agorootparentprevI really don't understand this comment. reply alienchow 8 hours agorootparentprevHow do you scale mTLS ops when the CISO comes knocking? reply carlmr 9 hours agorootparentprev>expert blindness at work. >It's not that complicated if you limit yourself to the core stuff. Isn't this the core problem with a lot of technologies. There's a right way to use it, but most ways are wrong. An expert will not look left and right anymore, but to anyone entering the technology with fresh eyes it's a field with abundance of landmines to navigate around. It's simply bad UX and documentation. It could probably be better. But now it's too late to change everything because you'd annoy all the experts. >There's way too much vendor garbage surrounding the ecosystem Azure has been especially bad in this regard. Poorly documented in all respects, too many confusing UI menus that have similar or same names and do different things. If you use Azure Kubernetes the wrapper makes it much harder to learn the \"core essentials\". It's better to run minkube and get to know k8s first. Even then a lot of the Azure stuff remains confusing. reply wruza 8 hours agorootparentThis and a terminology rug pull. You wanted to upload a script and install some deps? Here‚Äôs your provisioning genuination frobnicator tutorial, at the end of which you‚Äôll learn how to maintain the coalescing encabulation for your appliance unit schema, which is needed for automatic upload. It always feels like thousands times bigger complexity (just in this part!) than your whole project. reply rbanffy 5 hours agorootparentprev> There's a right way to use it, but most ways are wrong. This is my biggest complaint. There is no simple obvious way to set it up. There is no \"sane default\" config. > It's better to run minkube and get to know k8s first. Indeed. It should be trivial to set up a cluster from bare metal - nothing more than a `dnf install` and some other command to configure core functionality and to join machines into that cluster. Even when you go the easy way (with, say, Docker Desktop) you need to do a lot of steps just to have an ingress router. reply zelphirkalt 1 hour agorootparentThat is actually what my \"try out for a day\" experience with Nomad was years ago. Just run the VMs, connect them, and they auto load balance. While it took a week or so to get even the most basic stuff in Kubernetes and not even have 2 hosts in a cluster yet, while having to deal with hundreds of pages of bad documentation. I think since then the documentation probably has improved. I would hope so. But I will only touch Kubernetes again, when I need to. So maybe on a future job. reply p_l 2 hours agorootparentprevThe easy baremetal cluster these days is k3s. Includes working out of the box ingress controller. reply stiray 12 hours agorootparentprevI would buy the book. Just translate all \"new language\" concepts into well known concepts from networking and system administration. It would be best seller. If I would only have a penny for each time I wasted hours trying to figure out what something in \"modern IT\" is, just to figure out that I already knew what it is, but it was well hidden under layers of newspeak... reply deivid 10 hours agorootparentThis[0] is my take on something like that, but I'm no k8s expert -- the post documents my first contact with k8s and what/how I understood these concepts, from a sysadmin/SWE perspective. [0]: https://blog.davidv.dev/posts/first-contact-with-k8s/ reply MonkeyClub 6 hours agorootparentAnd its related HN thread: https://news.ycombinator.com/item?id=41093197 reply radicalbyte 11 hours agorootparentprevThe book I read on K8S written by a core maintainer made is very clear. reply c03 11 hours agorootparentPlease don't mention it's name, we don't want anyone else reading it.. reply radicalbyte 7 hours agorootparentKubernetes in Action (I didn't have access to my email or Amazon account let alone my office when I posted so couldn't check the name of the book). reply jpalomaki 11 hours agorootparentprevIs it this one, Kubernetes: Up and Running, 3rd Edition by Brendan Burns, Joe Beda, Kelsey Hightower, Lachlan Evenson from 2022? https://www.oreilly.com/library/view/kubernetes-up-and/97810... (edit: found the 3rd edition) reply radicalbyte 7 hours agorootparentNo, Kubernetes in Action, but that book was also on my radar (mainly as Kelsey Hightower's name reminds me of the Police Academy films I loved as a kid). reply schnirz 11 hours agorootparentprevWhich book would that be, out of interest? reply radicalbyte 7 hours agorootparentKubernetes in Action reply t-writescode 12 hours agorootparentprev> Admittedly, I've been using Kubernetes since the early days and I manage an Infra team I think this is where the big difference is. If you're leading a team and introduced all good practices from the start, then the k8s and Terraform or whatever config files can never get so very complicated that a Gordian knot isn't created. Perhaps k8s is nice and easy to use - many of the commands certainly are, in my experience. Developers have, over years and decades, learned how to navigate code and hop from definition to definition, climbing the tree and learning the language they're operating in, and most of the languages follow similar-enough patterns that they can crawl around. Configuring a k8s cluster has absolutely none of that knowledge built up; and, reading something that has rough practices is not a good place to learn what it should look like. reply paddy_m 8 hours agorootparentThank you. I can always xargs grep for a function name, at worst. Dir() in python at a debugger for other things. With YAML, kubernetes and other devops hotness, I frequently can‚Äôt even find the relevant scripts/YAML that are executed nor their codebases. This also happens with configuration based packaging setups. Python hatch in particular, but sometimes node/webpack/rollup/vite. reply karmarepellent 10 hours agorootparentprevAgreed. The best thing we did back when we ran k8s clusters, was moving a few stateful services to dedicated VMs and keep the clusters for stateless services (the bulk) only. Running k8s for stateless services was an absolute bliss. At that time stateful services were somewhat harder to operate on k8s because statefulness (and all that it encapsulates) was kinda full of bugs. That may certainly have changed over the last few years. Maybe we just did it wrong. In any case if you focused on the core parts of k8s that were mature back then, k8s was (and is) a good thing. reply thiht 1 hour agorootparentprev> It's not that complicated if you limit yourself to the core stuff Completely agree. I use Kubernetes (basically just Deployments and CronJobs) because it makes deployments simple, reliable and standard, for a relatively low cost (assuming that I use a managed Kubernetes like GKE where I don‚Äôt need to care at all about the Kubernetes engine). Using Kubernetes as a developer is really not that hard, and it gives you no vendor lock-in in practice (every cloud provider has a Kubernetes offer) and easy replication. It‚Äôs not the only solution, not the simplest either, but it‚Äôs a good one. And if you already know Kubernetes, it doesn‚Äôt cost much to just use it. reply figassis 12 hours agorootparentprevThis, all the sidecars. Use kubernetes to run your app like you would without it, take advantage of the flexibility, avoid the extra complexity. Service discovery sidecars? Why not just use the out of the box dns features? reply tommica 12 hours agorootparentBecause new people don't know better - I've never used k8s, but have seen sidecars being promoted as a good thing, so I might have used them reply namaria 6 hours agorootparentMaybe the \"I've heard about\" approach to tooling is the problem here? reply tombert 2 hours agorootparentprevIf I had set up the infrastructure myself I'd probably have a different opinion on all of this stuff, but I came into this job where everything was set up for me. I don't know if it was don't \"incorrectly\", and I do fear that stating as such might get into territory adjacent to the \"no true Scotsman\" fallacy. I mostly just think that k8s integration with GCP is a huge pain in the ass, every time I have to touch it it's the worst part of me day. reply fragmede 2 hours agorootparentWhat about your integration makes it a huge pita? reply tombert 2 hours agorootparentIt's just a lot of stuff; we have a couple hundred services, and when I've had to add shit, it ends up with me updating like two hundred files. Infrastructure as code is great, but lets be honest, most people are not thoroughly reading through a PR with 200+ files. There's of course tpl files to help reduce duplication, and I'm grateful for that stuff when I can get it, but for one reason or another, I can't always do that. It's also not always clear to me which YAML corresponds to which service, though I think that might be more of an issue with our individual setup. reply pas 8 hours agorootparentprevMy problem is the brittleness. Sure, I am playing with fire (k3s, bare metal, cilium, direct assigned IP to Ingresses), but a few weeks ago on one cluster suddenly something stopped working in the external IP -> internal cluster IP network path. (And after a complete restart things got worse. Oops. Well okay time to test backups.) reply coldtea 7 hours agorootparentprev>Before that I did everything from golden images to pushing changes via rsync and kicking a script to deploy. Sounds like a great KISS solution. Why did it regress into Kubernetes? reply mitjam 11 hours agorootparentprevAbsolutely, a reasonably sophisticated scalable app platform looks like a half-baked and undocumented reimagination of Kubernetes. Admittedly: The ecosystem is huge and less is more in most cases, but the foundation is cohesive and sane. Would love to read the k8s for greybeards book. reply coldtea 7 hours agorootparent>Absolutely, a reasonably sophisticated scalable app platform looks like a half-baked and undocumented reimagination of Kubernetes. Or maybe Kubernetes looks like a committee designed, everything and the kitchen sink, over-engineered, second system effect, second system effect suffering, YAGNI P.O.S., that only the kind of \"enterprise\" mindset that really enjoyed J2EE in 2004 and XML/SOAP vs JSON/REST would love... reply p_l 6 hours agorootparentYou misspelled DCOS /s reply cryptonym 9 hours agorootparentprevK8S is a beast and the ecosystem is wild. Newcomer won't know how to proceed to keep things simple, while still understanding everything that is being used. reply BiteCode_dev 10 hours agorootparentprevWould buy. But you probably should teach a few live courses before writing it because of expert blindness. Otherwise you will miss thr mark. Would pay for a decent remote live course intro. reply awestroke 10 hours agorootparentprevI would buy that book in a heartbeat. All documentation and guides on kubernetes seem to assume you already know why things are done a certain way reply DanielHB 10 hours agorootparentprev> What does fucking kill me in the Kubernetes ecosystem is the amount of add-on crap that is pitched as \"necessary\". Sidecars... so many sidecars. Yeah it is the same with terraform modules, I was trying to argument at a previous job that we should stick to a single module (the cloud provider module) but people just love adding crap if it saves them 5 lines of configuration. Said crap of course adding tons of unnecessary resources in your cloud that no one understands. reply theptrk 12 hours agorootparentprevI would pay for the outline of this book. reply quietbritishjim 8 hours agorootparentprevI hardly know the first thing about Kubernetes or cloud, so maybe you can help explain something to me: There's another Kubernetes post on the front page of HN at the moment, where they complain it's too complex and they had to stop using it. The comments are really laying into the article author because they used almost 50 clusters. Of course they were having trouble, the comments say, if you introduce that much complexity. They should only need one single cluster (maybe also a backup and a dev one at most). That's the whole point. But then here you are saying your team \"operates a couple thousand\" clusters. If 50 is far too many, and bound to be unmanageable, how is it reasonable to have more than a thousand? reply voidfunc 5 hours agorootparent> But then here you are saying your team \"operates a couple thousand\" clusters. If 50 is far too many, and bound to be unmanageable, how is it reasonable to have more than a thousand? It's not unmanageable to have a couple thousand Kube clusters but you need to have the resources to build a staff and tool chain to support that, which most companies cannot do. Clusters are how we shard our customer workloads (a workload being say a dozen services and a database, a customer may have many workloads spread across the entire fleet). We put between 100 and 150 workloads per cluster. What this gives us is a relatively small impact area if a single cluster becomes problematic as it only impacts the workloads on it. reply jalk 5 hours agorootparentprevSounds like it's their primary job is to manage clusters for others, which ofc is different from trying to manage your primary service, that you deployed as 50 microservices in individual clusters (didn't read the other article) reply adastra22 12 hours agorootparentprevI would buy that book. reply AtlasBarfed 12 hours agorootparentprevSo you don't run any databases in those thousands of clusters? To your point, and I have not used k8s I just started to research it when my former company was thinking about shoehorning cassandra into k8s... But there was dogma around not allowing access to VM command exec via kubectl, while I basically needed it in the basic mode for certain one-off diagnosis needs and nodetool stuff... And yes, some of the floated stuff was \"use sidecars\" which also seemed to architect complexity for dogma's sake. reply voidfunc 12 hours agorootparent> So you don't run any databases in those thousands of clusters? We do, but not of the SQL variety (that I am aware of). We have persistent key-value and document store databases hosted in these clusters. SQL databases are off-loaded to managed offering's in the cloud. Admittedly, this does simplify a lot of problems for us. reply tayo42 12 hours agorootparentHow much data? I keep hearing k8s isn't usable becasue sometimes there is to much data and it can't be moved around. reply darkstar_16 9 hours agorootparentIn the managed k8s space, the data is on a PVC in the same availability zone as the node it is being mounted on. If the node dies, the volume is just mounted on to a new node in the same zone. There is no data movement required. reply eek04_ 9 hours agorootparentprevWhile I've not played with k8, I did run stuff in Google's Borg for a very long while, and that has a similar architecture. My team was petabyte scale and we were far from the team with the largest footprint. So it is clearly possible to handle large scale data in this type of architecture. reply pletnes 11 hours agorootparentprevThe simplest approach I‚Äôm aware of is to create the k8s cluster and databases in the same datacenter / availability zone. reply pas 8 hours agorootparentprevpostgresql operators are pretty nice, so it makes sense to run stateful stuff on k8s (ie. for CI, testing, staging, dev, etc.. and probably even for prod if there's a need to orchestrate shards) > exec kubectl exec is good, and it's possible to audit access (ie. get kubectl exec events with arguments logged) and I guess and admissions webhook can filter the allowed commands but IMHO it's shouldn't be necessary, the bastion host where the \"kubectl exec\" is run from should be accessible only through an SSH session recorder reply khafra 7 hours agorootparentprevContainer orchestration is second nature to us SRE's, so it's easy to forget that the average dev probably only knows the syntax for deployments and one or two service manifests. And pods, of course reply pdimitar 2 hours agorootparentA factor for sure, but as a programmer I find that the discoverability of stuff in code is much higher than with k8s. Give me access to a repo full of YAML files and I'm truly and completely lost and wouldn't even know where to begin. YAML is simply not the right tool for this job. Sure you got used to it but that's exactly the point: you had to get used to it. It was not intuitive and it did not come naturally to you. reply torginus 9 hours agoparentprevKubernetes starts sucking at first sight and is kind of the sign of the ailment of modern times. Let me try to explain: First, you encounter the biggest impedance mismatch between cloud and on prem: Kubernetes works with pods, while AWS works with instances as the unit of useful work, so they must map to each other, right? Wrong, first each instance needs to run a Kubernetes node, which duplicates the management infrastructure hosted by AWS, and reduces the support for granularity, like if I need 4 cores for my workload, I start an instance with 4 cores, right?. Not so with k8s, you have to start up a big node, then schedule pods there. Yay, extra complexity and overhead! And it's like when you need 3 carrots for the meal your cooking, but the store only sells it in packs of 8, you have to pay for the ones you don't need, and then figure out how to utilize the waste. I'm not even going to talk about on-prem kubernetes, as I've never seen anyone IRL use it. Another thing is that the need for kubernetes is manifestation of crappy modern dev culture. If you wrote your server in node, Python and Ruby, you're running a single threaded app in the era of even laptops having 32 core CPUs. And individual instances are slow, so you're even more dependent on scaling. So, to make use of the extra CPU power, you're forced to turn to Docker/k8s and scale your infra that way, whereas if you went with something like Go, or god forbid, something as deeply uncool as ASP.NET, you could just put your 32 core server, and you get fast single threaded perf, and perfect and simple multi-threaded utilization out of the box without any of the headaches. Also I've found stuff like rolling updates to be a gimmick. Also a huge disclaimer, I don't think k8s is a fundamentally sucky or stupid thing, it's just I've never seen it used as a beneficial architectural pattern in practice. reply erinaceousjones 8 hours agorootparentBeing nitpicky about Python specifically, Python not necessarily single-threaded; gunicorn gets you a multiprocess HTTP/WSGI server if you configure it to. asyncio and gevent have made it easier to do things actually-concurrently. Judicious use of generator functions lets you stream results back instead of blocking I/O for big chunks. And we have threads. Yeah, the Global Interpreter Lock is still hanging around, it's not the fastest language, but there are ways to produce a Docker image of an API written in Python which can handle thousands of concurrent HTTP requests and actively use all available CPU cores to do intensive computation. reply zelphirkalt 1 hour agorootparentHere I thought you would bring multiprocessing and process pool in Python. reply regularfry 8 hours agorootparentprevIt really, really wants a higher-level abstraction layer over the top of it. I can see how you'd build something heroku-like with it, but exposing app developers to it just seems cruel. reply switch007 7 hours agorootparent> I can see how you'd build something heroku-like with it That's what many teams end up half-arsing without realising they're attempting to build a PaaS. They adopt K8S thinking it's almost 90% a PaaS. It's not. They continue hiring, building a DevOps team just to handle K8S infrastructure things, then a Platform team to build the PaaS on top of it. Then because so many people have jobs, nobody at this point wants to make an argument that perhaps using an actual PaaS might make sense. Not to mention \"the sunk cost\" of the DIY PaaS. Then on top of that, realising they've built a platform mostly designed for microservices, everything then must become a microservice. 'Monolith' is a banned word. Argh reply torginus 7 hours agorootparentprevThing is, k8s is already an abstraction layer on top of something like AWS or GCP reply ndjdjddjsjj 6 hours agorootparentprevRun a node process on each core? reply mrweasel 9 hours agoparentprevI wouldn't throw \"cloud shit\" in the same bucket as Kubernetes. Professional cloud services are mostly great, but super expensive. Kubernetes is interesting, because it basically takes everything you know and sort of pushes it down the stack (or up, depending on your viewpoint). To some extend I get the impression that the idea was: Wouldn't it be great if we took all the infrastructure stuff, and just merged the whole thing into one tool, which you can configure using a completely unsuitable markup language. The answer is that \"No, that would in fact not be great\". For me the issue is that Kubernetes is overused. You can not really argue that it's not useful or has its place, but that place is much much small than the Internet wants us to believe. It's one of the few services where I feel like \"Call us\" would be an appropriate sales method. The article is correct, you probably don't need Kubernetes. It's a amazing piece of technology, but it's not for the majority of us. It is and should be viewed as a niche product. reply nixpulvis 5 hours agorootparentWhat do you think its niche is? reply mrweasel 5 hours agorootparentVery large \"single product\" services, the focus being on \"very large\". It would also be relevant in the cases where your product is made up of a large number of micro-services, though if you have more than 50 services to support your main product I'd be interested in knowing why you have that many services. There might be completely sane reasons, but it is a special case. Mostly a question of scale to me, I'd guess that the majority (80-90%) of people running Kubernetes don't have large enough scale that it makes sense to take on the extra complexity. Most Kubernetes installations I've seen runs on VMs, three for control plane and 2 - 5 for worker node and I don't think the extra layer is a good trade off for a \"better\" deployment tool. If you do use Kubernetes as a deployment tool, then I can certainly understand that. It is a reasonably well-known, and somewhat standardised interface and there's not a lot of good alternatives for VMs and bare metal. Personally I'd just much rather see better deployment tools being developed, rather than just picking Kubernetes because Helm charts are a thing. You'd also need to have a rather dynamic workload, in the sense that some of your services is need a lot of capacity at one point in time, while other need the capacity at another time. If you have constant load, then why? It's like Oracle's Exadata servers, it's a product that has its place, but the list of potential buyers isn't that long. reply jmb99 9 hours agoparentprevI have pretty much the exact same opinion, right down to ‚Äúcloud shit‚Äù (I have even used that exact term at work to multiple levels of management, specifically ‚ÄúI‚Äôm not working on cloud shit, you know what I like working on and I‚Äôll do pretty much anything else, but no cloud shit‚Äù). I have worked on too many projects where all you need is a 4-8 vCPU VM running nginx and some external database, but for some reasons there‚Äôs like 30 containers and 45 different repos and 10k lines of terraform, and the fastest requests take 750ms which should be nginx->SQL->return inHe didn‚Äôt believe it was possible to have this kind of performance in a ‚Äúlegacy monolithic‚Äù (his words) application. > I think it‚Äôs so heavily ingrained in most cloud/web developers that this is the only option that they will not even entertain the thought that it can be done another way. One thing that I need to remind myself of periodically: The amount of work that a modern 1U server can do in 2024 is astonishing. reply sgarland 5 hours agorootparentHell, the amount of work that an OLD 1U can do is absurd. I have 3x Dell R620s (circa-2012), and when equipped with NVMe drives, they match the newest RDS instances, and blow Aurora out of the water. I‚Äôve tested this repeatedly, at multiple companies, with Postgres and MySQL. Everyone thinks Aurora must be faster because AWS is pushing it so hard; in fact, it‚Äôs quite slow. Hard to get around physics. My drives are mounted via Ceph over Infiniband, and have latency measured in microseconds. Aurora (and RDS for that matter) has to traverse much longer physical distances to talk to its drives. reply HPsquared 8 hours agorootparentprevIt's nice to think about the amount of work done by game engines, for instance. Factorio is a nice example, or anything graphics-heavy. reply jiggawatts 8 hours agorootparentprevSpeaking of Kubernetes performance: I had a need for fast scale-out for a bulk testing exercise. The gist of it was that I had to run Selenium tests with six different browsers against something like 13,000 sites in a hurry for a state government. I tried Kubernetes, because there's a distributed Selenium runner for it that can spin up different browsers in individual pods, even running Windows and Linux at the same time! Very cool. Except... Performance was woeful. It took forever to spin up the pods, but even once things had warmed up everything just ran in slow motion. Data was slow to collect (single-digit kilobits!), and I even saw a few timeout failures within the cluster. I gave up and simply provisioned a 120 vCPU / 600 GB memory cloud server with spot pricing for $2/hour and ran everything locally with scripts. I ended up scanning a decent chunk of my country's internet in 15 minutes. I was genuinely worried that I'd get put on some sort of \"list\" for \"attacking\" government sites. I even randomized the read order to avoid hammering any one site too hard. Kubernetes sounds \"fun to tinker with\", but it's actually a productivity vampire that sucks up engineer time. It's the Factorio of cloud hosting. reply pdimitar 2 hours agorootparent> I gave up and simply provisioned a 120 vCPU / 600 GB memory cloud server with spot pricing for $2/hour and ran everything locally with scripts. I ended up scanning a decent chunk of my country's internet in 15 minutes. Now that is a blog post that I would read with interest, top to bottom. reply mschuster91 8 hours agorootparentprevI mostly agree with you, but at least using Docker is something one should be doing even if one is on bare metal. Pure bare metal IME only leads to people ssh'ing to hotfix something and forgetting to deploy it. Exclusively using Docker images prevents that. Also, it makes firewall management much, much easier as you can control containers' network connectivity (including egress) each on their own, on a bare-metal setup it involves loads of work with network namespaces and fighting the OS-provided systemd unit files. reply chromanoid 8 hours agoparentprevIMO the actual experience you want is something as simple as you can do with those old-school simple PHP-based \"serverless\" web hosters. You just upload your stuff and maybe configure a database URL and that's it. Regarding AWS, function.zip Lambda + DynamoDB + S3 + SQS is basically this at \"enterprise-grade\". Now you have the in-between left, where you want enterprise-grade (availability, scaling and fault tolerance) but with a catch (like lower costs, more control, data sovereignty or things that are not as serverless as you want, e.g. search engine etc.). In these cases you will run into many trade-off decisions, that may lead you to K8s, cloud specific stacks and also simple VM ClickOps / ShellOps setups. As long as you can still be on the pet instead of cattle range of problems, K8s is not what you want. But as soon as you want cattle, reproducible throw-away online environments etc. \"just have a VM or a physical server\" will become a \"build your own private cloud solution\" that may or may not become a bad private cloud / K8s. reply stiray 12 hours agoparentprevI agree, but what pisses me the most is that today higher level abstractions (like cloud, spring boost,...) are hiding lower level functionality so well, that you are literally forced to use obnoxious amounts of time to study documentation (if you are in luck and it is well written), while everything is decorated with new naming of known concepts that was invented by people who didn't know that the concept already exists and has a name or some marketing guy figured out it will sell better with more \"cool\" name. Like Shakespeare work would be clumsy and half translated to french advertising jargoon and you are forced to read it and make it work on a stage. reply datadeft 10 hours agorootparentThe real benefits of LLMs is to give me a good summary of these documents. Still, using these abstractions is probably not worth it. reply PittleyDunkin 8 hours agorootparentWell, a summary. It's impossible to evaluate the quality of the summary without actually reading the document you're trying to avoid reading. reply stiray 6 hours agorootparentprevLLMs are a symptom, not a solution. Just another over-hyped bullshit (those downvoting will agree in few years or never as they are the ones riding the hype) that its only concern is to boost company stocks. Google is the proof, their search started to suck immediately when they added AI into concept. It promotes bullshit, while it doesn't hit the really relevant results, even if you specify them into the details. If AI would have any real value, it would never be given out for free and this is the case: they have a solution and they are searching for a problem it solves. reply andyjohnson0 8 hours agoparentprevKubernetes was developed by Google, and it seems to me it's a classic example of a technology that can work well in a resource-rich (people, money) environment. But in an averge business it becomes a time/money sink quite quickly. Way too many businesses cargo-cult themselves into thinking that they need FAANG-class infra, even though they haven't got the same scale or the same level of resourcing. Devs and ops people love it because they get to cosplay and also get the right words on their CV. If you're not Google-scale then, as you say, a few VMs or physical boxes are all you need for most systems. But its not sexy, so the business needs people who don't mind that. reply devjab 12 hours agoparentprevI don‚Äôt mind the cloud, but even in enterprise organisations I fail to see the value of a lot of the more complex tools. I‚Äôve anlways worked with Azure because Denmark is basically Microsoft territory in a lot of non-tech organisations because of the synergy between pricing and IT operations staff. I‚Äôve done bicep, terraform and both Kubernetes and the managed (I forgot what azure conteiner apps running on top of what is basically Kubernetes is called). When I can get away with it I always use the Azure CLI through bash scripts in a pipeline however and build directly into Azure App services for contained which is just so much less complicated than what you probably call ‚Äúcloud shit‚Äù. The cool part about the Azure CLI and their app services is that it hasn‚Äôt really changed in the past 3 years, and they are almost one size fit any organisation. So all anyone needs to update in the YAML scripts are the variables. By contrast working with Bicep/Terraform, Jenkins and whatever else people use has been absolutely horrible, sometimes requiring full time staff just to keep it updated. I suppose it may be better now that azure co-pilot can probably auto-generate what you need. A complete waste of resources in my opinion. It used to be more expensive, but with the last price hike of 600% on azure container apps it‚Äôs usually cheaper. It‚Äôs also way more cost efficient in terms of maintaining since it‚Äôll just work after the initial setup pipeline has run. This is the only way I have found that is easier than what it was when organisations ran their own servers. Whether it was in the basement or at some local hardware house (not exactly sure what you call the places where you rent server rack space). Well places like Digital Ocean are even easier but they aren‚Äôt used by enterprise. I‚Äôm fairly certain I‚Äôve ever worked with an organisation that needed anything more than that since basically nothing in Denmark scales beyond what can run on a couple of servers behind a load balancer. One of the few exceptions is the tax system which sees almost 0 usage except for the couple of weeks where the entire adult population logs in in at the same time. When DevOps teams push back, I tend to remind them that StackOverflow ran on a couple of IIS servers for a while and that they don‚Äôt have even 10% of the users. Eventually the business case for Azure will push people back to renting hardware space or jumping to Hetzner and similar. But that‚Äôs a different story. reply DanielHB 10 hours agorootparentTerraform has the same problem as Kubernetes sidecars with terraform providers trying to do magic for you. If you stick to the cloud platform provider it is actually much nicer than using the CLI. Although my experience is with AWS, I find the terraform AWS provider docs better documentation than the official AWS docs for different options. If they don't answer any question I have right away they at least point me where to look for answers in the mess that is AWS docs. reply MortyWaves 8 hours agorootparentprevThis was a good read! I have similar thoughts especially about IaC vs a bash script. Definitely clear pros and cons to both, but I‚Äôm wondering how you handle infrastructure drift with imperative bash scripts? I mean hopefully no one is logging into Azure to fuck with settings but I‚Äôm sure we‚Äôve all worked with that one team that doesn‚Äôt give a flying fuck about good practices. Or say you wish to now scale up a VM, how does your bash script deal with that? Do you copy past the old script, pass new flags to the Azure CLI, and then run that, then delete the old infrastructure somehow? I‚Äôm curious because I think I‚Äôd like to try your approach. reply devjab 3 hours agorootparentI think you‚Äôve nailed the issues with this approach. I think the best approach to control ‚Äúcowboy‚Äù behaviour is to make everything run through a service connection so that developers don‚Äôt actually need access to your azure resources. Though to be fair, I‚Äôve never worked with a non-tech enterprise organisation where developers didn‚Äôt have at least some access into Azure directly. I also think the best way to avoid dangers in areas like networking is to make sure the responsibility for these are completely owned by IT-Operations. With VNETs and private DNS zones in places all you really need to allow is for the creation of private end points and integration to the network resources. Similarity I think it‚Äôs best practice to have things like key vaults managed by IT operations with limited developer access, but this can depend on your situation. One of the things I like about the Azure CLI is that it rarely changes. I would like to clarify that I‚Äôm mainly talking about Azure App Services and not VMs. Function apps for most things, web apps for things like APIs. As far as the script goes they are basically templates which are essentially ‚Äúcopy paste‚Äù. One of the things I tend to give developers in these organisations is ‚Äúskeleton‚Äù projects that they can git clone. So they‚Äôll typical also have some internal CLI scripts to automate a lot of the code generation and an azure-pipelines-resource-creation.yml plays into this. Each part of your resource creation is its own ‚Äúif not exist‚Äù task. So there is a task to create a resource group. Then a task to create an app service plan and so on. It won‚Äôt scale. But it will scale enough for every organisation I‚Äôve worked with. To be completely honest it‚Äôs something which grew out of my frustration of repeating the same tasks in different ways over the years. I don‚Äôt remember exactly but I think quite a few of the AZ CLI commands haven‚Äôt change for the past three years. It‚Äôs really the one constant across organisations, even the Azure Poetal hasn‚Äôt remained the same. reply antihero 7 hours agoparentprevI think a good compromise is building your applications in a containerised manner so that you can simply run them with docker-compose, but then if it turns out you need some heavy scale, it's merely a case of switching the underlying infrastructure. That said, my experience has been fairly different. Running microk8s on a VPS with some containers and an ingress just seems like a nice way to spin them up as pods and manage them. It really doesn't feel that complicated. Once you integrate with cloud providers and you get more complex systems, sure, it gets more complex. I much prefer the container paradigm for separating parts of apps out and managing dependencies and reproducibility. Having a bunch of raw servers with all the bullshit and drift and mutability that comes along with it feels far more like a headache to me than the abstraction of k8s or docker. If you aren't deploying stuff with GitOps/IaC in 2024 I fear for anyone that has to manage or maintain it. 100% reproducibility and declarative infrastructure are wonderful things I could never come back from. reply ozim 12 hours agoparentprevI am running VPSes at our small startup-ish company on IaaS cloud. Every time we get a new guy I have to explain that we are already ‚Äûin cloud‚Äù there is no need to ‚Äûmove to cloud‚Äù. reply rcleveng 11 hours agorootparentDo they mean PAAS vs IAAS when they say \"move to cloud\"? reply ozim 11 hours agorootparentMostly business guys don‚Äôt know the difference but we are running on local cloud provider and they think of it is not on Azure or AWS it is not in cloud - they understand that we run stuff on servers but they also don‚Äôt understand VPS is IaaS. Developers want to use PaaS and also AWS or Azure so they can put it on their resume for the future. reply bluehatbrit 10 hours agorootparent> Developers want to use PaaS and also AWS or Azure so they can put it on their resume for the future. I think this is a little disingenuous. Developers want to use them because they already know them. The services composing them are also often well documented by the provider. I say all of that as someone trying to move a company away from aws, and over to our own hardware. reply PittleyDunkin 8 hours agorootparentI want to use them because I'm not paying for it and managing your own hardware is a pain in the ass I'd rather avoid when I could just code instead. Which is not to say that using your own hardware isn't smart, but it is definitely miserable. reply regularfry 8 hours agorootparentIn my experience you swap managing your own hardware for managing intensely obtuse service configurations, pretty much 1:1. That might be preferable but I see a lot of folks approach it like the tradeoff doesn't exist. reply bob1029 11 hours agoparentprevCloud is a broad spectrum of tools. I think the Goldilocks zone is something right in between bare-ass VMs and FaaS. If I can restart the machine and it magically resolves the underlying hardware fault (presumably by migrating me to a new host), then I am in a happy place. Most of the other problems can be dealt with using modern tooling. I lean aggressively on things like SQLite and self-contained deployments in .NET to reduce complexity at hosting time. When you can deploy your entire solution with a single zip file you would be crazy to go for something like K8s. One other cloud thing that is useful is S3-style services. Clever use of these APIs can provide incredible horizontal scalability for a single instance solution. SQLite on NVMe is very fast if you are offloading your blobs to another provider. reply grishka 11 hours agoparentprev> If I get to tens of millions of users, maybe I‚Äôll worry about it then. Nope, then you'll set up sharded databases and a bunch of application servers behind a load balancer. reply misswaterfairy 12 hours agoparentprevI hate \"cloud shit\" as well, though specifically that there's a vendor-specific 'app', or terminology, or both, for everything that we've had standard terms for, for decades. I just want a damn network, a couple of virtual machines, and a database. Why does eachhave to create different fancy wrappers over everything, that not even their own sales consultants, and even engineers, understand?(1) What I do like about Docker and Kubernetes is that shifting from one cloud provider to another, or even back to on-premises (I'm waiting for the day our organisation says \" is too damn expensive; those damn management consultants lied to us!!!!\") is a lot easier than re-building 's bespoke shit in 's bespoke shit, or back on-premises with real tech (the right option in my opinion for anyone less than a (truly) global presence). I do like the feel of, and being able to touch bare metal, though the 180-proof-ether-based container stuff is nice for quick, flexible, and (sometimes) dirty. Especially for experimenting when the Directors for War and Finance (the same person) say \"We don't have the budget!! We're not buying another server/more RAM/another disk/newer CPUs! Get fucked!\". The other thing about Docker specifically I like is I can 'shop' around for boilerplate templates that I can then customise without having to screw around manually building/installing them from scratch. And if I fuck it up, I just delete the container and spin up another one from the image. (1) The answer is 'vendor lock-in', kids. (I apologise, I've had a looooooong day today.......) reply yungporko 10 hours agorootparentagreed, cloud shit can fuck off. they market themselves as the solution to problems you will never have so that you build your shit on their land and they can charge you rent, and most people eat it up and think they're doing them a favour. reply tryauuum 13 hours agoparentprevI have same thoughts. the only form of kubernetes I would be willing to try is the one with kata-containers for having all the security of virual machines. reply kortilla 9 hours agoparentprevAll of these anecdotes seem to come from people who don‚Äôt bother to try to learn kubernetes. > YAML files, and then spend a day fixing them by copy-pasting increasingly-convoluted things on stackexchange. This is terrible behavior. Its not any different from yanking out pam modules because you‚Äôre getting SSH auth failures caused by a bad permission on an SSH key. > If I get to tens of millions of users, maybe I‚Äôll worry about it then. K8s isn‚Äôt there for 10s of millions of users. It‚Äôs there so you‚Äôre not dependent on some bespoke VM state. It also allows you to do code review on infra changes like port numbers being exposed, etc. Separately, your VM likely isn‚Äôt coming from any standard build pipeline so now a vulnerability patch is a login to the machine and an update, which hopefully leaves it in the same state as VMs created new‚Ä¶ Oh, and assuming you don‚Äôt want to take downtime on every update, you‚Äôll want a few replicas and load balancing across them (or active/passive HA at a minimum). Good luck representing that as reviewable code as well if you are running VMs. The people that don‚Äôt understand the value prop of infra as code orchestration systems like k8s tend to work in environments where ‚Äúmaintenance downtime‚Äù is acceptable and there are only one or two people that actually adjust the configurations. reply tombert 2 hours agorootparentSure, because Kubernetes is convoluted and not fun and is stupidly bureaucratic. I might learn to enjoy being kicked in the balls if I practiced enough but after the first time I don't think I'd like to continue. > This is terrible behavior. Its not any different from yanking out pam modules because you‚Äôre getting SSH auth failures caused by a bad permission on an SSH key. Sure, I agree, maybe they should make the entire process less awful then and easier to understand. If they're providing a framework to do distributed systems \"correctly\" then don't make it easy for someone whose heart really isn't into it to screw it up. > K8s isn‚Äôt there for 10s of millions of users. It‚Äôs there so you‚Äôre not dependent on some bespoke VM state. It also allows you to do code review on infra changes like port numbers being exposed, etc. That's true of basically any container stuff or orchestration stuff, but sure. Kubernetes just screams to me as suffering from a \"tool to make it look like I'm doing a lot of work\". I have similar complaints with pretty much all Java before Java ~17 or so. I'm not convinced that something like k8s has to be as complicated as it is. reply kortilla 59 minutes agorootparent> Sure, because Kubernetes is convoluted and not fun and is stupidly bureaucratic. Describe what you think bureaucratic means in a tool. > I might learn to enjoy being kicked in the balls if I practiced enough This is the same thing people say who don‚Äôt want to learn command line tools ‚Äúbecause they aren‚Äôt intuitive enough‚Äù. It‚Äôs a low brow dismissal holding you back. reply secondcoming 8 hours agorootparentprevJust because you're using VMs doesn't mean you're now dealing with state. It's 100% possible to have stateless VMs running in an auto-scaling instance group (in GCP speak, I forget what AWS calls them) reply kortilla 57 minutes agorootparentOnce you have the tools to manage all of that, you effectively have kubernetes. Container vs VM is largely irrelevant to what the op is complaining about when it comes to k8s. People that don‚Äôt like k8s tend to be fine with docker. It‚Äôs usually that they don‚Äôt like declarative state or thinking in selectors and other abstractions. reply everfrustrated 8 hours agorootparentprevIn the beginning AWS didn't even support state on their VMs! All VMs were ephemeral with no state persistence when terminated. They later introduced EBS to allow for the more classic enterprise IT use cases. reply nyclounge 13 hours agoparentprevOr if you got a static ip and fast up speed, then just port forward 80, 443 and start hosting your self. Even an old Intel Mac Book pro from 2000's with 4 GB of RAM may not be that hot running MacOS, but install Debian with no X. It is running smooth as a whistle, while running several conduit matrix, haraka, zone-mta, ice cast, nginx with no issues. WebRTC/TUN/STUN becomes an issue with the nginx config. May consider looking at pingora. The whole rust -> binary + toml file is super nice to run from system admin perspective. reply d3Xt3r 11 hours agorootparent> It is running smooth as a whistle ... until you get hit by a DDoS attack. Not much you can do about it unless your ISP offers protection, or you end up going for Cloudflare or the like instead of exposing your IP and ports. reply nyclounge 3 hours agorootparentOr hetzner has also DDoS protect for all their customers. Seems like a lot less rip off and scam than AWS and Cloudflare. Set your TLS a low number, and you can swap whenever you feel like it. reply PittleyDunkin 8 hours agorootparentprevFolding the second you get dos'd is aa feature, not a liability. Staying up through those is a great way to lose a ton of money basically instantly. reply zelphirkalt 4 hours agoparentprevI am sure the consultants and others peddling Kubernetes like it, since they are getting the paycheck for bringing it on, or cementing their position, as they are the ones with the expert knowledge of the system then, if anyone is at all, after something has been migrated to Kubernetes. reply Havoc 6 hours agoparentprev‚Äúlet me install everything myself‚Äù doesn‚Äôt generalise well and gets messy even if you IaC it. There is a reason k8s gang keeps going on about ‚Äúcattle not pets‚Äù. The starting assumptions and goals are fundamentally different vs ‚Äúgive me a physical server‚Äù Both have their place I think so not really one is right other is wrong reply tombert 2 hours agorootparentEveryone says this, but do we actually have data to back that up? I feel like I spend so much time working around CloudSQL for postgres support in GCP at work, to a point where I'm not actually sure I'm saving a ton of time over running and managing it myself. That's probably not true, I'm sure there are edge cases that I'm not accounting for, but I'm a little tired of everyone acting like AWS and GCP and Azure are the \"set it and forget it\" thing that they advertise. reply Havoc 56 minutes agorootparentNot sure how you‚Äôd even measure that meaningfully. My comment above was more k8s vs classic server rather than thinking about cloud k8s in particular. I do agree that cloud is stuff is a huge time sink. I‚Äôve learned to look at it in terms of how close it is to FOSS like world. Things that follow normal protocols and standards like say it speaks Postgres or is a docker image then cloud is ok. Things that are cloud vendor specific or a custom product‚Ä¶run for the hills. Not only is it lock in but also that‚Äôs where the pain you describe is. The engineering around it just becomes so much more granular and fragile reply immibis 5 hours agorootparentprevAnd people tend to vastly underestimate the power of a single server. These days you can get a terabyte of RAM, 96 cores and dual 10G Ethernet for a low-to-mid 4-digit price (used). Do you need the cloud? Some do, but often your highest conceivable scale fits on one or two servers. Stack Exchange famously ran this way for a long time (until recently when they've been bought by large investors and they're going full cloud and AIshit). reply Havoc 3 hours agorootparentScaling wasn‚Äôt really what I was getting at there per se. Said generalise but that‚Äôs admittedly quite fuzzy. Meant it more in the abstraction layer and standardisation sense. Installing stuff straight on server is very messy especially if it‚Äôs lots of different providers with their own dependencies. So you need to do some form of containers or VMs to isolate them. At which point you need some sort of tooling around that. And deal with failures etc. Before you know it you‚Äôve reinvented k8s except with less standardization and more duck tape. So it think there is a strong case for a k8s cluster but being mindful to keep it as simple as possible within that paradigm. Ie k8s but just the basic building blocks reply Woeps 8 hours agoparentprevI don't mind K8s, and it can be usefull if you just stay to the core essentials. But I do agree that there seems to be the sentiment:\"Everybody has to like it!\" And I mostly think that this is because our collective bias for everything Big Tech does is good. While often it just depends. Just because Google does X or Y doesn't mean it will work for everybody else. reply gigatexal 7 hours agoparentprevThe yaml and the k8s model can be grokked it just takes a willingness to. That being said there are abstractions terraform, pulumi, others. But my go to is always that most companies will never get to the point where k8s is required ‚Äî most companies never get to that scale. A well maintained docker compose setup gets you a long way. reply tapoxi 13 hours agoparentprevThis read as \"old man yells at cloud\" to me. I've managed a few thousand VMs in the past, and I'm extremely grateful for it. An image is built in CI, service declares what it needs, the scheduler just handles shit. I'm paged significantly less and things are predictable and consistent unlike the world of VMs where even your best attempt at configuration management would result in drift, because the CM system is only enforcing a subset of everything that could go wrong. But yes, Kubernetes is configured in YAML, and YAML kind of sucks, but you rarely do that. The thing that changes is your code, and once you've got the boilerplate down CI does the rest. reply tombert 2 hours agorootparent> But yes, Kubernetes is configured in YAML, and YAML kind of sucks, but you rarely do that. I'm sorry, citation needed on that. I spend a lot of time working with the damn YAML files. It's not a one-off thing for me. You're not the first person to say this to me, they say \"you rarely touch the YAML!!!\", but then I look at their last six PRs, and each one had at least a small change to the YAML setup. I don't think you or they are lying, I think people forget how often you actually have to futz with it. reply raxxorraxor 6 hours agorootparentprevI think it is also a difference between developer and IT. Usually the requirements don't ask for thousands of VMs if you don't run some kind of data center or a company that specializes on software services. reply catdog 12 hours agorootparentprevYAML is fine, esp. compared to the huge collection of often 10x worse config formats you have to deal with in the VM world. reply cess11 11 hours agorootparentprevI'd prefer Ansible if I was running VM:s. Did that at a gig, controlled a vCenter cluster and hundreds of machines in it, much nicer experience than Kubernetes style ops. Easier to do ad hoc troubleshooting and logging for one. reply vrighter 9 hours agorootparentuntil, as happened to us, you're in the middle of an upgrade cycle, with a mix of red-hat 6 and red-hat 8 servers, and ansible decide to require support for the latest available version of python on red-hat 8, which isn't available on red-hat 6, so we have no way of using ansible to manage both sets of servers. The python ecosystem is a cancer. reply mkesper 8 hours agorootparentWell, you were free to install a version of Python3 on the CentOS6 machines, that's what we ended up doing and using for Ansible. Python 2.6 support of Ansible was a bad lie, multiple things broke already. 10 years of support without acknowledging changes of ecosystem just don't work. reply vrighter 5 hours agorootparentwe did, but then most ansible modules still didn't work on the system. They advertise the no-agent thing and how it does everything over ssh, and instead require python to be installed on all your servers because it generates python code and runs it on the remote machine. And somemodules require specific versions sometimes. reply cess11 9 hours agorootparentprevSure, and I'm also not a fan of RedHat. We ran Ubuntu and Debian on that gig, the few Python issues we ran into we could fix with some package pinnings and stuff like that. reply mollusk 11 hours agorootparentprev> \"old man yells at cloud\" Literally. reply datadeft 10 hours agoparentprevOne thing that might help you in this madness is: https://github.com/dhall-lang/dhall-kubernetes Type safe, fat finger safe representation of your YAMLs is grossly underrated. reply wordofx 8 hours agoparentprevI‚Äôm confused. Do you hate cloud or the container shit? Cloud is awesome. Containers is dumb as hell for 99% of the applications hacker news kids work on. reply tombert 2 hours agorootparentI don't know what \"cloud\" means. I don't really like Kubernetes, and I don't really like the AWS and GCP systems for doing everything. The fact that WGU offers a bachelors degree in Cloud Computing with focuses on AWS or Azure should be telling. [1] Containers don't bother me that much on their own. I just feel like with k8s and its ilk I end up spending so much time futzing with weird YAML and trying to remember differences between stateful sets and services and fighting with stuff because I missed the thing that mounts a disk so my app will break in three hours. [1] https://www.wgu.edu/online-it-degrees/cloud-computing-bachel... reply friendzis 9 hours agoparentprevIn my limited experience k8s is treated as some magic instead of what it is: resource virtualization platform. Sort one (or two) step above hardware virtualization platforms (e.g. esxi). The fact that vmware can migrate a running vm to a different hardware node is surely powerful feature. Do you want to pay for that with complexity? If you are one infra team serving on-prem deployments with consistent loads you provision things when new projects are started and things break. However, if infra team serves internal product teams it is nice to give certain guarantees to them and limit blast radius how they can affect other teams. This is where kubernetes sit. It's a deployment platform, where the deployable is container image instead of VM image. Slice off a namespace to an internal team and have their deployment blast radius contained within their namespace. Do you need such flexibility? I'm pretty sure that roughly 99% of all teams do not. A static set of VMs provisioned with some container orchestration system is more than enough for them. Loads and deployments are too static for it to matter. >>> But it allows seamless upgrades! Dude or dudette, if you can't properly drain your nodes and migrate sessions now, kubernetes will not save you. reply raffraffraff 11 hours agoparentprevI'm sure you can get some of the handy extras that come with a typical kubernetes deployment without the kubernetes, but overall I'll take kubernetes + cloud. Once you've got the hang of it, it's ok. I have a terraform project that deploys clusters with external-dns, external-secrets, cert-manager, metrics, monitoring stack, scalers and FluxCD. From there, pretty much everything else is done via FluxCD (workloads, dashboards, alerts). And while I detest writing helm charts (and sometimes using them, as they can get \"stuck\" in several ways) they do allow you to wrap up a lot of the kubernetes components into a single package that accepts more-or-less standardized yaml for stuff like resource limits, annotations (eg for granting and AWS role to a service) etc. And FluxCD .postBuild is extremely handy for defining environment vars to apply to more generic template yaml, so we avoid a sprawl. So much so that I am the one-man-band (Sys|Dev|Sec)Ops for our small company, and that doesn't give me panic attacks. The cloud integration part can be hairy but I have terraform patterns that, once worked out, are cookie cutter. With cloud kubernetes, I can imagine starting from scratch, taking a wrong turn and ending up in hell. But I'm exchanging one problem set for another. Having spent years managing fleets of physical and virtual servers, I'm happier and more productive now. I never need to worry about building systems or automation for doing OS build / patching, config management, application packaging and deployment, secrets management, service discovery, external DNS, load balancering, TSL certs etc. Because while those are just \"words\" now, back then each one was a huge project involving multiple people fighting over \"CentOS Vs Ubuntu\", \"Puppet Vs Ansible\", \"RPMs Vs docker containers\", \"Patching Vs swapping AMIs\". If you're using Consul and Vault, good luck - you have to integrate all of that into whatever mess you've built, and you'll likely have to write puppet code and scripts to hook it all up together. I lost a chunk of my life writing 'dockerctl' and a bunch of puppet code that deployed it so it could manage docker containers as systemd services. Then building a vault integration for that. It worked great across multiple data centers, but took considerable effort. And in the end it's a unique snowflake used by exactly one company, hardly documented and likely full of undiscovered bugs and race conditions even after all the hard work. The time it took to onboard new engineers was considerable and it took time away from an existing engineer. And we still had certificates expire in production. reply bananapub 2 hours agoparentprev> I have set up about a dozen rack mount servers in my life, yes, k8s and co are silly for trivially tiny systems like this. reply Deutschlandds 6 hours agoparentprevI find it always interesting and weird to read so dimetrical points to kubernetes. 1. Cloud for me is a lot better than what we had before: Before i had to create a ticket for our internal it department, have huge cross-charges (like 500$ for a server, instead of 50), had to wait for a few weeks and than get lectured that installing basic default tools on that suse based server would take a week and add additional cross-charges onto it. Their reasoning? Oh we do backup and upgrades... With cloud, i click a server in a Minute for less money, i upgrade it myself and have snapshots as a basic backup workflow which actually is reliable and works. Then k8s came along and let me be clear: my k8s setup is big, so its definitly worth it but tx to my experience with a bigger k8s setup, my very small ones are also working very very well. I get, out of the box, HA, network policies, snapshotting through my selected storage setup, Infrastructure as code etc. Instead of having shitty shell scripts, ansible setup and co, i only write a little bit of yaml, check it into my git system and roll it out with ansible. Absolut no brainer. And the auto healing solved real issues: Out of memroy? just restart the pod. Out of disk? Just recreate it. Logging and metrics just works out of the box thanks to the prometheus based monitoring stack. Starting with one server, yeah why not but you know you are not doing it right if you are the only one who can set it up and recover it. But if you don't have anyone with expertise, i would also not just start with k8s. If my startup is a pure application + db thingy, i would go with any app platform out there. But we have real servers because we do stuff with data and need sometimes performance, performance is expensive if you run it in the cloud. reply gizzlon 6 hours agorootparent> shitty shell scripts, ansible setup and co, i only write a little bit of yaml Why are the shell scripts shity but the yaml not? When I look at those yaml files I always throw up just a little :P Also, have you tried Cloud Run? reply Deutschlandds 5 hours agorootparentYaml is declarative, you tell k8s what you want and how it looks. For shell scripts, try proper error handling. You start doing some catch hooks, you have issues cehcking error codes of different tools, debugging is hard too. In one infra project we swtiched from shell scripts to golang just to have a lot more control/stability of our scripts. reply gizzlon 5 hours agorootparentYAML is not declarative, it's a format. Well, according to Wikipedia it's a \"data serialization language\". IMO It's also bad choice for this, and those files become unreadable and hard to work with. Agree that shell scripts are also hard to work with, especially if you did not write them yourselves. I guess it's a combo of the language features of, say bash, and that no one who writes them really know bash. I mean, at all. Including me. Declarative is nice, but also have pros and cons. And, it's of course many ways to achieve this if that's a priority. Usually, what you really want is: Low time to replicate AND no data loss if a server blows up. But this also have to extend to, say, the k8 cluster. And, again, many ways to achieve this. The article does not call for Ansible setups and shell scripts though. Cloud Run uses YAML btw. One of the things I personally don't like about it reply fragmede 12 hours agoparentprevI'll let you in on the joke. The joke is the demand for 100% availability and instant gratification. we're making services where anything less than 4 nines, which is 5 minutes month, is deemed unacceptable. three nines is 10 minutes a week. two nines is 15 minutes a day. there are some things that are important enough that you can't take a coffee break and wait for, but Kubernetes lets you push four nines of availability, no problem. Kubernetes is solving for that level of availability, but my own body doesn't have anything near that level of availability. demanding that from everything and everyone else is what pushes for Kubernetes level of complexity. reply spacebanana7 8 hours agorootparentMost outages these days are also caused by \"devops errors\" that're much more likely to happen when working with complex infrastructure stacks. So there's real value in keeping things simple. reply EVa5I7bHFq9mnYK 11 hours agorootparentprev4 nines is a lie. That's not what I experience as a user. I experience 403, 404, 405, 500, or other forms of down, such as difficult captchas, 2fa not working, geolocation blockages etc several times a day. reply karmarepellent 6 hours agorootparentprevIts a matter of evaluating what kind of infrastructure your application needs to run on. There are certainly mission critical systems where even a sliver of downtime causes real damage, like lost revenue. If you come to the conclusion that this application and everything it involves better run on k8s for availability reasons, you should probably focus on that and code your application in a k8s-friendly manner. But there are tons of applications that run on over-engineered cloud environments that may or may not involve k8s and probably cost more to operate than they must. I use some tools every day where a daily 15 min downtime would not affect my or my work in the slightest. I am not saying this would be desirable per se. Its just that a lot of people (myself included) are happy to spend an hour of their work day talking to colleagues and drinking coffee, but a 15 min downtime of some tool is seen as an absolute catastrophe. reply tombert 1 hour agorootparentprevI agree with you in theory, and maybe even in practice in some cases, but I do not feel like we have less downtime with k8s than using anything else. reply kitd 11 hours agorootparentprevAre you the only one waiting on your app if it goes down? reply PittleyDunkin 8 hours agoparentprevIsn't using VMs or servers just cloud shit in a different form? How does that fix anything? Orchestrating software (or hardware) is a pain in the ass whether it's in your closet or someone else's. reply cess11 11 hours agoparentprevOnce it gets hard to run the needed services for all the applications in the organisation/team on your development machine it'll start to look more attractive to turn to Docker/Podman and the like, and that's when automatic tests and deploys built on disgusting YAML starts to make more sense. I've been at a place where the two main applications were tightly coupled with several support systems and they all were dependent on one or more of Oracle DB, Postgres, Redis, JBoss, Tibco EMS and quite a bit more. Good luck using your development device to boot and run the test suite without containers. Before that team started putting stuff in containers they used the CI/CD environment to run the full set of tests, so they needed to do a PR, get it accepted, maybe wait for someone else's test run to finish, then watch it run, and if something blew, go back to commit, push to PR, &c. all over again. Quite the nuisance. A full test suite had a run time of about an hour too. When I left we'd pushed it to forty minutes on our dev machines. They didn't use raw Kubernetes though, they had RedHat buy-in and used OpenShift, which is a bit more sane. But it's still a YAML nightmare that cuts you with a thousand inscrutable error messages. reply cheriot 13 hours agoparentprev> I might just be stupid, but it feels like all I ever do with ____ is update and break ____ files, and then spend a day fixing them by copy-pasting increasingly-convoluted things on stackexchange. I cannot imagine how anyone goes to work and actually enjoys working in ____, though I guess someone must in terms of ‚Äúlaw of large numbers‚Äù. I'd make a similar statement about the sys admin stuff you already know well. Give me yaml and a rest api any day. I see where you and the article are coming from, though. The article reasonably points out that k8s is heavy for simpler workloads. reply teekert 11 hours agoparentprevSorry to have to tell you this, but you‚Äôre old. Your neural plasticity has gone down and you feel like you have seen it al before. As a result you cling to the old and never feel like you grasp the new. The only reasonable thing to is to acknowledge and accept this and try not let it get in your way. Our generation has seen many things before, but at the same time the world has completely changed and it‚Äôs led to the people growing up in it to be different. You and me didn‚Äôt fully grasp CPUs anymore. Some people today don‚Äôt grasp all the details of the abstractions below K8s anymore and use it when perhaps something simpler (in architecture , not necessarily in use!) could do it better. And yet, they build wonderous things. Without editing php.ini and messing up 2 services to get one working. Do I think K8s is the end all? Certainly not, I agree it‚Äôs sometimes overkill. But I bet you‚Äôll like it‚Äôs follow-up tech even less. It is the way of things. reply creesch 11 hours agorootparentWhile this is a nice essay, it also is purely an emotional argument hanging together from assumptions and fallacies. Even if you are right in this instance, just brushing things off with the \"you are old\" argument will ensure that you end up in some horrible tech debt spaghetti mess in the future. Being critical of the infrastructure you deploy to is a good thing. Because for all the new things that do stick around, there are dozens of other shiny new hyped up things that end up in digital purgatory quite soon after the hype phase is over. That's not to say there isn't some truth to your statement. The older you get, the more critical you do need to be to yourself as well. Because it is indeed possible to just be against something because it is new and unfamiliar. At the same time, does experience provide insights allowing senior people to be more critical to things. *tl;dr:* The world is complicated, not binary. reply teekert 10 hours agorootparentWell, I fully agree with you. Perhaps the -hate ‚Äúcloud shit\"- remark triggered me a bit. It's just such a 'drown the baby with the bathwater', curmudgeon thing to say. And, imho, it betrays age. It's like my grandfather saying, I hate all this digital stuff, \"I will never put email on my phone because with emails come viruses.\" (Literal thing my father-in-law always claims, and perhaps he's not even wrong, he just stopped using new things, hating and resisting change. He has that right of course. And to be fair with his knowledge level it's perhaps even good to not have email on his Phone. But it's getting more difficult, i.e. he refuses our national Digital ID, making his life a lot harder in the process, especially because he also resists help, too proud). It's good to recognize this in oneself though, imho. reply tombert 2 hours agorootparentI don't think it betrays age really, I just think that a lot of this stuff with AWS and Azure and GCP is overly complicated. I am not convinced anyone actually enjoys working on it. I'm pretty sure that 21 year old me would have roughly the same opinion. As I said in a sibling comment, you can genuinely get a bachelors degree in AWS or Azure [1], meaning that it's complicated enough to where someone thought it necessitated an entire college degree. By \"cloud shit\", I don't mean \"someone else hosting stuff\" (which I tried to clarify by saying \"give me a VM\" at the end). I mostly think that having four hundred YAML files to do anything just sucks the life out of engineering. It wouldn't bother me too much if these tasks were just handled by the people who run devops, but I hate that since I am a \"distributed systems engineer\" that I have to LARP as an accountant and try and remember all this annoying arbitrary bureaucratic crap. [1] https://www.wgu.edu/online-it-degrees/cloud-computing-bachel... reply tombert 2 hours agorootparentprevI'm 33 dude, not exactly \"old\". I never really liked the devops stuff even when I was 20. I have no doubt that I could get better with k8s, but it's decidedly not fun. reply tedk-42 11 hours agorootparentprev> Is K8s the end all? Certainly not, I agree it‚Äôs sometimes overkill. But I bet you‚Äôll like it‚Äôs follow-up tech even less. It is the way of things. I agree with your analysis. People wanna talk up about how good the old days were plugging cables into racks but it's really laborious and can take days to debug that a faulty network switch is the cause of these weird packet drop issues seen sporadically on hot days. Same as people saying 'oh yeah calculators are too complicated, pen and paper is what kids should be learning'. It's the tide of change reply tombert 2 hours agorootparentI reject that comparison, I'm not really resistant to change, I'm resistant the awful bureaucratic crap that k8s and its ilk force you to use. It's not fun, as far as I can tell no one actually understands any of it (young or old), they just copy and past large blocks of YAML from blogs and documentation and then cross their fingers. I'm not saying that plugging in cables and hoping power supplies don't die is \"better\" in any kind of objective sense, or even subjective sense really, I'm just saying that I hate this cloud cult that has decided that the only way to do anything is to add layers of annoying bureaucratic shit. reply paxys 14 hours agoprev> Kubernetes comes with substantial infrastructure costs that go beyond DevOps and management time. The high cost arises from needing to provision a bare-bones cluster with redundant management nodes. That's your problem right there. You really don't want to be setting up and managing a cluster from scratch for anything less than a datacenter-scale operation. If you are already on a cloud provider just use their managed Kubernetes offering instead. It will come with a free control plane and abstract away most of the painful parts for you (like etcd, networking, load balancing, ACLs, node provisioning, kubelets, proxies). That way you just bring your own nodes/VMs and can still enjoy the deployment standardization and other powerful features without the operational burden. reply dikei 14 hours agoparentEven for on-prem scenario, I'd rather maintain a K8S control plane and let developer teams manage their own apps deployment in their own little namespace, than provisioning a bunch of new VMs each time a team need some services deployed. reply mzhaase 8 hours agorootparentThis for me is THE reason for using container management. Without containers, you end up with hundreds of VMs. Then, when the time comes that you have to upgrade to a new OS, you have to go through the dance, for every service: - set up new VMs - deploy software on new VMs - have the team responsible give their ok It takes forever, and in my experience, often never completes because some snowflake exists somewhere, or something needs a lib that doesn't exist on the new OS. VMs decouple the OS from the hardware, but you should still decouple the service from the OS. So that means containers. But then managing hundreds of containers still sucks. With container management, I just - add x new nodes to cluster - drain x old nodes and delete them reply rtpg 13 hours agorootparentprevEven as a K8s hater, this is a pretty salient point. If you are serious about minimizing ops work, you can make sure people are deploying things in very simple ways, and in that world you are looking at _very easy_ deployment strategies relative to having to wire up VMs over and over again. Just feels like lots of devs will take whatever random configs they find online and throw them over the fence, so now you just have a big tangled mess for your CRUD app. reply guitarbill 13 hours agorootparent> Just feels like lots of devs will take whatever random configs they find online Well it usually isn't a mystery. Requiring a developer team to learn k8s likely with no resources, time, or help is not a recipe for success. You might have minimised someone else's ops work, but at what cost? reply rtpg 13 hours agorootparentI am partly sympathetic to that (and am a person who does this) but I think too many devs are very nihilistic and use this as an excuse to stop thinking. Everyone in a company is busy doing stuff! There's a lot of nuance here. I think ops teams are comfortable with what I consider \"config spaghetti\". Some companies are incentivised to ship stuff that's hard to configure manually. And a lot of other dynamics are involved. But at the end of the day if a dev copy-pastes some config into a file, taking a quick look over and asking yourself \"how much of this can I actually remove?\" is a valuable skill. Really you want the ops team to be absorbing this as well, but this is where constant atomization of teams makes things worse! Extra coordination costs + a loss of a holistic view of the system means that the iteration cycles become too high. But there are plenty of things where (especially if you are the one integrating something!) you should be able to look over a thing and see, like, an if statement that will always be false for your case and just remove it. So many modern ops tools are garbage and don't accept the idea of running something on your machine, but an if statement is an if statement is an if statement. reply dikei 12 hours agorootparentprev> Just feels like lots of devs will take whatever random configs they find online and throw them over the fence, so now you just have a big tangled mess for your CRUD app. Agree. To reduce the chance a dev pull some random configs out of nowhere, we maintain a Helm template that can be used to deploy almost all of our services in a sane way, just replace the container image and ports. The deployment is probably not optimal, but further tuning can be done after the service is up and we have gathered enough metrics. We've also put all our configs in one place, since we found that devs tend to copy from existing configs in the repo before searching the internet. reply spockz 13 hours agorootparentprevI can imagine. Do you have complete automation setup around maintaining the cluster? We are now on-prem using ‚Äúpet‚Äù clusters with namespace as a service automated on it. This causes all kinds of issues with different workloads with different performance characteristics and requirements. They also share ingress and egress nodes so impact on those has a large blast radius. This leads to more rules and requirements. Having dedicated and managed clusters where everyone can determine their sizing and granularity of workloads to deploy to which cluster is paradise compared to that. reply solatic 13 hours agorootparent> This causes all kinds of issues with different workloads with different performance characteristics and requirements. Most of these issues can be fixed by setting resource requests equal to limits and using integer CPU values to guarantee QoS. You should also have an interface with developers explaining which nodes in your datacenter have which characteristics, using node labels and taints, and force developers to pick specific node groups as such by specifying node affinity and tolerations, by not bringing online nodes without taints. > They also share ingress and egress nodes so impact on those has a large blast radius. This is true regardless of whether or not you use Kubernetes. reply DanielHB 10 hours agorootparentprev> than provisioning a bunch of new VMs each time a team need some services deployed. Back in the old days before cloud providers this was the only option. I started my career in early 2010s and got the tailend of this, it was not fun. I remember my IT department refusing to set up git for us (we were using SVN before) so we just asked a VM and set up a git repo in there ourselves to host our code. reply jillesvangurp 9 hours agoparentprevFor most small setups, the cost of running an empty kubernetes cluster (managed) is typically higher than setting up a db, a couple of vms and a loadbalancer, which goes a long way for running a simple service. Add some buckets, a CDN and you are pretty much good to go. If you need dedicated people just to stay on top of running your services, you have a problem that's costing you hundreds of thousands per year. There's a lot of fun and easy stuff you can do with that kind of money. This is a pattern I see with a lot of teams that get sucked into using Kubernetes, micro services, terraform, etc. Once you need a few people just to stay on top of the complexity that comes from that, you are already spending a lot. I tend to keep things simple on my own projects because any amount of time I spend on that, I'm not spending on more valuable work like adding features, fixing bugs, etc. Of course it's not black and white and there's always a trade off between over and under engineering. But a lot of teams default to over engineering simply by using Kubernetes from day one. You don't actually need to. There's nothing wrong with a monolith running on two simple vms with a load balancer in front of it. Worked fine twenty years ago and it is still perfectly valid. And it's dead easy to setup and manage in most popular cloud environments. If you use some kind of scaling group, it will scale just fine. reply dikei 8 hours agorootparent> For most small setups, the cost of running an empty kubernetes cluster (managed) is typically higher than setting up a db, a couple of vms and a loadbalancer, which goes a long way for running a simple service. Not really, the cost of an empty EKS cluster is the management fee of $0.1/hour, or roughly the price of a small EC2 instance. reply jillesvangurp 7 hours agorootparent0.1 * 24 * 30 = 720$/month That's about 2x our monthly cloud expenses. That's not a small VM. You can buy a mac mini for that. reply dikei 7 hours agorootparent$72 Though if you are only spending $350 monthly on VM, Database and Load Balancer, you can probably count resource instances by hand, and don't need a K8S cluster yet. reply sbstp 12 hours agoparentprevMost control planes are not free anymore, they cost like 70$/mo on AWS & GCP. Used to be a while back. reply dikei 8 hours agorootparentGCP has $74 free credit for Zonal cluster, so you effectively have the first cluster for free. And even $70 is cheap, considering that a cluster should be shared by all the services from all the teams in the same environment, bar very few exceptions. reply szszrk 10 hours agorootparentprevThat's around the cost of a single VM (cheapest 8GB ram I found quickly). Azure has a free tier with control plane completely free (but no SLA) - great deal for test clusters and testing infra. If you are that worried about costs, then public cloud may not be for you at all, or you should look at ECS/App containers or serverless. reply oofbey 12 hours agoparentprevIf you do find yourself wanting to create a cluster by hand, it's probably because you don't actually need lots of machines in the \"cluster\". In my experience it's super handy to run tests on a single-node \"cluster\", and then k3s is super simple. It takes something like 8 seconds to install k3s on a bare CI/CD instance, and then you can install your YAML and see that it works. Once you're used to it, the high-level abstractions of k8 are wonderful. I run k3s on raspberry pi's because it takes care of all sorts of stuff for you, and it's easy to port code and design patterns from the big backend service to a little home project. reply ants_everywhere 14 hours agoprevPeople talk about Kubernetes as container orchestration, but I think that's kind of backwards. Kubernetes is a tool for creating computer clusters. Hence the name \"Borg\" (Kubernetes's grandpa) referring to assimilating heterogeneous hardware into a collective entity. Containers are an implementation detail. Do you need a computer cluster? If so k8s is pretty great. If you don't care about redundancy and can get all the compute you need out of a single machine, then you may not need a cluster. Once you're using containers on a bunch of VMs in different geographical regions, then you effectively have hacked together a virtual cluster. You can get by without k8s. You just have to write a lot of glue code to manage VMs, networking, load balancing, etc on the cloud provider you use. The overhead of that is probably larger than just learning Kubernetes in the long run, but it's reasonable to take on that technical debt if you're just trying to move fast and aren't concerned about the long run. reply stickfigure 14 hours agoparentK8s doesn't help you solve your geographical region problem, because the geographical region problem is not running appserver instances in multiple regions. Almost any PaaS will do that for you out of the box, with way less fuss than k8s. The hard part is distributing your data. Less overhead than writing your own glue code, less overhead than learning Kubernetes, is just use a PaaS like Google App Engine, Amazon Elastic Beanstalk, Digital Ocean App Platform, or Heroku. You have access to the same distributed databases you would with k8s. Cloud Run is PaaS for people that like Docker. If you don't even want to climb that learning curve, try one of the others. reply photonthug 12 hours agorootparent> just use a PaaS like Google App Engine, Amazon Elastic Beanstalk, Digital Ocean App Platform, or Heroku. This is the right way for web most of the time, but most places will choose k8s anyway. It‚Äôs perplexing until you come to terms with the dirty secret of resume driven development, which is that it‚Äôs not just junior engs but lots of seniors too and some management that‚Äôs all conspiring to basically defraud business owners. I think the unspoken agreement is that Hard work sucks, but easy work that helps you learn no transferable skills might be worse. The way you evaluate this tradeoff predictably depends how close you are to retirement age. Still, since engineers are often disrespected/discarded by business owners and have no job security, oaths of office, professional guilds, or fiduciary responsibility.. it‚Äôs no wonder things are pretty mercenary out there. Pipelines are as important as web these days but of course there are many options for pipelines as a service also. K8s is the obviously correct choice for teams that really must build new kinds of platforms that have many diverse kinds of components, or have lots of components with unique requirements for coupling (like say ‚Äúscale this thing based on that other thing‚Äù, but where you‚Äôd have real perf penalties for leaving the k8s ecosystem to parse events or whatever). The often mentioned concern about platform lock in is going to happen to you no matter what, and switching clouds completely rarely happens anyway. If you do switch, it will be hard and time consuming no matter what. To be fair, k8s also enables brand new architectural possibilities that may or may not be beautiful. But it‚Äôs engineering, not art, and beautiful is not the same as cheap, easy, maintainable, etc. reply vrosas 13 hours agorootparentprevPaaS get such a bad rap from devs in my experience, even though they would solve so many problems. They'd rather keep their k8s clusters scaled to max traffic and spend their nights dealing with odd networking and configuration issues than just throw their app on Cloud Run and call it a day. reply davidgl 9 hours agoparentprevYep, it's a cluster OS. If you need to run a cluster, you need to explore and understand the trade offs of k8s versus other approaches. Personally I run a small cluster on k3s, for internal tools, and love it. Yes it's a load of new abstractions to learn, but once learnt if really helps in designing large scalable systems. I manage lots of pet machines and VMs for clients, and it would be soooo much easier on k8. reply politelemon 14 hours agoparentprevI like to describe it similarly, but as a way of building platforms. reply ashishmax31 12 hours agoparentprevExactly. I've come to describe k8s as a distributed operating system for servers. K8s tries to abstract away individual \"servers\" and gives you an API to interact with all the compute/storage in the cluster. reply otabdeveloper4 8 hours agoparentprev> Containers are an implementation detail. They really aren't. Personally I have a big Nix derivation to deploy my (heterogeneous) cluster to bare metal. None of the k8s concepts or ideas apply here. reply _flux 13 hours agoparentprevWhat is the container orchestration tool of choice beyond docker swarm, then? reply rixed 11 hours agorootparentIs nomad still around? reply _flux 11 hours agorootparentThanks, hadn't heard of that. Seems pretty active per its commit activity: https://github.com/hashicorp/nomad/graphs/commit-activity But the fact that I hadn't heard of it before makes it sound not very popular, at least not for the bubble I live in :). Does anyone have any practical experiences to share about it? reply ChocolateGod 11 hours agorootparentYes have a few Nomad clusters in production and it's been great. You'll certainly want to combine it with Consul and use Consul templates and service discovery though. I'd say the difficulty and complexity level is between Kubernetes and Docker Swarm, not having to use YML too is a big benefit imho. reply Spivak 14 hours agoparentprevThis has got to be the most out there k8s take I've read in a while. k8s doesn't save you from learning your cloud providers infrastructure, you have to learn k8s in addition to your cloud provider's infrastructure. It's all ALBs, ASGs, Security Groups, EBS Volumbes and IAM policy underneath and k8s, while very clever, isn't so clever as to abstract much of any of it away from you. On EKS you get to enjoy more odd limitations with your nodes than EC2 would give you on its own. You're already building on a cluster, your cloud provider's hypervisor. They'll literally build virtual compute of any size and shape for you on demand out of heterogeneous hardware and the security guarantees are much stronger than colocated containers on k8s nodes. There are quite a few steps between single server and k8s. reply p_l 4 hours agorootparentK8s was designed around deployment on premise on bare metal hardware. The cloud extensions were always just a convenience. reply psini 9 hours agorootparentprevYou can self host Kubernetes on \"dumb\" VMs from Hetzner or OVH. reply lkrubner 15 hours agoprevInteresting that the mania for over-investment in devops is beginning to abate. Here on Hacker News I was a steady critic of both Docker and Kubernetes, going to at least 2017, but most of these posts were unpopular. I have to go back to 2019 to find one that sparked a conversation: https://news.ycombinator.com/item?id=20371961 The stuff I posted about Kubernetes did not draw a conversation, but I was simply documenting what I was seeing: vast over-investment in devops even at tiny startups that were just getting going and could have easily dumped everything on a single server, exactly as we used to do things back in 2005. reply OtomotO 15 hours agoparentIt's just the hype moving on. Every generation has to make similar mistakes again and again. I am sure if we had the opportunity and the hype was there we would've used k8s in 2005 as well. The same thing is true for e.g. JavaScript on the frontend. I am currently migrating a project from React to HTMX. Suddenly there is no build step anymore. Some people were like: \"That's possible?\" Yes, yes it is and it turns out for that project it increases stability and makes everything less complex while adding the exact same business value. Does that mean that React is always the wrong choice? Well, yes, React sucks, but solutions like React? No! It depends on what you need, on the project! Just as a carpenter doesn't use a hammer to saw, we as a profession should strive to use the right tool for the right job. (Albeit it's less clear than for the carpenter, granted) reply sarchertech 6 hours agorootparent>Just as a carpenter doesn't use a hammer to saw, we as a profession should strive to use the right tool for the right job. (Albeit it's less clear than for the carpenter, granted) The problem is that most devs don‚Äôt view themselves as carpenters. They view themselves as hammer capenters or saw carpenters etc‚Ä¶ It‚Äôs not entirely their fault, some of the tools are so complex that you really need to devote most of your time to 1 of them. I realize that this kind of tool specialization is sometimes required, but I that it‚Äôs overused by at the very least an order of magnitude. The vast majority of companies that are running k8s, react, kafka etc‚Ä¶ with a team of 40+, would be better off running rails (or similar) on heroku (or similar), or a VPS, or a couple servers in the basement. Most of these companies could easily replace their enormous teams of hammer carpenters and saw carpenters with 3-4 carpenters. But devs have their own gravity. The more devs you have the faster you draw in new ones, so it‚Äôs unclear to me if a setup like the above is sustainable long term outside of very specific circumstances. But if it were simpler there wouldn‚Äôt be nearly many jobs, so I really shouldn‚Äôt complain. And it‚Äôs not like every other department isn‚Äôt also bloated. reply ajayvk 15 hours agorootparentprevAlong those lines, I am building https://github.com/claceio/clace for teams to deploy internal tools. It provides a Cloud Run type interface to run containers, including scaling down to zero. It implements an application server than runs containerized apps. Since HTMX was mentioned, Clace also makes it easy to build Hypermedia driven apps. reply MortyWaves 8 hours agorootparentWould you be open",
    "originSummary": [
      "The author transitioned from Kubernetes to Google Cloud Run, citing Kubernetes's complexity, cost, and slow autoscaling as drawbacks.- Google Cloud Run is highlighted as a simpler, cost-effective alternative, charging only for actual CPU and memory usage, and offering quick scaling without Kubernetes's management overhead.- The author uses GitHub Actions for continuous integration/continuous deployment (CI/CD), managed databases, and pub-sub messaging, emphasizing Cloud Run's suitability for projects needing simplicity and efficiency over Kubernetes's extensive features."
    ],
    "commentSummary": [
      "The article critiques Kubernetes for being overly complex and often unnecessary for smaller projects, suggesting simpler solutions like a single virtual machine (VM) or server might be more efficient.",
      "It highlights the challenges of managing Kubernetes, including the added complexity from various add-ons and the tendency for some engineers to complicate systems.",
      "The consensus is that while Kubernetes is valuable, it is not always the best choice for smaller-scale operations, where simplicity can be more beneficial."
    ],
    "points": 321,
    "commentCount": 376,
    "retryCount": 0,
    "time": 1732674379
  },
  {
    "id": 42251799,
    "title": "Hacker in Snowflake extortions may be a U.S. soldier",
    "originLink": "https://krebsonsecurity.com/2024/11/hacker-in-snowflake-extortions-may-be-a-u-s-soldier/",
    "originBody": "November 26, 2024 14 Comments Two men have been arrested for allegedly stealing data from and extorting dozens of companies that used the cloud data storage company Snowflake, but a third suspect ‚Äî a prolific hacker known as Kiberphant0m ‚Äî remains at large and continues to publicly extort victims. However, this person‚Äôs identity may not remain a secret for long: A careful review of Kiberphant0m‚Äôs daily chats across multiple cybercrime personas suggests they are a U.S. Army soldier who is or was recently stationed in South Korea. Kiberphant0m‚Äôs identities on cybercrime forums and on Telegram and Discord chat channels have been selling data stolen from customers of the cloud data storage company Snowflake. At the end of 2023, malicious hackers discovered that many companies had uploaded huge volumes of sensitive customer data to Snowflake accounts that were protected with nothing more than a username and password (no multi-factor authentication required). After scouring darknet markets for stolen Snowflake account credentials, the hackers began raiding the data storage repositories for some of the world‚Äôs largest corporations. Among those was AT&T, which disclosed in July that cybercriminals had stolen personal information, phone and text message records for roughly 110 million people. Wired.com reported in July that AT&T paid a hacker $370,000 to delete stolen phone records. On October 30, Canadian authorities arrested Alexander Moucka, a.k.a. Connor Riley Moucka of Kitchener, Ontario, on a provisional arrest warrant from the United States, which has since indicted him on 20 criminal counts connected to the Snowflake breaches. Another suspect in the Snowflake hacks, John Erin Binns, is an American who is currently incarcerated in Turkey. A surveillance photo of Connor Riley Moucka, a.k.a. ‚ÄúJudische‚Äù and ‚ÄúWaifu,‚Äù dated Oct 21, 2024, 9 days before Moucka‚Äôs arrest. This image was included in an affidavit filed by an investigator with the Royal Canadian Mounted Police (RCMP). Investigators say Moucka, who went by the handles Judische and Waifu, had tasked Kiberphant0m with selling data stolen from Snowflake customers who refused to pay a ransom to have their information deleted. Immediately after news broke of Moucka‚Äôs arrest, Kiberphant0m was clearly furious, and posted on the hacker community BreachForums what they claimed were the AT&T call logs for President-elect Donald J. Trump and for Vice President Kamala Harris. ‚ÄúIn the event you do not reach out to us @ATNT all presidential government call logs will be leaked,‚Äù Kiberphant0m threatened, signing their post with multiple ‚Äú#FREEWAIFU‚Äù tags. ‚ÄúYou don‚Äôt think we don‚Äôt have plans in the event of an arrest? Think again.‚Äù On the same day, Kiberphant0m posted what they claimed was the ‚Äúdata schema‚Äù from the U.S. National Security Agency. ‚ÄúThis was obtained from the ATNT Snowflake hack which is why ATNT paid an extortion,‚Äù Kiberphant0m wrote in a thread on BreachForums. ‚ÄúWhy would ATNT pay Waifu for the data when they wouldn‚Äôt even pay an extortion for over 20M+ SSNs?‚Äù Kiberphant0m posting what he claimed was a ‚Äúdata schema‚Äù stolen from the NSA via AT&T. Also on Nov. 5, Kiberphant0m offered call logs stolen from Verizon‚Äôs push-to-talk (PTT) customers ‚Äî mainly U.S. government agencies and emergency first responders. On Nov. 9, Kiberphant0m posted a sales thread on BreachForums offering a ‚ÄúSIM-swapping‚Äù service targeting Verizon PTT customers. In a SIM-swap, fraudsters use credentials that are phished or stolen from mobile phone company employees to divert a target‚Äôs phone calls and text messages to a device they control. MEET ‚ÄòBUTTHOLIO‚Äô Kiberphant0m joined BreachForums in January 2024, but their public utterances on Discord and Telegram channels date back to at least early 2022. On their first post to BreachForums, Kiberphant0m said they could be reached at the Telegram handle @cyb3rph4nt0m. A review of @cyb3rph4nt0m shows this user has posted more than 4,200 messages since January 2024. Many of these messages were attempts to recruit people who could be hired to deploy a piece of malware that enslaved host machines in an Internet of Things (IoT) botnet. On BreachForums, Kiberphant0m has sold the source code to ‚ÄúShi-Bot,‚Äù a custom Linux DDoS botnet based on the Mirai malware. Kiberphant0m had few sales threads on BreachForums prior to the Snowflake attacks becoming public in May, and many of those involved databases stolen from companies in South Korea. On June 5, 2024, a Telegram user by the name ‚ÄúButtholio‚Äù joined the fraud-focused Telegram channel ‚ÄúComgirl‚Äù and claimed to be Kiberphant0m. Buttholio made the claim after being taunted as a nobody by another denizen of Comgirl, referring to their @cyb3rph4nt0m account on Telegram and the Kiberphant0m user on cybercrime forums. ‚ÄúType ‚Äòkiberphant0m‚Äô on google with the quotes,‚Äù Buttholio told another user. ‚ÄúI‚Äôll wait. Go ahead. Over 50 articles. 15+ telecoms breached. I got the IMSI number to every single person that‚Äôs ever registered in Verizon, Tmobile, ATNT and Verifone.‚Äù On Sept. 17, 2023, Buttholio posted in a Discord chat room dedicated to players of the video game Escape from Tarkov. ‚ÄúCome to Korea, servers there is pretty much no extract camper or cheater,‚Äù Buttholio advised. In another message that same day in the gaming Discord, Buttholio told others they bought the game in the United States, but that they were playing it in Asia. ‚ÄúUSA is where the game was purchased from, server location is actual in game servers u play on. I am a u.s. soldier so i bought it in the states but got on rotation so i have to use asian servers,‚Äù they shared. ‚ÄòREVERSESHELL‚Äô The account @Kiberphant0m was assigned the Telegram ID number 6953392511. A review of this ID at the cyber intelligence platform Flashpoint shows that on January 4, 2024 Kibertphant0m posted to the Telegram channel ‚ÄúDstat,‚Äù which is populated by cybercriminals involved in launching distributed denial-of-service (DDoS) attacks and selling DDoS-for-hire services [Full disclosure: Flashpoint is currently an advertiser on this website]. Immediately after Kiberphant0m logged on to the Dstat channel, another user wrote ‚Äúhi buttholio,‚Äù to which Kiberphant0m replied with an affirmative greeting ‚Äúwsg,‚Äù or ‚Äúwhat‚Äôs good.‚Äù On Nov. 1, Dstat‚Äôs website dstat[.]cc was seized as part of ‚ÄúOperation PowerOFF,‚Äù an international law enforcement action against DDoS services. Flashpoint‚Äôs data shows that @kiberphant0m told a fellow member of Dstat on April 10, 2024 that their alternate Telegram username was ‚Äú@reverseshell,‚Äù and did the same two weeks later in the Telegram chat The Jacuzzi. The Telegram ID for this account is 5408575119. Way back on Nov. 15, 2022, @reverseshell told a fellow member of a Telegram channel called Cecilio Chat that they were a soldier in the U.S. Army. This user also shared the following image of someone pictured waist-down in military fatigues, with a camouflaged backpack at their feet: Kiberphant0m‚Äôs apparent alias ReverseShell posted this image on a Telegram channel Cecilio Chat, on Nov. 15, 2022. Image: Flashpoint. In September 2022, Reverseshell was embroiled in an argument with another member who had threatened to launch a DDoS attack against Reverseshell‚Äôs Internet address. After the promised attack materialized, Reverseshell responded, ‚ÄúYall just hit military base contracted wifi.‚Äù In a chat from October 2022, Reverseshell was bragging about the speed of the servers they were using, and in reply to another member‚Äôs question said that they were accessing the Internet via South Korea Telecom. Telegram chat logs archived by Flashpoint show that on Aug. 23, 2022, Reverseshell bragged they‚Äôd been using automated tools to find valid logins for Internet servers that they resold to others. ‚ÄúI‚Äôve hit US gov servers with default creds,‚Äù Reverseshell wrote, referring to systems with easy-to-guess usernames and/or passwords. ‚ÄúTelecom control servers, machinery shops, Russian ISP servers, etc. I sold a few big companies for like $2-3k a piece. You can sell the access when you get a big SSH into corporation.‚Äù On July 29, 2023, Reverseshell posted a screenshot of a login page for a major U.S. defense contractor, claiming they had an aerospace company‚Äôs credentials to sell. PROMAN AND VARS_SECC Flashpoint finds the Telegram ID 5408575119 has used several aliases since 2022, including Reverseshell and Proman557. A search on the username Proman557 at the cyber intelligence platform Intel 471 shows that a hacker by the name ‚ÄúProman554‚Äù registered on Hackforums in September 2022, and in messages to other users Proman554 said they can be reached at the Telegram account Buttholio. Intel 471 also finds the Proman557 moniker is one of many used by a person on the Russian-language hacking forum Exploit in 2022 who sold a variety of Linux-based botnet malware. Proman557 was eventually banned ‚Äî allegedly for scamming a fellow member out of $350 ‚Äî and the Exploit moderator warned forum users that Proman557 had previously registered under several other nicknames, including an account called ‚ÄúVars_Secc.‚Äù Vars_Secc‚Äôs thousands of comments on Telegram over two years show this user divided their time between online gaming, maintaining a DDoS botnet, and promoting the sale or renting of their botnets to other users. ‚ÄúI use ddos for many things not just to be a skid,‚Äù Vars_Secc pronounced. ‚ÄúWhy do you think I haven‚Äôt sold my net?‚Äù They then proceeded to list the most useful qualities of their botnet: -I use it to hit off servers that ban me or piss me off -I used to ddos certain games to get my items back since the data reverts to when u joined -I use it for server side desync RCE vulnerabilities -I use it to sometimes ransom -I use it when bored as a source of entertainment Flashpoint shows that in June 2023, Vars_Secc responded to taunting from a fellow member in the Telegram channel SecHub who had threatened to reveal their personal details to the federal government for a reward. ‚ÄúMan I‚Äôve been doing this shit for 4 years,‚Äù Vars_Secc replied nonchalantly. ‚ÄúI highly doubt the government is going to pay millions of dollars for data on some random dude operating a pointless ddos botnet and finding a few vulnerabilities here and there.‚Äù For several months in 2023, Vars_Secc also was an active member of the Russian-language crime forum XSS, where they sold access to a U.S. government server for $2,000. However, Vars_Secc would be banned from XSS after attempting to sell access to the Russian telecommunications giant Rostelecom. [In this, Vars_Secc violated the Number One Rule for operating on a Russia-based crime forum: Never offer to hack or sell data stolen from Russian entities or citizens]. On June 20, 2023, Vars_Secc posted a sales thread on the cybercrime forum Ramp 2.0 titled, ‚ÄúSelling US Gov Financial Access.‚Äù ‚ÄúServer within the network, possible to pivot,‚Äù Vars_Secc‚Äôs sparse sales post read. ‚ÄúHas 3-5 subroutes connected to it. Price $1,250. Telegram: Vars_Secc.‚Äù Vars_Secc also used Ramp in June 2023 to sell access to a ‚ÄúVietnam government Internet Network Information Center.‚Äù ‚ÄúSelling access server allocated within the network,‚Äù Vars_Secc wrote. ‚ÄúHas some data on it. $500.‚Äù BUG BOUNTIES The Vars_Secc identity claimed on Telegram in May 2023 that they made money by submitting reports about software flaws to HackerOne, a company that helps technology firms field reports about security vulnerabilities in their products and services. Specifically, Vars_Secc said they had earned financial rewards or ‚Äúbug bounties‚Äù from reddit.com, the U.S. Department of Defense, and Coinbase, among 30 others. ‚ÄúI make money off bug bounties, it‚Äôs quite simple,‚Äù Vars_Secc said when asked what they do for a living. ‚ÄúThat‚Äôs why I have over 30 bug bounty reports on HackerOne.‚Äù A month before that, Vars_Secc said they‚Äôd found a vulnerability in reddit.com. ‚ÄúI poisoned Reddit‚Äôs cache,‚Äù they explained. ‚ÄúI‚Äôm going to exploit it further, then report it to reddit.‚Äù KrebsOnSecurity sought comment from HackerOne, which said it would investigate the claims. This story will be updated if they respond. The Vars_Secc telegram handle also has claimed ownership of the BreachForums member ‚ÄúBoxfan,‚Äù and Intel 471 shows Boxfan‚Äôs early posts on the forum had the Vars_Secc Telegram account in their signature. In their most recent post to BreachForums in January 2024, Boxfan disclosed a security vulnerability they found in Naver, the most popular search engine in South Korea (according to statista.com). Boxfan‚Äôs comments suggest they have strong negative feelings about South Korean culture. ‚ÄúHave fun exploiting this vulnerability,‚Äù Boxfan wrote on BreachForums, after pasting a long string of computer code intended to demonstrate the flaw. ‚ÄúFuck you South Korea and your discriminatory views. Nobody likes ur shit kpop you evil fucks. Whoever can dump this DB [database] congrats. I don‚Äôt feel like doing it so I‚Äôll post it to the forum.‚Äù The many identities tied to Kiberphant0m strongly suggest they are or until recently were a U.S. Army soldier stationed in South Korea. Kiberphant0m‚Äôs alter egos never mentioned their military rank, regiment, or specialization. However, it is likely that Kiberphant0m‚Äôs facility with computers and networking was noticed by the Army. According to the U.S. Army‚Äôs website, the bulk of its forces in South Korea reside within the Eighth Army, which has a dedicated cyber operations unit focused on defending against cyber threats. On April 1, 2023, Vars_Secc posted to a public Telegram chat channel a screenshot of the National Security Agency‚Äôs website. The image indicated the visitor had just applied for some type of job at the NSA. A screenshot posted by Vars_Secc on Telegram on April 1, 2023, suggesting they just applied for a job at the National Security Agency. The NSA has not yet responded to requests for comment. Reached via Telegram, Kiberphant0m acknowledged that KrebsOnSecurity managed to unearth their old handles. ‚ÄúI see you found the IP behind it no way,‚Äù Kiberphant0m replied. ‚ÄúI see you managed to find my old aliases LOL.‚Äù Kiberphant0m denied being in the U.S. Army or ever being in South Korea, and said all of that was a lengthy ruse designed to create a fictitious persona. ‚ÄúEpic opsec troll,‚Äù they claimed. Asked if they were at all concerned about getting busted, Kiberphant0m called that an impossibility. ‚ÄúI literally can‚Äôt get caught,‚Äù Kiberphant0m said, declining an invitation to explain why. ‚ÄúI don‚Äôt even live in the USA Mr. Krebs.‚Äù Below is a mind map that hopefully helps illustrate some of the connections between and among Kiberphant0m‚Äôs apparent alter egos. A mind map of the connections between and among the identities apparently used by Kiberphant0m. Click to enlarge. KrebsOnSecurity would like to extend a special note of thanks to the New York City based security intelligence firm Unit 221B for their assistance in helping to piece together key elements of Kiberphant0m‚Äôs different identities. This entry was posted on Tuesday 26th of November 2024 07:45 PM A Little Sunshine DDoS-for-Hire Ne'er-Do-Well News Ransomware The Coming Storm AT&T Boxfan buttholio Connor Riley Moucka cyb3rph4nt0m John Erin Binns Judische Kiberphant0m Naver Proman557 Reverseshell Shi-Bot Snowflake South Korea telekomterrorist Vars_Secc Verizon Waifu",
    "commentLink": "https://news.ycombinator.com/item?id=42251799",
    "commentBody": "Hacker in Snowflake extortions may be a U.S. soldier (krebsonsecurity.com)308 points by todsacerdoti 18 hours agohidepastfavorite167 comments alsetmusic 16 hours ago> Kiberphant0m denied being in the U.S. Army or ever being in South Korea, and said all of that was a lengthy ruse designed to create a fictitious persona. > > ‚ÄúEpic opsec troll,‚Äù they claimed. If this were really a fictitious persona meant to lead investigators away from their true identity, they'd never admit to such. This sounds like someone trying to deflect upon being found out. I'd wager that this person is going to be caught. Krebs has an image of a mind-map at the end of the article showing links between the aliases. reply seanhunter 11 hours agoparentYes. I'm pretty sure if you spoke to an intelligence analyst they would tell you there's no such thing as an opsec troll. Everything your target does (including misdirection) gives or risks giving away information, and there's no way someone who is actually in control of events would blow a cover because even if you were 99% certain it was false, you would have to continually waste resources trying to confirm that. In particular if they invested a lot in building this persona and you were on to them it's much more likely they would just go dark, wait and plan how to pick up with a new persona. reply InDubioProRubio 10 hours agorootparentThere are robots for everything social now- including manufacturing personas. reply datadrivenangel 6 hours agorootparentIt's not about the volume of manufactured personas, it's about the tool-marks that can be analyzed. reply horeszko 15 hours agoparentprev> Kiberphant0m denied being in the U.S. Army or ever being in South Korea, and said all of that was a lengthy ruse designed to create a fictitious persona. ‚ÄúEpic opsec troll,‚Äù they claimed. This is called a \"double cover story\", a classic deflection when someone is caught or exposed. reply asimjalis 15 hours agorootparentIt could be a triple cover story. The faked double cover story is meant to deflect. reply tedunangst 15 hours agorootparentMaybe even skipping the quadruple cover story and going straight to the quintuple. A true pro. reply function_seven 15 hours agorootparentI always play the (2n+1) game myself. (Or do I??) reply the_af 2 hours agorootparentThat's what they... er, you... er, somebody wants you to think? reply formerly_proven 2 hours agorootparentThat‚Äôs my secret‚Ä¶ I never think. reply labster 14 hours agorootparentprevGood luck, I‚Äôm behind seven cover stories reply blitzar 9 hours agorootparentGotta pump those numbers up. Those are rookie numbers in this racket. I myself, I have fourteen cover stories with an infinite loop at number 10 that directs you back to 4. reply oefnak 8 hours agorootparentWhere do you use 11-14 for? reply Mtinie 7 hours agorootparentHigher dimensional investigations. reply avn2109 7 hours agorootparentprevPlot twist, I'm actually undercover as you. reply the_af 2 hours agorootparentI know linking to videos on a tangent joke is frowned upon here, but I'll risk the downvotes for a worthy cause: You really need to watch this Key & Peele & Rocket Jump colaboration: https://www.youtube.com/watch?v=IHQr0HCIN2w Actually, since I'm actually undercover as you, and I've already watched it... reply edzillion 7 minutes agorootparentI know comments commending the previous post are also frowned upon but that is one of the funniest sketches I've ever seen. Hilarity ad absurdum _carbyau_ 14 hours agorootparentprev\"Fuck everything, we're doing five covers.\" ... \"Put another misdirect on that fucker, too.\" reply Mtinie 6 hours agorootparentThat reminds me of the escalating ‚Äútrace buster‚Äù scene in ‚ÄúThe Big Hit.‚Äù https://youtu.be/2VY_xxL2jL0?si=9hf6ibvtHFCGuCNL reply pnut 6 hours agorootparentprevContext https://theonion.com/fuck-everything-were-doing-five-blades-... reply gostsamo 14 hours agoparentprevLet's just not believe anything said by an untrustworthy person. What they say should not calculate in what we believe to be true, but only evidence we can verify. reply Y_Y 9 hours agorootparentI respectively disagree. If someone is shown to be unreliable then of course you won't take what they say at face value, but there's still information there. A deliberate lie may still contain something useful and reveal something about the person. In fact assuming someone to be truthful isn't a good prior, knowing that they may be \"untrustworthy\" doesn't tell me much, since I didn't start off thinking otherwise. reply red-iron-pine 3 hours agorootparentbut then we're not \"trusting\" what they're saying, just analyzing a statement for unintentional or partial truths. the assumption is not one of credibility. everything this person is doing is dubious as hell. this means every statement or action must be analyzed with the assumption is bunk, and then you pick out possible truths. the picture of the army gear, for example, consists of gear that could be purchased at any surplus store. I'm not in the US but I could easy acquire that, and I know enough about exif data to be able to alter an image to use GPS coordinates at a US Army barracks in SK. meanwhile if they were showing a picture of them sitting with, say, a 240B MG, or something that actually proves they're in the US Army I might believe them. while bartending back in the day I used to have a coworker who, after a few drinks one night, eventually confessed she was a camgirl for a while. she went by April, who was really Stefani -- nether of which were her real names, but were just layers to keep stalkers off of her back. she had friends on the other side of the country take pictures of their dorm to help further the story. I totally believe a serious cracker would take similar precautions; OPSEC on OPSEC reply Y_Y 2 hours agorootparentI agree and liked your comment. I just want to add that I was specifically disagreeing with this: > What they say should not calculate in what we believe to be true rather than thinking about definitions of trust. reply gostsamo 8 hours agorootparentprevYou can analyze a lie only if you know that the speaker is trying to convince you into performing an action. Binary statements about facts cannot be judged without knowing the truth. They could be used only for self-analysis of the analyzer and maybe if you want to exercise some tail chasing. Watch The Princess Bride and you will find a wonderful scene about choosing the right cup there. reply laborcontract 4 hours agorootparentvon Neumann proved that you can extract fair results from a biased coin without knowing the bias. No truth needed. While it doesn‚Äôt really apply to this situation, it‚Äôs all to say that i disagree with you saying there‚Äôs only information in the truth.. There‚Äôs information in everything. reply sourcepluck 8 hours agorootparentprevI can't help myself: is this the famous logic by which tech people don't trust apple, microsoft, amazon, meta, or google products? Or does it not apply to corporations? What's the distinction, if so? It certainly seems common to not to apply it to corporations. Not sniping here, I actually think this is solid logic, maybe with some exceptions but generally applicable. I feel like it's so commonly and happily not applied when it comes to the above companies (and others) that I find it stunning to see it stated so clearly here. reply cherryteastain 7 hours agorootparentWe already have direct evidence through Snowden leaks that US big tech corps are US intelligence assets. reply Y_Y 2 hours agorootparentprevPersonally my prior is that companies are always trying to manipulate you, and people only sometimes. On the other hand it can be easier to get away with false statements when you don't have a large audience and deep pockets. reply gostsamo 6 hours agorootparentprevThis FAANG stuff is coming a bit from left field here. I have my thoughts on their involvement with the US government, but I cannot testify if those thoughts are the same for any other tech person on this platform. Lots of other stuff to say, but generally, I tend to apply the same mental tools to everyone. You should ask everyone else for their opinions individually though. reply skybrian 11 hours agorootparentprevWell yes, but I doubt that Krebs is really posting this data dump for random Internet readers like us. Some other investigator might find some useful hints in it, though. reply dookahku 15 hours agoparentprev> This sounds like someone trying to deflect upon being found out. I'd wager that this person is going to be caught. that's what a super epic opsec troll would want you to think reply Terr_ 15 hours agorootparent\"You fell victim to one of the classic blunders! The most famous is 'never get involved in a(nother) land-war in Asia', but only slightly less well-known is this: Never go up against a once-Korean-resident when death is on the line! Aha-haha-hahaha!\" https://www.youtube.com/watch?v=pRJ8CrTSSR0 reply kgeist 13 hours agoparentprevInterestingly, Kiber- is how a Russian would transliterate \"Cyber-\". At first I thought he must be Russian, by the nickname alone (I'm a Russian speaker). reply ARandomerDude 18 minutes agorootparentI‚Äôm guessing any American military member in the Intel or Cyber business would know that these days though. Years ago when I was in the US military I knew many Russian weapons systems better than their US/NATO counterparts and had developed a decent working vocabulary of Russian words and prefixes in that specific area because it was my job to study Russian equipment. reply ANewFormation 12 hours agorootparentprevSomething I don't understand is why people don't appreciate /expect misdirection. For instance, a malicious actor, of even basic sophistication, coming from a Russian ip and occasionally using Cyrillic and missing grammatic artcles is probably not Russian. Similarly a malcious actor with a pseudonym including the term patriot, coming from a US IP and using terms like howdy probably is not American. False attribution is a core lesson in malice 101. reply andrewflnr 12 hours agorootparentThere's a case to be made for expecting misdirection more often, but the fact remains that most people, including malicious actors, don't have the foresight and skill to pull it off. You do need both. Unless you plan a consistent fake story from the very start of an identity, execute it consistently, and hermetically isolate it from any others, you'll leave clues. reply strken 8 hours agorootparentprevYou need actual evidence to make claims like this and be believed. \"Possibly not Russian/American\" is self-evident due to how easy misdirection is, but \"probably not Russian/American\" is a matter of probability for which you've presented no meaningful data or argument. reply RicoElectrico 3 hours agorootparentprevForget about grammar. Eyless emoticons are the best predictor))) reply johnnyanmac 9 hours agorootparentprevNot that it's necessarily the case here, but you'd be surprised how many grand capers were only busted because the actor made an embarrassingly dumb mistake in leaving some obvious trail. It's not unheard of to apply some occam's razor just in case while keeping misdirection in mind. Even masterminds aren't perfectly rational actors that cross all their t's. reply red-iron-pine 3 hours agorootparentprevAttribution is hard, and is a critical part of Threat Analysis. I generally agree with the quip about American patriot actors, mostly. reply lupusreal 4 hours agorootparentprevIf your company just got pwned, you'll probably be thankful to have an excuse to tell your investors that it was a Russian/etc \"state actor\" and therefore they should feel sympathy for you being the victim of a foe that far outclasses your assuredly reasonable and competent security measures. Looks a lot better than getting pwned by some jackass American teenager. So if the attack came from a Russian IP, or used some Cyrillic characters or something like that, there's a \"face saving\" incentive to take that probable misdirection at face value. reply pphysch 1 hour agorootparentThis is right. So many incentives are stacked in favor of making false attributions, specifically to enemy state actors: - real attacker doesn't want to get caught - victim doesn't want to admit being pwned by a script kiddy or petty criminal - military-industrial complex needs foreign threat inflation to stay in business - media loves the intrigue The pushback would come from the foreign state being falsely slandered, but they never get a say anyways. reply close04 4 hours agorootparentprev> False attribution is a core lesson in malice 101 I was always surprised to see security researchers confidently attributing some attack to a specific group based on easily falsifiable things like localization, alphabet, time zone, coding \"style\", specific targets, etc. Even if researchers can undeniably link one attack to a certain group (like when they publicly take responsibility) and can label their style accordingly, all those indicators become at least semi-public. If the researchers have access to them, so do other other actors who are free to fake or imitate them. The confidence is probably more for the media reporting. reply rightbyte 9 hours agorootparentprevDoubly so since warmongerers will defend your persona and corparations will use the persona as a politically palatable scapegoat. reply ykonstant 11 hours agorootparentprevSpot on, chap. reply boohoo123 4 hours agorootparentprevyea but 2 years prior he used the handle cyberphantom. So the switch is most likely him trying to throw people off. reply johndhi 15 hours agoparentprevIt also seems like a bad opsec if he creates multiple aliases for the same theme. Wouldn't you want to have one us soldier, one Russian, one African, etc. if you are trying to create red herrings? reply XorNot 13 hours agorootparentEven the soldier persona is consistent though. The trouble with opsec like this is (1) you always have to win and (2) almost everything - even total randomness tends to create a pattern (since you the negative space of trying not to stand out itself tends to make you stand out). reply hilbert42 12 hours agoparentprevRight, there's something odd about this. That image from 2022 of a person's legs [Kiberphant0m?] in army fatigues ought to be a dead giveaway. For starters why would anyone be stupid enough to do that, second I'd recon the floor pattern alone might be enough to reveal the person, again why do that? Surely those involved would have have thought of that? Alternately they're on the room-temperature side of dumb. Of course, that doesn't include the image being a ruse for other schema. reply krisoft 6 hours agorootparent> why would anyone be stupid enough to do that To prove their \"credentials\" that they are a real world \"though guy\", in the hopes of gaining social clout in among their peers. Same reason why some posts classified information on Discord or War Thunder. reply bayindirh 11 hours agorootparentprev> Alternately they're on the room-temperature side of dumb. When combined with the uses the claimed for their botnet, the person we're talking about leaves an impression of having emotional maturity of a 10 year old. So, you might not be very far when it comes to non-technical skills. reply scotty79 6 hours agorootparent> leaves an impression of having emotional maturity of a 10 year old That fits well with the position of US president or the currently richest person on Earth. reply hilbert42 6 hours agorootparentI dare not comment, the thread would be deleted. ;-) reply asimjalis 15 hours agoparentprevMaybe he is operating at the next level. He is deflecting because the investigators will think that he is trying to lead them away from this true identity and become even more convinced of it, which is exactly what he wants. reply CoastalCoder 14 hours agorootparentTruly next level would be for him to be one of the investigators. reply Tepix 10 hours agorootparentLet's skip of this step and go the next: It's a rogue AI. reply chefandy 14 hours agorootparentprevBut little did he know the other instigators were investigating him‚Ä¶ or so they thought‚Ä¶ reply Oarch 6 hours agoparentprevYou'll never catch me! reply PittleyDunkin 15 hours agoparentprevEh; let's wait and see. For any claim for insight there's an equivalent claim for fabrication. any such analysis that relies on this is inherently flimsy. reply rudolph9 16 hours agoparentprevOr it‚Äôs part of the troll. reply uoaei 15 hours agorootparentBothsidesism has crept into ... US counterintel agitprop? reply bityard 50 minutes agoprevSome serious testicular fortitude in that guy. If a civilian gets caught doing something illegal, they are entitled to a fair trial with a jury of their peers. If a military member gets caught doing the same thing, the court martial is a mere formality, they just more or less go straight to jail for a very long time. reply IAmGraydon 13 hours agoprevThis seems like it would be rather easy for the government to narrow down. Check the logs of who applied for an NSA job on or around the date the screenshot was posted and cross reference any that are/were located in South Korea. I would think that would produce a rather short list that a bit more investigation would crack. The guy seems arrogant, and arrogant = sloppy. He'll get caught. reply readyplayernull 13 hours agoparentHe knows he's about to get caught, reason why he hurried to knock NSA's door. They might let him in after all. reply lukan 8 hours agorootparentBut probably after they arrested him, to help with negotiations. And to pop that bubble of false confidence. The way he acted, would be a very red flag for me, if I were to hire him. Maybe skillfull, but careless. And that is not acceptable in that line of work. (Neither it is in the military) reply teractiveodular 15 hours agoprev> ‚ÄúType ‚Äòkiberphant0m‚Äô on google with the quotes,‚Äù Buttholio told another user. ‚ÄúI‚Äôll wait. Go ahead. Over 50 articles. 15+ telecoms breached. I got the IMSI number to every single person that‚Äôs ever registered in Verizon, Tmobile, ATNT and Verifone.‚Äù SBF levels of self-pwning right there. When, not if, they catch him, the Feds are going to hang this clown out to dry. reply tgsovlerkhgsel 14 hours agoparentI'd rather see them hang out to dry the 15+ telecoms who gave away \"the IMSI number to every single person that's ever registered in...\" because doing so was cheaper than investing in security. reply atoav 12 hours agorootparentThe only data you can't leak is the data you don't have. Therefore some data should either not be stored at all or deleted after it served its purpose. reply dfedbeef 12 hours agorootparentProbably hard for a telecom company to not keep IMSI -> account association somewhere reply red-iron-pine 3 hours agorootparentrandomized IDs and linked lists, which correspond to entries in DBs elsewhere. IMEI 123456789 has ID sjkadnasf8uywjerhsdu, and then in the hyper locked down Mongo instance used by billing knows that sjkadnasf8uywjerhsdu relates to John Smith, credit card number xxxx xxxx xxxx xxxx make it so you have to crack all of em, instead of just nailing one and walking out w/ all the crown jewels reply mschuster91 4 hours agorootparentprevYeah, in separate databases on separate systems. The network plane of a phone provider should only be able to access a database mapping IMSI -> account ID, and the billing/customer service department should only be able to access a database mapping account ID -> actual account data. Unfortunately, anything involving phones is based on literally decades of stuff that was made in a time where every participant in the network was trusted by default, and bringing up the legacy compatibility stuff to modern standards is all but impossible. reply nkrisc 4 hours agorootparentprevWhy not both? reply benreesman 11 hours agoparentprevAnthropic levels of getting seed funding from SBF and ending up a power unto themselves. reply cedws 5 hours agoprevIt's a good thing that independent cybercriminals like this are so arrogant that they make the most basic opsec mistakes and expose themselves. reply juunpp 15 hours agoprevI guess we'll soon find out how well the NSA normalizes its databases. Bring on that schema, folks. reply gregw2 16 hours agoprevAny insight based on histogram of the timing of this person's posts, particularly ones responding to a just slightly earlier post? (ie was clearly awake and not an artificially-delayed response). Krebs knows about this timezone analysis technique, wonder if he didn't check this or it was inconclusive? reply t-3 15 hours agoparentIs that effective for people who aren't literally being paid a salary to do this stuff 9-5? A lot of people who spend too much time on computers have totally out of wack sleep schedules that would look like they're operating from very different timezones. reply alwayslikethis 14 hours agorootparentYou can also schedule your posts, commits, etc to go out at some fixed hours each day. reply sundarurfriend 13 hours agorootparentYou can, but a lot of these pattern analyses work out because people get sloppy and overconfident over time, and don't use these measures even if their lives are on the line. reply 0xDEAFBEAD 1 hour agoprevI noticed he seems to have posted a photo of his camouflage uniform? Pretty sure those are unique to every soldier... reply bityard 58 minutes agoparentNo, they are a very standard pattern. reply andrewflnr 10 minutes agorootparentMaybe GP was thinking about lining up specific pattern features with e.g. pockets and seams to identify a particular uniform. reply 0xDEAFBEAD 7 minutes agorootparentprevCan you show me an image where 2 soldiers, both wearing fatigues, have an identical camouflage pattern? Every image I find on Google Images has a distinct pattern per soldier. reply gosub100 50 minutes agoparentprevThe floor tiles (particularly the edges) might be able to locate which building he was in which could further narrow it down reply mft_ 40 minutes agorootparentThey‚Äôd better hope Rainbolt doesn‚Äôt take on the challenge‚Ä¶ reply antihero 16 hours agoprevCouldn't literally all of this just be a bunch of misdirection? reply mikeyouse 16 hours agoparentIn theory, sure, in reality it's almost always much more benign and they have terrible Opsec over time that allows people to piece together their identity. Especially if they reuse usernames across services. reply JohnMakin 15 hours agorootparentIt's always crappy opsec that gets people otherwise very savvy. reply raffraffraff 12 hours agorootparentKinda like how the big mastermind criminals like Capone get away with murder and racketeering but get fucked on tax evasion. Reading this guy's posts, his ego is the biggest issue, and it will be his downfall. The \"I literally can't get caught\" mentality inevitably leads to carelessness and blabbermouthing. reply kortilla 9 hours agorootparentThat‚Äôs a little different. It wasn‚Äôt that Capone couldn‚Äôt handle taxes, it was that until that point nobody used it as a serious mechanism to take town criminals. It was only validated as a good approach by the Supreme Court a few years before. In fact, one of the primary pieces of evidence of his tax evasion were from communications from his lawyer about how much tax to pay to make his tax history legit in light of the recent effectiveness of tax convictions. Now major criminals launder money to avoid that. reply duxup 16 hours agoparentprevI feel like leaving a bunch of misdirection would also risk potentially just leave real traces behind that in some ways. At least in my mind leaving some false trails behind, when I run through scenarios, seems like it could leave actual trails / to the point of not being worth the extra risk. reply brookst 13 hours agorootparentYeah. If you have a choice of giving an adversary no information or false information, no information seems safer. The choice of false information is information. Same way that people are terrible at picking random numbers and fraudsters are often caught because they avoid round numbers. reply antihero 7 hours agorootparentIt would make sense if doing something illegal to do the former, but also leave \"slip ups\" that are complete red herrings, create trails to people that seem like opsec fails but are actually just framing others, etc. All about plausible deniability. Layers and layers and layers of dead ends that seem real. In this way, if you do actually slip up, it becomes near impossible to distinguish the real slip-ups with the orchestrated ones. reply brookst 5 hours agorootparentThe problem is that false ‚Äúslip ups‚Äù provide information. Sure, you waste investigator‚Äôs time, but once they rule out the false lead they have a bunch of information: - if the false slip-up used only public information about, you likely don‚Äôt have access to confidential information about that space. If it used confidential information, you do. - The geography and demographics of the false lead are probably not near-misses. The point of misdirection is to misdirect, so you likely won‚Äôt frame a coworker that will bring investigators to your own door. - Any mistakes in the false slip-up, from spelling to factual to timing, may reveal info. IMO this is a ‚Äútoo clever by half‚Äù scenario: leaving any trace at all is information. Leaving none is wiser. Example: you‚Äôre a master hacker. You‚Äôre going to repeatedly access a compromised system. Is it better to set an alarm for 3am each time to suggest you‚Äôre in a different time zone, or to use a RNG to close an alarm time? I say the RNG is better. Using 3am gives psychographics. Random isn‚Äôt clear if there‚Äôs any planning at all, or if you travel, etc. reply hn_user82179 11 hours agoprevwhat a great article, I loved seeing the links that Krebs (?)/Unit 221B (?) dug up and all the info they managed to connect. It felt like I was reading a detective story. It sounds like this guy is doomed, the NSA application date alone basically identifies him reply polyvisual 5 hours agoparent221B is 221B Baker Street, where Sherlock Holmes lived. reply Tepix 10 hours agoparentprevIf you have enough data, i wonder how much of this digging can be automated these days with good LLM prompts. Doing it manually is very time-consuming. reply CharlieDigital 4 hours agorootparentThe real work doesn't happen in the LLM. Having worked with LLMs over the past year+ trying to get them to do useful things in various contexts, the real work is typically pretty boring data acquisition (e.g. scraping) + ETL and then making that data available to the LLM. reply jamestimmins 10 hours agorootparentprevI think this whenever I read a modern detective novel (Bosch). So much of their work seems to be looking up data from different databases and trying to make connections or recognize patterns. I assume the FBI or whomever has automated this to some degree already, and I really hope someone does a great writeup of how LLMs/agents can do even more. reply victorbjorklund 4 hours agoprevIt is always really bad opsec that gets them. Always. reply Simon_ORourke 10 hours agoprevDoesn't that just mean they won't ever to subject to prosecution by the International Criminal Court? reply Bengalilol 8 hours agoprevI don't get how such people could be as verbose as shown in this quite precise article. And I'm not even getting into the idea that he could be a US soldier ... reply red-iron-pine 3 hours agoparenthe's not. it's gear you can order online or get at any local surplus store. I'm not even in the US and a quick look shows it's trivial to get. it's another layer of obfuscation. strippers telling you their name is April (but then whispering to you that their real name is Stefani)... but their real name is actually Angela, and it's just another deflection to keep off the stalkers. same idea with IT OPSEC reply ilaksh 12 hours agoprevYou might be able to get a rough show size and height/weight range from that photo. reply lph 10 hours agoparentI wonder how unique those floor tile patterns are? If that's taken on a military base in Korea, it might be possible to find the exact location of the photo. reply excalibur 15 hours agoprev> Immediately after Kiberphant0m logged on to the Dstat channel, another user wrote ‚Äúhi buttholio,‚Äù to which Kiberphant0m replied with an affirmative greeting ‚Äúwsg,‚Äù or ‚Äúwhat‚Äôs good.‚Äù It's kind of unfortunate for him that he didn't do a better job of referencing Beavis and Butthead. If his username was \"Cornholio\" or even \"Bungholio\", it could read as someone directly referencing the show and potentially unrelated to the other account, making his deniability a bit more plausible. reply boomskats 10 hours agoparentA true opsec troll is saving those references for the final standoff, for when they start really threatening him. reply red-iron-pine 3 hours agorootparentyeah that's 3 or 4 layers in. until then convince them you're Iranian and Chinese first reply fnord77 15 hours agoprevBeing a high-stakes criminal is too difficult. One slip-up and you're compromised. There's a million opportunities for slip ups and there's a million opportunities for investigators to get lucky. reply alwayslikethis 14 hours agoparentTrue, but you only hear about the ones who slipped up. I wonder what is the actual proportion of criminals being caught due to poor opsec. reply ethbr1 13 hours agorootparentThere's a line at the beginning of Ocean's 11 to the effect of \"the house always wins in the long run... unless you bet it all on a great hand, win, and then walk away.\" reply mxuribe 1 hour agorootparent> ...and then walk away. I think that's the key right there! ;-) reply brookst 13 hours agorootparentprevTo turn it around: what percentage of people are capable of perfect opsec forever? reply flextheruler 5 hours agorootparentFor internet crimes? Almost none in perpetuity. I‚Äôd think you‚Äôd need to go off the grid totally for a few years and come back without any reference to a prior life. For physical crime, my gut says quite a few people have avoided identification for decades until they were essentially caught by turning themselves in. Ted Kaczynski comes to mind, but there must be a few others. Perfect OPSEC to me, means near total isolation from socialization. Not something most people are capable of. If you‚Äôre a professional criminal of any kind you weigh the risks knowing that perfection is impossible. The government is a business with a monopoly on violence. The goal is to keep their ROI for catching you as low as possible. Every single man hour spent finding you is costing money and there‚Äôs a man upstairs who wants to see some results that reflect the money spent. Once you understand that premise, it‚Äôs easy to understand the why and how criminals are caught. The ones who are caught are always the ones who don‚Äôt know when to fold. Always the ones not to cash in and retire. The ones who get away with it, they fold they retire and society forgets about them and the ROI drops precipitously on catching them. Research statistics on cold cases. reply duxup 16 hours agoprev>‚ÄòBUTTHOLIO‚Äô These guys always seem to have the most stereotypical or corny hacker handles. Is that expected / desirable in that community? reply internet101010 15 hours agoparentGive them a break. They need tp. reply ethbr1 13 hours agorootparentWhy would they need tp? reply mikeyouse 12 hours agorootparentThe bungholio name is a reference to the bevis and butthead name where they‚Äôd say, ‚ÄúI am cornholio, I need TP for my bunghole‚Äù. You really had to be there. https://m.youtube.com/watch?v=LHv2dIM3t9I reply ethbr1 1 hour agorootparentOh, I was there. heeheeBUNGholeheehee reply red-iron-pine 3 hours agorootparentprev‡≤†_‡≤† edit: okay fine I'll bite -- because of chicken piccata reply aaronbrethorst 16 hours agoparentprevcorny I see what you did there. reply juunpp 15 hours agoparentprevThe real question is: who calls their company \"Snowflake\"? It's just crying to get stomped on. reply mulmen 15 hours agorootparentSnowflake is a type of multidimensional schema. It's a normalized star schema. Both named for the appearance of their entity relationship diagrams. reply chatmasta 2 hours agorootparentSnowflake schema is obviously the etymology, but the official story is that the founders ‚Äúreally like skiing.‚Äù It‚Äôs always aggravated me. I just assume the CEO told them to go with that instead. reply Der_Einzige 15 hours agorootparentprevSnowflake did the biggest epic fail of the ZIRP era. They bought streamlit (a python GUI front end for ML demos) for 800 MILLION dollars. https://techcrunch.com/2022/03/02/snowflake-acquires-streaml... Huggingface bought its biggest competitor, Gradio (still used more than Streamlit) for an \"undisclosed\" amount of money a year or so before hand. I'd wager HF paid on the orders of 1-5 million. reply wodenokoto 13 hours agorootparentI doubt Gradio is used more than streamlit. And so does Google [1] I know that's not exact, but if more people used Gradio, you'd expect at least a somewhat similar number of people searching for it online. Gradio is not even in the same ballpark as Streamlit here. [1] https://trends.google.com/trends/explore?date=now%201-d&q=%2... reply Der_Einzige 13 hours agorootparentI don't know what to say except that the overwhelming majority of HF spaces are made as Gradio demos and that gradio's whole design makes it far easier to do async things unrelated to reloading the webpage - which is a huge thing for ML/AI demos. I don't claim you're wrong, but I claim that gradio is far more effectively profitable to know than streamlit is - i.e. Gradio demos are used far more for a top AI paper demo (i.e. NeurIPS system demos) than Streamlit is. reply bagels 15 hours agorootparentprevThat is amazing! What a coup. I thought streamlit was pretty cool, but surely it wasn't $800m cool. reply rawgabbit 14 hours agorootparentprevSalesforce purchased Mulesoft for $6.5 billion. Mulesoft was so successful they decided to buy a different ETL tool Informatica. But the deal fell through. Mulesoft has about 1500 clients vs 9500 clients for Informatica. reply rajamaka 14 hours agorootparentprevComparing a disclosed sale price to an unknown theoretical sale price is a bit unfair though. Maybe it was 801 million. reply Der_Einzige 13 hours agorootparentNo way, HF didn't have anywhere near that kind of money when they acquired Gradio. I think they did it back in 2020 or 2019. I know for a fact it was a tiny sum. reply taspeotis 16 hours agoparentprevI believe the hacker known as 4chan once explained they choose their handles ‚Äúfor the lulz‚Äù reply Apocryphon 16 hours agorootparentLegion of Doom / Masters of Deception would like a word. reply tedunangst 15 hours agorootparentPhiber Optik just doesn't have the same haha you said peepee vibe. reply Apocryphon 16 hours agoparentprevI do think it‚Äôs funny how that might be a character revealing moment, suggesting the hacker is Gen X or at least elder millennial age. reply A4ET8a8uTh0 16 hours agorootparentI did toy with the idea of trying do analysis of HN aliases and keywords. It never went anywhere, because I forgot about it, but a longer weekend is coming:D But yeah, language betrays, who we are in references alone. reply gopher_space 13 hours agorootparentThere's no way you could determine how old a person is or what technologies they enjoyed way back in college solely from a username. reply willvarfar 12 hours agorootparentAre you just trying to goad them into showing they can? :D reply kasey_junk 6 hours agorootparent-gopher- space made the comment you are replying to. reply oefrha 12 hours agorootparentprevHave fun analyzing the alias I pulled from /dev/urandom! reply imp0cat 11 hours agorootparentKnows of the existence of /dev/urandom, must be old! ;) reply heromal 15 hours agoparentprevYes reply ChumpGPT 16 hours agoprevSeems like the guy has been fucking around for a while. No wonder none of our allies want to share intelligence or plans with us. The US Military is a liability when it comes to keeping shit secret, they leak like a sieve. They need to get a handle on this shit, who knows what this guy has given to the Russians or Chinese. reply 6510 11 hours agoparent\"pay-to-play\" reply benreesman 11 hours agoprevJesus. Let‚Äôs tick another box on our late capitalism bingo card: our soldiers are so desperate for cash and so cynical around institutions that they‚Äôve started doing mercenary crime. I can‚Äôt be the only person who has read of such situations throughout history. reply kortilla 9 hours agoparentWhat does this have to do with late capitalism? This has happened all throughout history and you just said you read about it yourself reply benreesman 8 hours agorootparentThe root of all failure at the level of the society is the fungibility of inherited wealth into political power, which rapidly gets deployed to impoverish everyone else including soldiers, and on its way it tramples institutions once revered. reply laborcontract 4 hours agorootparentthey could have just had an alcoholic parent. reply benreesman 4 hours agorootparentI‚Äôm a pretty easy going guy in general but others might take offense. reply assanineass 15 hours agoprevThey already arrested them right? reply sans_souse 12 hours agoparentNo they arrested two others. reply paganel 10 hours agoprevThis Krebs guy is a doxxer through and through, I wouldn't take anything that he writes down as being serious. If he thinks he knows something and he has palpable proof for it then he should contact the relevant authorities. reply richbell 6 hours agoparent> This Krebs guy is a doxxer through and through, I wouldn't take anything that he writes down as being serious. Can you explain your definition of \"doxxing\" and why you believe that means nothing he writes is serious? reply mtlynch 16 minutes agorootparentI'm overall a fan of Krebs' work, but he has done some questionable things to reveal people's identities that feel more like immature spite, sometimes outside the context of any crime he's accusing the person of committing: https://itwire.com/business-it-news/security/86867-infosec-r... reply paganel 5 hours agorootparentprev> Can you explain your definition of \"doxxing\" Revealing people names and addresses and implying that they have done something illegal, while the person doing that (this Krebs guy) does not represent the Law/the relevant authorities. See the Boston bombings debacle on this very website. > why you believe that means nothing he writes is serious? See the Boston bombings debacle on this very website. reply richbell 4 hours agorootparent> See the Boston bombings debacle on this very website. I'm familiar. I don't see the relevance considering that the linked article does not reveal anyone's names or addresses. reply paganel 3 hours agorootparentHe did that in the past. reply richbell 1 hour agorootparentFalsely? reply markus_zhang 15 hours agoprev [‚Äì] My two cents: - The \"hacker\" (I'm reluctant to use this term\" seems to be too high profile for some reasons; - We should discard Telegram reply shdh 15 hours agoparent [‚Äì] What does \"discarding\" Telegram mean? reply markus_zhang 15 hours agorootparent [‚Äì] We should not use Telegram -- sort of. I wonder whether Signal is better. reply wffurr 15 hours agorootparentNot sure Signal would have made a difference for this criminal. All the data on them I saw in the article was likely captured by someone in the channel / group message. It‚Äôs just plain poor opsec, but I kind of expect that from someone with poor enough judgement to be a criminal. reply 71bw 11 hours agorootparentprev>We should not use Telegram But why? There is no better platform for private and small chats. reply JTyQZSnP3cQGa8B 9 hours agorootparentTelegram is not E2E encrypted by default, and even if it changed, I wouldn't trust them. It's not private. reply xvector 15 hours agorootparentprev [‚Äì] Signal is absolutely better. Telegram is e2ee in name only reply autoexec 10 hours agorootparent [‚Äì] Not recommending Telegram, but personally, I suspect that signal is compromised. They've been permanently storing sensitive user data in the cloud for a long time time (https://community.signalusers.org/t/proper-secure-value-secu...) but the very first sentence of their Terms and Privacy page still claims \"Signal is designed to never collect or store any sensitive information.\" and they've been asked multiple times but refuse to update their privacy policy. I suspect that lie is being kept there as a giant dead canary. Making the change to start keeping exactly the data that the government has been asking them to turn over isn't a very good look. \"Securing\" user's data with something as week as a PIN isn't great either. https://www.vice.com/en/article/pkyzek/signal-new-pin-featur... Note that the \"solution\" of disabling pins mentioned at the end of the article was later shown to not prevent the collection and storage of sensitive user data. It was just giving users a false sense of security. To this day there is no way to opt out of the data collection. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Two individuals were arrested for data theft from companies using Snowflake, while a third suspect, known as \"Kiberphant0m,\" is still at large and believed to be a U.S. Army soldier in South Korea.",
      "The group has been involved in selling stolen data and extorting companies, with AT&T reportedly paying $370,000 to have stolen records deleted.",
      "Canadian authorities have arrested Alexander Moucka, and John Erin Binns is jailed in Turkey, both linked to the breaches, while Kiberphant0m remains active in cybercrime forums."
    ],
    "commentSummary": [
      "A hacker involved in extorting Snowflake, identified as Kiberphant0m, is under investigation, with speculation about possible ties to the U.S. military.",
      "Kiberphant0m denies any military connection, suggesting it was a deceptive tactic, though analysts doubt this would be effective in misleading investigators.",
      "The hacker's careless actions, such as posting a photo in army fatigues, underscore the difficulties in maintaining operational security and avoiding digital traces."
    ],
    "points": 308,
    "commentCount": 167,
    "retryCount": 0,
    "time": 1732668796
  },
  {
    "id": 42249746,
    "title": "ZetaOffice: LibreOffice in the Browser",
    "originLink": "https://zetaoffice.net/",
    "originBody": "LibreOffice in your browser Work from any device, maintain control over your data with self-hosting or our CDN, and enjoy seamless integration with your existing systems. Try it out Subscribe to Newsletter Trusted by Why choose ZetaOffice Web? Access from any device ZetaOffice Web brings LibreOffice to your browser, so you can access your documents from any device easily. No vendor lock-in ZetaOffice Web gives you full control over your data without relying on third-party clouds. Customizable Integration ZetaOffice Web integrates with your systems, and its API lets you tailor it to your workflows. Self-Hosted or CDN ZetaOffice Web lets you self-host or use our CDN for faster global access, allowing you to choose the deployment that suits your needs. Built on LibreOffice ZetaOffice Web, based on LibreOffice, is fully compatible with existing documents, enabling easy transition. Optimized Performance Optimized for browser performance, ensuring a responsive experience while efficiently handling complex and large files. ZetaOffice Suite Writer Comprehensive word processing with formatting and styling options Calc Advanced spreadsheets with data analysis and charting tools Impress Powerful multimedia presentations with various templates and transitions Try it out yourself Check out our demos now so you can see if ZetaOffice Web suits your needs. Writer Demo Calc Demo Chart Demo ZetaOffice for Desktop ZetaOffice is also available as a native Desktop application for Linux and Windows. Download the Beta here. Linux Flatpak ZetaOffice Flatpak DEB ZetaOffice Main ZetaOffice SDK ZetaOffice German Language Pack ZetaOffice German Help Pack ZetaOffice French Language Pack ZetaOffice French Help Pack ZetaOffice Spanish Language Pack ZetaOffice Spanish Help Pack RPM ZetaOffice Main ZetaOffice SDK ZetaOffice German Language Pack ZetaOffice German Help Pack ZetaOffice French Language Pack ZetaOffice French Help Pack ZetaOffice Spanish Language Pack ZetaOffice Spanish Help Pack Windows 64 bit ZetaOffice Main ZetaOffice SDK ZetaOffice English Help Pack ZetaOffice German Help Pack ZetaOffice French Help Pack ZetaOffice Spanish Help Pack 32 bit ZetaOffice Main ZetaOffice SDK ZetaOffice English Help Pack ZetaOffice German Help Pack ZetaOffice French Help Pack ZetaOffice Spanish Help Pack ARM 64 bit ZetaOffice Main ZetaOffice SDK ZetaOffice English Help Pack ZetaOffice German Help Pack ZetaOffice French Help Pack ZetaOffice Spanish Help Pack Frequently Asked Questions 1. What is ZetaOffice? ZetaOffice is a robust office suite built on the powerful LibreOffice foundation. ZetaOffice provides familiar functionalities with additional benefits like extended security updates. ZetaOffice is available for the web, desktop and mobile devices (coming soon). 2. Is ZetaOffice free? ZetaOffice is open source software based on the powerful LibreOffice suite. We offer paid packages that include the use of our high performance CDN and professional support options for your company. Our ZetaOffice services are currently in an open beta program. Sign up for our newsletter to find out more as soon as there is news about our packages. 3. Can I integrate ZetaOffice with my existing solutions? Yes, ZetaOffice offers full compatibility with the LibreOffice UNO API, allowing seamless integration into your current workflows or applications. This flexibility enables you to leverage the powerful features of ZetaOffice while maintaining your preferred ecosystem, enhancing productivity and user experience. 4. Is it possible to self-host ZetaOffice, or do I have to use the CDN? Both options are possible. Check out our Demo for examples of using the CDN. For more information about self-hosting, please see the Contact section below. 5. Does ZetaOffice require any special browser or system requirements? ZetaOffice Web is designed to function efficiently in most modern web browsers. While specific performance may vary depending on the browser or device capabilities, there are generally no strict requirements. As long as your browser supports HTML5 and a stable internet connection is available, you should be able to use ZetaOffice without any issues. We are allotropia Empowering businesses with LibreOffice Allotropia offers services and products to enhance LibreOffice. Our experts help organizations integrate it effectively, saving costs and improving efficiency. Dedicated team of certified LibreOffice developers Professional services focused on LibreOffice Pioneering native browser integration for LibreOffice Who we are Contact us Our office Versmannstr. 4, 20457 Hamburg, Germany Email Us info@allotropia.de",
    "commentLink": "https://news.ycombinator.com/item?id=42249746",
    "commentBody": "ZetaOffice: LibreOffice in the Browser (zetaoffice.net)262 points by marcodiego 22 hours agohidepastfavorite114 comments chrismorgan 14 hours agoI just tried the demo on my very capable laptop (ASUS Zephyrus G15 2021, Linux, Sway; Firefox, also tried Chromium). Performance is execrable. Text rendering is awful. Input is simply broken (e.g. my Compose key just doesn‚Äôt work). Double clicking highlighted the entire canvas thing, as well as the word under the cursor. Right clicking did nothing. Scrolling isn‚Äôt captured. The first menu thing I happened to try in the full-UI https://zetaoffice.net/demos/simple-examples/rainbow_writer.... example (Format ‚Üí Theme, maybe I just picked unfortunately) crashed the whole app (which means that it just stops working mysteriously, leaving the UI in the last state it was in). And you can‚Äôt even get started until it‚Äôs downloaded 50MB. (Though I‚Äôm actually mildly impressed it‚Äôs only that size.) Seriously, this is completely unusable. It‚Äôs ‚Äúcool tech demo‚Äù, but I would hate to actually have to use it. And I‚Äôm pretty sure, based on my rather accurate understanding of how all these things work (comprehensive on the web side, good on the native side, not so much specific about LibreOffice itself), that a lot of this is going to be completely unfixable‚Äîthough a couple of the things I identified are fairly straightforward to fix, which is if anything a further indictment. It‚Äôs going to be extremely hard to get even decent results without targeting real DOM instead of going pure-canvas, and you can‚Äôt get excellent results without doing so. reply thorstenb 2 hours agoparent> It‚Äôs going to be extremely hard to get even decent results without targeting real DOM instead of going pure-canvas, and you can‚Äôt get excellent results without doing so. One of the ZetaOffice (and LibreOffice) hackers here - and I have to disagree. For something like an office suite, the canvas is literally the only way to achieve the document layout fidelity that users expect. The DOM does not provide enough knobs & dials to get all of MSO (and OOo) bug-for-bug layout compatibility onto the screen (and it's not even close). Don't take my word for it, see e.g. here: https://news.ycombinator.com/item?id=42100660 (and that only deals with the text layout parts). reply peutetre 14 hours agoparentprev> It‚Äôs going to be extremely hard to get even decent results without targeting real DOM instead of going pure-canvas, and you can‚Äôt get excellent results without doing so. Sure you can. Google Docs switched to canvas three years ago: https://workspaceupdates.googleblog.com/2021/05/Google-Docs-... This wasm application renders to canvas and works fine for me: https://bandysc.github.io/AvaloniaVisualBasic6/ This one too: https://flutterweb-wasm.web.app/ Flutter and Google Docs gave up on the DOM because they couldn't get it working well enough, consistently enough across browsers. When you draw to canvas you get more consistent results because you control all the drawing. reply wiseowise 11 hours agorootparent> Sure you can. Google Docs switched to canvas three years ago: https://workspaceupdates.g You just need to be one of the critical projects for BigTech. Easy peasy, compared toindex.html. > This wasm application renders to canvas and works fine for me: https://bandysc.github.io/AvaloniaVisualBasic6/ Trying to select text on mobile Safari just selects whole canvas. Same for your Flutter example. What a regression for web. Just so that a couple of snowflakes can use their fad of the day or can stay in their comfort zone. reply RandomThoughts3 9 hours agorootparent> Just so that a couple of snowflakes can use their fad of the day or can stay in their comfort zone. Or because the DOM is a piece of technology designed for rendering documents and not web apps and with limitations which has been severely gimping proper rendering of web apps for the past decade despite a slew of libraries trying to fill the cracks with various amount of success. Whichever you prefer. reply solarkraft 4 hours agorootparent> Or because the DOM is a piece of technology designed for rendering documents and not web apps IDK, it seems to have been pretty successful at it to me, being of the most popular GUI frameworks currently, probably the most popular by a wide margin. Being designed for documents it should exceed at rendering documents. The problem isn‚Äôt on the DOM itself, it‚Äôs in mapping other frameworks to it. Of course it‚Äòd be hard to port LibreOffice‚Äòs rendering to the web, it‚Äòd be a crazy amount of work to reach parity. And it‚Äôs fine to argue that it doesn‚Äôt make sense at all to use the DOM for non-web document editing: OnlyOffice doesn‚Äôt do it either, as far as I‚Äôm aware. It‚Äôs just a bummer to me since documents are exactly what the web was made for. reply wiseowise 7 hours agorootparentprevJava was made for TV controllers. Now it powers majority of enterprise. JS was made to animate monkey on a screen, and now it powers internet. Technologies start with one goal and evolve. reply troyvit 1 hour agorootparent> We build our computer systems the way we build our cities: over time, without a plan, on top of ruins. -- Ellen Ullman reply jhbadger 4 hours agorootparentprevThe fact that there are so many alternative languages for the JVM or which transpile to Javascript suggests that (at least to many people) that neither were ideal choices for their current uses. reply legacynl 3 hours agorootparentI think this actually shows the exact opposite. That is like saying the existence of cargo trucks, pick-ups, minivans, campers, and rv's shows that the underlying 'internal combustion engine' technology is flawed. I think it rather shows that the technology is so useful that it is able to spawn different implementations aimed at slightly different use cases. reply eitland 9 hours agorootparentprevOr because Google doesn't like open web technologies, standards and interoperability now that they are the king of the hill? reply peutetre 9 hours agorootparentHow are WebAssembly and canvas not open web technologies? reply homebrewer 3 hours agorootparentThey're much harder to \"disassemble\" and applications written in them are much harder to modify and a relatively open DOM + JS model. Looks like a very promising technology for an ad company that's been pushing to make ad blockers significantly less effective, and has never let you install an adblocker into the most popular browser on the most popular platform in the world. reply eitland 4 hours agorootparentprevI didn't say they weren't. In the case of Google Docs kt might be because it is really convenient to use canvas because then it gets much harder for clients to do things Google don't like, i.e. interoperability. In other cases, like in IE^h^hChrome and large Google products like Calendar and YouTube there have been some interesting cases I think. reply CharlieDigital 4 hours agorootparentprevIs `HTMLDivElement` really that different from `class Rectangle`? reply RandomThoughts3 3 hours agorootparentYes, extremely. A div element is a node in a tree which will be rendered by a very opiniated rendering engine adhering to a fairly strict set of standards, and which can be manipulated using a limited subset of technologies which are themselves fairly opinionated. A class Rectangle can be pretty much whatever you want. reply CharlieDigital 3 hours agorootparent> A class Rectangle can be pretty much whatever you want In what way can an `HTMLDivElement` not emulate a `class Rectangle`? - Both are rectilinear - Both have width, height - Both can have borders, backgrounds - Both can be positioned in various grid/layout systems - Both can contain child instances - Both can contain a variety of child nodes like `Text` - Both can be clipped and masked - Both can be layered What can you do with a `class Rectangle` from a GUI perspective that you can't do with an `HTMLDivElement`? reply RandomThoughts3 2 hours agorootparentA class Rectangle can be whatever you want. You can overload it. You can change everything including how it‚Äôs rendered. It doesn‚Äôt have to be any of the things you list. A div element is a node in a tree which will be rendered by your browser in the way specified by the spec. You absolutely can‚Äôt freely do most of the actions you list to a div. There are severe limitations. A div doesn‚Äôt at all emulate a class. Its semantically something completely different. reply CharlieDigital 1 hour agorootparent> A Rectangle component is a node in a component tree which will be rendered by your OS graphics library in the way specified by the spec. You absolutely can‚Äôt freely do most of the actions you list to a div. There are severe limitations. No? It seems like you're just talking about a `Rectangle` in the abstract rather than the real limitation that even `class Rectangle` is subject to the rules of the runtime engine that renders said `Rectangle`...in a component tree...with the restrictions of the OS/GUI framework... reply wiseowise 2 hours agorootparentprevSo instead of standardized element that works pretty much the same on every browser, that can be inspected and controlled by virtually every tool that works with web I, as a user, get a binary blob, correct? reply peutetre 9 hours agorootparentprev> Trying to select text on mobile Safari just selects whole canvas. Same for your Flutter example. Ah, so yet again Safari is the problem. The new Internet Explorer unfortunately. reply wiseowise 7 hours agorootparentIt is the same on every browser. And you can even control zoom/scale on desktop. Very accessible! reply wiseowise 2 hours agorootparentCan‚Äôt* reply nox101 13 hours agorootparentprev> Google Docs switched to canvas three years ago: And broke CJK and emoji input. They only fixed emoji input recently. CJK is still broken. reply arcanemachiner 9 hours agorootparent> CJK \"The shorthand collective name for the Chinese, Japanese, and Korean writing systems.\"? reply jraph 3 hours agorootparentYep. This is a very widespread acronym, though I can understand that it feels like obscure jargon the first time you run into it. reply zelphirkalt 7 hours agorootparentprevGoogle Docs' Writer (or whatever they call it) is a terrible child's toy, just like Word of Office 365. Functionality is severely limited compared to traditional word processors like LibreOffice. > Flutter and Google Docs gave up on the DOM because they couldn't get it working well enough, consistently enough across browsers. When you draw to canvas you get more consistent results because you control all the drawing. And as a side effect, of course if you require the canvas, you will also be able to abuse the canvas, to fingerprint users. It is strange, how those things seemingly always coincide when it comes to Google products. reply rbanffy 23 minutes agorootparent> Google Docs' Writer (or whatever they call it) is a terrible child's toy, just like Word of Office 365 I'd believe the vast majority of the user base has never noticed anything off with these applications. I have noticed one or two things missing in the in-browser PowerPoint and that's about it. If you want to do precise publication layout, Word (and Writer) are not the appropriate tools - you'll need something like InDesign. reply jfengel 4 hours agorootparentprevFor the vast majority of what I do, a toy is all I need. This is the nasty catch-22. It is preferable to have a single tool that handles both simple and complex cases. But sometimes, you just can't make one tool that does both well. If you optimize for the hard cases, then most users will use only a tiny minority of the features. Microsoft tried to work around that with the \"ribbon\", which tried to learn which features each individual uses. Users hated it. So I keep around LibreOffice for the hard stuff, which I write perhaps once a year. And I use Google Docs every day. reply peutetre 7 hours agorootparentprev> Google Docs' Writer (or whatever they call it) is a terrible child's toy It's a toy that's making Google a lot of money. reply chrismorgan 13 hours agorootparentprevGoogle Docs isn‚Äôt pure-canvas: they only switched their document area to use it for layout. Text rendering is still browser (necessary to keep performance even close), and all the rest of the UI is still DOM. Having thought extensively about it, I cannot come up with any advantage to the approach they‚Äôve taken‚Äîneither the performance¬π nor the consistency¬≤ angles make any sense, and the product is actively worse because of it¬≥. I‚Äôve written more about it on HN at times, skim https://hn.algolia.com/?query=chrismorgan%20google%20docs&ty... for more. Seriously, having thought about it very carefully and reviewed the matter several times over the years, I honestly believe that they lied in their justifications. Flutter‚Ä¶ ugh, Flutter on the web is awful awful awful awful awful AWFUL AWFUL and I will hate you if you decide with open eyes to use it when you‚Äôre deliberately targeting the web.‚Å¥ I lack energy to express my vitriolic loathing. Just go through https://hn.algolia.com/?query=chrismorgan%20flutter&type=com..., there‚Äôs lots of detailed explanation of specifically what‚Äôs bad, if you need it. Avalonia Visual Basic 6? It‚Äôs the kind of thing where the limitations will show least, because of how limited it is. And also because it‚Äôs imitating (not quite the right word, but close enough) ancient software which itself wouldn‚Äôt work fully properly if run on current machines. Its text handling is dodgy, doesn‚Äôt do composition properly, scrolling is non-native, context menus are non-native which stops some things from working properly‚Ä¶ but honestly that‚Äôs kinda the vibe they‚Äôre going for, so it‚Äôs not particularly upsetting. Pure-canvas is irredeemably bad. With difficulty you can make some things decent even with it, but excellence is impossible with pure canvas. Flutter and Google Docs did not give up on DOM for the reasons you cite. Google Docs, I honestly don‚Äôt understand why they gave up on DOM, the reasons they cited publicly genuinely don‚Äôt make sense. Flutter, it was because they don‚Äôt actually care about the web, it‚Äôs a third-class target, and too much of the way they design their API doesn‚Äôt port to DOM directly, so that making DOM a first-class citizen would have required compromises in their APIs that they were unwilling to make. But it was emphatically not about cross-browser consistency. ‚Äî‚ÅÇ‚Äî ¬π Seriously, Google Docs is slower than it used to be, especially with higher latency and jitter. ¬≤ The parts they replaced had no consistency problems in any realistic browsers. Seriously. Their layout requirements are, in practice, really basic. The area where consistency can actually be a problem is text shaping and rendering, but they haven‚Äôt replaced that since it would tank performance. ¬≥ My favourite example is keyboard navigation. It doesn‚Äôt match platform conventions, and that‚Äôs really irritating. Since we‚Äôre in this thread, LibreOffice also flouts platform conventions in this area, and it‚Äôs really irritating. ‚Å¥ If you‚Äôre focusing on mobile and make a mobile app with Flutter and also put it on the web with Flutter because why not, better than nothing, I won‚Äôt like you very much, but I‚Äôll at least understand. But if you‚Äôre saying ‚Äúwe need a web thing, how about we use Flutter‚Äù‚Ä¶ no. reply peutetre 13 hours agorootparent> But if you‚Äôre saying ‚Äúwe need a web thing, how about we use Flutter‚Äù‚Ä¶ no. If you're making an application, there's really nothing special about the DOM. You might as well control your drawing. That way you don't need to figure out cross browser incompatibilities all day. And here's what someone who used to work on Google Docs has to say about it: https://news.ycombinator.com/item?id=27133929 reply chrismorgan 13 hours agorootparentPlease look over my comments on HN about Flutter and pure-canvas and such. There are big problems. There is plenty special about the DOM that you lose and cannot gain back if you go pure-canvas. Links. Scrolling. Text handling. Composition. And various more. Use DOM. Please use DOM. Use canvas for an actual drawing canvas, but for the UI and anything else that‚Äôs largely text, use DOM. reply peutetre 13 hours agorootparentThere aren't \"big problems\" because it works. When you put yourself in the corner of claiming \"pure-canvas is irredeemably bad\" when it's plainly not, then there's nothing practical on offer. reply chrismorgan 12 hours agorootparent‚ÄúIt works‚Äù is a terrible defence, because of the different degrees of working. I‚Äôm describing various specific ways in which it doesn‚Äôt work properly, in ways that stop users from doing things they may legitimately want to do, or which will frustrate some users, and you‚Äôre just disregarding them. I‚Äôm not being vague in most of my complaints, I‚Äôm being very specific. It‚Äôs like you have a screw, and it‚Äôs worn enough that sometimes it makes the screwdriver slip, but you‚Äôre saying ‚Äújust be careful, maybe apply a little more pressure, and it still works‚Äù. reply peutetre 7 hours agorootparent> and you‚Äôre just disregarding them. Of course. You're living in a world of your own imagined requirements. The practical reality is that there are plenty of use cases for this stuff, whether you like it or not. This stuff is fit for purpose for many purposes. reply wiseowise 11 hours agorootparentprevHow the hell you can claim ‚Äúit works‚Äù if you can‚Äôt even select text out of the box, lmao? reply peutetre 7 hours agorootparentBecause I can select text out of the box. reply wiseowise 6 hours agorootparentOkay, this getting absurd. At this point I‚Äôm 90% convinced that you‚Äôre just trolling. https://news.ycombinator.com/item?id=42252999 You can‚Äôt select text in neither of your provided samples on both PC and mobile in different browsers. reply peutetre 6 hours agorootparentYou can. Text selection works, cut and copy and paste works, zooming works. I don't know what you're doing. reply erinaceousjones 1 hour agorootparentWhat about screen readers and mobile users? There's all these useful accessibility tools that would also have to be reinvented for canvas based apps. Text selection and getting it to bring up a keyboard is iffy on the canvas-based things you linked to (I'm looking at them on Firefox for Android on a Pixel 6). Sure, the VB one is a desktop app. But the original (non canvas) version of that app likely worked with windows screen readers, and that is lost in this reincarnation onto the web. Good old fashioned DOM already has pretty good native accessibility support for mobile phone UI. There's a lot of things that have been thought about when it comes to usability and accessibility, in both the web, and traditional desktop/mobile UI frameworks. Reimplementing those UI frameworks in canvas in a browser environment requires mapping the a11y bits too, not just keyboard+mouse input and rendering to screen. Not to mention Qt and Gtk and the older Android framework apps all use forms of markup and styling which are inspired by XHTML and CSS and document object models...... reply wiseowise 2 hours agorootparentprevWhich browser/OS? reply yunyu 4 hours agoparentprevOn the flip side, this is extremely fast and works pretty well on my M1 Pro Macbook running Chrome. The only downside is that it's a little blurry (as it's rendering at 1x pixel scale). reply samiv 5 hours agoparentprev\"Release early, release often\", isn't that the often touted wisdom? Of course that has the problem is that you can make the \"first impression\" only once and when that said \"first impression\" is terrible it can be really hard to convince anyone to try the software again for the second time. I guess releasing, almost like everything else, is a balancing game between two early or too late and both extremes have costs. reply giamma 10 hours agoparentprevOnlyOffice has decent performance and is pure canvas. However, they have (or had) issues with respect to accessibility, as screen readers don't read canvas. reply tjoff 12 hours agoparentprevBarely worse than Teams or your typical web app. Needs polish for sure but the bar for web apps aren't exactly high. Canvas usually breaks text selections etc. and accessibility. But what they do seem to perform much better than trying to get the DOM to do something it wasn't designed for. reply zelphirkalt 7 hours agorootparentMS Teams is among the worst pieces of software, that people have to deal with on a daily basis, because it gets shoved down their throat at their jobs. If something is even worse than that, even if \"barely\", then it is a complete disaster. A little \"polish\" will not be able to make it right. reply chrismorgan 11 hours agorootparentprevWhen you delve into badly-performing web apps, DOM is almost never the actual performance bottleneck. It‚Äôs other things they‚Äôre doing. And in the rare cases where DOM is the bottleneck, it‚Äôs always that they were abusing it. As for this case, I have never encountered a web app with performance (throughput and latency) problems like this. Not anywhere near it. reply tjoff 33 minutes agorootparentSimilarly I don't think canvas is the bottleneck here. Oh, and abuse is the name of the game. Almost exclusively the only thing the browser deals with is abuse. Logical consequence when the users are the one paying for it. reply andrekandre 14 hours agoparentprevinteresting, on my 2019 ipad pro, after initial loading that took a bit of time, editing was quite quick and fast for me* i wonder if there is some parts that remain unaccelerated or hitting performance bottlenecks on linux/firefox? * admittedly a bit low-res/ugly and hard to use on touchscreen reply thorstenb 10 hours agorootparentFirefox is indeed a bit of a hit-and-miss these days (though we absolutely want to support it). Best experience currently is on Chrome(ium). reply zelphirkalt 7 hours agorootparentAny ideas why it is hit and miss? Do you test as much on FF as on Chromium based browsers, during development, as well as in quality assurance steps? I could imagine, that some devs are looking at it in Chromium (or even Chrome shudder) all day, while implementing things, and then just having to tick a checkbox for FF \"Yep, seems to work.\". Which would of course lead to a Chromium-centric code. reply curt15 5 hours agoparentprevThe UI in the home page screenshot also looks like 90s-era Windows. reply exe34 5 hours agorootparentOoh that's great, I might give it a try. reply rbanffy 9 minutes agorootparentI miss 1970's 3278 vibes. PROFs ftw! reply AnonC 14 hours agoprev> ZetaOffice is also available as a native Desktop application for Linux and Windows. Download the Beta here. Why is a desktop application being developed and provided if this is compatible with LibreOffice (since the latter already has desktop applications)? Is it just to have the same name and recognition? Is the desktop application kept on par with the latest LibreOffice release or does it only guarantee document format compatibility up to a specific version? reply thorstenb 10 hours agoparentZetaOffice is focusing on developers wanting to integrate it (be that a web app, or a desktop line-of-business application, e.g. via Eclipse RCP) - having the exact same code built across all platforms should make for excellent consistency (document rendering, and API compatibility). We can also offer LTS support & security updates, beyond the normal LibreOffice 1-year lifetime. reply n3storm 13 hours agoparentprevLooks like anything that can be snapflatpacked will be snapflatpacked. reply FrostKiwi 17 hours agoprevThat's excellent! You guys should interact with Nextcloud or someone should try their hand at a Nextcloud App [1]. Nextcloud's solution to Google Docs & friends is via the integration of OnlyOffice[2], which requires a DocumentServer [3] to function in the context of Nextcloud. Even without the collaboration aspect, having LibreOffice work off WASM, without any extra infrastructure requirement would be an excellent edition to that ecosystem I think. [1] https://apps.nextcloud.com/ [2] https://www.onlyoffice.com/ [3] https://github.com/ONLYOFFICE/DocumentServer reply sneak 15 hours agoparentNextcloud is terrible and will eat your data, silently and without remorse. Avoid it at all costs. reply high_priest 14 hours agorootparentWhat does \"Nextcloud will eat your data\" mean, specifically? Do you mean the applications of the suit are buggy, or are they somehow hackable / leaking private information? reply hobobaggins 13 hours agorootparent\"Eating your data\" seems to refer to very serious bugs rather than leaking or vulns. reply aryonoco 10 hours agoparentprevNextcloud is a steaming pile of barely maintained donkey dung one should not approach with anything other than a 10' pole while wearing a full Hazmat suit. reply nathanmcrae 1 hour agorootparentI've run Nextcloud for years primarily for webdav file sync and calendar+contacts. It pretty much just works. That's not to say there isn't any jank, but it's mostly if you try the more obscure apps e.g. I've set up the phone track feature and it worked for a while, but I've had trouble with it recently. Probably fixable, but I just haven't spent the time. I would say it is the core component of my self-(vps)-hosted setup and easily the most valuable. reply squarefoot 7 hours agorootparentprevWhat are its cons? I used it years back and worked fine; did it transition to the dark side or it's a matter of bugs? I'd use it only self hosted of course. Alternatives? reply Jaxan 9 hours agorootparentprevI use it at home just fine. Granted, I only use it for files and I‚Äôm not using the office apps from it. reply zaggynl 5 hours agorootparentprevCan you go into what you issues you saw? reply kgeist 5 hours agorootparentLast time I checked it (a few years ago), it was quite buggy and crashed often for me (self-hosted). For example, what I remember, there was a module to move photos from Google Photos, but it always stopped at 10% photos without any errors. Then there was also some document suite module and it would hang my entire machine regularly, for some reason (had to restart it). reply johnisgood 6 hours agoprevMay be an unpopular opinion, but: I do not want LibreOffice in my browser, my browser is already slow enough as it is for me. What next? Blender in the browser? OS inside the browser? (Oh yeah, we already have that!) reply EvanAnderson 7 minutes agoparentAlways a good time for \"The Birth and Death of Javascript\": https://www.destroyallsoftware.com/talks/the-birth-and-death... reply techwizrd 2 hours agoparentprevI disagree, it's useful to be able to click a document link and quickly preview it in your browser. At work, I have native apps for Word, Excel, PowerPoint, etc. and I still find myself using the browser version for quickly responding to a comment left in a document. It's also useful to be able to quickly send someone a link to collaborate on the document without needing them to install anything. Installing a separate app may not be possible for aging parents, people using shared computers (e.g., library or school computer), or organizations with restricted IT systems. reply johnisgood 1 hour agorootparentPreviews are different from native apps though, and when you click on a link to a document, you only have to click \"Open\" to open a native app. How is this an issue? For quick edits I can see the appeal, however. > Installing a separate app may not be possible for aging parents, people using shared computers (e.g., library or school computer), or organizations with restricted IT systems This seems like a non-issue, too. If my grandma were to use the PC, I would be the one installing programs (or the OS) on it, and if I knew she wanted to open and edit documents, I would install LibreOffice. It is one of the programs I install on my parent's computer. You (or the IT staff) ensure tools are available; you install LibreOffice, similarly to how you would install a browser to begin with. For example IT staff are already responsible for installing and maintaining browsers. Adding productivity software to their responsibilities is a standard practice in professional environments. Browser-based tools are a complement, not a replacement, and the push toward browser dependence should consider the trade-offs in performance, user experience and so forth. Using browsers for productivity tools may feel more convenient in very specific edge cases, but for most users and workplaces, the effort involved in installing and using native applications is negligible in comparison. (I remember the old days when I used https://gobby.github.io with my friend to edit code together. It is a native program for editing documents (incl. code) together. Today you would probably use an extension to VS Code unless it supports it natively (no clue).) I am pretty sure there are people on here who would be able to explain it better than I do. reply wakeupcall 23 minutes agorootparentprevWhen \"quickly\" means downloading 242mb of runtime, running it slower than native, on top of the document you want to preview... reply doubled112 5 hours agoparentprevThe browser is the OS now. Everything underneath is just a hardware abstraction layer. reply johnisgood 5 hours agorootparentI really do not want it to be the future. :( Just because some people use the browser all the time, it does not mean that it should be the \"OS\". It is silly. reply bigstrat2003 3 hours agoparentprevAgreed. Shoving things into the browser is utterly stupid. Native apps are just plain better, stop ruining things by putting them in the browser please. reply xrd 17 hours agoprevZeta.js is such an impressive JavaScript library. I'm blown away. The examples where you can load a document in less than ten lines, amazing. Then, change colors of all cells in less than ten lines, amazing. I'm also blown away that there is a gulp file in the repository. That's a blast from the past. reply chuckadams 16 hours agoparentI'm still working with stuff using grunt (most certainly not my choice). gulp is not that bad as a generic task runner, though the last thing I'd use it for these days is to build JS artifacts. reply porphyra 16 hours agoprevWhile it is an amazing technical feat, there are, expectedly, a bunch of quirks to be ironed out. The font rendering, for example, is very bad. Very excited to see how this goes in the future! reply akx 6 hours agoprevNeat! Couple of observations: - https://zetaoffice.net/demos/simple-examples/rainbow_writer.... hangs with an `unreachable` in the console if I try Tools -> Options. - Things don't seem to be hiDPI aware, so everything looks a bit unfortunate on e.g. my MacBook's retina screen. reply Andrew_nenakhov 4 hours agoprevFrom what I understand, Collabora basically runs LibreOffice on the server side and relays the resulting image to the client. This looks like it has similar approach. And I'm sad to say it but Collabora is near unusable compared to Google Docs. Humanity really does need an online self-hosted office suite that natively uses OpenDocument format, but I'm afraid that to achieve that it'll be easier to start from scratch with browser version as a first platform in mind. reply homebrewer 3 hours agoparentCollabora office uses a custom web ui for controls, dialogs, etc. The document body is rendered by the server and streamed in raster tiles over a web socket. https://sdk.collaboraonline.com/docs/architecture.html reply fguerraz 32 minutes agoparentprevCollabora is perfectly fine, what‚Äôs your gripe with it? reply alwayslikethis 3 hours agoparentprevMaybe Etherpad? https://etherpad.org/ reply velcrovan 1 hour agoprevPerfect, this gives me a great idea for an April 1 company-wide announcement next year. reply karencarits 18 hours agoprevI can remember testing libre office in the browser many years ago, seems like that project was frozen in 2020 as others external projects emerged. The wiki has a guide for docker: https://wiki.documentfoundation.org/Development/LibreOffice_... reply gbraad 16 hours agoparentthe link you refer to talks about collabora and allotropia. the first is what powers Nextcloud Office/Collabora Office online and mobile apps (using coolwsd). the latter is allotropia, who is behind Zeta that is mentioned here. both have a slightly different approach to how this works. as i understand it, all of this is upstream and not really frozen; perhaps that page needs an update? Note: \"LibreOffice Online is not intended as a standalone software. His goal is, instead, to be integrated with other tools to edit their documents.\" ... while Zeta and Collabora are standalone. reply chris_wot 15 hours agorootparentIt wasn't frozen, Collabora were the ones doing the work and so they have largely hosted and developed LibreOffice Online. reply gbraad 4 hours agorootparent(same thought here; just didn't want to sound harsh) The idea of LOOL (LibreOffice OnLine) is to be an embeddable component; we have used it before on a Moodle site. And this is the same for COOL (Collabora Office OnLine), which is used by Nextcloud Office (as components called COOLWSD, and LOKit). reply Animats 12 hours agoprevThat animated ad is a total turn-off. I've used LibreOffice/OpenOffice/StarOffice for two decades now. It's OK, not great. At least it interoperates with Microsoft desktop formats now. Mostly. reply tpoacher 10 hours agoparentLO is contantly updated and improved. The 2 decades observation isn't really useful. Would you compare today's MSO experience to MSO2000 on Windows Millenium? I use LO exclusively and it's a joy to use. On the rare instances I'm forced to use MSO it feels only marginally better than google docs. YMMV And, strictly speaking, the reason things break sometimes when switching from LO to MSO is because MSO is broken: LO follows the spec (both .odt and .docx) faithfully, which then breaks when MSO relies on undocumented features or outright bugs for the end-result (i.e. the \"works best on Internet Explorer\" legacy). reply squarefoot 7 hours agorootparent> I use LO exclusively and it's a joy to use. Same here and at several other people who asked me for alternatives over the years. I installed LO (formerly also OO) both on Linux and Windows and they became productive almost immediately. However when I install it on other people PCs I always set the default save formats as Word/Excel/Powerpoint 97-2003 so that nobody will complain when they send files to other people who presumably will be running mostly MS Office. reply gbraad 17 hours agoprevhow is this different from http://www.collaboraoffice.com/ ? Collabora works on mobile devices and integrates with Nextcloud note: they use WASM, so the load is on the client. Collabora relies on a server part, though easy to host. reply mstngl 11 hours agoprevI would love to have something like this in order to provide the office features for documents hosted in nextcloud directly. Yes, there is Nextcloud Office/Collabora Office but this needs separate provider and is not included in hosted Nextcloud (e.g. at Hetzner). The ease of OneDrive + MS365 in comparison is quite attracting. For my current use (sharing documents in a team of 50 - non-commercial but somehow professional approach) the latter is still the tool of choice. Being able to share a link, which allows others to directly edit presentations and spreadsheets in a browser (while the files are available in a local file structure) is just great. reply ptman 10 hours agoprevCryptpad, which includes a bundled copy of onlyoffice, works quite nicely. reply greenavocado 4 hours agoprevThe font rendering/kearning makes my eyes bleed reply karel-3d 4 hours agoprevIsn't there the Collabora stuff that's actually optimized for browser? (but I haven't been able to actually run it) reply austin-cheney 15 hours agoprevThere is also https://fleet.linuxserver.io/image?name=linuxserver/libreoff... reply radeeyate 14 hours agoparentKeep in mind that Zeta office runs completely in the browser with WASM while the thing you provided runs on a server and just streams back and forth to the client. reply kosolam 11 hours agoparentprevLooks interesting. What is it? reply wmf 19 hours agoprevHow does this work? Is it WASM-based or what? reply thorstenb 18 hours agoparentYup, and it's all fully upstreamed in LibreOffice, see our blog (https://blog.allotropia.de/category/libreoffice/), and the upstream wiki page: https://wiki.documentfoundation.org/Development/WASM For an even more obvious demo of that, c.f. the hidden gem https://zetaoffice.net/demos/simple-examples/rainbow_writer.... ;) Current source version powering the demos is https://git.libreoffice.org/core/+/0d9eb8245e1a1345ed9526ad8... - we should make that more prominent, indeed. reply bigbones 18 hours agorootparentIt sounds like you might know the answer to this. Would it be straightforward to use this for sandboxed headless file conversion? You can do that already with LibreOffice, but it's a monster amount of unsafe code that's difficult to containerize securely reply thorstenb 18 hours agorootparentIndeed can be done, proof of concept shown in this talk: https://www.youtube.com/watch?v=X8LwaDjcr7M Regarding sandboxing - everything WebAssembly is heavily sandboxed already, and requires cross-origin isolation in the browser, so we can use SharedArrayBuffers. So that's likely no worse than running LibreOffice containerized on a server. reply bigbones 18 hours agorootparentOh whoa a 5 minute video for exactly this :) Apologies for making you be my Google. Yep, everything in wasm makes things much easier to work with, especially if you want to run it on a client device reply e1g 15 hours agorootparentprevI just containerized LibreOffice to do docx->pdf conversation, but now I'm wondering - what parts seem particularly gnarly to you? My naive strategy is to mount an external volume to put/collect files, then call `soffice` inside the container to process them. We generate all source docx files so I'm not worried about an injection from that angle. reply benatkin 19 hours agoparentprevIt runs on ProseMirror and AG Grid. Joke aside, the source code isn't featured on the web page, despite LibreOffice (unlike Apache OpenOffice) being copylefted. They mention self hosting, but it says to contact them. It seems it runs on WebAssembly either directly or through a VM on top of WebAssembly like https://copy.sh/v86/ . The screen seems to be simulated with a canvas. I think perhaps they didn't change the code of LibreOffice much, but have a custom setup of something like https://copy.sh/v86/ or even are running it on actual WebAssembly with a virtual screen. So they have a virtual computer that it's running on, and they consider that separate when it comes to copyleft obligations. Plus it's possible to make something open source but inconvenient, and charge to make it convenient. reply hoistbypetard 19 hours agorootparentFrom the description here[1], it sounds like they're using WASM builds of LO. I'm not quite interested enough to spend the CPU cycles it'd take to build and see whether that is really the whole story. [1](https://github.com/allotropia/zetajs?tab=readme-ov-file) reply benatkin 18 hours agorootparentThat's nice. AFAICT nobody has yet figured out how to run the rust compiler in WebAssembly directly, but it runs in v86. That's why I wondered if they were taking that shortcut for another complex program. Here's their page about WASM: https://wiki.documentfoundation.org/Development/WASM It says it uses Qt/VCL. Maybe those can talk to canvas in a fairly straightforward way, or maybe ZetaOffice chose a different backend to get a proof of concept out faster. reply rzzzt 18 hours agorootparentprevSide question: did GTK3's HTML renderer get anywhere? I remember a calculator application running in a browser as a demo from a long time back. reply thorstenb 18 hours agorootparentThat still seems to be there, even for gtk4: https://docs.gtk.org/gtk4/broadway.html (but it says, between the lines, mostly stale I guess) As an aside: one of the very first demos of LibreOffice in a browser (from the Collabora people) was using the broadway backend. But they've moved on, using their own tiled rendering server backend, plus custom, javascript gui on the client. reply hoistbypetard 19 hours agoparentprevIt looks like they've developed a javascript library that interacts with a WASM build of LibreOffice: https://github.com/allotropia/zetajs?tab=readme-ov-file reply starik36 16 hours agoprevLove the Deep Space 9 Easter egg! reply cess11 11 hours agoprev [‚Äì] I might do documents in the browser if LyX was ported to WASM and performance is good. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ZetaOffice Web introduces LibreOffice to web browsers, enabling access from any device with options for self-hosting or using a Content Delivery Network (CDN) for data control.- The suite includes Writer, Calc, and Impress for word processing, spreadsheets, and presentations, and is available for both web and desktop on Linux and Windows, ensuring document compatibility.- ZetaOffice offers open-source software with paid options for CDN use and support, and integrates with existing systems via the LibreOffice UNO API, functioning efficiently in modern browsers."
    ],
    "commentSummary": [
      "ZetaOffice, a browser-based version of LibreOffice, faces criticism for performance and usability issues, including broken input and text rendering.",
      "There is an ongoing debate about whether using a canvas or targeting the DOM (Document Object Model) is better for rendering document layouts in web-based office suites.",
      "Despite challenges, ZetaOffice aims to provide a consistent cross-platform experience and is also available as a native desktop application."
    ],
    "points": 262,
    "commentCount": 114,
    "retryCount": 0,
    "time": 1732653144
  },
  {
    "id": 42249790,
    "title": "D-Link says it won't patch 60k older modems",
    "originLink": "https://www.techradar.com/pro/security/d-link-says-it-wont-patch-60-000-older-modems-as-theyre-not-worth-saving",
    "originBody": "Pro Security D-Link says it won't patch 60,000 older modems, as they're not worth saving News By Sead Fadilpa≈°iƒá published November 13, 2024 Just get a new modem, the company says When you purchase through links on our site, we may earn an affiliate commission. Here‚Äôs how it works. (Image credit: Future) Security researchers find critical flaws in modems reaching End of Life D-Link says it won't patch them, and recommends upgrading the hardware There are some 60,000 vulnerable devices out there Older D-Link routers are potentially vulnerable to more than one critical security issue which could allow threat actors to take over the devices. However, since they have reached end-of-life status (EoL), the company says it will not be releasing any patches, and advises users to replace the endpoints with newer models. The news comes shortly after we reported multiple D-Link NAS endpoints were found vulnerable to CVE-2024-10914, a command injection flaw with a 9.2 severity score - however the company again said it wouldn‚Äôt be issuing a fix, since the affected devices have all reached EoL. Now, security researcher Chaio-Lin Yu (Steven Meow) found three bugs plaguing the D-Link DSL6740C modem. One is tracked as CVE-2024-11068, has a severity score of 9.8, and allows threat actors to change passwords through privileged API access. The other two are CVE-2024-11067, and CVE-2024-11066, and are a path traversal flaw and a remote code execution (RCE) flaw, with 7.5 and 7.2 scores, respectively. Tens of thousands of vulnerable endpoints Roughly 60,000 vulnerable devices are currently connected to the internet, the majority being located in Taiwan. The model isn‚Äôt even available in the US, BleepingComputer states, since it reached EoL almost a year ago. With that in mind, D-Link said it wouldn‚Äôt be addressing the flaw, and suggests \"retiring and replacing D-Link devices that have reached EOL/EOS.\" The same model is also vulnerable to four additional high-severity command injection flaws, the publication states, citing information from the Taiwanese computer and response center (TWCERTCC). These flaws are tracked as CVE-2024-11062, CVE-2024-11063, CVE-2024-11064, and CVE-2024-11065. Users who are unable to replace their routers at the moment are advised to at least restrict remote access, and set secure access passwords, to minimize the chance of compromise. This would be a wise move since routers are one of the most targeted endpoints out there. YOU MIGHT ALSO LIKE D-Link routers are being hacked to steal customer passwords ‚Äî but it says there is no patch Here's a list of the best firewalls today These are the best endpoint protection tools right now Are you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Sead Fadilpa≈°iƒá Sead is a seasoned freelance journalist based in Sarajevo, Bosnia and Herzegovina. He writes about IT (cloud, IoT, 5G, VPN) and cybersecurity (ransomware, data breaches, laws and regulations). In his career, spanning more than a decade, he‚Äôs written for numerous media outlets, including Al Jazeera Balkans. He‚Äôs also held several modules on content writing for Represent Communications. MORE ABOUT SECURITY Top WordPress anti-spam plugin may actually be putting your site at risk of attack Firefox and Windows zero-day security bugs hit by Russian hackers, so be on your guard LATEST Save hundreds on the Motorola Thinkphone, probably the best smartphone deal for businesses this Black Friday SEE MORE LATEST ‚ñ∫ LATEST ARTICLES 1 Save hundreds on the Motorola Thinkphone, probably the best smartphone deal for businesses this Black Friday 2 I reviewed this great budget soundbar with surround sound, and this Black Friday deal makes it outrageously cheap 3 Are you a Call of Duty cheater? Watch out ‚Äì AI is coming for you, as Activision boasts of 19,000 bans from ranked play with Black Ops 6 4 Watch out, your office could be chock-full of tracking technology 5 17 of the best cordless vacuum deals in the Black Friday sales",
    "commentLink": "https://news.ycombinator.com/item?id=42249790",
    "commentBody": "D-Link says it won't patch 60k older modems (techradar.com)241 points by lobo_tuerto 22 hours agohidepastfavorite153 comments autoexec 18 hours agoHere's an article for those who'd rather read than watch someone's youtube video: https://www.techradar.com/pro/security/d-link-says-it-wont-p... Dlink has a long history of putting out insecure and even backdoored devices and so anyone with a dlink device is probably better off buying something different reply dang 16 hours agoparentOk, we've changed to that from https://www.youtube.com/watch?v=52v6gKPA4TM above. Thanks! reply xp84 3 hours agoparentprevThis isn‚Äôt snark, but I didn‚Äôt think DLink was really a player anymore. Did they pivot? It used to be (like 20 years ago) they were like the #3 consumer brand after Linksys and Netgear. Now, it seems like the players are Eero, ASUS, Netgear, Linksys, TP-Link, Google. I haven‚Äôt even seen a DLink product in a store (online or not) or in the wild, in a decade. Edit: checked their site: apparently they are still in the game, I guess just nobody buys them reply Melatonic 33 minutes agorootparentI remember them always being the cheap budget option - assuming that's still the case reply xyst 17 hours agoparentprevAnother 60,000 devices ripe for malicious entities to use in their botnet. reply chipdart 12 hours agorootparent> Another 60,000 devices ripe for malicious entities to use in their botnet. Right, my immediate reaction after reading the title was that D-Link might not patch their hardware, but others certainly will. reply daghamm 6 hours agorootparentSpeaking of things others could do: Dlink competitors should use this in their marketing. reply bell-cot 5 hours agorootparentHow much of Dlink's target market would both understand and care? reply sbarre 4 hours agorootparentI think, thankfully, that the average user is increasingly aware of these kinds of problems, and hopefully the era of companies being this irresponsible is starting to come to an end. Anecdotally, my elderly parents have asked me questions about ransomware and \"our house getting hacked\" because of segments they've seen on the mainstream nightly news. So the awareness is out there.. reply nubinetwork 4 hours agorootparentprevIs it any easier than the millions of IP cameras, DVRs and WAN accessible modems and routers (from other manufacturers, particularly from China or South America)? reply TacticalCoder 15 hours agoparentprev> Dlink has a long history of putting out insecure and even backdoored devices and so anyone with a dlink device is probably better off buying something different Except for unmanaged switches. These little D-Link unmanaged switches are little workhorses: I've got several so old I don't remember when I bought them. I take it D-Link didn't manage to fuck up even unmanaged switch? But seen their approach to security, I probably won't buy D-Link again. reply remuskaos 13 hours agorootparentI think they actually did manage to fuck up even the small unmanaged switches. I have three unmanaged switches at home, one on the ground floor and two in the first floor. Ground floor is an 8 port netgear, first floor are one to link and one d link. Every couple of weeks, the entire wired network goes down. Not even pinging adresses works. The d links ports leds are all flashing (perfectly in sync!) until I power cycle it. Then everything goes back to normal. I have no idea what happens, and I should probably replace the d link soon. reply vardump 9 hours agorootparentAre you aware about broadcast storms? Perhaps you somehow accidentally introduced a loop in the network? The symptoms fit that exactly. https://en.wikipedia.org/wiki/Broadcast_storm STP is meant to prevent that. https://en.wikipedia.org/wiki/Spanning_Tree_Protocol Of course you can't set up STP with unmanaged switches, so until you go managed and set up STP properly nothing will change. reply mitjam 7 hours agorootparentIt could be missing IGMP Snooping Protocol support in a network with IPTV or custom VLAN setups. There are 3 versions (IGMP snooping (v1, v2, and v3)), managed switches have them all, unmanaged usually don't have them. To avoid problems, only pass a single VLAN to the unmanaged switch (it must be behind the managed switch for that), otherwise the unmanaged switch can and usually will bring a network down after some time. Or just use a switch with IGMP snooping support. reply remuskaos 9 hours agorootparentprevI was not! Thanks for the hint! Although I'm 100% sure there are no loops, I haven't changed the actual cable layout in ages. reply bayindirh 11 hours agorootparentprevI have a couple of TP-Link unmanaged 4 port SOHO switches. They're pretty reliable so far. reply remuskaos 9 hours agorootparentThe TP Link (typo in my other post) and the Netgear are reliable, only the D Link causes issues. reply bombela 11 hours agorootparentprevJumbo frames? https://en.m.wikipedia.org/wiki/Jumbo_frame reply remuskaos 9 hours agorootparentI haven't enabled jumbo frames knowingly on my system, but even if I had, why would the issue occur only every few weeks? Also, it seems to be rather independent of the actual network load. reply bombela 4 hours agorootparentA friend had networked speakers that would freeze until a manual reboot time to time. It turned out to be the Linux running within the speakers that crashed on the occasional jumbo frame. reply bell-cot 5 hours agorootparentprevIf the D-link has a wall wart which you could easily replace, try that. (And maybe a real surge strip, if you've got one handy.) Iffy power can cause all sorts of bizarre behavior. reply PeterStuer 10 hours agorootparentprevDLink were for me one of the least reliable small unmanaged switches I tried over the years. Out of those I have had (I have about 7 in the house, they get replaced when one dies), there was DLink, Linksys, HP, Netgear and TP-Link, the TP-Links are by far the most reliable in so much as I have never had one die, and now all my switches are TP-Link as all of the others gave up the gost. reply nunez 1 hour agorootparentThe first 8-port 10G TP-Link switch I got died within a few weeks. I think its power supply fried. It's replacement has been rock solid since for the last year and change now, fortunately! reply autoexec 12 hours agorootparentprev> I take it D-Link didn't manage to fuck up even unmanaged switch? I'd hope not. I haven't seen it yet at least. reply heraldgeezer 5 hours agorootparentprevThe Netgear GS series is king. Metal case 5,8,16 port gigabit unmanaged switches. Runs forever. reply xp84 3 hours agorootparentThose blue metal Netgear switches are the only Netgear products I buy (after they burned me with their crappy routers back in the 802.11G era to the point I went full Office Space on one). reply mitjam 7 hours agoprevThis is something the EU Product Liability Directive potentially addresses. It demands that vendors (or importers) of products need to update their product if that's required to keep them secure. Otherwise they are liable for damages, even psychological damages. There is no specific duration mentioned in the directive, so it's probably best from a vendor point of view to add product lifetime info to the product description or the contract, up front. In Germany there is something similar in place, already and the expectation is that products (and necessary apps to run the products) need to be updated for 5 years on average. reply zokier 6 hours agoparent> There is no specific duration mentioned in the directive The directive has explicit 10 year expiry period, see (57) > Given that products age over time and that higher safety standards are developed as the state of science and technology progresses, it would not be reasonable to make manufacturers liable for an unlimited period of time for the defectiveness of their products. Therefore, liability should be subject to a reasonable length of time, namely 10 years from the placing on the market or putting into service of a product (the ‚Äòexpiry period‚Äô), without prejudice to claims pending in legal proceedings. https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A... reply mnau 6 hours agoparentprevThat D-Link DSL6740C device was released in 2014. It's well past lifetime. I am not sure about PLD, but CRA is only for lifetime or ~5 year. > When placing a product with digital elements on the market, and for the expected product lifetime or for a period of five years from the placing of the product on the market, whichever is shorter, manufacturers shall ensure that vulnerabilities of that product are handled effectively and in accordance with the essential requirements set out in Section 2 of Annex I. reply xmodem 5 hours agorootparentThe 5 year clock should start from the last time a consumer purchased the product new, though. I can't find anything concrete but some poking around on wayback machine indicates it was likely discontinued late 2018. Which probably still means they are in the clear in this instance even if you assume it takes a year for the inventory in the channel to sell through. reply thequux 2 hours agorootparentThe manufacturer can't control or even predict purchase dates, so that leaves potentially unbounded support lifetimes. I'd be comfortable with the 10-year timer starting from date of last manufacturer though reply hyperman1 43 minutes agorootparentIf this works like a warranty, the manufacturer can stop 10 years after selling to the shop. The shop is the one providing the warranty to the user. The shop can oblige their warranty by replacing with a (more recent) equivalent model, even from another manufacturer. reply bell-cot 5 hours agorootparentprev> The 5 year clock should start from the last time a consumer purchased the product new... Obvious problem - how could the manufacturer determine (let alone control) when, literally, that happened? They might tell when their major distributors and online retailers ran out of stock...but small distributors and bottom-feeding resellers and mom-and-pop retail? Impossible. On-package labeling (\"Software security updates for this thingie will be available until at least Dec. 31, 2029; also check our web site at https://support...\") would be the only fool-proofish method. reply xmodem 3 hours agorootparentI think on-package labelling is a good approach. You could also make the retailer liable for a lack of updates - just as they typically already are with defective products in most jurisdictions. reply xp84 3 hours agorootparentYeah, this isn‚Äôt that different than the food ‚Äúbest by date‚Äù requirements, and in most cases (despite popular belief) the likely consequences of eating old packaged food is not even getting sick, just staleness. Arguably, having exploitable electronics that are ‚Äúexpired‚Äù is a greater danger. reply ak217 16 hours agoprevIf anyone is looking for alternatives as far as long term supported products go... I've had nothing but good experiences with Ubiquiti (Unifi) and OpenWRT. At the lower end of the price spectrum, OpenWRT supported devices can be an incredible value, and most will probably remain supported for decades to come. More broadly, it's not just about the support commitment but also about the company's reputation for shipping solid software. i.e. what is the prior on a scenario like this after the product goes EOL. reply neilv 11 hours agoparentRegarding supporting devices long-term, I can still get current version official OpenWrt for the Netgear WNDR3700v2, which I think is about 15 years old at this point. https://firmware-selector.openwrt.org/?version=23.05.5&targe... https://openwrt.org/toh/netgear/wndr3700 I always try to find out what's one of the best-supported OpenWrt routers at the time I'm shopping. And can I get one (or a few) of them on eBay at great prices. WRT54-GL, WNDR3700(v2,v4) and WNDR3800, Netgear R7800. I also have an OPNsense box that I'm evaluating. But, since OPNsense (FreeBSD) isn't strong on WiFi, I'd need to pair it with separate WiFi APs (running OpenWrt). I'm not liking the extra complexity, when an OpenWrt R7800 still does everything I really need right now. reply close04 5 hours agorootparent> WRT54-GL, WNDR3700(v2,v4) and WNDR3800, Netgear R7800. The WRT54-GL stands out, while having a really long support life it's also just FE, 10/100Mbps. The others are gigabit Ethernet. Could possibly be replaced from the list by the D-Link DIR-825 (N, not AC) which is also at the same support level as the Netgear WNDR3700v2. reply cesarb 15 hours agoparentprev> At the lower end of the price spectrum, OpenWRT supported devices [...] will probably remain supported for decades to come. Not really. Each newer OpenWRT release needs slightly more storage and memory than the previous one, and these devices at the lower end of the price spectrum tend to have as little storage and memory as they can get away with. Older devices with as little as 4 MB of storage and/or 32 MB of memory are already unable to run current OpenWRT releases, and devices with 8 MB of storage and/or 64 MB of memory are already on the way out. But yeah, other than that OpenWRT does tend to support devices way past their original EOL. reply IntelMiner 15 hours agorootparentCounterpoint: The original \"Google Wi-Fi\" Mesh routers (the hockey puck looking ones) from about 10~ years ago come with *4GB* of storage and 512MB of RAM [1] [1] https://openwrt.org/toh/google/wifi They're about $30-$50 USD for a 3 pack on eBay reply ak217 14 hours agorootparentIt's not just those. The 16 MB storage/128 MB flash recommended minimums are a non-issue for pretty much any remotely popular router in the 802.11ac wifi era, and I doubt OpenWRT will suddenly explode in size and blow past those limits any time soon (just look at its trajectory over the past decade). reply xp84 3 hours agorootparentprevOh wow, are those OpenWRT compatible?? I‚Äôve been out of the game since having a WRT54GL with Tomato, so pardon my ignorance reply miohtama 14 hours agorootparentprevWhy did Google spec them so heavy? reply AlotOfReading 14 hours agorootparentThe storage is eMMC, basically the cheapest thing available once you've committed. You'd have to actively try to buy eMMC smaller than 2-4GB. Same for the RAM, that's a single chip. It's not a heavy spec, just somewhere near the bottom of the cost curve for those particular parts. They probably used similar parts in another product and threw them into the routers for the additional order volume, known bring-up risk, and dev benefits. The pixel series also uses Samsung eMMC, iirc. reply Dylan16807 14 hours agorootparentprevThey probably budgeted a dollar for storage and a dollar for ram, or close to it. Sometimes it's nice to be able to run a normal OS. reply baka367 9 hours agorootparentprevNote that the limit only applies to base OpenWRT installation. I have successfully configured my ancient router to boot from the router's USB storage (64gig flash drive) reply m463 9 hours agorootparentprevI disagree with your sentiment. I think the routers openwrt has dropped support for are super low spec, like $20. And they still run older versions of openwrt. You could probably also just run openwrt with out a gui and probably do fine. Additionally, I like that openwrt works on higher end boxes now, like the zyxel gs1900 12, 24 and 48-port switches. reply nucleardog 4 hours agoparentprevMikroTik also has a number of cheap devices and I have several of their \"discontinued\" products that are over a decade old that I'm still updating. Their releases aren't really for _a_ device, but for a CPU architecture/chipset, so I don't know that I've actually run across any device that went unsupported before I replaced it anyway for reasons of wanting faster networking (i.e., 10/100 -> 1000; 802.11bgn -> 802.11n -> 802.11ac). Many of them are also supported by OpenWRT. reply aesh2Xa1 5 hours agoparentprevThe vulnerabilities impact modem products rather than router products. If you have one of these modems, you'll need to replace the modem functionality with another modem. You can, however, place an OpenWrt router/firewall on your LAN side just past the modem. reply hedora 16 hours agoparentprevOpenBSD also works great for such things. reply xanth 15 hours agorootparentAnyone have any OPNSense budget hardware recommendations? reply amatecha 12 hours agorootparentJust to clarify, OPNsense is based on FreeBSD[0], not OpenBSD. But OpenBSD does indeed make a good router/firewall OS as mentioned by GP. :) [0] https://opnsense.org/about/about-opnsense/ reply crest 8 hours agorootparentprevWhat performance are you looking for alternatively what's you (power) budget? reply senectus1 15 hours agorootparentprevN100 is an excellent chip to go for. I'm currently using a aliexpress special with a celeron n5105 chipset in it.. it works fine as well, but I'd opt for the N100 next time if I had to replace it. Celeron N5105 CPU: Intel Jasper Lake Celeron Processor N5105, 4 core 4 threads,64 bit, 10nm, 2.0GHz up to 2.9GHz, 4M cache GPU: Intel UHD Graphics GPU, 24EU, 450MHz up to 800MHz vs Alder Lake N100 CPU: Intel Alder Lake Processor N100, 4 core 4 threads,64 bit, 10nm, Up to 3.4GHz, 6M cache GPU: Intel UHD Graphics GPU, 24EU, Up to 750MHz I bought a N100 model to run as my backup server (PBS etc) and its a cracker. Debian is so snappy on it. reply BLKNSLVR 14 hours agorootparentAlso running OPNSense (in a VM) on an N5105 from an AliExpress mini box, with four Ethernet ports. Thing gets hot though, passively cooled, but I put a fan on top of it. Also runs another VM with some lightweight docker containers. Reliable little thing. Would also go N100 if needed replacement. reply solnyshok 8 hours agorootparentN150 is on the way already. https://liliputing.com/at-least-four-mini-pcs-with-intel-n15... reply Uptrenda 14 hours agoparentprevI think OpenWRT is the right approach at this point. Open source really excels where there is a 'commons.' We all have a shared interest in secure networks. Commercialized gate keeping of router firmware doesn't make sense. These manufactures should just switch to OpenWRT and skin it. reply tomxor 14 hours agorootparent> These manufactures should just switch to OpenWRT and skin it. Take a look at Teltonika, that's basically what they do, but with nice over-provisioned hardware. Comes with the \"industrial\" price tag, but theirs is the most rock solid network gear I've ever used, and you actually receive frequent router and modem firmware updates. I have one of their RUTX50 (5G LTE modem/router) at home and get about ~550 Mbit's through it, best internet I've ever had. I've never been forced to reboot it. I tried some consumer 5G modems before that and they were a total waste of money. I've also used their non LTE gear elsewhere and it's the same pleasant experience, and naturally highly configurable due to OpenWRT without having to hack around. reply shmerl 14 hours agoparentprevopnsense also has hardware options. reply alias_neo 7 hours agoprevI've had a box of old wifi-routers for years that I'd been meaning to reverse engineer and write up blog posts on the vulnerabilities to educate people on just how poor quality the software is written for the things you buy in your local electronics store. Every 3-4 years I'd have to buy another because the manufacturer stopped providing updates, even when I was buying their higher-end stuff. I myself moved on to an Ubiquiti Edge Router almost 10 years ago, but Ubiquiti didn't do a great job of that in the long term and they ditched the EdgeRouter/EdgeMAX line so I ended up (and I wasn't interested in Unifi line for my router/firewall) buying a Protectli box, flashed coreboot and used pfSense for a while before eventually moving to OPNSense. I came to the conclusion over this time that any consumer network equipment is basically junk and if you care at all about security you shouldn't use it; sadly that's easier said than done for non-techy folks. Many pieces of older/cheaper hardware can be flashed with OpenWRT and I'd recommend that as the cheapest option for anyone who cares just a little, and doesn't want to buy new hardware, and for everyone who really wants to make an effort should buy some hardware that can run a properly maintained router OS like pfSense or OPNSense, even an all-in-one wifi-router-switch if you don't want to build out an entire SMB network. reply jart 2 hours agoparentYeah Ubiquiti used to be great before they went the other way. Now Mikrotik is the new hotness. reply alias_neo 57 minutes agorootparentI've been looking at some of the Mikrotik releases; I'll almost certainly be going Mikrotik when I get around to upgrading my home network to 10Gb, I'm just looking out for new APs and will probably replace them all at once. Current using Unifi AP-AC Pros and Unifi 6 Pro around the house, but I keep having to move them around because the (newer) U6 Pro has atrocious range on both 2.4GHz and 5GHz compared to the AP-AC-Pro and my wife is getting annoyed at the poor WiFi signal on the living room TV (constant buffering), so I put the AP-AC-Pro back and it's better for the TV but slower for everything else. Not sure if there's a better Unifi AP I can get for this part of the house or if I need to switch everything out as don't want to mix AP manufacturers/management tools. reply smitelli 19 hours agoprevBackground on the underlying context of the bug: https://www.youtube.com/watch?v=-vpGswuYVg8 -- It's objectively unforgivable. reply amiga386 17 hours agoparentTL;DW: Call GET /cgi-bin/account_mgr.cgi?cmd=cgi_user_add&name=%27;;%27 account_mgr.cgi is safe, it takes web parameters \"name\", \"pw\" and calls the equivalent of execlp(..., \"account\", \"-u\", name, \"-p\", pw); \"account\" was written by the intern and runs sprintf(buf, \"adduser \\\"%s\\\" -p \\\"%s\\\" >/dev/null\", opt_u, opt_p); system(buf); reply zahlman 15 hours agorootparentNever mind the actual mistake \"the intern\" made. Not only was \"the intern\" tapped to write code that accepts user input from HTTP and also use system administration shell commands - and use C to do raw string handling, for that matter; who knows if `buf` is properly allocated? - but there was either no review/oversight or nobody saw the problem. Plus there are two layers of invoking a new program where surely one would suffice; and it's obviously done in a different way each time. Even programmers who have never used Linux and know nothing about its shells or core utilities, should be raising an eyebrow at that. Meanwhile, people want to use AI to generate boilerplate so that their own company's \"the intern\" can feel like a \"10x developer\" (or managers can delude themselves that they found one). reply jasonladuke0311 16 hours agorootparentprevThat‚Äôs insane. reply tptacek 18 hours agoprevLook I am just being grumpy about this and I know it has nothing really substantive to do with the underlying story, which is D-Link EOL'ing products, but: there is really no such thing as a \"9.8\" or \"9.2\" vulnerability; there is more actual science in Pitchfork's 0.0-10.0 scale than there is in CVSS. reply 616c 9 hours agoparentWhat is this Pitchfork scale? Is it an actual one, searching didn't return any useful results. reply hiddencost 9 hours agorootparentIt's a music review site. reply 486sx33 18 hours agoprevOr well‚Ä¶ if you have one of these models, this is the way. https://openwrt.org/toh/d-link/start reply anonymfus 15 hours agoparentI didn't find most of the affected models there, and for these which I did, pages are full of warnings like that OpenWrt support is obsolete since 2022 and/or that 4 MB of flash and 32 MB of RAM is not enough to do anything useful reply wuming2 17 hours agoprevWasteful choice enabled by not being entirely responsible for pollution, energy consumption and trash. If they had to pay for environmental full restoration, energy at full cost and careful disposal of unsuitable hardware decision would have been different. reply CTDOCodebases 8 hours agoparentIMHO once devices are EOL'd the company should be legally required to release the source code for them. reply zer8k 1 hour agorootparentI'd settle for not getting sued when I try to jailbreak it. reply gtsop 7 hours agorootparentprevI like this. But i also assume parts of the stack are going to be reused in newer models as well, so this is probably going to be a blocker for them accepting it. reply zahlman 18 hours agoprevTo be fair, CVE scores generally don't seem very useful in assessing the real impact of a security vulnerability. The CUPS thing was a 9.9 and that was completely irrelevant for a large swath of people. reply Gigachad 16 hours agoparentSame as the NPM warnings. It‚Äôs always screaming that there are a billion super critical vulnerabilities, but when I look in to them it ends up being stuff like ‚Äúif you put a malicious regex in to your own config file, your js linter will get stuck‚Äù reply jeroenhd 11 hours agoparentprevThis is a command injection through a basic GET giving instant root access. Definitely worth a high score. These days I'm pretty sure browsers won't let you put a private IP in anURL anymore but for the past 10-13 years there have definitely been browsers where visiting a web page is all you needed to do to get your NAS hooked up to a botnet. reply ronsor 18 hours agoparentprevI'm pretty sure a 9.8 CVE for something connected directly to WAN is a very bad thing. reply zahlman 18 hours agorootparentThe point is that the title puts the number up there to sensationalize. It doesn't concretely explain the scope or magnitude of the vulnerability. reply likeabatterycar 14 hours agorootparentprevThe 9.8 CVE was for their NAS. Exposing any NAS directly to the open Internet is a Bad Idea. For that matter, nearly every shit-tier NAS vendor (WD, QNAP) has had some critical remote vulnerability in recent years. Some were notable for mass data loss incidents. That aside, these companies are all very good at making very, very nice hardware at a price point consumers can afford. Some corners have to be cut and it's often software. The dirty secret is many Internet of Shit device vendors outsource the software development, often to the lowest bidder in some offshore sweatshop. In some cases it's just a repackage of an ODM design from some no-name company in Shenzhen. None of which are known for secure coding or good software practices. Criticize all you want but this is a textbook example of getting what you paid for. It's unreasonable to pay $100 for a D-Link box and expect it's Cisco ASA quality with free indefinite support. Cisco, Juniper, and Palo Alto would all tell you to pound sand if you expect support after EOL or if you let your maintenance contract (aka protection racket) lapse. reply BeefWellington 17 hours agoparentprevThe problem is the way those specifics are handled. The Complexity metric is intended to handle the \"specific configuration required\" scenario but nobody is really incentivized to properly score their stuff. reply gtsop 7 hours agoparentprevOk I get it, but if anything, people pay way less attention to security than they should. So I personally don't mind. I would prefer living in a world where people spend too much time caring for security reply fresh_broccoli 17 hours agoprevIt's a shame that MikroTik routers' UI is completely unsuitable for non-powerusers. Otherwise they would be perfect. Cheap and supported practically forever. Their trick seems to be that they use a single firmware image for all routers with the same CPU architecture. reply Maxious 17 hours agoparentThey've been trying lately though, you can supposedly set one up for a basic pppoe and dhcp scenario using the Mikrotik phone app and they have a Back To Home wireguard VPN setup app reply protocolture 14 hours agoparentprevI dunno its pretty basic. It has lots of options but users only need to be guided to quick setup or a few other places. reply TiredOfLife 10 hours agoparentprevThere is https://play.google.com/store/apps/details?id=com.mikrotik.a... official Home user app And the default page on routers ip is https://help.mikrotik.com/docs/spaces/ROS/pages/328060/Quick... reply slimebot80 19 hours agoprevMost \"Critical\" thing is: you buy a new router that is not from Duh-Link. reply guidedlight 17 hours agoprevI remember this happened before, and someone smarter than me exploited the vulnerability to access every router and patch it remotely. reply markhahn 17 hours agoprevhow about this: you can only abandon hardware if you enable open firmware on it. reply ChrisArchitect 17 hours agoprevRelated: D-Link tells users to trash old VPN routers over bug too dangerous to identify https://news.ycombinator.com/item?id=42201639 reply pcl 7 hours agoprevI see a lot of comments here recommending OpenWRT. I‚Äôve been happy with it in some deployments, but also don‚Äôt overlook the alternatives! I just had a wonderful experience with Fresh Tomato repurposing an integrated router / AP / 4-port switch as a multi-WAN router. It would have been doable with OpenWRT‚Äôs robust scripting support, but was just a few clicks in the UI with Fresh Tomato. https://freshtomato.org/ https://en.m.wikipedia.org/wiki/Tomato_(firmware) reply isodev 14 hours agoprevCan't there be a law that says something like \"you can't release new hardware while you have unpatched older hardware still in use\"? Recall or update your stuff first, release new things second. reply thesnide 13 hours agoparentsimpler. Just open up the firmware when EOL. So a 3rd party can patch it. Stop e-waste and planned obsolcence. If you fear loosing sales on new HW, make it significantly better. reply isodev 13 hours agorootparentYes, that would be better. I have a drawer full of old iPhone and Mac devices that are practically blobs of ewaste because their OS doesn't update. reply phire 11 hours agorootparentIt would be nice. Though, as a life-long Android user, I've been jealously looking at how long apple have actually been supporting their iPhones (at least since the iPhone 6) and I'm seriously considering switching. The 6S, 7, 8 all got feature updates for 7 years, and are still getting security updates after 9 years. The iPhone XS is still getting feature updates after 6 years. On Android, you are lucky to get 3 years of feature updates and 5 years of security updates. reply yrro 8 hours agorootparentGoogle do seem to be improving here, with 7 years of support for Pixel 8 and 9, and 5 years for Pixel 6 and 7. Earlier models got 3 years which was barely acceptable. reply bell-cot 4 hours agorootparentprev> Just open up the firmware ... Two major issues: - \"a 3rd party can patch it\" != \"a competent and non-malicious 3rd party will bother to patch it in a timely manner\". Let alone \"Joe User will search for, find, correctly identify, and install that saintly-3rd-party patch\". At best, this would modestly reduce e-waste & obsolescence. - Outside of maybe Apple, nobody selling little network products is designing their own silicon, or even has authority over all the IP in them. The latter is often locked down by a web of (international) supplier contracts. Trying to force retroactive changes to such contracts, at scale, could become a 1,000-lawyer disaster. reply isodev 4 hours agorootparentIt's not without challenges but we need to want it. Apple or whatever will never make it easy just from the goodness of their hearts. Consider Asahi linux with their years long efforts to make it possible to use something else as an OS on the Mac. Or something like broadcom drivers that's now practically a meme. If I \"buy\" something it shouldn't come a blackbox inside. reply Eduard 12 hours agoparentprevThe European Union has the Cyber Resilience Act, which will most likely become effective / mandatory by the end of 2027. https://en.m.wikipedia.org/wiki/Cyber_Resilience_Act Skimming the regulation text, it seems it requires the manufacturer of a connected device to report on and quickly fix vulnerabilities within the device's \"support period\". The support period for device classes still has to be determined, but it seems it is a vital requirement for a device to get a CE certification (without which it otherwise is not allowed to be put on the EU market). reply jeroenhd 11 hours agorootparentThese devices were produced back on 2011 I believe. Even with the CRA, I don't think much would change. A decade is definitely the high end of reasonable required software support for cheap budget NASes in my opinion. Of course stores would be forced to stop selling any remaining stock of them, but I doubt that's much of a problem, really. reply malux85 14 hours agoparentprevHow would that be defined? What about low CVEs? Does that mean a company cant release a keyboard while theres unpatched network switches? What about devices that are hybrid like no releasing DSL modems but what if it has an integrated switch? Does that mean no switches too? Whos going to enforce this? I cant see a way this would't be turned into a \"game the system\" and wouldn't solve the unpatched product problem at all. reply clwg 18 hours agoprevJust opensource the firmware and redirect the update url. reply rbetts 6 hours agoparentThis assumes that vendors have IP rights to open source the firmware, which seems unlikely. Presumably there are third party commercial components they don't have rights to publish. A rule like this essentially forbids closed source software. (Which, hey, might be a good thing... but then just mandate that directly and outlaw closed source software licensing.) reply wmf 18 hours agoparentprevThat doesn't set a good precedent though. The community shouldn't be expected to carry every IoT device. reply doubled112 18 hours agorootparentMaybe not, but it'd be nice to have the option. Wouldn't it? reply wmf 16 hours agorootparentIf you as a user want third-party firmware usually you can jailbreak and install it yourself (especially if the original firmware has zero security). If we allow a vendor to choose to make \"the community\" responsible for their firmware, almost every vendor will choose that as quickly as possible (e.g. one year). reply OtomotO 15 hours agorootparentThat's why in sane countries there is jurisdiction to deal with that. If you leave capitalism unchecked it will fuck you as hard as any other system. reply pt_PT_guy 11 hours agoprevOne of the reasons why there are major security f-ups: no accountability and no consequences reply znkynz 18 hours agoprevD-Link says buy a new router after vulnerability emerges after the signposted end of support date. reply mr_toad 17 hours agoparentHaving experienced D-link products first hand I‚Äôd say that anyone with a D-link product should buy something else anyway. reply aforty 16 hours agorootparentSomething that supports OpenWRT. reply jasonladuke0311 16 hours agorootparentI don‚Äôt think there‚Äôs much overlap between ‚Äúpeople who run OpenWRT‚Äù and ‚Äúpeople who use EOL D-Link routers‚Äù reply cesarb 15 hours agorootparentWouldn't the overlap between ‚Äúpeople who run OpenWRT‚Äù and ‚Äúpeople who use EOL D-Link routers‚Äù be \"people who run OpenWRT on EOL D-Link routers\"? The table of supported hardware at the OpenWRT site lists several D-Link models which can run the latest OpenWRT release, and several of them are marked as \"discontinued\" (that is, no longer sold), a few of them even being in that status for more than five years. reply remuskaos 12 hours agorootparentprevI don't know, I've installed openwrt on each device I've owned especially because their original firmware wasn't supported anymore (or crap to begin with). Often because the cheap devices were either all I could afford or because I've even gotten them for free or basically free, like on flea markets. reply a1o 5 hours agoprevAny good router access point that has nice gigabit Ethernet and really good WiFi, for a second access point in the house? reply dmix 18 hours agoprevNot downplaying the risks, but could a vulnerability on a d-link router really let you monitor traffic on the device in a practical sense (as mentioned in the video)? Assuming it is non-SSL is there enough computing power to even do any meaningful monitoring and subsequent exfiltration? Or are the SOCs used on them powerful enough these days. reply op00to 18 hours agoparentIt‚Äôs powerful enough to mitm traffic if you get someone to install a certificate, and it can easily pass packets where ever the attacker wants. reply dmix 16 hours agorootparentTrue I was thinking of packet analysis being intensive but simpler MITM/splitting it outbound makes senses. Ransomware and bricking would probably be the primary risk though. And security cams, NAS, printers, etc. reply op00to 15 hours agorootparentThe major worry for these devices for me is someone using my network connection for nefarious uses. I suspect many of the ‚Äúget a residential IP for your crawler‚Äù services actually use hacked IOT devices. reply likeabatterycar 18 hours agorootparentprevThis is also true of every intermediate router between you and the destination. TLS would not need to exist otherwise. reply stephen_g 18 hours agorootparentMost intermediate routers don't have easily exploitable holes allowing attackers to take them over to MITM traffic though... reply op00to 15 hours agorootparentI thought most internet routers in the US at least were pwned by the NSA. :D reply dmix 15 hours agorootparentReminds me of a Dan Greer talk he gave at NSA from 2014 http://geer.tinho.net/geer.nsa.26iii14.txt the basic gist is in the event of a cyberwar you could brick millions of peoples routers and their only natural solution would be to go to BestBuy to get a new one... which almost certainly is running a 4-5yr old linux/firmware version that is equally vulnerable. Of course this requires some remote access or lateral entry from other systems on the network, but it's an interesting thought experiment regardless. reply cesarb 15 hours agorootparent> the basic gist is in the event of a cyberwar you could brick millions of peoples routers [...] but it's an interesting thought experiment regardless. I think this is already way past \"thought experiment\". In the day of the 2022 invasion of Ukraine by Russia, thousands of satellite modems were deliberately bricked. reply dmix 14 hours agorootparentand https://en.wikipedia.org/wiki/VPNFilter The lack of major cyber wins in the invasion of Ukraine is still very surprising though. Maybe holding their cards for something big (something they didn't expect to win in \"3 days\"), or US really helped prepare Ukraine, or it's harder than it sounds :) reply likeabatterycar 14 hours agorootparentprevYes they do. It's called BGP. reply sitkack 12 hours agoprevI could see them facing criminal liability here. Someone is having hard conversations with their insurance company. reply o11c 19 hours agoprevDiscussion around this seems very confused; there are quite a few severe vulnerabilities this year in various products (routers and NASes). https://nvd.nist.gov/vuln/detail/CVE-2024-3273 https://supportannouncement.us.dlink.com/security/publicatio... (April 4) affects NASes (DNS-* products, same as one of the November vulnerabilities), no fix, official recommendation \"buy a new one\". https://nvd.nist.gov/vuln/detail/CVE-2024-45694 https://supportannouncement.us.dlink.com/security/publicatio... (September 16) affects routers (DIR-* products), fix by upgrading frimware https://nvd.nist.gov/vuln/detail/CVE-2024-10914 https://supportannouncement.us.dlink.com/security/publicatio... (November 6) affects NASes (DNS-* products), no fix, official recommendation \"buy a new one\" (despite not selling NASes anymore?). CVE-2024-10915 looks to be identical to CVE-2024-10914 at a glance https://nvd.nist.gov/vuln/detail/CVE-2024-11066 https://supportannouncement.us.dlink.com/security/publicatio... (November 11) affects routers (DSL* products), no fix, official recommendation \"buy a new one\". Note that you need to look at multiple CVEs to get the full picture here. (no CVE?) https://supportannouncement.us.dlink.com/security/publicatio... (November 18) affects routers (DSR-* products), no fix, official recommendation \"buy a new one\". (several other RCEs require login first, and I could not find an associated login vulnerability. Additionally there are several buffer overflows that theoretically could become an RCE) reply seam_carver 15 hours agoprevHuh I recently retired all my Dlink routers as soon as they stopped getting security updates, lucky me. reply DocTomoe 9 hours agoprev‚ÄûJust buy a new modem‚Äú they say ‚Ä¶ sure won‚Äôt be a D-Link ever again. reply Uptrenda 15 hours agoprevYeah, this doesn't surprise me one bit. The number of vulns that get patched in home routers is staggering (D-Link is particularly shit-tier and known for this.) If there's that many vulns being fixed then imagine the backlog of unfixed vulns... Then imagine how many legitimate issues have to be hand-waved away because engineers know there's no way in hell they'll ever get the time to fix them. And have to prioritize the worst problems. It kind of surprises me that you can just release a commercial product that is dangerous, make tons of money from it, then totally refuse to fix any problems with it. These devices are going to sit on innocent peoples networks who deserve to have privacy and security like anyone else. It's not outside the realm of possibly that an owned device leads to crypto extortion which leads to a business going under. Or maybe someone's intimate pics get stolen and that person then... yeah. Security has a human cost when its done badly. reply TheRealPomax 18 hours agoprevI mean... yes? \"we no longer support these\" devices were hit with critical vulnerabilities, and that'll never get patched, just like any other device that hit EOL. You knew your device was no longer supported and would no longer receive security updates, \"someone found an exploit\" is kind of a given, and \"d-link won't patch it\" equally so? reply yjftsjthsd-h 17 hours agoparent> You knew your device was no longer supported and would no longer receive security updates I'm less confident that this is true. I think I know what the EOL is for all my networking equipment[0], you probably know the EOLs on your networking equipment, but I would wager that a majority of the population very understandably regards these things as appliances that you buy, plug in, and then it works indefinitely, and they do not in fact have any clue when the vendor will decide to stop providing security patches for it. [0] Actually, now that I think about it no I don't; I was thinking of the core bits that I control, but the edge of my network is an ISP-provided box that I know essentially nothing about. Given that I don't manage it, I hope my ISP will send me a new one when it hits EOL but I don't know that. reply TheRealPomax 17 hours agorootparentAs an adult paying for your ISP service: you have some responsibility here. Whether you want that responsibility or not. reply bdangubic 17 hours agorootparentyou are on HN so this makes sense to you. imagine your car was hacked while driving your family in the middle of the desert and bricked. as an adult that bought the car is this your responsibility that you endangered your family‚Äôs well-being? reply TheRealPomax 14 hours agorootparentA legally binding as well as moral yes. If you drive a 2000 pound death machine, know how it can kill you. The idea that you are somehow not culpable in the situation you've given is baffling. Of course you are. reply bdangubic 6 hours agorootparentyou should delete this comment :) reply TheRealPomax 55 minutes agorootparentnah, people who know that cars kill a _whole_ bunch of people each year, and believe that car ownership should come with full responsibility by the owner when it comes to whether their computer-on-wheels is compromised or not are just as free to post to HN as people who think that that's not the car owner's responsibility. If you have car with remote shutoff/control, you owe it to both yourself and especially your family to stay up to date on news about that. The world's bigger than just the US, some countries place more value on personal responsibility than others. reply bdangubic 21 minutes agorootparentso in your world anyone that uses anything which is connected to the internet (which is basically everything) needs to be a cybersecurity engineer? :) my dad (and most dads) will be pissed he can‚Äôt drive his EV or anything of the tech gadgets he likes cause he‚Äôs not technically qualified for ownership and responsibilities that comes with it‚Ä¶? that sounds reasonable :) in this world I would say the very least business could do is put up a disclaimer on the product ‚Äúrequires PhD from Carnegie Melon to own‚Äù reply bigstrat2003 17 hours agoparentprevYeah, the only thing that might make D-Link's position here unreasonable is how long ago the devices hit EOL. Like if it was last week then they are being a bit petty if they don't issue a patch, but on the other hand if it was 10 years ago it is ridiculous to expect them to patch it. I couldn't find that info in the linked article (probably it's somewhere in between the two extremes I mentioned), but without knowing that context I can't really fault a vendor for saying \"EOL means EOL, sorry\". reply Dylan16807 16 hours agorootparent> if it was 10 years ago it is ridiculous to expect them to patch it I don't think even that is \"ridiculous\". It came out of the factory defective. This isn't about features or maintenance. How many years total would that be since last sale, still less than 15? reply BenjiWiebe 15 hours agorootparentAlso, how many hundreds of dollars would it really cost them to release an update, even if it was 15 years old? reply swiftcoder 7 hours agorootparentprevFor at least one remote access vulnerability reported earlier this year, D-Link declined to patch even though the device only hit EoL during the disclosure period, and was still within the EoS (end-of-service) date (which by D-link policy is EoL + 1 year): https://supportannouncement.us.dlink.com/announcement/public... reply likeabatterycar 18 hours agoprev [‚Äì] I cannot identify who the aggrieved parties are, aside from bandwagoning D-Link haters. These devices are end of life. Anyone running an EOL device doesn't care about security and probably wouldn't update the firmware if it was available. For comparison, Apple does not update EOL devices outside exceptional circumstances. I never received a 20% discount to upgrade. reply mrweasel 4 hours agoparentUnless these devices would auto-update, it also doesn't matter one bit. Sure HN users might go in and update their router, but the majority of users doesn't. Whoever, because the are routers, that users will install and forget about, how are they even suppose to be made aware that these are end of life? D-Links, and other producers of consumer hardware, seems to think that it's fine to just EOL their products and say \"go buy a new one\". Being D-Link should be much harder than being Cisco. At least Cisco can assume that their customers are keeping up with product information, patches and so on. What is D-Links plan for informing users that their product is no longer secure? I don't think they have one and that pretty irresponsibility because they should know that the majority of their customers aren't all that technically savvy. I don't know if D-Link devices automatically pulls update, my guess is that they don't, but there should at least be a on device indicator that this device is now EOL and should be used at the customers own risk. It fine to say that a device is EOL and no more updates will be made available, but they need to indicate to the customers that these devices are now at risk. reply swiftcoder 7 hours agoparentprev> These devices are end of life If I told you that your fridge or car would be EOL in 5 years, and after that you should throw it away and buy a new one, you'd rightly laugh me out of the room. I think it's worth taking a moment to consider why we let manufacturers get away with abandoning tech gadgets so quickly... reply stephen_g 17 hours agoparentprevWhy do you think there is such a thing as 'D-Link haters'? I don't hate D-Link (I don't care about them anywhere near enough to bother), but I think there's enough of a history of poor security practices to avoid their products... reply luizfelberti 18 hours agoparentprevSure, but is EOL really a defense given the absolutely pathetic security posture that created this exploit in the first place? Is there a statute of limitations on mind boggling levels of incompetence? I'd usually give the EOL argument some credit, but this exploit is not an accident, someone deliberately wrote an unauthenticated remote command execution as a feature, and it made it to production, and no one in this long chain of failures thought to themselves \"gee, maybe we shouldn't do this\" reply wmf 18 hours agorootparentWe could have passed a law requiring minimum security standards but we didn't. The result was predictable and here it is. reply philipwhiuk 18 hours agoparentprevHow long should a consumer expect their modem to last? How long ago were they last being sold at retailers? reply forinti 4 hours agorootparentI think gadgets should have an EOL date on them, manufacturers might even start competing on who gives updates for longer. reply slimebot80 18 hours agoparentprev [‚Äì] Wait, has Apple ever exposed an end-point like this? Do we know how they'd react if they ever did? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "D-Link has announced it will not provide security patches for 60,000 older modems that have reached end-of-life status, urging users to upgrade to newer models instead.",
      "The unpatched security vulnerabilities could potentially allow hackers to take control of these devices, posing a significant risk.",
      "Most of the affected modems are located in Taiwan, and for users unable to upgrade, D-Link recommends restricting remote access and using secure passwords as precautionary measures."
    ],
    "commentSummary": [
      "D-Link has decided not to patch vulnerabilities in 60,000 older modems, exposing them to security risks, which raises concerns about device security and manufacturer responsibility.",
      "The announcement has sparked discussions on the importance of long-term support and the potential benefits of open-source solutions like OpenWRT for maintaining device security.",
      "There are suggestions for legal mandates requiring manufacturers to provide security updates or release firmware to the public when devices reach end-of-life, highlighting a broader industry issue."
    ],
    "points": 241,
    "commentCount": 153,
    "retryCount": 0,
    "time": 1732653377
  },
  {
    "id": 42251656,
    "title": "Marshall Brain died hours after alleging retaliation at NC State",
    "originLink": "https://www.technicianonline.com/news/popular-nc-state-professor-marshall-brain-dies-alleges-retaliation-for-ethics-complaints/article_152e5c80-ac2e-11ef-8b3f-036ac3c8d9bf.html",
    "originBody": "Top Story Breaking Popular NC State professor Marshall Brain dies, alleges retaliation for ethics complaints Kate Denning, Editor-in-Chief and Ethan Bakogiannis, Managing Editor 22 hrs ago 22 hrs ago 0 Facebook Twitter WhatsApp Email Facebook Twitter WhatsApp Email Print Copy article link Save Editor‚Äôs Note: This article contains reference to death. Questions are surrounding the death of a popular NC State faculty member, whom NC State police found dead in his office on Nov. 20. Police found Marshall Brain II, director of the Engineering Entrepreneurs Program, unconscious and nonresponsive in his office at Engineering Building II on Centennial Campus at 7:00 a.m. NC State Police Public Information Officer Conner Hartis confirmed police found Brain deceased upon their arrival. The Wake County Simulcast showed Brain‚Äôs wife called for a welfare check at 6:40 a.m. No cause of death has been released. Hours before Brain‚Äôs death, he sent an email to colleagues saying two University department heads retaliated against him after he filed several ethics complaints months before his death. University spokesperson, Mick Kulikowski, said the University has no comment on the allegations or Brain‚Äôs death. The University has also not issued a public statement on Brain‚Äôs death. Brain graduated from the University with a master‚Äôs in computer science in 1992 and worked at the University since 2012. Brain was an author, entrepreneur and founder of the popular website HowStuffWorks.com. The award-winning faculty member was an influential figure in the world of science and entrepreneurship on and off campus. His classes, which aimed to combine the worlds of engineering and entrepreneurship, were popular. The email shared to Technician and posted online on a website dedicated to Brain‚Äôs legacy contains allegations of wrongdoing. Brain claims he was forced into retirement as retaliation for submitting numerous ethics complaints. Brain wrote in the email that Stephen Markham, executive director of NC State‚Äôs Innovation and Entrepreneurship program, announced Brain‚Äôs retirement to the Innovation and Entrepreneurship team on Nov. 6, saying the retirement was effective Dec. 31, 2025. Brain was a member of the Innovation and Entrepreneurship Leadership team, alongside Markham. Brain wrote that he was not retiring but instead was fired. Markham did not respond to multiple requests for comment in time for publication. ‚ÄúI have just been through one of the most demoralizing, depressing, humiliating, unjust processes possible with the University,‚Äù Brain wrote. ‚ÄúThe fact is that I am not ‚Äòretiring.‚Äô Instead, NC State terminated me on Oct. 29.‚Äù Brain wrote that after submitting an ethics complaint concerning Veena Misra, head of the Department of Electrical and Computer Engineering, and bringing his concerns to her directly, Misra retaliated against him. Brain‚Äôs complaint contained allegations of wrongdoing in the form of ‚Äúuntrue statements, incompetence, hiding info, bad faith dealings and unethical behavior‚Äù after a disagreement with Misra in August regarding repurposing the Engineering Entrepreneurs Program meeting space to accommodate a new hire. ‚ÄúWhat came back was a sickening nuclear bomb of retaliation the likes of which could not be believed,‚Äù Brain wrote. ‚Äú[Misra] excommunicated me from my department for reporting my concerns to her.‚Äù Misra did not respond to Technician‚Äôs request for comment. Jim Pfaendtner, dean of the College of Engineering, responded on her behalf and referred Technician to Kulikowski. Brain wrote he received an email a few weeks later from Srinath Ekkad, head of the Department of Mechanical and Aerospace Engineering, saying the department would no longer recommend students participate in Brain‚Äôs Engineering Entrepreneurs Program. Brain wrote that, after outlining his concerns to Ekkad about this message, Markham informed Brain he would be taking disciplinary action against him for ‚Äúunacceptable behavior.‚Äù Brandon Kashani, Brain‚Äôs former student and a startup mentor at NC State‚Äôs entrepreneurship clinic, received Brain‚Äôs email along with more than 30 others both within and outside of the University. Kashani said he met with Brain on Nov. 15, where Brain detailed the situation and correspondence with the University. Kashani described Brain as ‚Äúheartbroken.‚Äù ‚ÄúHe felt like his reputation was tarnished, like everything he worked for was ruined, and the root of all that was he didn't get any support from the University, the University that he put all his life ‚Äî the last 12 years ‚Äî towards,‚Äù Kashani said. ‚ÄúAnd all he wanted to do was be heard.‚Äù Brain wrote in the email that he believed the ethics complaint system‚Äôs framework was not properly used in addressing his concerns. The complaints were submitted through EthicsPoint, a reporting tool used by employees to report ethical concerns. ‚ÄúMy career has been destroyed by multiple administrators at NCSU who united together and completely ignored the EthicsPoint System and its promises to employees,‚Äù Brain wrote. ‚ÄúI did what the University told me to do, and then these administrators ruined my life for it.‚Äù Kashani said Brain submitted numerous complaints through the EthicsPoint system and said tensions arose because Brain didn‚Äôt ‚Äúplay the political game‚Äù through his questioning of higher-ranking administrators. ‚ÄúMarshall was caught in an imbalanced group of people with more power than him, and they didn't like him calling them out,‚Äù Kashani said. ‚Äú... He was keeping people accountable. He didn't understand that political aspect of it, and they just wanted to get rid of him.‚Äù Kevin Barry, Brain‚Äôs former student and a member of the Board of Advisors for NC State‚Äôs Innovation and Entrepreneurship Leadership program, said Brain was pivotal in the lives of students in this program and beyond. ‚ÄúMarshall was a cornerstone of entrepreneurship at NC State, and a very key person who dedicated himself and was a real entrepreneur, and really dedicated himself to the students,‚Äù Barry said. ‚ÄúAnd he, through and through, down to the bone, had that love and desire to help students. So to see what's going on with him is just absolutely devastating and disgusting.‚Äù Both Barry and Kashani said they are disappointed in the lack of a public statement from the University surrounding Brain‚Äôs death. ‚ÄúIt's been six days now, which is insane,‚Äù Kashani said. ‚ÄúAnd I know a lot of people are reaching out. There‚Äôs a lot of pressure, but there hasn't been any acknowledgement of mistakes that were made, systems that failed, no resignations, not even a call to celebrate Marshall's achievements.‚Äù While Brain‚Äôs University biography remains on the Innovation and Entrepreneurship website, his page on the Computer and Electrical Engineering website no longer exists. This is a developing story. If you or someone you know is having difficulty processing grief or having a mental health emergency, the Counseling Center can be reached 24 hours a day at 919-515-2423. If you are in a crisis situation and need immediate help, please call the National Suicide Prevention Lifeline at 988. In the case of a life-threatening emergency, call 911. The Counseling Center‚Äôs website offers free online screenings, a plethora of self-help resources regarding mental health and wellness concerns and a comprehensive list of campus services available for those who need guidance. To view an exhaustive list, visit https://wellness.ncsu.edu/resources/. If you‚Äôre seeking professional counseling or other mental health services on campus, visit the Counseling Center‚Äôs Getting Started page at https://counseling.dasa.ncsu.edu/get-started/make-an-appointment/ to complete paperwork, set up an appointment and more. Facebook Twitter WhatsApp Email Print Copy article link Save Kate Denning Editor-in-Chief Follow Kate Denning Ethan Bakogiannis Managing Editor Follow Ethan Bakogiannis √ó Post a comment as anonymous Emoticons Comment Text Cancel Post comment √ó Report Cancel Report Abuse √ó Watch this discussion. Watch this discussion Get an email notification whenever someone contributes to the discussion Cancel Start watching (0) COMMENTS Welcome to the discussion. Log In Site search Search Facebook Twitter YouTube Instagram Weekly Newsletter Top Technician stories delivered to your inbox each Thursday Please enter a valid email address. Sign up Manage your lists OUR PRINT EDITIONS VIDEOS Technician Tries: Wolfstock 2023 Artist Reveal Isaac Hernandez Pantoja, Assistant Video Editor Apr 11, 2023 Biden visits North Carolina Katherine Wan, Video Correspondent Apr 4, 2023 Biden visits North Carolina Katherine Wan, Video Correspondent Apr 4, 2023 THE LATEST News Popular NC State professor Marshall Brain dies, alleges retaliation for ethics complaints Sports Hurricanes halt two-game skid with miraculous third-period comeback against Stars Sports Explosive fourth quarter elevates No. 20 NC State women‚Äôs basketball over Southern University Sports Wolfpack swimming shows out at Wolfpack Elite GAC Invite Sports Hurricanes lose more than just 5-4 in shootout to Columbus",
    "commentLink": "https://news.ycombinator.com/item?id=42251656",
    "commentBody": "Marshall Brain died hours after alleging retaliation at NC State (technicianonline.com)207 points by HappyKasper 18 hours agohidepastfavorite131 comments simpaticoder 17 hours agoHis story is a cautionary tale about real life vs idealism. The two come into conflict frequently, and sometimes violently. Nothing is more difficult or dangerous than holding power to account; the mechanisms we imagine are in place to hold power accountable exist purely in that imagination. The personal feelings of shame, guilt, or ethical responsibility we imagine there to be, or the social pressure brought to bear on those who demonstrate a lack of those qualities, is missing when push comes to shove. Being an idealist, really believing in these things, is the setup for great tragedy. The fundamental mistake is to believe that others think like you do or value the same things you value. Of course I know nothing of this particular situation, but the shape of it is all too familiar - an idealistic, inspirational collegue forced out after speaking truth to power. How many tens of such people do we know? How many of them do not actually get back on their feet? How many of them did we speak up for? reply brailsafe 16 hours agoparentYep. I often reflect on some of my career mistakes, especially when evaluating current decisions within the context of a job or interacting with other institutions, and what I wish I'd learnt earlier would be to \"read a room\". Sure, there is technically a process for reporting wrongdoing, but there's no process for reporting wrongdoing and keeping your job, and keeping your job is more important. What isn't your job is taking moral stances on things, having political opinions, provoking what others might see as unnecessary conflict, in any form. Sure, you could spend some time ensuring accessibility standards are being met, but really you shouldn't unless someone complains, because although you think it's good practice, you're being paid to put visible results on the screen, unless you can make a business case for it that's sufficiently compelling and rewarding that it's worth pursuing. You'll lose your job for not getting the thing shipped, but probably won't for it not being theoretically good enough, unless you're a real doctor or real engineer Don't stick your neck out unless you control the outcome (for positive or negative), and figure out what you're really being told to do or asked to do, and keep your effort to that. Don't go above and beyond, it's out of scope and you're better off sleeping. Not joking. If you can't do that, you might struggle to stay employed, and it's not worth your personal risk. At work, keep your opinions to yourself, nearly all the time, they're rarely important, just get the work done and go home, work isn't that important either, don't pretend like you're saving the world. reply coldtea 16 hours agorootparent>Sure, there is technically a process for reporting wrongdoing, but there's no process for reporting wrongdoing and keeping your job, and keeping your job is more important. What isn't your job is taking moral stances on things, having political opinions, provoking what others might see as unnecessary conflict, in any form. Up to a certain point. That answer didn't hold up well at the Nuremberg trials. After a point there's also dignity and morality, not just \"keeping the job\". reply passing_by_and 16 hours agorootparentThat only happened because they needed some show trials to pacify people. A few were picked to take the fall and the rest were quietly brought to universities and government labs all across western powers. The United States has a proud tradition of totally ignoring all the agreements that came out of those trials. reply JumpCrisscross 15 hours agorootparent> they needed some show trials to pacify people Which people? The Europeans were occupied or liberated under effectively caretaker governments. Americans didn't need pacification. > the agreements that came out of those trials The trials inspired some agreements. It didn't create any, other than the precedent of holding leaders accountable for crimes against humanity. reply foul 10 hours agorootparent> Which people? The Europeans were occupied or liberated under effectively caretaker governments. They were occupied but they weren't entirely busy: while \"low\" people were happy to kill ex-Nazi collaborators themselves, it's the post-war governments (all of them, USA's included) who needed, with those trials, to manifest a re-establishment of the rule of law once again. 80 years later we can see it's been a hypocrite farce in every part of it, but it saved lives, those that were worth of living, although spared Nazis, fascists and sometimes communists too. reply JumpCrisscross 8 hours agorootparent> who needed, with those trials, to manifest a re-establishment of the rule of law once again Do you have a source for this having been the motivation? I‚Äôm admittedly most familiar with the French and American perspectives. Those weren‚Äôt concerned with pacification but creating an international sense of the rule of law and legal basis for the occupation and restructuring of those societies. reply refulgentis 14 hours agorootparentprevNo. reply mistercheph 15 hours agorootparentprevWhat modern corporate employee wouldn't (haven't?) sleepwalk into perpetuating horrors on innocent people and then really and truly believe it when they say \"I was just doing my job...\" I am not excluding myself, we have not magically solved the social/political circumstances that lead to the second world war, and we are doomed to repeat those mistakes if we take for granted that those structures just fizzled away because we blood sacrificed millions of people and then the victors did a rain dance over the burial mound. reply totetsu 16 hours agorootparentprevNot trying to troll here, but, what does something like Nuremberg trails matter in a country where someone who can incite an insurrection and then become president again, or a world where international criminal court orders are ignored? reply JumpCrisscross 15 hours agorootparent> what does something like Nuremberg trails matter in a country where someone who can incite an insurrection and then become president again, or a world where international criminal court orders are ignored? Nuremberg had nothing to do with insurrections and revolutions. It also judged the Nazis according to standards that didn't exist when they committed their crimes; the ICC was created after Nuremberg as an imperfect system. Imperfect, however, is still better than nothing. reply coldtea 6 hours agorootparentprev>Not trying to troll here, but, what does something like Nuremberg trails matter in a country where someone who can incite an insurrection and then become president again \"A bunch of random people who get into a government building, take selfies, and are dispersed later\" is a pretty low bar for an insurrection. That's not how insurrections are organized and conducted, more like a \"flash mob\" of people with no clear idea what they're even doing. The symbolism of the Capitol aside, BLM/Antifa and co attacking government buildings, heavily clashing with police, setting government buildings, police departments, and properties on fire, and so on, for months, would count as a much more serious case. Though even that would still be more like a bunch of states-wide coordinated riots (with some partisan color) than an inssurection. And of course the latter was supported, and the first was met with pearl clutching indignation. It's more about interest in partisan politics than interest in the rule of law. Funnily, many people who have done actual inssurections, of the armed, overthrow the goverment for real, kind, with plans and teams arranged kind, have became presidents and PMs again in legitimate elections. Examples include from Hugo Chavez (coup in 1992, then prison, president in 1998), to Nelson Mandela (conducted anti-government operations and marked as a \"terrorist\" for decades, went to prison, then became legitimate president). A tamer example might be Mexico's own L√≥pez Obrador: lost elections in 2006, led demonstrations and clashes, created a parallel government with himself as \"Presidente Legitimo\" (the \"real prez\"), finally won elections in 2018. >or a world where international criminal court orders are ignored? Well, despite the name, the ICC is not a body with sovereign power over the whole world. If a country hasn't signed in to respect its rullings, it can just ignore them. And as usual the US signs only whichever it finds convenient, nothing that could bind it to respect global decisions (so much for \"rules based order\"). So in this case, the difference with the Nuremberg trials was that those conducting them had power over those accussed. Which would also be the case with, say, the FBI or the IRS and co. Which is why whether \"I just followed orders\" is a legitimate defense in such a case still matters. Unless of course the person has the power to brush off their persecution. reply riku_iki 15 hours agorootparentprev> That answer didn't hold up well at the Nuremberg trials. that's just winners were punishing losers. In alternative reality, those who dropped nukes were facing trial in Nuremberg. reply coldtea 6 hours agorootparent>that's just winners were punishing losers Whether it's winners punishing losers, or e.g. the FBI/FDA/DEA/IRS/whatever punishing some company exexutives and employees, the potential for this to be a bad defense remains constant. reply riku_iki 1 hour agorootparentwhen it is winners vs losers, your line of defense is irrelevant, since winners decide rules of the game. We can partially tell the same that FBI/FDA/DEA/IRS punishes regular Joe much more harshly, compared to CEOs which almost never goes to jail unless he stole from other rich/in power. reply yieldcrv 16 hours agorootparentprevGiven that this highly improbable outcome involves two separate coalitions of countries invading yours from both sides, ‚Äúread the room‚Äù is a safe bet for all parties to make, including last minute flights to Argentina reply coldtea 6 hours agorootparentIf only I had used this outcome only as a highly understood example, as opposed to as the exact sitution that will befall the person I responded to... oh, wait! reply yieldcrv 3 hours agorootparentThat‚Äôs cool but it‚Äôs something I think about a lot Like how some well known companies are implicated because of government contracts with that short lived regime in the 1930s and its like thats not really a deterrent because you don't really know what a government will do, and accountability requires a multi coalition invasion, losing, and subsequent leaking of state records the threshold for that to occur is so high, like for one, that government has to actually lose, and the one everyone is mad at typically doesn't makes more sense to contract with all parties in all countries and just collect the checks I think that specific example is a perfect choice to undermine the specific lesson you were aiming for reply aoanevdus 15 hours agorootparentprev> Don't stick your neck out unless you control the outcome (for positive or negative), and figure out what you're really being told to do or asked to do, and keep your effort to that. Don't go above and beyond, it's out of scope and you're better off sleeping. Not joking. If you can't do that, you might struggle to stay employed, and it's not worth your personal risk. Generally good advice but I would caveat it. Sometimes the org doesn‚Äôt know it wants something, or doesn‚Äôt know that you are the right person to ask. For example, I‚Äôve had good success when finding ways to save millions of dollars. And other, more domain-specific things that make management happy. Granted, you don‚Äôt need to do this if your position is stable and that‚Äôs enough for you. But if you are early in your career, trying to move up, or just want to be on the keeper list when there are layoffs, simply doing what is asked may not be enough. reply derangedHorse 7 hours agorootparentprevThe two most important lines of your comment: > you shouldn't unless someone complains ‚Ä¶ unless you can make a business case for it that's sufficiently compelling and rewarding that it's worth pursuing > Don't stick your neck out unless you control the outcome (for positive or negative) If there‚Äôs moral questions surrounding your employment and no structures to tackle them, then quit. If there‚Äôs a way to garner support for a proposal in a way that will incur a significant cost to the organization if rejected, then leverage those closest to the top who you believe will understand this. Basically, ‚ÄúIf you come for the king, you best not miss‚Äù reply sneak 16 hours agorootparentprev> What isn't your job is taking moral stances on things, having political opinions, provoking what others might see as unnecessary conflict, in any form. This is wrong, and how you end up with flying drone face recognizing skullpopping murderbots. \"I just work here\" is an abdication of adult responsibility to self, family, and society. It's not some idealistic stance, it's the truth. It's how we ended up with concentration camps in the USA multiple times, and why many companies are gearing up to build more right now. reply Aeolun 11 hours agorootparentAbsolutely, and 90% of people will happily do so. So your personal ‚Äòline in the sand‚Äô is just completely and utterly irrelevant (aside from your own satisfaction) reply BriggyDwiggs42 9 hours agorootparentI think this stance is mired in the big picture but ignores small altruism. Neighbors who sheltered jews during the holocaust didn‚Äôt alter the system, but they saved real lives. Clandestine action for the better, in line with one‚Äôs convictions, can be genuinely worthwhile. reply catlifeonmars 14 hours agorootparentprevIDK, that seems like a pretty unfulfilling job. A lot of jobs are like that, but not all of them are. Staying in your own lane is boring. reply MichaelZuo 16 hours agorootparentprevIt‚Äôs more nuanced then that. People don‚Äôt want others pretending to be superior to them, if they are not actually that much better. e.g. A literal supergenius can behave very erratically nearly every week of the year, 40 years straight, and still achieve notable successes in life, such as Kurt Godel But a regular genius pretending to be a literal supergenius and trying to do the same, is well at best going to be perceived as a clown. And it gets even more lopsided as you go down. Someone merely very smart pretending to be a literal genius is never going to earn anyone‚Äôs respect around the table. reply trinsic2 11 hours agorootparentHow does this have anything to do with standing up to harms? Im sorry this is starting to sound like the philosophy that the Nazi regime operated under. reply MichaelZuo 6 hours agorootparentHow does ‚Äòstanding up to harms‚Äô relate to how other people assess you? You can say anything, stand up to anything, etc., at a meeting but have differing underlying motives that is unsaid. reply Joel_Mckay 15 hours agorootparentprevLets be honest, most faculty members eventually become simple Ectoparasites on student work, or ruminate on problems they stopped making progress on for decades. As someone prone to idealism, you need to careful of the external consequences of work that runs into conflict with institution politics, government goals, and foreign/domestic intelligence services (professional thieves.) I am probably just a clown, but often had to consider the escalation of coercion stages in the context of personal resolve. You will be evil one day too... Best of luck =3 reply A4ET8a8uTh0 15 hours agorootparentprevnext [‚Äì]to transfer wealth upwards constantly This is overly simplistic. Truer: we will sacrifice a lot to maintain our relative standard of living. reply benreesman 10 hours agorootparentI want to answer this point separately. My standard of living ten years ago was so high it was honestly gross, I imagine it was easily in the ballpark of a BlackRock quant. The year I quit was my second highest earning year in which I made an amount that is shameful given that my job was to sell digital fentanyl. I will sacrifice my standard of living up to and including not living because I feel a deep identification with the abstraction I call ‚Äúmy fellow person‚Äù. A lot of people will sacrifice their principles to preserve their standard of living. In what is looking to be a rough decade or two those people are a liability to that same abstraction. reply JumpCrisscross 9 hours agorootparent> lot of people will sacrifice their principles to preserve their standard of living The line where principles outweigh personal interests (alternatively, where individual interest should be suppressed for the group) vary from person to person, group to group. But they are universally ahead of where those who‚Äôd prefer humans weren‚Äôt flawed, in their view, imagine them to be. The easy excuse is to conclude everyone is evil. The hard work, that granted few of us are cut out for, is making do with the world we have. (The fun, in exploring the richness these ‚Äúflaws‚Äù produce.) Note: I‚Äôm not asking anyone to settle for a lower moral rung. I‚Äôm saying: see the world as it is, not as you judge it to be. Would spacefaring be simpler without gravity? Yes. But the universe‚Äôs beauty, ourselves included, could not then exist. Human ambition and aspiration and yes, greed, are not aspects of ourselves I‚Äôd ever wish away. Even if it would make some problems easier. reply benreesman 8 hours agorootparentI want to express my admiration that you‚Äôve engaged with me on this tricky and controversial topic. I actually wish I had acknowledged several very astute points that I strongly agree with. I‚Äôm not a RenTech quant, but I‚Äôve spent enough time around heavyweights to know one when I see one. I‚Äôd like to have a dialog. If you feel the same please email me at b7r6@b7r6.net reply benreesman 15 hours agorootparentprevWho‚Äôs standard of living? We will render arbitrary people homeless to constrain the supply and push up real asset prices for homeowners. We‚Äôll tolerate flagrant cartel monopoly and flagrant securities fraud and all manner of evil to drive equities up? Qui bono? Not the working person at the median. reply JumpCrisscross 15 hours agorootparent> Who‚Äôs standard of living? Each person's. It's an individual determination. > We will render arbitrary people homeless to constrain the supply and push up real asset prices for homeowners Yes. Because from the homeowner's perspective, they're maintaining their real standard of living. Crafting good policy requires being very careful about whose relative standard of living you're sacrificing for the greater good. Because no matter how privileged you think someone is, for them, it's the baseline. > We‚Äôll tolerate flagrant cartel monopoly and flagrant securities fraud and all manner of evil to drive equities up? No, not really. Shareholders win in the aftermath of antitrust action and trusted equity markets. We tolerate those things, the first much more than the second, but not for the reasons you presume. reply benreesman 15 hours agorootparentI‚Äôm not sure what the theme of your contention is: it sounds like you‚Äôre basically saying everyone will fight as hard as possible with whatever means at their disposal to be maximally selfish. But that tired toy example from game theory shows that everyone loses if both grass the other up. Countless studies of both human beings and computer programs in the iterated prisoner‚Äôs dilemma show that the wining strategy is not in fact to drive housing prices so high that the homeless problem eventually wrecks your property value. This smash and grab, ‚Äúhow much can you carry‚Äù mafia capitalism has been tried before and the result was a guillotine. reply JumpCrisscross 14 hours agorootparent> everyone will fight as hard as possible with whatever means at their disposal to be maximally selfish No, I'm saying loss aversion is often misunderstood [1]. Both in its existence and strength. And the fact that it operates in relative terms, i.e. someone who is materially better off than they were 10 years ago may still throw their toys out of the pram if their neighbor is much better. > the wining strategy is not in fact to drive housing prices so high that the homeless problem eventually wrecks your property value Sure. The point is you also can't drive home prices down, because that hurts homeowners and activates them as a political bloc. (The solution is real home price growth as close to zero as possible amidst rising real incomes.) [1] https://en.wikipedia.org/wiki/Loss_aversion reply benreesman 14 hours agorootparentI‚Äôm aware of the concept of loss aversion, but I think it as an explanatory factor for macro economics is a red herring: one of a long list of diversions in the grand company of all trickle-down economics. People say that the without arbitrary incentives for arbitrary wealth that hard work and innovation won‚Äôt happen. Demonstrably false! The Internet that the current cartel is looting was a public private partnership! The best software these days is done substantially by passionate hobbyists! People point to Silicon Valley and say ‚Äúthis wouldn‚Äôt be possible in Europe‚Äù. Then they point to the market capitalizations of the vampire megacorps that the world would be far better without as the success story. People make other arguments slightly craftier: punitive taxes on the mega wealthy wouldn‚Äôt raise enough revenue to matter. True, but that‚Äôs not the point of a punitive wealth tax: the point of a punitive billionaire tax is to deprive billionaires of godlike power to restructure society in their own interest. Anyone outside a few narrow bubbles can see that this is going very badly. I‚Äôll agree with you this far: it‚Äôs going to be a tall hill to climb to get people with homes worth 20 times what they paid and 401ks to vote for a sane future. But this is a comparatively recent phenomenon: older people used to be obsessively concerned with the prospects of younger people for trivial biological reasons. These days? That ‚Äúblood boy‚Äù transfusion thing Thiel is always on about? It‚Äôs a terrifying metaphor for the bigger picture. The procedure was pioneered so a father could keep his daughter alive at great risk to himself. For some reason we now tolerate if not celebrate the vampire ideal of running that backwards. reply JumpCrisscross 9 hours agorootparent> These days? That ‚Äúblood boy‚Äù transfusion thing Thiel is always on about? This complaint is old as civilisation. Cato complained about the price of pickled fish exceeding that of ploughmen, and that was hundreds of years before even the Republic peaked. > punitive taxes on the mega wealthy wouldn‚Äôt raise enough revenue to matter Who said this? I‚Äôm a fan of higher (not necessarily punitive) taxes on billionaires. But you can‚Äôt trade that for middle-class income taxes 1:1; the former is far more volatile. reply benreesman 7 hours agorootparentI‚Äôve read Cato as well as undergraduate behavioral economics. No tax on the wealthy is worth its weight in paper unless it breaks the back of fluid fungibility of money into policy. We have any number of ways to raise revenue, most of which would be trivial if Bezos cast one ballot like anyone else. Directly or indirectly bribing legislators or regulators should be a capital offense. reply JumpCrisscross 7 hours agorootparent> No tax on the wealthy is worth its weight in paper unless it breaks the back of fluid fungibility of money into policy These are separate policy fronts. You've got a water leak in your engine and are trying to solve it by banning rain. > Directly or indirectly bribing legislators or regulators should be a capital offense Define this as loosely as Redditors consider lobbying and you essentially shut down democractic involvement to all but those who can afford the trip to D.C. to advocate in person. Or, to Cato, the Tribal Assembly. Bet you'd get a lot of rich people on board with that rule! reply benreesman 7 hours agorootparentWe‚Äôve all been having some version of this conversation for decades: any time someone proposes limiting campaign finance or any other mechanism by which wealth becomes law some unfounded assertion gets made about how it will have unintended consequences that actually favor the people with the money. ‚ÄúTrust me, I‚Äôll get you over the barrel even more easily if you try to stop me. Shhh, just let it happen.‚Äù I think it‚Äôs a bluff. reply benreesman 6 hours agorootparentIn the sunset of dissolution everything takes on the aura of nostalgia, even the guillotine. Society worked just fine without IO/PO striping, it worked just fine without K Street as an institution. I don‚Äôt make this case because I take any joy in what will happen to Marie Antoinette. It‚Äôs my aim to persuade the investor class to cut a deal before it gets ugly. reply JumpCrisscross 6 hours agorootparent> Society worked just fine without IO/PO striping, it worked just fine without K Street as an institution It worked fine without anyone in tech, too. Or crypto. Agree on K Street. But Trump's 2024 campaign is praxis in disintermediating K Street. We need more precision. > I don‚Äôt make this case because I take any joy in what will happen to Marie Antoinette. It‚Äôs my aim to persuade the investor class to cut a deal before it gets ugly This strikes me as idealistic, maybe arrogant. Marie Antoinette didn't have a private jet or wireable funds. Even then, most of France's aristocracy fled and lived fine. Violent revolution is not a romantic reset. It's a civilisation bowing out of the competition. They only fester now, post Industrial Revolution, because it's no longer profitable to invade unstable neighbours. The July Revolution, for example, was checked by the threat of foreign intervention. Hell, the \"Westphalian\" sovereignty Putin talks about was actually a contract permitting the great powers to invade the HRE to guarantee its Constitution. reply benreesman 5 hours agorootparentArrogant? You guys think you‚Äôre immune from consequences. You think everyone smart and relentless enough to represent any challenge is either already bought or easily sidelined. There are more of us than you think who walked straight out no education and no connections and trivially operated at comparable levels to privileged and credentialed peers. But the values are different: when you combine a street kid‚Äôs skepticism of our magistrates and noblemen with the first hand experience of seeing how utterly bankrupt the whole artifice is you get implacable enemies with extreme tolerance for adversity who play for keeps in a way no one can who ever benefitted from the system. Underestimate us all you like. reply JumpCrisscross 3 hours agorootparent> think you‚Äôre immune from consequences I‚Äôm saying they can get away and get their resources out faster than before, and even before they were mostly fine. > you get implacable enemies with extreme tolerance for adversity who play for keeps in a way no one can who ever benefitted from the system These are never the beneficiaries in revolution. Ever. That doesn‚Äôt stop revolution. Folks say ‚Äúfuck you‚Äù when enough is enough. But again, it‚Äôs not rebirth‚Äîit‚Äôs bowing out of the civilisation game. The ‚Äúrevolutions‚Äù we romanticise preserved pre√´xisting power structures. To the extent America stands on the precipice of revolution, it‚Äôs in the molds of C√¶sar and Augustus. reply benreesman 6 hours agorootparentprevI didn‚Äôt mean that I was personally going to broker some compromise. I meant that in my small way I‚Äôm part of a larger conversation. There are a lot of people bright enough to have been at the top of their field who for one reason or another are opposed to the status quo. I‚Äôm just one of a lot of people who are every bit as sophisticated as anyone on Jane‚Äôs Prop desk and yet still under its boot. reply JumpCrisscross 3 hours agorootparent> a lot of people bright enough to have been at the top of their field who for one reason or another are opposed to the status quo Sure. They should do more. My point is ‚Äúwatch out, you‚Äôll wind up headless‚Äù is more self soothing than a threat. If America flips over, the billionaires will be fine. Maybe a couple unlucky or stupid millionaires will lose their coin or lives. Most will, at worst, preserve their wealth; more likely, they‚Äôll get more wealthy and powerful. > Jane‚Äôs Prop desk and yet still under its boot Nobody at Jane Street is wealthy enough to be politically relevant outside its founders. (Unless they‚Äôre trading from a very small town, and you‚Äôre in it.) reply JumpCrisscross 6 hours agorootparentprev> any time someone proposes limiting campaign finance or any other mechanism by which wealth becomes law some unfounded assertion gets made about how it will have unintended consequences Saying \"directly or indirectly bribing\" encompasses all democratic interaction. I indirectly bribe my electeds with votes when they do what I want. You need to be more precise than that language to make a point. More pointedly, your issue is with money in politics. Not bribery, which is already illegal. Not paid lobbying, I don't think, unless we should outlaw the EFF. Not rich people per se, most of whom have the sense to shut the fuck up. reply benreesman 6 hours agorootparentI appreciate that the phrasing ‚Äúdirectly or indirectly‚Äù is a far cry from a reasonable draft of a bill. The Bipartisan Campaign Reform Act was better thought out by a long way. I was being informal given this is HN. We all know the moments in time when the public got knee-capped: Brooksley Born was highly on task preventing 2008 via her completely legitimate powers via the CFTC before Summers and Greenspan popped a cap in her ass. The same is about to happen to Gary Gensler and worse Lina Khan. This capture is a wratchet until it isn‚Äôt. And the Robespierre interlude is something we all hope to avoid. You sir are clearly educated and astute and traveled, a cut above by far the typical HN apologist for contemporary Friedman shit. If even you are willing to argue to the bitter end then I‚Äôm very sad about how brutal things will soon become. reply benreesman 6 hours agorootparentThis is the status quo. The fifth unit in Thiel‚Äôs Stanford startup lectures was titled ‚ÄúCompetition is for losers‚Äù. There‚Äôs a reason these assholes are building compounds in rural New Zealand. https://youtu.be/zI7hbEuopLI?si=iyZwEcScazFmMJzZ reply g-b-r 14 hours agoparentprev\"cautionary\", \"real life vs\", \"Nothing is more difficult or dangerous\", \"exist purely in that imagination\". You're claiming that real life is always as in this episode; and so, I guess, that you should never oppose someone at an higher position? Or with more power? It's healthy to be aware of the possibility that things could go this way, but it's definitely not a guarantee that they will; in some environments it's more likely to happen, in others more likely to not happen. But if we always acted as selfish cynics, then yeah, real life would be guaranteed to be what you describe reply medo-bear 14 hours agoparentprevhow about not being a coward being enough of a reason to stand up for what you believe in. no where is it written that being brave entails success. sometimes though it is said that success entails being brave reply AndrewKemendo 16 hours agoparentprevI mean can you offer any suggestions as to solutions to get out of this situation? Feels intractable reply simpaticoder 15 hours agorootparentCreative idealists tend to abstract away the social politics of power and are often suprised by the result of their actions. They do not have enough fear of others and what they are capable of. The response is not only a personal surprise, but an epistemological shock. The solution is to remain aware of the reality of your situation. This is particularly difficult for thinkers and dreamers because their attention is often elsewhere; but one must make the effort or bad abstraction will hit you like a freight train. The other solution is to ally yourself with other less pragmatic principled idealists such that you can help them assess the situation and take mutually beneficial action. One must understand the battle to come, you must feel the fear of failure and the possibility of success. The worst thing you can do is be unaware of the game entirely, or be aware and disdain it, and so play it like a fool. Finally, if you are extremely talented and recognized for it, the de facto situation is that you acquire advocates to play the game for you. But this is a rare position, and not without its drawbacks. reply peetle 16 hours agorootparentprevThe right answer for most people is to simply leave and pursue their ideals in a more favorable venue. reply thimkerbell 15 hours agorootparentHow could that more favorable venue be made, and have been made visible to him and to people like him? reply yoyohello13 16 hours agorootparentprevIt‚Äôs been the way of society since pre-history. Finding a solution would probably bring about utopia. reply danlugo92 16 hours agoparentprevnext [4 more] [flagged] dang 16 hours agorootparentEschew flamebait. Avoid generic tangents. https://news.ycombinator.com/newsguidelines.html reply s5300 16 hours agorootparentdang do you normally edit w/o leaving history of it? feels like this is the first time i‚Äôve noticed. reply dang 16 hours agorootparentI'm not punctilious about it; I usually add \"Edit:\" if the information materially changes the meaning of the comment. (https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...) In the case of the GP I changed my wording to be softer and refer directly to the site guidelines. (Originally it said \"Please don't take HN threads on political flamewar tangents. Nothing good's going to come of it, whichever way you lean.\") reply patrickhogan1 16 hours agoprevThis story really hits home for me. My dad was a physics teacher, and these complaints sound all too familiar‚Äîespecially this part: \"I did what the University told me to do, and then these administrators ruined my life for it.\" It‚Äôs frustrating how often dedicated educators are forced to navigate politics instead of focusing on teaching. The best educators are usually the least political, while those who thrive in politics often end up as administrators. reply SoftTalker 15 hours agoparentWorkplace HR ‚Äúethics‚Äù or ‚Äúwhistleblower‚Äù policies and processes are set up to protect the organization, not the person making the complaint. It‚Äôs you against the power structure in these situations, so you better have all your ducks in a row. Consulting with a very trusted advisor or attorney is probably a good idea. reply dmix 15 hours agoparentprev> The best educators are usually the least political, while those who thrive in politics often end up as administrators. The lady he accused of ethics violations was named Dept Head around the same time he made the complaint. An \"old head\" raising an issue against a new rising star... reply complexworld 15 hours agorootparentMy Dad was a university professor in mathematics. He loved his field! But the math department he worked in was taken over by someone who loved playing politics and maintaining power by playing favorites. My Dad refused to kiss the ring, and paid the price for that in his career advancement. He had tenure so it was never as bad as what happened to Marshal Brain. Now we have n == 2, this could be a pattern. Of course it's a similar situation outside of academia too. reply m463 9 hours agoparentprevI think university politics is just horrendous. I don't know the factors that lead to it though. Meanwhile in the business world, I think market forces tend to balance a lot of this stuff out. reply addcn 16 hours agoprevI met Marshall a few times. He was a good teacher and someone who had a positive impact on several successive classes of students who wanted to start companies and build meaningful products + technologies on that campus. And I trust (quite a bit) that whatever he brought to light should be followed up on - if no other reason than to respect his memory. I hope it is taken seriously and those who retaliated find themselves w/o their positions of responsibility and power over other faculty. reply RachelF 15 hours agoparenthowstuffworks.com in the 1990's was an amazing website I just went to it and had a look. Turned to junk now by the looks of things. reply panoply220 14 hours agorootparentHere‚Äôs a fun story about HSW and Marshall in the 90s https://www.linkedin.com/posts/kpwebb_like-scot-wingo-ive-sp... reply wyldfire 17 hours agoprev> ‚ÄúMy career has been destroyed by multiple administrators at NCSU who united together and completely ignored the EthicsPoint System and its promises to employees,‚Äù Brain wrote. Well, lesson learned. Take your ethical concerns to the public/press instead. The retaliation would be just as swift as it is with The Process. Or: abandon ship and leave the system to consume itself. reply dmix 15 hours agoparentHe probably cared more about losing a job he loved, the startup community he was fostering in NC, and his https://ecoprt.com/ project than about publicly fighting a battle over a minor ethical complaint about a shady hire... at least in the early days before it snowballed. reply emmelaich 16 hours agoparentprev> lesson learned I get your (good) point but it could be better put considering he's dead. reply wyldfire 4 hours agorootparentThis is a lesson that everyone at this university just learned. Maybe it's even a lesson for other workplaces with similar reporting programs too. reply JumpCrisscross 15 hours agoparentprev> Take your ethical concerns to the public/press instead Or at least above the heads of the people who are fucking around. Press might be seen as vindictive. But a sharp letter to the trustees of the university, possibly even some political offices, would not be out of place. reply eitally 15 hours agoprevI received my engineering masters from NC State, but not this department (I was in the Industrial & Systems Eng. dept, in the IMSE program: https://imsei.ncsu.edu/). That said, my program was intentionally broad & flexible because students seeking higher ed in manufacturing engineering might be EEs, MEs, CS undergrads, or something entirely different and could be pursuing any sort of leadership role in a manufacturing environment. Because of that, the program often referred students to Brain's program, and it was always common knowledge that one of the bigger differentiators at NCSU's engineering school was the focus on entrepreneurialism (especially compared to most other regional unis in the southeast, except perhaps GATech and maybe UFlorida). Even if the loss of Brain and/or the scandal around the circumstances seem fairly inconsequential to most of you, it's a big deal for NC State's engineering program and the students there. It's also likely going to be a big deal for large donors like John Sall (co-founder of the SAS Institute, which is HQ'd in Raleigh). reply walterbell 11 hours agoparentOther funders too. 2022, https://ece.ncsu.edu/2022/misra-named-to-darpa-microsystems-... & https://ece.ncsu.edu/2022/veena-misra-awarded-alexander-quar... > (DARPA) has named Dr. Veena Misra to the Microsystems Exploratory Council (MEC) for a three-year term.. total funding with Misra either as a PI or a mission-critical Co-PI exceeds $59 million. 2023, https://ece.ncsu.edu/2023/department-head-dan-stancil-to-ste... & https://engr.ncsu.edu/news/2024/05/10/misra-named-head-of-de... > After 14 years of outstanding leadership as head of our Department of Electrical and Computer Engineering (ECE), Dan Stancil will be stepping down from his position.. Veena Misra.. named Interim Head.. [May 2024] Veena Misra has been named as the permanent head of the Department of Electrical and Computer Engineering (ECE) at North Carolina State University. reply flocciput 14 hours agoprevLots of people in this thread alluding to similar experiences \"speaking truth to power\" or \"failing to read a room\" or \"not playing politics\" and suffering the fallout from it. But as someone at the start of their career I'm kind of interested in the specifics--what kinds of ethical concerns? What forms of retaliation? Everyone's being pointedly vague and I guess that's necessary to an extent to preserve internet anonymity (or maintain a reputation, if your professional work is tied to your HN account) but it is frustrating as someone trying to figure out how to \"read the room.\" reply xyzzy123 10 hours agoparentCommon patterns of behaviour are: 1. Generalised nepotism: heads-of favouring their buddies / installing crony networks, hiring/promoting only people of certain races or ethnic backgrounds, influencing supplier relationships for their own benefit (controlled by their family / friends / network), etc. 2. Toxic personality / power / ego and the political games, bullying and power plays that go along with that (to the detriment of the organisation). 3. Dangerous levels of incompetence (from the perspective of their reports), when people who shouldn't be allowed to operate a stapler are put in charge of major business units. Often everyone is fine with this if they don't touch anything, it only becomes a problem when they are influenced to make sweeping changes. Sometimes you get the whole package in 1 person. Of course, one person's nepotistic incompetent bully is another person's charming and shrewd nephew. Usually they got into their position through the strength of their network(s) so if you go at them you're likely to have a bad day. reply mu53 10 hours agoparentprevNever criticize anything. Do your best to blend into walls. Let other speak up and support them. \"48 laws of power\" is a book that everyone should read to understand politics. Its all ego and narcissism. reply salawat 10 hours agoparentprev>Everyone's being pointedly vague and I guess that's necessary to an extent to preserve internet anonymity (or maintain a reputation, if your professional work is tied to your HN account) but it is frustrating as someone trying to figure out how to \"read the room.\" Allpw me to possibly explain a bit about why there is a degree of cagey-ness/intentional vagueness. A lot of the startup world focuses around exploiting opportunities where there are profits to be realized in areas of mercantile endeavor that can ne in a bit of a grey zone, as it were. Areas the big boys won't touch because it's too risky, but that can have a large payoff with just a relatively small infusion of capital. So when you're talking a lot of these places, there is certainly room for a bait-n-switch to occur. Circumstances may be wildly different from instance to instance; but in general the same threads and warning signs are there. Going into specific details, as you point out, is a great way to out yourself. Sometimes it's just enough to tell someone to look hard, and generally with the prompting they'll figure it out. Now as far as reading the room goes... The sapd truth is this. If you didn't fund raise, you ultimately don't get to call the shots. Just how it works. Now it's best to listen to the folks you hire; don't get me wrong, but in most cases, an org does everything it can to make sure it is only steered from the top down by edict. It's not perfectly so, and there are ways to manage up (techniques no one who knows em is going to discuss in public), but at the end of the day, with power concentrated in the guy at the top, it comes down to how much trust you confer unto that person as a human being. If you're bringing up an ethics concern, and you're pretty sure it's not going to be taken well, or you've seen it ignored... Well... Adjust your trust levels accordingly. reply xeeeeeeeeeeenu 17 hours agoprevThe website is geoblocked in the EU. Mirror: https://archive.ph/R39hz reply mijoharas 15 hours agoparentOne thing I wonder: It says it's geoblocked because of GDPR. Have they geoblocked California too because of the CCPA? reply eitally 15 hours agorootparentNo. I am able to read it from California. reply stego-tech 17 hours agoprev> Kashani said Brain submitted numerous complaints through the EthicsPoint system and said tensions arose because Brain didn‚Äôt ‚Äúplay the political game‚Äù through his questioning of higher-ranking administrators. This right here is why I scoff at ‚Äúanonymous reporting systems‚Äù or stuff like EthicsPoint, for the simple reason that the only ethics that ultimately matter in an organization are those of everyone above you, and those individuals have a vested interest in preserving their political capital over acting or behaving ethically. It‚Äôs disgusting and reprehensible if true, but it‚Äôs sadly not surprising. Those of us who behave ethically are little more than prey to those whose moral compasses are fungible. reply dreamcompiler 15 hours agoparentOrganizations create these reporting systems to make themselves look good to outsiders, but they will punish you severely if you actually try to use them. It's kind of like your grandmother's good china: Look at it all you want but don't you dare use it. Stuff like this is incredibly confusing to people on the autism spectrum. reply stego-tech 15 hours agorootparent> Stuff like this is incredibly confusing to people on the autism spectrum. Upvoted for this alone. We thrive in clearly defined systems, but the powers that be are careful to hide the actual systems of power from us. It‚Äôs infuriating to find out we‚Äôve been playing the wrong ‚Äúgame‚Äù. reply permo-w 14 hours agorootparentprevThese systems must be used in conjunction with public media. reply dmix 15 hours agoparentprevIt doesn't sound like the process was anonymous, as it implies she found out it was him pretty quickly and worked to close ranks against him. Kinda defeats the purpose but I guess in any small organization it's probably easy to figure out who it is. reply dreamcompiler 15 hours agorootparentThere's no such thing as an anonymous reporting system in a company that owns the reporting infrastructure. Some companies contract out such systems to a third party to reinforce the illusion of anonymity. But what do you think happens when the CEO says to the contractor \"Tell me who wrote this or we won't hire you again\"? reply runnr_az 16 hours agoprevSounds like there‚Äôs a lot more to this story‚Ä¶ reply BJones12 17 hours agoprev> Brain‚Äôs complaint contained allegations of wrongdoing... regarding repurposing the Engineering Entrepreneurs Program meeting space to accommodate a new hire.. ‚ÄúWhat came back was a sickening nuclear bomb of retaliation the likes of which could not be believed‚Äù \"Academic politics is the most vicious and bitter form of politics, because the stakes are so low.\" - https://en.wikipedia.org/wiki/Sayre's_law reply Clubber 15 hours agoparentThis is funny because it's so accurate. I worked a year or two in college doing IT support for the College of Business in my final years of school. The prior boss who had actual experience in running IT departments was run out (fired) and replaced by an economics professor who had no idea what he was doing. The economics professor lead the charge in running out his predecessor. I don't know the reason but it was pretty ugly and everyone in IT support had zero respect for the economics professor. I came in after the fact so I had no skin in that game. As an aside, every professor got a brand new $4000 Dell every year because if the college didn't spend its budget, it would get less money the next year. Most of these professors just used Office to do their lesson plans and that's it. This was in the 1990s and it was a huge waste of money. I would imagine it's much worse now. That probably had something to do with it. I recently read a quote that paraphrased went like, \"bureaucracies care about following procedure over outcomes.\" I hope US universities get fixed. Their current state is a great disservice to the future of the country. reply angled 16 hours agoparentprevMy thoughts exactly. It was all about campus real estate! A room with a view. reply dgfitz 14 hours agorootparentI don‚Äôt understand how it escalated to this? reply knowitnone 16 hours agoprevsounds like typical high school bullying except by adults and so-called professionals. how does a disagreement between two turn into multiple departments jumping in for one side? reply fracus 14 hours agoparentI wish he took more time to heal emotionally. He might have seen this was not a place he wanted to work. reply SuperNinKenDo 13 hours agorootparentI've been in two situations like this where I eventually \"WON\". You don't simply heal. You don't accept that that just wasn't the place for you and move on. What you do is have your perspective on other humans permanently and irrevocably changed. If you are a certain kind of person who values truth and personal responsibility, you come to understand that the world is fundamentally incompatible with you, and are faced with the choice of living a meaningful life where you are constantly preyed upon and abused, or living a meaningless existence in which you betray everything you ever valued about yourself. reply fracus 11 hours agorootparent\"If you are a certain kind of person who values truth and personal responsibility, you come to understand that the world is fundamentally incompatible with you\" This logic is flawed in that you are assuming no one else shares the same values as you do. reply selimthegrim 9 hours agorootparentAnd how long have you spent in academia? What do you think research universities produce at scale to keep their Carnegie category? reply greenavocado 15 hours agoparentprevNepotism is a well documented phenomenon reply acjohnson55 14 hours agoprevThis is so sad. HowStuffWorks had a huge impact on me as a teenager. reply magic_smoke_ee 4 hours agoprevI consulted at a Stanford biomedical department that openly used age discrimination to displace older full-time employees. They also were biased in hiring researchers and staff who tended to be of the same ethnicity and characteristics as PIs, and they abused part-time workers for years to deny them benefits, organization-wide. reply gdjskshh 16 hours agoprevIt's sad to see a group of engineering professors having political squabbles involving unethical behavior in response to an ethics complaint. Ethics are supposed to be a core part of engineering, not too dissimilar from medicine. Good thing those folks are in academia where they can't hurt the rest of us. reply fwipsy 16 hours agoparentOn the contrary, in academia they can do lots of damage by encouraging the same behavior in new engineers. reply Onavo 15 hours agoparentprevEngineering ethics is completely different from classroom ethics. Engineering ethics is all about compliance. If you build a missile to kill people, you better make sure it works as described. Who it kills is none of your business but if it doesn't work as described then it's a breach of \"engineering ethics\". It's funny when people on HN call for the \"professionalisation\" of software engineering. The only person who benefits is management who will happily throw the poor engineers under the bus the moment a self driving car hits somebody. Hold the entire organization responsible, starting from the top, not the lowly engineer. reply thimkerbell 15 hours agoprevIs there anyone here on HN who has non-news-article knowledge of what the situation was, around him, at NCSU? reply Animats 15 hours agoprevWas he murdered? reply jim-jim-jim 16 hours agoprevWonder if he ever read Stoner. reply blindriver 15 hours agoprevMy son wants to be a mathematician. I told him never go into academia because it's a pit of poisonous vipers, administrators and professors both. I'm going to send him this article to hopefully re-indoctrinate him in case he forgot my previous message. reply KPGv2 11 hours agoparentWould you consider sending him the seemingly thousands of academics who aren't poisonous vipers who are quite happy to be in academia? reply StableAlkyne 17 hours agoprevI don't know why so many people want to go into academia these days. Tenure is a multi-year rat race with worse hours than a seed stage startup (to be fair to the startup, at least you have feedback in the form of sales and VC fundraising). The pay is bad and the politics are incredibly petty. Tick off the wrong person and your career is torched. reply vrosas 16 hours agoparentHaving worked with some ex-academia people I can feel this. They often seem to bring that bitterness (and in all honesty a certain level of masochism) with them to the workplace even after escaping. reply wellthisisgreat 14 hours agoprevReading the names of people who targeted him it seems like a case of cronyism in academia reply greenavocado 15 hours agoprevLink to ethics complaints? reply aithrowawaycomm 16 hours agoprevThe article suggests he was let go for \"submitting numerous ethical complaints\" but it is utterly unclear to me what these ethical complaints could have possibly been about, and the only source in this article is a starry-eyed protege. I am wondering if Brain was (perhaps unintentionally) abusing the complaint system as a way of adjudicating political disputes: \"this person is stubborn and wrong\" elevates to \"this person is behaving unethically.\" My suspicion is that the numerous ethical complaints evidenced a pattern of unstable behavior. I don't like speaking ill of the recently deceased. But I also don't like jumping into conspiracy theories based on platitudes about \"the system,\" when there are more obvious explanations: his last email is a work of unhinged paranoia and resentment, not truth-telling in the face of oppression. It is obvious that Brain was mentally unwell in his last few hours; I wonder how long that was going on. reply foul 10 hours agoparentEvery character in this story used mostly internal tools plus I don't know the rules in NCSU, but the reactions around his issues look like weirdly huge. \"Retired\" at 63? reply kbelder 11 hours agoparentprevThat was my immediate takeaway as well, although it's important to remember that we don't have any certainty either way. reply mistercheph 15 hours agoparentprevThere is a stark divide emerging between the sorts of people that in my view speak truth to power, even if they speak poorly or strangely or are entirely unable to read the room, and the kinds of people that have internalized the ideology that nothing is wrong and anyone that complains, especially more than once, is most likely mentally unstable, paranoid, delusional, and so on. reply mongol 14 hours agoprevThe site doesn't let me in because of GDPR. reply readthenotes1 12 hours agoprev\" 451: Unavailable due to legal reasons We recognize you are attempting to access this website from a country belonging to the European Economic Area (EEA) including the EU which enforces the General Data Protection Regulation (GDPR) and therefore access cannot be granted at this time. For any issues, contact technician-editor@ncsu.edu or call 919-515-2411. \" Must be a skeevy website to just rather not have me than not spy on me reply gnabgib 18 hours agoprev [‚Äì] Related Marshall Brain has died (322 points, 2 days ago, 157 points) https://news.ycombinator.com/item?id=42228759 reply HappyKasper 18 hours agoparentYes - at that time, the ethics complaint and retaliation allegations weren't public yet. This new article adds a lot to the story. reply tedunangst 17 hours agoparentprevPrevious submission link is dead, too. After two days. reply neonate 16 hours agorootparenthttps://web.archive.org/web/20241124180243/https://www.wral.... reply walterbell 11 hours agorootparentWRAL TV deleted both their web page and Youtube video clip? Supposedly the video transcript quoted a student saying that it was the second shooting on campus that night. Did WRAL have an update on the story? reply khazhoux 16 hours agorootparentprevIt disappeared from HN front page within a couple of hours, even with over 150 points, and I couldn't find it again in first 5 pages before I gave up. HN ranking algo is really weird that way. You'd expect things to slide downwards, but they just teleport to page 10 or whatever. reply dang 16 hours agorootparenthttps://news.ycombinator.com/item?id=42228759 spent 9 hours on HN's front page. The reasons why posts drop in rank are explained at https://news.ycombinator.com/newsfaq.html. reply Terr_ 17 hours agoparentprev [‚Äì] That's weird, the link to wral.com now redirects to 404 page. reply genter 17 hours agorootparent [‚Äì] From what I remember, it didn't say much. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NC State professor Marshall Brain, founder of HowStuffWorks.com, was found deceased in his office on November 20, after alleging retaliation from university officials.",
      "Brain claimed he was forced into retirement following ethics complaints, but the university has not commented on these allegations or his death.",
      "Former students and colleagues have expressed disappointment over the university's silence, highlighting the ongoing nature of this developing story."
    ],
    "commentSummary": [
      "Marshall Brain, a former professor at NC State, passed away after claiming retaliation from university administrators due to his ethical complaints.",
      "His case underscores the tension between idealism and reality, illustrating the potential dangers of holding those in power accountable.",
      "The incident prompts discussions on the effectiveness of internal reporting systems and the broader power dynamics within academic institutions."
    ],
    "points": 207,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1732667471
  },
  {
    "id": 42253241,
    "title": "Janet for Mortals (2023)",
    "originLink": "https://ianthehenry.com/posts/janet-for-mortals/",
    "originBody": "April 4, 2023 Janet for Mortals I wrote a book. It‚Äôs called Janet for Mortals, and it‚Äôs free, and it‚Äôs on the internet, and you can read it right now. And you should read it right now, instead of reading this blog post, because this blog post is not very interesting if you haven‚Äôt read the book. Heck, this blog post is not very interesting even if you have read the book. This blog post is a thinly-veiled promotion for my book to slip into my newsletter and RSS feed, with just enough additional content to pad it out to the length of a real post. The book is about Janet, a programming language that I have written about before. I‚Äôve been using Janet a lot lately, and I‚Äôve been having a lot of fun with it, and I think that more people should know about it so that they can have fun with it too. People like you. I‚Äôm not really going to talk much about why you should read the book, or even why you should care about Janet in the first place ‚Äì that will come in a later post. Instead, this is going to be a short retrospective of what it was like to write my first technical book. We‚Äôll start with some numbers. It took me twenty weeks to write the book, working in my spare time. I had originally estimated twelve weeks, which turned out to be a really good guess for how long I spent writing the book, but I didn‚Äôt account for how much time I would spend working on book-adjacent coding side quests. The final book is pretty short: 44k words of English prose, if you don‚Äôt count any of the code snippets. I tried to find an example of a famous book with a similar word count to put that number in perspective, and the best I can do is The Great Gatsby, which clocks in at 47k words. It‚Äôs right on the border between novella- and novel-length, but it‚Äôs less than half as long as my series of posts about Nix, which is sort of terrifying. But writing English words was only a fraction of the work. Over the course of those five months, I also spent a lot of time on: the website itself jimmy, bindings to a C++ library of persistent data structures Toodle.Studio, an interactive turtle graphics playground cmd, a command-line argument parsing library judge, an inline snapshot testing framework to do, a command-line todo list manager These things are not very interesting by themselves, but this blog post just exists to promote the book, so I‚Äôm going to reflect on them now. You are welcome to stop reading at any point and go read the actual book instead. The Website (2 weeks) The most interesting thing about Janet for Mortals is that it has a built-in repl. At any point you can press escape and pull it up, and it‚Äôs docked to the bottom of the page, just out of the way of the text. I‚Äôm sure that it‚Äôs not the first programming book to include a repl like this, but I‚Äôve never actually seen it done before. The editor portion of the repl is CodeMirror, which I had used previously in Bauble. CodeMirror doesn‚Äôt know anything about Janet out of the box, but I had already implemented some basic language support when I wrote Bauble. But I skipped a lot of the Janet language when I was writing the grammar for Bauble, like ``multi`backtick`quoted`` strings, because they didn‚Äôt really matter in Bauble‚Äôs constrained DSL. But they mattered for the book, so I had to spend time figuring out how to implement them. But fleshing out the CodeMirror grammar (or more precisely, the Lezer grammar that CodeMirror uses) had an unexpected side effect: it let me re-use the grammar to do syntax highlighting for the code snippets in the book itself. Janet for Mortals is just a static site, but no static site generators that I know of know how to highlight Janet code. For a long time the book was entirely black-and-white, which I don‚Äôt mind, but I knew I needed to add some color before I released it upon an unsuspecting public ‚Äì I think Janet‚Äôs syntax is pretty unfamiliar to most people reading the book, and anything to make it look friendlier helps. So I knew that I‚Äôd have to roll my own syntax highlighter of some kind, and I ended up just writing a simple static site generator in redo, which was not a very good fit, but‚Ä¶ well, least bad choice that I know of. The meat of the generator is written in JavaScript, so that I could plug in the Lezer grammar for free, but it‚Äôs all tied together by a fragile web of shell. I used Remark to implement the parsing of the book‚Äôs source, and it was nice how much control I had over the generated output. I even added a simple extension to label code blocks, which was pretty easy. I also re-used Remark in the client itself, as part of the repl. The docstrings in the Janet standard library are written in Markdown, and I‚Äôm actually parsing and rendering them to HTML on the fly as part of the repl autocomplete. I spent a long time getting the repl autocomplete working well ‚Äì because this book was written for newcomers to the Janet language, I thought that the help-as-you-type would be really useful for people trying to follow along in the repl. Autocomplete works by dynamically querying the Janet environment via WebAssembly at repl startup. This means if you define a new symbol with a docstring, it won‚Äôt actually appear in the autocomplete output, but I think that‚Äôs‚Ä¶ fine. I could re-generate the autocompletions after every command is run, but‚Ä¶ I don‚Äôt think there‚Äôs much value in that. The most interesting part of the repl is probably the (report) function, which takes a string and POSTs it to a simple web server that sticks it into a SQLite database for me to peruse later. It‚Äôs not really any different than a comment box, but I feel like there‚Äôs something fun about doing it from the repl. I‚Äôm really glad that I added it ‚Äì it‚Äôs been fun reading people‚Äôs feedback, and I‚Äôve fixed quite a few errors because of it. I‚Äôm sad that I didn‚Äôt implement any way to respond, though! The backend for reports is not written in Janet; it‚Äôs a tiny Haskell application that just listens for POST requests and sticks them into a SQLite database. There are people using Janet to make websites, but I am not one of them: the primary thing I want out of a web server is security, and I just don‚Äôt think Janet or its HTTP libraries are ‚Äúbattle-tested‚Äù enough for me to connect them to the internet. I also just think the idea of using a dynamically-typed interpreted language to build a web service is crazy, when there are optimizing compilers right there, but that‚Äôs a whole other conversation. jimmy (1 week) I spent a little bit of time writing bindings to immer, a library of persistent data structures. I never finished them, and probably won‚Äôt, at least not until I have a use for them. But as a demonstration of how to interop with C++ code from Janet, I think it was successful. https://toodle.studio (2 weeks) Last year I wrote a little art playground called Bauble. It was my first time embedding Janet in the browser, and I had a pretty tough time figuring out how to do that. There weren‚Äôt a lot of resources back then about embedding Janet period, and doing it in the browser added an extra layer of difficulty. I‚Äôd never used WebAssembly or Emscripten before, or even TypeScript, and it turns out there are no tutorials on how to write TypeScript Emscripten WebAssembly Janet bindings, so I spent a while figuring out how all the pieces worked together. And I‚Äôm glad I did, because I think the final product is really neat: it‚Äôs a website that is not written in JavaScript. I mean, a lot of it is. The UI is, still. But the actual application logic is all Janet. I thought that that was a really useful superpower of Janet, and I wanted to make the technique more accessible. In fact this was a big motivation for writing this book about Janet ‚Äì I wanted people to know that this was possible in the first place, and I wanted to make it easier to get started with it. But Janet for Mortals doesn‚Äôt talk about Bauble at all. Bauble is actually not very interesting from an interop perspective: Bauble is completely stateless, and basically uses Janet to implement a pure function from strings to strings (they‚Äôre‚Ä¶ pretty complicated strings; Bauble is a Janet-to-GLSL compiler, but they are strings nonetheless). I didn‚Äôt think it was a very good showcase for everything you can do with Janet, so I briefly considered talking about how I implemented the repl in the book, but I decided that that was far too boring. So I wrote Toodle.Studio ‚Äì an obvious fork of Bauble ‚Äì instead. Toodle.Studio seems a lot simpler than Bauble, but the interop with JavaScript is much more involved. Toodle.Studio has to execute long-running Janet programs asynchronously over time. It has to think about memory management, as the JavaScript code retains multiple references to the same Janet values. It has to pass complex nested data structures to and from Janet, going through C++ as an intermediary. It does a very simple version of all of these things, but it‚Äôs a pretty good showcase for the techniques. But the most interesting part of Toodle.Studio isn‚Äôt the interop or the memory management. The most interesting part of Toodle.Studio is the logo. I wasn‚Äôt really planning on making a logo ‚Äì this is a demo project for a book, after all ‚Äì but sadly I had no choice. When I was getting ready to release the website, I showed it to my partner, because it‚Äôs rare that I work on something comprehensible to normal human beings. I thought she‚Äôd like it, but she was aghast. ‚ÄúYou said you were working on turtle graphics,‚Äù she said. ‚ÄúWhere are the turtles?‚Äù I tried to explain that the turtles aren‚Äôt really turtles, that it‚Äôs like a flea circus, and the turtles are metaphors ‚Äì but she was having none of it. The lack of turtles was a base betrayal, so I had to spend a day or so modeling a cute animated turtle in Bauble to act as the logo. And making its eyes follow the mouse, of course. Relationship repaired. The logo wound up being my favorite part of the site, and it was fun to get a chance to use Bauble to make something ‚Äúreal.‚Äù cmd (2 weeks) One of the things that I spent the most time on, oddly enough, was a command-line argument parsing library. The library itself only gets, like, three paragraphs of screen time in the book, but it was very important to me that it exist before the book came out, so that I could unambiguously claim that ‚ÄúJanet is an excellent scripting language.‚Äù Before cmd, that was still true, but the phrasing was more ‚ÄúJanet is a great choice for scripting and writing CLI tools, except that the argument parsing is kind of janky, sorry, but hey at least it‚Äôs better than Bash.‚Äù cmd was heavily inspired by Core.Command, which is the best command-line argument parsing library that I have ever used. I‚Äôm extremely spoiled by how easy it makes writing CLIs, and I wanted to replicate that experience in Janet. cmd is definitely not as good as Core.Command ‚Äì types, my goodness, types make everything so much easier ‚Äì but it has 95% of the features I care about, and the concise notation makes it more pleasant to use in ad-hoc scripts. One thing that I miss, though, is that Core.Command autogenerates Bash completion functions. I want to add that to cmd one day ‚Äì the API is designed so that that will be possible to do. But‚Ä¶ so many projects, so little time. judge (1 week) judge was one of the first things that I wrote in Janet, all the way back in 2021. I think that it worked pretty well considering that I didn‚Äôt know anything about Janet when I wrote it, but now I do, so I rewrote it from scratch. Not only is the API much nicer to use now, but the implementation is way simpler ‚Äì and easier to make changes to. The main differences between Judge v1 and Judge v2 are that tests can now appear inside regular source files, not just the test/ directory, and I added the test-macro and test-stdout helpers, which are extremely useful. The OCaml equivalent of test-stdout is pretty much the only way that I write tests professionally, because OCaml doesn‚Äôt really have a way to embed arbitrary data in source code, so we turn everything into a string. After publishing the book ‚Äì which has a whole chapter on testing with Judge ‚Äì I had a chance to spend a little more time improving Judge, and I finally added an --interactive mode, which I‚Äôve been wanting for a long time. And since I‚Äôm not spending all my time working on this book anymore, I‚Äôve actually had a few opportunities to use the new Judge, and I gotta say: it‚Äôs nice. It‚Äôs really nice. I know I can‚Äôt impress upon you just how nice it is in this post ‚Äì it really needs a demo, and I‚Äôm too lazy to record one right now ‚Äì but I‚Äôm very happy with how it feels to use it to write Janet. to do (2 hours) I picked this project to highlight for the scripting chapter, because it‚Äôs a non-trivial thing that I had done in Bash before, and actually found it pretty painful. Parsing multi-line text with Sed is not fun, and trying to do date manipulation with date in a way that works the same on macOS and Linux is‚Ä¶ basically impossible, as far as I can tell. I quickly ran into the limits of my patience, and gave up on the idea some years ago. It was really fun to return to this with the full power of PEGs and sh and cmd at my disposal. I immediately surpassed all of features of my original Bash todo list, and was able to add quite a few more (like fzf multi-select ‚Äì good luck constructing null-terminated strings in Bash). The book covers a very simplified version of the app ‚Äì it can‚Äôt schedule tasks for the future, and there‚Äôs no concept of ‚Äúskipping‚Äù tasks. Those features are important for my todo list workflow, but they are probably not important for your todo list workflow, so the book only discusses the core functionality of adding things to a list and crossing them off. I think that it makes a good starting point to run with and make your own ‚Äì paired with zsh-autoquoter, it‚Äôs actually a surprisingly useful app! If you put all of these projects together, I was writing code for almost half the time that I spent working on the book. Eight out of twenty weeks, plus some periods where I was doing both at once. I didn‚Äôt really budget for that going into this. I thought that I‚Äôd improve Judge, and I thought that I‚Äôd write an argument parser. But I thought that writing an argument parser would be way easier than it actually was. And I thought that I‚Äôd just talk about Bauble ‚Äì it never occurred to me that I‚Äôd write another art playground just because Bauble was too easy. So that‚Äôs the story of writing the book. Or really, everything but writing the book. All the other things. The writing itself isn‚Äôt that interesting. I wrote it in Markdown, in Sublime Text, which is my favorite editor for writing long-form prose. I have nothing interesting to say about that part. Two new versions of Janet came out while I was writing the book, and I did have to go back and update the chapters on debugging and native modules to keep up with changes to the language. I plan on keeping the book up to date with the latest Janet release ‚Äì we‚Äôll see how long I can keep that up. I haven‚Äôt done much to promote the book yet. I submitted it to Hacker News, and I submitted it to Lobsters, and I wrote a very half-hearted tweet about it. The reception was pretty much as good as I could have hoped for: it was on the Hacker News front page all day, and even held the number one spot for a while. What does that actually mean? Well, according my Nginx access logs, I got: 30,025 unique visitors on Friday 9,568 unique visitors on Saturday 3,777 unique visitors on Sunday Those numbers don‚Äôt mean very much, though. Those are just people who clicked on a link ‚Äì the number of people who actually read the book is much, much smaller. I don‚Äôt actually know how much smaller exactly, because I don‚Äôt have any client-side behavior-tracking analytics on the site. But I can sort of try to guess, by looking at my access logs. It seems like retention is not great: Chapter One had 22% as many visitors as the home page. Chapter Two had 20% as many visitors as Chapter One. Chapter Three had 69% as many visitors as Chapter Two. Chapters Four and Nine, ‚ÄúPegular Expressions‚Äù and ‚ÄúXenofunctions,‚Äù had more visitors than Chapter Three. I‚Äôm guessing that last bit is because people clicked on those chapters to see what they were about, which just goes to show that unique visitor count is not a very dependable metric. My best attempt at answering the question ‚Äúhow many people are actually reading the book‚Äù is 387, as of the end of the launch weekend. So far 387 unique IP addresses have loaded five or more distinct chapters, which is probably a decent proxy for the metric I care about. I really had no expectations for what these numbers would be before I launched the book. It‚Äôs a big time commitment to read a weird book about a programming language you‚Äôve barely heard of, and 387 seems simultaneously low (compared to, say, any blog post) and high (I don‚Äôt think I‚Äôve ever read a book off a HN link). But it‚Äôs more than zero! Alright, I think that‚Äôs enough. I‚Äôll close with some fun facts: The Janet language is named after an immortal being in The Good Place who helps mortals navigate the afterlife, hence the title. The chapter with the fewest visits is currently ‚ÄúTesting and Debugging,‚Äù despite being the third-to-last chapter. This does not surprise me at all, but I think it‚Äôs a shame: the last three chapters are by far the most interesting in the book, and the style of testing described in that chapter is one of the biggest productivity upgrades that I have personally experienced in my engineering career. So far I‚Äôve received 494 reports from the built-in repl reporting feature. Most of these were of the ‚Äúhey nice book‚Äù or ‚Äútesting‚Äù variety, but I‚Äôve gotten several dozen typo reports, clarification requests, or otherwise useful comments through it as well. The most interesting report was just ‚Äúyou should listen to this song: https://www.youtube.com/watch?v=46i3LbIbbhI.‚Äù No context, no explanation, and I have no way to reply for clarification. But‚Ä¶ thanks! It‚Äôs a good song. I‚Äôm into it. A few people asked me questions without including any kind of contact info, so I have no way to answer them. I hope that they found peace, wherever they are. I‚Äôm not ignoring you. I just‚Ä¶ I only implemented an extremely primitive one-way feedback function. I‚Äôm going to plug the book one last time. With feeling: Janet for Mortals! Out now! The first infinity visitors get their copy for free!",
    "commentLink": "https://news.ycombinator.com/item?id=42253241",
    "commentBody": "Janet for Mortals (2023) (ianthehenry.com)195 points by magnio 13 hours agohidepastfavorite51 comments debo_ 5 hours agoThis is very cool: > this book contains a repl, and you can summon it whenever you‚Äôd like by pressing the escape key on your keyboard. The book will then start downloading like a megabyte of JavaScript and WebAssembly, and once it‚Äôs done you will be able to try out Janet right here in the comfort of your browser. No need to install anything; no need to leave the comfort of this book website if you‚Äôd like to test something out. > The repl is not just a repl, though. It is also a portal into conversation with me, the author. You can use the repl to report typos or factual errors, ask questions, or express confusion. I won‚Äôt be able to respond in the repl, but if you include some kind of contact information in your reports I will make an effort to follow up with you. reply sourcepluck 5 hours agoprevNot to mention https://bauble.studio/ from the same author! It doesn't work in my browser - which is understandable because my computer is ancient - but sometimes when I want a break from study in the library I'll spend thirty minutes on a library computer playing in bauble there. I might get around to trying to figure out how the thing works, but the graphics you can make just fiddling with numbers is wild. Long life to Janet. reply zellyn 3 hours agoparentFor me, on a 2021 MacBook Pro M1 Max, on MacOs 15.1.1, it appears to work in Chrome but in Firefox shows this error. error: script:16:1: compile error: unknown symbol twist in evaluate [lib/evaluator.janet] on line 81, column 7 in bauble-evaluator/evaluate [lib/init.janet] on line 8, column 12 reply ianthehenry 3 hours agorootparentdelete the contents of the script and then refresh ‚Äî you‚Äôve loaded an old version of bauble before and have the old tutorial cached in localStorage :/ reply jodrellblank 5 hours agoprev> \"the turtles are metaphors\" :( The turtles were real, not metaphorical: http://classicacorn.computinghistory.org.uk/8bit_focus/logo/... (it fits the definition of metaphor 'One thing conceived as representing another; a symbol' but it has the feel of people saying \"my niece thought the floppy disk save icon is a refrigerator because that's where you save leftover food\" not realising that it was a real piece of fun/cute hardware many moons ago). reply WJW 2 hours agoparentI don't think that what's displayed on that page is a \"real\" turtle... reply debo_ 5 hours agoprevIt's neat to compare Janet to GNU Guile. Guile's original pitch is that it's intended to be easily used side-by-side with C. However, because it's an older language, it hasn't (to my knowledge) picked up newer sensibilities like having a package manager shipped with the language toolchain. One thing I like about Guile is how much effort they've put into describing compatibility with the RNRS standards. Not sure how Schemey Janet actually is, but I'm curious to find out. reply packetlost 4 hours agoparentJanet it not Scheme-like at all. It's more like if someone made Clojure on top of Lua. reply giraffe_lady 4 hours agorootparentWhich is really funny because that's basically exactly what fennel is, which was made by the same guy. I don't think he's written about it but fennel compiles to lua while janet is its own thing. reply sourcepluck 2 hours agorootparentThis is funny, cos I saw this stated somewhere on HN the other day, was totally amazed he'd done both, went and checked, and found out it was untrue - I think! Someone correct me please if I'm confused. Calvin Rose made Janet https://github.com/bakpakin and https://bakpakin.com/ Phil Hagelberg made Fennel https://git.sr.ht/~technomancy/fennel and https://technomancy.us/colophon reply ianthehenry 2 hours agorootparentIt's complicated; Calvin Rose was the original creator of Fennel (\"fnl\"), but I understand it was just a little side project that he made over the course of a week or so in college. Phil Hagelberg found the project years later and thought it was cool, took over as its maintainer, and basically turned it into the Fennel you know today. So it's like, kind of, I dunno, both things are kinda true. reply sourcepluck 1 hour agorootparentThat's even more funny in the end, I thought GP was referring to Phil Hagelberg as creator of both, but they were referring to Calvin Rose as creator of both. Oops. Mystery solved. Anyway - Fennel and Janet look very interesting, and a large thank you to everyone involved! reply packetlost 4 hours agorootparentprevCorrect. Syntactically it's more similar to Clojure while the runtime is, to my understanding, heavily inspired by the non-JIT versions of Lua. As a language, it's fine. I found the documentation pretty good and the language makes some very sensible decisions but I can't bring myself to use it for anything serious. The lack tooling makes it challenging. reply giraffe_lady 3 hours agorootparentI have used janet for embedding into another program as an alternative to lua and it was great for that case. Lua doesn't have good tooling either, and I didn't have anything to gain from a tiny runtime and I wanted more powerful tools for making a DSL in there. It worked out perfectly, I'd do it again. reply packetlost 1 hour agorootparentYeah, I'm not saying there aren't usecases that it would excel at (sounds like you found one!), I just haven't really had a problem that I thought it would yet. I've come really close though reply threatofrain 10 hours agoprevThe book. https://janet.guide/ The language. https://janet-lang.org/ reply incanus77 11 hours agoprevI enjoyed this book‚Äôs practical take. It‚Äôs a big part of why I am currently learning Janet by doing Everybody Codes in it right now. https://everybody.codes reply riggsdk 9 hours agoprevThe title made me believe it was just another AI assistant (thinking Janet from \"The Good Place\" - but for us non-dead people instead. Was pleasantly surprised to see it is a programming language and that the title was just a clever joke on that: The Janet language is named after an immortal being in The Good Place who helps mortals navigate the afterlife, hence the title. It kinda surprised me that they ship the language with a PEG (parsing expression grammer) instead of a basic Regex engine. This has been my wish for any programming language that ships a Regex library by default to also include a capable PEG. reply tmtvl 7 hours agoparentGNU Guile also has a PEG library in its standard library (see ). reply petee 6 hours agoparentprevJanet's 'spork' module is kinda like their libc, and has a regex submodule; it's very likely to be installed. Janet is my first exposure to PEGs, so nothing to compare against but I love how powerful and easy they are. I have a better grasp of them in only a few months than dabbling over 20yrs with regex. Also there is quite a bit of The Good Place callbacks within the Janet community; numerous 3rd party modules are named after characters, for example. reply philsnow 1 hour agorootparentI had also not seen PEGs before, but the way you can use parsing node identifiers recursively (and mutually recursively) seems very intuitive. reply tessierashpool 4 hours agoparentprevElm does something similr. Neither elm/regex nor elm/parser are built-in, but elm/regex encourages you to use elm/parser instead. btw, I like the namesake, but a language named Janet is pretty much obligated to also prioritize control. reply prokopton 6 hours agoprevI‚Äôm holding out for the one written for immortals. reply numeromancer 3 hours agoparentI am not waiting for Janet for Ethereals. Once it ships, it will always have been available. reply petee 6 hours agoparentprevMeanwhile I'm waiting on \"Janet for Normies\" for myself reply sourcepluck 5 hours agorootparentOoooh, is this the start of a series - who's going to do those two, and then \"Janet for Aliens\", \"Janet for the Rest of Us\", \"Janet for Dummies\", and so on. The titles write themselves! reply rfrey 4 hours agoparentprevPreorder now, delivery in 10,000 years. reply jerrygenser 4 hours agoprevOff topic - a separate blog post by TFA got me into split mechanical keyboards. It helped me after years of shoulder and wrist pain. Highly recommend exploring other posts by Ian. reply petee 6 hours agoprevThis book got me started with Janet a few months ago, and I really think it helped me get past the difficulty I've had in the past starting with Lisp-y languages (Janet is Lisp like only in appearance afaik) but this just clicked. I'm having a lot of fun writing Janet and refer back to the book often. I do think the macro example that is early in the book is a little overwhelming; if you can get past that everything is far easier. Whats great is that you can leave the author a comment right from the repl, so I did :) reply purerandomness 9 hours agoprevAbsolutely love the writing style, which was the reason I got sucked into functional programming and the Janet language deeper than I'd had previously wanted to. Thank you! reply Tomte 6 hours agoparent> Okay great. I think that‚Äôs a totally reasonable second code sample ever for you to look at. I like it. reply MichaelGlass 10 hours agoprevI really like the slightly silly writing style! Reminds me of a toned-down Douglas Adams. Honestly, I'm not particularly interested in Janet but the style sucked me in. reply behnamoh 4 hours agoprevI've read the book and I found it very fascinating and kind of playful, which actually makes learning the Janet program language much more fun. However, I found the documentation of the language lacking in many ways. Oftentimes there are functions or commands that are just there, but there's no example or explanation. or explanation as to what they do. In fact, there are a lot of those that I found in the book, but I couldn't find in the documentation. So this is one of the reasons I stopped learning Janet, even though I really like the idea of this language, and the fact that it has many sane defaults and similarities to mainstream languages instead of like adhering to archaic Lisp conventions. At the end of the day, it's not actually a LISP because it's not cons lists. And it is fine by me, but again, I found the language not fully documented. reply Lyngbakr 19 minutes agoparentI had exactly the same experience (minus reading the book). Often, I'd just see the function signature and no further explanation. I do realise that it takes a lot of time and effort to build up extensive docs, but it happened enough that I put it down and started looking for another Lisp that compiles down to a binary. reply alectroem 1 hour agoparentprevDo you remember any of the functions/commands that were not documented? I'm semi active in the Janet community and would be able to work on improving the docs where its lacking! reply nickpeterson 5 hours agoprevThe style and tone of this book (website) is quite funny, I really enjoy it. reply 2pEXgD0fZ5cF 9 hours agoprevJanet looks really interesting. Especially with how easy to embed it is. If I understand it correctly creating DSLs in it should also be very easy with its macro and PEG feature? reply afranchuk 5 hours agoparentWriting DSLs is very easy, and fun! The PEG grammars are very elegant to build up. I wrote a language for programmatic recipes (think scaling, unit conversion, etc) with it and it was a delight. I'd provide an example but I haven't taken the time to write a README so I haven't published it publicly yet. reply 2pEXgD0fZ5cF 4 hours agorootparentHey that's cool. Are you willing to instead share an example snippet of what the DSL itself looks like? reply petee 6 hours agoparentprevI'm pretty new to it, but from what I've seen the answer is yes. And while I haven't wrote any macros yet I think PEGs are fantastic, and sooo readable. Their website has an example PEG to read Janet source - https://janet-lang.org/docs/syntax.html#Grammar Embedding is really easy, as is writing c modules. You can link shared, or use an amalgamated c file. Check out https://janet-lang.org/capi/embedding.html Honestly I'm having just as much fun learning Janet as I am writing C modules and embeddings; Janet all the things! reply giraffe_lady 3 hours agoparentprevIt's an incredible lua replacement for embedding. A lot of the time for an embedded scripting language you're defining a DSL which bare lua is fairly poorly suited to. And you lose the tininess and simplicity of the embedding if you're having to cram PCRE and shit in there too. Janet basically just copies lua's C interop because it's the best part of lua. And then with PEGs and a solid macro system you're in a much better position for scripting, or defining a scripting environment, or a configuration DSL, or whatever you wanted a non-C language for. reply katspaugh 6 hours agoprevLove the book! It's fun and inspiring to write programs recreationally! reply ulbu 9 hours agoprev‚ÄúWe‚Äôll start with some numbers‚Äù I was expecting he‚Äôll start by proclaiming it‚Äôs that language that uses floats for integers. reply subjectsigma 5 hours agoprevI couldn‚Äôt get into Janet, I‚Äôm not sure if this is a personal failing on my part. The only other Lisp I‚Äôve spent any significant time in is Emacs Lisp, and everything in Janet seemed similar enough to that but just subtly different that I was always making silly mistakes. The PEG features were really compelling on paper but I found the syntax unwieldy and confusing. The documentation was complete in that it had descriptions of all the functions, but spartan in that it lacked examples or other helpful usage information. There didn‚Äôt seem to be any basic batteries included such as JSON parsing; if I want to write a quick script in a language and I have to first write a JSON or XML parser, task is already failed. This was like four years ago, so maybe the ecosystem is better now. Or maybe scripting was the wrong ruler to measure Janet by. I don‚Äôt know but this post is making me want to reinstall it. reply petee 4 hours agoparentThey put things like JSON and regex in the 'spork' module, which is kinda like libc; theres a strong internal drive to keep the core light. Many projects depend on spork, so it its likely to be installed on early. The docs are decent, though I agree there are still gaps in practical examples, this has been supplemented by https://janetdocs.com, which are linked as \"community examples\" per function reply gen_greyface 11 hours agoprev> ... has a built-in repl. At any point you can press escape and pull it up, and it‚Äôs docked to the bottom of the page... probably not a good decision to use `Esc` since browsers have default bindings for it. firefox exits fullscreen on `Esc` reply bmitc 2 hours agoprev [‚Äì] This is a very \"Internet\" comment, but what struck me about the title and very many other titles in the software engineering world is that I'm not sure it's the best idea to belittle readers in the title. The implication of \" for normal people, mortals, dummies, etc.\" titles is that the reader is not on the level of the author of the book and the authors of the tool or topic that one is learning about. Specifically, \"for mortals\" implies the author and programming language author are immortals, or at least not mortal. I realize this is taking the title more seriously than probably intended, but this type of framing pops up a lot in the software and programming world. reply johnfn 1 hour agoparentI think a more charitable interpretation of the title is an implication that the other material written for Janet was written for supergeniuses (or whatever), so here's a book finally written for normal people. reply julianeon 2 hours agoparentprevI could see this is if the title was \"for morons\" (or something like it), something implying a class division. But 100% of humans are mortal. Everyone is mortal, including the author. So there's no real division here, no two tiered system: we are all on the mortal tier. reply ianthehenry 2 hours agoparentprev [‚Äì] hi, i am the author of this book and i agree with you. it's not a good connotation. i chose it because: 1. it is kinda memorable (look there are so many programming books with exactly the same name) 2. the language is named after an immortal being who guides mortals through the afterlife in the fictional property the good place, so there's some kinda connection. but i agree the implication that janet is somehow \"hard\" to learn or that the author is somehow \"on a higher plane\" is bad. i waffled on this a lot but never came up with another title i could stand and ultimately just pulled the trigger. (but note that i left myself some wiggle room with a neutral domain name.) i hope the tone of the book itself helps to counteract the title, but ya know who knows reply bmitc 1 hour agorootparent [‚Äì] This isn't really a specific complaint about this book. Just triggered my thoughts on a general theme. Thanks for writing the book. I might look into it, as I'm generally interested in Lisp/Scheme-likes. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author has released a free online book titled \"Janet for Mortals,\" focusing on the Janet programming language, which took 20 weeks to write.- The book includes 44,000 words and is accompanied by a website featuring a REPL (Read-Eval-Print Loop) for interactive learning.- The book and related projects, such as C++ library bindings and a testing framework, have gained positive attention on platforms like Hacker News."
    ],
    "commentSummary": [
      "\"Janet for Mortals\" is a book that offers an interactive REPL (Read-Eval-Print Loop) accessible via the escape key, enabling users to experiment with the Janet programming language directly in their browser without installation.",
      "Janet is recognized for its ease of embedding and creating Domain-Specific Languages (DSLs), though some users note that its documentation could be improved.",
      "The book's engaging style and the language's unique features have generated interest and positive feedback, despite some debate over the book's title."
    ],
    "points": 195,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1732685671
  },
  {
    "id": 42254379,
    "title": "Raspberry Pi CM5 is a faster, drop-in upgrade",
    "originLink": "https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly",
    "originBody": "November 27, 2024 The Raspberry Pi Compute Module 5 is smaller than a credit card, and I already have it gaming in 4K with an eGPU, running a Kubernetes cluster, and I even upgraded my NEC Commercial display from a CM4 to CM5, just swapping the Compute Modules! The Compute Module 4 was hard to get for years. It launched right after the COVID supply chain crisis, leading to insane scalper pricing. It was so useful, though, that Raspberry Pi sold every unit they made, and they're inside everything: from commercial 3D printers, to TVs, to IP KVM cards. After pre-announcing the CM5 earlier this year, the biggest question was, is it a drop-in replacement? Yes. For the most part. I've been testing it in tons of Compute Module boards, and it's been awesome seeing a 2-3x speedup just dropping in the new module. It boots up in seconds, it has USB 3 instead of USB 2, and it's compatible with PCIe Gen 3 instead of Gen 2. The CPU is 2-3x faster, RAM is 3-4x faster, WiFi's faster, storage is faster... It's basically a Pi 5, but without the plugs. Most CM4 cases and accessories still work with it, just there's a LOT more bandwidth. The big advantage to a Compute Module versus a Pi 5 is modularity. And I published a video today going over a ton of use cases enabled by various Compute Module carrier boards. All the ones I've tested were built for the CM4, but the CM5 is an instant drop-in upgrade: I won't cover the individual use cases in this blog post. Rather, I'll focus on CM5 benchmarking and my notes from using the hardware a few weeks. The second-most-asked question is how much it will cost. Put simply, the 8GB CM5 is roughly the same price as the 8GB CM4. The 4GB module is $5 more, and the 2GB module is $10 more. So the cheapest CM5 is now $45 instead of $35‚Äîthey're dropping the 1GB option from the lineup this generation. For any specific pricing information, please consult the CM5 Product Brief. Performance Good news: you can expect almost all the same numbers as a Pi 5 with the same amount of RAM. Raspberry Pi made some quality of life improvements for management, too: You can edit the EEPROM (e.g. to change the BOOT_ORDER) without needing another computer Raspberry Pi maintains pi-gen-micro to build smaller custom Pi OS installations Right off the bat, the most refreshing difference is it boots up about 4 seconds faster. Once it's running, the CPU is almost 3x faster. And it's also about 1.5x more efficient, according to my High Performance Linpack tests. And of course, I had to test recompiling the Linux kernel. The CM5 obliterates the CM4, it's more than 3x faster. Video encoding is also about 3x faster. I tested x264 transcoding both at 4K and 1080p resolutions, using Phoronix. All these benchmarks are helped by the faster LPDDR4x RAM on the CM5, which I tested using tinymembench: But all these speedups consume more power, at least at full blast: the CM5 uses almost twice the power flat out. But at idle, the CM5 uses a tiny bit less: I measured 2.3 watts at the wall: And if you're deciding on which CM5 to buy, more RAM is better, at least if you're looking for raw performance. You can save some money with less RAM, but don't expect the performance numbers on a 2 gig model to match the 8 gig model. The built-in graphics are much faster, too. Just testing with GLMark I saw the score jump from about 750 to 1916. It's not nearly as fast as even an older graphics card, but any improvement is welcome, especially for things like 4K displays. You might've noticed, there was a third module in most of these graphs, except that last one. That's another CM5, this one being made by Radxa. It uses a Rockchip RK3588S2, which is a monster in its own right, beating the Pi on almost every benchmark, including efficiency. The elephant in the room is all the Compute Module clones. Because of the Pi shortages, every SBC maker on the planet built their own Compute Module. Though... some work better than others. A lot are faster than the Pi, but pricing is fairly similar, when you compare RAM and relative performance. The big difference between the Pi and all the others, though, is support. I've written how other SBCs could become Pi-killers‚ÄîI mean the hardware is often there‚Äîbut they lack support. One big part of that is the breadth of options for the Pi, which may or may not work on other Compute Modules. And if you want to try, you can expect to debug hardware and OS issues yourself. Like I couldn't get a valid GLMark score for the Radxa, because I couldn't get an OS image to boot and use the built-in Mali GPU in time for this post! It's often a frustrating experience. I regularly test other Compute Modules, though, and I post all my test data and experiences in my sbc-reviews GitHub repo. Hardware - CM5 IO Board Along with the CM5, Raspberry Pi's selling an updated IO board, for $20, with a few helpful changes. First, a power button, with the same behavior as the Pi 5. This would've saved so much time debugging graphics cards on the CM4. Then, there's a new tiny fan header, the same one on the Raspberry Pi 5. Companies like EDAtec already have active coolers for the CM5, and I'll test some cooling options on my my 2nd channel, Level2Jeff. On the port side, they got rid of the 12 volt barrel jack for power, and now they just use USB-C. They dropped down to two multipurpose Camera/Display ports. Each one has 4 lanes of MIPI bandwidth, just like the Pi 5. There are still two full-size HDMI ports, an Ethernet port, and two USB type-A ports, but these are upgraded to USB 3. There's a microSD card that only works on Lite Compute Modules without eMMC, and finally an M.2 slot, with a little LED that blinks when you're using an SSD. This is nice, because probably 99% of people buying these things would plug in storage. On the CM4, you had to use an awkward adapter card, but that's not required anymore. Maybe we could see this on the Pi 5 someday? Or if not, maybe we could hack it using the Compute Module! That's foreshadowing... Hardware - CM5 The feature that'll make the biggest impact for me, since I use a lotta compute modules, is this new silkscreen up in the top corner. It has resistors for the RAM and storage sizes, so the specs are right up top. The major changes from the CM4 include: BCM2712 D0 stepping SoC, with 4x Cortex A76 CPU cores at 2.4 GHz RP1 chip for IO expansion (GPIO, MIPI Camera/Display, 2x USB 3.0 bus, Ethernet) eMMC storage is moved to the bottom of the Compute Module The Wireless chip has been raised up onto a short PCB mezzanine (I believe it can be had separately now, for system integrators, maybe?) The RAM is now an LPDDR4x RAM module, sporting much higher speeds (and on-chip ECC) The Pi 5 PMIC is included on the CM5 board, for USB-C PD negotation or direct 5V input like on the Pi 5 Other things are familiar, like the switchable PCB antenna / u.fl connector, the 2x 200-pin hirose board to board connections, and the Broadcom BCM54210PE (which enables hardware PTP timestamping support). I've been testing the CM5 on various carrier boards, even with eGPUs and 10 Gbps NICs on the official IO Board, and all that testing can be seen in my YouTube video on the CM5. Conclusion But tying up the CM5, Raspberry Pi kept the price the same for the 8 gig model; those start at $75 for the Lite version. For 4 gig, they're going up five bucks, and for 2 gig, it's up 10 bucks, from $35 to $45. They're dropping the 1 gig model from the lineup, and in reality, a lotta applications choke with less than 2 gigs of RAM, so I'm not surprised. When the Compute Module 4 came out, it changed literally everything about the Compute Module. Including the form factor. That meant everything built for the CM1 and CM3 had to be redesigned, and it made many hardware developers angry. Luckily, this time they kept the form factor, meaning for most things, it's a drop-in upgrade, where you get 2-3x faster performance, and at least for the larger models, the same price. Further reading The Rock 5 B is not a Raspberry Pi killer‚Äîyet The Raspberry Pi Compute Module 4 Review Testing PCIe on the Raspberry Pi 5 raspberry pi compute module cm5 youtube video Add new comment Comments Lionel Schinckus ‚Äì 10 hours ago Is it possible to use it with Turing PI 2? Reply Jeff Geerling ‚Äì 9 hours ago In reply to Is it possible to use it‚Ä¶ by Lionel Schinckus I haven't tested it on their CM4 adapter board yet. I hope it does work, hopefully I can get to testing that soon! I completely forgot to try, as well as to try on a Home Assistant Yellow (it would make for a nice upgrade for my home and office Home Assistants! Reply nada ‚Äì 9 hours ago let's hope then sans-wifi version will be easily available, for a change :) Reply",
    "commentLink": "https://news.ycombinator.com/item?id=42254379",
    "commentBody": "Raspberry Pi CM5 is a faster, drop-in upgrade (jeffgeerling.com)178 points by ingve 9 hours agohidepastfavorite92 comments Carrentt 8 hours agoPretty wild to see a drop-in replacement that's actually faster - usually that's marketing speak for \"technically compatible but slower in real life.\" The fact that you can just pop this into existing CM4 hardware and get 2-3x performance is impressive. Finally, my commercial display can run Crysis! (Ok, maybe not, but that USB 3 upgrade is sweet). Though I have to laugh at the \"good news everyone, it's the same price!\" followed immediately by \"...for the 8GB version only, everything else costs more.\" Classic Pi Foundation pricing gymnastics. At least we're not dealing with scalpers asking $200 for a CM4 anymore. The silkscreen specs on top is such a simple but brilliant addition. No more squinting at tiny chips trying to figure out which module is which in your parts drawer. reply creesch 8 hours agoparent> Finally, my commercial display can run Crysis! (Ok, maybe not, but that USB 3 upgrade is sweet). It actually can! .... if you also plug in a GPU. https://www.jeffgeerling.com/blog/2024/amd-radeon-pro-w7700-... reply benj111 7 hours agoparentprev>Classic Pi Foundation pricing gymnastics To be fair, theyve dropped the 1GB model, so do you want to compare old and new lowest specs? I don't know about relative sales figures, I infer that 8GB is expected to be the default going forward. reply esskay 6 hours agorootparentThing is once you start looking outside of the base model it becomes a bit less of a good offering when there are others making compatible boards that are arguably better specced. The only issue of course is some whilst sharing the same formfactor and connector aren't always compatible with the same hardware. If I recall correctly the Radxa CM3's for example are fully compatible. reply benj111 4 hours agorootparentRpis proposition has always been support rather than value per se. If you want cheaper, yes there are other options. If you want something where a mainline kernel will work, and has a community, Pis are a much better choice. reply micw 8 hours agoprevDoes anyone know if it's a good idea to base a product on Pi CM4/5 (or has experience with this)? I wonder how the availability any price in large quantities is (like 10k per year) and how reliable the connector is in comparison to a soldered SOM. reply davidhyde 6 hours agoparentAs someone who spent many months designing a product around CM4 and then waiting for more than 2 years for modules to arrive over the parts shortage era (eta kept being pushed out by the distributor) I will never put myself in that position ever again. The solution I have found was to skill up and learn how to do hardware design myself. At that point there are many more options. Understandably that's not ideal for a lot of people. reply jacobmarble 22 minutes agorootparentCan you highlight the resources that you used to level up this way? I can design my own microcontroller boards, but the complexity of SoCs and required peripherals seems too much for this part-timer. reply the__alchemist 3 hours agorootparentprevI see your point, and in most cases I would agree with you; this was an unusual time; you would have had the same problem using STM32s, etc. reply Joel_Mckay 5 hours agorootparentprevUnfortunately, chips EOL all the time, charge pin-outs, and the temptation to in-house an integrated SoM solution may add hundreds of thousands to the cost. If you are not moving >3m chips a quarter, than you are still vulnerable. We also had to violate the Design for Manufacturability guidelines to adapt to the shortages and part skelpers hitting JIT lines. Even today, we incur a questionable 12 USD labor cost on every product to ensure a generic carrier PCB drop-in population option is always available (0.1\" pins 1980's style). Training slide deck: \"Rule #21: No unicorn parts, and no excuses\" We dodged the CM4 choice luckily due to my concerns, but still were tagged by a proprietary missing RF module needed for legacy system interoperability. The vendors lied about inventory levels, and kept the order tied up for years before the spools arrived. Best of luck, =) reply nsnxjxnd 7 hours agoparentprevWhile we have never used the compute module in large quantities, we have used it numerous times for small batches with 1-2k/month and had no issue there If you plan on using it for small series ofIt boots up in seconds, > 23 seconds until ssh login Well ok, technically correct, but I expected faster when I read that. reply diggan 7 hours agoparentI'm guessing that's with whatever stock software/firmware stack Raspberry PI themselves ship, surely can be made a lot faster by not having to probe various hardware ports you know aren't used, for example. reply geerlingguy 3 hours agorootparentI didn't have it complete in time, but you can use pi-gen-micro from Raspberry Pi (it's a newer project) to build a very lightweight boot image now, on the order of a yocto/buildroot image, but with Pi OS as the base. reply rcarmo 5 hours agorootparentprevJust pruning a bunch of systemd units will get you to half that time. reply Mashimo 7 hours agorootparentprevYes, but you could do that with most devices running linux. reply nxobject 7 hours agoparentprevMilliseconds, even! reply fxj 9 hours agoprevTHe Raspi CM is also used in some synthesizers like the Korg Wavestate or the Ableton Move. reply exitb 8 hours agoparentAre they implemented on bare metal, or is modern synthesiser just a regular computer with a keyboard attached? reply fxj 6 hours agorootparentThe Ableton Move is just a CM4 with linux (abletonos) running and using a SD-Card in the box. https://www.reddit.com/r/ableton/comments/1fzd9ln/move_is_a_... reply frabert 8 hours agorootparentprevThe Korg Kronos (and I suppose the Nautilus as well) are just regular x86 PCs (I believe using Atom CPUs) running a custom Linux kernel and custom software reply Tepix 6 hours agorootparentThat's super interesting! Has anyone managed to dump the firmware? :-) reply frabert 5 hours agorootparentYou can probably ask the one who did the most reverse-engineering :) https://marcan.st/2016/06/hacking-and-upgrading-the-korg-kro... As far as I can tell, there's no custom \"firmware\" to speak of, it's a patched Linux kernel running a kernelmode audio synthesis engine and a usermode app for the UI reply tasn 5 hours agoprevThe Raspberry Pi is one of the only random gadget purchases that I've made over the years that found their way to the back of the drawer, then found their way out, back to the drawer, and out again. It's a really useful general purpose tool. It's currently running at my parents' place as a VPN server to let them access their smart home and cameras from outside the house (I didn't let them expose these to the internet). reply DanielHB 7 hours agoprevI got a raspberry 4 recently and was tinkering with it. I was appalled at the apparent disk IO performance of the thing, opening a browser takes several seconds. Is that just me or do I have a particularly crappy SD card? Anyone got any tips on how to improve disk IO? Would a USB3 external drive help with this? reply justin66 5 hours agoparent> Would a USB3 external drive help with this? Emphatically yes. It's an entirely different experience using a RPi 4 with a quality SSD. [0] It's also more expensive, so you have to decide whether that's important to you. [0] https://www.samsung.com/us/computing/memory-storage/portable... In my opinion it's a mistake to split the difference with a cheap SSD or one you need to plug in using a SATA to USB adapter. (troubleshooting first step: if it's not the power supply, it's the SATA to USB adapter...) reply antihero 7 hours agoparentprevPerhaps the M.2 HAT+ and a decent SSD? USB3 could plausibly be faster than the SD card as the spec allows for 5Gbps+ but I don't know about Pis that much, I'd defer to someone with experience. As a photographer I can tell you that SD cards, even high class ones have laughably awful speeds - any proper camera that needs to do video will use CFexpress Type B cards which are tremendously faster. reply jsheard 7 hours agorootparent> Perhaps the M.2 HAT+ and a decent SSD? That won't help OPs Pi4, the PCIe interface is new on the Pi5. USB is the best you can do on the older ones. reply antihero 1 hour agorootparentGood to know! reply wrboyce 7 hours agorootparentprevProper cameras use film ;) Seriously though, there are plenty of top-end cameras that use SD cards (all Nikons, for example). EDIT: completely missed that you said video, ignore me! reply teamonkey 5 hours agoparentprevThe Pi 4's IO is not great, but the choice of SD card affects it a lot. Brand seems to have more of an impact than speed (or at least the stated speed of the card). Cheap knockoffs will absolutely kill performance. That's why Raspberry Pi started selling their own branded SD cards. Using an external USB3 drive also helps but it's still pretty slow. I found it too slow to use as a SAMBA file server when connected over WiFi, even though it was hardly pushing the CPU or memory. It would regularly fail to transfer large files. One of the main selling points of the Pi 5 is faster IO. I'd love to see something tiny and power-sipping like the Zero but with the enhanced IO of the Pi 5. reply DanielHB 2 hours agorootparentI am using a USB3 drive as a samba drive and it works fine, although I use it mostly for streaming video not to transfer large files. My OS however is in the SD card which is Sandisk which I assumed was the good fair price brand. reply cillian64 7 hours agoparentprevThere is quite a bit of variation between SD cards, browser taking several seconds is surprisingly bad. On Pi 4 I use a 2.5\" SATA SSD (WD blue) on a startech USB3 adaptor and the performance seems to me much better than even good quality microsd cards. reply esskay 6 hours agoparentprevNo it's not just you. I/O on the Pi4 and below is awful, but for most applications it doesn't matter. Not sure on the Pi 5 as I jumped ship after the scalping and overall negativity around the foundation's activities in the last few years but I expect it's a fair bit better. reply Joel_Mckay 4 hours agoparentprevIn general, sdcards are slow... most use kernel cache lazy page flush if the pi4 has 8GB ram, and F2FS to improve flash reliability. After, \"sudo apt-get install preload\" it will cause previously used programs from the last session to auto-cache into ram. Combined with the above setting, the usual programs will launch much faster. There is also the option to use an external SSD drive for better performance. Part of the fun of pi4 was getting the OS optimized, but unless you have a legitimate \"Sandisk Extreme Pro U3\" or >30MB/sec rated sdcard it can still be slow (people have seen 4MB/sec on old counterfeit cards.) sdcard bus overclocking is a thing as the pi tries to maximize slow hardware compatibility by default. Note this feature is limited on the pi4, but can significantly decrease boot times on older models. YMMV =) reply thenickdude 5 hours agoprevOnly two total MIPI ports (DSI/CSI, for displays and cameras respectively) compared to 4 ports on the CM4. reply rekoil 8 hours agoprevThis feels like a good place to ask this. Has anyone who sees this attempted to run Home Assistant OS in a Home Assistant Yellow \"compute module board\" using a Radxa CM5? It's tempting to me because the Radxa CM5 uses a mainline kernel instead of the Broadcom-modified kernel the RPi CM4 uses, but I understand that there may be some level of work needed to be done to support the compute module + board combo, and I'm curious if that is true for the Radxa CM5 + Yellow board combo. Or have I misunderstood anything? reply tecleandor 7 hours agoparentI was tempted to do something similar when I got my Yellow because the low availability of the CM4s back then, but it seemed that, at least with older Radxas there were problems with kernels or compatibility. It might work with the newer one if you say it's mainline kernel but haven't found anything in the forum in quick search... reply rekoil 3 hours agorootparentI am keen to try. But I'm even more keen for someone else to tell me they have tried it and the result of said test because I am not keen on my home automation system being down for a longer period of time... reply dividuum 7 hours agoparentprevThere is no \"Broadcom-modified kernel\". There's a fork with changes needed to support all Pi hardware at https://github.com/raspberrypi/linux. Unlike some boards were you're eternally stuck at old versions, the fork is actively maintained (currently mostly at 6.6, soon 6.12) with its changes regularly getting upstreamed. You post make it sound like the Pi kernel is a mess, which it is absolutely not. reply zokier 7 hours agorootparent> There is no \"Broadcom-modified kernel\". There's a fork with changes needed to support all Pi hardware That's literally the same thing reply dividuum 6 hours agorootparentRight. I read it as \"modified by Broadcom\". Just wanted to point out, that this isn't inherently a bad thing if done right. reply rekoil 3 hours agorootparentI get where you're coming from, didn't mean to make it sound like that but I do see it the same way zokier seems to. End game for me is booting a vanilla kernel compiled entirely from open source code and having access to all the boards hardware. reply Jedd 7 hours agoprevI'm really torn as to whether 'smaller than a credit card' (when something is clearly much, much larger than a credit card), or re-purposing a previously well understood and generally agreed upon definition of 'artificial intelligence' to now mean a frequently wrong or bewildered statistical / language model, annoys me the most. reply diggan 7 hours agoparent> when something is clearly much, much larger than a credit card Is it? Too me it seems smaller both in width and depth, but the height seems some mm or more than a typical credit card. reply Havoc 6 hours agoprev> That's another CM5, this one being made by Radxa. It uses a Rockchip RK3588S2 Would rather go for this. The NPU on the 3588 are now starting to be usable for stuff like basic LLMs Unsure about the S2 variant though reply jamesy0ung 8 hours agoprevI wonder how the USB 3 works, considering it is drop in compatible with the CM4 which only had USB 2. reply micw 8 hours agoparentI guess \"mostly\" refers to the \"drop-in upgrade\", not to the 2-3x faster. The pinout has been modified slightly, so it's not 100% compatible. reply jamesy0ung 8 hours agorootparentYeah I wasn't too sure about the compatibility, but JG mentioned he was able to just pop it in his NEC Display and it was shown in a blade carrier. reply babarjaana 7 hours agoprevLooks like the Radxa CM5 is still significantly faster than Pi CM5, while only being slightly more expensive (113USD vs 95USD for the 8GB/64GB model from what I could find). Anyone here has any experience with it? reply Narishma 7 hours agoparentAs the article says, you pay for that with a lack of support compared to the Raspberry Pi. reply qwerty456127 8 hours agoprevDoes it still only encode to H.264, no HEVC/AV1? reply geerlingguy 8 hours agoparentTechnically the BCM2712 doesn't have any hardware encode support, only software/CPU. It includes an H.265 (up to 4K 60 fps) hardware decode block‚ÄîI tested that, and it works fine‚Äîbut no other video hardware encode/decode, unfortunately. The CPU is good enough for up to H.264 1080p encode at least, and with some tweaking could get a 4K stream or multiple HD streams encoded... but it's not ideal for that use case. reply henearkr 7 hours agoprev [‚Äì] I know it should theoretically work, but has anyone already tried to replace the CM4 of a HomeAssistant Yellow by the RPi CM4? reply newsclues 5 hours agoparent [‚Äì] https://www.home-assistant.io/blog/2024/11/27/home-assistant... Thanks to Raspberry Pi providing us with an early sample, we have been able to add Compute Module 5 (CM5) compatibility to the Home Assistant Yellow reply henearkr 4 hours agorootparent [‚Äì] Wow!! Those are really great news, thank you! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Raspberry Pi Compute Module 5 (CM5) is a significant upgrade from the CM4, offering 2-3 times faster performance, USB 3, and PCIe Gen 3 compatibility while maintaining the same form factor.",
      "The CM5 is priced similarly to the CM4, with the 8GB model starting at $75, and includes a faster CPU, RAM, and improved graphics, though it uses more power at full capacity.",
      "An updated IO board is also released for $20, featuring USB-C power and other enhancements, highlighting the CM5's support and modularity despite competition from other single-board computers (SBCs)."
    ],
    "commentSummary": [
      "The Raspberry Pi CM5 offers a significant performance boost over the CM4, with 2-3 times the speed, and includes a USB 3 upgrade.",
      "While the 8GB version retains its price, other versions are more costly, and some users note that other boards might have better specifications.",
      "Despite hardware improvements, the CM5 lacks hardware encode support but can decode H.265, and the Raspberry Pi's strong community and support remain key advantages."
    ],
    "points": 178,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1732698941
  },
  {
    "id": 42251564,
    "title": "ISPs say their \"excellent customer service\" is why users don't switch providers",
    "originLink": "https://arstechnica.com/tech-policy/2024/11/isps-say-their-excellent-customer-service-is-why-users-dont-switch-providers/",
    "originBody": "Broadband customer service ISPs say their ‚Äúexcellent customer service‚Äù is why users don‚Äôt switch providers ISPs tell FCC that mistreated users would switch to one of their many other options. Jon Brodkin ‚Äì Nov 26, 2024 8:05 PM211 Credit: Getty ImagesThamrongpat Theerathammakorn Credit: Getty ImagesThamrongpat Theerathammakorn Text settings Lobby groups for Internet service providers claim that ISPs' customer service is so good already that the government shouldn't consider any new regulations to mandate improvements. They also claim ISPs face so much competition that market forces require providers to treat their customers well or lose them to competitors. Cable lobby group NCTA-The Internet & Television Association told the Federal Communications Commission in a filing that \"providing high-quality products and services and a positive customer experience is a competitive necessity in today's robust communications marketplace. To attract and retain customers, NCTA's cable operator members continuously strive to ensure that the customer support they provide is effective and user-friendly. Given these strong marketplace imperatives, new regulations that would micromanage providers‚Äô customer service operations are unnecessary.\" Lobby groups filed comments in response to an FCC review of customer service that was announced last month, before the presidential election. While the FCC's current Democratic leadership is interested in regulating customer service practices, the Republicans who will soon take over opposed the inquiry. USTelecom, which represents telcos such as AT&T and Verizon, said that \"the competitive broadband marketplace leaves providers of broadband and other communications services no choice but to provide their customers with not only high-quality broadband, but also high-quality customer service.\" \"If a provider fails to efficiently resolve an issue, they risk losing not only that customer‚Äîand not just for the one service, but potentially for all of the bundled services offered to that customer‚Äîbut also any prospective customers that come across a negative review online. Because of this, broadband providers know that their success is dependent upon providing and maintaining excellent customer service,\" USTelecom wrote. While the FCC Notice of Inquiry said that providers should \"offer live customer service representative support by phone within a reasonable timeframe,\" USTelecom's filing touted the customer service abilities of AI chatbots. \"AI chat agents will only get better at addressing customers' needs more quickly over time‚Äîand if providers fail to provide the customer service and engagement options that their customers expect and fail to resolve their customers' concerns, they may soon find that the consumer is no longer a customer, having switched to another competitive offering,\" the lobby group said. Say what? The lobby groups' description may surprise the many Internet users suffering from little competition and poor customer service, such as CenturyLink users who had to go without service for over a month because of the ISP's failure to fix outages. The FCC received very different takes on the state of ISP customer service from regulators in California and Oregon. The Mt. Hood Cable Regulatory Commission in northwest Oregon, where Comcast is the dominant provider, told the FCC that local residents complain about automated customer service representatives; spending hours on hold while attempting to navigate automated voice systems; billing problems including \"getting charged after cancelling service, unexpected price increases, and being charged for equipment that was returned,\" and service not being restored quickly after outages. The California Public Utilities Commission (CPUC) told the FCC that it performed a recent analysis finding \"that only a fraction of California households enjoy access to a highly competitive market for [broadband Internet service], with only 26 percent of households having a choice between two or more broadband providers utilizing either cable modem or fiber optic technologies.\" The California agency said the result \"suggests that competitive forces alone are insufficient to guarantee service quality for customers who depend upon these services.\" CPUC said its current rulemaking efforts for California \"will establish standards for service outages, repair response time, and access to live representatives.\" The agency told the FCC that if it adopts new customer service rules for the whole US, it should \"permit state and local governments to set customer service standards that exceed the adopted standards.\" People with disabilities need more help, groups say The FCC also received a filing from several advocacy groups focused on accessibility for people with disabilities. The groups asked for rules \"establishing baseline standards to ensure high-quality DVC [direct video calling for American Sign Language users] across providers, requiring accommodations for consumers returning rental equipment, and ensuring accessible cancellation processes.\" The groups said that \"providers should be required to maintain dedicated, well-trained accessibility teams that are easily reachable via accessible communication channels, including ASL support.\" \"We strongly caution against relying solely on emerging AI technologies without mandating live customer service support,\" the groups said. The FCC's Notice of Inquiry on customer service was approved 3‚Äì2 in a party-line vote on October 10. FCC Chairwoman Jessica Rosenworcel said that hundreds of thousands of customers file complaints each year \"because they have run into issues cancelling their service, are saddled with unexpected charges, are upset by unexplained outages, and are frustrated with billing issues they have not been able to resolve on their own. Many describe being stuck in 'doom loops' that make it difficult to get a real person on the line to help with service that needs repair or to address charges they believe are a mistake.\" If the FCC leadership wasn't changing hands, the Notice of Inquiry could be the first step toward a rulemaking. \"We cannot ignore these complaints, especially not when we know that it is possible to do better... We want to help improve the customer experience, understand what tools we have to do so, and what gaps there may be in the law that prevent consumers from having the ability to resolve routine problems quickly, simply, and easily,\" Rosenworcel said. ISPs have a friend in Trump admin But the proceeding won't go any further under incoming Chairman Brendan Carr, a Republican chosen by President-elect Donald Trump. Carr dissented from the Notice of Inquiry, saying that the potential actions explored by the FCC exceed its authority and that the topic should be handled instead by the Federal Trade Commission. Carr said the FCC should work instead on \"freeing up spectrum and eliminating regulatory barriers to deployment\" and that the Notice of Inquiry is part of \"the Biden-Harris Administration's efforts to deflect attention away from the necessary course correction.\" Carr has made it clear that he is interested in regulating broadcast media and social networks more than the telecom companies the FCC traditionally focuses on. Carr wrote a chapter for the conservative Heritage Foundation's Project 2025 in which he criticized the FCC for \"impos[ing] heavy-handed regulation rather than relying on competition and market forces to produce optimal outcomes.\" With Carr at the helm, ISPs are likely to get what they're asking for: No new regulations and elimination of at least some current rules. \"Rather than saddling communications providers with unnecessary, unlawful, and potentially harmful regulation, the Commission should encourage the pro-consumer benefits of competition by reducing the regulatory burdens and disparities that are currently unfairly skewing the marketplace,\" the NCTA told the FCC, arguing that cable companies face more onerous regulations than other communications providers. Jon Brodkin Senior IT Reporter Jon Brodkin Senior IT Reporter Jon is a Senior IT Reporter for Ars Technica. He covers the telecom industry, Federal Communications Commission rulemakings, broadband consumer affairs, court cases, and government regulation of the tech industry. 211 Comments Comments Forum view Loading comments... Prev story Next story",
    "commentLink": "https://news.ycombinator.com/item?id=42251564",
    "commentBody": "ISPs say their \"excellent customer service\" is why users don't switch providers (arstechnica.com)173 points by alsetmusic 18 hours agohidepastfavorite118 comments Sabinus 17 hours ago\"Businesses will lie to customers and regulators as much as they're allowed to get away with because it's good for profits.\" Either the customer or regulator needs to hold companies to account. In an industry that is a natural monopoly like last-mile internet delivery, then regulators need to step in and work hard to structure the market such that it actually functions properly, with as much competition as possible. In Australia this had the government own the wires, which rented the capacity to companies, that sold internet service to consumers. An actual functioning market with competition, instead of one company owning all the wires for a town/city/state, refusing to rent them to anyone else, and charging sky high rates. reply protocolture 16 hours agoparentNatural Monopoly? Theres a natural Pit and Pipe monopoly, but ISPs are hardly bound to it. The Pit and Pipe asset is a gift from the federal government to Telstra, who sold it to NBN for a steal. There are multiple fibre companies in a lot of our pits. PIPE, Vocus, Optus. They are prevented by legislation from diverting any of that asset towards residential users. The only exception where theres any kind of competition at all, was TPG taking NBN to court over apartment buildings, otherwise its illegal to overbuild NBN. The penalty is quite hefty too. In fact NBN is being directed to overbuild other fibre providers. NBN says, we arent coming to this community. Community organises their own fibre. NBN says hey we actually do want to be in this market now. Now its a legal grey area as to whether the existing provider can continue their rollout. Thats before we get into fixed wireless. I spent 99% of the NBN \"debate\" with a 300M residential fixed wireless service. Shady operators give it a bad name, but a well engineered wireless link is a godsend. We had a functional market in this country. It was ULL. Legislation forced Telstra (through gritted teeth) to sell ULL copper instead of reselling their services. It lead to the largest sharpest increase in internet speeds in this country. The ULL model allows providers to provide their own hardware and upgrade it as demand requires. It removes a middle man from their logical networks. Why we trashed this model for an NBN cost recovery makes no sense. Singapore rents glass, it was a big undertaking and it has been extremely successful. Companies competing to be the first to roll out 5/10/100 gig services. Any discussion in this area needs to acknowledge it is illegal for me to rent pit and run a fibre cable into a residential dwelling thats already serviced by the NBN. There's nothing natural about it. reply polemic 17 hours agoparentprevYup - in NZ the infrastrucutre and the provider were separated as part of the nation-wide fibre-to-the-door rollout. I switched provider the other week, after the old one discontinued a discount. All I had to do was sign up with the new provider and provide the connection number. They organised everything else and my old provider _refunded_ me for part of an unused pro-rata month. Suspicously easy. reply BLKNSLVR 15 hours agorootparentYeah, the Australian Government was never going to structurally separate Telstra because it would have trashed the share price, which would have made them look bad because they were the ones that sold it off to create the Future Fund (public sector pension fund, sort-of). Telstra's behaviour post-privatisation somewhat precipitated the creation of NBNco. reply hilbert42 6 hours agorootparent\"structurally separate Telstra because it would have trashed the share price,\" I've whinged for years about the fact that Australia is the world's expert in fucking up communications services and it has done so for nearly a century, and it's cost the Australian public many billions of dollars (for some reason Oz people are like sheep, unfortunately they let governments and Big Business walk all over them and don't complain). I even challenged HN readers to come up with a country that made a worse mess of its communications and I've had no takers! It's not only the sale of Telstra that governments of both persuasions have fucked up, one only needs to see a litany of disasters with the NBN, and just wait until it's divided up among unscrupulous money-grubbing telcos, the Telstra sale will begin to look benign in comparison. What are my reasons you may well ask. I've said them all previously on HN and elsewhere, the latest only a week or so ago, it's here if you're interested: https://news.ycombinator.com/context?id=42104578 reply rasz 12 hours agorootparentprevSounds as easy as switching phone providers in Poland. reply BLKNSLVR 17 hours agoparentprevAnd how much did the Liberals and Murdoch media hate that? I got my FTTH connection a full ten years later than I would have if they hadn't fucked with the original plan. I can't forgive them for that. It's not even personal, it was holding back the progress of the entire country. The behaviour of Optus and Telstra at the time dictated that the only way to do it properly was to have it done by the government. And they were right, because it was 'for Australia', not for private companies' shareholders. reply marcus_holmes 17 hours agorootparent100% agree. Abbott should be held to account for this forever. The plan wasn't perfect, but the way they messed it up for purely political point-scoring (and keeping Murdoch happy) was criminal. reply protocolture 16 hours agorootparent\"Wasnt Perfect\" is the understatement of a lifetime. reply protocolture 16 hours agorootparentprevThe original plan was killed by the ACCC. You are thinking of the Rod Sims ACCC \"engineered\" plan written by the big 4 telcos (expanding the network to 121 POIs, preventing NBN from competing against fibre backhaul providers, generally making it hell for small players to compete), that would deliver FTTH but not the capacity or competition to make it viable. And we would still be undertaking the physical roll out. The LNP made the last mile worse by some metrics, but they vastly improved the economics. Its a testament to how bad their PR is that they have failed to capitalise on it politically. reply BLKNSLVR 15 hours agorootparentStrongly disagree that they improved the economics at all. I will say that, if they did improve the economics, then I agree that 'something' failed in getting that point across. They did crow about how bad the original economics was, but really just using scare tactics by quoting the large number that out's of the range of reasonable comparison by the average citizen. Most information I read was that they wasted additional money including paying for a lot, like a lot lot, of copper for last mile connections, including paying Telstra for some of their existing copper infrastructure - the dilapidated state of which was part of the reason that FTTH was the proposed solution for 9x% of the Australian population. In fact, it's almost impossible that improved economics making changes and causing the (decade+ in some cases) delay of the rollout of FTTH. One of my favourite pieces of graffiti: https://gadgetguy-assets.s3.ap-southeast-2.amazonaws.com/wor... I'm happy to be told I'm wrong, along with explanations, or if there are mitigating factors to anything I've written above. Edited to add: My rant may be on a different interpretation of 'economics' than which you're referring to. Mine's purely based on the cost of the project - not how it's been charged to ISPs or Customers. Edited to add post-reply below: Thanks for the detailed reply, that's very interesting information that I had read peripheral information around, but was less intimate with. Thanks for taking the time, two thumbs up. reply protocolture 15 hours agorootparentWhen I refer to the economics, I refer to the market that the NBN act creates. This is largely divorced from political spending, like purchasing the Optus HFC network to which you refer. The original labor approved cost for accessing the network made it unreasonable to purchase enough CVC to provide services for customers. Bevan Slattery used to discuss this alot, but NBN had the capability, and in one case threatened to use that capability, to cut off any wholesalers they like. So Bevan was the only one in a place to really publicly criticise them. A gentleman I know wrote a whitepaper about how bad the NBN Fixed Wireless service was and his employer forced him to scour it from the internet after threats from NBN Co. So as to publicly allowed criticism of NBN Co you dont get much other than that. I will see if I can dredge up the numbers. Under labors watch, they assigned engineers and specialists to design a fibre network. It was over engineered (should have been ULL with no active hardware) but we didnt get that. It was to consist of 21 points of interconnect and effectively would have provided an alternative to buying backhaul from Telstra/AAPT etc. The ACCC, after prompting from the big 4, changed the plan to include 121 points of interconnect. NBN co also mandated that Wholesalers be able to reach a very large number of them before they could connect to the system (with a plan for all 121). What they didnt do was change the pricing structure. So now to play ball, you now need 100 more points of presence on your network (very expensive) and you are paying a quite hefty fee for an extremely small amount of CVC. NBN Expected that more CVC would be purchased by providers, but as it worked out, this did not occur. Some providers purchased more CVC just to get started, and then phased it out. Others didnt bother. Ultimately, CVC proved to be lossmaking for ISPs, who at best had a dollar after the customers monthly sub with which to find Support/Hardware/all their other costs. This lead to a significant number of user complaints, regardless of last mile tech. LNP pops in, and they are looking for any way they can \"fix labors mistake\". ISP lobbying finally makes an impact and NBN starts bundling in CVC. The LNP also mostly stop talking about the NBN becoming a return on investment in x years, which takes pressure off of NBNCo to needle ISPs. This is where people with fibre connections started going from just having less dropouts, to having very significant speed increases versus other technology types. ISPs gained a very small amount of breathing room (still heaps of room for improvement) and the economics were somewhat improved. The thing is, the LNP didnt market this success. They went and fiddled around with the rest of the project, bought the optus network etc and campaigned on that nonsense instead. Really if they wanted to they should have done more to highlight and correct the actual failures of the NBN rather than the issues their donors had but w/e. reply hilbert42 6 hours agorootparent\"A gentleman I know wrote a whitepaper about how bad the NBN Fixed Wireless service was and his employer forced him to scour it from the internet after threats from NBN Co.\" I know, this bullying and like threats are just part of a much bigger problem. As I've said in my post to this story, that's just part of a much bigger problem with Australian communications and communications policy. When it comes to Australian governments and communications what we end up with is inevitably some sort of major fuck-up, and often it's monumental. If I were an alien I'd draw the conclusion that Australian people have a congenital abnormality that makes them lose all sense and reason when they hear strings that contain words like 'communications'. What else could it be, the fuck-ups are continuous and span over a century? Methinks, some grad student could likely get a PhD sorting this out and pinning the blame. Oh, but what a horrible job! reply cavisne 14 hours agoparentprevDidn't they end up taxing competitors who didn't use the government owned network? reply jmclnx 18 hours agoprevI first thought \"why did someone submit an onion article\", but it is arstechnica. If there was competition fir ISPs, everyone in my area would move off of comcast the first chance they get. reply prophesi 18 hours agoparentWhat you get from competition is the incentive to lay down fiber optics, so that you attract customers with your higher speeds and can rent the infrastructure to your competition. Though there are other forces at work in urban areas, in my area I know a lot of people out in the 'burbs with fiber optics while those living in the heart of downtown usually only have cable internet at best. Not sure what's happening there, and I imagine is where municipal internet can help (with both the taxpayer dollars and bipartisan buy-in for it). On the customer service front, the painpoint is usually related to mobile networks. It's very painful to switch from one carrier to another, with limited time offers to keep you or upselling when you've decided to join. It's when this spills over into their internet services that I want to get off the grid entirely. reply juliendorra 17 hours agorootparentFrom your post, it seems the European internet and mobile market is much more competitive than the US one. And yet much more regulated. It seems that‚Äôs two markets where EU regulations have actually created both enough competition (still not a lot of providers, 3, 4 everywhere) and constraints on the licensees to give us cheap very high speed fiber and painless mobile switch (number portability). Is your city dense? It‚Äôs so weird that the center would be left out of fiber when generally that‚Äôs where carriers prefer to lay it first. reply nijave 1 hour agorootparentprev>while those living in the heart of downtown usually only have cable internet at best If you're in the U.S. probably exclusive provider revenue share agreements with apartment buildings. The ISP gets exclusive access to the building and the building owner gets a % of ISP revenue. Anecdotally, that rev share can be tens of thousands a year. reply tptacek 18 hours agoparentprevMost people here would not. Comcast is a fun punching bag but for the most part it works fine for most people. Later Sorry, when I said \"here\", I meant (and you couldn't have known without reading my mind) \"in my municipality\", where I'm on the board that manages the ISP contracts and have some knowledge that normal people in fact actually like Comcast fine, are not especially interested in having a bunch of new choices. But we also have AT&T. reply booi 17 hours agorootparentSounds more like Stockholm syndrome. I used to be ok with comcast even with their incessant increasing of rates that i'd have to negotiate and the terrible service. Finally had enough, switched to AT&T fiber. omg. the difference is night and day. No more caps, no more random outages. Lower pings, half the price and no price increase so far. I don't know why anybody keeps it tbh reply nijave 1 hour agorootparentprevMy parents are hitting and exceeding their 1.2TiB data allotment streaming TV shows. I'm considering setting them up with T-Mobile home internet. Data caps alone are extremely anti consumer friendly. It's very difficult for non technical folks to understand how much they're consuming. Especially given the stark different between 1080p and 4k which might not even be obvious depending on their TV and streaming service. reply Loughla 18 hours agorootparentprevWhile I hate it, I agree with you. My in laws are my non-tech bellwether. They use Comcast, and love it. It's zero maintenance, comes bundled with their cable, and provides in person customer support for almost any problem at all at no cost. They're paying more than they should for slow speeds. But they don't care about that. They don't know technology, and their connection plays YouTube and Facebook. reply thayne 15 hours agorootparentprev> But we also have AT&T That might be part of it. When I first moved in, Comcast was the only ISP available. Then the city got municipal fibre. Suddenly, comcast decided to lower prices, and increase speeds. I will say that it was still a pain to cancel my subscription when I switched to the new setvice, though. reply Retric 15 hours agorootparentprevThe underlying technology not the company itself is good enough most people don‚Äôt really complain once everything is set up. But for people moving to or from different areas Comcast really comes off much worse than most ISPs. You can notice differences in web browsing above and beyond what the highly gamed ‚Äúspeed tests‚Äù suggest. Wait times for a technician are somewhat region dependent, but it‚Äôs never great etc. Total prices are high even when they have some competition and get silly when they‚Äôre a monopoly. reply voidfunc 18 hours agorootparentprevBingo. You really need to take HN thoughts (or really any nerd haven) with a grain of salt when it comes to _anything_ tech. Lots of strong (often informed) opinions that grounded in a reality that does not exist for most people. reply kasey_junk 18 hours agoparentprevThere is competition in my area and I stay on it. Just as a counter anecdote. reply dmoy 17 hours agorootparentThere is competition in my area and it is way faster, and I did switch But the competition isn't great either, so I get why people don't. The modem/router the other company uses (can't use my own modem) is terrible and their support had no idea what I was talking about when I pointed to the DHCP table full of random shit that it wasn't freeing up, and logs full of DNS errors. And the wifi access points they provided were terrible too (free, but terrible). Eventually I worked around that by just adding my own router in the mix with a (internal 192.168) static IP, cut their DNS out of my router's list of DNS, and used my own wifi access points (which I had from Comcast days). After my third support call I got a tech who provided instructions on putting their router/modem combo into bridge mode, but I'm hesitant to actually go through with that because I have no confidence their support can unwind me if anything goes wrong. Like sibling points out, Comcast does offer faster download speed due to the competition. Still not as fast, but w/e. reply Sabinus 17 hours agorootparentprevThe service you receive is made better just by the presence of competition. reply bix6 17 hours agoprevCox tried to switch me to $100/mo for absolutely no reason. Same plan, etc. Another provider had recently entered my neighborhood taking my choices from 1 to 2. I threatened to switch and they kept me at $50/mo. Monopolies are bogus. reply saghm 9 hours agoparentI'm very unhappy with the only ISP option I have in my apartment. I'll get (physical) spam from other ISPs that don't even offer service in my building, and around once a year I check a ton of common ISPs to see if they've added service to my building, but they never have. Meanwhile, every few months there will randomly be outages in the middle of the day for a few hours, but they always claim after the fact that the outage was shorter than it actually was so I don't qualify for any refund. The one time I tried to chat with their customer service they lied to me about it and then somehow the message asking me \"is there anything else I can help with?\" didn't show up until several minutes after the timestamp that it showed, by which point it came with a follow-up saying they were closing the chat due to a lack of response. reply nijave 1 hour agorootparentMaybe your building has an exclusive contract with the only ISP available. That was the case with our last apartment. There was AT&T fiber running in front and the building was wired with cat5e. I can almost guarantee there was an AT&T fiber ran to a wiring closet somewhere but Spectrum (cable) had an exclusive servicing contract. reply stemlord 12 hours agoparentprevi had the same experience with fios over webchat with a customer service rep-- told them the price increase was too much for me and if there were no other options i'd have to go back to spectrum and they immediately opened up with my original rate again reply georgel 18 hours agoprevIt was interesting to see one of the commenters mention Fort Collins Connexion. I've mentioned them a few times on HN with lots of other locals chiming in, but that service was incredible. I was very sad when I moved to an older apartment complex that refused to allow the buildup and had to go back to Comcast for a year before I moved away. Comcast offered 1.2Gb/s down, which was real, but the second anyone did a small upload, the entire network bogged down to actually unusable speeds (read: HN wouldn't load at all). Cheaper and significantly better service from the municipal ISP than mega-corp. reply leguminous 17 hours agoparentThat sounds like bufferbloat[1]. You can usually address that by using a router that supports active queue management, but it's a little esoteric. Newer versions of DOCSIS also specify support for simple active queue management on the modem, and I think this has become a little bit better in recent years. I used to have Comcast/Xfinity service and they didn't do terribly with regard to bufferbloat. They didn't do well, either, but it used to be much worse. Some of the cable ISPs also have such asymmetric service that you can use most of the upload bandwidth just with ACKs while downloading. They often use ACK suppression to reduce the number ACKs and use the link more efficiently. [1] https://en.m.wikipedia.org/wiki/Bufferbloat reply nijave 1 hour agorootparentComcast is supposedly rolling out mid split to boost upload. Spectrum has already rolled out high split in some markets reply tengwar2 16 hours agoprevOne thing I like about the UK is the concept of regulated competition. The purpose is to ensure that there is always a competitive market place - so for instance in Internet technology, wholesale provider provides DSL layer 1/2 to multiple ISPs, who provide the PPPoA/E termination and value added services (e.g. email). There is often other technology available to the same addresses - cable, FTTP. The result is that for most addresses there is a choice of about 200 ISPs. The one I use (Andrews and Arnold) is expensive, but I have a /28 and a /48, I can run servers, the line is monitored once every second using their custom-build hardware, and I've had them ring me to say there is a fault on the line which will be cleared within half an hour. Also they implement the Shibboleet protocol. I pay for this, and for most consumers it would not be worthwhile - but that's the point. There is genuine competition with real differentiation between ISPs. reply aembleton 9 hours agoparentSmall fibre companies have also been allowed to use Open Reach ducts and telegraph poles to speed up the fibre roll out. This has meant I've been able to get FTTP before Open Reach had brought it to my village. reply enlyth 15 hours agoparentprevI see that A&A have finally started offering uncapped data plans since August, good on them, since that originally put me off and I never signed up with them despite all the praise they get on HN reply sudb 6 hours agorootparentI've been a customer of A&A for a few years - I had the same reticence at first but thought I'd try them anyway. The only time I've come close to the 1TB monthly usage quota is this month, entirely because (for work) I had to download a very large number of docker images, in addition to a normal usage of 500-750GB. I think it helps that some unused portion of the usage quota gets rolled over too. Out of curiosity, what are you doing that would make you regularly exceed 1TB? reply enlyth 5 hours agorootparentI don't think I'm doing anything crazy, the odd game from steam, some ML models from huggingface, running a Plex server for myself and friends/family. I checked my usage and regularly exceed 1TB every month, so that's why I was put off. I've been lucky that a new ISP came to my area and I can avoid Openreach infrastructure completely, they've put a FTTH line directly into my house and offer up to 8Gbps symmetrical reply elmerfud 17 hours agoprevI don't switch my ISP because of their excellent customer service, instead I keep them because I have no idea how good their customer service is. When you need to know how good a company's customer service is that means the company has already failed at some level in the delivery. reply Yeul 11 hours agoparentExactly my thoughts. I've never had to get into contact with my ISP. If it works it works. reply skygazer 16 hours agoprevWhen I had a single ISP, I hated them for the downtime. I switched ISPs and also felt the same, for the same reason, of the new one. Now I have two ISPs, and because their respective occasional outages haven't overlapped, I'm generally fine with both, even though they've each continued to have outages. Not noticing outages has made all the difference. reply jebarker 18 hours agoprevThe best feature Comcast has added in recent years is the ability to request a $5 bill credit each time there's an outage. I use it more months than not. I suppose that's good customer service although it'd be better if it wasn't needed. reply thaumasiotes 17 hours agoparentHow recent is that? More than a decade ago, my friend related to me how his grandmother was subscribed to cable TV through comcast, but one channel wasn't working. And every day, she'd call them to complain about the one channel that didn't work, and they'd apply a minor credit to her bill. reply jebarker 17 hours agorootparentAs far as I'm aware the \"self-service\" version of it on their website is in the past year. I think you're right that it's been possible over the phone for a long time though. reply rascul 13 hours agoprevAT&T took gov money to lay fiber years ago and never lit it up. Centurylink will only offer me 6Mbps DSL. A few years ago my electric coop spun up a for profit ISP and ran fiber to all their customers and provides reliable service and decent speeds. Customer service has nothing to do with it. reply protocolture 18 hours agoprevThere's more to running a good ISP than support. Good service is a bigger driver than customer service. And expectation management is a total lifecycle thing, if you let customers set their own expectations then the service is probably trash by default and your customer support staff will get the blame. The solutions I see are 2 fold. 1. ISP gets completely involved in your home network, any kind of point of demarcation is completely scrapped in favour of optimising your home wifi. 2. ISP provides the best service they possibly can within reason, has good expectation management and is very firm with their demarc. 3. large scale provider with some kind of physical or regulated monopoly and the end users can smoke meat cigars. 1 has very diminishing returns. If you have 300 subscribers and only 5 of them are on dodgy links, you can get very involved with your customers network issues. But this doesnt scale, and when you try to scale you have left customers with all sorts of expectations. Its hard to package too, because theres a push to end call out fees. If you are rolling truck for \"Why facebook slow\" it can literally end your business. reply freeone3000 18 hours agoparentLots of ISPs (at least the Bell and Telus rebrands) are now doing remote-managed ‚Äúhome hubs‚Äù with integrated wifi that can be remote managed by the ISP. This solves the call-out problem and also fixes user expectations ‚Äî and they‚Äôre leased not sold, so they can actually be good wifi devices. I don‚Äôt personally use them, because ‚ÄúISP managed wifi‚Äù sounds like a bad idea to me, but I can see the value to people who can‚Äôt distinguish the above two terms. reply nijave 1 hour agorootparentAssuming the ISPs equipment works correctly. AT&T fiber in the U.S. has apparently had issues for months with a few patches to stabilize things. My Tp-Link Omada AP has better coverage and speed. I setup my parents up with edgerouterx and Tp-Link AP and it's been hands off for the last 1+ years. If ISPs can actually offer decent equipment I think it's a win but that seems like more the exception than norm. Reasonably priced prosumer and small business equipment has been way more stable in my experience. reply protocolture 15 hours agorootparentprevYeah I worked with one of those, a few months after I stopped playing with it, the company dropped the product entirely. Considering it could only be managed through their portal I saw lots of teeth gnashing from providers who had significant numbers in production. > but I can see the value to people who can‚Äôt distinguish the above two terms. The issue is that you have both as customers. And having multiple packages with different price points can cause headaches. You really need \"Bad customer brand\" with phat packages for people who cant use tech and \"good customer brand\" that offers a good service with little to no support. And keep them separate as possible. reply Sabinus 17 hours agorootparentprevAs long as it's optional and they still allow BYOD it's a good solution for some customers. reply freeone3000 3 hours agorootparentBYOD barely existed for cable (since DOCSIS specifies ISP remote management as part of the spec) and doesn‚Äôt exist at all for fiber. If you mean your own router: yeah, I do that, they don‚Äôt support it but there‚Äôs no real way to stop me? I do end up double-NAT‚Äôd but my real router is DMZ‚Äôd so there‚Äôs no practical issue‚Ä¶ until they start issuing IPv6. reply o11c 12 hours agoparentprevThe problem with \"ISP gets into your home network\" is that that locks the user out of a lot of important diagnostic tools on the router. I can't even view what kind of configuration it has. reply kwar13 16 hours agoprevIt's true. When I was in jail I also stayed because of the excellent wardens! reply justinclift 8 hours agoprevHere in Australia I've found (so far) only one ISP that's actually really, really good with good customer service: https://www.launtel.net.au They have super high review scores for good reason. :) https://www.productreview.com.au/listings/launtel Most other ISPs over here are the same kind of crap that you see in the article. Lots of PR and weasel words with crap service, support, and race-to-the-bottom pricing. Ugh. Well, the US doesn't seem to have race-to-the-bottom pricing, but all the other bits apply. --- Note that I've only used Launtel for residential internet, not business grade service. No idea how they are for business stuff. reply synack 18 hours agoprevIf I have to interact with your customer service, I‚Äôm already thinking about cancelling. Your net promoter scores are worthless. reply mrbluecoat 16 hours agoprevWe named our first child after our ISP, their customer service was that good reply WD-42 18 hours agoprevI went to return an old modem to Spectrum in the Central Coast, CA a few weeks ago. I showed up to the store with it all packed up nice and ready to go. Employees there directed me to a tablet on a stand at the entrance and told me to enter my name into the waiting list. I told them I was just dropping off the box. Nope. gotta sign in. Ok... one hour later they finally call me up (I have my infant baby in a stroller with me, luckily she didn't get fussy). Dude literally scanned the box with a barcode scanner, said thank you, and sent me on my way. Took less than 30 seconds. It was hard not to interpret this is an ISP power move. If I could go anywhere else I would. reply nijave 1 hour agoparentThey allow e-check in... Except for equipment return... At least they print a receipt with the unit MAC/serial as proof it's been returned. reply lupusreal 18 hours agoparentprevWhen I turned in a modem and set-top box to Comcast, they just chucked it into a bin behind the desk and said that was it. No scanning or otherwise recording any of it. I demanded they fish it all back out so they could write me up a receipt, because I don't trust those bastards to claim I never returned that stuff. To the workers credit, he did do that. Albeit with an incredible eyeroll. reply zachlatta 18 hours agorootparentI had this happen with Verizon, I insisted on a receipt, which they handwrote for me. Then they told me I never returned the device and charged me! Couldn't get through to anyone, no replies. I refused to pay. They sent it to debt collection, no matter how many times I sent the picture of the receipt they refused to take it. Took me 2 years to get it off my credit report, including sending multiple letters via certified mail. Caused my credit to go down by 100 until it finally disappeared and went back to normal. They. Are. The. Worst. reply rogerrogerr 17 hours agorootparentThis sounds like a case where consulting a lawyer might actually be useful‚Ä¶ reply mlyle 13 hours agorootparentIt could be, but you're not going to get into a situation where you recover attorney's fees. So you're in a position where you can either handle it yourself and grind it out, or you can pay a lawyer an indeterminate amount to fix it-- probably just enough for a letter, but that may not even do the trick. Suing in small claims is an option, though. You might recover something, and you'll certainly cause Verizon to incur expenses. reply latexr 6 hours agoprevThis reminded me of South Park‚Äôs take on cable companies. NSFW, it‚Äôs South Park. https://www.youtube.com/watch?v=vbHqUNl8YFk reply thomond 7 hours agoprevNorth Korea says their excellent Human rights is reason for low emigration rate. reply yuters 15 hours agoprevIn Canada, the large telcos are being regulated by the CRTC (Canada's FCC) and one recent regulation is forcing them to sell wholesale access to their fiber networks to smaller competitors. You think this would be a good thing, but the CRTC wholesale rates in that regulation are higher than what the big telcos are directly charging to their customers, which makes the smaller competitors unable to compete on price. I've been shopping around these small providers, and a lot of them have recently been acquired by the big telcos. reply euroderf 9 hours agoprevHelsinki offers a choice of ISPs thruout the metro area. So obv no one individual ISP laid all that cabling. I'm not sure how it was all organised & financed. Maybe someone who knows more can comment. Olkaa hyv√§. reply kittikitti 5 hours agoprevI only have one real option even nearby a high population density area, Comcast. reply TylerJaacks 15 hours agoprevI previously had on of the major ISPs in my State/Region and it was aweful, they suck. Then a relatively new company came in and I switched and it was finally fiber and cable and it is amazing. Its not perfect these are companies at the end of the day. But if it weren't for this new company I would be forced by no competion not because of the service of the ISP. reply netik 12 hours agoprevfull of lies. for example, in downtown SF the options are few and far between. there is comcast for high speed, and well‚Ä¶ there is comcast. If you want slow bonded DSL you can go to Sonic. Or At&T. Only recently has LTE become fast enough to make home Internet over LTE an acceptable alternative reply Swizec 18 hours agoprevI want to talk to my ISPs customer service about as much as I want to talk to my municipal water supply‚Äôs customer service. Just work, damn it. reply 0xbadcafebee 17 hours agoprevThat must be why they all lobby against municipal wifi. They must know the service would be better, so we'd all switch. reply Yeul 17 hours agoprevFor me its really simple: an ISP is a utility. As long as the connection works I don't even think about it. Why go through the hassle of changing it? Have to change modems and all that stuff. I've extended my contract for another 2 years because I have no complaints. reply hilbert42 7 hours agoprevGoebbels never told lies that big! Edit: but likely they learned his techniques. reply popol1991 17 hours agoprevThey are just equally bad at customer service that most people don't even bother. reply casenmgreen 7 hours agoprevBlack is white, weak is strong, ISPs have great customer service. reply bhaney 17 hours agoprevSpectrum used to have a monopoly in my area, so I was stuck with their 15mbps speeds and constant outages. When Google Fiber became available here, I immediately subscribed to it (it was significantly cheaper for gigabit speeds). As soon as the fiber was set up, I called Spectrum to cancel my account, and after being bounced around between a couple support people, I was finally transferred to retention where I could have my account properly closed. Except instead of a person, I got a machine telling me that the department was closed for the day, and I should call back Monday (this wasn't even late on a weekend, it was midday Friday). I called back to ask what was wrong and why I was transferred to an empty department, and the support rep told me the last rep should have known and shouldn't have transferred me there, but I would indeed need to wait until Monday. Fine. Monday I call back, get through the layers of reps, and am finally told that they're having an internal outage and won't be able to cancel my account, but they assured me that if I incur any additional charges on my bill because of the delay, they'll be happy to remove them. I don't know how long this \"outage\" is going to last, so I wait a couple days and call back again, very quickly get transferred to where I need to be, and with no pushback or excuses whatsoever get told my account is now cancelled and my bill is all settled up, and to have a good day. Great. I cancel the virtual credit card I used to pay them, since I no longer need it. A month later I get a text from Spectrum telling me they aren't able to bill me, and my service will be interrupted if I don't pay this new bill. I call and support tells me that my account is cancelled, I owe nothing, and to ignore the text. I do make some efforts to verify that the text is actually from Spectrum, and it does seem to be. No indications of a spammer impersonating Spectrum. The next month it happens again, and this time when I call I'm told my account is not cancelled and my service has been suspended because I now owe a couple months of payment plus late fees, and they won't be able to cancel my account until I pay those. They have no record of me cancelling my account, and unfortunately the manager who has the authority to waive the late fees is out today. I'm offered the opportunity to pay the full amount of bogus charges, and wished a good day when I decline. Every month since then they've texted me to let me know that another payment for the month hasn't gone through. Lately the texts have started saying that they will be sent to collections. Part of me hopes they take me to court over it. I think if you asked Spectrum, they would tell you that I'm still a customer of theirs, and that I'm sticking with them because of their excellent customer service. reply Arubis 15 hours agoprevWhen last I had checked, Comcast had a lower customer approval rating than United Airlines. You know, the punch-a-doctor-in-the-face, drag-him-off-the-flight folks. reply bastard_op 18 hours agoprevThis could be easily summed up with a public poll with one question, \"Would you switch ISP if you had a better option?\" My thought is somewhere around 98% would say yes, if not 99 and some points. reply lcnPylGDnU4H9OF 18 hours agoparentWhat does this not apply to? Would you have picked a different option if you had a better option? reply rogerrogerr 18 hours agorootparentThat‚Äôs not the question, though - it‚Äôs would they switch. Switching has significant friction, at least in people‚Äôs minds. You probably wouldn‚Äôt switch from ISP1 at $30/mo to ISP2 at $29.95/mo (with the same service) unless you‚Äôre irritated with ISP1 for other reasons. You might have chosen ISP2 if you were starting from scratch, though. reply drekipus 18 hours agorootparentSo what does \"better option\" imply? reply rogerrogerr 14 hours agorootparentBetter enough to overcome the switching cost. reply latexr 6 hours agorootparentSo you agree the question is meaningless. If ‚Äúbetter‚Äù means ‚Äúbetter enough to overcome the switching cost‚Äù, then the answer to ‚Äúwould you switch ISP if you had a better option?‚Äù would by definition always be yes. reply scubbo 17 hours agoprevI recognize that the title is intended to be tongue-in-cheek, but I'm one individual for which it's genuinely true. Sonic[0] has the best customer service of any company ever encountered, and it's not even close. The few times I've had to contact them for assistance, I've been very quickly connected with someone clearly _very_ technical who was able to grok my problem immediately and give clear, cogent, respectful debugging advice and perspective. I do not exaggerate when I say I would gladly pay double their current rate just for the peace of mind of knowing that I can depend on them if I ever need their support again. Not that I often do, because their baseline connectivity/speed is also great. ...yes, I know I look like a shill/bot. I don't care. They're genuinely just that good, and I will happily advocate for them until that ever changes. [0] https://www.sonic.com reply sprayk 18 hours agoprevIn my case, Comcast has a city government-granted monopoly to provide broadband, so they are my only choice (without going to a WISP/Starlink) reply toast0 13 hours agoparentExclusive municipal franchise agreements have been prohibited since the Cable Television Consumer Protection and Competition Act of 1992. Your city cannot unreasonably refuse to grant a franchise to another operator, in the unlikely event another operator would like to provide a similar service. These things used to be a government-granted monopoly, but IMHO, the continuing lack of competition stems from market realities. Building a new network in a city that's already covered adequately is hard to justify economically, because switching is a pain, and most of the market can't really tell the difference between providers; and even if you do start to attract customers, the competitor's network likely gets better as you relieve their bottlenecks. Targeting only the areas of the city that aren't well served is likely to not be economically viable either. For one thing, the franchise agreement might have a minimum coverage percent. For another, there are probably reasons the other network doesn't cover those areas; some of which may still apply. And there's the elephant in the room, the incumbent presumably has enough revenue from other areas that they can cross-subsidize network updates and build out to compete where you are. In some ways, this was Google Fiber's market strategy: Google Fiber's corporate goal was to get more people connected at high speeds so that they could load higher quality ads on YouTube and other Google properties. Building out fiber in the Kansas Cities was a way to meet that goal in those cities, but it was a lot of work. By announcing planned cities in early 2014 [1], Google was able to induce incumbents to improve their networks in those cities, reaching their goal before any Google Fiber permits were approved in those cities; then they could wrap it up and end all expansion works. :P [1] https://blog.google/alphabet/exploring-new-cities-for-google... reply tptacek 18 hours agoparentprevWhich city? reply blinded 18 hours agoprevLack of competition is the answer. There is only 1 provider that can give me 1g or more. ISPs are out of touch. reply tonetegeatinst 17 hours agoparentExactly. Few ISP's offer fiber. Very few ISP's will offer data center speeds. I am yet to find an ISP that offers over 5gig or for an affordable price. reply toast0 13 hours agorootparentThere's plenty of ISPs that offer over 5gig for an affordable price. You just need to live in a datacenter near an internet exchange. :) reply plagiarist 17 hours agoprevNo, it is because there is literally nothing to switch to. The costs of infrastructure are too great to have real competition. And on top of that they also sue anyone who tries. They are parasites. Other countries have fast internet at reasonable prices without weird data caps. I hope they get regulated and forced to lease out the \"last mile\" at cost. I'd like them to get eminent domained for stealing taxpayer money on lies that they would build infrastructure. Unfortunately we are instead looking at four years of deregulation. A huge gift to these massive assholes. reply donw 18 hours agoprevComcast has to be supplying their people with bulk lots of experimental aerospace-grade ganga if they can say this without immediately bursting into laughter. reply allears 18 hours agoparentI'm sorry, if that were me the ganga would make me more likely to break up, not less reply bigstrat2003 17 hours agoparentprevI assume they just hire sociopaths for this sort of PR role. That way the employees will have no issues with lying through their teeth, and the company doesn't need to spend money on weed. reply ginkgotree 16 hours agoprevI laughed out loud at this. Thanks for the laugh. reply dec0dedab0de 16 hours agoprevthey‚Äôre right, that‚Äôs why I switched to tmobile when my old job stopped paying for internet. I would get dialup before paying any money to comcast reply gigatexal 12 hours agoprevMy 70 year old mom who lives alone and whose only company is really her TV went nearly 5 weeks without tv or internet when some construction cut the line (or something near her place). Who is her provider? Comcast. Why did it take so long? Anybody‚Äôs guess. But was the customer service so amazing? No. Hahah. No. They‚Äôre just the only game in town. Monopolies suck for this reason. reply linotype 16 hours agoprevWhat other providers? reply mproud 12 hours agoprevHahahahahaha reply User23 15 hours agoprevThe funny thing is that telco customer service is in fact orders of magnitude better than it was in the monopoly days. Ma Bell was ruthless. reply ClassyJacket 16 hours agoprevI don't switch providers because thanks to the Liberal Party of Australia choosing copper phone lines instead of fibre for the NBN, no matter which provider I choose I'm stuck with 25mbps that doesn't work at all when it's raining. Details don't matter much when no matter what that's the best you can ever get, enforced by law. reply protocolture 15 hours agoparentI mean, if we were still on the fibre rollout you might still be waiting for fibre anyway. Are you sure you have no alternatives? NSW has a few ok to good wireless providers. reply jaimex2 16 hours agoprevYou should see the mess we have in Australia. I think most people churn every 6 months as every ISP does the same stupid 30% off for first 6 months deal. It's all the same national network so there's very little difference between ISPs. reply protocolture 15 hours agoparentIt has more to do with the cost of accessing that network. Bevan Slattery used to do a yearly Commsday presentation where he would tear the NBN economics up live on stage. Basically after getting the service from NBN to the provider, theres basically nothing left over for the provider to use for support, transit, peering, hardware whatever. reply dbg31415 17 hours agoprevNorth Korea has elections too! reply m3kw9 17 hours agoprevExcellent customer service for an ISP is no service. Your internet speeds don‚Äôt deviate I don‚Äôt call you. Otherwise I go for the lowest price and if your agree to a low price, your customer service is good. reply nobody9999 18 hours agoprevMy ISP (Spectrum business, not even the consumer end) can't even get me logged in to my account so I can manage my service. Multiple calls, same results. And they keep jacking up the price too. Astound, here I come! reply ocdtrekkie 17 hours agoparentAstound has worked really hard to lose my business, I moved to Comcast not too long ago. Astound also now stiffs you for the full billing month when you cancel, FYI, so if you make the mistake of switching away from Astound two days into your billing cycle, they'll try to collect the other 28 days as pure profit. reply nobody9999 15 hours agorootparent>Astound has worked really hard to lose my business, I moved to Comcast not too long ago. Astound also now stiffs you for the full billing month when you cancel, FYI, so if you make the mistake of switching away from Astound two days into your billing cycle, they'll try to collect the other 28 days as pure profit. Thanks. That's good to know. Sadly, Spectrum and Astound are the only two ISPs in my apartment building. Despite Verizon putting cell towers on the roof and repeated requests (not to mention having it in other buildings on my street), they have not made FIOS available to me and the other residents of my buiilding. Sigh. reply dcmatt 17 hours agoprevYeah, because every time I call they give me a new \"deal\" and lower my bill by $10 a month. reply delichon 18 hours agoprev [‚Äì] > The lobby groups' description may surprise the many Internet users suffering from little competition and poor customer service ... Starlink is the best internet service I've ever had, so I'm able to restrain my tears for the poor suffering users who only have that alternative. reply protocolture 15 hours agoparentStarlink is extremely variable. Its hard to overstate how little your satisfaction with the service is representative. I have had Starlink under 10/10 with frequent dropouts, and over the rated maximum capacity depending on geographical location. reply dylan604 18 hours agoparentprev [‚Äì] Starlink is 2x per month as my ATT fiber account. Can't compare speeds since Starlink's website doesn't show speeds with monthly pricing. I doubt it's 2x the speed reply delichon 17 hours agorootparent [‚Äì] I just speed tested my Starlink connection at 93 Mpbs down, 9.3 Mpbs up. That's slower than usual but better than 10x the speed I was getting from a rural telco, and it has been more reliable too, for about the same price. What am I missing out on from a faster connection? reply dylan604 17 hours agorootparentI get 1gbps up/down for ~$74/month. So Starlink is 1.7x for much less speed. The only way Starlink looks attractive to me is if living off the grid and its the only option. By the time I'm no longer paying for utilities, the increased for less performance will not be as expensive. That's not happening any time soon reply bigstrat2003 17 hours agorootparentprev [‚Äì] I looked at the Starlink website and it looks like residential service is $120/mo. I pay less than that ($110/mo) for 1 Gbps down and 40 Mbps up from Comcast. They also give me a public v4 IP, not CGNAT like Starlink. My service is quite reliable (I would say I have a few hours' downtime once every year or two), so that part is a wash. The one advantage Starlink has is they offer a /56 to IPv6 customers, not just a /60 that Comcast does. Obviously it varies significantly based on where you are. Different ISPs are different, and even the same provider might be good in one region and bad in another. But for me at least, Starlink would be a terrible choice. They are worse in most every way (sometimes significantly so), and only better in one way. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ISP lobby groups argue that competition ensures high customer service standards, making additional regulations unnecessary, as poor service would drive customers to switch providers.",
      "Regulators in California and Oregon report widespread customer dissatisfaction, highlighting issues such as long hold times and billing problems, contradicting ISP claims.",
      "The FCC is reviewing customer service practices, but with Brendan Carr's leadership, appointed by President-elect Trump, new regulations are unlikely, as the focus shifts towards reducing regulatory burdens."
    ],
    "commentSummary": [
      "ISPs attribute customer retention to their \"excellent customer service,\" but many believe it's due to a lack of competition in certain areas.",
      "In regions with limited ISP options, users often remain with their current provider despite dissatisfaction with service quality.",
      "Efforts in countries like Australia and Canada to regulate the market and boost competition face ongoing challenges, with users calling for genuine competition and improved regulation."
    ],
    "points": 173,
    "commentCount": 118,
    "retryCount": 0,
    "time": 1732666465
  },
  {
    "id": 42256093,
    "title": "Recommendation for a SWE looking to get up to speed with latest on AI",
    "originLink": "https://news.ycombinator.com/item?id=42256093",
    "originBody": "I am looking to get up to speed with the latest things happening in AI, I use ChatGPT almost everyday and i last used the open AI api for 3.5 last year. I am looking for a tech blogs like HN to keep updated on things AI, I came across https:&#x2F;&#x2F;simonwillison.net&#x2F; but it appears fragmented",
    "commentLink": "https://news.ycombinator.com/item?id=42256093",
    "commentBody": "Recommendation for a SWE looking to get up to speed with latest on AI138 points by Rizu 5 hours agohidepastfavorite62 comments I am looking to get up to speed with the latest things happening in AI, I use ChatGPT almost everyday and i last used the open AI api for 3.5 last year. I am looking for a tech blogs like HN to keep updated on things AI, I came across https://simonwillison.net/ but it appears fragmented pdevine 4 hours agoThe poster's looking for articles, so this recommendation's a bit off the mark. I learned more from participating in a few Kaggle competitions (https://www.kaggle.com/competitions) than I did from reading about AI. Many folks in the community shared their homework, and by learning how to follow their explanations I developed a much more intuitive understanding of the technology. The first competition had a steep learning curve. I felt it was worth it. The application of having a specific goal and the provided datasets made the problem space more tractable. reply rpastuszak 3 hours agoparentOut of sheer curiosity, how much time did you spend on it on average? How much of this knowledge are you using now? reply hzay 3 hours agorootparentNot the poster you responded to but I learned quite a bit from kaggle too. I started from scratch, spent 2-4 hrs per day for 6 months & won a silver in a kaggle NLP competition. Now I use some of it now but not all of it. More than that, I'm quite comfortable with models, understand the costs/benefits/implications etc. I started with Andrew Ng's intro courses, did a bit of fastai, did Karpathy's Zero to Hero fully, all of Kaggle's courses & a few other such things. Kagglers share excellent notebooks and I found them v helpful. Overall I highly recommend this route of learning. reply Foobar8568 3 hours agorootparentI was playing also on kaggle a few years back, similar feedback. reply solardev 3 hours agorootparentprevThanks for the detailed reply! reply swyx 1 hour agorootparentprevi mean yes but also how much does kaggling/traditional ML path actually prepare you for the age of closed model labs and LLM APIs? im not even convinced kaggling helps you interview at an openai/anthropic (its not a negative, sure, but idk if itd be what theyd look for for a research scientist role) reply hzay 14 minutes agorootparentI learned ML only to satisfy my curiosity, so I don't know if it's useful for interviewing. :) Now when I read a paper on something unrelated to AI (idk, say progesterone supplements), and they mention a random forest, I know what they're talking about. I understand regression, PCA, clustering, etc. When I trained a few transformer models (not pretrained) on my native language texts, I was shocked by how rapidly they learn connotations. Unets, GANs, etc were very cool too. I don't find transformer-based LLMs \"magical\". Very useful, yes, but not unsettlingly AGI-like, as I did before learning. I understand the usual way of building recommender systems, embeddings and things. So yeah, idk what they do in interviews nowadays but I found my education very fruitful. reply drcwpl 4 hours agoprevSimon's blog is excellent for an SWE For a general audience - https://www.ai-supremacy.com/?utm_source=substack&utm_medium... Fromm inside the AI Labs - https://aligned.substack.com/ https://milesbrundage.substack.com/ for swe - https://artificialintelligencemadesimple.substack.com/ reply drcwpl 4 hours agoparentalso https://magazine.sebastianraschka.com/p/understanding-multim... reply zackmorris 35 minutes agoprevLLMs and neural nets from first principles: https://arxiv.org/pdf/2404.17625 (pdf) https://news.ycombinator.com/item?id=40408880 (llama3 implementation) https://news.ycombinator.com/item?id=40417568 (my comment on llama3 with breadcrumbs) Admittedly, I'm way behind on how this translates to software on the newest video cards. Part of that is that I don't like the emphasis on GPUs. We're only seeing the SIMD side of deep learning with large matrices and tensors. But there are at least a dozen machine learning approaches that are being neglected, mainly genetic algorithms. Which means that we're perhaps focused too much on implementations and not on core algorithms. It would be like trying to study physics without change of coordinates, Lorentz transformations or calculus. Lots of trees but no forest. To get back to rapid application development in machine learning, I'd like to see a 1000+ core, 1+ GHz CPU with 16+ GBs of core-local ram for under $1000 so that we don't have to manually transpile our algorithms to GPU code. That should have arrived around 2010 but the mobile bubble derailed desktop computing. Today it should be more like 10,000+ cores for that price at current transistor counts, increasing by a factor of about 100 each decade by what's left of Moore's law. We also need better languages. Something like a hybrid of Erlang and Go with always-on auto-parallelization to run our human-readable but embarrassingly parallel code. Short of that, there might be an opportunity to write a transpiler that converts C-style imperative or functional code to existing GPU code like CUDA (MIMD -> SIMD). Julia is the only language I know of even trying to do this. Those are the areas where real work is needed to democratize AI, that SWEs like us may never be able to work on while we're too busy making rent. And the big players like OpenAI and Nvidia have no incentive to pursue them and disrupt themselves. Maybe someone can find a challenging profit where I only see disillusionment, and finally deliver UBI or at least stuff like 3D printed robots that can deliver the resources we need outside of a rigged economy. reply Maro 4 hours agoprevI don't think it's a good idea to kepp up to date at a daily/weekly cadence, unless you somehow directly get paid for it. It's like checking stocks daily, it doesn't lead to good investment decisions. It's better to do it more batchy, like once every 6-12 months or so. reply Luc 4 hours agoparentHow do you do that? Once you're out of the loop for half a year, it becomes harder to know what's important and what's not, I think. reply pilotneko 3 hours agorootparentEvery release is novel. Once something has been around for a while and is still being referenced, you know it‚Äôs worth learning. Waiting 3-6 months to take a deep dive is a good pattern to prevent investing your time in dead-end routes. reply SoftTalker 2 hours agorootparentYes this is why I never buy the latest CPUs and try to never run the latest release of any software. Stay a (supported) release or two behind the bleeding edge, and you'll find stuff is more stable. Common bugs and other issues have been shaken out by the early adopters. reply swyx 1 hour agorootparentprevmy conference is currently run on a 6 month batch https://www.youtube.com/@aidotengineer and is curated by me/my team. hope that helps people keep up on the video/talk-length form factor (as in, instead of books, though we also have 2-3 hour workshops) reply Maro 1 hour agorootparentprevSome ideas: 1. Buy O'reilly (and other tech) books as they come out. This will have a lag, but essentially somebody did this research & summarization work, and wrote it up for you in chapters. Note that you don't have to read everything in a book. Also, $50 is a great investment if it saves you 10s of hours of time. 2. Talks on Youtube at conferences by industry leaders, like Yann LeCun, or maintainers of popular libraries, etc. Also, YT videos on the topic that are upvoted/linked. 3. If you're interested in hardcore research, look for review articles on arxiv. 4. Look at tutorials/examples in the documentation/repo of popular ML/AI libraries, like Pytorch. 5. Try to cover your blindspots. One way or another, you'll know how new AI is applied to SWE and related fields. But how is AI applied to perpendicular fields, like designing buildings, composing music, or balancing a budget? Trying to cover these areas will be tougher, because it will be more noisy, as most commenters will be non-experts compared to you. To get a feel for this, do something that feels unnatural, like watch TED talks that seem bullshity, read HBR articles intended for MBAs, and check out what Palantir is doing. reply fallinditch 2 hours agoprevNew short course on FreeCodeCamp YouTube channel looks good - Ollama Course ‚Äì Build AI Apps Locally https://youtu.be/GWB9ApTPTv4?feature=shared As an aside, does anyone have any ideas about this: there should be an app like an 'auto-RAG' that scrapes RSS feeds and URLs, in addition to ingesting docs, text and content in the normal RAG way. Then you could build AI chat-enabled knowledge resources around specific subjects. Autogenerated summaries and dashboards would provide useful overviews. Perhaps this already exists? reply A4ET8a8uTh0 2 hours agoparent<< there should be an app like an 'auto-RAG' that scrapes RSS feeds and URLs, I am not aware if that exists yet, but the challenge I see with it is rather simple: you get overwhelmed with information really quickly. In other words, you would still need human somewhere in that process to review those scrapes and the quality of that varies widely. For example, even on HN it is not a given a link will be pure gold ( you still want to check if it fits your use case ). That said, as ideas goes, it sounds like a fun weekend project. reply be_erik 5 minutes agorootparentI do exactly this with hoarder. I passively build tagged knowledge bases with the archived pages and then feed it to a RAG setup. reply senko 1 hour agoprevI follow these: * Matt Berman on X / YT * AI-summarized AI news digest: https://buttondown.com/ainews by swyx * https://codingwithintelligence.com/about by Rick Lamers Then I manually follow up to learn more about specific topic/news I'm interested in. reply swyx 1 hour agoparentthanks for following! i admire the youtubers a lot and often wonder if i should be venturing into that domain. youtube takes a lot of work but also has the greatest reach by far. reply throwup238 3 minutes agorootparentIf you do please do it like PracticalEngineering with a full text transcript in article form. reply adroitboss 4 hours agoprevThe best place for the latest information isn't tech blogs in my opinion. It's the stable diffusion and local llama subreddits. If you are looking to learn about everything on a fundamental level you need to check out Andrej Karpathy on YouTube. There other some other notable mentions in other people's comments. reply BillFranklin 2 hours agoprevI read about 30 LLM papers a couple months ago dated from 2018-2024. Mostly folks are publishing on the ‚Äúhow do we prompt better‚Äù problem, and you can kind of get the gist in about a day by reading a few blogs (RAG, fine tuning, tool use, etc). There is also more progress being made for model capabilities, like multi modality, and each company seems to be pushing in only slightly different directions, but essentially they are still black boxes. It depends what you are looking for honestly ‚Äúthe latest things happening‚Äù is pretty vague. I‚Äôd say the place to look is probably just the blogs of OpenAI/Anthropic/Genini, since they are the only teams with inside information and novel findings to report. Everyone else is just using the tools we are given. reply handzhiev 1 hour agoprevFor news-like content I follow accounts on X: @kimmonismus @apples_jimmy and the accounts of Antropic, Mistal, Gemini / DeepMind and OpenAI. I think everyone who is really interested in the hot AI developments must also follow what comes from China. I follow https://chinai.substack.com/ but I am open to hear about other Chinese resources. reply iamwil 2 hours agoprevLots of people can get impressive demos up and running, but if you want to run AI products in production, you're going to have to do system evals. System evals make sure your product is doing what it says on the box with unquantifiable qualities. We wrote a zine on system evals without jargon: https://forestfriends.tech Eugene Yan has written extensively on it https://eugeneyan.com/writing/evals/ Hamel has as well. https://hamel.dev/blog/posts/evals/ reply aaronrobinson 2 hours agoprevWhat a goldmine of recommendations. I like Sam Witterveen‚Äôs YouTube stuff for keeping up to speed https://m.youtube.com/@samwitteveenai reply fourside 2 hours agoparentMy issue with YouTube channels that focus on AI news is that they‚Äôre heavily incentivized to give you a frequent stream of attention-grabbing news. Week-by-week updates aren‚Äôt that helpful. It‚Äôs easy to miss the bigger picture and there‚Äôs too much content to feel like a good use of time. reply Rizu 1 hour agorootparentI agree with this statement, most YouTube channels are incentivized to keep repeating the same trivial information like how to compose prompts etc reply aaronrobinson 59 minutes agorootparentCompletely agree in general, but his are not that. Yes he talks about recent stuff but it‚Äôs very considered and not attention or influence seeking IMO reply danofsteel32 3 hours agoprevI recently wrote a post for a coworker who asked the exact same question. https://dandavis.dev/llm-knowledge-dump.html reply zellyn 4 hours agoprevSimon's blog is fragmented because it's, well, a blog. It would be hard to find a better source to \"keep updated on things AI\" though. He does do longer summary articles sometimes, but mostly he's keeping up with things in real time. The search and tagging systems on his blog work well, too. I suggest you stick his RSS feed in your feed reader, and follow along that way. Swyx also has a lot of stuff keeping up to date at https://www.latent.space/, including the Latent Space podcast, although tbh I haven't listened to more than one or two episodes. reply swyx 2 hours agoparentthanks! i also have a daily news recap here https://buttondown.email/ainews/archive/ reply JSDevOps 2 hours agoprevFirst thing you need to do is change your LinkedIn to ‚ÄúAI evangelist‚Äù then go to your boss and say I want triple the pay. Then let the chips fall where they may. Oh also rename all your GitHub or personal projects to have AI in the name. You don‚Äôt actually have to do much else. reply goosethe 1 hour agoprevhttps://playground.tensorflow.org/ this is a classic which, imo, breaks it down to the simplest visuals. reply mavelikara 2 hours agoprevI found video lectures of ‚ÄúAdvanced NLP‚Äù course by Mohit Iyer very useful to get me started: https://people.cs.umass.edu/~miyyer/cs685/ reply AlphaWeaver 4 hours agoprevAs I was building up my understanding/intuition for the internals of transformers + attention, I found 3Blue1Brown's series of videos (specifically on attention) to be super helpful. reply galangalalgol 4 hours agoparentThis has been good for me, but it is more foundation than what is the latest. https://www.mattprd.com/p/openai-cofounder-27-papers-read-kn... reply notslow 3 hours agoprevMachine Learning Mastery (https://machinelearningmastery.com) provides code examples for many of the popular models. For me, seeing and writing code has been helpful in understanding how things work and makes it easier to put new developments in context. reply nullandvoid 3 hours agoprevYT channels: - https://www.youtube.com/@aiexplained-official - https://www.youtube.com/@DaveShap - https://www.youtube.com/@TwoMinutePapers/videos Then newsletter AI supremacy reply swyx 2 hours agoparentdaveshap quit ai right? got agi pilled/\"oneshotted by ayahuasca\" as the kids say reply mindcrime 2 hours agorootparentHe was only gone for a few days, IIRC. At any rate, he's back publishing AI related content again, and it looks like all (?) of his old content is back on his YT channel. reply swyx 1 hour agorootparenthonestly his channel quality is notably different than the other 2 you mentioned. i'm vaguely curious what you get out of it that makes you put him on the same tier. reply mindcrime 43 minutes agorootparentI think you replied to the wrong person. I didn't put DaveShap on any tier or anything. That said... I will say that in one of my other replies I did mention that some YT channels in this space can be a bit tabloid'ish, and I may have had Shapiro partly in in mind when saying that. But I still subscribe to his channel and some similar ones, just to get a variety of takes and perspectives. reply simonw 3 hours agoprevMy blog is very high volume so yeah, it can be difficult to know where to look on it. I use tags a lot - these ones might be more useful for you: https://simonwillison.net/tags/prompt-engineering/ - collects notes on prompting techniques https://simonwillison.net/tags/llms/ - everything relating to LLMs https://simonwillison.net/tags/openai/ and https://simonwillison.net/tags/anthropic/ and https://simonwillison.net/tags/gemini/ and https://simonwillison.net/tags/llama/ and https://simonwillison.net/tags/mistral/ - I have tags for each of the major model families and vendors Every six months or so I write something (often derived from a conference talk) that's more of a \"catch up with the latest developments\" post - a few of those: - Stuff we figured out about AI in 2023 - https://simonwillison.net/2023/Dec/31/ai-in-2023/ - I will probably do one of those for 2024 next month - Imitation Intelligence, my keynote for PyCon US 2024 - https://simonwillison.net/2024/Jul/14/pycon/ from July this year reply bingemaker 4 hours agoprevBeing a coder, I find these resources extremely useful: Github blog: https://github.blog/ai-and-ml/ Cursor blog: https://www.cursor.com/blog reply Workaccount2 3 hours agoprevThe localllama subreddit, although focused mostly on open source locally run models, still has ample discussion of SOTA models too. https://old.reddit.com/r/LocalLLaMA/ reply Der_Einzige 2 hours agoparentSadly, you'll have to include 4chan /g/'s local models general, which, unfortunately, seems to have top AI researchers posting there (anonymously) reply jumping_frog 4 hours agoprevSome youtube channels are good too. https://www.youtube.com/@umarjamilai https://huyenchip.com/blog/ reply mindcrime 2 hours agoprevLots of good suggestions here already. I'd start by adding one quick note though. \"AI\" is more than just LLM's. Sure, the \"current, trendy, fashionable\" thing is all LLM's, but the field as a whole is still much larger. I'd encourage you to not myopically focus on LLM's to exclusion. Depending on your existing background knowledge, there's a lot to be said for going out and getting a copy of Artificial Intelligence: A Modern Approach and reading through it. Likewise for something like Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow. Beyond that: there are some decent sub-reddits for keeping up with AI happenings, a lot of good Youtube channels (although a lot of the ones that talk about the \"current, trendy\" AI stuff tend to be a bit tabloid'ish), and even a couple of Facebook groups. You can also find good signal by choosing the right people to follow on Twitter/LinkedIn/Mastodon/Bluesky/etc. https://www.reddit.com/r/artificial/ https://reddit.com/r/machineLearning/ https://www.reddit.com/r/LLM/ https://www.reddit.com/r/agi https://www.reddit.com/r/ollama/ https://www.youtube.com/@matthew_berman https://www.youtube.com/@TheAiGrid https://www.youtube.com/@WesRoth https://www.youtube.com/@DaveShap https://www.youtube.com/c/MachineLearningStreetTalk https://www.youtube.com/@twimlai https://www.youtube.com/@YannicKilcher And you can always go straight to \"the source\" and follow pre-prints showing up in arXiv. https://arxiv.org/corr For tools to make it easier to track new releases, arXiv supports subscriptions to daily digest emails, and also has RSS feeds. https://info.arxiv.org/help/subscribe.html https://info.arxiv.org/help/rss.html There are also some bots in the Fediverse that push out links to new arXiv papers. reply eachro 3 hours agoprevReproduce nanogpt. Then find a small dataset and see if you can start getting close to some of the reported benchmark numbers with similar architectures. reply febin 3 hours agoprevBuild a tool on top of the LLM layer for a specific use case. That'll get you up to speed. You haven't missed much. reply magic_smoke_ee 3 hours agoparentExactly. Avoid intentionally throw-away effort and instead attempt to build something specific and practical. Learn by doing. reply gargigupta97 3 hours agoprevUnwind AI would be helpful. They publish daily newsletters on AI as well as tutorials on building apps with step-by-step walkthrough. Super focused on developers. https://www.theunwindai.com/ reply toddwprice 4 hours agoprevSubscribe to The Neuron newsletter reply sghiassy 3 hours agoparenthttps://join.theneurondaily.com/ reply barrenko 4 hours agoprevGet on Twitter (well, X) as that's where the the cutting edge is. reply bmitc 3 hours agoprevAre you wanting to get into LLMs in particular or something else? I am a software engineer also trying to make headways into so-called \"AI\", but I have little interest in LLMs. For one, it's suffering from a major hype bubble right now. The second reason is that because of reason one, it has a huge amount of attention from people who study and work on this every day. It's not something I have the time commitment for to compete with that. Lastly, as mentioned, I have no interest in it and my understanding of them leads me to believe they have few interesting applications besides generating a huge amount of noise in society and dumping heat. The Internet, like blogs, articles, and even YouTube, are already being overrun by LLM-generated material that is effectively worthless. I'm not sure of the net positive for LLMs. For me personally, I prefer to work backwards and then forwards. What I mean by that is that I want to understand the basics and fundamentals first. So, I'm, slowly, trying to bone up on my statistics, probability, and information theory and have targeted machine learning books that also take a fundamental approach. There's no end to books in this realm for neural networks, machine learning, etc., so it's hard to recommend beyond what I've just picked, and I'm just getting started anyway. If you can get your employer to pay for it, MIT xPRO has courses on machine learning (https://xpro.mit.edu/programs/program-v1:xPRO+MLx/ and https://xpro.mit.edu/courses/course-v1:xPRO+GenAI/). These will likely give a pretty up to date overview of the technologies. reply petesergeant 4 hours agoprevRead through this making flashcards as you to: https://eugeneyan.com/writing/llm-patterns/ Then spin up a RAG-enhanced chatbot using pgvector on your favourite subject, and keep improving it when you learn about cool techniques reply cranberryturkey 3 hours agoprevcheckout ollama. it lets you run open models on your own hardware. it also provides an easy to use rest api similar to openai's reply not_your_vase 3 hours agoprev [‚Äì] Unpopular opinion: if you can't use Google nor ChatGPT to get an answer to this question, I have bad news for you. reply henry2023 1 hour agoparent [‚Äì] Maybe you should read the responses here and acknowledge the value of a community. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The user is actively seeking reliable sources for the latest updates in Artificial Intelligence (AI), particularly through tech blogs similar to Hacker News (HN).",
      "They have experience using ChatGPT and the OpenAI API, specifically version 3.5, indicating a practical interest in AI tools.",
      "The user found Simon Willison's blog but feels it lacks cohesion, suggesting a need for more structured and comprehensive AI information sources."
    ],
    "commentSummary": [
      "Software engineers can enhance their AI skills by participating in Kaggle competitions, which offer practical, hands-on learning experiences.",
      "Staying informed through tech blogs, newsletters, and YouTube channels like Simon Willison's, AI Supremacy, and 3Blue1Brown can provide foundational and current AI knowledge.",
      "Engaging with AI communities on platforms like Reddit and Twitter, as well as exploring educational resources such as books and online courses from MIT xPRO, can deepen understanding and keep engineers updated on the latest AI trends."
    ],
    "points": 138,
    "commentCount": 62,
    "retryCount": 0,
    "time": 1732715720
  },
  {
    "id": 42252806,
    "title": "OpenAI hits pause on video model Sora after artists leak access in protest",
    "originLink": "https://www.washingtonpost.com/technology/2024/11/26/openai-sora-ai-video-model-artists-protest/",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=42252806",
    "commentBody": "OpenAI hits pause on video model Sora after artists leak access in protest (washingtonpost.com)126 points by marban 15 hours agohidepastfavorite111 comments MostlyStable 13 hours agoThis is so weird. They are mad that they didn't get paid for voluntarily participating in a program that never offered any pay? There are legitimate artist complaints around AI (I don't always agree with them, but they are reasonable complaints to have and are part of very important conversations about how society chooses to interact with AI), but this has got to be the silliest one I have heard so far. reply ENGNR 11 hours agoparentI‚Äôm guessing they gave feedback and felt that it was ignored. So rather than let the trial end and let OpenAI say ‚Äúwe even ran it past a bunch of artists, there‚Äôs no problem here‚Äù - someone decided to flip the table, since they were unheard anyway and felt there were unresolved issues reply hnlmorg 11 hours agoparentprevI suspect their protests stem from those legitimate artist complaints. Basically that they aren‚Äôt being compensated for testing a tool that is ultimately intended to replace them. I can definitely forgive their complaints when it‚Äôs framed that way. But I do agree that the article doesn‚Äôt do a particularly good job representing their view point. reply soco 10 hours agorootparentBut... why were they using/testing it in the first time? It's not like not being paid was a secret. Or maybe they registered exactly to setup this sort of protest? Because they are totally entitled to protest against AI taking jobs, just the particular conditions are a bit weird to me. reply KolyaKornelius 8 hours agorootparentBecause their work is being devalued by AI, wether they participate or not. reply lolinder 4 hours agorootparentSo you're suggesting that they joined the program specifically to leak it later? reply 2muchcoffeeman 12 hours agoparentprevMaybe they realised what they were really doing after the fact and changed their minds. They can‚Äôt really do anything about it so they are doing what they can. It a bit silly to think people won‚Äôt learn new information and change their minds. reply thyrox 9 hours agoparentprevI've been eagerly awaiting access to the tool for quite a while. I would definitely be willing to pay to try it out and provide feedback in addition. I'm genuinely surprised by this news. reply lemoncookiechip 3 hours agoparentprevYou can read their open letter yourself, whether or not you agree with their logic is up for you to decide. https://huggingface.co/spaces/PR-Puppets/PR-Puppet-Sora reply benreesman 8 hours agoparentprevI think that everyone at this point just distrusts the board who isn‚Äôt paid to say otherwise. OpenAI is the new high watermark in moral, ethical, social, and intellectual corruption and anyone who works there who has any moral sense is deeply conflicted. It‚Äôs cancer that has cancer. To defeat it would be like discovering a vaccine. reply tokioyoyo 2 hours agorootparentWho is everyone? Outside of very online tech enthusiasts like ourselves, nobody cares. reply shkkmo 12 hours agoparentprev> This is so weird. They are mad that they didn't get paid for voluntarily participating in a program that never offered any pay? Companies have been getting ever bolder about abusing volunteer and crowd sourced labor. When the participants are bound by strict NDAs, I think some skepticism is in order. All we really can tell is that non-neglibigle percentage of the participants in a limited access program were creeped out enough to be willing to blow up their access to call attention to it. I don't think this story is really even about AI at all, but about labor practices. reply andersa 11 hours agorootparentHow is it possible to \"abuse\" volunteer labor? Can't they just... stop volunteering? reply grahar64 11 hours agorootparentThe same way you can abuse paid labor, \"can't they just quit?\" reply andersa 11 hours agorootparentI think that's quite different, though. If someone is currently doing paid labor, they indeed can't just quit in most cases, because they depend on the income. But there's no such thing with volunteering to try a new service. That's just something people do because they feel like it, are bored, enjoy it in their spare time? reply dsign 7 hours agorootparentUnless those artists depended on (free) access to the model for monetization purposes. There have been some AI videos popping up in Youtube and other platforms. Creating a video using traditional CGI techniques is many orders of magnitudes more work than writing (even pages of) prompts. To that, I will add that there is a large market for content outside mainstream media[^1]. I'm sure there are creative folk out there which are not visual artists as their main thing[^2], but can use cheap visual art coming from AI to generate some sort of income... [^1]: See, for example, https://www.thinkwithgoogle.com/marketing-strategies/data-an... reply ValentinA23 6 hours agorootparentThey aren't free to post videos they generated with sora. It must be reviewed before hand reply _flux 11 hours agorootparentprevIn that case the paid labor loses their livelihood. What do they lose when they weren't being paid in the first place? reply Ratelman 11 hours agorootparentprevNot really a reasonable comparison - paid labour is more likely linked to income that is used for basic necessities, whereas volunteering implies freely offering to take part in an enterprise/task - thus no consequence for just choosing not to partake. Honestly seems like a bit of an emotional overreaction. reply azemetre 6 hours agorootparentprevIt‚Äôs a company that has raised billions, they can afford to pay for labor. reply _heimdall 6 hours agorootparentThat's not how markets work though. If someone is willing to do it for free, and you are happy with what that person produces, why would a company pay them anyway? reply shkkmo 2 hours agorootparent> why would a company pay them anyway? Because we have laws to protect workers. You can't just not pay an employee and call them a volunteer as a for profit company. There a legal limitations on what a for profit company can do with volunteer labor but companies have been increasingly bold about pushing those limits. Often times it is hard to tell if a program violates those limits since particpants are put under strict NDAs. reply shkkmo 2 hours agorootparentprevVolunteers can be abused in many of the same ways employees can be. In general, if a volunteer at a for profit compan is doing work that benefits that company, this can be considered \"competing\" with paid employees and mean the volunteer position must also be paid reply fragmede 11 hours agorootparentprevBy the time the volunteer quits due to abuse, it's too late. If Mr asshole goes off and yells a bunch of obscenities at someone, sure, they can respond by quitting, but they've already been yelled at and called a bunch of names. reply rightbyte 7 hours agoparentprevI prefer Pepsi to Coca Cola. I sometimes pose as a Coca Cola drinker to suddenly instigate protests among Coca Cola drinkers. Some people think I am acting strange but I'd argue they don't see my point. reply ruthmarx 10 hours agoparentprevThe less reasonable artist complaints are the ones where they just straight up accuse AI of stealing their work, when that's not how it works at all. reply rat9988 10 hours agorootparentThe problem stems when they change their mind but there is no new information. reply throwaway290 13 hours agoparentprevMaybe they agreed first and later realized that if they help ClosedAI murder their future careers and careers of other artists they might as well get paid for it. reply dyauspitr 13 hours agoparentprevProbably blown away by what was possible so they panicked. reply 0points 8 hours agorootparentBy judging from those videos, nothing can be further from the truth. Every single video is riddled by visual artifacts just like the still images. I saw a shaking rubiks cube, a shrinking cola bottle, and two dogs jumping into eachother and swapping places in a ridiculous way. No artist should be threatened by this nonsense. Can't wait for the hype to die. reply aabhay 13 hours agoprev‚ÄúHundreds of artists provide unpaid labor through bug testing, feedback and experimental work for the program for a $150B valued company‚Äù This is a hilarious basis for protest reply esperent 12 hours agoparentA huge company is using unpaid artist's labour to create tools that will reduce the potential for these and all future artists to get any paid work at all in the future. It seems like signing up as the volunteer with the goal of derailing the company as much as possible is a highly valid form of ptotest. reply eek04_ 9 hours agorootparent> A huge company is using unpaid artist's labour to create tools that will reduce the potential for these and all future artists to get any paid work at all in the future. \"Will\" is a strong claim. If the Jevons Paradox (https://en.wikipedia.org/wiki/Jevons_paradox) applies in this case - and it may well do so - the new technology will lower costs, and the increased productivity will increase demand. If so, it will require artists to work in a different way but they'll earn more. The Baumol Effect (https://en.wikipedia.org/wiki/Baumol_effect) may also lead to increased wages. reply kranke155 8 hours agorootparentNo that won‚Äôt happen. Audiovisual entertainment is already beyond capacity. We make more stuff than people have the time to consume it. The idea that this will raise wages is hilarious. I don‚Äôt see how that would be possible. reply starfezzy 8 hours agorootparentTbh a lot of art people want money for is garbage, and most money goes to a few corporations anyways. It would be nice to see that system rearranged. Even if there‚Äôs more art, money could instead fund artistic ventures people actually want rather than keeping powerful entities afloat/entrenched. Maybe the number of major corporations decreases (towards a permanent handful) as the number of paid artists increases (towards basically everyone who could desire payment for art that‚Äôs actually in demand). reply kranke155 7 hours agorootparentA system being rearranged is tempting, and yes, a very likely outcome. Hollywood depends on its advantage in production values, which is quickly being eroded by AI. However, if recent history is a guide, we won't see an increase in the number of paid artists, I'd say looking at the music industry, what we saw was the increase in the number of artists in general, but success seems to me as fickle as ever. Now, apparently, thanks to Ticketmaster monopoly, even live tours barely make any money and musicians are turning to Onlyfans (not porn, just direct support) to make money. So here's the state of the music industry (partially due to unchallenged monopolies): You, for the most part, don't make money making music and distributing it online You don't make money from a live tour either. Amazing outcome for an industry where the cost of production and distribution has collapsed. No one makes money except for the monopolies in streaming (Spotify) and ticketing (Ticketmaster). Without monopoly protections, that's what you get. Thankfully, there's a bit more competition in the audiovisual realm with Youtube and multiple streamers. Still, I don't know what to think about what might happen. Most artists / people in audiovisual production will likely make less money. Some will likely make a lot of money. My (kind of unfounded atm) assumption is that AI will just increase the differences in Paretto distribution of income, making the top 20% very rich and the bottom 80% very poor. Before genAI, you had a very large and vibrant VFX industry, with relatively well paid workers, which is likely to be cut down by huge numbers (it's already been cut by around 50%). reply dsign 6 hours agorootparentprev> Audiovisual entertainment is already beyond capacity. We make more stuff than people have the time to consume it. No we don't. I rarely find anything that I like in Netflix, Amazon Prime or HBO. Those services are stuffed with brain bleach that I don't even find entertaining. There are \"gold nuggets\"[^1] I have enjoyed in those sites, but it's like one or two per year. The rest of my watching time goes to videos of people camping in the wilderness, for lack of a better thing. [^1]: As in, they are entertaining. Rarely, they are imaginative. Even more seldom, they are educational or contribute to my personal growth. reply kranke155 6 hours agorootparentYes we do. You don‚Äôt get it. Those programs are made because they make money. Netflix is profitable because it makes shows that X number of people want to see. The number of people like yourself who are underserved by stuff to watch is too low to be profitable - or they don‚Äôt know how to make a show that would appeal to this group yet. The dark truth about TV is that it‚Äôs what people want to watch. There is no conspiracy. Here is a good Steve Jobs quote on the subject: ‚Äú When you‚Äôre young, you look at television and think, There‚Äôs a conspiracy. The networks have conspired to dumb us down. But when you get a little older, you realize that‚Äôs not true. The networks are in business to give people exactly what they want. That‚Äôs a far more depressing thought. Conspiracy is optimistic! You can shoot the bastards! We can have a revolution! But the networks are really in business to give people what they want. It‚Äôs the truth.‚Äù Anyway assuming that an industry screwed up because you personally don‚Äôt like their product is pretty incredible. No they didnt screw up. They‚Äôre just serving people who aren‚Äôt quite like yourself. reply dsign 5 hours agorootparentAnd? Two things can be true at the same time. Deadpool Wolverine was 300 million USD to produce. Nobody is going to put that amount of money into producing content for a corner wacko like myself, or Steve Jobs, whom, by your quote, apparently had the same problem (and 300 million USD to spare). But if it can be produced at a fraction of the price, then there is a market. And that's exactly my point. reply kranke155 4 hours agorootparentWhat kind of content could you want that‚Äôs not on YouTube today? reply lolinder 4 hours agorootparentA few examples: * Slow, thoughtful, hard sci-fi that's well-written and well acted, with immersive (not campy) sets and effects. Enough of that to fill an evening a week. * A spiritual successor to Firefly with the same production requirements and release schedule described above. Even YouTube is bound by the same limitations as the AAA streaming platforms are‚Äîyou can't sink money into something that's too niche, and right now doing things well costs buckets of money. So I'm sure there are a few fan films on YouTube adjacent to my interests, but their production value is going to be far below what it could be if things were made cheaper. reply smegger001 5 hours agorootparentprevJust because they make money from one nich doesn't mean they will appeal to another reply kranke155 4 hours agorootparentThey have limited amount of resources and people have limited time capacity. They make the most profitable content they can think of. reply Ratelman 11 hours agorootparentprevThere are better ways to protest than violating a legally binding agreement - seems more like an emotional reaction than a properly thought through protest. reply bryant 11 hours agorootparentIn fairness, some of the most effective protests have gone much further than that ‚Äî they've broken laws. (See basically every civil rights protest) Breaking contracts seems tame by comparison. reply Ratelman 10 hours agorootparentFair point - and I suppose we are on HACKERnews - and they are OPENAI, so helping them be more open is an effective form of protest. reply Retr0id 11 hours agorootparentprevThe most effective forms of protest usually are illegal reply HPsquared 10 hours agorootparentIt's risky though, if the protest is annoying or damaging enough (antisocial behaviour basically) it can actively turn people away from your position. As in \"Oh these are a bunch of insane/evil/violent etc people and that type of person tends to have this type of view, I as a good person do not have these kinds of views\" reply Ratelman 10 hours agorootparentprevTrue, true - didn't think that one through reply immibis 9 hours agorootparentprevthe ONLY effective forms of protest reply esperent 11 hours agorootparentprevYou'd rather a politely worded letter to the artist's local newspaper? reply Ratelman 10 hours agorootparentMeh, not entirely sure what would work better. Having read through the huggingface post a few times now, suppose it's less of an emotional reaction, more actual protest to abusive practices. reply vntok 10 hours agorootparentprevI'd rather they do... art? Why not organize a worldwide protest where every participant produces and shares Art denouncing generative AI? \"AI might produce single pieces but this collective work, this is what AI can't do\" and so on. What they're doing is so weird and ineffective in contrast, it baffles me. reply Philpax 9 hours agorootparentFor three hours, they gave everyone access to create videos with Sora, some of which could very well be art. Not only that, but the form in which they did this and the statement they made could also be considered art. I think they've done well here. In their statement, they make it clear that they're not opposed to the use of AI in art: they're opposed to the abuse of artists to pretend that OpenAI is doing this for their sake. This serves their perspective better than any juvenile anti-AI quilt could have. reply esperent 9 hours agorootparentprev> Why not organize a worldwide protest where every participant produces and shares Art denouncing generative AI Ah yes, a feel good protest that can be completely ignored by everyone, especially OpenAI. Even better, maybe OpenAI could fund it? That way they get to claim they hear the protests but they don't have to actually change anything. reply vntok 5 hours agorootparentSay everyone completely ignores the protest; surely that's a valid data point that should in itself make those artists reflect on their own positions & ideas? Maybe, just maybe, people in the general public actually value generative AI, regardless of what artists think about it? reply rafram 2 hours agorootparentprevI‚Äôm comfortable saying that there has never been a good protest in modern history that didn‚Äôt violate a legally binding agreement. reply Vampiero 10 hours agorootparentprevIf you want to make a legally binding agreement you better pay me first. reply tiahura 4 hours agorootparentprevThey‚Äôre artists. Theory of mind is important here. reply 71bw 10 hours agorootparentprev>It seems like signing up as the volunteer with the goal of derailing the company as much as possible is a highly valid form of ptotest. It's the most immature and pseudointellectual form of protest I can think of. \"Oh I am scared of the technology that's coming regardless, let me try and screw everybody else over as well!\" reply Ratelman 10 hours agorootparentLink to the post: https://huggingface.co/spaces/PR-Puppets/PR-Puppet-Sora If you read through it, they clearly state: \"We are not against the use of AI technology as a tool for the arts (if we were, we probably wouldn't have been invited to this program). What we don't agree with is how this artist program has been rolled out and how the tool is shaping up ahead of a possible public release. We are sharing this to the world in the hopes that OpenAI becomes more open, more artist friendly and supports the arts beyond PR stunts.\" reply meheleventyone 9 hours agorootparentThis is super interesting and seems to be the first organized push back against the platformization of 'creators' where the power imbalance is so great that corps expect free labor for the chance to become one of few outsized successes and it's whitewashed as 'democratization'. reply xkqd 10 hours agorootparentprevWell, both of those are subjective terms but if it‚Äôs effective it‚Äôs effective. The most effective movements are usually a combination of protest and civil disobedience. Considering livelihoods are under threat I wouldn‚Äôt condone nor blame anyone for even going one step further. reply HPsquared 9 hours agorootparentI don't know if protest actually does work. It can certainly be used to \"legitimise\" some course of action preferred by one group of elites. But there are so, so many examples of protest achieving nothing at all - or even having the opposite effect. reply rat9988 10 hours agorootparentprevYes, and bombing openai's headquarters is effective too. Effectiveness isn't a moral compass. reply Blahah 12 hours agoparentprevUnless they volunteered precisely so that they would have early access and could leak it, which would be sensible. reply pineaux 11 hours agorootparentWhich is what they did. So openAI was tricked, boohoo. Should be applauded here on h@x0rn3wz reply immibis 9 hours agorootparentIt's Y-Combinator tech-startup-in-a-garage-type-of-hacker news, not CCC-type-of-hacker news or Anonymous-type-of-hacker news. reply tiahura 4 hours agorootparentI thought it was Levy Hackers? reply yyuugg 12 hours agoparentprev\"We are doing labor, and are not being fairly compensated for our labor\" is a hilarious basis? How so? reply andersa 11 hours agorootparentThey are free to stop doing it for free? I don't understand. reply yyuugg 11 hours agorootparentMaybe they object to the idea that anyone's labor should be used, for free, to enrich the wealthy. I don't think that's a terrible stance to have, abstractly. I dunno if that was the case here. reply moi2388 11 hours agorootparentThen they simply should not have opted in. I didn‚Äôt? reply meheleventyone 9 hours agorootparentSomeone linked the actual open letter above: https://huggingface.co/spaces/PR-Puppets/PR-Puppet-Sora If you read it they state quite clearly that they feel like their participation was different than they expected it to be and that's why they are upset. reply esperent 11 hours agorootparentprevThey opted in with the express purpose of protesting, it seems. reply rat9988 10 hours agorootparentYou mean sabotaging. reply ramon156 10 hours agorootparentprevThe fact they said yes at the start shows a form of tunnel vision. I just can't empathize that much with borderline manchildren leaking access to something they got the privilege to reply benreesman 3 hours agoparentprevA lot of people refused to hang out with Diddy even if they could put their finger on exactly why. I know more than most, but the sexual assault allegations and shady restructuring and abuse of the the political process and the multiple firings for financial fraud and, well a lot of stuff, that‚Äôs all public record. Matt Gaetz got run out of DC for less. reply dyauspitr 13 hours agoparentprevSo stupid. I realize artists are panicking but this angle just makes them look like Luddite villains. reply willio58 12 hours agorootparentI highly recommend reading about luddites! This Smithsonian article covers the topic well: https://www.smithsonianmag.com/history/what-the-luddites-rea... Basically luddites were never the bad ones, they were protestors against abusive working conditions. They did sabotage the owners of the mills that paid them so poorly, sometimes by destroying machinery, but it was really an underground labor movement that‚Äôs super cool to learn about. reply CamperBob2 12 hours agorootparentNo, there was nothing \"super cool\" about the Luddites. Stop trying to rehabilitate these thugs. Failing that, do it someplace other than a site called \"Hacker News.\" reply weweersdfsd 12 hours agorootparentThere's nothing wrong with resisting bad working conditions, unfair pay, or getting replaced by a machine without adequate social safety nets in place. If businesses decide to replace workers with AI, then it's also their collective responsibility to pay for their retraining, or if that isn't possible their social security. reply HPsquared 10 hours agorootparentSurely the morality depends on how they go about their protest. reply sensanaty 3 hours agorootparentprevThe Luddite \"thugs\" were the ones that were getting murdered by the people they were protesting against, a protest which happened because they were about to be replaced while already working in extremely dangerous conditions with terrible compensation. It's telling that the AI sycophants side with the group that was actually murdering people, however. reply CamperBob2 3 hours agorootparenta protest which happened because they were about to be replaced while already working in extremely dangerous conditions with terrible compensation. Gee. Being \"replaced\" in a job like that sounds like a good career move to me. The system that prevailed up to that point didn't give them many options, of course... but neither would their response to it. Sabotage doesn't bring progress, no matter who told you that it did, or how much you want to believe it. reply yyuugg 12 hours agorootparentprevLuddites were highly educated, skilled workers whose work was being replaced by machines. They just wanted to operate the machines and share in the increased productivity. There's absolutely no parallels here, to AI. A machine that is taking work from highly skilled labor ohhhh wait reply CamperBob2 12 minutes agorootparentIf a machine can take your work, perhaps you weren't as \"highly skilled\" as you thought you were. reply atoav 12 hours agorootparentprevOr like cool activists that made a stupid-but-rich corp accept them despite their obvious activist goals ‚Äî who knows. You assume they changed their mind, there is no data point for that as of now. reply pineaux 11 hours agoparentprevHilariously correct you mean? reply yread 12 hours agoparentprevYeah, hilarious. Now lets go back to working on open source so that corporations can use it and openai can train on it reply hulitu 12 hours agoparentprev> > unpaid labor through bug testing, feedback and experimental work for the program for a $150B valued company‚Äù > This is a hilarious basis for protest Of course. Every CEO works for free these days. /s reply it_citizen 13 hours agoprevLooking at the examples here: https://x.com/kimmonismus/status/1861450051085545880 It seems pretty underwhelming compared to what was shown in early 2024 no? reply cloudking 13 hours agoparentThere's a bunch of commercial options live right now that have comparable results. Not sure what all the hype is about, here are a few: https://runwayml.com/ https://klingai.com/ https://hailuoai.video/ https://lumalabs.ai/ https://pika.art/ https://viggle.ai/ reply nicce 12 hours agoparentprev> It seems pretty underwhelming compared to what was shown in early 2024 no? People seem to have five fingers so I would say that as a win. reply Jordan-117 13 hours agoparentprevApparently they only had access to the light/turbo model, not the full one. reply ipsum2 12 hours agorootparentSource for this claim? I've never heard it before. reply MrCheeze 11 hours agorootparenthttps://xcancel.com/legit_rumors/status/1861448164084978157#... reply resiros 10 hours agoparentprevI don't think it's worse, just that the standards moved up, the expectations are now much higher. Sam forgot YC's advice to launch fast. reply rafram 13 hours agoparentprevYeah, for all the talk of Sora building an internal ‚Äúworld model‚Äù that could be a building block for AGI‚Ä¶ this seems to suffer from all the same glitches as the Will Smith spaghetti video, just with much, much more polish. I don‚Äôt think it‚Äôs that much worse than what OpenAI showed off earlier in the year when you consider that those examples were very cherry-picked, though. These new videos don‚Äôt make it seem like a bad model, they‚Äôre just a bit more realistically mediocre. reply samsartor 1 hour agorootparentAnyone who works closely with diffusion models knows the \"world model\" thing was hype. Diffusion models are really good at faking, starting with nonsensical large-scale structure and forcing it towards plausibility with lots of nice details. reply irjustin 13 hours agoparentprevWow yeah. The pixelation makes it hard but chopstick pens, pages moving, cars crossing over eachother. Demo's gonna demo. reply jdenning 13 hours agoprevhttps://archive.is/8sKXF reply daniel_iversen 14 hours agoprevI‚Äôd love to see the contract those artists signed! I‚Äôm sure they did, or should have, gone in with their eyes wide open, and not sure what they expected from OpenAI (since clearly there wouldn‚Äôt have been any mention of payment in the contract), or whether OpenAI started asking them for a lot of work maybe (that‚Äôs the only thing I can think of that would give them the right to complain)? reply HPsquared 9 hours agoparentThey probably signed up for the purpose of doing this. People don't usually change their opinions that easily, especially a total 180 from \"volunteering to support OpenAI\" to directly the opposite. reply dumpsterdiver 10 hours agoprevI‚Äôm convinced Sora will finally motivate me to finish my novel, and I‚Äôm so excited about that. reply HPsquared 9 hours agoparentGenAI has been a huge boon to my creativity as well. It does the donkey work. reply HPsquared 9 hours agoprevA bit of buzz, free publicity if anything. It's a competitive space. reply add-sub-mul-div 13 hours agoprevI wish the slop era would just get up to speed already so it can be seen for what it is. reply immibis 9 hours agoparentIt's already here even without pervasive video AI. We had text slop before LLMs too. reply orbital-decay 7 hours agoprevIn other news, Sora still exists. I thought they were never going to release it, there are comparable/better commercial options now. reply 9o1d 10 hours agoprev [‚Äì] Doesn't the law establish a minimum wage? Who violates the rights of the working person? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "OpenAI paused its video model Sora after artists leaked access in protest over unpaid participation, despite no promise of compensation.- The protest raises concerns about AI potentially replacing artists and highlights ethical issues related to unpaid labor in AI development.- Some view the protest as a strategic effort to bring attention to these broader issues within the industry."
    ],
    "points": 126,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1732679997
  },
  {
    "id": 42249545,
    "title": "Yes, it ‚Äòlooks like a duck,‚Äô but carriers like the new USPS mail truck",
    "originLink": "https://www.nytimes.com/2024/11/26/us/usps-new-mail-trucks.html",
    "originBody": "ADVERTISEMENT SKIP ADVERTISEMENT Yes, It ‚ÄòLooks Like a Duck,‚Äô but Carriers Like the New Mail Truck The electric trucks have a side cargo door, more space and, critically, air-conditioning, promising some long-overdue relief for carriers, who haven‚Äôt had an upgrade since the 1980s. Listen to this article ¬∑ 5:50 min Learn more Share full article ‚ÄúI know a lot of people say it looks funny,‚Äù Richard Burton, a letter carrier in Athens, Ga., said of his new electric delivery truck. ‚ÄúIt looks like a duck or a platypus. It does. But I tell them it gets the job done. It works for me.‚Äù Credit... David Walter Banks for The New York Times By Michael Levenson Nov. 26, 2024 For 19 years, Richard Burton, a letter carrier in Athens, Ga., drove the classic boxy mail truck, with only a fan on the dashboard to keep the cabin cool in the sweltering summer months. A second fan plugged into the cigarette lighter didn‚Äôt make much of a difference, he said. But about two months ago, Mr. Burton, 46, became one of the first letter carriers in the United States to get a long-awaited upgrade: a new electric mail truck with air-conditioning, a 360-degree camera and a sliding cargo door on the side that allows the unloading of packages directly onto the sidewalk. ‚ÄúIt makes the job easier to do because you‚Äôre not sweating bullets out there,‚Äù he said. ‚ÄúAnd in Georgia, you can imagine how hot it gets.‚Äù The new mail trucks ‚Äî 10 years in the making ‚Äî have started rolling into American neighborhoods, and the early reviews from letter carriers are positive. Many have complained for years that the mail trucks they have been driving, which were introduced in the 1980s, break down frequently and are stiflingly hot, as climate change pushes temperatures to greater extremes. The rear cargo space is so small, they say, that they have to crouch inside to grab packages. Image Mr. Burton adjusts the air conditioning in his Next Generation Delivery Vehicle. His previous truck was equipped only with a dashboard fan to keep him cool in the sweltering Georgia summers. Credit... David Walter Banks for The New York Times Image After the Postal Service was sued over its plans to make most of the new trucks gas-powered, it reversed course in 2022 and said that 75 percent of the vehicles would be electric. Credit... David Walter Banks for The New York Times Image The Postal Service began soliciting ideas for the new trucks from its carriers a decade ago. Some of their suggestions, such as nonslip surfaces and doorstep lights, were incorporated into the final design. Credit... David Walter Banks for The New York Times The Next Generation Delivery Vehicle, as the new truck is called, promises some long-overdue relief. But its appearance has not been universally applauded. It has a giant windshield and a low-slung hood designed to allow drivers of almost any height to see the road. One car enthusiast on YouTube called it ‚Äúugly by design.‚Äù Ezra Dyer, a columnist for Car and Driver, went further, describing the truck as a ‚Äúvisual abomination.‚Äù ‚ÄúIt looks like a robot Beluga whale ‚Äî built by the East German government,‚Äù he wrote in 2021, after the design was unveiled. ‚ÄúIt also reminds me of the baseball bullpen golf carts that were designed to look like motorized baseball hats.‚Äù Mr. Burton said that people on his route have been stopping him to take photos and to ask if they can peek inside. ‚ÄúI know a lot of people say it looks funny,‚Äù he said. ‚ÄúIt looks like a duck or a platypus. It does. But I tell them it gets the job done. It works for me.‚Äù Fans say the design just takes some getting used to. ‚ÄúIt is the goofiest thing in the world when you first look at it,‚Äù said Douglas Lape, a special assistant to the president of the National Association of Letter Carriers, a union that represents 205,000 postal delivery workers. ‚ÄúBut I will tell you, it grows on you.‚Äù The mail trucks are the most prominent piece of the Postal Service‚Äôs plan to invest $9.6 billion to modernize its fleet of aging delivery vehicles and make them more efficient, safer and better equipped to carry packages. Image Mr. Burton delivering mail in Athens, Ga. He said that people on his route have been stopping him to take photos of his truck and to ask if they can peek inside. Credit... David Walter Banks for The New York Times The Postal Service ordered 50,000 of the new trucks in March 2022, according to Oshkosh Defense, the Wisconsin company that won the contract to produce the vehicles at a plant in Spartanburg, S.C. A month later, attorneys general from 16 states and the District of Columbia, along with five environmental groups and the United Auto Workers union, sued the Postal Service, complaining that most of the new vehicles would be gas-powered, undercutting the fight against climate change. In December 2022, the Postal Service changed course and announced that 75 percent of the new mail trucks would be battery-powered. The trucks are designed to travel about 70 miles on a single charge, more than enough for the 12 to 15 miles of daily driving that city letter carriers generally do, including frequent stops, Mr. Lape said. Brian L. Renfroe, the president of the National Association of Letter Carriers, said that the new trucks have several advantages over the model they are replacing, the Grumman Long Life Vehicle. In addition to air-conditioning ‚Äî perhaps the most critical upgrade ‚Äî they have more cargo space, because letter carriers now deliver far more packages and far fewer letters and magazines than they did in the 1980s. The cargo door on the side of the new mail trucks is also safer, Mr. Renfroe said, allowing packages to be unloaded directly onto the curb. The old mail trucks had to be unloaded from the back, which resulted in postal workers‚Äô being injured and even killed when they were hit by oncoming vehicles, Mr. Renfroe said. Planning for the new vehicles started in 2014, when the Postal Service began soliciting ideas from letter carriers. Some of their suggestions were incorporated into the final design, such as nonslip surfaces and lights on the doorsteps, and a third sun visor for the windshield. The trucks also have airbags, automatic emergency braking and a collision-avoidance system ‚Äî safety features that are common in many new vehicles but were missing from the old vehicles. The new trucks may require some adjustment for letter carriers accustomed to driving the old delivery vehicles. Ykeyler Barnes, a letter carrier in Athens, said when she first got her new electric mail truck, she thought it wasn‚Äôt working when she pushed the button to start it. So she called a mechanic to check it out. ‚ÄúHe said, ‚ÄòIt starts ‚Äî you just can‚Äôt hear it because it‚Äôs electric,‚Äô‚Äù Ms. Barnes said. ‚ÄúI thought that was so funny. I came home and told my family and we got a good laugh out of it.‚Äù Driving a larger truck took a little getting used to, she said. But Ms. Barnes, who has been delivering mail for 26 years, said that she appreciated the air-conditioning and the additional cargo space, which allows her to walk inside the truck and get packages without having to stoop. She said other letter carriers will also come to appreciate the additional room for packages, especially during the holidays. ‚ÄúYou‚Äôre going to have to get used to it,‚Äù she said. ‚ÄúBut once you pass that phase, you‚Äôre going to really like it.‚Äù Image ‚ÄúIt is the goofiest thing in the world when you first look at it,‚Äù Douglas Lape, a special assistant to the president of the National Association of Letter Carriers, said of the new truck. ‚ÄúBut I will tell you, it grows on you.‚Äù Credit... David Walter Banks for The New York Times Michael Levenson covers breaking news for The Times from New York. More about Michael Levenson Share full article The Rise of Electric Vehicles Tax Credit in Jeopardy: Many car buyers have come to rely on a $7,500 federal tax credit on electric vehicles to soften the blow of their high prices. But those credits could disappear after President-elect Donald Trump takes office. Newsom Challenges Trump: California Gov. Gavin Newsom said his state will step in and provide rebates to eligible residents who buy electric vehicles if Trump ends the federal E.V. tax credit. Rivian E.V. Factory Loan: The Biden administration will lend $6 billion to help Rivian build an electric car factory in Georgia, part of an effort to lock in Democratic climate policies before Trump returns to the White House. Installing E.V. Chargers: After years of mixed results, retailers now see charging as a potentially profitable business in and of itself, not just as a spur for foot traffic and sales. Ford vs. G.M.: In the race to be second to Tesla in the U.S. electric vehicle market, Ford leaped to an early lead four years ago over General Motors. But the contest looks much different today. ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=42249545",
    "commentBody": "Yes, it ‚Äòlooks like a duck,‚Äô but carriers like the new USPS mail truck (nytimes.com)124 points by vincentchau 22 hours agohidepastfavorite142 comments kaveet 22 hours agohttp://archive.today/Mcwu5 garciansmith 22 hours agoprevI've read so much knocking their appearance, which is so confusing to me. It's ultimately function over form in this case; who cares if you don't like how it looks? I can only dream that the visibility and safety of having features like such a low hood and large bumpers would be incorporated into other vehicles (i.e., every SUV ever). reply klik99 22 hours agoparentProbably in the minority, but I actually like the look of them. I find so many modern car designs indistinguishable from each other. Cars such a narrow range of design that's considered \"good aesthetics\" that everything looks so uniform. reply m463 21 hours agorootparentI think when it comes to vans they've kind of let go of traditional designs. like https://upload.wikimedia.org/wikipedia/commons/1/11/Dodge-Ra... Now they've gotten the european influence to be very square: https://upload.wikimedia.org/wikipedia/commons/3/37/2015_For... or like the european designed mercedes sprinter, very tall too: https://upload.wikimedia.org/wikipedia/commons/f/f3/Mercedes... reply laurencerowe 20 hours agorootparentThe European equivalents to the Dodge Ram Van are the smaller Transit Custom or VW Transporter https://en.wikipedia.org/wiki/Ford_Transit_Custom https://en.wikipedia.org/wiki/Volkswagen_Transporter The equivalent US trucks mostly used by FedEx and UPS are much squarer than the European designed Transit or Sprinter vans that are now replacing them. https://commons.wikimedia.org/wiki/File:FedEx_Express_truck.... reply ttepasse 3 hours agorootparentThe main German postal service for a time manufactured their own e-vans, which where rather boxy: https://en.wikipedia.org/wiki/StreetScooter reply yencabulator 17 hours agorootparentprevRam Promaster is a rebranded Fiat Ducato. The European equivalent of it is thus a Fiat Ducato. UPS uses plenty of Promasters. reply laurencerowe 10 hours agorootparentThe Fiat Ducati / Ram Promaster is another Transit / Sprinter class van but the linked image with the ‚Äútraditional design‚Äù in the post I responded to was of an older, smaller Dodge Ram Van. https://en.m.wikipedia.org/wiki/Dodge_Ram_Van I was trying to point out that the Transit/Sprinter/Ducati class vans are replacing the larger and far more boxy FedEx and UPS vans like this: https://commons.m.wikimedia.org/wiki/File:UPS_package_car.jp... reply Oarch 20 hours agorootparentprevLike wet putty https://www.blackbirdspyplane.com/p/why-do-new-cars-look-lik... reply klik99 19 hours agorootparentGood article, though I do like some matte paints and some of the dulled color looks. The problem for me is not that these aren't good paint choices by themselves, but how uniformly dull every car is. Most cars come in 3-4 shades of grey or a dull red, if there is color more often than not it's that wet putty look. I legit felt sad a couple of times looking at a big parking lot and the total lack of color. If people had a variety of color cars, then a few of those wet putty dulled out versions would be part of that variety. There's almost certainly strong market and logistical reasons for this trend, and I bet some HN reader knows why to an unreasonable detail (I'd be interested to hear it!), but it still bums me out. reply shiroiushi 19 hours agorootparentI think there's two parts: 1) A lot of car buyers worry about resale value. For the same reason a house with a purple and pink paint scheme won't sell at top price, a car with strong colors won't either. You might like seeing cars in a variety of colors like bright orange, bright green, etc., but those colors will absolutely turn away a significant fraction of the potential buyers, thus lowering resale value. If you could just press a button inside the car to change its color, it wouldn't be this way, but as it is, repainting a car is prohibitively expensive. 2) Just look at the way people dress these days. Boring colors are in, bright and bold colors are out and generally associated with the 1960s. We're in a very bad time now as far as color palettes and styles go. reply chongli 18 hours agorootparentprevIs that writer from Philadelphia? Very quirky and colourful writing style! reply telcal 15 hours agorootparentWas it the jawn? That article was by Jonah Weiner who grew up in NYC. reply chongli 13 hours agorootparentYep! reply tim333 3 hours agorootparentprevYeah I think the kids would like it. It's a bit reminicent of Postman Pat's van https://content.instructables.com/FRX/AYCQ/JASJWQW4/FRXAYCQJ... reply grogenaut 16 hours agorootparentprevIf successful and widely deployed they'll become iconic and part of the gestalt. And if the pattern holds I'll be dead before the replacement is put in place. reply mschuster91 21 hours agorootparentprev> Cars such a narrow range of design that's considered \"good aesthetics\" that everything looks so uniform. The issue is fuel efficiency. Modern cars are all built to be as aerodynamic and fuel efficient as possible, and the constraints are virtually the same, so the designs are very similar as well. However, these mail trucks don't travel 85 miles an hour, most of them will be on average less than 25 mp/h or less, where aerodynamics plainly just does not matter (it's v-squared), so they can prioritize safety and driver comfort over anything else. reply klik99 19 hours agorootparentI don't fully buy this - if you optimized for aerodynamics and safety you'd get cars so far outside the aesthetic it would be ridiculed. No-one is making fun of the new USPS trucks for lack of fuel efficiency, they're saying it looks like a platypus. I can see a weaker version of what you're saying, that the intersection between the aesthetics a mass car market would accept and an acceptable fuel efficiency/safety yields a very narrow design space. reply XorNot 18 hours agorootparentNot really sure what you think would change if you did this? reply klik99 18 hours agorootparentMaybe I wasn't clear because I wasn't talking about doing anything, or suggesting that car manufacturers do anything, just I don't think this comment is the full story: > Modern cars are all built to be as aerodynamic and fuel efficient as possible, and the constraints are virtually the same, so the designs are very similar as well. reply abeppu 19 hours agorootparentprevI don't know that efficiency is really an explanation. If you look at a list of very aerodynamic cars, there are a bunch of older ones with very different designs. https://carbuzz.com/features/most-aerodynamic-cars/ And the still-not-released Aptera looks very distinctive and is claimed to have a drag coefficient of 0.13. https://electrek.co/2020/12/07/aptera-super-efficient-electr... reply ggreer 16 hours agorootparentOlder cars had fewer safety regulations, so they could play around with more designs. Also a lot of the old photos in that post are of concept cars or race cars, not production vehicles. The Aptera has a unique design because it is considered a motorcycle in the US, so most Federal Motor Vehicle Safety Standards don't apply to it. reply bsder 19 hours agorootparentprevIt's aerodynamics and safety combined. Those bars that you smack into everytime you get into your car and those bars that give you enormous blind spots to hit pedestrians? Yeah, they're there because of safety regulations. When you put the requirements to be able to roll over and not cave the roof along with aerodynamics, the design constraints are pretty heavy. reply Retric 19 hours agorootparentBeing able to roll without crushing the cabin doesn‚Äôt take that much. It‚Äôs airbags that are causing wide blindspot inducing pillars and there‚Äôs options that maintain good visibility. reply duskwuff 22 hours agoparentprev> I've read so much knocking their appearance, which is so confusing to me. Especially since the old LLVs were pretty ugly in their own way. We've just gotten used to seeing them over the last 38 years. reply tantalor 22 hours agoparentprev> It's ultimately form over function in this case Doesn't \"form over function\" mean the opposite of your usage? Form = appearance Function = usefulness reply garciansmith 22 hours agorootparentYes, I just reversed it by mistake! reply jackcosgrove 22 hours agorootparentprevI think it's a misquote of the phrase \"Form ever follows function\", commonly attributed to architect Louis Sullivan. It's an odd sentence structure, where the leader comes second in the phrasing, that trips people up. reply PittleyDunkin 22 hours agorootparentprevI took this to mean that critiquing appearance is itself form over function. reply tantalor 22 hours agorootparentOh. What does that even mean? Saying something is \"form over function\" is not derogatory. Lots of great inventions prioritize form over function (iPod comes to mind). reply bdavbdav 22 hours agorootparentI‚Äôm not convinced the iPod was. Everything else was pretty terrible at that time. The iPod did it right (and arguably still does) reply phil21 22 hours agorootparentpreviPod was famously both though? The click-wheel was pretty unique and worked great to make an accessible UIx for the masses. It may have been somewhat limiting in edge cases, but for normal usage I don't recall anyone complaining about it outside of hardcore tech circles. reply tantalor 21 hours agorootparent\"No wireless? Less space than a Nomad? Lame\" Seriously though, the iTunes integration and cross platform compatibility kind of sucked. It would have been much more useful if you could just mount it like a hard drive without special library management software. The click wheel was cool. reply PrismCrystal 19 hours agorootparent> It would have been much more useful if you could just mount it like a hard drive without special library management software. When I got my first iPod in 2006, I immediately put Rockbox on it, where the iPod indeed mounted like a hard drive and files (including all my .oggs, remember those?) could be dropped right onto the device. Never used Apple‚Äôs own UI even once. I still miss the iPod. It let you really immerse yourself in the music without all the distractions inherent in a smartphone. I occasionally considered getting a used one and installing larger storage and a new battery, but by now I think that ship has sailed. reply tantalor 5 hours agorootparentYou can still mod a used iPod, one of my coworkers has a few and they are really neat. Go for it! reply PittleyDunkin 20 hours agorootparentprev> Seriously though, the iTunes integration and cross platform compatibility kind of sucked. It would have been much more useful if you could just mount it like a hard drive without special library management software. I very much preferred this, actually. file management is really annoying compared to custom-built software with all the tagging etc built-in. Subjective, obviously, but I really miss that every time I'm managing music on linux or windows and get frustrated when labeling invariably changes (even if only subtly) when moved to a device. Granted, itunes could have also done a much better of unifying the tagging etc with the files to avoid this entire fiasco. reply VogonPoetry 20 hours agorootparentprevI think that making the iPod mount like a filesystem would have had significant impact on other aspects of the device. There is no filesystem level abstraction over USB (or Firewire). So plugging in presents as a hard drive / block device, which then means it needs to have a filesystem. For \"built-in\" cross OS compatibility that means it would be have to be a FAT filesystem. If you change these decisions either a new filesystem or device driver would need to be installed for some machines. Most devices that present a FAT filesystem when plugged in stop working like they do when unplugged. i.e. the device itself and the connected computer cannot access the data at the same time. For the iPod this would mean it wouldn't be possible to play music while syncing. I think it might be possible to build a \"fake\" drive and FAT filesystem when plugged in, but it would take quite a bit of work and have lots of odd corner cases. For example, the user on the computer attempting to re-format the drive, perhaps with a different filesystem. reply mulmen 15 hours agorootparentOk but the iPod could literally act as external storage. https://en.wikipedia.org/wiki/IPod > Some versions of the iPod can serve as external data storage devices, like other digital music players. Prior to macOS 10.15, Apple's iTunes software (and other alternative software) could be used to transfer music, photos, videos, games, contact information, e-mail settings, Web bookmarks, and calendars to the devices supporting these features from computers using certain versions of Apple macOS and Microsoft Windows operating systems. reply EasyMark 15 hours agoparentprevBut it's okay to call them ugly. People get used to a certain look of things and then you introduce something that look like what an 8 year old would draw (this mail truck, Musk's cybertruck) and you'll get some flack. It's utterly meaningless in the end, and just bar talk. If these are reliable and make the postal workers' lives better I'm all for it, but they are imo ugly as sin. reply techjamie 20 hours agoparentprevThe low hood is almost definitely to help prevent scraping mailboxes and other objects, but especially mailboxes. My dad was a rural USPS carrier that used his own vehicle, and despite him having been an excellent driver with no accidents on record in his life, he still ended up swapping minor paint with mailboxes a few times. Can't imagine how often it happens across the country. reply reaperducer 20 hours agorootparentThe low hood is almost definitely to help prevent scraping mailboxes and other objects, but especially mailboxes. The USPS states that it's to keep from hitting pedestrians. reply dylan604 22 hours agoparentprevfor utilitarian purposes, like the guy was quoted \"it gets the job done\", but for soccer moms and their SUV looks are important. reply bryanlarsen 22 hours agorootparentSafety should be even more important than both, but it obviously isn't since only the USPS trucks have a pedestrian safe design. reply dylan604 22 hours agorootparentIf safety were more important than looks, the stilleto would be banned. reply Terr_ 19 hours agorootparentprevVehicle choice is probably much more of a personal-identity / status thing for the soccer-mom. To riff off of a Bujold quote about uniforms: \"Fleet vehicles are always correct, or, if not exactly correct, clearly not the driver's fault, since they have no choice.\" reply 8ytecoder 19 hours agoparentprevSubarus use a boxer engine that drastically increases the visibility. I have a short torso with long legs and finding a car where I felt comfortable with visibility was a priority for me. I settled on the Subaru Impreza 10 years ago. Still has the best visibility of all the cars I‚Äôve driven. I‚Äôd expect EVs to also have better visibility - may be eventually - since they can drop the height of the hood as well. reply potato3732842 19 hours agorootparentThey're just as tall as anything these days. reply euroderf 9 hours agoparentprevFor an institution that was the origin of the term \"going postal\", it's a wonderfully human-oriented design. reply andrewflnr 21 hours agoparentprevWell, they're mostly not qualified to comment on the function, are they? reply browningstreet 18 hours agoparentprevA few ideas: 1) it kinda resembles Le Car 2) the junk in the frunk 3) and plus that extra forward bumper looks a bit like a telemark ski binding clip, and those ski folk never really looked especially smooth 4) it came out during DeJoy‚Äôs tenure, so it‚Äôs easy to imagine this is actually a shaming design 5) there are some very cute and charming EV designs out for Amazon FedEx UPS right now, and this isn‚Äôt up to the standard of those more forward looking (and admittedly bulbous but ‚Äúof our time‚Äù) designs. 6) we‚Äôll have to live, culturally, with this identity for a while. Seems a bit ‚Äúmeh‚Äù. I can see it now.. Kevin James as a future sitcom postal carrier and he will have a whole extra stage set up so he can have scenes in the enormous front cab of this thing. A la Art Carney as Ed Norton from the Honeymooners. We‚Äôll get to visit the monstrosity during future Universal Studio backlot tours. reply stackedinserter 20 hours agoparentprevWould you wear the same cloths but in clown colours? reply Animats 19 hours agoprevThe job of delivery services today is delivering small packages, not information. So everybody (USPS, UPS, Amazon) is converging on the same feature set: - Van big enough to stand up in - Door between driver compartment and package storage - Bin/shelf type package storage, not bags or piles - Good visibility - Battery electric - Optimized for 0 to 30 MPH with lots of stops. Aerodynamics don't matter much. Regenerative braking does. Amazon has some cute features. The driver wears some small RFID device, and when they step out of the truck, the door to package storage closes and locks, and the truck won't move. Amazon's new vans also have very high visibility from the rear, with many LEDs, so it's hard to rear-end them by accident. Good because they double-part frequently. reply smitelli 22 hours agoprevSay what you will about the Grumman LLV, but every one of them you see on the road today is at least 30 years old, and some could be pushing 40. (The similar-looking Ford-Utilimaster FFV is ~25 this year.) As uncomfortable as it must be to sit in one for hours on end (I never had the privilege myself) you've got to respect their longevity. Here's hoping these new trucks make it to the 2050s and beyond. reply hex4def6 22 hours agoparent\"While the all-aluminum body of the LLV has resisted corrosion exceptionally well over the years, the main powertrain components have been replaced multiple times and now must be sourced through aftermarket manufacturing. This has significantly increased repair costs while reducing performance and reliability. In fact, the Postal Service had to contract an alternative supplier to reverse engineer and manufacture the chassis frame to keep the LLV operational. As a result, the average annual maintenance cost exceeds $5,000, with 7% of LLVs exceeding $10,000 annually. Additionally, they are less fuel-efficient and unsuitable for future delivery needs given projected changes in market demand, mail mix, and increasing delivery points. The LLVs also lack modern safety features such as airbags, anti-lock brakes, air conditioning, back-up cameras, blind-spot warning systems, daytime running lights, and seatbelt reminders.\" https://uspsngdveis.com/documents/USPS+NGDV+FEIS_Dec+2021.pd... Sort of a Ship of Theseus vehicle. Yes, some have lasted over 40 years, but that's with potentially multiple drivetrain replacements, at an annual maintenance cost of $5,000 - $10,000. That feels high, given how simple those vehicles are. reply varikin 22 hours agorootparentI believe the LLV line was only suppose to be in service for 20 years, but the government gonna government and not find a replacement till it's almost too late. So yes it was a lot of scrounging and probably a lot of USPS mechanics needing to be creative, but the LLV lasted twice as long as it was designed for. I expect this same conversation will happen again in another 40 years. reply not_kurt_godel 21 hours agorootparent> the government gonna government and not find a replacement till it's almost too late Actually they were going to convert to EVs back in 2006 when Bush stepped in to prevent that and punish them on behalf of his oil buddies with the Postal Accountability and Enhancement Act. The problem isn't government, it's politicians voted in to destroy it in favor of corporate interests. reply throwworhtthrow 21 hours agorootparentAccording to Wikipedia: > Passed the House on December 8, 2006 (voice vote) > Passed the Senate on December 9, 2006 (unanimous consent) Can't pin it all on Bush Jr. reply not_kurt_godel 21 hours agorootparent> According to Tom Davis, the Bush administration threatened to veto the legislation unless they added the provision regarding funding the employee benefits in advance with the objective of using that money to reduce the federal deficit. Bush was responsible for the provision that kneecapped USPS to prevent them from ever funding their EV ambitions (until Biden funded NGDV in 2022) reply varikin 19 hours agorootparentprevI wasn't aware Bush was not part of the government in 2006. Thank you for the correction. reply AdamJacobMuller 21 hours agorootparentprev> manufacture the chassis frame Ship of Theseus notwithstanding, at that point, isn't it a new car if you're replacing the chassis? reply folmar 19 hours agorootparentSome manufacturers have a way of \"officially\" replacing the chassis, as in getting the chassis as a replacement part and procedure to replace it. For example see BMW part number 51 71 7 409 410, chassis for F16 https://www.online-teile.com/bmw-ersatzteile/51717409410_Bod... The law might look this or other way depending on where you are. reply whalesalad 22 hours agoparentprevFrom my desk at home I see the lil LLV come down our private road every single day. With retrofitted LED lighting. reply reaperducer 20 hours agorootparentFrom my desk at home I see the lil LLV come down our private road every single day. They seem very durable. I've forgotten the number of times I've seen one plowing an improvised short cut through the scrub brush between desert ranches. Probably cuts an hour off the time with little change in comfort compared to using what passes for \"roads\" in some places. reply potato3732842 18 hours agorootparentHere they slide down the hills in the snow and ice and hit things (at low-ish speeds). One got stuck in a snow bank at a cross street near me a few winters ago and another one showed up and they played bumper cars until it was though though I'm sure that activity is not officially sanctioned. I can't imagine how that would have gone with the Metris vans they're using as a stop gap reply m463 21 hours agoparentprevI'm pretty sure the enemy of vehicle longevity isn't design, but parts supply. The crown victoria could have kept on supplying police departments for another decade or two if ford didn't discontinue it. reply deciduously 21 hours agoparentprevConstantly starting and stopping, too, in a variety of temperatures. reply mmooss 20 hours agoparentprev> every one of them you see on the road today is at least 30 years old, and some could be pushing 40. Survivor bias: The ones you see are the ones that have survived. You don't see the junkyards full of failed trucks. reply mulmen 15 hours agorootparentOk but how many other 40 year old vehicles do you see? reply hiccuphippo 20 hours agoprevAccording to this video[0] the shape is because there's a requirement for 95th percentile males to be able to stand up inside and the front is low for 5th percentile females to be able to see a specific distance in front of the hood. The shape makes perfect sense. [0] https://www.youtube.com/watch?v=Rt6z4QvtQL8 reply fatboy 21 hours agoprevAfter driving a new Mercedes Vito (I can't describe how insane the controls of this vehicle are, but it has capacitive-touch buttons that you have to swipe to change the stereo volume ON THE STEERING WHEEL), I long for controls that look like this: https://static01.nyt.com/images/2024/11/20/multimedia/00xp-m... reply unethical_ban 20 hours agoparentTactile controls should be the default. I was actually interested in the Lincoln Corsair until I saw how much they rely on touch - even for things like the climate control, same as the Teslas. Instantly took it off the list. reply silisili 20 hours agorootparentThat's why I won't even consider a Tesla. Test drove a few vehicles and it's amazing how many do touch screen everything now. Will -not- buy. The one I ended up buying is all tactile except changing the radio stations. Even that gets really annoying, as you have to take your eyes off the road to change stations. I end up just poking it in random places blind until something happens. reply pearlsontheroad 22 hours agoprevI'm proud to have helped implement the brand new dedicated ERP system that is used to build these trucks. Nice to see the final product is hitting the streets. reply mmooss 20 hours agoparentI think you owe us some information to satisfy 'intellectual curiosity'! :) I'll start: Why did they create a brand-new and why a dedicated ERP system? Didn't the manufacturer have an ERP system used for manufacturing other vehicles? reply bnc319 22 hours agoparentprevCan you provide some more information as to what the ERP system is built on? (i.e. open source software, \"from scratch\", etc?) reply pearlsontheroad 22 hours agorootparentLatest Oracle JDE E1 reply cco 33 minutes agoprevI _love_ USPS. Glad we're starting to see these roll out. reply fencepost 22 hours agoprevHow could they not love them in comparison to the 30+ year old vehicles they've been driving? reply potato3732842 18 hours agoparentFrequently \"improvements\" come at the expense of compromising some key feature for lots of users. This is particularly true in tall organizations where the people doing procurement are far from the users. reply rectang 22 hours agoparentprevCultural hostility among a subpopulation to electric vehicles as \"woke\"? Ordinary sentimentality and the natural human discomfort with change? reply fencepost 21 hours agorootparentI have great faith in the ability of ahem some individuals to harm themselves out of spite or inability to recognize inbound leopards, but I'm pretty sure that even those would find the new vehicles to be an improvement even if they're EVs - at least if they're actually driving the old and new vehicles. reply evan_ 19 hours agorootparentplenty of folks will soil themselves if it means the people they dislike will have to smell it reply vaadu 4 hours agoprevAnother government boondoggle. The vehicle requirements were at the level of a combat vehicle so only one or two companies with DOD experience could win the contract. And the result is a $60k+ camel designed by committee. reply whatio 20 hours agoprevIt was designed with the person who will operate it in mind and it's made in the USA. That means it looks fantastic to me. reply littlekey 19 hours agoprev>Ykeyler Barnes, a letter carrier in Athens, said when she first got her new electric mail truck, she thought it wasn‚Äôt working when she pushed the button to start it. So she called a mechanic to check it out. ‚ÄúHe said, ‚ÄòIt starts ‚Äî you just can‚Äôt hear it because it‚Äôs electric,‚Äô‚Äù Ms. Barnes said. ‚ÄúI thought that was so funny. I came home and told my family and we got a good laugh out of it.‚Äù My favorite part of this, so wholesome. It really is shocking to hear the difference when you've been driving/hearing gas vehicles your whole life. reply schiffern 22 hours agoprevYes, It ‚ÄòLooks Like a Duck,‚Äô but... ...but that means it's far safer for pedestrians than the currently-in-vogue \"bulldozer\" vehicle front ends. I for one welcome our new duck-shaped overlords. reply matsemann 22 hours agoparentDirect Vision Standards[0] should implemented as a mandatory requirement everywhere for large vehicles traveling in cities or residential areas where there's \"soft road users\"[1] (pedestrians, cyclists). Should be able to see straight to the side and know you're not running someone over. [0]: https://en.m.wikipedia.org/wiki/Direct_Vision_Standard [1]: https://en.m.wikipedia.org/wiki/Non-motorist reply morsch 21 hours agorootparentI was squeezing by in front of a modern garbage truck this morning that basically had a glass side door. It was great: I could actually establish eye contact with the driver and sign that I was going to drive in front of him and he could give me small wave to go ahead. The driver of a less modern truck would have had no way at all to see me, much less communicate with me. reply magic_smoke_ee 2 hours agoprevBurners (of people who are still) with Cushmans will probably be seen with LLVs now. reply hoherd 21 hours agoprevThis is great news! The design is interesting though. Why would they choose such a hard angle for the hood and windshield vs something more gentle? Does anybody know why they made that design choice? reply NotSammyHagar 19 hours agoparentread other comments, so talk people can stand up in the back and short people and see over the hood. reply Havoc 18 hours agoprevSounds like they designed it for the target audience. A rare luxury these days for blue collar workers. Often designs focus on max profit reply xnx 22 hours agoprevI don't mind the appearance if it serves a function, but what's the function? An electric truck wouldn't need a traditional engine compartment. reply fencepost 21 hours agoparentThey aren't/weren't all going to be EVs. Originally the USPS was looking at 10% EVs and 90% internal combustion but there were a bunch of challenges to that (including that ratio being based on incorrect environmental impact data). Now it's 75% EVs in the first order of 60,000 and future orders may be that high or higher (currently expected that it will be all EVs starting in 2026). sources: article and wikipedia (https://en.wikipedia.org/wiki/Oshkosh_NGDV) reply agent281 21 hours agoparentprevOne benefit of a low hood is that it scoops up pedestrians that might get hit instead of hitting their torsos with the vehicle. It'll probably break your legs, but you are more likely to survive. This is one of the reasons that SUVs and large trucks are deadly: it's basically hitting you directly in the chest cavity. reply Workaccount2 21 hours agorootparentFew things are more masculine than mowing down pedestrians with a pseudo diesel locomotive. reply varikin 22 hours agoparentprevAccording to Wikipedia[1]: > Four variants of the NGDV are expected to be in fleet use: both gasoline-powered and battery-electric, in either front wheel drive or all wheel drive. So I expect the front hood is for the gas powered engine for those variants. Further down, it talks about only 10% will be EV at the start due to cost. Also, this is in partnership with Ford so the ICE power train is the from the Ford Transit van. [1]https://en.wikipedia.org/wiki/Oshkosh_NGDV reply capital_guy 22 hours agoparentprevA crumple zone? reply mulmen 15 hours agoparentprevTo have easy side entry the front wheels need to be in front of the driver. So you need something to cover the front suspension and hold up lights. Try drawing a flat nose version of this vehicle that maintains the same ease of access. reply dylan604 22 hours agoparentprevi guess they could have made it flat nosed like a bus?? are they putting the batteries in the nose? it looks like the cargo part is too low for them to be placed under there. also, gotta put that ac somewhere. probably makes it easier to work on under the little hood than having to climb on top of the truck. reply postoplust 22 hours agoprevThe seat height in the banner image looks too tall for the mailboxes. I wonder how the seat height in the NGDV compares to the Grumman LLV. reply reaperducer 19 hours agoparentThe seat height in the banner image looks too tall for the mailboxes. The very first image in the article shows a driver putting mail in a mailbox. What more proof do you need? https://static01.nyt.com/images/2024/11/20/multimedia/00xp-m... reply toast0 18 hours agorootparentIt looks like the letter carrier has to reach down to get to that mailbox. Yes, they can reach it, but I wonder about ergonomics. Not all mailboxes are the same height, so you probably have to reach down for some, but if this is a representative mailbox, I worry. reply vondur 19 hours agoprevCrazy it took 10 years to plan and get them in production. I think it looks cool. reply yongjik 20 hours agoprevHonestly I think it looks great - the design screams \"I care for pedestrian safety\" and \"I'm a nice person, and I don't need to compensate for anything, because I have great sex life.\" reply paulnpace 18 hours agoprev> For 19 years, Richard Burton, a letter carrier in Athens, Ga., drove the classic boxy mail truck... After reading this, I realized I still perceive the the current generation as the new generation. Geez. reply paulnpace 57 minutes agoparentWow, old people get downvotes for being old people now. reply imp0cat 21 hours agoprevNeeds just one thing - light blue paintjob with an orange beak and a tiny purple hat. ;) reply evan_ 19 hours agoparentI was just thinking they need a special green and yellow variant for the southern Willamette Valley... https://en.wikipedia.org/wiki/The_Oregon_Duck reply stanski 21 hours agoprevReminds me of the Pilatus PC-6. Another ugly duckling (in some people's eyes) that's a workhorse. reply whalesalad 22 hours agoprevInteresting that the front windshield only has about 50-60% usable space. On the top this makes sense, as the black coating acts as a sun shade. On the bottom... there goes all the visibility gained by having the low hood. wtf? The upfitter AUX switches appear to be Ford, same for the AC controls. reply starkparker 21 hours agoparent> The upfitter AUX switches appear to be Ford, same for the AC controls. Ford supplies the ICE engine, transmission, suspension, steering wheel, and instrument cluster, so that tracks. https://fordauthority.com/2024/10/new-usps-mail-carrier-uses... reply cooljoseph 21 hours agoparentprevThe camera is positioned so that the side window is visible through the front windshield. I think the \"black coating\" you are seeing is just the interior of the van, and that the entire front windshield is usable. reply ceejayoz 21 hours agoparentprevThe final photo in the article appears to show pretty good forward visiblity. Seems fine? reply jacobgkau 21 hours agoparentprev> On the bottom... there goes all the visibility gained by having the low hood. wtf? That is a little weird, now that I look at it again. But the way you'd use the rest of that bottom space would be by lowering the driver, basically, and that would mean the driver's not as high up over the hood. So maybe getting the higher angle gains more visibility than having them sit lower just to maximize usable windshield area? (The only way you could have both is if the dashboard was transparent.) reply justsomehnguy 20 hours agoparentprevMy $5 it's the usual 'too late to change'. Compare with the 2021 version. Also the if you trace LoS in the cabin pic in the article you would find what the driver wouldn't see more of the hood because he need to be sat quite a lot higher (up to 20cm I think) to gain the view you are thinking of. And this is incompatible with 'do the mailman thing without getting out of chair'. https://www.nalc.org/news/the-postal-record/2021/may-2021/do... reply juunpp 20 hours agoprevI thought it was going to be about duck typing. reply AcerbicZero 21 hours agoprevlol they're paying (with my money) something like 60k for each one of those. Should have just bought police explorers like the cops are driving and saved 15-20k+ per unit. Plus as a bonus you might have actual parts availability for the foreseeable future, unlike when Oshkosh corp decides burning money in a barrel is more financially viable than building replacement parts for the postal service and the 40-70k of these that they'll actually get ordered before the budget gets slashed or whatever. reply ggreer 21 hours agoprev [‚Äì] I wondered why other delivery companies use commercial vehicles instead of NGDVs or LLVs, and the answer is that commercial vehicles are more capable while being significantly cheaper. NGDVs cost $60,000 each, and that's for half of them being ICE vehicles and half EVs with a 70 mile range (35 miles if you use the heater). The ICE version gets 14.7 miles per gallon (8.6mpg if you turn on the air conditioning).[1] There is no hybrid version, which is outrageous considering the expected driving profile. For comparison, a Mercedes eSprinter (which has more cargo capacity and >2x the range of the NGDV) starts at $63,475 MSRP. I'm sure a bulk order of 50,000 would get a significant discount. This whole project seems to be a handout to a defense contractor, not an efficient use of funds. 1. https://en.wikipedia.org/wiki/Oshkosh_NGDV#Fuel_economy_and_... reply chomp 20 hours agoparentHow in the world is a mail carrier going to deliver mail in a huge esprinter, you going to have them open their door and climb out at every mailbox? reply ggreer 20 hours agorootparentMy point was that a much more capable vehicle could be purchased for a similar price. Depending on the use case, of course other commercial vehicles would make more sense. The smaller versions of the Ford Transit are a popular option among non-US postal services. And if US Postal Service was willing to buy foreign vehicles, they could have even smaller and cheaper options. (Though they'd have to deal with EPA and NHTSA rules to make them street legal.) reply mmooss 20 hours agorootparent> My point was that a much more capable vehicle could be purchased for a similar price. This leaps to a conclusion. Probably the documents are public - why did they choose this solution over off-the-shelf options? (No point in speculation; what is their actual analysis?) reply toast0 18 hours agorootparentprev> The smaller versions of the Ford Transit are a popular option among non-US postal services. And if US Postal Service was willing to buy foreign vehicles, they could have even smaller and cheaper options. Ford isn't selling the Transit Connect in North America anymore. And they're made in Europe, so despite the brand, they're a foreign vehicle, too. reply mulmen 15 hours agorootparentprev> non-US postal services What postal services are those? Are you sure you aren't confusing the USPS with a parcel service? reply reaperducer 19 hours agorootparentprevif US Postal Service was willing to buy foreign vehicles, It's not. Offshoring critical infrastructure is always a bad idea. they'd have to deal with EPA and NHTSA rules Possibly not. They don't even have license plates, as the Postal Service outranks state governments. reply ggreer 19 hours agorootparentThe NGDV's gross vehicle weight rating is 8,501lbs so that it is classified by the EPA as a heavy-duty truck. If the rating were a pound less, it would be classified as a light-duty truck and have much stricter emissions standards. reply saltminer 20 hours agoparentprevOne key difference between USPS and UPS/Fedex is that USPS does not do freight, and they do a lot more lightweight items (i.e. letters), so cargo capacity is much less of a concern. The fact that junk mail is so common actually reduces the need for cargo capacity since their routes tend to be made long not because of physical volume/distance so much as dwell time (that is, if someone is using EDDM[0] to target a neighborhood, you have to stop at every mailbox in that neighborhood, even if it's just to deliver that one piece of junk mail which will immediately get thrown away, and this takes far more time than delivering a bundle of packages to a handful of houses). I remember reading about the NGDV, and one of the reasons it looks so weird is because USPS wanted a vehicle that was low to the ground (to make it easier to climb in and out of) and easy to see over the hood, even for very short drivers[1]. Given that they are in residential areas (and thus, in proximity of kids playing outside) far more often than UPS/Fedex, I can't say I disagree with that requirement. (Also, if you have a tall truck like UPS and Fedex typically roll, good luck delivering to the average mailbox while staying in your seat.) USPS has certainly evaluated more traditional designs; in fact, they are actively using ~20k Ram ProMasters (a rebadged Fiat Ducato), which are quite similar to the Mercedes Sprinter, alongside ~9k mini vans[2]. [0]: https://www.usps.com/business/every-door-direct-mail.htm [1]: https://x.com/Nir_Kahn/status/1364465483911675905 [2]: https://www.uspsoig.gov/sites/default/files/reports/2023-01/... (PDF page 6) reply bigstrat2003 20 hours agorootparent> Given that they are in residential areas (and thus, in proximity of kids playing outside) far more often than UPS/Fedex... That isn't the case at all in my experience. In any neighborhood I've ever lived in, you see at least one van from each organization come through daily. And if anything, UPS and FedEx come through more than once per day sometimes, whereas USPS doesn't. Per your earlier point about freight I can imagine that UPS/FedEx have a lower percentage of company traffic in residential areas than USPS does. But I find it difficult to imagine that the total number of trips to residential areas is lower for them. They simply have more non-residential traffic than USPS, not less residential traffic. reply saltminer 19 hours agorootparentI wish there were publicly available data on this stuff, as we can only discuss anecdotes. In any case, in the neighborhoods I've lived in, it's not uncommon for UPS and Fedex to have zero deliveries at least one day of the week. If Fedex is rolling around twice in one day, it's never the same line (that is, Fedex Express vs Ground/Home; Express incurs a special surcharge for residential deliveries and thus is usually only used by companies that primarily deliver to commercial addresses or who don't care about cost). UPS is similar; usually, they only roll around in the evening, and when they roll around in the morning it's for one package with a specific delivery window obligation. During December, of course, this goes by the wayside. Even USPS will roll around twice a day on the weekends leading up to Christmas. reply mulmen 14 hours agorootparentprev> That isn't the case at all in my experience. In any neighborhood I've ever lived in, you see at least one van from each organization come through daily. And if anything, UPS and FedEx come through more than once per day sometimes, whereas USPS doesn't. USPS doesn't deliver freight, UPS does. So yeah, you are going to see both in a residential setting but you won't see any USPS trucks making freight deliveries in an industrial area. UPS has to support that use case, USPS doesn't. reply potato3732842 18 hours agoparentprevHaving wrenched more extensively than I want to on the Transit, the Sprinter and the Promaster I would hand out the pork to a defense contractor ten times over before I bought Euro vans of ANY make because at least they tend to build things with margin in the places you need it even if it's not peak comfort and user experience. The engineering culture and default assumptions are completely different and it shows. reply KK7NIL 21 hours agoparentprevDid you not read the article? The NGDVs aren't Sprinter vans, they're purpose made mail delivery vehicles, with ergonomics and cargo space setup for that, which makes a massive difference for the drivers, especially when it comes to repetitive motion injuries, which is a huge cost for USPS. Amazon went away from commercial vans to purpose made vehicles built by Rivian for many of the same reasons and they've been widely praised by the drivers. reply SoftTalker 20 hours agorootparentUPS brown trucks (they call them ‚Äúcars‚Äù internally) are also custom made. They don‚Äôt even resell them when they are at EOL they crush them. reply ggreer 20 hours agorootparentprevThe Rivian vans are commercially available.[1] Like the NGDV, they have a side door and an 80 inch interior height so that nobody has to stoop while in the cargo bay. 1. https://en.wikipedia.org/wiki/Rivian_EDV reply reaperducer 19 hours agorootparentThe Rivian vans are commercially available. If you follow the link in your link, you'll see that while new Postal Service trucks are $60,000, the Rivian vans START a $83,000‚Ä†, and it's simply not possible for the driver of one of those vans to reach a mailbox from inside the vehicle, which is how vast majority of what the new Postal Services will be used. Paying a 40% premium for less capability? That doesn't sound smart. ‚Ä† https://rivian.com/fleet reply ggreer 18 hours agorootparentI was just saying that the vehicle is commercially available, not that it was a better option for the US Postal Service. But $83,000 is the retail price. Anyone buying in bulk will get them for significantly cheaper. The $60k for the NGDV is the discounted price for a bulk buy of 50,000, and it's for a mix of ICE and EVs. The ICE vehicles are significantly cheaper to manufacture, so the EV price is probably close to the Rivian's bulk price, and the Rivian has significantly greater capabilities. reply KK7NIL 17 hours agorootparent> Rivian has significantly greater capabilities. According to you, some random tech bro CEO who hasn't delivered hundreds of letters a day for decades and is just looking at cost and going \"hey, this isn't the cheapest option, it must be one of those darn government projects meant to subsidize those annoying poor people!\" In reality, the USPS studied several other options in use by post offices around the world, from commercial vans to tricycles: https://www.uspsoig.gov/sites/default/files/reports/2023-01/... They've since published further reports on things like how to tighten up the manufacturing contract, opportunities to use EV's, etc etc: https://www.uspsoig.gov/focus-areas/focus-on/next-generation... But hey, I'm sure you know better! reply greenthrow 21 hours agoparentprevAs usual when you take a dismissive stance (\"this is obviously a waste of money!\") you are ignoring lots od details. The use case of a mail carrier is not well suited by a massive eSprinter. They have no need for something so large. They want to be seated at the height where most mailboxes are so they can make many deliveries without getting out of the car. Whenever you find yourself going \"why would they make THAT decision?\" assume it is yourself that is ignorant and take it as an opportunity to learn, rather than dismiss the choices of people who specialize in the area you are puzzled by. reply ggreer 20 hours agorootparentI used the eSprinter as one example, not the only option. Maybe something like the Ford eTransit or the Rivian EDV is a better fit for postal deliveries. My point is that other delivery companies and postal services use commercial vehicles, most likely because that's the most cost-effective option. Considering the NGDV's atrocious efficiency, lack of hybrid option, and high unit costs, it seems far more likely that this is a pork project for a defense contractor than that everyone else is doing it wrong. reply unethical_ban 20 hours agorootparentIs it inefficient? Would it be more worthy to have two chassis designs, one for ICE and one for EV, to make it more efficient for the gas version? Would any hybrid drivetrain provide higher efficiency for similar build costs on the same chassis? My point would be that they weighed a lot of design considerations and I assume this is the best they could get that meets all of them. Like others said, other commercial delivery vehicles don't have the same use case as this. Who cares about range when the use case for this vehicle is ~20 miles a day? Everyone else isn't \"doing it wrong\", they're doing it differently, for different needs. reply XorNot 18 hours agorootparentThere's a wider meta point here which is always relevant: nobody comes into work planning to do a bad job. I'd add the second point is: if you're not in the same field, then start with the assumption that the people who's work you're looking at had good reasons for their choices (and that it wasn't a conspiracy). reply mschuster91 21 hours agoparentprev [‚Äì] > I wondered why other delivery companies use commercial vehicles instead of NGDVs or LLVs, and the answer is that commercial vehicles are more capable while being significantly cheaper. Commercial vehicles in fleets are leased - they last anywhere from 2-5 years then they're pushed off to the used vehicle market. After 10-15 years they're so done that they'll end up on the scrap yard or shipped off to Africa or Asia. On top of that they're designed to be aerodynamic at highway speeds because they'll spend a lot of their life time on such streets and speeds, whereas these postal trucks will spend most of their time moving like snails. These USPS tanks in contrast are expected to last 30, 40 years like their predecessors, racking up insane mileage... and while no one cares if some underpaid gig worker runs over some child because the child happened to be in the dead spot of his vehicle, if the same happens to USPS the government itself is the target for a nice juicy lawsuit. So it makes sense for a custom order at that scale and expected life time, and it also makes sense to stray from what the market has to offer because the requirements are different. Oh, and commercial delivery doesn't have to take care about its workers. They'll get burned out with their backs and joints ruined, but the companies don't have to pay a dime. In contrast, USPS is a government agency and has a massive financial incentive to keep healthcare costs low. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The U.S. Postal Service is introducing new electric mail trucks as part of a $9.6 billion modernization plan, offering features like air-conditioning, increased cargo space, and enhanced safety.",
      "Originally intended to be mostly gas-powered, 75% of the fleet will now be electric due to legal challenges, marking a significant shift towards sustainability.",
      "Despite their unconventional design, the trucks have been positively received for their comfort and efficiency, incorporating input from postal carriers and including features like nonslip surfaces, airbags, and a collision-avoidance system."
    ],
    "commentSummary": [
      "The new USPS mail truck design emphasizes visibility and safety, featuring a low hood and large bumpers to enhance pedestrian safety and driver comfort, particularly in urban settings.",
      "While its unconventional appearance has sparked debate, the truck is engineered for durability, akin to the long-serving Grumman LLV.",
      "The design also focuses on improving postal workers' conditions and includes options for electric vehicles to meet modern delivery demands."
    ],
    "points": 124,
    "commentCount": 142,
    "retryCount": 0,
    "time": 1732651996
  },
  {
    "id": 42251919,
    "title": "Htmy ‚Äì Async, pure-Python rendering engine",
    "originLink": "https://volfpeter.github.io/htmy/",
    "originBody": "Source code: https://github.com/volfpeter/htmy Documentation and examples: https://volfpeter.github.io/htmy htmy Async, pure-Python rendering engine. Key features Async-first, to let you make the best use of modern async tools. Powerful, React-like context support, so you can avoid prop-drilling. Sync and async function components with decorator syntax. All baseline HTML tags built-in. Markdown support with tools for customization. Async, JSON based internationalization. Built-in, easy to use ErrorBoundary component for graceful error handling. Unopinionated: use the backend, CSS, and JS frameworks of your choice, the way you want to use them. Everything is easily customizable, from the rendering engine to components, formatting and context management. Automatic and customizable property-name conversion from snake case to kebab case. Fully-typed. Installation The package is available on PyPI and can be installed with: $ pip install htmy Concepts The entire library -- from the rendering engine itself to the built-in components -- is built around a few simple protocols and a handful of simple utility classes. This means that you can easily customize, extend, or replace basically everything in the library. Yes, even the rendering engine. The remaining parts will keep working as expected. Also, the library doesn't rely on advanced Python features such as metaclasses or descriptors. There are also no complex base classes and the like. Even a junior engineer could understand, develop, and debug an application that's built with htmy. Components Every class with a sync or async htmy(context: Context) -> Component method is an htmy component (technically an HTMYComponentType). Strings are also components, as well as lists or tuples of HTMYComponentType or string objects. Using this method name enables the conversion of any of your business objects (from TypedDictss or pydantic models to ORM classes) into components without the fear of name collision with other tools. Async support makes it possible to load data or execute async business logic right in your components. This can reduce the amount of boilerplate you need to write in some cases, and also gives you the freedom to split the rendering and non-rendering logic in any way you see fit. Example: from dataclasses import dataclass from htmy import Component, Context, html @dataclass(frozen=True, kw_only=True, slots=True) class User: username: str name: str email: str async def is_admin(self) -> bool: return False class UserRow(User): async def htmy(self, context: Context) -> Component: role = \"admin\" if await self.is_admin() else \"restricted\" return html.tr( html.td(self.username), html.td(self.name), html.td(html.a(self.email, href=f\"mailto:{self.email}\")), html.td(role) ) @dataclass(frozen=True, kw_only=True, slots=True) class UserRows: users: list[User] def htmy(self, context: Context) -> Component: # Note that a list is returned here. A list or tuple of `HTMYComponentTypestr` objects is also a component. return [UserRow(username=u.username, name=u.name, email=u.email) for u in self.users] user_table = html.table( UserRows( users=[ User(username=\"Foo\", name=\"Foo\", email=\"foo@example.com\"), User(username=\"Bar\", name=\"Bar\", email=\"bar@example.com\"), ] ) ) htmy also provides a @component decorator that can be used on sync or async my_component(props: MyProps, context: Context) -> Component functions to convert them into components (preserving the props typing). Here is the same example as above, but with function components: from dataclasses import dataclass from htmy import Component, Context, component, html @dataclass(frozen=True, kw_only=True, slots=True) class User: username: str name: str email: str async def is_admin(self) -> bool: return False @component async def user_row(user: User, context: Context) -> Component: # The first argument of function components is their \"props\", the data they need. # The second argument is the rendering context. role = \"admin\" if await user.is_admin() else \"restricted\" return html.tr( html.td(user.username), html.td(user.name), html.td(html.a(user.email, href=f\"mailto:{user.email}\")), html.td(role) ) @component def user_rows(users: list[User], context: Context) -> Component: # Nothing to await in this component, so it's sync. # Note that we only pass the \"props\" to the user_row() component (well, function component wrapper). # The context will be passed to the wrapper during rendering. return [user_row(user) for user in users] user_table = html.table( user_rows( [ User(username=\"Foo\", name=\"Foo\", email=\"foo@example.com\"), User(username=\"Bar\", name=\"Bar\", email=\"bar@example.com\"), ] ) ) Built-in components htmy has a rich set of built-in utilities and components for both HTML and other use-cases: html module: a complete set of baseline HTML tags. md: MarkdownParser utility and MD component for loading, parsing, converting, and rendering markdown content. i18n: utilities for async, JSON based internationalization. BaseTag, TagWithProps, Tag, WildcardTag: base classes for custom XML tags. ErrorBoundary, Fragment, SafeStr, WithContext: utilities for error handling, component wrappers, context providers, and formatting. Snippet: utility class for loading and customizing document snippets from the file system. etree.ETreeConverter: utility that converts XML to a component tree with support for custom HTMY components. Rendering htmy.HTMY is the built-in, default renderer of the library. If you're using the library in an async web framework like FastAPI, then you're already in an async environment, so you can render components as simply as this: await HTMY().render(my_root_component). If you're trying to run the renderer in a sync environment, like a local script or CLI, then you first need to wrap the renderer in an async task and execute that task with asyncio.run(): import asyncio from htmy import HTMY, html async def render_page() -> None: page = ( html.DOCTYPE.html, html.html( html.body( html.h1(\"Hello World!\"), html.p(\"This page was rendered by \", html.code(\"htmy\")), ), ) ) result = await HTMY().render(page) print(result) if __name__ == \"__main__\": asyncio.run(render_page()) Context As you could see from the code examples above, every component has a context: Context argument, which we haven't used so far. Context is a way to share data with the entire subtree of a component without \"prop drilling\". The context (technically a Mapping) is entirely managed by the renderer. Context provider components (any class with a sync or async htmy_context() -> Context method) add new data to the context to make it available to components in their subtree, and components can simply take what they need from the context. There is no restriction on what can be in the context, it can be used for anything the application needs, for example making the current user, UI preferences, themes, or formatters available to components. In fact, built-in components get their Formatter from the context if it contains one, to make it possible to customize tag property name and value formatting. Here's an example context provider and consumer implementation: import asyncio from htmy import HTMY, Component, ComponentType, Context, component, html class UserContext: def __init__(self, *children: ComponentType, username: str, theme: str) -> None: self._children = children self.username = username self.theme = theme def htmy_context(self) -> Context: # Context provider implementation. return {UserContext: self} def htmy(self, context: Context) -> Component: # Context providers must also be components, as they just # wrap some children components in their context. return self._children @classmethod def from_context(cls, context: Context) -> \"UserContext\": user_context = context[cls] if isinstance(user_context, UserContext): return user_context raise TypeError(\"Invalid user context.\") @component def welcome_page(text: str, context: Context) -> Component: # Get user information from the context. user = UserContext.from_context(context) return ( html.DOCTYPE.html, html.html( html.body( html.h1(text, html.strong(user.username)), data_theme=user.theme, ), ), ) async def render_welcome_page() -> None: page = UserContext( welcome_page(\"Welcome back \"), username=\"John\", theme=\"dark\", ) result = await HTMY().render(page) print(result) if __name__ == \"__main__\": asyncio.run(render_welcome_page()) You can of course rely on the built-in context related utilities like the ContextAware or WithContext classes for convenient and typed context use with less boilerplate code. Formatter As mentioned before, the built-in Formatter class is responsible for tag attribute name and value formatting. You can completely override or extend the built-in formatting behavior simply by extending this class or adding new rules to an instance of it, and then adding the custom instance to the context, either directly in HTMY or HTMY.render(), or in a context provider component. These are default tag attribute formatting rules: Underscores are converted to dashes in attribute names (_ -> -) unless the attribute name starts or ends with an underscore, in which case leading and trailing underscores are removed and the rest of attribute name is preserved. For example data_theme=\"dark\" is converted to data-theme=\"dark\", but _data_theme=\"dark\" will end up as data_theme=\"dark\" in the rendered text. More importantly class_=\"text-danger\", _class=\"text-danger\", _class__=\"text-danger\" are all converted to class=\"text-danger\", and _for=\"my-input\" or for_=\"my_input\" will become for=\"my-input\". bool attribute values are converted to strings (\"true\" and \"false\"). XBool.true attributes values are converted to an empty string, and XBool.false values are skipped (only the attribute name is rendered). date and datetime attribute values are converted to ISO strings. Error boundary The ErrorBoundary component is useful if you want your application to fail gracefully (e.g. display an error message) instead of raising an HTTP error. The error boundary wraps a component component subtree. When the renderer encounters an ErrorBoundary component, it will try to render its wrapped content. If rendering fails with an exception at any point in the ErrorBoundary's subtree, the renderer will automatically fall back to the component you assigned to the ErrorBoundary's fallback property. Optionally, you can define which errors an error boundary can handle, giving you fine control over error handling. Sync or async? In general, a component should be async if it must await some async call inside. If a component executes a potentially \"long-running\" synchronous call, it is strongly recommended to delegate that call to a worker thread an await it (thus making the component async). This can be done for example with anyio's to_thread utility, starlette's (or fastapi's) run_in_threadpool(), and so on. The goal here is to avoid blocking the asyncio event loop, as that can lead to performance issues. In all other cases, it's best to use sync components. Framework integrations FastAPI: FastHX Why At one end of the spectrum, there are the complete application frameworks that combine the server (Python) and client (JavaScript) applications with the entire state management and synchronization into a single Python (an in some cases an additional JavaScript) package. Some of the most popular examples are: Reflex, NiceGUI, ReactPy, and FastUI. The main benefit of these frameworks is rapid application prototyping and a very convenient developer experience (at least as long as you stay within the built-in feature set of the framework). In exchange for that, they are very opinionated (from components to frontend tooling and state management), the underlying engineering is very complex, deployment and scaling can be hard or costly, and they can be hard to migrate away from. Even with these caveats, they can be a very good choice for internal tools and application prototyping. The other end of spectrum -- plain rendering engines -- is dominated by the Jinja templating engine, which is a safe choice as it has been and will be around for a long time. The main drawbacks with Jinja are the lack of good IDE support, the complete lack of static code analysis support, and the (subjectively) ugly syntax. Then there are tools that aim for the middleground, usually by providing most of the benefits and drawbacks of complete application frameworks while leaving state management, client-server communication, and dynamic UI updates for the user to solve, often with some level of HTMX support. This group includes libraries like FastHTML and Ludic. The primary aim of htmy is to be an async, pure-Python rendering engine, which is as simple, maintainable, and customizable as possible, while still providing all the building blocks for (conveniently) creating complex and maintainable applications. Dependencies The library aims to minimze its dependencies. Currently the following dependencies are required: anyio: for async file operations and networking. async-lru: for async caching. markdown: for markdown parsing. Development Use ruff for linting and formatting, mypy for static code analysis, and pytest for testing. The documentation is built with mkdocs-material and mkdocstrings. Contributing All contributions are welcome, including more documentation, examples, code, and tests. Even questions. License - MIT The package is open-sourced under the conditions of the MIT license.",
    "commentLink": "https://news.ycombinator.com/item?id=42251919",
    "commentBody": "Htmy ‚Äì Async, pure-Python rendering engine (volfpeter.github.io)122 points by friendly_deer 17 hours agohidepastfavorite51 comments liendolucas 5 hours agoI can't clearly see a use case. I went on to the \"why\" section but I'm having a hard time trying to understand what this is trying to solve. Perhaps a clear and simple example to see why you would use it could be useful. Also I find it extremely verbose to write HTML the way is shown in the examples at the top. Having used Jinja for a very long time, its simplicity and separation from logic makes it almost (for me) the only templating lang that you need to learn in Python. Writing HTML code the way is shown is clearly not for me, but there might be uses cases for it. reply v3ss0n 3 hours agoparentSometimes I want to do things totally pure html, with more dynamicness and more reusability. Jinja template fall short. reply rafram 13 hours agoprevNot clear why HTML rendering needed to be infected with async. None of the example code has a clear need for async - even the `is_admin()` method would be a prefetched property in any reasonable database model. reply scotty79 6 hours agoparentAsync infrastructure allows your stuff to be sync or async. While sync infrastructure forces your stuff to be sync. If anything sync (not async) infects everything you do. Of course it depends if you call the infrastructure (then it's better for it to be sync) of if the infrastructure calls you (then it's better to be async). Rendering engine is something you rarely call, but it often calls your functions. reply rafram 4 hours agorootparentYes, and that‚Äôs the worst part of async. That‚Äôs why you need to be very strategic about where you introduce it into your code in order to minimize the number of functions it infects, not give up and write a framework that‚Äôs all async for no good reason. https://journal.stuffwithstuff.com/2015/02/01/what-color-is-... reply scotty79 3 hours agorootparentYes. But you should be equally strategic about introducing sync code into your platform. Because making your platform sync basically makes it only be able to call sync functions of your code. It's not that async infects. It's sync that infects and restricts. We are just used to it by default. The fact that we started from sync was the cause of all the trouble of rpc because everything outside of CPU is innately async. So make your utility functions sync whenever you can but make your platforms and frameworks async. reply rafram 2 hours agorootparentI just completely disagree. Async is syntactic sugar that can be reduced to sync code with callbacks. It doesn‚Äôt exist on equal footing. If you want to call sync code from async code, you just‚Ä¶ call it. If it performs blocking IO, it‚Äôll block, but that‚Äôs exactly what it would do if called from other sync code, too. By contrast, calling async code from sync code requires a special blocking wrapper (Python) or unavoidably breaks control flow (JavaScript). reply scotty79 1 hour agorootparent> By contrast, calling async code from sync code requires a special blocking wrapper (Python) ... That's exaclty my point. If you don't have async by default in your platform you need to do stupid things to fake it. If function calls and main in Python were innately async you could be calling async code just as easily as sync code. > [...] or unavoidably breaks control flow (JavaScript). async/await syntax avoids it completely. Tbh await should be default function call semantics and there should be special keyword for calling without awaiting. But since we come from sync primitives that would require small revolution that might happen at some point. > Async is syntactic sugar You could make sync code be syntactic sugar for await. reply crubier 20 minutes agorootparent> Tbh await should be default function call semantics and there should be special keyword for calling without awaiting. Your comment made me realize this is exactly what golang \"go\" keyword does. This is actually great. reply gpderetta 1 hour agorootparentprev> would require small revolution that might happen at some point. or python could have blessed gevent and done away with all the nonsense. reply hansvm 11 hours agoparentprevYour counterpoint still naturally involves something like async _somewhere_ (your proposal is just to move it out of the HTML rendering and into an initial data-gathering stage). If you accept that premise then the question is just where the async code goes. While on some level it makes sense for HTML rendering to be a pure function where the inputs are gathered from elsewhere (potentially asynchronously), it looks like htmy wants to make it easy to define hierarchies of components. Instead of `is_admin()`, imagine a dashboard whose layout is stored in a database, supporting configurable charts of various flavors. The heterogeneity of the data supporting different types of charts makes it hard to efficiently pull data in a single SQL query (equivalently, any reasonable database model), so somewhere in your code you're pulling a bunch of data asynchronously, and somewhere else you're rendering it. The question, still, is \"where?\" Going back to the idea of htmy defining hierarchies of components, imagine how annoying it would be to have to manually grab all the data for a \"reporting page\" component only to feed it straight back into the renderer -- either having to duplicate the hierarchial structure when feeding data into the renderer (a technique some UI libraries employ, though I don't like it) -- or having to come up with a method for flattening that hierarchy when instantiating the component (another technique some UI libraries employ, one I like more for small projects and less for large ones). They solve that (to the extent that you think it needs solving) by bundling all that background logic into the components themselves. Did they really need to implement that recursively instead of just walking the hierarchy, gathering the data up-front, and populating it? Eh. The code winds up being similar either way, and either way it definitely forces async back into the middle of HTML rendering. Mind you, that tends to either make some applications hard to build or to cause the framework to explode in complexity over time as people need new and new ways to say \"yes, re-render this thing; no, re-render that other thing, but don't grab its data, ....\" There's enough less particularly annoying code involved though that fat, smart components are a natural place for people to gravitate. Unrelated to htmy completely, a technique I like from time to time even for problems which don't need async per se (and I'm usually using lower-level languages, so the implementation is some sort of more manual continuation pattern, but all those things are basically async, so I won't dwell on the details) is explicitly designing pausable/restartable structures for long-running computations. It's about as easy to write as purely iterative code, and you can run the result as purely iterative with no runtime overhead, so the downsides are low. It opens the door though to easily tuning how long you defer invariant maintenance (too infrequent and your algorithm devolves to the slow thing it's replacing, too frequent and the overhead isn't worth it), easily checkpointing a computation, adding other custom runners for an algorithm (like animating its progress), .... I can absolutely see a use-case for wanting to visualize each step of an HTML rendering, or log OS network counters after each step, and so on. Python's async isn't really the right tool for the job for that (it's hard to modify the runtime to support them without building quite a lot of nonsense from scratch), but async in the abstract isn't bad at all per se. reply mattigames 11 hours agoparentprevImagine you have 2 big components, one fetches from an third-party API and the other from your backend, this way they can load at the same time instead of sequentially. reply anentropic 7 hours agorootparentI was imagining more like you have a Django view that does all the async data fetching and then you hand off the results to a 'dumb' page component that does only rendering I guess the point is to have components know how to fetch their own data, particularly when combining with HTMX and having backend return page fragments that correspond to components. But maybe this makes more sense in React than it does when translating the pattern back to server-side? e.g. same author has this https://github.com/volfpeter/fasthx?tab=readme-ov-file#htmy-... which is doing that, but there's still a 'view' endpoint. Why not put the data fetch code there and have 'dumb' components that don't need to be async? reply rafram 2 hours agorootparentprevBut does it actually work that way? If I `await fetch_from_api()` in the first component before returning the tree with the second component that fetches from my backend, `fetch_from_api()` has to resolve before Htmy finds out about the second component. reply ramon156 11 hours agorootparentprevBecause checking for two conditions is impossible? This seems like a solution for a non-existent problem. I could be missing something reply keithasaurus 13 hours agoprevThere's a bunch of these kinds of html renderers. Here's mine: https://pypi.org/project/simple-html/ But there are many others. Not sure I understand the point of async rendering, unless you want to mix IO with rendering? Which feels a bit too close to old PHP+html for my blood. reply guidopallemans 11 hours agoparentWhat's wrong with the old PHP+html ways? It's one of the best toolchains to knock out a small to medium sized project. I guess that fundamentally, it's not scalable at all, or can get messy wrt closing tags and indenting. But with this approach I think you're good on both these aspects? reply johnisgood 6 hours agorootparentFor websites you make for Tor, you would typically go for PHP or OpenResty, as it needs to be JavaScript-free. I personally aim for JavaScript-free projects regardless. Of course if you want client-side whatever, you need JavaScript. reply skeledrew 35 minutes agorootparentJavaScript is optional even on the client side nowadays with the advent of PyScript via WASM, etc. reply v3ss0n 3 hours agoprevThis is what I am looking for.When FastHTML was announced I expected to work like this one but it was with it's own webserver. reply voidUpdate 4 hours agoprevHypertext markup Yanguage? reply 01HNNWZ0MV43FF 12 hours agoprevOh it's server side \"rendering\"? reply Jaxan 9 hours agoparentTo me ‚Äúrendering engine‚Äù also means something else. Namely taking html and rendering it to the screen. reply zupa-hu 4 hours agorootparentConsider updating your vocabulary because the term is often used for both. Note that rendering to the ‚Äúscreen‚Äù really means writing bits at a memory range, which is just one interface for displaying things. Html is another, higher level interface these days. reply mixmastamyk 28 minutes agoprevI like the htmy method that an object can render itself, neat idea. But the extra classes for rows etc seems too bureaucratic. reply azinman2 11 hours agoprevBut what do you do use to create dynamic updates on the client side? I‚Äôm guessing it still has JS and makes API calls, no? And if so, it seems easier (to me) to just do all of the rendering client side and let the backend just be REST queries. reply mattigames 10 hours agoparentThis is just the static html renderer, it has no JavaScript to update client side, but the author has another project for fastapi + this + htmx: https://github.com/volfpeter/fasthx reply pplante 14 hours agoprevI was looking for something like this a few weeks ago. I typically use Django and hate the template engines limitations. I needed to make some reusable components and the best option available was switching to jinja to get their macro support, bleh. This reminds me of the best part of Flutter UI composition, but in a language I always return to. Have you done any benchmarking? I don't even know what the comparison would be. reply kissgyorgy 11 hours agoparentCheck this out: https://compone.kissgyorgy.me/ Much simpler than this library, components are simply functions, rendered to strings. I made one microbenchmark, it's \"only\" 2x slower than Jinja2 right now, but I know how to make it faster. reply anentropic 8 hours agorootparentif you can make it as fast as jinja2 I'm sold ...I haven't done my own benchmarking but so far I haven't seen any of these HTML-in-Python libs able to report comparable performance I've implemented a bunch of AlpineJS \"components\" as jinja macros in my current project and ... it works, but it's pretty ugly and it sucks not having type safety or ability for the IDE to understand connections between the template and the Python code what I really want is something like JSX/TSX for Python... having gone through this process I can see why that approach is desirable. I kind of feel like libs which mimic the syntax but unable to provide the type-safety/IDE support are missing the point. So although I love the look of \"Python HTML element objects\" approach libs like yours and OP have I think for now it is probably the best way available. for my current project we are pre-compiling all the jinja templates (via Jinja's own utils) for deployment as AWS Lambda I did look into JinjaX but it has its own separate jinja env and secondary template cache and didn't look like it would be easy to plug it into the pre-compile step reply rubenvanwyk 7 hours agorootparent+1 for TSX for Python, that would be great! reply neeleshs 12 hours agoparentprevYou might want to look at django-cotton for components reply ddanieltan 14 hours agoprevHow does this compare with FastHTML? reply revskill 6 hours agoparentSlower because there is no fast in the name. reply globular-toast 1 hour agoprevThere is already htpy: https://htpy.dev/ I have used it in production and like it. For those asking the point is being able to do similar to React JSX components, but on the server side. It's so much nicer to use than templates like Django or Jinja (there might be other reasons, but this is quite clearly the goal of htpy and I assume this too). Just looking at this one briefly it seems to use magic methods on dataclasses. What's the advantage of that over just a function? Seems like unnecessary nesting. reply murkt 14 hours agoprevWould love to see some benchmarks for all these libraries that compare them to Jinja2. reply throwaway314155 14 hours agoprevLooks great. Anyone using this in production? reply DonnyV 2 hours agoprevRendering html is something that needs to happen within 300ms. Anything more and its perceived as lagging. So why would you choose python to do visual rendering? reply nickpsecurity 58 minutes agoparentIt could be useful for content creators that value reusing their Python expertise over other factors. Also, many apps work better when every integrated component is written in the same language. Also, there‚Äôs a lot of code in Python for or supporting web programming. Finally, if people use AI auto-complete, many people say they‚Äôre more effective at common uses of Python vs other languages or situations. I‚Äôve found the performance issue to be serious in some situations. Fortunately, there‚Äôs a number of accelerators for Python code that boost its performance. They range from JIT‚Äôs (eg PyPy) to custom VM‚Äôs (eg Cinder) to writing fast paths in Cython to Python-to-C++ compilers (eg mycpp). So, you get the productivity and familiarity of Python with performance boosting in many use cases. If it doesn‚Äôt work, then it‚Äôs better to write that component as an extension in a systems language. reply dcreater 14 hours agoprevIs there a comparison or guide to choosing python frameworks? Every few weeks there's a new one posted here reply eyegor 13 hours agoparentIn the real world, for web things, people use django or fastapi. I'd suggest picking a project with lots of stackoverflow questions and poking around their docs to see which makes you the most comfortable. Personally I tend to favor litestar these days since it has good docs and issues don't sit around for years waiting on one dude to merge prs (fastapi) and it's a lot nicer than django (and I hate django docs). Flask/quart are painful to work with due to horrible documentation in my experience, but they're popular too. Quart is just an async rewrite of flask by the same owners. Litestar has a half baked comparison chart here: https://docs.litestar.dev/latest/ reply fermigier 7 hours agoparentprevNot a comparison, but a fairly comprehensive list that I maintain, with github stars as a proxy for popularity: https://github.com/sfermigier/awesome-python-web-frameworks Note: as you probably know, popularity is not necessarily correlated with \"actively maintained\". For instance, Hug and Sanic are quite popular, but haven't seen a commit for quite a long time. reply devjab 12 hours agoparentprevI think the ‚Äúrule of thumb‚Äù is that none of them are better than using HTMX with templates. HTMX obviously having some limits in terms of security and complex REBAC. reply anentropic 7 hours agorootparentHTMX + templates are complementary to a backend framework rather than an alternative to one reply LaundroMat 11 hours agorootparentprevOr Unpoly. I've been working with it for a month now and it's a real pity such a robust library it gets so little attention. reply jackson928 13 hours agoprevLooks similar to a framework I've been using for some personal sites reflex.dev, pretty cool when would you recommend using this over that? reply BiteCode_dev 10 hours agoprevnext [2 more] [flagged] anentropic 8 hours agoparentif anything this lib seems intended to be complementary to both reply eddautomates 11 hours agoprev [‚Äì] I think in almost-2025 any dataclass heavy library should probably use pydantic (or support it) reply tirpen 11 hours agoparentProbably, but I fail to see how that's relevant here. This is not a \"dataclass heavy\" library in any sense, they just used dataclass in the examples to make them shorter. Based on everything I see in the documentation, you should be able to use Pydantic models as well, or standard python objects, or anything else, as long as it has a method `def htmy(self, context: Context) -> Component`. reply franga2000 11 hours agoparentprev [‚Äì] Please don't! Pydantic demands 100% type correctness at runtime in a language that can't guarantee basically anything at \"compile\" (lint) time. Screw up one type annotation for one edge case and your entire system turns into one big ValidationError. Dataclasses let you return \"incorrect\" data and that's a good thing. I'd rather get an unexpected None here and there (which can be handled) than have library code crash because the wrong type snuck into a field I don't even care about. As for support, is any explicit support needed? You can Pydantic models into things expecting dataclasses and often the other way around too. reply worthless-trash 10 hours agorootparent [‚Äì] Spoken like a true dynamic types programmer. Some programmers prefer having errors over these surprises. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"htmy\" is a pure-Python rendering engine that supports asynchronous and synchronous function components, React-like context management, and built-in HTML tags, making it versatile for various web development needs.- It offers features like Markdown support, JSON-based internationalization, and easy integration with any backend or frontend frameworks, enhancing its adaptability and customization.- The library is open-sourced under the MIT license, encouraging community contributions, and can be installed via PyPI using `pip install htmy`."
    ],
    "commentSummary": [
      "Htmy is an asynchronous, pure-Python HTML rendering engine, sparking debate over its verbosity compared to Jinja and the necessity of async in HTML rendering.",
      "The discussion highlights the potential benefits of async for dynamic data fetching in component-based designs, though opinions vary on whether it complicates code.",
      "Htmy aims to provide a flexible rendering solution, but its advantages over established tools like Jinja are still under discussion."
    ],
    "points": 122,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1732669853
  }
]
