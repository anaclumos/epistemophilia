[
  {
    "id": 41753741,
    "title": "Arthur Whitney's one liner sudoku solver (2011)",
    "originLink": "https://dfns.dyalog.com/n_sudoku.htm",
    "originBody": "svec ← {shape←⍬⍴(⍴⍵)*÷2} ##.sudoku prob ⍝ Solution vector for Sudoku problem ⍵. The Sudoku puzzle consists of a 3×3 grid of 3×3 boxes, each cell of which is either empty or contains a number in the range 1 to 9. A typical problem might look like this: ┌─────┬─────┬─────┐ │· · 1│6 9 ·│5 · ·│ │4 · ·│2 7 ·│· · 1│ │· 7 ·│· · ·│· 9 ·│ ├─────┼─────┼─────┤ │· · ·│· · ·│· 3 ·│ │· · ·│4 3 ·│· · 7│ │· · ·│7 8 ·│6 · ·│ ├─────┼─────┼─────┤ │· · 6│· · ·│8 · ·│ │· 2 ·│1 4 ·│· 6 ·│ │· 1 ·│3 5 ·│· 4 ·│ └─────┴─────┴─────┘ The challenge is to supply the missing numbers in such a way that: each 3×3 box and each 9-item row and each 9-item column contains each of the 9 numbers with no repeats. A solution to the above problem might be: ┌─────┬─────┬─────┐ │3 8 1│6 9 4│5 7 2│ │4 6 9│2 7 5│3 8 1│ │2 7 5│8 1 3│4 9 6│ ├─────┼─────┼─────┤ │7 9 4│5 6 2│1 3 8│ │6 5 8│4 3 1│9 2 7│ │1 3 2│7 8 9│6 5 4│ ├─────┼─────┼─────┤ │5 4 6│9 2 7│8 1 3│ │9 2 3│1 4 8│7 6 5│ │8 1 7│3 5 6│2 4 9│ └─────┴─────┴─────┘ The puzzle may be generalised to accept problems of shape other than 3×3×3×3, see examples below. Argument matrix [prob] contains numbers 1-9 in occupied cells and 0s otherwise. Optional left argument [shape] specifies the box shape for non-square problems. The result is a vector of all solution matrices. Technical notes: This solution was supplied by Veli-Matti Jantunen, who says: ⍺ may be used to denote the sudoku rectangle, the default is 2/(↑⍴⍵)*0.5 (eg. if \"mat\" is a 6x6 matrix and the sub area is 2 3, the call must be 2 3 sudoku mat). The result is a vector of all the solutions found, or ⍬ (no solutions) or '' (error - should not happen, but if there are zillions of results) The algorithm is simple: handle the matrix as a vector the rows, columns and sudoku areas are denoted by index vectors do the basic checking for the puzzle (i.e. polish) and with the main function check one alternative from the list at time: filter all the possible elements for all the cells if at least one cell is empty = no solution -> take the next from the list if one cell contains more than one number -> select the cell from the tightest group and add every combination (from this cell) to the list if all cells contain one number = solution -> take the next from the list. Veli-Matti also provides this new-from-old problem shuffler: Shuffle←{ ⍝| Shuffle the original sudoku table to another one ;) ⍝| ⍺: sudoku box (use for e.g. 6x6 tables, like 2 3 Shuffle table). ⍺←(⍴⍵)*0.5 ⋄ (⎕IO ⎕ML ⎕RL)←1 3(⎕TS+.*2) (¯1+?3⍴2){(⌽⍣(↑⍺))(⍉⍣(↑1⌽⍺))(⊖⍣(↑⌽⍺))⍵}⍵{(0,(↑⍴⍺)?↑⍴⍺)[⍵⌷⍺+1]}(↑⍴⍵){∊{⍵[(⍴⍵)?⍴⍵]}{⍵[(⍴⍵)?⍴⍵]}¨⍵⊂⍳⍺}¨⍺/¨⍳¨⌽⍺ } David Crossley supplies an alternative coding: sudoku←{⎕IO←0 ⍝ Sudoku - ⍵: N×N setup where box size N*÷2 is integral ⍝ The setup is a valid arrangement in some cells of numbers from 1-N; the rest are 0´s. ⍝ Each row, column and the N boxes of each result must contain all numbers 1 to N. · valid←{⍝ Validate. ⍵ be... (2≠⍴⍴⍵)∨(≠/2↑⍴⍵)∨0≠1|(⊃⍴⍵)*÷2:1 ⍝ a square matrix with an integral box size ((⍴⍵)⍴0)≢⊃1↑0⍴⊂⍵:1 ⍝ numeric N×N matrix 1∊~⍵∊⍳1+⊃⍴⍵:1 ⍝ numbers 0-N only 0=+/,⍵ ⍝ at least one number } box←{⍵⌿(⍵×⍳⍵)∘.+⍵/⍳⍵} ⍝ Box template ⍵:sq root of size chk←{1∊1⊃⍺:⍵ ⍝ no cell p←⍵ ⋄ p[;⊃⍺]←⍺[1]=⍳⊃⍴⍵ ⋄ p ⍝ item ⍺ in to 1, rest of cell to 0 } next←{⍝ Cell-value pairs for possible values ⍵{⍵,¨iv ⍺[;⍵] ⍝ in the cell with the minimum nr of }{1⍳⍨⍺\\{⍵=⌊/⍵}⍺/⍵}/{(⍵>1)⍵}+⌿⍵ ⍝ possibilities (2 or more) } rules←{⍝ Apply logic tests to resolve cells ~0∊⊃z←sole ⍵:z ⍝ detect single-value possibilities ~0∊⊃z←↑singles/(⍳⊃⍴RCB),⊂z:z ⍝ single-valued cells in row/col/box ~0∊⊃z←↑uniques/(⍳(⍴⊃z)*÷2),⊂z:z ⍝ values unique to one row/col of a box ~0∊⊃z←↑NinN/4 3 2,⊂z:z ⍝ detect N vals in N cells ~0∊⊃z←↑matches/4 3 2,⊂z:z ⍝ matches of N vals in N cells of r/c/b z≡⍵:⍵ ⍝ finish if no state change ∇ z⍝ otherwise repeat rules } sole←{⍝ Resolve sole value cells. ⍺:soln, ⍵:possibles ~0∊⊃r p←⍵:⍵ ⍝ pass through 0∊n←+⌿p:⍬ ⍬ ⍝ no go (⍴r)=i←1⍳⍨n×r=0:⍵ ⍝ no remaining single value cells r[i]←1+p[;i]⍳1 ⍝ set result value p[¯1+i⊃r;i~⍨iv i⊃Masks]←0 ⍝ remove as possible value in related cells ∇ r p ⍝ check for further single-value cells } singles←{ ⍝ Fix box cells that resolve to single value ~0∊⊃r p←⍵:⍵ ⍝ pass through i←RCB[⍺;] ⍝ cells in row, col or box b←i/p ⍝ possibles for cells ~1∊l←(1=+/b)∧~(1+⍳⊃⍴p)∊i/r:⍵ ⍝ values that occur just once ex result values c←(iv i)[(↓l⌿b)⍳¨1] ⍝ cells where they occur p[;c]←(⍳⊃⍴p)∘.=iv l ⍝ modify to just the single value sole r p ⍝ resolve the sole values } uniques←{ ⍝ Unique to one row/col of the ⍺´th box ~0∊⊃r p←⍵:⍵ ⍝ pass through b←p[;⍺⊃Box] ⍝ box cell values i←(⍴i)⊤iv,(i>1)∧i=⍉(⌽⍴i)⍴+/i←+/b ⍝ 2 or more unique to a row j←(⍴j)⊤iv,(j>1)∧j=⍉(⌽⍴j)⍴+/j←+/[1]b ⍝ 2 or more unique to a column (0∊⍴i)∧0∊⍴j:⍵ ⍝ none found s←⊃⌽⍴b ⍝ box size p[(s(⍺ rinds)↓i),s(⍺ cinds)↓j]←0 ⍝ remove vals from cols of other boxes sole r p ⍝ resolve sole values } rinds←{⍝ uniques: row pick inds to update 0=⍴⊃⍵:0⍴⊂0 0 ↑,/(0⊃⍵),¨¨((⍺*2)×(1⊃⍵)+¨⍺×⌊⍺⍺÷⍺)+⊂(⍳⍺*2)~(⍺×⍺|⍺⍺)+⍳⍺ } cinds←{⍝ uniques: column pick inds to update 0=⍴⊃⍵:0⍴⊂0 0 ↑,/(0⊃⍵),¨¨((1⊃⍵)+¨⍺×⍺|⍺⍺)+⊂(⍺*2)×(⍳⍺*2)~(⍺×⌊⍺⍺÷⍺)+⍳⍺ } matches←{ ⍝ Resolve exact matches on ⍺ possible values ~0∊⊃r p←⍵:⍵ ⍝ pass through 0∊n←+⌿p:⍬ ⍬ ⍝ no go if no possibilities for a cell i←(n=⍺){iv ⍺\\un 2⊥⍺/⍵}p ⍝ cells with ⍺ possible values sole↑(⍺ match)/i,⊂⍵ ⍝ resolve each ⍺-set then sole values } match←{⍝ Resolve exact matches in row/col/box ~0∊⊃r p←⍵:⍵ ⍝ pass through ⍺⍺≠+/p[;⍺]:⍵ ⍝ cell no longer has ⍺⍺ values ⍺⍺>+/l←p[;⍺]∧.=p:⍵ ⍝ occurrences of matches with the ⍺´th cell 1∊⍺⍺⍺⍺ matches in any row/col/box ~1∊n=⍺⍺:⍵ ⍝ no r/c/b´s with exactly ⍺⍺ matches p←↑(l do_matches)/(iv n=⍺⍺),⊂p ⍝ remove matched vals from related cells sole r p ⍝ resolve singles then sole values } do_matches←{ ⍝ Remove vals from other row/col/box cells p←⍵⍝ ⍺⍺ marks all occurrences of match p[iv p[;⍺⍺⍳1];iv RCB[⍺;]∧~⍺⍺]←0 ⍝ filter occurrences in the ⍺´th row/col/box p } NinN←{⍝ Reduce ⍺-sets in exactly ⍺ cells of a row/col/box ~0∊⊃r p←⍵:⍵ ⍝ pass through s←⍺ sets(⍴r)*÷2 ⍝ all combns of sets of ⍺ values l←r=0 ⍝ non-singular cells n←(⍺=(s∨.∧p)+.∧⍉RCB)∧⍺=(s∨.∧l\\l/p)+.∧⍉RCB ⍝ set-RCB combinations with ⍺ occurrences i←↓[0](⍴n)⊤iv,n ⍝ indices of set-RCB combns sole↑(s do_NinN)/i,⊂⍵ ⍝ reduce non-set values from cells then sole values } do_NinN←{ ⍝ Remove values not in set ⊃⍺ from identified cells i←⍺⍺[0⊃⍺;] ⋄ j←RCB[1⊃⍺;] ⍝ set values / row-col-box mask r p←⍵ ⋄ p[iv~i;iv j∧i∨.∧p]←0 ⋄ r p ⍝ [vals not in set;cells in set and in row/col/box] } setup←{⍝ Setup LM possibilities per cell p←(⊂1+⍳⊃⍴⍵)~¨Masks/¨⊂,⍵ ⍝ possibles per cell, except... ((0≠,⍵)/p)←0~⍨,⍵ ⍝ adjust given cells to single value (1+⍳⊃⍴⍵)∘.∊p ⍝ convert to LM vals×cells } res←(⍴⍵)∘{⍺∘⍴¨((⍴⍵)⍴(×/⍺)↑1)⊂⍵} ⍝ Shape result(s) · valid ⍵:'Invalid setup' ⍝ Validate RCB←{,¨(⍵/⍳⍵)(⍵ ⍵⍴⍳⍵)(box ⍵*÷2)}⊃⍴⍵ ⍝ Rows-Columns-Boxes Masks←↓↑∨/{⍵∘.=⍵}¨RCB ⍝ Sets per cell of related row/col/box cells RCB←↑⍪/(⊂⍳⊃⍴⍵)∘.=¨RCB ⍝ Selection vectors for rows,columns,boxes Box←((⍴⍵)*÷2)∘⍴¨(↓RCB[(2×⊃⍴⍵)+⍳⊃⍴⍵;])/¨⊂⍳×/⍴⍵ ⍝ Box indices 1∊chk¨Masks/¨⊂,⍵:'Invalid setup' ⍝ Duplicates in row/column/box · res∊¯1 0 search(,⍵)(setup ⍵) ⍝: ADC 5Jun2005 } Finally, here is Arthur Whitney's amazing solution in K 5: x(,/{@[x;y;]'(!10)^x*|/p[;y]=p,:,3/:-3!p:!9 9}')/&~*x Translated by Phil Last into a D-function: sudoku←{⎕io←0 ⍝ Whitney/Last p←{(↑⍵)∘{(⍺∨.=⍵)/⍳n×n}¨,⍵},(n*÷2){⍵,⍺⊥⌊⍵÷⍺}¨⍳n n←⍴⍵ m←{(⊂⍵)⌈(⊂⍺=⍳⍴⍵)×(1+⍳n)~⍵[⍺⊃p]} (⍴⍵)∘⍴¨⊃{⊃,/⍺ m¨⍵}/{(⍸⍵=0),⊂⊂⍵},⍵ } Morten Kromberg's recasting defines some of K's constructs explicitly and so is closer to the original. Note that, like the K version, it takes and returns 81- vectors, rather than matrices. sudoku←{ ⍝ Define one k fn and one op missing from APL wh←{⍸⍵≠0} ⍝ k '&' function mg←{a←⍺ ⋄ a[⍺⍺]←⍵ ⋄ a} ⍝ merge operator: r←old (indexes mg) new rcq←(↑,⍳9 9),3/,3⌿3 3⍴⍳9 ⍝ Row, Column, Quadrant p←{wh rcq∨.=⍵}¨↓rcq ⍝ Cells in same row, col or quadrant nzd←1+⍳9 ⍝ Non-zero digits for a little more speed ⊃{⊃,/⍺{⍵∘(⍺ mg)¨nzd~⍵[⍺⊃p]}¨⍵}/(wh ⍵=0),⊂⊂⍵ ⍝ kapow! } Roger Hui presents this in the following more beautiful form, generalised for non-square puzzles: Sudoku←{⍺←(⍴⍵)*÷2 ⍝ Solutions of shape-⍺ Sudoku puzzle ⍵. svec ← {⊃pvex/(emt ⍵),⊂⊂⍵} ⍝ solution vector pvex ← {⊃,/⍺∘pvec¨⍵} ⍝ vector of placements pvec ← {(⍺ avl ⍵)⊣@(⊂⍺)¨⊂⍵} ⍝ placements avl ← {(⍳⊃⍴⍵)~⍵×⊃⍺⌷CMAP} ⍝ list of available numbers emt ← {(,⍵=0)/,⍳⍴⍵} ⍝ row & column indices of empty cells rcb ← {(⍳⍴⍵),¨⍺ box(⍴⍵)÷⍺} ⍝ row/column/box numbers box ← {(⊃⍺)⌿(⊃⌽⍺)/⍵⍴⍳×/⍵} ⍝ box numbers for a puzzle of size ⍵*2 cmap ← {⊂[⍳2]1∊¨⍵∘.=⍵} ⍝ contention map for puzzle ⍵ CMAP ← cmap ⍺ rcb ⍵ ⍝ contention map for puzzle svec ⍵ ⍝ vector of solutions. } See →sudoku_bfs← for an illustration of this algorithm. See \"Learn\" in: http://www.TryAPL.org for step-by-step demonstration. Watch: http://www.youtube.com/watch?v=DmT80OseAGs to see it in action. Thanks also to Maurice Jordan and John R. Clark for suggestions. Examples: s33⍝ sample 3×3 problem. 0 0 1 6 9 0 5 0 0 4 0 0 2 7 0 0 0 1 0 7 0 0 0 0 0 9 0 0 0 0 0 0 0 0 3 0 0 0 0 4 3 0 0 0 7 0 0 0 7 8 0 6 0 0 0 0 6 0 0 0 8 0 0 0 2 0 1 4 0 0 6 0 0 1 0 3 5 0 0 4 0 sudoku s33 ⍝ ... has 3 solutions. ┌─────────────────┬─────────────────┬─────────────────┐ │3 8 1 6 9 4 5 7 2│2 8 1 6 9 3 5 7 4│2 8 1 6 9 3 5 7 4│ │4 6 9 2 7 5 3 8 1│4 6 9 2 7 5 3 8 1│4 6 9 2 7 5 3 8 1│ │2 7 5 8 1 3 4 9 6│3 7 5 8 1 4 2 9 6│5 7 3 8 1 4 2 9 6│ │7 9 4 5 6 2 1 3 8│7 9 2 5 6 1 4 3 8│7 9 2 5 6 1 4 3 8│ │6 5 8 4 3 1 9 2 7│6 5 8 4 3 9 1 2 7│6 5 8 4 3 9 1 2 7│ │1 3 2 7 8 9 6 5 4│1 3 4 7 8 2 6 5 9│1 3 4 7 8 2 6 5 9│ │5 4 6 9 2 7 8 1 3│5 4 6 9 2 7 8 1 3│3 4 6 9 2 7 8 1 5│ │9 2 3 1 4 8 7 6 5│9 2 3 1 4 8 7 6 5│9 2 5 1 4 8 7 6 3│ │8 1 7 3 5 6 2 4 9│8 1 7 3 5 6 9 4 2│8 1 7 3 5 6 9 4 2│ └─────────────────┴─────────────────┴─────────────────┘ ⍝ This function separates inner boxes for easier reading: sbox←{⎕IO←0 ⍝ Box sudoku grids. ⍺←(⍴⍵)*÷2 ⍝ default square cells. vp hp←0=⍺|⍳¨⍴⍵ ⍝ vert and horiz partition vectors. numbs←⍉↑vp∘(⊂[0])¨hp⊂⍵ ⍝ numeric sub-areas. width←2+⌊10⍟⌈/1,,⍵ ⍝ digits per number. fmt←width∘{⍵=0:⌽⍺↑'·' ⋄ ⍺ 0⍕⍵} ⍝ dots for zeros. cells←0 1∘↓¨↑∘(,/)¨fmt¨¨numbs ⍝ char matrix sub-areas. hv←⍺⍴¨⊂¨⌽(⍴⊃cells)/¨'│─' ⍝ vert and horiz boundaries. in←{↑⍺{⍺,⍺⍺,⍵}/⍵} ⍝ ⍺ separates ⍵. (t m b)lr←'┬┼┴' '├┤'in¨∘⊂¨hv ⍝ bordering lines. body←m in⍉¨⊂[1 2]'│'in cells ⍝ collected cells. (⍉body in t b)in lr in¨'┌└' '┐┘' ⍝ boxed grid. } sbox¨ sudoku s33 ⍝ formatted solutions ┌─────┬─────┬─────┐ ┌─────┬─────┬─────┐ ┌─────┬─────┬─────┐ │3 8 1│6 9 4│5 7 2│ │2 8 1│6 9 3│5 7 4│ │2 8 1│6 9 3│5 7 4│ │4 6 9│2 7 5│3 8 1│ │4 6 9│2 7 5│3 8 1│ │4 6 9│2 7 5│3 8 1│ │2 7 5│8 1 3│4 9 6│ │3 7 5│8 1 4│2 9 6│ │5 7 3│8 1 4│2 9 6│ ├─────┼─────┼─────┤ ├─────┼─────┼─────┤ ├─────┼─────┼─────┤ │7 9 4│5 6 2│1 3 8│ │7 9 2│5 6 1│4 3 8│ │7 9 2│5 6 1│4 3 8│ │6 5 8│4 3 1│9 2 7│ │6 5 8│4 3 9│1 2 7│ │6 5 8│4 3 9│1 2 7│ │1 3 2│7 8 9│6 5 4│ │1 3 4│7 8 2│6 5 9│ │1 3 4│7 8 2│6 5 9│ ├─────┼─────┼─────┤ ├─────┼─────┼─────┤ ├─────┼─────┼─────┤ │5 4 6│9 2 7│8 1 3│ │5 4 6│9 2 7│8 1 3│ │3 4 6│9 2 7│8 1 5│ │9 2 3│1 4 8│7 6 5│ │9 2 3│1 4 8│7 6 5│ │9 2 5│1 4 8│7 6 3│ │8 1 7│3 5 6│2 4 9│ │8 1 7│3 5 6│9 4 2│ │8 1 7│3 5 6│9 4 2│ └─────┴─────┴─────┘ └─────┴─────┴─────┘ └─────┴─────┴─────┘ s22⍝ sample 2×2 problem. 0 2 3 4 3 0 0 0 2 0 0 0 4 0 0 0 sbox¨ sudoku s22 ⍝ ... has 3 solutions. ┌───┬───┐ ┌───┬───┐ ┌───┬───┐ │1 2│3 4│ │1 2│3 4│ │1 2│3 4│ │3 4│2 1│ │3 4│1 2│ │3 4│1 2│ ├───┼───┤ ├───┼───┤ ├───┼───┤ │2 1│4 3│ │2 1│4 3│ │2 3│4 1│ │4 3│1 2│ │4 3│2 1│ │4 1│2 3│ └───┴───┘ └───┴───┘ └───┴───┘ 3 4 sbox s34 ⍝ sample 3×4 problem. ┌───────────┬───────────┬───────────┐ │ 9 6 · ·│10 · · 8│ 2 · · 4│ │ · 1 · 11│ · 12 · ·│ · · 3 5│ │ · · · ·│ 6 · 7 11│12 · · ·│ ├───────────┼───────────┼───────────┤ │ · · 10 7│ · · · ·│ 4 · 9 ·│ │ 1 · 6 ·│12 11 · 4│ · 3 · ·│ │ · · 9 ·│ · 10 8 1│ · · 6 ·│ ├───────────┼───────────┼───────────┤ │ · 7 · ·│11 2 1 ·│ · 12 · ·│ │ 2 · 12 ·│ 4 · 6 5│ · 1 · 11│ │ · 10 · 5│ · · · ·│ 3 4 · ·│ ├───────────┼───────────┼───────────┤ │ · · · 10│ 5 8 · 7│ · · · ·│ │ 5 3 · ·│ · · 11 ·│ 9 · · ·│ │ 7 · · ·│ 3 · · 6│ · · 4 2│ └───────────┴───────────┴───────────┘ 3 4∘sbox¨ 3 4 sudoku s34 ⍝ ... has 2 solutions. ┌───────────┬───────────┬───────────┐ ┌───────────┬───────────┬───────────┐ │ 9 6 5 12│10 1 3 8│ 2 7 11 4│ │ 9 6 5 12│10 1 3 8│ 2 7 11 4│ │ 8 1 7 11│ 9 12 4 2│ 6 10 3 5│ │ 8 1 7 11│ 9 12 4 2│ 6 10 3 5│ │10 4 2 3│ 6 5 7 11│12 9 1 8│ │10 4 2 3│ 6 5 7 11│12 9 1 8│ ├───────────┼───────────┼───────────┤ ├───────────┼───────────┼───────────┤ │12 11 10 7│ 2 6 5 3│ 4 8 9 1│ │12 11 10 7│ 2 6 5 3│ 4 8 9 1│ │ 1 2 6 8│12 11 9 4│ 7 3 5 10│ │ 1 2 6 8│12 11 9 4│10 3 5 7│ │ 3 5 9 4│ 7 10 8 1│11 2 6 12│ │ 3 5 9 4│ 7 10 8 1│11 2 6 12│ ├───────────┼───────────┼───────────┤ ├───────────┼───────────┼───────────┤ │ 4 7 3 6│11 2 1 10│ 5 12 8 9│ │ 4 7 3 6│11 2 1 10│ 5 12 8 9│ │ 2 8 12 9│ 4 3 6 5│10 1 7 11│ │ 2 8 12 9│ 4 3 6 5│ 7 1 10 11│ │11 10 1 5│ 8 7 12 9│ 3 4 2 6│ │11 10 1 5│ 8 7 12 9│ 3 4 2 6│ ├───────────┼───────────┼───────────┤ ├───────────┼───────────┼───────────┤ │ 6 9 4 10│ 5 8 2 7│ 1 11 12 3│ │ 6 9 4 10│ 5 8 2 7│ 1 11 12 3│ │ 5 3 8 2│ 1 4 11 12│ 9 6 10 7│ │ 5 3 8 2│ 1 4 11 12│ 9 6 7 10│ │ 7 12 11 1│ 3 9 10 6│ 8 5 4 2│ │ 7 12 11 1│ 3 9 10 6│ 8 5 4 2│ └───────────┴───────────┴───────────┘ └───────────┴───────────┴───────────┘ See also: queens sudoku_bfs X sudokuX See also: http://www.ams.org/notices/200904/rtx090400460p.pdf See also: http://www.TryAPL.org See also: http://www.youtube.com/watch?v=DmT80OseAGs Back to: contents Back to: Workspaces",
    "commentLink": "https://news.ycombinator.com/item?id=41753741",
    "commentBody": "Arthur Whitney's one liner sudoku solver (2011) (dyalog.com)256 points by secwang 19 hours agohidepastfavorite163 comments nebulous1 17 hours agoHere is the line, it is written in K. K is a language created by the same person (Arthur Whitney) based on APL and Scheme. x(,/{@[x;y;]'(!10)^x*|/p[;y]=p,:,3/:-3!p:!9 9}')/&~*x Duanemclemore 2 hours agoprevFor me one of the most important things here is the clarity of the problem -maker- at the top. That's the difference between the \"Iversonian\" symbolic languages (J and K included) and others. It doesn't have the elegance and power of a one line solution, but it's just so clean and comprehensible even without the disciplined commenting. (Although I really think lamp is not a good comment glyph. Sorry about the sacred cow I just took a swipe at fellow array nerds.) One line solutions are incredible, and tacit is mind-bendingly cool. To use the unique compactness of a glyph-based language as a way to efficiently describe and perform functional programming - then to do that all over arrays!? - whoever had these ideas [0] is utterly genius. But as someone trying to make time to write a program ground up in APL, knowing that I won't be able to make it just a set of really good one liners, that example is also significant for me. [0] https://www.jsoftware.com/papers/fork.htm reply lokedhs 1 hour agoparentJust because you can write everything on one line without any spaces doesn't mean you should. You can ofcourse removethe capability to do thatand you'll effectively force the programmer to write more venous code, but then its strength as an interfacing tool is very much reduced. The Iversonian languages has the capability to write incredibly terse code which is really useful when working interactively. When you do, your code truly is write-only because it isn't even saved. This is the majority of code that at least I write in these languages. When writing code that goes in a file, you can choose which style you want to use, and I certainly recommend making it a bit less terse in those cases. The Iversonian languages are still going to give you organs that are much shorter than most other languages even even it's written in a verbose style. reply pjot 16 hours agoprev> Advocates of the language emphasize its speed, facility in handling arrays, and expressive syntax. Indeed. https://en.m.wikipedia.org/wiki/K_(programming_language) reply brookst 16 hours agoparent“Expressive” = like two cats fought while standing on the keyboard reply rtpg 11 hours agorootparentI've been messing with Uiua (https://www.uiua.org/) a good amount recently, and find its sort of dance between having a stack and being an array language somehow gets you to a nice level of legibility despite being a combo of two styles that tend to generate line noise. reply dahart 3 hours agorootparentThe front page there has examples like “÷3/+∿⊞×⊟×1.5.220×τ÷⟜⇡&asr” - is that closer to noise, or does it actually look more readable than K once you get used to both? I’m kind-of intrigued by the built-in multimedia output, but still this language looks scary and impractical at first glance. How does it compare to using numpy & jupyter? Do a lot of people prefer the extreme tenseness over using typeable keywords? I’m curious why it lets you type the readable operators but wants to turn them into glyphs; wouldn’t it be more approachable, more readable, and make more maintainable code, if it just used the keywords instead of glyphs? reply PhilipRoman 3 hours agorootparentprevCool language. I happened to notice the ⍜ operator, which operates on a transformed array, then reverts the transformation. Not sure if other array languages include this, but it's a really cool idea. I always found the traditional map/filter operators to be limiting in this regard, kind of like trying to write expressions without using parentheses. reply mlochbaum 2 hours agorootparentIt's in several, particularly newer APL dialects; see https://aplwiki.com/wiki/Under#History . Proud to say I originated the \"structural\" form used by Uiua, which is able to deal with transformations like filtering that lose parts of the input. Every language now seems to have its own take on what exactly Under means, with different implementations leading to different supported functions and various ways to relax the theory to be more convenient or handle intuitively expected things better. reply g8oz 4 hours agorootparentprevThanks for the link, it looks like a fascinating language reply xwolfi 15 hours agorootparentprevI work with it daily in a bank, and I couldnt find a better way to express it. Many colleagues throwing their keyboard in despair at this stupid impossible to remember syntax. reply nine_k 11 hours agorootparentNot that it's impossible to remember, bit it's definitely contrary to most traditional use of the symbols employed in it, though not without logic. My favorite is the functions from io package, called 0, 1, and 2 (yes, numbers) which handle interaction with stdin, stdout, and stderr respectively. In dyadic form they at least have a colon, but in monadic form they look like plain numbers: 1 \"Hello world\". I suspect that to study k (and use kdb) efficiently, you need to actively forget what you knew about the syntax of other languages, and study k as a language from Mars that happens to map to ASCII characters somehow. reply rak1507 15 hours agorootparentprevThere are a lot of things in various programming languages which are hard to remember, but k and array languages have such a small surface area, not being able to remember it while working with it daily amounts to learned helplessness. (source: mostly amateur k programmer, also worked with it in a bank, find it vastly easier to read/write/remember than most mainstream languages) reply anonzzzies 11 hours agorootparentprevIt is really easy to remember; it is so small that remembering is the least of the issue. The rest is just using it a lot; I find it readable and nice to work with. Unlike other some other languages we get shoved down your throats. reply aguaviva 14 hours agorootparentprevWhich is why banks love it. Because one has to be pretty smart to be able to wade through all that nutty, impossible to remember syntax. Therefore, k is a smart choice, and people who use k in business applications must be really smart. reply inopinatus 14 hours agorootparent\"Debugging is twice as hard as writing a program in the first place. So if you're as clever as you can be when you write it, how will you ever debug it?\" — Kernighan, Brian. The Elements of Programming Style (2e). McGraw-Hill, 1978. reply userbinator 13 hours agorootparentBy becoming even more clever: https://www.linusakesson.net/programming/kernighans-lever/in... reply nine_k 11 hours agorootparentIt's a nice interpretation. I prefer a different approach: \"smart is good; clever isn't smart\". If you have to express something in a clever, that is, highly contrived but actually working way, it means that you lack the right way to express it, and maybe your mental model of the problem is not that good. The theory of epicycles is clever; Kepler's laws are smart. reply darkwater 8 hours agorootparentprevThis can probably true for some people, but still will not work for many other. One probable outcome of a frustrated debugging session is \"let's rewrite/refactor it to make it easier to debug next time\", and not self-enlightenment. reply IshKebab 12 hours agorootparentprevVery unconvincing. If you become cleverer you can just write even more clever code and still not be able to debug it. reply chmod775 11 hours agorootparentGreat! reply chii 12 hours agorootparentprev> how will you ever debug it? By being so smart that your program has obviously zero bugs in it! reply nosianu 11 hours agorootparentThis view is too static. That is not possible, because the environment can (and at some point always will) change which wasn't planned for due to a lack of working crystal balls. Data, user behavior, the network, the system(s) the software runs on can all change over time. Also, it is way too expensive to try to cover every single conceivable possibility, so we deliberately leave holes. For non-trivial things we often prefer to wait to see what problems actually come up during use, and then fix exactly those, but not the many more problems that could come up but are too unlikely and/or too costly to guard against. In a living environment the software lives too, and keeps changing and adapting. reply boomlinde 10 hours agorootparent> That is not possible, because the environment can (and at some point always will) change which wasn't planned for due to a lack of working crystal balls. Data, user behavior, the network, the system(s) the software runs on can all change over time. It sounds to me like you are describing a change of problem, not bugs in the solution. If in the future someone redefines the concept of a Sudoku puzzle such that this solution is no longer applicable, or tries to use the solution verbatim in a language which is different from K and therefore yields different results, it's not a bug in the original code that it's not a solution to that new problem. It's still a solution to the same problem it was always a solution to. I can see what you mean in a practical sense, but also consider (practically) that a lot of problems can be broken down into smaller, well-defined problems which are themselves practically immutable. You can throw the solutions to such problems out when you no longer need them, and come up with solutions to whatever new problems replaced the original problems. reply chii 11 hours agorootparentprevyou might've missed the quip, since this whole thread is about a quote, which i'm countering with an alternative quote from Hoare > There are two methods in software design. One is to make the program so simple, there are obviously no errors. The other is to make it so complicated, there are no obvious errors. reply dotancohen 7 hours agorootparentprevI believe that you are addressing maintainability, not debugging. reply ryanjshaw 12 hours agorootparentprevThe average bank/company would rather have an average solution maintained by 10 easily replaceable average developers than a nutty, smart solution only understood by 1 highly talented developer. reply Moru 10 hours agorootparentYou could also say that the average bank/company should have learned from previous mistakes doing exactly that for many decades. Select a language that is well tested, understood and supported. Set a limit on cleverness and instead focus on maintainability and simplicity. reply speed_spread 7 hours agorootparentIf only. In my experience, banks end up building a solution that is maintained by 100 mediocre developers that a reasonably smart developer can't make sense of when it behaves erratically or has extremely poor performance. reply ryanjshaw 6 hours agorootparentI described the theory. You have described the practice :) reply aguaviva 3 hours agorootparentprevWhich was precisely my point (and I agree with all the responses in this thread), though my wording and light sarcasm seems to have been a bit too dry, and didn't quite take up as intended. reply queuebert 3 hours agorootparentprevKeeping skill barriers low keeps wages low as well. reply hilux 12 hours agoparentprevBut possibly not its maintainability. reply cduzz 16 hours agoprevI'll sometimes gauge code complexity by comparing the number of lines of code against the output of tar -cf - .gzipbase64wc -l IE \"how much does it compress?\" Looking at APL -- I'm reminded of what happens if I accidentally send the gzipped output to my tty... I'm impressed that there's anyone who can follow along (can you find the bug?) to code like p←{(↑⍵)∘{(⍺∨.=⍵)/⍳n×n∘}¨,⍵},(n*÷2){⍵,⍺⊥⌊⍵÷⍺}'⍳n n←⍴⍵ It really feels like compressed binary data where everyone's got a copy of the dictionary already... reply bryancoxwell 15 hours agoparentLegitimately curious how APL programmers think about maintainability and readability. Is code just thoroughly commented or otherwise documented? reply mlochbaum 5 hours agorootparentThe most uncompromisingly APL-ish code I've written is the BQN compiler[0]. Hard to write, hard to extend, hard to refactor. I generally recommend against writing this way in [1]. But... it's noticeably easy to debug. There's no control flow, I mean, with very few exceptions every line is just run once, in order. So when the output is wrong I skim the comments and/or work backwards through the code to find which variable was computed wrong, print stuff (possibly comparing to similar input without the bug) to see how it differs from expectations, and at that point can easily see how it got that way. The compiler's whole state is a bunch of integer vectors, and •Show [a,b,c] prints some equal-length vectors as rows of a table, so I usually use that. The relevant code is usually a few consecutive lines, and the code is composed of very basic operations like boolean logic, reordering arrays with selection, prefix sum, and so on, so they're not hard to read if you're used to them. There are a few tricks, which almost all are repeated patterns (e.g. PN, \"partitioned-none\" is common enough to be defined as a function). And fortunately, the line prefaced with \"Permutation to reverse each expression: more complicated than it looks\" has never needed to be debugged. Basically, when you commit to writing in an array style (you don't have to! It might be impossible!) you're taking an extreme stance in favor of visible and manipulable data. It's more work up front to design the layout of this data and figure out how to process it in the way you want, but easier to see what's happening as a result. People (who don't know APL, mostly) say \"write only\" but I haven't experienced it. [0] https://github.com/mlochbaum/BQN/blob/master/src/c.bqn [1] https://mlochbaum.github.io/BQN/implementation/codfns.html#i... reply upghost 2 hours agorootparentGod bless, my hat goes off to you sir. I have trouble wrapping my head around the concept of first class functions in ndarrays, let alone implementing it in hardcore APL. That has to be a feat on par with Hsu's Co-Dfns. Don't suppose you can point to any resources to help wrap your head around BQN, do you? reply mlochbaum 2 hours agorootparentWell this is pretty much the goal of the BQN website so my best attempts are there. I might point to the quick start page https://mlochbaum.github.io/BQN/doc/quick.html as a way to feel more comfortable with the syntax right away. And the community page https://mlochbaum.github.io/BQN/community/index.html collects links by others; Sylvia's blog in particular focuses on the sorts of flat array techniques that are useful for a compiler. reply upghost 2 hours agorootparentJust looked at the github -- wait, you wrote BQN? My God. Is there any prior art on this -- arraylangs with first class functions? I don't think very many people realize how incredible the semantic power of BQN is. The idea of an arraylang with first class functions... it truly staggers the imagination. I feel like if I were able to wrap my head around it I would never want to code in anything else. Thanks again and excited to take another look at it! reply mlochbaum 2 hours agorootparentK, for a start. Whitney's earlier dialect A+ too. See https://aplwiki.com/wiki/First-class_function . reply smabie 1 hour agorootparentprevDon't most array languages have first class functions? reply upghost 1 hour agorootparentThey have functions but not first class functions. Think (the ability to make) a vector/matrix of functions rather than just numbers :O What could you do with that? I don't know, but I bet some pretty cool stuff. reply dzaima 6 hours agorootparentprevOnce you've learned the syntax of the language, long expressions like that are about as readable as however-many-dozen lines of JS/Python with 1-to-3-character variable names; i.e. some parts may be obvious if they're a common pattern or simple enough, but the big picture may take a while to dig out. Probably the biggest readability concern of overly-golfed expressions really is just being dynamically typed, a problem shared with all dynamically-typed languages. But array languages have the problem worse, as nearly all operations are polymorphic over array vs number inputs, whereas in e.g. JS you can use 'a+b' as a hint that 'a' and 'b' are numbers, & similar. If you want readable/maintainable code, adding comments and splitting things into many smaller lines is just as acceptable as in other languages. reply upghost 2 hours agorootparentI am kind of curious if you have to mentally keep track of the rank/shape/dimensions in your head or if there is some implicit/explicit convention for conveying that to the reader. Does tracking rank/shape become second nature after awhile? I'm also wondering about things like (APL-style) inner products -- they are undeniably powerful, but it's hard for me to conceptual use cases above rank 3. reply lokedhs 1 hour agorootparentThat depends on the specific code. Some code is written to be agnostic to the rank, while others make certain assumptions. In my code I'd sometimes write assertions in the beginning of a function to not only ensure it's called with the right shape but also as documentation. Also, in practice really high rank arrays aren't used much. Even 4 is pretty rare. reply dzaima 1 hour agorootparentprevIf there's information on input format, it is simple enough to trace through the following shapes, but it does force reading the code rather linearly. Operations which implicitly restrict the allowed shapes are unfortunately intentionally rather few. I basically never use the generalized inner product; it's rather unique to the original APL - J has a variant that doesn't have the built-in reduction, and k and BQN and many if not most other array languages don't have any builtin for it at all. And in general I don't typically use rank higher than like one plus the natural dimensionality of the operation/data in question. reply t-3 12 hours agorootparentprevYou don't really have to worry about keeping track of tons of functions, variables, structs, classes, etc., and trying to keep all the names straight in your head - all you need is to know the symbols, so it's in some ways easier than reading a complex function in more verbose languages where you might need to lookup stuff from several libraries just to understand what's going on. Also, that one line is ~100 characters, each of which probably covers ~0.5-1 lines in other languages, so you should expect to set aside a similar amount of time to reading and understanding it. reply shawn_w 13 hours agorootparentprevI suspect that if you're fluent in the language, understanding an expression written in it comes just as easily and quickly as reading a sentence in a book does to me. reply campbel 2 hours agorootparentInformation density is studied in linguistics. It could likely apply to programming languages similarly. reply andylynch 9 hours agorootparentprevThat’s exactly what they say. Though most kdb I’ve see in business looks more like Python. reply rtpg 11 hours agorootparentprevmy impression is that the language is used more for scripts than for \"code\" in a true sense. A bit of \"how much can you juggle in your mind\" going on reply genewitch 13 hours agorootparentprevi've only seen these style of languages commented after a contest is over on stack programming challenges. I have no idea how one would learn all this stuff from code in the wild (like i learned most of python, for example). then again, i don't go searching github for k, apl, or perl for that matter. I'm sure each of those languages makes some guarantee about the sorts of errors that can be introduced - as opposed to C (let me pick on it) where the errors you know you can introduce, and the errors that are introduced aren't a large union. However i have a hard enough time typing english consistently, so the various \"symbol-y\" languages just glaze my eyes, unfortunately. It almost \"feels\" like these languages are an overreaction to the chestnut \"they must get paid by LoC\". reply rak1507 15 hours agoparentprevI'm not sure why it would be any more impressive or surprising than the billions of people who read and write in non English alphabets reply cduzz 15 hours agorootparentThat's a really good point... But -- (and forgive me if I'm totally wrong) -- this isn't just \"non-english\" but \"non-phonetic\" which is a smaller set of written languages, and the underlying language is ... math.... so understanding the underlying grammer itself relies on having decades of math education to really make it jive. If this code is just a final result of \"learn math for 2-3 decades, and spend years learning this specific programming language\" -- my statement stands. Interacting with this kinda binary blob as a programming language is impressive. I think I read somewhere that seymour cray's wife knew he was working too hard when he started balancing the checkbook in hex... reply rak1507 15 hours agorootparentThe underlying language isn't really very mathematical, at most there's a bit of linear algebra in the primitives but that's it. You certainly don't need any sort of formal maths education to learn APL. There are about 50 or so new symbols, which is not a big ask, with any sort of focus the majority of the syntax etc can be learned very quickly. The \"bugs\" in your original code stand out very clearly because things like \"∘}\" don't make sense, ∘ being \"dyadic\" (infix). reply RodgerTheGreat 14 hours agorootparentand it bears mention that a decent chunk of those symbols are things nearly everyone is familiar with from other languages (+, -, =, etc), symbols you've probably seen in math class or on your graphing calculators (÷, ×, ≠, ⌈, ←, etc), and symbols with very strong mnemonic associations once you've seen them explained (≢, ⍋, ⍳, ⌽, etc). reply geekraver 1 hour agoprevMuch better than some of the garbage solutions I have seen, including from sources that should know better, like The Algorithm Design Handbook. Some really absurd approaches out there, so bad I wrote a blog post about it in 2015: https://www.grahamwheeler.com/post/sudoku/ reply nine_k 11 hours agoprevLines of code is a poor metric, because languages use lines differently. A much better measure would be the number of nodes in a parse tree, of semantically meaningful non-terminals like \"a constant\" or \"a function call\". An even better measure would also involve the depth and the branching factor of that tree. reply xelxebar 9 hours agoparentJust... no. What are you even trying to compare? UX of a language matters. Clarity, thinking paradigm, expressability etc. all matter and are affected by the visual size of code. A one line solution takes up very little visual real estate. That matters a lot when you are working on some more complex problem. Flitting your eyeballs around a screen takes orders of magnitude less effort than scrolling around and navigating files. Cognitive load is important. We really need to burn this vague \"only semantics matter\" scourge that's creeped into our programmer values these days. I'm sorry, but I care about things like incentives against over-engineering, ease of directly thinking in the problem domain, and simplicity of the encompassing ecosystem. A terse one-line solution tells me there is virtually no room for over-engineering. Even without knowing K, I can see obvious constants side-by-side, telling me it's likely using a direct data representation of the problem in its code. Does K culture encourage code like that? Does programming in K bias you towards directness and simplicity? Then please, I want some of that special sauce on my team.reply dahart 3 hours agorootparentDon’t get confused between using smaller keywords and actually understanding the problem at hand. Terse languages do absolutely nothing to prevent over-engineering. They might even contribute by giving a false sense of simplicity and a tendency to prevent certain kinds of code reuse. To prevent over-engineering on large projects, you don’t need a terse language at all, you need the right mentality, the right management & product team, good team culture & cohesion, strong code review process, and job performance metrics that align with not over-producing code. It seems like parent’s metric (size of parse tree) would easily optimize for terseness and penalize bloat, regardless of language, so maybe your reaction was too reflexive. UX of a language does matter a bit, and one that’s too terse incurs development friction and technical debt when used in larger projects. Just study the history of Perl and why it’s not widely used. What a one liner looks like is more or less the worst possible metric to use for large software projects. In any language, the style of code changes the larger the codebase, and cleverness and terseness become a liability. https://www.teamten.com/lawrence/writings/norris-numbers.htm... reply lukan 8 hours agorootparentprev\"A one line solution takes up very little visual real estate. That matters a lot when you are working on some more complex problem.\" When I work on some more complex problem, I like to think about the problem, not spend energy decoding condensed text. Scrolling a bit more verbose, but clear code, is faster for me. reply cenamus 8 hours agorootparentI think the difference is not a bit of scrolling, but rather the whole program on half a page vs 10 files à 200 lines of mostly noise reply lukan 7 hours agorootparentThere is noise and there is self explaining code. One liners for complex problems are a nice challenge, but are seldom clear to read. reply Etherlord87 8 hours agorootparentprevWhy not create a programming language, that uses all possible unicode codepoints to further decrease the number of characters used? That would be so much more readable! reply agumonkey 3 hours agorootparentprevI mentally work like what parent described. I plug ast node in my mind when I read. I like operating with combinators, graphs/trees of them that I almost naturally understand the results of. Any language that add complexity at that layer loses me, and APL, even with crude visuals is not far from that. reply smokel 10 hours agoparentprevThe built-in functions and API to a system library spoil these metrics. As an example, consider HQ9+, which is pretty good at printing \"Hello, world!\" for instance. https://cliffle.com/esoterica/hq9plus/ reply tromp 11 hours agoparentprevThe preferred measure of information content is simply number of bits as used for instance in Algorithmic Information Theory [1]. [1] https://en.wikipedia.org/wiki/Algorithmic_information_theory reply jodrellblank 1 hour agorootparentBy that measure naming a variable “objUser” instead of “user” is better because it has more information, and naming the same variable “cgjkkytdvjkftujmhffetb” is even better because it contains more information. The parse tree approach is trying to get at a fuzzy notion of useful information and useful density of information. reply skrebbel 5 hours agoparentprevThis oneliner was obviously done for the giggles, and nobody pretends it's reasonably readable code. Getting anal about definitions here is entirely missing the point. (which is \"look, K lets you write extremely dense code!\") reply wk_end 5 hours agorootparentI don’t know if that’s the case, simply because all code that I see written by array language programmers looks like code golf. Even the language implementation itself! https://code.jsoftware.com/wiki/Essays/Incunabulum reply mlochbaum 4 hours agorootparentIs this because all the code you see is through HN or similar? No one's going to share something titled \"an unremarkable script I use to help run my business\" here. Not sure what your threshold for code golf is, but you can see APL written in a variety of styles by searching Github. It doesn't recognize K but does have Q, which is basically K plus keywords, obviously promoting more verbose code. Whitney originated the dense style of implementation shown at your link, and a few other implementers (including myself in the past) have picked it up, but it's not that common. For example April, GNU APL, Kap, Goal, and Uiua all use an idiomatic style for their implementation languages. APL: https://github.com/search?type=code&q=language%3AAPL Q: https://github.com/search?type=code&q=language%3Aq Implementation: https://aplwiki.com/wiki/List_of_open-source_array_languages reply jodrellblank 1 hour agorootparentprevhttps://news.ycombinator.com/item?id=39546175 reply gorgoiler 13 hours agoprevEvery K program ought to end in QED, and then I remember that KQED is also a thing, and I wonder if their two worlds have ever overlapped. (KQED is the Bay Area PBS partner. PBS is the US public television org.) reply shahbazac 16 hours agoprevI’ve often wondered about languages like APL/k, are the programmers actually able to think about problems more efficiently? reply Jorge1o1 16 hours agoparentAs a kdb+/Q programmer I would say it depends on the type of problem. For example, when working with arrays of data it certainly is easier to think and write “avg a+b” to add two arrays together and then take the average. In a non-array programming language you would probably first need to do some bounds checking, then a big for loop, a temporary variable to hold the sum and the count as you loop over the two arrays, etc. Probably the difference between like 6ish lines of code in some language like C versus the 6 characters above in Q. But every language has features that help you reason about certain types of problems better. Functional languages with algebraic data types and pattern matching (think OCaml or F#) are nicer than switch statements or big if-else-if statements. Languages with built-in syntactic sugar like async/await are better at dealing with concurrency, etc. reply lll-o-lll 16 hours agorootparentWhich is why C# is the giant ever increasing bag of tricks that it is (unkind people might say bloat…) ;-) Personally, I’m all for this; let me express the problem in whatever way is most natural. There are limits, of course, and it’s not without downsides. Still, if I have to code in something all day, I’d like that “something” be as expressive as possible. reply sudosysgen 15 hours agorootparentprevWell no, not in a non-array programming language. In any language that has a semi-decent type/object system and some kind of functional programming support, `avg a+b` would just be `avg(a, b)`, which is not any easier or harder, with an array type defined somewhere. Once you make your basic array operations (Which they have to be made in q anyways, just in the stdlib), you can compose them just like you would in q, and get the same results. All of the bounds checking and for-loops is unnecessary, all you really need are a few HKTs that do fancy maps and reduces, which the most popular languages already have. A very real example of this is Julia. Julia is not really an array-oriented programming language, it's a general language with a strong type system and decent functional programming facilities, with some syntactic sugar that makes it look like it's a bit array oriented. You could write any Q/k program in Julia with the same complexity and it would not be any more complex. For a decently complex program Julia will be faster, and in every case it will be easier to modify and read and not any harder to write. reply otteromkram 15 hours agorootparentWhy would it be avg(a, b)? What if I want to take the average difference of two arrays? reply IshKebab 12 hours agorootparentmean(a - b) reply rak1507 15 hours agorootparentprevI don't know what you mean by the q array operations being defined in the standard library. Yes there are things defined in .q, but they're normally thin wrappers over k which has array operations built in. reply sudosysgen 4 hours agorootparentI don't consider an interpreted language having operations \"built-in\" be significantly different from a compiled language having basic array operations in the stdlib or calling a compiled language. reply jksflkjl3jk3 13 hours agoparentprevFor some classes of problems that are easily vectorized, using an array-focused language can certainly make thinking about them and their solutions more efficient, since you can abstract over the data structure and iteration details. As a quant, I used kdb+/q quite a bit for 5+ years for mid-frequency strategies, but as I moved towards higher frequency trading that required calculations on the order book that couldn't be easily or efficiently vectorized, then continuing to use array-focused languages would have only complicated reasoning about those problems. reply upghost 2 hours agorootparentWhat did you switch to after that? reply omoikane 13 hours agoparentprevI went to this tech talk on Dyalog (a modern APL-like language), and the speaker makes the argument that the notation allows certain idioms to be recognized more easily: https://youtu.be/PlM9BXfu7UY?si=ORtwI1qmfmzhJGZX&t=3598 This particular snippet was in the context of compilers, but the rest of the talk has more on Dyalog and APL as a system of mathematical notation. The underlying theme is that optimizing mathematical expressions may be easier than optimizing general code. reply lokedhs 6 hours agoparentprev\"More efficiently\"? Maybe. It opens up a new way to think about solutions to problems. Sometimes those solutions are more efficient, and sometimes they are just different. It's a useful thing to learn though. And dare I say it, fun. Even if there was zero benefit to it, it'd still be fun. As it turns out, there really are benefits. For me, the biggest benefit is when I'm working with data interactively. The syntax allows me to do a lot of complex operations on sets of data with only a few characters, which makes you feel like you have a superpower (especially when comparing to someone using Excel to try to do the same thing). reply michaelg7x 5 hours agoparentprevI've found that the challenge is to \"think in vector operations\" rather than of iterating over the same data. The tricky part is figuring out how to get an operator to do the right thing over an array of stuff on the left hand side and this list/bag/etc of arguments on the right reply 082349872349872 13 hours agoparentprevone nice thing about the array language style is that it's possible to talk about variations on algorithms where the relevant code snippets, being a few characters, fits inline into the discussion; more traditional vertically-oriented languages that take handfuls or dozens of lines to say the same things need to intersperse code display blocks with expository prose reply giraffe_lady 16 hours agoparentprevHillel Wayne writes about it on his newsletter every once in a while. He's convinced me that he does in fact think through some problems better in array languages but I still can't really conceive of what that experience is like. reply RodgerTheGreat 14 hours agorootparentthere are several open-source K environments available, some which even run in the browser: http://johnearnest.github.io/ok/index.html if it's something you're interested in trying i'd be happy to point you toward more resources, and i'm sure there are plenty of other arraylang tinkerers reading this thread who could help, too reply upghost 3 hours agoprevWell if we are showing off sudoku solvers, it would be a sin not to share this one: sudoku(Rows) :- length(Rows, 9), maplist(same_length(Rows), Rows), append(Rows, Vs), Vs ins 1..9, maplist(all_distinct, Rows), transpose(Rows, Columns), maplist(all_distinct, Columns), Rows = [As,Bs,Cs,Ds,Es,Fs,Gs,Hs,Is], blocks(As, Bs, Cs), blocks(Ds, Es, Fs), blocks(Gs, Hs, Is). blocks([], [], []). blocks([N1,N2,N3|Ns1], [N4,N5,N6|Ns2], [N7,N8,N9|Ns3]) :- all_distinct([N1,N2,N3,N4,N5,N6,N7,N8,N9]), blocks(Ns1, Ns2, Ns3). While not one line, to me it is pareto optimal for readable, elegant, and incredibly powerful thanks to the first class constraint solvers that ship with Scryer Prolog. If you want to learn more about it or see more of Markus's work: https://www.metalevel.at/sudoku/ https://youtu.be/5KUdEZTu06o More about Scryer Prolog (a modern , performant, ISO-compliant prolog written mostly in rust) https://www.scryer.pl/ https://github.com/mthom/scryer-prolog reply upghost 13 hours agoprevMost people are put off by the symbols, that wasn't really the issue I had. So I do love APL and arraylangs, and learning them was really helpful in a lot of other languages. But they never became a daily driver for me not because of the symbols, which were honestly fine if you stick with it long enough, but after about 3-4 years of dabbling on and off I hit a wall with APL I just couldn't get past. Most other languages I know there is a \"generic-ish\" approach to solving most problems, even if you have to cludge your way through suboptimally until you find \"the trick\" for that particular problem and then you can write something really elegant and efficient. APL it felt like there was no cludge option -- you either knew the trick or you didn't. There was no \"graceful degredation\" strategy I could identify. Now, is this actually the case? I can't tell if this is a case of \"yeah, thats how it is, but if you learn enough tricks you develop an emergent problem solving intuition\", or if its like, \"no its tricks all the way down\", or if its more like, \"wait you didn't read the thing on THE strategy??\". Orrr maybe I just don't have the neurons for it, not sure. Not ruling it out. reply lokedhs 6 hours agoparentYou're not wrong. It's very easy to get that impression when trying to learn the array languages. It's very easy for someone who's used these languages for a long time to look at a problem, and say \"why did you use that really elaborate solution, when you can just use ⍸⍣¯1?\". No one probably ever told you that ⍸ has an inverse, and how you could use it. Even today, after having worked in these languages for years, I am still put off a bit by the walls of code that some array programmers produce. I fully understand the reasoning why it's written like that, but I just prefer a few spaces in my code. I've been working on an array language based on APL, and one of my original goals was to make \"imperative style\" programming more of a first-class citizen and not punish the beginner from using things like if-statements. It remains to be seen how well I succeeded, but even I tend to use a more expressive style when terseness doesn't matter. Here's an example of code I've written which is the part of the implementation that is responsible for taking any value (such as nested arrays) and format them nicely as text using box drawing characters. I want to say that this style is a middle ground between the hardcore pure APL style found in some projects and the style you'll see in most imperative languages: https://codeberg.org/loke/array/src/branch/master/array/stan... reply upghost 6 hours agorootparentVery nice! I like the readability-- not sure if thats just indicative of your style or the language, and the map construct is also nice. I don't remember any off-the-shelf map construct, at least not in Dyalog. reply lokedhs 5 hours agorootparentIt's likely a combination of both. It's certainly possible to write Kap in a much more condensed form. But things like if-statements and hash maps does allow for a more imperative style. reply eigenvalue 3 hours agoprevIt's cool in a novelty way that it’s so short, but I would infinitely prefer something like this for actual work and understanding: def solve(grid): def find_empty(grid): for r in range(9): for c in range(9): if grid[r][c] == 0: return r, c return None def is_valid(grid, num, pos): r, c = pos if num in grid[r]: return False if num in [grid[i][c] for i in range(9)]: return False box_r, box_c = r // 3 * 3, c // 3 * 3 for i in range(box_r, box_r + 3): for j in range(box_c, box_c + 3): if grid[i][j] == num: return False return True def backtrack(grid): empty = find_empty(grid) if not empty: return True r, c = empty for num in range(1, 10): if is_valid(grid, num, (r, c)): grid[r][c] = num if backtrack(grid): return True grid[r][c] = 0 return False backtrack(grid) return grid reply upghost 2 hours agoparentWhy is this getting down-voted without comment? Comparative analysis is taboo, now? I don't think Arthur Whitney would feel the least bit threatened by some Python code. reply BoiledCabbage 2 hours agorootparentSpeculation, but maybe because there is nothing of interest or to note in the comment. It's not clear why the poster prefers that other implementation, or that they understand APL or array programming. So as a result the comment reads as \"it's in a language I don't know. I'd prefer it in a language I do know.\" Which is a fairly useless comment. If that's not what they intended, it would be helpful for them to add some context to their comment. reply eigenvalue 2 hours agorootparentprevThe K-mafia is in control. Just kidding, I don’t really care either way… reply sorokod 11 hours agoprevThe LoC count and similar metrics have the advantage of an easy calculation. Ultimately though,they are a proxy to a more relevant but difficult to determine attributes such as Given a reasonably proficient engineer, the amount of time it would take them to resolve a bug in code written by someone else or alternatively extend its functionality in some way. reply Isamu 17 hours agoprevNot knowing K, am I correct in assuming this is a backtracking brute force solver? reply o11c 16 hours agoparentFrom the linked page (and the one linked beyond that), it's a breadth-first search actually. Keep a list of possible puzzle states at all times, pick a blank cell (theoretically arbitrary, but in practice intelligently for performance), add copies of the state with each possibility for that state added. reply dzaima 51 minutes agorootparentThe k code at least isn't doing any heuristics for the iteration order, and is just doing a fold over the indices of zeroes in index-ascending order. reply BobbyTables2 15 hours agorootparentprevThat sounds like 100+ lines in python or similar languages… reply throwup238 13 hours agorootparentYou should be able to do it in under 20 lines using the same matrix operations as the K code via numpy. reply anonzzzies 11 hours agorootparentNumpy is indeed very apl. Just more horrible to me; not python-y and annoyingly verbose for the apl-er. reply hrzn 9 hours agorootparentprevA few years back I made a modest attempt at writing a concise yet readable sudoku solver in Python - in about 29 lines: https://github.com/hrzn/sudoku/blob/master/sudoku.py Could have been made shorter at the price of readability. reply forgotpwd16 6 hours agorootparentLooks nice. Since imports numpy can utilize (more of) numpy's operations to squeeze validation functions and nested fors to one. Should result in shorter code but readability will probably depend on reader's experience in array programming. reply otteromkram 15 hours agorootparentprevIt probably isn't. At least, not for Python. reply bazoom42 9 hours agoprevThe discussions around “line noise”-languages are always intersting. Most programmers would agree the ‘/’ symbol is at least as clear as writing ‘divideBy’. The question is how often the symbols are used and if their frequency in code justifies learning them. reply lofaszvanitt 14 hours agoprevIt has strong perl vibes and it brings back ptsd :D. Maybe this overshortification of things is a personnel or intelligence indicator of some sorts. reply dang 14 hours agoprevI put 2011 in the title above because https://web.archive.org/web/20110813135700/https://dfns.dyal... appears to have the main thing - is there a better year? reply Intralexical 5 hours agoprevIt may be interesting to compare this one line to \"Code Golfed\" equivalents in different programming languages: https://codegolf.stackexchange.com/questions/tagged/sudoku?t... reply TZubiri 7 hours agoprevI thought it was written by Ursula K. Le guin. Not sure where I got that from. reply brador 8 hours agoprevSomeone should collate exceptional human coding achievements to test future AI. AFAICT AI cannot replicate this, yet, will be interesting when that day comes. reply 29athrowaway 17 hours agoprevThere is a video about this. https://www.youtube.com/watch?v=DmT80OseAGs You can try the solution at https://tryapl.org/ reply make3 15 hours agoprev\"one line in your custom language\" is not one line at all lol reply Spivak 15 hours agoparentTo be fair K is a real language that's used by more than just him. Why array languages seem to gravitate to symbol soup that makes regex blush I'll never know. reply IshKebab 12 hours agorootparentYeah I think MATLAB and Mathematica are waaay more used than K et al. They just don't look insane so people aren't posting them on HN as much. reply fodkodrasz 13 hours agorootparentprevnext [3 more] [flagged] exitheone 11 hours agorootparentArray language have been around far longer than any \"HN crowd\". reply fodkodrasz 3 hours agorootparentWhich is totally orthogonal to the original statement, and my reflection to it, which was on one hand statig that seemingly array languages tend to be letter soupy, for which I replied that a selection bias is at play, as array languges are used widely, most notably Matlab is used widely which is not a letter soup. It is simply not regurgulated on the site as it does not seem so hardcore. Nevertheless you are right, array langueges have been around earlier, for example Matlab itself dates back to the 1970s. I do not understand the awe some are giving them in the comments, they are an easy to understand paradigm, which is very well suited for certain types of problems. Some having overly terse syntax is a thing, but I do not feel that only geniuses can comprehend array programming, anyone who did learn some university level physics or signal processing has the tools in their belt. reply lucw 13 hours agoprevDoes anyone have any thoughts on what motivates people to play sudoku or write solvers for sudoku ? I have trouble finding motivation to solve artificial problems. That said I sink hundreds of hours into factorio. reply bramhaag 13 hours agoparentFor me personally, I have little motivation to do classical sudokus. They either have a not-so-elegant solve path (usually set by a computer) or are too difficult for me to solve. Variant sudokus on the other hand are a lot of fun. They often have very elegant solve paths and there are many neat tricks you can discover and reason about. Some fun ones, if you'd like to try: - https://logic-masters.de/Raetselportal/Raetsel/zeigen.php?id... - https://logic-masters.de/Raetselportal/Raetsel/zeigen.php?id... - https://logic-masters.de/Raetselportal/Raetsel/zeigen.php?id... reply sltkr 8 hours agorootparentTo each their own, but the puzzles you linked seem really convoluted compared to regular Sudoku. The last puzzle has no fewer than 9 custom rules, in addition to the regular Sudoku rules, and then it also says “every clue is wrogn [sic]” implying there is some meta out-of-the-box thinking required to even understand what the rules are. That is more a riddle than a logic puzzle. By contrast, the charm of classical Sudoku is that the rules are extremely simple and straightforward (fill the grid using digits 1 through 9, so that each digit occurs exactly once in each row, column, and 3x3 box) and any difficulty solving comes from the configuration of the grid. reply akleemans 13 hours agorootparentprevI also mostly enjoy Sudoku variants, most of which I discovered via Geocaches, interestingly. After solving a few I then implemented a solver with customizable constraints, if anyone's interested, should still be available here: https://www.sudoku-solver.ch/ reply thom 12 hours agoparentprevLike many puzzles, there’s a regular release of endorphins as you progress, and a lot of satisfaction in completing something. I enjoy puzzles just like reading a book or playing a game, it’s another world I can step into for a bit of an escape, but I like to think it’s decent mental exercise. Overall I vastly prefer cryptic crosswords where solving each clue genuinely brings a smile to my face, but that’s more of a commitment of time (and for me sometimes a guarantee of frustration). I also like doing puzzles in the newspaper because me and my kids can sit together and all contribute. Coffee, breakfast, sat in the sun with a newspaper and a good pencil[1], absolute bliss if you ask me. As for solvers, it’s a very elegant, well-formed problem with a lot of different potential solutions, many of which involve useful general techniques. I used to dabble clumsily in chess engines and honestly it’s the only time I’ve ever ended up reading Knuth directly for various bit twiddling hacks, so it’s always educational. 1: https://musgravepencil.com/products/600-news-wood-cased-roun... reply riffraff 13 hours agoparentprevI don't particularly enjoy sudoku but I like word puzzle games. They're all artificial problems, but your brain likes a challenge and you get a dopamine hit when you solve it, I suppose. reply teo_zero 11 hours agoparentprevAll games are artificial problems, so your question actually is, what motivates people to engage in pastimes? Sudoku, crosswords, Simon Tatham's puzzles etc. are an excellent way to pass the time while keep training the mind. Sports are their equivalent for the body. Finally, writing solvers for a problem, be it real or artificial, for many is just another variety of puzzle to engage in. reply proteal 11 hours agoparentprevidk man, you ask a good question. I think the idea has to do with the saddle you put on the invisible horse that is the game’s problem. Factorio has several complex saddles you must master to tame the beast. In factorio, you can get progressively better at using these saddles to tame even the most unwieldy scenario. Sudoku, at its heart, is not much different than factorio. However sudoku has one narrow problem with many different, increasingly nuanced ways of solving it. Factorio has many different “sudoku” style problems, but each problem needs to be handled differently, with each problem having increasing levels of sophistication. I think you might like factorio more because it’s just a bigger steak to chew on, and you’ve got the right appetite. reply dclowd9901 11 hours agoparentprevI don’t care much for sudoku but I do enjoy crosswords quite a lot, which feels like a somewhat arbitrary exercise. I enjoy the fact that I know a lot of words and it makes me feel clever. There’s probably something to that with most puzzle type challenges. reply ryanjshaw 12 hours agoparentprevI wasted too much time in my youth trying to min-max, and now I get bored as soon as I figure out, roughly, what the rules and mechanics look like for any game. reply lgeorget 10 hours agoparentprevI teach C++ and I made my students code a Sudoku solver last year. It's a very convenient project to give them: self-contained, already familiar, no OS-specific weirdness, you get to use STL data structures, algorithms, very gentle I/Os... reply jessekv 12 hours agoparentprevNormally I would concur, but I recently fell into a klondike solitaire binge and the only way out was to write a solver. reply grujicd 11 hours agoparentprevI play sudoku almost exclusively on the plane. It's a good way to lose 5-15min. reply asah 15 hours agoprevWhat baud is that? /s reply speed_spread 7 hours agoparentMy cat puked in the modem receiver cup, sorry. reply genewitch 14 hours agoparentprevmismatched, whatever it is, that's for sure. It's not quite line noise, so maybe it's just the wrong stop bit? reply yumraj 13 hours agoprevnext [11 more] [flagged] Etheryte 11 hours agoparentPlease don't litter HN with LLM spam, it adds nothing of value to the discussion. You even said it yourself, you have no idea if any of the word vomit is true or not. reply shawabawa3 11 hours agorootparentIt's your comment that's adding nothing It's very interesting that Claude can at least figure out it's a sudoku solver in K where chatgpt fails reply yumraj 13 hours agoparentprevGemini also identifies it as J and this is the output for comparison: The programming language used in the code is *J* (pronounced \"Jay\"). It's a concise, array-oriented programming language known for its expressive syntax and powerful capabilities. Here's a breakdown of the code: *1. Verb Definition:* * `x(,/{@[x;y;]'(!10)^x|/p[;y]=p,:,3/:-3!p:!9 9}')/&~x` defines a verb (a function in J terminology) and assigns it to the variable `x`. *2. Verb Structure:* * `x( ... )/&~x` is the basic structure of the verb. `x( ... )` applies the verb defined within the parentheses to its argument, which will be `x` itself. * `/&~x` is a hook, a control flow construct in J. It applies the verb defined within the parentheses to each element of `x` and then applies the verb `&~x` to the resulting array. *3. Verb Body:* * `,/{@[x;y;]'(!10)^x|/p[;y]=p,:,3/:-3!p:!9 9}` is the body of the verb. Let's break it down further: * `{@[x;y;]` creates a gerund (a verb-like noun) that takes two arguments, `x` and `y`. * `'(!10)^x` generates an array of `x` elements, each raised to the power of `!10` (factorial of 10). `/p[;y]=p` is a conjunction that appends the value of `p` to itself for each element in `y`. * `,:,3/:-3!p:!9 9}` generates an array of 3 elements, each of which is the factorial of `-3` (which is undefined and results in an error) followed by the number 9. *4. Overall Functionality:* * The verb takes an array `x` as input. * It applies the gerund to each element of `x`, creating an array of arrays. * It then applies the conjunction to each of these arrays, appending the value of `p` (which is likely defined elsewhere in the code) to itself. * Finally, it generates an array of 3 elements with errors and 9s. * The hook `/&~x` applies the verb to each element of `x` and then applies a function that is likely defined elsewhere in the code (since `&~x` is not defined within this verb). *Note:* Without more context about the definitions of `p` and other variables or functions used in the code, it's difficult to provide a more precise explanation of the verb's exact behavior. However, the breakdown above should give you a general understanding of the code's structure and logic. reply alach11 9 hours agorootparentFor completeness, I tested o1-preview and o1-mini. Both were able to identify the language, but only o1-preview realized it was a sudoku solver. reply rak1507 13 hours agorootparentprevPlease kindly delete your account, destroy your devices, and move to the woods far away from technology. reply yumraj 13 hours agorootparentSure. but please elaborate .. reply rak1507 13 hours agorootparentI cannot comprehend the mindset of people who decide to spam (because that is what your comment is) any forum with a page of bullshit GPT slop. Do you think it's helpful or interesting? reply yumraj 12 hours agorootparentPersonally I believe it is interesting since it shows the current state of the art for the 3 LLMs. I was surprised that Claude was able to identify the language and explain the code. But, please feel free to downvote my comments. I guess the aggregate in the end will demonstrate whether it was a useful comment or spam + bullshit GPT slop. reply rak1507 12 hours agorootparentIt wasn't able to explain the code, it was wrong. reply yumraj 12 hours agorootparentPerhaps you’ll be kind enough to post the explanation as a top level comment. It’ll certainly help those of us who do not know K. reply wileydragonfly 17 hours agoprev [17 more] Sudoku was always a meditative thing for me. It’s impossible not to win so long as you pay attention. Optimizing solutions seems contrary to the point to me. reply swatcoder 17 hours agoparentSolvers are useful for confirming that a puzzle you've recieved or generated is solvable. The meditative process can really go sideways when there is no solution for you to stumble upon. Puzzles in commercial collections don't usually have that problem, but those from other sources sometimes do. Solvers also make for a nice craft exercise, as here. Simple but not trivial, you can approach them in a lot of different ways and thereby work through different techniques or constraints you mean to explore. reply sellyme 8 hours agorootparent> Puzzles in commercial collections don't usually have that problem, I would argue that puzzles in commercial collections are more likely to have that problem than ones made freely available by hobbyists, as commercial enterprises inevitably cut corners on things like labour costs for an actual human setter. I have seen dozens of commercial puzzle games and applications that do not make any attempt to verify the (auto-generated) puzzles as solvable, but I don't think I've ever had the same problem on a site like LMD. reply UncleOxidant 17 hours agoparentprevI guess I'm the opposite. After doing a couple of sudoku many years ago my thought was \"Hey, I could just automate this\" and started thinking of algorithms. reply kranner 14 hours agoparentprevOptimising a Sudoku solver can be seen as a different puzzle entirely and not as a mode of playing Sudoku. reply teo_zero 11 hours agoparentprevInteresting position that was not expressed before. However please note that the same could be said about writing a solver. reply malux85 17 hours agoparentprevOptimising solutions is the meditative exercise for me. I enjoy running simulation after simulation after simulation, studying possible outcomes and optimising everything. Everyone is different :) reply gerdesj 17 hours agoparentprevMeta: No need to DV a comment you don't like for no reason. Engage instead. Why not have a chat? reply ben0x539 16 hours agorootparentWouldn't it be more productive/rewarding to instead engage with comments I do like? reply otteromkram 14 hours agorootparentOnly you can say what's best for you. If have to ask: What's rewarding about only having your viewpoint reinforced? reply johnisgood 7 hours agorootparentJust under this submission I have upvoted a handful of comments with which I disagreed, mainly because of its replies. reply ben0x539 14 hours agorootparentprevWhere are you getting the viewpoints thing from? reply swatcoder 16 hours agorootparentprevDownvotes and upvotes work together to manage the visibility of posts that align with the community's tastes. While I myself found an opportunity to reply to the GP and didn't down vote them, their comment only engaged with the article in a shallow way and only then, seemingly, to just dismiss the concept of solver altogether. It wasn't a offensive comment, but it didn't really contribute to the site in the way many people digging into deep technical walkthroughs like this expect to see. Some downvotes weren't guaranteed, but they're not surprising and they're probably helping new readers stay engaged with more topical and technical alternatives. It's not the end of the world to get a few downvotes, and it's almost never personal. It certainly isn't here. reply jksmith 15 hours agorootparentAside: Downvotes on HN can be an expression of age related, self-righteous sniper pique; Opinions on what contributes to a conversation can be all over the place and are entirely subject to biases, which can be interesting (I guess). Doesn't really matter, and Hail Satan anyway. Also \"Q for Mortals\" is an interesting book. reply riiii 16 hours agorootparentprevPeople are saturated with anger and frustration after doom scrolling. They engage with their pitchforks. reply mcphage 14 hours agorootparentA few anonymous downvotes are what qualifies as pitchforks these days? reply K0balt 16 hours agoparentprev [–] I find that sodoku is not a math or even a logic puzzle, but rather an epistemology puzzle. Lots of how we know/how much we know, and if you get into speed with some failure tolerance through estimating probability it adds even more thought provoking rabbit holes. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text explains solving Sudoku puzzles using APL and other programming languages, focusing on algorithms and code snippets contributed by various authors.",
      "It details the structure of a standard Sudoku puzzle and addresses the challenge of filling in missing numbers without repeats in rows, columns, and boxes.",
      "The text also covers handling non-standard Sudoku shapes and provides examples, solutions, and links to additional resources and demonstrations."
    ],
    "commentSummary": [
      "Arthur Whitney's one-liner Sudoku solver in the K programming language showcases the language's expressive syntax and efficient array handling.",
      "K, influenced by APL and Scheme, is praised for its compactness, though some find it difficult to read and maintain compared to more verbose languages.",
      "The discussion also explores the broader appeal and unique problem-solving approach of array languages, with differing views on their practicality and readability."
    ],
    "points": 256,
    "commentCount": 163,
    "retryCount": 0,
    "time": 1728172804
  },
  {
    "id": 41755183,
    "title": "HPy – A better C API for Python",
    "originLink": "https://hpyproject.org/",
    "originBody": "HPy - A better C API for Python What is HPy?¶ HPy provides a new API for extending Python in C. In other words, you use #includeinstead of #include . What are the advantages of HPy?¶ Zero overhead on CPython: extensions written in HPy run at the same speed as \"normal\" extensions. Much faster on alternative implementations such as PyPy, GraalPy. Universal binaries: extensions built for the HPy Universal ABI can be loaded unmodified on CPython, PyPy, GraalPython, etc. A migration path for mixing legacy C-API calls with HPy API calls. Once all the code is migrated, the extension can be compiled as a universal binary that works on any CPython version, PyPy, or GraalPy. Debug mode: in debug mode, you can easily identify common problems such as memory leaks, invalid lifetime of objects, invalid usage of APIs. Have you ever forgot a Py_INCREF or Py_DECREF? The HPy debug mode can be activated at runtime to detect these mistakes for you on universal binaries. Nicer API: the standard Python/C API shows its age. HPy is designed to overcome some of its limitations, be more consistent, produce better quality extensions and to make it harder to introduce bugs. Evolvability: As nicely summarized in PEP 620 the standard Python/C API exposes a lot of internal implementation details which makes it hard to evolve the C API. HPy doesn't have this problem because all internal implementation details are hidden. Current status¶ HPy is under active development. 0.9.0 is the latest alpha release but we will soon leave the _alpha_ state and are working hard towards a stable release. We feel that the HPy ABI is stable enough now that we can fulfill our backwards and forwards binary compatibility promises with the upcoming release, and that the API now covers enough use cases to migrate important packages (in particular, checkout our numpy port). We also provide porting guides and extensive documentation (in particular the API reference). We are, of course, always open for design discussions and new reqiurements. The Python/C API is huge. At the moment many popular functions are available. Is something missing for the port of your favorite extension? Please open an issue or even better a PR. HPy-compatible extensions¶ The extensions that we are experimenting with include: ultrajson-hpy: this was the first real-world module to be ported to HPy. It is a nice fit because it only exports functions (as opposed as custom types) and requires only a small number of API functions. piconumpy: as the name suggests, this is a minimal numpy-like module which defines a custom type (similar to ndarray but with many fewer features of course). numpy: one of our ambitious goals is to port numpy to HPy, and to use this experience to better understand how to design the API. This port is close to passing the test suite. matplotlib: Since Matplotlib also has a dependency to NumPy, the migration to universal mode is not fully finished. HPy provides the legacy compatibility API such that we can still call legacy C API functions from HPy and successfully run the test suite. kiwi-solver: A dependency of Matplotlib, it has been fully ported to universal mode. Benchmarks and more information about the Matplotlib and kiwi-solver ports can be found in the GraalVM blog post. The benchmarks show that the HPy ports have little impact on CPython performance, while enabling close-to-cpython performance with GraalVM Python for the kiwi-solver complete HPy port. Where we need help¶ Documentation: Our resources are very limited and we therefore concentrate on technical tasks. We already wrote a significant amount of documentation (see Documentation) but it is not complete yet. If this non-coding work is something you can do, let us know. Publicity: HPy is already well received among core developers of some important projects. For instance, we are actively talking to Python, NumPy, and Cython core developers. However, we need to get more package developers to be interested in and even use HPy. We appreciate any help for advertising HPy and we are also happy to help preparing talks, demos, etc. Tooling: This is also a topic we would need help. We are, for example, thinking of migration helper tools that do all the boilerplate work that can be automated when migrating a package from C API to HPy API. Packaging: There are several open questions we need to discuss and answer. How to package a universal extension and how to put it on PyPI? How best to package HPy itself How does HPy integrate with setuptools, mesonpy, or other build systems Upstreaming completed forks of the packages listed below, or upstreaming parts of the forks so the code does not suffer from bit-rot Website and logo design: You don't like this website and the HPy logo? Well, we have expertise in virtual machines, compilers, low-level programming, etc, but zero expertise in web development or graphic design. PRs are welcome ;) More info¶ Documentation HPy blog Github repository HPy Discord server #hpy IRC channel (obsolete but still there) Mailing list HPy is pronounced /h/ - pie (or using IPA notation: /eɪtʃ-paɪ/) Recent blog posts¶ 2023-10-12 19:00 hpy 0.9.0: Fourth public release 2023-10-10 10:00 HPy meetup and CPython core dev sprint in Brno (Oct 7-10, 2023) 2022-09-26 10:00 HPy Sprint Status Update and Feedback Session 2022-09-08 15:30 HPy on GraalPy and Matplotlib/HPy 2022-07-29 10:00 Dusseldorf PyPy/HPy/other sprint Sept 19-23, 2022",
    "commentLink": "https://news.ycombinator.com/item?id=41755183",
    "commentBody": "HPy – A better C API for Python (hpyproject.org)211 points by gjvc 12 hours agohidepastfavorite73 comments fforflo 1 hour agoSomething I don't see being mentioned in the comments: What's a really frustrating part of working with the C API? Setting up the compile/link flags! The python3-config works generally well but is only available at the OS level. But you don't want to mess with that (e.g., to access pip-installed packages). Beyond that, everything is a mess! python3 -m venv doesn't even bother creating such a script. anaconda/miniconda? Don't even try!. So every package pollutes their build scripts with many hardcoded `python3 -c \"import sys: print...\"` calls. I've opened a CPython/PR that may help a bit by adding `python3 -m sysconfig --json` flag [0] [0] https://github.com/python/cpython/pull/123318 reply pkkm 3 hours agoprevVery happy to see that these issues are getting attention now. I think that the Python language being so centered on one implementation is a long-term threat to its success. Web servers, command-line programs, and embedded devices have different requirements: high post-warmup throughput, fast startup, low memory usage. They aren't necessarily best served by the same implementation. If this project succeeds in replacing Python's C API with something that doesn't expose implementation details, such as whether the implementation uses reference counting, that could make it easier both to maintain alternative implementations, and to experiment with new techniques in CPython. reply koe123 11 hours agoprevIs my understanding correct that this would provide version agnostic python bindings? Currently, I am building a version of my bindings separately for each version (e.g. building and linking with python 3.7, 3.8, etc.). While automated, it still makes CI/CD take quite a long time. reply filmor 7 hours agoparentAs others have said, this has been supported since the limited/stable APIs were introduced. What this adds is a way of implementing a Python extension that can be loaded in (not just compiled for, which is already an improvement!) different Python implementations, namely CPython, Pypy and GraalVM. reply kzrdude 10 hours agoparentprevCpython also has a limited stable abi and cp3X-abi3 wheels are compatible across multiple versions of Python. https://docs.python.org/3/c-api/stable.html reply mardifoufs 4 hours agorootparentBut it is very limited. Understandably so, as they don't want to ossify the internal APIs, but it still is so limited that you can't actually build anything just using just that API as far as I know. reply masklinn 9 hours agoparentprevYou can already build a single wheel as long as you only target cpython, if your needs fit with the limited / stable abi (abi3). While pypy and graal have API support they don't have abi / abi3 support, so they still have to be built on their own (and per version I think). reply aragilar 10 hours agoparentprevI believe so, but it would presumably depend on what features you use. reply gjvc 10 hours agoparentprevWhile automated, it still makes CI/CD take quite a long time See about using ccache -- https://ccache.dev/ reply IshKebab 10 hours agorootparentI wouldn't recommend ccache (or sccache) in CI unless you really need it. They are not 100% reliable, and any time you save from caching will be more than lost debugging the weird failures you get when they go wrong. reply gjvc 9 hours agorootparentplease provide evidence for this assertion. reply imtringued 7 hours agorootparentYou can't cache based on the file contents alone. You will also need to cache based on all OS/compiler queries/variables/settings that the preprocessor depends on, since the header files might generate completely different content based on what ifdef gets triggered. reply mananaysiempre 6 hours agorootparentAnd that’s not impossible, just tedious. One tricky (and often unimportant) part is negative dependencies—when the build depends on the fact that a header or library cannot be found in a particular directory on a search path (which happens all the time, if you think about it). As far as I know, no compilers will cooperate with you on this, so build systems that try to get this right have to trace the compiler’s system calls to be sure (Tup does something like this) or completely control and hash absolutely everything that the compiler could possibly see (Nix and IIUC Bazel). reply zorgmonkey 3 hours agorootparentIn C++ the __has_include preprocessor expression has been standardized since C++17, I'm not certain if C has standardized it yet though. reply mananaysiempre 3 hours agorootparentIt’s not about that, that’s not relevant to ccache at all. (And yes, C23 does have __has_include, though not a lot of compilers have C23 yet.) It’s about having potentially conflicting headers in the source file’s directory, in your -I directories, and in your /usr/include directories. Suppose a previous compile correctly resolvedto /usr/include/libfoo.h, and that file remains unchanged, but since that time you’ve installed a private build of libfoo such that a new compile would instead resolve that to ~/.local/include/libfoo.h. What you want is to record not just that your compile opened /usr/include/libfoo.h (“positive dependencies” you get with -MD et al.), but that it tried $GITHOME/include/libfoo.h, ~/.local/include/libfoo.h, etc. before that and failed (“negative dependencies”), so that if any of those appear later you can force a recompile. reply zorgmonkey 1 hour agorootparentOh yeah that can cause lots of weird problems. I've run into that sort of issue a lot when cross-compiling, cause often then you might have a system copy of a library and a different version for the target, that can be a real pain. reply amelius 6 hours agorootparentprevMaybe run every build version in their own container? reply gjvc 4 hours agorootparentprevplease read the documentation before dispensing uninformed advice like this -- it works using the output of the preprocessor and optionally, file paths reply IshKebab 8 hours agorootparentprevWhy are you so skeptical? Think about how it works and then you'll understand that cache invalidation bugs are completely inevitable. Hell, cache invalidation is notoriously difficult to get right even when you aren't building it on top of a complex tool that was never designed for aggressive caching. Just search the bugs for \"hash\": https://github.com/ccache/ccache/issues?q=is%3Aissue+hash+is... reply Stem0037 8 hours agoprevIt would be interesting to see benchmarks comparing HPy extensions to equivalent Cython/pybind11 implementations in terms of performance and development time. reply actinium226 8 hours agoprevI'm a little unclear as to how this fits in with libraries like PyBind11 or nanobind? It seems like those libraries would need to be rewritten (or new libraries with the same goals created) in order to use this in the same way? reply rich_sasha 11 hours agoprevLooks very cool. How many new extensions are written in C these days? I was under the impression it's mostly things like Boost Python, pybind or PyO3. reply masklinn 9 hours agoparentPyO3 is bindings to the C API, so if you're using PyO3 you're still using the C API even if you're not actually writing C. reply rich_sasha 8 hours agorootparentYeah, sure, I mean, how many people write C to write an end-user Python module. There's stuff that genuinely wraps C libraries or predates higher level language wrappers, like numpy or matplotlib, but how many new modules are actually themselves written in C? reply masklinn 2 hours agorootparentThe point is that’s not relevant, the issue is the API / ABI of the modules, its requirements, and its limitations, not the langage in which the modules are written. reply aragilar 10 hours agoparentprevThere's also Cython. I would guess also that HPy would replace the includes of `Python.h` that pybind11 et al make in order to bind to CPython, and so existing extensions should be easier to port? reply physicsguy 8 hours agoparentprevQuite a lot, for things like simulation code Less so for general programming. reply m_rcin 9 hours agoparentprevfor C++ 11+, pybind11 > Boost.Python for C++ 17+, nanobind > pybind11 (both created by the same developer) \">\" meaning generally better, as described at https://nanobind.readthedocs.io/en/latest/why.html reply trkannr 7 hours agoparentprevA lot. You don't have to write in C, just use the C-API functions. pybind etc. introduce a whole new set of problems, with new version issues and decreased debug ability. reply ashvardanian 3 hours agoprevHey! First of all, cool to see some activity on this front! I’ve written a fair share of pure CPython bindings and regularly post about implementing them with minimal overhead () and would love to share a few recommendations, questions, and concerns :) Just a suggestion to help you grow—I'd restructure the landing page () and the README of the repo (). It could benefit from some examples to clarify the \"Nicer API\" bullet point. Maybe these could be taken from the API documentation page (). The page could also be more convincing with some supporting stats in favor of PyPy, GraalPython, and other Python runtimes. A reader like me might not be sure if they have enough usage and are stable enough. Avoiding singletons and having encapsulated context objects like `HPyContext` is definitely a great thing to have, especially in the multi-threaded Python future or in complex environments with multiple sub-interpreters. But this doesn't really solve the problem if, under the hood, the `HPyContext` still redirects to CPython's singleton. I've also looked at the linked benchmarks (). They are dated from 2019, five years ago, and already mention CPython's `METH_FASTCALL` fast calling convention, but it seems like they are not compared to it. In either case, parsing arguments from one \"ll\" string specifier is hardly a detailed benchmark if the underlying magic isn't explained. I occasionally do one-off benchmarks as well, but it's better to describe the principle—why the thing is supposed to be faster. For example, if you're concerned about performance, you'd just parse the arguments directly from the tuple without string formatters—like this:It’s more error-prone, but it would be cool to see if a high-level solution can achieve under a 10% latency penalty. Hope this is useful :) reply normanthreep 8 hours agoprevtangentially related question: is there something as simple as luajit's ffi for python? as in: give it a c header, load the shared library, it simply makes structs usable and functions callable. reply pkkm 3 hours agoparentcffi is closest to what you described. reply nly 8 hours agoparentprevcppyy does this for C++ reply lukego 8 hours agoparentprevYeah, cffi. reply gghoop 8 hours agoprevI'm interested in calling go from python, gopy generates python bindings to cgo. Maybe HPycgo would have less overhead. reply masklinn 2 hours agoparentUse IPC. Go wilfully set itself apart from and against the C ABI, it’s generally not worth fighting against that. reply crabbone 6 hours agoparentprevIt's a no-go at this point, if you want this on MS Windows. CGo on MS Windows uses MinGW, while CPython uses MSVC. It's very hard to make this work due to name mangling. I.e. you can do this for Python from MSYS2, for example, but not for the one your users will likely have. reply murkt 11 hours agoprevImagine how different the Python ecosystem could be, if this was done 20 years ago. reply lifthrasiir 10 hours agoparentUnless it was done at the very beginning, I doubt it would have been even possible because the current C API is the remnant from that very first public version. reply foolfoolz 10 hours agoparentprevpython has one of the most fractured development ecosystems of any moderately used language. i’m pretty convinced python is a language that attracts poor development practices and magnifies them due to its flexibility. the people who love it don’t understand the extreme flexibility makes it fragile at scale and are willing to put up with its annoyances in an almost stockholm syndrome way reply Quothling 9 hours agorootparentI think any programming language with a lot of popularity attracts poor development practices. Simply because a lot of programmers don't actually know the underlying processes of what they build. The flip-side of this is that freedom and flexibility also gives you a lot of control. Yes, it's very easy to write bad Python. In fact it's probably one of Python's weaknesses as you point out. If you're going to iterate over a bunch of elements, you probably expect your language standard libraries to do it in an efficient way, and Python doesn't necessarily do that. What you gain by this flexibility (and arguably sometimes poor design) is that it's also possible to write really good Python and tailor it exactly to your needs. I think Python scales rather well in fact. Django is a good example, as it's a massive workhorse for a lot of the web (Instagram still uses their own version of it as one example). It does so sort of anonymously similar to how PHP and Ruby do it outside of the hype circle, but it does it. One of the advantages Python has, even when it's bad, is that it's often \"good enough\". 95% of the software which gets written is never really going to need to be extremely efficient. I would argue that in 2024 Go is actually the perfect combination of the good stuff from both Python and C. But those things aren't necessarily easy to get into if you're not familiar with something like memory management, (maybe strict typing?), explicit error handling and the differences between an interpreted and compiled language. Anyway I don't think Python is anymore annoying than any other language. The freedom it gives you needs to be reigned in and if you don't then you'll end up with a mess. A mess which is probably perfectly fine. reply trkannr 7 hours agorootparentBut CPython itself has poor development practices: For about 8 years those in the inner circle can modify anything and pose as experts while brutally squashing criticism. reply gjvc 8 hours agorootparentprevpsst \"reined in\" https://www.merriam-webster.com/grammar/do-you-rein-in-or-re... reply est 8 hours agorootparentprev> most fractured development ecosystems of any moderately used language Can you elaborate? What's done wrong with Python and right with other \"moderately used language\" ? For start, C/C++ doesn't even have an official ecosystem. For Java or Golang, it looks better only because the \"ecosystem\" does not always include native extensions like cgo or JNI. Once you add them the complexity were no better than Python's reply rwmj 8 hours agorootparentPython .pth files are horrific. Here's an actual .pth file I was dealing with the other day (from Google Cloud Storage) which completely prevents you from overriding the module using PYTHONPATH: import sys, types, os;has_mfs = sys.version_info > (3, 5);p = os.path.join(sys._getframe(1).f_locals['sitedir'], *('google',));importlib = has_mfs and __import__('importlib.util');has_mfs and __import__('importlib.machinery');m = has_mfs and sys.modules.setdefault('google', importlib.util.module_from_spec(importlib.machinery.PathFinder.find_spec('google', [os.path.dirname(p)])));m = m or sys.modules.setdefault('google', types.ModuleType('google'));mp = (m or []) and m.__dict__.setdefault('__path__',[]);(p not in mp) and mp.append(p) reply est 4 hours agorootparentI agree those particular .pth files were horrific. But python package made by Google were noturously bad. Its awefulness dates back to the GAE days. reply talideon 7 hours agorootparentprevIf .pth files are the worst thing you can find to complain about, Python's doing pretty well. That horrific .pth file in question is better placed as the feet of its creators than the mechanism itself. reply rwmj 7 hours agorootparentThe fact they considered allowing executable code in path lookups shows a certain attitude. reply oefrha 5 hours agorootparentIt shows that the language is highly dynamic and you can patch anything? The .pth mechanism allows the party controlling the Python installation (site) to run some init code before any user code, basically an rc mechanism. Nothing more, nothing radical. Maybe you’re unhappy with the dynamism, in which case your complaint is misplaced. reply rwmj 2 hours agorootparentIn this case it prevents someone using PYTHONPATH to alter or override the order that modules are loaded. Hard to justify that. reply crabbone 6 hours agorootparentprevYou have Anaconda packaging world vs PyPI. You have pyproject.toml for project management, which is not supported by Anaconda or the flagship documentation generation tool: Sphynx. You have half a dozen of package installers, none of them work to the full extent / all have different problems. You have plenty of ways to install Python, all of them suck. You have plenty of ways to do some common tasks, s.a. GUI, Web, automation: and all of them suck in different ways, w/o a hint of unifying link. Similarly, you have an, allegedly, common relational database interface, but most commonly used SQL bindings don't use it. And the list goes on. reply est 4 hours agorootparent> You have Anaconda packaging world vs PyPI As I said, it's only because .so extensions were hard. If every package were pure Python, I would simply copy paste them in my source code `lib` path. Don't laugh at me, this is called \"vendoring\" or \"static linking\" by other languages, and the \"requests\" famously included a version of urllib3 for quite a while reply Demiurge 3 hours agorootparentprev> You have Anaconda packaging world vs PyPI There is no fracture or \"versus\" here. You can pip install on top of Anaconda. Anaconda provides a more stringent solver and OS level packages that some pip level modules often depend on, it just solves the integration problem, but I use both, including requirements.txt in my Anaconda env.yml all the time. > You have pyproject.toml for project management, which is not supported by Anaconda or the flagship documentation generation tool: Sphynx. Again, Anaconda is not \"standard\" python thing, it is a replacement for build OS level packages, such as GDAL, which is a just a subset of Python modules. Anaconda does not need to support standard python tooling, because those python tools exist outside of Anaconda. To simplify, for every Anaconda package, you can likely find it in PyPI, but for every PyPI, you will not find it in for conda. Anaconda is not a competitor for PyPI, it does not need to replicate every PyPI feature. > You have plenty of ways to install Python, all of them suck. What does this actually mean? You install Python with all the major OS installation methods, and absolutely none of them suck, any more than installing anything on this OS does. The standard ways are Python Setup.exe, apt-get install, and brew install. Yes, you can additional options such as conda distros, yet what exactly sucks about them? Nothing. > You have plenty of ways to do some common tasks, s.a. GUI, Web, automation: and all of them suck in different ways, w/o a hint of unifying link. I think I'm starting to get it. Everything sucks if you've been around long enough. Django is vastly prevalent web framework. wx widgets is standard, and there are bindings for most GUI toolkits. There are many toolkits, is it Pythons fault they all got invented by different organizations? Is it an interpreted language responsiblity to provide a cross platform GUI toolkit for you? > Similarly, you have an, allegedly, common relational database interface, but most commonly used SQL bindings don't use it. What are you even talking about? Who in the world cares about this? People use database specific libraries, in every single language, because every database has its own set of features. > And the list goes on. Your list reeks of someone flinging critiques without even knowing what they’re talking about—just a lot of hot air fueled by emotional baggage, likely from some long-dead language you once cherished before it was mercifully abandoned. reply Const-me 10 hours agorootparentprev> a language that attracts poor development practices I agree, but note there’s another way to frame it: “python can be used by people who aren’t professional software developers”. reply _fizz_buzz_ 9 hours agorootparentprevIt’s also fractured because it has such a massive user base that use it for very different applications with very different priorities. reply miohtama 10 hours agorootparentprevC/C++ is more fractured. While Python is fractured, it is nowhere near problems of C ecosystems. reply rbanffy 6 hours agorootparentAs anyone who has tried to build multi-platform software with C or C++ can easily tell you. It's almost a relief AIX, Solaris, and HP/UX are either very niche, or going the way of the Dodo. reply poincaredisk 7 hours agorootparentprev>the people who love it don’t understand the extreme flexibility makes it fragile at scale and are willing to put up with its annoyances in an almost stockholm syndrome way The people who love it understand that its extreme flexibility makes it applicable everywhere, while academic purity mostly doesn't work in the real work. They also prioritize getting things done over petty squabbling, but they know how to leverage available tooling where reliability is crucial. (See, I can generalize too) reply bvrmn 10 hours agorootparentprevThe reason is a popularity not a technical one. It's inevitable to get a diverse interest to improve different parts of ecosystem by different parties. reply jaimebuelta 7 hours agorootparentprevThere are only two kinds of languages: the ones people complain about and the ones nobody uses. reply redman25 5 hours agorootparentprevPython with types enforced by CI isn’t too bad. Or did you have something else in mind? reply analog31 5 hours agorootparentprevWould some other language have become just as fragmented if it had gained the same level of popularity across such a broad range of user interests? reply slashdave 2 hours agorootparentprevPerl says \"hi\" reply WhereIsTheTruth 8 hours agorootparentprevit's not 'fractured', it's just fragmented, and it's not necessarily a bad thing, it gives plenty of room for R&D and experimentation if something doesn't end up working well, you pivot reply amelius 5 hours agoparentprevIt would have taken time to do this and consequently Python would have missed the race and some other language would now be #1. reply pkkm 3 hours agorootparent> Python would have missed the race Why do you think that? There's no need for a Python 2->3 like transition here, it could have been done while supporting the old C API for a while. reply murkt 5 hours agorootparentprevPython missed the race pretty heavily with 2to3 transition and still came out on top. reply amelius 5 hours agorootparentSurvivorship bias. With version 2 they were already at the top. reply xiaodai 7 hours agoprevIs this thing “official”? reply trkannr 7 hours agoprev [–] After cpyext and cffi, this is the third attempt, largely driven by PyPy people, to get a C-API that people want to use. If they succeed and keep the CPython \"leaders\" who ruined the development experience and social structure of CPython out of PyPy, PyPy might get interesting. If they don't keep them out, those \"leaders\" will merrily sink yet another project. reply filmor 7 hours agoparentcffi replaces ctypes, which is a completely different thing. cpyext is a reimplementation of the Python C-API, so no attempt at improving the API. HPy on CPython uses the existing C-API under the hood, so there is zero need to build up some keep someone out... reply kagerl 6 hours agorootparentcffi is used to wrap c libraries. Only a masochist would use ctypes to wrap a whole library. While both are technically FFIs, it does not make sense to compare them. From a conceptual perspective, cffi was written to replace the C-API for C modules. reply VagabundoP 30 minutes agoparentprev [–] Expand here on your use of double quotes and the subtext of your comment if you please. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "HPy is a new C API designed to extend Python, offering zero overhead on CPython and improved performance on alternatives like PyPy.",
      "It supports universal binaries, provides a migration path for legacy C-API, includes a debug mode, and offers a modern, consistent API.",
      "HPy is actively developed, with version 0.9.0 recently released, and aims to support major packages like NumPy and Matplotlib."
    ],
    "commentSummary": [
      "HPy is designed to enhance Python's C API by simplifying compile and link flags, potentially allowing for version-independent Python bindings and reducing continuous integration/continuous deployment (CI/CD) times.",
      "Unlike the current C API, HPy supports multiple Python implementations, which could encourage alternative implementations and experimentation within the Python ecosystem.",
      "The project is attracting interest due to its potential impact on Python's ecosystem, with comparisons to existing tools like PyBind11 and Cython, and discussions on its benefits and concerns about ecosystem fragmentation."
    ],
    "points": 211,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1728195796
  },
  {
    "id": 41754008,
    "title": "So thieves broke into your storage unit again",
    "originLink": "http://oldvcr.blogspot.com/2024/10/so-thieves-broke-into-your-storage-unit.html",
    "originBody": "Old Vintage Computing Research REWIND and PLAY Saturday, October 5, 2024 So thieves broke into your storage unit - again If you've been wondering why entries have been a little slow lately, let me tell you a story. All collectors tend to be a bit obsessive by nature, and us classic computer nerds probably pick up more hardware than we can (or should) store in our residence — especially if the loves of our lives aren't as enthusiastic about the hobby than we are — and thus have storage units for the overflow. I have two small \"cold\" climate control units, kept small so that I can be out of one or both relatively quickly, as well as a larger \"hot\" conventional unit at ambient temperature. The hot unit is indoors and not exposed directly to the sun, so it's not particularly hot for sunny southern California, but I keep working spare electronics, hard disks, tapes, etc. in the cold units as a precaution and use the hot unit for non-working parts units, books, magazines and other household items. Of course, climate control units cost more, sometimes substantially, and thieves use this as a signal that more valuable stuff is likely to be kept there: Both times I've been burglarized, they were the cold units. August was the second time. So, with crime being a nationwide topic, let's talk about what happens when your storage unit gets broken into and how to recover from it. The first time was not quite two decades ago at a now defunct national chain. I was obviously rather younger then and didn't recognize that these units were incredibly poorly secured: they had simple plywood doors that opened out as opposed to metal roll-ups, the \"latch\" (such as it was) was just a regular safety hasp your padlock went on, and the door hinges were completely exposed. The exterior door to the climate control units (because there must be one to keep the climate controlled air in) was a regular unlocked door without any security cameras. According to the police, a couple of tweekers decided to use the climate units as free air conditioned apartments and intermittently took up residence in many of them, including mine. I had the good sense to use a disc lock instead of a regular padlock, but while they may have been drug-addled they turned out to be smarter than I was. Instead of attacking the lock they just pulled the hinge pins (only two) and got in without even touching the door, the lock or the hasp, and then were able to pull the door closed and escape discovery on walkthrus. By moving around they apparently weren't noticed for days. When a storage unit is hit, the police report that the facility files and any insurance claim they make are completely separate from yours. They may or may not use information from you, but you still have to file your own. During their vacation in my two units they stole and likely hocked my family's Panasonic VHS video camera, which didn't have any tapes we cared about but would have been fun to keep, as well as my first digital camera, an Olympus Camedia something or other that used SmartMedia and still had some photos on it I realized later I never downloaded, a Fisher-Price PXL2000 (the famous pixelicious video camera that uses regular audio cassettes instead of videotape) I had in its original box that I got to use exactly once, and my spare boxed Mattel Intellivision. They also stole a few items from my highway signs collection and even spray-painted a couple I suppose for lulz, and generously left some rather grotty drug paraphernalia and dirty blankets in trade which the police took as evidence. Only one of those items was recovered, the Intellivision (the one item I cared about least since that was a totally spare unit). It turned up at a pawn shop on the other side of the freeway. California law, at least at that time, said that the pawn shop had to be reimbursed what they paid: they couldn't sell it to you at retail, but they also were to be made whole. I went over with someone from the police department and I think it cost me $60 to recover it; I still have it. The cop also quietly pointed out all the things that were wrong with the storage units and told me to get out the rest of my stuff and leave at my earliest opportunity since they would almost certainly be hit again. But what about making me whole? I was required to have insurance on the units, but I just had an apartment at the time and didn't carry renter's insurance, so I paid a premium as part of my rental fees to the chain's \"insurance partner.\" If this smells like a kickback deal, you're right, and virtually every self-storage company engages in it. The idea is to offer you something cheap so that the insurance company will then protect the storage company by deflecting claims. The insurance is cheap because it sucks. I had a police report, obviously, but when I tried to submit the claims for each unit — on paper, as we did in the Dark Ages at the beginning of the 21st century — they were rejected for insufficient documentation (because who keeps a receipt for the Intellivision you bought five years ago from a thrift store?) and I was hardly in a position to sue them over it. As the cop instructed, I bailed out of there a couple months later. The doors had not been upgraded, there was still no lock on the exterior entrance, and the manager said installing cameras would be too expensive. I made sure to note on my \"exit survey\" that I was leaving because their security was worse than a Russian garrison after a vodka waffle party. The chain subsequently folded and got sold to some other megastorage company and I imagine they're still too cheap to do anything about it. The current break-in was a bit more professional because the facility I moved to was obviously more serious about security (they could hardly have been less). When I first moved in, the climate control section had proper roll-up doors and sliding security latches, and there were cameras scattered around the premises, but the exterior door was also just a regular door and usually left unlocked. One of the local unhoused encampments noticed this and moved in, leaving a mess and requiring forcible eviction by the police, though they didn't manage to get into any occupied units. After that the management installed a cipher lock-type door handle and issued unique codes to each tenant. We own a house now, but my particular homeowner's insurance policy doesn't cover rental units (I read every page, believe me). Even though the \"partner\" insurance was useless the first time around, I still went with the company this facility was getting kickbacks from since it was the cheapest alternative. After all, I figured if I got hit again they wouldn't pay off this time either, so I might as well spend as little money as possible on it. The door handle only controlled the latch; there was no deadbolt. So what do you do to attack a door like that? You crowbar it and pry the latch open (see also the well-known xkcd). The picture at the beginning was what it looked like when I came to survey the damage. The manager had effected some emergency repairs and installed a temporary keyed deadbolt, requiring me to go to the office to get inside. And what do you do to attack disc locks? Well, if you're not handy with a pick, you drill them. The drilled lock is on the right where you can see the small hole in the keyway. This lock was on the first unit, in which they upended several items and ended up stealing my Atari Portfolio in a camera bag (the good one, of course, not the flaky spare), a boxed set of Agenda VR3 PDAs (the famous MIPS Linux-based one), and an 867MHz Titanium PowerBook G4 in its original box. This unit was somewhat defective in that it has an iffy LCD CCFL that starts up pink. Later after submitting the claim and police report I also noticed they stole a box of Apple Pro Speakers (wait until they try to hook them up to anything). For some reason they didn't drill the lock on the second unit and instead took several whacks at it with some sort of sharp instrument, but this only made the lock completely inoperable. They then pried the latch off, but the shelves in that unit interfere with the roll-up door unless you know the trick and they apparently weren't able to get inside. (The manager had also replaced the latch before I arrived.) In the process, however, they did succeed in knocking some items around including a couple of hard disks off the shelf from my Outbound laptop systems. They were fortunately backed up before storage and should be replaceable with some other 2.5\" IDE equivalent device because they won't spin up now. Having learned my lesson from the first burglary, I had nothing irreplaceable in the units, though I did have some items from my Tomy Pyuuta collection in the second one temporarily. They also didn't go through any boxes, likely because they didn't have any time: the next scheduled security patrol arrived about ten or fifteen minutes after they gained access and discovered the theft, so no doubt they hauldassed when they saw the guard coming back on rounds. I also wasn't the only person burglarized, though the manager wouldn't tell me exactly how many other units were hit. For the units that were hit, he provided us with covers that slide onto the latch: I can see how this would make it very difficult to use boltcutters or an angle grinder on the lock shackle, but if you can get a key in it, you can get a wrench or a drill bit in it, so I'm not sure if it adds any meaningful security otherwise. I wandered around to see if the covers were on other units and I counted a few, though I couldn't say if everyone who got one was using it. This time, same city, the police never showed for my units and I don't know if they came to the premises at all. (Before you ask, I have absolutely no idea if Proposition 47 has anything to do with it.) I submitted the police reports online and got my case numbers, one for each unit as usual, and then did an online submission with the insurance company including the photos that I had. The insurance company took about a week to assign an adjuster. Despite having itemized the missing items twice on the police report and in the initial submission, I was asked to complete and notarize another inventory sheet for each unit on paper. The adjuster also wanted any proof of purchase or ownership, such as \"a receipt, invoice, order or shipping confirmation, or debit/credit statement.\" Naturally, these items are so old and have been in there so long that none of this exists. The situation sounded suspiciously like I was going to get stiffed again and I complained to the adjuster that if I had to pay a notary to notarize two documents that may never result in a payout, I'd be out even more money as well as time. (A fairly cynical way of discouraging claims by people for whom that amount of money is more significant.) To my surprise, although it took several E-mails and another ten days, the adjuster agreed to waive the notarization requirement. (I'm not even sure what the notarization step was accomplishing: the inventory sheets aren't affidavits.) The documents wanted purchase price and location, which I could only do from memory, and a replacement cost, which I did by eBay searches for comparable items. My insurance limit is $2,000 each unit with a $100 deductible, waived if you have a disc lock installed, which I did. I made sure the destroyed disc locks were listed as part of the claim and I determined a total replacement cost of $512.23 in the first unit and $57.23 in the second one. I didn't hear anything for a month and E-mailed the adjuster again. The next day they paid off on the claim: $269.40 and $48.96. \"The policy you have is based on the Actual Cash Value (ACV) of your items, which means depreciation needs to be applied to the item(s) based on their age. I've adjusted the loss presented and added in the applicable sales tax.\" Since I figured the alternative was $0 and extra vitriol for this blog post, I agreed. The checks arrived this week and we deposited them. They do not make me whole, though of course none of these items are critical. Here's the lessons learned for those of us with classic computers in storage: The quality of the facility's security matters. The best burglary is the one that never happens. If one does, higher quality facilities are more likely to work with less unreasonable partner insurance agencies. Store nothing you really care about in a storage unit. Real burglars notwithstanding, the other kind of theft you may have to worry about is an unscrupulous manager who says you didn't pay your bill and auctions it off. Such horror stories aren't common, but I know people who say this has happened to them, keeping in mind I'm only hearing their side of the story. For example, my original Tomy Tutor, the actual computer I got when I was seven in its actual box with its actual accessories that actually still works, will never go in storage. Neither will my first suitcase Commodore KIM-1. Use a disc lock. They're certainly better than the cheapo padlocks you buy at the store, but most insurance companies will also reduce or waive your deductable if you have what they consider to be a proper lock, and that usually means a disc lock. If you use the disc lock the storage facility sells, you'll likely pay an additional markup on it, but it's also guaranteed to be acceptable to their partner insurance company. Plus, you can claim the replacement cost. How you do inventory may not have much effect on the success of your claim. The advice that you should take photos of your storage unit each time you're in it is a good one and you might as well do it if you have the presence of mind, but it's not really what they're asking for on claims (\"you could have lost it, you could have misplaced it, that's not proof of ownership,\" etc.), and there's no guarantee you'll have photographed what in fact got taken. A beautiful spreadsheet doesn't prove ownership either. In both cases they wanted receipts and I didn't have any of those. In the first case, the insurance company told me to pound sand. In the second case, they paid off. I'll let you know if a pattern ever emerges, but the photos didn't have anything to do with it in either situation. Bulky and heavy items are ignored. Fortunately, many classic computing items are bulky and heavy, and they take up space in a truck. If it's going to slow them down and it's not clear they can fence it, they might damage it but they probably won't take it. By the way, claim damaged items too, not just stolen ones. You might as well ask. Something neat-looking that's light and portable might get nicked. The Portfolio was in a camera bag, so they probably figured it was a camera and yoinked it. Moreover, anything with an Apple logo that's light and portable will get nicked. These aren't usually technologically savvy people and they know that Apple makes this cool thing called an iPhone and some watch thing and people like those. So they took the PowerBook and Pro Speakers, even though they probably didn't fetch much when they tried to sell them. Conversely, if you make the thieves' job harder, they'll take less. Gangs that hit self-storage units aren't generally the ones that do a whole lot of preplanning and research. Other than maybe renting a unit themselves to look around and get a gate code, they usually won't know the exact interior layout or what units are occupied, and since they won't know what time window they have before any guards or staff come around they'll prefer to grab what's obvious. In my case, the door on the second unit won't fully open without a bit of particular fiddling, so they obviously gave up. Messy units are harder to work in but also harder to steal from. Put high value items in the back and out of view behind big heavy ones. Hide production packaging in non-descript boxes: they didn't get any of my Palm Pilot collection, for example, despite being small, portable, frequently in their original boxes and looking like something of value, because they were all in plain cardboard boxes with opaque descriptions in Sharpie marker. But they got the Agenda VR3 box because it was out on the shelf. You don't get what you don't ask for, and you won't get what you don't constantly get on their case about. The adjuster was clearly not a malignant person, just overworked, because this is a cut-rate insurance company who tries to screw their employees just as much as their covered individuals. The squeaky wheel gets the check. You will never get the full replacement value of your items. Ever. In the end, it's just stuff. I'm not happy it got broken into, but I'm not going to shrivel up or shoot myself in the head over it either. Nothing was in there I can't live without. Since the break-in occurred, the temporary deadbolt was replaced with a new cipher lock, but this one controls a full deadbolt, not just a door latch. The facility is also gradually converting the roll-up doors to pick-resistant cylinder locks and dispensing with padlocks altogether. I'm hopeful I won't be writing a third blog post on this topic in a few years. Posted by ClassicHasClass at 12:05 PM Email ThisBlogThis!Share to TwitterShare to FacebookShare to Pinterest Labels: protip No comments: Post a Comment Comments are subject to moderation. Be nice. Older Post Home Subscribe to: Post Comments (Atom) Welcome to Old VCR My general vintage computing projects, mostly microcomputers, 6502, PalmOS, 68K/Power Mac and Unix workstations, but that's not all you'll see. While over the decades I've written for publications like COMPUTE, TidBITS and Ars Technica, these articles are all original and just for you. My promise: No AI-generated article text, ever. Be kind, REWIND and PLAY. -- Cameron Kaiser Old VCR is advertisement- and donation-funded, and what I get goes to maintaining the hardware here at Floodgap. I don't drink coffee, but the Mr Pibb doesn't buy itself. :-) Thanks for reading. Greatest hits Meet your new two-factor authenticator: your Commodore 64 The MIPS ThinkPad, kind of Refurb weekend: Canon Cat Dusting off Dreamcast Linux If one GUI's not enough for your SPARC workstation, try four When you have too much memory for SheepShaver So long, home T1 line; hello, hacking the T1 router The Apple Network Server's all-too-secret weapon (featuring PPC Toolbox) Apple's Interactive Television Box: hacking the Set Top Box System 7.1 in ROM So thieves broke into your storage unit - again Other stuff I write Other classic computing posts from TenFourFox Development Talospace: OpenPOWER news and experiences from the free computing frontier Jerk Music Critic: music reviews worth what you paid for them About Me ClassicHasClass View my complete profile Blog Archive ▼ 2024 (18) ▼ October (1) So thieves broke into your storage unit - again ► September (1) ► July (1) ► June (2) ► May (3) ► April (2) ► March (4) ► February (2) ► January (2) ► 2023 (39) ► December (1) ► November (2) ► October (3) ► September (5) ► August (4) ► July (4) ► June (4) ► May (2) ► April (2) ► March (3) ► February (3) ► January (6) ► 2022 (36) ► December (5) ► November (4) ► October (6) ► September (4) ► August (3) ► July (3) ► June (2) ► May (2) ► April (1) ► March (2) ► February (3) ► January (1) ► 2021 (26) ► December (2) ► November (1) ► October (1) ► September (3) ► August (5) ► June (2) ► April (3) ► March (4) ► February (4) ► January (1) ► 2020 (25) ► December (2) ► November (5) ► October (2) ► September (3) ► August (2) ► July (3) ► June (3) ► May (2) ► April (3) Labels 3d (3) 6502 (25) 65816 (9) 6800 (1) 68000 (16) 8051 (1) 9995 (1) a/ux (2) administrivia (1) aix (3) alpha micro (2) amiga (1) apple ii (4) appletalk (3) arduino (1) atari 8-bit (1) bebox (3) beos (6) browser (7) bucketlist (1) c128 (6) c264 (1) c64 (12) canon (2) cap-x comp-x (1) casio (1) classilla (1) cobalt (1) commodore (16) console (2) cp/m (1) cray (1) crypto ancienne (4) dec (1) dec alpha (1) dectalk (1) dick smith (2) dos (2) dreamcast (2) emulation (1) firewire (1) forth (2) fouo (1) future (1) geos (1) gopher (7) graphics (6) hohoho (1) hp (1) hpux (1) humour (2) ibm (1) inty (1) itanium (1) kim-1 (8) linux (1) lynx (3) mac (13) magic cap (2) mattel (1) mechanical (1) memorials (10) mips (5) netware (1) networking (13) palm (7) parisc (2) pocket handheld (2) pong (7) power mac (20) powerpc (8) prior art (3) protip (2) refurb weekend (19) review (6) science (1) sega (1) sharp (1) smartwatch (2) software (50) solbourne (3) sparc (3) spreadsheet (1) sun (2) sunray (2) superh (3) tadpole (1) tandy radio shack (1) terminal (10) ti (4) tomy tutor (4) unboxing (1) unix (14) unscreenshotable (4) usb (4) usenet (1) vtech (1) wince (2) windows (2) workslate (1) x86 (3) yaddayaddayadda (1) z80 (3) Copyright 2020-24 Cameron Kaiser. CC BY-NC-ND 4.0. Powered by Blogger.",
    "commentLink": "https://news.ycombinator.com/item?id=41754008",
    "commentBody": "So thieves broke into your storage unit again (oldvcr.blogspot.com)197 points by goldenskye 17 hours agohidepastfavorite195 comments istjohn 1 hour agoThe storage unit industry is one of the most awful, customer hostile industries I've encountered. It's impossible to get the local facility on the phone, publicly listed phone numbers are all redirected to a national call center where reps are unable to even accurately quote prices. TFA covers the insurance kickback scam. Then after I moved into my unit, I discovered 75% of the units in my facility could be broken into with zero tools because the padlocks provided by the facility had enough slack in the shackle that if you rotated the lock 90 degrees there was room for the bolt to slide the half inch needed to clear the bolt hole in the strike plate. Then there was the rodent infestation. The paradox is that the monthly cost of a unit will quickly exceed the value of whatever is stored there unless the items have sentimental value or are very expensive. In TFA, their losses from theft was $500 and their insurance limit was $2,000. Within two years they would exceed that in rent payments on the unit. A Google search suggests the average storage unit tenancy is only 10 months. That's reasonable. Long-term storage only makes sense when the value exceeds what can reasonably be entrusted with the lax security of a storage facility. reply ebiester 3 minutes agoparentI think there are three use cases: 1. You are temporarily moving to a place outside your local area, or to a much smaller place. I was moving around for a year and a half, so I left my furniture and non-valuables in a storage unit until I would be settled again. 2. You live in a small unit in a big city. $100-$150 for an extra 50 square feet a month might be cheaper than the equivalent space and is a great choice for occasionally used items. if it's 4 dollars a square foot for living space or 2 dollars a square foot for storage space, that's a deal. 3. Short term holding: You're moving out of your rental in July, in AirBnbs until September when you've closed on your house. If you're in a suburban house and don't have enough space, that's a bad reason to have a storage unit. reply tshaddox 39 minutes agoparentprev> The paradox is that the monthly cost of a unit will quickly exceed the value of whatever is stored there unless the items have sentimental value or are very expensive. This is a tough one to manage psychologically, although it’s almost certainly also true of nearly anything you are storing in your own home. The difference of course is that home space is bundled inflexibly—you usually don’t have the option of paying 2% less for 2% less space. reply bigstrat2003 23 minutes agorootparentThat's why it isn't true of your home. The cost of storing an item in your home (assuming you didn't buy a bigger house just to store the thing) is 0. reply Simon_ORourke 33 minutes agoprevMy ex-wife demanded that we store some awful, terrible wicker furniture after a house move, so I put these cheap monstrosities into a $40/month storage unit in a semi-desolate area of town. The unit was broken into three or four times but the thieves didn't do me the favor of actually stealing anything. On the last break in I contemplated just leaving them a note with $20 inside pleading with them to just take the damned things. reply treflop 4 hours agoprevDon’t buy insurance from the same company giving you the service. Insurance is for you and you should pick it from your own choice of company and you should tailor the policy for your own needs. Same with financing. In my case, I get a lot of my insurance from a guy in my town and he has an office that I can walk into if I need help. reply cantSpellSober 1 hour agoparentHow to with rental cars? I don't own and no local insurers will offer me non-owner insurance. I have to get the crappy expensive insurance at the rental car desk. reply HFguy 5 minutes agorootparentThere are yearly policies you can get if you just rent cars. GEICO has them for example reply dylan604 1 hour agorootparentprevWhen I canceled my insurance after going carless, I was told that there would be a lapse in my coverage causing my rates to increase. So naturally I asked why would I cover a car I no longer own. Apparently, there is a type of insurance that covers you as a driver of other cars. Of course there is. Going on 4.5 years now with no insurance payments. It's been glorious reply maxerickson 31 minutes agorootparentIf you do regularly drive other cars, it can make a lot of sense to make sure you have a liability policy that will cover an incident (vs assuming that the coverage on the vehicles is appropriate for you). Not sure why you'd be bothered/dismissive that you can access a sensible financial product. reply BrentOzar 1 hour agorootparentprev> How to with rental cars? Some credit cards like American Express offer their own insurance as part of the membership fee as long as you pay for the rental with their card, and decline the coverage offered by the rental car company. reply eurleif 2 minutes agorootparentThis is typically (including in the case of AmEx) collision insurance only, not liability insurance. You still need liability insurance from somewhere. reply Dove 31 minutes agorootparentprevThere are companies that will sell you rental car insurance as a standalone policy. Google \"Rental Car Insurance\". Last I was dealing with this problem myself, the policies were something like half the cost of what the rental car place wanted. reply bbarnett 26 minutes agorootparentMany credit card companies offer insurance when you rent using them. reply tim333 4 hours agoparentprevI tend to avoid the insurance and just pile up the money I would have paid to cover the losses. Depending on the type of insurance. But theft insurance tends to be problematic. The fraudulent buy expensive stuff, keep all the receipts, sell the stuff for cash to a friend and then claim on insurance with the proper paperwork. Normal people tend not to keep and file away all paperwork and lose out. reply treflop 3 hours agorootparentAlthough it’s a little more complicated, generally if you can cover a loss out of pocket, then you don’t need insurance. Insurance is for losses that will have a major impact on you. It’s putting a price on risk. reply wjnc 2 hours agorootparentInsurers do notice that small claims (in P&C) are a relatively small part of claims + cost so most don’t offer the high deductibles. As a bonus, with higher deductibles come relatively more lawsuits. So safer to only offer low deductibles. (My experience after 20 years in the sector.) In my country a family perhaps pays about €5k total a year for two cars, health, house and the assortment of legal and liability insurance. That is quite modest (not for all income classes though), since there are catastrophes possible in nearly any avenue of life. A minimalist insurance scheme would save one about €2k/yr. That just isn’t that worthwhile utility wise. reply accrual 1 hour agorootparentprevRight. If I accidentally crash my vehicle into someone's property (or worse, someone) I don't want to be out of pocket for potentially 100s of thousands when I could just pay my sub-$100 premium and not worry about it. reply lifeisstillgood 12 hours agoprevI’m stunned by the idea of making the pawn shop whole. As I understand UK law, if you buy stolen goods, the original owner can just claim it back and you take the loss - simply to discourage buying with knowledge it was stolen. I guess the pawn shop would go out of business but it does seem if you let them act as a fence you are solving for the wrong problem reply bombcar 3 hours agoparentThey're likely trying to prevent the situation where the pawn shops become entirely uncooperative, but there's still a tragedy of the commons situation occurring. reply PaulDavisThe1st 2 hours agorootparentThis is a periodic public service announcement that there is not, and never has been \"a tragedy of the commons situation\". Even the author of the concept, Garret Hardin, has acknowledged that he made mistakes in his understanding and research. Resources held in common have historically been subject to significant control via social, civic and legalistic processes. What is typically referred to as \"a tragedy of the commons situation\" never turns out to be what Hardin originally suggested - individuals taking advantage of the lack of controls. Instead it is invariably individuals who first dismantle the control systems in place in order to pursue their own selfish ends. This matters because the \"tragedy of the commons\" concept has been used to suggest (successfully) that communities cannot manage commonly held resources, which is false. What is true is that communities frequently cannot manage a sustained attack by selfishness and greed against their own systems of management, and that's a very, very different problem. reply crazygringo 1 hour agorootparentCan you elaborate? My understanding is that overfishing and climate change are prime and valid examples of the tragedy of the commons. You seem to be claiming that the problem is with systems of management, but the entire point of the tragedy of the commons is that it happens when there isn't management. Which is abundantly the case at the global level of international waters and a shared atmosphere, because there is no such thing as a world government, nor do most people want one. So how exactly has there \"never... been a tragedy of the commons\"? How are overfishing and CO2 not exactly tragedies of the commons? What other principle explains why they weren't solved decades ago? reply clcaev 33 minutes agorootparentThe planet's air and international waters are truly public resources, at least currently. I'm not sure if I would call them a commons. Speaking of which, Elinor Ostrom's book, Governing the Commons, outlines the conditions for the successful management of a commons. Notably neither private ownership nor governmental control is ideal, the best outcomes are by cooperative organizations where those with a direct stake in the commons are the managers. reply crazygringo 4 minutes agorootparent> I'm not sure if I would call them a commons. I don't understand why not. That's the literal definition of a commons in the political economy sense -- a public resource everyone can take from freely. (As opposed to a public resource that is managed via licenses, auctions, limits, etc.) On what basis would you not call them a commons, in political economy? (Obviously we're not talking about commons as a literal shared pasture for livestock grazing.) tshaddox 22 minutes agorootparentprev> This matters because the \"tragedy of the commons\" concept has been used to suggest (successfully) that communities cannot manage commonly held resources, which is false. This is not my impression. I’ve always heard “tragedy of the commons” invoked precisely to advocate that commonly held resources must be regulated. reply willcipriano 10 minutes agoparentprevOften there is a fairly large delta between what they pay and what the sell for, I always assumed part of that premium was absorbing some risk the item was stolen and would have to be returned. Under this system, why not buy stolen goods and try your luck? \"Oh hello guy who looks like he sleeps rough, I would love to buy your thousands of dollars worth of power tools that you can't even tell me what they are for for pennies on the dollar.\" reply gary_0 5 hours agoparentprev[deleted] reply delichon 4 hours agorootparentLaws against fraud, like 18 U.S. Code Chapter 47 and others in each state? reply erinnh 4 hours agorootparentprevId say your friend being put behind bars would do the trick. reply HeatrayEnjoyer 4 hours agorootparentprevThey would just arrest the person who pawned the items. reply loopdoend 14 hours agoprev> I'm not even sure what the notarization step was accomplishing: the inventory sheets aren't affidavits. The percentage of people who see the word \"notarized\" alongside \"inventory sheet\" and simply give up must be quite high. Notarization accomplishes nothing besides causing a headache. Insurance companies don't make money by paying out claims, you know. reply meowster 14 hours agoparentNotarization just proves it was you who signed something, it has nothing to do with the contents of the document. Unfortunately a lot of people think notarization gives some kind of legitimacy to a document, or likely in this case, it's probably not the hassle of getting it notarized, but used as a scare tactic to prevent some people from committing insurance fraud by listing inflated or made-up items (people might conflate it with perjury). reply s1artibartfast 14 hours agorootparentIt proves not just who, but when. This can be pretty relevant in a number of situations. reply qingcharles 2 hours agoparentprevIllinois did away with notarization requirements for almost everything a few years ago. Now you can just sign things under penalty of perjury and it's done, which is the right way to go about it. reply tgsovlerkhgsel 13 hours agoparentprevIt also makes it feel more serious, deterring insurance fraud. Since it has only upsides, no downsides, for the insurance company (except that they'll get bad ratings from customers which they clearly don't care about in this scenario, as most customers don't shop around for them), of course they demand it. > Insurance companies don't make money by paying out claims, you know. This is why if you want actual insurance (not \"check the 'you must have insurance' box\") you don't pick the cheapest company and check reviews, ignoring any reviews that don't mention a claim. reply lazide 14 hours agoparentprevThat, and it would make it harder to claim mistake/accident if the insurance company tried to Prosecute for insurance fraud. The number of cases of people adding random expensive things that would be added to insurance inventories during a claim has to approach 90% if there is no potential for consequences. reply nsxwolf 14 hours agoprevI used to work security and making rounds in a place like this would give me chills. Running into thieves at 3 in the morning is one of the most terrifying things you will ever experience. reply nytesky 4 hours agoparentI feel it’s like walking in the woods in the south — you make a lot of noise so you don’t surprise a rattler? Were you walking stealthy so they don’t hear you coming? reply raincom 14 hours agoparentprevHow did you deal with such terrifying situations? reply pavel_lishin 4 hours agorootparentI'm not the person you asked, but most people like that - opportunistic burglars, etc - are no more keen to run into the police than you are to run into them. They'll just run. Granted, the equation changes dramatically when various drugs are involved. reply nsxwolf 2 hours agorootparentprevThankfully they always ran away. reply bodyfour 12 hours agoprevWhat is annoying to me is that in this internet-connected age, the storage units I see still don't have better per-unit security. Just a phone alert to say \"door to unit #xyz has been opened\" would be a huge improvement. Wire up a cheap webcam for extra credit. reply jwagenet 2 hours agoparentI’m pretty sure most large storage operations (U-Haul, extra space, etc) have per unit door sensors which work in concert with customer check in/out to verify authorized openings. reply meowster 1 hour agorootparentI'm pretty sure they don't: source I've helped move people's stuff in and out of a couple of different places. My experience is very limited, so if you have more data points where you have seen such things, please share. reply smeeger 3 hours agoprevhe gives a list of things to do or consider. supporting laws and politicians that catch and punish criminals effectively is somehow not on that list… reply darkwizard42 2 hours agoparentThe items he listed have extremely direct impact on YOUR ability to reduce theft. You just suggested something very broad. I might make the point that punishing criminals effectively will potentially reduce overall crime, but has no direct reduction on the crime in the article. It would be very hard to show any law which specifically targets the type of crime OP posted about, but I'm open if you have seen legislation proposed or enacted which targets this crime in a major city. reply Carrok 3 hours agoparentprevPlease provide a list. Keep in mind you yourself added “effectively” as a criteria. reply immibis 2 hours agoparentprevPoliticians who claim to be tough on crime are usually just tough on black people and drug users, which helps nobody. reply PaulDavisThe1st 3 hours agoparentprevWhat laws do you believe would be more effective a catching and punishing criminals? AFAIK, there is reasonably clear evidence that deterrence has a very low impact on this sort of crime, so laws based on deterring through fear-of-sentence would not seem to be likely to have much effect. What is it that you're proposing/desiring? reply dimensi0nal 1 hour agorootparentIncapacitation, not deterrence? If someone is in prison, they can't reoffend. reply peppermint_gum 2 hours agorootparentprev> AFAIK, there is reasonably clear evidence that deterrence has a very low impact on this sort of crime, Could you share some of this evidence? reply PaulDavisThe1st 1 hour agorootparentfirst result from google come for \"effect of deterrence on property crime\" https://www.house.mn.gov/hrd/pubs/deterrence.pdf second result, summarizes and links to several review papers: https://nij.ojp.gov/topics/articles/five-things-about-deterr... reply peppermint_gum 56 minutes agorootparentThen I'm not sure what you mean by \"deterrence\". Both of the linked articles argue against increasing the severity of punishment, but they also say that the certainty of getting caught is a strong deterrent. This doesn't seem to be in conflict with what the GP said (\"supporting laws and politicians that catch and punish criminals effectively\"). It seems to me that many people have a problem with thieves not being punished at all. reply smeeger 2 hours agorootparentprevdeterrence works. when i moved into my house it wasnt quite finished. i had soent a few years building it. neighborhood is ok but tweakers are walking around all the time. they walk around everywhere because they can, and to case houses. the people here think like you. they just let it happen. tweakers had stolen a lot of materials and a few tools from me at this point. so when i moved in, for some reason they decided it was a good time to try and break in. it was one guy, i caught him trying to get in the window. grabbed my pistol and confronted him. he ran away but i kept after him. he was so scared that he dropped his bag and begged me to confirm for myself he hadnt stolen. so i let him go and my neighbor met up with me outside my house. both openly displaying our guns. the getaway car rolled by, you could tell because it was tweakers and when they saw those guns their jaws dropped. like i said, this hood is ok but infested with tweakers. not after that night. not a single instance. not a single person casing houses. people like you always cite “evidence.” your evidence is nonsense. studies that are deeply flawed an not applicable. what do i suggest? first of all, actually enforcing laws that are already on the books. is theft really punished or are these people getting away with it so often that it might as well be legal? and when they do get caught its a slap on the wrist or even a nice little vacation with four hots and a cot because jail and homelessness is literally normal for these people. i suggest punishing people severely and immediately for crimes that arent victimless. i suggest allowing people to defend themselves. and i suggest that people actually take ownership of their communities and drive out scum. the west coast does the least of these things in the country and look at the results. portland has a higher violent crime rate than mexico city… take your bleeding heart nonsense and shove it. and dont reply, if you want to hash this out then give me your twitter handle and we can have a space about it reply PaulDavisThe1st 2 hours agorootparentI see. So a few anecdotes, handwaving dismissals of a century or more or crime and sociological research, and a suggestion to move to Twitter. reply samatman 2 hours agorootparentprevTheft is an organized crime. That tweaker/junkie who steals your bike, breaks into your storage unit, whatever? He's not an organization man. The dude with a standing offer to pay twenty bucks for the bike, or ten if it's shitty? He's with an organization. What I propose is that we start enforcing the law and treat theft as a crime, not a nuisance or fact of life. Roll up the organizations, toss them in prison, and repeat over and over until the message gets out. This isn't a problem which can be solved at the tweaker level. What we can do, and simply choose not to, is get every single dude with twenty bucks or a baggie to trade for your bike. All that's lacking is the political will. reply PaulDavisThe1st 2 hours agorootparentWhat's also lacking is any evidence of any kind that this would have the effect you desire. reply immibis 2 hours agorootparentprevReally? You want to make it illegal to buy a bike for $20? Ask the Soviet Union how well price controls work. reply samatman 51 minutes agorootparentThis comment is manifestly made in bad faith. I want the police to arrest, and DAs to prosecute, organized theft rings. Someone with several stolen bicycles is not a small businessman, he's a fence, and should do several years of time. It is in fact quite easy to tell that person apart from the guy who bought a bike on Craigslist and oops, turned out it was stolen. You're pretending this distinction is unclear to you, and insinuating that I'm proposing Soviet price controls. In reality, you are perfectly aware of the distinction and know that I'm not. That is arguing in bad faith. reply nytesky 4 hours agoprevIn general isn’t the consensus that storage units are a very bad deal for “storage”. It can be useful for temporary storage for bulky items like furniture when renovating your house or in between houses, but the fees would quickly accumulate and pay for almost any reasonable contents. If the fees wouldn’t cover replacement of the contents within 6 months, they are too valuable to store in a storage unit. reply crazygringo 4 hours agoparentIf you don't have space in your apartment or home for items you want to keep, then where else are you supposed to store things? Obviously it's up to you to figure out if it makes financial sense. But for people in urban areas with small apartments, it can be a heckuva lot cheaper than upgrading to an apartment with another bedroom. reply toast0 3 hours agorootparent> If you don't have space in your apartment or home for items you want to keep, then where else are you supposed to store things? On ebay? Sell the stuff now, buy it again if you need it. Doesn't work for everything, of course, and I don't practice it, I've got tons of space and tons of clutter. reply mdaniel 2 hours agorootparentI believe other people are using any such storage as a cache, trading space for time, since even if you instantly found the exact replacements, you'd still pay not only monetarily for shipping but wall-clock for both shipping and the drudgery of searching for said items Interestingly, I read a blog post where someone was using \"fulfilled by amazon\" as off-site storage, but I think it was a pseudo thought experiment more than an actual storage solution, similar to those folks who use data-as-video on YouTube as infinite backup storage reply crazygringo 1 hour agorootparentprevSo you're going to sell your surfboard and buy new ski equipment every winter, and sell your skis and buy a new surfboard every summer? As well as the rest of your bulky seasonal gear? Sounds expensive. reply nytesky 6 minutes agorootparentSurfboards mounted on the wall are a common decoration, so there is off season storage. You can rent skis for a season for $400, I suspect most rental places are than $100/month. But skis especially can usually fit in the back of a closet or under a bed. Kayak? Get a season pass for the rental place. reply dpifke 54 minutes agorootparentprevNot to mention the time value of haggling on Ebay, dealing with scammers, etc. reply crazygringo 49 minutes agorootparentAnd wasting all that money on shipping and sales tax with each transaction. Because yes, you have to pay sales tax on eBay, even for used items that already had sales tax paid on their original retail purchase. reply smeeger 3 hours agorootparentprevits almost as if people really shouldnt live inside glorified cubicles… as if they should in something larger. and maybe have a space with grass and also a little accessory structure with a door large enough to fit a vehicle. such a thing doesnt exist unfortunately reply crazygringo 3 hours agorootparentMy nearby park has tons of space with grass. And why would I want space for a vehicle when I have public transportation that is much faster? reply smeeger 2 hours agorootparentso you dont have to rub against a homeless man who smells like piss on the train, dont have to be screamed at by a crazy homeless person on the train, and so that you dont have to rely on tweaker infested, crooked ass storage companies for one of the most basic aspects of existing in the world. reply PhilipRoman 13 minutes agorootparent>dont have to be screamed at by a crazy homeless person on the train This was a great reminder of how differently public transport is perceived in different places. Don't recall the last time I've seen someone (much less a homeless person) scream there, maybe once >10 years ago? (for reference, I commute by public transport every day) reply rondini 1 hour agorootparentprevHaving a preference for large suburban homes is fine, but your view of vulnerable people in your community is gross. It sounds like you'd rather insulate yourself from the failures of your local gov't, which is a privilege many people don't have. reply snovv_crash 2 hours agorootparentprevSounds like trains in your area need to have better security and ticket checkers. reply zimpenfish 1 hour agorootparentprevPlease let me introduce you to the insanity of UK house prices... reply dpifke 58 minutes agoparentprevWhen I lived in a condo in San Francisco, I had a storage unit for my camping and outdoor gear. The alternatives would have been: a) buy a new tent/cooler/propane stove/etc. every 2-3 months, or b) not go camping regularly. I absolutely did not have room to store a kayak at home, and my neighbors would have been annoyed with me dragging muddy/dusty gear through the communal hallway to my unit. When I left SF, I spent about 18 months traveling before permanently moving in anywhere. I did the math on \"cost per cubic foot to store vs. cost to replace\" then, and interestingly, furniture and most housewares didn't make the cut—except for a few sentimental items. An unexpected bonus of instead donating that stuff to Goodwill was that when I moved into my new place, I got to outfit my kitchen with much nicer stuff than what I had previously accumulated. (Now I live in the Midwest and have a garage for the outdoor gear, which in addition to vehicle storage, also doubles as machine/metalworking/woodworking shops.) reply bluedino 3 hours agoparentprevTrue, but it's just another one of those illogical things people do. reply wakawaka28 3 hours agorootparentYou could apply the same logic to the stuff inside your house, which is just a glorified storage unit. Why are you paying premium to store that stuff, when you could downgrade to a studio apartment or a tent? The bottom line is, if you want to own stuff, then you must store it. You know what is more expensive than storage? Buying stuff you need or want and reselling it, again and again. Or leasing it in general. Some stuff has poor resale value, takes a lot of energy to choose and accumulate, and is not easy to replace. reply nytesky 2 hours agorootparentWell, when you are writing an apartment, people do generally go for the cheapest smallest place they can afford. But when you’re buying a place, you’re looking to have isolation from shared walls, and generally a larger property will appreciate more in value than a smaller property With some limits in both directions up and down in size. reply immibis 2 hours agorootparentprevIt would be illegal to live in a tent. reply wakawaka28 2 hours agorootparentEven if it was legal, most people wouldn't like that. reply roland35 3 hours agoprevWhat a story! Most people probably would just give up. Dealing with storage units is why I try to eliminate all the extra \"stuff\" in my life... George Carlin had a great bit on stuff: https://youtu.be/MvgN5gCuLac reply bluedino 3 hours agoprevAn acquaintance of mine was stealing big-ticket items from a storage unit. Campers, boats, etc. Of course he eventually got caught. The insurance company had already paid the owner of one of the campers, so it went to auction, and he bought it. Kind of funny. reply kstrauser 16 hours agoprevThere are a million reasons why you should never do this, but I would be tempted to use storage unit #3 as the place to keep my land mine collection. Edit: “You have a land mine collection?” No, but after storage unit #2, I’d daydream about starting one. reply Terr_ 15 hours agoparentI imagine it'd be a lot cheaper and legally-viable to store your collection of electronic burglar alarms. Especially if they dial a human when triggered. There are some neat videos out there where people make their own with Arduinos etc. reply mdaniel 2 hours agorootparent> There are some neat videos out there where people make their own The \"glitter bomb\" series is pretty funny: https://www.youtube.com/watch?v=xoxhDk-hwuo&list=PLgeXOVaJo_... reply userbinator 12 hours agorootparentprevMake them play sounds of approaching footsteps and gunfire. reply doubled112 6 hours agorootparentMerry Christmas, ya filthy animals. reply lazide 14 hours agorootparentprevHow about (accidentally) still charged high voltage capacitors? reply praptak 12 hours agorootparentWhere I live the \"accidental\" part doesn't really get you off the hook. Negligence is better than intention but still. If it kills someone or causes grievous bodily harm, it's still on you. Yes, even if it's a burglar. You also have to think about the fully legal situations when it's firefighter or a cop with a warrant. Or an edge case like a stupid kid. reply bigstrat2003 19 minutes agorootparent> If it kills someone or causes grievous bodily harm, it's still on you. Yes, even if it's a burglar. Honestly, the laws in your locale are unjust and need to be rewritten. There should be absolutely no liability to the owner (or renter) of a property if someone burglarizing it gets hurt accidentally. reply s1artibartfast 12 hours agorootparentprevWhere I grew up, problem thieves would just go missing, to be found years later dead at the bottom of a mine shaft. reply Karellen 1 hour agorootparentSo that's what happened to Captain Carnage! reply praptak 12 hours agorootparentprevWell this at least doesn't kill a random person who has to empty your storage for legit reasons and sets off a land mine. reply kstrauser 12 hours agorootparentprevI’m not saying I condone it… …but I understand. reply metadat 13 hours agorootparentprevDo they typically stay charged for only a few days at most? reply kstrauser 13 hours agorootparentWell, you might need to stop by frequently to visit them. reply pavel_lishin 4 hours agoparentprevIt's a fun fantasy. Work a few more elements into it: - you're hit by a bus, and your family is clearing out the storage locker. - management is alerted to a bad smell coming out of several units, and they have to enter yours to verify that you're not accidentally storing dead raccoons. - the police are serving a warrant on a unit, and accidentally open yours due to a typo. - a homeless teenager just needs a place to sleep for the night. reply kstrauser 3 hours agorootparentI’m not sure you grok the concept of “fun fantasy”. reply Analemma_ 15 hours agoparentprevBooby-trapping your property is illegal even in the reddest of red states. reply kstrauser 15 hours agorootparentThat would be one of the million reasons why I wouldn’t do it. I didn’t say I’d actually do it. I’d surely daydream of it. reply senectus1 15 hours agorootparentprevid put a bank of ultra bright white LED lights facing the door and a speaker with a recording saying this footage has been sent to a remote location. thank you for closing the door behind you. reply bko 3 hours agoprevThe indifference of this by everyone involved is infuriating. This criminal activity is treated as natural as rain, just something us 98% of people have to endure. It's important to remember that accepting crime, especially low level crime like this is a policy choice. It's the same people doing the same crimes over and over. They have run ins with the law and they just get let go to continue terrorizing the rest of us. For instance, the number of state prisoners that have had 15 or more prior arrests is over 26%. You can cut crime. You can just prosecute these people and take them out of society for their most destructive years (18-40) and we can end this madness. Even a 15 strikes and you're out policy would make a huge impact on the quality of life for the rest of us https://mleverything.substack.com/p/acceptance-of-crime-is-a... reply PaulDavisThe1st 2 hours agoparentThe US already incarcerates vastly more people than most comparable nations. And yet this level of incarceration does not seem to have had the effect you want. It seems that you imagine that the crime is somehow intrinsic to the current group of people committing it, and that by removing them from society, their behavior would not recur. While there are arguments for this sort of thing, it is also based on a wilfull misreading (or no-reading) of what we know about the reasons why people commit crime at all. reply bko 2 hours agorootparentExplain to me why someone that's been arrested 15 times should be let go to terrorize others. That person that has been arrest 15 times before cannot continue to commit crime if he's behind bars. You don't need to \"read\" the data to come to this conclusion. People commit crime in large part because they can get away with it. It's not complicated. reply PaulDavisThe1st 2 hours agorootparentThat's not really the issue though (and for the record, I agree that a person found guilty of what they were arrested for 15 times should be incarcerated). The problem is: why is this person doing this, because there are at least two outcomes: 1. we lock them up, and a part of the problem is gone 2. we lock them up, and someone else steps in to do the same thing From my perspective, there's ample evidence to suggest that #2 is more likely, and thus even if locking them up has some moral weight behind it, it isn't likely to be a solution to crime in general. reply bko 2 hours agorootparentThere's only so many people that are criminally predisposed. The org doing bike thefts will stop if the penalty is high enough. Singapore has low crime because they prosecute aggressively. No one seemed to fill in for arrested gang members in El Salvador (extreme example) Then there are the crazy person punching an Asian lady on the subway crimes and these fall squarely in 1 reply maxbond 2 hours agorootparentYou've blinded yourself by othering them. \"There's only so many people criminally predisposed\" - that may be comforting, but it's too naive to build a policy around. 100% of people would commit crimes under the right circumstances. As an extreme example, 100% of us could sustain a life changing head injury that renders us more violent and aggressive than we were before, and that could happen at any moment. The most kind and timid person you know could turn into a monster if they fell down the stairs. You could turn into a monster if you fell down the stairs. The only thing you can do to stop that from happening is to protect your head, it doesn't matter how good or virtuous you are presently. You can't incarcerate your way out of crime. An eye for an eye makes the whole world blind. reply snozolli 55 minutes agorootparent100% of us could sustain a life changing head injury that renders us more violent and aggressive than we were before, and that could happen at any moment Then I should be imprisoned if I present a threat to the public. I don't understand what your point is. reply maxbond 47 minutes agorootparentIf you think that there is a distinct group of people who commit all the crimes (as was suggested), and we can solve the problem of crime by locking all of them up, than you are mistaken. Or rather, that group is \"everyone.\" It's an easy trap to fall into for two reasons. It would appear that you and those you know aren't capable of being criminals. This is more comforting than it is true. Everyone, including good people, has the potential to do something horrible; the problem of evil isn't that it's present in a certain group who we can imprison, the problem is that it's present in us all. The second thing which makes \"lock them all up\" a seductive proposal is that it's cynical. Cynicism can feel like the opposite of naivete, so it can feel like you're being clear eyed and realistic about the situation and that the people you disagree with (say, prison abolitionists) are naive bleeding hearts. But cynicism is actually just another form of naivete. It's making the same error - blinking while staring into the abyss - with different aesthetics. reply dimensi0nal 16 minutes agorootparent> Everyone has the potential to do something horrible; the problem of evil isn't that it's present in a certain group who we can imprison, the problem is that it's present in us all. But some people are actually more predisposed towards criminality than others. We aren't blank slates. _dain_ 2 hours agorootparentprev>and for the record, I agree that a person found guilty of what they were arrested for 15 times should be incarcerated but you know damned well that most of the time it doesn't even go to trial. they're arrested, released, arrested, released, charges pressed, charges dropped; an endless merry-go-round. eventually people stop even reporting crime, why should they bother when the criminals don't get put away? >From my perspective, there's ample evidence to suggest that #2 is more likely why? this is like the \"lump of labour\" fallacy but for crime. and yes, getting rid of just a few career criminals does disproportionately reduce crime. here's a funny natural experiment from ireland: https://www.independent.ie/irish-news/crime/number-of-burgla... reply snozolli 58 minutes agorootparentprevwe lock them up, and someone else steps in to do the same thing Crime isn't an internship program. reply immibis 2 hours agorootparentprevYou don't have to commit a crime to be arrested. You just have to do something the police don't like - like holding up certain signs in a public space. reply bko 2 hours agorootparentRead the study > 73% of the prior offenses are violent and 80% are property related (obviously non-exclusive) reply smeeger 2 hours agorootparentprevamerican style incarceration breeds criminals. it isnt a form of punishment for the vast majority of people who end up in prison or jail. its details like these that bleeding heart people gloss over. reply _dain_ 2 hours agorootparentprev>The US already incarcerates vastly more people than most comparable nations because it has vastly more crime than comparable nations. you have to look at what happens to crime in the US over time, when you are more or less stringent about jailing criminals; predictably as you fill the jails, crime goes down, and when you empty them, crimes goes up. >It seems that you imagine that the crime is somehow intrinsic to the current group of people committing it, and that by removing them from society, their behavior would not recur. people try to smuggle this false premise into discussions about law and order all the time. the primary purpose of jail is not rehabilitation, it is to protect the public from criminals. you put them in jail so that they can't commit crimes. if they commit crimes when they leave, put them in jail again. jails mostly don't rehabilitate criminals, but that's a failure of the idea of mass rehabilitation, not a failure of mass incarceration. crime is a choice. reply PaulDavisThe1st 1 hour agorootparentwe incarcerate at a higher rate per capita, not just in absolute numbers. based on your apparent view of things, that ought to result in less crime per capita, but it does not. > more or less stringent about jailing criminals is quite different than \"fill the jails, empty the jails\" Quite a bit of research on the effect of deterrence on crime seems to strongly suggest that it is the level of certainty of being caught and punished that has a deterrent effect, not the severity of the sentence. This would correlate with \"more or less stringent about jailing criminals\". > the primary purpose of jail is not rehabilitation, it is to protect the public from criminals This is a statement of belief, and there are people who believe otherwise. I don't have a strong position either way, but I don't like people asserting that their opinions are self-obvious truths about the world. reply dimensi0nal 55 minutes agorootparentThe comment you replied to is talking about incapacitation, not deterrence. reply tightbookkeeper 1 hour agoparentprevOne of the costs of low trust society is it forces everyone to think short term. You can’t save if your money will be inflated. You can’t collect if it will be stolen and no party will take responsibility for protecting it. “But lay up for yourselves treasures in heaven, where neither moth nor rust doth corrupt, and where thieves do not break through nor steal” reply araes 1 hour agoprevSo many of these stories sound like some JRPG. Your reward for being such a diligent and highly achieving collector ... is the thieves target you preferentially. \"You gained a Torture++ Level, Congratulations!\" You spent so much effort solving the last burglary, and chose such a highly secure location ... that now the thieves view your collection as a high level challenge. ... and are immediately notified of the available achievement. Some Prison Warden voice announces \"There's a griefer, diligence punishing achievement available in Borg sector # of #.\" Their thief tools immediately 0-Day, exploit, jackpot, lottery level up to be better than your facility. reply immibis 2 hours agoprevEasy to say \"never use a storage unit\" when you have a long-term home. reply fortran77 4 hours agoprevIt’s outrageous that pawn shops don’t have to eat the loss in California. They have no incentive to check for stolen items. reply SoftTalker 2 hours agoparentAgree. Around here bike theft is a huge problem and none of the pawn shops will deal with bicycles at all, it’s too risky for them. reply User23 14 hours agoprevHaving to pay the fence to get your stuff back is so California. In the more civilized states pawnbrokers are expected to know the risks of buying potentially stolen property, and if they do they get to eat it. Maybe that's why property crimes short of grand theft aren't really enforced in California? reply __turbobrew__ 4 hours agoparentThat is the most surprising part to me. If the pawnbroker doesn’t bear the risks of buying stolen goods they are not disincentivized from buying stolen goods, which creates a larger market for selling stolen goods which in the end increases the market for property crime. reply coolspot 13 hours agoparentprev> property crimes short of grand theft aren't really enforced in California There is a hope we will undo this soon. reply willyt 12 hours agoparentprevYeah I was surprised about that one ‘Handling stolen goods’ is a criminal offence in Britain and if you can prove ownership of something you get it back. If you’re an innocent intermediary and you bought a stolen item without knowing you have to make a civil claim against the person you bought the item from to get the money back. reply meowster 3 hours agorootparentSame here. I believe in most U.S. states, knowlingly possessing stolen property is a crime. If you didn't know, you just have to forfiet it to the lawful owner. reply AndrewKemendo 1 hour agoprevThe key takeaway I think people are overlooking is that there’s a level of intelligence and persistence in thieves that make physical security an intractable problem with exponential cost scaling as you patch “holes.” So from a systems approach, the better solution likely is something like: Employ and provide safety for the people stealing from the units so they do not feel compelled to steal. Imagine if the money spent securing these things, which is a multiple of this persons efforts, were spent on solving the root cause? Sounds like a better return on investment reply tightbookkeeper 1 hour agoparentYou’re partly conceding that this level of corrupting and mistrust is just what we have to live with. It has not always been this way though. Side note. If I also accept it this is why cryptocurrency being able to reduce the cost of securing a transaction is still interesting to me. When you use a bank you don’t see the army of night guards, vaults, auditors, and IT people keeping it safe. reply kevinventullo 33 minutes agorootparentOn the other hand, I hear a lot more about crypto wallets getting hacked than I do checking accounts at large banks. reply tightbookkeeper 27 minutes agorootparentI’m just saying that aspect has appeal, not that you should bank with bitcoin. Of course, you don’t hear about internal bank problems either. reply mschuster91 1 hour agoparentprev> Imagine if the money spent securing these things, which is a multiple of this persons efforts, were spent on solving the root cause? Sounds like a better return on investment The root cause is social inequality of various kinds (including drug dependency). That should be something for society to resolve, not a burden for storage unit or home owners on their own - short of automated guns, there's not much any individual can do to keep out thieves. reply andrewstuart 13 hours agoprevAt this stage I'd probably thank thieves for clearing out my garage. Last time I cleared out my old stuff there was nothing I could do to get people to take most of the crap at zero cost. reply 486sx33 1 hour agoprevNothing gets broken into in Texas, when everyone has a gun, no one fucks around in the dark. Just sayin’ reply malshe 1 minute agoparentYou hope you simply forgot to add \"/s\" at the end reply fragmede 20 minutes agoparentprevI can see how you want to feel thats true, but the stats don't seem to say that's true. There's plenty of car theft and burglaries happening in the state, page 37 and 38. https://www.dps.texas.gov/sites/default/files/documents/crim... reply Simulacra 16 hours agoprevThis is heartbreaking. The storage facility insurance scam is one that needs to be investigated by the government. It's a tremendous rip off and covers nothing. reply asveikau 13 hours agoparentMost insurance in most industries is a racket. reply floydnoel 9 hours agorootparentThe famous Lloyds of London started as a gambling coffee house. Gambling and insurance are closely related, and offer the same bargain: the house always wins. reply cromulent 57 minutes agorootparent> the house always wins Well, until Lloyd’s did lose a lot of money in 1991, and the Names had too much exposure. Berkshire Hathaway cover them now, I believe. reply komali2 14 hours agoparentprevI wonder if an insurance company operated as a co-op would be a better arrangement. Interested parties pooling money to pay out to the one unfortunate one who has a disaster. Could potentially invest the pool in super low risk investments as well for a little upside. reply lotsofpulp 12 hours agorootparentMutual insurance companies have been a thing for hundreds of years. Some well known US mutual insurance companies are State Farm, Amica, Mutual of Omaha, and most non Elevance Blue Cross Blue Shield affiliated insurance companies. https://en.wikipedia.org/wiki/Mutual_insurance reply renewiltord 12 hours agoprevIf thieves had emptied my storage unit before I married my wife and she made the decision for me, they would have been doing me a favour. I don’t think any advanced security storage solution is likely to get many clients since they usually choose based on pricing. reply Magi604 15 hours agoprevGood old insurance companies, always looking for ways to get out of having to pay out for claims. I mean, I guess it is their job, so can't really fault them for that. reply tgsovlerkhgsel 12 hours agoparentNo, their job is to accurately calculate the expected value of the losses, then collect a premium slightly higher than the expected value, turning an unpredictable, potentially high loss into a predictable small one. Reverse gambling, basically. 1. Know your insurance contract, know what's actually covered and what not (sometimes describing the same facts in two different yet truthful ways will result in your claim being accepted or denied) and have a non-shit insurance company (check reviews that talk about how they handle claims or ask friends that had claims). 2. \"Self-insure\" risks where the variance won't hurt you. In other words, if you can grudgingly eat the loss if it happened, don't get insurance and eat the loss if it happens. If you have a lot of disposable income, you don't need insurance for something that won't noticeably shift your budget. Likewise, pick high deductibles. What would you rather do: Eat a $300 loss, or have paid $200 in additional premiums and spend two hours of filling out their paperwork? 3a. An exception is if you just really want the peace of mind, are willing to pay for that, and think you can find an insurance company that will actually pay. 3b. Another exception is if you think they miscalculated the premiums. I know that this is unlikely, but it ties into the \"peace of mind\" criteria - if you think a risk is more likely than it actually is, just insuring it might be an easy way out. The premium might also be accurate for the average, but you might also think or know that you are at a significantly higher risk than average. For the latter two points, I like to consider insurance cost \"per decade\" or \"per lifetime\". reply spencerflem 12 hours agorootparentBut they can offer a lower price than competitors or collect more profits (to taste) by having a lower expected value of losses by screwing you over reply thaumasiotes 11 hours agorootparentprev> No, their job is to accurately calculate the expected value of the losses, then collect a premium slightly higher than the expected value, turning an unpredictable, potentially high loss into a predictable small one. Reverse gambling, basically. No, premiums don't need to cover payouts. You have to pay the premiums before you get any payouts, so the company invests them and makes money that way. reply gruez 9 hours agorootparentThat's still basically the same thing if you take into account the opportunity cost of the premiums rather than the raw dollar value. reply hansvm 4 hours agorootparentOff-topic, I find people have a similar misunderstanding of FAANG compensation. Functionally, the salary + RSU + bonus + refresh structure is equivalent to a larger salary (enough to cover fees for the following procedure) where you take out 4-yr loans every year to invest in the company stock. With that in mind, listing the realized stock growth when describing total compensation always felt a bit disingenuous. reply pkteison 2 hours agorootparentNobody will give you an unsecured loan for 100 percent of your salary, but tech companies will happily grant you rsus for that much. reply js8 12 hours agoparentprevIt's not their job. It would be easy to adopt laws requiring insurance companies to separate insurance pool money (used to pay out insurance) and operational money (used to pay employees and profits), and have these separated when showing the price of insurance. That would reduce the moral hazard of insurance companies paying profit out of the pool. reply s1artibartfast 12 hours agorootparentIt can actually make it worse, and creates different Hazards. When it does work is when insurance has no influence on the price of goods, and is a minor consumer. For example, when fire insurance pays to replace your goods that burnt up. When it doesnt work is when insurance is the predominant purchaser of those goods. A good example would be US health insurance, which has an 80/20 rule just like your proposal. Health insurers by law (ACA) must pay out 80%, with 20% allowed for opex and shareholder returns. The Hazard is that as an industry, to increase returns, you want the cost of care as high as possible, thereby maximizing your allowable profit. It is a similar problem to how power is regulated in California, which has a mandated profit cap as a percent of costs. As a result, these regulated companies have the highest opex and cost of power in the nation of approximately $0.50/kwh reply js8 11 hours agorootparentWhat you're talking about is a market failure, basically admitting that markets don't decrease prices in many cases. Which is a much deeper rabbit hole. My proposal even doesn't say what the ratio should be. If there wasn't legally defined maximal price margin (say 20%), I don't see what it would change in your argument - the companies would be free to ask for even more. Conversely, there is nothing that prevents the companies from lowering the margin as a result of competitive pressure from consumers. reply Spivak 14 hours agoparentprevI've always wondered how expensive a good insurance policy is. One that is actually good for you the policy holder and enforced by contract. Like no haggling over market value because the items are insured for specific amounts. reply genewitch 13 hours agorootparenthomeowner's insurance approaches this if you know your agent (as in you've physically seen them) and the two of you have an understanding that you're going to be recording the purchase price (or market price, whichever is lower), date of purchase, serial numbers, and any other identification of all objects you want insured. If you do this, my understanding is that they cannot then do \"replace toaster: $8; replace TV, Onn brand 42inch $170;\" and so on. If your item's market price goes up in the meantime, the policy will have verbiage as to how that gets resolved. For example if i have a policy on something that is no longer being made, i can either be reimbursed for the price or a suitable replacement. Generic, cookie-cutter, boilerplate policies probably net the insurance companies a fair amount of profit. People who actually care about the actual items they are insuring are possibly the highest risk, and as such, the premiums are also the highest. In my state, an umbrella policy that would cover my home, land, frontage, vehicles, farm equipment, well pump, etc is ~$500/month, with limits of around $1mm (this was 8 years ago or so, they probably went up in premiums). a half million on two vehicles is only about $200/month and homeowners varies but is ~ The international code of insurances says goods cannot be insured for more than their worth. The intent was to avoid perverse incentives Would you mind explaining what the perverse incentive is here? If I want to insure a pillow that I claim is worth $1 million, why should it matter what others are willing to pay for it? reply praptak 12 hours agorootparentIf they let me insure my stuff for 100x of what it's worth, I lose all the incentive to prevent damage. Even in the legit cases the insurance companies have to account for the \"don't worry, it's insured\" mindset. Keeping the ceiling on the insurance value is intended to leave at least some of the incentive to prevent the damage with the owner. The insurance companies cannot rely solely on the \"don't be careless\" contract clause. reply dataflow 12 hours agorootparent> If they let me insure my stuff for 100x of what it's worth, I lose all the incentive to prevent damage. So what, though? Can't they just adjust the premium to account for that? It's not like they can't do their own modeling of what the item is likely worth -- if they see it's 1% of what you stated, then they can just as well cite you a ridiculous premium so that you wouldn't feel it's worth it. What's wrong with that? reply 2 hours agorootparentnext [2 more] [deleted] dataflow 2 hours agorootparentI don't think the logic follows. > For example, if I had a 15 year-old, unremarkable used car but insured it for $1m, then I'd have an incentive to leave it parked (but locked!) in sketchy areas of town in the hopes that it would be stolen. No, you wouldn't if the premium is high enough (i.e. your net gain from doing so is small enough). reply praptak 11 hours agorootparentprevIn theory nothing, in practice it's just not worth it. Mind that the bad effects would also spread broader than a voluntary contract between two parties. We'd have to fund the courts to resolve the inevitable insurance fraud accusations, not to mention the additional firefighting crews to put out the additional fires that consume the $1 pillows. reply rocqua 12 hours agorootparentprevThe difference between gambling and insurance, is whether you have an insurable interest. It makes the market for insurance much better if everyone actually has insurance. Because it reduces cost. It also keeps the industry legitimate, preventing gambling legislation from applying, and anti-gambling activists from targeting insurers. You'll have to go to a bookie if you want to gamble. reply dataflow 12 hours agorootparentI don't follow the logic? How does above-market-value insurance discourage people from having insurance? I don't get the comparison to gambling either, that reads more like an appeal to emotion than actual reasoning. reply rocqua 2 hours agorootparentBecause premiums will rise across the board, so people with an insurable interest pay premiums set for people who intend to gamble or manipulate their insurance. By demanding an insurable interest, insurance companies keep out gamblers and frauds. It also helps strengthen the idea that insurance shouldn't be abused or manipulated for a payout. reply dataflow 2 hours agorootparent> Because premiums will rise across the board I don't see why this is true. The insurer still knows the item and its market value. So if the insured amount is higher than the market value then it only needs to increase the premium in those cases, not for everyone else. reply rocqua 2 hours agorootparentprevAs for gambling. The point isn't gambling is evil, but that others think gambling is evil, so being associated with gambling is bad for business. reply dataflow 7 minutes agorootparentIf it's bad for business then don't do it? That doesn't justify an international code. schoen 12 hours agorootparentprevYou can read about it at https://en.wikipedia.org/wiki/Insurable_interest (I don't know if that will make you more sympathetic to the legal rule or not.) reply dataflow 12 hours agorootparentYou're definitely right -- it's interesting, but it's not making me any more sympathetic, because I fail to see why the lack of insurable interest is something the premium can't account for, and they fail to provide any explanation of that. As far as insurance gambling goes, it feels fundamentally different? In gambling, the \"house\" that sells you the ticket sets the rules and introduces the element of chance. In insurance, the entity selling the financial product here is in no way in control of the outcome, which is the exact opposite of gambling. reply js8 12 hours agorootparentprevThe incentive would be for you to have a \"happy pillow accident\" in which you get $1M. Of course, you might think that's good for you but the rules have to apply for everybody, by definition. reply dataflow 12 hours agorootparent> The incentive would be for you to have a \"happy pillow accident\" in which you get $1M. Of course, you might think that's good for you but the rules have to apply for everybody, by definition. This doesn't pass the smell test, though. The premium would take care of that. You've told them you have a pillow, and that you want it insured for $1M. They could easily look at it and go \"hm, this is worth $10\", and give you a absurd premium of $999,900 in exchange for your absurd valuation. So happy accidents won't be worth it anymore. What's wrong with just letting the premium take care of it? reply js8 11 hours agorootparentYou have simply rephrased the actuarial rule \"don't insure item for more than its actual value\". The \"premium\" you describe just inflated the value of the item. reply dataflow 3 hours agorootparentI don't see how this answers my question. reply smallnamespace 12 hours agorootparentprev> What's wrong with just letting the premium take care of it? Offering a deal that nobody honest would take is a waste of time for everyone involved. reply hansvm 1 hour agorootparentWalking back from the pillow analogy a bit, I'd happily pay for homeowner's insurance that also covered lost wages, a temporary rental place, legal fees, and the other incidentals likely to arise in a fire or flood (as opposed to paying whatever high deductible I'm comfortable with on top of those other large, unknown costs). Adding those to the policy would necessarily go beyond the home value. Is that level of excess allowed? reply dataflow 12 hours agorootparentprev> Offering a deal that nobody honest would take is a waste of time for everyone involved. I'm not suggesting any insurer should be forced to offer a deal. They're welcome to just shrug and tell you to pound sand. What I don't see is the logic behind having an international code prohibiting the offering of such deals. Is the international code trying to dictate to the insurance company what is worth their time? reply smallnamespace 3 hours agorootparentThe international code is also defining the key distinguishing factor of insurance: it makes the insured whole against a risk that they actually have. There are ways to bet on things where you don’t have that underlying risk: gambling, derivatives markets, prediction markets, etc. These aren’t insurance and aren’t regulated as such. reply rocqua 12 hours agorootparentprevThe premium would be 1M. Maybe .99M if they have reason to assume not everyone will be fraudulent. reply dataflow 12 hours agorootparentSure, whatever. The exact value of the premium has no bearing on the point I'm trying to make. reply smallnamespace 12 hours agorootparentprev> why should it matter what others are willing to pay for it? Because the actual value of the item determines your incentive to commit fraud. If you insure a $10 pillow for $10, when you damage your pillow, you personally will definitely be out $10's value in goods in the hope you'll recover that $10 later. Since your only outcome is mildly negative, you don't have any incentive to file a false claim. If you insure your $10 pillow for $1 million, as soon as the insurance is in hand, will have a strong incentive to destroy the pillow and try to collect a million dollars, since $1 million - $10 = $999,990. This incentive exists regardless of what premium you had paid for the insurance (since it was a prior cost), and can't really be perfectly mitigated. Yes, you can criminalize fraud, ask for evidence, etc. but courts aren't perfect and it's always possible to be clever and fool people. Also, some people are honest, and others are dishonest. An insurance company can't perfectly tell ahead of time who is who. Let's say I quote you $500k premium to insure your pillow for $1mm. A fraudster will see this as an opportunity to profit by $500k - $10. An honest person would see this as a terrible deal. Therefore only fraudsters would take this deal. If you continue to work backwards, as an insurance company you know there's no premium that you could quote that would end up in honest people taking this deal—there's no stable equilibrium where the premium charged ends up outweighing the (potentially fraudulent) claims. Btw, this situation is famously described in George Akerlof's paper The Market for Lemons (he called it \"market collapse\"): https://en.wikipedia.org/wiki/The_Market_for_Lemons#Conditio... Another way to see this: rationally as an insurance company, if you ask me for a policy for $1mm on a pillow, due to the risk of fraud I will likely be quoting you close to $1mm as the premium. You (as an honest person) rationally would never take this policy. Therefore, I shouldn't even bother offering it, to save everyone involved time and energy. reply zabzonk 12 hours agorootparentprevdepends on the premium, obviously reply dataflow 12 hours agorootparentWhat depends on the premium? In my mind, you state the item and the value, they tell you the premium they would cover it at. Where's the perverse incentive, and why is it relevant what anybody else would pay for it? reply listenallyall 12 hours agorootparentIf you intend to insure a pillow for $1 million, expect the premium to cost about $999,950. reply dataflow 12 hours agorootparentI wrote as much in https://news.ycombinator.com/item?id=41755211 reply listenallyall 10 hours agorootparentThen why did you object to zabzonk's comment? reply dataflow 10 hours agorootparentBecause I don't see what the perverse incentive is? reply zabzonk 9 hours agorootparentburning your house down? reply dataflow 3 hours agorootparentHave you seen the other threads? reply Spivak 4 hours agorootparentprevSurely there's some middle ground between the sibling thread where it's insured for 1000x and the situation I and many others find ourselves in with insurance dealings where the insurance company digs up some sale in a private database by a wholesaler in Szechuan, calls that the \"market price\" and then cuts you a check that doesn't even come close to replacing the item, usually a car. I would love a clause in the contract where for non-rare goods you have the option to have the insurance company make you whole by buying you a same model, same trim or higher, same miles or lower, same year or newer car. Like you claimed the market price was less then half of what I can buy it for, use whatever contacts you clearly have and buy it for that. reply 762236 16 hours agoprevSuggestion to authors: be pithy reply lostlogin 14 hours agoparentIt’s 3rd on HN right now, I’m not sure they need to change their approach much. reply mplewis 12 hours agoparentprevObservation: no one asked reply saulrh 15 hours agoprev [–] If you use the disc lock the storage facility sells, you'll likely pay an additional markup on it, but it's also guaranteed to be acceptable to their partner insurance company. I'm surprised - I'd have expected the facility's locks to be guaranteed to be unacceptable so as to minimize the insurance company's payouts. Insurance agencies already do worse on a daily basis, this level of consumer-hostile bullshit would barely even register. reply icehawk 13 hours agoparent [–] If they are deemed unacceptable, I now get to make the argument of negligence on the part of the storage facility, as they are the ones who sold it to me and I can reasonably assume that since they suggested it, and the insurance policy, that it is fit for purpose. I might then be able to make the case of fraud. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The repeated break-ins at storage units emphasize the vulnerability of storing valuable vintage computing items, particularly in climate-controlled units.- Insurance provided by storage facilities may be inadequate, with cumbersome claims processes requiring detailed documentation that may not be readily available.- Lessons learned include selecting secure storage facilities, using disc locks, and avoiding storing irreplaceable items, as well as the importance of improved security measures by the facility."
    ],
    "commentSummary": [
      "A break-in at a storage unit underscores significant issues in the storage industry, including inadequate security measures and poor customer service.- Faulty locks make many storage units easily accessible, and insurance often fails to cover losses sufficiently, raising concerns about the effectiveness of such policies.- The cost of storage can surpass the value of stored items unless they hold high sentimental or monetary worth, making long-term storage generally not cost-effective."
    ],
    "points": 197,
    "commentCount": 196,
    "retryCount": 0,
    "time": 1728176959
  },
  {
    "id": 41754074,
    "title": "We need a real GNU/Linux (not Android) smartphone ecosystem",
    "originLink": "https://old.reddit.com/r/linux/comments/1fx5fq0/we_need_a_real_gnulinux_not_android_smartphone/",
    "originBody": "whoa there, pardner! Your request has been blocked due to a network policy. Try logging in or creating an account here to get back to browsing. If you're running a script or application, please register or sign in with your developer credentials here. Additionally make sure your User-Agent is not empty and is something unique and descriptive and try again. if you're supplying an alternate User-Agent string, try changing back to default as that can sometimes result in a block. You can read Reddit's Terms of Service here. if you think that we've incorrectly blocked you or you would like to discuss easier ways to get the data you want, please file a ticket here. when contacting us, please include your ip address which is: 40.67.141.247 and reddit account",
    "commentLink": "https://news.ycombinator.com/item?id=41754074",
    "commentBody": "We need a real GNU/Linux (not Android) smartphone ecosystem (reddit.com)182 points by neelc 17 hours agohidepastfavorite190 comments alexey-salmin 13 hours agoAs much as we laugh at IBM and Intel nowadays and praise the success of ARM, the x86-based IBM PC ecosystem with standardized BIOS that maintains compatibility for decades is such a blessing, a huge breakthrough that we don't even notice anymore because we're so used to it. Before that the OS development was tightly coupled to hardware development. Booting an existing OS on a new device even with the same CPU required prior patching, configuration and re-implementation of the floppy drive driver. And it wasn't seen as odd because that's the way it was. I don't think the problem is a lack of OS enthusiasts, we probably have more of them than at the time Linux was born. The problem is they're fighting an uphill battle against a swarm of slightly different CPUs and device trees and uncooperative vendors that do anything they can to lock the device. reply pjmlp 13 hours agoparentA lucky accident that IBM failed to prevent, they didn't want to have such a market, Compaq made it possible, with a clever way to prevent it legally. reply AnthonyMouse 12 hours agoparentprevThe devices ship with a kernel that can use them. Is there anything we can do to make it easier to extract whatever device tree or other information from the compiled kernel it ships with, so it can be used with any other Linux kernel? reply zozbot234 11 hours agorootparentYou can use the downstream kernel directly via Droidian (a Mobian-derived GSI image). But otherwise the downstream kernels and device trees tend to be useless from an upstream development perspective - too hacked together and not maintainable in practice. Your proposed approach can be used however to extract existing firmware blobs (that will run unchanged no matter what the booting OS), and Mobian is pursuing that approach. reply transpute 12 hours agorootparentprevDevice tree is a file in /boot that can be decompiled. The missing artifact is open-source driver code. reply AnthonyMouse 12 hours agorootparentWhat stops someone from decompiling the closed source driver into barely legible \"source code\" and then grafting that onto a generic kernel so it can run on the device? It wouldn't be pretty but it would probably be a faster way to get running on the device than having to write a complete reverse-engineered driver from scratch before you can even boot, and then you have a starting point for writing an open source driver that doesn't suck as much. Could some change be made to the kernel to make that process easier? Do we need better tools to make it more practical? reply transpute 11 hours agorootparent> decompiling https://law.stackexchange.com/questions/101689/can-you-legal... If you look at a decompiled code and are influenced in how you write your code by the decompiled code, this is probably a \"derivative work\" of the original program and not just \"reverse engineering\" from the way that the computer program works. Copyright for software protects the decompiled code that is written, as a literary work, and anything derived from that decompiled code is also protected.. [clean-room reverse engineering] One group examines the source to write the specs and rundown. Another to make the code again, with no people from group 1 taking to them but for the spec sheet > do we need better tools to make it more practical? Good question, perhaps others can comment. The challenge is likely economics, not tooling. reply gomerspiles 11 hours agorootparentThis is GPL code so decompiling isn't necessary or the problem. Accepting over the wall low quality code and having a submitter for it who may know nothing about it makes it difficult to work any of this low quality code into the mainline kernel via its resource starved processes. reply atq2119 11 hours agorootparentprevIsn't that precisely what the GPL is for? Are all these vendors violating the license? reply transpute 11 hours agorootparentPossible, but sometimes vendor code isn't acceptable for upstream, even when public. Some vendors ship binaries with EULA restrictions to customers, who choose not to exercise their GPL rights. A modern approach to working around the GPL is to move functions from open drivers to closed firmware. reply mozball 9 hours agoparentprevIt is very puzzling. We have a plethora of brands from chinese, korean, european and american companies to kickstarter-funded projects to reskinned odm designs in developing markets,- all vying and clawing at each other to stand out in an oversaturated market with more cameras, more pixels, more features like AI, and filters and what-not. Yet not one of these companies think to release a phone that proffers to give the best rooting experience or Lineage OS compatibility - or better yet, comes with LineageOS out-of-the-box. reply raydev 2 hours agorootparent> Yet not one of these companies think to release a phone that proffers to give the best rooting experience or Lineage OS compatibility - or better yet, comes with LineageOS out-of-the-box. How profitable do you think this would be? reply lodovic 8 hours agorootparentprevI think one of the main reasons is that many apps such as banking or drm-protected apps, which are usually only offered through the official app stores, will refuse to work on a rooted or custom imaged phone. You'd have to go through youtube tutorials and have to download the software through third-party mirrors, and that's not a feature that will sell phones. reply fensgrim 3 hours agorootparentAnother reason is that giving users the option to root and unlock is possible only after ditching whatever agremeent is in place with Google. So, no Play support for this vendor at all means no sales to normal markets. Going deeper in conspiracy theories, Google would drop Qualcomm/Mediatek from the ecosystem if they'll ever allow a single SoC licensee to do such phone. reply ossyrial 8 hours agorootparentprevI believe Fairphone used to ship models with LineageOS out of the box—their new models optionally ship /e/OS, which I'm not familiair with but seems similar on the surface. reply matejdro 9 hours agorootparentprevI think OnePlus one comes the closest. It came with Cyanogen OS out of the box (a version of Cyanogen od, predecessor to the LineageOS) reply transpute 13 hours agoparentprev> uphill battle against a swarm of slightly different CPUs and device trees Economic incentives for \"differentiation\", e.g. device tree with upstream Linux and uboot support for feature A, but non-upstream uboot blob enables feature A+B. reply mikrotikker 10 hours agorootparentThe Samsung s5 had a noticeable difference in camera quality between stock and AOSP. reply xattt 11 hours agoparentprevOne issue between then and now is that there’s a hell of a lot more people now that are aware what transpired then and what steps to take to prevent or sabotage a burgeoning clone market. reply smegger001 7 hours agorootparentI wonder why google hasn't mandated some open standard like BIOS for all new arm based phones/tablet/smart-device that have the playstore and google services. I can't see it doing anything harmful to them and would make the whole ecosystem easier to develop for and may even make spread and make arm based laptops/desktop/servers more standardized which would be useful for data centers and such. it would probably help with the whole shitty driver situation on arm platforms. I honestly don't see a downside for anyone if everyone is having to do it which mandating it for android would essentially insure. reply Too 12 hours agoparentprevWith the vendor/system split introduced by project Treble in Android, it should be easier than ever to build your own system against a rich set of hardware abstractions, that work on a wide range of devices. Assuming you are ok with still running a very thick slice of the stack as proprietary vendor image. reply zozbot234 11 hours agorootparentYes you can run a GSI (and project Droidian does that) but then you're dependent on a downstream kernel and Android-ish early boot environment, that will likely lead to pointless incompatibilities compared to a fully-upstreamed approach. reply pjmlp 10 hours agorootparentUpstream doesn't care about clang and Rust as much as Google does, so that isn't ever going to happen as much as people vouch for it. reply zozbot234 10 hours agorootparentThe biggest hurdle to getting AOSP-kernel features into the upstream kernel is not clang or Rust, it's cleaning up hacked-together kernel code in a way that makes it long-term acceptable to upstream maintainers. (And getting rid of userspace blobs for things like graphics.) Always has been for as long as AOSP was a thing. reply dartos 12 hours agoparentprevIt’s even hard to find the uboot patches for clockworkpi hardware, and they open source almost everything. reply gmuslera 16 hours agoprevNokia had a chance for greatness around 2010 with Maemo and Meego. And either by stupidity or malice they ruined that. It was the right moment to have a chance, the smartphone game was still starting up, Nokia was still very influential in that arena, and the 2 devices it made (the N900 and N9) were great in their own way, for what was around that time. But between their own internal sectors still betting on Symbian, not being open enough and the mole that Microsoft introduced with Elop that opportunity was lost. From there on there was Sailfish (that never managed to get enough adoption), Ubuntu Touch and Firefox OS among others, but no big vendors backing. And the opportunity moment was already passed, as the de facto platforms for mobile development were iOS and Android, not even Microsoft was successful pushing their own platform there. All the killer apps are already released for those platforms, trying something new won't give the essentials to communicate with others and participate in society as of today. reply Tknl 16 hours agoparentN900 was my first smartphone and still miss the feeling of having a proper Linux box in my pocket. Unfortunately didn't buy the n9 as it was clear it was dead in the water by the time it came out. Based on my contacts at Nokia it was simply underfunding, believing that symbian would remain dominant in developing countries and seeing the meamo/meego line as a distracting and expensive side project as well as internal competition which people sought to sabotage internally. Some ex-Nokia people blogged quite extensively on it. reply MrMember 15 hours agoparentprevThe N900 was phenomenal for its time. One of the best smartphones ever made. If you just wanted to use it as a smartphone you could but if you wanted to dig deeper it was such a versatile and capable device. reply skykooler 12 hours agoparentprevI still use Sailfish OS, but it's becoming more frustrating with more and more things locked into proprietary apps (which are only available for android and ios) with no option to do things over a web interface. Just the other day I had to leave a laundromat because they only accepted payment via their mobile app. reply bad_user 13 hours agoparentprevNokia may have had an opportunity; however, you may not remember history, but the iPhone 1 was a game changer, and one thing that Android did right was to immediately adapt to the new form factor. Android won its place in the duopoly because it was and still is technically excellent, it adapted faster, and because it was immediately available to use by phone makers, borrowing many good lessons from Windows. The truth is, there was no more room left for a no. 3. The writing was on the wall for those able to see, Nokia's alternatives were out, much like Blackberry, regardless of what they did. I, too, was unhappy with Nokia's move to producing Windows Phones. But Microsoft, compared to other companies, knows how to build operating systems and create developer ecosystems around them. If Microsoft failed, IMO, Nokia did not stand a chance. reply senko 11 hours agorootparentNokia had a device on the market, the 770, before iPhone 1 release, and launched a successor, the 800 around the same time. However, for internal political reasons the devices didn’t have a GSM chip. The 800 was comparable to the iPhone: the touchscreen was much worse, but had a keyboard and could multitask. So, from the technical standpoint they could have adapted much faster. However, the Maemo team didn’t stand a chance against allpowerful Symbian internally. The team was tiny (50ish people on the software side if I recall correctly?), wasn’t given neither the resources nor the goahead to try and build the smartphone on the platform. It took years for the executive to realize Symbian’s not going to cut it and devote more resources to Maemo. Finally, with the launch of N900 Nokia two years later had a capable horse in the race. It promptly went to kneecap it by announcing, in the same announcement speech that introduced the N900, that the platform is obsolete and the new version will use a different platform (qt instead of gtk, rh instead of deb, etc etc). It was the worst ever act of self sabotage I have ever seen and to this day I don’t believe it wasn’t a malicious act by some executives, nobody could be that stupid. Anyways, Nokia proceeded to rewrite the entire platform, tied up with Intel in the process, and just wasted time until Elop told everyone to jump off. In 2007-2008 Nokia stood a fighting chance, but internal power struggles, short sightedness and politics killed it. (when I say Nokia I mean the smartphone division) reply mongol 10 hours agorootparentThe N800 was actually before the iPhone too, I know since I had it. This meant I wasn't as impressed by the IPhone as others, but I failed to appreciate the strength of the iPhone too. N800 had a resistive screen and a pen. It had a quite cumbersome interface and was more fragile. Also, it wasn't a phone. But I used it like I use my smartphone today. reply zozbot234 11 hours agorootparentprevThe LG Prada was the real game changer, the iPhone was just a knock-off. reply pjmlp 13 hours agorootparentprevAs ex-Nokia, it was a game changer in the US market where Symbian didn't had much luck in the market. Symbian development community wasn't that happy with Windows on Nokia phones, that is why most pivoted into Android and iOS. Nokia was mostly an anti-Microsot culture shop when I joined in 2004, we had HP-UX, Solaris, Red-Hat Linux and Symbian. Windows was only used as thin client. reply transpute 12 hours agorootparentprevAndroid was fortunate to recruit Matias Duarte with experience from Danger Sidekick and Palm WebOS. reply szundi 12 hours agorootparentprevOnly thing to add that it was funny how Blackberry didn't get for years that the browser is so important in the phones. Others missed that as well, everyone was doing the stupid half-browser thing. Of course they did as a normal browser needed a level up from their hardwares to be a PC leauge player. This would have maybe delayed the inevitable though for some years anyway, just sayin. reply transpute 12 hours agorootparentBlackberry did eventually get their act together, but it was too late. There was a Blackberry KEY2 phone based on Android, with a valiant effort to sandbox Android/Google with Blackberry security policy controls. That phone belongs in a museum of adversarial interoperability, alongside Godzilla/Kong memes. We need more devices with runtime competition between tech titans. Some is visible on iOS with Apple v. Facebook on ad targeting and contact databases. reply AnthonyMouse 12 hours agoparentprev> All the killer apps are already released for those platforms, trying something new won't give the essentials to communicate with others and participate in society as of today. I don't know about that. What's left are the things the existing platforms won't give you. Example: uBlock, but for apps. Runs the app in a container and blocks network requests to tracking servers, or otherwise modifies the app to remove misfeatures. Think: Game Genie for social media apps. The problem is you don't just need the killer app, you also need all of the existing apps, and hardware to run it on. So the real problem is you need your new system to be able to do that, but simultaneously be able to run common Android apps on common Android hardware. reply CalRobert 11 hours agorootparentI switched from Android to iphone a few months ago because I'm an idiot, and I was really disappointed to find there's apparently no way to set up an ssh tunnel in to my server so I can go to localhost:3000 and check out dagster from my iphone. 10+ years ago I had an HTC touch pro 2 with Lineage OS and I miss it dearly. Amazing hardware keyboard, linux in my pocket, no BS. And that phone originally ran Windows Mobile, funny enough. reply trenchgun 8 hours agorootparentYou can do it, just need third party app reply CalRobert 4 hours agorootparentSeems like it’s limited to ten minutes max in background by iOS reply rjzzleep 14 hours agoparentprev> Nokia had a chance for greatness around 2010 with Maemo and Meego. And either by stupidity or malice they ruined that. It was the right moment to have a chance, the smartphone game was still starting up, Nokia was still very influential in that arena, and the 2 devices it made (the N900 and N9) were great in their own way, for what was around that time. Meego, Maemo was really early experimentation IMHO. WebOS and Tizen were two worthy contenders, but both of them went to die in enterprise institutions that have no understanding how to create a product. HP absolutely smashed WebOS, and Samsung in its usual ultra hostile fashion destroyed any open source potential Tizen had. HP, Samsung, and Oracle is where Open Source goes to die. reply kamarg 12 hours agorootparentWebOS was absolutely amazing. The Palm Pre on the other hand felt like plastic trash. I was young enough when it came out that I was dependent on my parents to buy and pay for my phone still and I dragged my dad to a Sprint store at 5:00am to make sure we were first in line to get one so they didn't sell out. When we got there I figured I must have the wrong date because we were the entire line. I used that Pre until the plastic shell started falling apart and by then the writing was on the wall that it wasn't going to be the next big thing for phones and I regretfully bought my first Android phone with my own hard earned money. reply mlukaszek 13 hours agorootparentprevThere was also Bada OS, Samsung's attempt to cut the dependency on Android. I was actually running a device with 1.0, and it was surprisingly usable. The investment in building a development community was also there. They released lots of documentation and the SDK. Sadly, they followed with a 2.0 that really wanted to feel like Android (but wasn't). They obviously didn't want to put all their eggs into one basket and kept releasing Android phones in parallel. Eventually, Bada died a silent death, although some of it probably found its way to Tizen. reply transpute 13 hours agorootparentprevPalm/HP WebOS descendant lives as open-source based on OpenEmbedded, shipped on LG TVs. https://www.webosose.org/ reply pjmlp 12 hours agorootparentAnd much saner than using Android based TVs. reply 10xalphadev 10 hours agoparentprevWanna buy my N900? I don't miss using it. Especially its abysmal GPS, abysmal video recording, resistive touchscreen, terrible manual calendar sync setup, no choice of map software, etc. etc. Good riddance. That proper keyboard alone couldn't make up for everything else. reply nurettin 13 hours agoparentprevEven the N8 was comparable to the android I have today after 14 years. Full touch screen, great battery life, excellent camera quality, great maps, regular OS updates, ran all the software it had smoothly and could be programmed in C++ with Qt Creator. Then Microsoft came and ruined the N series by making nokia release some broken version of the OS (code named anna and then bella) so that people would buy Lumia. After a couple of months, there was no more application store. What terrible blunder that was. reply pjmlp 10 hours agorootparentNow imagine the Symbian community, with its anti Windows CE/Pocket PC bias, shortly after doing the whole set of transitions with Caride, Qt Creator, PIPS, being told that after all that transition work, they had to throw everything away and code for Windows Phone 7 with Silverlight and XNA in C#. Naturally most went elsewhere. reply kukkeliskuu 14 hours agoparentprevMy understanding as well that Nokia bet everything on Symbian. reply weinzierl 12 hours agoprevThe mobile ecosystem is basically the world Stallman and his comrades-in-arms wanted to prevent. It did't come to reality on the PC, but sneaked in through the backdoor with the advent of mobile devices. I have little hope that this can be undone, but we need to be prepared to nip these tendencies in the bud for the next paradigm shift. reply pjmlp 12 hours agoparentIt is coming, PC Clones only happened due to IBM not being able to legally prevent it taking off. It is no accident that the laptops as desktop replacement are just as vertically integrated, most people not using laptops have NUCs and game consoles, and custom built PC towers are seldom seen outside hardcore PC gamers. reply TZubiri 11 hours agoparentprevAnd that's one of the strongest criticisms of Stallman's Free Software. Instead of providing alternatives, they are just against them. Of course they tried to provide alternatives, but they are still stuck 30 years behind, they haven't gotten to phones yet. During Covid they had issues getting videoconferences to work. reply seba_dos1 7 hours agorootparent> they haven't gotten to phones yet Huh? I've been happily using several GNU/Linux phones as my daily drivers for the past 16 years. FSF also supported Replicant, which isn't something I'm personally interested in but it's there. reply globular-toast 11 hours agorootparentprevThey gave us a completely free version of Unix! What more do you want?! Do you even contribute to the FSF? reply pjmlp 10 hours agorootparentAT&T did that in first place, without the impediment to sell Bell Labs research and the Lions book, UNIX would never had been available for free to start with. reply TZubiri 5 hours agorootparentprevAnd they are still working on that. \"but they are still stuck 30\" What did I say? reply atoav 11 hours agoparentprevWorking with all major systems I have to say I don't have the feeling that the commercial OS is getting any better. If anything they are getting worse. What is getting better are the likes of KDE. Where a good decade ago running Linux still was a pain where it didn't work, nowadays it mostly just works, the System UIs are more usable, more customizable and in many cases better than any of the commercial OS for a while now (and yes, that includes MacOS). Android is a pain in the rear, IOS similarily so. reply pjmlp 10 hours agorootparentI just returned a NUC, because no matter what I tried, the UEFI bios and the collection of distributions I tried didn't come to terms. reply astrobe_ 11 hours agoparentprevFSF's position is restrictive in the sense that it limits the choices you have. On non-mobile, while a lot of people agree with FSF's point of view, in practice they have to make exceptions. (There's the urban legend that you're always breaking some law even when you try your best not to; probably you're also always running some opaque firmware blob even when you try your best not to). I don't see mobile users making any compromise like this, unless a gigantic scandal happens. reply weikju 15 hours agoprevIt’s happening (albeit slowly?) Librem 5 PinePhone and its Pro variant FuriLabs FLX1 Mobian UBPorts PostMarket OS And all the other distributions. Still what’s really lacking is some kind of critical mass that can’t be ignored. Many many services even in real life are locked behind an iOS/play store wall (even sometimes with no alternative outside needing a smartphone). We’re not completely locked in yet so there’s still time… reply linmob 11 hours agoparentThis. I try to collect all that happens weekly in the space at https://linmob.net reply binary132 14 hours agoprevSomething I think people in tech sometimes don’t realize is that the complexity of modern software generally requires a lot of money to be thrown at it to get meaningful amounts of stuff done, and that money is getting thrown at open source by the giants, who may have whole teams dedicated to advancing it. That means they’re the ones directing the R&D and advancing the state of the art, so your little indie/hobby/crowdfunded/grassroots thing isn’t going to be able to keep up, probably. Call me cynical, but that’s just what I seem to see right now. reply leidenfrost 13 hours agoparentThat's because you treat a FOSS project with a commercial mentality. Remember the first post Torvalds made for the kernel? He didn't say \"I'm doing a project to compete as fast as I can with commercial UNIX machine so please help\" He sid this: \"I'm doing a (free) operating system (just a hobby, won't be big and professional like gnu)\" And it became huge. By chance. A FOSS phone doesn't have to support Whatsapp. It should be open, fun to tinker with, modular and, maybe, with enough logic to handle carrier signal and SMS. Even if it's not successful, the code and schematics will still live somewhere on the Internet, ready for anyone to create a weird steampunk phone. Most people that want a Linux phone don't care about freedom of tech. They just want some portable Unix workstation with all the comfort of a commercial phone. Which it's not wrong by itself. But demanding Open Source to create another \"commercial-like but gratis\" it's already a bad attitude to start with reply fragmede 12 hours agorootparent> A FOSS phone doesn't have to support Whatsapp. What apps does it have to support, in your opinion? A computer in my pocket is useful for a lot of things, but central to its usefulness is communication. it can choose to not support all possible modes of communication, but it needs to at least support some of them, in order for there to be any adoption. reply palmfacehn 11 hours agorootparentA browser that provides PWAs if you are looking for a smart phone. An opensource app store alternative. That's how I imagine the bare minimum, but I'm not the biggest smart phone user. reply whytevuhuni 11 hours agorootparentprevMatrix. Then you can have a Raspberry Pi homeserver that bridges to Whatsapp and other things. reply WD-42 11 hours agorootparentprevI think you are missing the point. It will support whatever forms of communication the author wants it to. I know it’s hard to believe, but mass adoption isn’t the end goal of many FOSS projects. reply Dalewyn 11 hours agorootparentYou are commenting in a thread titled \"We need a real GNU/Linux (not Android) smartphone ecosystem\", mass adoption is the foremost goal. reply Dalewyn 11 hours agorootparentprevnext [5 more] [flagged] pjmlp 10 hours agorootparentWhich is also why VMs on macOS, Windows and ChromeOS are the closest mainstream users will ever get from Year of Desktop GNU/Linux. reply xk_id 9 hours agorootparentprev> You (and people like you) need to realize what makes Windows, Android, and iOS/MacOS successful: It's because they enable users to use computers as practical tools. What makes this cancer “successful” is the insane consumer exploitation that it enables, which motivates unfathomable amounts of money to be thrown at it to establish the monopolies. There’s no way out anymore and the entire society is suffering, except the venture capitalists who created this hell with cheap money due to decades of quantitative easing. Open your eyes at the tragedy around you instead of being so absorbed in your tech bro saviour complex. reply Dalewyn 9 hours agorootparent>What makes this cancer “successful” is the insane consumer exploitation that it enables >Open your eyes at the tragedy around you instead of being so absorbed in your tech bro saviour complex. I'll fire those words right back at you, particularly the bit about being a tech bro saviour. Computers are tools, tools that are practical will win mass adoption. FOSS as far as the zealots are concerned aren't even tools let alone practical, which is why they never win the mainstream audience. Do you know why the Steam Deck has been successful where everything else prior to it failed? Because it is a practical tool, specifically to play games. Most of the customers buying it don't care what it runs so long as it plays games. Concern yourself with making a better screwdriver, not whether the screwdriver is made from the finest libre materials. reply xk_id 9 hours agorootparent> tools that are practical will win mass adoption This is a very naive view. Deployed capital fabricates adoption and the current state of consumer tech is a great case study for this. Rational demand in consumer markets is a fantasy. reply Gigachad 13 hours agoparentprevI've given up on ever expecting an open source phone. Apple likely spends more money developing just the keyboard than these OSS companies have to spend on the entire phone, software and hardware. There is just no way they can release something that's even usable, let alone competitive. Did have an unexpected win in the form of the Steam Deck though. Never thought I'd have a powerful hand held, desktop linux gaming machine at an affordable price. Back in the day I was following the Dragonbox Pyra project and really liked the idea, but couldn't justify spending so much on a device that couldn't really do anything. reply binary132 4 hours agorootparentYeah, but Steam Deck is a perfect example of corporate funded semi-open-source winning. It could literally never have happened without spending millions of dollars on FTEs, not to mention getting the hardware side right. That’s EXACTLY what I’m talking about! Nobody who doesn’t have a giant stack of cash is going to come disrupt le heckin’ market with a great UNIX phone. reply jumping_frog 12 hours agoparentprevWhy can’t Facebook spearhead such a project? Zuck has always complained about closed ecosystems not allowing them to release cool features. Google forbids android OEMs from developing devices for other mobile stack. So we really have two hurdles. reply gorgoiler 13 hours agoprevAs an analogy: I use Sway but it doesn’t stop me from running GTK apps. I could use Gnome as my desktop software — a giant GTK app for running other GTK apps — but I don’t have to. Job scheduling, URL handling, settings daemons… we have standard tools for doing this as well on a Linux system. Somehow they remain only very loosely bound together and different bits can be omitted or swapped for alternatives. With Android / AOSP, are the components bound tightly together? I suppose the acid test would be: can I run Google maps APK on my Linux desktop as an app showing in a native window, or do I have to run an entire android emulator which has to take over a portion of my screen (and provide separate versions of all its own system services) to run one app? If a WINE-for-Android like thing exists, then I’d be very happy to run a standard Linux system on my phone and have it boot into an Android launcher that could run Android apps, but also be able to do anything else I wanted to do with a bare Linux system. Steamdeck from Valve does exactly this and it’s very good. The stock behaviour is to boot into their launcher (SteamOS) but if you sang you can toggle to a KDE desktop, get a shell in a terminal emulator, and hack away on what is just a regular PC. reply yjftsjthsd-h 13 hours agoparentI think you're looking for waydroid? AFAIK it does in fact have most of an android system bundled into it and it doesn't do rootless windows (Android apps are rendered into a single window that contains an entire Android UI), but it absolutely works. Funny enough, I use it on my laptop because Anki has dependency problems on my system but the F-Droid version is fine. reply Arnavion 12 hours agorootparent>it doesn't do rootless windows (Android apps are rendered into a single window that contains an entire Android UI) If you launch individual Android programs via `waydroid app intent ...`, they render as separate windows in the parent compositor. The single window for the entire Android UI is what you get if you run `waydroid show-full-ui`. reply seba_dos1 7 hours agorootparentIt's better to use the single window mode though. Splitting to separate windows is hacky and is never going to be 100% reliable unless completely reimplemented at a different layer. I'm using Waydroid on my phone sometimes, and frankly, single window mode is all you need anyway. reply yjftsjthsd-h 12 hours agorootparentprevOh! Thank you, I will have to try that. Here I just got it working and stopped reading docs... oops... reply Arnavion 7 hours agorootparentNote that the .desktop files that waydroid generates by default for each installed Android application already do that. reply weberer 1 hour agoprevWe do have one. I guess not many people even here know about it since it doesn't have a multi-million ad campaign around it. I've been messing around with a few distros on my Pinephone. The base Pinephone is much too weak to be used as a daily driver, but maybe the Pro is better. There are distros like Ubuntu Touch and Arch Linux Mobile. There are specific phone DEs like Phosh and (KDE) Plasma Mobile. Hardware compatibility is low, but you can at least check them out in a VM on your desktop. The best part is that you can run any software that works on ARM desktop Linux, so \"app\" compatibility isn't even a worry. Whether the software is usable in that form factor and resolution is another factor though. https://wiki.pine64.org/index.php?title=PinePhone_Software_R... reply seba_dos1 1 minute agoparent> The base Pinephone is much too weak to be used as a daily driver, but maybe the Pro is better. Both Librem 5 and PinePhone Pro are much faster than the original PinePhone, although PinePhone Pro is still relatively immature when it comes to software support. reply Almondsetat 13 hours agoprevNo we really don't. What we actually need is to do all over again what has been done for the last 30 years on computers: developing and reverse engineering open source versions of the various drivers for mobile devices' hardware. Without them you will be forced to pray for ABI compatibility at every update and you will never get to know your actual hardware reply pjmlp 11 hours agoprevNo we don't, because it would be UNIX command line and X11 on our phones, as proven by multiple attempts to GNU/Linux phones since OpenMoko. For all their flaws, iOS, Android, ChromeOS, and the gone Blackberry, Windows Phone, Symbian, actually rethought the whole programming stack, using modern programming languages, and UI/UX. reply fph 10 hours agoparentAnd security, don't forget that. Proper app isolation on Linux is still very tricky, with many competing approaches in Apparmor/Selinux/Snap/Flatpak/Docker, all complicated to set up and use. The consequence is that in practice a 2048 game has unlimited access to the files in my /home folder. On the other hand, Android has a very solid permission and isolation system. This is why I don't want GNU/Linux on my phone; I would rather have a proper FOSS Android. reply zozbot234 10 hours agorootparentThe Android approach is among the most \"complicated to set up and use\" (since it's based on SELinux under the hood) but the OEM does that for you. There's no reason why Linux distros couldn't do the same thing using Flatpak and/or bubblewrap. (Plus AppArmor for extra hardening where sensible.) reply kaba0 7 hours agorootparentJust the lack of.. the whole ecosystem adopting the restricted model and there being a properly specified and documented model in the first place. reply yarg 12 hours agoprevThe unforgivable part for me was Google prohibiting Android forks in their vendor licensing agreements for their add-on software. It was a deeply cynical way of doing an end-run around the GPL, and I've held them in utter contempt ever since. reply greyw 14 hours agoprevWe need real FOSS Android. I wish people would start building from there. reply NewJazz 13 hours agoparentThere's a lot of building going on. Waydroid builds their own highly specialized Android derivative. As does Replicant, Calyx, Graphene, /e/foundation, Lineage, microg, and probably lots more in the Foss space alone. reply yjftsjthsd-h 13 hours agoparentprevWhat do you want that LineageOS (plus F-Droid) doesn't do? reply criticalfault 11 hours agorootparentBanking apps come to mind. reply Eavolution 10 hours agorootparentThis is the only reason my phone's not running Lineage. I need those apps mainly for 2fa (some banks don't give me any alternative) or for one or two with no web app. It feels like a total artificial duopoly, you only get to use your essential service on android or ios. reply floydnoel 10 hours agorootparentprevwhat would a banking app do that a bank website can't, exactly? reply qingcharles 1 hour agorootparentIIRC some finance apps either don't have web sites that can perform financial transaction, or are lacking a number of features of the mobile app. Cash App and Venmo used to be some of the worst offenders, but have improved in recent times. reply krick 13 hours agoprevWe already had not one, but multiple. They lost to android. I imagine there were multiple reasons, really, but one of them seems pretty basic: simple SDKs. Even when there was no Android apps, making one was easier, than making... whatever. Now, when there are thousands (maybe millions? I have no idea) Android apps, I don't really see anything else catching on. To be fair, now there is this react-native approach, but still, all these permission frameworks, drivers, really necessary apps nobody will port and everybody needs... reply mozball 15 hours agoprevGoogle et al pour billions annually into making android a first-class and dominant mobile OS. I think the FOSS community should leverage that and focus on liberating Android instead of trying to reinvent the wheel. reply Fire-Dragon-DoL 15 hours agoparentIt's impossible because of hardware attestation. Until something is done for that (and \"legal\" seems the only way), there is no solution reply transpute 13 hours agorootparentAndroid Virtualization Framework with pKVM on Pixel 7+ can technically allow unmodified Linux VMs to run in parallel with \"official\" VMs that pass hardware attestation. This feature is not yet exposed to end-users. reply josephcsible 13 hours agorootparentThe point is that apps you need to run will only do so in the \"official\" VMs that pass hardware attestation and will intentionally fail in the unmodified Linux VMs. reply transpute 12 hours agorootparentIf a banking app or DRM-encumbered streaming app can run in the official attested VM, what would be the benefit of running such closed apps in unmodified Linux VMs? If banks and streaming vendors don't trust unmodified VMs, why would open-source Linux VMs trust closed apps with binary blobs? One benefit of running open-source Linux VMs is access to the vast corpus of mature open-source software applications packaged by Debian, Fedora, etc. reply josephcsible 12 hours agorootparent> what would be the benefit of running such closed apps in unmodified Linux VMs? That you wouldn't need the official attested VM anymore. > why would open-source Linux VMs trust closed apps with binary blobs? The point is that with an open-source Linux VM, the user could decide what to trust instead of some megacorp deciding for everyone. > vast corpus of mature open-source software applications The problem is that there's a lot of proprietary apps that are both (1) necessary for a lot of real-world things, e.g., the SeatGeek app for tickets to shows, and (2) not replaceable with FOSS because the company will ban you if you connect to their API with a third-party client. reply transpute 12 hours agorootparent> That you wouldn't need the official attested VM anymore. As hardware, sensor and cellular radio standards continue to evolve, someone has to pay for timely development of bare-metal software to drive new hardware. Today, that is the vendor providing the \"official attested VM\" and drivers. If Arm can reach x86 levels of backward compatibility and stable interfaces, it may be possible to extend the lifetime of mobile devices with OSS bare-metal drivers. It has taken many years to achieve this on relatively open x86 PCs. Even Arm SBCs still struggle, see the efforts of Armbian. Mobile devices are less open and more complex. > proprietary apps ... not replaceable with FOSS because the company will ban you if you connect to their API with a third-party client. Regulations and technology are evolving in the direction of more control, not less. Customers will need to find forms of collective and competitive action to influence vendor policy in sensible directions, because it will be increasingly expensive to bypass. Try to support vendors who use technology responsibly in service of their customers. Encourage OSS competition where feasible. reply rascul 11 hours agorootparentprevIs SeatGeek a great example? The web site seems to work fine on my phone. reply josephcsible 3 hours agorootparentFor one show I went to, I needed the app to be able to get in the door, because I had no option to print the tickets, have them mailed to me, or pick them up at will call, and the web site didn't let me see what they needed to scan. reply floydnoel 10 hours agorootparentprevmy bank websites work fine on my phone, too. i don’t run anyone's apps any longer as corpos just take the chance to add invasive data harvesting, location tracking, etc. reply josephcsible 3 hours agorootparent> my bank websites work fine on my phone, too. But don't they disable some features if you don't use the app, e.g., mobile check deposit? reply alwayslikethis 15 hours agoparentprevGoogle is clamping on that freedom by providing ways to detect when you run unauthorized/liberated software (i.e. root or custom ROM) reply mozball 14 hours agorootparentYour banking app is not going to work on Linux either. If Android is fundamentally broken then fork it. My point is, it seem smarter/easier to take Android and make it more linux-like than to take Linux and make it more Android-like. All the work is already done and paid for. Sailing with the wind vs sailing against the wind. edit : Unless the goal is also to benefit the linux desktop ecosystem (the whole convergence meme) reply CalRobert 13 hours agorootparentThis is why it's so worrying that browsers are getting the same treatment. Attestation/WEI will bring this to the desktop (and mobile browser for that matter) and you'll have to use Chrome or an approved Chrome reskin (every other browser, basically) for most things. reply NotPractical 12 hours agorootparent> you'll have to use Chrome That isn't sufficient. You'll also need to use an OS which provides \"acceptable\" hardware attestation capabilities (as defined by Google) required to verify that the copy of Chrome is legitimate (otherwise this could be spoofed). In practice that most likely means your options are limited to: Windows 11, macOS with System Integrity Protection enabled, Chrome OS, stock Android with Google services installed as system apps, iOS. Google's first attempt at bringing attestation to the web, WEI, was shot down by hackers, but it won't be the last. Please continue to fight against this. reply CalRobert 12 hours agorootparentHonest question - how? I run Linux, Firefox, etc. but I don't know what else I can do to help restore a healthy ecosystem. Run for office with the pirate party? reply alwayslikethis 5 hours agorootparentCrypto, piracy, and anything else you can do to protect yourself from the institutions that caused the these problems in the first place. The actual problem needs a societal/cultural solution though, not a technological one. reply metadat 14 hours agorootparentprev> Your banking app is not going to work on Linux either Why is that? I can use my bank through Linux via a web browser without issue. Logging in more frequently is a hassle but not a bad trade IMO. reply mozball 14 hours agorootparentThe native app won't work though. The problem alluded to by grandparent comment and in linked-article. reply walthamstow 11 hours agorootparentprevMy bank doesn't even have a web portal, it's app-only. This is remarkably common in the UK, birthplace of Monzo, Revolut and Starling. reply JetSpiegel 8 hours agorootparentThen change from the bank equivalent to MVNO into a real bank with a website. reply PhilipRoman 11 hours agorootparentprevPresumably this is about apps which are required for authentication, even in the browser version. reply zozbot234 11 hours agorootparentprev> If Android is fundamentally broken then fork it. My point is, it seem smarter/easier to take Android and make it more linux-like than to take Linux and make it more Android-like. That's what LineageOS (née CyanogenMod) tries to do, and what this leads to in practice is force them to depend on a heap of proprietary code (downstream kernels and userspace blobs). Outside of that, the work that's \"done\" on the AOSP/LineageOS UI layers and supporting software/\"apps\" is relatively easy to port over to Desktop Linux - the GNOME Mobile UX is actually making great progress from that POV. So I'm quite skeptical about your proposed approach. reply NotPractical 13 hours agorootparentprev> Your banking app is not going to work on Linux either. I think the idea is that no amount of forking Android is going to produce something different enough to entice developers to port their apps to it, but maybe if an entirely new Linux-based mobile platform kicks off, there's a chance? If you have to consult `developer.android.com` (a Google-owned domain) to develop for your \"totally not Android\" platform, it may be difficult to avoid the temptation to do as the documentation recommends and simply embrace proprietary Google services and hardware attestation and whatnot. After all, 99% of users have those things and it's just these several weird forks that don't? reply dtech 11 hours agorootparentI highly doubt devs are interested in developing apps for such a niche mobile OS outside of hacker circles. Windows Phone failed because even paying devs for apps couldn't entice them to do so. reply trickstra 12 hours agoprevWe already have it, but people aren't willing to use it. Using a real libre system will always be a little harder than using a nice and polished billionaire funded walled garden. For obvious reasons. People just aren't willing to sacrifice even a little bit of comfort for the freedom, so products like Librem or PinePhone get mostly just complaints, comparison with Apple, and current users are ridiculed as nerds or weirdos. We will never have freedom as long as this is the prevailing culture. It's up to us, the customers, the commenters. reply transpute 13 hours agoprevGoogle AVF/pKVM will allow unmodified Linux VMs on Pixel 7+. GrapheneOS has shipped early plumbing support, not yet exposed to users. reply ranguna 10 hours agoparentThat's exactly what I was going to mention. I'm waiting for android 15 to be released and for people to test hardware acceleration support. If the overheating problems are fixed, I'll get myself a pixel 9 XL (for the bigger battery) and use it as my laptop daily driver replacement. If performance is any good (fingers crossed for something close to the latest raspberry pi) then it's the perfect machine: usb C displayport, it fits in your pocket, can run proper Linux, fallback to Android for steam Link until valve releases an ARM version of steam. It'll be perfect. For actual laptop form factor usage, I'll connect the xreal glasses to get a big display and I'll use the pixel as a keyboard and trackpad, or an external keyboard and the pixel as a trackpad. Can't wait for people to test android 15. reply NewJazz 3 hours agorootparentThey reenabled display port output on the Pixel line? reply NewJazz 13 hours agoparentprevAll hail Big G in our Temple of Tensor. Amen. reply transpute 13 hours agorootparentIn comparison, Apple shipped a hypervisor 2 years ago, then removed it because users were running VMs. 2024 M4 iPads have silicon support for nested virtualization, but Apple prevents users from running VMs. At least Google has upstreamed pKVM to the Linux kernel. Since Pixel Tablet can run GrapheneOS, there's a path to running unmodified Linux VMs as open-source pKVM support matures. It's sad that customers have to settle, but non-zero Google table scraps > zero Apple VM slices. reply TZubiri 11 hours agoprevThe title and the fact that it's posted on reddit gives a real \"someone needs to do something, but it's not gonna be me.\" vibe. reply alwayslikethis 15 hours agoprevAs much as I like the concept, I'm not sure Linux phone is a good idea. Desktop Linux is not particularly prone to spyware scanning the filesystem and uploading it mainly because they mainly use free software from package repositories that are vetted by maintainers. If Linux phones are used like Android or iOS phones are used today (downloading random binaries, often to interact with real world things you can't opt out of, with distribution controlled by a corporation not too worried about your privacy), it would be a privacy nightmare. reply idle_zealot 13 hours agoparentIn my mind part of the \"Linux Phone\" package is moving primarily to a package repo software distribution solution. You can slap an App Store-esque frontend on it, but the software you're installing is (by default) from a curated list of supported open source packages, not random binaries from untrustworthy parties. Of course, this mentality is losing support even on desktop Linux with the move to Snaps/Flatpacks/AppImages/etc, which is a real shame. reply kaba0 11 hours agorootparentThe gnu/linux userspace has absolutely no security whatsoever. It’s a real shame how trivial it is to have even an npm install potentially do literally anything. Android has an actual, sane, rethought security model that has a good track record in protecting millions of non-tech-savvy people. reply zozbot234 11 hours agorootparentIf you run your npm install in a properly set up container (and at some point in the future, Flatpak will set this up for you), it isn't going to do much. Yes, I'm well aware that containers should still be tought of as \"not a real security boundary\" given the amount of remaining attack surface, but even then the Android approach is not very different. reply idle_zealot 8 hours agorootparentprevAndroid has a security model that protects the OS from applications and applications from users. A sane security model would put the user in control. reply alwayslikethis 7 hours agorootparentThat is true. A good way to remove the second part is to gain root. reply yjftsjthsd-h 12 hours agoparentprevWell... yeah, don't do that. I mean this seriously, not facetiously; when I say I want a Linux phone what I mean is I want a phone that runs Debian or whatever (on bare metal, with good quality of experience, and with a mainline kernel) and where I install software out of the official repos using apt (or whatever). (Also plenty of people on desktop Linux do `curlsh`, and some of us are getting most of our Android apps out of F-Droid; I'm not sure the distinction runs quite the way you're suggesting.) reply kaba0 11 hours agorootparentYou can have a pinephone, and it will work fine for like 2 hours, warming like hell, and having you wait for minutes for an app to open. That’s where the linux userspace is. Maybe we should take a look at android and simply re-use the multi-million dollars spent on actually making a working mobile OS? reply linmob 11 hours agorootparentWhile my experience with PinePhone has been significantly better (sounds like you may have had a faulty unit), we have working close-to-mainline ports for a few Qualcomm-powered phones (e.g., Xiaomi Poco F1, OnePlus 6(t), Google Pixel 3a, ...) in OSes like postmarketOS or Mobian. Turns out these work a lot better - having phones build with components for phones makes a significant difference. reply kaba0 6 hours agorootparentI didn’t mean to “shit” on the project, I did buy it as a means to both support it and to toy around with it - and yeah, the “free hardware” (which is arguably a bit naive and marketing-y goal) definitely doesn’t help create a device fit for everyday use, but I’m afraid the userspace is just not even ready to tackle the complexity, and I don’t see it happening anytime soon. Android has a proper security, IPC model, the whole userspace has a focus on battery-saving, apps are made in a way to be suspend-able, etc. “GNU/Linux” is living in the past where C-posix binary goes brr is considered safe and enough, and I just don’t think that’s the case. reply jwrallie 10 hours agoprevI’d like a portable device with good battery that would run free software, mostly for privacy reasons. Anything with a good battery could do, GNU/Linux would not be strictly necessary. Running TOR or a VPN over Wifi and a browser and fast enough to stream a YouTube video at 720p is all I need. I wonder what would be the closest hardware today that could do it. Smartphone or small tablet form factor would do just fine for me. reply zozbot234 10 hours agoparentGaming handheld would give you that. There are also old Intel-Atom based tablet PC's that are quite cheap on the second-hand market, and work well with Linux. Smartphone/palmtop form factor would be harder though. reply haolez 14 hours agoprevIn the opposite direction, would Android make a decent Linux desktop if it got a little more polish for this use case? What about it's code quality? Is it a mess or is it on par with GNOME + Wayland + whatever? reply fensgrim 3 hours agoparentLast decade's definition of \"power user\" is \"being able to type on physical keyboard and have more than 1 window open at a time\", and Android caters to that; it would not even remotely be decent, though it'll likely eat just a bit more battery and cpu than a pure XFCE running without compositing. reply silisili 14 hours agoparentprevThat's basically a Chromebook, which can run both Android apps and Linux apps. reply g-b-r 13 hours agoparentprevYeah, let's make desktops unusable toys as well reply kaba0 11 hours agorootparentIn what way is it “an unusable toy”? reply g-b-r 6 hours agorootparentHow can you see it any differently? You need an \"app\" for everything, they can hardly interact with each other, they can get killed at any time, and without rooting (which is subverting how the system is meant to be used) all sorts of things are crippled (from filesystem access, to using a firewall, to freaking setting a different volume for every app). And the limitations increase with every Android release reply kaba0 6 hours agorootparentThey have a proper, standard, high-level way of interacting with each other, literally the whole OS is built around than. Read up on android services, intents, etc. It is eons better than dbus-ing and writing to random files all over my home dir is that linux desktops do. Killing stuff from time to time is literally an advantage for a system - look at the battery life of a linux desktop or a pinephone. You have to make apps ready for a possible suspension, otherwise they just keep on draining the battery. Besides, services can be called from an active activity, or binded by one and then they will not be killed under normal circumstances. I don’t want a random app to read my browser caches/ssh keys, etc, but if you like any random repo you download having access to your personal files, you do you. reply fractallyte 12 hours agoprevWe already have it, and it's called Sailfish OS (https://sailfishos.org/ and https://en.wikipedia.org/wiki/Sailfish_OS) The paid version even comes with Android App Support - the 'killer feature' that allows a Sailfish device to run full Android apps in a sandbox (https://jolla.com/appsupport). Some people will inevitably moan that it's proprietary, but that's just the UI layer; the rest is wide open, familiar Linux. I can SSH into my device without any fancy workarounds, and it works almost identically to a desktop machine. (Besides, how else is a company meant to survive in the super-competitive mobile device market? The OS is cheap. Android App Support is awesome. Pay up and be grateful!) The UX is simple and consistent, WAY superior to iOS and Android. Most importantly, it has an ecosystem: the Jolla app store, a comprehensive SDK, and an alternative open source app repository (https://openrepos.net/). reply transpute 11 hours agoparent> Pay up and be grateful!) Website says it's only sold in EU. How is that verified? reply getwiththeprog 6 hours agorootparent\"We currently sell in European Union, UK, Norway and Switzerland. Please be welcome to use our software anywhere in the world, however due to our limited resources we can only support the noted regions.\" https://shop.jolla.com/ reply fph 10 hours agorootparentprevIt isn't. You can just use a VPN. reply rendaw 11 hours agoparentprevIt looks like it doesn't support android safetynet hardware attestation so banking apps etc won't work. reply Dwedit 14 hours agoprevKernel land is almost entirely Linux. Just without open-source drivers for some freakish reason. Userland is as different from desktop Linux as you can possibly get. reply pjmlp 10 hours agoparentNope, it is a custom Linux kernel with goodies that aren't available upstream like first level support for clang, several Rust modules (no need to argue with anti-Rust kernel folks), all security features turned on, and a micro-kernel like driver subsystem, supporting Java, C++ and Rust. reply kaba0 11 hours agoparentprev> Just without open-source drivers for some freakish reason Because manufacturers buy random parts from other suppliers, who may or may not own the source code, and they often legally simply can’t share forward that code. reply melodyogonna 9 hours agoprevI'm fine with Android. reply kkfx 12 hours agoprevWe need mandatory FLOSS and mandatory open-hardware with the obligation for all commercial products to be design and built openly from start to allow a community to form and switching marketing from mass advertisement to community flaws of interests. Essentially OEMs instead of being advertisement driven with brands like religions they should evolve toward being innovation-branded. That's would create a much better and knowledgeable world BUT it means having entrepreneurs in chief and managers and technicians aside ate the same level, \"high output managers\" do really dislike that. reply fensgrim 3 hours agoparentSo far, we can't even get Samsung to have their FOSS kernel stuff published in a buildable and usable form - its basically impossible to build their recent kernels with their recent toolchains without finding out that some obscure config option was skipped or that some file didn't survived the pre-release purge or that it requires some obscure Linux distribution to run on. And if you get it to build, chances that it will boot are slim. (Good luck finding out if there's a working UART somewhere on chip pins and it's not hidden behind hypervisor and fuses) reply kkfx 1 hour agorootparentI know, but IF we mandate openness from the start with a public development process this could not exists or the company does not respect the law, if we do not, we will never get much usable things, \"open source enterprise\" and \"open core\" are nowadays common ways to profit from FLOSS being not FLOSS at all while formally respecting the license. The problem to arrive at the laws is how many know enough to understand why we should and we must have such law, because if for most it's not even clear what is something you own vs something you can use via a proprietary remote service... Physical ownership is a clear concept for most, digital ownership for most is a mystery... That's the damn issue. reply bsder 12 hours agoprevThe problem with open mobile phones is neither the phone hardware or software. The main problem is the damn cellular network carriers. Until some government agency gets serious about forcing the cellular carriers to actually allow phones on their network without having to go through the anal violation that is \"certification\" for their network, the open mobile phone ecosystem will continue to suck. reply rangestransform 12 hours agoparentWhy would the government ever force carriers to accept uncertified devices? So they can emit interference on cellular frequency bands? So they can violate SAR limits and burn people? reply bsder 11 hours agorootparentThe devices would still be subject to FCC certification just like your WiFi chipsets are. Beyond that, the people developing chipsets generally have better tests for compliance than the carriers, themselves. You should be able to drop one of those chipsets in your phone, plug in a SIM, and get on with life. However, the carriers make you spend a couple of megabucks of bribes and then they will deign to allow your phone on their oh-so-fragile network. Effectively, the current cellular carriers are acting exactly like Bell System prior to the Hush-A-Phone lawsuit: https://en.wikipedia.org/wiki/Hush-A-Phone_Corp._v._United_S... reply kaba0 11 hours agoparentprevIt was the governments that require that certification, and for good reasons. We can play this “wild west hacker” whatever, but rules are a necessity for a working society, one can’t just start driving on the other side of the road, and neither would we be ahead with random frequencies getting emitted everywhere. reply zer0zzz 13 hours agoprevHow do you build such a thing when it doesn’t exist on PCs in the first place? In order to build an ecosystem you need cross compatible applications as well as some kind of strongly supported and strongly emphasized programming interface. reply ekianjo 13 hours agoprevThere is sailfish OS. And it runs quite a few Android apps too. reply transpute 13 hours agoparentAny recommendations for modern-ish devices which run Sailfish? Can the \"free trial\" be used indefinitely if you don't need Android app support? reply fph 10 hours agorootparentYes, the free version can be used indefinitely. The latest device you can use with full support is Sony Xperia 10 III, released in 2021. There have been no further releases; the project never really took off and unfortunately it seems that the OS is slowly dying. The Finnish company behind it, Jolla, had a joint project with Russia (Aurora OS), which I believe provided a good chunk of the funds via Rostelecom. With the war everything changed, and in 2021 they had to cut ties entirely with Russia for many reasons: embargos, and many people rightfully not wanting anything to do with \"a Russian OS\" on their phone. The company had to be \"restructured\" in 2023. reply quotemstr 12 hours agoprevNo, we need an alternative smartphone ecosystem like a hole in the head. Android won, and AOSP is free software. There is no reason to undertake the Herculean task of writing a new mobile userspace core. You might as well write a new kernel while you're at it. What would be the point? What are you going to do better than AOSP? A 5% more efficient binder? At Google HQ, there is a veritable mountain of skulls of Android competitor projects. Please notice the skulls before doing something that will almost certainly add your project to the pile. reply daviddever23box 17 hours agoprevIs this a parody post? reply snapplebobapple 16 hours agoparentNo, its something i strongly agree with. The phone ecosystem is a locked in disaster. If phone hardware was required to support some standard like x86 computers do we could turn all this apple amd android crap ibto something that actually respects privacy reply Demiurge 15 hours agorootparentEvery vendor that is not Apple already supports Android. Even the ones that don’t want to have the GSuit built in, and some of them care about privacy, while some don’t. A smartphone is comprised of more than one cpu, and there are proprietary chipsets with closed firmware all the way to battery. This is a much different world than x86 PC with pre EFI BIOS, when you could flash everything (except cpu?) What do you expect to be able to achieve with just the word “Linux” added to the mix? Can you build new 5G drivers for Linux as well? Smartphone market is moving pretty fast, the hardware is nearly disposable, and the consumer doesn’t even know what an OS is. GNU/Linux smartphone, that is competitive? Good luck with that. reply snapplebobapple 14 hours agorootparentThe firmware side of things is a different can of worms that also affects X86. That's not he ask I was making (although it is a good second phase). I just want phones to be more like X86 in that I can install whatever I want to them and have a more standardized interface than the current wild west situation so that it's easy to bring on new devices. It would be nice if the hardware vendors were not actively blocking installing my own operating system as well (in addition to the technical non standard issue). Why do you think I care about competitive or commercial viability? I just want the behemoth pushing apple and android crap to be forced to make their devices easier to boot an alternative and leave the rest to us to figure out and see what interesting things can be done. reply Demiurge 14 hours agorootparentIf you don’t care about competitive smartphones, why do you care about smartphones or phones at all? reply snapplebobapple 13 hours agorootparentIt's not about making a competitive linux smartphone, it's about making the hardware ecosystem more conducive to software competition by making it easy for people to run their own software on their own hardware. reply heavyset_go 12 hours agorootparentprevIt's a solved problem for ARM platforms with standards like SBSA. Thankfully, a few ARM notebooks implement ACPI, UEFI and whatnot that makes standardizing boot images easy instead of requiring bespoke images for every model. reply snapplebobapple 5 hours agorootparentThen i guess all that is really needed is legislation to force manufacturers to stop being a bunch of dickheads locking down the devices they sell? reply Brian_K_White 16 hours agoparentprevIs this a parody question? reply NewJazz 13 hours agoprev [–] We don't need a non-android ecosystem. The compatibility is nice. The security features are nice. What we need is more devices that allow unlocking the bootloader and rewriting the keys. reply bpye 13 hours agoparent [–] Sadly that isn’t really enough today - since many applications will refuse to function if SafetyNet fails because you have some non-standard image running. reply fensgrim 3 hours agorootparentThere's likely a statement in Play Services ToS for vendors to do all things possible to prevent bootloader unlock/relock flow from happening - reasoning from the fact that yellow AVB state is non-existent outside Pixel devices. Maybe it goes as far as for SoC vendors, as well. So far, outside of Huawei, no top tier hardware vendor ever decided that denying Play functionality to their users would be profitable - also all Mediatek based devices are basically licensed by mediatek afair, so there's no chance of, say, Vivo/Realme suddenly deciding to ditch Play and do bootloader relocking. Also the possibility of postmarket devices running non-bloated OS is a loss for a vendor since it both reduces the appeal of whatever next \"+1% cpu +1% battery\" lineup update (and its a bad idea to sell 200k \"good device model 1\" rather than 100k \"bad device model 1\" and \"bad device model 2\", because PR/stocks/whatever) and increases the possibility of having users dissatisfied with the brand name because battery/flash degradation is still a thing. reply NewJazz 13 hours agorootparentprev [–] That's not a problem and not getting fixed by diverging farther than android. To date none of my apps have required that, including my banking app. Even so, loss of some financial apps is a small price compared to loss of social and dating apps, public transit and health apps, and more. iNaturalist publishes an open source android app to complement their very functional website, and honestly I would give up all of GNU for that one app. reply Eavolution 10 hours agorootparentMaybe this is less of a thing outside the UK but the banking apps absolutely is a problem for me. I have banks that only have apps, no websites, or require the app for 3ds that will refuse to open with safetynet failing. It's not even just safetynet, at least one of them has it's own seperate tests to stop it working. This is the only reason for me (and presumably a fair few others) not to be using Lineage, I can do without google wallet etc but I can't do without access to my own bank accounts reply NewJazz 3 hours agorootparentThat sucks but yeah that is not my experience in the US. Not sure what 3ds is, some kind of identity or MFA service? All of my banks have functional websites. reply ThePowerOfFuet 4 hours agorootparentprevThen vote with your wallet and switch to a bank that isn't so hostile to its paying customers. Banks are fungible. reply NotPractical 12 hours agorootparentprev\"I personally haven't been affected by this, so it's not a problem\" is not a compelling argument. reply NewJazz 3 hours agorootparent\"I personally haven't been affected despite using the capabilities of the system extensively, so its not a dealbreaker\" isn't? reply yjftsjthsd-h 12 hours agorootparentprev [–] If you only care about Android app compatibility but not safety net, try waydroid? reply NewJazz 3 hours agorootparent [–] Waydroid was really slow last time I tried it, and most apps I tried did not work well or at all. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The current smartphone ecosystem is fragmented, with various CPUs and uncooperative vendors, unlike the standardized BIOS of x86-based IBM PCs that ensured compatibility.- Efforts like Droidian and Mobian aim to create a true GNU/Linux smartphone ecosystem, but face challenges due to the dominance of iOS and Android and lack of support for alternatives like Sailfish and Ubuntu Touch.- The debate persists on whether to develop a new ecosystem or enhance Android's openness to balance innovation, compatibility, and user freedom in the smartphone market."
    ],
    "points": 182,
    "commentCount": 190,
    "retryCount": 0,
    "time": 1728178108
  },
  {
    "id": 41757722,
    "title": "The Book of Kells, now digitized and available online",
    "originLink": "https://www.openculture.com/2024/09/the-medieval-masterpiece-the-book-of-kells-is-now-digitized-and-available-online.html",
    "originBody": "Online Courses Audio Books Movies Podcasts K-12 eBooks Languages Donate The Medieval Masterpiece, the Book of Kells, Is Now Digitized and Available Online in Art, Books, HistorySeptember 25th, 2024 4 Comments If you know noth­ing else about medieval Euro­pean illu­mi­nat­ed man­u­scripts, you sure­ly know the Book of Kells. “One of Ireland’s great­est cul­tur­al trea­sures” com­ments Medievalists.net, “it is set apart from oth­er man­u­scripts of the same peri­od by the qual­i­ty of its art­work and the sheer num­ber of illus­tra­tions that run through­out the 680 pages of the book.” The work not only attracts schol­ars, but almost a mil­lion vis­i­tors to Dublin every year. “You sim­ply can’t trav­el to the cap­i­tal of Ire­land,” writes Book Riot’s Eri­ka Har­litz-Kern, “with­out the Book of Kells being men­tioned. And right­ful­ly so.” The ancient mas­ter­piece is a stun­ning exam­ple of Hiber­no-Sax­on style, thought to have been com­posed on the Scot­tish island of Iona in 806, then trans­ferred to the monastery of Kells in Coun­ty Meath after a Viking raid (a sto­ry told in the mar­velous ani­mat­ed film The Secret of Kells). Con­sist­ing main­ly of copies of the four gospels, as well as index­es called “canon tables,” the man­u­script is believed to have been made pri­mar­i­ly for dis­play, not read­ing aloud, which is why “the images are elab­o­rate and detailed while the text is care­less­ly copied with entire words miss­ing or long pas­sages being repeat­ed.” Its exquis­ite illu­mi­na­tions mark it as a cer­e­mo­ni­al object, and its “intri­ca­cies,” argue Trin­i­ty Col­lege Dublin pro­fes­sors Rachel Moss and Fáinche Ryan, “lead the mind along path­ways of the imag­i­na­tion…. You haven’t been to Ire­land unless you’ve seen the Book of Kells.” This may be so, but thank­ful­ly, in our dig­i­tal age, you need not go to Dublin to see this fab­u­lous his­tor­i­cal arti­fact, or a dig­i­ti­za­tion of it at least, entire­ly view­able at the online col­lec­tions of the Trin­i­ty Col­lege Library. (When you click on the pre­vi­ous link, make sure you scroll down the page.) The pages, orig­i­nal­ly cap­tured in 1990, “have recent­ly been res­canned,” Trin­i­ty Col­lege Library writes, using state-of-the-art imag­ing tech­nol­o­gy. These new dig­i­tal images offer the most accu­rate high-res­o­lu­tion images to date, pro­vid­ing an expe­ri­ence sec­ond only to view­ing the book in per­son.” What makes the Book of Kells so spe­cial, repro­duced “in such var­ied places as Irish nation­al coinage and tat­toos?” asks Pro­fes­sors Moss and Ryan. “There is no one answer to these ques­tions.” In their free online course on the man­u­script, these two schol­ars of art his­to­ry and the­ol­o­gy, respec­tive­ly, do not attempt to “pro­vide defin­i­tive answers to the many ques­tions that sur­round it.” Instead, they illu­mi­nate its his­to­ry and many mean­ings to dif­fer­ent com­mu­ni­ties of peo­ple, includ­ing, of course, the peo­ple of Ire­land. “For Irish peo­ple,” they explain in the course trail­er above, “it rep­re­sents a sense of pride, a tan­gi­ble link to a pos­i­tive time in Ireland’s past, reflect­ed through its unique art.” But while the Book of Kells is still a mod­ern “sym­bol of Irish­ness,” it was made with mate­ri­als and tech­niques that fell out of use sev­er­al hun­dred years ago, and that were once spread far and wide across Europe, the Mid­dle East, and North Africa. In the video above, Trin­i­ty Col­lege Library con­ser­va­tor John Gillis shows us how the man­u­script was made using meth­ods that date back to the “devel­op­ment of the codex, or the book form.” This includes the use of parch­ment, in this case calf skin, a mate­r­i­al that remem­bers the anatom­i­cal fea­tures of the ani­mals from which it came, with mark­ings where tails, spines, and legs used to be. The Book of Kells has weath­ered the cen­turies fair­ly well, thanks to care­ful preser­va­tion, but it’s also had per­haps five rebind­ings in its life­time. “In its orig­i­nal form,” notes Har­litz-Kern, the man­u­script “was both thick­er and larg­er. Thir­ty folios of the orig­i­nal man­u­script have been lost through the cen­turies and the edges of the exist­ing man­u­script were severe­ly trimmed dur­ing a rebind­ing in the nine­teenth cen­tu­ry.” It remains, nonethe­less, one of the most impres­sive arti­facts to come from the age of the illu­mi­nat­ed man­u­script, “described by some,” says Moss and Ryan, “as the most famous man­u­script in the world.” Find out why by see­ing it (vir­tu­al­ly) for your­self and learn­ing about it from the experts above. For any­one inter­est­ed in get­ting a copy of The Book of Kells in a nice print for­mat, see The Book of Kells: Repro­duc­tions from the man­u­script in Trin­i­ty Col­lege, Dublin. Relat­ed Con­tent: Take a Free Online Course on the Great Medieval Man­u­script, the Book of Kells Dis­cov­er the Medieval Illu­mi­nat­ed Man­u­script Les Très Rich­es Heures du Duc de Berry, “the World’s Most Beau­ti­ful Cal­en­dar” (1416) Behold the Beau­ti­ful Pages from a Medieval Monk’s Sketch­book: A Win­dow Into How Illu­mi­nat­ed Man­u­scripts Were Made (1494) 800 Illu­mi­nat­ed Medieval Man­u­scripts Are Now Online: Browse & Down­load Them Cour­tesy of the British Library and Bib­lio­thèque Nationale de France Killer Rab­bits in Medieval Man­u­scripts: Why So Many Draw­ings in the Mar­gins Depict Bun­nies Going Bad Josh Jones is a writer and musi­cian based in Durham, NC. Fol­low him at @jdmagness by OCPermalinkComments (4)Sup­port Open Cul­ture We’re hop­ing to rely on our loy­al read­ers rather than errat­ic ads. To sup­port Open Cul­ture’s edu­ca­tion­al mis­sion, please con­sid­er mak­ing a dona­tion. We accept Pay­Pal, Ven­mo (@openculture), Patre­on and Cryp­to! Please find all options here. We thank you! Comments (4) You can skip to the end and leave a response. Pinging is currently not allowed. Laura Young says: September 26, 2024 at 1:52 pm Won­der­ful infor­ma­tion about the Book of Kelly’s! I love the rich col­or. Fas­ci­nat­ing sto­ry about how books were made so long ago. Reply R. Delat says: September 26, 2024 at 5:05 pm Thanks for this infor­ma­tive arti­cle! When I was young, I was in Dublin, but did­n’t get to see the Book of Kells. Now that I can’t trav­el, I very much appre­ci­ate this great, col­or­ful, pre­sen­ta­tion. Thanks to all who put this project togeth­er. Reply Behrouz ashtari says: September 27, 2024 at 1:05 am Hi I am from iran I have 3 vol­umes of old hand­writ­ten books about tra­di­tion­al Iran­ian med­i­cine, and I would like to sell them, are you will­ing? My what­sapp is 00989123595074, . Please advise, and please reply me on What­sApp Reply Bethany Chance says: September 28, 2024 at 8:31 am So if I’m under­stand­ing this cor­rect­ly, they had been pre­vi­ous­ly avail­able online, because I thought I had seen them. And this ver­sion has been res­canned at high­er qual­i­ty. Is that cor­rect? Thank you for this infor­ma­tion. I’m an artist with a fas­ci­na­tion for Illu­mi­na­tion, and use it fre­quent­ly in my paint­ings. Reply Leave a Reply Name (required) Email (required) Message Essentials 1,700 Free Online Courses 200 Online Certificate Programs 100+ Online Degree & Mini-Degree Programs 1,150 Free Movies 1,000 Free Audio Books 150+ Best Podcasts 800 Free eBooks 200 Free Textbooks 300 Free Language Lessons 150 Free Business Courses Free K-12 Education Get Our Daily Email Support Us We're hoping to rely on loyal readers, rather than erratic ads. Please click the Donate button and support Open Culture. You can use Paypal, Venmo, Patreon, even Crypto! We thank you! Free Courses Art & Art History Astronomy Biology Business Chemistry Classics/Ancient World Computer Science Data Science Economics Engineering Environment History Literature Math Philosophy Physics Political Science Psychology Religion Writing & Journalism All 1700 Free Courses Receive our Daily Email FREE UPDATES! GET OUR DAILY EMAIL Get the best cultural and educational resources on the web curated for you in a daily email. We never spam. Unsubscribe at any time. Click Here to sign up for our newsletter FOLLOW ON SOCIAL MEDIA Free Movies 1150 Free Movies Online Free Film Noir Silent Films Documentaries Martial Arts/Kung Fu Animations Free Hitchcock Films Free Charlie Chaplin Free John Wayne Movies Free Tarkovsky Films Free Dziga Vertov Free Oscar Winners Free Language Lessons Arabic Chinese English French German Italian Russian Spanish All Languages Free eBooks 700 Free eBooks Free Philosophy eBooks The Harvard Classics Philip K. Dick Stories Neil Gaiman Stories David Foster Wallace Stories & Essays Hemingway Stories Great Gatsby & Other Fitzgerald Novels HP Lovecraft Edgar Allan Poe Free Alice Munro Stories Jennifer Egan Stories George Saunders Stories Hunter S. Thompson Essays Joan Didion Essays Gabriel Garcia Marquez Stories David Sedaris Stories Stephen King Chomsky Golden Age Comics Free Books by UC Press Life Changing Books Free Audio Books 700 Free Audio Books Free Audio Books: Fiction Free Audio Books: Poetry Free Audio Books: Non-Fiction Free Textbooks 200 Free Textbooks Free Physics Textbooks Free Computer Science Textbooks Free Math Textbooks K-12 Resources Free Books Free Video Lessons Web Resources by Subject Free Language Lessons Quality YouTube Channels Teacher Resources Test Prep All Free Kids Resources Free Art & Images All Art Images & Books The Met The Getty The Rijksmuseum Smithsonian The Guggenheim The Tate The National Gallery The Whitney LA County Museum Stanford University British Library Google Art Project French Revolution Getty Images Guggenheim Art Books Met Art Books Getty Art Books New York Public Library Maps Museum of New Zealand Street Art Smarthistory Rembrandt Van Gogh Coloring Books Free Music All Bach Organ Works All of Bach 80,000 Classical Music Scores Free Classical Music Live Classical Music 9,000 Grateful Dead Concerts Alan Lomax Blues & Folk Archive Writing Tips Hemingway Fitzgerald Stephen King Ray Bradbury William Zinsser Kurt Vonnegut Toni Morrison Edgar Allan Poe Margaret Atwood David Ogilvy Steinbeck Billy Wilder Archive All posts by date Personal Finance Open Personal Finance Categories Amazon Kindle Animation Apple Architecture Archives Art Artificial Intelligence Astronomy Audio Books Biology Books Business Chemistry Coloring Books Comedy Comics/Cartoons Computer Science Creativity Current Affairs Dance Data Deals Design e-books Economics Education English Language Entrepreneurship Environment Fashion Film Finance Food & Drink Games Gender Google Graduation Speech Harvard Health History How to Learn for Free Internet Archive iPad iPhone Jazz K-12 Language Language Lessons Law Letters Libraries Life Literature Magazines Maps Math Media MIT MOOCs Most Popular Museums Music Nature Neuroscience Online Courses Opera Philosophy Photography Physics Podcasts Poetry Politics Pretty Much Pop Productivity Psychology Radio Random Religion Sci Fi Science Software Sports Stanford Technology TED Talks Television Theatre Travel Twitter UC Berkeley Uncategorized Video - Arts & Culture Video - Politics/Society Video - Science Video Games Web/Tech Wikipedia Writing Yale YouTube Great Lectures Michel Foucault Sun Ra at UC Berkeley Richard Feynman Joseph Campbell Carl Sagan Margaret Atwood Jorge Luis Borges Leonard Bernstein Richard Dawkins Buckminster Fuller Walter Kaufmann on Existentialism Jacques Lacan Roland Barthes Nobel Lectures by Writers Toni Morrison Bertrand Russell Oxford Philosophy Lectures Sign up for Newsletter First Name * Last Name Email * Please type in the letters in the image to prove you are not a robot. If you cannot read them, click on the image to generate a new one. About Us Open Culture scours the web for the best educational media. We find the free courses and audio books you need, the language lessons & educational videos you want, and plenty of enlightenment in between. Advertise With Us Great Recordings T.S. Eliot Reads Waste Land Sylvia Plath - Ariel Joyce Reads Ulysses Joyce - Finnegans Wake Patti Smith Reads Virginia Woolf Albert Einstein Charles Bukowski Bill Murray Hemingway Fitzgerald Reads Shakespeare William Faulkner Flannery O'Connor Tolkien - The Hobbit Allen Ginsberg - Howl W.B Yeats Ezra Pound Dylan Thomas Anne Sexton John Cheever David Foster Wallace Book Lists By Neil deGrasse Tyson Ernest Hemingway F. Scott Fitzgerald Allen Ginsberg Patti Smith Brian Eno Henry Miller Christopher Hitchens Joseph Brodsky W.H. Auden Donald Barthelme Carl Sagan David Bowie Samuel Beckett Art Garfunkel Marilyn Monroe Jorge Luis Borges Picks by Female Creatives Syllabi WH Auden David Foster Wallace Donald Barthelme Allen Ginsberg Zadie Smith & Gary Shteyngart Spike Lee Lynda Barry Junot Diaz Favorite Movies Kubrick Kurosawa's 100 Tarantino Scorsese Tarkovsky David Lynch Werner Herzog Woody Allen Wes Anderson Luis Buñuel Roger Ebert Susan Sontag Scorsese Foreign Films Philosophy Films Archives October 2024 September 2024 August 2024 July 2024 June 2024 May 2024 April 2024 March 2024 February 2024 January 2024 December 2023 November 2023 October 2023 September 2023 August 2023 July 2023 June 2023 May 2023 April 2023 March 2023 February 2023 January 2023 December 2022 November 2022 October 2022 September 2022 August 2022 July 2022 June 2022 May 2022 April 2022 March 2022 February 2022 January 2022 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 March 2021 February 2021 January 2021 December 2020 November 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 February 2020 January 2020 December 2019 November 2019 October 2019 September 2019 August 2019 July 2019 June 2019 May 2019 April 2019 March 2019 February 2019 January 2019 December 2018 November 2018 October 2018 September 2018 August 2018 July 2018 June 2018 May 2018 April 2018 March 2018 February 2018 January 2018 December 2017 November 2017 October 2017 September 2017 August 2017 July 2017 June 2017 May 2017 April 2017 March 2017 February 2017 January 2017 December 2016 November 2016 October 2016 September 2016 August 2016 July 2016 June 2016 May 2016 April 2016 March 2016 February 2016 January 2016 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 June 2015 May 2015 April 2015 March 2015 February 2015 January 2015 December 2014 November 2014 October 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 December 2012 November 2012 October 2012 September 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 December 2011 November 2011 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 April 2011 March 2011 February 2011 January 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 December 2009 November 2009 October 2009 September 2009 August 2009 July 2009 June 2009 May 2009 April 2009 March 2009 February 2009 January 2009 December 2008 November 2008 October 2008 September 2008 August 2008 July 2008 June 2008 May 2008 April 2008 March 2008 February 2008 January 2008 December 2007 November 2007 October 2007 September 2007 August 2007 July 2007 June 2007 May 2007 April 2007 March 2007 February 2007 January 2007 December 2006 November 2006 October 2006 September 2006 Search ©2006-2024 Open Culture, LLC. All rights reserved. Home About Us Advertise with Us Copyright Policy Privacy Policy Terms of Use Bio Audio Books Online Courses MOOCs Movies Languages Textbooks eBooks Open Culture was founded by Dan Colman.",
    "commentLink": "https://news.ycombinator.com/item?id=41757722",
    "commentBody": "The Book of Kells, now digitized and available online (openculture.com)148 points by ColinWright 3 hours agohidepastfavorite33 comments CalRobert 3 hours agoThe book of Kells is gorgeous and well worth a visit. If you are in Dublin and enjoy this sort of thing, _please_ also take the very short walk over to the Chester Beatty Library (https://chesterbeatty.ie/) as well. It's free and has an absolutely fantastic collection of ancient and sacred manuscripts. I was lucky enough to live across the street from it for several years and it remains one of my favourite museums in the world. reply grujicd 2 hours agoparentChester Beatty is a gem. I went into it not expecting much from \"museum of books\". But it's also in a way a museum of world's religions, which are tightly connected to writing and books. As an atheist who has low opinion on value of religion because of all the deaths they were and still are responsible for, it reminded me of their positive role in history. When you see all those ancient religious books you begin to question whether we would have writing at all without them? Who would go through a painstaking process of duplicating books before Gutenberg if not men devoting their lives to God? Thus carrying light of civilization and creating basis and tools for science to progress later. I know this is not some great revelation, but I felt enlightened a bit after leaving Chester Beatty. reply TRiG_Ireland 36 minutes agoparentprevThe Chester Beatty Library has a much larger collection than is shown at any one time. Many sacred texts, but also much else, including some printed news-sheets from the French Revolution. And a lot of Chinese and Japanese stuff, including some gorgeous jade snuffboxes. reply VagabundoP 1 hour agoparentprevThey have some gorgeous Asian exhibits as well from what I remember. reply brendoelfrendo 2 hours agoparentprevAgreed! We went last year and thoroughly enjoyed it. I understand that the Long Room in the Old Library is mostly empty for renovations, but the Book has been moved to a dedicated building during this time. Pro-tip to any potential visitors: they turn the pages every so often, and I have heard some travel bloggers complain that the pages on display when they went weren't very interesting, but the university will show you what pages of the book of Kells are currently on display: https://www.visittrinity.ie/book-of-kells-pages-on-display/ At the moment, it appears that they have it open to a pair of canon tables which have some really lovely illuminations. reply s_dev 3 hours agoprevThe animated film 'The Secret of Kells' is great and well worth a watch. Far more accessible/relatable to modern audiences than this historical Bible that was dug up in a field in Kells. I'm glad it got a mention but the other guy is right -- the link should have been to the digitized book. reply bdz 1 hour agoparentContrary to everyone I think it was pretty mediocre. The significance of the book is barely covered and the contents of it are not mentioned at all. The story itself is dancing around the “message of the book” and how it prevails over everything (see the allegory with the abbey’s wall) but somehow they just never say it’s the four Gospels of the New Testament which are the most important texts of Christianity. If you don’t know what the Book of Kells _really is_ then what’s left from the film itself? Not so much just a generic fantasy story. reply CalRobert 3 hours agoparentprevThat studio is amazingly good. The Breadwinner is harrowing but fantastic. reply lemming 1 hour agorootparentThe others in the Irish mythology series are really great too - Song of the Sea is my favourite. Great to watch with kids, but also can be enjoyed with no embarrassment by adults! reply patrickdavey 1 hour agoprevI went to college in Trinity and the Book of Kells is housed in the old library. Once you've finished seeing the book, you head upstairs through the Long Room, and that place is just special (they used it as the hall of the jedi) As a student there you could visit for free. I used to just go up and hang in the library for 10 mins or so a few times a year. Loved it. https://en.m.wikipedia.org/wiki/Library_of_Trinity_College_D... Edit: fix link reply TRiG_Ireland 39 minutes agoparentI once had a class in a room just off the old library. I had to go into the Long Room and step over a rope at the end. Very cool. reply CosmicShadow 2 hours agoprevI saw the real life Book of Kells earlier this year and it was so pristine and high quality it didn't look real, like seriously looked like a modern fancy reprint, it was a bit confusing! reply spl757 2 hours agoprevThe error message \"The requested URL was rejected. Please consult with your administrator.\" is from an F5 Networks Application Security Manager firewall and can usually be addessed by clearing certain cookies in your browser. I was able to get it to load using Chrome with all cookies cleared, but it does appear to be getting the \"hug of death\" as well as mywacaday says in another comment. reply calibas 1 hour agoparentI only see one cookie, for the captcha, and removing that just forces me to solve the captcha again. The 503 error itself doesn't seem to be cookie related, looks like the site can't keep up with the kind of traffic they're getting. Also, if clearing cookies prevents errors, it's likely related to caching. Depending on the server configuration, things like authentication cookies will cause the session to bypass caches for certain resources. reply Brajeshwar 2 hours agoprevIs this a different one from the one I found at Global Grey’s Collection https://www.globalgreyebooks.com/book-of-kells-ebook.html Global Grey was popular on HN a few years back, and I bought the whole collection. reply g40694 2 hours agoparentthe og scan of book of kells was done by a Swiss publisher in the early 90s. since you can't copyright a scan, and the book itself is in public domain, anyone can then take the scans (if they can get hands on the high dpi originals or whatever, or do a high dpi scan of the reproduction) and publish them as whatever they want. \"the complete encyclopedia of human knowledge (only $99.99 if you call now)\" \"the illuminated authoritative book of kells (comes with your own one of a kind handmade Irish cross)\" etc. you can get the scans themselves (afaiu its at matching dpi, if not the same format) from a 2006 trinity college dvd of book of kells. the op is an announcement of the completed rescan effort, with modern technologies and modern dpis. with a companion iPad app and a website that have consumer grade renditions of those modern research grade scans. reply oliwarner 1 hour agorootparent> you can't copyright a scan Why not? It's derivative but it's still work. reply KyleBrandt 34 minutes agorootparenthttps://en.m.wikipedia.org/wiki/Bridgeman_Art_Library_v._Cor.... https://commons.m.wikimedia.org/wiki/Commons:Reuse_of_PD-Art... reply g40694 34 minutes agorootparentprevit's a statement of fact, so we can just leave it at that. but the explanation as I understand it and I'm not a lawyer, is that scan or a facsimile is a mechanism of reproduction, and the act of reproduction doesn't give you copyright. work, derivative work, original work, demonstration of originality have all precise definitions, but in laymen terms which is also my understanding, your derivative work has to be creative and original in its own right to have a copyright. reply luma 38 minutes agorootparentprevPresumably, because it isn’t transformative enough to constitute a derivative work. Otherwise, making a copy of free works would allow one to put those works back under copyright. reply jeffbee 3 hours agoprevInstead of the popup and affiliate-link-laden article, you could go right to it: https://digitalcollections.tcd.ie/concern/works/hm50tr726?lo... reply senko 3 hours agoparent... and be forced to complete a captcha before getting 503 service unavailable. reply mepian 3 hours agoparentprev\"The requested URL was rejected. Please consult with your administrator. Error 503 - Service Unavailable\" reply mywacaday 2 hours agorootparentHaven't seen a hug of death in a while. reply secondcoming 2 hours agorootparentprevSomeone's Sunday just got ruined reply g40694 3 hours agoparentprevthe indignity of the entire experience is comedic, and we've come to accept it. the op article is empty aggregation, a little superficial bit of dopamine noise, that's exclusively parasitizing on actual content. the direct link is probably better, but it throws a CAPCHA for me, where I need to click on Indian men on motorcycles to teach an AI what a motorcycle is. sister comment is reporting that the underlying site is down anyway, despite the \"protection\" provided by the internet muscle services. which makes one wonder, why even go looking at the book of kells, like, who among the hackernews readership will sit down with an iPad or other high resolution device to peruse the entirety of the book at leisure, inspecting the subtle details of the illumination, taking notes etc. reply mistrial9 2 hours agorootparentit is a treasure of culture, available to the general public. Support your local library. reply g40694 2 hours agorootparentI don't understand the point you're trying to make and how it relates to what I said. the book of kell is available both as a facsimile from specialist publishers (/my/ local library has it in extended rotation) and as a 2006 dvd from trinity college library. but I'm not even talking about that reply mistrial9 2 hours agorootparent> why even go looking at the book of kells ... etc reply g40694 2 hours agorootparentwhy even go looking at the book of kells is the sentiment about the deliberate versus knee jerk information consumption, which was prompted by the reflection on the levels of ugliness and indignity supporting the knew jerk consumption. it wasn't a comment on the value of book of kells, or the effort of making it available to the public. reply chrisweekly 2 hours agoprevThe animated film (same prod crew that made Song of the Sea) is excellent. reply lihaciudaniel 45 minutes agoprevIf you want more like these drawings , check wikisource https://commons.m.wikimedia.org/w/index.php?title=File:Apoca... reply squiffsquiff 1 hour agoprev [–] Error 503 - Service Unavailable reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Book of Kells, a famous medieval illuminated manuscript, has been digitized and is accessible online via Trinity College Library.- Created around 806 on the Scottish island of Iona, the manuscript is renowned for its intricate artwork and contains the four gospels.- The digitized version provides high-resolution images, enabling worldwide access, and Trinity College offers a free online course on its history and significance."
    ],
    "commentSummary": [
      "The Book of Kells, a significant historical artifact, has been digitized and is now accessible online, allowing broader public access.",
      "Although the Old Library at Trinity College, where the Book of Kells is housed, is under renovation, the book is available in a dedicated building.",
      "The digitization of the Book of Kells is noteworthy as it enhances accessibility to this ancient manuscript, which is a key piece of cultural heritage."
    ],
    "points": 148,
    "commentCount": 33,
    "retryCount": 0,
    "time": 1728227955
  },
  {
    "id": 41752436,
    "title": "What is the history of the use of \"foo\" and \"bar\" in source code examples? (2012)",
    "originLink": "https://softwareengineering.stackexchange.com/questions/69788/what-is-the-history-of-the-use-of-foo-and-bar-in-source-code-examples",
    "originBody": "Join Software Engineering By clicking “Sign up”, you agree to our terms of service and acknowledge you have read our privacy policy. Sign up with Google OR Email Password Sign up Already have an account? Log in X Skip to main content Stack Exchange Network Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Visit Stack Exchange Loading… Tour Start here for a quick overview of the site Help Center Detailed answers to any questions you might have Meta Discuss the workings and policies of this site About Us Learn more about Stack Overflow the company, and our products current community Software Engineering help chat Software Engineering Meta your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions Tags Users Jobs Companies Unanswered Teams Now available on Stack Overflow for Teams! AI features where you work: search, IDE, and chat. Learn more Explore Teams Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Explore Teams Teams Q&A for work Connect and share knowledge within a single location that is structured and easy to search. Learn more about Teams What is the history of the use of \"foo\" and \"bar\" in source code examples? Ask Question Asked 16 years ago Modified 11 years, 1 month ago Viewed 310k times 60 votes Save this question. Show activity on this post. Want to improve this post? Provide detailed answers to this question, including citations and an explanation of why your answer is correct. Answers without enough detail may be edited or deleted. Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. Why do many code examples, especially tutorials, use the names \"Foo\" and \"Bar\" so often? It is almost a standard. For example: void foo(char* bar) { printf(\"%s\", bar); } terminology history variables Share edited Apr 4, 2012 at 14:08 community wiki 5 revs, 3 users 65% user15453 0 Comments disabled on deleted / locked posts / reviews14 Answers Sorted by: Reset to default Highest score (default) Date modified (newest first) Date created (oldest first) 65 votes Save this answer. Show activity on this post. Foo and bar come from the US Army WWII acronym FUBAR, \"F-ed Up Beyond All Recognition\". A whole family of these terms came into widespread use during the North African and Sicilian campaigns (1942-43). Rick Atkinson's excellent Day of Battle: The War in Sicily and Italy, 1943-1944 gives a list of these. For instance a JANFU is a \"Joint Army Navy F Up\", such as the incident on 11 July 1943 when the invasion fleet for Operation Husky shot down 23 Army Air Force C-47 transports carrying paratroopers to reinforce the beachhead. Update: Wikipedia has a list of related acronyms that includes some the original WWII ones listed by Atkinson. Any programmer will understand the motivation for using foo and bar to name variables. They certainly have been part of the C/UNIX culture from the start, and as @Walter Mitty points out, predated it. Update (10/5/2009): Here's Atkinson's description: Their pervasive \"civilianness\" made them wary of martial zeal. \"We were not romantics filled with cape-and-sword twaddle,\" wrote John Mason Brown, a Navy Reserve lieutenant headed to Sicily. \"The last war was too near for that.\" Military life inflamed their ironic sensibilities and their skepticism. A single crude acronym that captured the soldier's lowered expectations -- SNAFU, \"situation normal, all fucked up\" -- had expanded into a vocabulary of GI cynicism: SUSFU (situation unchanged, still fucked up); FUMTU (fucked up more than usual); JANFU (joint Army-Navy fuck-up); JAAFU (joint Anglo-American fuck-up); FUAFUP (fucked up and fucked up proper); and FUBAR (fucked up beyond all recognition) [Atkinson, p. 36]. Update (11/23/2011): @Hugo has a fantastic list of the non-military antecedents. Share edited Apr 12, 2017 at 7:31 community wiki 3 revs, 2 users 88% Jim Ferrans 4 3 To add to the etymology: \"FUBAR may have been influenced by the German word furchtbar, meaning terrible. It is pronounced with a soft cht, and probably made the transition during World War II\" – Mark Commented Jun 1, 2009 at 13:54 4 @Mark, The German Wikipedia (de.wikipedia.org/wiki/Fubar), suggests this might be a pseudoetymology. It also points to antecedents like the \"SILENCE IS FOO\" sign in Warner Brother's 1938 cartoon \"The Daffy Doc\". – Jim Ferrans Commented Jun 26, 2009 at 11:51 4 @Jim Ferrans: While FUBAR probably influenced the use of \"bar\" with \"foo\", there is strong evidence that \"foo\" by itself well predates WWII, with references at least back to the 1930s, as your comment indicates. It might be good to mention that in the body of your answer. – Daniel Pryden Commented May 27, 2010 at 15:38 Yes, foo definitely predates WWII. In fact, I've found an MIT newspaper piece from 1938 that tells us how common it was: \"As an expletive, of course, \"foo!\" has a definite and probably irreplaceable position in our language, although we fear that the excessive use to which it is currently subjected may well result in its falling into an early (and, alas, a dark) oblivion.\" See my answer for more and a 1937 reference in the same newspaper: programmers.stackexchange.com/questions/69788/… – Hugo Commented Jun 1, 2011 at 20:42 Add a comment59 votes Save this answer. Show activity on this post. I think it's the phonetic pronouncation of fubar. Which stands for: F*cked Up Beyond All Repair Share edited Jan 20, 2012 at 9:09 community wiki 2 revs, 2 users 95% FlySwat 7 18 Repair or Recognition ;P – Anders Commented Nov 4, 2008 at 16:20 10 \"Fouled\" is often used when needing to be polite. – Colonel Sponsz Commented Nov 4, 2008 at 16:30 30 repair? nah .. recognition – hasen Commented Mar 6, 2009 at 3:53 6 It's \"recognition\". See quote from Rick Atkinson's Day of Battle here: stackoverflow.com/questions/262271/… – Jim Ferrans Commented Dec 9, 2009 at 22:40 7 Just a note that there's strong evidence (see RFC 3092, the Jargon File, and other answers here) that \"foo\" was used as a placeholder nonsense word in the 1930s, well before FUBAR came into military slang in the WWII era. – Daniel Pryden Commented May 27, 2010 at 15:41Show 2 more comments 41 votes Save this answer. Show activity on this post. The New Hacker's Dictionary has a very good entry on this - and I consider it to be a better resource for this kind of thing than Wikipedia: metasyntactic variable /n./ A name used in examples and understood to stand for whatever thing is under discussion, or any random member of a class of things under discussion. The word foo is the canonical example. To avoid confusion, hackers never (well, hardly ever) use `foo' or other words like it as permanent names for anything. In filenames, a common convention is that any filename beginning with a metasyntactic-variable name is a scratch file that may be deleted at any time. To some extent, the list of one's preferred metasyntactic variables is a cultural signature. They occur both in series (used for related groups of variables or objects) and as singletons. Here are a few common signatures: foo, bar, baz, quux, quuux, quuuux...: MIT/Stanford usage, now found everywhere (thanks largely to early versions of this lexicon!). At MIT (but not at Stanford), baz dropped out of use for a while in the 1970s and '80s. A common recent mutation of this sequence inserts qux before quux. bazola, ztesch: Stanford (from mid70s on). foo, bar, thud, grunt: This series was popular at CMU. Other CMU-associated variables include gorp. foo, bar, fum: This series is reported to be common at XEROX PARC. fred, barney: See the entry for fred. These tend to be Britishisms. corge, grault, flarp: Popular at Rutgers University and among GOSMACS hackers. zxc, spqr, wombat: Cambridge University (England). shme Berkeley, GeoWorks, Ingres. Pronounced /shme/ with a short /e/. snork Brown University, early 1970s. foo, bar, zot Helsinki University of Technology, Finland. blarg, wibble New Zealand. toto, titi, tata, tutu France. pippo, pluto, paperino Italy. Pippo /pee'po/ and Paperino /pa-per-ee'-no/ are the Italian names for Goofy and Donald Duck. aap, noot, mies The Netherlands. These are the first words a child used to learn to spell on a Dutch spelling board. Of all these, only 'foo' and 'bar' are universal (and baz nearly so). The compounds foobar and `foobaz' also enjoy very wide currency. Some jargon terms are also used as metasyntactic names; barf and mumble, for example. See also Commonwealth Hackish for discussion of numerous metasyntactic variables found in Great Britain and the Commonwealth. Share edited Sep 1, 2013 at 17:32 community wiki 2 revs, 2 users 99% ColinYounger 5 Have to say, I'm from NZ and I've never heard of 'blarg' OR 'wibble'. – ChristianLinnell Commented Jun 2, 2009 at 2:28 That was one pretty good. It's elaborate.Thanks dude. – Tarik Commented Aug 10, 2009 at 6:13 OMG, my QL account is qux. Shocked... – flq Commented Jun 15, 2010 at 20:41 @Colin - I altered the link to a different site, since the existing one was offline. – therefromhere Commented Sep 26, 2010 at 11:15 I found some other interesting metasyntactic variables from an MIT 1964 paper about LISP (that of course also had foo): chi / boston new york / spinach butter steak / foo crock glitch / poot toop / toot toot / isthisatrivialexcercise / ploop flot top / snap crackle pop / one two three / plane sub thresher. See my answer for more info: programmers.stackexchange.com/questions/69788/… – Hugo Commented Jun 1, 2011 at 20:46 Add a comment25 votes Save this answer. Show activity on this post. Wikipedia gives this definition of Metasyntactic Variable : In computer science, programmers use metasyntactic variables to describe a placeholder name or an alias term commonly used to denote the subject matter under discussion or an arbitrary member of a class of things under discussion. The use of a metasyntactic variable is helpful in freeing a programmer from creating a logically named variable, which is often useful when creating or teaching examples of an algorithm. The word foo is the principal example. The term \"metasyntactic variable\" is primarily found in informal literature. It is sometimes also used as a synonym for metavariable. Any symbol or word which does not violate the rules of the language can be used as a metasyntactic variable, but nonsense words are commonly used. The same concept is employed in other fields where it is expressed by terms such as schematic variable (see logical form). By mathematical analogy: A metasyntactic variable is a word that is a variable for other words, just as in algebra letters are used as variables for numbers. The article also gives common examples of such variables in different programming languages : C In the following example of the C programming language the function name foo and the variable name bar are both metasyntactic variables. Lines beginning with // are comments. // The function named foo int foo(void) { // Declare the variable bar and set the value to 1 int bar = 1; return bar; } Python Spam, ham, and eggs are the principal metasyntactic variables used in the Python programming language.[5] This is a reference to the famous comedy sketch, Spam, by Monty Python, the eponym of the language.[6] In the following example spam, ham, and eggs are metasyntactic variables and lines beginning with # are comments. # Define a function named spam def spam(): # define the variable ham ham = \"Hello World!\" #define the variable eggs eggs = 1 return Ruby In the following example the baz, foo, and bar are metasyntactic variables and lines beginning with # are comments. # Declare the variable foo and set equal to 1 foo = 1 # Declare the variable bar and set equal to 2 bar = 2 # Declare the method (function) named baz, which prints the text 'Hello world' def baz puts 'Hello world' end Share edited Nov 23, 2011 at 21:51 community wiki 2 revs, 2 users 98% Matthieu Add a comment19 votes Save this answer. Show activity on this post. Here is wikipedia's answer: The terms foobar, foo, bar, and baz, are common placeholder names (also referred to as metasyntactic variables) used in computer programming or computer-related documentation. They are commonly used to represent unknown values, typically when describing a scenario where the purpose of the unknown values are understood, but their precise values are arbitrary and unimportant. The terms can be used to represent any part of a complicated system or idea, including the data, variables, functions, and commands. The words themselves have no meaning in this usage, and are merely logical representations, much like the letters x and y are used in algebra. Foobar is often used alone; foo, bar, and baz are usually used in that order, when multiple entities are needed. Foo has entered the English language as a neologism and is considered by many to be the canonical example of a metasyntactic variable.[citation needed] It is used extensively in computer programming examples (sometimes expressed as \"for once only\") and pseudocode. Eric S. Raymond has called it an \"important hackerism\" alongside kludge and cruft.[1] http://en.wikipedia.org/wiki/Foo And from RFC 3092: When used in connection with 'bar' it is generally traced to the WW II era Army slang acronym FUBAR ('Fucked Up Beyond All Repair'), later modified to foobar. Early versions of the Jargon File [JARGON] interpreted this change as a post-war bowdlerization, but it now seems more likely that FUBAR was itself a derivative of 'foo' perhaps influenced by German 'furchtbar' (terrible) - 'foobar' may actually have been the original form. For, it seems, the word 'foo' itself had an immediate prewar history in comic strips and cartoons. In the 1938 Warner Brothers cartoon directed by Robert Clampett, \"The Daffy Doc\", a very early version of Daffy Duck holds up a sign saying \"SILENCE IS FOO!\"...(snip) http://www.faqs.org/rfcs/rfc3092.html Share answered Jun 1, 2009 at 13:05 community wiki Daniel A. White 3 6 or you could just admit it comes from fubar = '\"f\" up beyond all recognition' – Jonathan Fingland Commented Jun 1, 2009 at 13:20 4 @Jonathan Fingland: No it doesn't. (In fact, \"foo\" probably predates both \"foobar\" and \"FUBAR\".) See RFC 3092 and the Jargon File entry for \"foo\". – Daniel Pryden Commented May 27, 2010 at 0:12 @Daniel, Excellent reference. Added – Jonathan Fingland Commented May 27, 2010 at 0:23 Add a comment19 votes Save this answer. Show activity on this post. tl;dr \"Foo\" and \"bar\" as metasyntactic variables were popularised by MIT and DEC, the first references are in work on LISP and PDP-1 and Project MAC from 1964 onwards. Many of these people were in MIT's Tech Model Railroad Club, where we find the first documented use of \"foo\" in tech circles in 1959 (and a variant in 1958). Both \"foo\" and \"bar\" (and even \"baz\") were well known in popular culture, especially from Smokey Stover and Pogo comics, which will have been read by many TMRC members. Also, it seems likely the military FUBAR contributed to their popularity. The use of lone \"foo\" as a nonsense word is pretty well documented in popular culture in the early 20th century, as is the military FUBAR. (Some background reading: FOLDOC FOLDOC Jargon File Jargon File Wikipedia RFC3092) OK, so let's find some references. STOP PRESS! After posting this answer, I discovered this perfect article about \"foo\" in the Friday 14th January 1938 edition of The Tech (\"MIT's oldest and largest newspaper & the first newspaper published on the web\"), Volume LVII. No. 57, Price Three Cents: On Foo-ism The Lounger thinks that this business of Foo-ism has been carried too far by its misguided proponents, and does hereby and forthwith take his stand against its abuse. It may be that there's no foo like an old foo, and we're it, but anyway, a foo and his money are some party. (Voice from the bleachers- \"Don't be foo-lish!\") As an expletive, of course, \"foo!\" has a definite and probably irreplaceable position in our language, although we fear that the excessive use to which it is currently subjected may well result in its falling into an early (and, alas, a dark) oblivion. We say alas because proper use of the word may result in such happy incidents as the following. It was an 8.50 Thermodynamics lecture by Professor Slater in Room 6-120. The professor, having covered the front side of the blackboard, set the handle that operates the lift mechanism, turning meanwhile to the class to continue his discussion. The front board slowly, majestically, lifted itself, revealing the board behind it, and on that board, writ large, the symbols that spelled \"FOO\"! The Tech newspaper, a year earlier, the Letter to the Editor, September 1937: By the time the train has reached the station the neophytes are so filled with the stories of the glory of Phi Omicron Omicron, usually referred to as Foo, that they are easy prey. ... It is not that I mind having lost my first four sons to the Grand and Universal Brotherhood of Phi Omicron Omicron, but I do wish that my fifth son, my baby, should at least be warned in advance. Hopefully yours, Indignant Mother of Five. And The Tech in December 1938: General trend of thought might be best interpreted from the remarks made at the end of the ballots. One vote said, '\"I don't think what I do is any of Pulver's business,\" while another merely added a curt \"Foo.\" The first documented \"foo\" in tech circles is probably 1959's Dictionary of the TMRC Language: FOO: the sacred syllable (FOO MANI PADME HUM); to be spoken only when under inspiration to commune with the Deity. Our first obligation is to keep the Foo Counters turning. These are explained at FOLDOC. The dictionary's compiler Pete Samson said in 2005: Use of this word at TMRC antedates my coming there. A foo counter could simply have randomly flashing lights, or could be a real counter with an obscure input. And from 1996's Jargon File 4.0.0: Earlier versions of this lexicon derived 'baz' as a Stanford corruption of bar. However, Pete Samson (compiler of the TMRC lexicon) reports it was already current when he joined TMRC in 1958. He says \"It came from \"Pogo\". Albert the Alligator, when vexed or outraged, would shout 'Bazz Fazz!' or 'Rowrbazzle!' The club layout was said to model the (mythical) New England counties of Rowrfolk and Bassex (Rowrbazzle mingled with (Norfolk/Suffolk/Middlesex/Essex).\" A year before the TMRC dictionary, 1958's MIT Voo Doo Gazette (\"Humor suplement of the MIT Deans' office\") (PDF) mentions Foocom, in \"The Laws of Murphy and Finagle\" by John Banzhaf (an electrical engineering student): Further research under a joint Foocom and Anarcom grant expanded the law to be all embracing and universally applicable: If anything can go wrong, it will! Also 1964's MIT Voo Doo (PDF) references the TMRC usage: Yes! I want to be an instant success and snow customers. Send me a degree in: ... Foo Counters Foo Jung But let's remember this question is about code examples, so let's find \"foo\", \"bar\" and \"foobar\" published in code. So, Jargon File 4.4.7 says of \"foobar\": Probably originally propagated through DECsystem manuals by Digital Equipment Corporation (DEC) in 1960s and early 1970s; confirmed sightings there go back to 1972. The first published reference I can find is from February 1964, but written in June 1963, The Programming Language LISP: its Operation and Applications by Information International, Inc., with many authors, but including Timothy P. Hart and Michael Levin: Thus, since \"FOO\" is a name for itself, \"COMITRIN\" will treat both \"FOO\" and \"(FOO)\" in exactly the same way. Also includes other metasyntactic variables such as: FOO CROCK GLITCH / POOT TOOR / ON YOU / SNAP CRACKLE POP / X Y Z I expect this is much the same as this next reference of \"foo\" from MIT's Project MAC in January 1964's AIM-064, or LISP Exercises by Timothy P. Hart and Michael Levin: car[((FOO . CROCK) . GLITCH)] It shares many other metasyntactic variables like: CHI / BOSTON NEW YORK / SPINACH BUTTER STEAK / FOO CROCK GLITCH / POOT TOOP / TOOT TOOT / ISTHISATRIVIALEXCERCISE / PLOOP FLOT TOP / SNAP CRACKLE POP / ONE TWO THREE / PLANE SUB THRESHER For both \"foo\" and \"bar\" together, the earliest reference I could find is from MIT's Project MAC in June 1966's AIM-098, or PDP-6 LISP by none other than Peter Samson: EXPLODE, like PRIN1, inserts slashes, so (EXPLODE (QUOTE FOO/ BAR)) PRIN1's as (F O O // / B A R) or PRINC's as (F O O / B A R). Some more recallations. @Walter Mitty recalled on this site in 2008: I second the jargon file regarding Foo Bar. I can trace it back at least to 1963, and PDP-1 serial number 2, which was on the second floor of Building 26 at MIT. Foo and Foo Bar were used there, and after 1964 at the PDP-6 room at project MAC. John V. Everett recalls in 1996: When I joined DEC in 1966, foobar was already being commonly used as a throw-away file name. I believe fubar became foobar because the PDP-6 supported six character names, although I always assumed the term migrated to DEC from MIT. There were many MIT types at DEC in those days, some of whom had worked with the 7090/7094 CTSS. Since the 709x was also a 36 bit machine, foobar may have been used as a common file name there. Foo and bar were also commonly used as file extensions. Since the text editors of the day operated on an input file and produced an output file, it was common to edit from a .foo file to a .bar file, and back again. It was also common to use foo to fill a buffer when editing with TECO. The text string to exactly fill one disk block was IFOO$HXA127GA$$. Almost all of the PDP-6/10 programmers I worked with used this same command string. Daniel P. B. Smith in 1998: Dick Gruen had a device in his dorm room, the usual assemblage of B-battery, resistors, capacitors, and NE-2 neon tubes, which he called a \"foo counter.\" This would have been circa 1964 or so. Robert Schuldenfrei in 1996: The use of FOO and BAR as example variable names goes back at least to 1964 and the IBM 7070. This too may be older, but that is where I first saw it. This was in Assembler. What would be the FORTRAN integer equivalent? IFOO and IBAR? Paul M. Wexelblat in 1992: The earliest PDP-1 Assembler used two characters for symbols (18 bit machine) programmers always left a few words as patch space to fix problems. (Jump to patch space, do new code, jump back) That space conventionally was named FU: which stood for Fxxx Up, the place where you fixed Fxxx Ups. When spoken, it was known as FU space. Later Assemblers ( e.g. MIDAS allowed three char tags so FU became FOO, and as ALL PDP-1 programmers will tell you that was FOO space. Bruce B. Reynolds in 1996: On the IBM side of FOO(FU)BAR is the use of the BAR side as Base Address Register; in the middle 1970's CICS programmers had to worry out the various xxxBARs...I think one of those was FRACTBAR... Here's a straight IBM \"BAR\" from 1955. Other early references: 1967 foo bar MIT AIM-127 1967 foo bar MIT AIM-127a 1965 foo MIT Tech Engineering News 1968 foo baz DEC 1971 FOO BAR UCLA-NMC RFC269 1972 FOO MIT AI 1972 FOO MIT AI HAKMEM (PDF scan) 1972 FOO DEC 1973 FOO DEC 1973 foo bar International Joint Council on Artificial Intelligence 1975 foo bar International Joint Council on Artificial Intelligence 1977 Foobar 1978 Foobar 1978 Moby Foobar in Software Wars I haven't been able to find any references to foo bar as \"inverted foo signal\" as suggested in RFC3092 and elsewhere. Here are a some of even earlier F00s but I think they're coincidences/false positives: 1959 \"FOO 31 IBM-704 Bettis Plant Uses a least squares technique\" U.S. Atomic Energy Commission 1960 FOO (FO Out, F1, F2, FOO, FOI) \"Digital computer and control engineering\" 1967 FOO? Share edited Oct 7, 2021 at 6:47 community wiki 4 revs Hugo 0 Add a comment13 votes Save this answer. Show activity on this post. using words like \"foo\" and \"bar\" make you focus on the concept not on what you can grasp based on the terms you know. For example: public abstract class Animal { public abstract void speak(); } public class Cat extends Animal { public abstract void speak() { System.out.println(\"meow\"); } } public class Dog extends Animal { public abstract void speak() { System.out.println(\"bark\"); } } The above code lets you fall back on your knowledge of real world things. If you are trying to explain a concept where the important part is not what is being done (printing meow or bark for example) but on how it is being done then removing the parts that you are familiar help: public abstract class Foo { public abstract void star(); } public class Bar extends Foo { public abstract void star() { System.out.println(\"A\"); } } public class Car extends Foo { public abstract void star() { System.out.println(\"b\"); } } Now you have to focus on what is really happening, you are no longer able to guess at what is going to happen. So, the short version is, that foo, bar, and the like, are used to stress concepts where the content doesn't really matter but the idea does. Share answered Mar 6, 2009 at 3:41 community wiki TofuBeer 4 ah, a real answer! – nickf Commented Mar 6, 2009 at 3:44 1 Yes, but why Foo and Bar specifically? Why not Lorum and Ipsum? – masher Commented Jun 2, 2009 at 2:08 en.wikipedia.org/wiki/Foo could be accurate... – TofuBeer Commented Jun 2, 2009 at 4:36 @TofuBeer Yep, they're \"metasyntactic variables\". @masher see my answer with loads of references as to why Foo and Bar and not Lorem and Ipsum. programmers.stackexchange.com/questions/69788/… In fact, there are loads of different metasyntactic variables that have been used over the years, and in different places. – Hugo Commented May 31, 2011 at 21:27 Add a comment7 votes Save this answer. Show activity on this post. From http://en.wikipedia.org/wiki/Foobar In technology, the word was probably originally propagated through system manuals by Digital Equipment Corporation in 1960s and early 1970s. Another possibility is that foobar evolved from electronics, as an inverted foo signal. This is because if a digital signal is active low (so a negative or zero-voltage condition represents a \"1\") then a horizontal bar is commonly placed over the signal label. The Jargon File makes a case that foo possibly predates FUBAR Share answered Oct 2, 2008 at 16:11 community wiki Cetra 2 this does not explain the why – hop Commented Jan 23, 2009 at 12:43 I've found plenty of references of first \"foo\" and later \"bar\" from MIT and also DEC (both in Massachusetts), in their work on LISP and the PDP-1 and Project MAC from 1964 onwards. It's a nice idea, but I couldn't find any reference to an \"inverted foo signal\". More here: programmers.stackexchange.com/questions/69788/… – Hugo Commented Jun 1, 2011 at 20:51 Add a comment7 votes Save this answer. Show activity on this post. From the Jargon Files http://www.catb.org/jargon/html/F/foo.html foo: /foo/ interj. Term of disgust. [very common] Used very generally as a sample name for absolutely anything, esp. programs and files (esp. scratch files). First on the standard list of metasyntactic variables used in syntax examples. See also bar, baz, qux, quux, garply, waldo, fred, plugh, xyzzy, thud. bar: /bar/, n. [very common] The second metasyntactic variable, after foo and before baz. “Suppose we have two functions: FOO and BAR. FOO calls BAR....” Often appended to foo to produce foobar. Share answered Oct 2, 2008 at 16:13 community wiki jop Add a comment5 votes Save this answer. Show activity on this post. According to http://en.wikipedia.org/wiki/Foo: The terms' origins are not known with certainty, and several anecdotal theories have been advanced to identify them. Foobar may derive from the vulgar military acronym FUBAR, or it may have gained popularity due to the fact that it is pronounced the same. Share edited Apr 4, 2012 at 14:06 community wiki 2 revs, 2 users 50% RichieHindle Add a comment4 votes Save this answer. Show activity on this post. I second the jargon file regarding Foo Bar. I can trace it back at least to 1963, and PDP-1 serial number 2, which was on the second floor of Building 26 at MIT. Foo and Foo Bar were used there, and after 1964 at the PDP-6 room at project MAC. Share answered Nov 4, 2008 at 16:26 community wiki Walter Mitty 2 +1 for witnessing one of the earliest uses of Foo Bar :) How exactly were Foo and Foo Bar actually used there? – Hugo Commented May 28, 2011 at 22:54 PS I've included your quote in my big answer: programmers.stackexchange.com/questions/69788/… – Hugo Commented May 31, 2011 at 21:29 Add a comment2 votes Save this answer. Show activity on this post. As far as I know, foo comes from foobar which is an alteration of \"fubar\", a military catch phraase that stands for \"F***ed up beyond all recognition.\" Then again, there may be other sources. http://en.wikipedia.org/wiki/Foo Share answered Jun 1, 2009 at 13:07 community wiki Chris Add a comment0 votes Save this answer. Show activity on this post. Foo and Bar (otherwise known as FUBAR...F***ed Up Beyond All Recognition) has just been used as standard generic names for things like classes, properties, method names, etc. Basically the idea is to convey your code without as much extraneous information that could possibly get away from how the code works (i.e. we don't need to know your function is named AddUser to see the code and understand what it does if we rename it to Foo() ). Share answered Jun 1, 2009 at 13:08 community wiki TheTXI Add a comment-3 votes Save this answer. Show activity on this post. These are nonsense words that in most cases can be substituted with more relevant example words. The words \"foo\" and \"bar\" are frequently used in programming when someone can't think of a good example. If \"foo\" and \"bar\" are derived from FUBAR, why is it they are used by so many professionals in instruction examples when the examples resemble nothing being f'd up beyond recognition? To me, the common use of these words inappropriately is what's so f'd up beyond recognition. Share edited Sep 1, 2013 at 18:17 community wiki 2 revs John 3 2 Note that just below the question is a banner: We're looking for long answers that provide some explanation and context. Don't just give a one-line answer; explain why your answer is right, ideally with citations. Answers that don't include explanations may be removed. Your answer offers little in the way of an explanation; currently it is merely an opinion. – Martijn Pieters Commented Sep 1, 2013 at 17:26 There are many other short answers. Why not provide an argument if you don't agree with what I'm saying instead of pointing out a technicality that doesn't apply? – John Commented Sep 1, 2013 at 18:18 edit in rev 2 made this answer even worse than it was before (though it was hard to imagine what could be worse): now it is just a repeats another answer that has been posted 4 years ago – gnat Commented Sep 1, 2013 at 18:30 Add a commentThe Overflow Blog Community Products Roadmap Update, October 2024 Meet the AI native developers who build software through prompt engineering Featured on Meta Preventing unauthorized automated access to the network Upcoming initiatives on Stack Overflow and across the Stack Exchange network... Linked 26 What's the origin of foo and bar? 2 Why \"Foo\" is so a special word? Related 2 Best way to delimit variable elements of a path in code documentation? 2 What is a better word for aligning your nesting? 102 What is the history of why bytes are eight bits? 11 What Are The Specific Meanings Of The Terms: Functions, Methods, Procedures, and Subroutines? 25 What is the reason for using lowercase for the first word in a local variable (eg, employeeCount, firstName) 6 Is there a name for web applications that do most of the navigation on the client side? 1 What is the use case for shadowing variables? 5 Stick with mis-named concepts or rename them in wrapper code? Hot Network Questions jq create object with property name from variable Why can I define a std::string instance that is constinit? Isn't constinit forbidden if an object requires dynamic initialization? Would adapting grounding notation to musical notation make the concept seem more distinctive and also clearer/more useful? I'm trying to replicate Rømer's experiment but can't seem to get even close to the correct value for the speed of light Who's \"Above all\"? Is the aboleth's mucus cloud ability supposed to hinder affected PCs? It seems beneficial Need help to solve the problem with the number of armed forces How do I make a sedentary culture more adventurous or exploratory? Making small talk: Which verbs most commonly accept “small talk” as their direct object? Elegant way to examine a string by \"word\" (whitespace-delimited substring) How is AES-128 still considered to be quantum resistant? How to center a series of text width a fixed width that can automatically linebreak and underline it? Can two different non-optimal policies have the same value functions? Thesis part was flagged as AI generated even though it is all original Uniform distribution of sequence mod 1 What should the semantics from branching from finally be? What is Iran's long-term objective in the Middle East? Pain in the little finger of the left hand during the playing of two notes at the same time Concocting a fourth spatial dimension that can support wormhole-like travel and not mess up life? How to draw vector on 3D surface Should chat audio be encrypted before sending it? How does the Push weapon mastery interact with occupied spaces? Different C's, different S's (in order) Are seaplanes with floats more aerodynamically efficient (less drag) than planes with tires? more hot questions Software Engineering Tour Help Chat Contact Feedback Company Stack Overflow Teams Advertising Talent About Press Legal Privacy Policy Terms of Service Cookie Settings Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2024.10.3.16276",
    "commentLink": "https://news.ycombinator.com/item?id=41752436",
    "commentBody": "What is the history of the use of \"foo\" and \"bar\" in source code examples? (2012) (softwareengineering.stackexchange.com)138 points by squircle 23 hours agohidepastfavorite131 comments symbolicAGI 21 hours agoMIT AI Lab back in the 1960s published technical reports containing program code. The military slang 'FUBAR' f'ed up beyond all recognition, was in the student and professor engineering vocabulary. The tradition became to use 'fu' and 'bar' as nominal function names, in same manner as X and Y were nominal variables. Often in the MIT technical reports, one would see 'x = fu(y)' or 'y > bar(z)' and so forth. If you knew, you knew. A few years later, perhaps with the welcome progress of more female faculty and students, textbooks changed the spelling, but not the pronunciation of the vulgar acronym 'fu' to 'foo'. Again, if you knew, you knew. And now you all know. reply WalterBright 19 hours agoparentOn a related note, we all know the story from WW2 where Bastogne was surrounded by the Wehrmacht, and the Wehrmacht sent a note to General McAuliffe suggesting he surrender. He returned with a note that simply said \"nuts\". I simply did not believe than an American GI ever said \"nuts\". So, I asked my dad (WW2 veteran). He said he briefly worked for the General, and asked him what he actually wrote. The General laughed, and replied \"what do you think I wrote?\" F-U The Stars&Stripes journalists changed it to \"nuts\" thinking the Americans couldn't handle the profanity. reply stackghost 14 hours agorootparentI doubt this story very much. It's well documented that McAuliffe rarely used profanity, and it's similarly well documented, including by the US Army official historian, that the official reply was indeed \"nuts\". https://history.stackexchange.com/questions/40063/what-did-g... reply WalterBright 13 hours agorootparentPeople who rarely use profanity means they do use it, and when they do, they do it for effect. Certainly, a demand that he surrender Bastogne would justify profanity in a forceful response. > including by the US Army official historian An official US Army historian's job is to make the US Army look good. As we are all painfully aware these days, the accounts of newspapers are rarely accurate, and often outright fabrications. Why would WW2 accounts be any different? I doubt McAuliffe would want to besmirch his record after the war, had nothing to gain by contraindicating it, and would be content to let it stand. My father was a carefully honest man, and was never known by me to lie. He held his tongue until after McAuliffe passed away. He also told me some family secrets after all involved had passed, and asked me to keep them to myself until after he died, which I did. It never occurred to me to ask him to write down that story, and now it's too late. I know my evidence is hearsay and inadmissible in court. You're free to draw your own conclusions. P.S. I was once personally involved in an incident that made the local TV news. There was nothing political about it, but each of the three local news channels got essentially all the basic facts about it wrong. But that is the \"record\" of the event. It pretty much soured me on the veracity of news reports. reply stackghost 13 hours agorootparentWell Walter, ask yourself why Kinnard, who was in the room at the time and Harper, who delivered the message, and Premetz, the non-commissioned medic who translated it for the Germans, all give repeated official accounts and interviews that contradict the account of your father, who by your own admission merely \"worked for the general briefly\". Is it all a grand conspiracy to protect the good name and reputation of McAuliffe? I'll say no more. reply WalterBright 12 hours agorootparentMy father had a first hand account from McAuliffe, like the other three, and had no reason whatsoever to misrepresent it. > Is it all a grand conspiracy to protect the good name and reputation of McAuliffe? A small conspiracy is not at all far-fetched. First off, it's an inconsequential thing. Secondly, if one of the three told the truth, then he'd be called a liar by the other two. Who needs that? If you're in the military, you don't get ahead by contradicting the narrative. (My dad found that out the hard way - he was punished more than once for not writing reports that fit the narrative.) For a grand conspiracy, consider how long Biden's staff held out insisting that Biden was sharp as a tack and writing off contrary reports as disinformation. The most compelling bit about my evidence is the frankly laughable idea that a GI would use the word \"nuts\". reply WalterBright 12 hours agorootparentP.S. I understand you have no particular reason to believe me, and if I were in your shoes I wouldn't, either. If there is any takeaway here, it would be that historical accounts are always suspect. History is written by the victors, as they say. reply __MatrixMan__ 5 hours agorootparentprevWhether or not it's true, I think it's a pretty good story because it aligns BAR with \"Beyond All Recognition\", which is exactly the point of a metasyntactic variable: to be so separate that that context is unrecognizable. Obfuscating the context is what F's it Up. Usually that's a problematic thing, but in the case of foo and bar, the F'ed Up version is maybe better. reply hinkley 1 hour agorootparentprevNext you’re gonna tell me it wasn’t “damn the torpedoes” reply mncharity 14 hours agoparentprev> Often in the MIT technical reports, one would see 'x = fu(y)' or 'y > bar(z)' Hmm, \"fu\"? The decades confound my memory, but I don't immediately recall seeing a \"fu\" there? Before the \"foo\" of AIM-127a[1] in 1967 and MIT-LCS-TR-032[2] in 1966, there's still a decade of AI Memos, and couple of years of TRs. DSpace finds at least some \"fu\"s... lots of ocr fragments. The AITR-220 '64 hit is ocr fragment. My search-fu tonight wasn't up to being exhaustive (spot checks were all fragments). And also, OCR could be missing older \"fu\"s. But I didn't quickly find a real \"fu\". A foo-bar-baz-quux in MIT-LCS-TR-365[3] in 1986. One can start on the CSAIL collections page[4] and explore. [1] \"FOO\" in abstract of AIM-127a LISP Linkage Feature: Incorporating MIDAS into PDP-6 LISP https://dspace.mit.edu/handle/1721.1/6136 [2] \"Thus if FOO has the definition (LAMBDA (X Y) [alpha]), and the user calls SYSTEM1 with NAME= FOO, ADVICE= [beta], WHERE= BEFORE\" on page 43 of MIT-LCS-TR-032 Pilot: A Step Towards Man-Computer Symbiosis https://dspace.mit.edu/handle/1721.1/149354 [3] \"if the back trace is: FOO [1]societal expectations historically placed on women, they’ve typically had to be “the adult in the room.” I think it was the opposite; they were infantilzed and sensitive, considered liable to faint or have a bout of hysteria. They were to be protected. Swearing might upset a woman. Men had final authority over them in many cases. For example, often women couldn't get jobs without their husband's permission. Women were sometimes the source of a sensitive, compassionate, nurting viewpoint, a balance to the man's roughness. She might appeal to him, but it was his decision. reply the_gorilla 20 hours agorootparentprev> due to the societal expectations historically placed on women This reads like aliens trying (and failing) to figure out why women act more like women than men do. reply jckahn 20 hours agorootparentCan you elaborate on that? My goal was to be as clear as possible and leave minimal room for misinterpretation. reply b59831 20 hours agorootparentprevThis is a sexist statement reply RichardCA 2 hours agorootparentVery sexist. Women were not only expected to never cuss, but also to pretend as if they had never even heard such awful words. https://youtu.be/Cq-If5vVvcc reply kortilla 19 hours agorootparentprevIt’s a discussion about a sexist environment. Catch up reply danaris 19 hours agorootparentprevDescribing the factual sexist environment that existed in a prior time (or, hell, the ones that exist today) is not itself sexist. reply cgriswald 19 hours agorootparentIt’s a fact the environment was sexist. Everything else is speculation unless their is some evidence that women’s complaints were the driving factor of a change in policy rather than, say, the infantilization of women or a sexist expectation that women would take exception to it. reply jckahn 20 hours agorootparentprevHow so? reply carlosjobim 18 hours agorootparentprevPeople had different values than you do in the past. They also have different values right now. reply blahyawnblah 18 hours agorootparentprevIt's clear. Fucked Up reply snypher 21 hours agorootparentprev'F--- you' reply kevinventullo 20 hours agorootparentIn this case the u stands for “up”: https://www.merriam-webster.com/dictionary/fubar reply the_gipsy 20 hours agorootparentNo reply riiii 18 hours agorootparentprevBecause fu. reply greenthrow 18 hours agorootparentprevThat part of the comment is not true. reply TacticalCoder 18 hours agorootparentprev> Why would women in particular object to \"fu\" and not \"foo\"? Honestly I don't know pussy. reply the_gipsy 20 hours agorootparentprevBecause they are subject both to sexual harassment and to higher expectations, including \"professionalism\" (not using profanity at the workplace in this specific case). reply b59831 20 hours agorootparentThis isn't an answer to the question. Smug responses like this just means you don't actually have a point. reply the_gipsy 8 hours agorootparentHow does it not answer the question \"why would women avoid fu over foo\"? I thought it was clear that \"fu\" means \"fuck up\" or even \"fuck you\", a sexual swear word, while \"foo\" means nothing at all. reply fuzzfactor 2 hours agoparentprevAlso legendary is the traditional GIGO which in some programming examples the FU is the garbage in and the BAR is the garbage out. reply Teknomancer 2 hours agoparentprevFOOcked-up Beyond All Recognition. reply yreg 6 hours agoparentprevFor people, who (like me) don't know US military slang, FUBAR apparently means 'Fucked/Fouled Up Beyond All/Any Repair/Recognition/Reason' according to Wikipedia. reply reaperducer 20 hours agoparentprevA few years later, perhaps with the welcome progress of more female faculty and students, textbooks changed the spelling, but not the pronunciation of the vulgar acronym 'fu' to 'foo'. I was always told that fu became foo because it lined up nicely on screens and on paper, making the code easier to scan. foo = 1 bar = 2 looks better than fu = 1 bar = 2 reply fsckboy 22 hours agoprevI don't know the story of the entry of foo into the computer science lexicon, but it is the case that the early days of computers were populated with a fair number of military veterans because early computers were mostly used in military applications so that produced people with computer experience (not to mention the compulsory draft which meant that a large number of people would have military experience anyway). FUBAR (\"fucked up beyond all recognition\") was supposedly a military slang phrase. And the popular comic strip Smoky Stover starting in the 1930's used the word \"Foo\" wrt a firefighting character perhaps giving that spelling more currency. this is the Foomobile from that comic https://duckduckgo.com/?t=ffab&q=Foomobile&iax=images&ia=ima... reply ahazred8ta 22 hours agoparentThe missing link is 'FURCHTBAR'. Smokey Stover started the meme of substituting 'foo' into words. 1930s german language classes turned furchtbar (frightful) into 'foo-bar'. The US military acronymized it into FUBAR. Apparently MIT adopted fu() and bar() as algebra placeholders. I'm partial to the 1938 song WHAT THIS COUNTRY NEEDS IS FOO - https://m.youtube.com/watch?v=W2pljKyCgwc reply diggan 21 hours agorootparentSeems like that retelling comes from an IETF RFC: https://www.ietf.org/rfc/rfc3092.txt (Etymology of \"Foo\") reply d0mine 20 hours agorootparentThe date of the rfc is Apr 1st -- unclear how truthful it is. reply chiph 5 hours agoparentprevNo \"supposedly\" about it. FUBAR is still in common use. As is RHIP (Rank Hath Its Privileges) and BOHICA (Bend Over Here It Comes Again) reply SeanLuke 2 hours agoprevThe top response is wrong. So of course it was locked and made impossible to downgrade or correct. If this isn't a canonical Stack Overflow example I don't know what is. reply douglee650 21 hours agoprevIt blows me away that \"The Jargon File\" is not required canon. Well, it can be anachronistic and old-school-nerd-bro coded, but there's some primal stuff in there http://catb.org/jargon/html/ reply xorcist 3 hours agoparentThere was this thing called the Jargon File. Then it was taken over by a rogue person who removed some things which didn't fit his personal liking and put in some other things. There was a lot of drama, but the end result was a skewed file that emphasized certain parts of hacker culture over others. It might be good to know that you linked to the version which one person had outsized influence of, and should probably not be used to write history from. Except history on early Internet drama, perhaps. reply justinpombrio 2 hours agorootparentCan the original be found somewhere? reply js2 2 hours agorootparenthttps://news.ycombinator.com/item?id=41753841 reply Uehreka 18 hours agoparentprevI think it feels dated because it’s from a time when there were far fewer hackers. It’s way easier to make sweeping generalizations (“hackers like X and don’t like Y”, “hackers have a Z-ish sense of humor”) about a small group and have it actually be true. These days it seems weird, even mildly culty, to make definitive and specific statements about “what hackers are like”. There are millions of us all over the world. Many of us barely have a spoken language in common, let alone share a sense of humor or cultural values. reply dfox 18 hours agoparentprevThe real jargon file is probably here: https://www.dourish.com/goodies/jargon.html And it includes an explanation of what is wrong with ESR's version. But well, lets reiterate that: ESR is this weird kind of quasi-libertarian ego-maniac who occasionally produces something marginally useful and then oversells how that thing is part of the critical internet infrastructure or something like that. reply d0mine 20 hours agoparentprevhttp://catb.org/jargon/html/F/foobar.html reply jollyllama 17 hours agoparentprevAt some point the lines crossed between people whose first exposure was the old \"FUBAR\" and those whose first exposure was the tech \"foo/bar/baz\". I wonder when it was. reply marssaxman 16 hours agorootparentI imagine that many of us who got into programming through the 1980s home computer boom encountered the terms \"foo\" and \"bar\" before we were old enough that adults would have felt comfortable using \"FUBAR\" around us. reply lupusreal 1 hour agorootparentIn my experience, adults were comfortable saying FUBAR around kids but didn't explain it to be an acronym. I learned it simply as a regular word, which though context I understood to mean something was badly messed up. reply FooBarBizBazz 20 hours agoparentprev> old-school-nerd-bro I'm trying to maintain that the nerds of yore and the bros* who invaded in the 2010s are different groups -- in which case \"old-school nerd bro\" would be a contradiction in terms -- but alas \"bro\" has simply come to mean \"male\", and, to the English majors writing the newspaper articles, \"they all look the same\". So maybe I need to give up. * etymology: \"tech bro\", in analogy with \"finance bro\", which originated because fraternity brothers from top schools used to go into finance, but then migrated into Tech around '08. Associated stereotypically with developed pectorals and polo shirts with popped collars. Close to the \"Chad\" archetype, but with some light granola/yoga overtones. reply IggleSniggle 19 hours agorootparentI've been the same way but I think it's time to give up; the language has moved on, and it's only a very specific age bracket that recognizes the distinction. Graybeard means something different now too. It's okay though. It's not important and doesn't need to be maintained; it was just another form of gate-keeping... the early \"nerd-bro\" practically required the distinction as a form of identity reclamation in a culture that disparaged their puny interests in computing. We should celebrate that that particular shield is no longer needed, and thus that gatekeeping is no longer needed for ego-survival, either. reply bee_rider 14 hours agorootparentprevYou are correct. Don’t give up! reply fragmede 20 hours agoparentprevmaybe it's time for an update reply lysace 20 hours agoprevFor some reason, in Sweden, the word \"gazonk\" is common after \"foo\" and \"bar\". I've never been been able to figure out why. Here's a variant: https://developer.arm.com/documentation/dui0493/i/CHDFAGEE > foo\\bar\\baz\\gazonk\\quux\\bop Some Erlang reference: https://erlang.org/pipermail/erlang-questions/2009-January/0... > 43> lists:keysearch(foo, 1, [3.14, {foo,bar}gazonk]). > {value,{foo,bar}} The GNU Emacs manual: https://www.gnu.org/software/emacs/manual/html_node/emacs/Li... > (setq foo '(bar zot > gazonk)) https://www.epicroadtrips.us/2003/summer/nola/nola_offsite/F...: > Gazonk is often used as an alternative for baz or as a fourth metasyntactic variable. Some early versions of the popular editor Emacs used gazonk.foo as a default filename. reply thaumasiotes 20 hours agoparent> For some reason, in Sweden, the word \"gazonk\" is common after \"foo\" and \"bar\". That doesn't look like it's a potentially Swedish word. It does resemble an English one: https://en.wiktionary.org/wiki/gazongas (For whatever reason, wiktionary insists on defining \"gazongas\" only as \"the plural form of 'gazonga'\", but the word \"gazonga\" cannot be used at all; much as with \"scissors\" or \"pants\", only the plural form exists.) reply cool_dude85 17 hours agorootparentI don't agree with the thing about the singular \"gazonga\". Just like if you were to say a boob or a tit, I think a gazonga would be understood by anyone. reply thaumasiotes 16 hours agorootparentWhat can be understood is a separate question from what it's possible to say. Here's a common type of utterance from a foreign student of English: *Where you heard this? There's no risk of being misunderstood, but that doesn't mean it's possible to phrase a question in English this way. What would you understand if someone asked you for \"the scissor\"? reply gU9x3u8XmQNG 19 hours agoprevI have always felt that the foo/bar demo/example snippets have held me back in comprehending code, because there was no reasonable logic to it. It just means nothing to me, other than the FUBAR reference others have mentioned. I personally, and professionally, think it’s a horrible convention. reply marssaxman 16 hours agoparentIt's supposed to mean nothing; that's the point. You use \"foo\" and \"bar\" (and \"baz\" and \"qux\", etc) when the names of the things in your example do not matter. It's the same way you'd see examples featuring \"x\", \"y\", and \"z\" when learning algebra: maybe your textbook also has story problems, but most of the examples will simply show an equation in terms of x, y, and maybe z, without pretending that those abstractions refer to anything concrete. reply callc 15 hours agoparentprevI understand your perspective, and have felt similarly at times. OTOH I appreciate having some culture and some fun things in our field and teaching materials that would otherwise be pushed out by being 100% reasonable and logical all the time. reply LouisSayers 16 hours agoparentprevI agree, to me it's always looked like baby speak. Reading about \"FUBAR\" makes it even worse. reply dang 21 hours agoprevSurprisingly little. Others? Foo Bar came from model trains at MIT - https://news.ycombinator.com/item?id=41069963 - July 2024 (2 comments) The Origin of Foo and Bar - https://news.ycombinator.com/item?id=14030938 - April 2017 (1 comment) Kind of related but not really: foo@bar.com - https://news.ycombinator.com/item?id=24605949 - Sept 2020 (281 comments) The Foo at bar.com - https://news.ycombinator.com/item?id=10108287 - Aug 2015 (29 comments) foo@bar.com is a real email address - https://news.ycombinator.com/item?id=3263021 - Nov 2011 (91 comments) reply ddtaylor 20 hours agoparentHeads up that link to bar.com goes to an advertisement to sell the domain now. reply rsyring 21 hours agoparentprevhttps://www.ietf.org/rfc/rfc3092.txt reply asimpletune 3 hours agoprevDoes anyone have any other successors to foo and bar? Mine have always been bis buz baz, but I don't know if they're canonical or if I just made up the next words in the sequence. reply hinkley 46 minutes agoparentI don’t know how I started this but I’ve used the following since before I had a beard: foo/bar/baz/bing/bang/bong Once in a while I’ll throw “biz” in after baz. I suspect the bar/baz pairing felt like alliteration to me and I extended it. I’ve never used it in production code of course, but I have in tests. For string interpolation or parsing tests you tend to need a lot of variables or values and you don’t care what the variable means you just want the right ones placed in or extracted from the correct spots. In particular if the rest of the data looks legit and the bits sunstituted looks like gibberish, I find it makes the red tests’ failure message quicker to read. reply rchard2scout 2 hours agoparentprevAccording to the Jargon File, (http://www.catb.org/~esr/jargon/html/F/foo.html) the successors are baz, qux, quux, etc. reply helph67 22 hours agoprev\"In World War One “Foo was here” was scrawled across camps occupied by the Australian Expeditionary Force. Generally assumed to have come from the acronym for Forward Observation Officer, veterans of that war may have brought the tradition with them into the next global conflict over two decades later\" https://taskandpurpose.com/history/the-story-of-kilroy-and-w... reply jph 22 hours agoprevIn addition to the military-programming history of \"foo\", there's also a military-programming history for the variable naming convention of \"alfa\", \"bravo\", \"charlie\", \"delta\", etc. The naming convention is known as the NATO phonetic alphabet: https://en.wikipedia.org/wiki/NATO_phonetic_alphabet reply zabzonk 22 hours agoparent> \"alfa\", \"bravo\", \"Charlie\", \"delta\" Bit offtopic: As well as general use, a lot of thesed are used to classify Soviet/Russien submarines from a NATO point of use. Even more off topic:This is quite interesting (to me at last) in that NATO has used prefix schemes for bombers, fighters etc. (for example Bear (bomber), Fishbed (fighter)) rather than their makers names. As far as I know, in WW2 the Germans always referred to RAF fighters by their RAF names. reply wlindley 20 hours agoparentprevIn the 1940s, the Army used a phonetic alphabet starting Able, Baker, Charlie. My late father was on the first two postwar atomic bomb tests (the first after Trinity, and at Hiroshima, Nagasaki) which were Able and Baker. Able was an air burst over Bikini (thus the name of the swimsuit). Baker, the water burst, was the world's first atomic disaster; as a result of Baker, the third scheduled test Charlie was cancelled. My father died years later of colon cancer, perhaps not unrelated to contaminated air and water at the Eniwetok base afterwards. FUBAR indeed. reply somat 20 hours agorootparentThe change from able... to alpha... was a NATO thing. some European countries don't use the \"a\" in \"able\", so it was changed to the \"a\" in \"alpha\" reply dfox 18 hours agorootparentAlso there is a way to pronounce all of the NATO alphabet words that is not exactly a normal english pronounciation in order to make the first letter obvious and to reduce the possibility of mistranscription (the most obvious example is “nineR”). Sadly this does not really work in Czech, as laypeople will very often interpret “keˈbɛk” as K. (So the takeaway there is to not use NATO phonetic alphabet when you are dictating the pickup code to the package pickup point clerk) reply Cheer2171 22 hours agoparentprevNATO phonetic alphabet is used in all areas where you have to say letters over voice. One character variable names for temp or iterator values are everywhere in programming. But I've never ever encountered one spelled out as a full transcriptions of the NATO phonetic alphabet like alfa, bravo, charlie. Exception is alpha for probability/statistics. reply mindcrime 20 hours agorootparent> NATO phonetic alphabet is used in all areas where you have to say letters over voice. Not all. Military definitely favors NATO, but there are other phonetic alphabets in use. In particular, at least in the US, fire/ems personnel (and sometimes also law enforcement) use alternatives. The one that goes Adam, Boy (or Baker), Charlie, David, Edward, Frank, ... is still widely used. I've also known agencies to use a mix, like Adam, Baker, Charlie, Delta, ... (a law enforcement agency that I dispatched for back in the 1990's used this version). Source: was a firefighter and 911 dispatcher in a previous life and still spend a lot of time monitoring fire/ems channels locally just to stay connected to that world. reply dfox 18 hours agorootparentLaw enforcement/EMS often have their own phonetic alphabets and it is not that uncommon to use two at once: one for call signs and second for the actual alphanumeric data (in theory, in practice it gets mixed up, but everybody still understands the meaning) reply g4zj 21 hours agorootparentprevSome of them could potentially be a little confusing as well, such as \"delta\" in game development, \"echo\" in some networking contexts, or \"uniform\" in OpenGL shaders. I don't tend to use single-letter variable names outside of the standard `for(;;)` syntax, but if I did, I don't think I'd replace them in this way. reply Yhippa 18 hours agoprevBut where did “baz” come from? reply 1vuio0pswjnm7 17 hours agoparentAnd quux. reply electricant 4 hours agoprevThe reference to the Monty Python spam sketch is gold :D reply wiihack 9 hours agoprevI remember when I started coding in java many years ago. Everywhere I saw foo classes and I had absolutely no idea what they mean :) reply DesiLurker 2 hours agoprevI though fubar was short for fu*ked up beyond all recognition. that'd have turned into foo-bar. reply wodenokoto 17 hours agoprevSo I guess it is lost to history, but how did a military cynicism sneak into programming? And judging from the origin stories posted it came from failed military campaigns and then was somehow spread to the broader programming community through MIT. There’s a few steps there missing. But on the other hand, a lot of posters in TFA writes “if you knew you knew”, and maybe most people who spread this didn’t know. I mean, I’ve used it without a second thought plenty of times just because. It might be as simple as an ex military professor writing it and students picking it up as “this is how we talk” with basically no one knowing what they are talking about. reply mikewarot 21 hours agoprevNo zot? I don't remember where I picked them up. But it was always fubar and zot. reply temp0826 21 hours agoparentNever heard of zot, but baz reply DougMerritt 19 hours agorootparentZot is (at least in part) from the old comic Wizard of Id and (by the same artist, Johnny Hart and Brant Parker) BC. It was the sound of a lightning bolt (natural or wizard-created). Reprint cover of \"Ala Ka Zot!\": https://m.media-amazon.com/images/I/61hytBWmsqL._SL1000_.jpg reply baggy_trough 22 hours agoprevNo love for quxx? reply mkl 20 hours agoparentScroll down. It's more commonly qux or quux. reply howard941 21 hours agoparentprevNope. Not even for xyxzzy reply donkeyboy 5 hours agorootparentLooks like xyzzy and plugh originated as a magic word in the computer game Colossal Cave Adventure reply golol 20 hours agoprevfoobar should die out. myvariable, mystring, myfunction etc. are better in every way. reply smolder 10 hours agoparentPrefixing things with My is so Windows 95... In place of foo and bar I prefer to go with stuff like one() two() three(), or a() b() c(), timeless classics that need no explanation. reply golol 4 hours agorootparentThe point is that tyoe is an EXTREMELY vaulable information and if you are explaining code to someone it is very helpful to clearly see what are keywords, what are arbitrary variable names, and what are the types of the variables. For example if you show me a programming language where there is a list object and you write list.one(), I don't know if list is a variable or a keyword, and I don't know if one is a variable or a keyword. Much better to write mylist.one() if one is a default function, or mylist.myfirstelement() otherwise etc. I mean everyone knows using descriptive variable names is good practice, but then in a coding tutorial it is somehow fine to use foo, bar, a, b, c? That makes things clearer for someone who understands all the types and the syntax, and wants to see the structure algorithm more clearly. It hurts someone trying to learn the language. reply smolder 3 hours agorootparentYour argument does make sense for teaching an intro to programming type class, where it may not be obvious what is a function name versus variable name. That just hasn't been my audience for a very long time now when explaining anything. I'd likely also go with var1 var2, fn1 fn2 type names if needing non-descriptive placeholders in that case. I mainly avoid foo and bar because to me it's a tired meme, and people tend to understand \"variable names and function names can be anything\" well before they ask \"why does everyone insist on using foo, bar and baz all the time?\" which is just extraneous lore. In my case, I was writing QBasic games many years before I encountered my first foo or bar. reply creativenolo 20 hours agoparentprevIs it not foo() and bar()? MyVariable and… ? reply fragmede 20 hours agoparentprevthey're longer, for one, so no reply jonathrg 20 hours agorootparentHow about x, y, f? reply fragmede 19 hours agorootparentHow about emoji? https://www.globalnerdy.com/wp-content/uploads/2014/06/poopy... reply jonathrg 18 hours agorootparentI have seen some tutorials where emojis are used as metasyntactic variables. Not an improvement reply Max_Ehrlich 21 hours agoprev [–] I understand that these variables have a rich and long history, but if you have ever heard a professor or anybody else say \"foo\" in lecture you will understand why I detest them. They have absolutely no connection to the matter at hand. Since foo is often used before bar, you would think there is an ordering between the two but there doesn't have to be. They are hard to pronounce and easier to confuse. Whenever I give an example I use variable names that actually make sense and are related to the example. I'm glad that I have been fortunate to not see \"foo\" and \"bar\" anywhere in all of the code I've seen in recent memory. reply maccard 21 hours agoparent> They have absolutely no connection to the matter at hand. Since foo is often used before bar, you would think there is an ordering between the two but there doesn't have to be. They are hard to pronounce and easier to confuse. I couldn’t disagree more. The entire point is that the variables are disconnected from the matter at hand. They’re widely recognised as placeholders, single syllable, distinctly pronounced from each other, and have an implied ordering. reply hedvig23 21 hours agorootparentI would agree with the comment you're responding to, too often in tutorials or especially in off hand comments here, I find their usage to assume some common but unindicated convention or subtext and obscure the concept they're trying to convey. reply jiggawatts 20 hours agorootparentThey’re the programmer equivalent of ‘x’ and ‘y’ in mathematics — which programmers don’t use as generic variables because they’re used for “math” embedded in code such as coordinates or measurements. reply thaumasiotes 20 hours agorootparentprev> distinctly pronounced from each other This isn't so much of an advantage for \"bar\" and \"baz\". Those sound pretty distinct to Americans, now, but \"r\" -> \"z\" is a known type of sound change, which implies that for some people they'll sound the same. \"R\" -> \"s\" is attested in Latin, presumably because \"z\" wasn't an option. (Latin fricatives don't have voicing distinctions.) For an only slightly different current example, the second consonants in \"virile\" and \"vision\" are perceived as distinct in American English, but identical in Mandarin Chinese, which is why the sound is spelled as \"r\" in Hanyu Pinyin and as \"j\" in Wade-Giles. reply urbandw311er 21 hours agoparentprev> they are hard to pronounce I’d find it hard to think of two words easier to pronounce— what do you mean by this? reply rmbyrro 21 hours agorootparentProof that for any little thing that existed, exists, or could ever exist in this universe, there will be a non-zero list of human beings unhappy with it. Until the end of humanity, at least... reply jiggawatts 20 hours agorootparentI am unhappy with your characterisation of my natural human trait of having a preponderance for unhappiness with all possible outcomes. reply rmbyrro 6 hours agorootparentProof that the statement is an axiom. And the fact that it's an axiom also falls under the axiomatic principle of guaranteed human unhappiness. reply douglee650 21 hours agoparentprevIt's like business schools using \"widget\" for the product and \"Acme\" for the company — they are dealing in concepts, not absolutes reply Brian_K_White 21 hours agoparentprevThe very reason you say something like foo is to avoid using any specific example that might actually mean something and confuse the listener into thinking it matters and focussing on some irrelevant detail instead of the actual concept being illustrated. You detest that someone says \"thing\" instead of \"house\" or something? \"...so you take a thing-\" \"what thing?\" \"It doesn't matter. It might be anything. So you-\" \"A car?\" Come on man. reply thiht 20 hours agoparentprev [–] When I started to learn programming (by myself), I had a really hard time understanding what foo and bar were and what they meant in various tutorials and blogs. I was already trying to learn the syntax and programming concepts, throwing some unknowns words in the mix did NOT help. For some time I thought foo had special meaning in PHP, or that it meant something in English (not my first language, and I was much less proficient in English at ~14 than I am today). Using foo bar baz qux is lazy when you can easily find countless examples. reply Dylan16807 17 hours agorootparent [–] If they used 'thing' and 'stuff' would you be happier? A B C? What would you suggest as a generic variable name? > Using foo bar baz qux is lazy when you can easily find countless examples. Countless examples of what? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Foo\" and \"bar\" are commonly used placeholders in programming, originating from the military acronym FUBAR, and have been part of programming culture since early computing days at MIT and DEC.",
      "These terms are used to represent unknown values in code examples, helping programmers focus on concepts rather than specific content."
    ],
    "commentSummary": [
      "The terms \"foo\" and \"bar\" used in programming examples originated in the 1960s at MIT's AI Lab, likely derived from the military slang \"FUBAR\" (Fouled Up Beyond All Recognition).",
      "Initially used as placeholder function names, \"foo\" and \"bar\" serve a similar purpose to \"X\" and \"Y\" in algebra, representing generic variables or functions without specific meaning.",
      "The evolution from \"fu\" to \"foo\" may have been influenced by the increasing presence of women in academia, as \"foo\" was considered less vulgar."
    ],
    "points": 138,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1728157929
  },
  {
    "id": 41756209,
    "title": "ByteDance is abusing the free video downloading service Cobalt for mass scraping",
    "originLink": "https://twitter.com/uwukko/status/1842538843720868016",
    "originBody": "earlier today i noticed very elevated traffic to cobalt api that looked a lot like ddos. it turned out to be bytedance!we can&#39;t tell what videos they were downloading or where the original request comes from as it&#39;s built to go around all limiters, but there&#39;s still a pattern https://t.co/gRvvkwnDEb— wukko (@uwukko) October 5, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41756209",
    "commentBody": "ByteDance is abusing the free video downloading service Cobalt for mass scraping (twitter.com/uwukko)129 points by jsheard 8 hours agohidepastfavorite47 comments Tiberium 7 hours agoImportant to note that the author assumes that this is ByteDance, but the ASN belongs to their cloud solution BytePlus, which could be used by other companies. https://x.com/sauceo_/status/1842866301066518875 https://www.byteplus.com/en reply edouard-harris 6 hours agoparentThe author does address this possibility in a reply: > it's very unlikely to be someone else because pricing is astronomical. you also have to \"contact sales\" to get access to anything outside of a free trial. no one would pay that much for a block of ips with terrible reputation https://x.com/uwukko/status/1842866807763308615 reply rfoo 6 hours agorootparent> pricing is astronomical. you also have to \"contact sales\" to get access to anything outside of a free trial You don't have to contact sales if you are a Chinese-speaking customer. And pricing is fine. ByteDance has a different brand for their cloud services in China: https://www.volcengine.com/ [1]. But of course the underlying infrastructure are all the same. This is very likely done by a Chinese customer using ByteDance's cloud service. [1] Well, Alibaba Cloud did this too, and ByteDance is copying Alibaba 1:1 (who in turn is copying AWS) so I'm not surprised. But at least Alibaba named their international brand \"Alibaba Cloud\" and their CN one \"AliCloud\", similar enough. reply Tiberium 6 hours agorootparentprevYes, but this is also pure speculation, since the product clearly exists, has customers, and even has a free trial. reply teractiveodular 6 hours agoparentprevThis. Bytedance's official spider has a clear User-Agent tagged Bytespider, but OP didn't mention what they're seeing. reply jsheard 6 hours agorootparentThis isn't spider traffic though, the traffic pattern indicates that it's a special-purpose bot designed to hit Cobalts internal API in particular. A generic spider probably wouldn't even be able to find the API endpoints that are only referenced by Javascript, nevermind consistently hit the API with a valid video URL from a residential proxy then switch to a different IP address to download the result every time. reply Thomashuet 7 hours agoprevShort version: a service known for evading YouTube's bot protection is complaining that ByteDance is bypassing their own protections. I agree that it's not nice from ByteDance but I find it hypocrite from Cobalt to call it evil. reply lunarmony 7 hours agoparent> cobalt was created for public benefit, to protect people from ads and malware pushed by its alternatives can't say the same for bytedance, which is designed to exploit users with various ads reply whywhywhywhy 5 hours agorootparentIt was created for donation money, lets not do mental gymnastics to justify one type of scraping and vilify another. Scraping is scraping and it's either all fair game or it's not all fair game. reply appendix-rock 7 hours agorootparentprevI feel like you’re missing the point on purpose? Cobalt is asserting that it’s doing good based on the shadier behaviour of its competitors. But can you justify Cobalt in isolation any more than you can justify whoever was scraping it? reply HeatrayEnjoyer 5 hours agorootparentYes. reply h4x0rr 7 hours agoparentprevYou can't compare that... cobalt doesn't DDOS YouTube reply jsheard 7 hours agorootparentCobalt is also completely free, without ads or any other monetization besides donations, it's purely meant to help normal people download videos for normal people purposes. It's not like they're a for-profit data harvesting outfit complaining about getting abused by another for-profit data harvesting outfit. reply Thomashuet 7 hours agorootparentYou're just saying that Cobalt is small and non-profit so they must be good and YouTube and ByteDance are big and rich so they must be evil. But if you only look that what they are actually doing here, it's very similar: bypassing protections to use a service in a way that the service provider doesn't like. reply phoronixrly 7 hours agorootparentBytedance and youtube are evil, but not beacause they are big and rich. Cobalt is good, but not because they are small and a non-profit. reply loloquwowndueo 6 hours agorootparentprevIf bytedance are so big and rich why don’t they implement their own scraping solution instead of abusing a small service like cobalt. reply sangnoir 2 hours agorootparent...Because someone scraping from a Bytedance IP range is not necessarily Bytedance, just like requests from an AWS IP do not imply Amazon authored the spider reply snvy 7 hours agorootparentprevCobalt is bypassing protections to allow legitimate Youtube users to download single videos without causing harm and with no monetary incentives. Bytedance is mass downloading thounsands of videos, all for monetary incentives while heavily breaking the TOS and potentially ignoring copyright laws. Similar, but one is doing way more harm than the other. reply whywhywhywhy 5 hours agorootparent> and with no monetary incentives Donations are a monetary incentive > while heavily breaking the TOS and potentially ignoring copyright laws Cobalt also breaks the TOS and ignores copyright laws, personally I don't think that matters but having a double standard when one company does it \"It's ok when they do it\" and when one you don't like does it you try to use copyright laws and TOS as a weapon just makes me think it really isn't about TOS or copyright is it. Also just gives YouTube ammunition to impose stricter protection against smaller violators like cobalt, like self running yt-dlp reply criddell 7 hours agorootparentprevCobalt didn’t say the DDOS was evil, they said: “bytedance's scraper was specifically built to go around cloudflare & other web security solutions, which is just genuinely evil” So I would say it’s a fair comparison. reply dewey 7 hours agorootparent> built to go around cloudflare Then they either didn't set up CF correctly or they just use the mode in most headless browsers that bypasses default CF protection when CF is not in attack mode. reply afavour 5 hours agoparentprevI don't see the hypocrisy here. Cobalt is a small, free service that results in Google (or so the argument goes) making less profit. ByteDance are a giant money printing machine using that free service for their own ends. They have more than enough resources to not abuse a free one. reply conradfr 7 hours agoprevSome time ago I noticed the ByteDance spider very aggressively scraping my modest side project and, more importantly, modest server. I wrote to them to please stop (I think the address was in the user agent or something), they replied sorry and actually stopped. Not sure why all these crawlers can't pace themselves. reply throwaway98797 5 hours agoparentdevs are promoted on how fast they get done faster, bigger, MOAR sometimes it’s hard to have nice things reply xbmcuser 7 hours agoprevI think Chinese isp can't store some data as they might get in trouble with Chinese censors so they dont cache it. And then if gets slightly viral you see huge traffic from 1 IP that might be a vpn. On reddit torrent channel you get similar question when ahem Linux iso is downloaded 1000s of times from same ip reply lithiumii 6 hours agoparentThat could be a completely different problem. In China many people run PCDN (p2p CDN) for profit. The ISPs detect (and ban) such PCDN nodes by checking your uploaded / downloaded ratio. To increase this ratio thus avoid being detected, these people download popular torrents again and again without uploading at all. reply lawrenceyan 1 hour agoprevWho else just found out Cobalt exists from this post? Wow, this is lit. reply horsebridge 7 hours agoprevAnybody running a site with data that is useful for AI will learn how horrible bytedance is. reply HeralFacker 6 hours agoprevBlackhole Bytedance's ASNs. Cobalt is an end-user tool, so there's not much legitimacy to a cloud service accessing it. reply 3np 7 hours agoprevInteresting timing. The last ~month or so we've seen a drastic shift in YouTube availability. Stricter enforcement of authentication tokens (including breaking some legacy clients) and IP blocking. Loads of Invidious instances either shut down or not able to serve videos anymore. yt-dlp not working at all over an increasing number of VPNs and proxies. Maybe this is some ByteDance engineers getting really desperate and resorting to abusing every youtube proxy service they can because apparently they do have a residential proxy network which doesn't cut it anymore? Unless it's just a cost-optimization measure (residential proxy traffic is relatively pricey). reply A4ET8a8uTh0 7 hours agoparentYeah, I noticed this as well. I think the window of what some might remember as old youtube is closing forever sooner than anticipated. As I may have suggested on this forum before, if you have anything in particular you want to archive, you would be wise to have a plan to do it sooner rather than later. Space is cheap enough and I assume most people won't want to archive the entire net ( I know data hoarders exist and god bless them, but I assume they will be ok ). reply Wowfunhappy 7 hours agorootparentShort of full-on using Widevine/eme for all videos (which I assume would lock out too many devices), how much more could Youtube do? As long as the data is being streamed to your computer, there will be a way to capture it, right? reply 3np 6 hours agorootparentI can very much imagine site-wide requiring Weidevine/eme for anything better quality than 480 and crusty audio not that long into the future. That's already the case for some (anecdotally increasing ) number of videos. reply HeatrayEnjoyer 5 hours agorootparentWhich YouTube videos require that? reply treyd 5 hours agorootparentprevThis would encourage a lot more people to want to break Widevine. :) reply A4ET8a8uTh0 6 hours agorootparentprevQualified yes is probably in order ( and more knowledgeable person can likely chime-in if I misstate something ). It is and always has been a cat and mouse game not completely unlike with game or movie piracy. As you stated, if you can see it on your PC, there is likely means to capture it. Still, notice how most of the low effort avenues are slowly being cut off one by one. I will use non youtube example. Not that long ago, I was able to rip blurays using off the shelf external bluray writer, but new firmware on currently sold drives remove that ability. Now, Google typically won't be ( and isn't ) everyone's hardware provider, but there are ways they could degrade 'non-sanctioned' experience in browser they can ( and do ) control. Granted, in Firefox ( and other non-google browsers ) it may not be as simple, but future there is not as straightfoward either given Mozilla's trajectory and financial dependence ( and moves ). In short, I agree with you but note that initially it was genuinely trivial to download youtube videos. This has changed over the years. reply seanhunter 7 hours agoprevA few big sites that I'm familiar with have seen in the last six months ByteDance become by far the most agressive scraper in their logs. reply FatalLogic 7 hours agoprev>i can safely assume that bytedance was scraping youtube videos by abusing our private api I'm not doubting the OP. But why is ByteDance doing this? What does that company get out of scraping YouTube? reply jsheard 7 hours agoparentLike every other tech giant they're in the AI arms race, and in particular they are building video generation models. It's probably safe to assume they are trying to grab as much of YouTube as possible for use as training material. https://decrypt.co/284353/tiktok-maker-powerful-ai-video-gen... reply ulrischa 7 hours agoprevByteDance ist also massively scraping official governemnetal sites with strange url patterns reply sergiotapia 6 hours agoprevwhy would they use cobalt instead of ytp-dl? is it to mask their origination IPs and such? reply jsheard 7 hours agoprev [–] @uwukko's full thread for those who don't have a Twitter account: earlier today i noticed very elevated traffic to cobalt api that looked a lot like ddos. it turned out to be bytedance! we can't tell what videos they were downloading or where the original request comes from as it's built to go around all limiters, but there's still a pattern first request: json post with content url & settings from a residential proxy second request: tunnel with pseudo microsoft edge on windows user agent & youtube origin/referer, from byteplus ip third request: same tunnel with aria2 user agent & no referer, also from byteplus ip cobalt is a media downloader, mostly known for supporting youtube even at worst times. cobalt's tunnel is either a proxy stream or ffmpeg live render considering all of this, i can safely assume that bytedance was scraping youtube videos by abusing our private api with release of v10 we implemented cloudflare turnstile, but later disabled it due to access issues by a chunk of our users enabling it back brought the server load to normal levels and stopped bytedance from choking our servers cuz they didn't account for this (yet) before resorting to turnstile, i attempted using other cloudflare services, but none of them seemed to help much my theory is that bytedance's scraper was specifically built to go around cloudflare & other web security solutions, which is just genuinely evil this incident caused a few minutes of api unavailability, but taught me that cobalt (and probably anything else) can no longer exist without active bot/scraping protection im really glad that cloudflare turnstile exists because i don't know what i'd do without it here byteplus AS that was spamming requests is 150436 and last seen ip range was 207.166.160.0/21 the amount of unique users on cloudflare analytics rapidly increased by 2.25 times and didn't go down since, while web analytics (plausible) show no increase whatsoever reply gnfargbl 7 hours agoparentSounds like they're using residential proxies for set-up in order to look like normal users, but then switching back to their own ASN for content because residential proxies are expensive. > im really glad that cloudflare turnstile exists because i don't know what i'd do without it here Why not just blackhole the byteplus ASN? reply sandworm101 6 hours agorootparentAnd how many of those residential IPs belong to work-from-home bytedance employees running work laptops? Any large company these days has direct access to a pool of innocent residential IPs. The weaponization of that pool may be more evil than the actual scraping imho. reply miki123211 6 hours agoparentprev [–] Bytedance seems to have increased its scraping efforts significantly. I've posted a canary token[1] URL as a Mastodon post, to check how scrape-resistant Mastodon actually is (it is not resistant at all), and have been getting quite a few hits from the ByteDance spider recently. Last hit is from 47.128.114.151, Mozilla/5.0 (Linux; Android 5.0) AppleWebKit/537.36 (KHTML, like Gecko) Mobile Safari/537.36 (compatible; Bytespider; spider-feedback@bytedance.com) Edit: added missing footnote. [1] https://canarytokens.org reply diggan 5 hours agorootparent [–] > to check how scrape-resistant Mastodon actually is (it is not resistant at all) That's expected, no? It's a social network that is explicitly designed to be as open as possible, as it's using ActivityPub. To be \"scraping resisting\" would be to go against the very goal of Mastodon. reply Aachen 5 hours agorootparent [–] Exactly, this is how I want it to be. I post there because it's not another walled garden that profits from lock-in reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A significant increase in traffic to the Cobalt API was observed, resembling a Distributed Denial of Service (DDoS) attack.",
      "The source of the traffic was identified as Bytedance, but the specific videos or original request sources remain unidentified due to bypassed limiters.",
      "Despite the inability to pinpoint exact sources, a discernible pattern in the traffic was noted."
    ],
    "commentSummary": [
      "ByteDance is accused of using the free video downloading service Cobalt for large-scale data scraping, potentially linked to their AI video generation projects.",
      "The activity might be associated with BytePlus, ByteDance's cloud service, which could be used by other companies, though the high cost and sales contact requirement suggest otherwise.",
      "The situation underscores the tension between data scraping practices and the terms of use set by service providers, as Cobalt criticizes ByteDance for bypassing protections while doing the same with YouTube."
    ],
    "points": 129,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1728211332
  },
  {
    "id": 41756842,
    "title": "WiFi4EU initiative provides free Wi-Fi in public spaces across Europe",
    "originLink": "https://hadea.ec.europa.eu/programmes/connecting-europe-facility/wifi4eu/download-wifi4eu-app_en",
    "originBody": "Download the WiFi4EU app The WiFi4EU initiative provides free Wi-Fi connectivity in public spaces across Europe. Our new app is designed to make it easier than ever to find these hotspots. With the WiFi4EU app, you can access high-speed, reliable Wi-Fi at thousands of locations throughout Europe. Whether you’re traveling for work, vacationing, or simply out and about in your local town, the WiFi4EU app will help you enjoy internet access wherever you go—without the burden of data charges. Why you’ll love the WiFi4EU app Find free WiFi4EU hotspots: Quickly locate available WiFi4EU hotspots near you using our intuitive map interface. No need to waste time hunting for a connection—our app does the work for you. Connect to over 93 000 hotspots across the EU: Access a vast network of more than 93 000 hotspots across Europe. Whether you’re in a major city or a small village, the WiFi4EU app connects you to the best public Wi-Fi options available. Privacy-friendly with no tracking: Your privacy is important. The WiFi4EU app ensures a private online experience with no tracking or data collection. Simply connect and enjoy free public Wi-Fi without concerns. Download now! iOS Available on the App Store Android Get it on Google Play FAQs Is the app for free? Are there any ads on the app? Where can I learn more about the WiFi4EU initiative? How do I connect to a WiFi4EU hotspot? Is my data secure when using the WiFi4EU app? What devices are compatible with the WiFi4EU app? More information WiFi4EU portal More information about the WiFi4EU initiative European Health and Digital Executive Agency (HaDEA) HaDEA implements WiFi4EU, learn more about what else the Agency is doing European Commission Main European Commission page © 2024 WiFi4EU. All rights reserved. The Google Play and App Store logos are trademarks of their respective owners.",
    "commentLink": "https://news.ycombinator.com/item?id=41756842",
    "commentBody": "WiFi4EU initiative provides free Wi-Fi in public spaces across Europe (europa.eu)100 points by nabla9 6 hours agohidepastfavorite89 comments morningsam 4 hours agoNIH as far as the eye can see: Germany already has a grassroots, volunteer-run network of free WiFi hotspots called Freifunk [1], which has pretty decent coverage in a lot of the larger cities. I'm sure similar initiatives exist in other EU countries. Does Wifi4EU leverage this in any way? Nope, there is no way for volunteer-run networks to get included in the app [2]. Instead, it looks like municipalities have to apply for Wifi4EU funding (which they currently can't because \"The next call has not been announced.\"), set up brand new hotspots themselves, and only then are eligible for inclusion in the app's database. [3] [1]: https://freifunk.net/ [2]: https://forum.freifunk.net/t/wifi4eu-vs-freifunk/21686 [3]: https://wifi4eu.ec.europa.eu/ reply cookiengineer 3 hours agoparentI once lived in the area where one of the Freifunk core contributors lives (Mannheim / Heidelberg / Karlsruhe / Rhein-Neckar Region). For years we also talked to the municipalities and the mayors of towns around the area, especially the smaller ones that had troubles getting their internet connections and bandwidths beyond 768kBit/s because they were ignored by ISPs and are kind of the best case for mesh networks. But, as the saying goes, with the incompetent conservatives (CDU) there's no limit on how they waste tax money. If there is a friend of them doing something for more expensive, it's getting bought; because cheaper means always worse, right? Right? For example, in a small town with around 20k citizens, they spend more than 50k EUR per year for two Wi-Fi spots near the local library, and those are \"maintained\" by an energy company. They also had to buy those access points for an initial sum of 20k EUR per access point, because they were very special and integrated in the street lights (not kidding you). Network speeds are less than 10Mbit/s. For that amount of money per year, you could've easily gotten a fibre connection to the library building (which also has less than 10Mbit/s internet connection, so they are kinda fucked once more than 5 people use the internet there). The moral of the story is somewhat that it's so ridiculous how incompetent politicians are when it comes to tech. I'm kind of glad that this is an EU-driven project that's delegated top-down, because that means those incompetent politicians have no excuse to buy overly expensive tech stuff from their golf buddies anymore. reply radicaldreamer 1 hour agorootparentIncompetence or corruption? reply yunohn 2 hours agorootparentprevThough Wifi4EU's website doesn't seem to have any clear indication on expected speeds of the networks they offer? Further, their selection criteria includes things like the historic value of the municipality rather than actual unmet demand or something connected to user desires. reply carlosjobim 2 hours agorootparentprev> The moral of the story is somewhat that it's so ridiculous how incompetent politicians are when it comes to tech. \"Incompetent\"... Everything within Europe and especially within EU runs on corruption. You're either a parasite or a host if you live in Europe. Reap that juicy corruption money by befriending people with influence or pay the salaries and luxurious lifestyles of the people who do with your taxes. reply znpy 4 hours agoparentprevI think the EU initiative is better. Volunteer-run infrastructure is fine, but you cannot rely on it. Can you really blame a volunteer if things break? No. They will hopefully fix it on they own time and dime, and that's good. Volunteer-managed infrastructure is a courtesy. The fact that it's been reliable so far is no indicator of future reliability. EU-driven initiative on the other hand supplies funds (15'000 euros, for proper hardware, maintenance and replacement parts) and uniformity: users in spain will have to go through the same procedures and configurations whether they are in italy, spain, germany, france or any other eu member state (does freifunk does the same?) reply morningsam 4 hours agorootparentI don't think it would've been very difficult to include volunteer networks in the database and allow users the option to fall back on them if an EU-funded network is not available (including a warning about potential eavesdropping on unencrypted communications). reply logifail 46 minutes agorootparentprev> users in spain will have to go through the same procedures and configurations whether they are in italy, spain, germany, france or any other eu member state \"The same procedures\", really? Can you use a wifi hotspot anonymously in Italy? I mean completely without the need to authenticate or provide a mobile number to receive one-time SMS code... I know for certain you can in Germany. Join the hotspot, tick a box to accept the T&Cs, off you go.... reply arielcostas 33 minutes agorootparentYou should if the network is supposed to be anonymous. Though Spanish law, for example, AFAIK requires you to identify customers if you're acting as an ISP (which you are when you offer internet services) or you could be liable for illicit activity. Wonder how this works, since I assume the liability would fall under the public entity who provides the service, not the company installing it. reply ExoticPearTree 2 hours agorootparentprevThere have been projects like this in the past. At least in some parts of Europe, they worked just for the minimum mandated period at the minimum mandated speeds. And the equipment bought was marked up heavily. And looking at the prices for enterprise grade WiFi these days... 15K EUR goes very little. reply matt-p 1 hour agorootparentFor this purpose unifi or similar is more than adequate, each hotspot is presumably just one or two APs. reply arielcostas 31 minutes agorootparentI can't disclose many details, but at the company I work at they did some Wifi4EU installs, and use Ubiquiti hardware, without noticeable reliability issues. Installs do have more APs usually, like for public buildings, libraries... But usually no more than ten. Can be handled with one UniFi Controller and a few APs, so no worries. reply IshKebab 4 hours agorootparentprevCan you blame anyone if \"official\" free WiFi breaks? I doubt it. reply dagmx 3 hours agorootparentYes? You can blame the government that is funding it with taxes. Thats a much clearer chain of blame and expectation of service. reply matt-p 1 hour agorootparentI think they're only paying for install costs and not ongoing fees. reply szundi 4 hours agoparentprevSome russian and chinese volunteers, just what we need reply sulandor 2 hours agorootparentimho \"free wifi\" is not to be trusted in any case reply deepsun 2 hours agorootparentYet users will use whatever is available. E.g. people routinely send SMS with sensitive data, even though SMS is probably the least trustworthy channel. They can only help that by securing the equipment and networks. Telling public \"don't trust these because foreign hackers\" is not going to do much. reply hedora 2 hours agorootparentIf you pay for icloud, there’s a button in iOS that tunnels everything over a tor-wannabe vpn. There’s no real reason to trust wifi access points at this point, or demand they be trustworthy. reply dkasper 4 hours agoprevUnpopular view perhaps, but public WiFi seems obsolete except for where cell signal can’t reach. 5G is usually faster and somewhat more secure than connecting to access points. reply fullspectrumdev 3 hours agoparentDepends where you are. In some European countries (Germany) mobile data is expensive. And mobile coverage even in cities can be kind of shit. reply einarfd 43 minutes agorootparentJust had a look at Ubigi, which I used when on vacation in Japan, and they sell a data only recurring monthly Germany 20 GB data subscription for 19 USD. It's 8 USD more if you want all of Europe. So a bit more pricey. I haven't looked at other vendors, but I don't think there is anything special with my choice of data esim vendor, nor their prices. I haven't seen anything, on their pages, that indicates, that there are stay limits, and if there where, you would expect them to flag that? I wouldn't view these prices as expensive, and they seem not that far from what I pay I Norway. But what is cheap for some, is expensive for others, so what do I know? This also won't help with coverage, of course, and if you want a phone number, you would need an extra SIM for that. reply satyamkapoor 2 hours agorootparentprevSome unfortunately only refer to DE. Every country adapted their data packages but in Germany, the prices are still vintage :/ reply chgs 3 hours agorootparentprevCould you not simply get an eSIM from another country with better costs and use free roaming? reply swiftcoder 49 minutes agorootparentI have some friends in Germany who have been using much cheaper Spanish pay-as-you-go SIMs for the last couple of years. Admittedly not as their daily drivers though - they use them intermittently for hotspots when they don't have access to decent wired/wifi reply looperhacks 2 hours agorootparentprevLast time I looked into this, there were no (cheap) providers that allow you to permanently reside in another country reply ffsm8 2 hours agorootparentDepends on the definition of cheap. I.e. firstly is available in most countries afaik, no matter where your residence is. https://www.firsty.app/ It's not very cheap if you want to use it for months, but plenty of other options around too reply RandomThoughts3 15 minutes agorootparentFirstly is extremely expensive. To give you an idea, my 200Gb/month 5G uncapped speed plan costs me 14 euros a month here in France. Amusingly this plan includes 40Gb/month in Germany at no additional costs which is much cheaper than a German plan. reply eertami 2 hours agorootparentprevThey will charge you for roaming if you're clearly abusing the system (ie, not living in the place you bought the SIM). How long that takes to happen depends on the individual provider - if they didn't then everyone would predictably just use cheaper eastern Europe SIMs. reply satyamkapoor 2 hours agorootparentAgree but despite the roaming at times it can be way cheaper. For instance paying for BElgium operator (not necessarily the cheapest) you can buy an unlimited 5G (limited to 90G in BE without throttle) which in roaming is 31G costing 25 Eur. I’ve also seen some cheaper providers than this in DE but they limit 5G to 50mbps :( reply looperhacks 2 hours agoparentprevSure, but neither my laptop nor my switch (the devices I'd reasonably use with Wi-Fi) support 5G or mobile internet at all reply ExoticPearTree 2 hours agorootparentAll phones these days can act as a hotspot, so basically you always have a WiFi router with you all the time. reply cubesnooper 1 hour agoparentprevCell signal is terrible for privacy, uniquely identifying each individual’s location at all times. Though Wifi can also be tracked, it at least is possible to use anonymously with MAC randomization as is the default on many phones. (Leaving aside countries like Switzerland which outlaw wifi without mandatory registration.) reply jpalomaki 3 hours agoparentprevTechnically this is the case, but due to operator pricing wifi is is still good option. 5G comes with the roaming charges (not so much problem within EU, although there are data caps) and at least local operators here in Finland don't really have good 5G packages for people with multiple devices. reply sunaookami 3 hours agoparentprevMobile data in e.g. Germany is much more expensive so free Wi-Fi is always better. reply moffkalast 2 hours agoparentprevData caps are still a thing for mobile data, coverage is often shit (as a result the speed is hit and miss), and basically only smartphones can use it so you have to faf around with making a hotspot. P2P stuff like webrtc is also blocked because we can't have nice things. reply ciberado 40 minutes agoprevWe have some spots here in Martorell (25km away from Barcelona). Really handy for those public places (like the public gym), as the mobile coverage is not great at all there (strong shadow zone, for whatever the reason). You don't need authentication: you accept terms of use, and you are good to go. Also, there is a cap in the amount of data that you can use each day (based on MAC, I guess), but it is generous enough to allow me to stream for youtube from one hour at the gym, or to work for two hours when I'm in the mood of doing it from the garden near the swimming pool. A friend of mine told me that the EU is paying the local administration for the equipment and installation, but there is an explicit condition in the contract that blocks any kind of personal tracking. So I would say this is a neat project. And 120M€ for an entity of this size doesn't look like an extraordinary amount of money. reply arielcostas 36 minutes agoparentYes, the initiative is from the EU for local administrations (so the Ajuntament gets the money for setting it up), though I didn't know there were bandwidth limits. I can't speak for every install, but some of them do the tracking based on MAC (since it's the only identifier the network gets), so I guess you could avoid it by randomising your MAC and connecting again. reply yreg 5 hours agoprevThis kind of apps/databases was much more necessary before EU got rid of (most of the) data roaming fees. reply GTP 5 hours agoparentThis is indeed an old initiative, it's not a new thing. reply yunohn 2 hours agoparentprevIn my experience, every mobile service provider (in NL at least) has different rules and restrictions on roaming data usage. For example, reduced data quotas, reduced data speeds, no guaranteed 4G/5G, etc. reply waihtis 5 hours agoparentprevyeah I have free roaming up until like 20GB in the EU with a 25e per month contract. Removes really any need to use wifi when travelling reply j_maffe 5 hours agorootparentStill nice to be able to open your tablet/laptop somewhere and get some work done without worrying about consumption. reply efdee 2 hours agorootparentI have 100GB for 25eur/m, I can't say I worry about consumption ;-) reply dewey 4 hours agoprev> The budget of the WiFi4EU initiative is EUR 120 million between 2018 and 2020. Looks like this is not a new thing, it would be nice to have a more unified experience across the EU (Just like https://eduroam.org), but I wonder if it would be more useful to have a unified minimum data cap on mobile networks instead of building out WiFi coverage across cities? reply est 3 hours agoparentExactly what I thought. eduroam was everywhere. If you setup for their authentication mechanism, you get the funding. reply mysteria 2 hours agorootparentThe authentication and registration requirement would be good from a legal perspective, but bad from a privacy one. Then again the alternative is cellular data which is tied to an account anyways. reply jeroenhd 2 hours agorootparentEduroam provides an authenticated tunnel to your home network which provides you with connectivity. The quality of said authentication varies by institution and some provide much better security and privacy than others. The level of privacy you can expect depends on what country you're in and what institution your account is from. So yes, Eduroam is no different than roaming on any 4G/5G network, but it's also not worse. If anything, I trust the backend security of Eduroam providers more than I trust mobile carriers. reply satyamkapoor 2 hours agorootparentprevLove eduroam reply lxgr 4 hours agoparentprevWi-Fi has the advantage of being usable on devices without a cell modem as well, such as most laptops, e-readers etc. That said, now that many phones support dual-SIM, I do wish there was a low-friction way to connect to a local 5G network without downloading an eSIM profile and all that. reply chrisweekly 3 hours agorootparentDoesn't tethering (laptopphoneinternet) solve that? reply lxgr 3 hours agorootparentLargely, but not everyone has unlimited data (especially not when traveling), and my laptop battery is much larger than my phone's too. reply chgs 3 hours agorootparentI’m currently charging my phone from my laptop. And tethering off my phone as the wifi on Amtrak (which could be great if it had a starlink dish on the top) is awful and keeps going back to unauthorised. I haven’t really had much signal problem and I’m not travelling through particularly built up areas (on the New York to Miami train, nearing the GA/FL border) reply lxgr 3 hours agorootparentThat definitely works, but it requires a cable, balancing two devices on a potentially small seatback tray etc. On most trains I've traveled on, Wi-Fi (if available) also works much better since the antenna for that is usually on top of the train, and windows are sometimes coated with a metallic paint to keep out solar radiation. reply efdee 2 hours agorootparentprev\"(especially not when traveling)\" In the EU there are no roaming costs so it's not any different when travelling. reply cubesnooper 1 hour agorootparentWhen I travel to Europe, my North America–only cell service doesn’t work at all. I definitely appreciate free Wi‐Fi at my destinations. reply moffkalast 2 hours agorootparentprevNobody has unlimited data in reality, it's just a marketing term. All providers will throttle you down to nothing at some point sooner or later. reply rvnx 5 hours agoprev80 hotspots in a single building, and none in the city. Seems like public funds were well used again. reply lxgr 3 hours agoparentIt's quite likely that some of these networks already had existing infrastructure used for something else (e.g. local free Wi-Fi under a different SSID, or a network used for some other non-public purpose), in which case 80 hotspots (probably meaning single access points?) would really not be unusual. I've seen this happen in some airports or even entire cities that broadcast the Eduroam SSID as well. Most curiously, I've seen at least one drink vending machine in Japan broadcasting functional Eduroam. reply dewey 5 hours agoparentprevMaybe it's just not adopted in your city yet? > Connect to over 93 000 hotspots across the EU: reply benjymo 3 hours agoparentprevLooking at a few spots around me, it seems it includes some hotspots in public buildings and museums and so on. So on the map it shows e.g. 30 hotspots in a museum, which seems OK as you probably need that many for coverage indoors with the amount of people typically there. reply caseyy 4 hours agoprevWiFi map: https://wifi4eu.ec.europa.eu/#/list-accesspoints reply user070223 3 hours agoprevAlthea Networks provide openwrt firmware which allows to buy/sell data by usage(micro transaction) on the fly, some cryptocurrency is/was involved which make some sense if you think about it(This and Filecoin might be the only projects which it makes sense IMHO). Wider adoption could incentivize the pricing to be as close to commodity. https://www.althea.net/ reply cachedthing0 4 hours agoprevFrom the site: \"Privacy-friendly with no tracking: Your privacy is important. The WiFi4EU app ensures a private online experience with no tracking or data collection.\" This app can only be installed via the GOOGLE/APPLE app stores, so this is a lie. reply dietr1ch 4 hours agoparentIs it not on fDroid? Does it prevent sideloading? reply jeroenhd 2 hours agorootparentNot all free apps are on F-Droid, because a) very few companies/projects want to/can be trusted to provide and maintain an up-to-date F-Droid repository of their own, and installing repositories is less-than user friendly to say the least and b) the standard repository only contains open-source applications _that have had their build system modified to match F-Droid's_ and have been vetted by the project. With F-Droid requiring either of those options by design, I don't think we'll see many government-run projects get F-Droid repositories. That said, I doubt anyone will have a problem grabbing the .apk from somewhere internet and installing it that way. I'm annoyed that they made this project app-based. I'd like to be able to use my computer on one of these networks... reply yupyupyups 2 hours agoprevDoes it require identification? reply rich_sasha 5 hours agoprevHow does this mesh with 5G? I don't use it (old phone) but I understood 5G is meant to offer similar bandwidth - and in fact somehow WiFi can be a part of a 5G network (maybe this bit I'm getting wrong...). reply vel0city 5 hours agoparent5G WiFi and 5G the collection of cell phone technology standards have practically nothing in common other than they're both collection of RF signaling standards. 5G for cell phones means the 5th generation of standards, 5G for WiFi is meaning WiFi networks operating around 5GHz (5.15–5.85 GHz). Which 5Ghz WiFi is quite a ways away RF-wise from the normal 2.4GHz. Just to make things confusing, there's also WiFi 5 (previously known as 802.11ac) which is a collection of WiFi standards. You can operate WiFi 5 on 5GHz. But you could also operate WiFi 4 (previously known as 802.11n) on 5GHz or 2.4GHz. WiFi 6 operates on 2.4GHz or 5GHz, and 6E operates on 2.4GHz, 5GHz, and 6GHz. WiFi 7 and 8 operate on 2.4, 5, and 6GHz. reply rich_sasha 4 hours agorootparentOh yes, I was aware there is WiFi at 5GHz, also called 5G. Rather, I understood that the behemoth that is \"5G mobile internet\" somehow incorporates wifi too. But maybe I just got myself confused there. reply lxgr 3 hours agorootparentMaybe you're thinking of \"unlicensed 5G\", which can operate in the same spectrum as 5 GHz Wi-Fi? reply sva_ 4 hours agorootparentprevgpt: WiFi 7E operates on 5, 6, and 7GHz reply vel0city 2 hours agorootparentThe band for 6GHz WiFi channels does dip a bit into 7GHz (up to 7125MHz) frequencies, but it's still normally called operating in 6GHz mode. You wouldn't normally say you're operating a 7G WiFi network, despite there being two 40MHz channels which exist entirely above 7000MHz Also, those channels aren't allowed in all countries. You can't use those freqencies in EU countries, Japan, Russia, and more. reply anthk 50 minutes agoprev>Privacy friendly >Releases it as closed non-free software No, thanks. reply landgenoot 4 hours agoprevWhy are they using yet another SSID? Shouldn't this be compatible with Openroaming? The map in the app does not load while offline, btw. reply GeorgeSBurgess 2 hours agoparentWiFi4EU phase 1 isn't a federated WiFi network, it uses whatever the WiFi operator uses. This makes a shared SSID less relevant. Not sure if phase 2, which will be OpenRoaming like, is active yet. reply lxgr 3 hours agoparentprevDoes Openroaming require users to create an account? I'm not sure if this does. At a first glance, Openroaming also seems to use \"Passpoint\"/WPA Enterprise, which not nearly all devices support, so at least a backup SSID makes sense. reply GeorgeSBurgess 2 hours agorootparentOpenRoaming, like Eduroam, requires an Identity Provider (IdP). This would be something that you could call an account. At least you would only need to create this once and the WiFi operators wouldn't see the details of your account, only the IdP would. reply lostmsu 2 hours agoprevYou can do it yourself: http://openwireless.org/ reply efdee 3 hours agoprevWhat's the point? 5G is cheap in Europe, with no additional roaming costs between countries. reply luuurker 1 hour agoparentYour comments here seem to be based on the assumption every country in Europe has plans like the one you have (€20/100GB). Those plans don't exist everywhere. reply krick 3 hours agoparentprevThere is some difference in included data packages between home and EU-roaming, but, yeah, it feels like it's about 10 years late. FWIF, 10 years ago I saw much more of free public WiFi. One part why it changed surely is security reasons, the other is just that people don't really need it that much, I think. I definitely don't rely on it that much (I do sometimes, because far cellular networks are not always available). IDK, maybe I would feel different if I used laptop on the go more, but I doubt it. Having a mobile phone seems to cover it now. reply efdee 2 hours agorootparentThere should not be. The law specifically says there should not be a difference in home use vs EU-roaming. I think you raise a good point though. I'm automatically suspicious of free WiFi. reply satyamkapoor 2 hours agoparentprevCheaper definitely depends on the region. In Germany a decent 5G without throttle is extremely expensive. reply hedora 1 hour agorootparentWith universal EU roaming, I usually just get an esim from outside Germany to use in Germany. For one thing, that bypasses the German requirements regarding presenting a physical id in person to get cell service. It’s possible that only works well for travelers though. reply ojagodzinski 4 hours agoprev [–] But why? For 7EUR/month I have 30GB of data transfer + unlimited SMS and calls in my my country + ~8GB of data in whole EU, every month. There is no cheaper option. Who needs public Wi-Fi? EU should increase the competitiveness of communication operators and not finance such stupid ideas. Also map in that app is online only. So you need internet access to get internet access... reply politelemon 2 hours agoparentPerhaps you are assuming that your conditions, plans, and access are exactly the same across all ~500 million people in the EU. reply jeroenhd 2 hours agoparentprev [–] Because of shit like https://www.telekom.de/shop/tarife/smartphone-tarife?tariffI... Data prices vary wildly by country. And no, you cannot use a foreign carrier to get cheap data and roam all year, they'll find you and charge out-of-package pricing for every gigabyte you've used (which isn't the standard rate). reply gruturo 1 hour agorootparent [–] True but if you go to Telekom you're basically _asking_ to pay a lot. A 30 second search cuts that price already by 66%: https://www.alditalk.de/kombi-pakete https://www.nettokom.de/tarif/nettokom-smart-l/ If you can settle for 50Mbps (not really 5G, but already Aldi and Netto had a 100Mbps limit which is... basically the ITU definition of 4G), here's 50GB/month for 13 EUR: https://www.lebara.de/de/vertrag/hello-flex/hello-25-flex.ht... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The WiFi4EU app provides access to free Wi-Fi in public spaces across Europe, connecting users to over 93,000 hotspots.",
      "The app features a user-friendly map for easy hotspot location and offers high-speed internet without data charges or tracking.",
      "Available for download on the App Store and Google Play, with more information accessible via the WiFi4EU portal or the European Commission's website."
    ],
    "commentSummary": [
      "The WiFi4EU initiative provides free Wi-Fi in public spaces throughout Europe, but it does not incorporate existing volunteer-run networks like Germany's Freifunk.",
      "Municipalities need to apply for funding to establish new hotspots, though applications are currently closed, leading to criticisms of inefficiency and potential corruption.",
      "Despite the growth of 5G, public Wi-Fi is still important in regions with limited mobile coverage or costly data plans, aiming to offer a consistent Wi-Fi experience across the EU."
    ],
    "points": 101,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1728219504
  },
  {
    "id": 41756023,
    "title": "Wi-Fi Goes Long Range on New WiLo Standard",
    "originLink": "https://spectrum.ieee.org/wi-fi-lora-hybrid",
    "originBody": "TELECOMMUNICATIONS NEWS Wi-Fi Goes Long Range on New WiLo Standard The new approach could underpin agricultural sensor networks and smart cities MICHELLE HAMPSON05 OCT 20242 MIN READ HUBER & STARKE/GETTY IMAGES",
    "commentLink": "https://news.ycombinator.com/item?id=41756023",
    "commentBody": "Wi-Fi Goes Long Range on New WiLo Standard (ieee.org)98 points by thebeardisred 9 hours agohidepastfavorite22 comments jessriedel 1 hour agoThe overwhelming issues with WiFi are 1. It is slow to connect, taking multiple seconds rather than a few milliseconds. (Wifi unreliability would have much less practical impact if there was rapid reconnect.) 2. The lack of a sufficiently flexible standard interface for logging in and accepting terms, leading to the terrible captive portal workaround. I cannot for the life of me understand why the standards committee cares much about various other minor improvements when these issues are still unsolved after two decades. (Similar complaints can be made about Bluetooth.) reply tjoff 2 minutes agoparent1. Can't remember when this had any effect on my use. Unreliability wouldn't improve either if you cut the connection and reconnected as it would bring down all open connections. No thanks. 2. Been years since I've seen one of those. The use-case is pretty much being abroad or in a really remote area with bad cell reception. And even in those cases it seems those captive portals are going out of fashion. All in all, so far down the list that I probably wouldn't think of them even if I tried. reply dataflow 45 minutes agoparentprev> It is slow to connect, taking multiple seconds rather than a few milliseconds. What is the reason for this? reply zamadatix 25 minutes agorootparentFor standard Wi-Fi the biggest factors for a fresh association are: - Discovery. You have to wait to see which saved networks are broadcasting. Broadcasting more often = less efficient airspace for already attached clients. Broadcasting less often = longer delay for clients to \"see\" the network when they start listening. - External authentication. E.g. if you're doing RADIUS auth or MAC auth with an external database instead of a PSK exchange there is extra time in setting up this exchange and then waiting for the external authenticator to validate it. - DHCP / NDP. Wi-Fi assumes you more or less want to emulate a standard Ethernet + IP session but over this new fangled air connection. This is an additional delay for an additional exchange with the services responsible for this. Typical clients e.g. Windows will also perform extra address duplication checks slowing things further. There are some extensions in more modern Wi-Fi standards for clients that want to \"sleep\" for long periods, immediately do some stuff, then sleep for long periods (like IoT). Particularly TWT (target wait time). These, and more, are already found in purpose built protocols like LoRa/LoRaWAN though. reply londons_explore 8 minutes agorootparentDiscovery could take up to 100 milliseconds. All the others, if properly implemented, are speed-of-light things. Eg. RADIUS auth to an external database on the same physical site should easily be doable within 1 millisecond. It's not like that database has a multi-second queue of other users to connect first. reply saurik 3 hours agoprevI do not have access to the original paper, but I would want to see how this compares to 802.11ah \"WiFi HaLow\". (edit) OK, I got a copy from ResearchGate, and I misunderstood! I had failed to grok the part of the article where LoRa is now supported by the sx128x (as opposed to the sx126x) on 2.4GHz. https://www.researchgate.net/publication/383692369_WiLo_Long... > In this article, we introduce a new algorithmic framework called WiLo, designed to enable directional communication from Wi-Fi to LoRa, which employs signal emulation techniques to enable off-the-shelf Wi-Fi hardware to produce a valid 2.4 GHz LoRa waveform. So, critically, and as far as I can tell this isn't in the summary article, this is purely unidirectional; and so, this isn't about being able to build a network that upgrades the range of WiFi with some tradeoffs: this is about being able to send data from existing WiFi hardware to existing LoRa hardware using a relatively minimal set of changes (though I still don't appreciate how this would practically be done to the existing hardware, and they apparently only simulated this with software-defined radio). > The core innovation of WiLo lies in the signal emulation technique used to generate a valid 2.4 GHz LoRa waveform. Through sophisticated signal processing algorithms, WiLo transforms the standard Wi-Fi signals into LoRa-like wave-forms, while ensuring compliance with the LoRa modulation specifications. This enables the LoRa hardware to decode WiFi signals without requiring any modifications to the hardware itself. The emulation of LoRa waveforms is achieved by carefully manipulating the parameters of the Wi-Fi signals, such as the modulation index, spreading factor, and BW, to closely match the characteristics of LoRa modulation. > We would like to emphasize that WiLo is directly supported among commodity devices, and the USRP-B210 devices are used only for evaluation purposes to measure low-level PHY information, which is inaccessible by commodity devices. For example, a commodity Wi-Fi card such as the Atheros AR2425 can replace USRP-B210 devices as the sender. reply keeda 28 minutes agoparent> (though I still don't appreciate how this would practically be done to the existing hardware, and they apparently only simulated this with software-defined radio). It is my understanding that most modern baseband chips can effectively be considered \"software defined radios\", as most of the modulation/demodulation is performed by the firmware. While the researchers appear to have used a USRP (a dedicated SDR platform), it is conceivable their scheme could be accommodated in the firmware. reply toomuchtodo 1 hour agoparentprev> So, critically, and as far as I can tell this isn't in the summary article, this is purely unidirectional; and so, this isn't about being able to build a network that upgrades the range of WiFi with some tradeoffs: this is about being able to send data from existing WiFi hardware to existing LoRa hardware using a relatively minimal set of changes (though I still don't appreciate how this would practically be done to the existing hardware, and they apparently only simulated this with software-defined radio). This leads me to believe you could flip a switch and turn entire swaths of access points into a broadcast fabric for LoRa? Wifi networks meet software defined radio a bit. reply NewJazz 2 hours agoparentprevI thought this was a HaLow competitor too... Thanks for checking on that. reply Szpadel 3 hours agoprevlet's assume that this takes off and it will become standard addition for our WiFi devices. Given big range of this technology, how this handle air congestion when we would have hundreds maybe thousands of devices in range? I expect low througput of this technology and for IoT that's usually fine, but when we need to share this spectrum with lot of devices we might quickly make this non operational. And this is even assuming we do not have some devices that request much more bandwidth that others. Wirh WiFi 2.4ghz we already struggle with air congestion and quick Google shows that lora have 13 + 8 channels and if I understand it correctly some of them are used explicitly for joining network (?) I think this technology is really cool only if it won't get much popularity reply 486sx33 1 hour agoparentI live on a pretty standard density street , there are a few semi detached homes mixed in. I’d still call it light density. I have 2 x 5ghz channels, 2 x 2.4 ghz channels, and then a repeater with another 2 and 2 In the evening there is so much congestion on every available channel on either band that I can’t watch 1080p tv This long range thing sounds awful. reply zamadatix 36 minutes agoparentprevPeople are responding to this with the mindset of watching 1080p TV not realizing 1 second of a 1080p Netflix stream will use 5x the total daily bandwidth of an IoT device reporting temperature once every 10 seconds for the whole day. It's entirely different use cases and the impact of congestion between the two is like talking about what matters to a garden on Mars vs Earth. The big limitation I see here, and where Wi-Fi has historically failed even with 802.11ah specifically built for the IoT use case and standardized back in 2015, is the \"uses extra power\" bit. Other protocols like LoRa are designed around minimizing power at the end stations. At the end of the day that's often a bigger deal than bandwidth for long IoT. reply neuroelectron 2 hours agoparentprevIt could be silently adopted to allow longer distance for things like map apps that only need a few kilobytes for wifi triangulation. reply brcmthrowaway 31 minutes agoprevIsnt there already 802.11ah? reply malfist 4 hours agoprevI'm curious what the speed would be, kinda strange the post mentions \"mentioning speed\" but not what speed is maintained reply nicpottier 4 hours agoparentThis looks to be about running LoRa like networks on WiFi hardware. Speed on LoRa is not something talked about much as it is more like SMS message passing or the like than IP networking. reply malfist 4 hours agorootparentProbably why it was taking about IoT use. 500 meters for a couple hundred baud connection doesn't seem too ground breaking. Off the shelf 900mhz radios can easily achieve that reply brookst 3 hours agorootparentIt’s about WiFi to LoRa interop, which is nice but not world changing. reply willcipriano 2 hours agorootparentFor smart home applications this could be big. No longer need a hub. reply MostlyStable 3 hours agorootparentprevYeah, the main draw seemed that you don't need a special receiver and that standard networking gear would work, but.....LoRa hardware is not very expensive or complicated. reply calibas 1 hour agoparentprevAssuming it's the same as LoRa, up to 50 kbit/s. reply est 3 hours agoprev [–] tl;dr exsisting Wi-Fi devices goes long range with LoRa protocols The catch: additional power consumption. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The new WiLo (Wi-Fi Long Range) standard is designed to extend the range of Wi-Fi connectivity, making it suitable for broader applications.",
      "This advancement is particularly beneficial for agricultural sensor networks and smart cities, where long-range connectivity is crucial for efficient data transmission.",
      "The introduction of WiLo represents a significant step forward in wireless technology, potentially transforming how remote and urban areas manage connectivity and data collection."
    ],
    "commentSummary": [
      "The new Wi-Fi WiLo standard allows Wi-Fi signals to be converted into LoRa waveforms, enabling long-range communication without needing hardware changes.",
      "This advancement could significantly benefit IoT (Internet of Things) applications by utilizing existing Wi-Fi devices for extended communication ranges.",
      "However, there are concerns about increased power consumption, air congestion, and low data throughput, particularly in densely populated regions."
    ],
    "points": 98,
    "commentCount": 22,
    "retryCount": 0,
    "time": 1728208446
  },
  {
    "id": 41754628,
    "title": "Gokapi: Lightweight selfhosted Firefox Send alternative with AWS S3 support",
    "originLink": "https://github.com/Forceu/Gokapi",
    "originBody": "Gokapi Available for: Bare Metal Docker About Gokapi is a lightweight server to share files, which expire after a set amount of downloads or days. It is similar to the discontinued Firefox Send, with the difference that only the admin is allowed to upload files. This enables companies or individuals to share their files very easily and having them removed afterwards, therefore saving disk space and having control over who downloads the file from the server. Identical files will be deduplicated. An API is available to interact with Gokapi. AWS S3 and Backblaze B2 can be used instead of local storage. Customization is very easy with HTML/CSS knowledge. Encryption including end-to-end encryption is available. Screenshots Admin Menu Download Link Installation Can be deployed in only a few seconds. Please refer to the documentation Usage Please refer to the documentation Contributors License This project is licensed under the AGPL3 - see the LICENSE.md file for details Donations As with all Free software, the power is less in the finances and more in the collective efforts. I really appreciate every pull request and bug report offered up by our users! If however, you're not one for coding/design/documentation, and would like to contribute financially, you can do so with the link below. Every help is very much appreciated!",
    "commentLink": "https://news.ycombinator.com/item?id=41754628",
    "commentBody": "Gokapi: Lightweight selfhosted Firefox Send alternative with AWS S3 support (github.com/forceu)97 points by thunderbong 15 hours agohidepastfavorite30 comments promiseofbeans 9 hours agoApparently Thunderbird are working on reviving Firefox Send and adding encryption. Overall Thunderbird seem to be doing white well from themselves since rejoining Mozilla: >$8m in donations last year I think. reply jasonjayr 6 hours agoparentFF Send already had encryption -- IIRC, Mozilla shut it down because it was being abused. reply mhuffman 6 hours agorootparentAbused in what way? Content? How would they know, if it was encrypted. Or volume? reply brandon272 5 hours agorootparentLikely law enforcement found out about it being used to distribute illegal content and then applied pressure. Companies don’t have a strong history of successfully resisting that pressure. reply compootr 1 hour agorootparentlaw enforcement is so bass-ackward on privacy/security tools Of course, if a hammer is for sale, some will use it to build houses and a subset will use it to hurt people. Just because something can possibly be bad doesn't mean we shouldn't have it reply darkwater 8 hours agoparentprevI just discovered this TH feature the other day when attaching a file to a mail but it looks like it works with plugins now, so you can use different providers. Actually I came here to ask if Gokapi works with that Thunderbird feature. reply Stem0037 8 hours agoprevConsider implementing a 'guest upload' feature with stricter expiration policies and file size limits. This could maintain security while allowing for more flexible use cases, especially in client-facing scenarios where bidirectional file sharing is necessary. reply latexr 1 hour agoprevThe staying power of “Firefox Send” as a brand is baffling to me. It never did anything that wasn’t already available by multiple other services, didn’t do it better, and it was embarrassingly obvious from day one it was another one of those projects Mozilla would abandon in no time. Just goes to show how powerful (and mismanaged) “Firefox” is a brand. reply voiper1 10 hours agoprevAny recommendations for s3/b2 - anyone can upload (or with password) and only the admin can download? Goal: allow customers to upload large files. reply bobnamob 10 hours agoparentTo go full aws on this: - lambda vending s3 pre signed urls with put only permissions - a static page with 20 lines of js that requests one of those urls and does the put I’m not aware of any existing solutions, but your problem seems simple enough that you could roll a solution yourself reply ricardbejarano 9 hours agoparentprevI run https://www.wormhol.org Ping me if you want your own instance. It uploads to S3. I could make it such that only you/admin can download. Right now everyone with the link can. Supports up to 5GB (S3's limit without doing multipart uploads). reply INTPenis 10 hours agoparentprevThis is exactly what I use Firefox Send for in my org. It's not strictly \"admin can download\" but anyone with the password/link can download. The effect is the same. reply toomuchtodo 14 hours agoprevAlso supports Backblaze B2 per the docs. reply ei8ths 2 hours agoprevI need something like this but allows users to upload and send files. I don't want to make everyone admin. reply ktosobcy 10 hours agoprevWould it be better than seafile and it's share link functionality (it can be expired after x days as well) reply your_challenger 12 hours agoprevCan we have this but something server less? Like using cloudflare workers and R2 (I know R2 is S3 compatible) reply tfolbrecht 11 hours agoparentIf this is something you’re interested in it can be reimplemented on CloudFlare workers super easily using the awssdk for s3 (R2) and with D1 as the DB. reply your_challenger 11 hours agorootparentYes, but would be great if someone made it and is open source. Would be cool little side project, no doubt. reply shrubble 10 hours agorootparentThe source code is there - you could try to add the functionality to it :-) reply Larrikin 5 hours agoparentprevYou could use Tailscale send reply gfody 10 hours agoparentprevxkcd949.com is serverless (azure only tho, github.com/gfody/webrelay) reply ornornor 2 hours agorootparentWhoops, http only reply peterpost2 10 hours agoprevAWS S3 scares the shit out of me. The company I worked for misconfiguration one of the buckets and allowed uploads. A couple of months later there was a bill for $15k. Since apparently some spammers were using our service. Which is OK for a company but I would not want to use it as a private individual. reply ksynwa 8 hours agoparentI have never had to use them directly but the use-now-pay-later model feels scary to me for the same reason. Maybe they allow setting the upper cap to the monthly bill (crossing which they don't serve you until you intervene) but I have never heard of it. On the other hand there are many stories extremely ballooned bills for some unforeseen reasons. reply leetrout 7 hours agorootparentThey have \"AWS Budgets\" for alerting you if you go over an amount but no automatic stops. reply ranger_danger 40 minutes agoparentprevNot using the budget reporting feature is the bigger issue here IMO and just highlights that the organization was poorly managed. reply fhke 8 hours agoparentprevNotwithstanding the fact that this was a user misconfiguration, S3 allows you to configure public access blocks to prevent this sort of thing. reply endgame 6 hours agorootparentThese days, you have to remove the public access block AND explicitly write a bucket policy (or set up deprecated ACLs) to allow public access. reply dddw 13 hours agoprev [–] I dig this reply peterpost2 10 hours agoparent [–] That's a different site, this is hackernews. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gokapi is a lightweight file-sharing server designed for Bare Metal and Docker environments, allowing only administrators to upload files, with expiration based on downloads or time.",
      "It offers features like deduplication, an API, support for AWS S3 and Backblaze B2, and customizable HTML/CSS, along with encryption options, including end-to-end encryption.",
      "The server is easy to install, comes with comprehensive documentation, and is licensed under AGPL3, encouraging contributions and donations."
    ],
    "commentSummary": [
      "Gokapi is introduced as a lightweight, self-hosted alternative to Firefox Send, with support for AWS S3, a cloud storage service.",
      "Discussions highlight Thunderbird's attempts to revive Firefox Send with encryption and the challenges of managing AWS S3 costs, emphasizing the need for budget alerts to avoid unexpected expenses.",
      "Users propose features such as guest uploads with stricter policies and explore alternatives like Cloudflare workers and Tailscale for enhanced functionality."
    ],
    "points": 97,
    "commentCount": 30,
    "retryCount": 0,
    "time": 1728186913
  },
  {
    "id": 41756277,
    "title": "The importance of local development",
    "originLink": "https://fastpaced.com/articles/local-development/",
    "originBody": "The importance of local development Local development is crucial for efficient software development, it enables faster iteration, better debugging and ensures consistency between local and production environments. Author David Muhr Published October 6, 2024 A good developer experience (DX) increases productivity, reduces cognitive load, and improves developer satisfaction, leading to higher code quality, faster onboarding, and talent retention. An easy-to-use local development environment might be the foundation for good DX. I regularly think back to the hilarious discussion, where Elon Musk proposed to rewrite Twitter reminding me about the following statement. One of the biggest problems is that you can’t run Twitter locally. When I was at Facebook, you could run all of Facebook on a laptop. There is no way to run Twitter outside of a very bespoke configuration in a datacenter and it makes it nearly impossible to build anything new on it. George Hotz The importance of a good developer experience seems to correlate with the number of people working on a project. As a lone fighter, it’s quite simple to spin-up a bespoke setup, because its configuration is known to a single person. I was a lone fighter myself for much of the research journey during my PhD, which might be the reason why I previously neglected developer experience, except for my own experience. It’s common to think about technical debt when adding new tools or features, but that is possibly not the entire story. The concept of DX-debt is equally relevant, yet it is not sufficiently discussed, in my opinion. Nowadays, there are options such as Draft, Skaffold, Tilt or Garden to spin-up entire clusters locally, or provide pseudo-local development environments. It’s never been easier to provide a great developer experience. What do you think? Updates and Corrections The source for this article is available at Github. If you want to suggest a change, please create an issue on GitHub. Citations and Reuse Figures, and text are licensed under Creative Commons Attribution CC-BY 4.0, unless noted otherwise. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption.",
    "commentLink": "https://news.ycombinator.com/item?id=41756277",
    "commentBody": "The importance of local development (fastpaced.com)94 points by davnn 7 hours agohidepastfavorite81 comments benreesman 6 hours agoThere are lots of reasons to want a robust local development environment, but a paved path or sometimes even the possibility of \"consistency between environments\" is not one of them dear sir or madame. The JankStack in which one piles Python environment jank on top of Ubuntu/Darwin jank, and piles Docker jank on top of the previous, and piles Docker Compose jank on the previous, until you finally arrive at Jank-As-A-Service via something like ECS or EKS gives a terrifyingly comforting illusion of such with roughly the risk profile of speedballing hard drugs while simultaneously free climbing El Capitan. It has the nice ancillary benefit of subsidizing some combination of mega-yachts and private space programs, so that's cool I guess. Sooner or later you're going to link CUDA, or glibc, or some other thing that just doesn't play like that. And then your are capital-F fucked if you didn't invest early on in some heavy-metal hermitic shit and some Gazed into a Palantir foresight around feature flags. reply the_gipsy 5 hours agoparentI get the \"stacking jank but then it's different in thr cloud\", okay, but what's the remedy? Are you talking about Nix, since you mention DLLs? reply benreesman 5 hours agorootparentThere are a number of things that I reach for in such situations, and some combination of Nix/Flox/Bazel is often what you opt for if you've got serious requirements around diverse software stacks, particularly in the presence of accelerators like NVIDIA cards. None of those things is a silver bullet though. They are among the best tools for that class of job, but while Nix and Bazel both have facilities for coping with multi-platform builds with difficult dependencies, you still work hard for it. Nix/NixOS will get you just about perfect builds on a given OS/CPU pair, and Bazel has a lot to offer there too, but when targeting `aarch64-darwin` for local development on Macs and `x86_64-linux` on the deployment target, it's not a free lunch. The documentation and OSS community support and stuff like that has gotten better (a lot better) in the last year or two for both of those things, but I still can't in good conscience recommend either to a shop that doesn't already have experienced staff (or staff that is passionate about getting that experience): it's a steep learning curve because the problem is fundamentally insane in practice if not in theory. For folks that want code to run the same in production as in development and can't categorically commit to languages and libraries that religiously eschew diverse native dependencies but still don't want to go through the looking glass with e.g. Nix the best bet in my experience is to provision dev servers adjacent to the production infrastructure and lean on a massively improved remote development experience in e.g. VSCode compared to even a few years ago. reply rollcat 5 hours agorootparentprevSimplicity. reply VHRanger 6 hours agoparentprevOr, you know, one of the 1350 dependencies deep in that stack hardcoded something stupid and now you can't update another critical dependency. reply benreesman 6 hours agorootparentI'm a particular fan of how `iconv` is ready to freak out and not link if it happened to doomscroll TikTok that morning and for no other reason more easily discovered than via `pwndbg`. reply johnchristopher 2 hours agorootparentHey, I got bitten by iconv writing PHP. reply mananaysiempre 5 hours agoparentprev> piles Python environment jank on top of Ubuntu/Darwin jank, and piles Docker jank on top of the previous, and piles Docker Compose jank on the previous, until you finally arrive at Jank-As-A-Service Don’t demand your language do the job of the operating system and come with a package manager. Your distro has packages that are guaranteed to play well together, use them. reply benreesman 5 hours agorootparentI use a number of operating systems/distributions/package managers, and they all have their strengths and weaknesses. Most can more or less build most stuff in a way that you can run infrastructure on as long as you're not in a nasty cross-platform setting (MacOS development and Linux deployment comes to mind). Off the top of my head I can't think of any language other than Python that manages to be a constant and persistent cavalcade of self-inflicted environment and dependency chemical fires on absolutely every single one of them. Pointing this out usually generates a bunch of \"pipenv/poetry/uv/whatever works fine for me\", and for those folks I am very happy that they don't deal with heavily native extension-backed requirements. Mazel tov. It's a meme: https://xkcd.com/1987/ reply keybored 2 hours agorootparent> Pointing this out usually generates a bunch of \"pipenv/poetry/uv/whatever works fine for me\", I had to use bundler (Ruby) and got some non-descript “missing dev dependencies”. After installing “dev dependencies” (?) for my Linux distro it still didn’t work. The first StackOverflow answer (for Windows) had over a dozen answers with “this worked for me on macOS”. No logic to it, just a random of assortment of commands that happened to work. At that point I decided to use devbox. And give up if that didn’t work (but it did). reply jt2190 3 hours agorootparentprev> Your distro has packages that are guaranteed to play well together… I’ve never worked in an org that had all machines 100% unified on a single distro from dev to prod. reply cletus 6 hours agoprevI live by this principle: If it takes you more than 30 seconds to test a change, you're going to have a huge productivity drain. That means writing a test should be easy and running it should be fast (including any compilation steps). As soon as something takes more than 30 seconds, you've lost a lot of people. They've switched tabs. They're on HN or reddit or they've pulled out their phone. You've broken the flow. Some people can work effectively in an environment where it takes 1-10+ minutes to build something and then you run enough code to test a bunch of changes at once. You might even have multiple clients open at once and you switch between. This doesn't suit me and it doesn't suit a lot of people I've worked with. Where does local storage fit in? Any test you write will probably need data. You don't want to mock out your data storage. You just want to use the same API and have it be backed by a hash map (or whatever) and have it easy to populate that with data. Once you have that, local data for something interactive like a website becomes a natural extension. reply andai 6 hours agoparentI find it irritating when a program's compile time is perceptible. In compiled languages, TCC (Tiny C Compiler) was the only one that came close, though it doesn't seem to be great for production use. This made me switch back to JS and Python. The frictionlessness of \"I made this change and I see the result in the same breath\" is very compelling to me. Fortunately there are fast TypeScript compilers now, which make the process more or less tolerable (in watch mode). I seem to be in the minority here, preferring instant responsiveness. When I run Windows XP in a VM, and press Win+E, an explorer window is presented to me in the next frame, fully rendered. When I do this on the host OS (Win10), it takes several hundred MS for the OS to draw a window, and then I watch with sadness for several moments as the UI elements are drawn one by one. If they had done nothing for twenty years, it would still be perfect. I'm also reminded of Casey Muratori doing the Visual Studio questionnaire. They asked how long do you think it should take to launch. The lowest option was \"ten seconds\", and he found this comical and depressing. VS used to be much faster, too. reply cletus 6 hours agorootparentI view JS as necessary because of the Web but honestly I don't like doing Python for anything serious because it's a dynamic language and I don't want to write unit tests for spelling mistakes. I realize it's the tool of choice for AI/ML/DS (for good reasons). But I'm with you on fast compilation and at Google this was the case, even with C++. There was a ton of infrastructure made around this that wouldn't be easy to replicate but I could certainly compile and run a C++ unit test inI live by this principle: If it takes you more than 30 seconds to test a change, you're going to have a huge productivity drain. > That means writing a test should be easy and running it should be fast (including any compilation steps). As soon as something takes more than 30 seconds, you've lost a lot of people. They've switched tabs. They're on HN or reddit or they've pulled out their phone. And here I am, compiling tailwind CSS on a blade based template consisting of hundreds of partials. ~30 seconds then refresh. FML. reply Washuu 5 hours agoparentprev> That means writing a test should be easy and running it should be fast (including any compilation steps). As soon as something takes more than 30 seconds, you've lost a lot of people. They've switched tabs. They're on HN or reddit or they've pulled out their phone. ADHD can make this worse since a time delay means getting distracted for much longer. I have been working on testing a single issue for months. I wrote the fix the first day, but because it can only be tested in the remote development environment. An environment that I have zero insight into how it works and also requires coordinator cross-team members to work together for several hours together to test the fix! ...Because if we need to make a change pushing takes twenty minutes to test and build the new environment. reply sovietmudkipz 6 hours agoprevAt my work senior leads and architects always shoot down being able to develop locally, especially when devs bring up wanting the capability. The critique is some variation of “it would be impossible to run all services locally” or “it would be too expensive.” So we develop the code and deploy into QA, often breaking things. Cycle times are measured in hours to days. Breaking QA is sometimes a fireable offense. Lol. The leads and architects are correct in my case; it would be impossible and too expensive to do. This is because our services are built on hundreds of bespoke manual configurations made along the way to production. Discovering and pulling into code/automation would be a whole months/year long project in itself. That said there are ways of developing locally without running everything locally. Pull in the code of the service you want to work on locally and just point to QA for its dependencies. Most times it takes some finagling of code but it usually works. Even if everything was running locally, often generating usable data is the biggest barrier. In QA thousands of hands have generated partly useable data. It’s a hard problem to solve since I don’t want to have to know about data requirements for every service. reply fuzzy2 5 hours agoparentWow that sounds like the absolute worst. My condolences. In projects I manage I even try not to use containers for the service being developed. (Only for its dependencies.) Everything that affects cycle times must go. That being said, you should also have a dev environment. QA isn't for development. It'll certainly be cheaper than firing people. reply Pxtl 5 hours agorootparentRight? I do the DevOps/architect stuff at my org and one game changer for testing was configuring it to spin up a separate instance per pull-request. Occasionally things get wonky because all the PR instances share an authentication/authorization server, but by and large it is excellent for being able to quickly demo. But it does mean that you have to be religious about building links and connection-strings in your code. reply rollcat 4 hours agorootparentOnce you have 3 environments (which IMHO is the minimum viable number: dev, staging, prod), it tends to be much easier to generalise that to N, at least from the application side (spinning up the extra infra is a separate beast). It tends to weed out many of the \"if (prod)\"s because there should now be differences between dev & staging that you need to take care of, and sprinkling elaborate switch statements gets tedious really fast - most devs tend to be happier actually simplifying code. I've seen some really nasty offenders though, e.g. actual business logic hidden behind an \"if (window.location.hostname == ...)\". Sometimes it takes a lot of patience to explain that this is how you get production-only bugs that QA will never have a chance to find or reproduce. reply tetraodonpuffer 5 hours agoparentprevI don’t understand some of my colleagues that feel this way either, I’ve been around a long time but having a way to set up a ”local” environment with a local automated build to me seems priority one for any piece of software cloud or otherwise. By “local” I mean self contained, my “local” environment is right now a single cloud Linux VM with kind for kubernetes, all sorts of k8s local monitoring / cert issuing / stubbed things, metallb and openvpn to access (with a local to my computer dhcpcd for DNS resolution) and so on, all building from local and orchestrated by a python set of scripts. All of this works great and has saved me so many times and made development so much faster compared to teams that rely on ci/cd even for basic development (where every commit takes an hour+ to deploy due to tests builds and so on) The only issue with this approach can be services / software that has hard dependencies on specific cloud products you can’t run “locally” but even in that case you can always spin up / tear down super small versions of them to use for the setup. Python has been great to glue orchestrating everything with easy to use kubernetes and docker libraries, and aws/azure cli commands as needed. If you have a product that you can’t easily build or deploy in an automated manner you’re going to have a bad time at disaster recovery time or when the one person that knew how that one piece gets installed is laid off. reply patrakov 5 hours agoparentprevI have also seen a prohibition to have a local copy of the code coming from cybersecurity guys worried about laptops being compromised, for example, through an email with a malicious link. \"Here is a web-based editor; please develop everything there, and at the bottom, there is a terminal to run your application,\" they say. reply acdha 34 minutes agorootparentYes - that’s an indictment of the security group on multiple levels (Kerckhoffs's principle, failure to deploy FDE / MFA, etc.) but depending on the organizational culture the cost might be shifted to the development groups and not everyone has senior technical staff able to challenge it. reply rcxdude 6 hours agoparentprevYeah, this is the situation being argued against. If you don't focus on making your environment reproducible, you wind up tangled in a mess no-one can understand. I imagine you also don't expect to be able to get things running again after a disaster strikes. reply simonw 7 hours agoprevI go back and forth on this. On the one hand, maintaining local development environments that work reliably across larger team if developers is a HUGE cost in terms of time and effort. Developers are amazing at breaking their environments in unexpected ways. It’s common for teams to lose many hours a week to problems related to this. So I love the idea of cloud-based development environments where, if something breaks, a developer can click a button on a website, wait a few minutes and have a fresh working environment ready to go again. But… modern laptops are getting SO fast now. It’s increasingly difficult to provide a cloud-based environment that’s remotely as performant as a M2 or M3 laptop. reply acdha 6 hours agoparentTwo thoughts: * in every single case I’ve seen, the developers who broke their local environments that badly had significant skill deficits which affected their general productivity. Investing in training paid dividends far beyond not having to deal with their local environment getting hosed since they also stopped creating massive security and performance problems in production. * building a cloud-based development where someone can refresh it automatically means you’ve identified a reliable process for installing and configuring everything. That same process can be run locally, probably using the same container definitions for everything except the parts they’re focused on. reply dimgl 3 hours agorootparent> in every single case I’ve seen, the developers who broke their local environments that badly had significant skill deficits which affected their general productivity. Investing in training paid dividends far beyond not having to deal with their local environment getting hosed since they also stopped creating massive security and performance problems in production. I mirror this sentiment. Another one that I've commonly seen: a bit of a yellow flag if a developer is struggling with Git. Becomes a red flag if the issues continue to happen after training. Usually means they don't understand other technical fundamentals. reply keybored 2 hours agorootparentA lot of developers struggle with Git. The only reason I don’t is because I’m interested in version control (too much according to some people I argue with). Well I say that I don’t struggle but I’ve never had to use submodules.[1] [1] Torvalds: people say that submodules is hard to use. True. But it’s gotten better now/it’s getting better. (Google Tech Talk 2007) reply acdha 59 minutes agorootparentFor me it comes down to how often something is holding you back. It’s perfectly reasonable for someone to only use the core Git operations, but if they’re losing work or having trouble collaborating that’s when I start to expect them to recognize that and try to improve. reply IX-103 5 hours agorootparentprevIf you've never seen good developers bork their local environments then you clearly haven't worked on a large enough and complex enough project. I worked on a large project that needed to support development on many platforms. The amount of scripting for the git hooks and build hooks alone required its own development team. When subtly incompatible changes in git hooks rolled out, you would see a few people that ran commands in just the wrong way to bork their repository. These commands are usually fine, but when combined with an otherwise invisible change in the hooks, would just break things. Now the actual breakage rate was low, like 1 in 1000 in a given month, but with as many developers as were working on this project that was always a couple of people that had to nuke their local repo from orbit (it's the only way to be sure). reply acdha 4 hours agorootparentNote that I’m specifically referring to breaking it in a way which is significantly harder to recover from than rerunning a known setup process (Simon’s comparison to a cloud environment where you could reset it on-demand). It’s not about never making mistakes, it’s about having a good conceptual understanding and habits around configuration management. reply pushtheenvelope 6 hours agoparentprevDevbox aims to solve this very problem: https://www.jetify.com/devbox reply rcxdude 6 hours agoparentprevWhat about local development precludes having a consistent, repeatable development environment? At worst you can distribute an environment the same way you would on the cloud. reply mtndew4brkfst 5 hours agorootparentIn practice, the number one way to bungle a previously-working local environment at many of my past roles has been \"brew upgrade\". The number two way was to have MacOS and at least one Linux distribution used for local dev on the same team, but one vastly outnumber the other. While I am very pro-containers as a deployment target I am also very resistant to containers in the critical feedback loop of local dev, chiefly due to iteration speed and performance/battery overhead, which was much more glaring when the Intel chips were all we had. I can't endorse Nix in any capacity these days but it did seek to address multi platform environmental consistency, without containerization as your LCD. reply rcxdude 5 hours agorootparentI firmly believe MacOS and linux should be considered as different as windows and linux from the point of view of platform support. If the only time your software runs on MacOS is during development, you're probably wasting your time supporting another platform, and your developers are never developing against the target. \"It's POSIX so it's the same\" is a lie in basically all the ways that matter, you'll have a much easier time with a VM (by which I mean developing in the VM, not building a whole new VM/container in your development loop) (And I don't think I've ever seen a dev macOS setup that could be called clean, but it's been a long time since I've interacted with that, so maybe the situation has gotten better since then) reply simonw 2 hours agorootparentprevWith local development the user has an almost unlimited array of other things they can do that might break stuff. With cloud, they can't. They could drop their laptop out of a window and still be up and running productively a few minutes later (given access to a computer with a keyboard and a web browser). reply teeray 6 hours agoparentprev> the idea of cloud-based development environments where, if something breaks, a developer can click a button on a website, wait a few minutes and have a fresh working environment ready to go again. Until the cloud development environment inevitably breaks, and your entire development team’s productivity drops to zero. reply simonw 2 hours agorootparentRight, but you can have a dedicated team working on preventing that from happening - including robust automated tests that exercise the cloud development environment itself, checking that newly launched environments come up and work as they should. I assert that such a team will be a lot more productive than the exact same sized team dedicated to local development support instead. reply pydry 6 hours agorootparentprevThis can and does happen with local environments too. Ideally both options would be available using a wrapper that ensures consistency across CI, cloud dev and laptop dev environments but I havent had that luxury anywhere. reply teeray 5 hours agorootparent> This can and does happen with local environments too. Absolutely—but when it does, it’s not evenly distributed. Some of your team can remain productive. Some can pair up. On the other hand, when the cloud development environment goes down, you always send your dev team home for the day. reply phito 6 hours agoparentprevDocker makes it really easy reply pards 6 hours agorootparentThis. Locally, we run the apps/services in our IDEs and all the supporting infra runs in Docker via docker compose: messaging systems, databases, caches, etc. This has the added benefit of ensuring that developers don't interfere with each other during development. Your Kafka messages will only be picked up by your processes. Your database changes don't impact anyone else until they're pushed. reply simonw 2 hours agorootparentprevIf only that were true. Source: several years of supporting other developers working with Docker-based local development environments. It certainly helps, but there's still SO MUCH that can go wrong. reply exe34 6 hours agoparentprevcan you have a central conda install? or zip a full conda env? with nixos, you can have a single default.nix and serve from a binary cache. reply austin-cheney 5 hours agoprevThe article does not provide numbers. The reason why local development is important is because of speed, like the article says, but the article supremely under sells this. We could easily be talking about several orders of magnitude performance improvements. When I first joined travel company Orbitz they had a build that took just over 90 minutes. Of course it was a Java first environment, so I needed to test a small one line change to the UI (that had absolutely to do with Java) I still had to wait 90 minutes. So, I just planned on doing nothing all day. In my personal software I start crying if my builds take longer than 12 seconds. The difference is that I really enjoyed getting paid to watch YouTube for 90 minutes stretches 5 or 6 times a day. It wasn't my time. It was their time. With my own software, though, it absolutely is my time. Small improvement increases to trivial items is a cost savings that adds up. Its like a flash flood. A rain drop isn't going to drown you. A bunch of rain drops are still insignificant, but when there are too many rain drops you are under water. Just think about how floods work, because its still just tiny rain drops. One increase does almost nothing on its own, but it enables other things to occur more frequently. When that happens everywhere you have a performance flood. Suddenly you can test automate several hundred features of your application end-to-end in less than 10 seconds. When that does occur it changes peoples behavior and their perceptions of risk, because now all options are discoverable in a nearly cost free manner for everyone. You will never ever get to experience that freedom if you are drowning in dependency and framework stupidity. reply CharlieDigital 5 hours agoprevFor this reason, I strongly recommend Google Firebase. The local emulator suite is one of the best I've seen[0] (would love to see others). Powerful and easy to set up[1]. It includes a top notch emulator for auth which gives you a full SSO flow as if going through Google's OAuth flow and makes it easy to get otherwise complicated auth flows nailed down. The database and Functions runtime emulators are excellent and make it easy to prototype and ship. Comes with a Pub/Sub emulator to boot for more complex async processes. You can export the emulator state to disk so you can share it or bring it back up into the same state. If you need to interface with relational DBs, you just use a Pg or MySQL container. Really phenomenal and would love to find other stacks with a similarly solid emulator suite. It's a strong recommend from me for any teams that value speed because it really allows much, much faster iteration. Edit: Dear GCP team, please, please - never kill this thing. [0] https://firebase.google.com/docs/emulator-suite [1] https://github.com/CharlieDigital/coderev/blob/main/web/util... reply nicoburns 5 hours agoparentFor this reason I strongly recommend AGAINST Google Firebase. The local emulator is a big improvement over not having one, but it still absolutely sucks compared to a stack where you can run the production versions of the tools locally. If you really need a 3rd-party Auth solution then it could be good for that. Otherwise I would recommend to sticking to open source tools on top of a hosting provider that gives you containers and a managed (postgres or mysql) database. reply CharlieDigital 3 hours agorootparentIt's easy enough to integrate with Google Cloud Run. I run a mix; some apps are pure Firebase and Functions. Some run Cloud Run serverless containers connected to Supabase upstream and Pg container locally. Firebase is quite flexible as a chunk of it is a facade for Google Cloud services (storage, auth API, CDN, Cloud Run). Very flexible model of upscaling services progressively. Functions -> Cloud Run -> GKE Autopilot -> GKE reply Dansvidania 5 hours agoprevGood local dev-env is vital for productivity, but even more so for dev satisfaction and engagement. I have been arguing with myself on what a good dev-env is for as long as I have been working in enterprise software dev which by now is about 10 years. All I know is that attempts to reproduce prod via tilt and similar have not been successful (I have witnessed 3 attempts). The promise of \"one dev env for all teams\" quickly falls apart. The main problems with this are IMO: - 1. there is a false sense of encapsulation of complexity: you don't need to know how the components of non-owned services work, until something breaks (and break it will), and then you really do. - 2. #1 + docker + k8s + kafka + graphql etc... make complexity seem very cheap. - 3. add a minimum of deadline pressure on teams, and quickly they will stop caring about keeping the dev-env images up-to-date and/or working. I would rather have intimate familiarity with what my services depend on, which is much easier to get by running these dependencies somewhat manually, close to natively. You can be sure that your colleagues will come knocking if complexity is not respected. But this seems hard to package as a product... reply jawns 6 hours agoprevLocal development works great ... until it doesn't. And then getting it to scale past a certain point is excruciating. My favorite argument against local development, however, is that isolation is a bug, not a feature. When I want to show another developer what I've built, or get help debugging an issue, I don't want to have to call them over to my laptop or do a screensharing session. I want them to have access to the same machine that I have access to, with the same data and configuration, and having cloud-based dev boxes enables that. reply largest_hippo 6 hours agoparentGreat point, and you're right that's easier if it's already cloud-based. But with ngrok-type utiltities (and good old SSH) there's nothing stopping us from saying \"hey, check out this weird bug on my local instance -- here's the url/ssh hotsname.\" The downside is that it's often harder to spin up multiple locals than multiple cloud instances, and so it's harder to publish a url for the team to play around with for a day (\"I'm building this new feature, but I'm not sure about the UX, what do you think?\"). But IMHO the benefit of being able to nuke and recreate a dev environment in seconds (rather than the ~10mins it sometimes takes for a cloudsql instance to spin up) is worth it. reply mirekrusin 6 hours agoparentprevLocal dev doesn’t imply you can’t have deployable PRs. reply plaguuuuuu 6 hours agoprevLocal development is extremely common in my area because the tooling is so good (dotnet). However the most productive I've been was on a team where local development, even on a single service, was eschewed for the most part. We had tests that would cover 90+% of the codebase - more importantly nearly 100% of what was worth testing - and would routinely deploy things into staging from master that had never even been executed as a whole app, let alone run in anger and tested with live dependencies. The coverage was good enough that everything actually held together really well. I'd never shipped anything that efficiently prior or since, it totally changed my view of TDD as being a time-consuming but safe and conservative regime vs my experience of it dramatically speeding up iteration. The only thing that started gnawing at my brain (while admittedly operating a far lesser sized constellation of distributed services than, say, Facebook) was that there is no way of unit testing (or even statically verifying with TLA+ or something) the wider-scale structure of services, at least that I'm aware of. At some point I might knock something together involving specs and code generation but I dunno. reply tmountain 6 hours agoprevMy team uses Supabase as our primary “backend” (API layer, auth, subscriptions, queuing, etc). It runs beautifully locally via the Supabase cli. We use migrations to sync the local DB to our production DB. Our app is written in NextJS. I can go from a fresh install of MacOS or Linux to running our app in less than 15 minutes. This has given us a huge advantage when testing, onboarding, and debugging weird issues in the production app. reply bsnnkv 6 hours agoprevWhenever I see a flake.nix in a project I'm more likely to contribute because I know I'm not going to get stuck in dependency hell before I can even test a single change. Reproducible builds are what I've found to be the most important part of any local dev experience; standing up local databases, message queues etc required for whatever is being developed has always been relatively simple in comparison. reply bob1029 6 hours agoprevI'm fighting with a variant of this right now - Attempting to build a multiplayer game with dedicated servers & master server authority. I've got 4 computers involved to run the full dev iteration (2 for 1v1 clients, 1 for master server and 1 for dedicated server host). The clients I am running in my local LAN with both servers in AWS. Attempting to do all of this on the local machine will mostly work, but it fails to exercise a lot of the networking concerns (public IP detection, port assignment, etc.), and weird edges crop up as latency grows beyond 0ms. It also makes it impossible to test with other players on other LANs without reaching for complicated networking setups that add even more confusion when things go wrong. I could write a bunch of bandaid \"if editor attached\" code throughout, but I also like the idea that I am testing the final thing on the ~final hardware and there isn't going to be any weird dragon fight after this. reply viraptor 5 hours agoparentHave you seen https://github.com/Shopify/toxiproxy ? Maybe you could use this / similar setup to test with more realistic network behaviour. reply bob1029 3 hours agorootparentI am using UDP transport so options are fairly limited. reply roland35 6 hours agoparentprevIt sounds like your experience is a good example of having a full integration test setup which is basically what the \"real thing\" is. For doing end to end tests, that is likely required! But as the project matures over time hopefully you can carve out code which can be tested without the network stack. reply wiradikusuma 6 hours agoprevThanks to Docker, whenever I start a new project or team, I always ensure that everything can be run locally (the DB, Redis, services, website, and mobile app). But it's hard to be disciplined, especially when reproducing bugs, so developers usually end up using a \"shared\" test server. Also, these days, I use Cloudflare more and more. They're very affordable, and deployment is a breeze for the simplest cases. But local development seems to be an afterthought. I built a service that uses some of their dev offerings. Some work locally (using Miniflare), and some can only work remotely (dev environment in your Cloudflare account). Imagine when you need both kinds of offerings! reply garydevenay 6 hours agoprevNot having a local development env is a total productivity burner for me. reply rcxdude 6 hours agoprevI do think most of the comments here are missing the core point, which isn't so much about whether your development environment is running on your laptop or on the cloud, but more that it's possible to stand up your own environment with a functional version of your product. It's distressingly common that this isn't possible, and you can only test and integrate your code in a single shared development environment, or worse, production, and that neither of these are actually reproducible. reply davnn 6 hours agoparentThat's the point I was trying to make, which is also why I brought up 'pseudo-local' development environments in the article. reply Aeolun 6 hours agoparentprevWe worked like this for 5 years, and the highlight of the new project we’re finally starting is to keep it all reproductible from the start. It’s a constant fight though. reply ehaikawaii 6 hours agoprevIf you have a local development environment that actually works, you have already done the hardest piece: Identified every single thing needed to stand up a functional version of your app and made the rails to do so in a repeatable fashion. You should do that anyway, and whether the dev environment is true local or runs using some special k8s hooks to some dev clusters or what have you is immaterial. reply Ozzie_osman 6 hours agoprevAgreed. I've seen this referred to as inner loop (local dev environment and work flow) and outer loop (deployment, production, etc). A team needs to optimize both loops, though each should have slightly different priorities in terms of speed, safety mechanics, etc. reply anonzzzies 6 hours agoprevWe went remote-only dev years ago; definitely never going back. It's such a pleasure to always have the same stuff everywhere, no matter what and on any device. reply hmottestad 5 hours agoparentYou have a single shared server that everyone has to book time on to run and debug their code? Or does everyone have their own server that they ssh into? Cause I consider that as close to local as you can get without running stuff on your own laptop. Would be very annoyed though those few times I work on a plane or a train with spotty 4G/5G. reply keybored 6 hours agoprev[deleted] reply mhuffman 6 hours agoparent>Only tangentially related of course. But we end up using the Web (webapp in this case) for all sorts of things where “works on my machine” is not even a potential problem. I am not sure how much web development you have done, but the \"works on my machine\" problem can and does show up. And not just machines, different browswers and different browser versions. Unless you go very simple, you can get a graphic designer to point out plenty of problems for you. reply keepamovin 5 hours agoprevI concur with this. Developing BrowserBox locally is useful for many reasons. Stress testing the application by stretching it like a rubber sheet to wrap around as many different operating systems as possible is a useful way to iron out various bugs that affect more than one system but may not have been triggered in an easier development process. Running the application locally is also a way that many people first download and try it, so ensuring a reasonable experience on a laptop is quite important. Iterating on front-end code with a TLS certificate from mkcert provides access to all the JavaScript APIs you’d expect to see on the public internet under TLS. Running the browser back-end on different OS and architecture targets is a good way to control for or “fuzz against” the quirks you might see in interactions between the operating system, file system layout, the behavior of common Linux-style command line utilities, and the creation of different users and running processes as them. Many of these things have slightly different behaviors across different operating systems, and stretching BrowserBox across those various targets has been one of the strong methods for building stability over time. My respect for Bash as the lingua franca of scripting languages has grown immensely during this time, and I’ve felt validated by the Unix-style approach where commonly available tools are combined to handle much of the OS-level work. Adaptations are made as needed for different targets, while a lot of the business logic is handled in Node.js. Essentially, this approach uses Bash and Linux philosophy as the glue that sticks the Node.js application layer to the substrate of the target operating system. I made this choice a long time ago, and I’m very satisfied with it. I increasingly feel that it’s the validated approach because new features requiring interaction with the operating system, such as extensions or audio, have been well-supported by this design choice for building the remote browser isolation application. An alternative approach might be to stick everything into first-class programming languages, seeking a Node library for each requirement and wrapping anything not directly supported in a C binding or wrapper. But I’ve never found that practical. Node is fantastic for the evented part of the application, allowing data to move around quickly. However, there are many touchpoints between the application and the operating system, which are useful to track or leverage. These include benefits like security isolation from user space, permissions and access control, and process isolation. The concept of a multi-user application integrated with a Unix-style multi-user server environment has been advantageous. The abundance of stable, well-established tools that perform many useful tasks in Unix, and targets that can run those tools, has been immensely helpful. On the front end, the philosophy is to stay at the bleeding edge of the latest web features but only to use them once they become generally available across all major browsers—a discipline that is easier to maintain these days as browser vendors more frequently roll out major, useful features. There’s also a policy of keeping top-level dependencies to a minimum. Essentially, the focus is on the Node runtime, some WebRTC and WebSocket libraries, and HTTP server components. Most of the Node-side dependencies are actually sub-dependencies and not top-level. A lot of dependencies are at the operating system level, allowing us to benefit from the security and stability maintained by multiple package ecosystems. I think this is a sound approach. Porting everything to a Windows PowerShell-type environment was a fascinating exercise. For the front end, having virtually no dependencies except some in-house tools fosters faster iteration, reduces the risk of breaking changes from external sources, and minimizes security risks from frequently updated libraries with thousands of users and contributors. Some of the ways we’ve approached security by design and stability by design include adopting a development process that is local-first but local-first across a range of different targets. reply Pxtl 5 hours agoprevImho this is a problem with many DevOps pipelines - we use Azure DevOps and the inability to run the Azure pipeline yaml files locally means I end up just writing all our deployment as PowerShell scripts and the DO pipeline just calls them. Local deployment is not negotiable. And I still come back to Spolsky's \"Joel Test\": there must be 1 command with no extra steps that you run to get running version of the software on your local developer machine. reply komali2 5 hours agoprevIf you can't build and run the full environment locally, even in a diminished state, how can you debug the production stack? I'm always advocating for ridiculously fleshed out readmes that describe in detail how to run every part of our stack locally, how to deploy it, and how it's running on the prod servers. If I die I want one of the juniors the next day able to report on how to do anything I do. reply FpUser 6 hours agoprev>\"Nowadays, there are options such as Draft, Skaffold, Tilt or Garden to spin-up entire clusters locally, or provide pseudo-local development environments. It’s never been easier to provide a great developer experience. What do you think?\" I think fuck it. I run my own company where I develop software for clients and the last thing I need is for my environment and tools is to be controlled / selected by some corporate imbecile. reply bagels 6 hours agoprev [–] You can't run Facebook on a laptop either. reply ramchip 6 hours agoparent [–] Perhaps it was possible when George Hotz (the quote's source) worked there in 2011? reply kleinsch 6 hours agorootparent [–] He said this in 2022 when it was definitely not possible to run FB on a laptop either. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Local development is essential for efficient software creation, offering faster iteration, improved debugging, and consistency between local and production environments.",
      "A good developer experience (DX) enhances productivity, reduces cognitive load, and increases developer satisfaction, which can lead to higher code quality and talent retention.",
      "Tools such as Draft, Skaffold, Tilt, or Garden facilitate the creation of effective local development environments, crucial for avoiding DX-debt, especially in larger teams."
    ],
    "commentSummary": [
      "Local development environments are essential for productivity but can be difficult to maintain uniformly across teams.",
      "Cloud-based environments provide easy resets, yet modern laptops often offer superior performance.",
      "The decision between local and cloud environments hinges on balancing speed, reliability, and the ability to mirror production conditions."
    ],
    "points": 94,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1728212495
  },
  {
    "id": 41752327,
    "title": "Router Security",
    "originLink": "https://routersecurity.org/",
    "originBody": "Router Security Website by Michael Horowitz Home Site Index Bugs News Security Checklist Tests DNS Resources Stats Search Popular Pages Also see my Defensive Computing Checklist website This site focuses on the security of routers. This includes both configuration changes to make a router more secure, and, picking a router that is more secure out of the box. If you are interested in faster WiFi, there is one page on extending the range of a Wi-Fi network. Sections of this page Why Router Security Secure Router Configuration - the SHORT list Secure Router Configuration - the FULL list Final Steps Some Additional Thoughts Ongoing Care and Feeding and Defense Hacked Router? Picking a Secure Router Conference Presentations You Are Safe Here To be clear, this site is about ROUTER security, not ROUTING security. There is nothing here about MANRS (Mutually Agreed Norms for Routing Security). See the recent updates to this site. Why Router Security Why devote an entire site to router security? I used to be like you. That is, I would buy a router, it would work fine and I would ignore it for years. However, after some huge router flaws, affecting millions of routers, caught my attention, I started following the topic more closely. As a Defensive Computing guy, I eventually realized that I needed to upgrade my own router security and get more up to speed on the topic. After all, if a router gets infected with malware, or re-configured in a malicious way, most people would never know. There is no anti-virus software for routers. I am not alone in pointing out the sad state of router software/firmware. Router security may be a dull and boring topic, but it's important. For proof, see what can happen if your router gets hacked. For the latest on routers, see the Routers in the news page. Non-techies can start at the Introduction to Routers page, which discusses what a router is conceptually, then describes the hardware and the many ways to communicate with a router. There is also a page on Access Points and an overview of Extending the Range of a WiFi network. This site has NO ADS. If you see ads, either your browser, computer or router is infected with adware. It also does not use Google Analytics or any third party analytics. In fact, it doesn't use any third part scripts/software of any kind. The search feature uses DuckDuckGo, but does not load any scripts. Secure Router Configuration - the SHORT list top This relatively short list of configuration tweaks can greatly increase the security of any router. Change the password used to access the router. Anything but the default should be OK, but don't use a word in the dictionary. More... If your Wi-Fi network(s) is using the default password, change it, even if it appears to be random. A Wi-Fi password should be at least 16 characters long. More... If you are using a default WiFi network name (SSID) change it. When choosing network names, don't identify yourself. More... Wi-Fi encryption should be WPA2 (with AES, not TKIP) or WPA3 or both. More... Turn off WPS More... Turn off UPnP Use a password protected Guest Network whenever possible, not just for guests but for IoT devices too. If the router has a web interface, Remote Administration is probably off, but since this is so very dangerous, take the time to verify that it is disabled. If the router is administered with a mobile app and a cloud service, disabling remote access to the router is unchartered territory. Lotsa luck. Port forwarding is an opened door (technically an open TCP/IP port). Poke around the router configuration to make sure there is no port forwarding going on. There is a small chance that something on your network needs a port to be forwarded, but every forwarded port is a security risk. For years, turning off IPv6 (IP version 6) was on the long list below, but as of August 2021, I think it belongs here on the short list too. Very very few people need it and in 2021 it was disclosed that there is a possible security issue with it. If the router can not disable IPv6, the NSA recommended (Feb. 2023) to \"ensure your router supports IPv6 firewall capabilities.\" Periodically check for new firmware. At some point you will go a year or two, or more, without any updates. That's when it is time for a new router. Secure Router Configuration - the FULL list top For the techies amongst us, the list below is as comprehensive as I can make it. Perhaps a spy agency would be the only one to implement everything on the list. Pick and chose, and implement as many as you can. If the router is new, see my suggestions for setting up a new router. Basic plan: make the most obvious few changes with the router off-line, go online behind another router to get the latest firmware, then make the rest of the changes. Change the password used to access the router (this is not a WiFi password). Don't use a word in the dictionary. Two words and a number should be fine (7coldapples). For more, see my router password advice. This is often the hardest step as it requires knowing how to access the router. If the router lets you change the userid used to logon to the router, change it If any of your Wi-Fi networks (a router can create more than one) use a default SSID (network name) then change it. Do not pick a name that makes it obvious that the network belongs to you. More... For Wi-Fi encryption, use WPA2 with AES or WPA3. If there is a choice to use TKIP or AES, opt for AES. There may also be an option to use both TKIP and AES - just use AES. Wi-Fi encryption will improve with WPA3 but WPA2 with AES is perfectly secure as long the password is long (next topic). If you see a reference to PSK that refers to the most common flavor of WPA2, which has a single password for the network. WPA2 Enterprise is the other flavor and it supports multiple users of a single network each with their own password. Wi-Fi passwords: Never use the default Wi-Fi password, even if it is long and random. Always change it/them. WPA2 passwords have to be long enough to fend off brute force attacks. This will not be an issue with WPA3. My best guess is that 16 characters should be sufficient, but the German government recommends 20. And, you really should not use a password anyone has ever used before. Check for new firmware. There are no standards here, every router has a different procedure. With most routers this will be an ongoing manual check, however, some are able to update themselves. Be aware of the risk; if something goes wrong you may lose Internet access. Best to do it at a time when your ISP has offices that are open, so the box can be exchanged, if necessary. For more, see the firmware updates page. Many routers no longer get firmware/software updates. If the last update for yours was a couple years ago, it is time for a new router. Turn off WPS Turn off UPnP. UPnP is a protocol that lets devices on a LAN punch holes in the firewall of the router. This exposes these devices to the Internet at large where, if they are vulnerable, they can be hacked. Technically, UPnP enables port forwarding without the router owner even knowing what port forwarding is. You are safer with UPnP disabled. To see if your router is doing any Port Forwarding, you can login to the router. No forwarding of ports is the safe, secure state. That said, there is a chance that disabling UPnP will break some network communication used by a device on your network, most likely an IoT device. This is why it is enabled by default on all consumer routers - to cut down on tech support calls. But this is only half the story. We also need to worry about UPnP on the WAN/Internet side of the router. UPnP was intended to only work on the LAN side of a router, but some routers are so miserably mis-configured that they expose UPnP on the WAN/Internet side too. This is a huge, mistake, akin to a surgeon amputating the wrong leg. Fortunately, there is an online test, from Steve Gibson, that checks the public side of a router for the existence of UPnP exposed to the Internet. On the first page, of his ShieldsUP! service, click on the gray Proceed button. On the next page, click on the yellow/orange button for GRC's Instant UPnP Exposure Test. As of June 2018, Gibson had found 54,000 routers exposing UPnP. For more, read about hacks via UPnP: Hacker Streaming PewDiePie Videos on Exposed Chromecast Devices (Jan. 2019) and for techies: Do You Know Where Your UPnP Is? (Oct. 2016). Guest networks (SSIDs) are your best friend. Use them not only for visitors but also for IoT devices. Guest networks should be password protected. Guest networks are usually, but not always, isolated from the main network. Review all the configuration options your router offers for the Guest network to insure they are isolated. The Security Checklist page has a list of options you might find. Network Isolation/segmentation: Guest networks are merely an appetizer, using VLANs for isolating groups of devices on the network is the main course. The idea is to prevent a single hacked device from causing grief for other devices on your network. How many groups (VLANs) to create is a matter of opinion. In February 2023, the US National Security Agency issued Best Practices for Securing Your Home Network which said \"At a minimum, your wireless network should be segmented between your primary Wi-Fi, guest Wi-Fi, and IoT network. This segmentation keeps less secure devices from directly communicating with your more secure devices.\" Their focus on wireless was a mistake, the VLAN concept applies equally to Ethernet-connected devices. They also don't go far enough, as they don't address the issue of whether devices in a VLAN can see each other. See the VLAN page for more. Much more. In the beginning, routers were administered via a web interface and a computer in your home/office. Now, many routers offer Remote Administration via a cloud service and a smartphone app. Management via a mobile app can be especially dangerous as it is likely to work from anywhere. Test this when away from home or by connecting your mobile device to the 4G/LTE network of your cellphone provider. If an app on your phone can get into the router remotely (when not connected to a Wi-Fi network from the router), then you are trusting every employee of the router vendor not to spy on you. Disable this if you can. This is a big issue to me, so much so, that I might replace a router if remote cloud/app access can not be disabled. My preferred router vendor, Peplink, has a cloud-based admin system called InControl2, however it can be easily disabled and the router can be completely administered locally. If the router has a web interface, turn off Remote Administration (aka Remote Management, Remote GUI or Web Access from WAN). It is normally OFF by default, but take the time to verify this. If you need Remote Administration, there are a number of ways to make it more secure, such as using HTTPS on a non-standard port and limiting the source IP address. The Security Checklist page has more on this. Turning off features you are not using reduces your attack surface. Among the features that should probably be disabled are SNMP, NAT-PMP, IPv6, Telnet access to the router and Application Layer Gateways (ALG). A longer list is on the Turn off page. Change the LAN side IP address of the router. Even better, change the entire LAN side subnet. See the page on IP Addresses for more. This helps prevent many router attacks. And, while you are at it, set up DHCP to allow for some static IP addresses. Chose a DNS provider: DNS is a security issue, but not for the router itself. Instead, it applies to the devices that connect to the router. If you are not familiar with DNS, the Test Your DNS Servers page starts with an introduction. By default, your router and your devices will use a DNS service from your ISP. This is the worst possible choice. There are many DNS providers to choose from, both free and paid. I have some suggestions on the DNS Providers page. DNS providers offer assorted services: privacy, malware blocking, porn blocking, ad blocking and/or tracker blocking. Chose a DNS protocol: While all routers support the old, insecure flavor of DNS, some routers also support the new, encrypted version. Old DNS does not use encryption, making it very easy for an ISP to spy on your activity. Both of the two newer methods of communication (DoH and DoT) use encryption and thus prevent the ISP from seeing DNS requests and responses. Old DNS is specified with IP v4 addresses (normally two of them). New DNS is typically specified with a server name. All of the DNS providers on the DNS Providers page support both DoH and DoT. On Peplink routers running firmware 8.2 secure DNS is configured on the Network tab -> WAN -> DNS over HTTPS. Built into the router is support for Cloudflare, Quad9, Google DNS and OpenDNS. The Custom URL option can be used for NextDNS. If a Wi-Fi network is using WPA2 and the router offers an option for protecting management frames, turn it on. WPA3 requires this option to always be enabled so a Wi-Fi network using WPA3 will probably not have an option for protecting management frames. Write down the critical information on a piece of paper and tape it to the router, face down. Include the Wi-Fi network names (SSIDs) and passwords, the router userid/password and the IP address of the router. For routers with a web interface, lock down access to the router from the LAN side. The Security Checklist page offers a dozen possible options (see the Local Administration topic) such as changing the port number(s) and limiting access by IP or MAC address. For routers that use a mobile app for administration, think about locking down access to the mobile app (this may require signing out). Turn off Ping reply. Sadly, different routers use different terminology for this. To test it, have someone ping your public IP address from outside your network. Steve Gibson's ShieldsUP! service also tests this. Turn off wireless networks when not in use. Some routers let you schedule this, others have a physical Wi-Fi on/off button, others have a mobile app. In the worst case, you have to login in to the router web interface to disable the Wi-Fi. In that case, a browser bookmark can ease the pain. Test if your router supports HNAP. If so, it should be replaced. Your modem is a computer too. Your router may be able to block access to the modem from all devices on the LAN. I blogged about this. See part 1 and part 2. If your router supports outgoing firewall rules, block the ports used by Windows file sharing. You may also want to prevent any network printers from making any outbound connections. This way if a printer gets hacked, it can't phone home. If the router can send email when certain errors occur, configure this feature. Try to prevent your router from spying on you. If you own a Netgear router, be aware that they added \"analytics\" with firmware updates released in April 2017. If you don't want Netgear watching your network, you need to login to the router and disable these analytics. For more on this, see the Bugs page for July 2017. Likewise, Asus and other routers include anti-malware software that may also be watching you. For more on Asus and their partnership with Trend Micro see the Bugs page from May 2017 and look for \"Privacy issues with Trend Micro software in Asus routers\" Trend Micro software is in other routers too and other anti-virus companies are also partnering with router vendors. The Test Your Router page has many ways to kick the tires on your router. One thing to look for is open ports. At Steve Gibson's ShieldsUP! site (click the gray Proceed button), start with the Common Ports test and pay special attention to the SSH (22) and Telnet (23) ports as these services are frequently abused by bad guys. The only good status for any port is Stealth (assuming remote administration is disabled). Next, do the All Service Ports test and finally, do the Instant UPnP Exposure Test (orange button). Test your router with my Shodan Query My Router page. It generates a Shodan query, a Censys.io query and nine other queries of your public IP address. If your router has been doing bad things, hopefully one of the queried sites will have detected it. Be sure to read the QUALIFICATIONS and MORE WARNINGS paragraphs to understand the limits of these tests. The router tests mentioned above are only a partial solution. For the most thorough test, connect the WAN port of a router to be tested (inside router) to a LAN port on another router (outside router). Then, from a computer connected to the outside router, scan the WAN side of the inside router using NMAP looking for open ports. This lets you test all 65,535 TCP ports and all 65,535 UDP ports. There should be no open ports. Remote administration will require an open port but it should, normally, be disabled. Speaking of nmap, it is also useful to run it on the LAN side of the router. There should be one port open for local administration, assuming the router has a web interface. The hard part will be getting the router manufacturer to explain any other open ports. One reason I like Peplink is that getting an answer to this sort of thing is easy. When someone found port 8183 open on the LAN side the company explained why. In 2019, I blogged about a Netgear router that was still somewhat operational for UPnP, even when UPnP was disabled. The smoking gun was two open LAN side ports. (added Sept 8, 2020) MAC Address Filtering: A MAC address is a unique identifier assigned to every network interface. A router typically has three, one for the WAN/Internet port, one for LAN side Ethernet and another for Wi-Fi. A laptop computer will have one MAC address for Wi-Fi and, if it has an Ethernet port, a different MAC address for Ethernet. This option can be used to limit the devices that can connect to a Wi-Fi network (or maybe all Wi-Fi networks depending on the router). You can either set up an INCLUDE list of allowed MAC addresses or an EXCLUDE list of banned ones. The bookkeeping involved in maintaining these lists can be a pain in the neck. Perhaps the most interesting aspect of this is how much it tells you about someone making a recommendation. People who do not understand the technology recommend using it, unaware of a flaw. People with an intimate understanding of how it works, say not to use it because of the flaw. MAC addresses are always broadcast unencrypted, so a bad guy can see the allowed ones and copy them. Should you use it? It depends. While the security is far from perfect, it should block unsophisticated attackers, even if they know the Wi-Fi password. And, if you only have a small number of Wi-Fi devices, then the bookkeeping is not that bad. But, it can be hard to learn the MAC address of a Wi-Fi device, especially an IoT device or one using an operating system that creates random private MAC addresses. The world changes. (added April 26, 2021) Someone who works from home should have an their own network that is isolated from all the other devices in their home. I wrote about this in a September 2020 blog, A second router can make working from home much more secure. Because this network will have a very small number of connected devices, there are router options that, normally rejected for a larger network, now make sense. Specifically: disable DHCP, enable MAC address filtering, do not broadcast the SSID, use only 5GHz Wi-Fi and lower the Wi-Fi radio signal strength. None of these features is a perfect barrier to entry, but since no one does this, bad guys without good technical skills should be tripped up. And, use Ethernet whenever possible (many printers support Ethernet and USB/Ethernet adapters are cheap). This makes the most sense when using two routers or a main router that supports VLANs. These options are not a good fit when there is only one consumer/ISP-supplied router. Many routers let you change the WAN MAC address. If you can, do so. This only applies when you have a stand-alone router, it should not be done on a combination modem/router device. A MAC address is 6 bytes long, the first 3 bytes identify the company that made the hardware. Making a router from company A appear to be manufactured by company B may offer some defense against a malicious ISP. Valid MAC Addresses can be found here. It would be great if we could change the WiFi MAC address(s), but I have not seen that option on any router. This is what the feature looks like on a router made by Asus, TP-Link, Linksys and Peplink. (added April 16, 2021) Your router may not be the only device creating a wireless network. Many HP printers (and probably other vendors too, but I tend to see this from HP) create their own Wi-Fi network using a feature called Wi-Fi Direct that lets wireless devices connect to the printer directly without going through the router. The security of Wi-Fi Direct is poor, so you should either connect a printer to your network -or- use Wi-Fi Direct. Do not use both. Suggestion courtesy of Ryan Woodings, the founder of MetaGeek. (added March 19, 2020) Routers that have a web interface are best administered with a clean web browser session. That is, start up a browser, work with the router, then logoff the router and shut down the browser. Need proof that this is good advice? Here is one example (from Nov. 2020) and another example (from May 2022). Better yet, use private browsing mode when working with the router. Even better, use a browser that has no (or very few) extensions or plug-ins installed. Bad neighbors can not target a Wi-Fi network that they do not see. To weaken the Wi-Fi signal that leaks out of your home, turn down the transmission power of the router. There are some other roadblocks that, while not foolproof, are nonetheless a barrier to be overcome. Details are on the Bad Neighbors page. (added September 2019) Eat your vegetables :-) Final Steps top When you are all done making configuration changes to a router, it is a good idea to back up the current settings. This way, should you ever have to reset the router, you can easily import/restore the last backed up state. Many routers can export the current settings to a file. With my favorite router, the Pepwave Surf SOHO, settings are backed up with System -> Configuration and click the Download button. The mesh routers that I have used can not export the current configuration settings to a file. If that's the case for you, consider taking pictures of the configuration screens. One reason you might have to re-install the current configuration settings is if someone resets the router. All routers come with a pinhole reset. Someone malicious, who can physically touch the router, may simply reset the router to factory defaults as a way to get around the security. A business may try to physically restrict access to the router, but at home, this is probably not viable. To offer the best Wi-Fi performance a router needs to be out in the open which leaves it vulnerable to being reset. Old school, techie-oriented routers have a ton of features. After making the changes above, its probably best to live with the router a while before changing some of the more obscure settings. Once you have a performance baseline, then consider enabling features like the detection and prevention of Denial of Service (DoS) attacks or SYN Flood attacks. Peplink, for example, offers Intrusion Detection and DoS Prevention that protects against 9 types of attacks (With firmware 8.2 this option is at: Network tab -> Firewall Access Rules). DrayTek routers offer protection from over 15 types of attacks. If you do not use a VPN then you can turn off the VPN pass-through options. Some Additional Thoughts top I also have write-ups on Synology routers, pcWRT, Google Wifi mesh routers, Eero, the Turris Omnia router, Apple routers. These are mostly, but not exclusively, focused on security. The term \"modem\" is often mis-used. See exactly what a modem is. The best possible over-the-air encryption is offered by Enterprise versions of WPA2/WPA3 instead of the more popular Personal versions. For more on this, see the WPA2 WPA3 encryption page. In August 2021, I blogged about Hiding on a Wi-Fi network. This was about hiding your computer from other devices on the LAN. This is mostly an issue when connected to a public Wi-Fi network, but it is also an issue with dedicated IoT networks at home. In March 2022, I added the black sheep of pages to this site. Rather than focus on security, it offers an overview of Extending the Range of a WiFi network. Turning things around, Wi-Fi devices generally keep a record of the networks/SSIDs they have connected to. This makes it easy or automatic to re-connect to known networks. Fine. Except, when they broadcast this list, it exposes the places you have visited to anyone able to record this broadcast. It may also expose where you live or work. For some additional privacy, periodically review the list and delete the SSIDs you do not expect to use in the future. iOS version 17: Settings -> Wifi -> Edit (link in the top right corner) Windows: coming .... Android 14 (on a Pixel phone): Settings -> Network and Internet -> Internet -> Saved Networks. Click on an SSID, then on Forget. macOS: coming.... Ongoing Care and Feeding and Defense top If the router does not self-update, then check for new firmware every month or two. If the router does self-update, check, every now and then, that the self-updating system is actually working. More about firmware updates. Register the router with the hardware manufacturer on the chance that they notify you of firmware updates. Netgear, for example, has a security newsletter that announces bug fixes. In December 2021, Google sent owners of their OnHub routers a note about their being discontinued and a coupon for large discount on a new router. At some point there will be no more firmware updates. When this is officially publicized it is called called End-Of-Life (EOL). Some router vendors have a list of their EOL devices, some do not. But, regardless of the official status, when the latest firmware is more than two years old, it is time to replace the router. Never mind: This item used to suggest periodically rebooting a router to remove malware. But, in January 2024 we learned about the FBI hacking already hacked routers to disable Chinese malware. In that case (see the Router News page for details) however, the fix was temporary and rebooting the router re-infected it. So, there is no single best policy. Original item: As per the topic below on Hacked Routers, it would be a good thing to re-boot a router, every now and then. Here is an example, from June 2022, of router malware that is removed by a re-boot: A wide range of routers are under attack by new, unusually sophisticated malware. How often to re-boot? In February 2023, the NSA said: \"At a minimum, you should schedule weekly reboots of your routing device, smartphones, and computers.\" Every router can display a list of attached devices. It is good to check this every now and then to insure that you know what every device is. Better routers will let you assign names to each device (Susans iPad, Bobs laptop, Georges iPhone). You may want to assign every device a name that begins with \"**\" for example. That way you can easily scan the list of devices (some households have quite a few Internet-using devices) for names that do not start with your favorite string of characters. Be aware that the list of devices may not include all devices connected to the router. Read the fine print. It may only be those that are active at the moment or only those using DHCP. Some mobile apps for routers show you information about devices that have recently been on your network, even if they are not currently using it. FYI: If you have more than one SSID (you should) a good router will show you which SSID each wireless device is connected to. The Surf SOHO does this. A common attack against routers is to change the DNS servers. You need to know what the DNS servers should be (discussed above). Many websites report the currently used DNS servers. Pick one or two and get in the habit of checking that your DNS servers have not changed. Consider making one of these sites your web browser home page to insure that you check it periodically. This has gotten more complicated with the introduction of Secure DNS settings in web browsers. If the router has any logging facilities, check the logs every now and then. Electricity: If either a modem or router is damaged by an electric surge, then you lose Internet access, perhaps for quite a while. It is best to connect each device to either a Surge Protector or a UPS. If shopping for a UPS, get an on-line or line-interactive model. These will boost the power when its a bit low and trim it when its a bit high. This is in addition to being a big battery for when the power fails. Any UPS should also provide surge protection. A good place to start when shopping for a UPS is the Tripp Lite SmartPro 1300VA which sells for about $150. Specs: LCD 120V 720W Line-Interactive UPS, AVR, Tower, LCD, USB, 8 Outlets. Hacked Router? (Added March 1, 2022) top By and large, it can be hard to impossible to tell if a router has been hacked. That said, you can look for this: If the router offers a display of CPU usage (some do, some do not) then high CPU usage when there is little activity might indicate cryptomining or some other type of infection. Both Asus and Peplink show current CPU usage but neither has a history of CPU usage so you can't see a pattern. High bandwidth usage may indicate the router is part of a botnet. Then again, if the bandwidth is directly attributable to the router (rather than a connected device) who knows if it will even show up in bandwidth reports? DNS changes So, what to do? Some malware infections can not survive a re-boot, so ... re-boot every now and then. Just for good luck. Better yet, power the router off, wait a minute, then power it on. Routers have dozens of configuration options and no automated way to notify you if anything changes. Note that pcWRT is an exception, it actually can email you about changes. To defend against malicious changes to the configuration, have a backup of the current settings (many routers can do this). If you suspect anything, then restore the settings backup, change the router password and maybe change the Wi-Fi password(s). Then, make a new backup of the current settings. I have seen suggestions to factory reset the router. This only makes sense if you do not have a backup of the system settings. Here again, change the router password and maybe the Wi-Fi password(s) after the reset. I would not expect a factory reset to modify the firmware itself (firmware is the operating system of the router), just the configuration settings. The worst type of infection modifies the firmware. To clear out infected firmware, download new firmware from the website of the hardware manufacturer, while connected to a different router. The last point brings an interesting question. If the router is already running the latest available firmware, can you install the current firmware over itself? Some routers do not let you install older firmware, but the issue of re-installing the same firmware has never come up as far as I know. Peplink shines in this area. Their routers have two installed copies of the firmware and there is no restriction on what each copy can be. Picking a Secure Router top This topic has been moved to its own page. In brief: The least secure routers are from an ISP. A small step up are consumer routers, but I would avoid them too. I recommend Peplink routers. As of 2024, the cheapest Peplink model (with Wi-Fi) is the B One for $300 US. Conference Presentations top I spoke on Securing a Home Router at the HOPE conference in July 2014. This website grew out of that presentation. A PDF of the presentation is available at box.net, video is available on YouTube, audio is available at x.hope.net. An article about the talk appeared in Toms Guide. I spoke again about Router Security, at the O'Reilly Security Conference on Nov. 1st, 2017. The talk was very different from the first one. See a PDF of the slides or watch the video on YouTube. For other Router Security opinions, I maintain a list of articles. Many stink, the good ones are noted in bold. You Are Safe Here top This site is as clean as clean gets. There are no ads. There are no trackers. It does not set any cookies. None of the links here are affiliate links. If you see any ads here, something (your computer, browser or router) has been hacked. No need to believe me about the safety of the website. Here are some tests. You can test for setting cookies at cookieserve.com. You can test for ads and trackers at Blacklight, a website privacy inspector from The Markup. Simply click here to run a live Blacklight test of this site. Apple's iOS versions 16 and 17 includes a website audit at Settings -> Privacy & Security -> App Privacy Report -> Website Network Activity. For each website the iOS device has contacted, it shows the other websites that were contacted. The section is called \"Domains contacted by website\". If you use an iOS web browser and go to Hilton.com (screen shot) you can see that it contacts many other sites. In contrast, this site (screen shot) does not call out to anywhere. Screen shots are from Jan. 2024. NOTE: If the address bar of your web browser says \"routersecurity.303.si\" you are viewing my site inside a frame that bad guys created. They do this to show ads. They got the domain for free from 303.si. This website should appear as \"routersecurity.org\" in the address bar of your browser. Top Page Created: January 30, 2015 Last Updated: September 18, 2024 4PM CT Viewed 2,539,090 times (718/day over 3,536 days) Website by Michael Horowitz Feedback: routers __at__ michaelhorowitz dot com Changelog Copyright 2015 - 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41752327",
    "commentBody": "Router Security (routersecurity.org)94 points by blueridge 23 hours agohidepastfavorite70 comments yjftsjthsd-h 21 hours agoSo I think this is mostly reasonable advice, but I do have to question disabling ICMP/ping and IPv6. I'm not aware of any actual attack that ping allows? And IPv6 should be fine if you have a firewall (which I would rather expect any regular COTS consumer router to have). The link on that suggestion describes a very specific problem where your router is also your WiFi AP and uses the old approach of just shoving the entire MAC address in to its v6 address, but am I wrong in thinking that it would be weird to see that actually happening in a new router, where new is \"still getting security updates\"? reply fourfour3 19 hours agoparentI'd agree - IPv6 is only going to get more important from now. Especially with ISPs doing rollouts paired with moving v4 to address conserving mechanisms like CGNAT. The short list looks pretty sensible to me with those two exceptions. The long list gets a bit paranoid for me at the end - especially 32 onwards or so. reply transpute 13 hours agorootparentAugust 2024, \"Zero-click Windows TCP/IP RCE impacts all systems with IPv6 enabled\", https://www.bleepingcomputer.com/news/microsoft/zero-click-w... > the bug in TCP/IP that would allow a remote, unauthenticated attacker to get elevated code execution just by sending specially crafted IPv6 packets to an affected target .. That means it's wormable reply fourfour3 8 hours agorootparenthttps://malwaretech.com/2024/08/exploiting-CVE-2024-38063.ht... is very worthwhile reading as a write on up this - it's nothing inherent in IPv6 and was a bug in Windows's packet processing of reassembled packets. I'm not convinced it would be particularly exploitable with a firewall between the system and the rest of the internet blocking unsolicited incoming traffic -which is what most consumer routers etc are doing for IPv6. reply BitPirate 11 hours agorootparentprevIf we stopped using things that had vulnerabilities, we'd be using sticks and stones by now. Other operating systems weren't affected, so it's not inherent in the protocol itself. reply transpute 11 hours agorootparentWindows users with IPv6-blocking routers were protected from RCE. Defense in depth is a viable approach if IPv6 features are not required. reply abhinavk 4 hours agorootparentWindows users with firewall-enabled routers were also protected from RCE. reply throw0101b 4 hours agorootparentprevBetter disable IPv4 then, as there were zero-click vulnerabilities in Windows in that as well, e.g., CVE-2021-24074. reply bbarnett 18 hours agorootparentprevI'd agree - IPv6 is only going to get more important from now. Yes, but while not inaccurate, I've heard this since 2000. reply kstrauser 16 hours agorootparentGoogle’s traffic is nearly 50% now: https://www.google.com/intl/en/ipv6/statistics.html Are there any cell providers that don’t use native IPv6? Verizon definitely does. I’d be surprised if any big ones don’t. reply fourfour3 8 hours agorootparentIn the UK we actually only have one provider that does - EE. They do native v6 and 464xlat for v4 connectivity where handsets support it. Every other major provider is doing a horrible mess of IPv4 CGNAT with no native v6 still. reply wiml 12 hours agorootparentprevYeah, in an era when mobile device users are a pretty major customer segment, and they're essentially all native-v6, it's weird to dismiss it. reply bbarnett 10 hours agorootparentCustomer segment? This is a thread about consumer edge routers. That is, individual people, not corporate connectivity. \"Customer segment\" is a meaningless term here, Grandma doesn't care about customers. A lot of this is regional, sadly. No mobile phone provider in Canada/US would not allocate ipv4 access. It'd be madness. Too many unreachable endpoints. In fact, no endpoint anywhere in US/Canada can get by without ipv4, but many don't care about ipv6. There will be a point where that changes, but certainly not yet. So why does Grandma care if her router can do ipv6? All major companies world wide, all consumer end points world wide support ipv4. And in US/Canada, everyone does ipv4 unless they are on some political campaign against it. And it will hurt them. reply throw0101b 4 hours agorootparent> Customer segment? This is a thread about consumer edge routers. No, this is a thread about homelab and prosumer routers. No consumer—not Grandma, not mom, not Aunt Alice—is adjusting or checking or modifying their settings. This is evidenced by: > 6. Turn off UPnP Really? Do you know how many things that will break for the average consumer? > So why does Grandma care if her router can do ipv6? Does Grandma care about UPnP and/or PCP? She's probably has never heard of them, but she should care about them if she wants certain apps to work. And if Grandma happens to use an ISP that didn't get in early on the IPv4 land rush (or doesn't have the cash to buy individual IPv4 addresses for all their customers) then she certainly should care if her router can do IPv6 (or rather someone should care on her behalf): > We learned a very expensive lesson. 71% of the IPv4 traffic we were supporting was from ROKU devices. 9% coming from DishNetwork & DirectTV satellite tuners, 11% from HomeSecurity cameras and systems, and remaining 9% we replaced extremely outdated Point of Sale(POS) equipment. So we cut ROKU some slack three years ago by spending a little over $300k just to support their devices. > First off I despise both Apple and that other evil empire (house of mouse) I want nothing to do with either of them. Now with that said I am one of four individuals that suggested and lobbied 15 other [American Indian] tribal nations to offer a new AppleTV device in exchange for active ROKU devices. Other nations are facing the same dilemma. Spend an exorbitant amount of money to support a small amount of antiquated devices or replace the problem devices at fraction of the cost. * https://community.roku.com/t5/Features-settings-updates/It-s... * Discussion, \"Roku devices don't support IPv6 in 2023 and it's costing ISPs\": https://news.ycombinator.com/item?id=35047624 You may just happen to be in a part of the Internet/world that got in early on the IPv4 address land rush, and/or can afford to throw money at the problem to buy individual addresses for each of their customers: not everyone is so fortunate. reply bbarnett 3 hours agorootparentNo, this is a thread about homelab and prosumer routers. No consumer These are still consumer endpoints. And: You may just happen to be in a part of the Internet/world that got in early on the IPv4 address land rush Yes, that's precisely what I was discussing. Everyone in the regions I discussed can access ipv4, period. All domestic businesses do ipv4. All businesses worldwide which want access to these markets do too. I'm not interested in ipv6 advocacy, but facts. And my statements stand. reply kstrauser 16 hours agoparentprevThat’s dumb advice and makes me question anything else they’d recommend. A ship is safe in harbor, but that’s not what a ship is for. If a router can’t handle IPv6 in 2024, throw it out the window. reply chgs 18 hours agoparentprevI think the problem with ipv6 is that people may enable firewall rules on ipv4, but completely forget about v6. With auto configuration you may be leaving yourself wide open. By all means enable ipv4 and v6 but remember to ensure you firewall both. reply wmf 15 hours agorootparentConsumer routers should be default deny so if you don't add any rules you're safe. reply chgs 5 hours agorootparentOn the outbound? My IoT network has a very controlled list of allowed outbound targets in the ipv4 world. If I blindly enabled IPv6 I’d have to ensure I protected against that too. Of course I also do things like intercept UDP/53 and nat it to my pihole as some devices have hardcoded dns servers, which many purists claim is an “ugly hack”. reply globular-toast 9 hours agorootparentprevWhat router software makes it easy to enable the firewall for ipv4 but leave ipv6 completely open? Are these routers without a real firewall at all that just rely on NAT as a pseudo-firewall? reply o11c 19 hours agoparentprevIf you haven't updated your kernel since 1998, you may be vulnerable to the Ping of Death. (I'm 90% sure this is the origin of this advice) reply transpute 13 hours agorootparentAugust 2024, https://news.ycombinator.com/item?id=41754925 reply kstrauser 11 hours agorootparentThat’s yet another Windows bug, not a problem with IPv6. reply transpute 11 hours agorootparentWindows users with IPv6-blocking routers were protected. reply ssl-3 12 hours agoparentprev> I'm not aware of any actual attack that ping allows? DoS. There may have been a time once, when some of us may have been minors, that using a command like \"ping -f -s 1000\" from a well-connected host to a specific dialup user's IP address may have been able to completely obliterate their connection to the point that it would fuck up their network stack enough to reliably disconnect their PPP session and send them back into redialing the local ISP's busy modem pool. Maybe. And that kind of thing might still work today for devices that respond to ICMP pings. (I'm no longer an angsty teenager so I wouldn't know, but angsty teenagers are still things that get made in factories every day.) reply neilalexander 10 hours agorootparentBelieve it or not, blocking ping at your router would have done absolutely nothing to prevent this, as those packets would likely have still been delivered to the router and possibly saturated the link anyway, regardless of whether the recipient was dropping them or not. That is why nearly all DoS flood-style attacks are UDP-based — unless you are behind a CGNAT or an upstream restrictive firewall, you can't really opt out of those packets being routed to you. reply ssl-3 9 hours agorootparentBelieve it or not, blocking pings at the router prevents said router from responding to pings, and this eliminates 50% of the problem on symmetric connections (and >50% on asymmetric connections). Don't let perfect be the enemy of good. reply throw0101b 3 hours agorootparent> Believe it or not, blocking pings at the router prevents said router from responding to pings, and this eliminates 50% of the problem on symmetric connections (and >50% on asymmetric connections). But if your downlink to clogged, it probably won't matter that much that your uplink is clear. I've self-DoSed when 'downloading Linux ISOs' because the downlink was 100% saturated and I couldn't do much anything else because the ACKs for TCP packets couldn't get down easily (this was for something as basic as SSH sessions that suddenly got laggy when typing). I had to tell the software in question to only use ~90% of my downlink speed (DSL at the time). reply dns_snek 8 hours agorootparentprev> Don't let perfect be the enemy of good. Better: Don't base your decisions on imaginary scenarios that haven't been relevant for decades. There's no \"good\" in blocking ICMP packets and especially ping. You won't protect yourself from DDoS attacks but you might summon some obscure, hard to diagnose networking issues. If you gave me your IP and your consent, I could rent a DDoS-for-hire service for lunch money and take you offline. They don't rely on their victims taking themselves offline with response packets. reply fourfour3 7 hours agorootparentYep, having been a recent victim, the cheap 'booter' services are still doing NTP & DNS reflection attacks. They're easy to do and require very few resources on the part of the attacker. Flooding a 1G service to the point of total uselessness is trivial and cheap. Sadly there's absolutely nothing you can do on your own firewall/router to block or mitigate them - your connection's downstream just gets flooded with UDP packets and becomes totally useless. The only mitigations/blocking can be done by your ISP and their connectivity partners. reply globular-toast 10 hours agorootparentprevHow much does disabling or filtering ping do to help, though? Won't they still saturate your downstream and put load on the firewall? reply bogantech 20 hours agoparentprevPeople who block ping should get swirlies reply nickburns 16 hours agorootparentWhat do you think about black box/IoT/whatever hosts on your LAN pinging external hosts with unknown payloads while you're not using them? Best security practice is obviously to block any/all ping not intentionally sent by you, whoever the local network admin is, or otherwise only whoever or whatever is explicitly allowed to. reply yjftsjthsd-h 12 hours agorootparent> What do you think about black box/IoT/whatever hosts on your LAN pinging external hosts with unknown payloads while you're not using them? I think that 1. they can connect out via TCP or UDP much more easily than ICMP, 2. that blanket blocking outbound connections is a short path to madness, 3. if you don't trust a device on your LAN you should unplug it or isolate it, both of which are more effective and less disruptive, and 4. depriving yourself of the most fundamental network diagnostic tool in the name of security is cutting off your nose to spite your face. reply nickburns 6 hours agorootparent1.) Carried out, that logic suggests not performing any outbound filtering because LAN hosts could simply find another way, protocol or port, out? I understand that 99.9% of LANs are configured default-allow LAN outbound. But the premise of your statement is untrue if the firewall is configured default-deny in all directions on all interfaces. 2.) I've not suggested 'blanket blocks' (nor 'blanket allows' for that matter). Specifically, both ingress and egress ICMP should be filtered by type code. 3.) In a zero trust model[1], every LAN device is untrusted. One should perform as much isolation and filtering as possible at all the relevant network layers. Network security is \"disruptive\" by definition. 4.) The second paragraph of my comment suggested that ping should be explicitly allowed for anyone/any device on the LAN legitimately utilizing it. [1] https://en.wikipedia.org/wiki/Zero_trust_security_model reply LargoLasskhyfv 20 hours agorootparentprevI'd rather swirl pings from the outside, from people who have no business at all to know about my internal infrastructures. Just GTFO. reply yjftsjthsd-h 19 hours agorootparentHow would somebody ping your internal network from the outside? Your firewall should block the ping getting past the router, regardless of the external interface responding. That said: Who cares? Even if you published exact list of every single IP on your network, it doesn't do an attacker any good, because again, there's a firewall between them and your devices. reply HeatrayEnjoyer 19 hours agorootparentNetwork metadata is sometimes valuable all by itself. Investment firms buy satellite imagery to identify the number and models of cars in corporate parking lots, for better inferring internal business conditions. Frequency of pizza deliveries to the Pentagon revealed when major ops were taking place. A private network will ideally present as an opaque black box to the outside. reply peanut-walrus 11 hours agorootparentThis site is about securing consumer level routers. Nobody using one of those has a network where the internal layout is valuable to a bad guy. reply throw0101b 3 hours agorootparentprev> A private network will ideally present as an opaque black box to the outside. Good luck (trying to) scanning a IPv6 /64 subnet. I've been in IT for 20+ years, and I have yet to find a situation where blocking ICMP(v6) caused more benefits than problems. Ditto for my home network: my last ISP had IPv6, and I had an Asus router which blocked unsolicited incoming connections: I could not SSH to any of my Macs from the outside (by default), but could ping if I knew the address (but good luck guessing 2^64). If you want to try to enumerate the equivalent of 4.3 billion IPv4 Internets that is a single IPv6 subnet, have fun. reply bogantech 20 hours agorootparentprevIf your internal infrastructure is not internet routable nobody would be able to ping it anyway reply LargoLasskhyfv 4 hours agorootparentMy comment wasn't about 'if's, but the thought of entitlement to mess around with other peoples stuff, or at least try 'look' at it. That deserves to be flushed down the drain, or the kitchen sink. reply RecycledEle 16 hours agoparentprev> I do have to question disabling ICMP/ping Ping is a tool I love, but it also allows a bad guy to discover your router with tracert. Disabling icmp/ping responses prevents that. reply kstrauser 16 hours agorootparentThat doesn’t get you anything. The bad guys assume every IP owned by an ISP has a customer router on it. reply Fnoord 10 hours agorootparentI recently installed fiber (IPv4 only via this ISP, :/). The moment I connected OPNsense I got all kind of connections on the usual suspect ports. The whole IPv4 address space is scanned within an hour. This doesn't hold up for IPv6 though. This address space is so large, you can run SSH server on it without it ever getting scanned. reply throw0101b 3 hours agorootparentprev> Ping is a tool I love, but it also allows a bad guy to discover your router with tracert. And? So some random IP, which is already known to be in the range of a residential ISP (because of ARIN/RIPE/ASN records), is pingable. So what? reply neilalexander 10 hours agoprevDisabling IPv6 in 2024 is bad advice. IPv6 adoption is undeniably on the rise. Better advice would be to ensure that the IPv6 firewall is configured to sane defaults, i.e. allow established/related, drop invalid, reject unexpected, just like you'd expect an IPv4 firewall to be. Disabling ICMP is also bad advice. If you want Path MTU discovery to work, you need ICMP. If you want to be told about TTL exceeded (which usually shows a routing loop), you need ICMP. If you are uniquely worried about ping for some reason, then block those ICMP type numbers specifically, not the entire protocol. reply hi-v-rocknroll 16 hours agoprev0. Don't use a garbage retail or ISP-provided, closed-source router. Here's one option: https://shop.opnsense.com/product/dec740-opnsense-desktop-se... 1. Suggesting turning off IPv6 is ridiculous security theater. It's a known quantity deployed at scale. Dual stack or turn in your \"hacker cred\" card now. ;) reply fourfour3 8 hours agoparentOh these are nice, I didn't realise they'd updated them with 2.5Gbit ports :) For something a bit more affordable, the Turris Omnia or Mox are nice options too - https://www.turris.com/ I'm not the biggest fan of OpenWRT et al (or pfSense/OPNsense, for that matter), but they're reasonably friendly for a technical user. Personally, I still really like a small, low power x86 box running normal Linux as a firewall & router. Sadly the options are either very expensive or from questionable sources (eg aliexpress x86 low power machines are common). I miss PC Engines - https://www.pcengines.ch/eol.htm :/ reply mito88 16 hours agoparentprev€749,00 gulp reply transpute 13 hours agorootparentFanless 10GbE is pricy. OPNsense is based on FreeBSD, runs on $100 micro PCs with PCIe quad NIC, https://www.servethehome.com/introducing-project-tinyminimic... reply BLKNSLVR 8 hours agorootparentExactly what I did/do. I vouch for this option. reply bpye 15 hours agorootparentprevPerhaps a more affordable option, find some hardware that runs OpenWRT [0]. [0] - https://openwrt.org/toh/start reply kQq9oHeAz6wLLS 14 hours agorootparentI run a cheap tiny PC and OpenBSD, if you want a more hands-on config process. reply bpye 13 hours agorootparentMaybe more fun than practical, given the performance you'll see [1], but OpenBSD has a mips/octeon port which runs on some of Ubiquiti's hw [0]. [0] - https://www.openbsd.org/octeon.html [1] - https://kernelpanic.life/hardware/openbsd-router-benchmarks.... reply commandersaki 10 hours agoprevSo what is the reality with respect to router security? Looking at https://routersecurity.org/othersgripeonrouters.php some 2019 article headline says \"the worst is yet to come.\" Virtually all routers do not have an admin interface exposed on Internet facing side, moreso due to CGNAT. What threats from routers are we seeing in the wild that are actually having an impact? reply Havoc 17 hours agoprevI’m much more comfortable use something like opnsense. Router manufacturers seem to just yolo it judging by backdoors etc found frequently > At some point you will go a year or two, or more, without any updates. That's when it is time for a new router. Is that good advice? Swapping a mature and patched platform for whatever device with new A.I. enabled half test beta firmware that just got rushed to market? reply yjftsjthsd-h 17 hours agoparentYes. If the thing sitting on the external side of your network, exposed to the open internet, isn't getting security patches, then it's time to replace it with something that is. reply BobbyTables2 15 hours agorootparentDoesn’t even have it be on the external side. Non-updated LAN device making outbound connections puts the entire LAN at risk… reply BenjiWiebe 15 hours agorootparentprevHow much is exposed? How much attack surface is Internet accessible on, say, a 5 year old netgear router? I guess I think it might be quite low. reply yjftsjthsd-h 12 hours agorootparentIf you've port scanned your public IP(s) and there are zero open ports, then you only have to worry about bugs in the TCP/IP stack, services listening on UDP, and intentional backdoors (which shouldn't happen but keep popping up). If there are exposed ports, then there's even more attack surface. Edit: actually I forgot the like of UPnP so that's not exhaustive. reply transpute 13 hours agoparentprevDoes OPNsense GUI support configuration of the router as a VPN client to commercial servers? Most of the docs cover site-to-site VPNs. reply Havoc 10 hours agorootparentDirectly no not to my knowledge. Seems like a bit of an esoteric layout to be honest. If you really want you could probably do it with two sets of interfaces but you'd still need an external device for wireguard. So same opnsense instance takes lan traffic and sends it to WG device, WG device sends it back to opnsense on a second set of interfaces and that goes out like a normal FW setup. That way have opnsense both as perimeter device, and also benefitting from it as a LAN mgmt (DHCP etc). To stick it all on one device you'd need virtualization I suspect. Can be done but wouldn't recommend. reply ajb 17 hours agoprevI get reducing your attack surface, but to what extent do modern devices still trust the network by default? Laptops and phones have to assume that the WiFi network is not under the control of the user. I guess printers etc assume they are in a trusted network? reply janwillemb 12 hours agoprevAlso, use two routers in serial. One is provided by my isp, the other is my own. The chances of both getting compromised at the same time are lower. reply kstrauser 11 hours agoparentFor peak security, unplug one of them. reply transpute 13 hours agoprevWi-Fi router security could be improved by per-device passwords and micro-segmentation, as seen in OSS https://github.com/spr-networks/super. VLAN for insecure IoT devices is a fallback. reply johnklos 2 hours agoprevIt really is difficult to take this seriously when they suggest disabling IPv6. There are already quite a good number of ISPs that use CGNAT for IPv4, which often means that connections die or are intentionally killed in short amounts of time, which can be a huge PITA for certain uses (interactive shells, large downloads, et cetera). Take Starlink for instance. When on IPv4, you really feel like you're on a janky network that's being rebooted every hour or two. After Starlink enabled IPv6, all sorts of things no longer required babysitting and restarting. The quality difference between IPv4 via CGNAT and native IPv6 is huge and noticeable, even for people who have no idea what's going on behind the scenes. Perhaps regular people can naively suggest turning off IPv6 because they don't know any better and they believe the FUD they've heard and read about, but if you're putting up a web site claiming to have good advice and you put more weight on FUD over real world experience and solid reasoning, then I'd be suspicious about everything they've written. reply kkfx 11 hours agoprevThe real main point is: how much control users of commercial routers could have with a reasonable effort (I mean, I know most are GNU/Linux machines, where the OEM sometimes respect the GPL providing the sources but there is no easy custom build and rom flash with very few exception like the little GL.iNet devices). If the router is just a person mini-computer with some *nix OS and it's config, directly tied to a media converter from the ISP it's a thing, otherwise it's essentially next to impossible doing most of reasonable actions including properly probing the internet-side for a small potatoes audit. Some countries have mandatory free router choice, like Italy (curiously), where at least the user is allowed by law to run it's own router so ISPs are obliged to give all settings, VoIP included, without making like of their customers needlessly harder, but that's not true in most countries. Some ISPs (i.e. Orange France) run arbitrary custom solution to makes people life harder if their put another router behind the ISP provided one. People choice is very limited even for those who would know and want to run their own home/SOHO LAN. reply fulafel 13 hours agoprev [–] Wow, disabling IPv6? Yeah, turning off your internet may increase security but this is pretty nihilist advice. Add \"disable IPv4\" too. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Router Security Website by Michael Horowitz offers a detailed guide on improving router security through configuration changes and selecting secure routers.- Key recommendations include changing default passwords, disabling features like WPS (Wi-Fi Protected Setup) and UPnP (Universal Plug and Play), and keeping firmware updated.- The site is ad-free, prioritizes user privacy, and provides resources and tests for ensuring router safety, emphasizing the importance of ongoing maintenance and detecting hacked routers."
    ],
    "commentSummary": [
      "The debate on router security focuses on whether disabling ICMP (Internet Control Message Protocol) and IPv6 is necessary, with many suggesting that modern routers with firewalls can manage these safely.",
      "IPv6 is gaining importance as ISPs (Internet Service Providers) adopt address-conserving methods like CGNAT (Carrier-Grade Network Address Translation), making its use more relevant.",
      "The consensus emphasizes maintaining updated routers and proper firewall configurations over disabling ICMP or IPv6, as disabling ICMP can impede network diagnostics and Path MTU (Maximum Transmission Unit) discovery."
    ],
    "points": 94,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1728156931
  },
  {
    "id": 41757010,
    "title": "Students who use AI as a crutch don't learn anything",
    "originLink": "https://english.elpais.com/technology/2024-10-03/ethan-mollick-analyst-students-who-use-ai-as-a-crutch-dont-learn-anything.html",
    "originBody": "ARTIFICIAL INTELLIGENCE Ethan Mollick, analyst: ‘Students who use AI as a crutch don’t learn anything’ The veteran professor, who has become a celebrity on social media, has published a book on how to better understand and use artificial intelligence in everyday life Ethan Mollick, professor at the University of Pennsylvania, has just published the book 'Co-Intelligence: Living and Working with AI.' GORDON ROBERTON (PENGUIN RANDOM HOUSE) JORDI PÉREZ COLOMÉ OCT 03, 2024 - 15:26CEST “I don’t have any help or anything. I organize myself and I get like 800 messages a day. I’m scared to look at my to-do list,” says Ethan Mollick, 49, a professor at the Wharton School of Business at the University of Pennsylvania. He has just published Co-Intelligence: Living and Working with AI, a book on how to make the most of artificial intelligence in everyday life. Despite this, managing his schedule remains extremely complicated. Although he recommends using AI as a companion for almost everything, he also believes that we should be careful. Thanks to his social media presence, newsletter and candid comments, Mollick has become one of the most popular analysts and testers of the new generative AI tools. Question: How does it feel to be an AI influencer? Answer. I hate that description. I’ve been on social media for a long time, and I’m a compulsive sharer. But I don’t take money from any of these AI companies or do sponsorship deals. I talk to them because it’s interesting. I’m a tenured professor, I can say whatever I want. It’s strange to see companies trying to manipulate me by showing me their stuff, but I don’t have the infrastructure of an influencer. I worry that that influencer title smears everything together. There’s a difference between public intellectuals, researchers, and critics. It would be better if we had more classes of thinking. Q. You recommend spending three sleepless nights to master AI. A. The best advice from the book is to spend 10 hours with AI and apply it to everything you do. For whatever reason, very few people are actually spending the time they need to really understand these systems. Q. You don’t like to call AI a crutch. A. The crutch is a dangerous approach because if we use a crutch, we stop thinking. Students who use AI as a crutch don’t learn anything. It prevents them from thinking. Instead, using AI as co-intelligence is important because it increases your capabilities and also keeps you in the loop. Q. Isn’t it inevitable that AI will make us lazier? A. Calculators also made us lazier. Why aren’t we doing math by hand anymore? You should be taking notes by hand now instead of recording me. We use technology to take shortcuts, but we have to be strategic in how we take those shortcuts. Q. Why should we approach artificial intelligence with a strategy? A. AI does so many things that we need to set guardrails on what we don’t want to give up. It’s a very weird, general-purpose technology, which means it will affect all kinds of things, and we’ll have to adjust socially. We did a very bad job with the last major social adjustment, social media. This time we need to be more deliberate. Q. Will we be able to better socially adjust to AI? A. What gives me some hope with this technology is that because it’s so human-like, it’s more natural to work with. Humans used to work with smart team members to solve problems. It’s one thing if this becomes an all-intelligent God machine, but at the current level, where you’re interacting with this thing, and it’s flawed, that’s where it can be useful to be human-like. Q. In your book, you talk about “just me tasks” in reference to raising children and values. Can we do those things better without AI? A. There are a lot of moral and ethical decisions. I can’t help with that much, but I think we have to making those choices. With social media, we didn’t make enough decisions about how we wanted to use it. People and a lot of books view AI as something that’s being forced on us, and companies are creating AI, but they don’t really know how it’s being used or what it’s good for. We can make some decisions about that, and I think people tend to view it as a government or corporate decision, but it’s not just that. Q. People already have AI-made partners and psychological advisors. A. We have lived with a general-purpose technology for many years: the internet. Social media is just one sharp edge of what the internet has done to society. It is just one application. Other applications have been dating apps or how we shop. The implications are deep and wide. For example, with AI’s voice mode, I don’t want to be friends with it, but at the same time, I find myself being apologetic and careful when I talk to it. We will have to adjust. I trust that we can, but people already have connections to AI. Some will have almost religious connections to AI, and others will be manipulated. We have to recognize that at a bunch of stuff is all going to happen at once, good and bad, and the more we’re kind of ready for that set of change the better off we are. Q. You’ve written that “much of the value of AI use comes from people not knowing you are using it.” Why are we afraid of others knowing we’re using AI? A. There are several layers in organizations that prevent people from using AI. One of them is that if I use AI to do work, others will think I’m brilliant. You don’t want people to know that you’re not actually that brilliant, especially since AI is very good at things like writing empathetic emails, and it would be weird for them to know that that empathy was coming from an AI. They also don’t want to show it because they’re afraid that you’ll realize their job is redundant, or that they’ll be asked to do more work. Q. You recently wrote that something is starting to change with OpenAI’s new model, ChatGPT-o1. A. I finished the book a year ago. I had to have enough foresight to see where things were going. Predictions for six years in the future and if AI will kill or save us all wasn’t my interest. My interest was: how do you work with this thing? One of the things I mention that wasn’t as important in the previous generation of AI and that I think will be key in the next year or two is this idea of autonomy and AI agents. It’s the beginning of AI that will perform processes autonomously, without our help. I don’t think that will fundamentally change how we work with AI, but we may move to models that come back and ask you questions when they have problems. There’s something valuable about being questioned. It’s something we do in all the AI tools we build for learning: there has to be a back-and-forth, and the o1 model doesn’t really do that. It doesn’t ask. That’s what’s unnerving. Q. You like the idea of AI-powered one-on-one tutoring for education. Is that where we’re headed, after what you call the “homework apocalypse”? A. The AI tutor is one piece of the puzzle in the transformation of education. I worked in interactive education long before generative AI, and there are things about classrooms that we know for sure are changing, independent of AI: lectures are no longer a good idea. Active learning is better, where students have to participate. You want personalization. In the classroom, a small group of students usually participate and others are lost. We are not teaching correctly. In some ways, lectures have value, they are not a disaster. We have a way of teaching that has evolved over 200 years, and that’s alright. The homework apocalypse gives us a chance that we won’t all take advantage of, but we should rethink learning. Q. How can we take advantage of this opportunity? A. Active learning classrooms instead of lecture halls are a better way to learn. We haven’t adopted them because it’s easier to keep giving lectures and homework. We have the opportunity to be more thoughtful, and AI tutors are part of being thoughtful, because they help fill in knowledge gaps. Class time should be used to work together on problems. We can’t keep doing what we were doing before. Q. What are some of the biggest misconceptions about AI? A. People are divided between those who are excited about AI and those who are nervous or anxious. Each group has its own myths. For non-adopters, one of the biggest myths is that AI doesn’t do anything original and all you get is pasted together content from others. And that’s not true. AI is built as an elaborate physical model for every human language and uses those rules to create new material based on its training. There is an originality there. That’s one of the big misconceptions. The other is comparing it to Google. It’s worse at the things that Google does well, but better at many other things that Google doesn’t do. Q. You say that the best experts of the future will be those who make the most use of AI. Are people who are waiting to use AI making a mistake? A. I get it, it’s an unnerving technology. People are freaking out. They’re getting a sense of three sleepless nights and running away screaming. It feels like an essential threat to a lot of careers. I think if you’re a good journalist, the first time you think, “oh no.” But then you start to see how this could help you do things better than before. And at least for the next few generations, it’s not going to replace you, even though the technologists say it is. We need to separate from the Silicon Valley noise. On one hand they’re completely right: this is a miraculous incredible technology that emulates thinking, but the other is it doesn’t understand our jobs. Sign up for our weekly newsletter to get more English-language news coverage from EL PAÍS USA Edition Sign up to EL PAÍS US Edition bulletin More information New AI models like ChatGPT pursue ‘superintelligence’, but can’t be trusted when it comes to basic questions Jordi Pérez Colomé How to use AI against conspiracy theories: ‘No, immigration does not increase crime’ Raúl Limón Archived In OpenAI ChatGPT Internet Adheres to More information If you are interested in licensing this content, please contact ventacontenidos@prisamedia.com newsletter Sign up to EL PAÍS US Edition bulletin APÚNTATE Most viewed China’s plan to get around Western tariffs: Fill the world with factories From Republican soldiers to ‘Tommies’: The Spaniards who wore British uniforms to fight in World War II Visa Lottery 2026: How to apply and which countries were left out of the draw Photo essay: The magma of dreams and nightmares of the US-Mexico border wall CERN trains AI models to revolutionize cancer treatment",
    "commentLink": "https://news.ycombinator.com/item?id=41757010",
    "commentBody": "'Students who use AI as a crutch don't learn anything' (elpais.com)91 points by belter 5 hours agohidepastfavorite119 comments TrackerFF 4 hours agoI'm guilty here. For years I've been meaning to learn modern webdev, but every time I've sat down to read the docs, tutorials, books, and what have you - I just give up after a couple of hours. Getting seemingly easy stuff done is just a drag. The other day I decide to try ChatGPT 4o with canvas. For a solid year, I've planned to create some easy membership registration and booking system for this small club I'm part of - just simple stuff to book rooms in a building. Well, to my absolute amazement - I had a working product up and running after 4 hours of working with ChatGPT. One block at a time, one function at a time. After a day I had built on a bunch of functionality. So while I'm not completely clueless on back-end programming, my front-end skills are solidly beginner. But it felt like a breeze working with ChatGPT. I think I manually modified at tops 10 lines during all this, everything else was just copy/paste and upload source files to ChatGPT. Any errors I'd get, I'd either copy/paste, or provide a screenshot. I actually tried doing something similar when GPT3.5 came out almost two years ago, but it was just too cumbersome then. What I experienced the other day felt lightyears beyond that. So, did I learn anything ? No - not really. But did it solve a problem for me? yes. EDIT: But I will add, it did provide solid explanations to any questions I had. Dunno how well it would have worked if my 70 year old mom had tried the same thing, but a gamechanger for people like me. reply swatcoder 3 hours agoparent> So, did I learn anything ? No - not really. But did it solve a problem for me? yes. And this is exactly the concern. The tools are genuinely useful for some tasks. But unlike club organizers getting to DIY some hobby project for their club, students aren't yet being tasked to produce useful things in the best way possible. They're being tasked to do fairly rudimentary things so that they can learn some fundamentals by way of practice. And likewise, in trades like ours, juniors are tasked to do useful things, but they're given affordance to deliver those things in ways that help them learn some fundamentals by way of practice. Students and juniors who skip the practice are basically just trading their future expertise and readiness to accomplish trivial things that either don't or barely matter. Some of them may become the first generation of expert prompt engineers, accomplishing things in totally new ways in what amounts to a novel trade, but many of them are just going to be shooting themselves in the foot. reply echelon 1 hour agorootparentThis is experience though, and people do learn this way. This is the exact same exercise as my first time slapping Dynamic Drive scripts together to customize EzBoard back in the 2000s. I didn't understand any of it at the time. This style of learning is hands on. You learn a little bit about the shape of the problem before you sit down and learn the theory. Not everyone learns by opening the book first. Some people like to get their hands wet. Introduction through practical osmosis can lead to a fertile appreciation for the theory. reply swatcoder 1 hour agorootparent> This style of learning is hands on. You learn a little bit about the shape of the problem before you sit down and learn the theory. We're talking about getting some project or task done. It's a practical exercise by definition. Any learning experience to be had is going to be hands on, and for student/junior-level tasks, it's not going to be some product of knowing deep theory in the first place. But the process of identifying the boilerplate that needs to be written, the process of manually entering it, the process of debugging your own code that you wrote, the process of scouring for examples and explanations, the process of being held accountable in a teacher or colleague's review, the process of discussing your experience of the task with someone who already understands it well... these all provide extra opportunities for hands-on learning that are short-circuited when having an AI put it together for you. Yes, script kiddies and VBA/Excel junkies in the sales department have been slapping together programs they didn't understand for decades, and many people have now joined the industry thinking that they might secure a career as an \"engineer\" by following tutorials well and pasting StackOverflow snippets efficiently. And while some people who found themselves starting on that path have eventually come to transcend it and learn fundamentals more deeply, the \"slap it together\" mentality, the \"find a tutorial\" mentality, and now the \"have a chatbot do it\" mentality easily become quiet traps for people who don't realize that they need to actively transcend them at some point. You can genuinely learn a lot about football by playing Madden on your couch, but if you don't get out on the field and actually play some games, your dreams of making it into the NFL are probably not going to pan out. reply fao_ 1 hour agorootparentprevIt's not learning if the AI is feeding the person an incorrect model of the world, though. There's less likelihood of that if someone is reading information curated by a human that understands the shape of the problem and the domain. The AI doesn't \"understand\" any of that and just spits out words in an order that \"seems correct\" — that's precisely the problem. reply dr_dshiv 1 hour agorootparentThe idea that AI doesn’t “understand” seems implausible with current models. We can say “machine understanding” if normal understanding requires felt experience. Otherwise, for all intents and purposes, the power of these tools rests in their understanding. reply swatcoder 48 minutes agorootparentThe power of these tools rests in how common certain patterns of text are in both immediate and superstrucral ways. They force us to admit that with 8B people in the world, many of the questions we have and tasks we pursue have already been approximated countless times. They reveal that much of what we do is not so original. Understanding -- human or machine -- is something different, and enables invention/originality/reflection in a way that recent innovations are still not yet able to acheive on their own. Importantly, though, students and juniors are specifically being assigned challenges that are already known not to be novel or inventive, which is why these tools can so easily do the work for them. But when when they let the tool do so, they sidestep the unique growth opportunity they were given in the first place. reply echelon 1 hour agorootparentprevUnless the learner is being purposely mislead, it's still learning no matter what the entry point is. Even if the learner is climbing a suboptimal hill, they're still learning the subject landscape and getting a sense of it. It's still a gradient. The entire subject of chemistry is like this. They feed you lies and half truths for the first few years of your undergraduate career so that you develop a sense for things. The real model is far too complicated and scary to introduce. reply anon22981 48 minutes agorootparentIt’s possible to learn literally nothing when using a gen ai. You can copy paste stuff without even glancing your code. For student work sized projects I’m sure it’s very doable to have a working product without knowing anything about how it works. Today I wanted to try to create a tool for a game: snapshot a picture and a program recognizes the clipboard event and does image recog things and gives me data. I had a working poc in 3 hours and learned nothing. (Tbf I knew what I wanted and how to do it in general terms so the process might be different for a beginner.) reply valval 1 hour agorootparentprevI’m at least twice the programmer I was before LLMs, and I spend maybe a tenth of the time reading docs I then did. reply aimazon 4 hours agoparentprevThe point missed here is that you didn’t need to write any code at all, with or without ChatGPT. ChatGPT helped you with busy work: you reinvented something that already exists, instead of using a mature and established membership platform, you built your own. The reason this has parallels to education is because that’s what education traditionally is: busy work. You did learn something, by the way: you learned how to use modern tools. You didn’t do things most efficiently but it was more efficient than writing code without the help of ChatGPT. reply stackghost 4 hours agorootparent>The reason this has parallels to education is because that’s what education traditionally is: busy work. Busy work is work that is assigned merely for the purpose of occupying one's time. That's not the same thing as practice. We drill children in arithmetic not to keep them busy but because it turns out repeatedly solving multiplication problems is an effective way to teach children their times tables. reply hbosch 3 hours agorootparent>That's not the same thing as practice. Exactly right. In terms of education, there generally seems to be a blurry line between was is considered learning and what is considered memorization. If you memorize your times tables, it doesn't mean you've learned multiplication for example... oftentimes the ability to memorize and recall things is opposed to learning, which means leveraging previous knowledge to solve something new. In the case of AI, it usually presents facts and opinions simultaneously (something a calculator famously does not do, for example). Facts are memorized, opinions are learned. In all core studies it's always been more important to understand what you're solving for, and why, rather than \"how\" to solve it. The continued dissolution of the \"how\" barrier is a net benefit for all of civilization, and when experts of \"why\" are valued more than experts of \"how\" the world will be a much better place. reply nunez 2 hours agorootparentThis is one reason why many educators are phasing out homework. It's great practice but can easily lead students to regurgitating information instead of understanding and retaining knowledge. This is also why quizzes and tests are vital in a well-designed curriculum: they test understanding (or at least are supposed to). reply ghostpepper 3 hours agorootparentprevThis may be why the practice was invented but I bet there are plenty of teachers who see it more as a way to keep them busy reply stackghost 3 hours agorootparentYes, intent matters. reply pclmulqdq 4 hours agorootparentprevWhen you are learning something, that busy work helps. What you think of as busy work when you are a professional is actually often sort of novel to learners and is a simple example of how to do stuff. reply whimsicalism 3 hours agorootparentprevI love that AI negativity on HN is so strong that we reclassify whatever work AI can do into “busy work” as soon as it is possible. reply aimazon 3 hours agorootparentThat’s not my point. I’m not disparaging AI. I described AI as modern tooling that is beneficial to learn. I’m sure there are many professional developers saving time using AI to generate code they would have otherwise written. My point is that in this specific case, AI didn’t enable anything useful. I would have said exactly the same if the OP had written the code without AI. If a problem is long solved, reinventing it is busy work. Busy work can be fun, I reinvent things all the time, but that doesn’t change the nature of it. If the project they had built had been something novel (that does not exist) then it would have not been busy work. I was shit talking education if anything :) reply valval 52 minutes agorootparentSo your definition of busy work isn’t “work AI can do”. It’s “work that accomplishes things that have already been accomplished before”. The latter is even sillier. Your position might be indefensible. reply JTyQZSnP3cQGa8B 3 hours agorootparentprev> you reinvented something that already exists Since AI can’t invent new stuff, who will do that? Juniors who haven’t learned anything because of those tools? Or seniors who will disappear one day because they are retiring or are being replaced by AIs? I already work with juniors who use ChatGPT and cannot explain what they wrote. They have a fucking engineers degree and don’t know anything. It’s catastrophic and may increase in the future. What will happen if it continues like this? reply aimazon 3 hours agorootparentcode is an input not an output. People don’t care about code, they care about products. You can build something new using code that already exists: every product we use today is built on a lot of what came before. My point wasn’t that writing code with AI is bad, my point was that writing code for the sake of writing code is bad. If something already exists, use it. If something doesn’t exist, build it, bring something new to the world — whether that’s with hand-typed code or ChatGPT assisted code, I don’t care. I think we should write less code. reply jpc0 3 hours agorootparent> You can build something new using code that already exists: every product we use today is built on a lot of what came before. I don't disagree with this from a business perspective but for an engineers perspective I find it severely limiting. Even very very basic things should probably stay fresh foe you. If you cannot implement a basic parser ( recursive dexent / pratt etc) you will very likely reach for regex when there is likely a better solution that isn't a lot of code. You should probably know how to write leftpad... Or how to strip ascii whitespace using an ArrayBuffer and a for loop in JS. These are things that is extremely easy but a little tedius to do but are fundamental skill to building up more complex solutions later. You should probably know how to build and reason about some more advanced datastructures in your language. Basic trees, directed graphs, trie. These are things that if they are second nature for you to implement you can come up with novel solutions to actually novel problems when they come up. You also get an innate understanding of where the performance characteristics of certian algorithms and datastructures actually lay. Because big O doesn't always tell the full story... reply nprateem 3 hours agorootparentAnd yet in 20 years of coding I've never needed to write any of these. Even implementing a graph is something I've only needed once or twice. It's far more important to know what you want to do rather than how to do it. reply jpc0 1 hour agorootparentAs the parent comment said. Even if you never need to do it. Being quire familiar with these topics can help you select the correct solution. Sometimes you don't need a binary tree, you just need a O(n) linear search but someone who has never played with the actual low level datastructures has no idea when that matters, so in their mind a hashmap makes a ton of sense because searching is between O(1) and O(log n) depending on implementation. But in many cases a flat array will be significantly more performant and is a simpler implementation but in their mind a hashmap is the better solution. Now it probably doesn't matter, but when it matters it's better to know the the answer. That for me is the big distinction between software engineering and software development. Plumbers don't need to be engineers, but there are times when you really need an engineer to design the plumbing system. Strive to be the engineer, purely because you will enjoy the craft a lot more, and people recognise drive and ambition. It doesn't matter if you are in the right place at the right time if you don't have the skills to back it up. Granted if all you want to be is a plumber that pipes APIs together and lives a different life, by all means I encourage you to enjoy life. But don't make students believe thats all their is to the industry. reply nunez 2 hours agorootparentprevIt's not about implementing a graph or a trie. It's about knowing when and why these data structures matter. Sure, you (or an LLM) can probably find a package that can quickly search for a file in an extremely large filesystem. I'm guessing that the authors of S3 didn't have that luxury when they were building out this service years ago, though. There are very few people on Earth that deal with exabytes of data, and prior art only gets you so far in this scenario. The only way something like that can be built is by truly understanding CS fundamentals. Most people study CS to become a SWE. If programming gets reduced to maintaining prompts and optimizing here and there, then there is a real risk of this discipline eroding over time. reply nprateem 3 hours agorootparentprevYes, but there's a balance. The HN purists who are wedded to their knowledge struggle with this, but then someone does need debugging skills to go in and fix things when some of the stupid things AI does makes things break. Also I've found telling it specifically where it's messed up is way more effective than just shouting at it to fix it after it's failed a second time. And sometimes you just need to manually fix it. I wrote an entire library last weekend, then rewrote it on Monday when I realised I'd messed up. Two things I wouldn't have bothered to do without AI doing the coding. I know how the important stuff works and I could pick my way through the JS, but glad I didn't have to write it. I mean, I just wouldn't have. reply valval 1 hour agorootparentprevWere juniors able to explain what they wrote when stack overflow was the source? reply weard_beard 2 hours agorootparentprevI feel in some regards this worry is akin to not knowing assembly. When/if it becomes good enough that the entirety of coding is abstracted away we won't care that new entrants don't understand it. Let's just not lose the documentation on how to modify/improve the AI when needed... Maybe that can be the job of a very select few. Fixing AI the way we fix robots for manufacturing. reply tempodox 4 hours agoparentprevYou happened to use an LLM for something that is most prominent in its training data. Do something off its beaten path and correcting all the hallucinations will be more work than just plain old learning it. reply ants_everywhere 3 hours agorootparentThis is my experience too. Even with pretty common problems in popular languages like Python. The code generated by ChatGPT 4o is full of bugs. If you give it feedback it just thrashes instead of trying to locate and correct the underlying problems. Even if you ask it to think about and correct the underlying problems, it still generates buggy code, often with the same problems it was pretty decent at reasoning about. reply whimsicalism 3 hours agorootparentprevnot true in my experience - of course you have to work within its capabilities but i find it to be a capable partner across large segments of tasks reply banku_brougham 3 hours agorootparentprevyep, this is what have found so far. reply simonw 3 hours agoparentprevI’ve long believed that the best way to learn anything in tech is to attempt to try to build something with it. My hunch is that people who use the process you are describing will still get a massive leg-up in learning skills like web development. Often it isn’t a choice between using AI-assistance to get some working vs spending 20 hours figuring it out from scratch: it’s a choice between getting somewhere with AI or not doing the project at all, because life is full of things to do that are more rewarding than those 20 hours of frustration. Anecdotally, I’ve heard from a bunch of people who always wanted to learn software development skills but were put off by the steep initial learning curve before you see any concrete progress… and who are now building useful things and getting curious about learning more. reply lovethevoid 2 hours agorootparentI agree on building to learn, but disagree on the massive leg-up. It's like believing that using a template off GitHub is going to teach you much (outside of specific use cases). This is also why a lot of GitHub issues now submitted by users don't even follow very basic processes you may have outlined on narrowing down problems. Here's this long copied code from terminal, fix it. What makes the most difference in building to learn is the tiny steps you take to build. Printing hello world for the first time, changing it and seeing something else, using inputs for the first time to print hello, [variable], getting that image to animate across the screen. Each step becoming a great foundation for further curiosity, rather than turning your project into a black box. In contrast, I've heard from a bunch of people who wanted to learn software development, but now don't see a point since AI can do it. Same with drawing. There's a large growing apathy towards learning skills I've noticed. This is why most advocates for it don't do it from the perspective of learning. They do it from the perspective of building fast in the hands of those who already grasp the foundations. reply treflop 3 hours agoparentprevIf it’s not your daily job, I don’t see the harm. Sometimes I use ChatGPT for something I absolutely don’t care about. But if it is, then I think you’re trading it for a career of trial and error. Regularly I watch people at work spend a week trying to solve a problem, but because I learned the fundamentals at some point in my past life, I am able to break down the problem, identify the root cause, and solve it quickly. reply analog31 2 hours agoparentprev>>> So, did I learn anything ? No - not really. But did it solve a problem for me? yes. In my old age (60), I've gotten a little bit philosophical about this issue. I'm old enough to have pored through entire textbooks and manuals, e.g., BASIC, HyperCard, Turbo Pascal, MS-DOS (to name a few). But I can still ask myself at the end of the day: So, did I learn anything? Those things are all flawed, temporary creations of some individual, and are no longer useful. On the other hand, there are certain things that I've learned, and consider to be \"fundamental,\" such as math, physics, and admittedly, music. Now a philosopher might correct me and point out that my choice of \"fundamental\" is arbitrary, but if nothing else, those things are long-lasting. The laws of physics that I'm capable of grasping haven't changed in my lifetime, nor has the technique of playing the double bass without injury. Perhaps a thing you could do is sit down and decide what things you consider to be fundamental enough (relative to your interests) to learn on a deep level, and what things you can interact with on a superficial basis by letting AI take care of them for you. reply hammock 3 hours agoparentprevThe whole thing reminds me of how we used to check out BASIC books from the library and manually type in complete programs, games etc from the book and run them. I wouldn’t say I learned NOTHING, far from it, but it definitely wasn’t a path to become fluent in BASIC reply illwrks 2 hours agoparentprevNot to put a downer but have you also perhaps created a liability for your club? If you don’t fully grasp what is going on with the code have you potentially left the door open to exploits? reply dmurray 1 hour agorootparentA reasonable thing to be concerned about, but he described having a solid understanding of the backend, which is the more likely place to introduce a security hole. reply sibeliuss 3 hours agoparentprevAs someone who already has skills in backend / frontend, AI tooling has made me fearless in terms of new material. I couldn't type it out by hand, but by getting something working through a (much faster) trial and error process, I'm learning so much! I suspect this is your case as well. There's a lot of learning going on underneath, which will only improve your abilities in ways that will come back as astonishingly beneficial if you keep working on your project. reply furyofantares 3 hours agoparentprevYou also didn't learn modern webdev for the years you'd been meaning to. You're actually better poised to learn it now if you care to, now that you have a component you care about that already works that you can work from. Of course maybe you won't, maybe having GPT there will indeed prevent you from ever learning it, I don't know. reply bdlowery 3 hours agoparentprevYou skipped all the hard parts, all the struggling, and now you have a working product without a mental model and can't level up to doing harder things on your own. Struggling IS learning. You didn't try different paths, piece different info together, and then eventually create a mental model. You just used ChatGPT to skip to the end result. It's like enrolling for a Calc 2, cheating on all the homework to get an A, and saying \"did i learn anything? No, but it solved all of these annoying homework problems for me!\" Now when you have to take the 1st exam you're screwed because you didn't learn anything. reply jessekv 2 minutes agorootparentTo dig into your metaphor, what would you say is the equivalent of the first exam in a programming context? reply drdeca 2 hours agoparentprev“In the Phaedrus, writing is the pharmakon that the trickster god Theuth offers, the toxin and remedy in one. With writing, man will no longer forget; but he will also no longer think.” When I have to navigate to somewhere I haven’t been before, I generally do not read a map, but follow instructions from some navigation software. As a consequence, I often don’t really know where places are, just the route I take to get to a destination. With GPS navigation, I do not get lost, but neither do I have much awareness of how locations are spatially arranged. Such technologies seem to always be like this. A potion which removes a difficult task, but also dulls the ability to do such tasks oneself. It is like that one SMBC comic https://www.smbc-comics.com/comic/identity “ Humans offloaded memory to books, then thought to computers. Now, we're offloading our desires to the network. All that remains are basic bodily functions, which well offload in another generation or two. At that point, well just merge into one united entity so, it all works out.” reply aithrowawaycomm 3 hours agoprevThis condescension is very common and very irritating: > Q. You say that the best experts of the future will be those who make the most use of AI. Are people who are waiting to use AI making a mistake? > A. I get it, it’s an unnerving technology. People are freaking out. They’re getting a sense of three sleepless nights and running away screaming. It feels like an essential threat to a lot of careers. I think if you’re a good journalist, the first time you think, “oh no.” But then you start to see how this could help you do things better than before. There are a lot of white-collar jobs where LLMs do more harm than good because a 1/4 hallucination rate means you waste too much time on wild goose chases. I briefly thought GPT-4 was useful for finding papers given a description of the results - I “kicked the tires” with some AI research and was very impressed. But when I tried to find papers on animal cognition, about 75% of the results were fictional, though supposedly authored by real animal cognition experts. And GPT-4o is even worse! The tools are just not good enough for my use case; Google Scholar is far more reliable. I just don’t understand the childish motivated reasoning behind assuming the skeptics are scared. Maybe if I spent “three sleepless nights” talking to ChatGPT I would be more enlightened. reply rsynnott 19 minutes agoparent> I just don’t understand the childish motivated reasoning behind assuming the skeptics are scared. Maybe if I spent “three sleepless nights” talking to ChatGPT I would be more enlightened. A lot of people are very invested, whether emotionally or financially or both, in this stuff not being a flop. There’s a lot of motivated reasoning going on. It is necessary to believe that the heretics simply haven’t seen the light yet - to question that gets too close to questioning whether there’s any light to see. reply simonw 3 hours agoparentprev> I briefly thought GPT-4 was useful for finding papers given a description of the results. That’s one of the many poorly documented traps of LLMs: trying to use them to find papers like that is a fast-track to worthless hallucinations. If that was one of your first experiments I can’t blame you for thinking this tech is “more harm than good”. LLMs are terrible search engines… except for the times when they are great search engines! Learning when and what to use them for continues to be a significantly under-appreciated challenge. reply aithrowawaycomm 2 hours agorootparentNo, it was not my first experiment - again with this unbelievable condescension! I have been playing around with this stuff since GPT-3. That was my first practical use case where GPT wasn't a totally useless waste of money. It works very well with AI-related papers, maybe a 1% hallucination rate. I got the idea from an AI researcher and I was intrigued that ChatGPT might actually be useful for me. But it was not. The problem, as always with ANNs, is that I went slightly off the happy path. Even a skeptic like me assumed the AI papers successes was evidence that GPT-4 was better at remembering its pretraining data; instead I think it's evidence that a data contractor RLHFed the answers and GPT had it memorized. > LLMs are terrible search engines… except for the times when they are great search engines! But note that what you said about finding papers was wrong, it works extremely well for AI research. The reason LLMs are useless to me across the board is that these unpredictable and arbitrary limitations apply to everything, not just search. \"Learning when and what to use them for\" is pure trial-and-error because it seems to amount to guessing what tasks the 3rd-party data contractors trained the LLM to solve. I am not a Python or JavaScript developer, nor do I write code for extremely well-known libraries. I use F# for oddball projects (often analytics), and GPT-4 was utterly useless for F# codegen. My first experiments with GPT-3.5 showed that it would plagiarize hundreds of lines of public F# projects, including from my own GitHub, without any prompt engineering or trial-and-error - it was just blind plagiarism. GPT-4 isn't quite that bad, but it's still not even close to being good enough to help me - in particular it has no understanding of high-performance F#. I would be spending far more time auditing and optimizing its crappy code. And time spent writing code has never been the limiting factor in my F# development. I also do some recreational mathematics on finite geometry and combinatorial group theory; GPT-4 was utterly useless here, even with CoT prompting, and even though it solved more complex graduate-level algebra problems without any difficulty. Of course, those problems were repeated and solved in dozens of graduate textbooks. My cute little groups, not so much. I believe CoT prompting is theoretically incapable of helping GPT here since the computational complexity is too high. What CoT prompting gives you is a bunch of insidious errors that take time and effort to unravel. Otherwise there's nothing I do that would even conceivably benefit from an LLM: it can't play guitar, it can't play with my cats, and I would never use it to communicate with friends or family. I guess I could fill my brain with shallow subject knowledge about something, a few choice sentences. But I'd much rather understand something in depth by reading a book. I'm not too busy to read a book. Otherwise... maybe I could use LLMs to write polite no-thank-yous to unsolicited recruiters. This tech truly has nothing to offer me. I think you are failing to understand that, as a Python developer who maintains one of the biggest Python web frameworks and writes a popular blog for general tech audiences, LLMs are unusually well-suited towards your use cases, due to reasons that will not extend to people working in more isolated corners of the world. reply lolinder 2 hours agoparentprev> There are a lot of white-collar jobs where LLMs do more harm than good because a 1/4 hallucination rate means you waste too much time on wild goose chases. I briefly thought GPT-4 was useful for finding papers given a description of the results - I “kicked the tires” with some AI research and was very impressed. But when I tried to find papers on animal cognition... This is less a question of which jobs benefit from AI in general and which don't than it is a question of tasks and specific tools. ChatGPT is not a search engine, so if you're looking for existing documents it's a very bad choice. But I've found myself using Perplexity—an LLM-powered search engine—more and more often because it reliably turns up results that Google fails to turn up. I suspect Perplexity is still also the wrong tool for scholarly articles, but that's not a fundamental limitation of the tech, it's just a question of the focus of the tools so far. reply dyauspitr 1 hour agoparentprevWhat are you talking about? I haven’t had a hallucinated link since 3.5 to paper sources. They must have some sort of post processing in place to remove made up links. reply karaterobot 3 hours agoprev> Q. Isn’t it inevitable that AI will make us lazier? > A. Calculators also made us lazier. Why aren’t we doing math by hand anymore? You should be taking notes by hand now instead of recording me. We use technology to take shortcuts, but we have to be strategic in how we take those shortcuts. An unpopular opinion I have is that most of the doomsaying about technology making us dumber is true. Yes, even back to Socrates. I won't say all, but I'd safely say a lot. What happened was that we developed tools, lost certain capacities without necessarily losing the capabilities that came with them, and redefined the level a normal human should function at. My only point is that people don't like to think that maybe they themselves are less intelligent—in many ways—than people who urinated outside and didn't know what the sky was. But I don't see how it could be any other way. When we say things like \"I don't need to remember, I can write it down\", and \"I don't need to do arithmetic in my head, I'll let a calculator do it\", or \"I don't need to read the article, someone will explain it in the comments\" we are accepting the consequences of that, good and bad. reply master_crab 3 hours agoparentPeople aren’t dumber, or smarter. They just focus on what’s the next important thing to tackle. For example, I doubt any website programmer knows the circuitry, assembly code, OS level calls, networking, etc, that make any webpage element do anything. Let alone can sit there and calculate any of the mathematical requirements needed to do any of that. But they know how to use an IDE and a framework like React. All this is a long way of saying: …on the shoulders of giants. AI is just the new tool needed for the next step up. reply mckravchyk 2 hours agorootparentIt's a completely different thing. You are talking about civilisation constructs, parent is talking about things like mental fitness, abilities to perform tasks in real-time by yourself. For example, card payments are a crutch. If you pay by card / phone everywhere and then out of the sudden you are to pay in cash, it becomes mildly challenging vs. if you are used to pay in cash you don't think about it. The brain is capable of a great deal of automation, performing learned actions is effortless. Unlike a calculator or a spreadsheet, the buyer is not doing anything, just buying. It's not a bicycle, it's a crutch. It simply atrophies the mental bandwidth. The mind becomes more lax, less sharp, when it does not engage. Now imagine what it will do to people's brains when instead of thinking about solutions themselves, they will ask the AI for everything. Those neurons will atrophy and the person will be even less skilled to ask the AI the right questions than if they did not use the AI in the first place. I think the key will be a balance between doing the work yourself and delegating the stuff to AI, but it will be difficult to find that balance. Just like smartphones can be very useful but in the end are a net negative to society. reply aliasxneo 2 hours agorootparentprevYeah, I'm not sure I understand how moving up an abstraction layer necessarily makes you less intelligent. I also don't think it makes you smarter. For the average individual, I feel like it simply moves your \"cursor\" up the stack, but you're not necessarily increasing your context window. Perhaps the confusion comes from the fact that we often produce more complex things as we move up layers. It's then assumed that the people who made them must be more intelligent, but as I said, I don't think that's a fair assessment. I would say the real measurement for intelligence here is how much of the abstraction layers you actually understand. In other words, can you move your cursor back down the stack and operate just as well as in the higher layers? Can you do this while unifying the complex interactions between each layer into a cohesive model? I've noticed that even AI tends to be pretty bad at this last step. It often takes prodding to get it to see the subtle errors often introduced when working with complex systems. reply aniviacat 3 hours agoparentprev> redefined the level a normal human should function at To a level much higher. We stopped doing many repetitive, tedious things, but in return moved to things that are way more abstract and complex. And that's happening everywhere. Even farmers are getting ever closer to being full on system architects. Oh, you didn't learn to do quickly calculate square roots in your head? Instead you spent that time on learning about relativity in high school physics class. By calling the people of the past smarter, you are really underselling the amount and depth of abstract though happening everywhere today. reply mamcx 1 hour agoparentprevI agree, and maybe a better frame is 'capable'. I can do math with a calculator, but if it is taken away? I can feed myself with doordash, but if it is taken away? I can program a complex web-scale app, but if all those tools are taken away? What is left? Somebody who will die fast. Reliance on all of this is removing agency and resiliency. By the law of numbers, the planet still has people who know some of the fundamentals that make the existence of the rest viable. But if it is taken away? reply valval 35 minutes agoparentprevI think technology makes the people who create it smarter, and doesn’t affect average people. reply 6SixTy 19 minutes agoprevI've been working with a CS student that often does not understand why her code doesn't work, does not want to understand how to improve herself, nor want break down a situation to it's bare components and apply them to new situations. I could give a bunch of long (and probably butchered) stories of my sessions with her, but in short, she's expects to be spoon fed the answers without properly digesting why they are the answers. She turns to ChatGPT because it will just automatically give her the answers without forcing her to do any thinking, just copy + paste in order to tick off another assignment. There's probably a middle ground where you could use ChatGPT properly, but I've had her reach towards ChatGPT once for what essentially amounts to spelling errors that she never notices herself or pay attention to errors telling her that she spelled something wrong. It's kind of hard to be supportive of a tool when the tool itself can essentially act like a replacement of your thinking cap and can't say no. reply vunderba 2 hours agoprevThe danger in the eventual ubiquitous availability of large language models (LLMs) isn't necessarily that they can seemingly answer any question. The real issue arises when it becomes far too tempting to immediately turn to an LLM for an answer, rather than taking a few moments to quietly ponder the problem on your own, engaging and manipulating, exploring different angles, etc. This kind of abstract thinking is a craft that only improves with consistent practice and deliberate effort. reply _tk_ 4 hours agoprevVery misleading title. From the article: „The crutch is a dangerous approach because if we use a crutch, we stop thinking. Students who use AI as a crutch don’t learn anything. It prevents them from thinking. Instead, using AI as co-intelligence is important because it increases your capabilities and also keeps you in the loop.“ reply ksd482 4 hours agoparentI feel like this is exactly what the title is conveying. What’s misleading about it? reply fgbnfghf 4 hours agoparentprevI use AI to ask questions when I am not totally sure what the question is, and it is very helpful for narrowing that down. It can be powerful as a tool to help get your foot in the door on new knowledge. Just like google search there is a correct way to use it and an incorrect way. Another thing to consider is the motivation of companies like OpenAI. Their products are designed to be used as a crutch. Their money is in total reliance on the product. reply lolinder 2 hours agoprevThe headline implies something other than what the interviewee is saying: > Q. You don’t like to call AI a crutch. > A. The crutch is a dangerous approach because if we use a crutch, we stop thinking. Students who use AI as a crutch don’t learn anything. It prevents them from thinking. Instead, using AI as co-intelligence is important because it increases your capabilities and also keeps you in the loop. > Q. Isn’t it inevitable that AI will make us lazier? > A. Calculators also made us lazier. Why aren’t we doing math by hand anymore? You should be taking notes by hand now instead of recording me. We use technology to take shortcuts, but we have to be strategic in how we take those shortcuts. reply ethn 2 hours agoprev‪ZIZEK: that AI will be the death of learning & so on; to this, I say NO! My student brings me their essay, which has been written by AI, & I plug it into my grading AI, & we are free! While the 'learning' happens, our superego satisfied, we are free now to learn whatever we want‬ reply nunez 2 hours agoparentYes, but therein lies the rub. Those that know how to learn will benefit. Those that don't will regress, possibly for life depending on when AI is introduced. This is especially demonstrated in essay writing. Many students associate essays with busy work because the topics they're asked to write about are boring. When the typical assignment that's given is \"read this boring ass book from the 40s that's been in the curriculum for decades without revisiting its application in today's world, then write a 1000-word essay on a topic that's been discussed to death that you couldn't give less of a shit about; points will be deducted for views that stray too far from the norm,\" then it's absolutely unsurprising that most students will shove this into ChatGPT and call it a day. On the flip side, when English or composition teachers are forced to assign thess assignments knowing full well that it's a crock of shit, then it is equally unsurprising that they will feed GPT into GPT and call it a day. Students that know how to learn and are actually interested in becoming better writers will find ways around this. Teachers who have the freedom to design their own curriculums will be more creative about the types of prompts they assign and the books they have their students read. The common link between the two? Money, of course! reply htk 2 hours agoprevTerrible agenda-driven title, implying that the interviewee's main message was about the dangers of relying on AI, where in fact it was the opposite, how AI can be a great tool to elevate human capacity if used well. reply sirsuki 2 hours agoprevIn struggled with this trend even before the AI hype. I love learning and focused my work towards always learning. But it takes energy and lots of work; some days are better than others. My love of learning keeps me motivated over time. However, I’ve noticed a downward trend of juniors who are focused on being spoon fed the answers and avoiding any learning. It drives me nuts and I don’t know how to reconcile this kind of mental model. reply Smithalicious 3 hours agoprevDamn kids, back in my day we had to copy-paste our homework from stackoverflow uphill both ways reply pluc 4 hours agoprevTechnology that renders effort and research pointless makes people lazy and stupid, story at 11 reply throwaway918299 4 hours agoparentI’m sure there were people that said the same thing about Google. I’m pretty sure they even said the same thing about the written word. reply yoyoyo1122 3 hours agorootparentIt's such a \"Back in my day...\" mentality. \"Farmers today are much less skilled and knowledge than farmers 50 years ago!\" reply gomerspiles 4 hours agoparentprevI suppose a headline that doesn't have much to do with the content is also such a technology? reply Asraelite 3 hours agoprev\"Free browsing by accepting cookies\" or \"subscribe and decline\". Is this legal? It might be, but I've never seen other sites do it so it seems dubious. reply pier25 3 hours agoprevThe less we learn the more stupid we'll be. The brain, like any muscle, atrophies if you don't use it. This is already happening with genz in college. https://www.theatlantic.com/magazine/archive/2024/11/the-eli... reply vunderba 2 hours agoparentWhether or not there is any truth to pithy sounding sayings (that have been parroted since the dawn of time aside), the brain is NOT a muscle. https://www.hopkinsmedicine.org/health/conditions-and-diseas... reply pier25 2 hours agorootparentIt's obviously not a muscle. Wasn't the metaphor obvious? reply pavel_lishin 3 hours agoparentprevI'd wager you can find a copy of an article with that premise about every generation going back to a generation after the invention of writing. reply pier25 2 hours agorootparentWhat about IQ declining after many generations of growth? Or what about the attention span crisis? Or the lack of technical skills in genz? I seriously doubt this is a generational thing as you seem to be arguing. Smartphones and social media didn't exist until 15-20 years ago and we're now seeing the consequences. reply bachmeier 3 hours agoprevThis type of article is so frustrating. \"You need to use AI to make yourself more productive.\" Followed by zero explanations of how I can do that. In addition, no mention of the implications of sending all your personal information to an entity that is waiting for an opportunity to use it against you. reply fnordpiglet 4 hours agoprevIf you use a crutch you won’t learn anything is an age old truism. I don’t know why we would think a new tool somehow changes that dynamic. My daughter is 10 and she is learning factoring, long division, and other things that a calculator does very well with. But she’s not allowed to use it at this stage because she can’t learn while using a crutch. She’s also learning to write essays. She writes her essays then puts them into ChatGPT and asks for analysis, feedback, explanatory revisions. Then she revises the essay on her own without being able to refer back to the advice. This is using AI as a complement to learning and it’s been remarkably powerful. She can get feedback immediately, it’s high quality and impartial, and she can do it as many time as she finds useful. So, the fundamentals of learning don’t change no matter how powerful or different the tools become. But ignoring the tools because they can be used in place of learning if used in place of learning is dumb. reply hyperG 2 hours agoparentIt wouldn't be shocking to me that in 30 years, your daughter would be tasked with writing a whole book and not just an essay. Part of the learning process is learning to leverage technology. Something I think we do a really bad job at teaching kids. Of course, leveraging technology to do the exact same thing you would do without the technology is a terrible lesson on many levels. reply ryandrake 3 hours agoparentprev> My daughter is 10 and she is learning factoring, long division, and other things that a calculator does very well with. But she’s not allowed to use it at this stage because she can’t learn while using a crutch. Which seems silly to me, but what do I know, I'm not a teacher. Nobody does long division in real life after K-12 school. It is not a useful skill to have, and it is not a useful concept to know. If I have to divide two numbers I just use a calculator like 99% of the humans on the planet. Knowing what division is, and what it means to divide one number by another is valuable, but can you just teach that without teaching the mechanics of \"divide the partial dividend by the divisor, then multiply the partial quotient by the divisor, and subtract from the partial dividend, extending to the next blah blah blah blah\"? Are we really training the next generation for a world without electricity? reply ben_w 3 hours agorootparent> Nobody does long division in real life after K-12 school. It is not a useful skill to have, and it is not a useful concept to know. To my surprise, when I did pure maths at A level I found the same ideas applied to dividing one polynomial by another. Of course as a mere memorisable algorithm a computer can also do this, so I'm not sure how useful it is even to pure mathematics, but there is (or was, 20 years ago) some use to the idea. reply nasmorn 3 hours agorootparentprevMaybe learning to follow a simple algorithm helps some children to structure their thinking. Divisions are not hard to do. Doing a lot of them has little benefit though. reply EVa5I7bHFq9mnYK 2 hours agoprevStudents who use assembly language as a crutch, don't learn the machine codes properly. reply brookst 3 hours agoprevI’m old enough to remember when the same claims were made of graphic calculators and high lever languages like Basic. A better formulation is perhaps “students who use AI to reduce work learn different things”. It’s easy for purists to say there’s no value whatsoever in learning to use a tool rather than learning to do the work. But that’s a judgment about the value of what is learned, and it’s kind of dishonest slight of hand to substitute that opinion. reply renewiltord 2 hours agoprevHighly useful tools are always described like this. Amusingly, search engines and then, to a lesser extent, Stack Overflow were both described like this. I can’t say that it’s very interesting a statement in its nth incarnation. reply adamnemecek 2 hours agoprevDo students who don’t use AI learn anything though? reply StarterPro 2 hours agoprevNo shit. Just like people who \"create AI art\" aren't actually creating anything. We've let these tech companies distill learning and creating down to a mouse click. reply nonrandomstring 3 hours agoprev> don't learn anything I don't think this is true. We learn a lot: Deference. Dependency. Entitlement. Impatience. Conformity. Distraction. Overconfidence. Intemperance... If something \"does the thinking for you\" it has a much deeper effect than simply being a \"crutch for the mind\". It changes our relation to the world, to knowledge, motives, ambition, self-control... \"AI\" is going to change our minds, but from what I've seen so far the outcome is a really quite awful kind of person, a net burden to society rather than a creative and productive asset. reply visarga 2 hours agoparentMaybe we need AIs that take care of our growth as well. Let's say a school or company mandates one hour chatting with an AI that will ask you questions and probe your knowledge, and give in explanations as well for things you don't know. The more time you spend with it, the better, it acts like a tutor not like a subordinate that hides away complexity from you. There is no reason AI can't work like a tutor, the current crop is just a first take on the human-AI interaction problem. The motivation part can be solved by gamification and constraints - you need to earn a number of points by chatting the AI, and those points are reported to your teacher/manager. So a triad of student+AI+human coach would solve the motivation part. reply nonrandomstring 34 minutes agorootparentThose are called parents. reply iamleppert 4 hours agoprev [–]That’s what they said when the calculator was invented. Out with the old, in with the new! Sorry but not sorry life was so hard before but we got AI to do the work for us now. reply giantg2 4 hours agoparentNot the same at all. The results of calculators are verifiable. The results of AI can be dangerously wrong without easy validation. Calculators don't eliminate the application of concepts from learning, but AI does. reply parpfish 4 hours agorootparentVerifiability is part of it, but the other part is that calculators don’t provide a full end-to-end solution (unless you’re doing worksheets for homework). Each calculation is just one step, it’s up to the user to figure out which steps to take and how to chain them together. they might even learn that the whole thing would be faster if they could do some of those calculations their head. like if you’re trying to figure out how much wood to buy for a deck, you’d still need to break the big problem down into those individual computations to do in the calculator. Unlike an llm where you could just ask it and it’d jump straight to a final answer reply ben_w 3 hours agorootparentprevThe results of a calculator are only easy to verify with either someone who can do the same arithmetic or who has another calculator. I had this happen to me once while shopping, where I could immediately tell that three items costing less than £1 each should not come to a total of more than £3, but the cashier needed that explained to them. (And that's aside from anything about asking LLMs to output in a format suitable for mechanical validation, which they can generally do). reply rthrth45y 4 hours agorootparentprevGood point but also not a new problem. Humans use the same mechanics to assign variable weights and biases in order to validate information. If you look at a banana, you can determine what it is based on the knowledge you contain, and that process triggers a similar cascade of weights. the difference is brains are much more capable of this, but we still misremember things and recite wrong information. The game of telephone is a great example. I don't think AI eliminated the application of concepts from learning. I think that has been eliminated enough due to the erosion of our public education systems. If we are not capable of critical thought with the information our own peers present us, why would it be any different when we seek it from AI? reply givemeethekeys 4 hours agoparentprevMy friends in a top tier high school had no intuition about numbers because they used calculators for everything, including basic addition and subtraction. Some of them had customer service jobs where they became utterly confused if the change was 99 cents and the customer gave them an additional penny. reply pclmulqdq 4 hours agorootparentEveryone crying \"calculator\" about ChatGPT has me convinced that ChatGPT is bad for your education. Learning to do mental math as a child sucked, but now that I can do it, my brain is so much more free to think about stuff that matters. There's no intervening step of \"let me pull out a calculator to see what that is,\" I just know the answer. The thoughts can just flow freely. reply SoftTalker 3 hours agorootparentThis is true of all memorized facts. It enables thinking at a higher level. “Why should I learn multiplication when I have a calculator on my phone” ignores this. The more you have memorized the more nimble your thinking is. If you have a large vocabulary you can effortlessly express yourself with precision while others are thumbing through a thesaurus (or these days asking an AI to “rewrite”). If you know the history of something you can have more interesting perspective and conversations about it. There is almost no situation where the person with a lot of memorized knowledge is at a disadvantage to the person who needs to look everything up or rely on tools to do the work. reply skydhash 2 hours agorootparentTrue. I have friends that have refused to learn algorithms and instead insisted that they only needed to master $FRAMEWORK. Then they got stumped by any problems that can not be solved by $LIBRARY, spending days on it with no result. Yes, it takes time, but learning is exponential, and overtime, the pace will increase greatly. reply ben_w 3 hours agorootparentprevThat's true for every skill that comes fluently. We've only got limited time, which skills really matter? I'd say yes to basic arithmetic; but I can't really use my own experience as a software developer who started off in video games to justify why a normal person needs to understand trigonometry and triangle formulas, any more than I can justify why they need to study Shakespeare and Alfred Tennyson over e.g. Terry Pratchett and Leonard Cohen — \"I find it intellectually stimulating\" is perhaps necessary, but certainly not sufficient, given there's more to learn than we can fit in a lifetime. reply skydhash 2 hours agorootparentBecause they give you flexibility. One does not need to master everything, if you have a wide and stable foundation, your options become more numerous later in life. And expertise is a pyramid, so the more diverse your basic skills are, the farther you can reach. reply mistrial9 4 hours agorootparentprevexcept that the typical case is ... the charge is $1.01, I give you a $5 and a penny. A penny from the client to the house on top of a charge of $0.99 by the house, does xxxxxxxxx ... (edit) as pointed out below, a penny plus a $0.99 charge means that the cashier can return a whole number of bills, avoiding any coins.. reply abanana 4 hours agorootparentThe change, not the charge. If the change is 99 cents, the customer gives an extra penny, the change is now 1 dollar, avoiding a handful of coins. It seems to have become the norm for young cashiers to be unable to understand. And if you try to explain, they'll insist \"I can't change it now I've rung it through\". Some seem to think the system keeps an exact record of the quantity of each individual coin (or they just don't even know where to begin to think about it). reply bogdan 2 hours agorootparentThis totally happened me as well but I don't necessarily see the connection with calculators. This is all anecdotal imo. reply Dalewyn 3 hours agorootparentprevAnother possibility: \"The register says 99 cents change and I am not paid enough to give any more of a damn than that.\" reply pessimizer 3 hours agorootparentIf you have basic comfort in arithmetic, this is not a calculation that involves giving a damn. Being confused about why someone would give you an extra penny and having a discussion about it with a stranger burns 100x more calories than knowing it. If basic arithmetic involves taking a deep breath and closing your eyes for half a minute, or looking around the room for a calculator, that's a different cost/benefit analysis. It's like the difference between a language you are fluent in and a language you are tentative in. If you're fluent, you have to make an effort not to listen to somebody's loud conversation, or not to pay attention to a billboard. They intrude into your consciousness. There's never a situation when I don't do simple arithmetic when exposed to it. I don't have to consciously figure out what 4 times 9 is. Subjectively, the number just pops into my head when I see the question. edit: If you can't do this with explanations of identities or related rates, etc., it's hard or impossible to follow any quantitative or especially probabilistic argument. Even the simplest ones. I think this results in people for whom arithmetic is difficult faking it by trying to memorize the words used during quantitative arguments without having any real understanding. Just sort of memorizing a lot of slogans and repeating them during any argument that shares similar words. I think discomfort with arithmetic ruins people politically (as citizens), so I really do think calculators are a problem. reply s0ss 4 hours agoparentprevLots of nuance that you’re not addressing, IMO. Here’s some more nuance: Steroids. It’s not a perfect metaphor, But I think it’s useful. Two people are trying to gain muscle mass. They both have an ideal starting point. First person has a healthy diet, lots of exercise, and sleep. The second person has all of the same things the first person however they also taking growth hormones. Lots of folks look at the two results and will see lots of different things. Beauty is in the eye of the beholder I suppose. If you think the end results of the work should yield sculpted bodies with larger than normal muscles… you might opt to use hormones. However, if you think sculpted bodies with larger than normal muscles looks unrealistic or just not your style/goal… you would probably opt for a more natural approach. Both have their merits and could be described as “fit” despite their differences. folks may value one over the other. people might fantasize about looking like thor, but if everyone actually looked like thor, things would be weird. My two cents: Thor is fiction, and while we need fiction. Im not going to pretend that anyone should look like thor in order to be in shape or to be described as fit. If we allow ourselves to be fooled into thinking that it can be normal to look like thor, then we are doing something wrong. Fiction should not become reality. reply StefanBatory 4 hours agoparentprevNo, I can't agree with you here. I'm software engineering student. I had a phase year ago where I was using ChatGPT a lot, a lot more than I ever should have. And it messed up with my brain a lot. I felt I became utterly lazy; to the point where quick fixes that should have taken me like, 10-15 seconds (?) I had to do with AI, which often took a very long time. And the point of studying is to learn. You won't learn anything if you have someone else write your software for you. reply wredue 4 hours agoparentprevA new study also shows people using AI produce code with 41% more bugs. And that’s just what the users missed! Calculators arent giving you “kind of correct” answers. reply aspenmayer 1 hour agorootparent> A new study also shows people using AI produce code with 41% more bugs. And that’s just what the users missed! Do you have a link or more info? Without further context, the 41% doesn't tell us the whole story; all we have is a numerator lacking a denominator. Did bugs per line of code go up, or down? Did # LOC produced after using AI go up/down? For all we know, the increase in productivity caused average bugs per line to go down, rather than up, which is contrary to the argument you're making. reply blibble 4 hours agoparentprevthe difference is I still understand everything the calculator can do, and can do it by hand on paper the AI generation is not going to know how to do anything other than type into chatgpt at which point human progress ends and we start going backwards reply SoftTalker 2 hours agorootparentAnd worse, the people who control the AIs now have ultimate power to rewrite history and mold opinion. If they want everyone to think the earth is flat they can do it. reply lawn 3 hours agoparentprev> That’s what they said when the calculator was invented. And it's beneficial to ban calculators for learning, which is the point of the article? reply nonrandomstring 4 hours agoparentprev [–] >> life was so hard before but we got AI to do the work for us now. Aggression against what? Yourself? I think you show a tragic misunderstanding of technology and what it is doing in the world. It's not the work that it's doing for you. It's the living. Is it really your life you want a machine to take? Nobody wants to \"work\". Henry David Thoreau said ,\"There is no more fatal blunderer than he who consumes the greater part of his life getting his living.\" All good, no? But that's not what \"AI\", in the hands of exploiters (or even yourself, as a self-exploiter) is going to do to you. Technology is more \"productive\" but creates more, not less labour. Better to heed Max Frisch who said, \"Technology is the knack of so arranging the world that we don't have to experience it.\" Would you employ a machine to enjoy a music concert for you? To have sex for you or play games for you so you're not troubled by the effort? reply Dalewyn 3 hours agorootparent [–] >To have sex for you or play games for you so you're not troubled by the effort? Two of the three games I play on a daily basis largely play themselves, so... yes, actually. I still have plenty of fun watching them. reply nonrandomstring 3 hours agorootparent [–] That is very interesting. Are you talking like city simulation games? I get the entertainment of quite passively tweaking and watching things unfold. But at what point would you say \"hey I'm not really a participating player any more, this is just watching TV\"? Is it still a game at that point? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ethan Mollick, a professor at the University of Pennsylvania, has released a book titled \"Co-Intelligence: Living and Working with AI,\" focusing on the effective integration of AI into daily life.",
      "Mollick emphasizes the strategic use of AI as a co-intelligence tool, enhancing human capabilities rather than serving as a crutch that could impede learning.",
      "The book discusses AI's potential in education, advocating for active learning and personalized tutoring, while addressing misconceptions and encouraging a balanced understanding of AI's possibilities and limitations."
    ],
    "commentSummary": [
      "The use of AI tools by students may lead to a lack of understanding of fundamental concepts, as they might rely on AI to solve problems without engaging in necessary practice.",
      "There is an ongoing debate about whether AI enhances or obstructs learning, with opinions divided on its role in education.",
      "While AI can offer innovative ways to interact with educational material, there is concern about the potential negative impact of becoming overly dependent on these technologies."
    ],
    "points": 91,
    "commentCount": 119,
    "retryCount": 0,
    "time": 1728221063
  },
  {
    "id": 41754084,
    "title": "We're excited about our new roundabout",
    "originLink": "https://wsdotblog.blogspot.com/2024/10/in-case-you-cant-tell-were-really.html",
    "originBody": "The WSDOT Blog Friday, October 4, 2024 In case you can’t tell, we’re really excited about our new roundabout on SR 203 By David Rasbach Our new compact roundabout along State Route 203 at the intersection with High Rock Road and 203rd Street Southeast south of Monroe is unique, to say the least. With a long, skinny island separated from a circular island by a pass-through lane, even our designers don’t know of any similar roundabouts this small. From above, it looks like an exclamation point, but we hope people who travel through will come to think of the roundabout as more of comma – a place to slow, take a pause when needed and then proceed on your travels. A new roundabout opened along SR 203 in late June south of Monroe at the intersection with High Rock Road and 203rd Street Southeast. Think of it as two roundabouts nested together, and the rules are the same as any other roundabout we’ve built: Slow to 15 to 20 mph as you approach. Move counterclockwise around the roundabout. Yield to vehicles approaching from your left already in the roundabout. Larger vehicles may drive over the center islands for tight turns. Drivers going northbound on SR 203 traffic may need to yield twice – once when entering the roundabout and again if traffic is passing between the two islands. If you think about it, that’s just following the same rules a second time. If you travel through the area, you may want to check out our video about driving this roundabout. The SR 203 roundabout slows vehicles that used to approach the High Rock Road intersection at 55 mph. Roundabouts calm traffic, improve flow and reduce the chances of serious T-bone and head-on crashes. These effects all apply to this stretch of SR 203. Making a roundabout for everyone OK, so why does it look so different from any other roundabout? The design accommodates large vehicles and farm equipment making left turns, fits the existing space and avoids the nearby hill and protected wetlands. Our engineering team found the unique design was needed to accommodate all the different vehicles that travel through this intersection. When we began planning, our designers considered a roundabout shaped like a dog bone – long and skinny with “knots” on the ends. They quickly realized that wasn’t going to work. A lot of large vehicles and farm equipment make left turns from 203rd Street Southeast to northbound SR 203. With a dog bone design, the turn at the southern end would be too tight for these vehicles to make. Unlike most compact roundabouts, the new roundabout along SR 203 features two center islands with a lane passing between them. Fitting a roundabout in a tight space Why not build the center island bigger to create better turning angles for those larger vehicles? In a word – geography. The new roundabout needed to be built in the same space as the old intersection. To the east is a steep hill. To the southwest there are protected wetlands. There wasn’t space or budget to mitigate the potential impact in either direction. With a hill to the eastside of the intersection and protected wetlands just to the southwest, engineers came up with a unique design to help improve safety and traffic flow at the SR 203 intersection at High Rock Road and 203rd Street Southeast. Making SR 203 safer We hope people traveling through the new roundabout will adapt quickly to the unique design and follow the same rules they should use at every roundabout. The new intersection is already performing its No. 1 goal of reducing chances of crashes that can lead to serious injuries or worse. Before construction started, cars flew along this busy rural section of SR 203 between Monroe and Duvall at 55 mph. The intersection is on a curve, adding to the risk people turning from High Rock Road or 203rd Street Southeast could have been hit. SR 203 drivers turning left also faced challenges judging oncoming traffic speed. National studies have shown that roundabouts create a 37% decrease in overall collisions, while reducing injury crashes by 75% and fatal incidents by 90%. Despite its unique design, drivers using the new SR 203 roundabout at High Rock Road should follow the same rules in place at any roundabout. We always monitor and evaluate all changes we make. This new roundabout is no exception, so we’ll be sure it’s working as designed. Yes, we know – not everybody loves roundabouts. This one requires adjustment, just like any change. But please give this unique little roundabout a chance. Slow down and follow roundabout rules and signs on the road. Make sure you stay distraction free as you drive through the area (and everywhere). And please have patience with others still learning. We believe you’ll soon enjoy improved safety and traffic flow in the area. RSS feed Email ThisShare this blog via emailShare to FacebookShare this blog on FacebookShare to TwitterShare this blog on X Tags: roundabout No comments: WSDOT comment policy Post a Comment Older Post Home WSDOT website WSDOT Facebook WSDOT TikTok WSDOT YouTube Search Archive ▼ 2024 (55) ▼ October (2) In case you can’t tell, we’re really excited about... Updates on the new US 2 Trestle PEL study ► September (7) ► August (7) ► July (4) ► June (8) ► May (5) ► April (12) ► March (4) ► February (4) ► January (2) ► 2023 (111) ► December (3) ► November (11) ► October (10) ► September (9) ► August (7) ► July (14) ► June (9) ► May (13) ► April (11) ► March (9) ► February (7) ► January (8) ► 2022 (24) ► December (3) ► November (8) ► October (4) ► September (8)",
    "commentLink": "https://news.ycombinator.com/item?id=41754084",
    "commentBody": "We're excited about our new roundabout (wsdotblog.blogspot.com)88 points by aendruk 17 hours agohidepastfavorite81 comments thepaulmcbride 14 hours agoI live in the US now, but originally from Ireland. My least favourite part of US road infrastructure is the 4 way stop. They are just not good compared to a roundabout. Half the time the only way you can tell it’s an all way stop is by looking for the back of the stop signs on the perpendicular road. With a roundabout, you only have to look in one direction, and if it’s clear, you don’t even have to stop. reply bfdm 13 hours agoparentYep. Canada suburbs here. We're starting to see roundabouts used more often for what would be higher traffic four-ways or inconvenient lights. They're great, both as a driver and as a cyclist. Lower conflict risk, simple rules to proceed. IMO all smaller 4 way stops should become what I've described as trash can roundabouts. Small island to circle around. So much better than stop signs. reply woleium 11 hours agorootparentIn the UK they are called mini roundabouts, and are sometimes just painted on: https://commons.m.wikimedia.org/wiki/File:Mini-roundabout.jp... reply maltalex 21 minutes agorootparentPainted roundabouts will be invisible when it snows. reply seanmcdirmid 12 hours agorootparentprevIn Seattle, we have trash can roundabout (really just round traffic calming islands, we don’t consider them roundabouts) and stop signs at the same intersections. reply MostlyStable 13 hours agoparentprevWait until you find one of the distressingly common places where they build a roundabout and put stop signs on some or all of the entrances. reply rented_mule 11 hours agorootparentYep, every time I drive through this one, I curse the idea of 4-way-stop-roundabouts: https://www.google.com/maps/@37.7609857,-121.1244208,3a,75y,... Too many people remain at the stop sign until the roundabout completely clears, so it becomes an excruciatingly slow 4-way stop. And there's not much traffic there. A few miles from that one, there's a high traffic roundabout that works very well. The heavily used right turn lanes are divided and don't enter the roundabout. There are very clear markings on the ground. And there are yield signs at the entrances, so people know what to do. Traffic flows great through it, with the heaviest direction of travel naturally getting more throughput. https://www.google.com/maps/@37.7004641,-120.976448,3a,75y,1... reply dave333 14 hours agoparentprevThat is a good way to have an accident - I know since I've done it. While \"looking one way\" on a USA counterclockwise roundabout you are looking left to see traffic already on the roundabout and if clear you go and run smack into the back of the vehicle ahead of you who for some reason stalled or hesitated or just judged the traffic differently. However it will be a low speed accident. reply sierra1011 13 hours agorootparentAs a general rule, one should be looking in the direction in which the vehicle is traveling. It's easily done though, if rushing, or if the vehicle in front pulls away slightly but stops again. reply nixosbestos 16 hours agoprevApparently I'm sticking my neck out here, but it really doesn't seem that hard. Overhead, I can intuit the path I would take, and if I imagine it first-person, it seems even more obvious. It's frustrating riding with certain other American drivers in other countries. I've met numerous folks now that seem upset that they have to actually pay attention to their driving and the traffic. Meanwhile I'm horrified that they're apparently just ... completely on auto-pilot in the US. reply 509engr 15 hours agoparentNo, you're definitely not the only one who likes them. Some folks complain about them when they first go in, but they tend to figure it out. WSDOT has been encouraging them for a few years now, and my town has several new roundabouts as a result -- and lots of other cities across the state are using them. They've made navigating those intersections way easier, reduced traffic \"waiting times\", and generally improved safety versus a lighted intersection. I'm glad they're continuing to find ways to make them work. It seemed when I was growing up in NJ, the state DOT was taking out the giant roundabouts that they were famous for, and now in Washington, they're having a huge resurgence. reply al_borland 14 hours agoparentprevI'm ok with most roundabouts. However, there is one near me that everyone complains about. There are 3 of them right in a row, but even that isn't the main issue. There is one with 5 places to turn out, which is relatively small and confusing. If you get it wrong it dumps you out on the expressway and it's an almost 9 mile trip to get back to where you originally wanted to go with no other option than to drive the 9 miles. I have yet to talk to a single person who hasn't made this mistake at least once. A little \"oops\" road to connect the expressway on-ramp with the road people intended to take would go along way and save hundreds, if not thousands, of wasted miles each year. Many people avoid the area completely because they don't want to deal with it. reply netsharc 6 hours agorootparentDon't the exits have signs to say where the exit takes you? In Europe they'd be labeled, and highway onramps will have a different background color to indicate a highway.. Also, keeping your navigation display \"north up\" is much better than having one that will probably be laggy in a roundabout, confusing you on which exit to take. If all else fails, look at the signage; I remember driving and a passenger not sure if the roundabout exit I was taking was correct, I said \"Well there's a big sign there that says this way to our destination.\" reply al_borland 59 minutes agorootparentI think part of the issue is that it’s multi-lane. So if you’re in the right-lane to go to one road, and miss it, staying in the right-lane forces you onto the highway. If there is a car in the left lane you can’t get over to avoid it without causing an accident, or stopping, which would backup the whole circle and also risk accidents. So you end up paying the 9 mile tax. There is no way to miss your turn and easily recover. reply tempestn 13 hours agorootparentprevYeah, roundabouts certainly have the potential to be superior, but they're not immune to bad design! reply Dalewyn 15 hours agoparentprevI'll take a traditional cross with traffic signals or stop signs on all sides, it's simple and effective. Roundabouts are a waste of space, disrupt traffic, and take more brain processing than I care to afford if I can help it. This particular example isn't even round. reply rootusrootus 15 hours agorootparentI vastly prefer roundabouts, with a single exception. If traffic is heavy and dominated by the same entry and exit points, it can be hard to get a turn if you're coming from the side. Our nearest roundabout is this way. I once saw a roundabout with stop signs. I assume it was an attempt to address this situation. reply Angostura 15 hours agorootparentIn the UK, you get roundabouts with traffic lights at the entrances, sometimes only operational at peak times, and off most of the time. Works well reply googledocsftw 15 hours agorootparentprevHow is a roundabout more disruptive than a 4 way junction with stop signs. In terms of brain processing, you get used to it and it becomes second nature. It is a skill. reply Terr_ 15 hours agorootparentAgreed, with the condition that there is only one lane. Ones with multiple layers stress me out, there are more ways to screw up and more demands on your defensive-driving attention. reply 8n4vidtmkvmk 14 hours agorootparentI think the problem is not that they're impossible to figure out but you have about 2 seconds from when you see the sign to when you're entering the double roundabout. reply labster 13 hours agorootparentThat’s a very solvable problem of bad signage. reply googledocsftw 9 hours agorootparentprevYes. If there are 2 it should be a \"dog bone\" with a long straight bit so you have time to adjust. Like:| =O============O= reply ProllyInfamous 15 hours agorootparentprevWe have back-to-back round-a-bouts in Chattanooga (153 / Lake Resort / Access) which have two loops (concentric inner & outer round-a-bouts)... that can be quite confusing for anybody unfamiliar with the local pattern. reply bfdm 13 hours agorootparentprevYour opinion here is at odds with the record for higher traffic throughput and better safety for roundabouts. They are better in pretty much every way, for appropriate situations. Here the situation is uneven road size, through traffic on the highway and odd angles. Perfect roundabout application. reply adammarples 6 hours agorootparentprevIf your stop signs don't disrupt traffic then they're not working properly. Roundabouts are designed to efficiently weave traffic streams together instead. reply holoduke 14 hours agorootparentprevRoundabouts are faster, safer and more convenient. It sometimes needs additional traffic lights, since heavily congested roundabouts lose their effectiveness. reply lolinder 16 hours agoprevKeep in mind that a lot of these traffic devices look way more confusing from above than they actually look while on the ground. From above you can see the whole device at once, and trying to trace a path through it can feel overwhelming, but when you're actually going through it your view is usually restricted in ways that limit your perceived choices at any point in time. reply lmm 16 hours agoparentI'd say just the opposite. Indeed, in the UK it's normal for the signs leading up to a roundabout to include an overhead map view, since that's often the easiest way to understand what you need to do to get where you want to. reply penguin_booze 9 hours agorootparentAgreed. I use to not pay attention to the layout at all. Instead, I resorted to counting down the exits I was moving past them, whilst remembering myself to gradually changing lanes to the left, paying attention to cars on the adjacent lanes. Because of this, I forget to look and plan ahead--almost like tunnel vision. Suffice to say, it was--and still is--stressful, especially at those roundabouts with which I'm not familiar. Then I started paying attention to the displayed layout. This helped me with the bearings and lane positioning. At least, that's one item off my list when I'm in the roundabout. reply meowster 14 hours agorootparentprevI imagine you're referring to a simple line drawing (with labels)? reply lmm 11 hours agorootparentThey're schematic but they reflect the shape of the roundabouts to help you follow it. E.g. https://www.youhaventlived.com/qblog/2005/QBlog160705A.html has some examples. reply dave333 13 hours agorootparentprevFor example - Britain's most notorious roundabout https://www.google.com/maps/@51.5622263,-1.7713205,3a,48.7y,... reply StuPC2000 12 hours agorootparentI grew up in this town, and even had to navigate this Magic Roundabout on my driving test. It's not so bad once you understand how it operates, but you have to pay attention. reply II2II 15 hours agoparentprevNever underestimate how confused people can get with the unfamiliar. I live a couple of blocks from a fairly standard roundabout and see people trying to exit the roundabout through an entrance to the roundabout or try to go clockwise in the roundabout (this is in Canada) several times a year. This happens even though the design of the roundabout, the road markings, and the signage make it perfectly clear how you are supposed to go through it. Then there is the less obvious stuff that happens multiple times per hour, like entering in the wrong lane given the desired exit (even though it is marked), vehicles inside the roundabout yielding to vehicles entering the roundabout (even though there is signage), or vehicles entering the roundabout failing to yield to vehicles inside of it (same signage). As for non-standard roundabouts, those can confuse just about anyone since people often don't realize that it is a roundabout. reply mjevans 13 hours agoparentprevThey're often not 'signaged' correctly. Ideally the sign would be 1) Rotated so that the driver proceeds from the base towards the top or sides. 2) Clearly depict the LOGICAL layout (bent slightly towards the physical) of what flow patterns _do_ during the roundabout from that input. 3) Also clearly depict which exits go where. There should really be two signs actually, one before the diagram that lists (locally relevant roads / landmarks) by lane for sorting (if there's more than one lane in). PS: The route map should also add a YIELD sign in mini next to the entrance with an according broken line. The interior lanes of roundabouts always have priority and all inputs are yield merges in. reply id00 15 hours agoprevAustralian who lived in Washington state for 4.5 years. Very happy to see those kind of changes. Much better and safer than 4-way stop intersections and I hope American drivers will figure out eventually how to use them reply rootusrootus 15 hours agoparentAside from one old lady that I saw doing laps a few years ago after our nearby roundabout first opened, it seems like most people figure it out pretty quickly. But they're too comfortable with it, and most people blast through without even hitting the brakes. That brings its own problems. reply freditup 14 hours agoprevThe picture of the roundabout from above at the beginning of the article is extra confusing because it doesn't have the final lane markings yet and the ones you can see are misleading. The (presumably) final markings[0] make things less confusing. [0]: https://www.google.com/maps/place/High+Rock+Rd,+Washington+9... reply jayyhu 14 hours agoparentThey made a video that explains how to navigate the roundabout, and shows what it will actually look like (with yield markings)[1] [1]: https://youtu.be/07_m7HHiZRw reply AngryData 14 hours agoprevI fail to see how this helps over more traditional designs. Not to mention tight roundabouts always have horrible curbs that trucks have to smash into to try and jump over to make the turns, and they are never gentle bumps, they are always tire and curb damaging trash, especially for heavy loads which are primarily the vehicles that need to jump the curbs. All the roundabouts around me I wish they would just get rid of, I can navigate them just fine, but they are way too small, over congested, and dangerous because the 5 seconds you have to read the signs as you approach to know whats going on is too much for anyone non-local which makes them unpredictable and nervous drivers. reply nullindividual 14 hours agoparentThere is no room for a traditional roundabout in this location and the gravel trucks from the nearby quarry can hop the very short curbs as needed. This roundabout is perfectly fine in practice. reply AngryData 12 hours agorootparentGravel trucks are the last trucks that should ever be hopping curbs though, even gentle ones. Gravel trucks already require many roads to be upgraded due to the weight and damage they do just to a flat surface. A truck carrying diapers and crackers won't mind so much, but when you got 50 tons of gravel then even a small 1 inch jump causes significant extra forces on both the road and the truck. reply nullindividual 10 hours agorootparentThat road has been carrying gravel trucks for decades. The smart WSDOT engineers took into account the business with large trucks that is just a mile away when building this roundabout. reply fbarred 13 hours agoparentprevWatch the video - this roundabout's islands are designed to be driven over by semis and trailers. (Hopefully the drivers of those vehicles know that). reply toast0 13 hours agoparentprev> Not to mention tight roundabouts always have horrible curbs that trucks have to smash into to try and jump over to make the turns, and they are never gentle bumps, they are always tire and curb damaging trash, especially for heavy loads which are primarily the vehicles that need to jump the curbs. I'm not a fan of roundabouts, but the recent WSDOT roundabouts I'm subjected to have gentle curbs, at least for now, so that part isn't so bad. The part where I actually need to look left and right simultaneously to see if there's room for me to join the flow, and also watch for pedestrians (if present) isn't so great. And I'm really not a fan of the unbounded wait when there is a large flow that crosses my entrance, which could result in a very long wait when the large flow comes from rush hour conditions or a ferry offloading. reply nine_k 14 hours agoparentprevOTOH if you can't read the sign where to turn right, you can keep turning left, make a full circle, and check the signs again, and again if needed, in under half a minute. All without creating a problem to anyone around you, and being safe yourself. I'll take it any time over a typical highway exit; if you miss it, or uf you take a wrong one, it's usually dozens of miles before you have a chance to take any corrective action at all. reply foota 14 hours agoparentprevFor one, roundabouts turn what would be a T-Bone intersection into a glancing hit. I think that's the biggest safety benefit. They also improve the flow of traffic since there's no starting and stopping (think of it like a stoplight is a mutex lock and a roundabout is a spinlock). reply chrisco255 13 hours agoparentprevThis roundabout was intentionally designed for the curbs to be traversable by long vehicles. reply buffaloPizzaBoy 13 hours agoprevWhats not mentioned in the article is that this particular intersection has a (15mph residential access road - top right) (25 mph farmland road - bottom) (50mph country highway - left and right) Previously, only drivers from the 15mph and 25mph roads had to stop! Visibility coming from the south would also be terrible to check for incoming highway drivers (left is blocked by foliage, right the road curves out of sight), so getting the highway drivers to slow down is a welcome improvement here. There is also not enough space to add at the intersection here either, its seemingly bordered entirely by private land. reply chrisco255 13 hours agoparentThey can eminent domain whatever land they need to expand the intersection. reply nullindividual 10 hours agorootparentThe area borders wetlands and a very steep hillside where one of the roads intersects. And the regular flow of traffic pre-roundabout was more like 60-65 mph. A roundabout was the correct choice. reply marssaxman 16 hours agoprevI'm glad they're excited, but I hope I never encounter this. reply ajb 15 hours agoparentIt may be unusual there, but in the UK we have loads. Some are smaller than this: the minimum roundabout is just a paint circle. They aren't a problem Most people here actually prefer roundabouts to traffic lights because you keep moving (although this is partly selection bias- traffic lights are deployed at junctions where a roundabout would fail to evenly arbitrate the different flows ) reply andreareina 14 hours agorootparentYou guys like roundabouts so much you've gone recursive. https://en.wikipedia.org/wiki/Magic_Roundabout_(Swindon) (To be clear I like roundabouts) reply ajb 12 hours agorootparentThat one is a bit odd, because the central bit looks like a roundabout but is not. To navigate it you need to forget the central bit and focus on the five mini roundabouts reply nullspace 15 hours agorootparentprevYou may feel less enthusiastic about it once you watch the linked video. I wouldn’t exactly call it a roundabout. That’s only what’s at the center of it. reply ajb 15 hours agorootparentOk fair enough, that extra bit does make it slightly more complicated. Having said that though, I would not be fazed by this, and I don't think many UK drivers would be - because we already deal with many that have more parts. When I was learning to drive, I found a particular triple roundabout quite painful but no longer have any difficulty. There are two skills you need to pick up to deal with any roundabout system. The first is judgement of how distant other vehicles need to be before you can enter. As a learner I used to irritate the drivers behind me by being far too cautious; on a busy roundabout you can't expect an enormous gap, so you need to know what length of gap the other drivers will expect you to take advantage of. This you can only learn from experience. The other is to plan your route, because you need to choose your entry lane based on where you want to go. These days your navigation app will probably tell you the best entry lane. reply code_runner 15 hours agoprevUS here. There seems to be an obsession at the moment with adding roundabouts in my area. They don’t always fit where they are put. Some of them have a stop sign in the roundabout? When asked why, the answer is reducing “points of conflict”, which is a static variable. There aren’t actually studies being done before or after to see if makes the flow of traffic better. They are also adding them in walkable areas with the express intent of “traffic never stopping” which doesn’t go well with pedestrians crossing the street. I think we can find better ways to spend money… including the salaries of the people dreaming up bizarre applications for these things. reply rootusrootus 15 hours agoparent> Some of them have a stop sign in the roundabout? Traffic gets much heavier and we'll need stop signs at our roundabout near my house. During rush hour it has predominantly one flow of traffic and nobody slows down below 30-35 mph so getting into the roundabout can be difficult. A stop sign would defeat some of the point of a roundabout but it may become necessary to enforce safety. reply thepaulmcbride 14 hours agorootparentIn the UK a lot of roundabouts have traffic signals for this purpose that only turn on during busy times. reply virtualwhys 13 hours agoprevOne area where a 4-way stop sign intersection is somewhat superior to a roundabout is the notion of taking turns -- in the States it seems like busy roundabouts are an opportunity for one stream of traffic to just plow through, completely ignoring everyone else who also has something better to do than sit around waiting for others to be courteous :) reply nostromo 16 hours agoprevSeattle Department of Transportation and Washington State DOT have honestly gotten way too creative. It's like every city, every locale, and sometimes every street has a new collection of obstacles and rules to circumnavigate. Roundabouts are great, but they should probably be round. In this case, it seems that it'd be easy to navigate if the two roads were brought into a single, simple roundabout intersection like you see at any other location. reply blamazon 16 hours agoparentThe article explains why they made the decision not to do a traditional dog-bone interchange with two circular roundabouts. Namely, there were right of way limitations and a need to incorporate heavy farm trucks making a left turn. So, they ended up with basically 1.5 roundabouts which represents a simplification over the dog bone. reply pfannkuchen 13 hours agoparentprevThe lack of turn signal usage in the region also makes funky roundabouts much harder to navigate. Like you have to wait until there is a large enough gap in the cars to enter the circle, even if none of the cars actually end up intersecting your path. reply jghn 16 hours agoparentprevIt is intentional. The idea is to force drivers to reduce speed, and the mechanism is because it isn't familiar to the drivers. The claim is it forces them to be thoughtful. Whether or not it works or is a good idea is not something on which I'm opining. reply nullindividual 14 hours agoprevI drive through this roundabout. It’s such a huge improvement. And little confusing at first due to being two roundabouts in one, but not hard to navigate. reply temporallobe 14 hours agoprevWe have a few roundabouts where I live in the USA now, and they are absolutely wonderful, apart from the occasional clueless driver who doesn’t know how to use them, which seem to come in two varieties: 1) blast right into them without yielding or even slowing, or 2) Going the wrong way. In their defense, they probably have never seen them or never learned about them in driving school. reply asimjalis 15 hours agoprevI would recommend some yield signs; the dashed line on the ground is easy to miss. reply mozzieman 14 hours agoprevThe comment section on the youtube video is soo good. Everyone seem to almost have accidents and everyone complaining. Think prob they need to work a bit on this design. reply twelve40 14 hours agoprevAt least that one is small. They'd know for sure from the change in numbers pretty soon if it improved things or not. But for multi-lane ones I absolutely lose my shit and freak out when I get into one. Many decades of driving experience, but when in Europe (France, Italy, Spain) i encounter a multi-lane roundabout, every time it feels extremely confusing and unpredictable. People moving in all directions, cars, scooters, you need to calculate which lane you need to get into, and get out of, and do all that while accommodating crisscrossing neighboring vehicles who are all also trying to maneuver in every direction. Having to turn the entire time makes it feel very fast and dangerous, always paranoid about crushing some scooter that I didn't spot from one of the many angles while turning. Doesn't seem to get easier with time for me either, unlike all other driving. Glad we don't have multi-lane roundabouts in CA. reply Legogris 7 hours agoparentIME (also observing other drivers), the usual multi-lane roundabouts are something you get comfortable with after just a little spaced repetition and then it's not all bad. There are major cities in those countries with a few exceptionally gnarly ones, though. I don't blame if you're traumatized if you ever found yourself circling Arc de Triomphe in Paris, for example. reply dzhiurgis 15 hours agoprevWe are getting similar one here [0]. Whenever you get there you try to get out asap. It’s a nightmare. 0: https://maps.app.goo.gl/BxmPqsf41p639Vy88?g_st=ic reply asynchronous 16 hours agoprevAt first glance I’m confused how to navigate it- a flowchart would be nice. Or just a video of traffic using it. reply btbuilder 16 hours agoparentThere’s a link in the article but here it is with a time code for the start of the simulation. https://youtu.be/07_m7HHiZRw?t=39 reply presentation 16 hours agoparentprevI think this is what it’s supposed to be like https://imgur.com/a/nsh80tf reply pwg 16 hours agoparentprevAbout half way in to the article is a link to a youtube video. reply 9021007 16 hours agoparentprevThe article has a video reply komali2 13 hours agoprev [–] I guess that's somewhere quite remote? I don't see any pedestrian infrastructure and I don't understand how a pedestrian would cross this road safely reply asteroidburger 12 hours agoparenthttps://maps.app.goo.gl/aBMc8ik6B1zZbBPQ7 It's not quite the middle of nowhere, but definitely quite rural. I wouldn't expect to find pedestrians out there. reply magneticnorth 13 hours agoparentprev [–] Yes, it's a few miles outside of the nearest town. It's the intersection of a state highway and some small roads that mostly lead to farmland. Not much pedestrian traffic expected there. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "WSDOT has introduced a new compact roundabout on SR 203, featuring a unique design with a long, skinny island and a circular island separated by a pass-through lane.",
      "The roundabout is designed to slow traffic, improve flow, and reduce crash risks while accommodating large vehicles and fitting the existing space.",
      "Despite its unique design, the roundabout has already enhanced safety by reducing high-speed approaches and crash risks, and WSDOT encourages drivers to adapt to it for improved safety and traffic flow."
    ],
    "commentSummary": [
      "Roundabouts are gaining popularity in the US, even in suburban areas, due to their efficiency and safety advantages over traditional 4-way stops.",
      "They are preferred by drivers from countries like Ireland and Canada for reducing conflict risk and improving traffic flow.",
      "Despite some poorly designed roundabouts causing confusion, they generally provide better traffic throughput and safety compared to traditional intersections."
    ],
    "points": 88,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1728178370
  },
  {
    "id": 41756346,
    "title": "When Earth Had Rings",
    "originLink": "https://nautil.us/when-earth-had-rings-920177/",
    "originBody": "Channels Topics About Contact us Newsletter Become a member Shop Channels Art+Science Biology + Beyond Cosmos Culture Earth Life Mind Ocean One Question Quanta Abstractions Rewilding Science at the Ballot Box Science Philanthropy Alliance Spark of Science The Porthole The Reality Issue The Rebel Issue Women in Science & Engineering Topics Anthropology Arts Astronomy Communication Economics Environment Evolution General Genetics Geoscience Health History Math Microbiology Neuroscience Paleontology Philosophy Physics Psychology Sociology Technology Zoology Already a member? Log in Join Close Search for: Log in Join Environment Flowers and the Birth of Ecology Zoology The Bird Photo of the Year Technology The March of the Mushroom Robots Environment Will Plants Grow on the Moon? Zoology This Tiny Frog Is Fierce History Is Discovery Inevitable or Serendipitous? Arts Our Magnificent Ocean Astronomy The Mystery of the Cosmic Radio Globs Evolution Puberty Hasn’t Changed Since the Ice Age Psychology When Do Kids Start Playing Pretend? Anthropology 7 Famous Fossil Hoaxes History How History Did the Dodo Wrong Environment Flowers and the Birth of Ecology Zoology The Bird Photo of the Year Technology The March of the Mushroom Robots Environment Will Plants Grow on the Moon? Zoology This Tiny Frog Is Fierce History Is Discovery Inevitable or Serendipitous? Arts Our Magnificent Ocean Astronomy The Mystery of the Cosmic Radio Globs Evolution Puberty Hasn’t Changed Since the Ice Age Psychology When Do Kids Start Playing Pretend? Anthropology 7 Famous Fossil Hoaxes History How History Did the Dodo Wrong Environment Flowers and the Birth of Ecology Zoology The Bird Photo of the Year Technology The March of the Mushroom Robots Environment Will Plants Grow on the Moon? Zoology This Tiny Frog Is Fierce History Is Discovery Inevitable or Serendipitous? Arts Our Magnificent Ocean Astronomy The Mystery of the Cosmic Radio Globs Evolution Puberty Hasn’t Changed Since the Ice Age Psychology When Do Kids Start Playing Pretend? Anthropology 7 Famous Fossil Hoaxes History How History Did the Dodo Wrong ADVERTISEMENT Nautilus Members enjoy an ad-free experience. Log in or Join now . Geoscience When Earth Had Rings A new way of thinking about the history of the Earth. By Sean Raymond October 4, 2024 Add a comment Share Facebook Twitter Pocket Reddit Email Sign up for the free Nautilus newsletter: science and culture for people who love beautiful writing. NL – Article speedbump Email * Sign up for free If you are human, leave this field blank. Explore Planetary rings may be one of space’s many spectacles, but in our solar system, they’re a dime a dozen. While Saturn’s rings are the brightest and most extensive, Jupiter and Uranus and Neptune have them, too. What’s more, four icy minor planets—Chariklo, Chiron, Quaoar, and Haumea—that orbit among or beyond our gas giants, also host ring systems. Even so, it would be fanciful to imagine that Earth once had a ring system of its own, wouldn’t it? I mean, that just seems almost too cool to be true. Or is it? Nautilus Members enjoy an ad-free experience. Log in or Join now . Rings are likely the dwindling remains of shredded asteroids or comets, and when you think about the turbulence Earth experienced around half a billion years ago, the reality of a bygone ring system around Earth seems less farfetched. That’s the case researchers make in a new study published in Earth and Planetary Science Letters. If Earth went through one ringed phase, there’s a good chance it went through several. ADVERTISEMENT Nautilus Members enjoy an ad-free experience. Log in or Join now . About 466 million years ago (long before the dinosaurs), the rate of stuff falling on Earth that was large enough to leave craters spiked sharply. Researchers have identified 21 impact craters from this spike, with sizes between a few and 50 kilometers in diameter. And sedimentary rocks from this period show a huge increase—a factor of 100 to 1,000—in the concentration of elements associated with a specific group of meteorites, called L chondrites. This period, the mid-Ordovician, also included an extreme drop in global temperature, roughly 10 degrees Celsius, which coincided with increased seismic and tsunami activity. Also, a mass extinction eliminated 85 percent of marine species, after which the temperature rebounded. What could possibly explain this? The authors of the new study, led by Andy Tomkins, a geoscientist at Monash University in Australia, claim that you can account for the craziness of the Ordovician period if Earth had a system of rings that it captured from an asteroid. And if it went through one ringed phase, there is a good chance that it went through several. And for good measure, the other rocky planets may have done the same. “This opens up a new way of thinking about the history of the Earth,” Tomkins wrote in an email. He and his colleagues focused on the distribution of craters on Earth during the Ordovician’s impact spike. The craters are spread across Earth’s surface, but its tectonic plates—the movement of which pushes the continents around—have shifted considerably in the last 450-plus million years. The researchers determined where the impacts actually took place by “rewinding the clock” of the continents’ movements using computer models of how the Earth’s surface has rearranged itself. This showed that all of the crater-forming collisions took place within a narrow band centered on the equator. They gathered the data on where craters are located today (across the globe, especially in areas that were not likely to have been covered in ice during the Ordovician, given that ice could prevent crater formation), while also taking into account the regions where such craters could not have been found (due to present-day ice coverage, such as in Antarctica), and where craters could not have been preserved because of processes such as burial and erosion. Putting all of these factors together, Tomkins and his colleagues calculated that it would be highly improbable—we’re talking about a 1 in 25 million chance—that the impacts were randomly distributed across the Earth’s surface. ADVERTISEMENT Nautilus Members enjoy an ad-free experience. Log in or Join now . MOVE IT: Animation of how plate tectonics have moved the continents around over the past billion years. Credit: EarthByte / YouTube. To explain why the impacts are concentrated at the equator, Tomkins and his colleagues proposed that the Ordovician Earth had a system of rings. The Ordovician impacts came from objects within the rings that crashed down onto Earth. Saturn’s rings are thought to have formed from a large icy object that passed so close to Saturn that it was torn into pieces in a process called tidal disruption. When a comet or asteroid passes very close to a planet, the difference in gravity across the object is strong enough to stretch it to its breaking point. We have seen tidal disruption in action: In 1992, the comet Shoemaker-Levy 9 passed so close to Jupiter that it was torn into a string of about 20 fragments. Most of these rained down onto Jupiter in 1994. In the case of Saturn’s rings, the shards of the disrupted object were captured into orbit. The orbits of captured fragments would have started off being extremely stretched-out, or eccentric, and aligned with the initial orbital trajectory of the icy parent body. In time, the ring fragments collided with each other and were ground down to smaller pieces, and the collection of objects settled to a circular system of rings aligned with the plane of Saturn’s equator, where we see them now. ALL BROKEN UP: Hubble Space Telescope image of the fragments of comet Shoemaker-Levy 9 after it was tidally disrupted during its close passage to Jupiter. Credit: NASA, ESA, and H. Weaver and E. Smith (STScI) ADVERTISEMENT Nautilus Members enjoy an ad-free experience. Log in or Join now . The ring-producing asteroid must have been an L chondrite, a type of ordinary meteorite (“ordinary” because they are the most common type of meteorites in our collections). Tomkins and his colleagues suggest that the L chondrite parent body passed extremely close to Earth—within just a few thousand kilometers of the surface, scratching the edge of the atmosphere—and was tidally disrupted, just like the object that broke apart and formed Saturn’s rings. Its fragments settled to Earth’s equatorial plane, and dust from the ring slowly rained down on Earth, along with the occasional impact of a larger fragment, mostly near the equator. This explains the high concentrations of L chondrite meteorite-like dust in Ordovician sedimentary rocks, as well as the distribution of craters across the globe. The sharp drop in temperature after the Ordovician impact spike—called the Hirnantian global icehouse—may also have been a consequence of the Earth’s rings. The rings’ shadow would have fallen on whichever hemisphere was in winter at that time, and would have had a net cooling effect, which the dust in the atmosphere may have amplified. This drastic cooling perhaps played a role in the late Ordovician mass extinction: The global temperature bounced back up after the end of the Ordovician impact spike, presumably due to the dissipation of the rings. “It seems plausible that the planets have seen multiple cycles of ring formation and loss,” Tomkins wrote in an email. These cycles would be triggered by the rare, very close passage of a comet or asteroid. Some planets are more likely to have ring phases than others, based on the frequency of asteroid flybys and the planets’ properties. Jupiter, Saturn, Uranus, and Neptune seem to have more frequent, or longer-lived, ring phases because they interact far more frequently with asteroids and comets than the rocky planets, and so have far more chances of disrupting one and capturing its fragments. Ring phases usually last for millions of years at a time, with considerable consequences for a planet’s geology, climate, and potentially life. For Tomkins, the search is underway for other potential pieces of evidence that Earth has undergone previous ring phases. The Ordovician spike is the clearest sign so far. “The cratering record gets weaker the further back in time we look,” he wrote in an email. “What other evidence can we look for that Earth may have had this and other rings in the past?” ADVERTISEMENT Nautilus Members enjoy an ad-free experience. Log in or Join now . It’s a good question. And I’m excited to know someone like Tomkins is out there chasing down an answer. Lead image: MarcelClemens / Shutterstock Sean Raymond Posted on October 4, 2024 Sean Raymond is an American astrophysicist working at the Bordeaux Astrophysical Laboratory in France. He also writes a blog at the interface of science and fiction (planetplanet.net) and published a book of astronomy poems. Get the Nautilus newsletter Cutting-edge science, unraveled by the very brightest living thinkers. NL – In Page Mobile Email: * Sign up for free If you are human, leave this field blank. Communication If You Meet ET in Space, Kill Him Environment Flowers and the Birth of Ecology Microbiology Your Cells Are Dying. All The Time. ADVERTISEMENT View / Add Comments Explore Flowers and the Birth of Ecology By Maria Popova October 3, 2024 Environment Without flowers, there would be no us. Explore The Bird Photo of the Year By Liz Lindqwister October 1, 2024 Zoology This award-winning shot offers a candid look at the cagey turkey vulture. Explore The March of the Mushroom Robots By Katharine Gammon September 30, 2024 Technology Scientists are making mycelia-machine hybrids that can crawl and roll. Explore Will Plants Grow on the Moon? By Tom Metcalfe September 26, 2024 Environment Three Earth plants will soon make a new home on the lunar surface. Explore This Tiny Frog Is Fierce By Liz Lindqwister September 25, 2024 Zoology The see-through amphibian goes big to protect its eggs. NAUTILUS: SCIENCE CONNECTED Nautilus is a different kind of science magazine. Our stories take you into the depths of science and spotlight its ripples in our lives and cultures. Get the Nautilus newsletter Cutting-edge science, unraveled by the very brightest living thinkers. NL – Footer Email: * Name Name First First Last Last Sign up for free If you are human, leave this field blank. Quick links Home About Us Contact FAQ Prime Ebook Shop Donate Awards and Press Privacy Policy Terms of Service RSS Jobs Newsletter Ethics Policy Social © 2024 NautilusNext Inc., All rights reserved. Enjoy unlimited Nautilus articles, ad-free, for less than $5/month. Join now ! There is not an active subscription associated with that email address. Already a member? Log in Join to continue reading. You’ve read your 2 free articles this month. Access unlimited ad-free stories, including this one, by becoming a Nautilus member. Join now ! There is not an active subscription associated with that email address. Already a member? Log in This is your last free article. Don’t limit your curiosity. Access unlimited ad-free stories like this one, and support independent journalism, by becoming a Nautilus member. Join now sponsored sponsored sponsored",
    "commentLink": "https://news.ycombinator.com/item?id=41756346",
    "commentBody": "When Earth Had Rings (nautil.us)82 points by rbanffy 7 hours agohidepastfavorite33 comments GolfPopper 3 hours agoI find myself, perhaps irrationally, quite irked that the picture headlining the article uses a picture of current Earth with rings, when Earth's surface 466 million years ago looked much different[1]. The paper itself [2] does have a map, although (understandably) not an artist's depiction. Most other sources covering the paper appear to have repurposed \"ringed terrestrial planet\" artwork, but I found one has an artist's rendition[3] to mollify myself. 1. https://dinosaurpictures.org/ancient-earth#450 2. https://www.sciencedirect.com/science/article/pii/S0012821X2... 3. https://www.yahoo.com/news/earth-had-saturn-rings-466-182200... reply amelius 5 hours agoprevNice opening image, but what would the view be like from Earth? reply jessriedel 4 hours agoparentRon Miller is an artist who made some very nice visualizations. I can’t vouch for the scientific accuracy, but they seem plausible enough to me, and consistent with the images I’ve seen of Saturn’s rings from nearby probes. https://www.planetary.org/articles/20130626-earths-skies-sat... reply morsch 20 minutes agorootparentWow, now I'm sad I don't live in that reality. reply KineticLensman 3 hours agoparentprevOff the top of my head, if the rings were a narrow band around the Earth, and were aligned with the terrestrial equator, they would be less visible from high or low latitudes. If they were aligned with the plane of the ecliptic, then they would be visible as a band following the 'zodiac constellations', and thus visible much further North and South. At night, in the shadow of the Earth, I'd think that they would be dark, perhaps even invisible. Perhaps moonlight would serve to illuminate them, depending on the relative position of the Sun and Moon. I'd guess they would look most impressive around and dusk. The particle density and albedo would influence whether they would be visible during full daylight. The ring density would affect whether they had sharp edges or simply faded out away from the centre. reply BurningFrog 3 hours agorootparentOnly part of the visible rings would be dark at night. You'd see sunlit parts on both sides of the shaded part. reply forgot-im-old 6 hours agoprevMay see rings around Earth again.. it's the expected state that space debris settles into after Kessler Syndrome. reply keyle 5 hours agoparentI was about to make a snarky comment about starlink. It's getting harder to take a shot of the sky without one of those pesky floaties. reply BurningFrog 3 hours agorootparentThey low orbit satellites are only visible while they're in sunlight near sunrise/sunset. reply FooBarBizBazz 1 hour agorootparentprevI read that those things' orbits degrade in like five years tops. So at steady state, for a constellation of size N, you need to launch N/5 of them each year, with the attendant fuel burn. Seems like that kind of pollution is a bigger long term worry than the short-lived junk? On the other hand, until it does fall down, I suppose it's a risk to anyone who wants to launch up through it. reply hggigg 5 hours agorootparentprevYeah this. I was 50 miles from civilisation in some mountains in central Asia last year trying to do astrophotography and I had to edit out the flying space trash after! reply fooker 3 hours agorootparentIf you needed rescuing from there, or if a nearby village was affected by a natural disaster, this flying space trash is what's saving lives. It makes sense for the vast majority of people to prefer that against the slight inconvenience in editing out satellite tracks faced by a tiny tiny community of ground bases astrophotographers. reply hggigg 3 hours agorootparentNo it's really not. Please don't think suburban USA can be extrapolated to the middle of bloody nowhere. I might be able to get a message off, but how the hell do you contact the emergency services and who the hell is going to rescue me in a country with one rescue helicopter that was out of action at the time? In circumstances like that it's better to actually get some mountain safety training, have some procedures and other comms equipment in place. And importantly travel in a group with the right equipment (including 4 legged transport devices). As for the astrophotography that was opportunistic. reply samegene321 3 hours agorootparentprevLow orbit satellites are unnecessary for emergency/comm. Fewer, dimmer, satellites at higher orbits are actually cheaper, but LEO constellations are now subsidized by the military industrial complex (there is other value to be low). reply Jtsummers 1 hour agorootparent> Fewer, dimmer, satellites at higher orbits are actually cheaper GEO satellites are pretty pricey. Each Milstar satellite cost $800 million, others in the same category are also in the hundreds of millions, WGS-11 was over $600 million. Starlink V2 cost $800k per satellite. And if you spent $800 million on a constellation of 1000 Starlinks, you'd have better coverage and bandwidth than the entire 6 satellite Milstar constellation put together for 1/6th the price. Digging around for more recent prices, GEO is around $100-300 million. That's still orders of magnitude more per satellite than LEO. At the low end this means you could get 100-400 Starlink V2s up there for the price of one GEO. One GEO that only covers part of the globe, versus 100-400 satellites providing global coverage. reply jjtheblunt 1 hour agorootparentprevAren’t you overlooking constraints on transmit power for mobile transmitters being better served my low earth orbit than higher orbits? reply Jtsummers 1 hour agorootparentThey're also overlooking the actual prices of GEO satellites versus LEO. LEO is much cheaper than GEO, there's a reason DOD and others are moving towards it and it's not that it's a fad. GEO has a few specific benefits but cost is not one of them. reply delichon 5 hours agorootparentprevDebris left in orbits below 600 km normally fall back to Earth within several years. The Starlink constellation is at around 350 km and below. reply forgot-im-old 5 hours agorootparentStarlink is actually 550 km and Amazon's Kuiper at 620 km. But the missile interceptors for the orbital 'American Iron Dome'* in the news lately would be ~ 350 km. * 2024 GOP platform #8: https://ballotpedia.org/The_Republican_Party_Platform,_2024 which developed out of Elon Musk and Mike Griffin's initiative for their founding of SpaceX: https://wikipedia.org/wiki/Michael_D._Griffin#Career#:~:text... reply samegene321 4 hours agorootparentit's a (Grok) ai transcript, but I found this SpaceX/Starlink history fascinating. Detailing how Musk has been working with key people on (Reagan's) Star Wars 2.0 for decades: https://archive.today/D2zIG#:~:text=Shotwell The only explanation I've heard for Musk's political antics that makes cold sense. reply kidme5 2 hours agorootparentwhenever the orange president mentions going to Mars, it's in the same sentence as the military and his MAGA Iron Dome. He's failing to keep the lid on the cover story. reply jajko 2 hours agorootparentprevDon't look for cold sense in mr musk's adventures, just look at whole twitter saga. He is a overgrown child with brilliant mind but very little control of his emotions (on top or other real mental issues under variable control). My almost-5 year old son has in some aspects more emotional maturity than him. Doesn't mean that stuff ain't truth of course, but his recent conservative alignment has deeply personal reasons too. reply kidme5 2 hours agorootparenthe sincerely believes saving humanity means being a Strategic Defense Initiative front-man under the guise of Mars reply delichon 4 hours agorootparentprevYou are right, it looks like I got a mistaken number from the Reddit (who could have predicted that). It says here that earlier this year Starlink was seeking permission to go lower. I wonder how that went. https://universemagazine.com/en/below-the-iss-orbit-starlink... reply sandworm101 6 hours agoparentprevThere isnt nearly enough mass up there in all the foreseeable sat constellations. They need enough collective mass to overcome the extreem orbital inclinations/speeds we use for sats. For a visible ring to form, we would have to send billions of sats into high/slow orbits and then just forget about them for millions of years. Even then, they would likely form into mini moons first before those moons eventually broke up into rings. reply JKCalhoun 5 hours agorootparentI had to laugh thinking that we (or some alien race) might come across a ringed planet only to find its rings are made of orbital space junk from a long-dead species that once flourished on the planet. reply McAtNite 4 hours agorootparentThis made me consider what sort of orbital archeology would take place. I imagine it would be a gold mine for anyone trying to study that civilization, and attempting to snatch pieces out of orbit would be a huge focus. reply jareklupinski 4 hours agorootparentprevhopefully the sight discourages them from leaving their own waste behind https://en.wikipedia.org/wiki/Roadside_Picnic reply chaosmanorism 6 hours agoparentprevKessler syndrome is inevitable if Elon & Trump get their way, https://www.washingtonexaminer.com/news/2811927/trump-propos... reply o_1 6 hours agorootparentlol reply mkl 5 hours agoprevhttps://archive.ph/A2ZhJ reply ChumpGPT 3 hours agoprev> Planetary rings may be one of space’s many spectacles, but in our solar system, they’re a dime a dozen. While Saturn’s rings are the brightest and most extensive, Jupiter and Uranus and Neptune have them, too,likely the dwindling remains of shredded asteroids or comets. Reading \"The Ring Makers of Saturn\", Dr. Bergrun suggests something very different. reply nprateem 3 hours agoprev [–] The ring of Uranus. One of the wonders of the solar system. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The article explores the concept of Earth's ancient rings, leading to debates about the accuracy of their modern depictions and the potential view from Earth.",
      "The discussion transitions to contemporary issues, such as space debris and satellite constellations, and their effects on astrophotography and the possibility of future rings.",
      "It also examines the trade-offs between low Earth orbit satellites and geostationary satellites, considering the implications of space debris on future space exploration."
    ],
    "points": 82,
    "commentCount": 33,
    "retryCount": 0,
    "time": 1728213444
  }
]
