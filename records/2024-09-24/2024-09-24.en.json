[
  {
    "id": 41629475,
    "title": "In 1870, Lord Rayleigh used oil and water to calculate the size of molecules",
    "originLink": "https://www.atomsonly.news/p/franklin-oil",
    "originBody": "Share this post Estimating the Size of a Single Molecule www.atomsonly.news Copy link Facebook Email Note Other Discover more from Atoms Only Science is for everyone. Subscribe Continue reading Sign in Estimating the Size of a Single Molecule How Ben Franklin and Lord Rayleigh used little more than oil and water to calculate a molecule's size. Sep 23, 2024 8 Share this post Estimating the Size of a Single Molecule www.atomsonly.news Copy link Facebook Email Note Other 6 Share Many decades before the discovery of x-rays and the invention of powerful microscopes, Lord Rayleigh calculated the size of a single molecule. And he did it, remarkably, using little more than oil, water, and a pen. His inspiration was none other than Benjamin Franklin. Sometime around 1770, while visiting London, Franklin became intrigued by a phenomenon he had observed during his transatlantic voyage. Specifically, he noticed that when ships discarded greasy slops into the ocean, the surrounding waves would calm. This ancient practice of oiling the seas to pacify turbulent waters was known to the Babylonians and Romans, but Franklin decided to investigate further. On a windy day in London, he walked to a pond on Clapham Common. Carrying a small quantity of oil — \"not more than a Tea Spoonful,\" according to his diary — Franklin poured it onto the agitated water. The oil spread rapidly across the surface, covering \"perhaps half an Acre\" of the pond and rendering its waters \"as smooth as a Looking Glass.\" Franklin documented his observations in detail; they can be read today on the Clapham Society's website. Clapham Common in London. Franklin's oil drop experiment, of course, was just one in a long line of “amateur” science experiments. He was also the first to demonstrate that lightning is electrical in nature (via his famous kite experiments), and he charted the Gulf Stream’s course across the Atlantic ocean, noting that ships traveling from America to England took longer than those going the opposite direction. His experiments at Clapham Common are not nearly as well-known. But Franklin was a careful experimenter, repeating his oil drop multiple times and taking notes each time. In his journal, he opined on how much oil might be needed to calm various areas of ocean (he was thinking specifically about applications for the Royal Navy) but never grasped the molecular implications of his experiments. It wasn't until more than a century later that Lord Rayleigh, whose real name was John William Strutt, revisited Franklin's experiment with a brilliant new perspective. An academic at the University of Cambridge and a baron by title, Rayleigh was renowned for his work in physics. The Rayleigh number, a common parameter used to describe the flow of water, is named for him; as is Rayleigh scattering, which explains how photons diffuse through the atmosphere and color the sky blue. Rayleigh also discovered the noble gas, Argon, earning a Nobel Prize for it in 1904. But a little experiment that Rayleigh performed in 1890, inspired directly by Franklin's observations, is not nearly as well-known. Subscribe! It’s free. Subscribe Rayleigh carefully measured a tiny volume of olive oil — 0.81 milligrams, to be exact — and placed it onto a known area of water. The oil quickly spread out and covered an area, which Rayleigh precisely measured. And then he did something that Franklin never thought of: Rayleigh divided the volume of the oil by the area it covered, thus estimating the thickness of the oil film. Assuming that the oil formed a single layer of molecules — a monolayer — then the thickness of the oil film is the same thing as the length of one oil molecule. This is how Lord Rayleigh became the first person to figure out a single molecule’s dimensions, many years before anyone could see such molecules. Here is his equation: \\(Thickness = {\\dfrac{Volume}{Area}} = {\\dfrac{0.00081 cm^3}{\\dfrac{1}{4}\\pi \\times (84 cm)^2}} \\approx 1.63 \\times 10^{-7}\\) Rayleigh’s final result was 1.63 nanometers. Olive oil is mainly composed of fat molecules called triacylglycerols, and we now know that they measure about 1.67 nanometers in length, implying that Rayleigh’s “primitive” estimates were off by just 2 percent. His original paper detailing the experiment can be found here. I love this story because it shows, at least anecdotally, how deep scientific insights can emerge from the simplest of experiments. It's a testament to the idea that you don't always need sophisticated equipment to unlock the secrets of nature — sometimes, all it takes is a drop of oil and a bit of ingenuity. For those interested in delving deeper into the history of these oil drop experiments, Charles Tanford's book, Ben Franklin Stilled the Waves, offers an extensive exploration. An excerpt from Lord Rayleigh’s published manuscript. Subscribe to Atoms Only By Niko McCarty · Launched 21 hours ago Science is for everyone. Subscribe Error 8 Share this post Estimating the Size of a Single Molecule www.atomsonly.news Copy link Facebook Email Note Other 6 Share",
    "commentLink": "https://news.ycombinator.com/item?id=41629475",
    "commentBody": "In 1870, Lord Rayleigh used oil and water to calculate the size of molecules (atomsonly.news)516 points by mailyk 23 hours agohidepastfavorite176 comments wwarner 20 hours agoIn 1676 Roemer estimated the speed of light by timing the orbit of Jupiter’s moon Io, noting that as the Earth approached Jupiter, Io emerged from behind Jupiter a little earlier every day, and as the Earth traveled away from Jupiter it appeared a little later every day, with the time of day varying by 22 minutes over a year. Knowing the difference between the two distances, he reckoned that light travels that distance in 22 minutes, or 227 thousand km/s. The actual speed is about 300 thousand km/s. Not bad! reply DaoVeles 17 hours agoparentI always appreciate these stories about how very specific observations that most people would miss can give away far deeper details of the universe that many wouldn't even consider. Eratosthenes using shadows and figuring out the size of the earth within a few percent is another well known one. reply shthed 6 hours agoparentprevhttps://en.wikipedia.org/wiki/R%C3%B8mer%27s_determination_o... https://en.wikipedia.org/wiki/Speed_of_light#First_measureme... Another interesting thing about using the timing of moon eclipses: > Galileo proposed a method of establishing the time of day, and thus longitude, based on the times of the eclipses of the moons of Jupiter, in essence using the Jovian system as a cosmic clock. The times of the eclipses of the moons could be precisely calculated in advance and compared with local observations on land or on ship to determine the local time and hence longitude. https://en.wikipedia.org/wiki/Galilean_moons#Determination_o... reply ForOldHack 53 minutes agoparentprevThe speed of light, because it is so fast, is the most precise physical constant known : 299 792 458 m / s. Less than 7/1000ths away from 300,000,000 m / s. I am not going to sweat this in the least. So light travels only 0.3 m / nano second, or 11.802 inches. https://www.youtube.com/watch?v=9eyFDBPk4Yw reply Neikius 28 minutes agorootparentArmed with this fact thinking about electronic devices. How the front of the signal travels and how suddenly the distance matters. Was blown away when I first thought about this. reply glial 26 minutes agorootparentprevTherefore in one cycle of a 3GHz processor, light travels about 4 inches. Wild. reply cchi_co 10 hours agoparentprevIt's amazing to think that with nothing more than a telescope and careful timing, he managed to get so close to the actual speed of light. reply NeoTar 7 hours agorootparentWell, also knowledge of the distances between the objects involved (at least the Earth and Jupiter), which in turn depended on a series of further investigations. Which is not to denigrate the achievement, but if I were to drop you on an alien world with only a telescope and an accurate time keeper, you're not going to be able to recreate it. reply zokier 4 hours agorootparent> if I were to drop you on an alien world with only a telescope and an accurate time keeper, you're not going to be able to recreate it. But you can relatively easily derive the distances too with timekeeper and telescope, by applying Keplers laws? reply wizzwizz4 2 hours agorootparentOne can, in principle. Most people lack the talent. (It's a skill that almost anyone could learn, but that doesn't make it a skill everyone has.) reply foggyjvdfghhv 1 hour agorootparentThat’s not the definition of talent reply wizzwizz4 1 hour agorootparentFrom what I've seen, talent is the tendency for a person to naturally develop a skill, if left alone to do so. It isn't some kind of intrinsic capability. reply ForOldHack 58 minutes agoprevHe had time to think. Something so rare these days. 30 years later, Henry Cavendish measured G and estimated the density of the earth. Using candles, mirrors and telescopes. https://en.wikipedia.org/wiki/Cavendish_experiment reply Terr_ 22 hours agoprevThat reminds me of the Millikan & Fletcher oil-drop experiment [0], which measured the charge of the electron. In short, microscopic atomized oil droplets had their fall-time through air measured to figure out their volume, and then a known electric field was used to levitate them. The calculated charge-per-molecule clustered around multiples of a smaller value, which would be the charge of an individual electron. [0] https://en.wikipedia.org/wiki/Oil_drop_experiment reply kqr 10 hours agoparentThey tried a similar experiment first, called the water drop experiment. It was intended to work in the exact same way, except with the obvious parameter varied: they would use water instead of oil. The reason the water drop experiment failed was that the bright lamps they used to look at the drops evaporated the water too quickly.[1] Such a relatable experience! [1]: https://buttondown.com/entropicthoughts/archive/when-bubble-... reply pdm55 14 hours agoparentprevThere is always more to the story: https://www.scribd.com/document/661270387/My-Work-with-Milli... Fletcher & Millikan https://www.youtube.com/watch?v=B-uWaEvXqbA reply n_plus_1_acc 21 hours agoparentprevHow can you make sure you don't end up with 2e as a result? (Or any other multiple) reply SyzygyRhythm 21 hours agorootparentFor that to happen, you would have to be very unlucky: all of your measurements would have to be 2e, 4e, 6e, etc. If a 3e or 5e sneaked in there, you'd realize that the charge was e, not 2e. With enough measurements, you can be confident that you've hit all the expected multiples of the quantum. reply db48x 11 hours agorootparentNot quite so. They did end up measuring a multiple of the fundamental electric charge. The experiment really measured 3e, 6e, 9e, etc. It turns out that the electron and proton have an electric charge 3× bigger than that of a quark. Since the experiment didn’t generate any free quarks, nobody noticed for years. Even today the mistake persists and school children are taught, unironically, that down quarks have ±⅓ of the fundamental indivisible unit of electric charge and that up quarks have ±⅔e. reply wholinator2 7 hours agorootparentNo need to nitpick, the original comment states perfectly accurately that he was measuring the fundamental charge _of the electron_, from which the constant e is derived. We've been using e to mean _electron_ charge for a very long time. Where do you get the idea that constant has anything to do with quarks? reply db48x 7 hours agorootparenthttps://i.kym-cdn.com/photos/images/original/000/992/402/c35... But seriously, it really is time to fix all the chemistry textbooks so that the charge of the electron is +3 instead of −1. reply empyrrhicist 2 hours agorootparentWhy, to make all that quark chemistry a bit easier? reply db48x 1 hour agorootparentBecause electric charge is quantized, so measuring it in thirds is just dumb. reply ForOldHack 1 hour agorootparent\"I see a clock, but I cannot envision the clockmaker. The human mind is unable to conceive of the four dimensions, so how can it conceive of a God, before whom a thousand years and a thousand dimensions are as one?\" -Albert Einstein It would have revealed a lower layer of higher understanding. No one has been able to calculate the mass of a quark: \"Nobody has seriously calculated theoretically a quark mass from first principles. So there is no issue of agreement with experiment. They are parameters in experimental fits, but sometimes remarkably consistent across a broad range of experiments-- and the QCD/EW calculations using them as inputs. If someone pretends to know their origin, he/she is bluffing.\" But the exercise is extraordinary! reply Terr_ 21 hours agorootparentprevIn 1909 the results results were couched in some \"elementary electric charge\" quantity, since the now-familiar subatomic particle model (and the \"electron\") was still gaining acceptance. I expect that the greater the number of trials, it becomes easier it is to detect a distinction between closer-multiples, and if at some point more trials stops changing the answer then you've likely converged on e, unless there's some new principle like \"X-ray exposure only affects charge in in multiples of e greater than one.\" reply adrian_b 9 hours agorootparentThe approximate value of the elementary electric charge had been known since 1874, when it was first computed by George Johnstone Stoney. After Stoney, other experiments had reduced the uncertainty with which the value was known, but it remained relatively high. The importance of the experiments of Robert Andrews Millikan consists in the fact that the uncertainty of the value of the elementary electric charge obtained by this method was much smaller than by any previous method (he claimed that it was better than one half of one percent, but he used wrong values for the viscosity of air, so his actual result was off by more than that, but still by less than one percent from the correct result). reply nkmnz 21 hours agorootparentprevYou do. Thae size of the steps between the results is the “quantum” of a single transferable charge. reply dekhn 21 hours agorootparentprevHe did- he selected the lowest value, ignoring all the multiples. reply ceejayoz 21 hours agorootparentNot ignoring the multiples; the multiples verify the result. If you calculate the charge of one at 1e and you measure 2.5e, something went wrong. All values must be a multiple of the lowest. reply rkagerer 15 hours agoprevThis is fascinating, but wasn't it still a bit of a conjecture to assume the oil would spread to a minimum thickness of one molecule? Did he have any doubts, like that surface tension might keep it thicker? Or other clues hinting it was indeed a monolayer? reply nielsbot 13 hours agoparentMy question exactly.. I hope someone can chime in :) EDIT: Thinking a bit more... I suppose it's a reasonable assumption that the molecules (mostly) wouldn't stack on top of each other. They all want to get lower and perhaps the resistance to the oil spreading out is much lower proportionately that the gravitational force encouraging the oil to flatten reply lIl-IIIl 11 hours agorootparentBut if I spill some oil on my plate it doesn't look a molecule thin to me. Why is it different with water? reply OvbiousError 9 hours agorootparentI guess oil is repelled by water, so when it's poured on top of water it's more like floating on top. So the water pushes up, gravity pulls down and the oil molecules pull on each-other, there is no horizontal friction, allowing the oil to spread out this way. Whereas the oil does slightly stick to your plate, as can be observed when moving the plate around, so it won't spread as thinly? reply MereInterest 7 hours agorootparentprevThere’s a couple of possible reasons. First, you probably spilled more oil onto the plate. In the experiment, 0.81 milliliters of oil spread out until it covered a circle with diameter 84 cm. Most spills would be more than a mL of oil, and most plates are much smaller. Second, most plates aren’t flat. If you have an area of the plate that is at a lower elevation than the rest, the oil would pool up in that area. Third, even if you fill the plate with water, you could have elevation changes due to surface tension of the water. If the water is concave up, the oil would float upward and form a ring around the edge. If the water is above the surface of the plate, held in just by surface tension, the oil would float upwards and form a bubble at the center of the plate. Fourth, you could have something else on the plate that acts as an emulsifier. Whether a bit of egg, some pasta water, leftover detergent, these would break up the oil and prevent a film from forming. The easiest way to have a flat surface is to do the experiment in the center of a much larger body of water, since any effects from the surface tension would be at the edge. reply gnramires 2 hours agoparentprevPerhaps he was observing the layer making sure it had integrity? Oil layers famously have an optical effect (iridescence from interference of reflections). This effect would transition as the layer goes from >= 1 molecule thick to One, Two, Three... Infinity: Facts and Speculations of Science (1947) https://www.amazon.com/One-Two-Three-Infinity-Speculations/d... PDF: https://archive.org/details/OneTwoThreeInfinity_158 .......................... >Thirty Years that Shook Physics: The Story of Quantum Theory (1966) https://www.amazon.com/Thirty-Years-that-Shook-Physics/dp/04... PDF: https://archive.org/details/ThirtyYearsThatShookPhysics-TheB... reply DonaldFisk 3 hours agorootparentprev> to deriving then proving experimentally proving general relativity and decomposing GR into Newtonian physics/other laws of electromagnetism Do you mean Special Relativity, which covers classical mechanics and electromagnetism? General Relativity covers gravitation and cosmology without electromagnetism (though Kaluza and later Klein devised a theory unifying gravity and electromagnetism by adding an fifth dimension to General Relativity, which can then be decomposed into 4-dimensional GR and Maxwell's equations). reply knodi123 3 hours agorootparentprevyou only had to take one physics class, and it was quantum electrodynamics??? That sounds to me as if someone said \"The only math class I've taken was differential equations.\" reply ddfs123 17 hours agorootparentprevThat was my Physics too, but Chemistry just completely glanced over the history. Same thing with Mathematics, no backstory of mathematicians. I guess that either 1. Physics History is short enough, well-recorded, or 2. Physicists really like teaching their history. reply SJC_Hacker 15 hours agorootparentPhysicists seem to be always seeking a deeper understanding of everything, more so than other fields like biology and sometimes chemistry, who have a tendency to get bogged down into to the idiosyncrasies of particular phenomena. reply shepherdjerred 15 hours agorootparentprevMIT has an excellent chem course on YouTube that goes into the history reply hn_throwaway_99 15 hours agorootparentprevYeah, in retrospect I think this aligns with my experience. But I'd even say that with the famous physics experiments I still remember often thinking \"How did they get such precision with such primitive instruments?\" I mean they would explain the experiments in very basic/schematic terms, but would have been nice to actually replicate I've to truly understand how it worked. reply layer8 21 hours agorootparentprev> experimentally proving general relativity Can you elaborate on that? What experiments did the professor perform? reply stevenwoo 17 hours agorootparentI mis wrote, he talked about the experiments done to verify general and special relativity. Michelson-Morley was one of them that sticks in my mind along with some traveling atomic clocks. We never recreated the experiments like some of the other commenters did in their classes. reply danielam 8 hours agoparentprevYes, often what is taught is taught in a manner that seems mysterious in origin, as if it were revealed, certain and final, and developing a sensibility like that concerning scientific matters is not good. You could argue that the viability of science as such rests on certain articles of faith, but the particular findings of science themselves are a matter of demonstration, interpretation of demonstration and argument making use of interpreted demonstration, as well as the making of certain working assumptions that do quite a bit of quiet heavy lifting. The last, I think, receives too little attention, but it also supports the idea that practical and pragmatic rather than theoretical motives and habits drive much of scientific activity. reply hn_throwaway_99 3 hours agorootparentYes! Not to get too political, but I saw a lot of this during the Covid debates, e.g. \"Trust the science!\" Noooo! Science is not just something you're supposed to \"trust\", but something that's supposed to be supported by evidence. Yes, I definitely understand that most people don't have the training and background to understand complex scientific topics, and in some ways we do have to trust the scientific community if we're not a part of it. And I get frustrated by the common calls of \"Do your own research!\", which often means \"Look at these YouTube grifters with absolutely no training who are just spouting stuff with no research of their own.\" But even the underlying problem with that is that most people aren't trained to evaluate the quality of data and motivations of people making it, and that is what scientific education should be about. For example, I may have to \"trust\" the scientific community when it comes to data about infectiousness of COVID because I'm not an epidemiologist, but how that data is translated into rules and regulations is a policy call, and that policy call is not necessarily one where the epidemiologists are the experts. I shouldn't be told to \"trust the science\" as though I should just accept policy recommendations even if I do accept the underlying data about transmissibility. reply nobrains 6 hours agorootparentprevPragmatic or luck? Hear me out... Why assume \"that the oil formed a single layer of molecules — a monolayer\" ? That is a very fundamental assumption, and could have been wrong as well (we know it is right, because the values match with more accurate recordings, but still...) reply NegativeLatency 19 hours agoparentprevDiscovering the quantization of the charge of electrons sounds like something you'd be interested in: https://en.wikipedia.org/wiki/Oil_drop_experiment We did it with several hundred volts (DC, scary) in college and it was pretty fun collecting the data and watching the numbers fall out in excel doing the analysis. reply physicsguy 13 hours agorootparentI remember doing this one and the equipment leaking oil all over me! Not long after that I decided to go more Theoretical… reply snatchpiesinger 9 hours agorootparentprevWe also did it in uni, it was very exhausting. And after a full day of measurements noone ever had enough data to see the quantization of the charge of electrons. reply leafmeal 19 hours agoparentprevI read Chasing the Molecule by John Buckingham recently and thoroughly enjoyed it! It give a good outline of the history of modern chemistry in a way that felt accessible but still thorough. It also does a great job of explaining the different characters and their stories. Some little-known who moved chemistry forwards in profound ways, and others, very well-known, who through their loyalty to false theories ended up holding it back. It's also a pretty short book when helps make it feel accessible. reply namuol 19 hours agoparentprevSo very true. The greatest science teachers understand the power that comes with the stories of scientific discovery. Carl Sagan’s Cosmos and some of Richard Feynman’s best lectures come to mind as some of the most memorable examples, but I’m certain all the best teachers out there know to incorporate the historical and human aspects to bring the essential perspective and natural mnemonic anchors to otherwise “dry” subjects. reply cchi_co 10 hours agoparentprevThe journey behind scientific discoveries for me is as captivating as the discoveries themselves reply schrectacular 19 hours agoparentprevAs part of 9th grade biology we had to read \"Microbe Hunters\". The grades ahead insisted that it was awful and boring but I devoured the whole thing in a weekend. So thankful that it was part of the curriculum. reply iamflimflam1 4 hours agoparentprevPretty sure I remember recreating this experiment in high school chemistry. reply andruby 1 hour agorootparentSame here (Belgium). We recreated a lot of experiments in class Even our math teacher would tell us the stories of how mathematicians \"came\" to their solutions. A good teacher makes such a huge difference reply humansareok1 4 hours agoparentprevThere's literally a dedicated major called History of Science. They teach fundamentally different things for different reasons. reply wheatgreaser 6 hours agoparentprevbut chronological order of scientific discoveries does not imply conceptual linearity, so i kinda get why colleges and schools do not go for that kind of approach reply lern_too_spel 14 hours agoparentprevHow we derived the laws and theories is science. (Some of the other commenters are mixing this together with biographies of the scientists, which is not science but is sometimes interesting in its own right.) The laws and theories in isolation are just trivia, and any class that teaches just those cannot truthfully be called a science class. Demand a better education. reply tsimionescu 9 hours agorootparentBoth have their value, both the process and the results. And given the immensity of scientific knowledge, you can only learn so much of it in a K-12 education, or even in college. I don't think it's a priori wrong to teach students our current understanding of the world, without going into the details of how we came up with it. I also don't think it's wrong to add those details, but the more details you add, the less of the full picture you'll be able to present. And I definitely don't think it would be a good idea to teach children how we do science, without teaching them what we actually learned from doing it. I'd also say that the reality of some of the process is extraordinarily boring (\"we kept meticulous records of precisely where on the sky various stars were each night, and how their position changed, for a few hundred years, and tried finding a function that matched those numbers; for a few hundred years, we kept adding more and more circles to correct things, until Kepler came up with some ellipses\"). And that for many children, learning history is already a huge bore, learning the history of science in addition would make science classes much worse. For others, the opposite is true. reply lupusreal 8 hours agorootparentprevMost of the general public would be better served with more emphasis on the history of science. Knowing how and when it happened makes it seem less like magic dogma given to them from the elders, against which rebellion is appealing. reply RheingoldRiver 16 hours agoparentprevI highly recommend this book! https://www.goodreads.com/book/show/25238350-the-hunt-for-vu... reply jonny_eh 14 hours agorootparentI'd recommend this one instead: https://en.wikipedia.org/wiki/A_Short_History_of_Nearly_Ever... reply SkyBelow 4 hours agoparentprev>that laws and theories are presented as just something that you need to memorize That's part of a larger problem in how science is presented. It is presented as something that is true, when it isn't. It is a model that describes reality. The models you are learning in high school and entry undergrad classes are mostly wrong models whose main use is that they are great building blocks to more complex models, as they work well enough in ideal conditions and correlate well enough with our exist. Yet even the best, most up to date models, aren't right. They work well enough in the places they are used that we can bet human lives on them, but that doesn't mean they describe what the universe is actually doing. Unless someone finds a way to crack open up the universe and check the \"source code\", we will never know exactly what the universe is doing and are limited to only ever improving models that approach the truth, like a sum that converges on a value at infinity but never equals that value for any finite sum of the series. reply at_a_remove 16 hours agoparentprevWhen I was a tutor, mostly doing math, when it came to polynomials and that range, I would trick my students into deriving the quadratic equation. It's not even a full page. Almost all of them finished with a strange expression, and then we had the little \"it was always there, waiting for someone to find it\" chat. Some people care about the history, some don't. I find when people talk about astrophysics stuff, most of them do not know the history and ought to, because most of their interpretations fall into the \"Yes, that was a question in the 1960s but eventually ...\" If you want one for relativity, I strongly suggest Was Einstein Right? by Clifford Will. It dates from 1986, so it is nearly forty years behind now, but it covers the many experiments and tests of relativities special and general. reply thimkerbell 20 hours agoprev\"Rayleigh divided the volume of the oil by the area it covered, thus estimating the thickness of the oil film. Assuming that the oil formed a single layer of molecules — a monolayer — then the thickness of the oil film is the same thing as the length of one oil molecule. This is how Lord Rayleigh became the first person to figure out a single molecule’s dimensions, many years before anyone could see such molecules.\" reply adrian_b 10 hours agoprevThe title of this thread appears to be wrong, because the parent article says \"But a little experiment that Rayleigh performed in 1890, inspired directly by Franklin's observations, is not nearly as well-known.\" Therefore Rayleigh computed the size of molecules in 1890, not in 1870 (in 1870 Rayleigh was young and not known yet for any original research). While Rayleigh has devised a novel method for determining the size of molecules, it should be noted that the first who has succeeded to determine the size and weight of molecules was Johann Josef Loschmidt, in 1865. https://en.wikipedia.org/wiki/Johann_Josef_Loschmidt The publication of the weight and size of air molecules by Loschmidt is one of the most important milestones in the history of physics. Until that moment in 1865, the theory of atoms revived by Dalton could still be considered as some kind of fictitious model that explained some features of the chemical reactions and of thermodynamics, but which might have been wrong and which would probably be replaced by some better model. Starting from that moment, the atoms and molecules could be weighed and counted, so their reality was no longer questioned. The determination by Loschmidt of the size and weight of air molecules was enough to determine the sizes and weights of any other known atoms and molecules, making use of the relative atomic weights that could be determined from chemical reactions and which were already known. Moreover, a few years later, in 1874, George Johnstone Stoney has used the results of Loschmidt together with the theory of the existence of an elementary electric charge published by Maxwell one year before, in 1873, to compute the value of the elementary electric charge. Some years later, Stoney has given the name \"electron\" to the elementary electric charge, which has been the source of a very large number of words in modern science and technology, from electronics to hadrons. reply bqmjjx0kac 22 hours agoprev> Assuming that the oil formed a single layer of molecules — a monolayer — then the thickness of the oil film is the same thing as the length of one oil molecule. How did he know that the film of oil was one molecule thick? It feels like a huge assumption to me, but maybe this blog post left something out. reply tech_ken 21 hours agoparentBlog post seems to have elided this point, but it did link the original paper which was quite short: https://www.damtp.cam.ac.uk/user/gold/pdfs/teaching/old_lite... Rayleigh's experiment was actually trying to solve for the minimum thickness of oil required to stop some camphor shavings from moving around on the water. He never states it explicitly, but I think the assumption is that the minimum thickness required to stop the shavings' movement would be such that the oil volume 'just' covers the surface, ie. is 1 molecule thick everywhere and hence the shavings never touch water. I think he's specifically making a slightly more clever point about surface tension, but that's a little beyond me. reply zokier 4 hours agorootparentReading the paper, there is no mention of sizes of molecules. Did Rayleigh actually make the connection between film thickness and molecular size at some point? Or is that just modern retconning? reply zokier 3 hours agorootparentReplying to myself, I found 1899 paper which is more explicit on the matter, and shows how Rayleigh was not all that certain about the results: The comparison of the present with former results throws an interesting light upon molecular magnitudes. It has been shown (Proc. Roy. Soc. March 1890) that the thickness of the film of olive-oil calculated as if continuous, which corresponds to the camphor-point, is about 2.0 μμ while from the present curves it follows that the point at which the tension begins to fall is about half as much, or 1.0 μμ [...] If we accept this view as substantially true, we conclude that the first drop in tension corresponds to a com- plete layer one molecule thick, and that the diameter of a molecule of oil is about 1.0 μμ XXXVI. Investigations in Capillarity:—The size of drops.—The liberation of gas from supersaturated solutions.—Colliding jets.—The tension of contaminated water-surfaces If we assume that the \"about 2.0 μμ\" value is just the previously mentioned 1.63 nm value rounded up, then that throws a wrench into the story, in particular this bit from blog post > Rayleigh’s final result was 1.63 nanometers. Olive oil is mainly composed of fat molecules called triacylglycerols, and we now know that they measure about 1.67 nanometers in length, implying that Rayleigh’s “primitive” estimates were off by just 2 percent is more of a numerological coincidence, the actual estimate that Rayleigh gives is half of that! reply tech_ken 1 hour agorootparent> is more of a numerological coincidence, the actual estimate that Rayleigh gives is half of that! I definitely thought so too, in the first paper the 1.67 isn't even really his primary guess so definitely some presentist bias in the OP reply bialpio 11 minutes agorootparentFrom the paper: \"The thickness of oil required to take the life out of the camphor movements lies between one and two millionths of a millimetre, and may be estimated with some precision at 1’6 micromillimetre.\" Looks like a primary guess to me, even if the table lists more data points. reply tech_ken 3 hours agorootparentprevIt's really (really) quick but the first line of the second para is: > In view, however, of the great interest which attaches to the determination of molecular magnitudes, the matter seemed well worthy of investigation... So it seems like his main goal was to understand the size of molecules via his film-thickness measurements reply youainti 17 hours agorootparentprevCamphor would release compounds that adjust the surface tension of water. So the oil would break that direct relationship. reply tech_ken 3 hours agorootparentAhhh that's cool, thanks for clarifying reply bloak 11 hours agoparentprevIf you try the experiment lots of times with drops of different sizes you find the oil layer always has roughly the same thickness. That's an interesting observation that calls for some kind of explanation, and the hypothesisis that the thickness of the oil layer is the length of one molecule is perhaps the most obvious and plausible explanation. Then one would look for confirmation, of course. (What was the next thing to confirm this, historically?) reply happytoexplain 22 hours agoparentprevIt feels intuitive that a thin fluid on a low-friction surface (like water) would spread out \"as much as possible\" given enough time. There certainly may be confounding factors, but it seems like a reasonable thing to pin as an \"assumption\" in a hypothesis. I.e. he didn't have to \"know\" - assumptions are OK, and I don't feel like this one is huge. reply chmod775 17 hours agorootparent> It feels intuitive that a thin fluid on a low-friction surface (like water) would spread out \"as much as possible\" given enough time. Most fluids do not behave this way in most circumstances, because of surface tension, so it's really not intuitive. This experiments is one of the few ways you can get an accurate measurement. Many other fluids will either mix or end up as bubbles/blobs many orders of magnitude thicker than a molecule. reply komali2 16 hours agorootparentprevI'm confused, the blog wrote \"known amount of water,\" so was it a closed little area like a bathtub? If you added a ton of oil wouldn't it spread out as much as possible aka 600 molecules thick or whatever? Or did he pour it into a huge lake or something? reply MereInterest 7 hours agorootparentMy understanding is that the actual body of water was larger, but that the oil would only spread out to one molecule of thickness. So you start with a larger area of water, and measure the diameter of the resulting oil slick. reply Cheer2171 15 hours agorootparentprevOne drop in a soup bowl sized petri dish, measure the area it covers. reply komali2 13 hours agorootparentSurely the first thing to test would be dropping it in increasingly large soup bowls until there's obvious gaps? reply kqr 10 hours agorootparentHow would the gaps be obvious? I'm not sure I could tell 1 molecule from 0 molecules when it comes to the thickness of oil film. reply munchler 22 hours agoparentprevAgreed. The experiment actually gives an upper limit on the size of a molecule in one particular dimension. Still a very useful result. reply layer8 21 hours agorootparentIt isn’t necessarily an upper bound. The molecules might spread out more distant than their size. reply bagels 19 hours agorootparentWouldn't that provide an upper bound then? If the real size is equal to or less than the calculated size? reply gus_massa 18 hours agorootparentprevIn a very unlucky world, they can form a 2D net, with molecules instead of strings and a lot of tiny holes. If this seams impossible, remember that when water freeze into ice, it expands to a 3D \"net\" with empty holes. reply tantalor 18 hours agoparentprevScientists frequently have to make assumptions in order to make progress. Famous example is Darwin figured out that traits are inheritable by natural selection, and this is the driving force of evolution, without having any concept of the physical nature of DNA, or how genes could change (eg. by DNA mutation) to develop adaptations and thus make an organism more fit. reply kccqzy 1 hour agorootparentThis is why I guess I was never really interested in scientific experiments personally and decided to study mathematics. These assumptions don't seem justified to me. At least in mathematics you always state these assumptions or hypotheses very clearly, or make them into axioms. reply jjk166 21 hours agoparentprevIf there were multiple layers of molecules then the film would spread out over a wider area. With repeated experiments it would be clear that films are always an integer multiple of this thickness and never thinner. reply MereInterest 7 hours agorootparentExcept that you could have part of the surface covered in 1 molecule, and another portion covered in 2 molecules. Since you never directly measure the thickness, this would produce the same apparent thickness as a uniform 1.5 molecule thick layer. reply jjk166 4 hours agorootparentThat's not how fluids work. The molecules spread out to form an even surface everywhere, so you can't have local high spots. You'd have to put in enough oil to cover the entire surface, and then put in more. reply kccqzy 1 hour agorootparentYeah and the point is that there is more embedded knowledge about surface tension here. For example if I put a small drop of water onto my desk, it does not spread out into a thin film of one water molecule thick. It remains a droplet due to surface tension. reply shultays 4 hours agoparentprevAn idea: if oil forms a two dimensional shape, ie a single layer of molecules, then adding 2x amount of oil would give you twice the area. If it is three dimensional, say oil makes a bubble, then it would look smaller. Of course this also fails if the oil formed a disc of X layers of molecules reply Jeff_Brown 3 hours agoparentprevAnd even assuming it's one molecule thick, how did he know how tightly the oil molecules in that layer pack together? reply taberiand 18 hours agoparentprevPerhaps at the time it was sufficient to define \"molecule of oil\" as \"the height of the amount when spread maximally across the surface of water\", and it just so happens that height is only 1 actual molecule reply mda 12 hours agoparentprevI have also immediately thought the same question. This is probably the most crucial part of the whole estimation and indeed left out in the article. reply stolen_biscuit 21 hours agoparentprev> How did he know that the film of oil was one molecule thick? He didn't. It was an assumption reply FpUser 22 hours agoparentprevnext [15 more] [flagged] ummonk 22 hours agorootparentSeems questionable that Rayleigh would have known that oil molecules are hydrophobic on one end and hydrophilic on the other. reply caymanjim 20 hours agorootparent> Seems questionable that Rayleigh would have known that oil molecules are hydrophobic on one end and hydrophilic on the other. That's not a true thing, so it kinda doesn't matter. Surfactants (soaps, emulsifiers) have hydrophobic and hydrophilic ends. Oils are just straight up hydrophobic and nonpolar and don't have a water-loving end. reply bryanlarsen 22 hours agorootparentprevHe certainly knew oil was hydrophobic. I don't think the hydrophilic nature was necessary for the logic. If it was, I'm sure he knew that soap oils are both hydrophobic and hydrophilic and had ways of figuring out that soap oils consist of a single type of molecule and aren't a mixture. reply ummonk 21 hours agorootparentHe used olive oil though, not a soap oil. reply bryanlarsen 19 hours agorootparentOlive oil is a soap oil. reply CamperBob2 13 hours agorootparentIf that's true, then the ChatGPT answer isn't wrong, at least for the specific case of olive oil. I love how a few self-appointed guardians of hackerhood are able to declare certain resources as haram, even when they propose a plausible answer to a question that went unanswered more than once in the thread. Instead of embarking on a discussion that leaves us all a bit better informed, the literal messenger is attacked. Does that gratify intellectual curiosity? Really? reply ummonk 4 hours agorootparentNo the idea that Rayleigh knew the film was one molecule thick, let alone why it was one molecule thick, is clearly made up. The paper makes it clear that he was reporting the thickness, and thought this might provide information on molecule size. reply bryanlarsen 3 hours agorootparentLOL, the first line of the ChatGPT response: `Lord Rayleigh didn’t know a priori that surface tension would cause the oil film to be exactly one molecule thick, ` reply FpUser 22 hours agorootparentprevNo idea. I was curious myself and decided to ask our \"guru\". The answer seems a bit fishy reply klyrs 22 hours agorootparentWhatever possessed you to post that bilge, despite finding it fishy, is beyond me. In the future, you might choose to keep such interactions to yourself. reply PhasmaFelis 22 hours agorootparentprev> Cortesy of ChatGPT: Can we not, please? At the very least not unless you personally have the knowledge to confirm that ChatGPT didn't make any mistakes, as it did here. reply fii 2 hours agorootparentAgreed, although it does make me wonder whether the number of mistakes chatgpt comments make would truly be greater (or at the least more harmful) than the outstanding number of folk who are confidently wrong in a way only obvious to domain experts. It’s easier to be skeptical of a bot. reply ajuc 22 hours agorootparentprevThis should be a rule on hacker news. reply elevaet 20 hours agorootparentAgreed. Everyone here knows how to use chatgpt. We come here for a different way to share, learn and interact. reply bangonkeyboard 22 hours agoprevI would have loved to have had a course in school about \"The Design of Scientific Experiments.\" One that described the processes of landmark historical experiments from antiquity onward, and challenged students throughout: \"Given this set of constraints, how would you design and execute an experiment to estimate the size of the Earth? Disprove phlogiston and luminiferous aether? Measure the speed of light?\" reply dekhn 22 hours agoparentI don't think many people today would be able to propose the Michelson Morley experiment and then actually do it. It was truly heoric (and Michelson was a genius). We did this oil/water experiment in freshman physics or chemistry lab. It was rushed, everybody just did the minimum, the teachers barely explained any of it, and then we moved on. reply _dark_matter_ 21 hours agorootparentI agree. The Michelson Morley experiment reminds me of some difficult algorithms: simple only in hindsight, and implementation is _hard_ to do correctly. reply buescher 19 hours agorootparentprevPeople still win Nobel prizes (LIGO, for example) using interferometers. It’s arguably the single greatest invention in experimental physics. reply cchi_co 10 hours agoparentprevThat would have been an incredible course! reply bsder 20 hours agoparentprevExperiments are HARD. There is a joke among physicists that theoreticians are washed up by 35 but experimentalists don't even get started until 45. To make a physics experiment work you have to be ridiculous about recording details and have a strong intuition. You have to design the experiment such that you can differentiate between \"hypothesis wrong\" and \"equipment doesn't work\" because you don't know the answer. (For example: When they turned on LIGO for the first time, they almost immediately caught a great event. Huge victory party, right? Nope. They promptly ignored it assuming that something was wrong with the machine. And it was only after significant post analysis and correlation that they decided that it was a real event.) reply andreareina 13 hours agorootparentThe lengths they're going to fix the \"loopholes\" in the Bell Inequality tests are amazing. reply raverbashing 10 hours agorootparentprev100% true And this is my sticking point with a lot of \"Science skeptics\" around that have skepticism as their personality Make no mistake, I do take scientific discoveries and knowledge very serious, and knowing the stories make it appreciate more the efforts and the work it took to get there But a lot of times people think the experiments give a very clear-cut results, when it's more like \"one line is squiggly down and the other is squiggly up\" with data being barely over 5 sigma reply tony-allan 15 hours agoprevhttps://www.atomsonly.news/p/franklin-oil Why this domain has been suspended Since January 2014, all ICANN accredited registrars (like Namecheap) have been required to verify the contact information (Registrant Whois) of customers registering domain names. This includes modifications to the contact details. reply tony-allan 5 hours agoparentFixed! reply OvbiousError 9 hours agoprevCool article. They somehow got the formula wrong though, the formula on the screenshot has an additional factor of 0.9 that accounts for the fact that 1l of oil is not 1 kg. Perhaps it's intentional, but for something so simple I don't think it needs to be dumbed down even further. reply CountHackulus 22 hours agoprevWe recreated this experiment in one of my university physics classes. It was a lot of work, and our results weren't nearly as good, but it was instructive and interesting. The equipment requirements were completely reasonable for an undergrad physics lab. I highly recommend giving it a try if you can. reply jll29 9 hours agoprevThanks for covering that story - I lived at Clapham Common for seven happy years. So much history: there is also a little church on the Common, whose past members played a role in the abolishion of slavery: https://en.wikipedia.org/wiki/Clapham_Sect reply FredPret 19 hours agoprevVery cool. For more like this, check out this lecture series: https://www.thegreatcoursesplus.com/the-evidence-for-modern-... It's by a guy called Don Lincoln and it's about how we established things like the existence of atoms, the speed of light, and many other fundamental things that are good to know. It's also an audiobook, though the lectures are easier to follow. reply IncreasePosts 21 hours agoprevA few days ago, there was a HN post about surface acoustic wave filters, and a commenter mentions how inspired the inventor of it must have been(https://news.ycombinator.com/item?id=41604937). That was this same fella! reply dilawar 19 hours agoprevI went to a talk by a very old physicist. At the end of his talk, he said, recalling from memory, all of the great experiments of the past were done by nothing. If an experiment costs more than $100, I am out. His setup has mud in a jar and bacteria in it which you can see with a simple microscope or handheld lens. reply AlotOfReading 13 hours agoparentThat's a bit harsh. To give one counterexample, the Michelson-morley experiment put the figurative nail in the coffin of centuries of speculation about the \"luminiferous aether\". The experimental apparatus was a table-sized precision carved slab of sandstone floating in a huge vat of mercury, holding the highest precision optical equipment of the day. I suspect it cost rather more than $100 even in the 1880s. reply veltas 5 hours agorootparentAlthough it was a refinement of the Fizeau experiment which conceivably could have cost $100 in living memory. reply arvindh-manian 21 hours agoprevRelated: Agnes Pockels’ experiments [0] [0]: https://en.wikipedia.org/wiki/Agnes_Pockels reply carlob 3 hours agoparentTen years earlier and she didn't publish it right away. That really goes to show how much more difficult it was for a woman to become a scientist back then. reply alnwlsn 22 hours agoprevThese are the best kind of posts, where there's something I've never even heard of before. I never knew 'oiling the seas' was a thing, or that it (apparently?) works. reply rkagerer 15 hours agoprevFun fact: Every 4 days humanity produces enough oil to cover the entirety of the world's oceans. Source: Public statistics and my back-of-napkin math, not accounting for waves. reply kitd 9 hours agoprev> and he charted the Gulf Stream’s course across the Atlantic ocean, noting that ships traveling from America to England took longer than those going the opposite direction ?? Has the Gulfstream changed direction in the intervening years? reply nes350 15 hours agoprevhttps://archive.is/oMgPW (The domain of the original article seems to be dead) reply xenocratus 21 hours agoprevLuckily it wasn't my grade that got this experiment as the practical exam in one of the National Physics Olympiads I went to... :) poor souls, most got answers orders of magnitude away. reply Summerbud 17 hours agoprev> I love this story because it shows, at least anecdotally, how deep scientific insights can emerge from the simplest of experiments. It's a testament to the idea that you don't always need sophisticated equipment to unlock the secrets of nature — sometimes, all it takes is a drop of oil and a bit of ingenuity. This can apply to many other fields too! reply quantadev 17 hours agoprevThe credit for proving the existence of atoms is more often associated with Einstein's explanation of Brownian motion and Jean Perrin's experimental confirmation, even though earlier work by Lord Rayleigh, Benjamin Franklin, and others hinted at the molecular structure of matter. reply cchi_co 10 hours agoprevEven back in the day, without all our modern technology, great minds like Franklin and Rayleigh could uncover truths that still resonate today. reply donkeybeer 8 hours agoparentIts not ancient times, some of the most accurate measuring instruments of that time are of a precision that you'd still need a few hundred or thousand dollars to buy today. The tooling wasn't primitive by any means. reply cwillu 15 hours agoprevSite has gone down with a dns error of some kind; anyone have a snapshot? reply kopirgan 6 hours agoprevVery interesting indeed! Was he just lucky that the spread was 1 molecule thick or that's the way oil spreads on water? Why? reply nick238 22 hours agoprevThe page is timing out for me, but is it the inverse problem of the time when Steve Mould/Matt Parker measured the unknown quantity π, but already assuming a size of the molecules? Presumably Lord Rayleigh already had a at least a good order-of-magnitude approximation of pi... https://www.youtube.com/watch?v=lmgCgzjlWO4 reply thirdhaf 22 hours agoparentBy 1870 pi was known to several hundred decimal digits, for something like this calculation where you have other large sources of error Archimedes approximation from 2 millennia earlier would probably be fine. (\"not more than a Tea Spoonful,\" according to his diary — Franklin poured it onto the agitated water. The oil spread rapidly across the surface, covering \"perhaps half an Acre\" of the pond and rendering its waters \"as smooth as a Looking Glass.\" What?? reply imp0cat 13 hours agoparent [–] Here's a video from another post: https://news.ycombinator.com/item?id=41630637 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Lord Rayleigh estimated the size of a single molecule using a simple experiment with oil, water, and a pen, inspired by Benjamin Franklin's observations from the 1770s.",
      "Rayleigh's calculation of an oil molecule's length (1.63 nanometers) was remarkably close to modern measurements (1.67 nanometers), demonstrating the power of basic scientific methods.",
      "This historical experiment underscores how straightforward techniques can lead to significant scientific discoveries, as detailed in Charles Tanford's book, \"Ben Franklin Stilled the Waves.\""
    ],
    "commentSummary": [
      "In 1870, Lord Rayleigh estimated the size of molecules by spreading oil on water and calculating the film's thickness, assuming it formed a single molecular layer.",
      "This method was inspired by Benjamin Franklin's earlier observations.",
      "Historical scientific achievements like Roemer's 1676 speed of light estimation and Millikan's oil-drop experiment to measure the electron's charge demonstrate how simple observations can lead to significant scientific insights."
    ],
    "points": 516,
    "commentCount": 176,
    "retryCount": 0,
    "time": 1727118494
  },
  {
    "id": 41636804,
    "title": "Winamp Legacy player source code",
    "originLink": "https://github.com/WinampDesktop/winamp",
    "originBody": "Winamp About Winamp is a multimedia player launched in 1997, iconic for its flexibility and wide compatibility with audio formats. Originally developed by Nullsoft, it gained massive popularity with still millions of users. Its development slowed down, but now, its source code was opened to the community, allowing developers to improve and modernize the player to meet current user needs. It really whips the llama's ass. Usage Building of the Winamp desktop client is currently based around Visual Studio 2019 (VS2019) and Intel IPP libs (You need to use exactly v6.1.1.035). There are different options of how to build Winamp: Use a build_winampAll_2019.cmd script file that makes 4 versions x86/x64 (Debug and Release). In this case Visual Studio IDE not running. Use a winampAll_2019.sln file to build and debug in Visual Studio IDE. Dependencies Use a build_winampAll_2019.cmd script file that makes 4 versions x86/x64 (Debug and Release). In this case Visual Studio IDE not running. Use a winampAll_2019.sln file to build and debug in Visual Studio IDE. libvpx We take libvpx from https://github.com/ShiftMediaProject/libvpx, modify it and pack to archive. Run unpack_libvpx_v1.8.2_msvc16.cmd to unpack. libmpg123 We take libmpg123 from https://www.mpg123.de/download.shtml, modify it and pack to archive. Run unpack_libmpg123.cmd to unpack and process dlls. OpenSSL You need to use openssl-1.0.1u. For that you need to build a static version of these libs. Run build_vs_2019_openssl_x86.cmd and build_vs_2019_openssl_64.cmd. To build OpenSSL you need to install 7-Zip, NASM and Perl. DirectX 9 SDK We take DirectX 9 SDK (June 2010) from Microsoft, modify it and pack to archive. Run unpack_microsoft_directx_sdk_2010.cmd to unpack it. Microsoft ATLMFC lib fix In file C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\atlmfc\\include\\atltransactionmanager.h goto line 427 and change from 'return ::DeleteFile((LPTSTR)lpFileName);' to 'return DeleteFile((LPTSTR)lpFileName);' Intel IPP 6.1.1.035 We take Intel IPP 6.1.1.035, modify it and pack to archive. Run unpack_intel_ipp_6.1.1.035.cmd to unpack it.",
    "commentLink": "https://news.ycombinator.com/item?id=41636804",
    "commentBody": "Winamp Legacy player source code (github.com/winampdesktop)451 points by gjvc 4 hours agohidepastfavorite204 comments eminence32 4 hours agoOpen sourcing is always good, because maybe you can learn some things by reading it. Also, Winamp Legacy is a fairly important piece of software, so having an archive of its source is a great thing. But the restrictions on the source are interesting. To quote the license file: * No Distribution of Modified Versions: You may not distribute modified versions of the software, whether in source or binary form. * No Forking: You may not create, maintain, or distribute a forked version of the software. * Official Distribution: Only the maintainers of the official repository are allowed to distribute the software and its modifications. I'm guessing the \"No Forking\" clause means I can't release my own media player based on this source code, but the language is curious because they explicitly welcome contributions and for a project hosted on Github the standard way to do that is to \"fork\" the project into your own account. reply xx_ns 3 hours agoparentThis seems to go against GitHub's own ToS[1]: > By setting your repositories to be viewed publicly, you agree to allow others to view and \"fork\" your repositories (this means that others may make their own copies of Content from your repositories in repositories they control). [1] https://docs.github.com/en/site-policy/github-terms/github-t... reply mrgoldenbrown 1 hour agorootparentThere are two distinct meanings of fork and you are conflating them I think. I suspect winamp's license is using the sense of the (pre GitHub) idea of creating a distinct version of a project maintained by a different group, and the GitHub ToS specifically refers to forking within the GitHub platform. reply krick 53 minutes agorootparentLet's say you are hallucinating \"two distinct meanings of fork\". Unless you are referring to tableware, a fork is a fork, it's any distribution of a software, based on the software in question. The fact that most forks on GitHub serve only operational purpose, nobody actively maintains them and nobody normally uses them instead of the parent project, doesn't change what they are: a distributions for (potentially, and unless PR is accepted, actually) distinct software projects, based on a project they are forked from. You are just so used to the button and the process, you lost track of what the label on that button actually means, why it's called \"a fork\". And the answer is, well, because it's a fork. In no way it is different from starting a MariaDB project. As soon as you press that button, you are distributing your own software, based on that parent software. If the parent project disappears, or moves on, or never accepts your PR, which somebody really likes, other people can (and probably will) use your fork in a way that isn't any different than, well, any larger and \"more obvious\" fork. So, essentially, winamp license means nothing. They already forfeited their right to deny you forking by posting it on GitHub. reply maxerickson 1 hour agorootparentprevAny public GitHub fork is being distributed. reply swinglock 45 minutes agorootparentIs forking a well defined term? Doubt it will hold up in court. reply efilife 1 hour agorootparentprevYou can't have a private Github fork reply bdcravens 45 minutes agorootparentYes you can; it's set at the organization level https://docs.github.com/en/organizations/managing-organizati... reply zorgmonkey 25 minutes agorootparentYou can, but only private forks of a private repo are allowed. Private forks of public repos are not allowed by design (modulo some weird bugs that were discussed on a past post). reply thomastjeffery 1 hour agorootparentprevWhat is the other meaning of fork? When you click \"fork this repo\" in GitHub, that clones the repository, and re-publishes it under your username. When you clone a repo to your system privately, that does not involve publishing. If this is their intended meaning of \"fork\", then this license must explicitly disallow cloning the repo! reply TheCraiggers 1 hour agorootparent> What is the other meaning of fork? The older, still in use today meaning is what happened when Oracle bought MySQL and ruined it. People forked it and now we have MariaDB. Basically, it means a fork in the code base and now there are two separate projects. reply simoncion 1 hour agorootparentYes. Until Github came along, \"Creating a copy of software for your own personal use\" had never been widely-accepted definition of the word \"fork\" in the context of software development. Forking a project has always involved independent publication and maintenance of said project. reply bee_rider 50 minutes agorootparentThe typical way of copying a project for your own personal use on GitHub involves publishing that copy on GitHub. So, it is a real fork—maybe not a well maintained one, or one that the author is particularly excited about, though! reply thomastjeffery 36 minutes agorootparentprevOK, but that's still not different. When you fork a project on GitHub, that literally creates a parallel working history, and publishes it under your username. That's what GitHub means by \"fork\". So what's the other definition? reply AshamedCaptain 31 minutes agorootparentMany years ago I would have called that \"mirroring\", which is definitely not forking. reply kjhcvkek77 1 hour agorootparentprevIn particular I think you may press the fork button on the github repo as per github rules. However, you are not allowed to make any commits to this new repo. reply squarefoot 3 hours agorootparentprevInteresting to see how would this play out in case of a lawsuit against an user who doesn't honor their license because it clashes with GH one. Anyway, that code has already been swallowed by some AI that will reorganize it, split in functional blocks and regurgitate it elsewhere someday, so too late for them to complain. reply kube-system 3 hours agorootparentThe GitHub ToS is not a software license. It is the terms for using the GitHub service. The penalty for breaking it is that your GitHub services might be terminated, not that they can somehow relicense your software. reply trehalose 3 hours agorootparentThis part of the ToS explicitly does grant such a license to other GitHub users. > If you set your pages and repositories to be viewed publicly, you grant each User of GitHub a nonexclusive, worldwide license to use, display, and perform Your Content through the GitHub Service and to reproduce Your Content solely on GitHub as permitted through GitHub's functionality (for example, through forking). reply IgorPartola 2 hours agorootparentAs written, this says that you can fork a repo but can’t then clone it and work on it on your own machine. Isn’t software licensing fun? reply skeaker 1 hour agorootparentInteresting. I guess you could just stick to the Github web editor to stay compliant? Really a terrible way to go about things though reply IgorPartola 54 minutes agorootparentYou also can’t run the code. reply bee_rider 45 minutes agorootparentHmm, it says not to distribute the source or the binary. What about WASM or LLVM IR? reply IgorPartola 15 minutes agorootparentIf GH provides they capability I suppose. efilife 3 hours agorootparentprevIt would seem that Github's TOS is superior to their license. They could have chosen other way to host their code reply Etheryte 2 hours agorootparentprevThere is no conflict here. The quote from Github's ToS means you allow others to copy the source code you've made public, it cannot and does not give you any rights regarding what you do with the code beyond that. Points one and two of the Winamp license quote are essentially one and the same, just worded in a different way for clarity. reply slightwinder 2 hours agorootparentprevI guess they mean with \"fork\" a rebranded or self-compiled version. So unmodified source code, but different logo or name. Or compiled with different settings or for an unsupported platform. Something along that line. But calling this fork, after they are already forbidding modifications in point 1 is really strange phrasing. reply elashri 3 hours agorootparentprevIt is interesting that in a hypothetical scenario if someone did fork it and then thes goes to court. Which licence would take precedence here? reply shiandow 3 hours agorootparentSeems to me that it's up to you which license you use, so if one grants the right to fork then there's nothing Winamp could do to prevent that. At best they could invalidate the one license they control, but even that seems iffy reply otteromkram 1 hour agorootparentprev> Which licence would take precedence here? Whichever one runs up the attorney's bill the highest. reply avodonosov 3 hours agorootparentprevDifferent meaning of \"forking\". \"modified/derived version\" vs \"copy\" reply your_drunk_dad 2 hours agorootparentprevTime to report it to GH then. reply rogerdpack 42 minutes agorootparentprevYou can fork it but not commit to it? LOL reply thomastjeffery 3 hours agorootparentprevIANAL... By creating an account on GitHub, you agree to this license. That seems like a pretty strong precedent for precedence. reply KPGv2 15 minutes agoparentprev> but the language is curious because they explicitly welcome contributions and for a project hosted on Github the standard way to do that is to \"fork\" the project into your own account. It's because techies instead of lawyers wrote it. The first and second restrictions overlap anyway, as it says you can't distribute a modified version in the first restriction, but then can't distribute a forked version in the second restriction. I'm not sure what the difference is, and courts don't like redundancy and will often invent reasons to interpret the phrases as meaning something different. I got a $15 parking ticket recently and got it dismissed after I contested the ticket on the basis that the way the city regs were written, they used both \"parking spot\" and \"parking area\" and thus \"parking area\" cannot be synonymous with \"parking spot,\" which altered the meaning of the reg they used to ticket me. reply grishka 3 hours agoparentprevIt feels like they wanted to make sure that no one distributes a modified \"Winamp\" that isn't built from the official sources, which makes sense, but they went too restrictive on it. The usual way to go about it is to say \"if you want to maintain and distribute your own fork of this product, you must change the name and the logo to make sure it doesn't infringe on our branding\". Telegram does this for its client apps, for example. reply simoncion 1 hour agorootparent> ...but they went too restrictive on it. I bet that they would disagree with you. This is an \"all rights reserved\" \"source available\" license. Given the redistribution restrictions, their assertion that it is a \"copyleft\" license is clearly false. reply bityard 4 hours agoparentprev> No Forking Amusing; there are already 6 forks on GitHub as of this writing. reply edm0nd 2 hours agorootparentNow 52 forks on GitHub. Thug life. reply flykespice 2 hours agorootparent72 now This is like a park having a sign on the corner telling you to not step on the grass because it is privately owned but people go and make picnic there anyway reply bastardoperator 1 hour agoparentprevLooks like someone just removed 180K lines of plugin source code from the repo too. Checkout from here: 7ce05499ff0508f9eb06f7194407f676de7d72f4 reply InsomniacL 2 hours agoparentprevThe person who set the license is also accepting PR's from forks. https://github.com/WinampDesktop/winamp/pull/7 reply greenavocado 53 minutes agorootparentThe confusion and disorganization is hilarious reply sva_ 3 hours agoparentprevSeems like 37 madlads have already pushed the fork button. reply sidewndr46 1 hour agoparentprevThis license prohibits maintenance. If the official copy had a single bit that prevents it from compiling on your local machine, you cannot make that change. Only the \"maintainers of the official repository\" are permitted to do that. reply proto-n 4 hours agoparentprevI'm not sure forking the repo would create a forked version of the 'software' if the fork's sole purpose is to develop a pull request. But I guess it's somewhat ambiguous langauge, and better safe then sorry when it comes to lawyers (which I'm not). reply aidenn0 3 hours agorootparentYou're not allowed to \"distribute\" a fork, even in source form. Posting something on Github certainly smells a lot like distributing it. reply mikepurvis 4 hours agorootparentprevPresumably the prohibition is around creating a forked release, with the language being intentionally a bit vague to cover their bases. Unfortunate that that's how these things are, though. reply netsharc 3 hours agorootparentInterestingly the first line says, even distributing a modified version in source form is not allowed... so a GitHub fork with a tiny modification already violates this line. reply derefr 1 hour agorootparentIn a very specific technical sense, it could be argued that it doesn't — the data for GitHub forks (i.e. their branches and the commits of such) is actually stored within the base repo forked from. In other words, by forking something on Github, you're not distributing anything; rather, the original org is now distributing an additional thing you made — your fork branch[es]. This is the source of many confusing things about the security of GH forks; and the source of some recent GH vulnerabilities. Also, if you're curious, this isn't a meaningless \"implementation-level distinction\", as it has semantic implications for repo management: it means that the branch attached to a PR coming from a fork repo continues to exist in the base repo, even if the fork repo that that branch originated from gets deleted. Because that branch was always \"in\" the base repo to begin with; the PR just changed the branch's GH ACLs to make it accessible to the owners of the base repo. (Really, the \"fork repo\" itself is an illusion — it's like a SQL view. There's only the base repo, which contains both regular branches, and user-fork-namespaced branches. This is in part why forks can't be private; they're just a view of resources in another repo, already security-controlled by that other repo; so they can't have their own additional security logic acting on those same resources!) reply mikepurvis 1 hour agorootparentThis implementation choice has always felt a bit odd to me, almost like premature optimization. Is there a reason to have done it this way other than storage deduplication? Since git is already a content-addressed store anyway, how hard would it have been to have some kind of abstraction below the repo layer that would provide the same deduplication? At this point there's obviously huge inertia in Github's early architectural decisions, but if you were building Github today, would it still make sense to go this route? reply eminence32 4 hours agorootparentprevI agree; your interpretation is reasonable and plausible. But it's disappointing to have this ambiguously, since the license file has a whole section for \"Definitions\" and yet it fails to define what \"forking\" means in this context. reply revscat 3 hours agoparentprevThe language is pretty clear to me. I understand what you’re saying, and suspect that this is an honest oversight on their part, but as it currently reads forks are prohibited. They may have meant something else, but what it says now is “no forking.” reply CrankyBear 3 hours agorootparentThey know exactly what they're doing. They're open-washing the program to get attention. It worked. As I write this, it's the number one YComb story. But, it's in no way, shape, or form open source. reply derefr 2 hours agorootparentWell, it's at least slightly more open than e.g. Microsoft's source-available repositories, let alone leaked proprietary source; as you do have the freedom to e.g. read the Winamp source code and then ground-up reimplement a Winamp-alike program, without their lawyers coming after you. (Orgs like ReactOS don't let people contribute if they've ever read code from a Microsoft source-available repos, lest ideas inspired by that code end up in the ReactOS codebase, and Microsoft sue them for that.) I'm not sure what to call a codebase that only grants you the (implicit) right to not be sued for reading the source and then getting inspired by it, though. reply bmacho 3 hours agorootparentprevI am all for reverse Hanlon[0]: don't assume incompetence when people profit from something. I think however that \"source available\" is a legit business model, and not just a HN hack. They made their source code available after all. Although it isn't compatible with github, as the others pointed it out. [0] : https://en.wikipedia.org/wiki/Hanlon's_razor reply z3t4 1 hour agorootparentprevI think this is a great license as it allows you to download the code, make modifications, create \"pull requests\", etc, but you are not allowed to compete, or distribute it with a virus baked in. That way the maintainers have full control and don't have to worry about hostile takeovers, or people making profits without contributing. reply hn_go_brrrrr 2 hours agorootparentprevIt's not \"Open Source\", to use the capitalized term the OSI attempts to gatekeep. It fits most non-zealots' definition, though. reply trashburger 2 hours agorootparentHow is it zealous to prevent people from co-opting and diluting the meaning, like you have done here? If anything, companies are trying to misuse \"open source\" for their source-available code. reply somat 1 hour agoparentprevIt's not open source. however I like it. I wish closed source licenses were more of a thing. as it is, our software tends to fall under two two extremes very liberal open source. closed build artifact only. with very little in the middle. I think a \"here is the copyrighted(with all that implies) source for you to compile on your machine\" software distribution would be a great middle ground. but it is a thing you normally only see on large screwball enterprise contracts. because the normal practice of here is the compiled build artifact really sucks when trying to trouble shoot why it is not working on your machine. reply lucideer 4 hours agoparentprevYeah the license self-refers as \"copyleft\" (an unregulated term afaik), and they have been very careful to avoid usage of the term \"open source\" rather preferring to say things like \"the source is open\". Regulated or not the use of \"copyleft\" still seems deliberately misleading to me - I don't think the restrictions you've listed are in line with the intent of the copyleft movement. reply deathanatos 1 hour agorootparentWhile \"copyleft\" is just a word like any other word, and subject to the same descriptivist drift as any other, in this case it is a specific word coined by a specific org, with a pretty specific definition. One that this license does not meet. reply wormius 46 minutes agorootparentFrankly, copyleft is MORE permissive than generic bullshit weasely term \"open source\" (thanks to corp-friendly ESR). The fact they try to avoid using \"open source\" but willingly use the more \"free as in freedom\" word \"copyleft\" is a bit distressing. I'm tired of this whole \"shared source\" movement, it's disingenuous, and ruins the spirit of actual open source (let alone \"copyleft\"). Boo on Winamp. Shame. I'm still using 5.666 until I die. I won't use their newer stuff, because it's clear they're not doing it with love but just trying to find another captive market of nostalgia nerds. reply kevin_thibedeau 2 hours agorootparentprevCopyleft just means you lose license privileges and revert to unlicensed copyright rules when violating its terms. There's no reason you can't use that principle in a more restrictive way than GPL. reply deathanatos 1 hour agorootparentThat's not at all what copyleft means. https://www.gnu.org/licenses/copyleft.en.html reply kevin_thibedeau 2 minutes agorootparentThat's the FSFs spin. Ultimately GPL is a promise not to pursue an entity for copyright violation without the need for a signed contract. That promise is revoked when you disobey the copyleft. panzi 3 hours agoparentprevYeah, I wouldn't call that an open source license. It's something like Microsoft's \"shared source\", as I expected/feared. reply merb 2 hours agoparentprevIanal but the license also prohibits fair use cases, which probably might circumvent the granted license. reply ndiddy 4 hours agoprevI'm curious how they expect people to contribute to the project. Section 4 of the license says \"Contribution to Project: You are encouraged to contribute improvements, enhancements, and bug fixes back to the project. Contributions must be submitted to the official repository and will be reviewed and incorporated at the discretion of the maintainers.\" However, the restrictions in Section 5 ban forking the code or distributing modified versions. This means that the standard Github \"fork the repo, make your changes in a branch, and send a pull request\" workflow for submitting changes would violate the license. reply tsukikage 3 hours agoparentOpen an issue and type your patch into the description. Note that you can't test or debug your patch, because that would mean creating a modified version of the codebase, which is prohibited. Just type that stuff straight in, directly from your fever dreams, unmediated by common practice. If it's good enough for the license, it's good enough for the code. reply cormorant 2 hours agorootparentNo, it says: \"You are granted the right to Modify the software for private use only. You may make, run, and propagate Covered works that you do not Convey, without conditions, so long as your License otherwise remains in force.\" It's clear they don't want you distributing modified versions. The thing people are getting caught up on is \"You may not create, maintain, or distribute a forked version of the software.\" They fail to define \"forked\" but they don't seem to have meant an undistributed modification. reply Novosell 4 hours agoparentprevThe Github ToS gives users the right to fork any public repos. reply wang_li 2 hours agorootparentOn Github. Doesn't give them a license to fork it to their workstation. reply otteromkram 1 hour agorootparentFork, then clone. Simple as. reply simoncion 1 hour agorootparentprevOne of the many bad things that Github did was to name the button that does the `git clone` action `Fork`. Like, I get why they did it, but (as we can see) it resulted in this stupid terminology confusion. reply bastardoperator 56 minutes agorootparentA fork is a linked copy, a clone is just a copy. They are not the same. Deleting your repository or changing its visibility affects that repository's forks. reply owaislone 1 hour agoparentprevI guess they mean \"fork\" in the broader Open Source sense when you fork something to create your own version of it and take it on a different path or do things differently like like NeoVim forked Vim. GitHub uses the term \"fork\" merely to create a copy of the repo for contributions. reply chrisfinazzo 4 hours agoparentprevAs @rollcat said, I suspect this means that people can contribute modifications, but that they cannot be distributed outside of the official sources. So, while you can send a patch to add a feature, you couldn't release that modified version on its own. reply amiga386 3 hours agorootparentDidn't lame do that for years? It was distributed as a patch you could apply to the patent-encumbered MPEG \"dist10\" reference source code (which as far as I can see, did not even have an explicit license, the distribution only includes disclaimers of warranty) reply chrisfinazzo 3 hours agorootparentNot sure... Someone smarter than me can answer that. reply thomastjeffery 4 hours agorootparentprevThat still contradicts the license as written. > No Forking: You may not create, maintain, or distribute a forked version of the software. There is no meaningful difference between the words \"patch\" and \"fork\"; and the act of creating an edited codebase is explicitly disallowed. If that isn't what they want, then they had better write more clearly. reply sramsay64 2 hours agorootparentThere is in other areas of copyright law, like romhacks and action replay codes. Romhacks seem like a very grey area but generally don't get DMCAed when they distribute large binary patch files of the original roms. And \"Lewis Galoob Toys, Inc. v. Nintendo of America, Inc.\" would imply that the dead simple 16 byte[0] \"patch files\" in the form of game genie codes are legal. To take a more practical example. Is there no meaningful difference between the dwm multimon patch files[1] and the full forked repo[2]? For context, lots of suckless software keeps extra features/addons in semi-offical out of tree patches files. The philosophy of suckless is generally to hardcode config options in source code and recompile instead of editing .rc files. This reduces the complexity of the code, so you end up with some very minimalistic easy to patch recompile and code. So it's a natural (if very esoteric) way of implementing plugins. Obviously this is a bit contrived because all the suckless code is actually open source, so none of this matters to them. But I think it's fair to say that distributing the 7 .patch files at [1] wouldn't count as distributing a forked version of dwm. The patch files contain some context lines ripped straight from the main codebase, but not the main repo. Hell I'd even wonder if there's some kind of fair use argument for patch files. After all, often they boil down to a criticism of the codebase, saying that it's bad because it contains all the lines of code starting with ' signs and really would be better if it had these extra lines of code after the '+' signs. The license doesn't seem contradictory to me. Counter-intuitive, unclear, and paradoxical (in the most general sense of the word), yes. But not contradictory. [0] Looks like the longest codes are 32 digits of hex long: https://archive.org/details/GameGenieSNESCodebookProgramming... [1] https://dwm.suckless.org/patches/multimon/ [2] https://github.com/garybgenett/.dwm reply chrisfinazzo 3 hours agorootparentprevEnglish is a stupid language ¯\\_(ツ)_/¯ reply thomastjeffery 3 hours agorootparentYou can't blame this one on English. Before the ambiguity of language can get in the way, there has to be a coherent idea that you want to express in the first place. This license explicitly contradicts itself. It says you are encouraged to contribute changes to the source, and you may not share changes to the source with anyone ever. reply hunter2_ 3 hours agorootparentIt seems like the intent is to encourage giving changes to exclusively the maintainer, and that forking in this context refers to distribution beyond a private communication between the change proposer and the maintainer. reply otteromkram 1 hour agorootparentprevNot really. Legalese is vague on purpose because not every situation can be rigidly defined. As for English, because of its plain nature, I have little trouble understanding someone who isn't proficient or who has a heavy accent, whereas languages with specific infections or tones might not have that kind of liberty. reply 0x0 4 hours agoparentprevI guess you could format a diff patch file locally and paste it as a text comment in an issue in their repo...? :P reply Spivak 4 hours agoparentprevBecause there are two definitions of fork. One is the button that says fork in Github which is really cloning the repo into your account. Then there is fork meaning \"fork the project\" which is actively developing and distributing an alternative lineage of the project, likely under a different name. You can use Github's PR workflow, it's fine. Github is the one with the unfortunate naming here that goes against the already established meaning of fork. It really should be clone. reply vel0city 3 hours agoparentprevYou don't need to fork a repo to create a branch. reply hunter2_ 3 hours agorootparentIf the permissions on the repo (in GitHub, not git) are such that you lack permission to create branches, then you must first clone (local git terminology) / fork (hosted on GitHub terminology) the repo so that all the permissions are yours. reply davidpfarrell 3 hours agoprevThe best thing we can do for the future of the project is to NOT engage with the project at this time ... Even just cloning the project into your private workspace to review / compile is giving more engagement than their current licensing stance warrants. I'll check again when an HN post comes out stating they've changed their licensing stance - Until then, closing this tab and forgetting about it ... reply lofaszvanitt 27 minutes agoprevThe only music player that wasn't annoying. Just did its job with a streamlined interface, without the clutter and clunky graphics that competitors thought was the way to go. reply abtinf 4 hours agoprevThey are either going to have to submit a ton of DMCA requests to GitHub and get their own repo taken down by GitHub, or they will be at risk of losing their copyright and will take it off GitHub themselves. Forking is a fundamental feature of GitHub. Forking policy may only be set on private repos, but this is a public repo. The license doesn’t permit forking. There are already 6 forks. Typically, copyright is not lost through selective enforcement (unlike trademark), but in this case the rights holder is making license violations both trivial and has full access to the list of violators. I suspect the courts will laugh them out of the room unless they vigorously defend their rights. In that case, I certainly wouldn’t want to deal with it if I was GitHub. It is a terrible user experience, where a user clicking one of the most popular buttons on the platform suddenly becomes a legal problem. reply thomastjeffery 3 hours agoparent> In that case, I certainly wouldn’t want to deal with it if I was GitHub. It is a terrible user experience, where a user clicking one of the most popular buttons on the platform suddenly becomes a legal problem. As others have mentioned, GitHub has already covered that with their ToS. All public repos may be forked. reply thefourthchime 3 hours agoprevI have a little history with Winamp. I wrote a popular plugin for it back in the day. This is the source code for Winamp 3, which is a total rewrite of winamp 2 in C++. In my opinion, it was overcomplicated and over-architected. The original source code by Justin Frankel in C. reply thedoctor_o 3 hours agoparentWhat has been \"provided\" is the stripped down 5.666 source bundle given to radionomy when sold on from AOL & the end result of their iterations up to the 5.9.2 release. So it's made up of the however many years of the 1.x -> 2.x -> 5.x development process & however many different people hacked upon it in that time (aka a mess). Yes there's a large part of winamp3 in there which was already long since open sourced properly in the aol era (unlike this heavily restricted licensing terms) but from what I remember when making the code deliverable the dedicated winamp3 repository was never provided (assuming my memory from 11yrs ago is still good). -dro reply jb1991 3 hours agoparentprevIs Frankel's original code anywhere? I do recall him saying once that he preferred C++ over C but used C++ as simply C with classes. Frankel is a hero of mine. reply mihaitodor 3 hours agorootparentI think there was a copy of it buried somewhere in the comments here: https://news.ycombinator.com/item?id=29379346 reply sionisrecur 2 hours agoprevFunny, the latest commit is \"Removing code which is not open\"[0], which means they are infringing on someone else's licensing terms by keeping it in the git history. [0] https://github.com/WinampDesktop/winamp/commit/0a4b7d32d0906... reply srockets 1 hour agoparentBased on https://github.com/WinampDesktop/winamp/issues/11 it's their own code, just a different service they didn't decide to release the source for. reply thedoctor_o 1 hour agorootparentllama group / \"winamp\" don't own shoutcast anymore as that was all sold off a year or so ago to azerion as part of changing audiovalley into llama group. -dro reply saylisteins 1 hour agorootparentlooks like both are under the same parent company Src: https://en.wikipedia.org/wiki/Radionomy#List_of_properties_f... reply thedoctor_o 59 minutes agorootparentThe history section just above the prior properties section is what's now the case with winamp & shoutcast under unrelated organisations nowadays. Though it's all a bit murky as radionomy & audiovalley were the same top people. -dro reply Asmod4n 1 hour agoprevIf you want a free copy of the SHOUTcast server software, they illegally share that code in their repo .. reply EMIRELADERO 39 minutes agoparentHere it is from a snapshot before removal: https://github.com/WinampDesktop/winamp/tree/3ab19235a69d96b... reply saylisteins 1 hour agoparentprevlooks like both are owned by a company called Radionomy src : https://en.wikipedia.org/wiki/Radionomy#List_of_properties_f... reply stonethrowaway 59 minutes agoparentprevHit that download button while it hasn’t been force-push cleared. reply nicholashead 3 hours agoprevI remember hanging out in #mpeg3 on EFNet many many years ago and becoming an acquaintance of Justin Frankel while he was working on this. I had made a skin and even a few tray icons for him to use in the app, and some of them are in here. I can't remember 100% which ones were mine, but the punchlabel one definitely was. My name is in the credits too: https://github.com/WinampDesktop/winamp/blob/0695744fd658c42... reply aantix 1 hour agoprevBack in the summer of 1999 while I was in college, we were the first house to use MP3's at our parties. Most houses used a CD disc shuffler which usually consisted of a bunch of scratched and smudged discs, so their music skipped all the time. We went all digital. We were ahead of our time. The parties were in the basement. We'd lock the computer up in a spare bedroom - ran the wires and speakers out to the main basement area. We used Winamp on shuffle. Hours of music without a single skip, without us having to babysit the music. Thank-you Winamp for the great memories. reply happyweasel 1 hour agoparent> Back in the summer of 1999 [..] > We went all digital. We were ahead of our time. Well I had a DAT recorder in 1993. Even a DAT walkman. reply comprev 2 hours agoprevThe source code itself appears to come from a cracked version [0] supplied by deadbeef\\ cracked by rOn\\ 32kb cool intro by lone\"; [0] https://github.com/WinampDesktop/winamp/blob/community/Src/W... Edit: Apparently it's an Easter Egg! Credit to bri3d for research reply bri3d 2 hours agoparentThis is a weird Easter Egg that's been compiled into real, genuine, uncracked Winamp release builds for a very long time. The actual compiled binary ends up with the same text you see linked there scrambled using XOR (you can see that on the other side of the #if 0) to avoid it appearing in the binary's strings verbatim. It's unfortunately hard to find stuff from the Old Internet anymore (I recall this being discussed at length on the original Winamp forums), but there are some references to it here: https://www.neowin.net/forum/topic/366648-winamp-51/page/2/#... There's a screenshot of the exact text from the source here: https://eeggs.com/items/45636.html And someone getting really confused about it on Reddit here: https://www.reddit.com/r/winamp/comments/caukeo/installed_wi... reply skandl 2 hours agoparentprevWeird, how does that even work? Does cracked mean its' been decompiled? It's strange because it includes other stuff like build scripts, etc that wouldn't be in released binaries.. reply benmmurphy 2 hours agoparentprevits probably an easter egg reply sionisrecur 2 hours agorootparentYes, by the cracker team not by the Winamp devs. reply thedoctor_o 1 hour agorootparentThose names were some of the original devs & they're the ones who put it in the easter egg on the about dialog that it relates to as a hacker-like joke. The source code is what aol sold on as a stripped down copy of 5.666 & then what radionomy/audiovalley/llama group iterated on afterwards. As much as I dislike what now calls itself \"winamp\", it's nothing nefarious & you can find old 2.x installs with that about easter egg text. -dro reply abetusk 3 hours agoprevA perversion of the term \"open\". The licensing terms do not allow redistribution or resale, which is a condition of \"open source\" (as it's commonly accepted). Note how the title nor the repository says \"open source\". I would have called this source available, not that \"the source is now open\". reply simoncion 1 hour agoparentThe license claims that it's a copyleft license... but it cannot be one with the distribution restrictions demanded by the license. I hope that they either remove the claim that it is a copyleft license, or relax the distribution restrictions to something like \"If you distribute modified versions of this Program, you may not call the modified versions Winamp.\". reply voidfunc 19 minutes agoprevBizarre license reeks of a company that doesn't know what to do with their own highly regarded software but is desperate for the community to give them free improvements that they can later monetize. reply qrush 4 hours agoprevThis really whips the llama's ass reply ChrisArchitect 4 hours agoprevFurther discussion about this \"opening up\" back in May: Winamp has announced that it is \"opening up\" its source code https://news.ycombinator.com/item?id=40383029 reply klaussilveira 4 hours agoprevI can't comprehend such a restrictive license on abandonware. And from the the looks of it, not very well written abandonware. reply npteljes 4 hours agoparentI was a huge fan of Winamp back in the day, but the way they handled the software completely soured me towards it. Winamp 3 was a clusterfuck, Winamp 5 was fine but felt like bloat, and then it was passed around like a hot potato, then abandoned on and off, and then the open sourcing feels like it was also around for quite some time. And now it's not even that, just a meager source-available. I know they don't owe me anything, but I feel disappointed. reply jb1991 3 hours agorootparentYou have to place some of the blame for latter Winamp versions on AOL who purchased Winamp from Frankel's team and messed with it so much he eventually resigned. reply deciplex 47 minutes agorootparentprevOne of the earlier examples of enshittification, before the process had been smoothed out and best practices established. reply f1shy 3 hours agoprevI was expecting to see some comment about the quality of the code. How clean (or not) it is. I was personaly hopping a much more ordered and clean codebase. reply opan 3 hours agoprevNot open source, not free software. Restrictions in license found here for those curious: https://github.com/WinampDesktop/winamp/blob/community/LICEN... reply grandpoobah 2 hours agoprevYou know what source code I'd like to see? ICQ and MSN and/or Windows Messenger. reply interestica 3 hours agoprevIt's 2024. Was Winamp2 + plugin system just peak audio playback software? reply Suppafly 2 hours agoparent>Was Winamp2 + plugin system just peak audio playback software? Yes. You can tell it was peak too because later versions got worse instead of better. reply yason 1 hour agoprevThis is the license equivalent of a specific automotive spare part for an old car where the dealer asks $1300 for it just to say they don't want to stock and sell those. \"Yeah, it's available, sure, but...you don't want it.\" reply stuaxo 1 hour agoprevFor anyone who wants to support a proper legacy I recommend backing the WACUP project. It's based on the winamp3 code, that Winamp did open source, and then the closed source parts are being re implemented. reply dfedbeef 2 hours agoprevFinally I can play MP3s on my desktop computer reply aflukasz 4 hours agoprev\"We take DirectX 9 SDK (June 2010) from Microsoft, modify it and pack to archive. Run unpack_microsoft_directx_sdk_2010.cmd to unpack it.\" Nice. Wonder how long will this version work? reply toast0 3 hours agoparentWindows executables mostly work forever. Especially if they were widely distributed. If Winamp is broken on Windows N+1, it's Windows that is broken. If Winamp is broken on Wine, it's Wine that is broken. reply AshamedCaptain 2 hours agorootparentMay have been true 20 years ago. But these days it is not hard to find a game which works in Wine but not Windows. And DirectX is often the reason. reply babypuncher 6 minutes agorootparentI think this is largely only true with Windows games from the '90s using still-nascent 3D apis. Many of these games were broken on modern versions of Windows by the time Vista came out. Once you get to the early '00s, you can still find a lot of games that are broken, but the culprit is usually changes in hardware and driver behavior rather than Windows itself. reply Sohcahtoa82 2 hours agorootparentprevYup. I have Master of Orion 2, which came out when DirectX was in version 1.0. It technically executes in Windows 10, but the graphics are glitchy. When they re-released it on Steam along with the MoO remake, they actually packaged the DOS version with DOSBox rather than release the Windows version. reply chrsw 3 hours agoparentprevI was surprised you're allowed to this. But I also haven't read the license. reply johndhi 1 hour agoprevSimply reading the word \"Winamp\" brings back a nostalgia for me almost like smelling the perfume of an old girlfriend. Spent so many hours looking at my custom Winamp skin and playing songs I'd downloaded from god-knows-where... reply thrashwerk 3 hours agoprevWhat a load of BS. This is just a poor attempt at open-source-washing. They rolled their own license but couldn't be bothered to read GitHub's ToS. \"collaborative\" license, \"opened to the community\", \"enabling the entire community to participate in its development\", \"global collaboration\" but you have to grant them perpetual rights and waive your own, you're not even allowed to fork lol. Seems like they're only looking for unpaid workers. reply metflex 1 hour agoprevIs there any chance or an already existing fork to build for apple silicon mac!? reply sunshadow 2 hours agoprevAccording to the license, this repo is not that different than me just extracting the source code from the binaries. Pass. reply Linkd 3 hours agoprevAre there any tools that can receive an entire code base like this, then analyze and answer questions about the code, structure, functionality? reply wppick 3 hours agoparentYa the one between your ears. Kidding! Maybe Sourcegraph Cody https://sourcegraph.com/cody, or possibly Github copilot. I think Cody might handle the multiple files better, and allows you to pick from multiple models. reply watt 2 hours agoparentprevapparently folks are making tools to do this: https://martinfowler.com/articles/legacy-modernization-gen-a... reply ing33k 1 hour agoparentprevCursor can do it. reply mihaitodor 3 hours agoprevWish they bothered to preserve the commit history... Can't imagine anything sensitive in there that they couldn't share. reply thedoctor_o 3 hours agoparentThat'd mean they'd have to do more work then necessary & there'd at most only ever be what went back to the stripped down 5.666 code deliverable they got after it was sold on from AOL at the start of 2014 (was looked into but determined not worth the hassle when that was being sorted out at the time). -dro reply mihaitodor 2 hours agorootparentI see... Fair enough. Thanks for the background! reply timvdalen 4 hours agoprevWhat happened here? Did someone buy the rights to the original Winamp? The linked site doesn't look very related to the original Winamp. reply stefanos82 4 hours agoparentHere you go https://about.winamp.com/press/article/winamp-open-source-co... reply justinclift 4 hours agorootparentOh great. Yet another bunch of people trying to claim their not-at-all-Open-Source custom license is actually Open Source. Hopefully one day they'll actually Open Source it. I mean, they're trying to pretend it is, so why not just do it properly? reply itslennysfault 4 hours agorootparentprevThanks for sharing. Wonder if they've ever heard of color contrast. Dark blue on dark blue is not very readable. Had to highlight the article to read it. reply stefanos82 24 minutes agorootparentCoincidentally, I thought it was this bug that bit you; it was reported a couple of days ago https://github.com/mui/material-ui/issues/43823 reply lucideer 4 hours agorootparentprevLooks like a bug in their light theme - it's using the dark theme's background. There's a theme toggle top-left to switch to the still-functioning dark theme. Guessing they probably started with a light theme then retrofitted a dark theme & rolled it out without realising it would regress the existing light theme. reply shrikant 4 hours agorootparentprevI'm not seeing that colour combination -- are you sure you don't have Dark Reader or some such add-on enabled..? reply reportgunner 3 hours agorootparentI also don't see the bugged light mode until I allow 3rd party scripts on the website in uBO reply gjvc 4 hours agoparentprevsee https://winamp.com/player/legacy or https://about.winamp.com/press/article/winamp-open-source-co... reply johnchristopher 3 hours agoprevWhich winamp is it ? Version 2 ? Version 3 with the wasabi (?) engine ? Or version 5 ? reply aeyes 2 hours agoparent5.9.2 https://github.com/WinampDesktop/winamp/blob/community/Src/W... reply JosephRedfern 3 hours agoprevThere is some pretty creative swearing throughout this codebase - very entertaining! reply anordal 1 hour agoparentI thought so, but that's what I came to the comment section to know ;-) reply lucideer 4 hours agoprev\"source code is open\" implies \"open source\", and the License refers to itself as a \"copyleft\" license, but it's a newly minted license - IANAL does anyone know if this is open source or another Elastic type situation? reply justinclift 3 hours agoparentIt's definitely not Open Source as it has pretty restrictive terms. :( reply zadler 1 hour agoprevLot of fun looking at an old battle worn codebase like this. reply zerkten 3 hours agoprevIs there an official announcement or something else that accompanied this? I don't know the current state of their organization and the chain of ownership for the code. reply factorialboy 3 hours agoprevF yeahhhhh ... the player that never crashed, even if Windows OS crashed all around it This is more significant (to me) than the iPhone 16 launch, I'll pay for people who can port this to Linux (Gnome) and Mac OS. reply mdaniel 1 hour agoparentBarring the ton of licensing stupidity ongoing (maybe they'll fix it, who knows), as far as I know you could actually do that by forking the repo and then connecting your fork to bountysource. Open an issue for each target OS, set the amounts, and then publicize that fact on as many social media channels as you have access to However, I wanted to draw your attention to \"are you asking the right question\" because there's a very real chance that the things you actually love about Winamp would not carry over to any such ports, since it's not \"recompile and get the Winamp on Windows experience\" - they would be Gnome and macOS apps, behaving similar to other such apps reply elpocko 1 hour agorootparentBountysource is long dead. reply 29athrowaway 3 hours agoprevThere is an open source clone of Winamp called XMMS. Sonique and Foobar2000 were also venerable players of that era. reply the__alchemist 1 hour agoparentI still use Foobar. Ideal/timeless software. reply jollyllama 4 hours agoprevAwesome, that's far more interesting than the new implementation, which doesn't include the batch media transcoding for exports to mp3 players. reply ilrwbwrkhv 3 hours agoprevOne of the best pieces of software ever made. Will devour its code. Hopefully new startups like Slack can learn from it too. reply papruapap 4 hours agoprevman, at first glance doesnt look like a lot of work to add support to linux. reply racked 40 minutes agoparentCare to elaborate on how you can see that? Eager to learn reply apricot 3 hours agoparentprevDoes Linux really need another media player? reply ginko 2 hours agorootparentIt certainly needs Winamp. reply momentsinabox 2 hours agoprevHaven't thought about converting FLAC files to mp3 in a while. Hell yeah Winamp reply theandrewbailey 17 minutes agoparentWhy convert? Winamp plays FLAC natively. reply prmoustache 2 hours agoprevCan't we just let it die? reply rollcat 4 hours agoprevEh, here we go again, there's yet-another custom license, \"Winamp Collaborative License (WCL) Version 1.0\". Quick skim: > No Distribution of Modified Versions: You may not distribute modified versions of the software, whether in source or binary form. > No Forking: You may not create, maintain, or distribute a forked version of the software. It's basically \"look but do not touch\". I don't see why this was necessary for something that's basically abandonware by now, and is mostly of historical interest. reply jjordan 4 hours agoparentLawyers. reply gjvc 4 hours agoprevsee also see https://winamp.com/player/legacy and https://about.winamp.com/press/article/winamp-open-source-co... reply bityard 4 hours agoparentThe second link is a 404 reply mikestew 3 hours agorootparentProbably this one: https://winamp.com/press/winamp-open-source-code reply gjvc 3 hours agorootparentprevfixed reply scblock 4 hours agoprevSource-available but certainly not open source. \"You are granted the right to view, access, and study the source code of the software. You are granted the right to Modify the software for private use only.\" \"No Distribution of Modified Versions: You may not distribute modified versions of the software, whether in source or binary form.\" \"No Forking: You may not create, maintain, or distribute a forked version of the software.\" reply dncornholio 4 hours agoparentNobody said anything about open source reply npteljes 4 hours agorootparentTitle is \"Winamp Legacy player source code is now open\". The usage of the word \"open\" in conjunction \"source code\" alludes to the long established \"open source code\" phrase, which implies a set of licenses, and the associated open source culture. A better choice for the title would have been \"Winamp Legacy player source code is now available\". reply dncornholio 3 hours agorootparentI agree but my statement still holds true. When something doesn't explicitly say \"Open Source\", it's not Open Source. This is a very old trick that i've learned decades ago.. reply RIMR 10 minutes agorootparentWell, the description in the Repo says this: >its source code was opened to the community I find it hard to believe that any serious person would argue that \"code that is open to the community\" ≠ \"open source code\". I think it's realistic to assume that the developers who wrote the README, and the lawyers who wrote the license didn't talk to each other much when making decisions about how much freedom users were going to have with the code. reply blue_cadet_3 3 hours agorootparentprevTheir official blog post does https://winamp.com/press/winamp-open-source-code reply dncornholio 3 hours agorootparentIt does not. It open-source only in it's URL which has no semantic value if you read the article. reply deathanatos 1 hour agorootparentAnd the license itself states, > The [license] is a free, copyleft license And then proceeds to not be a free, copyleft license. This pretty clearly seems like they're trying to squat on the terms \"copyleft\" \"free software\" and \"open source\" while weasel-wording their way out of it — \"open washing\", as someone else in the comments called it, seems to fit. This smacks of someone who wants to use the words, and to have you feel like they've used the words, but without having to actually do the things the words would mean, spoken genuinely. reply RIMR 8 minutes agorootparentContract law doesn't really allow for this kind of behavior. If you say over and over again that your software is open source and the community is free to develop with it as they please, and then write your license to say the opposite, you're going to have a hard time enforcing the license given that you're actively telling people to violate the terms in your press release. reply airhangerf15 1 hour agorootparentprevIt's still misleading and they're obviously trying to imply marketing value that doesn't exist. reply ryandrake 4 hours agorootparentprevYea this is just a case of a bad HN title. The source is clearly not open, even if though it is released. EDIT: looks like the title’s been corrected! reply blue_cadet_3 3 hours agorootparentThey say the same thing in their blog post announcing it. https://winamp.com/press/winamp-open-source-code reply bityard 4 hours agorootparentprevThe HN headline did reply Dalewyn 3 hours agoparentprevIf I can read the code, it's open source. What you're complaining about is free source code, which this probably is not. reply synergy20 2 hours agoprev [–] sorry but why does old winamp code still matter? there are plenty open source audio libraries these days along with different open source players. reply airhangerf15 1 hour agoparentIt's still one of the best simple media players (sadly). If it had better HiDPI support, it'd still be my go to on Windows (if I still used Windows). I wonder if anyone there still has the source to the failed Linux Alpha. It crashed all the time, but it did exist, for a very short while. reply acuozzo 1 hour agoparentprev [–] It's a fun diversion to browse around old codebases, especially those of software you once used extensively. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Winamp, a multimedia player launched in 1997, is now open-source, allowing the community to modernize its code.",
      "Building the Winamp desktop client requires Visual Studio 2019 and Intel IPP v6.1.1.035, with two main build options: using a script or within the Visual Studio IDE.",
      "Dependencies include libvpx, libmpg123, OpenSSL, DirectX 9 SDK, Microsoft ATLMFC lib fix, and Intel IPP, each requiring specific modifications and unpacking steps."
    ],
    "commentSummary": [
      "Winamp Legacy player source code has been released on GitHub with restrictions, including no distribution of modified versions, no forking, and only official maintainers can distribute modifications.",
      "These restrictions conflict with GitHub's Terms of Service, which permits forking of public repositories, leading to debates about the interpretation of \"forking.\"",
      "The release is considered \"source available\" rather than truly open source, resulting in mixed reactions from the tech community."
    ],
    "points": 453,
    "commentCount": 204,
    "retryCount": 0,
    "time": 1727188029
  },
  {
    "id": 41630913,
    "title": "We fine-tuned Llama 405B on AMD GPUs",
    "originLink": "https://publish.obsidian.md/felafax/pages/Tune+Llama3+405B+on+AMD+MI300x+(our+journey)",
    "originBody": "Hey HN, we recently fine-tuned the llama3.1 405B model on 8xAMD MI300x GPUs using JAX instead of PyTorch. JAX&#x27;s advanced sharding APIs allowed us to achieve great performance. Check out our blog post to learn about the cool sharding tricks we used. We&#x27;ve also open-sourced the code: https:&#x2F;&#x2F;github.com&#x2F;felafax&#x2F;felafaxWe&#x27;re a small startup building AI infra for fine-tuning and serving LLMs on non-NVIDIA hardware (TPUs, AMD, Trainium).Problem: Many companies are trying to get PyTorch working on AMD GPUs, but we believe this is a treacherous path. PyTorch is deeply intertwined with the NVIDIA ecosystem in a lot of ways (e.g., `torch.cuda` or scaled_dot_product_attention is an NVIDIA CUDA kernel exposed as a PyTorch function). So, to get PyTorch code running on non-NVIDIA hardware, there&#x27;s a lot of \"de-NVIDIAfying\" that needs to be done.Solution: We believe JAX is a better fit for non-NVIDIA hardware. In JAX, ML model code compiles to hardware-independent HLO graphs, which are then optimized by the XLA compiler before hardware-specific optimization. This clean separation allowed us to run the same LLaMA3 JAX code both on Google TPUs and AMD GPUs with no changes.Our strategy as a company is to invest upfront in porting models to JAX, then leverage its framework and XLA kernels to extract maximum performance from non-NVIDIA backends. This is why we first ported Llama 3.1 from PyTorch to JAX, and now the same JAX model works great on TPUs and runs perfectly on AMD GPUs.We&#x27;d love to hear your thoughts on our vision and repo!",
    "commentLink": "https://news.ycombinator.com/item?id=41630913",
    "commentBody": "We fine-tuned Llama 405B on AMD GPUs (publish.obsidian.md)434 points by felarof 21 hours agohidepastfavorite85 comments felarof 20 hours agoHey HN, we recently fine-tuned the llama3.1 405B model on 8xAMD MI300x GPUs using JAX instead of PyTorch. JAX's advanced sharding APIs allowed us to achieve great performance. Check out our blog post to learn about the cool sharding tricks we used. We've also open-sourced the code: https://github.com/felafax/felafax We're a small startup building AI infra for fine-tuning and serving LLMs on non-NVIDIA hardware (TPUs, AMD, Trainium). Problem: Many companies are trying to get PyTorch working on AMD GPUs, but we believe this is a treacherous path. PyTorch is deeply intertwined with the NVIDIA ecosystem in a lot of ways (e.g., `torch.cuda` or scaled_dot_product_attention is an NVIDIA CUDA kernel exposed as a PyTorch function). So, to get PyTorch code running on non-NVIDIA hardware, there's a lot of \"de-NVIDIAfying\" that needs to be done. Solution: We believe JAX is a better fit for non-NVIDIA hardware. In JAX, ML model code compiles to hardware-independent HLO graphs, which are then optimized by the XLA compiler before hardware-specific optimization. This clean separation allowed us to run the same LLaMA3 JAX code both on Google TPUs and AMD GPUs with no changes. Our strategy as a company is to invest upfront in porting models to JAX, then leverage its framework and XLA kernels to extract maximum performance from non-NVIDIA backends. This is why we first ported Llama 3.1 from PyTorch to JAX, and now the same JAX model works great on TPUs and runs perfectly on AMD GPUs. We'd love to hear your thoughts on our vision and repo! reply ipsum2 18 hours agoparentI, and several others, had no problem running on PyTorch on AMD GPUs, with no code changes from CUDA. Check out MosaicML's blog posts: https://www.databricks.com/blog/training-llms-scale-amd-mi25... reply mistymountains 17 hours agorootparentAgain, the problem is custom kernels in CUDA. It’s not straightforward for many applications (LLMs are probably the most straightforward). reply felarof 18 hours agorootparentprevAhh, interesting, will take a look! Curious what are the steps to run PyTorch on AMD (does it work out-of-box with PyTorch+rocm docker image)? Does torch.compile work smoothly? reply lhl 11 hours agorootparentWhile your project is neat and I'd like to see how the performance compares, for LLM training, PyTorch, including torch.compile works completely OOTB on AMD. All you have to do is pip install the ROCm version of PyTorch (or run the docker image) and it's seamless (the ROCm version just treats torch.cuda as calling ROCm). I've used axolotl (trl/accelerate based), torchtune, and LLaMA-Factory, which are all PyTorch-based without any issues for training. reply anthonix1 18 hours agorootparentprevYeah I would suggest taking a look at PyTorch on AMD before saying stuff like \"scaled_dot_product_attention is an NVIDIA CUDA kernel exposed as a PyTorch function\", because that is demonstrably false. Also, FWIW, I would suggest getting a small Llama 3.1 model training fast before trying to do a big 405B model -- faster to iterate and almost everything you'll learn on the small models will scale to the 405B. reply felarof 17 hours agorootparentThanks for the feedback! I appreciate you pointing that out. My understanding was based on the PyTorch documentation for scaled_dot_product_attention (https://pytorch.org/docs/stable/generated/torch.nn.functiona...). - \"The function may call optimized kernels for improved performance when using the CUDA backend. For all other backends, the PyTorch implementation will be used.\" And was trying to make a broader point about the lack of transparency (in performance, lower-level impl) in PyTorch when running on NVIDIA vs. non-NVIDIA hardware. reply chillee 10 hours agorootparent> And was trying to make a broader point about the lack of transparency (in performance, lower-level impl) in PyTorch when running on NVIDIA vs. non-NVIDIA hardware. I don't quite understand this argument. Lack of transparency from running PyTorch so instead we're gonna leave it all to XLA? How does this solve the \"transparency\" issue? reply anthonix1 16 hours agorootparentprevI just asked an instance of Hermes 3 Llama 3.1 405B running on AMD GPUs: \"does pytorch scaled dot product attention run on AMD GPUs?\": \"Yes, PyTorch's scaled dot product attention can run on AMD GPUs. PyTorch supports AMD GPUs through the ROCm (Radeon Open Compute) platform. To use PyTorch with an AMD GPU, you need to install the ROCm version of PyTorch, which is specifically built for AMD GPUs [...]\" And it proceeded to give the steps to follow to install and run, with example Python code to demonstrate it. One slight nitpick is that it referred to an older URL with the --index-url to install torch with pip, but otherwise it was correct. reply unlikelymordant 12 hours agorootparentare you at all confident that this isn't hallucinated? I'd never trust an answer like this from an LLM reply WithinReason 12 hours agorootparentprevDid you verify everything else it said is true? reply germanjoey 19 hours agoparentprevHow are you verifying accuracy for your JAX port of Llama 3.1? IMHO, the main reason to use pytorch is actually that the original model used pytorch. What can seem to be identical logic between different model versions may actually cause model drift when infinitesimal floating point errors accumulate due to the huge scale of the data. My experience is that debugging an accuracy mismatches like this in a big model is a torturous ordeal beyond the 10th circle of hell. reply felarof 16 hours agorootparentGood question. We used a new AI+math-based testing tool (benchify.com) to run comparison tests, but we are working on building more robust infrastructure for this. Translating models from PyTorch to JAX is core to our strategy. That said, this path is not uncommon (translating from one framework to another). HuggingFace translates Google's Gemma family models from JAX to PyTorch, and a ton of people use it. reply credit_guy 18 hours agorootparentprevWhen you say \"model versions\", do you mean different quantizations of the model? Then it's not floating point errors that accumulate. Different quantizations of the model are different models. People will call such a model something like Meta-Llama-3.1-8B-Instruct--q4_0, claiming that it's just a \"version\" of the Meta-Llama-3.1-8B-Instruct. But it's just a lie. It's not the same model, and you should not expect the same results. There is no reason to debug the differences, what exactly would you expect to find, and what action would you envision to take once you find what you are looking for? However, is the quantized version still a useful LLM? Absolutely. Most people don't have an A100 to run the original model, so a quantized version is better than nothing. reply srcreigh 19 hours agorootparentprevVery fascinating, can you explain more about a time when this happened? Like what area was affected by fp errors, why were they introduced (was it like refactoring of pytorch code?), how was this determined to be the cause? reply anthonix1 18 hours agoparentprevDoes JAX have its own implementations of matmul, flash attention etc? Or does it use the ROCm implementations like PyTorch does? (e.g,. hipblaslt, Composable Kernel FA etc) Not too familiar with JAX, but the abysmal PyTorch training perf on MI300x is in large part attributable to the slow perf of the ROCm libraries it is using under the hood. reply jdeaton 2 hours agorootparentJAX has a sub-system called Pallas[1] with a Triton-like programming model and an example implementation of Flash Attention [2]. It is quite fast. On TPUs I've heard that the XLA compiler already emits a flash-attention-like computation graph for a regular JAX implementation of attention so there's no need to have some specialized kernel in that case. 1. https://jax.readthedocs.io/en/latest/pallas/index.html 2. https://github.com/jax-ml/jax/blob/main/jax/experimental/pal... reply llm_trw 19 hours agoparentprevDoes this work on the consumer grade cards like the 7090 XTX? And by work I don't mean: spend two weeks trying to get the drivers set up and never update the server again. reply lhl 11 hours agorootparentA couple months ago I did some testing on some consumer cards. [1] I think you should be able to use torchtune or axolotl without anything besides installing the ROCm version of PyTorch. [1] https://wandb.ai/augmxnt/train-bench/reports/Trainer-perform... reply tommiegannert 3 hours agorootparentAm I reading that right that the 7900 XTX is on a par with 3090, and 4090 is twice as fast? reply lhl 1 hour agorootparentYeah, those numbers are correct as of their testing (in June) although people who are really interested should check out the linked repo and do their own runs as software/optimizations have continued to change a lot and the RDNA3 side has a lot of untapped potential. Eg, the 7900 XTX has a huge theoretical FLOPS advantage over the 3090 but the results totally don't reflect that. One example of this hobbling is that RDNA3 only recently got backpass FA via a still under-optimized aotriton implementation: https://github.com/ROCm/aotriton/pull/39 There are also still ongoing optimizations on the Nvidia side as well. In the beginning of the year the 7900 XTX and 3090 were pretty close on llama.cpp inference performance, but a few months ago llama.cpp got CUDA graph and FA support implemented that boosted perf significantly for both my 3090 and 4090. (For AI/ML, a used 3090 remains I think the best bang/buck for both inference and small training runs. You can pay twice as much for the twice as fast 4090, but at the end of the day you'll still wish you had more VRAM, so it's hard to really recommend unless you're going to use mixed precision. The RDNA3 cards are not as bad to work with as the Internet would have you believe, but they'd have to be a lot cheaper if your main use case was AI/ML for both the PITA factor and just from pure real-world performance.) reply woodrowbarlow 4 hours agorootparentprevi've been running inference on the 7900xtx using pytorch and rocm (installed directly from package managers, no manual fiddling) with great performance. no problem running the full flux1.dev model, for instance. haven't looked at training or fine-tuning yet. reply cameron_b 19 hours agoparentprevI'm glad to see a full implementation on AMD hardware. I'm not familiar with JAX, but the idea of providing an abstraction layer to more easily get to work on what hardware is available seems really valuable. Bringing back some competitiveness to the ecosystem will be a big win for workload mobility. I suspect that price/performance across implementations will be highly dependent on contract details, but do you intend to publish some comparisons in the future? reply anthonix1 18 hours agoparentprevAny direct comparisons to 8xH100? 2 toks/sec seems very slow! I haven't done any LoRA training on MI300x myself, but I have done LLama 3.1 full training on 8xMI300x and got pretty close to 8xH100 performance with my own kernels (ROCm is just too slow). reply felarof 16 hours agorootparentOops, my calculation was wrong. Let me add an edit to the blog, thanks for pointing it out! My train step was taking 30s. And I was using a batch size of 16 and seq length of 64, making the training speed as (16*64/30) tokens per sec == 35 tokens per second (for fine-tuning in JAX eager mode). (I haven't done comparison with 8XH100) reply gdiamos 12 hours agorootparentThat’s approximately 0.8% MFU - h100 would get more like 30% or 40% MFU if well tuned 405e9 parameters 2 flops per matrix multiply per parameter 3 matrix multiplies for (forward, backward param, and backward activation) passes batch size 16 seq length 64 1.3 petaflops per second per GPU in bfloat16 8 GPUs 30 seconds So that’s 0.8% = (405e9 * 2 * 3 * 16 * 64 / 30) / (1.3e15 * 8) Note that I’m ignoring the attention flops in this simplified calculation, but they would be a second order effect at this sequence length Also note that I’m assuming full weight training, not LoRA . The result would be lower MFU if using LoRA These MI300X results are promising functionally (it's tough to get any model this big running) but they have a long way to go on perf. It's also single node. The biggest issues I've seen on MI300X are related to scaling to multiple nodes. EDIT: The blog seems to indicate it is using LoRA. So we should remove the backward param pass from the equation above. Backward param only applies to adaptor weights, which are much more than 10x smaller, so we set it to 0 in the approximation. So we get 0.53% = (405e9 * 2 * 2 * 16 * 64 / 30) / (1.3e15 * 8) reply heyoni 11 hours agorootparentIf I feed your reply to an llm will it be able to tell me what you’re talking about? /edit I think it did alright… reply gdiamos 11 hours agorootparentI tried with Llama 3.1 and it hallucinated MFU. It also completely misinterpreted multi-node scaling. ========================================================== Let's break down the results described in the post. Context: The post is discussing the performance of a large language model on a MI300X GPU, which is a high-performance computing (HPC) system. The model has approximately 405 billion parameters and is trained using a batch size of 16 and sequence length of 64. Key metrics: MFU (Million Floating-Point Operations per Second): This is a measure of the model's performance, specifically the number of floating-point operations (FLOPs) it can perform per second. FLOPs: The number of floating-point operations required to perform a matrix multiplication, which is a fundamental operation in deep learning. GPU performance: The MI300X GPU is capable of 1.3 petaflops (1.3 x 10^15 FLOPs) per second in bfloat16 (a 16-bit floating-point format). Calculations: The author provides two calculations to estimate the MFU of the model: Initial calculation: Assuming full weight training (not LoRA), the author estimates the MFU as: 405 billion parameters 2 FLOPs per matrix multiply per parameter 3 matrix multiplies (forward, backward parameter, and backward activation) Batch size 16 Sequence length 64 30 seconds to complete the calculation 1.3 petaflops per second per GPU 8 GPUs The calculation yields an MFU of approximately 0.8%. Revised calculation: After correcting the assumption to use LoRA (a technique that reduces the number of FLOPs), the author revises the calculation by removing the backward parameter pass, which is only applied to adaptor weights (much smaller than the main weights). This yields an MFU of approximately 0.53%. Interpretation: The results indicate that the MI300X GPU is not yet optimized for this large language model, with an MFU of only 0.53% (or 0.8% in the initial calculation). This is a relatively low performance compared to the theoretical maximum of 1.3 petaflops per second per GPU. The author notes that the biggest issues are related to scaling to multiple nodes, suggesting that the performance may improve when running on a larger cluster. The revised calculation using LoRA reduces the MFU by about 33%, indicating that using this technique can lead to a more efficient use of the GPU resources. ========================================================== MFU means model flops utilitization. it is a measure of efficiency from 0% to 100% . 100% means that the model is running at maximum possible efficiency, i.e. 1.3 petaflops per gpu. ========================================================== In that case, the results indicate that the MI300X GPU is running the large language model at a relatively low efficiency, with an MFU of 0.53% (or 0.8% in the initial calculation). This means that the model is only utilizing a tiny fraction of the GPU's maximum theoretical performance of 1.3 petaflops per second. In other words, the model is not fully utilizing the GPU's capabilities, and there is a significant amount of headroom for optimization. To put this into perspective, an MFU of 100% would mean that the model is running at the maximum possible efficiency, using 1.3 petaflops per second per GPU. An MFU of 0.53% or 0.8% is extremely low, indicating that the model is running at a tiny fraction of its potential performance. The author's comment that the MI300X results are \"promising functionally\" suggests that the model is able to run, but the low MFU indicates that there are significant opportunities for optimization and performance improvement. reply heyoni 10 hours agorootparentMFU being maximal floating point utilization right? I used chatgpt 4o and it otherwise looks very similar to your llama result reply YetAnotherNick 11 hours agorootparentprev> The blog seems to indicate it is using LoRA. So we should remove the backward param pass from the equation above. Backward param only applies to adaptor weights Backward pass still runs on the non adapter weights. But yeah 10 TFlops/GPU specially on tiny sequence size is very bad compared to what you can get on Nvidia. And I believe the difference would be even higher with large sequence length. reply gdiamos 11 hours agorootparentbackward activations does but typically not backwards weight gradients. Why compute gradients with regards to weights that aren't going to be updated? reply ewalk153 6 hours agoparentprevDo you see tinygrad as a useful lower level abstraction or is JAX sufficient to get pref out of AMD GPUs? reply upbeat_general 10 hours agoparentprevscaled_dot_product_attention isn’t CUDA specific, it even works on TPUs. reply jgalt212 20 hours agoparentprevIs there some cost rule of thumb to compare Nvidia, AMD, and Google TPU? reply felarof 18 hours agorootparentGood question. No good metric give performance depends on software stack (JAX vs PyTorch) + optimizations. But my take performance per dollar of TPU > AMD > NVIDIA. reply CuriouslyC 19 hours agorootparentprevTPUs are slow but efficient and AMD has bugs but for some things works quite well. Nvidia is obviously the gold standard. reply felarof 18 hours agorootparentHaha, TPUs are not slow :) All of Google's training (including Gemini models) is done on TPUs. There are good 1p [a] and 3p [b] benchmarks comparing TPUs vs NVIDIA GPUs. [a] - https://github.com/GoogleCloudPlatform/vertex-ai-samples/blo... [b] - https://arxiv.org/pdf/2309.07181 reply ngcc_hk 20 hours agoparentprevGiven it is a migration, is there actual comparison of the same model on PyTorch vs your version. The comparison table there seems to be on technical side. Also any technical issues encountered? reply felarof 16 hours agorootparentWe have a few technical issues that we still need to address: 1) This entire fine-tuning run was done in JAX eager mode. I kept running out of memory (OOM) when trying to `jax.jit` the entire training step. Even gradual `jax.jit` didn't work. 2) The current version doesn't have gradient accumulation, and with a batch size of just 16, that’s not ideal. I'm working on implementing gradient accumulation next. 3) We still haven't found a good way to load large sequence-length data (like 32k sequence length). Currently, before sharding the training batch across GPUs, it ends up loading the entire batch onto a single GPU’s VRAM and causes OOM issues. reply logicchains 11 hours agorootparent> I kept running out of memory (OOM) when trying to `jax.jit` the entire training step. Even gradual `jax.jit` didn't work. Were you using activation checkpointing? https://jax.readthedocs.io/en/latest/_autosummary/jax.checkp... is very important for keeping memory usage reasonable when training large models. reply logicchains 11 hours agoparentprevDid you consider using https://github.com/AI-Hypercomputer/maxtext ? It has a Jax llama implementation, and gets decent MFU on TPU and GPU (I've only tried it on NVidia GPU, not AMD). reply lostmsu 4 hours agorootparentCould you share performance so we could compare? reply chillee 10 hours agoprevTo be clear, this performance is quite bad (presumably because you didn't manage to get compilation working). You're getting 35 tokens/s for a 405B model, which comes out to about 85 Teraflops. 8 MI300x GPUs comes out to 10.4 Petaflops, so you're getting about 0.8% MFU (which is about 40-50x worse than decent training performance of 30-40% MFU). For AMD's sake, I hope that it's your software stack that's limiting perf. reply jamalaramala 8 hours agoparentThat's exactly what I wanted to ask: Their github page claims that it is possible to \"tune LLaMa3.1 on Google Cloud TPUs for 30% lower cost\", but they don't mention performance. reply 3abiton 20 hours agoprevFirstly great work! I dabbled with AMD GPUs and ROCm support a year ago, and it was obvious AMD still a long way from catch ling up with Nvidia. While opting for JAX is in an interesting approach, what were the challenges for you deviating from pytorch (being the standard library for ML)? reply felarof 18 hours agoparentA few weeks ago, I did a Show HN explaining our journey: https://news.ycombinator.com/item?id=41512142. We initially started with the goal of fine-tuning LLaMA 3 on TPUs, but PyTorch XLA was clunky, so we decided to rewrite the model in JAX. That said, as mentioned earlier in the thread, we also believe JAX is a better platform for non-NVIDIA GPUs and want to build on JAX+openXLA for building infra for non-NVIDIA GPUs. reply 6y56h56 20 hours agoparentprevI cannot get AMD ROCm running on my debian 12 system which is what I think is causing Ollama to use CPU instead of GPU. So I guess there is still a long way to go. reply jchw 18 hours agorootparentAt the risk of pissing people off, I think you may be better served by a distribution that provides a more up-to-date kernel. Debian 12 will give you Linux 6.1 LTS, which is probably OK if you're using an older Radeon card, but I've heard support for the 7900 XT/X series is a bit dicey and beyond that (e.g. Radeon 890M) non-existent. If there were improvements on the AMDGPU DRM driver side, you would not see them in Debian any time soon, as the 6.1 LTS kernel will be stuck with roughly whatever shipped January of last year. This is just a shortcoming in the Linux kernel, due to its lack of any kind of stable ABI for drivers. Of course it is possible this would help nothing or even hurt. My experience running stable (or even newer) kernels has been quite good, though. I run stable or newer across a few devices and run into hiccups not more than once every few years, which is definitely worth it to be able to get new driver improvements years in advance. (FWIW Debian is not even supported by ROCm[1]... although distros with even older kernels are. But, even if ROCm works, I can't imagine you will get ideal hardware support when running older kernels. I am not sure if ROCm has some workaround for enterprise Linux distributions specifically, but it feels like they must, given how many of their customers in the datacenter are likely to want to use them.) [1]: https://rocm.docs.amd.com/en/latest/compatibility/compatibil... reply slavik81 14 hours agorootparent> I've heard support for the 7900 XT/X series is a bit dicey The firmware-amd-graphics package in stable is too old to properly support RDNA 3. It kind of works, but it is quite buggy. All RDNA 3 users on Debian 12 should be sure to install the kernel and firmware from bookworm-backports. There is full support for RDNA 3 hardware enabled on Debian Testing (both in the drivers and runtime libraries). The Debian ROCm Team intended to backport all the ROCm packages from Testing into Bookworm, but have been held up as LLVM 17 is not available in bookworm-backports (yet?). > FWIW Debian is not even supported by ROCm ROCm does not support Debian, but Debian supports ROCm. Most of the libraries that comprise ROCm have been directly packaged by the distribution. reply JonChesterfield 9 hours agorootparentprevROCm versions are fairly closely tied to kernel versions. Debian 12 should run fine with the ROCm that was released around the time of whatever kernel you're running, but it's going to be a bad experience mixing the latest ROCm with an elderly kernel or vice versa. Old kernel + old kernel driver + new rocm => the driver doesn't really know what the userspace is doing and you get the bugs which have been fixed since Old kernel + new kernel driver => very ymmv, the internel kernel api is not stable New kernel + matching driver, old rocm is probably OK, unless you're using upstream clang in which case it's all bad once more ROCm was designed and implemented in the HPC environment, where you know the exact kernel in use and the whole stack is deployed as one self consistent lump. Driver, compiler, libraries and so forth. It's not having such a good time in the Linux world of mix and match because the aggressive internal testing structure assumes you're using a consistent system. Backwards/forwards ABI and API compatibility is difficult, expensive and slow so it's not where the money is being spent. Rightly so, probably. reply ants_everywhere 20 hours agorootparentprevI've had more luck with the ROCm docker container. I run it via k8s. It was pretty painless to set up and has been mostly painless since. Prior to that it was nearly impossible to get Jax running reliably on ROCm. Even with the container, you have to be careful installing Python libraries because they can still break things. reply lenova 19 hours agorootparentI just recently went down the AMD GPU + ROCm rabbit hole as well. ROCm 6.2 was just released in August of this year and introduces a lot better support, though as the above poster mentioned, isn't merged into most recent OSes. This Github repo is good for tracking the latest Ubuntu + ROCm install process: https://github.com/nktice/AMD-AI reply latchkey 16 hours agorootparentThat's a nice repo of random installation notes. Very helpful, thanks! reply llm_trw 17 hours agorootparentprevLike everything in machine learning it only really runs on Ubuntu 22.04. Anything else is unsupported and you need to spend weeks tinkering to get it to work, then never upgrade. reply superkuh 19 hours agorootparentprevYou'd probably have a lot better luck using Vulkan acceleration (not ROCm) of llama.cpp as backend to ollama. It is incomparibly easier to set up and maintain compared to ROCm. You can actually do it on your computer's normal OS instead of inside a bunch of container/vms where the system libs are entirely customized to running just that one application. AMD's support of consumer cards is very, very short. By the time it's stable enough for a new card to run the card is no longer supported. In 2021 I bought an AMD GPU that came out 3 years before and 1 year after I bought it (4 years since release) they dropped ROCm support. reply coppsilgold 14 hours agorootparentROCm is not even worth the effort for inference workloads. Vulkan is much more convenient and performs fine. llama.cpp and stable-diffusion.cpp offer Vulkan backends but generally you can run most models on Vulkan if you use IREE[1]. [1]reply lhl 11 hours agorootparentWhile Vulkan can be a good fallback, for LLM inference at least, the performance difference is not as insignificant as you believe. I just ran a test on the latest pull just to make sure this is still the case on llama.cpp HEAD, but text generation is +44% faster and prompt processing is +202% (~3X) faster with ROCm vs Vulkan. Note: if you're building llama.cpp, all you have to do is swap GGML_HIPBLAS=1 and GGML_VULKAN=1 so the extra effort is just installing ROCm? (vs the Vulkan devtools) ROCm: CUDA_VISIBLE_DEVICES=1 ./llama-bench -m /models/gguf/llama-2-7b.Q4_0.gguf ggml_cuda_init: GGML_CUDA_FORCE_MMQ: no ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no ggml_cuda_init: found 1 ROCm devices: Device 0: Radeon RX 7900 XTX, compute capability 11.0, VMM: nomodelsizeparamsbackendngltestt/s| ---------------------------------------:---------:------------:------------:-------------------:| llama 7B Q4_03.56 GiB6.74 BROCm99pp5123258.67 ± 29.23| llama 7B Q4_03.56 GiB6.74 BROCm99tg128103.31 ± 0.03build: 31ac5834 (3818) Vulkan: GGML_VK_VISIBLE_DEVICES=1 ./llama-bench -m /models/gguf/llama-2-7b.Q4_0.ggufmodelsizeparamsbackendngltestt/s| ---------------------------------------:---------:------------:------------:-------------------:ggml_vulkan: Found 1 Vulkan devices: Vulkan0: Radeon RX 7900 XTX (RADV NAVI31) (radv)uma: 0fp16: 1warp size: 64llama 7B Q4_03.56 GiB6.74 BVulkan99pp5121077.49 ± 2.00| llama 7B Q4_03.56 GiB6.74 BVulkan99tg12871.83 ± 0.06build: 31ac5834 (3818) EDIT: HN should really support markdown... reply coppsilgold 1 hour agorootparentRadeon RX 7900 XTX is RDNA3 but I wonder if llama.cpp is using the Vulkan matrix instructions wmma and mfma. I have not noticed any remarkable differences between Vulkan and ROCm when using IREE but it's not a turnkey solution yet[1]. [1]reply tormeh 6 hours agorootparentprevAny chance we might see Vulkan extensions to close this performance gap? Was really hoping Intel and AMD would team up to vreate an open standard that we could all have installed by default, but instead we get these clumsy vendor-specific solutions... reply adrian_b 5 hours agorootparentI think that it is very unlikely that the performance difference is caused by anything that could be solved with a Vulkan extension. Vulkan only exposes the raw compute capabilities of the hardware and any well optimized Vulkan application can reach the full performance, but you need to write such optimized code. On the other hand, ROCm, like CUDA, includes optimized libraries for certain applications, like rocBLAS. It is likely that here the ROCm backend uses optimized library functions, perhaps from rocBLAS, while the Vulkan backend might use some generic functions for linear algebra, which are not optimized for the AMD GPUs. reply superkuh 5 hours agorootparentprev> ...so the extra effort is just installing ROCm? (vs the Vulkan devtools) The problem with ROCm is that for non-bleeding edge AMD cards you have to install an out of date unsupported version of it because the $current version does not support your card. And that means containerization woes. If you're going to spend $800 on a top of the line current generation video card anyway then you'll have fewer problems (for a few years). Also, the vulkan vs. rocm performance difference for non-bleeding edge non-top of the line cards is smaller. reply latchkey 20 hours agoprevNice work! I was just playing with the inference side of things with 405B myself this weekend [0]. I'm not convinced that 'torch.cuda' is really that bad since the AMD version of PyTorch just translates that for you. More like a naming problem, than anything. Fact is that it is just as easy to grab the rocm:pytorch container, as it is the rocm:jax container. I don't see very many numbers posted. What MFU did you get? [0] https://x.com/HotAisle/status/1837580046732874026 reply felarof 18 hours agoparentNice! I need to calculate MFU. GPU, VRAM details can be found in the repo: https://dub.sh/amd-405b-res. I plan to reattempt the training run next weekend and JIT the entire training step to calculate MFU then reply steeve 10 hours agoprevWe (ZML) measured MI300X at 30% faster than H100. These are great chips! reply yeahwhatever10 20 hours agoprevWhere is the performance data? reply felarof 18 hours agoparent(author here, sorry for the delay in replying, was stuck in back-to-back meetings) I updated our github repo to include GPU, VRAM utilization data (https://github.com/felafax/felafax?tab=readme-ov-file#amd-40...) Note: we couldn't run the JIT-compiled version of the 405B model due to our code/VRAM constraints (we need to investigate this further). The entire training run was executed in JAX eager mode, so there is significant potential for performance improvements. GPU utilization across the board was still ~30-40% even with eager mode, which is quite good! With JIT, I think the GPU util can easily shoot up to ~50-60%. reply dahart 5 hours agorootparentI’d be interested to hear how long it takes, wall clock, to train the same model to the same loss with same number of batches. I don’t trust utilization to say anything useful. reply brutus1213 7 hours agoprevDoes any Cloud provider have a 8xAMD MI300 host that one can rent? I use AWS for a lot of my professional work, and was hoping to try out an AMD GPU. reply Stem0037 12 hours agoprevIf possible, it would be interesting to explore ways to overcome the memory constraints and run a JIT-compiled version. This could potentially lead to further performance improvements. reply yieldcrv 12 hours agoprevIs AMD any closer to extracting value from this with large orders of their GPUs causing a shortage? I’m getting the impression of “no” reply system2 12 hours agoprevWhy is obsidian (a note-taking app) doing this? reply Zerot 12 hours agoparentThey aren't. This company is using obsidian publish to publish documents. reply system2 2 hours agorootparentWeird. reply varispeed 4 hours agoprevHow do you buy such a GPU or is it still only reserved to the rich so they can get ahead of the game once the pleb gets their unwashed hands on these cards? reply manojlds 20 hours agoprevThought this was a post from Obsidian at first. Why haven't they done the GitHub.com vs GitHub.io thing yet. reply codetrotter 18 hours agoparentLooking at the URL has me thinking that this confusion would be resolved if HN adds a small piece of logic to treat the domain publish.obsidian.md specially, just like how HN already does for pages served under forbes.com/sites which is not written by the Forbes staff themselves. So instead of showing the domain as obsidian.md, HN would show the domain for this link as publish.obsidian.md Maybe something for dang to consider if he sees this comment? reply gbraad 19 hours agoparentprevSame thought here. Why would Obsidian bother with AI? Oh wait, this is publish? So this is what $8 per month gets you? I am amazed, as I would have at least expected a subhost: [username].publish.obsidian.md reply felarof 18 hours agorootparentYeah, used Obsidian Publish. But struggling to get custom domain to work with it (have emailed support). reply abalaji 20 hours agoprev@dang: could we get url to include the username since this isn't about Obsidian itself, but rather a user generated blog? reply m00x 19 hours agoparentIt's strange that HN didn't include the full domain \"publish.obsidian.cmd\". reply dang 15 hours agorootparentThat's not turned on by default but I've done it for this domain now. reply j-bos 9 hours agorootparentThanks dang! reply meiraleal 19 hours agoparentprevThat's something obsidian should fix if they care about not looking like they are being impersonated on HN. reply viraptor 17 hours agorootparentObsidian can't do anything about it. It's HN chopping up the url reply oliver_jack 4 hours agoprev [2 more] [flagged] moritonal 4 hours agoparent [–] I guess it doesn't matter if this is human or bot, an advert's an advert. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A startup has fine-tuned the LLaMA3.1 405B model on 8xAMD MI300x GPUs using JAX instead of PyTorch, achieving notable performance improvements.",
      "They open-sourced their code and shared sharding techniques, highlighting JAX's ability to compile ML model code to hardware-independent HLO graphs optimized by the XLA compiler.",
      "This approach allows seamless execution of the same code on both Google TPUs and AMD GPUs, addressing challenges companies face with PyTorch's deep ties to the NVIDIA ecosystem."
    ],
    "commentSummary": [
      "A startup has successfully fine-tuned Llama 405B on AMD GPUs using JAX instead of the more common PyTorch, leveraging JAX's advanced sharding APIs for improved performance.",
      "JAX's hardware-independent HLO graphs, optimized by the XLA compiler, enabled the same code to run on both Google TPUs and AMD GPUs without modifications, addressing a common challenge with PyTorch's deep integration with NVIDIA hardware.",
      "The startup has open-sourced their code and is seeking feedback on their approach and vision for AI infrastructure on non-NVIDIA hardware."
    ],
    "points": 434,
    "commentCount": 85,
    "retryCount": 0,
    "time": 1727127746
  },
  {
    "id": 41635592,
    "title": "OpenFreeMap – Open-Source Map Hosting",
    "originLink": "https://openfreemap.org/",
    "originBody": "Hi HN,After 9 years of running my own OpenStreetMap tile server infra for MapHub (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11389989), I&#x27;ve open-sourced it and launched OpenFreeMap.You can either self-host or use our public instance. Everything is open-source, including the full production setup — there’s no &#x27;open-core&#x27; model here. Check out the repo (https:&#x2F;&#x2F;github.com&#x2F;hyperknot&#x2F;openfreemap). The map data comes from OpenStreetMap.I also provide weekly full planet downloads both in Btrfs and MBTiles formats.I aim to cover the running costs of the public instance through donations.Looking forwards for your feedback.",
    "commentLink": "https://news.ycombinator.com/item?id=41635592",
    "commentBody": "OpenFreeMap – Open-Source Map Hosting (openfreemap.org)422 points by hyperknot 7 hours agohidepastfavorite122 comments Hi HN, After 9 years of running my own OpenStreetMap tile server infra for MapHub (https://news.ycombinator.com/item?id=11389989), I've open-sourced it and launched OpenFreeMap. You can either self-host or use our public instance. Everything is open-source, including the full production setup — there’s no 'open-core' model here. Check out the repo (https://github.com/hyperknot/openfreemap). The map data comes from OpenStreetMap. I also provide weekly full planet downloads both in Btrfs and MBTiles formats. I aim to cover the running costs of the public instance through donations. Looking forwards for your feedback. btbuildem 0 minutes agoVery cool, love the various tile sets (especially the 3d layer!) One thing that tripped me up is the zoom -- the affordance for zoom in/out across most other mapping UIs is via mouse motions -- how come in your demo it's restricted to the +/- buttons? Perhaps I missed something... Thanks for sharing this, looks very neat. reply RagnarD 13 minutes agoprevIf it does a good job, somebody should get paid for it. I wouldn't rely on using this if it depends on donations (I call this begware). People expect to pay for services and products. reply sorenjan 1 hour agoprevThis is really cool, I'll definitely look at this if I need to embed a map in the future. Are there any libraries that lets you plot geographic data on top of this in Python, with Matplotlib or similar? Slightly off topic, but how come there doesn't seem to be any open projects using the Overture maps data? > Overture is a data-centric map project, not a community of individual map editors. Therefore, Overture is intended to be complementary to OSM. We combine OSM with other sources to produce new open map data sets. Overture data will be available for use by the OpenStreetMap community under compatible open data licenses. Overture members are encouraged to contribute to OSM directly. Sounds like it would be a good data source, or am I missing something? https://overturemaps.org/about/faq/ reply richiebful1 1 minute agoparentFolium is a useful library for plotting geographic data in Python. It generates a webpage with the map data displayed with Leaflet.js https://python-visualization.github.io/folium/latest/ https://leafletjs.com/ reply wcedmisten 11 minutes agoparentprevOverture is an awesome resource because it has more coverage than OSM, but at the cost of accuracy. When I was considering using it for restaurants in surprisedatespot.com, I found that it has a lot more automated content with bad geocoding (imprecise locations) compared to OSM. E.g. restaurants can come from an old Facebook page and the geocoding might not be accurate compared to a survey. So where OSM might have a restaurant that closed 8 years ago, overture has every restaurant that's been at that location for the past 8 years. reply jenny91 4 hours agoprevI really like the idea. Why OMT instead of protomaps? The latter is clearly where the community is moving towards (albeit very slowly). I'm somewhat sceptical about the \"free with no API keys\" idea. I guess your service is not guaranteed to be up so no one too big will rely on it. But what if you start getting abuse or someone using them on some humongous site (e.g. one of those cheap restaurant email builders that always embed a map), and you start getting way too much traffic from random sources and websites. What would you do? reply l3x 4 hours agoparentFrom the FAQs on GitHub [1] > What about PMTiles? > I would have loved to use PMTiles; they are a brilliant idea! > Unfortunately, making range requests in 80 GB files just doesn't work in production. It is fine for files smaller than 500 MB, but it has terrible latency and caching issues for full planet datasets. > If PMTiles implements splitting toOpenMapTiles, which OpenFreeMap uses, while open source, does not have a license that encourages derivative works Can you elaborate on this ? I'm derivating OMT and am quite worried now ^^ reply bdon 2 hours agorootparentOMT use a CC-BY license: https://creativecommons.org/faq/#can-i-apply-a-creative-comm... (edit: link) This means that software that implements OMT, even if written from scratch, cannot be re-used by other FOSS projects (Apache, BSD, GPL, AGPL, other software in the OpenStreetMap ecosystem, etc) without affecting the license. Ideally for Protomaps it should be possible to re-use just one portion - like only the label layer with your own layers from other sources, or even bundle it as a JS dependency in another open source project - without affecting the license of downstream projects. reply bauruine 3 hours agorootparentprevI did 150TB+ on a 40 Euro Hetzner server for years without any issue and also did the same amount in a similar price range on multiple different providers. The cloud and CDNs charge a huge markup. reply hyperknot 3 hours agorootparentThat's great to know! I know of one story where someone got terminated on Hetzner because of the bandwidth but it turned out he was also running a Tor node. reply maelito 2 hours agoprevRelated : I'm building https://github.com/laem/cartes, an alternative to Google Maps. On top of a custom protomaps tileset and a few other MapTiler options (such as satellite and hiking), it packs a search engine, a basic OSM place UI, transit calculators (walk, bike with profiles, transit, car), small features like ruler and favorites, transit maps, photos of places, place search by categories, and the French open source street view Panoramax. Of course, given the scope, its alpha software. It's built locally for France and French speaking users, though most of the code is English, some data sets are not. I'm spending ~ 50 % working on transit, lots need to be done. You can test it here : https://cartes.app. The aim is not to provide map tiles as an API to other project, but to build a UI on it. reply zaik 47 minutes agoparentWow this is one of the best Google Maps clones I've seen so far. Is there a plan to translate the UI into other languages than French? I would be willing to help out, if there is a Weblate interface or something similar. reply maelito 15 minutes agorootparentThanks ! I've raised this issue. Short : nothing yet. https://github.com/laem/cartes/issues/574 reply iudqnolq 26 minutes agoparentprevI see you're sourcing images from Wikimedia. Have you found any other good sources? I'm working on indexing images by place taken for my own project and am primarily very slowly and jankily enumerating the flickr API. (You can see https://plantopo.com/geophotos for a pre-alpha view of where I have coverage. Zoom in where there are blue dots and click the map to search. Don't click Oregon or Washington because of a bug I'm working on) Are you using opentripplanner for routing? reply hyperknot 1 hour agoparentprevWow, now that's an ambitious project! I wish you a lot of success with it! reply maelito 51 minutes agorootparentThanks ! It consists of using more focus initiatives like yours and bdon's :) reply ivanjermakov 2 hours agoparentprevOh, there is another pal who's streaming making his own maps, fairly entertaining: https://youtube.com/playlist?list=PL980gcR1LE3L8RoIMSNBFfw4d... reply maelito 2 hours agorootparentThanks ! I've thought about making an \"education\" project but it takes time, and after 9 months of working on it I'm now convinced it's possible to build a basic Gmaps alternative in a few years. Business model still missing though ! Edit : just watched some minutes, he's rebuilding low-level components, like route finding. Impressive stuff but not quite user-friendly. reply ivanjermakov 1 hour agorootparent> not quite user-friendly Yes, it does not seem like he makes a business or a product for a wide audience. It's more about exploring the unknown, teaching programming and being entertaining. Although I adore such ambitious projects that seem insurmountable at the first glance. reply wongarsu 5 hours agoprevI understand you don't plan to make money, only to cover costs. Nevertheless, I believe you would benefit from a more explicit \"business plan\". Your Gold support plan kind of fulfills that purpose (email support and an invoice), but right now it's kind of hidden in the middle of a donation request, and flavored as a donation. You might convince a lot more mba-type people to support you if you also extend the same offer under a heading like \"business plan\" (where you make it clear that commercial use is free, but you can subscribe to this totally-not-a-donation plan for email support) reply hyperknot 4 hours agoparentDo you think it'd be more clear to only accept donations on GitHub Sponsors and only offer actual support plans on the website? I mean actual email support, helping companies migrate their existing map stack to OpenFreeMap. reply lacoolj 27 minutes agorootparentIf you aren't doing this for a living and getting paid for it, or having someone else do it, you should reconsider either A) providing the support or B) how you make money. You may think it noble to \"only take donations\" just to pay the hosting cost, etc. but providing people support is a completely different thing. People are stupid, needy and inconsiderate of your time, feelings and experience. If you don't want to run ads, great! But your time should be compensated fairly as well. You should be charging businesses for things, with a substantial cost for substantial work. Charging a business is not the same as charging an end user and you should not be averse to doing so. reply nelsonic 4 hours agorootparentprev100% keep sponsorship separate from paid support. reply hyperknot 2 hours agorootparentThanks, I've thought about it and rewritten the whole donations / sponsorships / support plan section. What do you think? reply gmiller123456 2 hours agorootparentprevThe problem with putting different options in different places is that a lot of people will only ever see one of the options. reply 3np 4 hours agorootparentprevWould be super cool if you have a bitcoin and/or monero option. Even if just address for donations and not as payment for support. reply jszymborski 4 hours agoparentprevI second making a very generous free tier, and then charging reasonably for more requests in wide buckets. As a user, free or paid, it'd give me a lot more faith in this living past tomorrow. reply hyperknot 4 hours agorootparentI definitely not want to charge for requests, that's the founding principle of this project. And the risk of this project is largely mitigated by offering the full repo as open-source, so you can always self host this if needed. reply wongarsu 4 hours agorootparentIf you don't want to charge per request, you could also offer two pools of backend servers: free servers that are provided on a best-effort basis with fair-use-policy, and paid servers that are exclusive to people in the $150/month plan. The latter should be easier to manage with more predictable traffic, while giving you more leeway to deal with abuse on the free servers if it ever becomes an issue. reply hyperknot 4 hours agorootparentYes, I was thinking about that, it might actually be a good idea. Provide a premium service with SLAs, while providing the SLA-less service for free, with two pool of servers. reply dheera 34 minutes agoparentprevTo be honest I don't see the problem with making commercial use non-free. (a) They're making millions, you deserve a cut of that. (b) If making money makes you more likely to be around in 10 years, that's attractive to businesses. Nobody knows when your donations might suddenly dry up. reply mannyv 5 hours agoprevFYI if you need a CDN you can get bulk pricing from fastly with a monthly commitment. I'm not sure if their hosting works for you because you might be serving byte ranges. I think we're paying 2k/month usd for like 300TB/month. Backblaze-to-fastly is free, so no egress. Love your project, more power to you. I'll be using this for a few side projects for sure. reply hyperknot 5 hours agoparentAt Hetzner, the bandwidth is unlimited in theory. In practice, there are stories of terminating accounts of those who used too much. I don't think this project will ever make $2k per month. TBH, I'd be happy it it ever reaches $200 per month. I have to be very careful about what hosting providers to use and CDNs are out of the question. reply wongarsu 4 hours agorootparentI don't think it's still offered anywhere in the web interface, but Hetzner offers servers with 10Gbit uplink, with traffic charged at 1€/TB. Depending on resource usage this can be more cost effective than renting multiple servers, and paying for your traffic should prevent account termination for excessive traffic use. https://docs.hetzner.com/robot/dedicated-server/network/10g-... reply j45 5 hours agoparentprevI wonder if other CDNs can help. In addition to Cloudflare, bunny was on the radar too. reply hyperknot 5 hours agorootparentBunny is also $10-$60/TB/month. I believe Hetzner should not have any problem with using 100 mbps out of the 1 Gbps on their servers. That's 30 TB/month for free, per server. It'd be $300-$1800 per month on Bunny. reply tiluha 5 hours agorootparentFor this use case i would use the bunny volume tier which is $5/TB reply bauruine 3 hours agorootparentThat's still an order of magnitude more than what you can get with rented servers. I pay between 0.2 and 0.4 per TB doing nearly 2000TB a month. reply j45 2 hours agorootparentAgreed. Getting a dedicated fibre link colocated is a great way to backfill and push the free tiers of CDNS. Just like the cloud becoming easier to run on your own environments, tons of bandwidth is accessible too. reply baggachipz 3 hours agoprevI currently use the cyclosm[1] as a tile map for my small web app. I'd love to use OpenFreeMap instead, as cyclosm is quite slow. Is there any way I can do this for bicycle maps? Awesome project. [1] https://www.cyclosm.org reply hyperknot 2 hours agoparentWhat you need is a bike specific style for OpenMapTiles schema. Maybe you can find it on GitHub. Once you have the style, you can use Maputnik to tune it to your liking like on this link: https://maputnik.github.io/editor/#0.84/0/0 reply maelito 2 hours agoparentprevAs far as I know, no vector equivalent of cyclosm has been made. OpenMapTiles's data are too poor (\"compressed\" : different cycle way types are summarized in a unique tag) to make a great cycle map. reply noahjk 5 hours agoprevThis is neat! After the huge price increase a couple years ago with GMaps, it looks like you’ve come up with a creative way to offer much of the same functionality for most users. It’s unfortunate to still see small business sites to this day with error messages on their map widgets because of the API change from Google. I know nothing about mapping, but I’ve always had a dream of making a private neighborhood map which labels each house with people, sort of like a visual Rolodex. It would be great to have property boundaries, too. Do you have any suggestions for places to start? I don’t even know what file formats would hold this sort of data. reply tony_cannistra 17 minutes agoparentIf you live in the US, you can get parcel information from your local tax assessor's website, usually. Sometimes it's devoid of owner information. Such cases usually require going to a company like ReGrid or Corelogic to purchase the data. I work for a company (onXmaps) which produces user-friendly maps of such information. You could use our app to create such a \"rolodex\" of your neighborhood, by annotating individual parcels with your neighbors' information. https://onxmaps.com reply hyperknot 5 hours agoparentprevThanks! I don't know where you'd be able to get property boundaries, I guess it's usually not open-source / public data? Probably depends on the country / city. reply ryandrake 3 hours agorootparentIn the USA, parcel outlines are commonly handled at the county level. You can often do a search for “[your county] GIS maps” and find their ArcGIS map of the county property lines with metadata about who owns what. Who knows if any of them are willing to share the data, but that’s where it lives. reply allannienhuis 5 hours agoparentprevthis might be helpful?: https://github.com/martynafford/natural-earth-geojson/blob/m... public domain map data in GeoJSON format. also, for google maps I know you can respond to interactions with the supplied points of interest like buildings, including homes, and from that point you can obtain an address via reverse geocoding or some other technique. I expect other mapping tools may have similar abilities but I don't have any experience with anything other than Google. reply curzondax 2 hours agoprevAlternative: https://versatiles.org/ reply jnettome 1 hour agoprevRight on time! Thank you and congratulations for your release. I was looking for gmaps and mapbox alternatives this morning and right now I'm considering this. reply mike_d 4 hours agoprevI absolutely love this project and had a similar idea on my todo list for a while because I agree there should be at least one free open map provider with a developer friendly stack. If you want free servers/bandwidth around the world, hit me up. My email is in my profile. reply hyperknot 4 hours agoparentThanks a lot for the offer, I'll definitely reach out! reply nathancahill 5 hours agoprevWould be interested in seeing a cost bar vs donations bar on the website. reply hyperknot 5 hours agoparentCurrently I'm paying for 3 dedicated servers at Hetzner and getting total donations of $11 USD per month. Making this automatic might not be easy, but I might do it one day, it might help with the donations. reply linsomniac 3 hours agorootparent>getting total donations of $11 That total has gone up. :-) Not currently having any plans of using openfreemap, but I like the cut of your jib. I'm currently in the process of generating aerial tiles for Colorado, and updating 2 of our map tile sets (bitmap tiles, Here and OpenStreetMap), but at some point we should switch to vector tiles. When we do I'll try to get a business sponsorship going, but it is nearly impossible for me to get the company to pay for sponsorship. :-( reply hyperknot 2 hours agorootparentThank you so much for your donation, it's appreciated! reply swijck 2 hours agoprevI've been waiting for a good alternative to the paid map providers for a while but none of them have really hit near the level of feature parity I needed to be a good enough replacement. reply lipitic 3 hours agoprevThis is amazing! Last year I made a website for my gf where I had to build a custom map of Paris, and I struggled a lot trying to figure out how to actually make a map from scratch while avoiding paid services like mapbox. I finally managed to hack something up using openstreetmap data, then some manual work in QGIS to customize the look, and voila - I had a bunch of folders filled with raster tiles. This site is deployed for free on Netlify and is basically just a React SPA, a public folder with tiles, and I give the tile URL template to the OpenLayers lib to display it all nicely on the screen. Simple and it works! I always wanted to improve the map a bit by using vector tiles as I think it looks nicer, but I thought you need a dedicated server for that? (unless I'm mistaken, correct me if I'm wrong) reply hyperknot 2 hours agoparentYes, you need a dedicated server with 128 GB RAM to generate the tiles. For hosting the tiles, you can use anything with 300 GB disk space, CPU is not important. reply cheeaun 5 hours agoprevVery curious to know more about this, regarding PMTiles: > Unfortunately, making range requests in 80 GB files just doesn't work in production. It is fine for files smaller than 500 MB, but it has terrible latency and caching issues for full planet datasets. Wondering which part incurs the latency here. reply hyperknot 5 hours agoparentI explained a bit about PMTiles in this comment: https://news.ycombinator.com/item?id=41636376 In summary, on a cold start (so now when it's on HN it might be totally meaningless), the following page loads in like 8-10 sec for me: https://pmtiles.io/?url=https%3A%2F%2Fdata.source.coop%2Fpro... Technically why it's slow is entirely on CloudFlare, so I can only guess. But probably they are not mirroring files of this size across their datacenters / servers. I don't know how their public buckets hosting is done, but it's definitely very slow. OpenFreeMap on the other hand seems almost instant for me. reply bdon 2 hours agorootparentSee my response here: https://news.ycombinator.com/item?id=41638031 reply sphars 5 hours agoprevAlways on the lookout for self-hosted map servers, so I'll definitely try this one out. Slightly off-topic, one thing I'm having a hard time finding is satellite imagery. I need to self-host an offline web application using CesiumJS, and while I can spin up a map server, I can't find satellite imagery for free or cheap. I've used MapTiler[0], their server works great and they offer low-res satellite imagery for free/testing, but their high-res images are out of my price range. Anyone know of resources for downloading offline images of satellite imagery, compatible with OpenFreeMap or other server for use with CesiumJS? Doesn't have to be super recent images but would be nice. [0]: https://www.maptiler.com/ reply hyperknot 5 hours agoparentSatellite images are definitely expensive, they are by far the biggest cost for MapHub. I spend more on satellite images per month than on servers. I couldn't find a high quality satellite images from free sources. reply kisamoto 2 hours agoparentprevCurrently researching this myself? Have you explored the satellite images from ESA/NASA? They are painful to discover but they're available to download for free and fairly (3-6 months) up to date. reply kisamoto 2 hours agoprevI am currently exploring the open source mapping world and trying to get a better grasp of what's available. How does this project compare to Apache Baremaps (incubating)? https://baremaps.apache.org/ reply hyperknot 2 hours agoparentThey are providing the building blocks for making a self-hosted vector tiles server, they don't actually host the tiles. reply khobragade 1 hour agoprevAwesome! Moreover, I love how hyperknot is engaging with the people and the feedback :) This is super inspiring. reply timmg 4 hours agoprevJust want to say thank you for making this project. I think there's a good chance I will use it for a (very low bandwidth) personal project. reply hyperknot 4 hours agoparentThank you very much, and also thank you for your donation! reply komali2 4 hours agorootparentI'll be using this this Sunday for a project for a g0v civic hackathon. You solved a problem we had been discussing today. We were going to use protomaps instead https://protomaps.com/ The pitch for the project is here if anyone in Taiwan is interested in joining: https://hackmd.io/7K4kLkseTYCPI7DWoNv5mA?view Hackathon info: https://g0v-jothon.kktix.cc/events/g0v-hackath63n reply SebaSeba 4 hours agoprevSeems like a great service! We could definitely consider this as an viable option for our startup's application. I am not an expert regarding the OSM data and maps in general, but how customizable is your library, can I somehow relatively easy add housenumbers of the addresses from OSM data on the buildings in the map? reply hyperknot 4 hours agoparentThis is totally customizable and the house numbers are already present in the original data, it's just not displayed in the default styles. You can customize the style by using the Maputnik editor, house numbers are visible in the \"Inspector\" view. https://maputnik.github.io/editor?style=https://tiles.openfr... reply NKosmatos 5 hours agoprevThanks for this free service Zsolt. I hope it's not abused (too much traffic) and that donations from real users fund this very good initiative ;-) On a related subject, I remember seeing MapHub sometime ago and I have it in my bookmarks for one of my (forgotten?) projects. Whenever I find some free time I need to sit down and try the free tier to see if it will do what I have in mind. reply hyperknot 5 hours agoparentThanks a lot for your words! I'm also curious whether the donations will be able to cover the bandwidth costs. Currently I'm paying for 3 dedicated servers at Hetzner and getting a total of $11 per month from donations. reply jack_riminton 5 hours agoprevI'm relatively new to mapping, can you explain the difference between running Leaflet and a free map tiling provider compared to your product? reply hyperknot 5 hours agoparentAs far as I know, there are no \"Free Map Tiling provider\"-s. This project aims to be exactly one. You can use it with Leaflet using the https://github.com/maplibre/maplibre-gl-leaflet plugin. reply kisamoto 2 hours agorootparentI asked the question as a top level comment but also duplicating here. Isn't Apache Baremaps a \"free map tiling provider\"? Or do I misunderstand what a tiling provider is? https://baremaps.apache.org/ reply hyperknot 2 hours agorootparentThey are providing the building blocks for making a self-hosted vector tiles server, they don't actually host the tiles. reply jack_riminton 3 hours agorootparentprevInteresting thanks, I've used map tilers in the past without paying, maybe I just never came up against any rate limiting reply the-rc 3 hours agoprevHard links are to deduplicate identical tiles, right? How much does that save and how close is the tile with most links (empty one(s)?) to the filesystem limits? Inquiring minds want to know... reply hyperknot 2 hours agoparentYes, exactly, it's to save space. For example there is one such tile for \"ocean\", which covers 70% of earth. In total, there are 271 million hard links. So out of 300 million files 271 are hard links! The file system limit is 64k hard-links for the same file, so I have to handle the case when it's reached and then start a new file for the next 64k. reply mdaniel 1 hour agorootparent> The file system limit is 64k hard-links for the same file I had never heard that, so I went sniffing around and it seems to be ext4 specific[1] but I wasn't able to easily get the limits for ZFS (or xfs, etc), so depending on how much glucose one wished to spend it may be better to use a different FS than all that renaming work around 1: https://en.wikipedia.org/wiki/Hard_link#Limitations reply wkat4242 1 hour agoprevHow much disk space do you need to host it? reply hyperknot 56 minutes agoparentI'd recommend at least 200 GB. reply wkat4242 6 minutes agorootparentThanks! That's a lot less than I expected. reply vanillax 4 hours agoprevI know the github says docker free.... What would it take to dockerize so people can self host, say on kubernetes. reply hyperknot 3 hours agoparentSomeone making a Docker image from this. Instead of using Fabric's commands like c.sudo('git clone ...') it'd use the RUN commands. I think it would be quite a straightforward task to transform it into a Docker file. I'd be happy to link to it on GitHub. reply thinkingemote 5 hours agoprevLooks great love the free tiles and no limits or API keys. Question, why use btrfs? reply hyperknot 4 hours agoparentSo a full planet OSM extract is about 300 million binary files, in total about 90 GB. The most popular ways to store it: - MBTiles - an SQLite file, each file is a row in a table, you need a server to serve it. - PMTiles - a single file, optimised for serverless usage. - Extract them into a directory, which in practice should be on a partition image. This is the approach I choose. I tested ext4 and Btrfs and I choose Btrfs. The reason is how ext4 and Btrfs handles inodes. Btrfs handles inodes so much better compared to ext4, it doesn't allocate them at start and also allows putting tiny files right with the metadata. Because here the average tile size is only 405 bytes, most of the tiles can actually stored with the Btrfs metadata block. From the latest run: Btrfs data is 51.57GiB Btrfs metadata is 84.37GiB reply ahlCVA 1 hour agorootparentThis sounds like a perfect application for EROFS[1]. While it comes from an embedded systems background, it has seen some usage in container use cases and is moving towards a general \"mountable tar\" application. It would also avoid the tedium you have to go through in shrink_btrfs.py because you can just generate the image out of a tree. I wanted to give repackaging the btrfs image a shot but the download was pretty slow - I assume your server is getting HN-hugged a bit so I didn't want to make it worse and stopped the download. [1] https://erofs.docs.kernel.org/en/latest/index.html reply hyperknot 52 minutes agorootparentThanks a lot, I didn't know about it! I also liked the fact that Btrfs is probably super well tested in the Linux kernel by now. btrfs.openfreemap.com just a public Cloudflare bucket, no idea why it might be slow. reply ahlCVA 34 minutes agorootparent> I also liked the fact that Btrfs is probably super well tested in the Linux kernel by now. btrfs has certainly been around for longer, but in my (embedded systems only) experience, EROFS has been pretty solid - it's slowly being picked up by Android, so it is definitely seeing a lot of use in the wild (probably surpassing btrfs by the number of installations already). > btrfs.openfreemap.com just a public Cloudflare bucket, no idea why it might be slow. I'm getting 30 MiB/s (on a gigabit uplink) - not great, not terrible. A .torrent would be nice but I guess outside of being on the HN front page full-planet downloads by different people won't synchronize enough for this to be useful (and using web seeds is problamtic in its own right with small-ish chunks). reply c0nsumer 1 hour agorootparentprevI apologize if this is something stupid, or answered elsewhere, but is there a good way to trim Planet down to a smaller area? I've been making some custom map stuff for mountain bike trails and I'd really like to move to self-hosted vector tiles for all layers, but too much of what I find says to start with Planet.osm when all I really need is a State (in the US) or even a few-miles-wide area. (My goal is to basically snapshot OSM data, generate tiles, and use that until I decide to do another snapshot down the line, so the underlying data doesn't change. And limit it to a small area because that's all I need.) Examples of maps I've done this way, and want to improve, are: https://trailmaps.app/ramba/ and https://trailmaps.app/dte/ reply hyperknot 57 minutes agorootparentIf you know the tile numbers, you can just copy them out of the Btrfs image. reply thinkingemote 2 hours agorootparentprevDo you think btfs would work well for old school pre rendered raster tiles on disk? reply hyperknot 1 hour agorootparentYes, I think it would. Have a look at the extract_mbtiles script: https://github.com/hyperknot/openfreemap/blob/main/modules/t... reply sandreas 5 hours agoparentprevAfaik btrfs supports incremental send / sync very efficiently, so if you just want an update it saves bandwidth reply Coolbeanstoo 5 hours agoprevSeems like the full world download links dont work, 404: https://btrfs.openfreemap.com/ reply hyperknot 5 hours agoparentCloudFlare buckets don't support indexing / directory listing, so you need to get the exact URL. To help with this, here is a file listing the content of the bucket: https://btrfs.openfreemap.com/files.txt reply maxmcd 5 hours agoprevHey, just curious. If you have no Cloud/LB/CDN how are you routing requests to datacenters? Anycast? DNS? Something else? reply hyperknot 5 hours agoparentRound Robin DNS. The browser selects the best server, based on ping or some other internal metric. Also thanks for the donation! reply jsilence 4 hours agoprevAnybody know of a similar service for weather information? reply xd1936 3 hours agoparentUS-only, I've had good luck with the NWS JSON API[1]. Someone posted a while ago on here[2] about taking in various NWS models and creating \"Pirate Weather\"[3], a drop-in replacement for Dark Sky. 1. https://www.weather.gov/documentation/services-web-api 2. https://news.ycombinator.com/item?id=34329988 3. https://pirateweather.net/ reply zarazas 5 hours agoprevI would be interested in the differences between this and protomaps reply hyperknot 5 hours agoparentI'll write a detailed blog post for that, definitely. Basically Protomaps / PMTiles allows you to do this serverless, but it has it's downsides. There are two ways to use PMTiles with Cloudflare: - Putting the file in a public bucket and use HTTP range requests. - Deploy a worker to access it. For the range request version, you can test PMTiles here: https://pmtiles.io/?url=https%3A%2F%2Fdata.source.coop%2Fpro.... It loads in 8-10 sec for me on a cold start. Of course it gets faster if many of us try to request it at the same time, but if you check it once per day for example, it'll be really slow, up to 10 sec. Compare that with OpenFreeMap here: https://openfreemap.org/quick_start It's near instant for me. (I know it's not full screen but you can make the app and then see how it's in full screen). For the Cloudflare Workers version, I didn't find any publicly available full planet test, so I don't know the performance, but Workers are not free. It might not matter for a small project, but the $0.30/million requests per month can easily add up if your project gets popular. In terms of OpenFreeMap, hosting it on a Cloudflare Worker would be prohibitively expensive. reply bdon 2 hours agorootparentI'm the developer of Protomaps, to summarize: The latency you see on https://pmtiles.io/?url=https%3A%2F%2Fdata.source.coop%2Fpro... is representative of how PMTiles works on AWS S3, coming from the us-west-2 region. It will be reasonable to load for those in the western US and likely quite slow from Europe or Oceania. If you want to make a direct comparison of Protomaps to OpenFreeMap, you need to compare serving OpenFreemap with NGINX from btrfs on disk, to running `pmtiles serve` on a `.pmtiles` file on disk, as described here: https://docs.protomaps.com/deploy/server The OpenFreeMap page for me (in Taiwan) takes 1-2 seconds per tile, which is more than double the load tile for the PMTiles in us-west-2 example linked above. The best solution to get latency competitive with commercial providers, for a global audience, is to cache tiles at CDN edge locations. I describe automated ways to do that with Cloudflare Workers and AWS Lambda + Cloudfront here: https://docs.protomaps.com/deploy/cloudflare https://docs.protomaps.com/deploy/aws I'm also experimenting with http://tigrisdata.com which lets you geo-distribute a static storage bucket like in this example: https://pmtiles.io/?url=https%3A%2F%2Fdemo-bucket.protomaps.... reply hyperknot 2 hours agorootparentNo, the ping is 150 ms to us-west-2, and the tiles load in like 5 seconds on a cold start. Of course we cannot test cold start on HN comments because HN is the definition of hot :-) I can imagine workers to be fast, it's the range requests which are super slow. It's also outside of your control, it depends on how Cloudflare and S3 handles range requests to 90 GB files. I think if you could make PMTiles split into files <10 MB, it'd be perfect with range requests. reply bdon 2 hours agorootparentI agree, there are tradeoffs to using static storage - the intended audience for PMTiles is those that prefer using static sites instead of administering a Linux server. I would be interested to see a comparison of Btrfs + nginx serving latency, vs `pmtiles serve` from https://github.com/protomaps/go-pmtiles on a PMTiles archive on disk. That would be a more direct comparison. I think there's potentially some interesting use case for tiles in Btrfs volumes and incremental updates, which I haven't tackled in PMTiles yet! reply hyperknot 1 hour agorootparentI think both solutions could easily saturate a 1 Gbps line. I benchmarked Btrfs + nginx and it could do 30 Gbps, which doesn't really make a difference if your server is 1 Gbps only. The fact that there is no service running was the more important for me. Mostly for security and bugs. I had so many problems with various tile servers in production, they needed daily restarting, they had memory leaks, etc. Basically I wanted to go nginx-only for security and to avoid tile server bugs. reply bdon 54 minutes agorootparentI see, I think that's a good approach to enable serving with stock nginx as well as for companies that are built on Nginx or a plain HTTP serving stack already. For PMTiles the module is loadable directly as a Caddy plugin (https://docs.protomaps.com/deploy/server#caddyfile) which I prefer to nginx for security and bugs (and automatic SSL), and also enables serving PMTiles from disk or a remote storage bucket without a separate service running. reply adhamsalama 3 hours agoprevVery interesting, I might try this at $WORK. reply anthk 3 hours agoprevI miss some libre client for Google's Street View. On 3D maps, adapting Marble for OSGEarth should be a piece of cake. If not, declaring one with IMGui+layers can be done in a week from any experienced C++ programmer. The included demos for OSGEarth already depict a minimal client with impressive 3D maps for a nearly non-supported demo. I think KDE/Plasma lost a great oportunity there by not adopting OSGEarth. reply maelito 2 hours agoparentWhat would be the aim of a libre client for Google's SW ? Street View API is quite expensive. Do you know about https://panoramax.fr ? reply sylware 5 hours agoprev [–] The main issue: once a map service has enough success, it will require significant bandwidth resources which only Big Tech can afford. P2P? Well, there is always the issue of trust. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "After 9 years of development, the creator of MapHub has open-sourced their OpenStreetMap tile server, now called OpenFreeMap.",
      "OpenFreeMap allows users to self-host or use a public instance, with all components being fully open-source and no 'open-core' model.",
      "The project offers weekly full planet downloads in Btrfs and MBTiles formats, and aims to cover public instance costs through donations."
    ],
    "commentSummary": [
      "OpenFreeMap is an open-source map hosting service launched by hyperknot after 9 years of operating an OpenStreetMap tile server for MapHub.",
      "Users can self-host or use the public instance, with all components being open-source and map data sourced from OpenStreetMap.",
      "Weekly full planet downloads are available in Btrfs and MBTiles formats, and the project aims to cover public instance costs through donations."
    ],
    "points": 425,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1727179162
  },
  {
    "id": 41631130,
    "title": "iPhone 16 Pro Storage Expansion 128GB to 1TB [video]",
    "originLink": "https://www.youtube.com/watch?v=KRRNR4HyYaw",
    "originBody": "Watch later Back",
    "commentLink": "https://news.ycombinator.com/item?id=41631130",
    "commentBody": "iPhone 16 Pro Storage Expansion 128GB to 1TB [video] (youtube.com)372 points by haunter 20 hours agohidepastfavorite257 comments soganess 15 hours agoThis has the parts of my brain wired for: - working on cars (the torque \"wrench\" click is such a cue) - dissembling electronics - watching folks work on... mechanical watches - unnecessary / creative uses for a CNC all firing. I feel pandered to directly... and consider its a mostly silent video of someone replacing a nand chip, I'm not how to feel about that. On a more constructive topic: Can the performance/endurance characteristics be modified by using better nand chips(a la ram)? Or does it have to an Apple blessed part? reply physhster 13 hours agoparentM539/TronicsFix/Wristwatch Revival... reply throwaway48476 9 hours agoparentprevNAND only gets faster by having more of it in parallel. reply dannyw 8 hours agorootparentNot exactly true. For example, QLC is slower than TLC. reply jychang 13 hours agoparentprevIf you are okay with losing your operating system each time the phone turns off... reply wtallis 13 hours agorootparentDid you think that comment was suggesting replacing NAND with DRAM? I'm pretty sure it's just asking if there are varying speed grades of NAND the way there are varying speed grades of DRAM. reply roughly 14 hours agoprevPutting aside all the business model stuff, man, Apple makes some seriously pretty hardware. The packing, the cables and connectors, the wrapped motherboard - the whole thing is gorgeous. reply giancarlostoro 6 hours agoparentThere used to be cases for iPhones idk if they still exist, that show off the internals back 10 years or so. iPhones were always easier to open up and work on than Android phones in the early years. So even though they push things so they do repairs, they make it so that even if they don't fix your stuff, it's not a clobbered mess of things inside. reply munr 5 hours agorootparentThere are Teardown and X-Ray decals available from dbrand which were created in partnership with Zack from the JerryRigEverything YouTube channel and accurately represent the internals of the phone. They can attach directly to the back of the phone and there is also a case available. Teardown: https://dbrand.com/shop/limited-edition/teardown X-Ray: https://dbrand.com/shop/limited-edition/x-ray I've got one on my S24 Ultra and love it. Personally, I prefer to have the decal directly attached to the back of the phone with a clear case on top. reply teejmya 2 hours agorootparentBefore these, we had the real thing, which is what I assume giancarlostoro is referring to https://www.cultofmac.com/news/make-the-back-of-your-iphone-... reply maxglute 11 hours agoparentprevI feel like most phones have pretty clean internals these days. Apple goes the extra aesthetic mile to make everything same shade of grey/metal/black. reply cheeze 14 hours agoparentprevThe design of the iPhone has always fascinated me. It's just so... clean. reply jasonjayr 6 hours agorootparentApple has always made even the insides of their hardware clean and neatly laid out, dating back to the Original mac hardware. In the video, one of the inside brackets had a laser engraved apple logo! reply giancarlostoro 6 hours agorootparentprevAs a former Android user, it was one thing every iPhone fanboy had on me I couldn't argue on. Not why I switched, but I now appreciate it knowing that they still give attention to that little detail. reply krackers 13 hours agoparentprevI think it was Steve Jobs who insisted that that even the inside of their products look as clean as the outside. It unfortunately means it's a pain to disassemble, but they certainly do look pretty. reply nine_k 13 hours agorootparentI don't think it's about showing off. It's about reliability, mechanical sturdiness, compactness, the ability to cleanly assemble the device an test it on every significant step before sealing. You can't help but end up with a neat thing to meet all these requirements. reply kylebenzle 5 hours agorootparentSteve Jobs was famously obsessive about design, inside and out, call it showing off or whatever you want. He believed the internals of Apple products, like the original Macintosh, should be just as beautiful as the exterior, even if users never saw them. This attention to detail reflected his commitment to craftsmanship and quality. Source: Walter Isaacson's Steve Jobs biography. reply thechao 25 minutes agorootparentMy grandmother (she'd've been ~118, now) taught me to sew. There's specific techniques for turning down interior hems. That is, imagine a jacket: it has a shell, and a lining; I'm talking about a specific kind of hem for material between the shell and the lining. The finish work of that hem had no bearing on the quality of the item — it just demonstrated to the next tailor working on the jacket that you'd spent the time to finish the parts only they would see. And, goddamn, it doubled the effort for finishing a jacket. reply nine_k 4 hours agorootparentprevFortunately, the tendencies for neatness and build quality reinforce each other. (Sadly, Sir Ive's obsession with thinness and minimalism did not mesh with actual ergonomics equally well.) reply cancerhacker 6 hours agorootparentprevI don’t know if he came up with it, or if it was one of those fatherly : shop class myths, but there was a cabinet built, and the backside needed to be finished as well as the front, even though it would be nailed to a wall. The idea being that the design and craftsmanship should permeate the object. reply mckravchyk 2 hours agorootparentAnd it really does permeate it. I'm on Linux but I run it on an Intel Mac. It will be very hard to find a non-Mac replacement. I look at the laptops at the electronics store and simply nothing comes even close. Beautiful products, it's very unfortunate though that they become ever more closed. reply resource_waste 8 hours agoparentprevThey have learned aesthetics>quality. Its cheaper to make something pretty, than good. Humans use this shortcut and have a hard time resisting it. My experience opening an iphone box, giving all my personal information, and seeing the home screen of my work iphone was fun and exciting. Then within a few minutes, the swiping/changing between apps was noticably slow, the podcast app had a bug in it, and it kept asking me to 'sign in' by typing my password. The illusion had broke, and its not like I was going to return the phone now. reply consteval 3 hours agorootparentOut of all the things to complain about with Apple software/hardware, I think quality isn't one of them. The devices and accompanying software are very high quality. They're not repairable, they're quite restrictive, and they're perhaps too simple. But definitely high quality. reply afavour 3 hours agorootparentprev> Then within a few minutes > its not like I was going to return the phone now. Sounds like you're your own worst enemy here. You're well within the return window and could easily do so and replace it with, uh... well... let us know which mobile OS has more polish than iOS, I guess. reply webXL 5 hours agorootparentprevSo it’s more expensive to make something ugly. Gotcha ;) The slowness might be explained by the background tasks of restoring previously installed software and data. I have an iPhone 13 Pro with tons of apps and it’s still pretty snappy. But those specific bugs do pop up from time to time. Especially since they release new phones concurrently with new operating systems. reply resource_waste 4 hours agorootparent>So it’s more expensive to make something ugly. Gotcha ;) What is the point of this? Does anyone enjoy this? Everyone knows what is being said based on the context? >The slowness might be explained by the background tasks of restoring previously installed software and data. No, it never went away. I had been coming from a Pixel, so I wasnt really forgiving about bugs, limited features, or slow animations. It felt like I bought an old phone. That + the otterbox really dispelled the illusion. reply callalex 13 hours agoparentprevWhen I go to replace wear items such as the battery the insides of my Apple products look like goopy garbage because of all the adhesive I have to melt and scrape through. How is that considered “gorgeous”? reply judge2020 13 hours agorootparentEventually people wanted to be able to use it in somewhat moderate rain or want it to survive being accidentally dropped in the pool. reply callalex 13 hours agorootparentWhat about the dozens (at this point hundreds) of phone models that are both rainproof and have a replaceable battery without melting and scraping? They exist in real, observed reality. What about the last 15 years of MacBook models that never claimed to be waterproof but still require heat guns and risk of catastrophic immolation to extend their life beyond 3-5 years? But for some reason the internals of an iPhone 16 are still “gorgeous”…and merit a stage appearance and endorsement from Mother Earth herself! reply dacryn 9 hours agorootparentin my experience from a few years ago: I commute by bicycle to shool (and in the meantime work) in a very rainy country. My entire childhood, I had to replace phones every few months jsut because they got soaked in the rain and I didn't close the protective case perfectly or whatever. Then I started to buy waterproof phones, and my life was noticeably better. those still die from water damage, just slower. Every time you drop the phone and the case pops off, the water protection gets a bit worse, and after a year or so, the rubber gets hard, especially in winter, and its no longer waterproof. I wouldn't dare to put it in actual water. Now I have had my smartphone for many years, and I had the previous one for many years. So yes please, glue it together, glue it shut, at least if you're serious about water damage and dust ingress reply kjkjadksj 6 hours agorootparentA ziplock bag would have solved your problems reply bubaumba 12 hours agorootparentprev> What about the dozens (at this point hundreds) of phone models that are both rainproof and have a replaceable battery If that's what you are looking for just get one. It may come even with spyware preinstalled. Then try it underwater, should be fine if it's in specs, right? I just switched from Android for security primarily. The rest is a bonus. The problem is smartphone becomes a single point of failure. If it gets stolen I can't even work without authentication apps. reply throwaway81523 10 hours agorootparentSealing electrical stuff from water is literally 19th century tech. Plenty of underwater flashlights exist even today. If they just lose the obsession with thinness in phones, almost every other problem becomes trivial to solve. Instead they make the ultra thin, breakable phone, and then users put it in a protective case which eliminates the thinness anyway. reply argsnd 10 hours agorootparentThin phones are good. This is a thing you carry around in your pocket all day, you’ll notice almost every millilitre thicker and gram heavier it gets. reply throwaway81523 8 hours agorootparentThat's what Steve Jobs used to say and that's why Apple phones were 3.5 inches until he died. Who uses a 3.5 inch phone now? In fact small phones basically don't exist anymore. There were credit card or cigarette lighter sized phones that weighed under an ounce but they were 2G GSM, so now they are e-waste. There is nothing to replace them. Meanwhile the Unihertz Tank 2 weighs about a pound (22,000 mAH battery) and it's imho attractive, except too expensive. reply birksherty 7 hours agorootparentprevWhat? Phones are getting bigger and bigger that people can't put them in pocket now. reply j_maffe 8 hours agorootparentprevBut don't people use phone cases anyway to protect these fragile devices? what's the point then? reply meindnoch 6 hours agorootparentX mm phone + Y mm case >1. Does it really matter if you have a 16mm or 17mm phone + case? reply RandomThoughts3 9 hours agorootparentprevYour post doesn't make sense. A commenter complains that Apple uses a lot of adhesive inside their phones so they are not really a thing of beauty. Someone replies that it's because of water proofing. Another person points out that, no, actually plenty of companies make waterproof phones without using glue so Apple could. You tell them to go buy other another phone. How is it in any way related to beautiful design, waterproofing and glue use in manufacturing? reply balls187 14 hours agoprevThe technical skill of the modder is unreal. That said, imagine that is Israeli security service removing and replacing the nand storage. EDIT TO ADD: Pointing out how a determined state-level attacker could pin-point a single individual. reply RandomThoughts3 9 hours agoparentReality sadly goes much further than your imagination. Dumping without desoldering, reflashing in place, generally speaking if you think it's theorically possible, someone probably have tried. If they have your device, you have already lost. reply jeroenhd 8 hours agoparentprevSupply chain attacks to computers have been documented in various countries. I don't think attacking the iPhone's NAND is practical, though, as it would also need to somehow bypass the signature verification system of the CPU, and even then everything on the chip would be encrypted before it hits the flash. It's possible that there are bootloader exploits, but fortunately you can't beat these devices as easily as you can on PC. reply xp84 13 hours agoparentprev> removing and replacing the nand storage. But... with this kind of removal, what would these government agents gain besides a free blank phone? reply srockets 13 hours agorootparentWe know, from multiple leaks, that clandestine services from multiple countries, including the US and China, have supply chain attacks, where they intercept computing equipment and install hardware backdoors into it. Intercept an iPhone, replace the 128GB storage with a 128GB storage and some extra rootkit. Or anything else really. reply wtallis 13 hours agorootparentIf you can bypass Apple's secure boot, you probably don't need to do a complete swap of the physical storage medium to get that rootkit installed. reply teaearlgraycold 13 hours agorootparentprevReplace it in the box with hardware-level malware installed. reply curiousgal 13 hours agoparentprevWhy pin point a single individual? They can just boobie trap a whole shipment of iPhones and let them hit the markets. Terror's a numbers game! /s reply cudgy 19 hours agoprevJust watched this at 2x speed and the precision/stability of the hands is remarkable, especially when extracting the tiny foam gaskets. reply RankingMember 15 hours agoparentSeriously, made me think he was on beta-blockers or something to be so smooth. (insinuating PEDs were used for iPhone modding- we're through the looking glass here people. :P) reply naruhodo 15 hours agorootparentNah. It makes total sense that he was on Phone Enhancing Drugs. reply Alifatisk 9 hours agoparentprevHow do people watch videos at 2x speed? I don't know if it's just me but I can only do it for a couple of minutes before I stop following along. reply throwaway48476 9 hours agorootparent2x is slow, 4x keeps you on your toes. reply mensetmanusman 7 hours agorootparentprevThey are in a hurry to get to the next video that needs watching. reply benhurmarcel 3 hours agorootparentprevIt's a matter of getting used to. I raised it little by little and I'm comfortable at 3x in most videos now. reply kaashif 8 hours agorootparentprevUsually, if a video is too slow I find it frustrating and I'm more likely to stop watching or increase the speed. It's not like I'm actually following along with a screwdriver and iPhone so I don't need to watch it at 1x speed. reply mattmaroon 18 hours agoparentprevIt’s still impressive at 1x. reply deviation 14 hours agoprevIs there a hardware restraint for why he chose just 1TB? I'm seeing 2TB/4TB/8TB Nand Flash being sold online (the latter for a hefty ~$650). Is there anything stopping me from paying a professional like this to install an 8TB unit? edit: I see those NAND flash models are supported by Macbooks. Perhaps I am mistaken in thinking an iPhone could support it. reply smileybarry 6 hours agoparentMaybe it's a BIOS/firmware thing: replacing the RAM memory chips on a Steam Deck to 32GB total requires BIOS tweaks to recognize the chips. I assume in this case the motherboard may be trained to recognize up to 1TB, like the highest capacity model sold. 2TB+ may be too high density to \"just work\" out of the box. reply omgtehlion 11 hours agoparentprevCould you provide a link to 4TB in a single chip though? 2TB chips started appearing only this summer... reply presentation 9 hours agoprevAre there any manufacturers/standards that both pair parts to your phone (to make theft not worthwhile) but also allow authenticated unpairing of parts to your phone (to allow part reuse)? I am conflicted in that I like the idea of right to repair but I also like that locking things down helps fight phone theft. I imagine that something like this ought to be feasible: - the phone comes with a secret key baked into it - upon installation of parts, some secret generated from that key is baked into some secret enclave in the part to “pair” the part with your device so it can’t be harvested - the OS a provides a function to “unpair” a part with your phone that requires use of the secret key, so you can reuse that part elsewhere - parts are sold “unpaired” and therefore can be used with any phone (maybe via some open protocol to allow many manufacturers to provide parts, not just the OEM) reply a2128 2 hours agoparent> the OS a provides a function to “unpair” a part With your idea, if my phone gets damaged to a point I can't access that function anymore, all of its parts are non-reusable and complete e-waste. IMO a better and less complicated solution would be to blacklist the serial numbers when a phone is reported stolen, and phones can check serial numbers against a server (if offline just assume the parts are fine for now). Parts should be considered innocent until proven guilty, not the other way around. There's probably ways to break this system such as blacklisting the servers from your DNS and never connecting to any network other than your home, but it makes the phone much less practical to use and it only takes one slip-up for the phone to brick itself reply WmWsjA6B29B4nfk 7 hours agoparentprevYes, iOS 18 reply hi-v-rocknroll 17 hours agoprevSeen this before with other models. 1 TiB is a factory option, so it's not like the days when Asian market hacks gave 4x or 8x what was available. reply Scene_Cast2 16 hours agoparentThere's also that video of a guy adding a headphone jack in a similar fashion. I was impressed that he found the internal room for it. reply interestica 15 hours agorootparentI never understood why this was always seen as such a constraint. It’s three (or four) pins! It doesn’t even have to have the “hole” form factor. You could have them all in a straight line and then place a headphone jack AGAINST them. I always thought a magnetic TRRS set of pins along the side of a phone could work. Add a sleeve to the connector’s side too. Heck you could standardize a flattened TRRS or whatever that would still slip readily into a typical jack. reply bmicraft 4 hours agorootparentWhen you already need an adapter you might as well use the usb-c connector. reply grishka 14 hours agorootparentprevThat was on the iPhone 7. Its internals really look like the decision to omit the headphone jack was made pretty late in the development cycle, so they replaced it with a useless piece of plastic. reply daemonologist 15 hours agorootparentprevPossibly Strange Parts: https://www.strangeparts.com/bringing-back-the-iphone-headph... reply paxys 16 hours agoprevI wonder what happens if you increase the storage beyond what is offered by Apple in one of the models. Will it just work as normal with 2TB/4TB/8TB? Or will the OS realize that something funky is going on and try to restrict it? reply dagmx 16 hours agoparentStorage controller for the NAND is on the SoC so it only works for specific configurations of NAND. Assuming it followed the pattern of the M series Mac’s. reply herpderperator 14 hours agoprevI started watching this and as someone else commented, yeah, things looked doable at the start and then got progressively more impressive and insane. It's clear they know what they're doing. From the extremely intricate tools for each and every specific step, to the screwdriver that tightens only the exact amount when putting things back together, to - what! - CNC milling off an entire component?! I was so impressed. Surely their day job must be in some way related to assembling this phone? reply amelius 11 hours agoprevI just don't understand why people would want to keep supporting a company that is actively holding customers back in countless ways. reply asp_hornet 10 hours agoparentBecause i really dont want anything to do with google and there is really only 2 choices. reply piva00 10 hours agoparentprevThe competition doesn't provide a product package that is superior for everyone's use case, so Apple users balance the trade-offs and decide they prefer Apple's products even with its caveats? It's not like Pixel + Android, Samsung + Android, etc. produce objectively better products in every way. reply dadarecit 9 hours agoparentprevit works better than the offerings from competition, and Apple isn't beholden to China. reply GaryNumanVevo 6 hours agoparentprevFor me, I can buy a phone that works and will work for 6-8 years with software updates. I'm on my second iPhone, an 11 pro, that I've had for 5 years at this point. I have to use an Android phone for work and we replace them every two years as the security updates stop. reply Ecco 7 hours agoprevWhat is the white powdery/smokey stuff he drops on the eMMC chip using the soldering iron at 7min27s? Some kind of flux? reply beeforpork 6 hours agoparentYes, it is flux (solid rosin). He vaporizes some with the iron and the smoke resolidifies on the contacts, so there is a very thin layer of flux to help with the soldering. reply Ecco 6 hours agorootparentInteresting, I’ve never seen this before. How does it compare to regular gooey or liquid flux? Also how does it work? Just bringing a chunk of rosin next to a soldering iron would just vaporize the flux as seen on the video? reply xattt 6 hours agorootparentMy grandfather who learned electronics work in the USSR worked with solid rosin. When you touch the iron with the rosin, it starts smoking like incense at a church (same stuff actually), but a small amount remains on the tip. You transfer this to the contact you’re soldering, dip into the rosin again, and then solder as usual. reply exabrial 14 hours agoprevWow it's almost like they should put an... sd card slot. reply xp84 14 hours agoparentWhat a heretical idea. Surely all storage should be soldered down to the logic board, for security. reply sneak 13 hours agorootparentFor watertightness, more accurately. reply callalex 13 hours agorootparentWhat about the dozens of phone models that have SD slots and waterproof ratings? Please don’t unquestioningly regurgitate propaganda. reply thebigman433 12 hours agorootparentWhat are some examples of phones with SD card slots and similar waterproof ratings? A quick google search didnt turn up much reply throwaway81523 10 hours agorootparenthttps://www.gsmarena.com/samsung_galaxy_s5-6033.php Samsung Galaxy S5 from 2014. Headphone jack, SD card slot, and swappable battery. IP67 water resistant. Almost everything since then has been a regression. You can get a Nikonos V underwater film camera around $300 on ebay these days too. Designed by Jacques Cousteau in the 1960s, can shoot under 150+ feet of water, and is supposedly a good all-around rugged outdoor camera as well. I'd sort of want one but I haven't used any of my film camera gear in years. reply GaryNumanVevo 6 hours agorootparentAny phones that aren't a decade old? reply foldr 10 hours agorootparentprev>After every charge and boot sequence, the [Galaxy S5] reminds the user to preserve the IP67 rating by securing the back cover and making sure the USB flap is closed. Nobody wants to faff around with this stuff just in case today's going to be the day that they drop their phone in a puddle. reply ttrmw 8 hours agorootparentNo doubt, but we're 10 years on, if we'd carried on down the path of swappable storage we'd probably also have solved these minor ux things - no USB flaps on modern waterproof phones f.ex reply jeroenhd 8 hours agorootparentprevMicroSD cards go into the same slot the SIM cards go into. Unless Apple stopped taking SIM cards, there's going to be a bit that takes a sliver of plastic and metal. Clearly, Apple has already solved this problem, they just choose not to add the design complexity (and frankly, damage to their popcorn pricing model) of a microSD slot. reply sneak 5 hours agorootparentApple has stopped taking SIM cards in US devices. Only the iPhones sold in Europe still have sim slots, and I assume those do worse in immersion testing. reply trompetenaccoun 7 hours agorootparentprevA compromise would be having a slot inside the case. But we all know why they don't have any option to increase the storage to begin with. \"That'll be an additional $500 for the upgrade please.\" reply cenamus 12 hours agorootparentprevThey're in the same tray as the SIM card, you don't see people crying for esims because of waterproofing. And a simple gasket around the port is enough for the IP68 or whatever kind of rating the iphones and co have nowadays reply n_plus_1_acc 10 hours agorootparentprevOver 500 results here https://geizhals.de/?cat=umtsover&pg=1&v=e&hloc=at&hloc=de&s... reply exabrial 36 minutes agorootparentprevare you actually serious or are you joking? reply kasabali 6 hours agorootparentprevGalaxy S20? reply swarnie 13 hours agoparentprevWow, slow down there Charlie. Save some innovation for the iPhone 16 AI max plus. reply danbruc 8 hours agoprevIf you find this interesting you might also like repairing graphics cards and with that I mean stuff like fixing traces on the inner layers of the board. I just picked the first search result [1], not sure if that one is especially interesting or not. [1] https://www.youtube.com/watch?v=XwNB4uD5Pts reply jsheard 20 hours agoprevAny ideas how much that 1TB NAND chip costs? Significantly less than Apples $500 premium for the 1TB SKU I'm sure, but how much less exactly? reply NikkiA 19 hours agoparentA single 8Tbit NAND is about $130 in single quantities. reply throitallaway 10 hours agorootparentWhy use bits here when storage is usually measured in bytes? 8 Terabit == 1 Terabyte. reply jeroenhd 8 hours agorootparentThe industry uses bits rather than bytes. If you buy 1tb NAND from a factory or NAND dealer, you're going to get 128GiB (or perhaps even 125TiB) of storage. The conversion to bytes generally happens the moment products start being offered to end users. reply fragmede 10 hours agorootparentprevbecause that's what the underlying NAND chips the actual storage is made up of, are measured in reply 7speter 20 hours agoparentprevTerabyte nvmes selling for 60-80 dollars these days, and thats much higher than the prices last year. You’d be best off getting the top stuff though, I doubt Apple is using Chinese QLC, or bottom binned TLC. reply jsheard 19 hours agorootparentI suppose 2230 NVMe drives are probably the best proxy because those use a single very dense NAND chip similar to the one in the iPhone. Those are around $100 for 1TB TLC, but that includes the NVMe controller and retail markup. reply NikkiA 19 hours agorootparentThey're also using bulk pricing for the IC though, single quantity from digikey is around $130 https://www.digikey.com/en/products/filter/memory/774?s=N4Ig... reply bigbones 19 hours agoprevProbably a dumb question, but what are the 3 taps for after screwing each screw? I presume they are tapping the screwdriver itself? reply typeofhuman 17 hours agoparentThey're using a torque screwdriver, which ensures tightening to a specified torque to prevent excessive tightening. The \"clicking\" is made by the clutch that disengages once the preset torque has been reached. reply randmeerkat 19 hours agoparentprev> Probably a dumb question, but what are the 3 taps for after screwing each screw? I presume they are tapping the screwdriver itself? I think it’s a torque screwdriver. reply ipython 16 hours agoparentprevIt’s a torque screwdriver as others have said but to me it made the whole video into an asmr experience. reply dishsoap 19 hours agoprevI wonder what the reasoning is for grinding off the old chip instead of desoldering properly? Maybe the heat would damage something? reply jsheard 19 hours agoparentIt's hard to see but the original NAND is epoxied to the motherboard, which wouldn't come away easily with heat. I'm not sure what the purpose of the epoxy is but he goes to the trouble of replacing the epoxy later in the video so there must be a good reason for it. reply Retr0id 19 hours agorootparentThe epoxy protects from physical shocks and also helps manage the effects of thermal expansion, either of which could crack solder joints over time. reply jsheard 19 hours agorootparentAh, not taking any chances after bumpgate. reply Retr0id 19 hours agorootparentApple has been epoxying BGAs at least as far back as the iPod nano 1st gen, released in 2005 reply NavinF 17 hours agorootparentprevIt's called \"underfill\" and it's common for BGAs since the chip doesn't have the same thermal expansion as the PCB reply matthewfcarlson 17 hours agorootparentprevI’ve seen some fascinating slo mo videos of devices bouncing from a decent fall in an X-ray machine. The battery in particular squishes way more than you think should be possible or right. Epoxy makes a ton of sense when you consider the shock that it takes. reply Retr0id 19 hours agoparentprevThe chip has an epoxy underfill. It softens slightly in the heat and desoldering is probably possible, but the amount of force required means you're likely to damage something in the process. reply jampa 15 hours agoparentprevFrom the creator, in a reply: \"CNC is the safest and most efficient way. Using a hot air gun to remove it normally will cause irreversible damage to other components on the motherboard.\" reply lofaszvanitt 12 hours agorootparentYet, he uses hot air gun to solder the new chip. There are ways to safely remove that old nand chip, but why would they show the state of the art methods? reply rcarmo 11 hours agorootparentThe epoxy below the original chip would require a lot more heating to remove than soldering in a plain chip. reply xnyan 19 hours agoparentprevCNC drill removal is safe and can be done consistently by a machine with consistent predictable results. reply namuol 17 hours agoprevShame that the existing NAND has to be turned to dust. Gone are the days of upgradable hardware. reply RandomThoughts3 9 hours agoparentIt really is a shame no one has ever successfully added some form of small scale extendable storage to a phone that Apple could have copied so they are entirely forced to upsell you a phone 500$ more expensive so you can get extended storage at a five fold markup. Surely, if it was the case, customers would never stand being taken for such fools and would do something. /s On a more serious tone, I hate Apple for the way they do their products segmentation. It's for me the best proof that the market is not competitive enough. Multiple screen support forcing you on the pro line, decently sized storage requiring you fork 500$, the stuborn refusal to allow tablet users a proper interface to not canibalize the laptop sales, it's outrageous what Apple can get away with. Not that their main competitors are shaking the boat much mind you. Oligopolies are awful. At least, you can now record video directly to a usb-c connected hard drive but only in ProRes and no luck for photos (because f*** you that's why). reply jervant 19 hours agoprevI was sure this was going to be a dosdude1 video, he's upgraded the flash on a lot of things https://youtube.com/@dosdude1 reply rsktaker 14 hours agoprevI'm astonished that it works! To my understanding, the 128GB has specifications for how to \"talk\" to it on its datasheet and same with the 1TB. Do they have the same manufacturer for them to have the same pinout? And, how come they're the same size lol. Intuitively, I'd expect the 1TB to be way bigger. reply mastax 13 hours agoparentGenerally most memory uses standardized physical/electrical/firmware interfaces from JEDEC, an industry consortium. I do not know for certain if the iPhone memory is standard. Mobile RAM/Flash packages are usually made in larger capacities by stacking several dies within a package. This can involve die thinning - grinding the dies thinner so they fit within the same space after stacking. reply shultays 9 hours agoparentprev1TB storage comes from another donor iPhone apparently so it makes sense it just fits and works. I guess Apple didn't think of matching them to specific motherboards so you can still reuse them reply mensetmanusman 7 hours agorootparentDid they reassemble the cnc dust to get the donor 1TB? reply shultays 4 hours agorootparentFor donor phone, they probably kept 1TB NAND intact but CNCed away the rest of phone reply KolmogorovComp 10 hours agoprevIs this economically viable or just a show-off? Because considering the skilled labour and equipment, I’m not sure it’d be much cheaper than the $500 upgrade. reply throwaway48476 9 hours agoparentIt's not economically viable because the NANDs come from donor systems. Apple prevents the NAND oem from selling to anyone but them. It's part of their anti right to repair strategy. reply bmicraft 4 hours agorootparentAre you sure? Why would he need to reinstall the OS then? reply throwaway48476 1 hour agorootparentBecause there's a good chance that NAND came from a Mac and 1/4 of macos isn't going to boot on an iPhone. reply shultays 9 hours agoparentprevI don't have an answer but you can upgrade your existing phone you already bought using that method/service. Otherwise cost of official \"upgrade\" is $500 and a new iphone reply kernal 12 hours agoprevIn part 2 he reassembles the 128MB memory chip dust and solders it in a 32MB iPhone. reply hiatus 19 hours agoprevI can't believe they had to grind the memory chip off. I would have expected reflow work or something. Incredible. reply sda2 20 hours agoprevthis makes me feel better about paying for a 512GB model. reply brunorsini 12 hours agoprevThis dude has more manufacturing skills than most countries. reply kccqzy 19 hours agoprevDoes anyone know what's the purpose of the foam that's being removed at 3:50? Is it for waterproofing? reply ssl-3 18 hours agoparentMy first thought is acoustics. Empty spaces are resonant spaces, and this can be heard when the phone's speaker(s) are playing sounds and/or the microphones are microphoning. Mechanically damping resonances is always superior to handling them with DSP -- a DSP doesn't need to account for resonances that simply aren't problematic to begin with, freeing it for other duties. Such resonances can also be heard when handling the phone -- even when it is off. Tapping on the phone and hearing/feeling a dull, well-damped thud inspires more of a perception of solidity than a lingering resonance does, even though such foam itself contributes nothing to to the structure of the device at all. reply jwells89 16 hours agorootparentEven back in the iPod days, one of the stated goals of the designers at Apple was to make their handhelds feel like a singular piece, like something that naturally grows that way (think fruits, crystals, etc) instead of disparate pieces tenuously held together. An impression of solidity falls in line with that idea. reply userbinator 14 hours agorootparentFruits. Yet if you gently tap on a biological apple, a ripe one actually feels slightly hollow inside. reply xnx 19 hours agoparentprevMultiple purposes I suspect: Reduce vibration, even out thermals, etc. If water has gotten to that foam, something has probably gone very wrong. reply slicktux 20 hours agoprevThat is some craftsmanship! reply krick 11 hours agoprevCool, but hardly it was cheaper than just buying iPhone 16 Pro 1TB storage option. reply tibbon 16 hours agoprevI've wondered for a while if the 'non user upgradable' Macs were actually upgradable with enough effort. Seems so! reply xp84 13 hours agoparentEven the ones with non-soldered NAND can't be upgraded by anyone besides Apple. The NAND chips are serialized or something. https://www.youtube.com/watch?v=xEwS_VGD2yY&t=620s reply wtallis 13 hours agorootparentThat's a bullshit video. The guy conducting the tests doesn't know enough about how SSDs work or about how Macs boot to be drawing conclusions, especially not such strongly negative conclusions. He would have had to at the very least attempt a tethered restore from DFU (as is done for these phone storage swaps or any other situation where the NAND is blank or thoroughly corrupted) before concluding that Apple has everything totally locked down. Adding the second drive module is something that we should not expect to work the way he tested it. Plugging in a second hard drive to a desktop does not magically give you a RAID-0 without extra steps; expecting this from SSDs doesn't make any more sense. And without reverse engineering the machine config from the quoted prices, we don't even know if the two modules had the same capacity, let alone the same type and manufacturer of NAND (which is probably important if the system is going to treat the two modules as one SSD instead of exposing them to the OS as one drive). reply jeroenhd 8 hours agorootparent> Adding the second drive module is something that we should not expect to work Hard disagree. This approach works for just about any normal storage medium. Apple decided to Think Different about where the SSD controller lives and works and how storage pinouts work, but their weird approach wasn't publicly documented anywhere until people like this guy started trying. Uninitialised storage would've normally showed up just like that, as uninitialised storage, ready to be partitioned. Instead, the device didn't even turn on, let alone show the added flash storage in a partitioning tool. reply wtallis 3 hours agorootparentYou're still thinking of the storage modules as standalone SSDs to be managed by software, rather than devices hidden behind hardware RAID. I did almost exactly the same kind of drive-swapping tests with the WD Black AN1500 [0] in an Intel PC, with the same results in terms of whether the system can boot from the device, but none of that supports the conclusion that Western Digital is locking down what drives can be used behind that RAID controller. You can swap drives on the AN1500, but almost any such operation will require you to erase and reinstall. [0] https://www.westerndigital.com/products/internal-drives/wd-b... reply throwaway48476 9 hours agorootparentprevConfusion is understandable here because such technicalities were not officially documented and the community had not figured it out at such an early point. reply asdz 19 hours agoprevcan anyone explain why they have to grind off the old chip? (instead of unsolder it) reply ykl 18 hours agoparentThe old NAND chip is epoxied in (they reapply the epoxy on the new NAND chip too after installing later in the video). reply Brosper 20 hours agoprevHow much does it cost? reply Ringz 11 hours agoparentI don't know if anyone can offer something like that seriously. And I don't mean it badly. Technically, a conversion including warranty would certainly be possible. But would it work commercially? reply nodesocket 13 hours agoprevInteresting the USB-C connector has A3294 China engraved into it. My production US version of 16 Pro has no such engraving. reply secondcoming 7 hours agoprevI'm surprised Apple didn't hardcode the NAND capacity based on the model number, so even though he installs 1TB it'll still only allow 128GB to be used. reply sroussey 20 hours agoprevMore capacity and faster. reply xyst 17 hours agoprevImpressive work on undoing the Apple engineering and unnecessarily soldered component. The CNC grinding guarantees this is out of reach for many people. The blatant greedy decisions Apple makes is what has turned me away from their devices in general. Been winding down my usage for a few years now and aging out my current devices. reply lofaszvanitt 11 hours agoparentCNC not needed, they just F with users... User capture+lock in. I mean every sane minded person runs away from the iphone ecosystem when the first how can I get this file out from my phone and why it's such a mess experience kicks in. reply wtallis 14 hours agoparentprev> and unnecessarily soldered component Seriously? Do you want a M.2 card slot in your phone? reply userbinator 14 hours agorootparent(micro)SD/TF, many phones still have one. reply wtallis 13 hours agorootparentAll of those phones still have soldered storage as their primary storage. Removable primary storage isn't really a thing for smartphones, so calling it an \"unnecessarily soldered component\" is an extraordinary claim presented without any evidence. There's no standard removable storage form factor that's small enough to use inside smartphones that offers adequate performance for what's typical of today's smartphone operating systems and applications. microSD cards are fine for storing photos and videos (more for reading than sustained writing), but are horrible for random access and the performance gap between microSD and the soldered primary storage in phones is only getting wider. reply Ringz 11 hours agorootparent> There's no standard removable storage form factor that's small enough to use inside smartphones that offers adequate performance for what's typical of today's smartphone operating systems and applications. The question is why? I doubt that there are technical reasons. reply wtallis 10 hours agorootparenthttps://en.wikipedia.org/wiki/Universal_Flash_Storage#Versio... Looks like the UFS card interface only has one lane, but phones have been using two lanes for more performance for a long time. Samsung is planning a four-lane UFS solution for next year, but it's not clear whether that's intended for phones or laptops (their Snapdragon X Elite laptop uses UFS rather than NVMe). And the removable UFS cards standards have tended to lag behind by a few years on link speed, so it's really a 4x discrepancy in bandwidth between soldered UFS and removable UFS cards. In theory, something like UFS cards could have performance parity with soldered UFS (at least for the link speed; not sure if a package that small is adequate from a power/thermal perspective when stuffed with 1TB of NAND). But UFS cards have been dead on arrival in the market several times now, so it's understandable that nobody wants to try an even more ambitious version in the hopes that it can finally catch on. reply jeroenhd 8 hours agorootparentI think UFS might catch on if Samsung started cooperating with Samsung and Samsung to build a Samsung phone that would take Samsung UFS cards. Alas, I fear this can never happen, as Samsung wouldn't want Samsung's products to compete with their own storage tiers. The problem with microSD vs UFS is that microSD is actually more than fast enough for most use cases if you buy good cards. Random I/O on SD cards is rarely a requirement even of phones with SD cards in them. Most of the time it's just bulk writing or reading video files and downloads. reply leonewton253 8 hours agoprevImagine messing up the 1 TB NAND install and having to grind it to dust....owch. reply sergiotapia 19 hours agoprevphone storage hasn't mattered to me in years, what do you guys need the huge storage these days? the bulk of my data in the past was photos and videos, but now those are uploaded to the cloud and i instantly delete from my local phone. reply vachina 16 hours agoparentYour media is more valuable when stored locally, because they can be retrieved easily without waiting for network conditions. reply mise_en_place 18 hours agoparentprevRemovable storage should come standard with any mobile device. It's ridiculous to have to do these kinds of methods to increase storage. reply lofaszvanitt 12 hours agorootparentNext EU regulation incoming. reply randmeerkat 18 hours agorootparentprev> Removable storage should come standard with any mobile device. Removable storage should come standard with any device. reply renewiltord 17 hours agorootparentSadly, Black and Decker no longer offers the Hammer + SD card combo deal. reply randmeerkat 17 hours agorootparentTouché reply sneak 13 hours agorootparentprevThe iPhone Pro supports high speed external removable storage via the USB-C port. I plug a thumb drive into my iPhone 15 Pro Max all the time. reply devsda 14 hours agoparentprevIf you have the know how and the discipline to maintain proper backup strategy, then local storage(@ home) always wins over cloud in terms of pricing, flexibility or freedom. reply relaxing 17 hours agoparentprevI’ve done the math on whether it’s cheaper to pay for 1tb of local storage or 1tb of cloud, and local wins. reply eddy_chan 15 hours agorootparentWhat about for a whole family of iPhone users? I've got the 2TB cloud plan which my elderly parents are on, my kids are on and me and my wife are on which is letting us get away with the smallest class of storage for each device we have. reply skeaker 1 hour agorootparentFair question! To figure this out, you could calculate the price per GB that you're paying and that you would pay for local and compare the two values. Cloud storage can and often does have a better deal in instances like yours! With that said, your instance is just your instance, and for swathes of people it will be cheaper to have local storage. Them having the option of local storage wouldn't hurt you, so I would hope for their sake you would still support giving them that choice. reply baq 11 hours agoparentprevIf you're shooting photos raw, it matters. (I don't know anyone who insta-deletes photos from their phone even if they don't shoot raw.) If you're shooting prores video... you have a portable usb-c jbod array, so I guess it doesn't matter indeed. reply Unearned5161 18 hours agoparentprevI like having things stored locally. I'm not always in a spot with great reception, so waiting for a video to load from google photos or whatever isn't an option. reply dyauspitr 18 hours agoparentprevI don’t want to hand over my pictures to a 3rd party. reply NavinF 17 hours agorootparentWhy not? The major player in this space (icloud) can do end to end encryption and it's easy to do local backups on your NAS reply dyauspitr 49 minutes agorootparentWith all the celebrity leaks, hundreds of them (remember the fappening?), I don’t believe the encryption is the problem. It’s usually social engineering or cracking a password that leads to these leaks. reply realityfactchex 17 hours agoparentprevLocal LLM models can be many GBs each. One can have many of them. reply wtallis 14 hours agorootparentIs that something you actually do with your phone? reply userbinator 14 hours agorootparentLook at all the hype around AI assistants lately. Having those run locally is definitely much better from a privacy perspective. reply wtallis 13 hours agorootparentMany models of many GB each on a phone with only 8GB of DRAM doesn't make sense. Even on Android phones that have more DRAM than that, there's not enough performance for large models to be useful, let alone multiple models consuming tens of GB of storage. reply realityfactchex 11 hours agorootparent> Many models of many GB each on a phone with only 8GB of DRAM doesn't make sense. > there's not enough performance for large models to be useful For iPhone, the Private LLM app offers 44 models in its easy-install menu right now (on 15 promax), with avg model size about 2.7 GB. Total GB is ~120 GB to install and compare them all. People could argue about what being useful means, but asking these different models the same question can give quite different (and indeed thought-provokingly different) results. They all have either different foundations or different fine tuning or something. The same prompt gives rather different answers depending on what model you pick. It's fun that way. So to compare their outputs, one would need 120GB free at once, then install them all, or else do some very inefficient and weird dance of uninstall-then-reinstall n times while picking and choosing which ones to try out for a given prompt. And that's just for one offline \"gen AI\" app. There might be others. This can be done offline, while on a walk, or whatever, without hitting any servers at all, in the palm of one's hand. Performance is good enough on iPhone for a bunch of tasks/prompts. So, IDK. Does part of that not make sense? These models not being run run at once, and don't need to be in RAM at once. They're being stored on disk at once to be used when wanted. They initialize one at a time when in use. The large disk size is for storing the models. The phone can then use the models when wanted. (Granted, it's not the \"same\" as hitting huge versions of the models sitting on some beefy infra, but we're talking about mobile devices here and actual current uses for having a bunch of local storage available on them.) reply wtallis 3 hours agorootparentSo what I'm hearing is that you don't have a use case for having 44 LLMs on your phone simultaneously, aside from testing different LLMs for the sake of testing different LLMs. There's no way a user would want to keep all 44 LLMs around indefinitely; nobody could possibly remember which one they prefer for which type of query across that many models. I can believe there are uses for having a handful of models around and for trying out new ones when they become available, but I can't see many users bothering to thoroughly evaluate dozens of models at once. reply skeaker 58 minutes agorootparentWe're getting away from the point. What does it matter what the specific use case is? Who are you to be the arbiter of a valid or invalid use case? This one guy didn't justify himself to fulfill your arbitrary personal requirements; I guess that means nobody should even have the option of removable storage and that we should all be okay with paying an extra few hundred dollars for five more gigabytes of space on our phones (or whatever the insane going rate is now). reply realityfactchex 14 hours agorootparentprevYes, and it's awesome. reply xenospn 11 hours agoparentprevI have a lot of music on my phone. When I’m not in the US (I travel a lot), streaming music will eat up all of my data. reply m463 19 hours agoparentprev...as planned by apple Can you do this without apple managing your data? (it would be really nice to have a personal icloud replacement) reply eightysixfour 17 hours agorootparentYou can self host Immich for a photos replacement, including some of the neat machine learning tricks. reply sergiotapia 18 hours agorootparentprevi use android and google photos because it's really cool to auto match faces of my friends and family. but think about it, how crazy that someone can steal your phone and you would be totally fucked, priceless memories lost forever. now with cloud that's a non-issue no? reply paxys 18 hours agorootparentIt doesn't have to be one or the other. Apple/Google can permanently lock you out of your iCloud account at any instant. You can only be sure of access to your data if it is physically on you. reply fragmede 18 hours agorootparentAnd if you encounter pickpockets or get mugged, you won't have access to that data either. And don't forget to worry about natural disasters taking out your home. reply paxys 18 hours agorootparentWhich is exactly why you should have a local copy and a cloud backup. reply 6510 16 hours agoparentprevthis consumes bandwidth, battery and cpu(?) reply paxys 18 hours agoprevLive reactions watching this video: Remove two screws from the bottom of the phone – easy, I can totally do this! Soften the glue and pull out the back – hmm, I guess it's doable if I can find replacement glue. Disconnect dozens of cables and parts – wow, it's going to be hard to remember how everything goes back together. Peel off protective foam from motherboard – is it even possible to replace this stuff? CNC grind the existing 128GB NAND to dust – I should probably stop watching now... reply israrkhan 17 hours agoparentI was also blown away at CNC grinding step. Perhaps he did it because heat gun would have impacted other parts of the PCB. With grinding the impact was limited to Nand chip only. He eventually had to use heat to cleanup the residue. reply Joona 14 hours agorootparentIt's more so the 128GB package is not worth that much, so it's easier to just delete it. reply nine_k 13 hours agorootparentYou also need to be pretty precise with attaching the phone in an exact position, and grinding things with a very low margin of error, say, 0.05 mm along the vertical axis, in order to remove the chip but leave the PCB intact. Not for the faint of the heart. I suppose they have had several training rounds using badly broken phones first. reply johnwalkr 10 hours agorootparentThat's trivial for a machinist to check before starting the milling operation though. reply nine_k 7 hours agorootparentYrs, as long as the milling machine is adequate. Hobby-level CNC devices may have harder time doing that, and pro / industrial devices cost many times the iPhone. reply justinclift 8 hours agorootparentprevCould even be automated if they have probes handy. :) reply duskwuff 11 hours agorootparentprev> I suppose they have had several training rounds using badly broken phones first. Can't be very many of those yet. The iPhone 16 only became available for sale last Friday. reply tobyhinloopen 11 hours agorootparentObviously he meant other broken phones, like older models or other brands entirely reply nine_k 7 hours agorootparentYes, the flash chips are approximately the same in their mechanical properties. Milling speed, debris removal, depth of milling to keep the PCB intact, treatment of the PCB.afterwards to clear it and attach another chip. It all is best done several times on dead bodies before attempting a modification of the expensive target phone. reply rickdeckard 11 hours agorootparentprev> Perhaps he did it because heat gun would have impacted other parts of the PCB Most of all the components on the other side of the PCB. Even if the NAND was not additionally covered in resin, due to the large amount of contacts (and probably large amount of grounded pins, which dissipate heat faster), alot of heat would be needed. More than the smaller components underneath need to just fall off then... reply foldr 10 hours agorootparentThe components underneath shouldn't fall off. The surface tension of the solder should be enough to keep them in place. (That's how it's generally possible to reflow solder components to two sides of a board.) Of course, reflowing the components in an ad-hoc way is quite likely to cause other problems, so it's probably still a good idea to avoid it. reply omgtehlion 12 hours agorootparentprevWith only hot air you would need a lot of heat and pulling, potentially displacing other parts nearby, because it seems like the nand flash is not just soldered, but additionally glued with some kind of adhesive. reply godelski 14 hours agorootparentprevFwiw, you can get a desktop CNC for a few hundred dollars (I mean they're very similar to 3d printers in design). You can get pretty good ones for under $5k. But yeah, getting that chip off with just heat looks pretty hard without affecting anything else. I'd still want a heat sink to pull away heat from other parts but I'm not at this skill level and overly cautious. But this does look doable. And since it's HN, I do encourage everyone to give more repair a go. Things like micro soldering are easier than you think. And remember than your phones can be turned into servers (raspberry pi? How about my old nexus?). Though I'd love to hear if people know how to do this stuff on iPhones because I plan on switching over. I guess no more bash scripting for automatic backup of all my photos and stuff to my server :'( someone please tell me there's a way )': https://all3dp.com/1/best-cnc-router-desktop-cnc-machine/ reply xp84 14 hours agorootparent> Though I'd love to hear if people know how to do this stuff on iPhones Very little in the realm of \"server\" or \"raspberry pi alternative\" could be done with modern iPhones despite even a 2-year old iphone being OP in terms of hardware for most home server tasks. They really work hard to prevent any use besides what's officially blessed by Tim Apple himself. Whether that's \"for your own good\" or not is a matter of opinion, I happen to think it's lame but don't want to debate it. reply godelski 13 hours agorootparentI'm not too worried about old iPhones since by then it's pretty likely to be jail broken and no issues there. I mean even if I brick it (and somehow can't recover; so, very unlikely) it was going to be e-waste anyways, right? As far as recycling goes, turning your old phone into a server is a big win. But I'm more interested in being able to use my current bash scripts that run on my Pixel. Backup is really the only important one since I can connect to my computers from anywhere to do anything else reply appendix-rock 8 hours agorootparentDon’t count on that. There are still holes where certain iOS version ranges or iPhones to this day do not have a jailbreak available. reply andai 8 hours agorootparentprevCan you still install Linux on them? That seems like what OP is actually looking for. reply The_SamminAter 14 hours agorootparentprevSome of us do do this stuff with iPhones, and it’s do-able, sort of - TrollStore (available up to iOS 17.0 currently) + NewTerm/bootstrap gives you a native CLI, add Filza in there and you can do almost whatever you need (with some manual work). I must admit, it’s much easier/potentially more functional on iOS 16 and earlier, but what can you do… Alternatively there is iSH or a-Shell. reply godelski 12 hours agorootparentI've been playing with iSH and aShell on my iPad. I'm not particularly happy with them and there seems to be a big lack of documentation (e.g. the `mount -t ios idintmatter dest` was quite odd and I think surprising to anyone that's terminally terminal) Idk if I'll feel comfortable jailbreaking a new 16, but yeah apple is fucking weird. ==== Apple engineers, I know you're here ==== What the fuck guys? I want to throw a match case into my ssh config based on the SSID of the network I'm on (I can't rely on IP being static). - Airport Deprecated. - networksetup Not associated with AirPort network - wdutil Not only requires sudo, but you redact the SSID. To a root user‽‽‽ - ioreg -ln Airport driverperl -lne 'print $1 if $_ =~ /IO80211SSID.*\"(.*)\"/;' Redacted - system_profiler SPAirPortDataTypeawk '/Current Network/ {getline;$1=$1;print $0\"tr -d ':'\";exit}' Takes 10 seconds to run but at least it fucking works and doesn't require sudo! What The ᵃⁿᵈ ⁱ ᵈᵒⁿ'ᵗ ᵐᵉᵃⁿ ᵗʰⁱˢ ˡⁱᵍʰᵗˡʸ FUCK ‽‽‽ Seriously! What is going on here? Why are you __hostile__ to shell users‽ I don't know how to tell you that knowing the SSID of a machine that you already have access to is not a security risk. Seriously, what is going on here? I have a dozen ways to do this on Linux and you redact it with a sudo command but not with a user level command? Come on..... Have some balls and stand up to your bosses reply wtallis 11 hours agorootparentTry `ipconfig getsummary en0`. It's instant on my machine and dumps plenty of info about the current state of the connection, including the SSID and BSSID. reply oarsinsync 12 hours agorootparentprevSplit horizon DNS can help you solve this for all services, not just ssh, and not be at the whims of Apple. reply godelski 11 hours agorootparentThanks, I didn't know any this. I'll look into it more. But I'm still just confused by the decisions being made over at Apple. I understand hand holding those who don't know much but they do realize that the reason their device is so common among engineers is because it's not too dissimilar from Linux, right? Why attack power users? What's being gained? That's what I don't get. reply oarsinsync 7 hours agorootparentI long ago concluded that the overlap with Apple products and power tech user desires was a happy coincidence, and/or a hangover of their past, rather than an indication of their future. The Mac is the exception in their current product lineup: every other platform is heavily locked down, and the user’s behaviour heavily restricted. I strongly believe the Mac is heading in the same direction. See the progression from run what you want, to optional signing of binaries, to right click to run unsigned things, to disable a setting to be able to run unsigned binaries; or “worse”, the way spctl and csrutil no longer function after deploying Sequoia. reply godelski 1 hour agorootparentI mean I hate Windows more and that's the choice unfortunately. I'd love a Linux arm book though. I do think part of the problem is not enough engineers asking their bosses why. Or not enough engineers thinking decisions through. I hope to god it's not a lack of engineers that are power users because that's even worse in many ways, but I wouldn't be surprised. reply autoexec 11 hours agorootparentprev> And remember than your phones can be turned into servers I wouldn't turn a cell phone into a server without also disabling the wireless chipsets somehow. Knowing that some unknown number of people working for your phone manufacturer, your wireless carrier, and Google or Apple have privileged access, including the the ability to remote into your phone at any time and add/delete/modify files and install software, without any notice or even indication to you that something has been done isn't the kind of security/privacy I'd want on a server. reply godelski 1 hour agorootparentFor an android, you can always just flash the ROM. It's also very easy to remove physical devices like radio. I'd also like some source on that deleting file part. These companies aren't spending money editing your software post security updates. reply jahnu 11 hours agorootparentprevI believe that this is actually possible, but I'm curious if there is there any hard evidence that it has ever been done? reply autoexec 10 hours agorootparentIt happens all the time on the OS/carrier/manufacturer side. I've personally seen settings reverted, software installed without notice, etc. It's a lot harder to say what any random cell tower in range is able to do but the chipsets are closed source and have their own OS. Manufacturers and carriers have had it in their terms of service that they can do it. Here's what tmobile had in their ToS: We may remotely change software, systems, applications, features or programming on your Device without notice. These changes will modify your Device and may affect or erase data you have stored on your Device, the way you have programmed your Device, or the way you use your Device. You will not be able to use your Device during the installation of the changes, even for emergencies. reply godelski 1 hour agorootparentOn a 5+ year old device that no longer has a data plan? T-Mobile's TOS doesn't apply during that time. Plus, you know this is about software updates, right? It's generic but that's what it's about. Yes, upgrading means removing files at times as things get refactored or become obsolete, but they're not going to touch your main data, not that software isn't shitty and accidents happen. reply cenamus 12 hours agorootparentprevWhile technically it would be a CNC machine, desktop CNC are really just routers, and for most of them even soft materials like aluminium push them, requiring crazy spindle speeds for the tiny endmills they can handle due to the limited stiffness. And those high speeds create horrible fine metal dust reply cfn 13 hours agorootparentprevYes you can but operating one CNC without major snafus takes some practice and selecting the proper bit and speeds for such a delicate operation isn't exactly easy. It is actually very easy to puncture the iPhone through and through. reply throwaway81523 10 hours agorootparentprevMeh, I replaced the battery in a 1st gen (2016) iphone SE, per the ifixit instructions. The home pushbutton didn't work afterwards. Repeated disassembly and reassembly didn't help. No useful advice on ifixit forum. Unclear what if anything to try next. Luckily the phone was long obsolete by then, so replaced. Repairability of these things sucks and I miss swappable batteries. reply RandomThoughts3 9 hours agorootparent> Repairability of these things sucks and I miss swappable batteries. They become mandatory in the EU after 2027 so I expect them to make a strong comeback at some point. reply Someone 11 hours agoparentprev> Disconnect dozens of cables and parts – wow, it's going to be hard to remember how everything goes back together We didn’t invent writing, drawing, and photographing for nothing. 1. Have small storage boxes numbered 1 through 1000. 2. Before and after detaching anything, take photos (multiple, if needed) 3. Draw arrow/circle/… indicators on the photos to help you remember what to look at. 4. Whatever comes loose, put it in the next labeled box. 5. Take a photo of the filled box and the tool(s) you used to detach that part. 6. When putting things back together, work backwards through your photos. reply fragmede 10 hours agorootparentwe live in the future, just start recording video of everything. You probably have an old cellphone you could use, and you'll wish you had more angles if you do end up being to go back into the footage for something reply Someone 9 hours agorootparentI think that would make it a multi-person job. Keeping the relevant part in focus while you’re manipulating the device distracts from figuring out what to do next. reply creshal 10 hours agorootparentprevI don't think a GoPro can focus close enough to take detailed enough pictures of tiny components like these. reply fragmede 10 hours agorootparentokay, edited to say old cellphone reply creshal 2 hours agorootparentDoesn't really adress the basic problem, most old phones (and many new phones) don't have the sort of macro autofocus you'd need to keep a video recording at a high enough fidelity to keep track of millimetre-sized objects. Looking at various youtubers, even with semi-professional gear it can be a multi-second struggle to focus on much larger pieces of mechanical devices. Do that for 20-30 steps and you need an assistant or two to not lose track of what you're doing, and spend an hour in post editing out all the times you side tracked fighting the camera. reply tibbon 16 hours agoparentprevI wouldn't have thought to do it, but after seeing it, i think I could do this on a Bridgeport. I'm only so-so at machining, but I can make a Bridgeport grind with great precision in a rectangle! reply exabrial 14 hours agorootparentI was actually thinking the same thing; a maintained milling machine can easily grind at those tolerances. Get your Z level be the most important so you don't cut too deep into the solder pads. The being said, I'm wondering if he used something like a cheap SainSmart CNC... sounded like a dentist drill reply cenamus 12 hours agorootparentEven so, the solder pads are surely at least like 0.05 to 0.1mm thick, across the size of the 2cm chip that shouldn't be hard at all to get level enough reply Summerbud 17 hours agoparentprevCNC grinding part is so wild, it took my several replay to understand what is that reply csomar 10 hours agoparentprev> Disconnect dozens of cables and parts – wow, it's going to be hard to remember how everything goes back together. It's not going to be hard. You won't even need to note where everything goes. The sizes of the cables/parts are different and as a result you'll be able to match them up. reply bubaumba 13 hours agoparentprevthere should be an audio socket hidden somewhere, you can open it by drilling a hole.... (old joke) reply txdv 14 hours agoparentprevIf you visit cities in China that are heavily invested in the electronics industry you could buy a cheaper iPhone 16 pro with 128GB and upgrade it to 1TB. But if you do that regularly, you probably have the money to buy the 1TB version outright. reply sfmike 13 hours agorootparentmake a friend there or friends with a booth worker and just ship it there talk over wechat shipping cost quite low reply faangguyindia 12 hours agoparentprevInb4 someone does it on a 4jaw chuck in a lathe reply factorialboy 10 hours agoparentprev> CNC grind the existing 128GB NAND to dust – I should probably stop watching now... Ah yes, Apple, the king of repairability! reply wojokix 12 hours agoparentprevhahaha yeah reply stevev 16 hours agoprevI’ll just spend more for the storage lol. reply brailsafe 19 hours agoprev [–] Now do the ram inside an M1+ SoC reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The iPhone 16 Pro now offers storage expansion from 128GB to 1TB, sparking interest among tech enthusiasts and modders.",
      "The video showcases the technical skill required to replace the NAND chip, highlighting the precision and stability needed for such modifications.",
      "Discussions revolve around whether using higher-grade NAND chips could improve performance and endurance, and the aesthetic and design quality of Apple's hardware."
    ],
    "points": 372,
    "commentCount": 257,
    "retryCount": 0,
    "time": 1727129516
  },
  {
    "id": 41631912,
    "title": "WP Engine sent “cease and desist” letter to Automattic",
    "originLink": "https://twitter.com/wpengine/status/1838350670564377051",
    "originBody": "Direct link to letter: https:&#x2F;&#x2F;wpengine.com&#x2F;wp-content&#x2F;uploads&#x2F;2024&#x2F;09&#x2F;Cease-and-De...Related article on TechCrunch: https:&#x2F;&#x2F;techcrunch.com&#x2F;2024&#x2F;09&#x2F;22&#x2F;matt-mullenweg-calls-wp-en...",
    "commentLink": "https://news.ycombinator.com/item?id=41631912",
    "commentBody": "WP Engine sent “cease and desist” letter to Automattic (twitter.com/wpengine)252 points by kevmarsden 18 hours agohidepastfavorite179 comments Direct link to letter: https://wpengine.com/wp-content/uploads/2024/09/Cease-and-De... Related article on TechCrunch: https://techcrunch.com/2024/09/22/matt-mullenweg-calls-wp-en... supermatt 1 hour agoWP Engine calls itself the worlds #1 wordpress hosting (with over 1.5m clients), but they aren't even in the top 10 material contributors to wordpress. Although they have pledged to support wordpress development, is is only to the tune of 40 hours a week. Their pledge is miniscule given their usage of wordpress and isn't even in the top 25 pledges made. It seems they were called out on this, and told to resolve it or it would get highlighted, and highlighted it was. Sure, the license allows them to do whatever they want, but there's nothing wrong with publicizing that they don't give much in return. With over $400M ARR, thats something they could easily resolve. reply tptacek 16 hours agoprevI'm not a lawyer, as you will soon realize. This is just water cooler talk, which is what HN is for. I sort of directionally think that if WPE had a strong case here, their opening bid wouldn't be a C&D (I've noticed C&Ds frequently include a \"preserve documents\" section, presumably as punctuation, but for what it's worth that's an implicit threat they might sue). The meat of this C&D seems to be a section towards the middle where they describe Mullenweg's keynote speech. It makes, according to WPE, these claims (numbers mine): 1. Claiming that WP Engine is a company that just wants to “feed off” of the WordPress ecosystem without giving anything back. 2. Suggesting that WP Engine employees may be fired for speaking up, supporting Mr. Mullenweg, or supporting WordPress, and offering to provide support in finding them new jobs if that were to occur. 3. Stating that every WP Engine customer should watch his speech and then not renew their contracts with WP Engine when those contracts are up for renewal. 4. Claiming that if current WP Engine customers switch to a different host they “might get faster performance.” 5. Alleging that WP Engine is “misus[ing] the trademark” including by using “WP” in its name. 6. Claiming that WP Engine’s investor doesn’t “give a dang” about Open Source ideals. Under a US defamation analysis, claims (1), (3), and (6) appear to be statements of opinion. Statements of opinion, even when persuasively worded and authoritative, are generally not actionable as defamation. It might depend on the wording; in corner cases, an opinion can be actionable if it directly implies a conclusion made from facts known to the speaker and not disclosed to the audience --- but the facts involved have to be specific, you can't just imagine that I've implied I have secret facts (or my audience expects me to) because I'm Matt Mullenweg. Claim (4) seems like it's probably just a fact? Is WPE assuredly the fastest possible provider at any given price point? The \"might\" also seems pretty important there. That leaves (5) the allegation about the trademark dispute, which doesn't sound like an especially promising avenue for a lawsuit, but who knows? and (2) the bit about employee and former employee reprisals. The thing about (2) is if there's a single example of a disgruntled WPE employee who thinks they missed a promotion because they stuck up for the WordPress Foundation or whatever, WPE might have a hard time using that claim. You'd think that before WordPress/Automattic started directly demanding funds from the board of WPE, they probably had some kind of counsel review this stuff and figure out what they could and couldn't safely say? Maybe there's tortious interference stuff here that gives these claims more teeth than a typical defamation suit (I've come to roll my eyes at tortious interference, too; unless you're alleging really specific fact patterns I've come to assume these interference claims are also a sort of C&D \"punctuation\"). This is one of those times where I'm saying a lot of stuff in the hopes that someone much more knowledgeable will set me straight. :) reply mintplant 8 hours agoparentPeople in this thread seem to be focused on the defamation angle, but is the more important allegation not the alleged demand for large amounts of money to not destroy WP Engine's business? Matt sounds like a wannabe mob boss in the screencapped texts, sending photos of the crowd before his keynote and talking about how he could still \"very easily\" make it just a Q&A session if WP Engine agrees to pay up. reply Kye 6 hours agorootparentAgreed. I'm confused by a lot of the discourse in this thread. The extortion seems like the important thing. I would think (paraphrasing) \"I'm going to destroy your business if you don't pay me\" is extortion regardless of the merits of the claims used in carrying out the threat. reply BobaFloutist 3 hours agorootparentI mean if a business if built on top of your business, is it actually illegal to say \"Pay me if you want continued access?\" Is it the wording that makes it illegal? reply Kye 3 hours agorootparentWho built what business on whose business? It's not clear what you're referring to. reply FireBeyond 2 hours agorootparentprev... to the open source project WordPress? 1) it'd be hard to forbid any one entity from using it, based on the licensing, and 2) the announcements and banners pushed to users referenced WP.com, Matt's for-profit competitor which WPengine doesn't use, and brings about elements of tortious interference. reply chuckadams 4 hours agorootparentprevExactly, the extortion is the most serious allegation, but WPE isn't providing a lot of background in terms of what and how much Mullenweg was demanding, only texts that came well after the demand was made. My guess is if there's a really damning email, WPE's lawyers served them a legal hold privately rather than make it public. Alexa, order ten cases of popcorn... reply slouch 2 hours agorootparentMatt admitted on reddit that he asked for 8% of annual revenue or ~40 million. https://www.reddit.com/r/Wordpress/comments/1fnz0h6/comment/... He posted this after receiving the C&D. reply chuckadams 1 hour agorootparentCool, thanks for the link. I wonder how much of Automattic's board is made up of Matt's personal friends. He'd best hope it's a majority. reply bastawhiz 16 hours agoparentprevThe most damning claim, I think, is that Automattic put a banner in every WordPress dashboard on the subject, including WordPress instances hosted by WPE. Automattic is a direct competitor to WPE (by way of WordPress.com). I'm no lawyer but I expect there's at least some argument to be made that there's some abuse of Automattic's position in doing so (though I don't know enough about the law to know whether they have a chance of winning such an argument). If Automattic was purely producing open source software with no vested interest in profit, that would be a different story perhaps. reply trog 14 hours agorootparentI have never thought of WPE as a competitor to WordPress.com but perhaps weirdly I think of WordPress.com as a competitor to WordPress.org. For example, if I have a WordPress site I've built from scratch out of WordPress.org, I am just going to assume trying to put it on WordPress.com will be annoying (and possibly even impossible?), because of issues with themes or plugins or whatever due to the fact that WordPress.com is a separate, hosted SaaS-style CMS, and not a hosting environment for WordPress sites. WPE, by contrast, is Just Another Webhost to me, with some special bells and whistles for WordPress. reply fhd2 13 hours agorootparentIt's quite possible to host a \"normal\" WP installation with custom themes and plugins on WordPress.com (on the more expensive plan), I've done it a few times. But as much as I want to like it, I can't wholeheartedly recommend it. Some stuff that should be easy is just ridiculously difficult, like pulling logs programmatically. I think the main audience it caters to is people hosting a basic site with off the shelf themes. reply __jonas 8 hours agorootparentprevSorry could you expand on this, how can they \"put a banner in [...] WordPress instances hosted by WPE\"? I was under the assumption that WordPress is OSS, and WPEngine is running this software on their platform, so there was an update to this software, contributed by Automattic developers which included a banner denouncing WPE, and the WPE people decided to just deploy that update to their platform? I don't think that means they \"put the banner on their instance\" does it? If they are unhappy with the management of the open source software they are using on their platform they presumably could fork it, or decide to not deploy the version that includes this banner, no? reply pluc 7 hours agorootparentThere's a widget on the default WordPress dashboard that displays a RSS feed of WordPress.org, where Matt posted his rant, making it show up everywhere. reply __jonas 7 hours agorootparentAh I see, thanks for clarifying! I have seen the mentioned blog post now [1] the whole thing is starting to make more sense to me. [1] https://wordpress.org/news/2024/09/wp-engine/ reply camgunz 10 hours agorootparentprevIsn't this completely fine? If you and I both make aspirin, but we both put a little something extra in it (me vanilla, you salt) and I put banners on my web page saying \"bastawhiz's salty aspirin puts the ass in aspirin\", doesn't this just seem like typical rivalry? My point here is that defamation is defamation no matter the scale. I think scale is relevant re: damages, but not as to whether or not rivalry escalated to defamation in the first place. reply chrisandchris 9 hours agorootparent> Automattic put a banner in every WordPress dashboard on the subject, including WordPress instances hosted by WPE > I put banners on my web There's a large difference between putting up a banner on _your_ site and abusing your position to put a banner on _every_ site you can. reply malermeister 9 hours agorootparentIf you sell my aspirin in your shop, you will have to accept what I put on the packaging or stop carrying my product. reply chrisandchris 8 hours agorootparentThat's true, but does not apply to this situation. Automattic is not the owner of WordPress, the WordPress Foundation is. Even though many employees of Automattic work (maybe full-time) on WordPress [1]. So I sell your aspirin in my shop, and a friend of yours helped you package your aspirins and while doing that put some stickers onto your aspirin. [1] https://www.df.eu/blog/wer-steckt-hinter-wordpress-ueber-die... (German) reply Matticus_Rex 5 hours agorootparentDoes WPF take issue with this operational decision by Automattic? If so, they have the avenues to deal with it, and they're the party who can claim to be aggrieved, if it violates some duty Automattic has to WPF. I seems more like this, from my understanding: You sell a brand of aspirin in your shop. The brand has outsourced most of the production and decision-making to another company. That company puts messages on the bottle. If those messages bother me, I can bring it up with the brand and see if they'll address it, or stop carrying the brand, but the question of whether they've overstepped is for the brand owners rather than me. reply FireBeyond 2 hours agorootparent> and they're the party who can claim to be aggrieved, if it violates some duty Automattic has to WPF Tortious interference - where one party (Automattic) interferes with a contractual relationship between two parties (WPengine, their customers), in this case by means of disparagement pushed to the dashboard of WPengine instances. reply justinclift 8 hours agorootparentprevNah. Putting disparaging claims directly on the dashboard of my customers seems pretty abusive, and if it happened to me I'd be looking at legal options too. reply tasuki 2 hours agorootparentAutomatic are publishing a blog post and syndicating it to RSS, and some other software (WP.org) is displaying that feed. If you choose to use the WP.org software as is, it's kind of your fault, isn't it? reply tptacek 15 hours agorootparentprev\"Abuse of position\" is not generally an actionable claim. reply DannyBee 1 hour agorootparentUnfair competition is, particularly in California, which interprets it's UCL very broadly. Let's set aside all other claims (there are others), and take a look at \"Unlawful, Unfair, and Fraudulent Business Acts\" under that. We'll also throw out unlawful business acts (I don't see anything unlawful so far). Unfair: \"An “unfair” business act or practice, as defined by the UCL, is typically committed by either a company or a business competitor. ... In the context of a business competitor, it is considered an unfair business act when the company does something that broadly undermines competition in the marketplace.\" Additionally, they consider \" immoral, unethical, oppressive, and unscrupulous\" business acts to be unfair. Banners on wp engine sites probably not a good thing under this. Threatening your competitors with bad keynotes unless they pay you, also probably not a great practice. (I do think you'd be fine to say they suck. I just don't think you can get away with basically extorting them) Fraudulent: \"The UCL also prohibits “fraudulent” business acts or practices, which means any conduct that misleads or deceives consumers.\" Note that it does not have to be defamation, or malice, or illegal. Just misleading or deceptive. More exactly, it does not have the elements of common law fraud - Intent is not a requirement, and negligence can be a violation. So pure opinions without intent or with negligent intent that actually deceive consumers, while not defamation or common law fraud, are quite possibly a fraudulent business practice. Overall, I think they have a stronger case than you might. Not on defamation, but on other things. Regardless of the outcome, the approach i see taken by the Automattic CEO here seems remarkably stupid. Don't mix your roles unless you want a court to mix your roles. When he threatens to ban them from wordcamp[1] in what capacity is he doing it in? 1. Which, btw, the central website totally avoids mentioning who is in charge or paying overall anywhere i can find. I hope it's not the foundation (or him or automattic) and he's not mixing roles further while threatening his competitors. reply sfmike 13 hours agorootparentprevjust for monopolies right? And for hosting online and software that does it(two verticals of wordpress) there are hoardes of options. reply Terr_ 13 hours agorootparent> just for monopolies right? I suspect that's still not actionable in the way the parent poster means, since AFAICT there no private right of action: You can't sue, only petition some government agency to bring their own lawsuit. reply throwup238 12 hours agorootparentUS antitrust laws grant private rights of action for monetary damages and injuctive relief. They’re unlikely to apply to Automattic/Wordpress though. (Most other governments don’t grant these rights though) reply eastbound 14 hours agorootparentprevYes, but being the editor of the software used by your competitor is certainly funny. reply uudecoded 14 hours agorootparentprevGenerally, but also especially when the position is \"WordPress\". reply DannyBee 1 hour agoparentprevThe defamation angle is not interesting. They are pretty clear they will go after them for torturous interference, unfair competition, etc. California's UCL is much broader than you may think here - it is consistently interpreted very broadly by california courts, and has fairly low requirements (IE fraudulent business practices under the UCL do not have meet the same requirements as fraud) reply crashbunny 8 hours agoparentprevI'm also not a lawyer, pleased to meet you. > I sort of directionally think that if WPE had a strong case here, their opening bid wouldn't be a C&D I believe, as a non lawyer, in some places to be able to sue for defamation you must first contact the defamer and demand they take it down. I have no idea and no opinion if there is a case. If there is a case a C&D might be a necessary step. reply bravetraveler 8 hours agoparentprevThere is simply no need to preserve documents given how public this was. If pressed the grievance can be corroborated externally. The letter in entirety is a warning of potential legal action. That is the next action if the other party neither ceases or desists. Maybe this is normal, but we're glorified animals trying to find justice out of a made up process. It's arbitrary, hence arbitration. Not a lawyer either. You probably know more terminology than I do; I just deal with them a lot :/ edit: I think it's a little strange to be placing judgements at this stage. We'll hear the facts if this goes to court. There's enough to know several are upset. Another consideration: by placing the numbers you're kind of trying to make their argument. Why? Let them. reply akerl_ 6 hours agorootparentIt seems pretty likely that there’s communications internal to Automattic or the Wordpress Foundation where they talked about their objectives and plans, assuming the details in the claim are accurate. That’s what they’re talking about preserving. reply bravetraveler 6 hours agorootparentI can see that, I'm saying it's superfluous reply akerl_ 3 hours agorootparentWhy? reply akerl_ 16 hours agoparentprevI assume the real goal here is to have the letter exist and be public, as a counterpoint in customer conversations. reply DonHopkins 1 hour agoparentprev>6. Claiming that WP Engine’s investor doesn’t “give a dang” about Open Source ideals. But dang is not theirs to give! reply FireBeyond 2 hours agoparentprev> Maybe there's tortious interference stuff here that gives these claims more teeth than a typical defamation suit (I've come to roll my eyes at tortious interference, too; unless you're alleging really specific fact patterns I've come to assume these interference claims are also a sort of C&D \"punctuation\"). This is the big one to me, actually. If Matt used the announcement feature in the WP.org codebase to place an announcement in WPEngine customers consoles telling them they should not support WPEngine, but instead his for-profit competitor, WP.com, it's pretty hard to argue that that is anything but tortious interference. reply aimazon 16 hours agoparentprevMatt is predictable. WPE wrote this letter for the community. They knew Matt would throw a fit and they would be able to take the high ground while also releasing an assassination of Matt’s character. The Wordpress community doesn’t care about Wordpress.com, Matt just blew what little credibility he had left. Worthless as a legal letter, brilliant as a response for the Wordpress community. Matt will inevitably step down within a few weeks, and a few years from now, this will be seen as a pivotal moment enabling WPE to dominate Wordpress.com. Matt could not have played this worse. reply pxtail 5 hours agorootparent> Matt just blew what little credibility he had left Just \"lol\", it's really funny line when taking into consideration all the years how he manages WP, cares about direction it moves, fosters and cares about OSS, directs funds and all of other countless things AND putting on the other chalk some WP hosting which happened to grow for one reason or another and is contributing peanuts compared to what it gains from the WP. No, he still has a lot of credibility. reply Matticus_Rex 5 hours agorootparentprevMaybe my view into the Wordpress community (mostly via Twitter) isn't representative, but it does not seem like WPE represents the community's views from what I'm seeing. reply slouch 2 hours agorootparentTake a look at the votes on Matt's reddit comments https://www.reddit.com/user/photomatt/ reply Matticus_Rex 35 minutes agorootparentIn a sub that size with a subset of people who are quite pissed, those scores don't look that bad to me. The OP only has +17. We'll see, I guess. reply onli 11 hours agorootparentprevMatt has no reason to step down. He will explain where the monetary claim is coming from - probably the development time promised and not delivered, or the use of the trademark - and then you have two competing narratives. One by the Foss software maker, one by a big enterprise. Why would a relevant part believe wp engine? And even if, how would that harm internal automattic structures in a way that he loses control? Also, I see no way how this going forward even in front of courts could end up with wp engine replacing WordPress.com. reply aimazon 8 hours agorootparentAutomattic benefits greatly from their close relationship to Wordpress. Using the power they have to threaten a commercial competitor that has a good reputation in the community will push the Wordpress community to reevaluate that relationship. The contributions Automattic makes to Wordpress are valuable but valuable contributions do not excuse bad behaviour. Souring the relationship between Automattic and Wordpress is a major blunder, which Matt will be responsible for. If Automattic lose their preferential treatment and are forced to compete with WPE based only on service then they will be crushed because Automattic’s offerings are not as good — there’s a reason Matt is so sensitive about WPE. Automattic are just as dependent on venture capital as WPE, even more so because of how their business has been losing focus. Automattic’s value is based on its relationship with Wordpress, whereas WPE’s is entirely based on the service. Matt is threatening Automattic’s most valuable asset, removing him may be seen as the only option to rescue the relationship. As an aside, people don’t usually act like this when things are going good. Perhaps Matt is lashing out because of pressure he is already under. edit: and to close the loop, Matt is demanding benevolence from WPE that Automattic themselves don’t engage in. Automattic own the Wordpress.com domain and promote their hosting service through Wordpress.org (which causes the exact confusion Matt accuses WPE of benefiting from). The money Automattic spend on supporting Wordpress project is not a donation, it’s quid pro quo. Would WPE pay $10m a year to own all that? Of course, any rational company in the space would… but that’s not what Matt is offering. reply jarito 4 hours agorootparentprev8% of revenue in perpetuity seems like a licensing deal, not payment for services. WP is arguing that they don't need a license deal to deliver their service which seems to be true? Therefore, the 8% just seems like a shakedown to get money - good old blackmail. reply manuelmoreale 12 hours agorootparentprevI don’t follow the WP ecosystem very close since I left it years ago when I found better tools but I very much look forward to see if your confident prediction holds true. reply firecall 18 hours agoprev> Automattic CEO and WordPress co-creator Matt Mullenweg unleashed a scathing attack on a rival firm this week, calling WP Engine a “cancer to WordPress.” In my experience, WordPress itself could be called a Cancer to the Web. The amount of new clients I've picked up who needed help rescuing broken and malware ridden WordPress sites is... well, it's more than I'd like as I really do not enjoy WordPress LOL reply busterarm 14 hours agoparentThat's on the customers. I used to work at a shop that used WP and it was a huge force multiplier. We were WP Engine customers and at some point we moved to Pantheon.io and then we moved to a static site with an internal-only WP frontend for content editors. We had 2 developers, a PM, 20-30 content writers and $5B ARR. Websites were strictly for marketing/leadgen. Even when we switched to building a static site, we still had our content editors write markdown in WordPress because it was easier to do that and pull all of the content from the database on deploy than train them. The absolute worst part of being a WP Engine customer was being on Linode and the yearly Christmas Eve DDOS. reply manuelmoreale 12 hours agorootparent> That's on the customers No that’s on the various design agencies that sell “custom websites” and instead they just slap together a 59$ theme and a dozen plug-ins. Most customers don’t know shit about the web and they just trust the agency to do a professional job. And in my 10+ years of experience as a freelancer I’ve seen plenty of agencies taking advantage of clients. reply pluc 6 hours agorootparentWordPress has the same problem as PHP: it's too easy to do what you want the wrong way. The right way is great, but the wrong way is easier, cheaper, more common, more documented, etc. reply manuelmoreale 6 hours agorootparentTotally agree. Wordpress used as a CMS where you build everything from scratch using built in functions and the absolute minumum number of plugins (in my experience it was exactly 1, ACF) can generate sites that are solid. I have projects I built a decade ago that are still online, are still running and haven't been hacked. The problem is that the overwhelming majority of WP sites aren't built like that. Because \"there's a plugin for that\". And you end up with these monster sites with dozen of plugins, each importing their own scripts and styles, all injecting their own crap, all bringing in their own issues. And you use those on kitchen-sink style themes that are designed to do everything and end up doing nothing well. But that's the inevitable result when you lower the barrier to the point where one can just click buttons and install whatever. reply busterarm 5 hours agorootparentprevSupply and demand. These businesses exist and operate the way they do because of customer desires. The customers could hire better agencies but for a number of reasons don't. reply andruby 55 minutes agorootparentprev> 2 developers, a PM, 20-30 content writers and $5B ARR Please tell me that these 30 people weren't the full company generating $5B in annually recurring revenue? reply nottorp 12 hours agorootparentprev> Websites were strictly for marketing/leadgen. So they weren't web sites but spam. What I'm curious about though is if your former workplace still exists or is now AI generating the spam... reply manuelmoreale 12 hours agorootparentThat’s pretty unfair. Most of the work I do can be considered “marketing” since it’s corporate sites and portfolios. Businesses need to have an online presence of some sort and someone has to create one for them. Not everything is SEO spam. reply nottorp 2 hours agorootparent> it’s corporate sites and portfolios Oh wait. You used \"corporate sites and portofolios\". The OP used the generic \"content\" though. There's a difference. reply busterarm 5 hours agorootparentprevNot spam at all. I just don't want to be so obvious about what the business was, even though I've mentioned it in the past. Think top 10 keywords space and spanning about 4-5 of them. It's the largest business in its space and a major national advertiser both digitally and traditionally. You have seen their ads on the street, on TV, on websites and on Youtube. Even internationally, you have seen their ads on TV. Big hint. reply nottorp 3 hours agorootparent:) I don't watch TV and run ad blockers online, sorry. When you're using terms like marketing, leads and content writers, it sounds like a content mill with zero substance. Even if it's \"top 10 keywords\". reply anonzzzies 16 hours agoparentprev> as I really do not enjoy WordPress LOL me neither but it pays; when we get called, bad things already happened, so it's always an emergency which means we can ask for 400-500$/hr to fix it. And there are so many bad wp sites that we can retire on that alone. But let me tell you about OpenCart, Drupal, etc which also are all lovely targets and more niche so higher hourlies! As someone with a formal verification and static typing background, it is the most terrible crap there is, but it is very good business. reply mmarian 4 hours agorootparentAny recommendations on how you can find that kind of work? I'd personally enjoy it, but I don't know how to break into it without working as a WP dev at an unsustainably-low wage. reply MathMonkeyMan 17 hours agoparentprevI wonder to what extent that can be attributed to its ubiquity versus its quality. I've never worked with WordPress. For example, I notice that most of the automated \"attacks\" on my server are WordPress related. Is its defect rate significantly higher than other systems', or is it just that if you're going fishing you should bait for the most common fish? PHP and Apache come up a lot too. reply firecall 15 hours agorootparentWay back in 2013, Matt Cutts from Google said in a talk: “WordPress takes care of 80-90% of the mechanics of Search Engine Optimization (SEO)” Agencies really latched onto that! SEO was the new hotness. An industry was then built around WordPress. Clients would hear that it was the best at SEO, and they wanted a CMS they could update themselves. Agencies could churn out variations of the same WordPress site and plugin stack, and then charge clients for ongoing hosting and maintenance fees to keep it updated. Then there are all the plugins that get added depending on the whims of the 'developer' at the time. The WordPress website then languishes when the agency or dev vanishes, WordPress gets hacked, and the client gets charged again. The WP GUI builder plugins are a whole separate hellscape all to themselves! reply dylan604 17 hours agorootparentprevIt's like any other system designed to be used by people that are not technically savvy. Lots of things have default values that are not sane. That's why the script kiddies hit every server they can with known defaults and vulns. Otherwise, it's like any other publicly facing internet server in that it takes maintenance with patches and updates and being informed on what you're running and changes being made. So because the majority of users are not savvy, it's become a cesspool. Then you read about it on a tech forum like HN and it is derided as an inferior product rather than allowing improper use by the user/operator. reply lnxg33k1 17 hours agorootparentI've had an interview last week for a company doing WordPress stuff, and their tech lead, computer science guy, said their next project was a monitoring tool running unit tests in production to understand the health of the app It's not only the non-tech-savvy, even CS guys become trash when they go too close to WP reply smt88 15 hours agorootparentprev> I wonder to what extent that can be attributed to its ubiquity versus its quality Its quality is astonishingly bad. It was clearly developed by someone who didn't even have a basic understanding of relational databases. Unless something has changed, plugins and themes can run arbitrary PHP on the server. Anything ubiquitous is going to be hated. I agree. But WordPress is bad from a fundamentals perspective. reply joe_g_young 14 hours agorootparentI think your response can be said of any application made before now. reply smt88 13 hours agorootparentThere are degrees of bad. All code bases are bad. But I've been writing web software for 30 years and WordPress is among the worst mainstream applications. It's worse than its PHP competitors at the time, and it's worse than Ghost and many of the competitors that came after it. You can't just dismiss all criticism of the past because it was the past. Some people wrote worse software than others in the past, just as they do today. reply manuelmoreale 12 hours agorootparentPersonally I’m think a big issue is the insistence of wanting to keep everything as backwards compatible for as long as possible. It becomes a burden. At some point you have to accept to make substantial changes in order to improve the situation but it’s not going to happen in the WP ecosystem because that’s one of their selling points. reply ipaddr 12 hours agorootparentprevIt shows the code base rarely matters compared to user adoption. reply rurban 12 hours agorootparentprevExcuse me. phpwiki did exist before mediawiki and wordpress, and allowed no custom php in plugins and themes. It was all safe. Already 20 years ago. And as worse is better predicted, all new ones went insecure, with less features, but nicer looking themes. reply ufmace 15 hours agorootparentprevI run my own Wordpress server for a blog, and IMO it's basically fine if you use reasonable deployment management practices and don't install 500 random crap plugins and themes. The basic install is about as bulletproof as it gets in the mainstream web software business. I don't particularly love PHP, but you don't need to touch it if you don't try to write any plugins. Yes, some of its practices are pretty wacky, like every plugin has full access to the filesystem and database to do basically anything, and the system expects to be able to update code files in place from web requests, but meh, just give it it's own $5 server and let it do its thing, and definitely be very careful which plugins you use and how you get them. What you get in return for this is a perfectly fine CMS that anyone with basic computer skills can run. Yeah, static site generators are cool and all that from a tech expert's perspective, but nobody who isn't a tech expert can actually do anything with them, and oh, by the way, the ability to make any changes at all typically involves at the very least SSH access to the host server with full write permissions. reply sixtyj 13 hours agoparentprevAnd so nice it looked at the beginning… Instead of WordPress, what solutions do you use? Wix, Squarespace, Webflow, Webnode and other wysiwyg ones are even worse imho. Are there any non-Nodejs or non-React open source CMS that don’t vendor lock you? Because I feel that WP somehow sucks in details and maintenance, but I can’t find anything comparable without being sucked into development hell. :) Thanks for suggestions. reply manuelmoreale 12 hours agorootparentAfter a few years building on WP I switched to https://getkirby.com/ and never looked back. reply sixtyj 11 hours agorootparentThanks. It seems really good. PHP, files and folders instead of db, easy templating, plugins, admin interface built on Vue.js, open source at GitHub and a commercial license as well. Since 2012. The only issue is to have more themes available, at getkirby-themes_com there are 22 only. reply manuelmoreale 11 hours agorootparentBecause it's not designed with a theme approach. It's designed to build custom sites. Themes aren't really a thing inside kirby because of the tight relationship between content itself and admin interface. I like to think at it as an in between something like Laravel and WordPress. reply sixtyj 11 hours agorootparentI got it. But explain this to people who are spoiled by $59 themes :) More themes that you can choose from -> more Kirby users -> stability -> more users coming from other solutions etc… reply manuelmoreale 10 hours agorootparentIt's an entirely different target audience. Kirby is a tool that's designed mostly for developers, and not really for end users. There's no one-click install, there's no pressing a button to install plugins. And that's by design. reply sixtyj 10 hours agorootparentWell, in fact it was two clicks install :) I’ve downloaded it, unzipped into a folder and with PHP running I was ready… No Nodejs and React needed. These are so painful to maintain. So Kirby is really nice to run. And I understand your point. reply pjerem 12 hours agorootparentprevAre the good old PHP CMS dead ? Things like Joomla, Dotclear, Drupal … reply sixtyj 11 hours agorootparentThey are not dead. The reason why WP took web by storm and Joomla and Drupal became less visible is that WP did a lot of work in instant usability - their 2 minutes’ installation changed the game imho. reply chris_wot 17 hours agoparentprevI personally don't like block themes. reply lightlyused 17 hours agorootparentSimilar experience here. Poorly documented and inflexible. reply theyknowitsxmas 17 hours agoparentprevYeah I run wp2static on clients, cancel the hosting then push the files to vercel/cloudflare pages/github pages. A PHP version is vulnerable. If you upgrade it, some plugin breaks. If you manually upgrade the offending plugin, the pesky developer now wants a subscription. Just a nono. I build on Hugo. reply anonzzzies 16 hours agorootparentMany (some very large) companies would not allow that route; their marketing team is trained on wp and they specifically implemented it (in the EU this is per country generally) to sidestep the head office enterprise cms that is unusable and takes days of workflow steps to get anything published; they want more dynamic, not less and they want less techy not more. reply theyknowitsxmas 14 hours agorootparentWhy? Hugo is Markdown, child's play. You can use GitHub as a CMS. reply joenot443 8 hours agorootparentI think your question answers itself if you look from the perspective of a non-technical marketing person who's used to WYSIWYG tools, rather than a programmer who's reading a site called Hacker News. reply vundercind 2 hours agorootparentprev“I need to add an image gallery” “I need to add and edit multistep forms that send an email to me” “I need to change one of our social media links” That can be mostly or entirely self-serve for marketing folks on Wordpress, with all the work happening in their browser. Plus tons of other stuff. reply anonzzzies 14 hours agorootparentprevYes, I know, I use it too. But github is hardly usable by non technical users , nor is markdown. We are talking about marketing deps of billion$ companies. reply stvltvs 15 hours agorootparentprevThere are other plugins that generate static sites. Not sure if they would work for your use case, but worth looking into if you haven't. reply theyknowitsxmas 15 hours agorootparentMust clarify: not wp2static, but a random plugin breaking on php upgrade, sometimes requiring a subscription in new versions. reply gjsman-1000 18 hours agoparentprevAnd yet, reality is that for many companies, an off-the-shelf CMS is all they need, and all they can afford, and all they can figure out without hiring IT. Which means, if we want to kill WordPress, we need to offer a better solution. Not just for WordPress, but a coherent system that also reimplements the top hundred or so plugins. If anyone wants to join me rewriting it in Laravel so we could add a WSL-like layer for WordPress cancer plugins… I don’t know. I wish someone would have the conversation. I don’t even care whether it’s Rust. reply bigiain 17 hours agorootparent> Which means, if we want to kill WordPress, we need to offer a better solution. Not just for WordPress, but a coherent system that also reimplements the top hundred or so plugins. And a solution for which a typical non-tech business can ask around their family/friends/employees and find someone who's experienced enough to come in for a few hours out a few hours a week to to typical CMS admin/editorial stuff. And for which there are heaps of easy to find tutorials and youtube videos which can get someone up to speed enough to keep their own site running, while still spending 95+% of their time making widgets or selling trinkets or whatever their actual business is. I'm not _that_ much of a fan of WordPress, but WordPress on WPEngine is 100% my initial recommendation for anyone asking about how to run their business website. (I'd be curious to see a Rust backend API replacement for the WP + top 100 plugins that uses the standard html/frontend, to have the type safety and security Rust is famed for, while being identical in use to WordPress so all the people currently admin-ing WP site wouldn't have to even know it's different. But not curious enough to expend any effort to make it. ) reply iambateman 17 hours agorootparentprevStatamic for Laravel is pretty great for what it does. I wrote a WYSIWYG CMS for Laravel called Prodigy that I really enjoy but it hasn’t gotten much market pick up. There’s definitely some thinking in this area on how to move WP users toward Laravel. reply gjsman-1000 17 hours agorootparentStatamic is awesome; watching Jack McDade in person at Laracon last month was great. However, Statamic is not a WordPress replacement. We need a system that can be installed, with hundreds of themes and plugins available, without touching code. An open-source Squarespace, basically. Statamic has a role, but not as a WordPress replacement for most people unfortunately… reply ksenzee 17 hours agorootparentprevDrupal is trying for basically this with its Starshot project. It might just work, if they can get enough people to build third-party themes. reply bsder 17 hours agorootparentprev> And yet, reality is that for many companies, an off-the-shelf CMS is all they need Except they don't. A static website would work for 99.9% of all businesses and could be hosted on a potato. The problem is that marketing wants a website that \"Doesn't look embarassing and has 5 nines uptime.\" Translation: \"Marketing wants a website that looks completely like our competitors(because reasons)! But make it completely different (because reasons)! And make sure it's on AWS (because reasons)!\" Response from IT: \"Our website results in zero revenue to the company and is a gigantic security problem and spam magnet. And because marketing is involved it's also a headache of a political football. Here's the WP Engine credentials. Now fuck off.\" reply bigiain 16 hours agorootparent> The problem is that marketing wants a website that ... they can publish and update content without having to get IT involved - just like they did at their last job where the website was WordPress. Oh, and IT who thinks their company has a marketing department that adds zero revenue to the bottom line needs to go back to they mom's basement or academia. That's just not how the world works. reply bsder 14 hours agorootparent> Oh, and IT who thinks their company has a marketing department that adds zero revenue Please reread. I said the website brought zero revenue. The website for our company never broke 5 digits in total views. I could almost precisely correlate who was looking at our website with who marketing was currently talking to. Scaling was useless. Dynamism was useless. etc. All resource spent on the website was worse than useless as it took marketing away from doing anything else which would could result in revenue. A lot of businesses are in the same boat where the website brings in zero revenue. A static website would be more than good enough but somebody in mangement chain has a \"Must Keep Up With The Joneses\" streak. And then you wind up on WordPress. reply bongodongobob 16 hours agorootparentprevNo they can't. You don't roll out technical solutions without IT involvement for obvious security and stability reasons from hosting, bandwidth charges, auth, security maintenance, cert renewals, https, etc, unless you don't care about any of those things. That's literally ITs job and why the dept exists. reply bigiain 16 hours agorootparentThose concerns are kinda the raison d'être for WPEngine. For anywhere small enough to not have an IT department, or so large and where the IT department has effectively become obstructionist to other department's jobs, just buy marketing their own WPEngine subscription and let them do their thing. I think people who work in an \"IT Department\" sometimes have a too narrow view of the rest of the world. Both ignoring that almost all small and most medium sized businesses do not have an IT department, and also that there are people and departments in their own organisations who's IT needs are real but are not considered a priority by the IT Department. (Often understandably not the IT departments priority, the people in a bank IT department who're securing financial systems from continuous attacks almost certainly don't consider the HR departments need to set up a quick website for the company bbq or RUOK day to be a prioroty. But someone in HR is getting _super_ frustrated at not being able to do the \"simple things\" they know they could do if IT didn't keep pushing back.) reply bongodongobob 14 hours agorootparentI'll just ignore the \"IT pushback comments\", as if we don't have real actual reasons for pushing back against the stupid shit people with no experience think is a good idea. The main problem, security aside, is when shit goes south (and it will at some point), IT will be asked to handle something they didn't set up, don't know anything about, and will be looked down upon when they can't get it working quickly. As long as there is ownership of any problems by whomever set it up, yeah, go nuts, but experience also tells me that's never how it works. reply gg82 13 hours agorootparentAnd then people bypass IT for things that IT would be happy to help them with and end up getting called in to fix some non-standard thing that has become critical to their work. reply gjsman-1000 17 hours agorootparentprev> Response from IT This is where the mistake was made. Tens, possibly hundreds, of thousands of small businesses do not have an IT department. Even the business I work in - almost a dozen employees before a single IT guy. WordPress and Squarespace, and software like them, are the off-the-shelf solutions for them. You sign up for GoDaddy or another shared hosting provider, what do you get? Right now though, Squarespace is eating WordPress’ lunch, and (if you don’t need plugins) is objectively superior in many ways. We need a modern replacement for WordPress to fulfill that role which won’t make programmers swear, or let closed-source solutions shut out the open ones. reply bongodongobob 16 hours agorootparentprevHahaha, I've been in this exact situation. Marketing set up an entire WordPress website unbeknownst to IT. Over a year's worth of effort and they never even mentioned to us they work working on it. I'm in a monthly directors meeting of all depts and marketing unveils their wonderful website to much applause and oohs and ahhs. They then say, looking at me, \"Yes we should be ready to launch in a couple weeks after IT sets up authentication and integrates it with our CRM and mail blast system.\" I was so lost for words I just kind of nodded my head, wide-eyed. The way they had it set up did not allow us to use the same SSO/auth we used for everything else. So users would need a separate account. Their auth system didn't support any kind of MFA. Their plugins were not compatible with our CRM. External accounts would need to be set up manually. They used a different domain thinking they could just change it later but it got so baked into everything that changing it everywhere would be extremely difficult. Their hosting solution was going to cost us a shit ton of money because none of the graphics were optimized for web. Every image was like a 50MB PNG. It did look nice, but nothing was set up in a way that made it compatible with anything we already had in place. I told marketing there was no way I could make this work and they'd wasted a year's worth of effort by not pulling me in from the get go to at least help them find some sane compatible solutions. \"Well, if we can't use SSO, couldn't we just build a spreadsheet with everyone's logins so you could plug that in?\" Jfc no. The CEO/owner sends me a meeting invite and asks me why I'm refusing to work with marketing on their website. I explain that they had decided not mention any of this to me from the get go and explained the reasons why I couldn't make it work. I said, \"well, technically we could make anything work, but you're going to have to hire a small dev team to integrate this with our CRM. We're going to have to pay a lot more monthly for our CRM because now we need API access (we'd need that either way even if the plugins were compatible) and if you want a team to write some custom integrations for this, you'll need some kind of retainer to make sure they can support it when the plugins change and break everything in unpredictable intervals or the plugins are no longer maintained.\" He refused to believe me and basically said \"Well I'm not sure why I'm paying you if you can't even get a website to work.\" I quiet quit and resigned about a month later. You can imagine the other kind of shenanigans that went on if that was considered acceptable. reply johng 16 hours agorootparentThis really doesn't sound believable, on your part. You can't run pngquant on the images directory to shrink down the images? Should take 2 seconds of shell script. Honestly a lot of things you mention seem like pretty trivial to do... Wordpress is so well understood and there are so many utilities and integrations for it, it's one of the simplest things to integrate with something else. This comment sounds like you were mad they made something that the rest of the company wanted and got mad and didn't want to play ball.... could just be misinterpretation over text, who knows. reply bongodongobob 14 hours agorootparent* yes the images would be an easy fix * their CRM plugins did not support Salesforce * even if it did, they didn't realize that was like an extra $1500/month for API connection (something like that), which was also balked at, but just a plain fact * they already built everything out and changing plugins was not an option * I have almost no experience with WordPress and 0 time to figure it out alongside the myriad of other projects on my plate * 0 thought went into authentication and that was also something I couldn't change * this was not built by a team with WordPress experience, or any technical experience They said \"it's set up like this, make it work\". I couldn't, not without dropping everything and hiring someone to do it, and managing a contractor(s) which was also not an option. reply gnu8 2 hours agorootparentprev> He refused to believe me and basically said \"Well I'm not sure why I'm paying you if you can't even get a website to work.\" I would quit the moment I was spoken to in that way, if not sooner. reply econcon 17 hours agoparentprevWe had that problem in barebones WP with no plugins at all. Once we installed a few security plugins, it worked out just fine! reply breck 16 hours agoparentprevI'd love to get your feedback on https://hub.scroll.pub/. Create new sites in 0.1 seconds. No signup required. It's a new stack, but it's pretty revolutionary foundation, and as we get some good templates and imrpove the UX, I think it should bring a lot of joy to people who currently suffer with wordpress. It's all open source/public domain. Having started my programming career in Wordpress ~17 years ago, I have been able to take my favorite parts from it and get rid of all the annoying parts (like requiring a database, php/javascript hybrid, etc). reply Aloha 17 hours agoprevDisclaimer WP Engine Customer - I read the comments from Matt M yesterday, and it felt like a hit piece. I run a website for a couple scifi like conventions, we need cheap reliable hosting without me having to deal with the vagaries of running wordpress myself. I would have bought a product like WP Engine directly from Automattic, but AFAIK they dont offer one, this feels like lashing out at a competitor because they failed to enter a market segment, and now feel their lunch is being ate. I ran websites for a long time without any version control, and would have no problem doing it again, the benefit of WordPress is the semi-WYSIWYG editor and the plugin ecosystem. reply sceptic123 10 hours agoparent> cheap reliable hosting I can't speak to the reliability, but it's definitely not cheap reply philistine 16 hours agoparentprevCould you enlighten me as to what WP Engine does differently from Automattic that you can't buy from them? Looking at the WP Engine, it's the exact same thing, with the numbers filed off, as Automattic offers. reply deepfriedchokes 15 hours agorootparentWP Engine offers headless WP CMS to static, for one, and it’s pretty slick. I don’t believe Automattic offers that, yet. But I bet Automattic builds it in, in the near future, and that’s probably what this WP Engine beef is really all about: money. reply x0x0 2 hours agorootparentprevThey offered many features that wordpress.com copied (staging sites with one-button cloning; easy backup and restores; automated updates of php and wp code; tweaks to prevent security issues; automatic cdn) and others like serious engineers answering support tickets to help you sort out whatever fragile, insecure wordpress crap your marketing team, or their wordpress contractors, installed on your site. We shouldn't overrate a lot of those features, because I think they were pretty obvious things to want. But WPEngine was, afaik, the first to market with all of the above in a pretty-cheap and seamless package. reply authorfly 18 minutes agorootparentJason Cohen has done a number of talks on the origin of WP engine as being reliable/fast/secure in terms of preferences at the time of launch; But I think you are right, the features you listed naturally contributed and strengthened those needs. reply Aloha 16 hours agorootparentprevWhich particular service of Automattic? Like Wordpress.com in hindsight seems to offer it, but its not clear to me that I'm their customer target. reply x3sphere 15 hours agorootparentWordpress.com would be the equivalent. That said, they don't exactly offer an unmodified WP experience either at least not without upgrading to the higher tier plans. The base plan has plugins disabled for example. Not even sure how it's different from what Matt is accusing WP Engine of. reply partiallypro 15 hours agorootparentprevWordpress.com is very limited and locked down relative to the .org variant hosts like WPE. reply keane 12 hours agoprevJust as an observation this reminds me of the dynamic that other open-source software distributors are tasked with defending. Let's say you were distributing a browser, let's call it Firefox. You might have a corporation and a nonprofit and call them the Mozilla Corporation and the Mozilla Foundation. Maybe in this scenario you would allow certain commercial uses of your registered trademarks so that the software could be distributed by others. Parameters in this policy might only allow the commercial use of the trademarks in certain ways, enabling others to advertise their product like \"Grammarly for Firefox\" or even their service \"Download Firefox from CNET\" without infringement. But these parameters would go on to disallow one from using the terms in a way that implied a direct connection to the Mozilla Foundation or caused confusion with regards to the root product such as advertising your site, CNET, as \"The Firefox Store\". Then let's say someone renamed their CNET site FFXSource. And then advertised themselves as \"The Most Trusted Firefox Tech Company\" and that their download was \"The most trusted Firefox build\". They might be told this violated the terms that don't allow implying official connection to the wider project. (And then let's say the download they were offering had the browser History pane feature stripped out.) In this scenario, it seems it would be the duty of the trademark owner, the Foundation, to seek that FFXSource either come into compliance or, to continue use that exceeded the blanket guidelines, to acquire a dedicated, more-expansive commercial license. (Of course none of my thoughts on this are legal advice.) reply ptx 7 hours agoparent> Then let's say someone renamed their CNET site FFXSource. This is addressed on page 5, where they quote the trademark policy[0], which until a few days ago said: \"The abbreviation 'WP' is not covered by the WordPress trademarks and you are free to use it in any way you see fit\". The current policy[1] has since been modified to specifically mention WP Engine and make seemingly irrelevant accusations towards them, but it still retains the part about \"WP\" not being covered by their trademarks. > And then advertised themselves as \"The Most Trusted Firefox Tech Company\" and that their download was \"The most trusted Firefox build\". Using that sort of phrasing would clearly be misleading and looks like it would have been disallowed by the trademark policy, but is that what WP Engine actually did? [0] https://web.archive.org/web/20240912061820/https://wordpress... [1] https://wordpressfoundation.org/trademark-policy/ reply echoangle 12 hours agoparentprevFirst, I'm not sure your example comes close to infringing the trademark, but even if it does: Wouldn't the correct step be to inform the infringing party that you see it as infringement and give them a date by shich they have to rebrand, and give it to your lawyer after that? Why would you make threats about destroying their reputation by doing a keynote about them if you are legally in the right? That's just childish. reply ipaddr 12 hours agoparentprevI don't think any of those issues you raised passes the bar. ffxsource.. no. The most trusted build. no many people build their own and it could be trusted more because someone is testing the official build and making changes and ensuring it works. The most trust Firefox Tech company is accurate. It implies many firefox tech companies exist and they are the best one. reply markx2 2 hours agoprevWP Tavern Articles That Recently Went Missing Following WCUS Keynote https://old.reddit.com/r/Wordpress/comments/1fofdpy/wp_taver... reply ncr100 15 minutes agoparentWow https://wptavern.com/matt-mullenweg-identifies-godaddy-as-a-... .. interesting how the phrasing is repeating (\"cancer\" today) -- calling a competitor a \"parasitic company\" in 2022. There has to be a more intelligent descriptor for competitors to WordPress.com ? reply muglug 17 hours agoprevSad to see Matt M behaving in such a childish manner. The initial wordpress.org blogpost looked pretty bad, but the quoted text messages are so much worse. reply keane 16 hours agoparentIt's not uncommon for a license being required to use a registered trademark. WPE denies they need one. Matt apparently disagrees. reply ChrisArchitect 17 hours agoprevRelated: WP Engine is not WordPress https://news.ycombinator.com/item?id=41613628 reply mrkramer 8 hours agoprevAutomattic invested in WP Engine in the early days, why didn't they acquire it, or WP Engine didn't want to sell. But why did Matt choose the open source license that he chose, it seems like that at the end of the day he only cares for money and not the WordPress community. reply markx2 8 hours agoparentThe fact that he wants money for Automattic suggests that Automattic are now hurting financially in some way. reply mrkramer 8 hours agorootparentThey are both \"hurt\" financially but that's the competition which is normal and which should drive more innovation and lower the prices for customers. reply trvr 3 hours agorootparentprevWhere does it say that the money he is asking them to contribute would go to Automattic? reply oldstrangers 17 hours agoprevThis is funny considering WP Engine has been the only thing that kept me developing wordpress sites for years. reply seydor 15 hours agoprevThis reads more like a blog post than a cease and desist. Why do they take so long to get to the point of their demands. Matt is entitled to have opinions , and they should stick to the opinions they find unlawful instead of rambling on about everything he said reply mrwyz 15 hours agoprevI'm hopeful Automattic will win this one; WP Engine repackages WordPress and delivers it as a service. Fine. Software license allows for that. That does not give them the right to describe their service as \"[the] Most Trusted WordPress Hosting and Beyond\". They clearly say so in their policy: https://wordpressfoundation.org/trademark-policy/ reply echoangle 12 hours agoparentYou can't prevent someone from using your Trademark as a description with your trademark policy. Everyone can use your Trademark to identify the thing, they don't need your permission. I could call myself the best Linux admin ever and the Linux Mark Institute can do nothing. reply sureIy 15 hours agoparentprevYou’re making no sense. Those words are just marketing, they’re not shitting on Automattic like Automattic is doing. reply jmull 15 hours agoparentprevThe policy says, ...a business related to WordPress themes can describe itself as “XYZ Themes, the world’s best WordPress themes,” but cannot call itself “The WordPress Theme Portal.” It sounds like \"[the] Most Trusted WordPress Hosting and Beyond\" would be allowed. reply bawolff 14 hours agorootparentNot to mention, wouldn't this be allowed generally? Like you are allowed to use trademarks if it is the correct description of the products you sell. https://en.m.wikipedia.org/wiki/Nominative_use [Ianal] reply sfmike 13 hours agorootparentprevexactly the link was cited and that citation directly refutes the claim reply mrwyz 15 hours agorootparentprevTo me, it seems they have been using the mark to describe a product and the policy says clearly: > but they cannot use them as part of a product I mean, just go to wpengine.com and look at the first menu item: Products --> WordPress Hosting. reply echoangle 12 hours agorootparentIt doesn't matter what the policy says if there is no legal basis for it. WordPress can't prevent Nominative Use, everyone can call the thing they are doing \"WordPress hosting\" if it is WordPress hosting. If the policy doesn't allow that, the policy can be ignored. reply chuckadams 48 minutes agorootparentEven if WordPress could suppress nominative use, do they really want a world where everyone selling wordpress-based services and products avoids saying \"WordPress\" like it was the name of The Dark Lord Himself? Maybe it's time for some malicious compliance by way of a hard fork that strips the word \"WordPress\" everywhere except where legally required. Even if Mullenweg somehow had 100% of the facts and law on his side, he's still an embarrassment to both the company and the foundation. reply patmcc 15 hours agorootparentprev>>All other WordPress-related businesses or projects can use the WordPress name and logo to refer to and explain their services I think the policy is somewhat vague on this; does 'Wordpress Hosting' refer to and explain the offered service? Clearly. Is 'Wordpress Hosting' a \"product\" WP Engine is selling? Kind of, yah? My understanding of trademark is also that \"we've been doing this for ages and you didn't say anything\" is a pretty solid defense, and \"Wordpress Hosting\" is about the most generic hosting service offered on the internet at this point, everyone and their dog offers it. reply sfmike 13 hours agoparentprevcould someone articulate that wordpress.com is more trusted then wpengine? reply anomaly_ 15 hours agoparentprevEh, sounds like mere puffery to me. reply Pet_Ant 18 hours agoprevThis seems like it will be relevant... https://en.wikipedia.org/wiki/Streisand_effect reply Kye 18 hours agoprevMy slightly earlier submission with a direct PDF link for people who aren't able to view Twitter: https://news.ycombinator.com/item?id=41631920 reply torginus 8 hours agoprevI'm just confused about the whole thing. Aren't WP hosts a dime a dozen? And if you don't like how they conduct their business, just set up one yourself. I set up one for a friend on AWS, and while it requires some tech savvy, it's not exactly hard for someone with basic tech literacy and ability to follow instructions. reply malthaus 12 hours agoprevsome of the comments here are exceptionally biased towards the party that does the \"open source washing\". just look at the childish way automattic acted. that's not a way to lead an organization or deal with your competition. you compete by building a better product, take legal action in an adult way if you think they are warranted and in general take the high road - not display your immaturity. the conflict of interest around the governance of wordpress is icky on top. so he just puts on his \"open source\" hat to gain favour for his for-profit company? reply jeanlucas 12 hours agoprevsemi-off-topic: Does anyone have alternative links to twitter? I'm in Brazil and don't wanna go around and risk a fine just for a tweet... reply urban_alien 10 hours agoparentnitter reply jeanlucas 10 hours agorootparentthank you very much reply 820jf98ajow 11 hours agoprev\"I'm literally waiting for them to finish the raffle so my talk can start, I can make it just a Q&A about WP very easily\" If I were attending a conference I'd hope that the keynote speaker would put more thought into his talk than this. Not only is it childish, it's disrespectful to his audience. reply mk89 7 hours agoprevWhen I read the title I was wondering \"strange, wasn't Automattic the company behind wordpress? Who knows maybe they split and now they sued them for XYZ\". Crazy. Instead of going through all this, can't Automattic do like what most companies are doing now? Dual License (e.g., Redis, etc). reply CPLX 17 hours agoprevWithout additional context the letter does read as persuasive. Is there significant additional context? Having looked at Matt's comments in the speech I'm not seeing any actual substance of what's wrong with WP Engine. reply _hmry 17 hours agoparentThere's possible context (unknown veracity) from this comment 2 days ago: https://news.ycombinator.com/item?id=41614406 reply cldellow 15 hours agorootparentI don't use WP Engine or WordPress, so I don't have a side in this fight. As an outsider, that context seems a bit dubious to me. @photomatt has tweeted [5135]: \"[...] Please let me know if any employee faces firing or retaliation for speaking up about their company's participation (or lack thereof) in WordPress. We'll make sure it's a big public deal and that you get support. [...]\" If this was true, I would think that @photomatt's twitter feed would be loudly boosting this disgruntled employee's story of WP Engine-imposed limits and subsequent retaliation. Yet @photomatt's twitter feeds seems silent to me. This makes me skeptical of this context. [5135]: https://x.com/photomatt/status/1836862087320195174 reply ufmace 14 hours agorootparentprevThat, and the whole thing about Matt M going on a scathing rant about how bad WPEngine supposedly is[0], supposedly because they don't support WP page revision control as well as he'd like. Seems a bit over-the-top and breathless to me. I figure the whole thing is a corporate whine-fest over who makes more money from actually hosting Wordpress sites. [0] https://wordpress.org/news/2024/09/wp-engine/ reply x0x0 2 hours agorootparentprevSeems unlikely though? Matt wrote a post on the web, ie he had unlimited length available to him. If the dispute is over employee contributions, then he should have made that the focus of his complaint. reply gjsman-1000 17 hours agoparentprevIt’s kind of perverse of Matt considering: A. He accuses “WP Engine” for being confusing branding. He literally owns WordPress.com; which confuses tens of thousands of people on a daily basis. (“Are you on the WordPress login page?” “I swear that I am!”) B. He complains about the post revisions not being limitless. But until recently, WordPress.com had a limit of 25. C. If post revisions matter, surely plugins matter, right? WordPress.com requires going up two tiers to use any unapproved plugins. D. Matt was an investor in WP Engine, and even appeared on their podcast last year, even though this revisions system limitation has been in place for a decade? E. This is the same Matt who wrote the WordPress Bill of Rights, complete with specifically saying “The freedom to run the program, for any purpose” and “The freedom to study how the program works, and change it to make it do what you wish.” F. The same Matt who wrote in the WordPress trademark policy that “WP” is not a WordPress trademark and anyone may use it however they wish? G. The same Matt who forked B2, and if B2 was still around, would be quite vulnerable to B2 potentially complaining about Matt’s lack of contribution to them? It goes on. I hate to say it, but every sign points to Matt being a hypocrite. Even an extortionist. reply keane 17 hours agorootparentHave you taken a look at wpengine.com? The name WordPress is everywhere with them declaring they are \"The most trusted WordPress platform\", \"The Most Trusted WordPress Tech Company\", \"[WordPress's] #1 managed provider\" and that \"WP Engine is the #1 platform for WordPress\". The WP Engine C&D insists they're allowed to use 'WP' (as you echo) but the dispute could be partly related to this broader marketing, which possibly creates confusion (a court will likely have to decide). Edit: To your first point, Automattic, who originally registered the trademark, apparently has a license from the trademark owner (the Foundation) to use the mark (at least for that domain). https://wordpress.org/book/2015/11/the-wordpress-foundation/ WP Engine, by their own admission, does not have a license. It also seems odd to call Matt perverse in what seems to be a trademark dispute without any acknowledgment that he is the inventor of the software, as such the founder of the community, that his friend Christine Tremoulet coined the name, and that his company originally registered the trademark. reply gjsman-1000 17 hours agorootparentWordPress’s own trademark policy states: > For example, a consulting company can describe its business as “123 Web Services, offering WordPress consulting for small businesses,” but cannot call its business “The WordPress Consulting Company.” Similarly, a business related to WordPress themes can describe itself as “XYZ Themes, the world’s best WordPress themes,” but cannot call itself “The WordPress Theme Portal.” If WordPress specifically says that using the tagline “the world’s best WordPress themes” is okay, it’s hard to show anything WP Engine has done as being unacceptable. https://wordpressfoundation.org/trademark-policy/ Edit, because I’m responding too fast or some nonsense: That’s an interesting point; but if that were true, Matt should have used that as his argument, after sending a polite letter first explaining that was going too far. This did not happen; and considering Matt was on their podcast and didn’t give a darn until lately, it appears to not be a real problem. reply keane 17 hours agorootparentThe paragraph prior: >All other WordPress-related businesses or projects can use the WordPress name and logo to refer to and explain their services, but they cannot use them as part of a product, project, service, domain name, or company name and they cannot use them in any way that suggests an affiliation with or endorsement by the WordPress Foundation or the WordPress open source project. At https://wpengine.com/plans/ they appear to offer a product/service titled/branded \"Essential WordPress\" with others to choose from being \"Core WordPress\" or \"Enterprise WordPress\". (mirror: https://web.archive.org/web/20240921160743/https://wpengine....) reply Stratoscope 16 hours agorootparentprev> Edit, because I’m responding too fast or some nonsense It probably isn't you. There is a short timeout of a few minutes on the Reply link in a thread. I think this to discourage hasty and unthoughtful arguments. But if you click the timestamp on the comment, it takes you a page where you can reply immediately. reply johng 17 hours agorootparentprevNot to mention his text messages. It's clear that if they were willing to pay, he was willing to not even mention them in his keynote. It looks quite clear that he wanted money and was willing to let everything slide if they got it. reply keane 16 hours agorootparent(1) The WPE C&D is, in my opinion, sloppily written, full of equivocation/fallacious reasoning. The situation is not \"clear\". (2) We haven't heard Matt's explanation of the text messages. (3) The WordPress name was registered in 2006 by Matt's company Automattic. In 2010 it was generously (no good deed is unpunished) transferred to a 501(c)3 and Automattic was given a license to the mark (at least in WordPress.com). According to WPE themselves: \"the payment ostensibly would be for a 'license' to use certain trademarks like WordPress, even though WP Engine needs no such license\". That's a potentially disputed claim: they very well may need a license as they are (currently) possibly in violation of the (generous) trademark policy by advertising services they've titled \"Essential WordPress\", \"Core WordPress\", and \"Enterprise WordPress\". It's unwise to malign Matt publicly – a court will be sorting out the necessity of the license. reply etchalon 13 hours agorootparentYou don't end a trademark dispute with a blog post claiming a host utilizing a feature any sane host would utilize is a violation of some core tenant of WordPress. You end it with lawyers talking to lawyers quietly. reply sureIy 14 hours agorootparentprevYou hit the nail on the head. Who knows what put a chili up his, but this debacle has started out of nowhere and he’s not the good party here. reply Spivak 14 hours agoprevThis is a pretty bad look for Matt, it comes off as yet another CEO who's mad that there's no first-party advantage to hosting OSS. Thanks to the GPL and no CLA he can't take it proprietary like others before him. When you're mad at someone for using their freedom-to-run and freedom-to-modify it doesn't come off as pro-OSS as you think. Weaponizing the trademark that's more strongly associated with the software itself than the company Wordpress is a pretty low blow. WP Engine is hosting Wordpress, full-stop. There's maybe a discussion to have about when modifications constitute a fork that warrants a different name but we're about as far away from that as you can be. I honestly don't know why Matt cares. His competitor is owned by PE, just wait for them to eat the business and offer a one-click migration. Play the long game. reply pluc 16 hours agoprevWell, there's that context we were all asking for. reply partiallypro 15 hours agoprevI know it's not considered \"contribution\" in the sense that Matt was talking about, but WPEngine owns and maintains some of the most popular and powerful Wordpress plugins on the planet. I'm not sure why he chose to pick a fight with them. My best guess is that he wants Wordpress.com (hosting) to be what WPEngine became. reply etchalon 13 hours agoprevIt sounds like Automattic was desperate for money and played a desperate hand badly. The receipts in the C&D don't leave one with a positive impression of Matt. I'll wait for Matt's response, but I can't imagine it's anything more than \"well, we deserve the money I was demanding!\" reply 18 hours agoprev[deleted] riffic 15 hours agoprevin the court of public opinion I think I know who I'm going to side with. reply manuelmoreale 12 hours agoparentI'm going to side with chaos: let both fail, let new products come up. reply mdotk 17 hours agoprevI'm no fan of WP Engine and their outrageous prices for very average performance, but this is a terrible look for Matt M if true. reply reply nikolay 2 hours agoprev [–] I love it! WP Engine showed its true colors. I also agree with Automattic, and I know customers who got tricked into using WP Engine and were later sorry for doing so! Sending C&D over this stuff is something that bans them for life in my book! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "WP Engine issued a \"cease and desist\" letter to Automattic, accusing CEO Matt Mullenweg of defamation and extortion over statements made in a keynote speech.",
      "Mullenweg allegedly claimed WP Engine exploits the WordPress ecosystem and misuses the \"WP\" trademark, demanding $40 million to avoid further negative publicity.",
      "The incident underscores ongoing tensions regarding contributions to WordPress development and trademark usage, dividing the community's opinions on both parties' practices."
    ],
    "points": 252,
    "commentCount": 180,
    "retryCount": 0,
    "time": 1727137318
  },
  {
    "id": 41635583,
    "title": "Move Fast and Abandon Things",
    "originLink": "https://engineersneedart.com/blog/movefast/movefast.html",
    "originBody": "Engineers Need Art Projects SystemSix Mooncraft 2000 Adam74 Stereographer Move Fast and Abandon Things 15 Sep 2024 Almost-Rans Maybe it’s the change of weather. Fall often finds me looking backward, to the past — and anyway it is as good excuse as any as to why I have found myself peering into old hard drives trying to recover old bits and bytes from games that I wrote some thirty-five years ago or so. Shareware games that I released all those years ago I gathered onto a disk image and posted to GitHub as Soft Dorothy Software — Early Shareware Projects. I wrote about the sometimes extraordinary work I needed to employ in order to recover some of these in a blog post. The disk image is the kind you can drag to a 68K or PPC Mac emulator such as Basilisk II, Sheepshaver or MiniVMac. I followed up the shareware disk image with a disk image of Casady & Greene Projects. Casady & Greene was the name of the company that published my Glider 4.0 game back in 1991 and so the sources and build tools used to create Glider 4.0 are on that disk image. The thing that I enjoyed the most about this trip down memory lane was rediscovering and revisiting the almost-rans. While the paper airplane game I released is what people might know, there were plenty of game experiments that never even made it beyond the Hello World stage — for various reasons. What I rediscovered on the old hard drives were many of those early experiments. In trying to recover them, get them to compile again, I was reminded that there are so many indefinable things that go into making a good game. Some of these abandoned experiments may in fact have been gems in the rough had I spent a little more time trying to facet them, polish them. Or maybe not. AirBikes would have been a futuristic racing game — if it had been completed. Move Fast I was really excited to also find a document that I had created in 1991 or so listing the games and “creator codes” that I had used in these games. Creator codes were like a very crude “bundle identifier” back in the pre-OS-X era of the Macintosh. They were supposed to be unique from all other application creator codes. The document is interesting to me today because in it I had cataloged the projects that I had worked on up to that point. What follows is the list I created containing a creator code followed by the name and then the state of the game: Out of twenty-seven titles, five of them I released (highlighted above). What were the other applications? Quick prototypes. And these represent the projects over about an eighteen-month period. (At the time I created this list I was apparently “working on” three titles.) I guess to be precise, I did release UnMask — a utility I spent ten minutes writing. I would dismiss it from the data though. I was very prolific during that time — staying up well past midnight coding every night. I also developed a kind of “shell” for the type of sprite-based games that I was experimenting with so that the cost of a new “sketch”, a prototype game, was primarily paid for in MacPaint — creating the sprites, artwork. A little code for unique input methods, some game mechanics or physics would also be needed. Sounds, high scores, saved games — these are the things we could kick down the road, implement only for the deserving games. Sprites from AirBikes. But I was developing a methodology of prototyping ideas quickly in order to determine (quickly) if an idea had legs — if it stuck to the wall so to speak. Prototype Things Games are funny things. When I consider games that I liked, the reasons the game hooked me are often nuanced. I’m not sure you can just set out and make a good game. Serendipity seems to plays a role. Or maybe it’s just that I have found myself unable to just conjure up a great game the first go. Want to know if a kite-fighting game would be fun? Knock out enough of the game in a few days to where you can play with the physics and control of the kite. If flying the kite is too difficult to master, probably no one is going to enjoy the game. On the other hand if just flying the kite is fun, even without the combat element, you’re probably on to something. Another racing game, K-10 (Kansas highway 10) never moved beyond the prototype stage. Maybe you have played the arcade game, Joust. Even before enemies rez in it was fun just hitting the flap button to fly — sometimes having to pace your flapping, sometimes flapping frenetically to climb quickly. Quite fun. I found that a simple game where a paper airplane in a cluttered house had to make use of floor vents to get lift was kind of fun as well — even before you realize you should be making progress through the rooms and avoiding toast or whatever. But as I say, there’s only one way to find out if what you thought would be fun on paper is in fact fun. Abandon Them Some games make it out of the starting gate but then you find there’s nowhere to go with the game. In my list at the top of this post I had brutally notedfor some games. Like the platformer game I began, Thief of Baghdad, where you could ride a magic carpet and leap about. That was kind of fun, but … then what? Thief of Baghdad never got off the ground. Consider too that I was a solitary programmer. So some games seemed to have potential but it became clear very quickly that I would need to invest a year or more to get the game to a finished state. I loved Dungeons and Dragons and would have loved to write a sprite-based adventure game. But, man, when I consider all the sprite-work that would be required for the player, wielding all the weapons they might wield, all the monsters and their moves, all the spell effects, etc. Never mind coding all the spells, varied combat, etc. Lunge, parry … cool. Now draw her fighting with a mace, and then a bow. Also she might wear a cloak. Not Really Dead But this is not a case of The Marriage Problem, you can always go back and revisit a game you had previously shelved. (Assuming you can still find the sources, resources, and project files.) I did revisit Thief of Baghdad eighteen or so months later (in color and renamed Scheherazade) and it even started to get “a point”. Alas though, maybe you can’t go back after all — or perhaps should not. While I got further with the game in its second incarnation, it never really attained that indescribable something and so was abandoned again. Never mind that you can also harvest code from any of your shelved projects. I mean why rewrite the Fisher–Yates shuffle algorithm if you have it already in a shelved game? Code for switching the monitor depth (on those early Macs) I moved from game to game… Polygon-point collision code, a sine lookup-table for quick trig functions, a dot-product routine, cross-product routines… I never regarded these prototyping efforts as wasted ones. Salaryman The era of the indie Mac game developer felt to me like it was coming to a close as the 1990’s decade proceeded. In any event when I was presented with a job offer to come out to California and work at Apple I eagerly took it — even though I understood that from that point on I would not be allowed to work on non-Apple projects in my spare time. Not strictly true — to code outside of work though you did have to get written permission from management. I mean it’s part of that whole non-compete clause — tech companies having been burned throughout history by employees creating start-ups that eventually take over their business. Apple was not in the games business so perhaps I would have gotten a pass. It’s that fear that: what if I ask for permission and they say no? Finding myself in a world of whiteboards and conference rooms made no difference — I found that I continued to take a quick-prototyping approach to any project that landed on my desk (though, perhaps needless to say, the projects were no longer games). Other programmers that I worked with (maybe I should call them software engineers) designed software. And they made better use of the whiteboards than I did. Rather than iterate at compile-time like I was want to do, they would instead carefully plan and design their software before ever typing a line of code — iterating I suppose on a whiteboard. I wrote flight-sim code following a book and I soon had a steam-punk project … shelved (too much still to do). From my approach of diving in rather than planning I began to regard myself at Apple as a “blue-collar” programmer working among “white-collar” professionals (imposter syndrome maybe?). But to give myself some credit, after having written code for seven years or so at this point, my instinct as to which direction to dive in with a task was at least an informed one. There’s a guy on GitHub, his status is “I am typing on the keyboard to do the job.” Story of my life — I like it. No doubt though, often enough, this freewheeling approach might send me into the weeds. But with the speed at which I pulled the code together, I often found the bottlenecks fairly quickly — quick enough that I could more or less start the whole project over. If you find this narrator reliable, I will say that I often would start and then restart a project perhaps three times and, when all was said and done, have the project in as good a state at about the same time that my white-collar cohorts would have their more carefully designed code also running. So was the whole exercise of my guerilla programming technique a wash? Maybe. But it always served me well (or was perhaps the only way I knew to program effectively). Often though my last code revision was in fact to simplify the code — generally to make it easier to follow, easier to understand, easier to maintain. (The insight on how at last to organize the code having come out of treating the whole thing as wildly mutable from the beginning.) There were times too when a coworker might have said, “You should have used a Bloom Filter” and I was able to come back with, “Yeah, already tried that but the typical data we are seeing is so small that the performance gains were negligible and added unnecessary complexity to the code base so I tossed it.” Boom! (Okay, maybe something like that happened only once — but it was awesome when it did!) A.B.I. By the time I finally retired I had slowly come around to feeling like I had in fact been a contributing employee at Apple. To be clear, it was important to me to be a contributing co-worker really. The engineers on the teams that I worked on were the highlight of working as a salaryman (no longer coding solo in a monitor-lit corner of the bedroom all night). I worked with the smartest people I have ever come to know. There were people I worked with that were an order of magnitude better programmer than I will ever be. And it was important to me to feel like I was helping too in my way. I think I did rank among the fastest programmers. (Is that a category?) You wanted something prototyped to show as a demo for a meeting this week, I’ll have two versions for you then (one with and without a Bloom Filter, ha ha). And this bit is for my daughters. I have always told them growing up, “A. B. I.” “‘A’ — Always. ‘B’ — Be. ‘I’ — Iterating.” “Always Be Iterating.” I put together disk images of these games-that-never-were — projects, sources, tools — and posted them to GitHub. The pixel art of that early Macintosh era, especially the B&W era, resonates with nostalgia for a lot of people. There might too be a lesson to game devs in all the times that a game has not launched. For me, as I stated at the outset, I assembled these relics for the memories — or maybe to close that chapter. I have posted the disk images I have assembled to date as Soft Dorothy Software: Unfinished Tales (Vol. 1) and Soft Dorothy Software: Unfinished Tales (Vol. 2). There will be a Volume 3. It’s a bit of work though to get each project in shape for “release” so I can’t promise when a follow-on volume will appear.",
    "commentLink": "https://news.ycombinator.com/item?id=41635583",
    "commentBody": "Move Fast and Abandon Things (engineersneedart.com)222 points by JKCalhoun 6 hours agohidepastfavorite65 comments zackmorris 2 hours agoThis post really resonated with me, as I have between a dozen and a hundred abandoned projects, mostly games, since I started programming around 1989. Most of them written for the Mac Plus or Mac LC. And many of them following a similar mechanic or art style to the ones in the post. I think of the few shipped projects I've released or been part of as a shadow of who I am. Same with my resume and work experience. They're a fingerprint of a whole being living a dream life that never manifested, because I never had an early win to build upon. That's why I think UBI might magnify human potential by 10 or 100 fold, to get us from the service economy to agency and self-actualization, producing our own residual incomes. Oh and I played Pararena a ton! reply authorfly 33 minutes agoparentI do have a different opinion to you, and it was formed during the pandemic when there were UBI-like circumstances for me and my friend group. Those who didn't need to work any more, became rather depressed, quite quickly, compared to those who kept working. And it changed my view on UBI. Maybe in your friend group that was different or your country didn't follow such an approach? What's the difference between working on several games or focusing and finished one to you? Would you work on these things enough to produce finished projects if you had UBI? For more than a while? I think at some life stages, like parenthood or childhood, UBI makes sense. At others, when you are finding yourself - having a responsibility is useful. reply scottLobster 3 minutes agorootparentThat's why in the sci-fi, utopian economics of the Star Trek Federation they have a \"participation based\" UBI, where your ticket to the Federation's generous UBI (made possible by effectively infinite material resources) is contingent upon you doing something productive. You can't just sit on your ass all day and collect it. Now how they measure/judge what's \"productive\" and the fact that it works at all is what makes it sci-fi, but it highlights that responsibility is critical, even in a utopia. reply imchillyb 38 minutes agoparentprevIf minimum wage didn’t work, what metric makes you believe that a similar system but paying those who don’t work, will? This type of thinking truly baffles me. This magic UBI will be minimum wage for the masses that don’t work. How could that, possibly, be sustainable or even good? reply malignblade 12 minutes agorootparentAnswering your literal question, how could it \"possibly\" be good: Minimum wage probably doesn't work because it means a lot of people live in precarity while both emotionally and physically exhausting them. It might just be that minimum wage has stagnated while COL has skyrocketed. If the point of minimum wage is that it provides people with a guaranteed dignified life as long as they are employed, that needs to keep up with the cost of living a normal life in order to keep its effectiveness. That is one reason it might be \"failing\" although I don't know exactly what you mean by that. > get us from the service economy to agency and self-actualization This is the thing I think most people have a hard time connecting to \"measurable utility\" but will probably be the most sweeping effect of UBI or similar. Think about your typical gig worker, minimum wage worker in some high-turnover environment etc. This person probably does not have the financial safety net to pursue something meaningful, or to take the risk reskilling, or to otherwise improve their emotional and financial well-being. You will probably always have free-riders or people who just want to consume without producing. But is it better to have a society of exhausted, frustrated, barely-hanging-on people, or a society of people with the _potential_ to to be creative, passionate, and exploratory? Conversely to you, I find it hard to imagine that a society with surplus wealth would be more effective if it chose to subject its people to precarity and emotional strife instead of empowering as many of its people as possible. Some references: https://www.epi.org/publication/charting-wage-stagnation/ https://www.statista.com/chart/25574/living-wage-vs-minimum-... reply agumonkey 5 minutes agorootparentprevI believe UBI would require a few external attractors / motivators to avoid people being dilluted in choice and fuzzy self actualization path. reply alexissantos 26 minutes agorootparentprevPart of me wonders if this parallels the venture capital approach. Many won't don't anything economically productive with the opportunity UBI affords them, but the ones that do may make the cost worthwhile. Not sure if that's how it would actually pan out, of course, but I think it's plausible. reply dietrichepp 1 hour agoprevI’ve been going back and working on retro development. These days, making software for the 68K Macintosh, which is where I learned to program in the first place. I dug a lot through old books, comp.sys.mac.programmer posts, and the source code from Soft Dorothy and others (like the GliderPro source). It’s a trip seeing this old code through new eyes. I can see why the old Macs crashed so much (beyond the basic “they had no memory protection” explanation). I’m also fond of the 1-bit art, like the author mentions, and I curate a list of accounts on Twitter which post 1-but artwork (if you know anybody who’s missing from the list, let me know): https://twitter.com/i/lists/1578111923324944397 The nice thing about programming for a limited system is that it limits your options. It’s a nice break from the more modern experience where you can do anything by pulling in the right library. I sometimes imagine a world where computational power is frozen, and we simple get better and better software for systems that are well-understood. The thing about these old systems like the Mac 68K machines is that the pace of hardware development was so fast it made you dizzy. If a new processor came out like the 68020 or 80386, then you had maybe a couple years at most to make something that really used it to its full potential. If you waited too long, you’d be competing against a new generation of software written for a new generation of hardware. reply karaterobot 4 hours agoprevThat's a neat blog all around. Lots of interesting stuff to poke around in. I think it's okay to abandon things, and you can certainly learn things and reuse parts from abandoned projects. For me, a breakthrough moment was when I decided to make things so small that I could finish them. It helped me develop the skill of finishing things, which is a separate skill that's hard to learn, because it only happens at the end of a process so long and hard you almost never make it there. All my friends who are making video games start by writing their own engine, and get burnt out somewhere around the point where they're making a level editor. They learn a lot about things like tooling (which, coincidentally, is a lot like what they already knew how to do), but never actually make the game. It'd be like learning stone masonry by building a cathedral—you won't live to see the end. Start so small that you can't fail, then work your way up to bigger and bigger projects. reply bob1029 3 hours agoparent> All my friends who are making video games start by writing their own engine I've been there and done that one a few times. Even if you decide to use existing tools, you can easily get caught up in these infinitely-deep pools of complexity. I am working on a Unity project right now wherein I found myself antagonizing over how to best develop an RTS-style building placement system. Instead of doing what I would typically do (dive right in), I decided that I would rework the game concept to eliminate the need for the player to place buildings at all. After some experimentation, it turned out that this was actually a superior user experience for what I was trying to achieve. I initially rationalized it as \"I'll add the building system in the next iteration\". It likely won't happen now. Less is almost always more. That small starting point actually being finished is like nitromethane for the next iteration. Getting to 100% is what makes that next pass so much better. Getting to 80% will leave you feeling like you need to push the rock back up the hill all over again. reply lelanthran 2 hours agorootparent> I decided that I would rework the game concept to eliminate the need for the player to place buildings at all. This sounds interesting. Can you explain a bit more about this? reply bob1029 1 hour agorootparentSure. I replaced the building system with a big portal that each team controls. Instead of in-game buildings, I built a menu/UI system that allows the player to control which units would come out of the portal. Units don't take commands from the player (another massive simplification). They only seek out the enemy portal and will engage other units on that path automatically. Destruction of the portal is the win condition. Unity's navmesh system is doing most of the heavy lifting right now. It's amazing how much functionality you can get out of it before you have to reach for physics and animation. reply iamacyborg 1 hour agorootparentSounds vaguely similar to a late 90’s pc/playstation game I recall playing, although that also had capture points and the ability to build defense structures along the predetermined paths. Edit - this one https://en.wikipedia.org/wiki/Future_Cop:_LAPD reply chambers 36 minutes agoparentprev> It helped me develop the skill of finishing things, which is a separate skill that's hard to learn, because it only happens at the end of a process so long and hard you almost never make it there. Great insight. The skill of finishing what you started, is something that feels elided in discussions around productivity. Is there a blogpost or article that explains it even more? reply burningChrome 2 hours agoparentprev>> I think it's okay to abandon things, and you can certainly learn things and reuse parts from abandoned projects. I recently moved from front-end development into accessibility. Years ago, I had built a bunch of static sites, templates and other design projects that I had eventually abandoned for various reasons. Now that I'm in accessibility, I've gone back and dug many of these out and have re-built them to be accessible. Several used very old versions of bootstrap, so part of what I did was also upgrading to the latest version of bootstrap as well. I learned so much just from going back and making those older designs accessible. Its something that I definitely feel gave me a better perspective on stuff we look for when we're assessing sites and applications. It was also a real wake up as to how much of the stuff I built wasn't accessible at all. reply cezart 3 hours agoparentprevThank you for sharing this! I think a focus on shrinking personal projects to the point I might actually finish them, might be just what I need right now reply eddd-ddde 3 hours agoparentprevI don't think I've ever finished a _single_ personal project. At least for me that's _the_ hardest skill to develop. reply EricE 3 hours agorootparentLuckily this is also on the front page today: https://github.com/readme/guides/finish-your-projects reply pton_xd 1 hour agoprevPersonally I've learned (and earned) way more by shipping small things and THEN iterating on them. Or abandoning them. reply xiaoxiong 4 hours agoprevSome of the pixel art in those screenshots is seriously awesome! reply adamc 4 hours agoprevI like this and find it interesting, but at an organizational level, it strikes me as trickier to do. A lot of the things we discover about projects and technologies have to do with its feasibility at whatever scale our real projects operate on, and don't necessarily pop-up in smaller experiments. (And sometimes they aren't really technical issues at all, but issues of \"can we get most developers here to understand doing it this way.) None of which means we shouldn't do more of this. You can learn things by trying smaller projects. It's just not a guarantee it will work in the large. reply jujube3 36 minutes agoprevThe new Google motto? reply mojuba 5 hours agoprevIf the goal of this article is to normalize abandoning your projects then I'm not so sure it's a good idea. All else aside it can be a horrendous waste of time and no amount of \"at least I've learned something\" can justify that. Learn by also finishing stuff, right? reply bunderbunder 4 hours agoparentThere's a great Smarter Every Day episode where Destin works with a glassblowing shop to create shattered Prince Rupert's drops encased in blocks of resin. Nobody has done this before, they're working out how to do it as they go along, they make quite a few mistakes along the way. One of the things the video highlights is how, when this happens, the team wouldn't just stop and try the same thing again. They'd keep going, break it all the way, basically just use it as an opportunity to fuck around with their materials. He waxes poetic about how great this is. They're taking advantage of an unparalleled opportunity to learn more about the behavior of the materials they're working with. Because they're now free to try things they wouldn't want to do if they were still on the path to creating a complete, polished product. It doesn't even really count as taking risks anymore, because you can't really mess up something that's already trash. And he points out, rightly, that a mindset like that that values learning and experimentation over always succeeding, is one of the best ways to become truly great at what you do. reply ebiester 5 hours agoparentprevThe thing is that he also finished stuff. The goal is to avoid analysis paralysis and \"just try it\" instead of keep thinking about it. It's a bias toward action and rejecting sunk cost. reply Fellshard 5 hours agoparentprevThat is a misreading of the article. It's more about discovery through quick, iterative prototyping, which can include rapid discovery of fatal flaws early. reply thuruv 5 hours agorootparent+1 I am reading this is exactly pointing to the same concept as the todo management, but not addressing the todo paralysis. Everyone's mileage may vary. I accept that. Yet misreading something is far more dangerous than ignorance. reply Dalewyn 5 hours agorootparentprevAs Musk would say: Waste metal, not time. reply kyledrake 4 hours agorootparentThe man that spent his time on an overpriced takeover and subsequent ruining of Twitter instead of spending that time with the children he abandoned is a cautionary tale of wasted time, not a sage to be mined for wisdom. reply Dalewyn 4 hours agorootparentWasting metal instead of time is the difference between Dragon and Starliner. I will listen to the guy who's actually getting things done, thanks. reply jsight 9 minutes agorootparentIt is funny how much criticism you are taking for saying things that are obviously true. Yes, Musk's personal life is a mess and noone would enjoy being him. That can be true at the same time as his business philosophy effectively pushes forward multiple businesses more quickly than their competitors. That can even be true while his businesses are run in ways that most of us would find unacceptable. Regardless of palatability, SpaceX is effective. reply kyledrake 3 hours agorootparentprevImagine how much more he would get done if he addressed his mental illness and filled his life with the richness of family and social bonds instead of wasting that time gaming an algorithm on a platform he paid too much for to become the leading proprietor of authoritarian-conservative junk posting. If anyone thinks he doesn't have enough time for that, go over to Twitter and look at what he's doing with that time he doesn't have right now. reply lelanthran 2 hours agorootparent> Imagine how much more he would get done if he addressed his mental illness and filled his life with the richness of family and social bonds The people I know who satisfy that definition don't generally get shit done. The ones who do are outliers; i.e. so rare that you may as well judge them to be a rounding error. reply Dalewyn 3 hours agorootparentprevMy only takeaway from this exchange is you're jealous the man had the money to just go and buy Mysterious Twitter X and do with it as he wants, instead of complaining about it like the rest of us. reply Eisenstein 1 hour agorootparentI would like you to image a day in his life. His pleasures, accomplishments, fears, and compulsions. A personality and a lifestyle that drives away everyone except acquaintances and employees. The kind of insecurity that causes a person to gravely insult a someone who risked their life, many times over, to save the lives of strangers half a world from their home because they dismissed your media ploy in public. The kind of personality that is so addicted to attention that despite repeated public embarrassments that would make most people rethink their actions, they reform their own worldview in order to blame society instead of rightfully feeling ashamed. A person who has a compulsion to make money constantly when there is no longer any purpose to do so -- to the point where they use guest appearances on comedy shows to pump and dump novelty crypto coins in order to make a few more pennies. Does that sound like a happy, content person? If anyone is jealous of that life just so that they can have the fame then all I can say is that there is ever an opportunity where one of us can grab that for themselves, please -- be my guest. reply kyledrake 3 minutes agorootparent> The kind of insecurity that causes a person to gravely insult a someone who risked their life, many times over, to save the lives of strangers half a world from their home because they dismissed your media ploy in public. Called him a pedophile no less. He didn't win the libel case in court, but he certainly deserved to. The actual story of the cave rescue and the highly specialized cave divers that pulled it off is quite incredible, I highly recommend seeing it as it happens in The Rescue. The documentary takes the high ground and doesn't mention the Musk fiasco, but without directly doing so, also lays waste to how impossible the submarine idea was: https://films.nationalgeographic.com/the-rescue kyledrake 2 hours agorootparentprevIs he actually calling it Mysterious Twitter X now? reply bunderbunder 3 hours agorootparentprevIt's worth pointing out here that SpaceX's current product development practices and Boeing's current product development practices is a bit of a false dichotomy. We could also, for example, consider how Boeing did things a few decades ago. One particular reason I don't like this false dichotomy is that SpaceX's approach has negative externalities that aren't getting enough attention because everybody's so starstruck by all the fancy rockets. There's a reason the FAA and EPA are starting to pressure SpaceX about the environmental and social impact of their way of doing business. Maybe next OSHA can get on them for the high workplace injury rate. You're not actually doing things more cheaply if what you're really doing is hiding costs that would belong on your balance sheet by surreptitiously foisting them onto the public with the help of corrupt politicians. (Ostensible libertarians, pay extra attention to those last six words.) reply Mathnerd314 3 hours agoparentprevI think it's a bad title. The moral is more like \"work on everything you can think of but don't release anything until it's ready. And some projects will never be ready, but that's OK - you can look at them 30 years later and release them on github for nostalgia.\" ChatGPT summarizes it as \"Build Fast, Ship Never (Until You Do)\" reply criddell 3 hours agoparentprevLike John Lennon once said, time you enjoy wasting isn't wasted. reply mojuba 1 hour agorootparentArtists can say that, especially if it's John Lennon :) but I'm not sure I can apply it to myself reply Stem0037 3 hours agoprevIt’s interesting to consider how your guerrilla programming techniques could integrate with contemporary development tools and practices. For instance, leveraging version control systems more extensively or utilizing collaborative platforms might enhance the efficiency and scalability of your projects. reply for_i_in_range 3 hours agoprevSome of the worst advice I read comes from some of the smartest people out there. reply avg_dev 4 hours agoprevthis seems like a fantastic way to look back on a career where the author started as a prolific solo developer and later became an effective, fast, and contributing part of an effective development team. it was also just really fun to read, about the code reuse, the scrapping of ideas, the rewrites, etc. reply specialist 1 hour agoparentYes and: Quote from another blog entry \"In the end I think Apple got an engineer for the next twenty-five years that, though not the cleverest engineer, was one that worked quickly to prototype new ideas and took on some of the gruntwork that not every engineer wanted to work on.\" Some of us like doing the blue-collar parts. Plumbing, prototyping, fixing bugs, fit & finish, tackling tech debt. Alas, today's leetcode themed hazing rituals, err, interviewing filters out people like me, and presumably John Calhoun. I was fortunate to manage project and product teams with a mix of skills, temperments, experience. Pairing up doers with esthetes can work out great. In that \"whole greater than the sum\" sort of way. FWIW, most of the doers (I've managed or worked with) had no CS education and experience. Just an interest, curiousity in tech. Notables were a ballet dancer, historian, handful of mechanics, biologist, aeronautic engineer, sculpture, and of course musicians. People who would never get hired, much less considered, today. Every team needs at least one doer. reply brendanfinan 4 hours agoprevEngineer Sneed Art reply gwervc 2 hours agoparentGlad I'm not the only one who parsed the domain as such :) reply doublerabbit 1 hour agoprevMines just time. I get home from work, the last thing I want to do is sit in front of my computer. With two days off a week to fulfil with chores, I still don't want to sit in front of a computer screen. reply jimkoen 1 hour agoparentI'm a junior, currently trying to get an internship and subsequent job. I envy anyone that can do what you do. At the moment it feels like the industry is a cult, only looking for people that make tech and programming their entire life. I don't even mind the requirements, I have a work ethic and want to perform well, but the expectations seem higher than ever. I'm looking forward to finally having enough job security for a hobby that doesn't involve staring at computer screens (hoping to get into metal work soon). reply taeric 4 hours agoprevSomewhat related, I think, I am always surprised at how often we don't have non-critical paths in jobs. Half the reason stress is so high, it seems, is we have backed ourselves into a situation where things have to succeed. reply rurban 4 hours agoprevThat's exactly the playbook how they destroyed Perl6 then. They had the very same outspoken motto \"Move fast and destroy things\". They indeed do so very successfully, instead of fixing just the few outstanding bugs. reply wduquette 4 hours agoparentThat's not what the OP said. He said, \"Try things quickly, and abandon the ones that don't pan out.\" Nothing in there about destroying things that are working. reply rurban 3 hours agorootparentI didn't say that. I said that you should not destroy things that dont work. You should rather fix it. reply wduquette 3 hours agorootparentWhy? It's an idea you try to see if it has value. If it turns out not to have value, move on to something else. reply 03179794816 3 hours agoprevOk reply norir 2 hours agoprevAbandoning things is essential to development. If we didn't let things go, we'd be stuck with all of our weaker ideas. That doesn't mean they are bad or a waste of time, but rather you reach a point at which you realize there is something better you could be doing and move on. This can be painful but it's necessary. I keep beating this drum but I believe there is a significant amount of pain in software because people shipped first drafts and got stuck with foundational design issues. Once this has gone on long enough, even a greenfield rewrite is hard because both the programmers and the users have internalized the flawed design. reply perrygeo 2 hours agoparentAnd in many cases the entire org chart has been built around the first draft. It's psychologically hard for developers and for people paying the bills to throw stuff away, so we often dig in our heals and accept the first solution that works, along with the tech debt and resulting pain. Now the drum I keep beating is - software process needs a design phase. You need some plan, some coherent vision of the architecture, otherwise you get a system held together with duct tape and prayers. Agile made it fashionable to sprint ahead without any coherent plan. Waterfall obsessed about the plan and failed to adapt to new circumstances. There has to be somewhere in the middle where a design is subject to empirical testing. We have to change the design based on results of running real code. In other words, when the first draft doesn't work quite right, you don't ignore it (Agile) or try to shoehorn it into the existing design (Waterfall) - you change the design and try again. \"Throwing stuff away\" could be reframed as the scientific method. This needs to be normalized as a part of the process so we remove the stigma of \"failed\" experiments, which are not failures but valuable sources of information that improve the final product. reply hirvi74 2 hours agoprevI'm not sure I am all for abandoning all projects, but I do remember reading a comment on this very website that really resonated with me. Someone was complaining about always starting projects, but never finishing said projects. To paraphrase another user's response, it was something like, \"Not all projects need to be finished in order for value to be gained. To borrow a concept from Buddhism, perhaps you found what you were looking for all along?\" reply mym1990 3 hours agoprevThe irony of the #3 thing on HN today being this, and the #5 thing being 'Finish Your Projects' haha. Good points all around. reply parsimo2010 3 hours agoparentI think that these ideas are both compatible. In this blog post, it looks like the author finished working prototypes of several games but elected not to push them to a full release. So I think they “finished” the work, and we can’t fault them for estimating that it wouldn’t be worthwhile to make a full release. Not finishing a project in this case would be abandoning a game idea that you liked before you even got to a working prototype stage. Because then you can’t even see if your new idea plays well. reply mym1990 2 hours agorootparentYeah totally, I don’t disagree with that assessment. I would say it’s not productive to try to complete every single thing we start. It was just the headline snippets that were funny to me. reply loup-vaillant 3 hours agoparentprevIn a sense though, seeing that whatever project we're working on is no longer worth pursuing, is finishing that project. That's very different from letting life happen and stop working on it without really having decided it. reply mym1990 2 hours agorootparentClosure is important! I do feel that I get in the mindset of saying “I’m gonna get back to this later” and it just never happens, meanwhile taking precious mental capacity every time I think about doing that thing. It’s okay to say “I tried it, I don’t need to prove anything, on to the next adventure”. reply mathgeek 2 hours agorootparentprevI usually think of abandoning and finishing as two different ways to resolve a project. Resolution is a good goal that allows you to be explicit about what was finished or not before stopping. reply meindnoch 4 hours agoprev [2 more] [flagged] alex_suzuki 3 hours agoparent [–] Except for the moving fast part? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A developer has released a collection of old shareware games and unfinished projects from the early Macintosh era on GitHub, under the name Soft Dorothy Software.",
      "The disk images can be used with 68K or PPC Mac emulators like Basilisk II, Sheepshaver, or MiniVMac, allowing users to explore these nostalgic pieces of software history.",
      "This release offers a unique glimpse into the game development process of the past, showcasing both completed and abandoned projects, and highlighting the iterative nature of game design."
    ],
    "commentSummary": [
      "The article \"Move Fast and Abandon Things\" emphasizes the importance of quickly prototyping and abandoning unpromising projects to foster innovation.",
      "The author suggests that Universal Basic Income (UBI) could enable more people to pursue creative endeavors without financial constraints, sparking a debate among commenters about its impact on mental health and creativity.",
      "The discussion also highlights the balance between finishing projects and the benefits of focusing on smaller, manageable tasks to avoid the pitfalls of abandoning projects too hastily."
    ],
    "points": 222,
    "commentCount": 65,
    "retryCount": 0,
    "time": 1727179082
  },
  {
    "id": 41633155,
    "title": "Maker Pipe – Structural Pipe Fittings for DIY Builders",
    "originLink": "https://makerpipe.com/",
    "originBody": "0 Your Cart is Empty Continue Shopping $0.00 Subtotal Checkout Shop Kits Build Ideas Learn How Our Story Blog Videos Community All Connectors Kits Extras ALL US ORDERS SHIP FOR $7.99 OR LESS! SHOP NOW Menu 0 Your Cart is Empty Continue Shopping $0.00 Subtotal Checkout Your Cart is Empty Continue Shopping $0.00 Subtotal Checkout Shop Kits Build Ideas Learn How Our Story Blog Videos Community Contact Us 1-843-245-9747 Login ALL US ORDERS SHIP FOR $7.99 OR LESS! SHOP NOW 1-843-245-9747 Contact Us 0 Your Cart is Empty Continue Shopping $0.00 Subtotal Checkout Login Shop Kits Build Ideas Learn How Our Story Blog Videos Community All Connectors Kits Extras All Connectors Kits Extras All Connectors Kits Extras Endless Possibilities With Maker Pipe LEARN HOW SHOP NOW Our Connectors Maker Pipe is a system of steel pipe connectors that turns ordinary EMT Conduit into an affordable building platform with endless possibilities. Designed so you can build easily with simple hand tools. EMT Conduit EMT Conduit is a galvanized steel pipe that is strong and trusted by builders. It's readily available in the electrical aisle of your local hardware or home improvement store. Together they are easy Building with conduit and Maker Pipe is easy because you don't need any special tools or skills. A 5mm hex wrench is all it takes to make a connection. Conduit can be cut with a simple hand held metal pipe cutter. affordable Cost shouldn't hold your DIY project back. That's why we designed our affordable connectors to pair with inexpensive electrical conduit. This means you get to save money while making your DIY dream a reality. strong Just because it's easy and affordable doesn't mean you have to compromise strength. Metal conduit and our Maker Pipe fittings are made of durable steel so you can build with confidence indoors and out. You can build anything from a desk to a go kart Check out these creative conduit projects built by makers like you People Love Building with our connectors Don't believe us? Check out these Customer Testimonials! Ladder rack for enclosed trailer! Simple, yet effective and $$$ saver! Chestly I was very satisfied with the product. It did exactly what I was hoping it would do. I built a rugged, durable collapsable duck blind on an 18 foot Lund Alaskan. Excellent product. I found out about this product on the Facebook page DIY duck boat and blind builders page. I highly recommend this product to anyone that wants to build something DIY but with a bit more of a professional finish. Joel M. I just wanted to reach out and tell you how great the Maker Pipe worked for the sign we made! Bill Auntie Vivs I love this product! I have used it to build various things i.e. launch stands for drone racing, shelves for garage etc. I mean is this not cool? Rick C. I looked into railing kits but to get what I want it's stupid expensive. I've worked for an electrical contractor and I've built countless solutions to crazy problems using EMT conduit, usually by welding which is difficult and dangerous because of the zinc galvanize. I no longer have access to a welder so I began to search \"conduit fittings\" which led me to Maker Pipe which is the coolest concept ever! Electrician Eric Maker Pipe is great for teaching design processes. Our students are using power tools and pipe cutters to create their own workstations. It’s great! Robert Estelle Manor School District I love your brackets because I can adjust the shelving to different heights unlike the plumbing stuff! Carol Lynn Recreate Designs Found a great use for this! I have a mobile detailing company and was concerned about added weight for a shelf in the van. Then I came across these baby's! They worked amazingly. Super easy and affordable. Brennen After extensive internet searches, I found that Maker Pipe offered the great pricing with even better quality. Thanks for developing a wonderful product! Darrin C. I was just reaching back out about my recent purchase. The connectors were used to make a kayak cart for my sit on top fishing kayak. To be honest I couldn't be happier with it. I appreciate the quick service in both fulfilling my order and the great customer service that followed. Thank you! Sam H Thanks for making such an invaluable tool! Loreto R. A Few Of Our Conduit Creators OUR MOST POPULAR STRUCTURAL PIPE FITTINGS T Connector $3.34 90 Degree Structural Pipe Connector from $5.79 180 Degree Structural Pipe Connector from $4.95 45 Degree Structural Pipe Connector from $4.95 Adjustable Angle Hinge Connector from $3.24 Adjustable 180 Degree Connector from $2.95 Flange Connector from $4.95 Adjustable Angle Flange from $3.24 EMT Conduit Structural Coupling from $4.95 135 Degree Structural Pipe Connector from $5.79 4 Way Structural Pipe Connector from $7.49 5 Way Connector from $8.49 Top Rail T Connector $5.99 Sale Sample Bundle from $29.89 $31.47 Sale Mixed Structural Pipe Connector Bundle $88.10 $92.74 Sale Starter Bundle from $148.15 $155.96 Sale DIY Bundle from $247.48 $260.52 Sale Builder Bundle from $382.08 $402.20 Sale Creator's Bundle from $541.74 $570.26 Sale Build Anything Bundle from $880.64 $927.00 Sale Lean Business Bundle from $2,441.40 $2,569.90 Sale Maker Bundle from $152.30 $160.32 Sale Pro Bundle from $317.30 $334.00 Tool Bundle $25.95 T Connector $3.34 The T Connector is our most popular and versatile structural pipe fitting. It is designed to natively fit electrical conduit which is readily available at your local hardware store. The 3/4\" and 1\" variants will clamp securely to their respective size.The 1/2\" connector variant includes two adapter shims for building with 1/2\" EMT Conduit. The T fitting allows you to easily connect two pipes at a 90 degree angle or use it as an elbow on the ends of conduit. You only need a single 5mm hex wrench for the T Connector assembly. *Hardware is included with each T connector Color Silver EMT Conduit Size 3/4\" 1/2\" 1\" Color Silver EMT Conduit Size 3/4\" 1/2\" 1\" Qty Add to Cart Sale Mixed Structural Pipe Connector Bundle $88.10 $92.74 You Save 5% ($4.64) The Mixed Bundle includes (12) T Connectors, (4) 90 Degree Connectors, (4) 45 Degree Connectors, and (2) 180 Degree Connectors. The variety of fittings makes this kit perfect for DIY pros and beginners alike. Designed to fit inexpensive ¾ inch EMT conduit which is readily available at your local hardware store. Use this versatile building kit and conduit to create pipe furniture in your home or clean up the shop with a DIY shelving system. Your imagination is the only limit when building with the Mixed Bundle and conduit! *Hardware is included with each connector Color Silver Black EMT Conduit Size 3/4\" 1/2\" Upgraded Tools Without With Color Silver Black EMT Conduit Size 3/4\" 1/2\" Upgraded Tools Without With Qty Add to Cart Want to see more amazing diy builds? Visit Our free Community Add to Cart Customer Service FAQ Shipping Returns & Warranty Contact Us Get To Know Us Our Community Our Products Our Story Maker Pipe Blog Share On Social Use #makerpipe © 2024 Maker Pipe. All Rights Reserved Powered by Shopify",
    "commentLink": "https://news.ycombinator.com/item?id=41633155",
    "commentBody": "Maker Pipe – Structural Pipe Fittings for DIY Builders (makerpipe.com)193 points by elsewhen 14 hours agohidepastfavorite104 comments blorenz 6 hours agoThe real gem on this site is the Make Pipe Minis! What a great way to prototype your idea before committing to the real build. https://makerpipe.com/collections/modular-pipe-fittings/prod... edit: I did not even see when I posted this that they had made this open source with the downloadable STL to print your own connectors. Great move on them! reply epiccoleman 5 hours agoparentWith coffee stirrers! That's such a cool idea, to be able to print the connectors and then use something cheap, off the shelf, and easily cut as the \"pipe\". Brilliant! I can see that being a pretty fun cheapo building toy for the kids. Might have to grab a pack of stirrers and run off a couple handfuls of connectors. Very cool. reply catapart 4 hours agorootparentWith the added benefit of built-in upscaling! I would have loved, as a kid, to design my own \"clubhouse\" with coffee stirrers before going out in the yard and building a full sized one to chill in. reply breakfastduck 5 hours agoparentprevThat is an absolutely fantastic idea and what a brilliant way to help inspire confidence in your product. reply pohl 4 hours agoprevAh, piping, all about moving something from A to B. Has anyone else read Leslie Claret's classic text \"The Structural Dynamics of Flow\"? I got the chance to hear him speak, once. It was riveting: \"Hey, let me walk you through our Donnely nut spacing and cracked system rim-riding grip configuration. Using a field of half-seized sprats and brass-fitted nickel slits, our bracketed caps and splay-flexed brace columns vent dampers to dampening hatch depths of 1/2 meter from the damper crown to the spurv plinth. How? Well, we bolster 12 husk nuts to each girdle jerry — while flex-tandems press a task apparatus of ten vertically composited patch-hamplers — then pin flam-fastened pan traps at both maiden apexes of the jim-joists.\" reply oflannabhra 2 hours agoparentI did not expect to see a Patriot reference online today, thank you for making my day. For others, Patriot is a dark comedy TV show available on Amazon. I highly recommend it. reply jollyllama 32 minutes agorootparentAnd it sounds like it's derived from a classic Steve Martin Plumber Joke reply s0ss 3 hours agoparentprevI struggled to decode this and thought it was an LLM spouting drivel -- haha. After reading I see now that this is a character from a comedy called \"Patriot\". Got it! reply pohl 3 hours agorootparentI like to think of this scene as the retro-encabulator of a new generation. reply mindcrime 40 minutes agorootparentI'm just waiting for the ultimate hybrid: the LLM-encabulator! reply s0ss 3 hours agorootparentprevI felt like I was walking through an industrial space and bonked my head on \"piping\" trying to read this -- hahaha! TY for melting my brain just a tiny bit. reply neilv 2 hours agoprevHow does this compare to \"80/20\" https://en.wikipedia.org/wiki/T-slot_structural_framing ? (At a past startup, we used 80/20 for the structure of our factory stations. We were very happy with how 80/20 was easily adapted during prototyping and testing, and then our final station design could be replicated quickly stateside to several stations, then disassembled into a few assemblies for flight, reassembled at the factory in Asia, and hold up well in production, and it also looked professional for demos. A lot of that success was due to the know-how and effort of our mechE, but, IMHO, 80/20 is appealing to people who grew up with Lego-like toys, and even I, primarily a software person, felt I could do useful things with it and some basic tools.) reply jseutter 1 hour agoparentMy armchair assessment is that both will have their uses. 80/20 is 3-4x the price, but is lighter and more rigid than EMT conduit. EMT conduit is sold everywhere and will be more useful for quick and dirty setups. For a machine like a 3d printer, I would choose 80/20. For some lightweight shelves, EMT conduit or wood. So I see this product almost as a wood replacement rather than a 80/20 replacement. reply hinkley 1 hour agorootparentIs easier to control torsion with 80/20 as well isn’t it? Clamping a radius like this will leave you open to a lot more racking. reply hinkley 1 hour agoparentprevSteal can be bent without failing. I believe 80/20 has less flex than a similar sized pipe? But when it gets bent you’re done. So there will be situations where steel is a better choice. reply tommiegannert 10 hours agoprevThe \"discounted\" bundle is such an anti-pattern. I'm saving the price of one fitting, out of 20. So if the bundle has even one fitting that I have no use for, the whole deal falls apart, and I should have bought them individually instead. Anyone with the volume to make use of all connectors would probably want to negotiate a better deal anyway. reply digdugdirk 5 hours agoparentIt tends to be highly valuable for mechanical tools like these. Think of this product more like hardware (nuts/bolts/screws, not PC hardware) than a standalone \"product\". Most people who have a shop or do a lot of tinkering keep an assortment of misc hardware around just so they have it on hand whenever the need arises. This falls into a similar category, so having a grab bag to be able to handle whatever potential scenario you run into would be incredibly handy. reply metaphor 1 hour agorootparentWho are you kidding?? This isn't minor hardware...these fittings are ~$5 a pop! Priced individually:FittingPrice (ea)QtyTotal|---------|------------|-----|-------|T3.341240.08| 905.79423.16| 454.95419.80| 1804.9529.90|=========|============|=====|=======|2292.94In contrast, the bundle lists for $88.10...that's a lousy price delta of $4.84 (approx. 1 fitting). In consumer hoodwinking terms, it's the equivalent of buy-21-get-1-free...except the \"value proposition\" comes at a cost of zero optionality and overweight T fittings. If you've got the cash to burn on benchstock at this price point, more power to you, but the point is you're really paying a premium to throw away choice for the illusion of value with this bundle. reply bluGill 5 hours agoparentprevIf are close to needing a bundle worth then get the bundle as you need spare parts anyway. reply cius 6 hours agoprevAnyone interested in heavier duty may appreciate Kee Klamp. For example: https://keesystems.com/product-category/fittings/kee-klamp/?... reply hinkley 1 hour agoparentI think it’s early days for Maker Pipe so I’m not going to dunk on them too hard for this, but I noticed the lack of angles means you can’t build for instance a 3:2 rectangle with cross braces to prevent racking. You have to do squares only. Kee seems to have solved that problem. reply CtrlAltmanDel 1 hour agorootparentIs this not angles? https://makerpipe.com/collections/modular-pipe-fittings/prod... reply hinkley 32 minutes agorootparentThat’ll do triangles but not crossbracing. X’s not λ‘s reply CtrlAltmanDel 6 minutes agorootparentUse 2 of the 'Adjustable Angle Hinge' to make a single diagonal across the rectangle. At the midsection of the diagonal, install an 'Adjustable 180 degree' along with two more of the adjustable angles in each corner. Would that approximate it? Sorry I'm not better at ascii art. https://makerpipe.com/collections/modular-pipe-fittings/prod... reply bagels 2 hours agoparentprevI built a walk in closet clothing hanger system out of these, has held up well and was easy to assemble once I polished and cut the tubes. reply hinkley 1 hour agorootparentLooks like fewer places for clothing to snag as well. reply rsync 3 hours agoparentprevI think if you’re interested in heavier duty constructors such as this, the real move upwards is to unistrut… reply Pikamander2 9 hours agoprevI remember seeing their booth at the Orlando Maker Faire years ago. Metal pipe was a bit too expensive for my budget but I was still inspired by their display and started using PVC and custom 3D printed connectors in my gardening projects. I love how much work they've done on connectors. In my experience with PVC, one of the biggest hurdles to making interesting projects is finding prebuilt connectors for anything besides simple 90-degree angles. It makes sense given that most PVC projects are for construction rather than hobby projects, but it's still annoying. Having pre-drilled screw holes is also a nice bonus. reply Loughla 7 hours agoparentPVC plumbing fittings come in 22.5 degree variations between 0 and 180, just as an aside. It's what I use for most gardening projects. It lasts longer than thin wall conduit would, and is much less expensive than the thick wall steel pipe. reply Pikamander2 6 hours agorootparentThere are lots of options online but I've noticed that our local Home Depot is missing a surprising amount of common connectors and our Lowe's barely carries any. reply mauvehaus 4 hours agorootparentThis is because the customers at Home Depot and Lowe's are primarily muggles. The wizards will pop in if they need something and it's convenient, but by and large they buy at wizard stores that stock the full range of fittings. Said wizard stores sometimes have a handwritten sign taped up on the wall behind the counter dating back to the Carter administration that reads \"Those in the trade will be served first\"[0]. Your reward for being a wizard is having competent help at the store, and the fittings haven't been randomly distributed among the bins by a million prior muggles. Electrician wizards similarly work with electrical supply stores, not Home Depot if they can avoid it. Carpenter wizards cross over a little more, but they generally prefer to work with lumber yards that deliver[1] and have halfway decent lumber[2]. [0] Yes, literally. [1] I believe the box stores do to, but they charge handsomely because they don't really want to. [2] 2x3's are crap everywhere, but the quality on anything bigger goes up immensely at a real lumberyard. reply happyopossum 1 hour agorootparent> [2] 2x3's are crap everywhere, but the quality on anything bigger goes up immensely at a real lumberyard. This was once the case, but I've not found it to be true in recent history (in NorCal anyway). Lumberyards are getting 2x4/6/8 stock in roughly the same quality as the big box stores, and the only difference appears to be service and turnover rate. Covid's effects on the lumber supply chain are lasting - many sawyers and mills have closed, and what's left is produced to meet a price point. reply bluGill 5 hours agorootparentprevBecause they are trying to make a profit and so have gotten rid of things that don't see much. While sometimes I would make the argument that the lack of inventory is why people go online instead, in this case I think that is wrong. Their target market is home owners doing plumbing, and plumbing rarely needs those odd connectors. Frankly if you have small PVC/cPVC water pipes (as opposed to larger drain pipes) I would replace them with PEX where practical, and cut them off where not and install a PEX adapter. (I'd also do that for copper or iron pipes - copper because it might have lead solder but if it doesn't you are good for a while; iron because it hasn't been common in so long that anything you see is probably past expected lifespan) reply jollyllama 4 hours agorootparentprevIt's not likely to be much cheaper but there is probably a plumbing distributor near you with a much wider selection. reply elif 6 hours agorootparentprevCurious what you consider 'lasts longer' as all of my garden support frames and nets are held up by conduit for about 10 years and I'm not seeing any signs of significant rust.. reply quesera 4 hours agorootparentGalvanized EMT conduit will rust, especially if you let water get inside and it does not drain. I use silver spray paint on all cut or drilled spots, and drill tiny holes on the underside of any horizontal runs that descend from verticals. (E.g. I've bent EMT into four-sided frames for doors, etc). I have outdoor EMT structures (trellises, garden gates, chicken run frames, geodesic domes) that are 25 years old and going strong. :) Agreed though -- PVC pipe (the white stuff) does very poorly with exposure to UV light. The beige CPVC stuff is worse. The black PVC (ABS?) is supposed to be better, but less available in small gauges. And the grey plastic stuff used for electrical conduit is also supposedly UV-safe, but is far less structurally rigid than any of the others, or of course galvanized EMT. Sometimes that flexibility is a virtue, but usually not. reply rootusrootus 3 hours agorootparent> PVC pipe (the white stuff) does very poorly with exposure to UV light To my understanding, this is primarily an aesthetic issue. PVC pipes have been tested over years of UV exposure and remain structurally sound. This is a topic that comes up periodically on the pool forums since it is pretty common to have some amount of exposed PVC pipes above ground. reply quesera 3 hours agorootparentI've seen white PVC turn brittle after a few years of exposure to direct sunlight. There may be different formulations (in the same color?) that are more UV-resistant though. Pool piping is a good example, though I have usually seen them covered for UV protection. reply teucris 22 minutes agoprevI know this is meant for EMT, but these look a lot like chainlink fence end-rail clamps which go for about $2.50 a piece. The post material (galvanized 1-3/4” pipe) goes for about $2.50 per foot, so those could be a reasonable alternative for when you can’t get easy access to EMT or maker pipe shipped to you. reply hackcasual 12 hours agoprevEMT conduit isn't a great support material if you're handling human weight loads. The picture on the front page showing off the strength is visibly bending. It's kind of an awkward load profile, lower weight like an awning you're probably using ABS, higher weight you're using 1 1/4\" system like steeltek or keeklamp reply Animats 12 hours agoparentRight. There are many structural pipe fitting systems. Here's one.[1] Grainger, McMaster-Carr, and larger hardware stores stock them. Usually, they use bigger pipe. Fittings are really cheap on Alibaba. [1] https://www.easyfit.com/catalog reply fidotron 7 hours agorootparentWhat are the right keywords to use when searching for the fittings? My ali efforts often get flooded with nonsense. reply rpcope1 3 hours agorootparentIf you're buying hardware that has any possibility of harming someone or doing any amount of non-trivial damage if it fails from AliExpress or Amazon, you're doing it wrong and should reconsider whatever it is you're doing. Even the hardware from HD is generally pretty shitty these days. If you can't afford or won't go buy it from Fastenal or MMC or somewhere reputable, where you can expect the hardware you're buying actually adheres to a stated grade or spec, you just shouldn't do it. reply bluGill 5 hours agorootparentprevIf it is structural I'd buy from a big place not Ali. Unless you have the ability to verify the material really has the claimed properties you need you should stick with a major trusted supplier who will either verify the factory produces fittings to spec, or test everything for you. reply potato3732842 5 hours agorootparentPaying big bucks for a paper trail is almost never cost or time effective compared to just adding safety factor for \"normal applications\". And by \"normal applications\" I mean \"please nobody be intentionally obtuse and start nit picking about aerospace applications and connecting rod bolts and whatnot\". reply night862 4 hours agorootparentI would nit-pick about your cantilever worktable failing because of a crappy fastener, killing your cat. Child even? reply potato3732842 4 hours agorootparentThere will always be a weakest link. At some point you just gotta be an adult and not build things to within an inch of their lives for the use they will see and then have the self control to not push the limit. Resources are limited and engineering tradeoffs are everywhere. These discussions always devolve into absurdity very quickly. reply bluGill 2 hours agorootparentprevI don't need the paper trail just the quality it provide. That is often available for much less. reply fidotron 4 hours agorootparentprevIf it is to support a human I would tend to agree, but for desks etc. I have found local supplies (Canada) have declined in quality to such a degree they need the level of QA on arrival the Chinese ones do while costing 5-10x as much. reply bluGill 3 hours agorootparentunfortunately the big box stores do not check quality. mcmaster which was pointed out above does and is a similar price. I am not sure about granger. reply DannyBee 5 hours agorootparentprevPipe racking connector Modular pipe connector Those do okay without you getting hundreds of irrelevant air hose fittings reply DannyBee 6 hours agoparentprevAgreed. EMT exists to keep wire from getting damaged by accident. It isn't even considered self supporting let alone structural. You can easily bend 1/2 emt by hand. reply quesera 4 hours agorootparentBut 3/4\" is also readily available, and much stronger. And of course larger gauges are available as well, just more difficult to bend with a standard manual bender. I wouldn't use it for scaffolding(!) or anything supporting dynamic loads in the human-scale, but I've sistered three 3/4\" EMT pipes together for an extremely strong, rigid, and inexpensive support pole. reply DannyBee 4 hours agorootparentSure, you can use it for stuff, just don't expect it to hold anything real in any meaningful span. Here's some real values for you: 2ft 3/4 EMT has an expected failure force of about 3300lbs (some studies found actual is around 3900-4200lbs). 4ft 3/4 EMT ha an expected failure force of about 2000lbs. 8ft 3/4 EMT has an expected failure force of about 450lbs. So it is non-linear. This is the point at which it fails catastrophically, not the point at which it starts sagging. They are also not permanent load ratings, include no safety factors, etc. Cost wise, 3/4 EMT costs 11 bucks for a 10ft piece at my home depot. I can go to my local metal supply and get 3/4 square structural steel tube forPVC pipe does not survive outdoors, and the failure mode is messy. That's just not the case - thousands of pool owners can point to 20+ year old PVC pipes and fittings in exposed pool equipment decks... reply quesera 1 hour agorootparentI hear this in other comments, but I cannot reconcile it with my own direct experience with brittle white PVC pipes. There are a few grades of white PVC, including Schedule 40. There must be a subset of options which are appropriate for outdoor use. [Edit: FWIW A superficial web search agrees with me that standard white PVC will degrade in UV. A common recommendation is to use \"furniture grade\" PVC, or to paint or wrap the pipe to protect it. In this context I'm mostly thinking about options available at ordinary hardware stores, not special order stuff, but apparently there are options.] Other reasons to choose EMT though: thinner, more heat-resilient, less prone to sag, stronger by thickness, subjectively more attractive. reply jalk 8 hours agoparentprevAnd that’s even with his feet on the ground out of frame ;) reply elsewhen 5 hours agoparentprevthey have a video where they stress tested a table made out of EMT https://www.youtube.com/watch?v=1oCEMd4v9B4 reply hackcasual 4 hours agorootparentWild stuff. You can see the bottom horizontal trusses bending when loaded. EMT is just too thin walled for serious structural applications reply dddw 7 hours agoparentprevGood to know, my first thought seeing this way. I could build a raised bed. You save some lotta time reply DannyBee 5 hours agorootparentEmt will eventually rust if not painted as well, depending how much you care. It is really mostly used in open commercial/industrial settings (if you go to home depot or Costco you will see emt running everywhere). Aluminum is your obvious metal winner for this sort of thing outdoors (cost wise). PVC, even thick wall, becomes brittle pretty quickly in sunlight. This is why you see wood or outdoor plastics for raised garden beds reply analog31 3 hours agoprevAs a cheap and quick alternative for making simple structures, my dad used to join pieces of conduit by flattening the ends in a vise and drilling holes for bolts and nuts. reply loufe 55 minutes agoprevLast month I spent about 100 hours learning to MIG weld to create a giant mushroom art piece for a music festival. I had looked at Maker Pipe as an option, and it was very compelling. Slow and expensive shipping to Canada and the lack of discounting for large numbers of components pushed back. I would still love to try these, I just hope they manage to get distributors in markets outside the US. reply torginus 10 hours agoprevAre these elements friction-fit? That seems to be a majorly bad idea if you want to handle loads, especially if you want these fixtures to be permanent. A speck of grease or oil could make your structure collapse. Doubly bad, the friction seems to be created by screws that can get loose with time/ not be tightened with the proper torque. Also, an Europe specific thing (I think), is that we don't use metallic pipes for electric wiring, we use PVC. reply IshKebab 23 minutes agoparentThere's plenty of metal conduit for electrical wiring in Europe. Dunno where you got that idea. It's mainly used in commercial buildings where they don't care about things looking nice. In houses cables are chased into the wall, or just stuffed behind the plasterboard. reply ryukoposting 5 hours agoparentprevIn the US you use PVC for outdoor installations, and steel conduit for indoor... with some exceptions that I'm sure someone will be quick to lambast me for. reply dylanowen 4 hours agoprevThey also provide cad models for some of the connectors which I found very useful: https://connect.makerpipe.com/build-help/post/if-you-would-l... reply scottbez1 12 hours agoprevNeat idea! In college I hung blackout curtains in my dorm room with conduit - IIRC it was maybe $5 for a pipe that was longer, sturdier, cheaper, and less annoying than the typical telescoping curtain rods (where the curtain always gets caught up on the telescoping edges as you open it). I also love that you can add structural bends with readily available (and relatively compact) conduit bending tools. Gotta love economies of scale. reply topazas 12 hours agoprevAwesome, but what does 1'' mean? Some weird measurement unit? reply hnuser123456 7 hours agoparentThat would be 2.54 times 1/100th of the distance light travels in a vacuum during 1/299,792,458 of the time it takes for 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of a cesium-133 atom, if you prefer. reply bluGill 5 hours agorootparentWrong! While there is a 1 inch measure in common use that is as you described, the subject here is EMT. There is no dimension in EMT that is 1 inch by the system you describe. The diameter is close to 1 inch, but it is noticeably different to the naked eye, and for all useful purposes different enough that anything actually 1 inch in diameter is not compatible. reply bluGill 5 hours agoparentprev27 mm outside diameter. Which has zero relation to any other inch you might have heard of in common use (ie in the US). reply LukeShu 11 hours agoparentprev\" is imperial inches, ' is imperial feet. reply unwind 10 hours agoparentprevIt's awesome that they combine 1\" pipe with a 5 mm hex [1] (often \"Allen\" in the US) fastener. :) [1]: https://en.wikipedia.org/wiki/Hex_key reply gibspaulding 4 hours agorootparentYou see a lot of this in the bicycle industry. There are a lot of older standards in use like 9/16” pedal threads, 1 1/8” steerer tubes or 1” (25.4mm) handlebars but any new standard is metric - so bottom brackets, wheels, newer seat post diameters are all metric. It can make for some very strange looking spec sheets. reply bluGill 5 hours agorootparentprevThe actual size is 27mm. If you convert to an imperial system the size is not a nice number. reply wezdog1 7 hours agoparentprev/s might have been needed, it appears. reply Modified3019 11 hours agoparentprev1\" is one inch 1' is one foot So yeah, a weird measurement unit. Technically the symbol to be used is a prime symbol (https://en.m.wikipedia.org/wiki/Prime_(symbol)), but what’s used in practice is anything that looks close enough. reply esses 12 hours agoprevI have been shopping for pickup truck bed organization racks that are in the thousands of dollars, but can never pull the trigger because they do not seem like they should cost that much. If I can design these to support the weight I need they will find their way in to the truck bed and my overlanding rig. reply sokoloff 8 hours agoparentI think you’re far better off with black pipe or rigid metal conduit than EMT (thinner conduit which is not even allowed to support a light or outlet per the electrical code). Black pipe is still pretty cheap and way stronger than EMT. reply convolvatron 4 hours agorootparentactual structural steel round and square tube in 20' sections from a steel supplier isn't any more expensive than black pipe and is stronger and considerably easier to work with (no paint, less grainy). you can also make your own fittings since the right tube sizes are nesting. I do 1\" square and clamps made out of 1-1/4\" with 1/8\" wall. that is quite a bit stronger than emt for maybe 20% additional cost. reply sokoloff 3 hours agorootparentAll true; as a DIYer, it's a damn lot easier to buy pipe from Home Depot or Lowes than chase down the local steel supplier and figure out how to either get 20' lengths of tubing home or deal with asking them to cut it for what they know is a grand total of two tubes ever in your lifetime as a customer. reply convolvatron 2 hours agorootparentthe places I go they don't mind if you bring a portaband or a cut off wheel and spend a couple minutes in their yard. actually the place I often go has a chop saw out front. delivery in the city is $20. another place is happy to do cuts for $5, but you have to not mind waiting around for them to get to it. reply NegativeLatency 1 hour agoparentprevTook a welding class recently, it wasn’t that hard to get something pretty strong that could be ground and painted to look nice. You could build exactly what you want with a couple hundred for a stick welder and safety gear. Some places that teach welding will also let you rent their gear/shop time. reply conductr 12 hours agoparentprevProbably a little pricier but I’ve had great success with linear rails for projects like that. There’s a ton of sizes and accessories like wheels and plates and various hardware https://openbuildspartstore.com/linear-rail/ reply ryukoposting 5 hours agorootparentOne thing to keep in mind with this stuff is that it's really heavy. Regular aluminum square tube is much lighter for a given length/size. If you're making something that moves, it may be worth the effort to grab some plain square extrusion and hand-fabricate some brackets. reply TmpstsTrrctta 12 hours agorootparentprev+1 for rails like these. I’ve used 10 series aluminum extrusions in a roof rack, roof top tent, awning and solar panel setup. I purchased all mine and accessories from here https://www.tnutz.com/product-category/10-series-extrusions/ reply 082349872349872 10 hours agorootparentIncidentally, as a kid I loved Fischertechnik kits; they're like Lego but instead of a brick as the basic element, they have X-linear rails. reply linsomniac 6 hours agorootparentprevFor a larger project, consider buying from Alibaba. ~5 years ago I built a series of workbenches using 20 series and even with the shipping from China costs, I saved 2-3x over buying from the maker places. IIRC, final total was around $700. reply potato3732842 8 hours agoparentprevUnistrut is probably the better choice because there's a better/cheaper set of hardware relevant to your use for unistrut than there is for EMT. (Probably because unistrut is designed to hold thing whereas the EMT universe of hardware is more designed for holding EMT to other things) reply quickthrowman 6 hours agoparentprevYou cannot use EMT to support actual weight. RMC or 12ga strut can support an actual load. reply gtsnexp 8 hours agoprevCan you get them in Europe? reply N-Krause 5 hours agoparentThats what I was thinking, quick search got me this German shop: https://www.rohrverbindershop.de/rohrverbinder/ But seems like there are plenty of options. reply whatshisface 3 hours agoprevWhat's the advantage of metal pipe over treated wood? reply happyopossum 1 hour agoparentShape, size, weight, required tooling, fire-resistance, price, lack of dangerous chemicals, etc etc etc? In most of these cases they are tradeoffs, not direct advantages but it should be kinda obvious which would be best for any given situation reply WaitWaitWha 5 hours agoprevI would love to have these for several projects, but I need it for 2\" pipes. Any ideas who might have them? reply happyopossum 1 hour agoparentWhat you probably need to look for is \"structural pipe\" - Lowes and HD both carry a line of that with lots of fittings, and KeeKlamp and others are available online or from trade supply shops. reply albrewer 4 hours agoparentprevkeeclamp - https://keesystems.com/product-category/fittings/kee-klamp/ reply quickthrowman 6 hours agoprevEMT is pretty flimsy stuff, why would you build anything with it when extruded aluminum and strut channel exist? Or even RMC, it’s much stronger than EMT. I know it’s a cost thing, but use the right material for the job. There’s absolutely no way I’d trust a desk made of EMT, if someone leans on it too hard it will crumple immediately. reply FrustratedMonky 6 hours agoprevDon't often see product ad's getting to HN and not be flagged. But have to say, not enough people know that products like this exist that can allow building something a lot cheaper than buying something pre-made. reply pcdoodle 6 hours agoprev [–] I can vouch for this stuff, used some for a railing system for a ebike trailer that handled some abuse. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Maker Pipe offers a system of steel pipe connectors designed to turn EMT Conduit into an affordable and versatile building platform, requiring only simple hand tools for assembly.",
      "The connectors are made of durable steel, ensuring strength and reliability for various DIY projects, from furniture to custom shelving.",
      "Customer testimonials highlight the product's ease of use, affordability, and adaptability for a wide range of creative and practical applications."
    ],
    "commentSummary": [
      "Maker Pipe offers structural pipe fittings for DIY builders, emphasizing their Make Pipe Minis for prototyping, which can be 3D printed using downloadable STL files.",
      "Users compare Maker Pipe to other systems like 80/20 and Kee Klamp, discussing the pros and cons of each, and suggest alternatives like EMT conduit, black pipe, unistrut, or extruded aluminum for more robust projects.",
      "The discussion includes the practicality, availability, and quality of materials and fittings for various DIY projects."
    ],
    "points": 193,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1727153010
  },
  {
    "id": 41632460,
    "title": "Dumped orange peel transformed a barren pasture (2017)",
    "originLink": "https://www.sciencealert.com/how-12-000-tonnes-of-dumped-orange-peel-produced-something-nobody-imagined",
    "originBody": "How 12,000 Tonnes of Dumped Orange Peel Grew Into a Landscape Nobody Expected to Find ENVIRONMENT 30 August 2017 ByPETER DOCKRILL Daniel Janzen & Winnie Hallwachs An experimental conservation project that was abandoned and almost forgotten about, has ended up producing an amazing ecological win nearly two decades after it was dreamt up. The plan, which saw a juice company dump 1,000 truckloads of waste orange peel in a barren pasture in Costa Rica back in the mid 1990s, has eventually revitalised the desolate site into a thriving, lush forest. That's one heck of a turnaround, especially since the project was forced to close in only its second year – but despite the early cancellation, the peel already deposited on the 3-hectare (7-acre) site led to a 176 percent increase in above-ground biomass. \"This is one of the only instances I've ever heard of where you can have cost-negative carbon sequestration,\" says ecologist Timothy Treuer from Princeton University. \"It's not just a win-win between the company and the local park – it's a win for everyone.\" Daniel Janzen & Winnie Hallwachs The plan was born in 1997 when Princeton researchers Daniel Janzen and Winnie Hallwachs approached Costa Rican orange juice manufacturer Del Oro with a unique opportunity. If Del Oro agreed to donate part of its land bordering the Guanacaste Conservation Area to the national park, the company would be allowed to dump its discarded orange peel at no cost on degraded land in the park. The juice company agreed to the deal, and some 12,000 tonnes of waste orange peel carried by a convoy of 1,000 truckloads was unceremoniously dumped on virtually lifeless soils at the site. The deluge of nutrient-rich organic waste had an almost instantaneous effect on the fertility of the land. \"[W]ithin about six months the orange peels had been converted from orange peels into this thick black loamy soil,\" Treuer told Scientific American. \"Kind of passing through this gross stage in between of kind of sludgy stuff filled with fly larvae.\" Daniel Janzen & Winnie Hallwachs Despite this promising start, the conservation experiment wasn't to last, after a rival juice manufacturer called TicoFruit sued Del Oro, alleging that its competitor had \"defiled a national park\". Costa Rica's Supreme Court sided with TicoFruit, and the ambitious experiment was forced to end, which saw the site largely forgotten about for the next 15 years. Then, in 2013, Treuer decided to evaluate the site while visiting Costa Rica for other research. It turns out, the only problem was actually finding the former wasteland – a challenge that necessitated two trips to the site, given the arid landscape had been unrecognisably transformed into a dense, vine-filled jungle. \"It didn't help that the six-foot-long sign with bright yellow lettering marking the site was so overgrown with vines that we literally didn't find it until years later,\" Treuer told Marlene Cimons at Popular Science, \"after dozens and dozens of site visits.\" Daniel Janzen & Winnie Hallwachs When comparing the site to a nearby control area that hadn't been treated with orange peels, Treuer's team found their experimental compost heap yielded richer soil, more tree biomass, and a broader diversity of tree species – including a fig tree so huge it would take three people wrapping their arms around the trunk to cover the circumference. As for how the orange peels were able to regenerate the site so effectively in just 16 years of isolation, nobody's entirely sure. \"That's the million dollar question that we don't yet have the answer to,\" Treuer told Popular Science. \"I strongly suspect that it was some synergy between suppression of the invasive grass and rejuvenation of heavily degraded soils.\" While the exact mechanisms remain something of a mystery for now, the researchers hope that the remarkable success of this abandoned, 16-year-old orange peel dump will inspire other similar conservation projects. Especially since, in addition to the double-win of dealing with waste and revitalising barren landscapes, richer woodlands also sequester greater amounts of carbon from the atmosphere – meaning little plots of regenerated land like this could ultimately help save the planet. \"It's a shame where we live in a world with nutrient-limited degraded ecosystems and also nutrient-rich waste streams. We'd like to see those things come together a little bit,\" Treuer told Scientific American. \"That's not licence for any agricultural company to just start dumping their waste products on protected areas, but it does mean that [we] should start thinking about ways to do thoughtful experimentation to see if in their particular system they can have similar win-win-win results.\" The findings are reported in Restoration Ecology.",
    "commentLink": "https://news.ycombinator.com/item?id=41632460",
    "commentBody": "Dumped orange peel transformed a barren pasture (2017) (sciencealert.com)190 points by metadat 16 hours agohidepastfavorite130 comments ctippett 6 hours ago> But a year after the contract was signed — during which time 12,000 metric tons of orange peels were unloaded onto the degraded land — TicoFruit, a rival company, sued, arguing the company had “defiled a national park.” The rival company won the case in front of Costa Rica’s Supreme Court, and the orange-peel-covered land was largely overlooked for the next 15 years. Sounds like corporate jealousy on the part of the competitor. I wonder if the supreme court decision has set a precedent preventing future projects like this from going ahead. I don't think anyone would describe the land after 15 years as being \"defiled\" – quite the opposite. reply voiceblue 4 hours agoparentThere were no repercussions at all to their competitor (and, the Supreme Court sided with them), so it was logically the right move for a corporation. If the country or its people don’t bring the repercussions now, why wouldn’t these things continue to happen? It’s not a corporations job to regulate itself. If anything we can only blame the short sightedness and pettiness of humanity, which is causing bigger issues to flourish today. reply jgeada 50 minutes agorootparentThis is the thing that frustrates me so much about this sort of discussion: Just because something is legal, it doesn't mean it is ethical. We keep dismissing ethics as any consideration from business conduct. It is legal to ignore any and all environmental costs that have not yet been made illegal, so are corporations duty bound to ignore any obvious deleterious consequences as long as there is money to make today? Something feels very wrong about this approach. reply ctippett 3 hours agorootparentprevI'm not sure I follow your train of thought. What sort of repercussions are you alluding to? reply voiceblue 1 hour agorootparentI’m just saying it’s not “corporate jealousy”, it’s a rational strategic decision. If you want it to stop, you have to affect the rationale. reply brenschluss 2 minutes agorootparentThis either 1) assumes a homeomorphism between rationality and ethics, or 2) is technically true but missing the point. Akin to saying: \"Human deaths via a tsunami isn't a 'bad thing', it's a natural phenomenon\" Clamchop 1 hour agoparentprevI wonder under what legal theory it was decided. They'd seem to lack standing for not being party to the arrangement, but I'm not a lawyer and this was in Costa Rica anyway. reply WalterBright 14 hours agoprevI read years ago that the local Indians, instead of farming or conventional gardening, would create gardens with the desired plants all mixed together (including trees and bushes). This would create an ecosystem of interdependent crops which would provide food year round. They're largely abandoned and forgotten, but one can find them having gone wild in various places. They're marked by a marked diversity of flora. reply dghughes 3 hours agoparentThree Sister is a common technique. At least in my region for First Nations people (as we say here). Three Sisters is corn/maize, squash, pole beans (climbing). Squash leaves are big so shade the roots of the corn, the beans fix nitrogen in the soil, the corn stalks give the beans something to climb on. Then there is the food types each providing different nutrition. reply Suppafly 2 hours agorootparent>Three Sister is a common technique. I always wonder how common it was. You hear it mentioned anytime agriculture stuff gets brought up, but I wonder if it was a small group of people doing this and then everyone acting like all natives did it, or if it was actually widespread as people make it out to be. reply mbonnet 1 hour agorootparentprevThis was often supplemented by burying a fish or other animal near/in where the Three Sisters were planted, providing ample nutrients for less perishable foodstuffs to grow. reply HPsquared 9 hours agoparentprevSimple monoculture fields were appropriate for 20th-century mechanical equipment. I wonder if these kinds of higher-complexity arrangements could be automated with modern robotics and computer vision. reply FredPret 4 hours agorootparentYup, but on a tiny scale - 1 square meter instead of 1 hectare at a time: https://farm.bot It's a converted CNC router machine with cameras and water and weeding attachments. Though I'm sure you can mount a big version on a wheeled vehicle that drives around tending the farm. reply edm0nd 4 hours agorootparentThis farm bot is so neat, very interesting. It has my pondering if I should get one since I just moved out into the country. I suppose I should first just get a planter and do some regular growing first and then I'll be better positioned and understand its benefits. reply Cthulhu_ 7 hours agorootparentprevI doubt such an organic process could be fully automated - but why would you, given there's plenty of people around? It isn't going to be cheaper I'm sure. Anyway, there's been experiments with biodiversity that is compatible with machinery by alternating rows of plants. This reduced e.g. the proliferation of pests between rows. reply pfdietz 5 hours agorootparentI would hope that wages will rise across the world, making manual labor intensive processes obsolete. This would be a good thing. reply onemoresoop 4 hours agorootparent> I would hope that wages will rise across the world, making manual labor intensive processes obsolete. This would be a good thing. I don't know if this fully makes sense. If wages were to rise manual labor would thrive too. While some people enjoy working in offices same is true of manual labor, some people really do enjoy manual labor (excluding dangerous or demeaning jobs), and of course where it makes sense with tools to make it more efficient. reply fauigerzigerk 3 hours agorootparentThe only way to raise living standards is to become more productive. Manual or not manual is not really the point. The point is output per hour worked. Producing far less per hour worked than what is possible is either low paid work or a hobby. reply bovermyer 4 hours agorootparentprevExcept historically this is not what's happened when production has become more efficient. reply pfdietz 3 hours agorootparentOf course it's what happened. reply Isamu 2 hours agorootparentA bit of truth in both your statements. Productivity increases are usually due to investments in equipment and training, and employers are keen to recoup this cost. So the employees have to demand a share in increased wages. This may not happen. It is absolutely not automatic. No employer turns over increased profits to the employee (well not usually.) So what has happened during our lifetime is that jobs have been exported to lower wage markets, since the employer reasons that they can invest in higher productivity in a cheaper job market and pocket the difference. reply ETH_start 1 hour agorootparentWage increases are fundamentally automatic, because there is a limited pool of labor and higher productivity means companies have more goods/services with which to bid on that labor. In the last three decades of the 19th century in the US, wages doubled despite union membership being at historically low levels. The rise in wages was driven by the same process seen globally in every country that has experienced rapidly growing per capita GDP. As companies produce more per worker and compete for a limited pool of labor, they bid higher for workers. This results in greater value, in terms of goods/services, offered to the average worker, which, in monetary terms, translates to higher inflation-adjusted wages. reply MichaelZuo 6 hours agorootparentprevMost existing farms in the US/Canada already have trouble finding enough labor to work much simpler processes. reply Gravityloss 9 hours agorootparentprevThat idea sounds excellent and combines old and new ideas in an unexpected way. Hacker News can facilitate wonderful syntheses sometimes. reply Numerlor 7 hours agorootparentI think farmers are wary of relying on tech like that and ending up depending on some FaaS, or at least the independent ones that aren't just some huge corporation. reply mbonnet 1 hour agorootparentI'm from an agricultural region (though more ranching than crop farming). This is absolutely the case. Everyone got fucked over by John Deere and is now extremely wary of such things. reply whiplash451 8 hours agorootparentprevAny startup working on this in EU? reply bryanlarsen 7 hours agorootparentDon't know about startups or the EU, but \"big ag\" in North America definitely is. reply Gravityloss 7 hours agorootparentprevFrom quick Google it looks like there are a lot with different exact focuses! reply jinjin2 7 hours agoparentprevThis seems very similar to the Forest Gardening approach in Permaculture: https://www.agroforestry.co.uk/about-agroforestry/forest-gar... reply s_dev 6 hours agorootparentOr The Miyawaki Method: https://www.youtube.com/watch?v=R0d7Hox5J4M reply rubyfan 8 hours agoparentprevSee Permaculture: https://en.m.wikipedia.org/wiki/Permaculture reply klooney 14 hours agoparentprevI think there's a bit about that at the end of Seeing Like a State. Sometimes this is what is meant by permaculture. reply vonnik 9 hours agorootparentThere’s def a bit in Mann’s 1491. reply piva00 10 hours agoparentprevA friend of mine in Brazil abandoned working in tech to start farming using these methods. He grows many different crops intermixed with native vegetation, it's been about 12-15 years and the progress is astounding, all while helping to recover a little bit of the Atlantic Rainforest of São Paulo. reply specialist 2 hours agorootparentThat sounds amazing. IMHO gardening/farming/forestry is \"hacking\". Especially when coupled with tech like robots, chemistry, monitoring, forecasting, etc. Please share any and all links you may stumble across. reply blueant 9 hours agorootparentprevCan you share where? reply piva00 8 hours agorootparentCan share a rough location, it's around São José dos Campos in the state of São Paulo. reply Propelloni 11 hours agoparentprevThis sounds desirable. How could we harvest mixed cultures at industrial scale to feed the many mouths of humanity? reply HPsquared 9 hours agorootparentRobotics and computer vision perhaps? reply b800h 13 hours agoparentprevThis is the principle behind biodynamic farming, right? reply alex_duf 9 hours agorootparentI understand it more as \"it turns out composting tons of organic material makes the soil more fertile\" Which is far from a breaking news. I'm just curious about how composting this much agrumes didn't unbalance the soil's pH, but that they don't mention it at all in the article. reply bryanlarsen 7 hours agorootparentIt sounds like upsetting the ph balance was a key reason it worked so well. The article mentioned that displacing the invasive grass was part of the reason it worked so well. reply kombookcha 12 hours agorootparentprevEh, sorta. Biodynamic farming in the form promoted by Rudolf Steiner is kinda semi-mystical and involves astrology, lunar phases and manipulating the 'cosmic forces of the soil' by doing things like burying quartz inside a cow horn. But biodynamic farming does also emphasise the kind of cohesive view of your crops as an interacting system that you'd find in modern permaculture. It's just that biodynamic implies a bunch of other spirituality stuff that you wouldn't normally consider part of permaculture. reply pfdietz 5 hours agorootparentHeh. Sounds like something that works by accident. In that vein, I'm reminded of the old tradition of consulting oracles to make decisions when hunting or before a battle. If we see an even number of crows we do this, else we do that, things like that. The reason this worked was because the oracle was acting as a random number generator, and being unpredictable can have advantages in such situations (a lesson from game theory). reply hammock 5 hours agoparentprevPermaculture reply McGuffin 10 hours agoparentprevIntercropping, yes. One type of which is called Three Sisters, where you grow corn, climbing beans and squash together. It is of course harder to do on industrial scale, but it probably beats doing row monocrops on your backyard. reply bluGill 5 hours agorootparentThe three sisters approach made it easier to grow crops as the climbing beans didn't need you to create something for the beans to climb. However it reduces your yields by a lot of all crops (the corn shaded the squash, the beans hurt the corn plant) and so it was a bad idea unless land is cheap and labor is expensive. That isn't to say the idea is always bad, in some cases it can be good. You need to be careful as what seems good might have significant downsides that are hidden. reply specialist 2 hours agorootparentExactly. Depending on the whatifs, balancing labor & op-ex vs yield might pencil out differently. I'm very encouraged that we're discussing more than just maximizing yield. A luxury that the Green Revolution brought us. Huh, I hadn't thought of \"permaculture\" as a post-Green Revolution worldview before. reply Arubis 5 hours agorootparentprevIndeed. There's upsides to this beyond the convenience of location, too -- for example, planting basil alongside tomatoes helps repel pests. reply Mistletoe 3 hours agorootparentprevIn my experience it doesn't beat doing row monocrops in my backyard. It just turned into a big mess of plants shading each other, competing for nutrients, impossible to weed, etc. Never again. I'm native and I thought I would try it. Now I wonder how much of it is true and how much is romanticizing an idea that is a meme and sounds good. https://growingfruit.org/t/3-sisters-the-original-survival-f... \"This story is an exaggeration which has been further glamorized by plant sellers and periodicals that cater to advertisers of natural or organic seeds and other products. In reality the practice was not widespread. The Farmer’s Almanac is rarely a source of factual information.\" - Richard \"Three sisters is a very inefficient way to grow corn. It is not the way many Amerindian tribes grew their corn as shown by the fields of corn grown by the 5 tribes of the Iroquois. It was used by some tribes, but only if they had corn, beans, and squash adapted to the growing method.\" - Fusion_power Fusion_power usually knows what he is talking about, I recognize his name from Tomatoville where he is one of the best scientific posters and farmers around. reply Suppafly 1 hour agorootparent>Now I wonder how much of it is true and how much is romanticizing an idea that is a meme and sounds good. I've long assumed that that's what is happening. Also, you can't just throw all three seeds in a hole and call it done, you have to start the corn and then later start the squash and then later start the beans. It's a whole process. It probably works in specific conditions, but in general normal yearly crop rotation to replenish nutrients with things grown in correctly spaced rows and such is likely to work better and be more labor efficient. reply Spunkie 3 hours agorootparentprevDown here in Guatemala I see a large portion of corn fields have also planted beans but I've never seen squash intermixed. reply timsneath 2 hours agoprevhttps://www.princeton.edu/news/2017/08/22/orange-new-green-h... seems to be the original article; this is a very light rewrite by the looks of things. Perhaps we can change the linked article, dang? reply ProxCoques 11 hours agoprev> \"It's a shame where we live in a world with nutrient-limited degraded ecosystems and also nutrient-rich waste streams. We'd like to see those things come together a little bit,\" Saw a talk about circular economies once. One of the things that stuck in my mind was, \"If mankind has any chance of a permanent occupation of earth, the current meaning of the word 'waste' will have to fade away.\" reply bluGill 5 hours agoparentThe hard part is you cannot ship sewage from cities to farms on the same trucks you used to bring the food in from the farms as sewage contains harmful things you don't want in contact with food. reply svnt 4 hours agorootparentSituations like this are exactly why trucks carry containers. You don’t want to reuse the containers for those two things but you can absolutely reuse the trucks. The trucks cost on the order of six figures, the containers an order of magnitude less. reply bluGill 2 hours agorootparentSae problem the truck is still moveing both ways just sometimes with empty containers reply NathanKP 3 hours agorootparentprevYou can compost sewage and ship dirt back in dump trucks though reply bluGill 2 hours agorootparentall options work out to more trucks (more co2) reply hoosieree 4 hours agorootparentprev\"Septic Tanks Pumped. Swimming Pools Filled. Not Same Truck.\" reply chiefalchemist 3 hours agorootparentprevPerhaps but we could be smarter about human liquid waste. Human urine is nutrient-rich and is effectively nitrogen-rich liquid fertilizer. Wanna help your garden soil in the off-season? Pee in a bottle and dump it in the garden. You're welcome. reply lukas099 2 hours agorootparentMunicipal facilities turn human waste into fertilizer used on farms reply chiefalchemist 49 minutes agorootparentSolid waste, yes? reply hoosieree 4 hours agoparentprevThe only entities unable to grasp the inherent contradiction between infinite exponential growth in a finite environment are bacteria and venture capitalists. reply ETH_start 58 minutes agorootparentThere doesn't need to be infinite growth potential for there to be potential for massive expansion of civilization. The energy that is being wasted every single second from the sun emitting its rays out into empty space is many orders of magnitude greater than what humanity collectively uses, and all of that energy could be harvested and even saved if civilization expands to colonize the entire solar system. Until it does that, the vast majority of the energy outputted by the sun is going to waste. So slowing growth is generally extremely wasteful. reply MarkusQ 4 hours agorootparentprevAnd yet they and their ilk dominate (and thus drive most of the progress in) their respective areas. It's almost like not pre-deciding you're doomed and instead just getting on with it is the secret to getting anywhere. reply FredPret 4 hours agoprev\"Dumped orange peel\" from the title is really 12k tons of orange peel reply Suppafly 1 hour agoparentthank you. at first I thought this was akin to the dropped cheetos in the cave story from a while back but then I remembered I had read about this dropping of tons of peels story before years ago. reply 0cf8612b2e1e 15 hours agoprevWhat is the normal outcome of these orange peels? Fed to livestock? Mulch? Or just added to landfill? The results were impressive, but I imagine there were months of rotting orange peels. Which is probably not ideal neighbors, but fine in otherwise barren, uninhabited land. reply wnissen 56 minutes agoparentI thought it was interesting that the climate caused them to decompose, when orange peel is one of the most common forms of garbage I see on higher elevation (6000 ft. / 2000 m) trails. It's dry enough that the peel effectively never rots. Just goes to show that it's all about the system. https://thetrek.co/pacific-crest-trail/how-much-trash-gets-l... reply stevage 13 hours agoparentprevYou don't need to imagine: >\"Kind of passing through this gross stage in between of kind of sludgy stuff filled with fly larvae.\" reply rolfea 4 hours agorootparentI wonder about the practicality of complementing that stage of the decomposition with a free-range poultry operation. Bringing in chickens, the birds eat the larvae, and generate more fertilizer along the way. reply datavirtue 8 hours agorootparentprevYeah, the land was moving for a while. reply Mistletoe 13 hours agoparentprevhttps://www.sandiegoreader.com/news/1994/jun/23/straight-bil... >As for what happens to all the rinds from that mountain of oranges Tropicana processes, the nutrition in them (and apparently there is a lot) eventually comes back to us in the form of hamburgers. Tropicana and other processors dry the rinds, chop them up, and sell them for cattle feed. reply netsharc 11 hours agorootparent> the company would be allowed to dump its discarded orange peel at no cost on degraded land in the park. > The juice company agreed to the deal, and some 12,000 tonnes of waste orange peel carried by a convoy of 1,000 truckloads was unceremoniously dumped on virtually lifeless soils at the site. I guess they weren't doing this cattle feed deal back then, since evidently it was more economical for them to find a free dumping ground? Maybe they produce too much of it: 12000 tonnes, that's the cargo capacity of ninety 747s... reply ThrowawayTestr 5 hours agorootparentThe dumping was close to the factory so they saved money in shipping costs right there. reply netsharc 13 minutes agorootparentI guess they weren't selling the rinds to cattle feed producers (or maybe only a low percentage of it, and have to figure out how to get rid of the rest). If the rinds were being sold, they'd be sold at a profit or at least try to be cost-neutral. reply ineedaj0b 10 hours agoparentprevi grew up near an orange producer and they burned them. god it stunk. nice to see they found a better way to use the peels reply Suppafly 1 hour agorootparentI'm really surprised there aren't a bunch of secondary by-products created from the peels. Obviously there is always going to be some waste, but you'd think they'd extract all the oils and stuff first. reply rurp 3 hours agoprevSomewhat related to this, when I first setup a compost bin at home it was simply to try to reduce yard and food waste, and I hoped it wouldn't be too annoying to use. I was surprised to find that I've actually had a lot of fun with it! Especially around trying to optimize the throughput. It's interesting to me to try and find the ideal balance of inputs that will generate compost quickly and minimize organic waste. Managing a system that takes a whole bunch of scrap and turns it into something useful, in a largely autonomous way, tickles the same part of my brain that gets satisfaction from writing a custom script to automate away some annoying but useful task. reply WalterBright 14 hours agoprevI read about that case years ago, and as a result started composting my biomass garbage, especially the orange peel! I don't generate enough to make a difference, but the local fauna eats most of it. A couple of onions have sprouted in the pile. reply tonyedgecombe 11 hours agoparentWe used to do that, once I figured out how to stop the rodents. In the end our local council started collecting food waste which was a lot less hassle for us and we could include bones. We get to collect free compost once a year. reply alex_duf 9 hours agorootparent> once I figured out how to stop the rodents Any tips? reply tonyedgecombe 14 minutes agorootparentI used a traditional bin[1], drilled some holes in the bottom and buried it 12 inches into the ground. Prior to that we had a bin with a door at the bottom but the rodents always gnawed away at the door and got in. [1] https://www.tensens.com.au/productimages/SAB78025.jpg reply debacle 5 hours agorootparentprevIf you are in a remotely suburban area, a 10' tall post near the compost pile will act as a raptor perch and take care of most of your issues. Alternately, a \"hot\" compost setup generally is not amiable to rodents or other mammals. reply lukas099 2 hours agorootparentprevBury the nitrogen rich stuff in carbon rich stuff, like fall leaves. reply WalterBright 6 hours agorootparentprevYou can't stop the rodents. reply onemoresoop 4 hours agorootparentYou can invite their predators to take care of them. reply datavirtue 8 hours agorootparentprevCats. reply laeri 4 hours agoprevThis might be misleading as often biodiversity can't be measured by how lush it looks and how much vegetation there is. Certain plants and animals can only survive in arid landscapes that look 'dead' but can't survive otherwise as they are adapted to an environment with less nutrients. So it is possible that you actually reduce biodiversity by doing things like this. Often land has too much nutrients due to farming and leaving arid landscape as it is might be better. reply idunnoman1222 4 hours agoparentYou would only do this to a land that is degraded. I don’t mean, degraded like in its natural state I mean, degraded as an already fucked up by man. In this case, the land was choked with invasive grasses reply cbanek 14 hours agoprevI wish they had a picture of this fig tree they mention. reply jacoblambda 11 hours agoparentThis is the best image I could find (from another article). It's not the same fig but you can see a pretty substantial fig growth in this image. https://assets.rebelmouse.io/eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI... https://www.upworthy.com/a-juice-company-dumped-orange-peels... reply fourthark 14 hours agoparentprev> a fig tree so huge it would take three people wrapping their arms around the trunk to cover the circumference. No way that grew in 16 years… reply jacoblambda 11 hours agorootparentKeep in mind that banyan trees (those massive trees that can basically be a small forest in of themselves) are figs as well. Figs grow incredibly fast and often go from a bunch of vines all fighting to climb for sunlight into a giant fused mass that is a fig tree. reply Suppafly 1 hour agorootparent>Keep in mind that banyan trees (those massive trees that can basically be a small forest in of themselves) are figs as well. Do they produce fruit or are they just related to the fruiting ones? reply fuzztester 4 hours agorootparentprevhttps://en.m.wikipedia.org/wiki/List_of_banyan_trees_in_Indi... reply cortesoft 14 hours agorootparentprevFig trees are incredibly fast growing. They can grow 15 feet in a single year reply asdasdsddd 13 hours agorootparentFig trees are insane, you can literally put a branch on the ground and it will grow reply worthless-trash 5 hours agorootparentprevThe rainforest adapts -very- quickly to regrowth and second growth making way for the much older and much slower growing trees. I fear you underestimate the power of earths biology, especially in the rainforest areas. reply asdasdsddd 13 hours agoprevI'm surprised that the oranges didnt make the soil too acidic, but I guess organic matter + water == lushness works 100% of the time reply jacoblambda 11 hours agoparentOther articles (and the underlying research) actually mention this. It's suspected that the acidity killed off most of the younger, more temporary \"new growths\" (like non-native grasses) in the area and provides suitable conditions for \"old growth\" plants to quickly expand into the area after the acidity dropped off. reply dylan604 13 hours agoparentprevSome plants prefer a more acidic soil compared to others. Tomatoes are pretty well known for liking acidic soil. reply trevoragilbert 13 hours agorootparentTomatoes like a fairly neutral ph of ~6.5. A better example is blueberries with mid-4’s. reply seunosewa 12 hours agoparentprevThe acidity is temporary. The organic acids in the peels are eventually metabolized by the fauna and converted to carbon dioxide. reply cosmotic 13 hours agoparentprevThe juice is acidic. Are the peels? reply dylan604 13 hours agorootparentIt is recommended against putting them into your composite. reply linuxandrew 8 hours agorootparentSome people recommend avoiding citrus and onions in compost and worm farms typically because worms don't like it in the early stages of decomposition. I've never followed that rule personally and my compost system works really well. I get some black soldier fly larvae and other vermiculture in the early stages. In case you're wondering the black soldier flies aren't annoying like houseflies and typically steer clear of homes and humans. I usually only see a few BSFs around the compost and sometimes a lot of larvae, but it's seasonal. reply vlabakje90 13 hours agorootparentprevI'm not completely sure, but that might be because of the oils in the peel. Citrus peel oil has antimicrobial properties. reply pfdietz 5 hours agorootparentprevI've never had any trouble. reply ddmf 8 hours agoprevIt's very obvious when you walk through Scotland's forestry which trees are native, and which have been transplanted because there is lush grass and plants underneath the native trees, and a lot of the time bare patches underneath the imported. reply Amezarak 7 hours agoparentI don't think this of use as a general discriminator. At least in the US, some native trees kill or prevent the growth of pretty much anything under their canopy via shade and the volume/density of leaf litter. reply jddj 6 hours agorootparentAlso chemically: https://en.m.wikipedia.org/wiki/Allelopathy reply jessekv 6 hours agoparentprevAre the imported ones walnut trees? reply BoggleFiend 4 hours agoprevOne thing not mentioned in the article is the use of pesticide. Were the peels organic, or do the pesticides naturally degrade in a harmless way? reply idunnoman1222 3 hours agoparentI don’t know where people get the idea that pesticides are forever chemicals. All of them denature, The problem is sometimes not before they reach your table Chloripyriphos (sp?) are probably the longest lasting one and they don’t use them in any first world country and they’re half-life is something like 60 days The days of ddt are passed reply salad-tycoon 3 hours agorootparentAssuming and making up numbers for pesticide XYZ degrades in 6 months. First what is degrades is that 100% or 50%? Is that based on just because it’s no longer effective? Does your statement change if considering dumping huge amounts in a highly concentrated area? Does that concentrate what small percentage remains after 6 months, 6 years etc and does that change the conditions of decay for the stuff at the bottom of the pile, middle, top? Just seems like dumping a 1000 trucks worth of something might introduce some new factors into the equation. But yeah, I’d be more worried about living near or down stream of a rotting orange sludge landfill that’s pulsating with fly larvae I guess in the end than the pesticides, not that people who tend to live near these dump sites really have a choice one way or another. reply eYrKEC2 1 hour agoparentprevYes, modern pesticides degrade. Farmers keep very detailed spray records and fields have essentially \"lock out, tag out\" times after certain spray applications. Other sprays can't be applied X number of days before harvest, because the application's degradation isn't complete. After harvest, produce who's skin is consumed, like apples, go through a \"drencher\" and later \"dump tank\", to perform more washing of the produce's skin. reply Suppafly 1 hour agoparentprev>One thing not mentioned in the article is the use of pesticide. Were the peels organic, or do the pesticides naturally degrade in a harmless way? Seems irrelevant, presumably they wash them before juicing them. reply FrustratedMonky 6 hours agoprevWas there follow up now, to overturn the case to allow dumping/composting again? Stuff like this seems like such a win-win it would be sad if it didn't lead to some changes now. reply chiefalchemist 3 hours agoprev> As for how the orange peels were able to regenerate the site so effectively in just 16 years of isolation, nobody's entirely sure. Well, the first thing that comes to my mind is: Maybe it wasn't only the orange peels. Perhaps there were other factors that contributed to the turn around. And given that this was a one-off they need to reproduce this experiment again, ideally two more times. Once is not a pattern. Even twice isn't a pattern. Three times? Now we can begin to identify and consider there might be a causation-worthy pattern. To often we want a single causation, and more often than not it's not that simple. reply jonathanyc 12 hours agoprevThis is particularly interesting to me because (1) they have a natural control, given that it’s such a small area, and (2) the mechanism is apparently a mystery? > When comparing the site to a nearby control area that hadn't been treated with orange peels, Treuer's team found their experimental compost heap yielded richer soil, more tree biomass, and a broader diversity of tree species – including a fig tree so huge it would take three people wrapping their arms around the trunk to cover the circumference. > As for how the orange peels were able to regenerate the site so effectively in just 16 years of isolation, nobody's entirely sure. > \"That's the million dollar question that we don't yet have the answer to,\" Treuer told Popular Science. reply globular-toast 10 hours agoprevIsn't \"barren pasture\" an oxymoron? reply jessekv 6 hours agoparentIt would be if it weren't so common. Overgrazing is a huge problem worldwide. reply quantified 15 hours agoprevnext [4 more] Very misleading title. Barren soil is barren soil. Desert is a classification based on rainfall. Dumping ground is/was not a desert. reply dang 14 hours agoparentOk, we've put the barren pasture the article talks about back in the title above. reply 7e 15 hours agoparentprevYou could call it a “ecological desert”, but that said, it’s not even the title of TFA, which is more accurate. reply metadat 15 hours agorootparentThanks, I wasn't happy with the title either, for what is otherwise a decent article. TFA's title exceeded the HN limit, so I've done what I can. reply gbickford 15 hours agoprev [1 more] This article is from 2017 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In the mid-1990s, a conservation project in Costa Rica used 12,000 tonnes of waste orange peel to transform a barren pasture into a lush forest.",
      "The project, led by Princeton researchers, was halted due to a lawsuit but rediscovered in 2013, revealing a dense jungle with richer soil and diverse tree species.",
      "The success of this project, published in Restoration Ecology, suggests potential for similar conservation efforts, though the exact mechanisms remain unclear."
    ],
    "commentSummary": [
      "In 2017, 12,000 metric tons of orange peels were dumped on degraded land in Costa Rica, leading to a lawsuit and a Supreme Court ruling against the project.",
      "After 15 years, studies revealed the land had transformed into a lush, biodiverse area, sparking debates on the ethics and legality of using organic waste for environmental rehabilitation.",
      "The case underscored the potential benefits of organic waste in ecosystem restoration, despite facing initial legal and corporate obstacles."
    ],
    "points": 190,
    "commentCount": 130,
    "retryCount": 0,
    "time": 1727143546
  },
  {
    "id": 41633400,
    "title": "Colocation: Non-Clown Hosting",
    "originLink": "http://rachelbythebay.com/w/2024/09/23/colo/",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=41633400",
    "commentBody": "Colocation: Non-Clown Hosting (rachelbythebay.com)170 points by ingve 13 hours agohidepastfavorite166 comments dannyobrien 13 hours agoRelated and kinda related links: * In San Francisco, good old MonkeyBrains offers an off-the-menu, In'n'Out-style coloc deal: https://www.monkeybrains.net/colocation.php Fun! If you're thinking of doing this, say so here, maybe we can all share an amp or two. * If you just want to play with something that isn't an Amazon instance, and are not sure you want to commit to a >$50 a month server somewhere, https://lowendbox.com/ always has a few crazy deals. * Never underestimate just slinging a box under your desk at the end of a consumer internet connection. I think people sometimes overestimate how difficult it is; I honestly think everyone should do it once, if only to get that visceral feel of being a peer on the global Internet. reply piou 11 hours agoparentWell shoot, if you're in the East Bay and would rather colo in Oakland, use the coupon code \"non-clown\" to get half off the prices here: https://account.eppihost.com/order/colocation/ (I typically offer VPSes, but just added some colo options for my hosting services because of this thread, as you can probably tell by the package names I chose. The coupon only applies to colocation.) reply schmookeeg 1 hour agorootparentI live in Alameda and colo in San Jose and would way prefer the shorter drive, even though I never visit my server.. but... this webpage isn't a real product offering is it? Like, you made it in response to the topic post (right?) I lol'ed regardless. Bravo, and... I may look you up if OpenColo keeps irritating me. They have been surfing that line just below \"irritated enough to move\". They recently rug-pulled my whole IP block and forced a bunch of reconfig on me I wasn't down for. I'm still salty. Quadranet never did that to me in ~13 years with them. AWS neither come to that. reply piou 1 hour agorootparentClearly my business/branding sense and my sense of humor are off... it is a real product offering, and I'll honor the offer and the coupon if you sign up. Typically I provide website and VPS hosting, just hadn't advertised colo services publicly so threw the product page together. I'll change the product names eventually when I come up with something I like. (Standard disclaimer: while supplies last.) reply teruakohatu 10 hours agorootparentprevThanks for offering us a discount. Can I ask why your cabinet and the Mission facility mentioned in the parent comment have just a single 10Gbps fiber connection shared between colo servers. I can get a 5Gbps at home and probably 10 if I asked nicely, I thought in SF it would be straight forward to get multiples of that. reply michaelt 9 hours agorootparentMaybe my information is out-of-date but traditionally home internet connections were heavily over-subscribed - so that \"10 Gbps\" ISP would transfer at that speed for short bursts, but their business model relies on you averagingif you routinely used more than 1% they'd cut you off, throttle you, or apply traffic shaping. This is true, but how many projects will routinely use enough bandwidth to matter? Unless you're streaming media, very little. Keep in mind that cloud backups, P2P/torrenting, etc also uses upstream bandwidth substantially, and ISPs have come to terms with it. reply michaelt 4 hours agorootparentFor home use? You're probably right. teruakohatu asked why a colocation facility would have a mere 10Gbps link when a 5Gbps residential links are so affordable. If you tried to run a colocation facility on a residential link, it would spend most of the time severely throttled. reply piou 9 hours agorootparentprevIn case there's some confusion - I'm not with MonkeyBrains. I hope my comment didn't read like I was. (And just FYI, I know people who host with MonkeyBrains, and they have no complaints.) I'm just (self-interestedly) providing an alternative across the Bay. I can't speak for them, but my service is on a 10Gbps line because that covers the needs of my clients at the moment. With a network provider at a data center, you'll typically have a good Service Level Agreement, and throughput will actually match what you're paying for. Looking at the home fiber offering from one of the big players just now, they tell you up front, \"Actual speeds may vary.\" reply genewitch 12 hours agoparentprev> at the end of a consumer internet connection. CGNAT needs to be routed around, which means you need at least a \"$5 VPS\" with a routable IP address to bastion for you. If you monitor the word \"wifi\" on social media it's a pretty decent proxy for where CGNAT is prevalent. Used in a sentence, \"we just got wifi at the new house.\" I've written a couple guides on this and subjects like it; i've had to use squid in a datacenter to forward proxy my lightning detector at the house, otherwise it would never receive a heartbeat - even though it would auth and start trying to send data; i've bypassed CGNAT so i could host console \"co-op\" games (diablo III, for example); and i've \"mirrored\" my phone media sync to a colocated server as well, just to avoid trying to route around (triple?) CGNAT to my synology at home. reply toast0 12 hours agorootparentCGNAT is a scourge, but at least around me, it doesn't seem to be the norm for residential wired internet. 5G yes; starlink, I think so?; geosynchronous satellite, I don't know, but probably. T-Mobile 5G fixed location internet does offer static IPs if you have a SMB account with an EIN, but not for home accounts or SMB with a SSN. reply sulandor 11 hours agorootparent> CGNAT is a scourge, but at least around me, it doesn't seem to be the norm for residential wired internet. this is highly dependent on your location. most isp's do not have enough v4-adresses for their consumer base. reply vladvasiliu 11 hours agorootparentprev> at least around me, it doesn't seem to be the norm for residential wired internet. It used to be rare in France, too, but now it seems to be spreading. AFAIK SFR, one of the major ISPs, doesn't even offer the option (paid or otherwise) to avoid it. Edit: they do provide what looks like a fixed IPv6, though. reply kolp 10 hours agorootparentSFR will switch you from cgnat to ipv4 if you contact customer support and explain that you work from home and need to open specific ports to access your work servers or VPN. I did just this a month ago. Takes less than 24 hours and you should be OK on ipv4. reply consp 10 hours agorootparentprev> It used to be rare in France, too, but now it seems to be spreading. AFAIK SFR, one of the major ISPs, doesn't even offer the option (paid or otherwise) to avoid it. They realised they can sell the ipv4 blocks for far more and most consumers don't know any better or care. At least I keep my ipv4 adres if I keep the connection up (dhcp lease time is ignored, it is 4 hours despite dhcp saying 24). Asking for a ipv6 adres is like shouting into the void and waiting for an echo which never comes. reply altairprime 12 hours agorootparentprevNote for the unfamiliar that ISP (CG) NAT is not at all universal, nor always mandatory when initially present; my past several carriers all issued public IPv4 and public IPv6 /64 or greater that were accessible if I set the appropriate settings. Caveats apply; i.e. the AT&T BGW320 routers seem to cap at 8192 connections even when in bridging mode. Such are the tradeoffs of buying residential rather than business service. (The else-described proxies can be a cost-effective counter to this and other such concerns, i.e. dynamic IP assignments versus dyndns update intervals.) reply Neil44 11 hours agorootparentprevIn these parts that's only a thing on mobile connections. reply komali2 12 hours agorootparentprevOdd, I never heard of this. So I might be sharing a public IPv4 address with a neighbor? I run a server out of my bedroom with a TON of services on it. I used to use google domains + DDNS + nginx reverse proxy to manage it, and I still use that for two services that wasn't playing nice with cloudflare (jellyfin + tubearchivist), but now mostly use cloudflare tunnels. For the two services, I just pray my IP address doesn't change. For some reason, it doesn't. But I never new I might be sharing that IP address. I've never had routing issues, does that mean I'm lucky? Is this like, a major security vulnerability I've exposed users (just friends) of my hosted services to? Maybe because I'm in Taiwan our ISPs just operate a lot differently? For example, not a single complaint at terabytes up/down every month. reply yuye 11 hours agorootparentIf you've got Chunghwa/HiNet, you most likely don't suffer from CG-NAT. They're the most expensive offer because they're the best offer. If you're with those shitty resellers, you 99% will get CG-NATed. You pay 50% of the CHT price, but you get 25% the quality. You see this in large apartment buildings: They take Chunghwa fiber and resell it, NAT the entire building into the 192.168.0.0/16 block to save on costs, because IPv4 is $$$. Forget about IPv6 support. The bandwidth they have is oversold, so the 400M you bought might not actually reach those speeds during peak hours, unless you're lucky enough to be living in a new building where more than half the apartments are vacant. I have some experience with the latter. Their support staff is often utterly incompetent, too. reply consp 10 hours agorootparentThis sounds like the solution the provider offered when they commercialised my student internet connection. A building with over 1k connections had 4 ipv4 adresses and no proper cgnat. This means you get niceties like: * Everyone gets their neighbors favourite language in the search engine if you have a incognito session. * Only about 32k sessions possible per adres. And yes you can claim them all and kill everyone's internet connection. * All local ip's were interconnected and not firewalled. That was fun. * You get banned or soft throttled everywhere due to \"strange behaviour\". They were doing it on the cheap and fortunately got told it would void their contract if they did not provide something better and it was \"fixed\" after about a year. But during rush you would still end up maxing the 4gbit fiber uplink even with only a fast ethernet connection for everyone. reply nicoburns 11 hours agorootparentprevIf your servers are working fine then chances are you're ISP just isn't using this setup. Some do, some don't. reply fragmede 12 hours agorootparentprevTailscale funnel will let you expose a service to the world without a $5 VPS. reply PLG88 10 hours agorootparentPlenty of alternatives exist - https://github.com/anderspitman/awesome-tunneling. My issue with Funnel is that it includes no auth, exposing you to anyone in the world. I will advocate for zrok.io as I work on its parent project, OpenZiti. zrok is open source and has a free SaaS (as well as auth and hardening in general). reply genewitch 11 hours agorootparentprevipv4 space and bandwidth cost non-zero dollars so I'd ask \"who is paying and why?\" I'm understand that a significant portion of HN is on fiber or whatever, but not everyone has access to fiber, cable, or even - dare i speak it - DSL. CGNAT was mentioned as being prevalent in the UK and germany almost 6 years ago (for example.) I haven't had a non-cgnat ISP the entire time i've lived in Louisiana, and not for lack of trying. (at&t, t-mobile, at&t fixed wireless (x2!), starlink) I'm not paying >$5/month to solve the problem \"but what if i want to self host a public service\" to switch to business or whatever, either, that's ridiculous. edit: also i have colo hardware; i write guides for people who either don't or don't know how. cool if tailscale works. wireguard does too... reply Novosell 11 hours agorootparentTailscale runs over Wireguard. I'm pretty sure they just subsidise their free plan using earnings from their paid plans. Getting a foot in the door and all that. If devs use it at home, they might vouche for it at work. reply vladvasiliu 11 hours agorootparentprevI also think they mostly provide the connection setup, actual traffic should travel directly between the peers most of the time. reply razakel 10 hours agorootparentprevSo they're offering a free (presumably limited) ngrok-like service? reply chris_engel 12 hours agoprevColocation, I don't know... Without questioning peoples preferences but I think at that point I'd rather look for a decent fiber network connection for my home and let that raspberry run in my own cupboard. I mean, its a RASPBERRY you would probably do fine even without the fiber connection. reply sschueller 12 hours agoparentIt depends what it is. I have 25/25 fiber at home for practically nothing (~70 USD a month) but I can only go so far even with a UPS. If I loose power for too long or my internet goes down I have no backup which I would have at a co-location facility. reply altairprime 12 hours agorootparentIf those circumstances occur, what would you be serving that can't afford to go offline for a couple days? It's important to have an answer to that question, rather than to assume that being offline when your home internet is down is inherently a problem. You can safely estimate using \"X nines will cost X digits per month\": 1 nines, 36.5 days/year downtime is $#/month. (openwifi tier) 2 nines, 3.65 days/year downtime is $##/month. (residential tier) 3 nines, 9 hours/year downtime; are $###/month. (commercial tier, datacenter tier) 4 nines, 1 hour/year downtime, is $####/month. (datacenter tier) 5 nines, 5 minutes/year downtime, is $#####/month. (carrier tier) Speaking from experience, it's both important to decide which 'nines' you require before you invest in making things more resilient — and it's important to be able to say things to yourself like, for example, \"I don't care if it's down 4 days per year, so I won't spend more than $##/month on hosting it\". reply timvdalen 11 hours agorootparentprevWhat does 25/25 mean here? Gbps feels high for the home, but Mbps feels insanely expensive at that rate. (And also I didn't know they did fiber that slow, it's really only available in 1 Gbps and sometimes 500 Mbps here) reply db48x 8 hours agorootparentI don't see why 25Gbps symmetric would be so surprising. My current ISP Ziply Fiber offers 100Mbps, 300Mbps, 1Gbps, 2Gbps, 5Gbps, 10Gbps, and 50Gbps (all of them symmetric) in most of their service areas. I’m sure there are other providers with similar offerings, in some parts of the country. My previous ISP, Sonic.net, offers speeds up to 10Gbps. The reported price is pretty nice though. reply sulandor 11 hours agorootparentprevprobably this https://www.init7.net/en/internet/fiber7/ they explicitly (used to?) market that they don't throttle but simply connect at line-speed \"because we can\" reply radicality 10 hours agorootparentprevDamn, that sounds nice, the fiber in Switzerland linked to in other comment. Though the small cost is probably overshadowed by the large infra costs at home. So now you need a 25Gbp/s router, together with the rest of topology like qsfp+ switches, and then actually computers with >= 25Gb/s nics to make use of it. And then all the appropriate cooling for it. It’s starting to sound a lot like a home data center :P reply navaati 9 hours agorootparentYou can get 25G switches/router for not much nowadays, check Mikrotik. Throw a couple Intel NICs from ebay in your machines' PCIe ports and really it's not that much of a deal. reply lishzen 2 hours agorootparentprevI was looking for an UPS replacement and found this: Anker 521 Portable Power Station. Haven't decided what brand to buy, bit $200 sounds reasonable. reply forty 12 hours agorootparentprevIt's always a surprise to me how expensive internet access can be in the US. Here in France 1Gb/700Mb fiber connection costs 30€/month (and this is without commitment and includes TV stuff - \"more than 180 channels\" whatever that means, and landline phone) reply altairprime 12 hours agorootparentThe US has been specializing in telco monopolies in particular for the past hundred and fifty years or so: https://en.wikipedia.org/wiki/Bell_System https://en.wikipedia.org/wiki/Xfinity https://en.wikipedia.org/wiki/Verizon etc. reply eertami 9 hours agorootparentprevI'm fairly sure that person is Swiss, because CHF converted to USD is ~70USD for 25Gb/25Gb symmetrical Fiber in Switzerland. Regular 1Gb/1Gb is around 40CHF/40EUR often. reply hiAndrewQuinn 12 hours agorootparentprevThe EU invested pretty heavily into making sure even very remote parts of Europe, like northern Finland, have great Internet. I was very pleasantly surprised when I was able to work from home at the in-laws'! reply zokier 11 hours agorootparentBecause of these new subsidised fiber deployments, it's not uncommon anymore for rural/semi-rural areas to have better connectivity than urban or sub-urban areas, which is bit awkward. reply consteval 3 hours agorootparentprevThe US invested very heavily too, it's just that the money poof! Disappeared! reply sulandor 11 hours agorootparentprevthouh there are places near berlin that have to make due with 16mbps dsl reply Moto7451 11 hours agorootparentprevInternet speeds and prices are all over the place in the US. I pay $60 per month for 1Gb synchronous fiber (which really performs at 1.2 synchronous, yay me) at my house and $60 per month for 500/30 cable internet at my rental. Two different areas three postal codes apart with different vendors, prices, and products (even when the vendor is available in both). The way we sliced up space for utilities (lots of legal shared monopolies/guided capitalism) and their desire to build the last mile in their area leads to many different prices and products within a walkable distance. Before that 500/30 service showed up the best we had was unreliable 200/15 from another provider. reply immibis 11 hours agorootparentI think you mean symmetric fiber reply sweeter 2 hours agorootparentprevand it varies widely. I pay $170 a month for 30mbps down and 15 up lmao and I have 2 options to choose from who have the exact same service for the exact same price. Telecoms in the US is beyond horrifyingly bad. reply lambdaba 7 hours agorootparentprevit helps that France is the size of Texas reply forty 7 hours agorootparentI'm not sure size matters that much. Population density does indeed. reply jbverschoor 12 hours agorootparentprevA 2200VA/1320W UPS will run a macmini on full load (50watts) for 2 hours. So it's safe to say 12-20 hours under normal load. reply zokier 10 hours agoparentprevThese days I'm less excited about residential fiber deployments as they are more often than not some passive optical setup, which is worlds apart from a proper active fiber that you'd get in a DC or a dedicated business line. For example standard 10G-PON is asymmetric shared 10G down/2.5G up (10G-EPON is even worse, 10G/1G asymmetric), with up to 128 way split. That means that with your fancy fiber in the worst case you might get barely 20 Mbps upload capacity. reply Hikikomori 2 hours agorootparentHere proper fiber is the norm. Doesn't mean that it's not oversubscribed to the next hop though, typical oversubscription is 30x, it would be insanely expensive of they didn't do it. reply silotis 7 hours agorootparentprevIME most new residential fiber deployments in the US are using XGS-PON which provides 10 Gbps in both directions. Typically ISPs don't put the maximum number of clients in a node that the standard allows. I've heard 32 is a common number in practice. Obviously it'd still be a bad idea to run a high traffic server on a residential connection, but as long as you're not streaming 4K video 24/7 or something you'll probably be OK. reply Nextgrid 9 hours agorootparentprev> in the worst case you might get barely 20 Mbps upload capacity \"in the worst case\" being the key point, and frankly, 20 Mbps doesn't actually sound too bad as the theoretical minimum. In practice you're unlikely to hit situations where this is a problem even if everyone was hosting their blog/homelab/SaaS/etc. This is only a problem (and your ISP will end up giving you hell for it) if you're hosting a media service and are maxing out the uplink 24/7. For most services (even actual SaaS) it's unlikely to be the case. reply sokoloff 8 hours agorootparentI’m on Comcast cable internet and 20Mbps is my maximum with 12Mbps peak and 8Mbps sustained being more typical. It wouldn’t work for high bandwidth hosting, but works fine for residential and for 4 simultaneous video calls mostly all-day long during COVID. reply Zefiroj 5 hours agoparentprevI get some horrendous peering at home, and proper DC networking is not going to have that problem. reply jbverschoor 12 hours agoparentprevGood luck with your sdcard and what not. Just get a nuc or macmini. reply sangnoir 10 hours agorootparentPSA: if you're having RPi SD-card-corruption issues, get a higher-amperage power supply (the official power supplies work well). Low-voltage warnings are a telltale sign. reply ur-whale 12 hours agorootparentprevSD cards are indeed a really bad deal when it comes to reliability, especially if like me you tend to slam raspis everywhere almost as a reflex: before you know it, you end up with a large-ish fleet of the things in your house. But: Raspis these days work 100% fine with SSD's, and while a small SSD is not yet as cheap as an SD card, it's not far off. I have entirely stopped using SD cards for my Raspis for quite a long while now. reply adamcharnock 12 hours agorootparentI also had good experience setting up PIs with read-only root devices. All data needs to be sent off-device (or at least onto external storage), but it wasn’t too tricky and should avoid the usual SD-card issues. reply moomin 13 hours agoprevIf CoLo meant I had Rachel Kroll as my sysadmin, I’d regard it as a pretty good deal too. Unfortunately, it means I’d have me. reply krab 12 hours agoparentThat's a pretty much orthogonal issue if you compare dedicated servers to, say AWS EC2. There aren't that many tasks you would have to perform on bare metal that you don't have to do in EC2. PaaS such as Heroku or Vercel, that's another story. reply ur-whale 12 hours agoparentprev> Unfortunately, it means I’d have me. Yeah gearheads have a saying for that: first upgrade the driver then upgrade the car. reply blackfur 13 hours agoprevMy last experience with colocation hosting was that just the monthly fee was way more than a dedicated server on the same host. It was so confusing and I really want to hear some feedback if anyone else has had a similar experience. reply bubblethink 12 hours agoparentColo is for racks. It's for businesses. If you just need a single server, you'll be better served by a dedicated server from hetzner, ovh, etc. The only exception I can think of to this is GPUs. If you have your own GPUs and have a legitimate use for them, colo pricing may beat server rentals. reply chipdart 11 hours agorootparent> Colo is for racks. It's for businesses. This blog post mentions parking an old switch with a derpy little raspberry pi. Also, what makes colocation something for businesses is cost. The likes of Hetzner also sells colocation, and nowadays you can buy a used rack for around $100. Moreover, today's COTS computers are not like your parent's. A mini PC selling nowadays for peanuts has gigabit Ethernet, 16GB of RAM and half a dozen or so cores. You'd pay a small fortune for servers with those characteristics in the early 2000s, and nowadays that hardware is used to check emails. reply lmm 9 hours agorootparent> This blog post mentions parking an old switch with a derpy little raspberry pi. This blogger has weird preferences and money to burn on them. Doesn't mean it's a sensible way to do things if your main aim isn't reminiscing about being a '90s00s sysadmin. reply chipdart 8 hours agorootparent> This blogger has weird preferences and money to burn on them. I don't know. Spending $100/month on colocation costs is hardly a tophat-wearing level of expense. I recall reading from the old Reddit-to-Lemmy migration discussions that some self-hosting instances were costing that much on AWS, and they are still up. For perspective, we're in an internet forum where from time to time we get posts of users spending thousands on their home labs. reply jon-wood 8 hours agorootparentprevMy read of that was that the Raspberry Pi was mostly there for bootstrapping, so that they could drop servers into the rack and have something there already they knew they'd be able to get onto the local network with, not that they were buying colo just for a Raspberry Pi. reply chipdart 8 hours agorootparent> (...) not that they were buying colo just for a Raspberry Pi. I don't know. Might be, might be not. All I know is that there are already companies that are even selling colocation specifically for Raspberry Pis. It's not that weird, and not a step too far away from colocating Mac mini instances. reply navaati 11 hours agorootparentprev> Hetzner also sells colocation Oooooh, they do ! 120€ for 14U, now we're talking ! It's in Germany of course... I think that indeed my problem here is that I live in too expensive a place, expensive for me, expensive for my servers > My last experience with colocation hosting was that just the monthly fee was way more than a dedicated server on the same host. Cheap dedicated servers are usually very old and buggy hardware. With colocation, you can actually install some very good server hardware (pick up some good refurbished stuff rather than buying new) reply TZubiri 12 hours agoparentprevYou pay for the privilege of choosing and owning your hardware. Turns out it's cheaper to let the colo facility buy all of the same hardware and have full control to it. Who would have thunk reply em500 12 hours agoparentprevSounds like simple economy of scale? Same reason why for many things buying brand new can be cheaper than trying to get defects repaired. (I'd assume coloc is more labor intensive for the host.) reply bakugo 10 hours agoparentprev>just the monthly fee was way more than a dedicated server on the same host What kind of \"dedicated server\"? When you colocate, you have full control over the choice of hardware, meaning you can stuff 200TB worth of hard drives and 512GB of RAM into a machine and pay a few hundred dollars max for it. Good luck finding someone willing to rent out a dedicated server with those specs for the same price as the colocation. reply Neil44 11 hours agoprevPeople seem to be scared of owning servers. But my experience has been that generally speaking they're very reliable. If it's important you would always want duplicates, fallbacks etc but it's only the same with cloud services - multi region, multi cloud. reply Nextgrid 9 hours agoparentPeople spread FUD about running servers because they're scared their careers of complexity and fat margins on cloud services will evaporate. reply anymouse123456 7 hours agoprevIn similar news, inexpensive internet connections and old workstations are much faster, and more reliable than entry level cloud crap that's constantly shifting like sand underneath you. A $400-$600 workstation PC and a 400/40 connection with static IPs worked great for our first couple years of development. reply lifeisstillgood 13 hours agoprevI am fairly sure remote working and hybrid working are here to stay. Which means the commercial real estate market is going to shift with more and more “co-working” spaces being created. One thing I wonder is if they will simply turn one office room into a co-low space - where it’s easier to drive to, it’s simpler to manage. Because cloud first is a rubbish solution for most people - just have a server with a TB of disk and most companies can live on that happily running away in the corner. And there might be a growth for companies that have expertise in the basics of racks and HVACs just to run that room for them. reply llm_trw 12 hours agoparentI'm in the process of finding where to put $100,000 of 4090s for training non-llm models. It looks like \"my garage\" is cheaper by far even when I include installing an HVAC system and 3 phase power when I look at yearly costs for a spot with 20kW's of power. reply isoprophlex 12 hours agorootparentDid you factor in security to avoid the local thug population shopping for some free gpu compute? reply TZubiri 12 hours agorootparentA gun and some discretion are pretty cheap reply komali2 12 hours agorootparentYou'll sit in the garage with a gun 24/7? reply llm_trw 11 hours agorootparentYou can just train a vision model to detect people, then detect people on a white list. If you're not on the white list you send a head request to the shooter microservice which deals with the rest of the intruders lifecycle. reply faangguyindia 10 hours agorootparentYou can pay fps player on demand service to aim reply komali2 3 hours agorootparentAlways ends up being mechanical turks in the end, doesn't it? reply immibis 11 hours agorootparentprevWhat self-respecting conservative member of the population doesn't? reply llm_trw 12 hours agorootparentprevI do not live in California. reply borlanco 12 hours agorootparentprevPlease, please, please remember to install some fire suppression! reply bpye 13 hours agoparentprevI’m sure I’ve heard of this somewhere - where someone is hosting out of a coworking space’s server room - but of course cannot recall where. It’s not surprising I guess, office buildings often(?) have one or multiple server rooms, backup power or generators, maybe even redundant networking. reply earnesti 12 hours agoparentprevMany of the offices will be converted to regular housing. That process has been actually already going at least where I live. reply consteval 3 hours agorootparentThe issue is it's pretty hard to do because we have high standards when it comes to putting humans in living spaces. This isn't true though for computers. It's trivial (ish...) to turn an office floor into a datacenter. I know because that's what the company I worked for did. It's nice, because our servers are literally an elevator ride away. reply c0balt 11 hours agoprevInteresting, their definition of managed hosting appears to be quite different from my experience at a provider for managed hosting. We explicitly didn't grant customers \"root\" access unless they requested it. This both made it easier for us (less cleanup when a customer mucks up the setup) and for some customers)(no easy way to mess up your installation). Most people just wanted a managed deployment of their PHP app, a webshop or WordPress and this worked well. reply kqr 6 hours agoparentI agree. Managed hosting to me means configuring software and supplying only credentials for limited admin panels, not full server access. reply gnabgib 13 hours agoprevArticle title: More jabbering from me about non-clown hosting Related post A terrible way to jump into colocating your own stuff (184 points, 1 day ago, 126 comments) https://news.ycombinator.com/item?id=41622653 reply fourfour3 10 hours agoprevI've been doing colocation in the UK for my personal hosting for 15+ years now, and it has worked fantastically well for me. There are three things I'd recommend though that the articles kind of gloss over: * get reasonable OOB access as a priority * get real server hardware * set up backup on day 1 OOB access can be as simple as a serial console server that your colo provider lets you access (most modern servers still have DE9 serial ports!), but ideally you want server hardware with an IPMI. It is fantastic for saving you from the 'oh no, I just firewalled myself out' problem (my colo provider is about an hour away, I don't want to do that trek on my weekends!), and with a proper IPMI you can boot from an ISO file over USB to do things like OS upgrades/reinstalls/recovery or firmware updates with ease. I personally have a Mikrotik router doing WireGuard for me to connect to for remote access to secure the IPMI behind a VPN. Real server hardware saves you a ton of time & money in the long run for less upfront cost than you think. There's a lot of options - HP/Dell for more traditional choices (incl on site servicing options), Supermicro are well established, and there are more recent challengers that are putting out reasonable hardware like ASRock Rack. You should expect to buy this in a B2B fashion - you'll probably talk to/email a salesperson, but I've found I get ridiculously better pricing this way than buying online. As a bonus, you get an IPMI, ECC RAM that works, hot-swap drive trays, etc. In my experience, this kind of hardware really rarely fails - it's designed for 24x7 usage. There's lots of backup options. You might push to something like Backblaze b2, use someone like BorgBase, or push backups to home. I have a home server with a bunch of hard disks, so I do a mix - I use borgbackup & push my backups daily to both my home server and to BorgBase. My personal colo right now is an ASRock Rack EPYC 4004 barebone with a 12 core 24 thread CPU, 128G of RAM, 2x 2TB NVMe SSD, 2x 4TB SATA SSD, another 2x 2TB SATA SSD. I use quite a bit of the storage, and I use it to self-host a bunch of useful things - eg GitLab, CI, email, containers via Docker, side projects, the odd game server for playing things with friends. Adding up what those would cost me to host individually via VMs, AWS, GitHub subscriptions, etc makes paying for colocation an option I'm very happy with! reply schmookeeg 47 minutes agoparentI've said this to any of my engy friends who will listen. (not many) There's a small, yet tangible benefit to having a blank hardware slate to just riff on an idea when it strikes you, and having ample compute/storage/bandwidth to play with the idea. Or to send yourself down a spaghetti sysadmin nightmare you get to untangle. :) It's been a consistent part of my career since 2007 and I'd hate to not have it. Homelab is great, but spinning up your own VMs, architectures, all of it... is a superset of that same satisfaction. reply dhess 10 hours agoparentprevWhere/with whom are you colocated? I’ve been looking around in London and everything is shockingly expensive. reply fourfour3 9 hours agorootparentAt the moment I'm using Mythic Beasts in Cambridge - they're not cheap but their support is fantastic - https://www.mythic-beasts.com/. I have a few friends using https://www.ukservers.com/ and https://www.veloxserv.co.uk/ who are more reasonably priced. I've also used m247 in the past, but had terrible experiences with them since they were acquired by private equity - network & support quality went really downhill. For servers, I use https://serverfactory.com/ and https://www.rackservers.com/. As is typical for this kind of thing ignore the online pricing and email in - you'll usually do rather better, but they'll want you to pay by bank transfer. edit: being outside of London means power is a lot cheaper, but I get about an extra 2ms of latency to my server. I consider that a reasonable tradeoff :) reply dhess 7 hours agorootparentThanks! I was also considering Mythic Beasts. reply sangnoir 10 hours agoprevWhy are colocation providers reluctant to have clear pricing on their websites? Most of them have some form of \"Contact us for a quote\" link. I get their target market is B2B, but the additional friction probably prevents many colo-curious homelab operators from making the jump. reply 9cb14c1ec0 8 hours agoparentAnyone that doesn't have clear pricing doesn't want the colo-curious homelab crowd. Many colo companies won't do less than a full rack. reply sangnoir 1 hour agorootparentThe weird thing is some do publish the price of 1U/1 Amp along with half-racks and full racks, and nothing in between - not even a formula to estimate costs if one doesn't nearly fall into one of those buckets. The 1U pricing suggests that some do care about 1U collocation, while simultaneously limiting price information to quote requests for a 2U or an 800W 1U. It's strange. reply hiAndrewQuinn 12 hours agoprevWhat a coincidence, I spun up my first VM on DigitalOcean just yesterday for $4 a month. It felt... freeing after a few years of working with the Big Three for various things, big and small. Still a step above schlepping your own hardware, but it was still the cheapest Debian VM I could find by about a factor of 2. (Admittedly, I didn't look too hard, let me know if you know a better one.) https://hiandrewquinn.github.io/til-site/posts/common-sense-... reply aniviacat 11 hours agoparentThe cheapest VPS on 1blu costs 9€ and is about the level of a 48€ DigitalOcean droplet, with infinite traffic. (On my VPS I get a couple hundred Mb/s download speed.) Tradeoff: It's hosted in Germany only and the website is pretty bad. reply hiAndrewQuinn 9 hours agorootparentInfinite traffic? That's a heck of a pitch, actually. reply fellerts 11 hours agoparentprevI'd suggest adding ssh-audit to your list. It's literally a tool to harden SSH configs. https://www.ssh-audit.com/ reply stavros 11 hours agorootparentThis looks good, but unfortunately it doesn't give you the config to fix your setup, it just complains about your curves. reply fellerts 9 hours agorootparentThe website has guides for common OSes with one-liners to harden your config: https://ssh-audit.com/hardening_guides.html reply hiAndrewQuinn 9 hours agorootparentThanks! Gonna take this into use, seems fun. reply stavros 9 hours agorootparentprevExcellent, thanks! reply fragmede 12 hours agoparentprevmight I suggest changing the port ssh runs on from 22 to something else in your guide? and imo fail2ban -1 is just a recpie for getting locked out. personally I found the $4 DO droplet underpowered. reply hiAndrewQuinn 9 hours agorootparentI've been considering changing the SSH port, just for that extra bit of security. As for fail2ban -1, I just like seeing the Banned IP list slowly engulf the screen over time ;) reply lbriner 11 hours agoprevWe are seriously considering moving downwards from a dedicated server to some kind of BYOD/co-location. 1) Our server is at least 5 years old but you are still paying a high monthly charge. We have probably paid back 5 times its cost already (I know this includes power/air-con etc) 2) Even a recent quote for another 256GB RAM was quoted at $1200 install and $300 PER MONTH! 3) We find that the support are not quite good enough for anything other than the basics. We had a network performance issue that we insisted was something in their infra and they denied it, it was only after I used Wireshark to prove the problem that they finally found it. YMMV of course. 4) We run some test Hypervisors and then only support Windows + Hyper-V (or VMWare on their \"cloud\"). I don't mind Windows except the monthly Windows updates are very slow and tedious and require VMs to be shutdown. 5) We are getting performance issues because ultimately, each Hypervisor has one disk (might be RAID1) and 10 VMs all writing to it, this seems to have affected throughput, particularly on build agents which write a lot of stuff to disk. On the plus side: 1) We get 24 hour support for major outages, whether caused by them or us. They obviously can't fix anything we have broken but we at least have someone to call if the network seems to have gone down, for example. 2) We can have additional equipment run up reasonably quickly without having to purchase it or go to site. If we move to co-location, we can probably get an amazing server with 4 disks and 1024GB RAM for less than $10K, run Xen or Proxmox on it and get much better performance, although whether they would charge much less is the question. I don't know how many co-loc providers want people with only 1 or 2 servers, I guess they prefer the big corps who want to move 10 racks worth of stuff there. reply weinzierl 10 hours agoprevWhile we are at non-clown hosting and others suggesting smaller, alternative hosting options: Is there a hoster that offers hard pricing caps or maybe prepaid plans? The background is that I would like to give my kid a way to play around without worrying about the bill, even if that could mean being blocked for the remaining part of a month after allocated resources are exhausted. We are using Neocities at the moment, which is great (thanks @kyledrake) but we are outgrowing it, especially since at some point you need a real backend. When I learned web, I self hosted and could use university resources but today I find it hard to find a risk free environment for experimentation. reply jve 10 hours agoparentHosting what? VM? Managed hardware? Hard pricing definitely an option as traffic is not metered and one can pay in advance for x months and after that terminate the service. reply weinzierl 6 hours agorootparentA VM would do it, but what service has unmetered traffic? Don't they all have fine print where they reserve the right to charge you if you overextend your allowance? To be clear: I want to pay for our traffic and don't want to free ride, but I want the failure mode to be \"we cut you off\" and not \"we'll send you the bill later (possibly much later)\". reply jve 14 minutes agorootparentWe really do have free traffic. ToS ofcourse applies and we will warn and cut off but not bill - we don't have a mechanism to bill for traffic anyways. reply p0w3n3d 13 hours agoprevThank you very much for the education, the grassroots works. To be honest there is a lot of things nowadays which are covering up easier, cheaper and sometimes better ways which used to be normal. Younger people for example no longer know they can buy their own music or movies. And sometimes they send things from one computer to another using a Dropbox reply kkfx 11 hours agoprevNever underestimate the co-location power of personal homes of employees with their own HVAC, p.v. with storage and FTTH bandwidth: with good compensation to them might be cheaper and better supervised than choosing a third party. Ladies and Gentleman's it's about time to show the real purpose of homelabs and get paid for the ownership instead of paying third parties, it's about time to use modern logistic to work in a decentralized world instead of insisting with the old mainframe model renamed cloud. Imaging this world and how any remote worker in his/her own home could be a single-person company in a thriving society, instead of a flat+vertex one where most own nothing and smile like Canon workers in China https://www.theverge.com/2021/6/17/22538160/ai-camera-smile-... reply arkh 10 hours agoparentYou're making me think: communal Kubernetes cluster. You setup your nodes at home and share them with some people to make a cluster. The main problem would be securing secrets and data or you'd have to limit yourself to things you don't mind being public. reply kkfx 9 hours agorootparentNo need to imitate giants, meaning there is no reason to use k*s. We have declarative systems like NixOS and Guix System, there is no need to use paravirtualization, who is born for commercial reasons: selling ready made stuff to those who do not know at a price you can't sell for a snippet of nix/scheme. A company can simply develop their own decentralized infra, hosted by their employees. If it will need more it will also have money to buy sheds with p.v. and storage with good enough fiber links to have their own small datacenters. reply arkh 9 hours agorootparentI was thinking more of a cooperative operation. So people could totally join and quit on a whim and I think k8s would help with automatically moving your app were there is available resources. reply kkfx 8 hours agorootparentI do not say it's not possible, just from history every \"community of good citizens\" never last long nor perform well. Beside the fact containers are a very absurd model as full stack virtualization before them. If you really try to draw a big picture, we actually waste immense computing resources just to commercial evolution needs, to go \"autonomous\" we need to avoid copying the bad commercial model but introduce a better one. Declarative systems are MUCH better, with much less attack surface, easy development, documented evolution, ... they are not \"a FLOSS version of $giantname solution\", they are another paradigm. Similarly we should avoid working on VDIs which is the giants way (let's say Amazon Workspaces, Windows 365 etc) so not going let's say Guacamole but going on bare desktop computing syncing just files, using logistic to send iron, configuration management to manage it from remote etc. We should avoid NextCloud/other clones of giants webapps to works instead locally with different tools, let's say do use R/Python not a spreadsheet. Use email with a modern MUA (we currently miss, for non techie) not a web app for development and so on. Not trying to mimic someone else paradigm but proposing a new one better fit for our purpose. reply arkh 7 hours agorootparentLet's say I want to setup some blog, portfolio or fun experimental site but my internet connection is not perfect. I'm not alone on this kind of problems: we should be able to pool our resources and have those websites be delivered by whoever has a working connection to the computer requiring access. I think it could be done with k8s but maybe not. And websites are the easy model as they don't require a permanent connection between \"server\" and client, with things like IRC it should start being fun. reply kkfx 4 hours agorootparentYou contact $WeHostWebsites a company that do what the name imply, they have no datacenter, instead they are 10 people offering the service, some ready-made static website generators with a portfolio of themes, option for ecommerce etc, hosting their infra in their own homes. You pay them few $currency per year and you have your hosted website. At a certain point they need more iron but not much more people the owners buy a shed aside his/her own home and add the need iron, another own do the same... A day their business goes bad, they still own the iron, they can sell if as a service for others who need computing power for a short period of time or they can reinvent themselves in something else because they still have something tangible behind them, not a rent of someone else resources. That's the model. reply robertclaus 12 hours agoprevI've pretty much always had a raspberry pi running a few services in my basement. I never really considered moving it to some else's property. Interesting to hear it's an option. reply DeathArrow 12 hours agoprevI don't know what to say. Not paying big bucks to cloud platforms so they can lock you in and keep your code and data hostage seems undemocratic. reply Havoc 11 hours agoprevLet’s be real - if it could run in a raspberry temporarily then a five dollar vps would have been overkill let alone colo reply krab 12 hours agoprev... and we were doing serverless and build less before it was cool! It was called \"shared PHP hosting\". :-D reply immibis 11 hours agoparentIt was pointed out recently on HN that Lambda is basically CGI-as-a-service. (CGI being a more language-agnostic spec that operates similarly to PHP) reply sirsinsalot 9 hours agorootparentLemme just login to cPanel and check that reply asymmetric 11 hours agoprevIs there a list of colos by country/region somewhere? reply renewiltord 13 hours agoprevI’m always interested in a cheap Colo somewhere. Anywhere in continental US is fine. I’ll ship my stuff in, fly there, and set it up and try to make it work without repeat trips. Anyone have any ideas? One of the more crazy ones was that I just buy a home in Utah that’s rural ish to be cheap enough but also near fiber. Hard but there are some options. reply toast0 12 hours agoparentWebhostingtalk, lowendbox, and lowendtalk should have some options for you. Anywhere with a major internet exchange is likely to have lots of options. If you don't know where those are, you can just look for cities with Equinix locations. Equinix isn't cheap, but some will have a warehouse on the cheap side of town with fiber to Equinix and you can rent a cabinet from them. reply renewiltord 11 hours agorootparentOh surprising. I thought that those sites were for VPS alone. Thank you. reply toast0 4 hours agorootparentThey have everything. Shared hosting, tiny VPS, full sized VPS, managed/dedicated, colo, IP rental, etc. reply dilyevsky 12 hours agoparentprevHurricane Electric has a deal - $600 a cabinet with power and 1gbps transit. Used to be $300… reply renewiltord 11 hours agorootparentHaha it’s funny I posted about that earlier in the day https://news.ycombinator.com/item?id=41630783 They even had a $400/halfcab option earlier this year. Pity I didn’t jump on it. reply hattmall 12 hours agoparentprevLook on eBay. reply throwaway984393 12 hours agoprevI'm a little less grizzled, but I'm so glad I never have to deal with shuffling around broken hardware anymore, much less diagnosing the most inane, obscure bugs due to the hardware slowly crapping out. I've lost so much sleep to shit hardware and unstable, untrustworthy colos. APIs and automation rather than cage monkeys, IPMI, expect and crossed fingers. The Cloud is my church and I've seen the light, hallelujah. reply Stem0037 12 hours agoprev [–] While colocation offers greater control and potentially lower costs for high-performance needs, it's worth noting that for many small to medium-sized operations, cloud services can still be more cost-effective when factoring in the total cost of ownership (TCO). This includes not just hardware costs, but also the time and expertise required for maintenance, upgrades, and troubleshooting. Another one of the primary advantages of cloud services is the ease of scaling. In a colocation environment, scaling up often means purchasing new hardware and physically installing it. How do you address the scalability needs of rapidly growing applications or services in a colocation setup? reply altairprime 12 hours agoparentWhile that may be true, it's not relevant in the context of the article. As the final paragraphs indicate, this is about telling people that datacenters exist at all (yes, people don't realize this!) and allow anyone to sign up and host stuff: > If this is old hat to you, great! It means you're probably a grizzled 1990s sysadmin just like me, consarn it! This isn't for you, then. > This is for the newer folks who might not have realized that there's an alternative to paying tribute to one of the three churches of the Clown: M, G, or A. If you want to \"get your stuff online\", there are other ways... and there always have been! If you don't realize that self-service and managed-tier datacenters exist, you can't properly investigate, calculate, and compare TCO — and certainly the cloud providers aren't going to bring up datacenters unless they have to. reply sethammons 11 hours agoparentprevSendGrid ran our own data centers and scaled massively. Yes, orders to dell took forever and we were often worried if we were going to have enough compute. It worked out to be vastly cheaper than aws but we still moved load into their cloud to help new projects spin up and burst activity. And moving over to managed services eventually became our default, not because it was monetarily cheaper, but because it let teams develop faster. reply phamilton 12 hours agoparentprev [–] I'd add that cloud services are dramatically cheaper when your application is able to tolerate preemption. Spot pricing in AWS is around $0.015/vcpu/hr. That still going to be more expensive than a dedicated server, but it's much closer. If you have cyclical traffic patterns and other elastic workloads, the gap can be almost non-existent, even without considering personnel. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The discussion revolves around colocation (colo) services, which involve hosting servers in a third-party data center rather than at home.",
      "Users are sharing various colo options and deals, including discounts and personal experiences with different providers.",
      "The conversation highlights the pros and cons of colocation versus home hosting, such as reliability, cost, and technical challenges like CGNAT (Carrier-Grade Network Address Translation)."
    ],
    "points": 170,
    "commentCount": 165,
    "retryCount": 0,
    "time": 1727156367
  },
  {
    "id": 41629620,
    "title": "Telegram will now hand over phone number and IP for criminal suspects",
    "originLink": "https://www.theverge.com/2024/9/23/24252276/telegram-disclose-user-data-legal-requests-criminal-activity",
    "originBody": "Security/ Tech/ Privacy Telegram will now hand over your phone number and IP if you’re a criminal suspect Telegram will now hand over your phone number and IP if you’re a criminal suspect / ‘If Telegram receives a valid order from the relevant judicial authorities that confirms you’re a suspect,’ it may now reveal your info. By Emma Roth, a news writer who covers the streaming wars, consumer tech, crypto, social media, and much more. Previously, she was a writer and editor at MUO. Sep 23, 2024, 6:59 PM UTC Share this story Illustration by Alex Castro / The Verge Telegram will now turn over a user’s phone number and IP address if it receives a request from authorities, according to its just-updated privacy policy: If Telegram receives a valid order from the relevant judicial authorities that confirms you’re a suspect in a case involving criminal activities that violate the Telegram Terms of Service, we will perform a legal analysis of the request and may disclose your IP address and phone number to the relevant authorities. The adjustment is the latest change Telegram has made following the arrest of Telegram CEO Pavel Durov last month, who French authorities charged with enabling illegal activity on the platform. In a post on Telegram, Durov says the company is making these changes to “deter criminals from abusing” the app’s search function. Telegram’s search feature allows users to look for public channels and bots, but Durov says it’s been abused by people “to sell illegal goods.” “We’ve made it clear that the IP addresses and phone numbers of those who violate our rules can be disclosed to relevant authorities in response to valid legal requests,” Durov wrote in a post on his Telegram channel. “We won’t let bad actors jeopardize the integrity of our platform for almost a billion users.” Related Telegram changes its tone on moderating private chats after CEO’s arrest Telegram disables ‘misused’ features as CEO faces criminal charges As spotted by 404 Media, Telegram’s law enforcement policy previously only applied to terror suspects, saying: “If Telegram receives a court order that confirms you’re a terror suspect, we may disclose your IP address and phone number to the relevant authorities.” Telegram says it will disclose whether it provided user information to authorities in its quarterly transparency reports. Telegram’s lax moderation policies have made the platform a popular spot for criminals. A recent report from The New York Times uncovered thousands of channels with ties to terrorism, child sexual abuse material, drug trafficking, and extremism. Along with changing Telegram’s privacy policy, Durov says moderators are using AI to identify and remove “problematic content” from the platform’s search feature. Earlier this month, Telegram changed its language surrounding private chat moderation. It also disabled the “misused” People Nearby feature and paused media uploads to its anonymous blogging tool, Telegraph. As Telegram attempts to reverse its shady reputation, it will likely make even more changes to the platform’s approach to illegal content and moderation. Most Popular Most Popular What’s this new mystery Nintendo device? X will let people you’ve blocked see your posts Marques Brownlee says ‘I hear you’ after fans criticize his new wallpaper app Marvel’s new Thunderbolts trailer is armed to the teeth Google TV Streamer review: smarter than your average set-top box Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=41629620",
    "commentBody": "Telegram will now hand over phone number and IP for criminal suspects (theverge.com)163 points by anigbrowl 23 hours agohidepastfavorite121 comments Cody-99 22 hours agoThis shouldn't surprise anyone. If a company collects info about some user and the government comes to them with a legitimate warrant they have to handover the information about that user (or risk going to jail/other action by the court) . There is a reason other companies like signal go out of their way to collect as little as possible. reply molticrystal 22 hours agoparent>the government comes to them with a legitimate warrant Which government, such as the French government for all Russian users, the Russian government for all Ukraine users, or the USA government for all users? Whose standard for warrants, and how much use of coercion and force are they allowed to use for enforcement. Can the USA kidnap the owners for non-compliance, can the Russians? reply kortilla 22 hours agorootparentYou’re asking very basic questions that the answers to have been the same for hundreds of years. If you do business in a country you have to answer to its laws or you risk asset forfeiture or arrest. reply standardUser 22 hours agorootparentThat would only be true if you step foot in that country or posses assets in that country, right? Though I imagine the US government can reach a lot farther than the Russian or Chinese governments. reply DannyBee 19 hours agorootparentNot quite. Here: https://www.asil.org/sites/default/files/benchbook/jurisdict... This is both a reasonable exposition and fairly short. But also keep in mind data collection and transmission and sharing and rule enforcement are not really a jurisdiction thing. reply stvltvs 21 hours agorootparentprevOr the countries you live or travel in have extradition treaties with the other country. reply ocdtrekkie 19 hours agorootparentprevAlso bear in mind that government can convey restrictions on any other business in that country. See Brazil requiring ISPs to ban Twitter (even a penalty on individuals bypassing the block using VPNs!), or the US basically prohibiting any business with anyone in Russia. Basically if you want to operate in a country, you probably need to obey their laws, no matter what you think of those laws. If you ignore them, you can't really be surprised if you get blocked or penalized from doing business there. reply beaglesss 15 hours agorootparentThe ironic consequence of this is eventually if you want to use big tech for messaging privacy you'll be forced to basically pick one under the jurisdiction of an enemy non-extradition state like Russia or China. Sure their governments will farm and exploit the metadata even if encrypted, but they won't be handing it over to the west unless the deal is juicy. reply Gud 12 hours agorootparentAnother option is to use free and open source encryption software, like gpg/pgp. Like what most darknet markets use. reply ocdtrekkie 15 hours agorootparentprevEh, not really, because the US has shown it's happy to go ahead and make it illegal to have TikTok here as well. The real result is probably much, much simpler: Globally-operating apps won't make as much sense as they got away with in pre-regulatory eras of the Internet. Big Tech has basically spent the past twenty years pretending their global status made them above the law of any one nation, but in reality, being a global company just means you're subject to all the laws of all the nations. reply mistrial9 21 hours agorootparentprevremarkably, these are not very basic questions, and the answers are not the same for hundreds of years since this is electronic records that cross international boundaries reply DannyBee 19 hours agorootparentCertainly principles of international jurisdiction are well settled and fairly consistent. In that sense the comment was correct. However, you are also correct that legal principles around information collection and transmission are both new and not well settled. This feels like one of those hn discussions where everyone will end up talking past each other because of terminology failure. reply pixl97 20 hours agorootparentprevI mean if you were shit talking France when living in England a few hundred years back you're likely to get put on the enemies of France list, even if your pages were for consumption in England. Now if you never left England there wouldn't be much to worry about, unless they suddenly became friends and decided to export your corpse for goodwill. reply mikrotikker 14 hours agorootparentprevI have never paid telegram for their business reply mikae1 14 hours agorootparentSo, using the same logic, Meta should not be liable for what happens on Facebook because users do not pay… That's some Barlowesque[1] thinking that would play into the hands of big tech. If Telegram didn't want to answer to French law, they should've blocked French phone numbers from registering users. Problem solved. [1] https://disconnect.blog/reclaiming-sovereignty-in-the-digita... reply mikrotikker 14 hours agorootparentMeta sells my data to advertisers reply dkasper 22 hours agorootparentprevI think you answered why the only real solutions are a) don’t collect the data (signal approach) b) hire an army of lawyers and compliance people (big tech approach) c) ban users from entire countries where you don’t comply (common in crypto) d) risk jailtime or asset forfeiture reply AyyEye 22 hours agorootparentSignal has both phone numbers and IPs. reply shakna 20 hours agorootparentSignal hand over IP logs, phone numbers, and the datetime of last connection. [0] [0] https://signal.org/bigbrother/central-california-grand-jury/ reply PawgerZ 3 hours agorootparentThat link states that they only have two data points tied to an account: time of account creation and time of last connection. Since phone numbers are used as the account identifier, law enforcement would need to supply the phone number for signal to look up the account, right? Do you have any source for Signal supplying IP logs? reply larodi 19 hours agorootparentprevThis all seems bad news for all Russian war channels, but I guess they had enough time to migrate already. Influencers influence the whole world anyway, so they should expect a knock on the door if so brave. Stupid drug dealers will find other ways to deal or will go deeper the crypto/tor hole. Childporn offenders are anyway legit target for Mr.Robot. Who's left then...? Music pirates - who cares, Spotify lives on, Soulseek does well to. Torrents apparently kill business only where it cannot exist at all due to cultural specifics. This all somehow leaves perhaps not-so-big list of particularly interesting gentlemen then certain countries will undergo a lot of trouble to get to. No wonder then they did so this time, but wonder which particular among these is the culprit this time... reply mikrotikker 14 hours agorootparentBad news for the OSINT community who gets tonnes of leaks from Russian war telegram channels reply larodi 7 hours agorootparentI doubt the war channels are to be concerned, perhaps the secret chats, and leftover magic in the normal chats. Or even simpler - the phone of the devices allows mobile net tracking, for certain operations this is potentially more than enough. reply limit499karma 22 hours agorootparentprev> Which government ... Whose standard It depends entirely on where you land in your private jet. reply Cody-99 22 hours agorootparentprevWhere ever they want to do business at. If they expect to be allowed to operate in France/the EU they will have to comply with legitimate French/EU warrants. No one is saying they can't fight it if there is a reason to. >Can the USA kidnap the owners for non-compliance, can the Russians? Jailing someone/holding a company in contempt that does business in your country for ignoring legal warrants isn't kidnapping. Trying to frame it that way is pretty silly and disingenuous. reply Ajedi32 4 hours agorootparentWhat does it mean to \"operate\" in a country though? If I operate a service in the US and have no servers in Iran, no employees in Iran, no physical presence in Iran whatsoever, but Iranians are communicating with me over the global public internet, does that mean I have to comply with Iranian law? What about if its France and not Iran? What if these French/Iranian users are not only communicating with me, but also sending me money and/or cryptocurrency in exchange for that communication? reply Ajedi32 3 hours agorootparentPersonally I would contend that none of that counts as \"operating\" in France or Iran. You're operating entirely in the US, and it would be ridiculous for Iran or France to try to subject you to their laws just because people who live in their country are communicating with you or sending you money. (Though obviously those people are still subject to the laws of their respective countries in what they're allowed to do when interacting with you, just as you are subject to US law in your interactions with them.) Of course, the fact that something is ridiculous doesn't prevent a sovereign country from trying to do it anyway. Iran can threaten to assassinate you for communicating with their citizens, and France can threaten to jail you if you ever travel to France or extradite you. Both of those threats are unjustified in my opinion and should not be supported or condoned by other countries (particularly not the US), but like I said; they're sovereign countries so we can't do much to stop them if they want to be unreasonable. reply tmottabr 2 hours agorootparenti disagree completely on this.. If you are serving people in Iran or France then you are operating in those countries regardless of where you or your servers are and so you do have to comply with their laws or risk facing the consequences. Now, depending on where you are at the reach of the consequences can be negligible and not impact you at all or can be a major problem. At minimum you will get your service banned in those countries. reply Ajedi32 1 hour agorootparentIn this example everything is happening on U.S. servers, with U.S. employees, on U.S. soil. How is that \"operating in\" Iran or France? If someone physically flew over from Iran and talked to me in-person instead of over the internet would you make the same argument? That I'm \"operating in Iran\" and should be subject to Iranian law because I'm talking to an Iranian citizen? What if it was via a letter? How about a phone call? reply cpa 22 hours agorootparentprevSo what? Legitimate warrants cannot exist? Companies exist somewhere, and they follow the rules that can be enforced on them. I'll take warrents by imperfect democracies over autocracies and dictatorship any day. reply hartator 22 hours agorootparentprevHa! The devil of the details. reply crabbone 22 hours agorootparentprevThis will depend on how the company is registered and represented in the states it operates in. It will also depend on the citizenship of the kidnapped owners (and whether it will be even necessary, as maybe extradition would also work). In any case, a court in any particular state will be responsible for issuing the documents entitling the law enforcement to particular data. There's also the process to dispute issuance or legitimacy of such documents, again, through courts. So, obviously, there isn't a single answer to your questions. But, obviously, they aren't without answer. Any specific case will produce a potentially different set of answers. reply russdpale 22 hours agorootparentprevYou ask these like they are some kind of gotcha moment, but all of these very simple questions have been answered for decades by international law. You think yourself clever but show yourself ignorant. reply colechristensen 22 hours agorootparentprevYou have to follow the laws in the jurisdictions in which you do business. If you want to not be subject to the laws of a country you need to blackhole that entire country. reply krick 22 hours agoparentprevEvery time someone brings up Signal in these threads I cringe. One can make up stories about spam protection as much as he wants, but given how little (basically none) control one has over him phone number, no messenger strictly requiring a phone number can be considered \"privacy-oriented\" by any sane person. reply maxwell 22 hours agorootparentWhat do you advocate for an alternative identifier and how do you combat spam without verifying a phone number? reply pier25 22 hours agorootparentno IDs, only connect to the users you choose to connect with SimpleX comes to mind https://simplex.chat/ reply Cody-99 22 hours agorootparentprevHuh? I think you are confusing \"privacy-oriented\" and anonymous! Signal is pretty privacy oriented since it has E2EE by default (and so does Whatsapp). Telegram would be much more privacy oriented if it had E2EE by default. reply fragmede 22 hours agorootparentprevthey have usernames now reply lostlogin 22 hours agoparentprevUser data is a liability, not an asset. However this is untrue when breaches, leaks and misuse aren’t prosecuted. It’s a shame we have ended up here. reply BadHumans 22 hours agorootparentThis is only true if the cost of storing user data is greater than the profits it generates. When companies are allowed to sell out users and punishment for data leaks are just seen as the cost of doing business then why would you not store whatever data you can get your hands on? reply bdjsiqoocwk 22 hours agorootparentprev> User data is a liability, not an asset. Yeah Google and Facebook are all losing money in those liabilities. No theyre not, they're printing money because user data is an asset. Stop repeating silly sound bytes. reply sonofhans 22 hours agorootparentUser data is only an asset if your business model demands it, like Google and Facebook. If you don’t have, and won’t create, a way to monetize it then yes, it’s strictly a liability. reply lostlogin 12 hours agorootparentprevWhen you quote part of my comment, it give a different message. Clever! reply idle_zealot 22 hours agorootparentprevIt's not that it is a liability, it's that it should be. Likewise, it currently is an asset, but shouldn't be monetizable. reply upofadown 22 hours agoparentprevThe incentive is to claim to collect as little as possible. What a company actually collects is between them and any influential state actor that can manage to make use of the data in secret. A company can't support the needs of such an actor and law enforcement at the same time. reply slt2021 21 hours agorootparentyou care confusing collecting data with persisting user data. it is easy to prove what your app collects from OS's permission model and web traffic. People are less interested in whether you store it for future use or discard it immediately after receiving. Even if you claim you don't persist any of user data, you would still be collecting it reply whycome 22 hours agoparentprev\"Legitimate warrant\" is a flexible and fluctuating idea. When a new government takes over, they may want information on all potential opposition. reply beefnugs 22 hours agoparentprevyep, and reading the news lately \"legitimate warrant\" means things like \"has a harris poster on their lawn\" reply chemmail 21 hours agoparentprevBut my crypto bro friends said they would only communicate by Telegram because it is 1000% secure! reply greatgib 19 hours agoprevNow the question is, to which government Telegram will comply to share your info. If I live in Germany, and I do a channel with offensive content against the government of an Arabian shitty country, let's say UAE for example. The content might be legal here but illegal there. Will the UAE gov be entitled to get my IP address and other info? Leading them to be able to use that to harass me, like targeting me with Pegasus for example? reply oloila 3 hours agoparentI think, firstly you will be punished by DE, because of hate speech, hehe reply oloila 3 hours agoprevGovernments are enemies of freedom I miss old 200x years, when Internet was so free and there was no any problems, lol reply handity 22 hours agoprevThis was entirely predictable and inevitable. I don't understand what Durov thought would happen nor why he rejects E2EE as a liberating technology. Policy will never be the key to digital privacy, it must always be accompanied by cryptography. The status quo of allowing a third party read and store your messages forever, slurping up all the metadata along the way, is insane. reply enedil 20 hours agoparentI think it is pretty obvious why Durov did not opt for universal E2EE. His main purpose of making Telegram was to make the chat app that is the most usable of all. E2EE comes with a cost on user experience which was for him too high. Example: Signal can't handle more than one phone logged in, and if for some case you don't open the desktop app for more than 30 days, it logs you out there and you can never get these messages to the desktop. reply akimbostrawman 12 hours agorootparentthat is a limitation of signal not E2EE for an example see matrix although E2EE chats do take more computing and storage especially with very large groups reply sharpshadow 22 hours agoprevGood that the company is able to continue functioning with the CEO being trapped and under charges. Shame on France for pulling a nasty warrant mid air. reply bdjsiqoocwk 22 hours agoparentWell, the fact that Telegram wants to cooperate to me suggests that they previously could have been cooperating but weren't, which makes a charge of complicity make a lot more sense now. Thanks France! reply maipen 22 hours agorootparentnext [3 more] [flagged] dang 1 hour agorootparentCould you please stop posting unsubstantive comments and flamebait? You've unfortunately been doing it repeatedly. It's not what this site is for, and destroys what it is for. If you wouldn't mind reviewing https://news.ycombinator.com/newsguidelines.html and taking the intended spirit of the site more to heart, we'd be grateful. reply rmbyrro 22 hours agorootparentprevIt looks like we need tyranny from time to time so that people learn why lots of people died to earn basic rights... It's always tempting. \"We're only doing it to get the bad criminals!\" Sounds great. Until a tyrant decides you're bad. reply sirolimus 21 hours agoprevWell that's a shame... reply ChrisArchitect 23 hours agoprev[dupe] https://news.ycombinator.com/item?id=41628019 reply anigbrowl 22 hours agoparentDupes are submissions of the same article. I thought this one was better than the others I had seen on this topic. reply ChrisArchitect 22 hours agorootparentYou can't submit the same article twice for the most part. Dupes are duplicate discussions. There's an earlier article with some discussion and eventually maybe mods will merge them. No need to split up the discussion. Share your thoughts over there! You could even suggest this link in that thread as a better article option. reply anigbrowl 22 hours agorootparentYou totally can, the HN dupe detector is less than reliable. Submit something interesting at night and you'll often see it submitted the following day by someone else. As a more general point, the fact is that if a discussion doesn't take off while an item is on the front page shortly after submission, it probably never will. The page sorting algorithm ends up prioritizing recency and traction. I agree this isn't ideal. reply pier25 22 hours agoprevHonestly you have to be a bit dumb to write incriminating stuff on popular messaging apps like Telegram, Whatsapp, etc. I would imagine any serious criminal org will have their own messaging infra by now. reply quesera 22 hours agoparent> I would imagine any serious criminal org will have their own messaging infra by now. I'm guessing they do not -- that would be inconvenient, expensive, unreliable, insecure, and/or conspicuous. [Edit: \"serious\" criminal orgs run, e.g., custom-built submarines, so private comms infrastructure is clearly within their technical abilities. But having all org members communicating to a private centralized mothership seems risky from a surveillance perspective] reply LinuxBender 21 hours agorootparentI'm guessing they do not -- that would be inconvenient, expensive, unreliable, insecure, and/or conspicuous. Some do run their own platforms or share a self hosted platform set up by people in a non cooperating country. Sometimes the platform admins find out they were being MitM by mistake tech or law enforcement make. [1] Or not using the MitM detection Jabber is capable of. Jabber scales to millions of users per cluster, big enough for probably most criminal organizations. I doubt the cluster in question was specifically meant for criminals, but the smart criminals will find solutions best suited for their needs. In this case I think they chose poorly given VM's can be live migrated and snapshot including memory contents without interrupting the platform or raising suspicion. In my humble opinion the big shared corporate platforms will attract the ultra-lazy arrogant and cavalier criminals and I'm sure law enforcement are fine with it. Easy busts still look good to justify big budgets. There are probably people that say they don't know anyone that's been busted on those platforms but they are probably not moving enough volume of illicit goods to warrant immediate attention. That information would be quite useful for getting a warrant however if the target was suspected of something else or if they were an influencer thinking or saying the wrong thing in public. [Edit] Updated link to the snapshot describing potential mitigations including SCRAM PLUS which was not configured in this incident. [1] - https://archive.ph/4wi5t reply pier25 20 hours agorootparentprevMore insecure than an app that keeps track of everything in a database you cannot control and can be accessed by the authorities? Even when deleting messages how can you trust these are actually being hard deleted? I would imagine the inconvenience and cost are worth it but what do I know... I'm not a criminal :P reply standardUser 22 hours agoparentprevI know people who order drugs all the time via various messaging apps, in the US and throughout Latin America. Often the messages and menus are highly explicit. reply akvadrako 11 hours agoparentprevActually it's the criminals that use secure messaging services made for them that get in trouble. There have been a few big busts the last years by the Dutch police of criminal rings, caught because of their choice in messengers. The ones using Signal or Whatsapp are the smarter ones. reply RadixDLT 14 hours agoprevhaha Durov is singing like a bird now that he go apprehended reply oloila 3 hours agoparentThis is not \"haha\". It's a pity. Even Russia haven't forced Telegram to do things that now they need to comply because Pavel became hostage of this situation reply ein0p 18 hours agoprevRubber hose cryptanalysis works every time, unless you design your protocol to not have any visibility into the data. Which is impossible in the case of Telegram feeds at the very least. reply janmo 22 hours agoprevIn a sense the surveillance in the \"west\" and in particular in the EU is worse than what you have in China. At least the Chinese they know that all their conversations are being monitored and read by the government. In the EU many people still live under the illusion of GDPR, data privacy, democracy etc... reply TZubiri 22 hours agoprevSounds good to me reply sub7 22 hours agoprevThey are coming for you Tether reply bediger4000 23 hours agoprevAbout time. Criminals hiding behind some technicalities! reply JadeNB 22 hours agoparentThere is a difference between \"criminal\" and \"criminal suspect.\" reply lostlogin 22 hours agoparentprevIf you’ve got something to hide, you’re guilty! /s reply compootr 22 hours agorootparentWe don't need privacy! Only criminals want those pesky \"privacy policies,, to protect their operations! 1 reply cb86 22 hours agoprevWarrant canary removed: https://opentermsarchive.org/en/memos/telegram-expands-forbi... reply yieldcrv 20 hours agoparentHm, given how many requests Meta and Google disclose annually I dont think a warrant canary is really useful, it implies “we just got 1!” instead of “we just got an additional pile of 200 secret requests from G-7 national governments, one of which is already trying to incarcerate us for not being so forthcoming about compliance” reply jacobgkau 15 hours agorootparentGiven that you won't know the details of the 1 or 200 requests anyway, I think knowing the difference between 0 and >0 is useful. We do know what 0 means, and anything other than 0 means the platform's got the attention and jurisdiction of outside parties. reply akira2501 23 hours agoprevnext [34 more] [flagged] vel0city 23 hours agoparentThe CEO of Signal has not been arrested. Also, Signal does supposedly comply with all lawful warrants. They give over what data they do have when properly requested. It is just they don't normally have much useful data to give. Meanwhile, Telegram supposedly hasn't been properly handling lawful warrants in many countries and does have interesting data on their servers as only private secure messages are (meaningfully) encrypted and not most messages most users send on the platform reply tjoff 23 hours agoparentprevOf Signal? reply GaggiX 23 hours agoparentprevHow is enforcing subpoenas a form of terrorism? reply Hydenty 23 hours agorootparentIt's not the good old days any more. Your government doesn't represent you. Its police, military, and \"justice\" system are not manned by good people acting in the interests of the people and community. Snap out of it. reply vel0city 23 hours agorootparentThe good old days when governments represented people, like before the 17th Amendment when states picked the Senate in smokey backroom deals. Wait that can't be right, maybe like before the 19th Amendment. Wait no, during the Jim Crow era. No, the McCarthyism era. Wait...uhh...hmm... I don't know what time period you're thinking of with \"It's not the good old days any more. Your government doesn't represent you.\" Seems like the government represents more people better today than it did in the past given before so many couldn't even vote at all and the government was far more active in suppressing minority rights. And if its about them snooping in on conversations, these days they have to actually ask a lot of communication providers for data. Back in the day there was only one company providing electronic communications and the government was absolutely listening in to the conversations. Tons of those communications were happening over the air for anyone with the right antenna to listen in. US v. Miller was in 1976 and established what we now know as third-party doctrine. reply GaggiX 23 hours agorootparentprevYeah I'm sure it was better in the good old days ahaha reply AndrewKemendo 23 hours agorootparentNo it’s just that now it affects everyone not just certain groups which is the tipping point for Society to reorganize This is what is called out by Polybius, Socrates, Jefferson, Strauss/Howe as the socio-political cycle. reply weirdflex68 23 hours agoparentprevnext [21 more] [flagged] akira2501 23 hours agorootparentThis is the most bullying way to make excuses for the government, but okay. By the way, until convinced, he's not a criminal. You don't even see the problem that's crept into your own language, do you? reply ThePowerOfFuet 22 hours agorootparent>until convinced, he's not a criminal Freud would absolutely approve. reply mathgeek 23 hours agorootparentprevCriminal _suspects_ are not the same as criminals. reply ajsnigrutin 23 hours agorootparentprevThe problem lies in \"what is a crime?\" here. If you can get arrested for organizing a protest (that didn't even start that), do you still think that those people are criminals? Just look at all the people that got arrested recently in UK... It's sad, and telegram, not being a UK company (imho) shouldn't be forced to give UK government/police peoples ip addresses and phone numbers. reply ezst 23 hours agorootparentIf they want to operate in country X, they have to abide by the laws of country X, I don't see what's controversial about this. reply ajsnigrutin 21 hours agorootparentBut they're operating in UAE (or whereever they're registred). They just get visitors from UK. reply ezst 12 hours agorootparentWhere they operate doesn't matter, and it should be pretty obvious why (hint, for the same reasons that American bleached chicken can't be sold in the EU) reply immibis 22 hours agorootparentprevThe laws of country X are controversial. reply squarefoot 22 hours agorootparentAll countries have laws that are controversial for some other country. reply ajsnigrutin 21 hours agorootparentYep. Imagine iran requesting all the IP addresses of people who have viewed gay porn from pornhub (=Aylo or whatever it's called now) reply ezst 12 hours agorootparentI imagine that this would be reason enough for them to either comply with the law or not operate there, like every other business does? You seem to imply that it's ok for internet companies to be above the law, I don't see how that's compatible with self-determinism/democracy (loss of jurisdiction) nor in the interests of the people (because inevitably such companies will optimize their profits at the expense of the public and can't be held accountable, in your anarchic world order). reply ajsnigrutin 7 hours agorootparentLet's say your set up a raspberrypi at home (I assume you live in US), install apache, install wordpress, set up port forwarding and write a blog about making pickles. Then someone writes a comment under \"How much dill?\" and writes \"I'm from Iran and I'm gay\". Are you really operating in iran? You don't have servers there, you don't have employees there, you're not a registered company there, what ties do you have with iran? Someone from iran \"came to visit\"? Sure, so do brits with amsterdam and legal weed. reply immibis 11 hours agorootparentprevThey definitely wouldn't stop operating in Iran and miss that sweet ad money reply ezst 10 hours agorootparentthen it's fair game for Iran (or any other country) to fine them/block them for that. reply petesergeant 23 hours agorootparentprev> telegram, not being a UK company (imho) shouldn't be forced to give UK government/police peoples ip addresses and phone numbers They absolutely should if they want to operate in the UK. reply switch007 22 hours agorootparentDefine operate in. Does HN operate in the UK because I can access it here? Should they be subject to UK law? reply Jaepa 22 hours agorootparentprevShould the same rule exists in more authoritarian countries like China, North Korea, or Belarus? If so should the government be allowed access to non-nationals outside the country? How about if a non-national is inside the country communicating with those outside? How about if those folks are journalist reporting where journalism is illegal (see Russia's laws on \"fake news\" on Ukraine). I'm not saying your point of view is wrong, but I think its easy to jump to that conclusion as this is probably the least sympathetic case to set principle. But this _does_ set principle. reply ajsnigrutin 21 hours agorootparent> Should the same rule exists in more authoritarian countries like China, North Korea, or Belarus? If eg. Iran requested IP addresses from Pornhub (Aylo?) for all the visitors from iranian ip addresses who have viewed a gay video there, people would be changing their view pretty fast. reply ajsnigrutin 21 hours agorootparentprevBut they're registered in UAE (i think it's there). They might get \"visitors\" from UK, but so do \"coffeeshops\" in amsterdam. reply smileson2 23 hours agorootparentprevThat’s not for telegram to decide and dictate to everyone else I’m not sure I’d call that sad reply AStonesThrow 23 hours agoparentprevYes how strange that a DARPA project, handed off to the National Science Foundation and then awarded to Sprint, would be torn from the common man and wrested from its rightful owners into the heartless clutches of government authority reply akira2501 23 hours agorootparent> that a DARPA project How much of what you use today has anything to do with DARPAs original design goals or funding? > handed off to the National Science Foundation and then awarded to Sprint The NSF handled links between Universities and their funding not the Internet in general. Sprint was a primary contractor under this system. None of this should be understood as \"the Internet.\" > would be torn from the common man You do appreciate precisely how much open source software underpins everything we're doing, even in typing these comments to each other, over the internet, yes? I mean.. show me the government plan to build a web browser. > from its rightful owners Do you pay taxes? Congratulations. You are the rightful owner. > into the heartless clutches of government authority Yea. Hacker News. Typical bastion of mindless worship of \"government authority.\" Then again, if it has the natural right to exist, why does it need my taxes? reply derefr 23 hours agorootparentTo put a fine point on it: what DARPA did, was to sponsor a company called BB&N to develop a piece of hardware called the Interface Message Processor (or IMP). And that's pretty much it. The IMP was the first gateway doing what you'd think of today as Network Address Translation, isolating \"LAN\" from \"WAN\" and using arbitrary computation to rewrite packets between the two. Though at the time, far more work was needed than just address translation. Wholesale network protocol translation was needed, as every site network (and there were already many small site networks) used its own networking equipment; and each vendor's networking equipment spoke some random stack of proprietary protocols invented by that equipment vendor. (There were nascent standards with open reference-impl hardware, e.g. MIT's Chaosnet, but none of these were widely adopted.) This was true all the way up to the application layer — different networking equipment required different application software that spoke the network's supported application protocols! The IMP was a programmable router, allowing arbitrary CPU packet translation. So each site network could program the very same IMP with the details of its own network — what each type of local-network packet looked like, and what that should translate to for the WAN; and vice-versa. This allowed these site networks to be glued together into a larger network. The IMP translated packets, and also \"wrapped\" each (proprietary, site-local) address of each LAN host, giving it a globally-routable name — i.e. an Internet Protocol address. This allowed machines on these networks to — at least in theory — address other networks' machines. All without anyone having to rip out any networking equipment, or replace each network's host application software with new software speaking standardized protocols. Once the IMP was released, a bunch of universities and corporations came along and said to BB&N, \"oh hey neat, I'll buy one of these! Heck, I'll buy one for each campus!\" — and promptly stuck them into each of their (existing!) networks. (Some of these purchases were partially funded by DARPA as well — but only if the buyer reached out to ask.) This didn't actually get anyone any value at first, because the IMPs still needed to be programmed, not just with the details of their local networking standards, but with the details of what the \"WAN standard\" application packet protocols would/should be for these local networks to translate things into. There were no standards for that yet. So the folks doing the networking at these orgs, all got together to discuss how to actually get these boxes they bought to talk to each-other — e.g. what application-layer protocols they would need to invent/standardize on, to then get these gateway boxes to translate into from the proprietary site protocols they were using. That group became known as the Internet Engineering Task Force, and their meeting notes became known as RFCs. (Read https://datatracker.ietf.org/doc/html/rfc1 if you don't believe me.) Note that they called this WAN network formed by these sites through the IMPs the \"ARPA Network\" — presumably because that's what BB&N referred to it as, in turn because DARPA funded the IMP with the intent of creating such a network. But DARPA had no involvement in the actual development of the \"ARPA Network\"! They weren't even a site on it! They didn't attend the IETF meetings! Rather, DARPA just kinda stepped back and said \"go ahead, have fun\" — and watched as the Internet took shape. (I would thus describe DARPA's funding of the BB&N IMP as probably the most successful case of \"nudge theory\" in history. Almost as if someone at DARPA was a time-traveller who knew that that much effort, and no more, was all that was needed to shift the timeline.) reply AStonesThrow 22 hours agorootparentWell yeah, and the government sponsored a little company called Los Alamos to develop a few things. But now we own them, I guess. reply derefr 22 hours agorootparentBB&N was and remains a private company, and isn't primarily a government contractor. It was a one-time government grant — and for much less than the full CapEx required to build the thing. DARPA essentially said \"you want to build this? We'd sure like something like that to exist, so we'll give you some money to increase your chances/make it happen faster.\" As it turns out, \"throwing money at American-owned private companies who are being the [technological] change you [i.e. the state] wants to see in the world, to advance the technological edge America has over other countries\" is a large part of DARPA's mandate. DARPA seeks to incubate a healthy private sector in nascent high-tech industries, so that it can later rely on competition in those industries, to produce a healthy, non-monopolistic set of viable military contract bidders for the military as a whole to choose from / set against one-another. reply AStonesThrow 23 hours agorootparentprevPony Express, telegraph lines, railroads, a national highway system: what purpose and goals do you think were in mind here? So you could jaunt down Route 66 for a burger, and send back a 5c postcard??? Haha! > How much of what you use today has anything to do with DARPAs original design goals or funding? 100% The National Center for Supercomputing Applications (NCSA) is a state-federal partnership to develop and deploy national-scale cyberinfrastructure that advances research, science and engineering based in the United States.[1][2] NCSA operates as a unit of the University of Illinois Urbana-Champaign,[3] and provides high-performance computing resources to researchers across the country. Support for NCSA comes from the National Science Foundation,[1][4] [5] [6] the state of Illinois,[2] the University of Illinois, business and industry partners,[7] and other federal agencies. https://en.wikipedia.org/wiki/CERN https://en.wikipedia.org/wiki/CERN_httpd https://en.wikipedia.org/wiki/NCSA_Mosaic https://en.wikipedia.org/wiki/NCSA_HTTPd Are you even serious rn? If you're right then I shall take out my equity in the form of SAM batteries. How many will fit on my balcony. reply ElonChrist 23 hours agoprevPreviously posted: https://news.ycombinator.com/item?id=41629437 https://news.ycombinator.com/item?id=41628467 https://news.ycombinator.com/item?id=41628381 https://news.ycombinator.com/item?id=41628019 reply metadat 23 hours agoparentThe only relevant link with discussion is the last one: https://news.ycombinator.com/item?id=41628019 - 3 hours ago (6 comments) And it's not a dupe, only a related submission (different article / link). reply harryf 22 hours agoprev [–] It’s sad to see HN become so full of bots. > prompt: There’s an article on Hackernews titled “Telegram will now hand over your phone number and IP if you’re a criminal suspect”. Generate a comment in Hackernews style that supports this decision, implies that it’s because they didn’t encrypt the messages and uses Signal as an example of doing it right because “look! They haven’t had problems” Not surprised. Telegram doesn't encrypt by default, so of course they're handing over phone numbers and IPs. If you don't lock things down like Signal does, you're going to have problems. Signal can’t hand over what they don’t have—encrypted end-to-end, no metadata. Simple as that. reply handity 22 hours agoparent [–] I guess I'm a bot then. Yes, channels and groups are most likely what makes Telegram a threat where Signal isn't. That's an excellent argument for decentralized social media. You're probably exasperated that others don't see what to you seems like an obvious truth. Rather than mocking the opposing argument, it's probably still worth rehashing yours when the topic comes up, even if it feels like banging the same drum with nobody listening. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Telegram will now share a user's phone number and IP address with authorities if they are criminal suspects, as per its updated privacy policy.",
      "This policy change follows the arrest of Telegram CEO Pavel Durov, who was charged with enabling illegal activity on the platform.",
      "Telegram will include these disclosures in its quarterly transparency reports and is using AI to remove problematic content, alongside changes to its moderation policies."
    ],
    "commentSummary": [
      "Telegram will now share phone numbers and IP addresses of criminal suspects with authorities, complying with legal warrants.",
      "Unlike Signal, which collects minimal user data, Telegram's lack of default end-to-end encryption makes it more susceptible to data requests.",
      "This decision raises ongoing debates about privacy concerns and the implications of compliance across international jurisdictions."
    ],
    "points": 163,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1727119715
  },
  {
    "id": 41632719,
    "title": "Tracy: A real time, nanosecond resolution frame profiler",
    "originLink": "https://github.com/wolfpld/tracy",
    "originBody": "Tracy Profiler A real time, nanosecond resolution, remote telemetry, hybrid frame and sampling profiler for games and other applications. Tracy supports profiling CPU (Direct support is provided for C, C++, Lua and Python integration. At the same time, third-party bindings to many other languages exist on the internet, such as Rust, Zig, C#, OCaml, Odin, etc.), GPU (All major graphic APIs: OpenGL, Vulkan, Direct3D 11/12, Metal, OpenCL.), memory allocations, locks, context switches, automatically attribute screenshots to captured frames, and much more. Documentation for usage and build process instructions Releases containing the documentation (tracy.pdf) and compiled Windows x64 binaries (Tracy-.7z) as assets Changelog Interactive demo An Introduction to Tracy Profiler in C++ - Marcos Slomp - CppCon 2023 Introduction to Tracy Profiler v0.2 New features in Tracy Profiler v0.3 New features in Tracy Profiler v0.4 New features in Tracy Profiler v0.5 New features in Tracy Profiler v0.6 New features in Tracy Profiler v0.7 New features in Tracy Profiler v0.8",
    "commentLink": "https://news.ycombinator.com/item?id=41632719",
    "commentBody": "Tracy: A real time, nanosecond resolution frame profiler (github.com/wolfpld)156 points by Flex247A 16 hours agohidepastfavorite26 comments vblanco 10 hours agoA truly incredible profiler for the great price of free. There is nothing coming at this level of features and performance even on paid software. Tracy could cost thousands of dollars a year and would still be the best profiler. Tracy requires you to add macros to your codebase to log functions/scopes, so its not an automatic sampling profiler like superluminal, verysleepy, VS profiler, or others. Each of those macros has around 50 nanoseconds of overhead, so you can liberally use them in the millions. On the UI, it has a stats window that will record average, deviation, min/max of those profiler zones, which can be used to profile functions at the level of single nanoseconds. Its the main thing i use for all my profiling and optimization work. I combine it with superluminal (sampling profiler) to get a high level overview of the program, then i put tracy zones on the important places to get the detailed information. reply eagle2com 9 hours agoparentDoesn't Tracy have the capability to do sampling as well? I remember using it at some point, even if it was finicky to setup because windows. reply vblanco 8 hours agorootparentit does, but i dont use it much due to it being too slow and heavy on memory on my ryzen 5950x (32 threads) on windows. a couple seconds of tracing goes into tens of gigabytes of ram. reply forrestthewoods 4 hours agorootparentprevYeah I had issues with the Tracy sampler. It didn’t “just work” the way Superluminal did. My only issue with Superluminal is I can’t get proper callstacks for interpreted languages like Python. It treats all the CPP callstacks as the same. Not sure if Tracy can handle that nicely or not… reply forrestthewoods 6 hours agoparentprevTracy and Superluminal are the way. Both are so good. reply Flex247A 10 hours agoparentprevHello! Going through your tutorial and it's been a great ride! Thanks for the good work. reply gcr 5 hours agoprevMy favorite FOSS video game, Dr. Robotnik’s Ring Racers (http://kartkrew.org), has Tracy support! It’s not compiled into the default build. I’ve learned a lot reading the code. reply Flex247A 11 hours agoprevI am a beginner in graphics programming, and I came across this amazing frame profiler. Web demo of Tracy: https://tracy.nereid.pl/ This blows my mind. It's so fast and responsive I never expected a WebAssembly application to be! reply mastax 4 hours agoprevThis article is a good quick introduction to Tracy: https://luxeengine.com/integrating-tracy-profiler-in-cpp/ reply mastax 5 hours agoprevI just started using this yesterday, it looks really good. Haven’t really dug into it. Is the latest windows build broken for anyone else? It doesn’t start. In WinDbg it looks like it dereferences a null pointer. I built it myself and it works fine. reply mastax 4 hours agoparentOf course I come into work the next day and now I can't run my custom built one either... reply mastax 3 hours agorootparenthttps://github.com/wolfpld/tracy/issues/887 MSVC changed the mutex constructor to constexpr, breaking binary backward compatibility. They say WONTFIX, you must use the latest MSVCRT with the latest MSVC. But I have the latest MSVCRT installed? Whatever - a workaround was pushed to master yesterday. reply throwawaymaths 2 hours agoprevCan anyone with experience suggest pointers on arguing Tracy vs perfetto? My team uses perfetto and I highly suspect we are running into artefacts due to that. reply Green-Man 4 hours agoprevDoes anybody have an opinion or comparison with respect to easy_profiler? https://github.com/yse/easy_profiler Especially interesting if based on real practical experience. reply drpossum 9 hours agoprevCan someone explain how this achieves nanosecond resolution? That's an extremely difficult target to reach on computing hardware due to inherent clock resolutions and interrupt timing. reply simonask 9 hours agoparentThere are several sources of timing information, and I think in this context \"nanosecond precision\" just means that Tracy is able to accurately represent and handle input in nanoseconds. The resolution of the actual measurements depends on the kind of measurement: 1. If the measurement is based on high resolution timers on the CPU, the resolution depends on the hardware and the OS. On Windows, `QueryPerformanceFrequency()` returns the resolution, and I believe it is often in the order of 10s or 100s of nanoseconds. 2. If the measurement is based on GPU-side performance counters, it depends on the driver and the hardware. Graphics APIs allow you to query the \"time-per-tick\" value to translate from performance counters to nanoseconds. Performance counters can be down to \"number of instructions executed\", and since a single instruction can be on the order of 1-2 nanoseconds in some cases, translating a performance counter value to a time period requires nanosecond precision. 3. Modern GPUs also include their own high-precision timers for profiling things that are not necessarily easy to capture with performance counters (like barriers, contention, and complicated cache interactions). reply drpossum 9 hours agorootparentYes, that's my understanding and why I asked. I disagree about \"in this context\", though, which is a pitch. If I was going to buy hardware that claimed ns resolution for something I was building I would expect 1ns resolution, not \"something around a few ns\" and not qualified \"only on particular hardware\". If such a product were presenting itself in a straightforward way to be compared to similar products and respecting the potential user it would say \"resolutions down to a few ns\" or something more specific but accurate. There was even a discussion on this not long ago on how to market to technical folks and things to not do (this is one of the things not to do) https://www.bly.com/Pages/documents/STIKFS.html https://news.ycombinator.com/item?id=41368583 reply vardump 9 hours agoparentprevOn x86/AMD64 it uses CPU's TSC clock. https://github.com/wolfpld/tracy/blob/master/public/client/T... reply Galanwe 9 hours agoparentprevIt does reach nanosecond only in the sense that its sampling profiler can report nanosecond resolution. I've tried the event profiler for microsecond sensitive projets though, and it blows up the timings and latency even at low event frequency. reply vardump 6 hours agorootparentI think it’s mostly due to Tracy’s poor timing calibration code. TSC is good accuracy and latency wise. reply Galanwe 2 hours agorootparentThe problem is not the timestamping, it's the queue used to push profiling events which is not fast enough reply vardump 2 hours agorootparentThat queue is about as fast as it gets, <10 ns. Timestamp is taken before queueing. Again, due to bad calibration code the measured timestamps have quite a bit jitter. Edit: TSC might not be synchronized in multi-socket systems. (Multiple physical CPU sockets). That can generate a large error. reply cwbaker400 9 hours agoprevTracy is brilliant. @wolfpld I hope you're enjoying reading this and all of the other great comments in this thread. Great work and thank you very very much! reply boywitharupee 7 hours agoprev [–] can someone explain how is profiling tools like this written for GPU applications? wouldn't you need access to internal runtime api? for ex. Apple wraps Metal buffers as \"Debug\" buffers to record allocations/deallocations. reply MindSpunk 6 hours agoparentSome graphics APIs support commands that tell the GPU to record a timestamp when it gets to processing the command. This is oversimplified, but is essentially what you ask the GPU to do. There’s lots of gotchas in hardware that makes this more difficult in practice as a GPU won’t always execute and complete work exactly as you specify at the API level if it’s safe to. And the timestamp domain isn’t always the same as the CPU. But in principle it’s not that different to how you just grab timestamps on the CPU. On Vulkan the API used is called “timestamp queries” It’s quite tricky on tiled renderers like Arm/Qualcomm/Apple as they can’t provide meaningful timestamps at much tighter granularity than a whole renderpass. I believe Metal only allows you to query timestamps at the encoder level, which roughly maps to a render pass in Vulkan (at the hardware level anyway) reply ossobuco 7 hours agoparentprev [–] I don't know about Tracy, but I've seen a couple WebGPU JS debugging tools simply intercepting calls to the various WebGPU functions like writeBuffer, draw, etc, by modifying the prototypes of Device, Queue and so on[0]. - 0: https://github.com/brendan-duncan/webgpu_inspector/blob/main... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Tracy Profiler is a high-resolution, real-time profiler designed for games and other applications, supporting both CPU and GPU profiling across multiple languages and graphics APIs.",
      "It offers extensive features, including memory allocation tracking, lock profiling, context switch monitoring, and automatic screenshot attribution to frames.",
      "The tool's capabilities and updates are showcased in various releases and presentations, including CppCon 2023, with comprehensive documentation and Windows x64 binaries available."
    ],
    "commentSummary": [
      "Tracy is a free, real-time frame profiler with nanosecond resolution available on GitHub, praised for its extensive features and performance.",
      "Unlike automatic sampling profilers, Tracy requires adding macros to the codebase, with each macro introducing about 50 nanoseconds of overhead.",
      "Users appreciate Tracy's detailed stats window and often combine it with other profilers for comprehensive analysis, despite some setup difficulties and challenges with GPU applications."
    ],
    "points": 152,
    "commentCount": 26,
    "retryCount": 0,
    "time": 1727146667
  },
  {
    "id": 41636038,
    "title": "Halide rejected from App Store because it doesn't explain why it takes photos",
    "originLink": "https://9to5mac.com/2024/09/24/halide-rejected-from-the-app-store-because-it-doesnt-explain-why-the-camera-takes-photos/",
    "originBody": "iPhone Diary: Differences in iPhone 16 macro photos may be more software than hardware Ben Lovejoy Sep 24 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41636038",
    "commentBody": "Halide rejected from App Store because it doesn't explain why it takes photos (9to5mac.com)133 points by impish9208 6 hours agohidepastfavorite160 comments alias_neo 5 hours agoJust to add some balance to the conversation; this silliness isn't limited to Apple; we've had Play Store reject our app several times for doing something it literally doesn't do; they required us to add a data-protection policy to explain why we did it, and wouldn't accept that it (our app) literally doesn't (the app connects to a self-hosted server the user runs themselves, so it can easily be checked). In the end, we gave up and just added the DPP text anyway and it got approved. Edit to add: This was for an update, over half a decade after release, not the initial release, and nothing had changed in how it functioned in this regard in that time. Edit 2: Typo + clarification reply isodev 5 hours agoparentIn this case, they were correct to request that you add data protection policy. Your app may still process personal data locally and then you're still subject to data protection regulations. reply pjc50 4 hours agorootparentYou're going to have to cite a data protection authority case for me to believe that. Edit: no, the more I think about it the more this interpretation is completely nuts. It implies that every single software vendor needs to secure consent from every single end user of software they ship through any client. e.g. if SAP provide CRM software to Contoso, and Jim is a customer of Contoso, even though all the data is processed on Contoso premises, SAP still need to be in communication with Jim? reply isodev 4 hours agorootparentWell, certainly don't rely on forums to get your legal info. Feel free to consult someone versed with data protection regulations in countries where your app is available. reply izacus 5 hours agorootparentprevYou misunderstood the post I think. reply Arnt 5 hours agorootparentNo, it's true. On-device actions count in the eyes of the law. \"This app processes the user's data on-device, does not allow other apps to access the data, and optionally copies it to a server that the user provides\" is a description. reply cyanydeez 3 hours agorootparentRighy, isny it easy to understand, esepcially if your app allows http? The data protection policy would explicitly state such a exposure. \"No ezposure\" is a state. Any app that allows a user to put in a endpoint that transfers the user data should have a data policy, since a malactor could convince the user to change thta endpoint, leading to a breach. I think that it seems benign only in theory. reply alias_neo 5 hours agorootparentprevIt doesn't. reply tempfile 5 hours agorootparentprevAre you? If the user processes their own data on their own device using your software, you're the data processor? reply District5524 3 hours agorootparentNo. Data processor has a special meaning (at least under GDPR) and requires you to be a separate entity from the data controller (article 4(8) of GDPR). Just because you process data, will not make you a data processor. A software developer is neither a controller, nor a data processor per se, but the question is why the software processes any personal data. If there is no third person on whose behalf you process data, you might still easily be a data controller and all the privacy related obligations primarily rest on this role. Controllership does not depend on sending any data to remote locations/other apps outside the phone etc., but more on whether there is any personal data processed in the app at all and if there is, the reason for that processing. If you're not processing any personal data, you'll not be a controller, but if you do, you'll be unlikely to be able to skip this responsibility altogether. Considering you'll be the only one knowing exactly what your software can and cannot do with what kind of personal data, you'd better at least explain that to the user. Surely, developers of some software (e.g. compilers) will never be data controllers even if the software can compile software to process personal data... But for many frontend software, like apps, there is no such easy way out unless not processing any personal data at all, including usage data, which is also not an easy thing to do. But that doesn't mean you can just skip the obligation towards the store manageer who says you HAVE to provide a privacy policy even if you don't process any personal data. Similarly, processing for \"purely personal or household activity\", even by automated means is outside the scope of GDPR in EU, but that will not save you from the privacy policy obligation towards Apple or whomever. reply cyanydeez 3 hours agorootparentIf you have tge user enter a arbitrary endpoint, you are explicitly shipping user data off tge device and a foreign actor could use your app to maliciously MITM that arbitrary endpoint. It doesnt mattet if you good faith assume he user of your app is smart wnough to keep the app and that endpoint secure, you are providing a meansnto exfiltrate your app data reply dcow 3 hours agorootparentprevWhat’s the 1 sentence version of your point? reply refulgentis 3 hours agorootparentYes, unless someone spells out to you that they're the data controller and taking legal responsibility (think Google Analytics) I know that's the opposite of what they led with, I'm not trying to be cheeky. It's just shorter if you invert the premise and avoid technicalities. In general, on HN, I see people struggling to wrap their mind around that everyone who takes in data has to take it seriously, at least, that's how the app stores view it. reply isodev 5 hours agorootparentprevAs the app developer you clearly control the means of processing, you are the data controller. You may have opted for “offline processing” which simplifies your compliance, but it is still processing under your control (and subject to change in future updates, which needs to come with a change to your data processing policy with informed user consent). reply tempfile 2 hours agorootparentIt is certainly not processing under your control. You don't do anything with the data - none of your computers are involved, you never see or read or copy anyone's data whatsoever. The data subject is processing their own data, using a tool they perhaps don't understand (if the source code is unavailable, for example). The user is at liberty to start or stop the processing at any time. I don't even think this would apply in the pathological case where a bug in the app causes the personal data to be leaked. You didn't leak it, the user did. reply mordae 4 hours agorootparentprevUh-huh. Are we getting privacy policy for sed and grep next? EDIT: meant to reply lower. reply refulgentis 5 hours agorootparentprevCorrect. They are using my software to process their input. reply htek 4 hours agoparentprevYou would think for a 30% cut of all your [insert eStore name]-related business, it would include at least basic developer support explaining their decisions. reply kyleee 3 hours agorootparentProduct opportunity: Apple Store platinum plan for just 60% of your revenue. State of the art AI account managers will be happy to answer all of your questions. reply echelon 4 hours agoparentprevGoogle and Apple should not control what happens on mobile. They're too big and they've monopolized computing as a platform. Why do these companies get to say what you do with your camera, how you order food, or who you date? Their App Store dictatorship lets them control all of this. The DOJ needs to mandate web installs for both platforms. Sandboxing, permissions dialogues, behavioural heuristics, and signature detection are all we need to keep us safe. The App Store concept is just a grift to earn Apple and Google margin on all transactions. reply KeplerBoy 4 hours agorootparentYou know that Google never had that dictatorship on Android? Apple might lose its monopoly, at least if other legislations follow the EU. reply echelon 4 hours agorootparentGoogle (knowingly?) benefits from the current posture of defaults. You can't one click install a web app, nor is it the expected user behavior. The \"might be harmful\" and buried system dialogues mean that 0.001% of users will ever do this. It's completely unviable. In a sense this might be worse behavior. Google gets to skirt regulatory scrutiny, yet functionally enables zero companies and users to leverage this path. reply KeplerBoy 4 hours agorootparentThere are entire product lines of android devices out there which ship with different default stores. Think of Amazon or chinese huawei devices, even samsung ships it's own app store. Google's App Store is not that dominant. reply ewoodrich 3 hours agorootparentAmazon even lets you buy books on the Android Kindle app if installed via the Samsung/Galaxy Store vs the Play Store. reply notavalleyman 4 hours agorootparentprev>Why do these companies get to say what you do with your camera, how you order food, or who you date? Their App Store dictatorship lets them control all of this. Can you share some examples of when this happened to you? reply pjc50 4 hours agorootparentThe app store controls what food ordering and dating apps are allowed to exist. So it's not a \"to this person specifically\" situation, but certain things don't make it to the market. (personally I'm in the middle on this: some quality control is valuable, and probably essential for anything with access to user data or payment services. But the store is also anti-competitive.) reply echelon 4 hours agorootparentMoreover, what if I don't want Google or Apple to know about my {Islamic LGBT app, Chinese Democracy app, etc.} ? Why do they have to know or control me or my audience? reply KPGv2 3 hours agorootparent> Moreover, what if I don't want Google or Apple to know about my {Islamic LGBT app, Chinese Democracy app, etc.} ? I admit that I don't know about Apple's ecosystem, but if you don't want Google to know about your Islamic LGBT app, you don't have to tell them. Android users can download your app off your personally-owned .com and install it to their phone no problem. reply kyleee 2 hours agorootparentI am sure though Google gets metadata and usage data from Google play services and other system software on android that reveals app usage, though reply resource_waste 4 hours agorootparentprevI have been using Fdroid on my devices and am quite happy. All of my apps don't get 'upgraded' with new microtransactions, no SEO spam, and the apps do the job. reply sandofsky 17 minutes agoprevI'm the Halide cofounder who shared the silly rejection that blew up. I'm knee deep in our iPhone 16 update and tired, so I don't feel like engaging the discourse that comes up over and over around the App Store. Instead I'll just paste the follow-up I just posted to Reddit: Hey everyone. Apple followed up with us to confirm this was a reviewer goof. Normally, they don't sweat that description when it's obvious it's a camera app. They're stricter on apps that don't really need camera access. This was human error, there's no need for us to change the description, so we're all good. reply paxys 5 hours agoprevHere to see all the creative justifications for why Apple is correct, and it's actually the app developer's fault for not clearly stating why an app that users explicitly downloaded to take photos takes photos. It's for the users' own protection of course. Even after all these years the reality distortion field is strong as ever. Meanwhile if Google had done this people would already be outside their HQ with pitchforks and calling for the government to break up their evil monopoly. reply consteval 3 hours agoparentI agree Apple is a monopoly and their software grip should be loosened. However, in this particular case, I think Apple is correct. The intended functionality of the App, no matter how obvious it may seem, needs to be documented to users IMO. Yes it's a camera app - yes it takes pictures. However, users should understand WHEN and under what conditions the app takes pictures. Saying \"this app takes photos\" is really not enough. Does it take photos while I sleep? That might sound ridiculous but remember the plethora of apps that take location data when they don't explicitly need it at that moment. reply skhunted 5 hours agoparentprevThis is a strange narrative to me. Google and other companies have done crappy things without people calling for a break up of the company. It’s possible you are in your reality distortion field. An anti-Apple one. I don’t know anything about this particular case but there is a gray area when it comes to what an owner of a platform should/shouldn’t be allowed to do. I hope the EU cracks down hard on both Apple and Google. Both of these platforms have become essential to modern life in many ways and as such a case can be made for strict government oversight of them. reply anankaie 5 hours agorootparentNobody seems to be suggesting it is any better when Google does it; but on Android (if you ignore the efforts that Google has gone to to make the experience be limited) one can at least avoid the AppStore altogether, while still installing and running various things on device. reply JohnMakin 4 hours agorootparentprev> This is a strange narrative to me. Google and other companies have done crappy things without people calling for a break up of the company. Just a minor nitpick/correction here but there are multiple ongoing anti-trust suits that Google is getting killed on that very likely will lead to the breakup of some of its company's products, so that may be where the comment you are replying to is coming from. reply skhunted 3 hours agorootparentI see. Thank you for the clarification. reply poorno 3 hours agorootparentprevIt’s still a lame review of social media commentary and not a novel take A cherry picked measure of some rando who thinks Apple is taking money off the table that would be ours if not for Apple; free the market from this Kraken! More banal free market retail capitalism demands from the IT crowd who would be Tim Cook themselves. When someone here defines novel mathematical axioms, humanity will have reason to be impressed. Iterating inside the same old knowledge bubble and skill set is uninspiring; the demand to create an economic brand and build a flock of sycophants is sad old roleplay reply resource_waste 4 hours agorootparentprevI think Apple rightly gets the most criticism since their marketing is among mind-control levels and they are fine with doing unethical things (Lying in ads, using fake customers to pretend to have popularity, astroturfing/upvote farms to control narratives, making people status insecure) Once you realize how dirty Apple's marketing is, its quite off-putting. I have a similar aversion to Samsung, Nintendo, Disney. Maybe Google does mind control, but I didn't catch them. Apple, Samsung, Nintendo, Disney, these companies have no qualms making you feel pain to get a sale. reply skhunted 3 hours agorootparentThis is news to me regarding the level of shittiness of Apple's marketing. Do you have any sources? If not that is OK. I don't think it's outside the realm of feasibility that this is so. It's not an extraordinary claim. Apple executives have the aura of \"good guys\" but that is merely a public facing facade. reply isodev 5 hours agoparentprevIt's funny because it's true. You can always count on the defenders of the Corp. to show up when needed. reply JohnMakin 5 hours agorootparentI suspect this is in no small part because many people here’s livelihoods are dependent or intertwined with said Corps, whether directly or indirectly. It’s very difficult to separate that innate bias. I don’t agree with the gp comment’s sentiment though, plenty of people here and elsewhere go hard to bat for google, although admittedly lately that’s increasingly difficult to do with a straight face. reply jajko 4 hours agorootparentI've found out even seasoned (but more often junior) devs and other folks have trouble accepting that their job is just another cog in some corporate machine where their added value or morality of job is often sorta grey area, without clarity even on the shade of it. It can be banking, it can be ad business, or any other morally questionable endeavors, its the same story. Don't blame them per se, they don't know better and life would look suddenly pretty bleak with cold hard look in the mirror. Maybe the only clear failure IMHO is to not have something much more important defining who you are to yourself, your self-worth to say. Because then this becomes rather unimportant aspect of your existence and the need for elaborate invention of new convenient truths is much lower. reply JohnMakin 4 hours agorootparent> I've found out even seasoned (but more often junior) devs and other folks have trouble accepting that their job is just another cog in some corporate machine where their added value or morality of job is often sorta grey area, without clarity even on the shade of it. This was/is very difficult for me. I am about a decade into my career and 15 years into when I first started seriously messing around with tech - in those days, ~2010, tech was seen as the future to the planet and that message very much was pitched all around silicon valley and trickled into my coursework. The massive disillusionment I felt right out of school was a really hard hit and caused a bit of depression. I wasn't changing the world, I wasn't even doing anything remotely useful for a company that also wasn't doing anything remotely useful and I think that's been the case for most of my career, outside of the occasional instances where I do consulting (which I find rewarding actually). But such is life, outside of tech as well. I take pride now in my work, not whatever I think I am contributing to society. If my work is doing something ultimately pointless or supporting something that is morally or ethically gray, I take pride in ignoring that (because I have no control over it) and doing it as best as I can and that has helped a lot. Some may judge me harshly for that, but I don't care, it is really one of the only sane ways to cope - rather than conjuring insane justifications for why things are the way they are (which suck). reply resource_waste 4 hours agorootparentprevYou see teens/low income people with a new iphone and its their identity. I had a teacher call me poor for having an Android. I made 4x more money than her in a year, and decided to let her know that. I also let her know that a phone I can get for $30/mo isnt much of a status symbol. Unemployed teens are able to afford it somehow. reply ryandrake 4 hours agorootparentprevI’ve never understood why one would take time out of their lives, go to an online forum, and simp for a trillion dollar corporation or a billionaire. What are they getting out of it? MegaCorp isn’t going to give you a coupon for defending their honor online. Their CEO isn’t going to come to your birthday party. Their PR team isn’t going to send you a nice letter on parchment thanking you. What does one get out of putting finger to keyboard in defense of a megacorp? You see it all the time on HN and it is bizarre. reply cruffle_duffle 4 hours agorootparentBecause sometimes people are being wrong on the internet and given the entire point of this site is discussion, well, what else would you expect. Nobody is simping for anything. Taken at face value, folks just have an opinion that is different than your and they are expressing it on a site designed explicitly to express such things. And that is just fine. Who knows maybe they have a point that you never considered. Why else would you visit the comments here? Just to get a pat on the back that every person on the planet thinks exactly like you do? reply Uehreka 4 hours agoparentprev(looks around) Nope, not seeing anyone defending Apple on this (at least in the top hundred or so comments at time of writing). Even if you can find one, the posts ITT remarking on how common ridiculous Apple defenses are likely outnumber the actual comments defensive of Apple. Y’all may want to adjust your priors. reply petesergeant 4 hours agoparentprev> if Google had done this I’m coming fresh off weeks of app rejections that turned out to be I included the word “review” in the description of my app on the Google Play Store, and best I can tell was an automated rejection based on keyword matching and entirely unhelpful to explanatory text, so let us not pretend Google is running a tighter ship here. reply petesergeant 5 hours agoparentprevHere’s my creative justification: there’s a policy that works for 99% of apps, and in this case requires Halide to fill two sentences of text in to comply with. The alternative would be more mad. reply dghlsakjg 4 hours agorootparentThe alternative is that Apple lets me run code an apps on my phone (hand computer) without gatekeeping it. My laptop computer has that ability built in, and it isn't really \"mad\" reply petesergeant 4 hours agorootparentYou understand that this is an entirely separate argument about an entirely separate issue right? Even if Apple did do that, presumably it wouldn’t change their process for listing things on their curated App Store. reply dghlsakjg 4 hours agorootparentThe fact that Apple's app store is the ONLY place for third party software means that the issue of app store listing policies and the inability to load unapproved software are deeply linked, and effectively the same issue. If Apple allowed me to load software from third parties directly, like I do on my computer, I wouldn't care what the App store policies were, much like I don't care what the MacOS app store policies are. reply rollcat 4 hours agorootparentprevIt's endemic. I should put \"Expert at Writing Compliance Copypasta\" in my CV. reply valval 5 hours agoparentprevWith however many hundreds of thousands (or millions?) of apps in the store, the reason for why is quite obvious. Apple doesn’t need to have AI models that try to figure out what permissions an app would need. Nor do they need to hire people to do that manually. Instead, they can make app developers fulfill whatever criteria they want. It’s their platform after all. reply dmix 4 hours agorootparentThis is just some dumb random app reviewer as the creator of Halide said themselves. It’s like going to the DMV, the type of people who work at those human facing administrative jobs often don’t care about doing their job well, they just blindly check boxes and exploit their small of amount of power to avoid any personal responsibility. You guys are overthinking this reply angst_ridden 4 hours agoprevI once had a very frustrating battle with a new reviewer who told me my utilitarian app did not offer an \"innovative experience\" and wasn't \"interactive\" enough. So I had to add a completely useless feature where a user could partition their database by marking some items as \"favorites\" and have a separate \"favorite\" view. This was then approved, with the assertion that \"it's now the magical kind of experience users expect from the App Store.\" I'm pretty invested in an Apple ecosystem for some very specific software, but that was nearly enough to make me ragequit (unfortunately, the specific software is not something I could develop/imitate under Linux without a huge financial investment). reply andrewmcwatters 4 hours agoparentiOS devices are not professional tools, that’s primarily why. Ignore whatever preconceived notions you have about “pro” devices as well. reply bgidley 5 hours agoprevThe most bizarre App Store rejection I’ve seen was for a TV app which was rejected by Play for ‘Policy Violation’ without much explanation… After several rounds of resubmissions and emails it turned out the problem was some channels on it were in 4:3 (not widescreen). Google required we add a ‘warning’ to the App Store description that it contains 4:3 content! reply astolarz 1 hour agoparentThat's on you for adding NSFW* content to your app. *Not Safe For Widescreen reply cruffle_duffle 4 hours agoparentprevOh shit! Don’t download that app, son! It contains 4:3 content and I can’t be having any letter boxes on my phone. No sir-e Bob! reply djfdat 5 hours agoprevThe Apple Camera app comes preinstalled with no warnings or permission requests notifying me why it's requesting camera access. reply jimmaswell 4 hours agoparentRemember when MS was sued by the DoJ for bundling IE? And they didn't even block Netscape or put onerous requirements on third party software developers? What a different time. reply rs_rs_rs_rs_rs 5 hours agoparentprevCome on, this is a ridiculous point and makes no sense. reply djfdat 34 minutes agorootparentIt's a comment on their monopoly position and how they can make it difficult at any point for a third party to run their business/app. Apple doesn't need to jump through these hurdles, but they can be placed in front of anyone else randomly, disrupting their business and income and at the very least, creating a worse user experience for those apps. The article states that the alert had to be changed from: \"The camera will be used to take photographs\" to \"The camera will be used to take photographs for the app that you just downloaded to take photographs for.\" \"Spotify, why would you like to play audio? Please notify the users that you are using the speakers to play the audio for the app they just downloaded to play audio.\" If they make using third party apps a little more scary, a little more dense, consistently, people will slowly gravitate to Apple's first party apps. You can see a similar pattern for MacOS where more and more restrictions are added to opening apps downloaded from outside the App Store. reply xtracto 4 hours agorootparentprevIt is ridiculous right? Which is why the fact that Apple is rejecting the app is also ridiculous. reply exe34 4 hours agorootparentprevMaybe for Apple - but there's crap running on my lineage phone I've not had the courage to look up. I just generally hope the firewall is working and only the apps I actually want to connect to the internet are able to do so. reply amelius 5 hours agoprev> I don’t know how to explain why a camera app needs camera permissions. Developing for the App Store is about as much fun as filling out tax forms and talking to an IRS agent. reply lorenzsell 5 hours agoparentNo. The IRS tax agent will be way more helpful. reply rty32 5 hours agorootparentAnd I suppose CPA exists to help understand tax laws, and there is always a possibility to sue the government if you don't agree with them on how the law works. Whereas with app store reviews, it's a black box with no option other than trial and error to figure out what to do. reply abtinf 5 hours agoprev> The camera will be used to take photographs. That is a terrible reason to request camera access. It is just restating the access request and it should be rejected. Why will photographs be taken? Because it is a camera/photography application and will only take photographs on explicit user request. reply virtualritz 5 hours agoparentIt were if there wasn't any context. But as you just downloaded a camera app that you want to use to take pictures, that description is actually already beyond what could reasonably be expected. reply abtinf 5 hours agorootparentIt is trivial to come up with plausible justifications the user might reject if the reason were made explicit. E.g “The camera will be used to continuously take photographs and upload them to our AI platform for training, analysis, and aesthetic optimization.” reply ahoka 4 hours agorootparentYes, how would I know how else it might use the camera? reply nipponese 4 hours agorootparentprevDoes the reviewer have that context? In my job capacity, I give status updates about many unrelated projects. If I am not explaining full context in a seemingly simple update or question, I will get my hand slapped. And if I tell my boss to “read” it’s going to go worse. I would have removed the risk of removal by simply prefacing the app is a professional camera app and taking photos is the primary user function. And not just a lesson for here but also in life: One-liners are fun to say, but people generally don’t like being on the receiving end of them. reply soerxpso 1 hour agorootparentIt shouldn't be the developer's burden to ensure that the reviewer is operating above the reading level of a toddler. I am sorry that your boss apparently cannot, but that's not justification for all industries to operate that way. The purpose of a camera app is to take photographs. A user who downloads a camera app probably wants to use it to take photographs. This is something a child can understand. If I have to hold the reviewer's hand and explain what a camera is, I severely question whether that reviewer is qualified to be doing that job. reply nipponese 1 hour agorootparentIn my painful and long experience, that mindset just doesn't work if you're trying to become a more effective communicator and save yourself time in the long run. reply bsagdiyev 4 hours agorootparentprevIf the reviewer simply looked at the app description or opened the app they would have that context. Not hard. Just laziness. reply fragmede 4 hours agorootparentHow much time do you think the lowly non-Apple employee contractors get for reviewing each app? reply nottorp 2 hours agorootparentDoesn't Apple try to justify their 30% revenue cut by saying they offer unparalleled curation services in their app store? This is an example of such an unparalleled curation service. The app makers are just lucky enough to be popular (and even promoted by another arm of Apple) or they'd still be out of the app store. reply yencabulator 3 hours agorootparentprevThat would be a valid reason to criticize Apple. reply virtualritz 3 hours agorootparentprevThe text is not for the reviewer, it's for the user of the app. Imagine the ridiculous level of explanatory humdrum apps would need to conjure if they were to explain themselves to uninterested people pressed for time like that reviewer you described? reply TimTheTinker 5 hours agoparentprevAgreed - there are better ways to word the reason to more clearly communicate to all parties involved. \"This is an alternate camera app. To take photographs, it needs access to the camera hardware.\" reply drunkan 5 hours agoparentprevDon’t take the bait this guys clearly trolling reply throwuxiytayq 5 hours agoparentprevWelcome to Halide. This is Halide. Halide needs camera access to take photographs. You can take photos of anything. Anything at all. The only limit is yourself. Anything is possible in Halide. You can do anything with Halide. The infinite is possible in Halide. The unattainable is unknown in Halide. Welcome. reply j-pb 5 hours agorootparentThe internet was a simpler time back then, I bet very few younger devs even know zombo.com reply pchristensen 5 hours agorootparentprevZombo.com? reply tempfile 5 hours agoparentprev> That is a terrible reason to request camera access. Oh come off it. It's used to take photographs because it's a photography application. How much handholding do we need? reply cscurmudgeon 5 hours agoparentprev> Why will photographs be taken? Isn’t that a philosophical question? Do we now need to get philosophical to go through App Store reviews? reply throwaway290 5 hours agoparentprevIt's as good as saying \"contacts access will be used to get information about your contacts\". Photography is literally the only thing camera is good for and it's used for that purpose 100% of the time. They can just write that the reason is that Halide is a photo app and be back on the store with no need for hand wringing. I just wish Apple was as good as this at vetting all apps. There is always some junk on the store. reply rblatz 5 hours agorootparentI use it for lots of things that aren’t photography, scanning QR codes, AR uses like seeing how a piece of furniture will look in my house, identifying stars. reply throwaway290 4 hours agorootparentin every one of those the camera is used for photography though reply addaon 4 hours agorootparentHow is scanning a QR code photography? Photography is \"writing with light\"; the key property is that of making a lasting record of a transient handful of photons. When scanning a QR code, the imaging is incidental, but more importantly no record of the \"light\" is made. If scanning a QR code is photography, so is sitting on the porch reading a book... reply throwaway290 4 hours agorootparentYou can't scan a QR code without photography. But the QR code app won't just write \"oh we need the camera to capture some photons\". reply addaon 4 hours agorootparentBy what definition of photography is this true? Is photometry photography now? Is the barcode reader at my supermarket performing photography? The encoder on my scroll wheel? My solar roof? Cameras can be used for many things other than photography. Many other things than cameras can be used for photography. The two are not synonymous. reply throwaway290 3 hours agorootparentIf it is a camera then all it does is photography. If you call it a camera in your encoder and solar roof then yes sure. You are trying to bend definitions > Cameras can be used for many things other than photography Like plug a hole with it or hammer a nail? reply addaon 3 hours agorootparentLike photometry, and spectroscopy, and videography, and camera obscura, and a hundred other things. A camera is a tool for redirecting photons to create an image of a scene on a 2D plane. So many more things than just creating durable images by recording the spatial distribution of light on a plane (photography) are possible with such a tool. reply leetrout 5 hours agoprevReally needs to be regulated with some kind of oversight for this kind of silliness, and even better, needs a way for users to sideload when they choose to accept the risk and let devs sell direct. I side with Epic on that one. reply Zambyte 5 hours agoparentI don't even like the term \"sideload\" honestly. It implies that Apple reasonably has any say over the software installed on a computer they don't own, and by \"sideloading\" you are circumventing that. They have no meaningful say. Exercising power over a computer they don't own is simply malware, and would be illegal if it were not for the associated branding. People should be able to control computers they own. Simple as that. reply dcow 5 hours agorootparentExcept that there’s no way for you to boot the machine on anything other than Apple’s approved firmware. You don’t have the keys, you don’t have ownership. (Not commenting on whether I agree or not, just the facts.) reply welferkj 5 hours agorootparentprevnext [5 more] [flagged] dghlsakjg 4 hours agorootparentI love Apple products, and use their phones and computers. I absolutely agree that my phone should be allowed to run whatever code I want without their having approved it. Is the argument now better for having come from a different person, or am I misremembering what an ad hominem attack is? reply welferkj 1 hour agorootparentWhat argument? Ok, let's say it \"should\". Now what? Do you agree with state coercion forcing Apple to misdesign its products? If so, that's where you've lost me. reply ensignavenger 4 hours agorootparentprevIf I could install whatever app I wanted on an iPhone, I would definitely try one out and very likely switch to using it over Android. I actually did have an iPod Touch back in the early days of iOS, but it did not play well with my non-mac desktop, so I sold it and haven't owned an Apple device since then. But I am totally willing to give them another chance. But to answer your question- because free markets require regulation to keep them free. If Google and Apple are allowed to have an unregulated duopoly, they will abuse that position to force out competitors and prevent new ones from entering the market. reply exe34 4 hours agorootparentprevI own a Mac Book Air from mid-2012. I run nixos on it. It does what I tell it to. When it dies, I will have to figure out if I will have the same control on the next one I buy - if not, I won't buy it. It's not a theoretical argument. reply imgabe 5 hours agoparentprevSideloading would be better. Adding regulation just means another layer of even more clueless bureaucrat you have to appease. reply isodev 5 hours agoparentprevYes, and the process made public and transparent, especially for gatekeepers. This kind of mistakes happen both ways - legitimate apps have a hard time publishing updates and malicious apps get through and are made available to users. reply cruffle_duffle 4 hours agoparentprevIf anything, government regulation would make the App Store submission process even more onerous. Instead of new hire apple/google contractors you’ll be getting cranky government staff who probably have less agency than the former contractors ever had. Be careful what you wish for. reply abtinf 5 hours agoparentprevBecause regulations have never resulted in bureaucratic silliness? Oh, wait… reply userbinator 5 hours agoprevI guess the reviewer might not be familiar with the name, but after seeing what the app is for, it should be obvious. Unfortunately it seems the reviewer didn't have the competence to reach the second part. reply pasc1878 5 hours agoparentCorrectly - read the documentation first before even loading the app. If the docs don't say why then you do not go to the second stage. reply mikestew 4 hours agoprevIf it were just some random app, even something obvious like a camera app, I could be a little forgiving. Maybe the reviewer hadn’t heard of it. Maybe it wasn’t immediately obvious that it was a camera app. But the app was featured in the Glowtime event just weeks ago. The app has won an Apple Design Award. It has been in the App Store for, what, seven years? Of all the apps to reject, the reviewer sure made a poor choice. reply darajava 2 hours agoprevMy app was rejected for about 1 week because some home screen widgets I have advertised don’t show up on their simulator. This is a known bug with the iOS simulator and the widgets show up after killing the app and opening it again. I explained this and they ignored it and continued rejecting it. After I pushed a new build which targeted ios 18 (and did not fix the issue they were claiming was there), they accepted it within minutes. reply lawgimenez 5 hours agoprevApp Store reviewers need to get their acts together. Last week our app was rejected for submitting it for iOS 18, then they accepted it right away after realizing their mistake. Very weird. reply epistasis 5 hours agoprevApple previously published extensive Human Interface Design guidelines that were too-notch. For a generation of computing they really raised the bar on usability and improved experience. (Recently all of computer usability has gone far downhill, IMHO, especially starting with all the flat interfaces, and the penchant for mystery meat icons everywhere, but I digress from my main point...) If Apple is going to have strict usability requirements on the clarity of the permissions requests, that has the potential to be a good thing. But that requires establishing guidelines, and publishing them, and being clear about what in the prompt does not meet the guidelines. reply i_k_k 5 hours agoprevIf Halide were an alarm clock, the explanation would be wholly unconvincing: the rejection only seems silly if you know what Halide is. “This is a camera app”, might be a better explanation. reply Zitrax 5 hours agoparentThat was my first thought as well, \"The camera will be used to take photographs\" seem pointless, if it's a camera app it's obvious if it's not it does not help the reviewer. reply BadHumans 5 hours agoparentprevYou would expect the reviewer to do some research and even maybe, I don't know, use the app? reply dhosek 4 hours agorootparentI’m guessing reviewers have very limited time for each review. I don’t know what the internal process looks like, but I’m guessing an automatically generated screen listing the app’s permission requests, the justifications for each and other stuff? I would be surprised if there would be time for them to actually use any of the apps that they review or if they even have a phone to try apps on. reply exe34 4 hours agorootparentIt sounds like they are looking for plausible excuses, not necessarily what's going on or using common-sense. This seems ripe for LLM automation. reply mbrumlow 4 hours agoprevWe have a real problem with app stores. The thing is. I like apps needing to display and even better request permissions for resources like the camera, files and clipboard. But that should be the limit. What I don’t want is somebody, anybody other than my self deciding if an application actually needs those permission. WE need an alternative to walled garden app stores. It can be fine that a curated store exist that does these things. But they need to live side by side with stores or catalogs that do less and more. It’s an uphill battle because Apple and Google both know that it will be a loss of revenue for them. What is silly though is they could make the App Store have sub app stores curated by different entities (or not at all) and solve all this and keep revenue. But they won’t. reply blargey 5 hours agoprevWhy does this app use the camera to take photos? \"The camera will be used to take photographs\" Given how that reads, I'd think listing any single specific reason a user would want to take photos with this app instead of the default camera app would have worked fine. reply saagarjha 5 hours agoparentThat’s the job of the marketing copy, not a privacy alert. reply benmmurphy 3 hours agoprevThey were probably looking for something like: 'The app needs camera permissions so _you_ can take photographs'. 'The camera will be used to take photographs' is not clear that the app might be taking extra photographs that you did not intend. reply Wheaties466 4 hours agoprevPersonally, I don't even think this is sillyness. yes it should be strict to release apps and you should be accountable and have to explain why you need access to specific permissions on the app stores. The age of open permissions is should be long over. I'm sick over overreaching app permissions wasting my battery trying to collect more data on me. If you want more data, provide more value. reply mablopoule 4 hours agoparentBut it's a camera app. Of course it needs the camera. It's not overreaching app permission, it's been rejected because the text \"The camera will be used to take photographs\" wasn't considered a good enough explanation for the permission. reply compsciphd 4 hours agorootparenthow hard is it to say \"This is a camera app. Therefore it needs camera permissions in order to take photographs\". reply mablopoule 4 hours agorootparentWhile I believe that the app store reviewer was being dense on purpose, I agree that this is a better prompt. reply Wheaties466 4 hours agorootparentprevIf you cant sufficiently explain why your app needs the permissions it does thats on you and the submitter needs to take accountability here. Resubmit with a better explanation. I get that the app store is strict. But its strict for a reason. Apple or the app store isn't out to get your app or you. reply AndroTux 4 hours agorootparentAll right, mister smarty pants. Let's hear it then: What is a better explanation than \"this app need camera permissions, because it takes photos, because it is a fucking camera app\"? reply Wheaties466 4 hours agorootparentHalide is a professional-grade camera application that offers advanced photography features such as manual controls, RAW and ProRAW capture, live histograms, focus peaking, depth capture, macro photography, augmented reality overlays, adaptive gesture controls, exposure tools like zebra stripes, and advanced video recording options. In order to provide these functionalities, these require camera permissions to access and control the device's camera hardware in real-time. Each feature relies on direct interaction with the camera to adjust settings, analyze live image data, and offer immediate feedback, making camera access essential for the app to function as intended and enhance the overall user experience. moral of the story. spend 3 extra minutes writing something out and save yourself from a headache. why are we assuming every person that reviews apps knows what ur app does? with submissions like this the explain it like im 5 approach is necessary. reply quesera 4 hours agorootparentI agree that permission requests should include sufficient context -- but I think that paragraph is way too long for the purpose. People do not read unexpected dialog text. I'd save that for the App Store description, when people are more receptive to detail. For the permission request, I'd condense your paragraph into a sentence or two. It's not unusual to download an app, but not launch it immediately. Demanding that the user remember your App Store description is unfair. It's your baby, not theirs. They might not launch your app for hours or days after downloading. And Apple, reasonably I think, wants developers to try harder to accommodate user's realities. reply mablopoule 4 hours agorootparentprevThere's strict, and there's kafkaian. It's not as if the reason why a camera app would require the camera is pretty obscure, especially if neither the app nor the permission text changed that much between reviews. reply burnte 4 hours agoparentprevOk, but this is the worst example of permission overreach, as it's an app to take photos, obviously it needs access to the camera. reply xtracto 4 hours agoparentprevI disagree. The permission should be allowed/denied by the end user. There's no reason why a third party has to have say in that. reply mablopoule 4 hours agorootparentAs far as I understand it, the permission is allowed/denied by the end user. It's the App Store reviewer that considered the permission prompt to be unclear, and thus rejected the app from the platform. reply happytoexplain 5 hours agoprevApple's process is correct here, in my opinion. They (rightfully) require that an app declare why it needs access to resources/data, and they verify (rightfully) that it is meaningful and does not use circular logic (\"The camera will be used to take photographs\"). Remember, this is not only for users, it is also for reviewers - to keep out apps that unnecessarily access things (that many users don't have the energy to think about, and will just tap \"allow\" in the permissions spam they will come to expect from every app if this policy was not enforced). Given the enormous volume of app submissions and the large number of points each app must be reviewed on, it might be unrealistic to require that reviewers always use the full context of the app when reviewing each individual component - the person reviewing the message might not even know what the app is! And they shouldn't have to! The message should be self-explanatory. The app needs access to the camera because it is a photography app, not because it takes photos. I applaud Apple's thoroughness on this topic. It's much better than the opposite problem, which is what plagues virtually 100% of other software platforms historically, and I'm disheartened for software as a whole that some people (especially HN users, who should be more thoughtful) can't see beyond the petty \"it must be mindless Apple defenders\" catch-all, or the \"rejection reasons are sometimes non-specific\" problem, (the latter of which I am assuming on good faith is a real problem, though I've never personally encountered it). reply YawningAngel 3 hours agoparentI think for 30% of my revenue I'd expect reviewers to find the time to use the full context of the app. That may not be realistic for every app on the app store, but it is reasonable for apps with tens of thousands of reviews and hundreds of thousands (at least) in revenue. reply wibbily 5 hours agoparentprevMaybe if they were consistent... they had an update rejected, which implies that they've passed review before. Doesn't sound \"thorough\" to me. Plus, reviewers must be able to see the App Store page, right? Halide's has \"camera app\" and \"photography\" in the first paragraph of the description. (It literally has \"camera\" in the title. The icon is an aperture.) I mean hell that's the root of the problem. It doesn't matter what context you provide or how obvious you make things, you're feeding your app to a black box that gives results seemingly at random. I haven't met a developer that hasn't failed review for arbitrary reasons, including me. Either give me clear guidelines and procedures to follow - and then follow them - or don't lock me out of doing my job. reply happytoexplain 4 hours agorootparentFirst, to preface: Believe it or not, I am far from an Apple fanboy. I have never owned an iPhone, Apple Watch, Mac, or MacBook for personal use. I have owned one iPad, which I bought a few years ago. I also like the AirPods. I like (and dislike) a lot of things about Apple's DX, and I dislike (and like) a lot of things about their UX. That said, I agree, lack of consistency is frustrating. But there is a big caveat to that opinion. When I experience inconsistent rejection, it has always been due to things that are reasonable to not catch as a reviewer 100% of the time. But personally, I would rather they catch 75% of instances of a problem than give up and let them all through because the inconsistency is frustrating. Of course, I would really like them to get that number to 100%, but I acknowledge that a lot of this stuff is not easily captured at a 100% rate using a tester script, or automatic processing. The key here is of course that you agree with or understand the rule they are enforcing. This is probably where most of the disagreement actually lies, and not so much in the inconsistency. I happen to be the kind of \"purist\" who would rather things be stricter for developers. I want the UX to be as good as possible, and I want the APIs to continue to improve and to not burden/complicate the platform with a lot of backwards compatibility. This is the opposite of a lot of developers, and I totally understand the other side of that argument. This is not to say that Apple review is not shitty sometimes. I just happen to think that the one or two biggest things developers complain about seem to not be as clear-cut as developers describe. reply tempfile 5 hours agoparentprev> the person reviewing the message might not even know what the app is! Sorry, you have gone too far here. If the reviewer doesn't know what the app is, they aren't reviewing the app at all. Knowing that a photography app takes photographs is the absolute bare minimum of context that is required to even begin to meaningfully review it. reply happytoexplain 5 hours agorootparentYou're right, they're not reviewing the app, they're reviewing the rationale for access! Separation was the point of my suggestion. It is probably not even true in the first place - it was only a conjecture. But if they did do that, it would have ups and downs. I could see a rationale that intentionally separating certain review duties from the context of the app could actually help to enforce objectivity. I tend to agree that it would probably be more bad than good, though. reply quesera 4 hours agorootparentI'm totally on board with the idea that permission requests should include complete context, separated from any product description written in the App Store. For example, there's the case where you download an app today, and don't get around to trying it for hours or days or longer. Curt \"duh-style\" permissions requests are user-hostile. Apple insists that developers \"try harder\". In almost all cases, this is the right choice for the user. Sometimes it's hilariously wrong, of course! There are humans in the review loop, and I've been on the wrong side of some epic ridiculousness. But on the whole, they're usually more frequently right than wrong. I'll take it. reply saagarjha 5 hours agoparentprevnext [2 more] [flagged] happytoexplain 5 hours agorootparentAfter two decades, this is the only place left I engage with on the internet. Please, please don't do this. reply mensetmanusman 5 hours agoprevPublic lashings for overzealous reviewers. reply whywhywhywhy 4 hours agoprevHard to have sympathy for anyone choosing this path at this point, over a decade of stories like this and the “quality” of what Apple does let through tells you everything you need to know about their opinion and respect of software. reply dependsontheq 5 hours agoprevEven ChatGPT can give me better worded version in 5 seconds “Halide needs access to your camera to capture photos and videos with advanced controls for pro-level photography.” For user facing text I tend to always try a LLM version, just because the results are so middle of the road, which is exactly what I want in a case like this. reply throwuxiytayq 5 hours agoparentThat's not very readable and way too many words. Reads like a marketing copy. The purpose of the sentence isn't apparent; a person who struggles with English could be confused what advanced controls or pro photography even have to do with camera permissions. The reality of the situation is that the camera app needs camera permissions because it's a camera app. It's for taking photos, you know. reply sib 5 hours agoparentprevBut that's not really precise. Halide needs access to the camera to take any pictures at all, whether there are advanced controls or not, and for crappy or pro-level photography. In other words, \"camera app needs access to the camera.\" reply onemoresoop 4 hours agoprevThis rejection seems like a bureaucratization of the app store, which doesn't help with fraudulent applications, clones and other shenanigans. They should address the latter. Whoever is in charge of this process is utterly incompetent. reply helsinkiandrew 5 hours agoprev> The camera will be used to take photographs Isn't providing functionality provided by existing iOS apps still a reason for rejection? The description should at least say \"for taking photos with advanced customisation suitable for professionals\" reply pulvinar 5 hours agoprevThe problem stems from the name \"Halide\". It's not clear that it's a camera app. Unlike \"Apple\", which clearly indicates... reply nottorp 5 hours agoprevThis is the first product of Apple Intelligence(tm)! reply michaelteter 5 hours agoprev“AI” or outsourced low budget review staff. reply spacecadet 5 hours agoprevIve worked as a mobile app dev consultant since before the iPhone and have submitted nearly a 100 apps over the years. I always warn clients that when submitting an app you are at the mercy of the reviewer and their knowledge of Apple HCI guidelines, which is a lengthy tome of a document... I have had all manor of rejections for weird reasons, but have also had rejections where I just resubmit with no change or justification and get approved. I have also never had to specifically justify camera use and trust me, I have clients build some stupid ass apps that use the camera. This was random and probably the result of poor internal communication. reply andrewmcwatters 4 hours agoprevAnother story for me to add to https://github.com/andrewmcwattersandco/app-store-rejections ! Please submit others if you have any. reply sub7 5 hours agoprev [–] Why the f do any companies get to decide what code I can or cannot run on my device? I didn't rent the device from anyone, I bought it. Does anyone really think giving 20-30% of ecosystem revenue to some gatekeeper makes better ecosystems? We need new open computing laws. reply epistasis 5 hours agoparent [–] For the average user, ensuring that unwanted code does not run is the biggest possible feature for any device. If you don't want that feature, don't buy the device! Or jailbreak it. Or compile your own code and load it. It is not the 20%-30% of revenue that makes a better ecosystem, it's the vetting process for the software that makes it better. Every vetting process has errors, just as all software has bugs. The end goals of the process and the error rate of the process, and correction procedures of the process, are what makes a better software ecosystem. reply temp2033 4 hours agorootparentWhy should i compile or jailbreak. Its my own device, why not have a toggle to allow sideloading like android. Your average user won't know or even bother to change since as you mentioned they don't want to run unwanted code. Rest of us can run anything on our devices. reply epistasis 2 hours agorootparentEasy solution: don't buy into the ecosystem if you don't want the primary feature of the ecosystem. For example, I'm not going to buy Sonos speakers ever. It doesn't mean they should be outlawed for their practices. reply sub7 4 hours agorootparentprev [–] A much more robust and free market approach to this would be a great review system and an actually open app store - this vetting process you describe is not at all \"better\" it incentivizes platforms to 1) kill competition (or any company who refuses to sell out to them during BD negotiations) and 2) encourage/turn a blind eye to the 1000s of currently available scam apps that try to lock people into subscriptions that cannot get cancelled etc. Examples of both 1) and 2) are plenty, so I guess I just disagree that this vetting process helps anyone but the incumbent gatekeeper-taxers. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The iPhone 16's macro photography improvements might be attributed more to software enhancements rather than hardware changes.",
      "This suggests that Apple is focusing on software algorithms to enhance photo quality, potentially offering better macro shots without needing significant hardware upgrades.",
      "The emphasis on software could mean that existing iPhone models might also benefit from similar improvements through software updates."
    ],
    "commentSummary": [
      "Halide, a popular camera app, was rejected from the App Store for not explaining why it takes photos, highlighting a common issue developers face with app store reviews.",
      "Developers have experienced similar frustrations with the Play Store, including rejections for non-existent issues and the need to add data-protection policies to gain approval.",
      "The situation underscores the complexities and inconsistencies in app store review processes, prompting calls for clearer guidelines and more transparent policies, despite arguments that strict reviews are necessary for user protection."
    ],
    "points": 132,
    "commentCount": 159,
    "retryCount": 0,
    "time": 1727182950
  },
  {
    "id": 41629923,
    "title": "Inside a Ferroelectric RAM Chip",
    "originLink": "http://www.righto.com/2024/09/ramtron-ferroelectric-fram-die.html",
    "originBody": "Ken Shirriff's blog Computer history, restoring vintage computers, IC reverse engineering, and whatever Inside a ferroelectric RAM chip Ferroelectric memory (FRAM) is an interesting storage technique that stores bits in a special \"ferroelectric\" material. Ferroelectric memory is nonvolatile like flash memory, able to hold its data for decades. But, unlike flash, ferroelectric memory can write data rapidly. Moreover, FRAM is much more durable than flash and can be be written trillions of times. With these advantages, you might wonder why FRAM isn't more popular. The problem is that FRAM is much more expensive than flash, so it is only used in niche applications. Die of the Ramtron FM24C64 FRAM chip. (Click this image (or any other) for a larger version.) This post takes a look inside an FRAM chip from 1999, designed by a company called Ramtron. The die photo above shows this 64-kilobit chip under a microscope; the four large dark stripes are the memory cells, containing tiny cubes of ferroelectric material. The horizontal greenish bands are the drivers to select a column of memory, while the vertical greenish band at the right holds the sense amplifiers that amplify the tiny signals from the memory cells. The eight whitish squares around the border of the die are the bond pads, which are connected to the chip's eight pins.1 The logic circuitry at the left and right of the die implements the serial (I2C) interface for communication with the chip.2 The history of ferroelectric memory dates back to the early 1950s.3 Many companies worked on FRAM from the 1950s to the 1970s, including Bell Labs, IBM, RCA, and Ford. The 1955 photo below shows a 256-bit ferroelectric memory built by Bell Labs. Unfortunately, ferroelectric memory had many problems,4 limiting it to specialized applications, and development was mostly abandoned by the 1970s. A 256-bit ferroelectric memory made by Bell Labs. Photo from Scientific American, June, 1955. Ferroelectric memory had a second chance, though. A major proponent of ferroelectric memory was George Rohrer, who started working on ferroelectric memory in 1968. He formed a memory company, Technovation, which was unsuccessful, and then cofounded Ramtron in 1984.5 Ramtron produced a tiny 256-bit memory chip in 1988, followed by much larger memories in the 1990s. How FRAM works Ferroelectric memory uses a special material with the property of ferroelectricity. In a normal capacitor, applying an electric field causes the positive and negative charges to separate in the dielectric material, making it polarized. However, ferroelectric materials are special because they will retain this polarization even when the electric field is removed. By polarizing a ferroelectric material positively or negatively, a bit of data can be stored. (The name \"ferroelectric\" is in analogy to \"ferromagnetic\", even though ferroelectric materials are not ferrous.) This FRAM chip uses a ferroelectric material called lead zirconate titanate or PZT, containing lead, zirconium, titanium, and oxygen. The diagram below shows how an applied electric field causes the titanium or zirconium atom to physically move inside the crystal lattice, causing the ferroelectric effect. (Red atoms are lead, purple are oxygen, and yellow are zirconium or titanium.) Because the atoms physically change position, the polarization is stable for decades; in contrast, the capacitors in a DRAM chip lose their data in milliseconds unless refreshed. FRAM memory will eventually wear out, but it can be written trillions of times, much more than flash or EEPROM memory. The ferroelectric effect in the PZT crystal. From Ramtron Catalog, cleaned up. To store data, FRAM uses ferroelectric capacitors, capacitors with a ferroelectric material as the dielectric between the plates. Applying a voltage to the capacitor will create an electric field, polarizing the ferroelectric material. A positive voltage will store a 1, and a negative voltage will store a 0. Reading a bit from memory is a bit tricky. A positive voltage is applied, forcing the material into the 1 state. If the material was already in the 1 state, minimal current will flow. But if the material was in the 0 state, more current will flow as the capacitor changes state. This allows the 0 and 1 states to be distinguished. Note that reading the bit destroys the stored value. Thus, after a read, the 0 or 1 value must be written back to the capacitor to restore its previous state. (This is very similar to the magnetic core memory that was used in the 1960s.)6 The FRAM chip that I examined uses two capacitors per bit, storing opposite values. This approach makes it easier to distinguish a 1 from a 0: a sense amplifier compares the two tiny signals and generates a 1 or a 0 depending on which is larger. The downside of this approach is that using two capacitors per bit reduces the memory capacity. Later FRAMs increased the density by using one capacitor per bit, along with reference cells for comparison.7 A closer look at the die The diagram below shows the main functional blocks of the chip.8 The memory itself is partitioned into four blocks. The word line decoders select the appropriate column for the address and the drivers generate the pulses on the word and plate lines. The signals from that column go to the sense amplifiers on the right, where the signals are converted to bits and written back to memory. On the left, the precharge circuitry charges the bit lines to a fixed voltage at the start of the memory cycle, while the decoders select the desired byte from the bit lines. The die with the main functional blocks labeled. The diagram below shows a closeup of the memory. I removed the top metal layer and many of the memory cells to reveal the underlying structure. The structure is very three-dimensional compared to regular chips; the gray squares in the image are cubes of PZT, sitting on top of the plate lines. The brown rectangles labeled \"top plate connection\" are also three-dimensional; they are S-shaped brackets with the low end attached to the silicon and the high end contacting the top of the PZT cube. Thus, each PZT cube forms a capacitor with the plate line forming the bottom plate of the capacitor, the bracket forming the top plate connection, and the PZT cube sandwiched in between, providing the ferroelectric dielectric. (Some cubes have been knocked loose in this photo and are sitting at an angle; the cubes form a regular grid in the original chip.) Structure of the memory. The image is focus-stacked for clarity. The physical design of the chip is complicated and quite different from a typical planar integrated circuit. Each capacitor requires a cube of PZT sandwiched between platinum electrodes, with the three-dimensional contact from the top of the capacitor to the silicon. Creating these structures requires numerous steps that aren't used in normal integrated circuit fabrication. (See the footnote9 for details.) Moreover, the metal ions in the PZT material can contaminate the silicon production facility unless great care is taken, such as using a separate facility to apply the ferroelectric layer and all subsequent steps.10 The additional fabrication steps and unusual materials significantly increase the cost of manufacturing FRAM. Each top plate connection has an associated transistor, gated by a vertical word line.11 The transistors are connected to horizontal bit lines, metal lines that were removed for this photo. A memory cell, containing two capacitors, measures about 4.2 µm × 6.5 µm. The PZT cubes are spaced about 2.1 µm apart. The transistor gate length is roughly 700 nm. The 700 nm node was introduced in 1993, while the die contains a 1999 copyright date, so the chip appears to be a few years behind the cutting edge as far as node. The memory is organized as 256 capacitors horizontally by 512 capacitors vertically, for a total of 64 kilobits (since each bit requires two capacitors). The memory is accessed as 8192 bytes. Curiously, the columns are numbered on the die, as shown below. With the metal removed, the numbers are visible counting the columns. The photo below shows the sense amplifiers to the right of the memory, with some large transistors to boost the signal. Each sense amplifier receives two signals from the pair of capacitors holding a bit. The sense amplifier determines which signal is larger, deciding if the bit is a 0 or 1. Because the signals are very small, the sense amplifier must be very sensitive. The amplifier has two cross-connected transistors with each transistor trying to pull the other signal low. The signal that starts off larger will \"win\", creating a solid 0 or 1 signal. This value is rewritten to memory to restore the value, since reading the value erases the cells. In the photo, a few of the ferroelectric capacitors are visible at the far left. Part of the lower metal layer has come loose, causing the randomly strewn brown rectangles. The sense amplifiers. The photo below shows eight of the plate drivers, below the memory cells. This circuit generates the pulse on the selected plate line. The plate lines are the thick white lines at the top of the image; they are platinum so they appear brighter in the photo than the other metal lines. Most of the capacitors are still present on the plate lines, but some capacitors have come loose and are scattered on the rest of the circuitry. Each plate line is connected to a metal line (brown), which connects the plate line to the drive transistors in the middle and bottom of the image. These transistors pull the appropriate plate line high or low as necessary. The columns of small black circles are connections between the metal line and the silicon of the transistor underneath. The plate driver circuitry. Finally, here's the part number and Ramtron logo on the die. Closeup of the logo \"FM24C64A Ramtron\" on the die. Conclusions Ferroelectric RAM is an example of a technology with many advantages that never achieved the hoped-for success. Many companies worked on FRAM from the 1950s to the 1970s but gave up on it. Ramtron tried again and produced products but they were not profitable. Ramtron had hoped that the density and cost of FRAM would be competitive with DRAM, but unfortunately that didn't pan out. Ramtron was acquired by Cypress Semiconductor in 2012 and then Cypress was acquired by Infineon in 2019. Infineon still sells FRAM, but it is a niche product, for instance satellites that need radiation hardness. Currently, FRAM costs roughly $3/megabit, almost three orders of magnitude more expensive than flash memory, which is about $15/gigabit. Nonetheless, FRAM is a fascinating technology and the structures inside the chip are very interesting. For more, follow me on Mastodon as @kenshirriff@oldbytes.space or RSS. (I've given up on Twitter.) Thanks to CuriousMarc for providing the chip, which was used in a digital readout (DRO) for his CNC machine. Notes and references The photo below shows the chip's 8-pin package. The chip is packaged in an 8-pin DIP. \"RIC\" stands for Ramtron International Corporation. ↩ The block diagram shows the structure of the chip, which is significantly different from a standard DRAM chip. The chip has logic to handle the I2C protocol, a serial protocol that uses a clock and a data line. (Note that the address lines A0-A2 are the address of the chip, not the memory address.) The WP (Write Protect) pin, protects one quarter of the chip from being modified. The chip allows an arbitrary number of bytes to be read or written sequentially in one operation. This is implemented by the counter and address latch. Block diagram of the FRAM chip. From the datasheet. ↩ An early description of ferroelectric memory is in the October 1953 Proceedings of the IRE. This issue focused on computers and had an article on computer memory systems by J. P. Eckert of ENIAC fame. In 1953, computer memory systems were primitive: mercury delay lines, electrostatic CRTs (Williams tubes), or rotating drums. The article describes experimental memory technologies including ferroelectric memory, magnetic core memory, neon-capacitor memory, phosphor drums, temperature-sensitive pigments, corona discharge, or electrolytic diodes. Within a couple of years, magnetic core memory became successful, dominating storage until semiconductor memory took over in the 1970s, and most of the other technologies were forgotten. ↩ A 1969 article in Electronics discussed ferroelectric memories. At the time, ferroelectric memories were used for a few specialized applications. However, ferroelectric memories had many issues: slow write speed, high voltages (75 to 150 volts), and expensive logic to decode addresses. The article stated: \"These considerations make the future of ferroelectric memories in computers rather bleak.\" ↩ Interestingly, the \"Ram\" in Ramtron comes from the initials of the cofounders: Rohrer, Araujo, and McMillan. Rohrer originally focused on potassium nitrate as the ferroelectric material, as described in his patent. (I find it surprising that potassium nitrate is ferroelectric since it seems like such a simple, non-exotic chemical.) An extensive history of Ramtron is here. A Popular Science article also provides information. ↩ Like core memory, ferroelectric memory is based on a hysteresis loop. Because of the hysteresis loop, the material has two stable states, storing a 0 or 1. While core memory has a hysteresis loop for magnetization with respect to the magnetic field, ferroelectric memory The difference is that core memory has hysteresis of the magnetization with respect to the applied magnetic field, while ferroelectric memory has hysteresis of the polarization with respect to the applied electric field. ↩ The reference cell approach is described in Ramtron patent 6028783A. The idea is to have a row of reference capacitors, but the reference capacitors are sized to generate a current midway between the 0 current and the 1 current. The reference capacitors provide the second input to the sense amplifiers, allowing the 0 and 1 bits to be distinguished. ↩ Ramtron's 1987 patent describes the approximate structure of the memory. ↩ The diagram below shows the complex process that Ramtron used to create an FRAM chip. (These steps are from a 2003 patent, so they may differ from the steps for the chip I examined.) Ramtron's process flow to create an FRAM die. From Patent 6613586. Abbreviations: BPSG is borophosphosilicate glass. UTEOS is undoped tetraethylorthosilicate, a liquid used to deposit silicon dioxide on the surface. RTA is rapid thermal anneal. PTEOS is phosphorus-doped tetraethylorthosilicate, used to create a phosphorus-doped silicon dioxide layer. CMP is chemical mechanical planarization, polishing the die surface to be flat. TEC is the top electrode contact. ILD is interlevel dielectric, the insulating layer between conducting layers. ↩ See the detailed article Ferroelectric Memories, Science, 1989, by Scott and Araujo (who is the \"A\" in \"Ramtron\"). ↩ Early FRAM memories used an X-Y grid of wires without transistors. Although much simpler, this approach had the problem that current could flow through unwanted capacitors via \"sneak\" paths, causing noise in the signals and potentially corrupting data. High-density integrated circuits, however, made it practical to associate a transistor with each cell in modern FRAM chips. ↩ Email ThisBlogThis!Share to TwitterShare to FacebookShare to Pinterest Labels: chips, electronics, reverse-engineering 9 comments: Anonymous said... Hmm. Ferroelectric memory would be perfect in high-radiation environments, such as nuclear energy or spaceflight. September 23, 2024 at 12:07 PM Anonymous said... My former company had an ARM based reference design that offered a Ramtron FRAM memory module on it for development purposes. Same 8KiB capacity, it was just another device on the I2C bus you could use for data storage that didn't wear out. It was a surface mount part, and I'm not really sure why we included it - other than as an infinite write non volatile memory device. There was also a regular I2C EEPROM on the board. I never expected those FRAM devices to ever fail. September 23, 2024 at 8:45 PM Exophase said... Even in rad hard applications FRAM has been supplanted by MRAM. Or at least it has been for aerospace. September 23, 2024 at 9:09 PM Anonymous said... I've found FRAM chips in photocopiers and other interesting places. I've designed it into several embedded products since it has a practically infinite cycle life and has no need for a flash translation layer or wear leveling. This provides constant access time performance and reduced code complexity. It also allows the system state to be written constantly and handle power loss beautifully. These systems also had NOR flash for large storage, like firmware. I also support using FRAM for low-volume or hobby projects where the engineering effort saved by using a hardcoded memory map outweighs the chip cost. One thing I've never used, but is quite interesting, is the MSP430 TI produced with the internal SRAM replaced with FRAM. This allowed the chip to enter effectively a shutdown state and resume without losing any memory or register contents. September 23, 2024 at 10:26 PM Anonymous said... I implemented a triple micro controllers sharing 2 of 64mX8 (= 64meg x16) parallel Ramtron memory. Nothing else was fast enough, non volatile and I needed very fast (nanosecond) 16 bit real time access. Other static ram needed power, flash was well too slow & dram was a joke. Now Dram is fast enough, but flash is still relatively slow. I suspect massive dram production killed fram because production could never ramp up to the numbers needed to make it viable both in delivery time & cost. What fram is suited for is very fast low power (battery) data gathering. No need to do anything with the raw data it is stored! September 24, 2024 at 1:10 AM Brian of Romsey said... Something has gone wrong in footnote 6. Maybe a pasting error? September 24, 2024 at 2:30 AM Brian of Romsey said... Ramtron make the FM1806 which is a byte-wide 32 KiByte part with a 70 ns access time. Timing, control signals, and pinout make it a viable replacement for regular SRAMs. It can be used for making 8-bit retro systems that can re-write themselves without special software (effectively making the device a mix of RAM and ROM on a byte level without having to have two devices and decoding). September 24, 2024 at 2:36 AM Anonymous said... One FRAM application that many people encountered without knowing it is in the game cartridge of Sonic the Hedgehog 3 for the Sega Megadrive (Sega Genesis in the US). The console itself provided no ability to save the progress of a game, so each cartridge had to implement this itself. I think Sonic 3 was unique in using FRAM (Ramtron FM1208S) -- all other cartridges used either SRAM with a coin cell battery or (later) serial EPROM. With four million copies sold, presumably Sega got a good deal on the chips. September 24, 2024 at 3:59 AM Anonymous said... With a microscope like that you've gotta take a look at Optane PRAM by Intel. September 24, 2024 at 5:07 AM Post a Comment Older Post Home Get new posts by email: Subscribe About the site Contact info and site index Popular Posts The Pentium as a Navajo weaving Cells are very fast and crowded places Inside a ferroelectric RAM chip Inside a vintage aerospace navigation computer of uncertain purpose Inside the guidance system and computer of the Minuteman III nuclear missile Apple iPhone charger teardown: quality in a tiny expensive package Teardown and exploration of Apple's Magsafe connector A Multi-Protocol Infrared Remote Library for the Arduino Search This Blog Labels 386 6502 8008 8085 8086 8087 8088 aerospace alto analog Apollo apple arc arduino arm beaglebone bitcoin c# cadc calculator chips css datapoint dx7 electronics f# fairchild fpga fractals genome globus haskell HP html5 ibm ibm1401 ibm360 intel ipv6 ir java javascript math microcode oscilloscope Pentium photo power supply random reverse-engineering sheevaplug snark space spanish synth teardown theory unicode Z-80 Blog Archive ▼ 2024 (17) ▼ September (2) Inside a ferroelectric RAM chip The Pentium as a Navajo weaving ► August (2) ► July (2) ► June (1) ► May (1) ► April (1) ► March (2) ► February (3) ► January (3) ► 2023 (35) ► December (4) ► November (2) ► October (3) ► September (1) ► August (2) ► July (3) ► May (1) ► April (2) ► March (4) ► February (5) ► January (8) ► 2022 (18) ► November (3) ► August (1) ► July (1) ► June (1) ► May (1) ► April (4) ► March (2) ► February (3) ► January (2) ► 2021 (26) ► December (4) ► November (2) ► September (1) ► August (1) ► July (2) ► June (2) ► May (1) ► April (2) ► March (4) ► February (4) ► January (3) ► 2020 (33) ► December (2) ► November (3) ► October (2) ► September (4) ► August (5) ► July (2) ► June (3) ► May (4) ► April (2) ► March (5) ► January (1) ► 2019 (18) ► November (3) ► October (2) ► September (3) ► August (1) ► July (4) ► April (2) ► February (1) ► January (2) ► 2018 (17) ► December (1) ► September (4) ► August (1) ► June (1) ► May (1) ► April (1) ► March (3) ► February (1) ► January (4) ► 2017 (21) ► December (5) ► November (2) ► October (3) ► August (1) ► July (2) ► June (2) ► April (2) ► March (2) ► February (1) ► January (1) ► 2016 (34) ► December (2) ► October (5) ► September (8) ► August (2) ► July (3) ► June (4) ► May (1) ► April (1) ► March (1) ► February (4) ► January (3) ► 2015 (12) ► December (2) ► November (1) ► October (3) ► August (1) ► May (2) ► March (2) ► February (1) ► 2014 (13) ► December (1) ► October (1) ► September (3) ► May (2) ► March (1) ► February (5) ► 2013 (24) ► November (2) ► September (4) ► August (4) ► July (4) ► June (2) ► April (1) ► March (2) ► February (2) ► January (3) ► 2012 (10) ► December (1) ► November (5) ► October (1) ► May (1) ► March (1) ► February (1) ► 2011 (11) ► December (2) ► July (2) ► May (2) ► April (1) ► March (1) ► February (3) ► 2010 (22) ► December (2) ► November (4) ► October (3) ► August (1) ► June (1) ► May (2) ► April (3) ► March (4) ► January (2) ► 2009 (22) ► December (2) ► November (5) ► September (1) ► August (3) ► July (1) ► June (3) ► April (1) ► March (3) ► February (2) ► January (1) ► 2008 (27) ► July (3) ► June (1) ► May (3) ► April (4) ► March (10) ► February (6)",
    "commentLink": "https://news.ycombinator.com/item?id=41629923",
    "commentBody": "Inside a Ferroelectric RAM Chip (righto.com)132 points by chmaynard 23 hours agohidepastfavorite67 comments jonathrg 22 hours agoTexas Instruments has FRAM in some of their microcontrollers. It's really pleasant to use. You write to it like any other part of RAM, the only difference being that the bytes stay where they are when you lose power. With something flash you need to be more careful with how you use it. reply technothrasher 21 hours agoparentI've been using it in a few projects at work as a replacement for flash backed serial RAM. It drops right in, as it is pin and function compatible with other small SPI and I2C nvram and eeprom chips, and isn't really much more expensive in small capacities. reply beeflet 19 hours agoparentprevWhat is the latency like vs DRAM? reply polpo 19 hours agorootparentIn my experience with parallel FRAM, it’s as fast as SRAM and is a drop in replacement with the same timing. A lot of folks have replaced battery backed SRAM with FRAM on game consoles. reply beeflet 17 hours agorootparentHoly cow thats cool. So It's like an expensive nonvolatile replacement for volatile memory. I wonder if in the future there could be computers with no sense of \"memory vs storage\", that it would all just be a single contiguous \"memory\". Instead of turning off the computer and hibernating, you just turn off the LCD backlight and the IO. reply jasomill 16 hours agorootparentWhile implemented virtually rather than physically, two well-known (and very different) examples of systems that unify memory and secondary storage under a single addressing scheme are Multics (1969) and the IBM System/38 (1978). Note that the present-day IBM i née AS/400 is a direct descendent of the System/38. References: https://en.wikipedia.org/wiki/Single-level_store https://dl.acm.org/doi/pdf/10.1145/363095.363139 http://bitsavers.org/pdf/ibm/system38/G580-0237-1_IBM_System... https://archive.org/details/insideas4000000solt/page/171/mod... reply grishka 16 hours agorootparentprevYou would still need to turn the CPU off though. Or do you suggest replacing the registers and caches and all other volatile memory with this stuff? reply soganess 15 hours agorootparentI'm not sure what the performance/persistence implications of this (FRAM) actually are... But to your point, simply copying the processor state to a known location in FRAM (0xFFFFFFF0) and having the start routine read state from that location seem like a very low overhead solution to the problem. How long would it really take to do something your computer does as part of preemptive multi-tasking? Nanoseconds? Milliseconds? We are talking about $order(hundred) of instructions reply gmueckl 12 hours agorootparentThis may work on something with the complexity of a microcontroller or SoC, but becomes tricky beyond that. Any peripherals, especially removable ones would still need to be rediscovered and reinitialized on boot. Network connections may have died/reset while the system was off. Essentially, this scheme has all the major complications of resuming from sleep/hibernation in practice. reply mananaysiempre 7 hours agorootparentBecause it is, for the most part, suspend to RAM aka S3. reply saati 7 hours agorootparentprevIt would burn out in a few hours. reply Retr0id 6 hours agorootparentWhy? FRAM has extremely high write endurance. reply EGG_CREAM 6 hours agorootparentI did notice from the article that reading is destructive, so every time you read (or at least every time you read a 0), you have to re-write it out. I wonder how much that affects the practical durability. reply kens 2 hours agorootparentYes, since reads destroy the data, each read causes a write. The chip will handle 100 trillion read/writes. So yes, the chip will wear out rapidly if you do a lot of reads. reply Retr0id 2 hours agorootparentBy what process does the chip degrade? reply kens 2 hours agorootparentThere are multiple factors that limit the number of writes that FRAMs can handle: changes in crystal structure as Ti ions replace O, mobile ions collecting at grain boundaries, and something to do with 90º domains. reply nayuki 4 hours agorootparentprevReading destroys the stored value; it doesn't necessarily destroy the physical material. Reading from memory is already destructive in DRAM (capacitor gets discharged), magnetic core memory (need to alter the magnetization state to read out how much energy was needed), and probably other technologies as well. reply jonathrg 6 hours agorootparentprevFor the specific chip I used (MSP430FR2355), you could read and execute code at max 8MHz without wait states. Which means it's reading at most 4MHz since each MSP430 instruction that accesses memory requires at least 2 cycles. So latency is at least 1/4MHz=0.25µs reply kjs3 6 hours agoparentprevYa...the TI MSP430 had (have) it. Nifty 16-bit arch (esp if you like PDP-11s) and FRAM was just as you say a joy to use versus Flash. Very low power as well. reply therein 17 hours agoparentprevI really like their FRAM products too. Ultra low power, high data endurance. They have this NFC FRAM MCU product that can be powered by the reader itself. I want someone to incorporate these into their hardware wallet products. Would also be very cool for high endurance data storage. I understand we are talking about kilobytes of storage but still they have very small packaging anyway, just use them (the SPI bus FRAM products) by the dozens. reply djmips 13 hours agoprevJust musing around the word Ferroelectric, I was expecting perhaps something related to iron in the PZT but it's lead, zirconium, titanium, and oxygen. So I learned that Ferromagnetic simply means \"iron-like magnetic\" and that ferroelectric was coined by analogy to the hysterisis curve of ferromagnets in a magnetic field (MH curve) but in ferroelectric it's an electric field (P-E curve). reply heironimus 15 hours agoprevThese saved me from a redesign 25 years ago. I had an 8051 with 256 bytes of RAM and a serial EEPROM with limited writes. Replacing the EEPROM with a serial FRAM allowed me to increase the effective RAM. I had to do some tweaking and figuring because it was so much slower. Also, FRAMs had limited writes AND reads, but on the order of billions instead of millions. Billions of reads are a lot, but you still had to be careful. reply kens 23 hours agoprevAuthor here if anyone has questions about ferroelectric RAM... reply throwaway81523 21 hours agoparentFRAM seems great and I wonder why it's not used more. TI has some MSP430 processors that include it, but when they went to the MSP432 (ARM architecture), they said something about a process incompatibility. Some ARM or Risc-V processors with FRAM would be great. Any idea what the process issue is? Would you say FRAM is on the decline? Super low powered CMOS ram used to also be a thing, but I haven't seen that in a while either. Added: article mentions flash memory is $15/gbit. I guess that is NOR flash? NAND is way way cheaper, more like $15/terabit. Another question: is it reasonable to say that FRAM automatically implements secure erasure? Like if you overwrite a cell, can you be sure that the old contents are gone? With flash, you have to worry about stuff like sector remapping other the covers. Here's a 4 mbit Adafruit FRAM breakout, out of stock but smaller sizes are available: https://www.adafruit.com/product/4719 TI MSP430FR5969 development board: https://www.ti.com/tool/MSP-EXP430FR5969 That is a fancy MSP430 processor with 64KB of FRAM and 2KB of regular ram. The board is $16. The regular ram is I think a little bit faster than the FRAM and good for \"infinite\" write cycles instead of mere trillions, so I guess you need both. They have a few more of these boards including one with 128KB of FRAM if I remember right. reply kens 21 hours agorootparentThe metal ions from the ferroelectric material can contaminate the silicon production line. I read that they would manufacture the silicon die at one facility (i.e. make the transistors) and then do the rest of the fabrication (the ferroelectric material, top metal, etc.) at another facility to avoid contamination. Maybe that's the process incompatibility that you mentioned. I don't know if FRAM is on a decline or will hold on as a niche product. reply cushychicken 20 hours agorootparentIt’s real popular in the niches that use it. Industrial controls systems really seem to love it. I’ve heard that some real fast control systems like to have it as a recovery method to save state in event of major system hiccups. reply rcxdude 5 hours agorootparentIt's also a pretty good debug tool: you can log a trace into a circular buffer in it more or less continuously, then dunno or the contents after a crash or some other failure. reply throwaway81523 15 hours agorootparentprevHmm, thanks, I'm surprised those MSP430 cpus aren't more expensive if their fabrication is that complicated. So it sounds like the ARM designs (I guess basically hard macros from ARM Ltd.?) aren't compatible with that type of process. I wonder if a RISC-V design starting with downloaded HDL would be easier. I hope it happens: FRAM is really cool in concept and I've had a few application ideas where it would be great. reply myself248 4 hours agorootparentI've been wondering if the MSP430's are a single die with the FRAM and the µC on the same process, or if they're co-packaging a \"standard\" FRAM die made elsewhere. reply throwaway81523 2 hours agorootparentIf the FRAM was a separate die, they could use any CPU they wanted instead of being limited to the MSP430. Added: aha, found the fancier ($20) Launchpad that has 128KB of FRAM and an LCD display: https://www.ti.com/tool/MSP-EXP430FR6989 This thing was apparently released in 2014. Technology continues to march backwards. reply kragen 22 hours agoparentprevminor correction: the central atoms in pzt are not zircon but zirconium. zircon is zirconium silicate, the form in which zirconium is almost always found in nature. there is no silicate in pzt also, the atom that can substitute for zirconium in that central position is not lead but titanium. you do explain this in the following sentence, but first you say 'causes the lead or [zirconium] atom to physically move', which is wrong reply kens 22 hours agorootparentThanks, I've fixed those! reply kragen 22 hours agorootparenthappy to help! reply rwmj 22 hours agoparentprevBubble memory next please! It was the next big thing for storage for a brief period in the late 1980s. reply physicsguy 13 hours agorootparentI did my PhD on a purported successor to this - rather than using magnetic bubbles the idea was to use things called Skyrmions which emerge naturally in some materials as either information carriers or to store data in place. In practice it’s never really been taken up by industry for a few different reasons (density, can’t move the skyrmions in a straight line with a current, difficult to read whether one exists or not in a specific place). reply MBCook 15 hours agorootparentprevOh wow I’d never heard of bubble memory before. That’s crazy. The (in retrospect) strange and complicated things people came up with to store bits before magnetic core got popular and then later silicon wiped the field are so much more interesting than what we’ve got now. I get why silicon won. But it’s just nowhere near as fun as bubble memory, delay lines, or CRTs. reply kragen 8 hours agorootparentbubble memory is years after core, and dram is a great deal more complicated than you are imagining reply dfox 24 minutes agorootparentThere is not that much complexity (circuit-wise) in the DRAM array itself apart from the fact that the sense amplifier is essentially an SRAM cell and not really an “amplifier”. Another layer of ridiculous complexity is how to interface that to the outside world without spending the precious die area of DRAM optimized process for complex interface logic or PHYs, so you get the only high-speed single ended parallel bus with weird voltage levels interface that is used in modern computers. reply MBCook 5 hours agorootparentprevI know. I saw the bubble memory was used in the 70s and maybe even 80s, which is long after the days of core memory being becoming common. And I know DRAM isn’t exactly simple. But it just doesn’t feel as neat to me as pushing bubbles around or using a transducer to put a wave through mercury or other delay line. Or drawing a “picture of memory” for no one on a CRT because that _is_ your memory. If one of those had won and was what everyone was used to, I’m probably think they were old hat and DRAM was crazy and cool. But that’s not how history worked out. reply kens 22 hours agorootparentprevSomeone gave me a board with bubble memory chips to examine, but when I opened up the chip it turned out to be regular DRAM; they were mistaken about the type of memory. reply kjs3 6 hours agorootparentWhich bubble \"chips\" would someone confuse with dram? All the Intel, TI, Hitachi and Russian ones I've ever seen are relatively large, square, thick and decidedly un-DRAM like. I have several working bubble memory boards. You can't take them apart. :-) reply kens 2 hours agorootparentThis was an IBM board so all the chips were in large, square, metal packages. These packages are descendants of the SLT modules used in the System/360. reply kjs3 2 hours agorootparentAh...that makes complete sense. The SLT chips are certainly bubblememory-ish. reply alnwlsn 5 hours agoparentprevWell I guess we know what happened to those failed chips from Curiousmarc's broken DRO. Maybe I missed it, but what actually makes it wear out? And why does it last so much longer than flash/eeprom? reply kens 2 hours agorootparentThere are multiple factors that limit the number of writes that FRAMs can handle: changes in crystal structure as Ti ions replace O, mobile ions collecting at grain boundaries, and something to do with 90º domains. reply johnklos 22 hours agoparentprevI've always wondered if the ROMs on my VAXstation 4000/90a are ferroelectric. The DEC manuals refer to it as flash ROM, but I've also heard / read it referred to as FRAM, although I couldn't say I remember where or when. But 512KB of FRAM at $3 per megabit would make that pricier than the machine! So I wonder what it has in it instead. Interesting! Thanks :) reply kens 21 hours agorootparentIt wouldn't make sense to use FRAM for ROM, since the big feature of FRAM is fast write speed. I found one DEC document that says the Flash ROM on one product is the Intel 28F008SA, an 8Mb flash chip. So I expect the VAXstation uses boring flash too, rather than costly FRAM. Link: https://bitsavers.org/pdf/dec/semiconductor/arm/EC-QU5KA-TE_... reply sroussey 20 hours agorootparentWhat would be good for DRAM read speeds, and not care too much write speeds? I’m thinking of keeping an LLM’s weights in a storage RAM, where it would be updated only every few months. reply namibj 19 hours agorootparentDRAM or SLC NAND. Be careful with read-induced disturbance on the latter, though. reply aidenn0 20 hours agoparentprevAre the parts pin-compatible with parallel sram? I've always thought it would be nice to replace the battery-backed SRAM in old video game cartridges with MRAM or FeRAM reply polpo 19 hours agorootparentI’ve replaced battery backed SRAM in several game consoles and other devices with FRAM (Neo Geo CD, Sega Saturn, an HP oscilloscope) and for some it’s drop-in, and in a few you have to bodge some lines. reply rbanffy 14 hours agorootparentWon’t that negatively impact the life expectancy of the device? FRAM is rated for trillions of reads and, if the SRAM is frequently read, a trillion reads isn’t that much. reply seritools 6 hours agorootparentI guess it depends on whether the game cartridges only use it for storing savegames, or as actual additional RAM. reply formerly_proven 9 hours agorootparentprev>100 trillion reads per location over 30 years still means you gotta read locations at over 100 kHz 24/7. Not good enough for main memory, sufficient even for frequently accessed configuration values. reply kens 19 hours agorootparentprevThe FM1808B and FM1608B might work for you. These are 32Kx8 and 8K×8 FRAM chips with standard SRAM pinouts, in DIP packages. If you don't need a DIP, you have a lot more choices. reply aidenn0 19 hours agorootparentThe SOIC look like they could work as-is in a gameboy, which (thanks to Pokemon) is the most common request for replacing batteries. The DIPs could be made to work in most NES games too, I suspect. reply jaygreco 21 hours agoparentprevI have one! Any idea if the PZT cubes are added using the typical photoresist masking/etching or are they placed on die using some other process? reply kens 21 hours agorootparentFrom looking at various patents, I believe they put down a layer of PZT and then etch it into cubes with photolithography. Look at the process diagram at the bottom of my article, step 1128. reply anonymousDan 22 hours agoparentprevAny thoughts on how it compares to Intel Optane NVM? Also is there any particular material you envision as a potential successor for it? reply Brian_K_White 19 hours agoprevI've been using MRAM instead as soon as I read that the way FRAM works internally is that every read is actually destructive and but written right back after the read. I don't want that in something that's meant to replace a mask rom. reply rpaddock 7 hours agoparentI designed in a Everspin MRAM. Had to take it back out when we learned that the small magnet, to activate a reed switch, near the MRAM would destroy it. It did not just lose a few bits, the device was forever dead. We are talking Refrigerator Magnet level field in close proximity. Great technology as long as no magnetic fields are close to the device. reply Brian_K_White 3 hours agorootparentWow that is a biggie, than you. And they are expensive. I have an external memory card for a vintage portable word processor that the full bom ends up about $100 for 512k to build one, and something like over $30 of that is just the mram. reply kjs3 3 hours agorootparentprevI did not know that. That's a showstopper for...a lot of use cases. Thanks for the warning. reply therein 16 hours agoparentprevI remember there being some document in which TI describes how this is done atomically at a physical level so there is no way that you can end up losing power and having the read-triggered write fail to complete. reply anovikov 5 hours agoprevSo it's like magnetic core memory, miniaturised to fit into a chip? reply kens 2 hours agoparentFRAM is like magnetic core memory in many ways, but the underlying principle is completely different: it is ferroelectric rather than ferromagnetic. And the materials are completely different. reply tonetegeatinst 21 hours agoprev [–] I wonder if I could sketch a single fram using klayout. Hmmmm reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ken Shirriff's blog post explores ferroelectric RAM (FRAM), a nonvolatile memory technology known for its durability and rapid writing capabilities.",
      "Despite its advantages, FRAM's high manufacturing costs and complexity have limited its use to niche applications, with Ramtron's 1999 FRAM chip as a case study.",
      "The blog details the history, structure, and operation of FRAM, noting that while promising, its widespread adoption has been hindered, and Ramtron was eventually acquired by Cypress Semiconductor."
    ],
    "commentSummary": [
      "Texas Instruments has integrated FRAM (Ferroelectric RAM) into some microcontrollers, which retains data without power, unlike flash memory.",
      "FRAM is pin and function compatible with other non-volatile memory types like NVRAM and EEPROM, and is cost-effective in small capacities.",
      "Despite destructive reads requiring rewrites, FRAM's fast write speed and high endurance make it popular in industrial control systems and as a replacement for battery-backed SRAM in devices like game consoles."
    ],
    "points": 132,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1727121963
  },
  {
    "id": 41635962,
    "title": "Giving T cells extra batteries supercharges them against cancer",
    "originLink": "https://newatlas.com/cancer/cancer-immunotherapy-t-cells-extra-batteries-supercharges/",
    "originBody": "Cancer Giving T cells extra batteries supercharges them against cancer By Michael Irving September 20, 2024 Facebook Twitter Flipboard LinkedIn Giving T cells extra batteries supercharges them against cancer Giving immune cells extra \"batteries\" helps them fight cancer more effectively Shiladitya Sengupta, Brigham and Women's Hospital View 1 Images 1/1 Giving immune cells extra \"batteries\" helps them fight cancer more effectively Shiladitya Sengupta, Brigham and Women's Hospital T cells are our first line of defense against cancer, but the battle tends to exhaust them. Now, scientists have found a way to give them extra “batteries” to keep them fighting longer, with promising early results in mice. In a fair fight, the immune system would wipe out cancer every time – but this crafty disease doesn’t play fair. Along with its many tricks to avoid detection, tumors build microenvironments around themselves that are toxic to immune cells, draining them of energy. Sustained immune responses against a pathogen like cancer can lead to T cell exhaustion. Finding ways to supercharge the immune system to continue the fight is the main goal of immunotherapy. Now, a team from Brigham and Women’s Hospital has demonstrated a new way to refresh T cells, by essentially replacing their batteries. Mitochondria are organelles that produce chemical energy for cells, but during T cell exhaustion these little batteries can be lost or damaged. Previous studies have shown that cancer cells can use nanotubes like “tiny tentacles” to slurp up mitochondria from immune cells. For the new study, the researchers found that they could use the same mechanism to do the opposite – donate new mitochondria to T cells, from bone marrow stromal cells (BMSCs). The team cultured BMSCs and T cells together, and after 48 hours found that up to a quarter of the T cells had gained extra mitochondria. The researchers dubbed these juiced up immune cells Mito+. In tests in mice, Mito+ cells were found to more easily penetrate tumors and launch a more robust attack on them. Tumors shrank drastically, and 75% of treated mice survived the full 60-day study period. In contrast, control mice saw their tumors continue to grow, and all had died by the 20-day mark. Intriguingly, Mito+ cells could multiply quickly and pass their extra mitochondria to the new cells. Other immune cells, such as lymphocytes and CAR-Ts, also showed improved cancer-killing abilities after receiving extra mitochondria. “These supercharged T cells overcome one of the fundamental barriers of immunotherapy by penetrating the tumor and overcoming immune barren state in the tumor,” said Shiladitya Sengupta, corresponding author of the study. “Mitochondria provide the fuel. It’s like we’re taking T cells to the fuel station and gassing them up. This transplanting of mitochondria is the dawn of organellar therapy – where an organelle is delivered to a cell to make it more effective.” The team says that in future, BMSCs could be taken from patients and used to supercharge their own immune cells, which are then returned to the body to fight their cancer more effectively. The research was published in the journal Cell. Source: Brigham and Women’s Hospital",
    "commentLink": "https://news.ycombinator.com/item?id=41635962",
    "commentBody": "Giving T cells extra batteries supercharges them against cancer (newatlas.com)130 points by peutetre 6 hours agohidepastfavorite57 comments dopylitty 4 hours ago>Previous studies have shown that cancer cells can use nanotubes like “tiny tentacles” to slurp up mitochondria from immune cells. Biology is nuts. Regarding messing with T-cells I wonder how evolution came up with the current number of mitochondria per cell. Usually with these things there's some kind of push and pull between the benefits of something and the drawbacks. Or sometimes it's just whatever works. I know mitochondria can have some negative impacts on cells sometimes by releasing the byproducts of metabolism (reactive oxygen species) or triggering programmed cell death. reply agumonkey 18 minutes agoparent> Biology is nuts. for this particular case I 100% agree. I grew up to accept a wide range of complexity at the cell level, but this blew through the roof. reply derefr 2 hours agoparentprevDunno about mitochondria as a cell feature specifically. But there exists a similar constraint on the total size of the DNA in the cell nucleus (and therefore the ability of a species to survive polyploid mutations that double-or-more the amount of DNA per cell); and I believe we do (think that we) understand the cause of that one. This polyploidy constraint only exists for animal cells, not for plant cells. Plants can — and frequently do! — get as polyploid as they want; but animals have a ceiling. And that implies that the constraint has something to do with one of the main differences between plant and animal cells: namely, the fact that animal cells — specifically, blood cells — must move and flow along channels composed of other cells; while plant cells are fixed in place by their stiff cellulose membranes, with only fluids and tissues flowing. The problem animal cells have with polyploidy, is seemingly that it makes their cells physically larger — and in so doing, causes biological architectural assumptions like \"blood cells can travel through narrow capillaries to deliver oxygen to cells within extremity tissues\" to just fail to hold. The capillaries, when composed of larger cells, are narrower; and the blood cells flowing through, composed of larger cells, won't fit. (Evolution could in theory resolve this single problem by just scaling all features up in size. But that causes far more problems than it solves: the square-cube law requires huge changes to things like muscles and metabolism to keep up with increased size, if it's even possible; and some organs/tissues just require to be a certain size to function — like the nephrons of the kidneys — such that these instead need to stay the same size, evolving distinct adaptations to handle the increased size of the cells that travel to/through them.) reply rolisz 22 minutes agorootparentFrom listening to Michael Levin, he describes how in newts you can multiply the DNA of kidney cells (or some tubules around there). The cells become larger, so they adapt by forming the same size of tubule with fewer cells. If you keep duplicating the DNA, at some point a single cell is enough to form the tubule, which it does by bending around. reply cyberax 1 hour agorootparentprev> blood cells can travel through narrow capillaries to deliver oxygen to cells within extremity tissues Mammalian red blood cells do not have DNA or mitochondria. They lose them during the maturation process in the bone marrow. But apparently this might just be one of the evolution's blind turns. Birds have even faster metabolism with higher oxygen requirements, and their red blood cells have nucleus. reply Vecr 54 minutes agorootparentI think derefr might be talking about the cells that form the walls of the capillaries being bigger, so you can't really fit them in the places you need them, and if you tried they'd be too narrow. Except replace \"you\" with evolution and delete \"tried\". reply wnevets 3 hours agoparentprev> Regarding messing with T-cells I wonder how evolution came up with the current number of mitochondria per cell. An over active immune is generally a bad thing for the host. Maybe a higher number increases auto immune disease? reply devmor 2 hours agorootparentNot just a bad thing - one of the worst possible things. That's how you get chronic inflammation. reply ceedan 1 hour agoparentprev> Regarding messing with T-cells I wonder how evolution came up with the current number of mitochondria per cell. Cells can increase their number of mitochondria in response to things (mitochondrial biogenesis). I don't know anything about how that works out in the immune system, but have read about it related to fat cells and exercise. This was also my first thought, and it seems like \"giving them extra batteries\" accomplishes the same outcome reply kurthr 4 hours agoparentprevI really appreciate the commentary here on HN. The headline was awful enough, but the quotes, really let me know the level of horror movie aesthetic there is in the commentary supposedly about biology. Thanks, NewAtlas, but it's just not the mixed metaphor I'm looking for. reply ben_w 1 hour agoparentprev> I wonder how evolution came up with the current number of mitochondria per cell One of my probably-wrong ideas that I can't usefully ask* is if chronic fatigue/post-acute infection syndromes may be due to insufficient mitochondria for whatever reason. * if I ask StackExchange, I'll probably phrase it wrong enough to have it closed; if I ask an LLM then it will probably make something up because if the answer exists at all it is probably behind a paywall, and even if it isn't they do that 10-20% of them time anyway. reply golergka 4 hours agoparentprevCould it be just amount of energy available to the organism? Modern humans are in completely unique position relative to all history of life on Earth, having access to as much food (and energy) as we want, and having a widespread problem of eating too much. Evolution didn't have any chance to catch up with this reality. reply alexey-salmin 14 minutes agoprev> Intriguingly, Mito+ cells could multiply quickly and pass their extra mitochondria to the new cells. Is this accurate? I thought T cells can't multiply. reply Laaas 5 hours agoprev> The team cultured BMSCs and T cells together, and after 48 hours found that up to a quarter of the T cells had gained extra mitochondria. The researchers dubbed these juiced up immune cells Mito+. What an incredibly simple idea. Just scale it up. reply gorkish 5 hours agoparentHow many do you have to have before you can start using the Force? reply tomrod 1 hour agorootparentA more direct reference, though maybe obscure these days, is _Parasite_ _Eve_ reply highwaylights 3 hours agorootparentprevLess than you’d think. Not even master Yoda has a mitochondria count that high! reply CoastalCoder 4 hours agorootparentprev\"Whatever the stupid, lazy writers at Disney needed it to be this week.\" - The Critical Drinker* * I imagine reply adamc 4 hours agorootparentTotally a tangent, but he's right about that. It was a flaw in Harry Potter as well. There was no logical system to how magic worked; spells did whatever plot requirements said they did. And it detracts from the sense of realism in a world when the magic just does whatever is needed at the moment. reply 0cf8612b2e1e 1 hour agorootparentAcknowledging it is a children’s book… I take significantly bigger issue with the lack of societal change from having magic. Way too much of wizard society was “Muggles + occasional party tricks”. When you can conjure food, water, automatons, etc from nothing, nature of living would change completely. You can brew luck? I would be mainlining that stuff every day. Time travel is given to children? Why is there a train when there are a dozen different ways of magicking yourself around the world? Harry Potter and the Methods of Rationality touched on these inconsistencies. reply dylan604 2 hours agorootparentprevBut. It's. Magic. Magic can do anything. That's why it's magic. How does it work? Magic. It's a perfectly complete circle in logic. reply adamc 25 minutes agorootparentCompare to, say, \"A Wizard of Earthsea\", where magic is explained in a different way that points out that while a wizard could transmute one substance into another, no wizard would, because of the far-reaching ramifications. The system was not fully elucidated by any means, but the subtlety of it was suggested by such things as Ged deducing that the doorkeeper was one of the seven masters of Roke. reply 0cf8612b2e1e 51 minutes agorootparentprevThe very much NSFW web comic Oglaf had a strip about this. In this rare instance, the comic is SFW, but still be wary. https://www.oglaf.com/claret/ reply Aerroon 1 hour agorootparentprevWell, magic still needs to follow some kind of rules for it to be usable. Otherwise \"magic\" would just be something random (or maybe chaotic - we just haven't figured out the rules well enough). reply mrkstu 1 hour agorootparentprevOr, you can do the Brandon Sanderson thing, and have a comprehensive system that has limits and a consistent expression of magical power. reply dylan604 21 minutes agorootparentbut then it's no longer magic. it now becomes some sort of metaphysical science. magic is magic. once you understand it, it is no longer magic. reply jajko 59 minutes agorootparentprevSounds like most religions. And most modern folks having issues with religions they were brought up in don't have this as their main issue with it. One addresses child's imagination which just wants to be wowed, the other our eternal fear of unknown and death. reply rpmisms 4 hours agorootparentprevThat's probably what he would say. The actual minimum to be able to use the force is a 7000 midichlorian count. reply politician 3 hours agorootparentI thought it was over 9000. reply ImHereToVote 4 hours agorootparentprev\"The midichlorian is the forcehouse of the cell.\" reply phkahler 2 hours agoprevBatteries == Mitochondira So I wondered how one could increase the number of mitochondria and quickly found this nice piece from 2017 about promoting mitochondrial fission in mid-life (ok in fruit flys): https://www.nature.com/articles/s41467-017-00525-4 I'm pretty sure maintaining mitochondrial health will help a lot of health problems. They seem to come up every little while in regard to many different pathologies. reply anigbrowl 42 minutes agoparentCompletely spitballing here, but if bone marrow cells help charge up mitochondria (as this new study suggests), then strong healthy bones are a good defense against cancer. Resistance training (weightlifting being the most common variety) is well known to improve bone health so maybe this is another reason to practice it. reply amelius 7 minutes agorootparentMaybe the reason elephants don't get more cancer despite their comparatively large cell count. reply rKarpinski 2 hours agoparentprev> So I wondered how one could increase the number of mitochondria Lots of Zone-2 training. Inigo San-Milan & George Brooks are the two researchers to look at this for in humans. reply ceedan 2 hours agorootparentTheir research seems to be in relation to muscle and fat - not the immune system and cancer. I wouldn't expect zone 2 training to improve \"T cell exhaustion\" where mitochondria are stolen from T-cells by cancer cells. > Previous studies have shown that cancer cells can use nanotubes like “tiny tentacles” to slurp up mitochondria from immune cells. reply aidenn0 2 hours agoparentprevYeah, batteries was a funny metaphor given that everybody from my generation learned that Mitochondria are the \"powerhouse of the cell\" in Junior High. reply andrewflnr 32 minutes agorootparentFrom the headline, I was almost sure it was going to be about giving T-cells ATP, which is much more commonly (and appropriately) analogized to biological batteries. reply aidenn0 2 hours agoprevIn America, batteries are have cells. In Soviet Russa^W^W Poorly Written Headlines, cells have batteries. reply dazzlevolta 58 minutes agoprevFor what type(s) of cancer does this seem to be promising? reply VyseofArcadia 3 hours agoprevIncredible result, but my god do I hate this kind of headline. reply kthartic 3 hours agoparentWhy? As a laymen (who knows nothing about \"T cells\") the analogy helps reply Zelphyr 5 hours agoprevThis is why good quality nutrition is so important. It's like giving all of our cells--not just T cells--extra batteries. reply tjohns 5 hours agoparentTo be fair, I'd prefer not to give the cancer cells extra batteries. reply Zelphyr 4 hours agorootparentIn truth, it's usually the opposite when our bodies are fueled properly. reply hansvm 4 hours agorootparentI thought I remembered something about certain nutrients (magnesium?) being something you could intentionally reduce to slow down cancer growth -- kind of like a DIY chemotherapy; your cells need Mg to grow and multiply, but cancer cells need it more. Paired with other treatments, where applicable, the reduced nutrient diet had positive clinical outcomes. reply parineum 4 hours agorootparentprevDefine \"quality nutrition\" and cite a source. reply fhieufn 1 hour agorootparent\"Quality nutrition\" is any scientifically backed research results on good health. Here is a resource that uses research to back up its claims: https://www.efsa.europa.eu/en/topics/topic/dietary-reference... And it has a good tool to find and meet those results: https://multimedia.efsa.europa.eu/drvs/index.htm reply bitcoin_anon 1 hour agorootparentprevMy health has been improving by eating according to this book: https://a.co/d/2dHgtQr reply nradov 3 hours agorootparentprevReally? Most clinical trials for nutritional therapy as a cancer treatment haven't produced significant results. reply fhieufn 1 hour agorootparentThis is a surprising position. Can you link to any? Everything I have read on the subject says obesity, a nutritional imbalance, is one of the main contributors to cancer growth, and specifically a reduction in sugar and meat have significant positive results in combating cancer's growth. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9559313/ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9775518/ https://onlinelibrary.wiley.com/doi/epdf/10.1002/0470869976.... reply vaylian 5 hours agoparentprevHow is this related to the number of mitochondria in a cell? reply agumonkey 5 hours agorootparentI believe that the opposite is useful, fasting -> autophagy -> improved mitochondrial health (not sure). Maybe that's what parent tried to say. reply 1oooqooq 5 hours agoparentprevnah. let's base the entire world diet on numbers of calories, provided by crops which are collected annually or biannually so we can have an efficient futures market :thumbsupemoji reply tekla 4 hours agorootparentYep, we prefer to keep people alive first since its hard to care about the health and well being of dead people. reply gl-prod 5 hours agoprevCome on, T cells, you can do it reply ugh123 1 hour agoprevGreat! When can I buy Mitochondria Supplements at the grocery store? /s reply 1970-01-01 5 hours agoprev [–] ..in mice reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Scientists at Brigham and Women’s Hospital have developed a method to enhance T cells, the body's primary defense against cancer, by providing them with additional mitochondria from bone marrow stromal cells (BMSCs).",
      "These enhanced T cells, termed Mito+, showed improved tumor penetration and significantly reduced tumor size in mice, with 75% of treated mice surviving a 60-day study.",
      "This breakthrough, published in the journal Cell, suggests a potential new approach to boost patients' immune cells for more effective cancer treatment."
    ],
    "commentSummary": [
      "Researchers discovered that supplementing T cells with extra mitochondria can improve their cancer-fighting capabilities.",
      "The study raises questions about the evolutionary balance of mitochondria in cells, as an excess can lead to problems like reactive oxygen species or cell death.",
      "These findings could pave the way for new cancer treatments, although the precise mechanisms and broader implications are still under investigation."
    ],
    "points": 127,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1727182295
  }
]
