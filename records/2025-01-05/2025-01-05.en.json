[
  {
    "id": 42599189,
    "title": "Researchers design wearable tech that can sense glucose levels more accurately",
    "originLink": "https://uwaterloo.ca/news/media/no-more-needles-tracking-blood-sugar-your-wrist",
    "originBody": "Skip to main Skip to footer University of Waterloo Admissions About Waterloo Faculties & academics Offices & services Support Waterloo COVID-19 Search Menu This site Home 1974-75 Waterloo Warriors Mens Basketball season AI Workshop Fall 2024 Real Research The Sultans of String musical performance UWaterloo Admissions About Waterloo Faculties & academics Offices & services Support Waterloo COVID-19 Waterloo News Media October 29, 2024 No more needles! Tracking blood sugar on your wrist Waterloo researchers design wearable tech that can sense glucose levels for diabetics more accurately than ever before By Media Relations Engineering Research Health Futures Share Imagine shrinking satellite technology that predicts the weather into a device that transmits vital information about the health of the person wearing it. University of Waterloo engineers have achieved this technological feat to help people faced with chronic health problems such as diabetes monitor their glucose levels. The Waterloo team’s breakthrough addresses the major challenge of creating non-invasive, continuous glucose monitoring, essential for those managing diabetes. Currently, diabetics must frequently prick their fingers or rely on invasive wearable patches with micro-needles to track their blood-sugar levels. But the system designed by Dr. George Shaker, an adjunct associate professor at Waterloo’s Department of Electrical and Computer Engineering, and his colleagues eliminates this need, thereby reducing pain, the risk of infection and improving people’s quality of life. “We’ve developed radar technology that can now fit inside a smart watch and sense glucose levels more accurately than ever before,” Shaker said. “Just like you use glasses to improve your vision, our technology helps for better sensing of glucose levels.” To explain how the new system works, Shaker points to weather satellites that use radar to monitor the Earth’s atmosphere and, for example, measure storm movements and other kinds of cloud cover. “We’ve figured a way to miniaturize these radar systems on satellites and put them in a wearable device and use the same radar technology that looks at changes in the atmosphere to look at changes in the human body,” he said The system’s key components are a radar chip, which sends and receives signals through the body, an engineered “meta-surface”, which helps focus these signals for better accuracy, and microcontrollers, which process the radar signals using artificial intelligence algorithms. The algorithms improve the accuracy and reliability of the readings by learning from the data over time. The unique aspect of this system is the meta-surface which Shaker and his team have developed. It further improves the radar’s resolution and sensitivity, allowing for more accurate glucose readings. “Unlike existing methods that require skin penetration our system is entirely non-invasive and can detect even small changes in glucose level,” Shaker said. “No other technology can provide this level of precision without direct contact with the bloodstream.” More work remains to perfect their system. Although the engineers now power their device with a USB cable, they’re planning to optimize it for battery use to improve portability. Eventually, they hope it can be used to gather other health-related data, such as blood pressure. The team is currently working with industry partners to introduce the technology to be installed in the next generation of wearables. “We have a minimum viable product that’s already being used in clinical trials, and while there’s more work to be done, we’re much closer to a full marketable device,” Shaker said. The research paper, “Radar near-field sensing using metasurface for biomedical applications” was recently featured in Nature’s Communications Engineering. Tags Engineering Research Health Futures Related stories Read more Waterloo researchers awarded more than $10 million Funding supports a range of projects from sustainable 3D printed materials to 6G network innovations and improving the electric automotive industry Read more 12 Waterloo researchers among the most influential in the world Each researcher named on the Highly Cited Researchers™ 2024 list ranks in the top 1 per cent for their fields Read more Nine Waterloo researchers awarded $7.5 million From sustainable additive manufacturing and climate change to quantum molecular dynamics and human health, Waterloo researchers are leading future-focused researchers projects Read more Waterloo News Media? Contact media relations to learn more about this or other stories. TOP Share Waterloo news Find an expert Contact Media Relations University of Waterloo University of Waterloo 43.471468 -80.544205 200 University Avenue West Waterloo, ON, Canada N2L 3G1 +1 519 888 4567 Contact Waterloo Maps & Directions WatSAFE Accessibility Privacy Copyright Media Careers Feedback @uwaterloo social directory The University of Waterloo acknowledges that much of our work takes place on the traditional territory of the Neutral, Anishinaabeg, and Haudenosaunee peoples. Our main campus is situated on the Haldimand Tract, the land granted to the Six Nations that includes six miles on each side of the Grand River. Our active work toward reconciliation takes place across our campuses through research, learning, teaching, and community building, and is co-ordinated within the Office of Indigenous Relations. We use cookies on this site to enhance the user experience. Select 'Accept all' to agree and continue. You consent to our cookies if you continue to use this website. Accept all",
    "commentLink": "https://news.ycombinator.com/item?id=42599189",
    "commentBody": "Researchers design wearable tech that can sense glucose levels more accurately (uwaterloo.ca)324 points by ndrwnaguib 16 hours agohidepastfavorite119 comments Trasmatta 15 hours ago> Currently, diabetics must frequently prick their fingers or rely on invasive wearable patches with micro-needles to track their blood-sugar levels Type 1 diabetic here - for what it's worth, CGMs aren't particularly invasive. At least in comparison to the many many years of finger pricking! But a smart watch solution would be cool. (I actually do get my CGM readings on my smart watch, which is really nice!) I know Apple has also worked on this stuff in the past, but from what I remember the accuracy wasn't good enough to be safe for diabetics. I'd be really curious to see accuracy stats on this in comparison to Dexcom and Freestyle CGMs. I would definitely be excited to use something like this, but for me, the biggest quality of life improvements for me will be continued improvements with closed loop CGM + insulin pump systems. reply omnicognate 9 hours agoparentI don't use one or have diabetes but my understanding is that current CGMs measure interstitial glucose levels, which lag blood levels by up to 15 minutes. As a result, I believe those who require accurate spot measurements rather than just overall trends are still recommended to use finger stick tests. In the article, the researcher claims \"No other technology can provide this level of precision without direct contact with the bloodstream\", so it sounds like they're claiming it's better than existing CGMs in a way that might be clinically relevant. Not sure if that's plausible or whether they are directly measuring blood glucose rather than interstitial. reply asyx 10 hours agoparentprevThose might be really great for T2 though. I don’t need to know the exact number just a ballpark number to know how I’m doing. Having always had a bad relationship with food, I fall off way too easily without a CGM so for me, those things would be perfect. But also in times where we have the Libre 3 which is so tiny that you legit don’t even notice it, a CGM on your wrist is not worth the loss of accuracy for T1 I guess (assuming your insurance pays for it). reply mjrpes 15 hours agoparentprevNot having to pay $50-100/mo for CGM patches would also be nice. reply solumunus 7 hours agorootparentOh there will be a subscription, don’t worry about that. reply rorytbyrne 6 hours agorootparentBut if they want to capture (or create, commercially) the market they’ll probably price it closer to $20 or under. reply manmal 5 hours agorootparentMore likely is a dollar per day for T2 and higher for T1. The differentiator will be non-invasiveness, not price. reply brookst 4 hours agorootparentThen they will get their lunch eaten when smartwatch / ring / etc companies ship it for free. Probably smarter to go for market share with affordable one-time costs and build revenue from conplementsry goods and services. reply DavideNL 9 hours agoparentprev> but for me, the biggest quality of life improvements for me will be continued improvements with closed loop CGM + insulin pump systems You might find this interesting: \"A bi-hormonal fully closed loop system\" https://www.inredadiabetic.nl/en/home-english/ reply manmal 5 hours agorootparentHaving talked with T1 diabetics about such systems, the issue is that you don’t want to deplete glycogen stores just for basal management. Because your life might depend on their levels in case of a severe hypo. reply Scotrix 15 hours agoparentprevAgreed, cool and certainly some improvement but Freestyle is good enough already. Next step for me is more towards the new insulin research which activates only on glucose in the bloodstream (don’t recall how it was called but was here more recently also shared). This sounded more self controlling where it’s hopefully just making sure you have enough of it in your body and don’t need to take care of the rest. Until then, Freestyle with Omnipod Dash in a close loop with iAPS was a game changer for me: Almost no peaks anymore, HBA1c on the level of a non diabetic person… Nevertheless, good luck in productising it and I’ll be certainly trying it once it’s available… reply smt88 14 hours agorootparent> Freestyle is good enough already In my experience, the quality control isn't very good (some patches will read much more accurately than others) and accuracy isn't that good when you get out of normal ranges. I don't think the \"invasive\" nature of the Freestyle is a problem at all, but it would be nice to see some innovation on either the cost or the accuracy or both. reply nahsra 12 hours agorootparentOP lacks imagination for sure. This would reduce infections, prevent compression lows, be more discrete and potentially increase accuracy. In no way would I describe CGM as solved, and this would go a long way towards filling many of the gaps, especially in younger / older / less compliant patient populations. reply je42 11 hours agorootparentprevFor closed loop better cgms will help. Main points are (fsl2 based): - latency, currently 10min. - accuracy, fine in normal range, but when you have a low blood sugar suddenly the latency spikes a lot. - values when being under the shower too high. - start up time of 60min could be lower. -open up the hardware for any app to read reply fallsoffbikes 14 hours agorootparentprevI believe this is a reference to the tech you are talking about. I have a similar take as you: current cgm tech plus closed loop is pretty good. Self activating insulin is the first promising tech I’ve seen in the 40+ years of following the research. https://youtu.be/lVTS_J7Xmxs?si=vemMfo3IbfMlYrUi reply pneumatic1 5 hours agoparentprevNot diabetic myself but managing my little kids T1. If we could go from one poke every 10 days to 0 pokes, I am all in. Skeptical of the accuracy as well though especially for someone who is too young to fully participate and not fully hypoglycemic aware. reply scottyeager 11 hours agoparentprevFor me the worst part of current CGMs isn't the needle or the very thin piece of plastic it leaves behind with the probe. Rather, it's the effect on the skin under the patch and the residual adhesive. So from that perspective a watch would be cool. Indeed though, advancements in (affordable) closed loop tech matter more than where the CGM is worn. reply pneumatic1 5 hours agorootparentCan you say more about the plastic left behind? Polyurethane coating on the cannula? reply IndeterminateR 14 hours agoparentprevCGMs are probably going to still be more accurate, so the watch may not be ideal for Type 1, but could be nice for people with pre-diabetes who are trying to optimize their health. I'm also curious how accurate they will be. reply blackeyeblitzar 14 hours agorootparentCGMs themselves are still inaccurate compared to needles. And even needle based meters have a lot of different levels of accuracy. A CGM, even once calibrated, may be off by as much as 10%. reply caseyy 12 hours agorootparentThe value is in clinical application though. For closed loop systems, making a clinical decision for insulin dosing every 5 minutes is life-changing, even if the dosage is 10% off. I’d say even with compression lows, most systems are self-balancing enough to produce better results than a self-monitoring person could. Besides, 10% off doesn’t often matter: At 0-70 mg/dl the pump should suspend insulin either way. At 110-600 mg/dl the pump should ensure enough IoB by bolus, increase basal, and monitor either way. In that 70-110mg/dl the 10% MARD kind of matters for clinical decision-making, but not much. 90mg/dl is about as healthy as 81 and 99. Patients are sometimes fussy by this inaccuracy but forget the tremendous benefit of trend indicators, let alone closed loop systems. Both of these have a much much larger positive impact to health than blood glucose being 10% above or below target impacts health negatively. CGM withthey didn't do any testing, at all, with actual humans (or animals) They did mention in the article that clinical trials are on-going. reply hn_throwaway_99 14 hours agorootparentCorrect, but I'm extremely skeptical, and that sentence had my bullshit detector alarms screaming even louder: > “We have a minimum viable product that’s already being used in clinical trials, and while there’s more work to be done, we’re much closer to a full marketable device,” Shaker said. Absolutely no information about what this \"clinical trial\" entails, or what phase it was. Most importantly, to get an initial assessment of the accuracy of the device, no clinical trials are necessary - you simply need to do a test that compares the blood sugar reading from the device against the current gold standard, most likely first in some animal model. If their device was really as far along as the title and quotes are implying, they would be showered with so much money it would make the Theranos peak valuation look small. The only evidence they've provided (which, again, I'm not saying is insignificant) is that the \"metasurface\" they have developed enhances the resolution and sensitivity of a radar system against a beaker of water. reply sheepscreek 3 hours agorootparentIt’s fair to be skeptical. Personally, I’ll believe it when I see it in action. There’s likely an unexplained catch or they wouldn’t have shared any hard data in the paper. One possibility is that they want to sell this technology to a big company without publicly disclosing all their trade secrets. However, this research could have been sponsored by a public grant, which would have compelled them to share some information. Therefore, they published a paper that appears more like a patent application than a research paper with solid data. It’s still noteworthy that it was published in Nature. reply azinman2 12 hours agorootparentprevBut they have a minimal viable product! It’s viable! /s reply caseyy 11 hours agorootparentWell… yes. Looking at the article, it satisfies the MVP requirements for getting grant funding. A bar GlucoWatch cleared more than two decades ago, though it could never quite clear the bar of clinical viability. Theranos also had an MVP in this sense :) reply cb321 7 hours agorootparentI have probably seen \"viable\" overinterpreted 100s of times by now. Perhaps we need to re-interpret the 'V' in \"MVP\" as \"VC-investable\" or perhaps replace it with 'I' to be I)nvestible which gets you a more pronounceable \"MIP\" (and maybe, just maybe highlights uncertainty since all investment carries risk)? Happens to also abbreviate \"Multum In Parvo\" (Latin for \"many/much in little\") which is not even that far off from the semantic. ;-) reply m463 13 hours agorootparentprevI thought apple was trying to get glucose monitoring approved https://en.wikipedia.org/wiki/Noninvasive_glucose_monitor#Ne... (different technique) reply theendisney4 14 hours agoparentprevIf it fits in a watch a lot of nondiabetics will also buy it. It can be much cheaper that way. reply lukan 9 hours agorootparentWhy would I as a nondiabetic buy it? Out of general curiosity for my blood sugar levels? reply crazygringo 5 hours agorootparentNot general curiosity -- but for healthier eating. There's a theory that says you basically won't ever gain weight if you prevent your blood sugar from going above a certain level. So it's an objective way of knowing how much to eat and when. Also, to warn when blood sugar is too low. Some people (myself included) often get so into work (or whatever) that we forget to eat, with adverse consequences. An alert is very helpful. reply doxick 8 hours agorootparentprevMy garmin watch measures blood oxygen, heart-rare, breathing patterns, sleep patterns, stress-levels, etc Usefull? It is if you use it. I do triathlons and knowing exactly where my blood-sugar level is at would allow me to focus better on the type of nutrition and the impact of it while working out. It would also tell me if i was a bit down before a race, so i can take some food. Basically: this is a game-changer for amateur athletes, which would create a tremendous market for it. People i know already use the patches to measure as well, or lactate measurements, ketone measurements, etc. and that's just at the casual amateur level. Another application that springs to mind is knowing when to eat instead of just having lunch and sugar-crashing 2 hours later in the office. reply stevage 8 hours agorootparentI also wonder if monitoring your blood sugar is a potential way to avoid becoming a Type 2 diabetic. reply fragmede 7 hours agorootparentThat's what HelloLingo is selling. A wearable blood glucose monitor for 2 weeks, like diabetics wear, so non-diabetics can get a better feel for their blood sugar level and how what they do affects it. https://www.hellolingo.com reply mzhaase 7 hours agorootparentprevWould be a real game changer for endurance sports. There is \"bonking\" - depletion of muscle glycogen. When that happens your race is over. Sometimes it happens even to high level athletes what feels like out of the blue. If you knew ahead of time your blood sugar is getting low you could prevent it. reply lukan 3 hours agorootparent\"If you knew ahead of time your blood sugar is getting low you could prevent it.\" If I am connected to my body, I can also feel it by own biological sensors. But I do see the use case, to get another data input, for those cases where I am distracted and don't pay too much attention on myself. reply promiseofbeans 9 hours agorootparentprevBecause it's built-in as an extra feature to a watch that you were already gonna buy. Garmin watches can measure blood oxygen, but not many people use the feature because it drains the battery quickly. Samsung watches can do a single lead EKGs. Does that sell you the watch? Probably not. Is it yet another thing a company can add to the spec sheet and use to justify a price increase? Yes. reply e40 6 hours agorootparentprevBecause many of us have high blood sugar but are not diabetic and knowing the impact of diet on blood sugar would be a boon to controlling the issue. reply stabbles 9 hours agorootparentprevEndurance athletes already monitor this to figure out how to fuel best. reply hombre_fatal 8 hours agorootparentprevTo fuel their “low carb” low carb eating disorder. reply adaml_623 9 hours agorootparentprevI think this is a really important point. Making it a feature in millions of watches will drive the cost of implementation down reply nradov 14 hours agoparentprevType-2 diabetes is commonly comorbid with hypertension (similar root causes) so combining both sensors in a single wrist device would be useful for many patients. There are existing wrist blood pressure monitors such as Aktiia. Not as accurate as an arm cuff, but good enough for routine monitoring. https://aktiia.com/ reply sowbug 1 hour agoprevSlightly OT, but just last night I finished a 15-day Dexcom Stelo CGM session. If you can afford the $99, I highly recommend it. There is a world of difference between an intellectual understanding of blood glucose and actually witnessing your body maintaining exquisite control over a system dependent on food, exercise, stress, time of day, and the idiosyncrasies of your individual insulin response. reply Beijinger 2 hours agoprevSorry to break the party. A buddy of mine is deeply skeptical, and he is one of the few with a decent amount of peer-reviewed publications about non-invasive blood glucose measurement. The idea to use \"Radar near-field sensing\" is everything but new and nothing has ever come out of it. \"Breakthroughs\" in this field are a dime a dozen: https://finance.yahoo.com/news/liom-cracks-holy-grail-non-22... My buddy is one of the few guys that has a sound (no pun intended) technology that might work. But future will tell. I won't give a link. Yes, the company secured funding. reply bkraz 2 hours agoprevFor anyone interested in noninvasive glucose sensing, I'd highly recommend https://www.nivglucose.com/The%20Pursuit%20of%20Noninvasive%... RF-based approaches have the problem that they are not specific to glucose. A molecule of glucose absorbs infrared light at specific wavelengths due to its size and types of bonds. It does not have specific absorption of radio frequencies. In this paper, researchers measured glucose in pure water at concentrations 100X physiological levels. I'd like to see this work with whole blood or a tissue phantom, or measure glucose independently from any other solute. reply azinman2 12 hours agoprev> “We have a minimum viable product that’s already being used in clinical trials, and while there’s more work to be done, we’re much closer to a full marketable device,” Shaker said. I see this a lot. People seem to ignore the “viable” part of MVP. If there’s more work to be done to make it a full marketable device, it isn’t viable in its current stage. I wish them luck. reply justinl33 6 hours agoprevThe comparison to weather satellites is misleading and oversells this technology. Weather radar works by detecting water droplets at known atmospheric heights - it's a fundamentally different problem than trying to measure glucose concentrations in blood through layers of tissue. The real breakthrough here isn't the radar tech (which has existed for years), it's the machine learning pipeline that can extract meaningful glucose data from extremely noisy radar returns. reply exceptione 10 hours agoprevWhat I miss in the paper is any accuracy figure for glucose sensing. If this is an alternative to needles, how would the measurements compare? That is the first question one should ask. I fear we can assume that, although the approach might be novel, it can't replace needles for accurate measurement. But maybe I am overlooking the performance comparison. reply DavideNL 9 hours agoparentYea, it might perhaps be described more detailed in the mentioned paper (i haven't checked it yet.): https://www.nature.com/articles/s44172-024-00194-4 EDIT: No, i don't think it's mentioned... reply bobmcnamara 3 hours agoparentprevThey claim 90-some percent reply algorithmsRcool 3 hours agoprevI'm happy at the prospect of more accurate readings. But honestly, the Libre 3 is already simply excellent and I would personally prefer the back of the arm location to more wrist based tech. I wear a traditional (Citizen) mechanical watch, because I hated needing to charge a smartwatch. I had some issues with the Libre 2 sensor getting knocked off or loosening after a few days in the shower. But the libre 3 is smaller than a US quarter coin and lasts 15 days and doesn't snag on anything. Will this watch exceed that? Because if not, then I'm not looking to switch. Lastly for diabetics or pre-diabetics that are only using finger sticks, I CANNOT stress enough how important a CGM is to your health. You learn so much about how your body actually works with certian foods rather than low frequency (but somewhat more accurate) finger sticks and that information dropped my A1C like a rock in just a few months. Tell your older relatives also. These are life saving devices. reply gary_0 15 hours agoprevThe explanation of how it works sounds like hand-wavy technobabble from a bad sci-fi thriller. Micro-radar metasurfaces? Amazing that it's actually a real thing. reply pythonguython 14 hours agoparentIt sounds more complicated than it is. A metasurface is almost always just a fancy patch antenna. If you reduce some parameters down, you can really just view it as a resonant circuit. You could design a meta surface in a few minutes in any pcb design software and get it fabricated on low tech PCB fabrication equipment. In this case, they used an array of a specific type of patch antennas (that’s a meta surface) called the complementary split ring resonator. In a sense, all split ring resonators are “micro radar” surfaces, because a split ring resonator is designed to be electrically small compared to the wavelength. The researchers here found that the change in glucose in the bloodstream changes the dielectric properties of the bloodstream, and the resonant characteristics of the complementary split ring resonator change depending on the surrounding dielectric (a dielectric just describes the electrical properties of a material - for instance, a higher electric dielectric constant will slow down the phase velocity of an EM wave, which leads to various measurable effects in an RF system). Looks like great engineering work here, but I’ve always thought the term “metasurface” was foo foo jargon since I first began studying antennas. reply vlovich123 11 hours agoprev> and microcontrollers, which process the radar signals using artificial intelligence algorithms So glad we've rebranded primitive ML and basic control mechanisms as AI. reply winter_blue 11 hours agoparentOr maybe just a signal processor is being rebranded as AI. Soon a Fast Fourier Transform will be rebranded as AI as well. reply raincole 11 hours agoparentprevExcept AI has always meant quite primitive things. AI predates C. Actually AI predates lisp: > IPL was used to implement several early artificial intelligence programs, also by the same authors: the Logic Theorist (1956), the General Problem Solver (1957), and their computer chess program NSS (1958). https://en.m.wikipedia.org/wiki/Information_Processing_Langu... reply bregma 6 hours agoparentprevI had the same complaint over 20 years ago when the phrase \"game AI\" came into widespread use to describe a computer opponent. Now that we have an entire generation raised on the concept that anything a computer does is \"AI\" is it surprising everything a computer does is termed \"AI\"? reply cdmckay 11 hours agoparentprevWasn’t ML always considered AI? reply consp 11 hours agorootparentI've never seen ML been called AI until the past few years. And this is most likely not even ML but just fancy signal processing. reply saidinesh5 15 hours agoprevEven orange pi watch promised something like this... Do we have any updates on it? https://www.notebookcheck.net/Orange-Pi-Watch-D-Pro-New-smar... reply nahsra 12 hours agoparentIt won’t fly under the radar when this technology actually works. The FDA actually has warned, IIRC, that there’s a bunch of charlatans selling stuff that doesn’t work. reply barbegal 3 hours agoprevThere's far too many variables in skin for any non invasive techniques to work reliably in measuring blood glucose levels. The patches work fine and are highly accurate. The real next innovation is implanting devices inside the skin but the miniaturisation of the energy source to do this isn't quite there yet. reply spyder 9 hours agoprevLooks like it's using mm-wave radar technology to detect changes of the dielectric properties of solutions with different levels of glucose. There is also a paper from them doing it with the Google's Project Sali dev kit, the radar that was mostly demonstrated with gesture recognition, but looks like it's useful for other things too like this. They also show it can be also used to detect glucose levels in drinks too like Coke vs diet Coke. Besides the current one posted, they have multiple other publications about the topic: Using Project Sali back in 2018: https://scholar.google.ca/citations?view_op=view_citation&hl... This one is also nice detailed one: https://www.mdpi.com/2072-4292/12/3/385 and looks like the current one is about improving this technology with enhanced signal-to-noise ratio. reply tsimionescu 9 hours agoparent> Looks like it's using mm-wave radar technology to detect changes of the dielectric properties of solutions with different levels of glucose. I wonder if this is actually a viable path to detecting blood glucose. Wouldn't it be sensitive to other substances that affect the dielectric properties of a solution as complex as blood? reply richarme 9 hours agoparentprevNit: Google's project was called Soli. reply pakitan 8 hours agoprevThere is a company that (allegedly) already produces such a device: https://www.knowlabs.co/ I've looked over the studies/tests they've done and they look decent, though the accuracy is not that great. reply wsabihi 5 hours agoparentI initially got excited about this (and know people who would really love this to exist), but after a bit of digging, I am convinced that this is likely a scam. This report explains why it is: https://whitediamondresearch.com/research/know-labs-is-an-ob.... You could also look at the stock economics to see that this company has not behaved like one with a bright future. reply whatnotests2 14 hours agoprevRemarkable work! I was part of a team in 2014-2016 that tried using silicon micro needles layered with polymers in order to filter the interstitial fluid's glucose. Unfortunately it was difficult to calibrate for all the variables. We could have two sensors from the same silicon wager on the same person at the same time and get two different readings. Hats off to these researchers, who went a different direction. Better health really can start with glucose monitoring for everyone. Because we could all learn about sugar's effect on our bodies. reply SteveVeilStream 9 hours agoprevThis sounds great for the problem they are trying to solve but it also sounds like it could be useful for a lot of other interesting applications. I would assume you could put the same sensor on a plastic pipe and infer details about the liquid inside. If I was this team, I might look at how to commercialize this tech for industrial process control in parallel with the slow process of commercializing it for medical purposes. \"The system’s key components are a radar chip, which sends and receives signals through the body, an engineered “meta-surface”, which helps focus these signals for better accuracy, and microcontrollers, which process the radar signals using artificial intelligence algorithms. The algorithms improve the accuracy and reliability of the readings by learning from the data over time.\" reply tpoacher 6 hours agoprevA prof of mine back in Oxford told us a story how he invented a similar noninvasive blood glucose monitoring technique, shown to work, patented it, patent bought by big pharma and silenced. I'm more than convinced we had this tech ages ago but it was not profitable to deploy it. Now either relevant patents are finally expiring or the market has changed enough to allow such players to enter. reply crazygringo 5 hours agoparentDo you have a link to his patent? You should be able to find it by his name. But the hurdle today isn't in the physical sensing technology, it's how to detect an accurate signal from extremely noisy data. Patents aren't the main blocker -- nobody has built this at all in a way that is accurate enough. And Apple has been trying hard, and they have nothing to do with Big Pharma. reply lolc 4 hours agoparentprevI'm sceptical of this story. This is a huge market and it was a huge market 20 years ago. I participated in studies with prototype devices to measure blood glucose and nobody I talked to mentioned patent blocks. reply analog31 15 hours agoprevI work in a related field. Non-invasive blood glucose has been a holy grail for decades. It has bankrupted multiple start-ups. It would be exciting to see something that finally works, but my optimism is tempered. reply MBCook 14 hours agoparentApple has already been working on this, would love the feature, and has an absolute hell of a lot of cash. They also know how to turn very complicated things into miniaturized production products. If they could provide enough proof that it works the way they say it does, I bet they could find a really good suitor there. And you know the various other health/smart watch companies would love to get one up on Apple, outside of the obvious direct benefit it would provide their customers. reply analog31 3 hours agorootparentIn the past, the pharmaceutical companies were big enough to serve as the pot of gold at the end of the rainbow for these startups. Now Apple. On separate occasions, I've met two people who tried this, in two different start-ups, though it was a different kind of spectroscopy in each case. The challenge is, there's no a priori proof that a method can't work, because the information you need to make that assertion has to come from the same kind of research as trying to make it work. So far the start-ups have all failed in the same way, which is that a signal that looks promising in a test tube can't be reliably distinguished from the myriad sources of variation in the living system. Note that I'm not in any way discouraging the work, just offering some historical context for the problem space. reply bluGill 14 hours agorootparentprevThe problem is we don't know if the proqlem is solvable. We get data of course but it needs to be accurate to be useful and that may or may not be possible. reply RachelF 15 hours agoparentprevYes, the article is thin on facts. No mention of the frequency that they use, and how they measure the glucose level, which I'm guessing is some sort of spectral response. I'll take a closer look at the paper in Nature. reply rkagerer 15 hours agorootparentDirect link (from end of article): https://www.nature.com/articles/s44172-024-00194-4 reply vinni2 9 hours agoprevWonder what happened to so called smart insulin https://bristol.ac.uk/news/2018/august/ziylo-deal.html reply pneumatic1 5 hours agoparenthttps://www.biocentury.com/article/653947/science-spotlight-... NNC2215 explained: https://www.youtube.com/watch?v=lVTS_J7Xmxs reply vinni2 1 hour agorootparentI saw this video but the acquisition happened 6 years ago but not much progress after that. reply felipevb 10 hours agoprevI'm super curious about how far Dexcom and Abbott's research departments are with developing these technologies. It could be a (partial) disruption for them. Also - flashback to Rockley Photonics ($RKLY) - and their years-long promise of non-invasive glucose monitoring. reply jimrandomh 14 hours agoprevThis is yet another in a long line of glucose-measurement devices designed to sell to unsophisticated research grantmaking agencies, rather than to diabetics. Making a device that \"measures\" blood sugar in a watch form factor is easy, and many research groups have done so. Making one that's accurate enough to compete with the CGMs that are already on the market is a different matter entirely. reply mmooss 12 hours agoparentWhat about this research indicates to you that it doesn't address the accuracy issue? reply morganherlocker 3 hours agorootparent> Shaker said. “No other technology can provide this level of precision without direct contact with the bloodstream.” The existing alternatives do have access to the bloodstream. reply mmooss 59 minutes agorootparentHow does that indicate that they didn't address the accuracy of their technology, as the GGP claims? > The existing alternatives do have access to the bloodstream. So? Who says otherwise? People don't want invasive tests that have direct contact with their bloodstream. reply throwaway_ab 10 hours agoprevI wonder what other health measurements could be obtained with this technology? Sending radar through the wrist seems like a method that could observe much more information, although I am not sure which. reply looopTools 8 hours agoprevIf it has sufficient accuracy then this could be cool. But I want to see it battle tested before raising my arms to high reply kumarvvr 14 hours agoprevHow can an algorithm be \"artificial intelligence algorithm\"? Does it mean AI models are used for data fitting? Or clustering? For data generated in such low scales, wouldnt statistical methods or procedural methods be sufficient or efficient or both? reply bregma 6 hours agoparentIn modern common usage both the terms \"AI\" and \"algorithm\" are just newspeak for \"a computer does something\" so combining the two into a single phrase just superlatively multiplies the value, like how using a double negative emphasizes how very much more negative something is. In the middle ages the term might have been \"miraculous\" and it could also be well served just by sampling Magnus Pike exclaiming \"SCIENCE!\". reply gandalfgreybeer 12 hours agoparentprevAs an engineer working in the field who has designed both cloud algorithms and on-firmware algorithms, when marketing uses AI, it tends to just be training/data fitting. At best, the most complicated ones tend to be random forests and if any use neural networks, it’s usually just overkill. The answer to your last question is yes, especially when it’s from raw signals. Tbf, there are applications from devices that do use deep learning methods but from experience they are not practical except on very edge cases. reply jval43 10 hours agorootparent>when marketing uses AI In my experience when marketing wants to use AI, they will. Regardless of whether it is ML, basic statistics or even just a few if-else blocks. It used to be the way you describe up to about 2-3 years ago, now the term is meaningless. reply Hard_Space 12 hours agoparentprevIf you hard-code effective learned distributions from a trained model, I suppose that could be described as an 'AI algorithm', even though the final output is a flat algorithm. reply potamic 14 hours agoprevThey seem to be using radio waves instead of optical? Do radio waves penetrate the body or do they hypothesize that there will be changes on the surface of the skin due to blood sugar/pressure? reply pythonguython 13 hours agoparentYes, it is sub optical RF sensing. The important factor here is that the gluclose blood capacitively couples to small sensing antennas. The sensing antennas are resonant elements, whose exact resonance changes depending on the surrounding environment, in this case gluclose in the blood. You can then transmit an RF signal to the antenna, then record the signal reflected from the antenna’s port to estimate the gluclose level. reply toast0 13 hours agoparentprev> Do radio waves penetrate the body Generally, yes. Attenuation varies by frequency, and I guess blood sugar and pressure, though. reply caseyy 11 hours agoprevThis all sounds exciting, and good luck to all researchers earnestly working on it. If RF blood content diagnostics become possible, blood glucose sensing would be just the start. But as for this guy and his invention, don’t forget that in clinical setting, Theranos has shown more evidence of their product working. And GlucoWatch, a similar idea two decades ago, was FDA-approved and made it to market though still wasn’t clinically useful due to poor accuracy. Then, I’m not even talking about the charlatan cottage industry around glucose sensing watches, nor am I talking about how CGMs are a (generally) solved problem in diabetes. Let’s wait for some clinical trials of the applied blood glucose sensing before we pop the champagne? It quite likely won’t happen, welcome as that invention would be. reply pythonguython 2 hours agoparentAccording to the paper, this worked because the dielectric change from all other blood diagnostics was negligible, allowing glucose to be measured. Gluclose in blood is around 80 mg/dL. It may be possible to measure other blood chemistry metrics that are similar in concentration at other frequencies, but there’s a lot of blood tests, many of which would probably be impossible - like white blood cell count, anything enzymatic, something whose concentration is measured in ug/dL, or something that has no effect on dielectric properties of the blood. I wouldn’t expect to see a whole blood panel via wearable radar anytime soon, but we may get a few more tests from RF sensing. reply consp 11 hours agoparentprev> CGMs are a (generally) solved problem in diabetes. Good to know I'm not generally then. reply ars 14 hours agoprevThis title needs that missing exclamation mark. I read it straight as a single sentence and wondered when people used needles on their wrist. reply trimethylpurine 3 hours agoprevThis article is from 2014 and it should be noted as such. Looking at the comments, it's clear people have been misled by the presentation of this article to think this is an emerging technology rather than an old and inappropriate application of one. For others reading; this is about a small radar technology, having nothing to do with research in the detection of blood glucose whatsoever. reply freedomben 1 hour agoparent> This article is from 2014 How do you know? The date on the article says October 29, 2024 reply mlhpdx 15 hours agoprevNo mention of the actual accuracy (and precision) which is critical, obviously. Or did I miss it? reply ars 14 hours agoparentMaybe one of these has it: https://scholar.google.ca/citations?user=BuqNOOwAAAAJ&hl=en Edit: It's here: https://www.nature.com/articles/s44172-024-00194-4 But he's clearly spent his entire career on this! reply ilaksh 15 hours agoprevI wonder if this micro-radar or whatever could be used for brain-computer interfaces somehow. reply devmor 15 hours agoparentRadar doesn't seem like it would be particular useful for electrochemical activity. reply ilaksh 1 hour agorootparenthttps://healthylongevitychallenge.org/winners/multi-modal-mi... reply lofaszvanitt 9 hours agoprevWe need to find the api endpoints of the body somehow. reply paulcole 15 hours agoprevThis is 5 years away from being 5 years away. reply WesolyKubeczek 6 hours agoprev [–] Wake me when I, a consumer, can place an order for one. I keep hearing about such devices year in and year out, with none for sale. I feel like I will just die of old age or as a World War 3 casualty way before I can actually buy one. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers at the University of Waterloo have created a wearable device that uses radar technology to monitor glucose levels non-invasively, removing the need for needles.",
      "The device, led by Dr. George Shaker, incorporates a radar chip, a meta-surface for enhanced signal accuracy, and AI algorithms for precise glucose readings.",
      "Currently USB-powered, the device aims to become battery-operated for improved portability and may eventually monitor additional health metrics, with efforts underway to commercialize the technology."
    ],
    "commentSummary": [
      "Researchers have created wearable technology for non-invasive glucose monitoring, offering an alternative to finger pricking and Continuous Glucose Monitors (CGMs).",
      "The technology aims to provide accurate glucose readings without direct contact with the bloodstream, which could be significant for clinical applications.",
      "While promising, there is skepticism about its accuracy compared to existing CGMs, and further data and clinical trials are needed to confirm its effectiveness."
    ],
    "points": 324,
    "commentCount": 119,
    "retryCount": 0,
    "time": 1736043133
  },
  {
    "id": 42601847,
    "title": "The day I taught AI to read code like a Senior Developer",
    "originLink": "https://nmn.gl/blog/ai-senior-developer",
    "originBody": "The day I taught AI to read code like a Senior Developer Jan 3, 2025 A messy experiment that changed how we think about AI code analysis Last week, I watched our AI choke on a React codebase - again. As timeout errors flooded my terminal, something clicked. We’d been teaching AI to read code like a fresh bootcamp grad, not a senior developer. Here’s what I mean. The Bootcamp vs Senior Mindset Remember your first day reading production code? Without any experience with handling mature codebases, you probably quickly get lost in the details[0] But watch a senior dev review a massive PR: They jump straight to the core files Group changes by feature (“all auth changes, all db changes”) Build a mental model of architecture first Only then dive into implementation Obvious in hindsight, right? This realization led us to completely rewire our analyzer. The Experiment Instead of dumping files linearly, we built a context-aware grouping system: interface FileGroup { files: ProjectFile[]; totalSize: number; groupContext: string; // 'auth', 'database', etc. } export const groupFiles = (files: ProjectFile[]): FileGroup[] => { // Group files by related functionality and size const fileInfos = files.map(file => ({ file, size: file.content?.length || 0, context: getFileContext(file.path) })); // Process larger, more important files first fileInfos.sort((a, b) => b.size - a.size); const groups: FileGroup[] = []; let currentGroup = createEmptyGroup(); for (const { file, size, context } of fileInfos) { if (shouldStartNewGroup(currentGroup, size, context)) { groups.push(currentGroup); currentGroup = createNewGroup(file, size, context); } else { addFileToGroup(currentGroup, file, size); } } return groups; } Then we changed how we prompt the AI. Instead of “analyze this file”, we give it context about the feature group first: const buildGroupPrompt = (group: FileGroup): string => { return ` Analyzing authentication system files: - Core token validation logic - Session management - Related middleware Focus on: 1. How these integrate with existing auth patterns 2. Security implications 3. Performance impact on other systems Files to analyze: ${formatFiles(group.files)} `; } The Holy Shit Moment The results broke our benchmark script. We thought it was a bug. The AI went from: \"This file contains authentication logic using JWT tokens\" To: \"Warning: This auth change could impact websocket connections. The token refresh logic shares patterns with the notification service (added last month), suggesting a potential race condition during high-traffic socket reconnects. Related PR: #1234 (merged last week) modified the same retry logic. Consider adding backoff.\" That’s senior dev level awareness. It was catching connections we hadn’t explicitly taught it about. What Actually Changed? The magic isn’t in fancy ML or bigger models. It’s in mirroring how senior devs think: Context First: We front-load system understanding before diving into code Pattern Matching: Group similar files to spot repeated approaches Impact Analysis: Consider changes in relation to the whole system Historical Understanding: Track why code evolved certain ways The Unexpected Side Effects The system started catching things we didn’t design for: Spotting copy-pasted code across different features Flagging inconsistent error handling patterns Warning about potential performance bottlenecks Suggesting architectural improvements based on usage patterns Why This Matters Every few days there’s a new “AI-powered IDE” on Product Hunt. They’re solving the wrong problem. Making code suggestions without deep context is like having a brilliant junior dev who just joined yesterday - they’ll write clean code that subtly breaks everything. The key isn’t better code generation. It’s better code understanding. Open Questions We’re still figuring out: When to refresh vs preserve historical understanding How to handle conflicting patterns in different parts of the system Whether to expose uncertainty in the analysis What’s Next? I’m curious if we can teach AI to spot other senior dev instincts: Identifying tech debt before it happens Suggesting architectural improvements Catching security issues from usage patterns Understanding unwritten team conventions The problem isn’t making AI write more code. It’s teaching it to think about code the way experienced developers do. [0] Previously said You probably did what I did - start at line 1, read every file top to bottom, get lost in the details., edited in response to feedback from advael Discuss on Twitter Hi, I’m Namanyay — a professional developer since the age of fourteen, now building AI tools to enhance human potential. I write about technology, startups, and the future of work. I’m active on X and I would love to earn your follow. ← When perfect code isn’t enough: My journey with AI IDEs",
    "commentLink": "https://news.ycombinator.com/item?id=42601847",
    "commentBody": "The day I taught AI to read code like a Senior Developer (nmn.gl)293 points by namanyayg 4 hours agohidepastfavorite151 comments afro88 2 hours agoAnother cherry-picked example of an LLM doing something amazing, written about with a heavy dose of anthropomorphism. It's easy to get LLMs to do seemingly amazing things. It's incredibly hard to build something where it does this amazing thing consistently and accurately for all reasonable inputs. > Analyzing authentication system files: > - Core token validation logic > - Session management > - Related middleware This hard coded string is doing some very heavy lifting. This isn't anything special until this string is also generated accurately and consistently for any reasonable PR. OP if you are reading, the first thing you should do is get a variety of codebases with a variety of real world PRs and set up some evals. This isn't special until evals show it producing consistent results. reply asah 41 minutes agoparentIt's incredibly hard to get __ HUMANS __ to do this amazing thing consistently and accurately for all reasonable inputs. reply overgard 0 minutes agorootparentTo be fair, most senior developers don't have any incentive to put this amount of analysis into a working codebase. When the system is working, nobody really wants to spend time they could be working on something interesting trying to find bugs in old code. reply iaseiadit 20 minutes agorootparentprevSome humans can do it consistently, other humans can't. Versus how no publicly-available AI can do it consistently (yet). Although it seems like a matter of time at this point, and then work as we know it changes dramatically. reply InkCanon 2 hours agoparentprevI also think there's some exaggeration. Annotating files with a feature tag system is both manual and not scabale. Custom prompting for each commit or feature a lot more so. You do a decent bit of specialized work here. And I think he left out the most important part, was the answer actually right? The real value of any good dev at all is that he can provide reasonably accurate analysis with logic and examples. \"Could have an error\" is more like a compiler warning than the output of a good engineer. Side note: \"broke the benchmark script?\" If you have an automated way to qualitatively evaluate the output of an LLM in a reasonably broad context like code reading, that's far bigger a story. reply ryanackley 7 minutes agoparentprevWhat I want to know is how accurate was the comment? I've found AI to frequently suggest plausible changes. Like they use enough info and context to look like excellent suggestions on the surface but you realize with some digging it was so completely wrong. reply nuancebydefault 1 hour agoparentprevStill, the findings in the article are very valuable. The fact that directing the \"thought\" process of the LLM by this kind of prompting, yields much better results, is useful. The comparison to how a senior dev would approach the assignment, as a metaphor explaining the mechanism, makes perfect sense to me. reply namanyayg 2 hours agoparentprevThat's exactly what I want to do next. Any tips on how should I get codebases and real world PRs? Are the ones on popular open source repos on GitHub sufficient? I worry that they don't really accurately reflect real world closed source experience because of the inherent selection bias. Secondly, after getting all this, how do I evaluate which method gave better results? Should it be done by a human, or should I just plug an LLM to check? reply fuzzythinker 31 minutes agorootparenthttps://www.kaggle.com/competitions/konwinski-prize reply throwup238 1 hour agorootparentprev> I worry that they don't really accurately reflect real world closed source experience because of the inherent selection bias. As opposed to what, yet another beginner React app? That’s what everyone seems to be testing with but none of the projects I’ve seen are reflective of a production codebase that’s years old and has been touched by a dozen developers. Throw it at a complicated non-frontend mixed language repo like cxx-qt [1] or something, preferably where the training data doesn’t include the latest API. [1] https://github.com/KDAB/cxx-qt reply lukan 1 hour agorootparent\"preferably where the training data doesn’t include the latest API\" That is the reason LLM's in their current shape are pretty useless to me for most tasks. They happily mix different versions of popular frameworks, so I have to do so much manual work to fix it, I rather do all by myself then. Pure (common) math problems, or other domains where the tech did not change so much, like bash scripts or regex are where I can use them. But my actual code? Not really. The LLM would need to be trained only on the API version I use and that is not a thing yet, as far as I am aware. reply jarebear6expepj 2 hours agorootparentprev“…should it be done by a human?” Sigh. reply namanyayg 2 hours agorootparentI'll do it personally in the beginning but was thinking about doing it on scale reply JTyQZSnP3cQGa8B 1 hour agorootparent> doing it on scale Like cloud-scale, no-code scale, or NoSQL scale? You are confused, which shows that, maybe, you should not be using such tools with the experience that you don't have. reply QuadmasterXLII 1 hour agorootparentprevIf you could get an LLM to check, you could just spam solutions with any assortment of models and then use your checker to pick the best. reply smusamashah 2 hours agorootparentprevVery first thing you can tell us (or try if you haven't) is that if you re-prompt, does it give the same answer? Second can you get it to generate (consistently and repeatedly) the text that gp pointed out? Don't need to switch to a different repo for quick test, just make it reproable on your current repo. reply namanyayg 2 hours agorootparentNot the exact text, but still decent quality. I'll play around with temperature and prompts a bit. reply JTyQZSnP3cQGa8B 1 hour agorootparentprevnext [2 more] [flagged] tyrust 46 minutes agorootparentThey're asking about viewing existing PRs, not creating new ones. No need to be so hostile. reply mensetmanusman 42 minutes agoparentprevNo need for the pessimism, these are new tools that humans have invented. We are groking how to utilize them. reply ramblerman 17 minutes agorootparentOP brought a rational argument, you didn't. It sounds like you are defending your optimism with emotion. > We are groking how to utilize them. Indeed. reply ninetyninenine 1 hour agoparentprevThis post talks as if the results are a worthless pile of trash while obeying the HN rules of not directly insulting the results. I agree with everything under the first paragraph. Let me spell it out for you. These results. Are. Not. Worthless. Certainly what you said is correct on what he “should” do to get additional data, but your tonality of implying that the results are utter trash and falsely anthropomorphizing something is wrong. Why is it wrong? Imagine Einstein got most things wrong in his life. Most things but he did discover special and general relativity. It’s just everything else was wrong. Relativity is still worth something. The results are still worthwhile. We have an example of an LLM hallucinating. Then we have another example of additional contextual data causing the LLM to stop hallucinating. This is a data point leaving a clue about hallucinations and stopping hallucinations. It’s imperfect but a valuable clue. My guess is that there’s a million causal factors that cause an LLM to hallucinate and he’s found one. If he does what he did a multitude of times for different topics and different problems where contextual data stops an hallucination, with enough data and categorization of said data we may be able to output statistical data and have insight into what’s going on from a statistical perspective. This is just like how we analyze other things that produce fuzzy data like humans. Oh no! Am I anthropomorphizing again?? Does that action make everything I said wrong? No, it doesn’t. Humans produce correct data when given context. It is reasonable to assume in many cases LLMs will do the same. I wrote this post because I agree with everything you said but not your tone which implies that what OP did is utterly trivial. reply godelski 1 hour agorootparentThey didn't say worthless, they said amazing. Their comment is \"do it consistently, then I'll buy your explanation\" reply ninetyninenine 1 hour agorootparentlol “seemingly amazing” means not amazing at all. He didn’t literally say it but the comment implies it is worthless as does yours. Humans dont “buy it” when they think something is worthless. The tonality is bent this way. He could have said, “this is amazingly useful data but we need more” but of course it doesn’t read like this at all thanks to the first paragraph. Let’s not hallucinate it into something it’s not with wordplay. The comment is highly negative. reply wholinator2 45 minutes agorootparentYou seem very emotionally involved in this. It says \"an LLM doing something amazing\". That's the sentence. Later the term \"seemingly amazing\" is used. Implying that it _seems amazing_. Anything beyond that is your personal interpretation. Do you disagree that there is an excess of cherrypicked LLM examples getting anthropomorphized? Yeah, it did a cool thing. Yes, llms doing single cool things are everywhere. Yes, I well be more convinced of its impact when i see it tested more widely. reply ninetyninenine 18 minutes agorootparentI am emotionally involved in the sense that I disagree and dislike the tone. The core of my post is addressing tonality and thus emotions is the topic of my post. I’m emotionally involved in the same way it’s normal for humans to have emotions. If you can’t see this then you don’t have the rationality or emotional capacity to understand what I am saying. > Anything beyond that is your personal interpretation. Not true. In the context of that post when something is implied that it only seems amazing it also implies that it is likely not amazing. That is a common human interpretation. I find if you’re not interpreting it that way your emotions are influencing your interpretation. > Do you disagree that there is an excess of cherrypicked LLM examples getting anthropomorphized? I disagree. I think everybody is doing the opposite and cherry-picking the instances where the LLM gets stuff wrong and saying LLMs are garbage because of that and ignoring the instances where it gets shit right and classifying that instance as regurgitation. You’re not being rational here by bringing up anthropomorphization. We are mainly talking about correctness. If an aspect of LLM intelligence is similar to humans in generating correct data then anthropomorphizing it is the way to go. Whether it’s anthropomorphizing something is completely orthogonal to the problem. We are talking about correct results. If anthropomorphizing something gets us there… who cares? Human intelligence works and it’s even reasonable to believe LLMs think like humans because they are literally trained on human data. The act of even mentioning anthropomorphization without mentioning correctness is irrational and illogical. reply advael 4 hours agoprevI read to like the first line under the first bold heading and immediately this person seemed like an alien. I'll go back and read the rest because it's silly to be put off a whole article by this kind of thing, but what in the actual fuck? I was probably not alive the last time anyone would have learned that you should read existing code in some kind of linear order, let alone programming. Is that seriously what the author did as a junior, or is it a weirdly stilted way to make an analogy to sequential information being passed into an LLM... which also seems to misunderstand the mechanism of attention if I'm honest I swear like 90% of people who write about \"junior developers\" have a mental model of them that just makes zero sense that they've constructed out of a need to dunk on a made up guy to make their point reply lolinder 2 hours agoparentTo anyone who gets confused by the parent comment, note that the line they're referring to has been updated. It used to read: > Remember your first day reading production code? You probably did what I did - start at line 1, read every file top to bottom, get lost in the details. Now it reads: > Remember your first day reading production code? Without any experience with handling mature codebases, you probably quickly get lost in the details. reply thimabi 2 hours agorootparentThe change makes me question the authenticity of the text. I mean, did the author actually read files from top to bottom, or did he just write that because it suited his narrative? That’s a trivial change to make for a line that did not receive the feedback that the author wanted. If that’s the case, maybe the text was more about saying what people wanted to hear than honestly portraying how to make AI read code better. reply namanyayg 2 hours agorootparentI forced an analogy and took the metaphor too far. I promise you'll see better from me in the future! reply iaseiadit 7 minutes agorootparentWhen I started out, I did read code top-to-bottom. I was mostly self-taught and didn't have a mental model yet of how code was structured, so I relied on this \"brute force\" method to familiarize myself. I suppose it's not safe to assume that everyone started out like this. But advael is guilty of assuming that nobody started out like this. And on top of that, conveying it in a very negative and critical way. Don't get discouraged. reply tmpz22 2 hours agorootparentprev> Remember your first day reading production code? You probably did what I did - start at line 1, read every file top to bottom, get lost in the details. Top to bottom left to right is how we read text (unless you are using Arabic or Hebrew!), the analogy was fine IMO. Don’t let one HN comment shake your confidence, while people here may be well intentioned they are not always right. reply edanm 19 minutes agorootparentHebrew speakers also read top to bottom and left to right, when they're reading code, because coding is (almost always) in English languages. :) reply namanyayg 2 hours agorootparentprevHaha thank you for the kind words! I've been a lurker on HN ever since I was a kid. I've seen over and over how HN is the most brusque & brutal online community. But that's also why I love it. Taking every piece of feedback here to learn and improve in the future, and feeling grateful for the thousands of views my article is receiving! reply lolinder 2 hours agorootparentprevDon't take this feedback too personally—remember that most HN users read and don't vote or comment, a subset of them read and vote, and only a tiny loud fraction of us actually comment. Your article has been very well received, and it wasn't because that one line deceived people into paying attention, it's because the content is good. reply autobodie 2 hours agorootparentprevMetaphor? What metaphor? What analogy? reply brundolf 1 hour agorootparentprevWow, people are being very uncharitable in this comment section reply soneca 2 hours agorootparentprevOh, I was confused, thanks a lot. And, indeed, reading every file from top to bottom is very alien to me as a junior. I would just try to get to the file I thought the change I needed was made and start trying and error. Definitely not checking the core files, much less creating a mental model of the architecture (the very concept of architecture would be alien to me then). I would do get lost in irrelevant details (because I thought they were relevant), while completely missing the details that did matter. reply namanyayg 2 hours agorootparentprevOops, I should have marked my edit clearly. Added a footnote now. reply lolinder 2 hours agorootparentThanks! No worries, we all live and learn. :) reply dnadler 3 hours agoparentprevWhile that wasn’t my experience as a junior developer, this is something that I used to do with academic papers. I would read it start to finish. Later on, I learned to read the abstract, then jump to either the conclusion or some specific part of the motivation or results that was interesting. To be fair, I’m still not great at reading these kinds of things, but from what I understand, reading it start to finish is usually not the best approach. So, I think I agree that this is not really common with code, but maybe this can be generalized a bit. reply Aurornis 3 hours agorootparent> this is something that I used to do with academic papers Academic papers are designed to be read from start to finish. They have an abstract to set the stage, an introduction, a more detailed setup of the problem, some results, and a conclusion in order. A structured, single-document academic paper is not analogous to a multi-file codebase. reply rorytbyrne 3 hours agorootparentNo, they are designed to elucidate the author's thought process - not the reader's learning process. There's a subtle, but important difference. Also: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPape... reply p1esk 2 hours agorootparentthey are designed to elucidate the author's thought process - not the reader's learning process No, it’s exactly the opposite: when I write papers I follow a rigid template of what a reader (reviewer) expects to see. Abstract, intro, prior/related work, main claim or result, experiments supporting the claim, conclusion, citations. There’s no room or expectation to explain any of the thought process that led to the claim or discovery. Vast majority of papers follow this template. reply disgruntledphd2 3 hours agorootparentprev> reading it start to finish is usually not the best approach. It really, really depends on who you are and what your goal is. If it's your area, then you can probably skim the introduction and then forensically study methods and results, mostly ignore conclusion. However, if you're just starting in an area, the opposite parts are often more helpful, as they'll provide useful context about related work. reply the_af 2 hours agorootparentprevYou're supposed to read academic papers from start to finish. reply baq 2 hours agorootparentYou're supposed to read the abstract, preferably the bottom half first to see if there are conclusions there, then proceed to the conclusions if the abstract is insufficient. Once you're through with that, you can skim the introduction and decide if the paper is worth your attention. Reading start to finish is only worth it if you're interested in the gory details, I'm usually not. reply jghn 2 hours agorootparentprevI was taught to read the abstract, then the conclusion, then look at the figures, and maybe dig into other sections if there's something that drew my interest. Given the variety of responses here, I wonder if some of this is domain specific. reply fsmv 2 hours agorootparentprevI learned very quickly reading math papers that you should not get stuck staring at the formulas, read the rest first and let them explain the formulas. I would not say it should be read start to finish, I often had to read over parts multiple times to understand it. reply coldtea 3 hours agoparentprevI don't know. Your comment feels like alien. The first line under the first bold heading is: \"Remember your first day reading production code? Without any experience with handling mature codebases, you probably quickly get lost in the details\". Which looks pretty much accurate. And yes, this includes the (later) implied idea that many juniors would read a PR in some kind of linear order, or at least, not read it in order of importance, or don't know how to properly order their PR code reading. And yes, some just click in the order Github shows the changed files. Not that for 99% of the industry, \"junior dev\" is not the same as something like: \"just out of uni person with 12+ years of experience programming since age 10, who built a couple of toy compilers before they were 16, graduated Stanford, and was recently hired at my FAANG team\" It's usually something bewteen that and the DailyWTF fare, often closer to the latter. reply lolinder 2 hours agorootparentThe article was updated, probably in response to the parent comment. It used to read this: > Remember your first day reading production code? You probably did what I did - start at line 1, read every file top to bottom, get lost in the details. I copied before refreshing, and sure enough that line was modified. reply yodsanklai 31 minutes agoparentprevI find this distinction between junior/senior pretty annoying. There's such a big variance in terms of skills among SWEs than seniority (as in years of experience) isn't necessarily the main differentiator. Also, the field is changing fast, someone with decades of experience may not be more senior than a young graduate (for instance, when it comes to using the company internal tools or more recent tech). reply bobnamob 2 hours agoparentprevI think this article is indicative of the \"vibe\" I've been getting when reading any discussion around genAI programming. The range of (areas of) competence is just so damn vast in our industry that any discussion about the quality of generated code (or code reviews in this case) is doomed. There just isn't a stable, shared baseline for what quality looks like. I mean really - how on earth can Jonny Startup, who spends his days slinging JS/TS to get his business launched inFurthermore, the article is so bereft of detail and gushes so profusely about the success and virtues of their newly minted \"senior level\" AI that I can't help but wonder if they're selling something... With all the money in the AI space these days, my prior probability for an article extolling the virtues of AI actually trying to sell something is rather high. I just want a few good unbiased academic studies on the effects of various AI systems on things like delivery time (like are AI systems preventing IT projects from going overtime on a fat-tailed distribution? is it possible with AI to put end to the chapter of software engineering projects going disastrously overtime/overbudget?) reply 9rx 2 hours agorootparentprevIs there a difference in quality? Johnny Startup is presumably trading quality in order to release sooner, but the lower quality accepted in that trade is recognizable. reply bobnamob 2 hours agorootparentIf Jonny startup has been building release prioritised systems all his life/career, there's a decent chance he doesn't even know what more goes into systems with higher release & maintenance standards. Conversely, if Terrence has only ever worked in high rigour environments, he's unlikely to understand Jonny's perspective when Jonny says that code generation tools are doing amazing \"reliable\" things. Again, this isn't meant to be a value judgement against either Jonny or Terrence, more that they don't have shared context & understanding on what and how the other is building, and therefore are going to struggle to have a productive conversation about a magic blackbox that one thinks will take their job in 6 months. reply loeg 1 hour agoparentprevI have actually just printed out codebases and read them cover to cover before (sometimes referencing ahead for context), as a senior engineer. If you need to quickly understand what every line is doing on a small to medium sized body of code, it's a pretty good way to avoid distraction and ramp up quickly. I find that just reading every line goes pretty quickly and gives me a relatively good memory of what's going on. reply ninetyninenine 1 hour agorootparentDoing this requires higher IQ. Believe it or not a ton of people literally don’t do this because they can’t. This ability doesn’t exist for them. Thousands of pages of code is impossible to understand line by line for them. This separation of ability is very very real. reply pdhborges 38 minutes agorootparentprevI don't read all the lines of code but I open and scan a ton of files from the code base to get a feel of which concepts abstractions and tricks are used. reply schaefer 3 hours agoparentprev> I was probably not alive the last time anyone would have learned that you should read existing code in some kind of linear order, let alone programming. If you want to dive all the way down that rabbit hole, can I recommend you check out the wikipedia article for the book Literate Programming [1] by Donald Kunth [2]. [1]: https://en.wikipedia.org/wiki/Literate_programming [2]: https://en.wikipedia.org/wiki/Donald_Knuth reply namanyayg 3 hours agoparentprevI was a junior so long ago that I've forgotten how I first read code, but I do remember I was very confused. Edited the post to improve clarity. Thanks for the writing tip! reply advael 2 hours agorootparentYea sorry if I came off caustic there, dealing with really dismissive attitudes toward juniors I'm actively trying to foster has perhaps left a bad taste in my mouth reply namanyayg 2 hours agorootparentNo worries. I took the metaphor too far and you rightfully called me out. I'm still learning how to write well, I promise you'll see better from me in the future. reply advael 2 hours agorootparentLove to see someone genuinely trying to improve at something and I'm glad to have played a tiny part in it reply nfRfqX5n 3 hours agoparentprevDidn’t seem like dunking on juniors to me reply myvoiceismypass 1 hour agoparentprev> I was probably not alive the last time anyone would have learned that you should read existing code in some kind of linear order, let alone programming. Some of us have been around since before the concept of a “Pull Request” even existed. Early in my career we used to print out code (on paper, not diffs) and read / have round table reviews in person! This was only like 2 decades ago, too! reply olivierduval 2 hours agoparentprevI think that you missed the point and should have read until \"That’s exactly how we feed codebases to AI\"... ;-) Actually, the article shows that feed an AI with \"structured\" source code files instead of just \"flat full set\" files allow the LLM to give better insights reply Klonoar 3 hours agoparentprev> I was probably not alive the last time anyone would have learned that you should read existing code in some kind of linear order I think you're jumping ahead and missing a point that the article itself made: there are indeed bootcamp developers who were taught this way. I have spent quite a number of hours of my life trying to walk some prospective developers back from this mindset. That said I think that you could write this entire article without dunking on junior developers and I don't consider it particularly well written, but that's a separate issue I guess. reply advael 3 hours agorootparentI suppose such a bootcamp may exist but wow, that's crazy to me But yea, having now read the whole thing I'm mostly taking issue with the writing style I guess. I find the method they tried interesting but it's worth noting that it's ultimately just another datapoint for the value of multi-scale analytic techniques when processing most complex data (Which is a great thing to have applied here, don't get me wrong) reply brundolf 1 hour agoprevPeople are being very uncharitable in the comments for some reason This is a short and sweet article about a very cool real-world result in a very new area of tooling possibilities, with some honest and reasonable thoughts Maybe the \"Senior vs Junior Developer\" narrative is a little stretched, but the substance of the article is great Can't help but wonder if people are getting mad because they feel threatened reply namanyayg 46 minutes agoparentFelt a bit more cynic than usual haha. reply voidhorse 2 hours agoprevTo me, this post really just highlights how important the human element will remain. Without achieving the same level of contextual understanding of the code base, I have no clue as to whether or not the AI warning makes any sense. At a superficial level, I have no idea what \"shared patterns\" means or why it logically follows that sharing them would cause a race condition. It also starts out talking about authentication changes, but then cites a PR that modified \"retry logic\"—without that shared context, it's not clear to me that an auth change has anything to do with retry logic unless the retry is related to retries on authentication failures. reply jerpint 4 hours agoprevI think there will be lessons learned here as well for better agentic systems writing code more generally; instead of “committing” to code as of the first token generated, first generate overall structure of code base, with abstractions, and only then start writing code. I usually instruct Claude/chatGPT/etc not to generate any code until I tell it to, as they are eager to do so and often box themselves in a corner early on reply rmbyrro 4 hours agoparentaider.chat has an /architect mode where you can discuss the architecture first and later ask it to execute the architectural decisions works pretty well, especially because you can use a more capable model for architecting and a cheaper one to code reply namanyayg 3 hours agorootparentI didn't know about this, thanks for sharing reply Kinrany 3 hours agoparentprevWe already have languages for expressing abstractions, they're called programming languages. Working software is always built interactively, with a combination of top-down and bottom-up reasoning and experimentation. The problem is not in starting with real code, the problem is in being unable to keep editing the draft. reply qup 3 hours agorootparentNot a problem with the correct tooling. reply thegeomaster 4 hours agoparentprevThis is literally chain-of-thought! Even better than generic chain-of-thought prompting (\"Think step by step and write down your thought process.\"), you're doing a domain-specific CoT, where you use some of your human intuition on how to approach a problem and imparting the LLM with it. reply j_bum 3 hours agoparentprevYes I frequently do this too. In fact I often ask whatever model I’m interacting with to not do anything until we’ve devised a plan. This goes for search, code, commands, analysis, etc. It often leads to better results for me across the board. But often I need to repeat those instructions as the chat gets longer. These models are so hyped to generate something even if it’s not requested. reply namanyayg 3 hours agoparentprevThat's exactly what I've understood, and this becomes even more important as the size of codebase scales. Ultimately, LLMs (like humans) can keep a limited context in their \"brains\". To use them effectively, we have to provide the right context. reply sgt101 3 hours agoprevAs John McCarthy used to complain \"Look Mom, no hands!\" This isn't an experiment, or proof of anything. It's a story. I wish people in the community would engage their critical skills and training. The folks that taught the author should hang their head in shame that their student is producing such rubbish. reply namanyayg 3 hours agoparentIt's my personal experience for now. Have some experiments and further study planned. It's difficult to set up evals, especially with production code situations. Any tips? reply sgt101 2 hours agorootparentYeah, it is hard. The principal you need to work to is that you need to create evidence that other people will find compelling and then show that you have interrogated your results to show that you have checked that it's really working better than chance and not the result of some fluke or other. Finally you need to find a way to explain what's happening - like an actual mechanism. 1. Find or make a data set - I've been using code_search_net to try and study the ability of LLM's to document code, specifically the impact optimising n-shot learning on them*, this may not be close enough to your application, but you need many examples to draw conclusions. It's likely that you will have to do some statistics to demonstrate the effects of your innovations so you probably need around 100 examples. 2. Results from one model may not be informative enough, it might be useful/necessary to compare several different models to see if the effect you are finding is consistent or whether some special feature of a model is what is required. For example, does this effect work with only the largest and most sophisticated modern models, or is this something that can be seen to a greater or lesser effect with a variety of models? 3) You need to ablate - what is it in the setup that is most impactful? What happens if we change a word or add a word to the prompt? Does this work on long code snippits? Does it work on code with many functions? Does it work on code from particular languages? 4) You need a quantitative measure of performance. I am a liberal sort , but I will not be convinced by an assertion that \"it worked better than before\" or \"this review is like an senior, I think\". There needs to be a number that someone like me can't argue with - or at least, can argue with but can't dismiss. *I couldn't make it work, I think because the search space for finding good prompting shots (sample function)is vast and the output space (possible documents) is vast. Many bothans died in order to bring you this very very very (in hindsight with about $200 of OpenAI spending) obvious result. Having said that I am not confident that it couldn't be made to work at this point so I haven't written it up and won't make any sort of definitive claim. Mainly I wonder if there is a heuristic that I could use to choose examples a-priori instead of trying them at random. I did try shorter examples and I did try more typical (size) examples. The other issue is that I am using sentence similarity as a measure of quality, but that isn't something I am confident of. reply og_kalu 2 hours agoparentprevYeah it's a story. So what ? If you'd have liked evals or implementation details then you can just say so. People can and are free to tell stories if they want. It's not some failing. You don't have to engage with it anymore than that. reply Arch-TK 1 hour agoprevI am struggling to teach AI to stop dreaming up APIs which don't exist and failing to solve relatively simple but not often written about problems. It's good when it works, it's crap when it doesn't, for me it mostly doesn't work. I think AI working is a good indicator of when you're writing code which has been written by lots of other people before. reply jalopy 4 hours agoprevThis looks very interesting, however it seems to me like the critical piece of this technique is missing from the post: the implementations of getFileContext() and shouldStartNewGroup(). Am I the one missing something here? reply iamleppert 4 hours agoparentNo, the code he posted sorts files by size, groups them, and then…jazz hands? reply thegeomaster 4 hours agoparentprevReading between the lines, it sounds like they are creating an AI product for more than just their own codebase. If this is the case, they'd probably be keeping a lot of the secret sauce hidden. More broadly, it's nowadays almost impossible to find what worked for other people in terms of prompting and using LLMs for various tasks within an AI product. Everyone guards this information religiously as a moat. A few open source projects are everything you have if you want to get a jumpstart on how an LLM-based system is productized. reply layer8 2 hours agoparentprevYeah, and in the code bases I’m familiar with, you’d need a lot of contextual knowledge that can’t be derived from the code base itself. reply charles_f 1 hour agoprevI wondered if there was a reason behind the ligature between c and t across the article (e.g. is it easier to read for people with dyslexia). If like me you didn't know, apparently this is mostly stylistic, and comes from a historical practice that predates printing. There are other common ligatures such as CT, st, sp and th. https://rwt.io/typography-tips/opentype-part-2-leg-ligatures reply JoeAltmaier 4 hours agoprevPretty impressive. But for the part about nitpicking on style and uniformity (at the end) the results seem useful. Btw I thought, from the title, this would be about an AI taught to dismiss anyone's work but their own, blithely hold forth on code they had no experience with, and misinterpret goals and results to fit their preconceived notions. You know, to read code like a Senior Developer. reply svilen_dobrev 4 hours agoparent> to read code like a Senior Developer. you mean, as in \"code written by someone else == bad code\" ? reply dearing 3 hours agorootparentIts being cute but speaking about politicking at code review. reply ianbutler 1 hour agoprevCode context and understanding is very important for improving the quality of LLM generated code, it’s why the core of our coding agent product Bismuth (which I won’t link but if you’re so inclined check my profile) is built around a custom code search engine that we’ve also built. We segment the project into logical areas based on what the user is asking, then find interesting symbol information and use it to search call chain information which we’ve constructed at project import. This gives the LLM way better starting context and we then provide it tools to move around the codebase through normal methods you or I would use like go_to_def. We’ve analyzed a lot of competitor products and very few have done anything other than a rudimentary project skeleton like Aider or just directly feeding opened code as context which breaks down very quickly on large code projects. We’re very happy with the level of quality we see from our implementation and it’s something that really feels overlooked sometimes by various products in this space. Realistically, the only other product I know of approaching this correctly with any degree of search sophistication is Cody from SourceGraph which yeah, makes sense. reply theginger 4 hours agoprevWhat is with the font joining the character c and t on this site?(In headings) reply namanyayg 3 hours agoparentIn a previous lifetime I was a huge typography nerd (I could name 95% of common fonts in just a glance ~10 years ago). These are ligatures. I got the code to enable them from Kenneth's excellent Normalize-Opentype.css [0] [0]: https://kennethormandy.com/journal/normalize-opentype-css/ reply csallen 3 hours agoparentprevI was wondering the same thing. That doesn't seem to happen in the Lato font on Google Fonts: https://fonts.google.com/specimen/Lato?preview.text=Reaction... EDIT: It's called ligatures: https://developer.mozilla.org/en-US/docs/Web/CSS/font-varian.... The CSS for headings on this site turns on some extra ligatures. reply jfk13 3 hours agorootparentSpecifically, `font-variant-ligatures: discretionary-ligatures` enables this. (So does `font-feature-settings: \"dlig\" 1`, which is the low-level equivalent; the site includes both.) reply escape_goat 4 hours agoparentprevIt's not joining it in a kerning sense, that's just the remarkably serif nature of EB Garamond, which has a little teardrop terminal on the tip of the 'c'. It's possible that you have font smoothing that is tainting the gap, otherwise it's your eyes. reply wymerica 3 hours agorootparentI was curious about this as well, it looks as though he’s using a specific font which creates a ligature between those letters. I think it’s specific because it’s only on the CT and it’s on other pages in his site. I went further to investigate what this might be and it’s a little used print style: https://english.stackexchange.com/questions/591499/what-is-t... reply teraflop 3 hours agorootparentprevNo, the heading font is Lato, not Garamond, and it's definitely some kind of digraph that only shows up with the combination \"ct\". Compare the letter \"c\" in these two headings: https://i.imgur.com/Zq53gTd.png reply escape_goat 1 hour agorootparentThis should be upvoted. Thank you, I hadn't realized that OP was referring to the heading font or scrolled down to see what is yes, quite a remarkable ligature. It appears to be Lato delivered fromThe ligature appears due to discretionary ligatures being turned on. h1, h2, h3 { font-feature-settings: \"kern\" 1, \"liga\" 1, \"pnum\" 1, \"tnum\" 0, \"onum\" 1, \"lnum\" 0, \"dlig\" 1; font-variant-ligatures: discretionary-ligatures; } reply eichin 3 hours agorootparentprevActually, EB Garamond has c_t and s_t ligatures. reply jfk13 3 hours agorootparentIt does, but those would only be applied if the `font-variant-ligatures: historical-ligatures` property were specified, so they don't appear on this site. reply escape_goat 1 hour agorootparentI inspected for a ligature and any evidence of CSS kerning being turned on before commenting, but I didn't test it to see what the page looked like with it turned on, so I didn't have active knowledge of the possibility of a ligature. If I'd know, it would have been better to give wider scope to the possibility that somehow kerning was being activated by OP's browser. I should have known better than to make a remark about a font without absolutely scrupulous precision! I actually appreciate the comments and corrections. reply codesnik 3 hours agorootparentprevand a very subtle f_f. I don't find those nice though. reply OzzyB 3 hours agoprevSo it turns out that AI is just like another function, inputs and outputs, and the better you design your input (prompt) the better the output (intelligence), got it. reply jprete 3 hours agoparentThe Bitter Lesson claimed that the best approach was to go with more and more data to make the model more and more generally capable, rather than adding human-comprehensible structure to the model. But a lot of LLM applications seem to add missing domain structure until the LLM does what is wanted. reply Philpax 1 hour agorootparentThe Bitter Lesson states that you can overcome the weakness of your current model by baking priors in (i.e. specific traits about the problem, as is done here), but you will get better long-term results by having the model learn the priors itself. That seems to have been the case: compare the tricks people had to do with GPT-3 to how Claude Sonnet 3.6 performs today. reply do_not_redeem 3 hours agorootparentprevThe Bitter Lesson pertains to the long term. Even if it holds, it may take decades to be proven correct in this case. Short-term, imparting some human intuition is letting us get more useful results faster than waiting around for \"enough\" computation/data. reply mbaytas 3 hours agorootparentprevImproving model capability with more and more data is what model developers do, over months. Structure and prompting improvements can be done by the end user, today. reply shahzaibmushtaq 3 hours agoparentprevYou got that 100% right. The title should be \"The day I told (not taught) AI to read code like a Senior Developer\". reply crazygringo 2 hours agoprevI'm fascinated by stories like these, because I think it shows that LLM's have only shown a small amount of their potential so far. In a way, we've solved the raw \"intelligence\" part -- the next token prediction. (At least in certain domains like text.) But now we have to figure out how to structure that raw intelligence into actual useful thinking patterns. How to take a problem, analyze it, figure out ways of breaking it down, try those ways until you run into roadblocks, then start figuring out some solution ideas, thinking about them more to see if they stand up to scrutiny, etc. I think there's going to be a lot of really interesting work around that in the next few years. A kind of \"engineering of practical thinking\". This blog post is a great example of one first step. reply shahzaibmushtaq 1 hour agoprevAll fresh bootcamp grads aren't going to understand what the author is talking about, and many senior developers (even mid-seniors) are looking for what prompts the author wrote to teach AI how to become a senior developer. reply redleggedfrog 1 hour agoprevThat's funny those are considered Senior Dev attributes. I would think you'd better be doing that basic kind of stuff from the minute your writing code for production and future maintenance. Otherwise your making a mess someone else is going to have to clean up. reply qianli_cs 2 hours agoprevI thought it was about LLM training but it’s actually prompt engineering. reply namanyayg 2 hours agoparentI'm thinking about training next! But deepseek is so good already reply dimtion 2 hours agoprevWithout knowing exactly how createNewGroup and addFileToGroup are implemented it is hard to tell, but it looks like the code snippet has a bug where the last group created is never pushed to groups variable. I'm surprised this \"senior developer AI reviewer\" did not caught this bug... reply cloudking 3 hours agoprevSounds like OP hasn't tried the AI IDEs mentioned in the article. For example, Cursor Agent mode does this out of the box. It literally looks for context before applying features, changes, fixes etc. It will even build, test and deploy your code - fixing any issues it finds along the way. reply batata_frita 1 hour agoparentHave you tried cline to compare with cursor? I haven't tried Cursor yet but for me cline does an excelent job. It uses internal mechanisms to understand the code base before making any changes. reply cloudking 1 hour agorootparentI'll give it a go, I've also heard Windsurf is quite good. Personally I've been very impressed with Cursor Agent mode, I'm using it almost exclusively. It understands the entire codebase, makes changes across files, generates new files, and interacts with terminal input/output. Using it, I've been able to build, test & deploy fullstack React web apps and three.js games from scratch. reply dartos 2 hours agoprevI think the content is interesting, but anthropomorphizing AI always rubs me the wrong way and ends up sounding like marketing. Are you trying to market a product? reply patrickhogan1 1 hour agoprevThis is great. More context is better. Only question is after you have the AI your code why would you have to tell it basic things like this is session middleware. reply danjl 1 hour agoprev> Identifying tech debt before it happens Tech debt is a management problem, not a coding problem. A statement like this undermines my confidence in the story being told, because it indicates the lack of experience of the author. reply noirbot 1 hour agoparentI don't think that's totally accurate though. It can definitely be a coding problem - corners cut for expediency and such. Sometimes that's because management doesn't offer enough time to not do it that way, but it can also just be because the dev doesn't bother or does the bare minimum. I'd argue the creation of tech debt is often coding problem. The longevity and persistence of tech debt is a management problem. reply dijksterhuis 35 minutes agorootparent> it can also just be because the dev doesn't bother or does the bare minimum sounds like a people problem — which is management problem. > I'd argue the creation of tech debt is often coding problem. The longevity and persistence of tech debt is a management problem. i’d argue the creation of tech debt is more often due to those doing the coding operating under the limitations placed on them. The longevity and persistence of tech debt is just an extension of that. given an infinite amount of time and money, i can write an ideal solution to a solvable problem (or at least close to ideal, i’m not that good of a dev). the limitations create tech debt, and they’re always there because infinite resources (time and money) don’t exist. so tech debt always exists because there’s always limitations. most of the time those resource limitations are decided by management (time/money/people) but there are language/framework/library limitations which create tech debt too though, which i think is what you might be referring to? usually those are less common though reply danjl 1 hour agorootparentprevNot taking enough time is a management problem. It doesn't matter whether It is the manager or the developer who takes shortcuts. The problem is planning, not coding. reply kmoser 1 hour agoprevI wonder how the results would compare to simply prompting it to \"analyze this as if you were a senior engineer\"? reply jappgar 1 hour agoparentI do this all the time. Actually, I tell it that I am a senior engineer. A lot of people tinkering with AI think it's more complex than it is. If you ask it ELI5 it will do that. Often I will say \"I already know all that, I'm an experienced engineer and need you to think outside the box and troubleshoot with me. \" It works great. reply SunlitCat 2 hours agoprevOh my. That title alone inspired me to ask ChatGPT to read a simple hello world cpp program like a drunken sailor. The end result was quite hilarious I have to say. It's final verdict was: End result? It’s a program yellin’, \"HELLO WORLD!\" Like me at the pub after 3 rum shots. Cheers, matey! hiccup :D reply namanyayg 2 hours agoparentRecently I've started appending \"in the style of Edgar Allen Poe\" to my prompts when I'm discussing code architecture. It's really quite interesting how the LLM comes up with ways to discuss about code :) reply zbyforgotp 2 hours agoprevPersonally I would not hardcode the discovery process in code but just gave the llm tools to browse the code and find what it needs itself. reply mbrumlow 1 hour agoprev> Context First: We front-load system understanding before diving into code Pattern Matching: Group similar files to spot repeated approaches Impact Analysis: Consider changes in relation to the whole system Wait. You fixed your AI by doing traditional programming !?!?! reply Workaccount2 2 hours agoprevJust like training data, the more context and the higher quality the context you give the model, the better the outputs become. reply yapyap 3 hours agoprevhaha man, some of yall really talk about AI like it’s some baby with all the knowledge in the world, waiting to be taught common sense reply _0ffh 3 hours agoprevVery sceptical of \"Context First: We front-load system understanding before diving into code\". The LLM sees the whole input at once, it's a transformer, not a recurrent model. Order shouldn't matter in that sense. Ed. I see some people are disagreeing. I wish they explained how they imagine that would work. reply guerrilla 42 minutes agoprevToday I learned I have \"senior dev level awareness\". This seems pretty basic to me, but impressive that the LLM was able to do it. On the other hand, this borderline reads like those people with their \"AI\" girlfriends. reply atemerev 1 hour agoprevThis is what Aider doing out of the box reply whinvik 4 hours agoprevSounds interesting. Do you have documentation on how you built the whole system? reply namanyayg 2 hours agoparentI'll write something up, what are you curious about exactly? reply JTyQZSnP3cQGa8B 2 hours agorootparent> Do you have documentation on how you built the whole system Or any actual \"proof\" (i.e. source code) that your method is useful? I have seen a hundred articles like this one and, surprise!, no one ever posts source code that would confirm the results. reply namanyayg 2 hours agorootparentI have been trying to figure out how to publish evals or benchmarks for this. But where can I get high quality data of codebases, prompts, and expected results? How do I benchmark one codebase output vs another? Would love any tips from the HN community reply JTyQZSnP3cQGa8B 2 hours agorootparentThat's the problem with people who use AI. You think too much and fail to deliver. I'm not asking for benchmarks or complicated stuff, I want source code, actual proof that I can diff myself. Also that's why the SWE is doomed because of AI, but that's another story. reply techn00 2 hours agorootparentprevthe implementations of getFileContext() and shouldStartNewGroup(). reply deadbabe 1 hour agoprevThis strikes me as basically doing the understanding for the LLM and then having it summarize it. reply revskill 2 hours agoprevThe seniors master more than 2 or 3 languages. reply scinadier 2 hours agoprevA bit of a disappointing read. The author never elaborates on the details of the particular day in which they taught AI to read code like a Senior Developer. What did they have for lunch? We'll never know. reply namanyayg 2 hours agoparentCredit goes to \"You Suck at Cooking\" for their genius smash burger recipe [0] for my lunch that day [0] https://www.youtube.com/watch?v=nq9WnmCGoFQ reply highcountess 1 hour agoprevDev palms just got that much more sweaty. reply risyachka 3 hours agoprev>> The AI went from: >> \"This file contains authentication logic using JWT tokens\" So what was the initial prompt? \"What's in this file?\" And then you added context and it became context-aware. A bit of an overstatement to call this \"Holy Shit moment\" Also , why is \"we\"? What is \"our AI\"? And what is \"our benchmark script\"? And how big is your codebase? 50k files? 20 files? This post has very very little value without a ton of details, looks like nowadays everything \"ai\" labeled gets to the front page. reply dijksterhuis 2 hours agoparent> looks like nowadays everything \"ai\" labeled gets to the front page. it’s been this way for like a year or more. hype machine gotta hype. reply quantadev 2 hours agoprev [–] In my Coding Agent, I ended up realizing my prompts need to be able to specifically mention very specific areas in the code, for which no real good syntax exists for doing that so I invented something I call \"Named Blocks\". My coding agent allows you to put any number of named blocks in your code and then mention those in your prompts by name, and the AI understands what code you mean. Here's an example: In my code: -- block_begin SQL_Scripts ...some sql scripts... -- block_end Example prompt: Do you see any bugs in block(SQL_Script)? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The AI was initially challenged with analyzing React codebases, approaching them like a novice developer. - By emulating senior developers' strategies, such as focusing on core files and grouping changes by feature, the AI's code analysis improved significantly. - The focus is on enhancing code understanding rather than generation, with future plans to identify technical debt and comprehend team conventions."
    ],
    "commentSummary": [
      "The article explores the challenges of training AI to read and analyze code with the proficiency of a senior developer, noting the difficulty in achieving consistent and accurate results.",
      "It stresses the importance of providing context and structuring inputs to enhance AI performance in code analysis, while acknowledging skepticism about AI's current capabilities.",
      "The discussion highlights the need for further experimentation and evaluation to validate AI's performance and considers the broader implications and potential advancements of AI in software development."
    ],
    "points": 293,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1736086519
  },
  {
    "id": 42599102,
    "title": "Web page annoyances that I don't inflict on you here",
    "originLink": "http://rachelbythebay.com/w/2025/01/04/cruft/",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=42599102",
    "commentBody": "Web page annoyances that I don't inflict on you here (rachelbythebay.com)248 points by todsacerdoti 17 hours agohidepastfavorite129 comments wruza 12 hours agoI don't keep a \"dick bar\" that sticks to the top of the page to remind you which site you're on. Your browser is already doing that for you. A variation of this is my worst offender, the flapping bar. Not only it takes space, it flaps every time I adjust my overscroll by pulling back, and it covers the text I was trying to adjust. The hysteresis to hide it back is usually too big and that makes you potentially overscroll again. Special place in hell for those who hide the flap on scroll-up but show it again when the scroll inertia ends, without even pulling back. Can’t say here what I think about people who do the above, but you can imagine. reply hombre_fatal 8 hours agoparentFunnily enough for years I would say the general consensus on HN was that it was a thoughtful alternative to having to scroll back to the top, esp back when it was a relatively new gimmick on mobile. I remember arguing about it on HN back when I was in uni. reply wruza 5 hours agorootparentIt can actually be done correctly, like e.g. safari does it in the top-urlbar mode. - When a user scrolls content-up in any way, the header collapses immediately (or you may just hide it). - When a user scrolls content-down by pulling, without \"a kick\", then it stays collapsed. - When a user \"kick\"-scrolls content-down, i.e. scrolls carelessly, in a way that a when finger lifts, scroll still has inertia -- then it gets shown again. Maybe with a short activation distance or inertia level to prevent ghost kicks. As a result, adjusting text by pulling (including repeatedly) won't flap anything, and if a user kick-scrolls, then they can access the header, if it has any function to it. It sort of separates content-down scroll into two different gestures, which you just learn and use appropriately. But instead most sites implement the most clinical behavior as described in the comment above. If a site does that, it should be immediately revoked a dns record and its owner put on probation, at the legislative level. reply dredmorbius 7 hours agorootparentprevMost mobile browsers lack a \"home\" key equivalent (or bury it in a not-always-visible on-screen soft-keyboard). That's among the very few arguments in favour of a \"Top\" navigation affordance. I still hate such things, especially when using a desktop browser. reply oneeyedpigeon 7 hours agorootparentI think some, if not most, mobile browsers - even apps - used to implement it via a space near the top of the window/screen. That seems to have gone away, though. reply dredmorbius 6 hours agorootparentWorse: \"pull to refresh\" means that often when you try to scroll to the top of a page ... it reloads instead. The number of times this has happened whilst I've been editing a post on some rando site, losing my content ... reply wruza 6 hours agorootparentprevIt works since forever on ios in most (native) apps, including the browser. Tap on the \"clock\" to scroll up - that is the home button. In safari you might need to tap again, if the header was collapsed. reply cr125rider 6 hours agorootparentprevDouble tap the top bar and almost all scrolling panels on iOS will whoosh to the top reply oneeyedpigeon 5 hours agorootparentThis is definitely an Android failing, in that case. reply imoreno 16 hours agoprevI agree with most of this. If every website followed these, the web would be heaven (again)... But why this one? >I don't force you to use SSL/TLS to connect here. Use it if you want, but if you can't, hey, that's fine, too. What is wrong with redirecting 80 to 443 in today's world? Security wise, I know that something innocuous like a personal blog is not very sensitive, so encrypting that traffic is not that important. But as a matter of security policy, why not just encrypt everything? Once upon a time you might have cared about the extra CPU load from TLS, but nowadays it seems trivial. Encrypting everything arguably helps protect the secure stuff too, as it widens the attacker's search space. These days, browser are moving towards treating HTTP as a bug and throw up annoying propaganda warnings about it. Just redirecting seems like the less annoying option. reply throwaway58670 7 hours agoparentSome old-enough browsers don't support SSL. At all. Also, something I often see non-technical people fall victim to is that if your clock is off, the entirety of the secure web is inaccessible to you. Why should a blog (as opposed to say online banking) break for this reason? reply Gud 3 hours agorootparentHow old are these browsers and why should I let them online? Must be decades old. reply niutech 1 hour agorootparentAndroid versions prior to 4.4 support only TLS 1.0 which is deprecated and many old devices aren't upgradable. The same for Mobile IE 10. IE 10 in Windows Server 2008 doesn't support TLS 1.1+ by default. reply nayuki 16 hours agoparentprevWhen you force TLS/HTTPS, you are committing both yourself (server) and the reader (client) to a perpetual treadmill of upgrades (a.k.a. churn). This isn't a value judgement, it is a fact; it is a positive statement, not a normative statement. Roughly speaking, the server and client softwares need to be within say, 5 years of each other, maybe 10 years at maximum - or else they are not compatible. For both sides, you need to continually agree on root certificates (think of how the ISRG had to gradually introduce itself to the world - first through cross-signing, then as a root), protocol versions (e.g. TLSv1.3), and cipher suites. For the server operator specifically, you need to find a certificate authority that works for you and then continually issue new certificates before the old one expires. You might need to deal with ordering a revocation in rare cases. I can think of a few reasons for supporting unsecured HTTP: People using old browsers on old computers/phones (say Android 4 from 10 years ago), extremely outdated computers that might be controlling industrial equipment with long upgrade cycles, simple HTTP implementations for hobbyists and people looking to reimplement systems from scratch. I haven't formed a strong opinion on whether HTTPS-only is the way to go or dual HTTP/HTTPS is an acceptable practice, so I don't really make recommendations on what other people should do. For my own work, I use HTTPS only because exposing my services to needless vulnerabilities is dumb. But I understand if other people have other considerations and weightings. reply imoreno 16 hours agorootparent>the server and client softwares need to be within say, 5 years of each other, maybe 10 years at maximum That's a fair point. HTTP changes more slowly. Makes sense for sites where you're aiming for longevity. reply lstamour 13 hours agorootparentExcept it's not actually true. https://www.ssllabs.com/ssltest/clients.html highlights that many clients support standard SSL features without having to update to fix bugs. How much SSL you choose to allow and what configurations is between you and your... I dunno, PCI-DSS auditor or something. I'm not saying SSL isn't complicated, it absolutely is. And building on top of it for newer HTTP standards has its pros and cons. Arguably though, a \"simple\" checkbox is all you would need to support multiple types of SSL with a CDN. Picking how much security you need is then left to an exercise to the reader. ... that said, is weak SSL better than \"no SSL\"? The lock icon appearing on older clients that aren't up to date is misleading, but then many older clients didn't mark non-SSL pages as insecure either, so there are tradeoffs either way. But enabling SSL by default doesn't have to exclude clients necessarily. As long as they can set the time correctly on the client, of course. I've intentionally not mentioned expiring root CAs, as that's definitely an inherent problem to the design of SSL and requires system or browser patching to fix. Likewise https://github.com/cabforum/servercert/pull/553 highlights that some browsers are very much encouraging frequent expiry and renewal of SSL certificates, but that's a system administration problem, not technically a client or server version problem. As an end user who tries to stay up to date, I've just downloaded recent copies of Firefox on older devices to get an updated list of SSL certificates. My problem with older devices tends to be poor compatibility with IPv6 (an addon in XP SP2/SP3 not enabled by default), and that web developers tend to use very modern CSS and web graphics that aren't supported on legacy clients. On top of that, you've HTML5 form elements, what displays when responsive layouts aren't available (how big is the font?), etc. Don't get me wrong, I love the idea of backwards compatibility but it's a lot more work for website authors to test pages in older or obscure browsers and fix the issues they see. Likewise, with SSL you can test on a legacy system to see how it works or run Qualys SSL checker, for example. Browsers maintain forwards-compatibilty but only to a point (see ActiveX, Flash in some contexts, Java in many places, thetag, framesets, etc.) So ultimately compatibility is a choice authors make based on how much time they put into testing for it. It is not a given, even if you use a subset of features. Try using Unicode on an early browser, for example. I still remember the rails snowman trick to get IE to behave correctly. reply bigs 12 hours agoparentprevWhy should web browsers treat http like a bug? Many sites don’t need https. reply yjftsjthsd-h 11 hours agorootparent> Many sites don’t need https. Maybe intranet sites. Everything else absolutely should. https://doesmysiteneedhttps.com/ reply muppetman 10 hours agorootparentThose are some of the most pedantic grasping at straws reasons I've ever read. It's like they know there's nothing wrong with http so they've had to invent worst case nightmare scenarios to make their \"It's so important\" reasons stick. Https is great. I use it. That website is pathetic though. reply fractallyte 5 hours agorootparentThe source footer (\"View Page Source\") summarizes it perfectly: Sites that need HTTPS: - all of them If you like it, you better put a lock on it. And, BTW, the website is as delightfully simple and unobtrusive as the one in the article. reply kdmtctl 16 hours agoparentprevIt's fine on a simple site. But lack of SSL/TLS also effectively disables http2 which is a performance hit, not just a security concern. reply drpixie 14 hours agorootparent>>I don't force you to use SSL/TLS to connect here. Use it if you want, but if you can't, hey, that's fine, too. She accepts http AND https requests. So it's your choice, you want to know who you're talking to, or you want speed :) reply hackingonempty 16 hours agoprev> I don't keep a \"dick bar\" that sticks to the top of the page to remind you which site you're on. I use an extension called \"Bar Breaker\" that hides these when you scroll away from the top/bottom of the page.[0] More people should know about it. [0] https://addons.mozilla.org/en-US/firefox/addon/bar-breaker/ reply imoreno 15 hours agoparentIt's annoying that every time \"they\" come up with a new antipattern, \"we\" have to add yet another extension to the list of mandatory things for each browser. And it also promotes browser monopoly because extensions get ported slowly to non-mainstream browsers. It would be better to have a single extension like uBlock origin to handle the browser compatibility, and then release the countermeasures through that. In fact, ublock already has \"Annoyances\" lists for things like cookie banners, but I don't think it includes the dick bar unfortunately. Incidentally, these bars are always on sites where the navbar takes 10% vertical space, cookie banner (full width of course) takes another 30% at the bottom, their text is overspaced and oversized, the left/right margins are huge so the text is like 50% of the width... Don't these people ever look at their own site? With many of these, I'm so confused how anyone could look at it and say it's good to go. reply wilkystyle 14 hours agorootparentIt's not a silver bullet, but I do the following with uBlock Origin: 1. JS disabled by default, only enabled on sites I choose 2. Filter to fix sites that mess with scrolling: ##html:style(scroll-behavior: auto !important;) 3. Filters for dick bars and other floating elements: ##*:matches-css(position:fixed) ##*:matches-css(position:sticky) reply teddyh 14 hours agorootparentprevThe president was very insistent that we show popup ads at six different points in time, until he got home and got six popup ads, and said, “You know what? Maybe just two popups.” — Joel Spolsky, What is the Work of Dogs in this Country? (2001):reply threefour 9 hours agorootparentThe OP blames \"various idiot web 'designers'\" for problems, but in my 30 years of being a web designer I have yet to meet one designer that wants to cause these problems. It's usually people responsible for generating revenue. reply ryandrake 2 hours agorootparentThe web designers and developers are at the very least complicit. They are ultimately the ones typing in the code and hitting submit, so they at least must share the blame. reply yakshaving_jgt 9 hours agorootparentprevIn my career of roughly half as long, I have met plenty. Although it’s also true that it’s often people higher up who are amused by design gimmicks. reply wruza 12 hours agorootparentprevExtensions are already there: ubo, stylebot. We just have to invent a way to share user-rule snippets across these. There will always be a gray zone between trusted adblock lists included by default and some preferential things. reply xp84 16 hours agoparentprevNice. This may be my pet peeve on the modern internet. Nearly EVERY site has a dick bar, and the reason I care is it breaks scrolling with spacebar, which is THE most comfortable way to read long content, it scrolls you a screen at a time. But a dickbar obscures the first 1 to…10? lines of the content, so you have to scroll back up. The only thing worse than the dickbar is the dickbar that appears and disappears depending on last direction scrolled, so that each move of the scrolling mechanism changes the viewport size. A pox on them all. reply robertoandred 15 hours agorootparentNote to web devs: use scroll-padding to fix this: https://developer.mozilla.org/en-US/docs/Web/CSS/scroll-padd... reply dredmorbius 12 hours agorootparentNo. Just kill the fucking dickbar. reply resonious 12 hours agorootparentprevDick bar often breaks hash links as well. You click a link that scrolls you to a section, but you can't see the first few lines of it. reply nayuki 16 hours agorootparentprev> Nearly EVERY site has a dick bar, and the reason I care is that when reading on my laptop screen, it takes up valuable vertical space on a small display that is in landscape mode. I want to use my screen's real estate to read the freaking content, not look at your stupid branding bar. And I don't need any on-page assistance to jump back to the top of the page and/or find the navigation. I have a \"Home\" key on my keyboard and use it frequently. reply oneeyedpigeon 7 hours agorootparentTBF, many people don't have that Home key. I agree with you, though - there should be a better solution. At the very least, just have an optional \"Top of page\" toolbar button in your browser. reply P-Nuts 5 hours agorootparentCtrl+↑ reply oneeyedpigeon 5 hours agorootparentThat's one option. On macOS, it's fn + Left. On Android, I'm not sure there's anything. reply Doctor_Fegg 12 hours agorootparentprevIIRC (as a fellow spacebar aficionado) position:fixed breaks spacebar scrolling but position:sticky generally doesn’t. reply aembleton 6 hours agoparentprevI just toggle reader mode. Gets rid of this and everything else annoying. For sites where that doesn't work, I zap the bar in uBO. reply niutech 1 hour agorootparentBrave has an excellent Speedreader mode. reply kerkeslager 14 hours agoparentprevI am usually the first old man to yell at any cloud, and I was overjoyed when someone invented the word \"enshittening\" for me to describe how the internet has gotten, but it surprised me a bit that people found that one annoying. I can see the problem of it sticking the top of the page with a logo (which is basically an ad and I hate those), but they usually have a menu there, so I always thought of them a bit like the toolbar at the top of an application window in a native desktop application. FWIW when I've built those, I've always de-emphasized the branding and focused on making the menus obvious and accessible. I'm happy to learn something new about other people's preferences, though. If people prefer scrolling to the top, so be it! EDIT: It occurs to me that this could be a preference setting. A few of the websites that have let me have my way, I've started generating CSS from a Django template and adding configuration options to let users set variables like colors--with really positive feedback from disabled users. At a fundamental level, I think the solution to accessibility is often configurability, because people with different disabilities often need different, mutually incompatible accommodations. reply st-keller 9 hours agorootparentThis is exactly what CSS was designed for: allowing you to define your personal style preferences in your browser, applying them across all websites. The term ‘cascading’ reflects this purpose. Unfortunately, the web today has strayed far from its original vision. Yet, we continue to rely on the foundational technologies that were created for that very vision. reply ryandrake 2 hours agorootparentIMO browsers are broadly dropping the ball and failing to be \"the user's agent.\" Instead they are the agents of web developers, giving them the powers that users should have. If browsers catered to their user's desires more than they cater to developers, the web wouldn't be so shitty. reply kalensh 13 hours agorootparentprevAnother thing to check for with sticky headers is how it behaves when the page is zoomed. Often, the header increased in size proportionately, which can shrink down the effective reading area quite a bit. Add in the frequent sticky chat button at the bottom, and users may be left with not a lot of screen to read text in. There can be a logic to keeping the header at the top like a menu bar, and I applaud you if you take an approach that focuses on value to the user. Though I'd still say most sites that use this approach, don't have a strong need for it, nor do they consider smaller viewports except for portrait mobile. Configuration is great, though it quickly runs into discoverability issues. However it is the only way to solve some things - like you pointed out with colors. I know people who rely on high contrast colors and others that reduce contrast as much as they effectively can. reply albert_e 13 hours agoprevThey did not mention -- Text littered with hyperlinks on every sentence. Hyperlinks that do on-hover gimmicks like load previews or charts. Emojis or other distracting graphics (like stock ticker symbols and price indicators GOOG +7%) littered among the text. Backgrounds and images that change with scrolling. Popups asking to allow the website to send you notifications. Page footers that are two pages high with 200 links. Fine print and copyright legalese. Cookie policy banners that have multiple confusing options and list of 1000 affiliate third parties. Traditional banner and text ads. Many other dark patterns. reply lelanthran 12 hours agoparent> Hyperlinks that do on-hover gimmicks like load previews or charts. I haven't seen one that shows charts, but I gotta admit, I miss the hover preview when not reading wikipedia. reply oneeyedpigeon 7 hours agorootparentSomething else that should absolutely be a browser-native feature rather than one each site has to optionally invent poorly and/or inconsistently. reply niutech 1 hour agorootparentBlink-based browsers have a built-in link preview in a popup which you can turn on. reply albert_e 6 hours agorootparentprevAgreed, as long as it can be turned off by user on the browser, and doing so does not break the site / ux. reply dredmorbius 12 hours agoparentprevAnother: \"Related\" interstitial elements scattered within an article. Fucking NPR now has ~2--6 \"Related\" links between paragraphs of a story. I frequently read the site via w3m, and yes, will load the rendered buffer in vim (-e) to delete those when reading an article. I don't know if it's oversensitisation or progressive cognitive decline, but even quite modest distracting cruft is increasingly intolerable. If you truly have related stories, pile them at the end of the article, and put in some goddamned microcontent (title, description, publication date) for the article. As I've mentioned previously, my \"cnn-sanify\" script which strips story links and headlines from CNN's own \"lite\" page, and restructures those into section-organised, time-sorted presentation. Mostly for reading from the shell, though I can dump the rendered file locally and read it in a GUI browser as well. See:My biggest disappointment: CNN's article selection is pretty poor. I'd recently checked against 719 stories collected since ~18 December 2024, and of the 111 \"US\" stories, 54% are relatively mundane crime. Substantive stories are the exception. (The sense that few of the headlines really were significant was a large part of why I'd written the organisation script in the first place.) reply nayuki 1 hour agorootparent> put in some goddamned microcontent (title, description, publication date) for the article Do you mean metadata? reply ericrallen 4 hours agoparentprevI really appreciate hyperlinks that serve as citations, like “here’s some prior art to back up what I’m saying,” or that explain some joke, reference, jargon, etc. that the reader might not be familiar with, but unfortunately a lot of sites don’t use them that way. reply rchaud 5 hours agoparentprev> Text littered with hyperlinks on every sentence. This is the biggest hassle associated with reading articles online. I'm never going to click on those links because: - the linked anchor text says nothing about the website it's linking to - the link shows a 404 (common with articles 2+ years old) - the link is probably paywalled Very annoying that article writing guidelines are unchanges from the 2000s where linkrot and paywalls were almost unheard of. reply bshacklett 3 hours agoprev> I don't do some half-assed horizontal \"progress bar\" as you scroll down the page. Your browser probably /already/ has one of those if it's graphical. It's called the scroll bar. (See also: no animations.) Sadly, I would argue that this is inaccurate. Especially on mobile browsers, the prevalence of visible scroll bars seems to have dropped off a cliff. I'll happily excuse the progress bar, especially because this one can be done without JavaScript. reply swyx 16 hours agoprevthis is exactly the sort of idealistic post that appeals to HN and nobody else. i dont have a problem with that apart from when technologists try to take these \"back to basics\" stuff to shame the substacks and the company blogs out there that have to be more powered by economics than by personal passion. its -obvious- things are mostly \"better\"/can be less \"annoying\" when money/resources are not a concern. i too would like to spend all my time in a world with no scarcity. the engineering challenge is finding alignments where \"better for reader\" overlaps with \"better for writer\" - as google did with doubleclick back in the day. reply jmathai 13 hours agoparentMost people don't remember, and some have never experienced, the Internet before it became a money grab. I think a lot of people outside of HN would prefer that Internet way more than what we have now. reply scarface_74 13 hours agorootparentThe Web has been a money grab since Netscape was went public in 1995. My first for pay project was enhancing a Gopher server in 1993. reply jmathai 5 hours agorootparentSome people making money on the Internet is a lot different than what the Internet has become today - and what I meant by money grab. reply scarface_74 3 hours agorootparentYou do remember the entire dot com boom and bust, the punch the monkey banner ads, X11 pop under ads, etc? Don’t romanticize the early internet. reply imoreno 16 hours agoparentprevTo me, it seems like basically everything on this page is both better for reader and better for writer. Which ones are not, in your opinion? reply lolinder 16 hours agorootparentAll the tracking stuff is better for advertisers than going without, and most writers are paid by advertisers. So transitively it would be reasonable to say that tracking is good for writers and bad for readers. reply imoreno 15 hours agorootparentPeople oversell this tracking/advertising. It's not a goldmine for every site. For this blog, if she wanted to include analytics into her decision about what content to produce, does she really need super high resolution stuff like where people moved their mouse? Would she ever make a significant income from these \"ads\", or selling the data for possibly pennies? Besides, just google analytics or something like that wouldn't be that bad (I know the blog author would disagree). A lot of sites go nuts and have like 20 different trackers that probably track the same things. People just tack stuff on, YAGNI be damned, that's a big part of the problem and it's a net drain on both parties. reply MathMonkeyMan 16 hours agoparentprevThe author isn't trying to profit from the reader's attention; it's just a personal blog. An ad-based business would. Neither is right or wrong, but the latter is distinctly annoying. reply NotYourLawyer 15 hours agorootparentAd-based businesses are indeed wrong and immoral. reply StressedDev 12 hours agorootparentAd-based businesses exist because a lot of people (including many on this forum) refuse to pay for anything. During the late 1990s/early 2000s, people hated paying for anything and demanded that everything on the Internet should be free. Well, that led to the vast surveillance machine which powers Google, Facebook, and every ad-tech business out there. They need surveillance because it lets them serve more relevant ads and more relevant ads make more money. The bottom line is if you hate ad-based businesses, start paying for things. reply mft_ 7 hours agorootparentA personal take is that ad-based businesses exist because there’s no secure widespread reliable approach for micropayments (yet?). The mean value of adverts on a page is in the order of a tiny fraction of a cent per reader, which is presumably enough for the businesses that continue to exist online. If it was possible to pay this amount directly instead, and have an ad-free experience, I suspect many would do so, as the cumulative amount would usually be negligible. Yet so far, no-one’s figured it out. (I should mention, there are very strong reasons why it’s difficult to figure out currently, but AIUI these are rooted in the current setup of global payments and risk management by credit card companies.) reply wruza 12 hours agorootparentprevDoes this work? Which paid platform doesn’t eventually start showing ads to paid users? reply oneeyedpigeon 6 hours agorootparentPinboard is the obvious example that springs to mind. reply NotYourLawyer 12 hours agorootparentprevYes, it’s the individuals’ fault. Google, FB, and the rest need to spy on us! I feel just awful for those poor companies. No. If your business model requires you to do evil things, your business should not exist. Anyway, I do pay for services that provide value. I was a paying Kagi customer until recently, for example (not thrilled with the direction things are going there now though). reply Dweller1622 11 hours agorootparentWhat is the direction that things are going at Kagi now? What were they before? reply NotYourLawyer 10 hours agorootparentAll the AI shit, plus this https://old.reddit.com/r/ukraine/comments/1gvcqua/psa_the_ka... reply StressedDev 12 hours agoparentprevSubstack's UI is fairly minimal and does not appear to have many anti-patterns. My only complaint is that it is not easy to see just the people I am subscribed to. reply nayuki 10 hours agorootparentSubstack fails on several points for me. On the first or second page view of any particular blog, the platform likes to greet you with a modal dialog to subscribe to the newsletter, and you have to find and click the \"No thanks\" text to continue. Once you're on a page with text content, the header bar disappears when you scroll downward but reappears when you scroll upward. I scroll a lot - in both directions - because I skim and jump around, not reading in a rigidly linear way. My scrolling behavior is perfectly fine on static/traditional pages. It interacts badly with Substack's \"smart\" header bar, whose animation constantly grabs my attention, and also it hides the text at the top of the page - which might be the very text I wanted to read if it wasn't being covered up by the \"smart\" header bar. reply ghssds 11 hours agorootparentprevSubstack disable zooming on mobile and I hate it. reply arrowsmith 9 hours agorootparentReally? I can still zoom in and out in the normal way on a Substack article on Safari and iOS. What did they disable exactly? reply oneeyedpigeon 6 hours agorootparentI see the zoom-breaking on android. I also see the top and bottom dick bars, a newsletter popup on every article, and links opening in new windows. reply matheusmoreira 14 hours agoparentprevThis actually appeals to everyone. There are words and people can read them. It literally just works. With zero friction. This is peak engineering. It's how the web is supposed to work. It is objectively better. For everyone. Everyone except advertisers. The only problem to be solved here is the fact advertisers are the ones paying the people who make web pages. They're the ones distorting the web into engagement maximizing content consumption platforms like television. reply fragmede 14 hours agorootparentThe words are nice and all, but it's no https://ciechanow.ski/ reply skydhash 13 hours agorootparentThe nice thing about your example is that it works even in eww (emacs), and quite well (not the JS part, of course). reply ajb 6 hours agoprevIt's amazing to me what people tolerate, just because it doesn't seem like a human is doing it to us. If a door-to-door salesman was told to do the equivalent of this stuff, they'd be worried about being punched in the face. reply wruza 5 hours agoparentThe logic here is that it's you who come to visit, not them. But the next issue is that everyone agrees it's not normal for a private service either, even if it's free, and it should be disallowed. But laws don't work like that. We simply have no law systems that could manage that, nowhere on this planet. reply nicbou 2 hours agoparentprevImagine if people understood consent the way the tech industry does. reply ryandrake 2 hours agorootparentIf the world was a nightclub, the tech industry would be a creepy guy who goes up to everyone and says \"You're now dating me. [Accept or Try Again Later]\" reply winterbloom 1 hour agoprevDisagree with a few of these There's nothing wrong with progress. Expecting a user to have a JavaScript enabled browser is reasonable You don't expect an online retailer to accept mailed-in cash, do you? reply rchaud 5 hours agoprevWhile an interesting post because of the number of examples provided, this does read like somebody patting themselves on the back for building a website like it's 1995, when websites were not designed with the intention of making money or acting as a lead gen funnel. Let's have a look at the websites she's helped build at her job and see how many of those old web principles were applied. reply niutech 1 hour agoparentYou can make a profitable text-only website, e.g. Craigslist. But not everything on the web should be for profit. reply lenkite 7 hours agoprevactually bookmarked since Rachel has mentioned several annoyances that it is easy to accidentally include even if you have the best of intentions. Wish she gave this in checklist and categorized form instead of long-text. LOL'ed at \"dick bar\" - seriously that thing is so annoying. reply ValdikSS 11 hours agoprevThe page is so narrow, like it's made for a vertical smartphone screen. That's ANNOYING! reply nayuki 10 hours agoparentLook up any typographic manual and you'll learn that you can't make lines of text too wide or else people will have trouble reading them. Example - https://practicaltypography.com/line-length.html . This is also related to why professional newspapers and magazines lay out text in relatively narrow columns, because they are easy to scan just top-down while hardly moving your eyes left-right. I do think that vertical phones are too narrow for conveying decent text, but you also can't have completely unbounded page widths because people do run browsers maximized on desktop 4K screens. reply ryandrake 2 hours agorootparentThat research may be true, but the layout of the page should be up to the user, not imposed by the developer. If I want my browser to display a web page using the entire maximized 4K browser window, that should be something 1. I can easily configure and 2. web developers respect, no matter what the \"typographic researchers\" think. reply dredmorbius 7 hours agorootparentprevThat's true, but 60 characters is way toward the \"too narrow\" side of the scale. I'd fatten the page to ~45--55 em (or rem), and BTW, strongly prefer relative font-sized units to pixels, which ... are increasingly unreliable as size determinants, particularly as high-def, high-dot-pitch displays on monitors, smartphones, and e-ink displays become more common. Toto we're not in 96 dpi land any more. I also strongly prefer at least some padding around the edges of pages / text regions, with 5--10% usually much easier to read. I'd played with making those changes on Rachel's page through Firefox's inspector: html { font-family: garamond, times, serif; } body { max-width: 50em; } .post { padding 2em 4em; } To my eye that improves things greatly. (I generally prefer serif to sans fonts, FWIW.) reply rchaud 5 hours agorootparentprevWell, that site also has this: https://practicaltypography.com/columns.html The style of the page can use CSS column properties to make use of the width of laptop/tablet displays, instead of defaulting to ugly \"mobile size fits all\" templates. reply frogulis 13 hours agoprev> I don't pretend that posts are evergreen by hiding their dates. I didn't realise that hiding dates for the illusion of evergreen-ness was a desirable thing! On my personal site I added dates to existing pages long after they were uploaded for the very reason I wanted it to be plenty clear that they were thoughts from a specific time. For example, a bloggish post I wrote where, while I still think it's right, it now sounds like linkedin wank. I'm very happy for that one to be obviously several years old. reply arrowsmith 9 hours agoparentSupposedly it’s an SEO thing. The theory is that Google is biased towards novelty and so penalises older articles (although I’m not sure how removing the date would help because surely Google would still know how long the article has been online for.) I have no idea how true that is but I remember hearing SEO folks talk about it a few years back. reply AHTERIX5000 4 hours agorootparentSome content mills seem to display a date but automatically update it periodically. Sometimes you can outright see it can't be correct since the information is woefully out of date or you can check from Internet Archive that the content is the same as before but with a bumped date. reply oneeyedpigeon 7 hours agoprevSuch a good list, I may have to copy it for my own site and stuff it somewhere as a \"colophon\" of sorts. Maybe this kind of thing should even be a machine-readable standard... Rachel, I'm curious as to your mentions of 'old posts' that may not be compliant, e.g. missing an alt attribute - is this something you've considered scanning your html files for and fixing? reply xnx 5 hours agoprevPreviously I've used the \"disable styles\" shortcut key in the Firefox web developer extension to make unfriendly websites more tolerable. Today, I wish Chrome had a shortcut key for enabling reader mode to do the same. reply tasuki 10 hours agoprevThe one annoyance inflicted is the pointless container-for-everything with rounded corners. It makes the web page optically smaller on mobile and seems to serve no purpose. Just extend the background to the very corners like hacker news does! reply sircastor 10 hours agoprevOver the last year I’ve gotten a couple of offers from PCB manufactures to make my projects in exchange for a review and visibility in my projects and on my site. It was tempting, but every time I thought about doing it, it felt off. I really like writing to readers and not obligating them to anything else. No sales push, no ads, no sign ups. It’s nice that it’s just what I wanted to share. reply nayuki 16 hours agoprevI agree with pretty much everything on that page except: > Web page annoyances that I don't inflict on you here / I don't use visitor IP addresses outside of a context of filtering abuse. This point bit me personally about 5 years ago. As I browsed HN at home, I found that links to her website would not load - I would get a connection timed out error. Sometimes I would bookmark those pages in the hopes of reading them later. By accident, I noticed that her website did load when I was using public Wi-Fi or visited other people's homes. I assumed it was some kind of network routing error, so I emailed my Canadian ISP to ask why I couldn't load her site at my home. They got back to me quickly and said that there were no networking problems, so go email the site operator instead. I contacted Rachel and she said - and this is my poor paraphrasing from memory - that the IP ban was something she intentionally implemented but I got caught as a false positive. She quickly unbanned my IP or some range containing me, and I never experienced any problems again. And no, I never did anything that would warrant a ban; I clicked on pages as a human user and never botted her site or anything like that, so I'm 100% sure that I was collateral damage for someone else's behavior. The situation I saw was a very rare one, where I'd observe different behaviors depending on which network I accessed her site from. Sure, I would occasionally see \"verification\" requests from megacorps like Google/CAPTCHA, banks, Cloudflare, etc. when I changed networks or countries, but I grew to expect that annoyance. I basically never see specific bans from small operators like her. I don't fault her for doing so, though, as I am aware of various forms of network and computer system abuse, and have implemented a few countermeasures in my work sporadically. > I don't force you to use SSL/TLS to connect here. Use it if you want, but if you can't, hey, that's fine, too. Agreed, but I would like HN users to submit the HTTPS version. I'm not doing this to virtue-signal or anything like that. I'm telling you, a number of years ago when going through Atlanta airport, I used their Wi-Fi and clicked on a bunch of HN links, and the pages that were delivered over unsecured HTTP got rewritten with injections of the ISP's ads. This is not funny and we should proactively prevent that by making the HTTPS URL be the default one that we share. (I'm not against her providing an HTTP version.) As for everything else, I am so glad that her web pages don't have fixed top bars, the bloody simulated progress bar (I like my browser's scrollbar very much thank you), ample visual space wasted for ads (most mainstream news sites are guilty), space wasted mid-page to \"sign up to my email newsletter\", modal dialog boxes (usually also to sign up to newsletter), etc. reply o11c 16 hours agoparent> use the HTTPS version It's probably reasonable to use HSTS to force https-aware browsers to upgrade and avoid injection of all the things she hates. Dumb browsers like `netcat` are not harmed by this at all. But even then ... why aren't you using `curl` or something? reply Wowfunhappy 13 hours agorootparent> It's probably reasonable to use HSTS to force https-aware browsers to upgrade and avoid injection of all the things she hates. There's a broad spectrum between a browser that is \"aware\" of https and a browser that has all the cipher suites, certificates, etc to load a given page. reply StressedDev 12 hours agorootparentIf a browser does not support modern TLS (SSL), it probably also has unpatched security flaws. Unpatched browsers should never be used on the Internet because they will get hacked. reply Spivak 12 hours agorootparentSure but as a server operator, who cares? I already have zero trust in the client and it's not my job to punish the user for not being secure enough. If they get pwned, that's their problem. Unless I'm at work where there's compliance checkboxes to disallow old SSL versions I'll take whatever you have. reply FragenAntworten 12 hours agoparentprev> As I browsed HN at home, I found that links to her website would not load Thanks for mentioning this, because I was having the same issue and I was surprised no one was mentioning that the site was (appeared to be) down. Switching to using a VPN made the post available to me. reply joshdavham 13 hours agoprev> Safari recently gained the ability to \"hide distracting items\" I just looked into this feature and it looks awesome! Is there a way to do this in chrome? If not, are there any available chrome extensions that do this? reply wruza 11 hours agoparentIs there a way to do anything in chrome now? It became your personal google port and will soon disable any content-modification for the sake of your adsecurity and prinvadcy. reply dheera 13 hours agoprev> I don't do popups anywhere. You won't see something that interrupts your reading to ask you to \"subscribe\" and to give up your e-mail address. Every time I get hit with a popup by a site I usually just leave. Sometimes with a cart full of items not yet paid for. It's astounding that they haven't yet learned that this is actually costing them business. Never interrupt your customers. Same goes for stores. If I walk into your store to browse and you accost me with \"Can I help you\" I'll be looking for an exit ASAP. reply oneeyedpigeon 6 hours agoparent> Sometimes with a cart full of items not yet paid for. And then a week later you'll get an email \"Did you forget to buy all those products we're sure you want?...\" reply yakshaving_jgt 15 hours agoprevI think many of these are just design trends. As in, I think in a lot of cases web designers will add these “features” not for a deeply considered reason, but simply because that’s the thing everyone else seems to be doing. I’ve had to be pretty firm in the past with marketing teams that want to embark on a rebrand, and say however the design looks, it can’t include modal windows or animated carousels. And I think people think you’re weird when you say that. reply raegis 11 hours agoparent> I’ve had to be pretty firm in the past with marketing teams that want to embark on a rebrand, and say however the design looks, it can’t include modal windows or animated carousels. And I think people think you’re weird when you say that. Some small businesses create websites for branding only, and get their business exclusively offline. They just want to have a simple, static site to say \"we exist, and we are professionals\", so they are fine with the latest in web design. reply yakshaving_jgt 9 hours agorootparentRight. What I’m suggesting is their simple static site should probably just show the content they want to show, rather than write extra code [and add additional complexity] which makes that content gratuitously slide around the screen. reply Waterluvian 16 hours agoprevIs there a way to instruct browsers, when available, to just go right into reader mode? I wonder if when your page is so minimal like this one, you may as well just do that instead. Or I guess at that point, you just don’t do styles? Of all the things some people don’t do with their webpage, I’m the biggest fan of not doing visual complexity. reply Zacharias030 16 hours agoparentMy iOS Safari has it. I turned it on for the NYT, because I wanted a dark theme and then turned it off again because I realized that I like what they do with their pages (still have an ad blocker turned on though, because subscribers still see tons of ads). reply joshka 4 hours agoprevFor the style of reading I normally do, this particular width is actively harmful to my reading comprehension. I would prefer just a bit wider text generally. This is something which the site does inflict on the reader. I agree that many sites are too wide in general, but this feels is too narrow by about 33% for my liking. Additionally the way that the background degrades to a border around the text when using dark reader also causes problems in a similar way (due to the interaction between jagged text and a strong vertical line. These are subtle points though, and I appreciate the many annoyances that are not there when reading Rachel's stuff. reply scarface_74 13 hours agoprevYet unlike the 20+ other websites that I can just copy the main url into NetNewsWire, it doesn’t seem to have an RSS feed… reply dredmorbius 12 hours agoparentnext [–](Under the RSS icon.) reply tedunangst 11 hours agoparentprevhttp://rachelbythebay.com/w/2024/12/10/feed/ reply StressedDev 12 hours agoparentprevPerhaps you should either file a bug with NetNewsWire, or debug NetNewsWire and submit a PR so it works with her blog. reply scarface_74 6 hours agorootparentSo we are now going back to special casing websites that don’t follow standards like the IE6 days? reply munch117 5 hours agorootparentDo you need special-casing to recognise? reply scarface_74 5 hours agorootparentUsing the link given from the website https://imgur.com/a/DkifnBG reply munch117 3 hours agorootparentThe w3.org validator says that https://rachelbythebay.com/w/atom.xml is a valid Atom 1.0 feed (https://validator.w3.org/feed/check.cgi?url=https%3A%2F%2Fra...). It does seem like something's off about the feed. Vienna can read the file, but it comes up empty. But it doesn't seem like the problem is standards non-compliance. reply skydhash 13 hours agoparentprevThis particular button is quite visible on the webpage reply scarface_74 12 hours agorootparentWith NetNewsWire even when you go to URL from the link https://imgur.com/a/DkifnBG reply oneeyedpigeon 6 hours agorootparentOther posters mentioned her IP block - I wouldn't be surprised if that was the cause since automated netnewswire traffic might easily be confused with abuse. reply andrewmcwatters 16 hours agoprevEveryone using HTTPS protects everyone. Having some operators choose to not migrate to HTTPS-only websites makes the web less secure by increasing the surface area of attacks on users. reply modzu 14 hours agoprev [–] thank you reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The author avoids using certain web features like sticky bars, forced SSL/TLS, pop-ups, and unnecessary tracking to enhance user experience.",
      "There is an ongoing debate about the necessity of HTTPS for security versus its compatibility issues with older browsers.",
      "The discussion highlights the challenge of balancing user experience with modern web practices."
    ],
    "points": 248,
    "commentCount": 129,
    "retryCount": 0,
    "time": 1736042093
  },
  {
    "id": 42600846,
    "title": "How Nat Traversal Works (2020)",
    "originLink": "https://tailscale.com/blog/how-nat-traversal-works",
    "originBody": "Blog|August 21, 2020 How NAT traversal works We covered a lot of ground in our post about How Tailscale Works. However, we glossed over how we can get through NATs (Network Address Translators) and connect your devices directly to each other, no matter what’s standing between them. Let’s talk about that now! Let’s start with a simple problem: establishing a peer-to-peer connection between two machines. In Tailscale’s case, we want to set up a WireGuard® tunnel, but that doesn’t really matter. The techniques we use are widely applicable and the work of many people over decades. For example, WebRTC uses this bag of tricks to send peer-to-peer audio, video and data between web browsers. VoIP phones and some video games use similar techniques, though not always successfully. We’ll be discussing these techniques generically, using Tailscale and others for examples where appropriate. Let’s say you’re making your own protocol and that you want NAT traversal. You need two things. First, the protocol should be based on UDP. You can do NAT traversal with TCP, but it adds another layer of complexity to an already quite complex problem, and may even require kernel customizations depending on how deep you want to go. We’re going to focus on UDP for the rest of this article. If you’re reaching for TCP because you want a stream-oriented connection when the NAT traversal is done, consider using QUIC instead. It builds on top of UDP, so we can focus on UDP for NAT traversal and still have a nice stream protocol at the end. Second, you need direct control over the network socket that’s sending and receiving network packets. As a rule, you can’t take an existing network library and make it traverse NATs, because you have to send and receive extra packets that aren’t part of the “main” protocol you’re trying to speak. Some protocols tightly integrate the NAT traversal with the rest (e.g. WebRTC). But if you’re building your own, it’s helpful to think of NAT traversal as a separate entity that shares a socket with your main protocol. Both run in parallel, one enabling the other. Direct socket access may be tough depending on your situation. One workaround is to run a local proxy. Your protocol speaks to this proxy, and the proxy does both NAT traversal and relaying of your packets to the peer. This layer of indirection lets you benefit from NAT traversal without altering your original program. With prerequisites out of the way, let’s go through NAT traversal from first principles. Our goal is to get UDP packets flowing bidirectionally between two devices, so that our other protocol (WireGuard, QUIC, WebRTC, …) can do something cool. There are two obstacles to having this Just Work: stateful firewalls and NAT devices. Figuring out firewalls Stateful firewalls are the simpler of our two problems. In fact, most NAT devices include a stateful firewall, so we need to solve this subset before we can tackle NATs. There are many incarnations to consider. Some you might recognize are the Windows Defender firewall, Ubuntu’s ufw (using iptables/nftables), BSD’s pf (also used by macOS) and AWS’s Security Groups. They’re all very configurable, but the most common configuration allows all “outbound” connections and blocks all “inbound” connections. There might be a few handpicked exceptions, such as allowing inbound SSH. But connections and “direction” are a figment of the protocol designer’s imagination. On the wire, every connection ends up being bidirectional; it’s all individual packets flying back and forth. How does the firewall know what’s inbound and what’s outbound? That’s where the stateful part comes in. Stateful firewalls remember what packets they’ve seen in the past and can use that knowledge when deciding what to do with new packets that show up. For UDP, the rule is very simple: the firewall allows an inbound UDP packet if it previously saw a matching outbound packet. For example, if our laptop firewall sees a UDP packet leaving the laptop from 2.2.2.2:1234 to 7.7.7.7:5678, it’ll make a note that incoming packets from 7.7.7.7:5678 to 2.2.2.2:1234 are also fine. The trusted side of the world clearly intended to communicate with 7.7.7.7:5678, so we should let them talk back. (As an aside, some very relaxed firewalls might allow traffic from anywhere back to 2.2.2.2:1234 once 2.2.2.2:1234 has communicated with anyone. Such firewalls make our traversal job easier, but are increasingly rare.) Firewall face-off This rule for UDP traffic is only a minor problem for us, as long as all the firewalls on the path are “facing” the same way. That’s usually the case when you’re communicating with a server on the internet. Our only constraint is that the machine that’s behind the firewall must be the one initiating all connections. Nothing can talk to it, unless it talks first. This is fine, but not very interesting: we’ve reinvented client/server communication, where the server makes itself easily reachable to clients. In the VPN world, this leads to a hub-and-spoke topology: the hub has no firewalls blocking access to it and the firewalled spokes connect to the hub. The problems start when two of our “clients” want to talk directly. Now the firewalls are facing each other. According to the rule we established above, this means both sides must go first, but also that neither can go first, because the other side has to go first! How do we get around this? One way would be to require users to reconfigure one or both of the firewalls to “open a port” and allow the other machine’s traffic. This is not very user friendly. It also doesn’t scale to mesh networks like Tailscale, in which we expect the peers to be moving around the internet with some regularity. And, of course, in many cases you don’t have control over the firewalls: you can’t reconfigure the router in your favorite coffee shop, or at the airport. (At least, hopefully not!) We need another option. One that doesn’t involve reconfiguring firewalls. Finessing finicky firewalls The trick is to carefully read the rule we established for our stateful firewalls. For UDP, the rule is: packets must flow out before packets can flow back in. However, nothing says the packets must be related to each other beyond the IPs and ports lining up correctly. As long as some packet flowed outwards with the right source and destination, any packet that looks like a response will be allowed back in, even if the other side never received your packet! So, to traverse these multiple stateful firewalls, we need to share some information to get underway: the peers have to know in advance the ip:port their counterpart is using. One approach is to statically configure each peer by hand, but this approach doesn’t scale very far. To move beyond that, we built a coordination server to keep the ip:port information synchronized in a flexible, secure manner. Then, the peers start sending UDP packets to each other. They must expect some of these packets to get lost, so they can’t carry any precious information unless you’re prepared to retransmit them. This is generally true of UDP, but especially true here. We’re going to lose some packets in this process. Our laptop and workstation are now listening on fixed ports, so that they both know exactly what ip:port to talk to. Let’s take a look at what happens. The laptop’s first packet, from 2.2.2.2:1234 to 7.7.7.7:5678, goes through the Windows Defender firewall and out to the internet. The corporate firewall on the other end blocks the packet, since it has no record of 7.7.7.7:5678 ever talking to 2.2.2.2:1234. However, Windows Defender now remembers that it should expect and allow responses from 7.7.7.7:5678 to 2.2.2.2:1234. Next, the workstation’s first packet from 7.7.7.7:5678 to 2.2.2.2:1234 goes through the corporate firewall and across the internet. When it arrives at the laptop, Windows Defender thinks “ah, a response to that outbound request I saw”, and lets the packet through! Additionally, the corporate firewall now remembers that it should expect responses from 2.2.2.2:1234 to 7.7.7.7:5678, and that those packets are also okay. Encouraged by the receipt of a packet from the workstation, the laptop sends another packet back. It goes through the Windows Defender firewall, through the corporate firewall (because it’s a “response” to a previously sent packet), and arrives at the workstation. Success! We’ve established two-way communication through a pair of firewalls that, at first glance, would have prevented it. Creative connectivity caveats It’s not always so easy. We’re relying on some indirect influence over third-party systems, which requires careful handling. What do we need to keep in mind when managing firewall-traversing connections? Both endpoints must attempt communication at roughly the same time, so that all the intermediate firewalls open up while both peers are still around. One approach is to have the peers retry continuously, but this is wasteful. Wouldn’t it be better if both peers knew to start establishing a connection at the same time? This may sound a little recursive: to communicate, first you need to be able to communicate. However, this preexisting “side channel” doesn’t need to be very fancy: it can have a few seconds of latency, and only needs to deliver a few thousand bytes in total, so a tiny VM can easily be a matchmaker for thousands of machines. In the distant past, I used XMPP chat messages as the side channel, with great results. As another example, WebRTC requires you to come up with your own “signalling channel” (a name that reveals WebRTC’s IP telephony ancestry), and plug it into the WebRTC APIs. In Tailscale, our coordination server and fleet of DERP (Detour Encrypted Routing Protocol) servers act as our side channel. Stateful firewalls have limited memory, meaning that we need periodic communication to keep connections alive. If no packets are seen for a while (a common value for UDP is 30 seconds), the firewall forgets about the session, and we have to start over. To avoid this, we use a timer and must either send packets regularly to reset the timers, or have some out-of-band way of restarting the connection on demand. On the plus side, one thing we don’t need to worry about is exactly how many firewalls exist between our two peers. As long as they are stateful and allow outbound connections, the simultaneous transmission technique will get through any number of layers. That’s really nice, because it means we get to implement the logic once, and it’ll work everywhere. …Right? Well, not quite. For this to work, our peers need to know in advance what ip:port to use for their counterparts. This is where NATs come into play, and ruin our fun. The nature of NATs We can think of NAT (Network Address Translator) devices as stateful firewalls with one more really annoying feature: in addition to all the stateful firewalling stuff, they also alter packets as they go through. A NAT device is anything that does any kind of Network Address Translation, i.e. altering the source or destination IP address or port. However, when talking about connectivity problems and NAT traversal, all the problems come from Source NAT, or SNAT for short. As you might expect, there is also DNAT (Destination NAT), and it’s very useful but not relevant to NAT traversal. The most common use of SNAT is to connect many devices to the internet, using fewer IP addresses than the number of devices. In the case of consumer-grade routers, we map all devices onto a single public-facing IP address. This is desirable because it turns out that there are way more devices in the world that want internet access, than IP addresses to give them (at least in IPv4 — we’ll come to IPv6 in a little bit). NATs let us have many devices sharing a single IP address, so despite the global shortage of IPv4 addresses, we can scale the internet further with the addresses at hand. Navigating a NATty network Let’s look at what happens when your laptop is connected to your home Wi-Fi and talks to a server on the internet. Your laptop sends UDP packets from 192.168.0.20:1234 to 7.7.7.7:5678. This is exactly the same as if the laptop had a public IP. But that won’t work on the internet: 192.168.0.20 is a private IP address, which appears on many different peoples’ private networks. The internet won’t know how to get responses back to us. Enter the home router. The laptop’s packets flow through the home router on their way to the internet, and the router sees that this is a new session that it’s never seen before. It knows that 192.168.0.20 won’t fly on the internet, but it can work around that: it picks some unused UDP port on its own public IP address — we’ll use 2.2.2.2:4242 — and creates a NAT mapping that establishes an equivalence: 192.168.0.20:1234 on the LAN side is the same as 2.2.2.2:4242 on the internet side. From now on, whenever it sees packets that match that mapping, it will rewrite the IPs and ports in the packet appropriately. Resuming our packet’s journey: the home router applies the NAT mapping it just created, and sends the packet onwards to the internet. Only now, the packet is from 2.2.2.2:4242, not 192.168.0.20:1234. It goes on to the server, which is none the wiser. It’s communicating with 2.2.2.2:4242, like in our previous examples sans NAT. Responses from the server flow back the other way as you’d expect, with the home router rewriting 2.2.2.2:4242 back to 192.168.0.20:1234. The laptop is also none the wiser, from its perspective the internet magically figured out what to do with its private IP address. Our example here was with a home router, but the same principle applies on corporate networks. The usual difference there is that the NAT layer consists of multiple machines (for high availability or capacity reasons), and they can have more than one public IP address, so that they have more public ip:port combinations to choose from and can sustain more active clients at once. Multiple NATs on a single layer allow for higher availability or capacity, but function the same as a single NAT. A study in STUN We now have a problem that looks like our earlier scenario with the stateful firewalls, but with NAT devices: Our problem is that our two peers don’t know what the ip:port of their peer is. Worse, strictly speaking there is no ip:port until the other peer sends packets, since NAT mappings only get created when outbound traffic towards the internet requires it. We’re back to our stateful firewall problem, only worse: both sides have to speak first, but neither side knows to whom to speak, and can’t know until the other side speaks first. How do we break the deadlock? That’s where STUN comes in. STUN is both a set of studies of the detailed behavior of NAT devices, and a protocol that aids in NAT traversal. The main thing we care about for now is the network protocol. STUN relies on a simple observation: when you talk to a server on the internet from a NATed client, the server sees the public ip:port that your NAT device created for you, not your LAN ip:port. So, the server can tell you what ip:port it saw. That way, you know what traffic from your LAN ip:port looks like on the internet, you can tell your peers about that mapping, and now they know where to send packets! We’re back to our “simple” case of firewall traversal. That’s fundamentally all that the STUN protocol is: your machine sends a “what’s my endpoint from your point of view?” request to a STUN server, and the server replies with “here’s the ip:port that I saw your UDP packet coming from.” (The STUN protocol has a bunch more stuff in it — there’s a way of obfuscating the ip:port in the response to stop really broken NATs from mangling the packet’s payload, and a whole authentication mechanism that only really gets used by TURN and ICE, sibling protocols to STUN that we’ll talk about in a bit. We can ignore all of that stuff for address discovery.) Incidentally, this is why we said in the introduction that, if you want to implement this yourself, the NAT traversal logic and your main protocol have to share a network socket. Each socket gets a different mapping on the NAT device, so in order to discover your public ip:port, you have to send and receive STUN packets from the socket that you intend to use for communication, otherwise you’ll get a useless answer. How this helps Given STUN as a tool, it seems like we’re close to done. Each machine can do STUN to discover the public-facing ip:port for its local socket, tell its peers what that is, everyone does the firewall traversal stuff, and we’re all set… Right? Well, it’s a mixed bag. This’ll work in some cases, but not others. Generally speaking, this’ll work with most home routers, and will fail with some corporate NAT gateways. The probability of failure increases the more the NAT device’s brochure mentions that it’s a security device. (NATs do not enhance security in any meaningful way, but that’s a rant for another time.) The problem is an assumption we made earlier: when the STUN server told us that we’re 2.2.2.2:4242 from its perspective, we assumed that meant that we’re 2.2.2.2:4242 from the entire internet’s perspective, and that therefore anyone can reach us by talking to 2.2.2.2:4242. As it turns out, that’s not always true. Some NAT devices behave exactly in line with our assumptions. Their stateful firewall component still wants to see packets flowing in the right order, but we can reliably figure out the correct ip:port to give to our peer and do our simultaneous transmission trick to get through. Those NATs are great, and our combination of STUN and the simultaneous packet sending will work fine with those. (in theory, there are also NAT devices that are super relaxed, and don’t ship with stateful firewall stuff at all. In those, you don’t even need simultaneous transmission, the STUN request gives you an internet ip:port that anyone can connect to with no further ceremony. If such devices do still exist, they’re increasingly rare.) Other NAT devices are more difficult, and create a completely different NAT mapping for every different destination that you talk to. On such a device, if we use the same socket to send to 5.5.5.5:1234 and 7.7.7.7:2345, we’ll end up with two different ports on 2.2.2.2, one for each destination. If you use the wrong port to talk back, you don’t get through. Naming our NATs Now that we’ve discovered that not all NAT devices behave in the same way, we should talk terminology. If you’ve done anything related to NAT traversal before, you might have heard of “Full Cone”, “Restricted Cone”, “Port-Restricted Cone” and “Symmetric” NATs. These are terms that come from early research into NAT traversal. That terminology is honestly quite confusing. I always look up what a Restricted Cone NAT is supposed to be. Empirically, I’m not alone in this, because most of the internet calls “easy” NATs Full Cone, when these days they’re much more likely to be Port-Restricted Cone. More recent research and RFCs have come up with a much better taxonomy. First of all, they recognize that there are many more varying dimensions of behavior than the single “cone” dimension of earlier research, so focusing on the cone-ness of your NAT isn’t necessarily helpful. Second, they came up with words that more plainly convey what the NAT is doing. The “easy” and “hard” NATs above differ in a single dimension: whether or not their NAT mappings depend on what the destination is. RFC 4787 calls the easy variant “Endpoint-Independent Mapping” (EIM for short), and the hard variant “Endpoint-Dependent Mapping” (EDM for short). There’s a subcategory of EDM that specifies whether the mapping varies only on the destination IP, or on both the destination IP and port. For NAT traversal, the distinction doesn’t matter. Both kinds of EDM NATs are equally bad news for us. In the grand tradition of naming things being hard, endpoint-independent NATs still depend on an endpoint: each source ip:port gets a different mapping, because otherwise your packets would get mixed up with someone else’s packets, and that would be chaos. Strictly speaking, we should say “Destination Endpoint Independent Mapping” (DEIM?), but that’s a mouthful, and since “Source Endpoint Independent Mapping” would be another way to say “broken”, we don’t specify. Endpoint always means “Destination Endpoint.” You might be wondering how 2 kinds of endpoint dependence maps into 4 kinds of cone-ness. The answer is that cone-ness encompasses two orthogonal dimensions of NAT behavior. One is NAT mapping behavior, which we looked at above, and the other is stateful firewall behavior. Like NAT mapping behavior, the firewalls can be Endpoint-Independent or a couple of variants of Endpoint-Dependent. If you throw all of these into a matrix, you can reconstruct the cone-ness of a NAT from its more fundamental properties: NAT Cone TypesEndpoint-Independent NAT mapping Endpoint-Dependent NAT mapping (all types) Endpoint-Independent firewall Full Cone NAT * Endpoint-Dependent firewall (dest. IP only) Restricted Cone NAT * Endpoint-Dependent firewall (dest. IP+port) Port-Restricted Cone NAT Symmetric NAT * can theoretically exist, but don't show up in the wild Once broken down like this, we can see that cone-ness isn’t terribly useful to us. The major distinction we care about is Symmetric versus anything else — in other words, we care about whether a NAT device is EIM or EDM. While it’s neat to know exactly how your firewall behaves, we don’t care from the point of view of writing NAT traversal code. Our simultaneous transmission trick will get through all three variants of firewalls. In the wild we’re overwhelmingly dealing only with IP-and-port endpoint-dependent firewalls. So, for practical code, we can simplify the table down to:Endpoint-Independent NAT mapping Endpoint-Dependent NAT mapping (dest. IP only) Firewall is yes Easy NAT Hard NAT If you’d like to read more about the newer taxonomies of NATs, you can get the full details in RFCs 4787 (NAT Behavioral Requirements for UDP), 5382 (for TCP) and 5508 (for ICMP). And if you’re implementing a NAT device, these RFCs are also your guide to what behaviors you should implement, to make them well-behaved devices that play well with others and don’t generate complaints about Halo multiplayer not working. Back to our NAT traversal. We were doing well with STUN and firewall traversal, but these hard NATs are a big problem. It only takes one of them in the whole path to break our current traversal plans. But wait, this post is titled “how NAT traversal works”, not “how NAT traversal doesn’t work.” So presumably, I have a trick up my sleeve to get out of this, right? Have you considered giving up? This is a good time to have the awkward part of our chat: what happens when we empty our entire bag of tricks, and we still can’t get through? A lot of NAT traversal code out there gives up and declares connectivity impossible. That’s obviously not acceptable for us; Tailscale is nothing without the connectivity. We could use a relay that both sides can talk to unimpeded, and have it shuffle packets back and forth. But wait, isn’t that terrible? Sort of. It’s certainly not as good as a direct connection, but if the relay is “near enough” to the network path your direct connection would have taken, and has enough bandwidth, the impact on your connection quality isn’t huge. There will be a bit more latency, maybe less bandwidth. That’s still much better than no connection at all, which is where we were heading. And keep in mind that we only resort to this in cases where direct connections fail. We can still establish direct connections through a lot of different networks. Having relays to handle the long tail isn’t that bad. Additionally, some networks can break our connectivity much more directly than by having a difficult NAT. For example, we’ve observed that the UC Berkeley guest Wi-Fi blocks all outbound UDP except for DNS traffic. No amount of clever NAT tricks is going to get around the firewall eating your packets. So, we need some kind of reliable fallback no matter what. You could implement relays in a variety of ways. The classic way is a protocol called TURN (Traversal Using Relays around NAT). We’ll skip the protocol details, but the idea is that you authenticate yourself to a TURN server on the internet, and it tells you “okay, I’ve allocated ip:port, and will relay packets for you.” You tell your peer the TURN ip:port, and we’re back to a completely trivial client/server communication scenario. For Tailscale, we didn’t use TURN for our relays. It’s not a particularly pleasant protocol to work with, and unlike STUN there’s no real interoperability benefit since there are no open TURN servers on the internet. Instead, we created DERP (Detoured Encrypted Routing Protocol), which is a general purpose packet relaying protocol. It runs over HTTP, which is handy on networks with strict outbound rules, and relays encrypted payloads based on the destination’s public key. As we briefly touched on earlier, we use this communication path both as a data relay when NAT traversal fails (in the same role as TURN in other systems) and as the side channel to help with NAT traversal. DERP is both our fallback of last resort to get connectivity, and our helper to upgrade to a peer-to-peer connection, when that’s possible. Now that we have a relay, in addition to the traversal tricks we’ve discussed so far, we’re in pretty good shape. We can’t get through everything but we can get through quite a lot, and we have a backup for when we fail. If you stopped reading now and implemented just the above, I’d estimate you could get a direct connection over 90% of the time, and your relays guarantee some connectivity all the time. NAT notes for nerds But… If you’re not satisfied with “good enough”, there’s still a lot more we can do! What follows is a somewhat miscellaneous set of tricks, which can help us out in specific situations. None of them will solve NAT traversal by itself, but by combining them judiciously, we can get incrementally closer to a 100% success rate. The benefits of birthdays Let’s revisit our problem with hard NATs. The key issue is that the side with the easy NAT doesn’t know what ip:port to send to on the hard side. But must send to the right ip:port in order to open up its firewall to return traffic. What can we do about that? Well, we know some ip:port for the hard side, because we ran STUN. Let’s assume that the IP address we got is correct. That’s not necessarily true, but let’s run with the assumption for now. As it turns out, it’s mostly safe to assume this. (If you’re curious why, see REQ-2 in RFC 4787.) If the IP address is correct, our only unknown is the port. There’s 65,535 possibilities… Could we try all of them? At 100 packets/sec, that’s a worst case of 10 minutes to find the right one. It’s better than nothing, but not great. And it really looks like a port scan (because in fairness, it is), which may anger network intrusion detection software. We can do much better than that, with the help of the birthday paradox. Rather than open 1 port on the hard side and have the easy side try 65,535 possibilities, let’s open, say, 256 ports on the hard side (by having 256 sockets sending to the easy side’s ip:port), and have the easy side probe target ports at random. I’ll spare you the detailed math, but you can check out the dinky python calculator I made while working it out. The calculation is a very slight variant on the “classic” birthday paradox, because it’s looking at collisions between two sets containing distinct elements, rather than collisions within a single set. Fortunately, the difference works out slightly in our favor! Here’s the chances of a collision of open ports (i.e. successful communication), as the number of random probes from the easy side increases, and assuming 256 ports on the hard side: Number of random probes Chance of success 174 50% 256 64% 1024 98% 2048 99.9% If we stick with a fairly modest probing rate of 100 ports/sec, half the time we’ll get through in under 2 seconds. And even if we get unlucky, 20 seconds in we’re virtually guaranteed to have found a way in, after probing less than 4% of the total search space. That’s great! With this additional trick, one hard NAT in the path is an annoying speedbump, but we can manage. What about two? We can try to apply the same trick, but now the search is much harder: each random destination port we probe through a hard NAT also results in a random source port. That means we’re now looking for a collision on a {source port, destination port} pair, rather than just the destination port. Again I’ll spare you the calculations, but after 20 seconds in the same regime as the previous setup (256 probes from one side, 2048 from the other), our chance of success is… 0.01%. This shouldn’t be surprising if you’ve studied the birthday paradox before. The birthday paradox lets us convert N “effort” into something on the order of sqrt(N). But we squared the size of the search space, so even the reduced amount of effort is still a lot more effort. To hit a 99.9% chance of success, we need each side to send 170,000 probes. At 100 packets/sec, that’s 28 minutes of trying before we can communicate. 50% of the time we’ll succeed after “only” 54,000 packets, but that’s still 9 minutes of waiting around with no connection. Still, that’s better than the 1.2 years it would take without the birthday paradox. In some applications, 28 minutes might still be worth it. Spend half an hour brute-forcing your way through, then you can keep pinging to keep the open path alive indefinitely — or at least until one of the NATs reboots and dumps all its state, then you’re back to brute forcing. But it’s not looking good for any kind of interactive connectivity. Worse, if you look at common office routers, you’ll find that they have a surprisingly low limit on active sessions. For example, a Juniper SRX 300 maxes out at 64,000 active sessions. We’d consume its entire session table with our one attempt to get through! And that’s assuming the router behaves gracefully when overloaded. And this is all to get a single connection! What if we have 20 machines doing this behind the same router? Disaster. Still, with this trick we can make it through a slightly harder network topology than before. That’s a big deal, because home routers tend to be easy NATs, and hard NATs tend to be office routers or cloud NAT gateways. That means this trick buys us improved connectivity for the home-to-office and home-to-cloud scenarios, as well as a few office-to-cloud and cloud-to-cloud scenarios. Partially manipulating port maps Our hard NATs would be so much easier if we could ask the NATs to stop being such jerks, and let more stuff through. Turns out, there’s a protocol for that! Three of them, to be precise. Let’s talk about port mapping protocols. The oldest is the UPnP IGD (Universal Plug’n’Play Internet Gateway Device) protocol. It was born in the late 1990’s, and as such uses a lot of very 90’s technology (XML, SOAP, multicast HTTP over UDP — yes, really) and is quite hard to implement correctly and securely — but a lot of routers shipped with UPnP, and a lot still do. If we strip away all the fluff, we find a very simple request-response that all three of our port mapping protocols implement: “Hi, please forward a WAN port to lan-ip:port,” and “okay, I’ve allocated wan-ip:port for you.” Speaking of stripping away the fluff: some years after UPnP IGD came out, Apple launched a competing protocol called NAT-PMP (NAT Port Mapping Protocol). Unlike UPnP, it only does port forwarding, and is extremely simple to implement, both on clients and on NAT devices. A little bit after that, NAT-PMP v2 was reborn as PCP (Port Control Protocol). So, to help our connectivity further, we can look for UPnP IGD, NAT-PMP and PCP on our local default gateway. If one of the protocols elicits a response, we request a public port mapping. You can think of this as a sort of supercharged STUN: in addition to discovering our public ip:port, we can instruct the NAT to be friendlier to our peers, by not enforcing firewall rules for that port. Any packet from anywhere that lands on our mapped port will make it back to us. You can’t rely on these protocols being present. They might not be implemented on your devices. They might be disabled by default and nobody knew to turn them on. They might have been disabled by policy. Disabling by policy is fairly common because UPnP suffered from a number of high-profile vulnerabilities (since fixed, so newer devices can safely offer UPnP, if implemented properly). Unfortunately, many devices come with a single “UPnP” checkbox that actually toggles UPnP, NAT-PMP and PCP all at once, so folks concerned about UPnP’s security end up disabling the perfectly safe alternatives as well. Still, when it’s available, it effectively makes one NAT vanish from the data path, which usually makes connectivity trivial… But let’s look at the unusual cases. Negotiating numerous NATs So far, the topologies we’ve looked at have each client behind one NAT device, with the two NATs facing each other. What happens if we build a “double NAT”, by chaining two NATs in front of one of our machines? What happens if we build a “double NAT”, by chaining two NATs in front of one of our machines? In this example, not much of interest happens. Packets from client A go through two different layers of NAT on their way to the internet. But the outcome is the same as it was with multiple layers of stateful firewalls: the extra layer is invisible to everyone, and our other techniques will work fine regardless of how many layers there are. All that matters is the behavior of the “last” layer before the internet, because that’s the one that our peer has to find a way through. The big thing that breaks is our port mapping protocols. They act upon the layer of NAT closest to the client, whereas the one we need to influence is the one furthest away. You can still use the port mapping protocols, but you’ll get an ip:port in the “middle” network, which your remote peer cannot reach. Unfortunately, none of the protocols give you enough information to find the “next NAT up” to repeat the process there, although you could try your luck with a traceroute and some blind requests to the next few hops. Breaking port mapping protocols is the reason why the internet is so full of warnings about the evils of double-NAT, and how you should bend over backwards to avoid them. But in fact, double-NAT is entirely invisible to most internet-using applications, because most applications don’t try to do this kind of explicit NAT traversal. I’m definitely not saying that you should set up a double-NAT in your network. Breaking the port mapping protocols will degrade multiplayer on many video games, and will likely strip IPv6 from your network, which robs you of some very good options for NAT-free connectivity. But, if circumstances beyond your control force you into a double-NAT, and you can live with the downsides, most things will still work fine. Which is a good thing, because you know what circumstances beyond your control force you to double-NAT? Let’s talk carrier-grade NAT. Concerning CGNATs Even with NATs to stretch the supply of IPv4 addresses, we’re still running out, and ISPs can no longer afford to give one entire public IP address to every home on their network. To work around this, ISPs apply SNAT recursively: your home router SNATs your devices to an “intermediate” IP address, and further out in the ISP’s network a second layer of NAT devices map those intermediate IPs onto a smaller number of public IPs. This is “carrier-grade NAT”, or CGNAT for short. How do we connect two peers who are behind the same CGNAT, but different home NATs within? Carrier-grade NAT is an important development for NAT traversal. Prior to CGNAT, enterprising users could work around NAT traversal difficulties by manually configuring port forwarding on their home routers. But you can’t reconfigure the ISP’s CGNAT! Now even power users have to wrestle with the problems NATs pose. The good news: this is a run of the mill double-NAT, and so as we covered above it’s mostly okay. Some stuff won’t work as well as it could, but things work well enough that ISPs can charge money for it. Aside from the port mapping protocols, everything from our current bag of tricks works fine in a CGNAT world. We do have to overcome a new challenge, however: how do we connect two peers who are behind the same CGNAT, but different home NATs within? That’s how we set up peers A and B in the diagram above. The problem here is that STUN doesn’t work the way we’d like. We’d like to find out our ip:port on the “middle network”, because it’s effectively playing the role of a miniature internet to our two peers. But STUN tells us what our ip:port is from the STUN server’s point of view, and the STUN server is out on the internet, beyond the CGNAT. If you’re thinking that port mapping protocols can help us here, you’re right! If either peer’s home NAT supports one of the port mapping protocols, we’re happy, because we have an ip:port that behaves like an un-NATed server, and connecting is trivial. Ironically, the fact that double NAT “breaks” the port mapping protocols helps us! Of course, we still can’t count on these protocols helping us out, doubly so because CGNAT ISPs tend to turn them off in the equipment they put in homes in order to avoid software getting confused by the “wrong” results they would get. But what if we don’t get lucky, and can’t map ports on our NATs? Let’s go back to our STUN-based technique and see what happens. Both peers are behind the same CGNAT, so let’s say that STUN tells us that peer A is 2.2.2.2:1234, and peer B is 2.2.2.2:5678. The question is: what happens when peer A sends a packet to 2.2.2.2:5678? We might hope that the following takes place in the CGNAT box: Apply peer A’s NAT mapping, rewrite the packet to be from 2.2.2.2:1234 and to 2.2.2.2:5678. Notice that 2.2.2.2:5678 matches peer B’s incoming NAT mapping, rewrite the packet to be from 2.2.2.2:1234 and to peer B’s private IP. Send the packet on to peer B, on the “internal” interface rather than off towards the internet. This behavior of NATs is called hairpinning, and with all this dramatic buildup you won’t be surprised to learn that hairpinning works on some NATs and not others. In fact, a great many otherwise well-behaved NAT devices don’t support hairpinning, because they make assumptions like “a packet from my internal network to a non-internal IP address will always flow outwards to the internet”, and so end up dropping packets as they try to turn around within the router. These assumptions might even be baked into routing silicon, where it’s impossible to fix without new hardware. Hairpinning, or lack thereof, is a trait of all NATs, not just CGNATs. In most cases, it doesn’t matter, because you’d expect two LAN devices to talk directly to each other rather than hairpin through their default gateway. And it’s a pity that it usually doesn’t matter, because that’s probably why hairpinning is commonly broken. But once CGNAT is involved, hairpinning becomes vital to connectivity. Hairpinning lets you apply the same tricks that you use for internet connectivity, without worrying about whether you’re behind a CGNAT. If both hairpinning and port mapping protocols fail, you’re stuck with relaying. Ideally IPv6, NAT64 notwithstanding By this point I expect some of you are shouting at your screens that the solution to all this nonsense is IPv6. All this is happening because we’re running out of IPv4 addresses, and we keep piling on NATs to work around that. A much simpler fix would be to not have an IP address shortage, and make every device in the world reachable without NATs. Which is exactly what IPv6 gets us. And you’re right! Sort of. It’s true that in an IPv6-only world, all of this becomes much simpler. Not trivial, mind you, because we’re still stuck with stateful firewalls. Your office workstation may have a globally reachable IPv6 address, but I’ll bet there’s still a corporate firewall enforcing “outbound connections only” between you and the greater internet. And on-device firewalls are still there, enforcing the same thing. So, we still need the firewall traversal stuff from the start of the article, and a side channel so that peers can know what ip:port to talk to. We’ll probably also still want fallback relays that use a well-like protocol like HTTP, to get out of networks that block outbound UDP. But we can get rid of STUN, the birthday paradox trick, port mapping protocols, and all the hairpinning bumf. That’s much nicer! The big catch is that we currently don’t have an all-IPv6 world. We have a world that’s mostly IPv4, and about 33% IPv6. Those 34% are very unevenly distributed, so a particular set of peers could be 100% IPv6, 0% IPv6, or anywhere in between. What this means, unfortunately, is that IPv6 isn’t yet the solution to our problems. For now, it’s just an extra tool in our connectivity toolbox. It’ll work fantastically well with some pairs of peers, and not at all for others. If we’re aiming for “connectivity no matter what”, we have to also do IPv4+NAT stuff. Meanwhile, the coexistence of IPv6 and IPv4 introduces yet another new scenario we have to account for: NAT64 devices. So far, the NATs we’ve looked at have been NAT44: they translate IPv4 addresses on one side to different IPv4 addresses on the other side. NAT64, as you might guess, translates between protocols. IPv6 on the internal side of the NAT becomes IPv4 on the external side. Combined with DNS64 to translate IPv4 DNS answers into IPv6, you can present an IPv6-only network to the end device, while still giving access to the IPv4 internet. (Incidentally, you can extend this naming scheme indefinitely. There have been some experiments with NAT46; you could deploy NAT66 if you enjoy chaos; and some RFCs use NAT444 for carrier-grade NAT.) This works fine if you only deal in DNS names. If you connect to google.com, turning that into an IP address involves the DNS64 apparatus, which lets the NAT64 get involved without you being any the wiser. But we care deeply about specific IPs and ports for our NAT and firewall traversal. What about us? If we’re lucky, our device supports CLAT (Customer-side translator — from Customer XLAT). CLAT makes the OS pretend that it has direct IPv4 connectivity, using NAT64 behind the scenes to make it work out. On CLAT devices, we don’t need to do anything special. CLAT is very common on mobile devices, but very uncommon on desktops, laptops and servers. On those, we have to explicitly do the work CLAT would have done: detect the existence of a NAT64+DNS64 setup, and use it appropriately. Detecting NAT64+DNS64 is easy: send a DNS request to ipv4only.arpa. That name resolves to known, constant IPv4 addresses, and only IPv4 addresses. If you get IPv6 addresses back, you know that a DNS64 did some translation to steer you to a NAT64. That lets you figure out what the NAT64 prefix is. From there, to talk to IPv4 addresses, send IPv6 packets to {NAT64 prefix + IPv4 address}. Similarly, if you receive traffic from {NAT64 prefix + IPv4 address}, that’s IPv4 traffic. Now speak STUN through the NAT64 to discover your public ip:port on the NAT64, and you’re back to the classic NAT traversal problem — albeit with a bit more work. Fortunately for us, this is a fairly esoteric corner case. Most v6-only networks today are mobile operators, and almost all phones support CLAT. ISPs running v6-only networks deploy CLAT on the router they give you, and again you end up none the wiser. But if you want to get those last few opportunities for connectivity, you’ll have to explicitly support talking to v4-only peers from a v6-only network as well. Integrating it all with ICE We’re in the home stretch. We’ve covered stateful firewalls, simple and advanced NAT tricks, IPv4 and IPv6. So, implement all the above, and we’re done! Except, how do you figure out which tricks to use for a particular peer? How do you figure out if this is a simple stateful firewall problem, or if it’s time to bust out the birthday paradox, or if you need to fiddle with NAT64 by hand? Or maybe the two of you are on the same Wi-Fi network, with no firewalls and no effort required. Early research into NAT traversal had you precisely characterize the path between you and your peer, and deploy a specific set of workarounds to defeat that exact path. But as it turned out, network engineers and NAT box programmers have many inventive ideas, and that stops scaling very quickly. We need something that involves a bit less thinking on our part. Enter the Interactive Connectivity Establishment (ICE) protocol. Like STUN and TURN, ICE has its roots in the telephony world, and so the RFC is full of SIP and SDP and signalling sessions and dialing and so forth. However, if you push past that, it also specifies a stunningly elegant algorithm for figuring out the best way to get a connection. Ready? The algorithm is: try everything at once, and pick the best thing that works. That’s it. Isn’t that amazing? Let’s look at this algorithm in a bit more detail. We’re going to deviate from the ICE spec here and there, so if you’re trying to implement an interoperable ICE client, you should go read RFC 8445 and implement that. We’ll skip all the telephony-oriented stuff to focus on the core logic, and suggest a few places where you have more degrees of freedom than the ICE spec suggests. To communicate with a peer, we start by gathering a list of candidate endpoints for our local socket. A candidate is any ip:port that our peer might, perhaps, be able to use in order to speak to us. We don’t need to be picky at this stage, the list should include at least: IPv6 ip:ports IPv4 LAN ip:ports IPv4 WAN ip:ports discovered by STUN (possibly via a NAT64 translator) IPv4 WAN ip:port allocated by a port mapping protocol Operator-provided endpoints (e.g. for statically configured port forwards) Then, we swap candidate lists with our peer through the side channel, and start sending probe packets at each others’ endpoints. Again, at this point you don’t discriminate: if the peer provided you with 15 endpoints, you send “are you there?” probes to all 15 of them. These packets are pulling double duty. Their first function is to act as the packets that open up the firewalls and pierce the NATs, like we’ve been doing for this entire article. But the other is to act as a health check. We’re exchanging (hopefully authenticated) “ping” and “pong” packets, to check if a particular path works end to end. Finally, after some time has passed, we pick the “best” (according to some heuristic) candidate path that was observed to work, and we’re done. The beauty of this algorithm is that if your heuristic is right, you’ll always get an optimal answer. ICE has you score your candidates ahead of time (usually: LAN > WAN > WAN+NAT), but it doesn’t have to be that way. Starting with v0.100.0, Tailscale switched from a hardcoded preference order to round-trip latency, which tends to result in the same LAN > WAN > WAN+NAT ordering. But unlike static ordering, we discover which “category” a path falls into organically, rather than having to guess ahead of time. The ICE spec structures the protocol as a “probe phase” followed by an “okay let’s communicate” phase, but there’s no reason you need to strictly order them. In Tailscale, we upgrade connections on the fly as we discover better paths, and all connections start out with DERP preselected. That means you can use the connection immediately through the fallback path, while path discovery runs in parallel. Usually, after a few seconds, we’ll have found a better path, and your connection transparently upgrades to it. One thing to be wary of is asymmetric paths. ICE goes to some effort to ensure that both peers have picked the same network path, so that there’s definite bidirectional packet flow to keep all the NATs and firewalls open. You don’t have to go to the same effort, but you do have to ensure that there’s bidirectional traffic along all paths you’re using. That can be as simple as continuing to send ping/pong probes periodically. To be really robust, you also need to detect that your currently selected path has failed (say, because maintenance caused your NAT’s state to get dumped on the floor), and downgrade to another path. You can do this by continuing to probe all possible paths and keep a set of “warm” fallbacks ready to go, but downgrades are rare enough that it’s probably more efficient to fall all the way back to your relay of last resort, then restart path discovery. Finally, we should mention security. Throughout this article, I’ve assumed that the “upper layer” protocol you’ll be running over this connection brings its own security (QUIC has TLS certs, WireGuard has its own public keys…). If that’s not the case, you absolutely need to bring your own. Once you’re dynamically switching paths at runtime, IP-based security becomes meaningless (not that it was worth much in the first place), and you must have at least end-to-end authentication. If you have security for your upper layer, strictly speaking it’s okay if your ping/pong probes are spoofable. The worst that can happen is that an attacker can persuade you to relay your traffic through them. In the presence of e2e security, that’s not a huge deal (although obviously it depends on your threat model). But for good measure, you might as well authenticate and encrypt the path discovery packets as well. Consult your local application security engineer for how to do that safely. Concluding our connectivity chat At last, we’re done. If you implement all of the above, you’ll have state of the art NAT traversal software that can get direct connections established in the widest possible array of situations. And you’ll have your relay network to pick up the slack when traversal fails, as it likely will for a long tail of cases. This is all quite complicated! It’s one of those problems that’s fun to explore, but quite fiddly to get right, especially if you start chasing the long tail of opportunities for just that little bit more connectivity. The good news is that, once you’ve done it, you have something of a superpower: you get to explore the exciting and relatively under-explored world of peer-to-peer applications. So many interesting ideas for decentralized software fall at the first hurdle, when it turns out that talking to each other on the internet is harder than expected. But now you know how to get past that, so go build cool stuff! Here’s a parting “TL;DR” recap: For robust NAT traversal, you need the following ingredients: A UDP-based protocol to augment Direct access to a socket in your program A communication side channel with your peers A couple of STUN servers A network of fallback relays (optional, but highly recommended) Then, you need to: Enumerate all the ip:ports for your socket on your directly connected interfaces Query STUN servers to discover WAN ip:ports and the “difficulty” of your NAT, if any Try using the port mapping protocols to find more WAN ip:ports Check for NAT64 and discover a WAN ip:port through that as well, if applicable Exchange all those ip:ports with your peer through your side channel, along with some cryptographic keys to secure everything. Begin communicating with your peer through fallback relays (optional, for quick connection establishment) Probe all of your peer’s ip:ports for connectivity and if necessary/desired, also execute birthday attacks to get through harder NATs As you discover connectivity paths that are better than the one you’re currently using, transparently upgrade away from the previous paths. If the active path stops working, downgrade as needed to maintain connectivity. Make sure everything is encrypted and authenticated end-to-end. Share Author David Anderson Author David Anderson Share Loading...",
    "commentLink": "https://news.ycombinator.com/item?id=42600846",
    "commentBody": "How NAT Traversal Works (2020) (tailscale.com)246 points by hhthrowaway1230 9 hours agohidepastfavorite44 comments dennis-tra 6 hours agoThis is an excellent article! The tribal knowledge seems to be that you shouldn't do TCP-based hole punching because it's harder than UDP. The author acknowledges this: > You can do NAT traversal with TCP, but it adds another layer of complexity to an already quite complex problem, and may even require kernel customizations depending on how deep you want to go. However, I only see marginally added complexity (given the already complex UDP flows). IMO this complexity doesn't justify discarding TCP hole punching altogether. In the article you could replace raw UDP packets to initiate a connection with TCP SYN packets plus support for \"simultaneous open\" [0]. This is especially true if networks block UDP traffic which is also acknowledged: > For example, we’ve observed that the UC Berkeley guest Wi-Fi blocks all outbound UDP except for DNS traffic. My point is that many articles gloss over TCP hole punching with the excuse of being harder than UDP while I would argue that it's almost equally feasible with marginal added complexity. [0] https://ttcplinux.sourceforge.net/documents/one/tcpstate/tcp... reply dfawcus 4 hours agoparentThe existence of stateful firewalls, and the fact that most NAT filters are EDF rather than EIF means that simultaneous open (send) is necessary even for UDP. Hence the added complexity of doing a simultaneous open via TCP is fairly minor. The main complication is communicating the public mapping, and coordinating the \"simultaneous\" punch/open. However that is generally needed for UDP anyway... One possible added complexity with TCP is one has to perform real connect() calls, rather than fake up the TCP SYN packet. That is becase some firewalls pay attention to the sequence numbers. reply LegionMammal978 1 hour agorootparentYeah, I've gotten somewhat annoyed by the name of 'NAT traversal' for these methods. It seems to make some people think that cutting out NAT will lead to a beautiful world of universal P2P connections. But really, these methods are needed for traversing between any two networks behind stateful firewalls, which will pose a barrier to P2P indefinitely. Also, wouldn't it be easier for stateful firewalls to block simultaneous TCP open (intentionally or not)? With UDP, the sender's firewall must create a connection as soon as it sends off the first packet, even if that packet bounces off the other firewall: the timing doesn't have to be particularly tight. But with TCP, the firewall might plausibly wait until the handshake is complete before allowing incoming packets, and it might only allow the 3-way SYN/SYN-ACK/ACK instead of the simultaneous SYN/SYCK/ACK. reply ocdnix 8 hours agoprevFascinatingly effective, but maybe I'm the only one getting the heebie-jeebies when someone suggests implementing this in production corp networks. Sure it's super convenient, but the thought of bypassing all traditional NATs and firewalls, and instead relying solely on a software ACL, seems super risky. Maybe I just don't understand how it works, but it seems that a bad actor getting access to a stray VM with Tailscale on it in, say, your AWS testing env, essentially has an clear path all the way into your laptop on the internal corp network, through the kernel, into user space and into the Tailscale ACL code as the sole arbiter of granting or blocking access. Would I even know someone unauthorized made it that far? reply dfawcus 4 hours agoparentThat is why many of us keep repeating that NAT is not a security mechanism. Punching through NAT, and most associated state tracking filters, is very easy. I've implemented such in a production corp environment, as a product to be sold. There is no magic here, it is all well understood technology by the practitioners. If you actually want to have packet filtering (a firewall) then deploy a firewall instance distinct from any NAT, and with appropriate rules. However that only really helps for traffic volume reduction, the actual security gain from a f/w per se is now minimal, as most attacks are over the top: HTTP/HTTPS, POP/IMAP etc. reply miki123211 9 minutes agoparentprevAs far as I understand, Tailscale won't even let you initiate a connection (or give you WireGuard keys for a node) unless there's an ACL rule that allows it. reply dijit 7 hours agoparentprevto be completely fair with you, everyone misinterprets NAT as a security mechanism, because traditionally it is deployed alongside a stateful firewall. In reality, of course, the stateful firewall is doing all of the heavy lifting that NAT is getting the credit for. Tailscale does not get rid of the firewall in fact it has a much more comprehensive setup based on proper ACLs. Though I’m definitely the first to admit that their tooling around ACL’s could be significantly improved reply tptacek 1 hour agorootparentI think they mostly interpret NAT as a security mechanism because that's what it originally was; \"NAT\" was a species of firewall, alongside \"stateful\" and \"application layer\". And NAT obviously does serve a security purpose; just not the inside->out access control function we're talking about here. reply dijit 1 hour agorootparentI mean, it really isn’t a security mechanism of any kind. Any security properties at all are completely accidental. One need only disable stateful firewalling and use that to see how completely dire the situation would be. As all outbound connections open up your host to the internet. reply rixed 4 hours agoparentprevThis is to go through NAT, which are devices designed to work around the rarefaction of IPv4 addresses. Firewalling is a different concept, but since you raise that issue of connectivity wrt. security, I have to say that what makes /me/ sad and anxious is to see how internet security has always been hinging on bloquing paquets based on the destination port. Doing what's easy rather than what's correct, exemplified and labelled \"professional solutions\"... reply navigate8310 4 hours agorootparentI'm rather more curious as to why you stylized \"bloquing paquets\"? reply aborsy 4 hours agorootparentMaybe the OP is French? :) reply Hilift 7 hours agoparentprev> production corp networks. Networking has long been the toxic wasteland of security and misconfiguration. Now combine that with newer host-based networking models for containers. The Windows network stack is substantially different now due to that, and more complex. Since Wireguard has been part of Linux, everyone and their brother now has a VPN, somewhere connecting to a VPS. It's probably worse than you think because you don't know what you don't know. reply Muromec 6 hours agoparentprevThat’s how all voip worked since forever and we also have a bunch of standard and public facing infrastructure to make it easier. All the ice, turn and friends. It still needs something on the inside to talk to outside first, so the actual firewall should whitelist both outbound and inbound connections. Than again, if you rely on perimeter, it’s a matter of time when someone figures out what’s your equivalent of high wiz jacket is. reply rainsford 4 hours agoparentprevI'm not sure how to compare the risk and attack surface of traditional NATs and firewalls vs Tailscale's ACL code, but I'm not sure Tailscale is obviously the riskier choice there. I think more traditional network devices are more familiar and more of a known quantity, but there's a lot of janky, unpatched, legacy network devices out there without any of the security protections of modern operating systems and code. It's also worth considering that exploitability of ACL code is just one factor in comparing the risk and Tailscale or similar solutions allow security conscious setups that are not possible (or at least much more difficult) otherwise. For example, the NAT and firewall traversal means you don't have to open any ports anywhere to offer a service within your Tailscale network. Done correctly, this means very little attack surface for a bad actor to gain access to that stray VM in the first place. You can also implement fairly complex ACL behavior that's effectively done on each endpoint without having to trust your network infrastructure at all, behavior that stays the same even if your laptop or other devices roam from network to network. Not to say I believe Tailsclae is bulletproof or anything, but it does offer some interesting tradeoffs and it's not immediately obvious to me the risk is worse than legacy networks (arguably better), and you gain a lot of interesting features and convenience. reply miki123211 6 minutes agorootparentAnd for whatever it's worth, Tailscale is written in a language that makes buffer overflow and memory corruption vulnerabilities extremely unlikely. reply totallywrong 3 hours agoparentprevIt's no different from traditional VPNs. The tailnet admin has control over the routes that are exposed to clients and ACLs are available to further limit access. It's an overlay network, it doesn't magically give you access to user space on people's laptops. reply ray_v 32 minutes agorootparentGiven how tailscale works and many of the features (the SSH features especially) it's not terribly hard to imagine a critical flaw or misconfigured setup giving access to userspace reply bradleyjg 56 minutes agoparentprevYou don’t want to be hard on the outside, soft on the inside. Especially because you probably aren’t that hard on the outside! Defense in depth. reply 0xbadcafebee 3 hours agoparentprevNetwork security is a myth. NATS, firewalls, ACLs, etc don't keep you safe. Even on your Wifi LAN right now, you aren't safe from local network attacks originating from outside attackers. reply binary132 3 hours agoparentprevIsn’t this essentially what a VPN does? I mean, that’s what TailScale is built on: Wireguard. reply tantalor 5 hours agoparentprevSecurity in depth. reply devmor 8 hours agoparentprevThat is a whole lot of different levels of exploits that would have to be chained together that you just trivialized there. How do you suppose they gained access to the kernel and userspace just by having a network connection to the laptop? reply Muromec 6 hours agorootparentBy using an unpatched rce in any network exposed code. The whole point of firewall is to prevent bad hackers from the bad internet to exploit your unpatched rces, abuse your default passwords, host based security you shouldn't have had in the first place and access stuff using compromised credentials you didn't revoke or didn't know you should have revoked. Because consistently doing all of that all of the time is hard for creative professionals. It's a chore. It's a tax. reply cyberpunk 7 hours agorootparentprevI think the point is not that there are necessarily exploits, but by compromising one node in the tailnet they now have the ability to hit code in these locations, or services running on your tun0 interface on your laptop etc. reply aborsy 7 hours agorootparentYou would typically remove the default any to any ACL rule, and allow the connections that you need. The compromised node normally would not have access to anything interesting. Normally it’s jailed, or would not be able to make outgoing connections. Am I missing something? reply cyberpunk 7 hours agorootparentThe ACL logic happens in the tailscaled on the destination though doesn't it? So even if you block the access via the ACL the packet has still gone through the network stack and go runtime etc before the traffic is dropped which is a significantly bigger surface than a (traditional) external network firewall. reply aborsy 6 hours agorootparentI see your point. You are talking about a vulnerability. You are right. Tailscale nodes can send packets processed in any other node, irrespectively of ACLs. Essentially each node gets to “run code” in other nodes, which is normally dropped. I don’t know how deep the Tailscale packets go before being dropped (perhaps the coordination server distributes firewall rules). But you have to compare with another access method, like, the hub and spoke VPN. The compromised and uncompromised nodes connect to a VPN access server. A compromised node sends packets that are processed in the VPN server, but can also connect to the uncompromised node, meaning, the latter has to process and drop the packets of the former. You have to trust the OS IP stack. To some extent, the same is true if the trusted node VPNs directly to the untrusted node. During an established connection, the networking stack of the trusted node has to block the other side. Maybe someone familiar with the implementation of ACLs in Tailscale could chime in. Update: The ACL rules are applied to the incoming packets over tailscale interface. The filtering is then done by tailscaled. The packet has gone past the interface and processes by tailscaled. So an unauthenticated packet indeed travels through the kernel space all the way to the userspace. reply kortilla 6 hours agorootparentprev> Am I missing something? Yes > You would typically remove the default any to any ACL rule This part doesn’t happen. Defaults are rarely changed. reply apitman 1 hour agoprevThis is the article I sent people to for NAT traversal This may be the only way we ever have to build p2p apps. IPv6 doesn't have enough steam since NAT and SNI routing solve most problems for most people. And ISPs are very much not incentivized for that to change. reply vinay_ys 2 hours agoprevInteresting blast from the past. We built an oblivious p2p mesh network that did this in 2010. Back then, nobody cared about security as much as we thought they should. Since then, nobody still cares about security as much as they should. Devices have increased and their value has increased, and still, they are quite insecure. Truly secure endpoints with hardware root-of-trust and secure chains of trust for authn/authz and minimal temporary privileges is still hard, and network perimeter security theater is still ongoing in home networks, corp networks and even large production datacenter networks. Only reason we don't find these to be the primary root-cause for security breaches is because more easier attack chains are still easily available! reply zerox7felf 6 hours agoprev> So, to traverse these multiple stateful firewalls, we need to share some information to get underway: the peers have to know in advance the ip:port their counterpart is using. > [...] To move beyond that, we built a coordination server to keep the ip:port information synchronized This is where I wish SIP lived up to its name (Session Initiation Protocol, i.e. any session, such as a VPN one...) and wasn't such a complicated mess making it not worth the hassle. I mean it was made to be the communication side-channel used for establishing p2p rtp streams. reply Muromec 6 hours agoparentYeah, sip is doing so many things that its scary to load all them in your head at the same time. Its like http, but its also statefull, bidirectional, federated and works over udp too. Just looking at the amount of stuff (tls over udp included) baresip implements to barely sip. And it isnt even bloated, the stuff has to be there. reply rixed 4 hours agorootparent> Its like http and for the same reason: both were initialy designed to be simple... reply randunel 7 hours agoprevI wish there was a tailscale-like equivalent without connectivity encryption, for devices which encrypt at the application layer (like almost the entire internet does). We don't always need the lower layers to be encrypted, this is especially computationally expensive for low power devices (think IoT stuff running a tailscale like tunnel). GRE tunnels exist and I actually use them extensively, but UDP hole punching is not handled so hub-and-spoke architecture is needed for them, no peer to peer meshes with GRE (ip fou). Are there equivalent libraries out there which do UDP hole punching and unencrypted GRE tunnels following an encrypted handshake to confirm identity? reply jamilbk 6 hours agoparentYes, the established standard here is known collectively as Interactive Connectivity Establishment (ICE) [1] which WebRTC relies on -- there are a few good libraries out there that implement it and/or various elements of it [2] [3]. libp2p [4] may be what you're after if you want something geared more towards general purpose connectivity. [1] https://datatracker.ietf.org/doc/html/rfc8445 [2] https://github.com/pion/webrtc [3] https://github.com/algesten/str0m [4] https://libp2p.io reply randunel 2 hours agorootparentThank you for the resources! I will study them. FWIW, libp2p also enforces transport encryption, quote: > Encryption is an important part of communicating on the libp2p network. Every connection must be encrypted to help ensure security for everyone. As such, Connection Encryption (Crypto) is a required component of libp2p. reply Muromec 6 hours agoparentprevTurn, stun, ice is what does hole punching for voip, so you can reuse libraries from voip for that reply dfawcus 8 hours agoprev(2020) Previous discussion: (2022) https://news.ycombinator.com/item?id=30707711 (2020) https://news.ycombinator.com/item?id=24241105 reply normie3000 8 hours agoparentThanks. Links aren't clickable. Maybe these will be: https://news.ycombinator.com/item?id=30707711 https://news.ycombinator.com/item?id=24241105 reply binary132 3 hours agoprevReally clear and clean exposition on what can be a hairy and badly-discussed subject, thanks for posting! reply michidk 7 hours agoprevSuch a great explanation. Wish I would have had something like this back in my gamedev days. reply api 3 hours agoprev [–] Another year, another repost of an article about NAT traversal, another couple replies about how this is insecure followed by people explaining that NAT is not a security feature. reply Hikikomori 3 hours agoparent [–] It's like the Aragon broken toe of networking. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NAT traversal enables direct device connections despite the presence of Network Address Translators (NATs) and firewalls, using UDP-based protocols and direct socket control.",
      "Techniques such as STUN (Session Traversal Utilities for NAT) help in discovering public IP addresses, while relays like TURN (Traversal Using Relays around NAT) or Tailscale's DERP are used for more challenging NATs.",
      "The ICE (Interactive Connectivity Establishment) protocol optimizes connection paths by evaluating all possible options and selecting the most efficient one, ensuring robust NAT traversal with end-to-end encryption and authentication."
    ],
    "commentSummary": [
      "The article explores NAT (Network Address Translation) traversal, emphasizing the differences between TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) hole punching, noting TCP's slightly higher complexity.",
      "It challenges the perception of NAT as a security feature and discusses Tailscale's method for NAT traversal, raising concerns about depending solely on software ACLs (Access Control Lists) for security.",
      "The discussion highlights the importance of secure endpoints and critiques the limitations of conventional network security strategies in the context of NAT traversal."
    ],
    "points": 233,
    "commentCount": 42,
    "retryCount": 0,
    "time": 1736072158
  },
  {
    "id": 42599599,
    "title": "Guten: A Tiny Newspaper Printer",
    "originLink": "https://amanvir.com/guten",
    "originBody": "Guten: A tiny newspaper printer {__sveltekit_3bto65 = { base: new URL(\".\", location).pathname.slice(0, -1), env: {}};const element = document.currentScript.parentElement;const data = [null,null,null];Promise.all([ import(\"./_app/immutable/entry/start.0e364765.js\"), import(\"./_app/immutable/entry/app.4d98ed72.js\")]).then(([kit, app]) => { kit.start(app, element, {node_ids: [0, 3, 11],data,form: null,error: null });}); }",
    "commentLink": "https://news.ycombinator.com/item?id=42599599",
    "commentBody": "Guten: A Tiny Newspaper Printer (amanvir.com)228 points by thunderbong 15 hours agohidepastfavorite93 comments figbert 13 hours agoMade something similar that is probably my proudest work: https://figbert.com/projects/roll-call/ I increasingly have come to believe that it is the screen itself that lies at the root of the ills of technology. It brings so much benefit—and so much convenience, from its flexibility—but it is in its fundamental glow-y rectangular nature that sucks us in, crushing our attention, posture, and so much else. Was incredibly fun to experiment with something radically different. Excited to see where things go from here. reply Neywiny 4 hours agoparentIf this is your website, as a heads up it doesn't work well on my browser. Firefox on Android, I believe I have a dark mode and the text is still black but on a very dark background. reply paulnpace 3 hours agorootparentApropos. reply fmajid 8 hours agoparentprevNice! I got an Epson TM-m30II PoS printer on a whim, and haven’t really found a use for it yet, I’ll definitely try your script. reply phyrex 3 hours agoprevPlease be aware that handling thermal paper is super unhealthy: https://pmc.ncbi.nlm.nih.gov/articles/PMC5453537/ reply smartmic 2 hours agoparentNot necessarily, if you choose a friendly alternative. In Germany, we have https://www.oekobon.de/ , I guess there a similar offers for other markets. As always, there are downsides. In this case, the eco version comes with a blue base color. reply mosselman 32 minutes agorootparentWow this is great! Danke reply declan_roberts 2 hours agoparentprevThere's a reason why a lot of the Costco receipt checkers wear nitrile gloves now. reply iamjackg 14 hours agoprevI've had this same idea since I also own a thermal printer, but I could never get past the wastefulness of printing a piece of paper that I would then immediately throw away after reading, so I never implemented it. I still think about it periodically: there is something oddly alluring about finding a small piece of paper made specifically for me whenever I go to the kitchen in the morning. E-ink just doesn't quite feel the same. reply notpushkin 9 hours agoparentI wanna buy a dot-matrix printer for projects like that. Still would be wasting paper but at least it won’t be toxic and the result is usually more aesthetically pleasing IMO. reply adamm255 9 hours agorootparentLike this?? https://aschmelyun.com/blog/getting-my-daily-news-from-a-dot... reply smarx007 6 hours agorootparentEpson still makes new ones: https://epson.com/For-Work/Printers/Impact-Dot-Matrix/LX-350... reply Hackbraten 1 hour agorootparentWait a sec. There's no ribbon subscription plan? And they sell you high-yield ribbons (lasting many millions of characters) for $6 a piece? The printer even has USB, looks better on your desk than the average bulky MFP, and consumes ~ 1W on standby. Plus, not having toner particles in the air might be better for your health. If only the print quality and noise level weren't abysmal by today's standards, this could easily have been my next printer. reply jpc0 2 hours agorootparentprevOKI too https://www.oki.com/me/printing/products/lineprinters/index.... reply smarx007 2 hours agorootparentNice, although looks like the ca. 4500 EUR price for the cheapest model is gonna burn a hole in my pocket :) reply jpc0 2 hours agorootparentUnfortunately it seems they have discontinued all their smaller models than this... Likely because nobody is buying them. I haven't seen a dot Matrix printer in person for over a decade. On the other hand their smaller units are still in support till 2027 reply Schiendelman 6 hours agorootparentprevOof, barely 2/5 stars on their own website's reviews. reply smarx007 5 hours agorootparentWell, I always read reviews by ignoring all 1-star reviews first. Most 1-star reviews are made by disgruntled customers to grab customer service attention, a practice I detest. For example, one of the 1-star reviews says that a printer does not work on Win10 and thus is a garbage that was returned. Yeah, about that... https://www.youtube.com/watch?v=uV9lemggOuw sure it works on Win10 reply sleepybrett 2 minutes agorootparentprevinks and dyes aren't generally that friendly either. reply captn3m0 9 hours agoparentprevI've been wanting to build something similar, but can't get myself to buy a thermal print for just this project. I'll probably settle with a \"Sunday Newspaper\" as a compromise on my laserjet printer. reply pxoe 6 hours agoparentprevFeels like the vibe from tech scolds in general has shifted towards \"fun is wasteful\". Oh well. reply agumonkey 3 hours agoparentprevwe should have miniaturized 80s electrostatic screen for that reply fnordian_slip 11 hours agoparentprevYeah, I kind of expected this to be an art project decrying the wastefulness of our times, not an actual project. reply bowsamic 7 hours agorootparentI think there's a point where it's worth waste in order to enjoy life, for example writing on paper instead of typing, or eating a burger every now and then. Not using a small amount of thermal paper each day is I think a pathological over-optimisation reply serf 2 hours agorootparent>Not using a small amount of thermal paper each day is I think a pathological over-optimisation I agree, but OP is judging interest in order to produce a product from this concept. Using a bit of thermal paper each day on a personal basis creates negligible impact, agreed -- creating a company whose primary profit motive is the sales of equipment that produces this waste? That's a different question. reply fnordian_slip 5 hours agorootparentprevOf course, it's just the symbolism of the whole thing. I now realise that my comment had a bit too much pathos, and could easily be interpreted as looking down on the creator of this harmless concept. Companies waste such an insane amount of resources on advertising alone, that this fun little project can not be seen as morally problematic. It's just so on the nose, and together with the current bad press surrounding of thermal paper due to health concerns, it felt like satire to me. But thank you for your \"writing on paper\" example, that was a useful one. It made me realise how my comment would have to be construed by someone lacking the context I had created in my head :) reply amanvir_ 12 hours agoprevHey, I'm the creator of Guten! Thank you, OP, for posting this, and thanks to the community for all your support! To answer some common questions/comments/concerns: - Totally agree with the sentiment regarding screens being a big problem in today's day and age. The main reason I wanted to make Guten was so that I could start my day off reading something on paper instead of staring at my phone. It also helps that you can't doomscroll on a receipt ;) - I also love Little Printer - it seemed like such a cool product, but I unfortunately never had the chance to purchase one before it got discontinued. This is my attempt to bring back some of the functionalities in Little Printer that I'd find most useful in my day-to-day. - BPA in thermal paper was a concern of mine as well, but I thankfully found some BPA-free thermal paper on Amazon! reply Aloha 11 hours agoparentEpson still makes a two color impact printer as well in this form factor. https://epson.com/For-Work/POS-System-Devices/POS-Printers/T... I'd be very interested in a \"supply your own printer\" version of this as well - either using these two color printers or thermal. I suspect there isnt a ton of money to be made in selling printers, but rather the aggregation services needed to drive it. Let people buy a commodity printers, or a variety of them - if you use CUPS as an abstraction layer, you can basically run anything, and the CUPS turns the actual output device into an abstraction. reply fy20 8 hours agorootparentYou can get used impact printers fairly cheaply off eBay. They still have a use case in restaurant kitchens - where heat doesn't play nicely with thermal paper, and the noise alerts you to a new order. In Europe where fiscal printers are becoming the norm, it's usually cheaper to buy a new printer than repair and recertify it, if it breaks. Most receipt printers support the ESC/POS protocol, so an abstraction isn't really needed. reply afandian 11 hours agorootparentprevA dot matrix at 7am would also solve another problem I have. reply ninalanyon 10 hours agorootparentI fondly remember a dot matrix printer that looked a bit like a single slot toaster from many decades ago, long before the internet and doomscrolling. You sat it above a stack of fan fold paper. My memory claims it was called Tiger, but what brand it was I have no idea. It was incredibly loud but also very fast. reply smarx007 4 hours agorootparentThis Tiger? https://www.youtube.com/watch?v=u8I6qt_Z0Cg reply fmajid 8 hours agoparentprevFrench company Exacompta makes a line of BPA-free and sustainable thermal receipt paper: https://www.exacompta.com/en/recherche?search=Thermal The EU banned BPA in receipt paper since 2020, so any European supplier should work. reply haarts 8 hours agorootparentWhat? That's fantastic news! I've been uncomfortable handling receipts ever since (a long time ago) I learned about BPAs in them. reply dt23 7 hours agorootparentUnfortunately it seems it's largely been replaced by (equally?) toxic BPS https://www.fidra.org.uk/bisphenols/bps-joins-eu-candidate-l... reply aziaziazi 7 hours agorootparentThanks for sharing, interesting read. > In January 2020, BPA was restricted from use in thermal paper, including tickets and receipts, across the EU (3). As a result, another bisphenol, Bisphenol-S (BPS), began to take its place. In fact, an ECHA survey estimated that 61% of all thermal paper would contain BPS as a substitute for BPA, despite concerns of BPS being equally as harmful (6). Fast forward three years and BPS is now recognised as “toxic to reproduction” and a hormone disruptor, and has been added to the EU’s candidate list for Substance of Very High Concern (SVHCs), a common first step on the road to restriction (7). reply CarRamrod 10 hours agoparentprev>BPA in thermal paper was a concern of mine as well, but I thankfully found some BPA-free thermal paper on Amazon! Cheers to that. A note about buying BPA-free thermal paper on the site might be nice, especially for those who plan to have children interact with your project. reply fmajid 8 hours agorootparentThe EU banned BPA in receipt paper 5 years ago. French firm Exacompta makes good options in blue and standard white: https://www.exacompta.com/en/recherche?search=Thermal reply nakedrobot2 10 hours agoparentprevYeah it's the bpa more than the waste that would bother me. Honest question, isn't the bpa free paper just using something else than bpa that is unregulated and potentially even worse? reply aziaziazi 8 hours agorootparentDepends what you mean by worse: ink is a big problem for recycling paper (along polymer-filmed \"papers\"). Thermal ink isn’t an exception and contrary to other printer types, it need to cover the whole page for the printer to work. I don’t think it’s a major health problem if you don’t consume your daily newspaper after reading. reply CarRamrod 13 hours agoprevVery cool, but FYI, many types of thermal paper contain extremely high levels of the chemical BPA. reply macinjosh 12 hours agoparentYou’re not supposed to eat/lick/consume it. reply ornornor 12 hours agorootparentYou don’t have to. It would seem it also leeches through your fingers. reply bryanrasmussen 11 hours agorootparentPerfect for printing Aristotle's guide to comedy and passing around to the other monks. reply ptspts 2 hours agorootparentThis is a reference to the story of the novel The Name of the Rose by Umberto Eco. reply pavel_lishin 2 hours agorootparentprevThis reference is right on the tip of my tongue, but I can't quite place it. reply _joel 11 hours agorootparentprevGood job you can get BPA and Phenol free rolls then. reply ornornor 11 hours agorootparentAt least for plastic containers that are BPA free, it would seem the alternatives are just as toxic but we pretend it’s not because we have no alternatives. reply CarRamrod 10 hours agorootparentprevSure, but it's a lot easier to avoid a harmful chemical (and protect children from it) when you have been informed that it's there. reply apgwoz 15 hours agoprevThis looks cool! Reminds me of the long defunct Little Printer (https://vimeo.com/32796535). reply simonw 14 hours agoparentYeah, Little Printer may also serve as a warning that turning this kind of thing into a commercial endeavor is a very challenging road! You should be OK if you do the Kickstarter style of thing, take pre-orders etc - but I would be wary about raising investment for this kind of project. reply feisuzhu 15 hours agoprevI'm using a [Gprinter GP-1324D](https://www.ebay.com/itm/365264659480) in everyday work, printing task tracking stickers, various labels, etc. It's designed to print shipping labels / recipients in business scenarios so it's fairly robust. The only con I can think of is its physical size. I'm not familiar with eBay, but on Xianyu(Chinese second hand market app), yes you can buy one using only $20, shipping included. reply smarx007 5 hours agoparentThis is even better as it allows you to glue the printouts on a diary page instead of discarding them, e.g. https://www.youtube.com/watch?v=7kMFWM64gVQ reply feisuzhu 14 hours agoparentprevLinux CUPS driver here: https://github.com/feisuzhu/gprinter-cups reply dqv 14 hours agoprevWhat's the deal with the thermal paper though? I guess it's negligible exposure since you would only be using it once a day. There is an alternative thermal paper that uses vitamin c. It's slightly more expensive but I feel like that wouldn't matter for something like this since it's not using nearly as much as would be used for retail printing. I wonder if it's worth using the vitamin c kind instead. reply arminiusreturns 14 hours agoparentBased on some of my reading on the current thermal paper, we really need a safer alternative. If you deal with receipts many times in a day you should be wearing gloves! reply quartermaster 7 hours agoprevThis reminds me of Little Printers from a few years ago: https://nordprojects.co/projects/littleprinters/ Nice to see the concept is still alive and useful! reply eggy 4 hours agoprevAfter my PET 2001 I had purchased in 1977/78, I bought a Commodore Vic-20. Using the book, \"Practical Astronomy with Your Calculator\", I wrote a program in Vic BASIC which was the same as the PET's to identify the four most prominent moons of Jupiter based on their elliptical plane being on edge when viewed from Earth. I wanted a way of going on my roof in Brooklyn with my small refractor to identify them, so I bought a thermal printer and printed out the primitive graphics on a line for a given time for the next few hours or so of stargazing. I can't remember the printer brand, but it wasn't one of the Apple, Atari, or ZX offerings. Good fun. I have to say, I would use my phone nowadays or my e-ink tablet instead. Not from being 'sucked in' but merely because it would be quick and more accurate and have other uses for the same task like Stellarium! reply graypegg 13 hours agoprevI’ve wanted to make something like this for a while! Though with sudoku puzzles instead of news. My mum goes thru tons of those sudoku books, and doesn’t want to use her phone for it. Just a button to get 1 puzzle, or hold for a roll of 10 or something seems like an easy thing to set up. reply mediumsmart 14 hours agoprevThis is great for the environment. Millions of people could balance the strain they put on the planet by reading the news from their lithium powered Gadgets on good old paper. Win win reply latexr 2 hours agoparentMost thermal paper is made with harmful chemicals. reply salgernon 14 hours agoprevadafruit used to sell a little pi powered thermal printer[1] but I always found the case a little fiddly and fragile. And my office mate didn’t care for the thing coming on at random times. (Not as bad as the text only 40 col commercial receipt printer that used actual ink and was as loud as a full size Epson MX-80. Free idea: Uber for printers. Need to print something? Car drives up with a printer in the boot, you print whatever (umbrella as appropriate) and the driver is responsible for ink and paper. [1] https://www.adafruit.com/product/717 reply ornornor 12 hours agoparentI cant imagine how much it would cost per print. I doubt anyone would be willing to pay 5–10$ for the first page. It’s cheaper to drive to a print shop or send your pdf to a printing service and receive hard copies by mail. reply fragmede 11 hours agorootparentFor those not driving, Uber package delivery will probably do the delivery for you. reply aziaziazi 7 minutes agorootparentI’m not driving and just walk or ride my bike to the next print shop (150m) or the further one (300m). I’m blessed to live in an affordable, living suburb. There’s many Uber (and competitors) cars parked in my neighborhood but I don’t see them often in the road. They probably roam around more pricy neighborhoods for work. reply louismerlin 9 hours agoprevFun! A friend of mine has been working on something similar: https://www.wintermute.org/project/The_Screenless_Office/ reply alekratz 14 hours agoprevHey, I made something like this last year. It wasn't a self-contained unit, it was just a receipt printer with a script that would run every morning at 8am, getting the forecast, word of the day, and quote of the day. The idea was that if something important happened that day, I could hold onto that day's slip of paper and maybe write a note on it? I dunno, I stopped using after a month or so. reply aboardRat4 5 hours agoprevI'd like to have a program to prepare and typeset PDFs for newspapers to be printed out of a gazillion of news sources is like to read, very few of which have an rss. reply irs 14 hours agoprevThis is cool. Please make it so its not just for news and developer friendly so it can print any content on demand using api. Tried to use a \"memobird\" printer for similar purpose but couldn't get any support for their API. reply syndicatedjelly 14 hours agoparentYou can write your own script to do this. It's a few lines of scripting to query whatever APIs you want, and then output to /dev/usb0 or wherever the printer is hooked up. Seems a bit unnecessary to add an extra API wrapper just to do that You can test this right now by running `echo \"Hello, world!\" > /dev/usb0`, assuming a printer is connected to that USB port of your Unix-based device. https://unix.stackexchange.com/questions/141016/a-laymans-ex... reply jossephus01 5 hours agorootparentInteresting.i have always known usb0 exists but didnt think this would work. Now i am wondering what the equivalent command to print using bluetooth printers is. reply Samin100 14 hours agoprevThis is great! I wonder how hard it would be to use a pen plotter instead of a thermal printer. You could even use a procedurally generated handwriting font and Claude to make it feel like a handwritten letter. reply yellow_postit 12 hours agoparentThat’s a neat idea — I wonder about pairing it with a low cost plotter like: https://www.generativehut.com/post/ly-drawbot-a-70-pen-plott... reply mattvr 13 hours agoprevHow about showing all the money you spent/earned in the previous day, in one personalized receipt? reply bwoodward 13 hours agoprevI've wanted something like this since the days of TinyPrinter, but I just can't justify thermal printing. I'd love to have either impact or laser, however. I mostly want it for lists and recipes, but some other goodies would be fun, too. reply october8140 14 hours agoprevhttps://github.com/alibahmanyar/breaklist https://news.ycombinator.com/item?id=41742210 reply 4k93n2 10 hours agoprevtheres definitely something nice about how analog this is, but as an anti-screen solution it doesnt make much sense since you would have to spend more time using a screen to make sure your tasks are filled out the night before. for me anyway there are certain tasks i just remember so i mainly only make a note of the things i would forget, but with this i would have to write down everything reply mccolin 14 hours agoprevI have a TidByt in my office and this feels like the printed version of that. The ability to choose and order the sections of your daily newspaper from a library/app would be slick. reply NoboruWataya 4 hours agoprevVery cool looking thing, though I am confused from these comments as to whether it will kill me or not. reply mongol 10 hours agoprevI think the idea would work better using an ordinary laser printer. reply rkagerer 15 hours agoprevThis is totally awesome and would be even more wonky if it came out on a reel of teletype tape. reply sleepybrett 13 hours agoprevThis same project has been done several times. Most notably by BERG London https://nordprojects.co/projects/littleprinters/ This thing came out right on the cusp of IOT as a concept, They put a lot of nice effort into design. You could configure it for some predefined blocks of content and also some support for rss. Was nice to have a little actual pen and paper sodoku every morning on the bus. reply Mistletoe 7 hours agoprevDoes this fill your body with BPA like store receipts do for workers that touch them a lot? That would be a bad way to start each day. reply ck2 2 hours agoprevthermal receipt paper should not be handled they contain BPA and BPS which are endocrine-disrupting https://www.pca.state.mn.us/business-with-us/bpa-and-bps-in-... https://www.ecocenter.org/our-work/healthy-stuff-lab/reports... reply baumschubser 9 hours agoprevAs cool as thermal printers are, if you want to have printed news from the nyt in the morning, it might be simpler to just, you know, subscribe to the newspaper. reply CTOSian 9 hours agoprevthose cheap-as-chips thermals are nice, esp some old ones , they come with a parallel port - very retro! I used an 80mm one to print short todo/lists, they fit well into my 'ancient' pocket filofax (4-ring), alas this kind of paper is not echo friendly. reply akoboldfrying 12 hours agoprevCute project, I can see myself getting into building something like it as a hobby project. Would I pay for one? Honestly, there's no way in the world. reply blackeyeblitzar 12 hours agoprevAre there accessibly priced printers to do actual newspaper or magazine style printing? Like if you wanted to be your own small publisher. reply landgenoot 11 hours agoparentNewspapers and magazines are pressed, not printed. reply blackeyeblitzar 10 hours agorootparentIs that available at small scale? reply scraplab 8 hours agorootparentYes: https://www.newspaperclub.com/ Disclaimer: I was one of the founders of the business, but left a long time ago. It’s still a great service! We print a newspaper for our friends and family each year. reply TheMode 9 hours agorootparentprevYou could even 3d print it: https://www.youtube.com/watch?v=spvYDhja1mo (or try finding used etching presses). Though there is also the question of ink price, and ultimately an industrial printer may work better at small scale. reply mikojan 10 hours agoprev [–] Very inconvenient that people are still using Twitter. A presence on a more open network that would at least be cross-posted to, would be much appreciated. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Guten is a small-scale newspaper printer project designed to minimize screen time by delivering news in printed form. - Discussions around the project include concerns about the BPA content in thermal paper and suggestions for using BPA-free alternatives or different printing technologies like impact or dot-matrix printers. - Comparisons are made to the discontinued Little Printer, with recommendations for enhancing Guten's developer-friendliness and customization options, alongside considerations of environmental and health impacts of thermal paper."
    ],
    "points": 227,
    "commentCount": 91,
    "retryCount": 0,
    "time": 1736048832
  }
]
