[
  {
    "id": 42568399,
    "title": "One of my papers got declined today",
    "originLink": "https://mathstodon.xyz/@tao/113721192051328193",
    "originBody": "Create accountLogin Recent searches No recent searches Search options Only available when logged in. mathstodon.xyz is one of the many independent Mastodon servers you can use to participate in the fediverse. Administered by: Server stats: mathstodon.xyz: About · Status · Profiles directory · Privacy policy Mastodon: About · Get the app · Keyboard shortcuts · View source code · v4.3.1 SearchLive feeds Mastodon is the best way to keep up with what's happening. Follow anyone across the fediverse and see it all in chronological order. No algorithms, ads, or clickbait in sight. Create accountLogin About",
    "commentLink": "https://news.ycombinator.com/item?id=42568399",
    "commentBody": "One of my papers got declined today (mathstodon.xyz)779 points by GavCo 23 hours agohidepastfavorite254 comments cperciva 20 hours agoIn 2005, my paper on breaking RSA by observing a single private-key operation from a different hyperthread sharing the same L1 cache -- literally the first publication of a cryptographic attack exploiting shared caches -- was rejected from the cryptology preprint archive on the grounds that \"it was about CPU architecture, not cryptography\". Rejection from journals is like rejection from VCs -- it happens all the time and often not for any good reason. (That paper has now been cited 971 times according to Google Scholar, despite never appearing in a journal.) reply informal007 5 hours agoparentTime is always a better evaluater than anyone in any journal reply fl4tul4 14 hours agoparentprevThe journal lost, as it would have increased their h-index and reputation significantly. reply davrosthedalek 20 hours agoparentprevIs it on the arxiv? If not, please put it there. reply ilya_m 19 hours agorootparentThe paper is here: http://www.daemonology.net/hyperthreading-considered-harmful... As its author noted, the paper has done fine ciation- and impact-wise. reply cperciva 19 hours agorootparentPaper is here: https://www.daemonology.net/papers/cachemissing.pdf Your link is the website I put up for non-experts when I announced the issue. reply davrosthedalek 18 hours agorootparentprevIn this case, it's less about discoverability, but more about long term archival. Will daemonology.net continue to exist forever? Arxiv.org might perish, but I am sure the community will make sure the data will be preserved. reply cperciva 17 hours agorootparentI'm not too worried about that -- this paper is \"mirrored\" on hundreds of university websites since it's a common reference for graduate courses in computer security. reply ht_th 13 hours agorootparentIn my experience, once teachers retire or move on, or a course gets mothballed, it's only a matter of time for course websites disappear or become non-functional. If the course website was even on the open web to begin with. If they're in some university content management system (CMS), chances are that access is limited to students and teachers of that university and the CMS gets \"cleaned\" regularly by removing old and \"unused\" content. Let alone what will happen when the CMS is replaced by another after a couple of years. reply pabs3 4 hours agorootparentArchiveTeam is trying to save some of that stuff to archive.org, obviously it can't get the non-public stuff though. https://wiki.archiveteam.org/index.php/University_Web_Hostin... reply jraph 23 hours agoprevI was confused by the title because paper rejection is incredibly common in research, but that's the point and one of the goals is to fight imposter syndrome. It's a good initiative. Next step: everybody realizes that researchers are just random people like everybody. Maybe that could kill any remaining imposter syndrome. A rejection, although common, is quite tough during your PhD though, even ignoring the imposter syndrome, because in a short time, you are expected to have a bunch of accepted papers, in prestigious publications if possible. It feels like a rejection slows you down, and the clock is still ticking. If we could kill some of this nefarious system, that'd be good as well. reply arrowsmith 21 hours agoparentIt’s noteworthy because it’s from Terence Tao, regarded by many as the world’s greatest living mathematician. If you read the full post he’s making the exact same point as you: it’s common and normal to get a paper rejected even if you’re Terence Tao, so don’t treat a rejection like the end of the world. reply motorest 2 hours agorootparent> It’s noteworthy because it’s from Terence Tao, regarded by many as the world’s greatest living mathematician. I think it's important to post a follow-up comment clarifying that papers are reviewed following a double blind peer review process. So who the author is shouldn't be a factor. Also, the author clarified that the paper was rejected on the grounds that the reviewer felt the topic wasn't a good fit for the journal. This has nothing to do with the quality of the paper, but uploading editorial guidelines on the subject. Trying to file a document in a wrong section and being gently nudged to file under another section hardly matches the definition of a rejection that leads authors to question their life choices. reply ccppurcell 2 hours agorootparentJust a quick point: double blind is not common for mathematics journals, at least in my area. Some TCS conferences have started it. reply vitus 17 hours agorootparentprev> regarded by many as the world’s greatest living mathematician. Oh? Perelman comes to mind (as the only person who has been eligible to claim one of the Millennium prizes), although he is no longer actively practicing math AFAIK. Of Abel prize winners, Wiles proved Fermat's last theorem, and Szemeredi has a number of number-theoretic and combinatorial contributions. Recently deceased (past ~10 years) include figures such as John Nash, Grothendieck, and Conway. Tao is definitely one of the most well-known mathematicians, and he's still got several more decades of accomplishments ahead of him, but I don't know that he rises to \"greatest living mathematician\" at this point. That said, I do appreciate that he indicates that even his papers get rejected from time to time. reply xanderlewis 17 hours agorootparentHaving been a child prodigy somehow gives one infamy (in the wider public consciousness) beyond anything one can achieve as an adult. reply vanderZwan 4 hours agorootparentHe's a child prodigy who didn't burn out, that does make him quite rare. reply flocciput 3 hours agorootparentprevTo add to your list, you can also find Richard Borcherds teaching math on YouTube. reply jraph 12 hours agorootparentprev> It’s noteworthy because it’s from Terence Tao, regarded by many as the world’s greatest living mathematician. I didn't know :-) > If you read the full post he’s making the exact same point as you Oh yeah, that's because I did read the full post and was summarizing. I should have made this clear. reply bisby 22 hours agoparentprevIt's especially important coming from someone like Terence Tao. If one of the best and brightest mathematicians out there can get a paper declined, then it can happen to literally anyone. reply jonathan_landy 20 hours agoparentprevI guess it is nice to know that he is also not perfect. But it’s still the case that his accomplishments outshine my own, so my imposter syndrome remains intact. reply TheRealPomax 2 hours agoparentprevI'd counter the \"like everybody\": they're not. They spent a decade or more focused on honing their skills and deepening their knowledge to become experts in their subfield, and sometimes even entire fields. They are very much not random people like everybody in this context. reply firesteelrain 15 hours agoparentprevAt my college, you only need one paper not many reply jraph 12 hours agorootparentIn mine, I don't think there was a hard requirement, but your PhD would be seen as weak with zero paper, and only one would be common enough I guess but still be seen a bit weak. It's not very important to grade, but it's important for what follows: your carrier, including getting a position. reply 2-3-7-43-1807 20 hours agoparentprevterence tao is suffering from imposter syndrome? if anything, imposter syndrome is suffering from terence tao ... do you maybe not know who terence tao is? reply danielmarkbruce 14 hours agorootparentIt's terence tao trying to help others with imposter syndrome. It seems quite unlikely he himself would suffer from it... reply NooneAtAll3 14 hours agorootparenton the contrary, that's exactly what he states in comment discussion below the thread having higher reputation means higher responsibility not to crush someone with it in the sub-fields you aren't as proficient as reply danielmarkbruce 13 hours agorootparentyeah... he's telling a white lie of sorts...reread the comment. That doesn't sound like someone lacking self confidence. \"the other members collectively ...\". He's basically saying \"get the world leading experts in some area of math that I'm sort of interested in in a room and between them they'll know more than I do myself\". Lol. And, that's happened \"several times\". I'm sure he's a genuinely nice, friendly person trying to do the right thing. But he is also likely confident as hell and never felt like an imposter anywhere. reply jraph 12 hours agorootparentI don't think it's a white lie. Whether he has imposter syndrome is beside the point. It shows he has sympathy for his colleagues who might have it. Maybe he himself had it before which would let him understand even better what it is, and now he doesn't anymore, this would motivate him to make this point. The point he is making is all the motr convincing especially that he is seen as very good, whether he had imposter syndrome or not. reply danielmarkbruce 2 hours agorootparentYes, that's the point. reply bumby 22 hours agoprevAdam Grant once related an amusing rejection from a double-blind review. One of the reviewers justified the rejection with something along the lines of “The author would do well to familiarize themselves with the work of Adam Grant” reply orthoxerox 22 hours agoparentLife imitates art. In a 1986 comedy \"Back to School\" Rodney Dangerfield's character delegates his college assignments to various subject matter experts. His English Lit teacher berates him for it, saying that not only did he obviously cheat, but he also copied his essay from someone who's unfamiliar with the works of Kurt Vonnegut. Of course, the essay was written by Vonnegut himself, appearing in a cameo role. reply Cheer2171 16 hours agoparentprevFair warning: I don't know enough about mathematics to say if this is the case here. I hear this all the time, but this is actually a real phenomenon that happens when well-known senior figures are rightfully cautious about over-citing their own work and/or are just so familiar with their own work that they don't include much of it in their literature review. For everybody else in the field, it's obvious that the work of famous person X should make up a substantial chunk of the lit review and be explicit about how the new work builds on X's prior literally paradigm shifting work. You can do a bad job at writing about your own past work for a given audience for so many different reasons, and many senior academics do all the time, making their work literally indistinguishable from that of graduate students --- hence the rejection. reply bumby 16 hours agorootparentI totally understand the case when an author doesn't sufficiently give context because they are so close to their previous work that they take it for granted that it's obvious (or, like you said, they are wary of auto-citation). I may be misremembering, but I believe the case with Grant was that the referee was using his own work to discredit his submission. Ie \"If the author was aware of the work of Adam Grant, they would understand why the submitted work is wrong.\" reply Upvoter33 22 hours agoparentprevThis also happens pretty commonly. However, it's not even unreasonable! Sometimes you write a paper and you don't do a good enough of a job putting in the context of your own related work. reply CrazyStat 21 hours agorootparentAnd sometimes the reviewer didn't read carefully and doesn't understand what you're doing. I once wrote a paper along the lines of \"look we can do X blazingly fast, which (among other things) lets us put it inside a loop and do it millions of times to do Y.\" A reviewer responded with \"I don't understand what the point of doing X fast is if you're just going to put it in a loop and make it slow again.\" He also asked us to run simulations to compare our method to another paper which was doing an unrelated thing Z. The editor agreed that we could ignore his comments. reply Metacelsus 17 hours agoparentprevI, as a reviewer, made a similar mistake once! The author's initial version seemed to contradict one of their earlier papers but I was missing some context. reply j-krieger 6 hours agorootparentI also made this mistake! I recommended the author to read an adjacent work, which turned out to be by the very same author. He had just forgot to include it his work. reply adastra22 55 minutes agorootparentI’ve had it happen to me. Paper rejected because it was copying and not citing a prior message to a mailing list… the message from the mailing list was mine, and the paper was me turning it into a proper publication. reply Nevermark 22 hours agoparentprevYes, funny the first time. Not so much the fifth! reply remoquete 23 hours agoprevI find it refreshing when researchers disclose their own failures. Science is made of negative results, errors, and rejections, though it's often characterized in a much different, unrealistic way. By the way, even though some of you may know about it, here's the link to the Journal of Negative Results: https://www.jnr-eeb.org/index.php/jnr reply PaulHoule 3 hours agoprevIf you stick around in physics long enough you will submit a paper to Physical Review Letters (which is limited to about four pages) that gets rejected because it isn't of general enough interest, then you resubmit to some other section of The Physical Review and get in. These days I read a lot of CS papers with an eye on solving the problems and personally I tend to find the short ones useless. (e.g. pay $30 for a 4-page paper because it supposedly has a good ranking function for named entity recognition except... it isn't a good ranking function) reply UniverseHacker 23 hours agoprevI am actually quite surprised Terence Tao still gets papers rejected from math journals... but appreciate him sharing this, as hearing this from him will help newer scientists not get discouraged by a rejection. I had the lucky opportunity to do a postdoc with one of the most famous people in my field, and I was shocked how much difference the name did make- I never had a paper rejection from top tier journals submitting with him as the corresponding author. I am fairly certain the editors would have rejected my work for not being fundamentally on an interesting enough topic to them, if not for the name. The fact that a big name is interested in something, alone can make it a \"high impact subject.\" reply vouaobrasil 22 hours agoparent> I am actually quite surprised Terence Tao still gets papers rejected from math journals At least it indicates that the system is working somewhat properly some of the time... reply 9dev 9 hours agorootparentI find it bewildering that it wouldn’t, actually. I would have expected one of the earliest things in the review process happening would be to black out the submitters name and university, only to be revealed after the review is closed. reply vouaobrasil 7 hours agorootparentWell, the editor still sees the name of the submitter, and can also push the reviewers for an easy publication by downplaying the requirements of the journal. reply scubbo 20 hours agorootparentprevCould you elaborate on this statement? It sounds like you're implying something, but it's not clear what. reply monktastic1 19 hours agorootparentI interpret it as saying that at least the system hasn't just degraded into a rubber stamp (where someone like Tao can publish anything on name alone). reply TN1ck 19 hours agorootparentprevI think it’s that a paper submitted by one of the most famous authors in the math field is not auto approved by the journals. That even he has to go through the normal process and gets rejected at times. reply jcrites 20 hours agoparentprevCould that also be because he reviewed the papers first and made sure they were in a suitable state to publish? Or you think it really was just the name alone, and if you had published without him they would not have been accepted? reply UniverseHacker 19 hours agorootparentHe only skimmed them- scientists at his level are more like a CEO than the stereotype of a scientist- with multiple large labs, startups, and speaking engagements every few days. He trusted me to make sure the papers were good- and they were, but his name made the difference between getting into a good journal in the field, and a top “high impact” journal that usually does not consider the topic area popular enough to accept papers on, regardless of the quality or content of the paper. At some level, high impact journals are a popularity contest- to maintain the high citation rate, they only publish from people in large popular fields, as having more peers means more citations. reply ndesaulniers 22 hours agoprevThe master has failed more than the beginner has tried. reply TZubiri 22 hours agoprev\"Rejection is actually a relatively common occurrence for me, happening once or twice a year on average.\" This feels like a superhuman trying to empathize with a regular person. reply asah 23 hours agoprevNon-zero failure rate is indeed often optimal because it provides valuable feedback toward finding the optimal horizon for various metrics, e.g. speed, quality, LPU[1], etc. That said, given the labor involved in academic publishing and review, the optimal rejection rate should be quite low, i.e. find a lower cost way to pre-filter papers. OTOH, the reviewers may get value from rejected papers... [1] least publishable unit reply kittikitti 19 hours agoprevAcademia is a paper tiger. The Internet means you don't need a publisher for your work. Ironically, this self published blog might be one of his most read works yet. reply snowwrestler 17 hours agoparentYou never needed a publisher; before the Internet you could write up your findings and mail them to relevant people in your field. Quite a lot of scientists did this, actually. What publication in a journal gives you is context, social proof, and structured placement in public archives like libraries. This remains true in the age of the Internet. reply tetha 21 hours agoprev> Because of this, a perception can be created that all of one's peers are achieving either success or controversy, with one's own personal career ending up becoming the only known source of examples of \"mundane\" failure. I've found similar insights when I joined a community of musicians and also discovered twitch / youtube presences of musicians I listen to. Some of Dragonforces corona streams are absolutely worth a watch. It's easy to listen to mixed and finished albums and... despair to a degree. How could anyone learn to become that good? It must be impossible, giving up seems the only rational choice. But in reality, people struggle and fumble along at their level. Sure enough, the level of someone playing guitar professionally for 20 years is a tad higher than mine, but that really, really perfect album take? That's the one take out of a couple dozen. This really helped me \"ground\" or \"calibrate\" my sense of how good or how bad I am and gave me a better appreciation of how much of a marathon an instrument can be. reply amichail 23 hours agoprevSure, even top mathematicians have paper rejections. But I think the more important point is that very few people are capable of publishing papers in top math journals. reply atrettel 22 hours agoprevI agree with the discussion that rejection is normal and researchers should discuss it more often. That said, I do think that \"publish or perish\" plays an unspoken role here. I see a lot of colleagues trying to push out \"least publishable units\" that might barely pass review (by definition). If you need to juice your metrics, it's a common strategy that people employ. Still, I think a lot of papers would pass peer review more easily if researchers just combined multiple results into a single longer paper. I find those papers to be easier to read since they require less boilerplate, and I imagine they would be easier to pass peer review by the virtue that they simply contain more significant results. reply matthewdgreen 45 minutes agoparentOne of the issues is that we have grad students, and they need to publish in order to travel through the same cycle that we went through. As a more senior scientist I would be thrilled to publish one beautiful paper every two years, but then none of my students would ever learn anything or get a job. reply nextn 22 hours agoparentprevLonger papers with more claims have more to prove, not less. I imagine they would be harder to pass peer review. reply atrettel 18 hours agorootparentI agree with your first part but not your second. Most authors do not make outrageous claims, and I surely would reject their manuscript if they did. I've done it before and will do it again without any issue. To me, the point of peer review is to both evaluate the science/correctness of the work, but also to ensure that this is something novel that is worth telling others about. Does the manuscript introduce something novel into the literature? That is my standard (and the standard that I was taught). I typically look for at least one of three things: new theory, new data/experiments, or an extensive review and summation of existing work. The more results the manuscript has, the more likely it is to meet this novelty requirement. reply tredre3 21 hours agorootparentprev> Longer papers with more claims have more to prove, not less. I imagine they would be harder to pass peer review. Yes, a longer paper puts more work on the peer reviewers (handful of people). But splitting one project in multiple papers puts more work on the reader (thousands of people). There is a balance to strike. reply paulpauper 20 hours agoparentprevLots of co-authors. That is one surefire way to inflate it. reply kzz102 20 hours agoprevIn academic publishing, there is an implicit agreement between the authors and the journal to roughly match the importance of the paper to the prestige of the journal. Since there is no universal standard on either the prestige of the journal or the importance of the paper, mismatches happen regularly, and rejection is the natural result. In fact, the only way to avoid rejections is to submit a paper to a journal of lower prestige than your estimate, which is clearly not what authors want to do. reply directevolve 13 hours agoparentIt’s not an accident - if academics underestimated the quality of their own work or overestimated that of the journal, this would increase acceptance rates. Authors start at an attainable stretch goal, hope for a quick rejection if that’s the outcome, and work their way down the list. That’s why rejection is inevitable. reply ak_111 22 hours agoprevI always thought that part of the upside of being tenured and extremely recognised as a leader of your field is the freedom to submit to incredibly obscure (non-predatory) journals just for fun. reply ziofill 22 hours agoprevThis is his main point, and I wholeheartedly agree: …a perception can be created that all of one's peers are achieving either success or controversy, with one's own personal career ending up becoming the only known source of examples of \"mundane\" failure. I speculate that this may be a contributor to the \"impostor syndrome\"… reply drumhead 8 hours agoprevSaw the title and thought, nothing unusual in that really, then saw the domain was maths based, it's not Terrence Tao is it?! It was Terrence Tao. If one of the greats can get rejected then there's no shame in you getting rejected. reply aborsy 22 hours agoprevResearch is getting more and more specialized. Increasingly there may not be many potential journals for a paper, and, even if there are, the paper might be sent to the same reviewers (small sub communities). You may have to leave a year of work on arxiv, with the expectation that the work will be rehashed and used in other published papers. reply iamnotsure 11 hours agoprevPlease note that despite much work being done in the equality department being famous is nowadays still a requirement for acquiring the status of impostor syndrome achiever. Persons who are not really famous do not have impostor syndrome but are just a simple copycats in this respect. reply lcnPylGDnU4H9OF 2 hours agoparentSo the non-famous people who claim to have impostor syndrome are actual impostors because they claim to have impostor syndrome. Honestly, that seems like a bit of a weird take but to each their own. reply j7ake 11 hours agoprevWe can laugh at academia but we know of these similar rejection stories nearly in all domains. AirBnB being rejected for funding, musicians like Schubert struggling their entire life, writers like Rowling in poverty. Rejection will always be the norm in competitive winner take all dynamics. reply slackr 20 hours agoprevReminds me—I wish someone would make an anti-LinkedIn, where the norm is to announce only setbacks and mistakes, disappointments etc. reply omoikane 20 hours agoparentThere was a site where people posted company failures: https://en.wikipedia.org/wiki/Fucked_Company reply remoquete 20 hours agoparentprevFolks already do. They often turn them into inspirational tales. reply 77pt77 16 hours agoparentprevJust like in academia, no one cares about negative results in professional settings. reply justinl33 21 hours agoprevIt’s okay Terence, it happens to the best of us. reply ak_111 22 hours agoprev- hey honey how was work today? - it was fine, I desk rejected terence tao, his result was a bit meh and the write up wasn't up to my standard. Then I had a bit of a quite office hour, anyway, ... reply Der_Einzige 22 hours agoparentI've had the surreal moment of attending a workshop where the main presenter (famous) is talking about their soon to-be-published work where I realize that I'm one of their reviewers (months after I wrote the review, so no impact on my score). In this case, I loved their paper and gave it high marks, and so did the other reviewers. Not surprising when I found out who the author was!!! I have to not say a word to them as I talk to them or else I could ruin the whole peer review thing! \"Hey honey, I reviewed X work from Y famous person today\" reply krisoft 8 hours agorootparent> I have to not say a word to them as I talk to them or else I could ruin the whole peer review thing! In what sense would it ruin peer review to reveal your role after you already wrote and submitted the review? reply d0mine 22 hours agoprevWhy journals exist at all? Could papers be published on something like arxiv.org (like software is on github.com)? It could support links/backref, citations(forks), questions(discussions), tags, followers, etc easily. reply bumby 22 hours agoparentPart of the idea is that journals help curate better publications via the peer review process. Whether or not that occurs in practice is up for some debate. Having a curated list can be important to separate the wheat from the chaff, especially in an era with ever increasing rates of research papers. reply d0mine 10 hours agorootparentEliminating journals as a corporate monopoly doesn't eliminate peer review. For example, it should be easy to show the number of citations and even their specific context in other articles on the arxiv-like site. For example, if I like some app/library implementation on github, I look at their dependencies (a citation in a sense) to discover things to try. Curated lists can also exist on the site. Look at awesome* repos on github eg https://github.com/vinta/awesome-python Obviously, some lists can be better than the others. Usual social mechanics is adequate here. reply bumby 5 hours agorootparentI think citation is a noisy/poor signal for peer-review. I've refereed a number of papers where I dig into the citations and find the article doesn't actually support the author's claim. Still, the vast majority of citations go unchecked. I don't think peer-review has to be done by journals, I'm just not sure what the better solution is. reply d0mine 4 hours agorootparentI’ve definitely encountered such cases myself (when actual cited paper didn’t support author’s claims). Nothing prevents the site introducing more direct peer review (published X papers on a topic -> review a paper). Though If we compare two cases: reading a paper to leave an anonymous review vs reading a paper to cite it. The latter seems like more authentic and useful (less perversed incentives). reply sunshowers 20 hours agoparentprevI think in math, and in many other fields, it is pretty normal to post all papers on arXiv. But arXiv has a lot of incorrect papers on it (tons of P vs NP papers for example), so journals are supposed to act as a filtering mechanism. How well they succeed at it is debated. reply d0mine 9 hours agorootparentIt is naive to think that “journal paper” means correct paper. There are many incorrect papers in journals too (remember reproduction crisis). Imagine, you found a paper on arxiv-like site: there can be metadata that might help determine quality (author credentials, citations by other high-ranked papers, comments) but nothing is certain. There may be cliques that violently disagree with each other (paper clusters with incompatible theories). The medium can help with highlighting quality results (eg by choosing the default ranking algorithm for the search, introducing StackOverflow-like gamification) but it can’t and shouldn’t do science instead of practitioners. reply haunter 22 hours agoprevfwiw, editorial review =/= peer review reply soheil 9 hours agoprevShould we therefore also publicize everything else that lies between success and failure? reply abetusk 23 hours agoprevThe second post in that thread is gold: \"\"\" ... I once almost solved a conjecture, establishing the result with an \"epsilon loss\" in a key parameter. We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture. So we submitted elsewhere, and the paper was accepted. The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again. This time, the paper was rejected for only being an epsilon improvement over the previous literature! ... \"\"\" reply YouWhy 23 hours agoparentWhile I'm not a mathematician, I think such an attitude on behalf of the journal does not encourage healthy community dynamics. Instead of allowing the community to join forces by breaking up a larger problem into pieces, it encourages siloing and camper mentality. reply abetusk 22 hours agorootparentI agree. This is also a lack of effort on the journal's part to set expectations of what the reviewers should be looking for in an accepted paper. In the journal's defense though, what most likely happened is that the reviewers were different between submissions and they didn't know about the context. Ultimately, I think, this type of rejection comes down to the mostly the reviewers discretion and it can lead to this type of situation. I cut off the rest of the post but Tao finished it with this: \"\"\" ... Being an editor myself, and having had to decline some decent submissions for a variety of reasons, I find it best not to take these sorts of rejections personally, ... \"\"\" reply SergeAx 10 hours agoprevWe often talk about how important it is to be a platform for oneself, self-host blog under own domain etc. Why it is not the case for science papers, articles, issues? Like, isn't the whole World Wide Web was invented specifically for that? reply cess11 21 hours agoprevJournals are typically for-profit, and science is not, so they don't always align and we should not expect journals to serve science except incidentally. reply 23B1 21 hours agoprevA similar story. I actively blogged about my thesis and it somehow came up in one of those older-model plagarism detectors (this was years and years ago, it might have been just some hamfisted google search). The (boomer) profs convened a 'panel' without my knowledge and decided I had in fact plagiarized, and informed me I was in deep doo doo. I was pretty much ready to lose my mind, my career was over, years wasted, etc. Luckily I was buddy with a Princeton prof. who had dealt with this sort of thing and he guided me through the minefield. I came out fine, but my school never apologized. Failure is often just temporary and might not even be real failure. reply dwaltrip 23 hours agoprevHilarious irony: > With hindsight, some of my past rejections have become amusing. With a coauthor, I once almost solved a conjecture, establishing the result with an \"epsilon loss\" in a key parameter. We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture. So we submitted elsewhere, and the paper was accepted. > The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again. This time, the paper was rejected for only being an epsilon improvement over the previous literature! reply bumby 21 hours agoparentA lot of the replies make it seem like there is some great over-arching coordination and intent between subsequent submissions, but I’ll offer up an alternative explanation: sometimes the reviewer selection is an utter crap shoot. Just because the first set of reviewers may offer a justification for rejection, it may be completely unrelated to the rationale of a different set of reviewers. Reviewers are human and bring all kinds of biases and perspectives into the process. It’s frustrating but the result of a somewhat haphazard process. It’s also not uncommon for conflicting comments within the same review cycle. Some of this may be attributed to a lack of clear communication by the author. But on occasion, it leads me to believe many journals don’t take a lot of time selecting appropriate reviewers and settle for the first few that agree to review. reply dhosek 16 hours agorootparentLuck plays a lot of a role in many vaguely similar things. I regularly submit fiction and poetry for publication (with acceptance rates of 2% for fiction and 1.5% for poetry) and so much depends on things well out of my control (which is part of why I’m sanguine about those acceptance rates—given the venues I‘m submitting to, they’re not unreasonable numbers and more recent years’ stats are better than that).¹ In many cases the editors like what they read, but don’t have a place for it in the current issue or sometimes they’re just having a bad day. ⸻ 1. For those who care about the full messy details I have charts and graphs at https://www.dahosek.com/2024-in-reejctions-and-acceptances/ reply keepamovin 15 hours agorootparentprevAnd this is how we do science? How is that a good basis for scientific reality? Seems there should at least be transparency and oversight, or maybe the whole system is broke: open reviews on web not limited to a small committee sounds better. Science is about the unknown, building testable models and getting data. Even an AI review system could help. reply larodi 9 hours agorootparentThis is how we don’t do papers. Even though my pal did a full Gouraud shading in pure assembly using registers only (including the SP and a dummy stack segment) - absolute breakthrough back in 1997. We did a 4 server p3 farm seeding 40mbits of outward traffic in 1999. Myself did a complete Perl-based binary stream unpacking - before protobuf was a thing. Still live handling POS terminals. Discovered a much more effective teaching methodology which almost doubled effectiveness. Time-series compression with grammars,… And many more as we keep doing new r&d. None of it is going to be published as papers on time (if ever), because we really don’t want to suffer this process which brings very little value afterwards for someone outside academia or even for people in academia unless they peruse PHD and similar positions. I’m struggling to force myself to write an article on text2sql which is already checked and confirmed to contain a novel approach to RAG which works, but do I want to suffer such rejection humiliation? Not really… It seems this paper ground is reserved for academics and mathematics in a certain ‘sectarian modus operandi’, and everyone else is a sucker. Sadly after a while the code is also lost… reply tsurba 7 hours agorootparentIf you are not even going to bother writing them up properly, no one is going to care. Seems fair to me. You don’t have to make a ”paper” out of it, maybe make blog post or whatever if that is more your style. Maybe upload a pdf to arxiv. Half the job in science is informing (or convincing) everyone else about what you made and why it is significant. That’s what conferences try to facilitate, but if you don’t want to do that, feel free to do the ”advertising” some other way. Complaining about journals being selective is just a lazy excuse for not publishing anything to help others. Sure the system sucks, but then you can just publish some other way. For example, ask other people who understand your work to ”peer review” your blog posts. reply fhdjkghdfjkf 6 hours agorootparent> Half the job in science is informing (or convincing) everyone else about what you made and why it is significant. Additionally, writing is the best way to properly think things through. If you can't write an article about your work then most likely you don't even understand it yet. Maybe there are critical errors in it. Maybe you'll find that you can further improve it. By researching and citing the relevant literature you put your work in perspective, how it relates to other results. reply spenczar5 3 hours agorootparentprev“do I want to suffer such rejection humiliation? Not really” The point of Terence Tao’s original post is that you just cannot think of rejection as humiliation. Rejection is not a catastrophe. reply pabs3 4 hours agorootparentprev> Sadly after a while the code is also lost… Get it included in the archives of Software Heritage and Internet Archive: https://archive.softwareheritage.org/ https://wiki.archiveteam.org/index.php/Codearchiver reply marvel_boy 4 hours agorootparentprev>Discovered a much more effective teaching methodology which almost doubled effectiveness. Please, could you elaborate? reply michaelt 9 hours agorootparentprev> And this is how we do science? How is that a good basis for scientific reality? The journal did not go out empty, and the paper did not cease to exist. The incentives on academics reward them for publishing in exclusive journals, and the most exclusive journals - Nature, Science, Annals of Mathematics, The BMJ, Cell, The Lancet, JAMS and so on - only publish a limited number of pages in each issue. Partly because they have print editions, and partly because their limited size is why they're exclusive. A rejection from \"Science\" or \"Nature\" doesn't mean that your paper is wrong, or that it's fraudulent, or that it's trivial - it just means you're not in the 20 most important papers out of the 50,000 published this week. And yes, if instead of making one big splash you make two smaller splashes, you might well find neither splash is the biggest of the week. reply n144q 14 hours agorootparentprevIt is not a good way of doing science, but it is the best we have. All the alternatives, including the ones you proposed, have their own serious downsides, which is why we kept the status quo for the past few decades. reply eeeeeeehio 13 hours agorootparentPeer review is not designed for science. Many papers are not rejected because of an issue with the science -- in fact, reviewers seldom have the time to actually check the science! As a CS-centric example: you'll almost never find a reviewer who reads a single line of code (if code is submitted with the paper at all). There is artifact review, but this is never tied to the acceptance of the paper. Reviewers focus on ideas, presentation, and the presented results. (And the current system is a good filter for this! Most accepted papers are well-written and the results always look good on paper.) However, reviewers never take the time to actually verify that the experiment code matches the ideas described in the paper, and that the results reproduce. Ask any CS/engineering PhD student how many papers (in top venues) they've seen with a critical implementation flaw that invalidates the results -- and you might begin to understand the problem. At least in CS, the system can be fixed, but those in power are unable and unwilling to fix it. Authors don't want to be held accountable (\"if we submit the code with the paper -- someone might find a critical bug and reject the paper!\"), and reviewers are both unqualified (i.e. haven't written a line of code in 25 years) and unwilling to take on more responsibility (\"I don't have the time to make sure their experiment code is fair!\"). So we are left with an obviously broken system where junior PhD students review artifacts for \"reproducibility\" and this evaluation has no bearing whatsoever on whether a paper gets accepted. It's too easy to cook up positive results in almost any field (intentionally, or unintentionally), and we have a system with little accountability. It's not \"the best we have\", it's \"the best those in power will allow\". Those in power do not want consequences for publishing bad research, and also don't want the reviewing load required to keep bad research out. reply Ar-Curunir 10 hours agorootparentThis is much too negative. Peer review indeed misses issues with papers, but by-and-large catches the most glaring faults. I don’t believe for one moment that the vast majority of papers in reputable conferences are wrong, if only for the simple reason that putting out incorrect research gives an easy layup for competing groups to write a follow-up paper that exposes the flaw. It’s also a fallacy to state that papers aren’t reproducible without code. Yes code is important, but in most cases the core contribution of the research paper is not the code, but some set of ideas that together describe a novel way to approach the tackled problem. reply izacus 9 hours agorootparentI spent a chunk of my career working on productionizing code from ML/AI papers and huge part of them are outright not reproducible. Mostly they lack critical information (missing chosen constants in equations, outright missing information on input preparation or chunks of \"common knowledge algorithms\"). Those that don't have measurements that outright didn't fit the reimplemented algorithms or only succeeded in their quality on the handpicked, massaged dataset of the author. It's all worse than you can imagine. reply tsurba 7 hours agorootparentThat’s the difference between truly new approaches to modelling an existing problem, or coming up with a new problem. No set of a bit different results or missing exact hyperparameter settings really invalidates the value of the aforementioned research. If the math works, and is a nice new point of view, its good. It may not even help anyone with practical applications right now, but may inspire ideas further down the line that do make the work practicable, too. In contrast, if the main value of a paper is a claim that they increase performance/accuracy in some task by x%, then its value can be completely dependent on whether it actually is reproduceable. Sounds like you are complaining about the latter type of work? reply izacus 5 hours agorootparentI don't think theres much value in theoretical approaches that lack important derivation data either, so no need to try to split the papers like this. The academic CS publishing is flooded with bad quality papers in any case. reply withinboredom 10 hours agorootparentprevI spent 3 months implementing a paper once. Finally, I got to the point where I understood the paper probably better than the author. It was an extremely complicated paper (homomorphic encryption). At this point, I realized that it doesn't work. There was nothing about it that would ever work, and it wasn't for lack of understanding. I emailed the author asking to clarify some specific things in the paper, they never responded. In theory, the paper could work, but it would be incredibly weak (the key turned out to be either 1 or 0 -- a single bit). reply Ar-Curunir 8 hours agorootparentDo you have a link to the paper? reply no_identd 6 hours agorootparent+1 reply jeltz 5 hours agorootparentprevAnecdotally it is not. Most papers in CS I have read have been bad and impossible to reproduce. Maybe I have been unlucky but my experience is sadly the same. reply franga2000 9 hours agorootparentprevI don't think anyone is saying it's not reproducible without code, it's just much more difficult for absolutely no reason. If I can run the code of a ML paper, I can quickly check if the examples were cherry-picked, swap in my own test or training set... The new technique or idea was still the main contribution, but I can test it immediately, apply it to new problems, optimise the performance to enable new use-cases... It's like a chemistry paper for a new material (think the recent semiconductor thing) not including the amounts used and the way the glassware was set up. You can probably get it to work in a few attempts, but then the result doesn't have the same properties as described, so now you're not sure if your process was wrong or if their results were. reply pastage 8 hours agorootparentMore code should be released, but code is dependent on the people or environment that run it. When I release buggy code I will almost always have to spend time supporting others in how to run it. This is not what you want to do in Proof of concept to prove an idea. I am not published but I have implemented a number of papers to code, it works fine (hashing, protocols and search mostly). I have also used code dumps to test something directly. I think I spend less time on code dumps, and if I fail I give up easier. That is the danger you start blaming the tools instead of how good you have understood the ideas. I agree with you that more code should be released.. It is not a solution for good science though. reply cauch 7 hours agorootparentprevSharing the code may also share the incorrect implementation biases. It's a bit like saying that to help reproduce the experiment, the experimental tools used to reach the conclusion should be shared too. But reproducing the experiment does not mean \"having a different finger clicking on exactly the same button\", it means \"redoing the experiment from scratch, ideally with a _different experimental setup_ so that it mitigates the unknown systematic biases of the original setup\". I'm not saying that sharing code is always bad, you give examples of how it can be useful. But sharing code has pros and cons, and I'm surprised to see so often people not understanding that. reply HPsquared 7 hours agorootparentIf they don't publish the experimental setup, another person could use the exact same setup anyway without knowing. Better to publish the details so people can actually think of independent ways to verify the result. reply cauch 4 hours agorootparentBut they will not make the same mistakes. If you ask two persons to build a software, they can use the same logic and build the same algorithm, but what are the chances they will do exactly the same bugs. Also, your argument seems to be \"_maybe_ they will use the exact same setup\". So it already looks better than the solution where you provide the code and they _will for sure_ use the exact same setup. And \"publish the details\" corresponds to explain the logic, not share the exact implementation. Also, I'm not saying that sharing the code is bad, but I'm saying that sharing the code is not the perfect solution and people who thinks not sharing the code is very bad are usually not understanding what are the danger of sharing the code. reply pegasus 3 hours agorootparentNobody said sharing the code \"is the perfect solution\". Just that sharing the code is way better and should be commonplace, if not required. Your argument that not doing so will force other teams to do re-write the code seems unrealistic to me. If anyone wants to check the implementation they can always disregard the shared code, but having it allows other, less time-intensive checks to still happen: like checking for cherry-picked data, as GP suggested, looking through the code for possible pitfalls etc. Besides, your argument could be extended to any specific data the paper presents: why publish numbers so people can get lazy and just trust them? Just publish the conclusion and let other teams figure out ways to prove/disprove it! - which is (more than) a bit ridiculous, wouldn't you say? reply izacus 5 hours agorootparentprevWhat you're deliberately ignoring is that omitting important information is material to a lot of papers because the methodology was massaged into desired results to created publishable content. It's really strange seeing how many (academic) people will talk themselves into bizarre explanations for a simple phenomenon of widespread results hacking to generate required impact numbers. Occams razor and all that. reply cauch 4 hours agorootparentIf it is massaged into desired results, then it will be invalidated by facts quite easily. Inversely, obfuscating things is also easy if you just provide the whole package and just say \"see, you click on the button and you get the same result, you have proven that it is correct\". No providing code means that people will redo their own implementation and come back to you when they will see they don't get the same results. So, no, no need to invent that academics are all part of this strange crazy evil group. Academics are debating and are being skeptical of their colleagues results all the time, which is already contradictory to your idea that the majority is motivated by frauding. Occams razor is simply that there are some good reasons why code is not shared, going from laziness to lack of expertise on code design to the fact that code sharing is just not that important (or sometimes plainly bad) for reproducibility, no need to invent that the main reason is fraud. reply izacus 2 hours agorootparentOk, that's a bit naive now. The whole \"replication crisis\" is exactly the term for bad papers not being invalidated \"easily\". [1] Beacuse - if you'd been in academia - you'd find out that replicating papers isn't something that will allow you to keep your funding, your job and your path to next title. And I'm not sure why did you jump to \"crazy evil group\" - noone is evil, everyone is following their incentives and trying to keep their jobs and secure funding. The incentives are perverse. This willing blindness against perverse incentives (which appears both in US academia and corporate world) is a repeated source of confusion for me - is the idea that people aren't always perfectly honest when protecting their jobs, career success and reputation really so foreign to you? [1]:https://en.wikipedia.org/wiki/Replication_crisis reply kortilla 10 hours agorootparentprevThey aren’t necessarily wrong but most are nearly completely useless due to some heavily downplayed or completely omitted flaw that surfaces when you try to implement the idea in actual systems. There is technically academic novelty so it’s not “wrong”. It’s just not valuable for the field or science in general. reply DiogenesKynikos 11 hours agorootparentprev> It's not \"the best we have\", it's \"the best those in power will allow\". Those in power do not want consequences for publishing bad research, and also don't want the reviewing load required to keep bad research out. This is a very conspiratorial view of things. The simple and true answer is your last suggestion: doing a more thorough review takes more time than anyone has available. Reviewers work for free. Applying the level of scrutiny you're requesting would require far more work than reviewers currently do, and maybe even something approaching the amount of work required to write the paper in the first place. The more work it takes to review an article, the less willing reviewers are to volunteer their time, and the harder it is for editors to find reviewers. The current level of scrutiny that papers get at the peer-review stage is a result of how much time reviewers can realistically volunteer. Peer review is a very low standard. It's only an initial filter to remove the garbage and to bring papers up to some basic quality standard. The real test of a paper is whether it is cited and built upon by other scientists after publication. Many papers are published and then forgotten, or found to be flawed and not used any more. reply ksenzee 10 hours agorootparent> Reviewers work for free. If journals were operating on a shoestring budget, I might be able to understand why academics are expected to do peer review for free. As it is, it makes no sense whatsoever. Elsevier pulls down huge amounts of money and still manages to command free labor. reply withinboredom 10 hours agorootparentI think it has to be this way, right? Otherwise a paid reviewer will have obvious biases from the company. reply ksenzee 9 hours agorootparentIt seems to me that paying them for their time would remove bias, rather than add it. reply nativeit 9 hours agorootparentHow is that? reply flir 3 hours agorootparentI guess the sensible response is \"what bias does being paid by Elsevier add that working for free for Elsevier doesn't add?\" The external bias is clear to me (maybe a paper undermines something you're about to publish, for example) but I honestly can't see much additional bias in adding cash to a relationship that already exists. reply vixen99 9 hours agorootparentprevhttps://www.science.org/content/article/fake-scientific-pape... reply eru 13 hours agorootparentprev> It is not a good way of doing science, but it is the best we have. What makes you think so? We already have and had plenty of other ways. Eg you can see how science is done in corporations or for the military or for fun (see those old gentlemen scientists, or amateurs these days), and you can also just publish things on your own these days. The only real function of these old fashioned journals is as gatekeepers for funding and career decisions. reply n144q 4 hours agorootparentI heard first hand accounts from multiple people of running into a different set of problems (from academia) publishing papers in corporations. Publishing is never simple or easy. If you have concrete examples, or better, generally recognized studies that show there is an objectively better way to do research, I'd very like to know that. Because, as an PhD who knows dozens of other PhDs in both academia and industry, and who has never heard of this magic new approach to doing science, it would be quite a surprise. reply bumby 2 hours agorootparentI think the distinction in the examples given (corporations, military), science is being done but much less open. reply psychoslave 9 hours agorootparentprevSo the lesson is there is not a single good way to do science (or anything really), as whatever the approach retained, there will be human biases involved. So the less brittle option obviously might be to go through all possible approaches, but this is obviously more resources demanding, plus we still have the issue of creating some synthesis of all the accumulated insights from various approaches which itself might be taken into various approaches. That’s more of a indefinitely deep spiral, under that perspective An other perspective is to consider, what are the expected outcomes of the stakeholders maybe. A shiny academic career? An attempt to bring some enlightenment on deep cognitive patterns to the luckiest follows that have the resources at end to follow your high level intellectual gymnastic? A pursuit of ways to improve humanity condition through relevant and sound knowledge bodies? There are definitely many others. reply Panoramix 14 hours agorootparentprevWe kept that mostly due to inertia and because it's the most profitable for the journals (everybody does their work for free and they don't have to invest in new systems), not because it's the best for science and scientists. reply tuyiown 9 hours agorootparentprev> It is not a good way of doing science, but it is the best we have. It may have been for some time, but there is human social dynamics in play. reply fastball 14 hours agorootparentprevWhat is the serious downside of open internet centric review? reply Al-Khwarizmi 8 hours agorootparentIf by \"open\" you mean that the paper is there and people just voluntarily choose to review it, rather than having some top-down coordinated assignment process, the problem is that papers by the superstars would get hundreds of reviews while papers from unknown labs would get zero. You could of course make it double blind, but that seems hard to enforce in practice in such an open setup, and still, hyped papers in fashionable topics would get many reviews while papers that are hardcore theoretical, in an underdog domain, etc. would get zero. Finally, it also becomes much more difficult to handle conflicts of interest, and the system is highly vulnerable to reviewer collusion. reply daemontus 10 hours agorootparentprevAs others have mentioned, the main problem is that open systems are more vulnerable to low-cost, coordinated external attacks. This is less of an issue with systems where there is little monetary value attached (I don't know anyone whose mortgage is paid for by their Stack Overflow reputation). Now imagine that the future prospects of a national lab with multi-million yearly budget are tied to a system that can be (relatively easily) gamed with a Chinese or Russian bot farm for a few thousand dollars. There are already players that are trying hard to game the current system, and it sometimes sort of works, but not quite, exactly because of how hard it is to get into the \"high reputation\" club (on the other hand, once you're in, you can often publish a lot of lower quality stuff just because of your reputation, so I'm not saying this is a perfect system either). In other words, I don't think anyone reasonable is seriously against making peer review more transparent, but for better or worse, the current system (with all of its other downsides) is relatively robust to outside interference. So, unless we (a) make \"being a scientist\" much more financially accessible, or (b), untangle funding from this new \"open\" measure of \"scientific achievement\", the open system would probably not be very impactful. Of course, (a) is unlikely, at least in most high-impact fields; CS was an outlier for a long time, not so much today. And (b) would mean that funding agencies would still need something else to judge your research, which would most likely still be some closed, reputation-based system. Edit TL;DR: Describe how the open science peer-review system should be used to distribute funding among researchers while begin reasonably robust to coordinated attacks. Then we can talk :) reply reilly3000 14 hours agorootparentprevThe open internet. i.e. trolls, brigades, spammers, bots, and all manner of uninformed voices. reply bruce511 14 hours agorootparentTo expand on this - because if the barrier to publishing is zero, then the \"reputation\" of the publisher is also zero. (Actually, we already have the \"open publishing\" you are suggesting - it's called Blogging or social media.) In other words, if we have open publishing, then someone like me (with zero understanding of a topic) can publish a very authentic-looking pile of nonsense with exactly the same weight as someone who, you know, has actually done some science and knows what they're talking about. The common \"solution\" to this is voting - like with StackOverflow answers. But that is clearly trivial to game and would quickly become meaningless. So human review it is - combined with the reputation that a journal brings. The author gains reputation because some reviewers (with reputation) reviewed the paper, and the journal (with reputation) accepted it. Yes, this system is cumbersome, prone to failure, and subject to outside influences. It's not perfect. Just the best we have right now. reply eru 13 hours agorootparent> To expand on this - because if the barrier to publishing is zero, then the \"reputation\" of the publisher is also zero. That's fine. I don't read eg Astral Codex Ten because I think the reputation of Substack is great. The blog can stand entirely on its own reputation (and the reputation of its author), no need for the publisher to rent out their reputation. See also Gwern.net for a similar example. No need for any voting. reply ricksunny 11 hours agorootparentprevReviewers could themselves have reputation levels that weight how visible their review is. This would make brigading more costly. There might still be a pseudoscientific brigade trying to take down (or boost) a particular paper, one that clusters so much that it builds its own competing reputatation, but that's okay. The casual reader can decide which high-vote reviews to follow on their own merits. reply hanche 20 hours agorootparentprev> sometimes the reviewer selection is an utter crap shoot Indeed, but when someone of Tao's caliber submits a paper, any editor would (should) make an extra effort to get the very best researchers to referee the paper. reply crote 19 hours agorootparentBut isn't that exactly why the submission should be anonymous to the reviewer? It's science, the paper should speak for itself. You don't want a reviewer to be biased by the previous accomplishments of the author. An absolute nobody can make groundbreaking and unexpected discoveries, and a Nobel prize winner can make stupid mistakes. reply aj7 17 hours agorootparentIn subfields of physics, and I suspect math, the submitter is never anonymous. These people talk at conferences, have a list of previous works, etc., and fields are highly specialized. So the reviewer knows with 50-95% certainty who he is reviewing. reply gus_massa 16 hours agorootparentI agree, also many papers near the begining say > We are exending our previous work in [7] or cite a few relevant papers > This topic has been studied in [3-8] Where 3 was published by group X, 5 by group Y, 7 by group Z and 4, 6 and 8 by group W. Anyone can guess the author of the paper is in group W. Just looking at the citations, it's easy to guess the group of the author. reply hexane360 14 hours agorootparentprevIn many subfields, the submitter isn't even attempted to be hidden from the reviewers. Usually, even the reviewers can be guessed with high accuracy by the submitters reply hoten 19 hours agorootparentprevThe reviewer wouldn't need to know, just the one coordinating who should review what. reply sokoloff 19 hours agorootparentInherent in the editor trying to \"get the very best researchers to [review] the paper\" is likely to be a leak of signal. (My spouse was a scientific journal editor for years; reviewers decline to review for any number of reasons, often just being too busy and the same reviewer is often asked multiple times per year. Taking the extra effort to say \"but this specific paper is from a really respected author\" would be bad, but so would \"but please make time to review this specific paper for reasons that I can't tell you\".) reply bumby 18 hours agorootparentI didn’t read the comment to mean the editor would explicitly signal anything was noteworthy about the paper, but rather they would select referees from a specific pool of experts. From that standpoint, the referee would have no insight into whether it was anything special (and they couldn’t tell if the other referees were of distinction either). reply sokoloff 17 hours agorootparentThe editor is already selecting the best matched reviewers though, for any paper they send out for review. They have more flexibility on how hard they push the reviewer to accept doing the specific review, or for a specific timeline, but they still get declines from some reviewers on some papers. reply bumby 17 hours agorootparentI know that’s the ideal but my original post ends with some skepticism at this claim. I’ve had more than a few come across my desk that are a poor fit. I try to be honest with the editors about why I reject the chance to review them. If I witness it more than a few times, they obviously aren’t being as judicial at their assignments as the ideal assumes. reply taneq 18 hours agorootparentprevDoesn’t that just move the source of bias from the reviewer to the coordinator? Some ‘nobody’ submitting a paper would get a crapshoot reviewer while a recognisable ‘somebody’ gets a well regarded fair reviewer. reply wslh 18 hours agorootparentprevWhen submitting papers to high-profile journals, the expectations are very high for all authors. In most cases, the editorial team can determine from the abstract whether the paper is likely to meet their standards for acceptance. reply derefr 19 hours agorootparentprevFull anonymity may be valuable, if the set of a paper's reviewers has to stay fixed throughout the review process If peer review worked more like other publication workflows (where documents are handed across multiple teams that review them for different reasons), I think partial anonymity (e.g. rounding authors down to a citation-count number) might actually be useful. Basically: why can't we treat peer review like the customer service gauntlet? - Papers must pass all levels from the level they enter up to the final level, to be accepted for publication. - Papers get triaged to the inbox of a given level based on the citation numbers of the submitter. - Thus, papers from people with no known previous publications, go first to the level-1 reviewers, who exist purely to distinguish and filter off crankery/quackery. They're just there so that everyone else doesn't have to waste time on this. (This level is what non-academic publishing houses call the \"slush pile.\") However, they should be using criteria that give only false-positives [treating bad papers as good] but never false-negatives [treating good papers as bad.] The positives pass on to the level-2 (\"normal\") stream. - Likewise, papers from pre-eminent authors are assumed to not often contain stupid obvious mistakes, and therefore, to avoid wasting the submitter's time and the time of reviewers in levels 1 through N-1, these papers get routed straight to final level-N reviewers. This group is mostly made up of pre-eminent authors themselves, who have the highest likelihood of catching the smallest, most esoteric fatal flaws. (However, they're still also using criteria that requires them to be extremely critical of any obvious flaws as well. They just aren't supposed to bother looking for them first, since the assumption is that they won't be there.) - Papers from people with an average number of citations end up landing on some middle level, getting reviewed for middling-picky stuff by middling-experienced people, and then either getting bounced back for iteration at that point, or getting repeatedly handed up the chain with those editing marks pre-picked so that the reviewers on higher levels don't have to bother looking for those things and can focus on the more technically-difficult stuff. It's up to the people on the earlier levels to make the call of whether to bounce the paper back to the author for revision. (Note that, under this model, no paper is ever rejected for publication; papers just get trapped in an infinite revision loop, under the premise that in theory, even a paper fatally-flawed in its premise could be ship-of-Theseus-ed during revision into an entirely different, non-flawed paper.) You could compare this to a software toolchain — first your code is \"reviewed\" by the lexer; then by the parser; then by the macro expansion; then by any static analysis passes; then by any semantic-model transformers run by the optimizer. Your submission can fail out as invalid at any step. More advanced / low-level code (hand-written assembler) skips the earlier steps entirely, but that also means talking straight to something that expected pre-picked output and will give you very terse, annoyed-sounding, non-helpful errors if it does encounter a flaw that would have been caught earlier in the toolchain for HLL code. reply bumby 18 hours agorootparentI agree with a lot of this premise but this gave me pause: >under this model, no paper is ever rejected for publication; papers just get trapped in an infinite revision loop This could mean a viable paper never gets published. Most journals require that you only submit to one journal at a time. So if it didn’t meet criteria for whatever reason (even a bad scope fit) it would never get a chance at a better fit somewhere else). reply davrosthedalek 18 hours agorootparentprevTypically, papers are reviewed by 1 to 3 reviewers. I don't think you realistically can have more than two levels -- the editor as the first line, and then one layer of reviewers. You can't really blind the author names. First, the reviewers must be able to recognize if there is a conflict of interest, and second, especially for papers on experiments, you know from the experiment name who the authors would be. reply satellite2 18 hours agorootparentprevAssuming citations follow a zip distribution, almost all papers would have to go through all levels. reply melagonster 16 hours agorootparentprevUnfortunately, reviewers do not get salary from this... reply httpsterio 19 hours agorootparentprevdepending on the publication the reviewers might not even know who the authors are. reply sharth 19 hours agorootparentBut the journal editor should. reply nine_k 13 hours agorootparentprevIt's as if big journals are after some drama. Or excitement at least. Not just an important result, but a groundbreaking result in its own right. If it's a relatively small achievement that finishes a long chain of gradual progress, it better be some really famous problem, like Fermat's last theorem, Poinrcaré's conjecture, etc. I wonder if it's actually optimal from the journal's selfish POV. I would expect it to want to publish articles that would be cited most widely. These should be results that are important, that is, are hubs for more potential related work, rather that impressive but self-contained results. reply foxglacier 18 hours agorootparentprevOr maybe it doesn't matter. He got them published anyway and just lost some prestigious journal points on his career. Science/math was the winner on the day and that's the whole point of it. Maybe some of those lower ranked journals are run better and legitimately chipping away at the prestige of the top ones due to their carelessness. reply bumby 17 hours agorootparentResearch and publication incur opportunity costs. For every manuscript that has to be reworked and submitted elsewhere, you’re losing the ability to do new research. So a researcher is left trying to balance the cost/benefit of additional time investment. Sometimes that results in a higher quality publication, sometimes it results in abandoning good (or bad) work, and sometimes it just wastes time. reply melagonster 16 hours agorootparentfoxglacier offered a very good point! If some guy is so talented as Tao, perhaps this is the time to ameliorate journal by his power (like what he did here). reply Salgat 14 hours agorootparentprevThis is all due to the preverse incentives of modern academia prioritizing quantity over quantity, flooding journals with an unending churn of low effort garbage. reply bruce511 13 hours agorootparentThere are easily tens of thousands of researchers globally. If every one did a single paper per year, that would still be way more than journals could realistically publish. Since it is to some extent a numbers game, yes, academics (especially newer ones looking to build reputation) will submit quantity over quality. More tickets in the lottery means more chances to win. I'm not sure though how you change this. With so many voices shouting for attention it's hard to distinguish \"quality\" from the noise. And what does it even mean to prioritize \"quality\"? Is science limited to 10 advancements per year? 100? 1000? Should useful work in niche fields be ignored simply because the fields are niche? Is it helpful to have academics on staff for multiple years (decades?) before they reach the standard of publishing quality? I think perhaps the root of the problem you are describing is less one of \"quantity over quality\" and more one of an ever-growing \"industry\" where participants are competing against more and more people. reply Salgat 1 hour agorootparentPerhaps you have better insight into this, why do you think having the primary incentive for professors/researchers being quantity of papers published is appropriate? Or are you saying that it's simply unfixable and we must accept this? As far as I'm aware, quantity of papers published has no relevance to the value of the papers being published, with regard to contributing to the scientific record, and focusing on quantity is a very inappropriate and misleading metric to a researcher's actual contributions. And don't downplay that it isn't purely a numbers game for most people. Your average professor has their entire career tied to the quantity, from getting phd candidates through in a timely manner to acquiring grants. All of it hinging on quantity. reply eru 13 hours agorootparentprev> [...] way more than journals could realistically publish. In what sense? If you put it on a website, you can publish a lot more without breaking a sweat. People who want a dead tree version can print it out on demand. reply bruce511 11 hours agorootparentPublishing in the sense or reviewing, editing, etc. Distribution is the easy part. reply eru 6 hours agorootparentWell, but that scales with the number of people. The scientists themselves are working as reviewers. More scientists writing papers also means more scientists available for reviewing papers. And as you say, distribution is easy, so you can do reviewing after publishing instead of doing it before. reply bumby 5 hours agorootparentThe featured article demonstrates that good review may not be a function of the number of reviewers available. I personally think that with a glut of reviewers, there's a higher chance an editor will assign a referee who doesn't have the capability (or time!) to perform an adequate review and manuscripts will be rejected for poor reasoning. reply grepLeigh 20 hours agorootparentprevWhat's the compensation scheme for reviewers? Are there any mechanisms to balance out the \"race to the bottom\" observed in other types of academic compensation? e.g. increase of adjunct/gig work replacing full-time professorship. Do universities require staff to perform a certain number of reviews in academic journals? reply hanche 20 hours agorootparentNormally, referees are unpaid. You're just supposed to do your share of referee work. And then the publisher sells the fruits of all that work (research and refereeing) back to universities at a steep price. Academic publishing is one of the most profitable businesses on the planet! But univesities and academics are fighting back. Have been for a few years, but the fight is not yet over. reply throwaway2037 18 hours agorootparentIf unis \"win\", what is the likely outcome? reply bumby 17 hours agorootparentMore/easier/cheaper dissemination of research. reply SJC_Hacker 18 hours agorootparentprev> Do universities require staff to perform a certain number of reviews in academic journals? No. Reviewers mostly do it because its expected of them, and they want to publish their own papers so they can get grants In the end, the university only cares about the grant (money), because they get a cut - somewhere between 30-70% depending on the instituition/field - for \"overhead\" Its like the mafia - everyone has a boss they kick up to. My old boss (PI on an RO1) explained it like this Ideas -> Grant -> Money -> Equipment/Personnel -> Experiments -> Data -> Paper -> Submit/Review/Publish (hopefully) -> Ideas -> Grant If you don't review, go to conferences/etc. its much less likely your own papers will get published, and you won't get approved for grants. Sadly there is still a bit of \"junior high popularity contest\" , scratch my back I'll scratch yours that is still present in even \"highly respected\" science journals. I hear this from basically every scientist I've known. Even successful ones - not just the marginal ones. reply davrosthedalek 18 hours agorootparentWhile most of what you write is true to some extend, I do not see how reviewing will get your paper published, except maybe for the cases the authors can guess the reviewer. It's anonymous normally. reply SJC_Hacker 18 hours agorootparentThe editor does though, they all know each other. They would know who's not refereeing - and word gets around. reply tokinonagare 20 hours agorootparentprevI don't thing it's a money problem. It's more like a framing issue, with some reviewers being too narrow-minded, or lacking background knowledge on the topic of the paper. It's not uncommon to have a full lab with people focussing on very different things, when you look in the details, the exact researchers interests don't overlap too much. reply davrosthedalek 20 hours agorootparentprevTypically, at least in physics (but as far as I know in all sciences), it's not compensated, and the reviewers are anonymous. Some journals try to change this, with some \"reviewer coins\", or Nature, which now publishes reviewer names if a paper is accepted and if the reviewer agrees. I think these are bad ideas. Professors are expected to review by their employer, typically, and it's a (very small) part of the tenure process. reply jasonfarnon 18 hours agorootparentprevDo universities require staff to perform a certain number of reviews in academic journals? Depends on what you mean by \"require\". At most research universities it is a plus when reviewing tenureship files, bonuses, etc. It is a sign that someone cares about your work, and the quality of the journal seeking your review matters. If it were otherwise faculty wouldn't list the journals they have reviewed for on their CVs. If no one would ever find out about a reviewers' efforts e.g. the process were double blind to everyone involved, the setup wouldnt work. reply canjobear 18 hours agorootparentprevThere is no compensation for reviewers, and usually no compensation for editors. It’s effectively volunteer work. I agree to review a paper if it seems interesting to me and I want to effectively force myself to read it a lot more carefully than normal. It’s hard work, especially if there is a problem with the paper, because you have to dig out the problem and explain it clearly. An academic could refuse to do any reviews with essentially no formal consequences, although they’d get a reputation as a “bad citizen” of some kind. reply acomjean 20 hours agorootparentprevI know from some of my peers that reviewed biology (genetics) papers, they weren’t compensated. I was approached to review something for no compensation as well, but I was a bad fit. reply paulpauper 20 hours agorootparentprevIt's implicitly understood that volunteer work makes the publishing process 'work'. It's supposed to be a level playing field where money does not matter. reply wrsh07 16 hours agorootparentprevRight - it's somewhat similar to code review Sometimes one person is looking for an improvement in this area while someone else cares more about that other area This is totally reasonable! (Ideally if they're contradicting each other you can escalate to create a policy that prevents future contradictions of that sort) reply bradleyjg 22 hours agoparentprevThis seems reasonable? Suppose the full result is worth 7 impact points, which is broken up into 5 points for the partial result and 2 points for the fix. The journal has a threshold of 6 points for publication. Had the authors held the paper until they had the full result, the journal would have published it, but neither part was significant enough. Scholarship is better off for them not having done so, because someone else might have gotten the fix, but the journal seems to have acted reasonably. reply tux3 22 hours agorootparentIf people thought this way - internalizing this publishing point idea - it would incentivize sitting on your incremental results, fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take. If a series of incremental results were as prestigious as holding off to bundle them people would have reason to collaborate and complete each other's work more eagerly. Delaying an almost complete result for a year so that a journal will think it has enough impact point seems straightforwardly net bad, it slows down both progress & collaboration. reply gwerbret 22 hours agorootparent> If people thought this way - internalizing this publishing point idea - it would incentivize sitting on your incremental results, fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take. This is exactly what people think, and exactly what happens, especially in winner-takes-all situations. You end up with an interesting tension between how long you can wait to build your story, and how long until someone else publishes the same findings and takes all the credit. A classic example in physics involves the discovery of the J/ψ particle [0]. Samuel Ting's group at MIT discovered it first (chronologically) but Ting decided he needed time to flesh out the findings, and so sat on the discovery and kept it quiet. Meanwhile, Burton Richter's group at Stanford also happened upon the discovery, but they were less inclined to be quiet. Ting found out, and (in a spirit of collaboration) both groups submitted their papers for publication at the same time, and were published in the same issue of Physical Review Letters. They both won the Nobel 2 years later. 0: https://en.wikipedia.org/wiki/J/psi_meson reply jvanderbot 20 hours agorootparentWait, how did they both know that they both discovered it, but only after they had both discovered it? reply davrosthedalek 20 hours agorootparentPeople talk. The field isn't that big. reply ahartmetz 17 hours agorootparentprevThey got an optimal result in that case, isn't that nice. reply chongli 22 hours agorootparentprevThe reasonable thing to do here is to discourage all of your collaborators from ever submitting anything to that journal again. Work with your team, submit incremental results to journals who will accept them, and let the picky journal suffer a loss of reputation from not featuring some of the top researchers in the field. reply bennythomsson 21 hours agorootparentprevTo supply a counter viewpoint here... The opposite is the \"least publishable unit\" which leads to loads and loads of almost-nothing results flooding the journals and other publication outlets. It would be hard to keep up with all that if there wasn't a reasonable threshold. If anything then I find that threshold too low currently, rather than too high. The \"publish or perish\" principle also pushes people that way. reply lupire 18 hours agorootparentThat's much less of a problem than the fact that papers are such poor media for sharing knowledge. They are published too slowly to be immediately useful versus just a quick chat, and simultaneously written in too rushed a way to comprehensively educate people on progress in the field. reply bennythomsson 9 hours agorootparent> versus just a quick chat, Everybody is free to keep a blog for this kind of informal chat/brainstorming kind of communication. Paper publications should be well-written, structured, thought-through results that make it worthwhile for the reader to spend their time. Anything else belongs to a blog post. reply ahartmetz 17 hours agorootparentprevThe educational and editorial quality of papers from before 1980 or so beats just about anything published today. That is what publish or perish - impact factor - smallest publishable unit culture did. reply slow_typist 21 hours agorootparentprevDon‘t know much about publishing in maths but in some disciplines it is clearly incentivised to create the biggest possible number of papers out of a single research project, leading automatically to incremental publishing of results. I call it atomic publishing (from Greek atomos - indivisible) since such a paper contains only one result that cannot be split up anymore. reply hanche 20 hours agorootparentOr cheese slicer publishing, as you are selling your cheese one slice at a time. The practice is usually frowned upon. reply dataflow 12 hours agorootparentprevI thought this was called salami slicing in publication. reply lupire 18 hours agorootparentprevAndrew Wiles spent 6 years working on 1 paper, and then another year working on a minor follow-up. https://en.m.wikipedia.org/wiki/Wiles%27s_proof_of_Fermat%27... reply Too 10 hours agorootparentprevAcademic science discovers continuous integration. In the software world, it's often desired to have a steady stream of small, individually reviewable commits, that each deliver a incremental set of value. Dropping a 20000 files changed bomb \"Complete rewrite of linux kernel audio subsystem\" is not seen as prestigious. Repeated, gradual contributions and involvement in the community is. reply SoftTalker 21 hours agorootparentprevScience is almost all incremental results. There's far more incentive to get published now than there is to \"sit on\" an incremental result hoping to add to it to make a bigger splash. reply bradleyjg 22 hours agorootparentprevThe big question here is if journal space is a limited resource. Obviously it was at one point. Supposing it is, you have to trade off publishing these incremental results against publishing someone else’s complete result. What if it had taken ten papers to get there instead of two? For a sufficiently important problem, sure, but the interesting question is at a problem that’s interesting enough to publish complete but barely. reply parpfish 22 hours agorootparentThe limiting factor isn’t journal space, but attention among the audience. (In theory) the journals publishing restrictions help to filter and condense information so the audience is maximally informed given that they will only read a fixed amount reply btilly 21 hours agorootparentprevJournal space is not a limited resource. Premium journal space is. That's because every researcher has a hierarchy of journals that they monitor. Prestigious journals are read by many researchers. So you're essentially competing for access to the limited attention of many researchers. Conversely, publishing in a premium journal has more value than a regular journal. And the big scientific publishers are therefore in competition to make sure that they own the premium journals. Which they have multiple tricks to ensure. Interestingly, their tricks only really work in science. That's because in the humanities, it is harder to establish objective opinions about quality. By contrast everyone can agree in science that Nature generally has the best papers. So attempting to raise the price on a prestigious science journal, works. Attempting to raise the price on a prestigious humanities journal, results in its circulation going down. Which makes it less prestigious. reply waldrews 17 hours agorootparentprevSpace isn't a limited resource, but prestige points are deliberatly limited, as a proxy for the publications' competition for attention. We can appreciate the irony, while considering the outcome reasonable - after all, the results weren't kept out of the literature. They just got published with a label that more or less puts them lower in the search ranking for the next mathematician who looks up the topic. reply jvanderbot 21 hours agorootparentprevHyper focusing on a single journal publication is going to lead to absurdities like this. A researcher is judged by the total delta of his improvements, at least by his peers and future humanity. (the sum of all points, not the max). reply krick 19 hours agorootparentprevIt is easy to defend any side of the argument by inflating the \"pitfalls of other approach\" ad absurdum. This is silly. Obviously, balance is the key, as always. Instead, we should look at which side the, uh, industry currently tends to err. And this is definitely not the \"sitting on your incremental results\" side. The current motto of academia is to publish more. It doesn't matter if your papers are crap, it doesn't matter if you already have significant results and are working on something big, you have to publish to keep your position. How many crappy papers you release is a KPI of academia. I mean, I can imagine a world were it would have been a good idea. I think it's a better world, where science journals don't exist. Instead, anybody can put any crap on ~arxiv.org~ Sci-Hub and anybody can leave comments, upvote/downvote stuff, papers have actual links and all other modern social network mechanics up to the point you can have a feed of most interesting new papers tailored specially for you. This is open-source, non-profit, 1/1000 of what universities used to pay for journal subscriptions is used to maintain the servers. Most importantly, because of some nice search screens or whatever the paper's metadata becomes more important than the paper itself, and in the end we are able to assign 10-word simple summary on what the current community consensus on the paper is: if it proves anything, \"almost proves\" anything, has been 10 times disproved, 20 research teams failed to reproduce to results or 100 people (see names in the popup) tried to read and failed to understand this gibberish. Nothing gets retracted, ever. Then it would be great. But as things are and all these \"highly reputable journals\" keep being a plague of society, it is actually kinda nice that somebody encourages you to finish your stuff before publishing. Now, should have been this paper of Tao been rejected? I don't know, I think not. Especially the second one. But it's somewhat refreshing. reply JJMcJ 21 hours agorootparentprevGauss did something along these lines and held back mathematical progress by decades. reply lupire 18 hours agorootparentGauss had plenty of room for slack, giving people time to catch up on his work.. Every night Gauss went to sleep, mathematics was held back a week. reply YetAnotherNick 22 hours agorootparentprevTwo submission in medium reputation journal does not have significantly lower prestige than one in high reputation journal. reply Arainach 22 hours agorootparentprevThese patterns are ultimately detrimental to team/community building, however. You see it in software as well: As a manager in calibration meetings, I have repeatedly seen how it is harder to convince a committee to promote/give a high rating to someone with a large pile of crucial but individually small projects delivered than someone with a single large project. This is discouraging to people whose efforts seem to be unrewarded and creates bad incentives for people to hoard work and avoid sharing until one large impact, and it's disastrous when (as in most software teams) those people don't have significant autonomy over which projects they're assigned. reply mlepath 19 hours agorootparentHello, fellow Metamate ;) reply cvoss 22 hours agorootparentprevThe idea that a small number of reviewers can accurately quantify the importance of a paper as some number of \"impact points,\" and the idea that a journal should rely on this number and an arbitrary cut off point to decide publication, are both unreasonable ideas. The journal may have acted systematically, but the system is arbitrary and capricious. Thus, the journal did not act reasonably. reply remus 22 hours agorootparentprev> This seems reasonable? In some sense, but it does feel like the journal is missing the bigger picture somewhat. Say the two papers are A and B, and we have A + B = C. The journal is saying they'll publish C, but not A and B! reply Nevermark 22 hours agorootparentHow many step papers before a keystone paper seems reasonable to you? I suspect readers don’t find it as exciting to read partial result papers. Unless there is an open invitation to compete on its completion, which would have a purpose and be fun. If papers are not page turners, then the journal is going to have a hard time keeping subscribers. On the other hand, publishing a proof of a Millennium Problem as several installments, is probably a fantastic idea. Time to absorb each contributing result. And the suspense! Then republish the collected papers as a signed special leather limited series edition. Easton, get on this! reply slow_typist 21 hours agorootparentPublishing partial results is always an invitation to compete in the completion, unless the completion is dependent on special lab capabilities which need time and money to acquire. There is no need to literally invite anyone. reply Nevermark 19 hours agorootparentI meant if the editors found the paper’s problem and progress especially worthy of a competition. reply remus 5 hours agorootparentprev> I suspect readers don’t find it as exciting to read partial result papers. Unless there is an open invitation to compete on its completion, which would have a purpose and be fun. If papers are not page turners, then the journal is going to have a hard time keeping subscribers. Yeah I agree, a partial result is never going to be as exciting as a full solution to a major problem. Thinking on it a little more, it seems more of a shame the journal wasn't willing to publish the first part as that sounds like it was the bulk of the work towards the end result. I quite like that he went to publish a less-than-perfect result, rather than sitting on it in the hopes of making the final improvement. That seems in the spirit of collaboration and advancing science, whereas the journal rejecting the paper because it's 98% of the problem rather than the full thing seems a shame. Having said that I guess as a journal editor you have to make these calls all the time, and Im sure every author pitches their work in the best light (\"There's a breakthrough just around the corner...\") and Im sure there are plenty of ideas that turn out to be dead ends. reply cubefox 22 hours agorootparentprev... A and B separately. reply pinkmuffinere 22 hours agorootparentprevI agree this is reasonable from the individual publisher standpoint. I once received feedback from a reviewer that I was \"searching for the minimum publishable unit\", and in some sense the reviewer was right -- as soon as I thought the result could be published I started working towards the publication. A publisher can reasonably resist these kinds of papers, as you're pointing out. I think the impact to scholarship in general is less clear. Do you immediately publish once you get a \"big enough\" result, so that others can build off of it? Or does this needlessly clutter the field with publications? There's probably some optimal balance, but I don't think the right balance is immediately clear. reply nextn 22 hours agorootparentWhy would publishing anything new needlessly clutter the field? Discovering something is hard, proving it correct is hard, and writing a paper about is hard. Why delay all this? reply bumby 20 hours agorootparentPlaying devils advocate, there isn’t a consensus on what is incremental vs what is derivative. In theory, the latter may not warrant publication because anyone familiar with the state-of-the-art could connect the dots without reading about it in a publication. reply SilasX 21 hours agorootparentprevOuch. That would hurt to hear. It's like they're effectively saying, \"yeah, obviously you came up with something more significant than this, which you're holding back. No one would be so incapable that this was as far as they could take the result!\" reply pinkmuffinere 14 hours agorootparentThankfully the reviewer feedback was of such low quality in general that it had little impact on my feelings, haha. I think that’s unfortunately common. My advisor told me “leave some obvious but unimportant mistakes, so they have something to criticize, they can feel good, and move on”. I honestly think that was good advice. reply omoikane 21 hours agorootparentprevBut proportionally, wouldn't a solution without an epsilon loss be much better than a solution with epsilon? I am not sure what's the exact conjecture that the author solved, but if the epsilon difference is between an approximate solution versus an exact solution, and the journal rejected the exact solution because it was \"only an epsilon improvement\", I might question how reputable that journal really was. reply saghm 22 hours agorootparentprevIf this was actually how stuff was measured, it might be defensible. I'm having trouble believing that things are actually done this objectively rather than the rejections being somewhat arbitrary. Do you think that results can really be analyzed and compared in this way? How do you know that it's 5 and 2 and not 6 and 1 or 4 and 3, and how do you determine how many points a full result is worth in total? reply Brian_K_White 21 hours agorootparentprevIt's demonstrably (there is one demonstration right there) self-defeating and counter-productive, and so by definition not reasonable. Each individual step along the way merely has some rationale, but rationales come in the full spectrum of quality. reply sunshowers 20 hours agorootparentprevGiven the current incentive scheme in place it's locally reasonable, but the current incentives suck. Is the goal to score the most impact points or to advance our understanding of the field? reply mnky9800n 19 hours agorootparentIn my experience, it depends on the scientist. But it’s hard to know what an advance is. Like, people long searched for evidence of æther before giving up and accepting that light doesn’t need a medium to travel in. Perhaps 100 years from now people will laugh at the attention is all you need paper that led to the llm craze. Who knows. That’s why it’s important to give space to science. From my understanding Lorenz worked for 5 years without publishing as a research scientist before writing his atmospheric circulation paper. That paper essentially created the field of chaos. Would he be able to do the same today? Maybe? Or maybe counting papers or impact factors or all these other metrics turned science into a game instead of an intellectual pursuit. Shame we cannot ask Lorenz or Maxwell about their times as a scientist. They are dead. reply Ar-Curunir 22 hours agorootparentprevI don’t think that’s a useful way to think about this, especially when theres so little information provided about this. Reviewing is a capricious process. reply generationP 6 hours agoparentprevTo be the devil's advocate: Breaking a result up into little pieces to increase your paper count (\"salami-slicing\") is frowned upon. Of course this is not what Terry Tao tried to do, but it was functionally indistinguishable from it to the reviewers/editors. reply stevage 22 hours agoparentprevIt actually seems reasonable for a journal that has limited space and too many submissions. What's the alternative, to accept on or two of the half proofs, and bump one or two other papers in the process? reply jiggawatts 22 hours agorootparentWow, it’s so sad that their budget doesn’t stretch to purchasing hard drives with capacities measured in gigabytes. It must be rough having to delete old files from the floppies they’re still forced to use in this day and age. reply y1n0 21 hours agorootparentThat logic is absurd. You",
    "originSummary": [],
    "commentSummary": [
      "A paper by renowned mathematician Terence Tao was rejected, illustrating that even top academics encounter rejection, sparking a broader discussion on the prevalence of paper rejections in academia. - The discourse highlighted issues within the peer review process, including biases and the pressure to publish frequently, with many sharing personal experiences of rejection. - Suggestions for improvement included exploring alternative evaluation and publication systems, such as open internet-centric reviews, while acknowledging that rejection is a standard aspect of the academic journey."
    ],
    "points": 779,
    "commentCount": 254,
    "retryCount": 0,
    "time": 1735758777
  },
  {
    "id": 42572662,
    "title": "MitmProxy2Swagger: Automagically reverse-engineer REST APIs",
    "originLink": "https://github.com/alufers/mitmproxy2swagger",
    "originBody": "mitmproxy2swagger video.mp4 A tool for automatically converting mitmproxy captures to OpenAPI 3.0 specifications. This means that you can automatically reverse-engineer REST APIs by just running the apps and capturing the traffic. 🆕 NEW! Added support for processing HAR exported from the browser DevTools. See Usage - HAR for more details. Installation First you will need python3 and pip3. $ pip install mitmproxy2swagger # ... or ... $ pip3 install mitmproxy2swagger # ... or ... $ git clone git@github.com:alufers/mitmproxy2swagger.git $ cd mitmproxy2swagger $ docker build -t mitmproxy2swagger . Then clone the repo and run mitmproxy2swagger as per examples below. Usage Mitmproxy To create a specification by inspecting HTTP traffic you will need to: Capture the traffic by using the mitmproxy tool. I personally recommend using mitmweb, which is a web interface built-in to mitmproxy. $ mitmweb Web server listening at http://127.0.0.1:8081/ Proxy server listening at http://*:9999 ... IMPORTANT To configure your client to use the proxy exposed by mitm proxy, please consult the mitmproxy documentation for more information. Save the traffic to a flow file. In mitmweb you can do this by using the \"File\" menu and selecting \"Save\": Run the first pass of mitmproxy2swagger: $ mitmproxy2swagger -i-o-p# ... or ... $ docker run -it -v $PWD:/app mitmproxy2swagger mitmproxy2swagger -i-o-pPlease note that you can use an existing schema, in which case the existing schema will be extended with the new data. You can also run it a few times with different flow captures, the captured data will be safely merged.is the base url of the API you wish to reverse-engineer. You will need to obtain it by observing the requests being made in mitmproxy. For example if an app has made requests like these: https://api.example.com/v1/login https://api.example.com/v1/users/2 https://api.example.com/v1/users/2/profile The likely prefix is https://api.example.com/v1. Running the first pass should have created a section in the schema file like this: x-path-templates: # Remove the ignore: prefix to generate an endpoint with its URL # Lines that are closer to the top take precedence, the matching is greedy - ignore:/addresses - ignore:/basket - ignore:/basket/add - ignore:/basket/checkouts - ignore:/basket/coupons/attach/{id} - ignore:/basket/coupons/attach/104754 You should edit the schema file with a text editor and remove the ignore: prefix from the paths you wish to be generated. You can also adjust the parameters appearing in the paths. Run the second pass of mitmproxy2swagger: $ mitmproxy2swagger -i-o-p[--examples] # ... or ... $ docker run -it -v $PWD:/app mitmproxy2swagger mitmproxy2swagger -i-o-p[--examples] Run the command a second time (with the same schema file). It will pick up the edited lines and generate endpoint descriptions. Please note that mitmproxy2swagger will not overwrite existing endpoint descriptions, if you want to overwrite them, you can delete them before running the second pass. Passing --examples will add example data to requests and responses. Take caution when using this option, as it may add sensitive data (tokens, passwords, personal information etc.) to the schema. Passing --headers will add headers data to requests and responses. Take caution when using this option, as it may add sensitive data (tokens, passwords, personal information etc.) to the schema. HAR Capture and export the traffic from the browser DevTools. In the browser DevTools, go to the Network tab and click the \"Export HAR\" button. Continue the same way you would do with the mitmproxy dump. mitmproxy2swagger will automatically detect the HAR file and process it. Example output See the examples. You will find a generated schema there and an html file with the generated documentation (via redoc-cli). See the generated html file here. Development and contributing This project uses: poetry for dependency management pre-commit for code formatting and linting pytest for unit testing To install the dependencies: poetry install Run linters: pre-commit run --all-files Install pre-commit hooks: pre-commit install Run tests: poetry run pytest Run tests with coverage: poetry run pytest --cov=mitmproxy2swagger License MIT",
    "commentLink": "https://news.ycombinator.com/item?id=42572662",
    "commentBody": "MitmProxy2Swagger: Automagically reverse-engineer REST APIs (github.com/alufers)459 points by AbuAssar 10 hours agohidepastfavorite55 comments Gamemaster1379 10 hours agoThis is a nice tool. A game I liked to play announced end of service back in 2023. They gave enough notice to let me capture some logs from their cooridinator service. I captured them in mitmproxy and ran those through this to help me identify all the endpoints and their general structure. (A few things were a misnomer, like the examples suggesting certain values were able to be floats when they could only be integers) I was able to get a team together and we were able to stand up private servers as a result. reply simonjgreen 9 hours agoparentAmazing! What game was this for? I was involved in the RE efforts around UO way back in the day. reply kirici 5 hours agorootparentGundam Evolution, going by comment history. reply ge96 4 hours agorootparentDifferent plot/game mechanics but armored core 6 is great if you like mecha reply swyx 8 hours agoprevdid i miss something or why are there TWO (2) \"magically reverse engineer REST APIs\" projects on the HN front page right now? is there some offline beef going on? (screenshot in case this goes away https://x.com/swyx/status/1874762725383188502) reply Quarrel 8 hours agoparentPresumably, because the closed source one got some traction, so people are pointing out the open source alternative. reply littlestymaar 6 hours agoparentprevLikely because of this comment[1] in the other thread which made people submit this link, and when multiple independent people submit the same link in a short period of time you're very likely to end up on the front page (this exact situation happened to me once) [1] https://news.ycombinator.com/item?id=42568121 reply AbuAssar 1 hour agorootparentYeah, that's where I got the link from. reply TechDebtDevin 2 hours agoparentprevNoone asked for your twitter. reply zebomon 9 hours agoprevI looked through this earlier today when I saw it mentioned in that thread about the closed source tool for the same purpose. Having done a good bit of this type of reverse engineering the hard way over the years, it's a very exciting find. I had been talking with my partner about building something similar for the past six months. How exciting to learn that it's already out there and open source too! reply tecleandor 6 hours agoprevI've used this tool in the past with success. Not perfect but it accelerates the work greatly if you can launch a mitm proxy quickly and are familiar with the tool. I've been fighting lately with an API, though. It's not very, let's say, RESTy. It has only one endpoint, and the different \"sections\" of the API are defined in parameters, so MitmProxy2Swagger doesn't detect them properly :( reply quectophoton 5 hours agoparent> It's not very, let's say, RESTy. It has only one endpoint, To be fair, from what I understand an actual(tm) REST API would only have a single defined endpoint[1]: the entry point. With every other endpoint being discovered from the responses. And also from your message I'm guessing a URI still uniquely identifies a resource (specifically through the \"query\" part of the URI, instead of the more common \"path\"). So, technically, assuming there's nothing too weird with that API, it seems like MitmProxy2Swagger is failing to detect a REST API. [1]: Corollary: If an API is RESTful, it should be possible to rename any endpoint (except the entry point) at any moment in time without prior notice, and clients would not break as long as the response types/schemas are still supported by the clients. In-flight requests might fail with a 4xx, but after a retry they should go to the correct endpoint without any code change required. reply zdragnar 5 hours agorootparentThis is HATEOAS, basically the core feature of REST that very few people actually use. Most of what the industry calls REST or RESTful is just structured and inefficient RPC. reply nejsjsjsbsb 6 hours agoparentprevNothing is RESTy reply notcrazylol 8 hours agoprevI was wondering how it would take in graphql endpoints and convert it to swagger, since its just a single POST API with change in params. But thats more of a swagger issue than the tools. Has anyone dealt with this? Would be really helpful if you could share your ideas too :) reply asabla 8 hours agoparentWhy would you tho? If you're working against an GraphQL based API, you should be able to pull a schema file. And use that to implement your own API. All you would get from an Mitmproxy is example queries and mutations. With the additional complexity of extra tooling to stich together the schema file reply jampekka 8 hours agorootparentPulling the schema file can, and often is, disabled server side. And GraphQL APIs can, and often do, decline to serve other than persisted queries, and those can't be really inferred even with known schema. reply youngNed 8 hours agoprevperhaps a n00b question, but would this work, or is there something similar for apps, specifically android apps? reply tecleandor 6 hours agoparentI've used this specific tool to help me reverse engineer the private API of an Android App. The thing is, depending on how hardened the app is, you'll have to play with Android to allow this interception, mostly because of certificate pinning. Also I remember something about apps not using the system wide trusted certificates you install (IIRC). I remember using a rooted device with LineageOS, and downloading the APK and modifying it with a tool so the self signed certificate for the mitm proxy works with it. The mitm proxy docs have some links to tools that can do that [0] and you could also use an Android emulator if you don't have an extra phone to mess with it [1] 0: https://docs.mitmproxy.org/stable/concepts-certificates/ 1: https://docs.mitmproxy.org/stable/howto-install-system-trusted-ca-android/ reply whilenot-dev 7 hours agoparentprevA MITM proxy isn't specific to any app, it's a forward proxy for your outgoing network connection. In case of an Android app you'd need to run mitmproxy on a machine in your network and setup the connection as proxy in your Android's network settings. Then you'd need follow http://mitm.it to install mitmproxys root certificate on the Android device (to trust the connection with TLS) and off you go. EDIT: or rather follow the docs[0] [0]: https://docs.mitmproxy.org/stable/howto-install-system-trust... reply jazz9k 3 hours agoparentprevI use burp suite combined with Frida (which can remove root check and override ssl pinning). reply rhaps0dy 7 hours agoparentprevDepends on the app. If it uses some online functionality probably yes. You could also try decompilation, it’s decent on java apps like android’s. reply colesantiago 9 hours agoprevAgain, this is the very easy part of the reverse engineering API process that most tools can do, similar to API Parrot and the rest of them. This is not hard to do. The hard part is that inevitably, all these internal APIs will just add aggressive CAPTCHAs, Device Check, fingerprinting, etc to prevent common drive by re'ing. Easy to add these on the defence side, and extremely difficult to bypass on the other side. I can imagine all developer teams now upping their security with the combination of the above mentioned to prevent this. reply sebmellen 8 hours agoparentDepends on the age of the tool. We work with a lot of legacy systems that actually want us to integrate with them but don’t have the dev resources to build a proper API surface. As a result, we end up doing a lot of painful reverse engineering. These tools look promising for purposes like this. reply devjab 7 hours agoparentprevI curious as to why people would have a public API to begin with if they wanted to protect it from people using it. Then again, why would anyone have a public undocumented API in 2024 when a LLM can give you a cli tool to auto-generate 90% of the OpenAPI spec in a couple of hours? The last question isn't serious, I've worked in enterprise for decades and almost none of the tools organisations end up buying have good documentation for their API's. Not that those are publicly available, but still. reply lesuorac 2 hours agorootparentI think you have a misunderstanding here. The API needs to be \"public\" because the app uses the internet to communicate back to the home server. The API is not \"public\" in the sense that the app developers want anybody to use it; they just want their app to use this API. So they don't write publicly accessible documentation about it because they don't want to encourage its use. A tool like MitmProxy2Swagger lets you run the app and record all of its API calls so that you can use this unadvertised API. reply jampekka 3 hours agoparentprevMaking a mitmproxy dump from a manual browsing session is more or less unblockable, barring some TPM or similar fuckery. Usage of the API even with the protocol known OTOH can be quite easily made really hard. reply mad_vill 5 hours agoparentprevThere are many cases where users are behind a forward proxy for security/compliance reasons. Most applications need to support these types of users. reply srameshc 6 hours agoprevObvious question: How to protect against this ? reply mathgeek 6 hours agoparentBuild your API assuming anything public facing will be known. This includes anything downloaded to a device. reply K0nserv 6 hours agoparentprevYour first line of defence should be a secure API where an attacker doesn't gain anything by knowing it. You can add obfuscation, but ultimately if the client is shipped to the user you must assume an attacker can reverse engineer it. reply smallnix 6 hours agoparentprevWhat specifically do you want to protect? reply bandrami 6 hours agoparentprevI find this confusing because the point of an API is to be known, yes? Otherwise who's accessing it? reply quesera 4 hours agorootparentIt's a valid desire, but you have to be really dedicated to the effort to block it, in practice. You might intend your API to be consumed only by your own clients. E.g. your published mobile apps. A well-designed API won't allow a third-party client to do anything that your own client wouldn't allow of course. Permissions are always enforced on the back end. But there are many cases where a user might want a custom/different client: If your mobile apps are not awesome, or if they deprioritize a specific use case, or if they serve ads ... or even if your users want to automate some action in your service... If your service is popular enough (or you attract a certain kind of user), you will have some people building their own clients. reply bandrami 23 minutes agorootparentThose sound like bad use cases for a client-server model with public endpoints, then? I mean, you could cert-pin yourself in the client app, I guess. reply kube-system 3 hours agorootparentprevNot necessarily. A common pattern is to build a 'private API' intended to be used by one's own front-end applications. For example: most client-rendered applications, like the Airbnb example on this page. reply soheil 6 hours agoparentprevnext [6 more] [flagged] RandomRandy 6 hours agorootparentYou can read SSL traffic if you're able to install a root certificate on your device and the website/app doesn't use certificate pinning. I recently used HttpToolkit to reverse engineer a REST endpoint that used SSL encryption reply pimterry 6 hours agorootparentEven if it does use certificate pinning, you can generally disable that using tools like Frida (https://frida.re) with scripts like https://github.com/httptoolkit/frida-interception-and-unpinn... reply batch12 6 hours agorootparentprevThis isn't true. Mitmproxy and burp can both proxy TLS. Maybe you're misunderstanding the use case. reply iBotPeaches 6 hours agorootparentprevA good deal of APIs don't pin SSL certs so MITM works for a solid amount of them. reply erk__ 6 hours agorootparentprevOnly as long as you cannot load your own certificates, which you are able to in a lot of cases. Though on Android you can lock certificates allowed in a app, this can be circumvented though it adds another step. I am unsure if the same is a case for Apples devices, at least you might need jailbreak there. reply zython 9 hours agoprevThis is so cool. Thanks for sharing ! reply construct0 7 hours agoprevYeah - does this get nullabilities right? reply waseemmalik 9 hours agoprevnext [2 more] [flagged] efilife 9 hours agoparentWhy are all the spammers always from india/pakistan? reply soheil 6 hours agoprevnext [9 more] [flagged] CubsFan1060 5 hours agoparenthttps://docs.mitmproxy.org/stable/overview-getting-started/#... Seems like the proxy handles all the SSL, and likely strips any SSL Specific headers, etc.. But also, many, many, many companies do this exact thing. Just one example: https://knowledgebase.paloaltonetworks.com/KCSArticleDetail?... reply daemonhorn 5 hours agoparentprev1) Having the TLS stack trust a \"custom CA\" provided by any number of debug tools (like mitmproxy or OWASP Zap) is relatively simple operation and can be done by anyone on any OS as long as you have admin/root. 2) There are a number of additional debug ways to decode the encryption from an application endpoint (e.g. https://wiki.wireshark.org/TLS and look at SSLKEYLOGFILE environment variable supported by most major TLS stacks and all major browser). Since MitmProxy2Swagger also supports HAR format ingest (e.g. https://github.com/alufers/mitmproxy2swagger#HAR ), this can easily be exported from any browser built-in debug tools (which also removes the encryption). Modern TLS is great, but there are limitations on what it actually provides especially around the CA trust model. These mitm tools are not designed to take random traffic from the internet you intercepted, they require privileged endpoint access to enable specific debug features or configurations. reply at0mic22 4 hours agoparentprevI think HAR export consumption lets you avoid the whole MITM part if we are talking about website API detection reply eightnoneone 5 hours agoparentprevThis is only a problem if a client application has a server certificate pinned in source code. Otherwise, you can create a cert with a privacy CA and add it to a desktop OS trusted cert store. reply K0nserv 5 hours agorootparentAdding a CA cert to the OS trust store only works if the application uses it. I've encountered apps that don't use the OS trust store or networking stack; even then it's possible to reverse engineer the traffic though[0]. 0: https://hugotunius.se/2020/08/07/stealing-tls-sessions-keys-... reply dtn 6 hours agoparentprevIsn't that the point of mitmproxy? https://github.com/mitmproxy/mitmproxy reply cenamus 6 hours agoparentprevOption b could be more about breaking into some office that happens to contain those keys ;) reply bandrami 6 hours agoparentprevWait, it works fine on production APIs, what it doesn't work on is \"production clients\". You're deliberately man-in-the-middling yourself. reply tinchox5 9 hours agoprevCoool! reply andrewstuart 10 hours agoprev [–] This is something that would be easy to do an ordinary job of, missing lots of edge cases and not making something thorough and complete. A really professional and thorough job would be extremely time consuming and hard. reply matthewolfe 8 hours agoparent [–] I do this a lot for my work. A tool like this that can help get me to a nice starting point is huge. Instead of developing a mental model of the API in my head by manually looking through API requests/responses in ProxyMan, this can start me off much more quickly. From there, the edge cases can be worked out. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "mitmproxy2swagger is a tool that converts mitmproxy captures into OpenAPI 3.0 specifications, facilitating the reverse-engineering of REST APIs by capturing application traffic. - The tool now supports HTTP Archive (HAR) files from browser Developer Tools, expanding its usability for developers. - Installation can be done using Python3 and pip or Docker, and the project employs tools like poetry, pre-commit, and pytest for development, with an MIT license."
    ],
    "commentSummary": [
      "MitmProxy2Swagger is a tool designed to reverse-engineer REST APIs by analyzing traffic captured with mitmproxy, a popular tool for intercepting HTTP/HTTPS traffic.",
      "Users have successfully utilized it to recreate private servers for games and reverse-engineer APIs for Android applications, highlighting its effectiveness in identifying API endpoints.",
      "The tool is particularly beneficial for working with legacy systems or undocumented APIs, though it may face challenges with non-standard APIs and discussions include methods to protect APIs from reverse engineering, such as CAPTCHAs and certificate pinning."
    ],
    "points": 459,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1735805295
  },
  {
    "id": 42570988,
    "title": "The GPU, not the TPM, is the root of hardware DRM",
    "originLink": "https://mjg59.dreamwidth.org/70954.html",
    "originBody": "Skip to Main Content Captcha Check Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button! Log in Account name: Password: Remember me Other options: Forget your password? Log in with OpenID? Close menu Log in Create Create Account Display Preferences Explore Interests Directory Search Site and Journal Search Latest Things Random Journal Random Community FAQ Shop Buy Dreamwidth Services Gift a Random User DW Merchandise Interest Region Site and Account FAQ Email Privacy Policy • Terms of Service • Diversity Statement • Guiding Principles • Site Map • Make a Suggestion • Open Source • Help/Support Copyright © 2009-2024 Dreamwidth Studios, LLC. Some rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=42570988",
    "commentBody": "The GPU, not the TPM, is the root of hardware DRM (mjg59.dreamwidth.org)346 points by DvdGiessen 16 hours agohidepastfavorite325 comments no_time 11 hours agoThe author is correct in that media DRM is tied to GPU vendors on the field right now. But hardware backed DRM can be so much more invasive beyond that. I have no doubts the long term goal of MS is to have a Windows version of Play Integrity.[0] So total control over everything that happens on your device. Just to give an example of what could happen if this becomes reality: https://en.m.wikipedia.org/wiki/Web_Environment_Integrity This tech extended to browsers could easily mean that sites could refuse to serve you if your machine is running any bigcorp unapproved software. An easy example of that would be adblockers. Unless we get lucky with secure world compromises like the Tegra X1 bootrom exploit[1] or get real good at passing legistlation that forces companies to give you all the private keys to your own machine, the future for personal computing is looking grim. [0]: https://developer.android.com/google/play/integrity [1]: https://github.com/fail0verflow/shofel2 reply rustcleaner 1 hour agoparentI always said a hefty sales tax (50%? 100%? 200%?) on final sale of any product containing just a single Universal Machine which has artificial designs/locks that prevent the owner from replacing any and all firmware/software with versions he has authored, and/or which lacks complete enough documentation of design and interfaces that would enable a knowledgable and capable owner to author his own software/firmware. This should apply to PCs, phones, watches, microwaves, televisions, CPAP machines, automobiles, toasters... everything which contains a Universal Machine. Uncontrolled [by owner] Universal Machines are a national security concern which has the potential to turn grave at any moment. reply braiamp 49 minutes agorootparentWhy not just prohibiting the practice? This isn't weed or alcohol. reply ignoramous 9 hours agoparentprev> The author is correct in that media DRM is tied to GPU vendors on the field right now ... hardware backed DRM can be so much more invasive I expect mjg59 to know what they're talking about but like you say, I wonder the same thing about the strength of (what you call) Media DRM v Hardware-backed DRM. GPU vendors have quietly deployed [hardware-based DRM] ... [which] works just fine on [boards] that [don't] have a TPM and will continue to do so. Work fine? Even if a section of GPU's vRAM is out of the reach of the OS (here, to implement DRM), wouldn't TPM / DICE be needed to establish trust / measure GPU's firmware? reply mike_hearn 9 hours agorootparentNo, the GPUs have their own hardware RoT that measures the firmware. Modern GPUs are basically parallel computers with their own RAM, bootup sequence, BIOS, operating systems (drivers and firmware together are basically an OS), compiler toolchains, debuggers, sub-drivers and so on. reply rustcleaner 56 minutes agorootparentOne which needs to be opened to users/owners instead of locked away. A price-doubling 100% sales tax on Universal Machines which lock owners out like with video cards (and their firmware), should make products which are not fundamentally significantly GNU-ideals friendy unaffordable to the average consumer (and therefore not economically viable anymore). Siemens can still sell their $5MM machine for $10MM to BASF or whatever, because BASF can afford to borrow double to pay the tax, but Cletus and Dorothy will not be buying sony playstations and apple iphones because $2,000+ isn't worth it. reply urronglol 2 hours agoparentprevIf that ever happened I would nerd up on low level architectures. Get a job in a trusted company. Leak the keys. The only worthy cause to apply my patience to. reply aleph_minus_one 2 hours agorootparent> If that ever happened I would nerd up on low level architectures. Get a job in a trusted company. Leak the keys. > The only worthy cause to apply my patience to. This already happened for smartphones. Concerning your first claim: Did you attempt to get a job at such a company to leak the keys? Concerning your second claim: Did you already invest lots of personal ressources for this cause? reply badsectoracula 1 hour agorootparent> This already happened for smartphones. Sadly even in tech many people do not seem to see smartphones as real computers. reply Semaphor 1 hour agorootparentNot GP, and don’t have their patience anyway. But while I see them as real computers, they aren’t any that I enjoy using, so I care relatively little for them. reply aleph_minus_one 1 hour agorootparent> But while I see them as real computers, they aren’t any that I enjoy using, so I care relatively little for them. If you/people were brutally willing to crack them open, the \"enjoyability\" of using them for \"hacker-minded people\" could be improved insanely. reply kccqzy 3 hours agoparentprevI have trouble understanding your use of the term DRM. Media DRM makes sense: the copyright holders want to \"manage\" their rights digitally. How is that relevant to Play Integrity or WEI? Whose right is being protected or managed? If I have an Android without Play Integrity there are certain apps that will not run, but I don't see any rights being managed here: an app developer has the right to refuse service just like I have the right to refuse running an app. In fact I see no relationship between DRM and Play Integrity other than a tenuous connection that both are about controlling what a user cannot do on their device. If this is what you mean, then you have made the same mistake as FSF by conflating unrelated technologies. reply ethbr1 2 hours agorootparentUltimately, DRM is untenable without users also being locked out of their own devices. Consequently pressure to support more effective DRM will always translate into pressure to restrict what users can do with their devices. Furthermore, the only defense against this is large open device market share: once closed devices comprise most of the market, DRM proponents can announce they'll stop supporting open devices, creating a downward spiral that further decreases the availability of open devices. And then we live in a future that's fucked. reply badsectoracula 1 hour agorootparentprev> an app developer has the right to refuse service just like I have the right to refuse running an app. In this case it feels like an app developer having the right to punch[0] you in the face just like you have the right to refuse being punched in the face :-P. [0] (to use a family friendly verb) reply TacticalCoder 1 hour agoparentprev> the future for personal computing is looking grim I don't know. They could lock up the hardware stack as much as they want, in the end it's pixels being pushed to arrays. It's extremely hard to prevent these pixels from being intercepted. You'll have pirate groups just going deep in the hardware (opening the monitors and soldering and hacking and whatnots) and eventually tap these. As for personal usage: I've got hardware from the eigthies still working fine. Instead of: movie2025-WEBRip1080p-x265.mp4 people shall download: movie2025-WEBRip1080p-DRMfree-x265.mp4 And people shall just play that on their DRM-free hardware, either brand new or old. For example people can still buy brand new CRT (!) screens today. Not just CRT screens but also brand new CRT PCBs to drive either new or old CRTs. It's 2025 and people can still buy brand new CRTs. That's kinda rad. And if worse comes to worse, if it's really impossible to go \"tap\" into the pixels being sent to a DRMed monitor (which I don't buy for a second), there's still the analog hole. Pirates are just going to use old (non DRMed) gear to rip, analog style, DRMed content and then they'll just process the result with some AI models to get it back to near perfection. Heck, the day's probably not very far where I can use, say, two handcams from the 90s to film a movie at the movie theater and then use an AI model to give back a near pristine movie file (as in: one where it's impossible for the layman to discern from the original). > This tech extended to browsers could easily mean that sites could refuse to serve you That's already the case: some content is geo-blocked. People use a VPN or just fire up Frostwire or qbittorrent. Even a Raspberry Pi 5 goes a long way: when are these going to play the DRM game and make the future look grim, instead of bright? I don't doubt there are really deeply sick, evil, people out there thinking about how they can ruin of collective future but I also know that they'll encounter people who have systematically owned their sorry arses. reply thomastjeffery 10 minutes agorootparentWe're not concerned about DRM because it will (or won't) stop us from redistributing and playing content. The stated goal of DRM (blocking copyright infringement), and DRM's general failure to meet that goal, is the least interesting part of the story. We're concerned about DRM because what it does accomplish. DRM creates a vertically-integrated market wherein every layer of the stack is authoritatively controlled by a colluding oligopoly of vertically integrated hardware+media corporations (Apple, Amazon, Facebook, Comcast, etc.) The greatest problem with DRM is drivers. NVIDIA hardware only works well in Linux because it's important to NVIDIA's business. Even so, there are longstanding issues that would have been fixed decades ago if kernel devs were allowed to collaborate. Instead, DRM (and copyright in general) demands that the driver dev team be siloed away from the kernel devs. This way, NVIDIA can use the exclusivity of its CUDA implementation as an anticompetitive advantage in its hardware business. Copyright is, fundamentally, a wall between would-be collaborators. DRM is an implementation of that wall, but instead of isolating people, it isolates software. The wall DRM provides is not used to monopolize the distribution of content: it is used to construct moats in our software ecosystem. There's a reason I prefer the experience of torrenting a Netflix rip over streaming Netflix on my Roku: the entire hardware+software stack is superior. I can actually sort and navigate my library. I can decode&render with my faster GPU. I can adjust the audio delay. I can adjust subtitle placement & font. I can mix the audio so that dialogue is actually audible. I can do frame interpolation with SVP (again using a better GPU than whatever your \"smart\" TV has onboard). I can seek forward&backward quickly without changing bitrate. I can let the credits play without being interrupted by an ad. The list goes on... I don't want a goddamn CRT. I want modern hardware. The more we let corporations abuse us with DRM, the less compatible that hardware will be with real software. reply stonogo 51 minutes agorootparentprevThe issue isn't preventing piracy, it is defending GPU market segmentation. In the old days you could flash Quadro firmware to Geforce cards and unlock features or modify clocks. The common thread is artificial scarcity. reply 1vuio0pswjnm7 8 minutes agoprevIs it possible that some of the readers FSF is targeting may not be using a GPU. reply MBCook 14 hours agoprevI fully get the DRM hate. Now I don’t really follow the Windows world but I thought the goal of the newer TPM stuff was to be able to provide a trusted boot chain the way Apple does. I’m under the impression that some of the earlier versions allowed the TPM module to be a separate piece of hardware from the CPU and thus exposed an hardware attack path where someone could snoop or man in the middle. If you have a full trusted chain you can certainly use that to ensure that the DRM isn’t being tampered with. But I kind of doubt that’s the main reason behind all of it. There are enough good reasons they may want better security on the hardware outside of that it seems justifiable that they might push it. I’m not arguing it’s good or bad, I just don’t think it’s 100% about DRM and the rest is a smoke screen. reply yakaccount4 9 hours agoparentDeploying some sort of TPM remote attestation for DRM requires every component from every vendor to play nice, so I don't think you'll ever see that rolled out for Windows. I would guess that the actual push for TPM is to have 'better' BitLocker, and Passkey support. In practice the default BitLocker+TPM configuration isn't that great (no user entropy/pin, dTPM is basically worthless). I have no actual understanding for how TPM is involved for Windows Hello/WebAuthn/Passkey or whatever, but at a glance it would seem Biometrics without a TEE seems like a very weak link. reply MBCook 51 minutes agorootparentI figured it’s more about ensuring the kernel and boot loading and OS are 100% unmodified by attackers/malware. If that helps with bitlocker or passkeys or whatever that’s great. But I assume at its base it’s a pure integrity play. I would think that would also let you know the public key stuff used to communicate with hardware authentication like a fingerprint reader is secure too, but I don’t know how that stuff works well enough to know if that’s true. reply ChuckMcM 15 hours agoprevThis is a much more accurate statement than the hate on the TPM. As the article describes, it is the GPU that has its own separate memory space that it can show on the screen without the CPU being involved at all. I expect next generation workarounds will involve virtual GPUs. reply Retr0id 15 hours agoparentA virtual GPU is useless if it's not provisioned with the relevant key material. reply mike_hearn 9 hours agoparentprevIf that worked it'd have been done over a decade ago. The remote server is handshaking cryptographically with the GPU itself, which identifies itself using certificates and keys tied at the factory. You can't emulate such a GPU unless you find a way to steal the keys. reply MadnessASAP 16 hours agoprevI have to wonder A) What does DRM realistically accomplish for the media companies? And, B) How are these DRM schemes actually being defeated? I do occasionally don my pirate hat* and have never had an issue finding what I want at the quality I want within an hour of a episode/movie being released to streaming. That would seem to indicate that these efforts at DRM are actually failing to have any noticeable effect at all. [*] Jellyfin & and the -arr daemons are far more usable and stable then wading through the various streaming services interfaces, so I'll download episodes even though I do actually pay for the streaming services. reply pornel 6 hours agoparentPiracy is just a convenient excuse. DRM is really about control. It's a technical trick that thanks to DMCA anti-reverse engineering clauses becomes a legal trick to dictate exactly who and how can play the content, much tighter than what copyright and consumer laws allow by default. For example, without DRM you couldn't effectively sell separate licenses for computer screens and TVs, because users could just connect their computer to a TV. DRM allows negotiating everything about distribution, up to who pays who for having a button on the TV remote. Those who control the DRM have a veto power over everything, and have it viciously enforced internationally thanks to it being tied to copyright. reply n144q 2 hours agoparentprevDRM has definitely made pirating more difficult, and that is good enough for media companies, even though it is not enough to stop all forms of it. Also as others have pointed out, often it has more business/legal meaning than technical meaning. One example -- it has made creating pirated videos almost inaccessible to most people. In the past, if all other methods fail, you can always just record your screen with a common recording application. That's not possible with GPU enabled DRM, which is enough to stop a casual consumer to share a movie to their friends (even at a less ideal quality). > have never had an issue finding what I want at the quality I want within an hour of a episode/movie being released to streaming. That's because you are consuming mainstream/popular media. You often won't find recordings of a lot of performance art (ballet, concerts etc)* and I-am-not-going-to-name-it-content because there is a lot less demand. * an interesting exception is that a lot of content released via Blu-ray gets decrypted, ripped and torrented. reply majormajor 16 hours agoparentprevDRM has likely had a big impact in shifting the casual consumer conversation to \"hey they're gonna start down on account sharing\" from early-2000s style \"here's a straight-up copy I made for you.\" And this helps prop up the \"they'll get a Netflix account to binge the same three shows over and over\" part of the business model. The cumulative monthly cost adds up but it feels cheaper than forking over a few hundred bucks for a few box sets + buying a disc player. None of the hurdles stop 100% of people. But every hurdle causes some people to stop bothering. reply watermelon0 10 hours agorootparentIn many cases, downloading torrents and watching on a laptop/PC has a better UX than using streaming services. For example, it's impossible to watch 4k content on popular streaming services if you use Linux, and even with macOS/Windows you need a specific combination of hardware + OS + browser, if a service even offers it. reply LegionMammal978 2 hours agorootparentTo be fair, UX isn't only about the point of consumption. 4k torrents don't grow on trees (luckily, 1080p is good enough for my own tastes), and for old or less-popular movies, it's often tough to find seeders, or they all upload at 100 kbps or only have half the file or something dumb like that. (At least on the public trackers I'm aware of: I have no clue what goes on in the super-duper-exclusive private trackers that some love to boast about.) So I'd put accessibility and consistency as important parts of UX that torrenting can often miss out on. For the common person who is using Windows/Chrome, macOS/Safari, or a gaming console, those parts can easily be more important. Of course, these methods start to shine when legitimate methods are even less accessible. For instance, U.S. sports streaming is an absolute mess with multiple networks, regional blackouts, etc., on top of buggy apps, so that you sometimes can't watch a game legally for any price. People have widely picked up illegal streams as an alternative, usually preferring familiar platforms like YouTube if the streams aren't taken down quickly enough. reply charrondev 42 minutes agorootparentOn private trackers you can sometimes even see 4k blurry remuxes up before the blueray is even available in your local area due to different release windows around the world. As far as I’ve seen, they pretty much grow on trees as far as films are concerned. TV shows are a very different story though and outside of hugely popular series are far more inconsistent. reply jakogut 16 hours agoparentprevThere's always an analog loophole. Even if the OS is unable to access the memory storing the decrypted data, you could always just plug the output of the machine into a capture card and capture the decrypted stream that way. I suppose some monitors and TVs have \"features\" to cryptographically handshake with the GPU and ensure a secure link, but at some point the data must be decrypted and decoded to be displayed. This doesn't seem like much more than a speed bump for a motivated individual. reply tasn 15 hours agorootparentThe end goal is DRM all the way to the screen. No capture cards will be allowed. It's a cat and mouse game, but I wouldn't discount these efforts as a mere speed bump. Screen enforced DRM will make things much harder. A motivated individual with the right tools and hardware hacking know how may be able to jailbreak a screen to record stuff, but that's going to make things out of reach for most people. reply soerxpso 15 hours agorootparentIt doesn't matter at all how out of reach it is for most people. As long as one kid in Russia can do it, the torrent is available for everyone in the world just as soon. This has already been shown with videogame DRM like Denuvo. It's so hard to crack that only a handful of people know how, and yet they end up racing eachother so eagerly every time a new game comes out that it's usually done in under 24 hours. Unless you can beat \"so secure that only a handful of people in the world can crack it\" the situation will always be the same. reply tasn 4 hours agorootparentNot quite. The problem is that when you involve hardware, things are exponentially harder. When you tie it with content streaming, it's essentially a losing battle. Hardware: makes cracking much much harder and out of reach for a lot of people. Even the people that can do it are going to be drastically slowed down due to this. Streaming: means you can block specific device keys once you know they are compromised (the hacker managed to mod the TV to be able to record from it). reply jsheard 15 hours agorootparentprevDenuvo has pulled back into the lead lately, it's taking a very long time for cracks to appear, if they ever do. For example Dragons Dogma 2 came out in March and still hasn't been cracked. Avatar: Frontiers of Pandora hasn't been cracked for a full year. reply AnthonyMouse 14 hours agorootparentActive player counts: Minecraft: ~185,000,000 World of Warcraft: ~7,250,000 Dragons Dogma 2: ~4000 This seems more along the lines of nobody bothers to crack games nobody wants to play. reply jsheard 14 hours agorootparentDD2 is a single player game, those generally don't maintain their active player counts forever. It peaked at 228,285 concurrent (not total) Steam players which are pretty good numbers. reply AnthonyMouse 14 hours agorootparentThe peak was the release, after which it promptly cratered. It was below half that within a month and below 14k the next month. reply pxoe 3 hours agorootparentThis obsession with concurrent player counts, especially for single player games, is just obtuse. It's not actually telling what you want to believe. reply jsheard 2 hours agorootparentEven if we do go by concurrent players, Black Myth Wukong had one of the biggest launches in Steams history with a peak concurrent of 2.4 million players, and that hasn't been cracked either after five months. reply dvngnt_ 1 hour agorootparentprevthere's only one person releasing cracks for modern denuvo and their last release was a year ago, and they're crazy reply AnthonyMouse 7 minutes agorootparentApparently the people doing this kind of work have been disproportionately in Eastern Europe and what's going on in Ukraine has so disrupted that part of the world that they currently have bigger problems. So then you're waiting for either that region to stabilize or demand for cracks to cause people somewhere else to get into the game, and in the interim you effectively have a temporary supply chain issue. But it's hard to give credit for the ravages of war to the DRM pushers and it's not at all obvious that they've secured any kind of permanent advantage. loeg 1 hour agorootparentprevDenuvo is winning, for better or worse. You can see some of the lead times for cracking these games[1][2]. It's, you know, often months+. [1]: https://www.reddit.com/r/CrackWatch/comments/1hqd4p3/crack_w... [2]: https://www.reddit.com/r/CrackWatch/comments/ieo7u4/crack_wa... reply theshackleford 5 hours agorootparentprev> This has already been shown with videogame DRM like Denuvo. No it hasn’t. > Everytime a new game comes out that it’s usable done in under 24 hours This is not even remotely true and is not based in any kind of reality. reply Neonlicht 5 hours agorootparentBack in the day when piracy was quite literally just copy and paste it was a very active scene. But cracking Denuvo takes real skill- and there's no financial reward in it. Back in the 90s bootleg DVDs and CD-ROMs had organised crime making money from it. reply rescbr 26 minutes agorootparentExactly. Cracking Denuvo as a hobby is not something a sane person would do, and the downsides if caught are higher when one is fully employed. At least to me, a decade has passed since I left college and had spare time and energy to tackle such projects just for cred. reply geerlingguy 15 hours agorootparentprevWith how good modern screens are, and how good cameras are (and how easy both are to hack), you could always play back the video and capture the photons through the air. There was something called Macrovision back in the VHS/DVD days that tried to defeat digital/analog conversion, and I'm sure visual techniques could be devised... But I imagine someone with a good OLED and a good mirrorless camera (or even a cell phone nowadays) could make a pretty good 4K replication of any media that displays. reply anfilt 12 hours agorootparentProbably would be better carefully tap into the signal lines to the LCD panel, and record and decode that data to then make a video. However if we assume that even the cable going to the panel is encrypted and the board on the panel is decrypting it. (although I have never messed with a panel like that). However it still has to got to drive the rows and columns of the display, so then data to column and row drivers is still in the open. If we were to even assume the Column/Row drivers chips only accepted encrypted data they still have the individual traces coming out of them. The pitch of the traces is super tiny, but still possible to tap, but would be a massive pain, but still do able. Although you can get devices that strip the encryption from an HDMI signal these days so it's kinda moot. So it's not exactly something anyone would need to do these days. reply jdietrich 14 hours agorootparentprevOnce upon a time, this was how all video-to-film transfers worked. https://en.m.wikipedia.org/wiki/Kinescope reply loeg 1 hour agorootparentAlso called Telecine (or at least, a very related process), as in: https://en.wikipedia.org/wiki/Telecine_(copying)#Piracy reply rustcleaner 46 minutes agorootparentprevThis works for me! Nobody needs more than 480i anyhow. reply Wowfunhappy 15 hours agorootparentprevEspecially when you add HDR to the mix, I think it's still extremely difficult to get a high quality screen recording, if only because it's so hard to get the exposure right. reply kuschku 15 hours agorootparentYou'd think so, but I've already run into a situation where DRM broke our screen capture for a live talk recording and I simply set up a camera to record the screen. With a little bit of work (display a few calibration targets and build a quick and dirty LUT to match your display) you can get really convincing results. reply 3eb7988a1663 13 hours agorootparentIt was good enough for the moon landing. The video feed from Apollo 11 was some special format that was specially decoded onto a particular monitor. There was a camera pointed at the screen to rebroadcast the feed globally. reply Retr0id 15 hours agorootparentprevYou could record multiple exposures and merge them after the fact (and I agree the result would likely be subpar, but better than it's ever been at any previous point in time) reply Wowfunhappy 15 hours agorootparentYeah, I guess it really depends on what your standards are. It's certainly getting better but I have trouble imagining anyone would consider this a good solution. At minimum, if this was what pirates had to resort to, then I would think the DRM has done it's job, in that it very significantly degraded video quality for the pirates. reply sudosysgen 15 hours agorootparentprevModern dedicated cameras have far more dynamic range than any HDR TV in practice. The movies have to be recorded somehow :) reply Wowfunhappy 15 hours agorootparent> The movies have to be recorded somehow :) I'd imagine they do this via huge (non-consumer level) cameras as well as by professional editors and graders who spend countless hours on the process. But that doesn't really contradict your point. I don't know. I've never seen a good screen recording but I don't download pirated films so perhaps I've never seen an instance of someone really trying to get it right. reply geerlingguy 30 minutes agorootparentMy A7C II ($2000-class mirrorless) has a sensor with far more range than any monitor I've ever been able to afford. reply sudosysgen 14 hours agorootparentprevThe cameras you can buy used for a couple thousand dollars have essentially the same sensors as huge cinema cameras, if not better in this application assuming you'll take stills. Professional editors and color graders have to lower the dynamic range, because there is basically nothing that can get as bright as, say, the sun, and because basically no display can sustain peak brightness over the screen, which introduces an EOTF transfer curves, reducing the peak brightness and thus dynamic range. You're right about pirated films, but that's because they're typically recorded in a run of the mill cinema while it's playing, not in controlled conditions in front of a carefully calibrated screen-camera combination taking a photograph of every frame. reply baby_souffle 15 hours agorootparentprev> The end goal is DRM all the way to the screen. No capture cards will be allowed. Sure, but the closer you get to the eye ball, the bigger the loophole is. It's not common anymore, but _way_ back in the day, some releases were made *in the projection booth* with a semi-pro camera on a tripod pointed at the screen. (look for old NFO files with `TS` or `TeleSync` in them to get an idea of when this was common-ish) The analogue loophole will remain open until there's a HDMI to optical nerve technology that we're all forced to get at birth. reply Wowfunhappy 14 hours agorootparent> The analogue loophole will remain open until there's a HDMI to optical nerve technology that we're all forced to get at birth. This is kind of a pointless tangent, but you might not have to go that far. It's probably hard to get a recording of the Apple Vision Pro for instance. reply teeray 3 hours agorootparentLikely not an issue. Convincing consumers to strap a brick to their face has proven to be a persistent challenge, which even Apple has not been able to overcome. However, there is also a nontrivial percentage of the population who medically cannot use VR/AR. This population is large enough that there is a market for \"2D Glasses\" for removing 3D effects from movies in cinemas. Releasing a title as a VR exclusive means excluding this population from your sales figures entirely. reply baby_souffle 14 hours agorootparentprev> It's probably hard to get a recording of the Apple Vision Pro for instance. I hadn't actually thought about that! For 99.995% of my time on this earth, \"screen\" meant \"flat, glass, viewed from some distance\". I guess it's time to spend some time thinking about what new ways to exploit the analogue loophole are... I wonder which part would be harder: designing something to fool the \"am I on a head? Where are the eye balls looking?\" bits or the optics needed to re-combine the stereo? reply orev 15 hours agorootparentprevThere are many USB capture dongles with chips that ignore DRM, easily available for cheap at popular online stores. Nobody has to go as far as jailbreaking screens. reply mysteria 15 hours agorootparentprevIn this case the piracy model might change into something like the software cracking scene where groups with specialized skills and equipment would be the ones doing the uploading. Regular people wouldn't be able to make copies with a capture card to send to their friends but popular films and shows would definitely still be released by those groups. reply rustcleaner 48 minutes agorootparentprevI can always just not consume the media. I will never pay for that hot garbage anyhow. DRM won't make me pay, it'll only take your trash out of my mindspace... which is probably a blessing anyway. reply Bancakes 15 hours agorootparentprevOr I just split the raw pixel values from the monitors t-con board. reply mike_hearn 9 hours agorootparentprevThere is no analogue loophole, that's like 15 years behind the curve. Cinavia closed that a long time ago and meant that licensed devices like Bluray players, even TVs, can detect cammed recordings even those cammed in movie theatres. Of course you can try to play them with hardware that doesn't follow the rules. But there's a finite number of vendors, so that isn't necessarily easy. reply ls612 2 hours agorootparentI’m confused, you’re saying the TV can tell if someone is pointing a camera at it? That seems highly doubtful. reply kbolino 2 hours agorootparentIt doesn't detect the act of recording live, it detects that a piece of media was obtained via recording. So, you can still point a camera at the screen and obtain a video file without any disruption to the original signal. However, that file won't play properly on Cinavia-enabled devices. reply ls612 1 hour agorootparentAny computer or phone can play it back I’m sure. It’s just an MP4 file. And with Airplay or an HDMI cable your TV can too? reply kbolino 1 hour agorootparentIt's not clear to me how widely Cinavia is actually deployed. The Wikipedia article hasn't really been updated in over a decade, and that's where I'm getting my info from. However, the detection and enforcement can theoretically be done by any device or software that has access to the audio signal. The monitor, the GPU, the playback software, the operating system, etc. could each individually decide not to play the file, making it not work. Some of those can be bypassed in various ways, some can't. But instead of computers, there are smartphones, commercial media players/receivers, and televisions/projectors, which seem the most likely places to target for enforcement, and those would affect most people. Nevertheless, I do wonder how real this actually is. Again from the decade-old Wikipedia article, it seems like Cinavia was meant to target both recording devices and playback devices. However, the Aurora theater shooting happened not long before the article stopped getting meaningful updates, and I wonder if public safety concerns stalled its deployment. Also, the article mentions that people were finding ways to remove or neuter the signal. I also didn't encounter any problems with what I assume to be protected media (a 4K movie and a 1080p TV show), either recording my screen with my Android phone, nor with playing it back on that phone and with VLC on my Windows computer with an nVidia graphics card. reply loeg 15 hours agorootparentprevYeah, but pirate groups are getting the original streaming service's compression without re-encoding (so-called \"WEB-DL\"), even of 4k content. There's a weaker link somewhere. reply lksaar 15 hours agorootparentWV L1 Keys/ PR SL 3000 keys require breaking into the TEE to steal those decryption keys. Ever wondered why netflix 4k web-dls take a while for less popular shows? Netfliy monitors these more tightly apparently and blacklist keys that are used to download. Then the group needs to buy some new device, the old one is burned. reply Retr0id 15 hours agorootparentIt's true that known-compromised keys get revoked, but it's possible to avoid them knowing you've compromised a particular device. reply jsheard 15 hours agorootparentI think there's some kind of watermarking going on, so once a rip is released to the public they can trace it back to which device keys were used to decrypt it. reply Retr0id 14 hours agorootparentWatermarking would require a separate version of each encoded file for each target device, which is not amenable to efficient CDN-ing. It's quite easy to grab the encrypted media files, as they go over the wire - do this from two devices and compare what you get. (you don't need to strip the DRM to see if the two files are identical) reply jsheard 14 hours agorootparentThey wouldn't necessarily need to serve different data to each client when they control the whole playback stack, they could get clever by including duplicate frame data with subtle differences and making each device key only able to decrypt one of the variants. Repeat that throughout a show to add additional bits to the signature until it's uniquely identifiable. reply Retr0id 14 hours agorootparentBut they don't control the playback stack, once the attacker has the keys. The attacker brings their own stack, decrypting the data with their own software. reply jsheard 14 hours agorootparentThat doesn't help the attacker if their key can only decrypt the subset of frames which Netflix wants them to be able to decrypt. reply magila 14 hours agorootparentprevWatermarking was a problem when Widevine L1 was first introduced. Pirates seem to have found a way to scrub the watermark from their releases. Either that or someone is burning a _lot_ of cash on playback hardware judging from the rate of 4K WEB-DL releases. reply bccdee 1 hour agorootparentDepending on the bit size of a watermark, device-based watermarking should be easy to defeat using a quorum of devices to agree on bit values. It should only take around log2(n) attackers to remove an n-bit watermark. reply kimixa 13 hours agorootparentprevIt doesn't need to be a lot - just replaced in the same cadence as the latency from initial broadcast to key revocation. Even if it's all in-house in Netflix and the watermark sufficient to identify the specific device key not all releases are made instantly after being made available on the platform, it still has to be downloaded, verified, watermark extracted before the key can be revoked. If that's just a total of a single day, 365 cheap netflix devices per year certainly isn't out of the question, especially with the number of people involved in the many ripping groups. reply bambax 15 hours agoparentprevYes, DRM are a perfect example of the \"Smart Cow\" problem [0]. This is so obvious that, as you say (A) it's quite obscure why media companies still bother with DRM? The only beneficiaries of DRM seem to be hardware vendors, and even for them it's unclear if it's a net benefit, since it makes everything more expensive. [0] https://en.wikipedia.org/wiki/Smart_cow_problem reply fluidcruft 15 hours agorootparentProbably advantage of DRM is that circumvention can be criminalized and absence of DRM implies circumvention. reply AnthonyMouse 15 hours agorootparentWhat advantage does this have over just criminalizing the underlying infringement regardless of DRM? Also, how does criminalizing it actually help anything, since the difficulty is in the scale of it happening and the difficulty of detecting it rather than the severity of the penalties, and imposing draconian penalties on random kids only turns the public against you? reply fluidcruft 17 minutes agorootparentI think it plays differently before a jury. Juries can easily understand copying files and could potentially invalidate. But it's different when lawyers get to move the conversation to scary hacker garble about technical skill and intent. Evidence of intent is the real value. reply dannyobrien 15 hours agoparentprevIIUI it's mostly a question of a mess of contractual language and incentives. Rightsholders license content, and in their licensing contracts they require a certain level of DRM for certain products. So streamers, etc, implement the DRM to comply with those contracts. Nobody at any level has an incentive or leverage to change the contracts, so the DRM continues. reply cryptonector 2 hours agorootparentThat and also various principals are under the impression that DRM is possible, therefore they should implement it because it protects their IP, and protecting their IP is a fiduciary duty, therefore they must if they can. reply codethief 10 hours agorootparentprev> IIUI If I understand incorrectly? (Jokes aside, though, I haven't been able to figure out what IIUI stands for.) reply merrywhether 3 hours agorootparentIf I understand it? reply throwaway654322 15 hours agoparentprev> B) How are these DRM schemes actually being defeated? 1. Disable video hardware acceleration in browser (preferably FF) 2. Open OBS studio 3. Record screen while streaming service of your choice is running. Still works in modern OSs like Windows 10. You're technically not circumventing the DRM decryption routines when you do this since the pixels displayed on screen have already been decrypted (just like recording cable to VCR post-decryption), so the legality of it is towards the lighter grey end compared to ripping DVDs. IANAL though. reply jsheard 15 hours agorootparentThat only works with the weaker tiers of DRM which are typically only allowed to stream low resolutions. As mentioned in the OP article, the stronger DRM tiers never make the cleartext visible to software and those are mandatory for high quality streaming. Not to say the stronger tiers never get broken but it's a lot more involved than just recording them with OBS. reply kuschku 15 hours agorootparentYou can get HDMI capture cards that do 4K30 HDR while removing HDCP for $20. Use Microsoft edge for playback (so you get 4K HDR). Stylish as addon to remove any player hud. Especially useful if you want to legitimately use copyrighted content but obviously can't just use a pirated version. reply HeatrayEnjoyer 4 hours agorootparentWhich cards strip modern HDCP? reply ec109685 2 hours agorootparentSomething like this produces a clean hdmi stream: ViewHD 2 Port 1x2 Powered HDMI 1... https://www.amazon.com/dp/B004F9LVXC?ref=ppx_pop_mob_ap_shar... reply kuschku 51 minutes agorootparentprevhttps://aliexpress.com/item/1005003020587234.html reply Thorrez 11 hours agorootparentprevNetflix limits FF and Chrome on Windows to 1080p. On Linux it's even worse: 720p. And up through Dec 2023, FF and Chrome on Windows were limited to 720p. That's right, it wasn't until 2024 that Netflix on Chrome on Windows supported 1080p... That's what, 15 years after 1080p monitors became common? https://web.archive.org/web/20231229030336/https://help.netf... https://help.netflix.com/en/node/23931 reply rustcleaner 52 minutes agoparentprevDRM is the camel-nose of a worldwide technocratic North Korean-style digital future. reply jhanschoo 12 hours agoparentprev> A) What does DRM realistically accomplish for the media companies? My guess is that when content platforms negotiate with IP holders, there is some need to show that some DRM is in place. reply roenxi 15 hours agoparentprevThe sort of person who can set up -arr daemons isn't going to really be on the radar of anyone pushing DRM. Those skills are so rare people will pay for them. The point is that there is a huge market of people who barely know what an internet is but want to watch media. As long as they can't figure out how to get pirated content up and running quickly then DRM is doing its job. Pirated content represents a relatively small and motivated community. There'll always be something like it, so the question for rightsholders is how to manage the size and visibility of that community. reply jsheard 16 hours agoparentprev> How are these DRM schemes actually being defeated? Stripping the more advanced forms of DRM usually relies on compromised device keys which can and will be revoked if it becomes known that they've leaked, so the details are deliberately kept very quiet. If you've ever experienced a device suddenly losing the ability to play 4K Netflix, it may have been because its keys were revoked. reply lotharcable 16 hours agoparentprev> A) What does DRM realistically accomplish for the media companies? Control publishing rights, platforms, software and hardware that is used for the consumption of said media. The publishers control the DRM, which then needs to be licensed by television makers, software writers, and such things. Then that gives them control over how is it presented, how it is sold, how it is consumed and it forces everybody to agree to their terms. It is a power thing. They want to have power over other businesses. DRM laws help them do that. > How are these DRM schemes actually being defeated? Well I don't follow DRM piracy stuff, but at a high level the people that want to consume the media must be able to decrypt it to enjoy it. So if you buy one of these DRM devices and figure out how they work then you can decrypt anything that is compatible with them. And you only need to decrypt it once since digital media can be copied a infinite amount of times. reply AnthonyMouse 15 hours agorootparent> It is a power thing. They want to have power over other businesses. DRM laws help them do that. This is the argument for repealing them, which is why you rarely see them making it out loud. Instead they come up with some rubbish about making it marginally more difficult (spoiler: it's still easier to pirate stuff than use legal services and the only thing actually preventing everyone from doing it is that some people want to follow the law). So it's good to knock those fake arguments down when you see them and leave no excuse to keep the bad laws that ought to be repealed. Accepting their actual motivation like it's a legitimate reason to keep those laws is like saying the reason we should keep doing the stuff Snowden revealed is so the intelligence agencies can spy on the elected officials regulating the intelligence agencies. reply tonymet 2 hours agoparentprevIt seems to have been a success. Prior to DRM, pirated material was much more common than paid streaming services. Now that has been reversed. Now that streaming is commonplace it seems less necessary, but it was an essential stepping stone and an ongoing defense against piracy reply refulgentis 15 hours agoparentprevThat things are just annoying enough to pirate that there isn't ever a freeforall, like limewire or kazaa, again. reply maeil 15 hours agorootparentDepends, in certain locales pirate IPTV is very popular, arguably even easier than Kazaa ever was! Stick a USB in your TV, done. reply timewizard 15 hours agoparentprevThey hate \"losing\" money more than they enjoy making it. It's worthwhile to mention that Hollywood was and still is a cartel system. reply UniverseHacker 15 hours agoprevThere’s some technical details missing here. I get decrypting the video on a gpu makes it harder to screen capture, but can’t you just still emulate the GPU in software or directly capture the digital video output? The GPU still has no unique hardware private key, right? reply jsheard 15 hours agoparentCapturing the digital video output is supposed to be prevented by HDCP encrypting the signal, but in practice that's pretty well broken. That is a (slowly) moving target though, each time they roll out a new HDMI version (e.g. for 4K) they get to enforce a new version of HDCP which needs to be broken all over again. I don't think the version of HDCP attached to HDMI 2.1 has been broken yet but that's kind of a moot point because no current video formats require more than HDMI 2.0. reply pavon 13 hours agorootparentAlso note that the HDMI Forum refuses to allow AMD to make an open source implementation of HDMI 2.1 in their drivers for this reason. reply timewizard 15 hours agorootparentprevIt's hilarious to imagine the meeting where they finally convinced themselves they could put worthwhile lasting encryption in consumer devices with a 10 year+ installation lifetime. What a complete and total waste of effort. reply UniverseHacker 2 hours agorootparentI suspect bad encryption still does exactly what they intend, because it means there is no simple one click solution built into an OS or browser to download streaming media for later watching or sharing with friends. For example, a lot of regular modern OSs have the ability to rip and share an unencrypted audio CD in a simple intuitive way with no shady pirate software to install. It's a legal hurdle, not a technical one that prevents the 'above the board' software suppliers from adding this feature. Pirates clearly are able to extract the 4K video and upload them to torrent sites, but the average media consumer would rather pay a netflix subscription fee that deal with the shady underworld of those sites with the virus installing and crypto mining popups, warning letters from your ISP, etc. They've managed to make it hard enough that the number of people that do it is insignificant to their bottom line. reply ls612 2 hours agorootparentprevAll the HDCPs are broken by those cheap Chinese splitters which downgrade it to 1.4 (allowed by the specs for some reason) and 1.4 is thoroughly broken. At least that was the case last I checked. reply p_l 14 hours agoparentprevThe parts involved in protected Audio/Video path do have their own encryption keys and hardware support outside of anything touched by the OS. In fact it's major part of what Intel Management Engine does if you do not have the \"advanced\" license for remote management, and AFAIK why AMD PSP on normal AMD cpus has closed source firmware. Both are responsible for setting up protected media path and both are interrogated by DRM modules to setup encryption. reply mjg59 15 hours agoparentprevThe details don't seem clear, and I don't know that there's necessarily a unique key rather than stuff being batched, but basically yeah there's a cert chain back to a \"trusted\" source reply elthjan 15 hours agorootparenthow does the decryption key get into the GPU? are GPU's currently shipping preprogrammed with keys used in DRM? reply transpute 15 hours agorootparentSome GPUs have their own silicon root of trust. Intel ME has a role in PAVP (Protected Audio/Video Path). reply Mindwipe 11 hours agorootparentprevYes, every* card since the Kaby Lake iGPUs or Nvidia 1080 cards. *To all intents and purposes, I'm sure there's some exceptions with no market share. reply Asooka 4 hours agoparentprevMaking your own GPU sounds intriguing. You could hook up a small ARM computer to the PCI slot and implement a GPU in software. A very slow GPU obviously, but fast enough to decrypt the video frames. I'm not sure if you'll be able to write a driver for it that will seem legit to Windows. reply Stagnant 15 hours agoparentprevYes, you can get around it by playing the video in a virtual machine and capturing it from the host. For widevine videos playing in browser it is also as trivial as disabling hardware acceleration from the browser's settings. reply Wowfunhappy 15 hours agorootparentBut doesn't this limit you to 1080p? reply Retr0id 15 hours agorootparentCorrect reply Wowfunhappy 15 hours agorootparentYeah, so that's not really relevant. Hardware DRM is generally only used for 4K, as mentioned in the article. reply Retr0id 15 hours agorootparentIndeed, note that I'm not the same user you were originally replying to reply Wowfunhappy 15 hours agorootparent(Thanks, yes I know! I still wanted to finish the point!) reply Mindwipe 11 hours agoparentprev> The GPU still has no unique hardware private key, right? GPU's have had unique hardware private keys and secure memory for a decade. reply UniverseHacker 2 hours agorootparentHow does the remote streaming server know a key is an authentic hardware GPU that hasn't been compromised, and not something you just generated in software, to enable software level decryption of the media? It seems like you'd need some central SSL like certificate authority to verify and revoke credentials that were universally implemented in the same way by all GPU manufacturers.... surely there is no such thing? reply kbolino 58 minutes agorootparentAt least for HDCP, that's exactly how it works. From the HDCP 2.2 spec [1]: > Device Key Set. An HDCP Receiver has a Device Key Set, which consists of its corresponding Device Secret Keys along with the associated Public Key Certificate. > Public Key Certificate. Each HDCP Receiver is issued a Public Key Certificate signed by DCP LLC, and contains the Receiver ID and RSA public key corresponding to the HDCP Receiver. > The top-level HDCP Transmitter checks to see if the Receiver ID of the connected device is found in the revocation list. [1]: https://www.digital-cp.com/sites/default/files/specification... reply UniverseHacker 54 minutes agorootparentThanks, that clarifies my confusion about how this could be realistically implemented. I couldn't see a practical way to verify every device on every connection via a central authority without massive scaling and reliability issues, but maintaining a small revocation list that can be cached everywhere media is distributed from seems quite practical. reply stackghost 16 hours agoprev>The FSF's focus on TPMs here is not only technically wrong, it's indicative of a failure to understand what's actually happening in the industry. This sounds 100% on-brand for the FSF. The FSF's primary public-facing persona has peculiar computing habits so far removed from the mainstream that it's likely he has absolutely no clue how the real world works. In fact by his own statement he has to rely on volunteers to update his website. It's disappointing to me because the FSF could be so much more influential today, but the cult of personality around RMS has really destroyed their public credibility among \"normies\", the most important demographic to convince. When the FSF finally realizes that a political organization such as theirs needs a public face with charisma and social skills, it will be too late. reply UniverseHacker 16 hours agoparent“Normies” are never going to care about the stuff the FSF is interested in. I don’t think you can extract the philosophy from the eccentric personalities that created it, they’re one in the same. reply stackghost 16 hours agorootparentNormies are who you need to convince if you want to effect social change. If the FSF sticks to their current mission of preaching to the choir, they'll remain about as relevant as they are today, which isn't a lot. reply zb3 15 hours agorootparentPeople in power and people with money are who you need to convince.. reply solarkraft 15 hours agorootparentAnd how are they best convinced? Besides personal benefits like bribes, public opinion (re-election) and consumer habits (company profitability) seem to matter significantly. Please do add the options that I am forgetting. reply ignoramous 9 hours agorootparent> public opinion (re-election) No matter who is re-elected, there's a preset window for law & policy, which perhaps only public outrage (and opportunist politicians) can shift. Outrage is a high bar (may be perhaps outside of Twitter). reply stackghost 15 hours agorootparentprevEating junk from your toenails on camera doesn't convince those people either. reply talldayo 52 minutes agorootparentNor has rational discussion, either. reply chii 15 hours agorootparentprevbut those in power, at least in the west, is somewhat subservient to the population as a whole (via voting - wallet or ballot). reply solarkraft 15 hours agorootparentprevIf you believe that normies deserve computing freedom (this doesn’t seem to entirely be consensus in the scene), it ought to be a goal to explain the benefits of it in a way that they will understand. Some may still not care, but my experience is that a good part actually does. If nothing else this is good leverage to influence change for one‘s own interest. reply roenxi 15 hours agorootparentThe benefits are incomprehensible to \"normies\" and they have no power to effect change. They're just going to use whatever software gets put in front of them. All the progress - which has been substantial, free software is basically everywhere and does everything - has come from highly motivated and technical individuals who are anything but normal. That follows a basic pattern for any effective change, normal people pretty much always just whinge and achieve nothing. They're lucky to even be allowed the pittance of political power that is voting, historically speaking. reply UniverseHacker 2 hours agorootparentprevMost people just want to be able to access media easily with no effort- which they already can do with cheap streaming subscriptions. They have no interest in owning the rights to use it forever, or in downloading or copying it. They wouldn't want to take the time to figure out how to do that, even if they legally could when they can already just click and play. I think if you want people to care, you need to find a real world case where they are being blocked from doing something they really want to do- the abstract philosophical arguments about freedom are total non-starters. Possibly an alternative media supplier that was fundamentally less hassle, faster, and more reliable because it didn't have these systems could get people to switch. But good luck getting the digital rights owners to let you put their content on your platform. Or maybe convince people they can get higher quality media that way. I have a newish Mac with an amazing HDR screen, but few of the streaming sites are willing to stream the HDR content to my device. reply theandrewbailey 4 hours agoparentprevIt's been very clear to me for many years that the FSF is staffed by a bunch of out-of-touch boomers who believe that Microsoft is the end-all be-all of evil tech. That was probably true 30 years ago, but from their rhetoric, they've ignored how the computing landscape has changed. Namely, the ways smartphones are walled gardens that screw over people, often in the same ways Microsoft has. I've heard them mention in passing that Apple, Google, and Facebook are bad, but the volume of material directed at Microsoft overwhelms anything else. To the FSF, if it doesn't happen on a PC, its not a priority. It still amazes me that they're hurt over Linux stealing their GNU name/tools/momentum, but hardly a word is written about how Google stole Linux to make Android, and how the Android ecosystem is a complete betrayal of free software's values. reply talldayo 15 hours agoparentprevI think that's a misunderstanding of what the FSF stands for overall, though. The FSF can never be a diplomatic negotiator for the benefit of free software; they are idealists, even when it serves against their own interests. Their whole shtick is not settling for half-baked appeasements, and so they're destined to be a pariah of the tech industry at-large. Neither you nor me can stop them, it's entirely within their right to advocate and for practice simpler software. The statement criticized by the OP certainly seems warranted, but it's less endemic of the FSF removing itself from the mainstream and more like the mainstream has abandoned free software. > The FSF's primary public-facing persona has peculiar computing habits You know, the FSF would probably argue that our computing habits are the peculiar one. And unless you can tell me about the code your iPhone runs in detail, they're probably (albeit begrudgingly) correct. reply stackghost 15 hours agorootparentThere's no misunderstanding on my part; it's why I said that their ignorance is totally on-brand. >more like the mainstream has abandoned free software. Indeed, because free software development is largely driven by ideological purity rather than feature parity. Mainstream users see Free Software people as irrelevant kooks, and thus easy to dismiss, which is why Free Software has so utterly failed as a movement. >You know, the FSF would probably argue that our computing habits are the peculiar one. I'm sure flat-earthers feel that my belief that earth is an oblate spheroid is peculiar, too. Of what relevance is that to anyone? >And unless you can tell me about the code your iPhone runs in detail, they're probably (albeit begrudgingly) correct. We'll have to agree to disagree. The emacs developers don't even understand how large chunks of emacs work (per emacs-devel), for example. There's too much software out there for one person to keep in their head. This is not a reasonable heuristic. reply badsectoracula 1 hour agorootparent> Indeed, because free software development is largely driven by ideological purity rather than feature parity. This \"ideological purity\" didn't come out of nothing, it came out of the very practical issue of who is in control. People forget that RMS came up with the whole thing because he wanted to fix a broken printer and was denied the source code that could help him fix the issue. He wasn't siting in some ivory tower coming up with abstract philosophical questions, he was in some lab and had an actual practical problem he wanted to fix. reply talldayo 3 hours agorootparentprev> Indeed, because free software development is largely driven by ideological purity rather than feature parity. Ideological purity is a valuable thing. Look at Minix, hell, even look at the BSDs today. These are projects that have collapsed because of their feature obsession and ignorance of ideology. The differentiation of ideology is what makes free software uniquely successful - it is the feature. > Mainstream users see Free Software people as irrelevant kooks, and thus easy to dismiss, which is why Free Software has so utterly failed as a movement. Mainstream users don't think about Free Software at all. They certainly use it though. They rely on it, to provide and maintain the runtime their cell phone and iPad and router all depend on. It probably runs an RTOS on their grandpa's CPAP machine, it probably occupies the DVR for their cable TV and it's likely running on their games console and personal computer, too. Free software is even more inescapable than proprietary software. If users cared enough to understand the difference, you and I both know they would accuse the businesses of being the irrelevant kooks. Not a single \"maintream user\" I know would defend Apple or Google or Microsoft's business practices as software companies. No one. > I'm sure flat-earthers feel that my belief that earth is an oblate spheroid is peculiar, too. Of what relevance is that to anyone? As the other comment suggested, this is both an insincere response and one where you are the flat earther here. The FSF has reasons that they hold the principles they do, and you haven't refuted any of their ideology. You are the guy lambasting Gallileo, and when Gallileo asks you why heliocentrism offends you, you are replying \"because the mainstream clergy sees you as kooks.\" It's not a response at all. > The emacs developers don't even understand how large chunks of emacs work Nobody is so stupid that we expect every kernel dev to understand the whole of the kernel. It's folly, and not what I was asking anyways. Nobody at Apple understands how the entirety of iOS works either, but that's not an implication that it's inherently insecure. What makes the FSF balk at Apple is the inaccountability. The lack of reason associated with their statements asserting the privacy and security of a system that sues it's auditors. If you have a more reasonable heuristic to suggest, I'm all ears. reply stackghost 2 hours agorootparent>You are the guy lambasting Gallileo, and when Gallileo asks you why heliocentrism offends you, you are replying \"because the mainstream clergy sees you as kooks.\" I'm lambasting the people who think this fictional Galileo is a good public persona to lead their political movement, because this Galileo can't convince anyone of anything because he is almost entirely devoid of the skills one needs to advance a political cause even if Galileo might have written some good C code 45 years ago. >If users cared enough to understand the difference, you and I both know they would accuse the businesses of being the irrelevant kooks. Not a single \"maintream user\" I know would defend Apple or Google or Microsoft's business practices as software companies. No one. I can see we have irreconcilable differences. I find this statement ludicrous. I know lots of people who understand what free software is and choose to make a living selling proprietary software. This will be my last reply to you. reply talldayo 58 minutes agorootparent> I know lots of people who understand what free software is and choose to make a living selling proprietary software. That's not what I asked you, though. Do those same people defend Microsoft and Google and Apple's business strategies? Do they respect what the apex of proprietary software looks like, replete with advertising, data collection, vaporware promises, removed features, integrated spyware and mandatory junk fees? Unless your friends are an LLM, I suspect they don't, because they've been burned before and know better. As no serious economist promotes laissez faire economics in the 21st century, laissez faire software is not healthy for humans either. The abuses are right in front of us, and the blame is simple to dole out. It's for your own good that you stop replying to my comments if you're going to twist my words and avoid the topic. Free software isn't bound by the pragmatic demands of a market, and yes, that means that it can fail, but it can also end up displacing entire product categories as well. Anyone familiar with the past 3 decades of computing history knows this to be an irrevocable and proven fact. We would not be having this conversation on the internet if proprietary networking standards prevailed over open ones. reply BlueTemplar 8 hours agorootparentprevThe flat earthers are the people dismissing the concerns of the FSF though. (The Earth being round doesn't directly matter in practice to most people. It does have inevitable consequences though.) Or perhaps a better example is anthropogenic climate change : here too the implications are extremely inconvenient for most people, so denial is rampant. reply WeylandYutani 15 hours agoparentprevNormal people watch Netflix on a smart TV. Or their phone. Hell the only reason why I turn on my computer these days is for videogames. I wonder if the decline of the desktop has someone worried at Microsoft. reply pjmlp 10 hours agorootparentIt certainly has, and they have repented themselves of killing Windows Phone, turns out that when one wants to push stuff like AI and XBox ecosystem, having 10% market share is way better than not having none at all. Then again, they have been so busy with Azure and XBox profits, that Windows development has turned into a mess, of GUI teams fighting for resources, while the apps division couldn't care less, now filled with people that grown up using UNIX instead of Windows, and see Web UIs everywhere. Hence why Windows might be my main desktop, yet I eventually returned into Web/distributed computing world, disappointed with how UWP/WinRT development turned out. reply likeabatterycar 15 hours agoparentprevThe FSF has turned into the crazy old aunt that insists you unplug the coffee pot after use in case it's bugged. It's taken me a long time to come around to the reality that they are holding Linux back at every juncture, probably still salty over the GNU/drama. Modern TPM support in Linux and systemD now permits automatic disk unlock for LUKS encrypted volumes using a key stored in the TPM - some ~15 years after Windows could do it. I wonder what the TPM support is like in the HURD - ha! The only complaint I have about the TPM is there is no standardisation in connectors, pinout, or bus type when it's not soldered onto the board. I have three motherboards with plug-in TPMs and each required a different, unique part that was difficult to source. reply devops99 1 hour agorootparent> there is no standardisation in connectors, pinout, or bus type when it's not soldered onto the board. I have three motherboards with plug-in TPMs and each required a different, unique part that was difficult to source. This should be prohibited by commercial law. reply devops99 1 hour agorootparentprevWe have had \"FDE\" and secure boot with TPM in higher-than-commercial (defense) and the higher end of commercial settings for Linux, BSD, and illumos since TPM 1.2 was available, and I'd have to dig in some places to confirm but probably before Windows did in actual practice anywhere (let alone officially). Yeah, Debian/Ubuntu, Fedora, etc didn't have this, but as the saying goes: you get what you pay for. Although enough of the Gentoo users (the real Gentoo users) have such a thing had it around that time too, if they wanted it (and they tend to put together what they want). Some essential context: if you think the \"Linux community\" is elitist, wait until you see the niche commercial (and higher) players. I'm probably an example of such, to be fair. reply solarkraft 15 hours agorootparentprevWhile I broadly agree, I think it’s worth pointing out that they have made some compromises for practicality, the inclusion of MP3 software before patents had expired comes to mind. reply PeterStuer 10 hours agoprevBut afaik the TPM (or fTPM if no chip is present) is used to establish and restrict trusted access to the replay-protected memory block that the GPU (or other) DRM chain services depend upon to do their thing. IMHO the author does overrestrictively interpret the FSS statement to discredit them. reply mike_hearn 9 hours agoparentNo, TPM isn't involved with PAVP at any point. Matthew is correct about how it works. This is a typical case where social activists are light years behind the curve and don't really know what they're talking about at all. reply kittikitti 13 hours agoprevIf you go deep enough down the rabbit hole, it becomes very clear why a TPM is necessary. reply anal_reactor 9 hours agoprevAh yes. DRM. 1. Companies offer service that people don't want to pay for, and blame piracy. 2. Someone realizes that they can eliminate piracy and make lots of money by offering good service. 3. Piracy slowly dies, because people prefer €5 monthly subscription over torrent. 4. Other companies catch up. The market gets fragmented. By the nature of the market, it becomes impossible for one company to offer clearly good service. 5. Piracy gets fashionable again because it's more accessible than having twenty €50 subscriptions, half of them with ads. 6. Companies offer service that people don't want to pay for, and blame piracy. reply p0w3n3d 3 hours agoparentyou've nailed it reply cryptonector 12 hours agoprev> Now, TPMs are sometimes referred to as a TEE, and in a way they are. However, they're fixed function - you can't run arbitrary code on the TPM, you only have whatever functionality it provides. But TPMs do have the ability to decrypt data using keys that are tied to the TPM, so isn't this sufficient? Well, no. First, the TPM can't communicate with the GPU. The OS could push encrypted material to it, and it would get plaintext material back. But the entire point of this exercise was to avoid the decrypted version of the stream from ever being visible to the OS, so this would be pointless. And rather more fundamentally, TPMs are slow. I don't think there's a TPM on the market that could decrypt a 1080p stream in realtime, let alone a 4K one. As to the first point... the TPM can't communicate with the GPU, but maybe the GPU could communicate with the TPM. The way that would happen is that the GPU would talk to the TPM directly, using `TPM2_StartAuthSession()` to start an encrypted session with the TPM then it would use `TPM2_ActivateCredential()` or `TPM2_Import()`/`TPM2_Load()`/`TPM2_RSA_Decrypt()` to decrypt a symmetric session key that the GPU would then use to decrypt the stream. I.e., the GPU would do the bulk crypto, but the TPM would do the key transport / key exchange. That also addresses the second point: the TPM being slow is not a big deal because you'd only need it to do something slow once when starting the video playback. Of course, the GPU could just include TPM-like features to get the same effect, which really proves the point which is that: > The FSF's focus on TPMs here is not only technically wrong, it's indicative of a failure to understand what's actually happening in the industry. While the FSF has been focusing on TPMs, GPU vendors have quietly deployed all of this technology without the FSF complaining at all. Microsoft has enthusiastically participated in making hardware DRM on Windows possible, and user freedoms have suffered as a result, but Playready hardware-based DRM works just fine on hardware that doesn't have a TPM and will continue to do so. Pretty much. All the DRM functionality can be in the GPU, and there might not even be a standard API like TPM 2.0 that anyone could use, so the result is even worse than if the GPUs used TPMs to implement DRM. Though, if one were implementing DRM in the GPU or in the display monitor (why not) then the TPM 2.0 MakeCredential/ActivateCredential protocol is a very good fit, so one might as well use that, and even embed a TPM in the GPU and/or the monitor. If you do the bulk decryption in the monitor then the user doesn't even get to screenscrape (eavesdrop on) the connection between the GPU and the monitor. One could even implement just a small portion of TPM 2.0 -- everything needed to establish an encrypted session (`TPM2_CreatePrimary()` and `TPM2_StartAuthSession()`, but also `TPM2_FlushContext()`) and `TPM2_ActivateCredential()`, and maybe a bit more if attestation is required (`TPM2_Quote()` and `TPM2_CreateLoaded()`). What would one attest? I think one would use a platform certificate and its key as the signing key for a TPM2_Quote()-based attestation. The point would be to prove that the device is a legitimate GPU or monitor made by an approved vendor. If you dislike DRM then TPMs are not the enemy. Particularly the TPM on any server or laptop is not the enemy. TPMs in GPUs or monitors might be, but Windows 11 requiring a TPM on the box has nothing to do with that, and again, the GPU/monitor could implement the ActivateCredential protocol internally w/o a TPM anyways. reply mjg59 12 hours agoparentHow would the GPU verify it's speaking to a real TPM? You'd need to bake the full set of legitimate EK cert CAs into it somehow (charitably let's say that's a signed blob that the driver pushes in at startup), but that's still going to be a terrible user experience because you won't get media playback if your machine has a TPM that's too new or from too niche a vendor. reply cryptonector 3 hours agorootparent> How would the GPU verify it's speaking to a real TPM? Option 1: as I said, the GPU could have its own, and yes in that case the EK cert would be known to the GPU (or it could have a platform-like cert issued by the GPU OEM). Option 2: the platform vendor can teach the GPU the EK cert (or the public key for some primary key anyways). Option 3: the GPU could learn it on first use. > charitably let's say that's a signed blob that the driver pushes in at startup That's what TPM vendors do as to the EK cert. Surely if they can do that then so can GPU and platform vendors. Indeed, some platform vendors ship with platform certs. > but that's still going to be a terrible user experience because you won't get media playback if your machine has a TPM that's too new or . What do you mean \"too new\"? Like, you replaced your TPM? That's a thing on servers, but not laptops. As to \"from too niche a vendor\", as long as the platform vendor teaches the GPU what the EK cert is, or makes a platform-like cert that the GPU can use to authenticate the TPM, then it's good enough. Anyways I suspect that MSFT and others don't mind an incrementalist approach. You have a system that can do it their way? Great, it will. You have a system that cannot do it their way? Fine, they'll do weak software DRM for now. There's probably no other way to to get to their dream DRM everywhere state. reply mike_hearn 8 hours agorootparentprevRight, and more to the point there's nothing special about a TPM design-wise. It's actually a very odd kind of chip that only really exists due to the unique political and market requirements of the PC industry. If you look at vertically integrated platforms like Apple's, or the games consoles, or smartphones, there's no TPM. There are subsystems that do similar things, but none of them follow the TPM design specs. Even Intel abandoned it when designing SGX. SGX doesn't involve a TPM at any point. So for a GPU vendor there's no reason to introduce the additional complexity of handshaking with a TPM. Blowing a private key into some eFuses at the factory is relatively easy, add a RAM encryption engine on top and you're already providing better security than what a TPM provides. reply cryptonector 3 hours agorootparentTPM is a missed opportunity. What I really want for security is a solid secure enclave scheme on the CPU itself so my SE code can blaze. The TPM is not programmable and is very limited, both in terms of its API and in terms of its capabilities (e.g., number of keys loaded, number of algorithms supported, ...) and in terms of its performance. My point in my above reply was to say that even if TPMs were used by GPUs then TFA's point would still stand. reply mike_hearn 2 hours agorootparentDespite the bad press it's received over the years, SGX is a very solid design and works pretty well. Some of the papers presenting breaks turned out to be quite misleading when I looked closely at them some years ago. If you want a general purpose TEE then you could do worse than play with it. Unfortunately it's not available on consumer hardware anymore, and in the cloud only Azure really supports it AFAIK. And you have to write apps for it specifically, and then you have to have clients that know how to do remote attestation and bind it to secure channels, and you have to program in a threat model in which rewinds are possible at any moment. This is very hard, and it turns out most people in the market don't really care about their data that much (are happy to share it with trustworthy institutions). So it never really took off. But the tech is decent. reply cryptonector 1 hour agorootparentAmazon has their Nitro secure enclave system that's pretty easy to use. IIUC its based on isolating the code that runs it and in it onto one core set aside for just that, possibly just when it's needed. Having the SE be easy to use is a key thing. Not that the Nitro approach extends well to consumer hardware (it doesn't). reply zb3 15 hours agoprev> GPU vendors have quietly deployed all of this technology Citation or technical details needed. Obviously it \"makes sense\" that for 4K HD content you \"probably\" want to offload the decoding into the GPU, but this is the first time I see this mentioned and there are no links to technical details. In contrast, TEE / TrustZone and even the recent AVF with pVM - these are well documented technologies. reply mjg59 15 hours agoparentThe Playready docs make it clear the implementation is either in TEE or implemented in GPU hardware, and x86 has no TEE, so. You can easily find driver changelogs describing it being enabled for different hardware generations. reply bri3d 15 hours agorootparent> x86 has no TEE Not really; AMD have PSP (which, okay, isn’t x86, but it’s on the die) and Intel, as you mention in your post, had SGX and have ME. Google use PSP TrustZone to run Widevine on Chromebooks, for example. PowerDVD used SGX to decrypt BluRay, which led to BluRay 4K content keys being extracted via the sgx.fail exploit. You’re right though that PlayReady is usually GPU based on x86; on AMD GPUs PlayReady runs in GPU PSP TrustZone. On Intel iGPUs I think it runs in ME. The lower-trust (1080p only) software version of PlayReady uses WarBird (Microsoft’s obfuscating compiler) but this is of course fundamentally weak and definitely bypassed. Anyway, none of this takes away from your post, which I agree with. The FSF (and many HN commenters) have been whining about TPM in unfounded ways since the 2000s. reply mjg59 14 hours agorootparentMy fault, I meant x86 has no architectural TEE - various vendors offer their own weird things. But thanks, this is good clarification. reply transpute 15 hours agorootparentprev> x86 has no TEE Is Intel ME TEE-enough for DRM? reply mjg59 15 hours agorootparentNot in general, Intel briefly had a program for allowing vendors to deploy apps on ME but closed it years ago. But yes, ME is involved in this for Intel iGPU. reply wmf 14 hours agoparentprevhttps://en.wikipedia.org/wiki/Protected_Media_Path https://learn.microsoft.com/en-us/windows/win32/medfound/pro... reply p_l 14 hours agoparentprevIt was a big deal when Vista was released, with coincided with a lot of generational change in home computers (Watching Blu-Ray on computer still seemed to be a thing to expect, HDMI with HDCP was introduced, etc). There was a lot of talk about protected media path in Vista, how it linked with HDCP, how it killed hardware accelerated audio (including causing considerable death blow to promises made by OpenAL), etc. reply pjmlp 10 hours agorootparentEven game consoles moved into software accelerated audio, as it turns out doing it in software, with CPU vector instructions is fast enough, while being more flexible. This is also the way of the future for graphics, do way with any kind of hardware pipelines, and go back to software rendering, but having it accelerated on the GPU, as general purpose accelerator device. reply p_l 8 hours agorootparentEAX and the like were actually that - software components running on DSP inside sound card, and it was supposed that they would be something you would handle in the future akin to how GPUs are programmed. However while audio accelerators came back the protected media path business means they aren't \"generally programmable\" from major OS APIs even when both AMD and Intel essentially ended up settling on common architecture including ISA (Xtensa w/ DSP extensions, iirc), and are mainly handled through device specific blobs with occassional special features (like sonar style presence detection) reply kalleboo 10 hours agorootparentprevAnd Steve Jobs famously described it as a \"bag of hurt\" reply bri3d 15 hours agoparentprevAMD GPUs have a PSP that’s the same as the CPU one: an embedded ARM-Cortex A5 with TrustZone. reply zb3 15 hours agoparentprevIntegrated GPUs exist. Wouldn't it make more sense that the \"high value\" content should not be exposed to any external GPU? Then we can treat those integrated ones as part of the \"TEE\". That's my speculation, waiting for details. reply saxonww 15 hours agorootparentThis is the question I had about this. The reason this design works per the article is that the GPU memory is inaccessible to the OS, so the decrypted content cannot be stolen. With a unified memory architecture, is the shared GPU memory inaccessible to the CPU? reply tuetuopay 1 hour agorootparentWith the proper MMU settings, yes, the CPU can definitely be denied access to some memory area. This is why devices like the raspberry pi have that weird boot process (the GPU boots up, then brings up the CPU), it's a direct consequence from the SoC's set-top-box lineage. reply __m 3 hours agorootparentprevThe GPU ultimately has to output unencrypted content, it will always be possible to steal unless we manage to implement drm in human eyes reply mjg59 14 hours agorootparentprevYes, the memory controller can simply deny accesses to specific areas from the CPU while still permitting them from the GPU. reply wmf 14 hours agorootparentprevYou can't give a worse experience to people who paid more for a better GPU. reply shmerl 16 hours agoprevDMCA 1201 should be reversed and DRM itself should be illegal. reply CamperBob2 16 hours agoparentDRM shouldn't be illegal, but works protected by DRM should be ineligible for copyright protection unless a key is placed in escrow somewhere. Basically, rightsholders should be be able to choose enforceable legal protection or unbreakable technological protection, but not both. Copyright was supposed to be a two-way street, but DRM permanently barricades one lane. reply snvzz 8 hours agorootparent>should be be able to choose enforceable legal protection or unbreakable technological protection No. The latter would effectively mean rightsholders make their own laws, rather than follow the law. DRM should simply be abolished, as it interferes with the premise of copyright: To grow the public domain. reply p0w3n3d 3 hours agorootparentyeah, 105 years later we finally have a disney's a mickey mouse, but they still put the ears in every gadget to prolong it as a trademark. TBH I can see now how the conglomerates created by buying smaller studios by big fish start owning everything. They've divided the market by themselves, and now they are rising their prices. Meanwhile I cannot make a screenshot of my favourite cartoon to create a meme, because of \"copy protection\". But I have right to do it you now? It's written in law in my country (Poland) that I can have small pieces recorded down, screenshotted etc, as long as I am doing some creative work on it, or just keep it to myself. THIS IS THE LAW HERE. And it's being ignored. reply shmerl 15 hours agorootparentprevThat makes some sense, I'd say using DRM should void copyright completely, keys or not. I.e. if they want to go out of the way with invasive anti-user measures, they should lose any legal protection against copying of that stuff. It should also drive home the idea that DRM will be broken anyway and they'll be just left with nothing, so let them stick to copyright itself without all that DRM garbage. reply osy 15 hours agoprev> I'm going to be honest here and say that I don't know what Microsoft's actual motivation for requiring a TPM in Windows 11 is. It is quite obvious: to force people to buy a new PC. TPM provides no added security value for the vast majority of users[1] but it is a convenient hardware that has only started to become standard (fTPM) in PCs built in the last ~8 years so it provides an excuse for Microsoft to declare computers older than that (which can run Windows 10) obsolete using \"security\" as an easy scapegoat. [1]: https://gist.github.com/osy/45e612345376a65c56d0678834535166 reply p_ing 14 hours agoparent> TPM provides no added security value for the vast majority of users[1] Yes it does. The vast majority of users aren't going to have their laptop stolen by the CIA/NSA and have their DIMMs popped and cryofreezed. The vast majority of users aren't going to have the case opened and a special-purpose PCIe device installed to steal keys over DMA. The vast majority of users aren't going to have a dTPM vulnerable to SPI sniffing as modern and not-so-modern processors have fTPM. This is to provide some baseline level of protection of the user's data against theft and loss. Are there attacks against TPM? Yep. In as much as there are attacks against SMS 2FA, but for the vast majority of people, SMS 2FA is an acceptable level of security. If you're a CEO, well sure, you're going to want to do something better (TPM + PIN). I acknowledge that Windows 11 Home users don't have this specific option. Everyone needs to level set on the type of attacks that are practical vs. involved and who the targets of those attacks are. FDE (w/ TPM) is part of defense-in-depth. Even if imperfect, it's another layer of protection. reply AnthonyMouse 14 hours agorootparent> The vast majority of users aren't going to have their laptop stolen by the CIA/NSA and have their DIMMs popped and cryofreezed. That's kind of the point. The vast majority of users aren't going to have their laptop stolen at all, if they do it will 99% of the time be by someone who only wants to wipe it and fence it, and attempts to access data are most likely to be by unsophisticated family members who would be defeated by a simple password without any TPM. Meanwhile there have been plenty of TPM vulnerabilities that don't require anything so esoteric and can often be attacked purely from software, so if a normal user was facing even so much as someone willing to watch some security conference talks, they're going to lose regardless. If the TPM doesn't make them more vulnerable to that, because it contains the secrets and is susceptible to attack, vs. FDE with a boot key stored in some cloud service secured with the user's password instead of a TPM, which can then rate limit attempts without being susceptible to physical access attacks and be revoked if the device is stolen. Moreover, the more common threat to normal users is data loss, in which case you only want your laptop to be secure against your unsophisticated nephew and not the tech you want to recover your data after you forget your password. > In as much as there are attacks against SMS 2FA, but for the vast majority of people, SMS 2FA is an acceptable level of security. The current recommendation seems to be against SMS 2FA because the security of SMS really is that bad, so if you need 2FA, use an authenticator app or similar. > FDE (w/ TPM) is part of defense-in-depth. Any snake oil can be painted as defense-in-depth. reply devops99 34 minutes agorootparent> vs. FDE with a boot key stored in some cloud service secured with the user's password instead of a TPM Without secure boot (backed by TPM), I can boot a small USB device that has LEDs on it to indicate to me that the target system has been infected to send me a copy of the target's password, after I already imaged the disk (or when I have another team member steal it or take it by force later). If there's a UEFI password to access UEFI settings, I can reset it in under 20 minutes with physical access. Some tamper-evident tape on the laptop casing may stop me if I haven't already had a resource intrude into the target's home/office to have some replacement tamper-evident sticker material ready. Very very few places, even some really smart ones, make use tamper-evident material. Glitter+glue tamper-evident seals are something I can't spoof though. It's not that hard to get into a hotel room. Often enough if a business books a hotel for you it's because they want access to your laptop while you're at lunch with another employee who so kindly suggests to leave your backpack in the hotel room. disclaimer: all above is fictional and for educational and entertainment purposes only reply wkat4242 10 hours agorootparentprev> That's kind of the point. The vast majority of users aren't going to have their laptop stolen at all, if they do it will 99% of the time be by someone who only wants to wipe it and fence it, and attempts to access data are most likely to be by unsophisticated family members who would be defeated by a simple password without any TPM. True, any preboot password method (even fully software) will be sufficient to prevent data exposure when a laptop is stolen. The whole TPM + secure boot thing is more to prevent evil maid attacks where a laptop is messed with (eg installing a bootloader that intercepts the password) and then placing it back in the user's possession so they can be tricked into entering the password. That whole scenario is extremely far-fetched for home users. Laptops get stolen but then they're gone. reply sidewndr46 5 hours agorootparentBut it doesn't even do that. If I want to perform the \"evil maid\" attack why would I screw around with the bootloader? I'm just going to replace the entire device with something that captures the password & sends it to me remotely. reply wkat4242 4 hours agorootparentYou could but the user might notice. Most business laptops don't exactly look like new. I would very likely notice. reply p_ing 5 hours agorootparentprevI'm not groking what you're saying. Replace what \"entire device\"? reply sidewndr46 4 hours agorootparentYou're at an industry conference. I want the data on your laptop's hard drive. You leave your laptop in the hotel room. Which one is easier: 1. Go into your room and screw around with the boot loader to somehow give me unencrypted access to your laptop after you login next time. 2. Go into your room. Take your laptop. Put an identical looking laptop in place that runs software that boots and looks identical. Have it send me all of your password attempts over WiFi to my van in the parking lot. I'm going with option 2 every time. I have your original device. I have your password. TPM, SecureBoot, or whatever is irrelevant at this point. reply buran77 4 hours agorootparentThe attacker must be able to fake any pre-boot drive unlock screen and OS login screen to look exactly as the user's real screens but accept any password. Legend goes that security oriented people will visually customize their machines with stickers (and their associated aging patina) and all kinds of digital cues on the different screens just to recognize if anything was changed. MS chose to impose TPM because it allows encryption without interactive password typing (BitLocker without PIN or password which is what most machines are running). That's it. The users get all the convenience of not having to type extra passwords when the machine starts, and some (not all) of the security offered by encryption. Some curious thief can't just pop your drive into their machine and check for nudes. The TPM is not there to protect against NSA, or proverbial $5 wrench attacks but as a thick layer of convenience over the thinner layer of security. reply Topfi 4 hours agorootparent> Legend goes that security oriented people will visually customize their machines with stickers (and their associated aging patina) and all kinds of digital cues on the different screens just to recognize if anything was changed. Maybe I am mistaken, but I feel that the people going to such lengths to ward off an attacker and the people who’d want to rely on fTPM with Bitlocker over FOSS full disk encryption with a dedicated passphrase are two entirely separate circles. > The TPM is not there to protect against NSA, or proverbial $5 wrench attacks but as a thick layer of convenience over the thinner layer of security. I agree with you there, it is convenience, not security, but as such, should it be any more mandatory than any other convenience feature such as Windows Hello via fingerprint or IR? I’d argue only for newly released hardware, but don’t make that mandatory for existing systems. Especially since I had one case where fTPM was not recognized, no matter what I did, despite it being enabled in the UEFI and showing up in Windows 10 and on Linux, I could not install 11. reply buran77 2 hours agorootparent> the people going to such lengths to ward off an attacker and the people who’d want to rely on fTPM with Bitlocker over FOSS full disk encryption with a dedicated passphrase are two entirely separate circles. Bitlocker + PIN/password (hence my mention of a pre-boot password) is a good combination that isn't any worse than any \"FOSS full disk encryption\". Beyond the catchy titles of \"Bitlocker hacked in 30s\" is the reality that it takes just as many seconds to make it (to my knowledge) unhackable by setting a PIN or password. Adding the (f)TPM improves the security because you don't just encrypt the data, you also tie it to that TPM, and can enforce TPM policies to place some limits on the decryption attempts. > it is convenience, not security It's convenience and (some) security by default. Not great security but good enough for most of those millions of Windows users. The security was the mandatory part, encrypting the storage by default. The convenience was added on top to get the buy-in for the security, otherwise people would complain or worse, disable the encryption. Whoever wants to remove that convenience and turn it into great security sets a PIN. reply happymellon 4 hours agorootparentprevPasswords are generally defeated by a hammer to the fingers. Repeat until password is extracted. reply devops99 32 minutes agorootparentYour hammer is preempted by a teethed hollow point bullet to the face (in the hypothetical scenario, of course). reply ta1243 3 hours agorootparentprevKnees probably better -- break my fingers and I can't give you my password reply happymellon 3 hours agorootparentI didn't break your jaw, so you can still communicate. Point taken though, start with the toes, it gives you more to work with if you have to progress up the leg. reply ta1243 2 hours agorootparentI don't know what my computer's password is, it's muscle memory reply hiatus 2 hours agorootparentprevHave you been to an industry conference? So many laptops are covered in stickers, good luck recreating that. reply hathawsh 1 hour agorootparentI don't mean to disagree, but I think it's worth pointing out that with today's tech, it wouldn't be difficult for an attacker to also scan the stickers and print them out on sticker paper using a color printer, all in minutes. And the technology for doing that is only getting better. Just a thought. reply XorNot 10 hours agorootparentprevNo one wants a preboot password though. TPM means the system can boot and then do face login or whatever using the user's password in exactly one place. This is as much as most users will tolerate. And it also means Microsoft account recovery can work to unlock a forgotten password. The whole point is Microsoft don't want user devices to ever be trivially bypassed, regardless of how unlikely that is (probably more likely then you think though). These things are everywhere: they're used by small businesses, unsophisticated users etc. but the story which will be written if anything happens because the disk was imaged sometime will be \"how this small business lost everything because of a stolen Windows laptop\" and include a quote about how it wouldn't have happened on a MacBook. reply mjw_byrne 9 hours agorootparent\"No one wants a preboot password though\" - really? Doesn't strike me as particularly inconvenient, especially given the relative rarity of actual bootups these days. I've been using bog-standard FDE for as long as I can remember. One extra password entry per bootup for almost-perfect security seems like great value to me. reply zinekeller 7 hours agorootparentIt seems that you're looking at the wrong bubble here. Most people actually detests passwords and would rather use a different method if possible (this is why ordinary users turn on biometric authentication despite some here questioning its security). Adding another password will certainly make users - especially enterprises - complain. Also for technical reasons, Windows can't do the fancy one login/password screen (which assumes a file-level encryption, which is how it is implemented nowadays to support multiple users [1] [2]). This is due to Windows software that are expecting that everything is an ordinary file (unlike Apple which don't care on that aspect and Android which has compartmentalized storage). Even if we have an EFS-style encryption here, it will be incompatible with enterprise authentication solutions. 1: https://support.apple.com/guide/security/encryption-and-data... 2: https://source.android.com/docs/security/features/encryption reply hansvm 2 hours agorootparent> this is why ordinary users turn on biometric authentication despite some here questioning its security That's part of the reason. Another part is BigCo spamming the users asking for biometrics or whatever the current promotion-driver is, making opting out hard to find, and using their position of authority to assert that it's \"more secure\" (for your personal threat model no less, nice to be able to offload thought to a corporation). reply devops99 29 minutes agorootparentprevThe more inexpensive option of the newer Trezor wallets and \"login PIN\" as an optional alternative to a password that also works, seems to be the best option (that I have seen so far). The more recently released Trezor wallets are still new, and Yubikey 5C will probably be used in many places anyway just because of the keyring and no need for the usb-c cable. reply whatevaa 6 hours agorootparentprevAbsolutely. You are an exception. Get your head outside and look around you instead of assuming. reply wkat4242 8 hours agorootparentprevEvery phone has it these days.",
    "originSummary": [],
    "commentSummary": [
      "The core of hardware Digital Rights Management (DRM) is associated with Graphics Processing Units (GPUs) rather than Trusted Platform Modules (TPMs), with media DRM currently linked to GPU vendors.",
      "DRM's long-term goal may be to exert total control over devices, potentially impacting software like adblockers, raising concerns about the future of personal computing.",
      "The Free Software Foundation (FSF) may be misdirected in focusing on TPMs, as GPU vendors have already integrated DRM technology, highlighting the need for legislative intervention to protect user rights."
    ],
    "points": 346,
    "commentCount": 325,
    "retryCount": 0,
    "time": 1735783785
  },
  {
    "id": 42572057,
    "title": "Zasper: A Modern and Efficient Alternative to JupyterLab, Built in Go",
    "originLink": "https://github.com/zasper-io/zasper",
    "originBody": "⚡ High Performance IDE 🚀 Massive concurrency 🐥 Inspired by Jupyter Zasper is an IDE designed from the ground up to support massive concurrency. It provides a minimal memory footprint, exceptional speed, and the ability to handle numerous concurrent connections. It's perfectly suited for running REPL-style data applications, with Jupyter notebooks being one example. Currently Zasper is fully supported on Mac with limited support on Linux. Benchmarks - 4X Better Zasper uses one fourth of RAM and one fourth of CPU used by Jupterlab. While Jupyterlab uses around 104.8 MB of RAM and 0.8 CPUs, Zasper uses 26.7 MB of RAM and 0.2 CPUs. Why I built Zasper ? There are several proprietary JupyterLab-like frontend tools available in the market, such as Databricks Notebooks and Deepnote Notebooks. However, none of them are free or open-source, and most require users to work in the cloud. Even the modest personal computers these days are typically equipped with at least 8 GB of RAM, an 8-core CPU, and a decent 4 GB GPU, I saw an opportunity to create a solution that works seamlessly on local machines. That’s why I decided to build Zasper which can effectively utilize the resources available and guarantee maximum efficiency. Originally I wrote https://github.com/zasper-io/zasper_py (now in Private mode) to build a new frontend around Jupyter. During the process I realized, Go is the ideal choice to rebuild the Jupyter project. Go has excellent support for REST, RPC, WS protocols. Concurrency and Performance are the areas where Go shines. Go's Concurrency: Better suited for applications requiring both concurrency and parallelism, as it leverages multiple cores effectively. It's easier to handle blocking operations without freezing the system. Python's Event Loop: Ideal for I/O-bound applications that need to handle a lot of asynchronous tasks without blocking. However, it struggles with CPU-bound tasks and lacks native parallelism unless additional worker threads are used. Hence the Go version of Zasper was born! 📷 Screenshots Editor Terminal Launcher Jupyter Notebook Version Control Command Palette Dark Mode Architecture ⚡ Quick start Zasper comes in two flavours: Electron App Web App Electron App Install zeromq On debian sudo apt-get install libzmq3-dev On mac brew install pkg-config brew install zeromq Go to project home and start the server go build -o ui/public/zasper Go to ui and run the app in dev mode npm run electron-dev # dev-mode npm run electron-package # prod-mode Webapp Build the frontend cd ./ui/ npm run build Install zeromq On debian sudo apt-get install libzmq3-dev On mac brew install pkg-config brew install zeromq Start the backend Install zeromq. Go to project home and start the server go build -tags webapp This will crate a binary called zasper. Now add this binary to your path. Run zasper in any directory to see if the installation was done correctly. % zasper -h Usage of ../zasper: -cwd stringbase directory of project (default \".\") -debugsets log level to debug -port stringport to start the server on (default \":8888\") Go to any directory you want to serve and run zasper. This starts zasper server in the directory. % zasper 2024/12/15 20:39:12 Zasper Server started! Listening on port:8888 ███████╗ █████╗ ███████╗██████╗ ███████╗██████╗ ╚══███╔╝██╔══██╗██╔════╝██╔══██╗██╔════╝██╔══██╗ ███╔╝ ███████║███████╗██████╔╝█████╗ ██████╔╝ ███╔╝ ██╔══██║╚════██║██╔═══╝ ██╔══╝ ██╔══██╗ ███████╗██║ ██║███████║██║ ███████╗██║ ██║ ╚══════╝╚═╝ ╚═╝╚══════╝╚═╝ ╚══════╝╚═╝ ╚═╝ Go to http://localhost:8888 Logging By default, the application writes logs to the following locations: on Linux: ~/.config/zasper/logs/main.log on macOS: ~/Library/Logs/zasper/main.log on Windows: %USERPROFILE%\\AppData\\Roaming\\zasper\\logs\\main.log Wiki For Zasper architecture, and other info refer wiki. Contributing You can contribute in multiple ways: Documentation Bug Filing Submitting PRs or reviewing them Code of Conduct See Code of conduct Roadmap Data Scientists and AI Engineers spend most of their time running Notebooks on IDEs and hence need a robust ecosystem. Zasper aspires to be a full fledged IDE and the future development will be along making it more efficient by: Allowing custom data apps support rather than just Jupyter Notebooks. Easier integration with the existing tools. Zasper Hub for Self Hosted deployment in the cloud. Copyright Prasun Anand ⚖ License Zasper is licensed under AGPL-3.0 license.",
    "commentLink": "https://news.ycombinator.com/item?id=42572057",
    "commentBody": "Zasper: A Modern and Efficient Alternative to JupyterLab, Built in Go (github.com/zasper-io)338 points by thunderbong 13 hours agohidepastfavorite79 comments prasunanand 10 hours agoI am the author of Zasper. The unique feature of Zasper is that the Jupyter kernel handling is built with Go coroutines and is far superior to how it's done by JupyterLab in Python. Zasper uses one fourth of RAM and one fourth of CPU used by Jupterlab. While Jupyterlab uses around 104.8 MB of RAM and 0.8 CPUs, Zasper uses 26.7 MB of RAM and 0.2 CPUs. Other features like Search are slow because they are not refined. I am building it alone fulltime and this is just the first draft. Improvements will come for sure in the near future. I hope you liked the first draft. reply carreau 9 hours agoparentIPython maintainer and Jupyter dev (even if I barely touch frontend stuff these days). Happy to see diversity, keep up the good work and happy new year. Feel free to open issues upstream if you find lack of documentation or issue with protocol. You can also try to reach to jupyter media strategy team, maybe they'll be open to have a blog post about this on blog.jupyter.org reply szvsw 4 hours agorootparentI’m not adding a lot to the conversation, but it’s not often you run into someone who contributes to creating a tool so fundamental to your daily life, career, growth as a researcher etc, so let me just take the opportunity to say: thank you and the rest of your team for creating such an amazing interactive tool. reply prasunanand 9 hours agorootparentprevThanks @carreau. I think the documentation is amazing! Zasper is built on the great work and documentation from Jupyter team. I will reach out to Jupyter media strategy team. reply BiteCode_dev 9 hours agorootparentprevThat's stellar sportmanship right there. Not that jupyter's team needed even more respect from the community but damn. reply carreau 9 hours agorootparentI think that's fairly normal, having alternative frontends can only be beneficial to the community. I know it also look like there is a single Jupyter team, but the project is quite large, there are a lot of constraints and disagreements internally and there is not way to accomodate all users in the default jupyter install. Alternative are always welcome ; at least if they don't fragment the ecosystem by being not backward compatible with the default. Also to be fair I'm also one of the Jupyter dev that agree with many points of OP, and would have pulled it into a different direction; but regardldess I will still support people wanting to go in a different direction than mine. reply BiteCode_dev 8 hours agorootparentThe last paragraph let me think your normal is particularly collaborative lol. reply dleeftink 4 hours agorootparentprev> Alternative are always welcome; at least if they don't fragment the ecosystem by being not backward compatible with the default. Genuinely curious; what mechanisms has Jupyter introduced to prevent ecosystem fragmentation? reply williamstein 2 hours agorootparentThe Jupyter community maintains a public spec of the notebook file format [1], the kernel protocol [2], etc. I have been involved with many alternative Jupyter clients, and having these specs combined with a friendly and welcoming community is incredibly helpful!!! [1] https://github.com/jupyter/nbformat [2] https://jupyter-client.readthedocs.io/en/latest/messaging.ht... reply westurner 1 hour agorootparentjupyter-server/enterprise_gateway: https://github.com/jupyter-server/enterprise_gateway JupyterLab supports Lumino and React widgets. Jupyter Notebook was built on jQuery, but Notebook is now forked from JupyterLab and there's NbClassic. Breaking the notebook extension API from Notebook to Lab unfortunately caused re-work for progress, as I recall. jupyter-xeus/xeus is an \"Implementation of the Jupyter kernel protocol in C++* https://github.com/jupyter-xeus/xeus jupyter-xeus/xeus-python is a \"Jupyter kernel for the Python programming language\"* that's also what JupyterLite runs in WASM instead of ipykernel: https://github.com/jupyter-xeus/xeus-python#what-are-the-adv... JupyterLite kernels normally run in WASM; which they are compiled to by emscripten / LLVM. To also host WASM kernels in a go process, I just found: going: https://github.com/fizx/goingo .. https://news.ycombinator.com/item?id=26159440 Vscode and vscode.dev support wasm container runtimes now; so the Python kernel runs in WASM runs in a WASM container runs in vscode FWIU. Vscode supports polyglot notebooks that run multiple kernels, like \"vatlab/sos-notebook\" and \"minrk/allthekernels\". Defining how to share variables between kernels is the more unsolved part AFAIU. E.g. Arrow has bindings for zero-copy sharing in multiple languages. Cocalc, Zeppelin, Marimo notebook, Data Bricks, Google Colaboratory (Colab tools), and VSCode have different takes on notebooks with I/O in JSON. There is no CDATA in HTML5; so HTML within an HTML based notebook format would need to escape encode binary data in cell output, too. But the notebook format is not a packaging format. So, for reproducibility of (polyglot) notebooks there must also be a requirements.txt or an environment.yml to indicate the version+platform of each dependency in Python and other languages. repo2docker (and repo2podman) build containers by installing packages according to the first requirements .txt or environment.yml it finds according to REES Reproducible Execution Environment Standard. repo2docker includes a recent version of jupyterlab in the container. JupyterLab does not default to HTTPS with an LetsEncrypt self-signed cert but probably should, because Jupyter is a shell that can run commands as the user that owns the Jupyter kernel process. MoSH is another way to run a web-based remote terminal. Jupyter terminal is not built on MoSH Mobile Shell. jupyterlab/jupyter-collaboration for real time collaboration is based on the yjs/yjs CRDT. https://github.com/jupyterlab/jupyter-collaboration Cocalc's Time Slider tracks revisions to all files in a project; including latex manuscripts (for ArXiV), which - with Computer Modern fonts and two columns - are the typical output of scholarly collaboration on a ScholarlyArticle. reply zelphirkalt 7 hours agoparentprevThe actual RAM issue is another one. Every Python kernel you start consumes around 100-150MB RAM. So unless you are starting different kernels using Zasper, the majority of RAM usage is still going to be the same. reply shwouchk 4 hours agoparentprevHello and thank you for making this! Can I sway you to take this into a ... certain direction? From my POV any browser based editor will be inferior to emacs (and to lesser extent vim) simply because it won't run my elisp code. While a fresh and snappier UI compared to eg jupyter would be nice, I would love to see something that integrates well with emacs out of the box. So, perhaps it would be really nice if the backend+API was really polished as an end product itself in such a way that it could easily interface with other frontends, with remote attachment. I could go on with my list of demands but I would be thrilled and amazed at my luck if even those two happen... reply d0mine 6 minutes agorootparentHave you tried https://github.com/emacs-jupyter/jupyter Eg as org-mode code blocks. reply spudlyo 3 hours agorootparentprevI'm curious what your thoughts on are on emacs-jupyter[0] which seems to integrate reasonably well with Org mode. I have some complaints about how it has to handle output blocks, but otherwise it seems like a great way for Emacs to act as a frontend to a Jupyter kernel. [0]: https://github.com/emacs-jupyter/jupyter reply zitterbewegung 3 hours agorootparentprevThere already is a library that can interface emacs with Juypter it is called ein. I think what you really want is a kernel that executes emacs code and if you did make that kernel it would probably work in any of these systems. See https://github.com/emacs-jupyter/jupyter reply shwouchk 2 hours agorootparentYes, I'm aware of EIN. To start, it's been abandoned by it's author/maintainer as of April 2024 IIRC. Further, I do not need a kernel to execute emacs code - I have one and it's called emacs. The point regarding executing elisp code was a cheeky way to state that I am not looking forward to finding replacement and/or porting of all the custom code - mine and others' - that my editor runs, and that no amount of \"features\" from a webui editor will ever replace that. Hence I also mentioned vim since over time it got customized for me as well and I wouldn't want to port that either. Nor the convenience of the terminal, which is what vim is for. Putting that aside as with all respect and gratitude to the author, it was rather clunky in many respects - no interactive story, poor handling of sessions and remote kernels (have you tried to start one, disconnect and reconnect?), no integration with LSP, and lack of many many more features that /could/ be made. I don't know how much use you make of jupyter kernels or mathematica notebooks or similar technologies, but in my case I explored the available landcape quite thoroughly and regularly revisit. I know what I'm looking for and EIN is/was not it. [EDIT] I just noticed you mentioned EIN but linked to emacs-jupyer. Used that as well, of course. Ill add a bit more detail to that in sibling reply Demiurge 3 hours agorootparentprevDid somebody say eMacs? I dunno, I think VI integration could be more important. reply shwouchk 2 hours agorootparentI mentioned vim as well and generally proposed something that would be editor agnostic. Shoo! back to your cave. reply pplonski86 9 hours agoparentprevCongratulations on the launch! It's great to see alternatives to Jupyter. JupyterLab is an excellent, however creating editor for broad audience is challenging. I've found Jupyter difficult to use, especially for beginners. Managing kernels, Python environments, and installing new packages can be quite cumbersome. Are you planning to address these challenges in Zasper? reply prasunanand 9 hours agorootparentYeah, I will work on these problems and I already have solutions in mind. Just wanted to get the word out about the project first and see if the world actually needs something like Zasper. I am really happy to see the welcoming response from the dev community. reply dist-epoch 8 hours agorootparentprevHave you tried the Jupyter desktop app? It's more self-contained. reply pplonski86 7 hours agorootparentYes, I tried Jupyter Desktop. It is fantastic, I like that you can double click on notebook file to open app. However, it might be a little to complicated for beginners, you need to setup Python and select kernels. That's too much. reply Panoramix 4 hours agorootparentPeople can program in python but cannot select a kernel from a list? I find that hard to believe reply jerf 3 hours agorootparentI mean this without rancor or insult, but a lot of data scientists may use Python, but are definitely not Python programmers. They know the subset of Python necessary to process data, and literally not one bit more. They would have no idea how to create an iterator function, their own \"with\" handler, may not even know how to create a new subclass with a method. They just take data in, chew on it, and spit it out. Again, not an insult intended to them. They have their job and they do it, and I don't know much about their world either, after all. And of course you can find some data scientists who also deeply know Python. My point is merely that modeling them all generically as \"Python programmers\" in your head can lead to a model that makes bad predictions, which I found in my brief stint in that world can include you building tools for them that expect more out of them than they have. reply _venkatasg 2 hours agoparentprevJust wanna say this is a really cool project, and I can't think of higher praise than me hoping I build something as cool as this some day! I've been meaning to learn Go for sometime now, and will be referring to Zasper for the future :) reply tudorizer 8 hours agoparentprevOn a quick glance, it seems it's possible to run this as a service similar to JupyterLab, right? I'd be keen to offer it as an alternative to Jupyter on my little GPU platform experiment. reply filmor 2 hours agoparentprevIt currently hard-codes launching ipykernel, right? reply klooney 5 hours agoparentprevHow was your experience working with 0mq? reply crabbone 2 hours agoparentprevI'm not directly involved with extending Jupyter Lab, but I'm involved with the results (and testing) of our extension on the daily basis. What I find very often to be the source of complaints is the error reporting. In particular, the kind of error reporting that just disappears from the screen after few seconds. If there's one singular feature of Jupyter Lab that I really want changed, it's this. reply petre 5 hours agoparentprevDoes it have a Racket kernel yet? I love using Racket for notebooks in Jupyter, but the UI is just too slow. reply niyyou 8 hours agoprevIt's probably an unrelated post (apologies in advance) but I wanted to shoutout to the Marimo (https://marimo.io), it's the only Jupyter alternative that really got me excited, it's like Streamlit and Jupyter had a kid (and the kid took the best genes from both). reply CraigJPerry 6 hours agoparent>> marimo notebooks are pure Python and stored as .py files That sounds like a solid improvement. I’m going to give this a test drive. I feel like modularity is one of the hardest aspects of Jupyter notebooks in a team environment. I’d be interested to hear if anyone has cracked a workflow with notebooks for larger teams. Notebooks are easy for solo or very small teams, and the literate programming style benefits still apply in larger teams but there’s a lot of friction: “hey just %run this shared notebook with a bunch of useful utilities in it - oops yeah it tries to write some files because of some stuff unrelated to your use case in there (that’s essential to my use case)” My current best that I know of is to keep “calculation” (pure) code in a .py and just the “action“ (side-effectful) code in the notebook. Then as far as physically possible, keep the data outside of notebook (usually a database or csv’s). That helps avoid the main time sink pitfalls (resolving git conflicts, versioning, testing etc) but it doesn’t solve for example tooling you might want to run - maybe mypy against that action code - sure you can use nbqa but… interested to learn better approaches. reply szvsw 4 hours agorootparentI actually think the problem you are describing is actually sometimes helpful from a design perspective, if you can be conscientious enough to periodically review your notebooks and figure out what is the actual useful code which should be properly integrated into the codebase vs what is the “one-off” / non-modular code. Like you mentioned, calculation vs side-effects is one way to help you decide but not the only. There’s definitely no single answer. The key is to just periodically figure out what ought to be refactored into library code, which notebooks should just be straight up deleted (hopefully as many as possible - you can always get them back in your git history if needed!), and so on. reply qsort 3 hours agorootparentprevI'm mostly in the camp that notebooks aren't that great for software development, they thrive as an \"excel for coders\" of sorts, but take a look at nbdev from fast.ai. The literate programming aspect is very nice and I wish it was explored more. reply ThouYS 6 hours agoparentprevmarimo is really cool, albeit \"pure python\" is only true insofar as the diff is concerned. other than that, it's an unconnected group of functions that need the marimo runtime to stitch together. would be cool if marimo could \"unroll\" the compute graph into a standalone python script that doesn't need the marimo library reply mscolnick 2 hours agorootparentit’s already possible to do this: marimo export script nb.py Pure-python also helps to work with existing tools out of the box: formatting, linting, pytest, importing notebooks as modules, composition, PEP 723 inline metadata reply 3eb7988a1663 49 minutes agorootparentIf you are going to do that, you could stick with Jupyter + nbconvert. I rarely use notebooks directly anymore unless I require the output to be stored. Do most everything in VSCode with interactive .py files. Gets you the same notebook-y experience + all of the Python tooling. reply oivey 11 hours agoprevWhat’s the advantage of this? It isn’t obvious to me that reducing memory usage and CPU of an empty/idle kernel is all that meaningful if the actual Python code in your notebook uses far more resources. It’s also not obvious to me how Go’s better threading helps, either, if all the computational bits are in Python anyway. reply energy123 11 hours agoparentI have one nit with JupyterLab. When I press Ctrl+F, it takes ~0.4 seconds for the search box to open, and sometimes the first keystroke doesn't register when I type something into that search box. \"Zasper ... provides ... exceptional speed\". If they can just make input latency indistinguishable from vim, that's a very worthwhile value add. reply lf-non 11 hours agoparentprevIt is quite beneficial for people who aren't writing python. And for them managing jupyterlab installations is a bit of pain. I would like to use this with xeus kernel for sql (which is also native) and if this reduces the resource consumption of that setup significantly, its a big plus for me. reply oivey 10 hours agorootparentThe README says the savings is ~75 MB. In most notebook workflows you’re at most running a couple at once. Saving5. Rendering your app > Electron uses Chromium under the hood so your user sees the same on Windows, Linux and macOS. Tauri on the other hand uses the system webview: Edge Webview2 (Chromium) on Windows, WebKitGTK on Linux and WebKit on macOS. Now here comes the bad part, if you are a web developer you know that Safari (Based on WebKit) is always behind a step from every web browser. Just check out Can I Use. There is always a bug that you are not seeing from Chrome, only your dear Safari users. The same issues exists in Tauri, and you can't do anything against it, you have include polyfills. The winner has to be Electron here. https://www.levminer.com/blog/tauri-vs-electron reply est 5 hours agorootparentThen why can't Chrome/Edge provide a up-to-date library for everyone like mshtml.dll? reply pjmlp 5 hours agorootparentThat is what Edge Webview2 is, https://developer.microsoft.com/en-gb/microsoft-edge/webview... https://learn.microsoft.com/en-us/microsoft-edge/webview2/ reply benatkin 34 minutes agorootparentMaybe the situation only sucks on OS X. On Linux you could hopefully swap it out with a new one on build. Either way, I think perhaps Tauri should provide a way to optionally use its own build of the rendering engine and a preset/example configuration that uses the included one for the platforms that are up to date and its own build of a rendering engine for OS X and possibly Linux. reply low_tech_punk 11 hours agoprevI wish the author considered https://wails.io/ for UI. Why all the effort with Go and ended up with Electron? reply nbittich 11 hours agoparentBecause they use code mirror to build their ide reply hbbio 9 hours agorootparentYou can use CodeMirror with Wails I think, it's still web technologies but with a thinner layer compared to electron. https://wails.io/docs/howdoesitwork reply RossBencina 10 hours agoprevHonest question: what's the advantage of this over the Jupyter notebook support in VSCode? (which I use daily) reply bandrami 41 minutes agoparentOr for that matter Emacs reply gdevenyi 4 hours agoprevCan I disconnect and reconnect from a running frontend (close and reopen a tab) and not lose any output? reply Flux159 11 hours agoprevThis looks pretty nice - this is specifically replacing the JupyterLab frontend and keeping the connections to Jupyter kernels - there shouldn't be any theoretical reason that it couldn't support Javascript or other language kernels, although I guess the project has only been tested with IPython kernels. Would be interested to see where this goes. reply barrettondricka 3 hours agoprevThat demo gif is horrible. You are not showcasing anything, but looping low resolution screenshots with special effects. reply 1121redblackgo 4 hours agoprevGood looking project I will check this out for sure reply cess11 7 hours agoprevHow's the maturity compared to Livebook? https://livebook.dev/ reply __tyler__ 8 hours agoprevHow does this compare to Marimo? reply jampekka 8 hours agoparentDoesn't seem to fix the invisible state problem that Marimo fixes. reply set92 6 hours agorootparentFrom my POV is not fixing, is another way of work. I don't like what Marimo does, because for that I have scripts. If I'm loading files from S3, I'm being charge for it. If Marimo re-executes this cell to maintain the state, it will charge me double. I don't need that. I'm able to organize my code, and know how it is being run. reply jampekka 4 hours agorootparentI use mostly the script workflow, but for exploration Marimo is more convenient. It got also to-disk memoization recently. Kinda best of both worlds for exploration (although I'm not a huge fan of editing code in browser). In comparison to the JupyterLab hidden state spaghetti it's a fix. With proper structuring of the blocks, Marimo will not re-execute the cell. Also memoization in script based workflows is still somewhat clunky on Python even with something like Snakemake. I do find Marimo's approach, \"global\" variables tracked between blocks, less than ideal, but it's the best out there. reply amoss 2 hours agorootparentprevhttps://docs.marimo.io/guides/expensive_notebooks/ reply v3ss0n 10 hours agoprevWhat's the point of this? Only benefit seems to be decoupling frontend in react. Nobody complaints about Jupyter performance. You can just build frontend and keep Jupyter as it is, it is already concurrent enough for multiple users use cases. reply dizhn 10 hours agoprevInstall instructions seem incomplete. reply lutusp 8 hours agoprev> ... A Modern and Efficient Alternative to JupyterLab ... This is not meant as criticism, just perspective. It's a classic development sequence: * A team creates a powerful, small-footprint, REPL environment. * Over time people ask for more features and languages. * The developers agree to all such requests. * The environment inevitably becomes more difficult to install and maintain. * A new development team offers a smaller, more efficient REPL environment. * Over time ... wash, rinse, repeat. This BTW is what happened to Sage, which grew over time and was eventually replaced by IPython, then Jupyter, then JupyterLab. Sage is now an installable JupyterLab kernel, as is Go, among many other languages, in an environment that's increasingly difficult to install and maintain. Hey -- just saying. Zasper might be clearly better and replace everything, in a process that mimics biological evolution. Can't leave without an XKCD reference: https://xkcd.com/927/ Again, not meant as criticism -- not at all. reply RossBencina 8 hours agoparent> JupyterLab kernel There is no such thing. There are Jupyter kernels. JupyterLab is just one of many UIs that speak the Jupyter protocol. Other examples include the original Jupyter notebook editor, VSCode Jupyter extension, and now Zasper. I'm pretty sure Sage was always intended as a project that integrates the world, never \"small footprint\". reply lutusp 7 hours agorootparent>> JupyterLab kernel > There is no such thing. A Web search reveals that the alternate term \"Jupyter kernel,\" appears equally often. The terms are interchangeable. > I'm pretty sure Sage was always intended as a project that integrates the world, never \"small footprint\". A large install became true eventually, but it began as a small Python-based install, about 120 KB. Then people asked for extensions, and William Stein said \"Yes\". reply williamstein 5 hours agorootparentNo. reply lutusp 1 hour agorootparentOkay, a slightly exaggerated account. reply prirai 7 hours agoparentprevSagemath offers a different purpose which is scientific computing in order to compete with Mathematica and MATLAB. It offered a good interactive notebook interface which went on till about 2016, and later on was migrated to using the jupyter backend. It currently isn't well supported in Windows which is what you might have meant by the complexity. However it works pretty well with linux systems. reply lutusp 6 hours agorootparent> Sagemath offers a different purpose which is scientific computing in order to compete with Mathematica and MATLAB. Yes, that was its goal, when Python wasn't as evolved as it is now. More recently I've come to rely on Python libraries like sympy for symbolic processing. For these kinds of results Sage relies on a rather old environment called Maxima, and I think current sympy does pretty much everything that Maxima does. And as time passes Python libraries are beginning to provide some of the numerical processing originally provided by MATLAB (but more slowly). > It currently isn't well supported in Windows which is what you might have meant by the complexity. Actually I was thinking of JupyterLab itself. As time passes I find it more difficult to get it installed without library conflicts. But that can be said about many Python-based projects in modern times, which is why a Python virtual environment is becoming more the rule than the exception, in particular with GPU-reliant chatbots and imaging apps, to avoid the seemingly inevitable library version conflicts. If memory serves, Sage now installs on Windows by creating a Linux VM to support it. reply waseemmalik 9 hours agoprev [2 more] [flagged] v3ss0n 8 hours agoparent [–] What are you suppose to mean? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Zasper is a high-performance Integrated Development Environment (IDE) inspired by Jupyter, optimized for massive concurrency and minimal memory usage. - It is built with the Go programming language for enhanced concurrency and performance, offering both Electron and Web App versions, and is open-source under the AGPL-3.0 license. - Zasper supports REPL-style (Read-Eval-Print Loop) data applications and aims to expand beyond Jupyter Notebooks to support custom data applications, with full support on Mac and limited support on Linux."
    ],
    "commentSummary": [
      "Zasper is a new alternative to JupyterLab, developed in the Go programming language, promising enhanced efficiency with reduced RAM and CPU usage.",
      "It utilizes Go coroutines for improved kernel management, contrasting with JupyterLab's Python-based approach, and aims to tackle issues like kernel management and package installation.",
      "The project is in its early stages, with support from the Jupyter community, and is open to feedback and collaboration, highlighting the benefits of diverse frontends and potential integration with tools like Emacs."
    ],
    "points": 339,
    "commentCount": 79,
    "retryCount": 0,
    "time": 1735797320
  },
  {
    "id": 42569236,
    "title": "Rails for everything",
    "originLink": "https://literallythevoid.com/blog/rails_for_everything.html",
    "originBody": "Rails for everything Published: 2025-01-01 After spending part of my holiday building and deploying a new Rails 8 application, It's clearer than ever that Rails is awesome, and it's especially great for small projects with a single developer. Guide is good The latest Getting Started with Rails guide is really excellent. There's a bit of hand waving around installing Ruby (which is still more difficult than it needs to be). But if you follow it start to finish, you'll have a Rails app in production. And it isn't just hello world. Your app will have authentication, caching, rich text, continuous integration, and a database. That's a real application. If you're brand new to Rails, the guide is the best place to start. SQLite is all you need SQlite is a great tool, but its focus on backwards compatibility means that it wasn't ideal for a production database out of the box. You had to add some gems to get it ready to perform. However Rails 8 deals with that for you, and SQLite is ready for production. Now that you SQLite is a more robust choice, you don't have to worry about spinning up a PostgreSQL server. On top of that, with tools like solid cache you don't need to stand up redis either. Everything is running under Rails and within SQLite. Superb. Easy CI After I pushed my initial Rails commit, I got an unexpected email: Run failed: CI - main. My first thought was actually a malicious actor, but I was wrong. Rails 8 comes with basic CI config and Github comes with 2000 free minutes per month of actions usage. Aside from it being really cool to have CI with no effort, 2000 minutes of run time is a lot for solo developer! Authentication generator Devise is the canonical authentication gem. But it hides a lot of complexity and it's not exactly easy to configure correctly, especially for a beginner. Rails 8 adds a new authentication generator. It add a simple sign in flow for existing users. All you need to do is add a user via the Rails console and boom. You can log in. The generated code is pretty minimal and easy to read about. Easy and fast deploys with Kamal I am more than happy to leave deploys to my very smart friends in the ops team. To deploy a new Rails 8 app, I just needed to update a few items in deploy.yml, follow a few directions, and I had an app live! With SSL! Honestly it took less time to get a web app up than it took me to get SSL on a Github page. CI + easy deploys might be the best part about Rails 8. Even just using the getting started guide, it encourages best practices. Conclusion Rails is not dead; It's better than ever. Try using it to make something new this year.",
    "commentLink": "https://news.ycombinator.com/item?id=42569236",
    "commentBody": "Rails for everything (literallythevoid.com)325 points by FigurativeVoid 22 hours agohidepastfavorite203 comments ajmurmann 19 hours agoI've been building some apps with stacks lately that are supposed to be more modern and performant. Namely an app with Spring Boot and another with Micronaut. Both had a React frontend. It really made me appreciate Rails' omakase approach. Just having a form that shows validation errors from the backend and having something as simple as Rails' flash messages isn't solved by the frameworks themselves and requires you to build it yourself or find a third-party solution that might or might not do the basic thing you need or might or might not be well-supported. Rails truly solves the problems 90% of web apps share. It might not be in a way that's perfect for your specific project but it will likely work and you can swap it out one you've validated you app or feature. reply neeleshs 16 hours agoparentSpring boot has form validations pretty much out of the box, via validation annotations. reply ajmurmann 10 hours agorootparentIt does have validations but the integration of then in Rails goes much further. In Rails you associate the form with the model and the validation errors somatically show up on the form. reply olavgg 8 hours agorootparentThe biggest difference here is that Spring Boot has the errors in a seperate object BindingResult. If you use Thymeleaf, this is smoothly integrated and you just write: Invalid Comment Grails Framework (Spring Framework more like Rails) integrates errors directly into the domain model, so if you have a domain class Person, it was extended with person.errors property. reply nesarkvechnep 6 hours agorootparentprevI'm amazed that some people think that coupling your forms to your database models is a good practice. reply neeleshs 47 minutes agorootparentMore often than not, forms are the database model. They very frequently evolve together. The entire data transfer object to model copy back and forth is unnecessary most of the time reply mst 6 hours agorootparentprevIf the form is basically raw CRUD then it works out well, and being able to get up and running quickly and replace it with something more sophisticated later when you actually need that is a good thing. It does require the discipline to actually _do_ the 'replace it' part when you reach that point and the results of failing to do that are ... not pleasant ... but that doesn't mean it's _always_ the wrong choice, especially when getting started. reply lolinder 6 hours agorootparentprevIt depends a lot on the application. I have a little Django app that I haven't updated in years and is used by one person—it's basically just a nice frontend for a database. For that use case, being able to just directly plug forms into database models is super convenient! reply imtringued 6 hours agorootparentprevMaybe, because it works? What value does \"not coupling\" give you, when you end up copy pasting the attributes from one object to another anyway? reply game_the0ry 5 hours agorootparentprevCould you elaborate on why it is a bad practice? reply rednafi 17 hours agoprevRails is awesome, and so is Django. I’ve built mission-critical apps in both and still do with Python. That said, I’d love to switch to Go for building large monoliths since it has a tighter type system and better concurrency constructs. The problem is, Go community has never really filled that gap. I love Go, but the whole \"Go doesn’t need a Rails or Django\" mindset is part of why it hasn’t taken off in this space. Building networking tools and CLIs in Go is great, but when it comes to quickly building a full-stack web app, I still reach for Rails or Django. So this whole \"X is dead\" doesn't apply to Rails at all. reply lapusta 22 minutes agoparentI could really recommend Encore https://encore.dev/ that works best when you use their PaaS offering https://encore.cloud/ (think of NextJS & Vercel combo). One can argue it goes against some of the Go principles, but it's a really nice stack for solos or small teams without dedicated SREs. And as you grow you can BYOC & deploy it yourself or completely rewrite your API layer using Go stdlib. You would still need NextJS or Remix/RR7 for the front-end, but one nice thing is that it would auto-generate the client SDK in TypeScript which makes integration a breeze. And while I personally prefer Remix/RR7 for frontend, Encore has integration with Vercel PR feature which is really hard to beat. reply koito17 16 hours agoparentprevWith tools like ogen[1], one can take a single OpenAPI document and generate server code with a static router, request/response validation, Prometheus metrics, OpenTelemetry tracing, and more out of the box. It can also generate clients and webhooks. Authentication is just declaring a SecurityScheme in the OpenAPI document then implementing a single function. The rest of the backend is just implementing a single interface. Unlike oapi-codegen, there is no need to tinker with routing libraries or middleware for authentication and logging. Pair this with sqlc[2] and SQLite's `pragma user_version`, and you get type-safe database code and database migrations for free. I will concede that adding SQLite is a manual process, but its just two imports added to main.go. Frontend is entirely your choice. Go's standard library provides good enough text templating that I don't miss ERB or Django-style templates. Using the standard library's `embed` package, one can easily embed static assets into a single binary, so deployment can be as simple as `go build` and moving the binary. I have a hard time using languages besides Go for developing backends, because the code generation tools make Go as convenient as frameworks like Quarkus while staying lightweight and fast. [1] https://ogen.dev/ [2] https://sqlc.dev/ reply adamtaylor_13 14 hours agorootparentJust reading this kinda makes the OP’s point. This isn’t simple, when compared to Rails. The simplicity-yet-capability of Rails is hard to match. reply multiplegeorges 15 hours agorootparentprev> Frontend is entirely your choice. You are missing the entire point of Rails and making the OP's point for them. > Go's standard library provides good enough text templating Rails offers much more than this, this again makes OP's point for them. reply rednafi 12 hours agorootparentExactly. I don’t want to waste time on trivial decisions like which frontend tool to use or what templating engine to pick. This is exactly why Go isn’t great for building full-stack apps. Every app in Go looks different because you have to assemble all the parts yourself. In contrast, RoR or Django provides a nice rubric to get you up and running quickly. That said, I still like Go when I need to spin up a microservice with a well-defined scope. reply samtheprogram 14 hours agorootparentprevSecond this. My GP missed the point — the integration with front end tooling all the way to the database means you get so much more for free. reply WuxiFingerHold 13 hours agoparentprevI was looking for a mature, complete and powerful statically typed stack as well. ASP.NET was my clear answer (not Go or Rust). There's a lot of noise coming from Microsoft to sell their new products (this year: Aspire.NET). But don't be mislead by this noise: .NET Core (C#, ASP.NET Minimal API or MVC, EF Core) is more batteries included and reliable than most other options. The only gripe I have is the need to get into the OOP and DI mindset (\"create custom implementations of some abstract classes and put them into DI and the framework calls your implemented methods magically\" kind of stuff). Takes some time, but not a big deal for experienced devs (and younger ones can learn faster anyway :-)). reply rednafi 12 hours agorootparentThe problem is finding fresh blood who want to write C#. RoR or Django is a much safer choice in that regard. This OO/DI stuff has fallen out of fashion (whether that’s good or bad, I don’t know) and very few enjoy working with these constructs anymore. reply tormak070707 11 hours agorootparentThat's true. Once upon a time when I was intern I was charmed with ASP .NET. Couple of years later I had opportunity to work with Django. Everything looked so batteries included, felt hackable and syntax was friendlier to me (Only exception ORM). Unfortunately project got on hold and I was moved to write new service in ASP .NET. Holding mental model of Dependency Injections, everything OOP, boilerplate produced is cumbersome, CamelCase... reply neonsunset 4 hours agorootparentprevHave you ever had to actually hire? reply iovrthoughtthis 9 hours agorootparentprevc# (and the project i was working on) destroyed my love of programming reply rednafi 8 hours agorootparentMicrosoft Java reply sroerick 13 hours agoparentprevI’m working on a project in go right now, and I’m really, really enjoying it, but I really do not disagree with you. AI has helped me overcome those framework hurdles. The codebase feels extremely clean to me. My gut still says rails for customer facing, Django for internal tooling or data work. reply teleforce 11 hours agoparentprevThe author of Stanza language has this insightful article on the viability of a programming language for creating a powerful framework like Ruby on Rails [1]. Surprisingly there's no Go and Java equivalent, either it's the incompetence of the programming languages (can't) or the programmers (won't), or both. [1] Stop Designing Languages. Write Libraries Instead: http://lbstanza.org/purpose_of_programming_languages.html reply sverhagen 9 hours agorootparentI've had to do some maintenance on Rails apps in the past, coming from my Java background, and it was painful as hell. It's just what you're familiar with. I can take my Java and Spring Boot, both of which I'm very familiar with, and write an article like that to wonder why Ruby has not something awesome like Spring Boot. But I don't do that, because it'd be equally embarrassing. Spring Boot for me is super productive, has a lot of batteries included, and is a dream to work with, hence I have no desire to play with Rails. Had I stumbled into Rails development, as a career path, I'm sure it'd talk about this the opposite way. reply funny_falcon 4 hours agorootparentprevDo you use stanza? reply cgg1 17 hours agoparentprevI’m a big fan of Django and Go as well but the only thing in the Go ecosystem that I’ve found that comes close is beego: https://github.com/beego/beego But it still needs to mature quite a bit before I’d be comfortable saying it’s anywhere near Django or Rails reply joshlemer 9 hours agorootparentThere’s also https://www.goravel.dev/ reply pjmlp 7 hours agoparentprevIt isn't the anti-frameworks mindset, it is also the anti-modern-features mindset. Java, Kotlin, Scala, C#, F#, OCaml, Haskell, D, are also much better for networking tools and CLI. And nowadays people can't even complain the Java AOT options are commercial, or .NET is stuck on Windows. reply rednafi 7 hours agorootparent> It isn't the anti-frameworks mindset, it is also the anti-modern-features mindset. Touché! > Java, Kotlin, Scala, C#, F#, OCaml, Haskell, D, are also much better for networking tools and CLI. Maybe. But I wouldn't touch any CLI written in a Java, Kotlin or Microsoft Java with a 10-foot pole. YMMV. reply pjmlp 6 hours agorootparentSo you dump every executable before making use of it? reply sigzero 17 hours agoparentprevI don't think Go was trying to capture that space really. reply rednafi 15 hours agorootparentGo initially tried to capture the C/C++ space and failed miserably. Rob Pike lamented[^1] over that in a famous blog post. It got the most love from people coming from Python and Node. Then it became the defacto language for writing networking tools, and to this day, it holds that crown. Go is in an awkward spot—it’s not dethroning Python because it’s not as expressive, academics hate it, and it’s not as fast as Zig or Rust to appeal to systems programmers. So it only makes sense to target the web services section dominated by Django and RoR. [^1]: https://commandcenter.blogspot.com/2012/06/less-is-exponenti... reply peteforde 10 hours agorootparentKudos: I find this to be an exceptionally helpful and concise description of the Go meta. I would offer that Erlang did a good job of capturing the [concurrency?] space, though some of the tooling is showing its age. It's therefore interesting to see Elixir straddle the divide between Erlang and Ruby. I'm still Rails all day, but I've never stopped thinking Elixir is cool. reply out_of_protocol 9 hours agorootparentWell, i think Elixir/Phoenix is better Rails than real Rails - great developer experience (and developed by rails contributors) reply mstipetic 6 hours agorootparentEvery time I step out of elixir I feel like I’m coding with some cumbersome construction gloves and everything is kinda coerced to work together. But for some reason it’s not picking up a lot of steam and the job situation is rough reply lolinder 5 hours agorootparentTyped languages are in big time, and any dynamic language is facing an uphill battle for adoption, no matter how good it is. Elixir seems to recognize this and is getting there, but it hasn't fully arrived yet. reply blandflakes 1 hour agorootparentTypes and editor tooling IMO. Both places they're making investments, but both areas where I feel like I'm giving up a lot of power, even though it's admittedly to GET a lot of power. reply arrowsmith 8 hours agorootparentprev100%. I’m never going back. reply sroerick 13 hours agorootparentprevNot too familiar with Go but this makes sense to me. The standard libraries are really great for microservice type stuff. Things that, as a python guy, I would have reached to Flask for. Problem is, I never reached to Flask for much of anything. I’m really having fun with Go these days, though reply rednafi 12 hours agorootparentGo’s stdlib is almost as good as Python’s—with the bonus of a stricter type system and faster execution speed. Package management in Go is better too, though uv is making Python’s experience smoother. That said, Python is great, and beginners love it. For algorithms and prototyping, I still prefer it. But for writing servers, Go’s stdlib lets me spin up a production-ready, concurrent server using just the basics. What Go lacks, though, is something like Django, which it could really benefit from. reply lolinder 5 hours agorootparent> Go’s stdlib is almost as good as Python’s—with the bonus of a stricter type system and faster execution speed Define good, and for what applications? I'm having a very hard time imagining that go's standard library is anything like as comprehensive as python's. reply jen20 5 hours agorootparentNo need to imagine - here’s the documentation for it: https://pkg.go.dev/std I’ve found the Go standard library to not only be very complete, but also to contain far fewer sharp edges and dead batteries than that of Python for every use case I’ve tried. reply sroerick 12 hours agorootparentprevWSGI was a learning curve for me reply rednafi 12 hours agorootparentASGI too. But it’s not too bad and tools like Starlette / FastAPI make it a breeze. Go servers are fast but generating docs from code is a lot more work which you get free in FastAPI. reply adhamsalama 11 hours agorootparenthttps://huma.rocks/ https://github.com/go-fuego/fuego reply __MatrixMan__ 15 hours agorootparentprevGo is best at interfacing with kubernetes, which I think will carry it pretty far, for better or worse. reply jen20 5 hours agorootparentThe Kubernetes API is one of my least favourite Go packages - largely generated, boilerplate all over the show and hasn’t even adapted to use things like log/slog without some wrapper. A much nicer library for dealing with Kubernetes is the kube crate [1] for Rust. The worst aspect of it is the dependency discipline, though that is no worse than the official Go client. [1]: https://github.com/kube-rs/kube reply rednafi 11 hours agorootparentprevYeah, Go’s niche is networking. But it could be so much more. The language is nice and fast, and there’s no reason it can’t be a solid choice outside the microservice and tooling universe. reply joshlemer 9 hours agoparentprevYou could give https://www.goravel.dev/ a look! reply shortrounddev2 15 hours agoparentprevNode/Express is my goto for quick and dirty picoservices that only really run on local developer machines. Asp.Net WebAPI or MVC is my ideal backend stack reply nomilk 16 hours agoprev> if you follow (the Rails Guides) start to finish, you'll have a Rails app in production. And it isn't just hello world. Your app will have authentication, caching, rich text, continuous integration, and a database. That's a real application. These features are great for established apps like GitHub and Airbnb, but if you're making a tiny startup, and want to test ideas quickly, I wouldn't spend time on CI, caching, Rails's authentication (use extremely feature rich Devise gem), Rails's 'turbo' features, and writing tests. These are all good things for medium or larger apps, or well-funded apps with a long run way, but are usually cost-benefit negative for small apps. Turbo saves a fraction of a second on many page loads, but can add days of development time for those not fluent in javascript when it causes some core functionality to not work (e.g. devise's Log out!). Testing is very important on large apps but for quickly flicking a few ideas together and getting it in front of users; unless you're a banking or healthcare app, they can probably be postponed until you have traction. Be mindful of your size and timelines and don't succumb to 'default bias' where you use things simply because they were there out of the box. Feel confident to say 'no, we don't need that (for now)'. reply aantix 12 hours agoparentIf you're looking to build a SaaS app, start with a professionally curated Rails template. It will save you months of development time. Payments/Auth/etc are built in and there are solid patterns in place to extend from. Jumpstart Pro is great. https://jumpstartrails.com/ So is Bullet Train. https://bullettrain.co/ reply anarwhal 7 hours agorootparentThese are great recommendations, thank you! Gives me a reason to spin up a new project I've been musing about for a while in order to play with this reply bleuchase 11 hours agorootparentprevDo projects like Jumpstart Pro or Bullet Train exist for other languages? Like Go? reply aantix 10 hours agorootparentNot sure about the Go ecosystem. reply gavmor 15 hours agoparentprevWhen do you switch from Flask/Express/Sinatra/Gradio/Hono to Rails? reply peteforde 10 hours agorootparentWhen you realize that all you need to add to X to make it great is a crappy reimplementation of all of the things that ship with Rails before you can start building your app. reply boredtofears 14 hours agoparentprevCI should speed your development up, not slow it down. It's definitely something you should add earlier to the project than later. reply speleding 8 hours agorootparentAs long as the test suite is small enough to quickly run on the devs laptops the gains from CI are fairly minimal. With old school Capistrano-rails you can deploy in 20 seconds and roll back in 5 seconds, IMHO you don't need to pay the price of multi-minute deploys until much later in a project's lifecycle. I appreciate that they wanted to keep Kamal simple, but rebuilding a Docker image each time you deploy a tiny change feels like a waste. Capistrano just does a 'git pull / bundle / server restart' which seems much more elegant. Of course, things like upgrading to a new ruby version become much harder with Capistrano's model, you need a separate process for a small release and a big release. But those things happen twice a year, on small projects you can do those manually until you have time to set up Kamal / Terraform / Ansible. reply yakshaving_jgt 15 hours agoparentprevI don’t agree with your position on tests. I find that writing tests even for small applications saves me time. And that’s even in a language with a sophisticated type system. I’m also not sure how much time you imagine one spends on setting up CI. In my case it’s just one file with about 20 lines in it, and I usually just copy and paste it from previous projects. reply gavmor 15 hours agorootparentSome people use tests as a design tool, and as a way to repeatedly execute code in a known state while developing it. In that regard, it improves upon print statements and, frankly, step-through debuggers. That it leaves behind a harness for triangulating bugs in pull requests is, of course, an invaluable side-effect. reply yakshaving_jgt 14 hours agorootparentThat’s exactly my approach. I learned it from watching the Destroy All Software screencast series a decade ago. While the screencast demonstrates this with Ruby and RoR, it’s still applicable to all my work in Haskell and Yesod, despite some ideologues arguing that there is some dichotomy between types and tests. reply nomilk 15 hours agorootparentprev> I’m also not sure how much time you imagine one spends on setting up CI. In my case it’s just one file with about 20 lines in it, and I usually just copy and paste it from previous projects. The problem is when it breaks due to some versioning issue or some other easy-in-hindsight problem that saps 3-6 hours of time that could otherwise have been spent talking to users and discovering/building real features. I start to question \"did I really need CI in the first place\", I think the answer for non-critical apps (e.g. with a small number of users; not healthcare/banking/similar) is usually a hard \"no\". Other than autonomously running tests what value does CI offer?.. to me, nothing that I can think of. Not saying everyone should denounce it, just that it's very okay to say 'nope, don't need it (yet)'. reply boredtofears 14 hours agorootparent3-6 hours is nothing in terms of the money you will spend on development for even a modestly funded startup. You definitely don't need to be a healthcare or banking app to quickly reap the benefits of a robust dev/deploy cycle. reply yakshaving_jgt 14 hours agorootparentprevHmm… Interesting. I use Nix so I don’t have versioning issues. Maybe I would have if I didn’t. reply icameron 16 hours agoprevGlad to see Rails is looking better than ever! I've been supporting a few Rails web apps since the Rails 2.3 days -almost 12 years- and today's rails is quite different, like a fully evolved Pokémon. Thankfully the comprehensive Rails Upgrade Guides are solid and well documented. It was manageable to upgrade my apps one version at a time over the years without a major refactor. Rails embraces new developments in web tech, so it's never been backwards compatible, but at least their changes are well documented. ActiveStorage was a huge improvement over the 3rd party gems for file attachments, and came with cloud provider support. The toughest lift was the migration to Webpacker from Bundler for the javascript stuff, which we only finally did a couple years ago. But now it looks like that is all behind us with Import Maps support. I'm looking forward to upgrading these apps once again to 8.1 this year. reply samtheprogram 16 hours agoparentI took a pay -loss- to maintain a Rails app for a client with a small budget, about 4 years ago on an outdated app using Ruby 2.3. Super happy with the decision. It’s too easy to add features or upgrade the app and I love working in the codebase. reply sroerick 13 hours agorootparentShot in the dark here, drupal dev? reply samtheprogram 3 hours agorootparentHeh, no. Full Stack with a lot of NextJS/React/ReactNative these days. Sprinkle in a Spring Boot + Angular project and this Rails gig. I also spent a few years doing Obj-C/Swift iOS development. Rails was one of the first web frameworks I learned after PHP and it and Ruby were always favorites of mine. Closest I came to being a Drupal dev was shipping a small CodeIgniter app in around 2011 (right before picking up a Rails book). reply block_dagger 18 hours agoprevAs a single developer of an open source Rails project that has grown to serve ~120k MAU, I can attest to this article’s claims. One tidbit to add: ActiveStorage, which provides file attachment features, is another excellent piece of the Rails family. I’ve been using Dokku but looking forward to trying Kamal. Rails keeps getting better, and Ruby keeps getting faster. reply schneems 16 hours agoparentIf you like dokku, have you seen Cloud Native Buildpacks? You can build an OCI image from them as a first class feature https://github.com/heroku/buildpacks/blob/main/docs/ruby/REA... reply block_dagger 13 hours agorootparentBuildpacks look cool, but Dokku is perfect for single-server projects with its plugin system. It has one-command setup for Postgres and Redis, auto-backups to S3, built-in nginx reverse proxying, and an easy Let's Encrypt plugin. My current server has an uptime of 1,912 days (~5.3 years) with near 100% app availability. With reliability like that, I plan to stick with Dokku when I upgrade to a new server next month. For multi-server setups, Buildpacks with orchestration tools probably make more sense though. reply josegonzalez 10 hours agorootparentDokku uses heroku buildpacks by default and supports cloud native buildpacks by changing the builder to pack via builder:set. reply cjohnson318 14 hours agoprev> There's a bit of hand waving around installing Ruby (which is still more difficult than it needs to be). For real. I put together a simple Jekyll blog, and figuring out gems and this and that after not looking at Ruby for 15 years was a real slog. A lot of that was my fault for being out of the Ruby loop, and being unfamiliar with Jekyll, but I feel like the process could have gone a little more smoothly. Anyway, this made me excited to try Ruby again. reply Syntaf 11 hours agoprevI’m building a member management platform [1] with Rails + Turbo + Stimulus and it continues to surprise me how easy it is to just… do things with rails. * Want to allow your users to write rich text? Easy just use ActionText * Storage and attachments? ActionStorage is easy to setup * Job queue, asynchronous work? No problem with ActiveJob Today I learned about Rails system tests and found it so cool. With almost no configuration I can write tests that interact with my app through a headless browser. Rails is the ultimate solo developer and hobby project tool for me [1] https://embolt.app reply dewey 10 hours agoparentSame feeling, I’m usually a Go developer but all my side projects are in Rails. It’s just fun to work with and see how fast things are up and running. Using gorails.com and Copilot helped a lot too. reply rich_sasha 18 hours agoprevAs someone who doesn't do enough web dev to justify learning Ruby just for Rails: how does it compare to Django? That's the only batteries-included web backend framework I'm familiar with... Asking out or curiosity. reply Lutger 5 hours agoparentHaving years of experience in both, though not recently in rails, these are some of my thoughts: Obviously Django ties you into python and its ecosystem while Rails means ruby (and its gems). The ecosystem is more important than the language. This can either impact your project a lot, or not much at all, depending on context. Rails doesn't have the equivalent of Django's admin CMS. There are gems but Django is still much stronger. A lot of orgs have their entire CMS / administrated-by-staff part of the product written in it. Rails, otoh, has a very powerful scaffolding cli. If you are proficient, you can generate some basic crud stuff in minutes from A to Z. In general, I think Rails is at an even higher level of abstraction than Django. A lot of the architecture or structure is more or less given with rails, whereas you need to make a lot more choices with Django yourself. Routing is a good example. The 'batteries' that are included are also a bit bigger and seem to be in much more active development than Django. Also a generalization: rails/ruby seems to value brevity and the DRY principle a lot more than is common in django/python. There's a split in taste on this, often python devs find the 'magic' of Rails rather frivolous and unreadable - even though django has a fair bit of metaprogramming itself, whereas Rails devs think the 'pythonic simplicity and straightforwardness' is actually rather crude. Or to be a bit more precise: in the rails world, code duplication seems to be thought of as a greater evil than semantic coupling. I realize these are all quite subjective, and probably reflecting my own development experience more than being an accurate feature-by-feature comparison. reply sroerick 13 hours agoparentprevThis is my go to line and nobody has challenged me on it thusfar: If I was building a web ‘app’, consumer facing product, I’d reach for Rails. I think scaffolding up to ‘market ready’ seems easier in Rails. I say this having never really done this in production. For internal tooling (using the admin panel), data based work, or geospatial work, stick to python reply WD-42 17 hours agoparentprevThe biggest difference is python vs ruby. Python’s ecosystem is massive, so if you want to pull in any third party libs you have plenty of choices for whatever you may need. Django also has auth and the admin interface built in, both of which are very nice. reply tyre 17 hours agorootparentRuby and rails’ ecosystems are also massive. Devise and ActiveAdmin are options for those two, though I haven’t used either in years. With much of the AI development happening in python and typescript, you might be right about those areas. reply WD-42 17 hours agorootparentRoR's ecosystem is indeed massive - for web apps. But if you want to make an app that integrates with an existing domain, Python is just so far ahead. Numpy, SciPy, Pandas, basically the entire field of astronomy and biology, data science and FinTech... the list goes on. But if you are sticking to basic web/database stuff it's hard to go wrong with RoR. reply wmoxam 16 hours agorootparentAll of that extra stuff can still use Python and integrate easily with an RoR app. Typically your astronomy/biology/ata science stuff isn't needed in the context of a request and is done asynchronously reply WD-42 3 hours agorootparentThis is just not true. I’ve worked with many scientists, none of them want some complicated micro service architecture they have to deal with. They just want a page that displays their data or whatever, and that means using Django or flask and using whatever library they write directly. Most people haven’t even heard of ruby. reply wmoxam 2 hours agorootparentOk reply theonething 16 hours agorootparentpreva best of both worlds solution might be to have a Rails web app and Python services. Of course if you like Django/Python better anyway, then just use those. reply realusername 15 hours agorootparentprevPython might be bigger outside of the web but for any Web app, Rails wins hands down on the amount of battery included software that exists in my opinion. I've done both and I find that in Django I had to resort to more manual steps than what I'd do in Rails. The testing story is also better in Rails compared to Django, that's not even close. reply sethherr 18 hours agoparentprevOne place that I think there is a big difference in developer experience is in testing. Rails, as described in the article, comes with CI setup and corresponding tests are automatically generated when using rails generators. reply Glyptodon 16 hours agoparentprevHistorically, Django Admin is better (in terms of ease of use and flexibility) than anything equivalent in Ruby, but Rails has better conventions for tests and routing. (Or at least that's my opinion.) I also like ActiveRecord + Arel more than the Django default ORM, but that's more so preference driven by like the Ruby AR syntax more than the Python. (And a general unsupported opinion that Ruby is a slightly better/more pleasant language for writing code than Python.) reply aantix 12 hours agorootparentI would say that Avo is by far the best Rails admin-like solution out there. It's beautiful. https://avohq.io/ reply dismalaf 17 hours agoparentprevRuby doesn't really have a learning curve... Maybe block syntax but that's super easy. Rails gives you way more structure than Django. reply hatsix 15 hours agorootparentI tell people that Ruby is a language optimized for reading. Things just make sense when you are reading what someone else wrote, but it can be much more difficult to write something from scratch with no guidance. Take dates, for example. Let's say you are fixing an issue, validation was set to accept one week in the future, but should have been one day in the past. 1.week.from_now becomes... well, how do you look that up? You head to the Ruby Lang site and look up Integer, but Integer doesn't have `.week`, so now you have to rely on Google-fu to find what you need, but you'll get a mix of base Ruby and Ruby on Rails, which modified base classes with some syntactic sugar. Eventually you find 1.day.ago and file that away, only to go through the same research for the next line you need to change. It can be one of the most pleasant languages to read, but a lot of hidden knowledge is required to write it like Ruby wants you to. reply Kerrick 2 hours agorootparentThat isn't Ruby, that's Rails. Ruby doesn't have nearly as big of a learning curve as Rails. reply dismalaf 45 minutes agorootparentprevLiterally everything you described is fixed by reading the documentation. Using Rails? Read Rails documentation. Using bare Ruby? Read Ruby documentation. And literally every programming language is like this. C# won't contain Unity C# classes. Basic Python won't have Numpy classes. JS won't have React functions. And so on. Also it's not like Ruby is the only language to ever have monkey patching... It's absurd that this is being brought up as a Ruby weakness when both the Ruby website and the Rails website each have amazing documentation and if you actually read the documentation, go through tutorials, it's all laid out very clearly. https://www.ruby-lang.org/en/documentation/ https://rubyonrails.org/docs Dunno, whenever I learn a new language, I read the official docs. When I learn a new framework, I read the official docs. Even when I was an absolute newbie, I learned from the resources on the official website. reply delichon 16 hours agorootparentprevYou may be overestimating the rest of us. It took me years to get fluent and I'm still learning after 12 years full time in Ruby. Sure you can learn the basic syntax in short order, but for us muggles, not the quirks of the standard libraries, let alone the whole ecosystem. reply dismalaf 12 hours agorootparentThere's always things to learn. Ruby does have enough features that you can take years to memorize things, sure. But to learn enough to make a program that does useful things doesn't take long. If you already know how to program in a different language, maybe a weekend at most. Ruby was my first language and it didn't take me long (maybe a week of very part time tinkering) to learn how to make a basic 2D platformer game, or scrape the web for financial data and throw it into a database. The first time I made a Rails app it took maybe 30 minutes, to go from nothing to a basic CRUD app that does things and is online on Heroku. In a professional context, I've heard of non Ruby devs getting up to speed pretty quickly. And as much as there might be to learn mastery, it's still a dynamic language that takes away most details for you (like managing memory) so you can definitely be useful far quicker than if you were to learn C, Rust, Haskell or shudders C++. reply shepherdjerred 16 hours agorootparentprevRuby _definitely_ has a learning curve reply hombre_fatal 13 hours agorootparentEspecially reading other people’s code. reply bluecheese452 6 hours agorootparentprevNot my experience reply ezekg 19 hours agoprevAfter using SQLite in production for a little while, I don't think \"SQLite is all you need.\" Migrations are a pain, so any long-lived app will eventually experience pain. As an example, SQLite doesn't have a way to add a NOT NULL constraint to an existing column; you have to rebuild the entire table using a temp table. reply peteforde 9 hours agoparentThey will have to pry Postgres from my cold, dead hands. That said, I do think it's really positive that sqlite3 is now a first class option in the framework. Tons of high quality work by very smart people has been invested in recent years. reply masklinn 10 hours agoparentprev> As an example, SQLite doesn't have a way to add a NOT NULL constraint to an existing column; you have to rebuild the entire table using a temp table. Or any other constraint for that matter, every few months I look for ADD CONSTRAINT again, only to rediscover there isn't anything. The lack of any sort of PL language (or even just trivial stored procs aliasing queries) also makes migrations more annoying, CTE can handle some of the load but the verbosity and limitations of basic SQL make that awkward, and needing to round-trip through the host language for everything is frustrating (even more so when the host language is statically typed and thus requires adaptation out). reply Lutger 5 hours agoparentprevThis isn't what rails advocates, is it? I thought SQLite in rails is a replacement for redis, not for postgres. I've been out of the loop though. EDIT: this comment is more about rails itself than the actual blog. I take the point being, that sqlite is fine for starting out with a tiny app if you have very little users, and I think that is true. However, migrating later on to a different database is a always a pain, so I wouldn't recommend starting out with sqlite if you intend to do that later on (with your production data). reply FigurativeVoid 18 hours agoparentprevHuh. TIL. But in the rails context couldn’t you mostly manage with an ActiveRecord validation? I know it wouldn’t be ideal. reply cjk 18 hours agorootparentThis is perhaps what you were hinting at when you said “wouldn’t be ideal”, but Active Record validations on their own are subject to race conditions with concurrent requests. The only truly safe way to ensure integrity of your data is to enforce validations/constraints at the database level. IME you usually want _both_ the Active Record validations, and the database-level validations, because you get better error messages from the former, and the latter is just a safeguard. reply FigurativeVoid 17 hours agorootparentNo I agree. I always want a belt and suspenders with my data validations reply shermantanktop 16 hours agoprevThere’s a thing here that seems to separate people like the article author from…well, from me. They just have a deep, deep affection for Ruby and Rails. It makes everything great, and every new surprise is like discovering that your new special friend also knows how to juggle! And speaks Cantonese! How cool is that?? Oh, they’re afraid of spiders? How cute. But did you know they went to Ecuador in college? There’s a honeymoon effect that just never stops, whereas for me it never started. I’m actually jealous. reply Lutger 5 hours agoparentVery accurate. Every programming language or framework has this kind of emotional attachment of enthusiastic users, to a certain extent. But nothing quite like Rails. Its in the culture. reply Glyptodon 15 hours agoparentprevPersonally, I don't like a variety of things about Rails. Like its love for pluralization of everything. But every time I've wanted to have similar productivity with say, a Javascript backend, I find it basically impossible. At the same time, I am always shocked out how many people fight against Rails conventions when building in Rails. (Not that you've done this, but seriously, I take over a random code base and they'll have done something like written a worse version of Active Job from scratch for no real reason.) reply mosselman 19 hours agoprevIf you want to only use sqlite, I suggest looking into litestack: https://github.com/oldmoe/litestack I've not used it myself, but I am going to rewrite one of my projects that I only use locally from postgres to litestack. The benchmarks are incredible! https://github.com/oldmoe/litestack/blob/master/BENCHMARKS.m... reply jherdman 19 hours agoparentIs this really necessary given the advances with SQLite in Rails 8? What edge does this have over what’s included these days? reply mosselman 12 hours agorootparentVery good question, I don't know. Ideally you'd stick with the most vanilla stack, being solid queue, etc. However after trying solid queue in my production environment with Postgres I was left very disappointed at the reliability and speed. This could've been some misconfiguration on my part though. Another thing that I noticed is that if you compare litestack's benchmarks to solid_cable (for example) litestack claims to outperform redis whereas the argument for solid_queue is that it is slower, but worth the simplicity of 'just using the database': https://github.com/rails/solid_cable?tab=readme-ov-file All in all I would prefer 'the standard' solution, but I am interested in experimenting with litestack. After all that is what side projects are perfect for. reply adamtaylor_13 19 hours agorootparentprevLitestack provides numerous benefits, but the largest is live replication to S3-compatible storage, which SQLite will not do by default. reply tillcarlos 17 hours agorootparentAre you confusing it with Litestream, the backup solution? https://litestream.io What they meant was https://github.com/oldmoe/litestack which has a lot of things built on top of sqlite, like job queue and caches. Rails 8 now comes with most of them out of the box. My SaaS ran on litestack until rails 8 came out, then I switched without problems. reply adamtaylor_13 13 hours agorootparentAhh, yeah you’re right. My bad. Litestream was what I was thinking of. reply rootedbox 13 hours agoprevWith sqlite and docker.. rails apps are easy to share.. my last project is easy to install and use because of rails https://github.com/ThinkThinkAI/ThinkDB # change directory_on_your_machine_for_think_db_storage docker run -d --name thinkdb -p 3000:3000 -v directory_on_your_machine_for_think_db_storage:/app/storage thinkthinkai/think_db:latest TADA.. Rails is great. reply ethagnawl 19 hours agoprevInbuilt authentication is a very welcome addition. I've been using Django instead of Rails for the last 4-5 years (for business reasons) and that was one of the features Django provided which, upon reflection, seems like table stakes for a modern web app. The other glaring omission being an inbuilt admin interface -- which may have been added after I moved on. reply weaksauce 19 hours agoparent> The other glaring omission being an inbuilt admin interface -- which may have been added after I moved on. with scaffolding and other rails generators with custom templates is that really a big asset? might not look amazing out of the box but you can find css templates easy enough too. maybe they should make an admin generator but rails is king of crud and if you need it ootb you can use one of the many gems. reply Lutger 5 hours agorootparent> with scaffolding and other rails generators with custom templates is that really a big asset? Yes, it is. Django CMS just hits that sweet spot where you can do almost everything you need for an administrative backend with very little customization. Because there is a convention of how things hang together, you are that much more productive. Its kind of a cms that you can throw together programmatically, it sits at a higher level than scaffolding + templates. Honestly it feels, ironically, like a very rails-like thing to do (here's my model, you know all about it: now generate an admin interface for it!), except that in the rails world it would be unacceptably ugly (in various ways). But it is this very ugliness that prevents you from exposing it to consumers, or spending more time on it that it really needs, so it tends to stay in that sweet spot of being just good enough to do its job. It is very pragmatic and effective. Is it a must-have? No, of course not. You can DIY an admin interface with rails very easily, too easily almost. However, the same thing can be said about pretty much anything that rails has got going for it: you can DIY in django/python too. And there is always a package... reply ethagnawl 19 hours agorootparentprevI think so. You could also make that same argument about the new authentication feature, ActionStorage/Jobs/whatever. Yes, of course, _there's a gem for that_ but after having used Django, it's really very nice to have those features included and not have to spend any time thinking/arguing about which Gem to choose and remembering/endeavoring to keep that Gem patched, etc. reply weaksauce 18 hours agorootparentthere's also administration-zero which is basically scaffolding for admin pages and would be similar to what they'd give you built in if they were to. they consider it outside the scope of rails' responsibility as scaffolding is so easy to make. administration zero doesn't do much other than install a few gems, and include a scaffold that you can use to generate admin pages akin to django but you do get pagination and search and filters added on top. no magic though just rails scaffolds. https://github.com/lazaronixon/administration-zero reply sroerick 12 hours agorootparentprevDjango admin is particularly fantastic in the first 100 hours of a project. I think it offers a lot of the same developer experience and convenience that the rails generators do, though obviously in a different way. reply weaksauce 11 hours agorootparentI'm looking at the django admin interface and I see a very superficial admin interface. I am not sure why it's so lauded when the rails scaffold gives you 90% of that out of the box albeit in a style neutral way which is easy enough to gemify. are aesthetics what people are so craving for this? there's no search. nothing that stands out as a killer admin panel. I used to program django professionally around 2007ish and it doesn't seem like much has changed with the admin site... am i wrong? reply Lutger 4 hours agorootparentDjango admin also has various ways of filtering, search, navigation including menu's, pagination, permissions, custom actions and change tracking out of the box. Most importantly, it also includes ways to easily deal with relations (inline admins). Last time I programmed with rails was many years ago, but none of these things are included in the default scaffolds right? I understand the comparison with scaffolding, but I don't think they really overlap too much. You'd typically throw away a lot of the generated scaffolds from rails for a production app. They are more of a tool to avoid having to manually write boilerplate code, increasing productivity and (maybe) reducing errors. But django admin interface is meant for production, though often more as a backend tool than a customer facing interface. Different purposed. I miss the scaffolding in django and the admin interface in rails. reply sroerick 5 hours agorootparentprevNo, I don’t think so. It’s just a preference thing. I think that the rails scaffolding is definitely comparable. For most apps in Django I ultimately move away from admin in production towards custom views. There is a search fields feature, which I use frequently, but it might not do what you’re looking for. I think user permissioning and the audit trail are pretty useful in the early stages of an app. At the end of the day, crud is crud, and if you have a workflow that works for you nothing the admin panel offers is going to save you all that much time. Rails scaffolding is a similar way. It’s just one workflow. I’m doing a side project in Go right now, which is decidedly not “batteries included”, and I love it. Go and htmx are kind of a match made in heaven. That doesn’t mean I think Django Admin or Rails Scaffolding are useless, they’re just a convenience. I rolled my own login system, cause it’s fun. Is Django user land or Devise more secure? Absolutely. Is it necessary for what I’m doing? Nope. My personal preference is that if I’m doing app design or consumer facing work, Rails seems stronger. For internal tooling, data analysis work, or geospatial work, I reach to Django to have those Python libraries available. reply FigurativeVoid 18 hours agorootparentprevI was going to write about more things that I want, but it didn’t feel like it fit so much. I would love a basic admin interface plus some auth. It would be cool if rails mirrored some Devise helpers so that Pundit/Cancancan worked out of the box. reply weaksauce 18 hours agorootparenttry out https://github.com/lazaronixon/administration-zero just a thing to install an admin generator scaffolds which you control fully after the fact. no magic just generators. reply Kerrick 19 hours agoprevSince Rails 8 I’ve even found myself using Rails + Sitepress over a static site generator. Kamal makes it really easy to run multiple lightweight sites on a cheap VPS writing even less configuration than Nginx, so it saves time up front. Plus, nearly every static site ends up with someone saying, “oh I wish I could ____, but it’s a static site.” Instead of needing to pick a client-side-only solution, use a third party service, or integrate with a cloud Functions as a Service provider, Rails and a production-ready database are right there ready to help. reply sroerick 12 hours agoparent> Kamal makes it really easy to run multiple lightweight sites on a cheap VPS writing even less configuration than Nginx, so it saves time up front. Save me from my free tier GitHub pages / Netlify / SaaS hell. This is the hottest tip in this thread imo reply lolc 4 hours agorootparent> Save me from my free tier GitHub pages / Netlify / SaaS hell. Depends on how you like your hell: Now you're on the hook for security updates to the full stack. reply wiseowise 3 hours agoprevI always read how great Ruby/Rails are, but learning language just for one thing (Rails) rubs me up the wrong way. Especially when alternative (Python) is so much more useful (on a surface) and Django can do the job of Rails (while not as good or nice as Rails (from what I gathered), but still). Kinda like learning Dart for Flutter. Those of you who struggled with the same dilemma, what did you do? reply jaynetics 3 hours agoparentAs others have pointed out, there are many use cases for ruby. It's probably the best choice for scripts (rake, optparse, fileutils, ...). There's embedded stuff (mruby), music (Sonic Pi), cross-platform GUI apps (e.g. glimmer), game development, and much more. But I'd be interested to know where Python is more useful, apart from science, data science, ML, AI, and such. reply wiseowise 2 hours agorootparentI don't doubt there are many uses for Ruby. But if we're talking strictly about employment, there's literally nothing outside of Rails (quick search of Ruby vs Python in the Netherlands yields 762 vs 20k hits (many of those are garbage, but you get the idea)). Python also has far stronger typing story, it is used as a glue in many orgs (just look at Mozilla, Chrome and countless more codebases), there's also an order of magnitude more people using Python which means far more nicer LLM story. On the other hand Ruby evangelists swear by Ruby like it's the second coming, so there must be something that makes people so happy. I'm trying to understand if it matters enough to pay opportunity cost for switching to Ruby. And yes, I know that you can learn both, but becoming proficient in languages takes time and practice. Ruby isn't something that I'll be able to sell at my org, which means I'll have to invest into it in my own free time. On top of that you have to stay up to date with language developments if you want to stay relevant. reply jaynetics 40 minutes agorootparentI agree to all your points but the stat stands out in particular: > 762 vs 20k hits That's impressive! I guess the difference is smaller here in Berlin as we have a lot of rails shops, but internationally speaking, your stat might well be representative. There might also be less competition in the Ruby job market, but perhaps not to such a degree to offset the difference in job numbers. In the end, Python is probably the safer and more career friendly option, especially if you're interested in AI. However, if you enjoy coding, Ruby is IMHO the top choice to maximize this enjoyment. I don't think it's the second coming, but there's no other commonly used language where you can do things as easily and so without bending to any limits of the language. The downside of this power is that you're never done learning about it. Maybe people who are drawn to coding as a hobby are more likely to enjoy Ruby than those with more of a separation between work and private interests. reply phoronixrly 19 hours agoprevThe essential convention over configuration ideas still prevail when you want to pile on functionality quickly and without boilerplate. reply FigurativeVoid 18 hours agoparentI was going to write a bite more about convention over configuration in regards to AI, but it didn’t feel super tight. I think that the doctrine of convention over configuration leads to content that is much more legible to LLMs in training. I find querying Claude for Rails issues to be really helpful. I suspect would be very helpful to a novice. reply loktarogar 17 hours agorootparentAi also works better with more mature frameworks that have a lot of examples/questions/posts on the internet where the API has been mostly the same for a while, like Rails reply hk1337 18 hours agoprevI’m curious on others thoughts on whether or not to use Devise? With the recent Rails updates, even in Rails 7, Devise didn’t seem that useful and seemed to over complicate the user authentication, registration, lost password experience and also seemed like I had to do a lot of work overriding their views to fit with my application. It seemed easier to not use Devise? It had its usefulness in earlier versions of Rails but not so much now? reply stouset 16 hours agoparent> over complicate the user authentication, registration, lost password experience As a SWE and infosec guy, please don’t just roll this stuff yourself. Maybe Devise is more complicated than it needs to be, but a lot of this stuff is far more subtle than people realize and trivially easy to get catastrophically wrong. I’m absolutely certain a lot of the parts you think are unnecessarily complex are the result of having gotten it wrong before. How do I know? Because I’ve personally submitted vulnerabilities to Devise (specifically the lost password flow) that ended up getting a redesign to fix the vuln. So even if you don’t use Devise, please use some other project which has already suffered through iterating over vulns so you don’t have to. reply jwcooper 17 hours agoparentprevI figure if it's good enough for login.gov [1], it's good enough for my sites as well. I also find devise pretty simple to get setup and use. It's so easy to mess up some small thing while writing your own auth. I've always pretty much trusted myself to at least get devise setup properly. [1] https://github.com/18F/identity-idp/blob/main/Gemfile#L30 reply peteforde 9 hours agoparentprevAcknowledging that I haven't had a chance to try the new Rails 8 auth stack... over the last decade I've gone from being a Devise hater to a Devise lover. Yes, it can seem esoteric and magical (in the bad way) until you wrap your head around the idioms and design philosophy. There's a lot of functionality that happens unless you override it. I fully get that this rubs a lot of people who aren't in the pool the wrong way. However, in addition to the impressive selection of modular capabilities mentioned elsewhere in this thread, there's a very bright light that goes on when you realize that you can make powerful changes to the way the library works by reopening a few controller classes and defining your own methods. My strong advice for anyone looking at Devise and perhaps feeling stumped is to open up https://github.com/heartcombo/devise/tree/main/app/controlle... and spend some tens of minutes looking at how the library does what it does. These controller - especially sessions and registrations - contain all of the business logic driving the \"magic\". Not only do they reveal themselves as relatively simple and well thought out, all of those yield calls mean that you can call those methods while passing a block to them. Whatever is in that block will be evaluated inside of that method when it runs. The people who designed Devise put a lot of thought into this stuff. When you get it, you suddenly don't want to be without it. reply Glyptodon 15 hours agoparentprevI don't like Devise. Rodauth covers similar ground in what seems to be a slightly better way. I know there are some other options. My pet peeve with most of the auth solutions is that they tend to be extremely coupled to hard-coded emails, which makes it varying degrees of annoying to use third party tools for the parts of a product funnel that intersect with auth and also to integrate SMS cleanly. But I guess I'm the kind of person who finds it annoying to override a \"send invite email\" method with something that triggers events or sends an SMS instead just because it's not really what it says on the tin at that point. reply theonething 16 hours agoparentprevSome simpler alternatives to consider: Rails 8 comes with a basic auth generator: https://www.bigbinary.com/blog/rails-8-introduces-a-basic-au... There's also https://github.com/lazaronixon/authentication-zero that goes beyond that. reply Ocha 18 hours agoparentprevMy experience is opposite. Getting devise up and running is very easy. Adding OAuth for GitHub, google, and other providers is also very easy. Editing views is pretty straightforward - you can put your forms or whatever you want - just post the form data to devise endpoint and that’s it. All in probably will take 30 minutes to set it up. reply loktarogar 18 hours agoparentprevDevise bakes in a lot of knowledge about auth. You probably don't need it for a simple app. As your needs grow, when you need things like social logins, Devise makes that easier. If you get really big you probably will have to build out something bespoke anyway. So Devise is sort of for the middle of the journey. reply cjk 18 hours agoparentprevFor very simple username/password authentication, what Rails 8 provides is probably sufficient. But the moment you need other auth providers, 2FA, etc., Devise is very much still useful. reply hk1337 17 hours agorootparentInteresting, I hadn’t really thought about using, or knew, it could handle that type of authentication. That’s good to know reply dartos 5 hours agoprevFor those of you with a functional bend, check out elixir and phoenix. Elixir very similar to ruby in syntax and Phoenix very similar to rails in functionality. The creator of elixir (Jose Valim) was a core rails contributor back in the day IIRC reply cal85 5 hours agoprevAnyone know any good hosting options for little personal, experimental Rails apps that might not go anywhere (i.e. that I might well lose interest in but forget to cancel)? I’ve always liked Vercel’s approach for these kind of side-projects, as I don’t have to worry about cancelling anything if I stop using it. But I guess that is a perk of it being serverless, which precludes Rails. What’s the next best option, something suitable for small, database-driven Rails apps? reply azuanrb 1 hour agoparentYou're correct. You need a server, so Vercel approach with serverless are not applicable here. As for the hosting, any VPS should be fine. I host mine on Digital Ocean. You can use Kamal to setup for database too. Or if it's simple enough, sqlite is great. reply softwaredoug 5 hours agoparentprevI just use Fly (http://fly.io) for toys... and it works pretty well. Have not tested at scale / reliability for a real thing. reply 94b45eb4 15 hours agoprevRuby and Rails anre amazing. I love Rails and recommend it for most small to medium sized projects. What I find frustrating though is the constant hum of people using “Ruby is slow” as the excuse for every problem they have. Everyone I know using Rails is in the process of convincing everyone that they have outgrown its capabilities and need to move onto something “more mature”. I also see a lot of people using Rails but replacing its components with others. A. If part of what makes Rails powerful is that it comes with pretty much everything you need, replacing them without good reason (there usually isn’t one) erodes the value you get from Rails. reply lylo 10 hours agoprevRails is wonderful and I’m thankful for what the community (and DHH) has done over the years. My company (founded 2007) was built on Rails and that B2B app now has 200,000 customers… all on a Rails monolith, the same code base that has evolved with Rails over the years. It’s not just for side projects! That’s said, I run my current side project on Rails 8 and Postgres (I don’t get on with SQLite). You can do so much with so little code! Inspect the source code here if you like :) https://github.com/lylo/pagecord reply jilles 18 hours agoprevIf you replace the title with Django it still works. I’m doing the same as the author, but with Django. reply najarvg 17 hours agoparentNot hands on with Django (or other Python based frameworks) so pardon the basic question. How do the speed of the generated application compare with the speed of a generated rails application? I know the latter has made some strides recently.. reply sroerick 12 hours agorootparentI built a data app one time and one of my devs spent a lot of brain cycles trying to get data to process a little bit faster. We were getting data through a partner who restricted our data access through an API, where we were limited to 100 records per call. Turns out discussing Spark vs Duck DB isn’t helpful if 99.9% of your software latency is from having to make 750,000 HTTP calls every weekend to run your BI pipeline. For the record, that API was a Rails app - but it was certainly not the fault of the framework in that scenario. Point being, for web apps, I don’t think it matters unless you’re in the top 100 websites, and even then it probably doesn’t. Complaints about htmx efficiency always confused me for this reason. Your app isn’t slow because you rendered HTML instead of JSON. Sorry to digress, others may know better than I do but this one is just my experience. The only time I’ve run into computation speed bottlenecks in either was doing data analysis in Python, and you usually just bring in Python libraries that aren’t written in Python like polars or DuckDB. Sounds dumb, but it works pretty well. Standard practice has always been for me that long running tasks get sent to a job queue anyways. So ideally nothing in the UI is dependent on something that is long running. But again, in my own work any long running tasks is almost always limited by network latency. reply rednafi 17 hours agorootparentprevPython is generally faster than Ruby, especially in the newer versions. That said, we’re still talking about two of the slowest languages out there, so the performance gap probably isn’t that big. reply ismailk 16 hours agorootparentThis was generally true before the introduction of YJIT, but with YJIT, Ruby's performance has improved significantly and may even outpace Python in some scenarios[1]. [1]: https://benchmarksgame-team.pages.debian.net/benchmarksgame/... reply rednafi 15 hours agorootparentYeah, Python 3.13 got some great performance improvements as well. But both languages are quite sluggish compared to something like Go and even Node. Also, while I like Ruby, other than RoR, I wouldn’t opt for it to build something. reply pjmlp 7 hours agoparentprevLikewise I keep doing the same but with Spring and ASP.NET, depending on the project. reply nickjj 6 hours agoprevOne thing I don't get about the current Rails direction is pushing hard to use SQLite and removing external dependencies but at the same time also advocating to use Docker. Running Postgres and Redis in Docker is a matter of adding a few lines of YAML to a file once and never thinking about it again. I have done this for 10 years, it is painless. I'm all for reducing moving parts and would also choose the same strategy if there were no down sides but DHH is running their apps on dedicated hardware with some of the best performing SSDs you can get. Most VPS providers have a lot worse disk performance. There's also downsides to running your DB (SQLite or Postgres) directly on your single VPS when it comes to uptime. If your server is stateless then you can upgrade it with zero downtime. All you have to do is spin up a new server, provision it, add it to DNS, wait a day or 2 and then decommission the old one. This is nice for resizing instances or big OS updates in a zero risk way. You can just make a new server. That works because it doesn't matter if the old or new server is writing to your externally hosted DB. If your DB is directly on the host or using block storage that can only be connected to one instance at a time then you can't spin up a new server since one of the DBs will get out of date. reply wiseowise 4 hours agoparent> I have done this for 10 years > it is painless Huh, I wonder why. reply nickjj 2 hours agorootparent> Huh, I wonder why. I didn't start with 10 years of experience if that's what you mean. A basic Redis config inside of Docker Compose could be: services: redis: image: \"redis:7.4.1-bookworm\" restart: \"unless-stopped\" volumes: - \"redis:/data\" volumes: redis: {} Now you have Redis running with your project and you can use \"redis\" as the hostname to connect from your app. It even persists to disk with a volume if needed. It's similar for Postgres except you'd also want to set the PG username and password with environment variables so your initial user and DB get set up with reasonable defaults. A working version of this is in my Rails starter app at: https://github.com/nickjj/docker-rails-example It sets a few more properties but those aren't essential to get going. reply anthony_franco 18 hours agoprevI agree with everything except for Kamal. I'm happy to have someone else handle the server side maintenance. Maybe once my service grows so huge that handling it myself makes sense moneywise, but starting off that way is overkill when there's such affordable alternatives. reply sroerick 12 hours agoparentAnother thread just said basically the opposite, that it was easy to host multiple sites, and sold me on Kamal. I get not wanting to do it, but I just spent 10 minutes writing a basic HTML page and 90 minutes trying to get GitHub pages to do SSL and I’m still not sure I got it. So if I have to do a little brain damage to configure Kamal but then can push sites to it easily? I’m in reply Ocha 17 hours agoparentprevI thought 2024 was very underwhelming for Rails - not really big advancements besides Kamal and Kamal should not have been part of rails to start with. If rails team wants to work on docker deployment tool, they can - just don’t call it rails feature reply trevorhinesley 13 hours agorootparentGenuinely, I don't understand this take. 2024 brought huge additions like Solid Cache, Solid Queue, and Solid Cable, the stable version of Strada (Hotwire Native) which completed the current vision for the Hotwire stack, in addition to Kamal (let's not sell that short, because whether you personally like it or not, it's a fairly robust tool for what it's meant for) and other niceties. Even if you don't like one/all of these, I don't understand seeing these as small advancements of the framework, particularly in a single year. reply dzonga 11 hours agoprevfor auth - instead of devise or the rails 8 auth - you can also opt for authentication-zero. what's hardly ever mentioned is how great hotwire is. it takes time getting used to, documentation is sparse but oh man oh man - hotwire is nice. you get to skip a majority of spa shenanigans. reply chooma 11 hours agoparentI am really struggling to get hotwire running to be honest. I now just postponed implementing it till after the launch. Any good ways of getting up to speed on hotwire and debugging it? reply ignurant 1 hour agorootparentA lot of people seem to overcomplicate it by bringing their thoughts on how other modern js apps are written. It would be helpful to have a specific example of some of the things you need to work through. Reading through the [handbook](https://hotwired.dev/) should get you most of the way there. One of my colleagues recently switched from mostly react to default full stack Rails. He was really struggling with how to filter things in a table. When I showed him how I would do it, his comment was along the lines of: “I can’t believe how simple this is. Modern JS just doesn’t work this simple any more. This is like how jquery used to work but way more organized”. I can’t say I know enough about modern js development to validate that comment. He noted something about expectations of how the dom managing things… So, if you’re coming with a certain mindset of how to do things, try to leave that behind a moment and read through the handbook. Especially if it involves making fetch requests to do things. That’s like, the number one “you probably shouldn’t do it like that” in Hotwire. reply thathoo 16 hours agoprevI 100% agree. I have been able to get started super quickly with small projects using Rails. Such a blessing! reply jchw 18 hours agoprevDon't really know much about Rails because I wound up picking Django instead when faced with the choice many years ago. That said, honestly, my perspective of Ruby on Rails has been tainted by watching GitLab get pwned over and over and over. My distro can barely keep up with GitLab being pwned because by the time the security release hits stable channels there's already another CVE. I liked GitLab, but something is deeply wrong. Of course clearly not all apps are GitLab, but GitLab is the only Rails app I run, and must be one of the most problematic software I've ever deployed for security patching, and most of it seems to do with issues in the Ruby side of things. What makes GitLab so uniquely crap at security, and how do you avoid it as a Rails developer? reply _jss 18 hours agoparentAs a counter-point (and I know nothing about Gitlab), but GitHub and Shopify are both prominent Rails apps with pretty good security records. GitHub wrote about it last year: https://github.blog/engineering/architecture-optimization/bu... I think the answer to your question is the same as any large application: pay attention to your supply chain, architect your systems well, if you don’t know how to do things securely go learn before building (or learn as you go, but that has consequences typically). reply jchw 17 hours agorootparentOf course, it's definitely not impossible to write secure Rails apps, just like anything else; it's hard to know from the outside what that says about Rails in particular. For example, PHP had a lot of rough edges, but Facebook still managed to take it to the highest heights as far as websites go. I'm not arguing Rails is like PHP, but I see a commonality: - PHP had a really good developer experience (even with the rough edges, for the time), but building robust applications on PHP could prove quite challenging. It has gotten a lot better, but there are still remnants all over from the past. - Ruby, likewise, seems to have a really good developer experience, and indeed it seems Rails apps sometimes suffer with robustness and reliability. Not just GitLab, but also Twitter in the past, too. I think some people may read what I'm saying and think I'm just a hater, but not really. I actually just wonder if what I see with GitLab is telling us more about GitLab, or if it's telling us more about Ruby or Rails. Is it hard to make robust Rails software? > I think the answer to your question is the same as any large application: pay attention to your supply chain, architect your systems well, if you don’t know how to do things securely go learn before building (or learn as you go, but that has consequences typically). This is good general advice but I am aiming more specifically. I'm wondering if anyone with more expertise could answer to what classes of issues you have to work to avoid. I know Shopify was working on gradual static typing for Ruby: is dynamic typing a problem? That sort of thing. Of course, you can write both secure and insecure code in any programming language in many different ways, but some ecosystems make it easier and harder and I think that's more what I'm getting at. Frankly, even if it's true that it's tricky to make Rails apps secure, that wouldn't really dissuade me from still using it in some cases if it seemed like it could save me a lot of time and effort. That's pretty much exactly why I used Django to begin with; I definitely don't feel like Django was the most robust platform to write webapps in, just a very productive one (that was still decently robust in my experience, but you know, YMMV.) reply tyre 17 hours agorootparentRails has excellent defaults out of the box for security. You have to go out of your way to explicitly get around them, like with parameter whitelisting and SQL sanitizing. I don’t see as many CVEs, at least to my knowledge, with GitHub or Shopify. Not that they haven’t happened, but seem to _much_ less. Stripe is mostly ruby, though not rails, and have done well with security. My suspicion from outside of Gitlab is that it’s a quality and prioritization problem. Security is hard. It requires very deliberate decision making and investment. Ruby and Rails are generally very stable, but you can use them to crazy ends if you allow yourself to. reply rkerno 17 hours agoparentprevGotta say, this comment is spot on. I had a small peek under the covers when another of the major severity issues surfaced and the conclusion reached is that the software is fragile as f*k. I'll be migrating as soon as I have some spare cycles. Still no conclusion as to whether Rails, Ruby or GitLab is the major contributor, but the result is awefull. reply VeejayRampay 7 hours agoprevRuby and Ruby and Rails are really having a revival recently I guess the work on performance and tooling has paid off and people are starting to realize that if python can have the spotlight then ruby (overall a better language) might deserve it too reply patatero 14 hours agoprevTitle says \"everything\" but author didn't mention Android/iOS apps. reply mattl 14 hours agoparenthttps://native.hotwired.dev/ — I’m curious how well this works reply kissgyorgy 11 hours agoprevSame for Django+SQLite reply rglover 17 hours agoprev> Rails is not dead; It's better than ever. Try using it to make something new this year. I hope as an industry we can move away from this \"___ is dead\" talk. The OP shouldn't even need to say this. If something is being worked on (in any capacity) and has at least one user, it isn't \"dead.\" \"Is it dead\" is groupthink questioning that leads to great ideas being swept under the rug because they're not perceived as popular enough. Think for yourself and use the tools that make sense to you. reply mrinterweb 12 hours agoparentAgreed, but we have all seen the numerous articles about \"rails is dead\" over the last 5ish years. Devs were really buying that idea and wouldn't touch rails, because the whole dead thing. I tried hard to find an alternative that could sway me away from rails, but I could not find anything I felt nearly as productive with or enjoyed more. I'm kind of relieved rails is having a comeback. All of the good stuff of rails never really left. People just got too pulled into SPAs and microservices, and rails 8 just showed many who are paying attention how much better things can be. The group think of SPAs and microservices has been crazy to me. I don't think devs took the time to fully consider how much complexity they were accepting with SPAs and microservices. Certainly SPAs and microservices have their place, but not for everything. reply bdcravens 14 hours agoparentprevAvailability of resources and talent are very real concerns. reply FigurativeVoid 17 hours agoparentprevIt’s also a bit of a joke to ask if Rails is dead in the community. reply anonzzzies 16 hours agoparentprevSomehow if something didn't have a commit in the past 2 weeks and/or it wasn't top HN for a few weeks, it is dead. Might be if you are resume grifting, however if you just need something that works and is stable, there are many things that have this. We use many packages that have not have updates outside security for years: they don't need updates as they just work. I prefer it that way; updates just to show updates/commits is very lame and somehow a very javascript and open source investor community thing; 'must show progress, let's just change shit that doesn't need changing and break things every minor release for no reason at all!'. But then it is 'not dead' somehow; for me reading a changelog with breaking api changes that don't actually bring new functionality is a good reason never to touch it. reply kuduebrahim 17 hours agoparentprevRight, I agree. But Perl is dead… reply rglover 17 hours agorootparentIs it? https://jobs.perl.org/ I don't use it and you may not but it still has an active community and job listings. The last release was on December 20th [1]. This is what I'm talking about: it may not be popular in a \"bleeding edge\" sense, but it's still being used and developed. [1] https://dev.perl.org/perl5/news/ reply bdcravens 14 hours agorootparent\"Dead\" languages still have codebases that need to be maintained, and companies already invested that need new development may lean on the expertise the company already has, but this is more a sign of subsistence, not thriving life. reply theonething 16 hours agorootparentprevuh, it's got a total of three jobs on there currently with two of them over a month old. reply fragmede 17 hours agorootparentprevRaku's doing alright though reply shortrounddev2 15 hours agoparentprevMany people choose what language to invest time in based on the labor market for that language. Companies shouldn't be so religious about the languages they use, but for small teams they usually pick one language for the entire company so that devs can hop between projects without any linguistic learning curve. Hence why there are so many Node + React companies out there; you hire a bunch of react bootcamp grads and they can quickly start working on backend features as well since they already know javascript. In an ideal world, you hire engineers who have a breadth of knowledge of programming instead of specializing in one language/framework, and then it doesn't matter if a language is \"dead\" or not, you just pick the best tool for the job. Unfortunately, there's not enough good engineers to go around for such a strategy. As it stands, I would estimate that most people employed with the title of \"Software Engineer\" barely know what they're doing reply bluecheese452 6 hours agorootparentI would suspect the same in any job. reply kylecazar 17 hours agoparentprevI agree with the general sentiment. But, ecosystem/popularity can matter (you didn't claim it doesn't, just saying). Specifically, it might be useful to know if a once very popular (dominant in some circles) framework is significantly less so. That downward trend might be relevant for someone, somewhere. \"Dead\" is still probably not the right word. reply gjsman-1000 17 hours agorootparentMore accurately: “Established” versus “Trendy” technology. Maybe it’s stereotyping, but I strongly suspect users of Trendy technology are more likely to be vocal about it, including by answering surveys, and especially in online forums. I’m personally a PHP developer, one of the least Trendy technologies, and you’ll never see me loudly talking about it like a JavaScript developer. The internet, and frankly HN, would tell you that a language with over a billion Docker pulls isn’t worth learning. reply bdcravens 14 hours agorootparentDepends on the frameworks more than the language. Ruby is dependent on Rails, Javascript on Node and the various front-end frameworks, and PHP on Wordpress and Laravel. Not to say that there isn't vanilla development happening in each of these, but that's not what drives adoption. (Especially when you use upstream dependencies like Docker pulls as metrics) reply darksaints 17 hours agoprev [–] > Rails is not dead; It's better than ever. Try using it to make something new this year. Apparently that's one of the few things you can do well with a rails app. As evidenced by all of the rails apps stuck behind 3+ major versions because refactoring or upgrading without breaking everything is damn near impossible. reply bdcravens 14 hours agoparentIn the past year I've worked with a couple of codebases upgrading multiple versions, and it wasn't that much work. The upgrade generator lets you step through each changing file, view diffs, allowing you to edit files manually if you edited the core config files extensively. In general, the more you edit those core config files instead of extending via initializers, the more painful it is, so perhaps you've worked with codebases where there wasn't a lot of discipline. reply hatsix 16 hours agoparentprevI rant about rails, often, but this is just a full on garbage comment. Your evidence is \"all of the rails apps stuck\"... where exactly? like... you have a listing of these? Or are you just making things up? I've done a ton of rails upgrades in my career, they've all been easier than any other framework (except the current batch of js/ts frameworks that use codemods to update the majority of breaking changes). DHH has been making some pretty wild changes with non-Ruby parts of Rails, but Rails 8 still fully supports sprockets, their asset pipeline introduced 15 years ago. All of the other asset pipeline alternatives are still supported, even though Rails introduced \"Propshaft\" as a replacement. The only thing we've had trouble with upgrading has been when Rails added full support for read/write shards... it wasn't fully compatible with Aurora Serverless at launch, but we had wanted to migrate off that anyways. So.... try adding some signal instead of just noise. Cite specific issues, rather than just try to ride a bandwagon. reply Glyptodon 15 hours agoparentprevI've had a much better time moving Rails code bases through version and library changes than JS, PHP, or Python ones. But I think that might be nothing more than Rails code bases being more likely to have some sort of test suite that covers some meaningful application surface. reply criddell 16 hours agoparentprevI manage a Redmine installation (a Rails-based issue tracking package that’s amazing). I’ve been upgrading it every year for close to ten years now and every upgrade has gone smoothly even though I know almost nothing about Rails or Ruby. reply dudeinjapan 16 hours agoparentprev [–] I upgraded a large Rails app from 3 to 5 using a flag ENV[\"RAILS_NEXT\"] everywhere in my code and a few monkey-patch shims here and there (easy to do in Ruby.) We ran with the ENV var set in staging for 3 months before flipping it in prod, it was fine. Upgrades since version 5 have been much easier. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Rails 8 is optimized for small projects and single developers, offering a comprehensive \"Getting Started with Rails\" guide to build full-featured applications.",
      "SQLite is now production-ready in Rails 8, reducing the dependency on PostgreSQL or Redis, and includes basic continuous integration (CI) configuration with 2000 free GitHub action minutes.",
      "The new authentication generator and straightforward deployment with Kamal make user sign-in and live app setup with SSL easier, promoting best practices."
    ],
    "commentSummary": [
      "Rails is a popular framework for web app development, known for its simplicity and efficiency compared to other modern stacks like Spring Boot or Micronaut. - It is favored for quickly building full-stack web apps, with integrated features like ActiveStorage and system tests, making it ideal for solo developers and small teams. - Despite ongoing debates about its relevance, Rails continues to evolve with recent updates, enhancing its capabilities and maintaining its appeal in the development community."
    ],
    "points": 325,
    "commentCount": 203,
    "retryCount": 0,
    "time": 1735765084
  },
  {
    "id": 42573875,
    "title": "Where to Work After 40?",
    "originLink": "https://news.ycombinator.com/item?id=42573875",
    "originBody": "I turned 40 last month and spent the past decade working on my own startup that ultimately failed. I&#x27;m now trying to figure out the next step. Someone once said to me, Google is the place you go to retire after 40. I&#x27;ve done my time at various startups, and spent some time at Google. As an engineer the landscape of things is always changing and we&#x27;ve now moved from Cloud to AI pretty rapidly. I&#x27;m just curious to know what moves people made after 40 and what worked for them.",
    "commentLink": "https://news.ycombinator.com/item?id=42573875",
    "commentBody": "Where to Work After 40?230 points by asim 6 hours agohidepastfavorite192 comments I turned 40 last month and spent the past decade working on my own startup that ultimately failed. I'm now trying to figure out the next step. Someone once said to me, Google is the place you go to retire after 40. I've done my time at various startups, and spent some time at Google. As an engineer the landscape of things is always changing and we've now moved from Cloud to AI pretty rapidly. I'm just curious to know what moves people made after 40 and what worked for them. scrumper 5 hours agoI have a couple ideas for you from my own experience. There's about a bajillion C/D+ stage 100-500 person software companies in any B2B vertical you could mention who would fight hard for your type of experience. Not necessarily SaaS click-and-drool tools for corporate drones, but unique and opinionated products that have some significant engineering innovation inside. Those companies have essentially no ability to attract talent organically, anyone interested in FANG would turn up their noses, and their number one problem is quality people. In many cases the CEO/CTO leadership is incredibly strong and smart; the colleagues are happy, motivated, intelligent, and disciplined; and the work/life balance is good for the middle aged. They're vital to their customers but under continuous competitive pressure so it is far from a snoozy place to serve out time - it's a mission and a struggle every day, things change often, the pace is fast. It can be very rewarding and compensation is decent. The tradeoff is the big exit is vanishingly unlikely. Second idea is go into consulting/professional services. Not Accenture or anything horrible like that, but dozens of boutique/smaller firms with decently inspiring leadership and a very high standard of colleague. Work is variable in interest and environment, pressures are somewhat unfairly around whether you are billable or not which is not really in your control as an engineer. reply InsideOutSanta 4 hours agoparentThis. I'm now working at a small- to mid-sized (~80 people) local B2B company. Pay is fine, they offer 100% WFH if you want, but they also have nice offices, they make good and stable revenue with reasonable growth targets, the actual work is somewhere between interesting and mind-numbingly stupid (e.g. integrating with poorly documented enterprise software - can be fun, but can also be aggravating), people are mostly happy. There is a focus on delivering for clients rather than following processes. I have about an hour of required meetings a week, 15-30 minutes technical meetings where people bring up any tech roadblocks or things where they need help, and a 20-45 minute sprint planning meeting. There's one monthly \"show cool stuff\" meeting for the whole company where everybody can voluntarily show something interesting they made. The rest of the time, I'm writing code, documentation, helping coworkers, talking to clients, stuff like that. There is very high trust, e.g. people make honest effort estimates and there's no punishment or bad feedback if they're missed. There's a wide variety of skills because it's hard to attract top performers. This makes it easy to get hired (they immediately invited me for an interview after I sent them my CV, and made an offer after talking to me for 30 minutes), and it also means there's a culture of helping people and being patient and understanding when people are making an honest effort, but don't quite get things on the first try. I'm working eight hours a day, five days a week, and when I'm done with work for the day, I don't think about it until the next day. It's nice. reply brainwipe 2 hours agorootparentThis has been my life for the last 10 years and I know who my children really are. They're evil and I love it. reply PaulHoule 2 hours agorootparentIf you let that (evil) go too far you'll regret it. reply grajaganDev 14 minutes agorootparentprevA reasonable interview process is huge - avoid the Leetcode charade. reply icedchai 1 hour agorootparentprevThat place sounds great. I complain about more than an hour of meetings a day and am told that is unrealistic. This is a small company with under 30 people. Half of them seem to go to meetings all day long. reply xivusr 1 hour agorootparentprevThis is a great job ad - are they hiring? reply InsideOutSanta 14 minutes agorootparentYes, but there's a 99.9% chance they can't hire you, because you live in the wrong country :-) What I would do is look at local governments, at local municipalities. They often have public calls for bids for software projects, like digitizing some forms or processes. Stuff that's too small for big corporations to care about. Look at the companies that apply for these projects. They're often small, local, stable, and starved for good software engineers. reply jb74427442 2 hours agorootparentprevHi InsideOutSanta, This sounds like a place I'd enjoy working at. Email is HN username at gmail. Thanks reply dhd415 3 hours agoparentprevMy longest employment stint was at such a company and it was a very good experience for me. That said, even though I worked at such a company for a while, I don't have a very good idea how I would go about identifying other such companies with open roles. Any suggestions on how to do that? reply cloverich 1 hour agorootparentVC firms often have recruiters that are familiar with the stage and quality of their portfolio amd can provide warm introductions. Last go round I gave them my criteria (no moonshots, solid revenue, post series A, no crypto) and had several quickly lined up. reply tomrod 3 hours agorootparentprevI wonder if Crunchbase would be useful here? reply mcmcmc 24 minutes agorootparentFor identifying companies by size/funding/vertical sure. Been a while since I used it (thank god I got out of sales) but they almost definitely track headcount growth if not actual openings. Trouble is you probably won’t find it in the free version reply bix6 1 hour agorootparentprevResponded to another thread but Pitchbook or Crunchbase can both be helpful. Try: https://www.crunchbase.com/hub/software-companies-late-stage... reply stogot 59 minutes agorootparentIsn’t the Series D or E when a painful restructure or layoffs or pivot occurs or is that a later round? reply leojfc 5 hours agoparentprevI would second the mid-size B2B option here. I found professional services a bit stressful for what the OP is saying. But I also think it’s really personal. Since turning 40 I tried: moving into management at a ~100 dev company; IC at a big tech firm (first time I’d worked somewhere really big as a dev); and now I’m back to running tech side of things at a startup. I don’t think I could have known in advance which of those was going to work for me. There were a lot of positives to the first two, even though I ultimately left. Turns out I actually do prefer a) small places and b) a mix of management and IC work. But I’m absolutely sure that’s not true for everyone. OP might feel like they want something very different from running their own startup – I also felt pretty burnt out on that after 7 years of my own – but once they’ve had some time they might remember why they went that way in the first place! reply karaterobot 1 hour agoparentprev> pressures are somewhat unfairly around whether you are billable or not which is not really in your control as an engineer. Oh, well said there. Worked consulting for 13 years, and this was the main source of stress. You feel like it's your fault—and are sometimes treated by management like it's your fault—because you're on salary and they have nothing for you to work on. Emphasis on 'they'. That feeling of being on the chopping block, unsure of whether you'll be laid off or not, recurred independently about 3-6 times a year. reply mlacks 5 hours agoparentprevwasn't going to reply but you called out Accenture. I work at the Government Contracting arm of Accenture called Accenture Federal and it is by far the best place I've ever worked ( I worked in submarines for a decade so probably nowhere to go but up from there). It ranks highly in those marketing pieces \"best places to work\" if you're into that sort of thing. anyway, I highly recommend Accenture Federal. Great projects, benefits, and WLB reply shulber 2 hours agorootparentI work for Accenture too. It's like any giganto-corp, there are parts of the organization that are great and parts that are not so great. I was lucky to be hired into one of the very good areas. I've worked for a bunch of other Fortune 500s and it's the same story. I think at that scale it's basically impossible to have a uniform culture. reply roland35 4 hours agorootparentprevThat's true there is nowhere to go but up if you're in a submarine! reply rickydroll 1 hour agorootparentSome passengers from the oceangate submersible Titan might have a different opinion. reply pc86 1 hour agoparentprevThe question I always run into for your first point - how do you find these companies? If I want to move into a brand new business vertical, by definition I don't know any of the players or know where to look for that - for lack of a better word - audience. reply grajaganDev 12 minutes agorootparentImagine that you are a customer of that vertical and search accordingly. reply guiomie 1 hour agoparentprev\"C/D+ stage 100-500\" where could I find a list of such companies? reply bix6 1 hour agorootparentPitchbook if you have access/a friend, otherwise crunchbase. I’m on mobile but try this: https://www.crunchbase.com/hub/software-companies-late-stage... reply antisthenes 7 minutes agoparentprev> and the work/life balance is good for the middle aged > under continuous competitive pressure so it is far from a snoozy place to serve out time - it's a mission and a struggle every day, things change often, the pace is fast How do you reconcile these 2 statements? Maybe there's something else you mean by work/life balance? reply mobilene 3 hours agoparentprevThis. 1000% this. I'm 57 and still kicking around the industry deliberately choosing companies like the ones described. It's also important to note that I have a small network of people also working for companies like this who have helped me and sometimes have outright hired me. reply AaronM 2 hours agoparentprevI work for a place very similar to what you described. Its a really good gig reply yodsanklai 3 hours agoprevI don't think anybody can answer this question for you. At 40, you can still do the exact same jobs as someone who's 25 (at least in tech) if you put your heart in it. I don't know what's the expiry date for a SWE, but it's not 40. I'm a median IC in big tech at almost 50 and don't feel discriminated against yet, and for the most part, don't feel incompetent or behind, and feel I'm having the greatest time of my career (although it's demanding). I have no issue learning the same new techs as the younger guys when I need to. I may be a bit slower but it hasn't came up as an issue so far. I also have a few colleagues older than me and they're still going strong. reply stickfigure 39 minutes agoparentMaybe I'm misreading, but this sounds like a defeatist take. Why would a 50yo be slower? I'm in my early 50s and at the absolute top of my game. I'm a principal eng at a medium-ish company and spend a lot of my time mentoring the \"kids\" and providing direction to engineers that don't have the same well of experience to draw on. I would naturally assume that an IC in their 40s or 50s is much faster than someone in their 20s. But that assumes they've actually been doing IC work. I've had a lot of interviews with people that are very experienced on paper but struggle in the pairing interview; whatever they were doing before, it wasn't hands-on-keyboard work. If you enjoy programming I don't see why there's any limit other than senility or death. reply austin-cheney 2 hours agoparentprevWhile many people talk about a bias against hiring ICs over 40 I also wonder if there is a bias to favor people over 40 for promotions. reply IshKebab 2 hours agorootparentIn my experience the only bias against hiring ICs over 40 (at least in the UK) is * They tend to get stuck on old technologies that nobody uses any more. I don't really care about your Perl skills, sorry. * They expect higher salaries. If you keep up to date with your skills (Rust, Typescript, Nix, etc.) and aren't precious about your salary increasing forever then I don't think there's an issue. I've worked with plenty of very skilled ICs into their 60s. reply jghn 1 hour agorootparentIt's not just the UK. As someone who is themselves in the same age range, as a hiring manager it's been eye opening to see the clusters of resumes from older candidates. It continues to boggle my mind how many resumes out there are people who have spent the last 20+ years working on the same set of problems, using the same tech. The reason a lot of these people aren't getting jobs is not that they're old. It's that they've stagnated to a degree I would not have thought possible. Meanwhile there are people out there who are staying relevant *and* bringing extra wisdom to the table. Those people get hired. reply toast0 39 minutes agorootparentOn the other hand, a lot of big tech is solving the same sorts of problems over and over. Someone could be working on instant messaging or a/v conferencing for the past 30 years. Or anything in sales and advertising. Etc. reply jghn 1 minute agorootparentThere's nothing wrong with that per se, especially for a company. I'm only referring to hireability in new roles. If someone is staying in such a role that entire time, especially if their niche hasn't evolved such that it indicates refreshing tech skills from time to time, they shouldn't be surprised if the rest of the world has moved on from where they've stayed. cluoma 1 hour agorootparentprevWhat would you look for to see if somebody is 'staying relevant'? Side projects? Personally, I would like to explore new technologies, and am still excited to learn, but feel limited by what is actually needed/required in my day-to-day which is unlikely to change. reply yodsanklai 2 hours agorootparentprevProbably depends on the company. I think it's not in those big tech companies where everything is quite standardized. In my case, besides my manager, most of the guys discussing my promotion wouldn't even know me personally. Evaluation is very factual. It's more about picking the right projects so you can check all the boxes, also not pissing off colleagues. Same goes for interviewing. I passed several FAANG interviews when I was 45. I just practiced Leetcode like anybody else. Leetcode has its flows, but solving leetcode problems isn't out of reach for an older candidate. Could be harder to find the time to practice, but solving problems in interview situation is a matter of practice. The problems are pretty much known in advance. Edit: Now that I'm an interviewer, I really just ask my questions, and check boxes based on the candidate performance. We're also trained to avoid biases and so on... That being said, I very rarely see \"older\" candidates despite the constant reminder we're an inclusive place. reply meowfly 1 hour agorootparentprevI don't know if by promotions you mean into ic tree also, but it's definitely there for management. My boss who is probably a decade older than me is very much hinting I'm making a mistake if I don't move into management at my age. I think there is probably some bias against promoting a young manager over an older one. I'm currently a team lead and I've resisted a management role. I just don't like managing (or being a team lead), but I'm aware lots of people do jobs they don't like. So we'll see. reply willseth 1 hour agorootparentDo you think you might like management if you knew it didn’t have to be permanent? Highly recommend Charity Majors’ blog about this if you haven’t already https://charity.wtf/2017/05/11/the-engineer-manager-pendulum... reply parpfish 1 hour agorootparentprevinteresting that in the US age 40 is precisely when protections for age discrimination kick in reply 93po 2 hours agorootparentprevThere is probably bias in that social skills tend to be better as you get older, which makes you a better leader and manager in many cases. reply smithbits 4 hours agoprevFor me it was management. I was an SDE who started caring more about the users of my code than about the code itself and that led me to a team lead position and that led to management at a small company and that led to management at a big company. I found I really like mentoring junior engineers and I'm a good sounding board for senior engineers. I got to spend a lot of time saying variations on \"Hey, let's not do that thing that won't work, let's do something easier that will work.\" I also focused a lot more on my career and making money rather than most of my life which I spent focused on cool tech and that got me to a place where I could retire easily when the time was right. Now I code for fun and I still chat with former colleagues from time to time and get to say things like \"Yeah, but you know option B is the right choice so go do that.\" None of it was clearly planned, all of it was stressful but in the end it sort of worked out. reply sarabande 3 hours agoparentCan you share more about your experience regarding how management at a small company lead to management at a big company? Was the switch voluntary, and how did you do it? reply smithbits 1 hour agorootparentThe short version is I got lucky. The slightly longer version is that at the small company I was doing tech lead things because I learned I could get more done to help people by helping organize the other engineers. Then when my boss quit to go sail around the world I was offered his job. I was now a \"manager\" but initially I still acted like a tech lead, writing a little code, taking care of the database, that sort of thing. The nice thing about the small company was they gave me space to learn and lots of mentorship. I got to see all the numbers on the business side and changed from being the \"Let's write something new in Rust!\" kind of developer to being the \"But what's the simplest thing we can do to help our customers now\" kind of manager. Then I got a call from a friend I had worked with many years agi who was staffing up a new org. He needed people and had a very big budget. This is where the \"career\" part came in. I had a job with people I really liked, making okay money and could probably work there until normal retirement age. The new job offer was much more risky for much more money and I was always bad about taking risks. So I took a lot of long walks with my wife and we talked about the upsides and the downsides (upside: _so_ much money. Downside: What if I'm no good at the job?) and in the end I took the job. The job was in another state and my son only had two more years at one of the best high schools around so I got a small apartment and flew home every three weeks. It was an incredibly learning experience. My new manager jokingly explained to me that my new job was people and if I was looking at code I wasn't doing my job. I took that to heart. I met some amazing people. I went to an insane number of meetings. I also got paged awake at 2:00am to be low-key yelled at by a group of Irish people because a computer in India wasn't getting enough network traffic and had run out of entropy. I think I helped some junior engineers with stories like \"Ha! You think that was a screw up, let me tell you about my friend who turned off amazon.com for 6 minutes many years ago.\" And I learned the trick of going toe to toe with a senior architect in a design review meeting by asking \"Okay, but what if these two things I'm picking at random happen at the same time?\" In the end it worked out for me. I saw other people go from SDE to SDM and then go back to SDE after a year because it wasn't a good fit for them. They were better engineers for having spent a year in management, but they didn't like it at all. Also I'm typing all this with the benefit of hindsight and probably making it sound easier than it was. I made lots of mistakes in my career, but going into management turned out okay for me. And now I'm trying to write a Smalltalk VM in Rust and no one in Ireland is waking me up at 2:00am. I got lucky. reply justanother 5 hours agoprevAs someone comin up on 50 myself, I have to say age has yet to be an issue with my career. Maybe I don't go out of my way to advertise it (cut the resume down to the past 10 or so years, don't have a face full of white hair), but I'm still landing plenty of the same ole gigs with Typescript, Ruby on Rails, Python, whatever the flavor of the month is. So I guess my advice is to just ignore it? Of course, trying not to giggle at the 28 year old who thinks they need 4 meetings a day for their precious startup is a different matter. But as long as they pay on time... reply drchopchop 2 hours agoparentNot advertising it is key. I'm also coming up on 50, and people constantly are surprised when they inevitably find out how old I am. Ageism can unconsciously creep in when you have more than 15 years of experience visible on your resume, even for higher management-level positions. Also - if you're a mid-level IC in your 40's you should start asking yourself what's stopping you from being higher up on the IC or management tracks. \"Career senior engineer\" is not a great place to be, long-term. reply Scubabear68 2 hours agorootparentI am in my mid fifties and am closing in on 60. I am half way between IC and management. I stopped emphasizing my full experience around 45, by fifty I was actively avoiding the subject, now I really avoid it. I am fortunate I have a so called “baby face” thanks to my Hungarian dad. I have found more and more that people value me a lot more as a strategic advisor than a coder, and that sweet spot works very well. In that role I can draw on my full 35+ years of experience. Stuff I did in the early 90s still has some relevance all these decades later, at a high level at least if not in the details. Being a coding IC at this age is much harder as they can generally hire someone younger / cheaper with lower expectations and get somewhat similar results. reply radicalbyte 4 hours agoparentprevI'm mid-40s and have a lot of older friends. Age doesn't matter for experienced people. Skill is independent of age. Wisdom usually isn't. reply berkes 3 hours agorootparentAge does matter for experience though. And \"experience\" is what allows one software architect to select the right stack, and the other to select something that turned out to be abandonware half a year later. It is what allows one developer to introduce abstractions in exactly the right place, and another to either overabstract or turn stuff into a tangled mess. It's what allows one team lead to estimate the right time and resources for a project, while the other keeps missing deadlines or burning out team-members. I'm going towards my fifties now. And I have made, or been part of, so many mistakes, failures, errors and stupid decisions. Much more than the average 20-something colleague. I've seen software projects survive 10+ years of continuous change just fine, and others to grind to a screetching halt after even 8 months already. I'm selling this experience now. As freelancer. I still like to write code. But the experience allows me to often not write it in the first place. Or to write very little of it. Or to map out a path that allows us to write it fast today and continue to do so in the next 15 years. reply radicalbyte 2 hours agorootparentAbsolutely.. that's what I mean with wisdom :-) I've been doing the same thing. When I was younger I was a little worried that I'd \"age out\", only until I thought about the older people I was working with. They were either the worst on the team or the best on the team. The latter group were the path I was going down so there risk was small :) reply eludwig 5 hours agoprevIt really depends on the type of environment and work you are looking to do. At 59, I applied for a “full stack” (ugh..not my favorite term) job at a large Asia-based multi-national corporation working on support software (web apps) for their entertainment appliance platform. I got the job after a blessedly short interview process that did not involve any leet coding problems. I am on an amazing senior team at a company with a great, relaxed work culture! This work is many things: fun, challenging, predictable, boring. Devs will understand how it can be all these things at once lol. Find yourself a situation that meets your current drive/ambitions. There are a ton of places out there. Probably harder now (I got the job in 2018), but there are still people hiring. reply Secretmapper 2 hours agoparentThat's interesting, are you based in Asia? I've found companies similar to what you're mentioning but they're all based in America while I wanna stay in Asia. reply eludwig 1 hour agorootparentActually in Los Angeles, but they have offices all over the world. The home office is in Tokyo. reply Secretmapper 32 minutes agorootparentThat's pretty cool. I guess the tough part in Asia are the languages, so there's a language barrier between say Tokyo vs Malaysia vs Singapore. I think the hardest part sometimes of my situation is not really having any seniors/mentor figures I can bounce ideas off. The safest bets from my peer groups all involved just moving to US/Canada which I'm not really particularly interested in. reply daveidol 2 hours agoparentprevAre you working remote or in office? reply eludwig 1 hour agorootparentMainly remote, even though I am about a mile from the office lol. They fully bought into the remote first idea. We have team get togethers generally about once a month. Very nice to spend time with the team, but I prefer my home office with my own stuff for daily work. reply willismichael 5 hours agoparentprev> fun, challenging, predictable, boring All of these at the same time? Or sometimes one, sometimes another? reply eludwig 4 hours agorootparentUsually one at a time, but sometimes they combine. Also, parts of the same task can be one or the other, so you may have to switch from fun (coding something new) to boring/annoying (writing unit tests) in a single day. reply pjmlp 5 hours agoprevFor me, reaching 50, it is all about boring enterprise consulting. You still get to jump around technology, althought it might not be as cool, as whatever newer generations are making use of on startups, but on the other hand seniority combined with such stacks is exactly what many companies are looking for. Naturally social skills also play a big role, as they expect people of our age to also contribute to discussions with all involved key persons, drive architecure and junior devs. You need to lookout for opportunities where you can bring more than plain coding. Given their classical interviews and crazy workhours, I doubt Google is really the place to retire. reply eru 5 hours agoparentGoogle was relatively cozy when I was working there about ten years ago. (But that was as an SRE and in Sydney. I believe the Americans make more of a show of long hours? They always seemed more exhausted in any case.) reply pjmlp 5 hours agorootparentMight be, apparently doing less than 60h or not being reachable during the already short holidays is not doing enough, if the memes are to be belived. reply markus_zhang 5 hours agorootparentWhat about non-SREs? I get SREs need to be always on-call but I'm not sure about other positions. reply chgs 5 hours agorootparentI really don’t understand that - if you have 20 SREs why would you need to be on call more than 3 weeks a year? If you do get called frequently then you should probably be working shifts anyway. reply eru 5 hours agorootparentOnly being oncall 3 weeks a year doesn't work: you'll forget everything in between. It makes more sense to split the work by topic or area or so. But yes, follow-the-sun shifts make sense. reply the-rc 3 hours agorootparentprev20 SREs, assuming two different time zones, means ten weeks per year. You need two people in the same continent for the same 12h shift, so that one can drive, take the train home, shower, etc. Within five weeks, you have gone through the entire team. If your pager response SLO is not that strict and is not impacted by such routines, then you probably can't justify staffing a team of 20, either. reply markus_zhang 50 minutes agorootparentprevI think maybe two reasons: 1. Multiple SREs on-call for the same week. 2. On-call chains make senior ones called more often than they hope so. reply FrustratedMonky 5 hours agorootparentprevBut where did you get the '20' figure from? Many companies have specializations, and maybe only 1,2 or 3 people for each one. So at best you might have some vacation coverage. reply magic_smoke_ee 4 hours agorootparentprevThere's always going into management.. become an SRM today! ;o) reply pelagic_sky 4 hours agoparentprevDepends on the team you're working with. I'm not going to call out names. But some teams are nightmare 60hr weeks and other teams are 30hr weeks. reply jghn 2 hours agoparentprevAre you talking about big companies like Accenture, Deloitte, etc? Or something else? reply pjmlp 2 hours agorootparentI am talking about Fortune 500 consultancy, those aren't the only ones. reply wheaties 5 hours agoprevI've been told there are two places which value experience: 1. A large organization where they have enough people with decades of knowledge to recognize what that is worth. 2. A small startup as head or lead on some domain where they need your knowledge to build their products. It used to be that you could consult but I can tell you from direct experience with this market that it has been flooded with folks who've never consulted but neednwork, e.g. they are charging way too little. The flip side, it's a great time to hire \"cheap\" contract talent. reply bdcravens 3 hours agoprev47 here, and I've worked for the same very small company for about 15 years, in a role where I'm the primary architect and responsible for every layer of the stack. Along the way, I've done side consulting, as much to keep fresh as for the money, primarily for similarly small companies where I usually report direct to the owner. I've been the most miserable when I find myself as a cog in a bigger wheel. The times I've dipped my toes in managing folks it's shined a spotlight on the fact that is not a competency I have. reply billwear 4 hours agoprevAt 60, I applied to Canonical and got hired. The hiring process is thorough but very fair, all WFH, and they generally don't care about personal attributes. Gave me 20% above my asking price and a higher starting rank than expected. reply LambdaComplex 3 hours agoparent> The hiring process is thorough but very fair I thought Canonical was the place where every candidate had to write a bunch of essays and talk about how they did in math in high school (regardless of how long ago that was). Glad you had a good interview experience there, but it's genuinely the first time I've heard of it happening. reply neverartful 1 hour agorootparentI interviewed with Canonical in 2023. It was an enormous waste of time. I would never suggest anyone interview with them while they still have the same interview process. reply wing-_-nuts 2 hours agorootparentprevI would struggle to have a polite response to that question. Come to think of it, the last company that even asked me about high school was a horribly toxic place, and it'd be a red flag that this wasn't a place for me. reply ndiddy 3 hours agoparentprevHow similar was the hiring process you experienced to this summary? https://old.reddit.com/r/recruitinghell/comments/15kj845/can... reply weatherlite 5 hours agoprev> Google is the place you go to retire after 40 I don't get this honestly. About 1%-2% of devs will manage to work at a FAANG, that's it (correct me if I'm wrong). The rest of us will grind code somewhere else. I'm 40 and I'm staying put in the startup I'm currently working for because I like the people and it's not a sweatshop. Eventually I'll find something else. I'm more worried about A.I making me irrelevant than my age. reply bluGill 3 hours agoparent1-2% at a FAANG seems way to high. There are a lot of other companies out there hiring people. Some of them are great places to work, some of them are not. reply dartos 5 hours agoparentprevIs grinding code at a FAANG really that different? reply fatnoah 2 hours agorootparent> Is grinding code at a FAANG really that different? It probably depends on where you're coming from. I was an Engineering manager at a FAANG, and roughly 80% of my 1:1's with my team revolved around their performance, or lack thereof, with 5% devoted to supporting mental health, and 15% around general topics such as what they were working on. I had 3 managers in two years, and with one we mostly talked about strategy, goals, and what we're working on. With the other two, it was always about my performance and that of my team. It was a very high-pressure environment. The types of people who succeed long term are those that are good at playing the game or who naturally will do the required things to get good ratings. In return, you get fantastic pay. I didn't quite hit 7 figures in compensation, but if I'd stayed another year to ride more of the run-up, I would have come close to $2M for a year. All that said, there was some really interesting work and great teams. While it sucked as a manager, I think 30 year old me would have loved it as an IC. reply sharmajai 1 hour agorootparentI am 100% sure that company is the F in FAANG. reply sangnoir 1 hour agorootparentprev> Is grinding code at a FAANG really that different? On paper, code is code. In reality, grinding code at a FAANG has a lot more \"performance anxiety\" and is generally more competitive, and likely worse mental health but pays way more. YMMV by company, vertical, team and manager. reply willismichael 5 hours agorootparentprevI think that the intention of the FAANG comment is that statistically speaking there is only so much room for people at those companies. Not everybody is going to land there. reply lazycog512 3 hours agoparentprevWhere do white males go? Obviously they can't go to Google... reply tyrust 3 hours agorootparenthttps://about.google/belonging/diversity-annual-report/2023/ In 2023, 31.7% of the workforce was white males (page 15). reply 93po 2 hours agorootparenti dont want to contribute to crying over the difficulties of white men, but the more honest stat would be what percent of the hiring in 2023/2024 was white men https://static.googleusercontent.com/media/about.google/en//... the hiring of white people is about the same, and the hiring of men is actually a little bit higher between 2022 and 2023 the interesting take-away here is mostly that there is an increase of hiring of people who are asian while people who are black or latinx are in decline reply tyrust 1 hour agorootparentNo worries, you make a good point. Thanks for the assist. reply kridsdale1 57 minutes agorootparentprevAm white male. Am at Google. Your comment is bad and you should feel bad. reply neverartful 4 hours agoprevI'm in my upper 50s and I resigned from the corporate employee world in spring of 2024. I've been working my handyman business since then. I don't have enough business to keep my schedule full (and not enough income), so I decided to get back into tech on my own terms. I've started developing a software product that I hope to launch soon. No idea how any of this will turn out, but it's the best plan I've got at the moment. reply newprint 1 hour agoparentI would be interested to hear about your experience transitioning to this line of work, since I want to do the same. I'm in my early 40s, software engineer. reply neverartful 1 hour agorootparentWhen you say 'this line of work' are you referring to my handyman business or work to develop a new software product? (I'm happy to discuss either) reply softwaredoug 5 hours agoprevWhat software communities[1] are you a part of and who are you helping in those communities? Do you contribute there in the form of (code, documentation, blog posts, conference talks, helping juniors, etc)? At 40 I think you do well to have a decent network in a focused set of communities of people you've mentored, supported, and worked with. IE folks in a specific discipline, project, thing where you might expect there to be community conferences around or other community institutions. You'd be a mainstay there, always looking to help juniors / new people, paying it forward everywhere you can, etc. Then finding the next job is about those relationships, continuing to help them through the years, etc Don't focus on \"F-You money\", focus on an \"F-You network\" https://softwaredoug.com/blog/2024/05/08/build-an-f-you-netw... 1 - community can mean discord/slack communities, subreddit, projects, on social media, having coffee 1-1 with people, etc etc reply willseth 3 hours agoparentIf someone is looking for a job at 40 and they haven’t already built a big network, it’s not helpful to tell them they should build one. But if you’ve been working for about 20 years you probably do have at least some friends or colleagues you can (and should) reach out to for opportunities. reply jvanderbot 5 hours agoprevI'm 40+ though I try not to act like it. My most recent gig, which is my favorite job to date, is working at a small startup as \"The X guy\", for an X I've worked on for years and years. I suspect you can similarly specialize, if you think carefully about what you did for 10 years. If my current gig weren't an option, I'd try for some of the DoD startups where X is applicable, or I'd try to move into consulting, as others have mentioned, or I'd open my own shop for small businesses nearby, in an unrelated field. Small time one-stop consultants in my area charge more for database admin than I do for X in my PhD field. reply n144q 4 hours agoprevWhat do you care about? Money, stableness, scope or opportunities? I know people who \"settle down\" in companies with well-known work-life balance (usually develop for B2B products). I know many more people who stayed at the same company and climbed the corporate ladder. I know people who jump to a different, big company for better compensation and work in different areas. I also know a small fraction of people who create their own startups -- yes, in their 40s. It all comes to -- what do you want? reply noisy_boy 3 hours agoparentNot OP but I want to help the end users and be appreciated and paid reasonably well to do so. No double-speak, no politics, no manifesto driven development but actually helping people with their problems and making their lives easier without getting killed in the process. How do I find such jobs? reply parpfish 1 hour agoparentprevi'm early 40s and my goal is to work in tech for a couple more years to build up enough retirement nest egg that i can spend the next couple decades pursuing lower-paid non-tech work where i can doing things i find more personally meaningful or maybe even something mindless but more present in my local community. reply vouaobrasil 5 hours agoprevI spent a long time in tech (not 40 yet but close), and my opinion is that technology creates a mechanical mindset that is sometimes a blind spot. Although it might be best for you to stay in it, I suggest testing the waters elsewhere for a bit in a more artistic area. It might be quite fun to take a break. I am frequently in the minority here but I do believe that spending all your life in a narrow domain like technology can be restricting in the journey to figure out what life is all about. reply Tade0 3 hours agoprevI'm a few years your junior but at the same time the youngest in my team. So far it seems that the 40s are the new 30s, because there's nothing notable about my coworkers being in their 40s save for their work experience. And I can imagine why - there were quite simply too few people born in countries with a 95%+ literacy rate over the past 20 years for the usual generational turnover to occur. reply beauzero 3 hours agoprevI accidentally fell into working for state government. Small state relatively and it has been one of the most enjoyable things I have ever done. I am able to help people, again, use technology to make things easier. It is very enjoyable. I can see myself working here until I am no longer able to keep up. I enjoy programming, but more importantly solving problems, and really hope that I don't have to retire. reply remoquete 1 hour agoprevI'm 42 and have been working as a technical writer since I was 26. I'd argue that technical writing is one of those fields where you can comfortably work until retirement. Many in my field think AI will take their job — I think otherwise. I'm now working as a Documentation Engineer, using LLMs daily to speed up my work. But I'm also learning Rust on the side. Guess it'll never be late for that move? reply david-gpu 1 hour agoparent> Many in my field think AI will take their job — I think otherwise. I'm now working as a Documentation Engineer, using LLMs daily to speed up my work. Say that LLMs are increasing your productivity by 20%, just for argument's sake, and that a company used to have six technical writers, but one of them recently left. Why hire a new a replacement when the five remaining LLM-augmented writers can now do the job that six humans used to do? That is how automation often replaces workers: not by doing 100% of what humans used to do, but by increasing their productive output. Maybe you are lucky, maybe the company has an increasing need for writers and keeps hiring them. But maybe the productivity increases from ever-improving AIs are able to catch up with that increasing workload. reply remoquete 53 minutes agorootparentYeah, the increase in productivity thanks to LLMs makes the need to hire a junior writer or a contractor less pressing. Way less. I guess that's why I'm developing my coding lifeboat on the side. reply david-gpu 4 minutes agorootparentGood luck! These are difficult times for workers. Our societies will eventually figure something out, but until then it is best to adapt to these rapidly changing circumstances to the extent of our abilities. reply fresh_geezer 5 hours agoprevI'm in the same situation, 41 and just folded a startup in November after six years and looking at what to do next. My concern is if I jump on another startup and it doesn't go well, I will have even less chance to land a decent gig afterwards. Who knows what AI capabilities will be five years down the line? I have some friends that work in government that could help me get a job there where you are basically unfireable and even get a pension, but the work is not very technically interesting. They all say it's soul-killing but stay for the stability and benefits. Is a large tech company a better bet? I consider my self a very good developer but not sure if I can pass through all filters and the leetcode gauntlet either. Deciding which road to go down is giving me more anxiety than ever before. reply willseth 3 hours agoparentI think you mostly only run the risk of pigeonholing yourself as a “startup person” if you jump on another startup. But startup people value startup experience, so as along as you enjoy startup work and are making solid contributions, I think you have a long career ahead, with the caveat that options to work in a bigger company may be diminishing. Even then, it’s not all that uncommon for big companies to try to bring in startup types to breathe some life into a stagnant culture. Not so much FAANG but there are a lot of other big tech companies with good comp. reply pseingatl 6 hours agoprevAfter 40, it's musical chairs. The music will stop and there won't be a chair for you. McKinsey comes in and says \"cut staff.\" HR comes in, says \"cut 5% and replace them with Desi H1-B's.\" Your best bet is to take a deep breath and build another start-up. In the meantime, take any job of any nature. reply jvanderbot 5 hours agoparentI try to say this gently, but this comment would make more sense if it came from lots of direct experience, rather than (what appear to be) repeated tropes. Have you seen this repeated in your own over-40 experience or the experience of people you know? reply reaperducer 5 hours agorootparentHave you seen this repeated in your own over-40 experience or the experience of people you know? I can't speak for the parent, but that exact thing has happened to me. It's no trope. reply cs02rm0 4 hours agorootparentLikewise. I hit 40, which I didn't think was that old, dropped out of contracting and found employed work has gone from being easy to, well, IME impossible to turn up. reply benfortuna 5 hours agorootparentprevAt best it would be anecdotal, and if not from experience it's an intentionally alarmist and flippant remark. reply tecleandor 5 hours agorootparentprevSounds a bit like IBM. Or like a company going through a private equity acquisition. reply Clubber 4 hours agorootparentprevI've seen it a few times. One company replaced the entire QA department with off shore people from India, this didn't go well. Another replaced a bunch of devs with off shore people in Belarus, this did go well. Disney did it back in 2015 or so. https://economictimes.indiatimes.com/markets/stocks/news/do-... reply jvanderbot 4 hours agorootparentThis happens, that much is unarguable. But replacing departments does not disproportionately affect workers over 40 unless that dept is disproportionately over 40, which begs the original question: How can one find such a dept!? reply Clubber 4 hours agorootparentMedical. reply magic_smoke_ee 4 hours agoparentprevAfter 40, getting hired has a similar to propensity to making friends. Ageism is a subtle, pervasive bias. When I was 20, I looked about 13 and everyone wanted to hire me. reply mihaitodor 1 hour agoprevI worked as a software engineer on various unrelated products since 2007 (mostly SaaS backend and infrastructure, some desktop apps etc). I can still do it, but I have been yearning for many years now to transition to a career in research and spend some time in academia. I switched to open source freelancing last year and now I’m looking for some way to get myself into a PhD on computational biology focused on cancer immunotherapy. Would be cool to work as a research assistant for a bit before I embark on that path. reply daft_pink 4 hours agoprevI’m not sure about 40, but as you get older, the Federal government is a great place to work as they will allow you generous leave if you get sick, great vacation time and good benefits. reply dasil003 2 hours agoprevI made the move from smaller startups to progressively large companies and from IC to manager. My main motivator is to continue to find personal growth, which increasingly means learning about the human side of building software at scale. As I approach 50, a bigger pay check and more stability are of course bonuses, but I find the idea of software engineers \"retiring\" at 40 pretty offensive. It reeks of entitled rest-and-vest culture, and will put you in a position where companies would be right not to hire you. Instead, stay hungry, and find a place that rewards that. reply dddddaviddddd 5 hours agoprevThis should be about what you want in your career now, and not about your age. Once you can clearly answer the first question, it will be easy to find the right place. reply jebarker 5 hours agoparentYou're making an assumption that OP has the financial security to follow their desires rather than needs. reply 9rx 4 hours agorootparentNeither desire or need was mentioned, only want, which addresses both desire and need. If financial security is what the OP wants, the parent comment already has him covered. reply quesera 3 hours agorootparentIf you can coherently differentiate \"want\" from \"desire\", I'd love to hear it. :) reply 9rx 3 hours agorootparentPer the dictionary, want is defined as: \"ought, should, or need to do something.\" That which you ought, need, or should do is not necessarily what you desire. As it relates the conversation, financial stability is not likely a desire in and of itself, but it may be what you need. reply quesera 3 hours agorootparentThere is no \"the dictionary\". E.g.: desire: transitive verb: To wish or long for; want - The American Heritage® Dictionary of the English Language, 5th Edition desire: verb [T not continuous]: (WANT) - The Cambridge Dictionary (et cetera ad nauseam) reply 9rx 2 hours agorootparentYes, words often mean more than one thing. \"want\" has several commonly used meanings, not to mention that the author can define it however he pleases on the spot. reply quesera 2 hours agorootparentRight. So I'm sticking with the belief that you cannot coherently differentiate \"want\" from \"desire\", which was my point. :) reply 9rx 2 hours agorootparentIn context, \"desire\" is defined as what one would prefer to do absent of any financial constraints. With the stated acceptance of reality, one can want financial independence out of need without it being their desire (per the given definition). It may be true that some definitions of \"want\" and \"desire\" prevent coherent differentiation, but as we established, and you willingly agreed, words do allow for more than one meaning... reply quesera 2 hours agorootparentI cannot think of a single case where the words \"want\" and \"desire\" are not interchangeable. One might connote a greater or lesser longing or preference in a given context, but I think that will also vary. To the point: > one can want financial independence out of need without it being their desire (per the given definition). This sentence works equally well with the words swapped. ... Anyway, this is not an interesting diversion. It was intended to point out that the semantics are not worth debating. Hopefully it will be disconnected from the thread and not waste anyone else's time. reply 9rx 2 hours agorootparentBy strict application of the most common use, that is effectively true. But in that case needing financial independence before seeking more lofty careers goals is a desire like any other. The premise introduced in the first reply is a false premise if you want to take that angle. However, to do so shows a gross misunderstanding of the English language. Meanings are not set in stone like that. Meaning is fluid and can change with context. Said reply defines \"desire\" to exclude financial concerns, but maintains \"want\" in the original sense. The intent of the comment is quite clear. It fails by false assumption. With that contextual defining of \"desire', these words are no longer interchangeable. \"Want\" includes the case where one wants financial independence, while \"desire\" is defined, in context, to exclude wanting financial independence. reply snowwrestler 2 hours agorootparentprevI mean, they are different words for a reason. reply quesera 2 hours agorootparentThen differentiate them coherently for me. Ideally with either prescriptivist justification or descriptivist evidence. reply kaskakokos 1 hour agorootparentYou want someone to teach you the difference, but what you desire is for no one to be able to point out a single difference to you. I had to try :/ reply ghaff 3 hours agoparentprevThat actually distills it down pretty well. What's your financial position? What do you want/need your financial position to be once you (maybe, largely) stop collecting a paycheck? Are you OK with not working for a company vs. maybe doing some stuff on the side? Especially once you've thought about your finances, your horizons may open up a lot. I know people who largely retired in their 40s and that may be for you or may be hell. reply pomatic 2 hours agoprevI think the biggest concern for a would-be employer would be: can you take instruction. After a decade of being in-charge, that's going to be a really tough call. I'd suggest consultancy might be the easiest way to transition in to full time employment - at some point you'll find a great fit and they'll offer you a permie role. reply game_the0ry 2 hours agoprevIs there still age-ism in tech? Bc I see plenty of people in IC roles working into their 40s, and even some in their 50s with kids in college. Could be the industry I work with has less age-ism: financial services. reply philk10 5 hours agoprevJust after hitting 40 I moved from being a dev to being a tester/QA I was working at a small company and after almost 20 years there was getting bored - the tech was changing ( from BCPL on a PDP-11 to C and .Net on Macs/PCs ) but I felt stuck in a rut and found I was better at finding bugs than writing them... Got involved with the test community, learned a lot, got myself known and then ended up moving from the UK to Michigan just before I hit 50 to work for a small but growing s/w consultancy reply Apreche 4 hours agoprevAm I the only one still getting e-mails from recruiters all the time? My LinkedIn profile indicates I’m not looking for new work, and yet they still come to me in both personal and my work inbox. If I change that setting on my profile I know I’ll be absolutely inundated by them. Most of them I’m sure are non-starters, but occasionally there is one that is promising. reply javcasas 1 hour agoparentI wish. It has dried up a lot recently, and only getting junior stuff that eventually becomes paranormal (I/E ghosts). reply sreekanth850 3 hours agoprevIam at 41, but I learned 100X in my last 2 years than i was at working in sales for a domestic company for 10 years. Currently pursuing my passion - Startup in workplace collaboration. Moral: Age is just a Number. reply limaoscarjuliet 3 hours agoparentUp to a point and then you start feeling getting older. I started noticing while approaching 50. I can no longer push as much as I used to. I need to take breaks. Etc. reply travisgriggs 1 hour agoprevAt 41, I found a local family owned company with a desire to participate in the gadget space (ie material widgets with electronics for added value) in a relatively niche market (ag automation). It’s a small group, I’m sometimes the only full time software part of the team. We’ve had some wins. At 54, I imagine I’ll retire here eventually. I’ve enjoyed a huge amount of autonomy, learned a wide range of different tech (still doing so) and am rewarded by a company that values me and invests in me (I also get to put up with the drama/dysfunction that can come in a multi-generation company in the back woods of ag). TLDR; go find a niche that is underserved and serve it. You have the breadth to succeed as a generalist now. reply cwiz 4 hours agoprevIndie gamedev. It will feel like early day startups again. And gamedev is so special that every one in a while you switch to a new project, and that again feels fresh. But gamedev is demanding. reply vuggamie 3 hours agoparentAre you building your own products and launching them as a single developer? What platforms are you targeting and what kind of games are you making? How's the revenue? reply cwiz 1 hour agorootparentI'm just 35 so I'm preparing. I've been doing 2-3 game jams per year for last 3 years and developing small plugins for engine I use. I can't transition into gamedev just yet, but it seems that landing a position at gamedev studio will be a logical continuation of career. I'm at the point where I can plan an indie game that could be worth of steam page, but a decent quality game would take at least a year. reply ojbyrne 5 hours agoprevI switched from SWE to SRE in my fifties. The perception is that neckbeards take a long time to grow. reply wheresmycraisin 5 hours agoprevLegacy app maintenance in an obscure tech stack is basically all that's out there reply lnsru 5 hours agoprevI am similar demographics. In parallel to my regular job I am registering myself as self employed electrician (in Germany). For couple hours a week at the beginning and let’s see how it evolves later. reply oytis 3 hours agoparentOut of curiosity: did you already have an education that certified you for the job, or is it something you acquired recently? reply lnsru 2 hours agorootparentI have German university Dipl. -Ing. diploma. I have Handwerkskarte after examination of my university diploma (headshake here) by Chamber of Crafts. I have passed TREI exam. And I have few offers for upgrade of electrical system in my house ranging between 25000€ and 40000€. That’s my main motivation, but I will accept other jobs too. reply trebligdivad 4 hours agoprevI worked for 9 years at one of the large US softy companies after 40; I worked from home. Got promoted a few times, avoided doing management. reply 43t346t345 1 hour agoprevCouldn't tell you. I am 40 with no career off the ground at all. Totally screwed. reply PeterWhittaker 3 hours agoprevI'm 59 and doing the most technical and hands-on work of my life. When I was 40, I was a few years into my consulting gig, and that went very well for a long time (I'm a cybersecurity guy with a strong ICAM and PKI background, located in the Ottawa area, so there was plenty of work with government clients.) But I was starting to tire of the consulting grind and found I was doing a lot of the same-old-same-old in most contracts (TRAs, PIAs, audits, etc., and, after incidents, explaining to senior management how recommendations made 6-12 months previously might have prevented or at least greatly mitigated said incident). I was fortunate: 6ish years ago, I was winding down a couple of contracts through a friend's company and he needed someone to fill a gap and knew I had downtime, so I started a contract with him, 90+% WFH. Every few months we'd chat about where he was taking his company and about what the future product teams would need (he'd bid successfully on a pair of unrelated PoC-to-product contracts, one hardware, one software, and was looking to take things to the next level). Long story short, 5.5 years ago I retired my shingle and returned to full time \"wage slavery\" (tongue firmly in cheek), almost 100% WFH. My initial role was to work with customers, fill gaps, learn fast, build fast, and move on, and our plan was to move me into a business-development-slash-product-management role, which appealed to me because of two previous contracts that had a lot of that (he'd worked on one of those and knew what I brought to the table). You know that old saw about life being what happens when you are making other plans? Yeah, that happened :-> My title now is Director, Special Projects, but what that really means is \"our customers think this is critical, no one has any idea how to do it, make it happen\". It's more a senior/staff engineering position in some ways, mostly systems programming, the levels getting progressively lower (my Christmas holiday reading has been the excellent Mara Bos book on Rust Atomics). I'm far more technical now than ever before, entirely hands-on, and it's fantastic. It helps tremendously that I work with a great team, people I've known for years, but hadn't worked directly with until now, and that our boss, my friend, understands how complex is what we are doing and how we need regular breaks and downtime; at the same time, the entire team knows how important are revenue and deadlines. My advice, if I have any, and it all comes with a strong dose of YMMV, is two-fold: One, it will be OK. You will be OK. 40 isn't the end, nor is 50, and I doubt 60 will be either. I'm pretty sure I'm going to spend the time around my 65th year working on ABE and data filtering in FPGAs, but that's just a guess. :-> Two, work your network. Talk to your friends and colleagues, ask who's doing what, what the gaps are, where they think they are going, and what they might need. You have skills, others need them, do NOT under any circumstances undervalue or dismiss them. I won't advise or even suggest consulting, because it isn't for everyone, and the kinds of contracts that, IMHO, at least, best allow you to explore the space and build a better network, are, by their nature, stressful: short term, possibly requiring travel, and sometimes spread out such that when one ends you don't know when the next will begin. But if you are OK with a certain degree of churn, uncertainty, and repetition, then it might be something to consider. Regardless of how and where you go, remember Advice One: It will be OK, you will be OK, 40 isn't the end. reply faangthrow51727 3 hours agoprevI am at Google (and have been for quite somewhat over a decade now), and am over 40 too. Despite a lot of internal criticism about \"the old Google\" and how things have changed, they are still a very good company to work for in my opinion. Lots of well-known benefits, decent comp, and critically a very good work-life balance (no mandatory work-from-office so far, I probably average about 0.5 to 1 days a week in the office) and laid-back pace. I have been basically doing 8:15am to 3pm for my hours (no discussion with management about it - it's just what I do), essentially logging off at 3pm to go collect my kids and not logging back on after that (although I keep a rough eye on chat and email and jump back on if something urgent/critical comes up) and no one has batted an eye lid at all - so long as the work gets done, people are happy and are not closely monitoring where you are or how you are working. Some of the work is interesting and engaging, other part are more \"meh\" but I think that is true of many jobs really. Yes I might be able to get slightly more money elsewhere (especially fintech) and might get to work on more sphincter-clenchingly-exciting work elsewhere (especially startups) but the quality of life from what is quite an easy ride of things is very valuable to me. Google is quite grown up in many ways and the culture is calm and predictable (on the whole - the recent (year or two ago) redundancies were not predicted!) I'd recommend it. reply CalRobert 3 hours agoparentTo be fair, it seems like getting Google to interview you is a challenge. reply faangthrow51727 3 hours agorootparentNot saying that it is an easy place to get in to - the bar is high, but if you are good enough to get in it is fairly chilled. FWIW I interview a lot of candidates and there is quite a broad range of ages from college grads up to and including folks older than me. The hiring process is flawed in many ways, but they do seem to go out of their way to be fair and equitable regarding age race gender etc. It is no longer \"culture fit\" examined during interview for example, but now \"culture add\" reply reaperducer 5 hours agoprevTech is everywhere. You don't have to work at a \"tech\" company to work in tech. Try healthcare, banking, pharma, or any other industry that has been around longer than the internet. Many big, established companies are used to people who have worked in one place for decades. That means middle-aged people. It's not weird for them, and their experience has taught them to value experience. Protip for anyone: When you interview for a new job, ask how many retirement parties the company had in the last five years. That will tell you a lot about the company. reply cranberryturkey 5 hours agoprevI’m 50 and the offers stopped coming in 2022 reply PaulHoule 5 hours agoparentOffers stopped coming for a lot of people in 2022. reply Jgrubb 5 hours agoparentprevAgree w the other poster, 22 is when the music stopped for most of the industry. reply ghaff 4 hours agorootparentMore optimism may be creeping back in but there's still a lot more hesitancy, caution, and conservatism in my experience than there was for much of the last decade+ (except probably in AI which is pretty hot overall). It's also not clear how hiring is distributed by seniority. On the one hand, I hear that things are tougher for junior people without networks. On the other hand, I hear that filling slots opened up by attrition are tending to go to more junior/cheaper people. reply angoragoats 5 hours agoparentprevI'm in my 40s and I (and the entire team I worked on) was laid off in 2022. After taking a week or so to relax, I was able to find a new position within about 4 weeks, which I'm still at now, and has turned out to be one of the better roles I've had in my career. I realize this is just another anecdote, but don't be discouraged by the other posters here -- companies value people with lots of experience. reply axpy906 3 hours agoprevI am turning 43 and trying to figure things out as well. I am at the point in my life where the most important thing to me is not work. I just want a balanced 9 to 5 without toxicity or high demands. Is such a thing possible in this industry? If so where? reply PaulHoule 2 hours agoprevYears ago I worked at an academic library where software devs over 50 felt really comfortable but people under 40 felt they were never going to be taken seriously. Part of the problem was that to get ahead and be taken seriously you had to have a library science degree but changes in the world made it seem that an applications programmer with DBA experience could be better at taxonomy, ontology and classification not to mention all the skills that were becoming essential for digital librarianship. I could take my skills anywhere, but the librarians had to carve out a place for themselves in this world. The funniest thing was an ambitious 30-something dev who thought he was not getting taken seriously who (1) started studying for an MBA, (2) deliberately gained 30 lbs, and (3) got one of those fancy haircuts where they put aluminum foil in your hair to make grey streaks. That organization was under a lot of stress and something popped and there was enough blame to go around including for myself and I wound up looking for a job. We have a \"workforce development center\" which is sometimes helpful in my town, but this time I was arguing with the councilor that I didn't think I was facing age discrimination in the way he expected. Since then I've worked at a number of places and been the oldest person at a startup a few times. It helps that (1) I am always keeping up with new technology and (2) I've had a long term interest in things like AI and ML (and UX, VR, ...) so when an AI startup needs somebody with 5+ years of experience that's me and (3) I keep an eye on things that are timeless like the fundamental of computer science (e.g. if a Turing machine can't do it an LLM can't do it, but it might bullshit you into thinking it can... is that the real Turing test?), project management, people skills, etc. I worked at one platoon-sized startup where I was the oldest person where I did run into a different sort of problem. Most of the employees didn't really understand or believe in the business model of the company. I believed it because I needed foundation models for the work I was doing in 2010 and knew the world would need them, but this company was a few years too early. We had frequent \"all hands\" meetings where I could easily upstage the CEO because I was older, could look and sound like a leader, was more enthusiastic (got this job because I'd maxxed out my HELOC chasing my own El Dorado.) Ultimately this lead to trouble. reply surfingdino 2 hours agoprev40+ shouldn't make it difficult for you to find work, IMHO. 50+ is where ageism starts to be a problem, no matter what your skill level. Consulting is a viable route, but even though your startup failed, I'd start a business anyway and stash as much cash as you can before you pass 50. reply mymcat 5 hours agoprevyou can email me your resume at kalypso@mymcat.ai reply pseingatl 5 hours agoparentWe need more physicians who earned their place in medical school by gaming the MCAT. Equality has no place in hospitals. reply pryncekarki 5 hours agorootparentHuh? I'm not sure I understand your post buddy. reply nunobrito 6 hours agoprevJust apply to any large companies. reply pseingatl 5 hours agoparentFB gets over 15,000 applications for each posted vacancy. Your cv is weeded out by an automated system that's difficult to game. Even if you have a contact at the company, your odds suck. You are just as likely to win the lottery. Perhaps buying scratch-off cards isn't such a bad idea. reply withinboredom 5 hours agorootparentIf you've ever run a company, you know how bad people's CVs can be and what you need to do to stand out. I recommend it to everyone. I would get 15-20 CVs for a small company, and I didn't even closely look at 10-15 of them because it was clear people were just writing random shit or applying without even looking at what we wanted. I suspect it is a similar ratio for any software company. My best hire ever was a math teacher in a previous career that wrote his own tools. Worst hire ever was a guy with a PHD that thought he was still in university. reply e-brake 5 hours agorootparentSecond this, try to stand out in some way. I mostly receive floods of terrible resumes, spam and obvious LLM generated text. The worst hire I made also had university credentials and apparently wasn't educated in how to deliver anything but academic noodling. reply dan-robertson 5 hours agorootparentprevThe way you write this suggests that for each engineer at Meta there are 15k other people who applied for the job and didn’t get it, so their ~40k engineers correspond to a pool of 600 million potential employees. This is obviously nonsense. There are a few ways to explain your number: - the same unsuitable candidates apply many times. This is not so surprising: suitable candidates get jobs and so stop repeatedly applying - perhaps many people can be hired for a single ‘open position’, eg perhaps one is ‘software engineer based at headquarters’ - if many applicants are from people who are grossly unsuitable, eg maybe you must demonstrate job applications to get some state unemployment assistance - maybe Meta aren’t hiring much at the moment and so it is harder to get in than other companies that are hiring - the number might be misremembered The downside to applying is trivial so even if chances do seem low, it can still be reasonable to apply. I think the probabilities implied by the comment I’m replying to are so extreme that you should have some higher estimated success probability from also considering the chance that the comment above is misleading. The thing one often sees about automated cv filtering systems is mostly widely-believed nonsense. It is a story that is told to job seekers to sell cv-optimisation services. That’s not to say automated filtering doesn’t exist – a simple case is filtering out candidates that were recently rejected – but I think even if a lot of people are filtered out, that doesn’t mean you will be. reply eru 5 hours agorootparentprevI have Facebook recruiters chasing me (and many of my friends). So I don't think it's that hard to get in. (I even worked there briefly for six weeks. But that's another story.) reply jvanderbot 5 hours agorootparentHere's the thing - having worked there briefly you are now on the top of their lists. You're part of the exclusive club in recruiters' eyes, whether it actually sets you apart or not. I worked at Amazon for a few months, and regularly get contacted by Amazon recruiters. But never Facebook, etc. reply eru 5 hours agorootparentI did not notice much of a difference in recruiter intensity before or after my short stint there. (But I was at eg Google before at some other point in my career.) reply devoutsalsa 3 hours agoprevBe good and you can work anywhere you like. reply oxqbldpxo 2 hours agoprevDenmark or Latin America reply dafuqdat 5 hours agoprevPizza shop reply Suzuran 5 hours agoprev [–] It is my understanding that if you are older than 35, have no C-suite social connections, and you lose your tech job, your tech career is over. Your only opportunities will be entry-level since none of your original education will pass automated filters, no entry-level hire is paid anything above subsistence wages, and at 35+ your rapidly-increasing medical issues (the piper's due for 20+ years of treating your body like shit pulling all-nighters 6 days a week) make living on subsistence wages an impossibility. If your health is intact, consider yourself lucky and get the hell out before it gets worse. Find some non-tech job you can scrape out a living from and make tech your hobby instead. If your health has already failed, well, good job making it this far, but the only things you have waiting for you in the future are losing whatever medical coverage you have, losing access to your medications, and finding out by experiment how long it will take for your conditions to become terminal when unmedicated. I don't see any reason to believe this situation will improve in the near future. It's probably time to make and/or exercise your end-of-life plans. reply plagiarist 5 hours agoparentI hope you're doing okay because this is pretty bleak. I also have a bleak outlook on the future, the healthcare costs in particular. I don't want to spend years building up money and then have cancer wipe it all out in just months. I haven't (yet) added \"tech career ends at 40\" to my set of looming tragedies. I'm currently more worried for people starting their careers, they seem replaceable by LLMs. Perhaps I have a false sense of security. reply prettyblocks 4 hours agorootparentLots of doomers on here, yet somehow I keep meeting highly technical people still working on interesting things that are in their 40s, 50s, 60s, and older. I think HN probably skews really young and tech tends to fetishize youth, so this is the mentality you get. reply chasd00 1 hour agorootparentI'm 48 and the only age bias i've encountered so far has been me against myself. Usually it's like I think i'm too old to learn something new, or don't have the energy to keep up, but if I give myself the chance then it turns out I'm wrong. You'll surprise yourself with what you're capable of if you're actually willing to make the effort. reply Suzuran 3 hours agorootparentprevI am 46. I am more or less describing my present situation, except I haven't yet been fired. I say \"yet\" because my employer's products are government-facing and the incoming administration has priorities incompatible with the usage of our products. I am told I work on interesting things, but the interesting things are my hobbies and not anything related to my employment. My day job is largely a slowly losing battle against technical debt. reply jsfunfun 4 hours agorootparentprevI’m 64 and just landed a great new job … it’s always my long history of C/C++ and mobile skills that get me in the door. reply AR-shinobi 27 minutes agorootparentI needed to hear something like this. I'm 61, got laid off last April and haven't had an interview since June. I have a long history in PHP and Perl, half a decade on Golang, Vue, React and devops. I was beginning to think that ageism was playing against me. Now I know I need to dig deeper.. thanks. reply Suzuran 3 hours agorootparentprevI am not sure I would call what I am doing \"okay\", but I am still here. I can't say the same for many of my friends. It was full renal failure in my case. I had no insurance. My savings were gone in the first two days. My entire medical debt is now such that it would take somewhere between three and four full lifetimes at the highest wage I earned during my career to pay it all down, and that assumes that no further debt was incurred in those extra lifetimes. reply bloomingkales 2 hours agorootparentprevThis person sounds incredibly negative and delusional. We're not animals that put people into a job in there 20s and say your career is over in 15 years. If your worldview is that people are animals, then yeah, you know. Work on yourself. reply angoragoats 4 hours agoparentprevYour understanding is wrong, though I do generally share your concern about the state of healthcare in the USA. Reposting something I wrote elsewhere in this thread: > I'm in my 40s and I (and the entire team I worked on) was laid off in 2022. After taking a week or so to relax, I was able to find a new position within about 4 weeks, which I'm still at now, and has turned out to be one of the better roles I've had in my career. I'll add that I had zero connections in my personal network (C-suite or otherwise) relating to the new role I took in 2022. I found the posting on a job site and applied, went through their standard interview process, and they made me an offer. reply adamredwoods 2 hours agoparentprev [–] >> It's probably time to make and/or exercise your end-of-life plans. My situation is as bleak as hey come. I'm much older, I have major health issues, and I'm a single father raising a teenager. Fortunately I have a good job thus far. I won't give up just yet, and hope you don't either. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Career paths after 40 can differ significantly, with options including joining mid-sized B2B (Business-to-Business) companies, consulting, or professional services.",
      "Personal goals, financial needs, and interests should guide the decision, with networking and past experiences playing a crucial role in discovering new opportunities.",
      "The ideal career path is subjective and varies based on individual preferences and circumstances."
    ],
    "points": 230,
    "commentCount": 192,
    "retryCount": 0,
    "time": 1735821184
  },
  {
    "id": 42569109,
    "title": "My favourite computer ergonomics hack",
    "originLink": "https://blog.jacobvosmaer.nl/0036-beeper/",
    "originBody": "Jacob Vosmaer's blog My favourite computer ergonomics hack 2024-12-31 In this post I will talk about my favourite computer ergonomics hack, a DIY device I call \"The Beeper\". Background I built the Beeper almost 8 years ago but I have never written a blog post about it and I thought it might be interesting. I do computer work sitting down at a desk at home. When I get focused on my work then I sit still for too long and my body starts hurting. The Beeper solves the sitting still problem. The Beeper consitst of three parts: the hardware, the firmware runnning on the hardware, and software running on my work computer. If my computer screen is unlocked for too long, the Beeper starts beeping and because it is situated away from my desk I must get up to silence it. Mission accomplished: I stopped sitting still. Hardware The Beeper is built into a small ABS Hammond 1551KTBU enclosure. Inside the enclosure are an Adafruit Feather Huzzah ESP8266 development board, a momentary switch and a piezo buzzer. The buzzer is glued to the case. The switch connects to the RST and GND pins of the Huzzah. Pushing the switch resets the microcontroller. The buzzer is connected to a PWM pin and GND. The Huzzah is powered over its Micro-USB port. I cut a hole in the case that lets the USB plug come through. ABS plastic is easy to drill, cut and file. Firmware I'm a little fuzzy on how I got the firmware working because it's so long ago and I don't work with ESP8266 or Lua often. I had to upload a NodeMCU binary blob to the development board. I then somehow configured the ESP8266 to connect to our home WiFi network and when it starts up it runs the following Lua script. -- init.lua: Beeper firmare pin0 = 3 pin2 = 4 pin5 = 1 -- Periodically blink the LED connected to pin0 function blink() gpio.mode(pin0, gpio.OUTPUT) gpio.write(pin0, gpio.HIGH) tmr.create():alarm(10000, tmr.ALARM_AUTO, function() gpio.write(pin0, gpio.LOW) tmr.create():alarm(100, tmr.ALARM_SINGLE, function() gpio.write(pin0, gpio.HIGH) end) end) end -- TCP server that lets us remote-control the device over WiFi function startserver() sv = net.createServer(net.TCP, 30) gpio.mode(pin2, gpio.OUTPUT) gpio.write(pin2, gpio.HIGH) gpio.mode(pin5, gpio.OUTPUT) if sv then sv:listen(5678, function(conn) conn:on(\"receive\", function(sock) sock:close() gpio.write(pin2, gpio.LOW) beep() end) end) end end -- The beeping magic function beep() freq = node.random(500) + 500 delay = node.random(1000) + 1000 pwm.setup(pin5, freq, 500) pwm.stop(pin5) tmr.create():alarm(delay/2, tmr.ALARM_SINGLE, function() pwm.start(pin5) tmr.create():alarm(delay, tmr.ALARM_SINGLE, beep) end) end blink() startserver() The high level description is that this script blinks an LED every 10s to show that the microcontroller hasn't halted and it starts a TCP server on port 5678. If anything connects to that port the connection handler calls a function called beep() which effectively loops forever because it keeps rescheduling itself with a timer. Every beep() invocation produces a shrill, annoying beep of random pitch and duration. I added the randomness because it makes it harder to mentally tune out the noise. The only way to get this annoying beeping to stop is to reset the microcontroller with the switch. Software The software running on my laptop is the part I have had to tweak the most over the years. It has the biggest impact on the user experience and it is important to get this right, because if the Beeper is too annoying I will unplug it and then I no longer get the health benefits. The current iteration of the laptop software is the following script. #!/bin/sh set -e screen_locked() { ioreg -n Root -d1 -agrep -q CGSSessionScreenIsLocked } external_monitor() { # The model identifier of my external monitor is EV2785 system_profiler SPDisplaysDataTypegrep -q EV2785 } do_sleep() { sleep_time=1200 expect_done=$(($(date +%s) + $sleep_time)) sleep $sleep_time delta=$(($(date +%s) - $expect_done)) if [ $(($delta * $delta)) -gt 100 ] then echo 'clock skew' exit 0 fi } main() { do_sleep if ! screen_locked && external_monitor && ! pgrep -q zoom.us then echo hellonc $IP $PORT fi } main This script is started automatically by a macOS LaunchAgent. It sleeps for 20 minutes (which is the time I'm allowing myself not to move), checks if it is appropriate to beep and if so it activates the Beeper. If not then the script exits, macOS restarts it and we wait another 20 minutes. If my screen is locked then I'm probably not sitting at my desk so we should not beep then. If I'm using my laptop somewhere else in the house away from my desk then the beeping would also be too annoying so we check if the external monitor that sits on my desk is connected to the computer. Finally, after many Zoom calls where I had to ask people to wait while I got up and turned off the beeper, I decided it would be better to not beep while I'm in a meeting. It's certainly less awkward to not have the Beeper do its magic during a video call but in my experience video calls can be even worse than focused programming when it comes to sitting still too long. Arguably, I should not be suppressing the Beeper then. But I just got fed up with having to explain to the other participants in Zoom calls why I have to get up all the time. Conclusion and acknowledgments It's a silly device but it works. I am happy about how simple it is. It appears that the 10 seconds it takes for me to get up and push the button are enough to counteract the discomfort caused by sitting still too long. As a closing thought I want to acknowledge and thank my wife for pointing out to me that I sit still too much and for putting up with the horrible screeching noises from the Beeper for the past 8 years and counting. Tags: diy Back",
    "commentLink": "https://news.ycombinator.com/item?id=42569109",
    "commentBody": "My favourite computer ergonomics hack (jacobvosmaer.nl)214 points by vortex_ape 22 hours agohidepastfavorite59 comments buildsjets 2 hours agoMy company has forced RSIGuard software on us, with unchangeable break timing and annoying pop-ups that you cannot disable for presentations, etc. It’s detestable and only done so The Company has a plausible defense against lawsuits while continuing to only supply only the crappiest Fischer-Price grade Dell peripherals that get thrown in the box for free. https://www.cority.com/home-ergo/ reply memalign 19 hours agoprevMy solution for sitting too long: every time I get up, I drink a glass of water. That ensures I have to get up again! It’s a self-reinforcing loop too. reply regularfry 6 hours agoparentSomeone, I forget who (Kent Beck, maybe?) refers to this as the peemodoro technique. reply dark__paladin 19 hours agoparentprevTight fitting pants + a belt is a sure-fire \"stand goal\" hack if you drink a lot of water. reply kylebenzle 16 hours agorootparentCan you explain this? reply taneq 16 hours agorootparentWhat goes in must come out. :P If you drink a glass of water every time you pee, then you’re gonna need to pee again relatively soon. The belt just limits how much room you have in the tank. reply rickydroll 1 hour agorootparentA belt also helps you detect weight change faster than any other method. It works so well that I wear sweats. reply hndc 20 hours agoprevThis is one of the better applications of an Apple Watch, which will detect when you haven’t stood for a while and pester you to do so. Of course, the watch comes with a giant bundle of other features that may or may not be desired. And building it yourself is so much cooler. reply cdaringe 2 hours agoparentWhich did you build yourself reply theendisney 18 hours agoprevLong ago i wrote a thing that gives you a textbox to explain what you were doing and a countdown enforcing a break. It is funny to read later what you did.(as oppose to what you wanted to get done and what you should have) reply jrmg 5 hours agoparentI love this idea. I used break enforcing software for a long time, but got into a routine of just pressing the ‘snooze’ button in order to avoid the break if I was into something. I feel the text box idea might’ve helped avoid that. reply zvr 5 hours agoprevAm I the only one who does not understand how the script on the Mac side works? I don't use a Mac and I don't know how \"macOS LaunchAgent\" operates, so I may be missing some details. But the code presented in the post seems to only check about the state at the 20-minute mark after execution. If the script is fired at 00:00, I take a break at 00:15, return at 00:19, it will still buzz at 00:20. I assume LaunchAgent restarts the script after it exits, so it is essentially a check that a person has locked the laptop at 20, 40, 60, 80, ... minutes after the initial start of the script, regardless of what other breaks take place. reply lbotos 20 hours agoprevJacob is the best! So glad to see him on HNWhen I get focused on my work then I sit still for too long and my body starts hurting. I wish I had this problem. Lately it is the opposite. I break focus every 20-30 minutes to go get a beverage, take a pee, tend to the dog, etc. reply astrodude 9 hours agoprevwith a Mac and iPhone, you can probably achieve the same thing without any additional hardware reply BlueTemplar 18 hours agoprevNice, I was already considering to get a pull-up bar, now I will think about adding a smart beeper to it... (with a camera detecting a face in the up position ??) reply msp26 16 hours agoparentDefinitely buy a pull up bar, it's one of the best purchases I've made. Pull ups and chin ups are fun exercises and they make your back feel REALLY good. reply Groxx 19 hours agoprev>... because it is situated away from my desk I must get up to silence it. Yeah, that's probably what I need too. An elegant self-hack. I think I'll try it with a kitchen timer instead, but I can certainly appreciate the ability to fine-tune it for self-annoyance only at the correct times. reply petesergeant 17 hours agoprevThe only thing that was effective for my RSI — and was really effective — is an app that forces me to stop typing for 15 seconds every 4 minutes. Super irritating but it works. AntiRSI on a Mac, Workrave on Windows and Linux, are examples of ones I’ve used. Been doing this for 20-odd years at this point. reply Lio 7 hours agoparentI switched to Colemak keyboard layout for RSI reasons. I don’t think I got any faster at typing but my wrist pain went away and hasn’t really come back in the 16 years since. reply JSR_FDED 16 hours agoparentprevSwitching to Vim cured my RSI completely. I was thinking that coding might no longer be my occupation, but thanks to Vim I’m still working 10+ years later! reply petesergeant 12 hours agorootparentinterestingly I was all-in on Vim when it was at its worst! reply REDS1736 8 hours agorootparentMaybe your keyboard was a contributing factor? I had wrist pain typing in vim on a \"regular\" (Keychron C1) Keyboard. The wrist pain is gone since i use a split keyboard (Ergodox EZ) which allows me to rotate both halves of the keyboard in order to match the \"incoming angle\" of my forearm which removes the need to constantly bend my wrists outwards. reply plagiarist 20 hours agoprevThis is neat. Simple but smart. I have been thinking of something similar: I'd like a wearable that haptic taps me once every 10 or 15 minutes. Then I would check with myself if I am doing something that's actually interesting to me or just idling away. I keep considering smart watches but if the goal is to prevent me from wasting time those could be counter-productive. Also I am sick of having products that require their specific charging dock. reply Groxx 19 hours agoparentIf you're interested in a fairly simple, fairly programmable, and long-lasting option: https://www.espruino.com/Bangle.js2 it's the only watch that hasn't been a distraction or (too much of an[1]) annoyance for me. You could probably build your own \"start/stop a motion-sensitive reminder\" app in a couple hours, though fine tuning it will likely take some time. I regularly get a full week of battery out of it, and it uses a standard magnetic watch charger. The vibration motor is a bit weak though, and personally I rapidly grow to not notice frequent haptics so I can't use it for this kind of thing. But apparently watch-vibrations work for many. [1]: it certainly has some annoying quirks and minor frictions, but they irk me far less than the quirks/etc in other watches I've tried. and I am MORE than willing to put up with it for the battery life and daylight-readable screen - I'm downright happy with it, and have returned every other watch I've tried in the past couple years. reply vinni2 19 hours agoparentprevApple watch already does that. reply grahamj 19 hours agoprev [–] Brilliant! Now you just need to hook up a Switchbot or something to it so you can deactivate it remotely. Say, from your desktop. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Jacob Vosmaer introduces \"The Beeper,\" a DIY device designed to encourage movement by beeping if the computer screen remains unlocked for too long. - The Beeper is composed of hardware (Adafruit Feather Huzzah ESP8266, switch, piezo buzzer), firmware (Lua script), and software that manages activation. - Despite its simplicity, the device effectively promotes regular movement, and Jacob acknowledges his wife's support in the project."
    ],
    "commentSummary": [
      "Users expressed frustration with mandatory RSIGuard software at work, which enforces breaks with fixed timing and disruptive pop-ups. - The discussion included various ergonomic hacks, such as drinking water for regular breaks, using tight clothing, and relying on Apple Watch reminders. - Alternatives like AntiRSI, Workrave, custom solutions, and smartwatches like Bangle.js2 were suggested to manage repetitive strain injury (RSI) and improve ergonomics."
    ],
    "points": 216,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1735763993
  },
  {
    "id": 42576443,
    "title": "UBlockOrigin GPL code being stolen by team behind Honey browser extension",
    "originLink": "https://old.reddit.com/r/uBlockOrigin/comments/1hr6xjc/ubo_quick_filters_list_being_stolen_by_team/",
    "originBody": "whoa there, pardner! Your request has been blocked due to a network policy. Try logging in or creating an account here to get back to browsing. If you're running a script or application, please register or sign in with your developer credentials here. Additionally make sure your User-Agent is not empty and is something unique and descriptive and try again. if you're supplying an alternate User-Agent string, try changing back to default as that can sometimes result in a block. You can read Reddit's Terms of Service here. if you think that we've incorrectly blocked you or you would like to discuss easier ways to get the data you want, please file a ticket here. when contacting us, please include your ip address which is: 20.161.78.9 and reddit account",
    "commentLink": "https://news.ycombinator.com/item?id=42576443",
    "commentBody": "UBlockOrigin GPL code being stolen by team behind Honey browser extension (reddit.com)212 points by extesy 1 hour agohidepastfavorite58 comments max_ 1 hour agoWhy can't people just run businesses decently without deception & scams? I'm sure they can be profitable. This deceptive behaviour actually makes the business loose customers in the long term. reply cjbgkagh 1 hour agoparentThe bad pushes out the good until you’re only left with bad. A system that tolerates bad actors like this will in time only have bad actors. It’s tolerated because it makes a large amount of money for a small number of people. reply jszymborski 46 minutes agorootparentThis is exactly it. When things are horrible around us, there is a strong temptation to throw ones hands up in apathy and let the rot fester. \"Eh, Honey is probably selling my data but I got $5 off my new mattress, so wtv\". We need to resist that call to apathy, stop acquiescing, and start demanding better of others. That, incidentally, often starts at demanding better of ourselves. reply throwaway4659 4 minutes agorootparentI work for a very large company. I'm very close to throwing my hands up in apathy because the company keeps throwing the teams in our area into chaos and disarray with little regard for the humans in them. We have no investors to answer to. We're printing money. Yet at every opportunity company leadership reveals itself as this slavering beast where the only people in positions of power have gotten there through duplicity and a lack of empathy. The tech job market is terrible. I'm trapped in the guts of a machine that was supposed to be one of the \"good ones\". I'm not sure there's anything to do for people who want to act ethically and be decent to each other if even the \"good\" companies show a complete lack of regard for anything but making their profits take off into the stratosphere. reply cjbgkagh 31 minutes agorootparentprevI disagree that it’s down to the individuals. While individuals can throw themselves into the gears of the machine it is understandable why they do not. I see things in terms of a sharecropping analogy, feudal lords (corrupted government) allow the scammers to harvest the crop (victims) for a share of the proceeds. We cannot fix people to the point they are un-scammable and there does not exist a democratic force strong enough to fix the government. Almost all ads I’ve ever seen are for obvious scams, especially on twitter. You’d think the richest guy in history (possibly?) could afford not to allow industrial exploitation of his users but apparently not. You have gambling sites and binary auction scams that have a turnover that includes a significant percentage of suicides. I wish we had a democracy that could prevent this but we do not. While many of us here may be smart enough to avoid falling victim to these scams we have family members that we care about who are not so this still indirectly costs us wealth. reply LeifCarrotson 14 minutes agorootparentAbsolutely! I think this was kind of what OP was driving at with the suggestion to \"start demanding better of others.\" It doesn't work to expect they should do better from their own motivation, we need to fix the broken incentives and consequences that result in those bad decisions being attractive. reply cjbgkagh 4 minutes agorootparentWhile I agree with that ideal I’m not sure how realistic it is. Trump was elected on a populist platform and quickly betrayed his base before he has even take office. What are people to do, vote harder? It’s not like Kamala would have fixed this either. If Kamala had a better chance of winning the ‘Tech Titans’ wouldn’t have switched teams. They would have done anything the government asked for so long as the scamming ad revenue kept flowing. If we mean ‘we tech workers’ then you’ll just be replaced, just like how I was when I quit being a researcher at FANG companies over this and other ethical concerns. The only observable outcome is that my clear conscious came with the cost that I’m far poorer than I could have been. I’m lucky as I’m still well off but not everyone can make that call and survive. These scamming behaviors are trivial to detect and especially so at the large internet company level. It exists on these platforms because the owners want them to. teamspirit 12 minutes agorootparentprev> I wish we had a democracy that could prevent this but we do not Doesn't this rely on us as the individual? We get the government we allow. We, humanity, could've had anything we wanted, this is what we gave ourselves. reply formerly_proven 9 minutes agorootparentprev> I disagree that it’s down to the individuals. Individual action is known to be so inefficient that the oil&gas industries poured money into promoting the idea of the personal climate footprint. reply Pxtl 31 minutes agorootparentprevI mean laws are supposed to stop the bad actors but at this point the extreme cost of legal action and the street-crime fixation of police forces mean those laws don't constrain wealthy interests unless they harm other wealthy interests. Protects and does not bind vs bind but does not protect. Same as always. reply FergusArgyll 29 minutes agoparentprevHayek: Why the worst get on top https://fee.org/resources/the-road-to-serfdom-chapter-10-why... reply joshstrange 29 minutes agoparentprev> I'm sure they can be profitable. Some aren’t and never will be without the deception and those companies just shouldn’t exist. reply 0xDEAFBEAD 33 minutes agoparentprevBusinesses which quietly do the right thing don't make the news. reply throwawaysleep 2 minutes agoparentprevWhy? I don’t see any incentives for decency. Decency is as desired by society as “made locally.” Very few people are willing to pay for it and behaving that way he tremendous opportunity costs. reply api 57 minutes agoparentprevMost do, but the scammers and hustlers often win. When you're scamming and hustling you don't have to do the real work, which means you can spend 100% of your time and energy marketing and you win there. I'm deeply pessimistic about the future of open source. A lot of people are going to give up on it as it becomes clear that it's just free labor for SaaS companies and hustlers. That and I expect far more supply chain attacks in the future. I'm quite surprised there haven't been a lot more like the attempted XZ poisoning... yet. Or maybe there have been and we haven't caught them. Edit: I forgot free training data for code writing AI. It's that too. OSS is one of the Internet's last remaining high trust spaces. It'll be dead soon like all the others. The Internet is a dark forest. reply yoyohello13 54 minutes agoparentprevMy general belief is that you can be a millionaire by acting ethically, but you can’t be a billionaire. Lots of people motivated by money want to be billionaires. reply jsheard 44 minutes agorootparentAnd in this case it worked, PayPal acquired Honey for $4 billion in cash. I can't say I'm surprised to learn that the founder is also very into Web3, crypto is a grifter magnet. reply betweenbroth 26 minutes agorootparentprevI know one billionaire. He's third generation to run a investment / hedge fund firm that is super secretive. Can barely find him on google, just a few articles about his dad and granddad. They quietly played the financial system for 7 decades and the fourth son will soon take over, but all he seems to do is travel because their employees do all the work. I've learned there are hundreds of billionaires that play this quiet financial-machine game and do everything in their power to remain anonymous. To the first order they are \"ethical\" because they follow the law, but when you can write the laws that define the financial system by funding congresspeople to insert obscure legislation that no one but financial experts can comprehend, it is very hard to explain exactly what is unethical in a way that your typical Cletus-like voter can understand (hell, I have no effing clue so I should go easy on Cletus). You're right though, centimillionaires feel entitled to become billionaires, and billionaires feel entitled to become centibillionaires. However, I have noticed that the decimillionaires I know are aware that they still aren't in the right lane to even think that way and are largely content. (wow, you're getting downvoted, the little boys on the site sure are a jealous bunch.) reply talldayo 34 minutes agoparentprev> I'm sure they can be profitable. But can you be as profitable as your indecent, deceptive, scamming competitor? If not, it won't matter how much of a goody-two-shoes you are. If the market sets the bar low, you either limbo or leave. reply whalesalad 53 minutes agoparentprevsome people have a substantially lower bar for personal ethics. \"why can't people...\" what you and I consider to be normal is not even on some people's radar. reply o11c 38 minutes agoparentprevBecause we, as a society, have decided that lying should be effectively mandated and there should be no punishment for it in general. It's not just a few businesses, it's practically all of them. As a rule, an honest businessman can't make enough money to survive while being undercut by everyone else. reply Suppafly 52 minutes agoprevAs if Honey isn't already under enough fire with half the youtube world releasing videos about their shady practices. reply BadHumans 28 minutes agoparentTitle is misleading. The original team behind Honey has created a new company that is doing this and not Honey itself which is owned by Paypal. reply jzb 32 minutes agoparentprevIs really being \"under fire\" if it's just accurate reporting? reply ilbeeper 3 minutes agorootparentJustified fire is still fire reply nhinck2 12 minutes agorootparentprevYes. reply nicce 46 minutes agoparentprevSecond half advertises its existence in a positive way as they pay for influencers. reply Sephr 40 minutes agoprevTo be fair, Honey could easily bypass this legal issue by downloading filter lists at runtime from the official source. Then they aren't redistributing the resources. reply moonshadow565 30 minutes agoprevI don't think you can copyright lists of publicly available information (iirc there was some case with phone numbers before). That being said, they also stole code... reply onli 26 minutes agoparentRight, or: maybe. Depends on where you are (or maybe better: where they are), and whether data collections fall under copyright or some other protection that is translateable enough for the gpl to apply. But if they really also used code that point is moot. reply 2OEH8eoCRo0 12 minutes agoparentprevYou might be able to. It took work to curate that (as opposed to all phone numbers without curation). reply gonesilent 54 minutes agoprevpaypal paid 2 billion for honey did all the devs leave? reply gkoberger 12 minutes agoparentLooks like they sold in 2020 for $4Bn, and both founders left two years later in March 2022. One founder started Pie, which basically seems like Honey with a slightly different angle. The other founder became a VC. reply mfer 41 minutes agoprevThe author of UBlockOrigin should contact the PayPal legal department (in a legal manner). That might be a more direct path dealing with the Honey business. reply slowmovintarget 1 hour agoprevIf any software ever deserved being sued into non-existence it is the Honey browser extension, and any other scam software they turn out (Pie Adblock in this case). https://www.youtube.com/watch?v=vc4yL3YTwWk reply tzs 1 hour agoparentI've seen a few ads from them on YouTube promoting their ad blocker, specifically touting that it gets around YouTube's efforts to block ad blockers. I thought it was interesting that YouTube, in the midst of trying to crack down on ad blockers, allows ads promoting an ad blocker that is specifically claiming to evade that crackdown. reply Drakim 28 minutes agorootparentI wonder if there could be anti-trust aspects to cracking down on such ads. reply chasebank 1 hour agoparentprevThe founders sold 5 years ago to PayPal. Do they just get to laugh on their way to the bank? Probably. reply ndriscoll 31 minutes agoparentprevFrom what I've gathered, honey basically replaced affiliate codes with their own and then gave the user part of the commission back? Is there something they did that users should be unhappy about? reply xen0 1 minute agorootparentIt seems the voucher codes they 'find' are not the result of them searching the Web. They are simply codes provided by partnered businesses and may be beaten by codes you can get by searching yourself. If true, then this is them outright lying to the user. And you know, if they don't find a coupon code for you, one might still be at least a little annoyed that the original 'salesman' didn't get their affiliate commission; it instead being pinched by another. reply iou 1 hour agoparentprevThis is the one worth watching, it’s a total scam and PayPal is fine with it apparently. reply kurthr 1 hour agoprevI really wish PieAdblock was in the article headline, since it's more relevant. \"UBlockOrigin GPL code stolen by Pie Adblock Extension and Honey team\" Of course Pie is scummy, it is brought to you by the people behind Honey. In addition to stealing GPL Source the new over-hyped Adblocker that probably also steals (silently rewrites in the background) affiliate links, just like the old \"coupon finder\". No surprises! reply graemep 46 minutes agoparentThe developers of the misused code can sue for breach of copyright. The people in breach in this case have money and are worth going after if there are a reasonable number of copies of the code illegally distributed. reply zb3 1 hour agoprev [–] If something is \"heavily promoted by influencers\", it's garbage. Would it make a difference if this garbage was GPL licensed? reply blibble 32 minutes agoparentpersonally I think it's hilarious that \"influencers\" were taking a pittance to unknowingly cut off their affiliate income and not just cut it off once, but cut it off forever and as a bonus: cut it off for all other influencers too reply nicce 49 minutes agoparentprevIt works. The only reason I knew what Honey was because so many Podcasters and Youtubers have advertised it on their content. I have never used it, but I recognized the name and knew what it does. reply lesuorac 47 minutes agorootparentIn case you missed the news, it doesn't work the way it was advertised. Honey _does not_ scour the web for discount codes. Honey instead partners with webpages to provide you a discount code (or not) with the advantage for the webpage being that less people will use a 30% discount code and instead use Honey's 10%. Of course the really funny part was that basically none of the influencers did due diligence on their counter-party and Honey also took all of the influencer's affiliate money as well. reply cjbgkagh 39 minutes agorootparentThey do crowdsource discount codes from other users which is how you get internal discount codes used for testers leaked to other users. I think this is a facilitation of theft, though the theft is hidden to the user so the user does not possess criminal intent while using the code. I’m not sure how illegal it is but it is clearly wildly unethical. reply lotsofpulp 33 minutes agorootparentThere is no theft as long as the “testers” or whoever are voluntarily installing Honey. The T&C of installing Honey surely includes the right for Honey to see and share the discount codes. reply cjbgkagh 16 minutes agorootparentIt should be incumbent on Honey to check if these discounts are indeed public. 100% discounts would be an obvious place to start. Given that Honey claims to search the public internet for discounts according to their claims they can in fact do this. At the scale and resources of Honey the claim of ignorance becomes unreasonable. It would help their case if they had a made a documented good faith attempt, but I think due to the obvious nefarious nature they would have avoided collecting such data because they wanted to continue the practice. But as mentioned, I’m not sure how illegal it is despite the TOS but it’s clearly wildly unethical. reply lotsofpulp 11 minutes agorootparentWhy would it be incumbent on Honey, or illegal at all? It is a voluntary transaction by two businesses. If the business does not want their codes given out, then they should not agree to Honey’s T&C. reply cjbgkagh 0 minutes agorootparentJust because the user agrees to Honeys T&C does not mean the user has the right to share the coupon in that manner. The coupon originating company did not give the user the coupon with permission to share. If it was a printed coupon and photocopied it would be obviously illegal, I’m not sure how the digital equivalent would not be illegal. If such a coupon was publicly available then it would be like if honey went and fetched you a new coupon instead of copying an existing one. observationist 43 minutes agoparentprevYes, possibly a huge difference. If they provided legitimate work and contributed to the project, with diligence and respect for the licensing, and respectfully, transparently, honestly ran with some sort of referrals / adshare type program for monetization, it would almost be respectable. What they did was out themselves as garbage humans, with laziness, antisocial grifting, disrespect for the law, and general unpleasantness at every possible level. It'd be difficult to be worse people without adding murder or violence to the mix. reply zb3 1 hour agoparentprevOh it gets even better: > Pie Adblock: Block Ads, Get Paid Really? Do people not understand how the economy works or something? Education failed so bad :( reply sodality2 1 hour agorootparentFrom their home page: > Browse ad-free with Pie Adblock and earn cash rewards for the ads you choose to see. Sounds like they replace the ads with their own, paying you (and surely taking their cut). Sounds a lot like Brave Rewards, similar thing... reply entropicdrifter 1 hour agorootparentI was gonna say the same thing. Brave browser all over again reply LordShredda 1 hour agoparentprev [–] I would never install anything advertised on youtube. Not claiming that I'm an elitist, but the audience on youtube would not have the ability to differentiate between a chocolate bar and a landmine. reply starttoaster 39 minutes agorootparent [–] Not sure where to start here. You could have found Honey advertised basically anywhere on the internet, not just YouTube. YouTube users are common across most of the developed world at this point, so it's probable that there are millions of YouTube users that are more intelligent than you or me. And what you said implies you do differing levels of due diligence for the services you sign up for depending on the platform you heard about them from, which is ill advised; regardless of where one found out about Honey, you should have questions about how their business works. Someone who has been around the block a couple times would have deduced that a business that clips coupons for you is doing something to make money, and since it's not obvious what that thing is, it's almost certainly something shady. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The Honey browser extension team is accused of using GPL (General Public License) code from UBlockOrigin without proper attribution, sparking controversy.",
      "Reddit users express concerns about deceptive business practices, emphasizing the negative impact on customers and the tech industry.",
      "The discussion highlights broader issues, including corporate ethics, the influence of money in politics, and challenges in maintaining business integrity, with skepticism about the future of open-source projects due to potential exploitation by companies."
    ],
    "points": 213,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1735838848
  },
  {
    "id": 42571367,
    "title": "Blogs rot. Wikis wait",
    "originLink": "https://j3s.sh/thought/blogs-rot-wikis-wait.html",
    "originBody": "↵return blogs rot. wikis wait. blogs rot. wikis wait. 2025-01-01 wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my abyss is my wiki is my Abyss ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⣀⡀⠒⠒⠦⣄⡀ ⠀⠀⠀⠀⠀⢀⣤⣶⡾⠿⠿⠿⠿⣿⣿⣶⣦⣄⠙⠷⣤⡀ ⠀⠀⠀⣠⡾⠛⠉⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⣿⣷⣄⠘⢿⡄ ⠀⢀⡾⠋⠀⠀⠀⠀⠀⠀⠀⠀⠐⠂⠠⢄⡀⠈⢿⣿⣧⠈⢿⡄ ⢀⠏⠀⠀⠀⢀⠄⣀⣴⣾⠿⠛⠛⠛⠷⣦⡙⢦⠀⢻⣿⡆⠘⡇ ⠀⠀⠀⠀⡐⢁⣴⡿⠋⢀⠠⣠⠤⠒⠲⡜⣧⢸⠄⢸⣿⡇⠀⡇ ⠀⠀⠀⡼⠀⣾⡿⠁⣠⢃⡞⢁⢔⣆⠔⣰⠏⡼⠀⣸⣿⠃⢸⠃ ⠀⠀⢰⡇⢸⣿⡇⠀⡇⢸⡇⣇⣀⣠⠔⠫⠊⠀⣰⣿⠏⡠⠃⠀⠀⢀ ⠀⠀⢸⡇⠸⣿⣷⠀⢳⡈⢿⣦⣀⣀⣀⣠⣴⣾⠟⠁⠀⠀⠀⠀⢀⡎ ⠀⠀⠘⣷⠀⢻⣿⣧⠀⠙⠢⠌⢉⣛⠛⠋⠉⠀⠀⠀⠀⠀⠀⣠⠎ ⠀⠀⠀⠹⣧⡀⠻⣿⣷⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⡾⠃ ⠀⠀⠀⠀⠈⠻⣤⡈⠻⢿⣿⣷⣦⣤⣤⣤⣤⣤⣴⡾⠛⠉ ⠀⠀⠀⠀⠀⠀⠈⠙⠶⢤⣈⣉⠛⠛⠛⠛⠋⠉ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠉⠁ wikis are companions a wiki for you-- just you to add, read, delete, expand a changeling, chaotic, inconsistent, wild, forever flailing and uncertain, like you ... a blog is a storefront pretty products adorned, designed, pristine and tailored, for them skinny plastic legs poke through perfect plastic casing landfills of abandoned posts decay ... a wiki is an abyss thoughts written alone unravel, and stitch themselves with meaning ... blogs rot. wikis wait. [0]⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⢰⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡠⠖⠒⠒⠦⡄⠀⢠⠄⠀⠀⠀⠀ ⠀⠀⠀⠀⠒⠀⠠⠄⠀⠀⠀⠀⠀⠀⠀⠐⠀⠀⠀⠀⠀⢠⣋⠂⢀⠀⠀⠀⠀⡠⠞⠀⠀⠀⠄⠀ ⠂⠀⠀⠀⠀⠨⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⡏⠀⣠⠔⠋⠀⠈⡇⠐⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⠀⠀⠀⠀⢀⠀⠀⠀⠀⠈⡣⣺⣥⣶⡀⠀⠄⣰⠁⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠚⠉⠘⠮⢍⣝⡥⠞⠁⠀⠀⠀⠀⠐⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⠀⠀⠀⠀⠀⠀⠀ ⠀⠁⠀⠀⠀⠀⠄⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠄⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠁⠀⠀⠀⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⢀⠔⠋⢠⠔⠊⠁⠀⠀⠉⠳⡄⠀⠀⠀⠀⠀⠀⠀⠀⠂⠀⠀⠀⠀⠀⠀⠀⢀ ⠀⠀⠀⠀⠀⠀⠎⠁⣠⠊⠀⢀⡤⠂⠊⠉⠉⠉⠻⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢀⠎⠀⠀⠀⠀⡐⠁⣠⠖⢦⠀⠸⡀⠀⠙⡄⠀⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⠀ ⠄⠀⠀⠀⡜⢠⠀⠀⠀⢐⠃⠀⡇⠀⢸⠀⠀⢸⠀⠀⢱⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢊⠘⡄⠀⠀⠘⢆⣀⣀⣠⠃⠀⢠⠏⠀⠀⠰⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠘⣆⢳⡀⠀⠀⠀⠀⠀⣀⣀⡴⠊⠁⠀⠀⡆⠀⠀⠀⠀⠀⠁⠀⠀⠀⠀⠀⠀⠂⠀⠀ ⠀⠀⠠⠀⠀⠀⠘⠪⠑⠒⠀⠀⠀⠀⠀⠀⠀⢀⡠⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠁⠈⠈⠈⠈⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ^ your wiki here p.s. i'm working on a new wiki to replace my website with - something new, from the ground up. git.j3s.sh/abyss - stay tuned [0]: ascii art from https://emojicombos.com/galaxy-ascii-art follow me on mastodon! last updated 2025-01-01T00:00:00.000Z",
    "commentLink": "https://news.ycombinator.com/item?id=42571367",
    "commentBody": "Blogs rot. Wikis wait (j3s.sh)176 points by j3s 15 hours agohidepastfavorite110 comments jefftk 4 hours agoAs both a reader and a writer I disagree: * A blog post is a snapshot: what did the author think at the time they wrote the post? If they change their mind or learn more, they write a new post and link forward and backwards. I know how to write for this environment (write what I think now, try to write things I'll feel glad to have written later) and how to work with things other people have written (consider the date, it's just one person's view). * A wiki page is unclear. When should it be updated? How much should I trust that it was up-to-date as of the last-updated date vs that just being when someone fixed a typo? A few wikis and sites with wiki-like approaches (Wikipedia, gwern.net) manage to handle this well, but I think it's generally much more difficult and rot-prone. reply xemdetia 3 hours agoparentI think in modern times because you don't see it the same way you forget that a newspaper, magazine, encyclopedia, academic paper, and a reference book are different for a reason and do not have to be unified, and there was no need to do so. Having a way to publish contemporary articles vs building an effective knowledge reference are different goals. The physical print production was part of the language of intent. A blog with a contemporary note of an obscure Ubuntu upgrade issue is often the best way to describe it whereas a wiki with a current reference of now the fundamental baseline of relevance. A wiki eschews the most relevant details the same way an encyclopedia focuses on the core points. As a writer I need many formats and as a reader I cherish many formats. reply notpushkin 3 hours agoparentprevAnd a blog could be updated as many times as you want! Suppose you wrote a post with some kind of a guide a few years that still gets a lot of views — you can still update that, and even re-publish it on your homepage. This style is more popular with some media sites — e.g. journal.tinkoff.ru (in Russian) does this with their “instructional” posts — but I think it should work for personal blogs just as well. reply 3eb7988a1663 45 minutes agorootparentFor the love of deity, just include timestamps. It is incredible to me how many blogs do not include a date created or modified. reply 1dom 9 hours agoprevI like the sentiment of this, I feel it very strongly. But I also think this is just another expression of personal website anxiety. This is the same sentiment that lead to the boom in digital gardens, notion, PKM etc. I haven't accepted it yet, but I think people who host their own personal websites need to accept that they're hosting a personal website, and it's going to change over time as they change. People already know and accept and see that as a feature of a personal website. It's necessary as the tech changes too, a personal website with the latest and greatest tech from 20 years ago renders like garbage in a modern browser. I really don't mean to sound mean, and I do sincerely empathise and sympathise with the author, because every year or 2, I have the same revelation that my website hasn't been updated in a while, and it's not my fault, it my platform just isn't technically correct and it's too restrictive and _that's_ what's stopping me being consistent on my personal website. But let's be honest, that's a me problem for not updating it or adding to it. Every year or 2 for the past 20 years, I'm sure many of us could write the same \" rots.wait\". reply oneeyedpigeon 8 hours agoparent> a personal website with the latest and greatest tech from 20 years ago renders like garbage in a modern browser The irony being that one without the \"latest and greatest\" tech would still render fine - tbh, even in 2005, some of this \"latest\" tech was recognised as not the \"greatest\". Examples? I don't think daringfireball.net has changed that much since 2002, neither blog.codinghorror.com since 2004. reply Macha 7 hours agorootparentCoding Horror has moved from self hosted movable type to hosted movable type to Ghost. The theme has been deliberately kept relatively consistent, but the tech has had significant changes. reply 1dom 6 hours agorootparentprev12 year old me's website from 2002 on webarchive looks like trash compared to when I made it because framesets and css has evolved since then. Many of my nerdy friends at the time also had fully flash based, or just a flash animation on the front of their websites. We also all made liberal use of blink and marquee tags which might still work in some places, but are officially deprecated and unsupported in others. At the time, these sorts of things were considered the latest and greatest. Hell, I remember one maniac playing around with Microsoft Silverlight on their personal site as we were in college. We knew some was good, some was bad etc. None of it survives as intended now though, unless it was updated. There aren't many personal like websites I remember that have stayed personal sites for over 10 years. But some have, kind of. Take gwern.net or stevepavlina (not a regular reader anymore): both of them - if you squint - look pretty similar minimal 2000 - 2010 style as when they first started, but the implementation has had to evolve as even things like CSS have had a bunch of breaking changes over the major versions. codinghorror uses Discourse for comments, and that didn't come around until 2014, and the only thing that looks like it might be from 10+ years ago on daringfireball is the content: the tech that renders it and the design all hinges on 2010+ technologies and companies. I love minimal styles and ideals. But if you want to create a personal website that survives time and looks how you expect in a modern browser, even a minimal one, you have 2 options: 1. it has to either look exactly like some variation of motherfuckingwebsite.com, and that will eventually vary between browsers 2. it takes some effort to maintain over a period of years Sorry, I wrote the lengthy response above and I think just realised me and the other person who responded to you have misunderstood your comment: I think me and the other person initially assumed you're making only 1 point, that latest and greatest tech wouldn't render, but your examples clearly use modern tech from well after 2004, which makes no sense. On rereading, you're making 2 points, right? 1 point is that tech from 2004 can still work (but you didn't provide example) and other point is that those 2 sites you did provide are example that \"website structures\" (e.g. linear blog) can survive time but didn't actually state that point. Is that right? Assuming so, you're completely right on your second point, and people who've done that (maintained a blog for years) are the real legends who've conquered person website anxiety. They're better than many, including me and OP, who have the issue of feeling like they need to completely rearchitect their website every 2 years to a wiki, or digital garden, or knowledge base, or whatever the latest PKM tech buzzword is. This is why I was saying that there's no need to crap all over e.g. blogs for rotting, as your examples prove blogs can survives decades. OP is just another response to that feeling of \"uuurgggh I can't quite wrangle my thoughts into a neat, atomic, chronological list of blog posts and people who read blogs will judge my personal website, so I'll tell them it's not a blog\". reply rpcope1 14 hours agoprevWikis are great, but it feels like outside of Wikipedia they've been dying. I wish bashhackers was still with us, and regret even more that there's not other large old school wikis for things like systems software development or other programming languages (or even a newer take on the original WikiWikiWeb). I guess maybe some of it is GitHub pages or that weird GitHub wiki thing now, but they don't really feel the same. reply jjmarr 14 hours agoparentIt's tricky, as a lot of what makes Wikipedia good is an accumulation of policies and practices that force you to use its features. You can't just install MediaWiki or Confluence and expect it to be good. As an example, orphan articles (ones not linked from any other pages) [1] are categorized and tagged on Wikipedia. There are many editors that spend their time trying to find places to link to orphaned articles, which improves discoverability of that information. The best programming language-specific Wiki I've found is cppreference.com. They have a very nice stylistic approach to dealing with the different C++ standards. [1]https://en.wikipedia.org/wiki/Wikipedia:Orphan reply bawolff 13 hours agorootparentThere is a saying you can't solve a social problem with a technical solution. Wikis are mostly just a thin technical layer to let people create their own solutions to social problems. reply wruza 12 hours agorootparentThat saying said, people often wrongly call technical problems social, being blind to obvious technical flaws that drive users into various directions. They attribute it to some inherent user property when in reality it’s a technical nuance of a system that does it. Most problems include a user behavior, but most user behaviors include the shape of some existing solution. reply diggan 7 hours agorootparentI think I understand what you mean, but it would be really helpful to make sure I understand if you could make a practical and specific example of what you mean? Has there been a case with Wikipedia/the Wikimedia Community where this specifically has happen? reply wruza 2 hours agorootparentI think this can only be seen by an insider-enough, and I am not that much of a wikipedia guy. An example that probably everyone can understand is youtube. Content creators are often begging for like/subscribe and even present graphs that show that only 10% of their regular viewers are subscribed. This seems like a social problem to some, but in reality it’s a technical problem because if you like/subscribe, your feed will drown in “similar” videos of much lower quality and that will haunt you for weeks. And there’s a whole set of other ui/ux issues even if you decide to subscribe. So many people avoid interacting with videos too much because of that. I know youtube is a beaten horse, but it is a textbook example of what I mean. I could theorize about what’s wrong with wikis, but wiki guys see it much better. My key thought here is “check twice that it’s not technical before calling it social”, but it may not be the case here. reply moffkalast 6 hours agorootparentprevAh but we can create a technical solution to easily ignore a social problem until it festers horribly! reply Thorrez 12 hours agorootparentprevI used to sit next to Nate, the founder of cppreference.com . Humble dude. I had no idea he created it until a coworker mentioned \"did you know that Nate created a website about C++\". I thought cool, assuming it was some small site. I asked Nate what it's called, he said cppreference.com . I thought wow, that's the C++ website. reply crooked-v 14 hours agoparentprevI feel like that's been helped along culturally by fandom.com buying out various independent wikis and then shittifying them to the point of unusability. reply TkTech 14 hours agorootparentThere's an ongoing mini-revolution against Fandom, with the wikis that have the manpower moving away to other platforms like wiki.gg, WeirdGloop, or just self-hosted. Minecraft, WoW, Runescape, LoL, etc. reply j3s 14 hours agorootparentyep! i recommend indie wiki buddy for discovering these sorts of community-led wikis. the extension recognizes when you’re on fandom and recommends equivalent community wikis instead fandom will not take down old wikis (that’d be bad for SEO), so the fandom content persists even after a full community migration. just one of the many shitty things that company does. reply shnock 13 hours agorootparentThis? https://getindie.wiki/ Thank you from a long-time hater of Fandom and PE-driven enshittification and lover of community-driven knowledge work reply doublepg23 13 hours agorootparentprevI'm glad https://en.uesp.net/wiki/Main_Page survived Fandom. reply diggan 7 hours agorootparentIf only we could have something similar but official for Starfield. For some very stupid reason, Bethesda decided to launch official modding support with Starfield while their wiki is \"temporarily down for maintenance\". But it's been like that for at least 1 year, so seems unlikely to ever come back, and who the fuck takes down something so vital for a feature you're shipping in a major game anyways, without letting a read-only copy remain online at least? reply Kye 5 hours agorootparentprevThe moved-out Minecraft wiki is finally starting to get competitive in search with Fandom. At least on DuckDuckGo. I used to have to dig for it. reply emodendroket 13 hours agorootparentprevI guess that doesn't help but it feels like our cultural moment doesn't have the same kind of spirit that made people want to make a Wiki. reply brutal_chaos_ 12 hours agorootparentprevHow is fandom shitty now? I'm asking from a newer user perspective. What did standalone wikis do better? My initial guess is ads, but is there more to it? reply blharr 10 hours agorootparentAdding autoplay videos that are tangentially related to the wiki page. Said videos take about 10 seconds to show up and will cause the screen to scroll to a different point from where you are currently reading Their privacy policy is exhaustive, and you opt in by default to sharing your data with Google and 7 other analytics providers UI noise like \"share to Instagram/YouTube/LinkedIn\" that probably 0.1% of people even consider using When you're on a specific game wiki, you care only about that wiki content, but fandom places a Fandom navigation bar and side menu Their default email strategy sent almost daily updates for random posts on (unrelated) FANDOM community when I made a couple comments on a specific wiki a decade ago. reply WorldMaker 3 hours agorootparentAlso, on mobile the video ads plus Fandom navigation bar now take up a sticky combined 50% or more of the viewport until you find the close button. Also, Fandom got its start by taking advantage of the easy, permissive nature of CC licenses of major early wikis, including much of Fandom started as chunks of even Wikipedia itself that got excised for \"relevance\" or other \"non-encylopedia\" factors. Even in some of the cases where communities have decided to leave Fandom, Fandom believes it remains their right to scrape the community's new site and not need to include links back to the \"real\" home, so Fandom itself becomes an SEO disaster for the community. Even communities that had hoped to protect themselves from such situations by choosing a more restrictive CC license with the NC (Non Commercial) clause have been struggling with revoking Fandom's access to their content against Fandom's legal team saying that Fandom's commercial waver to the content was both retroactive and in perpetuity, and those wikis would have known that at the time. reply krige 12 hours agorootparentprevAds, awful layout on desktop, beyond awful on mobile, slow server responses. On the flipside more wikis are actually moving OFF Fandom lately, for instance to wiki.gg reply fractalcounty 8 hours agorootparentprevThe last time I visited a Fandom wiki on mobile, it autoplayed two videos simultaneously at full volume and required me to scroll through 75% of the page to get to the actual article, which itself was also full of ads. It was so bad that it motivated me to setup my own DNS server with ad blocklists reply xeonmc 4 hours agorootparentprevFANDOM Please help us personalize your experience! [I’m an adult] [I’m a kid] reply giantrobot 2 hours agorootparentprevBesides ads and points sibling posts made: Fandom does a terrible job making a wiki an actual wiki. Their infoboxes are garbage, there's awful category navigation, and just general \"wikiness\" is entirely removed or hidden. Fandom presents wikis like they're SEO spam sites rather than actual references. Check out Wookiepedia or Memory Alpha on the Wayback machine sometime and compare them to current Fandom wikis. Even the thinly styled MediaWiki was vastly more navigable than the shit that is Fandom. The footers Fandom adds with advertisements of unrelated other wikis is also ridiculous. Fandom is SEO spam infested with intrusive and obnoxious ads and is terrible at being an actual wiki. It fails at everything but co-opting community generated content to make money. reply naravara 12 hours agorootparentprevThe pages are basically unreadable on mobile. reply anthk 2 hours agorootparentprevInstall Libredirect for Firefox/Chrome compatible browsers and set the Fandom redirection to something else. reply KPGv2 14 hours agorootparentprevUgh, that explains why the Miraculous Ladybug wiki is so godawful. reply mattlondon 11 hours agoparentprevI think the default media wiki implementation suffers from there being no nice \"page of contents\" - Wikipedia is the same but many articles have a lot of manually curated \"see also\" or \"other foos from bar\" type table of links that helps a lot, but without it, it feels to me like the default discoverability and search on media wiki are terrible. So if you are setting up your own wiki then you need to spend a lot of effort to create and maintain the ToC/landing page and build those interconnections up, and just hope Google indexes everything so you can search etc (... and if you have an internal wiki at work then you are basically screwed because Google won't index that). Otherwise you write your articles and they \"disappear\" and are not readily found. At least that was my experience of working with media wiki and dokuwiki - the sites always felt \"empty\" even if you had teams of people contributing articles, because it was hard to see what was there in a meaningful way. And so they always felt moribund and abandoned even if they actually weren't. Patiently waiting for someone to create an overhauled UX. Potentially one that does some sort of clever LLM-powered hierarchy so people can browse and peruse page hierarchies sliced-and-diced by some sort of topic/area-of-interest. So say I enter \"engines\" or something as my area of I treat, the LLM auto-categorises the pages into a sensible hierarchy that I can view, then I change my term to e.g. \"steam engines\" and it recalculates the hierarchy and shows something sensible for that etc. reply ghxst 14 hours agoparentprevWiki's are still doing well in the gaming space I think (https://oldschool.runescape.wiki to name one, has a dedicated community of thousands of players behind it). I agree with you in general though, the GitHub wikis really don't feel the same. reply jsheard 14 hours agorootparentThere are a lot of gaming wikis but unfortunately a lot of them are hosted by Fandom, and it's hard for independent alternatives to compete with Fandoms SEO. reply chii 13 hours agorootparenti wish there's more alternative to fandom. I think one of the best alternative (that is still free) is actually github pages. The problem is that the contribution model is not trivially solvable via permissioning - the owner of the github page has to approve (the PR changes). Ideally, what would be best is if there's a set of github action that would automerge changes from a list of approved contributors (who would first fork the page, make the edits and submit a PR). This set of github action would need to be a turn-key setup, without needing much technical knowledge (so that the laymen can do it). reply bawolff 13 hours agorootparentBetween miraheze, weirdgloop and wiki.gg it seems like there are quite a few alternatives to fandom. What is missing? reply rogers12 13 hours agorootparentSearch engines rank crappy inactive fandom wikis above official wiki.gg wikis. reply rcarmo 7 hours agorootparentprevThe GitHub wikis are for utilitarian documentation, not really general knowledge management. reply bawolff 13 hours agoparentprev> (or even a newer take on the original WikiWikiWeb) I think that would be http://fed.wiki/view/welcome-visitors (the author of wikiwikiweb's new thing) reply senko 9 hours agoparentprevNotion is basically a wiki too, and seems pretty popular in startups. If you squint a bit, Obsidian as well. reply zaik 13 hours agoparentprevThe Arch wiki is still going strong... reply justinator 12 hours agoparentprevThe Fell Running Wiki is excellent. https://fellrnr.com If you don't know what Fell Running is, you probably would have little use for it and it wouldn't ever be on your radar -- as would be most things outside the pale of pop culture or your own version of the Roman Empire. reply rcarmo 7 hours agoparentprevMy blog is actually a wiki, and has been going for 23 years. There are quite a few other old farts^W^Wvintage bloggers out there with similar setups. reply Kiro 9 hours agoparentprevI presume you're not a gamer. In many games I play you pretty much need to have the wiki open on the second monitor. reply zahlman 13 hours agoparentprev>it feels like outside of Wikipedia they've been dying My understanding is that Wikipedia has been in decline (in terms of user activity) since 2007 (much as Stack Overflow has since 2014). reply 3eb7988a1663 13 hours agorootparentWhen it first started, there were great swaths of stuff that could be written. Some huge fraction of history, art, science, etc now all have pages with some level of detail. To continue ongoing maintenance for current events is going to take significantly less activity. reply Gigachad 11 hours agorootparentAnd the stuff that isn’t already on Wikipedia generally has too few primary sources to be allowed to be created. So the ongoing edits would be primarily updates to existing content rather than new stuff. reply bawolff 13 hours agorootparentprevI think it was declining, but somewhat stabilized around 2015. reply rr808 14 hours agoparentprevThe last few jobs I had all ran confluence for docs. I dont know why its so slow but does the main things you want. Any tips on docs that integrate with support tickets and maybe some AI would be great. reply mrweasel 11 hours agorootparentDoesn't Jira and Confluence just integrate seamlessly? Unless you want some particular feature? Both systems are able to link to each other. I worked for a company where Jira was configured to take a support ticket, and then link it to a knowledge base article in Confluence based on namespace and topic I think. reply smallmancontrov 13 hours agoparentprevosdev.org is still one of the greats, but in general you're right, they seem to be getting rarer for new projects. reply drewcoo 14 hours agoparentprevThe whole wiki notion is decentralized and free . . . everyone adding things as needed. That conflicts with things like known governments and corporations: authoritarian, if not also bureaucratic. The attempts to control wikis make people much less likely to contribute. reply fl0id 11 hours agoparentprevAlso Wikis rot too reply INTPenis 9 hours agoprevThat's complete rubbish. Information rots, whether it sits in a blog or a wiki doesn't matter. A blog can be updated, can show its last updated date, just as a wiki does. The statement hits home with me because over the past 20 years I have actually gone back and forth between having a wiki as a personal website and now finally back at blog again. I find that markdown + tags is the best way to organize my personal knowledge base that I call a blog. My attempts at using Wikis always felt overkill. reply fractalcounty 8 hours agoparentI interpreted the poem less as a literal manifesto against the practicality of blogs and more as a metaphor for how the format impacts us psychologically. Blogs, being chronological and linear, feel a bit disposable—you post and move on—which promotes rot. Wikis, on the other hand, are dynamic and interconnected, inviting ongoing growth and freshness. I still don't really really agree with that either, though. I tried swapping out my simple static blog for a MediaWiki instance and quickly realized why you don't see many people doing that anymore. Maintaining a \"complex abyss of ever-evolving thoughts\" and actually writing stuff are often mutually exclusive reply wink 3 hours agorootparentAs someone who regularly finds pages on his own wiki that have not been changed for 10 years (and forgotten): I kinda disagree :P reply tasuki 4 hours agorootparentprevMediaWiki is too much of a pain to maintain for single user. I use Vimwiki: easy to version control, no database to maintain, familiar (to me) interface. Back up by git push/pull to/from many places. reply daymanstep 9 hours agoparentprevdo you find that a blog (with the web interface) adds any value over just having a git repository of markdown files that have tags inside? reply INTPenis 5 hours agorootparentYes it adds value to see an interface, funny you should mention that specifically because recently I was on the job market and I created a Hugo blog where each job I applied for was one post. So I could keep track of when I applied, how, interviews, results and so forth in one markdown file. Then when it was time to report my job applications to the government so I would get money I just ran hugo server and looked at them graphically and chronologically. reply oneeyedpigeon 8 hours agorootparentprevI'm guessing the main advantage is navigational structure - while I agree that can be overdone, and I practice very minimal navigation on my own 'blog', I think some amount can make the pile of markdown files easier to read. reply Apocryphon 8 hours agoparentprevBlogs are normally run by a single person (unless for a publication), wikis are normally run by a community. Hence someone can discover a wiki and edit it long after its original creators have departed, so long as it wasn’t set to private. The best that discoverers of an old blog can do is to write in the comments section. Maybe reblog it and hope that pingbacks (remember those?) get triggered. The implicit invitation to collaborate is what gives the wiki longevity and the possibility of resurrection. reply arjie 9 hours agoprevI’m sure it will come to bite me in the ass one day but my personal site is a wiki written in the style of website that I’d write as a teenager: random updates about things and my life without any overlying theme or brand. I just write what I think, sticking my Blog entries under the Blog category and posting things haphazardly otherwise. Other things I do that one doesn’t these days but you’d be eager to do in the past is that I’m public about my life. Funnily enough, it was someone else’s comment about Wikipedia deleting their article (which I did manage to recover) that pointed me to a Japanese mathematician. His website filled me with such nostalgia. There were all these stories of his life and things like that. We used to put things like that on the Internet. The one thing I did miss back then was the ability to make small updates to people’s websites to fix typos and so on. So my website is a wiki (it’s just Mediawiki). It’s been vandalized before by bots but I make nightly backups to R2 so I just dump and restart if things get ugly. Otherwise, it’s been fine. One thing that might be fun is if someone one day happens upon my site and feels that sensation of looking at someone’s lived life. reply ninalanyon 9 hours agoparent> We used to put things like that on the Internet Some of us still do. But I think it was always very much a minority even on platforms that encouraged it. See Similarworlds.com, a successor to the Experience Project. reply skrebbel 9 hours agoparentprevHey I enjoyed reading your site! Also, notably, it made me aware of the word \"Bundeshausfrau\" which is my new second-favourite German word (after the un-dethroneable \"Sitzpinkler\"). reply sshine 9 hours agorootparentI’m a sucker for “Krankenhaus!” reply mikae1 5 hours agoparentprevLovely lil wiki you have! :) reply internetter 14 hours agoprevI quite like the \"Wiki\" on my site. It's half blog, half wiki. The entries can be dated. They are presented chronologically. Navigation metadata is assigned to each entry. But not every entry appears on the blog feed. I can link between entries like [[link]]. Each entry tracks the links to and from it. The best of both worlds I think ^^ reply simonw 14 hours agoparentI'm contemplating adding something like that to my https://simonwillison.net site at the moment: most of my content works great as a blog but I like the idea of having some content that's more \"page like\" which I can continually update - things like a list of currently active projects. reply PhilippGille 12 hours agorootparentMartin Fowler calls it Bliki: https://martinfowler.com/bliki/ reply rcarmo 7 hours agorootparentYeah, although the form predates the term. reply internetter 14 hours agorootparentprevIf you'd like a reference implementation, it's all under AGPL here: https://github.com/boehs/site :) reply smnrg 14 hours agorootparentprevJulian.com (Julian Shapiro) is a great, hyper-focused example of regularly refined pages. reply wakawaka28 12 hours agoparentprevDates are very helpful, especially for information about software. reply OuterVale 10 hours agoprevPerhaps the greatest contributor to the philosophy behind my own site is taken from the website of Wendy Carlos. Her site houses a page describing how her website ‘lives’: [1] > I’m happy to report that this page (like most housework) will never be finished. It is a living document that grows and matures, just like most of real life. It is not a “work in progress”, for this would imply not much intrinsic value until that magic day it is completed. > A novel is a work of art that, once completed may continue to exist forever in that finished state. An encyclopedia must be published at regular intervals to reflect new information gathered since the day it was published. Periodicals are timely only when first printed, then fall behind the times – get the latest issue to keep up. The technology behind web documents allows us to update information as often as is necessary. In this context, publishing dates become an outdated concept. > While it is possible to “finish” a web document, the fixed information becomes stagnant, thus abolishing any desire for a return visit. This is something I call a cob-web page. [1]: https://www.wendycarlos.com/live.html reply gritzko 11 hours agoprevWithin my current project, I use a special C dialect. So, I have to write a lot of explanatory text for those who dare to use it. And even in solo projects, I have been in situations when I had to check my own docs to understand what's going on. As a result, my project is effectively also a wiki: https://replicated.wiki/abc/ https://github.com/gritzko/librdx/tree/master/abc The idea is to put motivational and explanatory text into the parallel wiki, while all the API docs stay in the code the normal way. These are seriously different things. The next step to unit tests all the code docs. Or, the other way around, to document tests to make them joy to read. That is the only way to solve doc rot. Overall, I am trying to get as close to Literate programming as practically possible: https://en.wikipedia.org/wiki/Literate_programming Because code is hypertext, IDE is a browser. reply kmfrk 4 hours agoprevStatic blogs and dynamic blogs are also leagues apart given how much less is susceptible to rot. GitHub.io blogs feel like something that came and went, but maybe the SEO wasn't there enough for people to stick with it. The resurgence of newsletters is also another revitalization of blogs with better syndication (e-mail over RSS). Probably not a great time to operate a WordPress blog though. reply fractalcounty 9 hours agoprevLovely poem, but I don't 100% agree with the idea that the wiki possesses some kind of ethereal, spiritual advantage over the blog. The post-SEO internet has been unkind to all forms of online writing, and the wiki has been an equally effective vessel for the proliferation of rot as any other (looking at you, Fandom). From a practical perspective: Blogs may rot, but wikis decay. Larger projects with established community manpower may not struggle with offsetting the maintenance and complexity that traditional wikis demand. For personal writing, however, the burden of preventing decay falls entirely on the author- and it's not a trivial burden. Like others have mentioned, there seems to be an absence of great wiki software offerings that do a great job of mitigating said burden. The few I have tried introduced an inherent complexity and maintenance overhead that significantly detracted from the core activity of writing. Regardless, I'm hoping that it's just an engineering problem that has yet to be solved instead of an unavoidable characteristic of the medium itself. I would love for the wiki to make a big comeback. reply xenodium 13 hours agoprevDoing my bit to bring pre-seo-driven, or just genuine blogging to the foreground. Just launched https://lmno.lol blogging platform (no tracking or ads here). Read blogs from anywhere. No JS required. reply WaitWaitWha 13 hours agoprevAlthough I am not fond of the fixed flow of blogs, I have yet to find a \"wiki\" or similar mind-map-like tool that allows me to write better interconnected, non-linear writing that also works with a static site. Any ideas? reply wonger_ 12 hours agoparentTiddlywiki https://tiddlywiki.com/ is good at cross-linking notes and publishing to the web. Consider writing plain HTML and calling it a digital garden, so you aren't locked into the chronological feed blog mindset. Maybe Obsidian Publish? https://obsidian.md/publish#:~:text=Explore%20Publish%20site... Although it's a paid service and it seems a little clunky. reply rcarmo 7 hours agorootparentTiddlywiki suffers a lot from being heavily JS-based. reply audiodude 13 hours agoparentprevhttps://tiddlywiki.com/ maybe? reply danieldk 10 hours agoparentprevObsidian with Quartz: https://quartz.jzhao.xyz reply rcarmo 7 hours agorootparentQuartz completely breaks down with very large sites since it does client-side search, making it really hard to find things. It’s still too young. reply Shank 11 hours agoprevI really love the idea of keeping a wiki, but for the same reasons j3s self-hosts a single binary for the blog, none of the wiki software that exists is particularly appealing to host and it sounds like a relatively large amount of work to build something like this from scratch. reply kqr 8 hours agoprevCounterpoint: I subscribe to many blog RSS feeds because the content comes in a useful format and appropriate cadence. I have never subscribed to a wiki to get regular updates for it. reply altairprime 14 hours agoprevNote that the usage of “blog” in this poem has nothing to do with livejournals and pre-spam personal journal blogs in general; it’s referring to the post-indexing apocalypse brought on by SEO and Google reacting to ‘freshness’. reply mro_name 8 hours agoprevfrankly I find rot quite appealing. Rotting produces compost, fertiliser. And at the same time makes way for new things. Great, isn't it? reply fractalcounty 8 hours agoparentThe expression \"polishing a turd\" comes to mind. reply openrisk 8 hours agoprevAfter the history-making success of wikipedia the wiki movement has unfortunately stagnated. Wikinomics [1] is yet another early vision of the digital society that did not come to pass. The reasons as always quite complex: from the general decline of the public internet due to centralization / enshittification (and now wholesale appropriation), to poor technology choices and missing value propositions that could induce the next wave of adoption and development. Yet there is still no tangibly better alternative vision for open source knowledge management, especially if of the collaborative kind. One interesting direction - yet after more than a decade still largely in embryonic phase as far as broad adoption - is wikibase [2]. It runs as an extension of mediawiki and makes it relatively painless to integrate structured data in a semantic web style (e.g. [3] for an example of integrating veris [4] data). Its not clear if the wiki era is permanently dead or it just waits for some rain to blossom again. [1] https://en.wikipedia.org/wiki/Wikinomics [2] https://en.wikipedia.org/wiki/Wikibase [3] https://www.openriskmanual.org/wiki/Special:WhatLinksHere/It... [4] https://github.com/vz-risk/veris reply diggan 7 hours agoparent> One interesting direction - yet after more than a decade still largely in embryonic phase as far as broad adoption - is wikibase [2]. It runs as an extension of mediawiki and makes it relatively painless to integrate structured data in a semantic web style (e.g. [3] for an example of integrating veris [4] data). I agree a lot with this. As a person who speaks many languages, something that gets evident very early is that isn't one \"The Web\", but many webs like English Web, Spanish Web, Portuguese Web and so on. This is extra noticeable on Wikipedia, since many articles exist in many languages. The drawback is that sometimes information is split across the languages, so someone speaking English, Spanish and Swedish can sometimes build a more complete picture from just one Wikipedia article, if the data isn't in the other article languages. Enter Wikidata+Wikibase, which makes the knowledge itself trans-language, and instead only the definition/value names need translated, but the composition itself is language-agnostic. If this imaginary article with separate info in three languages for one article could all use Wikidata as a base, they can all share the same knowledge and make sure that people who only speak one of the languages, come out with the same understanding. Basically, Wikidata if successful, will multiply the knowledge on the web! reply anthk 2 hours agoprevGopher holes and Gemini capsules don't. Also, there are tons of small blogs out there. reply j3s 13 hours agoprevironically i posted this on my blog 3: reply topato 13 hours agoprevOh GOD! PLEASE don't kill vore.website!!! I very much appreciate that service!It's timely that Oxford 'academics' have no idea what 'brain rot' means but Urban Dictionary (A wiki) gets it right. I have never seen Brain Rot used consistently with any of the UD definitions, and always consistently with the OUP's definition. reply emodendroket 13 hours agorootparentI agree with you. Also, Wiktionary is much more Wiki-like and a much better resource than Urban Dictionary. reply Macha 7 hours agorootparentprev [–] The front page of urban dictionary's definitions are all added post 2020, which fits since the urban dictionary usage is the way far more online members of gen z use it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post contrasts the enduring nature of wikis with the transient nature of blogs, suggesting that by 2025, wikis will become more personal and meaningful.",
      "Wikis are described as dynamic and reflective of the writer's evolving thoughts, whereas blogs are likened to static, forgotten storefronts.",
      "The author is transitioning from a traditional website to a wiki format, indicating a shift in how personal content is managed and shared."
    ],
    "commentSummary": [
      "Blogs offer a time-specific snapshot of an author's thoughts, allowing for updates through new posts, but often lack timestamps for context. - Wikis, such as Wikipedia, can struggle with clarity on update timing and reliability, leading to potential outdated information. - Both blogs and wikis have unique advantages and can coexist, serving different purposes in content creation and knowledge sharing."
    ],
    "points": 176,
    "commentCount": 110,
    "retryCount": 0,
    "time": 1735788777
  },
  {
    "id": 42571608,
    "title": "Meta Wants More AI Bots on Facebook and Instagram",
    "originLink": "https://nymag.com/intelligencer/article/meta-wants-more-ai-bots-on-facebook-and-instagram.html",
    "originBody": "SCREEN TIME DEC. 31, 2024 Meta’s Big Bet on Bots Why AI friends are coming to Facebook and Instagram. By John Herrman, a tech columnist at Intelligencer Photo-Illustration: Facebook Among Meta’s many resolutions for the new year — making augmented reality and the metaverse happen, positioning itself to absorb TikTok refugees if the app gets banned, cracking open Apple’s platforms to get more access to user data, and attriting its competition in artificial intelligence with breathtaking spending — one stands out as plain weird: filling its social-media platforms with bots. According to the Financial Times: The Silicon Valley group is rolling out a range of AI products, including one that helps users create AI characters on Instagram and Facebook, as it battles with rival tech groups to attract and retain a younger audience. “We expect these AIs to actually, over time, exist on our platforms, kind of in the same way that accounts do,” said Connor Hayes, vice-president of product for generative AI at Meta. “They’ll have bios and profile pictures and be able to generate and share content powered by AI on the platform . . . that’s where we see all of this going,” he added. The company has been talking about this for a while, to somewhat bewildered responses from the general public. The simplest explanation for what it’s doing is that the company has invested a lot in building generative AI models and would like to get a return on its investment through its most lucrative products: If there’s any economically productive way for Meta to plug AI tools into Facebook, Instagram, and WhatsApp, it’ll consider it. But Meta, a company with no qualms about chasing, copying, and acquiring its way into trends, is also reacting here. It bought SocialAI, a Twitter-ish “social network” where users’ “feeds” and “comment sections” are filled entirely with bots playing different characters. At the same time, it’s surely noticed that its platforms are already filling with AI slop anyway and that some of this slop was creating a lot of engagement, meaning that, in the ways that matter most to Meta, it’s not really slop at all. The company also clearly noticed the rise of Character.ai, the popular — but possibly doomed — lawsuit magnet of an app in which young users create and chat and act out fictional scenarios with AI characters. Still, Meta’s framing here is unique to the company. It’s by far the leading American social-network firm, with more than a billion actual people using its products around the world to interact with one another. Practically everyone in tech is trying practically everything with AI, but Meta, the suggestion goes, is in a singular position to populate shared human spaces with synthetic characters, and it seems to think it’ll work. As galling as this might sound to a casual Facebook user — after years of characterizing fake and automated profiles as spam, it’s okay now if Meta is running the accounts and they’re a little more convincing? — it has the benefit of sounding somewhat new and novel. Maybe these personas really will be engaging enough to post and respond alongside your friends, family, co-workers, and celebrities in your existing social-media feeds; maybe social-media feeds are the right place to encounter highly specific chatbots; maybe these chatbots can be entertaining or even helpful in the context of the apps users already check multiple times per day. It might not be a convincing story, but it’s a story: There are increasingly intelligent bots among us, and they’re joining social media. The main benefit of this story is that, like a lot of AI products — it’s right there in the name! — it anthropomorphizes the underlying technology. A less compelling but perhaps more honest and useful way to characterize Meta’s impulse here is as the next step in a long process of automation and social mediation. When Facebook and Instagram were new, the content you encountered wasn’t just created by people you knew or chose to follow — it carried with it legible and obvious evidence of provenance. If you saw something from someone you didn’t follow or intend to interact with, it was because someone you know chose to share it; if you posted something, you could mostly assume it would be seen by people who intended to see it, and maybe by more people they intended to show it to. Well before the rise of TikTok, which mostly replaced follow/follower relationships with opaque algorithmic distribution, but especially after it, Facebook and Instagram have leaned hard into subtler forms of automation: content recommendations; people recommendations; unexplained stuff appearing in feeds, as Reels, or bugging users in notifications. The result is platforms where users are consuming more content but in some cases producing less, spaces that function less like social networks than like targeted advertising systems for everything. A lot of formerly social aspects of a platform like Facebook, in other words, have already been automated and replaced with machine learning, but each step in this direction has been subtle and somewhat concealed: You don’t really know, and certainly aren’t clearly told, why Meta assumes this or that Instagram Reel is something you want to see, or why one thing appears above another in an algorithmically sorted feed. The idea of introducing AI characters into Meta’s platforms is in some ways distinct and new — we’re talking about not just automating content curation and promotion here but, in some cases, actual creation — but can also be understood as a way to rebrand an effective but alienating overhaul that’s been a decade in the making. With many AI products — from ChatGPT to a customer-support bot — the performance of personhood, which is a bit of a misleading magic trick even when done carefully, is at least as important as raw capabilities. Meta can claim it’s building technology to create social-media agents that can exist on its platforms “in the same way that accounts do,” and maybe it’ll turn out to be right. But Meta’s AI characters are also a way to slap a more friendly, humanlike face on a long, bloodless campaign of social automation. SIGN UP FOR JOHN HERRMAN COLUMN ALERTS Get an email alert as soon as a new article publishes. Email TAGS: JOHN HERRMAN SCREEN TIME TECHNOLOGY ARTIFICIAL INTELLIGENCE MORE SHOW 23 COMMENTS",
    "commentLink": "https://news.ycombinator.com/item?id=42571608",
    "commentBody": "Meta Wants More AI Bots on Facebook and Instagram (nymag.com)172 points by marban 14 hours agohidepastfavorite307 comments EcommerceFlow 4 hours agoThis gave me a funny idea for a new social media app... One that's centered around \"you\" and filled with thousands/millions of LLM bots praising you, treating you like a celebrity, etc. Each of your posts will get tens of thousands of \"likes\", hundreds of comments, etc. Dm's straight to your feed, people wanting you, etc etc. If the newsfeed is already mostly \"the algorithm\", might as well take it to the extreme. I bet tons of people would get addicted to the dopamine hit of celebrity status (whether it's bots or not). reply onlyrealcuzzo 4 hours agoparentThis is sort of TikTok, right? Wasn't TikTok known for becoming viral by having tons and tons and tons of fake upvotes for everything to make everyone think TikTok was a better place to post content [1] [2] [3] [4] [5]? Facebook and Instagram had the same \"problems\", they just addressed it much earlier than TikTok. I would imagine they have already tested fake likes to maximize how believable the like ratio can be, but who knows - maybe there's opportunity left to be more fake? [1] https://g.co/gemini/share/3fbe558d4191 (Ask Perplexity, GPT, or Claude the same question - you'll get a similar answer) [2] https://www.indiehackers.com/post/tiktok-views-are-inflated-... [3] https://www.vice.com/en/article/get-buy-tiktok-followers-lik.... [4] https://medium.com/dfrlab/suspicious-third-party-apps-moneti... [5] https://www.statista.com/statistics/1308893/tiktok-accounts-... reply oefrha 3 hours agorootparentEvery single one of your supposed citation talks about third parties selling engagement, except some speculation in [2]. Even the AI answer doesn’t support your claim, and regardless it’s super ironic that you consider several AI agents giving you similar answers about real world events strong evidence of anything. reply onlyrealcuzzo 3 hours agorootparentAre you implying that TikTok had >50% of likes coming from bots and didn't know it? You don't need to fake the likes yourself to get the effect you want. The same thing was happening on Instagram and Facebook - just at a much smaller ratio - mostly because they stopped the problem earlier and the bot technologies got better and easier while TikTok was trying to grow and doing nothing to stop it - not because Instagram and Facebook were less fake. reply oefrha 1 hour agorootparentI’m saying you gave a bunch of “citations” that don’t support your claim. And your original claim is TikTok the first party boosted content with tons of fake upvotes to appear more viral, which you seem to have modified to a much weaker “they knowingly allowed third party bots to fester in order to appear more viral” in your reply. Now, does either of the original strong claim or the subsequent weak claim match reality? It’s anyone’s guess, I’m leaning on likely for the latter and maybe for the former. But that’s not the point. Giving fake citations to make one’s argument appear stronger is what irks me, and again ironically, it’s almost a parallel of appearing more viral with fake likes. Edited to add: your comment here is a perfect example of two problems on HN: using citations to give the impression of being well-supported when the citations say something else (occasionally the exact opposite); and lately, using AI slop as evidence. reply yitianjian 2 hours agorootparentprevIt’s super interesting some platforms in China have discarded view counts and likes in favor of engagement scores, more ways to show a big exciting number to the creators reply albedoa 25 minutes agorootparentprev> Are you implying that TikTok had >50% of likes coming from bots and didn't know it? I wonder if you are able to map any part of this to any part of the comment you are replying to. reply PaulHoule 3 hours agorootparentprevReddit too... https://www.vice.com/en/article/how-reddit-got-huge-tons-of-... reply qwertox 2 hours agorootparentprevI feel so stupid about never having thought of this; how naive am I? I mean, yes, I knew about people paying for likes in order to boost their visibility, but never imagined that the platforms themselves would add fake likes to accounts in order to make their users feel more happy about the platform. This makes me question the reason for X making the move to hide the origin of likes, even if my posts never receive any likes, except for likes from bots. Talking about bots, since uBlock Origin breaks my \"block user\" button, I've resorted to block bots by reporting them as accounts encouraging suicide, this then gives me a \"block user\" button which does work. The interesting thing is that all of these accounts still do exist, never get removed, even though it's obvious that they are non-user accounts ( like https://x.com/Siothit074kkNx ). reply hibikir 1 hour agorootparentThis happens in videogame matchmaking too: Someone that loses too much quits, so you want to giving people a positive boost of a very easy game every so often if they lose too badly. Filling lobbies with bad bots does this effectively reply mentalgear 3 hours agorootparentprevmaybe add a source reply Retr0id 4 hours agoparentprevThere are several of these already. Example: https://apps.apple.com/us/app/socialai-ai-social-network/id6... Surprisingly, it has broadly positive reviews. Maybe Meta is onto something. reply hn_throwaway_99 2 hours agorootparent> Surprisingly, it has broadly positive reviews Gosh, I wonder who could be leaving so many positive reviews on an app designed to have fake AI bots praise you: > I’ve been using SocialAI for a while now, and it’s been an incredible tool for both reflection and connection. The AI-powered conversations feel tailored to my thoughts and moods, making it a great space for journaling or just venting. It’s refreshing to have a social app that focuses on you and doesn’t rely on real users, which creates a unique, private experience. I also love the therapeutic aspect, as it feels like you’re always heard and supported by a community of AI followers. Overall, it’s a fantastic tool for personal growth and mental wellness, especially if you're looking for a safe space to express yourself. Highly recommend! Awesome, that totally sounds like a Real Human wrote that! Add this to my \"nuke it from space\" bucket... reply StableAlkyne 49 minutes agorootparentprevWhenever an on-device variant gets figured out, this could be a fun way to keep up with journaling. Especially if you want an alternative to the dopamine steam social media provides. In fact, this type of program could lend itself very well to on-prem hardware. Social media is by its nature asynchronous; waiting minutes or hours for a reply is completely acceptable. That means your only real hardware requirement is enough RAM to fit the LLM. Would be a lovely experiment to try and make a simulacrum of Usenet or the forums of old, since even days between replies are acceptable in that case. reply jonny_eh 1 hour agorootparentprevThe creator of that app got re-hired by Meta. Looks from the outside like an pseudo-acquisition. reply cultofmetatron 2 hours agorootparentprevthat has to be the most black mirror nightmare fuel I've seen so far this year.... reply lazide 1 hour agorootparentEspecially because you know a bunch of people will pay for it. reply ceejayoz 1 hour agorootparentHonestly, we should crowdfund a subscription for certain prominent folks. It’d be crack cocaine for some of the influencers and whatnot out there. reply TeMPOraL 18 minutes agorootparentInfluencers are drug dealers, not drug users, and they're in this for the money, not for the high. reply EcommerceFlow 3 hours agorootparentprevThank you, my dreams have finally come true. reply some_furry 3 hours agorootparentI think I just heard the sound of a finger on a monkey paw curling. reply kridsdale1 2 hours agorootparentprevMatt Sayman was a PM in my org at FB in 2015. Smart guy. He was 18 at the time. I watched his journey on Threads as he taught himself to program this year in order to make that app. Proud of his success. reply jonny_eh 1 hour agorootparentMichael Sayman? reply joenot443 2 hours agoparentprevIt might be heavy, but I really like the idea of someone building this to run offline and completely on-device. Maybe branded as a sort of 'personal journal with an audience'. My experience with mobile diaries is the biggest challenge is encouraging the user to keep up the habit. I'm very curious if this could be solved by introducing a new cycle of feedback from AI peers who would feign curiosity about my life. Could you see people using that? reply FireInsight 2 hours agorootparentDoes it come with people picking you apart, hatemail, unsolicited nudes, etc.? reply joenot443 2 hours agorootparentI think in an ideal world you could groom your audience to your liking! Personally, if I could suspend my disbelief, I'd love an army of virtual techies telling me how clever my ideas are. Others might prefer a legion of other super moms praising their selfless parenting when no one else does, or like you were getting at, maybe just a peanut gallery! Image gen on-device might be tough, we'll save that for the 1.1 release ;) reply ndileas 1 hour agorootparentEven humorless curmudgeons (like me) can get in on the action with a huge array of people to disagree with, act snobby to, and never before heard of stupid opinions! reply krisoft 2 hours agorootparentprevI'm not sure if you are sarcastic, but your definition of \"ideal world\" feels very different from mine. What you describe sounds as close to the scifi concept of wireheading as I can imagine to get without brain surgery. reply joenot443 1 hour agorootparentI'm being tongue in cheek, for sure. Let's pretend I said \"ideally\" instead, as in, \"ideally the product would function this way\". I admittedly wouldn't be the target audience for this concept, nor would I take up wireheading. When I see the huge success of Character.ai or the above SocialAI though, I'm really convinced there's a market segment of people younger than us who get a lot out of communicating with virtual \"friends\". reply consumer451 4 hours agoparentprevI posted this basic idea here a while back, based on a reddit post. Wow, I can't believe it's already been two years. I personally find this to be the scariest form of psychological conditioning that I can imagine. It is just pure mind control, with no \"social\" window dressing. https://news.ycombinator.com/item?id=34597562 reply sheperd 4 hours agoparentprevAlready exists, social AI. Meta hired the owner to implement this feature. Doesn't hurt to create a competitor if you're interested though! reply kridsdale1 2 hours agorootparentWait really? Matt was boomeranged? reply joenot443 1 hour agorootparentHere's the announcement post - https://x.com/michaelsayman/status/1835841675584811239 Looks like his name's Michael and that indeed, he's presently at Meta. If you end up reading this Michael, great product! reply quantified 24 minutes agorootparent> Introducing SocialAI, a private social network where you receive millions of AI-generated comments offering feedback, advice & reflections on each post you make. Ah, to be heard by machines! Must be as fulfilling as playing with dolls. reply jonny_eh 1 hour agorootparentprevWho's Matt? reply jaysonelliot 4 hours agoparentprevThis sounds so absolutely absurd that it would probably work. reply kibwen 4 hours agorootparentOne of the fundamental rules of our modern world is that if your business model is indistinguishable from the plot to an episode of Black Mirror, then you're about to be a millionaire. reply lioeters 2 hours agorootparentPalantir CEO at the 2024 Reagan National Defense Forum: > Our adversaries do not have our moral compunction if it's even. They will take advantage of our niceness, kindness, our desire to be at home in Nebraska or New Hampshire or wherever we live in our peaceful environments. And they need to wake up scared and go to bed scared. > My version of service is the soldiers are happier, the enemies are scared, and Americans go back to enjoying the fact that we're the only one with a real Tech scene in this country, and we're going to win everything. reply rthajl 1 hour agorootparentStriking the iron while it is hot. A couple of people may find out within 10 years that the defense industry is cyclical, too. reply bilater 33 minutes agoparentprevThat is the end game - your own little miniverse with you as the central character. And I think thats awesome. reply zzzbra 31 minutes agorootparentI ask you honestly -- why? Why do you think it's awesome? It sounds like hell to me. reply IG_Semmelweiss 2 hours agoparentprevSounds like a decent plot line for idiocracy 2.0 Jokes Asier, i think this is more likely than what we want to believe. Tiktok grew on the basis of showing you random but interesting content. If AI can do it , there's nothing preventing that from succeeding. Itd be a new form of entertainment. Content is already spamming the greater web. Ita bound to happen w multimedia/rich media reply darepublic 2 hours agoparentprevThere would be the need for some adversity too. Bots playing for the other team, tailored so that with effort you can outwit and out reason then and stop the spread of their social media shenanigans reply nemomarx 2 hours agorootparentyeah the one I saw before let you pick sarcasm levels and a few other traits like that? I assume you'd want more sophisticated prompting to enable winning arguments and dunking on them but it seems like a solid strategy. reply jkestner 3 hours agoparentprevCheaper than buying Twitter. reply nemomarx 4 hours agoparentprevI swear someone demoed this on HN in the last year? it does seem workable. I've at least heard of companies investigating heaven banning where problem users are put in a bots only space to keep them happy or something.. reply fullshark 2 hours agoparentprevThere are already plenty of video games where the user gets to live out some wish fulfillment fantasy. reply morkalork 3 hours agoparentprevThat sounds just like the \"TV show\" from Fahrenheit 451, just endless conversations about nothing where you are the star. reply sd9 4 hours agoparentprevThis actually sounds plausible and that it would be successful. reply smallmancontrov 4 hours agoparentprevSigh. This is going to be a thing, isn't it? On second thought, social media monetizes negativity and this does the opposite. Fight fire with fire? reply gedy 2 hours agorootparentI suppose you could tune the experience for whatever people want, downvotes, etc. \"I'd like to have an argument, please.\" reply Vagari 4 hours agoparentprevYou could even create targeted brands: \"Narcissistic Social\" -where everyone sees you the way you think you are- reply whydoineedthis 2 hours agoparentprevWant a partner to help build it? Count me in. reply SecretDreams 3 hours agoparentprevWe could call such an app \"echo\". reply ljm 3 hours agorootparentI feel like this would be 'echo', but 'echo' in the context of House of Leaves. An app appears on your phone. You didn't install it. Nobody else except you seems to have it. They can't see it either. A doorway to a non-euclidean dimension existing just outside your mind. The chatter of millions of thoughts reflected back at you from seemingly infinite personalities, dimly distinguishable through the void as faces you can't recognise. It's all you. They've learned from you. They're telling you what you want to hear. If it didn't feel so pleasant, it would be madness. reply LudwigNagasena 1 hour agorootparentprevEcho and Narcissus. reply scotty79 1 hour agoparentprevMake it a dating app. If you don't go overboard with response rate most men won't notice. reply zeroCalories 4 hours agoparentprevIf something like this does happen I imagine it would target a small segment of the population, as this would be very expensive. reply EcommerceFlow 4 hours agorootparentGiven the average IG comment, a 300m parameter model should suffice. reply smallmancontrov 3 hours agorootparentSounds about right, and we just elected GPT-2 president, so 1.5b parameters is an upper bound on what you need to impress most people. reply krapp 3 hours agorootparentFake news. The president has so many parameters, you wouldn't even believe it. All the biggest, best parameters. American made parameters, best in the world, genius, genius parameters. You wish you had parameters like these. reply datadrivenangel 3 hours agorootparentwe're talking trillions people reply qwerpy 3 hours agorootparentprevAnd somehow still an improvement over the last one, who had a painfully small context window that would randomly clear. reply exe34 2 hours agoparentprevas a chronically lonely person, I always dreamed of the day AI would reach today's level so that I could create a few imaginary friends for myself. As it happens, I've just gotten used to it now, so I have lost interest in making that sort of thing. reply lazide 1 hour agorootparentLt. Barclay is both hero and cautionary tale. reply exe34 1 hour agorootparenthonestly if addiction was the only impediment, I wouldn't care. it's just that I don't care enough anymore. reply Tarsul 50 minutes agorootparentDid you get bored of your AI friends? reply entropicdrifter 40 minutes agorootparentprevYou sound deeply depressed, you know that right? reply Culonavirus 3 hours agoparentprevI don't know, I feel like you have be a pretty low IQ person (I'm talking about the millions of people on the far left of the IQ bell curve) to consider any interaction with a bot as socially meaningful or stimulating (dopamine). Maybe if you used some future LLM and hidden the \"this is a bot\" icon, more people would interact, but as it stands, only dumb people (and there's not that many of them, again, normal distribution) will buy into it. The kind of people who \"fall in love with their AI girlfriend chatbot\" would be your income stream. Lmao. (Thinking about it now, I don't think I've ever heard about a female doing this... probably because the dumbest of us men are far dumber than any woman.) reply freehorse 2 hours agorootparentMy impression from reddit posts was that replika had/has a lot of female users. Though I do not think that I personally understand it, I think that there are many reasons people can \"fall\" for something like this and circumstances that can drive it. Loneliness is not to be underestimated. In any case, I am not sure it is _that_ much \"dumper\" than the parasocial relationships with onlyfans (or other) influencers, for examples, that people also fall for. reply herbst 1 hour agorootparentI build a diy-sexy-chatbot in the past, that's also the way I advertised it more or less. And to my own surprise many people choose to use it in a non sexy way. I don't know what they talked about (obviously) but many choose neutral tags like 'honest' 'sweet' 'pessimistic' over all the kinky stuff I gave them. Later I tried a similar approach advertising it less sexy and that didn't convert at all. I think people actually think they want sex but in the end they just want company reply smallmancontrov 2 hours agorootparentprevBack when character.ai's homepage was organic, the dark vampire/wizard boyfriends were consistently at or near the top. Loneliness is definitely not unique to men. reply freehorse 56 minutes agorootparentIt does not surprise me, and even disregarding loneliness per se as a factor. The erotic fandom/fanfiction space, and in general (written) erotica, was afaik always female dominated. I have not really followed this space recently, but it would not surprise me if roleplaying with yaoi-trained llms (or whatever is trending nowadays) was a thing right now in such subcultures. People there have _a lot_ of material to train stuff on. reply nemomarx 3 hours agorootparentprevcharacter. ai exists somewhat profitably right now, and Replika had very dedicated users, so that doesn't rule out an audience who just wants to be lied to reply amyames 1 hour agorootparentC.ai they changed their model at some point and now I get short, terse, boring responses as if it hates talking to me. I felt like I lost a friend when they lobotomized it. reply bilbo0s 3 hours agorootparentprevThinking about it now, I don't think I've ever heard about a female doing this Gentlemen I give you, the latest iterations of the Nigerian Romance Schemes. reply PaulHoule 3 hours agorootparentprevIt's not IQ but emotional intelligence. Resistance to high pressure tactics is its own thing. You may be foolish (unwise) if you fall for: (1) the extended service plan when you buy a new car, (2) get convinced you need to pay the IRS or FBI with gift cards, (3) get hit with a one-two punch of love and crypto. You're not necessarily low IQ. Personally I've had many fun conversations with A.I. that made me feel good, even a little giddy, but I've had my share of experience with getting giddy and can recognize it for what it is. (see [1] for some explanation of what I mean of \"giddy\") My profile for the person who falls for the crypto scam who is 50+, has been in love and can recall what it feels like (a loveless 25 year old has themselves to blame, a 50+ could have had it and lost it) but is lonely because they've lost love) My evil twin would say that if you're trying to seduce people your \"self\" in the sense of [1] can get in the way. For one thing people have a desire to get mirrored which you can not always do because of the \"counter-transference\", in the sexual space you might find somebody else's turn on is a turn off for you for instance and it can be very hard to suppress that enough to keep somebody on the hook as it shows in terms of tension in your body, facial microexpressions, a faltering voice, etc. If you are lucky they are so self-absorbed that they don't notice; you get hundreds of chances to screw this up and most people find it tiring to keep up the front. There's a continuous male complaint, for instance, that women often seem to be attracted to \"bad boys\" who are low in conscientiousness and have sociopathic characteristics. That kind of person just \"doesn't give a ----\" and they don't worry about things and don't give off tells. Somebody conscientious who is always worried about doing the right thing is worried and radiates that worry. Although the sociopath's behavior leads to chaos in the end, in the short term they radiate calm which makes women feel calm. I (we? am I becoming a person with pronoun problems?) think the A.I. girlfriend can do a better job of mirroring than most real people because it doesn't have a self, doesn't have a counter-transference, it doesn't get offended, doesn't get squicked out, etc. I'd say seduction has a lot to do with the popularity of coding assistants. Combine a little obsequiousness with what looks like a mind that's engaged on your projects (appears to take an interest in what they are interested in) and you can feel a kind of satisfaction working with a coding assistant and you can even feel like you're doing something meaningful when it asks for you help with it's tools and you tell it \"You're running on Windows, the path does not start with /, it starts with C: and you should use the backslash instead of the slash.\" [1] https://monoskop.org/images/9/96/Baudrillard_Jean_Seduction.... [2] https://en.wikipedia.org/wiki/Self_psychology reply a2128 3 hours agoprevFacebook Meta has been making baffling bets lately. They spent tens of billions building a metaverse with the belief that people want to spend their days in a creepy legless 3d avatar of themselves that is pretty effective at simulating what it feels to have body dysphoria, playing with their other legless friends and spending a lot of money customizing their dysphoric avatars. Now they believe what users really want from social media is less social human connection. What users really want is AI spam and parasocial relationships with corporate AI celebrities. They don't want Facebook to tackle the problem of fake celebrities and fake profiles of handsome men sending friend requests in an attempt to romance scam them, what they really want is more fake profiles I really believe Zuckerberg is a lizard after all, I can't find any other sane explanation for this reply afavour 2 hours agoparentI know it's selling him short but I can't help but feel like Zuckerberg is one of the luckiest tech CEOs out there. From all the way back in the mid 2000s when FB totally whiffed on smartphones (Google bought Android and pivoted hard, Facebook could have done the same and just... didn't) I've never come away with any clear sense of what Zuck thinks Facebook is or should be. He took initial market advantage and made a bunch of really smart acquisitions from people who actually do have ideas and then just disappeared into a weird world of VR and whatever. In a way I'm not surprised by this AI stuff. I don't think Zuckerberg uses Facebook in any meaningful way and I think he's so off in his own world that he doesn't even understand how the average person operates any more. It's just like when they pivoted too hard to video, or too hard to chatbots. AI profiles = traffic growth = good. That's all there is to it. There's no overarching vision at work. reply tarsinge 2 hours agorootparentNetwork effect is strong. That’s why they buy already successful networks. I’m sure he recognizes that he has no clue how to build another one and that it was mostly luck of being at the right place at the right time. reply fullshark 1 hour agorootparentprevHis smartest move was ignoring any non-poaching agreement and exploding developer salaries in order to build out a trillion dollar company / ad network. For that I will always appreciate him. reply spencerflem 1 hour agorootparentWhy do you appreciate building an ad network? Like good for him I guess but it doesn't make me happier. reply datadrivenangel 56 minutes agorootparentDeveloper market salary. FB helped bring up total developer compensation. reply coldcode 2 hours agoparentprevI mostly use Facebook for posting tiling/tesselation art in a moderated speciality group (https://www.facebook.com/groups/tiling) that has 72,000 people in it. There are some really nice speciality groups you don't find anywhere else. Facebook's UI is horrific for comments, I think even a bad AI design couldn't be much worse, but the comments are generally pleasant. I check my regular facebook friends occasionally, but not very often. I ignore everything else. reply n144q 1 hour agorootparentI always thought reddit would be a better place for such topics, and before reddit, forums. reply wil421 1 hour agorootparentCar forums are still active but a lot pf younger generations use Fb groups or even worse, discord. Discord is by far the worst for speciality groups. Reddit never really had much appeal to me in the niche world, there was always a forum that was better. Facebook has surpassed Craigslist for classifieds. reply bwfan123 2 hours agoparentprevSame here, I am baffled by making llama free for all to use. Only incentive I see for them is to remove barriers to ai slop generation. So, their platforms become stickier. Risky bet if you ask me. reply fullshark 2 hours agorootparentThat's about commoditizing the competition. Also it wasn't the original plan potentially, the LLAMA weights leaked and maybe they shifted strategies as a result. reply InkCanon 2 hours agoparentprevIf they gave us Ready Player One or Necromancer they would have crushed it. Gibson knows what possessed them to make the best possible impression of an office space in Purgatory. reply Avicebron 1 hour agorootparentYeah what's crazy is that VRchat has existed for years, aside from getting sick and looking like an idiot, what people want out of VR seems like a solved problem... reply Nasrudith 1 hour agorootparentMaybe we are thinking of different things, but my first thought was \"We don't have DNI down yet for VR.\" reply wnevets 3 hours agoparentprevThey probably looking at their metrics and finding their primary user base loves AI content. https://www.buzzfeed.com/sienaegiljum/ai-images-facebook-boo... reply coffeebeqn 3 hours agorootparentI’m pretty sure everyone involved is a bot. The con is pulled on the ad buyers reply Cheer2171 2 hours agorootparentNope, my mother sends these to me all the time and even said that Facebook was getting more interesting every day. She's completely addicted to her phone that at Christmas this year, I felt like I was the parent. She couldn't stop scrolling through her phone while her grandkids were opening presents. I thought she was recording video, but no. A perfect user in Zuck's eyes. reply StefanBatory 2 hours agorootparentMy mom is also like that :( reply dartos 2 hours agorootparentprevNo, there are people on Facebook really do like AI slop. My Nonna unironically loves the AI Jesus gifs and AI gifs of dogs washing babies. Many elderly people, I think, don’t know or care if an image is AI generated. reply kingkongjaffa 2 hours agorootparentThis really made me think that the distinction is not age, but rather the people who have ever used computers to create things, and those who use smart phones as a source of entertainment only. People who create things, have a sense of the time and effort that goes into making something meaningful. So most of the 'hackers and makers' on HN fit into that and show a disdain for GenAI generated content. We've even coined the term AI slop for it. OTOH if you don't create things, or at least don't create digital things (writing, code, whatever), then you probably don't care if something is AI or not. From the typical HN POV the rise of LLMs and GenAI has been a seismic shift and there's been debate ad nauseum about the ethics, safety, and capabilities of these tools. Grandma has done none of that reading, writing or thinking about this technology. To grandma it's basically an extension of gifs and emojis and memes, silly little novelty distractions. reply Loughla 1 hour agorootparentprevThat makes me really sad for some reason. AI content is replacing something for the elderly. Is that good or bad? I don't know but it feels sad. reply jocaal 2 hours agorootparentprevYeah, when I listen to the videos my mother is watching on Facebook, 90% of the content is narrated by a bot. I'd imagine AI content is also super popular on TikTok. Folks on HN should keep in mind they are not representative of the average person when it comes to tech. reply add-sub-mul-div 2 hours agorootparentprevBuzzfeed also went in the direction of churning out slop, if I remember correctly. They were more respectable when they were about their dumb quizzes. reply apwell23 29 minutes agoparentprevaccording to CEO Satya Nadella “The metaverse is not just transforming how we see the world. It’s changing how all of us actively participate in it” reply k1kingy 9 hours agoprevMy FB timeline is already a complete mess with most irrelevant garbage as it stands. Not exactly sure what adding additional 'noise' is going to achieve outside of boosting numbers (which I guess is what they want). A current snapshot my feed: - Group post (from one I follow) - Ad - Post (from company I don't follow) - Group post (from Group I don't follow) - Group post (from one I follow) - Ad - Group post (from Group I don't follow) - Group post (from Group I don't follow) - Post (from person I don't follow) - Group post (from Group I don't follow) - Group post (from Group I don't follow) - Group post (from Group I don't follow) - Post (from person I don't follow) - Group post (from Group I don't follow) - Group post (from Group I don't follow) - Group post (from one I follow) - Group post (from Group I don't follow) - Group post (from Group I don't follow) - Group post (from one I follow) I gave up writing the above, but it was about 9 more posts before I saw a post from a person I actually know. reply iib 4 hours agoparentI don't want to make you use it more, but I found a thing that actually works for me, to restore some of the previous feed behavior. I saved a bookmark that directly goes to the \"Friends\" feed. It seems to have surprisingly few (I think zero or one) ads and recommended things this way. The funny thing is that the \"You read all the posts\" thing still appears if used in this way, telling you to go outside. I do the same for instagram [2], and there was also a post of setting \"Google web\" as the default search engine, showing you actual web results, not stuff recommended by Google. https://www.facebook.com/?filter=friends&sk=h_chr [1] https://www.instagram.com/?variant=following [2] reply freehorse 2 hours agorootparentThanks! The \"friends\" filter with facebook does not really work from me (I have unfollowed all my fb friends and follow only pages/groups mostly for events and such) but realised that replacing \"friends\" with \"following\" in the url actually provides a feed with anything I am following, so really thanks! I used to use the FBP extension but it still takes so long to load and filter out stuff that facebook floods my feed, so this is much better. https://www.facebook.com/?filter=following&sk=h_chr reply bongodongobob 2 hours agorootparentprevThis is it. My feed is fine too. If you don't tell FB what you do and don't want to see, it's just going to spray random shit at you. reply 0xEF 9 hours agoparentprevWhy are you still using it? I dropped FB about 12 years ago, have not looked back since. I ask people this question who still use FB and complain about terrible it is. They answer with some generic \"to stay in touch with such and such\" which is easier and less invasive to do with SMS or email. So, why are you still using it? reply nothercastle 4 hours agorootparentMarketplace… somehow they took over the marketplace for used stuff and killed cl. OfferUp was always crap so it doesn’t count. reply _heimdall 4 hours agorootparentI haven't used Facebook itself for 7 or 8 years now, but had to break down and make a private account just to access Marketplace. For buying used cars private party today, it seems like Marketplace is the only good option. reply ethagnawl 2 hours agorootparentDo sellers question the ghost account? I've had that happen to me the few times I've tried using my dev account to make inquiries. reply _heimdall 2 hours agorootparentI haven't had any issues with it. I honestly don't know how locked down a Facebook account can be these days so \"ghost account\" may not be the right term. I have my name and a profile photo on there, but I've never posted anything, don't follow anyone, and all privacy setting are set to block me from search, feeds, etc. I've only ever had one person block me after messaging about a car for sale, and I couldn't say whether it was because of the account or the questions I sent made them think I'd be an annoying buyer to deal with. reply bluGill 4 hours agorootparentprevCraigslist is still there. They only way to keep it around is make sure you use it. reply nerdponx 3 hours agorootparentYou can use it, but you're swimming upstream if you do. Fewer buyers, fewer sellers of things you might want to buy. reply bluGill 2 hours agorootparentSure, but if you don't use it you just make that worse. Of course if Craigslist had died where you are then there is no choice. However where I live Craigslist is still active enough that I can afford to ignore anyone who isn't there. reply qup 3 hours agorootparentprevIn some regions (mine) Craigslist never took off, and now is a ghost town. I would estimate it gets less than 1% of the traffic of FB Marketplace, in terms of number of vehicles posted. And nearly all of them are car lots, not individuals. reply bluGill 4 hours agorootparentprevSMS and (to a lesser extend) email are not ways to communicate with distance friends. Someone I went to school with 30 years ago and haven't seen since isn't going to call me about their new grandkid, Facebook works well to share these types of pictures. SMS and email take too much effort, Facebook is much lower friction to share that and thus I find out, while if they uses SMS or email I wouldn't be on the list as they would give up before they got to my name in their contacts. reply ozim 4 hours agorootparentSomeone who went with me to school 30 years ago and did not sent me an sms or some kind of message - is not my friend and I don’t care. My distance friends have contact with me at least once a year and mostly at least once a month via WhatsApp. I do not need feed for that and if someone is gone - it is gone I don’t have time to hunt down people who are not in contact with me anyway. reply FredPret 1 hour agorootparentprevExactly - social media is the perfect way to replicate that “town square” vibe our cavemen ancestors must’ve had to communicate with distant social connections, short of having an actual town square. reply 0xEF 4 hours agorootparentprevMany of the replies are saying something similar, so I apologize, as I am not trying to call you out, but to better understand; ask yourself why you need to know about the grandkid of someone you went to school with 30 years ago. So many of these things that we use to sell ourselves to hang on to social media tend to crumble under any honest scrutiny. This upsets people. I get it. I mentioned in another comment having dealt with a substance abuse problem in the past, and the same pattern emerged. I had a problem, but refused to recognize it, so I rationalized continuing down the same path by performing some mental gymnastics about why I needed to keep doing this thing. It was pretty eye-opening when I went through the exact same process during my time leaving Facebook a few years into my sobriety. We are social creatures and social connection is undoubtedly important to our mental health. But like all things, it tends to be better in moderation. In the case of FB, is hearing about a grandkid from a distant acquaintance a meaningful relationship? Conversely, do the likes we might get from distant acquaintances on our post add value or fulfillment to our lives in any meaningful way? I posit that when we engage with these unfulfilling interactions, we spread ourselves much too thin, causing stress and anxiety by drawing our energies away from relationships that are closer to home, in some cases maybe driving distance between them. Sure, I can only speak from my own experience, but I've yet to see anyone's life change for the worse when walking away from social media. Hence my concern about why people seem so desperate to stay, and make no mistake, from this perspective and the replies I generally see when this gets brought up, it's the same excuse-driven desperation I see in fellow alcoholics that resist recovery. reply nradov 3 hours agorootparentI don't need to know, but I want to know. Social media interactions doesn't cause me any stress or anxiety: rather the opposite. Most of us don't have problems with substance abuse or negative social media engagement. You shouldn't generalize from your own very limited experience or presume to give advice about things you don't understand. reply lumb63 3 hours agorootparentDoes this desire to want to know things about people you no longer associate with, not strike you as strange? There is no actual communication here - on one end, there is someone who either has no group of people whom they feel care about their update, so they “share” it with everyone; or, they are so conceited as to think everyone on the entire internet cares. On the other end is someone who does not know what they want updates about, but knows that they want updates from some set of people (but does not want the updates enough to actually talk to those people). This mode of “communication” has for a long time struck me as very strange. reply jameshart 2 hours agorootparentBack in the previous century, people used to do things like post birth and wedding announcements in the local paper. If you had moved away it would not be unheard of for you to be sent a clipping of such a thing by a grandparent letting you know about an old schoolfriend or teacher or neighbor. Keeping in touch with the ongoing life trajectory of people you once knew has long been something people liked to do. reply bluGill 1 hour agorootparentprevI still associate with these people. I go to my high school reunion every 5-10 years. sometimes I go back home and run into them on the streets (not often but it happens). Because I see their pictures I recognize them - when you have not seem someone for 30 years you won't recognize them in person when you go to renew that connection, but if you see pictures you can talk to an old friend who life has drifted you part from. (as opposed to talking to a different group of friends and both of you leave wondering why the other didn't even show up as you were hoping to reminisce about something with them) reply RiverCrochet 1 hour agorootparentprevIt strikes me as strange too. I understand wanting to believe your life is so important that you think the world at large needs to know, but the converse - truly desiring to be the receiving end of those announcements particularly of people you don't know very well - I cannot wrap my head around. reply nradov 2 hours agorootparentprevNo, it strikes me as being completely normal. reply reaperducer 4 hours agorootparentprevSMS and email take too much effort If writing an e-mail to a friend is too much effort for you, then you're not a friend. You're an acquaintance, at best. Low effort means low quality. If all you have to offer is low effort content, what makes you think anyone wants to read it? Be less lazy. reply bluGill 1 hour agorootparentI'll accept Acquaintance. I still want some connection - we will meet again in person someday. However because they are that low and it will be years I need to put most of my effort into friends. reply freehorse 1 hour agorootparentprevEvents and groups/communities (eg hobby, housing etc related). Otherwise I do not \"follow\" any of my actual (or not) friends. reply Symbiote 8 hours agorootparentprevI use it for events. It aggregates most of the small and large music and other events in the city into a single place, and shows me when a friend is \"interested\" or \"going\" to the event. I have forgotten how we did this before Facebook. But there are many events only advertised on Facebook! For others, I'd need to check 20+ websites every week to keep up. RSS is no longer implemented on these sites, neither are aggregators like last.fm keeping up to date. (That's probably what I used before Facebook.) My feed is about 30% content I've asked to see or would want to see, the rest junk (AI crap, far right rage, far left rage). Two months ago I started a subscription to see if that would reduce the amount of junk, hopefully to zero, but it doesn't seem to have made any difference. It has probably hidden ads, but I had an adblocker anyway. For a long time I've objected under GDPR to the tracking, which I think is why I get the mixture of political junk. reply nicklaf 8 hours agorootparent> My feed is about 30% content I've asked to see or would want to see, the rest junk (AI crap, far right rage, far left rage). Since we both seem to use Facebook in the same way, I'll just point out that you can reduce the junk to 0% by skipping your timeline, and going to Feeds: https://www.facebook.com/?filter=all&sk=h_chr That will give you a feed of pages you've followed, and doesn't have any algorithmic or suggested content. I think the only pitfall is that it only shows you recently posted content. reply 0xEF 7 hours agorootparentprev> I have forgotten how we did this before Facebook Radio, newspaper, word-of-mouth, local bulletin boards, email and print newsletters, advertising posters, etc. I might be dating myself, but that's how we got word out about things in urban areas, back in the day. The way I see it, as a person who has dealt with actual substance abuse and understands an addiction when it presents itself, we have collectively become hooked on social media and give ourselves all sorts of excuses as to why it's better than the way we used to keep in touch or get the word out. Every one of those excuses is really just us giving things up that we cannot get back (such as time and privacy), things that others profit greatly from exploiting, all cloaked in a Trenchcoat of Convenience. It is likely very easy for you to advertise your music events with a few clicks, yes? It beats walking around town, posting bills and leaving flyers on corner store countertops...in terms of footwork, anyway. But we lose that connection with the community around us in exchange for the illusion of a broader network that is filled with superficial relationships, at best. > But there are many events only advertised on Facebook! And there's the rub. These event organizers are giving FB permission to dominate our lives and extract/exploit whatever it wishes from us simply because they wanted to do a little less footwork. I used to go to local shows at least two or three times a month in my younger days, prior to FB or even MySpace and Friendster, for that matter. I never felt like I was missing any because I didn't hear about them, since it was not hard to catch wind of this or that venue's upcoming bookings. Even the punk shows, which sometimes were organized the day of, knew how to spread the word. We were all connected, but on a more personal level, and I seem to remember less in-fighting within the groups versus what I saw back when I used FB. Online, it seems like people are at each others throats with much more ease, perhaps driven by the social shield of a keyboard, which told me that maybe we were not really meant to be quite that connected with each other. Part of me blames the fatigue that came with our over-exposure to each other being the keystone to exploiting us on a mass scale, be it to sway political opinion, impose oppression or just sell us a product we never needed. Social media changed our landscape, so it's pretty much impossible to go back to \"the way things were,\" but none of us are expecting that, I think. We need new ways to spread the word, ways that don't exploit us as profitable and disposable soft product. Email could be a start. We beat that drum of email being filled with spam for so many years that it's hard to separate our views on email from that, despite spam filters being pretty darned good now, and various methodologies of mitigating spam to your primary inbox in the first place. There's at least a dozen newsletters I subscribe to and read because it's actually pretty darned convenient, now that my inbox is not filled with spam. Things have changed on that front, so where else have they improved? Is Bluesky a better option than Twitter? Would people still pick up flyers from the counter of a local pizza joint? Can we use VOIP numbers for SMS about local events so nobody's real phone number is being put on a list somewhere? I see the problem and am open to solutions, but those solutions need to come from the people who think they need FB in their lives, I think. reply Kiro 4 hours agorootparentprevHow is SMS easier? I can't easily access it on the desktop or the browser. Group SMS chats seem to be non-standard if possible (never seen anyone use it). Sharing things such as photos and videos through SMS is still a broken mess. reply reaperducer 4 hours agorootparentHow is SMS easier? I can't easily access it on the desktop or the browser. As someone in the Apple ecosystem, I find SMS much easier when using it from Apple's desktop Messages program. It's not ideal that not everyone has that opportunity, but don't make the mistake of thinking that your experience is the only experience. It's also a bit strange, because back when I was making the transition from Wintel to Macintosh – this was before the iPhone – there were many programs that would link your desktop with your phone via Bluetooth so you could send and receive SMS messages. Do they no longer exist? reply Kiro 4 hours agorootparent> but don't make the mistake of thinking that your experience is the only experience I'm literally responding to someone claiming it's easier across the board. I'm not the one making that mistake. > Do they no longer exist? That sounds really complicated compared to just opening a web page. Besides, my computer doesn't even have a Bluetooth connection. reply reaperducer 3 hours agorootparentThat sounds really complicated compared to just opening a web page. It's actually less complicated than using a web page because you just start the SMS/iMessage program, and it's there ready to go. With a browser you have to start the browser and then tell it to go to Facebook. Then open the messaging portion of Facebook. Three times a many steps. Besides, my computer doesn't even have a Bluetooth connection. That's interesting to me. I didn't think any computer made in the last 20 years didn't have Bluetooth. What kind is it? reply nick__m 1 hour agorootparentThat's interesting to me. I didn't think any computer made in the last 20 years didn't have Bluetooth. What kind is it? When you assemble your own computer wifi and Bluetooth are still completely optional. reply spacechild1 8 hours agorootparentprevIn my case: 1. stay in touch with all sorts people around the world (who are not family, close friends or colleagues). Basically like an extended address book. 2. advertize events to many people in a certain area. Conversely, I regularly find out about events on FB. The FB timeline has become a complete shitshow and I stopped engaging. I really wish there were good replacements for my last remaining use cases... reply prinny_ 9 hours agorootparentprevThe answer is network effect and friction . It is hard to communicate to everyone on your friends list that moving forward they can reach you via email or text only. It’s going to work with close friends and family but other people that want to reach out will not be able to find you. And there are always cases when you want to connect (or be easy to find) with someone who is not a close acquaintance. reply 0xEF 8 hours agorootparentI'm not trying to be combative, but that still seems like a very weak reason. And it's one that I used to use, not just with FB, but Twitter, IG and LinkedIn. They all held the same promise and failed to deliver it. The idea that we need to be constantly networking is overblown, to say the least. When you step back and have an honest conversation with yourself about how much having access to these people you occasionally talk to benefits your life, it seems to be negligible at best. Certainly not something worth sticking around for, encouraging more and more privacy encroachment, targeted advertising, etc, adding undo stress and annoyance to your experience online and off. Are we sure that we are not using the \"stay connected\" excuse to hide the fact that these things were designed to be addictive and we got sucked in by it? The only people benefiting from continued use are not users, but the advertisers and platform owners? Is there really anyone on that list where your life would be worse off for not ever interacting with them again? Are there other ways of making yourself just as accessible on the off chance a stranger wants to collaborate with you on something, such as a contact email in a GitHub profile or personal webpage that would satisfy whatever net positive you think you are getting from doing the same on FB? These are not easy questions to answer, but when we start drilling down, our excuses for sticking around start to fall apart and our control for being their gets exposed in ways that we maybe don't like. edit: fixed some autocorrect errors from mobile reply tokioyoyo 3 hours agorootparentYour argument holds a weight only if you already think that “Facebook/IG is bad for keeping in touch”. For almost any average person, that just doesn’t matter. Privacy, targeted ads, “benefits of networking for your future” are things that only us, extremely fringe group of people, care about. My parents? Never. My non-techie friends? I don’t think they know what “targeted ads” even mean. reply parpfish 4 hours agorootparentprevPeople got used to a passive “push” model for staying in touch that they forget the norm used to be “pull”. Now you just passively absorb updates from people to stay factually informed but don’t directly engage with one another. With email/sms, you can just ask somebody “hey what’s up?” And get their big updates. It’s more active and requires some more investment but that’s a good thing for making stronger relationships. And for all those distant connections that you follow on FB but don’t want to talk to… you can ask your real friends “hey, have you anything about so-and-so?” reply bluGill 4 hours agorootparentThose models don't work for distant friends. I should call my mom more often. However nobody would call someone they were distant friends with 20 years ago to talk about their kids sports game - but 10 seconds to see those pictures on Facebook is still appreciated. When that is what Facebook does it is valuable. reply parpfish 3 hours agorootparentwhat's the point in seeing photos of a kids sports game if you are so uninterested in maintaining a relationship that you'd never consider chatting with the person? at that point, it may as well be a parasocial relationship with a celebrity where you look at photos of their life and say \"wow, i'm so glad i've connected with them\". there's a difference between being informed about the goings-on in somebody's life (which social media browsing/posting can help with) and actually having relationships with people. reply bluGill 2 hours agorootparentThe point is to have something to talk about at the next reunion. It won't be for several more years, but I do plan on connecting again. Remember these pictures take only seconds to view, but they ensure when I next meet that person we have some place to start from when talking. reply nradov 4 hours agorootparentprevYour reasons are even weaker. We don't need to be constantly networking but for better or worse, Meta platforms have become the only remaining effective ways to get updates from a large group of extended family and friends spread out all over the world. Like if my second cousin in Indiana has a baby I'd like to know, and I didn't think they're going to announce it via email. reply Kiro 3 hours agorootparentprevI don't understand why people are downvoting you when you're just explaining the reason why. Judging by the sentiment and aggressive downvoting in this thread one would think using anything else than email and text is completely abnormal. Fwiw I don't know a single person using email outside of work and the only texts people get are appointment reminders. reply downsplat 4 hours agorootparentprevDon't people use whatsapp in your corner of the world? Over here in Europe all of that happens over whatsapp, which is still a Meta property at the end of the day, but one that hasn't been enshittified with off-network crap or algorithmic feeds... so far! reply Kiro 3 hours agorootparentI presume GP thinks it's equally unnecessary considering they specifically mentions email and SMS. reply freehorse 1 hour agorootparentWhat is the big difference between messaging apps and sms? They are both forms of semi-synchronous communication via texting. SMS in many cases incures charges, moreover messaging apps actually do not necessarily require using an actual phone, or even _having_ a phone, which is a big plus in my book. reply nox101 3 hours agoparentprevMy feed in the mobile app is - post from friend - post from friend - post from friend - people you might know - post from friend - post from friend - post from friend - post from friend - post from friend - post from frien - loops - post from friend - post from friend - post from friend - post from a non-friend about a friend - post from friend - post from friend - post from friend - post from friend - post from friend I can only guess the reason mine isn't filled with spam is because I click the ... and pick \"don't show me this\" whenever it shows me something I don't care about. I wish I could tell it never show me loops, never recommend friends, never show me posts of friends of friends. While annoying, it's not so bad ATM that I've felt the need to quit On the other hand I check it less than once a week, maybe once every 2 weeks. reply RajT88 2 hours agorootparent> \"don't show me this\" I have tried this with bizarre results. Any kind of booby hot chick type post, I will do this. Sometimes I go so far as blocking the account. There was a week it was all AI-generated booby photos of Salma Hayek - no matter how many accounts I un-followed or blocked, there was a never-ending stream of accounts with AI generated Salma Hayek photos being posted. I gave up after a week, and took some time of Facebook. A month later, I returned, and the Salma Hayek stuff is all gone. Periodically it goes back into some sort of booby photo trend, and I can't get it to stop, so I just quit browsing facebook for a while and when I return it's done. On the time order of a couple weeks, unfollowing and/or blocking makes no difference. I should mention - I am part of a couple groups for car stuff, and a couple groups for fishing stuff. It's not like the content I am interacting with is particularly boob-rich. As far as friends, I only see stuff from friends who post a lot. That's the trend. They aren't people I comment on their posts, or even really talk to in real life anymore. reply amyames 1 hour agorootparentI think when you click on the offending profile to block it, Facebook must decide that’s what you like to see. Or something. Because some moron has 1000 profiles for “cars under $2500” and the more of them I clicked and blocked , the more of them would show up in my feed. I hate that I can’t opt out of the “for you” stuff and don’t actually see anything from family or friends anymore . And I hate that the more I try to block a certain type of content (say: “Salma Hayek boobies”) the more I’m spammed with it. So much that I have not even logged on in about a year. reply RajT88 1 hour agorootparentThis is probably it. They do not discriminate types of engagement - blocking or unfollowing is still engagement, and some team is probably gaming their numbers by intentionally not discriminating. Meta is a rotten company. reply Atotalnoob 1 hour agorootparentprevI would presume the fishing and car groups are male heavy, and those men who have similar likes as you, like the booby photos. They are profiling your likes. reply RajT88 1 hour agorootparentPlausible - sort of. I have never 'liked' a booby photo, and it's true probably lots of those guys have. FWIW, booby photos are verboten in those groups/group chats. The owners try hard to keep things topically relevant. reply kraftman 3 hours agorootparentprevThat many posts from friends would represent months worth of my friends posts. For most people facebook doesnt show friends posts because no one posts anymore. reply KaiserPro 2 hours agorootparentprevhow have you managed this? mine is full of thirdparty shit even though I have been actively saying \"I don't like this\" reply toomuchtodo 3 hours agoparentprevI want an app that uses the accessibility API to plug into Meta, Snap, etc and gives you full control over your socials ala Recall using LLMs. I feel like Gen AI is the countermeasure to closed social ecosystems trying to treat you as the product. Ingest everything my social users have access to, and let me control the experience (Recall meets Buffer?). Scraping is old and busted, consuming the firehose available to you and controlling consumption of it on your own terms is the new hotness. https://www.recall.ai/ https://learn.microsoft.com/en-us/windows/ai/apis/recall reply jameshart 2 hours agoparentprevThe original value proposition of Facebook - keep people you don’t see in person very often up to date on what’s happening in your life, and keep up with what’s going on with them - still feels like something people actually want, but it’s been clear for a long time that no service that tries to offer that can sustain it. Facebook got too excited with its ability to leverage the ‘friend graph’ and broke the very reason people wanted to ‘friend’ people on FB in the first place. Feels like people have generally decided that WhatsApp group chats are the preferred model for keeping in touch. reply the__alchemist 3 hours agoparentprevRead this post to yourself aloud. Why are you still checking Facebook? Keep the messenger app on your phone if people you know still use it. reply toomuchtodo 2 hours agorootparentNot OP, but my global friend network still has folks who post life updates on Facebook, making it a requirement. reply freehorse 1 hour agorootparent\"Requirement\" is a quite strong term. A requirement as to what? Keeping in touch with people can happen in many different ways. I do not see how if some of my friends posted in facebook (maybe they do? I never check) that would necessitate me to connect with them through their posts there. reply manfre 5 hours agoparentprevAny time I see a post with the \"Follow\" link, I click the X or triple dot to hide or signify disinterest. They appear as a flood, but the system gives up and I get a several week reprieve from unwanted suggestions. reply Finnucane 3 hours agoparentprevIt's really become unusable. Most of my friends have stopped posting. There's very little incentive to log in now. reply muglug 4 hours agoprevInstagram just asked if I wanted to chat with a Hawk Tuah AI bot. To me that’s the clearest possible evidence that the product people over there have basically given up. It reminds me of when Facebook went all-in on Live Video in 2016 — a product direction that pretty obviously came from the top. reply InkCanon 4 hours agoparentIt's a clear sign Meta leadership has clearly lost the plot, giving in to hype instead of any vision. reply dagmx 3 hours agorootparentMeta leadership have rarely had a vision beyond “how do we capture the success others are having in this space”. I suppose that’s a vision in and of itself but not a very inspired one. This is the case for most of their successful products: - Facebook itself started this way for Zuck - Instagram and WhatsApp were purchases to corner that market against incumbents, as is Thread - Oculus was a purchase to try and get their own app ecosystem after their phone project failed. They have brilliant engineers and put out interesting stuff, but I don’t think there’s a top down vision. Take oculus, their vision has been scattershot and even Boz says they basically make tons of different product directions and then decide what goes to market. Which sure, can work, but that also implies they don’t have a North Star to shoot for. Quest Pro was a failure and they released three types of Oculus lines close to each other (Rift, Go, Quest) before realizing the Quest was the real success path. Similarly with AI, their approach has been to throw stuff at the wall and see what sticks. Like their celebrity AI chatbots ( https://youtu.be/sfdzkHawZLo?si=oCKAbFHjiOlFRKKh ) or sticking GenAI in every product without a specific user story. Again, great engineering work in all of their pursuits. But if you analyze any given product venture, it’s always throwing ideas at the wall and hoping one catches. reply blululu 2 hours agorootparentIn general this all feels right, but I don' think that a lack of a grandiose vision is necessarily a problem for a company (Facebook's mission of 'make the world more open and connected' boiled down to 'senator - we sell ads'). Product design is about delivering things that people want. Observing trends and trying to get ahead of them somehow is a big part of what makes for a successful product. The bigger issue for Meta right now is that they are not as effective at this game as they used to be. To some extent this might be an issue of brand (the Facebook portal was a great product but nobody trusts the company). But based on my experiences with their products I feel like this gets things backwards. People don't like their brand because their products suck (Apple sucks up way more personal data, but thousands of Apple fans will crawl from the woodwork to defend them) If their core products were good experiences things would be different. The engineering talent at Facebook is truly top notch and while they are good on recruiting I think a lot of it comes from a culture of excellence on the technical side. But the product and UX directions of Meta feel off. Accounts alone has personally burned me. I have an Oculus quest that was effectively reset because of Meta's accounts transitions. My Instagram, WhatsApp and Facebook accounts were all separate, and are all now partially merged but transition sucked for all of them with no benefit to me the user. reply dagmx 53 minutes agorootparentYes, part of successful product design is skating to where the puck is (what consumers want), but vision is thinking multiple steps forward to get it where it needs to be (what consumers need but don’t know yet). That account issue is precisely because meta doesn’t have vision. At best, they’re slightly better than Google, but they very much are cut from the same cloth of throwing multiple takes of something at the wall to see what works. Other companies do so internally, Meta and Google do so externally and go through many deadends as a result. reply dml2135 33 minutes agorootparentprevThe bear is sticky with honey reply lenerdenator 2 hours agorootparentprevThe vision is simple: drive engagement to get you to give up more information about yourself to sell to advertisers and get your eyeballs on their app to see ads made by said advertisers. If they can get you to do that to an AI, well, why not? ... besides the obvious risks to society and mental health, which Zucc has never cared about before. reply iLoveOncall 4 hours agorootparentprevWas that not obvious enough when they renamed to Meta? It seems everyone has forgotten the absolute failure that this shift has been. reply InkCanon 3 hours agorootparentI don't fault them for taking risks and failing (I think at the time there was still an argument for VR, could be possible they were ahead of the curve). I think the tipping point is when they're actively pushing for things that degrade user experience. reply rchaud 3 hours agorootparentAhead of the curve? Their \"virtual meeting\" software presentation had graphics that made you look like a Nintendo Mii avatar from 2006, and couldn't draw arms or legs. reply riffruff24 2 hours agorootparentI dont understand why meta didnt pair up with vrchat/gamedev/game engine dev at the time. Sure they got John Carmack, but their presentation is so much worse. Its so hard not to draw comparison with the other half baked crypto metaverse. Meanwhile Vive Index not only have Alyx but they even bring out Portal themed toybox to showcase the hardware. reply InkCanon 2 hours agorootparentprevTheir execution was indeed almost comically bad. I suspect it was because they had really wanted to focus on the B2B market, so they made the most sanitised virtual world possible. The overall VR direction was not entirely ridiculous, although it was clear on the ground people were much more in love with the idea of VR than the reality of it. reply phillipcarter 1 hour agoparentprev> To me that’s the clearest possible evidence that the product people over there have basically given up. Is it really though? I had my annual bubble-breaker family visit for the holidays and at least two of my family members would have totally gone for that. reply itishappy 3 hours agoparentprev> Hawk Tuah bot million dollar idea right there > that you can chat with on Instagram oh, nevermind reply hbn 3 hours agoparentprevFacebook Live has seemed to be somewhat successful among MLM moms reply Maken 4 hours agoparentprevThat was back then when every tech company tried to be Twitch. reply moolcool 4 hours agoparentprevAnd then there's Meta and Apple's diversions into VR. All of these top-down hype driven product decisions which nobody actually wants are laughable. reply paganel 4 hours agoparentprevFacebook the app/website is already dead, as only boomers and people like me (not yet boomers but not young, either) are now its only remaining users, while IG is going into the same realm of irrelevance, mostly because millennials (its main audience) have spiritually become boomers-like themselves. As such, Meta is throwing everything at the wall hoping that something, anything, will stick. reply FredPret 3 hours agorootparentYou mean it’s a social network that advertises exclusively to people in their prime spending years? Sounds like a roaring success to me. Looking at their financials, I’m right about that: https://valustox.com/META. Our culture is obsessed with youth. But economically the young are not a great demographic to have frequenting your site: - fashions change quickly - they can be demanding - they have no money Contrast to a 40-60 y.o. with a net worth 100-1000x what it was when they were 19, and who are set in their ways, and one of those ways is to go on Facebook every day. reply kingkongjaffa 2 hours agorootparentI guess OP means that they are culturally dead. They will never again have the zeitgeist. TikTok has completely dominated in that regard. That doesn't mean it's not a good business. The real kicker is if there's any sense of 'app loyalty' as people age do they move on to older social media, or do they stay with the one from their youth? Certainly I and my 'cohort' went from myspace to facebook, and then everyone's parents got on facebook, so we went to snapchat and instagram and pretty much stayed on instagram. I suspect the TikTokers will stay on TikTok and either a new app will emerge or TikTok will just completely clean up as the user bases of the the other apps 'age-out'. The real USP for tiktok was being video-first and it's another level of addictive, targeted content, which is super easy to consume. I probably bet on video-first winning and therefore TikTok. VR is not going to take off with current tech. There's no new medium to exploit, we roughly went from text -> images -> video as people's mobile data plans and phones got faster and more powerful. reply paganel 2 hours agorootparentprevYes, it’s in its BlackBerry 2005-2006 moment (optimistically), more like its 2008 moment (realistically). There was still lots of money coming in for both BB and Nokia around 2005-2006, too much money, for that matter, which eventually made them collapse. Ask yourself this, who do you see still using Facebook (the app) in 5-10 years’ time? But, then again, lots of people here which have a direct stake in Meta, either through owning shares or through direct employment (the same discussion applies to whenever other big US tech companies are discussed in here), so there’s no use debating. As per the focus on youth thing, which you’re correct about, how do you expect Meta to pitch to potentially future 20-something employees in, let’s say, 5 years’ time? “Come work for us cause we’ve got the boomers’ market cornered?”. That won’t work, and, at best, it will attract only people chasing the big comps, which doesn’t help at all with innovation. Granted, they still have “AI” in order to attract future worthwhile and non-mercenary talent, plus bringing in future revenues that are supposed to replace Facebook the app eventual demise, but imo that’s still an open bet at this point. reply FredPret 1 hour agorootparentLook, every company goes through a lifecycle; tech companies go through them faster. But I’m in my mid 30’s and will probably use Facebook (very casually) for life. I’ve bought multiple products from their ads; they’ve got my profile zero’ed in, and that suits me perfectly. Every week I go on it for 5 minutes, see my friends’ baby pictures and a handful of products that are perfect for me. That’s much better than most sites. As to recruiting 20-somethings, I’m not convinced that’s crucial to any established business, and even if it were - there are tons of boring businesses that hire smart 20-somethings every day. reply ljm 2 hours agorootparentprevThe only thing I can take away from this message is that literally everybody is a boomer. By inference - post boomer: dead - boomer: old - aspiring boomer: middle-aged - spiritual boomer: almost middle-aged - pre-boomer: young reply freehorse 2 hours agorootparentOK boomer /s reply alex1138 13 hours agoprevHey here's a novel idea Have social media websites be reverse chronological posts by friends/pages you follow instead of what AI thinks you're interested in (and yet somehow not explicitly following, yet you get it in your feed anyway) reply vasco 10 hours agoparentThey want more engagement. It's like if you build a typewriter and give it to a few humans, they'll write on it a few times a week maybe, not that much. Sometimes a supermarket list or a letter to a friend. This is what I'd call \"quality engagement\". There's a person doing a valuable activity for themselves, where time using the thing isn't relevant. Then you give the same typewriter to a monkey and every time the monkey finishes a page he gets a banana. He'll stay there all day every day. Lots of engagement and just gibberish on every page. Advertisers are buying monkey engagement. And platforms don't care so right now all the typewriters are made for a monkey hand to type all day every day, and you can no longer write your normal letters without feeling annoyed at why it got better for the monkey instead of leaving it alone for you. reply alex1138 10 hours agorootparentYeah, but replace \"they\" with \"Zuckerberg\" and \"platforms\" with \"Facebook\" reply _Algernon_ 9 hours agorootparentIt applies to much more than facebook though. For example, Tiktok, Youtube, Reddit, Instagram. Not sure why you want to single out Facebook. reply scrollaway 4 hours agorootparentPlenty of trash there of course but YouTube also has very good quality content (if you know where to look for, both as a user and as an advertiser). This in turn is why there is so much more money into YouTube than other social media: because there is also highly qualitative content and thus viewers there. YouTube gets insane amounts more money and attention from the industry because of this. reply alex1138 9 hours agorootparentprevBecause Zuckerberg has a generally weasely reputation and also I don't see the other platforms being nearly as scummy as Facebook has been (Instagram as you probably know is also owned by Facebook and people are similarly tired of the constant spam) reply _Algernon_ 9 hours agorootparentFocusing on one particular company distracts from the fact that this is a result of systemic incentives. It is the incentives that need to change, not any particular company. Facebook / Instagram is crap, but so is Tiktok, Youtube, Reddit, etc. The fundamental problem is the business model where money is parasitised from people's attention. You want change? Make these companies responsible for the negative externalities they impose on society, just like companies that pollute the commons are held responsible. We don't need another Tiktok ban; we need industry wide regulation. Shortsighted focus on single companies is simply a distraction from this fact, which only benefits these companies and allows most of them to continue as before. reply alex1138 7 hours agorootparentI will just point out Facebook has been accused of gaming metrics (among other things, autoplaying videos) Which can lead to websites like Reddit making unpopular changes to try to match Facebook's market cap (I think I've read they were specifically trying to do that) If you create fake metrics everyone else will copy you in a race to the bottom No other CEO begins the company with \"If you need info on people at Harvard, just ask, they trust me, dumb fucks\" reply rnd0 9 hours agorootparentprev>Because Zuckerberg has a generally weasely reputation and also I don't see the other platforms being nearly as scummy as Facebook has been Have you not looked at Musk recently? Or is supporting AfD (the German far-right party) and adopting the persona of \"kekius maximus\" (a right wing meme) somehow less scummy than whatever it is Zuckerberg is doing? Mind you, Zuck pulls some fucked up crap -and some of it may well be worse. But my point remains ...he's not alone. All of the Social Media platforms are corrupt and toxic and in many cases...Musk, Spez..their owners are as well. reply ahartmetz 8 hours agorootparentMusk isn't weasely in the background, he's unhinged in public. Big difference. reply wincy 11 hours agoparentprevI’ve developed this tic where anytime I’m on Facebook I aggressively block all the non sponsored suggested content in my timeline. I’ve blocked literally thousands of pages at this point. So the recommendations have gotten really weird, last week it thought maybe I was gay, then I started recommending Chinese state sponsored pages, now it’s recommending all 50 National Geographic pages. It’s always pages over a million “likes” whatever that means. I'm curious what’ll happen if I manage to block all of them. Honestly probably something lame where the recommendations just get weirder and weirder (which I guess is happening now) reply parpfish 3 hours agorootparenti have a burner fb account that i use to follow a local lost-pets group and check hours for restaurants that refuse to have normal webpages. this account has no friends and just the one group membership so my feed if 100% platform-promoted swill. and it is bad. the current fad is for there to be accounts that repost screenshots of successfull AITA reddit posts to engagement farm. the sad part is that it works. they get a ton of comments and likes reply koutetsu 9 hours agorootparentprevWhat a coincidence! I have done the exact same thing but on Instagram instead of Facebook and have had similar results to yours. Since both belong to Meta, we can safely assume that they use the same or very similar backends to serve ads. I think it would be interesting to do a large scale experiment to see what can happen. reply bluGill 4 hours agorootparentI've been doing this for a couple years. My feed is better, but they still have plenty of garbage I'm not interested in. I make it a point to scroll until I have blocked two of these - that is my signal that it is time to read. Hopefully if more of us start that rule of two eventually it will be populate enough that they notice and add a mode for those like to better see our friends thus keeping us a little longer (I doubt it, but it would be nice). reply Symbiote 8 hours agorootparentprevDo you get fewer junk posts in the feed, or are they just different? reply toddmorey 4 hours agoparentprevThis is what makes bluesky so refreshing reply hapticmonkey 11 hours agoparentprevYou can access those simpler chronological feeds in Facebook under More > Feeds. They still insert sponsored posts in that feed, but you can block them with browser extensions. The annoying part is that if you load the feed url from a bookmark, at least on mobile, it reloads to the home page anyway. So you need to navigate to it manually each time. Never used to be this way. I guess they’ll remove the “feeds” feature soon enough anyway. reply Symbiote 8 hours agorootparentThat's wonderful! Thanks! On mobile the URL is just facebook.com so there's nothing to bookmark for me. It's still useful though. reply fullshark 2 hours agoparentprevSounds like a good way to lose 50% of your revenue reply Groxx 12 hours agoparentprevit'll never work. what's next? federation? insanity. impossibility. reply darth_avocado 12 hours agoparentprevBut think about the poor shareholders reply _Algernon_ 9 hours agoparentprevBut how will that create value for shareholders? reply InsideOutSanta 9 hours agorootparentThe numbers are going up! What numbers? THE NUMBERS! reply nradov 4 hours agoparentprevMost users don't want reverse chronological feeds. They say they do but they really don't, and fail to appreciate how that would actually work. First, that would incentivize posting more low-value crap just to stay on the top of everyone else's feed. Second, if you don't log on for a while you're likely to miss some major life events (birth, death, marriage, divorce, move, new job) that people most want to see. reply hmmm-i-wonder 9 minutes agorootparent> First, that would incentivize posting more low-value crap just to stay on the top of everyone else's feed For 'social influencers' sure, but normal users don't care about that. Removing the engagement hacked platform that primarily benefits social influencers would be a significant improvement for most users on most social media platforms. reply mrweasel 3 hours agorootparentprev> They say they do but they really don't, Probably depends on your usage pattern. I think most would prefer it, but \"engagement\" measurements will make it seem like they hate it, because they spend less time on the page. If companies like Facebook actually wanted to know, they'd make the setting \"sticky\" rather than constantly reset to algorithmic, then measure over 3 - 12 months how many switches to either one and stays there. The fact that you can set your feed to permanently be chronological tells me that Facebook REALLY doesn't want you do use this feature. \"Power users\" may prefer the algorithm, due to the volume of posts they'd see, while many casual users prefer reverse chronological and then just check in every other week. Seriously the last year I was on Facebook, that was my usage. Block everything not posted directly by a \"friend\", sort by date, read the five posts from the past two week and logoff. Took me just a few minutes a week to catch up. I just don't think that usage aligns with Facebooks business model. reply 65 3 hours agorootparentprevThe real solution is to make the content sortable like Reddit. reply lizardking 16 minutes agoprevI was on a Facebook group for SWEs (can't remember which one), and I had the distinct feeling a person I was engaging with was a bot. All his comments were boilerplate takes or non-sequitur replies, and he ultimately agreed with every point I made. I assumed I was just being paranoid, but maybe not. reply simonw 12 hours agoprevI think this whole thing can mostly be explained by the job titles. What do you expect the \"Vice-president of product for generative AI at Meta\" to be pushing for? This is happening across hundreds (thousands?) of companies right now. They've decided they need a generative AI strategy, there's very little existing precedent for what works and what doesn't so they're hurling things at the wall and seeing what sticks. reply simonw 12 hours agoprevBack in April Meta were experimenting with bots that replied to forum posts that hadn't had any traction yet: https://x.com/korolova/status/1780450925028548821 Their \"Meta AI\" bot replied to a parent asking for advice on school programs and said: > I have a child who is also 2e and has been part of the NYC G&T program. We've had a positive experience with the citywide program, specifically with the program at The Anderson School. reply throwup238 12 hours agoparentThat sounds like it’s talking about the Meta executive in charge of privacy and consumer protection. The AI has developed a parasocial parental relationship with its own executives. reply corobo 9 hours agoparentprevMan that's gonna be some prime real estate for adverts reply grecy 9 hours agoparentprevFor years social media sites have been able to hide behind the Chapter 120 defence, because they didn’t generate the content, so they’re not liable for it. I wonder if their AI boys will open them up to lawsuits. If their not recommends a product or location that turns out to be dangerous, or medical advice that is harmful etc. reply nradov 4 hours agorootparentI have no idea what the \"Chapter 120 defense\" is, but online liability concerns were always mostly about libel. That's what led to the CDA Section 230. https://www.eff.org/issues/bloggers/legal/liability/230 Giving harmful advice generally doesn't create any legal liability so no defense is needed there. It might be bad for PR though. reply openrisk 9 hours agoprevWe need a tech hype that is not terminally tainted as an anti-human abomination. Is it too much to ask for? Surely those gazillions of GPUs can be deployed to do something actually useful? Are we beyond redemption? reply InkCanon 4 hours agoparentIf anything causes the AI bubble to burst, it's that 99% of finding is going to companies that don't solve any real problems. It's shocking that the only major player in real world problem solving is DeepMind. reply baggachipz 3 hours agorootparentI'm going to say \"when\" and not \"if\" here, because of your assertion above. VC's spending multiple fortunes on shoehorning in shit that nobody wants or needs. reply InkCanon 2 hours agorootparentI'd say most will fail (although this is the case for most startups anyway) but the question is if there will be any massive success that pulls the average up, so to speak. reply baggachipz 1 hour agorootparentAs we work our way to the last two steps of the Gartner Hype Cycle, there will no doubt be legitimate uses. But shoving \"AI\" in everything will be a punchline for a long time to come. reply tokioyoyo 3 hours agoparentprevWhat you consider “useful” is not useful for others, and vice versa. For some 19 year olds, curating their IG feeds and making the smoothest transition on TikTok to go viral is actually important. It sounds stupid, but we went through this entire debate back in early 2010s. FB/IG/TT/YT obviously won, and seems like that’s what majority of people prefer doing. reply openrisk 1 hour agorootparentThis relativism applies to some extent to pure entertainment activities. What is worthwhile, trendy, in-group (or whatever) does vary enormously by region, age group etc. But these platforms are now for most people \"all-there-is\". They have replaced effectively any other source of information. What can go wrong when algorithmically titillated echo chambers shape people's mental horizons and behavior? We are increasingly finding out. reply friend_Fernando 13 hours agoprevI think we actually need more bots discussing politics online. Specifically, we need echo chambers to be replaced by cacophony chambers. The only way to salvage democracy is to bring it back offline. Online, it was undermined by troll farms pulling the strings in favor of certain shady factions. It's time for the good guys to get their hands dirty and break the spell. Trolls cannot be silenced, but they can be offset. reply hmmm-i-wonder 5 minutes agoparentConsidering the state of offline media today, I doubt there is any going back to the real or imagined pre-internet days of media. reply Animats 12 hours agoparentprev> Specifically, we need echo chambers to be replaced by cacophony chambers. That's the objective of modern Russian propaganda. The goal is not to be believed. It is to create confusion and reap inaction. reply herbst 1 hour agorootparentIsn't that the same for any bigger propaganda machine? I don't see the US doing any different than that reply throwaway48476 11 hours agorootparentprevThat's the objective of propaganda within russia. For external audiences the objective is to sow chaos. reply bergen 11 hours agorootparentcacophony = chaos, so a lot of mixed opinions that don't really make sense would achieve just that. I would not expect thought out and stringent discussion from throwing a bunch of bots at every discussion reply friend_Fernando 12 hours agorootparentprevYes, but they do so selectively for what's against their interest. The net, filtered result is what's in their interest. That leaves \"mutual assured dialogue destruction\" as the only option, IMO. reply Animats 12 hours agorootparent> Yes, but they do so selectively for what's against their interest. Generating division is sufficient. There were Russian attempts to hack both campaigns in the last US election.[1] [1] https://www.nbcnews.com/politics/national-security/us-sancti... reply friend_Fernando 12 hours agorootparentThey're usually not filtering pro-left or pro-right. They're filtering pro-Russian-faction within the left and right. This usually means extremists that used to have no hope of winning in the pre-Internet days. These factions are more likely to be beholden to their \"troll benefactors\" afterwards. But even if they turn out to be ungrateful, the extremism itself is worth pursuing. As you said, confusion and division are useful in their own right. Add other rogue countries to the mix, and you end up with a nasty filter. We should turn it into white noise, or at least drop its SNR. reply BeetleB 12 hours agorootparentprev> Yes, but they do so selectively for what's against their interest. The net, filtered result is what's in their interest. Not really. You can go and see the ads Russia placed on Facebook in the 2016 election. They had pro-life and pro-choice ads. They had pro-LGBTQ and anti-LGBTQ ads. They had pro-guns and anti-guns ads. reply friend_Fernando 12 hours agorootparentI don't think we disagree here, unless you saw some pro-Ukraine 2024 ads. It's not about left and right. To demagogues, ideologies are just tools of the trade. reply throwaway48476 11 hours agorootparentIn the communist era russian propaganda had a definite ideological position. It was also far more effective. Much of the 60s era progressive politics was a result of russian influence and the west was full of communists before the tankies split off. reply finnthehuman 14 minutes agoparentprev>Online, it was undermined by troll farms Meh, the conversation had already been undermined by that point. People discussing politics already ceded the conversation to people who liked fiery arguments. The posting farms were just convenient scapegoats for flameposters to explain why they weren't winning, and try to salvage some reputability. reply panta 11 hours agoparentprevI have been thinking about these lines for a long time. Humanity would be much better if we went back to pre-social network internet, populated by small human-moderated and vertical forums. We can and should destroy social networks, using their own tactics. reply concordDance 9 hours agoparentprev> Online, it was undermined by troll farms pulling the strings in favor of certain shady factions. No, online it was undermined by selection effects. Where those who care the most about something are most likely to engage or post, leading to endless streams of unrepresentative and extreme views. reply jokethrowaway 9 hours agorootparentIt was shaped by censorship! Conservatives and libertarians have been banned for a decade. Since the first Obama social media campaign the internet became very one sided - and people started believing that crap so much, everyone here had to sit through at least one DEI training. I'm against any form of government and centralization of power (which nearly always happens thanks to regulations and laws); I'm not a fan of Musk and conservatives (I'll change my mind after I see with my eyes a significant reduction of the US government) but I'm glad to see a return to balance in online discourse. We had another DEI training at work and I was impressed to read everyone left negative reviews about it. Quite the change in sentiment! reply nextworddev 9 hours agoparentprevYou are describing Reddit reply cloudking 1 hour agoprevWe're at the tipping point where average users cannot tell the difference between AI generated and human content. It's already very evident on Facebook and Threads, just spend a few minutes on either platform, you'll find a post with an AI generated image or video and tons of human engagement supporting it. reply axegon_ 9 hours agoprevMost likely an effort to boost the DAU numbers. I quit facebook over a decade ago because I truly felt that it was pointless. At the time I was convincing myself that it's a way to stay in touch with a certain number of people I would otherwise have no way of contacting. Then a friend said something that changed my mind: \"If someone is not actively a part of your life, chances are there's a good reason they are not\". And he was right: I deleted it, knowing full well that I'd have no other way to connect to hundreds of people. Over a decade later I haven't had the reason to try and contact either one of them. At this point, I don't even know what facebook looks like but all this AI-generated crap is just as pointless as the ads that would get shoved down my throat if I didn't have a very aggressive ad blocker. As much as I was strongly against ad blockers 10 years ago, since many sites and blogs used only that to get some reward for their effort, we are at a point where the internet is unusable without an ad blocker. All major platforms are flooded by AI-generated crap. And I mean Facebook, Medium, StackExchange, hell, I'm willing to bet a good chunk of papers coming out these days are mostly ai-generated. And don't even get me started on musk's shithole that is Twitter. No, I am not saying that AI is not useful or helpful - it is, but it should be a supplement, not the primary ingredient, let alone the sole ingredient. The true value of the internet used to be the collective knowledge, and not mass-produced regurgitated set of tokens and pixel values. Personally I've gone to the even pre-rss days and have a list of personal blogs I scroll through for things I find interesting and avoid large platforms altogether. Interestingly enough, I've been finding more and more motivation to start writing myself though I rarely get the chance to push it through the end and in most cases I get stuck at 95% for many months until I get to find the time to do the remaining 5% of the work. That's how many I have lined up so far: git status .wc -l 59 reply agilob 3 hours agoprevDead internet isn't a theory anymore, it's a product. reply worldvoyageur 2 hours agoprevIt makes sense to me. Meta knows who their real users are and what their real users want to consume. They know who their real advertisers are and what they are willing to pay to reach their real users. This means they know what their real users would like to consume but can't, because that content isn't being created. Why wait and hope that content your real users want to consume gets created? Have AI create that content. Now you have more product for your advertisers to pay for, plus it is the juicy, premium rate stuff you know they'd want to buy. With all your data, it practically automates itself. I'm not saying all this is good, just that it totally makes sense if you are in the business of making money and see yourself as doing that by giving both your users and your advertisers what they want. reply seydor 4 hours agoprevSocialization is about conspecifics. AI may augment the process for humans, but you can't expect people at large to engage with nonhumans. I mean, people do talk to their pets, but they don't consider that socializing. reply bluGill 4 hours agoparentIf you just need someone to talk to AI might be good. There are a lot of lonely people out there that need someone to talk to and don't know how to do it. (particularly people in nursing homes who thus cannot get out and meet real people) However I want Facebook as a way to remain connected to be distant friends not talk with people. I want to see my friends kids, their cats, whatever else they do that they are proud of. I know them personally even if I only see them at a class reunion every 10 years or something. I don't want to see cute cats (unless it is your cat), I don't want to see \"joke of the day\" - if I want that I'll find one of the many joke of the day places that cater to my sense of humor. I get plenty of politics elsewhere (unless they are running for office or assisting a campaign - share is not assisting a campaign). If I care about professional sports I can see it myself - let me know how your (or your kid's) games go since I won't find out about that. I wish there was a way to make Facebook that latter - it sortof fills that role. However Facebook hates it because I catch up after 5-10 minutes of scrolling every day (usually the lower end of that list, but with the holidays the latter these last few weeks) and then close. reply mrweasel 4 hours agoparentprev> but they don't consider that socializing. Which is exactly why this will make Facebooks problem even worse. Honestly I don't think Facebook understand what their main issue is, it's lack of real human interaction. The stupid part is that they killed their main product themselves, in order to push ever more ads. LinkedIn is becoming a shit show as more and more people are posting stuff that previously belonged on Facebook, though they are tacking on some work related angle, you know to keep it professional. It is my opinion that the reason why LinkedIn is seeing more and more of these Facebook posts is because it is the last place online where you'll get real human interaction and socializing (however f-ed up it might be). reply weitendorf 2 hours agorootparentYou can certainly get real engagement on other platforms still. I think the reason there is so much weird cringe on LinkedIn is that: 1. It actually does get a lot of engagement and watch time, maybe not even despite how bad it is, but because it’s so bad that people can’t look away. If it’s cringy enough it’s no longer boring. It used to be that people ignored the feed entirely because it was all just boring stuff. 2. Building a personal brand is a really big thing these days and is legitimately valuable. Being able to write something and hit post and get real engagement for $0 (vs what it’d cost to get that engagement by paying for it directly) is nuts. IMO this isn’t obvious if you’re working as an engineer but if your job requires any sales or marketing it’s genuinely helpful. 3. LinkedIn is actually a really good place to farm engagement because of its general user base (professionals from early career to prime earning years), professional bent (intent), and availability of real names/titles/location. I find it kind of fascinating how these engagement mechanisms work in spite of it all because they all rely on some kind of “hack” on human attention. reply mrweasel 1 hour agorootparentYou're second point is interesting, because that's probably what's going on, but the brand that many of these people are building is that they are psychopathic nutjobs who view dead/dying/sick children as a career advancing opportunity. reply tokioyoyo 3 hours agoparentprevA few months ago, the same argument popped up about AI videos. But the long game strategy is making it “normal” for the kids and youth growing up, so they would consider it as socializing. It’ll be up to the adults to fight against it. If we grew up with AI YouTube, we wouldn’t bat an eye on more AI videos, or socialization and etc., as we would consider that as just… business as usual. reply seydor 3 hours agorootparentNot sure. Which Cgi videos make it to the top? Not even movies reply tokioyoyo 2 hours agorootparentDoesn’t matter, we’re not the audience. We have preexisting beliefs that if there was no effort put into making the video, it’s not worth watching. The key is to target people who don’t have that. reply paxys 3 hours agoparentprevSocial media stopped being about socialization a long time ago. It's now purely content consumption. reply nerdponx 3 hours agoparentprev> you can't expect people at large to engage with nonhumans NPCs are a big component of a lot",
    "originSummary": [
      "Meta is set to launch AI bots on Facebook and Instagram to engage younger users and leverage its investment in generative AI technology. - These AI bots will have profiles and create content, functioning similarly to regular social media accounts, following Meta's acquisition of SocialAI. - This initiative reflects Meta's broader strategy of automating social interactions and content curation, aligning with trends seen in apps like Character.ai."
    ],
    "commentSummary": [
      "Meta is introducing more AI bots on Facebook and Instagram to boost user engagement by simulating interactions, reflecting a broader industry trend of using AI to enhance user experience.",
      "There are concerns about the authenticity of interactions, as AI-generated content might overshadow genuine human connections on these platforms.",
      "Critics worry that increased AI presence could lead to a less authentic social media experience, potentially alienating users who value real interactions."
    ],
    "points": 172,
    "commentCount": 308,
    "retryCount": 0,
    "time": 1735791600
  },
  {
    "id": 42569913,
    "title": "My 25-year adventure in AI and ML",
    "originLink": "https://austinhenley.com/blog/25yearsofai.html",
    "originBody": "Austin Z. Henley Associate Teaching Professor Carnegie Mellon University azhenley@cmu.edu @austinzhenley github/AZHenley HomePublicationsTeachingBlog My 25-year adventure in AI and ML 12/31/2024 I never intended to work with AI or ML. It more so happened along the way naturally from using whatever tools I needed for the task, and eventually it took over. I didn't even realize it at the time. Given that it is New Year's Eve, it seems appropriate to look back on my career to see how I got here. Let's go back to the year 2000 and walk through the major AI/ML projects I worked on. If statements and random numbers I've talked about how I got into programming before: Learning HTML was too hard so I made a compiler instead. But along the way, I also tried to make video games (like any kid). The first project I remember making in VB6 was a game based on Tamagotchi pets. Unfortunately, I had no idea how to make the pet \"come alive\". The best I came up with was a timer that triggers some effect every X seconds plus some conditionals. Increase pet's hunger every 10 seconds. Decrement health every 3 seconds if hunger level is greater than 5. Faint if health reaches 0. Not a fun game at all. Fast forward to high school. The biggest game I made at the time without giving up was a 2d space shooter where you defended yourself against waves of enemies while collecting simple powerups. A pretty standard exercise for a wanna-be game developer. For this, I hard coded a long, long sequence of if statements that used random numbers, how long you've been playing, how many shots you have fired, your hp, etc. to determine which wave of enemies to send out next. Finally, it felt dynamic and not entirely predictable. It was even almost fun. But no one would play it more than a few minutes. (Unfortunately, I can't find any screenshots from this era.) Somewhere in the mid-2000s, I purchased the book Programming Game AI by Example (Amazon). It took a few years to prove useful though... State machines and higher-order functions In college, I took it up a notch with my games. They were played by millions, and I even made money! My coding skills were finally maturing, I could put what I read in books into practice, and my roommate spent every waking moment making games. I used finite state machines for the enemy behaviors, the factory pattern to spawn and manage objects, and higher order functions to make enemies and weapons composable. Each unit, each weapon, and each bullet was given a set of behavior functions that would execute each frame to determine what happens next (e.g., the weapon will shoot bullets in bursts that are in the shape of a narrow cone that oscillates left and right 25 degrees; the bullets will slightly home into the nearest target and have a 1% chance of ricocheting) I found that incrementally adding a bit of dynamism (i.e., based on the game state and the player's input) and variation (i.e., changing behaviors through randomness and composability) made my games much, much more fun. It required layers though. I needed to add this to everything: sprites, particle emitters, sound effects, enemies, bullets, and animations, not just the enemy behaviors. The games started to feel alive! But this isn't AI, right? In the end, it is just some handcrafted if statements and well-architectured function calls. Hmmm. First-order logic, knowledge representation, support vector machines, and neural networks After graduating, I enrolled in a MS program at the very last minute (as in, after the deadline and just before the Spring semester started). That meant most of the courses were full. I signed up for the only ones available, which included Artificial Intelligence and Neural Networks. I was hoping for a compilers course! I was disappointed when I found out that neither of these courses involved any coding or how to implement what we learned. They were very high level and we spent a lot of arguing over definitions. The AI course consisted of in-class discussions dissecting the famous book, Artificial Intelligence: A Modern Approach, Third Edition (Amazon). I learned about planning, agents, first-order logic, and knowledge representation. It gave me some vocabulary for thinking about these problems, but I wasn't able to make the leap of applying any of it. Sorry, Norvig. The neural networks course was heavy on theory. We covered perceptrons, support vector machines, feedforward networks, hopfield models, and back propagation. The textbook wasn't useful so I won't link to it. I asked the professor how I could actually build a neural network and he said, \"I think there is a MATLAB package\". Welp. I spent the summer and fall trying to put this knowledge to use. I built a program for low-bandwidth video chat. I used OpenCV to detect the face, extract regions of the face, and then a classifier to determine the state of those regions. For example, is the mouth curving up? Is the left brow raised? Is the right eye open? I had several hundreds of labeled face images from some open database back then. The application sent the binary states over a socket to be used to draw an avatar using OpenGL. It didn't work well. It was tedious to modify, it was extremely sensitive to lighting, minor changes to parameters would have big consequences, OpenCV was a pain to use, and training took forever. I really had no idea what I was doing, but I eventually learned a lot and got it somewhat working! Here is a [very amateur] demo video that I uploaded in January 2013: Over 1000 views! Decision trees, clustering, and recommendation algorithms As I got into my PhD, I needed statistical methods to analyze log data from code editors. Can I identify when a programmer is stuck or lost in the code? Can I predict which file they'll navigate to next? Can I accurately recommend code of interest? I learned how to use the C4.5 algorithm to generate decision trees, k-means and DBCSCAN to cluster events, and Apriori and collaborative filtering to find associations between events. Although fairly simple, these are surprisingly powerful. In fact, I'd say that most of the time that you think you need a big neural network, you don't! These methods got the job done. I published papers, did a bunch of internships, and built developer tools involving these, and eventually graduated. If you want to read more about some of these projects, I recommend starting with: Data analysis on how developers look for information: Foraging and Navigations, Fundamentally: Developers' Predictions of Value and Cost (pdf) My Microsoft internship experience report about building a code review bot: When users never use they features they asked for Intelligent user interfaces As a new tenure-track professor in 2018, I needed a schtick that I would base all my research around. I chose intelligent developer tools, though it was much fuzzier of a concept in my head back then. My first week on the job, I submitted a grant proposal where I'd use predictive models to preemptively identify and correct programmers' misconceptions. The abstract of the proposal said: In particular, this project will develop novel tool designs that accomplish three mutually supportive goals: (1) identify misconceptions that novice programmers have about their program's behavior by leveraging program analysis techniques and predictive models, (2) correct novice programmers' misconceptions and explain the rationale without disrupting the programmers, and (3) prevent future misconceptions by generating test code for the novice programmers that will catch unintended changes to the program's behavior. I summarized that project in my post, An inquisitive code editor: Overcome bugs before you know you have them. Next, I collaborated on a project where we'd use models to predict the information needs of programmers and generate user interfaces for them on the fly (e.g., if they're looking through their git history for relevant code, generate a visualization comparing a recommended set of commits). Then I tied all this work together into my grand vision: Inquisitive Programming Environments as Learning Environments for Novices and Experts. You can see the proposal (pdf) and my blog post on how I wrote it (What a $500,000 grant proposal looks like). However, I resigned right around the time I was notified the grant was being funded, so I didn't get to make more progress. Program synthesis and large-language models In January 2022, I joined the program synthesis team at Microsoft. Now I was immersed in AI. It was perfect timing because ChatGPT was released 10 months later and the world forced LLMs upon everything. Although I was on an AI team, I often pushed back against applying AI unless we had a really compelling reason. What is the user problem we are trying to solve? Do we really need an LLM or could a few if statements suffice? Are we sure that natural language is the appropriate interface for this? I went on to share my opinions: Natural language is the lazy interface and Don't trap me in a chat window. I worked on a lot of cool projects. Including: Investigating whether existing LLM attention weights can be used to predict where a human developer will look next Follow-up Attention: An Empirical Study of Developer and Neural Model Code Exploration (pdf) An AI tutor for data science Motivation: The pain points of teaching computer science Motivation: Mistakes that data science students make IntelliCode's user experience for multi-line code edit suggestions Exploring 50 user interfaces for AI code LLM-based tools for data scientists Motivation: Can ChatGPT do data science? Tool: Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition (pdf) Tool: Data Wrangling with Data Wrangler LLM-based tools for students Motivation: Learning to code with and without AI Tool: CodeAid: A classroom deployment of an LLM-based programming assistant Tool: Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning (pdf) Empirical study of how companies are building copilots The pain points of building a copilot Since leaving Microsoft, I continue to tinker on my own AI tools, such as Mirror and Promptclipper. It has been a fun 25 years. What's next? I'm going to continue teaching, learning, and building. There are Amazon affiliate links on this page.",
    "commentLink": "https://news.ycombinator.com/item?id=42569913",
    "commentBody": "My 25-year adventure in AI and ML (austinhenley.com)172 points by ibobev 20 hours agohidepastfavorite35 comments mtrovo 18 hours ago> Although I was on an AI team, I often pushed back against applying AI unless we had a really compelling reason. What is the user problem we are trying to solve? Do we really need an LLM or could a few if statements suffice? Are we sure that natural language is the appropriate interface for this? This practical approach to AI feels refreshing in a field drowning in buzzwords. I’ve built tools where simple regression models outperformed neural networks, and convincing teams was an uphill battle. It's hard to not get pushback from teams for not going all-in on AI when it seems decisions and budgets are hype-driven. reply frereubu 3 hours agoparentI have a friend who was tasked by a think tank to build an AI model for which they'd managed to get an enormous amount of funding. My friend pointed out that it would be much more effective if they used a regression model that could be built in a couple of days by a junior developer. Eventually he was fired from the project for sticking to his guns and refusing to pad his time while building something worse just so they could say they'd used \"AI\". reply extr 12 hours agoparentprevI have pushed back in a similar way many times (wrt LLMs), the response I typically get is some combination of: - A custom/heuristic driven approach would perform better but will take much longer to build so would be lower ROI. - There is a strategic angle to using AI here (building competency). We aren't sure what new use cases will open up in the medium term and we need to be fluent with building AI products. - There is a perceptual/marketing angle to using AI here. We need to convince the market/investors we are on the bleeding edge (hype). 3 is widely mocked but is a completely rational allocation of resources when you need to compete in a market for funding. reply physicsguy 5 hours agorootparent> will take much longer to build so would be lower ROI This one is funny because my experience has been that ekeing out the issues in this sort of thing is enormously complicated and unreliable and takes an inordinate amount of time. Often the 'bugs' aren't trivially fixable. One we had was the LLM formatting URIs given in the prompt wrongly meaning they're no longer valid. Most of the time it works fine, but sometimes it doesn't, and it's not reproducible easily. reply extr 1 hour agorootparentIt's true, it can be maddening (impossible?) to chase down all the edge-case failures LLMs produce. But outside of life/death applications with extreme accuracy requirements (eg: medical diagnostics) the attitude I've seen is: who cares? A lot of users \"get\" AI now and don't really expect it to be 100% reliable. They're satisfied with a 95% solution, especially if it was deployed quickly and produces something they can iterate on for the last 5%. reply _glass 8 hours agorootparentprevProlog is AI, so whenever I see such a problem, I use miniKanren, implementing Relational/Logic programming in a light-weight way. Bleeding edge AI it is. reply mrieck 1 hour agorootparentprevYou didn't list the most important reason: - Assume LLMs will be more intelligent and cheaper, and the cost of switching to a new LLM model is non-existent. How does improving the custom/heuristic compare in that future? reply extr 1 hour agorootparentThat's kind of what I was getting at in point 2, about \"new use cases\" opening up, but yeah you stated it more directly. It's hard to argue with. With a heuristic driven approach we know we will need expertise, dev hours, etc to improve the feature. With LLMs, well, some lab out there is basically doing all the hard work for us, all we need to do is sit back and wait for a year or two and then change one line of code, model=\"gpt-4o\" to model=\"gpt-5o\" or whatever. reply jorblumesea 2 hours agorootparentprevfor 1/2, surprised to hear this because debugging models is usually a total black box and practically impossible. for 2, it's a similar problem where getting performance and accuracy using the same model over and over again on different problem sets can be challenging. not an AI expert or anything this has been my experience on the product side. reply extr 1 hour agorootparentResponded to the same sentiment elsewhere but my general sense is that for many use cases users simply do not care about high 9s accuracy/consistency. A 95% solution using AI is \"good enough\" if you can ship it quickly and give them the tools to iterate on that last 5%. reply jorblumesea 0 minutes agorootparent95% solution might work for small startup X or small biz y but at large company scale 5% is a huge deviation to correct on. Maybe just depends on the client and how touchy they are. At my company, we measure metrics in bps and moving something 50 bps is a huge win. 500 bps would be unheard of. d_sem 17 hours agoparentprevThis is a perfect lesson in why strong communication skills are important in engineering organizations. It's leaderships responsibility to learn from engineering what is technically feasible but its also engineering's responsibility to communicate well enough to convince their organization on the right path forward. reply IanCal 9 hours agoparentprevI've found having a cascade of things helps. Trying to split things into \"decision at this later, or pass on to the next\" with increasingly complicated models/approaches. Start with ifs, then svms then something else for example. This has some technical benefits, like speed, and gives you a place to put important hard coded fixes for where a better model makes a small but key mistake. But the bigger benefit imo is getting something to solve the bulk of the problem quicker, and a organisationally it means not saying no to an approach - just where it fits and at what level of improvement it's worth it. reply cm2187 11 hours agoparentprevCV driven development! reply spacecadet 16 hours agoparentprevFor years I worked at a company doing manufacturing automation with a generative CAD component. People would constantly throw out, \"use ML\" \"use AI\", everything was just regressions and open cascade... and those people never understood that it worked just fine without buzzwords. reply BOOSTERHIDROGEN 15 hours agorootparentCould you offer more insight into how regression analysis and open cascade are utilized in manufacturing processes? reply j45 11 hours agoparentprevIt's important to consider if existing tech can do something as well if not better. LLMs can have have great application where existing tech can't reach. Too often, seeing LLMs doing something that's done better already by an existing tech or something it's not designed for seems to miss the impact being sought. reply mlepath 14 hours agoprevI have had a somewhat similar journey but 14 years instead of 25 and I always wonder how it would be different today. We were lucky enough to grow up with the industry and progressively learn more complexity. The kids out of school today are faced with decades worth of complexity on day one on the job. reply mnky9800n 10 hours agoparentPhysicists have centuries to catch up on just to get started. I think they will survive. The main issue today is more the saturation of useless information in my opinion. There’s little time for your own thoughts as too much time is spent sorting the thoughts others want you to think. reply fallous 14 hours agoparentprevThis is true for every field. Everyone has had to step into a field that was built upon the hard-won experience of others and had to get up to speed, and the easiest way to do so is to recognize that fact and take advantage of the wisdom of those who came before. reply SteveSmith16384 5 hours agoprevIt makes such a refreshing change to have a web page not cluttered with adverts and popups. Just nice, clean, well-spaced-out text and simple organisation. reply Evidlo 18 hours agoprevI saw this guy recently left UTK, which is close to my hometown. He made a blog post which made me rethink going into academia after grad school. reply gbnwl 17 hours agoparentWhich one and in which direction did you rethink? Your comment made me curious so I looked at his posts and he has a one about leaving academia because he wasn't happy in 2022, and a more recent one about rejoining it some months ago. https://austinhenley.com/blog/leavingacademia.html https://austinhenley.com/blog/rejoiningacademia.html reply Evidlo 15 minutes agorootparentI didn't see the more recent post, so thanks for the link. I should say that I'm still in grad school (nearing the end), so the decision hasn't been made yet. The direction I'm thinking is away from academia. I love the academic environment, access to university resources and close proximity to lots of domain experts. However my experience as of late has been pretty isolating, as my group is almost fully remote despite nearly everyone living in the same town making motivation difficult some times. I also sometimes miss exercising my practical engineering skills, as my current work is entirely analytical/simulation. Overall its been less rewarding than I had hoped. reply vouaobrasil 6 hours agoprev [–] For a lot of people, AI is a fun journey where they create things that are amazing. And I agree, the results are quite amazing. But it's also a sad thing that the world works this way because scientists like this never think of the larger social consequences of their work. They are insulated and elevated to lofty social positions while their creations fundamentally alter the social fabric. AI is one of those things that is quite dangerous and the fact that large corporations attract people by glorifying their intellect is a recipe for disaster. reply dale_glass 6 hours agoparent [–] I'm not sure what this means exactly, because AI is a wide field that covers so much and angers a great many people for many different reasons. But IMO it's pointless to hope for something else. AI at its core turns out to be pretty simple. No matter what the best intentioned scientist did, somebody else would think differently. For example, Stable Diffusion was originally released with a filter that refused to generate porn. There's your scientist thinking of social consequences. But does anyone even still remember that was a thing? Because I'm pretty sure every SD UI in existence at this point has it disabled by default. reply _heimdall 5 hours agorootparent> For example, Stable Diffusion was originally released with a filter that refused to generate porn. There's your scientist thinking of social consequences We would have to know their internal conversations to know whether that filter was being driven by scientific concern over social consequences or any number of business goals/concerns. We can't assume the reasoning behind it when we only have the end result. reply dale_glass 3 hours agorootparentThat doesn't matter for the point I'm making: which is that this attempt (and any other) are trivially nullified by those that come next. The SD devs couldn't have created a state of affairs in which AI never ever would generate porn. And transformer architecture is too low level to care about things like that, there was no way for the people who made the guts of the modern AI systems to make it so that they only can ever make cute fluffy kittens or give accurate advice. So what I'm saying is that there's no timeline in which socially conscious scientists would have succeeded in ensuring the the current gen AI landscape with its porn, deepfakes and propaganda didn't come to exist. reply vouaobrasil 6 hours agorootparentprev [–] > No matter what the best intentioned scientist did, somebody else would think differently. This is exactly an argument that supports technological determinism. We simply can't decide -- we have no ability for oversight to stop technology from evolving. That's precisely why I think AI is so dangerous. reply dale_glass 6 hours agorootparent [–] IMO, the dangers of AI are mostly overrated. AI is just a new fancy way of generating pictures and text. It does those things better in some regards, but the danger is the same we already had. reply HarHarVeryFunny 2 hours agorootparentWe're only just starting to get to the point that AI, if unconstrained, is capable enough to be dangerous. The danger is getting to the point where the not-so-bright malevolent actor can tap into AI to get detailed instructions to do something highly destructive, or have it do it on their behalf (e.g. hack into some system), that they wouldn't previously have been able to figure out just by Googling for information and trying to piece it together themself. Of course not all malevolent actors are dimwits, but there are also many things that even a highly intelligent individual couldn't do on their own, such as a Stuxnet level attack, that AI will eventually (how soon?) be able to facilitate. reply _heimdall 4 hours agorootparentprevThis is actually where the AI concern arguments seem to get misunderstood in my opinion. I've never heard anyone raise serious concerns over fancier ML and generative algorithms - maybe concerns over job loss but I don't think that's what you had in mind (correct me if I'm wrong). The more serious concerns I hear are related to actual artificial intelligence, something much smarter than humans acting on a time scale drastically different than humans. I'm not vouching for those concerns here, but I would say its more fair to keep them in the context of AI rather than ML, LLMs, and generative tools. reply vouaobrasil 5 hours agorootparentprev [–] It's also a way of mechanizing even further large amounts of human labor and reducing the importance of art. I guess it depends on what you value: for you, apparently a world with AI is not so bad. For me, it's disgusting. reply dale_glass 5 hours agorootparent [–] I honestly don't see it fundamentally different from most other code. I generated images and music (PLAY instruction) with GWBASIC back when I was a teenager. I generated text with Perl. This is just the continuation of the same old, just a bit fancier. reply vouaobrasil 4 hours agorootparent [–] I don't think it is. One could say that getting hit by a car is the continuation of getting hit by a person, but one is much more powerful than another. AI allows mass creation of much more complicated works at a speed much greater than before. the PLAY instruction might create some music, but it won't be the sort of music that can compete with human-made music. AI music is very close to it. Speed is important, strength is important. There is no obvious qualitative difference, but qualitative differences emerge due to a massive increase in complexity, just like consciousness emerges in us but (probably) not in a bacteria due to the massive difference in complexity, even though we are just a scaling of the former. Your text generation with Perl wouldn't be able to write an article, but ChatGPT can, and the magnitude difference is precisely what we cannot handle, just like I can't be hit by a speeding car at 100km/h and survive but I'd probably walk away from being hit at 2km/h (and once this actually happened to me, without injury). Would you say there's not much difference between the two? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Austin Z. Henley, an Associate Teaching Professor at Carnegie Mellon University, shares his 25-year journey in AI (Artificial Intelligence) and ML (Machine Learning), highlighting his transition from initial disinterest to active involvement through various projects.",
      "His career path includes developing simple games, studying AI and neural networks, and applying decision trees and clustering during his PhD to analyze code editor data.",
      "Henley joined Microsoft's program synthesis team in 2022, working on AI projects, including tools based on LLMs (Large Language Models), and continues to explore AI tools independently while teaching."
    ],
    "commentSummary": [
      "There is a growing trend in the AI (Artificial Intelligence) and ML (Machine Learning) fields to use AI even when simpler solutions might be more effective. - Some professionals argue against this trend, emphasizing the need for practical approaches and questioning the necessity of AI in every application. - The debate underscores the importance of communication within engineering teams to balance innovation with practicality, while also considering the societal impact of AI on traditional human roles and creativity."
    ],
    "points": 172,
    "commentCount": 35,
    "retryCount": 0,
    "time": 1735771276
  }
]
