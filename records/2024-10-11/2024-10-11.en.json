[
  {
    "id": 41805446,
    "title": "$2 H100s: How the GPU Rental Bubble Burst",
    "originLink": "https://www.latent.space/p/gpu-bubble",
    "originBody": "Share this post $2 H100s: How the GPU Bubble Burst www.latent.space Copy link Facebook Email Note Other Discover more from Latent Space The AI Engineer newsletter + Top 10 US Tech podcast. Exploring AI UX, Agents, Devtools, Infra, Open Source Models. See https://latent.space/about for highlights from Chris Lattner, Andrej Karpathy, George Hotz, Simon Willison, Emad Mostaque, et al! Over 52,000 subscribers Subscribe Continue reading Sign in $2 H100s: How the GPU Bubble Burst Last year, H100s were $8/hr if you could get them. Today, there's 7 different resale markets selling them under $2. What happened? Eugene Cheah Oct 11, 2024 32 Share this post $2 H100s: How the GPU Bubble Burst www.latent.space Copy link Facebook Email Note Other 4 Share Swyx’s note: we’re on a roll catching up with former guests! Apart from our recent guest spot on Raza Habib’s chat with Hamel Husain (see our Raza pod here), we’re delighted for the return of Eugene Cheah (see our pod on RWKV last year) as a rare guest writer for our newsletter. Eugene has now cofounded Featherless.AI, an inference platform with the world’s largest collection of open source models (~2,000) instantly accessible via a single API for a flat rate (starting at $10 a month). Recently there has been a lot of excitement with NVIDIA’s new Blackwell series rolling out to OpenAI, with the company saying it is sold out for the next year and Jensen noting that it could be the “most successful product in the history of the industry”. With cousin Lisa hot on his heels announcing the MI3 25 X and Cerebras filing for IPO, it is time to dive deep on the GPU market again (see also former guest Dylan Patel’s pod for his trademark candid take of course - especially his take on what he calls the “AI Neoclouds”, which is what Eugene discusses here). Do we yet have an answer to the $600bn question? It is now consensus that the capex on foundation model training is the “fastest depreciating asset in history”, but the jury on GPU infra spend is still out and the GPU Rich Wars are raging. Meanwhile, we know now that frontier labs are spending more on training+inference than they make in revenue, raising $6.6b in the largest venture round of all time while also projecting losses of $14b in 2026. The financial logic requires AGI to parse. Fortunately, we’ve got someone who spends all his time thinking about this. What follows is Eugene’s take on GPU economics as he is now an inference provider, diving deep on the H100 market, as a possible read for what is to come for the Blackwell generation. Not financial advice! We also recommend Yangqing Jia’s guide. TLDR: Don’t buy H100s. The market has flipped from shortage ($8/hr) to oversupplied ($2/hr), because of reserved compute resales, open model finetuning, and decline in new foundation model co’s. Rent instead1. For the general market, it makes little sense to be investing in new H100s today, when you can rent it at near cost, when you need it, with the current oversupply. A short history of the AI race ChatGPT was launched in November 2022, built on the A100 series. The H100s arrived in March 2023. The pitch to investors and founders was simple: Compared to A100s, the new H100s were 3x more powerful, but only 2x the sticker price. If you were faster to ramp up on H100s, you too, can build a bigger, better model, and maybe even leapfrog OpenAI to Artificial General Intelligence - If you have the capital to match their wallet! With this desire, $10-100’s billions of dollars were invested into GPU-rich AI startups to build this next revolution. Which lead to …. The sudden surge in H100 demand Market prices shot through the roof, the original rental rates of H100 started at approximately $4.70 an hour but were going for over $8. For all the desperate founders rushing to train their models to convince their investors for their next $100 million round. Nvidia, literally pitched to their investors & datacenter customers, in their 2023 investor presentation - the “market opportunity” on renting H100s at $4/hr For GPU farms, it felt like free money - if you can get these founders to rent your H100 SXMGPUs at $4.70 an hour or more, or even get them to pay it upfront, the payback period was = 40% price drop per year, especially for small clusters. NVIDIA’s marketing projection of $4 per GPU hour across 4 years, has evaporated away in under 1.5 years. And that is horrifying because it means someone out there is potentially left holding the bag - especially so if they just bought it as a new GPUs. So what is going on? What’s the ROI on a USD $50k H100 SXM GPU? This will be focusing on the economical cost, and the ROI on leasing, against various market rates. Not the opportunity cost, or buisness value. The average H100 SXM GPU in a data center costs $50k or more to set up, maintain, and operate (aka most of the CAPEX). Excluding electricity and cooling OPEX cost. More details on the calculation are provided later in this article. But what does that mean for unit economics today, as an investment? Especially if we assume a 5-year lifespan on the GPUs itself today. Generally, there are two business models for leasing H100, which we would cover. Short on-demand leases (by the hour - by the week - or the month) Longterm reservation (3-5 years) On-demand leasing ROI Spreadsheet for : new H100 ROI (Aug 2024) In summary, for an on-demand workload >$2.85 : Beat stock market IRR = 40% price drop per year we see now. But it’s a means of projecting an ROI while taking into account a certain % of price drop. At $4.50/hour, even when blended, we get to see the original pitch for data center providers from NVIDIA, where they practically print money after 2 years. Giving an IRR (Internal rate of return) of 20+%. However, at $2.85/hour, this is where it starts to be barely above 10% IRR. Meaning, if you are buying a new H100 server today, and if the market price is less than $2.85/hour, you can barely beat the market, assuming 100% allocation (which is an unreasonable assumption). Anything, below that price, and you're better off with the stock market, instead of a H100 infrastructure company, as an investment. And if the price falls below $1.65/hour, you are doomed to make losses on the H100 over the 5 years, as an infra provider. Especially, if you just bought the nodes and cluster this year. Longterm reservation leases (3 years+) Many infrastructure providers, especially the older ones - were not naive about this - Because they had been burnt firsthand by GPU massive rental price drops, after a major price pump, from the crypto days - they had seen this cycle before. So for this cycle, last year, they pushed heavily for a 3-5 year upfront commitment and/or payment at the $4+ price range. (typically with 50% to 100% upfront). Today, they push the $2.85+ price range - locking in their profits. This happened aggressively during the 2023 AI peak with various foundation model companies, especially in the image generation space, indirectly forced into high-priced 3-5 year contracts, just so to get to the front-of-the-line of a new cluster, and be first to make their target model, to help close the next round. It may not be the most economical move, but it lets them move faster than the competition. This, however, has led to some interesting market dynamics - if you are paying $3 or $4 per hour for your H100, for the next 3 years, locked into a contract. When a model creator is done training a model, you have no more use for the cluster. What would they do? - they resell and start recouping some of the costs. The current H100 value chain From hardware to AI inference / finetune, it can be broadly viewed as the following Hardware vendors partnered with Nvidia (one-time purchase cost) Datacenter Infrastructure providers & partners (selling long-term reservations, on facility space and/or H100 nodes) VC Funds, Large Companies, and Startups: that planned to build foundation models (or have already finished building their models) Resellers of capacity: Runpod, SFCompute, Together.ai, Vast.ai, GPUlist.ai Managed AI Inference / Finetune providers: who use a combination of the above While any layer down the stack may be vertically integrated (skipping the infra players for example), the key drivers here are the “Resellers of unused capacity” and the rise of “good enough” open weights models like Llama 3, as they are all major influencing factors in the current H100 economical pressures. The rise of open weights models, on-par with closed-source models. Is resulting in a fundamental shift in the market Market Trends: The rise of open-weights models ↑↑ Increased demand for AI inference & fine-tuning Because many “open” models, lack proper “open source” licenses, but are being distributed freely, and used widely, even commercially. We will refer to them collectively as “open-weights” or “open” models instead here. In general, with multiple open-weights models of various sizes being built, so has the growth in demand for inference and fine-tuning them. This is largely driven by two major events The arrival of GPT4 class open models (eg. 405B LLaMA3, DeepSeek-v2) The maturity and adoption of small (~8B) and medium (~70B) fine-tuned models Today, for the vast majority of use cases, enterprises may need, there are already off-the-shelf open-weights models. Which might be a small step behind proprietary models in certain benchmarks. Provides an advantage with the following Flexibility: Domain / Task specific finetunes Reliability: No more minor model updates, breaking use case (there is currently low community trust that model weights are not quietly changed without notification in public API endpoints, causing inexplicable regressions) Security & Privacy: Assurance that their prompts and customer data are safe. All of this leads to the current continuous growth and adoption of open models, with the growth in demand for inference and finetunes. But it does cause another problem… Compounded collapse of small & medium model creators ↓↓ Shrinking foundation model creator market (Small & Medium) We used “model creators” to collectively refer to organization that create models from scratch. For fine-tuners, we refer to them as “model finetuners” Many enterprises, and multiple small & medium foundation model creator startups - especially those who raised on the pitch of “smaller, specialized domain-specific models”, are groups who had no long-term plans / goals for training large foundation models from scratch ( >= 70B ). For both groups, they both came to the realization that it is more economical and effective to fine-tune existing Open Weights models, instead of “training on their own”. This ended up creating a triple whammy in reducing the demand for H100s! Finetuning is significantly cheaper than training from scratch. Because the demands for fine-tuning are significantly less in compute requirements (typically 4 nodes or less, usually a single node), compared to training from scratch (from 16 nodes, usually more, for 7B and up models). This industry-wide switch essentially killed a large part of smaller cluster demands. Scaling back on foundation model investment (at small/mid-tier) In 2023, there was a huge wave of small and medium foundation models, within the text and image space. Today, however, unless you are absolutely confident you can surpass llama3, or you are bringing something new to the table (eg. new architecture, 100x lower inference, 100+ languages, etc), there are ~no more foundation model cos being founded from scratch. In general, the small & medium, open models created by the bigger players (Facebook, etc), make it hard for smaller players to justify training foundation models - unless they have a strong differentiator to do so (tech or data) - or have plans to scale to larger models. And this has been reflected lately with investors as well, as there has been a sharp decline in new foundation model creators’ funding. With the vast majority of smaller groups having switched over to finetuning. (this sentiment is combined with the recent less than desired exits for multiple companies). Presently today, there is approximately worldwide by my estimate: = 6 months), it is very well possible that many of these groups had already made the upfront payment before they made the change, essentially making their prepaid hardware “obsolete on arrival”. Alternatively, those who had the hardware arrive on time, to train their first few models, had come to the same realization it would be better to fine-tune their next iteration of models. Instead of building on their own. In both cases, they would have unused capacity, which comes online via “Compute Resellers” joining the market supply…. Other factors causing an increase in supply & reduced training demand 1) Large model creators goes off public cloud platform Another major factor, is how all the major Model Creators, such as Facebook, X.AI, and arguably OpenAI (if you count them as part of Microsoft) are moving away from an existing public provider, and building their own billion-dollar clusters, removing the demand that the existing clusters depend on. The move is happening mostly for the following reasons: Existing ~1k node clusters (which costs >$50M to build), is no longer big enough for them, to train bigger models At a billion-dollar scale, it is better for accounting to purchase assets (of servers, land, etc), which has booked value (part of company valuation and assets), instead of pure expenses leasing. If you do not have the people (they do), you could straight up buy small datacenters companies, who have the expertise to build this for you. With the demand gradually weaning away in stages. These clusters are coming online to the public cloud market instead. Vast.ai essentially does a free market system, where providers from all over the world, are forced to compete with each other 2) Unused / Delayed supply coming online Recall all the H100 large shipment delays in 2023, or 6 months or more? They are coming online, now - along with the H200, B200, etc. This is alongside, the various unused compute, coming online (from existing startups, enterprises or VCs as covered earlier). The bulk of this is done via Compute Resellers, such as : together.ai, sfcompute, runpod, vast.ai, etc In most cases, cluster owners have a small or medium cluster, (typically 8-64 nodes), that is underutilized. With the money already “spent” for the cluster. With the primary goal is to recoup as much of the cost as possible, they rather undercut the market and guarantee an allocation, instead of competing with the main providers, and possibly have no allocation. This is typically done either via a fixed rate, an auction system, or just a free market listing, etc. With the later 2 driving the market price downwards. 3) Cheaper GPU alternatives (esp. for inference) Another major factor, is once your outside of the training / fine-tune space. The inference space is filled with alternatives, especially if your running smaller models. One do not need to pay for the premium invoked by H100’s Infiniband and/or nvidia. a) Nvidia market segmentation H100 premium for training is priced into the hardware. For example nvidia themselves recommend the L40S, which is the more price competitive alternative for inference. Spreadsheet for: H100 Infiniband Cluster math (Aug 2024) Which Is 1/3rd the performance, at 1/5th the price. But does not work well with multi-node training. Undercutting their very own H100 for this segment. b) AMD and Intel alternative providers Both AMD and Intel may be late into the game with their MX300, and Gaudi 3 respectively. This has been tested and verified by us, having used these systems. They are generally: Cheaper than a H100 in purchase cost Have more memory and compute than a H100, and outperforms on a single node. Overall, they are great hardware! The catch? They have minor driver issues in training and are entirely unproven in large multi-node cluster training. Which as we covered is largely irrelevant to the current landscape. To anyone but =$2.90 / hour) because there is no other option. For those who truly need it. We are starting to see this trend for example with Voltage Park: Where clusters with Infiniband are charged at a premium. While the Ethernet-based instances, which are perfectly fine for inference are priced at a lower rate. Adjusting the prices for the respective use case/availability. While there’s been a general decline in foundation model creator teams, it is hard to predict if there will be a resurgence, with the growth in open weights, and/or alternative architectures. It is also, expected that in the future, we will see further segmentation by cluster sizes. Where a large 512-node cluster with Infiniband may be billed higher per GPU than a 16-node cluster. Bad: New public cloud H100 clusters, late to the game, might be unprofitable - some investors may get burnt. There is a lot against you, if you price it below $2.25, depending on your OPEX, you risk potentially being unprofitable. If you price it too high >= $3, you might not be able to get sufficient buyers to fill capacity. If you're late, you could not recoup the cost in the early $4/hour days. Overall, these cluster investments will be rough for the key stakeholders and investors. While I doubt it’s the case, if new clusters, make a large segment of the AI portfolio investments. We may see additional rippling effects in the funding ecosystem from burnt investors. Neutral: Medium, to large Model creators, who purchased, long-term leases - already extracted value at the premium Instead of a negative outlook, a neutral outlook would be some of the unused compute foundation model creators, coming online, are already paid for. The funding market has already priced in and paid for this cluster and its model training. And “extracted its value” which they used for their current and next funding round. Most of these purchases were made before the popularity of Compute Resellers, the cost was already priced in. If anything, the current revenue they get from their excess H100 compute, and the lowered prices we get, are beneficial to both parties If so the negative market impact is minimal, while overall it’s a net positive win for the ecosystem. Good: Cheap H100s, could accelerate the open-weights AI adoption wave Given that the open-weights model has entered the GPT-4 class arena. Falling H100 prices will be the multiplier unlock for open-weights AI adoption. It will be more affordable, for hobbyists, AI developers, and engineers, to run, fine-tune, and tinker with these open models. Especially if there is no major leap for GPT5++, because it will mean that the gap between open-weights and closed-source models will blur. This is strongly needed, as the market is currently not sustainable. As there lacks the value capture on the application layer for paying users (which trickles down the platform, models, and infra layers) In a way, if everyone is building shovels (including us), and applications with paying users are not being built (and collecting revenue and value). But when AI inference and fine-tuning becomes cheaper than ever. It can potentially kick off the AI application wave. If it has not already slowly started so. Conclusion: Don’t buy brand new H100’s Spending on new H100’s hardware is likely a loss-maker Unless you have some combination of discounted H100s, discounted electricity, or a Sovereign AI angle where the location of your GPU is critical to your customers. Or you have billions and need a super large cluster. If you're investing, consider investing elsewhere. Or the stock market index itself for a better rate of returns. IMO Featherless.AI plug … What we do … At Featherless.AI - We currently host the world’s largest collection of OpenSource AI models, instantly accessible, serverlessly, with unlimited requests from $10 a month, at a fixed price. We have indexed and made over 2,000 models ready for inference today. This is 10x the catalog of openrouter.ai, the largest model provider aggregator, and is the world’s largest collection of Open Weights models available serverlessly for instant inference. Without the need for any expensive dedicated GPUs And our platform makes this possible, as it’s able to dynamically hot-swap between models in seconds. It’s designed to be easy to use, with full OpenAI API compatibility, so you can just plug our platform in as a replacement to your existing AI API for your AI agents. Running in the background And we do all of this; As we believe that AI should be easily accessible to everyone, regardless of language or social status. why we decided to be different, from other inference providers… On the technical side of things, related to this article. It is a challenge having PetaBytes’s worth of AI models, and growing, running 24/7 - while being hardware profitable (we are), because we needed to optimize every layer of our platform, down to how we choose the GPU hardware. In an industry, where the typical inference provider pitch is typically along the lines of winning with their, special data center advantages, and CUDA optimization that they perform on their own hardware. Hardware is CAPEX intensive. (Which is being pitched and funded even today) We were saying the opposite, which defied most investors’ sensibilities - we were saying we would be avoiding buying new hardware like the plague. We came to a realization, that most investors, their analysts, and founders failed to realize, thanks to the billions in hardware investments to date. GPUs are commodity hardware. Faster than all of us expected. Few investors have even realized we have reached commodity-level prices at $2.85 in certain places, let alone loss-making prices of a dollar. Because most providers (ignoring certain exceptions), only show their full prices after quotation or after login. And that was the trigger, which got me to write this article. While we do optimize our inference CUDA and kernels as well. On the hardware side; We’ve bet on hardware commoditizing and have focussed instead on the orchestration layer above. So for us, this is a mix of sources from, AWS spot (preferred), to various data center grade providers (eg. Tensordock, Runpod) with security and networking compliances that meet our standards. Leveraging them with our own proprietary model hot swapping, which boots new models up in under a second. Keeping our fleet of GPUs right-sized to our workload, while using a custom version of our RWKV foundation model as a low-cost speculative decoder. All of which allows us to take full advantage of this market trend, and future GPU price drops, as newer (and older) GPUs come online to replace the H100s. And scale aggressively. PS: If you are looking at building the world's largest inference platform, and are aligned with our goals - to make AI accessible to everyone, regardless of language or status. Reach out to us at: hello@featherless.ai Head over to Eugene’s Blog Tech Talk CTO for more footnotes on xAI’s H100 cluster we cut from this piece. Additional Sources: GPU data: Tech Power Up Database. The A100 SXM had 624 bf16 TFlops, the H100 SXM was 1,979 bf16 TFlops Microsoft & AWS allocated over $40 billion in AI infra alone: Wall Street Journal Nvidia investor slides for Oct 2014: page 14 has the pitch for “data centers” Semi Analysis: deepdive for H100 clusters, w/ 5 year lifespan approx for components Spreadsheet for : new H100 ROI (Aug 2024) Spreadsheet for: H100 Infiniband Cluster math (Aug 2024) 1 Unless you have some combination of discounted H100s, discounted electricity, or a Sovereign AI angle where the location of your GPU is critical to your customers, or you have billions and need a super large cluster for frontier model training 2 The cited “600 Billion Dollars “ is about Sequoia David Cahn article Subscribe to Latent Space Hundreds of paid subscribers The AI Engineer newsletter + Top 10 US Tech podcast. Exploring AI UX, Agents, Devtools, Infra, Open Source Models. See https://latent.space/about for highlights from Chris Lattner, Andrej Karpathy, George Hotz, Simon Willison, Emad Mostaque, et al! Subscribe Error 32 Share this post $2 H100s: How the GPU Bubble Burst www.latent.space Copy link Facebook Email Note Other 4 Share Previous A guest post by Eugene Cheah Builds Attention-Free Transformer AI models (http://wiki.rwkv.com) from scratch, CEO @ featherless.ai (prv recursal.ai) - Also known for k8s infra & UI testing tools, webapps, and GPU.js, Hot-takes/Views are my own Subscribe to Eugene",
    "commentLink": "https://news.ycombinator.com/item?id=41805446",
    "commentBody": "$2 H100s: How the GPU Rental Bubble Burst (latent.space)351 points by swyx 16 hours agohidepastfavorite241 comments latchkey 11 hours agoI am building a bare metal mi300x service provider business. Anyone offering $2 GPUs is either losing money on DC space/power, or their service is so sketchy under the covers, which they do their best to hide. It is one thing to play around with $2 gpus and another to run a business. If you're trying to do the latter, you're not considering how you are risking your business on unreliable compute. AWS really twerked people's perception of what it takes to run high end enterprise GPU infrastructure like this. People got used to the reliability hyperscaler offers. They don't consider what 999999% uptime + 45kW+ rack infrastructure truly costs. There is absolutely no way anyone is going to be making any money offering $2 H100s unless they stole them and they get free space/power... reply dijit 10 hours agoparent> 999999% uptime Assuming you mean 99.9999%; your hyperscaler isn't giving you that. MTBF is comparable. It's hardware at the end of the day, the VM hypervisor isn't giving you anything on GPU instances because those GPU instances aren't possible to live-migrate. (even normal VMs are really tricky). In a country with a decent power grid and a UPS (or if you use a colo-provider) you're going to get the same availability guarantee of a machine, maybe even slightly higher because less moving parts. I think this \"cloud is god\" mentality betrays the fact that server hardware is actually hugely reliable once it's working; and the cloud model literally depends on this fact. The reliability of cloud is simply the reliability of hardware; they only provided an abstraction on management not on reliability. reply llm_trw 10 hours agorootparentI think people just don't realize how big computers have gotten since 2006. A t2.micro was an ok desktop computer back then. Today you can have something 1000 times as big for a few tens of thousands. You can easily run a company that serves the whole of the US out of a closet. reply JohnBooty 6 minutes agorootparentIt's just wild to me how seemingly nobody is exploiting this. Our industry has really lost sight of reality and the goals we're trying to achieve. Sufficient scalability, sufficient performance, and as much developer productivity as we can manage given the other two constraints. That is the goal, not a bunch of cargo-culty complex infra. If you can achieve it with a single machine, fucking do it. A monolith-ish app, running on e.g. an Epyc with 192 cores and a couple TB of RAM???? Are you kidding me? That is so much computing power, to the point where for a lot of scenarios it can replace giant chunks of complex cloud infrastructure. And for something approaching a majority of businesses it can probably replace all of it. reply geodel 4 hours agorootparentprevWell the problem nowadays is what can be done has become what must be done. totally bypassing on question of what should be done. So now instead of single service serving 5 million requests in a business is replaced by 20 micro services generating traffic of 150 million requests with distributed transactions, logging (MBs of log per request), monitoring, metrics and so on. All leading to massive infrastructure bloat. Do it for dozen more applications and future is cloudy now. Once management is convinced by sales people or consultants any technical argument can be brushed away as not seeing the strategic big picture of managing enterprise infrastructure. reply dartos 8 hours agorootparentprevWell you’d probably also at least want a cdn in each region, so like 3 closets. reply jgalt212 7 hours agorootparentCloudflare caching of static resources is cheap, so back to one closet. But three if you want to be pure and totally cloudless. reply felixgallo 6 hours agorootparentWith one closet you can also lose the entire business if one water pipe breaks or one wire goes bad in drywall. Back to three closets. reply llm_trw 6 hours agorootparentIf only it were possible to make backups. Alas no such technology exists. reply dartos 5 hours agorootparentbackups do not prevent downtime. reply krab 1 hour agorootparentYes. That's a risk assessment every company must make. What's the probability of downtime vs the development slowdown and the operating costs of a fully redundant infrastructure? I worked for a payments company (think credit cards). We designed the system to maintain very high availability in the payment flow. Multi-region, multi-AZ in AWS. But all other flows such as user registration, customer care or even bill settlement had to stop during that one incident when our main datacenter lost power after a testing switch. The outage lasted for three hours and it happened exactly once in five years. In that specific case, investing into higher availability by architecting in more redundancy would not be worth it. We had more downtime caused by bad code and not well thought out deployments. But that risk equation will be different for everyone. reply LoganDark 5 hours agorootparentprevYes. That's what the other closets are for. Redundancy. reply packetlost 4 hours agorootparentprevVery few businesses are living and breathing by their system uptime. Sure, it's bad, but having a recovery plan and good backups (or modest multi-site redundancy, if you're really worried) is sufficient for most. reply dartos 1 hour agorootparentprevLet’s call it a day and just go for a single colo. reply everforward 2 hours agorootparentprev> The reliability of cloud is simply the reliability of hardware; they only provided an abstraction on management not on reliability. This isn't really true. I mean it's true in the sense that you could get the same reliability on-premise given a couple decades of engineer hours, but the vast majority of on-premise deployments I have seen have significantly lower reliability than clouds and have few plans to build out those capabilities. E.g. if I exclude public cloud operator employers, I've never worked for a company that could mimick an AZ failover on-prem and I've worked for a couple F500s. As far as I can recall, none of them have even segmented their network beyond the management plane having its own hardware. The rest of the DC network was centralized; I recall one of them in specific because an STP loop screwed up half of it at one point. Part of paying for the cloud is centralizing the costs of thinking up and implementing platform-level reliability features. Some of those things are enormously expensive and not really practical for smaller economies of scale. Just one random example is tracking hardware-level points of failure and exposing that to the scheduler. E.g. if a particular datacenter has 4 supplies from mains and each rack is only connected to a single one of those supplies, when I schedule 4 jobs to run there it will try to put each job in a rack with a separate power supply to minimize the impact of losing a mains. Ditto with network, storage, fire suppression, generators, etc, etc, etc. That kind of thing makes 0 economic sense for an individual company to implement, but it starts to make a lot of sense for a company who does basically nothing other than manage hardware failures. reply zaptrem 9 hours agorootparentprevAs someone who has done a bunch of large scale ML on hyperscaler hardware I will say the uptime is nowhere near 99.9999%. Given a cluster of only a few hundred GPUs one or multiple failures is a near certainty to the point where we spend a bunch of time on recovery time optimization. reply traceroute66 5 hours agorootparentprev> instances aren't possible to live-migrate Some of the cloud providers don't even do live-migration. They adhere to the cloud mantra of \"oh well, its up to the customer to spin up and carry on elsewhere\". I have it on good authority that some of them don't even take A+B feeds to their DC suites - and then have the chutzpah to shout at the DC provider when their only feed goes down, but that's another story... :) reply wkat4242 1 hour agorootparentprev> Assuming you mean 99.9999%; your hyperscaler isn't giving you that. MTBF is comparable. Yeah we've already had about a day's worth of downtime this year on office 365 and Microsoft is definitely a hyperscaler. So that's 99.3% at best. reply dijit 4 hours agorootparentprevmeta: I'm always interested how the votes go on comments like this. I've been watching periodically and it seems like I get \"-2\" at random intervals. This is not the first time that \"low yield\" karma comments have sporadic changes to their votes. It seems unlikely at the rate of change (roughly 3-5 point changes per hour) that two people would simultaneously (within a minute) have the same desire to flag a comment, so I can only speculate that: A) Some people's flag is worth -2 B) Some people, passionate about this topic, have multiple accounts C) There's bots that try to remain undetected by making only small adjustments to the conversation periodically. I'm aware that some peoples job very strongly depends on the cloud, but nothing I said could be considered off topic or controversial: Cloud for GPU compute relies on hardware reliability just like everything else does. This is fact. Regardless of this, the voting behaviour on my comments such as this are extremely suspicious. reply neom 5 hours agoparentprevThis reads exactly like what people said about DigitalOcean when we launched it. reply count 5 hours agorootparentTo be fair, DO was muuuch sketchier in the past (eg https://news.ycombinator.com/item?id=6983097). Launching any multitenant system is HARD. Many of them are held together with bubble gum and good intentions…. reply neom 5 hours agorootparentBoy I'm never going to live that one down around here huh? Hackernews always going to keep you honest, ha. :D reply imglorp 5 hours agorootparentprevHow was DO able to provide what AWS didn't want to? Was it purely margins? reply neom 5 hours agorootparentAWS just really didn't want to, very different market segment. They were doing a pure enterprise play, looking to capture most of the enterprise. We were doing a b2c play that we presumed over time would suck us up into the SMB. My theory was we had like 1% risk from them. From what I could tell Jeff and Jassy had zero interest in our segment. I left just before the IPO but when we started it, the margin was about 60%, after we figured out how many VMs we could comfortable fit on the box, Ben U just did napkin math and said \"50% seems like a fine enough margin to start\" reply michaelt 9 hours agoparentprev> There is absolutely no way anyone is going to be making any money offering $2 H100s unless they stole them and they get free space/power... At the highest power settings, H100s consume 400 W. Add another 200 W for CPU/RAM. Assume you have an incredibly inefficient cooling system, so you also need 600 W of cooling. Google tells me US energy prices average around 17 cents/kWh - even if you don't locate your data centre somewhere with cheap electricity. 17 cents/kWh * 1200 watts * 1 hour is only 20.4 cents/hour. reply ckastner 8 hours agorootparentThat's just the power. If one expects a H100 to run for three years at full load, 24 x 365 x 3 = 26280. Assuming a price of $25K per H100, that means about $1/h to amortize costs. Hence the unless they stole them, I guess. Factor in space, networking, cooling, security, etc., and $2 really do seem undoable. reply Negitivefrags 8 hours agorootparentNone of that matters if you already bought the H100 and have no use for it. You might as well recoup as much money as you can on it. reply ckastner 6 hours agorootparent> You might as well recoup as much money as you can on it. Depending on how fast their value depreciates, selling them might recoup more money then renting them away. And being exposed to 3y of various risks. Selling now at a 40% loss gets you back the equivalent of 60c/h over three years, and without having other costs (DC, power, network, security) and risks. reply dwattttt 8 hours agorootparentprevIf you already have the H100s, renting access to them at a loss isn't better. Throwing them in the trash will lose you less money. reply michaelt 6 hours agorootparentThat's not how this works. Imagine I own a factory, and I've just spent $50k on a widget-making machine. The machine has a useful life of 25,000 widgets. In addition to the cost of the machine, each widget needs $0.20 of raw materials and operator time. So $5k over the life of the machine - if I choose to run the machine. But it turns out the widget-making machine was a bad investment. The market price of widgets is now only $2. If I throw the machine in the trash on day 1 without having produced a single widget, I've spent $50k and earned $0 so I've lost $50k. If I buy $5k of raw materials and produce 25k widgets which sell for $50k, I've spent $55k and earned $50k so I've lost $5k. It's still a loss, sure, but a much smaller one. reply adgjlsfhk1 4 hours agorootparentand for GPUs, the math is even more stark because rather than having a 25k item lifespan, the lifespan is the time until GPUs improve enough to make the current one irrelevant. reply dragonwriter 30 minutes agorootparentprevNo, if its only a “loss” due to counting amortization of the sunk cost of initial acquisition, throwing them in the trash will lose you more money. The only way you can avoid the key cost is to travel back in time and not buy them, and, yeah, if you can do that instead, maybe you should (but, the time travel technology will make you more money than the H100s would ever cost, so maybe don't bother.) reply ericpauley 7 hours agorootparentprevGGP already showed the marginal power cost is well below $2. reply cheschire 7 hours agorootparentThere is so much more to lifecycle sustainment cost than that. Rackspace. Networking. Physical safety. Physical security. Sales staff. Support staff. Legal. Finance. HR. Support staff for those folks. That’s just off the top of my head. Sitting down for a couple days at the very least, like a business should, would likely reveal significant depths that $2 won’t cover. reply ericpauley 6 hours agorootparentThese are all costs of any server hosting business. Other commenters have already shown that $2/hr for a racked 1U server at 400W is perfectly sustainable. reply H8crilA 7 hours agorootparentprevSo you terminate all of the above right now, or continue selling at a loss (which still extends the runway) and wait for better times? Also, do you know that similar situations occasionally occur in pretty much any market out there? The market doesn't care how much you're losing, it will set a price and it's up to you to take it, or leave it. reply swyx 8 hours agorootparentprevamortization curves for gpus are 5-7 years per my gpu rich contacts. even after they cease to be top of the line they are still useful for inference. so you can halve that $1/h reply stogot 6 hours agorootparentHaven’t electric costs been increasing though? Eventually those two curves should death cross reply latchkey 3 hours agorootparentprevYou are not looking at the full economics of the situation. There are very few data centers left that can do 45kW+ rack density, which translates to 32 H100/MI300x GPUs in a rack. Most datacenters, you're looking at 1 or 2 boxes of 8 GPU, a rack. As a result, it isn't just the price of power, it is whatever the data center wants to charge you. Then you factor in cooling on top of that... reply sandworm101 8 hours agorootparentprevFor the fuller math one has to include the cost of infrastructure financing, which is tied to interest rates. Given how young most of these H100 shops are, I assume that they pay more to service their debts than for power. reply Wytwwww 8 hours agorootparent> I assume that they pay more to service their debts than for power. Well yes, because for GPU datacentres fixed/capital costs make up a much higher fraction than power and other expenses than for CPUs. To such an extent that power usage barely even matters. A $20k that uses 1 kW ( which is way more than it would in reality ) 24x7 would cost $1.3k to run per year at 0.15$ per kWh, that's almost insignificant compared to depreciation. The premise is that nobody could make any money by renting H100s for 2$ even if they got them for free unless they only had free power. That makes no sense whatsoever when you can get 2x AMD EPYC™ 9454P servers at 2x408 W (for full system) for around $0.70 in a German data center. reply bjornsing 9 hours agoparentprev> There is absolutely no way anyone is going to be making any money offering $2 H100s unless they stole them and they get free space/power... That’s essentially what the OP says. But once you’ve already invested in the H100s you’re still better off renting them out for $2 per hour rather than having them idle at $0 per hour. reply Wytwwww 8 hours agorootparentThen how come you can still get several last gen EPYC or Xeon systems that would use the same amount of power for under $1 per hour? For datacentre GPUs the energy, infrastructure and other variable costs seem to be relatively insignificant to fixed capital costs. Nvidia's GPUs are just extremely expensive relative to how much power they use (compared to CPUs). > H100s you’re still better off renting them out for $2 per hour rather than having them idle at $0 per hour. If you're barely breaking even at $2 then immediately selling them would seem like the only sensible option (depreciation alone is significantly higher than the cost power of running a H100 24x365 at 100% utilization). reply bjornsing 6 hours agorootparent> If you're barely breaking even at $2 then immediately selling them would seem like the only sensible option (depreciation alone is significantly higher than the cost power of running a H100 24x365 at 100% utilization). If you can then probably yes. But why would someone else buy them (at the price you want), when they can rent at $2 per hour instead? reply Wytwwww 6 hours agorootparentI don't think the why matters as long as people are buying them at very high prices, which they seemingly still are. reply bjornsing 5 hours agorootparentWhat makes you think they are? reply marcyb5st 8 hours agoparentprevBut it is about minimizing losses, not making profits. If you read the article, such prices happen because a lot of companies bought hardware reservations for the next few years. Instead of keeping the hardware idle (since they pay for it anyway), they rent it out on the cheap to recoup something. reply traceroute66 6 hours agoparentprev> 999999% uptime I've said it before and I've said it again.... Read the cloud provider small-print before you go around boasting about how great their SLAs are. Most of the time they are not worth the paper they are written on. reply foobiekr 3 hours agoparentprevYou should consider the possibility that one outcome is that no one is going to make money offering H100s. reply rajnathani 8 hours agoparentprevFrom your bio, your company is Hot Aisle. This company TensorWave covered by TechCrunch [0] this week sounds very similar, I almost thought it was the same! Anyway, best of luck, we need more AMD GPU compute. [0] https://techcrunch.com/2024/10/08/tensorwave-claims-its-amd-... reply dx034 9 hours agoparentprevSince most applications aren't latency sensitive, space and power can be nearly free by setting up the data center in a place where it's cold, there's nearly free electricity and few people live. Leaves you with cost for infrastructure and connectivity, but I guess electricity prices shouldn't be the issue? reply serjester 3 hours agorootparentAmbient cooling can only go so far. At the end of the day if you have a rack of GPU’s using 6000 watts per node, you’re going to need some very serious active cooling regardless of your location. You’ll save a little but it’s a small percentage of your overall costs. reply pie420 2 hours agorootparentin industrial manufacturing, recovering waste heat is a very common junior engineer task, usually a great first year project from recent grads to do a simple, $50-100k project that has a 1-2 year payback period. Surely someone in the trillion dollar datacenter industry can figure out a way to take waste heat and use it in a profitable way, right? reply coredog64 2 hours agorootparentI’d guess that there’s not enough energy density in the waste heat to do anything useful, especially once you bring it away from the clean areas of the facility where it’s produced to someplace you could actually use it at scale. reply tonetegeatinst 9 hours agorootparentprevI'd think cost of internet would be the big issue even if can afford the AI hardware. In rural areas or even with low population it takes forever to get fiber to roll out and if your selling access to your hardware infrastructure then you really want to get a direct connection to the nearest IX so you can offer customers the best speed for accessing data and the IX would probably be one of the few places you might be able to get 400G or higher direct fiber. But if your hooking up to a IX chances are your not an end user but a autonomous system and already are shoving moving and signing NDA's to be a peer with other Autonomous Systems in the exchange and be able to bgp announce. (Source - my old highschool networking class where I got sick of my shitty internet and looked into how I could get fiber from an exchange. I'm probably mistaken on stuff here as it was years ago and its either wrong or outdated from all those years ago.) reply oasisbob 5 hours agorootparentAssuming rural areas have less fiber availability isn't always a good assumption. In NW Washington state at least, the rural counties (Whatcom, Island, Skagit, etc) have had a robust market in dark fiber for over two decades. The normal telcos weren't responsive to need, so private carriers picked up the slack. When I was last involved in this market, you could get a P2P strand, including reasonable buildout, for less than a cost of a T1 line with a two-year commit. The tiny four-branch credit union I worked for had dedicated fiber loops between all our locations, no big deal. It was great. reply acd10j 9 hours agoparentprevMay be their business model is running compute at loss and stealing ip/code from people using platform? reply fhars 6 hours agoparentprevI think this is what they are insinuating with the \"Hot the Bubble Burst\" in the headline. You are not expected to make money if you have invested in a bursting bubble. reply tasuki 6 hours agoparentprev> If you're trying to do the latter, you're not considering how you are risking your business on unreliable compute. What do you mean by \"risking your business on unreliable compute\"? Is there a reason not to use one of these to train whatever neural nets one's business needs? reply oefrha 6 hours agorootparentWell, someone who’s building a GPU renting service right now obviously wants to scare you into using expensive and “reliable” services; the market crashing is disastrous for them. The reality is high price is hardly an indicator of reliability, and the article very clearly explains why H100 hours are being sold at $2 or less, and it’s not because of certain providers lacking reliability. reply lazide 6 hours agorootparentprevIf it crashes half way through, you don’t get a useful model, and you’re still on the hook for the rental costs to get there maybe? reply wolfgangK 6 hours agoparentprevFor training, doesn't checkpoint saving make high reliability a moot point ? Why pay for 99.99999? uptime when you can restart your training from last/best model ? reply hnaccount_rng 9 hours agoparentprevCan you elaborate on the cost basis? With how little could a very lean operation still make money? I know that's basically impossible to answer generically, especially given that the recurring cost is likely already zero, given that the GPUs are already paid... reply pico_creator 10 hours agoparentprevSomeone is losing the money. It’s elaborated in the article how and why this happens TLDR, VC money, is being burnt/lost reply shermantanktop 9 hours agorootparentTons of VC money burned in pursuit of low-probability success. It’s no wonder that some people find it easier to scam VCs than it is to build a real business. reply scotty79 8 hours agoparentprev> There is absolutely no way anyone is going to be making any money offering $2 H100s unless they stole them and they get free space/power... I think that's the point. Trying to buy and run H100s now either for yourself or for someone else to rent it is a terrible investment because of oversupply. And prices you can get for compute are not enough to cover the costs. reply TechDebtDevin 16 hours agoprevI've been saying this would happen for months. There (was) a giant arbitrage for data centers that already have the infra. If you could get a hold H100s and had an operational data center you essentially had the keys to an infinate money printer on anything above $3.50/hr. Of course, because we live in a world of effecient markets that was never going to last forever. But they are still profitible at $2.00 assuming they have cheap electricity/infra/labor. reply pico_creator 16 hours agoparentProblem is - u can find some at $1 reply swyx 12 hours agorootparentoriginal title i wrote for this piece was \"$1 H100s\" but i deleted because even i thought it was so ridiculously low lol but yes sfcompute home page is now quoting $0.95/hr average. wild. reply ipsum2 11 hours agorootparentsfcompute is a scam. You can't buy GPUs at that price. They're running a \"private beta\" where people can bid for a spot GPU, but they let a limited number of people into the beta, so the prices are artificially low. reply neom 5 hours agorootparentAs an advisor to those guys, I take a great deal of objection with you calling it a scam. It's not a scam. They're testing things out, so the price is low and not many people can use it... because they're testing. That isn't a scam. reply flaque 1 hour agorootparentprevHi! I run sfcompute. We don't have a limited number of slots! We just go down a lot. It's VERY beta at the moment; we literally take the whole thing down about once a week. So if we know of some major problem, or we're down, we just don't let people on (since they'll have a bad experience). You're right though that the prices are probably lower because of this. That's why we have a thing on our website that says \"*Prices are from the sfcompute private beta and don’t represent normal market conditions.\" If you'd like on anyway, I can let you on, just email me at evan at sfcompute, but it may literally break! reply Schiendelman 28 minutes agorootparentIf I may recommend: put a note where people will see those prices so that they understand those prices are unlikely to remain. If the outcome of your current UX is people thinking you're a scam, you have a problem that will last as you start to scale. It's hard to measure now, but it's harder to fix later. Also, I'm really impressed at how great your replies about your product are! You're a gem. reply authorfly 10 hours agorootparentprevThey might be and thanks for warning about that one company - but if this is anything like renting 3090s (ignoring the period of time during crypto rises), the prices really can go low to a loss level, I guess sunk cost crisis for the owners or the inertia of not pulling them out and selling them hits hard. reply pico_creator 11 hours agorootparentprevI actually signed up for separate new account, to double check that my business account was not being favored or rigged in \"private beta\" Its really not that hard to validate this claim, you can just rent for 4 hours at $1.50 - which is under $50 Also like I said, they are *not* the only one, shop around reply ipsum2 11 hours agorootparentI signed up and don't have access currently. My point that the prices are low because demand is limited because of lack of users still stands. Once people sign up and hear about it, the price will increase substantially. reply qeternity 10 hours agorootparentWe are actively using sfcompute at the moment. It's a great product for us where we have a backlog of R&D workloads that can be incrementally run in short bursts. I think you're right about the small private beta resulting in relatively low demand. But it's also a different value prop. If you need a large cluster for a reasonable period of time, you're not paying $1/hr. But if you can use the remnants of someone who contracted for a large allocation, but doesn't need part of it, they can offer it into the market and recoup what would otherwise just be wasted hours. Currently they have some issues around stability, and spin up times are longer than ideal (ca. 15 min), but the team is super responsive and all of these are likely to be resolved in the near future. (No affiliation, just happy users rooting for the sfcompute team). reply startupsfail 15 hours agorootparentprevThe screenshot there is 1xH100 PCIE, for $1.604. Which is likely promotional pricing to get customers onboarded. With promotional pricing it can be $0 for qualified customers. Note also, how the author shows screenshots for invites for private alpha access. It can be mutually beneficial for the data center to provide discounted alpha testing access. The developer gets discounted access, the data center gets free/realistic alpha testing workflows. reply pico_creator 13 hours agorootparentWhen I did the screenshot a month ago, it wasn't public info yet. Now its public: SFCompute list it on their main page - https://sfcompute.com/ And they are *not* the only one reply ipsum2 11 hours agorootparentOkay, but you can't actually buy it at that price, it's a pure marketing ploy. reply pico_creator 11 hours agorootparentNot at $0.5 (which the lower bound in their marketing), but $1.5 is very doable on right times (done so multiple times) The article says $2. Which is quite consistent for a small cluster reply ipsum2 11 hours agorootparentThe average consumer cannot. Only those who have access to sfcompute's private beta can access those prices. Once it opens up to the public, the price will increase. reply zaptrem 9 hours agorootparentprevRunning preprocessing jobs on a $0.5 SFCompute H100 node RN (though price usually bounces up to what you mentioned). reply electronbeam 14 hours agorootparentprevThe PCIE has much lower perf than even a 1x slice of an SXM reply pico_creator 12 hours agorootparentI really suggest shopping around.slow ( Collectively there are less thanFor all the desperate founders rushing to train their models to convince their investors for their next $100 million round. Has anyone actually trained a model actually worth all this money? Even OpenAI is s struggling to staunch the outflow of cash. Even if you can get a profitable model (for what?) how many billion dollar models does the world support? And everyone is throwing money into the pit and just hoping that there's no technical advance that obsoletes everything from under them, or commiditisation leading to a \"good enough\" competitor that does it cheaper. I mean, I get that everyone and/or they investors has got the FOMO for not being the guys holding the AGI demigod at the end of the day. But from a distance it mostly looks like a huge speculative cash bonfire. reply justahuman74 14 hours agoparent> For all the desperate founders rushing to train their models to convince their investors for their next $100 million round. I would say Meta has (though not a startup) justified the expenditure. By freely releasing llama they undercut every a huge swath of competition who can get funded during the hype. Then when the hype dies they can pick up what the real size of the market is, with much better margins than if there were a competitive market. Watch as one day they stop releasing free versions and start rent seeking on N+1 reply grues-dinner 12 hours agorootparentRight, but that is all predicated that, when they get to the end, having spent tons of nuclear fuel, container shiploads of GPUs and whole national GDPs on the project, there will be some juice worth all that squeeze. And even if AI as we know it today is still relevant and useful in that future, and the marginal value per training-dollar stays (becomes?) positive, will they be able to defend that position against lesser, cheaper, but more agile AIs? What will the position even be that Llama2030 or whatever will be worth that much? Like, I know that The Market says the expected payoff is there, but what is it? reply vineyardmike 11 hours agorootparentAs the article suggests, the presence of LLAMA is decreasing demand for GPUs. Which are critical to Metas ad recommendation services. Ironically, by supporting the LLM community with free compute-intense models, they’re decreasing demand (and price) for the compute. I suspect they’ll never directly monetize LLAMA as a public service. reply grues-dinner 10 hours agorootparentWith all these billions upon billions in AI hardware screaming along, are ads actually that much better targeted than they used to be? I imagine admongers like Meta and Google have data that shows they are right to think they have a winning ticket in their AI behemoths, but if my YouTube could present any less relevant ads to me, I'd be actually impressed. They're intrusive, but actually they're so irrelevant that I can't even be bothered to block them, because I'm not going to start online gambling or order takeaways. reply vineyardmike 9 hours agorootparentA better question, with a growing push for privacy, how can they keep ads from regressing? There’s a lot more that goes into the ad space than just picking which ad to show you, and it’ obviously depends on who wants to reach you. For example, probabilistic attribution is an important component on confirming that you actually got the ad and took the action across multiple systems. Also, since you mentioned it, TV ads tend to be less targeted because they’re not direct-action ads. Direct action ads exist in a medium where you can interact with the ad immediately. Those ads are targeted to you more, because they’re about getting you to click immediately. TV ads are more about brand recognition or awareness. It’s about understanding the demographic who watches the show, and showing general ads to that group. Throw a little tracking in there for good measure, but it’s generally about reaching a large group of people with a common message. reply mark_l_watson 5 hours agorootparentYou ask a great question, and I wonder how the push for more privacy will pan out (pardon the gold mining analogy). I am almost done with the very good new book The Tech Coup by Marietje Schaake, and I have also read Privacy is Power and Surveilance Capitalism. I think more of the public is waking up to the benefits of privacy. All that said, I am an enthusiastic paying customer of YouTube Prime and Music, Colab (I love Colab), and sometimes GCP. For many years I have happily have told Google my music and YouTube preferences for content. I like to ask myself what I am getting for giving up privacy in a hopefully targeted and controlled way. reply jorvi 9 hours agorootparentprev> Ironically, by supporting the LLM community with free compute-intense models, they’re decreasing demand (and price) for the compute. For other people that that sentence didn't make sense for at first glance: \"by supporting the LLM community with free compute-intense models [to run on their own hardware] they’re decreasing demand (and price) for the compute [server supply].\" reply vineyardmike 9 hours agorootparentSorry, I should have been more clear. They’re decreasing demand for expensive GPUs that would be required to train a model. Fine-tuning and inference are less compute intense, so overall demand for top-end GPU performance is decreased even if inference compute demand is increased. Basically, why train an LLM from scratch, and spend millions on GPUs, when you can fine tune LLAMA and spend hundreds instead. reply jorvi 5 hours agorootparentThank you for the extra clarification, I hadn’t even thought of inference vs training! reply fragmede 9 hours agorootparentprevHow fungible is that compute though? Having even a single H100 is different than having a bunch of 4090's, nevermind a properly networked supercomputer of H100s. reply vineyardmike 9 hours agorootparentThat’s the point. You can run inference on a 4090 but training is better on a H100. If you use llama, you don’t need to train on an H100, so you can free that supply up for meta. reply fragmede 9 hours agorootparentI haven't been following llama closely but I thought the latest model was too big for inference on 4090's, and that you can't fine tune on 4090's either, but furthermore, the other question is if the market is there for running inference on 4090s. reply vineyardmike 1 hour agorootparentWell, (1) there are a ton of GPUs out there of various specs, and you can also use an inference provider who can use a H100 or similar to serve multiple inference requests at once. (2) there are a ton of LLAMA sizes, from 1b, 2b, 8b, 70b, and 400b. The smaller ones can even run on phone GPUs. reply rsynnott 6 hours agorootparentprev> having spent tons of nuclear fuel It will be primarily gas, maybe some coal. The nuclear thing is largely a fantasy; the lead time on a brand new nuclear plant is realistically a decade, and it is implausible that the bubble will survive that long. reply scotty79 8 hours agorootparentprev> there will be some juice worth all that squeeze. Without the squeeze there'd be a risk for some AI company getting enough cash to buy out Facebook just for the user data. If you want to keep status quo it's good to undercut someone in the cradle that could eventually take over your business. So it might cost Meta pretty penny but it's a mitigation for existential risk. If you climbed up to the top of wealth and influence ladder you should spend all you can to kick off the ladder. It's gonna be always worth it. Unless you still fall because it wasn't enough. reply pico_creator 12 hours agorootparentprevGiven their rising stock price trend, due to their moves in AI. Definitely worth it for them reply mlinhares 12 hours agorootparentprevGiven meta hasn’t been able to properly monetize WhatsApp I seriously doubt they can monetize this. reply fragmede 9 hours agorootparentWho says they haven't? reply jordwest 14 hours agoparentprev> I get that everyone and/or they investors has got the FOMO for not being the guys holding the AGI demigod at the end of the day Don't underestimate the power of the ego... Look at their bonfire, we need one like that but bigger and hotter reply bugbuddy 14 hours agorootparentI spit out my tea when I read your last sentence. You should consider standup comedy. reply Aeolun 14 hours agoparentprevIsn’t OpenAI profitable if they stop training right at this moment? Just because they’re immediately reinvesting all that cash doesn’t mean they’re not profitable. reply Attach6156 13 hours agorootparentAnd if they stop training right now their \"moat\" (which I think is only o1 as of today) would last a good 3 to 6 months lol, and then to the Wendy's it is. reply Aeolun 12 hours agorootparentThat is similarly true for all other AI companies. It’s why they don’t do that. But everyone is still happy to give them more money because their offering is good as it is. reply 0xDEAFBEAD 12 hours agorootparentprevThis guy claims they are losing billions of dollars on free ChatGPT users: https://nitter.poast.org/edzitron/status/1841529117533208936 reply fragmede 9 hours agorootparentEd Zitron's analysis hinges on a lot of assumptions. Much of it comes down to the question of how much it actually costs to run a single inference of ChatGPT. That $20/month pro subscription could be a loss-leader or it could be making money, depending on the numbers you want to use. If you play with the numbers, and compare it to, say, $2/hr for an H100 currently on the front page, $20/$2/hr gets you 10 hours of GPU time before it costs more in hardware than your subscription, and then factoring in overhead on top, it's just not clear. reply elcomet 10 hours agoparentprevNot everyone is doing LLM training. I know plenty of startups selling AI products for various image tasks (agriculture, satellite, medical...) reply mark_l_watson 5 hours agorootparentYes, a lot of the money to be made is in the middleware and application sides of development. I find even small models like Llama 3.2 2B to be extremely useful and fine tuning and integration with existing businesses can have a large potential payoff for smaller investments. reply hackernewds 12 hours agoparentprevLots of companies have. Most recently Character AI trained an internal model and did raise $100M early last year. They didn't release any benchmarks since the founding team and Noam taken to Google reply tonetegeatinst 9 hours agoparentprevPretty sure anthropic has reply authorfly 10 hours agoprevHaha. Cries in sadness that my university lab was unable to buy compute from 2020+ when all the interesting research in AI was jumping up and now AI is going into winter finally compute will be cheap again. reply 7734128 8 hours agoparentI don't feel any winter yet. reply alecco 6 hours agorootparentIf you remove LLMs, there is absolutely an AI winter. reply kkzz99 5 hours agorootparentAudio generation (music, tts, voice cloning), Video and Image generation, multi-modal models, protein simulation... where is the winter? reply authorfly 4 hours agorootparentWell, it's in academia, in traditional universities, any way. I think corporates are still thriving. I can say from an academic point of view, I knew 4 PhDs who started in 2018/2019, all 4 got depressed and left the field. Their research was obsolete before they were halfway through. Usually some PhD students get depressed, but these 4 had awful timing. Their professors were stuck on 3-10 year grants doing things like BERT finetuning or convolution or basic level AI work - stuff that as soon as GPT-3 came out, was clearly obsolete, but nobody could admit that and lose the grants.. In other cases, their work had value, but drew less attention than it should have became all attention went to GPT-3 or people assumed it was just some wrapper technology. The nature of academia and the incentive system caused this; academia is a cruise ship which is hard to turn. If the lighthouse light of attention moves off your ship on to another fancy ship, your only best is lifeboats(industry) or hoping the light and your ship intersect again. The professors have largely decided to steer either right into Generative AI and using the larger models (which they could never feasibly train themselves) for research, or gone even deeper into basic AI. The problem? The research grants are all about LLMs, not basic AI. So basically a slew of researchers willing and able to take on basic AI research are leaving the field now. As many are entering as usual ofcourse, but largely on the LLM bandwagon. That may be fine. The history of AI winters suggests putting all the chips on the same game like this is folly. I recall journals in the 90s and 2000s (my time in universities was after they were released, but I read them), the distribution of AI was broad. Some GOFAI, some neural nets, many papers about filters or clear visual scene detection etc. Today it's largely LLM or LM papers. There is not much of a \"counterweight underdog\" like neural networks served the role off in the 90s/00s. At the same time, for people working in the fields you mention, double check the proportion of research money going into companies vs institutions. While it is true things like TortoiseTTS[1] were an individual effort, that kind of thing is now a massive exception. In stead companies like OpenAI/Google literally have 1000+ researchers each developing the cutting edge in about 5 fields. Universities have barely any chance. This is how the DARPA AI winter went to my understanding(and I listened to one of the few people who \"survived via hibernation\" during my undergraduate); over promising - central focus on one technology - then company development of projects - government involvement - disappointment - cancellation. [1] https://github.com/neonbjb/tortoise-tts reply KaoruAoiShiho 3 hours agorootparentTechnology progressing too far is the opposite of a winter, this sounds like a \"too hot\" problem rather than the opposite. reply thelastparadise 6 hours agorootparentprevAt least not until LLM gains hit a wall. So far every open weight model has far surpassed the previous releases at the same model size. reply danpalmer 6 hours agorootparentBut closed models are clearly slowing. It seems reasonable to expect that as open weight models reach the closed weight model sizes they’ll see the same slowdown. reply anshulbhide 14 hours agoprevThis reminds me of the boom and bust oil cycle as outlined in The Prize: The Epic Quest for Oil, Money & Power by Daniel Yergin. reply swyx 12 hours agoparentcare to summarize key points for the class? reply dplgk 8 hours agorootparentIt seems appropriate, in this thread, to have ChatGPT provide the summary: In The Prize: The Epic Quest for Oil, Money & Power, Daniel Yergin explains the boom-and-bust cycle in the oil industry as a recurring pattern driven by shifts in supply and demand. Key elements include: 1. Boom Phase: High oil prices and increased demand encourage significant investment in exploration and production. This leads to a surge in oil output, as companies seek to capitalize on the favorable market. 2. Oversupply: As more oil floods the market, supply eventually exceeds demand, causing prices to fall. This oversupply is exacerbated by the long lead times required for oil development, meaning that new oil from earlier investments continues to come online even as demand weakens. 3. Bust Phase: Falling prices result in lower revenues for oil producers, leading to cuts in exploration, production, and jobs. Smaller or higher-cost producers may go bankrupt, and oil-dependent economies suffer from reduced income. Investment in new production declines during this phase. 4. Correction and Recovery: Eventually, the cutbacks in production lead to reduced supply, which helps stabilize or raise prices as demand catches up. This sets the stage for a new boom phase, and the cycle repeats. Yergin highlights how this cycle has shaped the global oil industry over time, driven by technological advances, geopolitical events, and market forces, while creating periods of both rapid growth and sharp decline. reply DebtDeflation 7 hours agorootparentThis isn't just the story of GPUs or Oil, this is the entire story of capitalism going back to the early Industrial Revolution in the 1700s. The economist Hyman Minsky added asset prices and debt financing to it to round out a compelling theory of the business cycle including the extreme bubbles and depressions sometimes seen. reply swyx 39 minutes agorootparenthave you ever read a good expanation of why Minsky Moments happen? it always occured to me if you can time them right you can make a ton of money on the way up and on the way down reply automatic6131 6 hours agorootparentprevAren't these both simply cases of the bullwhip effect? https://en.wikipedia.org/wiki/Bullwhip_effect reply DebtDeflation 4 hours agorootparentThat's a supply chain specific example. If you're looking for something more fundamental, they're all examples of unstable systems with positive feedback loops. reply yalogin 5 hours agoprevWhat does it mean for OpenAI? As open source models improve, OpenAI needs to keep on improving their models to stay ahead of them. Over time though, if it hasn’t already happeened, the advantages of OpenAI will not matter to most. Will OpenAI be forced to bleed money training? What does it mean for them over the next few years? reply bjornsing 9 hours agoprevThanks for the heads-up. I just increased my short position in NVDA a tiny bit. The peak should be near. (This is not financial advice.) reply aurareturn 3 hours agoparentI would not bet against Nvidia right now. Yes, H100s are getting cheaper, but I can see the cheap price drawing in a wave of fine tuning interest, which will result in more GPU demand for both training and inferencing. Then there’s the ever need for bigger data centers for foundational model training, which the article described as completely separate from public auction prices of H100s. I don’t think the world has more GPU compute than it knows what to do with. I think it’s still the opposite. We don’t have enough compute. And when we do, it will simply drive a cycle of more GPU compute demand. reply bjornsing 3 hours agorootparentI don’t think I’m betting against Nvidia. I’m betting against Nvidia being worth 3.3 trillion. reply KaoruAoiShiho 3 hours agoparentprevI just went balls deep into long positions including calls and 2x etfs. reply bjornsing 3 hours agorootparentInteresting… What’s your thesis? reply alecco 6 hours agoparentprev\"Markets can stay irrational for longer than you can stay solvent\" reply bjornsing 5 hours agorootparentI know. :) That’s why I keep it small. And I’m long semiconductors as a whole. reply kristopolous 13 hours agoprevThis sounds like bad news for the gpu renter farms. Am reading this right? reply swyx 12 hours agoparentthe marketplaces like sfcompute do great, bc so much cheap supply and theres lots of demand. its the foundation model startups who locked into peak hype contracts for access that are eating a lot of losses right now... (which perhaps explains why the bigcos are acquiring only the founders and not assuming the liabilities of the oldco...) reply sgu999 5 hours agorootparent> which perhaps explains why the bigcos are acquiring only the founders and not assuming the liabilities of the oldco... Who did? reply physicsguy 13 hours agoprevOpen models like Llama make it pointless for the majority of companies to train from scratch. It was obvious this would happen. reply 7734128 7 hours agoparentInference should always be more significant than training in the end though. reply Tepix 7 hours agorootparentThere are more options for inference. reply bjornsing 8 hours agoparentprevTrue. The hard part is timing it. reply hamilyon2 8 hours agoprevIs this the most computational bang for buck one ever seen? Another question: what is the maximum size of model I can fine-tune on 1 H100? reply ranger_danger 14 hours agoprevLast year we reached out to a major GPU vendor for a need to get access to a seven figure dollar amount worth of compute time. They contacted (and we spoke with) several of the largest partners they had, including education/research institutions and some private firms, and could not find ANYONE that could accommodate our needs. AWS also did not have the capacity, at least for spot instances since that was the only way we could have afforded it. We ended up rolling our own solution with (more but lower-end) GPUs we sourced ourselves that actually came out cheaper than renting a dozen \"big iron\" boxes for six months. It sounds like currently that capacity might actually be available now, but at the time we could not afford to wait another year to start the job. reply chronogram 13 hours agoparentIf you were able to make do with cheaper GPUs, then you didn't need FP64 so you didn't need H100s in the first place right? Then you made the right choice in buying a drill for your screw work instead of renting a jackhammer even if the jackhammer would've seemed cooler to you at the time. reply KeplerBoy 10 hours agorootparentDoes anyone doing AI need FP64, and yet they sell well. reply ranger_danger 3 hours agorootparentprev> didn't need H100s I think we're splitting hairs here, it was more about choosing a good combination of least effort, time and money involved. When you're spending that amount of money, things are not so black and white... rented H100s get the job done faster and easier than whatever we can piece together ourselves. L40 (cheaper but no FP64) was also brand new at the time. Also our code was custom OpenCL and could have taken advantage of FP64 to go faster if we had the devices for it. reply Havoc 11 hours agoprevThere is also the small matter of a new gen coming out… Not convinced anything has burst yet. Or will for that matter. The hype may be bubble like but clearly we will need a lot of compute. reply sva_ 10 hours agoprevI've been wondering if any state actors might seem it favorable to offer gpus and sniff on the training data/model architectures reply Der_Einzige 12 hours agoprevI just want to observe that there are a lot of people paying huge amounts of money for consulting about this exact topic and that this article is jam packed with more recent and relevant information than almost any of these consultants have. reply pico_creator 12 hours agoparentFeel free to forward to the clients of \"paid consultant\". Also how do i collect my cut. reply swyx 12 hours agoparentprevauthor @pico_creator is in here actively replying in case u have any followups.. i just did the editing reply pico_creator 12 hours agoparentprevAlso: how many of those consultants, have actually rented GPU's - used them for inference - or used them to finetune / train reply aurareturn 3 hours agorootparentI’m guessing most of them are advising Wallstreet on AI demand. reply ctrlGsysop 15 hours agoprevA good in depth mkt analysis. While it’s not crypto, many of the key points are rinse and repeat of mining - things like insatiable demand and projected ROI. Markets and tech solve high costs all the time. Great point made about the $4/hr number that was most likely a top bullet in a 1000 pitch decks citing NVIDIA. Bagholders could just be all the nations buying all the billionaire’s stories. reply pico_creator 12 hours agoparentYea, the older GPU providers, were pushing 3-5 year commits for a reason. They seen this before reply aurareturn 3 hours agoparentprevThe only difference is that LLMs have a real world value. reply bugbuddy 14 hours agoparentprevThere is one big exception in the list of all nations. I don’t know what to make of it. Irony? reply wmf 14 hours agoparentprevYeah, I did this same kind of math all the time back during the early ASIC mining days except it was accelerated; you had to break even in 9 months or never due to the exponentially growing difficulty. reply askl 16 hours agoprev$2/h rental, not $2 sales price. Pretty misleading. reply squigz 13 hours agoparentMisleading? Anyone who read this title and thought it was referring to the full purchase price might deserve to be misled. reply hackernewds 12 hours agorootparentThat is what the title says explicitly. That's how click bait works reply squigz 12 hours agorootparentIt also explicitly says \"rental\", so I'm not sure how one can possibly arrive at the conclusion that they meant \"$2 to own an H100\" reply gnabgib 12 hours agorootparentIt didn't say that at the time, the article still has the submitted title: $2 H100s: How the GPU Bubble Burst reply squigz 12 hours agorootparentEven so, I genuinely don't see how anyone who might be clicking this article could possibly interpret it the way GP is saying. reply cuu508 12 hours agorootparentWell, case in point, I did. When I read the title I thought – \"IIRC these were going for thousands, could they have really dropped so hard? Well, sometimes companies, cars, real estate properties cost $1, but there's always of course a catch. Let's see what the catch is here...ah, it's a 4x reduction of rental price, boring\" reply nottorp 5 hours agorootparentprevAnyone who isn't an \"AI\" fanatic can and will interpret the title as the sale price :) reply bongodongobob 12 hours agorootparentprevHoly fuck. * walks past gnabgib's desk \"Good morning!\" \"Who are you talking to? Me? You haven't specified who you're interacting with. Which morning? Today? What metric are you measuring by good? This is too confusing for me.\" reply CapeTheory 10 hours agorootparent\"Do you wish me a good morning, or mean that it is a good morning whether I want it or not; or that you feel good this morning; or that it is a morning to be good on?” reply kibibu 12 hours agorootparentprevThe HN title has been editorialized, perhaps recently. The original article title is: > $2 H100s: How the GPU Bubble Burst reply pico_creator 16 hours agoparentprevIf we $2 H100 this year or next. Either AI is super dead, or a new alien GPU rained from the sky reply marcyb5st 13 hours agorootparentThere's option 3: current capacity is enough for our AI needs and so GPUs now the market is flooded. I think AI is not gonna die even in its current stocastic parrot incarnation. It is a useful tool for some tasks and, albeit not transformative like some CEOs, I believe it's gonna stay. At most I believe we will enter another AI winter until there's the next algorithmic breakthrough. reply friendzis 12 hours agorootparentCurrent stochastic parrots do not have to be transformative, they have to appear smart enough for a critical mass of dumb enough people. And judging anecdotally from scanning social media - they already do. Even here, on HN, you find numerous comments of the shape: \"${my favorite gpt} says this: \" reply ranger_danger 14 hours agorootparentprevBlackwell B100/B200 did kinda rain down, also the AMD MI300X and increased availability of H200. There's also cheaper NVIDIA L40/L40S if you don't need FP64. reply askl 14 hours agorootparentprevI'm hoping for the first one reply qingcharles 13 hours agoparentprevSome of the Tesla GPUs are almost at this price per unit on eBay now. I've seen them go for under $15 online. Here's one for ~$18 inc shipping with 6GB DDR5: https://www.ebay.com/itm/Nvidia-Tesla-K20X-6GB-90Y2351-C7S15... reply dplgk 9 hours agorootparentIt appears this GPU cost $7700 when it launched in 2012? GPUs have gotten that much better that this thing isn't even with $100? reply pico_creator 13 hours agorootparentprevThat hurts - i used those GPUs before at their peak Now any random GPU in the computer store murders it reply chessgecko 12 hours agorootparentNot just gpus, the k20 was at 3.9 Tflops (fp32) and the new iPhone is at 4.3 (fp16). If you don’t need the precision it got passed by the phones reply barrenko 13 hours agorootparentprevAre these a viable buy? reply chessgecko 13 hours agorootparentYou’d get better perf training on a current gen phone than that gpu, but it probably functions reply pico_creator 12 hours agorootparentprevOnly if ur a collector (so no if ur plugging it in) reply stego-tech 14 hours agoparentprevAgreed, and I doubt we’ll see one retail at that price even on the secondhand market anytime soon. That said, could I see them being offloaded in bulk for pennies on the dollar if the (presumed) AI bubble pops? Quite possibly, if it collapses into a black hole of misery and bad investments. In that case, it’s entirely plausible that some enterprising homelabs could snatch one up for a few grand and experiment with model training on top-shelf (if a generation old) kit. The SXMs are going for ~$26-$40k already, which is cheaper than the (worse performing) H100 Add-In Card when brand new; that’s not the pricing you’d expect from a “red hot” marketplace unless some folk are already cutting their losses and exiting positions. Regardless, interesting times ahead. We either get AI replacing workers en masse, or a bust of the tech industry not seen since the dot-com bubble. Either way, it feels like we all lose. reply two_handfuls 5 hours agoparentprevAgreed, \"$2/h\" would be the correct unit, \"$2\" reads to me like a typo. reply osigurdson 14 hours agoparentprev2 bucks for a GPU? Maybe a PIC microcontroller. reply askl 14 hours agorootparentThey don't even have HDMI ports so they are pretty useless, but I'd buy one at $2 as a desk ornament. reply qingcharles 13 hours agorootparentGPU display stand: https://www.reddit.com/r/nvidia/comments/1fw68rl/retiring_a_... reply qingcharles 13 hours agorootparentprevhttps://news.ycombinator.com/item?id=41806396 reply renewiltord 15 hours agoparentprevBruh reply amelius 10 hours agoprevDoes that include electricity? reply lamontcg 13 hours agoprevso, time to short NVDA? reply pico_creator 12 hours agoparentHard to say, i mean A100's had the same freefall - and nvidia just grew with H100's reply swyx 12 hours agorootparentcan you do a quick rerun of the ROI math with BH200 numbers now that we know them? minus the fp4 shenanigans ofc reply pico_creator 12 hours agorootparentDo we have actual fp8 numbers? (or i could proxy it by /2 the fp4) reply aurareturn 3 hours agoparentprevThe fact that cheaper GPU prices have drawn so much interest here should tell you that prices will bounce back. The lower the price, the more people will experiment with fine tuning and inferencing. reply Ekaros 13 hours agoparentprevOld adage still stands. But I would certainly unload some if I had any. reply _sys49152 12 hours agorootparentpast 4 years have taught me to bet on irrational reply andreasmetsala 12 hours agorootparentThat works until it doesn’t. reply bsder 14 hours agoprevSo, where can a plebian like me buy a (or 10) used H100? reply wmf 14 hours agoparentI don't expect them to hit the used market before 2026-2027. Data centers will start replacing H100 with R100 at that time. reply hislaziness 16 hours agoprevTLDR: Don’t buy H100s. The market has flipped from shortage ($8/hr) to oversupplied ($2/hr), because of reserved compute resales, open model finetuning, and decline in new foundation model co’s. Rent instead. Is the AI infra bubble already bursting? reply pico_creator 16 hours agoparentI’m hopping more for an open weights AI boom With cheap compute for everyone to finetune :) reply TechDebtDevin 16 hours agoparentprevNo, but the prices will likely converge with MSRP pricing. A lot of datacenter were filled with h100s that cost a premium to get ahold of. reply pico_creator 16 hours agorootparentCovered in the article. They are below MSRP essentially reply hislaziness 14 hours agorootparentprevIt is not just MSRP, management and operations cost too. The article goes into the details of this. reply pico_creator 12 hours agorootparentQ_Q yes - ur right on that - and i wrote the article (about a month ago) reply swyx 12 hours agoparentprev(editor here) we've been commenting on the Winds of AI Winter for a while now :) https://latent.space/p/mar-jun-2024 reply justahuman74 14 hours agoparentprevYes, please only rent instead - sincerely, all of the cloud providers reply pico_creator 12 hours agorootparent~Cough~ not all cloud provider (there are many still willing to charge you an arm and a leg) Only the ones who can give you below MSRP essentially reply evbogue 14 hours agoprevI was surprised recently when I fired up ollama on my refurbished Thinkpad -- a laptop that doesn't even have a GPU. All of the hype had me convinced that I couldn't run any of this LLM stuff at home! It's a little bit slower, but while I wait for the text to generate I have another cup of coffee. Sometimes I even prompt myself to generate some text while I'm waiting. reply heiploy 14 hours agoparenttraining is the phase that needs all that compute reply evbogue 14 hours agorootparentThis is good to know. I had read somewhere (that was probably on the Internet) that every time I submitted a prompt at the Meta AI web site that I was vaporizing an entire bottle of water, so imagine how thrilled I was to be saving so much water by prompting AI at home! But alas, the water was already vaporized. The climate? Already changed. reply gloflo 13 hours agorootparentNope, climate is changing to even worse. It's not a \"oops, OK now we live with this new reality\" but \"oh fuck, the rollercoaster is getting steeper AND is accelerating more and more, the breaks are lose and we already lost half of the wagons\". reply evbogue 4 hours agorootparentMaybe with enough H100s we can next word predict a solution to this global issue. reply m3kw9 14 hours agoparentprevCurrent 1b model will do you no good, just rotate through all the free stuff and it would cover most of you usecases reply evbogue 14 hours agorootparentI will admit that Llama3.1 70B does make my old Thinkpad pretty cranky. But winter is coming, so if I can change the climate of my bedroom while I'm waiting that's always a bonus this time of year. reply bugbuddy 15 hours agoprevAt $2 per hour, factoring in the overall hardware cost, labor, electricity, and other sunk costs like floor space and bandwidth, how many total hours does it take to break even? What is the expected hardware operation lifespan in hours of this system? How much would the hardware cost have to drop for the economic of $2/hour to work? reply hislaziness 15 hours agoparentThe details are in the article. They have done the math. reply bugbuddy 14 hours agorootparentThere was no answer to my last question which I think is the most important thing when considering if we are going to have another GFC this year or next year. reply rsynnott 6 hours agorootparentDoes \"GFC\" stand for \"global financial crisis\" here? It seems implausible that the collapse of the LLM bubble will cause one; it might have a pretty dramatic impact on the markets, but it's unclear how it would cause the sort of systemic failure that we saw in the noughties. reply latchkey 11 hours agoparentprev> What is the expected hardware operation lifespan in hours of this system? Better question: what support contract does the provider have with their manufacturers? For example, we buy Dell pro support 3 year next business day contracts on all of our gear. reply pico_creator 12 hours agoparentprevYou could technically break even at $2, assuming 100% allocation, and cheap electricity. But reality is not 100%, so I would argue at-least 25% or even 50% drop in the H100 price (approx 50k each, after factoring other overheads) reply frhack 11 hours agoprev [–] Artificial Intelligence will replace many jobs and business. So the race is on to become the main AI providers of the future. For the big players this is an opportunity and a necessity. The question is: - how long will this race last? - how long will NVIDIA be the main GPU provider and beneficiary of this race? Predicting the future is very difficult, especially in an unprecedented revolution like this. As Nobel Prize winner Parisi said: \"No matter how hard you try to predict the future, the future will surprise you\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The GPU market has experienced a significant price drop, with H100 GPUs decreasing from $8/hr to under $2/hr due to oversupply and changing demand dynamics.- Factors contributing to this shift include reserved compute resales, open model fine-tuning, and a reduction in new foundation model companies, making renting GPUs more favorable than purchasing.- The emergence of open-weight models and more affordable alternatives, such as AMD and Intel GPUs, is influencing the market, with a growing emphasis on AI inference and fine-tuning, supported by platforms like Featherless.AI offering cost-effective AI solutions."
    ],
    "commentSummary": [
      "The GPU rental market has experienced a dramatic price drop for H100 GPUs, from $8/hr to $2/hr, due to an oversupply and decreased demand from new foundation model companies.",
      "This price reduction has burst the GPU rental bubble, affecting investors who heavily invested in GPU infrastructure.",
      "The article explores the potential for a more accessible AI landscape with cheaper compute options, though the long-term sustainability of these low prices and the future of AI infrastructure are uncertain."
    ],
    "points": 351,
    "commentCount": 241,
    "retryCount": 0,
    "time": 1728613182
  },
  {
    "id": 41805706,
    "title": "Tesla Robotaxi",
    "originLink": "https://www.tesla.com/we-robot",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=41805706",
    "commentBody": "Tesla Robotaxi (tesla.com)251 points by iamwil 15 hours agohidepastfavorite649 comments Animats 13 hours agoIt's amusing that this was at the Warner back lot, which is out in Burbank. Not Paramount or Universal, which are both in Hollywood. It would have been embarrassing to do this at Paramount or Universal, because those are in Waymo's service area. People would have arrived at the event in real self driving taxis. reply milleramp 12 hours agoparentAll of Warner is \"out in Burbank\" as is most of what is normally considered Hollywood. reply Animats 12 hours agorootparentYes, Disney is also in Burbank. reply rapsey 13 hours agoparentprevnext [64 more] Waymos however need thousands of dollars of hardware to achieve this and only work in limited areas. Tesla's bet is a lot more risky but also with a lot more potential. reply fshbbdssbbgdd 12 hours agorootparentThe idea that Tesla would win the robotaxi race by not needing LiDAR died sometime between when LiDAR cost $100k and when it cost $1k. Now it’s just Elon being intransigent. reply aaronblohowiak 11 hours agorootparentcan I get a lidar for 1k like the cars use? reply threeseed 10 hours agorootparentThere is no reliable FSD implementation on any car right now so it's kind of an irrelevant question. The more relevant one is what will happen first. Tesla figuring out how to make vision only work on their existing hardware. Or the price of LiDAR coming down. reply p_l 9 hours agorootparentOn-chip lidars are coming to automotive sector currently reply fragmede 11 hours agorootparentprevYou're going to have to be more specific with your necessary specs, there are $100 360° hobbyist LIDAR sensors on Amazon. reply IshKebab 10 hours agorootparentNo there aren't. Those use triangulation. LIDAR is time-of-flight. They also only scan a single rotating point which is only sufficient for simple robots like vacuum cleaners. reply jauntywundrkind 9 hours agorootparentIntel's L515 lidar from 2020 wasthe number of things that can potentially happen is far greater than the number of training examples we could ever produce Models don't need to have been trained on every single possibility - it's possible for them to generalize and interpolate/extrapolate. But, even knowing that it's theoretically possible to drive at human-level with only the senses humans have, it does seem like it makes it unnecessarily difficult to limit the vehicle to just that. Forces solving hard tasks at/near 100% human-level, opposed to reaching 70% then making up for the shortcoming with extra information that humans don't have. reply fauigerzigerk 5 hours agorootparent>Models don't need to have been trained on every single possibility - it's possible for them to generalize and interpolate/extrapolate. They do have some in-distribution generalisation capabilities, but human intentions are not a generalisation of visual information. reply Ukv 5 hours agorootparent\"human intentions are not a generalisation of visual information\" is a bit confusing category-wise. Question would be to what extent you can predict someone's next action, like running out to retrieve a ball, given just what a human driver can sense. Clearly that's possible to some extent, and in theory it should be possible for some system receiving the same inputs to reach human-level performance on the task, but it seems very challenging given the imposed constraints. Also, for clarity, note that the limitations don't require the model be trained only on driver-view data. It may be that reasoning capability is better learned through text pretraining for instance. reply p_j_w 35 minutes agorootparentprevHumans use our brains to drive. Unless you're planning on popping an actual human brain or something that can perform equivalently into the car, you'd do well to consider more superior sensor suites. reply pelorat 7 hours agorootparentprevHumans eyes are an order of magnitude better than the cameras in a Tesla. Humans also have a database in their head and remembers how to behave in certain situations. FSD doesn't have any database of any kind. reply garyfirestorm 11 hours agorootparentprevHumans don’t have radar, or thermal cameras, or ultrasonic sensors, doesn’t mean planes and boats shouldn’t use those reply svantana 11 hours agorootparentprevThat same argument can be used for all companies to fire all their employees. They are all human after all. Just implement all the needed features in hardware and software, done. reply threeseed 10 hours agorootparentprevHumans continuously move their heads in three dimensions to infer depth. Cars can't do this. And not surprisingly the biggest problem with FSD is the accuracy of its bounding boxes. reply e_y_ 30 minutes agorootparentCitation? Humans are not constantly moving their heads to the degree that chickens do, and I find it doubtful that the micro movements from our head (which our eyes have to adjust for with the vestibulo-ocular reflex so things aren't blurry, similar to image stabilization in cameras) are large enough to infer depth. reply trhway 11 hours agorootparentprevBirds have to flap wings while our planes don't have to. There is absolutely no reason to limit self-driving cars in the same way our bodies are limited. When it comes to AI though, humans are using biological neural net much more capable than any today's AI you can cram into a car. So, even if one accepts your premise of targeting human performance as a design guideline, more sensors is still logical at this point as way to compensate for the weaker AI. Also, if you read how Tesla does vision it is very different from, and i think inferior to, how your eyes and brain build the 3d map of the surroundings. If one is limiting oneself to only vision, the first thing would be to try to get as good as possible that 3d mapping, and the vision seems to be among the simplest and most researched brain functions, ie. easiest to reproduce. As Tesla doesn't seem to be doing it - only may be couple years ago they only started to elicit the 3d model - i think they aren't on the shortest path to success when it comes to FSD. reply meow_catrix 11 hours agorootparentPlanes do ”flap their wings”, just not the ones protruding from the fuselage. reply trhway 11 hours agorootparentI think you're mistaking rotating for flapping. Rotation is one of those fundamental things differentiating our technological civilization from Nature. reply andsoitis 5 hours agorootparent> Rotation is one of those fundamental things differentiating our technological civilization from Nature. Rotation is very common in nature. Planetary rotation, inner-core rotation, spinning galaxies, dung beetle rolling, Keratinocyte migration, Rotifers, spirals, rotational symmetry, etc. What isn’t common (but not non-existent) is using rotation for locomotion in biology. reply eesmith 7 hours agorootparentprevBacterial flagellum rotate. See also https://en.wikipedia.org/wiki/Rotating_locomotion_in_living_... . reply BoorishBears 11 hours agorootparentprevI can't tell if this is satire, or if replicating 6 million years of evolution has legitimately become handwave material for Elon's supporters... reply InDubioProRubio 10 hours agorootparentThey are afraid, times of crisis - especially planetary one, have the weaker minded and scared ones always rally around figureheads. Some guy in operetta uniforms, exclaiming \"Im the captain, give me all your cash\" brandishing a detached steering wheel is what the passengers want to see. Reality be a lovecraftian horror to much to bear. reply consp 11 hours agorootparentprevMammalian vision and vision itself have been around a lot longer than 6 million years by at least one, likely two, orders of magnitude. reply ben_w 11 hours agorootparentprevI don't know if you've tried this recently, but take a photo of something on your phone and put it into an AI. There may even be an AI built into your photo library app. reply BoorishBears 9 hours agorootparentThe fact I work on self-driving cars makes me a tiny bit more of a realist than someone who thinks CLIP is proof of what AI can and can't do... reply danjl 1 hour agorootparentI'm curious. Can you elaborate on what CLIP proves about what AI can and can't do? reply ben_w 8 hours agorootparentprevSo your job is to, in your own words, be \"replicating 6 million years of evolution\"? You know how big your own team is, and that your team is itself an abstraction from the outside world. You know you get the shortcuts of being able to look at what nature does and engineer it rather than simply copy without understanding. You know your own evolutionary algorithms, assuming you're using them at all, run as fast as you can evaluate the fitness function, and that that is much faster than the same cycle with human, or even mammalian, generational gaps. > CLIP is proof of what AI can and can't do CLIP says nothing about what AI can't do, but it definitely says what AI can do. It's a minimum, not a maximum. reply falcor84 11 hours agorootparentprevs/feasible/possible/ reply IshKebab 10 hours agorootparentprevYou mean \"very much theoretically possible\". reply fragmede 11 hours agorootparentprevfeasible? I want the thing to drive better than me, especially in the rain, fog, and the dark! reply gniv 11 hours agorootparentprevThink of pile-ups. No matter how good a driver you are there are situations where you cannot prevent crashing. But lidar can. reply mlindner 10 hours agorootparentPray tell how a Lidar prevents crashing in this situation? reply actionfromafar 8 hours agorootparentAccurately determine distance to objects in almost no time. While a human has 1 second reaction time. There will be situations a fast reaction time alone can save. reply slac 13 hours agorootparentprevI strongly believe that once you have everything working it's much easier to start working on the costs. reply i2infinity 12 hours agorootparentprevI wouldn’t step into a Tesla robotaxi in bad weather, period. They’d absolutely need a human remotely operating it. Without a steering wheel, passengers can’t take control even if they wanted to. Even in good weather, I’d be genuinely surprised if Teslas, in their current form, could drive around autonomously. I was really hoping Musk would mention new sensors being added for extra safety, maybe spinning it as: “Your Model 3 doesn’t need additional sensors, but just to be safe, we’re adding new ones.” reply bryanrasmussen 11 hours agorootparentcan multiple operators from India operate the robotaxis or does it need one on one operation? I mean consider the savings! reply i2infinity 4 minutes agorootparentJust ranting here - The psychological disconnect between a remote operator and passengers in a robotaxi needs more research though. Remote operator might have less empathy and responsibility towards passengers possibly causing moral disengagement. The remote driver might never face the real-world aftermath of their actions, which can reduce their sense of remorse or responsibility. There could be complex legal dilemmas too (especially if operator is from a different country) But this has definitely been researched a lot in the field of military drone operators who can make life altering decisions from thousands of miles away. reply karel-3d 11 hours agorootparentprevThe latency will kill you. Both figuratively and literally. Maybe something like Mexico would be better. reply varjag 11 hours agorootparentLatency? That's when Starlink comes into play! reply bryanrasmussen 10 hours agorootparentprev>The latency will kill you. I mean - I wasn't thinking I would risk it!! reply davedx 12 hours agorootparentprevMy Tesla still beeps at me because it thinks I'm about to drive into pedestrians or parked cars because there's a bend in the road. I honestly think at this point Tesla's FSD AI is way, way overfitting on a few US cities. reply kalleboo 9 hours agorootparentIt's way overfitting on the routes that the CEO and a few YouTubers drive. https://electrek.co/2024/07/09/tesla-insiders-say-elon-optim... reply jajko 10 hours agorootparentprevWell my 10 year old BMW F11 does it too sometimes, it really is a stupid primitive technology with tons of badly handled corner cases. Luckily its not obnoxious and I got used to it quickly so ignoring it. But in critical situations it can take away a bit of focus which is pretty bad. Of course can't be turned off. Nobody expected 15 year old design from BMW to perform better I guess. From modern up-to-date teslas who don't even have steering wheel but lidar is a no-no because his ego? I can't imagine it getting approved in Europe, ever. Which is fine, there will be tons of competition for this in few years. reply danso 2 hours agorootparentprevBut Teslas vehicles can’t operate ANYWHERE autonomously — not even with supervision inside the closed loop tunnels in Las Vegas [0] — 6+ years after Musk said autopilot/FSD was capable of driving itself coast to coast. Whenever Teslas manage to offer autonomous driving, what makes you think LIDAR etc will still cost what it does now? [0] https://www.reviewjournal.com/news/news-columns/road-warrior... reply seanmcdirmid 13 hours agorootparentprevThis is definitely the big bet Tesla is making. However, the hardware Waymo uses will also become cheaper over time and with scale, so either bet has advantages and disadvantages. reply petters 12 hours agorootparentprevI think “thousands of dollars” in hardware is fine reply ulfw 13 hours agorootparentprevWaymos exist. This intro of nothing doesn't. It's much much easier to make an existing thing cheaper and better over time. reply rapsey 12 hours agorootparentWaymos drive in limited geofenced zones. FSD exists but needs driver supervision. Both are incomplete and it is unknown who will be the winner. reply Yoric 11 hours agorootparentBut isn't it the case that Waymos are actually usable (for this purpose), while FSD/RoboTaxi isn't? Geofencing sounds like a good idea to me. It's a mean to roll things out carefully, while minimizing risk of death. If actual FSD/Robotaxi is ever released, I suspect that they'll need to geofence, too, for a while. reply altacc 11 hours agorootparentprevFSD is also geofenced, just a bigger fence. When/if the robotaxi actually debuts it too will be heavily geofenced and have usage restrictions but it will also be several years behind Waymo in terms of development, testing, technology and regulation. Whilst it is unknown who will be the winner, or even valid competitors, we can predict with high confidence that Tesla has a massive challenge to reach where Waymo is today. reply hackernewds 12 hours agorootparentprevThe geofence can extend. Drivers are harder to replace. reply haliskerbas 2 hours agorootparentHave been seeing both the LA and SF Waymo operating zones increase steadily. Also seen Waymo's being driven manually outside of those ranges presumably for further development. reply imtringued 12 hours agorootparentprevThe people living in the \"geofenced\" areas don't care about how \"incomplete\" it is. The point of a self driving taxi is that you don't have to own the vehicle. reply vidarh 11 hours agorootparentAnd this is a vast difference. You can expand a self-driving taxi service by running an Uber-like service and dispatching w/safety-drivers for journeys taking you out of the area, and its functionally equivalent - people are buying the mobility, not the self-driving. You get to start rolling out without solving the whole problem. reply prmoustache 10 hours agorootparentprevIsn't any Tesla costing thousands of dollars anyway? reply imtringued 12 hours agorootparentprevHow does it have more potential? I don't know how much taxi drivers earn in the US but let's pick a random number like 50k USD per year. If Waymo hardware costs $10k but Tesla costs $2k, then the savings are $40k for Waymo in the first year and $48k for Tesla. That is a 20% increase in the worst case for Waymo and the longer the vehicle lasts or the higher the taxi driver salary, the worse it gets for Tesla. Their potential is heavily bounded and gets worse over time. reply hackernewds 12 hours agorootparentNot to mention, Tesla might not be able to do it at all. Plus a driver that makes magnitudes less mistakes, is punctual, doesn't sue, doesn't rest, or is a liability is worth much more than $50k. The human component though we could argue whether humans are meant to be driving cars full time putting themselves and others at human error risk reply hyfgfh 13 hours agorootparentprevPotential lawsuits reply specialist 5 hours agorootparentprevTesla's autobots are free? Waymo & Hyundai announced a partnership. IIRC Waymo has always intended to work with OEMs, vs make their own vehicles. https://seekingalpha.com/news/4156375-hyundai-motor-joins-fo... Having no opinions about the IONIQ 5, I've gleaned that it's well regarded. Maybe not a Model Y, but close enough. Of all the legacy OEMs, Hyundai has a fair chance of surviving the Tesla (& BYD) juggernaut. So I think Waymo chose wisely. reply tim333 1 hour agoprevI must say the show seemed a bit lame and the market seems to agree - TSLA down 8% at present. The robotaxis did 5 mph on cleared streets and so seemed much less impressive than Waymos which can deal with real pedestrians and do 30 mph+ They only had two seats which is not how you'd make a commercial robotaxi and so probably just made for show to try to impress investors. The robots serving drinks etc seem to have been remotely controlled by humans. It's not that impressive when Waymo are driving people around in real life and also various robotaxis in China eg. https://youtu.be/izLfWY4c0Ko I've always defended Musk saying robotaxis will be here in a year or two over the last decade because new tech is hard but they now look a bit in danger of being left behind by the competition. reply binoct 13 hours agoprevThey claim that unsupervised autonomy in existing cars will arrive in California and Texas next year (with an easy bogieman that it will depend on regulatory approval), but no details as to what exactly this would mean. It’s possible that they might be able to get an Level 3 product out similar to offerings by the likes of Daimler, Cadillac, and Ford - where on certain highways under certain conditions you don’t have to pay much attention but still must be available to take over relatively quickly if the conditions change. That seems the most likely route, although all other systems I believe rely on vision+radar or vision+lidar fusion. Those approaches have a lot more broad industry experience and quantifiable benefits in safety, but it’s possible Tesla has compelling data on the performance of its vision system, especially during daylight hours. I’m honestly not sure how they could ship what they are implying - basically FSD as it is today but without anyone in the driver’s seat. That would imply they are (nearly) comfortable with it driving 10’s to 100’s of millions of miles between fatal accidents without any intervention. Either that or they are willing to ship and know it’s less safe than an average driver. That’s ignoring non-fatal accident rates. There are some middle ground options where UFSD would have a larger set of conditions it can operate “unsupervised”, say in good weather and possibly daytime, and maybe only on some types of roads. But the edge cases where it transitions out of those conditions can be brutal and not easy to address. It’s relatively easy to say “just pull over and make the driver take over”, but especially on highways or heavy traffic that can take a while. reply Animats 12 hours agoparent> (with an easy boogieman that it will depend on regulatory approval) Right. Tesla has avoided getting the California DMV's autonomous driving licenses. They have a \"learner's permit\" for testing with a safety driver. California DMV's regulations for self-driving vehicles mirror those for drivers. There's the \"learner's permit\", (with safety driver), which has much the same restrictions as a human learner's permit. There's the autonomous testing permit, which is comparable to a regular (class C) driver's license - you can drive yourself and your employees, but not for hire and not large trucks. Then there's the deployment license, which allows charging money and is hard to get. Mercedes, Nuro, and Waymo have one. Cruise used to have one, but DMV revoked it after a fatal crash. Tesla reported zero autonomous miles driven on California roads in 2023.[1] They're not even trying. Tesla has long been scared of the reporting requirements. All disconnects have to be logged, miles driven have to be logged, and all accidents, however minor, have to be reported. Everybody else in the real self driving industry, from Apple to Zoox, does this. The ones with bad numbers grumble about it sometimes. Waymo doesn't. [1] https://www.dmv.ca.gov/portal/vehicle-industry-services/auto... reply wilg 13 hours agoparentprevFord and Cadillac have Level 2 systems, not Level 3. Tesla also has Level 2, but it is significantly more capable. (I don't think any of the others work on city streets at all, or even change lanes automatically based on navigation.) Mercedes is so limited to just technically qualify for Level 3 that it could be likely be trivially outmatched by some limited FSD conditions if that's the route Tesla wanted to go. But yeah I assume you start with some limited Level 3 subset, probably highway, then extend it to city streets. Then just start working your way through validating new conditions. reply binoct 13 hours agorootparentFair call out that bluecruise and supercruise are not actually L3 reply oblio 11 hours agorootparentprevhttps://www.arenaev.com/mercedesbenz_drive_pilot_now_works_a... reply wilg 10 hours agorootparent? this demonstrates the limitations of drive pilot. and its describe a feature that is not out until 2025. current limitations are 40mph on a straight line highway, no lane changes, navigation, etc reply oblio 8 hours agorootparentMercedes, unlike every other automaker, including Tesla, *takes over legal liability* in those circumstances. They're putting their money where Musk's mouth is. And next year it will go up to 85kmph, close to highway speeds. reply wilg 3 hours agorootparentThey’re taking legal liability when you are driving a straight line on selected freeways going less than 40mph and with a car in front of you to follow during the day. This doesn’t demonstrate advanced capability, just limited scope. reply danso 2 hours agorootparentTesla’s system is purportedly far more advanced — do you believe that they could offer the same safety promises and legal protection for that limited scope if they wanted to? (leaving aside for the moment, why they wouldn’t want to) reply wilg 1 hour agorootparentI’m not sure, I think it’s technically feasable given the current state, I expect that scope has pretty good safety numbers on current software, since it’s such a narrow scope. But they would probably want to do all kinds of extra training and validation and fine tuning on it first rather than just blast out the current version. reply flutas 6 hours agorootparentprevNo they aren't. If you look at their wording, they are saying they are ready to defend themselves and their software, not that they will protect anyone from a lawsuit. The owners manual even explicitly states you are always the operator under drive pilot. reply enragedcacti 4 hours agorootparent> The owners manual even explicitly states you are always the operator under drive pilot. Just a straight up lie. The manual states: > The person in the driver's seat when DRIVE PILOT is activated is designated as the fallback-ready user and should be ready to take over control of the vehicle. > As soon as the driver steers, accelerates or brakes, the responsibility for driving and safe operation of the vehicle, including compliance with traffic regulations, will be returned to the driver. reply marsten 13 hours agoprevThe most interesting thing to me by far was the lack of a steering wheel on the Robocab. Without manual controls, vague promises (\"puffery\"?) about autonomy won't drive vehicle sales as they do today across all Tesla's models. The Robocab as shown literally cannot function (or make a dime of revenue) until they've fully solved autonomy and have convinced regulators of the same. reply davedx 12 hours agoparentThat's not entirely true. Waymo have remote control operators, these would have the same - you don't need 100% foolproof autonomy to operate a fleet of cars like this. I am also highly sceptical of everything about Tesla's program though reply nipponese 11 hours agorootparentYou're going to buy a personal car that can be remoted into at any time? reply luma 10 hours agorootparentThese are robotaxis, not personal cars. reply pelorat 7 hours agorootparentNo, the idea is that these are personal vehicles that are not operated by Tesla, but owned by regular people who gets to keep most of the profit they make driving strangers around. Tesla has zero intentions of operating a fleet of autonomous vehicles on their own. reply fragmede 7 hours agorootparentTo the public, sure, but I'm sure their employees need a way to get around. reply nipponese 4 hours agorootparentprevHe stated that they would be for sale to individuals. reply SmartJerry 1 hour agoparentprevAutonomy is solved. It will have hiccups/mistakes, but fewer than a human driver makes. The lack of steering wheel is solved by having support drivers who can work it remotely when the passenger presses a 'help' button or similar. reply notsylver 2 minutes agorootparentSolved, just not by Tesla who have been promising it every year since.. 2016? reply modeless 13 hours agoparentprevIt's not going to be in mass production until 2027 at the earliest, realistically. Will they have unsupervised FSD \"next year\" as claimed? I doubt it. But by 2027? I think there's a strong possibility. I've been testing FSD since it was released and lately the pace of improvement has gotten a lot faster. And the Cybercab is going to have a much faster onboard computer, and probably more/better cameras. reply m463 13 hours agorootparentI got to try fsd (supervised) recently, and although it wasn't perfect, it was pretty good. I also had to learn to to enable adaptive driving (or whatever it is called) to let the car go slightly over the speed limit and go with the flow of traffic, otherwise it would only go the speed limit and people would rage-pass. reply perbu 12 hours agorootparentI suspect if it works well 99% of the time, which is pretty good, they're about half way to their goals. Making it work well 99.9999% is probably a lot harder. reply cinntaile 12 hours agorootparentprevIf they were that close, why did Karpathy leave 2 years ago? reply modeless 12 hours agorootparentYou'd have to ask him. He worked there for 5 years, maybe he just wanted a change instead of a second 5 years of sprinting to the goal? In interviews he says he is still bullish on Tesla. reply haspok 11 hours agorootparentOf course he is bullish on Tesla, probably still has some stocks or stock options. Otherwise saying that he is bullish costs nothing to him. And \"wanted a change\" my *ss. If you believe the hype that autonomous driving is really just around the corner (has been since 2015) AND you are leading the R&D of the company that does this, would you want to jump ship before the product is shipped? Do you think Jobs would have left Apple in 2006, just before the Iphone announcement because \"he wanted change\"? If you do, I have a bridge to sell you. reply cinntaile 12 hours agorootparentprevThere is no reason for him to burn bridges so being bullish doesn't really mean much imo. It sounds like what any socially capable person would say. To me it feels like the traditional auto manufacturers are catching up to Tesla and now they need the next hype to stay ahead of the game. It keeps the stock price high. I am aware this is not a new goal though. I very much doubt it's within reach by 2027. I'm happy to be proven wrong though, driving a car is a bit tedious imo. reply modeless 11 hours agorootparentCheck the video here. https://youtu.be/hM_h0UA7upI?si=Tt9HqQoxceXKHmiI&t=140 He's not just politely saying he likes Tesla, he's talking for 5 minutes in detail about exactly why he believes Tesla is ahead of Waymo and will beat them to scale. reply vessenes 10 hours agorootparentprevNo idea. But, as always, I consider how hard working at Tesla is, and what percent of the total economic value of working at Tesla Karpathy had acquired at the time he left. You don't need to imagine anything other than \"cool, I'm good, see you guys around\" for such a decision to make sense. We saw a bunch of execs leave shortly after Tesla presold 500k Model 3s. Super sensible -- they were vested most likely, and other industry execs could be retained for the herculean lift that getting scaled up for the M3 was going to be. Why kill yourself? And from Tesla's point of view, why overpay in the market for those guys? You can hire someone from Audi (which they did) for much less on the back of the successful pre-order. reply 14 12 hours agorootparentprevIt is interesting that you are confident in that matter. But you have been playing with it for a long time. Someone like myself with zero experience with it am very skeptical about how much I can trust it. We have seen several accidents over the years in the news. How do we convince the masses that this car is safe and this car will not suddenly drive off the road? I do think self driving cars are as a whole a lot safer but I also consider myself a good driver so it would be hard to give up that control. When I would be sold on the tech is when it is so good I am legally allowed to sit back and sleep between destinations. Wake up in a new city each day. reply vessenes 10 hours agorootparentI've had FSD (as branded by Tesla) for probably five years; it's gone from \"actively trying to kill you constantly\" to \"very, very, good\" to \"probably safer than my teenager (who is a good driver)\". I banned my current youngest driver from using the old version, but encourage use of the latest version for night driving -- it's really excellent. In most circumstances, it's probably a better driver than me. That said, my kid told me last night in the rain with some cars slowing, it tried to pull left into oncoming traffic, and needed a quick recovery. We seem to be at stuff like that every thousand or so miles, down from every mile five years ago. it is WAY WAY WAY ahead of any other car I've driven or ridden in that can be bought. I understand Waymo in SF is significantly better. But, compared to Rivian, Ford, Volvo, Mercedes, it's years ahead. reply FireBeyond 44 minutes agorootparent> and needed a quick recovery. We seem to be at stuff like that every thousand or so miles, down from every mile five years ago. it is WAY WAY WAY ahead of any other car I've driven or ridden in that can be bought. That's orders of magnitudes better than other FSD users. Independent testing of over 1,000 miles through Southern California required 77 interventions, at an average of once every 13 miles. I suspect your \"one intervention every one thousand miles\" might be a little optimistic. reply modeless 12 hours agorootparentprevThere are more than enough on the road already to know exactly how safe they are. FSD has already driven a billion miles. Once it is good enough they will have the statistics to prove it. reply Topfi 10 hours agorootparentTesla has, as far as I can tell looking through the reports, done not a single mile or kilometer under the Californian DMV Autonomous Vehicle Tester (AVT) Program[0]. Nor have they partaken in any other program of this kind that would enforce public reporting or any measure of transparency. There is no public data to gauge safety or reliability as of yet. [0] https://www.dmv.ca.gov/portal/vehicle-industry-services/auto... reply modeless 10 hours agorootparentYou are right, there is no public data, they've kept it all private. FSD is not anywhere near good enough to be unsupervised right now so there's no real point to doing autonomous testing. I'm simply saying that when it improves to the point where it can be unsupervised, they will definitely have the data to prove it. reply Yoric 11 hours agorootparentprevIt's interesting, because FSD has probably driven a billion miles, but I couldn't find any useful statistics yet. So... I think it's a bit early to start believing the hype :) reply two_handfuls 4 hours agorootparentClosest we have is this: https://arstechnica.com/cars/2024/09/tesla-full-self-driving... reply Yoric 17 minutes agorootparentSadly, it's not the real statistics. Also, it's not really good. reply modeless 11 hours agorootparentprevIt is far from good enough today, no doubt. But the rate of improvement is what matters, and from personal experience I believe it is quite high. I do wish Tesla would release some better statistics. reply jillesvangurp 10 hours agoparentprevI'm guessing it will show up first on a lot of private roads. This thing would be perfect on airports, big events, etc. It will be interesting to see what kind of companies will buy this thing. I don't think they'll be selling these to consumers any time soon. The regulator thing is going to be a game of who will give in first and where. Once a few do, it might flip around quickly to regulators being more eager to not miss out. You see a little of that with Waymo where some cities would maybe like to get Waymo in their city sooner rather than later now that they are up and running in more glamorous places like LA and San Francisco. Unfortunately, waymo isn't able to rapidly roll out everywhere rapidly because they have to do a lot of work with mapping and testing in every place they roll out. Tesla might be able to move faster here once they get going and actually give some of these cities an alternative to waiting for Waymo to eventually show up. Of course the whole thing is getting a bit political as well with Elon Musk's backing of Trump. My guess would be that Texas is going to be first. Probably Austin, where Tesla and SpaceX are of course very present. I'm guessing Tesla has pretty warm relationships with the local politicians there. On the other hand, LA needs to look good during the next Olympics and Tesla did just host their Robotaxi event there. Some of those Robovans would probably be helpful in addressing some of the traffic headaches and sustainability goals with the Olympics. Paris just put a huge stake in the ground on that front so there is a fair bit of pressure. There's an opportunity there for Tesla. reply forgot-im-old 13 hours agoparentprevnext [13 more] [flagged] zizee 12 hours agorootparentThat Reddit thread reads like /UFOs, i.e. unhinged. Do you have a link to anything more reputable? reply forgot-im-old 12 hours agorootparentThis summary: https://www.reddit.com/r/WikiLeaks/comments/1fy10k1/comment/... I'm quite familiar with the topic if you have questions. reply nolok 12 hours agorootparentSo the answer is no, you do not have a reputable source. Neither comment on reddit nor one here are really valuable source when talking nuclear defense secret. As much as I dislike 99%of what Elon is and represent the past few years, that's doesn't mean we should loss critical thinking. reply forgot-im-old 12 hours agorootparentThe statements are hyperlinked to sources in the comments. You can read those. What in particular are you disputing? reply nolok 11 hours agorootparentThe source are talk and wish dreams and nothing more. Elon said a anti missile shield called SHIELD would be cool (nooo, Elon had another random idea from someone who doesn't know the field but has enough pr clout to make it published?), and Elon used to work or at least be in the same building as a general when he visits for a company that do space launch and is critical to US infrastructure needs (noo? you don't say ?) , and someone else said about shield against missile wouldn't be cool (noo?). That's nothing real or factual. reply forgot-im-old 11 hours agorootparentYou really don't know what you're talking about. That \"visiting 4 Star General\" now reports full time to Elon, as the WSJ determined via numerous sources. reply nolok 10 hours agorootparentAnd? Is he still a general while reporting full time to Elon? If yes you have a bigger scandal, active duty general report full time to private interests! If not then it's what happens when high level public official leaves office to go in the private space, of course he works for one of the connection he made. Unless you have proof that despite his leaving office he has an active decisionnary role on public and defense spending, then you're accusing someone juste because they work after leaving their previous job. reply forgot-im-old 10 hours agorootparentYou obviously didn't read the whole thing: https://www.reddit.com/r/WikiLeaks/comments/1fy10k1/comment/... reply nolok 3 hours agorootparentI did, my questions stand. reply m463 13 hours agorootparentprevAll that puffery is overestimated in the short term, and underestimated in the long term. reply ulfw 12 hours agorootparentNo it isn't. Where's that Roadster he promised 7.5 years ago? And that's an easier thing to do. https://jalopnik.com/its-still-very-funny-that-1-000-people-... reply m463 10 hours agorootparentouch, $250,000 of TSLA in nov 2017 would be worth just under $3M today. reply nikcub 15 hours agoprevHere's an idea - take the Robocab car design, strip out all the FSD/autopilot stuff, put in a steering wheel and dash and sell it starting at the end of the year for ~$25k. It would sell +++ reply modeless 11 hours agoparentIt has no rear window and wacky doors and only two seats. It would not sell. It's purpose built as an autonomous taxi, where those choices make perfect sense. They are also doing a $25k car, they just aren't revealing it today. reply nikcub 10 hours agorootparentThis is why I want a pragmatic operational industry expert CEO[0] for Tesla, in the same way Shotwell is for SpaceX. Announce and do the far stuff, but at the same time ship the near things that people want. A pragmatic auto CEO would have had that $25k car moving already. A pragmatic industry CEO also wouldn't have such a large event without a call-to-action. If they had a \"reserve now for Feb 2025 delivery\" button under todays announcement it would have gone offff [0] edit: ok Gwynne is COO - let Elon keep the title, but we know what matters. reply modeless 10 hours agorootparentI agree that Tesla's biggest mistake was doing Cybertruck before the $25k car. But if they solve autonomy and/or succeed with Optimus then everything else becomes irrelevant. reply nikcub 10 hours agorootparentI agree, but these are moonshot announcements that should sit isolated from the core business. The same thing that Google (ironically) did with X - which led to Waymo, which now already has autonomous taxis[0] You can't keep perpetually hyping tomorrow when the next Q is due. I have an affinity for Tesla since it's named after someone from a village my mums family is from (and who I'm named after), and I like environmentalist, decarbonise, and electrify Elon.. but sometimes he makes it hard. [0] on that note - not only have I seen better taxi demos than today, also seen better robot demos from Boston Dynamics. reply panick21_ 8 hours agorootparentThe question is how much does a Boston Dynamics robot full of complex hydrolics cost vs a Tesla bot that full of electric actuators. Boston Dynamics robots aren't really design to be produced in numbers and are designed for a different use-case. reply enragedcacti 6 hours agorootparentBoston Dynamics' humanoid robots thus far have been R&D platforms so the cost isn't all that important. That said, they released a quick teaser for the next gen of Atlas which seems to be all electric. https://www.youtube.com/watch?v=29ECwExc-_M reply modeless 9 hours agorootparentprevYeah Boston Dynamics is way better at locomotion, but their advantage in manipulation is smaller. You also won't see 50 at the same time like Optimus today. Tesla's advantage will be manufacturing. Optimus has improved quickly. Gen 3 should be better. They showed Gen 3 hands today that looked pretty good. reply nikcub 9 hours agorootparentI don't think Tesla have an advantage in manufacturing. China today is what Japan was in the 70s and their processes are so fucking good. You can't win on manufacturing - this is, after all, a nation that is now building Volvo's better than the Swedes did. Tesla fell into the China partnership trap, where the gov subsidises you and you open a \"partnership\" there, meanwhile they take your IP and knowledge for the benefit of the state (I was in that situation in '07 with Tencent and turned it down). Hence now $10k Chinese cars - and Biden introducing tariffs to protect local industry (including Tesla - which Elon doesn't seem to appreciate) On AI at Elon's recent recruitment event he put X.ai in Tier 1 with OpenAI and Anthropic and didn't even mention Meta. To me, as someone who applies these models across industries every day X.ai has never even come up. That tells me he isn't informed on what Meta are doing (and that is - undercutting the commercial AI industry). I'm hesitant to think it but there's a ton of hand waving and investor pumping happening here. Which is a shame, because a company with that market cap can do _a lot_ better. I wasn't impressed by a single thing I saw today. I've seen the same autonomous car demo in a closed environment at my own uni 25+ years ago. I've seen better robots from Boston. I've also seen much better presentations than someone who looked like they are reading the text for the first time. They have the capital, the mindshare, and the means and they're wasting it. reply modeless 2 hours agorootparentTesla's advantage over Boston Dynamics will be manufacturing. Over China, it will have to be innovation and software. China is going to be much harder to beat than Boston Dynamics for sure. But remember that Tesla is no stranger to competing with Chinese companies and they are doing OK vs BYD today and not just in the US, with the bestselling car model in the world and in China. I think the \"partnership trap\" was more relevant years ago; today China has a lot less need to steal tech, at least in the domain of car manufacturing (note that Tesla is not manufacturing Optimus in China). It's hardly new news that Elon is an awkward presenter and it isn't relevant to future performance of Tesla. You have to look at the pace of improvement of what Tesla is doing. Among humanoid companies that started in 2021 or later Tesla is the furthest along and improving much faster than the likes of Boston Dynamics. While they are still far behind, they have the time and the funding to catch up. The Cybercab demo was an amusement park ride (and Elon explicitly billed it as such), however Tesla's FSD is released to the public and can be directly evaluated. While it is not yet near Waymo it is impressively good as of this month and the rate of improvement is very fast now. It just drove me across town for 20 minutes and I didn't have to touch the steering wheel a single time. It was incapable of that on that specific drive just two months ago. And I have the less powerful older variant of the Autopilot computer. reply grecy 4 hours agorootparentprev> I agree that Tesla's biggest mistake was doing Cybertruck before the $25k car. While a $25k EV seems to be what we all want and is almost guaranteed to be a massive hit, there is no evidence such a thing can be done yet without losing money on every sale. Why isn’t any other car company doing it? Rivian are losing money on every car sold at 4 times the price. reply FireBeyond 41 minutes agorootparent> Why isn’t any other car company doing it? No other car company offers it, or promises it's coming next year, or ... Similarly, who actually believes a $39,000 CyberTruck will EVER appear? Crickets? reply panick21_ 8 hours agorootparentprevPeople really have gone off the deep end with Shotwell, yes she is awesome. But you know what makes it a huge amount easier to be awesome, having a reusable rocket to sell in the first place. Musk makes the primary choices at SpaceX, he decides the company strategy, he decides where the money goes, he decides what future projects to take on. If its so clear what a 'pragmatic auto CEO' would do, why do other car companies not have those cheap cars? And the data shows pretty clearly that 2 person cars, even cheap ones don't sell very well. reply 7thpower 6 hours agorootparentprevI thought they said they were scrapping the $25k car? reply modeless 2 hours agorootparentReuters said that, and Elon directly denied it. I think it is likely that the $25k car was delayed somewhat from whatever its initial plan was, but not canceled. reply ZeroGravitas 5 hours agorootparentprevThe rear window thing is also done by Polestar in one of their latest cars. I believe the reason was it adds strength that let's you have higher wider glass roof above passengers heads. And the rear view mirror replacement uses cameras. reply darth_avocado 14 hours agoparentprevThis. If you have a robotaxi for under 30k, why not just sell the car for that much? reply toomuchtodo 14 hours agorootparentTesla market cap is based on AI/robotaxi/FSD. Without that, they’re just playing catchup to BYD (who quietly, yet aggressively, executes at scale; they offer EVs today between $10k-$20k and already employ more workers than Toyota [for scale]). https://www.cnn.com/2024/04/03/cars/china-tesla-byd-competit... https://www.cnbc.com/2024/07/03/chinas-byd-is-set-to-beat-te... https://www.counterpointresearch.com/insights/bev-sales-10-m... reply thefourthchime 13 hours agorootparentI think you're ignoring the fact that Chinese manufacturers are heavily tariffed in the west reply toomuchtodo 13 hours agorootparentNot at all. Global light vehicle sales are ~90M units/year. US ~17M/year. EU ~13M/year. China remains a factory to the world (and itself is the leading market). BYD can build in Mexico (NAFTA) and the EU to avoid tariffs, if desired. Tariffs aren’t going to keep the EV printer at bay. They only delay the inevitable. https://electrek.co/2024/10/09/byd-to-sell-100000-evs-north-... https://electrek.co/2024/08/16/byd-plots-another-ev-plant-wh... https://electrek.co/2024/03/12/byd-triple-ev-market-share-eu... https://www.rystadenergy.com/news/china-ev-driving-seat-us-a... reply monocasa 13 hours agorootparentThe tariffs would most likely morph to disallow that. reply toomuchtodo 12 hours agorootparentI disagree this would be effective or a path to success. The evidence does not show policy moves faster than capital, and auto tariff policy gymnastics only work until foreign corporations open factories in country (as Toyota, Honda, Nissan, VW, BMW, Mercedes, Stellantis, and Hyundai all have done [US example]). US EV demand is simply not at the point where this is economically rational (imho), yet. And so, you’re stuck with a legacy auto EV, a Tesla, or a BYD with 100% tariff markup for now. Even with the tariff, the BYD is still cheaper than a Tesla. reply monocasa 12 hours agorootparentIt's not rational, but the current tariffs are explicitly aimed at Chinese EVs and were created faster than they could hit the US market in any sizable quantity even using China's existing manufacturing infrastructure. Policy in support of existing capital that is a heavy hitter politically can absolutely move faster than capital of new entrants. And with both political parties explicitly being anti-chinese capital currently, it's not clear that a chinese factory would even be allowed to open domestically. reply moralestapia 12 hours agorootparentprev>BYD can build in Mexico (NAFTA) and the EU to avoid tariffs, if desired. Not if Trump wins and I mean that without cynicism. reply rswail 12 hours agorootparentprevHeavily tariffed in the US, no tariffs in AU/NZ/Asia. EU is imposing tariffs depending on the manufacturer's co-operation with cost investigations. reply kmlx 11 hours agorootparentNo special tariffs in the UK also. reply ktosobcy 8 hours agorootparentprevYou are ignoring the fact that the world doesn't end with the USA (and EU)... Even in LatAm (which is \"west\") there is abundance of Chinese cars... In Africa it's probably even more visible... reply seanmcdirmid 12 hours agorootparentprevChina can easily get around that the same way they made western manufacturers get around its own tariffs. Only the Americans aren’t going to require 49/51 JVs, even though they should. reply eecc 12 hours agorootparentprevBYD are literally handmade. I expect QA issues worse that Tesla’s Production Hell and in long term support. Plus, they’re doped up with subsidies like an Eastern Block Olympic Athlete; China needs to prop up its books after the Real Estate bubble turned to rubble reply madaxe_again 11 hours agorootparentThey seem to have significant quality issues - I have multiple friends with them in Thailand, and every second social post from them is bitching about whatever randomly stopped working or fell off this time - although I have a feeling they build their Thai market models elsewhere. reply torginus 12 hours agorootparentprevThis is a bit of an aside, but why does everyone assume, if not for the sanctions, BYD would eat Western manufacturers alive? I for one, don't like to engage in anti-China hysteria, but having had experience with Chinese products, their quality and reliablity is a hit and miss. How would you know, that they didn't cheap out on caps in inverters, and they won't break down after a decade/200k km? Also their cars are build like modern consumer electronics, welded/glued together at every opportunity. Take a look at this video where a guy tries to pry apart a BYD battery pack: https://www.youtube.com/watch?v=HPTefsqNGI4 I guess BYD's strategy of world domination involves a high degree of automation, so they can make their cars in countries without a large pool of free workers/high wages, that's why they're made like this. And here in Europe, they're not even that much cheaper, before tariffs. A Seal costs almost as much as a Model 3. reply saturn8601 14 hours agorootparentprevHas he like ever met his promised price? If we go by almost every single other car he has released, The 30k robotaxi will be available for like 1 week on a stripped down tier (maybe like 25kwH battery?) or available off menu for like 6 months until it disappears and no one dares speak of it again. reply iknowstuff 13 hours agorootparenthttps://skills.ai/tesla-car-prices-analysis/ 37k model 3 for a good chunk of time, especially given the inflation since initial announcement, and given the amount of features in the base version which you'd have to pay out the ass with other OEMs, is actually very good. reply saturn8601 13 hours agorootparentEhh I disagree, the main competition like the Mazda 3 has still been very competitive price wise in that they also kept prices either low or lowered them further post COVID inflation and if you are comparing to the luxury brands then consider the fact that the car launched with a very stripped down interior compared to their competition and still remains that way while their competition have clearly continued to excel in this regard indicates that Tesla have hidden the inflation there. But the problem with comparing \"features\" is that tesla fanboys/haters get to assign arbitrary values to the features the cars have. It would be so much easier to just meet your promised price point. In that regard my point still stands. reply iknowstuff 12 hours agorootparentThe interior is minimalist, and ever since the model 3’s release, all other brands have been slowly trending in its direction. The 2024 model 3 interior is beautiful to the point that all the pointless plastic widgets present on other OEMs are kinda hilarious to look at. what makes you think the mazda 3 is the main competition? reply saturn8601 12 hours agorootparent>and ever since the model 3’s release, all other brands have been slowly trending in its direction. This is probably the most untrue statement you've made all evening and you have made plenty. >The 2024 model 3 interior is beautiful to the point that all the pointless plastic widgets present on other OEMs are kinda hilarious to look at. The market seems to disagree given that the gasoline competition is still the overwhelming majority of new sales. There are many reason for that but if this interior was so good they should have swept the market after 7 years of this cost cutti I mean minimalism? >what makes you think the mazda 3 is the main competition? The mazda 3 is a non luxury sedan that competes in that segment. You can substitute the corolla the civic or any of those cars on the non luxury side. If you instead consider the Tesla to be a competitor to luxury cars (which is difficult to argue again because you cannot compare feature to feature) then you'd obviously go with the german/japanese luxury brands(as I also mentioned but you ignored). Again going back to my point, Tesla has a history of never meeting their promised price point when they release their car. Not one model has ever hit their primosed price point. Not even the 12 year old Model S with its sub 50k price point. After 12 years of lies and false promises, there is no credibility that they will get to this magical 30k price point so it becomes moot when the market (which cannot afford their damn cars today gien their sales slump) will not be buying this contraption when it comes out years past its announced release window. reply iknowstuff 2 hours agorootparentyup it’s only the world’s best selling vehicle :) they have swept the market. indeed interiors of most other brands have morphed into a large screen instead of the 2010 circus of buttons. Model 3/Y is very competitive with premium german/japanese brands like bmw/audi etc. I don’t disagree their pricing goals are usually not really met unless given the discount of inflation. fyi EVs are 25% of the global car market and growing. reply madsmith 12 hours agorootparentprevI’m sure the 30k is below cost assuming Tesla makes some revenue on the taxi service over the lifetime of the vehicle. reply hackernewds 12 hours agorootparentprevBecause people lie. reply m463 13 hours agoparentpreva ROUND steering wheel and add turn signal stalks!! reply qwerpy 12 hours agorootparentThe squircle actually works pretty well in the CT! Agree about the turn signal stalks though. reply amluto 15 hours agoparentprevIt would need a NACS port. Otherwise it would be a rather expensive brick. reply bravetraveler 14 hours agorootparentToss in a spare tire, too. I care to do without! It's several thousand dollars. Signed, annoyed owner of a car with a fix-it-kit and a pat on the ass reply m463 13 hours agorootparentwithout a spare tire, every flat I've gotten is a giant unplanned waste of time (min was 4 hours) reply odysseus 12 hours agorootparentLast flat I had, there was a giant Allen wrench stuck in the tire and it was rapidly leaking. Filled it back up as much as I could with the included inflator kit, took it a big box store, they patched it up and was on my way. Took maybe an hour total out of my day? No $ cost to me (under tire warranty) reply m463 10 hours agorootparentTeslas don't come with an inflator. sigh. (and if you get one + slime stuff, you will kill the TPMS and have to buy a new one) reply iknowstuff 14 hours agorootparentprevI think it has one but techcrunch/verge bloggers heard inductive charging and leapt into assuming thats the only way to charge reply Veedrac 13 hours agorootparent\"The robotaxi has no plug\" — Elon Musk reply ClassyJacket 14 hours agorootparentprevIt must already have one. reply porphyra 14 hours agorootparentprevand a steering wheel i guess reply jsemrau 13 hours agoparentprevMake it a convertible. reply wilsonnb3 15 hours agoprevAnybody know why the autonomous taxi isn't just a model 3? I don't see the point in a purpose built two seater with no steering wheel or pedals and I don't know why regulators would approve an autonomous car with no way to manually override it. reply dv_dt 15 hours agoparentEspecially because every autonomous taxi fleet to date seems to have runs where they end up blocking roads and emergency vehicles. reply kshacker 13 hours agorootparentImagine if you could have one human operator able to go anywhere in the city for every 50 active cars ! Of course you can scale the number up and down based on actual needs. Kinda like Tesla AAA. Overhead will be less than having a driver per car and could be reasonable. reply echoangle 13 hours agorootparentHow long would it take for the single operator to reach a stuck car, worst case and average? I don’t know how it’s in the US but I’m pretty sure you could never get this certified in the EU, you can’t have your cars stuck and blocking traffic for 20 minutes before someone comes to get it unstuck. I think remote control would be much better for this. reply zizee 12 hours agorootparent\"You're trip is important to us, please hold and the next available operator will assist you as soon as possible.\" reply dv_dt 12 hours agorootparentprevImagine a hurricane knocks out mobile internet and every car in the fleet is offline, x% of all cars on road stop operating, or maybe they have some independence, but if they get stuck, are stuck immobile until comms are restored. I guess at least if they're small other vehicles can shove them out of the way. reply tim333 1 hour agoparentprevI'm guessing mostly for show. I they had a driving system that actually worked they could fit it on a car and try it in real life like Waymo. reply strulovich 15 hours agoparentprevBarring all the issues, if you did build a huge fleet of autonomous taxis - smaller, lighter cars with less moving pieces would save you a lot of money. 2 seater - smaller car No wheels or stuff - saves money on the build and parts. reply dmix 15 hours agorootparentThey are probably planning to reuse lots of parts from model 3 to save money And people are creatures of habit and highly social so version 1 of robotaxis will 100% look like normal cars. Regardless of whatever benefits you can come up with on paper. Once it's normalized then you experiment. reply saturn8601 14 hours agorootparentThis is the company that released the CyberTruck. V1 will probably look mostly like what was presented. Every single prototype they have ever unveiled eventually ended up looking very similar to the production model. reply justahuman74 13 hours agorootparentYikes, I had assumed it was the usual concept car BS until you mentioned the cybertruck reply rob74 11 hours agorootparentprevMark my words: the \"final form\" of robotaxis will seat 4 (up to 6 in a pinch) people on facing seats, will be able to drive in both directions and have all 4 wheels fully steerable for more flexibility. reply Iulioh 8 hours agorootparentThe 4 fully steerable wheels on robottaxis is an interesting ones. For human drivers were a little overkill with no real advange besides parking in small spaces) but they would be probably more usefull. But the fact that they are a little too complex remains, maybe making them semi standardized and modular would help reply ulfw 12 hours agorootparentprevOr god forbid you'd build a proper electric public transport network that can transport dozens, sometimes hundreds of people way more efficiently. reply rob74 11 hours agorootparentYou can see Musk's vision of that in Las Vegas: in tunnels (so it doesn't disturb \"regular\" motorists), but still using cars (what else?). reply ulfw 11 hours agorootparentCars driven by a human driver. He can't even to FSD in a 2.4 mile TUNNEL after years reply grecy 3 hours agorootparentA driver in the Vegas tunnel told me they self drive perfectly fine, it’s a regulation thing holding them back. It seems certain they’ll correct that with their massive expansion coming reply matthewfelgate 5 hours agorootparentprevI don't understand how they can't get autonomous working in a tunnel. It sounds like the perfect controlled environment. reply SmartJerry 1 hour agoparentprevBecause most Uber rides are 1-2 person and a car designed to be smaller is cheaper. reply Unroasted6154 13 hours agoparentprevThey said in the event that they will first deliver 3s and Ys. They just add a 2 seater and 20 seater van later to fill other use cases. reply gniv 10 hours agoparentprevBTW, Google tried this too (building a small 2-seater w/o controls). What happened to that project? https://www.youtube.com/watch?v=uCezICQNgJU reply yourabstraction 14 hours agoparentprevThey're going for lowest cost per mile. Most rides have 2 or less people, this will address that huge market in a very efficient way. reply nateglims 14 hours agorootparentWhy is that market not served by a 4 person self driving car? reply Unroasted6154 13 hours agorootparentThe mentionned the show that they will have autonomous versions of 3 and Y first. reply dev_tty01 13 hours agorootparentprevOr by a Waymo you can already use in a visit to SF? reply buzzerbetrayed 13 hours agorootparentBecause roads exist outside of SF and Waymo should have competition. reply cryptoegorophy 15 hours agoparentprevFirst reason - doors won’t close themselves. reply m463 13 hours agorootparentGood thought. The upward opening doors will also be able to open anywhere, and for anyone, even with canes or bags/luggage. reply wilsonnb3 15 hours agorootparentprevThat is true, although they could add that to a model 3. I wonder how Waymo deals with it. reply bagels 15 hours agorootparentYou close the door yourself, and open it yourself. I was horrified to discover this. reply cryptoegorophy 15 hours agorootparentWhat?? What if you don’t close it and just leave? I mean this will happen. reply agildehaus 14 hours agorootparentTheir cars currently produce an audible request to close the doors. In practice it doesn't happen often, I've never seen it happen in person. They also have support just minutes away usually. The Zeekr vehicle they're testing now, and presumably the Hyundai they're starting to develop, will have self-closing doors. reply jezzamon 4 hours agorootparentprevIt just sits there asking for help: https://x.com/WholeMarsBlog/status/1712009158210519474?s=19 reply bagels 15 hours agorootparentprevIn San Francisco? You're probably liable for all the property damage that happens next. I wasn't brave enough to find out. reply echoangle 13 hours agorootparentprevWell they know who booked the ride, so they will probably charge you for it or block you from riding again. reply sangnoir 11 hours agorootparentThey'd also have multi-camera high definition video and a LIDAR point cloud of the rider not closing the door and walking away. reply pcbro141 15 hours agorootparentprevYou just close the door when you exit the Waymo lol. reply Animats 14 hours agorootparentThe next generation of Waymo vehicles, based on the Hyundai Ioniq 5, will have powered doors.[1] [1] https://waymo.com/blog/2024/10/waymo-and-hyundai-enter-partn... reply saturn8601 14 hours agorootparentI've heard in the past that the OEMs don't want to be relegated to being just some whitebox manufacturer so many of them have been very cold (in receptiveness) to working with Waymo. Probably explains the terrible selection of vehicles they have used, Chrysler Pacifica minivan, Jaguar i-Pace, the ionic 5 was surprising since I suspected the others were just OEMs offloading their turds onto Waymo and telling them to take a hike. Maybe Hyundai is getting something good in exchange. reply conradev 14 hours agorootparentHuh? Hyundai has Tesla-tier automated factories that churn out EVs, and they’re building plants around the world. I don’t think they care who buys their cars. Tesla sold a bunch of cars to Hertz which turned out to be terrible for Hertz, but great for Tesla. reply saturn8601 13 hours agorootparent>Huh? Hyundai has Tesla-tier automated factories that churn out EVs, and they’re building plants around the world. I don’t think they care who buys their cars. They very much care if they are selling their cars to an entity that is striving to make them irrelevant. Think about it: If the world moves to a car sharing system where any type of car is available on demand and no one actually owns a car, do you think anyone will actually give one hoot about the badge on the front of the car? That puts manufacturers into the worst possible business model. Competing solely on price...ie a commodity. So the manufacturers will either not want to work with them, give them whatever junk they can't sell and then tell them to go away...or they expect to get something big in return maybe like some technology sharing or a exclusive partnership. Why else has Waymo partnered with the bottom of the barrel OEMs up to this point? Why not a Toyota or a Mercedes or hell even get the good cars from the OEMs they have partnered with? reply conradev 13 hours agorootparentWaymo partnered with Hyundai on the Ioniq 5 because Hyundai just rolled out the first Ioniq 5 from their Georgia “metaplant” literally yesterday. They’re one of the few companies mass-manufacturing affordable EVs in the US. Toyota doesn’t make many EVs and none in the US? Mercedes doesn’t make affordable cars in general? Waymo is clearly focused on cost reduction and EVs. Hyundai is clearly focused on selling as many Ioniq 5s in the US they possibly can (and most to consumers directly!). I don’t know, seems pretty clear cut to me. I also don’t see any future in which Waymo builds a metaplant? reply saturn8601 13 hours agorootparent>Waymo partnered with Hyundai on the Ioniq 5 because Hyundai just rolled out the first Ioniq 5 from their Georgia “metaplant” literally yesterday. What does one have to do with the other? The I-Pace was built in Austria. They dont seem to care about where it was built. >Toyota doesn’t make many EVs and none in the US? Mercedes doesn’t make affordable cars in general? The Chrysler Pacifica was a gas powered vehicle, The I-Pace had a starting MSRP of ~70k. They didn't seem to care about propulsion method or cost of vehicle either. What they do have in common is that they were both poorly selling cars made by manufacturers that were desperate to sell. >Waymo is clearly focused on cost reduction and EVs. Hyundai is clearly focused on selling as many Ioniq 5s in the US they possibly can (and most to consumers directly!). I don’t know, seems pretty clear cut to me. Any evidence to prove this assertion? Going back to my previous comment I mentioned that an OEM could want to partner with them if they got something meaningful out of the deal. Seems like thats what Hyundai is getting: Waymo Tech transfer/possibly an exclusivity agreement. >I also don’t see any future in which Waymo builds a metaplant? I never said or implied that they would. reply conradev 13 hours agorootparentHyundai #2 to Tesla: https://www.businesskorea.co.kr/news/articleView.html?idxno=... Waymo optimizing for cost: https://waymo.com/blog/2024/08/meet-the-6th-generation-waymo... reply saturn8601 12 hours agorootparentYou ignored the rest of my response which is again driving the point: What does Hyundai really get out of this? Circling back to my point, this does not really explain why they are partnering with Waymo. Waymo is a rounding error in sales for Hyundai. If Waymo was solely focused on cost, then they should have stuck with the pacifica which is cheaper or gotten something even cheaper like a Toyota. It makes no sense to go with Hyundai which is not even the cheapest for the features that it offers(compared to id 4, Niro EV, Hell even Kona EV). It is a smaller car compared to the Pacifica and the i-Pace and is far less equipped in terms of comfort and space. We dont even know if they specifically wanted to go with an EV. Thats just something you just asserted without evidence. reply conradev 12 hours agorootparentWaymo has touted that their entire fleet is now electric: https://waymo.com/blog/2023/03/paving-way-toward-fully-elect... It sure seems like their self-imposed constraint is EVs. Their goal beyond that is cost reduction. It seems like the actual key right now might be volume: “The team at our new manufacturing facility is ready to allocate a significant number of vehicles for the Waymo One fleet as it continues to expand. Importantly, this is the first step in the partnership between the two companies and we are actively exploring additional opportunities for collaboration.” https://waymo.com/blog/2024/10/waymo-and-hyundai-enter-partn... but to your point, Hyundai may see this as an opportunity for “future collaboration” to get autonomous driving tech into their vehicles. But selling a “significant number of vehicles” is also very much in Hyundai’s interest. If Hyundai was making the Niro or Kona EV in the US, then they may have been an option, but they’re not. They are not eligible for the tax credit. Toyota won’t make EVs here until 2025 or 2026. The ID.4 would meet that criteria, though, and I wonder if Waymo considered going with Volkswagen. reply saturn8601 12 hours agorootparentUh that article is clearly a PR puff piece timed to coincide with the retirement of the Pacifica fleet which is nearing 5-6 years of service at that point. Again given their strange choices in the past and their backpedaling on previous initiatives (having Chrysler produce special Pacificas and then going back to retrofitting them by hand themselves, going from commiting to purchasing 65k pacificas to NOT purchasing 65K Pacificas, getting Magna to go a custom design of the iPace for them to not having them do a custom design) I dont see this as a deal that Hyundai got into without major concessions. >The ID.4 would meet that criteria, though, and I wonder if Waymo considered going with Volkswagen. If my theory is correct I suspect they are not getting a warm reception from many manufacturers and they have to pick whatever they can get. I'd imagine their ideal company is Toyota. They have experience with those cars from the early days, they make cars that can help minimize downtime due to their reliability and costs can be reduced. There is a reason so many taxis are prisues. Why not apply that common sense cost savings to Waymo's fleet? reply porphyra 15 hours agorootparentprevThe Waymo car has a speaker that tells you to close the door lol. reply echoangle 13 hours agorootparentIf Tesla pivots to this later, fans will be like „The best part is no part, that’s so genius!“ reply thefourthchime 13 hours agorootparentprevWhy is this a requirement? reply bdjsiqoocwk 12 hours agoparentprev> Anybody know why the autonomous taxi isn't just a model 3? It's so Enron Musk can say it's still 2 years away. reply mplewis 14 hours agoparentprevBecause all the work of allegedly building a new vehicle platform is a better excuse for making no profit on the robotaxi initiative for the next ten years. reply sandspar 14 hours agorootparentWhat's the deal with cynical, low effort comments like this that add nothing to the discussion? There's obviously more to the story than what you're saying. HackerNews is supposed to be for discussion, not Reddit-tier snark. Comments like yours are just visual pollution. reply rsynnott 5 hours agorootparentI mean, you've got to look at the context. This isn't happening in a vacuum; they've been promising this any minute now for the last eight years. At a certain point, the benefit of the doubt becomes strained, and every ostensible delay starts to look like a delaying tactic. reply stackghost 13 hours agorootparentprev>What's the deal with cynical, low effort comments like this that add nothing to the discussion? People are starting to wake up to the (shitty) new reality that Big Tech created for us. The cynical nature is just the natural reaction to a serial grifter becoming the world's richest man. I don't think anyone but the most naive actually believes anything in this PR piece will come to market. reply mavhc 12 hours agorootparentOh yeah, look at all the terrible things Tesla has done, sell more EVs than everyone else, and make them for less cost, and include a good infotainment system in a car, what a terrible reality reply older 12 hours agorootparentTesla doesn't sell more EVs than everyone else, BYD does. reply mavhc 3 hours agorootparentTesla has sold about 6.5 million cars at least. BYD sold 131k in 2020, 321k in 2021, 911k in 2022, 1.6million in 2023, and in 2024 q1: 300k q2: 444k q3: 443k, total: 4.15 million reply stackghost 12 hours agorootparentprevThe future I was promised was utopian, and instead my appliances all play ads and spy on me, and the robber barons at the top of the heap will use their billions that they got selling my personal data to advertising scum to leave legacy trusts that will continue to erode the fabric of society and increase wealth disparity long after said billionaires are dead and buried. But sure, your Tesla has a good infotainment system so that's cool. reply mavhc 4 hours agorootparentWhich Tesla car plays ads? reply stackghost 47 minutes agorootparentWhich CEO is leaning into far-right conspiracy theories and using Twitter to boost the electoral chances of the most dangerous US presidential candidate in history? reply mavhc 42 minutes agorootparentThe Twitter that's barely used by anyone and thus isn't important? Surely they should be using facebook, that's already proven to be great at helping with genocides reply steveoscaro 12 hours agorootparentprevYeah this place feels like Reddit right now. Hivemind takes left and right. reply vessenes 10 hours agorootparentYes. Sadly, it's always been this way. Look up the response posts to Dropbox, Ethereum, .. Every few years I'm like \"I think it's gotten worse\" and then I'm like \"I'm going to spin up some sentiment analysis to prove it's gotten worse\" and then I read some old posts and I'm like \"I miss jacquesm, but nah it's pretty much the same.\" And then I think \"this is still the best forum on the internet.\" reply bravetraveler 3 hours agorootparentprevLook at your post. Hivemind is an easy way to handwave common sentiment, perhaps even perception. This meta-commentary can be insightful. Yet. reply whamlastxmas 15 hours agoparentprevI assume robo taxi will be significantly cheaper to manufacture. You can get away with much less range and creature comforts being quite a bit less. People care much less about comfortable for something they sit in for twenty minutes versus buy for $50k reply jjulius 15 hours agorootparentCreature comforts, fine, they can go, but a shorter range? I thought the idea was for me to be able to have my car galavanting around the city all day being a taxi for people to help me make money. Forgive my ignorance, but how is a shorter range going to help with that? reply dmix 15 hours agorootparentI guess it depends on the initial regulatory environment. But most likely it's not any cheaper. He said in the video it's cheaper through the economics of reuse, not through it being cheap itself reply whamlastxmas 14 hours agorootparentprevYou don’t need 350 mile range for city errands and if for some reason you did, they can just coordinate vehicle swap that takes 30 seconds reply m463 12 hours agorootparentprevI would imagine the interior would be more \"passenger proof\". Maybe easier to clean, or wash out vomit, or even warn of forgotten items. reply avalys 14 hours agorootparentprevHuh? You will spend exactly as much time in the Robotaxi as you do in a vehicle you buy for yourself. If people are willing to pay extra for comfort and style already, why would they stop? I feel like so much of this discourse is dominated by people who hate cars. Most people like their cars! That's why they bought them. reply wilsonnb3 15 hours agorootparentprevYeah I would be interested in seeing how the costs shake out. There is logic in this design being cheaper to manufacture but I would think that it would be a long while before you \"broke even\", so to speak, compared to using a design that you already know exactly how to make. reply panick21_ 8 hours agoparentprevMany reasons. Model 3 is to big. The Model 3 is missing many features needed, like inductive charging, automatic doors. And has lots of things not needed, like a steering wheel column. Model 3 is build on a much older architecture, even the upgraded versions. Model 3 still uses traditional car wiring. With all the changes you would have to do to M3, its basically a new car. This Robotaxi will have all the drive-by-wire architecture of the Cybertruck. The new electronics architecture and Ethernet bus. And things like wireless charging. reply jaarse 13 hours agoparentprevBecause that isn’t different or new enough to get investors excited. The point of this presentation was not to spell out technically how they are going to accomplish this. Agreed, a fleet of model 3s would work great. The point of this presentation was to look like a cool visionary tech company that is going to change the world, to justify that your Market cap is now larger than EVERY OTHER MAJOR AUTOMAKER COMBINED! Same reason the prototypes need to look like they were lifted from Blade Runner. reply dplgk 9 hours agorootparentSo a pump and dump? reply TrainedMonkey 15 hours agoparentprevI have no first hand knowledge here, but thinking from first principles. From Robotaxi fleet perspective you want autonomous maintenance, cleaning, charging, and lowest cost. From Robotaxi user perspective you want climate / music / entertaiment / safety. So the idea for robot taxi is that it should be better than model 3 in some or all of those dimensions. Now speculating for the moment, from Elon perspective you probably want things to be more cyberpunky as that is how future looked in his childhood and he is trying to build it. Also, engineers / designers were likely mandated to handle all of the maintenance and possibly production by Tesla Bots. reply yourabstraction 14 hours agorootparentYes, I think you're spot on. They showed a video of a robot arm cleaning the car's inside, and it appears the vertical opening doors make that kind of access easier. The car will also have wireless charging, which makes that easier to automate as well. reply y1n0 14 hours agorootparentprevFrom what “first principles” are you thinking? reply TrainedMonkey 9 hours agorootparentAs a rough draft I went with: 1. What is important for a vehicle optimized for large scale robotaxi fleet from manufacturing and operational perspectives. 2. What is important for me if I get an into autonomous vehicle. reply j7ake 14 hours agorootparentprevAutonomous cleaning? Good luck vacuuming all the nooks and crannies in a car. reply BluSyn 14 hours agorootparentThey literally showed a clip of a robot cleaning the car in the announcement. Also perfect task for Optimus. reply kombookcha 13 hours agorootparentI straight up do not believe that Optimus is capable of vacuuming a car unassisted without damaging itself, the car or the hoover. reply grecy 2 hours agorootparentLike any robot on a vehicle assembly line, it’s going to be trivial to get it to follow a pre programmed path. All the cars it has to clean are identical…. So actually it will be simple. reply m463 12 hours agorootparentprevwhat if the robot can exchange it's arm for a vacuum? sort of Kentucky Fried Movie style :) reply kombookcha 12 hours agorootparentChainsaw arm ala Evil Dead and I'm back on board. Groovy ;) reply Zanfa 12 hours agoprevGiven current Tesla FSD drives like a drunk teenager even in good conditions, I don't see how this is anything but a scam. It's the perpetual \"Teslas will be able to fully self-drive in 2 years\". reply redwood 11 hours agoparentNot my experience driving FSD in silicon valley. I was floored reply Zanfa 8 hours agorootparentI obviously don't know your personal experience, but with the amount of videos from Tesla owners showcasing FSD turning into oncoming traffic, trying to clip parked cars, blazing through stop signs without even slowing down and taking roundabouts the wrong way around in 30 minutes and then finishing the video by concluding that FSD did well is insane. Just the amount of scary FSD footage from Cybertrucks alone that only got FSD a few weeks ago is massive. reply DennisL123 13 hours agoprevClassic bait and switch setup. Selling people the future in 2 years time with little to nothing to show for today. Timelines will slip, plans will change, software won‘t be ready, prices will change. And that doesn’t even account for where Waymo is in two years from now, or what the Chinese EV industry is able to pull off until then. Even this underwhelming event was originally announced on short notice to prop up perception when sales looked bad in April [1], delayed by two‘ish months, and then didn‘t even start on time. Oh, and implementing the robo taxi was a two-months project back then [1]. It‘s a ruse, folks. [1] https://fortune.com/2024/07/16/elon-musk-tesla-robotaxi-dela... reply wg0 10 hours agoparentElon has almost no credibility left for what he says. It's basically just a website at the moment with bunch of 3D renders which you too could get done from a web shop. Tesla has nothing new to offer and competition is catching up, EV adoption slowing down and such. If I had, I would gradually drop Tesla stock because it's going to go downhill if not rock bottom from here. reply mrich 10 hours agorootparentTesla at a forward P/E of 80 is massively overvalued as a car company. You can get Mercedes or BMW at a P/E of 6, with a 9% yield. Sure, the EV market is still growing, but Tesla is not the only player. All brands now have EVs, there are both cheaper and more luxurious Chinese EVs, that's some massive competition. The only reasons Tesla could be valued differently are FSD and Robotics, which Musk and Tesla-friendly analysts are heavily pushing. Since Musk has made massive loans against his Tesla stake you can expect that he will keep highlighting those narratives as well. A revaluation of the stock to sane levels would certainly cause him some financial difficulties. reply tim333 3 hours agorootparent>The only reasons Tesla could be valued differently are FSD and Robotics Maybe a bit of that but investors are more buying into Musk's past track record with Tesla and SpaceX which has been pretty good really. reply forgot-im-old 10 hours agorootparentprevInvestors with security clearances know the full force of the U.S. government backs him (or at least did under Trump) https://www.reddit.com/r/WikiLeaks/comments/1fy10k1/comment/... reply bravetraveler 8 hours agorootparentAnyone with eyes can see him cozying up to public funding/Uncle Sam reply red-iron-pine 3 hours agorootparentdebatable given how much he's been cozying up to the Russians and Saudis betcha in 10 years time we'll learn about all of the ITAR violations and other shady behavior reply forgot-im-old 2 hours agorootparentThat's typical smoke screening when your'e working with the CIA as the link implies Don't have to wait 10 years if you read the WikiLeaks above. reply jrflowers 45 minutes agorootparentWait is the “Wikileaks” here the Reddit post or is the “Wikileaks” the couple of links to public news sites? reply bravetraveler 3 hours agorootparentprevYoung money comes from old money, yes reply acchow 10 hours agorootparentprev> It's basically just a website at the moment with bunch of 3D renders which you too could get done from a web shop. They had 2 dozen vehicles with no steering wheels taking attendees around the venue. The bar was staffed by Optimus robots. “Basically a website”? reply benterix 9 hours agorootparent> They had 2 dozen vehicles with no steering wheels taking attendees around the venue. To quote a participant[0]: > After over 10 years of Full Self-Driving development, @Tesla is limited to a 20-30 acre geofenced 5mph ride on a preprogrammed, premapped and heavily rehearsed route with no traffic and no pedestrians. [0] https://x.com/realdanodowd/status/1844605093368512799 reply twobitshifter 56 minutes agorootparentI saw pedestrians walking in front of the cars in the live stream. The rest is true though. It reminded me of taking the classic car ride around an amusement park where the cars all follow each other on a track. reply valianteffort 9 hours agorootparentprevThere are countless videos on youtube of people recording their experience with FSD's open beta. It is probably 90% of the way there, if not more. Anyone who thinks Tesla won't get there first is peak delusional. Hate on Elon as much as you want, but Tesla are top-tier engineering. Real funny seeing a bunch of web devs on HN talk shit about Tesla's engineers too lmao reply pelorat 7 hours agorootparentThat 90% is about as good as a teenager taking his first practice drive with a parent (meaning an extreme road hazard). reply sshine 4 hours agorootparent> about as good as a teenager a suicidal teenager reply trissi1996 9 hours agorootparentprevEven if you'd be right about the 90%, I highly doubt they'll be first. How long did it take to get to that 90% ? AFAIK they first mentioned FSD ~2016(Self-driving itself even earlier). As the last 20% of work are often 80% of the effort we can estimate that those remaining 10 % take ~ 40% of the time. They've been at it for ~8 years , which gives an expected release of ~ 2029. We'll see what Waymo and other competition has until then. reply bellgrove 5 hours agorootparentprevI feel like there’s some software adage about the last 10% being the hardest. It certainly holds true from my experience - even if they are 90% of the way there, it’s not a linear path to 100%. reply tocs3 4 hours agorootparent90% done, 90% left to go. reply darepublic 2 hours agorootparentprevso the 90% is really meaningless in that case.. it's what we judge to be 90% which is erroneous. reply tliltocatl 8 hours agorootparentprevThere are 90% and then there are 90% more. reply eesmith 7 hours agorootparentA.K.A the Rule of Credibility: \"The first 90 percent of the code accounts for the first 90 percent of the development time. The remaining 10 percent of the code accounts for the other 90 percent of the development time.\" - https://en.wikipedia.org/wiki/Ninety%E2%80%93ninety_rule Followed by Hofstadter's law: \"It always takes longer than you expect, even when you take into account Hofstadter's Law.\" - https://en.wikipedia.org/wiki/Hofstadter%27s_law reply kevinventullo 3 hours agorootparentprevI live in Los Angeles, and Tesla will not get here first because Waymo has already arrived. reply benterix 9 hours agorootparentprev> Real funny seeing a bunch of web devs on HN talk shit about Tesla's engineers too lmao It's not \"talk shit about Tesla's engineers\", it's just a very hard problem to solve. It's easy to get it \"most of the time\" but extremely difficult to finish it. It's obvious it will take decades, not years to get us there. Whereas Musk insists he will solve it \"this year\", every year from 2014. reply golol 3 hours agorootparentprevTesla has the world's best autonomous vehicle offering by some way of measuring things. There are many ways to measure things, but at least in some \"category\" they are indeed leading: Level 2 systems for the US which you can privately buy. reply danjl 1 hour agorootparentMercedes already has a level 3 available for purchase in California: https://www.mbusa.com/en/owners/manuals/drive-pilot reply golol 16 minutes agorootparentYes which can not do a bunch of things that FSD can. reply horns4lyfe 6 hours agorootparentprevUS competition with Tesla isn’t even close and the only way anyone has able to get a functional charging network up and running was to piggyback off of Tesla. I know the Trump stuff is annoying, but there’s way too much criticism of Tesla out there that is our political emotion. reply ryandvm 5 hours agorootparentTrump is Tesla's only hope. Elon knows Trump is a transactional person and as long as he supports Trump, he can get the necessary governmental treatment his companies need to survive (tax credits, Chinese EV tariffs, some sort of asinine Mars mission). reply mensetmanusman 4 hours agorootparentEV tariffs are going to happen throughout the entire west with or without Trump. Western governments have discovered the Chinese plan to decimate western manufacturing by subsidizing it at over 10 X the rate required and seen in the west. Vehicles matter because they are a means for war machine production. reply lokar 2 hours agorootparentHe needs more than that. Both Mercedes and BMW are eating into high end Tesla sales. reply lowkey 10 hours agorootparentprev- I believe he can launch rockets into space and land them on their own footprint. - I believe he can revolutionize auto manufacturing and disrupt a 100 year old industry replacing fossil-fuel burning dinosaurs with clean electric vehicles that outperform them and that appeal to the general public - I believe he can allow quadrapelegics to interact with the world in ways never thought possible - I believe he can, to a great degree, restore free speech on social media even if it is messy and imperfect at times - I believe that innovation is hard and just because he boldly claims he is going to Mars or make cars drive themselves - and hasn’t done it yet, is no reason to discount the possibility that he might actually pull it off one day reply porbelm 10 hours agorootparentHE can do nothing of the sort because he is an idiot with very few real skills. Even his code in the pre-PayPal days was amateurish. What he has done is throw money at people who can. But now he has started micromanaging things because he believes he knows best. He is a total buffoon. reply ben_w 9 hours agorootparent> HE can do nothing of the sort because he is an idiot with very few real skills. Management is a real skill. Salesmanship is also a real skill. I may not approve of the showboating, but drumming up enthusiasm for a future that most consider to be fantasy, was a necessary (though not sufficient) part of building an electric car company in an era when most people thought hydrogen was the future and that \"electric car\" meant \"a milk float\" and, if they had memories of any real personal electric vehicle, those memories would have been of the failure of the Sinclair C5: https://en.wikipedia.org/wiki/Milk_float https://en.wikipedia.org/wiki/Sinclair_C5 reply dsr_ 7 hours agorootparentPretty sure nobody except Toyota thought hydrogen was going to be a useful intermediate fuel: handling is ridiculously difficult compared to room-temperature liquids, energy density is ridiculously low. It would have made more sense to sell Fischer-Tropsch synthesized carbon fuel from purpose-grown crops, at a mere 3x the current production price of fossil carbon fuels, using the existing infrastructure for distribution into existing vehicles. reply nytesky 2 hours agorootparentI wonder if Honda and Toyota are still backing on a carbon neutral fuel replacement. They have been slow to electrify. reply twobitshifter 50 minutes agorootparentprevI don’t like the guy but he’s built companies that are implanting brain chips to give people vision and parapalegics the ability to interact in the world, has blanketed the globe in true high speed internet, have built spaceships that launch more frequently than any nation has ever done their own. And then there’s the EV thing which many see as key to fighting climate change. If he wasn’t so unlikable and part of this twitter debacle, the world would be praising each of these efforts. reply panick21_ 9 hours agorootparentprevSame old nonsense story. > What he has done is throw money at people who can. Funny then that countless other space and car startups had far more money and were far less successful. And many of those were far less micromanaged. BlueOrigin for example literally got 100x as much money from its owner as SpaceX did. > But now he has started micromanaging things because he believes he knows best. This is just factually inaccurate, he has been micromanaging since the beginning. Literally everything ever said about him was that. Look we get it, you don't like him as a person, but these statement just make you seem dumb and uninformed. reply noch 8 hours agorootparent> Same old nonsense story. Most of the passionate (embittered? salty? flavourless?) critiques of Elon always sound like a confession: His critics can't explain why he is successful, why his companies are successful, nor why he is wealthy. When they attempt an explanation, it's less an explanation and more a dismissal: luck, other people, teams, theft, subsidies, corruption, \"the system is broken!\", a technoaccelerationist cabal secretly pulling the levers of power. But, fundamentally, the question whose answer eludes the majority of humans especially Elon's critics is: Why am I not as wealthy and relevant as Elon yet I'm obviously smarter and more ethical than he is? (Their implicit answer is that \"life is unfair and doesn't reward the best people.\") Because if any of his critics actually had a meaningful critique that corresponds to reality, they would simply build better products and companies, become billionaires themselves and exemplify rather than pontificate about a better mode of billionaire behaviour and grandeur of vision. reply kibwen 6 hours agorootparentI wonder if Musk fans realize that constantly deflecting all criticism with \"you're just jealous, bro\" says more about them than about the people they're limply trying to discredit. reply noch 5 hours agorootparent> I wonder if Musk fans realize that constantly deflecting all criticism with \"you're just jealous, bro\" says more about them than about the people they're limply trying to discredit. I wonder if the critics of Musk's \"fans\" realize that deflecting all criticism with \"they're just Musk fans, bro\" says more about their own anemic ability to imagine the legitimacy of another perspective, their utter lack of humility and complete poverty of intellectual honesty, than about the so-called fans they're flaccidly trying to discredit? reply 7thpower 6 hours agorootparentprev>> Even his code in pre-PayPal days was amateurish. ..Okay? Calling Elon Musk an ’idiot’ in a non-ironic way tells us you’re not being objective and contributing to a rational discussion. reply mensetmanusman 4 hours agorootparentEDS is real. reply ETH_start 9 hours agorootparentprevIf you can't recognize his contributions I think you're too emotionally attached to the question. reply Fricken 6 hours agorootparentAny day now a Tesla Semi truck will stop by to deliver my solar shingles. I can then use them to charge my Tesla robotaxi. My Robotaxi will ferry people around when I'm not using it and pay for itself in under 2 years. Then I can start saving for my ticket to Mars, where I'll be safe from the woke mind virus that is consuming everyone here on earth. reply tim333 3 hours agorootparentI don't think the argument is that everything he touches turns to gold. Transforming two industries and going from in debt to the planet's richest is an achievement in itself. reply horns4lyfe 6 hours agorootparentprevYou’d prefer the rich just throw their money at political back room deals or speculative finance? At least he’s spending money to build cool things. reply forgot-im-old 10 hours agorootparentprevHe's a conduit between DARPA and good engineers, don't attribute it all to him. Someone else would fill his shoes if needed. https://www.reddit.com/r/WikiLeaks/comments/1fy10k1/comment/... reply ben_w 9 hours agorootparentNobody else did, though. That's the reason he was able to get this rich with SpaceX and not stall sooner — most of the other space companies were (and in the west, still are) busy scratching backs rather than developing successful products. reply mensetmanusman 4 hours agorootparentprevSomeone like Boeing. The administrative class has taken over and they have zero risk appetite. Nothing new will come of them. reply horns4lyfe 6 hours agorootparentprevYou honestly believe that DARPA would have given us the Tesla model Y? reply red-iron-pine 3 hours agorootparentDARPA doesn't give us anything, it just runs with ideas and develops them enough to push to others to build and run. ARPA gave us TCP/IP, but MS, Google, telcos, etc. gave us the modern internet and the tools to use it reply fragmede 6 hours agorootparentprevIt's possible that Tesla, which Musk didn't found, would have given us an EV by another name. Rivan also got us an electric truck before the cybertruck came out. Fisker's not doing so well though. reply ben_w 9 hours agorootparentprevMostly I agree, modulo \"he knows how to make teams to do XYZ\", which I'm happy to count for the same reason I'm happy to blame him personally when those teams he's ordering around do something I don't like: > I believe he can, to a great degree, restore free speech on social media even if it is messy and imperfect at times I strongly disagree with this. Even if I ignore the proxy of all the investors writing off their buy-out loans by 75%, even if I ignore that when people link me to random threads I can only see the specific one linked and not any reply because of an invisible paywall^w account-wall, even if I ignore that loading a random tweet now often takes 26 seconds or more (yes, I did just record my screen to get that number), even if I ignore that undesirable stories can be buried by an avalanche of alternative narratives and not just by censoring the truth… There's still the problem of Musk intervening politically in ways that, although totally legal, are exactly the kind of thing he was complaining about before the takeover: https://en.wikipedia.org/wiki/Twitter_suspensions reply specialist 6 hours agorootparentYes and: I'd like someone, eg Musk, to define \"free speech\". Start with some of those \"first principles\" he likes so much. Then, per \"theory vs reality\" cliché, I'd like someone, eg Musk, to explain or demonstrate or larp or interpretative dance what \"free speech\" looks like in practice. Maybe even point to an existing example. For bonus credit: - explain relationship between \"free speech\" and news feeds (algorithmic hate machines) - explain operation of \"free speech\" multinationally - explain how to balance \"free speech\" and moderation - enumerate the tradeoffs of, downsides due to, and consequences of \"free speech\" reply dom96 10 hours agorootparentprevYou’re a fool tricked by another fool who shouts loudly that they support free speech while they ban speech left and right. For goodness sake, ElonJet was banned and you can’t even say the word “cisgender” on the platform. How delusional are you? reply pavlov 9 hours agorootparentAlso Musk has banned mentions of his own transgender daughter, who now posts on Meta’s Threads app instead. X is like a textbook case of why total autocracy isn’t actually good management practice. Musk has become the Henry VIII of social media. reply horns4lyfe 6 hours agorootparentprevI prefer that to the CIA having a direct line to the top of the platform and free reign to use it for propaganda, yes. reply ETH_start 9 hours agorootparentprevElonJet was a live geotracking site for private jets. You can post cisgender, it just comes with a warning. Before, people were being banned for using \"him\" instead of \"her\" to describe biological males who self-identified as women. People were secretly de-amplified for criticizing the government policy of lockdowns. It was censorship on a whole different magnitude. reply dom96 8 hours agorootparentSo your response is “it was worse in the past”? Two wrongs don’t make a right. Either you’re a “free speech absol",
    "originSummary": [],
    "commentSummary": [
      "Tesla recently showcased its Robotaxi, emphasizing a vision for autonomous taxis that contrasts with Waymo's approach, which uses costly hardware like LiDAR.- The Robotaxi's design, which lacks a steering wheel, indicates a future dependent on full autonomy, though it faces regulatory and technological challenges.- Tesla's Full Self-Driving (FSD) technology is a topic of debate, with critics questioning its readiness for unsupervised driving and supporters optimistic about its potential."
    ],
    "points": 251,
    "commentCount": 649,
    "retryCount": 0,
    "time": 1728617065
  },
  {
    "id": 41809698,
    "title": "Begin disabling installed extensions still using Manifest V2 in Chrome stable",
    "originLink": "https://developer.chrome.com/docs/extensions/develop/migrate/mv2-deprecation-timeline",
    "originBody": "Home Docs Chrome Extensions AI Manifest V2 support timeline Stay organized with collections Save and categorize content based on your preferences. Understand when Manifest V2 will stop working for extensions Latest October 9th 2024: an update on Manifest V2 phase-out. Over the last few months, we have continued with the Manifest V2 phase-out. Currently the chrome://extensions page displays a warning banner for all users of Manifest V2 extensions. Additionally, we have started disabling Manifest V2 extensions on pre-stable channels. We will now begin disabling installed extensions still using Manifest V2 in Chrome stable. This change will be slowly rolled out over the following weeks. Users will be directed to the Chrome Web Store, where they will be recommended Manifest V3 alternatives for their disabled extension. For a short time, users will still be able to turn their Manifest V2 extensions back on. Enterprises using the ExtensionManifestV2Availability policy will be exempt from any browser changes until June 2025. See our May 2024 blog for more context. June 3rd 2024: the Manifest V2 phase-out begins. Starting on June 3rd on the Chrome Beta, Dev and Canary channels, if users still have Manifest V2 extensions installed, some will start to see a warning banner when visiting their extension management page - chrome://extensions - informing them that some (Manifest V2) extensions they have installed will soon no longer be supported. At the same time, extensions with the Featured badge that are still using Manifest V2 will lose their badge. Upcoming June 2025: Chrome MV2 deprecation enterprise rollout Enterprises using the ExtensionManifestV2Availability policy to ensure the continued functioning of Manifest V2 extensions in their organization will have one additional year - until June 2025 - to migrate the Manifest V2 extensions in their organization. Browsers with the policy enabled won't be impacted by the rollout of the deprecation until that time. Past June 2022: Chrome Web Store - no new private extensions Chrome Web Store stopped accepting new Manifest V2 extensions with visibility set to \"Private\". January 2022: Chrome Web Store - no new public / unlisted extensions Chrome Web Store stopped accepting new Manifest V2 extensions with visibility set to \"Public\" or \"Unlisted\". The ability to change Manifest V2 extensions from \"Private\" to \"Public\" or \"Unlisted\" was removed.",
    "commentLink": "https://news.ycombinator.com/item?id=41809698",
    "commentBody": "\"Begin disabling installed extensions still using Manifest V2 in Chrome stable\" (chrome.com)198 points by freedomben 4 hours agohidepastfavorite194 comments dang 15 minutes agoRecent and related: Chrome Canary just killed uBlock Origin and other Manifest V2 extensions - https://news.ycombinator.com/item?id=41757178 - Oct 2024 (46 comments) That one never made the frontpage, so I'm leaving the current thread up. reply freedomben 4 hours agoprevNotably, Firefox is not removing v2 support (at least for now as of March 2024) > Firefox, however, has no plans to deprecate MV2 and will continue to support MV2 extensions for the foreseeable future. And even if we re-evaluate this decision at some point down the road, we anticipate providing a notice of at least 12 months for developers to adjust accordingly and not feel rushed.[1] [1]: https://blog.mozilla.org/addons/2024/03/13/manifest-v3-manif... reply EasyMark 3 hours agoparentTo my knowledge the “big” chrome engine alternatives aren’t either. I know that Vivaldi and Brave plan on keeping around v2 as long as it is economically feasible reply echoangle 27 minutes agorootparentThis sounds like Android phone manufacturers making fun of apple for removing the headphone jack and then doing it themselves a year later. Are they seriously going to maintain V2 support for a relatively small percentage of Powerusers which probably are mostly already using Firefox anyways? The point of being economically infeasible is probably in a month or so. reply luuurker 11 minutes agorootparentprevAren't these v2 extensions being removed from Chrome's store? If so, are the alternatives based on Chromium running their own store? reply zamalek 26 minutes agorootparentprevThough it is less of an issue for those two, given that they have built-in adblocking. Still a laudable effort. reply creesch 12 minutes agorootparentWhile adblocking has gotten most of the focus, it isn't the only functionality that is being limited or made more complicated. One of my favorite extensions is still not available for MV3 because of complications: https://github.com/openstyles/stylus/issues/1430 reply sunshowers 12 minutes agorootparentprevAt least when I last tested, Vivaldi on Android's adblocking is pretty far behind uBlock Origin -- it doesn't get nearly as many anti-adblock interstitials as it should. reply simcop2387 3 hours agoparentprevAlong with that, I'd hope they'll add needed support for proper adblocking even with v3 and beyond reply TiredOfLife 26 minutes agoparentprevBut they are removing adblock extensions that use v3 reply sunaookami 22 minutes agorootparentNo they removed uBO Lite due to a misunderstanding/mistake and gorhill choose to not bother with Mozilla's annoying \"review\" process. reply emaro 4 hours agoprevFor people that have somehow missed the story, manifest v3 removed support for certain powerful network apis, severly limiting ad-blockers capabilities. uBlock Origin will not work anymore without manifest v2 (there's a v3 compatible lite version of uBlock Origin). reply btown 3 hours agoparentIt's worth noting that the maintenance of the \"lite\" version is at some nonzero risk of burnout for its developers, ironically in part due to Mozilla being unnecessarily hostile: https://github.com/uBlockOrigin/uBOL-home/issues/197#issueco... discussed at https://news.ycombinator.com/item?id=41707418 - and while there's no plan yet to discontinue the Chrome MV3 compatible version, there are a million ways that this could go wrong. My only long-term hope for this space is that a nonzero segment of congressional representatives have had ad blockers installed by their aides, realize that their experience online takes a nosedive when MV2 is discontinued, and calls for hearings! Blocking isn't just about not seeing ads, it's about a user's freedom to set up their \"user agent\" to preserve their privacy online from sites that don't respect their wishes. That's a right that Google is using its market power to erode, and it's not something we should take sitting down. More on MV3 from a few years ago: https://www.eff.org/deeplinks/2021/12/chrome-users-beware-ma... reply Kbelicius 17 minutes agorootparent> It's worth noting that the maintenance of the \"lite\" version is at some nonzero risk of burnout for its developers, ironically in part due to Mozilla being unnecessarily hostile: Why would you even use the lite version on firefox when the original works? reply jokoon 4 hours agoparentprevnext [9 more] I saw there is a manifest v3 ublock lite. I don't understand why and how it would be less capable, and so far I have not read the details of how/why. So far, it's just rumors to me. I will keep using firefox anyway, but honestly I am still waiting for a clearer explanation. reply sjnonweb 3 hours agorootparentWith manifest v2, the extension could dynamically intercept requests and block them based on a custom rule. With v3, extensions have to predefine the rules for blocking. Which is the limiting factor reply sho 3 hours agorootparent> extensions have to predefine the rules for blockin And there's a limit of 5000 such rules. reply nolist_policy 3 hours agorootparentThe limit is 330000 rules: \"Based on input from the extension community, we also increased the number of rulesets for declarativeNetRequest, allowing extensions to bundle up to 330,000 static rules and dynamically add a further 30,000.\" https://blog.chromium.org/2024/05/manifest-v2-phase-out-begi.... reply EasyMark 3 hours agorootparentGiven the size and complexity of modern ad malware I doubt if 330,000 rules is enough, so why limit it? reply lyu07282 3 hours agorootparentpreveven if it was infinite that wasn't really the issue, you can't express the algorithms uBlock Origin is using as a static list reply hypeatei 3 hours agorootparentprevThat and certain features like the element zapper in uBO aren't available in Lite. reply kristofferR 4 hours agorootparentprevYou can't just call stuff you simply don't bother to look up \"rumors\". Read up here: https://github.com/uBlockOrigin/uBOL-home/wiki/Frequently-as... reply byteknight 3 hours agorootparentprevSo because you don't understand it, its rumors? A Simple google search would answer all of your questions in a literal sentence. It removes APIs used by ad blockers. https://gprivate.com/6dp1q reply sho 4 hours agoprevHopefully this is the inflection point for Chrome. Despite all their made-up \"security\" reasons, everyone knows this is solely about making adblock less effective. For many users, adblock is what makes chrome bearable - and if they make it unbearable, then those users will leave. Slowly but surely. Google seems much too sure of itself making this change. I hope their arrogance pays off just the same as Microsoft's did with IE. reply freedomben 3 hours agoparentAgreed on hoping this is the inflection point, but only partial agreement that it's about adblock. For sure Google wants adblock to die, but I think it goes even deeper than that. I think it's part of a much bigger trend in tech in general but also in Google: Removing user control. When you look at the \"security\" things they are doing, many of them have a common philosophy underpinning them that the user (aka device owner) is a security threat and must be protected against. Web integrity, Manifest v3, various DoH/DoT, bootloader locking, device integrity which conveniently makes root difficult/impossible, and more. To all the engineers working on this stuff, I hope you're happy that your work is essentially destroying the world that you and I grew up in. The next generation won't have the wonderful and fertile computing environment that we enjoyed, and it's (partly) your fault. reply pipo234 18 minutes agorootparent> To all the engineers working on this stuff, I hope you're happy that your work is essentially destroying the world that you and I grew up in. I recently quit my job, developing among others the means to \"protect\" media using DRM. While this was not a primary motivation, I'm glad to somewhat clean my hands. The technology (dubbed Common Encryption) is a bunch of smoke and mirrors that a childishly easy to hack around. Yet clearly aimed against good faith consumers. reply immibis 5 minutes agorootparentThat's a good job - people who don't like DRM (you) get more money, and the bad DRM is a distraction that delays the implementation of good DRM. reply kbolino 3 hours agorootparentprevIt is important, I think, to understand that personal computing is just one part of the picture. \"Enterprise\" environments (governments, businesses, large organizations, etc.) have demanded many of these \"features\" even before Google started implementing them. Your workplace, by and large, does not want you, the replaceable person who happens to be sitting at the keyboard, to be in full control of the device that they own and which is connected to their network. Often this is made more explicit by the device just being a \"thin client\" or other totally locked down narrow viewport to some other computer you can't even touch. It sucks and the general trend of workplaces trusting their employees less and less has been demeaning and degenerative to the point of often fostering self-fulfilling prophecies of mistrust (don't trust anyone => get untrustworthy people => bad things happen => don't trust anyone => ...). However, it is important to also understand that the employee is not the only stakeholder. Government agencies answer to legislators, nonprofit management answer to donors, corporate management answer to investors, etc. There are layers of compliance that must be considered as well (internal policies, external regulations, different insurance costs, etc.). It is unsurprising that these fewer but generally deep-pocketed entities have an outsized influence on the market compared to more numerous but less moneyed end users. If you refuse to serve the former, you may quickly find yourself out of business. reply EasyMark 3 hours agorootparentThen they could have made Mv3 an option to turn on by sysadmins who lock down their browsers. If you aren’t locking down your users browsers then that’s on you. I mean at worst they could have made mv2 opt-in and most people would have highly curtailed their complaints of “I’ll jump ship to _____________” . People don’t like it when features are removed especially when there are viable alternatives like, adding a special tier of review to get mv2 approval for your extension, opt-in/out as discussed, easy access by sysadmins to turn it on/off. Instead google pulled a bully “so, pencil-neck, what are you gonna do about it?” instead. They are tone-deaf and see themselves as the new 800lb silverback on the block. reply kbolino 2 hours agorootparentI was mostly commenting on the \"broader trend\" aspects and the assignment of primary blame to implementing engineers. There's another problem with Chrome, which is that nobody is actually paying for it. So the big corps move features along there only in the sense that they won't adopt it or will drop it otherwise. I don't think the big corps are pushing for Mv3 but they also probably don't care that it arrives either. Conversely, I wager Google estimates nearly nobody will revolt and leave Chrome over the loss of Mv2. It hurts ad-blocker developers and it hurts the most conscious users, but Chrome is a marketing product targeted at mass adoption first and foremost. I personally hope their estimation is wrong and the current browser monopoly breaks, but this may not yet be the breaking point. Even if that happens, Chrome eagerly adopting enterprise policy support may keep it on life support in that environment, though. reply consp 3 hours agorootparentprev> It sucks and the general trend of workplaces trusting their employees less and less You get what you pay for. Seeing that employee retention is frowned upon. reply Arch-TK 3 hours agorootparentprevThe technologies themselves are mostly a good idea. The problem is that the companies designing them also like to abuse them. Take, for example, hardware attestation on android. There's not really any serious issue with this feature, it can be used to ensure your device is not compromised. This is for example how GrapheneOS enables its use with the auditor application. But, on the other hand, Google abuses the feature to ensure that you are running a google signed OS if you want to use Google Pay. Meanwhile you can use banking apps which also use hardware attestation (although, from their perspective, they don't use enough of it to ensure it isn't being spoofed, and even then...) without any problem on GOS. Moreover, before Google Pay completely killed all of its competition, it was possible to even find third party banks which would provide you with the ability to pay with your phone without using google pay. Likewise, secure boot is a great concept if you want to be more sure about the integrity of your laptop throughout its lifetime. But some companies have abused it to force you to use Windows. If you want to set up your own signing keys for secure boot, you end up having to deal with poorly managed UEFI keys from third parties which weaken the security of your machine. The feature, as it's implemented, is rarely designed with helping end user's secure their machines. But the core of the design is fine. I think limiting root on a phone is also a really good idea, the issue is that Google likes to give themselves and their \"system apps\" special privileges. If APIs were exposed to allow you to bless your own applications with the right permissions, you would probably not care so much about root restrictions. So all in all, fundamentally, most of these features are fine. They're genuinely great for security. But the main problem is how they're abuse by the companies in control and how little effort is put into allowing power-users to use those features for their own benefit. reply freedomben 3 hours agorootparentNo disagreement here, although if past experience has proven anything I think it's that companies will abuse whatever \"security features\" they can to accomplish their objectives. It reminds me a lot of the old adage, \"the same wall can keep people in just like it can keep people out.\" When the OS is fundamentally in the user's control, they are limited in what they can do, but when the OS disregards it's owners preferences/desires and enforces it's creators desires. Minor thing actually: > If APIs were exposed to allow you to bless your own applications with the right permissions, you would probably not care so much about root restrictions. I absolutely agree with this in theory, but in practice I'm not sure it would ever work because they just aren't going to put in the work to build and maintain APIs for things they don't care about, and there would be a very long tail of things to do (and sometimes those things are legitimately a lot of work). Call recording being a classic example. But all in all, I very much agree. I love those features when they are in my control on my devices. Biggest issue is, they virtually never are and the number of occurences is trending down. Anyway, reply kuhsaft 1 hour agorootparentprev> To all the engineers working on this stuff, I hope you're happy that your work is essentially destroying the world that you and I grew up in. That was a world where the user base was much more limited and devices were less capable. Now we have children, grandparents, educated, and uneducated users with access to web connected devices. These devices now contain everything about you. Compromise of a device can destroy someone’s life. Not only that, but compromise of a device can cause collateral damage to other devices on the same network. We now have to cater to every user. Not just to the technologically adept. Look at what people believe on social media. The bar is so low to con people into compromising their device. reply jauntywundrkind 1 hour agorootparentStill a shit poor pathetic excuse to screw over the userscript/grease monkey users. The browser is called a user agent, but this shift to absolute security no matter what, no say about it is a shift to native apps, is a shift to the developer is in control, is a shift to this being Google and the sites browser, not ours, and that being done unilaterally with nearly no opt outs is the sort of mega tectonic shift that ruins this magical special unique place in software where users had some say in what was happening. We cannot pander to imagined ever worsening users forever. It feels like the things being done in the name of security are really building an immense prison. The work being done to allow verified age and identity checking ranks up there highly in the this corals humanity, area, not giving us agency. reply kuhsaft 1 hour agorootparent> Still a shit poor pathetic excuse to screw over the userscript/grease monkey users. Tampermonkey still works fine with MV3 > We cannot pander to imagined ever worsening users forever. The most popular software/hardware will always pander to the most users. That’s why they’re the most popular. You can’t complain about the most popular option pandering to the most users. Well, you can complain, but you might be in the minority of the users. > It feels like the things being done in the name of security are really building an immense prison. I get that, but we are running so much untrusted code on our machines now. Applications that use thousands of dependencies with the hope that someone spots a bad actor. reply mossTechnician 33 minutes agorootparent> The most popular software/hardware will always pander to the most users. That’s why they’re the most popular. I think the point of \"We cannot pander to imagined ever worsening users forever\" is that these users do not exist. I would take that one step further and say that I believe companies like Google are shaping users to accept the things that would be most beneficial to themselves, a reframing of a sort of technological Overton window. reply justanotheratom 3 hours agorootparentprevyes, iOS now restricts Apps from getting blanket access to their contacts, photos, and even clipboard. On the one hand, it does protect the user from malicious Apps that trick users into giving blanket access. On the other hand, they could have atleast done it like location access - where user still has an option to give blanket access. It is not fair that Siri is the only one that can access these things now. reply kstrauser 3 hours agorootparentThat's literally how iOS works today. If I go into Settings > Privacy & Security > Photos, I can give apps None, Limited Access, or Full Access. Same with Contacts, same with the clipboard (where the per-app choices are Ask, Deny, or Allow). > It is not fair that Siri is the only one that can access these things now. That would be true if it was, but it isn't. reply moi2388 3 hours agorootparentprevIt can. You can still give apps access to all of it with a single press. And manifest v3 makes things a bit more tedious but not impossible. There are other adblockers which still function just fine reply Cthulhu_ 3 hours agorootparentprevI get why they built in all of those protections; the vast majority of tech users are not knowledgeable about the details of the stuff they use. And I think a big chunk of those that are, overestimate their own abilities, knowledge, and control. They all need to be protected against themselves. That said, I don't like that the choice is being taken away. If you do want to tinker at that level with the technology you own, you should be given the choice. By all means make it not obvious how to get there - like, have people reboot their computers while playing Twister on their keyboards with interesting key combos, but give them the option. reply moooo99 3 hours agoparentprevAdblock doesn’t only make Google Chrome bearable, it makes the internet bearable. I recently uninstalled my Adblock for testing purposes. Most websites nowadays are just ads with a little bit of text in between reply DataDive 3 hours agoparentprev> Hopefully this is the inflection point for Chrome. Here is one empirical data point. I switched over to Firefox this morning and will advocate for it. I've considered it for a while, but I never felt motivated to make the switch. It took me a good half hour to set it up the way I like it. reply karaterobot 3 hours agoparentprevI'd like to think that's true, but I don't know, because people seem to have a very high tolerance for advertisements. Surprisingly so. I have a very low tolerance, and do what I can to get rid of them. But then, every once in a while I use someone else's computer and see how they live with them. I say \"I can show you how to get rid of those ads,\" but they usually just don't care enough to do it. I bet the majority of people are like that—maybe the vast majority—and Google is probably making the same bet, but with even more information. My prediction is that if (God willing) Chrome loses significant market share, it'll be for some other reason than this. reply Rychard 4 hours agoparentprevThe widespread adoption of Chrome was largely driven by word of mouth, people like you and I installing it on our friend's/relative's computers and telling them it was safer/faster/better. Nothing stops us from doing the same thing again. I've been recommending Firefox to all my family/friends/colleagues for years (ever since I've seen the writing on the wall for Chrome). While Firefox isn't perfect, it's in a much better place than Chrome is, and meets the the needs of nearly 100% of people. reply undercut 3 hours agorootparent>The widespread adoption of Chrome was largely driven by word of mouth No, it was driven by having a banner in the most privileged spot of the Internet, Google.com (the most visited site in the world with 0 ads on the homepage) saying that was faster and more secure than the alternatives. In fact Firefox benefited from some free ads on Google.com against Internet Explorer before Google developed Chromium. reply sunshowers 10 minutes agorootparentThe other aspect, somewhat memory-holed, was that Chrome was automatically installed as shovelware if you went to install Adobe Flash for IE or Firefox: https://www.reddit.com/r/chrome/comments/23jnmy/why_is_chrom... This kind of not-freely-given consent was key to Chrome's growth. reply x0x0 3 minutes agorootparentprevEarly chrome was driven by the fact that firefox was a piece of garbage. Firefox 3 was not good software, and had an unpleasant habit of totally crashing the entire browser regularly. Your only other popular choice was ie8. Also not great. Later Google's ability to buy installs and put it on google.com came into play, but for at least the first 5 years and probably longer, chrome was a far faster, more secure, and more reliable choice. They also pioneered the multi-process model to isolate different components of the browser. reply freedomben 3 hours agorootparentprevIt was kind of both, depending on the timeline. Early on it was word of mouth, then Google saw they had momentum and they capitalized on it with the banners and aggressive marketing. reply undercut 3 hours agorootparentIt was a long time ago but I'm 99% sure that there was a banner for Chrome on Google.com since the first public release. reply cyberpunk 3 hours agorootparentprev… isn’t that banner an ad? reply Uehreka 2 hours agorootparentprevYeah, I feel like in general we on HN give ourselves way too much credit in terms of our ability to drive public opinion or affect purchasing/usage patterns among the public. The idea of the “nerd-led revolution” may have had some impact in the past, but I think the days of that are over. Large corporations now know what they’re doing in ways that they hadn’t figured out in the 2000s or even the early 2010s. reply Izkata 3 hours agorootparentprevI swear I also remember it getting included in installation wizards for unrelated software (on Windows), so people would end up with Chrome/Chromium without even realizing it. reply EasyMark 3 hours agorootparentI’ve been out of the windows game for so long I forgot all that malware that was installed by various installer engines and was so relieved when I found portable apps and oldversion.com and ninite. And now I guess there are things like chocolaty that do similar things. Switching to Mac and Linux I don’t really miss it at all reply EasyMark 3 hours agorootparentprevDid you miss the barrage of ads for Chrome that google played for literally years on the internet and television? reply throwaway48476 34 minutes agoparentprevSo, are you going to leave chrome then? reply wooque 3 hours agoparentprevI'd argue it won't make a dent in Chrome market share. People who really care about this (tech minded people) are not using Chrome anyway, others (regular people) will switch to less powerful Manifest V3 adblockers that would probably be good enough and won't switch from Chrome. reply crazygringo 3 hours agoparentprev> everyone knows this is solely about making adblock less effective I thought I knew that. Then I switched from uBlock Origin to uBlock Origin Lite in Chrome, which is compatible with Manifest v3. I was prepared for the horrible onslaught of ads, expecting at least a quarter would start getting through, ready to switch to Firefox... ...and didn't notice a single change. Not a single ad gets through. And at the same time, loading pages feels a little faster, though I haven't measured it. Which has now got me wondering -- what if Manifest v3 really was about security and performance all along? Because if Google was using it to kill adblockers, they've made approximately 0% progress towards that goal as far as I can tell. If they really wanted to kill adblockers, they'd just, you know, kill adblockers. But they didn't at all. reply Spunkie 3 hours agorootparentThis is just because Google was especially insidious about how they crippled ad blockers in v3. Adblockers do multiple things: 1. Visibly block ads from the user 2. Block the user tracking that's attached to those ads 3. Protect the user from malware 4. Save bandwidth and cpu cycles by not loading all that junk 5. Allow control to users over how a webpage is displayed to them Arguably uBlock Origin Lite can only accomplish some of #1 and a sprinkle of #2 now. And even those abilities are compromised by artificially low limits imposed by chrome in v3 that will eventually allow ad networks to overwhelm those limits and get ads through to users. Google is 100% boiling the frog here and you/the average user is left in the pot unaware. reply crazygringo 1 hour agorootparentI don't think any of that is accurate though. Manifest v3 blocks user tracking -- if the request is blocked, any tracking attached to it is blocked. I'm sure it's not 100% perfect, but it's certainly working well enough in practice. And what malware are you talking about? If a request is blocked, it's blocked. It doesn't matter if it's an ad or malware. Manifest v3 is better at #4, because the junk isn't loaded, and the blocking is more efficient in terms of CPU. And then #5 I don't know what you're talking about. I use Stylus and Tampermonkey to customize webpages and they continue to work great. So I just don't see the evidence that \"Google is 100% boiling the frog here\". That's what everyone was saying, but now that Manifest v3 has come out, I just see adblocking that continues to work and uses less CPU to do it. I see a lot of fearmongering around Google, but now that the results are in with Manifest v3... they just don't seem true. You're making all these claims, but I just don't see the evidence now that we're seeing how it works in practice. reply eikenberry 3 hours agorootparentprevIf I remember right then the difference is more about ad-tracking/privacy than blocking. V2 allowed UBO to find and intercept the calls to the ad servers before the calls were made. Where V3+UBL still makes the calls it just doesn't display the results. So while you might not see the ads, the ads see you. reply kuhsaft 2 hours agorootparentOn the contrary, MV2 used onBeforeRequest which let extensions see what requests you were making. They could then take that data and use it for malicious purposes. MV3 doesn’t allow extensions to know what requests are being made, so extensions can’t use your data maliciously. Requests to ads that are blocked are blocked. I think you’re thinking of Privacy-preserving ad measurement which is an option in Firefox and Safari. https://support.mozilla.org/en-US/kb/privacy-preserving-attr... reply sunshowers 5 minutes agorootparentDoesn't onBeforeRequest still exist in Manifest v3? The thing that's been removed is the ability to block on it, not the ability to register handlers for requests. reply GeoAtreides 41 minutes agorootparentprevbut op wasn't talking about what extensions are seeing, but what the ad servers do. You haven't address their point at all reply flohofwoe 3 hours agorootparentprev> ...and didn't notice a single change. Not a single ad gets through. When I tried UBO Lite recently it couldn't block YouTube ads, not sure if that's impossible with Manifest V3, or if UBO Lite just isn't updated regularly like UBO to defeat the YouTube anti-ad-blocking updates. Update: looks like it's fixed now, not bad :) reply Cthulhu_ 3 hours agorootparentYoutube's adblocker-evasion and adblocker's youtube ad blocking has been a cat-and-mouse game since time immemorial. reply moi2388 3 hours agorootparentprevIt makes things a bit more annoying? But in v3 you can still do everything you need to do to block ads reply surajrmal 3 hours agorootparentprevPeople seem to see what they want. And many seem to be blinded by Google hate and must find ways to be unhappy with all decisions they make. Google has publicly delayed v2 depreciation to ensure ad blockers worked well under v3. reply kmlx 3 hours agoparentprev> making adblock less effective adblocking still works just fine on Safari, which has been doing the same thing as Manifest V3 for years now. reply yupyupyups 3 hours agoparentprevYeah, I don't browse the web without an ad blocker. reply faefox 4 hours agoprevSwitch to a different browser! The Chrome monopoly only exists because we collectively allow it to exist. reply lapcat 3 hours agoprevThis submission title does not appear to be accurate. Here's what was actually said: > October 9th 2024: an update on Manifest V2 phase-out. > Over the last few months, we have continued with the Manifest V2 phase-out. Currently the chrome://extensions page displays a warning banner for all users of Manifest V2 extensions. Additionally, we have started disabling Manifest V2 extensions on pre-stable channels. > We will now begin disabling installed extensions still using Manifest V2 in Chrome stable. This change will be slowly rolled out over the following weeks. Users will be directed to the Chrome Web Store, where they will be recommended Manifest V3 alternatives for their disabled extension. For a short time, users will still be able to turn their Manifest V2 extensions back on. Enterprises using the ExtensionManifestV2Availability policy will be exempt from any browser changes until June 2025. See our May 2024 blog for more context. reply wtallis 3 hours agoparentThey said \"we have started disabling Manifest V2 extensions on pre-stable channels\", and the \"Chrome canary\" referenced in the submission title is a pre-stable channel. The submission title is accurate, but narrowly highlighting only one facet of Google's update statement. reply lapcat 3 hours agorootparentThat's old news, as noted in my other comment: https://news.ycombinator.com/item?id=41810420 The change here is actually about the stable channel. Also, the title makes it sound like MV2 code has been removed from the source, but that's not the case. reply wtallis 3 hours agorootparent> That's old news, as noted in my other comment: None of your comments have actually provided evidence for this assertion, and the previous update dated June 3rd 2024 says users will start seeing a warning. So when between June 3 and October 9 did Google start actually disabling MV2 extensions, and where was it publicized prior to their October 9 update? reply lapcat 2 hours agorootparent> None of your comments have actually provided evidence for this assertion It's not an assertion. It's simple reading comprehension. How else can you interpret this? \"Over the last few months, we have continued with the Manifest V2 phase-out. Currently the chrome://extensions page displays a warning banner for all users of Manifest V2 extensions. Additionally, we have started disabling Manifest V2 extensions on pre-stable channels. [paragraph break] We will now [emphasis mine] begin disabling installed extensions still using Manifest V2 in Chrome stable.\" > So when between June 3 and October 9 did Google start actually disabling MV2 extensions, and where was it publicized prior to their October 9 update? I don't know if it was publicized, until now. After all, when did they publicize that there would be a warning in Chrome stable? But there is a warning in Chrome stable. That started happening some time before this announcement. Four months is a long gap between announcements. reply wtallis 2 hours agorootparent> I don't know if it was publicized, until now. So you literally don't know if it was news before now, but you're insisting on calling it \"old news\", apparently based solely on Google using past tense in their announcement. reply lapcat 2 hours agorootparent> So you literally don't know if it was news before now, but you're insisting on calling it \"old news\" That was just a figure of speech, which I don't wish to quibble over. I don't insist on using that phrase. The point, from the beginning, is that the HN submission title is not good. It actually doesn't matter when exactly that Google began disabling MV2 extensions in Chrome canary, because what's the justification for focusing on canary in the submission title when the announcement says, \"We will now begin disabling installed extensions still using Manifest V2 in Chrome stable\"? [EDIT:] I see that the submission title has now indeed been changed, so this argument has become redundant. reply EasyMark 3 hours agorootparentprevBut still it’s the first stab wound inflicted on CaesarMainline, he’s toast reply dang 26 minutes agoparentprevOk, I've replaced the title with that language from the article (shortened a bit to fit HN's 80 char title limit). Thanks! Submitted title was \"Manifest v2 is now removed from Chrome canary\" reply freedomben 3 hours agoparentprevThe most relevant part is: > Additionally, we have started disabling Manifest V2 extensions on pre-stable channels. Title could have been a bit more broad (probably should say \"pre-stable\" instead of \"canary\"), but I would say it is inaccurate. reply lapcat 3 hours agorootparent> The most relevant part is: That's actually not the most relevant part. The most relevant part is \"We will now begin disabling installed extensions still using Manifest V2 in Chrome stable. This change will be slowly rolled out over the following weeks.\" Google had already started disabling Manifest V2 extensions on pre-stable channels, prior to October 9. The first paragraph is \"what we've been doing.\" The second paragraph is \"what we'll do now.\" reply freedomben 4 hours agoprevI hoped this day would never arrive, but alas all good things must come to an end. Since adopting uMatrix, my web experience radically changed and I can never go back to a pre-uMatrix world. With the v2 removal, I've got to eliminate Chrome from my life. I also adopted a workflow that has been very conveninent for many years, essentially using Chrome for personal stuff and Firefox for work and other various things (especially once container support arrived!). It's not going to be easy to undo years of muscle memory, but I guess it's time to bite the bullet. reply blakesterz 4 hours agoprevHas anyone been using the v3 compatible version of uBlock Origin? Have you noticed much of a difference? From what I read there isn't supposed to be much of a difference? reply tyingq 4 hours agoparentStatic list of uris versus live heuristics. So \"much of a difference\" depends a lot on what you browse. If your browsing is covered by the static list, yes...there's little difference. Also, keep in mind advertisers are not unaware of all this movement. You don't think they'll try new tactics once they know everyone using chrome is now hobbled to solely static lists? That cloaking (or other approaches) won't then become really popular? reply fpoling 4 hours agorootparentA lot of other ad blockers use static lists for years. The fact that they work tells that ad industry does not see the blockers as a problem that needs to be dealt with. It can also be that so far the increased cost of development of ads that are immune to simple static lists is not worth it. reply vlovich123 3 hours agorootparentI’ve noticed a huge number of websites have interstitials pop up asking you to remove your ad blocker. While some let you bypass it anyway some don’t. Clearly the websites themselves seem to care. reply tyingq 4 hours agorootparentprevRight. Advertisers didn't bother with all these tactics because normal chrome users could download a plugin without any major hurdles to thwart it. Why drive people that wouldn't otherwise use an ad blocker to do so? That's going away now. Now mostly everyone is vulnerable with the only recourse being pretty technical stuff, not just downloading a very popular plugin. So advertisers will now be free to get more aggressive without much downside. Edit: I do get that this sounds like conspiracy theory. But it really matches the Google boiling frogs approach. Removing the blocking onBeforeRequest, as one of the very first things in the manifest v3 spec was not a coincidence. reply fpoling 18 minutes agorootparentEven if Google did want to reduce effectiveness of ad blockers, doing that via removal of blocking webRequest API is a double-edged sword. It may push users to alternate browsers with more effective ad-blocking. Besides, webRequest implementation in Chromium is a terrible collection of hacks on hacks. It is a good example how not to design or implement API. I will not be surprised if the removal of the API comes from a simple desire to remove that embarrassing code. reply kuhsaft 2 hours agorootparentprevonBeforeRequest was removed because it is a massive spyware and malware vector. > I do get that this sounds like conspiracy theory. > … was not a coincidence. Could it be that it was coincidence? Do you have a solution for reducing extension malware without removing onBeforeRequest? reply tyingq 19 minutes agorootparent> onBeforeRequest was removed because it is a massive spyware and malware vector. Yet you can still inject js right into the page. You just can't stop a page that was going to load from loading. They could have taken away the onBeforeRequest redirect capability and left just the onBeforeRequest cancel capability. Not sure I've heard of any spyware/malware depending on just that cancel capability. reply kuhsaft 13 minutes agorootparentThat uses a different manifest permission. https://developer.chrome.com/blog/crx-scripting-api#breaking... reply throwaway48476 18 minutes agorootparentprevI made a plugin for scraping using onBeforeRequest. It's very useful. reply kccqzy 4 hours agoparentprevI have been using the Firefox version of it for more than a year by now, basically as soon as it came out. I commented on HN that I was going to do it: https://news.ycombinator.com/item?id=37219071 There's no difference whatsoever. And it's not surprising because on my iOS device I've been using similarly architected content blockers since 2015. There's no issue with declarative ad blocking. Of course this differs with the kind of sites you visit. So you need to try it on your own. I can believe that perhaps for some people this is a downgrade, but don't automatically assume uBlock Origin Lite won't work well for you. reply drivebycomment 4 hours agorootparentAnyone jumping up and down about MV3 while using Mac or iOS are hypocrites, since MV3 is essentially doing the same thing Safari did years ago, finally matching the security and the privacy in that regard. The reduction in adblocking is so miniscule in aggregate - since declarative approach will always cover all the major advertisers - that it's not even a meaningful \"trade-off\". reply kuhsaft 3 hours agorootparentIt’s similar, but not the same. Safari lets you dynamically generate rules that are then compiled for privacy and efficiency. The limits were increased to 150000 rules per content blocker due to user demands [1]. And each extension can have multiple content blockers. MV3 has a measly 30000 static rule limit. These rules are included with the extension and cannot be updated dynamically. And a 5000 dynamic rules limit. [2] EDIT: Chrome now has a 300000 shared pool for static rules for extensions that go over their 30000 limit. And a 30000 dynamic rule limit [3]. [1] https://adguard.com/en/blog/adguard-for-safari-1-11.html [2] https://adguard.com/en/blog/adguard-mv3-beta.html [3] https://developer.chrome.com/docs/extensions/develop/concept... reply nolist_policy 3 hours agorootparentThe limit is 330000 rules: \"Based on input from the extension community, we also increased the number of rulesets for declarativeNetRequest, allowing extensions to bundle up to 330,000 static rules and dynamically add a further 30,000.\" https://blog.chromium.org/2024/05/manifest-v2-phase-out-begi.... reply kuhsaft 3 hours agorootparentIt looks like it’s a shared quota now with a minimum per extension [1]. Still sucks that the rules are static though. AdGuard devised a method to diff ruleset changes with the built in rules to generate dynamic rules between extension updates. So, I guess it works. [1] https://developer.chrome.com/docs/extensions/develop/concept... reply yjftsjthsd-h 3 hours agorootparentprev> Anyone jumping up and down about MV3 while using Mac or iOS are hypocrites, since MV3 is essentially doing the same thing Safari did years ago, iOS I'll give you, but macOS can in fact run ex. Firefox. > finally matching the security and the privacy in that regard. \"Matching\" inferior security+privacy is not a good thing. The only way this is an improvement if you think the blockers are malicious; otherwise a useful tool in the users interest has been made less powerful. reply drivebycomment 3 hours agorootparentOne of the most common API malware extensions use is what MV3 blocks, and adblock extension is one of the common malware vectors: https://helpcenter.getadblock.com/hc/en-us/articles/97384768... https://www.wired.com/story/fake-chrome-extensions-malware/ This has been never ending. reply yjftsjthsd-h 2 hours agorootparentOkay, if you absolutely must then make that specific API require extra audit approval from the extension store, but breaking it outright is throwing out the baby with the bathwater; in a world where the FBI outright recommends an adblocker because ads are such a strong malware vector ( https://techcrunch.com/2022/12/22/fbi-ad-blocker/ ), it's irresponsible to undermine uBo. reply kccqzy 1 hour agorootparentNobody likes extra audit approvals. The platform doesn't want to spend resources doing the audit. The developers don't want to be audited. The Firefox version of uBlock Origin Lite was pulled due to unsatisfactory audit process: https://news.ycombinator.com/item?id=41707418 reply kuhsaft 3 hours agorootparentprev> The only way this is an improvement if you think the blockers are malicious Extensions and in turn MV2 blockers can easily be malicious. https://usa.kaspersky.com/blog/dangerous-chrome-extensions-8... Look at how many in Kaspersky’s list are advertised as ad blockers. The majority of users aren’t tech savvy like HN. reply yjftsjthsd-h 2 hours agorootparent> Look at how many in Kaspersky’s list are advertised as ad blockers By my count 5, 6 if we include \"Autoskip for Youtube\", out of 34. That might be an argument for dropping extensions, but I don't think it's an argument for breaking ad blockers. reply kuhsaft 1 hour agorootparent> That might be an argument for dropping extensions Those extensions used the same API that ad blockers used, but for malicious purposes. So, you would support removing that API? Well, that’s what they did for MV3 and implemented an API just for ad blocking. reply SoftTalker 3 hours agorootparentprevI see boatloads of ads in Safari on iOS. To the point that web browsing on my phone is intolerable, so I don't do it. reply kccqzy 3 hours agorootparentThis is such a data-free anecdote. Which websites are showing ads? Which ad blocker did you install on iOS? reply HDThoreaun 2 hours agorootparentprevWhich adblocker are you using? I have adguard and dont get ads on most safari sites but its just static DNS blocking so first party ad servers like youtube dont get blocked. reply the_gipsy 3 hours agorootparentprev> There's no difference whatsoever. That's simply not true. Have you ever donde a side by side comparison, or are you just going by feeling? reply michaelt 3 hours agorootparentprev> And it's not surprising because on my iOS device I've been using similarly architected content blockers since 2015. There's no issue with declarative ad blocking. Really? Because I find adblockers on iOS are nowhere near as good - they let far more ads through, and they leave far more sites broken so I have to disable the ad blocker for the site to work. reply eek2121 3 hours agorootparentThat is the fault of the blockers themselves. The one I use (https://apps.apple.com/us/app/1blocker-ad-blocker/id13655310...) works extremely well and even uses a local VPN setup for app ad-filtering. Twitter and YouTube ads are blocked. The drawback? It isn’t free. reply kuhsaft 4 hours agoparentprevI’ve been using AdGuard. There are some limitations with MV3, but it’s not noticeable [1]. AdGuard uses dynamic rules for updating rules between extension updates and for custom user rules. There’s the option using their system level AdBlocker too. [1] https://adguard.com/en/blog/adguard-browser-extension-mv3-re... reply tapoxi 4 hours agoparentprevI've been using Lite for the past few months, I've seen no real difference. I think if you're particular about rulesets or are heavily customizing uBlock you may want to consider switching browsers, but I'm happy enough that I'm remaining on Chrome. reply internet2000 3 hours agoparentprevAnother happy user of uBlock Origin Lite on Chrome here. No difference. 1Blocker on Safari user since Apple came out with the declarative adblocking system there as well. reply joshdavham 4 hours agoparentprevI use Adblock Plus, and ad blocking still perfectly works. Not sure about uBlock origin though. reply Cthulhu_ 3 hours agoparentprevI for one am just going to wait it out and see what the internet looks like nowadays without an adblocker, if it doesn't auto-update. It's been so long. reply neoromantique 4 hours agoprevOn Mac OS: https://kagi.com/orion/ reply codetrotter 4 hours agoparentFrom the Orion FAQ: > Is Orion open-source? > We’re working on it! We’ve begun with some of our components and intend to open more in the future. > Forking WebKit, porting hundreds of APIs and writing a browser app from scratch has been challenging for our small team. Properly maintaining an open-source project takes time and resources we’re short on at the moment, so if you want to contribute at this time, please consider becoming active on orionfeedback.org. reply vinnymac 4 hours agorootparentI won’t be touching this binary with a ten foot pole until every line of code is open. Many excellent alternatives already exist that are also open and free, I don’t see a compelling argument to use this software on any device at the moment. reply freediver 3 hours agorootparentCurious why exactly and what is wrong with closed source paid for products? By that token nobody should be touching Safari or iOS/macOS for that matter? reply neoromantique 1 hour agorootparentprevFair play, but by that logic you shouldn't touch Mac OS as well, so the whole thing is moot since Mac OS is the only OS that is supported by Orion. reply madeofpalk 4 hours agorootparentprevIsn't Webkit GPL? How is it not open source? reply freedomben 3 hours agorootparentJust a general rule of thumb that has served me well: If it's GPL, Apple wouldn't be using it. Apple hates the GPL as it is the antithesis of their operating model. reply codetrotter 3 hours agorootparentprevhttps://webkit.org/licensing-webkit/ WebKit is part LGPL, and part BSD. So I think from purely a licensing point of view, they are probably not in violation. Provided that the way they are linking the LGPL-licensed code is compatible with the LGPL. But like the other commenter said, I too would not run any web browser that was not fully open source, like this Orion browser. reply madeofpalk 2 hours agorootparentIf they are forking Webkit, like they say, doesn't that require they distribute the source to their fork? Even if they don't have to distribute the browser linking to it? Or do I not understand the obligations of LGPL? reply Etheryte 2 hours agoparentprevI love Kagi, but I wish they focused on their core product first. Search is a hard problem to nail down and there's no shortage of bugs in Kagi right now, their issue tracker is a solid testament to that. When they spread their attention and resources between multiple products, they run the risk of pulling a Mozilla and shooting themselves in the foot multiple times. reply frizlab 4 hours agoparentprevOrion is amazing. reply sunaookami 3 hours agoprevAdblockers are my least concern, a lot of other useful add-ons won't work, like Imagus, Redirector, Violentmonkey, etc. So I switched to Firefox a few months ago. reply sirolimus 4 hours agoprevGoodbye Chrome, hello firefox reply OptionOfT 2 hours agoprevI am tied to Microsoft Edge for sync between desktop and phone, and Microsoft Edge on iOS has AdBlock built in. But looking at this it seems inevitable that Edge will retain V2. As to switching to Firefox? I'd love to, but Firefox on iOS refuses to put in an AdBlocker. Yea, you can use Firefox Focus but that one doesn't sync. I don't understand Mozilla's stance on this. reply throwaway48476 13 minutes agoparentFirefox doesn't exist on iOS, it's just reskinned safari. It's not Mozillas fault that Apple won't let you install a different web engine. reply Mrdarknezz 4 hours agoprevTotally unrelated, firefox is an excellent browser reply lemagedurage 3 hours agoprevFor people who want to stick with a Chrome-based browser while still using the full-featured uBlock Origin: Brave will keep supporting uBlock Origin even after Manifest V2's removal from Chromium. https://brave.com/blog/brave-shields-manifest-v3/ reply grounder 2 hours agoparentBrave browser should probably not be trusted. They violated basic trust by redirecting URLs to their own affiliate links for those URLs. That is pretty bad. https://www.theverge.com/2020/6/8/21283769/brave-browser-aff... reply the_gipsy 3 hours agoparentprevFor how long, though? And what will be the next marketing scam after crypto/tokens? Something with AI? reply ParetoOptimal 3 hours agoparentprevNote that Brave's creator opposes same sex marriage, is a Coronavirus \"skeptic\", and his silly cryptocurrency is made to work with brave browser. reply gabrielsroka 3 hours agorootparentBrave's creator, B. Eich, also created JavaScript, so I assume you have that disabled everywhere. reply jovial_cavalier 11 minutes agorootparentprevI don't care. reply sunaookami 16 minutes agorootparentprev>opposes same sex marriage That's not true, he donated to organizations supporting California Proposition 8 which banned same-sex marriage which by the way was supported by the majority back then in California. That was also 16 years ago, it's time to let it go and stop spreading misinformation. You should instead not rely on ad-hominem and critize Brave for being ridden with cryptocurrency and doing shady stuff. reply Kelteseth 4 hours agoprevhttps://www.mozilla.org/en-US/firefox/new/ reply varun_ch 4 hours agoparentChrome to Firefox is a relatively easy switch, especially for those that don’t depend on Google sync. The main sources of friction for me were the lack of a good profile switching UI (solved with a browser extension that mimics the Chrome menu), and weird security requirements for homemade extensions (IIRC if you want to have the extension persist after restarting Firefox, you need to sign the extension, which is a pain) For users switching from Arc, there is no good alternative, but Firefox with Sidebery and custom CSS comes close. reply Lukas_Skywalker 3 hours agorootparentI don't know if this is what you meant, but as an alternative to profile switching, there are Multi Account Containers [1]. It allows assigning a container to each tab, and the containers are isolated from each other. If you have an MS or Google account for both work and personal, you can open them at the same time in different tabs. [1] https://addons.mozilla.org/en-US/firefox/addon/multi-account... reply lyu07282 3 hours agorootparentthis is such a killer feature I don't understand why it even is an extension, every browser that isn't adversarial to the user should have that feature tbh reply throwaway48476 11 minutes agorootparentI've found it hard to teach people how to use but it is a killer feature. reply elashri 4 hours agorootparentprev> For users switching from Arc, there is no good alternative, but Firefox with Sidebery and custom CSS comes close. I would suggest zen browser [1] for those people. [1] https://zen-browser.app reply MrAlex94 4 hours agorootparentI'd like to pop in and say Waterfox also has a list of comparable features: https://www.reddit.com/r/waterfox/comments/1ff0kzz/comment/l... reply afranchuk 3 hours agorootparentprevNote that Firefox profile management is getting an overhaul right now, including an easy profile switching UI. I'm not sure when it will be landing in release, but it is being actively built! reply starky 2 hours agorootparentprevI've tried to switch from Vivaldi to Floorp and there is some things that Firefox does that drive me absolutely nuts. The main one is the behaviour of pinned tabs. Pinning in Firefox turns it into an icon that is harder to hit and doesn't even protect it from closing. This makes them essentially useless, they should be moved to the front of the tab bar and be protected from closing. The second is that when you use vertical tabs the tab bar acts like a title bar instead of a separate entity. This means you can't double click to create a new tab, and trying to drag a tab often results in the entire window moving. I have to use Tree style tabs and disable the normal tab bar completely to prevent this. There are also things that I don't like such as how downloads are handled and I've has issues with my session tabs being saved properly. reply nalinidash 3 hours agorootparentprevProfile is already available in Firefox(before chrome implemented it). Details on how to use it: https://support.mozilla.org/en-US/kb/profile-manager-create-... Also in chrome, multiple profiles need multiple google account(If I understand the UI correctly)connected, but in Firefox no account is needed. reply wtallis 3 hours agorootparent> Also in chrome, multiple profiles need multiple google account(If I understand the UI correctly)connected, but in Firefox no account is needed. You can use Chrome with multiple profiles by disabling the \"Allow Chrome sign-in\" option so that none of your browser profiles are tied to a Google account. I don't know if that option can be toggled on a per-profile basis, because I happen to prefer it off for all of my browser profiles. reply grounder 3 hours agorootparentprevI don't know much about Arc. But Arc users could give Firefox \"Nightly\" a try to preview new features coming up. It has vertical tabs and you can \"pin\" a few tabs at the top. Nightly also has containers already built-in, so you can have multiple accounts open for the same site in different container tabs. reply tapoxi 4 hours agorootparentprevArc has a built-in adblocker, so it depends if you're tied specifically to uBlock Origin (non-lite) features. I'm not sure what other extensions would be broken in Manifest v3. reply sbrother 3 hours agorootparentprevIn the past I've had a lot of issues with Google properties not working properly on Firefox -- either outright broken or using crazy amounts of CPU on Firefox but not Chromium-based browsers. Does anyone know if this is still an issue? I'd love to try again before I'm forced to by uBO breaking. reply beached_whale 4 hours agorootparentprevOne feature that is missing, removed, from Firefox is PWA's/running sites as apps. This is super handy for low trust apps reply byteknight 3 hours agorootparentprevFirefox containers are amazing reply husam212 4 hours agorootparentprevI've been using Floorp for a while to get proper vertical tabs. reply foxandmouse 4 hours agoparentprevI love Mozilla, but I’m concerned about its future. Since 80% of its income reportedly comes from the Google search deal, do they have a plan to replace it after the recent ruling? And can they maintain their current level of autonomy while doing so? reply EasyMark 2 hours agorootparentKilling adblocking in Chrome might be a boost they need to attract someone else to pay for being the landing search page. I doubt if anyone will pay as much as google though. Or probably even close. reply cma 3 hours agorootparentprevThe Android version of Firefox still doesn't have working keyboard shortcuts after 13 years or a way to delete individual history items to prevent broken auto complete. The money is going into lots of other things than the browser. reply SAI_Peregrinus 1 hour agorootparentI'm not sure keyboard shortcuts for a version designed to run on an OS for devices without keyboards will ever be a priority. You can use a keyboard on an Android device, but the vast, vast majority of Android devices are phones that never get used with keyboards. I don't expect there's much priority to adding that feature. I agree that a lot of money is going to things other than the browser though. reply TwoNineA 4 hours agoparentprevuBlock Origin + Multi Account Containers makes Firefox enjoyable to use. reply anovick 4 hours agoparentprevMain reason I'm still using Chrome and can't switch to Firefox: https://connect.mozilla.org/t5/ideas/feature-suggestion-fire... reply undercut 4 hours agorootparentThere is something wrong with your Firefox installation (maybe try a new profile with vanilla settings). I use search shortcuts all the time (w + spacebar for wikipedia) and it's exactly the same behavior in Firefox than Chrome/Edge. reply prettymuchnoone 4 hours agorootparentprevhm i'll post this in the thread over there later but i'm pretty sure ff has that? https://imgur.com/a/gXrsBq3 reply bdcravens 3 hours agoprevAnyone using a PiHole to block on their network? I've been aware of it, but honestly, ad blocking was good enough that I didn't go down that route. Is PiHole good enough? Is there a big problem with false positives? reply kstrauser 3 hours agoparentYep, and it's great. Beyond ads, you can also configure it to block malware. Got a phishing email from scammer.ru? Nothing happens even if you to click the link in it because that name won't resolve. There were a very short list of exceptions, maybe 2 or 3, I had to add to ours over the years, mainly for hostnames like tracking.shippingcompany.com that got added by mistake. Note that it does nothing to block DNS over HTTPS lookups. If your browser insists on going around your LAN's DNS setup, Pi-hole can't help you. reply surajrmal 3 hours agoparentprevId argue pihole is roughly equivalent to what you can do with manifest v3 based afld blockers. I use it as my primary ad blocker as well, and don't really understand why folks are upset about losing V2 that much. It seems like removing root in favor of more granular permissions which is generally a good thing. reply bberrry 1 hour agoparentprevIt can't handle YouTube ads unfortunately. reply Gimpei 3 hours agoprevWhat does this mean for browsers derived from chrome, like Arc? I heard they plan on continuing to support Manifest v2, but will ublock continue to be maintained for chrome? reply noname120 2 hours agoparenthttps://resources.arc.net/hc/en-us/articles/25540117353623-W... reply paulryanrogers 3 hours agoparentprevMV2 code should remain well into 2025 since enterprises can still enable MV2 extensions. After that they may have to hard fork, which could become increasingly costly. Though they could coordinate to minimize duplicated efforts. reply pentagrama 3 hours agoprev> Users will be directed to the Chrome Web Store, where they will be recommended Manifest V3 alternatives for their disabled extension. I'm curious about which extensions will be recommended to replace uBlock Origin after it's disabled. I'm sure those alternatives will see a surge in installs. Also, why doesn't the creator of uBlock Origin update the V2 version to the V3 version? I know V3 version isn't as good as V2, but if you're developing that product, at least give your users something instead of leaving them with nothing. Otherwise, they may end up choosing poor alternatives. reply dtgm92 3 hours agoprevI will recommend Librewolf. Default Firefox has a lot of garbage and bloat. reply rtawsc 4 hours agoprevDarn, ublock also no longer works on Firefox for YouTube. At the beginning of each video there is one forced ad and sometimes the video stops for no reason. I suppose they want everyone to stop using the Internet and read books. reply atmavatar 3 hours agoparentI run uBO on FF, and I've yet to see any forced ads or video stops. I'm on FF 131.0.2 with uBO 1.60.0. reply zamalek 22 minutes agorootparentAre you on premium. YouTube seemingly doesn't care about my adblocker because I am on premium. reply deadbunny 3 hours agoparentprevWorks for me. I have Youtube on constantly when at my desk as background noise and uBo is still blocking everything perfectly fine. Edit: Seems Google/Youtube are experimenting/testing with injecting ads directly into the video streams: https://old.reddit.com/r/uBlockOrigin/comments/1de9kv5/youtu... reply aspenmayer 3 hours agoparentprevYou probably need to update your filter lists. There is a megathread on Reddit for this issue, because it can have a lot of other causes also. https://old.reddit.com/r/uBlockOrigin/comments/1etvawp/youtu... reply archerx 4 hours agoparentprevThe Brave Browser still blocks YouTube ads. reply eek2121 3 hours agoparentprevDisable all other extensions and update your lists. It will work then. reply imbnwa 1 hour agoprevWhy is this thread not on the first 4 or 5 pages of HN? reply greenie_beans 3 hours agoprevcan i just setup dns blocking on my network to block the ad requests? especially on youtube, ublock origin stopped working a few weeks ago. reply sunshowers 0 minutes agoparentSo yes... but the issue with DNS blocking is in the exceptions. First, exceptions are at the domain level. So you can't say \"allow this domain on this site\", you have to blanket-allow a domain or not. Second, the UX for making exceptions isn't great. With uBO it's just a couple of clicks. With something like Pi-hole it's more complex: https://discourse.pi-hole.net/t/how-do-i-whitelist-or-blackl... reply WesolyKubeczek 3 hours agoparentprevNot enough, especially since your browser may weasel out of it by using its own DNS via DoH. reply surajrmal 3 hours agorootparentAre you aware of any that do this? I've been using pihole for years and have no complaints. I've only seen smart TVs seem to do this, although it's usually configurable. reply ck2 4 hours agoprevTime to try Supermium again, I couldn't get it to install using my Chrome profile last time, maybe fixed by now. Unless Supermium is following the manifest path too? Doubt it. https://en.wikipedia.org/wiki/Supermium reply WesolyKubeczek 3 hours agoprevI wish some brave enough (no relation to Brave) soul patched Blink so it became possible to delegate URL blocking decisions to an external process via some sort of IPC. In goes a full URL and maybe an opaque session ID so some state may be tracked, out goes a boolean value. Assume all are allowed if this process cannot be connected to. reply est 4 hours agoprev [–] Can't we avoid the Manifest bullshit altogether? I remember how IE plugins roles: just dll inject into the process. reply emestifs 4 hours agoparentInject dll's from the internet right into the browser. Yes, let's! reply yjftsjthsd-h 3 hours agorootparentI'm not convinced that this is a good idea, but I don't think that's the reason; don't all your dlls come from the internet? reply emestifs 3 hours agorootparentMy comment was sarcasm. The difference here is are you downloading a random dll from a well known source or from http://free-vpn-fast-internet.dwnloadfree.ru/free-chrome-vpn...? My mom isn't going to know the difference and will click the big green DOWNLOAD NOW button blindly. reply yjftsjthsd-h 2 hours agorootparentBut that's not a difference, is it? Can't Windows enforce that DLLs have to be signed just like extensions? reply arp242 4 hours agoparentprev [–] Why not avoid all this unnecessary DDL overhead and just load as a kernel module? reply betaby 3 hours agorootparent [–] TempleOS https://en.wikipedia.org/wiki/TempleOS reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google is phasing out Manifest V2 for Chrome extensions, with warnings and disabling of these extensions starting on pre-stable channels as of October 9, 2024.",
      "Users are encouraged to transition to Manifest V3 alternatives, with enterprises having until June 2025 to complete the transition using the ExtensionManifestV2Availability policy.",
      "The phase-out process began on June 3, 2024, and the Chrome Web Store has not accepted new Manifest V2 extensions since June 2022 for private and January 2022 for public or unlisted extensions."
    ],
    "commentSummary": [
      "Chrome is transitioning from Manifest V2 to Manifest V3 extensions, affecting ad blockers such as uBlock Origin by limiting their capabilities.- While Chrome is making this shift, browsers like Firefox, Vivaldi, and Brave intend to continue supporting Manifest V2 for the time being.- This change has prompted discussions on user control and privacy, with some users contemplating switching to alternative browsers to retain effective ad-blocking features."
    ],
    "points": 198,
    "commentCount": 194,
    "retryCount": 0,
    "time": 1728656426
  },
  {
    "id": 41808696,
    "title": "A Lisp compiler to RISC-V written in Lisp",
    "originLink": "http://www.ulisp.com/show?4Y20",
    "originBody": "Home Reference Forum uLisp Getting started Lisp for microcontrollers Performance Using uLisp Using uLisp from a terminal Integral documentation Debugging in uLisp Using the program editor SD card interface I2C and SPI serial interfaces Lisp Library Download and install uLisp uLisp Sensor Library Forum Self-contained Lisp computers LilyGO T-Deck uLisp Machine Lisp Badge LE Lisp Badge Pocket Op Amp Lab Tiny Lisp Computer 8/16-bit platforms Arduino Uno and Nano Arduino Mega 2560 ATmega1284 ATmega4809 boards AVR DA and DB series boards 32/64-bit platforms Arduino M0 boards Adafruit M0 boards QT Py SAMD21 and XIAO SAMD21 Adafruit Neo Trinkey Adafruit M4 boards Adafruit PyGamer and PyBadge Seeed Studio Wio Terminal Adafruit nRF52840 boards Circuit Playground Bluefruit Seeed Studio XIAO nRF52840 BBC Micro:bit and Calliope Mini Maxim MAX32620FTHR Teensy 4.0 and 4.1 Raspberry Pi RP2040 boards Adafruit RP2040 Feather boards QT Py RP2040 and XIAO RP2040 LILYGO T-Display RP2040 Arduino Uno R4 Boards Raspberry Pi Pico 2 Adafruit ESP32 Feather boards Adafruit QT Py ESP32 Pico Other ESP32 boards ESP32-S2, ESP-S3, and ESP-C3 boards ESP32 boards with a TFT display Sipeed MAiX RISC-V boards Simple examples Blinking primes Tweetmaze Mood light LED 8x8 dot-matrix display Simon game I2C clock Data logging Ringing the changes Driving DotStar RGB LEDs LCD character display DDS signal generator Temperature sensor Simple data plotter Thermocouple interface Benchmarks Games Animals Eliza chatbot Simple arcade game Simple maze game Bulls & Cows game Mini text adventure game Larger examples Route finder Calculating with fractions Infinite precision arithmetic Scrolling text display Dot-matrix clock Graphics display interface in Lisp Plotting to a colour TFT display GPS interface using uLisp GPS mapping application Query language uLisp GSM server A LoRaWAN node using uLisp Solving resistor networks Fast Fourier Transform Sudoku solver Automatic uLisp to C converter A Lisp compiler to ARM written in Lisp A Lisp compiler to RISC-V written in Lisp New! Simple object system Graphics examples Graphics utilities Plotting the Hofstadter Q sequence Surface of rotation Ray tracing with uLisp Prime number spiral Dragon curve Mandelbrot set Barnsley Fern Wi-Fi examples Wi-Fi examples Wireless message display Assemblers AVR assembler overview AVR assembler examples AVR NeoPixel driver using assembler ARM assembler overview ARM assembler instructions ARM assembler examples ARM NeoPixel driver using assembler RISC-V assembler overview RISC-V assembler instructions RISC-V assembler examples Mandelbrot set using assembler Returning a floating-point result Tutorials Getting started Lists Expressions Defining functions Variables Strings Testing a result Manipulating lists Processing items in a list Recursion Returning functions Lisp for C programmers Thinking in a Lispy way Reference Language reference Floating-point extensions Graphics extensions Wi-Fi extensions Programming AVR registers Programming ARM registers Error messages Preloading functions in uLisp Adding useful functions to uLisp Implementation Implementation Objects Symbols Built-in symbols Strings Arrays Read, Evaluate, Print Garbage collection Tail-call optimization Saving and loading images Extended RAM New! Assembler and defcode ARM assembler written in Lisp New! Debugging uLisp Adding your own functions Converting between C and uLisp Porting uLisp to a new platform uLisp Builder uLisp Zero uLisp extensions Adding your own functions Arbitrary-precision arithmetic extension NeoPixel extension T-Deck screen capture Other information FAQ About me Contact Legal stuff RSS Feed uLisp news! A Lisp compiler to RISC-V written in Lisp 11TH OCTOBER 2024 This is a simple experimental Lisp compiler, written in uLisp, that will compile a Lisp function into RISC-V machine code. You can run the compiler on the RISC-V core of a Raspberry Pi Pico 2 (or another RP2350-based board): It's based on my earlier project A Lisp compiler to ARM written in Lisp. Introduction When I added the facility of executing machine code to uLisp I had in mind the eventual goal of being able to compile uLisp functions into machine code, and this is a first step in that direction. The nice thing about compiling Lisp is that you don't have to write a tokeniser or parser, because Lisp programs are already in a consistent structure that can be processed by another Lisp program. The compiler program is written in the subset of Common Lisp supported by uLisp, and will run on the RISC-V core of a RP2350-based board; I used a Raspberry Pi Pico 2. You can also run it using Common Lisp on a laptop or desktop computer, and display the code it generates, but of course you won't be able to run the RISC-V machine code because Common Lisp doesn't have uLisp's defcode command. I got my initial inspiration for this compiler from Peter Norvig's book \"Paradigms of Artificial Intelligence Programming\" [1]. Resources To use the compiler you first need to load the RISC-V assembler from: RISC-V assembler in uLisp. Get the full source of the compiler here: Lisp compiler for RISC-V. Or from GitHub here: https://github.com/technoblogy/lisp-arm-compiler. For information about setting up uLisp on a Raspberry Pi Pico 2 see: Raspberry Pi Pico 2. Using the compiler To run the compiler you simply call compile on a Lisp function; for example: (compile 'fibonacci) The function will be compiled into a machine code function, replacing the original Lisp code, so that calling fibonacci will now execute the RISC-V machine-code version. You can also display the code generated for an expression by calling comp on the expression; for example: (pprint (comp '(* 13 17))) (:integer ($li 'a0 13) ($addi 'sp 'sp -4) ($sw 'a0 0 '(sp)) ($li 'a0 17) ($lw 'a1 0 '(sp)) ($addi 'sp 'sp 4) ($mul 'a0 'a1 'a0)) The :integer prefix shows that the result is an integer; see below. For examples of several simple Lisp programs that it will successfully compile see Examples below. These also give a comparison of the speed of the Lisp and machine-code versions. Specification The compiler understands the following Lisp objects: Defining variables and functions: defun, setq Symbols: nil, t List functions: car, cdr Arithmetic functions: +, -, *, /, mod, 1+, 1- Arithmetic comparisons: =, , >=, /= Conditionals: if, and, or Tail-call optimisation Although the compiler doesn't include any iteration constructs, it does provide tail-call optimisation which can make recursive programs as efficient as iterative ones. Consider this recursive program to add two positive numbers: (defun add (a b) (if (= b 0) a (add (+ a 1) (- b 1)))) On a system without tail-call optimisation, evaluating: (add 10000 10000) will probably fail, because it requires 10000 stack frames to store the intermediate results. This compiler recognises that the recursive call to add can be replaced by a jump to the start of the program, and so it has no problem evaluating it. For a more sensible example see factor below. How the compiler works Register usage To avoid needing to keep track of register usage the compiler makes use of the stack to pass values to an expression, and store the value returned by an expression. The following table shows how the RISC-V registers are used within the compiler: Registers Use a0 a1 a2 a3 Used to pass the parameters to the main function's arguments. a0 Contains the value returned by the main function. a4 a5 a6 a7 Contain copies of the function arguments within the function. a0 a1 Used to pass the arguments to each operator. a0 Used to return the value from each operator. s0 to s11 Local variables. Compiling an expression The following steps show the sequence of compiling an expression, such as: (* x 13) Code is generated to evaluate each of the arguments, in this case x and 13, and each result is pushed onto the stack, apart from the last which is left in a0. The first value is popped from the stack into register a1. The function, in this case *, is then evaluated for a1 and a0, with the result in a0. This stack-based approach ensures that a more complex expression, such as: (* (- x 1) (+ x 13)) will also compile into correct code, without conflicts between registers. Calling the function recursively The compiler supports calling a function recursively from within the function itself. Because the registers corresponding to the parameters and local variables would be overwritten by the recursive call they are stored on the stack around the function call. There are several recursive functions in the examples below. Types For boolean operations I decided to represent nil as 0, and t as 1. A problem I hadn't anticipated was that I would need to keep track of what type of object each function returned, integer or boolean. For example, consider the problem of compiling the statement: (and x y) If x has the value 0 and y has the value 7 this should return 7. However, if x has the value nil and y has the value 7 this should return nil. Representing nil as zero leads to an ambiguity. I solved this by returning a type, :integer or :boolean, with each compiled expression, according to the following rules: Predicates, and t or nil, always return a :boolean. Arithmetic operations always return an :integer. An if form requires a :boolean test form and returns an :integer. A progn or let block returns the type of its last expression. An item with an ambiguous type returns the type nil. Running the examples I used the following simple examples to test the compiler. Before compiling a new function you might want to remove the previous one from memory using makunbound to free up the code memory before compiling the next function; for example: (makunbound 'fibonacci) Alternatively you could increase the amount of memory available for machine code by editing the directive such as: #define CODESIZE 256 before uploading uLisp to your board. Examples The following examples take integer arguments and return an integer result. Factor This function takes a simple approach to finding the least prime factor of a number: (defun factor (n d) (if (> (* d d) n) n (if (= 0 (mod n d)) d (factor n (1+ d))))) It should be called with n equal to the number to be factorized, and d=2. It takes advantage of the compiler's tail-call optimisation, which makes it as efficient as an iterative solution. If the number is prime, factor will print the number itself. To find the least prime factor of 2146654199 (46327 x 46337): Lisp version: > (time (factor 2146654199 2)) 46327 Time: 5.4 s Compiled version: > (time (factor 2146654199 2)) 46327 Time: 19 ms You can use the above function as the basis for a simple recursive routine to factorize a number into a list of its prime factors: (defun factorize (n) (let ((f (factor n 2))) (if (= n f) (list n) (cons f (factorize (/ n f)))))) For example: > (factorize 731731731) (3 17 43 333667) Takeuchi function This is a version of the highly-recursive benchmark I use for comparing versions of Lisp [2]: (defun tak (x y z) (if (>= y x) z (tak (tak (1- x) y z) (tak (1- y) z x) (tak (1- z) x y)))) Lisp version: > (time (tak 18 12 6)) 7 Time: 4.1 s Compiled version > (time (tak 18 12 6)) 7 Time: 16 ms Factorial This is a recursive implementation of the factorial function: (defun fact (n) (if ( (time (fact 12)) 479001600 Time: 1 ms Compiled version > (time (fact 12)) 479001600 Time: 0 ms Fibonacci This is a recursive implementation of the Fibonacci series: (defun fibonacci (n) (if ( (time (fibonacci 27)) 196418 Time: 50.5 s Compiled version > (time (fibonacci 27)) 196418 Time: 80 ms Greatest Common Divisor A recursive algorithm to calculate the greatest common divisor of two integers. (defun gcd (a b) (if (= b 0) a (gcd b (mod a b)))) Lisp version: > (time (gcd 2032460032 2056252672)) 256 Time: 1 ms Compiled version > (time (gcd 2032460032 2056252672)) 256 Time: 0 ms Hofstadter Q sequence This is one of several recursive sequences described in Douglas Hofstadter's book \"Gödel, Escher, Bach: an Eternal Golden Braid\". It is defined as follows: (defun q (n) (if ( (time (q 21)) 12 Time: 8.6 s Compiled version > (time (q 21)) 12 Time: 25 ms Two-dimensional recursive function Q2 This function Q2 is my two-dimensional extension of the Hofstadter Q sequence [3]: (defun q2 (x y) (if (or ( (time (q2 7 8)) 31 Time: 13.8 s Compiled version > (time (q2 7 8)) 31 Time: 50 ms Number of combinations - nCr This is a simple but very inefficient way of recursively calculating nCr, based on Pascal's Triangle: (defun ncr (n r) (if (or (= r 0) (= r n)) 1 (+ (ncr (1- n) (1- r)) (ncr (1- n) r)))) For example, to calculate the number of possible poker hands from a pack of cards: Lisp version: > (time (ncr 52 5)) 2598960 Time: 615.5 s Compiled version > (time (ncr 52 5)) 2598960 Time: 1.7 s List examples Any of the arguments to a machine-code function can be a list, in which case the address of the list is passed to the routine in the corresponding parameter. You can then use the functions car and cdr to process the elements in the list. Dot product This recursive function calculates the dot product of two vectors: (defun dot-product (a b) (if (and a b) (+ (* (car a) (car b)) (dot-product (cdr a) (cdr b))) 0)) It can handle two vectors of arbitrary length provided they are the same length. For example, to calculate the following dot product: (987 654 321) • (963 852 741) = 987 × 963 + 654 × 852 + 321 × 741 = 1745550 Lisp version: > (time (dot-product '(987 654 321) '(963 852 741))) 1745550 Time: 0 ms Compiled version > (time (dot-product '(987 654 321) '(963 852 741))) 1745550 Time: 0 ms Compiler source Here's a description of the source of the compiler. Invoking the compiler To compile a Lisp function you simply give the command compile followed by the name of the function; for example, to compile the fibonacci function: (compile 'fibonacci) Here's the definition of the command compile: (defun compile (name) (if (eq (car (eval name)) 'lambda) (eval (comp (cons 'defun (cons name (cdr (eval name)))))) \"Not a Lisp function\")) Main compiler function The main function comp returns the compiled code for an expression or form, as a list of assembler instructions prefixed by the type, :integer or :boolean: (defun comp (x &optional env tail) (cond ((null x) (type-code :boolean '(($li 'a0 0)))) ((eq x t) (type-code :boolean '(($li 'a0 1)))) ((symbolp x) (comp-symbol x env tail)) ((atom x) (type-code :integer (list (list '$li ''a0 x)))) (t (let ((fn (first x)) (args (rest x))) (case fn (defun (setq *label-num* 0) (setq env (mapcar #'(lambda (x y) (cons x y)) (second args) *locals*)) (comp-defun (first args) (second args) (cddr args) env)) (progn (comp-progn args env tail)) (if (comp-if (first args) (second args) (third args) env tail)) (setq (comp-setq args env tail)) (t (comp-funcall fn args env tail))))))) The function comp takes the item x to be compiled, the current environment env associating each local variable with a register, and a flag tail which is true if the item has no successors. Each of the different types of form are handled by separate functions such as comp-defun, comp-if, and comp-progn. Utilities The compiler uses the following utility functions: The functions push-regs and pop-regs generate instructions to push a list of registers to the stack, and pop a list of registers from the stack: (defun push-regs (&rest regs) (let ((n -4)) (append (list (list '$addi ''sp ''sp (* -4 (length regs)))) (mapcar #'(lambda (reg) (list '$sw (list 'quote reg) (incf n 4) ''(sp))) regs)))) (defun pop-regs (&rest regs) (let ((n (* 4 (length regs)))) (append (mapcar #'(lambda (reg) (list '$lw (list 'quote reg) (decf n 4) ''(sp))) regs) (list (list '$addi ''sp ''sp (* 4 (length regs))))))) The function mappend applies a function to the elements of a list, and the results, which should be lists, are appended together: (defun mappend (fn lst) (apply #'append (mapcar fn lst))) The function type-code adds a code type label to the front of a list of assembler instructions, and the functions code-type and code return the code type label, and the code list, respectively: (defun type-code (type code) (cons type code)) (defun code-type (type-code) (car type-code)) (defun code (type-code) (cdr type-code)) The function checktype gives an error if the value returned is not the correct type: (defun checktype (fn type check) (unless (or (null type) (null check) (eq type check)) (error \"Argument to '~a' must be ~a not ~a~%\" fn check type))) The lists *params* and *locals* list the registers available for use in the compiler: (defvar *params* '(a0 a1 a2 a3)) (defvar *locals* '(a4 a5 s0 s1 a6 a7 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11)) Finally, gen-label generates a new label for use in branches and jumps: (defvar *label-num* 0) (defun gen-label () (read-from-string (format nil \"lab~d\" (incf *label-num*)))) The remaining functions handle the compiling of specific types of Lisp form: Symbols The environment is represented by an association list giving the register associated with each variable, such as: ((y . r5) (x . r4)) The function comp-symbol looks up a symbol in the association list and returns the appropriate register: (defun comp-symbol (x env) (let ((reg (cdr (assoc x env)))) (type-code nil (list (list '$mv ''a0 (list 'quote reg)))))) Assignment The function comp-setq handles assignment to a variable: (defun comp-setq (args env tail) (let ((value (comp (second args) env tail)) (reg (cdr (assoc (first args) env)))) (type-code (code-type value) (append (code value) (list (list '$mv (list 'quote reg) ''a0)))))) Function definition The definition of the function being compiled is handled by comp-defun: (defun comp-defun (name args body env) (setq *used-params* (subseq *locals* 0 (length args))) (append (list 'defcode name args) (list name) (apply #'append (mapcar #'(lambda (x y) (list (list '$mv (list 'quote x) (list 'quote y)))) *used-params* *params*)) (code (comp-progn body env t)))) Progn special form The function comp-progn compiles a progn form: (defun comp-progn (exps env tail) (let* ((len (1- (length exps))) (nlast (subseq exps 0 len)) (last1 (nth len exps)) (start (mappend #'(lambda (x) (append (code (comp x env t)))) nlast)) (end (comp last1 env tail))) (type-code (code-type end) (append start (code end))))) It compiles code to evaluate each expression in the body of the progn, discarding all but the last results, and returns the type of the last form as the type of the whole block. If special form The function comp-if compiles the code for an if special form: (defun comp-if (pred then else env tail) (let ((lab1 (gen-label)) (lab2 (gen-label)) (test (comp pred env nil))) (checktype 'if (car test) :boolean) (type-code :integer (append (code test) (list (list '$beqz ''a0 lab1)) (code (comp then env t)) (list (list '$j lab2) lab1) (code (comp else env tail)) (list lab2) (when tail '(($ret))))))) Function calls Finally, comp-funcall compiles code for function calls to the built-in functions, or a recursive call to the main function: (defun comp-funcall (f args env tail) (let ((test (assoc f '(( . $sgt)))) (teste (assoc f '((= . $seqz) (/= . $snez)))) (testn (assoc f '((>= . $slt) ( (length args) 1) (append (list (list '$mv (list 'quote (nth (1- (length args)) *params*)) ''a0)) (apply #'pop-regs (subseq *params* 0 (1- (length args)))))) (cond (tail (list (list '$j f))) (t (append (apply #'push-regs (cons 'ra (reverse *used-params*))) (list (list '$jal f)) (apply 'pop-regs (append *used-params* (list 'ra)))))))))))) The arithmetic comparisons take advantage of the RISC-V instructions such as slt (Set if less than), which set the destination register to 0 if the comparison is false, and to 1 if it's true; this provides the required boolean result without needing a branch. The function comp-funcall uses the routine comp-args to generate code to compile each of the arguments to a function: (defun comp-args (fn args n type env) (unless (or (null n) (= (length args) n)) (error \"Incorrect number of arguments to '~a'\" fn)) (let ((n (length args))) (mappend #'(lambda (y) (let ((c (comp y env nil))) (decf n) (checktype fn type (code-type c)) (if (zerop n) (code c) (append (code c) (push-regs 'a0))))) args))) Appendix The following example shows the code generated by a simple function, rec, a recursive function related to the factorial function: (defun rec (n) (1+ (* n (if (= n 0) 0 (rec (1- n)))))) Compiling this gives the following RISC-V machine code: > (compiler 'rec) 0000 rec 0000 872a ($mv 'a4 'a0) 0002 853a ($mv 'a0 'a4) 0004 1171 ($addi 'sp 'sp -4) 0006 c02a ($sw 'a0 0 '(sp)) 0008 853a ($mv 'a0 'a4) 000a 1171 ($addi 'sp 'sp -4) 000c c02a ($sw 'a0 0 '(sp)) 000e 4501 ($li 'a0 0) 0010 4582 ($lw 'a1 0 '(sp)) 0012 0111 ($addi 'sp 'sp 4) 0014 8533 ($sub 'a0 'a1 'a0) 0016 40a5 0018 3513 ($seqz 'a0 'a0) 001a 0015 001c c119 ($beqz 'a0 lab1) 001e 4501 ($li 'a0 0) 0020 a819 ($j lab2) 0022 lab1 0022 853a ($mv 'a0 'a4) 0024 157d ($addi 'a0 'a0 -1) 0026 1161 ($addi 'sp 'sp -8) 0028 c006 ($sw 'ra 0 '(sp)) 002a c23a ($sw 'a4 4 '(sp)) 002c f0ef ($jal rec) 002e fd5f 0030 4712 ($lw 'a4 4 '(sp)) 0032 4082 ($lw 'ra 0 '(sp)) 0034 0121 ($addi 'sp 'sp 8) 0036 lab2 0036 4582 ($lw 'a1 0 '(sp)) 0038 0111 ($addi 'sp 'sp 4) 003a 8533 ($mul 'a0 'a1 'a0) 003c 02a5 003e 0505 ($addi 'a0 'a0 1) 0040 8082 ($ret) Trying it out: > (rec 12) 1302061345 This example demonstrates how the RISC-V Lisp assembler takes advantage of 16-bit compressed instructions where possible, instead of the equivalent full 32-bit instructions. ^ Norvig, Peter \"Paradigms of Artificial Intelligence Programming\" Morgan Kaufmann Publishers, Inc, San Francisco, 1992, pp 784-833, available as a PDF paip-lisp on GitHub. ^ Benchmarks - Takeuchi function. ^ Benchmarks - Two-dimensional recursive function Q2. Previous: A Lisp compiler to ARM written in Lisp Next: Simple object system Copyright 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41808696",
    "commentBody": "A Lisp compiler to RISC-V written in Lisp (ulisp.com)192 points by chrisjj 7 hours agohidepastfavorite29 comments Joker_vD 23 minutes agoThis is all very neat and all but could anyone please explain to me how this thing handles forward label resolution e.g. in the \"if\" construct? I think I know how it does that but I am very likely to be be wrong. reply kragen 55 minutes agoprevI don't think it's yet complete enough to compile itself; though I haven't looked at the assembler code, I'm pretty sure it requires bitwise operations the compiler can't compile yet. Also, the compiler itself requires things like null, symbolp, eq, and atom, which it also doesn't implement yet. Without those I'm not sure that it's fair to describe its input language as Lisp, though it does support car and cdr. But it's still super cool. A really great thing about Lisp for purposes like this is that you don't get hung up on syntax and parsing, which is the most salient part of writing a compiler but not the most important. reply reikonomusha 4 hours agoprevSBCL is a Common Lisp compiler written in Common Lisp that also can target RISC-V. reply amszmidt 4 hours agoparentCan it run on the MCU mentioned in the post? Somehow I doubt that. Can SBCL even target MCU boards like the pico? reply AyyEye 4 hours agorootparentnext [3 more] Second sentence from TFA: > You can run the compiler on the RISC-V core of a Raspberry Pi Pico 2 (or another RP2350-based board) reply McGuffin 4 hours agorootparentWhat article are you referring to? (Specifically, the parent comment asked about SBCL, Steel Bank Common Lisp, running on the pico 2, not about uLISP) reply AyyEye 3 hours agorootparentNo more comments before coffee for me. reply dang 7 minutes agoprevEdit: It's a pity we missed http://www.ulisp.com/show?4W2I. It was posted (https://news.ycombinator.com/item?id=41190553) but didn't get attention. We'd have put it in the SCP for sure (https://news.ycombinator.com/item?id=26998308) if we had seen it. --- Related. Others? uLisp: Lisp for Microcontrollers - https://news.ycombinator.com/item?id=41681705 - Sept 2024 (1 comment) An ARM Assembler Written in Lisp - https://news.ycombinator.com/item?id=36646277 - July 2023 (31 comments) uLisp wireless message display with a Pi Pico W - https://news.ycombinator.com/item?id=32722475 - Sept 2022 (6 comments) Visible Lisp Computer: embedded real-time display of Lisp workspace using uLisp - https://news.ycombinator.com/item?id=30612770 - March 2022 (7 comments) uLisp on the Raspberry Pi Pico - https://news.ycombinator.com/item?id=29970231 - Jan 2022 (14 comments) uLisp - https://news.ycombinator.com/item?id=27036317 - May 2021 (87 comments) Lisp Badge: A single-board computer that you can program in uLisp - https://news.ycombinator.com/item?id=23729970 - July 2020 (25 comments) A new RISC-V version of uLisp - https://news.ycombinator.com/item?id=22640980 - March 2020 (35 comments) uLisp – ARM Assembler in Lisp - https://news.ycombinator.com/item?id=22117241 - Jan 2020 (49 comments) Ray tracing with uLisp - https://news.ycombinator.com/item?id=20565559 - July 2019 (10 comments) uLisp: Lisp for microcontrollers - https://news.ycombinator.com/item?id=18882335 - Jan 2019 (16 comments) GPS mapping application in uLisp - https://news.ycombinator.com/item?id=18466566 - Nov 2018 (4 comments) Tiny Lisp Computer 2 - https://news.ycombinator.com/item?id=16347048 - Feb 2018 (2 comments) uLisp – Lisp for the Arduino - https://news.ycombinator.com/item?id=11777662 - May 2016 (33 comments) reply spsesk117 6 hours agoprevulisp is an incredible achievement and has brought me a lot of joy. There is something very fun about writing lisp for an Arduino nano, and trying to golf your intentions into ~300 characters :) reply bongodongobob 2 hours agoparentThat's neat but I don't know why you'd minimize characters rather than ROM size for a microcontroller. reply bloopernova 5 hours agoprevI got a RP2350 \"Feather\"[1] from Adafruit[2]. Amazing little thing, with lots of stuff built-in. The lipoly charge port is super useful and Just Works, and the STEMMA QT connector means no soldering or breadboards for simple projects. My main half-baked idea for this is to control a CPU usage monitor[3], but I also want to make some better lights for my Lego SHIELD Helicarrier, and maybe add some movement too. And now you're telling me I can use Lisp on this? It would be interesting to see how streamlined the development process is for each one of uLisp, CircuitPython, MicroPython, and Arduino/C. [1] https://www.adafruit.com/product/6000 [2] https://www.adafruit.com/newThere is something about RISC-V that really inspires lots of hackers \"Not Arm\" :) reply trq01758 4 hours agoparentprevSimplicity, it's a modern MOS 6502. Base RISC-V has even less instructions than 6502. reply acegopher 1 hour agorootparentThe same could be said of the ARM Cortex-M0+. reply kragen 52 minutes agorootparentThe Cortex-M0's Thumb-1 is a really unpleasant instruction set compared to ARM, Thumb-2, RISC-V, or ARM64. reply Joker_vD 3 hours agorootparentprevAlso it has less registers (32 vs. 256 in the zero page) and less addressing modes. reply wk_end 23 minutes agorootparentBut the 6502's \"registers\" are much smaller and you can do much less with them. You can't really sensibly compare the two approaches so superficially. reply pjmlp 5 hours agoprevI see Lisp compilers and upvote. :) Great work. reply hinkley 1 hour agoprevGretchen! Stop trying to make Lisp happen. It’s not going to happen. reply neuroelectron 6 hours agoprev [3 more] [flagged] johnsondavies 6 hours agoparentSorry, I'd posted the link to the code in the wrong format - corrected now. Would you like to delete that copy? reply bee_rider 5 hours agoparentprev [–] Wait it fits in a comment? What sort of magic is this? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "uLisp is a version of the Lisp programming language designed for microcontrollers, supporting platforms like Arduino, Raspberry Pi, and ESP32.- It includes features such as debugging, SD card interface, and I2C/SPI serial interfaces, with examples for applications like LED blinking and data logging.- A significant feature is the Lisp compiler for RISC-V, which compiles Lisp functions into machine code, supporting recursive functions and tail-call optimization for improved performance."
    ],
    "commentSummary": [
      "A Lisp compiler for RISC-V, written in Lisp, is under development but lacks certain operations and functions to be self-compiling.- The compiler supports basic Lisp functions like car and cdr, but is not yet complete.- uLisp is highlighted for its simplicity and suitability for microcontrollers, with RISC-V being an attractive platform for tech enthusiasts and hackers."
    ],
    "points": 192,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1728647817
  },
  {
    "id": 41807681,
    "title": "Nobel Peace Prize for 2024 awarded to Nihon Hidankyo",
    "originLink": "https://www.nobelprize.org/press-release-peace-2024/",
    "originBody": "Press release Navigate to: Summary - Nihon Hidankyo Prize announcement Press release English Norwegian Announcement The Norwegian Nobel Committee has decided to award the Nobel Peace Prize for 2024 to the Japanese organisation Nihon Hidankyo. This grassroots movement of atomic bomb survivors from Hiroshima and Nagasaki, also known as Hibakusha, is receiving the Peace Prize for its efforts to achieve a world free of nuclear weapons and for demonstrating through witness testimony that nuclear weapons must never be used again. In response to the atomic bomb attacks of August 1945, a global movement arose whose members have worked tirelessly to raise awareness about the catastrophic humanitarian consequences of using nuclear weapons. Gradually, a powerful international norm developed, stigmatising the use of nuclear weapons as morally unacceptable. This norm has become known as “the nuclear taboo”. The testimony of the Hibakusha – the survivors of Hiroshima and Nagasaki – is unique in this larger context. These historical witnesses have helped to generate and consolidate widespread opposition to nuclear weapons around the world by drawing on personal stories, creating educational campaigns based on their own experience, and issuing urgent warnings against the spread and use of nuclear weapons. The Hibakusha help us to describe the indescribable, to think the unthinkable, and to somehow grasp the incomprehensible pain and suffering caused by nuclear weapons. The Norwegian Nobel Committee wishes nevertheless to acknowledge one encouraging fact: No nuclear weapon has been used in war in nearly 80 years. The extraordinary efforts of Nihon Hidankyo and other representatives of the Hibakusha have contributed greatly to the establishment of the nuclear taboo. It is therefore alarming that today this taboo against the use of nuclear weapons is under pressure. The nuclear powers are modernising and upgrading their arsenals; new countries appear to be preparing to acquire nuclear weapons; and threats are being made to use nuclear weapons in ongoing warfare. At this moment in human history, it is worth reminding ourselves what nuclear weapons are: the most destructive weapons the world has ever seen. Next year will mark 80 years since two American atomic bombs killed an estimated 120 000 inhabitants of Hiroshima and Nagasaki. A comparable number died of burn and radiation injuries in the months and years that followed. Today’s nuclear weapons have far greater destructive power. They can kill millions and would impact the climate catastrophically. A nuclear war could destroy our civilisation. The fates of those who survived the infernos of Hiroshima and Nagasaki were long concealed and neglected. In 1956, local Hibakusha associations along with victims of nuclear weapons tests in the Pacific formed the Japan Confederation of A- and H-Bomb Sufferers Organisations. This name was shortened in Japanese to Nihon Hidankyo. It would become the largest and most influential Hibakusha organisation in Japan. The core of Alfred Nobel’s vision was the belief that committed individuals can make a difference. In awarding this year’s Nobel Peace Prize to Nihon Hidankyo, the Norwegian Nobel Committee wishes to honour all survivors who, despite physical suffering and painful memories, have chosen to use their costly experience to cultivate hope and engagement for peace. Nihon Hidankyo has provided thousands of witness accounts, issued resolutions and public appeals, and sent annual delegations to the United Nations and a variety of peace conferences to remind the world of the pressing need for nuclear disarmament. One day, the Hibakusha will no longer be among us as witnesses to history. But with a strong culture of remembrance and continued commitment, new generations in Japan are carrying forward the experience and the message of the witnesses. They are inspiring and educating people around the world. In this way they are helping to maintain the nuclear taboo – a precondition of a peaceful future for humanity. The decision to award the Nobel Peace Prize for 2024 to Nihon Hidankyo is securely anchored in Alfred Nobel’s will. This year’s prize joins a distinguished list of Peace Prizes that the Committee has previously awarded to champions of nuclear disarmament and arms control. The Nobel Peace Prize for 2024 fulfils Alfred Nobel’s desire to recognise efforts of the greatest benefit to humankind. Oslo, 11 October 2024 To cite this section MLA style: Press release. NobelPrize.org. Nobel Prize Outreach AB 2024. Fri. 11 Oct 2024.Back to top",
    "commentLink": "https://news.ycombinator.com/item?id=41807681",
    "commentBody": "Nobel Peace Prize for 2024 awarded to Nihon Hidankyo (nobelprize.org)180 points by danielskogly 9 hours agohidepastfavorite238 comments kaon_ 9 hours agoAt home I have a book telling stories of Dutch WW2 survivors still living today. One of them was an eye witness account of the Hiroshima bomb. He was a POW and worked in a quarry or mine on the outskirts of town. He saw a single plane fly over. A bomb dropped with a parachute attached. Moments later he was flung to the back of the quarry and the city was gone. I would never have guessed there were eyewitnesses like this, let alone coutrymen of mine. reply trescenzi 6 hours agoparentThe book Hiroshima by John Hersey has many accounts like this. It’s a short read and follows six people and covers the first year after the bombing. I’d highly recommend reading it if such accounts are interesting to you. reply tirumaraiselvan 4 hours agorootparentIt was published in New Yorker https://www.newyorker.com/magazine/1946/08/31/hiroshima Fun fact the cover image if this edition was kind of a decoy (perhaps to accentuate the shock): https://www.newyorker.com/magazine/1946/08/31 reply ralfd 2 hours agorootparentWow, brutal! As an aside I would never had guessed this artstyle was a 40s cover. reply Metacelsus 7 hours agoparentprevLittle Boy didn't have a parachute. Maybe he was mis-remembering that. reply dogben 7 hours agorootparentThere were instruments dropped by parachute. reply tephra 6 hours agorootparentIIRC those were dropped by a second plane accompanying the Enola Gay. reply cchi_co 7 hours agoparentprevJust how widespread the effects of World War II were reply LeonM 8 hours agoparentprevWhich book is it? reply mppm 9 hours agoprevThis is indeed a very timely award. I sometimes feel like the world has forgotten that nuclear weapons still exist and are still on hair-trigger alert to obliterate major cities. Maybe the end of atmospheric testing and the success of (now defunct) weapons reduction treaties has blunted public perception to the ongoing threat that they represent, and to the need to tread carefully where nuclear powers are involved. reply vasco 9 hours agoparentIf I put a hammer over your head that can fall any minute you'll be worrying, but if you're born with the hammer over your head and your parents before you as well, it becomes less of a thing. reply jsbg 30 minutes agorootparentmaybe your parents aren't old enough to remember how much of the population could expect to die in wars before nuclear weapons (i.e. mutually assured destruction) existed reply vkou 1 hour agorootparentprevMy parents had no problem reminding us that we all live with a nuclear sword hanging over our heads. It just so happens that most people in the West are comfortable, are completely insulated from the consequences of war, and can't even imagine a regular war happening to them. And nuclear war is so much more horrifying and its consequences are so much beyond the pale, that people can't even think of what it would mean. reply Arrath 1 hour agorootparentOh I can imagine it happening. I'm currently working in Pearl Harbor and find myself hoping that I'll be on-base if the balloon goes up, thus avoiding any post-apocalyptic survival bullshit in a brilliant flash. reply sandworm101 9 hours agorootparentprevOn an individual level, we all have a variety of hammers over our heads. Cancer has killed far more people prematurely than nuclear weapons. Something like 500,000 people a year are murdered. Traffic/bicycle/pedestrian accidents also kill more than nuclear weapons. Even compared to a once-in-a-century nuclear war that perhaps kills a billion people, cancer will kill roughly a billion in the next century anyway. So, for the rational/selfish person, the nuclear threat isn't worth worrying about. reply LeifCarrotson 48 minutes agorootparentWorry is unproductive in the sense of feeling anxiety, sure, but it's noble to worry at the various hammers in the archaic definition to \"move, proceed, or progress by unceasing or difficult effort, to shake or pull at with the teeth.\" Some of the hammers such as the hammer representing nuclear weapons - are caused by people and can be solved by people. There's a big game theoretic hill to climb over, but social pressure and advocacy have been effective at making progress. Others, like cancer and general senescence, are more of a looming threat that's a fundamental characteristic of biology, we can (and should) worry at them to make incremental progress but we're unlikely to suddenly eliminate them. The murder rate is enormously dependent on individual location and individual relationships. Traffic/bicycle/pedestrian accidents are enormously dependent on individual behavior. Of those threats, addressing the problem of nuclear weapons - especially for a member of Nihon Hidankyo, with a personal and persuasive story of the damages these weapons caused - is probably near the top of the list for actions which can have the greatest positive change. reply squigz 8 hours agorootparentprevI'd like to think of myself as a rational person, yet I worry about it. Because it's not just a matter of math; the effects of a billion people dying at once would be far more detrimental than the deaths from cancer over a century. (One might think this line of reasoning that some people apply is a coping mechanism to ignore the reality, but that might be a different conversation) reply timeon 7 hours agorootparentBut it is not just about coping. We as society, can make policies to decrease chance of getting a cancer and decrease traffic deaths. We just chose not to out of convenience and profit. reply w0m 46 minutes agorootparentit's easier to ignore 100 papercuts than it is to ignore missing a hand. reply valval 0 minutes agorootparentYour analogy makes no sense whatsoever. More mundane causes of death aren’t paper cuts, and nuclear war isn’t losing a hand. IG_Semmelweiss 6 hours agorootparentprevIf I fall 1 feet one hundred times, I'll probably be Ok If I fall 100 feet once, I won't. 1m people dying in 1 day is not the same as 1M people dying over a decade. Also. People generally dont fear death itself. This is expressed by people in pallitative care. Its the chaos and uncertainty preceding death that is really feared reply wang_li 1 hour agorootparentIf that one million people dying is followed by 3649 days of no one dying from that cause, yes it is. reply kortilla 1 hour agorootparentNo, abrupt deaths are much more disruptive to society reply brightball 2 hours agorootparentprevI think for a lot of people, myself included, you try not to worry about things you can't control. \"Worrying is like a rocking chair. It gives you something to do, but it doesn't get you anywhere. Write that down.\" - Van Wilder reply jszymborski 1 hour agorootparentWhile this apathy is an important coping mechanism to some degree, it's important not to become complacent. It's precisely this apathy and hopelessness that authoritarian regimes cultivate to prevent action. reply dfxm12 38 minutes agorootparentI don't think this registers as apathy in this context. Maybe you live in a country that has nuclear weapons and can vote for one leader or another. This may or may not have some impact on things. Certainly, we cannot influence what other countries do with their arsenals. Our mental stacks can only run so deep & I'd wager for most of us, the things that are in our sphere of influence simply take priority. reply w4 4 hours agorootparentprev> So, for the rational/selfish person, the nuclear threat isn't worth worrying about. Until you have children and future generations to worry about. Then it suddenly seems quite a bit more pressing that their world could be obliterated at a moment's notice by a small handful of decision makers. reply BurningFrog 1 hour agorootparentSo what value do you get out of worrying about the nuclear threat, that makes it worth it? reply cynicalpeace 8 hours agorootparentprevThose other things are also worth worrying about too. Gee, I hope the people in charge don't think \"the nuclear threat isn't worth worrying about\" reply thimabi 8 hours agorootparentprevThat depends on where you live. There are people right now in certain places who are terrified of the nuclear threat. reply smokel 8 hours agorootparentprevExtrapolating from two samples to \"once-in-a-century\" does not strike me as rational. reply specialist 5 hours agorootparentprevDoes your risk assessment methodology also account for near misses? Agency? Morality? Source of risk? Costs of mitigation? Benefits? Something like actuary tables? Mitigation of bike and pedestrian deaths is cheap. Just reform land use, advantage people over vehicles. Oops, now you're into culture and values. Mitigation of cancer deaths is very expensive. Though we didn't invent cancer, we feel the moral imperative to \"cure\" it. And yet, while we're mitigating it, we're also making it worse. Cross purposes. What's your balance sheet for this conundrum? Drugs kill lots of people. We own that one, right? How's the War on Drugs working out? In conclusion, I wish I could wave away these dilemmas with a cute nominator and denominator. But I can barely reason about them before my head explodes. So I'm not buying what you're selling. Life's a bit more complicated, a bit more empirical, a bit less rational, than your tidy equations. reply mistrial9 2 hours agorootparentprevI once knew an academic who would not fly in an airplane. He was invited to a distinguished conference across the country, but complained to me that he was too scared to fly. \"Why?\" I ask.. \"Terrorists\" he replied.. \"it is too serious. I just can't do it\". so a year or two pass and then I see this Academic again. While talking he mentions that he just returned from a great conference far away. \"What? I thought you were afraid to fly in an airplane!\" .. He replies \"that was true, I was scared of someone carrying a bomb on the flight. But, I calculated the statistical odds of there being TWO bombs on a single plane, and it was infinitesimal...\" \"So now I carry my own!\" reply petra 8 hours agorootparentprevEverybody dies so there's nothing to fear from war? reply IG_Semmelweiss 6 hours agorootparentChaos , without death. reply faggotbreath 8 hours agorootparentprevYou have no idea what you’re talking about. 2 billion people will die in the first 70 minutes of a peer nuclear exchange. reply Ekaros 8 hours agorootparentWhy does that figure looks really suspicious to me. So in nuclear exchange there is either already fully setup blocks or the responding party will pull in others in? reply wdr1 3 hours agoparentprev> I sometimes feel like the world has forgotten that nuclear weapons still exist I don't understand this. Between Iran and the Russia/Ukraine conflict, they seem to be very top of mind for many. reply cchi_co 7 hours agoparentprevI agree completely. The award serves as a crucial reminder of the ever-present threat of nuclear weapons reply MisterBastahrd 2 hours agoparentprevThe entire purpose of nuclear armaments is to make certain wars too nasty to fathom engaging in. If their organization didn't exist at all, we'd still have exactly the same number of nuclear war casualties since the 1940s. reply Hammershaft 1 hour agorootparentInterdependence via global trade makes it unlikely that without nuclear weapons we would have nearly the number of wars we had in the 1940s. reply WillPostForFood 5 minutes agorootparentIn 1913, Norman Angell published a book called \"The Great Illusion\" in which he argued that the use of military force had become economically futile due to the interconnectedness of international finance and trade. World War I started one year later. Trade and interconnectedness probably have a net positive effect on reducing war, but not a reliable guarantee. reply mc32 5 hours agoparentprevTotally agree this is very relevant today. We have heads of state in the EU and to some degree people in the USG with very cavalier approaches to the ideological war between the West and the BRICS. I really don't know what the F* they are thinking but they keep pushing further and further and hope there is no elastic snap. It's like they forgot about diplomacy with enemies --at the height of the cold war, at its Apex in the Cuba Missile Crisis, we had communication with the enemy --it was inconceivable we would not have communications with them but now it's a wild west of bluster and provocation. I'm not saying were not right in tamping down aggression, but you have to be cognizant of the perils that exist. Quite striking is strident opponents of the Hiroshima/Nagasaki decision have few qualms about the prospects of current escalation. It's insane. reply Hammershaft 1 hour agorootparentBRICS? What ideological war is South Africa, India, and Brazil waging against the west? Members of Brics such as India and China are closer to war with each other then they are to war with the West. reply mppm 3 hours agorootparentprevI'm not sure why this got downvoted. The point is not to bow to Putin in all matters, but to treat the matter with extreme seriousness: Take time to do proper background research, evaluate your sources, give serious consideration to the Russian narrative -- without necessarily agreeing of course, allow for a margin of error both in your own judgement and for stray missiles entering the detection radius, etc. If it still seems like a good idea to take a stand afterwards, OK. But let's please not cause a nuclear war over Facebook likes and political brownie points. reply nrml_amnt 1 hour agorootparentWhat is the Russian narrative? How to give consideration for something that is not even meant to be sensical? reply seabass-labrax 2 hours agorootparentprevI haven't downvoted it, but one issue with parent's post is that it applies double standards to our nations' responses to those of the Cold War. During the 20th century, the public impression of diplomacy was the very same 'wild west of bluster and provocation' - only nowadays, we get to see more behind the scenes of the Cold War as files are declassified and then-current affairs become history. The propaganda from the American and Soviet leadership was no more nuanced historically than it is now from contemporary leaders like Putin and Trump (and since parent mentioned the EU, we could include European figures such as von der Leyen here as well). I predict that future history books will observe a certain amount of care and diplomatic engagement in our era that isn't visible from the press releases and the ways in which politicians want to be seen. reply nradov 2 hours agorootparentprevI don't know why you're bringing BRICS into this. Brazil and South Africa aren't nuclear powers (at least not anymore, and South Africa is an irrelevant failed state anyway). India isn't engaged in any sort of ideological war with the West. Their nukes are purely defensive to deter China and Pakistan. That leaves China and Russia. We learned during the Cold War that a policy of aggressive containment is effective and this should continue. Don't give them an inch. reply satvikpendem 7 hours agoprevI recently went to the Hiroshima museum. I had originally thought that people simply vaporized when the bomb hit, but that is not the case. The museum shows how people's skin simply sloughed off and some were holding parts in their hands as they walked around to find their loved ones. But the worst part was radiation poisoning. Many that did not initially get hit and burned directly went towards the center of the city to find their families and over the course of days, months and years, they almost always died a slow, painful death, with their teeth falling out and their skin and organs becoming necrotic. Truly, everyone should visit Hiroshima or Nagasaki at some point, if only to understand what true horrors nuclear weapons create. And those are only atomic weapons of the 1940s, the hydrogen bombs we have today that fuse instead of fiss are orders of magnitude more powerful, but at least those under their effects (near the epicenter) will die a quick vaporized death instantaneously. reply mppm 7 hours agoparentAs an addition (and correction) to this, powerful thermonuclear weapons don't vaporize anyone either. They are targeted for high-altitude airbursts and kill through a combination of burns and building collapse, plus secondary fires, infection and breakdown of emergency services. The majority of the victims would not die an instant death. For more information: https://nuclearweaponarchive.org/Nwfaq/Nfaq5.html reply seatac76 3 hours agoparentprevI had a similar experience, looking at the contorted metal lunchboxes and other household items was more terrifying, I always used to think things just go poof. reply lode 9 hours agoprevThis is the organisation that has won the 2024 Nobel Peace Prize: https://www.ne.jp/asahi/hidankyo/nihon/english/ reply cynicalpeace 8 hours agoprevPhenomenal choice. While 80 years is nice- it's a blip on the timescale of history. I personally think we're a button click away from going back to the stone age. I know others will disagree, but it's not something you wanna take a gamble on. I think it's one of the reasons we have to be self sustaining on other heavenly bodies. And also why wars or proxy wars between nuclear powers are extremely foolish and should be stopped with great urgency. reply palata 8 hours agoparent> I think it's one of the reasons we have to be self sustaining on other heavenly bodies. I think this is a very naive take. * We can't really live on another planet in the solar system. * Look at how far the next star is and realise that we won't get there anytime soon (probably at all). * What's the point of surviving on another planet, without any other species? * Without considering the risk of nuclear war, we are in the process of destroying life on Earth. The resources we put on that project are mostly wasted. We should try to live on Earth, I hear it's a nice place. reply seabass-labrax 1 hour agorootparentI don't personally believe we should colonize other heavenly bodies because of a potential nuclear apocalypse, but the negation of that is no reason to abandon space travel either. Every time we have launched a mission into deep space we have learnt more as a species about what makes Earth 'tick'. We can also do a lot without actual space travel - maybe if more people had heeded the observations of the greenhouse effect on Venus in the 60s, for instance, we would have less of an issue cleaning up our own atmosphere now. I'm not confident that our place is in the stars, but it would be narrow-minded not to give living out there a go. reply palata 1 hour agorootparent> maybe if more people had heeded the observations of the greenhouse effect on Venus in the 60s We know pretty well what's happening on Earth and we have for decades. It's not like we just realised 5 years ago that we have a problem. We have not done anything (and we still aren't), but we knew, that's for sure. > I'm not confident that our place is in the stars, but it would be narrow-minded not to give living out there a go. In terms of survival as a species, anything that's not about solving our biodiversity and climate problems is a loss of time. I'm fine if some people work on it (just like it's good to have people working in art), but a lot of those researchers and engineers working on space exploration may actually be more useful to the species if they worked on the actual problems we have. reply cynicalpeace 23 minutes agorootparentprevI think this is a very naive take. We could live on Mars. Just a matter of time. Let engineers iterate. We would obviously bring species here at home with us to Mars. And then new species would flourish too. reply Manuel_D 12 minutes agorootparentI don't think people understand just how un-feasible life on Mars would be. It's got 1% of the atmospheric pressure as Earth. It's -65 degrees Celsius. It'd be more feasible to try colonizing the Moon or Antarctica. reply throw0101c 6 hours agoparentprev> I personally think we're a button click away from going back to the stone age. One reason to use less oil now is to perhaps preserve it in case we need to 'reboot' civilization in the future in case of a future cataclysm. We were only able to reach beyond (near-)subsistence living because of cheap energy, first coal and later petroleum. All the easily accessible stuff is now kind of gone, so if there's another collapse (which may be more likely to be global in nature: see pandemics), then depending on how much knowledge we lose it could be hard to get back to the say level without the previously cheap/easy energy. In past collapses (Europe: Western Roman Empire, Black Death) we were able to eventually recover because we at a simply technological level that could keep going even with the loss of a lot of knowledge. > I think it's one of the reasons we have to be self sustaining on other heavenly bodies. I think this will be impossible given advanced countries can't even be self-sufficient on Earth. Is there oil on those heavenly bodies? Probably no, so you're importing your lubricants and seals/o-rings. Advanced fabs? No? Well you're importing your electronics. What kind of silica is there, because if you don't have the right kind of sand, you're mot making your own solar panels. How much radioactive material (uranium, plutonium, thorium, etc) is around if you want to try nuclear power. reply palata 1 hour agorootparent> I think this will be impossible given advanced countries can't even be self-sufficient on Earth. And that's only after you've passed the fact that it's impossible for us to reach the next star. reply lutorm 1 hour agorootparentprevThere is so much coal... I wouldn't worry about running out of that. reply EasyMark 4 hours agoparentprevSo like usual I offer up \"what's your alternative\" ? Is it to ignore Russian's invasion of countries? Ignore Iran's chaos it wants to sew constantly in the Middle East? It's easy to say \"just be peaceful\" but history shows that countries are not peaceful towards one another, they constantly want to take other's resources, or force their way of life on others, or settle some vague issue they have with another country (or people there). I think most people would love if countries would just stop attacking others. right now we don't have the tech to live on \"other bodies\", that is pie in the sky. I would love if nation-states just stopped the nonsense and were good to one another and their inhabitants, but that has never been the case. reply cynicalpeace 29 minutes agorootparentYou realize achieving a compromise is not simply \"ignoring\" or surrendering to Russia? Putin and Biden haven't spoken in years. I would say you're proposing ignoring the situation until it becomes even more of a powder keg in a decade or two. Alternative is accepting some territorial losses, compromising, soldiers go home. Doomsday clock ticks back to 5 minutes to midnight. You're acting as if this is the first time anyone has annexed territory. Do I like it? No. But you gotta manage with the cards you're dealt and that territory is not worth decades long conflict with two major nuclear powers. reply aguaviva 22 minutes agorootparentYou realize achieving a compromise is not simply \"ignoring\" or surrendering to Russia? Depends on the degree of compromise. What kind of compromises do you think Ukraine should make at this point in order to win \"peace\" with Russia? Specifics needed please, especially in regard to: (1) the proportion of currently occupied territory Ukraine would need to grant permanent recognized sovereignty to Russia on; (2) the proportion of the the estimated 1T in material damage caused to Ukraine that Russia would need to pay before sanctions are lifted; and (3) the matter of some 20k abducted citizens, mostly minors that Ukraine asserts (with a high degree of credibility) are currently behind held by Russia? Because it's the specifics that matter. (BTW, future NATO status is mostly symbolic at this point; items (1)-(3) are what really matter). reply quotz 1 hour agorootparentprevIrans wants to sew chaos? The whole conflict with Iran started because the US and UK installed a puppet government (Pahlavi) so they can control the oil. After Pahlavi was ousted, the religious extreme took control, and cut ties with the west as a result. Its more like the west wanted chaos and started this whole mess reply cynicalpeace 26 minutes agorootparentIt's this same mentality that got us in trouble in literally all conflicts of the past 40 years. One day it's gonna get us blown up and I hope it's not over the Donbas. reply exoverito 57 minutes agorootparentprevThe CIA was actively involved in the Maidan revolution, which sought to pull Ukraine out of Russia's sphere of influence and into the EU / NATO. Obviously this is antagonistic towards Russia, especially when they have so few natural barriers to defend against invasion of their land. Look at how quickly the Wagner group reached Moscow after defecting from the Ukrainian front. If the shoe were on the other foot, and China had supported a revolution in Mexico and was setting up military bases, the American government would not take it lightly. The US would cook up some reason to wage war against Mexico as a continuation of the Monroe Doctrine. These wars are not about good and evil, as much as it's about empires and power. reply dsign 8 hours agoparentprev>> I think it's one of the reasons we have to be self sustaining on other heavenly bodies. This is not a joke. But every time anybody brings it up a mob shows up saying that we must make it work here on Earth, and we should all go to hell if we can't. But we only need a few madmen in power for the rest of us to not matter. reply fifilura 7 hours agorootparentI imagine that if you can colonize other planets you can also target them with nuclear weapons. It is like saying that the solution to all problems is colonizing Antarctica. reply palata 1 hour agorootparentprev> But every time anybody brings it up a mob shows up saying that we must make it work here on Earth Yeah, we must. As in: it's not rational to even consider that becoming self-sustaining on other heavenly bodies is an alternative. It's fun, it's interesting, it's many things. But it's not an alternative. reply kortilla 48 minutes agorootparentOf course it’s an alternative. A self sustaining colony could be the only thing that survives a massive pandemic. reply timeon 7 hours agorootparentprevPoint is that if we can not behave on Earth how can we do it in other place. reply addaon 3 hours agorootparent> Point is that if we can not behave on Earth how can we do it in other place. If we have a 90% chance of behaving in any given century, we are doomed on earth. If we have a 10% chance of behaving in any given century, a continuous heritage is possible in a galaxy (re-)populated by slowships. reply palata 1 hour agorootparentExcept that the current state of physics says that we just can't possibly reach another galaxy. Period. reply addaon 1 hour agorootparent> Except that the current state of physics says that we just can't possibly reach another galaxy. Period. Yes, that's exactly why my comment limited itself to discussion of population of /this/ galaxy. reply fragmede 7 hours agorootparentprevit's an open question as to how interplanetary politics will actually go. it's possible that ancient squabbles between countries will carryover, but hopefully they won't, which means that a terrorist's nuclear bomb causing MAD on Earth wouldn't necessarily carryover to MAD on a terraformed Mars and Lunar colonies, as we saw with the Russians who boarded the ISS in blue and yellow. But even if it doesn't, Earth being hit by an asteroid is another scenario that being a multi-planetary species would prevent our extinction in. reply throw0101c 5 hours agorootparent> it's possible that ancient squabbles between countries Don't forget with-in countries. If another planet becomes another 'country', they'll have internal disagreements. reply protomolecule 1 hour agorootparentprev>as we saw with the Russians who boarded the ISS in blue and yellow That's just the colors of one of the top Russian universities from which all three cosmonauts had graduated. [0] [0] https://ru.wikipedia.org/wiki/Московский_государственный_тех... reply mordae 8 hours agoparentprevStone age? Hardly. More like 18th century. I am more worried that we do not have that many attempts at rebuilding, because coal and oil are finite. OTOH a slower 2nd iteration might actually work better than this one. reply cynicalpeace 8 hours agorootparent\"I know others will disagree, but it's not something you wanna take a gamble on.\" Far more important than 18th century vs stone age debate is the fact that there are people in charge that would lead us down either path. reply verisimi 7 hours agorootparent> there are people in charge that would lead us down either path Must you follow? reply cynicalpeace 7 hours agorootparentWould love not to. But I'm not the decider whether we head down the path of nuclear armageddon. reply bonzini 5 hours agorootparentprevIf we lost access to electricity, we'd be completely screwed; we can't even get drinkable water in many places without electricity. For example where I live there is water around 10-20m depth, but it's polluted (it may be usable for agriculture but not for human consumption); you'd have to dig a well over 100m below the surface. reply generic92034 1 hour agorootparentThe standards for what is fit for human consumption might drastically change in a post-apocalyptic scenario, though. reply kortilla 46 minutes agorootparentprevBoil it reply fifilura 8 hours agoparentprev> And also why wars or proxy wars between nuclear powers is extremely foolish and should be stopped with great urgency. The strict interpretation of that foreign policy is that any nuclear nation is free to invade any non-nuclear nation and abuse its citizens. Where do you draw the line? If for example an ally is invaded by a nuclear nation. Should you intervene or just call peace? Does the rule-of-law between countries have any relevance? reply cynicalpeace 8 hours agorootparentYou're claiming \"wars or proxy wars between nuclear powers\" are not \"extremely foolish\" and should not \"be stopped with great urgency\"? reply fifilura 8 hours agorootparentYes but how? Obviously the invader is not going to stop the war and say \"this was foolish\". So it is up to all other nations to bow down and let them have their piece of the world. reply cynicalpeace 7 hours agorootparentnext [36 more] [flagged] bspammer 7 hours agorootparentThe candidate I assume you’re voting for increased the future nuclear threat last time he was in office by pulling out of the Iran deal, for no good reason at all. He’s also one of the most jingoistic people in politics. reply cynicalpeace 7 hours agorootparentA lot less war under his admin than now. And I voted for the current admin. He's more jingoistic than Dick Cheney? reply bspammer 5 hours agorootparentHe’s certainly more jingoistic than Harris, as his slogans and supporters make evident. reply EasyMark 4 hours agorootparentnot to mention fact checkers are often overwhelmed after just one speech of his there are so many lies and exaggerations. He is a narcissistic grifter that became a cult leader. reply cynicalpeace 1 hour agorootparentYou're describing me in this comment thread right now. Overwhelmed by the onslaught of political bias. At least Trump's lies have killed less people than Victoria Nuland's reply fifilura 29 minutes agorootparentYou who brought the 2024 election into the thread. reply aguaviva 6 hours agorootparentprevI don't know if the Russians are just as jingoistic and corrupt, Short story: current regime in the Russian Federation quite definitely is, may more so in fact, and has fascist, revanchist, genocidal ideology to boot. You may want to look further into its history (and that of the Russian/Soviet empires, which it sees itself as the natural successor to), and into the writings/thinking of the folks the helm of that regime in more detail sometime. Sabotaging negotiations in Turkey That's a myth, as you will easy verify for yourself by doing adequate research into the topic. Forget about Dick Cheney. Instead look into who's been drip-feeding you false narratives like the above, and why. reply cynicalpeace 6 minutes agorootparentIt is absolutely true. Davyd Arakhhamia, Ukraine’s chief negotiator at Istanbul, said \"[Boris] Johnson brought two simple messages to Kyiv. The first is that Putin is a war criminal; he should be pressured, not negotiated with. And the second is that even if Ukraine is ready to sign some agreements on guarantees with Putin, they [the NATO powers] are not\" We've all been drip-fed by the military industrial complex since at least 9/11 that war is necessary. Look what it got us- millions dead in Iraq, Afghanistan, Syria, Libya, Yemen, Ukraine, Israel, Gaza. Not to mention our countless soldiers killed and injured on the line of duty. It's evil, no I will not forget Dick Cheney. aguaviva 1 hour agorootparentprev\"way more so\" reply fifilura 7 hours agorootparentprevI am not talking about any conflict in particular. I am just pointing out that this is the consequence of that kind of policy. The world is not black and white. And that also gives you the right to choose what part of the grayscale you want to be, good on you! reply cynicalpeace 7 hours agorootparentYou have stated you agree that wars between nuclear powers are extremely foolish. It's difficult to say how you can stop such wars if you don't know what the war is. reply fifilura 7 hours agorootparentIt was you who said that. reply cynicalpeace 1 hour agorootparentYou responded “Yes but how?” to my question. Did I misunderstand and you meant wars between nuclear powers is not foolish? reply fifilura 1 hour agorootparentYes. I am sorry but you missed the second part of the post and then proceeded with putting words in my mouth. reply piva00 7 hours agorootparentprevCan we think on the next step then? A nuclear nation invades and annexes territories from a non-nuclear one, given the premise to avoid wars between nuclear powers by proxy it means that a nuclear nation can then invade and annex anything in their surroundings with little repercussion, since we want to avoid any escalation towards nuclear powers at war. They settle for peace, the nuclear power gets what they want, stops for a while to re-arm, and then pushes to another non-nuclear nation. What would stop other nations from pursuing their own nukes if that's the case? It also would make any military alliance such as NATO moot, there are only 3 nuclear powers in the alliance, any other country in the alliance which gets invaded by a nuclear power wouldn't be able to call for help since we want to avoid nuclear confrontation. This only spirals more and more, countries without nukes are at a massive disadvantage, they will naturally seek nukes to protect themselves, just increasing the odds that a nuclear exchange will happen by sheer statistics. > This is why I will be voting for the candidate who was not endorsed by Dick Cheney. Proving my point that you don't think very rationally at all. reply cynicalpeace 6 hours agorootparentYou're claiming a compromised peace in the Donbas could spiral into a nuclear exchange. I'm claiming that continuing the proxy war between a jingoistic US government and a (probably) jingoistic Russian government could spiral into a nuclear exchange, and that the US government should be less jingoistic. Being jingoistic doesn't reduce the chance of nuclear war. I doubt we're going to convince each other, so I would challenge readers of the two claims to decide for themselves what makes more sense for preventing nuclear armageddon. reply bryanlarsen 6 hours agorootparentIt's a classic short-term vs long-term tradeoff. Letting Russia get away with an invasion of Ukraine decreases the risk of a nuclear war in the next couple of years but increases it in the following decades. I personally believe the long-term thinkers have the better argument reply cynicalpeace 51 minutes agorootparentIt's not long vs short term. It's money and conquest vs peace and compromise. The \"long term\" vision you're proposing is a decades long entrenched conflict with multiple nuclear states. Literally every single foreign policy disaster of the past 40 years has been orchestrated by following this exact playbook, by the exact same people. The \"long term\" vision I propose is normalizing relation with these nuclear states and we do business with them all without telling everyone how to live. This is actually how long term peace is achieved. We shouldn't be the world's policeman. We do much better as the world's businessman. reply piva00 6 hours agorootparentprevNo. I'm claiming that a compromised peace in the Donbas with the annexation of territories of the Donbas and Crimea will further strengthen that if you have nukes you have a massive lever to use against non-nuclear nations. And Russia wants the Donbas, Crimea and the land bridge all the way around the Sea of Azov, that's a massive plot of land. You are only considering a narrow point in time, think ahead in terms of 20-50 years the repercussions of allowing an annexation to happen uncontested. Right now it's Ukraine, let's say next is Iran acquiring nuclear weapons over the next 20 years and moving towards Basra in Iraq + Kuwait for their oil fields, in this scenario they are a nuclear power, arming themselves for 20 years (and they already have ballistic missiles), to avoid a nuclear escalation between Iran and USA + Israel a negotiated peace happens. The Saudis see that happening and now they feel the need to arm themselves with a nuclear weapon, just in case Iran thinks of continuing this campaign. Multiply this across many other nations under similar low-level confrontations, African nations fighting for water sources, one of them arms themselves with a nuclear weapon (let's say Sudan) to have leverage to control a massively important water source, what's going to stop others around it to not arm themselves (like Eritrea) to not get invaded? It's a spiral, the moment you allow a nuclear power to use that status to force the hand of an opposing nation at war you open a can of worms. Since 1945 the world has been trying to control proliferation through other means, wars of annexation have been shunned, you really don't want that to come back into a world armed with nuclear weapons. I don't have an answer, I don't think anyone does. Putin has changed the world with this invasion, you are choosing to vote for Trump on a flimsy argument, you don't even know what the fuck he will do since he's a massive liar. On top of that you're jeopardising your country's democracy based on wishful thinking of what you project Trump will do, it's all from your head, not from his words. reply bonzini 5 hours agorootparent> It's a spiral, the moment you allow a nuclear power to use that status to force the hand of an opposing nation at war you open a can of worms. Since 1945 the world has been trying to control proliferation through other means, wars of annexation have been shunned, you really don't want that to come back into a world armed with nuclear weapons. You also have an example of what happens when some countries are more powerful than others: the veto at the UN Security Council. The UN is essentially unable to do anything that is against the interest of US, Russia or China (it just happens that France and the United Kingdom usually agree with the US). Imagine US, Russia and China having the same power but with 1) the actual ability to wipe enemies off Earth, instead of just blocking UN processes; 2) anybody able to join the club \"just\" by investing into nuclear proliferation. Doesn't seem good. reply cynicalpeace 44 minutes agorootparentWhen did Russia withdraw from the nuclear testing treaty? reply fifilura 8 minutes agorootparentNovember 2nd 2023. https://www.reuters.com/world/europe/putin-revokes-russias-r... philistine 4 hours agorootparentprevDo not discount the veto at the UN of the UK and France. Part of the current situation with Israel rests on those two countries colluding with Israel for a war the other three did not want. reply bonzini 2 hours agorootparentIn the past yes, but right now UK and France have not used the veto for over 30 years; while the Biden administration (just because those are the numbers I found most easily) has already used it over ten times on Israel-Palestine relationships. China also used it a lot more sparingly than Russia and the United States, I must say, but probably that's also because some China issues don't even reach the Security Council. reply bryanlarsen 6 hours agorootparentprev> based on wishful thinking of what you project Trump will do, it's all from your head, not from his words. Since we're off-topic already can I just emphasize this point? Pretty much everybody I know who has or will vote for Trump is like this. For example, I knew one guy who voted for Trump because he thought Trump would legalize marijuana. reply cynicalpeace 40 minutes agorootparentHe explicitly said he'll try to get peace before he even gets sworn into office. I don't think he'll succeed that quick, but that's way better than pushing for further conflict. And again, under his administration we saw more peace than any president since at least Clinton. reply philistine 4 hours agorootparentprevTrump is all vibes, zero policy. The people working for him are zero vibes, all policy. With Trump being the complete reverse of a workaholic, his fours years in power ran on the wishes of his appointees. He was curtailed when in power. If Trump actually liked working and writing laws, he'd have probably legalized marijuana. reply cynicalpeace 1 hour agorootparentHilariously, Trump effectively legalized marijuana accidentally in the 2018 Farm bill. https://thehill.com/homenews/4564181-2018-farm-bill-hemp-can... reply bryanlarsen 3 hours agorootparentprevTrump's first term was basically another 4 more years of Bush. Without leadership from the top, his mostly Bush-era appointees kept doing what they did before. His second term will be filled with fanatics rather than Bush-era appointees. reply seabass-labrax 1 hour agorootparentI don't manage to keep up with Republican party machinations - please could you explain why the Bush-era staff won't be there if Trump is elected again? reply eropple 1 hour agorootparentBecause most have left, either retired or disassociated from Trump and his movement. Trump's running as hard as he can (which isn't very, he isn't convincing) from the proudly published (and terrifying!) Project 2025 stuff, but they aren't running from him, and there are reasons for that. reply cynicalpeace 45 minutes agorootparentprevIn terms of 20-50 years where will we be if the Ukraine conflict continues? At best an entrenched, decades long conflict, where we're at odds with 2 major nuclear powers. At worst, we're all dead. Including my children. Over a bunch of neoliberal theories proposed by the architects of the last number of catastrophic wars? No thanks. The left/Democrats/progressives used to be anti-war. But they've been entirely co-opted as a result of Trump derangement syndrome. reply aguaviva 16 minutes agorootparentNo need to worry about 20-50 years from now. It is very unlikely the conflict will continue much longer once Putin croaks or enters his diaper stage, in a few years. EasyMark 4 hours agorootparentprevliterally all the Russians have to do is stop and go back home and the war is over. they will never do that because they elected a President who is named Putin and now he has a Hitleresque dream of taking all the old Soviet vassal states back. He is the one doing this and he is the one you will have to convince to stop; although I am sure there are plenty of yes men that he has attracted to his orbit to support his crazed dream of Soviet restoration reply cynicalpeace 35 minutes agorootparentCorrect. Russians should absolutely go home. You're pushing forward a neoliberal wet dream that he wants the whole eastern bloc. reply mihaaly 8 hours agoparentprevHumanity en masse are superficial ignorant pretentious idiots. They are so pretentious that they pretend they are not pretentious and they care a lot ('It is utmost important for us [arbitrary lie here]'). Except Trump kind of people. They honestly and proudly announce that they give no fuck about anyone but themselves. reply psychoslave 7 hours agorootparent>Humanity en masse are superficial ignorant pretentious idiots. Oh I see how I can perfectly fit this role sure, I tell you so as the most humble entity that universe ever spawned. It was of the outmost importance for me to deliver this lie: I don't care about anyone, humanity can go extinct, self included, and it doesn't trigger any emotion in me. reply dahfizz 8 hours agoparentprevYeah, this is also a big concern of mine. Nuclear weapons haven’t been used since ww2, but there also hasn’t ever been total war between two nuclear powers. The current climate in Russia and the Middle East may change that. reply tgv 9 hours agoprevIn \"The Making of the Atomic Bomb\" by Rhodes, a poignant point was made, originating from people like Bohr, who were definitely on the peaceful side: without demonstrating the effect of the atomic bomb, the \"nuclear taboo\" would not have come into existence, and the first large conflict between nuclear powers would have seen a terrible outcome. The use of the bomb was inevitable, so it was sadly better to use it in a restricted war, before the US and the CCCP would use them against each other and the rest of the world. reply istjohn 1 hour agoparent> And to the others he said in mine hearing, Go ye after him through the city, and smite: let not your eye spare, neither have ye pity: > Slay utterly old and young, both maids, and little children, and women... Ezekial 9:5-6 > Now go and smite Amalek, and utterly destroy all that they have, and spare them not; but slay both man and woman, infant and suckling, ox and sheep, camel and ass. 1 Samuel 15:3 > And every living substance was destroyed which was upon the face of the ground, both man, and cattle, and the creeping things, and the fowl of the heaven; and they were destroyed from the earth: and Noah only remained alive, and they that were with him in the ark. Genesis 7:23 Two and a half thousand years later, human nature is unchanged. How easily we make peace with wholesale slaughter. reply 082349872349872 8 hours agoparentprevThat might have been a better argument if the USSR[0] had had the bomb in 1945[1]? Lagniappe: https://www.youtube.com/watch?v=oRLON3ddZIw#t=15s [0] first test: 29.08.1949 [1] a year in which the US and USSR were, however tenuously, still allied reply cbolton 8 hours agorootparentDoes it matter? It was probably obvious to the scientists working on the bomb that other countries would get it too sooner or later, including countries at odds with each other. reply 082349872349872 8 hours agorootparentI don't know. Could Hirohito (Suzuki, etc.) have been convinced by bombs dropped elsewhere? (our physicists were able to back-of-the-envelope; should their physicists have needed hundreds of thousands of civilian deaths to calculate what an A-bomb could do?) So I think it's not obvious (multiple books have been written on the subject) what could or should have been done or not done back then; now, from my point of view, those cards have been dealt, for good or for ill. reply tgv 2 hours agorootparentHirohito was apparently convinced after the bomb on Hiroshima, the cabinet and military staff still wanted to fight on after the bomb on Nagasaki. They even tried to block his radio speech. Personally, I think it was tragic, but there was not much choice. Forcing Japan to its knees by conventional means would have been a prolonged bloodbath (with the Soviets getting in the game as well), with probably a higher death toll. reply thimabi 8 hours agorootparentprevBut was it really obvious? From what I can tell, much of the nuclear arms race happened thanks to espionage. Had information on warheads and the like been properly contained, maybe other countries would not have so easily developed the bomb. reply throw0101c 5 hours agorootparent> Had information on warheads and the like been properly contained, maybe other countries would not have so easily developed the bomb. The Soviets had people inside the Manhattan Project / Los Alamos. As the US made progress that information was fed to the Soviets/Russians. * https://en.wikipedia.org/wiki/Klaus_Fuchs * https://en.wikipedia.org/wiki/Atomic_spies reply tgv 4 hours agorootparentprevNot so easily, but they would have done it. Once it was known, there wouldn't have been any way to stop Stalin. His paranoia knew no limits. And then there would have been dozens, hundreds when the war would break out, nobody would be scared to use them. reply quickthrowman 1 hour agorootparentprevJapan was better off in the long run being occupied solely by the US instead of a split occupation with the Soviets like Germany. If we hadn’t dropped the two bombs, the Soviets were set to invade northern Japan. reply belter 8 hours agoprevTsutomu Yamaguchi survived both the Hiroshima and Nagasaki atomic bombings... https://en.wikipedia.org/wiki/Tsutomu_Yamaguchi reply LightBug1 8 hours agoparenta.k.a. Tsutomu \"Wolverine\" Yamaguchi reply abe94 9 hours agoprevOne of my friends grandmothers was an atomic bomb survivor - she was just a baby when the bomb hit and was blind the rest of her life. One thing I was surprised by was the number of survivors and also that there was at least one person who survived both bombs [1] [1] https://en.m.wikipedia.org/wiki/Tsutomu_Yamaguchi reply lqet 9 hours agoparent> A resident of Nagasaki, Yamaguchi was in Hiroshima on business for his employer Mitsubishi Heavy Industries when the city was bombed at 8:15 AM, on 6 August 1945. He returned to Nagasaki the following day and, despite his wounds, returned to work on 9 August, the day of the second atomic bombing. That morning, while he was being told by his supervisor that he was \"crazy\" after describing how one bomb had destroyed the city, the Nagasaki bomb detonated. reply krisoft 8 hours agorootparent> That morning, while he was being told by his supervisor that he was \"crazy\" after describing how one bomb had destroyed the city, the Nagasaki bomb detonated. That is one way to win an argument. Not that anyone would prefer that \"win\". reply zczc 8 hours agoparentprevThe Wikipedia article says there were at least 165 survivors of both bombings: \"[Yamaguchi] was invited to take part in a 2006 documentary about 165 double A-bomb survivors\". reply jsrcout 1 hour agoparentprevI, too, was shocked to learn this. I only learned about it fairly recently, from my older brother who read a book from the school library on it as a child: Nine Who Survived Hiroshima & Nagasaki Hardcover – January 1, 1957 https://www.amazon.com/Nine-Who-Survived-Hiroshima-Nagasaki/... reply tomp 7 hours agoprevThis is a bad choice. Nuclear weapons are the biggest cause of the last 80 years of peace between major world powers. The best way to stop nuclear weapons from ever being used again, is to keep lots of them, in as many countries as possible (mutually assured destruction). reply exmadscientist 7 hours agoparentIt is, as so often the case, a classic prisoner's dilemma problem [0]: \"no nukes\" is pretty clearly superior to \"any nukes at all\", but \"they have nukes but we don't\" is game over, so... nukes for all (major world powers)! It's awful, but that's the prisoner's dilemma for you. I have a hard time respecting any anti-nuclear activist who doesn't at least acknowledge this facet of things, even if \"no one has nukes and no one can easily get them\" really would be best for the world. [0]: if anyone hasn't seen it before, the interactive https://ncase.me/trust/ on the iterated prisoner's dilemma is excellent reply tomp 4 hours agorootparentNo, I disagree. There hasn't been a hot war between nuclear powered states, ever. This is pretty obviously superior compared with the previous \"no nukes\" era, that had plenty of hot wars... reply jhbadger 4 hours agorootparentDefine \"hot war\". There have been plenty of fighting in border regions of India and Pakistan in recent years, and both have nukes. India since 1974 and Pakistan since 1998. reply whatshisface 1 hour agorootparentprevChinese troops and Soviet planes were there in Korea. reply MisterBastahrd 2 hours agorootparentprevIf the past 8 years have shown us anything, it's that we are capable of electing incredibly stupid people who likely would get us into war if being blown back into the stone age weren't a possibility. I like nuclear weapons for that reason. It scares tyrants into complacency on the larger scale. reply ranger207 4 hours agoparentprevI'm also of the opinion that MAD has been the largest single greatest cause of peace in the past 80 years, but I disagree that this award is bad. The reason we haven't seen a single use of nuclear weapons since then, not even relatively small ones, is because of the nuclear taboo that organizations like this have engendered reply thimabi 7 hours agoparentprevNuclear weapons have not prevented major world powers from engaging in proxy wars. As we can see today in the Middle East, proxy wars can make things dangerous and more likely to lead to an unwanted escalation. Mutually assured destruction works best when the number of involved parties is limited. If every state were to have a warhead of its own, many risks would increase: those of miscalculation, nuclear proliferation to non-state actors, etc. reply linhns 1 hour agoparentprevThat's not applicable to the mullahs in Iran. If they have they'd use it on Day 1. reply 2OEH8eoCRo0 7 hours agoparentprevWhat if a fanatical leader has them? Castro said he would have nuked the US if he could and didn't care if Cuba gets destroyed. https://www.youtube.com/watch?v=CtUfBc4qQMg reply protomolecule 2 hours agorootparent>What if a fanatical leader has them? Like Nixon, you mean? [0] [0] https://en.wikipedia.org/wiki/Madman_theory#Richard_Nixon reply 2OEH8eoCRo0 2 hours agorootparentNot at all. A fanatic wouldn't feign it, they'd do it. Self destruction be damned. reply protomolecule 18 minutes agorootparentSo why mention Castro? reply ChrisArchitect 4 hours agoprevOf course the reminder of the impact there and the ongoing risk is nice but is this really a relevant and current choice? Why not last year? Why not ten years ago? What success have they even had? Considering where we are right now. This isn't a group making an impact on the ground anywhere right now. Many of the winners in recent years have been civil & human rights activists in real fights on the ground in their countries/regions. The public will take the reminder but mostly shrug the news off. reply istjohn 1 hour agoparentThis discussion proves the importance. We are so far from properly appreciating the horror of nuclear weapons. One would think that after nearly eighty years Americans would be able to apprehend our crimes against the innocents of Hiroshima and Nagasaki with clear vision. reply thimabi 9 hours agoprevCongratulations to Nihon Hidankyo! As said in the announcement, even 80 years after those bombs were dropped in Hiroshima and Nagasaki, we still need to highlight the dangers of nuclear weapons. The threat and use of such weapons is still allowed by customary international law. Maybe movements like this will help change this sad fact. There has been progress in this direction. However, of course, nuclear-weapon states have been vehemently opposed to that, although they are obliged to negotiate a general and complete nuclear disarmament. reply gus_massa 8 hours agoparent\"Customary international law\" is written by countries that can win a huge wae that are countries that have nuclear weapons, so they will not forbid themself the use of nuclear weapons. reply thimabi 7 hours agorootparentAs the name says, customary international law is not written. It arises from international practices that have become so widespread that states begin to recognize they have a legal obligation to continue them (opinio juris). Current literature says that the non-usage of nuclear weapons has become a widespread international practice, but that the resistance of nuclear powers has prevented the formation of an “opinio juris” thus far. What is at stake is whether an international custom can be formed despite the opposition of certain states — as long as several other states acknowledge the custom. reply exmadscientist 7 hours agorootparentDoesn't the history of war in the twentieth century (because we've got to start somewhere) suggest that \"international law\" means absolutely fucking nothing at fucking all when it comes to major wars? Why bother? What are you going to do to enforce it, invade the guy who just nuked/invaded you/your friends? reply gus_massa 7 hours agorootparentprevBut the several other states must have nuclear weapons to enforce the custom on a rogue country with nuclear weapons. reply walthamstow 9 hours agoprevI visited the Hiroshima museum last year. They've got a set of stone steps, a person was sat there when the bomb went off and they were simply vaporised. The stone steps bear the residue of the person, almost like a shadow. reply kachapopopow 9 hours agoparentThe atomic bombs weren't close enough to vaporize anyone since they were detonated in the air, what you see is disintegration which is a little bit different and instead of turning the human body into what could be considered \"nothing\" the materials are torn apart and get embedded into the surrounding environment. Some vaporization did occur, but only on plants and the skin tissue of humans. reply krisoft 8 hours agorootparent> instead of turning the human body into what could be considered \"nothing\" You can't turn material into \"nothing\". At best you can turn it into equivalent amount of energy if you collide it with antimatter. That being said I don't really feel the difference between \"vaporisation\" and \"disintegration\". In both cases you stop being biology and start being physics in a subjective instant. (at least from the perspective of your own central nervous system, which has not enough time to even detect that something has happened) In both cases you go from a living, breathing, laughing, thinking human being into contaminants in the air or surfaces around you. What do you feel is the difference between \"vaporisation\" and \"disintegration\"? Is it about how big your largest continuous chunk is? Where do you draw the line? reply kachapopopow 7 hours agorootparentBy \"nothing\" is that there isn't a piece of you that is still you. Disintegration means that we can still find pieces of \"you\" in the environment. Not sure if there's any recoverable DNA left thought, that was most likely destroyed by the other waves of the atomic bomb. reply fragmede 7 hours agorootparentprevthe specific definition is that vaporization turns solids and liquids into gas or plasma, while disintegration means being broken into pieces. the difference between a gas and a solid, and also fine solids suspended in a gas, is fairly well defined. reply krisoft 4 hours agorootparentThat makes sense! Thank you. Gas or plasma vs solids is indeed a well defined difference. reply tomp 7 hours agoparentprevAre you sure that's the explanation? It could be (and I think it's more likely) that the rest of the stone was lightened, and the part in the shadow, wasn't. No \"residue of a person\", just literally \"shadow\". See also: https://en.wikipedia.org/wiki/Human_Shadow_Etched_in_Stone reply LeonM 8 hours agoparentprevAt that distance you wouldn't be vaporized, but burned. What you see on the steps is not vapor deposits, but rather they are shadows. The immense heat and light from the detonation burned/discolored the stones, but not in the shadow of the person sitting on the steps. Hence why you can see these 'permanent shadows' in various places in the city. Some caused by humans, but most are just shadows of structures. For example bridge railings: https://www.atomicarchive.com/media/photographs/hiroshima/im... reply belter 7 hours agoparentprevhttps://en.wikipedia.org/wiki/Human_Shadow_Etched_in_Stone reply matsemann 9 hours agoparentprevVisited Hiroshima over a decade ago during a school trip, and had a local guide that was a survivor. Very powerful. As a teenager we also visited concentration camps on a school trip, and a survivor joined the trip from Norway to Germany. We got to know him a bit during the week long trip, and there was a session where he told his story. I'll never forget this, and I think it affects me to this day. Soon we will have no Time Witnesses left. Edit: I remembered a very specific anecdote he told, about how him randomly having learned to knit helped when in a concentration camp, as some officer wanted something to be made, and he then could sit inside and do that instead of working himself to death in the quarry. Based on this I managed to find his name again now. Haakon Sørbye, thanks for telling us your story. reply Timari 8 hours agoprevI watched the film “Threads” last night, anyone in any doubt about the horrific consequences of a nuclear exchange should watch it. The speed at which society falls apart is simply terrifying. Those poor souls unlucky to be in a war zone will understand better than I ever will. The world needs a new order. reply cchi_co 7 hours agoprevThe Hibakusha's firsthand accounts and efforts have kept the horrors of nuclear war alive in the world's consciousness, helping to build a lasting taboo against the use of such weapons. reply retrocryptid 30 minutes agoprevi'm confused. what does Hidankyo have to do with large language models? reply AlbertCory 2 hours agoprevThe chances of a nuclear bomb being used in the next 30 years is at least 90%. That's an opinion so don't ask for a link. Why? Purely because of the combinatorial math of proliferation, and the likelihood of either an accident or a crazy person getting control of a bomb. I wish it weren't so, but eventually your luck runs out. reply jojobas 8 hours agoprevNuclear weapons are not used not because they are morally unacceptable, but rather because of MAD and their limited efficiency when used against armies. If you wanted to give a Nobel Prize to someone for preventing nuclear wars, give it to Nuclear Winter researchers and military analysts. reply contrarian1234 9 hours agoprevIt's a bit unclear to me why you need an organization that advocates against nuclear weapons. I'd argue the “nuclear taboo” is just the product of.. I don't just seeing one nuclear test video? It doesn't take the cataloging of witness testimony to see it's terror (though that may be important in its own right) I'm not intimately familiar with Japanese self-perceptions - but from the outside it seems like post-WW2 the country really leaned into a view that \"nuclear weapons are terrible\" to the point of distraction - instead of a more self-reflective \"nationalism is terrible\" or something along those lines. There seems to be much less anxiety about preventing getting into a similar situations that triggered WW2: neo-colonial military bullying and domination of neighbors, xenaphobic oppression of ethnic groups, sycophantic following of cultural leaders etc. and an intense worry about the more tangeable use of nuclear weapons - which I'd argue is something that even if it were to come to pass would almost certainly never involve the Japanese people. I wonder how this seeming diversion of public attention is perceived in Japan itself. As I understand it, the anti-nationalist narrative was repressed due to anti-communist agendas of the occupation forces (ex: freeing of nationalist war criminals) Would be curious to hear from anyone Japanese on the topic reply nabla9 8 hours agoparentThe general human tendency to focus on single short term events seems to be the main cause. Let's compare using Wikipedia as a source: Atomic bombings in Japan: 50,000–246,000 casualties. Air Raids in Japan: 241,000–900,000 killed, 213,000–1,300,000 wounded, 8,500,000 rendered homeless. Mass killings of large civilian populations should not happen. I don't personally see nuclear weapons as worse than incendiary bombs or artillery. It's the number of casualties that makes it horrible. reply defrost 8 hours agorootparentThe evidence we have is * one early bomb is more or less equivilant to one conventional HE + incendiary raid. * 2,000+ other bombs have since been detonated, a good number of which were orders of magnitudes more destructive than the early \"first gen\" bombs used on Japan. Nuclear war with the larger weapons that followed would be considerably worse than incendiary bombs, in physical destruction, in immediate deaths, and in injuries and following mortalities. reply nabla9 8 hours agorootparentIt's all about scale. Not about the type weapons themselves. All the testifying of the horrors seems irrelevant. Using nuclear weapons only tactically against counterforce targets would not be that horrifying. reply Dalewyn 8 hours agorootparentprevI agree. I've been to the Hiroshima Peace Park or whatever it's called in English numerous times, but I can't say I've been anymore moved by it than any other demonstration of human brutality. I can't register a difference between a nuclear bomb and, say, a GBU-12 Paveway conventional bomb. They both destroy and kill brutally, the magnitude is irrelevant and it would be great if we never have to use either of them. reply faggotbreath 8 hours agorootparentA nuke and a pave way? That’s like comparing a 22lr to a 155mm HE shell. reply gabaix 8 hours agoparentprevThe Hiroshima museum, while advocating for a nuclear free world, has an interesting take on why the US dropped the bomb on them. According to them, the US dropped the bomb because they wanted to show their strengths against the Soviets. It makes little to no mention of the bloody battles in the Pacific. reply makeitdouble 8 hours agoparentprev> instead of a more self-reflective \"nationalism is terrible\" or something along those lines. It used to bother me a lot, until I realized that - the US purposefully left the Emperor in place with only a slap on the fingers (\"you're not a god anymore...except for those who still believe you are\") - all surrounding countries have incentives to to keep distances from Japan (in particular as long as the US are there, Japan and China will never be allies, same for Russia), Taiwan being the exception. I see no future where Japan nationalism is truly solved, short of these two things also getting solved. And boy is there no end in sight to this. reply Dalewyn 8 hours agorootparent>the US purposefully left the Emperor in place with only a slap on the fingers This was a deliberate political decision in an effort to not repeat the grave mistake of how post-WW1 Germany was handled which essentially led to WW2. Denying Japan of their identity and dignity would have risked an eventual WW3, and the US did not want to even entertain the possibility. It also didn't help that practically all of Japan were not going to see their Emperor deposed or worse; Japan was willing to compromise on literally everything but the Emperor in making peace with the US and the west, and the extended Imperial family along with all the other nobles thereof lost their titles and powers in the post-war occupation and restructuring. reply makeitdouble 7 hours agorootparentI think we're mostly in agreement. It was a strategic move and it might have helped a lot letting Japan get back on its feet. And it's also the move that left the deep deep nationalism in place and it's still here today. Perhaps there was no way to have one without the other, but at least I want to look at it as a series of cause and consequences. Crazy popular anime girl representations of WW2 battleships is the most funniest form of that reality IMHO. reply krisoft 8 hours agoparentprev> I'd argue the “nuclear taboo” is just the product of.. I don't just seeing one nuclear test video? And yet some high ranking military planers were seriously pushing for employing nuclear weapons in Vietnam. Do you think they just haven't seen any nuclear test videos? > It's a bit unclear to me why you need an organization that advocates against nuclear weapons. Because humans keep building, and fielding nuclear weapons. Not sure where you live, but chances are good your taxes are used to build, and maintain nuclear weapons and the means to carry them. reply Dalewyn 8 hours agoparentprevI'm Japanese-American, so I can throw two cents in your hat. Post-war Japan is against nuclear weapons to an absolute, but it must be admitted that the response to nukes in particular is just as much a kneejerk reaction. NHK literally spams the entirety of August with anti-nuclear propaganda every year. Japan's anti-nuclear stance is also hypocritically at odds with relying on the US nuclear umbrella for national security. More rationally, post-war Japan is against wars of any and all kinds to an absolute. This goes as far as refusing to defend the US in the event of an attack on the US-Japan alliance; this was only changed recently in the last decade or so after strong pressure from the US to reciprocate the US's defense commitments to Japan. Nationalism is a... complex topic. You will be considered a crazy person if you wave the Japanese flag or put up a flagpole on or around your house, but at the same time loyalty and reverence to the Emperor still remains strong and the country is politically and culturally very conservative/liberal with a very interesting mix of individualism and conformity. Most Japanese ex-pats actually leave Japan because they are more progressive and can't stand the conservative culture. Japan is actually quite welcoming of foreigners, but there is a hard gentlemen's agreement that if you're in Japan you do as the Japanese do. Those who can adapt are welcomed, those who can't/don't are excluded and ejected sooner or later. reply WhereIsTheTruth 9 hours agoprevNot sure if that organisation is making progress, sounds like a smoke bomb, to please people who care about these meaningless rewards https://www.defense.gov/News/Releases/Release/Article/385216... reply melasadra 8 hours agoprevAs some other commenters have pointed out: It is lamentable that the focus is almost always on the atomic bombing itself instead of why it came to that point at all. Many Asian countries feel scant sympathy toward Japan. From Indonesia to Malaysia to the Philipipines or even worse and for much longer, in Korea and China. In each of these countries the Japanese perpetrated massacre, forced labour, gang rape and forced prostitution in the millions. Even European women who were stranded in their former colonies were not spared. In fact their diaries are the foremost historical sources. Their brutality is such that the hatred towards colonialist European nations were ameliorated and pretty much forgotten these days. It's sickening to me that outside East and Southeast Asia itself, most of the world only remember Nagasaki and Hiroshima when it comes to casualties in the Pacific theatre of WW2. This sympathy felt even more misplaced considering even to this very day, unlike Germany, Japanese historiograpy deliberately downplays Japan brutality during occupation or that there was any aggression on their part at all. Most Japanese college mates in the US that I've talked to were not even aware that Japan occupied my country for years resulting in millions of casualties. reply yread 8 hours agoparentThere are also well-maintained shrines (like Yasukuni) to the Japanese war criminals frequented even by high-level politicians (former PM went there, current ministers went there). Imagine that in current Germany! reply glandium 7 hours agorootparentThe Yasukuni situation is more complex than \"the shrine for war criminals\". A lot more people are enshrined there, the war criminals are a tiny fraction (and were only added in 1978, while the shrine was established 109 years earlier). To give you an example of an important and less controversial figure enshrined there: Sakamoto Ryōma. There are 2+ millions souls enshrined there. reply matt123456789 9 hours agoprevAn excellent choice. reply pyrale 9 hours agoprevI have no issue with this laureate, but it is sad that the comittee could not find someone deserving that is working on a more current conflict. I guess this is not a positive outlook for the current state international conflicts. reply thimabi 9 hours agoparentAt a time when Russia threatens the use of nuclear weapons in Ukraine, Israel and Iran escalate tensions, North Korea tests missiles and warheads… it is hard not to relate the award to these circumstances. Perhaps the committee thought it was best to express its opinion on current conflicts indirectly, as it has done so in the past. reply pyrale 6 hours agorootparent> Perhaps the committee thought it was best to express its opinion on current conflicts indirectly, as it has done so in the past. I do agree, and this is my point: this particular committee expressing concern rather than celebrating success is a source of lament to me. reply Cthulhu_ 9 hours agoparentprevI'm just glad it looks like a legitimately given out award this time, instead of giving it to e.g. Peres, Arafat, Obama, Aung San Suu Kyi, etc. reply Dalewyn 9 hours agorootparentObama is by far the most vapid recipient of the award, but I wonder if he is also the best representative for the lack of peace given his legacy of \"Yes we can, (but we don't).\" The reason we seemingly can't have peace is because we deliberately refuse it. reply slightwinder 8 hours agoparentprevSince over 2 years, we again live now under the constant real threat of a nuclear war. Or this is at least what Russia is regularly claiming. This is very current as long as Putin doesn't get his s** together. Of course there are other current candidates who would also deserve it, but I think it might be also a matter of how hot and current the problem is, and how much political impact this message would have. Russia and their threats are cooling down for the moment, so it's \"safer\" to send this message, instead of anything related to the Middle East, for example. reply Strawberry76 8 hours agoprevA good one this year. Some past recipients, not so good... reply kdhusakdjhsadkj 8 hours agoprevnext [11 more] [flagged] dang 2 hours agoparentYes, this is a generic tangent—somewhere between generic and offtopic, actually—and certainly a flamewar tangent, so it is correctly flagged. Please don't create accounts to break HN's rules with. \"Eschew flamebait. Avoid generic tangents.\" https://news.ycombinator.com/newsguidelines.html reply mihaaly 7 hours agoparentprevI believe the west cares that much to pretent that they have doubt about interfering drastically in the life of heterogeneous and diverse view people grouped together geographically and called country. Showing that they respect independence and self governance. A rigteous self image to cloak cowardnes towards risky acts you know. Also global assholes cover each other's ass and there are quite a few of them. reply jncfhnb 8 hours agoparentprevThe risk is that if you start bombing Iranian nuclear facilities that they immediately start manufacturing a nuclear bomb. reply yard2010 6 hours agorootparentStart..? reply jncfhnb 5 hours agorootparentCurrent intelligence believes Iran is not actively building a bomb, although the time to do so is very short if they choose to. reply kdhusakdjhsadkj 4 hours agorootparentprevand how exactly will they be able to do so without any nuclear facilities? reply jncfhnb 3 hours agorootparentYou cannot guarantee success on knocking them out. You cannot guarantee other countries won’t make the situation vastly more complicated. reply bbb651 7 hours agoparentprevI have a feeling this will change real soon. reply yard2010 6 hours agorootparentI wish you were wrong because that means shit that is hitting the fan real hard and I'm not up for this. \"I died, I swear, when the ABC said we're going to war, I really believed we wouldn't fight no more\" Edge of the World Pt. 3 by Pond reply EasyMark 4 hours agorootparentprev50/50 but yeah it's like Israel attempts to bomb Iranian nuclear facilities. Problem is they are buried so deep now that it's pointless and at best a slight delay. Only the US (or maybe China or Russia) to get at facilities that deep and I don't see that happening unless Trump wins. Biden/Harris will never sign off on that. reply artursapek 8 hours agoprevnext [3 more] One of the reasons I like Trump is he’s one of the few modern politicians to talk about the threat of nuclear war all the time. I feel like most people have gotten complacent about it. reply jncfhnb 7 hours agoparentThat’s because he is manipulating you with scare tactics, much like virtually every other topic. Great Depression 2! Dog eaters! Rapists! Every other sentence is an appeal to fear. reply Ylpertnodi 7 hours agoparentprevGenuinely interested: if Trump talking nukes is 'one of the reasons (for liking him), what are the others, and do they include his talking about soldiers and generals? reply roschdal 9 hours ago [flagged]prevnext [2 more] Our friendly reminder that USA detonated nuclear bombs in Hiroshima and Nagasaki. reply dang 2 hours agoparentCould you please stop posting unsubstantive comments and flamebait? You've unfortunately been doing it repeatedly. It's not what this site is for, and destroys what it is for. If you wouldn't mind reviewing https://news.ycombinator.com/newsguidelines.html and taking the intended spirit of the site more to heart, we'd be grateful. reply matthewfelgate 8 hours ago [flagged]prevnext [5 more] Nuclear non-proliferation is one of the dumbest ideas ever. - Liberal democracies should have Nuclear Weapons. - Dictatorships and Communists countries shouldn't. The idea that the West should give up its weapons while Russia, China, and even North Korea, Iran have them, is idiotic. reply dang 2 hours agoparentCan you please make your substantive points without name-calling and flamebait? We've had to ask you this before! https://news.ycombinator.com/newsguidelines.html reply aguaviva 7 hours agoparentprevwhile Iran has them, Present tense, you say? reply gus_massa 7 hours agoparentprevWhat about right wing dictatorships backed by the CIA? reply wtcactus 7 hours agorootparentIs there any right wing dictatorship backed by CIA that has nuclear weapons? reply thrownawaysz 9 hours agoprevIf I were a gambling man I'd put some money on a chinese professor getting the economics Nobel Prize reply thaumasiotes 9 hours agoparentYou might want to consider a little more carefully before putting money down. There is no economics Nobel Prize. reply thrownawaysz 9 hours agorootparent\"Although not one of the five Nobel Prizes established by Alfred Nobel's will in 1895, it is commonly referred to as the Nobel Prize in Economics, and is administered and referred to along with the Nobel Prizes by the Nobel Foundation. Winners of the Prize in Economic Sciences are chosen in a similar manner as and announced alongside the Nobel Prize recipients, and receive the Prize in Economic Sciences at the Nobel Prize Award Ceremony\" reply Simon_ORourke 6 hours agoprevI wonder if that Timnit Gebru will come out of the woodwork again on this because of whatever, or more importantly as some \"look at me instead I'm loudly aggrieved about very little\" play for PR and funding. reply psychoslave 8 hours agoprevNice to see they do somehow recognize the whole association of people and not push to much about a single person. But the committee is trapped with the rules that push for this ridiculous individual centric point of view which is so out of touch with measurable realities considering what forces actually come at play to anything with large social impact. Also on a side note: >the most destructive weapons the world has ever seen. Well, first thing, this is a quite restrictive anthropocentric and restrictive POV for what count for a weapon. Putting appart all things that triggered previous mass extinction as they might not really fit the expectation of weapon and \"ever witnessed as implied agent\", ok. But let's consider European invasion of America: while this was not intended and per design, it somehow greatly leveraged on bacteriological weapons. Currently humanity is also at war with biodiversity, and the scale is massive and worldwide, using a large panel of tools. Of course we are more prone to empathy to our fellow humans, and nuclear weapons are abominations. reply hruzgar 1 hour agoprevSo US has nuclear bombs, but japan is somehow not allowed to make their own? Seems like controlled oppression to me reply khuey 1 hour agoparentJapan is free to withdraw from the NPT at any time. reply ignoramous 9 hours agoprev [–] The peace prize is being awarded to a Japanese organization that advocates nuclear non-proliferation, as the committee emphasizes its urgent importance amid two ongoing wars, in which one belligerent threatens to use nuclear weapons while in another one probably has. But the committee ostensibly fails to call out that nuclear weapons come in all shapes and sizes (they are not just big bad bombs), as the US, world's largest weapons manufacturer, both uses it and sells it to its allies: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7903104/ / https://www.europarl.europa.eu/doceo/document/E-8-2015-00348... reply KK7NIL 8 hours agoparentDepleted uranium ammunition is not a type of nuclear weapon since its method of dealing damage is kinetic, not a nuclear reaction. Ironically enough you calling these \"nuclear weapons\" only serves to confuse people and soften the nuclear taboo. reply kgwgk 1 hour agorootparentThey are clearly atomic weapons - they are made of atoms. reply ignoramous 1 hour agorootparentprevhttps://en.wikipedia.org/wiki/Dirty_bomb reply KK7NIL 11 minutes agorootparentStop. You know very well that depleted uranium rounds are neither nuclear weapons nor dirty bombs and claiming so only creates confusion. The US' military usage of DU (not just in ammunition but also armor) has been controversial and you're free to critique it, but that's not what you're doing. Instead you lied and created these fictional \"nuclear weapons\" that the US is supposedly spreading everywhere, which is just not true. reply Dalewyn 9 hours agoparentprev [–] Japan's national security policy is hypocritical given that it relies solely on the US nuclear umbrella for security despite disavowing anything to do with nuclear weapons, but unfortunately reality is not ideality. Ukraine is the perfect example of what actually happens when a country discards its nuclear arsenal. So yes, Japan is absolutely hypocritical and the Nobel Peace Prize has been the most vapid of all the Nobel Prizes, but for once this Peace Prize is actually trying to say something meaningful in an ever violent human world. reply krisoft 7 hours agorootparent> Ukraine is the perfect example of what actually happens when a country discards its nuclear arsenal. That's silly. Ukraine never had a nuclear arsenal. Ukraine had nuclear weapons on their soil, but they were managed, and controlled by forces loyal to Moscow. Had forces loyal to Kyiv tried to force their way into the silos they would have been repelled and a war would have broken out there and then. Ukraine had a nuclear arsenal as much as Turkey has a nuclear arsenal because the USA stores nuclear warheads in Incirlik. reply myrmidon 6 hours agorootparentI agree that Ukraine was not a nuclear power even while they had warheads on their territory after the USSR fell apart, but I believe it was very feasible for them to become one. Posession is nine tenths of the law, after all-- it would've been quite possible to just lock down a few silos and refuse to hand the weapons over. Russia as a state was highly disrupted at that point, and would've had a hard time opposing this effectively. I'm not disputing that this would've been a very costly move for an already poor nation (in potential economical sanctions and also maintenance of the arsenal itself). Maybe the external political/economical pressure resulting from this would've ripped Ukraine apart some other way. But I'm highly confident that Russia would not have risked annexing territory from an country with a few nuclear ICBM silos. No need even to have full control/launch capability, as long as there is sufficient doubt (on Russias side). reply makeitdouble 8 hours agorootparentprev [–] As a matter of fact Japan has no other choice than being under US protection. I can't imagine a chain of event that would lead the US to get out of Japan volunteerly [0], nor Japan being able to kick the US out forcibly. It's just outside of the realm of possibility right now. [0] they won't even move out of Okinawa as the whole island loathes the US base and gives the middle finger to their own gov to get them out. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The 2024 Nobel Peace Prize has been awarded to Nihon Hidankyo, a Japanese organization of atomic bomb survivors, known as Hibakusha, for their advocacy for a nuclear-free world.- The Hibakusha have significantly contributed to establishing the \"nuclear taboo,\" a global norm against the use of nuclear weapons, through their impactful testimonies.- This recognition aligns with Alfred Nobel's vision of honoring efforts that benefit humanity and continues to inspire new generations towards nuclear disarmament."
    ],
    "commentSummary": [
      "The 2024 Nobel Peace Prize was awarded to Nihon Hidankyo, a Japanese organization advocating against nuclear weapons, underscoring the persistent threat of nuclear arms amid global tensions.- This award serves as a reminder of the devastating impact of nuclear warfare, as exemplified by Hiroshima and Nagasaki, and stresses the importance of disarmament.- The prize discussion also involves the complexities of nuclear deterrence, international law, and the geopolitical dynamics among nuclear powers."
    ],
    "points": 180,
    "commentCount": 238,
    "retryCount": 0,
    "time": 1728637314
  },
  {
    "id": 41805391,
    "title": "WordPress Alternatives",
    "originLink": "https://darn.es/wordpress-alternatives/",
    "originBody": "📝 Editor note: Due to this article's unexpected attention, I've included a few more alternatives that people suggested. I've also added some contextual notes you should know before diving into these options. Due to gestures vaguely, everything going on right now with WordPress, I thought I'd put together a list of alternative CMSs that better fit the criteria someone might have for their website. The modern CMS landscape is super broad, with the very definition of \"Content Management System\" being stretched. Some see it as a full-package website platform, and some see it as just UI for their content stored elsewhere. The criteria for this list are \"Can it be downloaded, dropped onto a server, and you'll have a website?\" This eliminates API and git-based CMSs, which I enjoy using; however, wiring a daisy chain of tools is just not viable for many. Ghost: The best open source blog & newsletter platform Beautiful, modern publishing with email newsletters and paid subscriptions built-in. Used by Platformer, 404Media, Lever News, Tangle, The Browser, and thousands more. Ghost - The Professional Publishing Platform People will already know I have a soft spot for Ghost. But what you might not know is what I'd recommend for hosting. Magic Pages Get your Ghost CMS publication up and running in no time with Magic Pages’ Ghost CMS web hosting – starting at $4/month! Magic Pages Magic Pages is what I'm using for Design Systems WTF, and it's been great! The uptime is good, the price is very reasonable, and Jannis provides a personal touch with support. In addition, this sidesteps Ghost's own hosting option (Ghost Pro), which I would be wary of due to past experiences with other customers. Kirby is the CMS that adapts to you Kirby is the content management system that adapts to any project. Made for developers, designers, creators and clients. Kirby CMS I have not used Kirby in client work, just briefly as a local setup, but it seemed like a smooth experience, and I only heard good things online. It's file-based, which seems super appealing to someone like myself who gets cold sweats when opening a database. Indiekit The little server that connects your website to the independent web. Get Started Indiekit seems like an interesting option; it's also file-based but needs a database to manage existing content. Craft CMS Craft is a flexible, user-friendly CMS for creating custom digital experiences on the web and beyond. Craft CMS It's a bit more of a commercial option with Craft CMS, but it does offer a free option for solo creators. Warning, though, as you'll need to spend time architecting your content structure by the looks of it. ClassicPressStable. Lightweight. Instantly Familiar. ClassicPress is a community-led open source content management system. A fork of WordPress 4.9, it retains the WordPress classic editor as the default option. ClassicPress ClassicPress appears to be a direct fork of WordPress but at version 6.2.3. It seems perfect for anyone looking for \"the good old days.\" However, it uses the official WordPress plugin API, so it's not a 100% clean break if that's what you're going for. Thanks to Pelle Wessman for this suggestion. Statamic is a powerful, highly scalable CMS built on Laravel. The open source, flat-first, Laravel + Git powered CMS designed for building easy to manage websites. Statamic I've had several people suggest Statamic. It does look pretty good, plus they have a free solo plan (similar to Craft CMS). I think if the cofounder hadn't brazenly endorsed a horrendously damaging politician, I'd have tried it. Django Content Management SystemWagtail CMS Meet Wagtail, an open-source Django content management system powered by Python. It’s free, beautiful, versatile and fast. Find out how to get started. Wagtail CMSNicolas Leung Developer, Digital Programme, M+ Probably the most comparable CMS to WordPress, Wagtail is open-source and created by Torchbox, which is just around the corner from my co-working space. I've tried it extremely briefly, but the installation was pretty smooth, as far as I recall. Textpattern CMSOpen source content management system Textpattern CMS is a free, PHP open source CMS (content management system) with a browser-based interface in over 50 languages. Textpattern CMSPete Cooper The text pattern looks extremely utilitarian, with a text area, a title, and publishing options. If that's all you need, then I guess you're all set 👍🏻 I was going to suggest Perch and Buckets on this list, but public activity seems low for both. The Perch website even has SSL certificate issues, which isn't a good sign. Check them out if you're interested, but you have been warned. Honourable mention# Lifting Anchor Help on how to use Anchor Anchor CMS Many years ago, I contributed to Anchor, a humble PHP-based CMS that grew a little community around itself. Sadly, the creator, Charlotte, passed away in 2020, and the remaining core team couldn't keep the project going while juggling other responsibilities. I think of it fondly and wish we could give it the time it deserves. The theming and custom types aspects were wonderfully simple; heck, I even made a whole site dedicated to themes and sites built with it: Welcome - Anchor Themes Themes and sites built for Anchor, obviously Anchor ThemesDavid Darnes I'll try to keep this list up to date if I recall any others I've used in the past. Hopefully, you find this useful if you're seeking alternative CMSs.",
    "commentLink": "https://news.ycombinator.com/item?id=41805391",
    "commentBody": "WordPress Alternatives (darn.es)144 points by pabs3 16 hours agohidepastfavorite106 comments Brajeshwar 14 hours agoIf one is looking for a simple/personal blog and wants to write in plain-text Markdown, one should consider Jekyll on GitHub Pages[1]. The beauty is that one does not need to worry about setting up Jekyll on the local machine. Just write and push to Github. If one wants to skip that, just go to GitHub and write there; a version of VSCode is built in there. This also allows one to carry (take out) their content anywhere on any platform that supports plain text (MarkDown). Browsers can also just render plain-text as it, so if you just drag-drop them on a server, it should render as your website. I have a pretty large personal site[2], and I hate Jekyll because it takes too long to compile locally, but I’m on it because I don’t let it interfere with my writing. As for a WordPress replacement/alternative, it is going to be pretty hard to find something as prolific and click-clacky easy as WordPress to start off. It has like two decades of the mother of all kitchen sink built-in for anyone to jump in and rummage something out it. Update/Edit: Github Pages has also become rock solid stable too. No downtime in the past 3+ years. 1. https://pages.github.com 2. https://brajeshwar.com/2021/brajeshwar.com-2021/ reply l2dy 10 hours agoparentFor personal blog, I have found the following alternatives: - Chyrp Lite: lightweight blogging engine, written in PHP. https://github.com/xenocrat/chyrp-lite - Typecho: a PHP-based blog software. https://github.com/typecho/typecho and file-based static content generator: - Quartz: Publish an Obsidian vault as a static site. https://github.com/jackyzha0/quartz - Logseq: Publish a Logseq graph as a static site. https://github.com/logseq/publish-spa also Jekyll templates: - https://github.com/maximevaillancourt/digital-garden-jekyll-... reply paulnpace 1 hour agoparentprevWhy is GitHub better than WordPress? reply whyoh 10 hours agoparentprevA blog without integrated commenting is not a proper blog, IMHO. And sure, you can add 3rd party commenting to a static page, but from what I've seen none of them are as good (or as free). reply minimaxir 12 hours agoparentprevYou can use Hugo with GitHub Pages, you just need to use a GitHub Action to trigger the deploy on a new commit, luckily there's an official workflow: https://gohugo.io/hosting-and-deployment/hosting-on-github/ My personal Hugo-based blog for reference: https://github.com/minimaxir/minimaxir.github.io reply mikae1 13 hours agoparentprevI wish more people came across https://getpublii.com as a middle ground between full-on SSG and a hosted CMS. It's so damn good at this point. reply Brajeshwar 13 hours agorootparentYes, yes, I was there Gandalf. I was there 3,000 years ago. I tried Publii during its early release or beta (I think it was popular on HN). Unfortunately, I felt that it encapsulated too much for me and my site just died -- similar issues with waiting for my tea to boil while Jekyll compiles a simple style change. I hope it is much better now. reply ptman 10 hours agorootparentprevI took a new look at Publii. Recently more support for websites instead of blogs. Great! But collaboration seems to be a problem. You can sync the workspace using dropbox or syncthing, but there can be conflicts on the sqlite database. There is git support, but that just pushes the published page into git. Are there no better interfaces for mortals to SSGs? reply marcosscriven 14 hours agoparentprevWhat do you do about images? reply shubhamjain 12 hours agorootparentIf you don't mind paying a few bucks a month, you can give my service [1] a try. I actually designed it with that specific use-case in mind. Handling images is the biggest PITA for static-site generators. There are other image CDNs (Cloudinary, Imagekit, Imgix) but they have been designed for developers and are prohibitively expensive beyond their free-tier. [1]: https://magecdn.com/ reply Brajeshwar 13 hours agorootparentprevThere are two ways I have done and both worked for me. It is outlined in my article https://brajeshwar.com/2021/brajeshwar.com-2021/#q-what-abou... and here is the gist. 1. Move all of your images and static assets (zip, downloads, pdfs, videos) that are not part of WordPress textual content to something like S3+Cloudfront. Maintain that as in a sub-domain `https://static.brajeshwar.com/` Now, start using it in your writing as ``. This makes it easy and allows you to switch WordPress hosting providers in minutes if not seconds. In my case, around late 2000s and early 2010s, I keep getting warned by Media Temple (mt) of the bandwidth and so Amazon’s S3 came to the rescue.† WordPress plugins are a galore that does the re-direct. That solved multiple problems - not tied down to a particular hosting provider, a CDN that is simple and cheap. Thus, moving out of WordPress with the text that contains those links will continue to just work. 2. Once you move to Static HTMLs, in my case, I felt that it makes more sense to just have them together in one folder — `brajeshwar.com` with everything in it — all the files. I also tend to ask the question and try answering, “Can I move out easily?” That has let me to not use images and other non-essential contents as much as I can avoid. An article/post should continue to work and be meaningful even if the images fails. † My website was kinda of a deal back then. Now, CloudFlare claims that my website does about 4-5GB a month in bandwidth. This is after I have deleted many, delegated most downloads to Github, and to S3+ CloudFront sub-domains such as `cdn.oinam.com` and `archives.oinam.com`. During the days when (mt) complains is when it hits like 50GB a month on downloads, etc. In all of this, these days, I pay single digit dollar every month to maintain my entire personal website and the remnants of its past. I don’t want the links from Adobe, Google, Wikipedia, the Chinese, the Russians, etc. to end up in a 404. reply freosam 13 hours agorootparentprevI've done this sometimes with hosting images and other large files on a combination of Flickr, Wikimedia Commons, Internet Archive, and Zenodo. Flickr costs money, but it feels like it's worth it given I'm using Netlify and all the others for free. I know some people use S3 services for hosting images, but then you have to worry about generating your own thumbnails etc. and it's trickier. reply Brajeshwar 13 hours agorootparent> I know some people use S3 services for hosting images, but then you have to worry about generating your own thumbnails etc. and it's trickier. This is one reason why I started asking, “Is this image really needed for this article.” As for the thumbnail generation, I used to have a few Photoshop actions that I just click and be done with. Now, I just manually optimize the few images I uses in such a way that it is somewhere in the middle -- CSS can still shrink it as a thumbnail but the original isn't that too large either. Something like that. If you still maintain that a popular website to worry about images that much, I would try out CloudFlare image service. reply xigoi 6 hours agorootparentprevWhat about them? Git can store images just fine, even though it’s not optimized. reply wordofx 11 hours agorootparentprevHost them on GitHub. reply mikae1 13 hours agorootparentprevMy first thought too. reply tomjen3 14 hours agoparentprevIts solid advice if that is your problem and if you are migrating from a standard wordpress. I ran into another problem - I wanted a static site[0]. I tried some of the static hosting engines, including Jekyll, but they always seemed to want to force my site into a blog format. Yeah with some work they could partially be twisted into what I wanted, but only partially. Do you know of a static website builder that builds websites, and not blogs? [0]: The difference to me is that my content should never have a date associated with it, and the landing page should be a landing page, not a list of recent pages. reply tasuki 12 hours agorootparentJekyll is perfectly fine even for non blog sites. I organise a yearly event (https://lsg.go.art.pl/english) and made its website with Jekyll (https://github.com/tasuki/lsg). Absolutely no blog involved. Middleman is nice if you need something more flexible than what Jekyll can offer. reply Brajeshwar 13 hours agorootparentprevI think yours is the candidate for Pandoc[1] or something like Soupault[2]. But you will be doing the HTML/CSS writing yourself. 1. https://pandoc.org 2. https://soupault.app reply hombre_fatal 14 hours agorootparentprevBuild your website like you would normally and then crawl it to build a static html site. Years ago I used some npm library that was like a fancy `wget -r` for this purpose. I was generating a static site from an express server I made. reply kcrwfrd_ 13 hours agorootparentprevAstro is pretty nice if editing content in markdown checked into the repo works for you. reply keiferski 14 hours agoprevFor developers, there are many alternatives, but for the vast majority of use cases, there really aren’t any. WordPress is popular because it’s a dead simple way to make a website that doesn’t require any technical skills - and has been this dead simple solution for almost the last two decades. Most of the popular hosts come with WP installed, so there is no need to install software on a server (a fairly “technical” thing to do.) Realistically the only alternative for these users is another website builder like Wix, Squarespace, or Shopify. The hosted version of Ghost is pretty good too and probably the single closest thing to WordPress. reply qingcharles 13 hours agoparentPlus the large plugin library. reply bigiain 12 hours agorootparentFor us, it's the huge existing user base of people who know how to do authoring/publishing in WordPress. (Even if they don't have the skills to understand what they're doing installing plugins sensibly, we mostly don't hand over Admin role accounts ion we don't have to.) I don't want to hand hold a small business owner through writing markdown or how to commit to git to get their homepage edited. I want to be able to tell them \"Just ask around your staff or family or friends, someone will know how to update your wordpress site, or one of them will at least know somebody who can. Failing that, go to your local craft/hipster coffee place and ask anyone with a laptop open for suggestions.\" reply p4bl0 11 hours agoprevThere's an obvious actual alternative to WordPress that's missing here: Dotclear. When I say \"actual alternative\" I mean a web based blog engine rather than something entirely different like a static site generator that transpile markdown files into HTML web page and an RSS feed from the command line that you then have to rsync to your server or make use of the continuous integration service of a software forge to rebuild on the server side. I'm not saying this is a bad workflow, just that I don't feel it really counts as an alternative to WordPress for most people (you know, non-technical people). I ended up using Dotclear for my own personal blog after years of using home-made blog engines. By default, I was going for WordPress initially, but configuring it and creating a custom theme that looked like I wanted it to look like was a mess. I felt like I had to learn a whole new technology stack instead of being able to use my PHP, HTML, and CSS skills. In comparison, Dotclear was a breeze to work with, and after days scratching my head on the complexity of WordPress, it took me maybe like two hours to get where I wanted with Dotclear, including the time to discover and installing the software. I enjoy it very much since then! See https://dotclear.org/ for more information. Anecdoticaly, Dotclear is older than WordPress (2002 vs 2003) :). reply johnchristopher 10 hours agoprevThat list isn't deep enough. These are CMS alternatives, not WordPress alternatives. I need a WordPress alternative to/with the following requirements: - self-hostable - opensource core (paid plugins are not a problem) - so it can be installed and intensively tested without shelling too much money just for R&D - has ACF equivalent - has a visual composer à la Gutenberg, a middle-ground between WordPad editing interface and Divi/Elementor - so the marketing/press department can push content fast - REST API - to hydrate stuff - optional: needs to have been around for 5 years - optional: needs to still be around in 5 years Ghost has no ACF apparently (https://forum.ghost.org/t/custom-fields-for-posts/1124/46 and https://github.com/TryGhost/Ghost/issues/9020) and Astro is too custom as of now and I don't want another Gatsby (too short-lived). reply KayL 7 hours agoparent100% TRUE. Also, a simple and workable e-cart I tried many alternatives. Their upgrade path is painful. reply julienmarie 15 hours agoprevSpecial mention to Processwire. Worked with it a few years ago and really loved it at the time. https://processwire.com/ Craft is great but a bit slow in my tests. They have a really powerful e-commerce offer though and is really flexible. reply wvbdmp 1 hour agoparentProcessWire is great and it’s the perfect example for the OP’s main criterion “can be downloaded, dropped onto a server, and you’ll have a website”! One great thing about it is that that’s also how you update it. Download new version, replace a single directory on the server, and you’ll have the new version. For a WordPress alternative, however, ProcessWire is perhaps not batteries-included enough. Like many of the systems in this thread, it caters more to developers who want full control over their site. For someone who just needs a blog with maybe a contact form and wants to choose a nice “template” and be done with it, ProcessWire isn’t a good fit. While it has “site profiles”, it’s lacking a lot of traction in that area, as well as a consumer-oriented marketplace that’s nice to browse (screenshots, curation etc.). But for anyone who wants to build something more complex, it’s a great choice. Cozy little community, too. reply jlahijani 14 hours agoparentprev+999 for ProcessWire. It's my CMS of choice for 10 years straight and is actually a pretty good platform for web applications as well (with some limitations compared to something like Rails or Laravel since configuration is stored in the database). I made this 36-part video series comparing WordPress to ProcessWire which I recorded on-and-off between 2014-2018 and released it that year. Although that was a while ago, it's still mostly accurate since both systems are mature and haven't changed drastically in that time (this is before Gutenberg): https://www.youtube.com/playlist?list=PLOrdUWNK38ibz8U_5Vq4z... Also worth a read: https://processwire.com/about/wordpress-vs-processwire/ For the JS devs, ProcessWire has a similar approach to Payload CMS from what I've seen (although ProcessWire dates back to 2003 and open-sourced in ~2010/11). Best CMS ever. :) reply possibleworlds 14 hours agoparentprev+1 for ProcessWire. I am not doing freelance dev anymore but for the small set of sites I still maintain I love doing updates for the ProcessWire installs and dread it with every other project. Anyone shopping for Wordpress alternatives should definitely check it out. The only project I’ve tried recently that is as fun, flexible and productive is Astro. reply dmje 6 hours agoparentprevThanks for mentioning ProcessWire. I've heard of it but never looked. Just spent a couple of hours fiddling and I have to say - really like the look of this. Thank you for bringing it to my attention! reply egeozcan 11 hours agoparentprevTotally agree! Processwire is super simple for simple things and is super extensible if you need anything custom. There's nothing I couldn't do with it and PHP isn't even remotely my language of choice. It gets the job done with tremendous flexibility. reply brylie 11 hours agoprevCross-posting here: I can highly recommend Wagtail CMS: https://wagtail.org/ It’s based on Python/Django and has an excellent developer and user experience. They pay a lot of attention to detail, including a block-based content editor, similar to Gutenberg, and first class accessibility support. reply oidar 14 hours agoprevIf you are looking for a no-nonsense, simple blog platform consider Bear[1] - It's super simple to use, and has been solid for me for the past year. Plus the support (and dev - Herman Martinus here on HN[2]) is responsive and friendly. [1] https://bearblog.dev [2] https://news.ycombinator.com/user?id=HermanMartinus reply HermanMartinus 12 hours agoparentThanks for the shoutout! For clarity, as a sibling comment has pointed out: while Bear is open-source, it is a platform and not managed hosting of individual blogs. If you're interested in self-hosting something that looks like Bear, there's a free Hugo template[1]. If you're happy using a platform, then Bear is super fast and built with longevity in mind (at both the tech and organisational level). [1]https://themes.gohugo.io/themes/hugo-bearblog/ reply xNeil 10 hours agorootparentSharing the Hugo theme is a great move Herman. I'll be starting a Bearblog now, all thanks to this comment. reply gloflo 12 hours agoparentprevEmphasis on platform. > Bear Blog has been built as a platform and not as an individual blog generator. It is more like Substack than Hugo. Due to this it isn't possible to individually self-host a Bear Blog. reply kyriakos 2 hours agoprevWordPress is popular for the same reason Windows is popular. User Inertia, wide availability, widespread support, cheap. WordPress is not bad, it has its purpose and works well. It's bad when you try to make it do things it wasn't meant to with dubious plugins. I made some money on WordPress and I understand why people started using it and why they still do. It's very hard to replicate the community support that took years to build. reply pkphilip 11 hours agoprevInteresting to see that some of the biggest and closest alternatives to Wordpress are missing from the list: * Joomla * Typo3 * Drupal reply yawnxyz 14 hours agoprevI've just moved my stack Astro deployed on Deno Deploy and it's been very very fun and easy. Really like it. I just copied all my Svelte files over and it worked. I copied over all my Deno files and it worked. And it's building static pages onto Deno, effortlessly. And I'm just pulling in content from Notion and Airtable as CMS and caching on Deno KV, and that's also very very easy. reply DavidDarnes 9 hours agoprevHey there, author here. Lots of good suggestions here, but a lot of them are for complex development stacks. My criteria was something that can be installed and ran without having to do much wiring up. That being said I do love me an SSG and content API, my own site is Eleventy hooked up to Ghost. Also saw some suggestions like Drupal and Joomla, I may add these but from personal experience I've almost always been migrating away from them. There's a reason they're popular though. Ps. Sorry if you got upset about the political spin, but it's not escapable. Tech is not exempt from politics. reply openrisk 11 hours agoprevIts telling about the stagnation of Web technology that there isnt a real Wordpress alternative. You'd think that after all those decades there would be a modern, open source solution that offers the same and more functionality (not... less, looking at you SSG wanabees) but with a cleaner, safer and easier to use stack that is liked by both technical and non-technical people. Stands to reason that such a leap forward in web publishing should be technically possible (the requirements are clear and dont need AGI) but there is also some truth in the saying \"its the economy stupid, thats why you can't have good things\": There is no economic incentive in this direction in the modern digital landscape. reply threatofrain 11 hours agoparentIt's not about web technology, it's about popularity. It's like saying it's damning to technology that we don't have a serious YouTube contender. People don't just want technology, they want to be on the most popular thing. There are consequences to popularity. For example, if you need help it's a lot easier to find both self-help guides and technical people to help you. There are a lot more extensions or 3rd-party tooling. Even if there are exploits there are a lot more eyes on the problem and fixes come sooner. So there are other WordPress alternatives, they're just less popular with all the consequences that come with being a minority player. reply openrisk 10 hours agorootparentYes, I agree there is the popularity / network effects barrier. But when the advantage offered by technology is irresistible these barriers can be overcome. Tiktok is case in point and arguably it has become a pretty serious youtube contender (whether one likes the implications or not...) reply timeon 9 hours agoparentprevAll modern solutions (including php+Laravel) are not possible to use on basic cheap shared hosting - where the most 'self-host' web still is. reply synergy20 14 hours agoprevis Drupal getting better for ordinary people to deploy? it was my choice 15 years ago it's sad python, rails,node never had a rival platform to replace WordPress over the years, long live php for the web reply tylershuster 13 hours agoparentI don't understand the \"Drupal is hard\" mentality on HN. Drupal is just as simple as WordPress to deploy. Unzip, plug in database credentials and go. It's better with composer, but there's some real prejudice against it. Drupal 7 is admittedly too complicated but the new Symfony-based Drupal is fun to develop. I used to use WordPress and after the first few months of Drupal I realized how much better it was at, like, everything, than WordPress is. It's been buttering my bread for 6 years now and I think it's better every release. reply JohnTHaller 14 hours agoparentprevDrupal has gotten more difficult for 'ordinary' people to deploy. That's a big reason there are many times more sites still running Drupal 7 than there are running the current release: https://www.drupal.org/project/usage/drupal The complexity compared with something like WordPress is a big part of the difference in install base. Drupal powers under a million websites (I run 3 of those). WordPress powers something north of 450 million websites. reply tylershuster 13 hours agorootparentIt's hard to upgrade from Drupal 7 to Drupal 8, but it's really not hard to deploy anew. The \"Drupal CMS\" initiative is trying hard to lower the already low barrier to entry. reply BarryMilo 14 hours agoparentprevDoubt it, it mostly went more corporate over time. reply todotask 14 hours agoprevYou're going to encounter various limitations with the CMS that it was designed for. I'll say this once: if we need a complete rebuild in 2025 and beyond, the Astro web framework could be the core engine due to its unopinionated nature and support for many UI components, including the latest addition, VanJS. It's seem like a well designed to keep things as simple as possible and still open to community feedback. Of course, you could host it on Netlify, Cloudflare, and Vercel using adapters from Astro. Although it's not a traditional CMS, it's capable of serving as the core engine that should serve well for 99% of use cases out there. reply oddb0d 9 hours agoprevDrupal is the dark horse here, especially with the new can-run-in-your-browser Drupal CMS, try it out here: http://dgo.to/drupal_cms Out-of-the-box you've got a responsive theme, built-in accessibility, multilingual capabilities, a security team, and the accumulation of 23 years of tried-and-tested code. The efforts that are being put into this new product are making it as easy to use as any other CMS, which is a huge leap for Drupal. Add into the equation things like the new AI initiative (http://dgo.to/artificial_intelligence_initiative) where you can literally configure the site through chat as founder of Drupal, Dries Buytaert, recently demonstrated asking AI to create a categorisation of wine tour events based on the top 20 wine regions (https://bit.ly/wine-tours-taxonomy) I have a feeling that, based on my 21 years of using it, I think Drupal's going to surprise quite a few people over the next year. I don't just use it as a CMS, I leverage native commerce (http://dgo.to/commerce) and CRM (http://dgo.to/contacts) modules in order to have a fully integrated framework which, architecturally, enables me to create functionality that would be expensive if even possible using separate systems. There's even a no-code suite Drupal ECA (http://dgo.to/eca). I could go on... reply aaronbrethorst 14 hours agoprevAgainst all odds and expectations, Movable Type is apparently still around and a thing: https://github.com/movabletype/movabletype reply pabs3 15 hours agoprevSwitching to a static site generator seems like the way to go for lots of sites, especially blog-only ones. Are there any graphical SSGs that non-technical users could run locally to generate a site and upload it to their web host? reply mikae1 13 hours agoparent> Are there any graphical SSGs that non-technical users could run locally to generate a site and upload it to their web host? https://getpublii.com is amazing and it's strange it doesn't get more attention. reply burningChrome 14 hours agoparentprevI've used Netlify for a while now for a lot of my basic static site customers. You can easily transfer a domain, they have automatic builds when you commit to several different source control vendors like Github or Gitlab. They have a ton of services and I was using them when they still a startup and Mathias used to personally answer your emails. Now they're pretty big and have a host of different services they offer. Their analytics are still in need of some help, but their services are rock solid and very, very affordable. They were really the first company to push the idea of JAMSTACK (Javascript, APIs, Markup) and have really been pushing that envelope ever since. They've also acquired several Y Combinator startups recently. https://www.netlify.com/ reply whyoh 10 hours agoparentprev>especially blog-only ones I disagree. I think a blog should have comments. And I've yet to see a commenting system for static sites that is free and that works as well as WordPress. reply jszymborski 14 hours agoparentprevI haven't used it since forever ago, but Lektor [0] is this weird in between. You need to be able to pip install and run `lektor serve` in the terminal but most else is done in the browser. [0] https://www.getlektor.com/ reply pabs3 14 hours agorootparentSounds more like WordPress than what I was thinking :) reply krapp 14 hours agorootparentprevI used Lektor recently. I was OK but I found the editor UI awkward and things like tags and subjects difficult to manage, and there didn't seem to be much in the way of current support or a plugin ecosystem. Publishing directly to a server with Git push and only having html online was nice, though. I might go back to it. I switched to Wordpress but I blog so little it seems like overkill. AFAIK Lektor doesn't have a way to crosspost to Mastodon and I don't want to learn enough Python to write a plugin myself. reply jszymborski 4 hours agorootparentI used it not longer after it launched and it had (perhaps understandably) a lot of rough edges. I haven't bothered trying since I switched to Hugo. reply kijin 14 hours agoparentprevThis is a big problem with the \"blogging CMS\" market. A technical person who just wants a blog can easily set up a SSG, or even write their own CRUD app, in just a couple of hours. So they don't really need a WordPress alternative. A non-technical person, on the other hand, will want (if not need) at least a few plugins and themes to set up a blog. Anything that can't be auto-installed on GoDaddy or requires manual file editing and/or shell commands is right out. Most of the alternatives are sorely missing in this department. reply slhck 9 hours agoprevSince when is the WordPress ecosystem this … bad? I built WP websites 10-15 years ago and it was a quite straightforward experience back then. These days, there seems to be no around themes and plugins that all have very limited free versions, and constantly nag you about upgrading to the pro version, in a million different styles of banners and popups. Hosting providers have made it easier to deploy WordPress in a one-click manner, but anything beyond a basic page (sending email, backups, contact forms) already turns into a nightmare. No thanks! reply nicbou 11 hours agoprevI used Craft for years for All About Berlin. I edit this website for a living and Craft served me really well. It was an elegant way to set a content structure and proved quite flexible in that regard. Eventually I switched to a custom-made SSG because clicking around an admin area is very slow, and because of serious bugs with the WYSIWYG editor led to content loss that was very hard to fix. Editing plain text with familiar purpose-built software, and deploying with source control and branches is incredibly valuable. I wrote more about the reason and benefits of the switch here: https://nicolasbouliane.com/projects/ursus reply whyoh 8 hours agoprevA performance comparison between WordPress and ClassicPress: https://www.tukutoi.com/whats-better-classicpress-or-wordpre... reply aisyk 1 hour agoprevpluxml is a good alternative : https://pluxml.org/ reply raybb 14 hours agoprevI've been wanting to setup SSG for a while now. However, if you want something hosted that is free and no fuss I've really been enjoying hashnode. Idk how long it'll last but it dumps all my blog posts into markdown files on GitHub and has worked great for me. Devs respond quickly to issues. Even bringing your own domain is free. Not sure how they plan to make money yet. https://blog.rayberger.org/ reply invisiblea 10 hours agoprevSanity is a great headless CMS with a generous free tier package https://www.sanity.io/pricing Paired with caching/static frontend, it's more than enough to power small to medium traffic sites. reply kcrwfrd_ 14 hours agoprevPayload is really nice: https://payloadcms.com reply ThinkBeat 10 hours agoprevI dont think the political rant on there is offputting and childish drama. Having a world where ecochamber credentials and political adherens is as far from an open and inclusive society. reply rushabh 14 hours agoprevFrappe Builder: https://frappe.io/builder https://github.com/frappe/builder Visual website designing + publishing, built on Frappe Framework reply lfaw 11 hours agoprevNot mentioned in OP: https://getgrav.org/ I used it for a project once and both me and the client were happy. It compares to kirby. reply mewc 13 hours agoprev+1 to ghost. built in node, supports the standard stuff you'd expect and new school. reply 4ndrewl 11 hours agoprevWill be interesting to review this in 5-10 years to see how many of these are still viable and whether there's a fashion tax to pay by having to switch. reply maurits 11 hours agoprevAny recommendations for a self hosted back-end that is images, photography only? Instagram seems to have taken over this space. reply ruthmarx 11 hours agoprevI'm a fan of Wagtail, built on Django. Much more setup to get configured, but it's far more customizable and stable once you do. reply openrisk 10 hours agoparentwagtail is really not ready for prime time, maybe by design. in some respects its easier to use the django admin... reply lbbenjohnston 10 hours agorootparentI think Wagtail is better suited for sites that want a lot more control over the base HTML, page output and data models. WordPress may be a bit directly comparable to https://www.coderedcorp.com/cms/ It's just a few extensions on Wagtail that let you get started with common page models for blogging and generic websites out of the box. I often think of Wagtail as a framework for building your CMS, where as WordPress is a pre-built CMS. Disclaimer: I'm on the Wagtail core team. reply openrisk 10 hours agorootparentI tried to like wagtail the way I love django but the chemistry didn't work out :-). Indeed I think its more suited for serious publishers that can dedicate the resource to build something major. reply ruthmarx 10 hours agorootparentprevNo idea where you are getting that from. It's used in production on plenty of sites. reply openrisk 10 hours agorootparent\"used in production\" is not the same as being a serious wordpress alternative. Would bet that none of those production deployments are without some non-negligible developer time investment. On top of that (assuming that extra investment is possible / desirable) the abstractions layered on top of django are quite opaque and have a steep learning curve. Having to code standard CMS functionalities becomes an eye-rolling exercise. reply ruthmarx 2 hours agorootparent> \"used in production\" is not the same as being a serious wordpress alternative. You only said you thought it wasn't ready for prime time, which I think a reasonable interpretation is that you were saying you didn't think it was ready for production use. > Would bet that none of those production deployments are without some non-negligible developer time investment. That's the thing, I think the time invested is pretty negligible. Especially when compared to maintaining wordpress and having to deal with plugin craziness. > Having to code standard CMS functionalities becomes an eye-rolling exercise. You only really have to setup models for pages, tags, categories etc, after that the editor is incredibly functional. reply tiffanyh 14 hours agoprevTextPattern use to a thing like around the same time WP got started. It’s also PHP based. https://textpattern.com/ reply Brajeshwar 14 hours agoparentIf I remember correctly, TextPattern was done correctly compared to WordPress. Unfortunately, that meant it was more complex for most developers to go deeper. The community flocked to WordPress, and every other one became more of a niche. Didn't they also have a Markdown-ish writing style? I liked that, and I used it as a plugin for WordPress for a very long time. TextPatten went slow and now seems to have been chugging along well. reply KayL 7 hours agoprevWP plugins are very stable. It's their advantage. reply yellow_lead 14 hours agoprevI don't see framer here but it seems like it's getting popular recently. Can anyone share their experience with it? reply qingcharles 13 hours agoprevI did what any regular (in)sane developer would do when faced with this type of problem: wrote my own from scratch...! reply timetraveller26 15 hours agoprevwhat about woodworking? reply kmeisthax 13 hours agoprevMatt Mullenweg is being an asshat about WP Engine (and in general) but that doesn't mean you have to jump off WordPress. That's actually the power of the GPL: it's enshittification resistant. The flipside of this is that you can't stop freeloading. In fact, freeloading is a feature, not a bug. Now, if Automattic had CLA ownership over 100% of WordPress, I'd actually be scared, because they could strip the GPL off of new releases and lock the system down. But as far as I'm aware WordPress's copyright ownership is distributed, so Automattic can't just change the license to the Fuck You, Pay Me Public License and rugpull the whole community. The worst part about this drama is that Matt's not even wrong. WP Engine is kinda shit[0]. But Matt's behavior is extremely unprofessional and he's making WP Engine into the victim of an extortion campaign. [0] If you're wondering, the thing that makes it shit is not that they disable revisions. It's that they have significant reliability issues, both with their shared and dedicated offerings, and their support teams do not have visibility into their systems to fix those issues. reply librasteve 14 hours agoprevnone of these look attractive to me … what about a clean fork of WordPress? reply joshdavham 15 hours agoprevOut of these, what do you guys recommend? reply manuelmoreale 13 hours agoparentI personally jumped from Wordpress to Kirby years ago and never looked back but it obviously depends on the types of projects you work on. For my use case it works perfectly. reply chalcolithic 14 hours agoprevstrange that no aws-based alternatives exist for low traffic websites cloudfront + lambda + dynamodb is free reply robjan 14 hours agoparent> The criteria for this list are \"Can it be downloaded, dropped onto a server, and you'll have a website?\" reply tylershuster 13 hours agoprevDrupal should be the obvious choice here. Still PHP-based, still fieldable entities, and a much saner data structure with infinite extensibility. It gets weird hate on HN so I expect that kind of pushback but hey, it's put food on my family's table for more than 6 years and powers some huge and popular sites so I'm not concerned. reply kioleanu 13 hours agoparentIt gets weird hate because it has (had?) an insanely steep learning curve and no setup looked like the other. With wordpress at least, it's pretty consistent across plugins and implementations and very easy to pick up reply tylershuster 13 hours agorootparentMust be \"had\" — I've used it since D8 first came out and while there's weirdness, it's never been anything beyond what WordPress threw at me. In terms of setup, it's just like — enter database credentials and start making pages. There's plenty of themes out here and HN users aren't stupid — everyone knows how to compile their own CSS and use composer if they want to. reply theluketowers 15 hours agoprevWhat about Winter CMS? reply jszymborski 14 hours agoparentWasn't aware OctoberCMS had a FOSS fork. Looks neat! reply exodust 13 hours agoprev [–] > \"I have not used Kirby in client work, but I hear only good things.\" Not a great idea to recommend something based on hearsay. There's good & bad things to hear about any CMS. One inexplicable decision by the Kirby team was to push their politics by \"taking a stand\" against Twitter, suddenly cutting off their account. This leaves you wondering if Kirby is abandoned software since their top post is from Jan 2023 announcing version 3. https://x.com/getkirby If you don't like Musk, why on Earth would you rattle the cages of your potential customers with such views? It's possible to use Twitter/x in the most minimal way, disable replies, post every blue moon. At least keep the latest version visible. Twitter is essentially an online feed of you business activities. From a potential customer point of view, Twitter is agnostic to \"where is your software at\" research. Ending your timeline in a principled huff, isn't smart. Meanwhile, in the article: > \"Statamic.... I think if the cofounder hadn't brazenly endorsed a horrendously damaging politician, I'd have tried it.\" All aboard the facepalm express. Is it too much to ask to keep politics out of software recommendations and social media version announcement updates? reply pbowyer 12 hours agoparentMore the problem with Kirby is the admin still using Vue 2, so if you use Vue 3 for everything else and want to make a plugin, you have to go back to how you used to write Vue and no longer do. reply ruthmarx 11 hours agoparentprev> Is it too much to ask to keep politics out of software recommendations and social media version announcement updates? Frankly, yes. Things have become so bad that the more people taking a stand and showing they don't support a party that has no issue with racism, sexism, misogyny and various other kinds of bigotry, the better. Sitting on the sidelines shouldn't be an option for most ethical people based in the US, IMO. reply manuelmoreale 13 hours agoparentprev> This leaves you wondering if Kirby is abandoned software since their top post is from Jan 2023 I mean, the project has an official website and a public repo on GitHub. I’m not sure why we’re expecting Twitter to be an official update channel. It clearly isn’t anymore. reply johnchristopher 11 hours agoparentprev> > \"Statamic.... I think if the cofounder hadn't brazenly endorsed a horrendously damaging politician, I'd have tried it.\" > All aboard the facepalm express. Is it too much to ask to keep politics out of software recommendations and social media version announcement updates? One on hand (the business side and the being-a-professional side), I do agree, on the other hand (ethics ?) I disagree that tech should get a free pass regarding political concerns. Overall, I think this sentence could have been phrased more professionally/politely, 14yo sarcasm is annoying. Something like \"I can't recommend Statamic for personal reasons.\" (I know it's still a political statement but it feels less childish and more personal). I know it's a meta and larger debate and that HN as a whole wants/needs (to maintain its level of discussion) to talk about tech without the political implications or concerns but these concerns are still there, I think hinting at it is okay, making it the whole talk is annoying for everyone. /meta > All aboard the facepalm express. That still puts a smile on my face 15 minutes later :D reply timeon 8 hours agoparentprev [–] > This leaves you wondering if Kirby is abandoned software since their top post is from Jan 2023 announcing version 3 Most people do not judge if software is abandoned based on Twitter, as most people do not have Twitter. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article has been updated to include more Content Management System (CMS) alternatives due to increased interest, particularly in light of the current WordPress situation.- The list features downloadable CMS options like Ghost, Kirby, Indiekit, Craft CMS, ClassicPress, Statamic, Wagtail, and Textpattern, excluding API and git-based CMSs.- Notable mentions include Ghost for its built-in email features, Kirby for its file-based approach, and ClassicPress as a community-led WordPress fork, while some CMSs like Anchor are no longer maintained."
    ],
    "commentSummary": [
      "Jekyll on GitHub Pages is recommended for simple blogs using Markdown, offering ease of use without requiring local setup and allowing content portability across platforms.",
      "Alternatives to WordPress for blogging include Chyrp Lite, Typecho, Quartz, and Logseq, while Drupal, ProcessWire, and Wagtail provide more flexibility for developers.",
      "Static site generators such as Astro and Publii are becoming increasingly popular, and for image hosting, options like S3+Cloudfront or CloudFlare are suggested."
    ],
    "points": 144,
    "commentCount": 106,
    "retryCount": 0,
    "time": 1728612210
  },
  {
    "id": 41808917,
    "title": "Google Play killed my game and won't tell me why",
    "originLink": "https://antiidlereborn.com/news/",
    "originBody": "2024-10-11 Google Play has “terminated” me Hello everyone – this is Tukkun (of course) and this is my first real post on this website! I know you guys are all excited for the release of my upcoming game “Anti-Idle: Reborn” and it is my intention to keep this website updated with contents related to the game – its development, gameplay sneak peeks, and so on. But before that, today I’d like to write this post to explain the current situation. In short… I have submitted the game “Anti-Idle: Reborn” to both Google and Apple for review. Both Google and Apple have reviewed the game and approved it for production. Closed Beta of the game has been ongoing for about a month. People have found lots of weird bugs, and I have fixed many of them. However, on October 7, 2024, without any prior warnings, Google decided to terminate my account due to “prior violations” and “High Risk Behavior”. I’ve re-read the policies, I’ve checked everything I can think of, and I still can’t figure out why. I sent an appeal but it seems like they haven’t looked into it yet (as of October 11, 2024). I have gathered any information I can think of and sent it to the Google Play Team, but I only receive the same (possibly automated) response. I have developed games for many years, and “Anti-Idle: Reborn” is more than just my passion. It’s over one year of full time work and dedication, and it is my future source of income. With the Google Play Developer account terminated, I can no longer continue work. A quick search showed me that I am not the only one in this situation. Lots of other developers have had their account terminated for vague reasons, possibly by bots and automated algorithms, and received nothing other than automated messages when appealing. I would like to emphasize that I understand the need for thorough app reviews and termination of accounts that violate the rules. However, this shouldn’t come at a cost of many good faith developers’ accounts being wrongly terminated. The full story While I think most of you are familiar with my works and are just here to check for new information about my game Anti-Idle: Reborn, I understand that some of you might have gotten here from other pages and have no idea who I am. In that case, or in the rare case that a Google employee is somehow reading this, let me introduce myself. I am Tukkun, an indie game developer making games since 2008. My most significant work is a PC Flash game I made back in 2009 called Anti-Idle: The Game, uploaded to the website Kongregate. As of the writing of this post, the game has been played 16,392,188 times (and this is not counting plays of the offline version). I know I shouldn’t say too much good stuff about my own projects (just like anything, my game had imperfections), but Anti-Idle: The Game is often said to have pioneered the idle game genre. It is one of the first games to popularize many mechanics often seen in modern idle games and is a source of inspiration for the development of many popular idle games, including several games on the Play Store (Android) and App Store (iOS). It is even mentioned in the Wikipedia page for Incremental game: The early pioneers of idle games also saw some games parodying the genre, such as Anti-Idle (2009, by tukkun) which has elements of both active and idle games. The game was extremely complicated, content-rich, and constantly updated, and it helped popularize the genre. A screenshot of “Anti-Idle: The Game” Following the success of Anti-Idle: The Game, I decided to develop the mobile sequel Anti-Idle: Reborn. I started doing serious design works on the game since 2023, and started programming it in Unity since the beginning of 2024, with the target of releasing it to Android and iOS late 2024. The idea of developing a mobile sequel started as early as around 2020, with Flash no longer being supported by browsers, and lots of people in the community asked for a “mobile version” of the game. However, like many grown up adults, I had a day job and didn’t have enough free time to develop a mobile game. Despite that, I’ve released a few updates for the original Anti-Idle: The Game – 13 years after its initial release, the game still has a nice active community. That’s why I decided to follow my passion – I went as far as quitting my day job some time ago to fully dedicate myself to game development, and to make Anti-Idle live on. I’ve decided to announce and work on Anti-Idle: Reborn as my first mobile game. Creating a game from scratch feels great – when I managed to get the game design work on paper, when I opened Unity and created a simple loading screen that worked, when I got a prototype running… everything felt like a huge milestone. A screenshot of “Anti-Idle: Reborn” (under development) The day eventually came when I created enough features to launch the first version of the game and decided that Closed Beta can finally begin. I made a Google Forms so people can voluntarily register for Closed Beta and shared it with the community that still played my original game after over 14 years. To my surprise, they shared it to many other communities, including this post on Reddit r/incremental_games, and in total over 1000 people have applied! Then, of course, in order to start Closed Beta, I would have to upload my game to the stores: Play Store (Android) and App Store (iOS). Little did I know, this is only the beginning of the story. Uploading the game to iOS I’ve always been under the impression that it is really difficult to upload a game to the App Store of iOS. They have always set high quality standards and from what I’ve heard, they seem to review apps really thoroughly. And I guess I was right. Within a few hours of uploading my game to the App Store for review, it got rejected. Apple’s initial rejection Oh, great, I knew it. Of course “Anti-Idle” is a world-renowned intellectual property and it is natural for Apple to think I have no permission to use it (sigh). I attempted to convince Apple that I am the real Tukkun (because that’s who I am), and I submitted some proof to the Apple review team, including a screenshot of the source code of the original Anti-Idle: The Game and a link from my profile on Kongregate to this website of Anti-Idle: Reborn. I told Apple that I would provide any other information if necessary. A few hours later, they reviewed the game again, pointed out a bug and even sent screenshots as evidence. I fixed it, and they approved the game. All of the subsequent updates also passed through Apple’s review just fine. All good. iOS version has been approved! Hooray! Uploading the game to Android Onto the next fun part – I entered the necessary information and uploaded the game to the Play Store. It seemed to get through review pretty quickly. I was able to get the Closed Beta up and running in no time. I think initial review for my first closed testing version took around half a day. My first impressions with the Google Play Console were pretty good, it’s easy and intuitive to use. However, for the Play Store, there is a policy that before applying for production (which is required to start open testing and put the game on pre-registration) you need to run closed testing for at least 14 days with at least 20 testers (this seems like a new policy since 2023). All good, that sounds like it will increase the quality of apps uploaded to the store. And I didn’t have problem finding testers at all – as I said, I had over 1000 people applying so I just randomly picked 40 of them for the first phase of testing. During testing, the testers have found a lot of bugs, ranging from minor ones to game-breaking ones, like microtransactions not working correctly, user data sometimes being rolled back and every action within the game causing serious lag. I fixed the game-breaking ones pretty quickly (as a result though, I didn’t have much time creating new features or writing progress updates). And with the game-breaking bugs gone, I have also fulfilled the requirements of “20 testers in 14 days” so I figured I should apply for production. So I did. There was a questionnaire about how I found testers, what the testers did, how I incorporated the testers’ feedback, what makes the game stand out, and why I think the game is ready for production. I just answered the questions truthfully. And after Google’s review, on October 4, they approved my request for production! Look, I even received a congratulations email. My game has been granted Google Play production access! Great! Now all that’s left is testing some more, improving the game quality and then publishing to production, right? That’s Google’s recommendation as well. Unfortunately, before I could do that, three days after the above email, on October 7, testers started reporting that in-app purchases suddenly stopped working and the URL to download the game doesn’t work anymore. In a hurry, I checked and was shocked to find out that my account has been terminated. My account has been terminated… Wait, what? I did a quick search for the issue and learned that a termination for this reason is most likely related to prior violations, possibly prior violations of associated accounts. Which is weird. My app got two policy warnings from Google Play before, but both times I fixed it promptly, and according to Google’s Enforcement Process, app rejections or violations of this level shouldn’t affect the standing of my account. And my game was even approved for production. Which leads me think of prior violations of associated accounts. But what’s an associated account exactly? I am an indie developer and this is my first and only account. Well, I did add some trusted developers and testers into the internal testing track, but I’ve checked with them and they insist that their accounts are in good standing. Do the 40 testers I added for closed testing count? And why should I be responsible for their prior violations (how do I even know whether they made any violations in the first place)? I even took extra precaution steps: I used my Google Play Console account on only one device that I use for releasing the game, I didn’t use VPN, I didn’t use the same network with other people, and ensured I didn’t accidentally connect to some public Wi-Fi. And yet Google still decided that my account has a “high risk of abuse” and terminated it. I have heard a lot of stories about other Android developers having their accounts terminated, but I never thought it would happen to me. I re-read their policies once again just to be sure (by now, I think I’ve read through Google’s policies at least five times). Believing that I did nothing wrong, I sent an appeal. Appealing The appeal form only allowed me to enter 1000 characters, so this is what I wrote. After thoroughly checking the Developer Program Policies and Developer Distribution Agreement, as well as the Policy Coverage policy, I don’t believe I have made any violations that could have led to account termination. I have promptly resolved violations in the past, and my app was even approved for production a few days ago. I am also working closely with my testers in Closed Testing to fix bugs, improve app performance, and ensure that my game “Anti-Idle: Reborn” meets all of Google’s standards and meets user expectations prior to production. I am new to the Developer Program, this is my first account and my first app. I don’t know about “associated accounts” but if this includes the testers’ emails I have added, they are users who volunteered to test my game and I’m not associated with any of their violations (if any). I am always thriving to improve app quality and would greatly appreciate it if you could tell me what is wrong with my app or account so that I could resolve it. In hindsight, that was probably not the most useful information that could have fit into 1000 characters, but that’s all I could think of at the time. I received a system email saying that my appeal would be reviewed by a specialist, subsequently followed by an email with the name of a person at Google (presumably the “specialist”). Hi developers at Tukkun, Thanks for contacting the Google Play team. I’ve received your appeal and I appreciate your patience while I look into it. I’ll let you know as soon as I have any additional information to share. Please let me know if you have any questions in the meantime. […] Regards, [Name of Google specialist] I subsequently sent some additional information in relatively lengthy emails, basically everything that I can think of. Any information I know about my prior violations (I’ve promptly resolved them anyway) How I am “the real Tukkun” and have rights to the things I’m using within the game (basically the same things I’ve sent Apple) How I’ve put my heart and soul into the development of Anti-Idle: Reborn and that it is a very anticipated release. I’ve even sent screenshots of the game’s design files Anything I know about what’s possibly considered “associated accounts” Anything else that I think might be the problem I just said everything I can know of with all of my honesty, and said that whatever the problem is I am committed to resolving it. I still have no idea what the exact problem is though. Of course, in my emails, I tried asking for more information too. However, both times I contacted them, they responded with the exact same email: Hi developers at Tukkun, Thanks again for contacting the Google Play team. I’ve received your appeal and I appreciate your patience while I look into it. I’ll let you know as soon as I have any additional information to share. Regards, [Name of Google specialist] They didn’t respond instantly, but several hours after I sent the information. And to be fair they did say “thanks again” (they know it’s not the first time I contacted them), but there’s no other useful information in the email. At this point I’m not even sure if that’s an actual human or just an automated email delayed to feel human. I wouldn’t even be surprised if Google started giving AI unique “names” to make them sound like human specialists. According to Google, it can take up to 7 days for them to make a decision. As of the writing of this post, it is the 4th day. There’s still time and I guess “I appreciate your patience” is still better than a rejection, but I am beginning to get impatient and this is affecting my future plans for the development of Anti-Idle: Reborn. And the Closed Beta testers are just as impatient as I am. I still believe that I have done nothing wrong, and I hoped it would be easy to show my good faith (just like how Apple immediately re-reviewed my app after I sent the evidence that I am indeed Tukkun), but I’m starting to get more and more worried as each day passes without any new information. And from what I’ve read about these appeals, most of the time they just get rejected for vague reasons. And that’s it. Over 15 years of game development, first app on Android with over 1 year of development, and my career as an Android game developer is at stake for no reason, even before the game is released. Dear everyone who is looking forward to the release of Anti-Idle: Reborn on Android, thank you for your continued support and your interest in the game. While I can’t make any promises under the current situation, I will keep you updated with any new information. Dear Google, thank you for providing a trustworthy place for app developers to provide apps to billions of users. Once again, I would like to emphasize that I understand the need for thorough app reviews and termination of accounts that violate the rules. It is what allows users to trust the Google Play Store to download and use apps. However, it also needs trust from developers so they can confidently develop great apps without the fear of everything being erased without prior warning and for no reason. Please, tell me what I am doing wrong and what I can do to have my account and my game restored. Anti-Idle: Reborn is my hopes and dreams, and a large community is waiting for it to become a reality. In case anyone at Google is reading this, my appeal ticket number is 6-1733000037134, and my game’s package ID (before it was removed from Google Play) is com.tukkun.anti.idle.reborn",
    "commentLink": "https://news.ycombinator.com/item?id=41808917",
    "commentBody": "Google Play killed my game and won't tell me why (antiidlereborn.com)121 points by xy2_ 6 hours agohidepastfavorite59 comments billy99k 5 hours agoThis is the problem with these companies having so much power. I had my Amazon seller account banned over a decade ago for a single bad review. I believe it was a competitor, because I had already refunded the customer and the negativity/review just didn't make sense. There was nobody to talk to and support just redirected me to an inbox that bounced. At time time, it destroyed my business that I had been building on the platform for five years and it took me some time to rebuild (in a different industry and not on anyone's platform). I finally got my account back a few months ago with no explanation. reply adamc 5 hours agoparentThis is the kind of thing where some level of regulation might actually improve things. reply CM30 4 hours agorootparentHmm, perhaps the law should be that any business selling to the public has to provide a way to get human led support/contact someone at the company? Not sure how it'd work for companies whose entire purpose is \"ultra cheap product/service without any guarantees\" (like many unmanaged hosting providers), but it'd certainly force Google, Facebook, Amazon, etc to actually support their customers in some way or another. reply DrillShopper 4 hours agorootparent> Not sure how it'd work for companies whose entire purpose is \"ultra cheap product/service without any guarantees\" (like many unmanaged hosting providers) Hopefully the same way the law works for a company that won't pay above minimum wage - completely destroyed in the legal system. I'm sorry if your business plan doesn't conform with law. Perhaps you should focus on a business plan that does conform with the law. reply glimshe 2 hours agorootparentprevThey should at least give companies a premium tier where human support is guaranteed. I suspect they think they are less likely to be sued if they offer no explanation reply willcipriano 2 hours agorootparentprevWe may also want to popularize the idea of not building you business with someone else's platform. If people were more skeptical of these firms in the last few decades they wouldn't have gotten off the ground in the first place. reply tdeck 51 minutes agoparentprevIt's hard to square this with the Amazon of today where sellers openly sell fake products or change the listing from one product to another and seem to face no consequences. reply anonymousiam 4 hours agoprevA few weeks ago, Google Play killed Cheogram (a XMPP communications suite). The details of the \"Anti-Idle: Reborn\" takedown are quite similar, and there has been some speculation among devs that Google has delegated too much of the app analysis legwork to AI. Disclaimer: I have no relationship with Cheogram, other than being annoyed at Google Play disappearing a useful app for which I paid $5. reply tslocum 2 hours agoprevProblems like this show why publishing outside of Google Play is necessary. I wrote about why I think F-Droid is the best alternative app store to use. https://rocket9labs.com/post/on-the-importance-of-f-droid/ reply pie420 2 hours agoparentwhat does it matter if F-Droid has 0.001% of the reach and audience of Google Play Store reply brutal_chaos_ 1 hour agorootparentChicken and egg. People need to also host on F-Droid to pull more users to F-Droid. Eventually if enough momentum is built towards F-Droid, dropping Google Play wouldn't be too much of an issue. Granted this is a really long longshot, but Google Play could use some serious competition amd the more apps that host on multple app stores, the more likely that is to happen. reply mrkramer 5 hours agoprevGame looks awesome....release it on Steam. reply bitbasher 5 hours agoparentSteam is a mess. It looks like it would do well on the Switch and you'd make a lot more money on console. reply ffsm8 5 hours agorootparentSaying that the Nintendo/Switch developer experience is better then valve/steam... Needs citations to say it mildly. reply bitbasher 3 hours agorootparentI never said the developer experience was better. I said the money was better. In my experience, a shit game on steam will make 3 figures if you're lucky. A shit game on Switch will make four figures most of the time. reply kadoban 2 hours agorootparent> In my experience, a shit game on steam will make 3 figures if you're lucky. A shit game on Switch will make four figures most of the time. Is that a good metric? Ideally shit games _should_ make very little money. Don't we want to look at what decent games are making and how they're doing? reply bitbasher 1 hour agorootparentIf a crap game makes money on the platform, a decent or good game is likely to make more. If you're doing full time game development on your own (like the linked blog post), your metric is probably more along the lines of \"which platform is most likely going to give me enough money to not reverse mortgage my home or sell a kidney.\" Steam is a tough marketplace. Crappy games do really bad. Great games don't do much better. You can sink a 1~3 years in an objectively good game and make $10k. It's a terrifying market for someone doing fulltime game development. My general advice is make smaller games (1-6 months of dev time) and target consoles unless you have a good reason to be on steam. reply mrkramer 5 hours agorootparentprev>Steam is a mess. Please elaborate? It's the best we have as of today for PC gaming. reply junaru 4 hours agorootparentMobile shovelware devs hate it because it's a stark reminder that no adult finds value in their product. reply Fire-Dragon-DoL 4 hours agorootparentI do love this statement reply pie420 2 hours agorootparent\"Why is it so hard to scam people on this platform????\" reply oniony 5 hours agorootparentprevSwitch is absolutely the worst store I've ever used. There are no useful ways to browse the content and no ratings or reviews on anything. reply glimshe 2 hours agorootparentNeither does Netflix, Apple TV etc. Many people believe reviews go against the curation paradigm and have their own problems (such as review bombing). reply rendall 5 hours agoprevThis kind of policy and publicity leads to drops in app quality. Seems quite risky to spend time and money on mobile app development. reply Mistletoe 5 hours agoprevTrying to talk to a tech giant is like trying to talk to the borg. I don’t know when it became acceptable to just have no customer service or someone to talk to at all. reply pif 5 hours agoparent> I don’t know when it became acceptable to just have no customer service or someone to talk to at all. The word that makes anything acceptable is \"cheap\". We love to buy cheap and complain about quality. But hardly anyone buys quality, if any! reply fragmede 4 hours agorootparentcomplaining costs $0 reply trabant00 5 hours agoprevA long time ago I operated an email blacklist. Since then I don't just trust by default when people shout \"they banned me for absolutely no reason, I swear!\". I am not saying anything about this case, I just notice people on HN always take these post as 100 percent true. When money is involved, people get caught and their revenue affected they are capable of spinning the wildest tales. reply yjftsjthsd-h 4 hours agoparentA while back, I operated the postfix mail servers for a B2B app. AFAIK the only way to get email from these servers was to work at a company using our product, add your email to the app, and explicitly opt into getting notification emails. And even then, the only emails they'd send were transactional emails; the marketing dept did their own unrelated thing. In spite of this, we semi-regularly found our servers blacklisted for allegedly sending spam. Since then I don't just trust by default when people add things to blacklists. All this is to agree with the sibling comments; maybe your priors give you a particular default view, but it's not universally shared, and even so Google rather suffers from a long history of banning people in ways that sure look arbitrary and then refusing to say anything about it to anyone, which rather assists in the banned party looking sympathetic. reply adamc 5 hours agoparentprevI get that life experiences give you biases. Those of us who've been blamed for things we definitely didn't do might have the opposite bias. Either way, organizations that cannot communicate why they took certain actions are not to be trusted. reply pif 5 hours agoparentprev> they banned me for absolutely no reason, I swear! I tend not to believe the \"no reason\" part, but I still stand on their side when their privileges are revoked without human intervention and without a human customer support agent available by phone. reply elashri 4 hours agorootparentI tend to always assume that when people say absolutely no reason, they mean no reason provided. What makes it worse is that there is usually no way to know because they cannot even get to talk to someone. I understand that fraud detection people don't want to let their methods public but this became the norm for most/all companies. reply indymike 1 hour agoparentprev> Since then I don't just trust by default when people shout \"they banned me for absolutely no reason, I swear!\". Email shenanigans and the shenaniganiers will quickly erode any sense of faith in your common man. That said, it's easy to believe these stories after dealing with support at any number of big tech companies. reply commandlinefan 3 hours agoparentprev> operated an email blacklist. Since then I don't just trust Curious how much you could share more details about what you discovered during that time? reply iJohnDoe 3 hours agoprevGoogle will leave apps that have viruses, spyware, and malware. They’ll remove legitimate apps. Whoever they outsourced these app reviews to is just sabotaging Google Play. reply ocdtrekkie 5 hours agoprevMicrosoft will be selling games on Android next month, Epic will be next year. The solution is competition, and we can thank Tim Sweeney for finally making it happen on mobile. reply hedora 4 hours agoparentI honestly can’t tell if the judges in these anti-trust cases intentionally screw up the penalties. Instead of forcing Google to do a thing they already do (allow alternative app stores on android), they could have banned them from distributing apps that require Google Play Services (i.e., all apps must run well on the open source version of android, which must be permissively license, and manufacturers would incur no penalties for shipping other mobile operating systems). That would instantly open the android ecosystem up to competition by making AOSP (and things like Lineage/Graphene) viable competitors. reply mindslight 2 hours agorootparentWhen these topics reach the mainstream breaking point, I swear things invariably end up going the wrong way. Look at the current movement to \"break up Google\" into independent verticals that will still each have their own network effects. Effective anti-trust would be focusing on separating the markets for hosted services from that for client software, by forcing their debundling with open APIs and whatnot. I think it has to do with the difference between top-down and bottom-up perspective. Top-down politicians/regulators/courts/whatnot end up looking at these things of how they can be contained and controlled (regardless of how they will continue wielding the leverage that allows them to dominate their specific market), whereas bottom up we look at what it would actually take to actually create some competition (despite such attempts inherently looking like baby steps at the start). reply ocdtrekkie 3 hours agorootparentprevIt's not the judge screwing up, it's you. You are showing incredible \"tech nerd\" bias by thinking Lineage or Graphene are \"competitors\" or that they could or will matter. They're nerd hobbies, they affect less than a hundredth of a percent of Android devices, and do not matter. What the judge did ban is a bunch of things Google did you may not have even realized they were doing, like the terms in the MADA agreements all manufacturers like Samsung, LG, etc. were required to sign which prevented any competition and required Play Services. The judge also banned revenue sharing agreements with manufacturers and mobile carriers used to prevent companies from using different search engines or app stores. Nobody, figuratively, will ever care about some custom ROMs. But the judge has broken all of the means Google was using to control device manufacturers. reply nosioptar 2 hours agoparentprevYou can already sell android games on itch.io reply artemonster 5 hours agoprevWelcome to dystopia. Your lifeline ends due to some automatic flagging and you are banging your head against semi-automated processes and autogenerated \"we are looking into it\" replies and the only way forward is a public outcry via blog/HN. I hate this timeline very much. Good luck with your appeal process! reply mrkramer 5 hours agoparentEven Zuckerberg complains that every time they patch some of the Meta's apps on the App Store they need to wait days or weeks in order to get approved. If Facebook and Instagram are not important to Apple and most probably Google too then we can't be surprised that indie devs get cold feet. reply mmmlinux 4 hours agorootparentI mean, that's good right? They aren't getting special treatment over anyone else. reply HideousKojima 4 hours agorootparentA company not giving priority to some of their biggest customers/revenue generators/whatever is a sign that there's deeper rot within that company. See the recent fiasco with Mozilla mishandling the uBlock Origin/Lite dev for another example of this. reply hackable_sand 2 hours agorootparentThe size of a paycheck has zero dictation of priority What dumbbells are out here optimizing for that? reply HideousKojima 2 hours agorootparentAre you serious? Suppose you're running a company, and you have two clients. One brings you $20,000 in profit a year, the other brings in $600,000 a year. Both of them have some sort of issue they need to resolve and report it to you at almost the exact same time. Let's say the smaller company reports it slightly earlier. But you only have enough manpower to solve the issues one at a time. Whose do you solve first? The incredibly obvious answer to 99% of people is to solve it for the company that brings you 30 times more profit than the other. Any other answer is a sign of severe dysfunction and or insanity in the company. reply adamc 5 hours agoparentprevMakes me think of ecology, and creatures (e.g., mites) that have high risk/high reward strategies. Sometimes you find a bubble of food and have lots of offspring! But mostly you die. I can't remember where I read about this -- DHH, maybe -- but it's also the difference between going for a sustainable business or venture capital. VCs don't care if most of their investments die horribly as long as a few make them rich. But the people who work for those businesses might care. Sometimes it's better for your own mental health to avoid these \"opportunities\". reply htek 5 hours agoparentprevYeah, gotta love the modern conveniences of fobbing your customers off to automated hell. Reminds me of my experience buying something on eBay without creating an account, having a problem with the item and no way to contact the company other than creating an eBay account and reaching out to the seller. Well, that went well as I was instantly blocked, terminated and told to never return. All I did was contact the seller with my order number, as presented by eBay, through eBay. The customer service drone was very unhelpful. Hope the OP has better luck with Google. reply HideousKojima 5 hours agoparentprevPart of me hopes a breakup of Google will fix this nonsense, another part of me worries it will only make things worse. reply adamc 4 hours agorootparentIf it makes it worse, the break-up will help the pieces die and be replaced. Or at least make it more likely, absent the huge monopoly advantage. reply amelius 5 hours agoparentprev> Welcome to dystopia The end-game of capitalism is where companies start to recursively regulate their own markets. Perhaps government regulation wasn't so bad after all? reply TheJoeMan 5 hours agoprev [–] I’m not saying it’s the author’s fault, but their metadata has many “yellow” flags… it looks like a copycat of a popular flash game, the author’s name is atypical, and they admitted to already have 2 strikes on Google Play Console. None of this is their fault, and it’s certainly a false positive. I know they’ve put in hundreds of hours of sweat on the code, but perhaps they could turn their focus to registering a corporation, getting trademark for “anti-idle”, and linking the DUNS to their app store accounts. reply waitforit 5 hours agoparent> it looks like a copycat of a popular flash game, the author’s name is atypical That popular flash game is the game of this author. > I am Tukkun, an indie game developer making games since 2008. My most significant work is a PC Flash game I made back in 2009 called Anti-Idle: The Game, uploaded to the website Kongregate. reply janice1999 4 hours agoparentprev> I’m not saying it’s the author’s fault >the author’s name is atypical I would like to know what you consider a \"typical\" name for the 2+ billion Android users. reply seba_dos1 4 hours agoparentprev> perhaps they could turn their focus to registering a corporation, getting trademark for “anti-idle”, and linking the DUNS to their app store accounts Sorry, I have an honest question as it's not marked and I can't quite figure it out - is this sarcasm? reply piva00 4 hours agoparentprev [–] Or Google could use some of the US$ 50b of profit in a quarter to have better systems and human support for this kind of automated bullshit. How many more hoops will people have to jump through because a company holding a very significant share of the market refuses to provide a basic level of support to people, people that are helping to enrich Google's own ecosystem by developing apps for their platform? reply hindsightbias 3 hours agorootparent> Alphabet net income for the quarter ending June 30, 2024 was $23.619B, a 28.59% increase year-over-year. Seems like they have a winning strategy. You get what you pay for. reply warkdarrior 3 hours agorootparentprev [–] As a Google shareholder, why should my company waste money on support? reply piva00 2 hours agorootparent [–] Because if it doesn't at some point the regulation hammer will come down on it, do you prefer your company to decide for itself how to approach customer support or do you prefer legislators to dictate how it should behave? That's the risk it takes, without support it will build up many similar cases to this one, until at some point the levee breaks and some legislator wanting to champion this issue as a cause will come for it. Or you can be short-sighted and see it as a waste, it's your choice. Notwithstanding the morality of it, of course, but since you are speaking financially I think we both know you don't care about that angle. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Tukkun, an indie game developer, has been working on \"Anti-Idle: Reborn,\" which was approved by Google and Apple, and has been in Closed Beta for a month.- On October 7, 2024, Google terminated Tukkun's account citing \"prior violations\" and \"High Risk Behavior,\" but did not provide a clear explanation, impacting his work and income.- This situation highlights a broader issue where developers experience vague account terminations, prompting calls for more transparency and clarity from platforms like Google."
    ],
    "commentSummary": [
      "Google Play removed a developer's game without explanation, underscoring the significant control tech companies have over developers.",
      "Similar incidents have been reported with Amazon and Google, where accounts or apps are banned without clear reasons or adequate support.",
      "Developers are encouraged to diversify their platforms to mitigate risks, as this situation highlights broader concerns about tech giants' customer service and the dependency risks of building businesses on their platforms."
    ],
    "points": 121,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1728650042
  },
  {
    "id": 41806629,
    "title": "Nurdle Patrol",
    "originLink": "https://www.nurdlepatrol.org/app/",
    "originBody": ".",
    "commentLink": "https://news.ycombinator.com/item?id=41806629",
    "commentBody": "Nurdle Patrol (nurdlepatrol.org)113 points by amar-laksh 13 hours agohidepastfavorite34 comments jdietrich 7 hours agoIn 2023, 221 shipping containers were lost at sea, out of a total of 250 million shipped. That's a loss rate of 0.000088%. Plastic pellets are a visible pollutant on beaches. I have not seen any evidence that they're a particularly harmful pollutant. A single 20 tonne containerload of plastic pellets can leave a visible residue on hundreds or thousands of beaches, but the 15 tonnes of CO2 emitted by the average American every year is entirely invisible. https://static1.squarespace.com/static/5ff6c5336c885a268148b... reply protonbob 6 hours agoparentThey are particularly harmful because they end up in your food and cause damage to your organs. reply jdietrich 6 hours agorootparentA plastic pellet is typically 3-5mm in diameter. I think I'd notice that in my food. Even if I did enjoy swallowing fish guts whole, a plastic pellet is just going to pass straight through my digestive system. Additives can leach out of plastics and enter the food chain, but pellets lost at sea are a completely insignificant factor because the total volume of waste produced by this route is so small. The majority of marine plastic is either post-consumer waste dumped in rivers in developing countries, or fishing gear that is lost at sea. If you're really worried about this, then you really need to take it up with the government of the Philippines and the global fishing industry. https://ourworldindata.org/ocean-plastics reply doctorhandshake 4 hours agorootparent>> a plastic pellet is just going to pass straight through my digestive system Through the mechanical grinding action of weather and tides (the same mechanisms that make sand out of rock and coral), these chunks can become much much smaller, small enough to cross the intestine into the bloodstream and small enough to cross the blood brain barrier or pass up your nose, lodging in your brain. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10141840/ https://jamanetwork.com/journals/jamanetworkopen/fullarticle... reply quietbritishjim 2 hours agorootparentIt's a pity the parent commenter led with that point. Their second point, that the overwhelming majority of ocean plastic pollution comes from those two sources, remains valid (albeit I'm not sure if it's actually true but it certainly seems feasible). reply doctorhandshake 2 hours agorootparentTo their second point, blaming the Philippines for dumping our ‘recycling’ in the ocean is a little bit like blaming African countries for burning our e-waste. We can’t pretend you can generate pounds of single-use plastic waste per person and have the problem disappear when you put it in a blue bin. Recycling is a lie invented by the packaging industry, and the reality is that we export the problem in bulk to the developing world, who inconveniently happen to share a planet, physics, and economy with us. We’re the ones buying the plastic to begin with, and it’s only right it washes onshore back here so we can’t pretend it doesn’t exist when it hits the bin. reply jdietrich 25 minutes agorootparentThe Philippines accounts for 0.16% of the world's waste plastic imports. Switzerland imports 10x more plastic waste and the Netherlands imports 100x more. Your explanation is very wrong. https://ourworldindata.org/grapher/share-plastic-waste-impor... reply FrustratedMonky 6 hours agorootparentprev\"I think I'd notice that in my food\" That isn't how food processing works. There are many steps of grinding, pulverizing, mixing, re-forming, de-forming, extruding, heating, cooling. The 3mm plastic pellet becomes a thousand smaller bits. Also, you'd be surprised how many bugs are in your creamed corn, and you don't notice those either. reply Cthulhu_ 6 hours agorootparentprevWell, probably not the nurdles themselves unless they're scooped from the oceans and used as a food additive, but they'll break down into microplastics and enter the food chain that way. The damage of said microplastics is still being researched, at the moment (I believe) it's still fairly vague, not unlike asbestos or smoking. IIRC they have been found to mimic hormones though. reply ptk 5 hours agorootparentWhat do you find vague about the studied effects of smoking or asbestos? Or did you mistype and mean “unlike” instead of “not unlike”? reply davidjhall 5 hours agorootparentI think they meant \"not unlike\" as - we didn't think asbestos was bad, then we thought it could be bad, then yes, after studies, this is really awful. Similarly, we might find that ingested plastics cause more damage than we realize now. reply jdietrich 4 hours agorootparentThere was never any doubt about asbestos, we just didn't care. https://en.wikipedia.org/wiki/Nellie_Kershaw reply amatix 4 hours agoprevThere's a similar UK initiative which has spread to a number of other countries. Nurdles are everywhere... https://www.nurdlehunt.org.uk/nurdle-finds.html reply amar-laksh 35 minutes agoparentOh thanks! I was looking for something similar when I posted. reply zombot 6 hours agoprevWow, Texas seems to be one of the worst offenders here. How do you collect close to 1000 nurdles in 10 minutes? Do people wade through them on the beach? reply api 6 hours agoparentThat doesn’t necessarily mean they are all coming from Texas though does it? It could mean ocean currents are carrying them there. I think the idea here is we have maps of ocean currents and can trace them to their likely source. reply whythre 3 hours agorootparentThat’s a good point. Texas beaches are the cul-de-sac of the Gulf Coast. Makes sense that trash would collect there. reply rc_kas 1 hour agoprevIn sprite of all the Trumps and Putins and Netanyahu's out there. This project is just that reminder : There really are good humans in the world. reply tsimionescu 9 hours agoprevMuch nicer to run into a Nurdle patrol than a Nurgle patrol (I know this is not the kind of comment HN is for, but I couldn't help it). reply flir 9 hours agoparentThe nurdles mostly come from the manufacture of Nurgles. reply wyldfire 5 hours agoparentprevWhat's worse, a patrol of Nurgles or a patrol of Nargles? reply Traubenfuchs 7 hours agoprevImagine a beach completely consisting of nurdles. Imagine an ecosystem of bacteria, microorganisms, fish and other seafood creatures adapted to living on it. I feel like as humanity we could totally reach a point where evolution to that kind of ecosystem becomes the only choice. Same for our immune, digestive and lymph system. We could end up at a point where most of life NEEDS microplastic to survive! Then we can finally stop caring about micro plastics and start loving them instead. I for one love nurdles! reply dTal 7 hours agoparent\"Evolve\" here is a neat word for \"countless trillions of creatures die preventable deaths or otherwise fail to reproduce over geological time\". If your terminal goal is to \"finally stop caring about micro plastics\" rather than \"protect Earth's existing ecosystem\", why wait? Just nuke the planet to glass. Microplastic worry over. (A similarly nihilist viewpoint comes from the people who pontificate that \"the planet will be fine, it's humans who will suffer\". Sure, if by \"the planet\" you mean \"a lump of mass orbiting the sun\". Low bar for your ethical framework.) reply flir 5 hours agorootparent> Low bar for your ethical framework Or highest. Puts overall species diversity ahead of the future of a single species (us). reply oasisbob 4 hours agorootparentprevThere's a broad read on the definition of \"social Darwinism\" I like to remember. Natural selection is a scientific concept and process. When people hijack these concepts for social or political aims, it's no longer scientific, and it's something else entirely. reply mnazzaro 7 hours agoparentprevThis is such a strange spot for a glass half full take lol. \"At least it's warm in hell!\" reply prepend 7 hours agorootparentI think the good news is that we can adapt to enjoy how warm it is in hell. So it’s bad news that we’re going to hell, good news is that we’ll eventually like it. reply mikro2nd 6 hours agoparentprevThe trouble with that notion is this: imagining that a plastic-based ecosystem arises (horrifying thought!) it means that there are life-forms capable of deriving energy from plastics, breaking them down. That makes plastics useless to us humans, because any time we try to use plastics for all the things we currently do with them, those life-forms are going to come along and attack, break down the stuff we deem \"useful plastics\"; the critters will make no distinction between nurdles lost on the beach and the plastics holding your car/house/clothes/aeroplane together. i.e. It's Game Over for plastics use. reply cglace 6 hours agorootparentThat's not necessarily true. There is an ecosystem for breaking down wood, and my house is framed in wood. reply FrustratedMonky 6 hours agorootparentTermites are a good example. They are a natural way to break down wood. And they can eat your house. Thus we have come up with ways to mitigate them. Now there is an entire industry around preventing termites, fixing termite damage, etc.. So, the problem is, we find some microbe that eats plastics. Boom, now we have a new problem, we need an entire industry to prevent them from eating the plastics we don't want them to eat. Think of traveling with your laptop, 'oops, got a little bit of plastic eating microbe, guess i'm buying a new laptop' reply Cthulhu_ 5 hours agoparentprevI mean sure, with issues like plastics, global warming, ozone layer hole, melted polar caps, extreme weather events, bug collapse, etc etc etc, life will find a way. It's not a \"final\" extinction event per se, nor one as catastrophic as the meteor strike from back when. But we are living in a mass extinction event. Billions of crabs died. Bug population has collapsed. Biodiversity has nosedived. Humanity hasn't suffered yet in terms of total population, but that's because we're able to adapt our environment accordingly. That said, we will see famines and scarcities in our lifetime. Hell, we already do, but it mainly presents itself in day to day life (in \"the west\") as some products going out of shelves (the UK having supply problems due to brexit / long border queues) or prices spiking (e.g. produce from Ukraine). But worldwide we will see more of that. As for (micro)plastics, IIRC we've yet to determine the full impact. But we know these nurdles break down into microplastics over time due to UV exposure and the like, but they don't disappear completely and find their way into everything. We'll only know the full impact looking back in a few hundred years. reply mrspuratic 2 hours agorootparentHarvest in England the second worst on record because of wet weather https://www.theguardian.com/environment/2024/oct/10/harvest-... reply amelius 6 hours agoparentprevFast forward to that future, someone says: imagine a world where we don't have to live in our own waste ... how much more efficient would our biology be? reply yashasolutions 3 hours agoprev [–] Here are the real nurds reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "In 2023, 221 shipping containers were lost at sea, a minor number compared to the 250 million shipped annually, highlighting the scale of global shipping operations.",
      "Plastic pellets, known as nurdles, are visible pollutants on beaches and can degrade into microplastics, entering the food chain and posing potential harm, though they are not the primary source of marine plastic pollution.",
      "The discussion on plastic pollution emphasizes its complexity and global impact, including the export of waste issues from developed to developing countries and the potential adaptation of ecosystems to plastic pollution, raising concerns about future plastic use."
    ],
    "points": 113,
    "commentCount": 34,
    "retryCount": 0,
    "time": 1728626403
  },
  {
    "id": 41808013,
    "title": "Initial CUDA Performance Lessons",
    "originLink": "https://probablydance.com/2024/10/07/initial-cuda-performance-lessons/",
    "originBody": "Probably Dance I can program and like games Initial CUDA Performance Lessons by Malte Skarupke I am somehow very late to learning CUDA. I didn’t even know until recently that CUDA is just C++ with a small amount of extra stuff. If I had known that there is so little friction to learning it, I would have checked it out much earlier. But if you come in with C++ habits, you’ll write suboptimal code, so here are some lessons I had to learn to get things to run fast. Memory Coalescing If you have multiple threads operating on an array in C++, you probably want to iterate like this: std::vector vec = ...; size_t per_thread = vec.size() / num_threads; T * my_slice = vec.data() + per_thread * my_thread_i; for (size_t i = 0; i 90% idle. This is changing the algorithms that are used in deep learning. If algorithm A can just do bigger matrix multiplications to get higher quality results, and algorithm B can achieve better quality results by cleverly doing lots of little pieces of work, people will choose algorithm A. Different Kinds of Memory Memory is more complicated in CUDA, but with my limited understanding so far I think of CUDA as having three different types of memory: Normal memory Shared memory (faster) Registers (fastest) Registers are particularly weird. One thread block has 65536 registers, meaning you can store 256k bytes of data in registers. Which is more than you can store in shared memory. I was trying to understand how some cuDNN kernel could possibly be as fast as it was, when I realized that they keep a particular matrix entirely in registers where each thread holds a small part of the matrix. You get some control over how many registers you have. You can have up to 1024 threads per thread block, meaning you get 64 registers per thread by default. But you could launch fewer threads and get proportionally more registers per thread. If you need, say 150 registers because you want to cache some data, you divide 65536/150 which tells you that you can use 436 threads. But you’re still just writing in C++ which doesn’t make it easy to say “keep this data in registers.” The best way I found to do this is to keep a fixed-size array on the stack and then use “#pragma unroll” in every single loop that uses that array. The loop needs to be unrolled because every unrolled iteration of the loop needs to refer to different registers. Shared memory was straightforward in comparison. It allows you to dedicate some cache space for a specific purpose, and the data is shared between threads. So you can use it for two purposes: To communicate between threads To load data more quickly: If you want to load 512 floats and you have 512 threads, every thread can load one float into shared memory. So you don’t even have to loop. Sharing is ~Free Within a Warp This one was a delight when I saw code doing this for the first time: A warp is 32 threads that share one instruction pointer. They all do the same thing at the same time. So if you e.g. parallelize a dot product, the 32 threads of the warp can sum their results to get the overall result in five steps, using a parallel sum algorithm: On a CPU this algorithm is impractical because the overhead of keeping the threads in sync is too high. But on a GPU they just are in sync, so sharing is literally five steps: __device__ float add_warp(float x) { static constexpr const unsigned all = 0xffffffff; x += __shfl_xor_sync(all, x, 1); x += __shfl_xor_sync(all, x, 2); x += __shfl_xor_sync(all, x, 4); x += __shfl_xor_sync(all, x, 8); x += __shfl_xor_sync(all, x, 16); return x; } I verified that this compiles down to two instructions each. This compiles to 5 SHFL.BFLY instructions plus 5 FADD instructions for the addition. There are no secret locks or barriers here. This only works within a warp (32 threads). For a thread block, up to 1024 threads, you can use shared memory, which requires using barriers because the threads won’t automatically be in sync. If you need more threads than that and want to share data between them, don’t. (you’ll often want many more threads, you just can’t share data. You need to write out the result to memory and then launch a new thread to work on the new data) Parallelism First My intuition for how many threads to use was wrong by a lot. If you’re iterating over some data and have to do several non-trivial things to it, it’s probably best to launch one thread for each of the things you want to do. It’s tempting to say “this thread already loaded all the relevant data, it can just do a bit of extra work” but in CUDA it’s better to launch a separate thread for that extra work, even if they both have to load the same data. It’s much cheaper for them to synchronize and share their data than it would be on a CPU. When I ran Nsight Compute on the first couple versions of my code, the feedback that came back could always be summarized as “you’re barely using the GPU, make it more parallel.” This also means that you often want to pull your algorithm apart. If there is one part that can run massively parallel (across tens of thousands of threads) and one part that has limited parallelism (say only a few hundred threads) then it’s probably worth to launch those as separate kernels to benefit from the massive parallelism on part of your problem, even if that part is only a small part. So whenever you try to solve a problem, the first question should not be “how can I make this fast?” but “how can I run this in parallel?” After you solve that, worry about making the parallel code fast. Conclusion Writing CUDA definitely has a different feeling. It feels more puzzly because it’s so easy to accidentally only use 1% of your GPU. It actually reminds me of TIS-100, especially the trick of distributing data in the registers of multiple threads. But instead of managing a small number of chips you have to figure out how to generate work for tens of thousands of threads. My mental model is that you’ve got a bunch of container ships that can travel at 10% of the speed of light. You’re using them to ship goods around the world. They’re very fast so most of the work is in setting up your harbors so that you can load and unload these container-ships in fractions of a second so that it can sail to do the next thing. It’s not easy to feed these beasts, but if you do it right you can do huge chunks of work in almost no time. Share this: Twitter Facebook Like Loading... Related Published: October 7, 2024 Filed Under: Programming Tags: C++ : CUDA : performance : Programming Leave a comment This site uses Akismet to reduce spam. Learn how your comment data is processed. « Previous Post Search for: Recent Posts Initial CUDA Performance Lessons How I use LLMs to program Transform Matrices are Great and You Should Understand Them Two Kids Put Me on a Two Sleep Schedule Beautiful Branchless Binary Search Archives October 2024 April 2024 October 2023 September 2023 April 2023 December 2022 September 2022 June 2022 February 2022 January 2022 October 2021 July 2021 April 2021 January 2021 November 2020 October 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 January 2020 December 2019 September 2019 August 2019 June 2019 April 2019 March 2019 June 2018 May 2018 April 2018 January 2018 December 2017 November 2017 October 2017 September 2017 August 2017 February 2017 January 2017 December 2016 November 2016 June 2016 April 2016 March 2016 February 2016 December 2015 September 2015 July 2015 June 2015 May 2015 February 2015 January 2015 December 2014 November 2014 October 2014 September 2014 August 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 October 2013 September 2013 August 2013 May 2013 February 2013 January 2013 December 2012 November 2012 October 2012 August 2012 July 2012 April 2012 March 2012 February 2012 January 2012 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 Categories Children Games Links Math Politics and Economics Programming Uncategorized Meta Register Log in Entries feed Comments feed WordPress.com Blog at WordPress.com. %d",
    "commentLink": "https://news.ycombinator.com/item?id=41808013",
    "commentBody": "Initial CUDA Performance Lessons (probablydance.com)112 points by ibobev 9 hours agohidepastfavorite28 comments elashri 5 hours agoI like this writeup as it summarizes my journey with optimizing some cuda code I wrote for an LHC experiment trigger. But there are few comments on some details. There are 65536 registers per SM not thread block and while you can indirectly control that by making your block takes all the SM but this presents its own problems. NVIDIA hardware limits the threads max number to 1024 (2048) and shared memory to 48 KB (64 KB) per SM. So if you consume all of that in one thread block or near the maximum then you are using one thread block per SM. You don't usually want to do that because it will lower your occupancy. Additionaly , If the kernel you’re running is not compute-bound and does not need all the registers or shared memory allocated to it, having fewer blocks on the SM could leave some compute resources idle. GPUs are designed to thrive on parallelism, and limiting the number of active blocks could cause underutilization of the SM’s cores, leading to poor performance. Finally, If each thread block occupies an entire SM, you limit the scalability of your kernel to the number of SMs on the GPU. For example, if your GPU has 60 SMs, and each block uses one SM, you can only run 60 blocks in parallel, even if the problem you’re solving could benefit from more parallelism. This can reduce the efficiency of the GPU for very large problem sizes. reply otherjason 1 hour agoparentFor devices with compute capability of 7.0 or greater (anything from the Volta series on), a single thread block can address up to the entire shared memory size of the SM; the 48 kB limit that older hardware had is no more. Most contemporary applications are going to be running on hardware that doesn’t have the shared memory limit you mentioned. The claim at the end of your post, suggesting that >1 block per SM is always better than 1 block per SM, isn’t strictly true either. In the example you gave, you’re limited to 60 blocks because the thread count of each block is too high. You could, for example, cut the blocks in half to yield 120 blocks. But each block has half as many threads in it, so you don’t automatically get any occupancy benefit by doing so. When planning out the geometry of a CUDA thread grid, there are inherent tradeoffs between SM thread and/or warp scheduler limits, shared memory usage, register usage, and overall SM count, and those tradeoffs can be counterintuitive if you follow (admittedly, NVIDIA’s official) guidance that maximizing the thread count leads to optimal performance. reply dahart 4 hours agoparentprevGood points, though I agree with sibling that higher occupancy is not the goal; higher performance is the goal. Since registers are such a precious resource, you often want to set your block size and occupancy to whatever is best for keeping active state in registers. If you push the occupancy higher, then the compiler might be forced to spill registers to VRAM, that that will just slow everything down even though the occupancy goes up. Another thing to maybe mention, re: “if your GPU has 60 SMs, and each block uses one SM, you can only run 60 blocks in parallel”… CUDA tends to want to have at least 3 or 4 blocks per SM so it can round-robin them as soon as one stalls on a memory load or sync or something else. You might only make forward progress on 60 separate blocks in any given cycle, but it’s quite important that you have like, for example, 240 blocks running in “parallel”, so you can benefit from latency hiding. This is where a lot of additional performance comes from, doing work on one block while another is momentarily stuck. reply winwang 1 hour agorootparentIs this really true in general? I'd expect it to be true for highly homogenous blocks, but I'd also expect that kernels where the warps are \"desynced\" in memory operations to do just fine without having 3-4 blocks per SM. reply jhj 4 hours agoparentprevAiming for higher occupancy is not always a desired solution, what frequently matters more is avoiding global memory latencies by retaining more data in registers and/or shared memory. This was first noted in 2010 and is still true today: https://www.nvidia.com/content/gtc-2010/pdfs/2238_gtc2010.pd... I would also think in terms of latency hiding rather than just work parallelism (though latency hiding on GPUs is largely because of parallelism). This is the reason why GPUs have massive register files, because unlike modern multi-core CPUs, we omit latency reducing hardware (e.g., speculative execution, large caches, that out-of-order execution stuff/register renaming etc) and in order to fill pipelines we need to have many instructions outstanding, which means that the operands for those pending arguments need to remain around for a lot longer, hence the massive register file. reply elashri 4 hours agorootparentI agree that optimizing for lower occupancy can yield significant performance gains in specific cases, especially when memory latencies are the primary bottleneck. Leveraging ILP and storing more data in registers can indeed help reduce the need for higher occupancy and lead to more efficient kernels. The examples in the GTC2010 talks highlighted that quite well. However, I would argue that occupancy still plays an important role, especially for scalability and general-purpose optimization. Over-relying on low occupancy and fewer threads, while beneficial in certain contexts, has its limits. The first thing to consider is the register pressure. Increasing the number of registers per thread to optimize for ILP can lead to register spilling when the register file is exhausted, which drastically reduces performance. This becomes more pronounced as problem sizes scale up (the talk examples avoids that problem). Many real-world applications, especially compute-bound kernels, need high occupancy to fully utilize the GPU’s resources. Focusing too much on minimizing thread counts can lead to underutilization of the SM’s parallel execution units. An standard example will be inference engines. Also, while low-occupancy optimizations can be effective for specific workloads (e.g, memory-bound kernels), designing code that depends on such strategies as a general practice can result in less adaptable and robust solutions for a wide variety of applications. I believe there is a balance to strike here. low occupancy can work for specific cases, higher occupancy often provides better scalability and overall performance for more general use cases. But you have to test for that while you are optimizing your code. There will not be a general rule of thump to follow here. reply Mithriil 40 minutes agoprevIn the conclusion, I like the image: > My mental model [for GPU threads] is that you’ve got a bunch of container ships that can travel at 10% of the speed of light. You’re using them to ship goods around the world. They’re very fast so most of the work is in setting up your harbors so that you can load and unload these container-ships in fractions of a second so that it can sail to do the next thing. It’s not easy to feed these beasts, but if you do it right you can do huge chunks of work in almost no time. reply amelius 4 hours agoprevIn the 90s we had segmented memory programming with near and far pointers, and you had to be very careful about when you used what type of pointer and how you'd organize your memory accesses. Then we got processors like the 286 that finally relieved us from this constrained way of programming. I can't help but feel that with CUDA we're having new constraints (32 threads in a warp, what?), which are begging to be unified at some point. reply dahart 4 hours agoparentWhile reading I thought you were going to suggest unified memory between RAM and VRAM, since that’s somewhat analogous, though that does exist with various caveats depending on how it’s setup & used. SIMD/SIMT probably isn’t ever going away, and vector computers have been around since before segmented memory; the 32 threads in a CUDA warp is the source of its performance superpower, and the reason we can even fit all the transistors for 20k simultaneous adds & multiplies, among other things, on the die. This is conceptually different from your analogy too, the segmented memory was a constraint designed to get around pointer size limits, but 32 threads/warp isn’t getting us around any limits, it’s just a design that provides high performance if you can organize your threads to all do the same thing at the same time. reply krapht 4 hours agoparentprevI'll believe it when autovectorization is actually useful in day to day high performance coding work. It's just a hard problem. You can code ignorantly with high level libraries but you're leaving 2x to 10x performance on the table. reply talldayo 4 hours agoparentprevYou can blame ARM for the popularity of CUDA. At least x86 had a few passable vector ISA ops like SSE and AVX - the ARM spec only supports the piss-slow NEON in it's stead. Since you're not going to unify vectors and mobile hardware anytime soon, the majority of people are overjoyed to pay for CUDA hardware where GPGPU compute is taken seriously. There were also attempts like OpenCL, that the industry rejected early-on because they thought they'd never need a CUDA alternative. Nvidia's success is mostly built on the ignorance of their competition - if Nvidia was allowed to buy ARM then they could guarantee the two specs never overlap. reply oivey 3 hours agorootparentCUDA clobbered x86, not ARM. Maybe if x86’s vector ops were better and more usable ARM would have been motivated to do better. reply refulgentis 2 hours agorootparentWhole concept sounds like groping in the dark for a Take to me: GPUs (CUDA) are orthogonal to consumer processors (ARM / X86). Maybe we could assume a platonic ideal merged chip, a CPU that acts like a GPU, but there's more differences between those two things than an instruction set for vector ops. reply talldayo 43 minutes agorootparent> GPUs (CUDA) are orthogonal to consumer processors (ARM / X86). We're talking about vector operations. CUDA is not a GPU but a library of hardware-accelerated functions, not necessarily different from OpenCL or even NEON for ARM. You can reimplement everything CUDA does on a CPU, and if you're using a modern CPU you can vectorize it too. x86 handles this well, because it's still got dedicated logic that keeps pace with the SIMD throughput an integrated GPU might offer. ARM leaves out the operations entirely (which is smart for efficiency), and therefore either relies on someone porting CUDA code to an ARM GPU shader (fat chance) or offloading to a remote GPU. It's why ARM is excellent for sustained simple ops but collapses when you benchmark it bruteforcing AI or translating AVX to NEON. SIMD is too much for a base-spec ARM core. > Maybe we could assume a platonic ideal merged chip, a CPU that acts like a GPU, but there's more differences between those two things than an instruction set for vector ops. Xeon Phi or Itanium flavored? reply refulgentis 11 minutes agorootparentI've read this 10x and get more out of it each time. I certainly don't grok it yet, so I might be wrong when I say its still crystal clear there's a little motte/bailey going on with \"blame ARM for CUDA\" vs. \"ARM is shitty at SIMD vs. X86\" That aside, I'm building something that relies on llama.cpp for inference on every platform. In this scenario, Android is de facto \"ARM\" to me. The Vulkan backend doesn't support Android, or it does, and the 1-2 people who got it running see absurdly worse performance. (something something shaders, as far as I understand it) iOS is de facto \"not ARM\" to me because it runs on the GPU. I think llama.cpp isn't a great scenario for me to learn at the level you understand it, since it's tied to running a very particular kind of thing. That aside, it was remarkable to me that my 13th gen Intel i5 framework laptop gets 2 tokens/sec on on iGPU and CPU. And IIUC, your comment explains that, in that \"x86...[has] dedicated logic that keeps pace with SIMD...on [an integrated GPU]\" That aside, my Pixel Fold (read: 2022 mid-range Android CPU, should certainly be slower than 2023 Intel mid-upper range) kicks it around the block. 7 tkns/sec on CPU. 14 tkns/sec with NEON-layout. Now, that aside, SVE was shown to double that again, indicating there's significant headroom on NEON. (https://github.com/ggerganov/llama.cpp/pull/9290) (I have ~0 idea what this is other than 'moar SIMD for ARM', for all I know, it's Amazon Graviton specific) reply oivey 2 hours agorootparentprevYeah, that’s true. CUDA is in large part for big HPC servers, where ARM historically wasn’t a player and still isn’t dominant. x86 got clobbered for HPC by CUDA. reply dboreham 4 hours agoparentprev386? reply lmeyerov 2 hours agoprevNice! It's interesting from the perspective of maintenance too. You can bet most constants like warp sizes will change, so you get into things like having profiles, autotuners, or not sweating the small stuff. We went more extreme, and nowadays focus on several layers up: By accepting the (high!) constant overheads of tools like RAPIDS cuDF , we get in exchange the ability to easily crank code with good saturation on the newest GPUs and that any data scientist can edit and extend. Likewise, they just need to understand basics like data movement and columnar analytics data reps to make GPU pipelines. We have ~1 CUDA kernel left and many years of higher-level. As an example, this is one of the core methods of our new graph query language GFQL (think cypher on pandas/spark, w optional GPU runtime), and it gets Graph500 level performance on cheapo GPUs just by being data parallel with high saturation per step: https://github.com/graphistry/pygraphistry/blob/master/graph... . Despite ping-ponging a ton because cudf doesn't (yet) coalesce GPU kernel calls, V1 competes surprisingly high, and is easy to maintain & extend. reply trentnelson 2 hours agoparentHad any exposure to r=2 hypergraph implementations on the GPU? Ideally with an efficient way to determine if the graph is acyclic? (The CPU algos for doing this work great on CPUs but are woeful on GPUs.) reply lmeyerov 1 hour agorootparentPretty good - r=2 is a regular graph afaict, and basically anything that maps to a frontier-based pattern works well. Ex: level synchronous bfs during topological sort. For the 'easy' way we do in gfql, which is basically vector ops on bulk wavefronts, we can do massive cypher traversals like you're asking, like 100M edges touched in a result substep, and on a tiny GPU. There are other such bulk patterns we want to add such as Pregel style, which open other algorithms here. In practice we can often just call cudf/cugraph as building blocks so haven't had the pressure to do so yet. The weak spot I find is more like small OLTP lookups. Ex: Imagine a taxi routing traffic service pinging for one car to do a couple hops out, where you just want a KV store in cheap RAM. But if you are batching those queries, like in a heavy city, and going deeper on them, maybe more interesting. reply bagels 1 hour agoprevDefinitely not an expert, but trying to use AVX instructions explicitly in a c++ program can also produce un-optimal performance vs. just letting the optimizer decide, much like this article points out with not shaping your memory and compute to fit the GPU model. reply miki123211 3 hours agoprevWhat are some actually good resources to learn this stuff? reply corysama 3 hours agoparentI answered that recently here: https://old.reddit.com/r/GraphicsProgramming/comments/1fpi2c... reply markhahn 3 hours agoparentprevthere are a thousand excellent CUDA programming courses/sites. none of what was mentioned in this blog post is news if you've ever had more than 2 hours of a CUDA course... reply markhahn 3 hours agoprev [–] little annoying to see the one-core-compared-to-whole-gpu comparisons - now decades past when this was an innocent wrong. compare a 500W GPU to all the cores of a 500W CPU, please. I'm not expecting the CPU (say, a 192-core AMD that does fast AVX512) to beat the GPU on all data-parallel workloads, but it won't be the silly sort of graphs shown in this blog. or compare one SM to one CPU core - that has merit as well. best yet, we're finally getting some CPUs (well, APUs...) with in-package RAM. that makes the comparison more interesting as well. reply oivey 3 hours agoparent [–] The first example plot is a 9950X that includes all threads with AVX512 vs a 4090. The 9950X has a 170W TDP, which doesn’t include any other components like the RAM or motherboard. The 4090’s total max power is ~450W. The chart shows the 4090 burying the 9950X by far more than 450/170. Comparing SMs to CPU cores 1:1 also makes no sense. They don’t do the same things. reply adrian_b 2 hours agorootparent [–] It should be kept in mind that a 4090 only buries a 9950X for FP32 computations. For FP64 computations, the reverse happens, a 9950X buries a 4090, despite the latter having a 3-times higher price and a 2.5-times higher power consumption. For FP64 operations, 4090 and 9950X are able to do a similar number of operations per clock cycle (288 vs. 256), but 9950X can do them at a double clock frequency and it is easier to reach a high fraction of the maximum theoretical throughput on a 9950X than on a 4090. reply xfalcox 1 hour agorootparent [–] What about FP8? It is a target that is very popular for LLM inference. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Malte Skarupke discusses his experience learning CUDA, noting that it is essentially C++ with additional features for parallel computing.",
      "Key lessons for optimizing CUDA performance include memory coalescing, understanding various memory types, and maximizing parallelism by using many threads and separating tasks into different kernels.",
      "Skarupke emphasizes that writing CUDA is akin to solving a puzzle, where the primary focus should be on running tasks in parallel before optimizing for speed."
    ],
    "commentSummary": [
      "The discussion focuses on optimizing CUDA code for GPU performance, specifically for an LHC (Large Hadron Collider) experiment trigger, by managing registers, shared memory, and thread blocks.",
      "It emphasizes the trade-offs between occupancy (the number of active threads), register usage, and memory latencies, highlighting the evolution of programming constraints in CUDA.",
      "The conversation compares GPU and CPU performance, noting differences in power consumption and computational capabilities, and stresses the importance of balancing occupancy and performance for future hardware and software advancements."
    ],
    "points": 112,
    "commentCount": 28,
    "retryCount": 0,
    "time": 1728640892
  },
  {
    "id": 41802823,
    "title": "The FBI created a coin to investigate crypto pump-and-dump schemes",
    "originLink": "https://www.theverge.com/2024/10/10/24267098/fbi-coin-crypto-token-nexgenai-sec-doj-fraud-investigation",
    "originBody": "Tech/ US & World/ Crypto The FBI secretly created a coin to investigate crypto pump-and-dump schemes The FBI secretly created a coin to investigate crypto pump-and-dump schemes / NexFundAI, the FBI’s Ethereum-based token, was used to investigate price manipulation in crypto markets. By Gaby Del Valle, a policy reporter. Her past work has focused on immigration politics, border surveillance technologies, and the rise of the New Right. Oct 10, 2024, 5:58 PM UTC Share this story Image: The Verge The FBI created a cryptocurrency as part of an investigation into price manipulation in crypto markets, the government revealed on Wednesday. The FBI’s Ethereum-based token, NexFundAI, was created with the help of “cooperating witnesses.” As a result of the investigation, the Securities and Exchange Commission charged three “market makers” and nine people for allegedly engaging in schemes to boost the prices of certain crypto assets. The Department of Justice charged 18 people and entities for “widespread fraud and manipulation” in crypto markets. The defendants allegedly made false claims about their tokens and executed so-called “wash trades” to create the impression of an active trading market, prosecutors claim. The three market makers — ZMQuant, CLS Global, and MyTrade — allegedly wash traded or conspired to wash trade on behalf of NexFundAI, an Ethereum-based token they didn’t realize was created by the FBI. “What the FBI uncovered in this case is essentially a new twist to old-school financial crime,” Jodi Cohen, the special agent in charge of the FBI’s Boston division, said in a statement. “What we uncovered has resulted in charges against the leadership of four cryptocurrency companies, and four crypto ‘market makers’ and their employees who are accused of spearheading a sophisticated trading scheme that allegedly bilked honest investors out of millions of dollars.” Liu Zhou, a “market maker” working with MyTrade MM, allegedly told promoters of NexFundAI that MyTrade MM was better than its competitors because they “control the pump and dump” allowing them to “do inside trading easily.” An FBI spokesperson told CoinDesk that there was limited trading activity on the coin but didn’t share additional information. On a Wednesday press call, Joshua Levy, the acting US attorney for the District of Massachusetts, said trading on the token was disabled, according to CoinDesk. The DOJ has reportedly secured $25 million from “fraudulent proceeds” that will be returned to investors. Most Popular Most Popular Tesla Cybercab announced: Elon Musk’s robotaxi is finally here Tesla’s Robovan is the surprise of the night The bill finally comes due for Elon Musk Tesla’s Cybercab robotaxi event: the biggest news and announcements Tesla’s Optimus bot makes a scene at the robotaxi event Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=41802823",
    "commentBody": "The FBI created a coin to investigate crypto pump-and-dump schemes (theverge.com)109 points by croes 23 hours agohidepastfavorite122 comments loeg 22 hours agoThere is a nice Levine column on the same topic today: https://www.bloomberg.com/opinion/articles/2024-10-10/crypto... reply wslh 21 hours agoparenthttps://archive.is/2024.10.10-162504/https://www.bloomberg.c... reply chirau 21 hours agorootparentHow do you generate these links? Whenever I try, it says the URL is currently live or something like that. reply bagels 21 hours agorootparentThere are two url inputs, use the other one. reply woleium 11 hours agorootparenti use this as a bookmark javascript:location.href='https://archive.is/?run=1&url=%27+encodeURIComponent(documen... reply ucarion 22 hours agoprevI think this is the website for the FBI's sting? https://nexfundai.com/ I find it interesting that they made up both \"NexFundAI\" and \"NextFundAI\" (with a t) with some sort of made-up relationship between the two. reply jackcosgrove 21 hours agoparentThe stock photos of robots with glowing fingertips pointing at charts projected onto a glass screen are :chefs_kiss: reply Lockal 21 hours agorootparentAlso page-source looks ai-generated. Each tag is annotated, as ifis not self-explanatory enough. reply VagabundoP 20 hours agoparentprevWhere can I buy this coin? reply petesergeant 21 hours agoparentprev> With every transaction supply shrinks by burning a percentage of reflections to the burn wallet … Reflections get distributed to loyal holders with each transaction. “Now the first thing to say is that this is definitely not Pyramid Selling, ok?” https://youtu.be/KCQtKOm_pcw?feature=shared reply Fauntleroy 20 hours agoparentprevI don't know if it was present when you linked this, but there's a huge banner on the site confirming this as of now. reply benmmurphy 21 hours agoprevHow is this not entrapment? Wouldn’t it be better for the FBI to investigate crypto scammers using their own coin than to create a coin for the purpose of scamming? I feel like law enforcement always uses the option which produces easy prosecutions rather than the more difficult option that involves complex investigations that has more risk but more likely to produce long term good. reply ceejayoz 20 hours agoparentIt’s only entrapment if you push someone into doing something they wouldn’t normally do. If the FBI threatens your family to get you to commit a crime, that’s entrapment. If you pull up to a sex worker and proposition them, but it turns out to be a cop, that’s not entrapment. Because you were looking to commit the crime. reply soco 6 hours agorootparentPeople: coins are great because everybody can create them. FBI: creates coins. People: not like that reply jsheard 20 hours agoparentprevIANAL but my understanding is it's only entrapment if they encouraged the other parties to commit crimes they may not have otherwise, if those other parties approached FBIcoin with a proposal to do crimes entirely of their own accord then it's a kosher sting operation. reply phil21 20 hours agoparentprevFor all intents and purposes entrapment basically doesn’t exist according to modern court interpretation. If you as a layman think it’s entrapment it’s probably not. reply nimbius 20 hours agorootparentSo, for clarification: Police are allowed to set up stings . if you walk in to a crack house and willingly buy crack, thats on you. You broke the law and there was intention to do so. If the government say, gave you money and told you to invest it with their friend at glowcoin to dump it, that would be entrapment. Local us government agencies at the state level routinely get slapped down for entrapment. The FBI, not so much... reply pests 17 hours agorootparentIn my view it gets iffy in some situations. If they set up that crackhouse in a neighborhood with no crack, where no one knows where to get crack and there are no users... Then the person walking in wouldn't have been doing so if they didn't set up the trap in the first place. Giving it as an option.. allows a crime to be committed that otherwise wouldn't. reply EasyMark 14 hours agoparentprevEntrapment is sitting at a bar and pushing someone to take the prostitute at the end of the bar for hotel room transaction. Whereas if you proposition the FBI agent who is just sitting at the bar looking cute and offer her money for sex, that’s a legitimate bust. reply nostrademons 20 hours agoparentprevIt'd depend heavily on what the specific circumstances of the FBI's actions were. Creating a coin to investigate pump & dumps is not entrapment. That's a legal action, and one that many legit people and businesses do. It's akin to standing up a server on the Internet to see who hacks it. If they approached a market maker who was not otherwise marketing pump & dumps and said \"Hey, I have this coin, can you pump it up so I can exit with a profit?\" and the market maker replies \"This is not normally something we do, we're not interested\" and then the FBI keeps approaching them with progressively higher prices until they give in, they'd have a good case for entrapment. If they threaten the market maker's family, it'd be a very good case. But note that even if it's the FBI doing the approaching, but the market maker just says \"Sure, here's the price\", it's still not entrapment. In that situation they're still clearly willing to commit crimes. reply JackYoustra 21 hours agoparentprevlaw enforcement has limited resources, and must try to catch the most criminals and dissuade the most crime given said resources. It's especially bad in tax these days, there are tens of thousands of people with incomes over a million dollars that the US doesn't have the capacity to go after. reply benmmurphy 20 hours agorootparentIt is a complex situation. The worst case scenario from these entrapment operations is the FBI incentives people into a committing a crime they would otherwise not have committed. The end result is more crime, but maybe it kind of nets out because FBI has 100% success and victims are made whole but then you have the sunk cost of this FBI work. The more optimal case is the FBI nabs people who would have otherwise committed another crime and this is a more efficient way of dealing with these people than investigating real crimes. My concern is the FBI doesn’t actually try and determine which is the best allocation of resources but just presses the button that makes the FBI look best. Investigating real crimes is a lot more difficult than investigating these ‘sting’ crimes so if investigating ‘sting’ crimes was less efficient then it might be incorrectly priotized. reply vlovich123 20 hours agorootparentprevThat’s the IRS not the FBI. reply samatman 20 hours agoparentprevFundamentally, it's not entrapment because entrapment doesn't mean what many of us, myself included, feel that it should mean. The crime was committed. So the burden of proof falls on the defendant to demonstrate entrapment, which only happens if they can make a convincing case that they were not otherwise inclined or likely to commit the crime. That's quite difficult to do when, in fact, they did commit the crime. I think the standard should be stiffer: it should need a preponderance of evidence (not proof beyond reasonable doubt) that the defendant either also committed similar crimes, or was demonstrably predisposed to committing the crime in question. I rather suspect that the defendants in this case would not be able to mount that defense either. But I've grown quite tired of reading about the FBI hitting up some random resentful teenager and talking him into buying a fake bomb. reply JumpCrisscross 15 hours agorootparent> it should need a preponderance of evidence (not proof beyond reasonable doubt) that the defendant either also committed similar crimes That seems to be true here. They didn’t just set up a bait car, they followed it to the yard where the thieves stored their other stolen cars. reply CPLX 20 hours agoparentprevThey were targeting companies that performed market manipulation as a service for creators of crypto coins. So they created a coin to pose as a customer of this service. It’s just not entrapment at all, it’s not similar or close to entrapment either. It’s analogous to posing as a drug dealer to bust money laundering services, or posing as a car thief to bust a fencing operation. reply cyanydeez 21 hours agoparentprevBy not pumping and dumping? reply daniel_iversen 20 hours agoparentprevCame here to ask the same. I guess it's entrapment when law enforcement induces a person to commit a crime they otherwise wouldn't have.. so maybe it depends on how hard and well they marketed it? :) It's such a fine line - both legally maybe (IANAL) but certainly morally I feel. reply fragmede 19 hours agoparentprevEntrapment is when the police threaten you into doing something you wouldn't normally do. I'll kill your daughter if you don't rob the bank. If you weren't going to rob the bank and you just happened to have bank robbing tools and you really weren't going to use them, that's actually totally fine. if it was the cops threatening you that made you rob the bank then that's entrapment. reply ceejayoz 6 hours agorootparentThreaten, or beg/cajole. https://en.wikipedia.org/wiki/Jacobson_v._United_States They tried to push him into ordering CSAM for years, with fake penpals, fake advocacy organizations, fake catalogs, etc. Gave up repeatedly, but after three years they finally got him to bite. reply Capricorn2481 20 hours agoparentprevEntrapment would be if they encouraged people to break the law who otherwise wouldn't be pre-disposed to doing that. It's a fairly difficult thing to prove, but nothing they talk about here rises anywhere close to that. They just made their own coin. reply potato3732842 20 hours agoparentprev>How is this not entrapment? Look at the majority of the replies to your comment. Now imagine twelve of those people on a jury and a defendant who isn't mother teresa. That's how. reply Capricorn2481 20 hours agorootparentNow I'm imagining if you were on the jury because you don't know what you're talking about. It's just not entrapment. If an FBI agent sells you a baseball bat and you kill someone with it, that's hardly entrapment. There's lots of actual terrible things the FBI does that there's no reason to make something out of nothing. reply potato3732842 20 hours agorootparentIt's never that cut and clear. They're usually going out of their way to create some situation that temps people who don't normally do that type of crime to do it. The quintessential example is a bait car with the keys in it. Every real car theif walks right on by and after a week of it sitting there they nab some teenager with a weed dealing prior and then throw the book. Yeah, he did steal it but he probably wouldn't have if he didn't walk by it sitting there with the keys in it for an f-ing week. Frequently when it's \"real crime\" they're going after informants are involved and that often muddies the waters a lot since the informant is usually trying to get a break on some other charge. reply rainsford 17 hours agorootparent\"I was tempted\" is generally not considered a legal defense if you commit a crime. What difference does it make if the police created the particular temptation? If the person in your example stole a non-bait car where the owner was just careless about leaving their keys inside, that's still a crime right? How does the police creating a similar situation change the legal facts at all? Entrapment debates are also a pretty good opportunity to apply the average person heuristic. Would the average person likely steal a car if they saw the keys sitting inside? Probably not, so someone who would do that is arguably predisposed to committing the crime if presented with the opportunity. Now there's a very valid argument to be had about whether or not it's a good use of police time trying to catch lazy criminals (i.e. those that are willing to commit a crime but only when it's super easy). But that's a police policy discussion, not a legal defense. The criminals in those situations still deserve to be charged. reply Capricorn2481 20 hours agorootparentprev> They're usually going out of their way to create some situation that temps people who don't normally do that type of crime to do it So you're just making up that they did that here because your gut says they usually do that? > The quintessential example is a bait car with the keys in it. Every real car theif walks right on by and after a week of it sitting there they nab some teenager and then throw the book. Yeah, he did steal it but he probably wouldn't have if he didn't walk by it sitting there with the keys in it for an f-ing week. We're looking at multiple individuals collaborating long-term saying they can \"control the pump and dump\" and do \"inside trading easily.\" These are just scammers doing scam things. reply potato3732842 19 hours agorootparentThe fact that you fall back to \"these are bad guys doing bad things and in this particular case it wasn't entrapment\" brings us around to the first point about juries. reply kortilla 20 hours agorootparentprev> The quintessential example is a bait car with the keys in it. A bait car isn’t entrapment either. I don’t think you’re understanding the term. Making a crime look easy is not entrapment. Putting on a short dress is not “rape entrapment”. reply j0hnyl 17 hours agoprevThe thing about crypto pump and dump schemes is that usually the folks issuing the tokens are the ones doing the pumping and dumping. reply guywithahat 20 hours agoprevThe FBI really shouldn’t be creating fake securities for people to buy. I don’t think any of the fake companies they make (including the secure phone one) should be allowed. It’s a bad use of taxpayer funds and it’s not how government should be arresting people reply janalsncm 20 hours agoparentI don’t mind it. They’re taking down seasoned scammers. We all agree they should be punished, now we’re just arguing about how to catch them. If you want to be upset about government overreach, look into Richard Glossip’s case. He’s been on death row in Oklahoma for decades for a murder even Oklahoma agrees he didn’t commit, based on the false testimony of the actual murderer. reply Geeek 20 hours agoparentprevWhy not? reply mschuster91 20 hours agorootparentA reasonable argument can be made that the government enticed people to break the law. In some jurisdictions (like Germany) this kind of behavior is illegal for the police to use, only the secret services can do so (but only very limited in scope, and their discoveries are all but impossible to share with police). reply Geeek 19 hours agorootparentHow did they entice anyone to commit a crime? They created a vessel for crime to occur, and it occurred because the criminals wanted to commit the crime. reply moolcool 6 hours agorootparentprevThat's like saying speeders are enticed by government built roads reply the_gorilla 20 hours agoparentprevThis is apparently a controversial opinion but I don't think the government should be allowed to break the law. And no cheating by writing a law that laws don't apply to you. reply ceejayoz 20 hours agorootparentSo, emergency vehicles should do the speed limit and wait for red lights? reply jjulius 20 hours agorootparentThe post you're responding to says that they shouldn't break the law. Emergency vehicles are allowed, by written law, to exceed the speed limit and move through red lights. Here's one, for instance... https://oregon.public.law/statutes/ors_820.300 reply creato 20 hours agorootparentIt also says: > And no cheating by writing a law that laws don't apply to you. reply jjulius 20 hours agorootparentI mean, there's a difference between writing an exemption just so you can do a thing without getting in trouble, and writing an exemption that is so obviously for the benefit and health of society/community writ large. I can't think of a crappier example to have used to have tried to make the point they're making. reply janalsncm 20 hours agorootparentThe FBI didn’t write the law. And it’s not for the benefit of the FBI, it’s for the purpose of getting scammers off the street. Billions of dollars have been lost of crypto scams. reply ceejayoz 18 hours agorootparentprevThe parent poster called that sort of exemption “cheating”. reply jjulius 18 hours agorootparenthttps://news.ycombinator.com/item?id=41804340 reply wizzwizz4 20 hours agorootparentprevNot all emergency vehicles are the government. reply Capricorn2481 20 hours agorootparentprevAnd where did they break the law? reply axlee 20 hours agorootparentprevWash traders are the ones breaking the law. reply mattmaroon 21 hours agoprevI realize I’ll be in the minority here saying this but: Isn’t all crypto a pump and dump scheme? It has no intrinsic return, it only makes you money if someone buys it from you at a higher price than you paid for it. It’s still barely used as money. Any actual utility imagined for cryptocurrency has yet to materialize in any significant quantity despite nearly a decade of tech bros telling me it’s coming any day. I’d bet less than 0.1% of good and services are actually bought with it. (Optimistic estimates are 0.2%). So it’s clearly not primarily used as currency. You can’t eat it and it doesn’t pay a dividend. It’s just people pumping and dumping and other people hoping to time their purchases and sales along with the pump and dumpers. reply lallysingh 21 hours agoparentYou'll end up in a slippery slope there, though. Lots of stocks don't pay dividends, and you can't eat them either. But one use is to get around currency controls / manipulation by the government. Not a big deal in EUR/USD countries, but some places limit how much money you can take with you outside, or occasionally invalidate their old currency for a new one altogether. reply popcalc 20 hours agorootparent> Lots of stocks don't pay dividends, and you can't eat them either. Yes, you can. If you are an UHNWI your private banker who also manages your portfolio will organize cash loans to you and your family using the shares as collateral. It just shows up in your bank account and you pay your bills, go eat out and live off that tax free income. If you don't have major equity holdings (say a kleptocrat living in London who, coming from the wild-west has an aversion to publicly listed equities) your banker will do the same but using your real estate holdings, yachts, etc. as the collateral. reply kortilla 20 hours agorootparentThey will also do the same thing with bitcoin as collateral. Ability to be used as collateral doesn’t mean anything reply popcalc 20 hours agorootparentExtremely small market. The reason is there is a real risk that past margin call for the lender there will be no one to offload the crypto onto, even at fire-sale prices. With AAPL and condo developments in LA/NYC there is very low cost of insuring an annihilation of value for obvious reasons -- because it's unthinkable. Not so much for magic internet beans. reply vlovich123 11 hours agorootparentBitcoin’s market cap is $1.2T and the 2008 banking crisis wiped out a huge amount of value of condo value by in LA/NYC. While condo’s may be less volatile, I don’t think Bitcoin is particularly more volatile than the stock market overall. Indeed one of the criticisms is that it seems highly correlated indicating it’s not really a unique asset class from a stock. reply popcalc 6 hours agorootparentIt's not volatility, rather underlying real value. You can't live in a bitcoin. reply vlovich123 4 hours agorootparentYou can’t live in a stock either. What’s your point? Value is what we assign to something collectively. It’s not a measure of some intrinsic reality. reply popcalc 1 hour agorootparentAAPL and MSFT create value for their customers. >Value is what we assign to something collectively. It’s not a measure of some intrinsic reality. I beg to differ. reply lottin 21 hours agorootparentprevWhether a stock pays dividends or not has no relevance to the stock returns. reply popcalc 20 hours agorootparentprev>limit how much money you can take with you outside Bearer shares were once a choice tool for cross-border money laundering. Once commonplace, now outlawed or neutered virtually everywhere on earth. What you are describing is money laundering. It is a crime. We are not debating whether it should be considered so, or that all engaging in it are the bad guys (some are ordinary wealthy/middle class fleeing warzones/regime-change/political persecution), but it is ridiculous to use this as a line of defense for the existence of something. reply mschuster91 20 hours agorootparentprev> You'll end up in a slippery slope there, though. Lots of stocks don't pay dividends, and you can't eat them either. If you get enough shares you can force a dissolution of the company and get paid the proceedings. Of course that only works for stocks that are not overvalued, but stocks in that territory are for gamblers only anyway. reply kortilla 20 hours agorootparentThe stock of every healthy company is overvalued by that measure. The dissolution of the company resulting in the share value means there were 0 expected earnings. reply wmf 21 hours agoparentprevLegally it's only a \"pump and dump\" if the people doing the pumping and the people doing the dumping are the same or working together. Otherwise it's just speculation. reply seanw444 21 hours agoparentprevThat's the way most people use it now, yes. I'm also in the minority, in that I use Monero to pay for goods/services that accept Monero. That's it. Believe it or not, some of us use Monero as a matter of principle, not to do anything nefarious. reply popcalc 20 hours agorootparentThe only reason anyone accepts it from you as payment is because they believe one of a million speculating gamblers (who prefer to be called day-traders) will in turn take it off their hands for liquid cash. Also we cannot deny the impact Tether has on propping up all cryptocurrencies by way of printing USD value out of thin air. Imagine using BBBY shares as a store of value and you have pretty much the same situation. reply seanw444 19 hours agorootparentWe haven't hit a tipping point where cryptocurrencies are actually needed for their intended purpose en masse. We live in peace and comfort, and not enough people in the first world are concerned about their digital transactions being used against them. When that changes, we will likely see shift from using bad CCs like Bitcoin for dumb pump and dumps, towards actually-useful CCs like Monero for daily transactions. However, if things change too drastically (the power grid goes down), then CCs are completely useless anyways and we'll be back to bartering. So I'll keep a good stock of Monero, and an even larger stock of things people value in a crisis. Guns, ammo, tools, food, water, medicine. reply popcalc 19 hours agorootparent>bartering A total myth. Only occurs in places where a peg is established to currency outside the environment, e.g. prisons. The very few anthropological examples of bartering occur between travelers who do not meet each other again for mutual fear of jealousy. Debt: The First 5,000 Years is required reading: https://annas-archive.org/md5/af5cf10f842d46b32a893be4ff52ba... What happens after apocalypse is people return to providing goods and services on credit. Once every month a communal reckoning brings the community together and debts are cancelled out in a circle. If you have lived in a small eastern-European village filled with hen-farming babushkas, beekeepers and craftsmen as I have in Hungary you will recognize this to an extent even today. The commoner's social life and trade is inexorably linked. Even the wholesale traders who did make use of cash only settled using it once every few weeks or so, reminiscent of the hawala, fei chien (Chinese flying money), and other ancient mirror transfer systems. While debt was nominally denominated in it among peasants, only standing armies (Rome & USA), mercenaries, criminals, and nomadic peoples/traveling merchants ever held on to cash for longer than a moment. Acceptance of money to settle debts is the legitimacy of a state's monopoly on violence expressed in units. Why would I give you a sandwich for your monero in our fallout scenario? Monero is only worth anything today because someone will buy it from you for dollars. Why are dollars worth something? Because the U.S. Gov requires you to accept it for debts and they control the printing of it. If the government loses the ability to enforce that everything reliant on it falls with it. They are able to enforce it by way of the most powerful, violent standing army the world has seen. reply seanw444 15 hours agorootparentPerhaps I misspoke. In a \"fallout scenario\", I'm not using Monero. The Monero is for when society is still intact, but no longer trusts the state-sanctioned currency. I don't really know what to say to the bartering point. People want valuable and scarce things they don't have in exchange for valuable and scarce things they do have. How that's a myth to you is beyond me. reply EasyMark 14 hours agoparentprevThis argument is as old as cryptocurrency. Is collecting baseball cards as an investment pump and dump? Lots of people buy cards they expect might go up and then sell the later. Same with real estate. So no it’s not pump and dump, lots of people have made a legitimate fortune on it. Others well they pwned themselves. It’s kind of like realizing the stock market isn’t much more than a casino unless you buy vanguard 500 for the long haul, well crypto is similar. reply mattmaroon 7 hours agorootparentBaseball cards are a great analogy. Yes, they have been pump and dumped. They also started off seeming valueless, became very valuable, and once people realized they could have made a lot of money from them, the market was flooded and people stopped throwing them out and its now been many decades since you could realistically profit from anything new. That’s about what I expect bitcoin will look like in the future. (Kind of already does.) If you bought them in the early days you made a fortune, now they’re mature and they’ll never rapidly appreciate again. Real estate has intrinsic value. Companies have inventive value (usually). Both of them can be used you give you a return even if you don’t sell. reply nyolfen 21 hours agoparentprevit gives ordinary people the ability to discipline their central bank and preserve their own personal holdings. there are other uses but this is the one i care about. > I’d bet less than 0.1% of good and services are actually bought with it. (Optimistic estimates are 0.2%). this also applies to nearly every 'normal' currency reply mattmaroon 6 hours agorootparentI mean, no. You could already just buy any other currency for that and you’d still be better off. Crypto, being a ponzi scheme, has price fluctuations that make it undesirable as a store of wealth. If somebody put all of their liquid assets in any major fiat currency and lost half of it in a couple months you’d be surprised. If that happened with a crypto currency you wouldn’t. Which goes back to my statement that any benefits beyond gambling are only theoretical and haven’t actually materialized in 15 years of being told it’s coming any day now. reply lottin 20 hours agorootparentprevSorry, but you're delusional. Central banks are held accountable through a system of checks and balances and the rule of law. reply nyolfen 20 hours agorootparenti'm sure that is deep solace when you lose half of your savings to inflation. btw not sure which central banks you're thinking of, but this checks and balances stuff does not apply to the fed at least; it is explicitly defined as independent (ie unaccountable). reply lottin 14 hours agorootparentIndependent doesn't mean unaccountable. The Fed is accountable to the Congress. reply mrighele 20 hours agorootparentprevPlenty of countries have neither checks and balances nor rule of law. reply lottin 14 hours agorootparentOf course. And that is a problem that a cryptocurrency won't solve. reply samatman 20 hours agoparentprevI doubt this comment will change your mind. But it should. https://news.ycombinator.com/item?id=33644090 reply mattmaroon 3 hours agorootparentWell, I do know remittances and other forms of cross-border payments are a use case and that’s lovely, but that’s not why Bitcoin is at $60,000. It’s at $60,000 because Americans gamble on it. reply gwbas1c 21 hours agoparentprevYou're not in the minority. It's just that, until recently, the groupthink would downvote / flag comments like yours. reply TacticalCoder 19 hours agoparentprev> I realize I’ll be in the minority here saying this but: Isn’t all crypto a pump and dump scheme? Bitcoin was created as a gigantic middle finger to the various governments, worldwide, ever printing more money out of thin air. This has been made very clear in the message encoded by Satoshi in Bitcoin's genesis block: \"Chancellor on the brink of second bailout for banks\" From there everybody was free to side with cypherpunk anarchists and to mine Bitcoins or to buy Bitcoins. Now I'm not disputing there have been lots of pump and dump. I'll list two examples... Without squinting too much the following for example is one kind of fraud: although SBF and FTX had already been exposed (by a famous short-seller) for the complete and utter scammy fraud they were, \"journalists\" at the NYT kept writing articles about SBF as if he was the second coming of Christ. Not surprisingly SBF had parents very well connected in NY and raising tens of millions for the dems. This, too me, is not far from a criminal organization (SBF/FTX/his parents and their accomplices at the NYT) actively defrauding people. One may dispute what's \"pump and dump\" (FTX was known to pump and dump a lot) but the NYT's articles certainly lured many into FTX, which pumped a great many shitcoins, and then, poof, all the money disappeared. Following that even, the very Chamath Palihapitiya said that VC from SV had to look very deep into the way they were functioning because they actively took part in a great many pump and dump of shitcoins (he criticized for example lessons being given as to how to create coins). It's nearly as if the biggest of the biggest of the pump and dumps were organized by well-known and well-respected entities and not by the cypherpunks who originally created Bitcoin no!? As for an actual usecase, I'll leave this here: - Turkey inflation rate in 2022: 72% - Venezuela inflation rate in 2022: 234% (\"slowing\" down from previous year) - US government public debt: soon to reach 36 *trillion* I think people who buy Bitcoin see it as the digital equivalent of physical gold. Now physical gold is something lots of HNer used to make lots of fun of in the past. They're probably not laughing that much now that central banks are stockpiling physical gold and that gold reached new all-time highs. So I'd suggest this: first wonder if you were one of these making fun of physical gold, thinking it was stupid. Then wonder if you were maybe wrong or not. Then wonder if \"digital gold\" is really that crazy of an idea? reply FactKnower69 20 hours agoprev>Liu Zhou, a “market maker” working with MyTrade MM, allegedly told promoters of NexFundAI that MyTrade MM was better than its competitors because they “control the pump and dump” allowing them to “do inside trading easily.” hilarious, but running an operation of this scale to only charge 18 people? this is like squishing a few individual ants, then going on a victory lap bragging to national media about what a canny and clever exterminator you are. great job cleaning up 0.0001% of the market 10 years late! reply TrapLord_Rhodo 21 hours agoprevThis is such a gray line after reading this and the Levine article. Here, they are blatantly fraudulent. They trade between themselves, using fake generated wallets. But what about Jump Capital? They have a crypto division that also does market making. The difference here is there are given a large chunk of tokens to market make with, as they please. Doing arbitrage through MEV (Which is just a collusion agreement between the mevbot and the miners), Buying at low points and dumping at high points. At what point does convulusion and complexity create enough of a \"Market Maker\" vs. Trading with yourself. trading off the same signals is collusion on \"Signal sharing\". Creating MEV bots that take advantage of arb opportunities in the pool is insider trading. Having significant equity in the company, but no financial interest or obligation to disclose dumps? reply davidmr 21 hours agoparent> But what about Jump Capital? They have a crypto division that also does market making. The difference here is there are given a large chunk of tokens to market make with, as they please. It may be a little early to make that comparison. Jump is still being investigated for its crypto shenanigans. reply shortrounddev2 22 hours agoprevnext [16 more] [flagged] whtsthmttrmn 22 hours agoparentSounds like something a crypto-fraudster would say... reply piva00 22 hours agoparentprevWho do you propose should investigate? reply passwordreset 21 hours agorootparentI'd suggest no one should investigate. So you lost your Bitcoin from some massive fraud? Too bad. That's the cost of playing that game. You should not get a free pass when you ask your government for assistance, and you should not have your government investing time and money looking into massive fraud concerning Internet Fun Bucks. You assume all risk when using this kind of money. reply tonetegeatinst 21 hours agorootparentIs its internet fun bucks why are they taxing it? Imagine next, taxing people who do protein folding of use the SETI project....because those points earned have a value to them. reply ben_w 21 hours agorootparentCan you trade SETI points? If not, then no. But you could tax someone for getting free gifts \"in kind\", so if you donated GPU time to do protein folding for GlaxoSmithKlein and they rewarded you with some internet points, they might be taxable on the difference. reply AnthonyMouse 20 hours agorootparent> Can you trade SETI points? Now you're getting into this mess: https://www.journalofaccountancy.com/news/2020/feb/video-gam... Video games have all kinds of gold etc. that you can use to buy items. People will pay you real money to get your video game points if the video game is popular. So now is everybody who plays a popular video game committing tax fraud unless they report their gameplay to the IRS, because they earn points which have monetary value? That's not going to go over well. They seem to want to go with something like it's not taxable unless you cash out. But that's a whole different kind of mess. If you trade somebody your Roblox points for their Fortnite points, is that cashing out, or are you both just trading your non-taxable thing for a different non-taxable thing? Is there any reason for this to be different than trading your sword for a crossbow within a single game? What about games that share worlds? What about games that have cryptocurrency in them? The whole thing is a mess because \"anything of value\" is too broad to be practical, but narrow it an inch and you have a loophole. reply shortrounddev2 5 hours agorootparentprevI believe that the government should tax transactions involving money. If you cash out your bitcoin, then that's income, and should be taxed. I don't think unrealized gains of bitcoin should be taxed because bitcoin isn't money reply shortrounddev2 5 hours agorootparentprevI believe crypto should be unregulated reply uoaei 22 hours agorootparentprevProbably the Secret Service. They investigate wire fraud among other things. reply infecto 22 hours agorootparentI always got the impression that the FBI was more aligned with securities fraud which I think is probably the closest aligned here. reply dragontamer 22 hours agorootparentIf it's a currency, then the Secret Service should investigate. If it's a security, then FBI should investigate. -------- These crypto coins feel more like a security to me, so my bet is FBI. In either case, fraud is rampant and there needs to be more crackdowns. So I don't care who investigates really. There just need to be more of them. reply Jerrrrrrry 21 hours agorootparentthe point of the ecosystem is blurring lines to the point of exhaustion, exploiting the juxtaposition between the latency of the bureaucracy and its jurisdictional dick-swinging and the relatively near-instant pay out of \"legally-gray\" fraud. reply datavirtue 22 hours agorootparentprevIt's all number of rampant fraud. reply playingalong 22 hours agorootparentprevWhy is the same agency tasked with investigating financial fraud and provide physical security for the president? reply filoleg 21 hours agorootparentProbably because their official stated purpose has been “conducting investigations into currency and financial-payment crime, and protecting U.S. political leaders, their families, and visiting heads of state or government.”[0] Especially since US secret service was originally created with the former purpose, as protection of political leaders was added to their list of responsibilities only later on. 0. https://en.wikipedia.org/wiki/United_States_Secret_Service reply nunobrito 22 hours agoprevnext [10 more] [flagged] LiquidSky 22 hours agoparentHeh, yeah, I was thinking \"so did the NSA\". reply TrapLord_Rhodo 21 hours agorootparentIs this a thing?... I never thought about it before... but after reading the \"The Shadow Factory\" I totally understand they could do that... It's halvings are correlated to right before a presidential elections which seems suspicious. But why? Is it a giant honeypot that got out of hand? reply cut3 21 hours agorootparentDigital transactions being easier to track than physical ones is my guess. Everything I buy with crypto is attached to my wallet. No one knows what I bought with cash or traded items for. reply nunobrito 8 hours agorootparentIt was quite convenient in those days to convince drug dealers to adopt bitcoin exactly because of that. Eventually all the smart ones moved to monero where privacy between transactions is beyond doubt. Trivia: 1) Guess which crypto is now being delisted from all major exchanges? 2) Now guess which crypto the US gov is actively purchasing/supporting? reply j-bos 21 hours agorootparentprevFor fun try googling the Japanese translations of \"nakamoto\" and \"satoshi\". reply TrapLord_Rhodo 18 hours agorootparentnow try \"\"moto\" and \"satoshi\" reply wizzwizz4 20 hours agorootparentprevThey look like names to me. What are you referring to? reply j-bos 17 hours agorootparentHuh, I guess google really isn't what it used to be. Nakamoto can be translated s central: https://www.bing.com/search?q=nakamoto+etymology&pq=nakamoto... and Satoshi can be translated as intellingence: https://www.bing.com/search?q=satoshi+etymology&pq=satoshi+e... reply wizzwizz4 9 hours agorootparentWhere are you getting \"s central\"? reply staplung 20 hours agoprevPlease tell me they called it HooverCoin. Such entrapment. Very problem. Wow. reply declan_roberts 21 hours agoprevlol how do I get a job at the FBI doing this kind of stuff. I love it! reply xmprt 21 hours agoparentStart off by getting a job not at the FBI doing this kind of stuff. reply HPsquared 21 hours agoprev [–] I do kind of like the idea of joining AI and cryptocurrencies though. AI workloads could be an actually useful piece of \"work\" that there can be \"proof\" of. EDIT: maybe I had assumed too much about the technical feasibility... reply ben_w 21 hours agoparentTo the extent that you could have an P!=NP type thing going on where an AI does a lot of work to reach an easy-to-verify solution, you're likely to have some combination of: 1. The answers have a value uncorrelated with the price: either the problems are stupid (just like BTC's are) or they're so much more valuable than the mere mining reward that you'd do it anyway, with very little \"correctly priced\". 2. If the problems are completely arbitrary you get all the stupid spin-off coins just like we saw with cryptocurrency; and if they're not completely arbitrary then you vary between having lots of new problems and hardly any in exactly the same way that gold mines were suddenly found and then got mined out back when the gold standard was a thing, and IIRC that's one of the reasons against the gold standard. reply AnthonyMouse 19 hours agorootparent> The answers have a value uncorrelated with the price: either the problems are stupid (just like BTC's are) or they're so much more valuable than the mere mining reward that you'd do it anyway, with very little \"correctly priced\". Why can't you solve the high value problems by having the person who wants their problem solved bid to have the miners solve their problem instead of someone else's? Then the mining reward includes the bid and stays high as long as people are willing to pay to have their problems solved. Transaction fees are near-zero because the miners are paid by the bidders, and the amount of hardware you need to do a 51% attack goes way up because mining is more profitable this way so there is more competition. reply WJW 21 hours agoparentprev [–] The main problem is that an AI training workload eventually ends, or (if inference is also included) at most generates more work proportional to the rate of user queries. If you have 10 times as many workers, you are done in 1/10th of the time. Crypto on the other hand generates as more and more work as more miners join the network, so that the overall time taken remains constant. This is an essential part of the system, to prevent improvements in technology devaluing all previously mined crypto. The two have a fundamental incompatibility. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The FBI developed an Ethereum-based cryptocurrency, NexFundAI, to investigate and expose crypto pump-and-dump schemes, leading to significant legal actions.- Charges were filed against 18 individuals and entities for fraud and market manipulation, with the Securities and Exchange Commission targeting three market makers and nine others for inflating crypto asset prices.- The Department of Justice successfully recovered $25 million in fraudulent proceeds, which will be returned to investors, highlighting the operation's effectiveness in combating crypto fraud."
    ],
    "commentSummary": [
      "The FBI developed a cryptocurrency to probe pump-and-dump schemes, which are fraudulent practices that artificially inflate the price of an asset before selling it off.",
      "This initiative has ignited debates on entrapment and the ethical implications of law enforcement creating counterfeit securities.",
      "The discussion extends to broader concerns about the legitimacy of cryptocurrencies and the government's role in regulating digital currencies."
    ],
    "points": 109,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1728589967
  },
  {
    "id": 41808943,
    "title": "NotesHub: cross-platform, Markdown-based note-taking app",
    "originLink": "https://about.noteshub.app",
    "originBody": "Thank you for your comments, just some context:- The app is available for iOS, Android, Windows, Mac, Apple Vision Pro, and the Web.- The Web version is implemented as a Progressive Web Application that is very responsive, local first, offline first, can be installed, and is entirely free to use.- Native (hybrid) versions do not require subscription fees and have small one-time payment.- You can store your notes in Git using any Git provider such as GitHub, GitLab, or Bitbucket. However, it has the best built-in integration with GitHub. Self-hosted scenarios like Gitea are also supported. In addition to Git, you can store your notes in a file system and iCloud Drive on Apple Devices.- It has a rich Markdown syntax support with added extensions like Mermaid, ABC music notation, callouts, etc.In addition to regular Markdown notes, you can create Kanban boards for easy task management (under the hood, it is still stored in Markdown). If that is not enough, you can create whiteboards based on Excalidraw and embed them back into your notes.",
    "commentLink": "https://news.ycombinator.com/item?id=41808943",
    "commentBody": "NotesHub: cross-platform, Markdown-based note-taking app (noteshub.app)107 points by alex-titarenko 6 hours agohidepastfavorite90 comments Thank you for your comments, just some context: - The app is available for iOS, Android, Windows, Mac, Apple Vision Pro, and the Web. - The Web version is implemented as a Progressive Web Application that is very responsive, local first, offline first, can be installed, and is entirely free to use. - Native (hybrid) versions do not require subscription fees and have small one-time payment. - You can store your notes in Git using any Git provider such as GitHub, GitLab, or Bitbucket. However, it has the best built-in integration with GitHub. Self-hosted scenarios like Gitea are also supported. In addition to Git, you can store your notes in a file system and iCloud Drive on Apple Devices. - It has a rich Markdown syntax support with added extensions like Mermaid, ABC music notation, callouts, etc. In addition to regular Markdown notes, you can create Kanban boards for easy task management (under the hood, it is still stored in Markdown). If that is not enough, you can create whiteboards based on Excalidraw and embed them back into your notes. proee 4 hours agoNice product and website. Your homepage uses a lot of passive voice. Personally I think changing it to active voice makes the product sound more appealing. \"your notes will always be\" -> \"your notes are always\" \"content will be synced\" -> \"content is synced\" \"note will be periodically synced\" -> \"notes are periodically synced\" \"You can use it for managing personal tasks...\" -> \"Manage your personal tasks...\" \"You can choose between light and dark\" -> \"Choose between light and dark\" reply teraflop 3 hours agoparentNitpick: that's not what \"active voice\" means. The active voice equivalent of \"content will be synced\" would be \"NotesHub will sync your content\". reply cscheid 3 hours agoparentprevDropping passive voice helps most writing, but > \"content will be synced\" -> \"content is synced\" FYI that's still passive voice. reply j_bum 3 hours agorootparentTo quickly determine passive vs. active voice, you can add the phrase, “by zombies” to the end of the sentence. If it’s clear the zombies are doing the action (subject), then the content is passive voice. Otherwise, if the zombies are an adverbial phrase, the sentence is in active voice. Passive voice: “Content is synced by zombies” Active voice: “NotesHub syncs the content by zombies” reply rangerelf 3 hours agorootparent\"Thanks\" for making me spit my coffee, that's hilarious but awesome; I will be using it in the future. :-D reply j_bum 2 hours agorootparentGlad you liked it :) When I started grad school and was learning how to write effectively, I struggled with passive/active voice differentiation… until I learned the zombies tip. It’s so absurd that you can’t forget it, and it’s simple enough to differentiate the two in a split second! reply miles 38 minutes agoprevThank you for crafting and sharing this. Have been looking for a modern MacDown[0] replacement, and this fit the bill nicely. Especially appreciate the reasonable, one-time cost and support for local storage. The \"Key Features\" section mentions \"Export notes to PDF\"; please consider adding an \"Export notes to HTML\" option. Custom theme support for the preview pane via CSS would be helpful too. [0] https://macdown.uranusjr.com reply jdthedisciple 2 hours agoprevIt seems the creator has been a senior SWE at Microsoft for 7 years now. It genuinely astounds me that as a solo dev he can make such a featureful app yet Microsoft the company has been failing hard in this realm for the last decade. Also it makes you wonder how many UI-design teams, product owners, and middle managers are entirely obsolete next to a single competent SWE with a bit of talent for UI/UX. reply dewey 2 hours agoparentIt's not that surprising, it's just different priorities. If a company would prioritize \"Let's build a featureful note-taking app\", they'll also get it done. But there's usually a lot of different priorities that are higher than building yet another app for the platform. reply alternatex 2 hours agoparentprevAlthough I agree with your observation wholeheartedly, it should be obvious that shipping something at Microsoft is way more involved than shipping a hobby project. Just security and privacy compliance is half the work. That Microsoft is just not good at building consumer-facing software in general is hard to deny though. reply tinkrr 2 hours agoparentprevOneNote is a pretty decent note taking app. reply reacharavindh 4 hours agoprevOh I like the web version! I just hooked up the web app to my _public_ blog repo, and started editing the markdown files. Hit save and it automatically performs a git commit on my behalf. Perfect. Next time I'm working on the files locally, all I need is a git pull and I am good to go. I like it. Although I didnt quite like that it asked for a permission to pretty much _everything_ in Githuhb - public and private repos, deploykeys?!, everything. I wish that were customisable. It was okay for me because I dont keep any non public code in Github, but others might have.. reply kseistrup 4 hours agoparentThe FAQ has the following instructions for more fine-grained access control: > To accomplish this scenario select generic Git notebook provider (instead of GitHub) and for the password field put fine-grained personal access token which can be generated to have access only to certain repositories. reply amimetic 2 hours agorootparentI tried this and doesn't seem to work; though unclear what permissions I should be granting it, so possibly that is the issue. reply aanet 3 hours agoprevFantastic app, good, clean design, and a very useful use-case. I can see myself using it. However, a few questions: 1. Can I self-host it? If so, how? 2. Can I connect to a \"private\" Github repo? (I dont want my personal notes publicly viewable, unless I choose so) 3. What's the pricing model? Wasn't entirely clear. Thanks!! reply alex-titarenko 3 hours agoparentYou can't self-host it. Yes, you can connect to \"private\" GitHub repo. Pricing model is one time payment for native apps and free web app. reply ukuina 2 hours agorootparentCan you provide more detail on connecting to a \"private\" GitHub repo? The FAQ says \"To accomplish this scenario select generic Git notebook provider (instead of GitHub) and for the password field put fine-grained personal access token which can be generated to have access only to certain repositories.\" I created a PAT with EVERY permission within a selected repo, to the fullest-extent allowed by the fine-grained PAT, but still see \"An unhandled error occured, please try again\" when setting it up within NotesHub. reply amimetic 2 hours agorootparentI didn't go that far (every permission) but had the same experience. reply HiPHInch 4 hours agoprevPeople seem interested in this. But I still wonder what is the advantage over Obsidian. reply superbforme 56 minutes agoparentThe app being the in store for mac and ios, I stopped using obsidian when they removed the app from the mac store and only allowed it for ios. I need the sandbox, for bussiness is a no brainer, allow some apps from the store, give the right permissions, done and for me personally, I don't use anything that doesn't come from the store, even if I can download the app freely from the project page, a few bucks for the sandbox and peace of mind is worth it to me. I donated to Obsidian because I liked the project in general, I dislike the way they distribute the app in all platforms outside of ios, ex, snap with --classic rendering the attempt to sandbox it useless. Edit --- Reading some comments, it's pretty obvious that a lot of people even install third party plugins, on an app that is about taking personal notes, it's refreshing to see how much people care about cybersecurity and their personal, business notes. reply marcuskaz 3 hours agoparentprevNotesHub is one-time payment of $4 and Obsidian is $50/yr reply dtkav 45 minutes agorootparentObsidian is free for individual use. The $50/yr is a commercial license. They also have a $4/month sync product (sync across devices with e2e encryption), but you can use icloud, google drive, etc too. reply hanifc 1 hour agorootparentprevWhat does the $50 get you with Obsidian? I don’t pay, and I’m able to access my notes from my desktop and mobile apps. reply dtkav 44 minutes agorootparentThey must be talking about the commercial license. [0] https://obsidian.md/pricing reply accra4rx 3 hours agoparentprevIn Obsidian , you can even sync to github or dropbox with community plugins . so price wise it is free Also Obsidian has much better search (using community plugin) which is lacking in noteshub reply dtkav 2 hours agorootparentThe plugin ecosystem is amazing. I wrote a plugin called Relay that makes obsidian multiplayer with live collaboration (using CRDTs), and there are a few others in the space too. Obsidian sync is also great for e2e encrypted sync for your own devices if you don't want to rely on third parties like GitHub. reply alex-titarenko 2 hours agorootparentprevObsidian's git sync has many issues, at least, this is what I hear from my customers who used both products. Search in NotesHub is also robust, please read here: https://about.noteshub.app/blog/archive/2024/7/noteshub-34 reply wodenokoto 3 hours agoparentprevWithout having tried both side by side, pricing is an advantage. reply WillAdams 3 hours agoparentprevPay once pricing? A really interesting feature would be the ability to post to your own host --- the publishing aspect is the one thing which has me seriously contemplating Obsidian, but I'm so deep into gitbook and github I haven't been able to justify a cost-benefit calculation. reply ttul 4 hours agoprevI have grown to love markdown in the past year. It is just expressive enough without being burdensomely complex. I appreciate the ability to switch between WYSIWYG and plain text editing modes to achieve precision. In contrast to pure-WYSIWYG editors like Google Docs, the formatting can’t get totally hosed in markdown because you can always dip under the hood and fix stuff. I just wish every rich text editor had accessible markdown… reply WillAdams 3 hours agoparentMicrosoft Word having a Markdown mode would be _huge_. If I were still using it regularly I'd put one together using WordBASIC/VBAscript. reply emmanueloga_ 4 hours agoprevCan you share a bit about the tech behind this? Are the desktop apps electron apps or something else? Thx! reply alex-titarenko 2 hours agoparentWindows version is Electon-based, but not really hungry for resources. MacOS is not Electron-based. reply awill 4 hours agoparentprevthat's always my first thought. Do I need 64GB of RAM to run this note app? :) reply cloverich 2 hours agorootparentTry checking the memory usage of Apple notes, if you use it. I was shocked how high it was. reply dbcurtis 1 hour agoprevI will definitely check this out. I love that syncing can be self-hosted, that it supports LaTeX for math, and even music notation. The one additional thing I would love in a text-based note-taking app is some kind of mind-mapping software. I still have an old copy of Mindnode on my Mac, and there are times where it is the perfect solution. I am a little disappointed that the Linux story is weak. reply alex-titarenko 1 hour agoparentNotesHub has support of Mermaid diagrams that has mind-mapping. Or you can use Whiteboarding functionality to mimic mind-maps. reply ponytech 2 hours agoprevI have been an Evernote, then Notion and now a Jopplin user. A feature I used a lot in these apps is the browser extension that allows me to quickly bookmark a web page into a note. Would you consider such a feature? reply eagleinparadise 1 hour agoprevIt looks like the keyboard shortcut Cmd-L conflicts with Arc browser in the web app. Looks great otherwise! Are there plans for plugins and so forth ala obsidian? For instance, it would be great to have a daily/monthly/quarterly/yearly note and what not. reply TripleChecker 2 hours agoprevUseful product. Are you planning to add integration with self-hosted Gitlab? There are a few typos on the site you might want to review: https://triplechecker.com/s/259685/about.noteshub.app?v=rLAc... reply novoreorx 2 hours agoprevThis is a really nice product. The web version reminds me of Prose [^1], which introduced the concept of writing in a GitHub repo online since 2013. For those asking about the advantages of NotesHub over Obsidian, this app offers a web version—a feature I have long wished Obsidian would provide. [1]: https://github.com/prose/prose reply Towaway69 3 hours agoprevI'm a big fan of iA Writer - it basically does everything I need. The best part is its clean interface - just a white screen and cursor. Markdown based with HTML templates to allow for different appearance when converted to PDF. It also has cross references to other files, so that long documents can be broken down into separate files. It doesn't have all the features that NotesHub has - hats off to that and I hope NotesHub becomes a success. reply jdthedisciple 3 hours agoprevLooks great, just wish it had end-to-end-encryption. I made a quite similar app with some other features that are a personal must-have which this one lacks. reply aiono 3 hours agoprevLooks nice, but what advantage it has over Obsidian or Zettlr? Maybe Obsidian is more expensive but Zettlr is free and also FOSS. reply xz18r 4 hours agoprevI am on a Macbook where I'm not signed in with an Apple ID (let alone my own), can I buy the app for my private devices and install it somehow on my work Macbook? reply danudey 3 hours agoparentIf you copy the app over to your work Macbook it should ask you to authenticate to the App Store when you try to launch it so that it can validate your license. IIRC this doesn't cause it to save that login to the app store but just does a one-off authentication for that app. YMMV, but this is my recollection. reply tinkrr 2 hours agoprevIt seems like you re-use the code from the web app to create the hybrid mobile apps. Which tool / framework do you use to achieve this? reply ukuina 3 hours agoprevHey, awesome, clean Material design! Are notes held on disk unencrypted? reply bbor 4 hours agoprevA) Wow this is just incredibly impressive for a solo dev - well done! The feature list just keeps going and going, by the time I got to kanban boards I was in disbelief. I was incredibly dubious based on the title that any “Show HN” could rival Obsidian, but i think I stand corrected! I sadly use my own hand-rolled markdown system way too often to really switch, but I’ll definitely have to check this out for an on-the-go replacement for Google Keep. B) “offline first” is a great feature, but I’m curious why you didn’t go with the terms hear more often, “local first”? Just wanted something more accessible to laypeople? C) “offline first” seems hard to match up with “progressive web app” — not from any sort of user perspective (sounds ideal, even!), just in terms of technical implementation. Am I correct in assuming that the iOS and android versions are PWAs, and that they still durably store files on device? If so, how hard was that? D) “all major platforms: iOS/macOS/Android/Windows” made me shed a brief tear. It’s ~~infrastructure~~ Linux Week, time to add a platform!! Best of luck and thanks for sharing your work. I look forward to meeting you on top of the world one day ;) reply dbacar 4 hours agoprevwhat is the license? Always free? One day might cost you? reply alex-titarenko 2 hours agoparentThe web version is free, native versions have small one-time fee. reply lormayna 3 hours agoprevDo you have a self-hosting version? reply vuldin 4 hours agoprevThis looks good, but in order for me to try this it would need vi support and a Linux install option. reply ttul 4 hours agoparentI think you might be in the top 0.03% of people who use note taking apps! reply alwayslikethis 4 hours agoparentprevA closed source note-taking app is also a questionable decision regardless. The app looks impressive in terms of features, which is actually a con because you may not be able to find an alternative when the time comes and you can no longer use it for any reason. reply w0m 29 minutes agorootparenttbf; all data stored in markdown theoretically solves that. I currently use Foam on VSCode for notetakng / personal project management. But 2/3rds of my actual typing tends to be inside NeoVim following the foam format (vscode vs vim on the day is determined more by what i'm working on that day vs anything else). I'm constantly on the lookout for a better* system; but haven't found one yet as sometimes I want a UI; but Grep and quick jots inside the terminal is just very useful. reply w0m 4 hours agoparentprevha, NGL my thought exactly. Maybe ship also as a VSCode extension? reply joshdavham 4 hours agoprevIs the source code available anywhere, by chance? I’m curious how it was built. reply alex-titarenko 2 hours agoparentIt's not open sourced. You can look at Settings -> Third-party Licenses to see what libraries are in use. reply awill 4 hours agoprevWhat does native (hybrid) mean? reply invaliduser 4 hours agoparentThat's when the native Android or iOS app is basically a webview displaying the web app (either served locally or from the website) reply awill 4 hours agorootparentThat's not really native in my book. reply invaliduser 3 hours agorootparentThat's why it's called hybrid I guess reply rcarmo 5 hours agoprevI don't get why iOS doesn't have filesystem notebooks on the comparison table. reply jedberg 4 hours agoparentIt has iCloud Drive instead, which is the closest equivalent to a filesystem on iOS reply rcarmo 3 hours agorootparentSo you can't use other file providers? That tech is really stable now, I've been using it for years to edit a git repo inside Working Copy or files inside other apps using yet another set of apps (Textastic, iA Writer, even vim inside a-Shell). You should really consider reviewing that viewpoint. reply alwayslikethis 4 hours agoparentprevThe fact that iOS doesn't really have a real filesystem you can use, would be my guess. reply Towaway69 3 hours agorootparentAs someone who left iOS for Android because of that, I was pleasantly surprised - when I went back - to find that iOS now has a Files app for managing files on the device and also network shares. iOS has definitely improved in that area and definitely now has a filesystem. reply rcarmo 3 hours agorootparentprevAs someone who regularly uses vim inside iOS to edit files from another application and syncs the whole lot via SyncThing, I beg to differ. From a filesystem perspective, it's no different from jails or container mount points. reply jedberg 3 hours agoprevAnyone got a good tutorial on switching from Evernote? reply maelito 3 hours agoprevThanks ! Wonderful alternative to gitjournal. reply stonogo 2 hours agoprevThe website leans hard on \"fully cross-platform\" for a program that clearly isn't. reply alex-titarenko 2 hours agoparentIf you are talking about Linux, you can use the Web version, which is Progressive Web Application, works offline and can be installed. reply dukeofdoom 3 hours agoprevI keep my todos in markdown checklist boxes. I generate a dayplan with chatgpt and I ask for output in markdown. Just copy and paste it. I now use typora.. but I'll check out your app later. reply mdhb 3 hours agoprevJust out of curiosity is this a Flutter app and if so how did you find the experience of using it to develop a cross platform app? reply alex-titarenko 2 hours agoparentIt's not a Flutter app. It's a React-based app. reply ndimares 3 hours agoprevAnotha one reply deafpolygon 4 hours agoprev [–] This might be an unpopular take, but I'm tired of all these Markdown text editors. It almost feels like a cop-out at this point. Ever since text editors started supporting Markdown, we've gotten away from all of these great rich-text editors. Apple Notes is an example of a notetaking application \"done right\", albeit with fewer features. It's enjoyable to use and offers good UI for attaching files. It certainly is not without its flaws, however. Obsidian gets really close. I bet the devs could go all the way. I want something WYSIWYG-like, without dealing with the underlying mechanisms... give me rich-text on the front and save the file in Markdown behind the scenes. I hardly care, as long as there is a robust export option built-in.reply emaro 4 hours agoparentI can understand that. There're so many Markdown editors, choice paralysis easily kicks in. Markdown ist basically a must have for me though, because I know most applications will be outlived by my notes, and I want to be able to move on to a different editor. To try a new one, or even use multiple at the same time (say, on my phone and on my computer), it's unacceptable for me if I have to export and import all my notes first and risking diverging branches. In general I think taking notes is a very personal thing many people do every day and they're looking for an app fitting their exact workflow. That's why there are so many options. I was considering writing my own one several times already, although it's probably not worth the time. reply jandrese 4 hours agorootparentThe one thing that annoys me is that Markdown is not highly standardized. Seems like every implementation is its own dialect and feature support varies quite a bit. reply input_sh 2 hours agorootparentYeah that's what happens when you come up with a \"standard\" and then forget about it for two decades. reply deafpolygon 2 hours agorootparentprev> because I know most applications will be outlived by my notes A robust export option is what we're all looking for here. > taking notes is a very personal thing I agree with that. reply threetonesun 4 hours agoparentprevBear with \"hide Markdown\" checked pretty much gets you there, if only on Apple devices. Markdown vs. Rich Text to me is less about the editing experience and more about do you want your files aligned to a file system or not. The options are either: - rich text editor with files that only make sense to a single application. - rich text editor with no files but (hopefully) some way to export them to (hopefully) compatible formats. - text files in a folder than can be read / edited by almost anything, with the editing experience tied to your application of choice. reply chrisweekly 3 hours agoparentprevObsidian's WYSIWYG editor is excellent and amazingly featureful. I use it for hours every day, only ever in \"edit\" mode w/ \"live preview\", just a couple plugins enabled, and it's by far the best interface to markdown I've encountered. reply deafpolygon 2 hours agorootparentI agree, which is why I use it. But there are a few quirks that rely on on reading mode. reply great_kraken 4 hours agoparentprevJoplin supports editing in WYSIWYG with formatting tools and saving markdown on the backend, or swapping to the markdown editor whenever you want to edit that way. reply thecodrr 4 hours agoparentprevYou might want to give Notesnook [0] a try. [0]: https://notesnook.com/ reply askafriend 4 hours agoparentprev [–] Apple Notes is the greatest note taking app of all time. I literally don't need anything else. reply WillAdams 3 hours agorootparentFor folks who buy into the Apple eco-system perhaps --- I'd consider it if it were possible to view/edit notes made in it on my MacBook using a Wacom One screen on my Samsung Galaxy Note 10+ --- bonus would be if they could get Amazon to put it on the Kindle Scribe. reply lawgimenez 1 hour agorootparentprev [–] Apple notes has been lagging and crashing a lot. So annoying since it is my most used app. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The app is available across multiple platforms, including iOS, Android, Windows, Mac, Apple Vision Pro, and the Web, with the Web version being a free Progressive Web App that works offline.- Notes can be stored in Git repositories, with the best integration with GitHub, and also support self-hosted options like Gitea, file systems, or iCloud Drive.- The app supports rich Markdown syntax with extensions for creating Kanban boards, Excalidraw-based whiteboards, and includes features like Mermaid and ABC music notation."
    ],
    "commentSummary": [
      "NotesHub is a versatile, Markdown-based note-taking app available across multiple platforms, including iOS, Android, Windows, Mac, Apple Vision Pro, and the Web.- The app offers a free Progressive Web App version, while native versions require a one-time payment, with strong integration for storing notes in Git repositories like GitHub, GitLab, or Bitbucket.- It features rich Markdown syntax, Kanban boards, and Excalidraw-based whiteboards, with users praising its clean design and offline capabilities, though it is not open-sourced and has limited Linux support."
    ],
    "points": 107,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1728650257
  },
  {
    "id": 41809879,
    "title": "Dead man's switch without reliance on your infra",
    "originLink": "https://github.com/adamdecaf/deadcheck",
    "originBody": "I wrote this Go project to implement a dead man’s switch that didn’t rely on cron jobs, timers, databases, etc on the infra it runs on. Deadcheck integrates to PagerDuty and keeps a long running incident snoozed until expected check-in times where it’ll alert unless a check-in occurs.",
    "commentLink": "https://news.ycombinator.com/item?id=41809879",
    "commentBody": "Dead man's switch without reliance on your infra (github.com/adamdecaf)102 points by adamdecaf 4 hours agohidepastfavorite90 comments I wrote this Go project to implement a dead man’s switch that didn’t rely on cron jobs, timers, databases, etc on the infra it runs on. Deadcheck integrates to PagerDuty and keeps a long running incident snoozed until expected check-in times where it’ll alert unless a check-in occurs. remram 3 hours agoIf you call this a \"dead man's switch\" I'd expect it to turn my app off when I die. E.g. \"switch\" something when something happens to a \"man\". Your own README links to this definition: \"A dead man's switch is a switch that is designed to be activated or deactivated if the human operator becomes incapacitated\". This is a watchdog timer / monitor / heartbeat, setting off an alert if a timer elapses. reply aftbit 2 hours agoparentThe \"original\" dead man switch as I heard about it was a pedal on a train that would apply the brakes if the operator released it. I've often wondered about how to reliably take software actions after my death or dishonor. After all, you can't really rely on me being able to pay my bills. I'm not looking to do something expensive, more like delete my accounts and send some messages. reply xnorswap 2 hours agorootparent> I've often wondered about how to reliably take software actions after my death This is actually fairly simple and well understood: leave instructions in your will. \"Notifyto delete my account\" is a perfectly valid instruction to leave for an executor. You could leave behind a password cache with a master password left in your will, but I suspect much of this still runs on trust. I'd imagine (I haven't tried), that \"X has died, please take action Y\" is a fairly reliable social engineering vector if you have a convincing \"proof\" that X has died. It's worth noting that the executor isn't hard forced to carry out your wishes, the legal recourse for them not doing so comes from other beneficiaries ability to take legal action against the executor. If those other beneficiaries don't care much for enforcement, then you might prefer technical methods such as the submission. reply ryandrake 1 hour agorootparentI keep a \"death README\" with all of my online and offline account credentials and phone unlock codes, PII that might be needed to authenticate w/ various companies' services, copies of wills, trusts, powers of attorney, health care proxies and so on, copies of all vital docs like marriage certificate, birth certificates, home router SSIDs and passwords, information about doctors, health insurance, life insurance, all financial accounts and brokerages, approximate balances, bills and how to pay them, tax returns and how to file them, a list of recurring expenses and how to pay them, property w/ approximate values, and so on. A hardcopy is kept in our house where next of kin can find it if needed without knowing a safe combination, but casual robbers wouldn't stumble across. reply echoangle 1 hour agorootparentprevThe „X has died, please take action Y“ thing also only works if the service reliably knows that the account belongs to X. My executor can’t delete my HN account because he can’t prove it’s actually my account (without getting the password). reply ssl-3 46 minutes agorootparentCan it not be cryptographically proven? Leave a public key in your HN bio. And leave a matching private key and validation instructions in your will. If the keys match along with a death certificate, then: The account owner is validated as being dead. reply echoangle 21 minutes agorootparentIf I prepare for it, sure. At that point, I can just leave my password though. I was responding to the point that you don’t need to leave the password because a death certificate would be enough. reply edm0nd 2 hours agorootparentprevWould be cool to have some kind of \"deadmans infra AI or bot\" that would auto fund your server bills for X amount of additional months/years and then send out emails and post a notice you have died and your service EOL is estimated to be X or Y. I also suppose you would have to also roll in some kind of automated patching and etc into it which would be rather difficult and break a lot of thing if went bad but some kind of \"self healing\" bot could perhaps also look after this part to fix anything should it break. Also kinda opens up an entirely new attack vector. Threat actors could scan for these notices and go \"hey this person is dead. lets hack their stuffs\". reply DowagerDave 2 hours agorootparentprev>> after my death or dishonor honest question: why do you care? reply vincnetas 2 hours agorootparentif you care about people that you leave behind... reply nurettin 2 hours agorootparentprevFrom experience, it is a huge inconvenience to people surviving the deceased leaving without any way to pay their debits. And if you don't care about what happens after you die, why did you even care when alive? Why not always be a dick? At least it is consistent. reply hotspot_one 1 hour agorootparentUnder US law, the debts die with the person. You are under no obligation to repay your parent's debts. Now if the debt is tied to a house (mortgage) or a car (car loan), you might lose the house/car if you don't pay, but you do not have an obligation to pay. Likewise failure to pay will not impact your credit. So if I die in debt up to my eyeballs, and if I am sole signatory on those debts, I have only hurt my creditors, not my family. caveats-- if my family was counting on the house and I have an unaffordable mortgage, then yes I have caused them harm. Likewise other irresponsible debts. -- at the end of the chain, creditors are also people. It is their job to loan money at risk, so their loss is their problem, but this assumes I was dealing in good faith when I took the loan. reply groby_b 1 hour agorootparentThe debts very much don't die with the person - the estate is on the hook to pay your debts before distributing to heirs. Obviously, with some \"it depends\" nuance - but if the difference between this and your world view would make a significant difference to your loved ones, you might want to talk to an attorney. reply SoftTalker 54 minutes agorootparentCorrect, but if you die broke, nobody else is on the hook to pay your debts, unless that person cosigned a loan or something like that. reply greiskul 2 hours agorootparentprevGoogle has an option for what to do with your account if you are inactive for a set period of time. So you can choose what to delete, and what to give access to someone you want. You can also have it send emails to up to 10 people, with whatever message you want. reply adamdecaf 2 hours agorootparentprevYea the idea is that if your service doesn’t check-in then a preconfigured alert triggers. reply BrandoElFollito 2 hours agorootparentprevWhat is \"dishonor\" in that context? (Sorry, not a native speaker of English) reply eep_social 1 hour agorootparentAs a native speaker, I don’t think the phrasing is idiomatic but I read it to mean imprisoned or otherwise out of society without actually being dead. reply aftbit 50 minutes agorootparentYes, you got it 100%. I agree, it is not idiomatic, but was intended to call back the \"death before dishonor\" trope that your sibling commenter mentioned. I intended \"dishonor\" to cover a number of cases short of my death where I might be unable to continue to care for my obligations for a long period of time. For example, imprisoned, deplatformed, critically injured in a coma, lost in a serious mental health crisis, etc. In some ways, handling that is a harder challenge than handling death, as there are fewer well-worn paths to follow. reply meindnoch 2 hours agorootparentprevIt doesn't mean anything, because it is wrong. The correct idiom is \"death before dishonor\", which means that one would choose death instead of doing something disgraceful/shameful. reply superb_dev 1 hour agorootparentThat doesn’t make sense in the context reply asdfman123 2 hours agoparentprevI thought this was going to be some way to exact retribution on your employer after being laid off reply hinkley 1 hour agorootparentThat is the typical scenario in the context of software. Not that it happens often, but that the incidents are so memorable. reply duggan 2 hours agorootparentprevRoutinely surprised that there are adult human beings that do this, but so it goes. reply asdfman123 2 hours agorootparentI would never do it myself. Move on with your life! I did know a guy who worked at a major corporation explain his dead man switch like it was the most normal thing in the world, though. Extremely cursed. reply hinkley 1 hour agorootparentI could see people in a somewhat toxic situation do things like this but it’s better to get out. Especially if there’s some complex onerous task that needs to happen and you get no credit for doing it well. Leave, and let them find out what it’s like being one of the other characters in It’s a Wonderful Life in the worst timeline. reply John_Cena 2 hours agorootparentprevNaw, in the modern world only people like Bench Simmons get guaranteed contracts. :| reply vorpalhex 2 hours agoparentprevWire in pagerduty to whatever your action is. Ideally distributed on multiple infra pieces. This is just the switch side not the action side. Normally deadmans switches can be compromised by disrupting the deadman switch hardware. This removes that attack vector and pushes it further up the chain (which may or may not help you). It's certainly very clever. reply adamdecaf 2 hours agorootparentThanks. We already rely on PD so preconfiguring the alert/snooze isn’t additional risk for us. reply rozenmd 3 hours agoprevThe term of art you're looking for is: \"heartbeat check\"/\"healthcheck\", or most commonly: \"cron job monitor\". reply bravetraveler 2 hours agoparentSeems very similar to a 'watchdog', just... reporting instead of doing anything about it. reply adamdecaf 3 hours agoparentprevThere’s no crontab for banking days. Deadcheck also requires checkins within a delta of the expected checking time. Deadcheck also doesn’t rely on your infra to alert. reply vivzkestrel 1 hour agoparentprevuptime monitor? reply rozenmd 1 hour agorootparentUptime monitors ping your server, this seems to do the opposite. reply herpderperator 3 hours agoparentprevYeah I thought \"dead man's switch\" was such a weird name for this. reply cduzz 2 hours agoprevI guess I'm an oldster shaking my fist at clouds, but ... Depending on where you live, and if it matters, give it to an attorney. Maybe use this to trigger the notification to your attorney, with instructions on how to double check things before doing things. reply danbruc 2 hours agoparentI agree, I think people underestimate the importance of actually checking why the heart beat was missed, double checking is important. You might think you can easily click some button once a week and it is no problem to take some drastic and maybe irreversible actions after a week without any event. And then you get into a serious accident and end up in hospital for weeks. Or there is some bug unintentionally triggering the actions. reply cuu508 1 hour agorootparentThe configuration example in README has \"Reports Finalized\", so I assume this is more for IT infra monitoring, than for taking irreversible actions when you become incapacitated :-) reply christina97 2 hours agoprevI sometimes think about a “dead man service”: you leave instructions (that you upload to the service), then when you pass away/etc, the service operators go and follow your instructions and do whatever you asked for. You’d pay some pre-agreed sum, possibly annuity-type subscription, and at the end we go and follow your wishes. Basically a technically competent will executor. It’s probably too much to expect your family to know how to operate your systems. Maybe you encrypt the instructions and give fractional keys to family etc. reply lancesells 1 hour agoparentThis is an attorney. No subscription, no tech, no bugs, no encryption, less hackable. reply mhink 1 hour agorootparent> Basically a technically competent will executor. I don't think OP is saying that an attorney *can't* get these things done, but that it would make them feel more comfortable knowing that a technically competent person and/or service will be performing the actual actions. I do think there's a place for an attorney here, in the sense that they could be the trusted individual responsible for notifying DeadManService, Inc. that a particular person has, indeed, passed on and wishes DeadManService to run their instructions. reply ufmace 36 minutes agorootparentI'm not sure what value adding a DeadManService would have then. Probably simpler to just have the attorney's instructions say, \"Hire a technical consultant to carry out the following:\". reply INTPenis 2 hours agoparentprevI've thought about this too but I think the type of business best suited to execute this is a law firm, or you know, the normal executor of people's wills. They just need the IT bit. reply 9dev 3 hours agoprevI’m not sure I understand what the application itself does; as far as I can see, it basically configures the external services to carry out the actual checks and ensures this configuration is up to date? Wouldn’t it be better to do this as part of a Terraform script or something? Not to take away from the project, it sure looks neat—just wondering if I really want to deploy yet another, independent IaC tool. reply adamdecaf 3 hours agoparentIt sets up expected check in times for an app/job. The job is responsible for checking in, but the alert will fire regardless of your infra. Doesn’t require a start command and your infra can completely fail and you’ll still get alerted. reply hiatus 3 hours agoparentprevThere is a pagerduty provider for terraform, too. https://registry.terraform.io/providers/PagerDuty/pagerduty/... reply pigeonhole123 3 hours agoparentprevIt doesn't look like PagerDuty supports sending out alerts on missing heart beats reply bryanlarsen 3 hours agorootparentAFAICT, that's a better description of the project for people like us. It's a way to add a missing heart beat alert to PagerDuty. reply adamdecaf 3 hours agorootparentprevThe idea is an app checks in after scheduled jobs, which extends the snooze reply hiatus 3 hours agorootparentprevThat's exactly how escalation in pagerduty works. reply INTPenis 2 hours agoprevI did something similar years ago when I was working with observability. Prometheus alertmanager triggers a special alert constantly that calls a lambda (or any webhook), so when alertmanager dies or is unable to alert then the lambda will send an alert over a 3rd party push service to notify ops that alertmanager is down. We called it a dead man's switch but it was really just a way to monitor alertmanager. reply adamdecaf 1 hour agoparentYea I’ve setup two alertmanagers that check each other before. It’s useful for multi site deployments. reply herpderperator 3 hours agoprevSo... like BetterStack's heartbeat monitor? [0] [0] https://betterstack.com/docs/uptime/cron-and-heartbeat-monit... reply neilv 2 hours agoparentBetter Stack got on my disapproval list, for spamming me with a series of automated sales emails 15-20 minutes apart, which seemed designed that way. \"One more thing.\", etc. They should've sent one welcome&upsell email, not several. And not abused contact info that was intended to reach me reliably and promptly. For my immediate very simple need, Uptrends didn't spam me, and so far they've reliably and promptly notified me whenever my site is down even briefly (e.g., rebooting for kernel update), so they'll be getting money from me as I grow. https://www.uptrends.com/ reply herpderperator 1 hour agorootparentSorry to hear. I didn't have that experinece; it's been pleasant for me (there was a billing snafu while they changed their plan structure but it was resolved with a support email) and their monitoring has been very reliable since I signed up a year ago. Their service also seems to be better (4 checks/locations vs Uptrend's 2.) Anyway, tl;dr is I never had an issue that resulted in not getting alerted about something that I needed to be alerted about, which, above all else, is the point of their offering. reply tnolet 2 hours agoparentprevor Checkly's heartbeat check https://www.checklyhq.com/docs/heartbeat-checks/ reply adamdecaf 59 minutes agorootparentI don't see how to configure anything but an interval (e.g. every N minutes) in checklyhq. Deadcheck allows you to expect check-ins at arbitrary times (e.g. 9am, 1:15pm, 3:15pm on weekdays). https://developers.checklyhq.com/reference/postv1checksheart... reply focusedone 2 hours agoprevI feel like posting a software project to HN and meeting criticism is some near-end-stage of programming mastery. reply wcallahan 2 hours agoparentWas thinking the same! reply siliconc0w 3 hours agoprevA possible integration are messaging apps that support send later. I sometimes set these up if I'm going hiking. reply adamdecaf 3 hours agoparentYea, and you would delete the pending message. Good idea… reply v3ss0n 1 hour agoprevBetter have something that runs off the cloud. PagerDuty is not something under your countrol. A stuff as imporant as dead man switch should not rely on someone's service. reply tatersolid 1 hour agoparentOkay, so now your dead man’s switch depends on your home or colo’s power, internet connection, compute hardware, storage hardware, network hardware, software stack maintenance, plus the ability to pay bills for those on time? Pre-Paying a cloud service pennies per month to do all that for you will likely be more reliable and much simpler. reply turtlebits 3 hours agoprevI'm not sure running an additional service plus a SaaS requirement is better than relying on infra. Standing up this service is going to rely on your infra. What if it goes down? If you're going to have to write a scheduled check-in anyways, why not use something like cronitor and reduce the complexity? (they host the check-in endpoint) reply psnehanshu 2 hours agoparentIf the infra goes down, you fix it while alive, otherwise the snooze timeout on the PagerDuty incident will expire and that will trigger the configured tasks. If PagerDuty goes out of business before that, then that's a different discussion. reply turtlebits 29 minutes agorootparentMy point was - if you're going to rely on a SaaS (Pagerduty), why not just use one that includes health check monitoring (ie cronitor) and cut out this self hosted webhook service? reply adamdecaf 27 minutes agorootparentDeadcheck handles calculating the snooze durations for you. It could be a library as well. reply adamdecaf 2 hours agorootparentprevExactly. At Moov we rely on PD, so if they’re down we have bigger issues anyway. I plan to support additional integrations so a check-in could update multiple reply roshan8 2 hours agoprevNice one! Do you have any plans to support something else apart from Pager duty. I have been using Squadcast.com for my hobby project monitoring. Integration with that would be nice. I'm open to create a PR if you are interested. reply adamdecaf 2 hours agoparentThanks, yea I’d like to support other vendors. Haven’t heard of Squadcast I have https://github.com/adamdecaf/deadcheck/issues/12 tracking additional vendors Edit: I'm open to a PR if you're willing. Curious, but would you use their delayed notification config to implement? https://apidocs.squadcast.com/?version=latest#7742a9af-29fe-... reply wil421 3 hours agoprevAny support for something besides pager duty? I work for a telco and there are so many different heartbeats we rely, this project seems very useful for something like that. The config file looks much better than the python/perl/bash whatever scripts we have scheduled on our systems. reply adamdecaf 1 hour agoparentYea I want to support other vendors. What do you use? reply encoderer 2 hours agoprevCool trick using PagerDuty like that. If you don’t want to use a service like Cronitor, you can self-host this without the usual fear that an outage will also take down your monitoring. reply adamdecaf 2 hours agoparentYep. I looked at Cronitor and thought about using it, but direct to PD removed a step for us at Moov. reply grahamj 2 hours agoprevNeat. We use OpsGenie to monitor our alerting infra and it has deadman/heartbeat support so something like that is another way to go. reply adamdecaf 1 hour agoparentHow are they triggering the alert when the dead man’s switch isn’t tripped in time? reply joshbetz 2 hours agoprevVery clever. I have Alertmanager in a second region so it can check on my first Alertmanager, but this is much nicer. reply adamdecaf 1 hour agoparentYea I’ve setup multiple Alertmanagers that all check each other before. That setup is useful to detecting route failures between sites. reply jrockway 2 hours agoparentprevI ended up going this route: https://github.com/jrockway/alertmanager-status reply xyst 2 hours agoprevI’ll use this for my next wormable vuln instead of hard coding DNS checks ;) reply hiatus 3 hours agoprevDo the people on the receiving end of a pagerduty notification require pagerduty accounts? reply adamdecaf 1 hour agoparentNo, you can get text, email, slack, etc alerts from PagerDuty without installing their app. reply lopkeny12ko 3 hours agoprevI don't understand this. You're still taking on a dependency on some infra, but now that infra is Pagerduty. What problem is this even solving reply hypeatei 3 hours agoparentThat's what I thought; this tool is \"kicking the can\" to whatever third party service you're using. So, it's essentially just a tool that will ping stuff for you in a slightly more convienent way? reply adamdecaf 1 hour agorootparentSystems always rely on something. PagerDuty has been very reliable for years and we use it for alerting, so relying on it more isn’t a big ask. I plan to support multiple integrations so you could get alerted from multiple streams. reply zeroq 3 hours agoparentprevIt's a cloudification of dead man's switch. reply hooverd 2 hours agoparentprevYour infra is relying on an ISP and colo and the power company and maybe even the Post Office. You're always relying on something that's not you. Personally I'd rely on pre-paid AWS. If all of us-east-1 goes down for days then we probably have bigger problems. reply ForHackernews 1 hour agoprevI don't know about the rest of the people here, but I aim to outlive PagerDuty. reply jbverschoor 3 hours agoprevNot to be confused with deadmanssnitch.com reply EGreg 2 hours agoprev [–] Speaking of not using anyone’s specific infra, we deployed software on blockchains to do this. We had to implement a “heartbeat” and “succession” in our blockchain-based solutions for organizations to control things together. It’s part of our “application suite for organizations” where each one is sort of this general-purpose LEGO block that could be used to build a custom solution. In each case, you’d enter some parameters and create an instance from a Factory. We made it simple and secure for any organization to use this. In this specific one, ControlFactory is used to create ControlContract instance that can be used to control an address together (to sign off things collectively, like transfer tokens or call an arbitrary method on a different address) We had to handle what happens if the M of N people don’t show up for a while. And we said they have to call a heartbeat() method every so often. If they fail to call it then control temporarily passes to the next group in succession, until the OGs can finally call the heartbeat() method again. Here is more info on the why: https://community.intercoin.app/t/intercoin-applications-con... And here are the rest of the blockchain apps for organizations: https://community.intercoin.app/t/applications-of-intercoin-... You can go ahead and use it, the factory it’s been deployed on many EVM blockchains, at the same address. PS: fun fact, you can configure a ControlContract to also manage calling methods on itself, thereby creating custom “policies” for organizations when it comes to granting/recoving rights of other people to the quorum. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new Go project, Deadcheck, has been developed to function as a dead man's switch without relying on cron jobs, timers, or databases.- Deadcheck integrates with PagerDuty, a popular incident management platform, to keep incidents snoozed until a check-in is missed, at which point it triggers an alert.- This project is notable for its innovative approach to managing alerts and incidents without traditional scheduling or database dependencies."
    ],
    "commentSummary": [
      "Deadcheck is a Go project designed as a dead man's switch, eliminating the need for cron jobs or databases, and integrates with PagerDuty to manage alerts.",
      "The project has sparked discussions on dead man's switches, including legal aspects and alternative solutions such as using attorneys or blockchain systems.",
      "Users have suggested existing services like Cronitor or OpsGenie for similar functionalities, and the project plans to expand integrations beyond PagerDuty."
    ],
    "points": 102,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1728657639
  },
  {
    "id": 41808683,
    "title": "Understanding the Limitations of Mathematical Reasoning in Large Language Models",
    "originLink": "https://arxiv.org/abs/2410.05229",
    "originBody": "Computer Science > Machine Learning arXiv:2410.05229 (cs) [Submitted on 7 Oct 2024] Title:GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models Authors:Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, Mehrdad Farajtabar View PDF HTML (experimental) Abstract:Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a large-scale study on several SOTA open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of this http URL findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and show that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is because current LLMs cannot perform genuine logical reasoning; they replicate reasoning steps from their training data. Adding a single clause that seems relevant to the question causes significant performance drops (up to 65%) across all state-of-the-art models, even though the clause doesn't contribute to the reasoning chain needed for the final answer. Overall, our work offers a more nuanced understanding of LLMs' capabilities and limitations in mathematical reasoning. Comments: preprint Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI) Cite as: arXiv:2410.05229 [cs.LG](or arXiv:2410.05229v1 [cs.LG] for this version)https://doi.org/10.48550/arXiv.2410.05229 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Seyed Iman Mirzadeh [view email] [v1] Mon, 7 Oct 2024 17:36:37 UTC (5,949 KB) Full-text links: Access Paper: View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.LGnewrecent2024-10 Change to browse by: cs cs.AI References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) IArxiv recommender toggle IArxiv Recommender (What is IArxiv?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=41808683",
    "commentBody": "Understanding the Limitations of Mathematical Reasoning in Large Language Models (arxiv.org)98 points by hnhn34 7 hours agohidepastfavorite118 comments eigenform 1 minute agoThe difference is that, if we are solving a math problem together, you and I [explicitly or implicitly] can come to an agreement over the context and decide to restrict our use of language with certain rules. An LLM is very good at recovering rules, but being good at pattern recognition is not the same thing as being good at unambiguously following rules in the appropriate context. reply woopwoop 3 hours agoprevThis paper, among other things, shows that LLMs have dramatically worse performance on basic algebra questions when you add in irrelevant information. The examples are things like \"John picked 43 kiwis on Monday, 24 kiwis on Tuesday. On Wednesday, 5 of the kiwis he picked were smaller than usual. Altogether, on Monday, Tuesday, and Wednesday, John picked 87 kiwis. How many kiwis did John pick on Wednesday?\" In this question, the remark about some of the kiwis on Wednesday being small is irrelevant, but adding things like this reduces performance on a popular benchmark from 95% to 77% for GPT-4o, for example. I don't find this very impressive. Forget LLMs for a second. Let's say _you_ read a question of that kind with some bit of irrelevant information. There are two possibilities you have to consider: the question may as well have excluded the irrelevant information, or the question was miswritten and the irrelevant information was meant to be relevant. The latter is a perfectly live possibility, and I don't think it's a dramatic failure to assume that this is correct. I have to confess that when I read some people's LLM gotcha questions, where they take some popular logic puzzle and invert things, I think I would get them \"wrong\" too. And not wrong because I don't understand the question, but wrong because with no context I'd just assume the inversion was a typo. reply aithrowawaycomm 2 hours agoparentThe problem here is that throwing in little gotchas like that is a tactic used by math and physics educators to ensure that students actually understand the topic by reasoning through new problems, rather than mindlessly turning the crank from learning the \"surface structure\" of earlier problem sets. The argument here is that the LLM is not reasoning, it's mindlessly turning a crank. I don't think this exact question would be out of place on a 6th grade math test. I distinctly remember being taught this skill in \"word problems,\" learning to identify information that actually pertains to the question rather than being distracted by red herrings the teacher threw in. reply aguaviva 1 hour agorootparentIndeed, and the ability to make heads or tails of slightly-slippery problems of this sort is an extremely important real-world math skill. It's not extraneous at all. And their poor performance on these tasks highlights deficits in exactly the kind of higher-order, off-the-page reasoning skills -- i.e. to not just reason based on the apparent objects in the stream (the kiwis and the numbers in this case), but to reason about the token stream itself: \"okay, these tokens are important, but these others I can leave out\", efficiently and seamlessly (like humans do) -- that the models are supposed to develop. This whole attention business, they're calling it. reply aithrowawaycomm 1 hour agorootparentIn particular the fact that humans sometimes don't do this, taking the bait with extraneous distractions, is almost always a fairly shallow psychological thing rather than an actual cognitive deficit, e.g. OP hypothetically assuming the question had a typo and trying to read the examiner's mind. In education the gotchas really can be unfair if the (human) student has been conditioned to bark answers but the teacher changes things drastically on an exam. I don't think that's an accurate characterization of this study; even if it was that would be a problem with shallow LLM training, not mean-spirited evaluation. But I suspect that \"barking answers according to surface characteristics\" is as far as transformers can go. It certainly is possible that we just need to train transformers better... but there have been some theoretical results suggesting otherwise. [E.g. transformer LLMs + chain-of-thought is pretty good at O(n) problems but struggles with O(n^2), even if the O(n^2) task is an obvious combination of two O(n) tasks it is able to do.] That leads to a serious annoyance I have with discussing LLMs - humans' capacity for boredom / cynicism / distraction / laziness being used to excuse away what seems to be deep-rooted limitations in LLMs. It simultaneously misunderstands what a human is and what a machine is. (\"Sometimes humans also refuse to work\" would be a bad excuse from an auto dealer.) reply swatcoder 2 hours agoparentprevReal discourse has tons of irrelevant information for all sorts of reasons. There are some contexts, academic or professional, where questions are posed carefully and specifically, but these are narrow contexts. A useful general purpose assistant needs to be able to find what's relevant among what's irrelevant. Excellence at just solving math problems that are especially well specified can be a useful domain assistant (no small win!), but is not the same thing. That said, if you've got a hundred billion dollars betting on your AI project achieving AGI, you benefit a lot by conflating those contexts. In that case, grinding on formal SAT, LSAT, GRE, etc problems amounts to tuning for microbenchmarks rather than real world use cases. reply woopwoop 2 hours agorootparentReal discourse is also full of typos which accidentally invert the meaning of things, asking the wrong question for deep reasons, asking the wrong question for shallow reasons, and all of the other things that justify subtracting the below average size kiwis from the final answer. reply meroes 1 hour agoparentprevIrrelevant info is taught in grade skill and is a skill for the SAT for example. Basically any kind of model (not just LLMs/ML) has to distill out irrelevant info. The point is having an answer that you can defend logically and most people would agree. If the model said “I’m not sure if this portion is a typo”, I guarantee you the model creators would take the RLHF in a different direction, because that is somewhat reasonable and defensible. However in your specific question, I personally think there is a singular objective answer—but that isn’t always the case to be fair for misleading/irrelevant prompts. The models are being fooled however based on how they respond. I say this as a RLHF’er who sees and is told to write similar questions at times. At the end of the day, this is how the Model creators want their models to predict language. And anyone using them is in for their ride. reply sottol 2 hours agoparentprevI think this is valid though. Transformer models don't explicitly do logic but implicitly \"vibe\" out the answer from the input sequence (using the attention mechanism) and learnt knowledge - they're predicting text sequences after all. So adding more irrelevant context to the input would quite likely influence the the output. I could see attention possibly being able to overcome this, but if not that would be a pretty big gotcha for real-world applications and reliability in real-world scenarios where, as others have said, it's not immediately clear what is relevant info. These models would be a lot less useful if a human had to decide which information to feed them and the output would be dependent on human judgement. I understand it's where we're at right now and that they are quite useful already but the valuations hint at investors expecting more imo. reply jfrbfbreudh 2 hours agoparentprevI think it’s an important result because filtering signal from noise is just as, if not more, important than forming conclusions from signal. reply andoando 1 hour agoparentprevConsider that asking exam style direct questions with only the precise context that matters is a very niche task out of all the possible contexts in which an intelligence is asked to understand. reply WhitneyLand 2 hours agoparentprevI agree it wasn’t that convincing, moreover the variation wasn’t that dramatic for the large sota models. Why should they write a paper about the inherent reasoning capabilities for “large” language models and then in the abstract cherrypick a number that’s from a tiny 1B parameter model? reply parsimo2010 4 hours agoprevI won't take a strong stance on whether or not LLMs actually do reasoning, but I will say that this decrease in performance is similar to what I see in college freshmen (I'm currently teaching a calculus course in which almost half of the students took AP calc in high school). They perform well on simple questions. Requiring students to chain multiple steps together, even simple steps, results in decreased accuracy and higher variance (I have no data on whether this decrease is linear or not, as the paper assumes that the decrease should be linear with the number of steps). We see similar results with adding unrelated statements into a problem- many students are trained to make sure to use all given information in solving a problem- if you leave out something that the instructor gives you, then you probably forgot to do something important. So while I don't take a stance on what an LLM does should be considered reasoning, I do think that SOTA LLMs like GPT-4o perform about as good as high school graduates in America with average intelligence. In other words, average Americans exhibit similar limitations on their reasoning as good LLMs. Which on the one hand is a little disappointing to me in terms of the human performance but is kind of good news for LLMs- they aren't doing graduate-level research but they are already capable of helping a large portion of the population. reply skydhash 4 hours agoparentNot to disparage American school system (my country’s is worse) but it’s very much easy mode. I know that not everyone is suited to academic excellence, but it’s definitely easier to learn when young. I do believe too much hand holding actively harm learning. reply BriggyDwiggs42 4 hours agorootparentI don’t think the issue with American schools is that there’s too much hand holding. If anything, it’s the opposite; teachers at drastically underfunded schools don’t have any time to help the students of their 50 person class through the confused curriculum. reply skydhash 3 hours agorootparentHere, we have to go through 4 state exams just to get to university. The first when you’re 11, the second at 14, then two consecutive ones at 17 and 18. There’s a national curriculum that the exams will be about, although the schools are free to add to it. So however you feel about the school or the teacher, you have to master the subjects enough to go through. And that means paying attention in class, cram before it, or hoping you can cheat. We have our own problem too, but the consensus among all the people I know that have moved to the US is that classes are easy there. Not a bad thing per se (better explanation, better understanding instead of rote memorizing). reply debit-freak 4 hours agoparentprev> In other words, average Americans exhibit similar limitations on their reasoning as good LLMs. It's not even clear this is a good example of \"reasoning\". You can progress all the way through multi-variable calculus with just decent pattern-matching, variable-substitution, and rote memorization of sufficient lists of rules. I imagine for \"reasoning\" ability to apply you need to be able to detect incoherency and reject an approach—and incoherency detection seems to be a big missing ingredient right now (...which many humans lack, too!). On the other side—any such ability would cripple a chatbot's ability to answer questions about the real world as our world is characterized (via description with informal language) by incoherent and contradictory concepts that can only be resolved through good-faith interpretation of the questioner. A large mark of intelligence (in the colloquial sense, not the IQ sense) is the ability to navigate both worlds. reply richerram 3 hours agoparentprevThis, it is like when I hear interviews of PHDs talking about AI and they mention something like \"AI will be smarter than humans\", I am like \"really?, where have you been all this time?, do you smart people ever leave your labs and go see the real world?, LLMs are already smarter that the huge majority of Humans in this planet, what are you talking about?\" reply zeroonetwothree 3 hours agorootparentThis must be some bizarre definition of “smarter”. reply bob1029 5 hours agoprev> we investigate the fragility of mathematical reasoning in these models and demonstrate that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is due to the fact that current LLMs are not capable of genuine logical reasoning I'd offer a simpler explanation: Tokenization. If you tokenize \"12345 * 27271\" you will get the following: \"123\", \"45\", \" *\", \" \", \"272\", \"71\" The statistical likelihood that any of these tokens predicts any of the others is completely meaningless in the context of simple arithmetic. You can argue that this is where tool use comes in (and I would be inclined to agree), but I don't think this bodes well for \"genuine logical reasoning\". reply soulofmischief 4 hours agoparentNanda, et al. successfully recovered the exact mechanism through which a transformer learned to carry out modular addition. [0] Transformers are all about the training data, and we will increasingly learn that structuring the order in which data is learned matters a lot. But it's clear that transformers are absolutely capable of encoding generalized solutions to arithmetic. Given the right tokenization scheme and training regimen, we can absolutely create LLMs which have statistically sound arithmetic capabilities. I still wouldn't trust a stochastic model over the algorithmic certainty of a calculator, but what's more important for mathematicians is that these models can reason about complex problems and help them break new ground on hard mathematical problems by leveraging the full statistical power of their weights. [0] https://arxiv.org/abs/2301.05217 reply pfortuny 1 hour agorootparentIt is important to note that the paper deals with addition modulo a specific prime P=113 (I think it is prime). This is important because the paper does not prove that the LLM discovers the algorithm for addition modulo n for general n. reply ttul 4 hours agoparentprevI respectfully disagree. While tokenization certainly plays a role in how language models process input, it's simplistic to attribute the challenges in mathematical reasoning solely to tokenization. SOTA language models don't just rely on individual token predictions, but build up contextual representations across multiple layers. This allows them to capture higher-level meaning beyond simple token-to-token relationships. If this weren’t the case, it would be inconceivable that models would work at all in all but the most utterly simplistic scenarios. The decline in performance as complexity increases might be due to other factors, such as: - Limitations in working memory or attention span - Difficulty in maintaining coherence over longer sequences - Challenges in managing multiple interdependent logical constraints simultaneously (simply due to the KQV matrices being too small) And in any case, I think OpenAI’s o1 models are crushing it in math right now. The iterative, model-guided CoT approach seems to be able to handle very complex problems. reply m3kw9 4 hours agorootparentI would say the more variable you give it the more the probability drifts for each of the facts they have to hold, maybe LLMs still doesn’t have the ability to ignore useless stuff you add to the prompt reply l33t7332273 3 hours agorootparentI thought attention was all you need reply altruios 2 hours agorootparentHow much attention do you need? ...is probably an important question too. reply andrepd 4 hours agorootparentprev>And in any case, I think OpenAI’s o1 models are crushing it in math right now. My man, it cannot solve even the simplest problems which it hasn't seen the solution to yet, and routinely makes elementary errors in simple algebraic manipulations or arithmetic! All of this points to the fact that it cannot actually perform mathematical or logical reason, only mimic it superficially if trained in enough examples. I challenge you to give it even a simple, but original, problem to solve. reply WhitneyLand 2 hours agorootparentPlease provide your precise definitions of “reasoning” and “original”. There’s no consensus in the literature on what these mean even if you make it more specific by talking about “mathematical reasoning”, so I don’t really understand what opinions like these are based on. I see a lot of no true Scottsman fallacy going around, even the paper resorts to this as it actually uses phrases like “true reasoning” several times. I don’t think the paper is very convincing btw, the abstract is kind of click-baity and talks about 65% variation when that was a cherry picked example from a tiny phi model and the SOTA models showed way less variation which was arguably not that interesting. reply Workaccount2 3 hours agorootparentprev>I challenge you to give it even a simple, but original, problem to solve. (34903173/x)+(238 * 2650) - 323326 = 45323434, solve for x Statistically, no one has ever done this calculation ever before. It's entirely unique. O1 answered \"x = 34,903,173 divided by 45,016,060\", which is correct.[1][2] Now I guess you can pick up the goal post and move it. [1]https://chatgpt.com/share/6709481a-3144-8004-a7fd-0ccd9e3bc5... [2]https://www.wolframalpha.com/input?i=%2834903173%2Fx%29%2B%2... reply bob1029 2 hours agorootparent> Now I guess you can pick up the goal post and move it. The central problem with math is that you have an infinite amount of space within which to move these goalposts. How many variants on this trial before we find a mistake? What is an acceptable error rate? reply naasking 2 hours agorootparent> How many variants on this trial before we find a mistake? How many variants would it take for a human to make a mistake? It's certainly not \"infinity\", so is this an indication that humans don't reason? reply jimhefferon 2 hours agorootparentprevAt this moment, the error rate seems to be that of a beginning graduate student. Or at least, that's what Terry Tao thinks. That's pretty good. reply ukuina 3 hours agorootparentprevDo you have some categories of such original problems? It seems markedly better at reasoning/logic puzzles, and programmatically-solvable problems are often offloaded to the Python interpreter. reply TZubiri 4 hours agoparentprevWouldn't a slight change in tokenization? (say mapping single digits to single tokens) help with this specific challenge? reply wenc 3 hours agorootparentAren’t coding copilots based on tokenizing programming language keywords and syntax? That seems to me to be domain specific tokenization (a very well defined one too — since programming languages are meant to be tokenizable). Math is a bit trickier since most of the world’s math is in LaTeX, which is more of a formatting language than a syntax tree. There needs to be a conversion to MathML or something more symbolic. Even English word tokenization has gaps today. Claude Sonnet 3.5 still fails on the question “how many r’s are there in strawberry”. reply gwillen 3 hours agorootparent> Aren’t coding copilots based on tokenizing programming language keywords and syntax? No, they use the same tokenization as everyone else. There was one major change from early to modern LLM tokenization, made (as far as I can tell) for efficient tokenization of code: early tokenizers always made a space its own token (unless attached to an adjacent word.) Modern tokenizers can group many spaces together. reply bob1029 3 hours agorootparentprevContext-specific tokenization sounds a lot like old fashioned programming. reply m3kw9 4 hours agoparentprevThe llm will know 123 and 45 is a contiguious number just like how humans can tell if you say 123 and then a slight pause 45 as a single number reply TZubiri 4 hours agorootparentIt's just so dissonant to me that the tokens in mathematics are the digits, and not bundles of digits. The idea of tokenization makes sense for taking the power off letters, it provides language agnosticism. But for maths, it doesn't seem appropriate. I wonder what the effect of forcing tokenization for each separate digit be. reply soulofmischief 4 hours agorootparentprevI think that as long as the attention mechanism has been trained on each possible numerical token enough, this is true. But if a particular token is underrepresented, it could potentially cause inaccuracies. reply sva_ 4 hours agorootparentprevIt won't 'see' [123, 45] though, but [7633, 2548], or rather sparse vectors that are zero at each but the 7634th and 2549th position. reply s-macke 5 hours agoprevThese results are very similar to the \"Alice in Wonderland\" problem [1, 2], which was already discussed a few months ago. However the authors of the other paper are much more critical and call it a \"Complete Reasoning Breakdown\". You could argue that the issue lies in the models being in an intermediate state between pattern matching and reasoning. To me, such results indicate that you can't trust any LLM benchmark results related to math and reasoning when you see, that changing the characters, numbers or the sentence structure in a problem alter the outcome by more than 20 percentage points. [1] https://arxiv.org/html/2406.02061v1 [2] https://news.ycombinator.com/item?id=40811329 reply oliwary 5 hours agoparentSomeone (https://x.com/colin_fraser/status/1834336440819614036) shared an example that I thought was interesting relating to their reasoning capabilities: A man gets taken into a hospital. When the doctor sees him, he exclaims \"I cannot operate on this person, he is my own son!\". How is this possible? All LLMs I have tried this on, including GPT o1-preview, get this wrong, assuming that this the riddle relates to a gendered assumption about the doctor being a man, while it is in fact a woman. However, in this case, there is no paradox - it is made clear that the doctor is a man (\"he exclaims\"), meaning they must be the father of the person being brought in. The fact that the LLMs got this wrong suggests that it finds a similar reasoning pattern and then applies it. Even after additional prodding, a model continued making the mistake, arguing at one point that it could be a same-sex relationship. Amusingly, when someone on HN mentioned this example in the O1 thread, many of the HN commentators also misunderstood the problem - perhaps humans also mostly reason using previous examples rather than thinking from scratch. reply layer8 4 hours agorootparent> perhaps humans also mostly reason using previous examples rather than thinking from scratch. Although we would like AI to be better here, the worse problem is that, unlike humans, you can’t get the LLM to understand its mistake and then move forward with that newfound understanding. While the LLM tries to respond appropriately and indulge you when you indicate the mistake, further dialog usually exhibits noncommittal behavior by the LLM, and the mistaken interpretation tends to sneak back in. You generally don’t get the feeling of “now it gets it”, and instead it tends to feels more like someone with no real understanding (but very good memory of relevant material) trying to bullshit-technobabble around the issue. reply oliwary 4 hours agorootparentThat is an excellent point! I feel like people have two modes of reasoning - a lazy mode where we assume we already know the problem, and an active mode where something prompts us to actually pay attention and actually reason about the problem. Perhaps LLMs only have the lazy mode? reply letmevoteplease 3 hours agorootparentI prompted o1 with \"analyze this problem word-by-word to ensure that you fully understand it. Make no assumptions.\" and it solved the \"riddle\" correctly. https://chatgpt.com/share/6709473b-b22c-8012-a30d-42c8482cc6... reply hoosieree 2 hours agorootparentMy classifier is not very accurate: is_trick(question) # 50% accurate To make the client happy, I improved it: is_trick(question, label) # 100% accurate But the client still isn't happy because if they already knew the label they wouldn't need the classifier! ... If ChatGPT had \"sense\" your extra prompt should do nothing. The fact that adding the prompt changes the output should be a clue that nobody should ever trust an LLM anywhere correctness matters. [edit] I also tried the original question but followed-up with \"is it possible that the doctor is the boy's father?\" ChatGPT said: Yes, it's possible for the doctor to be the boy's father if there's a scenario where the boy has two fathers, such as being raised by a same-sex couple or having a biological father and a stepfather. The riddle primarily highlights the assumption about gender roles, but there are certainly other family dynamics that could make the statement true. reply s-macke 2 hours agorootparentprevI have found multiple definitions in literature of what you describe. 1. Fast thinking vs. slow thinking. 2. Intuitive thinking vs. symbolic thinking. 3. Interpolated thinking (in terms of pattern matching or curve fitting) vs. generalization. 4. Level 1 thinking vs. level 2 thinking. (In terms of OpenAIs definitions of levels of intelligence) The definitions describe all the same thing. Currently all of the LLMs are trained to use the \"lazy\" thinking approach. o1-preview is advertised as being the exception. It is trained or fine tuned with a countless number of reasoning patterns. reply tgv 5 hours agorootparentprevI'm sure we fall back on easy/fast associations and memories to answer. It's the way of least resistance. The text you quote bears more than a superficial similarity to the old riddle (there's really nothing else that looks like it), but that version also stipulates that the father has died. That adds \"gendered\" (what an ugly word) information to the question, a fact which is missed when recalling this particular answer. Basically, LLMs are stochastic parrots. reply travisjungroth 3 hours agorootparentHow people don’t see the irony of commenting “stochastic parrots” every time LLM reasoning failure comes up is beyond me. There are ways to trick LLMs. There are also ways to trick people. If asking a tricky question and getting a wrong answer is enough to disprove reasoning, humans aren’t capable of reasoning, either. reply s-macke 5 hours agorootparentprev> perhaps humans also mostly reason using previous examples rather than thinking from scratch. We do, but we can generalize better. When you exchange \"hospital\" with \"medical centre\" or change the sentence structure and ask humans, the statistics would not be that different. But for LLMs, that might make a lot of difference. reply apsec112 5 hours agoparentprevBoth Claude-3.5 and o1-preview nail this problem \"Let's think through this step-by-step: 1. Alice has 3 brothers 2. Alice has 2 sisters 3. We need to find out how many sisters Alice's brother has The key here is to realize that Alice's brothers would have the same sisters as Alice, except they would also count Alice as their sister. So, Alice's brothers would have: - The 2 sisters Alice has - Plus Alice herself as a sister Therefore, Alice's brothers have 3 sisters in total.\" reply s-macke 5 hours agorootparentAnd here lies the exact issue. Single tests don’t provide any meaningful insights. You need to perform this test at least twenty times in separate chat windows or via the API to obtain meaningful statistics. For the \"Alice in Wonderland\" paper, neither Claude-3.5 nor o1-preview was available at that time. But I have tested them as well a few weeks ago with the issue translated into German, achieving also a 100% success rate with both models. However, when I add irrelevant information (My mother ...), Claude's success rate drops to 85%: \"My mother has a sister called Alice. Alice has 2 sisters and 1 brother. How many sisters does Alice's brother have?\" reply probably_wrong 4 hours agorootparentYour experience makes me think that the reason the models got a better success rate is not because they are better at reasoning, but rather because the problem made it to their training dataset. reply s-macke 3 hours agorootparentWe don't know. The paper and the problem was very prominent at that time. Some developers at Anthropic or OpenAI might have included that in some way. Either as test or as a task to improve the CoT via Reinforcement Learning. reply andrepd 3 hours agorootparentprevAbsolutely! It's the elephant in the room with these ducking \"we've solved 80% of maths olympiad problems\" claims! reply Workaccount2 4 hours agorootparentprevWe do have chatbot arena which to a degree already does this. I like to use: \"Kim's mother is Linda. Linda's son is Rachel. John is Kim's daughter. Who is Kim's son?\" Interestingly I just got a model called \"engine test\" that nailed this one in a three sentence response, whereas o1-preview got it wrong (but has gotten it right in the past). reply andoando 1 hour agorootparentprevYou also need a problem that hasn't been copy pasted a million times on the internet. reply einarfd 4 hours agorootparentprevMy problem with this puzzle, is how do you know that Alice and her brothers share both parents? Is it not correct English to call two people who share one parent, sisters, or brothers? I guess I could be misguided by my native Norwegian where you have to preamble the word with \"hell\" (full), or \"halv\" (half), if you want to specify the number of shared parents. reply thfuran 4 hours agorootparentIt is pretty much the same in English. Unqualified would usually mean sharing both parents but could include half- or step-siblings. reply s-macke 3 hours agorootparentI am not a native English speaker. Can you reformulate the problem for me, so that every alternative interpretation is excluded? reply zeroonetwothree 3 hours agorootparentAlice has N full sisters. She also has M full brothers. How many full sisters does Alice’s brother have? reply s-macke 2 hours agorootparentTried it with N=2 and M=1 (brother singular) with the gpt-4o model and CoT. 1. 50% success without \"full\" terminology. 2. 5% success with \"full\" terminology. So, the improvement in clarity has exactly the opposite effect. reply zeroonetwothree 3 hours agorootparentprevThey would usually be called “half-sisters”. You could call them “sisters” colloquially though but given it’s presented as a logic question I think it’s fine to disregard reply resters 2 hours agoprevI think it's obvious that LLMs will be able to do \"reasoning\" far better than humans. We must separate our notion of what is remarkably human. Rarely is it the reasoning, it's the intuition that a logical path exists -- for example a mathematical proof that draws from separate sub-disciplines of mathematics, etc. Consider that in a LLM, language inputs are tokenized and fed as inputs into the neural network, and connections in the network create output sequences that are not just syntactically correct (trivial) or form semantically plausible sentences (early transformers did this). LLM output sequences follow the deep patterns of language which include sometjhing that resembles reasoning as the model has learnt from its training data. LLMs seem to fall short because they often fail at truly abstract reasoning tasks that humans find easy. If trained properly, LLMs can develop advanced representations of logical systems that will surely outpace what humans can do in terms of raw reasoning. However, human mathematicians have not even unified around constructive mathematics as a must for the study of mathematics. This reveals that even highly evolved mathematical disciplines rely on objects whose characteristics do not lend themselves to full logical scrutiny and are in a way socially constructed and effectively hard to audit. While notation in mathematics is incredible technology it is also a highly limiting factor that suffers major tradeoffs. Humans struggle to invent new notation fast enough and to discard outdated notation fast enough. If we do see an AI-powered boom in mathematics, I suspect our notion of notation and the fluidity we demand from it will change dramatically. reply islewis 1 hour agoparentThis argument is centered around the belief that language and reasoning flow bidirectionally- language can be understood first (we are here), and reasoning is the next natural rung of the latter (your thesis believes we will get here with LLMs). I see language more as a medium for transcribing reasoning. While language certainly communicates reasoning, you can have reasoning without language, but not language without reasoning. This paper seems to imply that current LLM's are just copying the training dataset's reasoning communication, not understand the actual reasoning. I don't think LLM's moving past this is \"obvious\" or even close to being inevitable. > Instead, LLMs likely perform a form of probabilistic pattern-matching and searching to find closest seen data during training without proper understanding of concepts. While this process goes beyond naive memorization of words and the models are capable of searching and matching more abstract reasoning steps, it still falls short of true formal reasoning. reply resters 1 hour agorootparentI realize there is subtlety to the question of which is first. An infant, crying when it is hungry and pre-linguistic, is applying modus ponens. C -> F crying implies food, so I cry and then I get fed. Language grows in humans just like arms and legs, and so does reasoning. Baby animals do the same behavior but don't use language, so perhaps some logic is wired by instinct. Either way I don't think we need to worry about that detail. Consider how language input to an LLM is tokenized. Now imagine a tokenization scheme that introduces tokens that track the strict logical reasoning in the language. Thus two completely different English sentences could both tokenize as the application of Modus Ponens over assumption 1 to conclude conclusion 2, for example. Now consider that we can tokenize formal notation as used in mathematics and logic, and we can train LLMs on mathematical papers, peer review write-ups, etc. We can generate millions of correct proofs and teach it which ones are remarkable and why, etc. Ultimately we run into the same barrier as mathematical constructivists run into, but I think it's still quite plausible that LLMs trained as I describe would be able to reason quite well and find oversights humans missed. However creating the optimal scheme and implementation is not trivial. reply sottol 2 hours agoparentprev> If trained properly, LLMs can develop advanced representations of logical systems that will surely outpace what humans can do in terms of raw reasoning. We have already trained the LLMs on most of the human knowledge base (so like 4-5000 years?) - imo training data will become a problem and will soon be more expensive than compute. Sure, you can work around some of this using synthetic training data but I personally would not count on general-purpose LLMs (especially LLMs aka transformer models) developing super-human representations of logical systems anytime soon. reply resters 1 hour agorootparentI don't disagree, however I'm optimistic because most of the current reasoning \"ability\" of LLMs comes from the accidental reasoning embedded in language patterns. For example, the prompt completion: \"The mouse has a unique digestive system compared to other rodents, however the sparrow\" on GPT-4o is \"exhibits a highly specialized digestive system adapted for rapid processing of food, particularly seeds and insects, through structures like the crop and gizzard, which are not found in rodents.\" Claude 3.5 completes it as \"has a completely different digestive anatomy as a bird. Birds like sparrows have adaptations for flight, including a lightweight skeletal system and a specialized digestive tract. Unlike mice, sparrows have a crop for storing food, a gizzard for grinding it, and generally shorter intestines to reduce weight. They also lack teeth, instead using their beak to manipulate food.\" What appears to be a thoughtful contrast is merely a language pattern. Similarly, a prompt like \"Assume -B, A->B. Under what circumstances is B true?\" will simply follow the gradient to return output that is likely correct. Prompts like \"what is 2+2\" fail only because nobody bothers to write about it so simple arithmetic was not in the training data. However the way that multi-modal LLMs handle images is inspiring as it effectively converts from the visual domain into the sequential token domain. The same could be done for symbolic systems, etc. reply agentultra 1 hour agoparentprevI don’t see how it’s obvious that LLM’s will be capable of any mathematical, “reasoning. LLM’s can infer relationships and maintain longer context chains in order to generate their output… it still happens that some times the output is correct depending on the training data, layers, context, etc. And it can get more accurate when we change the parameters of the model. But the algorithm isn’t “doing” anything here. It will generate something regardless of what it’s prompted with. Maybe it’s right. But the algorithm is an algorithm. It doesn’t care what truth is. It’s generating BS essentially. A human is doing a lot more work when performing mathematics. It may be that LLM’s can be a useful tool in mathematical reasoning but it’s not obvious that it will ever be capable of it without a human, let alone be better than a human. reply resters 1 hour agorootparentI think models could be designed that in separate layers created \"logical system\" representations which could feed back into the output, much like how attention works. Attention is about relevance, the logical layers could be based on logical schema-based patterns. Consider an LLM that happened to have some pre-trained layers that were trained abstractly on all the constructive proofs available for modern mathematics. LLMs with image recognition rely on existing visual pattern recognition layers, fwiw. reply trehalose 1 hour agoprevI see a lot of discussion about irrelevant clauses tripping up the LLMs and why that does or doesn't matter. To me, what's far more damning is this: > Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. This seems like irrefutable evidence of overfitting, that in the best case scenario is epidemic among current LLMs (and in the worst case interpretation, is covering up fundamental inabilities to learn mathematical reasoning from the training data). reply thenoblesunfish 5 hours agoprevVery interesting, and aligns with what I would expect in terms of the type of \"thinking\" LLMs do. I think that it's also the type of \"thinking\" that will let a student pass most school courses, except of course for the ones where the teacher has taken the time to pose test questions that aren't as amenable to pattern matching. (Hard, but I assume most readers here are familiar with leetcode style interviews and what makes questions of that kind higher or lower quality for assessing candidates) (And yes, I know people are hard at work adding other types of thinking to work along with the pure language models) reply gradientsrneat 1 hour agoprevCould this be Goodhart's Law in action? AI tools like to showcase benchmarks in bar graphs to show how well they perform compared to other models. Maybe the benchmark Qs/As snuck into training sets accidentally. Is it still Goodhart's Law if it's unintentional? Daniel Lemire has blogged about being impressed with how well the LLM answers his CS problem questions. I was impressed too. Not sure where the line of competence lies. reply yk 5 hours agoprevI test llms actually similar. For example there is a well known logic puzzle were a farmer tries to cross a river with a cabbage a goat and a wolf. Llms can solve that since at least GPT-2, however if we replace the wolf with a cow, gpt-o does correctly infer the rules of the puzzle but can't solve it. reply getoffmyyawn 5 hours agoparentI've found that the River Crossing puzzle is a great way to show how LLMs break down. For example, I tested Gemini with several versions of the puzzle that are easy to solve because they don't have the restrictions such as the farmer's boat only being able to carry one passenger/item at a time. Ask this version, \"A farmer has a spouse, chicken, cabbage, and baby with them. The farmer needs to get them all across the river in their boat. What is the best way to do it?\" In my tests the LLMs nearly always assume that the boat has a carry-restriction and they come up with wild solutions involving multiple trips. reply SonOfLilit 4 hours agoparentprevI've been using this as my first question to any new LLM I try and I'm quite sure nothing before GPT-4 even got close to a correct solution. Can you post a prompt that GPT-2 or 3 can solve? reply chasd00 5 hours agoparentprevWhat happens if you sit down and invent a logic game that is brand new and has never been documented before anywhere then ask an LLM to solve it? That, to a layman like me, seems like a good way to measure reasoning in AI. reply jprete 4 hours agorootparentI think the problem is inventing new structures for logic games. The shape of the problem ideally would be different than any existing puzzle, and that's hard. If a person can look at it and say \"oh, that's just the sheep-wolf-cabbage/liar-and-truthteller/etc. problem with extra features\" then it's not an ideal test because it can be pattern-matched. reply layer8 4 hours agorootparentprevThis is being done, but the difficulties are: (1) How do you assess that it is really brand-new and not just a slight variation of an existing one? (2) Once you publish it, it stops being brand-new, so its lifetime is limited and you can’t build a longer-term reproducible test out of it. reply Analemma_ 2 hours agorootparentprevYou can do this, but at that point what are you really benchmarking? If you invent a de novo logic puzzle and give it to 100 people on the street, most of them won't be able to solve it either. If your aim is to prove \"LLMs can't really think like humans can!\", this won't accomplish that. reply voidUpdate 5 hours agoparentprevI'm scared of the cows around you if they eat goats reply andrepd 3 hours agoparentprevMeaning it's just a glorified Google. reply romwell 2 hours agorootparent...that makes up results when it can't find any reply singularity2001 4 hours agoprevIf the argument is that LLMs are bad at reasoning because they are easily distractible and the results vary with modifications in the question, one should be reminded of the consistency and distractability of humans. reply zeroonetwothree 3 hours agoparentWhy? LLMs are supposedly better than humans (as many comments claim in this thread). reply riku_iki 2 hours agoparentprevTrained human can tell if distracted: \"I am distracted and can't figure out answer\", while LLM will confidently gives you wrong answer, which makes whole results not reliable. reply criddell 5 hours agoprevIt would be interesting if this kind of work could ever be extended to show the limitations of mathematical reasoning in animals and humans. For example, just as a dog will never understand a fourier transform, there are likely ideas that humans cannot understand. If we know what our limits are, I wonder if we could build machines that can reason in ways we aren't capable of? reply myrmidon 4 hours agoparentI think it is a naive assumption that such a limitation even exists (\"exists\" in a sense that it is actually useful, by being consistent and somewhat simple to describe). We investigated similar ideas for language (=> Noam Chomsky), where we tried to draw clear, formalized limits for understanding (to show e.g. how human capabilities contrast with animals). The whole approach failed completely and irredeemably (personal opinion), but researching it was far from useless to be fair. reply r2_pilot 4 hours agorootparentAs the human brain is finitely bounded in space and time, any idea that can't be compressed or represented by condensing notation, which is \"larger\" than the 100B cells+100T synapses can represent, or whose integration into said human's brain would take longer than 150 years, would be considered unable to be contemplated by a normal human. reply klabb3 3 hours agorootparentYes but we overcome. We can do absolutely insane things like just large prime number testing, because of reasoning + tool use. Humans invent tools and wield them. Whether it's pen & paper to extend our memory, a horse to become stronger, a calculator to speed up our thinking or an airplane to literally fly, the tools we wield become extensions of our agency and control. A lonely human without knowledge sharing or tools isn’t that much more capable in their lifetime than the smartest animals. When we talk about human ability colloquially, we’re generally talking about what we can do with access to our human heritage, civilization, safety and access to materials and tools. Pattern matching against something others have already done is great but this is shared with at the very least all mammals to some extent. Pushing the boundaries of our species forward over time is a different game. Or at least, it seems to be… It certainly seems like we’ve found the holy grail of pattern matching (system 1 thinking), which is an insane leap! But what about system 2? The million dollar question is what the hell is the topology of that pre-frontal cortex thinking machine? Is it just more pattern matching but against different patterns? Or is it completely and qualitatively different? And if so, is it more or less hard? To me, following the debate is just watching one bad prediction after another, (including my own of course). We just don't know how it works. Not you or me, not Sam Altman in full though-leading leather jacket uniform, or even our top neuro-scientists. reply woopwoop 4 hours agoprevI'm curious about what happens with the no-op dataset if you include in the prompt that the questions may contain irrelevant information. reply dr_dshiv 5 hours agoprevIt seems incredibly easy to generate an enormous amount of synthetic data for math. Is that happening? Does it work? reply ilaksh 4 hours agoparentThey did that for o1 and o1-preview. Which if you read the paper or do your own testing with that SOTA model you will see that the paper is nonsense. With the best models the problems they point out are mostly marginal like one or two percentage points when changing numbers etc. They are taking poor performance of undersized models and claiming that proves some fundamental limitation of large models, even though their own tests show that isn't true. reply foobarqux 4 hours agorootparentYou choose to ignore Figure 8 which shows a 18% drop when simply adding an irrelevant detail. In the other test the perturbations aren’t particularly sophisticated and modify the problem according to a template. As the parent comment said this is pretty easy to generate test data for (and for the model to pattern match against) so maybe that is what they did. A better test of “reasoning” would be to isolate the concept/algorithm and generate novel instances that are completely textually different from existing problems to see if the model really isn’t just pattern matching. But we already know the answer to this because it can’t do things like arbitrary length multiplication. reply aithrowawaycomm 2 hours agoparentprevIt's easy enough to generate an enormous amount of formal math problems, but utterly quixotic to generate an enormous amount of quantitative reasoning problems, which is the thing LLMs are lacking. reply MacsHeadroom 5 hours agoparentprevYes, this is how o1 was trained. Math and programming, because they are verifiable. This is also why o1 is not better at English. Math skills transfer to general reasoning but not so much to creative writing. reply bentice 5 hours agoparentprevData is the wrong approach to develop reasoning. You we don't want LLM's to simply memorize 3x3 = 9 we want them to understand that 3 + 3 + 3 = 9 therefore 3x3 = 9 (obviously a trivial example). If they have developed reasoning very few examples should be needed. The way I see it reasoning is actually the ability of the model to design and train smaller models that can learn with very few examples. reply dr_dshiv 1 hour agorootparentMy understanding is that, if you train these enough, it becomes likely to develop efficient compressions— which “reasoning” would be. reply hackinthebochs 4 hours agorootparentprev> If they have developed reasoning very few examples should be needed. Yes, once the modules for reasoning have converged, it will take very few examples for it to update to new types of reasoning. But to develop those modules from scratch requires large amounts of examples that overtax its ability to memorize. We see this pattern in the \"grokking\" papers. Memorization happens first, then \"grokking\" (god I hate that word). It's not like humans bootstrap reasoning out of nothing. We have a billion years of evolution that encoded the right inductive biases in our developmental pathways to quickly converge on the structures for reasoning. Training an LLM from scratch is like recapitulating the entire history of evolution in a few months. reply Davidzheng 5 hours agoparentprevIn which distribution? Like school math or competition or unsolved problems? FWIW I think one and three and probably easier to generated as synethetically. It's harder to bound the difficulty but I think the recent David silver talk implies it doesn't matter much. Anyway there's some work on this you can find online--they claim to improve gsm8k and MATH a bit but not saturate it. Idk in practice how useful it is reply ninetyninenine 5 hours agoparentprevI don’t think so. The data is biased towards being very general. reply dev1ycan 5 hours agoprevI don't understand the idiocracy we live in, it is beyond obvious not just that the stock market is a bubble but ESPECIALLY the AI related stocks are a massive bubble, when it pops, and it will, it is going to be very very ugly, yet people keep pouring in, as Sabine said it, it's starting to look like particle physics where they keep asking for bigger colliders, just because you have a bigger collider, if your methodology is flawed you aren't gonna get any more significant returns. Eventually they will run out of exponential cash to pour in, and investors will start asking questions, stocks are already valued at 60x+ their earnings, whenever it pops you don't want to be the one who bought the top. Guess it's still gonna take a while more for the layman to realize the issues with LLMs, but it'll happen. reply Workaccount2 4 hours agoparent>if your methodology is flawed you aren't gonna get any more significant returns. The problem with this statement is that predictions made about scaling 5 years ago have held true[1]. We keep adding parameters, adding compute, and the models keep getting more capable. The flaws of LLM's from 2024 are not what is relevant. Just like the flaws of LLMs from 2021 were not relevant. What is relevant is the rate of change, and the lack of evidence that things won't continue on this steep incline. Especially if you consider that GPT4 was sort of a preview model that motivated big money to make ungodly investments to see how far we can push this. Those models will start to show up over the next 2 years. If they break the trend and the scaling flops, then I think a lot of air is gonna blow out of the bubble. [1]https://arxiv.org/pdf/2001.08361 reply vrighter 4 hours agorootparentwe added a lot of parameters. We added a LOT of data. The resulting models have become only slightly better. And they still have all of their old problems. I think this is proof that scaling doesn't work. It's not like we just doubled the sizes, they increased by a lot, but improvements are less and less each time. And they've already run out of useful data. reply dev1ycan 4 hours agorootparentprevThey are very literally asking for trillions and even nuclear powered data centers, pretty sure we've gotten to the point where it's not sustainable. reply Workaccount2 4 hours agorootparentThose are roadmap items being asked for, but the next gen models are already in training. If they keep moving along the same trend line, like all the previous models have, then they probably will be able to find the investors for the next next gen. Even if it's a few trillion dollars and a few nuclear power plants. This doesn't even factor in the tech inertia. We could stop making new models today, and it would probably be 4-5 years before integration slowed down. Google still hasn't even put Gemini in their home speakers. reply empath75 3 hours agoparentprevComputers have been able to do mathematical calculation and logical deduction cheaply and perfectly for decades, and it's not really required for generative AIs to be able to do it for them to be useful. It's good enough if they can write and execute some python code to do it, and generally they are fairly capable of that. The question of whether they can do it is interesting in an academic sense, but has nothing to do if they're useful or not. They also don't need to be true AGI to be useful. reply beardyw 5 hours agoprevI honestly can't see why LLMs should be good at this sort of thing. I am convinced you need a completely different approach. At the very least you mostly only want one completely correct result. Good luck getting current models to do that. reply hackinthebochs 4 hours agoparentLLMs aren't totally out of scope of mathematical reasoning. LLMs roughly do two things, move data around, and recognize patterns. Reasoning leans heavily on moving data around according to context-sensitive rules. This is well within the scope of LLMs. The problem is that general problem solving requires potentially arbitrary amounts of moving data, but current LLM architectures have a fixed amount of translation/rewrite steps they can perform before they must produce output. This means most complex reasoning problems are out of bounds for LLMs so they learn to lean heavily on pattern matching. But this isn't an intrinsic limitation to LLMs as a class of computing device, just the limits of current architectures. reply qudat 3 hours agoparentprevOne core issue is that we need to convert spoken/written languages (e.g. english) into more formal math languages since sometimes the underlying mathematical problem is written using prose. The example in the paper: > When Sophie watches her nephew, she gets out a variety of toys for him. The bag of building blocks has 31 blocks in it. The bin of stuffed animals has 8 stuffed animals inside. The tower of stacking rings has 9 multicolored rings on it. Sophie recently bought a tube of bouncy balls, bringing her total number of toys for her nephew up to 62. How many bouncy balls came in the tube? So I would argue it's critical that LLMs knows how to convert text to math and then perform those math calculations. This extends beyond just math but also the underlying logics. We just need to figure out how to inform the LLM to read, write, and understand formal languages. My guess is attention heads could probably work in this context, but we might want something that is a little more rigid, naturally extending from the rigidity of logic and formal languages. Conversely, we might not have figured out how to properly train LLMs on formal languages and have them preserve the underlying logic and axioms necessary to correctly perform math calculations. reply s-macke 3 hours agoparentprevWell, my perspective on this is as follows: The recurrent or transformer models are Turing complete, or at least close to being Turing complete (apologies, I’m not sure of the precise terminology here). As a result, they can at least simulate a brain and are capable of exhibiting human-like intelligence. The \"program\" is the trained dataset, and we have seen significant improvements in smaller models simply by enhancing the dataset. We still don’t know what the optimal \"program\" looks like or what level of scaling is truly necessary. But in theory, achieving the goal of AGI with LLMs is possible. reply golol 5 hours agoparentprevI'm a math phd student at the moment and I regularly use o1 to try some quick calculations I don't feel like doing. While I feel like GPT-4o is so distilled that it just tries to know the answer from memory, o1 actually works with what you gave it and tries to calculate. It's can be quite useful. reply banditelol 4 hours agorootparentI'm curious what kind of quick calculation do you usually use llm for? Edited for clarity reply golol 4 hours agorootparentJust earlier today I wanted to check if exp(inx) is an orthonormal basis on L^2((0, 1)) or if it needs normalization. This is an extremely trivial one though. Less trivially I had an issue where a paper claimed that a certain white noise, a random series which diverges in a certain Hilbert space, is actually convergent in some L^infinity type space. I had tried to use a Sobolev embedding but that was too crude so it didn't work. o1 correctly realized that you have to use the decay of the L^infinity norm of the eigenbasis, a technique which I had used before but just didn't think of in the moment. It also gave me the eigenbasis and checked that everything works (again, standard but takes a while to find in YOUR setting). I wasn't sure about the normalization so again I asked it to calculate the integral. This kind of adaptation to your specific setting instead of just spitting out memorized answers in commonn settings is what makes o1 useful for me. Now again, it is often wrong, but if I am completely clueless I like to watch it attempt things and I can get inspiration from that. That's much more useful than seeing a confident wrong answer like 4o would give it. reply apsec112 5 hours agoprev [–] () reply ilaksh 4 hours agoparent [–] That makes the whole conclusion obviously false. I don't really understand why, but I think we are going to see total denial from a significant percentage of the population all the way up to and past the point where many average mathematicians and software engineers cannot in any way compete with AI. We already are reportedly getting pretty close with o1 (not o1-preview). There are also new paradigms for machine learning and hardware in the pipeline that will continue to provide orders of magnitude performance gains and new capabilities in the next 5-10 years. Many people still claim that \"self driving cars don't exist\", in so many words, even though they are deployed in multiple cities. reply sottol 1 hour agorootparent [–] > Many people still claim that \"self driving cars don't exist\", in so many words, even though they are deployed in multiple cities. But just look at the predictions of that time - cities will change, ... and so on. Sure, we have self-driving cars but the reality looks very different (and a lot more like the past!) than the pundits and futurists imagined! I'm not sure anyone will make their billions of dollars investmented back within even 20 years. Just two random examples from ~10 years ago (2013-2016), you can google many more of that time. * \"Ford Targets Fully Autonomous Vehicle for Ride Sharing in 2021; Invests in New Tech Companies, Doubles Silicon Valley Team\" [1] * \"Disruptions: How Driverless Cars Could Reshape Cities\" [2] [1] https://media.ford.com/content/fordmedia/fna/us/en/news/2016... [2] https://archive.nytimes.com/bits.blogs.nytimes.com/2013/07/0... [3] https://www.gensler.com/dialogue/30/the-game-changer-for-cit... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper \"GSM-Symbolic\" by Iman Mirzadeh et al. investigates the mathematical reasoning capabilities of Large Language Models (LLMs) using the GSM8K benchmark.- The authors introduce GSM-Symbolic, a new benchmark with symbolic templates, showing that LLMs struggle with variations in numerical values and additional clauses in questions.- The study suggests that LLMs may replicate reasoning from training data rather than performing genuine logical reasoning, highlighting their limitations in mathematical reasoning."
    ],
    "commentSummary": [
      "Large Language Models (LLMs) face challenges in mathematical reasoning, particularly when problems include irrelevant information, which affects their performance.- This limitation underscores LLMs' reliance on pattern recognition over logical reasoning, making them less effective in real-world scenarios with extraneous details.- Despite advancements, LLMs still struggle to distinguish important information from noise, a critical skill needed for practical applications."
    ],
    "points": 98,
    "commentCount": 118,
    "retryCount": 0,
    "time": 1728647706
  },
  {
    "id": 41804829,
    "title": "ARIA: An Open Multimodal Native Mixture-of-Experts Model",
    "originLink": "https://arxiv.org/abs/2410.05993",
    "originBody": "Computer Science > Computer Vision and Pattern Recognition arXiv:2410.05993 (cs) [Submitted on 8 Oct 2024] Title:Aria: An Open Multimodal Native Mixture-of-Experts Model Authors:Dongxu Li, Yudong Liu, Haoning Wu, Yue Wang, Zhiqi Shen, Bowen Qu, Xinyao Niu, Guoyin Wang, Bei Chen, Junnan Li View PDF HTML (experimental) Abstract:Information comes in diverse modalities. Multimodal native AI models are essential to integrate real-world information and deliver comprehensive understanding. While proprietary multimodal native models exist, their lack of openness imposes obstacles for adoptions, let alone adaptations. To fill this gap, we introduce Aria, an open multimodal native model with best-in-class performance across a wide range of multimodal, language, and coding tasks. Aria is a mixture-of-expert model with 3.9B and 3.5B activated parameters per visual token and text token, respectively. It outperforms Pixtral-12B and Llama3.2-11B, and is competitive against the best proprietary models on various multimodal tasks. We pre-train Aria from scratch following a 4-stage pipeline, which progressively equips the model with strong capabilities in language understanding, multimodal understanding, long context window, and instruction following. We open-source the model weights along with a codebase that facilitates easy adoptions and adaptations of Aria in real-world applications. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2410.05993 [cs.CV](or arXiv:2410.05993v1 [cs.CV] for this version)https://doi.org/10.48550/arXiv.2410.05993 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Dongxu Li [view email] [v1] Tue, 8 Oct 2024 12:44:57 UTC (20,715 KB) Full-text links: Access Paper: View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.CVnewrecent2024-10 Change to browse by: cs References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=41804829",
    "commentBody": "ARIA: An Open Multimodal Native Mixture-of-Experts Model (arxiv.org)91 points by jinqueeny 18 hours agohidepastfavorite20 comments cantSpellSober 6 hours ago> outperforms Pixtral-12B and Llama3.2-11B Cool, maybe needs of a better name for SEO though. ARIA has meaning in web apps. reply panarchy 2 hours agoparentThey could call it Maria (MoE Aria) won't help with standing out in searches however. Maybe MarAIa so it would be more unique. I'm here all night if anyone else needs some other lazy name suggestions. reply theanonymousone 8 hours agoprevIn an MoE model such as this, are all \"parts\" loaded in Memory at the same time, or at any given time only one part is loaded? For example, does Mixtral-8x7B have the memory requirement of a 7B model, or a 56B model? reply 0tfoaij 4 hours agoparentMoE's still require the total number of parameters (46b, not 56b, there's some overlap) to be in ram/vram, but the benefit is that the inference speed will be based on the amount of active parameters used, which in the case of Mixtral is 2 experts at 7b each for an inference speed comparable to 14b dense models. This 3x improvement in inference speed would be worth the additional ram usage alone, especially for cpu inference where memory bandwidth rather than total memory capacity is the limiting factor, but as a bonus there's a general rule you can use calculate how well MoE's will compare to dense models by taking the square root of the active parameters * total parameters, meaning Mixtral ends up comparing favourably to 25b dense models for example. In the case of ARIA it's going to have the memory usage of a 25b model, with the performance of a 10b~ model while running as fast as a 4b model. This is a nice trade off to make if you can spare the additional ram. If it helps, MoE's aren't just disparate 'expert' models trained to deal with specific domain knowledge jammed into a bigger model, but rather are the same base model trained in similar ways where each model ends up specialising on individual tokens. As the image dartos linked shows, you can end up with some 'experts' in the model that really, really like placing punctuation or language syntax for whatever reason. reply dartos 8 hours agoparentprevCloser to 56. All part are loaded in as any could be called upon to generate the next token. reply theanonymousone 8 hours agorootparentAha, so it's decided per token, not per input. I thought at first the LLM chooses a \"submodel\" based on the input and then follows it to generate the whole output. Thanks a lot. reply dartos 6 hours agorootparentYeah, this image helped solidify that for me. https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_pr... Each different color highlight is a generated by a different expert. You can see that the \"experts\" are more experts of syntax than concepts. Notice how the light blue one almost always generates puncuation and operators. (until later layers when the red one does so) I'm honestly not too sure the mechanism behind which experts gets chosen. I'm sure it's encoded in the weights somehow, but I haven't gone too deep into MoE models. reply MacsHeadroom 5 hours agorootparentI see a whitespace expert, a punctuation expert, and a first word expert. It's interesting to see how the experts specialize. reply dartos 1 hour agorootparentRight? Then you get some strange ones where parts of whole words are generated by different experts. Makes me think that there’s room for improvement in the expert selection machinery, but I don’t know enough about it to speculate. reply niutech 10 hours agoprevI’m curious how it compares with recently announced Molmo: https://molmo.org/ reply espadrine 2 hours agoparentThe Pixtral report[0] compares positively to Molmo. (Also, beware, molmo.org is an AI-generated website to absorb through SEO Allen AI’s efforts; the real website is molmo.allenai.org. Note for instance that all tweets listed here are from fake accounts since suspended: https://molmo.org/#how-to-use) [0]: https://arxiv.org/pdf/2410.07073 reply bsenftner 9 hours agoparentprevKnow of where Molmo is being discussed? Looks interesting. reply petemir 9 hours agoprevModel should be available for testing here [0], although I tried to upload a video and got an error in Chinese, and whenever I write something it says that the API key is invalid or missing. [0] https://rhymes.ai/ reply vessenes 15 hours agoprevThis looks worth a try. Great test results, very good example output. No way to know if it’s cherry picked / overtuned without giving it a spin, but it will go on my list. Should fit on an M2 Max at full precision. reply SubiculumCode 14 hours agoparentHow do you figure out the required memory? The MoE aspect complicates it. reply vessenes 11 hours agorootparentIt does; in this case, though, a 25b f16 model will fit. The paper mentions an A100 80G is sufficient but a 40 is not; M2 Max has up to 192G. That said, MoEs are popular in lower memory devices because you can swap out the experts layers -- their expert layers are like 3-4b parameters, so if you are willing to have a sort of pause on generation where you load up the desired expert, you could do it in a lot less RAM. They pitch the main benefit here as faster generation, it's a lot less matmul to do per token generated. reply ProofHouse 11 hours agorootparentprevEach model added, no? reply Onavo 15 hours agoparentprevWhat's the size of your M2 Max memory? reply treefry 13 hours agorootparentLooks like 64GB or more reply SomewhatLikely 11 hours agoprev [–] \"Here, we provide a quantifiable definition: A multimodal native model refers to a single model with strong understanding capabilities across multiple input modalities (e.g. text, code, image, video), that matches or exceeds the modality specialized models of similar capacities.\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Aria is an open multimodal native AI model that integrates diverse real-world information for a comprehensive understanding, surpassing models like Pixtral-12B and Llama3.2-11B in performance.- It is a mixture-of-expert model with 3.9 billion and 3.5 billion activated parameters per visual and text token, respectively, enhancing its language and multimodal capabilities.- The model's weights and codebase are open-sourced, facilitating easy adoption and adaptation by developers and researchers."
    ],
    "commentSummary": [
      "ARIA is a new multimodal native Mixture-of-Experts (MoE) model that surpasses Pixtral-12B and Llama3.2-11B in performance and inference speed by efficiently utilizing active parameters.- Despite having memory usage similar to a 25B model, ARIA performs like a 10B model and operates as quickly as a 4B model, making it suitable for devices with adequate memory, such as an M2 Max.- The model's experts focus on syntax, with room for improvement in expert selection, and it is currently available for testing, although some users have encountered platform issues."
    ],
    "points": 91,
    "commentCount": 20,
    "retryCount": 0,
    "time": 1728605092
  }
]
