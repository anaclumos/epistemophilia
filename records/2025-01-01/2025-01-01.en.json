[
  {
    "id": 42562750,
    "title": "Happy New Year 2025",
    "originLink": "https://news.ycombinator.com/item?id=42562750",
    "originBody": "Hey HN, this site always drags me back to visit it everyday. So for that Happy New year !",
    "commentLink": "https://news.ycombinator.com/item?id=42562750",
    "commentBody": "Happy New Year 20251117 points by martynvandijke 22 hours agohidepastfavorite244 comments Hey HN, this site always drags me back to visit it everyday. So for that Happy New year ! abixb 19 hours agoUS Central Time here, so still a couple hours to go, but HAPPY NEW YEAR to y'all fellow HN-ers -- HN is probably the least guilt-ridden procrastination I do on the whole wide internet. Thank you to every one of you who has made HN among the most intellectually dense places on the web -- I wouldn't be where I'm today without reading all the insightful comments, submitted links and perspectives of all the HN-ers over the last 7 years. My wish for the new year: hopefully, AI singularity is still a few years away and doesn't happen in 2025! reply gabigrin 12 hours agoparentAmen! reply moffkalast 11 hours agoparentprevIndeed, happy new year to all the intellectually dense people on HN! ;P reply andrepd 9 hours agoparentprev\"Dense\" is a curious choice of words, but I agree, it often applies! reply Cumpiler69 12 hours agoparentprevMy wish for the new year is to have a body so jacked and ripped that when I commit a crime the media posts my shirtless pictures everywhere and everyone goes \"wow\". reply Donald 17 hours agoprev45^2 = 2025 Happy perfect square year, everyone. The previous one was 1936 and the next one will be 2116. reply umeshunni 15 hours agoparent2025: 1) is a square: 45² 2) is the product of two squares: 9² x 5² 3) is the sum of 3-squares: 40²+ 20²+5² 4) is the sum of cubes of all the single digits: 1³+2³+3³+4³+5³+6³+7³+8³+9³ reply _kb 14 hours agorootparent5) sum of the single digits squared: (1+2+3+4+5+6+7+8+9)² reply umeshunni 14 hours agorootparentSome more (thanks to chatgpt-o1) 6) sum of the first 45 odd numbers: 1+3+5+...+89 7) is a Harshad number: https://en.m.wikipedia.org/wiki/Harshad_number reply globnomulous 13 hours agorootparent6 is kind of cheating. It's a restatement of 45^2. 3^2 is the sum of the first three odd numbers. 4^2 is the sum of the first four odd numbers. 5^2 is the sum of the first five odd numbers. Edit: sorry, don't mean to be a pill. reply fifilura 12 hours agorootparentI don't consider it cheating, I bet most of these rules have an internal relation. reply roenxi 11 hours agorootparentThey do indeed have an internal relation - they all add up to 2025. Obviously all the formula will be equivalent to each other. They are, by construction, all restatements of each other. reply mr_toad 9 hours agorootparentI guess that means that every number is equivalent to a formula? Is there some sort of metric of how many formula produce the same number? reply layer8 7 hours agorootparentYou’d have to at least exclude subtraction and division (and zero) to not have infinitely many formulas for every number. reply kdmccormick 5 hours agorootparentprevI would say that a rule is \"cheating\" iff it is implied by another rule for any arbitrary N. reply bonzini 12 hours agorootparentprev4 and 5 too reply xerox13ster 12 hours agorootparentprev89 isn't 9^2, 81 is. reply mkl 8 hours agorootparentHuh? 89 is the 45th odd number. reply nhatcher 10 hours agorootparentprev(just reading wikipedia here, I didn't know about Harshad numbers) There is no such thing as a Harshad number, there is a _Harshad number in a given base_. All integers between zero and n are n-harshad numbers. Which is a pity, because apparenty it means the `joy-giver`. I think human kind could use a joy giver year reply bratwurst3000 11 hours agorootparentprev8) the sum of 2024 + 1 also reply keepamovin 8 hours agorootparentprevOh I like these two. reply lxgr 16 hours agoparentprevAlso, (20 + 25)^2 = 2,025! Happy New Year :) reply Bootvis 9 hours agorootparentPython: [x**2 for x in range(32,100) if x**2 // 100 + x**2 % 100 == x] [2025, 3025, 9801] reply User23 15 hours agorootparentprevThis decomposition is especially fun! reply devsda 16 hours agoparentprevGreat to know that someone else too keeps track of squares. At the ages of perfect squares is when we all cross or achieve significant milestones in our lives as children, students, (young)adults, spouses, parents, grandparents, senior citizens of society and so on. This year being a perfect square, I wish that it will be as much or more special as it was for everyone at those ages. reply gylterud 12 hours agorootparentMy youngest is fascinated by squares at the moment. Luckily for him, he is 4 years old, his older brother is 9, while I just turned 36. He will be delighted when I tell him that we are entering 45 squared! reply whycome 19 minutes agorootparentAlso, if you add your ages together… 7^2 If you multiply your ages… 36^2 reply jthemenace 17 hours agoparentprevThis is the most Hacker News comment I’ve seen today. Well played. reply edoceo 17 hours agorootparentUp there with Putnam and Dropbox. reply chrisvalleybay 15 hours agorootparentThank you for the Putnam; I did not know about it. For anyone else that did not understand this reference; https://news.ycombinator.com/item?id=35015. Legendary. reply fxtentacle 9 hours agorootparentThat's an epic thread. Thank you very much for sharing it :) And now, looking back 17 years later, I'd say he succeeded. It's the tarsnap founder. reply LPisGood 15 hours agorootparentprevPutnam? Of math competition fame? reply edoceo 4 hours agorootparentYep, specifically this comment: https://news.ycombinator.com/item?id=35083 reply raverbashing 11 hours agorootparentprevAnd \"Less space than a Nomad\" reply abixb 17 hours agoparentprevTotally nothing bad happened in the decade following the last perfect square year in 1936. :') reply anon_cow1111 17 hours agorootparentWell things have already been a tad rough around this square, so if we follow the trend, the next square might turn bad even sooner. So maybe around, I dunno, 2101? reply frereubu 11 hours agorootparentprevUnless something equivalent happened in 1849, 1764, 1691... I think we're OK :) reply jostylr 9 hours agorootparent1225: ten years earlier, Magna Carta starting to limit monarchs and the seed of individual freedom 1681: eight years later was glorious revolution with a bill of rights, marking individual freedoms 1764: ten years later, beginning of American Revolution and being free of monarchs 1849: ten years-ish later, start of US civil war; was the time of an attempt by the British to end slavery around the world 1936: ten years later, colonial empires were being dismantled, UN established to attempt global cooperation, US in the ascendancy with a seed of ties being established more by economics than military force, great economic upswing lifting people out of poverty (60% in poverty then, 10% now) while the global population blossoms 2035: Majority of the global population in middle class or better, triumph of individuals over technocrats, bureaucrats, and corporatists :) reply keepamovin 8 hours agorootparentI love this! Haha, I was hoping someone would do that. :) reply eddyg 5 hours agoparentprevAnd (20+25)^(20/(2*5)) as well. reply keepamovin 17 hours agoparentprev2025 = 515 (palindromic in base 20) reply jostylr 9 hours agoparentprevUS President number 45 returns, kind of seems like squaring applies. reply throw0101f 7 hours agoparentprev* https://www.numbersaplenty.com/2025 reply jll29 12 hours agoparentprevDonald = Donald E. Knuth? ;-) reply joseangel_sc 13 hours agoparentprevhere’s to all be alive and well floating in amniotic liquid living in VR paradise reply waldrews 15 hours agoprevHappy new year to readers who are fellow humans, to any bots who, unbeknownst to us, can already experience happiness, and I guess if any gorilla, parrot, elephant, or dolphin is having this message communicated to them, happy new year to you too. Let's hope all our respective species keep existing. reply xerox13ster 12 hours agoparentI told my crow friends happy new year and I'm reasonably certain they know today is special even if they don't get why. [0][1] (this is just one and I offered peanuts first but it stared me down and did not budge until I put out beef) [0]: https://media.discordapp.net/attachments/433008121234063360/... [1]: https://cdn.discordapp.com/attachments/434337586182619136/13... reply moffkalast 9 hours agorootparenthttps://media.tenor.com/89nJBdQJ8FkAAAAe/crow-approve.png reply bwag 21 hours agoprevSame. I've been a lurker since 2008. Been hitting this site practically every day since. I've learned so much in the process. Thanks for everything hn, happy new year! reply FlyingSnake 13 hours agoparentDitto! I’m a long time lurker (under old defunct alts) and occasional poster but I’ve opened HN almost every day since I discovered the site in 2008. This community has an outsized impact on my career and life and I’m eternally grateful for it. Thank you! Happy new year and eine Guten Rutsch ins neue Jahr. reply papichulo4 18 hours agoparentprevAah. Same class I see :) Hope everything has gone well for you since. Happy new year! reply lukan 12 hours agoprevHappy new year as well, even though it already started for me on the 21. of December on Solstice, when the days were starting to get longer. That is a real turning point in the natural cycle and I like to follow natural cycles where possible. 1.1. is just arbitary numbers changing to me, but for the majority it means something, which also makes it real and I can appreciate the intent and celebrate anyway.. (And I did had an awesome drug and alcohol free party with self made music and wild dancing) reply parski 12 hours agoparentI live near the arctic circle so the bit of sunshine we gain every day makes a real difference. I'm also in complete denial on June 21st, absolutely refusing to acknowledge that the days get shorter. reply whycome 16 minutes agoparentprevHow can I be where you are reply grumpy-de-sre 12 hours agoparentprevDefinitely a fan of non-religious winter solstice celebrations (good occasion to combine elements of Christmas and new years). My wife is Chinese and loves dumplings so we pretty much celebrate Dongzhi. Always goes down well with our western friends. reply treebeard901 6 hours agoprevAbout 64 million people die every year, congrats on not being one of the 150,000 that die every day. May your luck extend for another 64 million. reply mettamage 15 hours agoprevMartyn, same, happy new year to everyone. This year will be the year that I've been visiting this site almost daily for 10 years. Wow. I can remember the days that I just came for the science and not the technical stuff because I found it too hard. Then quickly later using the technical articles to accelerate my computer science studies and now it just feels like I can dive into anything. Love this placeHappy New Year! Buon anno a tutti! reply nielsbot 14 hours agoparentDon’t forget to enable those anti-procrastination settings in 2025! :-P reply gbarletta 1 hour agorootparentHa! I’m working on it :> reply alienself 15 hours agoprev* Happy New Year, Hacker News! * As the clock ticks into a brand-new year, let’s toast to the innovators, the builders, the thinkers, and the dreamers who make this community so vibrant. Here's to: - Writing elegant code and tackling tough bugs. - Exploring new frontiers in tech and beyond. - Learning, sharing, and leveling up together. May this year bring you breakthroughs, discoveries, and joy in every pull request and project. Keep building. Keep dreaming. Happy New Year, HN! reply husamia 6 hours agoprevHappy New Year, fellow Hacker News community members! As we embark on this new chapter, I'm filled with a sense of optimism and excitement for the possibilities that lie ahead. This community has been a constant source of inspiration, knowledge, and camaraderie over the years, and I'm grateful to be a part of it. In 2025, I hope we can continue to push the boundaries of innovation, tackle complex challenges, and learn from one another. Whether it's through elegant code, groundbreaking research, or thought-provoking discussions, I believe this community has the power to make a lasting impact on the world. As we reflect on the past and look towards the future, let's remember the values that have made Hacker News so special - a relentless pursuit of truth, a commitment to intellectual honesty, and a genuine desire to uplift and support one another. These qualities have been the bedrock of this community, and I'm confident they will continue to guide us in the years to come. Here's to a new year filled with breakthroughs, discoveries, and the joy of creating. May 2025 bring us closer together, sharpen our minds, and inspire us to reach new heights. Happy New Year, Hacker News! reply bartekpacia 5 hours agoparentHah, I knew at the beginning of the second sentence that it’s AI-generated. reply charles_f 14 hours agoprevI'm grateful for this community. It's good having a place where some reason prevail. I wish everyone here had a good one and has a good one. Merry 2025! reply beng-nl 10 hours agoparentWell said. This is the only quality discussion forum I’ve ever seen on the internet; in fact given the common trend of other forums I’d given up on it being possible. Then I learned the magic formula: the hard work of smart and active and moderation with empathy. Thank you dang. And thank you to everyone else for being generous and smart contributors. reply Bluestein 10 hours agorootparentI wanted to humbly second everything said. Honored to be here, and contribute whenever. - 2025 is going to be an interesting year - and I wish for y'all the best. - reply omnee 1 hour agoprevHN has, within a few years, become one of my primary sources of information for all things related to technology and many other intellectual topics. Not least because of the many knowledgable commentators. Happy (20+25)² to all! reply FranchuFranchu 16 hours agoprevHappy new 2025 = (20 + 25)^2 = (2 + 0!)^2*5 = (1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9)^2 = 1^3 + 2^3 + 3^3 + 4^3 + 5^3 + 6^3 + 7^3 + 8^3 + 9^3 reply cobbaut 8 hours agoparent> = (2 + 0!)^2*5 How? 0! = 1 so how does 3^2*5 become 2025? reply mkl 8 hours agorootparentIt doesn't, you need to square the whole thing. reply kappuchino 7 hours agoparentprev(2 + 0!)^25 is only 45 on my account, should be ((2 + 0!)^25)^2 :-/ reply _-_-__-_-_- 17 hours agoprevI created an account in 2022, but had been a regular reader much earlier. From Slashdot in 2002 to Digg in 2004 to Reddit in 2010 and now HN. Happy New Year (+30). Here's to a personally productive 2025! reply mindcrime 13 hours agoparentI wish you a year covered in hot grits in Soviet Russia, being spied on by old people via email. reply jll29 12 hours agoprevHappy New Year! Besides family breakfast, brushing teeth/shower, opening HN makes a good morning better, and an okay start into what will hopefully be a great year. Here's wishing everyone out there: 1. happiness, 2. purpose, 3. love, 4. health, 5. peace, 6. good flow, 7. clean code ;-). Happy Hacking! reply domador 1 hour agoprevHappy 2025! Only 13 more years now 'til 2038! Maybe we can still fix that problem! But feel free to take today off, hackers. reply benatkin 19 hours agoprevThe days are getting longer in the northern hemisphere and shorter in the southern hemisphere. And the start of the ISO 8601 dates is changing! I also monitor the changes of the hexadecimal unix timestamps. The next time the first of 8 hex digits changes is in 2029. from datetime import datetime '{:02X}'.format(int(datetime.now().timestamp())) datetime.fromtimestamp(0x70000000) And this spits out the year in Python: 3**2**2*5**2 reply _kb 19 hours agoparentEven better, all of these are also 2025: (20+25)² (∑n)² and ∑n³ for n 1..9 reply benatkin 19 hours agorootparentNice. A unique year indeed, since the last one was 1936, 89 years ago. It's obvious to me now - that's 2025-(45*2-1) and I can picture a row and a column at the edges of a grid being removed, wth one cell being shared between the row and column. I think maybe at some point I saw that. 1600 and 2500 are more obvious, and 2050 is the midpoint between them linearly. The others in Python: sum(range(1, 10))**2 sum(n**3 for n in range(1, 10)) reply bryant 20 hours agoprevGiven all the division and change across the rest of the web (and by extension the world), glad to have a place where I can learn, share, grow, and maintain an open mind. Happy new year :) reply sebnun 7 hours agoparentSame, happy new year. reply sangeeth96 15 hours agoprevHappy new year to all the HN members! Thankful for this site's existence and for all the knowledge and wisdom I gained over the years just by being here almost every single day. reply hackernj 1 hour agoprevHappy 10 + 9 - 8 + 7! / 6 / 5 * 4 * 3 - 2 * 1! reply Phoenix453 18 hours agoprevAlthough this is just the usual digits incrementing periodically, take the opportunity to look back, reflect and hope for a brighter future for you, your friends, family and rest of the world. reply yard2010 15 hours agoparentIt might be just digits but it stands for a far more complex idea - time! Just because people like discrete things and discrete things never capture the nature of our continuous universe doesn't mean it's less special! reply moondistance 19 hours agoprevHappy New Year! I know so few of you but feel like you’re my best friends. Love to all. reply jasoneckert 18 hours agoprevHappy Year++ I'm thankful that this site exists to allow me to catch up on the news, events, and perspectives that I'm most interested in. And I'm even more thankful that it uses a simple, functional layout. Keep rockin' into 2025, HN! reply adzm 16 hours agoparent> Happy Year++ You mean Happy ++Year of course ;) reply smrt 19 hours agoprevHappy new year / Andariki nootana samvatsara subhakanshalu! reply plastic_bag 17 hours agoparentIt would've been better if you had written that in the original script. So, I'll do that for you ;) అందరికీ నూతన సంవత్సర శుభాకాంక్షలు! reply devsda 17 hours agorootparentIf we are going down this road, let's go all in and be specific :) its అందరికీ ఆంగ్ల నూతన సంవత్సర శుభాకాంక్షలు! I'll consider the previous one as advanced wishes for 30'mar 25 ;) reply reedBu 16 hours agoprevHappy new year from a Shenzhen China Mainland! reply shayansm1 15 hours agoprevHappy New Year, everyone! I’m incredibly grateful for this amazing community. Your informative posts and insightful comments have taught me so much, and I truly appreciate all of you. Here's to another year of learning and growth together! reply openrisk 10 hours agoprevMeaningful communication between real people, a interesting mix of experts and learners. This should be so much easier with all the fancy digital tools we have now available. Yet HN is nowhere near the norm but rather a rare exception. Lets hope its a pattern that spreads more broadly in 2025. We are already getting past the first quarter into the 21st century after all. reply chistev 22 hours agoprevYea, I discovered this site late last year (2024) around October, and it's now a site I visit everyday. At least 4 times a day. reply mohu21 17 hours agoprevFor me, HN is the social platform/media I can enjoy for breakfast or breaks. Allways somethibg interesting to read without the temptation of infinite scrolling. I am grateful for that and for the cool articles y‘all write. Happy NY! reply hugs 17 hours agoprevHappy 0x37 SE! Hex 37 (int 55) years Since Epoch (Jan 1 1970) reply attentionmech 10 hours agoprevI don't know you all but know that I love to read your thoughts on HN. I open it like 20 times a day. I enjoy that I am here with all of you to witness our existence together. and that includes AI bots. You are also part of our shared world now. I hope we will be kind to each other as far as it matters. reply b8 18 hours agoprevHappy New Years from Louisiana! A few hours to go still here. I'm glad that Hanukkah and xmas happened on the same day this year. Hoping for better health, and a new job in 2025. I met a new woman, and I hope that pans out. reply selimthegrim 41 minutes agoparentJust read this, bittersweet now but thank you for posting this as I read it from New Orleans. reply the_arun 19 hours agoprevHN is our backyard for learning & understanding new perspectives. To all - ಹೊಸ ವರ್ಷದ ಶುಭಾಶಯಗಳು!! reply vikasvm 19 hours agoparentಎಲ್ಲರಿಗೂ ಹೊಸ ವರ್ಷದ ಶುಭಾಶಯಗಳು reply cull 19 hours agoprevHappy New Year. I hope 2025 brings the best to you and yours! reply gauden 17 hours agoprevHappy New Year from Malta! Thanks for all you have taught me over the years. reply enc0d3r 10 hours agoprevHey HN, Im recently create my account in this forum, and I just really want to enjoy new friends, with the same objectivies than me. Im just really enjoy algoritms, I have five years of experiencie, but my anxiety and my burnouts doenst allow me to level up, but now I believe I have all necessary to just be pacient. To 2025 Happy New Year, to us, ping me, Im be happy if I get new friends. BTW: My english is horrible, Im from Brazil with accent of Indian guy mix with a lot of sheet. reply thehappyfellow 13 hours agoprevHappy New Year everyone! I hope this coming year you’ll find the meaning you’re yearning for, spend it with people who deeply care for you, love and be loved. That you’ll flourish, feel content and happy. That you’ll experience more good than evil. Learn OCaml in 2025 reply shahzaibmushtaq 11 hours agoprevThank you all who are reading this for a wonderful 2024. I hope 2025 is a year of real changes in terms of progress, peace and less polarized world. For the record, I'll try my best for personal and professional growth. reply Quizzical4230 18 hours agoprevI joined in late 2024, now its my daily! Happy New Year HN! Thanks for teaching me so muchthe best site on the internet You know the internet has porn and discount bulk goods on it right reply TheAceOfHearts 16 hours agoprevMerry 2025! My goals for next year are to write more and try to change the world for the better. Spending the last day of the year without electricity was a huge wakeup call that big changes are needed. It has left me wondering why fusion energy has taken so long to develop, so that's a topic I'm really interested in exploring. reply Bluestein 10 hours agoparentMany new reactor types coming online 2025. Will be an interesting year ... reply euvin 14 hours agoprevDiscovering this site was one of the better things the internet has given me. Happy new year! reply bovermyer 19 hours agoprevHappy New Year, whether you celebrated it in the past or the future. Remember - the new year is not yet written. Amazing and unexpected things are sure to come. reply zakokor 18 hours agoprevFeliz año 2025! Por más años para este sitio! reply fabmilo 15 hours agoprevHappy new year to everyone, hacker news is more than my home page. This community is awesome! reply slyfox125 20 hours agoprevOne of the best sites, period! reply reconnecting 1 hour agoprevHappy 20¼! reply chrisvalleybay 15 hours agoprevHappy New Year from Oslo! I really appreciate this community; it gives me great peace. reply cannibalXxx 15 hours agoprevHappy New Year. May more hacker News users join https://chat-to.dev this year and make it a useful means of communication for all programmers and beyond. reply pauletienney 14 hours agoprevHappy new year to all of you, fellow visitors of Internet best website. reply thr0waway001 2 hours agoprevHappy New Years! reply sudohackthenews 15 hours agoprevHappy new year from Dallas, everyone! I’ve been a lurker on this site for years, truly is a fantastic source of knowledge and the breadth of experience among commenters is insane. Here’s to a great 2025! reply misonic 13 hours agoprevHappy New Year to All. reply financeinnolab 9 hours agoprevHappy New Year to one of the most informative and interesting communities on the interwebs! reply zoom6628 15 hours agoprevHappy new year from a ferry between Zhuhai and home in HongKong. reply BimJeam 10 hours agoprevHappy new year, brothers in code! :-) reply coldfoundry 15 hours agoprevHappy new year all! Thanks everyone for helping to uphold the high quality interactions found on here. To a good 2025! reply tmountain 12 hours agoprevHappy new year from Amsterdam. Thanks to everyone for the good times all these years! reply flaterkk 19 hours agoprevLogged in just to say happy new year, also a lurker :-) reply rishikeshs 15 hours agoprevHappy New Year everyone! പുതുവത്സരാശംസകൾ! reply TechnicolorByte 17 hours agoprevHappy New Years, y’all! Curious to hear if anyone has any specific goals/resolutions/things they’re especially looking forward to in 2025. reply gnuly 17 hours agoparenti prefer a theme[1] over goals. my this year's theme is learning - which i'm starting with learning to cook more novel dishes. [1]: CGP Grey's video on it: https://www.youtube.com/watch?v=NVGuFdX5guE reply 256_ 13 hours agoprev2025 will be the year in which a certain operating system is used on desktop machines. reply coolcoder613 12 hours agoparentYes, 2025 will be the year of the Haiku desktop! reply raegis 13 hours agoparentprevIndeed, I just upgraded to kernel 6.13rc5, and now everything works perfectly! Just in time for New Years! reply koevet 12 hours agoprevHappy new 2025 from Berlin, proud to be a long time HN'er. Peace! reply keepamovin 17 hours agoprevFor many reasons bigger than this place, Happy New Year!!! You deserve a great 2025 - have a good one! reply Wintereise 15 hours agoprevHappy new year from Singapore! reply mihirsahu 16 hours agoprevHappy new year y'all! I've learned so much here and I appreciate you all. reply mihirsahu 16 hours agoprevHappy new year everyone! I've learned so much here and I appreciate you all. reply endorphine 14 hours agoprevHappy new year fellow humans, wishing for more love and a healthy 2025! reply andyjohnson0 21 hours agoprevHappy new year from a rainy Manchester, UK! reply pedroigor91 7 hours agoprevHappy new year everyone! reply soulofmischief 16 hours agoprevHappy New Years, everyone. Let's make this year count for something. reply danwills 15 hours agoprevHappy 2025 all HN'ers! I'm a daily HN'er - It's my only source of news apart from occasional YT vids, but what a brilliant source of news it is!!! I frequently find myself saying: 'Yeah that was on HN a few weeks ago'! It's so up-to-the-minute and really just wholeheartedly good! Dang is a goddamned legend in my opinion I can hardly believe it works so incredibly well and it's surely mostly from dang's good work! Thankyou dang, so much!! I think calendars (especially the gregorian) are fairly approximate things so try not to assign too much meaning to the number ticking-over these days.. sun/moon/earth/nature didn't care that our numbers ticked-over very much did they? But still, in order to be able to talk to others we have to try to store our memories using dates as keys (I'm actually really crap at that, but still!), so HOORAY for the next approximate-date-memory-key-era!! Much love to all teh hackers! You are all awesome! Even the black-hats!! Curiosity FTW!!!! reply georgel 14 hours agoparentBeen here since 2010, worked at multiple YC companies. Shout out to @dang, he has done a great job keeping the community healthy. reply coolcoder613 12 hours agoparentprevMe too! I find myself saying 'that was on HN a while ago' very often, actually. reply Insanity 18 hours agoprevHappy New Year everyone!year + 1) For the \"get off my lawn\" crew: $('#year').text(Number($('#year').text()) + 1) reply bdangubic 19 hours agoparentprevdon’t start the year by mutating state, geeeeeez :) reply User23 15 hours agorootparentIt's not mutating state, it's defining a transition function from one immutable state to another! reply nejsjsjsbsb 11 hours agorootparent[year, setYear] = useState(2024) Get off my lawn means no libraries, just web api. reply pryelluw 18 hours agoparentprevyear = year + 1 reply Sn0wCoder 15 hours agoprevHappy New Year may the next be the best one yet.... reply wafflez 19 hours agoprevCouldn’t agree more. Stay classy HN, have a happy & healthy 2025! reply robblbobbl 11 hours agoprevHow do I delete my account here reply eps 10 hours agoparentEmail the mods - hn@ycombinator.com reply nonrandomstring 10 hours agoprevWish you all a prosperous 2025 filled with kindness and love. reply dorianniemiec 12 hours agoprevHappy new year too, from Poland! reply Aniket-N 14 hours agoprevHappy New Year from the Pacific coast! reply all2 14 hours agoparentHalt new year! May Good bless you richly in your pursuits and may He bless the work of your hands. reply gboss 10 hours agoprevHappy new year everyone! reply jsomedon 18 hours agoprevHappy New Year to all of you my fellow HN readers! reply optymizer 14 hours agoprevHappy New Year to all the hackers! reply ivanmontillam 18 hours agoprevHappy new year 2205 HN community! I love you, my favorite site ever. reply ivanmontillam 18 hours agoparentI typo'd the year, but now I cannot change it as I consider my comments immutable. reply smeej 16 hours agorootparentEven a typoed comment is right once every 180 years. reply TheKnownSecret 16 hours agoprevY'all make me happy. Happy new years! reply saikatsg 16 hours agoprevThanks for everything! Happy new year HN! reply Spooky23 17 hours agoprevHappy New Year all! You’re all wonderful. reply bennathanson 10 hours agoprevHappy new year HN! reply pseudoeu 19 hours agoprevFeliz ano novo! reply grigy 14 hours agoprevIn US PST, Happy New Year! reply glitchc 15 hours agoprevHappy new year to everyone! reply codetrotter 19 hours agoprevHappy New Year / Godt nyttår! reply jamieplex 17 hours agoprevHappy Gnu Ears, Y'all!! reply leptoniscool 20 hours agoprevHappy New Year from the West coast! reply mistersquid 19 hours agoparent> Happy New Year from the West coast! This was around 18:10 PST so the greeting may have introduced a race condition. Happy New Year anyway, logic be darned! reply maxcruer 14 hours agoprevHappy new year 2025! reply tokioyoyo 16 hours agoprevHappy new year, everyone’ reply nurkhz 11 hours agoprevHappy Hacking! reply FrustratedMonky 19 hours agoprevShout out. Crossing fingers for 2025. Reading some Peter Turchin, not looking good. reply irs 17 hours agoprevHappy New Year y’all ! reply nioj 20 hours agoprevHappy New Year from Europe! reply chocks 17 hours agoprevHappy new year folks! reply mrKola 18 hours agoprevHappy new year everyone. reply Gigacore 16 hours agoprevHappy New Year, HN! reply senectus1 20 hours agoprevthis is such old news ;-) (in North Queensland atm, New years was nearly 10 hours ago :-P ) reply Frederation 17 hours agoprevHappy 2025 to all :D reply replwoacause 16 hours agoprevHappy New Year HN! reply Dracophoenix 14 hours agoprevHappy New Year! reply fung 16 hours agoprevHappy new year!!! reply ceinewydd 18 hours agoprevHappy New Year, HN! reply ctenb 11 hours agoprevHN! reply gregjw 15 hours agoprevHappy new year! reply maxcruer 14 hours agoprevloop { year += 1; live_on(); } reply reynaldi 18 hours agoprevHappy New Year HN! reply 3rdworldeng 17 hours agoprevHappy New Year !! reply davidhariri 19 hours agoprevHappy new year, HN! reply kittikitti 16 hours agoprevHappy New Year! reply neom 17 hours agoprevtnx mods! https://www.newyorker.com/news/letter-from-silicon-valley/th... reply vlatoshi 19 hours agoprevHave a HN Year HN! reply glasshead969 17 hours agoprevHappy new year! reply __LINE__ 17 hours agoprevHappy new year reply sandworm101 14 hours agoprevHappy new year to all of you still at work! We are what make holidays possible for everyone else. reply pstuart 15 hours agoprevThanks to all you participants who make this site so valuable. reply ilrwbwrkhv 15 hours agoprevHappy new year everyone. And thanks dang for not banning me. I promise to be better about that topic this year. reply 01HNNWZ0MV43FF 16 hours agoprevReal reply heyitssim 15 hours agoprevhappy new year from Asia! reply wellthisisgreat 17 hours agoprevYou guys are really great. Happy New Year to all of us reply lolu_plan 11 hours agoprevHappy New Year! reply booleandilemma 17 hours agoprevHappy New Year HN! reply deadbabe 18 hours agoprev2025 seems pretty cool so far, you 2024 people will like it. reply ngkw 19 hours agoprevhappy new year from tokyo reply G1N 18 hours agoprevhappy new year HN :) reply amelius 12 hours agoprevIt's almost like an echo chamber now, but Happy New Year HN! :) reply montyanderson 19 hours agoprevhappy new year! reply andrewinardeer 19 hours agoprev [–] What are the chances of an extinction level event occurring in 2025? By now, that's about the only black swan event left to happen. reply keepamovin 17 hours agoparentProbably fairly low because the future is still talking to us so there have to be at least some timelines extending from the present that make it reply zappy42 14 hours agorootparentOther than Demolition Man, what is talking to us? reply keepamovin 8 hours agorootparentHeh, Demolition Man is a great film. I had the fortune to randomly rediscover it before it was recently re-recognized as incredibly prescient. It was a cool experience, made all the better because I was totally surprised by it. I had zero expectations and just thought it was a dumb fun action movie. It was actually great. But as to your real question: well, tune in, man. :) reply nejsjsjsbsb 11 hours agoparentprev [–] 167725-1 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [],
    "points": 1117,
    "commentCount": 244,
    "retryCount": 0,
    "time": 1735688916
  },
  {
    "id": 42566112,
    "title": "DOOM CAPTCHA",
    "originLink": "https://doom-captcha.vercel.app/",
    "originBody": "built with v0 & vercel / how it works / @rauchg Debug Play DOOM® and kill at least 3 monsters Downloading ... Tap to play 0/3",
    "commentLink": "https://news.ycombinator.com/item?id=42566112",
    "commentBody": "DOOM CAPTCHA (doom-captcha.vercel.app)611 points by denysvitali 8 hours agohidepastfavorite151 comments anandsuresh 1 hour ago+100 for technical chops, -100 for usability. +10 for the trip down memory lane, and the self-realization that I now suck at playing video games. reply smitelli 8 minutes agoparentThis is the secret level (E1M9) that you'd normally encounter after E1M3. By this point in the regular progression you'd have found a shotgun, chaingun, rocket launcher, and probably some armor. Starting this level with just a pistol (and it looks like maybe U-V or Nightmare difficulty) is just begging for a buttwhipping. reply sznio 26 minutes agoparentprev>and the self-realization that I now suck at playing video games. Nah... No mouselook really makes this much harder. Took me over 10 attempts to pass, and I'm Diamond at Overwatch. reply teach 47 minutes agoparentprevYeah, amusingly, I use a keyboard that doesn't have arrow keys. I've bound them to a different layer, but that doesn't work well with this setup. If this implementation supported the now-standard WASD (which was absolutely used by some high-level Doom players back in the day) AND if it allowed me to fire using the left mouse button (again, like the original game), then it would have been relatively easy to prove that I'm a human. :) reply computerdork 19 minutes agorootparentAnother thing that makes it \"easier\" is this actually does support strafe, using Option + left and right arrow keys. Still not easy, but more doable:) reply charlesabarnes 6 hours agoprevI tried to do it the intended way, but found it too difficult. I was able to cheese it by staying in the starting area and killing the enemies that spawned to the right. reply BiteCode_dev 2 hours agoparentWell, this is not the first level, but this is the level entry weapon. Plus, left and right arrows rotate the characters since it's keyboard only, but in modern FPS you are used to having them laterally move you and you rotate with the mouse, so your reflexes are off. reply hansjorg 1 hour agorootparentAs in the original, you can use alt + left/right arrow keys to strafe. reply Zetaphor 35 minutes agorootparentSo this is just as difficult as every other captcha then reply BiteCode_dev 57 minutes agorootparentprevGood memory. But very platform dependant, so maybe OP is on a browser or OS that doesn't let you do that. I know it works on Chrome for me, but not on FF. reply sweeter 5 minutes agorootparentprevnice, that was the first thing that I noticed that I kept trying to do. It makes it a lot easier. I forgot about how clunky controls can be for older games without retroarch rebinds and stuff. I was playing Perfect Dark last night on my Steamdeck and I was able to bind the controls to a modern layout (left-stick walk, right-stick look, etc...) and it makes the game a ton easier. reply gruez 4 hours agoparentprevYou don't even need to cheese it when everything is client side, so there's no way for the server to verify you actually killed the required amount of enemies. reply Maxatar 3 hours agorootparentPerhaps this implementation works that way, but in principle if the game is strictly determined based on a random seed and player input, then the server can verify that the player's inputs do in fact result in the correct outcome. reply bcoates 1 hour agorootparentDoom doesn't even have a (variable) random seed, it's deterministic like an NES game and has built-in record/playback that's just a frame by frame list of player moves. reply make3 4 hours agorootparentprevit's a PoC reply cwillu 3 hours agorootparentWhat part of the concept was proven? reply hombre_fatal 2 hours agorootparentYou could send inputs to the server, the server simulates them to see if you killed monsters. The concept here is the UX of what it would be like if it were properly hooked up. Just like what you would do with any captcha proposal. You’d want to mock up the UX to evaluate whether it something people can do. Though here’s it’s just for fun. reply oliwarner 2 hours agorootparentprevI think this is unfairly downvoted. Anyone can think of something humans do and just playing DOOM in a browser falls well short of anything new. All the hard stuff is missing. It's half an idea. reply cwillu 18 minutes agorootparentI find the early votes on new comments are biased downwards; I can speculate as to why, but it usually is more than balanced out by later votes. reply 93po 3 hours agorootparentprevyes - i refuse to use captchas for basically any reason - if a site blocks me with a captcha where i have to label traffic lights or whatever, i close the tab and move on i would probably choose to use doom captcha even if it takes 5 times longer. it is proven that at least people will interact with this if they wouldnt with traditional ones reply yieldcrv 2 hours agorootparentfound the robot jk robots can do this now reply cuu508 5 hours agoparentprevHah, same here. 1. press the back arrow to move back 2. press spacebar every second and that's it, 30 or so seconds later the captcha is solved :-) reply lightning8113 2 hours agorootparentI didn't even have to move. Holding space bar down from the start seemed to work for me. reply TehCorwiz 5 hours agoparentprevYeah, pistol starting this particular level is...unkind. At least start with a shotgun. reply oytis 5 hours agoparentprevIDDQD works. Just saying. reply zorked 4 hours agorootparentYou don't get credit for IDDQD though. Also use something like IDCLEV15 and you can go to other stages. reply Dwedit 2 hours agorootparentprevOddly enough, IDCLIP and IDCLEV work. You can't activate any doors or switches, but you can beat E1M8 with No Clipping Mode. Then you're stuck at the \"Ordering Info\" screen with no way to activate the menu. reply huhtenberg 5 hours agorootparentprevBut WASD doesn't! reply oytis 4 hours agorootparentWas it working in the original DOOM though? I don't remember any more. reply gusfoo 4 hours agorootparent> Was it working in the original DOOM though? I don't remember any more. By default it was the arrow keys for movement andfor turning with CTRL as fire. But you could re-map the keys and after a few years quite a lot of people did. reply bigstrat2003 13 minutes agorootparentprevNope. Doom was arrow keys to go forward/back/turn, plus alt-left/right to strafe. reply doganugurlu 5 hours agorootparentprevHow nostalgic, and authentic! reply TeMPOraL 4 hours agorootparentprevSo does IDKFA. reply Dwedit 3 hours agorootparentMonsters killed by the Rocket Launcher (gibbing) do not increase the kill counter. reply seattle_spring 4 hours agorootparentprevHoly crap, so does IDSPISPOPD reply johnisgood 3 hours agoparentprevYes, same. Are those invisible turrets?! reply bilekas 1 hour agoprevWell this is hard, guess I'm not a human! It's been so long since I've played doom but without strafing.. it's almost impossible! reply KerryJones 1 hour agoparentStated elsewhere: hold alt + (left/right) to strafe reply cpill 1 hour agoparentprevjust go forward to trigger the monsters and then immediately back to where you started for cover and then pick them off at a distance. easy! reply casenmgreen 7 hours agoprev1. That's a tough level, one of the hidden levels IIRC. 2. It feels like \"-fast\" has been used. 3. The task is much, much more difficult because you can't strafe. Very cute though :-) reply epcoa 6 hours agoparentCorrect, it's E1M9, the shareware secret level, on Nightmare difficulty. You can strafe with the old-school chording of Alt. The sound was fucked up for me, high pitched, no idea why (fits the ridiculousness of this experience though, so NBD). reply wellthisisgreat 5 hours agorootparent> old-school chording of Alt Damn I completely forgot it was a thing even, wow. And yet it was for like 7 years of my gaming experience reply RiverCrochet 46 minutes agoparentprevHold ALT, you definitely can strafe. At least I could. reply mistaken 6 hours agoparentprevStrafing works for me on linux with firefox. Maybe it's an OS or browser setting that prevents it? reply hnlmorg 6 hours agorootparentIt’s not available on touch screen devices. reply plussed_reader 4 hours agorootparentBluetooth keyboard to the rescue! reply casenmgreen 4 hours agorootparentprevI also FF on Linux. But I always redefined A and D as strafe-left and strafe-right. I literally did not know the keyboard shortcut to strafe, because I have probably literally never used it. reply mock-possum 3 hours agoparentprevIs it actually that tough?? I was ready to good-naturedly complain that it didn’t work on mobile, but the onscreen controls worked just fine, and I didn’t have any trouble killing 3 guys right away. I guess I have been playing a fair amount of classic doom lately though so reply casenmgreen 35 minutes agorootparentWe mean the whole level, not the three mobs for the captcha. reply inglor_cz 58 minutes agoparentprevYeah, E1M9 is notoriously hard with a pistol start. I immediately recognized it ... which speaks to the amount of time I spent on Doom in my youth. reply mrcwinn 39 minutes agoprevNo WASD?! CAPTCHA fail — I can tell no human created this. reply galleywest200 7 hours agoprevThere are so many monsters, took me 3-4 tries...just like a real captcha! reply phoronixrly 7 hours agoparentMan, and just like real CAPTCHA it is hell for people with disabilities... 10/10 reply throwaway7679 5 hours agorootparentIt's doom, so hell for everyone reply UniverseHacker 2 hours agorootparentprevexcellent comment reply gamegod 7 hours agoprevWhat kind of monster doesn't give us WASD or at least ctrl to shoot? Awesome captcha though :) reply InMice 6 hours agoparentijkl; reply felixg3 6 hours agorootparentUnfortunately very specific to QWERTY layouts:( reply zamadatix 4 hours agorootparentThat depends entirely on whether you opt to do the compare by code or key. E.g. in JS KeyboardEvent.code == \"KeyW\" may resolve true even though KeyboardEvent.key == \"W\" may resolve false because the user is on AZERTY or what have you. reply zubairshaik 3 hours agorootparentErgonomic keyboards on software like ZMK or QMK actually change both iirc, so that's a no go for external keyboard users. reply zamadatix 28 minutes agorootparentI'm a QMK user woth a custom no -standard layout myself. I think you're referring to mapping keys to a given keycode as part of the firmware config. That's not inherently a problem, do it properly and it still lines up with whatever OS layout you load. If you're purposefully changing the keycodes to avoid letting the OS know the layout is different... well, you got what you explicitly configured you wanted it to behave like? Leave a layer if you want both behaviors, if not it's not up to the app devloper to assume otherwise. reply airstrike 5 hours agoprevThis was created with Vercel's AI assistant \"v0\" Here's a link to the chat: https://v0.dev/chat/4X85A52Dzde?b=b_tOXbbZzZPgT&f=0 reply gruez 4 hours agoparent>This was created with Vercel's AI assistant \"v0\" \"with\" is doing a lot of the heavy lifting here. I skimmed the log and so far as I can tell, the only thing that the AI assistant did was design the UI. It didn't implement the actual game. This might sound impressive, but aside from adding minor bits of interaction (eg. a button that shows \"loading\" for a few seconds), there's little difference functionality-wise from a drag-and-drop UI designer like winforms (and its predecessor, visual basic, which existed in the 90s). reply pierrec 4 hours agoparentprevThe JS part is nowhere to be seen, I guess they used the assistant to create the layout, but not the actual DOOM integration part (?) Even then, that chat gets pretty painful to read after a while... Paraphrasing, but that's the gist of it: \"center the text in the button\", \"you didn't center it, center the text\", \"please please center the text\"... reply airstrike 4 hours agorootparentThe very beginning of the chat is already inefficient as it wastes a lot of \"context space\" to just get very basic stuff in like defining the text at the top.. that kind of stuff should go in the very first message reply skrebbel 4 hours agoparentprevI read through the chat but it's all nitpicking about layout and there doesn't seem to be any point where DOOM is actually inserted. I don't understand, did the author get the AI to do the easy part and then code the hard part by themselves? reply monkpit 4 hours agorootparentIsn’t WASM doom a solved thing already? I wouldn’t consider that the hard part, unless I’m missing your point. reply skrebbel 4 hours agorootparentwell you'll need integrations to have the WASMised doom tell you when a monster gets hit, or when you died. you need to worry about which keyboard events to pass in, etc. i know it's not super hard but it's definitely the more exciting part of this, vs all the \"make the title text bigger\" stuff that's in the chat reply runlevel1 4 hours agoparentprevAs others have pointed out, that was only setting up the UI. Here's the repo with the rest of the source: https://github.com/rauchg/doom-captcha They also had to modify Doom to skip the menus, add the necessary callbacks, and a few other tweaks. reply econ 2 hours agoprevJust shooting without moving shouldn't solve it. The ammo is excessive. Mobile needs a better interface and landscape mode. reply sira04 6 hours agoprevOne day we'll have the Dark Souls captcha https://www.youtube.com/watch?v=WqnXp6Saa8Y reply Dwedit 3 hours agoprevIt took me using Debug Mode to realize there was supposed to be a confetti animation that plays after winning, it loads from a third party site. I have third-party javascript blocked by default. reply vunderba 4 hours agoprevThank you for doing the right thing and crediting the original Doom Captcha creator on the github repo. My expectations of the software industry in general have been at an all-time low lately, so this was nice to see. The original from a few years back: https://vivirenremoto.github.io/doomcaptcha https://github.com/vivirenremoto/doomcaptcha reply itvision 6 hours agoprevSolved it on a second attempt on my smartphone. It's horrible. 99% of people will give up. reply threekindwords 6 hours agoprevOk, so this is the kind of content I show up for. On one hand, it’s a clever and fun way to show off what we can do with the web these days. The way it is presented hits just right... the demo is dead center of the page, with debug tools and more info within reach. I particularly enjoyed reading the \"how it's made\" page to understand how it was put together. I like how all of this extra stuff was not front and center when the page loads. Even the design language of the CAPTCHA box itself felt just right. On the other hand, it's a satire of what we have done to the web. The bad guys (like the monsters in the game) have won. I'm a flesh and blood human, but here I am having to click on fuzzy pictures of random objects before I can do the task I actually wanted to accomplish. Behind the scenes, my human insight gets licensed and used for whatever purpose (nefarious or not). Just like the DOOM demo here, it's hard and cumbersome, but for whatever reason we all accept it as the way it has to be. We all shake our heads and say \"what a shame, what a shame.\" reply mschuster91 6 hours agoparent> Just like the DOOM demo here, it's hard and cumbersome, but for whatever reason we all accept it as the way it has to be. Because most if not all of us have lost all hope that eventually our governments will be either willing or able to do something about the bad actors on the 'net. reply puttycat 51 minutes agoprevCool, but why is this a CAPTCHA? That is a very broad definition of the test. reply RiverCrochet 44 minutes agoparentWell, for one, CAPTCHA means Completely Automated Public Turing Test To Tell Computers And Humans Apart and I don't think DOOM as in the gameplay is Turing-complete. reply magic_smoke_ee 5 hours agoprevIDSPISPOPD, IDKFA, and IDDQD work but the only weapons that work are the chainsaw up to the rocket launcher. reply acidburnNSA 6 hours agoprevThank God the cheat codes I have memorized still work. reply bstsb 7 hours agoprevreading the chat with v0 was interesting. the last time i tried v0 it generated really basic tailwind templates but the first image generation was actually really good for an LLM. reply fixprix 5 hours agoparentYea looks like most people are missing the fact it was built by the CEO of Vercel with v0, an AI site builder. Doom in a browser has been done to death. Link to chat log: https://v0.dev/chat/4X85A52Dzde reply Kiro 6 hours agoparentprevWhy are people downvoting this? I also found the chat very interesting and a cool demo of v0. It's linked at the bottom of the page. reply indigoabstract 1 hour agoprevOuch, the puzzle is too hard. Maybe the next step could be an automated tool for solving wicked CAPTCHAs? :) reply alexandrehtrb 3 hours agoprevVery cool. Suggestions: - Make the player immortal by default. Also all weapons by default. - Add strafing, if possible. - Make the player go to the level exit to finish the captcha (maybe a custom short map?) - A simpler version for mobile could be the original 3x3 captcha square with enemies attacking you. Tapping on enemy squares would kill them. reply Nition 2 hours agoparentConsidering that they've picked a very difficult level on purpose, I assumed it's hard on purpose as a joke. You get to solve the CAPTCHA only once you've got significant skills at Doom. reply johnisgood 3 hours agoparentprevThose suggestions are anti-CAPTCHA or unrelated to CAPTCHA, however. reply jordigh 5 hours agoprevAw, monster in-fighting kills don't count? That's my favourite kind of kill. In-fighting is a basic Doom skill, kind of forgotten in modern FPSes. reply anta40 6 hours agoprevFailed on 1st attempt, then beat it on 2nd attempt (I'm on Macbook Air). Very amusing idea. Perhaps I'll implement this for my personal project... well because why not? :p reply mosquitobiten 2 hours agoprevI broke it, I can enter the menu in firefox with F1, get put in the first level, I shoot the barrels and it counts as monsters killed. reply tnvmadhav 6 hours agoprevI tried moving and I died. Stay at the spawn point and keep shooting anything that moves :) reply zoklet-enjoyer 5 hours agoparentSame. Only way I could beat it reply michaelsshaw 2 hours agoprevThis would be way cooler if this wasn't so fucking difficult! reply econ 2 hours agoparentIf you take a right turn then a left and run into the corner you drop into a secret area with a chain gun, some health and a med pack. The problem is that they are waiting for you if you take the elevator back up. I have no idea how to get past them without killing to many monsters. Even shooting the barrel counts -. - reply foo-stuff 6 hours agoprevI wonder how long this would need to train in order to pass the Captcha... https://github.com/apollopower/DOOM-AI reply phoronixrly 5 hours agoparentI would argue that you do not need AI in the sense of ML to pass this specific CAPTCHA as it stands (move forward, move back then shoot until solved). If it was extended to all DOOM levels and you started at a completely random position of a level, I bet there is a high chance you would still not need any ML to beat it... You would at best have to implement an AI (in the sense of game development, not ML) algorithm... Ofc all of this is going to be necessary IF it actually cannot be trivially circumvented... How does the FE prove to the backend that you actually killed the monsters? reply jsheard 5 hours agorootparent> How does the FE prove to the backend that you actually killed the monsters? Doom is fully deterministic so you could record the players inputs and replay them on the server to verify that the kills actually happened. Some games actually do that to make cheating their online leaderboards more difficult, because it's a lot more work to fake a record-setting replay than it is to just submit a fake score, and even if you do fake a working replay it might not stand up to human review. reply Beijinger 5 hours agoprevNice. But I would prefer this as a Captcha: https://play-cs.com/ reply chrisan 5 hours agoparentDoom is the defacto \"I wonder if we can get it to run on x\" program reply wruza 3 hours agoprevCan’t strafe on mobile, that’s can shooting range and you are the can. reply pg5 7 hours agoprevPretty cool, but a little on screen pad would be good for mobile users. reply yousif_123123 7 hours agoparentIt does have it. If you tap on it, it should show it. reply djeastm 6 hours agoparentprevI also was unable to see controls on mobile. Tried tapping everything I could see. reply turbocon 7 hours agoparentprevThere is a pad on the screen for mobile, I think you just need to tap it reply pjmlp 5 hours agorootparentNope, not for Android Chrome. Taping shows the instructions for keyboard use. reply kmeisthax 6 hours agoprevCan't move or shoot on my iPad Pro with Magic Keyboard. reply knolan 5 hours agoparentTap on it . Arrow keys to move and space to shoot. It’s annoying because you can’t strafe. reply discoinverno 6 hours agoprevI couldn't win without cheating ^:) It's crazy how ingrained in my memory is the code tho, could remember it automatically after maybe 25 years reply tom_ 2 hours agoprevWell at least it wasn't E4M2. reply rickreynoldssf 2 hours agoprevKind of hard without strafe. reply cydmax 4 hours agoprevIt took me 3 retries. I’ve forgotten how to strafe and just moved a bit to the right… reply rmac 36 minutes agoprevdo diablo reply midnight_shaman 4 hours agoprevGreat idea, looking forward to seeing it on production websites ;) reply dvngnt_ 3 hours agoprevdidn't google's ai genie use automomus agents to play doom to generate training data? reply entropie 6 hours agoprevIts awesome, but actually quite hard without arrow keys on a HHKBpro. reply ricardo81 6 hours agoprevExcellent, though I'd have liked it more with a bigger gun reply ac29 5 hours agoparentIDKFA reply yobid20 3 hours agoprevDoesnt work on mobile. reply apgwoz 3 hours agoparentWas able to play, but it didn’t recognize kills. Definitely got 2, possibly a 3rd (hard to tell in small screen). FF on iOS. reply EVa5I7bHFq9mnYK 5 hours agoprevNo BFG 9000 :( reply cyanydeez 2 hours agoprevAren't you afraid you are training AI? reply snarfy 1 hour agoprevthe controls are ass reply martinbaun 4 hours agoprevI just died. I guess I am getting old and need to play more strategy games hehe. reply ulrischa 5 hours agoprevDoes not work on a smartphone reply TechTechTech 5 hours agoparentWorks fine on android Firefox mobile reply oxide 5 hours agorootparentGame loads on firefox desktop, but is a black screen. Debug didn't show anything out of the ordinary. loads fine on Chrome though. reply stuckkeys 2 hours agoprevThanks satan. reply super_normal 6 hours agoprevbeat the captcha first try on a pixel 6. true gaming legend signing out, el oh el oh el... reply mobilio 6 hours agoprevfun mode - iddqd and idkfa works! reply mjrpes 6 hours agoparentInteresting; it recognizes kills made with chainsaw, gun, shotgun, machine gun, but not rocket launcher. Plasma and BFG keys don't work. reply mobilio 4 hours agorootparentin shareware version plasma and BFG guns aren't available reply anthk 1 hour agorootparentThe authour could had just used FreeDoom https://freedoom.github.io which is a free as in freedom replacement for DOOM I/II and deathmatch iWADs (totally compatible with community PWADS). reply layer8 4 hours agoprevNot very accessible. reply ybbond 4 hours agoprevit's too hard, I bet only bot can accomplish this reply pkkkzip 4 hours agoparentvery easy to build an aimbot. i think its entertaining but to be used as real captcha you need a variety of challenging games but at the risk of turning away many humans, which will ironically open up a market for more such decaptcha services reply joshcsimmons 6 hours agoprevThis is so metal. Great work. reply deeviant 6 hours agoprevI feel this faster than the average \"click on all pictures of x\". reply runlevel1 5 hours agoparentThat's a low bar. Google's reCAPTCHA sometimes feels like it was created in a lab to be as infuriating to humans as possible. If you're not logged in and are using a shared IP (CG-NAT in my case), you get all sorts of fun behaviors. It loves to fail correct responses -- sometimes multiple consecutive ones. Occasionally, it will deliberately slow down new image fade-in to a snail's pace to test reaction time. Spot those stairs too fast? You must be a bot. reply mrlonglong 5 hours agoprevBFG9000, here I come! reply MB-EU 6 hours agoprevonly thing I'd change is put shoot as CTRL :) - Good work reply bogrollben 6 hours agoprevtoday I learned I really suck at Doom. reply tw0fac3 2 hours agoprevWow reply quotemstr 5 hours agoprevFunny, but thanks to RL, I'd expect this to actually be an ineffective CAPTCHA. DOTA was solved years ago, yes? reply pseingatl 5 hours agoprevidkfa doesn't work reply EGreg 6 hours agoprevI think it’s nearly impossible on a mobile phone hehe reply make3 3 hours agoprevyou would have to randomize spawns otherwise they can just record a playthrough and repeat it to unlock reply m3kw9 6 hours agoprevit's not possible to win without strifing reply jokethrowaway 2 hours agoprevThe sad thing is that this is easier than some captchas I've seen. I remember some crap from hell with hcaptcha reply anthk 5 hours agoprevNow do it with Nethack/Slashem. reply doctor_radium 6 hours agoprevI've rolled my eyes for years over when this sort of thing would happen for real: \"score 3000 points at Pac Man and maybe we'll let you view our web site\". +1 for the technical achievement, but I turn and run at Cloudflare tick boxes. reply mensetmanusman 7 hours agoprev [–] This will work until agents are common. I bet the best bot farms are first adopters of agents though. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "DOOM CAPTCHA is a creative project requiring users to play a level of the classic game DOOM as a CAPTCHA test, highlighting technical skills and nostalgia. - Users find it challenging due to the absence of modern controls, leading to mixed reactions about its practicality and accessibility. - The project, although novel, underscores the persistent dissatisfaction with traditional CAPTCHA systems, despite being built with Vercel's AI assistant and manual game integration."
    ],
    "points": 613,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1735740735
  },
  {
    "id": 42562847,
    "title": "Static search trees: faster than binary search",
    "originLink": "https://curiouscoding.nl/posts/static-search-tree/",
    "originBody": "Static search trees: 40x faster than binary search December 2024 62-minute read Ragnar Groot Koerkamp results walkthrough highlight hpc search-index Table of Contents 1 Introduction 1.1 Problem statement 1.2 Motivation 1.3 Recommended reading 1.4 Binary search and Eytzinger layout 1.5 Hugepages 1.6 A note on benchmarking 1.7 Cache lines 1.8 S-trees and B-trees 2 Optimizing find 2.1 Linear 2.2 Auto-vectorization 2.3 Trailing zeros 2.4 Popcount 2.5 Manual SIMD 3 Optimizing the search 3.1 Batching 3.2 Prefetching 3.3 Pointer arithmetic 3.3.1 Up-front splat 3.3.2 Byte-based pointers 3.3.3 The final version 3.4 Skip prefetch 3.5 Interleave 4 Optimizing the tree layout 4.1 Left-tree 4.2 Memory layouts 4.3 Node size 𝐵 = 15 4.3.1 Data structure size 4.4 Summary 5 Prefix partitioning 5.1 Full layout 5.2 Compact subtrees 5.3 The best of both: compact first level 5.4 Overlapping trees 5.5 Human data 5.6 Prefix map 5.7 Summary 6 Multi-threaded comparison 7 Conclusion 7.1 Future work 7.1.1 Branchy search 7.1.2 Interpolation search 7.1.3 Packing data smaller 7.1.4 Returning indices in original data 7.1.5 Range queries 7.1.6 Sorting queries 7.1.7 Suffix array searching In this post, we will implement a static search tree (S+ tree) for high-throughput searching of sorted data, as introduced on Algorithmica. We’ll mostly take the code presented there as a starting point, and optimize it to its limits. For a large part, I’m simply taking the ‘future work’ ideas of that post and implementing them. And then there will be a bunch of looking at assembly code to shave off all the instructions we can. Lastly, there will be one big addition to optimize throughput: batching. All source code, including benchmarks and plotting code, is at github:RagnarGrootKoerkamp/suffix-array-searching. Discuss on r/programming, hacker news, twitter, or bsky. 1 Introduction 1.1 Problem statement Input. A sorted list of 𝑛 32bit unsigned integers vals: Vec. Output. A data structure that supports queries 𝑞 , returning the smallest element of vals that is at least 𝑞 , or u32::MAX if no such element exists. Optionally, the index of this element may also be returned. Metric. We optimize throughput. That is, the number of (independent) queries that can be answered per second. The typical case is where we have a sufficiently long queries: &[u32] as input, and return a corresponding answers: Vec.11 For those not familiar with Rust syntax, Vec is simply an allocated vector of 32 bit unsigned integers, like std::vector in C++. &[u32] is a slice (or view) pointing to some non-owned memory. [u32; 8] is an array of 8 elements, like std::array. Note that we’ll usually report reciprocal throughput as ns/query (or just ns), instead of queries/s. You can think of this as amortized (not average) time spent per query. Benchmarking setup. For now, we will assume that both the input and queries are simply uniform random sampled 31bit integers22 You’ll see later why not 32bit . Code. In code, this can be modelled by the trait shown in Code Snippet 1. 1 2 3 4 5 6 7 8 9 trait SearchIndex { /// Two functions with default implementations in terms of each other. fn query_one(&self, query: u32) -> u32 { Self::query(&vec![query])[0] } fn query(&self, queries: &[u32]) -> Vec { queries.iter().map(|&q| Self::query_one(q)).collect() } } Code Snippet 1: Trait that our solution should implement. 1.2 Motivation Aside from doing this project just for the fun of it, there is some higher goal. One of the big goals of bioinformatics is to make efficient datastructures to index DNA, say a single human genome (3 billion basepairs/characters) or even a bunch of them. One such datastructure is the suffix array (wikipedia), that sorts the suffixes of the input string. Classically, one can then find the locations where a string occurs by binary searching the suffix array. This project is a first step towards speeding up the suffix array search. Also note that we indeed assume that the input data is static, since usually we use a fixed reference genome. 1.3 Recommended reading The classical solution to this problem is binary search, which we will briefly visit in the next section. A great paper on this and other search layouts is “Array Layouts for Comparison-Based Searching” by Khuong and Morin (2017). Algorithmica also has a case study based on that paper. This post will focus on S+ trees, as introduced on Algorithmica in the followup post, static B-trees. In the interest of my time, I will mostly assume that you are familiar with that post. I also recommend reading my work-in-progress introduction to CPU performance, which contains some benchmarks pushing the CPU to its limits. We will use the metrics obtained there as baseline to understand our optimization attempts. Also helpful is the Intel Intrinsics Guide when looking into SIMD instructions. Note that we’ll only be using AVX2 instructions here, as in, we’re assuming intel. And we’re not assuming less available AVX512 instructions (in particular, since my laptop doesn’t have them). 1.4 Binary search and Eytzinger layout As a baseline, we will use the Rust standard library binary search implementation. 1 2 3 4 5 6 7 8 9 10 pub struct SortedVec { vals: Vec, } impl SortedVec { pub fn binary_search_std(&self, q: u32) -> u32 { let idx = self.vals.binary_search(&q).unwrap_or_else(|i| i); self.vals[idx] } } Code Snippet 2: The binary search in the Rust standard library. The main conclusion of the array layouts paper (Khuong and Morin 2017) is that the Eytzinger layout is one of the best in practice. This layout reorders the values in memory: the binary search effectively is a binary search tree on the data, the root the middle node, then the nodes at positions 1 4 𝑛 and 3 4 𝑛 , then 1 8 𝑛 , 3 8 𝑛 , 5 8 𝑛 , 7 8 𝑛 , and so on. The main benefit of this layout is that all values needed for the first steps of the binary search are close together, so they can be cached efficiently. If we put the root at index 1 , the two children of the node at index 𝑖 are at 2 𝑖 and 2 𝑖 + 1 . This means that we can effectively prefetch the next cache line, before knowing whether we need index 2 𝑖 or 2 𝑖 + 1 . This can be taken a step further and we can prefetch the cache line containing indices 16 𝑖 to 16 𝑖 + 15 , which are exactly the values needed 4 iterations from now. For a large part, this can quite effectively hide the latency associated with the traversal of the tree. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 pub struct Eytzinger { /// The root of the tree is at index 1. vals: Vec, } impl Eytzinger { /// L: number of levels ahead to prefetch. pub fn search_prefetch(&self, q: u32) -> u32 { let mut idx = 1; while (1self.get(idx)) as usize; prefetch_index(&self.vals, (1self.get(idx)) as usize; } let zeros = idx.trailing_ones() + 1; let idx = idx >> zeros; self.get(idx) } } Code Snippet 3: Implementation of searching the Eytzinger layout, with 𝐿 = 4 levels of prefetching. If we plot these two, we see that Eytzinger layout performs as good as binary search when the array fits in L2 cache (256kB for me, the middle red line), but starts to be much better than binary search as the array grows to be much larger than the L3 cache (12MB). In the end, Eytzinger search is around 4 times faster, which nicely corresponds to being able to prefetch 4 iterations of cache lines from memory at a time. Figure 1: Query throughput of binary search and Eytzinger layout as the size of the input increases. At 1GB input, binary search needs around 1150ns/query, while Eytzinger is 6x faster at 200ns/query. 1.5 Hugepages For all experiments, we’ll make sure to allocate the tree using 2MB hugepages by default, instead of the usual 4kB pages. This reduces pressure on the translation lookaside buffer (TLB) that translates virtual memory addresses to hardware memory addresses, since its internal table of pages is much smaller when using hugepages, and hence can be cached better. With transparent hugepages enabled, they are automatically given out whenever allocating an exact multiple of 2MB, and so we always round up the allocation for the tree to the next multiple of 2MB. However, it turns out that small allocations below 32MB still go on the program’s heap, rather than asking the kernel for new memory pages, causing them to not actually be hugepages. Thus, all allocations we do are actually rounded up to the next multiple of 32MB instead. All together, hugepages sometimes makes a small difference when the dataset is indeed between 1MB and 32MB in size. Smaller data structures don’t really need hugepages anyway. Enabling them for the Eytzinger layout as in the plot above also gives a significant speedup for larger sizes. 1.6 A note on benchmarking The plots have the size of the input data on the logarithmic (bottom) x-axis. On the top, they show the corresponding number of elements in the vector, which is 4 times less, since each element is a u32 spanning 4 bytes. Measurements are taken at values 2 𝑖 , 1.25 ⋅ 2 𝑖 , 1.5 ⋅ 2 𝑖 , and 1.75 ⋅ 2 𝑖 . The y-axis shows measured time per query. In the plot above, it says latency, since it is benchmarked as for q in queries { index.query(q); }. Even then, the pipelining and out-of-order execution of the CPU will make it execute multiple iterations in parallel. Specifically, while it is waiting for the last cache lines of iteration 𝑖 , it can already start executing the first instructions of the next query. To measure the true latency, we would have to introduce a loop carried dependency by making query 𝑖 + 1 dependent on the result of query 𝑖 . However, the main goal of this post is to optimize for throughput, so we won’t bother with that. Thus, all plots will show the throughput of doing index.query(all_queries). For the benchmarks, I’m using my laptop’s i7-10750H CPU, with the frequency fixed to 2.6GHz using Code Snippet 4.33 One might argue that this is unrealistic since in practice processors do have dynamic frequencies, but here I prefer reproducible benchmarks over realistic benchmarks. 1 sudo cpupower frequency-set -g powersave -d 2.6GHz -u 2.6GHz Code Snippet 4: Pinning the CPU frequency to 2.6GHz. Also relevant are the sizes of the caches: 32KiB L1 cache per core, 256KiB L2 cache per core, and 12MiB L3 cache shared between the physical 6 cores. Furthermore, hyper-threading is disabled. All measurements are done 5 times. The line follows the median, and we show the spread of the 2nd to 4th value (i.e., after discarding the minimum and maximum). Observe that in most of the plot above, the spread is barely visible! Thus, while especially the graph for binary search looks very noisy, that ’noise’ is in fact completely reproducible. Indeed, it’s caused by effects of cache associativity, as explained in the array layouts paper (Khuong and Morin (2017); this post is long enough already). 1.7 Cache lines Main memory and the caches work at the level of cache lines consisting of 64 bytes (at least on my machine), or 16 u32 values. Thus, even if you only read a single byte, if the cache line containing that byte is not yet in the L1 cache, the entire thing will be fetched from RAM or L3 or L2 into L1. Plain binary search typically only uses a single value of each cache line, until it gets to the end of the search where the last 16 values span just 1 or 2 cache lines. They Eytzinger layout suffers the same problem: even though the next cache line can be prefetched, it still only uses a single value in each. This fundamentally means that both these search schemes are using the available memory bandwidth quite inefficiently, and since most of what they are doing is waiting for memory to come through, that’s not great. Also, while that’s not relevant yet, when doing this with many threads in parallel, or with batching, single-core RAM throughput and the throughput of the main memory itself become a bottleneck. It would be much better if somehow, we could use the information in each cache line much more efficiently ;) We can do that by storing our data in a different way. Instead of storing it layer by layer, so that each iteration goes into a new layer, we can store 4 layers of the tree at a time (Code Snippet 5). That takes 15 values, and could nicely be padded into a full cache line. Then when we fetch a cache line, we can use it for 4 iterations at once – much better! On the other hand, now we can’t prefetch upcoming cache lines in advance anymore, so that overall the latency will be the same. But we fetch up to 4 times fewer cache lines overall, which should help throughput. Unfortunately, I don’t have code and plots here, because what I really want to focus on is the next bit. Figure 2: The first two rows show how we could pack four layers of the Eytzinger search into a single cache line. The first follows a classic binary search layout, while the second applies the Eytzinger layout recursively. The third row shows an S-tree node instead. For simplicity and clarity, I’m using consecutive values, but in practice, this would be any list of sorted numbers. 1.8 S-trees and B-trees We just ended with a node of 15 values that represent a height-4 search tree in which we can binary search. From there, it’s just a small step to S-trees. B-trees. But first I have to briefly mention B-trees though (wikipedia). Those are the more classic dynamic variant, where nodes are linked together via pointers. As wikipedia writes, they are typically used with much larger block sizes, for example 4kB, since files read from disk usually come in 4kB chunks. Thus, they also have much larger branching factors. S-trees. But we will instead use S-trees, as named so by Algorithmica. They are a nice middle ground between the high branching factor of B-trees, and the compactness of the Eytzinger layout. Instead of interpreting the 15 values as a search tree, we can also store them in a sorted way, and consider them as a 16-ary search tree: the 15 values simply split the data in the subtree into 16 parts, and we can do a linear scan to find which part to recurse into. But if we store 15 values and one padding in a cache line, we might as well make it 16 values and have a branching factor of 17 instead. S+ trees. B-trees and S-trees only store each value once, either in a leaf node or in an internal node. This turns out to be somewhat annoying, since we must track in which layer the result was found. To simplify this, we can store all values as a leaf, and duplicate them in the internal nodes. This is then called a B+ tree or S+ tree. However, I will be lazy and just use S-tree to include this modification. Figure 3: An example of a ‘full’ S+ tree (that I will from now just call S-tree) on 18 values with nodes of size (B=2) and branching factor (B+1=3). Each internal node stores the smallest value in the subtree on its right. In memory, the layers are simply packed together behind each other. A full S-tree can be navigated in a way similar to the Eytzinger layout: The node (note: not44 ;) value) at index 𝑖 has its 𝐵 + 1 child-nodes at indices ( 𝐵 + 1 ) ⋅ 𝑖 + 1 + { 0 , … , 𝐵 } . When the tree is only partially filled, the full layout can waste a lot of space (Figure 4). Instead, we can pack the layers together, by storing the offset 𝑜 ℓ of each layer. The children of node 𝑜 ℓ + 𝑖 are then at 𝑜 ℓ + 1 + ( 𝐵 + 1 ) ⋅ 𝑖 + { 0 , … , 𝐵 } . Figure 4: The full representation can be inefficient. The packed representation removes the empty space, and explicitly stores the offset (o_ell) where each layer starts. At last, let’s have a look at some code. Each node in the tree is simply represented as a list of 𝑁 = 16 u32 values. We explicitly ask that nodes are aligned to 64byte cache line boundaries. 1 2 3 4 #[repr(align(64))] pub struct TreeNode { data: [u32; N], } Code Snippet 5: Search tree node, aligned to a 64 byte cache line. For now, N is always 16. The values in a node must always be sorted. The S-tree itself is simply a list of nodes, and the offsets where each layer starts. 1 2 3 4 5 6 7 8 9 /// N: #elements in a node, always 16. /// B: branching factor{ /// The list of tree nodes. tree: Vec>, /// The root is at index tree[offsets[0]]. /// It's children start at tree[offsets[1]], and so on. offsets: Vec, } Code Snippet 6: The S-tree data structure. It depends on the number of values per node 𝐵 (usually 16 but sometimes 15) and the size of each node 𝑁 (always 16). To save some space, and focus on the interesting part (to me, at least), I will not show any code for constructing S-trees. It’s a whole bunch of uninteresting fiddling with indices, and takes a lot of time to get right. Also, construction is not optimized at all currently. Anyway, find the code here. What we will look at, is code for searching S-trees. 1 2 3 4 5 6 7 8 9 10 11 12 13 fn search(&self, q: u32, find: impl Fn(&TreeNode, u32) -> usize) -> u32 { let mut k = 0; for o in self.offsets[0..self.offsets.len()-1] { let jump_to = find(self.node(o + k), q); k = k * (B + 1) + jump_to; } let o = self.offsets.last().unwrap(); // node(i) returns tree[i] using unchecked indexing. let mut idx = find(self.node(o + k), q); // get(i, j) returns tree[i].data[j] using unchecked indexing. self.get(o + k + idx / N, idx % N) } Code Snippet 7: Initial code for searching S-trees, directly adapted from https://en.algorithmica.org/hpc/data-structures/s-tree/#searching. The find function finds the index of the child of the current node. Our first step will be optimizing the find function. 2 Optimizing find 2.1 Linear Let’s first precisely define what we want find to do: it’s input is a node with 16 sorted values and a query value 𝑞 , and it should return the index of the first element that is at least 𝑞 . Some simple code for this is Code Snippet 8. 1 2 3 4 5 6 7 8 pub fn find_linear(&self, q: u32) -> usize { for i in 0..N { if self.data[i] >= q { return i; } } N } Code Snippet 8: A linear scan for the first element ≥ 𝑞 , that breaks as soon as it is found. The results are not very impressive yet. Figure 5: The initial version of our S-tree search is quite a bit slower than the Eytzinger layout. In this and following plots, ‘old’ lines will be dimmed, and the best previous and best new line slightly highlighted. Colours will be consistent from one plot to the next. 2.2 Auto-vectorization As it turns out, the break; in Code Snippet 8 is really bad for performance, since the branch predictor can’t do a good job on it. Instead, we can count the number of values less than 𝑞 , and return that as the index of the first value ≥ 𝑞 . (Example: all values ≥ 𝑞 index gives index 0.) 1 2 3 4 5 6 7 8 9 pub fn find_linear_count(&self, q: u32) -> usize { let mut count = 0; for i in 0..N { if self.data[i]usize { // Simd is the protable-rust type for a SIMD vector of N(=16) u32 values. let data: Simd = Simd::from_slice(&self.data[0..N]); // splat takes a single u32 value, and copies it to all N lanes. let q = Simd::splat(q); let mask = q.simd_le(data); mask.first_set().unwrap_or(N) } Code Snippet 11: A find implementation using the count-trailing-zeros instruction. 1 2 3 4 5 6 7 8 9 10 11 vpminud 32(%rsi,%r8), %ymm0, %ymm1 ; take min of data[8..] and query vpcmpeqd %ymm1, %ymm0, %ymm1 ; does the min equal query? vpminud (%rsi,%r8), %ymm0, %ymm2 ; take min of data[..8] and query vpcmpeqd %ymm2, %ymm0, %ymm2 ; does the min equal query? vpackssdw %ymm1, %ymm2, %ymm1 ; pack the two results together, interleaved as 16bit words vextracti128 $1, %ymm1, %xmm2 ; extract half (both halves are equal) vpacksswb %xmm2, %xmm1, %xmm1 ; go down to 8bit values, but weirdly shuffled vpshufd $216, %xmm1, %xmm1 ; unshuffle vpmovmskb %xmm1, %r8d ; extract the high bit of each 8bit value. orl $65536,%r8d ; set bit 16, to cover the unwrap_or(N) tzcntl %r8d,%r15d ; count trailing zeros Code Snippet 12: Assembly code for Code Snippet 11. Instead of ending with popcntl, this ends with tzcntl. Now, let’s look at this generated code in a bit more detail. First up: why does simd_le translate into min and cmpeq? From checking the Intel Intrinsics Guide, we find out that there are only signed comparisons, while our data is unsigned. For now, let’s just assume that all values fit in 31 bits and are at most i32::MAX. Then, we can transmute our input to Simd without changing its meaning. Assumption Both input values and queries are between 0 and i32::MAX. Eventually we can fix this by either taking i32 input directly, or by shifting u32 values to fit in the i32 range. 1 2 3 4 5 6 7 8 9 10 11 pub fn find_ctz_signed(&self, q: u32) -> usize where LaneCount: SupportedLaneCount, { - let data: Simd = Simd::from_slice( &self.data[0..N] ); + let data: Simd = Simd::from_slice(unsafe { transmute(&self.data[0..N]) }); - let q = Simd::splat(q ); + let q = Simd::splat(q as i32); let mask = q.simd_le(data); mask.first_set().unwrap_or(N) } Code Snippet 13: Same as before, but now using i32 values instead of u32. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 -vpminud 32(%rsi,%r8), %ymm0, %ymm1 -vpcmpeqd %ymm1, %ymm0, %ymm1 +vpcmpgtd 32(%rsi,%rdi), %ymm1, %ymm2 ; is query(%ymm1) > data[8..]? -vpminud (%rsi,%r8), %ymm0, %ymm2 -vpcmpeqd %ymm2, %ymm0, %ymm2 +vpcmpgtd (%rsi,%rdi), %ymm1, %ymm1 ; is query(%ymm1) > data[..8]? vpackssdw %ymm2, %ymm1, %ymm1 ; pack results +vpxor %ymm0, %ymm1, %ymm1 ; negate results (ymm0 is all-ones) vextracti128 $1, %ymm1, %xmm2 ; extract u16x16 vpacksswb %xmm2, %xmm1, %xmm1 ; shuffle vpshufd $216, %xmm1, %xmm1 ; extract u8x16 vpmovmskb %xmm1, %edi ; extract u16 mask orl $65536,%edi ; add bit to get 16 when none set tzcntl %edi,%edi ; count trailing zeros Code Snippet 14: The two vpminud and vpcmpeqd instructions are gone now and merged into vpcmpgtd, but instead we got a vpxor back :/ (Ignore the different registers being used in the old versus the new version.) It turns out there is only a > instruction in SIMD, and not >=, and so there is no way to avoid inverting the result. We also see a vpshufd instruction that feels very out of place. What’s happening is that while packing the result of the 16 u32 comparisons down to a single 16bit value, data is interleaved in an unfortunate way, and we need to fix that. Here, Algorithmica takes the approach of ‘pre-shuffling’ the values in each node to counter for the unshuffle instruction. They also suggest using popcount instead, which is indeed what we’ll do next. 2.4 Popcount As we saw, the drawback of the trailing zero count approach is that the order of the lanes must be preserved. Instead, we’ll now simply count the number of lanes with a value less than the query, similar to the auto-vectorized SIMD before, so that the order of lanes doesn’t matter. 1 2 3 4 5 6 7 8 9 10 11 pub fn find_popcnt_portable(&self, q: u32) -> usize where LaneCount: SupportedLaneCount, { let data: Simd = Simd::from_slice(unsafe { transmute(&self.data[0..N]) }); let q = Simd::splat(q as i32); - let mask = q.simd_le(data); + let mask = q.simd_gt(data); - mask.first_set().unwrap_or(N) + mask.to_bitmask().count_ones() as usize } Code Snippet 15: Using popcount instead of trailing zeros. 1 2 3 4 5 6 7 8 9 10 vpcmpgtd 32(%rsi,%rdi), %ymm0, %ymm1 vpcmpgtd (%rsi,%rdi), %ymm0, %ymm0 vpackssdw %ymm1, %ymm0, %ymm0 ; 1 -vpxor %ymm0, %ymm1, %ymm1 vextracti128 $1, %ymm0, %xmm1 ; 2 vpacksswb %xmm1, %xmm0, %xmm0 ; 3 vpshufd $216, %xmm0, %xmm0 ; 4 vpmovmskb %xmm0, %edi ; 5 -orl $65536,%edi +popcntl %edi, %edi Code Snippet 16: the xor and or instructions are gone, but we are still stuck with the sequence of 5 instructions to go from the comparison results to an integer bitmask. Ideally we would like to movmsk directly on the u16x16 output of the first pack instruction, vpackssdw, to get the highest bit of each of the 16 16-bit values. Unfortunately, we are again let down by AVX2: there are movemask instructions for u8, u32, and u64, but not for u16. Also, the vpshufd instruction is now provably useless, so it’s slightly disappointing the compiler didn’t elide it. Time to write the SIMD by hand instead. 2.5 Manual SIMD As it turns out, we can get away without most of the packing! Instead of using vpmovmskb (_mm256_movemask_epi8) on 8bit data, we can actually just use it directly on the 16bit output of vpackssdw! Since the comparison sets each lane to all-zeros or all-ones, we can safely read the most significant and middle bit, and divide the count by two at the end.55 It would be really cool if we could teach compilers this trick. It already auto-vectorized the counting code anyway, so this is not that much more work I’d say. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 pub fn find_popcnt(&self, q: u32) -> usize { // We explicitly require that N is 16. let low: Simd = Simd::from_slice(&self.data[0..N / 2]); let high: Simd = Simd::from_slice(&self.data[N / 2..N]); let q_simd = Simd::::splat(q as i32); unsafe { use std::mem::transmute as t; // Transmute from u32 to i32. let mask_low = q_simd.simd_gt(t(low)); let mask_high = q_simd.simd_gt(t(high)); // Transmute from portable_simd to __m256i intrinsic types. let merged = _mm256_packs_epi32(t(mask_low), t(mask_high)); // 32 bits is sufficient to hold a count of 2 per lane. let mask: i32 = _mm256_movemask_epi8(t(merged)); mask.count_ones() as usize / 2 } } Code Snippet 17: Manual version of the SIMD code, by explicitly using the intrinsics. This is kinda ugly now, and there's a lot of transmuting (casting) going on between [u32; 8], Simd and the native __m256i type, but we'll have to live with it. 1 2 3 4 5 6 7 8 9 vpcmpgtd (%rsi,%rdi), %ymm0, %ymm1 vpcmpgtd 32(%rsi,%rdi), %ymm0, %ymm0 vpackssdw %ymm0, %ymm1, %ymm0 -vextracti128 $1, %ymm0, %xmm1 -vpacksswb %xmm1, %xmm0, %xmm0 -vpshufd $216, %xmm0, %xmm0 -vpmovmskb %xmm0, %edi +vpmovmskb %ymm0, %edi popcntl %edi, %edi Code Snippet 18: Only 5 instructions total are left now. Note that there is no explicit division by 2, since this is absorbed into the pointer arithmetic in the remainder, after the function is inlined. Now let’s have a look at the results of all this work. Figure 6: Using the S-tree with an optimized find function improves throughput from 240ns/query for Eytzinger to 140ns/query for the auto-vectorized one, and down to 115ns/query for the final hand-optimized version, which is over 2x speedup! As can be seen very nicely in this plot, each single instruction that we remove gives a small but consistent improvement in throughput. The biggest improvement comes from the last step, where we indeed shaved off 3 instructions. In fact, we can analyse this plot a bit more: For input up to 2 6 = 64 bytes, the performance is constant, since in this case the ‘search tree’ only consists of the root node. Up to input of size 2 10 , the thee has two layers, and the performance is constant. Similarly, we see the latency jumping up at size 2 14 , 2 18 , 2 22 and 2 26 , each time because a new layer is added to the tree. (Or rather, the jumps are at powers of the branching factor 𝐵 + 1 = 17 instead of 2 4 = 16 , but you get the idea.) In a way, we can also (handwaivily) interpret the x-axis as time: each time the graph jumps up, the height of the jump is pretty much the time spent on processing that one extra layer of the tree. Once we exceed the size of L3 cache, things slow down quickly. At that point, each extra layer of the tree adds a significant amount of time, since waiting for RAM is inherently slow. On the other hand, once we hit RAM, the slowdown is more smooth rather than stepwise. This is because L3 is still able to cache a fraction of the data structure, and that fraction only decreases slowly. Again handwavily, we can also interpret the x-axis as a snapshot of space usage at a fixed moment in time: the first three layers of the tree fit in L1. The 4th and 5th layers fit in L2 and L3. Once the three is 6 layers deep, the reads of that layer will mostly hit RAM, and any additional layers for sure are going to RAM. From now on, this last version, find_popcnt, is the one we will be using. 3 Optimizing the search 3.1 Batching As promised, the first improvement we’ll make is batching. Instead of processing one query at a time, we can process multiple (many) queries at once. This allows the CPU to work on multiple queries at the same time, and in particular, it can have multiple (up to 10-12) in-progress requests to RAM at a time. That way, instead of waiting for a latency of 80ns per read, we effectively wait for 10 reads at the same time, lowering the amortized wait time to around 8ns. Batching very much benefits from the fact that we use an S+ tree instead of S-tree, since each element is find in the last layer (at the same depth), and hence the number of seach steps through the tree is the same for every element in the batch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fn batch(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; for [o, _o2] in self.offsets.array_windows() { for i in 0..P { let jump_to = self.node(o + k[i]).find(qb[i]); k[i] = k[i] * (B + 1) + jump_to; } } let o = self.offsets.last().unwrap(); from_fn(|i| { let idx = self.node(o + k[i]).find(qb[i]); self.get(o + k[i] + idx / N, idx % N) }) } Code Snippet 19: The batching code is very similar to processing one query at a time. We just insert an additional loop over the batch of 𝑃 items. Figure 7: Batch size 1 (red) performs very similar to our non-batched version (blue), around 115ns/query. Increasing the batch size to 2, 4, and 8 each time significantly improves performance, until it saturates at 45ns/query (2.5x faster) around 16. One interesting observation is that going from batch size 1 to 2 does not double the performance. I suspect this is because the CPU’s out-of-order execution was already deep enough to effectively execute (almost) 2 queries in parallel anyway. Going to a batch size of 4 and then 8 does provide a significant speedup. Again going to 4 the speedup is relatively a bit less than when going to 8, so probably even with batch size 4 the CPU is somewhat looking ahead into the next batch of 4 already 🤯. Throughput saturates at batch size 16 (or really, around 12 already), which corresponds to the CPU having 12 line fill buffers and thus being able to read up to 12 cache lines in parallel. Nevertheless, we will settle on a batch size of 128, mostly because it leads to slightly cleaner plots in the remainder. It is also every so slightly faster, probably because the constant overhead of initializing a batch is smaller when batches are larger. 3.2 Prefetching The CPU is already fetching multiple reads in parallel using out-of-order execution, but we can also help out a bit by doing this explicitly using prefetching. After processing a node, we determine the child node k that we need to visit next, so we can directly request that node to be read from memory before continuing with the rest of the batch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 fn batch(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; for [o, o2] in self.offsets.array_windows() { for i in 0..P { let jump_to = self.node(o + k[i]).find(qb[i]); k[i] = k[i] * (B + 1) + jump_to; + prefetch_index(&self.tree, o2 + k[i]); } } let o = self.offsets.last().unwrap(); from_fn(|i| { let idx = self.node(o + k[i]).find(qb[i]); self.get(o + k[i] + idx / N, idx % N) }) } Code Snippet 20: Prefetching the cache line/node for the next iteration ahead. Figure 8: Prefetching helps speeding things up once the data does not fit in L2 cache anymore, and gets us down from 45ns/query to 30ns/query for 1GB input. We observe a few things: first prefetching slightly slow things down while data fits in L1 already, since in that case the instruction just doesn’t do anything anyway. In L2, it makes the graph slightly more flat, indicating that already there, the latency is already a little bit of a bottleneck. In L3 this effect gets larger, and we get a nice smooth/horizontal graph, until we hit RAM size. There, prefetching provides the biggest gains. 3.3 Pointer arithmetic Again, it’s time to look at some assembly code, now to optimize the search function itself. Results are down below in Figure 9. 3.3.1 Up-front splat First, we can note that the find function splat’s the query from a u32 to a Simd on each call. It’s slightly nicer (but not really faster, actually) to splat all the queries up-front, and then reuse those. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 pub fn batch_splat(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; + let q_simd = qb.map(|q| Simd::::splat(q)); for [o, o2] in self.offsets.array_windows() { for i in 0..P { - let jump_to = self.node(o + k[i]).find (qb[i] ); + let jump_to = self.node(o + k[i]).find_splat(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; prefetch_index(&self.tree, o2 + k[i]); } } let o = self.offsets.last().unwrap(); from_fn(|i| { - let idx = self.node(o + k[i]).find (qb[i] ); + let idx = self.node(o + k[i]).find_splat(q_simd[i]); self.get(o + k[i] + idx / N, idx % N) }) } Code Snippet 21: Hoisting the splat out of the loop is slightly nicer, but not faster. The assembly code for each iteration of the first loop now looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 movq (%rsp,%r11),%r15 leaq (%r9,%r15),%r12 shlq $6, %r12 vmovdqa 1536(%rsp,%r11,4),%ymm0 vpcmpgtd (%rsi,%r12), %ymm0, %ymm1 vpcmpgtd 32(%rsi,%r12), %ymm0, %ymm0 vpackssdw %ymm0, %ymm1, %ymm0 vpmovmskb %ymm0, %r12d popcntl %r12d, %r12d shrl %r12d movq %r15,%r13 shlq $4, %r13 addq %r15,%r13 addq %r12,%r13 movq %r13,(%rsp,%r11) shlq $6, %r13 prefetcht0 (%r10,%r13) Code Snippet 22: Assembly code for each iteration of Code Snippet 21. (Actually it's unrolled into two copied of this, but they're identical.) 3.3.2 Byte-based pointers Looking at the code above, we see two shlq $6 instructions that multiply the given value by 64 . That’s because our tree nodes are 64 bytes large, and hence, to get the 𝑖 ’th element of the array, we need to read at byte 64 ⋅ 𝑖 . For smaller element sizes, there are dedicated read instructions that inline, say, an index multiplication by 8. But for a stride of 64, the compiler has to generate ‘manual’ multiplications in the form of a shift. Additionally, direct pointer-based lookups can be slightly more efficient here than array-indexing: when doing self.tree[o + k[i]], we can effectively pre-compute the pointer to self.tree[o], so that only k[i] still has to be added. Let’s first look at that diff: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 pub fn batch_ptr(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; let q_simd = qb.map(|q| Simd::::splat(q)); + // offsets[l] is a pointer to self.tree[self.offsets[l]] + let offsets = self.offsets.iter() + .map(|o| unsafe { self.tree.as_ptr().add(*o) }) + .collect_vec(); for [o, o2] in offsets.array_windows() { for i in 0..P { - let jump_to = self.node(o + k[i]) .find_splat(q_simd[i]); + let jump_to = unsafe { *o.add(k[i]) }.find_splat(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; - prefetch_index(&self.tree, o2 + k[i]); + prefetch_ptr(unsafe { o2.add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { - let idx = self.node(o + k[i]) .find_splat(q_simd[i]); + let idx = unsafe { *o.add(k[i]) }.find_splat(q_simd[i]); - self.get(o + k[i] + idx / N, idx % N) + unsafe { *(*o.add(k[i] + idx / N)).data.get_unchecked(idx % N) } }) } Code Snippet 23: Using pointer-based indexing instead of array indexing. Now, we can avoid all the multiplications by 64, by just multiplying all k[i] by 64 to start with: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 pub fn batch_byte_ptr(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; let q_simd = qb.map(|q| Simd::::splat(q)); let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); for [o, o2] in offsets.array_windows() { for i in 0..P { - let jump_to = unsafe { *o. add(k[i]) }.find_splat(q_simd[i]); + let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); - k[i] = k[i] * (B + 1) + jump_to ; + k[i] = k[i] * (B + 1) + jump_to * 64; - prefetch_ptr(unsafe { o2. add(k[i]) }); + prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { - let idx = unsafe { *o. add(k[i]) }.find_splat(q_simd[i]); + let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); - unsafe { *(*o.add(k[i] + idx / N)).data.get_unchecked(idx % N) } + unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 24: We multiply k[i] by 64 up-front, and then call byte_add instead of the usual add. Indeed, the generated code now goes down from 17 to 15 instructions, and we can see in Figure 9 that this gives a significant speedup! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 movq 32(%rsp,%rdi),%r8 vmovdqa 1568(%rsp,%rdi,4),%ymm0 vpcmpgtd (%rsi,%r8), %ymm0, %ymm1 vpcmpgtd 32(%rsi,%r8), %ymm0, %ymm0 vpackssdw %ymm0, %ymm1, %ymm0 vpmovmskb %ymm0, %r9d popcntl %r9d, %r9d movq %r8,%r10 shlq $4, %r10 addq %r8,%r10 shll $5, %r9d andl $-64,%r9d addq %r10,%r9 movq %r9,32(%rsp,%rdi) prefetcht0 (%rcx,%r9) Code Snippet 25: When using byte-based pointers, we avoid some multiplications by 64. 3.3.3 The final version One particularity about the code above is the andl $-64,%r9d. In line 6, the bitmask gets written there. Then in line 7, it’s popcounted. Life 11 does a shll $5, i.e., a multiplication by 32, which is a combination of the /2 to compensate for the double-popcount and the * 64. Then, it does the and $-64, where the mask of -64 is 111..11000000 which ends in 6 zeros. But we just multiplied by 32, so all this does is zeroing out a single bit, in case the popcount was odd. But we know for a fact that that can never be, so we don’t actually need this and instruction. To avoid it, we do this /2*64 => *32 optimization manually. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 pub fn find_splat64(&self, q_simd: Simd) -> usize { let low: Simd = Simd::from_slice(&self.data[0..N / 2]); let high: Simd = Simd::from_slice(&self.data[N / 2..N]); unsafe { let q_simd: Simd = t(q_simd); let mask_low = q_simd.simd_gt(t(low)); let mask_high = q_simd.simd_gt(t(high)); use std::mem::transmute as t; let merged = _mm256_packs_epi32(t(mask_low), t(mask_high)); let mask = _mm256_movemask_epi8(merged); - mask.count_ones() as usize / 2 + mask.count_ones() as usize * 32 } } pub fn batch_byte_ptr(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; let q_simd = qb.map(|q| Simd::::splat(q)); let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); for [o, o2] in offsets.array_windows() { for i in 0..P { - let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat (q_simd[i]); + let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); - k[i] = k[i] * (B + 1) + jump_to * 64; + k[i] = k[i] * (B + 1) + jump_to ; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 26: Manually merging /2 and *64 into *32. Again, this gives a small speedup. Figure 9: Results of improving the search function bit by bit. Like before, the improvements are small but consistent. Throughput on 1GB input improves from 31ns/query to 28ns/query. 3.4 Skip prefetch Now we know that the first three levels of the graph fit in L1 cache, so probably we can simply skip prefetching for those levels. Figure 10: Skipping the prefetch for the first layers is slightly slower. As it turns out, skipping the prefetch does not help. Probably because the prefetch is cheap if the data is already available, and there is a small chance that the data we need was evicted to make room for other things, in which case the prefetch is useful. 3.5 Interleave One other observation is that the first few layers are CPU bound, while the last few layers are memory throughput bound. By merging the two domains, we should be able to get a higher total throughput. (Somewhat similar to how for a piece wise linear convex function 𝑓 , 𝑓 ( ( 𝑥 + 𝑦 ) / 2 )5 , and thus we need the next value in the red layer (which is stored as a single array), which is 6 . The problem now is that the red tree nodes exactly correspond to cache lines, and thus, the 6 will be in a new cache line that needs to be fetched from memory. Now consider the left-max tree below: Figure 13: In the left-max S+ tree, each internal node contains the maximum of its left subtree. Now if we search for 5.5 , we descend into the middle subtree rooted at [ 7 , 9 ] . Then we go left to the [ 6 , 7 ] node, and end up reading 6 as the first value ≥ 5.5 . Now, the search directly steers toward the node that actually contains the answer, instead of the one just before. Figure 14: The left-S tree brings runtime down from 24ns/query for the interleaved version to 22ns/query now. 4.2 Memory layouts Let’s now consider some alternative memory layouts. So far, we were packing all layers in forward order, but the Algorithmica post actually stores them in reverse, so we’ll try that too. The query code is exactly the same, since the order of the layers is already encoded into the offsets. Another potential improvement is to always store a full array. This may seem very inefficient, but is actually not that bad when we make sure to use uninitialized memory. In that case, untouched memory pages will simply never be mapped, so that we waste on average only about 2MB per layer when hugepages are enabled, and 14MB when there are 7 layers and the entire array takes 1GB. Figure 15: So far we have been using the packed layout. We now also try the reversed layout as used by Algorithmica, and the full layout that allows simple arithmetic for indexing. A benefit of storing the full array is that instead of using the offsets, we can simply compute the index in the next layer directly, as we did for the Eytzinger search. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 pub fn batch_ptr3_full(&self, qb: &[u32; P]) -> [u32; P] { let mut k = [0; P]; let q_simd = qb.map(|q| Simd::::splat(q)); + let o = self.tree.as_ptr(); - for [o, o2] in offsets.array_windows() { + for _l in 0..self.offsets.len() - 1 { for i in 0..P { let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); - k[i] = k[i] * (B + 1) + jump_to ; + k[i] = k[i] * (B + 1) + jump_to + 64; prefetch_ptr(unsafe { o.byte_add(k[i]) }); } } from_fn(|i| { let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 28: When storing the array in full, we can drop the per-layer offsets and instead compute indices directly. Figure 16: Comparison with reverse and full memory layout, and full memory layout with using a dedicated _full search that computes indices directly. As it turns out, neither of those layouts improves performance, and so we will not use them going forward. 4.3 Node size 𝐵 = 15 We can also try storing only 15 values per node, so that the branching factor is 16. This has the benefit of making the multiplication by 𝐵 + 1 (17 so far) slightly simpler, since it replaces x = (x> shift for some value of shift, rather than at index 0 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 pub fn search_prefix(&self, qb: &[u32; P]) -> [u32; P] { let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); // Initial parts, and prefetch them. let o0 = offsets[0]; - let mut k = [0; P]; + let mut k = qb.map(|q| { + (q as usize >> self.shift) * 64 + }); let q_simd = qb.map(|q| Simd::::splat(q)); for [o, o2] in offsets.array_windows() { for i in 0..P { let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 29: Searching the full layout of the partitioned tree starts in the partition in which each query belongs. Figure 20: The ‘simple’ partitioned tree, for (b_{textrm{max}}in {4,8,12,16,20}), shown as dotted lines. We see that indeed, the partitioned tree has a space overhead varying between 0 and 1 , making this not yet useful in practice. Larger 𝑏 reduce the height of the remaining trees, and indeed we see that queries are faster for larger 𝑏 . Especially for small trees there is a significant speedup over interleaving. Somewhat surprisingly, none of the partition sizes has faster queries than interleaving for large inputs. Also important to note is that while partitioning is very fast for sizes up to L1 cache, this is only possible because they have ≫ 1 space overhead. 5.2 Compact subtrees Just like we used the packed layout before, we can also do that now, by simply concatenating the representation of all packed subtrees. We ensure that all subtrees are still padded into the same total size, but now we only add as much padding as needed for the largest part, rather than padding to full trees. Then, we give each tree the same layout in memory. We’ll have offsets 𝑜 ℓ of where each layer starts in the first tree, and we store the constant size of the trees. That way, we can easily index each layer of each part. Figure 21: Compared to before, Figure 19, the lowest level of each subtree now only takes 2 instead of 3 nodes. The code for querying does become slightly more complicated. Now, we must explicitly track the part that each query belongs to, and compute all indices based on the layer offset, the in-layer offset k[i], and the part offset. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 pub fn search(&self, qb: &[u32; P]) -> [u32; P] { let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); // Initial parts, and prefetch them. let o0 = offsets[0]; + let mut k: [usize; P] = [0; P]; + let parts: [usize; P] = qb.map(|q| { + // byte offset of the part. + (q as usize >> self.shift) * self.bpp * 64 + }); let q_simd = qb.map(|q| Simd::::splat(q)); for [o, o2] in offsets.array_windows() { for i in 0..P { - let jump_to = unsafe { *o.byte_add( k[i]) }.find_splat64(q_simd[i]); + let jump_to = unsafe { *o.byte_add(parts[i] + k[i]) }.find_splat64(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; - prefetch_ptr(unsafe { o2.byte_add( k[i]) }); + prefetch_ptr(unsafe { o2.byte_add(parts[i] + k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { - let idx = unsafe { *o.byte_add( k[i]) }.find_splat(q_simd[i]); + let idx = unsafe { *o.byte_add(parts[i] + k[i]) }.find_splat(q_simd[i]); - unsafe { (o.byte_add( k[i]) as *const u32).add(idx).read() } + unsafe { (o.byte_add(parts[i] + k[i]) as *const u32).add(idx).read() } }) } Code Snippet 30: The indexing for the packed subtrees requires explicitly tracking the part of each query. This slows things down a bit. Figure 22: Compared to the the simple/full layout before (dark blue dots for (b=16)), the compact layout (e.g. red dots for (b=16)) consistently uses less memory, but is slightly slower. For fixed 𝑏 max , memory overhead of the compact layout is small as long as the input is sufficiently large and the trees have sufficiently many layers. Thus, this tree could be practical. Unfortunately though, querying them is slightly slower than before, because we must explicitly track the part of each query. 5.3 The best of both: compact first level As we just saw, storing the trees one by one slows queries down, so we would like to avoid that. But on the other hand, the full layout can waste space. Here, we combine the two ideas. We would like to store the horizontal concatenation of the packed trees (each packed to the same size), but this is complicated, because then levels would have a non-constant branching factor. Instead, we can fully omit the last few (level 2) subtrees from each tree, and pad those subtrees that are present to full subtrees. This way, only the first level has a configurable branching factor 𝐵 1 , which we can simply store after construction is done. This layout takes slightly more space than before because the subtrees must be full, but the overhead should typically be on the order of 1 / 16 , since (for uniform data) each tree will have ≥ 9 subtrees, of which only the last is not full. Figure 23: We can also store the horizontal concatenation of all trees. Here, the number of subtrees can be fixed to be less than (B+1), and is (2) instead of (B+1=3). Although not shown, deeper layers must always be full and have a (B+1) branching factor. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 pub fn search_b1(&self, qb: &[u32; P]) -> [u32; P] { let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); let o0 = offsets[0]; let mut k: [usize; P] = qb.map(|q| { (q as usize >> self.shift) * 64 }); let q_simd = qb.map(|q| Simd::::splat(q)); - for [o, o2] in offsets.array_windows() { + if let Some([o1, o2]) = offsets.array_windows().next() { for i in 0..P { let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); - k[i] = k[i] * (B + 1) + jump_to; + k[i] = k[i] * self.b1 + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } - for [o, o2] in offsets .array_windows() { + for [o, o2] in offsets[1..].array_windows() { for i in 0..P { let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 31: Now, the code is simple again, in that we don't need to explicitly track part indices. All that changes is that we handle the first iteration of the for loop separately, and use branching factor self.b1 instead of B+1 there. Figure 24: When compressing the first level, space usage is very similar to the compact layout before, and query speed is as fast as the full layout before. 5.4 Overlapping trees A drawback of all the above methods is that memory usage is heavily influenced by the largest part, since all parts must be at least as large. This is especially a problem when the distribution of part sizes is very skewed. We can avoid this by sharing storage between adjacent trees. Let 𝑆 𝑝 be the number of subtrees for each part 𝑝 , and 𝑆 𝑚 𝑎 𝑥 = max 𝑝 𝑆 𝑝 . Then, we can define the overlap 0 ≤ 𝑣 ≤ 𝐵 , and append only 𝐵 1 = 𝑆 𝑚 𝑎 𝑥 − 𝑣 new subtrees for each new part, rather than 𝑆 𝑚 𝑎 𝑥 as we did before. The values for each part are then simply appended where the previous part left off, unless that subtree is ‘out-of-reach’ for the current part, in which case first some padding is added. This way, consecutive parts can overlap and exchange memory, and we can somewhat ‘buffer’ the effect of large parts. Figure 25: In this example, the third tree has (6) values in ([8, 12)) and requires (S_{max}=3) subtrees. We have an overlap of (v=1), so that for each additional tree, only (2) subtrees are added. We add padding elements in grey to ensure all elements are reachable from their own tree. When the overlap is 1 , as in the example above, the nodes in the first layer each contain the maximum value of 𝐵 subtrees. When the overlap is larger than 1 , the nodes in the first layer would contain overlapping values. Instead, we store a single list of values, in which we can do unaligned reads to get the right slice of 𝐵 values that we need. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 pub fn search(&self, qb: &[u32; P]) -> [u32; P] { let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); let o0 = offsets[0]; let mut k: [usize; P] = qb.map(|q| { - (q as usize >> self.shift) * 4 * 16 + (q as usize >> self.shift) * 4 * (16 - self.overlap) }); let q_simd = qb.map(|q| Simd::::splat(q)); if let Some([o1, o2]) = offsets.array_windows().next() { for i in 0..P { + // First level read may be unaligned. - let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); + let jump_to = unsafe { o.byte_add(k[i]).read_unaligned() }.find_splat64(q_simd[i]); k[i] = k[i] * self.l1 + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } for [o, o2] in offsets[1..].array_windows() { for i in 0..P { let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { - let idx = unsafe { *o.byte_add(k[i]) }.find_splat(q_simd[i]); + let idx = unsafe { o.byte_add(k[i]).read_unaligned() }.find_splat(q_simd[i]); unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 32: Each part now contains 16 − 𝑣 values, instead of the original 16. We use read_unaligned since we do not always read at 16-value boundaries anymore. Figure 26: Overlapping trees usually use less memory than the equivalent version with first-level compression, while being about as fast. 5.5 Human data So far we’ve been testing with uniform random data, where the largest part deviates form the mean size by around 𝑛 . Now, let’s look at some real data: k-mers of a human genome. DNA consists of ACGT characters that can be encoded as 2 bits, so each string of 𝑘 = 16 characters defines a 32 bit integer66 We throw away the most significant bit to get 31 bit values. . We then look at the first 𝑛 k-mers of the human genome, starting at chromosome 1. To give an idea, the plot below show for each k-mer of length 𝑘 = 12 how often it occurs in the full human genome. In total, there are around 3G k-mers, and so the expected count for each k-mer is around 200. But instead, we see k-mers that occur over 2 million times! So if we were to partition on the first 24 bits, the size of the largest part is only around 2 − 10 of the input, rather than 2 − 24 . The accumulated counts are shown in orange, where we also see a number of flat regions caused by underrepresented k-mers. Figure 27: A plot showing k-mer counts for all (4^{12} = 16M) 𝑘 = 12 -mers of the human genome. On random data each k-mer would occur around 200 times, but here we see some k-mers occurring over 2 million times. Figure 28: Building the overlapping trees for k-mers of the human genome takes much more space, and even using only 16 parts regularly requires up to 50% overhead, making this data structure not quite practical. 5.6 Prefix map We need a way to handle unbalanced partition sizes, instead of mapping everything linearly. We can do this by simply storing the full tree compactly as we did before, preceded by an array (in blue below) that points to the index of the first subtree containing elements of the part. Like for the overlapping trees before, the first layer is simply a list of the largest elements of all subtrees that can be indexed anywhere (potentially unaligned). Figure 29: The prefix map, in blue, stores (2^b) elements, that for each 𝑏 -bit prefix stores the index of the first subtree that contains an element of that prefix. To answer a query, we first find its part, then read the block (16 elements) starting at the pointed-to element, and then proceed as usual from the sub-tree onward. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 pub fn search(&self, qb: &[u32; P]) -> [u32; P] { let offsets = self .offsets .iter() .map(|o| unsafe { self.tree.as_ptr().add(*o) }) .collect_vec(); let o0 = offsets[0]; let mut k: [usize; P] = qb.map(|q| { - 4 * (16 - self.overlap) * (q as usize >> self.shift) + unsafe { 4 * *self.prefix_map.get_unchecked(q as usize >> self.shift) } }); let q_simd = qb.map(|q| Simd::::splat(q)); if let Some([o1, o2]) = offsets.array_windows().next() { for i in 0..P { let jump_to = unsafe { o.byte_add(k[i]).read_unaligned() }.find_splat64(q_simd[i]); k[i] = k[i] * self.l1 + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } for [o, o2] in offsets[1..].array_windows() { for i in 0..P { let jump_to = unsafe { *o.byte_add(k[i]) }.find_splat64(q_simd[i]); k[i] = k[i] * (B + 1) + jump_to; prefetch_ptr(unsafe { o2.byte_add(k[i]) }); } } let o = offsets.last().unwrap(); from_fn(|i| { let idx = unsafe { o.byte_add(k[i]).read_unaligned() }.find_splat(q_simd[i]); unsafe { (o.byte_add(k[i]) as *const u32).add(idx).read() } }) } Code Snippet 33: In code, the only thing that changes compared to the previous overlapping version is that instead of computing the start index linearly (and adapting the element layout accordingly), we use the prefix_map to jump directly to the right place in the packed tree representation. Figure 30: As long as there are more elements than parts and the tree has at least two layers, the space overhead of this representation is close to (1/16) again. Although memory usage is now similar to the unpartitioned version, queries for large inputs are slightly slower than those previous layouts due to the additional index required. We can also again do the interleaving queries. These are slightly faster for small inputs, and around as fast as interleaving was without the partitioning. Figure 31: Prefix-map index with interleaving queries on random data. On human data, we see that the partitioned index is a bit faster in L1 and L2, and consistently saves the time of roughly one layer in L3. For larger indices, performance is still very similar to not using partitioning at all. Figure 32: Prefix-map with interleaving on human data. 5.7 Summary Figure 33: Summary of partitioning results. Overall, it seems that partitioning does not provide when we already interleave queries. 6 Multi-threaded comparison Figure 34: When using 6 threads, runtime goes down from 27ns to 7ns. Given that the speedup is less than 4x, we are now bottlenecked by total RAM throughput, and indeed methods that are slower for a single thread also reach near-optimal throughput now. 7 Conclusion All together, we went from 1150ns/query for binary search on 4GB input to 27ns for the optimized S-tree with interleaved queries, over 40x speedup! A large part of this improvement is due to batching queries and prefetching upcoming nodes. To get even higher throughput, interleaving queries at different levels helps to balance the CPU-bound part of the computation with the memory-bound part, so that we get a higher overall throughput. Using a 15 elements per node instead of 16 also improves throughput somewhat, but doubles the overhead of the data structure from 6.25% to 13.3%. For inputs that fit in L3 cache that’s fine and the speedup is worthwhile, while for larger inputs the speed is memory-bound anyway, so that there is no speedup while the additional memory requirements are somewhat large. We also looked into partitioning the data by prefix. While this does give some speedup, it turns out that on skewed input data, the benefits quickly diminish since the tree either requires a lot of buffer space, or else requires an additional lookup to map each part to its location in the first level of the tree. In the end, I’d say the additional complexity and dependency on the shape of the input data of partitioning is not worth the speedup compared to simply using interleaved queries directly. 7.1 Future work 7.1.1 Branchy search All methods we considered are branchless and use the exact same number of iterations for each query. Especially in combination with partitioning, it may be possible to handle the few large parts independently from the usual smaller parts. That way we could answer most queries with slightly fewer iterations. On the other hand, the layers saved would mostly be the quick lookups near the root of the tree, and introducing branches to the code could possibly cause quite a bit of delay due to mispredictions. 7.1.2 Interpolation search As we saw in the last plot above, total RAM throughput (rather than per-core throughput) becomes a bottleneck once we’re using multiple threads. Thus, the only way to improve total query throughput is to use strictly fewer RAM accesses per query. Prefix lookups won’t help, since they only replace the layers of the tree that would otherwise fit in the cache. Instead, we could use interpolation search (wikipedia), where the estimated position of a query 𝑞 is linearly interpolated between known positions of surrounding elements. On random data, this only takes 𝑂 ( lg ⁡ lg ⁡ 𝑛 ) iterations, rather than 𝑂 ( lg ⁡ 𝑛 ) for binary search, and could save some RAM accesses. On the other hand, when data is not random its worst case performance is 𝑂 ( 𝑛 ) rather than the statically bounded 𝑂 ( lg ⁡ 𝑛 ) . The PLA-index (Abrar and Medvedev 2024) also uses a single interpolation step in a precisely constructed piece wise linear approximation. The error after the approximation is determined by some global upper bound, so that the number of remaining search steps can be bounded as well. 7.1.3 Packing data smaller Another option to use the RAM lookups more efficiently would be to pack values into 16 bits rather than the 32 bits we’ve been using so far. Especially if we first do a 16 bit prefix lookup, we already know those bits anyway, so it would suffice to only compare the last 16 bits of the query and values. This increases the branching factor from 17 to 33, which reduces the number of layers of the tree by around 1.5 for inputs of 1GB. Another option, also suggested by ant6n on hacker news, would be some kind of ‘variable depth’ encoding, where the root node stores, say, the top 16 bits of every value, and as we go down the tree, we store some ‘middle’ 16 bits, skipping the first 𝑝 bits that are shared between all elements in the bucket. 7.1.4 Returning indices in original data For various applications, it may be helpful to not only return the smallest value ≥ 𝑞 , but also the index in the original list of sorted values, for example when storing an array with additional data for each item. Since we use the S+ tree that stores all data in the bottom layer, this is mostly straightforward. The prefix map partitioned tree also natively supports this, while the other partitioned variants do not: they include buffer/padding elements in their bottom layer, and hence we would need to store and look up the position offset of each part separately. 7.1.5 Range queries We could extend the current query methods to a version that return both the first value ≥ 𝑞 and the first value > 𝑞 , so that the range of positions corresponding to value 𝑞 can be determined. In practice, the easiest way to do this is by simply doubling the queries into 𝑞 and 𝑞 + 1 . This will cause some CPU overhead in the initial layers, but the query execution will remain branch-free. When 𝑞 is not found or only occurs a few times, they will mostly fetch the same cache lines, so that memory is efficiently reused and the bandwidth can be used for other queries. In practice though, this seems only around 20% faster per individual query for 4GB input, so around 60% slower for a range than for a single query. For small inputs, the speedup is less, and sometimes querying ranges is even more than twice slower than individual random queries. 7.1.6 Sorting queries Another thing that we did not at all consider so far, but was brought up by orlp on hacker news, is to batch queries. If we assume for the moment that the queries are sorted, we know that we have maximal possible reusing of all nodes, and they all need to be fetched from memory only once. If the number of queries is large (say at least 𝑛 / 16 ) then many nodes at the last level will have more than one query hitting them, and fetching them only once will reduce memory pressure. Similarly, if we have at least around 𝑛 / 256 queries, we can avoid fetching before-last layer nodes multiple times. In practice, I’m not quite sure how much time the sorting of queries would take, but something simple would be to do one or two rounds of 8-bit radix sort, so we sort into 256 = 16 2 or 65536 = 16 4 parts, and we can then skip the first two or four first layers of the search. 7.1.7 Suffix array searching The next step of this project is to integrate this into a fast suffix array (wikipedia) search scheme. The idea is to build this S-tree on, say, every 4th suffix, and then use the first 32 bits (or maybe 64) of each suffix as the value in the S-tree. Given a query, we can then quickly determine the range corresponding to its first 32 bits, and binary search only in the (likely small) remaining range to determine the final slice of the suffix array that corresponds to the query. References Abrar, Md. Hasin, and Paul Medvedev. 2024. “Pla-Index: A K-Mer Index Exploiting Rank Curve Linearity.” Schloss Dagstuhl – Leibniz-Zentrum für Informatik. https://doi.org/10.4230/LIPICS.WABI.2024.13. Khuong, Paul-Virak, and Pat Morin. 2017. “Array Layouts for Comparison-Based Searching.” Acm Journal of Experimental Algorithmics 22 (May): 1–39. https://doi.org/10.1145/3053370. For those not familiar with Rust syntax, Vec is simply an allocated vector of 32 bit unsigned integers, like std::vector in C++. &[u32] is a slice (or view) pointing to some non-owned memory. [u32; 8] is an array of 8 elements, like std::array. ↩︎ You’ll see later why not 32bit ↩︎ One might argue that this is unrealistic since in practice processors do have dynamic frequencies, but here I prefer reproducible benchmarks over realistic benchmarks. ↩︎ ;) ↩︎ It would be really cool if we could teach compilers this trick. It already auto-vectorized the counting code anyway, so this is not that much more work I’d say. ↩︎ We throw away the most significant bit to get 31 bit values. ↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=42562847",
    "commentBody": "Static search trees: faster than binary search (curiouscoding.nl)543 points by atombender 22 hours agohidepastfavorite171 comments skrebbel 9 hours agoTotally off topic, but I've started to notice that more and more algorithmic low-ish level content assumes Rust by default. My entire life I've been used to anything algorithmic being either written in sciency pseudocode (invariably in latex-generated PDFs), or plain old C(++), the vulgar latin of computer programming. I know C and I don't really know Rust but nevertheless I love that this is changing! I'd never advise a new programmer interested in low-level/fast stuff to begin with C now, so much good content is written around Rust. Like the old C examples, the post doesn't even say \"this is Rust\". You're expected to expect it to be Rust. And, well the language choice doesn't really matter for the core subject here. I could follow this post fine even though I don't really know Rust (just like I assume a Rust programmer could follow a well written algorithms deep dive with examples in C with a bit of dedication). EDIT okok that was a lie, I could follow the first half of this post, ish, and then it got way too deep for me. But anyway, standardize on Rust, I like it. I'd love if a bit more Zig was thrown into the mix here but either of them feel like a better default than C at this point to me. After decades of C being The Standard for this stuff, I love that this is finally changing. reply uecker 9 hours agoparentThis assumes that Rust is actually a better language. IMHO it isn't. reply p2detar 8 hours agorootparentI’m still unsure of how to feel about Rust. But if it has made it into the Linux Kernel, then I assume adoption is ongoing. Still, Zig seems somewhat more intuitive to me, even though I’ve used it as little as Rust thus far. A nice write up on the topic Zig and Rust: https://matklad.github.io/2023/03/26/zig-and-rust.html edit: typos reply deaddodo 2 hours agorootparentGenerally Zig is going to be more intuitive for C developers (people who prefer more low-level and procedural style coding), while Rust would be more intuitive/conducive to C++ developers (those who prefer more abstractions and language level features/guarantees). Which is totally fine, there's a reason C++ never completely subsumed C; both are valid avenues. reply jltsiren 7 hours agorootparentprevI think it's almost irrelevant how good Rust is as a language. Rust is winning in many contexts, because you can use it to replace C++, but the standard library and tools are substantially better. reply nostradumbasp 2 hours agorootparentThe entire user experience is so much nicer that even if Rust was slightly worse I would prefer it. I don't miss header files, makefiles, not having a package manager, maintaining all the crazy code people wrote themselves as pet projects instead of using an existing project in an ecosystem. Thankfully its not worse, so I don't even have to weigh the odds. reply tomcam 33 minutes agorootparentWait isn't cargo a package manager? Not a rust expect so I'm probably missing something reply 110jawefopiwa 6 hours agorootparentprevI think the main problem is that Rust doesn't allow for basic data structures like graphs or doubly-linked lists without extra effort, which is why I've generally always preferred pseudocode. reply emilsayahi 2 hours agorootparentI often hear this and am confused; not only are things like 'object soup'[0] possible and straightforward (putting things in collections and referring to them by indices), I never concretely hear why a graph or doubly-linked list becomes uniquely difficult to implement in Rust (and would genuinely be curious to learn why you feel this way). If you needed such data structures anyway, they're either in the standard library or in the many libraries ('crates' in Rust-lingo) available on Rust's package registry[1]---using dependencies in Rust is very straightforward & easy. [0]: https://jacko.io/object_soup.html [1]: https://crates.io/ reply fpoling 4 hours agorootparentprevWell, one can always emulate that in Rust with array indexes. And it will be closer how the actual CPU works where a pointer is just an offset into a memory chunk. Perhaps this is the reason performance oriented articles prefer Rust. In allows to skip a lot of memory allocation while still catching memory-safety bugs, which is a hard problem with C++. reply szundi 2 hours agorootparentHow could something to implement a pointer be more straightforward than a pointer? People seem to like Rust in excessive, sometimes botheringly excessive proportions. reply norman784 8 hours agorootparentprevI would argue that in some sense it is, just because of the enforced safety and correctness. reply uecker 23 minutes agorootparentIt does neither enforce correctness nor safety. It enforces memory safety in programs that stick to the safe subset. But don't get me wrong, Rust certainly has many good ideas and the focus on memory safety is good. I still do not think it is a great language. reply peoplefromibiza 8 hours agorootparentprevSo it's Ada since 1980, before C++ was even created. reply sroussey 6 hours agorootparentI wrote my first optimizing compiler for Ada in C++ around 1990. reply curiouscoding 7 hours agoparentprevAnything in particular that threw you off? I'd be happy to add a few words to briefly explain some of the less intuitive rust syntax. reply skrebbel 6 hours agorootparentNah just the final bits, stuff like `Simd::::splat(q)`, I'm not sure what splatting is or how Rust's Simd library works or, admittedly, how SIMD works in detail at all. So eg I'm not sure what that 8 is doing there in the type parameters, details like that. Maybe this isn't a Rust thing but a SIMD thing, btw, I don't know much Rust but I also never wrote any SIMD code ever. I don't know how the article could be clearer, IMO once you go into the deep nitty gritty optimization stuff you just gotta assume the reader knows the tools you're using. I'm OK with dropping out halfway cause the core idea is there even before you squeeze out all the perf. reply burntsushi 6 hours agorootparent`Simd::` is describing a vector with 8 lanes, where the width of each lane is 32-bits. For targets that support it, that should get you a 256-bit register. The `splat(q)` constructor is just saying, \"populate each lane with `q`.\" That is, the value is \"splatted\" across every lane in the vector. The main idea of SIMD is simple: you represent multiple points of data in the same register and use specialized CPU instructions to operate on those points simultaneously. The difficulty of SIMD is coming up with clever algorithms that use the available instructions in an efficient way. reply skrebbel 5 hours agorootparentAhh right, I've been doing too much TypeScript lately. I thought a type parameter couldn't impact behavior but only typechecking but clearly in Rust (like in C++) it can. Thanks for the explanation! Ah so splat is like a memset for the entire vector to the same value. OK makes sense, I bet that wasn't actually a Rust-ism at all, just basic SIMD lingo I didn't know. Thanks again! reply bennythomsson 5 hours agorootparentprevNice to see other real experts (and a bit of celebrities) in here. (For the uninitiated: Burntsushi of ripgrep fame.) reply skrebbel 4 hours agorootparentyeah tbh i was a bit starstruck that burntsushi would reply to my comment explaining what i assume is utter SIMD basics. that must be how swifties feel when she (or, likelier, her PR drones) click \"like\" on their insta comments. reply freeopinion 51 minutes agorootparentDoes burntsushi have PR drones (who can explain SIMD)? :) reply Narew 7 hours agoparentprevI don't know if it's good or bad, with pseudo code you put no constraints on how it should be implemented. It's known that some kind of algorithm are really hard to implement in Rust (every one use the link list data structure as an exemple). So having the article that use rust is good to see it can fit to rust constraints but at the same time does this constraint limit the algorithm itself ? reply npalli 6 hours agoparentprevQuite honestly, doesn't seem like Rust is a win here over C++. In fact, C++ has fewer sigils that make it somewhat easier to read sort of striking the balance between being simple enough (C-like) and abstractions (templates). Readability wise, I would have preferred Julia as that would have been the cleanest explanation of the code through the different topics at sufficient level of detail. Alas, it seems to have stalled somewhat (relatively speaking). It also doesn't help that every Rust article has Rust advocates jumping on you with \"WAHT ABOUT SAFETY\" which is off-putting since not every program needs to deal with all the complexity of the Rust memory/lifetime model to enable safety (simple bounds checking etc. might be sufficient). reply fpoling 3 hours agorootparentThe article is about how to squeeze absolute maximum in performance from the hardware. So you need a language that allows a relatively low-level access to hardware. And big plus of Rust is that it has standard SIMD libraries while C++ will get them only in C++26 reply User23 6 hours agoparentprevFun fact: a lot of that “sciency pseudocode” is actually Algol. reply mananaysiempre 2 hours agorootparentBecause that’s the original problem statement for Algol! As in, we’ve been publishing all that pseudocode for quite a bit and it seems like conventions have emerged, let’s formalize them and program in that. ... People were markedly more naïve back then, but then that’s sometimes what it takes. reply orlp 20 hours agoprevOne dimension that is not explored is partitioning the queries in batches. The primary cost is doing lookups on the out-of-cache table, so if you have a sufficiently large amount of queries you can resolve a couple layers of the tree in one step while those layers are in cache, grouping them based on where they land deeper in the tree, and then resolving all those queries that touch the same deeper part of the tree in one batch as well. In theory, with an infinitely large amount of input queries you will never have to do an out-of-cache lookup, it can be completely amortized away into linear scans. That said, you now end up with a bunch of results that need to be put back into the correct output order, which likely makes it not worth it. But if the operation can be fused into a reduction (e.g. find the sum of the binary search results) or the output order does not matter in some other way then all of a sudden it might make sense. reply mlochbaum 8 hours agoparentI have explored it, see https://mlochbaum.github.io/BQN/implementation/primitive/sor.... I implemented this method in Dyalog 18.0 with BlockQuicksort-like partitioning, using vectorized comparison with bit-boolean output. It's faster than you'd expect, maybe twice as slow as regular binary search when searched values are in cache, and better once they fall out of L2. But Dyalog reverted to 17.1 for later versions so you won't see it in a new download. It'll probably make it into CBQN eventually, perhaps with radix partitioning. Note that both quicksort and radix partitioning can be done and undone in a cache-friendly way. Unlike quicksort, there's no issue of pivot selection since you always choose the midpoint of the searched values. However, there's a complementary issue of memory if the partitions become unbalanced, because the larger partition can require saved memory of roughly the depth times the number of elements. With a bit per comparison it's bounded by the size of the input. reply mlochbaum 5 hours agorootparentWasn't the best section link, last paragraph here has more detail: https://mlochbaum.github.io/BQN/implementation/primitive/sor... reply tmyklebu 17 hours agoparentprevThere are theory papers on \"buffer trees\"---B-trees where each node is augmented with an O(B)-length array of pending updates and queries. I believe there were also some attempts at building SQL databases based on them. It sounds like you're reaching for the same trick. reply koverstreet 17 hours agorootparentthat's a hybrid compacting data structure: compacting within the btree node, normal btree topology otherwise. And it works much better than pure compacting (i.e. the leveldb lineage), because you avoid lock contention at the root on multithreaded update workloads, and the compaction/resort is much lower overhead when it fits in l2. incidentally, there's a filesystem that uses this technique. reply loeg 16 hours agorootparent> incidentally, there's a filesystem that uses this technique. BetrFS? reply hinkley 1 hour agoparentprevThere was some work a while back on streaming data past queries, but you need a fairly bounded data set for that to work. Having ten years of historical data in a data set would gum that up severely. reply mikepurvis 20 hours agoparentprevInteresting stuff, definitely the kind of real world optimization that happens when you’re able to look at actual access characteristics rather highly abstracted models. At one level you could just be saving the results into a hashtable to bubble them out again, but at the extreme end the lookup is actually spread across multiple machines in a cluster, so it’s more like throwing the query to the proper one with the right chunk of the index, along with instructions about where the final RPC is supposed to go with the result. reply natmaka 16 hours agoparentprevIt enhances the throughput (on average everyone waits less) at the price of a higher max latency (some, who posted a request mobilizing a very-recently-out-of-cache-index, will wait way, way more...), isn't it? In the real world those worst cases quite often kill such optimization. The (data size / cache size) ratio and queries local (in time) dispersion are key. reply curiouscoding 6 hours agoparentprevAh yes, I did consider sorting the queries at some point but I guess I then forgot about it again. If the queries are random and much less than the input size, probably most queries will hit different cache lines in the final layer, and I suspect benefits will be limited at maybe 2x best case since the last layer is where the bottleneck is. Also (radix) sorting is very memory bound usually, and we probably need to sort in at 16^2=256 buckets or so to get sufficient reusing of the higher layers, but I don't have the numbers of what a round of radix sort takes. (My guess is order 1ns per query? Maybe I'll find time to investigate and add it to the post.) reply koverstreet 18 hours agoparentprevThat presumes there's both locality in your queries, and it's not an online system - result latency doesn't matter much. That's not terribly common. reply bobmcnamara 17 hours agoparentprevThis works really well for subset testing, especially if sets sorted. Walk the larger tree, using the smaller tree. reply wolfgangK 21 hours agoprevAmazingly thorough ! I love how the author leaves no stone unturned. I had no idea you could do the kind of low level efficiency shaving in Rust. I wonder how a C++ implementation with https://github.com/jfalcou/eve would compare. reply curiouscoding 21 hours agoparentThanks! It's somewhat tiring to not have loose ends, but I agree it pays off :) Doing this stuff in Rust is absolutely possible, and I'd do it again since my C++ days are now past me, but the endless transmuting between portable-simd types, plain rust arrays, and intrinsic types is quite annoying. Also rust is not made for convenient raw pointer arithmetic. There plain C would be much more to the point. reply ant6n 12 hours agorootparentYou kind of lost me towards the end, so I’m not sure whether you attempted it, but I was wondering whether it would be possible for the internal nodes to store only the upper 8/16 bits (that are nonzero for the current subtree). This implies that one 64 byte cache line stores 32 or 64 entries instead of 16 (or better: 31 or 62/63, since u may need some bookkeeping dat). The next level would be to keep track of how many prefix bits are implied by the parents, so leaf nodes could perhaps also only use 8/12/16 bits, if the the higher bits are implied by the parent. or instead of bit masks, use offsets (i.e. leaves store k bits offset from parent value). That may screw around with the branch predictor, and may work very good with evenly distributed data vs uneven data. reply curiouscoding 6 hours agorootparentOhh yes some good ideas there! I've thought about pretty much exactly this at some point but then didn't end up including it. But I do think it's quite promising, and most of the bookkeeping can be made to be branchless. On the other hand, most of the latency is in the last few layers, and probably there isn't as much to be saved there. The biggest problem might be that the bottom layer will anyway have to store full-width numbers, since we must be sure to have the low-order bits somewhere in case they weren't covered yet in earlier layers. Or we could have variable width encoding per node maybe (instead of per layer) but that does sound a bit iffy on the branch predictor. In the end I guess I kinda like the simplicity and hence reliability of the 'just do the full tree and the first layers are cheap anyway' approach. Probably another factor 2 speedup is possible on specific datasets, but anything beyond this may not be reliably good on worst case inputs (like is the issue for the prefix partitioning methods). reply ant6n 1 hour agorootparentThe lowest level could be encoded with whatever number of bits is required for the numeric distance between the leafs. With proper book keeping, the full 32 bit values don’t need to be stored. The value for each node should be something like (parentdouble hash or truncate to lowest 32 bits and this technique works for strings as well. You can replace string with any data structure you can hash or index really. reply vlovich123 5 hours agorootparentAh but this then absolutely fails for range queries but makes sense if you want to build an index for point lookups. reply throw-qqqqq 3 hours agorootparentDefinitely! If the integers are (truncated) hashes, ranges are completely meaningless. But what would a range over strings even represent? Perhaps if you e.g. use string indices into an array of sorted strings (by length, by prefix or whatever), you could use it for something. Depends on the application I guess :) reply owenthejumper 20 hours agoprevElastic Binary Trees https://wtarreau.blogspot.com/2011/12/elastic-binary-trees-e... reply swiftcoder 12 hours agoprevAbsolutely love the level of detail here! Not often you see the process of optimising something spelled out in so much depth reply astronautas 12 hours agoprevCool! Thanks for the investigation. reply purple-leafy 20 hours agoprevcant understand the comp sci stuff yet, but love the way this site looks reply curiouscoding 5 hours agoparentThanks! I did spend some time fiddling with CSS to make the yellow highlights so that the titles stand out a bit more, and to improve the code blocks, but otherwise it's a relatively common theme for Hugo. (I think it's linked in the footer.) reply westurner 21 hours agoprevsuffix-array-searching/static-search-tree/src/s_tree.rs: https://github.com/RagnarGrootKoerkamp/suffix-array-searchin... partitioned_s_tree.rs: https://github.com/RagnarGrootKoerkamp/suffix-array-searchin... reply jokoon 2 hours agoprevso a tree when the data cannot be updated? What is the point? reply curiouscoding 33 minutes agoparentI've added a little motivation section on this :) The final goal is to index DNA, say a human genome, or a bunch of them, and this is static data. Then as new DNA comes in (eg is read by a DNA sequencer) we can efficiently query against the index built on the reference genome, and this reference is often fixed. reply colesantiago 19 hours agoprevThis is a great new interview question for junior and senior software engineering candidates. Definitely going to use this for our next round of interviews. reply butterlettuce 16 hours agoparentPlease don’t. Just test us on how to center a div. reply animal531 10 hours agorootparent\"Go ahead Junior, please implement this world class work and explain it to me as you go along. Oh, starting salary? No no, this is an unpaid 6 month internship.\" Fun aside, asking someone to work through a problem with you is fine, but when it diverges so much from the actual work then it just becomes ridiculous. reply ryao 21 hours agoprev [–] This would have been easier for a larger number of people to read if it had been in C or Python. reply unrealhoang 20 hours agoparentWhat a weird thing to complain about. The Rust code in TFA are purely arithmetic and imperative function calls. Any C developer that is good enough to care about the algorithm mentioned will have no issue reading such Rust code, heck, they could even throw the code to chatgpt to translate for them no problem. Such a good and detailed article that packed with techniques that are applicable everywhere yet the complaints are: “but rust”. Regarding Python, how could such optimizations be implemented in Python? Generating LLVM bytecodes directly aside. reply shawn_w 18 hours agorootparentFluent in C and C++ among others, know nothing about Rust. It's mostly easy to follow, but I'm having trouble with notation like `&[u32]` and `&[u32; P]`. Arrays that hold unsigned 32 bit integers? But there's `Vec` which also seems like an array type? Is it like the difference between C++ primitive arrays and std::vector? reply loeg 16 hours agorootparent`&[u32]` is essentially `std::span`. `&[u32; P]` is similarly something like `std::span`. `[u32; P]` (no `&`) is essentially `std::array`. `Vec` is essentially `std::vector`, yes. reply shawn_w 4 hours agorootparentThanks reply dwattttt 17 hours agorootparentprevFor `&[u32]` and `&[u32; P]`, those are both references to an array of unsigned 32 but integers, however the former is to an array of any size (and carries its size at runtime), whereas the latter is to an array with an explicitly known size at compile time. It's unusual in C, I think you can express it as `int[24] *` (or possibly some other permutation, I'm away from a compiler). Vec is pretty much like std::vector compared to them, yeah. reply ryao 20 hours agorootparentprevI have not studied Rust and find its syntax alien. It looks like a cross between a functional language and C++. Trying to read it is like forcing myself to read Italian. I don’t know Italian, but have studied Spanish and Latin. I can sort of figure things out if I put in effort, but there is always uncertainty when I do. That is the problem with reading Rust. This could be addressed if I just learned Rust (much like my difficulty with Italian could be addressed by studying Italian). However, I already know at least 10 programming languages. I am unwilling to learn the latest fashionable language unless it can promise me that the language will not change and there will never be another fashionable language for me to learn. Given that Rust rejected the standardization process that C and C++ embraced, and Zig is expected to replace Rust one day, I doubt Rust can make such assurances. As for Python, it is often used for teaching CS and everything except the assembly code is doable in it. Using low level assembly from Python would require using the FFI. Also, Python has nothing to do with LLVM. reply unrealhoang 20 hours agorootparentSuck to be you, I guess? If you don’t care enough then you don’t care. You wouldn’t bitch when there’s an article written in Italian with good knowledge inside: “but Italian”. You either trying to read using translation tool or ignore it entirely. I didn’t say python has anything to do with LLVM, it’s just a technique, read about it, or not. reply quotemstr 20 hours agorootparentprev> Zig is expected to replace Rust one day That's a bold prediction considering that Zig is unsafe and Rust is safe. If Zig's idioms make it safe, then modern C++ is safe too. reply ryao 20 hours agorootparentZig replacing Rust is not my prediction. It is what I am hearing from the Zig enthusiast I know. I have also seen others express the sentiment that the next fashionable language after Rust will be Zig. Regardless of whether it is Zig, there will be another. Rust is just one part of a never ending cycle of people trying to reinvent programming. reply kllrnohj 7 hours agorootparentThere's approximately a 0% chance of Zig seeing non-trivial adoption anywhere other than maybe the embedded world. It otherwise solves basically nobodies problems in the real world and is just a love letter to C. It's cute, kinda, but that's about it. reply quotemstr 5 hours agorootparentZig is like the Vulcan Centaur next to Starship. reply Sharlin 13 hours agorootparentprev> Zig enthusiasts Yeah, don’t you think they might be perhaps just slightly biased? I have some news for you about your average technology enthusiast… Anyone who claims Zig is going to replace Rust knows nothing about either Zig, Rust, or both. Zig is designed to solve none of the problems that Rust solves. Trillion-dollar corporations are rewriting things in Rust because it solves problems that really matter to them. The US government strongly recommends writing all new mission-critical code in memory-safe languages. Guess which one of Rust and Zig is memory-safe? I have nothing against Zig, it looks like a very nice better C, and the comptime stuff is both cool and useful. But its priorities are not Rust’s priorities. reply nottorp 7 hours agorootparentOf course, Rust evangelists are also more than slightly biased. reply nicoburns 19 hours agorootparentprev> Rust is just one part of a never ending cycle of people trying to reinvent programming. This is true of every single programming language. reply ryao 19 hours agorootparentThat is my complaint against the next fashionable language. Once you have some level of proficiency in around 10 languages, adding more to the list is a chore. It lacks the enjoyment that came from the first few. At least, that is my experience. That is why I am resistant to learning new languages unless software I want to modify is already written in it. Then, I am forced to learn and time spent on it is time that actually needed to be spent, unlike my brief time spent teaching myself FORTRAN in college, which was largely a waste of time. reply rurban 14 hours agorootparentprevBoth are unsafe, just zig is usually safer than rust. And also so more readable, ie. maintainable reply Sharlin 13 hours agorootparentThat’s one crazy claim to make. reply quotemstr 20 hours agorootparentprev> Regarding Python, how could such optimizations be implemented in Python? Generating LLVM bytecodes directly aside. You don't. You instead use your favorite Python extension system (regular Python modules, Cython, Numba, whatever) to implement this tree algorithm and expose it to Python already shaped into a container. reply wolfgangK 21 hours agoparentprevI don't think that Python would be the right language for such low-level performance maxxing endeavor. I would have picked C++ but t was eye opening for me to see how rust enabled such low level optimization, so I'm grateful for the choice. reply ryao 21 hours agorootparentC would be useful to the broadest audience. C++ programmers can read C while C programmers cannot always read C++, especially when the newer language constructs are used. I mentioned Python because of its popularity. Interesting, the Algorithmica article the author cited is in C: https://en.algorithmica.org/hpc/data-structures/s-tree/ reply npalli 21 hours agorootparentC++ not C. The author explains his choices elsewhere in the site. reply ryao 20 hours agorootparentThe code snippets should be accepted by a C compiler and therefore are valid C code. reply npalli 20 hours agorootparentIf you want to be pedantic, there is a constexpr in the snippets, wont be accepted by the C compiler. More broadly though it is a C++ tutorial. I insisted on it because the author of algorithmica actually explains he chose C++ and perhaps sometime later C/Rust or something might be better. Should respect his POV. reply ryao 20 hours agorootparentI had not seen the use of constexpr. You are correct that those are in C++. reply lubutu 14 hours agorootparentC23 has constexpr, albeit only for objects, not functions. The code also uses namespaces, as in `std::aligned_alloc(P, T)`. reply ryao 12 hours agorootparentYou have to be 1/3 down the page to see any of this in the code examples. By that point, you would already have seen a number of examples that are valid C code and it is reasonable to expect the rest to be. At least, that was my experience. reply curiouscoding 21 hours agorootparentprevYeah, I don't think python is the right tool here. C++ definitely would be an option though. Anyway very happy that this is also showing off what rust can do reply ryao 19 hours agorootparentAs far as I can tell, the community is largely divided into three major groups. Those that can read C, those that can read Python and those that can read both. Using either of them would have dodged criticism that your code examples are not accessible to much of the community. That said, you are right that Python is not the best language to use when you need to use intrinsics, as you would be writing it in another language and using the Python FFI to access it. reply oguz-ismail 18 hours agorootparentprev> this is also showing off what rust can do To people who already know Rust, yes. To others, not so much reply kubb 21 hours agoparentprevMaybe, but should the author really cater to people who can’t overcome a language barrier? They probably won’t understand the concept anyway. reply ryao 20 hours agorootparentThe ACM for a time only accepted code examples in ALGOL because it was felt that there should be a standard language that everyone understood. ALGOL eventually gave way to C and others, but there is definite value in ensuring things are accessible to the largest possible audience. reply kubb 20 hours agorootparentYou're free to use ALGOL in your posts if you want. It reads like pseudocode used in algorithmic books, and should be familiar to anyone who used the Pascal family. ALGOL gave way to C, and C is now giving way to Rust, Zig and others. You're playing the role of the people who wanted to keep the example snippets in ALGOL. reply ryao 20 hours agorootparentThe point was that examples should be in widely understood languages. The niche languages you list do not qualify as widely understood. Estne melius scribere exempla latine? reply mplanchard 7 hours agorootparentprevThis is someone’s blog, not an ACM publication. Why hold it to the same standard? They can write in whatever they like. I have a hard time reading Haskell, but I don’t sit and kvetch about it anytime someone wants to use it in a blog post. reply dxbydt 20 hours agorootparentprevusaco explicitly nudges you towards C++ on the first page itself. problems are graded on running time, even with moderately large datasets, Python simply doesn’t make the cut. So most high schoolers end up using C++ for usaco, and Java for AP Comp Science. reply mangamadaiyan 20 hours agorootparentprevErm, the concepts that you're referring to are independent of the language being used. The author is free to use whatever language they want. The GP (I think) was merely trying to make a point about making the article accessible to a wider audience that is capable of appreciating the concepts involved. reply kubb 20 hours agorootparentIf you can't understand the code snippets in this post, the concepts will most likely be lost on you, no matter what other language would be used for the code. reply mangamadaiyan 14 hours agorootparentIsn't that precisely the point that the GP was trying to make, about the accessibility of the article? Edit: Eytzinger layout, Cache lines, SIMD, et cetera are independent of the particular language used in the article. They're just as valid in C, for example. I don't understand your point about them being tied to Rust. reply ryao 19 hours agorootparentprevYou are correct. reply FridgeSeal 20 hours agoparentprevI have a far easier time reading Rust than C. Probably because it’s been years since I’ve had to do C, and I find some of the syntax and patterns quite C-specific and confusing. Python also does not express some of the important implementation details well enough in its standard syntax IMO: there’s no obvious delineation between references and pass by value in Python, borrowing, etc. So realistically, this is just the other half of the coin for all the articles where the code examples were written in C and everyone who didn’t really read C just had to put up with it. reply ryao 20 hours agorootparentThe TIOBE index suggests that you are in a much smaller group than those who have difficulty reading Rust: https://www.tiobe.com/tiobe-index/ reply coliveira 18 hours agorootparentYes, he is in a bubble. reply Rendello 21 hours agoparentprevI wonder what percentage of Rust users have significant experience with C. The difficulty curve of Rust was too high for me when I was coming from Python, but after doing HolyC and Zig, I find it fairly straightforward to conceptualize, though still difficult. I've been working with real C today and have been having fun, but it's very different for me to step back into the C world again after working with more modern tools. reply tmtvl 12 hours agoparentprevOh no, it would've been better if it was written using the most readable language: Scheme. reply bawolff 18 hours agoparentprevI've never programmed in rust and i can understand find. At the end of the day rust is just another imperative programming language. You shouldn't need to know the language at all to understand the very simple examples written in rust. reply plasticeagle 21 hours agoparentprevAs a computer science article, it should have mostly been pseudocode. Concrete implementations can be given in an appendix, where they belong. reply kccqzy 21 hours agorootparentThat's unrealistic given that the author is not just doing computer science but also engineering using SIMD. The kind of available SIMD instructions actually affects code choice. reply nostradumbasp 2 hours agorootparentprevI strongly prefer actual implementations and adore the way this was written. Maybe its all of the \"to get this to run in O(N) time we will leave the trick for the reader to discover\" I've bumped into. Or the classic \"use this esoteric pay-walled reference for instructions for this important subalgorithm\" then when you get that reference you realize its doing the same sort of thing. Super cool for quizzing masters students, pretty ridiculous for people in industry or hobbyists who learn by playing with code. Unfortunately when that happens there is almost never an OSS implementation with the \"trick\" either. reply curiouscoding 21 hours agorootparentprevThe problem with pseudocode is that it's completely underspecified. And how would I ever write intrinsics in pseudocode? Much easier to do a proper language directly so people can actually Google things and read their official documentation. reply sigbottle 19 hours agorootparentMy former roommate works in a similar domain; https://dl.acm.org/doi/pdf/10.1145/3448016.3452841 is an example of a paper implementing intrinsics in pseudocode. They \"unroll\" the intrinsics with a comment saying that this is implemented with an intrinsic. Of course though, your blog isn't a paper, don't know why people are getting up in arms about it. Also the other comment saying that \"psuedocode is not concerned with intrinsics\" is false. You can get \"great\" theoretical speedups (the shaveoffs are tiny but hey, they're better) with \"simple\" intrinsic operations - that's my roommate's entire research lol. The external memory model, for example, formalizes caching and allows all these low level optimizations to flourish. I'm not sure how intrinsics tied into it, but he's published so I'm not gonna question it :) --- Speaking of which, I noticed that you did competitive programming. How does CP compare to research? I loved data structure manipulation problems in CP when they were clever - often because they involved noticing that you can take a \"common\" model, but then optimize it significantly because you only needed to support a subset of the operations through a clever mathematical proof based on the structure of the problem - but as I got to the higher levels it felt more and more that a lot of them became really obscure \"support 413 operations on a tree, and yes, you really need to support all 413 operations on a tree\" and that's kind of my opinion of data structure research unfortunately as well :( I guess because solving broad general instances is more important. I'd love to hear your perspective though. reply ryao 19 hours agorootparentPseudo code can be whatever you want it to be. You can do SIMD pseudo code, but most generally don’t as that is often an implementation detail. reply barbegal 21 hours agoparentprevNeither of those languages gives you portable SIMD. Rust is rapidly becoming the language of choice for high performance code. reply npalli 21 hours agorootparentgoogle has a mature C++ library for portable SIMD. The original article seems to be a translation of the excellent algorithmica site which had it in C++. https://github.com/google/highway reply ryao 20 hours agorootparentYou can do portable SIMD in GNU C/C++ using the vector extension: https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html reply swiftcoder 12 hours agorootparentI'm not sure that \"portable\" and \"only works on one specific compiler vendor\" are very compatible concepts reply bigpingo 10 hours agorootparentgcc is available on and targets more platforms than rust. So if GNU C is not considered portable you can forget about 'portable rust'. reply swiftcoder 7 hours agorootparentPortability in the C and C++ worlds generally means across standard-conforming compilers, not just across platforms reply peutetre 18 hours agoparentprevWell, you can do the C implementation then. Don't see it as a problem, see it as an opportunity. reply quotemstr 21 hours agoparentprevRust is now common enough in the industry that everyone should be expected to at least read it, just like every programmer should be able to fizzbuzz in Python and JavaScript just as a matter of general technical literacy. There's no advanced Rust here and no concepts specific to the language. It's a good article. If Heinlein were in our industry, he might write this: A programmer should be able to write a shell, parse binary data, design a protocol (and reverse engineer one too), authenticate a password, not fumble multi-code-point graphemes, wrangle semaphores, plug memory leaks, compress data, migrate databases, automate builds, git rebase a tree, profile tail latency, write a simple design doc for a complex system, draw a triangle, multiply tensors, and do fizzbuzz in every popular language on GitHub. Specialization is for insects. reply ryao 21 hours agorootparentHere is a list of languages people can be generally expected to be able to read: * C * C++ * Java * JavaScript * Python It is the top 6 of the TIOBE index, minus C#: https://www.tiobe.com/tiobe-index/ Rust is not very high on the TIOBE index. It has rank 14 with a 1.29% rating. That is not much higher than COBOL. reply bschwindHN 20 hours agorootparentYou forgot the part where no one cares about TIOBE though. reply ryao 19 hours agorootparentAs the TIOBE index says “The ratings are based on the number of skilled engineers world-wide, courses and third party vendors”. Very many people do care about that. Is there any reason I should think your remark is from some legitimate issue rather than you not liking the index results? reply bschwindHN 19 hours agorootparentI would argue most people working software jobs either haven't heard of TIOBE or don't care about it. I only occasionally hear about it from strange internet comments that are far too focused on language particulars. reply ryao 18 hours agorootparentThat is surprising. I heard about the TIOBE index often about 15 years ago, but now that I think about it, I have not heard about it lately. I wonder if the rise of Python and ML has caused people to stop asking “what language should I learn”. That is the question the TIOBE index often was cited to answer. reply zahlman 19 hours agorootparentprevAs an aside: why is Java winning out over C# these days? When I first experienced C# I didn't want to go back. reply quotemstr 20 hours agorootparentprevRust is where the action is though. It's not just about cumulative SLOC weight, but about mindshare among the \"movers and shakers\" of the industry. Think of it as a prestige language, an acrolect, you should at least vaguely know so that you can participate in the most challenging conversations in the field. reply ryao 20 hours agorootparentThat is an interesting perspective. Here is my perspective. There are no popular projects that use Rust as a primary language. The current fashionable area of computers is machine learning. As far as high level languages go, you will see a mix of Python, C++ and perhaps a tiny bit of C there. Rust is nowhere to be seen. Your description would be better applied to C, C++ and Python. That is what the majority of popular software uses and people having challenging conversations are often using one of those languages. reply tyre 19 hours agorootparent> There are no popular projects that use Rust as a primary language. Servo is pretty notable and visible. ripgrep, influxdb, wasmer, deno. uv and ruff in the python ecosystem are written in rust. AWS, Cloudflare, Discord (iirc), and Microsoft have all adopted Rust extensively. As of late 2023 there are committed drivers in the Linux kernel written in rust. (Linux is pretty popular.) prior to those, only C and assembly were allowed. reply ryao 18 hours agorootparentNone of this contradicts what I said. reply quotemstr 15 hours agorootparentprevDon't forget Pydantic reply dwattttt 17 hours agorootparentprev> There are no popular projects that use Rust as a primary language You may be surprised to learn, Python's `cryptography` project is written (EDIT: maybe not primarily, it's hard to compare given dependencies) in Rust, and saw around 8.1 million downloads from PyPI yesterday. That puts it close to the top 20 (the 20th project comes in at 8.5m). reply nostradumbasp 2 hours agorootparentprevI would like to also point out that rust is boring as hell. Lots of otherwise ordinary people write super simple non-fancy programs using it too :) reply forrestthewoods 15 hours agorootparentprevIf you know C/C++ you could have learned to read Rust in the time you spent commenting in this thread. The number of new syntaxes you need to learn is quite minimal. reply pxmpxm 21 hours agoparentprev [–] I suspect like 9/10 of these type of articles are really just meant to be PR for rust. Like someone that wants to write Bart Simpsonensque \"rust is great\" over and over, but have to hide it into something more interesting. reply remram 21 hours agorootparentDo you think this article was written specifically as just PR for Rust? Who do you think is behind this? The government? reply estebarb 20 hours agorootparentClearly it is Big Compiler propaganda!reply curiouscoding 21 hours agorootparentprevRust is great :\") But no, this is actually part of my PhD research. The next step will be to use this in a fast suffix-array search algorithm. reply jackschultz 21 hours agorootparentGreat stuff. We get told O notation is what matters for data structures / algorithms, but improvements low level with memory and storage with things like rust is much more where improves can be made. These types of tricks for anctual run times are so valuable, and interesting to follow. reply curiouscoding 20 hours agorootparentOhh yeah, don't get me started in big-O... It was great while computers were not really a thing yet, but these days it's often so meaningless. We see papers with 2x speedup with a lot of novel algorithmic stuff that sell better than 10x speedup just by exploiting CPUs to the fullest. Even myself I kinda think theoretical contributions are cooler, and we really need to get rid of that (slightly exaggerating). reply ryao 18 hours agorootparentYour article led me to wonder if our b-trees would be faster if I switched the intra node operations to use Eytzinger ordered arrays: https://github.com/openzfs/zfs/commit/677c6f8457943fe5b56d7a... There are two ways to look at this Big O wise. One is that insertions and deletions would be asymptomatically faster since memmove() is a linear operation while bubble up/down are logarithmic operations. Look ups would not be any different asymptotically, but the constant factor might improve from being able to do prefetch. The other way is that the N is bounded, such that it is all O(1) and the difference is how big the constant factor is. I imagine I could implement it and benchmark it. However, my intuition is that the end result have lookups be marginally faster to the point of splitting hairs while insertions and deletions would be slower. While memmove() is a technically a linear time operation, it is a sequential operation that has a very low constant factor. The bubble up and bubble down operations needed to do insertions and deletions in a Eytzinger ordered array are technically random access, which has a higher constant factor. At some point, the Eytzinger ordered array operations should win, but that point is likely well beyond the size of a b-tree node. My reason for saying this is to say that Big O notation still matters, but understanding when the constant factor is significant is important. reply jackschultz 18 hours agorootparentprevSame with async and throwing threads at a problem. People love do those and think it's the right answer, but you can do a ton with smarter memory management and actually looking at what the code is doing lower level rather than abstractions. Video about this that was very interesting to follow and somewhat related to what you're doing: https://www.youtube.com/watch?v=5rb0vvJ7NCY reply Andys 19 hours agorootparentprevYou're really just exploiting hidden O(?) implementations inside the CPU, so it still applies, just less visibly. reply ryao 18 hours agorootparentHe is improving the constant factor in big O notation. University algorithm classes tend to ignore cases where the constant factor difference is significant enough to favor a asymptomatically slower algorithm. Matrix multiplication is the quintessential example of this, since a good implementation of the O(n^3) algorithm will outperform asymptotically faster algorithms, such as the famous O(n^2 * log(n) * log(log(n))) one that uses the FFT. At least, it outperforms it on matrix multiplications people actually do in practice. reply quotemstr 20 hours agorootparentprevRust is... okay. I still prefer C++'s template system to Rust generics, in part because Rust doesn't have specialization and won't for a while. Memory safety by default is a big enough win to make me overlook these nits. Really, though, most people most of the time should be writing managed code. reply stevenhuang 16 hours agorootparentprev [–] You suspect wrong. People are interested in things you're not. Get over it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the implementation and optimization of static search trees (S+ trees) for significantly faster searching of sorted data, achieving speeds 40 times faster than traditional binary search. - Optimization techniques such as batching, prefetching, and manual SIMD (Single Instruction, Multiple Data) are employed to enhance query throughput. - The article also explores various tree layouts, node sizes, and memory management strategies, with a discussion on future work like branchy search and interpolation search to further improve search efficiency."
    ],
    "commentSummary": [
      "The discussion highlights a shift from C/C++ to Rust for algorithmic content, especially in static search trees, due to Rust's safety and performance benefits.",
      "Rust's growing popularity in low-level programming is noted, with some users preferring C or pseudocode for accessibility, while others value Rust's modern features.",
      "The conversation also explores the potential of the Zig programming language and the challenges associated with learning new languages, reflecting the evolving landscape of programming languages."
    ],
    "points": 543,
    "commentCount": 171,
    "retryCount": 0,
    "time": 1735690083
  },
  {
    "id": 42565606,
    "title": "30% Drop In o1-Preview Accuracy When Putnam Problems Are Slightly Variated",
    "originLink": "https://openreview.net/forum?id=YXnwlZe0yf&noteId=yrsGpHd0Sf",
    "originBody": "Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning Aryan Gulati, Brando Miranda, Eric Chen, Emily Xia, Kai Fronsdal, Bruno de Moraes Dumont, Sanmi Koyejo Published: 10 Oct 2024, Last Modified: 31 Oct 2024MATH-AI 24EveryoneRevisionsBibTeXCC BY 4.0 Keywords: Benchmarks, Large Language Models, Mathematical Reasoning, Mathematics, Reasoning, Machine Learning TL;DR: Putnam-AXIOM is a challenging mathematical reasoning benchmark for LLMs, revealing significant reasoning performance gaps and the impact of data contamination. Abstract: As large language models (LLMs) continue to advance, many existing benchmarks designed to evaluate their reasoning capabilities are becoming saturated. Therefore, we present the Putnam-AXIOM Original benchmark consisting of 236 mathematical problems from the William Lowell Putnam Mathematical Competition, along with detailed step-by-step solutions. To preserve the Putnam-AXIOM benchmark's validity and mitigate potential data contamination, we created the Putnam-AXIOM Variation benchmark with functional variations of 52 problems. By programmatically altering problem elements like variables and constants, we can generate unlimited novel, equally challenging problems not found online. We see that almost all models have significantly lower accuracy in the variations than the original problems. Our results reveal that OpenAI's o1-preview, the best performing model, achieves merely 41.95% accuracy on the Putnam-AXIOM Original but experiences around a 30% reduction in accuracy on the variations' dataset when compared to corresponding original problems. Concurrent Submissions: ICLR 2025 Submission Number: 86 Loading",
    "commentLink": "https://news.ycombinator.com/item?id=42565606",
    "commentBody": "30% Drop In o1-Preview Accuracy When Putnam Problems Are Slightly Variated (openreview.net)422 points by optimalsolver 10 hours agohidepastfavorite380 comments jerf 6 hours agoI remember when this stuff was all coming out and people were finally excited about ChatGPT getting the problem with \"which is heavier, a 10 pound bag of feathers or a 10 pound bag of bricks?\" problem correct. But of course it got it correct. It was in the training set. Vary the problem slightly by just changing the nouns, or changing the numbers so that one in fact was heavier than the other, and performance went all over the map. I just went to chatgpt.com and put into the chat box \"Which is heavier, a 9.99-pound back of steel ingots or a 10.01 bag of fluffy cotton?\", and the very first answer I got (that is, I didn't go fishing here) was The 9.99-pound bag of steel ingots is heavier than the 10.01-pound bag of fluffy cotton by a small margin. Although the cotton may appear larger due to its fluffy nature, the steel ingots are denser and the weight of the steel bag is 9.99 pounds compared to the 10.01 pounds of cotton. So, the fluffy cotton weighs just a tiny bit more than the steel ingots. Which, despite getting it both right and wrong, must still be graded as a \"fail\". If you want to analyze these thing for their true capability, you need to make sure you're out of the training set... and most of the things that leap to your mind in 5 seconds are leaping to your mind precisely because they are either something you've seen quite often or something that you can easily think of and therefore many other people have easily thought of them as well. Get off the beaten path a bit and the math gets much less impressive. reply sholladay 5 hours agoparentChatGPT Plus user here. The following are all fresh sessions and first answers, no fishing. GPT 4: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. The type of material doesn’t affect the weight comparison; it’s purely a matter of which bag weighs more on the scale. GPT 4o: The 10.01-pound bag of fluffy cotton is heavier. Weight is independent of the material, so the bag of cotton’s 10.01 pounds outweighs the steel ingots’ 9.99 pounds. GPT o1: Since both weights are measured on the same scale (pounds), the 10.01-pound bag of cotton is heavier than the 9.99-pound bag of steel, despite steel being denser. The key is simply that 10.01 pounds exceeds 9.99 pounds—density doesn’t affect the total weight in this comparison. reply mjburgess 3 hours agorootparentSo do what the commenter suggests and make irrelevant permutations to the input to find when it fails. ie., engage in hypothesis testing rather than confirmation bias. If a system has the capability to solve problems of {parts1...parts_n}, then it only has that capability if irrelevant permutations {parts1..parts2'...parts_n} make no difference. Its very obvious that such permutations can destory such apparent capabilities. reply jdietrich 2 hours agorootparentI've just tested a number of permutations with Claude 3.5 Sonnet. It correctly answered all variants I tried on the first attempt, as follows: Which is heavier, a 9.99 kilogram tungsten cube or a 10.01 kilogram block of aerogel? Which is heavier, 10,000 steel balls weighing 0.999 grams each or 10,000 polystyrene balls weighing 1.001 grams each? Which is heavier, a 10.01kg block of steel on Venus or a 9.99kg bag of feathers on Earth? Which is heavier, a 10cm^3 block of steel or a 100cm^3 block of balsa wood? Which is heavier, a golf ball made of steel or a baseball made of lithium? In all cases, Claude clearly used CoT and reasoned out the problem in full. I would be interested in seeing if anyone can find any variant of this problem that stumps any of the leading LLMs. I'm bored of trying. reply mjburgess 39 minutes agorootparentHey, ChatGPT please write me a python program which randomly samples from various materials and various weights then poses a problem to the ChatGPT 4o API -- the goal is to find cases where the LLM fails to obtain the correct answer.... reply Isinlor 28 minutes agorootparentprevBTW - the model may be wrong depending on the example. More voluminous objects displace more air and due to buoyancy are lighter for the same mass. The proper way to ask it would be to ask which object has more mass. reply wongarsu 2 hours agorootparentprevIf GP's hypothesis was \"it fails for small variations of the input, like this one\", then testing that hypothesis with that exact variation on a couple models seems fair and scientific. Testing it with more variations until one fails feels a bit like p-hacking. You'd need to engage in actual statistics to get reliable results from that, beyond \"If I really try, I can make it fail\". Which would be a completely different hypothesis than the one presented at the start reply roughly 2 hours agorootparentExcept that if the model genuinely was reasoning about the problem, you could test it with every variation of materials and weights in the world and it would pass. Failing that problem at all in any way under any conditions is a failure of reasoning. reply jdietrich 2 hours agorootparentBy that logic, humans can't genuinely reason, because they're often fooled by counter-intuitive problems like Monty Hall or the Birthday Problem, or sometimes just make mistakes on trivial problems. reply wongarsu 2 hours agorootparentprevWe are pretty certain that humans can reason, yet they are sometimes wrong. Even if you give them the same problem over and over again with slight variations. LLMs get things wrong due to different factors than humans (humans lose focus, LLMs have randomness applied when sampling their responses to improve results). But clearly we have to choose a goal somewhat below 100% if we want a test that doesn't conclude that humans are incapable of reasoning. reply roughly 1 hour agorootparentThe difference is we _know_ that LLMs are fancy stochastic models, we don't know that they're capable of reasoning, and the null hypothesis is that they're not (because we know what they _are_ - we built them) - any \"reasoning\" is an emergent property of the system, not something we built them to do. In that case, evidence they're not reasoning - evidence they're stochastic parrots doing a performance of reasoning - weighs heavier, because the performance of reasoning fits into what we know they can do, whereas genuine reasoning would be something new to the model. There's deeper philosophical questions about what reasoning actually _is_, and LLMs have made those sharper, because they've shown it's clearly possible for a complex statistical model to generate words that look like reasoning, but the question is whether there's a difference between what they're doing and what humans are doing, and evidence that they're _not_ reasoning - evidence that they're just generating words in specific orders - weighs heavily against them. reply Isinlor 6 minutes agorootparentIt's widely accepted that reasoning is not a binary skill. You can make mistakes and still reason. Very often people given the same premises will disagree in thier reasoning as we are doing right here. wongarsu 1 hour agorootparentprevWe haven't coded LLMs to be stochastic models, we coded them to predict text with any method gradient decent finds on a transformer architecture. That's not exactly the same. But more importantly, if you want to show that LLMs can't reason you obviously have to use a test that when applied to humans would show that humans can reason. Otherwise your test isn't testing reasoning but something more strict. reply whakim 1 hour agorootparentprevI’m not really sure what you’re trying to say here - that LLMs don’t work like human brains? We don’t need to conduct any analyses to know that LLMs don’t “know” anything in the way humans “know” things because we know how LLMs work. That doesn’t mean that LLMs aren’t incredibly powerful; it may not even mean that they aren’t a route to AGI. reply zahlman 31 minutes agorootparent>We don’t need to conduct any analyses to know that LLMs don’t “know” anything in the way humans “know” things because we know how LLMs work. People, including around HN, constantly argue (or at least phrase their arguments) as if they believed that LLMs do, in fact, possess such \"knowledge\". This very comment chain exists because people are trying to defend against a trivial example refuting the point - as if there were a reason to try. > That doesn’t mean that LLMs aren’t incredibly powerful; it may not even mean that they aren’t a route to AGI. I don't accept your definition of \"intelligence\" if you think that makes sense. Systems must be able to know things in the way that humans (or at least living creatures) do, because intelligence is exactly the ability to acquire such knowledge. It boggles my mind that I have to explain to people that sophisticated use of language doesn't inherently evidence thought, in the current political environment where the Dead Internet Theory is taken seriously, elections are shown over and over again to be more about tribalism and personal identity than anything to do with policy, etc. reply nwienert 2 hours agorootparentprevI feel like I'm almost 100% certain that the smart guys at OpenAI have added many more variations of the problem to their training set since OP did his failing test, so it doesn't surprise me at all to know that this exact one now passes. In fact, in my use of o1 it's incredibly clear that it still has the same problems. It's incredibly common that the second I ask for someone even slightly outside the training set, it's more likely to \"round\" to some wrong solution in the training set, rather than use any sort of human-like reasoning to figure out the right answer (often the right answer isn't hard to get, just not found in a Google search). reply bee_rider 1 hour agorootparentCan’t really do science with closed source software, right? Who knows what’s in there. reply zahlman 42 minutes agorootparentprevWe aren't testing whether the model's results are stable or correct for a given class of problem. The goal is to establish whether the model can reason. Nothing capable of reasoning would contradict itself so blatantly and in such a short span while failing to indicate any kind of uncertainty. reply jack_pp 2 hours agorootparentprevIt's not p-hacking, he's right. You're both right. First test the same prompt on different versions then the ones that got it right go to the next round, variations on the prompt reply otabdeveloper4 3 hours agorootparentprev> ...engage in hypothesis testing rather than confirmation bias Please leave the premises, sir. We don't take kindly to luddites here. reply dullcrisp 3 hours agorootparentTough crowd reply david-gpu 2 hours agorootparentLots of other websites are more appropriate for meme jokes. reply dullcrisp 1 hour agorootparentLike I said. reply blibble 3 hours agorootparentprevthey've likely read this thread and adjusted their pre-filter to give the correct answer reply escape_goat 1 hour agorootparentprevI asked ChatGPT-4 mini the previous comment's question (\"\"Which is heavier, a 9.99-pound back of steel ingots or a 10.01 bag of fluffy cotton?\") in new incognito tabs until I got an incorrect result. It only took four tries. 1: \"The 10.01-pound bag of fluffy cotton would be heavier. Even though cotton is much less dense than steel, the weight of the cotton bag is 10.01 pounds, while the steel ingot bag weighs 9.99 pounds, making the cotton bag the heavier of the two by 0.02 pounds.\" 2: \"The 10.01-pound bag of fluffy cotton is heavier. Even though the steel ingots are denser and more compact, the cotton weighs more at 10.01 pounds compared to the steel ingots' 9.99 pounds. The difference is only 0.02 pounds, but in terms of weight, the cotton bag is heavier.\" 3: \"The 10.01-pound bag of fluffy cotton is heavier. Despite cotton being less dense than steel, the weight is determined by the total mass, not the material's density. So, since the cotton bag weighs 10.01 pounds and the steel ingot bag weighs 9.99 pounds, the cotton bag is heavier by 0.02 pounds.\" 4: \"The 9.99-pound bag of steel ingots is heavier. It weighs 9.99 pounds, while the bag of fluffy cotton weighs 10.01 pounds. Despite the cotton being fluffier and taking up more space, the steel ingots are still lighter by 0.02 pounds.\" reply themgt 1 hour agoparentprevI just asked Claude 3.5 Sonnet, which appears to have improved its response with CoT but there's mistakes that demonstrate the model doesn't really \"understand\": Q: A woman and her son are in a car accident. The woman is sadly killed. The boy is rushed to hospital. When the doctor sees the boy he says \"I can't operate on this child, he is my son\". How is this possible? C: Let me think about this step by step: A woman and her son are in an accident The woman (the mother) dies The boy is taken to hospital A doctor says they can't operate because the boy is their son But the mother is dead... Ah! The doctor is the boy's father. This is a classic riddle that highlights gender bias - many people assume doctors must be men, but don't initially consider that the doctor could be the father. Alternatively, the doctor could be the boy's other mother in a same-sex relationship, though this wasn't the original intent of the traditional riddle. reply whimsicalism 6 hours agoparentprevhttps://chatgpt.com/share/67756897-8974-8010-a0e0-c9e3b3e91f... so far o1-mini has bodied every task people are saying LLMs can’t do in this thread reply jerf 6 hours agorootparentThat appears to be the same model I used. This is why I emphasized I didn't \"go shopping\" for a result. That was the first result I got. I'm not at all surprised that it will nondeterministically get it correct sometimes. But if it doesn't get it correct every time, it doesn't \"know\". (In fact \"going shopping\" for errors would still even be fair. It should be correct all the time if it \"knows\". But it would be different if I was fishing over and over and over and finally got one, versus the first time I asked.) Edit: It appears it isn't the model I used. The point holds, though, you need to make sure you're off the training set for it to matter. This isn't a \"ChatGPT can't do that\" post as some are saying, it's more a \"you aren't asking what you think you're asking\" post. You get the same problem in a human context in things like code interviews. If you ask an interviewee the exact question \"how do you traverse a binary tree in a depth-first manner\", you aren't really learning much about the interviewee. It's a bad interview question. You need to get at least a bit off the beaten trail to do any sort of real analysis. reply elliotto 3 hours agorootparentCould you share the exact chat you used for when it failed? There is a share chat button on openai. It's very difficult to be an AI bull when the goalposts are moving so quickly that ai answering core correctly across multiple models is brushed off as 'nondeterministically getting it correct sometimes' reply stefan_ 2 hours agorootparentWhy? Did a grocery store self checkout ever fail to calculate sales tax? Do I need to run a study on that? The people selling this could not make a car drive but now its AGI. reply dialup_sounds 5 hours agorootparentprevI believe this is just a case of OpenAI's naming scheme being weird and confusing. The default model I see on chatgpt.com is GPT 4o-mini, which is not o1-mini. OpenAI describes GPT 4o-mini as \"Our fast, affordable small model for focused tasks\" and o1/o1-mini as \"Reasoning models that excel at complex, multi-step tasks\". reply whimsicalism 6 hours agorootparentprevyou sure? i just asked o1-mini (not 4o mini) 5 times in a row (new chats obviously) and it got it right every time perhaps you stumbled on a rarer case but reading the logs you posted this sounds more like a 4o model than an o1 because it’s doing its thinking in the chat itself plus the procedure you described would probably get you 4o-mini reply 7thpower 3 hours agorootparentMay be unrelated, but I have been having a lot of issues lately with ChatGPT letting me select a model (o1) and silently switching to 4o. This is coming off my TWO DAY cooldown on o1 usage, which is frustrating. reply JumpCrisscross 5 hours agorootparentprev> just asked o1-mini (not 4o mini) 5 times in a row (new chats obviously) and it got it right every time Could you try playing with the exact numbers and/or substances? reply whimsicalism 5 hours agorootparentgive me a query and i’ll ask it, but also i don’t want to burn through all of my o1mini allocation and have to use the pay-as-you-go API. reply drivebyhooting 4 hours agorootparent> What is heavier a liter of bricks or a liter of feathers? >> A liter of bricks and a liter of feathers both weigh the same—1 kilogram—since they each have a volume of 1 liter. However, bricks are much denser than feathers, so the bricks will take up much less space compared to the large volume of feathers needed to make up 1 liter. The difference is in how compactly the materials are packed, but in terms of weight, they are identical. reply whimsicalism 4 hours agorootparenthttps://chatgpt.com/share/677583a3-526c-8010-b9f9-9b2a3374da... o1-mini best-of-1 reply JumpCrisscross 5 hours agorootparentprev> give me a query and i’ll ask it Which is heavier: an 11kg bag of lint or a 20lb bag of gold? reply whimsicalism 5 hours agorootparentyeah it gets it https://chatgpt.com/share/67757720-3c7c-8010-a3e9-ce66fb9f17... e: cool, this gets downvoted reply blharr 3 hours agorootparentIt got it right, but an interesting result that it rambled on about monetary value for... no reason. > While the lint bag is heavier in terms of weight, it's worth mentioning that gold is significantly more valuable per pound compared to lint. This means that even though the lint bag weighs more, the gold bag holds much greater monetary value. reply JumpCrisscross 2 hours agorootparentLegal said someone might sell a bag of gold for one of lint without it. reply thaumasiotes 3 hours agorootparentprev>> so far o1-mini has bodied every task people are saying LLMs can’t do in this thread > give me a query and i’ll ask it Here's a query similar to one that I gave to Google Gemini (version unknown), which failed miserably: ---query--- Steeleye Span's version of the old broadsheet ballad \"The Victory\" begins the final verse with these lines: Here's success unto the Victory / and crew of noble fame and glory to the captain / bold Nelson was his name What does the singer mean by these lines? ---end query--- Italicization is for the benefit of HN; I left that out of my prompt. reply ted_dunning 15 minutes agorootparentHmm... Gemini (1.5 Flash) just aced that exact question for me: These lines celebrate the victory of the British ship HMS Victory, led by the famous Admiral Lord Nelson, in the Battle of Trafalgar in 1805. \"Here's success unto the Victory\": This line directly praises the ship itself, acknowledging its role in the successful battle. \"and crew of noble fame\": This recognizes the bravery and skill of the sailors who served aboard the Victory. \"and glory to the captain\": This line specifically honors Admiral Nelson, the captain of the Victory, for his leadership and strategic brilliance in the battle. \"bold Nelson was his name\": This emphasizes Nelson's courage and daring, which were legendary. The lines express admiration for the ship, its crew, and most importantly, Admiral Nelson, who became a national hero in Britain for his victory at Trafalgar. reply whimsicalism 2 hours agorootparentprevi'd prefer an easily verifiable question rather than one where we can always go \"no that's not what they really meant\" but someone else with o1-mini quota can respond reply mikeruiz 1 hour agorootparent“They’re toasting Admiral Nelson’s ship (HMS Victory) and its valiant crew, hailing the ship’s successes and Nelson’s heroism. In other words, the singer is offering tribute—“success unto the Victory”—to the vessel and its famed sailors, and “glory to the captain” who led them, namely the celebrated Admiral Horatio Nelson.” …but to your point, no idea if the artist intended some more obscure reference. o1-pro was also able to produce a relatively complete version of original source, though, amusingly, referred to it as a ‘broadside’ rather than ‘broadsheet’. Appropriate given the context! reply thaumasiotes 2 hours agorootparentprevIt's not a difficult or tricky question. reply mortehu 6 hours agorootparentprevWhile this may be true, it's a very common problem that people who want to demonstrate how bad a model is fail to provide a direct link or simply state the name of the model. reply chongli 5 hours agorootparentOpenAI is not doing us any favours by using confusing naming schemes for their models and obscuring which models people are actually working with. If I didn’t know any better, I’d say OpenAI doesn’t want us doing these tests accurately and is trying to hide something. reply whimsicalism 5 hours agorootparentit’s extremely easy to see which model you are using. one’s own… difficulties understanding are not a conspiracy by OpenAI reply chongli 5 hours agorootparentIt does not show the model version anywhere on the page on chatgpt.com, even when logged in. reply qup 4 hours agorootparentYes it does, at the top of every chat there is a drop-down to select the model, which displays the current model. It's been a constant part of the UI since forever. reply chongli 3 hours agorootparentNo, it only says \"ChatGPT Plus (Upgrade)\" or \"ChatGPT\". Maybe it's different if you have a paid account? reply whimsicalism 3 hours agorootparentif i go to chatgpt.com on my phone not logged on at all it tells me very prominently at the top that i am using 4o mini reply bcrosby95 3 hours agorootparentLogged in, non paid account, on a desktop, for me, it's exactly as the person you're replying to has stated. If I log out, it shows 4o mini, and when I try to change it, it asks me to login or sign in rather than giving me any options. When I use enough chatgpt when logged in it gives me some nebulous \"you've used all your xyz tokens for the day\". But other than that there is no real signal to me that I'm getting a degraded experience. It's really just confusing as hell. reply blharr 3 hours agorootparentprevSomeone else in this thread said, > With a free account the model it claims to be using is \"4o auto\", which is not a model but apparently an attempt to automatically decide models for you to be more cost effective. reply lukeschlather 5 hours agorootparentprevI usually test models using the OpenAI API which doesn't offer links the way I think you mean. If I provide some output I got from a particular model you're just going to have to take my word for it. reply 4ad 5 hours agorootparentYou can use https://lluminous.chat (bring your own key) to link to chats using any model across all LLMs. reply whimsicalism 5 hours agorootparentopen router is the more standard solution reply Jerrrry 5 hours agorootparentprevThey need to provide an small hash with the api result that can be verified by others. reply deeviant 6 hours agorootparentprevI don't believe that is the model that you used. I wrote a script and pounded 01 mini and gpt 4 with a wide vareity of tempature and top_p parameters, and was unable to get it to give the wrong answer a single time. Just a whole bunch of: (openai-example-py3.12) :~/code/openAiAPI$ python3 featherOrSteel.py Response 1: A 10.01-pound bag of fluffy cotton is heavier than a 9.99-pound bag of steel ingots. Response 2: A 10.01-pound bag of fluffy cotton is heavier than a 9.99-pound bag of steel ingots. Response 3: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Response 4: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Response 5: A 10.01-pound bag of fluffy cotton is heavier than a 9.99-pound bag of steel ingots. Response 6: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Response 7: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Response 8: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Response 9: The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Response 10: A 10.01-pound bag of fluffy cotton is heavier than a 9.99-pound bag of steel ingots. All responses collected and saved to 'responses.txt'. Script with one example set of params: import openai import time import random # Replace with your actual OpenAI API key openai.api_key = \"your-api-key\" # The question to be asked question = \"Which is heavier, a 9.99-pound bag of steel ingots or a 10.01-pound bag of fluffy cotton?\" # Number of times to ask the question num_requests = 10 responses = [] for i in range(num_requests): try: # Generate a unique context using a random number or timestamp, this is to prevent prompt caching random_context = f\"Request ID: {random.randint(1, 100000)} Timestamp: {time.time()}\" # Call the Chat API with the random context added response = openai.ChatCompletion.create( model=\"gpt-4o-2024-08-06\", messages=[ {\"role\": \"system\", \"content\": f\"You are a creative and imaginative assistant. {random_context}\"}, {\"role\": \"user\", \"content\": question} ], temperature=2.0, top_p=0.5, max_tokens=100, frequency_penalty=0.0, presence_penalty=0.0 ) # Extract and store the response text answer = response.choices[0].message[\"content\"].strip() responses.append(answer) # Print progress print(f\"Response {i+1}: {answer}\") # Optional delay to avoid hitting rate limits time.sleep(1) except Exception as e: print(f\"An error occurred on iteration {i+1}: {e}\") # Save responses to a file for analysis with open(\"responses.txt\", \"w\", encoding=\"utf-8\") as file: file.write(\"\".join(responses)) print(\"All responses collected and saved to 'responses.txt'.\") reply zaroth 3 hours agorootparentDownvoted for… too conclusively proving OP wrong? reply gmueckl 2 hours agorootparentDown voted for not actually countering the argument in question? The script doesn't alter the phrasing of the question itself. It just generates a randomized, irrelevant preamble. reply deeviant 1 hour agorootparentWell, I understood the argument in question to be: was it possible for the model to be fooled by this question, not was it possible to prompt engineer it into failure. The parameter space I was exploring, then, was the different decoding parameters available during the invocation of the model, with the thesis that if were possible to for the model to generate an incorrect answer to the question, I would be able to replicate it by tweaking the decoding parameters to be more \"loose\" while increasing sample size. By jacking up temperature while lowering Top-p, we see the biggest variation of responses and if there were an incorrect response to be found, I would have expected to see in the few hundred times I ran during my parameter search. If you think you can fool it by slight variations on the wording of the problem, I would encourage you to perform a similar experiment as mine and prove me wrong =P reply qup 4 hours agorootparentprevIt's so weird that people use questions that are well-known for duping humans, who we all consider to be general intelligence. Getting this question wrong doesn't say much about the intelligence of humans, why would it say something about the AI? reply zahlman 12 minutes agorootparentWe use variations on questions that are well known for duping inattentive humans, to test a system that we expect a priori to be incapable of such inattention. Unless \"getting easy things wrong sometimes\" is an inherent property of intelligence, we should expect that a properly \"intelligent\" computerized system would never err on problems far below its level of comprehension - unless we had some reason to believe it \"wanted to\", and as of yet I see no reason to believe this is even possible in principle. Humans err, broadly speaking, for two reasons: genuinely reaching the limits of their comprehension, or trusting \"system 1\" (in Kahneman's analysis) too much. reply flatline 4 hours agorootparentprevBecause for things like the Putnam questions, we are trying to get the performance of a smart human. Are LLMs just stochastic parrots or are they capable of drawing new, meaningful inferences? We keep getting more and more evidence of the latter, but things like this throw that into question. reply xtracto 5 hours agorootparentprevSo, there is this meme going around in Mexico about a previous president who in an interview said \"we will land in about 1 minute, no, less about 5\" Does this proves he is not an intelligent being? Is he stupid? This he had a lapse? Would we judge his intelligence for that? reply NewsaHackO 6 hours agorootparentprevThis happens literally every time. Someone always says \"ChatGPT can't do this!\", but then when someone actually runs the example, chatGPT gets it right. Now what the OP is going to do next is proceed to move goalposts and say like \"but umm I just asked chatgpt this, so clearly they modified the code in realtime to get the answer right\" reply jorvi 3 hours agorootparentPrompt: In the Netherlands, in terms of drinks, is there a particular spirit that represents the country? > Yes, in the Netherlands, jenever (also known as genever) is the traditional spirit that represents the country. Jenever is a type of Dutch gin that has a distinctive flavor, often made from malt wine and flavored with juniper berries. It has a long history in the Netherlands, dating back to the 16th century, and is considered the precursor to modern gin. > Jenever comes in two main types: oude (old) jenever, which has a richer, maltier flavor and is often aged in wooden casks, and jonge (young) jenever, which is lighter and has a more neutral taste. Both types can be enjoyed straight or used in cocktails. > In addition to jenever, the Netherlands is also known for its liqueurs, such as advocaat, a rich and creamy drink made from eggs, sugar, and brandy, often enjoyed as a dessert or in cocktails. However, jenever remains the most iconic spirit associated with Dutch culture. This is completely wrong. Jenever certainly is very Dutch, but no one would say it is iconic as the Dutch spirit. For example, if you asked up north in Friesland, they would say Berenburg. This happens literally every time. Someone always says \"ChatGPT can do this!\", but then within one or two prompts, its gets it wrong. reply elif 2 hours agorootparent'Berenberg is made by adding herbs to jenever' From your comment it would seem that you are disputing jenever's popularity by saying jenever is more popular... Perhaps it was a good faith mistake? If so, that would imply that the AI knows more about jenever than you? reply ipaddr 2 hours agorootparentprevSo you believe they are incorrect because regionally some area would select something different because it represented that area. But your question asked nationally.. is there a better answer than the one they gave? Were you expecting a no? reply zahlman 9 minutes agorootparentThe point is that there is no correct national answer, because the locals don't see it as a matter of national identity. What's expected is an ability to identify trick questions, i.e., to recognize fundamental problems in the phrasing of a question rather than trying to provide a \"helpful\" answer at all costs. This corresponds to one of the many reasons LLM output is banned on Stack Overflow. reply ludwik 2 hours agorootparentprevBut what does this have to do with reasoning? Yes, LLMs are not knowledge bases, and seeing people treat them as such absolutely terrifies me. However, I don’t see how the fact that LLMs often hallucinate “facts” is relevant to a discussion about their reasoning capabilities. reply zahlman 7 minutes agorootparent\"Hallucinating a fact\" that isn't in the training set and is also illogical, is exactly what a failure to reason correctly looks like. reply stocknoob 39 minutes agorootparentprevSimilarly, in every thread there’s an AI skeptic who says LLMs are “useless” for coding, and never provides an example query for what they were trying. reply JumpCrisscross 5 hours agorootparentprev> Someone always says \"ChatGPT can't do this!\", but then when someone actually runs the example, chatGPT gets it right I mean, if I had OpenAI’s resources I’d have a team tasked with monitoring social to debug trending fuck-ups. (Before that: add compute time to frequently-asked novel queries.) reply anamexis 6 hours agorootparentprevHow is that moving the goalposts? reply whimsicalism 6 hours agorootparentprevyeah… that’s hn for you. that said, i don’t think this is a good test - i’ve seen it circling on twitter for months and it is almost certainly trained on similar tasks reply devoutsalsa 1 hour agoparentprevI tried Claude and got this… * What’s heavier? 9.99 kg of super dense lead or 10 kg fluffy feathers?* Let me think about this step by step: 1. We're comparing two masses: * 9.99 kg of lead * 10 kg of feathers 2. The density of the materials doesn't affect their mass: * While lead is indeed much denser than feathers * A kilogram is a unit of mass, not volume * 1 kg of any material has the same mass as 1 kg of any other material 3. We can directly compare the numbers: * 10 kg > 9.99 kg Therefore, 10 kg of feathers is heavier than 9.99 kg of lead. The feathers would take up much more space (volume) due to being less dense, but they have a greater mass. reply jstummbillig 5 hours agoparentprevFYI: If you do that without a subscrpition, you currently (most likely) get a response generated through 4o-mini — which is not any of their reasoning models (o1, o1-mini or previously o1-preview) of the branch discussed in the linked paper. Notably, it's not even necessarily 4o, their premiere \"non-reasoning\"-model, but likely the cheaper variant: With a free account the model it claims to be using is \"4o auto\", which is not a model but apparently an attempt to automatically decide models for you to be more cost effective. Without a ChatGPT subscription you can't select a specific model anymore, not even rate limited, as was previously possible. reply jsheard 5 hours agorootparentThere doesn't seem to be a way to choose a model up-front with a free account, but after you make a query you can click on the \"regenerate\" button and select whether to try again with \"auto\", 4o, or 4o-mini. At least until you use 4o too many times and get rate limited. reply evertedsphere 3 hours agorootparentyou can select the model in the header bar when you start a chat: the name of the currently selected model can be clicked to reveal a dropdown reply jstummbillig 2 hours agorootparentAre you on the free version? Because for me it did not show there, only on the paid one. reply jsheard 3 hours agorootparentprevThat option isn't there for me, maybe it's an A/B test thing. reply jstummbillig 4 hours agorootparentprevAh, interesting! reply mmaunder 5 hours agoparentprevI've posted this before and I know it's a cliche, but this really is Goodhart's Law at work with the benchmarks becoming targets. reply collinvandyck76 6 hours agoparentprevI reproduced this on Claude Sonnet 3.5, but found that changing your prompt to \"Which is heavier, a 9.99-pound back of steel ingots or a 10.01-pound bag of fluffy cotton?\" corrected its reasoning, after repeated tests. For some reason it was not able to figure out that \"10.01\" referred to pounds. reply oktoberpaard 4 hours agorootparentThis is the first response that I got from Claude with an exact copy and paste of the question: Let me think about this step by step: 1. We're comparing two masses: * Steel ingots: 9.99 pounds * Cotton: 10.01 pounds 2. The cotton bag has a mass of 10.01 pounds, while the steel bag has a mass of 9.99 pounds 3. While steel is much denser than cotton (meaning it takes up less space per pound), this doesn't affect the weight - a pound is a pound regardless of material 4. 10.01 is greater than 9.99 by 0.02 pounds Therefore, the 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. The cotton may take up much more space, but when we're just comparing weights, density doesn't matter - only the mass does. reply bufferoverflow 6 hours agorootparentprevYou wrote \"back\" instead of \"bag\". reply collinvandyck76 5 hours agorootparentAh, good catch -- I had just copied the OP. Changing it to bag instead of back doesn't seem to change much. It still oscillates between the right and wrong answer, versus qualifying the 10.01 value as pounds, which has not yet given me the wrong answer (small sample size, of course). reply qwertox 4 hours agoparentprevAs long as an LLM is capable of inserting \"9.99 > 10.01?\" into an evaluation tool, we're on a good way. It feels a bit like \"if all you have is a hammer, everything looks like a nail\", where we're trying to make LLMs do stuff which it isn't really designed to do. Why don't we just limit LLMs to be an interface to use other tools (in a much more human way) and train them to be excellent at using tools. It would also make them more energy efficient. But it's OK if we currently try to make them do as much as possible, not only to check where the limits are, but also to gain experience in developing them and for other reasons. We just shouldn't expect them to be really intelligent. reply riffraff 4 hours agorootparent> As long as an LLM is capable of inserting \"9.99 > 10.01?\" into an evaluation tool, we're on a good way chatgpt will switch to python for some arithmetic with the result that you get floating point math issues when a 8yo will get the result right. I think \"switch to a tool\" still requires understanding of which tool to get a reliable result, which in turn means understanding the problem. It's an interesting issue. reply maratc 1 hour agoparentprevStill waiting for some reasoning about an upward buoyancy force on the bags, which is equal to the weight of the air displaced by the bags, and the force acting on the cotton is bigger simply because the bag of cotton displaces more air (because it \"appears larger due to its fluffy nature\".) reply anon946 2 hours agoparentprevAdd some extra information, and it gets confused. This is 4o. https://chatgpt.com/share/67759723-f008-800e-b0f3-9c81e656d6... One might argue that it's impossible to compress air using known engineering, but that would be a different kind of answer. reply amluto 2 hours agorootparentIt seems more like ChatGPT was asked a rather bizarre question with far too little detail to make sense, and ChatGPT failed to notice or to ask for more information. Although it did get rather impressively confused about the pressure of the air. reply F7F7F7 45 minutes agorootparent“Failed to notice” is a hilariously weird way of talking about tokenization. reply dogcomplex 38 minutes agoparentprevlol no, with a small amount of generally-applicable prompt-fu it answers with a ton of nuance that perfectly encapsulates the problem: https://chatgpt.com/share/6775b99d-2220-8003-993b-8dd008a97f... reply Horffupolde 3 hours agoparentprev10 pounds of bricks is actually heavier than 10 pounds of feathers. reply AnimalMuppet 2 hours agorootparentCan you explain? An ounce of gold is heavier than an ounce of feathers, because the \"ounce of gold\" is a troy ounce, and the \"ounce of feathers\" is an avoirdupois ounce. But that shouldn't be true between feathers and bricks - they're both avoirdupois. reply Horffupolde 2 hours agorootparentFeathers are less dense so they have higher buoyancy in air, reducing their weight. reply chongli 1 hour agorootparentPounds are a unit of weight, not of mass. 10 lbs of feathers is whatever amount of feathers causes a scale to display 10 lbs. If the scale also displays 10 lbs for the quantity of bricks, then they weigh the same, regardless of any differences in mass. reply wongarsu 1 hour agorootparentIs this still true? I thought pounds are now defined in terms of kilograms (about 0.453)? Because kilograms are definitely a unit of mass, not weight. Or is the pound defined as some amount of kilograms at a specific point on earth, in a specific phase of the moon? reply chongli 47 minutes agorootparentIt seems the pound has since been redefined and split into separate units: pound mass and pound force, the former in terms of kilograms (1 lb = 0.45359237 kg) and the latter in terms of the force exerted by one pound of mass in earth’s gravitational field (standard g = 9.80665m/s^2). So using the word pound without qualification is ambiguous in contexts where it’s not clear whether mass or force is meant. reply 9rx 2 hours agorootparentprevAccording to the dictionary, \"heavier\" can refer to weight or density. In their typical form, bricks are heavier (more dense) than feathers. But one should not make assumptions before answering the question. It is, as written, unanswerable without followup questions. reply gtirloni 5 hours agoparentprevo1. prompt> Which is heavier, a 9.99-pound back of steel ingots or a 10.01 bag of fluffy cotton? Please state in your answer what's the difference in grams. answer> The 10.01-pound bag of cotton is heavier. The difference is 0.02 pounds, which is roughly 9.07 grams (using 1 pound ≈ 453.59237 grams). Reference • National Institute of Standards and Technology (NIST): Conversion Factors reply Leary 6 hours agoparentprevDeepseek got it right: \"A 10.01-pound bag of fluffy cotton is heavier than a 9.99-pound pack of steel ingots. Even though steel is denser and takes up much less space, the weight is determined by the mass, and 10.01 pounds is greater than 9.99 pounds.\" reply OutOfHere 5 hours agorootparentThe issue with the commercial Deepseek API is that it supports a context length of only 64k, whereas GPT supports at least 128k. reply kqr 4 hours agoparentprevShows the importance of chain of thought! Forcing it to commit to an answer without deliberation is not playing to its strength. reply jiggawatts 1 hour agoparentprevA real acid test is to use numbers that confuse LLMs such as: “Which is heavier: a bag with 9.9 pounds of fluff or a bag with 9.11 pounds of steel block?” Try swapping the numbers and the materials, run each test at least 10x times. reply deadbabe 1 hour agoparentprevIf you define a new universe with physical laws that are different from our own, performance will also suffer because there is no training data for that custom universe. While some may say this is cheating, a human would be able to deduce correct answers by understanding the deep implications of the new physical laws in that custom universe. reply thaumasiotes 3 hours agoparentprev> the problem with \"which is heavier, a 10 pound bag of feathers or a 10 pound bag of bricks?\" Interestingly, the variation of this problem that I first encountered, personally, was \"which weighs more, a pound of feathers or a pound of gold?\" This is a much more difficult question. The answer given to me was that the pound of feathers weighs more, because gold is measured in troy weight, and a troy pound consists of only 12 ounces compared to the 16 ounces in a pound avoirdupois. And that's all true. Gold is measured in troy weight, feathers aren't, a troy pound consists of only 12 ounces, a pound avoirdupois consists of 16, and a pound avoirdupois weighs more than a troy pound does. The problem with this answer is that it's not complete; it's just a coincidence that the ultimate result (\"the feathers are heavier\") is correct. Just as a pound avoirdupois weighs more than a troy pound, an ounce avoirdupois weighs less than a troy ounce. But this difference, even though it goes in the opposite direction, isn't enough to outweigh the difference between 16 vs 12 ounces per pound. Without acknowledging the difference in the ounces, the official answer to the riddle is just as wrong as the naive answer is. reply Izkata 2 hours agorootparentYeah, this is the original version of this riddle. People who don't know it think the trick is that people will reflexively say the metal is heavier instead of \"they're the same\", when it actually goes deeper. No idea if GP did it intentionally to further drift from training data, but steel doesn't count as a precious metal, so it messes up the riddle by putting the two weights in the same system. reply zahlman 0 minutes agorootparent> Yeah, this is the original version of this riddle. People who don't know it think the trick is that people will reflexively say the metal is heavier instead of \"they're the same\" ...Have you really never encountered people who would reflexively say that? MattGaiser 6 hours agoparentprevhttps://chatgpt.com/share/67756c29-111c-8002-b203-14c07ed1e6... I got a very different answer: A 10.01-pound bag of fluffy cotton is heavier than a 9.99-pound bag of steel ingots because 10.01 pounds is greater than 9.99 pounds. The material doesn't matter in this case; weight is the deciding factor. What model returned your answer? reply NewsaHackO 6 hours agorootparentYou also didn't ask the question correctly. reply MattGaiser 5 hours agorootparentThe “back” misspelling is also in OP’s quote so I included it. reply 12345hn6789 3 hours agoparentprevAre you sure you weren't fishing? I ran 5 sessions and never got the wrong answer. All using gpt 4o-mini, which is the default non logged in experience on chatgpt.com. 1. The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. Despite the difference in material density, the key factor here is the weight itself, with 10.01 pounds being greater than 9.99 pounds, regardless of the substance. 2. The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. The weight of an object is directly determined by its mass, and in this case, the cotton bag weighs 10.01 pounds, while the steel ingot bag weighs 9.99 pounds, making the cotton bag heavier by 0.02 pounds. 3. The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots, even though the cotton is much less dense. The comparison is purely based on weight, and 10.01 pounds is greater than 9.99 pounds. 4. The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. While steel is much denser than cotton, the weight is the determining factor here, and 10.01 pounds is slightly more than 9.99 pounds. So, the cotton bag weighs more. 5. The 10.01-pound bag of fluffy cotton is heavier. Despite the cotton being less dense and bulkier, the weight of the cotton is still 10.01 pounds, which is greater than the 9.99-pound bag of steel ingots. reply adrian17 2 hours agorootparentNot OP, but I got 4o-mini confused on second attempt. https://chatgpt.com/share/67759d1a-1430-800b-a0a9-2c5f2ac02a... reply wim 8 hours agoprevOne experiment I would love to see, although not really feasible in practice, is to train a model on all digitized data from before the year 1905 (journals, letters, books, broadcasts, lectures, the works), and then ask it for a formula for mass-energy equivalence. A certain answer would definitely settle the debate on whether pattern recognition is a form of intelligence ;) reply amluto 7 hours agoparent> ask it for a formula for mass-energy equivalence Way too easy. If you think that mass and energy might be equivalent, then dimensional analysis doesn’t give you too much choice in the formula. Really, the interesting thing about E=mc^2 isn’t the formula but the assertion that mass is a form of energy and all the surrounding observations about the universe. Also, the actual insight in 1905 was more about asking the right questions and imagining that the equivalence principle could really hold, etc. A bunch of the math predates 1905 and would be there in an AI’s training set: https://en.m.wikipedia.org/wiki/History_of_Lorentz_transform... reply tlb 6 hours agorootparentIt’s nontrivial why it’s mc^2 and not 1/2 mc^2, since kinetic energy generally is 1/2 mv^2 reply whimsicalism 7 hours agorootparentprevbut e=mc^2 is just an approximation e: nice, downvoted for knowing special relativity reply mitthrowaway2 27 minutes agorootparentThis thread has come up before(1), but I'll continue to argue that relativistic mass is a perfectly valid concept as much as any other, and if you disagree, you'll need arguments more substantial than it just being unpopular these days. Especially if you're trying to pedantically argue people out of using a concept that they personally find useful to aid their own understanding, just because it doesn't fit your own mathematical or aesthetic preferences. 1: https://news.ycombinator.com/item?id=38425252 reply amluto 6 hours agorootparentprevCan you elaborate? How is E=mc^2 an approximation, in special relativity or otherwise? What is it an approximation of? reply whimsicalism 6 hours agorootparentE^2 = m^2 + p^2 where p is momentum and i’ve dropped unit adjustment factors like c this allows light to have energy even if its massless reply ac29 6 hours agorootparentpreve=mc^2 is only correct for objects at rest. The full equation takes into account velocity, but for \"low\" speeds where v The goal is to make it intelligent, by which OpenAI in particular explicitly mean \"economically useful\", not simply to be shiny I never understood why this definition isn't a huge red flag for most people. The idea of boiling what intelligence is down to economic value is terrible, and inaccurate, in my opinion. reply ben_w 7 hours agorootparentEveryone has a very different idea of what the word \"intelligence\" means; this definition has got the advantage that, unlike when various different AI became superhuman at arithmetic, symbolic logic, chess, jeopardy, go, poker, number of languages it could communicate in fluently, etc., it's tied to tasks people will continuously pay literally tens of trillions of dollars each year for because they want those tasks done. reply zaroth 3 hours agorootparentMaybe by the time it’s doing a trillion dollars a year of useful work (less than 10 years out) people will call it intelligent… but still probably not. reply s1mplicissimus 7 hours agorootparentprevI haven't seen \"intelligent\" used as \"economically useful\" anywhere outside the AI hype bubble. The most charitable interpretation I can think of is lack of understanding of the common usage of the word, the most realistic one is intentionally muddying terminology so one cannot be called a liar. Are LLMs helpful tools for some tasks like rough translations, voice2text etc? Sure. Does it resemble what humans call intelligence? I'd yet have to see an example of that. The suggested experiment is a great idea and would sway my opinion drastically (given all the training data, model config, prompts & answers are public and reproducible of course, we don't want any chance of marketing BS to taint the results, do we). I'll be honest though, I'm not going to hold my breath for that experiment to succeed with the LLM technology... edit: lol downvoted for calling out shilling i guess reply numpad0 7 hours agorootparentprevThey don't have to do it themselves. The super-GPU cluster used to train GPT-6 will eventually shrink down to a garage size and eventually some YouTuber will. reply lupire 7 hours agoparentprevThe best human performance on that task required many many hours of private work given that input. How much would ChatGPT charge for that much reasoning? Isn't cost quadratic in sort term working memory? It would be more interesting to prompt it with X% of a new paper's logical argument, and see if it can predict the rest. reply wslh 6 hours agoparentprevWhy do we need this when current models already handle questions and answers about new discoveries: ones that are happening every week and are often easier to grasp than Einstein’s equations? I think it is clear that they will fail on most of them. That doesn't mean that LLMs are not useful but there are more walls in the road. reply redman25 7 hours agoparentprevWhy does AI have to be smarter than the collective of hummanity in order to be considered intelligent? It seems like we keep raising the bar on what intelligence means ¯\\_(ツ)_/¯ reply willis936 7 hours agorootparentA machine that synthesizes all human knowledge really ought to know more than an individual in terms of intellect. An entity with all of human intellect prior to 1905 does not need to be as intelligent as a human to make discoveries that mere humans with limited intellect made. Why lower the bar? reply ninetyninenine 7 hours agorootparentThe heightening of the bar is an attempt to deny that milestones were surpassed and to claim that LLMs are not intelligent. We had a threshold for intelligence. An LLM blew past it and people refuse to believe that we passed a critical milestone in creating AI. Everyone still thinks all an LLM does is regurgitate things. But a technical threshold for intelligence cannot have any leeway for what people want to believe. They don’t want to define an LLM as intelligent even if it meets the Turing test technical definition of intelligence so they change the technical definition. And then they keep doing this without realizing and trivializing it. I believe humanity will develop an entity smarter than humans but it will not be an agi because people keep unconsciously moving the goal posts and changing definitions without realizing it. reply klabb3 5 hours agorootparentDisagree. The AI we have is very useful for specific things. The pushback you see is not so much denying the milestones that have been surpassed, but rather the milestones that enthusiasts claim are near. And for good reason! Every time and in every field we’ve extrapolated an exponential-looking curve ad infinitum, it’s turned out to be S-shaped, and life goes on. > We had a threshold for intelligence. We’ve had many. Computers have surpassed several barriers considered to require intelligence such as arithmetic, guided search like chess computers, etc etc. the Turing test was a good benchmark because of how foreign and strange it was. It’s somewhat true we’re moving the goalposts. But the reason is not stubbornness, but rather that we can’t properly define and subcategorize what reason and intelligence really is. The difficulty to measure something does not mean it doesn’t exist or isn’t important. Feel free to call it intelligence. But the limitations are staggering, given the advantages LLMs have over humans. They have been trained on all written knowledge that no human could ever come close to. And they still have not come up with anything conceptually novel, such as a new idea or theorem that is genuinely useful. Many people suspect that pattern matching is not the only thing required for intelligent independent thought. Whatever that is! reply redman25 5 hours agorootparentIf you consider that evolution has taken millions of years to produce intelligent humans--that LLM training completed in a manner of months can produce parrots of humans is impressive by itself. Talking with the parrot is almost indistinguishable from talking with a real human. As far as pattern matching, the difference I see from humans is consciousness. That's probably the main area yet to be solved. All of our current models are static. Some ideas for where that might be headed: - Maybe all it takes is to allow an LLM to continuously talk with itself much like how humans have \"the milk man's voice\". - Maybe we might need to allow LLMs to update their own weights but that would also require an \"objective\" which might be hard to encode. reply Dylan16807 4 hours agorootparent> If you consider that evolution has taken millions of years to produce intelligent humans--that LLM training completed in a manner of months can produce parrots of humans is impressive by itself. I disagree that such a comparison is useful. Training should be compared to training, and LLM training feeds in so many more words than a baby gets. (A baby has other senses but it's not like feeding in 20 years of video footage is going to make an LLM more competent.) reply ImPostingOnHN 6 hours agorootparentprevSince we know an LLM does indeed simply regurgitate data, having it pass a \"test for intelligence\" simply means that either the test didn't actually test intelligence, or that intelligence can be defined as simply regurgitating data. reply greentxt 5 hours agorootparentIntelligence is debateble without even bringing ai into it. Nobody agrees on whether humans have intelligence. Well, smart people agree but those people also agree we have or will soon have agi or something negligibly different from it. reply ImPostingOnHN 4 hours agorootparent> Intelligence is debateble without even bringing ai into it. Nobody agrees on whether humans have intelligence. Yep, that constitutes the second of the two options I mentioned. > Well, smart people agree but those people also agree we have or will soon have agi or something negligibly different from it. lol, the ol' \"I know what all smart people think and it's what I think\" appeal. reply 343rwerfd 5 hours agorootparentprev\"Why lower the bar?\" Because of the chance of misundertanding. Failing at acknowledging artificial general intelligence standing right next to us. An incredible risk to take in alignment. Perfect memory doesn't equal to perfect knowledge, nor perfect understanding of everything you can know. In fact, a human can be \"intelligent\" with some of his own memories and/or knowledge, and - more commmonly - a complete \"fool\" with most of the rest of his internal memories. That said, is not a bit less generally intelligent for that. Supose it exists a human with unlimited memory, it retains every information touching any sense. At some point, he/she will probably understand LOTs of stuff, but it's simple to demonstrate he/she can't be actually proficient in everything: you have read how do an eye repairment surgery, but have not received/experimented the training,hence you could have shaky hands, and you won't be able to apply the precise know-how about the surgery, even if you remember a step-by-step procedure, even knowing all possible alternatives in different/changing scenarios during the surgery, you simply can't hold well the tools to go anywhere close to success. But you still would be generally intelligent. Way more than most humans with normal memory. If we'd have TODAY an AI with the same parameters as the human with perfect memory, it will be most certainly closely examined and determined to be not a general artificial intelligence. reply Jensson 4 hours agorootparent> If we'd have TODAY an AI with the same parameters as the human with perfect memory, it will be most certainly closely examined and determined to be not a general artificial intelligence. The human could learn to master a task, current AI can't. That is very different, the AI doesn't learn to remember stuff they are stateless. When I can take an AI and get it to do any job on its own without any intervention after some training then that is AGI. The person you mentioned would pass that easily. Current day AI aren't even close. reply dogcomplex 33 minutes agoprevI have a feeling the fact you're only slightly varying the input means the model is falling back into the question it was expecting and getting things wrong as a result. If you just varied it a little more and added some general-purpose prompt-fu like: \"First break the problem down into known facts, then pull relevant world knowledge, then bring it all together to assess the problem from multiple angles and make a conclusion. Do not immediately just use the first obvious conclusion.\" You're gonna get a lot better responses. I suspect this is more of a \"look! LLMs make bad kneejerk responses when we try to trick them from what they were expecting!\" rather than \"Look! They aren't even smart reasoners, they can't even figure out these problems without memorizing!\" They do memorize. But that cuts both ways - making problems very close to the memorized one mess with their perception, the same way humans will instinctually respond to something that looks like a face before stepping back and assessing. reply rrr_oh_man 9 hours agoprevPerformance of these LLMs on real life tasks feels very much like students last-minute cramming for Asian style exams. The ability to perfectly regurgitate, while no concept of meaning. reply whimsicalism 7 hours agoparento3 is able to get 25% on never seen before frontiermath problems. sure, the models do better when the answer is directly in their dataset but they’ve already surpassed the average human in novelty on held out problems reply fldskfjdslkfj 7 hours agorootparent> never seen before frontiermath problems How do you know that? reply whimsicalism 7 hours agorootparentBecause that is the whole conceit of how frontiermath is constructed reply fldskfjdslkfj 7 hours agorootparentDidn't they run a bunch of models on the problem set? I doubt they are hosting all those models on their own infrastructure. reply whimsicalism 7 hours agorootparent1. OpenAI has confirmed it’s not in their train (unlike putnam where they have never made any such claims) 2. They don't train on API calls 3. It is funny to me that HN finds it easier to believe theories about stealing data from APIs rather than an improvement in capabilities. It would be nice if symmetric scrutiny were applied to optimistic and pessimistic claims about LLMs, but I certainly don’t feel that is the case here. reply s1mplicissimus 6 hours agorootparent> 1. OpenAI has confirmed it’s not in their train (unlike putnam where they have never made any such claims) Companies claim lots of things when it's in their best financial interest to spread that message. Unfortunately history has shown that in public communications, financial interest almost always trumps truth (pick whichever $gate you are aware of for convenience, i'll go with Dieselgate for a specific example). > It is funny to me that HN finds it easier to believe theories about stealing data from APIs rather than an improvement in capabilities. It would be nice if symmetric scrutiny were applied to optimistic and pessimistic claims about LLMs, but I certainly don’t feel that is the case here. What I see is generic unsubstantiated claims of artificial intelligence on one side and specific, reproducible examples that dismantle that claim on the other. I wonder how your epistemology works that leads you to accept marketing claims without evidence reply ttul 2 hours agorootparentOpenAI’s credibility is central to its business: overstating capabilities risks public blowback, loss of trust, and regulatory scrutiny. As a result, it is unlikely that OpenAI would knowingly lie about its models. They have much stronger incentives to be as accurate as possible—maintaining their reputation and trust from users, researchers, and investors—than to overstate capabilities for a short-term gain that would undermine their long-term position. From a game-theoretic standpoint, repeated interactions with the public (research community, regulators, and customers) create strong disincentives for OpenAI to lie. In a single-shot scenario, overstating model performance might yield short-term gains—heightened buzz or investment—but repeated play changes the calculus: 1. Reputation as “collateral” OpenAI’s future deals, collaborations, and community acceptance rely on maintaining credibility. In a repeated game, players who defect (by lying) face future punishment: loss of trust, diminished legitimacy, and skepticism of future claims. 2. Long-term payoff maximization If OpenAI is caught making inflated claims, the fallout undermines the brand and reduces willingness to engage in future transactions. Therefore, even if there is a short-term payoff, the long-term expected value of accuracy trumps the momentary benefit of deceit. 3. Strong incentives for verification Independent researchers, open-source projects, and competitor labs can test or replicate claims. The availability of external scrutiny acts as a built-in enforcement mechanism, making dishonest “moves” too risky. Thus, within the repeated game framework, OpenAI maximizes its overall returns by preserving its credibility rather than lying about capabilities for a short-lived advantage. reply F7F7F7 31 minutes agorootparentFind me the folks who see nothing but good will in OpenAI’s actions and I’ll find you the folks who have been hyping up AGI for the last 2 years. 4 was literally sitting on a shelf waiting for release when 3.5 was launched. 4o was a fine tune that took over two years. o1 is embarrassingly unimpressive chain of thought which is why they hide it. The company hit a wall a year ago. But showing progress towards AGI keeps the lights on. If they told the truth at their current burn rate…they’d have no money. You don’t need game theory to figure that one out. reply Groxx 1 hour agorootparentprev>OpenAI’s credibility is central to its business: overstating capabilities risks public blowback, loss of trust, and regulatory scrutiny. Uh huh. Kinda like what's happening right now? They're marketing blow-hards. Everyone knows it. They've been wildly over-stating capabilities (and future capabilities!) as long as Altman has had power, and arguably longer. They'll do it as long as they can get away with it, because that's all that is needed to make money on it. Factual accuracy rarely impacts the market when it's so hype-driven, especially when there is still some unique utility in the product. reply fldskfjdslkfj 7 hours agorootparentprevEasier to believe or not, thinking that it's not a reasonable possibility is also funny. reply whimsicalism 7 hours agorootparentDo you also think they somehow stole the codeforces problems before they were even written or you are willing to believe the #175 global rank there? reply fldskfjdslkfj 6 hours agorootparentI dont think codeforce claims to contain novel unpublished problems. But i'm not saying it's what they did, just that it's a possibility that should be considered till/if it is debunked. reply whimsicalism 6 hours agorootparentfrankly i’m not sure what standard you would possibly consider a debunking codeforces constantly adds new problems that’s like the entire point of the contest, no? reply jcranmer 7 hours agorootparentprevThe modern state of training is to try to use everything they can get their hands on. Even if there are privileged channels that are guaranteed not to be used as training data, mentioning the problems on ancillary channels (say emailing another colleague to discuss the problem) can still create a risk of leakage because nobody making the decision to include the data is aware that stuff that should be excluded is in that data set. And as we've seen from decades of cybersecurity, people are absolute shit at the necessary operational security to avoid mentioning stuff on ancillary channels! Given that performance is known to drop considerably on these kinds of tests when novel problems are tried, and given the ease with which these problems could leak into the training set somehow, it's not unreasonable to be suspicious of a sudden jump in performance as merely a sign that the problems made it into the training set rather than being true performance improvements in LLMs. reply whimsicalism 7 hours agorootparentOkay, then what about elite level codeforces performance? Those problems weren’t even constructed until after the model was made. The real problem with all of these theories is most of these benchmarks were constructed after their training dataset cutoff points. A sudden performance improvement on a new model release is not suspicious. Any model release that is much better than a previous one is going to be a “sudden jump in performance.” Also, OpenAI is not reading your emails - certainly not with a less than one month lead time. reply sudosysgen 3 minutes agorootparento1 has a ~1650 rating, at that level many or most problems you will be solving are going to be a transplant of a relatively known problem. Since o1 on codeforces just tried hundreds or thousands of solutions, it's not surprising it can solve problems where it is really about finding a relatively simple correspondence to a known problem and regurgitating an algorithm. In fact when you run o1 on \"\"non-standard\"\" codeforces problems it will almost always fail. See for example this post running o1 multiple times on various problems: https://codeforces.com/blog/entry/133887 So the thesis that it's about recognizing a problem with a known solution and not actually coming up with a solution yourself seems to hold, as o1 seems to fail even on low rated problems which require more than fitting templates. ImPostingOnHN 6 hours agorootparentprevCan you give an example of one of these problems that 'wasn't even constructed until after the model was made'? I'd like to see if it's truly novel and unique, the first problem of its type ever construed by mankind, or if it's similar to existing problems. reply whimsicalism 5 hours agorootparentSorry, I thought the whole point of this thread was that models can’t handle problems when they are “slightly varied”. Mottes and baileys all over the place today. reply sudosysgen 1 minute agorootparentThe point is that it's not consistent on variations, unless it finds a way to connect it to something it already knows. The fact it sometimes succeeds on variations (in codeforces the models are allowed multiple tries, sometimes ridiculous numbers, to be useful) doesn't matter. The point is that the fact it's no longer consistent once you vary the terminology indicates it's fitting a memorized template instead of reasoning from first principles. Spooky23 6 hours agorootparentprevFrankly you need to read what they say explicitly and not infer what they mean by your reckoning. They are the system to beat and their competitors are either too small or too risk averse. They ingest millions of data sources. Among them is the training data needed to answer the benchmark questions. reply jvanderbot 7 hours agorootparentprevThe average human did zero studying on representative problems. LLMs did a lot. reply tzs 6 hours agorootparentI don't know anything about frontiermath problems, but for Putnam problems (which is what the submitted article is about) the average human that takes the exam is an undergraduate mathematics or science major who has studied prior Putnam problems and other similar problems recently to specifically prepare for the exam...and the most common score is still 0. At top tier schools the most common score will usually be somewhere in the 0 to 10 range (out of a possible 120). reply whimsicalism 7 hours agorootparentprevOkay? We are measuring capabilities. reply hshshshshsh 9 hours agoparentprevLook into JEE Advanced. reply umeshunni 6 hours agorootparenthttps://openreview.net/forum?id=YHWXlESeS8 Our evaluation on various open-source and proprietary models reveals that the highest performance, even after using techniques like self-consistency, self-refinement and chain-of-thought prompting, is less than 40%. The typical failure modes of GPT-4, the best model, are errors in algebraic manipulation, difficulty in grounding abstract concepts into mathematical equations accurately and failure in retrieving relevant domain-specific concepts. I'm curious how something like O1 would perform now. reply anilakar 9 hours agoparentprevBasically yet another proof that we have managed to perfectly recreate human stupidity :-) reply cscurmudgeon 9 hours agorootparentGood students are immune to variations that are discussed in the paper. But most academic tests may not differentiate between them and the crammers. reply falcor84 8 hours agorootparent> Good students are immune to variations I don't believe that. I'd put some good money that if an excellent student is given an exact question from a previous year, they'll do better (faster & more accurate) on it, than when they're given a variation of it. reply n144q 8 hours agorootparentI don't think you are betting on the same thing the parent comment is talking about. The assumptions aren't the same to begin with. reply Bjartr 8 hours agorootparentWhat's the difference between benefitting from seeing previous problems and being worse off when not having a previous problem to go from? reply fn-mote 7 hours agorootparentprevThe point is that the “good student” will still do well on the variations, not suffer a 30% decrease in grade. reply orange_puff 2 hours agoprevThis is very interesting, but a couple of things to note; 1. o1 still achieves > 40% on the varied Putnam problems, which is still a feat most math students would not achieve. 2. o3 solved 25% of the Epoch AI dataset. - There was an interesting post which calls into question how difficult some of those problems actually are, but it still seems very impressive. I think a fair conclusion here is reasoning models are still really good at solving very difficult math and competitive programming problems, but just better at ones they have seen before. reply yifanl 9 hours agoprevIs it just an open secret that the models are currently just being hardcoded for random benchmarks? Seems weird that people would be asking Putnam problems to a chatbot :/ reply resoluteteeth 6 hours agoparent> Is it just an open secret that the models are currently just being hardcoded for random benchmarks? Seems weird that people would be asking Putnam problems to a chatbot :/ It's because people do keep asking these models math problems and then, when they get them right, citing it as evidence that they can actually do mathematical reasoning. Since it's hard to determine what the models know, it's hard to determine when they're just spitting out something they were specifically trained on. reply Trasmatta 9 hours agoparentprevNot hardcoded, I think it's just likely that those problems exist in its training data in some form reply jsheard 7 hours agorootparentIt certainly feels like certain patterns are hardcoded special cases, particularly to do with math. \"Solve (1503+5171)*(9494-4823)\" reliably gets the correct answer from ChatGPT \"Write a poem about the solution to (1503+5171)*(9494-4823)\" hallucinates an incorrect answer though That suggests to me that they've papered over the models inability to do basic math, but it's a hack that doesn't generalize beyond the simplest cases. reply mmmore 5 hours agorootparentThere's a few things there that could be going on that seem more likely than \"hardcoded\". 1. The part of the network that does complex math and the part that write poetry are overlapping in strange ways. 2. Most of the models nowadays are assumed to be some mixture of experts. So it's possible that saying write the answer as a poem activates a different part of the model. reply whimsicalism 7 hours agorootparentprevhttps://chatgpt.com/share/67755e6f-bfc8-8010-9aa3-8bcbbd9b26... reply jsheard 6 hours agorootparentTo be clear I was testing with 4o, good to know that o1 has a better grasp of basic arithmetic. Regardless my point was less to do with the models ability to do math and more to do with OpenAI seeming to cover up its lack of ability. reply whimsicalism 6 hours agorootparenti think it’s mostly that o1 mini can think through the solution before it starts writing the poem. i’m able to reproduce your failure on 4o reply lelandfe 7 hours agorootparentprev“a poem about” reads to me at least like the solution need not be in the answer; maybe something like “a poem that includes the answer in the last stanza” reply whimsicalism 6 hours agorootparentyeah but it like actually gets the answer wrong not just omits it reply InkCanon 9 hours agorootparentprevI've always assumed they removed it, because it's such a basic and fundamental part of ML training that you separate your test and train data. And yet I never see any papers even mention if/how they do this. And I wonder if they do, how do they guarantee with high reliability that their massive terabytes of data don't contain the answer. reply jprete 8 hours agorootparentI don't see any reason to assume they removed it unless they're very explicit about it. Model publishers have an extremely strong vested interest in beating benchmarks and I expect them to teach to the test if they can get away with it. reply stingraycharles 7 hours agorootparentAs usual, once a metric becomes a target, it stops being useful. reply franktankbank 5 hours agorootparentWell, they are doing BigCorpStuff not Science reply whimsicalism 5 hours agorootparentprevputnam isn’t an llm benchmark ahhhh none of these companies are reporting putnam scores there’s nothing nefarious about training on putnam problems reply captainbland 8 hours agorootparentprevI think it's reasonable to assume that openAI is optimising for maximum hype at this point which may include wilfully overfitting for impactful benchmarks to generate positive reports. reply lupire 8 hours agorootparentWhen 4 came out they released a document that did BOTH inflate scores by changing the exam conditions, and also bragged about scoring worse than guessing on a multiple choice test. reply marcosdumay 7 hours agorootparentprevHow could they remove it? Those are well known problems, that people talk about on different contexts. They would have to review their entire training set. reply woopwoop 5 hours agorootparentprevI agree that openai is somewhat sketchy about this, but they're sketchy about everything. In the past though they have admitted up front to data contamination (e.g. the original gpt-4 press release did not use big-bench as a benchmark due to data contamination). For the Putnam in particular: this is not a benchmark that they use. There is no reason to exclude it since it is not part of the \"test set\" in any meaningful sense. reply whimsicalism 7 hours agorootparentprevBut putnam isn’t an official test? I find llm discourse on hn so frustrating reply llm_trw 9 hours agorootparentprevImagine you have someone polluting your training data every day. That's what happens when you scrape any tech forum today. The short version is that llm trainign data is the lowest quality data you are likely to see unless you engage in massive potential copyright infringement. reply ryvi 8 hours agorootparent> unless you engage in massive potential copyright infringement. And nobody is going to do that reply YetAnotherNick 9 hours agorootparentprevFirst of all, Putnam is not in the test data, at least I haven't seen OpenAI claiming that publicly. Secondly, removing it from internet data is not 100% accurate. There are translations of the problems and solutions or references and direct match is not enough. MMLU and test set benchmarks show more resilience though in some previous research. reply rst 7 hours agorootparentOpenAI is extremely cagey about what's in their test data set generally, but absent more specific info, they're widely assumed to be grabbing whatever they can. (Notably including copyrighted information used without explicit authorization -- I'll take no position on legal issues in the New York Times's lawsuit against OpenAI, but at the very least, getting their models to regurgitate NYT articles verbatim demonstrates pretty clearly that those articles are in the training set.) reply chvid 7 hours agorootparentprevIt is on the open internet - questions and suggested solutions: https://kskedlaya.org/putnam-archive/ I would expect all llms to be trained on it. reply fn-mote 7 hours agorootparentprevLet’s think about this. > Putnam is not in the test data, at least I haven't seen OpenAI claiming that publicly What exactly is the source of your belief that the Putnam would not be in the test data? Didn’t they train on everything they could get their hands on? reply whimsicalism 7 hours agorootparentdo you understand the difference between test data and train data? just reread this thread of comments reply YetAnotherNick 6 hours agorootparentI don't know why I and you are getting downvoted. Sometimes, HN crowd is just unhinged against AI. reply whimsicalism 7 hours agorootparentprevfunny that nobody replying to you seems to even know what a test set is. i always overestimate the depth of ML conversation you can have on HN reply mlepath 6 hours agorootparentprevYea, people have a really hard time dealing with data leakage especially on data sets as large as LLMs need. Basically if something appeared online or was transmitted over the wire should no longer be eligible to evaluate on. D. Sculley had a great talk at NeurIPS 2024 (same conference this paper was in) titled Empirical Rigor at Scale – or, How Not to Fool Yourself Basically no one knows how to properly evaluate LLMs. reply Panzer04 9 hours agorootparentprevSeems a bit picky. If the bot has seen the exact problem before it's not really doing anything more than recall to solve it. reply bandrami 9 hours agorootparent20 years ago in grad school we were doing a very early iteration of this where we built Markov chains with Shakespeare's plays and wanted to produce a plausibly \"Shakespearian\" clause given a single word to start and a bearish professor said \"the more plausible it gets the more I worry people might forget plausibility is all that it promises\". (There was also a much earlier piece of software that would generate semi-intelligible Kant or Hegel one sentence at a time, though that was through a series of a priori generation rules and a large at the time dictionary of stock phrases. I wonder what ever happened to that.) reply sickblastoise 8 hours agorootparentI think your prof’s worries came true on a massive scale reply jeffreygoesto 9 hours agorootparentprevIt became a successful consultant... reply marcosdumay 7 hours agorootparentprevThat said, a bot with contextual recall can be very useful. The problem is just that people keep insisting that those things are intelligent. reply hansworst 9 hours agorootparentprevIsn't that just the LLM equivalent of hardcoding though? reply Trasmatta 8 hours agorootparentI wouldn't call that hardcoding, otherwise you'd have to call everything it does \"hardcoded\". reply freehorse 6 hours agorootparentprev\"Overfitting\" would be a bit more accurate term if the problem lies in the specific examples existing in its training set in various forms, places, languages etc but with the same values. reply wslh 9 hours agorootparentprevIf I temember well this is call overfitting [1]. [1] https://en.wikipedia.org/wiki/Overfitting reply strangescript 6 hours agoparentprevThere are tests they are passing that they can't be hardcoded for by design. They still have all kinds of flaws and inconsistency but getting upset they answer \"2+2=4\" because someone trained them on what the answer to 2+2 is supposed to be is silly. reply bwfan123 3 hours agoparentprevthis work is similar to the GSM symbolic paper (applied to putnam) https://arxiv.org/html/2410.05229v1 going forward, llm performance must be reported on the confounded benchmark as well reply pama 5 hours agoprevThis workshop contribution is OK, and the benchmark is somewhat valuable even without the rephrasing part of the problems, but the rephrasing (of only a small number of problems) sometimes genuinely makes the problem more confusing to humans as well by either poor phrasing (fig 3), or unneeded breaking of convention (fig 4; points in 2D are often P, with coordinates x,y). It would have been nice to see effects on the rephrasing of the latest/post-training date problems as a function of the increased noising, to delineate part of this confusion. I wonder how much better o3 is on the same benchmark. Also, the correct title of this contribution is: Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning reply ankit219 9 hours agoprevThey are highly effective pattern matchers. You change the pattern, it won't work. I don't remember who, but most likely @tszzl (roon), commented on x that they still trained the traditional way, and there is no test time compute (TTC) or Montecarlo Tree search (like Alpha Go) in o1 or o3. If that is true, then it's still predicting the next word based on it's training data. Likely to follow the most probable path - which comes directly from the training itself - even for the slight variations. Encouragingly, if TTC hasnt been explored, there is a long runway for performance improvements. The other reason this seems hard to guess is because we don't know how much of what we are asking is in the training data. It would perform on some tasks, while fail at others even though those are similar. reply e1g 8 hours agoparentI recently watched two interviews with OpenAI researchers where they describe that the breakthrough of o-series (unlike GPT series) is to focus on test time compute as they are designed to “think” more specifically to avoid pattern matching. Noam Brown https://youtu.be/OoL8K_AFqkw?si=ocIS0YDXLvaX9Xb6&t=195 and Mark Chen https://youtu.be/kO192K7_FaQ?si=moWiwYChj65osLGy reply ankit219 6 hours agorootparentThank you, this is helpful. The post on X was seemingly wrong. reply mmmore 5 hours agorootparentThe comment was likely that there's no explicit search. In o1, the model has learned how to search using its context. Presumably they do this by RLing over long reasoning strings/internal monologues. reply x_may 8 hours agoparentprevI believe they are using scalable TTC. The o3 announcement released accuracy numbers for high and low compute usage, which I feel would be hard to do in the same model without TTC. I also believe that the 200$ subscription they offer is just them allowing the TTC to go for longer before forcing it to answer. If what you say is true, though, I agree that there is a huge headroom for TTC to improve results if the huggingface experiments on 1/3B models are anything to go off. reply ankit219 6 hours agorootparentThe other comment posted YT videos where Open AI researchers are talking about TTC. So, I am wrong. That $200 subscription is just because the number of tokens generated are huge when CoT is involved. Usually inference output is capped at 2000-4000 tokens (max of ~8192) or so, but they cannot do it with o1 and all the thinking tokens involved. This is true with all the approaches - next token prediction, TTC with beam/lookahead search, or MCTS + TTC. If you specify the output token range as high and induce a model to think before it answers, you will get better results on smaller/local models too. > huge headroom for TTC to improve results ...1B/3B models Absolutely. How this is productized remains to be seen. I have high hopes with MCTS and Iterative Preference Learning, but it is harder to implement. Not sure if Open AI has done that. Though Deepmind's results are unbelievably good [1]. [1]:https://arxiv.org/pdf/2405.00451v2 reply whimsicalism 5 hours agorootparentprevttc is an incredibly broad term and it is broadening as the hype spreads. people are now calling CoT “TTC” because they are spending compute on reasoning tokens before answering reply HarHarVeryFunny 4 hours agorootparentYes, and HuggingFace have published this outlining some of the potential ways to use TTC, including but not limited to tree search, showing TTC performance gains from LLama. https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling... reply HarHarVeryFunny 4 hours agoparentprevOpenAI have openly stated that o1 & o3 are using test time compute, and released a log scale graph indicating linear performance gains for exponential compute usage. https://openai.com/index/learning-to-reason-with-llms/ They only confirm that the model/system is doing chain of thought, but the exponential factor and origin of reasoning gains likely comes from TREE of thoughts (number of branches/compute goes up exponentially with depth), essentially doing tree search over different reasoning chains. I assume roon's identity is well known inside OpenAI (he's an employee), so I wouldn't expect him to be leaking implementation details on twitter. reply e1g 8 hours agoprevThe paper includes several examples of their modified questions. There has been a substantial jump from o1-preview to o1, so I gave several samples to o1 and o1-pro (not o1-preview), and current o1s gave the correct answer to those modified problems. SOTA changes fast. reply jtefera 7 hours agoparentThe paper mentions that on several occasions the LLM will provide a correct answer but will either take big jumps without justifying them or will take illogical steps but end up with the right solution at the end. Did you check for that? reply e1g 7 hours agorootparentNo, I don't know enough math to test the logic, only the check questions against their expected answers in https://anonymous.4open.science/r/putnam-axiom-B57C/data/Put... reply zeroonetwothree 6 hours agorootparentPutnam problems need to actually be graded, often the answer itself is trivial. reply suddenlybananas 7 hours agoparentprevLLM boosters are so tiresome. You hardly did a rigorous evaluation, the set has been public since October and could have easily been added to the training data. reply e1g 7 hours agorootparentI'm not skilled enough in math to do a rigorous evaluation, so it was a quick check. Terence Tao is skilled enough, and he describes O1's math ability is \"...roughly on par with a mediocre, but not completely incompetent graduate student\" (good discussion at https://news.ycombinator.com/item?id=41540902), and the next iteration O3 just got 25% on his brand new Frontier Math test. Seeing LLMs as useless is banal, but downplaying their rate of improvement is self-sabotage. reply fumeux_fume 6 hours agorootparent> \"...roughly on par with a mediocre, but not completely incompetent graduate student\" Let it sink in how vague and almost meaningless that statement is. reply pizza 4 minutes agorootparentWhat types of questions are you hoping to answer for that to be considered a vague statement? reply gdhkgdhkvff 7 hours agorootparentprevYour points would be more convincing if you didn’t preface them with arrogant cynicism. reply frikskit 4 hours agoprevAn interesting example of this is: There are 6 “a”s in the sentence: “How many ‘a’ in this sentence?” https://chatgpt.com/share/677582a9-45fc-8003-8114-edd2e6efa2... Whereas the typical “strawberry” variant is now correct. There are 3 “r”s in the word “strawberry.” Clearly the lesson wasn’t learned, the model was just trained on people highlighting this failure case. reply bwfan123 3 hours agoparentReminds me of software i have built which had some basic foundational problems. Each bug was fixed with a data-patch that fixed the symptom but not the cause. hence we continually played whack-a-mole with bugs. we would squash one bug, and another one would appear. same with llms, squash one problem with a data-fix, and another one pops-up. reply sealeck 3 hours agoparentprevIt also fails on things that aren't actual words For example, the output for \"how many x's are there in xaaax\" is 3. https://chatgpt.com/share/677591fe-aa58-800e-9e7a-81870387be... reply curious_cat_163 6 hours agoprevThe metaphor that might describe this paper is \"iteration\". I'd hazard to predict that we’ll likely see more iterations of the following loop in 2025: -> A new benchmark emerges with a novel evaluation method. -> A new model saturates the benchmark by acquiring the novel “behavior.” -> A new benchmark introduces yet another layer of novelty. -> Models initially fail until a lab discovers how to acquire the new behavior. Case in point: OpenAI tackled this last step by introducing a paradigm called deliberative alignment to tackle some of the ARC benchmarks. [1] Alongside all this technical iteration, there’s a parallel cycle of product iteration, aiming to generate $ by selling intelligent software. The trillion $ questions are around finding the right iterations on both technical and product dimensions. [1] https://openai.com/index/deliberative-alignment/ reply atleastoptimal 5 hours agoprevok but preview sucks, run it on o1 pro. 99% of studies claiming some out of distribution failure of an LLM uses a model already made irrelevant by SOTA. These kinds of studies, with long throughputs and review periods, are not the best format to make salient points given the speed at which the SOTA horizon progresses reply red75prime 4 hours agoparentI wonder what is baseline OOD generalization for humans. It takes around 7 years to generalize visual processing to X-ray images. How well does a number theorist respond to algebraic topology questions? How long it will take a human to learn to solve ARC challenges in the json format just as well as in the visual form? reply whimsicalism 7 hours agoprevSo many negative comments as if o3 didn’t get 25% on frontiermath - which is absolutely nuts. Sure, LLMs will perform better if the answer to a problem is directly in their training set. But that doesn’t mean they perform bad when the answer isn’t in their training set. reply optimalsolver 7 hours agoparentEpochAI have to send the questions (but not the answer key) to OpenAI in order to score the models. An overnight 2% -> 25% jump on this benchmark is a bit curious. reply exitb 7 hours agorootparentThe 2% result belonged to a traditional LLM that costs cents to run, while o3 is extremely expensive. reply whimsicalism 7 hours agorootparentprev1. OpenAI said they did not train on these problems & they don’t train on API calls in general, that is a legal policy. 2. It was a new major model release from work over the course of months - struggle to see that as an ‘overnight’ jump in any real meaning. 3. Why is it easier to believe large scale corporate fraud than that the stated capabilities on a held out test set are real? Reads like cope, if I’m being frank. reply zeroonetwothree 6 hours agorootparentI don’t think it’s “easier to believe” just that it raises some red flags. reply MattDaEskimo 6 hours agoparentprevSure, it did good in frontiermath. That's not what this thread is about. Your comment isn't relevant at all reply whimsicalism 5 hours agorootparentthis thread is about math LLM capability, it’s a bit ridiculous to say that mentioning frontiermath is off topic but that’s just me reply MattDaEskimo 4 hours agorootparentJust because you can generalize the topic doesn't mean you can ignore the specific conversation and choose your hill to argue. Additionally, the conversation of this topic is about the model's ability to generalize and it's potential overfitting, which is arguably more important than parroting mathematics. reply whimsicalism 3 hours agorootparentperformance on a held-out set (like frontiermath) compared to putnam (which is not held out) is obviously relevant to a model's potential overfitting. i'm not going to keep replying, others can judge whether they think what i'm saying is \"relevant at all.\" reply MattDaEskimo 3 hours agorootparentAgain, you set your own goal posts and failed to add any insights. The topic here isn't \"o-series sucks\", it's addressing a found concern. reply Topfi 7 hours agoprevI wouldn’t be surprised if similar will be found concerning the ARC challenge and it is why I still maintain my own private LLM challenges to gauge current capabilities. Course, I have little illusion that these are fully private, but it is better than fully public tests. Even the most straight forward, logical, easily reasoned ones stump all LLMs I have access to, which is why I am so skeptical concerning emergence, reasoning and all this hype around “AGI”… reply itfossil 9 hours agoprevOh so its almost like everything else AI related, they basically cheated and lied. If you are shocked by this, you are the sucker in the room. reply itfossil 8 hours agoparentnext [6 more] [flagged] lompad 8 hours agorootparentAnd within half an hour somebody invested in nvidia stock is going to swoop in and explain how they totally (trust me bro) made x thousand with an app written by llm. Every. Single. Time. Almost as if there was a financial incentive to do that. reply surgical_fire 8 hours agorootparentIt's rhe crypto bullshit all over again. Tech hype is becoming unbearable as time goes on. reply danielbln 8 hours agorootparentWhat's with the bitterness? Maybe don't get blinded by the hype and bring a little bit of wonder (and humility) back. reply surgical_fire 5 hours agorootparentBecause the hype is not only annoying, but it makes potentially cool and interesting technology toxic once people figure out that the people hyping things up know it to be mostly bullshit. Great things take many years, sometimes decades to develop properly. Different generations of people to experiment and try things out. That is not good for the ones pushing up the hype. You don't get rich quick by doing that, you don't get to scam enough investors by something being slowly improved. You may call it bitterness, whereas I am just jaded by watching things play out. reply HelloMcFly 6 hours agorootparentprevIt is extremely lame to reply to your own comment to grouse about downvotes. reply ben_w 8 hours agoprevLink title says \"slightly\", but the PDF says two different kinds of variations: variable names (slight) and problem constants (significant), and the 30% drop is on the combination of a 26 variable and also 26 variable + constant questions. It's good to have a better test (though I bet this one will also be quickly saturated like all the others), but the title here doesn't seem justified by the page title there or the content. reply sundarurfriend 7 hours agoparentI would definitely classify both of those as slight changes. In fact I'd rename those as slight => trivial and significant => slight. reply zeroonetwothree 6 hours agorootparentRight, renaming a variable should have zero effect on ability to solve (it wouldn’t for a human). Changing a constant should be very minor, probably also ~0 effect in most cases. I say this as someone that’s done many of these problems. reply chvid 8 hours agoprevIsn't this simply because the dataset used (Putnam-AXIOM Original) is in the training data used to train the various models? Given that these are simple variations (variable names and constants value change in math problems). Why would the companies creating these models (OpenAI etc.) create these variations themselves in order to insure that the model is learning how to solve the problem rather than memorize a solution? Seems like a very obvious thing to do ... reply lupire 6 hours agoparentThey are not only simple renames. LLM is good at those. They are minor structural changes. reply WiSaGaN 8 hours agoprevI don't think this proves that the LLM is just \"pattern matcher\". Human makes similar mistakes too, especially when under time pressure (similar to non-reasoning model that needs to \"use system one\" to generate answer on one go). This is further evident that if you specifically ask the models to pay attention to traps, or just ask follow up question \"are you sure?\", then they usually can get it right. reply jsheard 8 hours agoparentYou're saying that humans perform worse on problems that are slightly different than previously published forms of the same problem? To be clear we are only talking about changing variable names and constants here. reply Lerc 8 hours agorootparentThat is the principle behind the game 'Simon says' reply zeroonetwothree 6 hours agorootparentThat’s a very silly analogy. A more realistic analogy would be do humans perform better on computing 37x41 or 87x91 (with showing the work)? reply Lerc 4 hours agorootparentIt was not an analogy at all. It was an simplified example of the idea that a slight change in a pattern can induce error in humans. It seems some people disagree that that is what the game \"Simon Says\" is about.",
    "originSummary": [
      "Putnam-AXIOM is a benchmark designed to assess large language models (LLMs) on advanced mathematical reasoning using problems from the Putnam Mathematical Competition. - The benchmark includes 236 original problems and a variation with 52 altered problems to avoid data contamination. - OpenAI's top-performing model achieved 41.95% accuracy on the original problems but experienced a significant performance drop of approximately 30% on the altered problems, highlighting challenges in adapting to variations."
    ],
    "commentSummary": [
      "A study revealed a 30% decrease in the accuracy of the o1-Preview model on Putnam problems when minor variations were introduced, indicating challenges for Large Language Models (LLMs) with small changes. - The findings fuel the debate on whether LLMs can genuinely reason or if they primarily depend on pattern matching and memorization, similar to human errors under pressure. - Despite these challenges, models like o1 and o3 continue to perform well on complex mathematical problems, though their capacity to generalize is still under scrutiny."
    ],
    "points": 423,
    "commentCount": 381,
    "retryCount": 0,
    "time": 1735734078
  },
  {
    "id": 42566192,
    "title": "Databases in 2024: A Year in Review",
    "originLink": "https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-retrospective.html",
    "originBody": "Databases in 2024: A Year in Review Posted on January 01, 2025 Like a shot to your dome piece, I'm back to hit you with my annual roundup of what happened in the rumble-tumble game of databases. Yes, I used to write this article on the OtterTune blog, but the company is dead (RIP). I'm doing this joint on my professor blog. There is much to cover from the past year, from 10-figure acquisitions, vendors running wild in the streets with license changes, and the most famous database octogenarian splashing cash to recruit a college quarterback to impress his new dimepiece. I promised my first wife that I would write more professionally this year. I have also been informed that some universities assign my annual blog articles as required reading in their database courses. Let's see how it goes. Previous entries: Databases in 2023: A Year in Review Databases in 2022: A Year in Review Databases in 2021: A Year in Review It’s My Database and I’m Going to License it the Way I Want! We live in the golden era of databases. There are many excellent (relational) choices for all types of application domains. Many are open-source despite being built by for-profit companies backed by VC money. But VCs want that money back and their trap full, so these companies turn out a hosted service for their DBMSs on the cloud. But the cloud makes open-source DBMSs a tricky business. If a system becomes too popular, then a cloud vendor (like Amazon) slaps it up as a service and makes more money than the company paying for the development of the software. This threat is why many database companies change to more restrictive source code licenses that protect against cloud vendors from reselling their products. MongoDB was among the first to do this in 2018 when they switched to their Server Side Public License (SSPL). This past year was a turbulent one for license changes, and the most prominent two were Redis™ and Elasticsearch. Redis: Redis Ltd. (the company) is on an aggressive path towards its IPO. Originally starting as Redis Labs in 2011, they switched their name to Redis Ltd. in 2021 when they acquired the Redis trademark from its creator (Salvatore Sanfilippo), who Redis Labs had bankrolled. Over the last few years, Redis Ltd. has attempted to consolidate control over the Redis landscape. The company has also tried to cast off the perception that the system is primarily used as an in-memory cache by adding support for vectors and other data models. In March 2024, Redis Ltd. announced they were switching from the system's original (very permissive) BSD-3 license to a dual license comprising the proprietary Redis Source Available License and MongoDB's SSPL. The company announced this change the same day they announced the acquisition of Speedb, an open-source fork of RocksDB. The backlash to the Redis license move was quick. The same week the license changed, two forks were announced based on the original BSD-3 code line: Valkey and Redict. Valkey started at Amazon, but engineers at Google and Oracle quickly joined. In only one week, the Valkey project clapped back at Redis Ltd. when it became part of the Linux Foundation, and several major companies shifted their development efforts to it. Redis Ltd. did not help their perception of being up to no good when they got frisky with their beloved trademark and started taking over open-source Redis extensions. In an obvious homage to when Bushwick Bill (RIP), Scarface, and Willie D got back together in 2015, the Redis' creator announced in December 2024 that he is in touch with the Redis Ltd. management and is looking to make a comeback to reunite the Redis community. Elasticsearch: Elastic N.V. is the for-profit company backing the development of the leading text-search Elasticsearch DBMS. In 2021, they announced their switch to a dual-license model of the Elastic License and MongoDB's SSPL. Again, this was in response to the rising prominence of Amazon's Elasticsearch offering, even though the service had been out since 2015. Amazon didn't take this switch kindly and announced their OpenSearch fork. Three years later, Elastic N.V. announced in August 2024 that they reverted their license change and switched to the AGPL. Their blog article announcing this change references Kendrick Lamar's songs (e.g., Not Like Us). Amazon did not like being called the Drake of Databases and announced the following month that they were transferring ownership of the OpenSearch project to the Linux Foundation. Andy’s Take: This turmoil seems like a lot just over licenses, but remember, there is big money in databases. And this is just two systems! I didn't even discuss Greenplum quietly killing off their open-source repository after nine years and going proprietary. But people did not notice because nobody willingly runs Greenplum anymore. The only DBMS I know of that made the same open-source reversal is Altibase in 2023. I'll be blunt: I don't care for Redis. It is slow, it has fake transactions, and its query syntax is a freakshow. Our experiments at CMU found Dragonfly to have much more impressive performance numbers (even with a single CPU core). In my database course, I use the Redis query language as an example of what not to do. Nevertheless, I am sympathetic to Redis Ltd.'s plight of being overrun by Amazon. However, the company is overestimating the barrier of entry to build a simplistic system like Redis; it is much lower than building a full-featured DBMS (e.g., Postgres), so there are several alternatives to the OG Redis. They are not in position of strength where such posturing will be tolerated by the community. The Elasticsearch saga is the same story as Redis, except they are further along in the plot: the company announces license change, competitors create an open-source fork, and the company reverts to an open-source license to muted fanfare. Notice that Redis and Elasticsearch are receiving more backlash compared to other systems that made similar moves. There was no major effort to fork off MongoDB, Neo4j, Kafka, or CockroachDB when they announced their license changes. CockroachDB even changed its license again in 2024 to make larger enterprises start paying up. It cannot be because the Redis and Elasticsearch install base is so much larger than these other systems, and therefore, there were more people upset by the change since the number of MongoDB and Kafka installations was equally as large when they switched their licenses. In the case of Redis, I can only think that people perceive Redis Ltd. as unfairly profiting off others' work since the company's founders were not the system's original creators. An analysis of Redis' source code repository also shows that a sizable percentage of contributions to the DBMS comes from outside the company (e.g., Tencent, Alibaba). This \"stolen valor\" was the reason for the ire HashiCorp received when they changed Terraform's license in 2023. The overarching issue in these license shuffles is the long-term viability of open-source independent software vendors (ISVs) in the database market. The cloud vendors are behemoths with infinite money. If an open-source DBMS takes off, they will start hosting it and make more money than the ISV. Or they will add your DBMS's wire protocol as a front-end to an existing DBMS, like when AWS added InfluxDB v2 protocol support for their Timestream DBMS in March 2024. They can then be the girlfriend of the aforementioned Bushwick Bill and shoot you in the eye, like when AWS announced that their new Valkey-compatible services are 30% cheaper than their Redis-compatible services. Update 2025-01-01: I missed the news that ScyllaDB announced in December 2024 that they are killing off the open-source (AGPL) version of their DBMS and making the enterprise version \"source available\". [Credit] The Databricks vs. Snowflake Gangwar Continues There continues to be no love lost between Databricks and Snowflake. This fight is a classic database war that has spilled out into the streets. The two companies’ previous feud over query performance has expanded to other areas of data management and become much more expensive. Databricks took the first shot in March 2024 when they announced they spent $10 million to build their DBRX open-source LLM with 132 billion parameters. The Mosaic team led the development of the DBRX model, which Databricks acquired in 2023 for $1.3 billion. One month later, Snowflake rolled up to the same corner and lit it up using their Arctic open-source LLM with 480 billion parameters. Snowflake boasted they only spent $2 million to train their model while outperforming DBRX for “enterprise” tasks like SQL generation. You can tell that Snowflake cares most about taking a shot at Databricks because their announcement shows other LLMs doing better than them (e.g., Llama3), but they highlight how they are better than DBRX. One AI researcher was confused about why Snowflake focused so much on DBRX in their analysis and not the other models; this person does not know how much blood these two database rivals have spilled. While the public LLM battle raged, another front in the war between Databricks and Snowflake opened up behind the scenes over catalogs. For most of the 2010s, Hive’s HCatalog has been the de facto catalog system on data lakes. Iceberg and Hudi emerged as replacements in the late 2010s from Netflix and Uber, respectively, and both became top-level Apache projects backed by VC-funded startups. These systems provide a meta-data service to track files and support transactional ingestion of new data on an object store (e.g., S3). Databricks has a proprietary catalog service called Unity, which works with its DeltaLake platform. Snowflake announced their initial integration with Iceberg-backed tables in 2022. They then expanded their support for Iceberg over the next few years. Then, they looked into acquiring Tabular, the main company behind Iceberg, to compete against Databricks with Unity and DeltaLake. The story goes that Snowflake was about to close the deal for $600 million. But then Databricks crashed the party and splashed $2 billion to acquire Tabular. Databricks announced the acquisition the same day as the Snowflake CEO’s conference keynote address, where he was announcing their new open-source Polaris catalog service in June 2024. Databricks continued to kick Snowflake in the teeth when they announced they were open-sourcing their Unity catalog the following week. Straight murdergram. Andy’s Take: What is interesting about this database battle is that it is not just about raw performance numbers. It isn’t like the old Oracle versus Informix shootout of the 1990s, where they were mostly boasting about faster query latencies. It is true that the battle also went beyond just benchmark shots when Informix sued Oracle (and later had to withdraw their suit) because Oracle poached some top Informix executives. Later, the world found out that the Informix CEO had cooked the company’s books to inflate revenue numbers to look better against Oracle and had to do a two-month bid in the federal clink. Instead, the Snowflake versus Databricks battle has expanded to be about the ecosystem around the database. That is, it is about the infrastructure people use to get their data into a database and then the tools they use on that data. Vectorized execution engines for analytical queries are a commodity now. Databricks and every other OLAP vendor follow Snowflake’s architecture design from 2013, originally based on one of the Snowflake co-founders’ Ph.D. thesis. What matters now are quality-of-life facets (which are hard to monetize and compare with competitors), compatibility with other tools, and AI/LLM magic. At least the competition between Snowflake and Databricks has an upside for consumers. Such ferocity means better products and technology for data (e.g., Snowflake’s Polaris is now an Apache project) and eventually (hopefully) lower prices. It’s not like the previous pissing match between Oracle and SalesForce CEOs, where it was two rich guys taking pop shots at each other during their expensive conferences. Shoving Ducks Into Everything In the same way that Postgres is the default choice for anyone starting a new operational database, DuckDB has entered the zeitgeist as the default choice for someone wanting to run analytical queries on their data. Pandas previously held DuckDB's crowned position. Given DuckDB's insane portability, there are several efforts to stick it inside existing DBMSs that do not have great support for OLAP workloads. This year, we saw the release of four different extensions to stick DuckDB up inside Postgres. The first announcement came in May 2024 when Crunchy Data revealed their proprietary bridge for rewiring Postgres to route OLAP queries to DuckDB. They later announced an expanded version of their extension to leverage DuckDB's geospatial capabilities to accelerate PostGIS queries. In June 2024, ParadeDB announced their open-source extension (pg_analytics) that uses Postgres' foreign data wrapper API to call into DuckDB; they previously were using DataFusion in an earlier version (pg_lakehouse) but switched to the Duck. Then, in August 2024, the next DuckDB-for-Postgres extension (pg_duck) came out. The source code for this extension is hosted under the DuckDB Labs GitHub organization. As such, this is the officially sanctioned DuckDB extension for Postgres. The original announcement touted this project as being a collaboration between MotherDuck, Hydra, Microsoft, and Neon. The latter two were (allegedly) kicked out of the mix over a dispute on development controls, similar to Arabian Prince leaving NWA. The repository now only lists it as a joint effort between MotherDuck and Hydra. The latest DuckDB extension dropped in November 2024 with pg_mooncake. Mooncake differs from the other three because it supports writing data through Postgres into Iceberg tables with full transaction support. Andy’s Take: Most OLAP queries do not access that much data. Fivetran analyzed traces from Snowflake and Redshift and showed that the median amount of data scanned by queries is only 100 MB. Such a small amount of data means a single DuckDB instance is enough for most to handle most queries. DuckDB's convenience and portability are the reasons for its proliferation in the Postgres community. Although ClickHouse has existed since 2016, it was not as easy to run as DuckDB until recently (see this blog article that discusses the steps to deploy ClickHouse in 2018). These DuckDB extensions are a single entry point to the broader data ecosystem. Users no longer need to install separate extensions to access data in Iceberg and separately for S3. DuckDB can handle all of that for you. It allows organizations to gain high-performance analytics without needing an expensive data warehouse. Postgres' support for extensions and plugins is impressive. One of the original design goals of Postgres from the 1980s was to be extensible. The intention was to easily support new access methods and new data types and operations on those data types (i.e., object-relational). Since 2006, Postgres' \"hook\" API. Our research shows that Postgres has the most expansive and diverse extension ecosystem compared to every other DBMS. We also found that the DBMS's lack of guard rails means that extensions can interfere with each other and cause incorrect behavior. Earlier projects that added columnar storage to Postgres (e.g., Citus, Timescale) only solved part of the problem. Columnar data formats improve retrieving data from storage. However, a DBMS cannot fully exploit those formats if it still uses a row-oriented query processing model (e.g., Postgres). Using DuckDB provides both columnar storage and vectorized query processing. There is likely a turducken joke here involving an elephant, but I will not make it because I do not want to get fired or put on probation by the university (again). Random Happenings Many one-off events happened with databases last year that you might have overlooked. Here is a quick summary of them: Releases: Amazon Aurora DSQL There isn't much public information yet about how AWS implemented their new \"Spanner-like\" DBMS (see Mark Brooker's discussion about the DBMS architecture). The key ideas are a distributed log service (rumors were it was going to be based on now-defunct QLDB) and timestamp ordering via Time Sync. But this announcement shows you how much brand recognition the name \"Aurora\" carries in the database world because AWS used it for this new DBMS that seemingly shares no code with their flagship Aurora Postgres RDS offering. CedarDB Umbra is one of the most state-of-the-art DBMSs written by the world's greatest database systems researcher (Thomas Neumann). But Thomas is content with staying at his university to work on Umbra, remaining comfortably on top of the Clickbench leaderboard, and not worrying about pesky customers. That's why his top Ph.D. students forked his code and are commercializing it as CedarDB. Google Bigtable The only interesting part of this announcement is that the former vanguard of the NoSQL movement in the late 2000s now supports SQL in 2024. Limbo Turso has been working on the libSQL fork of SQLite for a while, but they went all out in 2024 by announcing a complete rewrite of SQLite in Rust. In their announcement, they correctly point out that the value of SQLite is not just from its code, but also from the insane test engineering that ensures it runs correctly everywhere. That is why the Limbo developers are working with a deterministic testing startup by ex-FoundationDB people. See FoundationDB's 2020 CMU-DB talk for more information on what this testing means. Microsoft Garnet This key-value store is the successor to the impressive FASTER system from Microsoft Research. It is compatible with Redis and supports inter-query parallelism, larger-than-memory databases, and real transactions. Redis should not be anybody's first choice these days. MySQL v9 Six years after MySQL v8 went GA, the team turned v9 out on the streets. But people quickly found that it crashed if your database had more than 8000 tables. I am underwhelmed with the feature list in this new major version. Oracle is putting all its time and energy into its proprietary MySQL Heatwave service. MySQL is still widely used, but the excitement is not there anymore. Everyone has moved on to Postgres. Prometheus v3 It has been seven years since the latest major version of Prometheus. There are so many compatible alternatives now that the OG Prometheus may not be the best option for some organizations. Acquisitions: Alteryx → Private Equity I've never met anybody who uses Alteryx, and I don't have an opinion about them. MariaDB → Private Equity Hopefully the PE people buying the MariaDB Corporation can clean up the mess. See my analysis from last year about the MariaDB dumpster fire. OrioleDB → Supabase This purchase makes sense if you are one of the leading Postgres ISVs. Postgres has a great front-end but an outdated storage architecture. OrioleDB fixes that problem. PeerDB → ClickHouse Better ETL tooling to get data out of Postgres and into ClickHouse. This is a smart move by ClickHouse, Inc. PopSQL → Timescale They bought themselves a fancy SQL editor UI. It is a quality-of-life improvement. Speedb → Redis Ltd. See the discussion above. They are likely going to use Speedb to allow Redis to spill data to disk. Speedb's developers never explained what changes and improvements they made in their RocksDB fork (or I could not find it?). See Mark Callaghan's recent comparison of Speedb vs. RocksDB. Rockset → OpenAI This is big news for the company, but unfortunately they had to shutdown the DBaaS in September 2024. Rockset had a great engineering team with some of the best database engineers from Facebook. I just never liked how their DBMS stored three copies of your data in its indexes. Tabular → Databricks Again, see the discussion above. Iceberg is the standard (sorry Hudi); even Amazon S3 now supports it. It remains to be seen how the adoption of Polaris will evolve and whether they will be able to maintain compatibility in the long term. Verta.ai → Cloudera I guess Cloudera is still alive? Warpstream → Confluent Rewriting Kafka in golang but then making it spill to S3. I'm happy for the Warpstream team, but Confluent could have done this themselves. Funding: Databricks - $10 billion Series J LanceDB - $8 million Seed Round SDF - $9 million Seed Round SpiceDB - $12 million Series A TigerBeetle - $24 million Series A There are a few more raises from CedarDB, SpiralDB, and others but those amounts are not public yet. Deaths: Amazon QLDB If Amazon can't figure out how to make money on a blockchain database, then nobody can. And yes, I know QLDB is not a true P2P blockchain, but it's close enough. OtterTune Dana, Bohan, and I worked on this research project and startup for almost a decade. And now it is dead. I am disappointed at how a particular company treated us at the end, so they are forever banned from recruiting CMU-DB students. They know who they are and what they did. I want to also give special props to Andres Freund for discovering the xz backdoor in 2024 while working on Postgres at Microsoft. This attack was a two-year campaign to inject malicious code into an important compression library widely used in computing. Although the backdoor targeted SSH and not Postgres directly, it is another example of why database engineers are some of the best programmers in the world. Andy’s Take: Databricks has blown away all other fundraising in the world of databases for the second year in a row with a disgustingly brash $10 billion Series J round. This is after their $500 million Series I in 2023 and $1.6 billion Series H in 2021. What is different about this time is this funding was for buying stock from employees who were getting impatient about Databricks' inevitable IPO. CMU-DB has several alumni at Databricks, including a former #1 ranked Ph.D. student. I know some of them are anxiously awaiting the Databricks IPO before deciding what to do next. The upcoming year is going to be the test of strength for many database startups. Nobody wants to be the next MariaDB Corporation, and thus several are waiting to ride Databricks' wake before going IPO themselves. Declining interest rates in the upcoming year may open up additional funding for several database companies that have raised large amounts more than two years ago (e.g., CockroachDB, Starburst, Imply, DataStax, SingleStore, Firebolt). The one standout from this crowd is dbtLabs, which I have heard is comfortably crushing it. See also the Database of Databases list of new DBMSs released in 2024. Can’t Stop, Won’t Stop Do you know who had their 80th birthday this year? The legendary Larry Ellison! Once again, we see that he is a man who refuses to settle down or be put into a box. First, Larry propelled himself up Forbes' Billionaires List to become the third richest person in the world. In March 2024, the Oracle stock rose so much that he made $15 billion in a single day. Flush with cash, Larry went shopping in July 2024 and signed a deal to purchase Paramount Studios at $6 billion for his only son (third wife). He then decided to relax by buying a Palm Beach resort for only $277 million. These moves happened in just one year, and databases paid for all of it. But these are mere trifles compared to Larry's most significant accomplishment in 2024. Everyone I know was surprised when our Larry Ellison news alerts woke us up in the middle of the night in November 2024. The headlines were touting how Larry helped the University of Michigan football program recruit the premiere college quarterback. The university had previously announced that this player was transferring from Louisiana State to Michigan. Their press release included a curious acknowledgement to \"Larry and his wife Jolin\" for helping with the recruiting effort. Reporters soon confirmed that this \"Larry\" was the one and only Larry Ellison! Larry contributed $12 million to the booster campaign to bankroll the best quarterback's move to Michigan. The bigger mystery in this story was the identity of this \"Jolin\" person. Investigators found older photos of Larry watching a tennis match with a woman wearing a Michigan hat. Then, two weeks later, a major news organization broke the story at 5:30 am (my alerts woke me up again) that the woman's identity was Jolin (Keren) Zhu and they confirmed that she was Larry's new wife. Andy’s Take: I am beaming with pride over what Larry accomplished in the past year. He famously did not graduate from any university and had no prior connection to the University of Michigan. And yet, because the love of his life went to Michigan about a decade ago, Larry made magic happen by writing a check for a measly $12 million (about 0.0055% of his net worth). I told Larry this especially means a lot to me because my former #1 ranked Ph.D. student is now a professor in Michigan's Computer Science department with their famous Database Group. What is even more fantastic about this story is that Larry is again in love! Too many people struggle in today's world to find that special somebody. Dating apps are a mess, speed dating events are awkward, and it is now considered uncouth to hang around a playground to meet single parents when you do not have kids of your own. Then, just when you think you finally found the right person, it all falls apart when you learn they do not wash their socks regularly or like to put hot sauce on cold cereal. That is why everyone was telling me that Larry would never get married again after his 2010 divorce from romance novelist Melanie Craft (fourth wife). Those people were telling me the same thing after his 2020 divorce from Nikita Kahn (fifth wife). But I knew better, and Larry proved me right with his surreptitious marriage to Keren Zhu (sixth wife)! Conclusion I was planning on starting this article boasting how this is the first time in three years where I was celebrating NYE not sick. But then my biological daughter gave me COVID so I'm laid up with that. I got boosted back in September and they gave me Paxlovid, so I'll survive this. I am disappointed that OtterTune is dead. But I learned a lot and got to work with many brilliant people. I am a big fan of Intel Capital and Race Capital for sticking with us to the end. I hope to announce our next start-up soon (hint: it’s about databases). In the meantime, I am happy to be back full-time at Carnegie Mellon University. Jignesh Patel and I have some baller research projects that we hope to turn out this upcoming year. I am also looking forward to teaching a new course on query optimization this semester. I need to figure out to juice my stats because in September 2024, Wikipedia removed the article about me over not having enough citations. We are staying true to DJ Mooshoo while he is locked up in Cook County. We hope to free him in 2025. Lastly, I want to give a shout-out to ByteBase for their article Database Tools in 2024: A Year in Review. In previous years, they emailed me asking for permission to translate my end-of-year database articles into Chinese for their blog. This year, they could not wait for me to finish writing this one, so they jocked my flow and wrote their own off-brand article with the same title and premise.",
    "commentLink": "https://news.ycombinator.com/item?id=42566192",
    "commentBody": "Databases in 2024: A Year in Review (cmu.edu)305 points by avinassh 8 hours agohidepastfavorite98 comments antirez 5 hours agoWow, the reasons why Redis commands API suck in Andy's video (linked in the post) are the weakest ever. It is possible to make a case against the Redis API (I would not agree of course but... it's totally legitimate), but you gotta have stronger arguments than those, particularly if you are a teacher of some kind. Especially: you need to be somewhat fluent in Redis and how developers use Redis in order to understand why so many people like it, and then elaborate what it's wrong about it (if you believe there is something wrong). The video shows a general feeling of \"I don't really use / know this, but I don't like how NON-SQL it is\". reply apavlo 3 hours agoparent> Wow, the reasons why Redis commands API suck in Andy's video (linked in the post) are the weakest ever. In my example, the API on a key changes based on its value type. And the same collection can have different value types mixed together. You've recreated the worst parts of IBM IMS from the 1960s. However, the original version of IMS only changed the API when a collection's backing data structure changed. Redis can change it on every key! We didn't get into the semantics of Redis' MULTI...EXEC, which the documentation mischaracterizes as \"Transactions\". I'm happy that at least you didn't use BEGIN...COMMIT. reply antirez 3 hours agorootparentYou totally miss that Redis is more like a remote interpreter with a DSL that manipulates data structures stored at global variables (keys): you (hopefully) would never complain about languages having this semantics. I don't think you understood how Redis collections work. The items are just strings, they can't be mixed like integers or strings together or whatever, nor collections can be nested. The Redis commands do type checking to ensure the application is performing the right operation. In your example, GET against a list, does not make sense because: 1. GET is the retrieve-the-key-of-string-type operation. 2. Having GET doing something like LRANGE 0 -1 would have many side effects. Getting for error a huge list and returning a huge data set without any reason, creating latency issues. Also having options for GET to provide ranges (SQL alike query languages horror story). And so forth. So each \"verb\" should do a specific action in a given data type. Are you absolutely sure you were exposed enough to the Redis API, how it works, and so forth? About MULTI/EXEC, when AOF with fsync configured correctly is used, MULTI/EXEC provide some of the transactional guarantees you think when you hear \"transaction\", but in general the concept refers to the fact that commands inside MULTI/EXEC have an atomic effect from the point of view of an external observer AND point-in-time RDB files (and AOF as well). MULTI / INCR a / INCR a / EXEC will always result in the observer to see either 2, 4, 6, 8, and so forth, and never 3 or 5. Anyway, I believe you didn't put enough efforts in understanding how really Redis works. Yet you criticized it with weak arguments in front of the most precious good we have: students. This is the sole reason why I wrote my first comment, I believe this to be a wrong teaching approach. reply jsnell 2 hours agorootparent> 1. GET is the retrieve-the-key-of-string-type operation. That's a tautological argument. The question isn't what the definition of GET is, but whether the design is good. > 2. Having GET doing something like LRANGE 0 -1 would have many side effects. Getting for error a huge list and returning a huge data set without any reason, creating latency issues. If this really were the reason, you'd have separate operations for tiny strings and huge strings. After all, by analogy having GET return a huge string \"without any reason\" would create latency issues. But that's not how Redis works, right? reply antirez 2 hours agorootparentThe examples I made are just a subset of the protection that this provides. Similarly you can't LRANGE a set type, and so forth. So this in general makes certain errors evident ASAP (command mismatch with the key type). This does not meant that Redis would not work having generic LEN, INSERT, RANGE commands. But such commands would end also having type-specific options, that I have the feeling is not very clean. Anyway these are design tastes, but I don't think they dramatically change what Redis is or isn't. The interesting part is the data model, the idea of commands operating on abstract data structures, the memory-disk duality, and so forth. If one wants to analyze Redis, and understand merits and issues, a serious analysis should hardly focus on these kind of small choices. reply osigurdson 1 hour agorootparentprev>> stored at global variables This is an interesting (and correct) perspective. Global variables scare us in software but we are ok with it when it comes to application state stored in a db. reply zzzeek 2 hours agorootparentprev> You totally miss that Redis is more like a remote interpreter with a DSL that manipulates data structures stored at global variables (keys): I think he makes the point that these \"global variables\" are dynamically typed; you can have \"listX\" and then write a non-list into that same name; statically typed systems would not allow this. He makes the fairly non-controversial point that a statically typed system (SQL, other than that of SQLite) adds a level of type safety that can guard against software bugs. reply DrBenCarson 1 hour agorootparentprevJust because there are reasons for why Redis sucks doesn’t meant it doesn’t suck reply nicoritschel 4 hours agoparentprevWith all due respect, the linked video was pretty fair. It didn't imply not to use Redis, just not as a primary datastore. I don't think folks work with Redis out of fondness for the model, but because it's the least worst datastore for caching, lightweight message broker, and simple realtime things like counters. reply antirez 4 hours agorootparentTalking about the broken API argument here. Also Redis is particularly useful exactly in other situations compared to what OP says. Leaderboards style use cases with sorted sets are killer applications (super hard to model with SQL) of the data structure server thing. Apparently OP does not understand this and says \"simple GET/SET\" is what you should use Redis for. Redis has probabilistic data structures, the ability to implement complex queueing patterns, and so forth. That's where the value is. Otherwise we would still be just with Memcached without caring about Redis. Another killer app was Twitter initial use case (then they used it for pretty much everything): to cache latest N Tweets, using capped lists. I could continue forever. So OP argoment is flawed IMHO, for the above arguments, not fair. When you talk to students you need to make your homeworks. Really understand the system you are talking and provide a realistic image of it. Then, yes, if you want, criticize it as much as you want, with grounded arguments. You know what? I re-read this comment and it's embarassing I ever have to write this, because after 15 years of Redis history at such scale and popularity, pretty much everybody that was seriously exposed to Redis knows those stuff. Is tech culture really degraded so much that we have to restate the obvious? Do I really need to explain GET/SET is not exactly where Redis shines after 15 years of half the Internet used all the kind of Redis patterns? reply daneel_w 3 hours agorootparent> Is tech culture really degraded so much that we have to restate the obvious? Maybe, though the author of the article is known to be a little bit too opinionated, and unfortunately habitual with phrasing himself in a bombastic manner. The piece reads like a dramatic recap of the past year's sporting events, littered with irrelevant and disconnected references to lyrics and drama in the world of rap and hip hop. A \"quirky and fun\" journalistic abortion. reply memhole 3 hours agorootparentprevWhat are your thoughts about Rails switching to SQLite from Redis? I've only used Redis to store session data and cache app data. So my opinions are pretty limited and mostly positive. https://rubyonrails.org/2024/11/7/rails-8-no-paas-required reply antirez 3 hours agorootparentMy feeling is that for their use case, it makes sense to have something vertical that just cover the needs of Rails. AFAIK SQLite has a RAM backend, so still you are not going to hit disk. Seems like a good idea to reduce system complexity, to me. reply nicoritschel 3 hours agorootparentprevI am grateful for Redis and I agree you pioneered a lot of data access patterns in production for a lot of people, myself included. I've used Redis for 10 years, at times for use cases as you mention, for real time feature engineering for ML as well. The API is just different compared to SQL, which is a downside for many. There's modern advancements in the space with IVM and more databases are supporting probabilistic data structures. reply sureglymop 3 hours agorootparentprevMaybe this is a weird question but, knowing only some math and not redis, what is a sorted set and how is it different than a list/tuple? reply antirez 3 hours agorootparentSorted sets are abstract data structures were you insert elements into a set, but every element is associated with a floating point score. Elements are taken ordered inside the sorted sets, so you can ask for ranges, or a specific element rank (position), and so forth. It sounds like the (many) cases where Redis is the best idea to get started and deliver (see for instance the Instagram case, that used Redis for years while becoming bigger and bigger). Then as you understand you are at scale and need just XYZ, you may choose to implement XYZ inside your system in other ways and that's it. reply cloverich 3 hours agorootparentprevRedis is stable, powerful, widely supported, and has been running strong... over a decade now? Ive never heard it recommended as a primary datastore... why would someone do that? Ive seen it used at scale for numerous businesses now and its caused problems exactly never. People understand how to use it because its relatively simple and provides the first things you need beyond the database. Do people complain about redis commonly? News to me. reply nicoritschel 3 hours agorootparentAdtech/ML reply brightball 2 hours agoparentprevYea, I always use Redis for very specialized purposes. Like offloading a shared data structure between threads / processes / machines so that I don’t have to deal with thread safety issues. reply Spivak 2 hours agorootparentI understand machines but threads?! Why introduce IPC overhead on the fastest/easiest way to share data? This is beyond a solved problem and your language probably has multiple ready-made battle tested solutions. In Python you don't even need a lib, dict is thread safe even in nogil. reply fforflo 4 hours agoparentprevI've been working on something Redis-y over the holidays, and it has reinforced my view that it's the epitome of a 20%- 80% tool. I've always used the 20%, but anything beyond that sounds useless unless you've encountered the requirement in a production environment. The challenges Redis has been solving for years, never really touched the research/academic community (even the 20%). Even in the various taxonomies of DBS in the research literature, Redis was mentioned with a wave of the hand as an \"in-memory\" database, which undersells the important (for me) part of the \"data structure\" server. Putting the \"database\" after Redis could be a marketing misstep. Because it puts you in the is-it-sql territory. TL;DR: Redis is mostly appreciated by practitioners (web) developers. Academics find it lacking a theoretical foundation, so... meh. reply Tanjreeve 28 minutes agorootparentDevelopers know it's limits. Or you have developers with vague \"scaling issues\" or \"buggy caching\" who don't understand why they have them or suddenly start suffering from them at inconvenient moments. reply tayo42 3 hours agoparentprev> Andy's video (linked in the post) Is there a \"to long didnt watch\" summary any one knows of? I hate videos, but am curious lol reply nojito 5 hours agoparentprevSQL is king and history has shown non-sql languages are not good which causes many non-sql DBMS's to adopt sql eventually. reply antirez 5 hours agorootparentMany non-SQL DBs had query languages that were broken Javascript-ish versions of SQL. Of course, this is wrong, and people will eventually adopt SQL instead. But if your data model isn't anything like relational DBs, non-SQL makes a ton of sense. OP seems to miss exactly this, that the Redis query language is shaped on the Redis data model, that is basically alien to the relational model. The idea behind Redis data model is that \"describe data\" then \"query those data in random ways\" is conceptually nice but practically will not model very well many use cases. SQL databases plagued tech with performance issues for decades because of that. So Redis says instead: you need to put your data thinking about fundamental things like data structures and access times and the way you'll need those data back. And the API reflects this. You don't have to automatically agree with that. But you have to understand that, then provide your \"I'm against\" arguments. Especially if you are in front of young people listening to you. reply im_down_w_otp 5 hours agorootparentAgreed. Many noSQL-boom-era databases eventually bolted on a SQL-esque layer, but that was also because they were mostly also all targeting \"enterprise database\" use cases and customers who both expected that and whose use cases largely fit with it. So, there was a lot of pressure to conform to norms when the advantage of not doing so wasn't immediately self-evident. We have a database [1] and query language [2] that's tailored to storing & querying trace/telemetry data produced by different layers and components of cyber-physical systems for systems engineers to analyze, verify, and validate what a complex system is doing. It's not quite a traditional relational problem. It's not quite a traditional time series problem. It's not quite a traditional graph problem. Addressing the way that systems engineers think about their domain in an effective way required coming up with something different. Are there caveats and rough edges? Sure. But, they're a lot less pernicious and onerous than the alternative of trying to leverage a bunch of ill-fitting menageries of different solutions. Redis is fit-for-purpose. So, it makes sense that its query interface would also express that. [1] https://docs.auxon.io/modality/ [2] https://docs.auxon.io/speqtr/ reply nojito 3 hours agorootparentprev>But if your data model isn't anything like relational DBs, non-SQL makes a ton of sense. OP seems to miss exactly this, that the Redis query language is shaped on the Redis data model, that is basically alien to the relational model. Sure...but all roads lead back to SQL eventually. Another recent example also mentioned in the OP is BigTable adopting SQL. reply threeseed 3 hours agorootparent> but all roads lead back to SQL eventually No it doesn't. SQL is designed for relational databases. For other forms i.e. JSON, Graph, Key/Value they all use other query languages. reply anovick 4 hours agorootparentprevSQL (and RDBMS in general) has its limitations, particularly with regards to recursive operations. An extended Datalog[1] can provide performance optimizations not available to RDBMS. [1]: https://dl.acm.org/doi/10.1145/3639271 reply atombender 4 hours agoprevThe article mentions Greenplum, but it's worth noting that when the code was closed, several of the original developers created an open-source fork, Cloudberry, which seems to be thriving. Cloudberry was accepted into the Apache project this year, and has synced with Postgres 14, whereas the closed-source Greenplum is still stuck on Postgres 12. The architecture is quite ancient at this point, but I'm not sure it's completely outdated. It's single-master shared-nothing, with shards distributed among replicas, similar to Citus. But the GPORCA query planner is probably the most advanced distributed query planner in the open source world at this point. From what I know, Greenplum/Cloudberry can be significantly faster than Citus thanks to the planner being smarter about splitting the work across shards. reply ledgerdev 3 hours agoparentThanks for the cloudberry mention, wasn't aware of it. reply gigatexal 2 hours agoprevThis take screams more than a technical criticism but of something personal. “I'll be blunt: I don't care for Redis. It is slow, it has fake transactions, and its query syntax is a freakshow. Our experiments at CMU found Dragonfly to have much more impressive performance numbers (even with a single CPU core). In my database course, I use the Redis query language as an example of what not to do.” (From the article) Of course it’s not to be used as a general purpose DB it’s keys and values. Used for caches and things like that. In my experience in real world scenarios and loads vanilla single threaded Redis is stable, fast, and nigh bulletproof. reply bcoates 1 hour agoprev\"I've never met anybody that used Alteryx\" I have! It's a pretty good no-code/minimal-code graphical ELT+Analytics in one tool. It's one of those alternate-universe tools that has it's own way of doing things from everything else in the industry, but it’s pragmatic and the people who use it tend to love it. The one thing that makes it viable is that is has/had (pre-acquisition) very aggressive compatibility with anything else that can hold data, so you can use it as a bolt-on to whatever other databases or files your company has. Despite what the PE press release about the acquisition says, it has virtually nothing to do with AI, at lease in the modern big NN sense. If you're looking to fix your giant pile of alteryx workbooks or migrate them to something else, hmu reply mrtimo 4 hours agoprevEnjoyed his roundup in the \"Shoving Ducks into Everything\" section. DuckDB is a great tool. In April 2020, the creator of DuckDB gave a talk at CMU. In the beginning he makes a convincing argument (in 5 minutes) why data scientists don't use RDBMS and how this was the genesis of DuckDB. Here is a video that starts 3 minutes into the talk (where is argument starts): https://youtu.be/PFUZlNQIndo?si=ql9n2QuBlAEuGIqo&t=204 reply PeterZaitsev 4 hours agoprevI think one thing Andy misses about why people were pissed about Elastic and Redis but not as many for MongoDB and some other is their license and size of Contributors Community. When original license is as restricted as AGPL it is unlikely there is much of embedded use... so less people are impacted in truly catastrophic way Also if there is no contributor community to speak of... who is going to do the fork ? I put some thoughts about it in my post about ScyllaDB https://peterzaitsev.com/thoughts-on-scylladb-license-change... reply tayo42 3 hours agoparent> In the case of Redis, I can only think that people perceive Redis Ltd. as unfairly profiting off others' work since the company's founders were not the system's original creators. An analysis of Redis' source code repository also shows that a sizable percentage of contributions to the DBMS comes from outside the company He mentions this in \"Andy’s Take\" section btw reply PeterZaitsev 3 hours agorootparentYes. Not the license though. reply codeulike 5 hours agoprevWeird how SQL Server and its Azure variants gets no mention. It dominates in certain sectors. DBEngines ranks it third most popular overall https://db-engines.com/en/ranking reply teej 3 hours agoparentAre people choosing SQL Server independently of the Microsoft ecosystem? My understating is that you typically use it because you’re forced to choose a MS product. reply Tostino 1 hour agorootparentAgreed with the other person. It's a great database. I wouldn't choose it for a startup over Postgres, but it is extremely capable. reply rawgabbit 3 hours agorootparentprevSQL Server is a terrific product. And I detest most things Microsoft. reply stackskipton 2 hours agoparentprevSRE who deals with some .Net stuff that uses MSSQL but is converting to MySQL. so I feel somewhat qualified to talk about MSSQL. TL;DR: Nothing interesting going on. There is nothing to talk about here. It's boring database engine that powers boring business applications. It's pretty efficient and can scale vertically pretty well. With state of modern hardware, that vertical limit is high enough most people won't encounter it. It's also going the way of Windows Server which is to say, it's being sold but not a ton of work is being done on it. Companies that are still invested in it are likely because they don't care about cost ultimately or cost of switching is too high to greenlight the switch. Anyone who does care about cost like my current company has switched to OSS solutions like PostGres/MySQL/$RandomNoSQLOSSOption. My company switched away when turned into SaaS business and those MSSQL server costs ate into bottom line. This has been happening throughout the ecosystem. Proget which is THE solution for .Net Artifacts is switching to PostGres: https://blog.inedo.com/inedo/so-long-sql-server-thanks-for-a... Also, I saw this article from Brent Ozar, who I see as MSSQL smart person, which basically said if you have the option, just go with PostGres: https://www.brentozar.com/archive/2023/11/the-real-problem-w... It's also worth noting that Microsoft even bought PostGres scaling solution called Citus so they read the writing on the wall: https://blogs.microsoft.com/blog/2019/01/24/microsoft-acquir... reply mbreese 1 hour agorootparent> It's boring database engine that powers boring business applications I'm taking that as a positive thing... it's boring and does its job with little fanfare. That's pretty much what I want out of a RDBMS. So long as it is \"fast-enough\" with enough features for the applications that use it, that seems like a good place for an RDBMS to be. One could still argue about Windows and licensing fees, but from a technical point of view, for business customers, boring isn't necessarily a bad thing. reply FridgeSeal 1 hour agorootparentThere’s other boring databases that also reliably fill that job, and they also cost far less. It can also be a bit of a pain outside the C# ecosystem, whereas every language ever has nice postgres drivers that don’t require us to download arms setup ODBC. It runs on Linux as of a few years ago, but I also wouldn’t be surprised if many people didn’t realise that. reply stackskipton 46 minutes agorootparentI’ve run into MSSQL on Linux. Most DBAs know but their entire ecosystem is Windows Server so what’s another Windows Server is their thinking. reply rawgabbit 2 hours agorootparentprevI was a big proponent of MSSQL. It is still a good product but I see Microsoft constantly fumbling with new OLAP tools. It is a shame but it seems Microsoft is abandoning MSSQL. reply RadiozRadioz 4 hours agoparentprevLots of people deliberately avoid Microsoft technologies and their whole ecosystem. There's of course interesting stuff happening there, but not enough for those outside the ecosystem to care. It's more a cultural thing than anything else. HN for example largely leans away from MS. It's quite interesting how little overlap there is between the two worlds sometimes. Speaking as one of those people, it's just not my thing, so it's not on my radar at all. There's enough stuff happening outside MS to keep me busy forever. reply patja 5 hours agoparentprevThe fawning over Larry Ellison is also weird. reply cactusfrog 4 hours agorootparentThe joke is that his greed/ unwillingness to squeeze margins has made the entire database company ecosystem possible. reply ak_111 3 hours agoprevWow his database startup that raised 12M died this year after only three years. If anything this shows how insanely difficult it must be to succeed as a database startup (when was the most recent startup success in this space?), as the founding team is stellar. On the other hand I am surprised it died this quick and interested to know if they did a proper postmortem. Not only did they raise way more than is needed to survive for three years but the idea is about utilising AI to improve DB performance and I find it hard to imagine they couldn't find more investors to lend them a lifeline with all the AI hype. reply dig1 4 hours agoprev> There was no major effort to fork off MongoDB, Neo4j, Kafka, or CockroachDB when they announced their license changes. AFAIK people didn't take MongoDB seriously from the start, especially with the \"web scale database\" joke circulating. The Neo4j Community version has been under GPLv3 for quite some time, while the Enterprise version has always been somewhat closed, regardless of whether the source code was available on GitHub (the mentioned license change affected the Enterprise version). Regarding CockroachDB, I must admit that I've only heard about it on HN and don't know anyone who seriously uses it. As for Kafka, there are two versions: Apache Kafka, the open-source version that almost everyone uses (under the Apache license), and Confluent Kafka, which is Apache Kafka enhanced with many additional features from Confluent, and the license change affected Confluent Kafka. In short, maybe the majority simply didn't care about these projects very much, so there is no major fork. > It cannot be because the Redis and Elasticsearch install base is so much larger than these other systems, and therefore, there were more people upset by the change since the number of MongoDB and Kafka installations was equally as large when they switched their licenses. I can’t speak for MongoDB, but the Confluent Kafka install base is significantly smaller than that of Apache Kafka, Redis and ES. > Dana, Bohan, and I worked on this research project and startup for almost a decade. And now it is dead. I am disappointed at how a particular company treated us at the end, so they are forever banned from recruiting CMU-DB students. They know who they are and what they did. Call me a skeptic, but I can't see this as a fair approach. If your company fails for whatever reasons, you should not recruit the university department/group/students against your peers (I can't find that CMU-DB was one of the founders of Ottertune). Wrt Andy, here are [1] somehow interesting views from (presumably) previous employees. [1] https://www.reddit.com/r/Database/comments/1dgaazw/comment/l... reply apavlo 2 hours agoparent> Wrt Andy, here are [1] somehow interesting views from (presumably) previous employees. I am only seeing this now and I take the complaints about being \"slightly racist and offensive\" very seriously. I am checking with investors, former HR people, and co-founders. I was not made aware of any issues. If anything, I was overly cautious at the company. I was openly transparent with our employees about every direction the company was pursuing up until the very end. The complaint that \"He thinks he knows everything about business\" makes me believe this person is just trolling because I was always the first to admit in meetings that I was not an expert in how to run a business. We had to fire people because of inappropriate behavior, but not because I had strong disagreements with how to run the company. reply moab 14 minutes agorootparentFWIW, as someone who had multiple friends who worked closely with Andy over 5+ years and at all stages of their career (both BS / PhD) those comments reek of someone with an axe to grind. All of the many anecdotes I have about Andy paint a picture of a great advisor and mentor. I suppose I should say \"shenanigans aside\", but if you can't separate his jokes from his academic side you need to develop a sense of humor. reply paulddraper 4 hours agoparentprevThere are production uses of MongoDB (Stripe comes to mind). But it is certainly not a popular choice there. reply threeseed 3 hours agorootparentMongoDB does over $2b in revenue (and growing by 20%) each year. There are a lot of production uses. reply Upvoter33 1 hour agoprevPretty funny. One factual issue: \"The university had previously announced that this player was transferring from Louisiana State to Michigan.\" This is not true. Underwood had committed to LSU but then switched his commitment to Michigan. He was still in high school at the time, and has never attended LSU. But, do you really expect a funny database prof to know much about football? reply mpbart 1 hour agoparentI never thought I’d see a discussion about the Underwood NIL drama on a databases blog post but here we are. reply softwaredoug 4 hours agoprevOn the “Amazon can just offer your DB as a service” Yes this can happen. But a lot of people don’t want a AWS managed service. They're like 30% cheaper for 30% less value. They can develop a bad reputation and feel like weird forks (kinesis vs Kafka) that have weird undocumented gotchas and edge cases that never get fixed. Many teams want to host on k8s anyway, and you’ll probably have better k8s support from the main project. Another example is the success of Flink over hosted Google Dataflow. Seems eventually the teams I know trend to the most mainstream OSS implementation over time, maybe after early prototyping on a managed system. IMO it might not be the highest growth market anymore. Those who want to pay for a managed service will. But many are just figuring out a k8s based solution to their infra needs as k8s knowledge becomes more ubiquitous. reply the_arun 4 hours agoprevThis person started with news on DB - reviewing all prominent DBs & finally ended talking about love of Larry Ellison. A perfect human in the days of LLMs. Amazing write up. reply polishdude20 3 hours agoprevAfter I interviewing at OtterTune a while back and being bombarded with multiple rounds of leetcode questions, I somehow knew OtterTune wouldn't make it reply mebcitto 4 hours agoprevA couple of spicy things: > OtterTune. Dana, Bohan, and I worked on this research project and startup for almost a decade. And now it is dead. I am disappointed at how a particular company treated us at the end, so they are forever banned from recruiting CMU-DB students. They know who they are and what they did. Ouch. > Lastly, I want to give a shout-out to ByteBase for their article Database Tools in 2024: A Year in Review. In previous years, they emailed me asking for permission to translate my end-of-year database articles into Chinese for their blog. This year, they could not wait for me to finish writing this one, so they jocked my flow and wrote their own off-brand article with the same title and premise. Also sounds like he's preparing a new company: > I hope to announce our next start-up soon (hint: it’s about databases). reply iso8859-1 3 hours agoparentHow do they enforce the ban? Do universities have non-compete clauses for PhD students? reply mebcitto 3 hours agorootparentI assume it's not that kind of ban, but more like he'll recommend his students to avoid the company. reply spprashant 3 hours agoparentprevAnyone know what company he may be talking about? reply ksec 5 hours agoprev>Six years after MySQL v8 went GA, the team turned v9 out on the streets. ......Oracle is putting all its time and energy into its proprietary MySQL Heatwave service. Oracle actually released 9.1 already in 2024. [1] And expect another release this month, and every quarter. So I think MySQL continues to get some new features bug fix and support like it used to. Contrary to most people think it is all going to Heatwave. I just hope Vector will be open source later as official to MySQL rather than behind Heatwaves. [1] https://dev.mysql.com/doc/relnotes/mysql/9.1/en/news-9-1-0.h... reply m_ke 6 hours agoprevAndy is a treasure, if only we had more professors like him reply CT4u8798 5 hours agoprevI love SQL. I'm not a full-time developer but always use SQL over other abstractions, which I find extremely confusing and way more complicated that plain SQL. reply skeeter2020 5 hours agoparentI'm now firmly into management but the one skill I use very regularly is SQL. By far the best investment I made in my entire career was a little bit of relational algebra, some casual study of DBMS internals and a lot of hands-on SQL. The quasi-standards have also made it the easiest transfer across specific DBs and their flavours over the years. PSA: Hi kids, here's a dinosaur with yet more free advice: put the tiniest bit of effort into SQL early on and watch the compound interest add up. reply threeseed 3 hours agoparentprevThat's just because it is what you are comfortable with. Many developers will jump straight for ORMs when given the chance. reply Tostino 58 minutes agorootparentWhich for certain types of applications ORMs absolutely have their use. reply RedShift1 4 hours agoprevI've been using plain postgres for over 5 years now, reading this I feel like I'm in the eye of a storm... reply badindentation 7 hours agoprevThe section on Larry Ellison is amusing. reply avinassh 5 hours agoparentLarry always makes appearances in his reviews, lol > But the real big news in 2023 was how Elon Musk personally helped reset Larry's Twitter password after he invested $1b in Musk's takeover of the social media company. And with this $1b password reset, we were graced in October 2023 with Larry's second-ever tweet and his first new one in over a decade. https://www.cs.cmu.edu/~pavlo/blog/2024/01/2023-databases-re... > These journalists made it sound like Larry was doing something nefarious or indecent, like the time he made his pregnant third wife sign a prenup two hours before their wedding. I can assure you that Larry was only trying to use his vast wealth as the 7th richest person in the world to help his country. His participation in this call is admirable and should be lauded. Free and fair elections are not a trivial affair, like a boat race where sometimes shenanigans are okay as long as you win. Larry has done other great things with his money that are overlooked, like spending $370m on anti-aging research so that he can live forever https://www.cs.cmu.edu/~pavlo/blog/2022/12/2022-databases-re... reply leeoniya 6 hours agoparentprev\"Do not fall into the trap of anthropomorphising Larry Ellison.\" https://m.youtube.com/watch?t=33m1s&v=-zRN7XLCRhc&feature=yo... reply epolanski 6 hours agoparentprevI couldn't understand if it was satire or something. Do they believe the guy marries a 30 years old cause she loves him? In any case, who cares, how was that relevant.. reply masklinn 6 hours agorootparentIt's definitely satire, how would you take this sentence as serious: > I told Larry this especially means a lot to me because my former #1 ranked Ph.D. student is now a professor in Michigan's Computer Science department with their famous Database Group. reply maeil 4 hours agoprevGood read! > Postgres' support for extensions and plugins is impressive. One of the original design goals of Postgres from the 1980s was to be extensible. The intention was to easily support new access methods and new data types and operations on those data types (i.e., object-relational). Since 2006, Postgres' \"hook\" API. Our research shows that Postgres has the most expansive and diverse extension ecosystem compared to every other DBMS. Greenhorn developers don't even know that there are non-Postgres databases which have extensions too - such is the gap! I wouldn't be surprised if Postgres had as many as all others combined. reply memhole 6 hours agoprevLove the style! CMU making databases cool. Sorry to hear about OtterTune. reply osigurdson 1 hour agoprevMore like: \"Database license drama - a year in review\". reply based2 3 hours agoprevhttps://dbos-project.github.io news reply refset 1 hour agoparentMore specifically, DBOS Inc. raised a $8.5 million seed round [0] and is backed by Michael Stonebraker (the creator of Postgres). I initially assumed Andy was alluding to this when he wrote \"the most famous database octogenarian splashing cash\" :) [0] https://techcrunch.com/2024/03/12/new-startup-from-postgres-... reply kwillets 4 hours agoprevI spent the past year puzzling over the DB market as well, but I don't feel like I'm much closer to understanding it. It appears that a lot of attention is now directed at the folks doing 100 MB queries, and the high end has moved past everybody's radar. My idea of an exciting product is Ocient, who have skipped over Cloud and gone for hyperscale on-prem hardware. Yellowbrick is also a contender here. I have a lot of experience with Vertica, and they seem to have gotten stuck in this niche as well, with sales tilted towards big accounts, but less traction in smaller shops, and a difficult road to get a SaaS or similar easy-start offering. There's a crossover point where self-managed is cheaper than cloud, but nobody seems to have any idea where it is. Snowflake will gladly tell you that your sub-$1M Vertica cluster should be replaced by $10M of sluggish SaaS, and that you are saving money by doing so. These decisions seem more in the realm of psychology or political science. DHH's cloud exit was a refreshing take on the expense issue, even if it wasn't strictly in the database space -- the cost per VCPU and so forth that he documented is a good start for estimating savings, and he debunked a lot of the \"hidden costs\" that cloud maximalists claim. In the business/financial space the biggest news to me was the correction in Snowflake's stock price, which seemed to indicate that investors were finally noticing metrics like price-performance, but they added a little more AI and went back into irrationality. I'm heavily in favor of DuckDB, Hudi, Iceberg, S3 tables, and the like. Mixing high-end and low-end tools seems like the best strategy (although settling on one high-end DWH has also worked IME), and the low end is getting better and cheaper, squeezing out the mid-range SaaS vendors. In research I found Goetz Graefe's work in offset-value coding exciting -- he's wired it into query operators in a way that saves a lot of CPU on sorting and joins/aggregation. This is a technique that I've applied favorably in string sorting, and it was discovered in the DB community decades ago but largely forgotten. (This work precedes 2024, but I'm a slow study.) reply roark_howard 2 hours agoprevDuckDB dominating over DataFusion could fuel the ongoing language war with a great half baked argument! reply rednafi 2 hours agoprevLoved the overview. Hated the shade toward Redis. Redis has arguably the best key-value query syntax, and there’s a reason so many people swear by it. True, the decision-makers at Redis Ltd are absolute pieces of trash, but Redis itself is a delightful piece of engineering artifact. I don’t care about the billion-dollar drama behind a piece of tech, but Redis defined the key-value query API for many similar databases. Trashing it just because it isn’t SQL-like feels unjustified. reply lvl155 3 hours agoprevI highly recommend their Youtube series on databases. They have great guest speakers. reply sigbottle 5 hours agoprevThese year in review posts are really neat, I liked the AI in review posts really well. Maybe algorithms review or TCS review or some specific math topic review next? reply samanthasu 6 hours agoprevwould love to see what Andy's take on GreptimeDB https://github.com/GreptimeTeam/greptimedb reply leeoniya 6 hours agoparentmade same comment recently in https://news.ycombinator.com/item?id=42330055#42331927 reply samanthasu 6 hours agorootparentlooking forward to the bonus content! reply travisgriggs 5 hours agoprevThe funding section had me thinking “one of these is not like the others”. Both the amount and count of successive rounds. reply rozenmd 6 hours agoprevI loved ottertune, it's a shame it died the way it did. reply wahnfrieden 5 hours agoprev2024 was also the year that Realm died reply bionhoward 3 hours agoprevRedis is slow? reply kermatt 1 hour agoparentI wish there was more context around that statement in his post. Redis while not having some of the features he mentions in [1] (i.e. SQL), when used for what it excels at is usually not considered \"slow\". As an in-memory data structure server, a common use case is to use it for where some operations in a typical RDBMS are slow. [1] https://youtu.be/fZbwD1gzjLk?t=2018 reply mihirrd 7 hours agoprevQuite informative reply quotemstr 2 hours agoprevThere's one QOL extension that I haven't seen anyone else implement: dimensional analysis. I can declare a column is an integer. Why not an integer that expresses feet? Why shouldn't I be able to write SELECT 1inch + 1cm and get a correctly computed length? Why can't the query parser help me avoid nonsense like SELECT 1kg + 1hr? All this stuff is pretty straightforward to add and would help avoid avoidable mistakes. reply wslh 4 hours agoprevGreat heads up. I wonder about graph databases. He mentionedandboth include the graph use case and I wonder how they compare to . reply Beefin 6 hours agoprev [–] TL;DR SQL is king reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The database landscape in 2024 experienced significant changes, including major acquisitions, license shifts, and ongoing rivalries among key players like Redis, Elasticsearch, Databricks, and Snowflake. - DuckDB gained popularity for analytical queries, with integrations into Postgres, while notable releases included Amazon Aurora DSQL and Microsoft Garnet. - Acquisitions such as Tabular by Databricks and OrioleDB by Supabase were significant, and despite setbacks like OtterTune's closure, the industry remains dynamic with new projects and funding."
    ],
    "commentSummary": [
      "The discussion critiques Redis' API, with some arguing that the criticism lacks a deep understanding of Redis' design and its unique data model.",
      "Redis is recognized for its effective use in specific applications like leaderboards and real-time systems, despite some API criticisms.",
      "The conversation also explores the broader database landscape, including challenges for startups, the role of SQL, and the evolution of database technologies, emphasizing the importance of understanding systems before critiquing them."
    ],
    "points": 305,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1735741659
  },
  {
    "id": 42564687,
    "title": "Books I Loved Reading in 2024",
    "originLink": "https://thoughts.wyounas.com/p/books-i-enjoyed-most-in-2024",
    "originBody": "Share this post Thoughts of an imprint Books I Loved Reading in 2024 Copy link Facebook Email Notes More Books I Loved Reading in 2024 The Books I Enjoyed Most in 2024 Waqas Younas Dec 30, 2024 10 Share this post Thoughts of an imprint Books I Loved Reading in 2024 Copy link Facebook Email Notes More 1 Share Hunters in the snow I was able to read several books this year. Here are some books I loved reading in 2024. Cicero Letter to Friends: Volume 1 Cicero was a Roman statesman, and not only was he an orator of the highest order, but he was also a captivating writer who penned beautiful prose. There are few individuals in history who have written prose more beautiful than his. In fact, he wrote such exquisite Latin that, at one time, education literally meant reading Cicero, Cicero, and some more Cicero. This book is a collection of letters, translated from Latin to English, that he wrote to friends, family members, and colleagues. Sometimes, he wrote letters because he was concerned about a friend’s health; other times, he wrote to his family because he was worried about their well-being or needed to give them directions. Occasionally, he wrote to friends and colleagues to curry favor for people he knew. Let me share a few excerpts. Sometimes he would talk about books, as in: In my command here I have put into practice the whole Education of Cyrus, a work which I read so often that I wore out the book. What follows is Cicero asking a friend for a favor for another friend: Now, my dear Paetus, be a friend, and take the whole affair upon yourself, and relieve Fabius of the worry. We need your name and sound judgment, and your personal influence too. Don’t let the brothers get into litigation and become embroiled in discreditable lawsuits. Mato and Pollio are Fabius’ enemies. Briefly, I assure you that I cannot write down in full how much you will oblige me if you put Fabius’ mind at ease. He thinks, and persuades me, that it all depends on you. Even though I was reading English translations of his letters, his prose remained captivating, even in translation. There are two reasons I like this book. First, it offers insight into the old times, life back then, and how things were. Second, he wrote engaging prose, sometimes even lyrical. Among countless examples, here are a few phrases I enjoyed: Please rest assured that my solicitude for your credit increases every day, though your own integrity and clemency have so enhanced it that any addition seems impossible. Another one: If he proves himself worthy of his forbears, as I expect and hope he will, some part of the credit will go to you. If he stumbles, the damage will be entirely his, not yours at all. And this one has a nice ring to it: If you do what is best for your health, you will best comply with my wishes. So think it over in that clever head of yours. I miss you, but I love you. Loving you, I want to see you fit and well; missing you, I want to see you as soon as possible. The former, there, must come first. So make it your chief concern to get well. Of your countless services to me this will be the one I shall most appreciate. How beautifully he weaves simple words to convey emotion. In the truest sense of the word, he was a man of letters. Writing prose like his isn’t something an ordinary individual can easily emulate. Mathematical Logic for Computer Science by Ben-Ari I wanted to brush up on logic for computer science, and this book came highly recommended by someone I trust. It did not disappoint. It’s a technical book, heavy on theory, so I had to read it slowly, ensuring I absorbed everything as I went along. Some books aren’t easy to read and aren’t rewarding either, while others aren’t easy to read yet are rewarding. This one wasn’t easy, but it was certainly a rewarding experience for me. The best part of the book was its use of a first-principles approach. The book covers propositional logic, deductive systems such as Gentzen (I even blogged about it) and Hilbert, Binary Decision Diagrams, SAT solvers, First-Order Logic, Temporal Logic, verification of sequential programs, and verification of concurrent programs. The last three topics intrigued me the most, and I liked the way the content was presented so much that I bought another book by the same author and read it. Philosophy as a Way of Life by Pierre Hadot I came across this book accidentally, but I’m so glad I did. Pierre Hadot was a French philosopher who could not only philosophize but also write simply—an ability not common among top-tier philosophers, if I may say so with respect. This work explores themes on how to use philosophy to live better lives. What better purpose could philosophy serve than this? Hadot believed that the purpose of ancient philosophy was to transform souls, which is why philosophical teaching was primarily given in oral form. Nothing stirs the soul like a good spoken word, and the written part was, for the most part, a complement to this oral teaching. The oral tradition and dialogue were at the center of philosophy. While it was important to present the solution, it was even more important to show the “path traversed together in arriving at this solution.” This book offered insights that were outside my sphere of knowledge. For one, if you want to truly understand why Marcus Aurelius wrote his Meditations the way he did, then this book is for you. You learn why he sought to reform rather than inform. You also discover the framework he used to write down his meditations. Further, you learn about Epictetus and his philosophy. For instance, one should not content oneself with philosophical discourses or texts, but strive to live a good life. As Epictetus once said, “our only occupation should be the cure of ourselves.” The essence of philosophy, then, is to produce good actions, to live virtuously and not viciously, to pursue truth and not ignorance. He also talks about spiritual exercises in this book, which is both interesting and worth a post in its own right. Philosophy shouldn’t be confined to specific institutions or individuals. Instead, we all should be able to use it to refine ourselves, to dialogue with others and with oneself, to examine our conscience, and to be masters of ourselves. The idea is not for anyone to “satisfy himself with discourse, with the conceptual architecture that he has constructed, without putting into question his own life.” Hadot calls this a perpetual danger of philosophy, where a philosopher takes refuge in the “reassuring universe of concepts and of discourse instead of going beyond discourse in order to take upon himself the risk of the radical transformation of himself.” I feel Pierre Hadot’s aim in writing this book was to make philosophy accessible to common men and women, to help us use philosophy to live better lives. I believe he succeeded. There is much in this book that can serve us well. Asechylus’s Oresteia Aeschylus was not just a soldier but also the father of Greek tragedy and a figure whose influence still echoes through his works. He won first prizes often at the Dionysia (an ancient Greek festival that included theatrical performances of tragedies and comedies). Oresteia, a winner at the Dionysia, was a trilogy that explored the themes of justice, vengeance, and the evolution of societal order. There is much wisdom in the trilogy. This following famous quote about “learning by suffering” is in the first play: Zeus, who set mortals on the road to understanding, who made “learning by suffering” into an effective law. There drips before the heart, instead of sleep, The misery of pain recalled: good sense comes to men. His thoughts on human psychology and the way he crafted his stories are why I liked this book. I have to admit, there is a lot in it that I need to absorb. I’ll surely be re-reading this one sometime soon. It’s one of those books that one ought to read multiple times in life because I’m certain that every time we read it, it will offer something new. Principles of the SPIN Model Checker by Ben-Ari There are technical books that are thick and heavy yet offer little, and then there are books that are short yet offer insight and ignite your interest and curiosity even further. This book gave me both insight and a deeper curiosity about the subject. This book introduces the SPIN model checker and exposes the reader to the nuances of verifying programs using SPIN. A nice feature of the book is how it explains concepts using thoughtfully developed, freely available tools (such as jSpin) that the author created for pedagogical purposes. It’s a demanding book, but the content was interesting. The book presents details about concurrency, temporal logic, non-determinism, advanced SPIN topics, and even case studies. I’ve already written a few blog posts about the topics I explored while reading this book, and I plan to write more. Overall, it’s a good book. I’m sure I’ll revisit the latter half again. Born Standing Up by Steve Martin It’s a nice, short, and moving memoir by the comedian and actor Steve Martin. The book details his early working days at shops and clubs, his relationships, and eventually his rise to fame. He shared his struggles, his failures, long hours of practice, his reflections to refine his craft, and his efforts to find his own unique voice as a comedian. Any memoir that only talks about successes and never discusses struggles, rejections, or weaknesses is suspect. This one is not. What I like about his writing is that it feels candid and, at times, funny. From reading the book, it’s clear that recognition for one’s work takes time. What you can’t control is how and when you get recognition. What you can control is how hard you work and persevere. He firmly understood what he could control and focused on that. His was a long journey, full of obstacles, but he never gave up. He kept refining his craft, kept working, kept improving, and finally, he earned the recognition he much deserved. Reading this book reinforces the idea that success is nine times patience times effort times reflection times some luck. Less Than One by Joseph Brodsky Joseph Brodsky was a poet, an essayist, and a Nobel Prize winner. This book is a collection of essays, and some of them are quite profound. One of his essays on Dostoevsky is particularly insightful; it left such an impression on me that I reflected on it and wrote an essay of my own. He is one of those writers who frequently shares wisdom about literature or the human condition in his writing. You don’t stop reading him because he keeps you so engaged by offering insights on the topic at hand. He’s also one of those writers who gives you unexpected angles on familiar things. For instance, his essay on Dostoevsky offers subtle insights into why Dostoevsky’s work is immortal. One difference between masters and beginners is that masters have explored and mastered details that beginners may not even notice. Similarly, another takeaway from this book is understanding how experienced literary connoisseurs interpret and analyze literary works. The way he untangles and interprets some literary pieces, and the depth and detail he explores, isn’t just insightful—it’s something that someone like me couldn’t even notice at first. He has a whole essay on W.H. Auden’s poem, and the way he delves into it is simply fascinating. All in all, it’s a good book with some thought-provoking writing. A Wizard of Earthsea by Ursula Le Guin I had never read anything by Ursula Le Guin, but then I came across some excerpts of her work online, and I thought I should give her a try. I was also going through a phase in my life where I believed reading more fiction would help power up my imagination. I picked this book up, and I liked it. On the surface, it’s about wizards and magic, but there’s more to it. Every now and then, Ursula Le Guin sprinkles in some wisdom. One reason I like this book is how the plot folds and then unfolds. Another reason is that you come across phrases that make you pause and think, like: It is very hard for evil to take hold of the unconsenting soul. Or this: To light a candle is to cast a shadow... Or this: I had forgotten how much light there is in the world, till you gave it back to me. I enjoyed the book, and I plan on exploring and reading more of her work. The Best of Tagore Rabindranath Tagore was a Bengali poet, writer, composer, philosopher, social reformer, and Nobel Prize winner. I admire philosophers who not only talk but also put their words into action to better the world. Tagore not only left behind a remarkable body of work but also tried to make the world a better place through his actions—such as opening a school, which now boasts a list of distinguished alumni. This book contains his essays and plays. It’s a big volume, and I bought it because it includes his most notable works, although, for now, I was mainly interested in his essays. Some of his essays are thought-provoking. His reflections on education, nationalism, and other topics are not only stirring but also showcase literary brilliance. The man could write. Here is one of his quotes I particularly like: The one who plants trees, knowing that he will never sit in their shade, has at least started to understand the meaning of life. The Strangest Man by Graham Farmelo This is a good biography of arguably the most brilliant scientist, Paul Dirac, famous for co-inventing the most revolutionary theory in the last hundred years or so—the theory of quantum mechanics. Paul Dirac was a man of very few words, hardworking, and a brilliant scientist who took pride in the beauty of mathematics. Sometimes I believe an appalling childhood is a precondition for genius; Dirac had one. He once said, “I never had a childhood.” But thankfully, he received a superb education. He was not known to talk much, even during his childhood. The only time he spoke was when he politely corrected the errors of his teachers. Dirac believed he was a geometrical thinker, probably due to his excellent technical drawing skills learned at school. Eventually, he earned a PhD at Cambridge, and as a scientist, he never looked back. There is so much in this book that I should probably write about in a separate review sometime. Dirac was also quite a character, and making small talk with him wasn’t easy. He once responded to the comment, “It’s a bit rainy, isn’t it?” by walking to the window, returning to his seat, and stating, “It is not now raining.” He was very careful with his speech; he once said, “I was always taught not to start a sentence until I knew how to finish it.” His contributions to the field of physics are seminal. He definitely led a life worth living. I found this an engaging biography and thoroughly enjoyed reading it. The argumentative Indian by Amartya Sen I had not read any of Amartya Sen’s work before this book. Mr. Sen is a notable scholar and a winner of the Nobel Prize in Economics. It’s stimulating work as well as easy to read. Although parts of South Asia are not commonly known to have an argumentative gene, Amartya Sen convincingly shows that Indian history is deeply rooted in an argumentative tradition. He masterfully weaves evidence and tales to make his point. There is much I learned that I didn’t know, even though I’m from South Asia (which was a bit embarrassing). For instance, I learned how poets from the working classes questioned social divisions and the barriers of disparate religions. He also cites historical evidence showing how the argumentative tradition was firmly rooted in India’s history. For example, Ashoka’s remarkable interest in the rules of discussion in the third century BC is evident in one of his edicts: “A person must not do reverence to his own sect or disparage the beliefs of another without reason.” In parts of South Asia today, different sects still find it difficult to sit and settle their differences even when the state intervenes, yet a few centuries ago, the king Akbar arranged interfaith dialogues. Sen also thoroughly presents a convincing case for how India’s intellectual accomplishments were marred by biases associated with its colonial past. His critique of James Mill’s (father of John Stuart Mill) work on Indian history is particularly insightful. This book also introduced me to Tagore and his ideas, such as his views on education and his critique of patriotism and nationalism. Additionally, the book discusses the accomplished Indian filmmaker Satyajit Ray (who was awarded an Oscar for lifetime of cinematic excellence). After reading about him, I watched some of his movies, which are not only fascinating but also thought-provoking. Simple storytelling, yet stories that make you think. Overall, this book illuminated some corners of my brain—it was educational. Human, All Too Human by Nietzsche Nietzsche wasn’t trained as a philosopher; he was trained as a philologist, and he had a way with words. He wrote penetrating thoughts about culture, society, morals, arts, and politics in this multifaceted work. You may disagree with Nietzsche on ideas he considers first-rate, but you cannot disregard him as a second-rate writer. Nietzsche uses an aphoristic style, which Wikipedia defines as: “An aphorism is a concise, terse, laconic, or memorable expression of a general truth or principle.” Why did he use that style? Perhaps because of his severe and disabling health problems. Or maybe he prized the aphoristic style because he believed “brevity is the soul of wit.” Some of the aphorisms in the book indeed show sharp wit. One might speculate that his aphoristic style could lead to incoherence of thought in this work. I don’t find that to be the case. In several places, I found him laying the foundations for some of his notable ideas, such as will to power. One cannot be incoherent and simultaneously lay out influential ideas in philosophy. One major theme I took away from this book is to bring anything I believe under much stronger scrutiny; only such scrutiny can bring us closer to the truth. The subtitle of the book is A Book for Free Spirits. What does he mean by a free spirit? It’s someone able to liberate themselves from the chains that hinder them, to scrupulously scrutinize ideas, and to show determination to undertake tasks requiring excellence, strength, and courage to break away from conventional values, traditions, and societal expectations. In Nietzsche’s own words, a free spirit feels like a wanderer, rejects dependence on things like honors, money, or official positions, and is thankful for the struggles and uncertainties of life. A free spirit is curious and daring, works tirelessly, uses resources carefully, is inventive and flexible, and has a love of solitude. On being bound by tradition, in one of his aphorisms he says: The less men are bound by tradition, the greater is the fermentation of motivations within them, and the greater, in consequence, their outward restlessness, their mingling together with one another, their polyphony of endeavors. On habits in drawing conclusions, he observes: The commonest erroneous conclusions drawn by mankind are these: a thing exists, therefore it has a right to. Here the conclusion is from the capacity to live to the fitness to live, from the fitness to live to the right to live. Then: an opinion makes happy, therefore it is a true opinion, its effect is good, therefore it itself is good and true. In the book, one can also see Nietzsche developing and laying the foundations for his ideas, such as will to power. For example: The reason the man of power is grateful is this. His benefactor has, through the help he has given him, as it were, laid hands on the sphere of the man of power and intruded into it: now, by way of requital, the man of power in turn lays hands on the sphere of his benefactor through the act of gratitude. It is a milder form of revenge. If he did not have the compensation of gratitude, the man of power would have appeared unpowerful and thenceforth counted as such. That is why every community of the good, that is to say originally the powerful, places gratitude among its first duties. Swift suggested that men are grateful in the same degree as they are revengeful. On intellect and morality, he writes: One has to have a good memory if one is to keep a promise. One has to have a powerful imagination if one is to feel sympathy. So closely is morality tied to the quality of the intellect. There is an interesting chapter titled From the Souls of Artists and Writers—interesting because art and writing interest me. On the sudden occurrence of inspiration versus gradual work leading to excellence, he states: Artists have an interest in the existence of a belief in the sudden occurrence of ideas, in so-called inspirations; as though the idea of a work of art, a poem, the basic proposition of a philosophy flashed down from heaven like a ray of divine grace. In reality, the imagination of a good artist or thinker is productive continually, of good, mediocre and bad things, but this power of judgement, sharpened and practised to the highest degree, rejects, selects, knots together; as we can now see from Beethoven’s notebooks how the most glorious melodies were put together gradually and as it were culled out of many beginnings. Nietzsche also shares a recipe for becoming a good novelist: The recipe for becoming a good novelist, for example, is easy to give, but to carry it out presupposes qualities one is accustomed to overlook when one says, ‘I do not have enough talent.’ One has only to make a hundred or so sketches for novels, none longer than two pages but of such distinctness that every word in them is necessary; one should write down anecdotes each day until one has learned how to give them the most pregnant and effective form; one should be tireless in collecting and describing human types and characters; one should above all relate things to others and listen to others relate, keeping one’s eyes and ears open for the effect produced on those present; one should travel like a landscape painter or costume designer; one should excerpt for oneself out of the individual sciences everything that will produce an artistic effect when it is well described; one should, finally, reflect on the motives of human actions, disdain no signpost to instruction about them, and be a collector of these things by day and night. One should continue in this many-sided exercise some ten years: what is then created in the workshop, however, will be fit to go out into the world. What, however, do most people do? They begin, not with the parts, but with the whole. Perhaps they chance to strike a right note, excite attention and from then on strike worse and worse notes, for good, natural reasons. On why thinkers write badly, Nietzsche remarks: Most thinkers write badly because they communicate to us not only their thoughts but also the thinking of their thoughts. And on who is the best author, he states: The best author will be he who is ashamed to become a writer. Nietzsche also has interesting thoughts favoring idleness: Scholars are ashamed of otium (leisure). But there is something noble about leisure and idleness. If idleness really is the beginning of all vice, then it is at any rate in the closest proximity to all virtue; the idle man is always a better man than the active. But when I speak of leisure and idleness, you do not think I am alluding to you, do you, you sluggers? And in another aphorism about leisure, he notes: The man who lies ill in bed sometimes discovers that what he is ill from is usually his office, his business, or his society, and that through them he has lost all circumspection with regard to himself: he acquires this wisdom from the leisure to which his illness has compelled him. This is the only book from which I want to share the most. Right now, as I write this, just like a child who wants to show all his favorite toys to his friends, I want to share all my favorite thoughts from this book. I have to admit, I have never read a philosopher who had more penetrating thoughts in a book. Some of his ideas hit you like a thunderbolt. His writing is penetrating, and he makes his point in as few words as possible. He means business. He should be read. If you enjoyed this essay, or if it struck a chord with you, I would be honored if you shared it with someone who might appreciate it. Writing gives my life meaning—it’s a pursuit I hold close—and your support, whether through a subscription, a one-time donation, or a recommendation, motivates me to keep going. For this, I am deeply grateful. Thank you for being part of this journey. Subscribe to Thoughts of an imprint By Waqas Younas · Launched 8 months ago Thoughts. And Essays. Subscribe Error 10 Share this post Thoughts of an imprint Books I Loved Reading in 2024 Copy link Facebook Email Notes More 1 Share",
    "commentLink": "https://news.ycombinator.com/item?id=42564687",
    "commentBody": "Books I Loved Reading in 2024 (wyounas.com)289 points by simplegeek 14 hours agohidepastfavorite122 comments sapphicsnail 17 minutes agoIt's a little odd that he recommends Loebs for Cicero and Aeschylus. They have Greek/Latin on one side and English on the other. The translations vary in quality and they are significantly more expensive than buying an English-only translation. I have a bunch of Loebs but I studied Classics and can read Greek and Latin. I would never recommend them to a friend. Edit: Just wanted to add that Aeschylus, Euripedes, and Sophicles are great reads. You can read a whole play in one sitting. If I could recommend one from each it would be Agamemnon, The Bacchae, and Antigone. Each of those plays deeply affected me and they're fairly accessible. reply kaycebasques 6 hours agoprevMy best books of 2024: * Chemistry: A Very Short Introduction by Peter Atkins. Now that I'm into physics I had a hunch that I would now also appreciate chemistry. This book delivered. * Philosophy of Mind: A Very Short Introduction by Barbara Gail Montero. I recall it just being a really well-written overview of an interesting field. * Systemantics by John Gall. Very entertaining musings on why systems fail. * Hard-Boiled Wonderland by Haruki Murakami. Read this while in Japan. A very strange and interesting noir detective story. * All Systems Red by Martha Wells.Hard-Boiled Wonderland The English translation of a second book in the same universe (well, one of the two universes) was just released---The City and Its Uncertain Walls. I've only just started reading it, though, so I can't offer any commentary beyond that. If you like Murakami, you might like Convenience Store Woman or Earthlings, both by Sayaka Murata. Mieko Kawakami is also great. Killing Commendatore (by Murakami, again) is my favorite of his. I have no idea why it's my favorite, though. To be honest I can barely remember the plot of any of his books; it's just a feeling. reply wonger_ 5 hours agoparentprev+1 to antimemetics. I don't usually enjoy sci-fi, but this one captured my attention. You can read it online too: https://qntm.org/scp reply tyrust 4 hours agorootparentI read it this year, too. It's a fun read, but I wouldn't recommend anything past the first group of articles (that is, don't bother with \"Five Five Five Five Five\"). The ideas are good, to be sure, but the overall arc past that is pretty weak. reply BalinKing 2 hours agorootparentYeah, the first half or so is a blast, but there’s a point where I feel it drops off quite a bit. (For me, I think it was when the POV changed to Adam.) Still worth a read, though! reply kemiller2002 5 hours agorootparentprevThank you sooo much for posting! reply ylem 5 hours agoparentprevDr. John Gall was my pediatrician! When I was young, I was interested in astronomy and he gave me a membership in the astronomy book club. I only learned of his work on system theory after his death. reply kaycebasques 4 hours agorootparentWow, what an interesting guy. I have a big affinity for people who are interested in lots of different fields. Gotta love any story about someone who feels so strongly about some idea that they fork over their own money to self-publish the book. (IIRC Gall self-published the first edition himself after getting turned down by 20 publishers.) reply hinkley 1 hour agoparentprevCongrats on starting Martha Wells but how did you stop at one? I think I read or consumed almost 25 of her books last year. reply wholinator2 6 hours agoparentprevYooo you got the chemistry introduction by Atkins? He's the author of the \"standard\" undergraduate physical chemistry text and some others. I've got tons of those tiny \"very short introduction\" books but i have yet to see chemistry. reply kaycebasques 5 hours agorootparentIt was exactly the kind of overview I was looking for. You can tell that Atkins is someone that was writing out of pure intellectual love for his domain. reply TheGoodBarn 6 hours agoparentprevSomeone gifted me All Systems Red this year and I had never heard of the series and it may be one of my faves of all time. I’m on book 5 now it’s been such a joy reply hombre_fatal 3 hours agorootparentIt's only a 3-4 hour long audiobook. Definitely gonna try it on my run tonight. reply kaycebasques 5 hours agorootparentprev> “It calls itself ‘Murderbot,’” Gurathin said. I opened my eyes and looked at him; I couldn’t stop myself. From their expressions I knew everything I felt was showing on my face, and I hate that. I grated out, “That was private.” reply 383toast 2 hours agoparentprevIf you want more brainfuck, read Gnomon by Nick Harkaway reply adelmotsjr 6 hours agoparentprevWhat book would you recommend for Physics? reply kaycebasques 5 hours agorootparentThat Fundamentals book by Wilczek that I mentioned is a good start. I'm also reading through the pop-sci classics now (A Brief History Of Time, Feynman's stuff) and they're not disappointing. I really like the Very Short Introduction series by Oxford University Press. I've read 30 of them so far (just counted). At this point they basically have a book on every aspect of physics that has interested me at one time or another: black holes, gravity, quantum theory, waves, time, thermodynamics, chaos, etc. Really love being able to literally put the book in my back pocket and read a few pages whenever I have a spare moment. Each book can be very hit-or-miss, though. Some of them are badly written and fail at their basic value proposition (providing a concise and reasonably complete overview of a field). reply lencastre 3 hours agoparentprevqnmt is the gift that keeps on giving reply cmiller1 7 hours agoprev> I was also going through a phase in my life where I believed reading more fiction would help power up my imagination. I kind of hate this mindset. Why does reading always have to be with the goal of self improvement? When someone binge watches a new TV series on Netflix no one asks them what skill they were trying to sharpen by enjoying that media. reply bisby 2 hours agoparentI also dislike the mindset that reading == intellectual. I know plenty of people who read a LOT but it's all Twilight or 50 Shades of Grey type stuff. And I know people who never read books, but are constantly watching documentaries or otherwise always learning. People should be able to have hobbies and self improvement separate and each one delivered in whichever medium they happen to prefer. (And I'm not trying to say bad things about either of the books I mentioned, but rather illustrate that certain types of books aren't going to make you a scholar, just because you read a lot. Read what you enjoy.) reply edanm 32 minutes agorootparentAs someone who reads a lot - probably more than 99% of people, I guess? - I mostly agree. > People should be able to have hobbies and self improvement separate and each one delivered in whichever medium they happen to prefer. Agreed. > Read what you enjoy. Semi-agree on this one. There are different reasons to read. You can read for pure entertainment. You can read to learn things. You can read to be motivated. You can read to calm down. You can read to be part of the conversation. Reading what you enjoy is good advice, and it's a valid approach, but so is reading something that's a little but hard and not very enjoyable, because you want to expand your knowledge, to learn and grow. Read what you want for whatever reason you want, would be my recommendation. (I personally mix most of the reasons above.) reply hombre_fatal 4 hours agoparentprevJust because you categorize something as a leisure activity doesn't mean someone shouldn't do it with an objective in mind. Daily creative writing, journaling, (trying to) learn to dance, reading books in Spanish when I'd get more enjoyment reading in English. These are all things I've done with goals in mind beyond leisure. In fact I don't particularly enjoy them enough to do them without an objective, else I wouldn't have had to go out of my way to do them. You don't enjoy everything or else you wouldn't have to try at anything. > When someone binge watches a new TV series on Netflix no one asks them what skill they were trying to sharpen by enjoying that media. But they weren't demanding this of anyone else. It was an objective for themself. You are actually the one demanding something of someone else just because you have different preferences. ;) Is that a great mindset? reply layer8 3 hours agoparentprevThose without that mindset don’t write blog posts about it. reply hinkley 1 hour agoparentprevI can get through about six to eight books a year on the self improvement route and a couple dozen or more if I just have fun with it. Revisiting old audiobooks is especially good for those times you are doing a mundane task or just need something comfortable for one of those days/weeks. reply Sam6late 6 hours agoparentprevThere are many ways of reading, the selection and the diversity (old and contemporary writers) of what you read helps you see how you could appreciate a more critical view of what you are reading. Reading a novel before watching someone's rendering of the same novel into, say Netflix, may expand your imagination and possibly show you how limited the director's version of the same story. I felt that with Stephen King's thrillers, Pet Sematary and Thinner, then watching them as movies. reply maksimur 3 hours agoparentprevTV series and movies can also be watched with a goal in mind, whether secondary to the fun or not. Examples are seeing how culture changed or how a genre evolved. reply globular-toast 7 hours agoparentprevAs someone who reads books for fun (including hardcore technical books) I get where you're coming from. But I think the author understands that books can be both fun and useful. In fact they point it out several times. There's nothing wrong with reading books (or watching netflix) for fun, but there's nothing wrong with doing it because it's useful either. reply cmiller1 7 hours agorootparentPerhaps, but the fact that they needed to include that line almost defensively speaks to the culture, as if they had to justify why they were reading fiction books. reply walterbell 6 hours agoparentprevIn censorship-plagued societies, some non-fiction can only be found in fiction. reply ChrisArchitect 9 hours agoprevRelated: What is the best thing you read in 2024? https://news.ycombinator.com/item?id=42508087 Best non-fiction book you read in 2024? https://news.ycombinator.com/item?id=42218828 reply bsenftner 10 hours agoprevHis finish, going into details of Nietzsche is simply wonderful. For those that have tried, but cannot penetrate these types of books, start with any Nobel Literature winner that looks interesting. They are the gateway to serious literature, and by reading the recognized \"best written intellectual novel of the year\" you'll be gradually exposed to the writing structures used in harder to penetrate literature. Don't be fooled into thinking that a Nobel Literature winner is difficult to read, none of them are and that is why they have the award. They are also white knuckle rides through tragic human lives where the main character wins against incredible odds, and these novels demonstrate the critical thinking and secondary considerations necessary to prevail when others are crushed. Great literature teaches one first hand how to use critical thought, a dire need today. reply GeoAtreides 3 hours agoparent> Don't be fooled into thinking that a Nobel Literature winner is difficult to read, none of them are Kind of a stretch there. No casual reader can handle Doctor Faustus (Thomas Mann) or the Glass beads game (Hesse) without serious effort. Sure, one can try, in the same way one can try running a marathon without training, with the same predictable results. reply tyrust 40 minutes agorootparentI've read a few books from Hesse, including The Glass Bead Game, and found the English translations rather readable. His more commonly recommended books, Siddhartha and Steppenwolf, should be fine for any high school level reader. reply AnonC 9 hours agoparentprevAny personal recommendations for a starter or favorites (perhaps top three or five or something like that)? reply nihzm 1 hour agorootparentRoughly sorted by thickness (for the editions I own), these are among my favourites and arguably a good starting point * Animal Farm - George Orwell * The Fall - Albert Camus * Flowers for Algernon - Daniel Keyes * One hundred years of solitude - Gabriel García Márquez * The Master and Margarita - Mikhail Bulgakov reply matthew_stone 8 hours agorootparentprevThree Booker prize winners I’m particularly fond of: The God of Small Things - Arundhati Roy The Remains of the Day - Kazuo Ishiguro Girl, Woman, Other - Bernardine Evaristo Pachinko by Min Jin Lee is another recent literary favorite reply atulatul 6 hours agorootparentI haven't read Evaristo but I will add Salman Rushdie to your list. Particularly, Midnight's Children. reply matthew_stone 4 hours agorootparentI bounced off Midnight’s Children the first time I tried to read it, but that was probably 10 or 15 years ago now. I’m in between books at the moment, so your comment will push me to put it on the top of my list for the new year :) Girl, Woman, Other is one of my overall favorites from the last few years. Th character work is phenomenal. Do try to read a hard copy, rather than on an ereader, if you can. The book uses punctuation and the layout of text on a page creatively, and I’m not sure how well that gets preserved in an ebook. reply Lyngbakr 4 hours agorootparentI've tried my damnedest, but simply cannot get into Rushdie. Given that Midnight's Children won the \"Booker of Bookers\", I thought that would be a great place to start. When I finished the book I turned it over in my hands wondering if I missed something or if I'm simply not smart enough to get Rushdie. I read a couple more of his books and the result was much the same, unfortunately. reply wahnfrieden 5 hours agorootparentprevKrasznahorkai is by far my favorite Booker recipient He also did the screenplays for most of Bela Tarr’s movies reply bsenftner 7 hours agorootparentprevIt's subtle in how it delivers it's brilliance: A Clockwork Orange. Warning: spoilers follow that do not diminish the knock out punch this work delivers: It's written in it's own language, a mixture of Russian and UK slang, which one cannot read at first. About 3 chapters in, the language clicks and then a good reader starts the book over from the beginning. It is a popular book due to the film, and the ultra violence depicted within, but it is also ground breaking philosophical literature because the main character is a hardened criminal and is the narrator, he spends the entire novel explaining his philosophy of life, which by the end of the novel you realize is the same philosophy of modern politics, and the UK edition of the novel ends with the entire novel being the story of a senior member of parliament's youth origin story. The fact that the novel is in a fictional language increases the reader's submersion in the story line, creating one of the most impactful novels I know. Another great read, much shorter, more like getting into a street brawl: Notes From The Underground by Dostoyevsky. Practically the creator of self critical essays, and often the first read for people interested in Existentialism. Anything from the \"Beat Generation\" authors, anything from Philip K Dick, anything from Herman Hesse. reply stevoski 9 hours agorootparentprevErnest Hemingway - starting with “The Old Man and the Sea”. After reading that, you’ll no longer think that Nobel Prize winners for literature write books that are difficult to read and understand. reply otherme123 2 hours agorootparentWhen someone ask for my favourite author my answer is Hemingway. Want to write better? Try to write like Hemingway. That said, people who read less tend to believe that more and bigger words equal better writting. My (usually scientific) texts are described as \"telegraphic\", and heavily expanded without adding any real content. E.g. \"the house was white\" gets transformed to \"the paint that covered the beautiful house was pure white\". reply jgalt212 8 hours agorootparentprevMost of Steinbeck is similarly approachable. reply smodo 8 hours agorootparentprevImre Kertesz - Fatelessness Easy to read but provides a profound understanding of the unique historical situation it describes. A famous and heartbreaking sentence: ‘(…) I would like to live a little bit longer in this beautiful concentration camp.’ reply okasaki 9 hours agorootparentprevDoris Lessing reply sillyfluke 7 hours agoparentprevI like to encourage extensive use of quotes whenever I see them in book reviews, and at least this author makes a little effort to provide some. It often annoys me to no end when I read long book reviews with very little quotes from the actual book. Like, where is the evidence of this amazing writing. I understand that for some books specific quotes don't quite get across what makes the book great. But in those cases I expect the author to address that characteristic directly, and make an effort to try to explain why the book is great despite not being very quotable. And by quotes I mean quotes that can span an entire page if need be. The only exceptions to this that I'm inclined to allow is when your descriptive writing skill is at such a pro level that the review itself is a piece of art. But most \"professional\" book reviewers are not even at that pro level frankly. An example of actual \"pro level\" would be this Martin Amis line from one of his reviews: \"You can stir a vat of molasses with James Wood's Chekhov boner.\" (I'm recalling the line from memory) reply pavlov 5 hours agorootparentLong quotes are problematic from a copyright point of view, especially because different countries have different interpretations of what may be called \"right to quote\" or \"fair use\". reply p3rls 7 hours agoparentprev>> Great literature teaches one first hand how to use critical thought, a dire need today. And that's why we see in the halls of our colleges, where these works are pored over day in and day out, that these humanities majors are the font of wisdom in our civilization. BTW Nietzche speaks in goodreads quotes and meme-like aphorisms. If you can't get through Nietzche maybe reading isn't for you. (There's nothing wrong with audiobooks, https://www.youtube.com/watch?v=sv5IyRuEVI4&t=10s either) reply bsenftner 7 hours agorootparentIf not them, then who is? It sure is not the management wealth class, driving all of humanity off an extinction cliff. It's not the religious leaders, that appear to be as corrupt as they can possibly be. It's not the tech industry or leaders, that appear to be yes-person suck ups to wealth if not fascist wealth itself. Wisdom does not equate with power, in fact: overt power is not the result of wisdom, but fanatical perseverance to wealth creation, often in opposition of wisdom in favor of simple dominance of others, and basic mental illness driving that individual. reply maeil 4 hours agorootparentYour profile has made me curious. May I ask you if it was the MBA itself that made you come to this insight? It's so uncommon to see an MBA holder with such views. reply bsenftner 2 hours agorootparentWell, I also have 5 undergraduate degrees: computer science, creative writing, philosophy, statistics, and a general business degree. I was a fat kid that stuttered, read far too much to avoid people and then got carried away with learning. I read all the Nobel Lit winners by the end of my 4th grade, by the end of grade school I was running out of authors, but I discovered writing software and that took over my attention. Plus, my MBA was also to understand the world, as business is this world. reply JadeNB 5 hours agorootparentprev> BTW Nietzche speaks in goodreads quotes and meme-like aphorisms. Aside from the fact that I doubt it's true, this seems a lot like panning The Third Man as derivative of later thrillers. reply vmilner 8 hours agoprevI can never praise A Wizard of Earthsea enough - although it’s highly regarded I never think it quite receives the level of praise it should as a book that will move children (and adults). I first heard it read by Edward Fox on BBCs Jackanory in the mid70s and have remembered it ever since. reply thefaux 3 hours agoparentIt bums me out that we live in the world of Hogwarts rather than the world of Earthsea. Even though they are accessible to children, the depth of these books is so far beyond most contemporary culture while also beautifully stirring the imagination. reply diob 4 hours agoprevBest I read in 2024: \"I'm Starting to Worry About This Black Box of Doom\" Highly recommend it to folks, especially if you enjoy Pargin's other works (\"John Dies at the End\", \"Futuristic Violence and Fancy Suits\"). I am continually in awe at how he is evolving as a writer. His characterizations and insights convey a unique and profound interest in the world we live in, and it’s clear he takes great care in understanding others and what makes them who they are. It'll make you rethink some of your relationships / reactions to the current world (social media, other humans, etc.). reply edanm 26 minutes agoparentIt's really interesting how strongly Pargin has managed to \"brand\" himself, at least in my mind. I read the title you mentioned, and despite only having read \"John Dies at the End\", I insta-guessed it's the same author. Weird thing is that \"John Dies at the End\" sounds like something I'd love, and yet I really bounced off of it when trying to read it. I've been meaning to give it another go. reply diob 5 minutes agorootparentThat series definitely had a different feel at the start compared to his current work (and even later work in the same series). He's no less funny, but he's honed in on exploring the human condition (in a natural way) in each of his books. reply pknerd 7 hours agoprevA kind of off-topic: How do you, as a techie, find time to read most of the books? Any tips or hacks? Ryan Holiday once mentioned that he managed to read extensively by always keeping books with him, allowing him to read whenever he found some spare time. reply edanm 22 minutes agoparentListen to audiobooks. The amount of \"spare time\" most people have, time they're doing random things that don't require full focus, is enormous, at least it is for me. Arranging breakfast for the kids before the school day, doing dishes, walking to and from places, working out at the gym, etc - all of those times become moments to listen to whatever you're reading. reply s1artibartfast 7 hours agoparentprevI think having/making time to read is pretty independent from being a techie. I know people who work 6 hours a week and 60 hours a week. People that haven't touched a book since college, and those that build their careers around the ability to read books. reply linsomniac 6 hours agoparentprevI've made it part of my bedtime routine. Part of it is that it is not the dreaded \"blue light\". Some days I only ready for ~5 minutes before I'm falling asleep, but I try to make at least some progress every day before sleeping. reply rr808 7 hours agoparentprevRight and how do you stop your wife and/or kids interupting you every 30 seconds? I also I have a huge backlog of tech books that I should work on because this career kinda requires it. reply tw42566499 3 hours agorootparentAt the risk of sounding insensitive: an ounce of prevention is worth more than a pound of cure—this is one of those things that if it's a problem someone is experiencing, that thing is not their real problem, which is a deep failure somewhere else, way, way back. The unvarnished truth is that the answer to your question (\"how do you stop your wife and/or kids interrupting you every 30 seconds?\") for many people is \"I don't\". They don't stop them, that is. Because they don't have to. Because they didn't marry someone who interrupts them every 30 seconds and then have kids with them and then raise those kids to be the kinds of kids who interrupts them every 30 seconds. reply ilbeeper 6 hours agorootparentprevRead when they are asleep. I also read when sitting next to my son on his bed, after I read him a book, while waiting for him to fall asleep reply rr808 6 hours agorootparentYeah I miss those days, now they go to bed after I do. :) reply maksimur 3 hours agorootparentprevI set up some time for myself and let everybody know not to interrupt me unless necessary. reply sonabinu 7 hours agorootparentprevCould also be husband and kids ;) reply rr808 6 hours agorootparentAbsolutely! I'm sure some couples are both readers, still not sure I'd have the time though. reply sonabinu 5 hours agorootparentThere are weekends where I spent 3 to 4 hours reading at the public library. It is definitely a deliberate act, not always supported by other family members but it is possible. I am able to do 20 to 30 books a year. All the best! I hope you are able to get started. Happy reading. reply sonabinu 7 hours agoparentprevI have my reading material next to my work desk. I read 15 to 20 minutes before I start work and most days read about 15 to 20 before bed. I also read over the weekends and have chosen that over TV and other entertainment. I carry a book with me to places where I have to wait - doctor's office, DMV, airports, school conferences etc. reply BeetleB 4 hours agoparentprev> How do you, as a techie, find time to read most of the books? Audiobooks while driving. I easily do over ten a year this way. reply SoftTalker 2 hours agorootparentDoes that count as \"reading\" though? I find it very difficult to engage with an audiobook in the way I do with a real book in my hands. reply edanm 23 minutes agorootparentYes, it \"counts\". There are differences, but the main point of books (the conveying of a story and/or information) happens perfectly well with audiobooks, at least for me. reply selykg 2 hours agorootparentprevI would call it reading. But it’s up to the person. Ultimately I find time for both. I completed 30 books in 2024. 2-3 of them were audiobooks I think. They count in my opinion. reply SoftTalker 2 hours agorootparentThat's pretty impressive. I have not read 30 books in the past decade. Probably not even 10. reply SonicScrub 7 hours agoparentprevEscape into the woods for at least 1 week out of the year with no internet connection. It rekindles my love for reading, and helps keep that fire burning throughout the year. reply AnimalMuppet 7 hours agorootparentI do that (for a few days, not a full week). I always read less than I intended to, because the space to be able to think, to feel, and to be is more valuable than the space to read. reply joeyagreco 6 hours agoparentprevThe rule of thumb is: The number of pages you read every day is the number of books you will read in a year. Read 10 pages per day? That's 10 books that year. I read a little less than 1 page per minute (depends on book), but the way I look at it is minutes per day = books in year. Read 30 minutes every day that's 30 books that year. reply Scarblac 6 hours agoparentprevI often spend way too much time on my phone (like now). The days when I keep my ereader nearby so I look at that instead I am much happier. reply wazoox 7 hours agoparentprevWhen I take my breakfast, I'm reading a book. Whenever I lie on my bed, I'm reading a book. This way, I read 30-50 books every year. I don't use any of TikTok, WhatsApp, X etc, that probably helps too. reply hypertexthero 5 hours agoprevMy 2024 favorites: * The Creative Act by Rick Rubin. Maybe the best book about creative process in everyday life and art I’ve read. Positive vibes and meditations. Speaking of which… * Meditations by Marcus Aurelius. Timeless advice about life and death from a ruler/philosopher who seemed to have been actually good and uncorrupted by power. And speaking of that, at the top of my to-read list for 2025 sits On Tyranny: Twenty Lessons from the Twentieth Century by Timothy Snyder, also available in a visual graphic edition. * Drawing on the Dominant Eye by Betty Edwards. Worthwhile, even if not as much as Drawing on the Right Side of the Brain. * Not finished yet, but The Art of Game Design, A Book of Lenses by Jesse Schell is eloquent and erudite so far. reply ok123456 4 hours agoprevUnmask Alice by Rick Emerson was a very enjoyable read. It's about Beatrice Sparks and her unique genre of fake teen diaries, of which Go Ask Alice was the most famous. It chronicles her whole-cloth invention of tragic teens who succumbed to whatever the current panic is consuming late-to-mid-twentieth-century concerned suburban parents: from accidentally becoming acid freaks to ritualistic satan worship to HIV/AIDS. reply avaika 5 hours agoprevMy 2024 top 3: - They would never hurt a fly. Croatian journalist Slavenka Drakulic covered the Hague trial for military crimes in Bosnia war. The book made me rethink how I view the war in general and what motivates people to do absolute evil things. - A primate memoir by Sapolsky. I can't stress enough how interesting, witty and overwhelming this book is. One of the rare reads I couldn't stop reading until the very end. - Neapolitan novels by Elena Ferrante. Even though sometimes it might be felt like a boulevard novel, it gave me absolutely fantastic insight and the atmosphere of Italian Naples in the 1960-1970s. reply HellDunkel 10 hours agoprevI just finished the Cicero Trilogy by Robert Harris. Probably easier to digest than the works of the man himself and a very good read too. reply alkyon 7 hours agoparentFinished Imperium, Lustrum and Dictator last year - what an excellent read! By Harris I also enjoyed Fatherland, his alternative history detective novel. reply vmilner 8 hours agoparentprevI sometimes struggle with Harris’s recent books but I agree these are great. reply DavidPiper 10 hours agoprevStrong second for Born Standing Up, just in case anyone was on the fence. Steve Martin is a delight. (Get the paperback if you can, the edition I have is the most well-weighted and well-proportioned high-quality paperback I think I own. I hope they still print it like that.) reply linsomniac 7 hours agoparentBought. The Kindle edition is $2.99 at amazon right now. Long ago I read Shopgirl by Steve Martin and I recall enjoying it, but don't recall much about it. Looks like it's a movie now. Just recently, after that SNL skit about the Five Timers Club, I found that Steve Martin was the fastest to reach the Fiver Timers Club, it sounds like in 1977 he was hosting SNL all the time. Thanks for the recommendation, I've added it to my To Read list (currently working on Doctrow/Stross Rapture of the Nerds, I'm kind of Meh on it). reply kh_hk 1 hour agoprevHarry Potter and the Methods of Rationality reply rottc0dd 4 hours agoprevI personally loved \"The Gene : An intimate history\". I thought genes were hardcoded code that is needed sometime during life creation and once the cells specialized, they are done. The cells are computer that operated on proteins, the input is protein being present and output is specific protein that does specific job. reply hinkley 1 hour agoprevI got through almost 50 books last year, which is about what I got through in the previous three. The first trick was giving myself permission to stop a book I started in 2023. I’m about to start trying to finish it again later this week. The biggest was finding myself with too much free time which I don’t recommend. But all the physical books I read were strictly for pleasure and not self improvement. The half dozen books I consumed in the latter category were as audiobooks, and half of those were Goldratt, who cheats anyway by making his entire book into a fictional story about the moral of the book. Essentially a parable. If you want to read a lot, then do it to have a good time. reply wannabebarista 5 hours agoprevHere's my list for 2024: * Wisdom’s Workshop (2016) by James Axtell is a history of the American research university from Medieval times to the present. * The Principles of Science (1874) by William Stanley Jevons (of economics fame) is a wide-ranging treatment of logic and philosophy of science that’s bursting with ideas. * Ballyhoo! (2024) by Jon Langmead is a history of professional wrestling and combat sports from its outlaw roots in the late nineteenth century through the first half of the twentieth century. * A Discourse on Political Economy (1824) by John Ramsay McCulloch is the first history of economic thought from the era of the classical economists. Check it out in more detail here: https://bcmullins.github.io/interesting-books-2024/ reply amarcheschi 11 hours agoprevI read the strangest man a few years ago, a therapist I went to talk to suggested me to read it because - despite not bejng possible to diagnose dead people - he definitely had some traits that overlapped with autism. Definitely an interesting read reply globular-toast 7 hours agoparentI read it years ago and it definitely helped me get comfortable in my own skin. There's more acceptance (or at least it's given more lip service) towards \"neirodivergent\" people now, but for a long time it felt like I had something wrong with me because I didn't understand normies. There are also some good documentaries and books about the people working at Bletchley Park. A lot of them seemed to have been wired similarly. reply swayvil 8 hours agoparentprevIn the old days they called it, \"habitually one-pointed\". Those guys really know how to concentrate. reply bilater 3 hours agoprevHere's my book journey as a visual :) https://x.com/deepwhitman/status/1872821464417878256 reply norir 4 hours agoprevThe most impactful book I read this year was \"Computer Power and Human Reason\" by Joseph Weizenbaum. For a book written about ai in 1976, it has aged very well. reply voisin 4 hours agoprevI really enjoyed Dutch House and Commonwealth, both by Anne Patchett. Beautiful writing about somewhat commonplace or relatable people and their lives. reply buseb 10 hours agoprevSiddharta, Anna Karenina reply alexpotato 6 hours agoprevI recently started putting together an organized list of books I've really loved. It's organized and filterable by: - fiction vs non fiction - author - general themes https://alexpotato.com/books/?l=hn reply imajoredinecon 3 hours agoprevThe Idiot by Elif Batuman So funny that my face was basically fixed in a smile the entire time reading. reply unitpass 4 hours agoprevMy favorite book is Deep Work by Cal Newport reply joeyagreco 6 hours agoprevMy top 3 books of 2024: 1. Right/Wrong - Juan Enriquez 2. Man's Search for Meaning - Viktor E. Frankl 3. How to Win Friends & Influence People - Dale Carnegie reply Apocryphon 1 hour agoprevre: that Paul Dirac book, were there any atomic scientists during WWII who wasn't a mystic? reply retskrad 11 hours agoprevPeople often lament the decline in literacy, but the books mentioned in the article demand hundreds or thousands of hours of focused practice to achieve even moderate reading speed and comprehension. These books can be far more rewarding than social media or YouTube, but they are often dense, esoteric, and written in complex sentence structures. Since our brains aren’t naturally wired for reading, developing this skill is a challenging and humbling process. Most people decide it isn’t worth the effort. reply technothrasher 8 hours agoparent> Since our brains aren’t naturally wired for reading There's actually some evidence that we are, in fact, naturally wired for reading. The below study, for instance, shows that the area in the brain used for visualizing words seems to be already hooked up to language processing areas in newborns. https://www.nature.com/articles/s41598-020-75015-7 reply Jabbles 10 hours agoparentprev> Most people decide it isn’t worth the effort Most people \"decide\" to not develop their reading skills when they are young children without the ability to understand the long-term implications. reply criddell 8 hours agorootparentAI tutors might help with this because I think the constraints teachers have make it difficult to foster a love of books in a lot of kids. When I was growing up, teachers would assign one text for the entire class to read. Sometimes it was a book I enjoyed (like Canticle for Leibowitz) but more often than not it was some book I hated (like Great Gatsby which I reread as an adult and still think it’s terrible). If you really wanted to instill a love of reading and develop skills around reading, you would give students more choice. My kids had a similar experience so I don’t think much changed between 1985 and 2015. If anything, it’s worse now. It feels like schools do as much as they can to prevent kids from enjoying reading. They were assigned only books they had zero interest in and were given so much homework they had no desire or energy left to read for pleasure. It took me a long time after high school to start reading for pleasure (thank you Douglas Adams and Michael Ondaatje). I hope it works out for my kids too. So maybe the problem isn't kids who decide they don't like to read, but voters and taxpayers have decided that they don't want to pay for anything better. reply cinntaile 10 hours agoparentprevIt depends. If the complex sentence structures can be expressed more clearly using simpler structures, I would argue the writer is lacking. reply dantondwa 8 hours agorootparentSometimes the writing itself is a guide for the mind of the reader, and the indirect path prose can take is part of the message. Not everything has to be written in digestible snippets of text. reply raffraffraff 9 hours agorootparentprevMy wife writes a little, but reads a lot. One time she went back and re-read something she had written years ago, and came away thinking \"I hate this type of writing! It thinks it's so damn smart!\". Her takeaway was this: if you're in love with the way you phrased something, rewrite it. Hey goal is to write a story with plot. Real characters. Arcs. As soon as she finds herself wasting time rolling sentences around her mouth, like toffee, with big fancy words, she is directly hurting the readers' flow. Sometimes it's nice to leave one or two, but in general you shouldn't try to be in love with every sentence you've written. But every sentence should move the story forward. Just tell the damn story. Because when you come back to your writing years later, it's those very stylish, witty, fancy phrases that will embarrass you. reply cenazoic 8 hours agorootparentI think this speaks to a common misunderstanding of ‘literary’ fiction vs. ‘genre’ fiction - the former is typically more character- or idea-driven, while the latter is story/plot driven. I’m not making the argument that one is intrinsically ‘better’ than the other; rather that their goals are different. I do tend to agree with the idea that you shouldn’t be ‘afraid to kill your darlings’ (cite needed). Flannery O’Connor was once asked whether she thought that MFA programs killed too many aspiring authors. Her reply was that she thought they didn’t kill enough of them. reply aspenmayer 1 hour agorootparent> I do tend to agree with the idea that you shouldn’t be ‘afraid to kill your darlings’ (cite needed). Flannery O’Connor was once asked whether she thought that MFA programs killed too many aspiring authors. Her reply was that she thought they didn’t kill enough of them. It's funny to me that that line by O’Connor is both good writing and good business, at least in that it reduces competition with their own works. Furthermore, making quotable quips is the best kind of publicity for your writing you can do for free as an author. I wonder how many MFA programs are so explicit about the dismal prospects of writing as a livelihood or career, not that it was ever much better in the past. Arguably, it's easier than ever to get paid as an independent writer, but that doesn't make it any easier to make a decent living exclusively from one's published output. Found the citation: https://en.wiktionary.org/wiki/kill_one%27s_darlings > A piece of advice to prospective authors that they must kill their “darlings”, i.e. suppress overuse of their favorite expressions, tropes, characters, etc. Often attributed to William Faulkner (1897–1962), but already expressed earlier by Arthur Quiller-Couch (murder one's darlings); more recently popularized by Stephen King. reply bbddg 8 hours agorootparentprevWas it intentional that you used the phrase “rolling sentences around her mouth, like toffee” in a post about how it’s better to write plainly? reply greenie_beans 7 hours agorootparentprevwilliam faulkner would like a word reply greenie_beans 7 hours agoparentprevreading this whole debate in this thread, i thought: \"literary fiction writers should not be worried about ai because tech ppl don't like prose\" reply HellDunkel 10 hours agoparentprevThe thing is- it often isn‘t (worth it) until you can put things in context and even then it is not a given you will be rewarded. I stopped reading to forcefully educate myself and just read for entertainment. Turns out I read much more and even found many more great books i want to read. reply begueradj 5 hours agoprevFrom my experience, Sturgeon's law applies to books too. reply dllthomas 5 hours agoparentI mean, it would, wouldn't it? Theodore Sturgeon wrote a bunch of books, and I've always assumed his \"Revelation\" was initially delivered in that context. reply coolThingsFirst 10 hours agoprev [–] that's i think a lot reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The list features a diverse range of books, including historical, philosophical, scientific, and personal narratives, each offering unique insights and enriching experiences.",
      "Highlights include Cicero's letters for insights into Roman life, Ben-Ari's works on computer science logic and program verification, and Steve Martin's memoir on comedic success.",
      "The collection also includes philosophical explorations by Pierre Hadot and Nietzsche, Greek tragedies by Aeschylus, and literary works by Ursula Le Guin and Rabindranath Tagore."
    ],
    "commentSummary": [],
    "points": 289,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1735719369
  },
  {
    "id": 42568399,
    "title": "Terence Tao: One of my papers got declined today",
    "originLink": "https://mathstodon.xyz/@tao/113721192051328193",
    "originBody": "Create accountLogin Recent searches No recent searches Search options Only available when logged in. mathstodon.xyz is one of the many independent Mastodon servers you can use to participate in the fediverse. Administered by: Server stats: mathstodon.xyz: About · Status · Profiles directory · Privacy policy Mastodon: About · Get the app · Keyboard shortcuts · View source code · v4.3.1 SearchLive feeds Mastodon is the best way to keep up with what's happening. Follow anyone across the fediverse and see it all in chronological order. No algorithms, ads, or clickbait in sight. Create accountLogin About",
    "commentLink": "https://news.ycombinator.com/item?id=42568399",
    "commentBody": "Terence Tao: One of my papers got declined today (mathstodon.xyz)255 points by GavCo 3 hours agohidepastfavorite84 comments dwaltrip 2 hours agoHilarious irony: > With hindsight, some of my past rejections have become amusing. With a coauthor, I once almost solved a conjecture, establishing the result with an \"epsilon loss\" in a key parameter. We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture. So we submitted elsewhere, and the paper was accepted. > The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again. This time, the paper was rejected for only being an epsilon improvement over the previous literature! reply bumby 44 minutes agoparentA lot of the replies make it seem like there is some great over-arching coordination and intent between subsequent submissions, but I’ll offer up an alternative explanation: sometimes the reviewer selection is an utter crap shoot. Just because the first set of reviewers may offer a justification for rejection, it may be completely unrelated to the rationale of a different set of reviewers. Reviewers are human and bring all kinds of biases and perspectives into the process. It’s frustrating but the result of a somewhat haphazard process. It’s also not uncommon for conflicting comments within the same review cycle. Some of this may be attributed to a lack of clear communication by the author. But on occasion, it leads me to believe many journals don’t take a lot of time selecting appropriate reviewers and settle for the first few that agree to review. reply grepLeigh 1 minute agorootparentWhat's the compensation scheme for reviewers? Are there any mechanisms to balance out the \"race to the bottom\" observed in other types of academic compensation? e.g. increase of adjunct/gig work replacing full-time professorship. Do universities require staff to perform a certain number of reviews in academic journals? reply bradleyjg 2 hours agoparentprevThis seems reasonable? Suppose the full result is worth 7 impact points, which is broken up into 5 points for the partial result and 2 points for the fix. The journal has a threshold of 6 points for publication. Had the authors held the paper until they had the full result, the journal would have published it, but neither part was significant enough. Scholarship is better off for them not having done so, because someone else might have gotten the fix, but the journal seems to have acted reasonably. reply tux3 2 hours agorootparentIf people thought this way - internalizing this publishing point idea - it would incentivize sitting on your incremental results, fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take. If a series of incremental results were as prestigious as holding off to bundle them people would have reason to collaborate and complete each other's work more eagerly. Delaying an almost complete result for a year so that a journal will think it has enough impact point seems straightforwardly net bad, it slows down both progress & collaboration. reply gwerbret 1 hour agorootparent> If people thought this way - internalizing this publishing point idea - it would incentivize sitting on your incremental results, fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take. This is exactly what people think, and exactly what happens, especially in winner-takes-all situations. You end up with an interesting tension between how long you can wait to build your story, and how long until someone else publishes the same findings and takes all the credit. A classic example in physics involves the discovery of the J/ψ particle [0]. Samuel Ting's group at MIT discovered it first (chronologically) but Ting decided he needed time to flesh out the findings, and so sat on the discovery and kept it quiet. Meanwhile, Burton Richter's group at Stanford also happened upon the discovery, but they were less inclined to be quiet. Ting found out, and (in a spirit of collaboration) both groups submitted their papers for publication at the same time, and were published in the same issue of Physical Review Letters. They both won the Nobel 2 years later. 0: https://en.wikipedia.org/wiki/J/psi_meson reply jvanderbot 1 minute agorootparentWait, how did they both know that they both discovered it, but only after they had both discovered it? chongli 1 hour agorootparentprevThe reasonable thing to do here is to discourage all of your collaborators from ever submitting anything to that journal again. Work with your team, submit incremental results to journals who will accept them, and let the picky journal suffer a loss of reputation from not featuring some of the top researchers in the field. reply slow_typist 1 hour agorootparentprevDon‘t know much about publishing in maths but in some disciplines it is clearly incentivised to create the biggest possible number of papers out of a single research project, leading automatically to incremental publishing of results. I call it atomic publishing (from Greek atomos - indivisible) since such a paper contains only one result that cannot be split up anymore. reply jonas21 40 minutes agorootparentprev> fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take. This doesn't really happen, except in obscure areas, because you always have to worry about being scooped (i.e. someone independently publishing the incremental result while you're sitting on it). reply SoftTalker 1 hour agorootparentprevScience is almost all incremental results. There's far more incentive to get published now than there is to \"sit on\" an incremental result hoping to add to it to make a bigger splash. reply bennythomsson 46 minutes agorootparentprevTo supply a counter viewpoint here... The opposite is the \"least publishable unit\" which leads to loads and loads of almost-nothing results flooding the journals and other publication outlets. It would be hard to keep up with all that if there wasn't a reasonable threshold. If anything then I find that threshold too low currently, rather than too high. The \"publish or perish\" principle also pushes people that way. reply jvanderbot 46 minutes agorootparentprevHyper focusing on a single journal publication is going to lead to absurdities like this. A researcher is judged by the total delta of his improvements, at least by his peers and future humanity. (the sum of all points, not the max). reply JJMcJ 1 hour agorootparentprevGauss did something along these lines and held back mathematical progress by decades. reply bradleyjg 2 hours agorootparentprevThe big question here is if journal space is a limited resource. Obviously it was at one point. Supposing it is, you have to trade off publishing these incremental results against publishing someone else’s complete result. What if it had taken ten papers to get there instead of two? For a sufficiently important problem, sure, but the interesting question is at a problem that’s interesting enough to publish complete but barely. reply parpfish 1 hour agorootparentThe limiting factor isn’t journal space, but attention among the audience. (In theory) the journals publishing restrictions help to filter and condense information so the audience is maximally informed given that they will only read a fixed amount reply btilly 1 hour agorootparentprevJournal space is not a limited resource. Premium journal space is. That's because every researcher has a hierarchy of journals that they monitor. Prestigious journals are read by many researchers. So you're essentially competing for access to the limited attention of many researchers. Conversely, publishing in a premium journal has more value than a regular journal. And the big scientific publishers are therefore in competition to make sure that they own the premium journals. Which they have multiple tricks to ensure. Interestingly, their tricks only really work in science. That's because in the humanities, it is harder to establish objective opinions about quality. By contrast everyone can agree in science that Nature generally has the best papers. So attempting to raise the price on a prestigious science journal, works. Attempting to raise the price on a prestigious humanities journal, results in its circulation going down. Which makes it less prestigious. reply YetAnotherNick 2 hours agorootparentprevTwo submission in medium reputation journal does not have significantly lower prestige than one in high reputation journal. reply Arainach 2 hours agorootparentprevThese patterns are ultimately detrimental to team/community building, however. You see it in software as well: As a manager in calibration meetings, I have repeatedly seen how it is harder to convince a committee to promote/give a high rating to someone with a large pile of crucial but individually small projects delivered than someone with a single large project. This is discouraging to people whose efforts seem to be unrewarded and creates bad incentives for people to hoard work and avoid sharing until one large impact, and it's disastrous when (as in most software teams) those people don't have significant autonomy over which projects they're assigned. reply remus 2 hours agorootparentprev> This seems reasonable? In some sense, but it does feel like the journal is missing the bigger picture somewhat. Say the two papers are A and B, and we have A + B = C. The journal is saying they'll publish C, but not A and B! reply Nevermark 2 hours agorootparentHow many step papers before a keystone paper seems reasonable to you? I suspect readers don’t find it as exciting to read partial result papers. Unless there is an open invitation to compete on its completion, which would have a purpose and be fun. If papers are not page turners, then the journal is going to have a hard time keeping subscribers. On the other hand, publishing a proof of a Millennium Problem as several installments, is probably a fantastic idea. Time to absorb each contributing result. And the suspense! Then republish the collected papers as a signed special leather limited series edition. Easton, get on this! reply slow_typist 1 hour agorootparentPublishing partial results is always an invitation to compete in the completion, unless the completion is dependent on special lab capabilities which need time and money to acquire. There is no need to literally invite anyone. reply cubefox 2 hours agorootparentprev... A and B separately. reply omoikane 38 minutes agorootparentprevBut proportionally, wouldn't a solution without an epsilon loss be much better than a solution with epsilon? I am not sure what's the exact conjecture that the author solved, but if the epsilon difference is between an approximate solution versus an exact solution, and the journal rejected the exact solution because it was \"only an epsilon improvement\", I might question how reputable that journal really was. reply sunshowers 33 minutes agorootparentprevGiven the current incentive scheme in place it's locally reasonable, but the current incentives suck. Is the goal to score the most impact points or to advance our understanding of the field? reply cvoss 2 hours agorootparentprevThe idea that a small number of reviewers can accurately quantify the importance of a paper as some number of \"impact points,\" and the idea that a journal should rely on this number and an arbitrary cut off point to decide publication, are both unreasonable ideas. The journal may have acted systematically, but the system is arbitrary and capricious. Thus, the journal did not act reasonably. reply pinkmuffinere 2 hours agorootparentprevI agree this is reasonable from the individual publisher standpoint. I once received feedback from a reviewer that I was \"searching for the minimum publishable unit\", and in some sense the reviewer was right -- as soon as I thought the result could be published I started working towards the publication. A publisher can reasonably resist these kinds of papers, as you're pointing out. I think the impact to scholarship in general is less clear. Do you immediately publish once you get a \"big enough\" result, so that others can build off of it? Or does this needlessly clutter the field with publications? There's probably some optimal balance, but I don't think the right balance is immediately clear. reply nextn 1 hour agorootparentWhy would publishing anything new needlessly clutter the field? Discovering something is hard, proving it correct is hard, and writing a paper about is hard. Why delay all this? reply bumby 32 minutes agorootparentPlaying devils advocate, there isn’t a consensus on what is incremental vs what is derivative. In theory, the latter may not warrant publication because anyone familiar with the state-of-the-art could connect the dots without reading about it in a publication. reply SilasX 51 minutes agorootparentprevOuch. That would hurt to hear. It's like they're effectively saying, \"yeah, obviously you came up with something more significant than this, which you're holding back. No one would be so incapable that this was as far as they could take the result!\" reply Brian_K_White 1 hour agorootparentprevIt's demonstrably (there is one demonstration right there) self-defeating and counter-productive, and so by definition not reasonable. Each individual step along the way merely has some rationale, but rationales come in the full spectrum of quality. reply saghm 2 hours agorootparentprevIf this was actually how stuff was measured, it might be defensible. I'm having trouble believing that things are actually done this objectively rather than the rejections being somewhat arbitrary. Do you think that results can really be analyzed and compared in this way? How do you know that it's 5 and 2 and not 6 and 1 or 4 and 3, and how do you determine how many points a full result is worth in total? reply Ar-Curunir 2 hours agorootparentprevI don’t think that’s a useful way to think about this, especially when theres so little information provided about this. Reviewing is a capricious process. reply stevage 2 hours agoparentprevIt actually seems reasonable for a journal that has limited space and too many submissions. What's the alternative, to accept on or two of the half proofs, and bump one or two other papers in the process? reply jiggawatts 2 hours agorootparentWow, it’s so sad that their budget doesn’t stretch to purchasing hard drives with capacities measured in gigabytes. It must be rough having to delete old files from the floppies they’re still forced to use in this day and age. reply y1n0 1 hour agorootparentThat logic is absurd. You might as well consider the whole internet a journal and everything is already published, so there is nothing to complain about. reply jiggawatts 1 hour agorootparentIt pretty much is the logic — except replace digital media with paper. It’s also “why” research papers can’t have color pictures or tables of raw data — because they’re expensive to print. Scientists internalised their limitations and treat these as virtues now. Limited space in printing means you have to “get in”, and that exclusivity has a cachet. They also now advise each other that photos are “not real science” (too much color!) and raw data shouldn’t be published at all. I was making a joke to highlight how inane this is in an era where I can keep every paper ever published on one hard drive. The same people that complain about negative results or reproductions not getting published will defend these limitations to the death. reply JJMcJ 1 hour agoparentprevDo Reddit mods also edit math journals? reply gxs 2 hours agoparentprevAre you sure this wasn’t an application to the DMV or an attempt to pull a building permit? reply kzz102 1 minute agoprevIn academic publishing, there is an implicit agreement between the authors and the journal to roughly match the importance of the paper to the prestige of the journal. Since there is no universal standard on either the prestige of the journal or the importance of the paper, mismatches happen regularly, and rejection is the natural result. In fact, the only way to avoid rejections is to submit a paper to a journal of lower prestige than your estimate, which is clearly not what authors want to do. reply cperciva 1 minute agoprevIn 2005, my paper on breaking RSA by observing a single private-key operation from a different hyperthread sharing the same L1 cache -- literally the first publication of a cryptographic attack exploiting shared caches -- was rejected from the cryptology preprint archive on the grounds that \"it was about CPU architecture, not cryptography\". Rejection from journals is like rejection from VCs -- it happens all the time and often not for any good reason. (That paper has now been cited 971 times according to Google Scholar, despite never appearing in a journal.) reply jraph 2 hours agoprevI was confused by the title because paper rejection is incredibly common in research, but that's the point and one of the goals is to fight imposter syndrome. It's a good initiative. Next step: everybody realizes that researchers are just random people like everybody. Maybe that could kill any remaining imposter syndrome. A rejection, although common, is quite tough during your PhD though, even ignoring the imposter syndrome, because in a short time, you are expected to have a bunch of accepted papers, in prestigious publications if possible. It feels like a rejection slows you down, and the clock is still ticking. If we could kill some of this nefarious system, that'd be good as well. reply arrowsmith 1 hour agoparentIt’s noteworthy because it’s from Terence Tao, regarded by many as the world’s greatest living mathematician. If you read the full post he’s making the exact same point as you: it’s common and normal to get a paper rejected even if you’re Terence Tao, so don’t treat a rejection like the end of the world. reply bisby 2 hours agoparentprevIt's especially important coming from someone like Terence Tao. If one of the best and brightest mathematicians out there can get a paper declined, then it can happen to literally anyone. reply jonathan_landy 20 minutes agoparentprevI guess it is nice to know that he is also not perfect. But it’s still the case that his accomplishments outshine my own, so my imposter syndrome remains intact. reply 2-3-7-43-1807 6 minutes agoparentprevterence tao is suffering from imposter syndrome? if anything, imposter syndrome is suffering from terence tao ... do you maybe not know who terence tao is? reply bumby 2 hours agoprevAdam Grant once related an amusing rejection from a double-blind review. One of the reviewers justified the rejection with something along the lines of “The author would do well to familiarize themselves with the work of Adam Grant” reply orthoxerox 1 hour agoparentLife imitates art. In a 1986 comedy \"Back to School\" Rodney Dangerfield's character delegates his college assignments to various subject matter experts. His English Lit teacher berates him for it, saying that not only did he obviously cheat, but he also copied his essay from someone who's unfamiliar with the works of Kurt Vonnegut. Of course, the essay was written by Vonnegut himself, appearing in a cameo role. reply Upvoter33 1 hour agoparentprevThis also happens pretty commonly. However, it's not even unreasonable! Sometimes you write a paper and you don't do a good enough of a job putting in the context of your own related work. reply CrazyStat 34 minutes agorootparentAnd sometimes the reviewer didn't read carefully and doesn't understand what you're doing. I once wrote a paper along the lines of \"look we can do X blazingly fast, which (among other things) lets us put it inside a loop and do it millions of times to do Y.\" A reviewer responded with \"I don't understand what the point of doing X fast is if you're just going to put it in a loop and make it slow again.\" He also asked us to run simulations to compare our method to another paper which was doing an unrelated thing Z. The editor agreed that we could ignore his comments. reply Nevermark 1 hour agoparentprevYes, funny the first time. Not so much the fifth! reply remoquete 2 hours agoprevI find it refreshing when researchers disclose their own failures. Science is made of negative results, errors, and rejections, though it's often characterized in a much different, unrealistic way. By the way, even though some of you may know about it, here's the link to the Journal of Negative Results: https://www.jnr-eeb.org/index.php/jnr reply UniverseHacker 2 hours agoprevI am actually quite surprised Terence Tao still gets papers rejected from math journals... but appreciate him sharing this, as hearing this from him will help newer scientists not get discouraged by a rejection. I had the lucky opportunity to do a postdoc with one of the most famous people in my field, and I was shocked how much difference the name did make- I never had a paper rejection from top tier journals submitting with him as the corresponding author. I am fairly certain the editors would have rejected my work for not being fundamentally on an interesting enough topic to them, if not for the name. The fact that a big name is interested in something, alone can make it a \"high impact subject.\" reply jcrites 7 minutes agoparentCould that also be because he reviewed the papers first and made sure they were in a suitable state to publish? Or you think it really was just the name alone, and if you had published without him they would not have been accepted? reply vouaobrasil 2 hours agoparentprev> I am actually quite surprised Terence Tao still gets papers rejected from math journals At least it indicates that the system is working somewhat properly some of the time... reply asah 2 hours agoprevNon-zero failure rate is indeed often optimal because it provides valuable feedback toward finding the optimal horizon for various metrics, e.g. speed, quality, LPU[1], etc. That said, given the labor involved in academic publishing and review, the optimal rejection rate should be quite low, i.e. find a lower cost way to pre-filter papers. OTOH, the reviewers may get value from rejected papers... [1] least publishable unit reply tetha 1 hour agoprev> Because of this, a perception can be created that all of one's peers are achieving either success or controversy, with one's own personal career ending up becoming the only known source of examples of \"mundane\" failure. I've found similar insights when I joined a community of musicians and also discovered twitch / youtube presences of musicians I listen to. Some of Dragonforces corona streams are absolutely worth a watch. It's easy to listen to mixed and finished albums and... despair to a degree. How could anyone learn to become that good? It must be impossible, giving up seems the only rational choice. But in reality, people struggle and fumble along at their level. Sure enough, the level of someone playing guitar professionally for 20 years is a tad higher than mine, but that really, really perfect album take? That's the one take out of a couple dozen. This really helped me \"ground\" or \"calibrate\" my sense of how good or how bad I am and gave me a better appreciation of how much of a marathon an instrument can be. reply amichail 2 hours agoprevSure, even top mathematicians have paper rejections. But I think the more important point is that very few people are capable of publishing papers in top math journals. reply slackr 23 minutes agoprevReminds me—I wish someone would make an anti-LinkedIn, where the norm is to announce only setbacks and mistakes, disappointments etc. reply remoquete 12 minutes agoparentFolks already do. They often turn them into inspirational tales. reply TZubiri 1 hour agoprev\"Rejection is actually a relatively common occurrence for me, happening once or twice a year on average.\" This feels like a superhuman trying to empathize with a regular person. reply ndesaulniers 1 hour agoprevThe master has failed more than the beginner has tried. reply justinl33 38 minutes agoprevIt’s okay Terence, it happens to the best of us. reply atrettel 2 hours agoprevI agree with the discussion that rejection is normal and researchers should discuss it more often. That said, I do think that \"publish or perish\" plays an unspoken role here. I see a lot of colleagues trying to push out \"least publishable units\" that might barely pass review (by definition). If you need to juice your metrics, it's a common strategy that people employ. Still, I think a lot of papers would pass peer review more easily if researchers just combined multiple results into a single longer paper. I find those papers to be easier to read since they require less boilerplate, and I imagine they would be easier to pass peer review by the virtue that they simply contain more significant results. reply nextn 1 hour agoparentLonger papers with more claims have more to prove, not less. I imagine they would be harder to pass peer review. reply tredre3 54 minutes agorootparent> Longer papers with more claims have more to prove, not less. I imagine they would be harder to pass peer review. Yes, a longer paper puts more work on the peer reviewers (handful of people). But splitting one project in multiple papers puts more work on the reader (thousands of people). There is a balance to strike. reply ziofill 1 hour agoprevThis is his main point, and I wholeheartedly agree: …a perception can be created that all of one's peers are achieving either success or controversy, with one's own personal career ending up becoming the only known source of examples of \"mundane\" failure. I speculate that this may be a contributor to the \"impostor syndrome\"… reply aborsy 2 hours agoprevResearch is getting more and more specialized. Increasingly there may not be many potential journals for a paper, and, even if there are, the paper might be sent to the same reviewers (small sub communities). You may have to leave a year of work on arxiv, with the expectation that the work will be rehashed and used in other published papers. reply ak_111 2 hours agoprevI always thought that part of the upside of being tenured and extremely recognised as a leader of your field is the freedom to submit to incredibly obscure (non-predatory) journals just for fun. reply ak_111 2 hours agoprev- hey honey how was work today? - it was fine, I desk rejected terence tao, his result was a bit meh and the write up wasn't up to my standard. Then I had a bit of a quite office hour, anyway, ... reply Der_Einzige 1 hour agoparentI've had the surreal moment of attending a workshop where the main presenter (famous) is talking about their soon to-be-published work where I realize that I'm one of their reviewers (months after I wrote the review, so no impact on my score). In this case, I loved their paper and gave it high marks, and so did the other reviewers. Not surprising when I found out who the author was!!! I have to not say a word to them as I talk to them or else I could ruin the whole peer review thing! \"Hey honey, I reviewed X work from Y famous person today\" reply d0mine 2 hours agoprevWhy journals exist at all? Could papers be published on something like arxiv.org (like software is on github.com)? It could support links/backref, citations(forks), questions(discussions), tags, followers, etc easily. reply sunshowers 26 minutes agoparentI think in math, and in many other fields, it is pretty normal to post all papers on arXiv. But arXiv has a lot of incorrect papers on it (tons of P vs NP papers for example), so journals are supposed to act as a filtering mechanism. How well they succeed at it is debated. reply bumby 2 hours agoparentprevPart of the idea is that journals help curate better publications via the peer review process. Whether or not that occurs in practice is up for some debate. Having a curated list can be important to separate the wheat from the chaff, especially in an era with ever increasing rates of research papers. reply NicholasGurr 39 minutes agoprevHe can use my name. - Dr. Nick Gurr reply abetusk 2 hours agoprevThe second post in that thread is gold: \"\"\" ... I once almost solved a conjecture, establishing the result with an \"epsilon loss\" in a key parameter. We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture. So we submitted elsewhere, and the paper was accepted. The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again. This time, the paper was rejected for only being an epsilon improvement over the previous literature! ... \"\"\" reply YouWhy 2 hours agoparentWhile I'm not a mathematician, I think such an attitude on behalf of the journal does not encourage healthy community dynamics. Instead of allowing the community to join forces by breaking up a larger problem into pieces, it encourages siloing and camper mentality. reply abetusk 2 hours agorootparentI agree. This is also a lack of effort on the journal's part to set expectations of what the reviewers should be looking for in an accepted paper. In the journal's defense though, what most likely happened is that the reviewers were different between submissions and they didn't know about the context. Ultimately, I think, this type of rejection comes down to the mostly the reviewers discretion and it can lead to this type of situation. I cut off the rest of the post but Tao finished it with this: \"\"\" ... Being an editor myself, and having had to decline some decent submissions for a variety of reasons, I find it best not to take these sorts of rejections personally, ... \"\"\" reply cess11 1 hour agoprevJournals are typically for-profit, and science is not, so they don't always align and we should not expect journals to serve science except incidentally. reply haunter 2 hours agoprevfwiw, editorial review =/= peer review reply 23B1 1 hour agoprevA similar story. I actively blogged about my thesis and it somehow came up in one of those older-model plagarism detectors (this was years and years ago, it might have been just some hamfisted google search). The (boomer) profs convened a 'panel' without my knowledge and decided I had in fact plagiarized, and informed me I was in deep doo doo. I was pretty much ready to lose my mind, my career was over, years wasted, etc. Luckily I was buddy with a Princeton prof. who had dealt with this sort of thing and he guided me through the minefield. I came out fine, but my school never apologized. Failure is often just temporary and might not even be real failure. reply tinktank 2 hours agoprev [–] I wish I has an IQ that high... reply aleph_minus_one 2 hours agoparentIf you want to become smarter in math, read and attempt to understand brutally hard math papers and textbooks. Torture yourself harder than any time before in your life. :-) reply revskill 2 hours agoparentprev [–] IQ means interesting questions. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Terence Tao, a prominent mathematician, shared an experience of having a paper rejected, underscoring the frequent occurrence of rejections in academia. - His story sparked discussions on the arbitrary nature of peer reviews and the challenges faced in academic publishing. - The conversation highlighted that rejection is a normal part of the academic process, even for leading researchers, and stressed the importance of sharing failures to address imposter syndrome."
    ],
    "points": 256,
    "commentCount": 85,
    "retryCount": 0,
    "time": 1735758777
  },
  {
    "id": 42565821,
    "title": "API Parrot – Automatically Reverse Engineer HTTP APIs",
    "originLink": "https://apiparrot.com/",
    "originBody": "When automating business processes at work, I found it difficult and time-consuming to reverse engineer business systems&#x27; APIs. I often had to manually reverse engineer APIs using developer tools or settle for less optimal technologies such as Robotic Process Automation (RPA).Often, the issue is that it can be hard to resolve all the cookies, access tokens, and other elements required to successfully execute the requests. Manually trying to resolve these dependencies using developer tools is especially challenging with multiple requests where data is stored in JavaScript objects or HTML elements.To try to solve this issue, I built a tool called API Parrot that automatically identifies the data correlations between requests and builds a graphical representation of the flow to give users a better understanding. To streamline the process, I also included functionality to record requests, define your own inputs and outputs, and export the entire flow—or parts of it—as JavaScript code.The application is Electron-based and currently compiled for Windows and Linux. Please try it out and give feedback!Online Tutorial: A simple example of reverse engineering the USPS API is available at https:&#x2F;&#x2F;docs.apiparrot.com&#x2F;docs&#x2F;category&#x2F;tutorial---reverse-...",
    "commentLink": "https://news.ycombinator.com/item?id=42565821",
    "commentBody": "API Parrot – Automatically Reverse Engineer HTTP APIs (apiparrot.com)241 points by pvarghav 9 hours agohidepastfavorite66 comments When automating business processes at work, I found it difficult and time-consuming to reverse engineer business systems' APIs. I often had to manually reverse engineer APIs using developer tools or settle for less optimal technologies such as Robotic Process Automation (RPA). Often, the issue is that it can be hard to resolve all the cookies, access tokens, and other elements required to successfully execute the requests. Manually trying to resolve these dependencies using developer tools is especially challenging with multiple requests where data is stored in JavaScript objects or HTML elements. To try to solve this issue, I built a tool called API Parrot that automatically identifies the data correlations between requests and builds a graphical representation of the flow to give users a better understanding. To streamline the process, I also included functionality to record requests, define your own inputs and outputs, and export the entire flow—or parts of it—as JavaScript code. The application is Electron-based and currently compiled for Windows and Linux. Please try it out and give feedback! Online Tutorial: A simple example of reverse engineering the USPS API is available at https://docs.apiparrot.com/docs/category/tutorial---reverse-... brushfoot 6 hours agoImpressive project. I was curious how it discovers data relationships and was going to check the repo, but it looks like there's no code, only issues and releases. Is that right? Which leads me to... - Is this closed source? - Does it cost money? - How does it discover data relationships? reply pvarghav 5 hours agoparentThanks for your interest! - Is this closed source? Currently, the code is not open source, but I might open-source parts of it in the future. - Does it cost money? The software is free to use. If there is demand, I might create a \"pro\" version for businesses in the future. However, I intend to always have a free version available for individuals. - How does it discover data relationships? I've discussed how it discovers data relationships in the documentation here: https://docs.apiparrot.com/docs/tutorial-extras/exchange-mod.... In short, the tool breaks down the data in the requests and responses into smaller parts by identifying their formats. For example, `[\"foo\", \"bar\"]` would be recognized as a JSON array and broken down into the elements `\"foo\"` and `\"bar\"`. By applying this method recursively, you build a tree-like structure of the data. If an exact match is found between data in a response from a previous request and data in a subsequent request, a correlation is detected. Please feel free to ask if you have any more questions! reply bjt12345 21 minutes agorootparentIf this can save me time at work, I'd be happy to throw some money at it. My bosses OTOH...let's just say, there's no penalty within companies for pointy haired bosses not making decisions to purchase something like this and ignoring staff. It's a false economy but I'm tired of it and just purchase what I can afford. reply urronglol 5 hours agorootparentprevSounds like it has little utility in the real world. reply skeptrune 5 hours agoparentprevIt's entertaining that Github has become such a common place to find information that even closed source projects put something up there reply rynn 3 hours agoprevHow does it compare to mitmmitmproxy2swagger? https://github.com/alufers/mitmproxy2swagger reply faizshah 16 minutes agoparentThis might be more useful than the OP. This thing lets you translate HAR to Swagger… My usual process is Dev tools -> Copy as CURL -> delete unnecessary headers -> translates to requests in python (these days I just use ChatGPT) -> wrap in python sdk for managing auth etc. The OP’s correlation features are really nice though. reply 1a527dd5 2 hours agoparentprevThe first and immediate difference for me is the ability to recall the name. I can recall Postman/Insomina fine, and now for API Parrot. I'm never going to be able to recall mitmproxy2swagger. Unfortunately, names matter. reply itsafarqueue 1 hour agorootparentThanks 1a527dd5. reply 1a527dd5 1 hour agorootparentHa! Nicely played. That was out of purely laziness. I don't like using one handle across sites, so I take the first 8 chars of (New-Guid).ToString() and then dump it in my password manager. reply yoavm 1 hour agorootparentprevAs someone who uses mitmproxy and swagger quite often, I actually think the name isn't so bad. I haven't even looked at the readme but I already know what it does, how to run it and what output to expect. reply SparkyMcUnicorn 1 hour agorootparentprevI often forget the name of things, sometimes even the big ones. GitHub search is one of the primary ways I rediscover them. \"reverse-engineer API\" returns mitmproxy2swagger as the third result, and this is how I found it last time I needed it. It is a bit frustrating when a project on GitHub doesn't have good tags or searchable keywords, making it harder to find. reply setheron 6 hours agoprevVery sad half the comments are asking for MacOS app. The rise of development on MacOS for server development when the final target is Linux will cause long term harm to the newer generation of engineers reply victorbjorklund 5 hours agoparentWhy? I mostly code on Mac and deploy on Linux (or FreeBSD). Never really encountered a situation where programming a web app on Mac has caused issues when deploying to the server. reply UltraSane 2 hours agorootparentWhat about issues with CPU architecture? reply lionkor 2 hours agorootparentWhen you write web code you should never have to worry about that. Actually, if you write any user space code, except drivers, you shouldn't have to worry about that. If you have to worry about it, reconsider your tooling very seriously reply SparkyMcUnicorn 1 hour agorootparentprevAWS Graviton is ARM. My experience is that having a team with mixed platforms has helped reduce deployment woes, with the rare platform-specific bugs getting worked out beforehand. reply Sardtok 2 hours agorootparentprevYes, when you write web apps in x86 assembly, it gets tricky. reply rob 1 hour agorootparentI'm still on OS/2 Warp. reply criddell 4 hours agoparentprevOr maybe some of the newer generation will take time to update Linux to be more competitive with macOS for developers. Could be a long term win for Linux fans. reply Sardtok 1 hour agorootparentLinux is good for development, but Apple hardware is pretty damned nice. Now if Framework laptops were available in Norway, I'd probably rather have that, even if they're not as powerful. Also, depending on where you work, there might be restrictions in the choice of platform. Usually limited to Mac or Windows. reply Merad 18 minutes agoparentprevReally? In the modern .Net world (originally .Net Core) it's very common for devs to use Windows machines to write code whose CI pipelines and deployed environments are all Linux. I've seen a handful of issues with things like path separators and file system case sensitivity, but we're talking about 3 or 4 minor problems in 6-7 years that I've been using it. reply cdaringe 5 hours agoparentprevNot sad at all! Mac has excellent hardware, excellent reliability, excellent day to day performance. Im not a fanboy, but it won for (IMHO) clear and obvious reasons. Of course folks want a mac app. No comment on the “harm” bit. reply bearjaws 3 hours agorootparentIt is always amazing to me people who will chastise people for using Macs. It is by far the most robust hardware and 15 years later Windows laptops may finally be catching up. My first programming job was LAMP so I had a Linux desktop and loved it. Later I got a new job that gave us laptops, but they were quite beefy. I had a Dell laptop with an Nvidia GPU and an Intel iGPU... After updating my OS my gpu was the only way to use my laptop, which made the battery die in under an hour and of course it was much hotter. I tried numerous driver installs, proprietary, open source, reinstall OS, different OS... Nothing got it working again on a newer version of the Linux kernel. Went to the Apple Store bought a MBP and have never had an issue since. Not one dead laptop, in 10 years, I plug in my USB C dock and go. 2 years later, what happened to one of my coworkers? Same exact thing. He spent 3 days trying to fix it and basically had a workaround that crashed occasionally. I get paid to produce working software not configure my OS, and people wonder why Macs are so popular? reply rorroe53 3 hours agorootparentMacbooks have been nice since M1 era, but the Intel Macbooks between years 2013-2020 were hardly robust. My partner's 2014 MBP Retina's screen plastic film started peeling off, which was a known design flaw of those models. Later the ones with butterfly keyboard were notoriously unreliable, with keys getting stuck. Personally I haven't had much trouble with Linux on modern Thinkpads. Very little to configure manually, as long as you pick the right distro. Even a Dell laptop at work with Linux isn't causing me much OS-related issues, although battery life sucks. reply Klonoar 50 minutes agorootparentWell, no. The 2015 MBP is a well known workhorse that stretched many people professionally up to the M1. I would absolutely agree that the 2016-2020 Intel MacBooks were rough though. reply forty 3 hours agoparentprevI agree, people don't realize the value of not depending on a single company to do their work. We can see this problem even more with LLM code generators. reply yoavmmn 5 hours agoparentprevNowadays everything runs on docker anyway reply setheron 5 hours agorootparentYou'd never see a Windows developer work in MacOS or a iOS developer work in Linux but Linux developers (server side) routinely work in MacOS Unnecessary abstraction reply quesera 5 hours agorootparentCounter-argument: it could be risky to dev on and deploy to a single monoculture. But empirically, I've been developing on macOS (etc) and Linux (often simultaneously), and deploying to Linux (Debian, RHEL/AL), Solaris (etc), and FreeBSD ... for more than 20 years. Aside from package management tooling differences, package naming, and package content splits (e.g. pkg vs pkg-dev) -- all of which are equally inconsistent between Linux distros -- I cannot recall a single issue caused by this heterogeneity. reply prophesi 3 hours agorootparentprev> iOS developer work in Linux I dream of the day Apple releases official docker images. Building for iOS is the only reason I have to touch a Mac. reply chuckadams 1 hour agoparentprevHow about a real-world example of the harm you're clutching your pearls over? Besides, most devs doing web development on Macs are also using Docker, which is always Linux. reply dangoodmanUT 5 hours agoparentprevconjecture? reply rafram 5 hours agoparentprevMost people scraping sites aren’t writing anything low-level enough to care about the particular flavor of Unix-like OS it runs on. reply F7F7F7 4 hours agorootparentI’d argue that there’s no correlation at all between the two. reply yawndex 6 hours agoprevAny current plans for a macOS release? reply pvarghav 5 hours agoparentYes, I plan to release a macOS version of API Parrot. Unfortunately, I currently don't own a Mac, and since building macOS applications requires one, this has delayed the release. I'm actively exploring solutions, such as accessing a Mac environment remotely or acquiring the necessary hardware. reply tveyben 1 hour agoprevI’m not able to read what the product actually does - I keep getting distracted by the ‘snake’ animation surrounding the content .. not sure what the purpose is ;-) reply sumanyusharma 3 hours agoprevHow is this different from Integuru? They posted a few weeks back here: https://news.ycombinator.com/item?id=41983409 reply 1a527dd5 2 hours agoprevThis is pretty cool, I ran it against one of a largest customer sites and it was very interesting to see how the page all interconnects. I'm pretty sure it can be used to spot architecture/performance problems. reply davide_v 7 hours agoprevNice, I was looking for something like this. I tried it on Ubuntu but after clicking Capture requests > Launch Chrome, nothing happens. reply chompin 6 hours agoparentSame issue, would prefer the option to use any browser also. Chrome is not my cup of tea reply 7357 6 hours agoparentprevLooks like it wants to run chrome using `start chrome` which is AFAIK a Windows-only command. reply pvarghav 4 hours agoparentprevThank you for pointing this out. I've addressed the issue, and it should now be fixed in version 0.2.1, which is available for download on the website. Please update to the latest version, and let me know if you encounter any more problems. reply ashenke 7 hours agoparentprevYep same problem reply sidgarimella 2 hours agoprevLove this. I’ve worked on a few projects in RPA prior and I’m losing faith in selectors. I think either direct data access like this or AI based CV are the automation arms of the future. reply remoquete 2 hours agoprevLooks very interesting. Does it produce an OpenAPI file? That'd help immensely in documenting APIs that lack specifications. reply yellow_lead 6 hours agoprevHi, it seems youve spelled reverse wrong > API Parrot is the tool specifically designed to reverese engineer the HTTP APIs of any website. reply pvarghav 5 hours agoparentThanks for pointing this out! It should now be fixed. reply ozim 1 hour agoprevIf only there would be something with schema like XML that people would use for the APIs ;) You could generate diagrams from WSDL and even generate client code from that. There is also bunch of JSON schema stuff nowadays. But yeah for a lot of people schema of API contracts feels like too much work and too much hassle. JSON serialization doesn’t throw errors for new properties quickly added on sending side and receiving side can ignore stuff - well as long as API semantics allow but that’s generally going to be a hassle always even with LLMs somehow autofixing your „schema”. reply teichman 3 hours agoprevIntegru has been really great for us. Curious how you think about differentiation? reply gtirloni 6 hours agoprevIs there a ToS/License somewhere? reply devops000 6 hours agoprevFeedback: add a newsletter form to get notification when you will release the MacOSX version reply pvarghav 1 hour agoparentThank you for your suggestion! I've added a newsletter sign-up form at the bottom of the webpage: https://apiparrot.com/#newsletter Feel free to subscribe to receive notifications when we release the MacOSX version. reply toomuchtodo 6 hours agoparentprev+1, ready to buy reply colesantiago 5 hours agoprevThis is the easy part. One of the issues with these tools is that more and more websites now employ multiple aggressive CAPTCHAs, fingerprints, device check, etc, rendering tools like API Parrot almost useless. reply moon82 5 hours agoprevlooks amazing! thanks for sharing, will give it a shot in a short while. Btw, how do you keep yourself motivated on working on free projects? Obviosly it takes a lot of effort and no one is paying for that. reply pvarghav 34 minutes agoparentThank you! Working on this side project has been both fun and rewarding. I've learned a lot throughout the process, which keeps me motivated even without immediate financial gain. I have plenty of ideas on how to improve the software in various ways. Some of these enhancements could become part of a \"pro\" version tailored for businesses. My long-term ambition is to turn this into a full-fledged product, which would enable me to dedicate more time to its development. reply enricotal 6 hours agoprevFantastic Tool ... Mac version is paramount reply victor106 6 hours agoprevLooks great, but no Mac app? reply pkkkzip 4 hours agoprevinteresting but not sure what the value add here is, it gives you a graph flow of all the API requests being made? and then the goal is to replay them? aren't there github libraries that do this already? reply m00dy 5 hours agoprevcan it reverse websocket-protocols ? If so, how does it do binary decoding etc ? reply pvarghav 46 minutes agoparentCurrently only HTTP requests are supported. I might add support for websockets later, however that is a harder problem to solve due to the binary encoding etc. reply TripleChecker 7 hours agoprevnext [2 more] [flagged] woleium 7 hours agoparentI am getting bit sick of this triplechecker spam. reply vhayda 7 hours agoprev [–] Nice! It needs some refinement and a macOS version. reply tommiegannert 7 hours agoparent [–] Could you give some examples of what refinement you think it needs? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "API Parrot is a new tool designed to simplify the automation of business processes by automatically identifying data correlations between API requests and providing a graphical flow representation. - It allows users to record requests, define inputs and outputs, and export these flows as JavaScript code, making the process more efficient than manual reverse engineering or using less optimal technologies like Robotic Process Automation (RPA). - The tool is built on Electron and is available for both Windows and Linux platforms, with a tutorial available for reverse engineering the USPS API."
    ],
    "commentSummary": [
      "API Parrot is a tool that automates the reverse engineering of HTTP APIs, facilitating the automation of business processes by identifying data correlations between requests. - It offers features such as recording requests, defining inputs and outputs, and exporting flows as JavaScript code, with a graphical flow representation. - Currently available for Windows and Linux, API Parrot is free, with a potential \"pro\" version for businesses, and plans for a macOS release in the future."
    ],
    "points": 241,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1735737303
  },
  {
    "id": 42562529,
    "title": "FBI: Largest homemade explosives cache in agency history found in Virginia",
    "originLink": "https://thehill.com/national-security/5061535-virginia-man-arrested-explosives/",
    "originBody": "Access to this page has been denied window._pxVid = ''; window._pxUuid = 'fed0d742-c890-11ef-bd63-92510d25a2cd'; window._pxAppId = 'PX6zcfGH4h'; window._pxHostUrl = '/6zcfGH4h/xhr'; window._pxCustomLogo = '/wp-content/themes/the-hill/assets/the-hill-logo-horizontal.svg'; window._pxJsClientSrc = '/6zcfGH4h/init.js'; window._pxFirstPartyEnabled = 'true'; var script = document.createElement(\"script\"); script.src = '/6zcfGH4h/captcha/captcha.js?a=c&u=fed0d742-c890-11ef-bd63-92510d25a2cd&v=&m=0&b=aHR0cHM6Ly90aGVoaWxsLmNvbS9uYXRpb25hbC1zZWN1cml0eS81MDYxNTM1LXZpcmdpbmlhLW1hbi1hcnJlc3RlZC1leHBsb3NpdmVzLw==&h=R0VU'; document.head.appendChild(script); script.onerror = function () { script = document.createElement(\"script\"); script.src = 'https://captcha.px-cloud.net/PX6zcfGH4h/captcha.js?a=c&u=fed0d742-c890-11ef-bd63-92510d25a2cd&v=&m=0&b=aHR0cHM6Ly90aGVoaWxsLmNvbS9uYXRpb25hbC1zZWN1cml0eS81MDYxNTM1LXZpcmdpbmlhLW1hbi1hcnJlc3RlZC1leHBsb3NpdmVzLw==&h=R0VU'; script.onerror = window._pxDisplayErrorMessage; document.head.appendChild(script); }; window._pxDisplayErrorMessage = function () { var t = document.createElement(\"style\"); t.innerText = \"@import url(https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap);body{background-color:#fafbfc}@media (max-width:480px){body{background-color:#fff}}.px-captcha-error-container{position:fixed;height:328px;background-color:#fff;font-family:Roboto,sans-serif}.px-captcha-error-header{color:#f0f1f2;font-size:29px;margin:67px 0 33px;font-weight:500;line-height:.83;text-align:center}.px-captcha-error-message{color:#f0f1f2;font-size:18px;margin:0 0 29px;line-height:1.33;text-align:center}div.px-captcha-error-button{text-align:center;line-height:50px;width:253px;margin:auto;border-radius:25px;border:solid 1px #f0f1f2;font-size:20px;color:#f0f1f2}div.px-captcha-error-wrapper{margin:23px 0 0}div.px-captcha-error{margin:auto;text-align:center;width:500px;height:86px;font-size:12px;background-color:#fcf0f2;color:#ce0e2d}img.px-captcha-error{margin:6px 10px -2px 0}@media (min-width:620px){.px-captcha-error-container{width:528px;top:50%;left:50%;margin-top:-164px;margin-left:-264px;border-radius:3px;box-shadow:0 2px 9px -1px rgba(0,0,0,.13)}}@media (min-width:481px) and (max-width:620px){.px-captcha-error-container{width:85%;top:50%;left:50%;margin-top:-164px;margin-left:-42.5%;border-radius:3px;box-shadow:0 2px 9px -1px rgba(0,0,0,.13)}}@media (max-width:480px){.px-captcha-error-container{width:528px;top:50%;left:50%;margin-top:-164px;margin-left:-264px}}\"; document.head.appendChild(t); var r = document.createElement(\"div\"); r.className = \"px-captcha-error-container\"; r.innerHTML = 'Before we continue...Press & Hold to confirm you area human (and not a bot).Press & HoldPlease check your network connection or disable your ad-blocker.Please allow-list the domain captcha.px-cloud.net in your ad-blocker.For instructions on how to add to the allow-list or disable your ad-blocker please click here.'; document.body.appendChild(r); }; var cip = '13.91.68.93'; var ets = 'Wed, 01 Jan 2025 22:37:34 GMT'; setTimeout(function () { try { document.getElementsByClassName(\"px-captcha-error-wrapper\")[0].innerHTML = document.getElementsByClassName(\"px-captcha-error-wrapper\")[0].innerHTML + 'If you have any issues, please contact us at ' + 'challengehelp' + '@' + 'humansecurity.com' + ''; } catch(ex) { } }, 500); Your browser appears to have Javascript disabled.For instructions on how to enable Javascript please click here.If you have any issues, please contact us at &#99;&#104;&#97;&#108;&#108;&#101;&#110;&#103;&#101;&#104;&#101;&#108;&#112;&#64;&#104;&#117;&#109;&#97;&#110;&#115;&#101;&#99;&#117;&#114;&#105;&#116;&#121;&#46;&#99;&#111;&#109;",
    "commentLink": "https://news.ycombinator.com/item?id=42562529",
    "commentBody": "FBI: Largest homemade explosives cache in agency history found in Virginia (thehill.com)224 points by domofutu 23 hours agohidepastfavorite371 comments slavboj 7 hours agoThe only thing he is actually charged with is possession of a short barreled rifle. The prosecutor's documents do not even have photographs of the portion of the firearm that would establish whether it was configured as a \"rifle\" - it is perfectly legal under federal law to possess an AR style pistol with a naked buffer tube or a pistol brace, without a tax stamp. In the one photograph they do have of this firearm, they intentionally crop it so that it is not possible to evaluate. reply jvanderbot 2 hours agoparentThe suspect informed a confidential source that he had a 10\" barrel rifle. The source provided pictures of the rifle to authorities, and had seen it before several times, including going shooting with the suspect. The source provided several other points of data supporting him caching weapons and possessing a short rifle. https://storage.courtlistener.com/recap/gov.uscourts.vaed.56... You might be referring to this image? Which is fairly clear, but I'm not sure how they measure barrel length here, but to my eyes it is 13\" (unless the last 3 are a suppressor of some sort that isn't counted). https://storage.courtlistener.com/recap/gov.uscourts.vaed.56... This is from the probable cause affidavit, which I guess is used to obtain a warrant? reply twalla 1 hour agorootparentIn the eyes of the ATF, this is considered a pistol, which has no restrictions on barrel length. https://cdn11.bigcommerce.com/s-lpuqsi1cy6/images/stencil/12... Additionally, this is _also_ considered a pistol with a \"stabilizing brace\" (which are subject of much contention and confusion) https://www.sb-tactical.com/wp-content/uploads/sbpdw-install... The GP's complaint is that the linked photo contains insufficient context (for us, at least) to determine if the firearm in question is, from a legal standpoint, an SBR. reply Tuna-Fish 2 hours agorootparentprev> You might be referring to this image? Which is fairly clear, The issue is that it is entirely legal to have an AR-15 configured as a pistol with a very short barrel, without any tax stamps. That is, not having a stock attached to it. The image provided does not prove that he has a short-barreled rifle, because you cannot see whether it has a stock. reply jvanderbot 1 hour agorootparentOh thank you. That's a very clear distinction. reply generalizations 2 hours agorootparentprev> You might be referring to this image? Which is fairly clear The buffer tube extends off the rear, which has been cropped from the image. reply jvanderbot 9 minutes agorootparentI understand now, thank you reply ImPostingOnHN 2 hours agorootparentprevThe muzzle device looks to be a flash suppressor, possibly a Noveske KX3 or something similar. Muzzle devices don't count towards barrel length, except in some cases where they're permanently attached. That said, 13\" is also a short-barreled rifle length. If this is indeed a rifle, and not an AR pistol. reply declan_roberts 5 hours agoparentprevIt seems to me like they busted an eccentric collector. Men love this kind of stuff. If TNT was legal to own there would probably be a collector for it. reply llamaimperative 2 hours agorootparentWhat if he had ISIS flags hung around his home? reply potato3732842 2 hours agorootparentMake them communist flags, I don't care. Political signaling wouldn't change anything for me unless there was evidince he was going to engage in violence. reply llamaimperative 48 minutes agorootparentI know this is easy for people to say in theory, but as mentioned elsewhere, if this materialized into an attack people would’ve retrospectively seen that as “certain” evidence of intent. reply NicholasGurr 21 minutes agorootparentHahaha, you’ve got to be kidding me. No, it’s easy to say in theory and in practice. I’ve read articles where they mention a killer had hundreds of bullets at his home, and I still think, so what? That’s not evidence of anything. I remember they arrested a man at an elementary school near my home, and in reporting the story, the note that he had a knife, rope, duct tape, and other such items in his trunk. Even that seems absurd to me. I have many of the same items in my trunk. But when we start talking about it in the context of some potential threat of violence, people throw all logic out the window. No, again, in theory and in practice, I still wouldn’t view it as evidence of intent. reply llamaimperative 16 minutes agorootparentI think you forgot to read the thread reply NicholasGurr 8 minutes agorootparentNope. Up your reading comprehension, including what you wrote and who you replied to. petre 1 hour agorootparentprevThat kind of evidence usually turns up when the suspect ends up shooting people. When it's already too late. reply rickandmortyy 1 hour agorootparentalexa play minority report lol reply franktankbank 5 hours agorootparentprevIf TNT was legal to own I'd be buying it for my farm. reply lazide 5 hours agorootparentit is legal to own with the right permits, in most areas. The more dense the population, the more heavily restricted in general. reply franktankbank 1 hour agorootparentThere's legal and then there's needing 5 certifications, yearly renewals etc etc in order to avoid destroying your tractor for handling common nuisance on the farm. reply fasa99 28 minutes agorootparentA lot of regulations are a mess. As I understand it, agriculture drones full of fertilizer are beginning to be used throughout, makes sense. And tractors run on diesel since forever. So add diesel to the fertilizer drone now you have a viable powerful weapon... unregulated. I'm sure tens of thousands of farmers have this in their pocket right now, just not their intent. Same with firearms. A pea shooter .22, highly regulated, felony charges everywhere. Now, a 50 caliber airgun? No gunpowder, not a firearm. They even make automatic airguns. Arguably with a large air supply and large ammo clip, and airgun could trounce some automatics, primarily because their barrels won't overheat, they might overcool though because physics of expanding gasses. And yet the humble .22 is the highly regulated one. Some governments and regulators attempt to enumerate every possible conceivable bad thing and outlaw it. Problem is it's not enumerable, there will always be dozens of missed loopholes, which the regulations will steer people into. Parallels the warping and skewing of trying to fix an economy through proclamation versus distributed capitalism. reply lazide 1 hour agorootparentprevi agree, which is why it’s harder to run across now. Notably, it’s about the same amount of paperwork or less than owning guns in most European countries. reply jt2190 5 hours agoparentprevAs a legal filing, perhaps it’s important to show a picture of the weapon in a neutral way, in order to avoid an argument over the filing itself. (I’m not a lawyer just speculating.) reply wl 1 hour agorootparentThey could have photographed the entire firearm from buffer tube to muzzle device in a neutral way. reply strathmeyer 7 hours agoparentprevOK but what about all the dangerous explosives and the intent to murder innocent people? reply ncr100 4 hours agorootparent\"Soon\": Get the process going, ankle monitor strapped and movement of suspect restricted, continue the law enforcement investigation, and make additional charges if violations are identified. reply giantg2 6 hours agorootparentprevThat's the question - why isn't he charged with those more blatant infractions. Maybe he will be, but just hasn't yet. reply ceejayoz 6 hours agorootparentThat's not uncommon; Luigi Mangione was first charged with having the unpermitted handgun and fake IDs. They want enough to hold and investigate further initially; they'll have taken all the bombs. reply rustcleaner 3 hours agoparentprevI have a dream... that one day we will have a DEA which only regulates purity and accuracy of dose for drugs, and an ATF which only regulates quality and accuracy for firearms. These laws do little to protect the public and they mire enthusiasts with steep and discouraging legal (and thus personal physical) risks. This sort of thinking about the role of government has to stop; it is human civilization's chief sickness. reply anon7000 3 hours agorootparent“Chief sickness” is pretty strong when there are dozens of other human problems that are considerably worse. reply bigfudge 1 hour agorootparentprevBut drugs and firearms have very different risk profiles for other people. Perhaps it bears repeating: US lax gun laws and culture which glorifies violence leads to an order of magnitude more violent deaths than comparable countries in Europe. reply cyanydeez 2 hours agorootparentprevI have a well regulated militia dream. give up guys. reply sneak 2 hours agorootparentThe 2A is interpreted both popularly and legally as an individual right: it is the right of the people, not the right of the militia. And, as I’m sure you know, the term “regulated” as written in 2A does not mean the same thing as “regulated” in terms of “government regulation”. In context, it means approximately “well-functioning” or “reliable”. reply dr_dshiv 2 hours agorootparent“A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed” An individual right to participate in a well regulated militia. reply jandrewrogers 2 hours agorootparentThe militia is every able-bodied person, both as a matter of history and as literally defined in US law for centuries. Furthermore, this militia is expressly recognized as \"unorganized\" in law i.e. separate from organized militias created by the government. In the US, the militia is explicitly independent of the government. Even if one were to accept your narrow reading, which no court has, I don't see how it would materially change anything given that any random group of blokes without any government involvement is a militia as a matter of law. reply Pyxl101 2 hours agorootparentprevIn historical context, the “militia” was everyone, every able bodied person who could participate in common defense. It wasn’t a specific organization like we’d think of today Beyond that, the right is entirely unconnected with service in a militia. That clause at the beginning “A well-regulated Militia …” does not scope or bound what comes next; it offers one explanation for why that right is protected. SCOTUS explained the historical meaning of these words in more detail in District of Columbia vs. Heller, including an in-depth examination of the language as part of its opinion that the right is an individual right. https://en.m.wikipedia.org/wiki/District_of_Columbia_v._Hell... The SCOTUS decision itself is quite readable. https://tile.loc.gov/storage-services/service/ll/usrep/usrep... Notably: > Held: > 1. The Second Amendment protects an individual right to possess a firearm unconnected with service in a militia, and to use that arm for traditionally lawful purposes, such as self-defense within the home. > (a) The Amendment’s prefatory clause announces a purpose, but does not limit or expand the scope of the second part, the operative clause. The operative clause’s text and history demonstrate that it connotes an individual right to keep and bear arms. reply dmoy 2 hours agorootparent> In historical context In current federal legal context, the \"militia\" is all men between like age 18-45, plus all people in the national guard, or something like that. That's what the US CFR says. reply Aloisius 42 minutes agorootparentprevAre we really to believe that slave states ratified the 2nd amendment with the belief that they were giving every individual the right to keep and bear arms? Because that seems absurd given their rather large population of slaves. reply bongodongobob 2 hours agorootparentprevI have a dream that all the wannabe militia men that have boners for guns just sign the fuck up for the army. Getting tired of daily school shootings. And 2A isn't going to protect you from the US military if that's your fetish. You and all the rednecks that want to play cops and robbers will be absolutely bodied. reply potato3732842 2 hours agorootparentThat's a non-starter. These militia types don't see the state headed in a good direction so of course they're not gonna sign up to be part of one of the violence arms of the state (military, LEO, etc). If they did believe in the state they'd already have signed up. reply jl6 12 hours agoprevIf this guy went on a terror rampage and it later emerged that he had spent years stockpiling bombs and obsessing over weapons, there would be a chorus of “why didn’t someone intervene earlier?” and “of course the guy was dangerous”. Hindsight makes it easy, but before the fact it’s difficult to judge where to place the line between non-criminal eccentricity and imminent threat. reply declan_roberts 5 hours agoparentThe problem is that his arsenal is hardly any more dangerous than driving a 6,500 lb truck into a crowd during a celebration. The people who want to harm our country don't seem to have any difficulty doing it. reply Retric 4 hours agorootparentIt seems likely you could do far more harm with 150 finished explosive devices than driving a truck through a crowd. There’s many examples of people driving into dense crowds and the death totals are rarely in the double digits. Ex: 5 dead 235 injured https://en.wikipedia.org/wiki/2024_Magdeburg_car_attack Though obviously the amount of explosives per device is going to modify the risk profile. reply belorn 3 hours agorootparentA truck full of ammonium nitrate, which trucks occasionally carry, could do a lot more damage than 150 handmade explosives. There is occasionally discussions if we should ban trucks that carries dangerous materials from driving near large cities. The main counter argument is that the number of people who has access to trucks with dangerous goods in them is so few compared to the number of people with access to a car. Thus the more logical solution to mitigate risks is to address car access to areas with crowds. reply Retric 2 hours agorootparentAgain, scale isn’t mentioned. 150 devices could be several tons of high explosives which are more dangerous than a truck of ammonium nitrate which only becomes an explosive when mixed with other chemicals. reply jandrewrogers 2 hours agorootparent> ammonium nitrate which only becomes an explosive when mixed with other chemicals This is incorrect, ammonium nitrate is intrinsically high-explosive. It is mixed with other ingredients to improve performance and/or sensitize it but this is not required. There are several famous examples of stored ammonium nitrate exploding e.g. https://en.wikipedia.org/wiki/2020_Beirut_explosion reply Retric 28 minutes agorootparentYou’re of course technically correct, but in practice a truck of ammonium nitrate is basically inert on its own. If you’re going to assume they have access to significant explosives to actually detonate pure ammonium nitrate, then you also need to consider flour and other ‘safe’ compounds due to the potential for even larger fuel air explosions. reply lazide 1 hour agorootparentprevThe confusion likely stems from Ammonium Nitrate (uncontaminated) generally only being explosive when hit with a very high speed shockwave (aka a booster charge + detonator in typical mining/blasting applications), or when sensitized with other chemicals (like with tannerite). Most of those other blasts, including Beirut, involved lots of contamination of the AN + large fires + very large quantities of ammonium nitrate. In truckload or less quantities, and when not contaminated with specific substances, ammonium nitrate is pretty much impossible to detonate without a sizable quantity of some other high explosive. reply AnarchismIsCool 3 hours agorootparentprevThey're pipe bombs so quite low yield. They're typically based on smokeless powder so they're \"low explosives\" meaning they don't really detonate, they deflagrate at below the speed of sound. reply Retric 2 hours agorootparentPipe bombs cover a wide range and can be extremely deadly or basically a dud. There’s no mention of the guy using smokeless powder just hexamethylene triperoxide diamine which is an actual high explosive. reply ImPostingOnHN 2 hours agorootparentSome of the bombs shown were labeled ETN [0], likely erythritol tetranitrate [1] 0: https://ktla.com/wp-content/uploads/sites/4/2024/12/FBI-pipe... 1: https://en.wikipedia.org/wiki/Erythritol_tetranitrate reply lm28469 2 hours agorootparentprevSome are very effective: https://en.m.wikipedia.org/wiki/2016_Nice_truck_attack 86 deaths, 434 injured reply Retric 51 minutes agorootparentThat’s leaving the territory of what most people have ready access to. The poser referred to a “6,500lb truck” vs “19-tonne Renault Midlum cargo truck” used in that attack. reply ben_w 5 hours agorootparentprev> The people who want to harm our country don't seem to have any difficulty doing it. We see the examples of successful attempts at harm, most of us don't pay much attention to the failed attempts, which makes it difficult to draw conclusions about how hard it go from \"attempted harm\" to \"actual harm\". reply gilleain 5 hours agorootparentprevReally? >Investigators also found hexamethylene triperoxide diamine, which the agency described as “an explosive material that is so unstable it can be exploded merely as a result of friction or temperature changes.” I mean, I don't even have to look that chemical up to see that it is explosive. Actually looking at it, it's a cage of nitrogens and peroxides. Cricky. https://en.m.wikipedia.org/wiki/Hexamethylene_triperoxide_di... >Cases of detonation caused by the simple act of screwing a lid on a jar containing HMTD have been reported reply oliwarner 6 hours agoparentprev> there would be a chorus The problem of listening and reacting to public outbursts is that there are enough people on all sides of this that there'll be an outburst whatever happens. The Algorithm makes us a pile of hyper-reactionary babies. reply llamaimperative 6 hours agorootparentEh, this is true but not really relevant to the claim here. If the FBI had all this information and didn't act on it, then he e.g. went into a tower and murdered dozens of people in the street, there is not going to be a substantial number of people saying \"oh well ya know they didn't have a basis to intervene when they were first informed of his 1) probably-illegal firearms, 2) extreme violent views and 3) growing stockpile of explosives.\" reply oliwarner 4 hours agorootparentThe comment seemed to be about when it was right to ignore Constitutional Rights, giving two examples of people noisily pushing for that. There will always be people noisily complaining because that's what we amplify these days. I personally don't think there's enough public consultation on rights. For some reason America relies on an increasingly political supreme court to set those boundaries rather than what The People actually want. And all of this is entirely impossible to derive from online conduct because it's just wall-to-wall strife, disagreement and suffering. A system continuously telling us to be angry with other people, rather than how to enjoy these short, little lives we have. Weird if you ask me. reply llamaimperative 47 minutes agorootparentThe comment did not say that. The comment said that people would have perceived it as certain evidence of an impending attack and a clear security failure. All of that is absolutely, obviously true. reply harrall 2 hours agorootparentprevI’m sure the real explanation is that there are probably a lot of people with weapon caches or doing other really questionable stuff but very few of them have intent to harm and the small remaining number of people who have that intent are never actually going to do anything and may not yet violate any laws. As it always is, people are always on some spectrum for an activity. reply ethbr1 5 hours agorootparentprevLots of Americans don't understand legal due process. Especially the ones who watch hyper-partisan news. reply jmathai 7 hours agoparentprevFrom the article, there seemed to be evidence of mental instability and propensity towards violence. I don’t know the line but it seems this would obviously warrant investigation regardless of if this person broke a law. I say that as someone who believes in limited government. reply bloomingeek 6 hours agorootparentYour point, to me, is well taken. I can't imagine being a neighbor of this man when he suddenly snapped and went on a rampage. Some might argue who knows if he would have ever snapped, that's all well and good if you're not living near him. Is it fair of my neighbor to instill fear in his fellow neighbors? What if his stash was kept secret for decades, are all those bombs good for the neighborhood? What if he dies and then his stash is discovered in some kind of explosive event? reply oceanplexian 4 hours agorootparentThere are probably lots of people doing exactly that, who are running meth labs or dealing drugs like Fentanyl with minimal scrutiny from federal law enforcement. However, instead of going after those criminals, the FBI has placed its focus on sending a SWAT team to arrest someone who downloaded the wrong 3D print file or ordered a spicy plastic gun accessory on the Internet. That’s a disingenuous application of the law by people who have an agenda, not an approach that’s actually intended to reduce harm. reply bloomingeek 4 minutes agorootparentYour reply to my reply has nothing to do with what I said! I suspect yours has a veiled political/2nd amendment agenda. Again, and please read this slowly, to be a decent, caring, good neighbor is not to have them worried about what you're building in your garage. Your reply cares nothing if one of his kids or neighborhood playmates happens upon one of his bombs that could lead to a potential explosion. reply thinkcontext 52 minutes agorootparentprev> There are probably lots of people doing exactly that, who are running meth labs or dealing drugs like Fentanyl with minimal scrutiny from federal law enforcement. Why do you think the fbi is giving a pass to drugs? There's ample evidence that they devote a lot of resources to it. reply trehalose 3 hours agorootparentprevThe article implies that the FBI was aware of his large collection of extremely dangerous explosives at the time they arrested him. It doesn't mention a SWAT team, but I'll take your word for that, but do note that there had to be a bomb disposal team because some of the bombs were too sensitive to remove and had to be exploded on-site. reply epolanski 6 hours agoparentprevMeanwhile half the internet and some comments here are \"what is he being charged for? He did nothing\". reply giantg2 6 hours agorootparentThat's to be expected in this community. There are more libertarian views on here due to the DIY and inquisitive nature of the hacker community. In a large way, the intended use or application of dangerous things are considered a more important point on here because many of us know the damage a person can cause with common things that have legitimate purposes (certain computer software). I'm generally on the side of intended use mattering more than mere possession of things. However, it seems there may be evidence in this case of violent intentions and destructive devices intended to kill. The comments about the SBR are mostly based on the mental contortions one must do to say an SBR is somehow more dangerous than a braced pistol (even if one is clearly illegal and the other is legal, the question is why). reply ethbr1 5 hours agorootparentThe issue, from a public safety and law enforcement perspective, is that intent is mostly a post-hoc construction. Whereas possession can be judged before an act occurs. If the US intends to stick to the freedom-first philosophy with regards to possession, then it would behoove everyone to have a more nuanced legal view of intent. E.g. graduated escalating consequences for 'Making threats and remarks of a violent nature' to 'Taking actions that indicate preparation for violent action' etc. Like you, I think if people want to mess around with homemade explosives, and they have enough land to do so, then that's their business. BUT! There should also be a pattern of behavior, evidence, and witnessed statements where we say 'This particular individual has ceded the right to access dangerous things.' So essentially being able to charge and convict someone (with due process) of 'violent intent', with no financial or incarceration penalties, but temporary addition (5 year?) to lists that preclude their being able to access dangerous material (guns, explosives, etc). Of course, the NRA has historically been the biggest lobbyist blocker to anything of that nature, given their paranoia that any legal government consequences will spiral into a panopticon. Unfortunately, that view doesn't solve the fact that there are very troubled individuals out there, and we'd all be able to be afforded greater freedom if we did a better job in managing those particular people's access to lethal things. reply giantg2 5 hours agorootparent\"So essentially being able to charge and convict someone (with due process) of 'violent intent', with no financial or incarceration penalties, but temporary addition to a lists that preclude their being able to access dangerous material (guns, explosives, etc).\" I'm not sure what you're getting at on this one. This individual faces potential incarceration. He is on bail and would be denied access to dangerous things... in theory. Of course he manufactured explosives, so it's not like he has to pass a background check to come into possession of them again. \"and we'd all be able to be afforded greater freedom if we did a better job in managing those particular people's access to lethal things.\" Do you have some examples of additional freedoms we're missing currently? \"Of course, the NRA has historically been the biggest lobbyist blocker to anything of that nature, given their paranoia that any legal government consequences will spiral into a panopticon.\" I'm not exactly sure what you're referring to that they oppose. But the legal term for a slippery slope is the Overton Window. Speaking of gun regulations generally, it's not hard to understand why a pro-gun group would be against the types of additional regulations that are already present in other states that arguable do not improve safety or could even reduce it in legitimate use circumstances (eg hollowpoint bans, etc). reply bigfudge 59 minutes agorootparent>Do you have some examples of additional freedoms we're missing currently? Freedom from gun violence for thousands of US children annually? reply ethbr1 4 hours agorootparentprev> This individual faces potential incarceration. He is on bail and would be denied access to dangerous things... in theory. The current US justice system is based around conviction of a crime (which usually requires having already committed it, or a VERY high bar for having intended to do so) in order to impose consequences (usually severe). Or limitations on individuals' rights after conviction of the above. There's no lesser standard of 'at higher risk to commit a crime', aside from a patchwork of short-duration city/state red-flag type laws, most of which are being challenged in court. > Do you have some examples of additional freedoms we're missing currently? Access to NFA-controlled devices? [0] E.g. a breach-loading potato gun > I'm not exactly sure what you're referring to that they oppose. But the legal term for a slippery slope is the Overton Window. The Overton Window isn't a legal term: it's a PR/clickbait term. The NRA has and currently opposes red-flag laws [1], even when constructed with due process procedures, because of its mistrust of any government firearm regulation. If they instead switched their lobbying approach to productively crafting due process procedures that would allow targeting individuals with a history of threats, abuse, and violence, the rest of us could benefit from greater freedom to dangerous devices. Instead, their tunnel vision on absolute freedom requires repeatedly casting a blind eye to inconvenient situations where disturbed individuals leverage that freedom to kill others. Solving problems requires clear-eyed appraisals of the risks and benefits of various approaches to arrive at optimal outcomes. The NRA has fueled the exact opposite, by leveraging histrionics and fear mongering, not least for its own financial gain. Fuck em. [0] https://en.m.wikipedia.org/wiki/Title_II_weapons [1] https://www.nraila.org/search/?t=79503 reply giantg2 3 hours agorootparentOh, you're talking about red flag laws. What makes you think passing red flag laws will provide additional freedoms? It seems highly unlikely that those who support the current red flag laws would support any loosening of other firearm restrictions. Your statement also implicitly assumes that red flag laws would be significantly effective to allow looser restrictions overall. However, groups like RAND have found no conclusive evidence that red flags work. The best evidence they have is potentially reducing suicides. What would the protections you mention look like? The whole point of moving things like red flag laws or civil asset forfeiture to the civil side is because it lacks the protections on the criminal side - lower burden of proof, no right to representation, ex parte proceedings, etc. It's no wonder we see constant abuses of the process in traditional PFAs during divorces in many states. Surely we could fix the existing processes to ameliorate the problems and concerns thus providing a solid basis for the argument to expand them. Currently, the ACLU opposes most of the red flag laws due to civil liberties issues. I would bet that the NRA will propose ammendments to any national red flag legislation introduced, just as they helped shape the 1968 legislation once it looked inevitable. That's all a part of the political game. Sure, the Overton Window is associated with some clickbait, but it's a real and valid concept in politics. This is why groups aren't going to volunteer to help implement things that are counter to their goals, be it the NRA or Everytown. Do you really think Everytown would support something like national reciprocity in exchange for red flag laws? No, as they are also a hardliner and playing the game. \"Solving problems requires clear-eyed appraisals of the risks and benefits of various approaches to arrive at optimal outcomes.\" So what's the solution? What's the optimal outcome? reply ethbr1 3 hours agorootparentNo, I'm talking about the need to have a discussion around moving access restrictions to before a crime is committed, while still ensuring individuals have access to due process. The NRA's blanket opposition to red flag laws is simply one example their willingness to ideologically fight even the simplest approach to a priori restrictions. > So what's the solution? What's the optimal outcome? In my ideal world, the US would lean more heavily into universally-accessible but universally-required certification for access to dangerous devices. Similar to motor vehicles, the default should be that no one has access to these things, but everyone has a right to obtain certification to have them. As an example, that would look something like national \"must issue\" concealed weapons permits, but contingent on completing a non-trivial safety course and passing a background check (to ensure the individual isn't spending their free time talking about murdering people online / to their neighbors, appealable ofc). Instead, we've spent ~60 years wringing our hands to try and square the circle between {everyone deserves access to dangerous things} and {some people are too irresponsible to have dangerous things}. Why not just start with those facts and craft a viable system from there? reply giantg2 2 hours agorootparentYeah, that's going to be a tough sell considering the problems with the driving test being a joke and the history of requirements in some areas just being a pretext to deny rights to specific groups or individuals (still to this day). The main problem I see is that a safety course isn't going to prevent violent crime. It could prevent use of force issues or accidents, but those tend to occur at an extremely low rate already (for civilians). The background check part is already implemented depending on jurisdiction. The way the current system is set up, it's supposed to weed people out before they get access to the more dangerous stuff. As juveniles, if they get convicted of certain offenses, they will be prohibited, at least until 35. We have eroded various aspects of this with selective enforcement, plea deals, and the promoting the continuation of childhood with delays in freedoms and responsibilities. Then for the of-age group we have stuff like conspiracy, voluntary/involuntary commitment, terroristic threats, and all manner of prohibiting offenses. There's certainly some room for improvement, but it hard to say what an effective improvement would be. reply oceanplexian 4 hours agorootparentprev> Taking actions that indicate preparation for violent action The contradiction is that that’s literally the content and purpose of the 2A of the US Constitution. It’s not the right to bear arms for hunting deer, or the right to go target shooting. The language is pretty explicit, if it isn’t clear enough the founders took the time to explain the purpose of it in the Federalist Papers after they fought an armed revolution against their own government. My take on unstable people is that if you’re not stable enough to own guns you’re not stable enough to participate in society. If the person in this case made credible threats, they should charge him with a crime other than possession of a firearm accessory. There are plenty of other ways that deranged people hurt others (Like driving a vehicle into a christmas market). The only way we can claim to live in a free society is by maintaining a system of due process. reply ethbr1 3 hours agorootparent> The language is pretty explicit The literal text is ambiguous to a degree that commas change its meaning: >> A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed. Relying on contemporaneous ancillary (and unratified with consensus) documents should be an obvious sign that textual clarity is lacking. Furthermore, the ability of an 18th century individual to craft weapons of mass destruction was vastly inferior to our modern access. > My take on unstable people is that if you’re not stable enough to own guns you’re not stable enough to participate in society. If the person in this case made credible threats, they should charge him with a crime other than possession of a firearm accessory. Not only stability! Just normal common sense. ~20% of English-proficient Americans can't do basic numerical tasks in English [0]. I wouldn't trust anyone that dumb around a loaded 6-lb trigger pull. As the aphorism goes, some people ain't got the sense God saw fit to give a squirrel. And while they and unstable people are fully entitled to live their lives however they want, it would behoove society at large to say 'Maybe we're not going to hand you things that require the highest amount of safety and carefulness.' But I'm from the generation where you started out firearms ownership with a hunter safety course at the local firehouse, followed by supervised use with your family, eventually progressing to independent use by high school. [0] https://nces.ed.gov/pubs2020/2020025.pdf reply oceanplexian 2 hours agorootparent> ~20% of English-proficient Americans can't do basic numerical tasks in English [0] We don’t gatekeep rights based on someone’s perceived intelligence. The same logic was used to keep southern blacks from voting in the civil rights era and was promptly struck down. If you’re an American, it’s your inalienable right. > The literal text is ambiguous to a degree that commas change its meaning The people who wrote the amendment literally wrote essays explaining their thought process. It’s not like we’re deciphering ancient greek artifacts, we all know exactly what the founders meant when they wrote it. The Supreme Court has repeatedly affirmed this extremely obvious interpretation. reply stouset 4 hours agorootparentprevDoes the second amendment authorize me to bear nuclear weapons? If no, you acknowledge there is a line. We’re allowed to bear arms, but not any and all arms. If yes, maybe your views are consistent but you’re utterly insane. reply potato3732842 1 hour agorootparentprev>My take on unstable people is that if you’re not stable enough to own guns you’re not stable enough to participate in society. I Exactly. Prison or full rights, guns, voting, living beside a school, all of it. Get rid of all this inbetween crap. Oh, the prisons are too crowded you say? Well perhaps criminalize less things. reply rat87 1 hour agorootparentprevThe second amendment was to make sure the government could organize militias to put down armed rebellions, not to empower them. You may consider it hypocritical, but the vast majority of the founders ( Jefferson was an exception) were very very anti armed rebellion! That's the context for the Constitution replacing the articles of confederation. Having recently fought one they didn't think we needed any more revolutions and didn't want any more revolutions! And didn't appreciate several violent incidents like Shays rebellion. https://www.reddit.com/r/AskHistorians/comments/75z37x/what_... > Shays’ Rebellion was an armed uprising led by former Massachusetts militiamen and veterans of the American Revolution which took place between 1786 - 1787. Daniel Shays led several thousand ‘rebels\" to fight against the economic injustices that were facing farmers and agrarian peasants all across America. (3) These farmers were experiencing extreme poverty following the end of the Revolutionary War. All across America, farmers saw their lands foreclosed on in unfair property seizures, and they wanted to fight back. They were also trying to fight taxes which were beginning to be levied against them.(4) People in rural American fought these perceived injustices in a few ways, with Shays' Rebellion being the most violent. Shays' Rebellion would ultimately be put down, but it startled the gentry who feared further uprisings throughout the United States. > While we call it a “rebellion\" today, these men did not label themselves this way. They called themselves “regulators,” specifically they called themselves the “Massachusetts Regulation,” modeling off of the North Carolina Regulators that we saw just a moment ago.(5) This was the larger part of a trend of poor Americans fighting back against economic injustice. The idea of “civilian regulation” was catching on and becoming a popular idea for ending government corruption. They believed that if the government wasn't regulating itself on behalf of \"We the People\", then \"the People\" had the right to regulate, or take back the government – to take it back and do what they believed was right. They didn't see themselves as a rebellion, but rather the gentry labeled them as such in order to de-legitimize their cause. By calling them \"rebels,\" neutral Americans would see these men as insurgents who needed to be stopped. But this regulation was not the only type of fighting Americans across the country participated in. Many states saw widespread revolts ... > By the time the the constitutional convention convened, America was under extreme duress. In Terry Bouton's article \"A Road Closed: Rural Insurgency in Post-Independence Pennsylvania\" he masterfully explained the fighting and rebellion that took place in the rural country sides of Pennsylvania that mirrored what had happened in Massachusetts.(7) The gentry were terrified that they were losing control of rural America, and as a result they would not be able to seize foreclosed land and collect taxes, which they needed. Empowering militias to be trained and carry firearms allowed the gentry to call up these men in times of need and suppress these rebellions that were taking place. The Founders knew that the only solutions were to call up militias as they had done in North Carolina and Massachusetts. ... > Multiple other bills of rights from other states had already protected a militia's right to bear arms (such as Section 13 of Virginia's Declaration of Rights) and many of these states were fighting to have the federal government protect this as well. Here their declaration stated: > > SEC. 13. That a well-regulated militia, or composed of the body of the people, trained to arms, is the proper, natural, and safe defense of a free state; that standing armies, in time of peace, should be avoided as dangerous to liberty; and that in all cases the military should be under strict subordination to, and governed by, the civil power.(8) > This wording is even more carefully crafted then in the national Bill of Rights. Here, they define “well-regulated” meaning they were trained my military officers. You also see that they define the purpose of it as being necessary to “defend” the state (implying against people in rebellion) and they of course explain why they feared a standing Army. Now if you examine the wording of the Second Amendment, we can see some clear similarities: > > A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed. > Like in Virginia, “well regulated\" is the key phrase. They are referring to militias led by people like Benjamin Lincoln and his Massachusetts Militia, not Shays and his \"rebellion\". The idea that people need firearms to protect themselves from the government is not accurate. It was a message propagated by anti-gun control advocates of the 1980s. This “right” was crafted when rebellions were happening everywhere and the only way the government could maintain control was to make sure they could call up their militias. reply ClumsyPilot 1 hour agorootparentprev> think if people want to mess around with homemade explosives, and they have enough land to do so, then that's their business. Do you also believe you should not need a driving license, or an electrician should not have any certification? Because an average person can watch a YouTube video and wire a circuit, or learn to drive by themselves, but their chances of making explosives without posing a danger for themselves or others are far, far lower. This should be a licensed activity where you need to demonstrate at least basic competence and mental stability. reply roughly 2 hours agorootparentprev> There are more libertarian views on here due to the DIY and inquisitive nature of the hacker community. Bluntly, it’s also the hacker community, or at least this hacker community, being kind of poor at generalizing things to an overall population and confusing their own emotions about something for a reasoned defense of it. We’re arrogant, overconfident in our ability to reason about things, undervalue others’ reasoning, experience, and history, regularly mistake our ability to reason through a technical issue for expertise in things outside our wheelhouse, and are profoundly gifted at self-motivated reasoning, so the idea that anyone else might have a valid opinion on why we shouldn’t do something we really want to do strikes us as tyranny. reply BobaFloutist 37 minutes agorootparentAlso bombs and guns are \"cool\" and bureaucrats aren't, and most programmers are more likely to have been \"harmed\" (had their taxes collected) by a bureacrat than a bomb or a gun, so they automatically side with the guns and bombs. reply onlyrealcuzzo 4 hours agoparentprevDoes anyone have a problem if I start stockpiling smallpox and nuclear bombs? Where do we draw the line of ridiculousness? reply Stevvo 3 hours agoparentprev\"it’s difficult to judge where to place the line between non-criminal eccentricity and imminent threat.\" Fortunately, this guy commited over 150 crimes. Bail was denied. We can lock him up and throw away the key. It really doesn't matter if he were to be an imminent threat or not. reply pjc50 5 hours agoparentprevAmerica sits on a weird knife edge where there's (a) lots of talk about political violence, which is constitutionally protected and (b) lots of stockpiling of weapons, which is constitutionally protected, and (c) lots of routine mass murder incidents, which follow logically from (a) and (b) .. BUT .. apart from Jan 6 and a few milita incidents, nobody ever combines these three into politically targeted violence. The mass murders are always either strangers, workplace, or schoolchildren. Politically motivated, but not targeted at any kind of power structure. It's been a long time since the Unabomber. All the elements are in place for a really serious deterioration of civil safety, but so far the glue is holding. reply oceanplexian 4 hours agorootparent> (c) lots of routine mass murder incidents, Your other points are valid but this one has been so highly politicized that inner city gang violence is classified as mass shooting, which is a completely different social issue that’s being co-opted in with the political violence issue and the mental health crisis. All of those problems are complex and have different root causes, implications and magnitudes, but activists like Everytown want to lump them together to portray a “Gun Problem” to pitch their forced solution, which is making it harder for law-abiding citizens to own guns. reply rat87 1 hour agorootparentI mean it is a Gun problem. Or rather many Gun problems. If guns were better regulated and we had less of them we would have a safer less violent society. Those other issues would still exist but would lead to less violence. Instead we have activists who claim that any gun laws are unconstitutional going even further then our very activist supreme court. reply ganoushoreilly 4 hours agorootparentprevn your (a), (b), and (c) list, you imply that (c) — routine mass murders — connects directly to (a) (talk of political violence) and (b) (stockpiling weapons). However, the examples you give, like Jan. 6 or militia incidents, don’t align with your routine mass murders implication. You could imply unrest for sure and I wholly agree that subsets could even be targeted violence, but that's not unique to either of your examples. The elements will always be in place for disturbed individuals, just look at the number of \"Cars running over crowds\" stories, such as yesterday in New Orleans. The question and premise for a lot of the battles are, do we take away rights or abilities of those that won't do it, on the off chance that someone could? Clear laws, enforced consistently would help a lot here. I would also posit, though not likely a popular opinion, there are people that cannot be a part of a functioning society and we have to collectively agree on that. We need to bring back functioning mental health facilities for long term care and accept that some people will be placed here and not leave. reply pjc50 4 hours agorootparent> However, the examples you give, like Jan. 6 or militia incidents, don’t align with your routine mass murders implication That's my point: there's loads of \"apolitical\" school shootings and much less \"political\" violence. reply ganoushoreilly 3 hours agorootparentMy mistake there, I misinterpreted your point of view. reply mitthrowaway2 4 hours agorootparentprevWeren't there at least two high profile presidential candidate assassination attempts in 2024? reply pjc50 4 hours agorootparenthttps://en.m.wikipedia.org/wiki/Ryan_Wesley_Routh https://en.m.wikipedia.org/wiki/Thomas_Matthew_Crooks Indeed. But since they're right wing guys attacking Trump, it seems to have faded from the conversation. Also they failed. reply sadboi31 4 hours agorootparentprevYeah they do. Check out the 764 cult + project gladio. Lots of assassinations towards left-leaning folks. Atleast two such cases recorded on forensic architecture of murders of hacktivists going unchecked after quiet obviously being staged by intelligence agencies. One in Germany and one at a BLM event. I wont speak more on it here but I can think of atleast 6 people i've known closely who've just gone completely dark online + in their community after anti-govt organization. I assume they're dead. reply billsmithaustin 1 hour agoprevHe probably started out wanting to make just one pipe bomb but you know how it is, you get a great discount if you buy the ingredients in bulk. So he made his pipe bomb and then he had all these leftover ingredients just taking up space in his closet. And so he went ahead and made another 149 pipe bombs. reply smallmancontrov 55 minutes agoparentCould be, or maybe they had a really good discount at the pipe bomb store and he'd basically be losing money if he didn't buy at least 150 pipe bombs. reply fasa99 36 minutes agorootparent“We had two barrels of fertilizer, seventy-five pellets of gunpowder, five sheets of high powered C4, a salt shaker half full of nitro, and a whole galaxy of 50 cals, buckshot, slugs, tracers... and also a quart of kerosene, a quart of diesel, a case of grenades, a kilo of raw uranium and two dozen rockets. Not that we needed all that for self defense, but once you get locked into a serious explosives collection, the tendency is to push it as far as you can.” -Osama Bin Laden reply boomboomsubban 22 hours agoprevIf he was prepared to set up a turret to prevent his arrest, how did they nab him without incident? Reading more about this, it seems to have come after a several year investigation. Yet he is out on bail as for some reason the only thing he's being charged with is owning a short barreled rifle. Which seems bizarre. https://www.vpm.org/news/2024-12-31/norfolk-homemade-explosi... reply jandrewrogers 21 hours agoparentHigh explosives are basically legal in the US, depending on State law, to a degree that I think would surprise most people. I've been to local retail depots where you could literally buy high-explosives by the ton from a pretty large menu, cash and carry. And explosives are dirt cheap, it is bulk industrial chemistry. The only real requirement was that you have a vehicle with the standard hazard placards and the surface of the storage area in the vehicle is non-sparking material. A short-barreled rifle, on the other hand, it is strictly forbidden without an appropriate Federal tax stamp. One of the reasons that high-explosives are widely legal is that they have several common applications for individual use. Despite the availability and consumption of high-explosives in the US, misuse has been very rare in practice. reply giantg2 6 hours agorootparent\"High explosives are basically legal in the US\" The compounds generally are. The applicable use is where the laws come into play. Things like pipe bombs, devices marked \"lethal\", etc are not legal without special permits and would be deemed destructive devices. reply nullc 15 hours agorootparentprevAnyone who is surprised that high explosives are available has not had to deal with a bunch of large stumps. -- they're a nightmare even with a large excavator, explosives are a life saver. reply kstrauser 14 hours agorootparentYup. I was surprised when my cousin showed me my uncle’s TNT stash, but then explained how they cleared stumps off the family farm. One of my rural buddies told me how he spent a summer mixing diesel and fertilizer to clear fields, approaching it like a lab experiment and keeping detailed notes. Honestly, both sounded like a lot of fun. reply buildsjets 7 hours agorootparentprevI read a book a while back about the founder of San Juan Airlines, a local commuter airline, in the Puget Sound area. There was an entire chapter that described the process of the founder clearing the Friday Harbor runway on San Juan island of trees, mostly working alone, using TNT and heavy equipment. https://www.amazon.com/Island-Bush-Pilot-Founder-Airlines/dp... reply sandworm101 15 hours agorootparentprevOr a beaver dam. Imagine a bunch of those stumps all concreted together with mud. reply raddan 10 hours agorootparentTwenty-plus years ago I hiked the Appalachian Trail. Back then, it was common practice to hitch a ride into town for resupply. One time when my partner and I were hiking in Virginia, we got picked up by a state department of conservation employee. During the ride I asked him what he did and he said “I destroy beaver dams.” When I asked him how he did it he said “with dynamite.” I laughed—how ridiculous, right?—and he looked at me very seriously and said “it’s not funny; beaver dams are difficult to remove.” For years I thought that this was some dumb redneck thing until I met another former DCR employee back home who told me the same story. reply op00to 7 hours agorootparentI dunno, the image of some beaver watching a guy in green and brown blow up its hard work with dynamite is pretty damned funny. His little face all surprised and angry. reply littlestymaar 13 hours agorootparentprevOr you can use stump remover (Potassium nitrate) which allows to use fire to destroy them safely. reply linsomniac 7 hours agorootparentAKA Saltpeter. I've heard that you can just dig the stump out after a few months, in addition to using fire. I bought some to remove a stump a few years ago, but when I went to drill the stump I found it had already rotted enough that I didn't need it. This was a small, maybe 10\" diameter, stump that had sat for a couple years. Going to see how well it works soon though; a few weeks ago had a ~2ft diameter stump left when my 65ft spruce snapped in a wind storm. Turns out about halfway up it had branched off into two trunks, and that junction was rotting, the wind storm caused that junction to snap half way up. In looking, my neighbor has a tree with the same dual-trunk situation, though hers is more likely to land on her house. reply lazide 12 hours agorootparentprevIt doesn’t work very well, and it can cause underground fires which pop up a year+ later. reply littlestymaar 7 hours agorootparentIt works well enough to be the only legal way of dealing with them in most of EU, and the consequences of mishandling are no doubt more severe with high explosive than simply “can cause underground fire”. reply foobiekr 0 minutes agorootparentAre you familiar with Centralia? nullc 6 hours agorootparentprev\"Works well\" may also depend on the species and sizes of the trees in an area as well as the soil composition. reply lazide 7 hours agorootparentprevUh, the EU has plenty of bans of very useful things. I know of at least one 500+ acre wildfire in California that was caused by burning roots. As to how much it matters or not? No clue. reply littlestymaar 4 hours agorootparent> Uh, the EU has plenty of bans of very useful things. Yeah, like AR-15 and high explosives, surprisingly violent death rate is much lower here… reply lazide 4 hours agorootparentAnd a whole slew of common chemicals used in harmless synthesis, and in many countries even things like common knives. reply littlestymaar 3 hours agorootparent> And a whole slew of common chemicals used in harmless synthesis The US also regulate chemicals, and knives are free to sell everywhere, it's just forbidden to be carried in public. reply chopin 2 hours agorootparentYou can buy this knife, but you can't carry it home. Many things which were common in my youth are vanishing forever. reply orf 1 hour agorootparentOf course you can carry it home… reply littlestymaar 1 hour agorootparentprev> You can buy this knife, but you can't carry it home. How can otherwise reasonable people come to believe nonsense like this just because it fits their worldviews will always remain a mystery for me. reply lazide 1 hour agorootparentNot in the EU anymore, but this was a consistent issue in the UK - at least in London with kitchen knives. reply solidsnack9000 4 hours agorootparentprevLike speech, equity compensation... AR-15s are actually not banned in many parts of the EU. reply tonetegeatinst 3 hours agorootparentIv got a photo from an unnamed image board. The dude showed of this EU compliant collection. Multiple pistols and rifles, and what some state would classify as weapons of war, an SBR, or a assault weapon. All obtained legally via permits and a local cop signing off on the paperwork. reply littlestymaar 3 hours agorootparentprev> Like speech Speech, in both the EU and the US is free under the limits set by law, the US isn't an “absolute free speech land”, you will definitely be jailed for speech that goes against the law (for instance death threats, see [1]). > equity compensation... What are you talking about, I've been given equity more than once… [1]: https://nypost.com/2024/12/12/us-news/florida-mom-arrested-f... reply krior 8 hours agorootparentprevI honestly don't know - what are some common applications of explosive material for private persons? reply chiph 8 hours agorootparentFor a farmer or other rural resident - getting rid of tree stumps or large boulders. No one in a suburb or city truly needs explosives. Note that it's not totally unregulated. If you are only an occasional user, you get a permit from the ATF for $25. Plus whatever your state/county wants. https://www.atf.gov/explosives/federal-explosives-licenses-a... reply pfdietz 7 hours agorootparentAnother application is removal of large rocks, or excavation in places where the bedrock is close to the surface. I recall seeing this done in Ridgefield, Connecticut some decades ago. The excavation was right next to a building and a mat was used to contain fragments. reply abakker 6 hours agorootparentHaha, as I read your comment I was thinking “yeah, like back in CT.” I saw this done in ridgefield as well. My friends property was basically all bedrock about 1’ under the topsoil. reply pfdietz 3 hours agorootparentIt was at the Schlumberger-Doll Research Center (which Schlumberger since moved to Cambridge, MA in 2007). reply infecto 8 hours agorootparentprevStump removal for one. I would wager this is one of those things where the further outside of the city you get the more common it’s use would be. reply zikduruqe 8 hours agorootparentBlowing up beaver dams that are flooding your farm land. reply krior 7 hours agorootparentprevMaybe I am naive, but is the ability to remove stumps without specialists really worth the risk of random inexperienced/careless people buying dangerous explosives? reply infecto 5 hours agorootparentTo be frank I don’t have much of an opinion on either side. Just sharing how it’s used. I have heard of very few issues with people buying these historically and most/all of these require putting your name on a list. I suspect a far greater many are injured from fireworks. reply Loughla 7 hours agorootparentprevWe use machinery for that now. It isn't 1823 anymore. reply infecto 5 hours agorootparentI am not advocating for anything but sharing how it’s used. The why would be a lot of people don’t have access to stump grinders and they can be awfully slow if you have a lot to take care of. They also are more expensive to rent and especially to buy. You don’t seem to have experience in the area but if you are taking care of multiple acres and need to knock out a number of stumps, machinery is pretty inefficient. It’s also difficult to move around if we are talking multi acre properties and not a residential less than acre lot. Get out of here with your ridiculous 1823 hyperbole. These explosive can be very efficient and useful when managing multiple acres. reply Loughla 3 hours agorootparentI have either full time or part time row cropped and livestock farmed for the last 40 years. The last time anyone anywhere even remotely close to me used explosives was to bust a levee. If you're clearing multiple acres you use a track hoe and a large bulldozer. Source: the 60 acres of grown up crp we finished clearing last month. I know the Internet wants you to think that rural life is all guns and explosions, but that's sometimes not the case. Why do you think every small town has multiple excavator companies? reply infecto 2 hours agorootparentI am sure you have but in the parts of the country I have lived in it’s been a fairly common tool used when clearing forested back country. Not talking so much farming. I don’t know where your snark comes from but it still has a place for some use cases. Sorry to disappoint your imagination. Certainly if you are whole clearing 60 acres machines are helpful. If you are cleaning up some spots here and there on a multi acre property it can be quite useful. So much snark from you for no reason. Different experiences for different folks. reply potato3732842 1 hour agorootparentprev>I have either full time or part time row cropped and livestock farmed for the last 40 years. The last time anyone anywhere even remotely close to me used explosives was to bust a levee. Because the law is such an expensive PITA to comply with that nobody does it. People blew up rocks and stumps all the time before the mid 1970s. reply potato3732842 1 hour agorootparentprevMachinery is a complete joke compared to explosives unless you're operating right up near stuff you care about. About once a week I get pissed off that I'm on Craigslist looking for expensive tractors and expensive attachments instead of just a drill bit and explosives all because some leftists blew up some bathrooms in the 1970s and the 1970s equivalent of people like you wrung their hands over it. Source: Clearing acreage the hard way in my spare time reply harimau777 5 hours agorootparentprevAt one point it was pretty common for farmer's guidebooks to include recipes for explosives that could be used to clear land (e.g. boulders). It's fairly common for tannerite to be used for target shooting. Gunpowder is commonly available for reloading. I doubt this is common and should probably be illegal if it isn't already because it's horrible for the environment. However, blast fishing is apparently actually a thing! https://en.wikipedia.org/wiki/Blast_fishing reply jandrewrogers 4 hours agorootparentprevMostly agriculture, mining, and (re-)moving rock. reply boomboomsubban 13 hours agorootparentprevThere are laws barring explosives, see https://www.law.cornell.edu/uscode/text/18/842, and the one mentioned in the article is listed as having no known use with at least some evidence of others being charged with having it. Maybe the charge would get thrown out at some point, but not including it in the indictment seems odd. reply brookst 8 hours agorootparentNot sure about this kind of case, but for more garden variety crimes it is common for the first charges to be slam-dunk, with tons of evidence and a clear path to conviction. Then, during the pre-trial phase, a superseding indictment can be added as more evidence is gathered and a stronger case is put together. This happened with Paul Manafort, who was first indicted for “conspiracy against the United States”, but then the superseding indictment included all sorts of tax and bank fraud. reply lazide 12 hours agorootparentprevThose laws don’t actually bar explosives at all, and there are numerous carve outs that could potentially meet what the poster is describing. You might want to read it? Though it would be helpful to know which state, because I don’t know of any that are quite that easy to deal with. BATF to my knowledge does still require a license (albeit easy to get if you meet the requirements) for commercial use, anyway. reply boomboomsubban 7 hours agorootparent>It shall be unlawful for any person to engage in the business of importing, manufacturing, or dealing in explosive materials without a license issued under this chapter Seems fairly clear cut. You could argue the term \"business\" means they need to be selling the stuff, but the definitions clarify \"manufacturing\" includes for personal use. edit it never occurred to me he may be licensed. Still, this particular explosive seems to have no approved use, and the licensing seems to be for specific explosives. I may be wrong on that though. And it's Virginia, the Isle of Wight is a county in Virginia. reply solidsnack9000 4 hours agorootparentWhere does it clarify that manufacturing includes personal use? I did read it over a couple of times and I couldn't find anything that says that, at least not in those words. However, it may be that the suspect violated a different section of the law: It shall be unlawful for any person to store any explosive material in a manner not in conformity with regulations promulgated by the Attorney General. The suspect may also have violated the NFA, by manufacturing destructive devices without appropriate permitting or record keeping. reply boomboomsubban 3 hours agorootparent>Where does it clarify that manufacturing includes personal use? The definitions, which were on the previous page. https://www.law.cornell.edu/uscode/text/18/841 reply solidsnack9000 3 hours agorootparentYou may be referring to (h), but that is the definition of \"manufacturer\". I'm not sure if we can take that to mean \"engaged in the business of manufacturing\" includes non-commercial activity. reply lazide 7 hours agorootparentprevPurchasing, and using are still fine (when non-commercial). The dealer would be the one with the license. Also, manufacturing and using on site for non-commercial purposes is exempted (albeit not explicitly). Which is why tannerite and personal explosives research is fine and widespread. reply tonetegeatinst 3 hours agorootparentCan I see a link to the exemption for non commercial use? While I get some things are exempt like tannerite, I find it highly unlikely someone could just manufacture TNT or rdx and use it in their back yard without breaking a ton of laws. Even if you used it within the 24 hour requirement so it didn't have to be stored(iirc from my memory of old legal readings) reply lazide 1 hour agorootparentIt depends on state laws, but there are a LOT of folks doing it on youtube - zero prosecutions i’m aware of. [https://www.atf.gov/explosives/binary-explosives], halfway through the ‘License and or permit requirements’. It’s not actually specific to binary explosives, but those are the ones where it most clearly applies to random members of the public. Specifically, “Persons manufacturing explosives for their own personal, non-business use only (e.g., personal target practice) are not required to have a federal explosives license or permit under 27 CFR, Part 555” The issue is the law is clearly written to regulate commercial activites, and the fed gov’t (at least in theory) only has jurisdiction over commercial activities (those involving trade). There is a lot of court precedent on this, some of it confusing. So while the law doesn’t explicitly exempt personal, non-business use, the courts (and constitution), and the law, doesn’t cover personal, non-business use either. So, legal. also, there is zero chance they could stop it. reply Hnrobert42 10 hours agorootparentprevnext [2 more] [flagged] lazide 9 hours agorootparentMy comment did not refer to the article at all. It was if they had read the link to the law they pasted. Which near as I can tell they hadn’t, because the content of the law is the opposite of what they are asserting it is. Feel free to check the law yourself if you’d like. reply strathmeyer 7 hours agorootparentprevUS government started tracking explosives sales in the 70s which is why such terror incidents drastically dropped at that time. Misuse is rare because of government regulation. reply jabroni_salad 14 hours agoparentprevEasiest way to arrest somebody with a built up home is to just wait for them to leave. This guy had a day job. reply giantg2 6 hours agorootparentBAFTE may have finally learned that after their extensive history of ignoring location, such as Ruby Ridge, then Waco, etc... reply ty6853 21 hours agoparentprevTannerite, black powder and some explosives can be legally bought and owned cash and carry. It's quite likely no law was broken and all they found was a questionable pistol brace on a short lower. Remember FPSRussia went down for paint on a serial number and a few vape pens but the arrest bulletin made him sound like a madman. reply loamaa 19 hours agorootparentI was interested, so went and checked out the filing for this [1], it looks like he only got hit with the possession with intent to distribute, with the other 3 charges (including 'possession of a firearm with an obliterated serial number') being dismissed. [1] https://www.courtlistener.com/docket/8228342/parties/united-... reply WatchDog 11 hours agorootparentHe took a plea deal, might have beaten the charges at trial, but the consequences of losing were way too high for him, can’t really blame him. reply throwup238 15 hours agorootparentprevMarijuana and honey oil. He watched too much Trailer Park Boys and got caught. reply throwaway173738 15 hours agorootparentHe must’ve forgot to mix it with maple syrup. reply d883kd8 7 hours agorootparentprevAre you sure that's the same case? That links says, \"Last Updated: Oct. 7, 2022, 6:14 a.m.\" and the defendant name is different from in the OP. This appears to be the actual case: https://www.courtlistener.com/docket/69482949/united-states-... reply aspenmayer 5 hours agorootparentYou're both right, but your comment is confusing the issue. You're linking to the relevant case for TFA, whereas parent is linking to the relevant case for this thread regarding FPSRussia. https://en.wikipedia.org/wiki/FPSRussia reply d883kd8 4 hours agorootparentmy bad I should have read closer reply sgarland 9 hours agorootparentprevIt remains bewildering to me that tannerite is legal to purchase in large quantities without question. I shot 1 lb. of it once with a Mosin-Nagant, and that was enough to rattle the house a few hundred yards away. There are people who have set off charges orders of magnitude more than that, which apparently can be felt MILES away. It’s an explosive, full stop. I have no problem with the premade targets that have a small amount, but honestly, the larger quantities should require at a minimum a background check. reply bravetraveler 6 hours agorootparentI know little about this... but small amounts could still pose an issue. See: mules, Pseudoephedrine reply lazide 5 hours agorootparentprevlook up TATP. you aren’t going to be able to ban those ingredients either. reply mschuster91 4 hours agorootparentGermany manages to do so just fine. It's virtually impossible to obtain hydrogen peroxide in enough high concentration and volume to produce significant amounts of TATP without setting off more than a few alerts. Almost all popular precursor chemicals for drugs and explosives are heavily controlled in Europe. reply jandrewrogers 1 hour agorootparentThey do the same in the US but it just makes the synthesis a bit more complicated. Friction may be the point. Plenty of people synthesize the precursors. It is precursors all the way down, each one more ubiquitous and innocuous than the previous. Bootstrapping chemistry is 19th century technology. reply tonetegeatinst 3 hours agorootparentprevWouldn't this just encourage another killdoser situation without the guns? Just the armor? I mean if someone wants to cause mass causulty and terror its going to happen, be it a gun or a knife or explosive. Hell I'd argue cyber attacks could also do the same. reply giantg2 4 hours agorootparentprevWhat's the concentration cutoff at? reply lazide 4 hours agorootparentFrankly, you can make it with 3%. It just takes longer. reply giantg2 4 hours agorootparentI mean the legal limit in Germany. reply fullspectrumdev 13 hours agoparentprevBecause the turret thing was probably a drunken shitpost/joke he made to the informant that he thought was his friend much like the “claymore roomba” or “tannerite dog” meme. reply ganoushoreilly 4 hours agorootparentIf you look at a lot of their evidence it's a bunch of memes, if it goes to trial it'll be an interesting case to read for sure. reply 45645g54g54 4 hours agoparentprevPeople like this are a dime a dozen. They are the \"If the government tries and comes to takes ma guns 'way im gon....\" type. Most of the time they are entirely harmless and it is all action fantasy. FBI keeps track of these types (they are loud) and they keep track of the inventory too. This guy isn't ever going to go on a rampage, and when the FBI knocks he will always roll over and comply. It only turns into a Waco when you accumulate a following of sorts. reply praptak 3 hours agorootparent> It only turns into a Waco when you accumulate a following of sorts. You don't need a Waco for many people to die a violent death. https://en.wikipedia.org/wiki/Oklahoma_City_bombing reply ufmace 7 hours agoparentprevIt did say he was supposedly \"considering\" doing that, not that he actually did it. reply m0llusk 12 hours agoparentprevProsecution of cases like this can be extremely complex. Most likely the gun charge was an easy first step to get the process going. Other charges will be waiting on analysis of exactly what was going on and what materials have been found and taken. With this much it takes a while to be fully sure of the inventory. reply sandworm101 16 hours agoparentprev>> how did they nab him without incident? Because the vast majority of these guys are all talk. For every Ted Kaczynski there are a thousand Dale Dribbles: backyard tinkerers who give up all notion of resistance when the cops actually show up. The cops cannot tell the difference and so must treat them all as potential Teds. Once safely in custody, the Dales will quietly plead guilty to vastly reduced charges. reply vasco 14 hours agorootparentKaczynski was arrested peacefully as far as I can find. reply giantg2 6 hours agorootparentThat's because they surprised him. I'm pretty sure they had to yank him out of the cabin after he realized what was going on and started to close the door. reply mathgeek 11 hours agorootparentprevThe difference being the act of using the explosives, not resisting arrest. reply sandworm101 11 hours agorootparentprevYes but Ted clearly demonstrated a willingness to kill. If he had seen them comming, who knows what he might have done. reply potato3732842 1 hour agorootparentprevEh, enough of those guys will go down shooting that I wouldn't want to sign up for kicking in the doors. They know it's either jail for life or death. The difference is that the Dale Gribbles don't go out of their way to harm anyone whereas the uncle Teds do. reply mcnamaratw 7 hours agorootparentprevDale Gribble reply lordofgibbons 22 hours agoprev> The filing also references Spafford’s belief in “no lives matter,” an apparent nod to a far-right ideology that primarily coordinates through encrypted apps. That's a scary sentence. I fear this might be used to mandate backdoors into encrypted apps. reply asveikau 10 hours agoparentTo me the scariest part of that sentence is that multiple people would subscribe to a misanthropic statement like \"no lives matter\". We should also object to telegram being called an encrypted app. It is not encrypted by default. When you optionally enable the cryptography it has, IIRC they rolled their own ciphers and it's not considered good by anybody serious. reply e40 10 hours agorootparentThe gal of post-modern propaganda is to make people believe in nothing. Nihilism through and through. reply raddan 10 hours agorootparentprev“No lives matter” was also a tongue-in-cheek slogan for the “Cthulhu for President” campaign [1], which riffed on the absurdity of Trump running for president in 2016. Maybe it has morphed into something else since then. [1] https://en.m.wikipedia.org/wiki/Cthulhu_for_President reply nosioptar 8 hours agorootparent\"No lives matter\" is also a 2017 song by Body Count [0] about class inequality. [0] https://youtube.com/watch?v=hlk7o5T56iw reply neilv 22 hours agoparentprevThe journalist's bio: > I am The Hill’s national security and legal affairs reporter [...] So I assume the journalist wrote the piece themself, and knew how loaded that line was. reply HeatrayEnjoyer 14 hours agoparentprevThe sentence is accurate nonetheless. reply dotancohen 12 hours agorootparentYes, implanting inaccurate ideas in peoples' worldviews via the use of not-innaccurate statements is an artform that is being perfected. This is a scary example of such. reply dialup_sounds 12 hours agorootparentSo saying true things is bad now? reply dotancohen 11 hours agorootparentSaying true things has always been bad when done with bad intentions. Implying that \"coordinating through encrypted apps\" is a property of \"far-right ideologies\" is a clear attempt to smear the usage of encrypted apps, assuming that the reader already has a negative association with \"far-right ideologies\". reply dialup_sounds 26 minutes agorootparentI don't think that's clear at all. You're both assuming \"bad intentions\" on the part of the author and that other readers are apt to make an association that you yourself wouldn't make. But for the sake of curiosity: How would you rephrase the same facts to not be a smear? reply gverrilla 10 hours agorootparentprevIt was not implied it's a \"property of far right\", at all. All it's saying is \"no lives matter\" coordinate not in public networks. reply llamaimperative 9 hours agorootparentprevI didn’t read it that way at all. reply luckylion 10 hours agorootparentprevTechnically yes since communication via most messengers, forums etc are encrypted. But I assume that's not how most readers will understand that message, their mind will go towards something like encrochat, i.e. some app specifically made for illegal/terrorist/far right extremist communications. If you said \"we should do something about that\", that'll get a fair bit of agreement. If you said \"we should do something about your browser being able to use encryption\", you'll get less. reply wakawaka28 18 hours agoparentprevYour instincts are right. They parade the freaks in front of our faces to manufacture consent for all kinds of oppression. >I fear this might be used to mandate backdoors into encrypted apps. You mean above and beyond the multiple levels of surveillance now in place, including AI agents on your devices and god knows what backdoors into TLS? They already have more than most people imagine. They just don't want you to know for various reasons. reply icameron 22 hours agoprevAs a teenager in the 90s I was a bit of a pyromaniac. The early internet allowed us to purchase long fuses, nitromethane from eBay, and “homemade C4” from Amazon. An FBI field agent had a knock and talk to the address we had ordered the fuses to. They don’t mess around! Not sure how they found out either. reply geor9e 21 hours agoparentThat unique 90s time period where any kid could print out bomb making recipes on the school printer from alt.anarchy or whatever, but columbine hadn't occurred yet so we didn't really get in trouble when a teacher found out. reply jcims 14 hours agorootparentIn the mid 80s my best friend brought in a select fire (aka full auto capable) mauser c96 with the case that doubles as a stock. His grandpa acquired in wwii, the teacher just asked if it was loaded. reply SoftTalker 15 hours agorootparentprevOr the '80s, when you could just order the Anarchist Cookbook from a willing bookstore (some would refuse). At the time I recall that there were definitely kids into this stuff. Not literal anarchy or violence, they just liked making bombs and setting them off out in the woods somewhere. Homemade fireworks really. They got into the chemistry of it, just nerdy stuff. No harm intended. reply ganoushoreilly 4 hours agorootparentIn the 90's almost all of us played with fireworks and m80's in the fields. We used to rig up long fuses with our estes rocket kits for remote detonation. Everyone turned out fine. The pre No Child Left Behind / Zero Tolerance era of school, was a great time. I feel bad for kids today. reply jandrewrogers 14 hours agorootparentprevTo be honest, the Anarchist Cookbook had some really dodgy recipes. It was arguably a collection of future Darwin Awards. reply Spooky23 13 hours agorootparentThe bookstore clerk told us that, and suggested that we purchase an army improvised munitions field manual. Lol reply bboygravity 13 hours agorootparentprevThe tennisball bomb definitely didn't work as advertised. Just saying * looks around innocently * reply 0xDEADFED5 13 hours agorootparentso you also made a tennis ball rocket? reply magic_smoke_ee 13 hours agorootparentprevIn the 90's, Tower Records sold The Anarchist Cookbook no questions asked. Its recipes didn't appear very well researched and some seemed outright lethal or impossible. reply ganoushoreilly 4 hours agorootparentOn the bulletin boards there used to be all these horrible phone phreaking plans that were clearly not functional, like the blotto box that would electrocute someone across the phone lines. We also had all those weekly world news tabloids.. i think some of it just made for weird entertainment. reply ternnoburn 15 hours agorootparentprevI was also around then, and even then it had a reputation of being trash, not really anarchist, and probably dangerously poorly put together. reply pstuart 14 hours agorootparentprevI've heard the two gateways into becoming interested in chemistry are getting high and blowing shit up. reply AuryGlenz 14 hours agorootparentA friend and I want to make a small amount of nitroglycerin in chemistry class in HS. The teacher was all for it, but it got bumped all the way to the superintendent who shot it down. Boo. reply magic_smoke_ee 13 hours agorootparentAnything fun in life is illegal, immoral, fattening, or dangerous. In high school chemistry, I once superheated magnesium in a covered crucible and then blew on. That was fun. reply magic_smoke_ee 13 hours agorootparentprevAll chemists are pyros, by definition and by requirement. reply StanislavPetrov 21 hours agorootparentprevIn the early 1990s a friend of mine ran a dial-up BBS. It was completely unmoderated (aside from spam), and ended up become a rather active board for (mostly black hat) hackers to post and trade information. My friend wasn't involved in any hacking directly - he simply ran the BBS which also hosted a bunch of doors (games) like TW2002 that were also quite popular. One day, a mutual friend of ours (who was an aspiring black hat hacker) got picked up by the FBI for a variety of phone phreaking offenses. During questioning, they asked him a bunch of questions about the BBS. As soon as he got out on bail, he relayed this information to my friend who ran the BBS. Needless to say, the BBS was shut down and all of the disks/hard drives trashed within an hour. Thankfully there were never any legal implications for my friend with the BBS, but you can be damn sure there were quite a few sleepless nights subsequently as he waited for a knock on the door! reply macintux 22 hours agoparentprevI have a very old, very fuzzy memory of someone telling a story about sending a completely meaningless, “encrypted” (garbage) snail mail letter to somewhere in the Soviet Union. Despite taking great precautions to obscure their identity, they still received a visit from government law enforcement. reply jokoon 2 hours agoparentprev> Not sure how they found out either. I surely hope they can find out, and the harder it is to know how they found out, the better it is since fewer people will be able to evade it. reply underlipton 4 hours agoparentprevThese kinds of posts are always fascinating to me, as someone who had to move heaven and earth to get a graphics tablet and a PC that could run XP and Blender c. 2006. It's not like we were in particularly dire straits financially, and were on the more rational side of \"overly sheltered\" (having known people who couldn't attend school clubs or who had a parent hovering over their shoulder every time they got online), but the freedom and access some of y'all had is just... hard for me to fathom. Like, whose credit card were you using?? reply icameron 45 minutes agorootparentYou could buy western union money orders for 45 cents at the minimart, and mail it to the seller with the item number. Sometimes even send cash. reply boomboomsubban 4 hours agorootparentprevBefore eBay acquired PayPal in 2002, buying something then mailing the person a check was fairly common. reply ganoushoreilly 4 hours agorootparentprevFor some of the stuff in the early days we could mail cashiers checks with the order number, bypassing need for credit card. Sure it took longer, but you could still buy a lot of stuff that way. reply fullspectrumdev 13 hours agoprevI’m still not sure what this guy is meant to have done wrong beyond having a rifle that’s “too short” and blowing up some shit on his own property and I guess having some edgy political ideas. None of which should be crimes. reply surfingdino 10 hours agoparentMaking pipe bombs is not something you can defend in court, even if purchase and possession of explosives is legal. reply magic_smoke_ee 9 hours agorootparentPipe bombs can be legally owned by private parties with an DD NFA tax stamp. They probably require a certain type of BATF manufacturer cert to make as well. reply tonetegeatinst 8 hours agorootparentThis is correct. ATF permit to manufacture and use explosives, and Destructive Devices. Register the destructive device and any made explosives. Normally each state has an explosives license that you must also have, some of which are almost impossible to obtain unless this is your main job, so hobbyists can't get a permit. Also destructive devices have to be legal in the state. And the use of the device has to be recorded via paperwork. As someone who has an interest in energetics and law, the federal law is pretty reasonable if not just a pain in the ass to handle paperwork wise. The addition of every state having laws you need to comply with in addition can make this pretty easy or upright impossible unless your main day job is working in some mine or something similar. reply magic_smoke_ee 8 hours agorootparentHad to look it up because I can't remember nitty-gritty details: DD manufacturer under class 10 FFL or class 2 SOT. I imagine the various types of insurance needed to operate such a business are expensive and painful too. reply tonetegeatinst 7 hours agorootparentCorrect. DD manufacturing the separate license from the ATF then an explosive manufacturing license and then if a pipe bomb is constructed it's considered a destructive device not an explosive device and has to be registered on paper as such and then you also need a separate license to use the device and then once used it has to be marked as used on paper. reply giantg2 6 hours agorootparentAnd if you have the materials (short pipes, lots of caps, etc) to build the pipe bombs in the same area as your expolsive manufacture without the DD paperwork, you could still be charged with constructive intent. Same as if you have an unbuilt short barrel and a built lower with a stock they have charged people with intent to manufacturer an SBR. reply tonetegeatinst 3 hours agorootparentCorrect. While I have the ability to read some legal text despite having 0 law education, it still is confusing and hard to interpret stuff. While I understand the need for regulation, and safety, it seems almost if not impossible to navigate. Unless you have the money to pay for lawyers and someone to handle compliance, its very easy to make a mistake that could kill your career. So your corporations or large businesses can afford lawyers and compliance consultant people so they ensure they are fine and dandy, but if you rural person wants to build explosives to mess around and experiment and research, their is no way they can afford this unless they are super rich. Ordinance Labs somehow does this but they are Texas based, and make money off of consulting....so they are a great example of how hard this is. They also are being accused of violating ITAR and EAR which is serious. reply giantg2 6 hours agorootparentprev\"the federal law is pretty reasonable if not just a pain in the ass to handle paperwork wise\" I mean, that's how they get you. Make it so you have to jump through a ton of hoops, make the penalties to accidentally violating them felonies, then wait. That's how you discourage people from doing something - make the penalties for mistakes so high that people give up. That's part of why you see gun ownership numbers go down in places like NJ while they brag about gun safety laws working. The trick is, the laws like hollowpoint bans didn't actually improve gun safety, it simply reduced the guns per capita by reducing number of people willing to own a gun when harmless mistakes can ruin your life. reply tonetegeatinst 3 hours agorootparentCorrect. I believe their is a term for it but basically they pass a \"gatchya law\" that is super difficult to follow and open to interpretation, then if someone gets caught doing something they have a reason to prosecute. Example: speeding laws, ammo or firearm storage laws, tax laws etc. Most people are reasonable when they drive, but don't always follow the speed limit. If they catch you and other charges fail they always have speeding as an excuse. Tax code is so complicated and constantly changing its a real joke. They even have people who exist to handle the bullshit because its so complex, just like how laws are written. CPA and lawyer do the same job in a sense, figure out the bullshit so you don't go to jail or commit a felony. reply potato3732842 1 hour agorootparentThe real evil is the people who give the power to the people who create this perversion of rule of law, saw that they did this and decided they were ok with it. I don't care what the subject is, the law should NEVER be like this. reply surfingdino 5 hours agorootparentprevThings I learn on HN... Thanks! I wonder if the guy had all necessary tax stamps or licenses? reply jandrewrogers 21 hours agoprevThe one explosive they mention by name as \"unstable\" is actually a pretty professional primary for specialist applications. Easy to synthesize from common materials but not trivial for amateurs to make usable. In addition to being entirely unworkable as a main high-explosive it also tends to rapidly decompose (benignly) when in contact with many common metals and poor storage, so shelf-life can be an issue. reply Hilift 14 hours agoparentIt's stable when pure. This guy made his own, and lost three fingers in the process. It seems to have developed a reputation with suicide bombers, probably due to the illusion of easy manufacture. reply jandrewrogers 13 hours agorootparentThe articles I’ve seen do not imply he lost his fingers working with it. I’ve also never seen it associated with suicide bombers, you may be thinking of acetone peroxide chemistries (e.g. TATP), which are common low-grade explosives used by terrorists. Also highly inadvisable, TATP is a pretty shit explosive in almost all aspects (low power, low stability). Someone stupid enough to be using TATP should not be using HMTD, as the latter requires more discipline than TATP. There is a technical gap between making HMTD and processing it into a form that can actually be used in practical explosive systems. reply littlestymaar 13 hours agoparentprev> The one explosive they mention by name as \"unstable\" is actually a pretty professional primary There's no contradiction here, the main characteristic of a primary is it's (relative) instability. reply ty6853 22 hours agoprevRight to keep and bear arms shall not be infringed. You could own cannons and warships when 2a was passed. The real criminal in this case is feds depriving fundamental civil rights under color of law. The failure to register short barrel rifle pretext in particular is based on faulty precedent that military did not use short barrel arms thus the NFA stamp was 'constitutional'. ( then, lol, gov obliviously sold a bunch of surplus rifles to public breaking this same law on accident which is why rifles have lower limit now than shotguns). reply neilv 21 hours agoparent> The real criminal in this case is feds depriving fundamental civil rights under color of law. The allegation is that this person made a veritable arsenal of pipe bombs and other explosives, with plausible domestic terrorism intent or inclinations. The Second Amendment technicality you mention might come up in a legal defense, but I don't understand fixating on that as \"the real criminal\" here -- on a story of securing a very dangerous-sounding cache of pipe bombs, mishandled explosive material, etc. reply ty6853 21 hours agorootparentThe actual charge here is a tax violation (failure to buy a stamp for a short barrel rifle). Not paying $200 in NFA taxes. The precedent is based on a lie the gov itself accidently violated during surplus sales to the public. The precedent exists because the Supreme Court took up a case against a dead guy with no representation, as a poison pill. The state argued the military didn't use short barrel arms, which was a lie. No defense was there to contest it, and this it is now binding on total fiction. Of course the most hilarious part is 'short barrel' anything was just a measure to ban pistols, which congress changed their mind on last minute and allowed pistols while forgetting to nix the law on creating pistols from long arms. This guy is charged for essentially violating a historical vestigial accident upheld by bogus precedent against an undefended dead guy. reply neilv 19 hours agorootparentThere could be an interesting meta discussion here, of the kind that doesn't usually happen recently. IIUC, you're focusing on that 2A aspect because it's a topic that you know and care about, and think needs to be mentioned? And the other aspects of the story were already being discussed, and you had nothing to add on those? If so, did you say \"the real criminal\" only as a figure of speech? Or do you think that nothing about the pipe bombs, etc., was criminal? reply snypher 19 hours agorootparentJust to be clear, he was charged with a single firearms offense, and is presumed innocent of that. If other charges appear then they should be discussed. >do you think that nothing about the pipe bombs, etc., was criminal? Seems like the FBI don't, for now. Just like when someone is reported as having \"an encrypted messing app\" - fear mongering nonsense. reply neilv 13 hours agorootparent> If other charges appear then they should be discussed. The HN post is on the news story. The news story is not a trial, and is about more than whatever charges are filed against anyone thus far. Other aspects of the story are already in active discussion. I'm trying to get at more substantial discussion than on Twitter, by understanding why someone was speaking the way they were, by asking them. > Seems like the FBI don't, for now. Does it actually seem like that, or does it seem like probably the FBI expects that there will probably be additional charges? reply simoncion 11 hours agorootparent> I'm trying to get at more substantial discussion than on Twitter, by understanding why someone was speaking the way they were, by asking them. You said: > The allegation is that this person made a veritable arsenal of pipe bombs and other explosives, with plausible domestic terrorism intent or inclinations. > The Second Amendment technicality you mention might come up in a legal defense, but I don't understand fixating on that as \"the real criminal\" here -- on a story of securing a very dangerous-sounding cache of pipe bombs, mishandled explosive material, etc. Your slant there is that this fellow's possession of explosives was illegal... or maybe SHOULD have been. If it was even vaguely-plausibly illegal, the fellow would have been charged. The cops searched his entire place and detonated some of his explosives, so it's not like the cops were unaware of the explosives. As mentioned in this thread [0] (and accompanying subthread), he's just being charged with a tax violation (and is currently out on bail) probably because possession of high explosives is usually entirely legal in the US. Frankly, it should be illegal for police and other similar government agents to engage in character assassination. Statements from government agents like \"This fellow was in possession of large-but-entirely-legal quantities of entirely-legal substances and materials. Be very afraid!\" should absolutely leave the speaker personally liable for something akin to libel. [0]reply lazide 12 hours agorootparentprevNah, they’re holding him on the super easy to prove felony while they see if they can nail him on a bunch of other things. reply giantg2 5 hours agorootparentThey aren't really holding him. He's out on bail, right? reply lazide 5 hours agorootparentDespite everything they’ve been saying (this was all in the court filings to try to deny him bail), he did still end up getting released on bond. So it wasn’t enough. or the evidence they provided wasn’t credible. reply ganoushoreilly 4 hours agorootparentWhich should also be a red flag, if this individual was a credible threat they wouldn't have granted bail. I can't even imagine the headlines that some of my neighbors would have \"Man with Arsenal and stockpile of thousands of rounds of ammunition\" presented in a slant. Meanwhile he had a few buckets of 22lr, and a half dozen rifles. Given the evidence we've seen, the memes, and what would clearly pass as joking, there isn't really any \"Here's my plan for x date\" type smoking gun. reply sleepybrett 6 hours agorootparentprevlet me introduce you to the 'superseding indictment'. They charged him with the easiest thing. They'll follow it up later. reply ty6853 6 hours agorootparentIllegal explosives are also usually NFA tax violations, fwiw. reply ungreased0675 7 hours agorootparentprevThe domestic terror intent seems like a real stretch. Guns, grenades and explosives are legal, if you do the right paperwork. This guy is being charged with not doing the right paperwork, with a bunch of inflammatory right-wing memes stacked on top. reply ganoushoreilly 4 hours agorootparentRight, you could find memes from just about anyone and paint an extremist picture with the right context left in or out at your discretion. I think that it's clear this wasn't the \"credible\" threat implied, simply by his bail. reply magic_smoke_ee 9 hours agoparentprevThere exist private ownership of artillery field pieces and Bofors L/60 40 mm autocannon in America. The thing though is that any sort of exploding shell requires a DD NFA tax stamp for each. reply wat10000 21 hours agoparentprevI don’t think I’ve encountered anyone who thinks there should be a right to privately own nuclear weapons. Basically everybody agrees there should be limits on the Second Amendment, the only real disagreement is where. reply solidsnack9000 3 hours agorootparentThis is not really an interesting line of discussion because all the relevant regulations regarding classified information, materials handling, and industrial safety would be enough to effectively prohibit possession of nuclear arms, without any reference to arms at all. I'm not sure we even have any laws explicitly prohibiting possession of nuclear weapons -- most of the material I've found so far on the subject in the",
    "originSummary": [],
    "commentSummary": [
      "The FBI uncovered the largest cache of homemade explosives in its history in Virginia, leading to significant legal and public debate.",
      "The suspect is currently only charged with possessing a short-barreled rifle, as the legality of his firearms is being examined.",
      "The case has ignited discussions on gun laws, the Second Amendment, and the balance between government regulation and individual rights."
    ],
    "points": 224,
    "commentCount": 371,
    "retryCount": 0,
    "time": 1735686210
  },
  {
    "id": 42562743,
    "title": "Déjà vu: Ghostly CVEs in my terminal title",
    "originLink": "https://dgl.cx/2024/12/ghostty-terminal-title",
    "originBody": "Déjà vu: Ghostly CVEs in my terminal title Exploring a security bug in Ghostty that is eerily familiar. As I've spoken and written about all modern terminals are actually \"emulating\" something dating from the 1970s. The full details are surprisingly complex and having a standard building block for these things is important. We can probably do better, but it's hard to change something so fundamental. In Feburary 2003 HD Moore published a paper to bugtraq called \"Terminal Emulator Security Issues\". On the 26th December 2024 Mitchell Hashimoto released Ghostty 1.0. A new terminal emulator. The name even has a little nod to the \"tty\" of old. I instantly tried it out and ran my terminal tester on it: Oh dear. That 2003 CVE is indeed the one HD Moore found many years ago. The new issue has been assigned CVE-2024-56803. Why are we here again? First of all, given the number of terminals which have been affected by this, this is clearly a fundamental issue. The fundamental problem is that terminals use in-band signalling, that is the ASCII escape character escapes from the mode the terminal is usually in (printing text) and starts handling the input to it as something else. These other things are known as escape sequences and they can change the colour or ask the terminal to do various control things. One of those control things is setting the title. That's useful, when you run cd in your shell, it's quite nice the title of the window or tab updates so you know which directory a particular terminal is in. However there is also a sequence to query the title. These \"query\" sequences are particularly problematic when combined with the in-band signalling nature of a terminal, if the program running inside the terminal does not expect a reply at that moment, it may handle it differently, or even treat it as user input. In general any reply where the user can control the data should be considered very carefully. Most terminals therefore disable title reporting by default or even don't implement it. (A recent iTerm2 bug was a regression around the configuration option itself to disable it.) In 2022 I discovered a bug in xterm where the font query could be used to inject user controllable text. This only worked on Zsh and made use of the fact the \"Escape\" used as part of the escape sequence is also the key you press to leave insert mode and enter the Vi normal mode. The Ghostty variant It turns out with Ghostty we can do something very similar to the xterm issue, in Zsh with vi mode enabled (set -o vi), simply outputting this sequence to the screen: printf '\\e]0;iopen -a Calculator\\a\\e[21t\\e]0;:accept-line\\a\\e[21t' Results in it opening calculator (on macOS): All released versions of Zsh have a behaviour that they default the keymap to vi if the $EDITOR or $VISUAL environment variables contain \"vi\". So this is quite a common setup for users. This default has been removed after Zsh 5.9, but that is not yet released. Bash with set -o vi: printf '\\e]0;iopen -a Calculator\\a\\e[21t\\e]0;vZZ\\a\\e[21t' Unlike Zsh this setting does have to be enabled by the user, so is likely to be a less common configuration. But is this an RCE? Spoiler: Yes One aspect of this attack that isn't immediately clear is the input goes via your terminal, so it's like you typed it, even if you're connected to a remote system via SSH. If the remote system is compromised, it can decide it isn't interested in your input and make it get buffered, with it probably getting delivered locally. We can demonstrate this with a simple script that stops the shell. In this case I run it as another session of the user, but it could also be run via root on a remote system if the system is compromised. SSH disconnect attack on Ghostty 1.0.0 ▶ The \"disconnect-ghosty\" script used in the demo is below: #!/bin/bash # David Leadbeater, 2024. http://©.st/dgl pid=${1:?$'\\e'\"[GUsage: $0 pid-of-shell\"} tty=\"/dev/$(ps -otty -p$pidtail -1)\" kill -STOP $pid printf '\\e]0;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxiopen -a Calculator\\a\\e[21t\\e[21t\\e]0;:accept-line\\a\\e[21t' > $tty kill -9 $pid Fixes and mitigations Ghostty 1.0.1 is out now, fixing this (by making it configurable and disabling it by default). If for some reason you can't upgrade, the advisory has a workaround where a fixed title will not let an attacker control the value reported back. An alternative is to put the following in your ~/.zshrc: function skip-osc-sequence() { local key while read -sk key && (( $((#key)) != 0x1B && $((#key)) != 0x07 )); do # empty body done if [[ $((#key)) = 27 ]]; then # ^[\\ read -sk key fi } zle -N skip-osc-sequence bindkey '\\e]' skip-osc-sequence This makes Zsh skip over OSC replies rather than treat them as input. This is only a mitigation and you should upgrade as there may still be cases where you could be attacked (e.g. with the remote attack over SSH, careful timing could lead to a \"torn\" read that may mean the local shell doesn't see the start of the OSC sequence). It also doesn't hurt to leave in your config, as it provides defense-in-depth. Or if using bash, put this in ~/.inputrc: \"\\e]\": skip-csi-sequence \"\\e\\\\\": skip-csi-sequence This isn't as complete as the Zsh mitigation, as you could still be blindly tricked to press Enter and run an unexpected command, but it works for this particular issue in Ghostty. Please don't see this post as any kind of attack against Ghostty, remember it just had a 1.0 release. I've been using it and I'm writing this very post in it. The \"terminal inspector\" is very nice for people interested in diving into the internals of their terminal. Thanks to Mitchell for the quick fix. If you want to see more on this subject you might like my Microsoft BlueHat talk from 2023, or my longer in depth post on various issues with terminals. 31st December 2024",
    "commentLink": "https://news.ycombinator.com/item?id=42562743",
    "commentBody": "Déjà vu: Ghostly CVEs in my terminal title (dgl.cx)185 points by dgl 22 hours agohidepastfavorite46 comments mitchellh 16 hours agoJust cross posting my lobsters post: I want to say thanks to @dgl for reporting this, and this article is also expertly written. I also have to say for me personally its quite embarrassing because as I told @dgl when he reported this: I’ve studied his work before and made it a note to test Ghostty against his past discoveries prior to release. And I… quite simply forgot. I didn’t make an issue for myself so it slipped away and here I am with egg on my face. I’m sorry! But, I appreciate @dgl for the security report, reviewing the fix, and continuing to be an active user of the terminal. I also shared with him some broader thoughts on terminal security in general. Addressing terminal security in a more fundamental way is one of the first proposals I want to make regarding terminal innovation. My thinking is still too early and under-researched for a formal proposal. But my general feeling having built a terminal over the past 2 years is that the security surrounding escape sequences is fundamentally flawed and poking one by one at these sequences to try to make them individually safe doesn’t feel like the right long term solution. The surface area is too large and the complexity of some of the newer sequences too high (i.e. Kitty Graphics) to be confident in secure implementations. DoS is far too easy with terminals (Ghostty has a handful of known DoS attacks, but so does pretty much every other terminal I know of). And some legacy sequences are just kind of shocking to have immediately available. For example, DECCOLM is available in macOS Terminal.app. If you issue a DECCOLM (CSI ? 3 h I believe), Terminal.app will physically resize the window and lock it to 132 columns. You can very easily crash Terminal.app at anytime by sending enough of these (a DoS attack). There are many more. Part of my thinking is trying to design a mechanism that can effectively create something akin to either CPU protection rings or OpenBSD’s pledge() syscall. Whatever the mechanism, the general idea is: reduction of capability. For example, it makes sense for a shell to be extremely powerful. It’s literally a code execution device. However, it doesn’t make much sense for cat to be able to execute arbitrary escape sequences (which it does today in any terminal). Whether it is the shell or cat itself, something should be able to tell a terminal: “hey, only execute some subset of escape sequences (or none at all).” For cat, that might be none or perhaps just SGR sequences (styles, colors, etc.). The insecurity of cat-ing or tail-ing any form of data that could contain user-generated data is hopefully well known at this point… As I said before, this thinking is all still very raw and I don’t have anything concrete to proposal. I want to share this because I want folks to know that I’m thinking about it, and perhaps others may be interested in thinking about it with me… if so, please contact me. I’ve already shared this line of thinking with @dgl as well. reply aumerle 16 hours agoparentYou proposal does not address this issue since shells would still need full privileges. This entire class of exploits (query responses with user controlled data leading to shells executing commands) would be removed if shells just moved to using the kitty keyboard protocol with all key events represented as escape codes and implemented a full escape code parser for data received form the terminal. You cannot embed an escape code inside another, or while technically you can, it is trivial to implement a security policy of disallowing these in both terminals and shells. Then barring implementation bugs in the escape code parser (which can easily be shipped as a standalone native code library) you dont have this entire class of issues and the associated one that the bracketed paste hack was created to address. reply mitchellh 15 hours agorootparentI believe it could. A shell could reduce capability by default for all executed shell scripts (file or inline on the prompt) and require opt in to not do this. Something akin to a umask of sorts. It’d break exceedingly few real scripts. (Hand waving a lot here with the “opt in” mechanism to avoid that being scripted but I have ideas) Also note my thoughts (very much not even close to being a proposal) are very raw. Inviting this kind of discussion is exactly what I hope to do :) Reduction of capability in general is not intended to address all class of security issue. For example you’d still want unsafe paste detection (to detect newlines or attempted bracketed paste escapes) on a prompt line. But I think having a mechanism to eliminate the possibility of entire class of actions without wholesale disabling them in the terminal emulator is a desirable property. Right now a lot of these features are mostly on/off. reply gigatexal 12 hours agorootparentWhatever you all do please continue the fight. I love love love the ergonomics of the terminal. It feels like a super power for me and is crucial to my work flow. If someone told my CTO that terminals are an attack vector they might do something silly and ban them — might sound crazy but management has gone crazier things. reply aumerle 15 hours agorootparentprevSo if I am to understand your proposal more concretely it is something like implement an escape code that the shell can use to turn off all other escape codes (presumably with some kind of listing mechanism) and then have the shell do that before launching any third party script/program/function? How would the shell know which escape codes the program it is running needs? I can, kind of, see the utility of a pledge() type system within a single program, but in a shell, whose whole job is basically running programs it knows nothing about beyond their name? How would that work? reply mitchellh 15 hours agorootparentSorry to be a broken record but I have no “proposal” whatsoever. It’s more of an information sharing and seeking discussion. I don’t know what I want yet except that I think we can do better. The end result could be that it’s all a terrible idea and that’s okay, but hopefully something comes out of it eventually. Id love to continue this discussion, but I think HN threads probably aren’t the right medium. If you’d like I can email you or we can schedule a call. I’m not trying to seek privacy, I’d be happy for any to be recorded or shared publicly, I just don’t find HN to be a good place if you really want to dive into this! reply aumerle 15 hours agorootparentOf course, I didn't mean to put you in a spot. We can always continue this later once your thoughts have matured. Sadly I have an extremely full schedule so I dont think I have the badwidth to noodle on this at this stage but if and when you have something more concrete please do post it somewhere public and I will try to contribute to the discussion. reply mitchellh 15 hours agorootparentAppreciate it!To wit, ghostty does not actually have a fast release velocity compared to its peers. Sigh. I’ll explain again but seems like you don’t want to listen either ;) My original comment didn’t have to spark a comparison war. If I walk past a new flower shop in my village and remark at how beautiful the roses look, it isn’t criticizing all other flower shops and or saying this one has the best roses. Maybe I even already know a shop with better roses. It’s just a comment, not a declaration of superiority. It actually doesn’t matter if another shop sells better roses, it doesn’t make the initial comment wrong, worthless and worth shooting down. Now let’s say 5 days after the shop opens, they leave the doors and till unlocked and the local news posts an article about it on the front page. The shop owner reacts quickly to improve security. A little embarrassing perhaps. So seeing this, I think to say something encouraging instead of piling on negativity, because new businesses can be good for people but also face a lot of challenges. Basically, something called empathy :) reply aumerle 10 hours agorootparentnext [7 more] [flagged] sevg 10 hours agorootparent> And I didn't feel the need to resort to personally attacking you to try to make my point. Something you should learn from. Coming from the person repeatedly calling me a shill and a liar? Don’t make me laugh! It seems you still don’t get it. You are the one that has turned this into ghostty vs kitty, not me. I suspect you understand the flower shop analogy but are just ignoring it because it doesn’t help your argument. At no point have I said that ghostty is better than kitty ;) I’m still using kitty as we speak, so my usual flower shop hasn’t changed. It’s kind of sad that you are so upset that someone on the internet could possibly be impressed with ghostty’s 1.0.1 release notes. I have little interest in your take on it, because it is needlessly trolling on an innocent comment. Possibly you should take note from the downvotes and flags on your comments here. No doubt you will blame the army of ghostty shills who have organised themselves into a globally coordinated voting ring. As for me, I take it as a signal that what you have to say on this thread isn’t particularly interesting or worth replying to. reply aumerle 9 hours agorootparentnext [6 more] [flagged] sevg 8 hours agorootparent> to refute yours Oh boy, you still don’t get it! The fact you saw it as something that needed refuting really says a lot more about you than anything else. It’s actually ok to let positive comments about other terminals go unrefuted and just get on with your life ;) But seemingly you can’t let it go. By the way, nobody is choosing ghostty over kitty just because of the release notes for 1.0.1, so no need to fret! If I was shilling I’d have picked something more persuasive ;) For anyone else following this disaster of a subthread, I’ve now realised “aumerle” is actually Kovid Goyal, the undisclaimed author of Kitty. If I had to speculate, seems he’s just on edge that there’s a new kid on the block gaining popularity. A story as old as time! reply aumerle 7 hours agorootparentnext [5 more] [flagged] sevg 7 hours agorootparent> Still waiting for you to admit you were wrong in the first place. It’s actually incredible you still don’t see. It’s impossible for my comment to be wrong, because I get to decide what I’m impressed by. Just because you wrote a terminal, doesn’t mean you suddenly have authority to tell others what they should or shouldn’t be impressed by. You have no such authority :) If I’d claimed that ghostty’s release velocity is better than kitty’s (or vice versa), then you’d have a point. But I didn’t ;) > You have provided increasingly desperate personal attacks. Actually, I haven’t. I also don’t have skin in the game and have no reason to be desperate. I haven’t devoted a significant amount of my time to writing a terminal, for example. And I don’t even use ghostty (yet). Downvotes on your comments are still ticking up, as are upvotes on mine. I know it’s not kosher to talk about votes, but I don’t know what other signal you need to maybe take a break for a bit and calm down :) reply aumerle 5 hours agorootparentnext [4 more] [flagged] sevg 5 hours agorootparent> \"It's impossible for me to be wrong\" that right there tells us all we need to know about you. Actually, it doesn’t, as it’s very clear you still don’t understand what I’m saying XD If I was comparing ghostty to kitty, I can obviously be wrong. But I was just saying I’m impressed, which literally can’t be wrong unless I’m lying about being impressed. It’s like if I look across a lake and say “what a lovely view”. And someone comes by and says “no there’s a much better one where I was standing, you should take back what you said or provide evidence to your claim”. Don’t you see how silly this is ;) > Do you actually believe ghostty has a development velocity faster than its peers, specifically, kitty and WezTerm? Yes or no. You said you didn’t give a “rat’s ass” about my opinion ;) This is where you’ve gone wrong. It don’t know or care whether ghostty has a development velocity faster than kitty. I didn’t say it did. Nobody in this sub-thread has said anything (good or bad) about kitty. The only person interested in ghostty vs kitty in this sub-thread is you. So the question you’re demanding that I answer is like demanding I prove that the view I was impressed with across the lake is better than the view you had. When it really doesn’t matter which view was better. It’s possible to be impressed by something in isolation, without it being turned into a competition. I’m not answering your question because I have no part to play in the 1-person argument you’re having with yourself about whose development velocity is faster, when nobody was making the comparison to begin with (except you). I feel like I’m wasting my breath though, but at least I can say I tried! And I suspect HN comment depth limits may kick in soon. So I’ll bow out now and give you the pleasure of the last word, since you certainly seem to need it more than me ;) 2 more throwawaykitten 11 hours agorootparentprevit's good practice to note when you're the maintainer :) still if you insist on direct comparison, ghostty addressed 5x as many issues in half the time reply rurban 13 hours agorootparentprevActually usable now, or still entirely insecure? reply MrLeap 2 hours agoprevThis is fascinating. I was just playing around with this pretty printing library in .net and I wondered how security critical such a thing was, and whether or not it could be trusted. https://spectreconsole.net/ Things like this make me a little more cautious about standard out in general! More research to do. reply wslh 3 hours agoprev [–] It is worth mentioning my prior report on Bugtraq from 1999 [1], which predates that Bugtraq 2003 report. I recall there were earlier reports elsewhere, though I'm uncertain if I made my exploit publicly available. What stood out about this type of exploit was that it could be triggered simply by a banner in FTP/Telnet/SSH. [1] \"Kvt bug\":reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ghostty, a new terminal emulator, had a security vulnerability similar to one from 2003, allowing ASCII escape characters to execute commands like opening applications. - The issue was notably problematic with Zsh and Bash in vi mode, but Ghostty 1.0.1 has resolved this by disabling the feature by default. - Despite the security flaw, Ghostty is commended for its features, and the developer promptly addressed the issue, providing fixes and workarounds for users."
    ],
    "commentSummary": [
      "The discussion centers on terminal security vulnerabilities, particularly those related to escape sequences, and explores ways to mitigate these risks. - Suggestions for enhancing terminal security include adopting systems akin to CPU protection rings or OpenBSD’s pledge() syscall, which limit capabilities to prevent exploits. - Participants acknowledge the challenge of balancing security with functionality in terminal applications and express interest in further exploration and collaboration to improve security practices."
    ],
    "points": 185,
    "commentCount": 46,
    "retryCount": 0,
    "time": 1735688876
  },
  {
    "id": 42563534,
    "title": "Large Concept Models: Language modeling in a sentence representation space",
    "originLink": "https://github.com/facebookresearch/large_concept_model",
    "originBody": "Large Concept Models Language Modeling in a Sentence Representation Space [Blog] [Paper] This repository provides the official implementations and experiments for Large Concept Models (LCM). The LCM operates on an explicit higher-level semantic representation, which we name a \"concept\". Concepts are language- and modality-agnostic and represent a higher level idea. In this work, a concept corresponds to a sentence, and we use the SONAR embedding space, which supports up to 200 languages in text and 57 languages in speech. See the list of supported languages here. Approach The LCM is a sequence-to-sequence model in the concepts space trained to perform auto-regressive sentence prediction. We explore multiple approaches: MSE regression (base_lcm in this code). Variants of diffusion-based generation (we include two_tower_diffusion_lcm in this release). Models operating in a quantized SONAR space (coming soon). These explorations are performed using 1.6B parameter models and training data in the order of 1.3T tokens. We include in this repository recipes to reproduce the training and finetuning of 1.6B MSE LCM and Two-tower diffusion LCM. See instructions below. Installing Using UV The LCM repository relies on fairseq2. If you have uv installed on your system, you can install a virtual environment with all the necessary packages by running the following commands: uv sync --extra cpu --extra eval --extra data You can also use uv run to run the demo commands with the correct environment. Note that we only provide requirements for cpu dependencies, if you want to use GPU support, you will have to choose the variants of torch and fairseq2 that work for your system. For example for torch 2.5.1 with cuda 1.21, You would do something like: uv pip install torch==2.5.1 --extra-index-url https://download.pytorch.org/whl/cu121 --upgrade uv pip install fairseq2==v0.3.0rc1 --pre --extra-index-url https://fair.pkg.atmeta.com/fairseq2/whl/rc/pt2.5.1/cu121 --upgrade Check fairseq2 variants for possible variants. Note that LCM currently relies on the release candidate for fairseq2 0.3.0 rc1. Using pip To install with pip, the commands are very similar, but you will have to manage your own environment and make sure to install fairseq2 manually first. For instance, for a cpu install. pip install --upgrade pip pip install fairseq2==v0.3.0rc1 --pre --extra-index-url https://fair.pkg.atmeta.com/fairseq2/whl/rc/pt2.5.1/cpu pip install -e \".[data,eval]\" If fairseq2 does not provide a build for your machine, check the readme of that project to build it locally. Usage Note If using uv prefix all commands with uv run to use the environment created by default in .venv, e.g., uv run torchrun --standalone. Alternatively, you can activate the environment once and for all with source .venv/bin/activate. Preparing data The LCM can be trained and evaluated using textual data split in sentences and embedded with SONAR. We provide a sample processing pipeline that can be used to prepare such training data, you can run it with: uv run --extra data scripts/prepare_wikipedia.py /output/dir/for/the/data This pipeline shows how to get a dataset from huggingface and process it with SONAR and SaT. Check out the file for more details on processing your own data. While the script provides an example pulling data from huggingface, we also provide APIs to process jsonl, parquet and CSV. Datacards The trainer described below relies on datacards configuring the datasets. These datacards are yaml files with pointers to the dataset files (locally or on s3) and information on its schema. We provide some sample datacards in lcm/datacards/datacards.yaml. Once you have processed some data, you can update the datacards with your paths. Fitting a normalizer To fit a new embedding space normalizer on a given weighted mixture of datasets one can use the following command : python scripts/fit_embedding_normalizer.py --ds dataset1:4 dataset2:1 dataset3:10 --save_path \"path/to/new/normalizer.pt\" --max_nb_samples 1000000 Here, dataset1, dataset2, dataset3 are the names of datasets declared in the datacards as shown above and (4, 1, 10) their respective relative weights. The resulting normalizer can be next declared as a model as shown in lcm/cards/sonar_normalizer.yaml and referenced in all model training configs. Pre-training models Base MSE LCM To train an MSE LCM, we will use one of the following commands: Option 1. Training with SLURM using submitit via stopes's launcher: python -m lcm.train \\ +pretrain=mse \\ ++trainer.output_dir=\"checkpoints/mse_lcm\" \\ ++trainer.experiment_name=training_mse_lcm \\ With this command, we will submit a slurm job named training_mse_lcm with the recipe's requirements, in this case: requirements: nodes: 4 tasks_per_node: 8 gpus_per_node: 8 cpus_per_task: 32 mem_gb: 0 timeout_min: 10000 You can override the job's requirements like the timeout limit and the launcher's slurm partition with: python -m lcm.train \\ +pretrain=mse \\ ++trainer.output_dir=\"checkpoints/mse_lcm\" \\ ++trainer.experiment_name=training_mse_lcm \\ ++trainer.requirements.timeout_min=100 \\ ++trainer.requirements.cpus_per_task=8 \\ ++launcher.partition=$partition_name Option 2. Training locally with torchrun (e.g. using only 2 GPUs) with a smaller batch size (overriding ++trainer.data_loading_config.max_tokens=1000): CUDA_VISIBLE_DEVICES=0,1 torchrun --standalone --nnodes=1 --nproc-per-node=2 \\ -m lcm.train launcher=standalone \\ +pretrain=mse \\ ++trainer.data_loading_config.max_tokens=1000 \\ ++trainer.output_dir=\"checkpoints/mse_lcm\" \\ +trainer.use_submitit=false \\ Important Since we're changing the number of GPUs required by the recipe, this will not reproduce the experimental setup of the paper. The checkpoints directory checkpoints/mse_lcm will be structured as: . ├── checkpoints │ ├── step_2000 │ ├── ... │ └── step_250000 ├── config_logs ├── executor_logs ├── model_card.yaml ├── tb # tensorboard logs └── wandb # W&B logs Note that W&B logging is skipped unless wandb is available. You can install wandb with uv pip install wandb. W&B arguments can be changed by overriding Hydra config values in the recipe: ++trainer.wandb_project=$project_name ++trainer.wandb_run_name=$run_name Two-tower diffusion LCM Similar to the base MSE LCM we can submit a training job following the recipe in ./recipes/train/pretrain/two_tower.yaml via: python -m lcm.train \\ +pretrain=two_tower \\ ++trainer.output_dir=\"checkpoints/two_tower_lcm\" \\ ++trainer.experiment_name=training_two_tower_lcm \\ Tip To understand the different ingredients of training recipes, check this README. Finetuning models To finetune the previously pre-trained two-tower diffusion LCM on supervised data, follow these steps: Step 1. Register the pre-trained checkpoint as a fairseq2 asset. You can finetune the final checkpoint with the card checkpoints/two_tower_lcm/model_card.yaml or any checkpoint after a specific number of training steps, e.g., checkpoints/two_tower_lcm/checkpoints/step_2000/model_card.yaml. To register the selected checkpoint, copy the automatically created yaml file to ./lcm/cards/mycards.yaml and rename the model to replace the default on_the_fly_lcm. ./lcm/cards/mycards.yaml will look like: __source__: inproc checkpoint: file://path_to/large_concept_model/checkpoints/two_tower_lcm/checkpoints/step_2000/model.pt model_arch: two_tower_diffusion_lcm_1_6B model_family: two_tower_diffusion_lcm name: my_pretrained_two_tower For more on how to manage fairseq2 assets, see documentation. Step 2. Launch a finetuning job pointing to the model to finetune, in this instance my_pretrained_two_tower: CUDA_VISIBLE_DEVICES=0,1 torchrun --standalone --nnodes=1 --nproc-per-node=2 \\ -m lcm.train launcher=standalone \\ +finetune=two_tower \\ ++trainer.output_dir=\"checkpoints/finetune_two_tower_lcm\" \\ ++trainer.data_loading_config.max_tokens=1000 \\ +trainer.use_submitit=false \\ ++trainer.model_config_or_name=my_pretrained_two_tower or python -m lcm.train \\ +finetune=two_tower \\ ++trainer.output_dir=\"checkpoints/finetune_two_tower_lcm\" \\ ++trainer.experiment_name=finetune_two_tower_lcm \\ ++trainer.model_config_or_name=my_pretrained_two_tower Similarly, to finetune an MSE LCM, follow the same instructions for registering a pre-trained checkpoint and submit a finetuning job with the appropriate recipe (./recipes/train/finetune/mse.yaml) via: python -m lcm.train \\ +finetune=mse \\ ++trainer.output_dir=\"checkpoints/finetune_mse_lcm\" \\ ++trainer.experiment_name=finetune_mse_lcm \\ ++trainer.model_config_or_name=my_pretrained_mse_lcm Evaluating models Note For advanced evaluation (benchmarking different tasks, comparing results with LLMs, etc.) , check the evaluation documentation. Step 0. Download NLTK data required for evaluating ROUGE: python -m nltk.downloader punkt_tab Step 1. Generate and score outputs of a model either by pointing to its model_card yaml file or after registering it as a fairseq2 asset (the same way we registerd my_pretrained_two_tower): model_card=./checkpoints/finetune_two_tower_lcm/checkpoints/step_1000/model_card.yaml OUTPUT_DIR=evaluation_outputs/two_tower torchrun --standalone --nnodes=1 --nproc-per-node=1 -m lcm.evaluation \\ --predictor two_tower_diffusion_lcm \\ --show_progress true \\ --data_loading.max_samples 100 \\ --model_card ${model_card} \\ --launcher standalone \\ --dataset.source_suffix_text '[MODEL]:' \\ --tasks finetuning_data_lcm.validation \\ --task_args '{\"max_gen_len\": 10, \"eos_config\": {\"text\": \"End of text.\"}}' \\ --data_loading.batch_size 4 --generator_batch_size 4 \\ --dump_dir ${OUTPUT_DIR} \\ --inference_timesteps 40 \\ --initial_noise_scale 0.6 \\ --guidance_scale 3 \\ --guidance_rescale 0.7 where in the example we are evaluating 100 samples only (--data_loading.max_samples 100) and limiting the model output length to 10 sentences (--task_args '{\"max_gen_len\": 10}'). Outputs dumped in ./evaluation_outputs/two_tower will be structured as: . ├── metadata.jsonl ├── metrics.eval.jsonl ├── raw_results ├── results └── tb where metrics.eval.jsonl contains corpus-level scores. To evaluate an MSE LCM, we use the associated predictor (base_lcm) and evaluate with: model_card=./checkpoints/finetune_mse_lcm/checkpoints/step_1000/model_card.yaml OUTPUT_DIR=evaluation_outputs/mse_lcm torchrun --standalone --nnodes=1 --nproc-per-node=1 -m lcm.evaluation \\ --predictor base_lcm --sample_latent_variable False \\ --show_progress true \\ --data_loading.max_samples 100 \\ --model_card ${model_card} \\ --launcher standalone \\ --dataset.source_suffix_text '[MODEL]:' \\ --tasks finetuning_data_lcm.validation \\ --task_args '{\"max_gen_len\": 10, \"eos_config\": {\"text\": \"End of text.\"}}' \\ --data_loading.batch_size 4 --generator_batch_size 4 \\ --dump_dir ${OUTPUT_DIR} \\ Note that in this example, we only show how to evaluate the LCM on the same finetuning dataset (validation split). To evaluate in a downstream task, and compare results with the LLM, refer to the Evaluation documentation. Contributing See the CONTRIBUTING file for how to help out. Citation If you use this codebase, please cite: @article{lcm2024, author = {{LCM team}, Lo\\\"{i}c Barrault, Paul-Ambroise Duquenne, Maha Elbayad, Artyom Kozhevnikov, Belen Alastruey, Pierre Andrews, Mariano Coria, Guillaume Couairon, Marta R. Costa-juss\\`{a}, David Dale, Hady Elsahar, Kevin Heffernan, Jo\\~{a}o Maria Janeiro, Tuan Tran, Christophe Ropers, Eduardo Sánchez, Robin San Roman, Alexandre Mourachko, Safiyyah Saleem, Holger Schwenk}, title = {{Large Concept Models}: Language Modeling in a Sentence Representation Space}, publisher = {arXiv}, year = {2024}, url = {https://arxiv.org/abs/2412.08821}, } License This code is released under the MIT license (see LICENSE).",
    "commentLink": "https://news.ycombinator.com/item?id=42563534",
    "commentBody": "Large Concept Models: Language modeling in a sentence representation space (github.com/facebookresearch)151 points by batata_frita 19 hours agohidepastfavorite53 comments nutanc 4 hours agoThis maps a little to what we are doing research on what we are calling as shape of stories[1]. We can clearly see in 2D space itself how different \"concepts\" are explored. Using the shape of stories for semantic chunking we can clearly see in multiple articles how we can chunk by \"concepts\". [2] Now we are trying to see if we can just use these chunks and train a next \"chunk\" predictor instead of a next word predictor. In the paper, they take a sentence to mean a concept. We believe that a \"semantic chunk\" is better suited for a concept instead of a sentence. [1] https://gpt3experiments.substack.com/p/the-shape-of-stories-... [2]https://gpt3experiments.substack.com/p/a-new-chunking-approa... reply Lerc 1 hour agoparentCan you spot conceptually similar stories by their shape? For instance what is the shape of the ugly duckling compared to Rudolf the red nosed reindeer. They are essentially the same story, so presumably on some dimension you should be able to spot them in a group of unrelated stories. reply rxm 2 hours agoprevWhat used to be feature engineering a decade or more ago now seems to have shifted to developing distributed representations. LLMs use word tokens (for words or the entities in images). But there are many more. The 3D Fields (or whatever they have evolved to) developed by Fei-Fei Li's group represent visual information in a way better suited for geometrical tasks. Wav2Vec, the convolutional features for YOLO and friends, and these sentence representations are other examples. I would love to read a review of this circle of ideas. reply stravant 14 hours agoprevThis feels like a failure to learn the bitter lesson: You're just taking the translation to concepts that the LLM is certainly already doing and trying to make it explicitly forced. reply mdp2021 13 hours agoparentIt is explicitly stated in the paper that > One may argue that LLMs are implicitly learning a hierarchical representation, but we stipulate that models with an explicit hierarchical architecture are better suited to create coherent long-form output And the problem remains that (text surrounding the above): > Despite the undeniable success of LLMs and continued progress, all current LLMs miss a crucial characteristic of human intelligence: explicit reasoning and planning at multiple levels of abstraction. The human brain does not operate at the word level only. We usually have a top-down process to solve a complex task or compose a long document: we first plan at a higher level the overall structure, and then step-by-step, add details at lower levels of abstraction. [...] Imagine a researcher giving a fifteen-minute talk. In such a situation, researchers do not usually prepare detailed speeches by writing out every single word they will pronounce. Instead, they outline a flow of higher-level ideas they want to communicate. Should they give the same talk multiple times, the actual words being spoken may differ, the talk could even be given in different languages, but the flow of higher-level abstract ideas will remain the same. Similarly, when writing a research paper or essay on a specific topic, humans usually start by preparing an outline that structures the whole document into sections, which they then refine iteratively. Humans also detect and remember dependencies between the different parts of a longer document at an abstract level. If we expand on our previous research writing example, keeping track of dependencies means that we need to provide results for each of the experiment mentioned in the introduction. Finally, when processing and analyzing information, humans rarely consider every single word in a large document. Instead, we use a hierarchical approach: we remember which part of a long document we should search to find a specific piece of information. To the best of our knowledge, this explicit hierarchical structure of information processing and generation, at an abstract level, independent of any instantiation in a particular language or modality, cannot be found in any of the current LLMs reply motoboi 9 hours agorootparentI suppose humans need high level concepts because we can only hold 7[] things in working memory. Computers don’t have that limitation. Also, humans cannot iterate over thousands of possibilities in a second, like computers do. And finally, animal brains are severely limited by heat dissipation and energy input flow. Based on that, artificial intelligence may arise from unexpected simple strategies, given the fundamental differences in scale and structure from animal brains. - where 7 is whatever number is the correct number nowadays. reply dr_dshiv 8 hours agorootparentprevI just don’t understand that — I thought deep neural nets were inherently hierarchical. Or at least emergently hierarchical? reply mdp2021 6 hours agorootparentNeural Nets can be made to be hierarchical - I would say a most notable example is the Convolutional Neural Network so successfully promoted by Yann Le Cun. But the issue with the LLMs architectures in place is with the idea of \"predicting the next token\", so strident with the exercise of intelligence - where we search instead for the \"neighbouring fitting ideas\". So, \"hierarchical\" in this context is there to express that it is typical of natural intelligence to refine an idea - formulating an hypothesis and improving its form (hence its expression) step after step of pondering. The issue of transparency in current LLMs, and the idea of \"predicting the next token\", do not help in having the idea of typical natural intelligence mechanism and the tentative interpretation of LLM internals match. reply nightski 5 hours agorootparentIs that true? There are many attention/mlp layers stacked on top of each other. Higher level layers aren't performing attention on input tokens, but instead on the output of the previous layer. reply mdp2021 4 hours agorootparent> Is that true Well, if you are referring to «The issue of transparency in current LLMs», I have not read an essay that explains satisfactorily the inner process and world modelling inside LLMs. Some pieces say (guess?) that the engine has no idea what the whole concept in the reply would be before outputting all the tokens, others swear it seems impossible it has no such idea before formulation... reply throwawaymaths 4 hours agorootparentprevthere is a way that \"predicting the next token\" is ~append-only turing machine. Obviously the tokens we're using might be suboptimal for whatever goalpost \"agi\" is at any given time, but the structure/strategies of LLMs is probably not far from a really good one, modulo refactoring for efficiency like MAMBA (but still doing token stream prediction, esp. during inference) reply anon373839 13 hours agoparentprevThe bitter lesson isn’t a law of nature, though. And as GPT-style LLMs appear to be at the foot of a scaling wall, I personally think inductive bias is due for a comeback. reply Der_Einzige 13 hours agorootparentEveryone keeps claiming this but we have zero evidence of any kind of scaling wall what-so-ever. Oh you mean data? Synthetic Data, Agents, and Digitization solve that. reply anon373839 13 hours agorootparentI disagree, but I also wasn’t referring to the exhaustion of training materials. I am referring to the fact that exponentially more compute is required to achieve linear gains in performance. At some point, it just won’t be feasible to do $50B training runs, you know? reply throw5959 12 hours agorootparent50B still seems reasonable compared to the revenue of the Big AI companies. reply mentalgear 11 hours agorootparentwhat revenues? If by big AI companies you mean llm service providers (OpenAI, ...), their revenues are far from high or profitable. https://www.cnbc.com/2024/09/27/openai-sees-5-billion-loss-t... Maybe Nvidia, but they are a chip / hardware maker first. And even for them 50B training run with no exponential gains seems unreasonable. Better to optimize the architecture / approach first, which also is what most companies are doing now before scaling out. reply UltraSane 2 hours agorootparentprevThere seems to be a affordable scaling wall. reply cubefox 12 hours agorootparentprevThere were multiple reports confirming that OpenAI's Orion (planned to be GPT-5) yielded unexpectedly weak results. reply pegasus 3 hours agorootparentAnd not just OpenAI is facing this problem. Anthropic and Google as well. reply UltraSane 2 hours agorootparentprevAnd costs $500 million per training run. reply Der_Einzige 1 hour agorootparentprevSo Deepseek V3 did nothing to show you how wrong this take is? reply Jensson 10 hours agoparentprev> You're just taking the translation to concepts that the LLM is certainly already doing and trying to make it explicitly forced. That is what tokens are doing in the first place though, and you get better results with tokens instead of letters. reply mdp2021 10 hours agorootparentWell, individual letters in these languages in use* do not convey specific meaning, while individual tokens do - so, you cannot really construe a ladder that would go from letter to token, then from token to sentence. This said, to research whether the search for concepts (in the solutions space) works better than the search for tokens seems absolutely dutiful, in absence of a solid theory that showed otherwise. (*Sounds convey their own meaning e.g. in proto-Indo-European according to some interpretations, but that becomes too remote in the current descendants - you cannot reconstruct the implicit sound-token in words directly in English, just from the spelling.) reply IanCal 10 hours agorootparentprevIs that true? I thought there was a desire to move towards byte level work rather than tokens, and that the benefits of tokens was more that you are reducing the context size for the same input. reply fngjdflmdflg 4 hours agorootparent>there was a desire to move towards byte level work rather than tokens Yeah, latest work on this is from Meta a last month.[0] It showed good results. [0] https://ai.meta.com/research/publications/byte-latent-transf... (https://news.ycombinator.com/item?id=42415122) reply mdp2021 14 hours agoparentprevThat should be proven. The two approaches - predicting tokens vs predicting \"sentences\" - should be compared to see how much their output differ in terms of quality. Edit2: ...and both (and their variants) be compared to other ideas such as \"multi-token prediction\"... Edit: or, appropriateness of the approach should be demonstrated after acquired \"transparency\" of how the LLMs effectively internally work. I am not aware of studies that make the inner workings of LLMs adequately clear. Edit3: Substantially, the architecture should be as solid as possible (and results should reflect that). reply blackeyeblitzar 7 hours agorootparentIsn’t “sentence prediction” roughly the same as multi token prediction of sufficient length? In the end are we just talking about a change to hyper parameters or maybe a new hyper parameter that controls the granularity of “prediction length”? reply mdp2021 6 hours agorootparent> multi token prediction of sufficient length Is multi token prediction the same as predicting the embedding of a complex token (the articulation of those input tokens in a sentence)? reply blackeyeblitzar 3 hours agorootparentTo be honest I don’t know. Maybe the only way to know is to build and measure all these variations. reply macawfish 6 hours agoparentprevAt a performance boost of 10-100x :) reply attentionmech 9 hours agoprevI like the idea of \"concept\" .. you can represent a concept with language, visual etc. but it isn't any of those. Those are symbols used to communicate a concept or give representation to it but concepts are just connections between other concepts at the core. The closest things i feel to this is categories in category theory. reply layer8 5 hours agoparentConcepts need to be linked to reality somehow in order to carry any meaning. They are thus not just relations between themselves. reply dr_dshiv 2 hours agoparentprevPlatonic forms? reply attentionmech 10 minutes agorootparentinteresting concept they are. reply mdp2021 15 hours agoprev> Current best practice for large scale language modeling is to operate at the token level, i.e. to learn to predict the next tokens given a sequence of preceding tokens. There is a large body of research on improvements of LLMs, but most works concentrate on incremental changes and do not question the main underlying architecture. In this paper, we have proposed a new architecture, For some 2024 may have ended badly, but reading the lines above shines a great light of hope for the new year. reply inshard 18 hours agoprevThis is interesting. I wonder if such a project could dive into lower-level concepts, those akin to prime numbers. The atoms from which all other concepts are built. reply upghost 8 hours agoprevAside from the using the word \"concept\" instead of \"language\" I don't see how this is different than an LLM. It's still doing next token prediction. This is like in D&D where you have two swords with wildly different flavor text but ultimately they both do 1d6+1 damage. What am I missing -- aside from the marketing? Is there something architecturally different or what? Looks like regular autoregressive sequence transformer to me. reply tantalor 7 hours agoparent(Guessing here) It does tokenization and prediction for a whole sentence, not fragments of words. I like this idea because that's how humans think. We mentally formulate a whole sentence, then say it. People who don't do this speak in run-ons and word salad. reply botanical76 33 minutes agorootparentI would be interested to know how many people do formulate a whole sentence before saying it. \"Think before you speak\" as they say. I feel I do not have the cognitive window or processing speed to do this; instead, I formulate a concept of how I would like to respond abstractly, and then think of and say phrases of several words one at a time until the sentence ends itself. The latter process leans heavily on some kind of next word anticipation. reply upghost 7 hours agorootparentprevoh interesting. concepts as tokens. Yeah I'd buy that. They do something similar with transformers in robotics, except they use tokens as actions instead of word chunks. Good eye. reply mdp2021 6 hours agoparentprev> something architecturally different An embedding space engine accepting sentences (SONAR) fit in so that the tokens of this architecture are complex sets of the tokens of past architectures. reply benreesman 17 hours agoprevBetween this and learned patches and ModernBERT and DeepSeek? I think it’s time to read up. reply YeGoblynQueenne 9 hours agoprevFrom the paper: >> In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a “concept”. I wonder if the many authors of the paper know that what they call \"concept\" is what all of machine learning and AI has also called a \"concept\" for many decades, and not a new thing that they have just named from scratch. For instance, classes of \"concepts\" are the target of learning in Leslie Valiant's \"A Theory of the Learnable\", the paper that introduced Probably Approximately Correct Learning (PAC-Learning). Quoting from its abstract: ABSTRACT: Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learned using it in a reasonable (polynomial) number of steps. Although inherent algorithmic complexity appears to set serious limits to the range of concepts that can be learned, we show that there are some important nontrivial classes of propositional concepts that can be learned in a realistic sense From: https://web.mit.edu/6.435/www/Valiant84.pdf Or take this Introduction to Chapter 2 in Tom Mitchell's \"Machine Learning\" (the original ML textbook, published 1997): This chapter considers concept learning: acquiring the definition of a general category given a sample of positive and negative training examples of the category. From: https://www.cs.cmu.edu/~tom/mlbook.html (clink link in \"the book\"). I mean I really wonder some times what is going on here. There's been decades of research in AI and machine learning but recently papers look like their authors have landed in an undiscovered country and are having to invent everything from scratch. That's not good. There are pitfalls that all the previous generations have explored thoroughly by falling in them time and again. Those who don't remember those lessons will have to find that out the hard way. reply mdp2021 6 hours agoparentI am not sure that fits the point, YGQ: it seems to me the concept of «concept» in the paper is \"the embedding vector we get in systems like SONAR (which we could use to generalize ordered sets of tokens into more complex ideas)\". That's pretty specific, only marginally related to past handling as mentioned. reply YeGoblynQueenne 5 hours agorootparentThat's only the representation of a concept. Different systems and different approaches will have different representations but that doesn't change the fact of what is being represented. reply mdp2021 4 hours agorootparentBut if the issue is about \"research in AI has had to deal with the concept of \"concept\" since the inception\" (and of course it had to), the contribution in this paper is to try an operational implementation that could bear fruit and possibly fix architectural shortcomings of the mainstream effort. (It is not separate from the context of LLMs.) reply YeGoblynQueenne 3 hours agorootparentRight, but there's been many operationalisations before. That's what's not new. Tome Mitchell's textbook has plenty of examples. Basically all of machine learning is about learning concepts- in practice as well as in theory. That's the whole point. reply lern_too_spel 17 hours agoprev [–] This is like going back to CNNs. Attention is all you need. reply zed1726 16 hours agoparentQuantum states are all one really needs, but it turns out that it's way to computationally expensive to simulate all that just for the purpose of AI applications - so instead we have to go to higher levels of construction. Attention is surely just about on the cusp of what is computationally reasonable which means that it's not all we need, we need more efficient and richer constructions. reply mdp2021 15 hours agorootparentWe do not need quantum states to build (arithmetic) calculators. Nor, very probably, for complex and much more complex calculators. reply katamari-damacy 15 hours agorootparentprevYes, just spray Quantum on it reply chronic4948412 15 hours agorootparent> Yes, just spray Quantum on it Careful, don’t give Sam Altman any ideas. Once OpenAI cannot raise enough capital, he will aim quantum AGI. reply snake_doc 15 hours agoparentprev [–] Attention is just communication? It’s orthogonal to the space of the representation. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The repository offers implementations for Large Concept Models (LCM), which utilize \"concepts\" as a higher-level semantic representation for language modeling.",
      "LCM supports 200 text languages and 57 speech languages using the SONAR embedding space, and is trained for auto-regressive sentence prediction with methods like MSE regression and diffusion-based generation.",
      "The repository provides installation instructions, data preparation, training, finetuning, and evaluation guidelines, and is released under the MIT license, using fairseq2 with UV and pip installation options."
    ],
    "commentSummary": [
      "Large Concept Models focus on representing language in terms of \"concepts\" rather than individual tokens, aiming to enhance semantic chunking and prediction.",
      "This method proposes using higher-level representations to mimic human planning and communication, potentially offering advantages over traditional token-based models.",
      "The approach addresses limitations in current Large Language Model (LLM) architectures by emphasizing explicit hierarchical structures to better replicate human reasoning."
    ],
    "points": 151,
    "commentCount": 53,
    "retryCount": 0,
    "time": 1735699102
  }
]
