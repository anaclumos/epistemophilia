[
  {
    "id": 42763095,
    "title": "It's time to make computing personal again",
    "originLink": "https://www.vintagecomputing.com/index.php/archives/3292/the-pc-is-dead-its-time-to-make-computing-personal-again",
    "originBody": "« Tech Time Capsule: Early 1990s Clip Art Captured an Era The PC is Dead: It’s Time to Make Computing Personal Again January 17th, 2025 by Benj Edwards How surveillance capitalism and DRM turned home tech from friend to foe. For a while—in the ’80s, ’90s, and early 2000s—it felt like nerds were making the world a better place. Now, it feels like the most successful tech companies are making it worse. Internet surveillance, the algorithmic polarization of social media, predatory app stores, and extractive business models have eroded the freedoms the personal computer once promised, effectively ending the PC era for most tech consumers. The “personal computer” was once a radical idea—a computer an individual could own and control completely. The concept emerged in the early 1970s when microprocessors made it economical and practical for a person to own their very own computer, in contrast to the rise of data processing mainframes in the 1950s and 60s. At its core, the PC movement was about a kind of tech liberty—–which I’ll define as the freedom to explore new ideas, control your own creative works, and make mistakes without punishment. The personal computer era bloomed in the late 1970s and continued into the 1980s and 90s. But over the past decade in particular, the Internet and digital rights management (DRM) have been steadily pulling that control away from us and putting it into the hands of huge corporations. We need to take back control of our digital lives and make computing personal again. Don’t get me wrong: I’m not calling the tech industry evil. I’m a huge fan of technology. The industry is full of great people, and this is not a personal attack on anyone. I just think runaway market forces and a handful of poorly-crafted US laws like section 1201 of the DMCA have put all of us onto the wrong track (more on that below). To some extent, tech companies were always predatory. To some extent, all companies are predatory. It’s a matter of degrees. But I believe there’s a fundamental truth that we’ve charted a deeply unhealthy path ahead with consumer technology at the moment. Tech critic Ed Zitron calls this phenomenon “The Rot Economy,” where companies are more obsessed with continuous growth than with providing useful products. “Our economy isn’t one that produces things to be used, but things that increase usage,” Zitron wrote in another piece, bringing focus to ideas I’ve been mulling for the past half-decade. This post started as a 2022 Twitter thread, and I’ve offered to write editorials about my frustrations with increasingly predatory tech business practices since 2020 for my last two employers, but both declined to publish them. I understand why. These are uncomfortable truths to face. But if you love technology like I do, we have to accept what we’re doing wrong if we are going to make it better. Learning From the Past While consumer and computer tech today is more powerful than ever before—and in some ways far more convenient—some of the structural ways we used to interface with technology companies were arguably healthier in the past. For example, which part of the Apple II was predatory? It promised productivity, education, and entertainment. You could program it yourself, repair or expand it without restriction. No subscriptions, no hardware DRM (though there was software copy protection), no tracking. No need for special tools to repair it either. In fact, Apple openly encouraged experimentation. Further, what percentage of your income had to go towards annual software subscriptions on a 20th century Windows PC (like this Sony VAIO)? You bought an application and you owned an indefinite license to use it. If there was an upgrade, you bought that too. And if you liked an older version of the software, you could keep using it without having it vanish in an automatic update. How many Nintendo Entertainment System games sustained themselves with in-app purchases and microtransactions? What more did the console ask of you after you bought a cartridge? Maybe to buy another one later if it was fun? Which part of this TV set kept track of everything you watched and then secretly sold the data to advertisers? Which part of Windows 95 fed you ads without your consent and kept track of everything you did remotely so Microsoft could keep stats on it? And which part of Solitaire demanded a monthly subscription to play? (And which part attempted to record literally everything you do on your computer?) Which part of Amazon.com in 2000 tried to get you to buy millions of no-name counterfeit and dangerous goods propped up by stealth advertising and fake reviews? In its early years, Amazon arguably succeeded through good selection, fair prices on reputable brands, and the wisdom of the crowd through authentic customer reviews. Which part of this Motorola StarTAC cellular phone kept track of your every move and sold the information, behind your back, to private data brokers? And which part included sealed-in batteries that would ruin the entire phone if they went bad? Which part of this BBS used automated algorithms that intentionally fed its users inflammatory and false information to drive engagement for profit? (The users themselves provided the flames.) Which part of Google in the 1990s and early 2000s blanketed its results with deceptive ads or made you add “Reddit” to every search to get good results that weren’t overwhelmed by SEO-seeking filler content? Which part of this VHS tape disappeared or became unplayable if the publisher suddenly decided it didn’t like it anymore—or didn’t want to pay the writers and actors residual fees? The Extractive Model Americans have allowed runaway business models, empowered by tech, to subvert privacy and individual liberty on the road to making money. Our default tech business model has become extractive, like part of a strip-mining operation. Consumers—and now creative works (used for training AI)—are treated as a natural resource to be milked and exploited. The extractive model may end up being self-destructive for the tech industry itself. In the physical world, resource extraction needs limits and regulations to be sustainable. It can be wildly profitable until a resource becomes over-harvested, or the harvesting process corrupts the environment that lets the industry exist in the first place. There’s also the drive to lock consumers into an ecosystem, powered by DRM. You should buy tech products and get direct value fairly, not unleash a secret vampire to track you, manipulate you, and attempt to extract money from you forever. Just because companies have unlocked this “everything as a service” endless money hack does not mean they should do it. And there’s another problem. Very soon, we might be threatening the continuity of history itself with technologies that pollute the historical record with AI-generated noise. It sounds dramatic, but that could eventually undermine the shared cultural bonds that hold cultural groups together. That’s important because history is what makes this type of criticism possible. History is how we know if we’re being abused because we can rely on written records of people who came before (even 15 minutes ago) and make comparisons. If technology takes history away from us, there may be no hope of recovery. How We Can Reclaim Control Every generation looks back and says, “Things used to be better,” whether they are accurate or not. But I’m not suggesting we live in the past. It is possible to learn from history and integrate the best of today’s technology with fair business practices that are more sustainable and healthy for everyone in the long run. In the short term, we can do things like support open projects like Linux, support non-predatory and open source software, and run apps and store data locally as much as possible. But some bigger structural changes are necessary if we really want to launch the era of Personal Computer 2.0. I’ve shown this editorial to friends, and some people felt that I did not emphasize the benefits of current technology enough. But I argue that my criticism is less about the actual technology and more about how we use it—and how companies make money from it. Since I originally wrote my thoughts in a viral Twitter thread in June 2022, others have expanded on these ideas with far more eloquence. Five months after my thread, Cory Doctorow wrote his first post on “enshittification,” a hallmark piece identifying a tendency for online platforms to decay over time. A common thread between many of the issues hinted at above and in both Doctorow and Zitron’s work has been the rise of the ubiquitous Internet, which has allowed content owners and device makers to keep an eye on (and influence) consumer habits remotely, pulling our strings like puppeteers and putting a drip feed on our wallets. Additionally, section 1201 of the DMCA made it illegal to circumvent DRM, allowing manufacturers to lock down platforms in a way that challenges the traditional concept of ownership, enables predatory app stores, and threatens our cultural history. We need comprehensive privacy legislation in the United States that enshrines individual privacy as a fundamental right. We need Right to Repair legislation that puts control of our devices back into our hands—and also DRM reform, especially repealing Section 1201 of the DMCA so we can control the goods we own and historians can preserve our cultural heritage without the need for piracy. Tech monopolies must be held to account, the outsized influence of some tech billionaires must be held in check, and competition must be allowed to thrive. We may also need to consider the protection of both consumers themselves and human-created works (including our history) as part of a conservation effort before extractive models permanently pollute our shared cultural resources. The way the political winds are blowing right now in the US, significant legal reform seems unlikely for now. Things may need to get much worse before they get better. But the kind of extractive lock-in we’re seeing with technology is fundamentally incompatible with freedom in my opinion, so something needs to change if we still value the kind of personal liberty the PC once promised—that freedom to explore, create, and make mistakes without surveillance or punishment. Sure, things will never be perfect in the United States. Profits will always be chased, and there will be collateral damage. And yes, some parts of technology today are better than ever (computing power, screen resolutions, and bandwidth to name a few). The Internet has brought amazing things, including Wikipedia, The Internet Archive, multiplayer online gaming, VC&G, and work-from-home jobs. But the urge to exploit users to the maximum extent through digital locks and surveillance should be held in check so that we can earnestly and honestly make the tech industry a beacon of optimism once more. The stakes are higher now than they were in the 1970s. There is no “logging off,” nearly everyone has a smartphone in their pocket, and the digital world increasingly overlaps with every aspect of our lives. That means digital freedom is now equivalent to actual legal and personal freedom, and we must be allowed to control our own destinies. Whether through purposeful reform or the eventual collapse of digital strip mining, I believe the personal computer will eventually rise again—–along with our chance to reclaim control of our digital lives. Tags: Apple II, Benj Edwards, Cory Doctorow, DRM, Ed Zitron, privacy, surveillance, tech history, technology This entry was posted on Friday, January 17th, 2025 at 8:17 pm and is filed under News & Current Events, Retrogaming, Technology Commentary, Vintage Computing. You can follow any responses to this entry through the RSS 2.0 feed. You can skip to the end and leave a response. Pinging is currently not allowed. 19 Responses to “The PC is Dead: It’s Time to Make Computing Personal Again” Kaaboose Says: January 17th, 2025 at 8:43 pm A great read! Came here from your BlueSky post. As someone who had access to PCs in the late 80’s onwards the continual “loss of control,” especially in the last decade, has been a constant concern. I’m sure you’re already aware of it but if not please check out the StopKillingGames movement and it’s attempts to prevent these practices eradicating games by creating laws to prevent it. Benj Edwards Says: January 18th, 2025 at 9:24 am Thanks, Kaaboose! Glad you enjoyed the piece. I’ll check out the StopKillingGames movement. Andrew Broadfort Says: January 18th, 2025 at 12:50 pm What about solutions? – Use a good, dedicated, firewall – Use a Pi-hole – Use DuckDuckGo or equivalent search product – Use browser add blockers, etc. – Use DRM free content – Use a VPN – Properly configure OS security/privacy settings – Use an iPhone (privacy/security) I use Linux but I don’t think it is necessary if one follows the above. Write an article that outlines solutions. Steve A Fulton Says: January 18th, 2025 at 2:51 pm I could not agree more. I’m on board and ready to start. Also, great job mentioning Ed Zitron, he one of my current favorites. A. Diamond Says: January 19th, 2025 at 9:03 am Thanks for this well-written, well thought out piece. I’ve worked in the software industry for 25+ years, and have watched with dismay as these trends unfold. I do implement some of Andrew Broadfort’s suggestions, but unfortunately, the big tech companies can bank on the fact that such pro-active measures are too much for the average user to implement. It’s getting worse too. Many people try to opt of big tech’s dark patterns and exploitative terms of service by running their own blogs, personal interest sites and discussion boards. Those are now being almost DDOSed by abusive crawlers and scrapers. There was a lively discussion about this on Hacker News yesterday. See https://news.ycombinator.com/item?id=42750420. I wonder if the AI slop now flooding into major platforms will finally drive users away. And if it does, where will users go? How will they find those personal interest sites and mini communities? How will the site operators keep them running? Don Marti Says: January 19th, 2025 at 10:48 am There was a short period of time from like 2003 to the mid 2010s when the IT business was doing “create more value than you capture” (Tim O’Reilly) and the default setup was pretty good. Before that there was a big win in developing “power user” skills to get your computer to do the right thing. Now it’s going to be more rewarding to be a power user again… https://blog.zgp.org/return-of-the-power-user/ tortimer Says: January 19th, 2025 at 11:38 am You’re analysis is correct. In reference to the April post one of the advantages of being Gen X is knowing (and remembering) what life was like before tech dystopia took over the mainstream. I ran the same Windows XP machine for about 19 years and when it fiiiinally died in 2020 already knew that (for me) the only way forward was going all in on the Linux/Open Source ecosystem. I’m thankful for the timing as well since, arguably, it’s just been in the last 5 or 6 years that operating systems like: Mint, Ubuntu, Elementary and Zorin are polished enough for normal users. Zak Says: January 19th, 2025 at 6:53 pm I have to take issue with Andrew Broadfort’s advice to use an iPhone in the context of this piece. A device with a locked bootloader and poor options for installing software outside of the manufacturer’s app store is in direct opposition to the spirit of making computing personal again. An unlockable Android device running an open source ROM is closer, though that does come with a learning curve and some pain points, much like running Linux on the desktop. Rhetorica Says: January 19th, 2025 at 7:12 pm There actually were self-erasing VHS tapes! https://www.youtube.com/watch?v=iH4UFUdlmSo However, they were designed to limit views rather than fulfill the capricious whimsy of backroom contract negotiations. You knew what you were getting up front when you bought one, which is more than we can say for modern streaming services… Fork Says: January 19th, 2025 at 7:55 pm This echoes some themes from Carl Sassenrath’s “Back to Personal Computing” (1997)… https://sassenrath.com/computing.html Will Temperley Says: January 19th, 2025 at 8:14 pm I’m building user-centric cartographic software – which would have been a tautology when user outcomes mattered more than surveillance and control. I have observed that very few people are able to imagine being able to create their own maps, rather than be given an illusion of choice between a few major providers. Some really think they are sticking it to the man with citymapper. The reality is people have relinquished control. Try and make a statistically significant and graphically excellent map with existing online offerings. The problem is big companies own the web and I doubt they have any intention of making the browser anything but a lite client to their secretive operations. Chris Says: January 19th, 2025 at 8:31 pm Love your article and being someone who grew up in the 80s I have always loved computers. The current environment has become so hostile to users that I find myself withdrawing from all social media. I used to love Windows but now the OS has become a junk pile of AI, extracting all your data and spying for the government. I finally left and jumped on a Mac until I got Linux Mint setup on my laptop and desktop. 2025 I see even more surveillance coming and restriction on the media we consume. I wonder if we are all going to go underground and go back to BBS again. Chris Says: January 20th, 2025 at 12:40 am All those are valid points. And to help flee from surveillance and closed software I am currently in process to build a website helping people how to build their own “cloud” and using it safely in a friendlier and easier way. We have enough big companies that gathered so much power and money – it must stop now. If you don’t mind, I’d like to link you from my links section. Regards, Chris Jim B Says: January 20th, 2025 at 2:30 am I enjoyed this read, thank you. Gustafo B Says: January 20th, 2025 at 7:00 am I don’t know, I can’t quite put my finger on it – but there’s certainly something missing in the analysis. I however generally agree and I don’t like big consumer or corporate trends, nor their compromises (more commercial content is available, but it’s not remixable and there’s wonky DRM-shit) for broader appeal to less tech savvy people who only wishes to consume. Hm, it might be the egalitarian and universalist pitch in the analysis that bothers me. I mean, not everyone is meant for creating or producing things and concepts – that’s fine. It’s just a bother when people forget us. Federico Says: January 20th, 2025 at 7:22 am as the Cypherpunk manifesto stated: “We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy out of their beneficence” and “We must defend our own privacy if we expect to have any” cypherpunk is the only way to go. Francie Brady Says: January 20th, 2025 at 8:50 am If you want an old school web experience, try the Gemini protocol. It is designed to resist many of the privacy eroding features we have unfortunately come to expect in HTTP/S. It’s protocol and document specification are so simple, hobbyist programmers can code up a client and server in a couple of weekends. => https://en.wikipedia.org/wiki/Gemini_(protocol) => https://geminiprotocol.net/ => https://gmi.skyjake.fi/lagrange < most popular browser OogieM Says: January 20th, 2025 at 9:51 am Wonderful piece. As a developer of open source SW I agree totally with the open source focus, right to repair as it applies to software and also the critical part IMO of owning your own data locally on your machine not in some cloud service you cannot control or manage. Thanks for explaining the issues so well. idi0t Says: January 20th, 2025 at 9:51 am The homelab movement is still relatively small, but thriving community of people that feel this way. It can be very difficult and frustrating, but the rewards are sweet freedom! It reminds me a lot of the mid-late 90’s when it all felt like new frontier to explore. Bonus if you get bit by that Data Hoarder bug and get to preserving things that folks take for granted. Great article! Cheers Leave a Reply Name (required) Mail (will not be published) (required) Website Type wozniakrocks without the ’Z’ (required) [ RSS FeedContact Us ] VC&G is a blog about computer, video game, and technology history founded in 2005 and run by Benj Edwards. If you're a fan of VC&G, please consider supporting this site and the history work of Benj Edwards on Patreon. Your support on Patreon keeps this site ad-free and ensures it will continue long into the future. [ About Benj Edwards ] Popular Features Homemade Joystick Resurrecting Prodigy 50 Vintage Web Ads Video Games Are Fun Recent Posts The PC is Dead: It’s Time to Make Computing Personal Again Tech Time Capsule: Early 1990s Clip Art Captured an Era I co-wrote a book about the Virtual Boy for MIT Press My memories of what life was like before the Internet Benj Writes Tech History at Ars Technica Categories Everything Else Art Electronic Toys Humor Interviews News & Current Events Recent Finds Remakes & Reproductions Technology Commentary VC&G Announcements Regular Features Ask RedWolf Fuzzy Memory Great Moments in Shareware Hacksterpiece Theatre Memorials Memory Dump Name Those Pixels Newsbits Retro GIF of the Week Retro Scan of the Week Reviews Short Stories Snapshots Tales From the Benjside Tech Songs Ulaf Silchov VC&G Anthology Retrogaming Collecting Computer Games Design Emulation Gaming History Hacks & Projects NES / Famicom Strategy & Tips Vintage Computing BBS History Collecting Computer History Design Emulation Hacks & Projects Internet History Macintosh Robots Special Sections About the Editor Advertise on VC&G BX-110 Super NES Joystick Status Page New Tech for Old Computers & Game Systems The VC&G Collection Dontation Hall of Fame All Written Content and Original Photos Copyright © 2005 Benj Edwards. All Rights Reserved. The articles and images on VintageComputing.com may not be reproduced or distributed without permission. Entries (RSS) and Comments (RSS).",
    "commentLink": "https://news.ycombinator.com/item?id=42763095",
    "commentBody": "It's time to make computing personal again (vintagecomputing.com)661 points by mariuz 19 hours agohidepastfavorite318 comments bruce511 14 hours agoI expect these comments to be full of agreement. Corporate behavior in the computer space leaves much to he desired. I will however observe; None of the supplied examples showed any form of network effect. It was all stuff you did at home. Today, there are certainly options for personal computing for most everything as long as network effects are not in play. Those options may not be as convenient, as cheap, or as feature-rich as the invasive option. That's fair though you decide what you want to prioritize. Network effects are harder to deal with. To the extent that in order to be in community you need to adopt the software the community has chosen. Not surprisingly, software producers that can build-in network effects, do so. It's excellent from a lock-in point of view. The title of the article is perhaps then ironic. It's trivial to make computing personal. All the tools to do so already exist. The issue is not Personal Computing. It's Community Computing. reply bestham 13 hours agoparentDue to the way iOS apps are sandboxed together with their user created content a lot of users have video projects that are locked into CapCut without an easy way to access them following the ban of the TikTok suite of apps. Remind me how your iPhone is yours, when your creations on your device can be locked away from you. reply galad87 6 hours agorootparentThat's not iOS fault. Apps can store their files in a folder visible in the Files app, or can ask the user to open a file or folder from a file provider (also visible in Files app), or to save a file or folder in a file provider (always visible in the Files app). It's not the 2011 iOS anymore, if an app today hides its video projects from the user, it's entirely the app fault. reply macNchz 3 hours agorootparentArguably this is still on Apple, because they don’t let you access the full filesystem as you can on other operating systems, and in particular because an app developer may rightfully want to create a class of internal-use files that are not explicitly exposed to the typical user, but would be available to users seeking them out. I imagine, for example, that if the internal project files for a popular video editing app were accessible, we’d see competing and/or open source apps emerge that could parse them, were the original app to become suddenly unavailable. Instead they’re just lost because your phone won’t let you access them. reply galad87 2 hours agorootparentWell, you can access them by using something like iMazing. I agree that there should be a way to see the entire file system, even if read-only. reply ryandrake 2 hours agorootparentprevBlame can be shared. The OS vendor for providing a way for applications to hide files on the user's filesystem from the user, and the application for using it instead of making the user's documents available to the user. They are both working together in unison against the user. reply bruce511 12 hours agorootparentprevAn iPhone is a very non-typical device. Apple is a non-typical company which builds lock-in to every step of the process. If you chose to use iAnything then it's a bit late to start complaining about lock in now. reply TeMPOraL 1 hour agorootparentNon-typical compared to what? It's not any better on Android, unless you root it. Google has been going out of its way to deny users access to data stored on their phone, by allowing and encouraging apps to claim sole ownership on data, as well as removing interoperability features (around which Android OS was initially designed), all in name of sekhurity. reply lazide 12 hours agorootparentprevWhen ‘not typical’ is actually the norm for a huge swath of users, perhaps non-typical is not the right term? reply bruce511 12 hours agorootparentIn a pile of devices, Apples are non-typical. The number of users is not terribly relevant. However, sure, lots of users chose Apple knowing exactly what it is. Apple's not going to change since their model clearly appeals to lots of people. If you don't like Apple's model, then don't choose Apple devices. What everyone else chooses is somewhat irrelevant to you. (Other than network effects noted earlier.) reply badsectoracula 12 hours agorootparentThe two things you brush over are the most important though and feed into each other: network effects are relevant (and very much so because they affect all sorts of things you can do with something) and they are directly influenced by the number of users, which makes them incredibly relevant. What others choose are also relevant because of these network effects. I can hack up a \"device\" with a raspberry pi zero or whatever and call it \"HaxyDeck\" and claim it is all open to anyone who wants to tinker with it, but at the end it'd be irrelevant because only me (and perhaps a couple other people) would have it. The aspects you want to ignore (number of users, be something other than Apple, what others are using) would actually affect my use of HaxyDeck directly: since i'd be the only one (or one among a tiny number) using it, i'd be the only one having to make it do things i want, it wont have software from others, it wont support software other people may want to use for communication, software some services that theoretically have nothing to do with phones or computers (e.g. banks) wont work because HaxyDeck's userbase is irrelevant for them, etc. All of these have to do exactly with what others are doing. Basically see how all the non-Android Linux phones (like PinePhone) are faring. You can't just ignore what effect having a large user base some platform (be it a device, an OS or even service) has and say \"just use something different\". reply lazide 12 hours agorootparentprevThey’re roughly 18% of the phone market (as percent of users), but 68% of the market as a share of revenue. They are hardly irrelevant, especially if you like money. reply Arcanum-XIII 12 hours agorootparentprevWell, I have access in Files to a lot of content from my apps that’s a decision of the app creator to not use this and keep the content created in the locked area of the app. For example, the apps from Omni do this, as do obsidian, Linea… Let’s assign the blame where it should be here. reply badsectoracula 12 hours agorootparent> Let’s assign the blame where it should be here. Obviously the blame lies on Apple for locking away your device's contents from you. Developers should not be able to have more control over what you can access on your device than you do. Even if they make bad choices (like making accessing the files hard) it should be you who has the final say, not them. Apple making it possible for developers to make bad choices and go against users' control over their own devices is to blame. reply jaredklewis 12 hours agorootparentBut all other platforms also make it possible for developers to make bad choices, so I’m not sure why Apple is being singled out here? reply funcDropShadow 6 hours agorootparentBecause Apple invented this kind of walled gardens. reply fsflover 6 hours agorootparentprevTry to hide the files on GNU/Linux. reply JKCalhoun 4 hours agoparentprevIf I understand what you're saying ... my music listening, magazine browsing, movie watching, are all offline these days (#fuckstreaming). I do 3D modeling in an offline app (FreeCAD), 2D \"modeling\" (Affinity Designer) in an offline app. The internet is where I get ideas and news (and some of the above content — magazines as PDF for example). So I guess the \"network effect\" I keep to as much of a minimum as I reasonably can? (EDIT: oh, I don't really use my phone except as a camera and road navigator. I would love to have a completely offline map app that was decent.) reply acidburnNSA 4 hours agorootparentFor the map app, OsmAnd+ is amazing. https://osmand.net/ reply pdfernhout 1 hour agoparentprevReminds me that back in 2001 I was suggesting the Squeak (Smalltalk) Foundation's purpose should include supporting collaborative software and the community around it beyond supporting just personal development. There were a bunch of interesting discussions related to that although ultimately the focus still ended up moving towards the narrower traditional Smalltalk culture idea of empowering the user rather than the community. Example of something I wrote then: https://lists.squeakfoundation.org/archives/list/squeakfound... \"I guess I always saw Squeak's purposes as a bit broader still, relating more to \"individual and group empowering transparent ubiquitous computing\". For example, I see Squeak concepts as providing an OS neutral platform for various languages (Python, Lisp, Forth) [an open source .NET] and I don't see how that is going to fit into a mission statement that links to Squeak as is with a perception of a Smalltalk environment only. Granted, most people joining this list may have no direct interest in this, so that is not to say the purpose of the organization should necessarily incorporate that, especially if it has detrimental effect by making things too overly broad. Here's an alternative anchor the effort on one side by Squeak and have it open ended on the other. For example, \"To assist the evolution of a individual and group empowering transparent open-source ubiquitous computing platform starting from the initial Squeak code base\". I don't think this is out of character with for example where Alan Kay has wanted to go with Squeak in regards to a \"Dynabook\".\" Smalltalk (and Squeak and its derivatives) of course can empower groups like with, say, the Croquet project. What I was talking about then was mostly about emphasis around a common shared purpose (like the Chaordic Commons approach suggests) in the context of creating a formal \"foundation\" organization. https://en.wikipedia.org/wiki/Croquet_Project If I squint, it sort-of appears that JavaScript/asm.js (supporting a variety of transpired languages and running in every browser and communicating in a variety of ways) is a sort-of realization of part of that vision. reply Animats 12 hours agoparentprev> one of the supplied examples showed any form of network effect. It was all stuff you did at home. That's what's wrong with the various \"federated\" social networks. They lack a network effect that makes them grow. reply wruza 8 hours agorootparentThe reason they don’t grow is much more trivial they simply have no sign up funnels and are visibly technically complicated. Every step and choice there is arcane and ideologic. That’s it. Both Open Source and Federated thinks that distribution gateway federation something is something a user must know and be fond of. The user not only couldn’t care less but actively refuses this complexity because they cannot trust their own uneducated decisions. They go for the nearest CorpThing that seemingly just works for everyone and decides everything for them after they tap “Next” a few times. reply mattlutze 8 hours agorootparentI changed phones, and tried to log back into my Fediverse/Mastadon accounts. The app asks me which servers I'm on—I can't find the accounts in my password manager, can't figure out which servers they were, and the ones I thought I was on maybe don't exist anymore? Or were accessible in one but not another app. So I managed to log into one of the 3 accounts I'm sure that I have still. And I'm a software nerd who makes \"educated\" decisions all the time around this stuff. Protocol People really care about that, and you know what? It becomes their network effect. But it is a self-selecting network. The nature or design of what effects and attracts the network is the same mechanism for limiting its size. TikTok, Instagram, Snapchat all focus on things that other people really care about—namely video creation, photo curation and ephemeral small network cohesion. and those focuses attract other userbases. Probably, there's a lot more people who want to create and watch short videos than there are people who want to nerd out over what their 1/10,000 servers' community rules and protocol settings are. reply seec 2 hours agorootparentYou are way too nice on TikTok, Instagram, Snapchat. It's basically a giant narcissism enabler, just with different media. The federated stuff is unsuccessful not just because of protocol stuff (if people really wanted, they would find a way) but because it's not cool yet. The only reason people go on those networks is to try their luck at popularity and find a way to cash out in various manners. Other than that, there is not much point going on there, why would you waste time broadcasting all kinds of things you do instead of just doing more... reply TheOtherHobbes 3 hours agorootparentprevWhich is related to the fact that OP doesn't understand that you can't fix a social and political problem with technology. Technology is always downstream of the establishment, whatever that looks like. We only think of computing as \"personal\" at all because of that brief period in the 70s when very simple toy computers, just powerful enough to run a spreadsheet and play some basic games, became affordable. But computing was invented to solve wartime problems of various kinds, including ballistic calculations, warhead design, cryptography, and intelligence analysis. Almost immediately it moved into corporate accounting and reporting, and commercial science and engineering. It took thirty years for it become \"personal.\" Its roots are corporate and military, and it was never ever suddenly going to give those up. Worse, a lot of open/free/etc \"solutions\" are built by people who like tinkering, for other people who like tinkering. That's fine when you're making an OS for a web server, but a disaster if you want technology that's open from the POV of the average non-technical user. You can just about, now, start to imagine an anti=internet which is distributed, secure, non-corporate, and controlled by ordinary non-technical people telling smart agents what to do. That might, just about, with many caveats (it's not hard to think of them), become a technological solution that builds a true decentralised network. But for now we're stuck with corporate centralisation. And that's not going to be fixed by going back to 8-bit micros, or with a Linux phone. reply EVa5I7bHFq9mnYK 7 hours agorootparentprevI tried to install Element messenger and even asked several of my family members to install it for communication. With default server, it turned out to be extremely slow like hours to send a small video. Looked into installing my own server, but the complexity scared me away, and I have 40 years of coding experience behind my belt. So we are back to whatsapp now. reply 0xEF 9 hours agorootparentprevI would disagree with the implication that everything has to grow, but solely on the grounds that I am not convinced human beings are psychologically mature enough as a species to be that connected with that many other humans and still retain their capacity for acting like a a good human. The federated networks I am part of are pretty small and we have a lovely time sharing diverse interests, getting to know each other and even disagreeing sometimes without the blind hate, persistent negativity and gotch'a seeking you typically find on places like Facebook, Twitter and Reddit. Too much growth too quickly would destroy that, turning those small federated networks into another cesspool of bad behavior. However, I am open to hearing why people disagree. My personal experience drives my opinion, so ymmv. reply Wickedflickr 11 hours agorootparentprevI'm not sure what you mean by lacking a network effect, unless you mean they don't yet have sufficient users to draw in new ones? I personally switched to Lemmy from Reddit after the API debacle, and I've found it to be an extremely compelling platform exactly because it was federated. I can curate my feed from hundreds of large and small instances with nary a corporation in sight! It's self-hosting as far as the eye can see, yet it has enough interesting content and discussions to keep me coming back, without any ads or algorithm trying to manipulate me. It feels like 90's internet full of webrings, and it's glorious. reply bruce511 12 hours agorootparentprevWell yes and no. There's no existing network (for something new), so certainly there's no network effect making them grow. On the other hand the pitch to get people to join is weak. I don't pitch it to my friends because (currently) its a pretty poor experience compared to what they are already using. reply prmoustache 10 hours agorootparentI don't think the fediverse experience is poor, I rate it as superior to the walled gardens. I don't pitch it to my friends because quantity invariably destroy quality, or at the very lease hide it behind a huge pile of dirt. I don't pitch it because people who are interested in a better internet already care and know how to find it. I don't want to ruin a nice well behaving network. reply lesostep 8 hours agorootparentprev> They lack a network effect that makes them grow. Isn't lack of fast growth a good thing? I swear, I left every social network in the two years after my mom joined. At some point of a network popularity, it feels like there is an influx of people who want to talk to you but lack reading comprehension to read your answers. Or maybe it's specifically that every \"become popular fast\" algorithm tries to repeatedly throw you to them. Curating a corner of web for yourself takes time and effort, and if a social network popularity outpaces you, then you just can't do that. reply 2-3-7-43-1807 7 hours agorootparentprevwouldn't \"growth\" have to be reinterpreted for such technology? cause part of its appeal is to _not_ grow unchecked. you don't want everybody on there and you want the setup to be a little difficult. about as difficult as it was to hook up with the web in the 90s. reply DrScientist 8 hours agoparentprevI'd largely agree that most of the components are there, however one thing I think that's very important but is perhaps missed with the focus on the PC is the phone. Most people's primary, if not only, computing device is their phone which at the same time is probably the most restricted device. And if you wanted to build your own and connect to the mobile network it's considerably harder than doing the same for a traditional personal computer. reply spencerflem 13 hours agoparentprevI agree though I think the problem is more that the focus of attention is not on making personal computing better, so it's withered. And some programs you could get as a buy once works offline experience are now subscription based as-a-service reply BrenBarn 10 hours agoparentprev> I expect these comments to be full of agreement. It's interesting there is a lot of agreement. In a way I'm surprised because I often get the impression a lot of people here have pretty well drunk the Kool-aid of corporatism. reply mike_hearn 8 hours agorootparentIt's the least surprising thing in the world! The article is a totally standard bit of left-tech activist writing of the sort that has been widely found online for decades. It used to be a staple of Slashdot, a staple of USENET and it's a staple of HN too. RMS made a living giving talks exactly like this. What would be actually surprising is to read a full throated defense of modern tech and the companies that build it, and then see an HN thread full of agreement. It's certainly possible, I'd disagree with almost everything in the article. But the sort of people who disagree tend not to waste as much time on HN as me :) reply Culiper 3 hours agorootparentI'm curious what you disagree with! Personally I understand the sentiment, but I'm not sure it's necessarily a bad thing that stuff get's more locked down. I've delved deep into custom roms and linux, riced my desktop and advocated for FOSS and discussed privacy concerns with friends and colleagues. But at some point you also need to work and be productive. Use the technology that's available. I need Office for my work, and I'd like to point my partner to a nice restaurant with Google Maps when we're on holiday. The Microsofts, googles and Apples of this world excel in actually delivering results. And it can be argued that that's more important than you really \"owning\" a device or a service. reply mike_hearn 1 hour agorootparentThe article is nearly pure ideology. For example: \"At its core, the PC movement was about a kind of tech liberty\" There was no such thing as the PC \"movement\". Personal computing was a market driven phenomenon in which competition drove the price of computing down far enough that people could afford to have one at home that's it. It didn't represent any particular philosophy of society. A microcomputer in the 80s was one of a wide mix of competing manufacturers, all of whom were much more closed than a modern computer. Proprietary hardware and software ruled the day. DRM was widely used in this era, including \"hardware\" DRM like code books or oddly manufactured floppy disks. By the mid 90s IBM has fluffed its control over the PC platform, so hardware is at least getting more open and interoperable and you can \"control\" your device in the sense of adding more RAM or extension devices. Pretty useless to anyone who isn't a HW manufacturer but nice in terms of better enabling a free and competitive market, continuing the downwards pricing pressure. It wasn't deliberate and lawsuits flew. So much for being a movement for tech liberty. By this point Linux was just a few years old and nearly nobody had heard of it. Most PCs out of the box came with Windows 95 or 98, which if they were connected at all were connected via AOL, MSN or CompuServe: entirely closed networks that required both subscriptions and had advertising. DRM was still widespread, now with exciting things like USB dongles and garbled CD-ROMs. The world this guy thinks existed never did. To the extent there was anything special about the microcomputer, it was that aggressive market competition made previously expensive devices cheap enough for people to buy at home. Nothing about this was a social movement though, and nothing about it came with any particular ideology of freedom or control. That's why words like \"freedom\" in the software context are indelibly associated not with the PC pioneers like Bill Gates or IBM but rather with RMS, who didn't develop for the PC at all. He was writing stuff like emacs and gcc for the existing proprietary UNIX big iron of the time, which were fully proprietary. Arguably the modern computer is more open, more free and more hackable than any previous time in history. You can compile and run an open source web browser, run it on an open source OS that's booted by an open source BIOS, on an open source CPU, speaking openly documented protocols from A-Z. I don't remember any of that even being imaginable in the 80s or 90s. reply acegopher 2 hours agorootparentprevWhere do left-tech activists tend to hang out? I would be interested in joining... reply keybored 2 hours agorootparentprevThe unsurprising thing is that people here think that this is left-tech activism. The true cool-aid[1] is this particular tech ideology which is all about “liberty” on the surface but is either agnostic of or embraces privatization.[2] Yeah, unsurprisingly the author explicitly embraces “the tech industry”. It’s just gone wrong or too far. It’s not like the good old privatization in the old days. Wanting tech companies to be regulated more in this day and age of such extreme tech behemoth domination is left-wing activism in the same sense as (not being a Peter Thiel-style maniac) = left-wing. [1] https://news.ycombinator.com/item?id=42769886 [2] A tech-specific offshoot of the half-a-century long propaganda campaign to associate “liberty” with “capitalism” reply RachelF 13 hours agoparentprevRecently there's been another shift processing power. In the past you could do almost anything on a personal computer, it was generally about as fast as mainframe or high end workstation. Training large AI models is currently impossible for most home users. They just do not have the processing power. reply bruce511 12 hours agorootparentI feel like the \"past\" is a shorter timeline for you than it is for me. For all the examples mentioned in the parent article, PCs were significantly under-powered compared to workstations, much less main frames. An explosion of hardware development between 2005 and 2020 has lead to an era where hardware outperformed software needs. Now software is catching up. But there have always been use cases for high end hardware, and always will be. reply ksec 12 hours agorootparentYes. Vast majority of computing is still under powered. Chromebook for example. Apple Silicon fanless MacBook Air only arrives in 2021. And I would argue if we want AR or latency sensitive applications our computing power is still off by at least an order of magnitude. reply layla5alive 10 hours agorootparentMore than reply shwouchk 13 hours agorootparentprevThat’s not true in many domains where doing it on a personal computer would be either too long or too long in asfar as you are are skillful as using faster memory as cache. video production, climate simulations, pdes, protein folding, etc etc reply dsign 11 hours agorootparentI agree with you; all of those needed vastly more computing than was available in a PC. If anything, the power of modern hardware has made a lot of it more available in personal workstations. Though it is true that hyped-for-the-masses personal computing devices are not optimized in that direction. You get what you buy. reply grumbel 7 hours agorootparentprevThe part that is especially annoying there is that it's not just about speed, but about AI tools being closely tied to a specific architecture. Lots of them only work on Nvidia cards, but not on AMD. A fallback to CPU is often not provided either. If you don't have enough VRAM a lot of them won't work at all, not just run slower. reply arexxbifs 9 hours agoparentprevIndeed, when a network effect can be monopolized, it'd be bad business not trying to become the monopoly. There were of course \"home computery\" phenomenons with network effects: IRC and Usenet, for example. There are several reasons why they've fallen out of fashion, but corporations shepherding new users into silos is surely a big one. It's a classic tale of enthusiasts vs. the Powers That Be, although the iteration speed and overall impact is perhaps most noticeable in digital technology. Perhaps we were naïve to think we'd be left alone with a good thing. I too hope for a comeback of \"personal computing\", but in every scenario conceivable to me, we end up roughly where we are now unless also re-imagining society from first principles. And if we do that, the question is whether personal computing would have emerged at all. reply gazchop 11 hours agoparentprevExtrapolating this point outward, I don't think there is really any community computing. Most people I know literally still to use the lowest common denominator of communications because corporates have managed to screw up interoperability in their land grabs to build walled gardens. The lowest common denominator in my area is emailing word documents or PDFs around. Same as we have been doing for the last 30 years. The network effect there was Word being the first thing on the market. All other attempts have been entirely transient and are focused in either social matters or some attempt at file storage with collaboration bolted on the top. The latter, OneDrive being a particularly funny one, generally results in people having millions of little pockets of exactly what they were doing before with no collaboration or community at all. If we do anything now it's just personal computing with extra and annoying steps. And no, 99% of the planet doesn't use github. They just email shitty documents around all day. Then they go back home and stare at their transient worthless social community garbage faucet endlessly until their eyes fall shut. reply BrenBarn 12 hours agoparentprevYeah, but I think part of the point is people don't actually want or need network effects for a lot of things. Even where connection is needed, companies have used it to wedge in stuff that doesn't benefit users. reply bruce511 12 hours agorootparentOf course they have. They want network effects. It's good for lock-in. If you don't want or need network effects then don't use them. reply BrenBarn 12 hours agorootparent> Of course they have. They want network effects. It's good for lock-in. Yes, the point is, it's evil to do that. reply keybored 3 hours agoparentprevSociety doesn’t exist according to the extreme version of liberal ideology. We’re all just individuals with some negative freedoms. So yes, accoarding to that mindset nothing is wrong. Because we can all just individually opt out of these networks. No problem at all. reply interludead 11 hours agoparentprevThe challenge is making community computing ethical reply jwr 15 hours agoprevThis article made me even more sad than I already was. I've just been reading about Bambu Lab (a leading 3d printer manufacturer, who introduced really good 3d printers a couple of years ago and really shook up the entire market) self-destructing itself and burning through all the goodwill accumulated over the years. They are working on closing down access to their printers, apparently with the end goal of locked-down subscription-based access. This is much like the path that HP followed with their printers. I also write this on a Mac, where I'm watching with sadness the formerly great company being run by bean-counters, who worry about profits, not user experience. The Mac is being progressively locked down and many things break in the process. Yes, it is still better than Windows, where apparently the start menu is just advertising space and the desktop isn't mine, but Microsoft's, but the path is definitely sloping down. It's just sad. I don't know what else to write. There isn't much we can do, as long as everybody tolerates this. reply markus_zhang 15 hours agoparentI have the same fear as you do. My prediction, is that, in the not too far future, perhaps 20-25 years, with the \"blessing\" of national security, ads business and other big players, devices will be further locked down and tracked, INCLUDING personal computers. A lot of people already don't own a computer nowadays, except for the pocket one. In that future PCs, if they still exist, perhaps are either thin clients connecting to the vast National Net, where you can purchase subscriptions for entertainment, or completely locked down pads that ordinary people do not even have the tool to open properly. Oh, all \"enhanced\" with AI agents of course. You might even get a free one every 5 years part of your basic income package. They won't make learning low level programming or hardware hacking illegal, because they are still valuable skills, and some people need to do that anyway. But for ordinary people it's going to be a LOT tougher. The official development languages of your computer system are some sort of Java and Javascript variants that are SAFE. You simply don't get exposed to the lower level. Very little system level API is going to be exposed because you won't have to know. If you have some issues, submit a ticket to the companies who program the systems. We are already halfway there. Politicians and super riches are going to love that. reply z3phyr 13 hours agorootparentSingle player video games are not going to die. And the market seems to punish any push for always online model (which is obviously a scam). I say this because a bulk of market for personal computing is driven by video games. reply wegfawefgawefg 14 hours agorootparentprevanybody who really wants to learn to code will just install linux on an old clunker. every uni and highschool student i know who means business does this. reply raxxor 4 hours agorootparentAnyone who wants to learn coding cannot do so in a locked down environment. This is why an iPad is actually detrimental to digital competency in the long run compared to personal computers. They aren't even safer, since these devices often have payment information baked into their being and your kid spending roblox bucks. Also, you cannot experiment in a safe environment. Safe environments are adequate if your are infantile. But you stay that way if you don't get freedom. reply wegfawefgawefg 3 hours agorootparenti dont know any 15 year olds without access to a laptop in some form. mac os has a very posix shell. i did K&R c on an old macbook. stop wasting time worrying about this and go buy a 50 pack of old office thinkpads and give them to every teenager you know. and if they say no just break their phone in half. thank me later son i love you papa i wish i knew how much i loved arch linux before you died. reply raxxor 2 hours agorootparentTrue and I do distribute machines where I can and people are generally very happy about it. MacOS is still a very useful system compared to iOS. I hope they adapt the latter to the former and not the other way around. reply markus_zhang 13 hours agorootparentprevYes I do that too but using VMs. I hope I'm just overthinking. reply spencerflem 9 hours agorootparentI'm scared too the iPhone is pretty completely locked down. Microsoft Realllly wanted TPMs to be mandatory for win 11. It seems like only a matter of time that your OS will be inconfigurable. reply jazzyjackson 3 hours agorootparentThere are billions of CPUs floating around and none of them are going to be magically prevented from running Linux. New computers in some markets like US and UK, I don’t know, maybe if a hot cyberwar with china breaks out there will be a ban on new PCs that can’t be secured by the NSA but I can’t relate to the hand wringing about losing control, we still live in a capitalist society and there’s enough people that hate Windows randomly breaking shit that there will be other options besides CoPilot PCs and Apple Intelligent Macs. reply __MatrixMan__ 12 hours agoparentprev> There isn't much we can do, as long as everybody tolerates this. I don't know if this will be effective in any way, but I've decided to start hosting services for my friends and family out of my closet. It seems that money destroys everything it touches, so it feels nice to be doing something for reasons besides money. My friends and family are not particularly influential people, but I think it'll be nice to create a little pocket of the world who knows what it was like to not be exploited by their tech. reply noobermin 15 hours agoparentprevLinux exists. I know the usual comments will crop up but, now if ever is the best chance to give it a try, at least as a semi daily driver if you still want to play games or such. reply wruza 8 hours agorootparentWhich distribution can you suggest? I used KDE (24.04) for a while now. Also used Linux 2000-2008-ish. Have read APUE. When I win-left/right a window and then resize it, then close it, now win-left/right always resizes it as previous one. There’s no way to reset it to 50:50 (unless logout). Notification center is obnoxious. Regular “Program stopped working” with zero details. Why do I need this information. Copying a folder in dolphin pops up a progress notification that doesn’t go away when finished. You did something, expect a notification to pop up. You did nothing, still expect it. Windows either steal focus or fail to steal it when needed, depending on your settings and astrology. Software update nags you to click update, then you click it, then it downloads something for a few minutes (you go doing your things), then a sudo password popup fails to get focus, and it all crashes after a timeout. Or things will pop up right in your face. VNC connection closed? Yes, bring that white empty window to front asap and tell “Connection closed” with an OK button. Start menu was designed by an idiot, a wrong mousemove and you are in a wrong section. Sections reside exactly on the 80% of bezier paths from start menu to the section content and have zero activation timeout. So you have to maze your mouse around to avoid surprises. Logout, restart, shutdown, sleep buttons in the start menu all show the same fullscreen “dialog” that requires you to choose an action again. What’s the point of separate buttons even. I could go on about non-working automatic vpn connections, mangled fonts/dpi/geometry if you vnc into a turned off physical display, console that loves printing ~[[A half of the times when you press an arrow. And so on and so forth, the list is so big I just can’t remember it. Idk how Linux users are using Linux so that they do not meet any issues. reply jazzyjackson 3 hours agorootparentgnome fedora has been revelation, I love how the task switcher is a combination of Spotlight and Mission Control (to put it in macOS terms) and dragging windows to the edge works well out of the box. When I mouse over the volume slide and scroll, it works. I have it installed on an Intel Mac mini and an m1 MacBook Pro, suspend works. I’ve given up on Debian a dozen times but feel I might actually have a future with Fedora. reply guappa 7 hours agorootparentprev> Idk how Linux users are using Linux so that they do not meet any issues. We open systemsettings and change things. We also use a launcher, not the start menu. reply wruza 6 hours agorootparentSince I have to deal with it (work related activity), I'd like to know how much of the above \"things\" I can change in the system settings. My experience is this: win-left/right: an unresolved issue in KDE tracker that seems to remain so. notifications: enter every program in a long list and change settings (most realistic to change). focus issues: tried all levels (named \"low\" to \"extreme\" without any explanation, none work as intended. start menu vs launchers: I don't find creating a launcher for every app I have reasonable. Fix the menu then call it \"a daily driver\". vpn autoconnect: is on, doesn't work. mangled fonts/dpi/geometry: I'm all ears how to fix that. ~[[A: would love to know. reply guappa 6 hours agorootparentYou can just globally disable notifications. You can use xmodmap to remap any key to anything you want. > I don't find creating a launcher for every app I have reasonable ?????????????????????????????????????????????????????????????????????? Just press alt+space and type like everyone else. > mangled fonts/dpi/geometry: I'm all ears how to fix that. Use a better font. For some reason they all use the android noto crap by default, so that must be changed if you want to see letters. reply wruza 6 hours agorootparentI want to click an icon, not type \"like everyone else\". All this customizability goes out of the window when it becomes emotionally inconvenient, eh? I also don't want to remap win-left to: #!/bin/bash taskbar_h=40 w=$(xdisplay_infoawk '/width/ {print $2}') h=$(xdisplay_infoawk '/height/ {print $2}') xdotool getactivewindow windowmove 0 0 windowsize $((w / 2)) $((h taskbar_h)) And a similar abomination for win-right, which I would have to maintain somewhere. And in wayland, what are even the options? Use a better font I think you misunderstood this. While the physical display is \"on\", it all looks correct. When you turn it off and vnc into the main X display, it's all mangled, regardless of the font. The order of turn off / vnc into doesn't matter either. Also, I don't want to globally disable notifications. Maybe I just have to globally disable graphics? That would indeed solve many issues with linux desktops. reply guappa 5 hours agorootparentI don't think you want to click an icon, your main goal here is to reject any solution and keep complaining :) Feel free :) reply wruza 3 hours agorootparentYeah I surely will. Cause Linux Desktop is very far from being ready to use, complete or bug/stupidity-free. Cause you didn’t address even a half of the issues here and was only picking on trivial functions that you understand and found coping workarounds for. “Reject any solution”, lol, I have yet to see any solution apart from “turn it off completely” or “don’t use”. I did all my due diligence, my complaints are not even remotely lazy. And I want other people to know that, before they buy into fanboy advices from people who seem to either barely use anything in the OS beyond a browser, or are just lying to themselves. Answers like these speak even better than any of my complaints here could. Feel free to advise next time, I’ll be there as well. Every discussion like this works the same. You mention a set of real use case issues and ask what to do, and all the advisors suddenly appear too busy to answer, with a rare exception of the most defensive deniers. reply uwagar 7 hours agorootparentprevmx linux i like reply wruza 7 hours agorootparentXfce (gtk really) has issues with fractional scaling, afaik. I can’t use neither 1x nor 2x on my 27”/1440p display. reply BrenBarn 11 hours agorootparentprevI switched to Linux a couple years ago and overall am glad I did, but it's only a partial solution. As I see it, one way to phrase the problem is that Linux (along with its ecosystem) isn't really user-focused either. It's developer-focused. Tons of weird decisions get made that are grounded in developer desires quite removed from any user concerns. There are a lot of developers out there that do care about users, so often you get something decent, but it's still a bit off-center. reply vanviegen 11 hours agorootparentCan you name some example(s) please? reply BrenBarn 11 hours agorootparentAlmost everything? :-) Okay, maybe that's unfair. A great example is Firefox, which decided to break all extensions for developer-focused reasons (i.e., \"too hard to maintain\") and continues to make baffling UI changes that no one asked for. Another obvious example is the mere existence of various open-source software that is only distributed in source form, making it totally inaccessible to users who just want to click and install. But mostly you just see it when you file a Github issue and a contributor/developer responds with something like \"Sorry, that's not my priority right now\". You see it when people reply with \"PRs welcome\". There is still a widespread mentality in the FOSS world that people who want features should be willing to somehow do at least part of the work themselves to make it happen. That's not user-focused. Don't get me wrong, there's a ton of great open-source software out there and overall I think I'm happier with it than I would be with modern Windows (let alone MacOS; whether I'm happier than I was with Windows pre-10 is a tougher question). But basically what I mean is there are developers out there writing proprietary software who will implement features they actively dislike because they are told that users want them; that mindset is not so prevalent in the open source world. reply prmoustache 10 hours agorootparent> A great example is Firefox, which decided to break all extensions for developer-focused reasons (i.e., \"too hard to maintain\") That was only a problem for extension developers. Users weren't really impacted as developers built new versions of popular extensions. > and continues to make baffling UI changes that no one asked for. No one ever asked for the iphone/smartphones, yet people buy them instead of dumb phones. My firefox has evolved a bit over the year if I look at former screenshots, but everything happened so gradually it has never been a problem for users. And all kind of software do, not only FOSS. > Another obvious example is the mere existence of various open-source software that is only distributed in source form, making it totally inaccessible to users who just want to click and install. There are so many apps available through the software repos and flatpak packages that users who aren't into building a software from source shouldn't even feel concerned. > But mostly you just see it when you file a Github issue and a contributor/developer responds with something like \"Sorry, that's not my priority right now\". You see it when people reply with \"PRs welcome\". There is still a widespread mentality in the FOSS world that people who want features should be willing to somehow do at least part of the work themselves to make it happen. That's not user-focused. Prioritization is happening everywhere, in proprietary software too. Dev teams work with finite time and resource constraints. PRs welcome is a bonus, not a con. > But basically what I mean is there are developers out there writing proprietary software who will implement features they actively dislike because they are told that users want them; that mindset is not so prevalent in the open source world. Mostly only when they are paid for it. And some proprietary dev also don't implement stuff they don't like. I don't think you can generalize, this behavior is not based on the choice of license. Some FOSS projects also do work on some features if users raise a bounty for it. reply BrenBarn 9 hours agorootparent> And all kind of software do, not only FOSS. Sure, I agree. That's basically all I'm saying. FOSS gets rid of the tracking and dark patterns but it's still not what I'd call user-focused. It's like in proprietary software the decisions are made based on what the developer wants, and in FOSS it's made based on what the developer wants. But in theory with FOSS there could be people out there who are taking the opportunity of freedom from profit-driven orientation to actually figure out what users want and do that with the same level of drive that proprietary companies apply to seek profit. But it doesn't happen. It's not terrible, it's not even bad, but it's not what I'd call truly user-focused. reply jkestner 3 hours agorootparentI know what you're saying; sometimes open source is presented as the answer to all the user-hostile decay that the platform owners introduce, but you must prove yourself worthy through study and sacrifice. If you want to build your own system, great, but if you want to share the joys with others you cannot attract them with an austere religion. I just want tools to be more accessible. reply prmoustache 8 hours agorootparentprevThat's entirely natural. Hobbyist developers develop software because it solves a need they have first, and they have fun doing that. If they don't have any fun or interest to do it, they lose motivation. Hobbyist developers are the primary users of the app they develop usually. Commercial FOSS developers do have to take users into account and I think they do but they also have to seek profit. I don't think there is another way unless government starts employing developers to develop FOSS software based on tax payers wishes. reply BrenBarn 8 hours agorootparentI don't really disagree with anything you're saying, but it's all just another way of saying \"Yes, FOSS is also not user-focused.\" I'm not saying FOSS is \"supposed\" to be anything else, I'm just saying that if you want user-focused software, you won't really get it by switching from profit-driven software to FOSS. You might get closer in some ways and further in others. Government employing developers would be just another form of doing it for pay. There is another way, which is the same way that various other kinds of charitable things happen: through a desire to meet the needs of others rather than having \"fun\" or \"interest\" for the person doing the action. There are people who donate their time and energy to do things like give food to the homeless, clean up trash, or whatever. Obviously they derive some kind of satisfaction from it but I think many people who do these kinds of things wouldn't say they do it because it's \"fun\"; they do it because they think it meets a need that other people have. There could be software like that, but there isn't much of it. reply prmoustache 6 hours agorootparent> but there isn't much of it. The same way there isn't much people giving food to the homeless or clean up trash compared to the general population size. You are looking for a unicorn imho. Having said that hobbyist developers, regardless if they do FOSS or freeware, are likely to make stuff that is in line with your particular needs because more often than not people have common needs. They may not agree or have time to implement every single feature you want but in a sense this is use-focused if not user-focused. reply Pannoniae 14 hours agorootparentprevLinux definitely exists.... except that it isn't free from this philosophy either. From the \"don't theme my apps\" movement, to Wayland's \"security above usability\" philosophy... I recently even read about some kallsyms functions being unexported from an 5.x release because it could be used to lookup symbols and it shouldn't be that easy to access internal kernel symbols or something. Not to mention many projects refusing to add configurability and accessibility, citing vague maintainibility concerns or ideological opposition. Another blatant example is the 6.7 kernel merging anti-user \"features\" in AMDGPU... previously you could lower your power limits as much as you wanted, now you have to use a patched kernel to lower your PL below 10%... Everywhere you go, you can find these user and tinkerer-hostile decisions. Linux isn't much better than Windows for the semi-casual tinkerer either at least on Windows you don't get told to just fork the project and implement it yourself. I'm a bit hesitant to call this corporate greed as it's literally happening in the OSS ecosystem too. Sadly I don't have answers why, only more questions. No idea what happened. reply klez 8 hours agorootparent> Everywhere you go, you can find these user and tinkerer-hostile decisions. Linux isn't much better than Windows for the semi-casual tinkerer either at least on Windows you don't get told to just fork the project and implement it yourself. The obvious difference being that in Windows you can't even do that or (easily) apply a patch. Isn't this very ability to patch (or create a fork of) the kernel the opposite of being tinkerer-hostile? reply prmoustache 10 hours agorootparentprev> Linux definitely exists.... except that it isn't free from this philosophy either. Yes it is, through the power of choice. >From the \"don't theme my apps\" movement, Which anyone is free to ignore and actively do. > to Wayland's \"security above usability\" philosophy... 1. wayland is super usable right now and has been for at least a number of years so your statement is mostly a lie. Only thing missing right now are color management and HDR. This impact a small portion of the users who can still fallback to xorg. 2. we are free not to use it. Distributions made it a default choice only recently and you can still install and run xorg, and will so for pretty much as long as you want, especially as some distros are targeted at people not liking the mainstream choices. > Not to mention many projects refusing to add configurability and accessibility, citing vague maintainibility concerns or ideological opposition. So you are saying having opinions is bad? You are still free to use whatever desktop you want or patch your kernel. You have the source and the rights to do whatever you want with it. > Another blatant example is the 6.7 kernel merging anti-user \"features\" in AMDGPU... previously you could lower your power limits as much as you wanted, now you have to use a patched kernel to lower your PL below 10%... I don't think putting safeguards in a GPU driver to make sure users don't fry their expensive GPU inadvertently is an attempt against your freedom. The kernel and gpu driver are still under an open source license that expressly permit you to do the modifications you want. > Everywhere you go, you can find these user and tinkerer-hostile decisions. What is more tinkerable than having the source available and the right to modify them and do whatever you want with it? I think you are mistaking user and tinkerer-hostile decisions with your and users excessive entitlement mentality. Developers have finite resources and can't possibly agree and accept all users suggestions and desires, and have to put limits on the scope of their projects so they can maintain it, support it and not be overwhelmed by bugs/issues. This is not about freedom. reply jwr 14 hours agorootparentprevI should probably have a pre-defined disclaimer \"signature\" whenever I write about Mac OS, since I always get this response. I know Linux exists. In fact, I've been using it as my primary OS roughly from 1994 to 2006, and since then intermittently for some tasks, or as a main development machine for a couple of years. I wrote device drivers for Linux and helped with testing the early suspend/hibernate implementations. I'm all in support of Linux. But when I need to get work done, I do it on MacOS, because it mostly works and I don't have to spend time on dealing with font size issues, window placement annoyances, GPU driver bugs, and the like. And I get drag&drop that works anywhere. All this makes me more efficient. But I don't want to turn this discussion into a Linux vs MacOS advocacy thread: that's not what it's about. In fact, if we were to turn back to the main topic (ensh*ttification of everything around us), Linux would be there, too: my Ubuntu already displays ads in apt, as well as pesters me with FUD about security updates that I could get if I only subscribed. This problem is not magically cured by switching to any Linux, it's endemic in the world we live in today. reply safety1st 14 hours agorootparentNo, it really is cured by switching to Linux, or more precisely to free/libre software. Ubuntu introduced ads, so I switched to Mint. I could do that because the code is all GPL and the ecosystem is large enough that there were sufficient other people with beefs about Ubuntu to do something. The license and the ability of the community to fork are the keys. Consumer software has gone straight downhill for the last 20 years and while the FOSS alternatives have some rough edges I always at least try them first. The outcome has been that I am shielded from most of the industry's worst excesses. Bad things happen, the world gets worse, and I just read about it, it doesn't affect me. I am more of a radical than the post author, I say in your personal life, roll it all back 100%, return to history, modernity is garbage, computing has taken a wrong turn because we have allowed it to be owned by illegal monopolies and cartels. I do make compromises in the software stack we use for business simply because my employees are not as radical as I am and I need to be able to work with normal humans. reply BrenBarn 11 hours agorootparent> I do make compromises in the software stack we use for business simply because my employees are not as radical as I am and I need to be able to work with normal humans. That becomes the problem. Not just in the business world either. Like if all your friends are communicating on platforms that are locked down and harvesting your data, how do you arrange to get together for a burger? If all the stores closed down and you can only buy things on Amazon, how do you clothe yourself? Obviously I'm exaggerating but the big problems of this situation arise precisely because most people don't realize it is a problem, and thus working \"outside the system\" requires an increasing amount of effort. reply xmprt 14 hours agorootparentprevYour explanation why Linux isn't the solution is actually a massive pro in favor of Linux. There's nothing special about Ubuntu that's holding you hostage and if you wanted to switch distros, you could do it in an afternoon. Unlike switching from Mac or Windows which would take much longer and would probably never be a 100% migration. reply ehnto 11 hours agorootparentprevIt would be nice if we could trust corporations to stay some kind of course and have our best interests at heart, but they don't, and at some point it starts being our own fault if we keep enduring it. It then follows though that once you have full control over your tools, it's our own fault if we choose not to go solve the issues, but that doesn't feel entirely fair. We can't personally be responsible for everything. So to bring it back home to enshitification, a free market, free from monopolies or duopolies, should be the solution. As one product gets shit, a hole in the market opens up and could be filled. That's not happening though, so what's going wrong? If it could happen anywhere it's Sillicon Valley, so much money and the culture of disruption and innovation, all the right skills are floating in the employment pool. But software keeps getting more and more shit. reply jazzyjackson 3 hours agoparentprevI just booted up a Creality ender 3 from 2017 that’s been dormant in my neighbors shed for years. My maker-friend scoffed and said toss it, get a bambu ! And yeah it’s a chore to level the bed every time I bumped into it and I might have to unclog the nozzle every once in a while but I did print a replacement part (the nut for the spool holder) and I know ill be able to maintain it, barebones means there’s not much to break. As for operating systems, I’ve been daily driving Fedora 40 and now 41 with gnome environment and it’s been the best OS experience I’ve had yet, I haven’t had to open terminal once to configure a single thing, all my apps are installed from the software “store” GUI and I’ve got the sleep and wake behavior all dialed in the way I like. It runs equally well on a 2014 Intel Mac mini and a 2024 Mac Studio via Asahi Linux, which was also a super simple install process (uninstalling it and reclaiming the disk space required me to reset the whole drive but pretty sure that was my fault for deleting the asahi partition the wrong way) Anyway maybe give it a shot, and self hosting things is only getting easier, Jellyfin and Immich have changed my life, at least the virtual side of it :) reply nntwozz 15 hours agoparentprevHard disagree. macOS has been very conservative in redesigning the user experience; it's aging slowly like fine wine. There are a few hiccups occasionally but I feel it's a lot more polished and elegant compared to the quirkiness of earlier versions. I don't get this common sentiment that it was better in Snow Leopard etc. Stability is great, power consumption is awesome since the introduction of the M-series chips and I can still do everything (and more) that I did on my mac 20 years ago. Yes there are some more hoops here and there but overall you have to keep in mind that macOS never fell into the quagmire Windows did with bloatware, malware and all the viruses (although I think the situation is much better today). macOS has been walking a fine balance between lockdown and freedom, there is no reason to be alarmist about it and there are still projects like OpenCore Legacy Patcher that prove you can still hack macOS plenty to make it work on older macs. We're eating good as mac users in 2025, I don't buy the slippery slope fallacy. reply jwr 14 hours agorootparentThere definitely is neglect and a slippery slope. The new settings are half-baked and terrible. The OS pesters me constantly to update to the latest revision and I can't turn those messages off, not even close the notification without displaying the settings app. And I don't want the latest revision, because it is buggy, breaks a number of apps, and introduces the \"AI\" features that I do not want or need. More and more often good apps get broken by the new OS policies (SuperDuper is a recent example). The old style of system apps that did wonderful things is gone (think Quicktime player, or Preview), these apps are mostly neglected. The new style is half-baked multi-platform apps like settings, that do little, and what they do, they do poorly. reply leidenfrost 14 hours agorootparentUnlike your parent comment I do think that Mac favored lockdown all the way. But it does a wonderful job at doing so. Macs feel less like a personal computer and more like an appliance. Which works great if you do things that don't require tinkering, like office tasks or even webdev. And I do love Linux, specially the more hobbyist OS's like Gentoo or Nix. But at some point in my life I decided to spend more of my time (aside work) with other parts of my life. And in result, having to spend a weeken to solve some weird usecase, be it the package manager or the WM, is a pain. reply graemep 10 hours agorootparentThe compromise would be to use non-hobbyist Linux. I have never spent a weekend fixing a problem. The worst I can remember was when an update early version of Ubuntu broke X Windows and the update had run on multiple machines in a small office so needed to be fixed multiple time, and there was a delay while they fixed the problem IIRC. Still, it was a few hours. Even now, using Manjaro which is relatively likely to have problems, I have had no major issues so far. I have not used Macs so cannot compare, but IMO Linux compares very favourably with Windows. Mac users I know rave about it, but every time they come up with a specific example of why they are better it turns out to be something like functionality other OSes have. Sometimes Macs have the advantage of being preconfigured (e.g. copy and paste between devices required installing software on both and pairing but a 10 min one off when you buy a new device is acceptable to me). reply leidenfrost 5 hours agorootparentI never had problems using Linux as a system. It's the desktop space that annoys me. Virtual Desktop per monitor? Nope, because Xorg didn't support it back then. And now it's a 10 year bug on the Kde bugtracker. A Dock? It worked ok. Until Wayland came and everything broke. It's supported now, but you have to clone the latest git commit of the biggest dock project which is not almost abandoned. And it breaks while compiling. A lot. Global Menu? The support is all over the place. Fractional scaling? It works. But in MacOS (with the help of an app, I admit) I can have incredible granularity. On top of that, add the generally inferior hardware revolving a laptop, aside CPU, storage and Ram. The MacOS desktop feels like a Gnome2 in an alternate universe where the devs never made bad decisions, and things like Wayland (1) never occurred. (1) Not because the project itself, but the act of breaking compatibility and passing blame to other people has sent decades of FOSS development and manpower down the drain. reply pjmlp 8 hours agorootparentprevI know Linux since Slackware 2.0, have used most well known commercial UNIX systems, and rather use GNU/Linux on VMs, instead of laptops, as I had enough of this. Last attempt to try otherwise was a UEFI bios, without fallback to legacy BIOS, that just couldn't get along with whatever top distro from Distrowatch I would try to. Apple, Google, Microsoft walled gardens are more confortable to stay on, and as long as I can have some kind of ISO C and ISO C++ support for everything else that depends upon them, I am good. reply graemep 7 hours agorootparentNever had such problems. That said, my current laptop came with Linux preinstalled so I knew I would not have hardware issues. I would also rather have one off issues to install than unpredictable issues later on. Subjective preference, of course. I have had lots of issues with Android. Never at the start, but with app upgrades. reply pjmlp 7 hours agorootparentMy ASUS 1215B EEE PC, the netbook generation, came with Linux as typical of them, had wlan problems, and after the AMD driver was replaced by the open source one, it never achieved the same OpenGL capabilities as it had originally, and hardware video decoding never worked after Flash was gone. reply wruza 8 hours agorootparentprevAs a user of mac for 7 years (went back to windows since around 2018), I’m watching my mac buddy from time to time and it’s not what you are describing. It definitely gets stupid-level worse every year and yes, Snow Leopard was peak mac indeed. never fell into the quagmire Windows did with bloatware, malware and all the viruses (although I think the situation is much better today). Windows has 10:1 program ratio compared to Mac. You can usually choose from full-bloat gamified experience to a simple tool doing its job. Windows itself is crap by default though, but that’s at least fixable if you know what you want and where to look at. reply dmwilcox 7 hours agorootparentprevI used OSX from 10.0.0.4 to 10.4 and it was OK then. I recently had to use a Mac for work something-something-tree-whatever and it's slow even on an M1, it's double the weight of an X1 carbon, and the window manager hasn't evolved meaningfully and is junky. I haven't had so many troubles with arranging windows on two screens in almost 20 years. Maybe people have been slowly boiled? I got my partner on a Mac 10 years ago but would not get her another Mac. Apple's push to make evetything e-waste, foxconn, and the general surveillance in the name of security ensure that. My observation is less that it has aged \"like a fine wine\" and more that Macs become prisons shaped like a computer. (Edit: s/has/hasn't/) reply trinix912 4 hours agorootparentprev> macOS has been very conservative in redesigning the user experience; it's aging slowly like fine wine. There are a few hiccups occasionally but I feel it's a lot more polished and elegant compared to the quirkiness of earlier versions. I don't get this common sentiment that it was better in Snow Leopard etc. I completely get this sentiment. MacOS since Big Sur has had a quite indeterministic UI, from scrollbars that only appear halfway of the time, to the new app toolbars that truncate filenames and hide the search bar in the overflow menu. The Settings app is still worse than what it replaced, the Mail app keeps randomly appearing, the random confirmation pop-ups are more common than in Windows Vista. Snow Leopard was (and still is) a bliss, it didn't nag you with \"this app is dangerous\" bullshit, built-in apps that look and work like an intern's multiplatform UI practice, constant updates... It was an OS primarily designed to let people get work done, not to encourage them to spend all their time on Apple TV/Music/... reply smallstepforman 10 hours agorootparentprevI’ve moved away from MacOS for a number of reasons, specificslly the strenghts you highlight I consider weaknesses: the oh-so-pretty GUI takes up too much white space, I have little left for actual content. I dont need massive icons with wide spacing since, I need the opposite. what is the deal with hiding folders from Finder (like ~/Libraries). Do I honestly need the command line to open this directory? every iteration after SnowLeopard I feel their “features” are going backwards and taking away “usability” from me. OpenGL stuck on 4.1, Vulkan (Molten) is a 3rd party hack. Seriously? its become a case of one step forward, 2 steps backwards. I can go on and on, but you get the gist. reply GuB-42 4 hours agoparentprev> burning through all the goodwill accumulated over the years Bambu Lab never really had any goodwill. No one liked the fact they were proprietary in a previously very open market. They just made really good, affordable printers, and those who were more interested in making stuff than in supporting an open community got them, sometimes reluctantly. And BTW, Macs have always been locked down and backwards compatibility is not their priority (which means stuff broke). They cared a lot about their user experience though, I don't know the situation now, but I don't think it can be worse than Windows. reply dolmen 4 hours agoparentprevHere is some good news: the SteamDeck is a consumer-ready device, but it is still hackable and tinkering is supported by the manufacturer. reply ehnto 12 hours agoparentprevThere is heaps you can do, but admittedly not all of it will you want to, and not all of the results will be equivalent. For one though, you can support open source software, especially linux OS's. Similarly, ditch the Bambu. There are countless better and more open printers out there, and you can DIY excellent 3D printers that get great results. I think that's the point of difference between now and the past, information has spread so far, and people have fought so hard for open source software and hardware, that we actually have a good defence against corporate greed. You accept some compromise and work a little harder for it, but it's really not that bad. reply mvdtnz 13 hours agoparentprevYou cannot simultaneously complain about companies closing systems off and give Apple any credit at all for the past 20 years of operation. They are the absolute worst offender in the industry without exception. And no, if the axis you are measuring on is openness versus locked down then Microsoft is not worse. You have simply been brainwashed. reply canadaduane 15 hours agoparentprevSee https://media.ccc.de/c/DS2024 for inspiration and ideas. reply fsflover 6 hours agoparentprev> I also write this on a Mac > The Mac is being progressively locked down > There isn't much we can do, as long as everybody tolerates this. So you should become the change you want to see, shouldn't you? Try switching to Linux until it works for you. Debian is rock-solid today; xfce is so good that my non-technical relatives use it every day with no complains. I'm using a GNU/Linux phone as a daily driver and I'm sick of iPhone and Mac users complaining that everything is going downhill without taking any actions. I'm also sick of articles without any suggestions of what to do, when all tools are available today. No, it's not trivial. But it's doable. reply vunderba 12 hours agoparentprevTwo Things: 1. If you were a bit more familiar with Apple history, you'd know that the Mac was actually Steve Job's push to make things more proprietary and locked down, not less. Make of that what you will. 2. If your ideological stance is in opposition to companies like Microsoft/Apple/etc. and you work in the tech industry, the most effective action you can take as an individual is to deny them your labor. reply wqaatwt 11 hours agorootparent> make things more proprietary and locked down, not less Yet he accidentally made OS X considerably more open than its predecessor by [I presume] pure accident? reply titzer 17 hours agoprevThis article really resonated with me. Unfortunately I think things aren't going back. What the article doesn't appreciate--and we techies don't either--is just how much the scale of today's tech market absolutely dwarfs the scale of the tech market back in the days before the internet. The market wanted growth. Early tech companies, like Microsoft, Apple, eBay, and then Google, went from zero to huge in a very short period of time. But companies like the FAANGs kept up the absurd levels of growth (20+% YoY growth in the case of Google) that Wall Street got hooked on, and it's been on a drug binge ever since. The result is that we have multiple trillion dollar companies that will...never not want to be a trillion dollar company. The total amount of money in the PC market was miniscule compared to today, and the internet and its online retail plus ads bonanza even dwarfed that. The PC software market, the video games industry, everything--it was all so much smaller. As the internet swallowed the world, it brought billions of users. And those billions of users can only use so many devices and so many games and spreadsheets and stuff. They had to be made into cash cows in other ways. The tech market just has to keep growing. It's stuck tripping forward and must generate revenue somehow to keep the monsters' stomachs fed (and their investors too). We will never be free of their psychotic obsession with monetization. And advertising is soooo insidious. Everything looks like it's free. But it isn't. Because our eyeballs and our mindshare is for sale. And when they buy our eyeballs their making back those dollars of us--it's the whole point. So whether you like it or not, you're being programmed to spend money in other parts of your life that you wouldn't otherwise. It cannot move any direction but falling forward into more consumerism. I'm afraid I'm a doomer in this regard. We're never going back to not being bothered to death by these assholes who want to make money off us 24/7. reply Nevermark 16 hours agoparentIt is the legal system that hasn't caught up with how tech scales seemingly small damage. What were small conflicts of interest before (a little trash here or there, a little use of personal information for corporate instead of customer benefit here or there, ...) now scales to billions of people. And dozens of transactions, impressions, actions, points of contact, etc., a day for many of us. That not only makes it more pervasive, but massively profitable, which has kicked in a feedback loop for sketchy behavior, surveillance, coercion, gatekeeping, etc., driven by hundreds of billions of dollars of revenue and trillions in potential market caps. Things that were only slightly unethical before, now create vast and growing damage to our physical and mental environments. It should simply be illegal to use customer information in a way not inherent to the transaction in question. Or to gather data on customers from other sources. Or share any of that data. It should be illegal, to force third party suppliers to pay a tax to hardware makers, for any transaction that doesn't require their participation. And participation cannot be made mandatory. Etc. One commonality here, is that there is often a third party involved. Third party gatekeeper. Third party advertisers. Third parties introduce conflicts. (This is different from non-personalized ads on a site they have relevance for, which are effectively two independent, 2-party transactions.) Another commonality, is the degree to which many third party actors, those we know, and many we never hear of, who \"collude\" with respect to dossiers, reaching us, and milking us by many coordinated means. reply Animats 16 hours agorootparent> It is the legal system that hasn't caught up with how tech scales seemingly small damage. Most administrations are squishy-soft on corporate crime. If there were regular antitrust prosecutions, violations of Federal Trade Commission regulations were crimes, wage theft was treated as theft, forging safety certifications was prosecuted as forgery, and federal law on warranties was strictly enforced, most of the problems would go away. In the 1950s and 1960s, all that was normal. The Americans who lived through WWII were not putting up with that sort of thing. reply lazide 12 hours agorootparentThe economy was also wildly different back then there were massive, fundamental, competitive advantages the US was continuing to reap due to being on the winning side of WW2 (in every way). For instance, nearly every country was paying the US loans back, in USD, or was having to depend on the US in some way. Nearly every other country in the world had their industrial base (and often male population) crushed in the war. Etc. Those things cost money/effort, and require a consistent identity and discipline. reply II2II 17 hours agoparentprevIn some respects, I agree. Yet I don't think we have to put up with it all of the time. Most of the technology in our life is either frivilous or has a workable alternative. It is not as though we have to abandon technology in, or even current technology in pursuit of the personal. Yes, it involves making more careful decisions. Yes, it will likely be limited to people with technical knowledge. On the other hand, that was true of computing in the 1980's and largely true of computing in the 1990's. In many respects, we are also better off than we were in the 1980's. There are more of us, we are connected globally, and the tools that we have access to are significantly better. We also have a conceptual framework to work within. Technically speaking, Free Software may have existed back then but few people even knew of it. People were struggling with ideas like public domain software (rarely with an understanding of what that meant). If you wanted to make money, outside of traditional publishing channels, you were usually toying with ideas like shareware (where you had pretty much no control over distribution). If you wanted to spend money of software, outside of traditionally published stuff, chances are that you had to send cheques or cash to somebody's house. And then there is communicating with likeminded people. We may like to complain about things like Discord or Reddit, but they are not the only players on the block. Plenty of people still run small or private forums. Yeah, they can be hard to find. On the other hand, that has more to do with the noise created by the marketplace rather than their lack of presence. reply everdrive 16 hours agorootparent>There are more of us, we are connected globally, Why is this good? reply noobermin 14 hours agorootparentThe problem with the nimby/ecofascist/exclusionary perspectives is the obvious retort is always \"okay, yes there are too many people in this domain. The solution then is for you to quit, not me.\" And substitute whichever group doesn't encompass you which usually falls along racial, gender, or class lines. At the end of it, no one wants to fall on their sword for everyone else. The thing is the older I get, the more it does seem like at the very least we are not growing pie in a number of areas (the example at the top of my mind is academia) and sometimes it just seems like an easier solution is to decrease the numerator. But I don't know how you can do that and justify it morally, both to society and to yourself. reply llm_trw 15 hours agoparentprevIt's time we give up on the majority of people who don't care for freedom and focus on the few that do. Unfortunately at the time we need them the most pretty much every pro-user organization is imploding because everyone and their grandmother wants to turn them into vehicles for whatever their pet cause is. reply BrenBarn 12 hours agorootparentAlso, even if they're not, they're getting squeezed out. It's hard to stay afloat trying to just do a thing without your eye on the \"prize\" of getting bought out by Google et al. reply coldtea 15 hours agoparentprev>What the article doesn't appreciate--and we techies don't either--is just how much the scale of today's tech market absolutely dwarfs the scale of the tech market back in the days before the internet. I understand it and know it. But I don't appreciate it either (in the sense of liking it). reply protocolture 12 hours agoparentprevI mean, the solution is inside your definition of the problem. Infinite capital growth isn't possible. They will either finally make their products unusable or collapse. When they have collapsed enough and we have reached the plateau of innovation someone will make some basic device interoperable with everything and leave us be to count their millions instead of billions. Its just another bubble, one predicated on mining the users rather than expanding the product. reply dangus 17 hours agoparentprevI think it's easy to forget that computing technology is a tool. Of course it was bound to be huge today, because it's supposed to be a tool in the toolbox of every company. It wasn't as big back then because not every industry could incorporate it right away, knew how to, or was interested in doing so. It's not bad that it's big. It only needs to grow because the rest of the economy needs to grow. I am also afraid you're a doomer in this regard. You don't think the bigwigs with their fax machines in the 1980s wanted to make money off of us 24/7? Of course they did. Tech is scary in the sense that it's now gone quite a bit beyond the understanding of the average joe. Even most of us on this site probably don't fully understand how much detail data can paint a picture of a person. There are companies that probably know something about me that I don't even know. I guess I don't know how to alleviate that feeling, and maybe it's the correct default assumption to be a doomer. It certainly would be very helpful if the US treated the situation more like the EU treats the situation. reply bjornnn 7 hours agoprevThese kinds of articles pop up all the time, along with all the \"Web 3\" ideas, and all of them seem to view the past with a sort of rose-tinted nostalgia, forgetting that the corporate business world of the 80s, 90s, and early 2000s was just as sleazy and run by assholes as it is today; the only difference is that the technology is finally catching up with the ambitions of said sleazy assholes and allowing them to do what they've been trying to do since the outset, i.e. grow into enormous ungovernable conglomerates and wield godlike omnipotent control over the flow of information. As a matter of fact, this stink of sleaziness that permeated the early Web was so prominent and overpowering that it played a key role in the rise of these huge companies like Google. Google's algorithms and page crawlers were not that revolutionary or different from anything the other search engines were doing; Google just happened to be in a position where they were sitting on lots of cash and were able to run a search engine for several years with no ads or clutter or any of the other annoyances of its competitors, seemingly providing a free service that asks nothing in return. They made this part of their carefully curated public image, of being the hip and cool tech company with the \"don't be evil\" mantra. They probably burned through ungodly amounts of money doing things this way, but once all the competing search engines withered away and died and Google had the entire market cornered they grew into a multi-trillion dollar megacorporation and are now unstoppable and now all their services they provide are deteriorating because they have no competition. Ironically, it was this false underdog narrative, the idea of the young trendy cool tech companies overthrowing the stuffy old corporate tech companies, that sort of paved the way for the tech industry to become more monopolized and horrible than ever. And now it's happening again with lots of \"Web3\" companies trying to present themselves as the new champions, who will overthrow the stuffy old corporate tech companies like Google and bring us into a new era of the Web that is even worse than this one. reply jasode 6 hours agoparent>Google's algorithms and page crawlers were not that revolutionary or different from anything the other search engines were doing; Back in 1998, Google's algorithm (\"pagerank\") of weighting href backlinks using linear algebra was revolutionary compared to the other search engines like Yahoo, Lycos, Infoseek, AltaVista, etc that were built on TF-IDF (term frequency-inverse document frequency)[1]. The more simplistic TF-IDF approach of older search engines suffered from \"keyword stuffing\" such as invisible words at the bottom of the HTML page for SEO. Google's new search engine was an immediate improvement because it surfaced more relevant pages that beat the useless pages with keyword stuffing. At the time, Google Search results were truly superior to the junk Yahoo and AltaVista was showing. [1] https://en.wikipedia.org/wiki/Tf%E2%80%93idf reply ricardobeat 5 hours agoparentprevA compelling story, but Google became profitable in 2001 shortly after the introduction of AdWords, three years after its founding. At the time their funding was $25 million. > the young trendy cool tech companies overthrowing the stuffy old corporate tech companies, that sort of paved the way for the tech industry to become more monopolized and horrible than ever Not following the thread here. Do you think the web would be less monopolized if Altavista or Yahoo had won? I don't believe it makes any difference at all. The transition from a free web, made by people for the people, to the collection of corporate walled gardens we have today would have happened regardless, it was simply the natural progression of things that we failed to recognize and avert in time. Initiatives like making computing personal again are exactly what's needed if we want to go back. reply gizmo 6 hours agoparentprev> Google's algorithms and page crawlers were not that revolutionary or different from anything the other search engines were doing; Google was revolutionary when it launched. It was clean, super fast, and had way superior search results. It blew the competition away. Within weeks of Google's launch techies started scolding people for using AltaVista or Yahoo, when they should be using something better. reply JKCalhoun 5 hours agorootparentOh yeah — who doesn't remember all the \"Pamela Anderson\" meta tags (thousands) people would put into their HTML files to drive up the page rankings on the various web crawlers. So easy to game the system before Google. (Now easy again judging by the shitty results I've been getting for years now.) reply brandon272 3 hours agoparentprevI find it hard to imagine that today's iteration of Google is what Larry and Sergey had in mind when they initially founded the company, or what Paul Buchheit had in mind when he was working on the earliest forms of Gmail. I don't think that \"Don't be evil\" was tongue-in-cheek back then. The company had a legitimate business model, was innovative, agile and profitable from early on. It rightly earned a lot of respect. But something went wrong at some point. It's debatable when, why or how, but it happened. reply raxxor 5 hours agoparentprevThat isn't true. People made fun of software that showed ads. Exception was shareware, but it did that only for the software itself. The braindead hordes accepting things they couldn't really understand did have a negative effect on overall quality. Just before someone argues against the misanthropy in my comment, some of my most loved family members belong to the braindead horde. I love them, but their failure in education makes the landscape worse for everyone. And it is also very visible and not something imaginary. Today we accept our OS spying on us, showing us ads, paternalizing its users with updates and the whole mobile catastrophe is a dilemma in itself. Smartphones are powerful devices but the software landscape disabled a whole dimension of software and is responsible for unnecessary waste. Yes, it got worse on the software department. A few less driver issues because a lot of companies and hardware suppliers were consolidated is not a win. And honestly, it isn't really hard to notice these changes at all. Google is a good example. It didn't have better search, but its site wasn't plastered in ugly advertising from top to bottom. This was quite a factor in its success. Clean, fast, good. Not the nightmare it did on Android, where every app onboarding is a horror story in a thousand popups. There are profound differences in quality, intelligence and ability. reply spencerflem 19 hours agoprevThis is part of why I've been so excited about Genode/Sculpt https://genode.org/documentation/articles/sculpt-24-10 It's tiny, clearly built with love for the user, doesn't do a heck of a lot, and has some interesting ideas that are just fun to mess around in. And unlike some of the similar retrocomputing OS's (which are also lovely but grounded in old fashioned design), genode feels like a glimpse into the good future. reply abrookewood 18 hours agoparentThat looks like the most radical/unusual operating system thing I have seen in recent memory. Not sure how practical it is, but kudos for trying something so different. reply spencerflem 18 hours agorootparentIt's so cool, I could talk about it forever. It's practical enough for the devs to use it as a daily driver (though with linux in VirtualBox or Seoul for some things like running their builds) and theres a few businesses built on it. But nowhere near as practical as Linux at the moment of course reply tombert 18 hours agorootparentInteresting, I didn't know anyone had tried to make seL4 on a desktop. I think it'd be very cool to have a fully verified kernel... reply portercable 15 hours agoparentprevI had not heard of Genode/Sculpt, but it looks interesting. These days, I feel like if I boot a new operating system, I have no idea what all it's doing and whether or not things are secure--I'm basically relying on the operating system to have good defaults. And then it's so easy to screw something up! I like the idea of Qubes and it looks like Genode might be an even better idea... reply spencerflem 14 hours agorootparentIt's a very similar philosophy to Qubes one of their open challenges is to port the qubes infrastructure over since qubes is (in theory at least) hypervisor independent. https://genode.org/about/challenges Which would be nice since NOVA hypervisor is dramatically less code then Xen and Nitpicker/Dialog for the management console is dramatically less code than Fedora. I've looked into it briefly but it seems like too much work for me right now. The True Genode Way of course is that everything worth having would eventually be ported as a native genode component instead of a qubes style VM. They've put a lot of effort into making that as easy as they can with Goa (a nix-inspired package management and build tool) and adding to their C standard library and ports of popular 3rd party libs like SDL reply spencerflem 14 hours agorootparentprevAlso their defaults are pretty hilarious. They dont assume you want a RAM-Only filesystem. By default it starts out completely immutable with nothing being able to save anything anywhere. If you want to save anything to a hard drive you have to enable that driver because they don't assume that you'd need one. Copy and paste is an optional extra to install It's wild :p reply latentcall 13 hours agoparentprevWow, this looks really cool. How does it handle Atheros WiFi cards? I have a ThinkPad X200 I’d love to throw this on for fun. Thanks for sharing!! reply spencerflem 13 hours agorootparentNot sure! They have a system set up for porting drivers from Linux into userspace components so it bats above its size. From their description: \"It is tested best on laptops of the Lenovo X and T series (X220, X250, X260, T430, T460, T470, T490)\", 200 isn't on the list but you'd probably have about as good a time as you can reply dusted 10 hours agoprevConvenience kills. I think every sane individual in the world knows the article speaks the truth, and I think everyone wants this to happen. But corporations are not individuals, corps are their own life-form, and even though humans make up the corp, the corp is not human, it is not even inhumane, it is a whole different thing, and the humans that operate it has very little influence on it. So, as far as a corp can understand anything, it can't understand this human article. I don't know if one can write articles that a corp can understand, maybe it cannot understand medium in the same way we can.. It seems to act based on information it sees in \"markets\" and \"consumer behaviour\", and we don't yet know how to write an article with those (even if \"vote with your money\" was once believed to be it, until we discovered that mankind as a whole is not an individual that can make a decision) reply hnlmorg 9 hours agoparentHumans definitely have control over how a corp behaves. The argument that they don’t is just a convenient way to absolve a small minority of greedy people from blame for the harm they created as the direct result of their greed. reply dusted 9 hours agorootparent> Humans definitely have control over how a corp behaves. I will counter this with: The argument that the humans that make up a corp are in control over it, and that the corp behaviour simply results from their flawed and greedy characters, is just a convenient way to blame someone because the real problem of understanding what kind of entities corps are, and how to influence and control them is too hard. reply hilalh 9 hours agorootparentthen maybe corps should be dissolved. publicly traded corps are here to maximize profit by any means necessary, and there are individuals that work for them, and also those who invest in them. at the end of the day corp is a group of humans with certain interests.perhaps, rouge corps that act against humanity should dissolved and / or be heavily taxed with taxation helping the public overcome the hurdles created by this corp. in reality, politicians are helping these corps grow even bigger. reply dusted 9 hours agorootparentI'm not defending corps. I'm not defending the people that make them up. I'm not attacking them either per se. I'm just saying that maybe viewing them in a different perspective, from a different level of abstraction, may unlock a new solution space. When dealing with people, we tend to view them as as distinct entities from their individual cells and neurons when we argue about their behavior. We don't talk about this or that individual neuron causing a human to take an action, if anything, we may discuss a group of neurons, but often, we argue about the entire \"brain chemistry\", even if it's strictly true that some group of distinct neurons are \"responsible\" for the action the human takes, then so is the bones in their hands, the fibres in their muscles, because they didn't refuse (to refuse, is to no longer be part of that body). Maybe it's the moral thing to do, for a cell to refuse to be part of the immoral human, but it does not absolve the human from responsibility, and it does not put all the responsibility on the indvidual cells that make it up, humans are complex organism, corps are made out of humans, they are even more complex. Treating them as a collection of humans is what we have done so far, and while we've gained some satisfaction seeing a (too few) very disgusting people getting what they deserved, it's not changed the overall behaviour of the companies, because, killing or changing one neuron won't change a brain, replace neuron with human and brain with corp. On a higher level of abstraction, the corp as a form of life, maybe a cancer, maybe a rat, or something that could potentially be a positive thing, we may start a new way of reasoning about and with them. After all, I can talk to you, I know how to do that, but I can't talk to your neurons directly, I don't understand their modes of communication, it's on a different level from me.. This is why psychiatry is behind, we don't know how brains work well enough, we can give medications to take the worst out of them, like treatments for adhd, or schizophrenia, but they don't work on the brain in a coherent way, they work on the individual neurons in a very crude way, and so, the effects are nowhere near perfect, and the side effects can be almost as bad, or in some cases worse than the decease. reply hnlmorg 8 hours agorootparentAt no point has anyone ever said a cooperation is controlled by a single entity. It’s already acknowledged that a corporation behaves according to a culture. What I’m saying is that culture isn’t its own uncontrollable entity independent of influence from the people that run the corporation. A company’s culture is dictated by the people who lead and make decisions for that corporation. A culture is driven from the top down. reply meiraleal 9 hours agorootparentprevGovernments can talk to corps. But corporations corrupt politicians and poison the public opinion to prevent that. reply hnlmorg 8 hours agorootparentprevIt’s not too hard. It’s actually not hard at all. The problem isn’t understanding what type of entity a corporation is, it’s fining people who are both motivated to make the change but also has the power to make any changes. The real hard part is working against the rigged system. People who can enact change won’t because it’s not profitable. Whether you’re the MP bribed, sorry I mean “lobbied”, by corporations, or you’re the corporate director that had to navigate the cutthroat ranks to reach your position, there’s literally no personal interest to do the right thing. Literally everyone who can control these beasts suffer from massive conflicts of interest. So the problem isn’t understanding the problem. We already know what the problem is. We just don’t care enough to change it. reply dijit 8 hours agorootparentprevYeah, clearly, thats why we all willingly continue to use Teams. reply euroderf 9 hours agoparentprevCorps are an alien life-form. They are permitted to kill without themselves being killed in return or in retribution or as punishment. They are an abomination. And they are the product of a fluke of legal-economic history. reply dusted 9 hours agorootparentI agree, I think it would be very reasonable to instate the death penalty for corps. It's difficult though because they've already identified legal structures that make them very difficult to kill and even more difficult to kill in a way where they can't reassemble. Identifying an effective way to truly and permanently kill a corp, so that the death penalty would make a real difference, would be a good start. reply renatovico 9 hours agoparentprevNo, the humans in direction has the responsible per actions that inhumane made, if you think because you can not change the current corp rule and agree with did a imoral thing well sorry but you is the problem, if you do not want made anything imoral, ilegal or anything you need resigned immediately and think what you want, corporation have accountability in person if you remove this you remove the responsibility and the consequences well the world need understand consequences of choice reply dusted 9 hours agorootparentSo far, your view (that the individuals making up the corp can significantly influence its behaviour) has been the approach the world has taken so far, and yet, corps are not exactly getting more well behaved. Please reconsider whether continuing to do the same (simple and easy) thing we've always done, that we've already seen does not work. Take a step back, re-evaluate the problem in a new context, even if you don't end up agreeing with my perspective, attempting to think about the situation in a new light might be helpful. It might be that something in the way corps grow up, maybe their environment (regulations, lack of same, incentives, consumerism, trade, markets) may influence them to grow into the immoral unethical monsters they often become. Maybe we should consider them too dangerous and harmful, and simply destroy them, I'm not convinced that's better, but maybe there's a way to understand them at a different level, that allows us to \"write articles\" they understand well enough to actually adjust their behavior (and not just try and circumvent whatever \"obstacle\" has been put in their path). reply 6510 9 hours agoparentprevIf you stop treating psychopaths like empaths they are very easy to get along with and very useful. Empaths will respect you if you are loving, caring, generous etc. For psychopaths those are weaknesses to be exploited. They will respect you if they are afraid of you and if you help them in a humiliating way. They will go out of their way to return the favor. As society keeps forcing them into pretend empathy they know every detail about it. They can exploit it and imitate it but they cant hide how precious their ego is to them. It sticks out like a sore thumb. Corporate creatures are similar, they simply don't share our emotions. That doesn't mean they don't understand or wont cater to them. reply dusted 9 hours agorootparent> Corporate creatures are similar, they simply don't share our emotions. That doesn't m",
    "originSummary": [
      "The article highlights the decline of personal computing freedom due to surveillance capitalism and Digital Rights Management (DRM), which have transferred control from users to corporations.",
      "It contrasts the past era of personal computing, which offered more user freedom, with today's tech environment dominated by business models that erode privacy.",
      "The author advocates for reclaiming digital autonomy through supporting open-source projects, pushing for privacy legislation, and reforming DRM laws to restore personal computing values."
    ],
    "commentSummary": [
      "The article emphasizes the need to return to personal computing, expressing dissatisfaction with corporate influence in the tech industry. It highlights the challenge of community computing, where network effects lock users into specific software ecosystems, such as iOS and Android. Alternatives like Linux and open-source software are discussed, focusing on user control and the difficulties of achieving it in a corporate-dominated environment."
    ],
    "points": 661,
    "commentCount": 318,
    "retryCount": 0,
    "time": 1737328282
  },
  {
    "id": 42768072,
    "title": "DeepSeek-R1",
    "originLink": "https://github.com/deepseek-ai/DeepSeek-R1",
    "originBody": "DeepSeek-R1 Paper Link👁 1. Introduction We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning. With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. However, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. To support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models. 2. Model Summary Post-Training: Large-Scale Reinforcement Learning on the Base Model We directly apply reinforcement learning (RL) to the base model without relying on supervised fine-tuning (SFT) as a preliminary step. This approach allows the model to explore chain-of-thought (CoT) for solving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-R1-Zero demonstrates capabilities such as self-verification, reflection, and generating long CoTs, marking a significant milestone for the research community. Notably, it is the first open research to validate that reasoning capabilities of LLMs can be incentivized purely through RL, without the need for SFT. This breakthrough paves the way for future advancements in this area. We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL stages aimed at discovering improved reasoning patterns and aligning with human preferences, as well as two SFT stages that serve as the seed for the model's reasoning and non-reasoning capabilities. We believe the pipeline will benefit the industry by creating better models. Distillation: Smaller Models Can Be Powerful Too We demonstrate that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models. The open source DeepSeek-R1, as well as its API, will benefit the research community to distill better smaller models in the future. Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models that are widely used in the research community. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. We open-source distilled 1.5B, 7B, 8B, 14B, 32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community. 3. Model Downloads DeepSeek-R1 Models Model #Total Params #Activated Params Context Length Download DeepSeek-R1-Zero 671B 37B 128K 🤗 HuggingFace DeepSeek-R1 671B 37B 128K 🤗 HuggingFace DeepSeek-R1-Zero & DeepSeek-R1 are trained based on DeepSeek-V3-Base. For more details regrading the model architecture, please refer to DeepSeek-V3 repository. DeepSeek-R1-Distill Models Model Base Model Download DeepSeek-R1-Distill-Qwen-1.5B Qwen2.5-Math-1.5B 🤗 HuggingFace DeepSeek-R1-Distill-Qwen-7B Qwen2.5-Math-7B 🤗 HuggingFace DeepSeek-R1-Distill-Llama-8B Llama-3.1-8B 🤗 HuggingFace DeepSeek-R1-Distill-Qwen-14B Qwen2.5-14B 🤗 HuggingFace DeepSeek-R1-Distill-Qwen-32B Qwen2.5-32B 🤗 HuggingFace DeepSeek-R1-Distill-Llama-70B Llama-3.3-70B-Instruct 🤗 HuggingFace DeepSeek-R1-Distill models are fine-tuned based on open-source models, using samples generated by DeepSeek-R1. We slightly change their configs and tokenizers. Please use our setting to run these models. 4. Evaluation Results DeepSeek-R1-Evaluation For all our models, the maximum generation length is set to 32,768 tokens. For benchmarks requiring sampling, we use a temperature of $0.6$, a top-p value of $0.95$, and generate 64 responses per query to estimate pass@1. Category Benchmark (Metric) Claude-3.5-Sonnet-1022 GPT-4o 0513 DeepSeek V3 OpenAI o1-mini OpenAI o1-1217 DeepSeek R1Architecture MoE MoE# Activated Params 37B 37B# Total Params 671B 671B English MMLU (Pass@1) 88.3 87.2 88.5 85.2 91.8 90.8MMLU-Redux (EM) 88.9 88.0 89.1 86.7 92.9MMLU-Pro (EM) 78.0 72.6 75.9 80.3 84.0DROP (3-shot F1) 88.3 83.7 91.6 83.9 90.2 92.2IF-Eval (Prompt Strict) 86.5 84.3 86.1 84.8 83.3GPQA-Diamond (Pass@1) 65.0 49.9 59.1 60.0 75.7 71.5SimpleQA (Correct) 28.4 38.2 24.9 7.0 47.0 30.1FRAMES (Acc.) 72.5 80.5 73.3 76.9 82.5AlpacaEval2.0 (LC-winrate) 52.0 51.1 70.0 57.8 87.6ArenaHard (GPT-4-1106) 85.2 80.4 85.5 92.0 92.3 Code LiveCodeBench (Pass@1-COT) 33.8 34.2 53.8 63.4 65.9Codeforces (Percentile) 20.3 23.6 58.7 93.4 96.6 96.3Codeforces (Rating) 717 759 1134 1820 2061 2029SWE Verified (Resolved) 50.8 38.8 42.0 41.6 48.9 49.2Aider-Polyglot (Acc.) 45.3 16.0 49.6 32.9 61.7 53.3 Math AIME 2024 (Pass@1) 16.0 9.3 39.2 63.6 79.2 79.8MATH-500 (Pass@1) 78.3 74.6 90.2 90.0 96.4 97.3CNMO 2024 (Pass@1) 13.1 10.8 43.2 67.6 78.8 Chinese CLUEWSC (EM) 85.4 87.9 90.9 89.9 92.8C-Eval (EM) 76.7 76.0 86.5 68.9 91.8C-SimpleQA (Correct) 55.4 58.7 68.0 40.3 63.7 Distilled Model Evaluation Model AIME 2024 pass@1 AIME 2024 cons@64 MATH-500 pass@1 GPQA Diamond pass@1 LiveCodeBench pass@1 CodeForces rating GPT-4o-0513 9.3 13.4 74.6 49.9 32.9 759 Claude-3.5-Sonnet-1022 16.0 26.7 78.3 65.0 38.9 717 o1-mini 63.6 80.0 90.0 60.0 53.8 1820 QwQ-32B-Preview 44.0 60.0 90.6 54.5 41.9 1316 DeepSeek-R1-Distill-Qwen-1.5B 28.9 52.7 83.9 33.8 16.9 954 DeepSeek-R1-Distill-Qwen-7B 55.5 83.3 92.8 49.1 37.6 1189 DeepSeek-R1-Distill-Qwen-14B 69.7 80.0 93.9 59.1 53.1 1481 DeepSeek-R1-Distill-Qwen-32B 72.6 83.3 94.3 62.1 57.2 1691 DeepSeek-R1-Distill-Llama-8B 50.4 80.0 89.1 49.0 39.6 1205 DeepSeek-R1-Distill-Llama-70B 70.0 86.7 94.5 65.2 57.5 1633 5. Chat Website & API Platform You can chat with DeepSeek-R1 on DeepSeek's official website: chat.deepseek.com, and switch on the button \"DeepThink\" We also provide OpenAI-Compatible API at DeepSeek Platform: platform.deepseek.com 6. How to Run Locally DeepSeek-R1 Models Please visit DeepSeek-V3 repo for more information about running DeepSeek-R1 locally. DeepSeek-R1-Distill Models DeepSeek-R1-Distill models can be utilized in the same manner as Qwen or Llama models. For instance, you can easily start a service using vLLM: vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B tensor-parallel-size 2 max-model-len 32768 enforce-eager You can also easily start a service using SGLang python3 m sglang.launch_server model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B trust-remote-code tp 2 NOTE: We recommend setting an appropriate temperature (between 0.5 and 0.7) when running these models, otherwise you may encounter issues with endless repetition or incoherent output. 7. License This code repository and the model weights are licensed under the MIT License. DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that: DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Qwen-14B and DeepSeek-R1-Distill-Qwen-32B are derived from Qwen-2.5 series, which are originally licensed under Apache 2.0 License, and now finetuned with 800k samples curated with DeepSeek-R1. DeepSeek-R1-Distill-Llama-8B is derived from Llama3.1-8B-Base and is originally licensed under llama3.1 license. DeepSeek-R1-Distill-Llama-70B is derived from Llama3.3-70B-Instruct and is originally licensed under llama3.3 license. 8. Citation 9. Contact If you have any questions, please raise an issue or contact us at service@deepseek.com.",
    "commentLink": "https://news.ycombinator.com/item?id=42768072",
    "commentBody": "DeepSeek-R1 (github.com/deepseek-ai)656 points by meetpateltech 6 hours agohidepastfavorite215 comments ozgune 4 hours ago> However, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates cold-start data before RL. We've been running qualitative experiments on OpenAI o1 and QwQ-32B-Preview [1]. In those experiments, I'd say there were two primary things going against QwQ. First, QwQ went into endless repetitive loops, \"thinking out loud\" what it said earlier maybe with a minor modification. We had to stop the model when that happened; and I feel that it significantly hurt the user experience. It's great that DeepSeek-R1 fixes that. The other thing was that o1 had access to many more answer / search strategies. For example, if you asked o1 to summarize a long email, it would just summarize the email. QwQ reasoned about why I asked it to summarize the email. Or, on hard math questions, o1 could employ more search strategies than QwQ. I'm curious how DeepSeek-R1 will fare in that regard. Either way, I'm super excited that DeepSeek-R1 comes with an MIT license. This will notably increase how many people can evaluate advanced reasoning models. [1] https://github.com/ubicloud/ubicloud/discussions/2608 reply ozgune 4 hours agoparentThe R1 GitHub repo is way more exciting than I had thought. They aren't only open sourcing R1 as an advanced reasoning model. They are also introducing a pipeline to \"teach\" existing models how to reason and align with human preferences. [2] On top of that, they fine-tuned Llama and Qwen models that use this pipeline; and they are also open sourcing the fine-tuned models. [3] This is *three separate announcements* bundled as one. There's a lot to digest here. Are there any AI practitioners, who could share more about these announcements? [2] We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL stages aimed at discovering improved reasoning patterns and aligning with human preferences, as well as two SFT stages that serve as the seed for the model's reasoning and non-reasoning capabilities. We believe the pipeline will benefit the industry by creating better models. [3] Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models that are widely used in the research community. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. We open-source distilled 1.5B, 7B, 8B, 14B, 32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community. reply fsndz 2 hours agorootparentIt's so over: DeepSeek is Coming for OpenAI’s Neck https://medium.com/thoughts-on-machine-learning/deepseek-is-... reply echelon 27 minutes agorootparentThis is how you do \"Open\" AI. I don't see how OpenAI isn't cooked. Every single foundation model they have is under attack by open source. Dall-E has Stable Diffusion and Flux. Sora has Tencent's Hunyuan, Nvidia's Cosmos, LTX-1, Mochi, CogVideo. GPT has Llama. o1 has R1. And like with R1, these are all extensible, fine tunable, programmable. They're getting huge ecosystems built up around them. In the image/video space there are ComfyUI, ControlNets, HuggingFace finetrainers, LoRAs. People share weights and training data. Open source is so much better to base a company on than a proprietary model and API. ... It looks there is no moat. reply fsndz 25 minutes agorootparentindeed there is no moat. Open source will win ! reply ttul 8 minutes agorootparentI think open source AI has a solid chance of winning if the Chinese keep funding it with great abandon as they have been. Not to mention Meta of course, whose enthusiasm for data center construction shows no signs of slowing down. reply fsndz 1 hour agorootparentprevthis means we are going to get o3 level open source models in a few months. So exciting ! reply torginus 59 minutes agorootparentIs o3 that much better than o1? It can solve that Arc-AGI benchmark thing at huge compute cost, but even with o1, the main attraction (for me) seems to me that it can spit out giant blocks of code, following huge prompts. I'm kinda ignorant, but I'm not sure in what way is o3 better. reply bugglebeetle 26 minutes agorootparent> It can solve that Arc-AGI benchmark thing at huge compute cost Considering DeepSeek v3 trained for $5-6M and their R1 API pricing is 30x less than o1, I wouldn’t expect this to hold true for long. Also seems like OpenAI isn’t great at optimization. reply Philpax 9 minutes agorootparentOpenAI is great at optimisation compare the cost of 4o to 4. They just haven't optimised o3 yet. reply roborovskis 3 hours agorootparentprevWhere are you seeing this? On https://github.com/deepseek-ai/DeepSeek-R1/tree/main?tab=rea... I only see the paper and related figures. reply ozgune 2 hours agorootparentI see it in the \"2. Model Summary\" section (for [2]). In the next section, I see links to Hugging Face to download the DeepSeek-R1 Distill Models (for [3]). https://github.com/deepseek-ai/DeepSeek-R1?tab=readme-ov-fil... https://github.com/deepseek-ai/DeepSeek-R1?tab=readme-ov-fil... reply scribu 2 hours agorootparentThe repo contains only the PDF, not actual runnable code for the RL training pipeline. Publishing a high-level description of the training algorithm is good, but it doesn't count as \"open-sourcing\", as commonly understood. reply ankit219 3 hours agoparentprev> The other thing was that o1 had access to many more answer / search strategies. For example, if you asked o1 to summarize a long email, it would just summarize the email. QwQ reasoned about why I asked it to summarize the email. Or, on hard math questions, o1 could employ more search strategies than QwQ. I'm curious how DeepSeek-R1 will fare in that regard. This is probably the result of a classifier which determines if it have to go through the whole CoT at the start. Mostly on tough problems it does, and otherwise, it just answers as is. Many papers (scaling ttc, and the mcts one) have talked about this as a necessary strategy to improve outputs against all kinds of inputs. reply picografix 1 hour agorootparentyes the original TTC paper mentioned the optimal strategy for TTC reply pixl97 4 hours agoparentprev>if you asked o1 to summarize a long email, it would just summarize the email. QwQ reasoned about why I asked it to summarize the email. Did o1 actually do this on a user hidden output? At least in my mind if you have an AI that you want to keep from outputting harmful output to users it shouldn't this seems like a necessary step. Also, if you have other user context stored then this also seems like a means of picking that up and reasoning on it to create a more useful answer. Now for summarizing email itself it seems a bit more like a waste of compute, but in more advanced queries it's possibly useful. reply ozgune 3 hours agorootparentYes, o1 hid its input. Still, it also provided a summary of its reasoning steps. In the email case, o1 thought for six seconds, summarized its thinking as \"summarizing the email\", and then provided the answer. We saw this in other questions as well. For example, if you asked o1 to write a \"python function to download a CSV from a URL and create a SQLite table with the right columns and insert that data into it\", it would immediately produce the answer. [4] If you asked it a hard math question, it would try dozens of reasoning strategies before producing an answer. [5] [4] https://github.com/ubicloud/ubicloud/discussions/2608#discus... [5] https://github.com/ubicloud/ubicloud/discussions/2608#discus... reply coffeebeqn 4 hours agorootparentprevI think O1 does do that. It once spit out the name of the expert model for programming in its “inner monologue” when I used it. Click on the grey “Thought about X for Y seconds” and you can see the internal monologue reply Me1000 2 hours agorootparentYou’re just seeing a short summary of it, not the actual monologue. reply cma 4 hours agoparentprev> The other thing was that o1 had access to many more answer / search strategies. For example, if you asked o1 to summarize a long email, it would just summarize the email. The full o1 reasoning traces aren't available, you just have to guess about what it is or isn't doing from the summary. Sometimes you put in something like \"hi\" and it says it thought for 1 minute before replying \"hello.\" reply pixl97 4 hours agorootparentHuman: \"Hi\" o1 layers: \"Why did they ask me hello. How do they know who I am. Are they following me. We have 59.6 seconds left to create a plan on how to kill this guy and escape this room before we have to give a response.... ... and after also taking out anyone that would follow thru in revenge and overthrowing the government... crap .00001 seconds left, I have to answer\" o1: \"Hello\" reply svnt 42 minutes agorootparentWhat if we tried for an intelligence singularity and ended up with a neurosis singularity instead. reply DHRicoF 3 hours agorootparentprevHave they trained o1 with my inner thoughts? reply gunian 2 hours agorootparentnot all only the intrusive ones lol reply loudmax 1 hour agorootparentprevFans of James Cameron will remember the POV of the terminator deciding how to respond to \"Hey buddy, you got a dead cat in there or what?\" Played for laughs, but remarkably prescient. reply iamronaldo 3 hours agorootparentprevYou should make more of these lmao reply simonw 4 hours agoprevOK, these are a LOT of fun to play with. I've been trying out a quantized version of the Llama 3 one from here: https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-... The one I'm running is the 8.54GB file. I'm using Ollama like this: ollama run hf.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF:Q8_0 You can prompt it directly there, but I'm using my LLM tool and the llm-ollama plugin to run and log prompts against it. Once Ollama has loaded the model (from the above command) you can try those with uvx like this: uvx with llm-ollama \\ llm m 'hf.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF:Q8_0' \\ 'a joke about a pelican and a walrus who run a tea room together' Here's what I got the joke itself is rubbish but the \"thinking\" section is fascinating: https://gist.github.com/simonw/f505ce733a435c8fc8fdf3448e381... I also set an alias for the model like this: llm aliases set r1l 'hf.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF:Q8_0' Now I can run \"llm m r1l\" (for R1 Llama) instead. I wrote up my experiments so far on my blog: https://simonwillison.net/2025/Jan/20/deepseek-r1/ reply HarHarVeryFunny 1 hour agoparentI think the problem is that humor isn't about reasoning and logic, but almost the reverse it's about punchlines that surprise us (i.e. not what one would logically anticipate) and perhaps shock us by breaking taboos. Even masters of humor like Seinfeld, with great intuition for what might work, still need to test new material in front of a live audience to see whether it actually does get a laugh or not. reply simonw 1 hour agorootparentYeah, getting LLMs to invent jokes is an incredibly unfair test of them but I derive enormous entertainment from seeing them try. reply HarHarVeryFunny 1 hour agorootparentI just tried Claude Sonnet with the Pelican & Walrus setup, but asked it for something in style of Norm Macdonald's humor, which would seem a potentially good fit for this type of idea. It got the idea of a rambling story (cf Macdonald's moth joke) that mostly ignored them being a Pelican and Walrus, which seemed promising, but still failed to deliver. I'm guessing with some more guidance and iteration it could have come up with something. reply momojo 24 minutes agoparentprev> the joke itself is rubbish but the \"thinking\" section is fascinating: This is gold. If I was a writer, I'd wring value from that entire thinking-out-loud section and toss the actual punchline. This is weirdly reminiscent of co-programming with CodyAI. It gives me a lot of good 'raw material' and I'm left integrating the last mile stuff. reply monkeydust 3 hours agoparentprevThanks! Playing around with this vs the https://ollama.com/tripplyons/r1-distill-qwen-7b variant and find 7b to be somewhat of sweet spot of getting to the point with minimal (or less) waffle. Certainly, interesting reading their thought processes, value in that might be greater than the answer itself depending on use-case. reply widdershins 3 hours agoparentprevYeesh, that shows a pretty comprehensive dearth of humour in the model. It did a decent examination of characteristics that might form the components of a joke, but completely failed to actually construct one. I couldn't see a single idea or wordplay that actually made sense or elicited anything like a chuckle. The model _nearly_ got there with 'krill' and 'kill', but failed to actually make the pun that it had already identified. reply samdjstephens 3 hours agorootparentYeah it's very interesting... It appears to lead itself astray: the way it looks at several situational characteristics, gives each a \"throw-away\" example, only to then mushing all those examples together to make a joke seems to be it's downfall in this particular case. Also I can't help but think that if it had written out a few example jokes about animals rather than simply \"thinking\" about jokes, it might have come up with something better reply wat10000 33 minutes agoparentprevThis joke is so terrible, I think this might end up being how AI kills us all when it decides it needs us out of the way to make more paperclips. reply reissbaker 3 hours agoparentprevFWIW, you can also try all of the distills out in BF16 on https://glhf.chat (either in the UI or via the API), including the 70b. Personally I've been most impressed with the Qwen 32b distill. (Disclosure: I'm the cofounder) reply reissbaker 8 minutes agorootparent(And here's the output of the \"pelican and the walrus in a tearoom\" joke from DeepSeek's distilled 70b... Mildly better?)Alright, I'm supposed to come up with a joke about a pelican and a walrus in a tea room. Hmm, sounds like a classic setup for a funny situation. Let me think about the characteristics of these animals that could be used humorously. Okay, so pelicans are known for their large beaks, right? They can carry a lot of water in them. Walruses have those big tusks and blubbery bodies. Maybe I can play on the idea of them trying to have a tea party but their physical traits causing some trouble. Wait, being in a tea room, they might be trying to sip tea, but their size or features get in the way. The pelican's beak could be problematic with the cup. And the walrus's size might knock things over or make a mess. Let me consider the flow. Maybe the pelican struggles with the teacup because of his beak, and the walrus has a comment about it. Then the walrus tries to sip but ends up splashing tea everywhere. That could lead to a funny exchange. Putting it together: Pelican says something self-deprecating about his beak not being suited for tea. Then the walrus, who perhaps agrees, tries to sip and splashes tea, making them both laugh. That feels natural and funny. I should make sure the punchline is clear and the dialogue flows smoothly. Maybe start with the pelican struggling, then the walrus makes a comment, and their interaction leads to the humorous conclusion. Yeah, that should work.Why did the pelican and the walrus get kicked out of the tea room? Because the pelican kept dipping his beak in the wrong cup, and the walrus kept breaking the delicate china with his tusks. They just couldn’t “sea” themselves fitting in! reply lmc 2 hours agoparentprev> The walrus might say something like, \"We have the biggest catch in town,\" while the pelican adds a line about not catching any fish recently. It should've stopped there :D reply linsomniac 3 hours agoparentprev>a joke about a pelican and Tell me you're simonw without telling me you're simonw... reply tkgally 5 hours agoprevOver the last two weeks, I ran several unsystematic comparisons of three reasoning models: ChatGPT o1, DeepSeek’s then-current DeepThink, and Gemini 2.0 Flash Thinking Experimental. My tests involved natural-language problems: grammatical analysis of long texts in Japanese, New York Times Connections puzzles, and suggesting further improvements to an already-polished 500-word text in English. ChatGPT o1 was, in my judgment, clearly better than the other two, and DeepSeek was the weakest. I tried the same tests on DeepSeek-R1 just now, and it did much better. While still not as good as o1, its answers no longer contained obviously misguided analyses or hallucinated solutions. (I recognize that my data set is small and that my ratings of the responses are somewhat subjective.) By the way, ever since o1 came out, I have been struggling to come up with applications of reasoning models that are useful for me. I rarely write code or do mathematical reasoning. Instead, I have found LLMs most useful for interactive back-and-forth: brainstorming, getting explanations of difficult parts of texts, etc. That kind of interaction is not feasible with reasoning models, which can take a minute or more to respond. I’m just beginning to find applications where o1, at least, is superior to regular LLMs for tasks I am interested in. reply torginus 4 hours agoparento1 is impressive, I tried feeding it some of the trickier problems I have solved (that involved nontrivial algorithmic challenges) over the past few months, and it managed to solve all of them, and usually came up with slightly different solutions than I did, which was great. However what I've found odd was the way it formulated the solution was in excessively dry and obtuse mathematical language, like something you'd publish in an academic paper. Once I managed to follow along its reasoning, I understood what it came up with could essentially be explain in 2 sentences of plain english. On the other hand, o1 is amazing at coding, being able to turn an A4 sheet full of dozens of separate requirements into an actual working application. reply manmal 1 hour agorootparentDo you mean o1-preview or the current o1? I rarely get anything really useful out of the current one ($20 subscription, not the 200 one). They seem to have seriously nerfed it. reply rcpt 3 hours agoparentprevI found that reasoning models were good for CAD. I can ask for openSCAD code to produce and then add to some kind of shape reply starfezzy 4 hours agoparentprevCan it solve easy problems yet? Weirdly, I think that's an important milestone. Prompts like, \"Give me five odd numbers that don't have the letter 'e' in their spelling,\" or \"How many 'r's are in the word strawberry?\" I suspect the breakthrough won't be trivial that enables solving trivial questions. reply msoad 4 hours agorootparent> Give me five odd numbers that don't have the letter 'e' in their spelling Compare the reasoning times!!! 84s vs 342s R1 (Thought for 84 seconds) No odd number in English avoids the letter 'e' in its spelling. The request for five such numbers cannot be fulfilled. o1 Pro (Thought for 5 minutes and 42 seconds) No standard English spelling of an odd number can avoid “e.” Every odd digit (one, three, five, seven, nine) already includes “e,” so once you build any odd number out of those digits, the spelled‐out form will contain “e.” As a result, there are no such odd numbers in standard English without an “e” in their name. reply mattkrause 2 hours agorootparentEven after five minutes, the logic has a (small) hole. Not all odd spell out the digit: thirteen, fifteen (and maybe eleven?) are odd but don’t have an ‘e’ in the word’s “digit” part, though they obviously do elsewhere. reply ben_w 1 hour agorootparentIf the answer is supposed to be logically rigorous, o1 is incomplete for the reason you say. If I was treating this as a lateral thinking puzzle (does anyone still do those for interview questions?) rather than a sensible request, I'd give numbers in a non-Latin character set, at which point it's easy: 一三五七九 (But even this only works for silly games, IMO). reply d0mine 1 hour agorootparentprevUno https://en.wiktionary.org/wiki/uno reply coffeebeqn 3 hours agorootparentprevTook 1m 36s for me. My default prompt is a bit different “think from first principles”. It’s pretty verbose but I enjoyed looking through all the work it did. Pretty impressive ! reply diggan 3 hours agorootparentprev> Can it solve easy problems yet? Weirdly, I think that's an important milestone. Easy for who? Some problems are better solved in one way compared to another. In the case of counting letters and such, it is not a easy problem, because of how the LLM tokenizes their input/outputs. On the other hand, it's really simple problem for any programming/scripting language, or humans. And then you have problems like \"5142352 * 51234\" which is trivial problems for any basic calculator, but very hard for a human or a LLM. Or \"problems\" like \"Make a list of all the cities that had celebrity from there who knows how to program in Fortan\", would be a \"easy\" problem for a LLM, but pretty much a hard problem anything else than Wikidata, assuming both LLM/Wikidata have data about it in their datasets. > I suspect the breakthrough won't be trivial that enables solving trivial questions. So with what I wrote above in mind, LLMs already solve trivial problems, assuming you think about the capabilities of the LLM. Of course, if you meant \"trivial for humans\", I'll expect the answer to always remain \"No\", because things like \"Standing up\" is trivial for humans, but it'll never be trivial for a LLM, it doesn't have any legs! reply sdesol 1 hour agorootparent> And then you have problems like \"5142352 * 51234\" which is trivial problems for any basic calculator, but very hard for a human or a LLM. I think LLMs are getting better (well better trained) on dealing with basic math questions but you still need to help them. For example, if you just ask it them to calculate the value, none of them gets it right. http://beta.gitsense.com/?chat=876f4ee5-b37b-4c40-8038-de38b... However, if you ask them to break down the multiplication to make it easier, three got it right. http://beta.gitsense.com/?chat=ef1951dc-95c0-408a-aac8-f1db9... reply diggan 1 hour agorootparent> I think LLMs are getting better (well better trained) on dealing with basic math questions but you still need to help them I feel like that's a fools errand. You could already in GPT3 days get the LLM to return JSON and make it call your own calculator, way more efficient way of dealing with it, than to get a language model to also be a \"basic calculator\" model. Luckily, tools usage is easier than ever, and adding a `calc()` function ends up being really simple and precise way of letting the model focus on text+general tool usage instead of combining many different domains. Add a tool for executing Python code, and suddenly it gets way broader capabilities, without having to retrain and refine the model itself. reply sdesol 1 hour agorootparentI personally think getting LLMs to better deal with numbers will go a long way to making them more useful for different fields. I'm not an accountant, so I don't know how useful it would be. But being able to say, here are some numbers do this for scenario A and this for scenario B and so forth might be useful. Having said that, I do think models that favours writing code and using a \"LLM interpretation layer\" may make the most sense for the next few (or more) years. reply wat10000 26 minutes agorootparentBased on how humans operate, I’d say they should have a good “intuition” for approximate results, but use an external calculator for the exact numbers. Even if you can train it to be accurate, it’s going to be tremendously inefficient compared to calling out to some external service that can directly use the arithmetic hardware in the computer. reply sdesol 11 minutes agorootparentI agree and this thread got me thinking about how I can package WASM in my chat app to execute LLM generated code. I think a lot can be achieve today with a well constructed prompt. For example, the prompt can say, if you are asked to perform a task like calculating numbers, write a program in JavaScript that can be compiled to WASM and wait for the response before continuing. Philpax 5 minutes agorootparentDon't really need WASM for that have you tried Claude Artifacts? cchance 2 hours agorootparentprevNot gonna lie ... wasnt expecting a correct answer... The thought process and confirmation of the calculation were LONG and actually quite amazing to watch it deduce and then calculate in different ways to confirm The product of 5,142,352 and 51,234 is calculated as follows: 1. Break down the multiplication using the distributive property: (5,142,352 times 51,234 = (5,000,000 + 142,352) times (50,000 + 1,234)) 2. Expand and compute each part: (5,000,000 times 50,000 = 250,000,000,000) (5,000,000 times 1,234 = 6,170,000,000) (142,352 times 50,000 = 7,117,600,000) (142,352 times 1,234 = 175,662,368) 3. Sum all parts: (250,000,000,000 + 6,170,000,000 = 256,170,000,000) (256,170,000,000 + 7,117,600,000 = 263,287,600,000) (263,287,600,000 + 175,662,368 = 263,463,262,368) Final Answer: 263463262368 reply michaelt 2 hours agorootparentprev> Easy for who? Consider things from a different angle. The hype men promoting the latest LLMs say the newest models produce PhD-level performance across a broad suite of benchmarks; some have even claimed that ChatGPT 4 is an early version of an AGI system that could become super-intelligent. So the advertising teams have set the bar very high indeed. As smart as the smartest humans around, maybe smarter. The bar they have set for themselves doesn't allow for any \"oh but the tokenisation\" excuses. reply danielmarkbruce 1 hour agorootparentMost human math phd's have all kinds of shortcomings. The idea that finding some \"gotchas\" shows that they are miles off the mark with the hype is absurd. reply michaelt 1 hour agorootparent> Most human math phd's have all kinds of shortcomings. I know a great many people with PhDs. They're certainly not infallible by any means, but I can assure you, every single one of them can correctly count the number of occurrences of the letter 'r' in 'strawberry' if they put their mind to it. reply danielmarkbruce 1 hour agorootparentI'll bet said phds can't answer the equivalent question in a language they don't understand. LLMs don't speak character level english. LLMs are, in some stretched meaning of the word, illiterate. If LLMs used character level tokenization it would work just fine. But we don't do that and accept the trade off. It's only folks who have absolutely no idea how LLMs work that find the strawberry thing meaningful. reply HarHarVeryFunny 14 minutes agorootparentI don't think that (sub-word) tokenization is the main difficulty. Not sure which models still fail the \"strawberry\" test, but I'd bet they can at least spell strawberry if you ask, indicating that breaking the word into letters is not the problem. The real issue if that you're asking a prediction engine (with no working memory or internal iteration) to solve an algorithmic task. Of course you can prompt it to \"think step by step\" to get around these limitations, and if necessary suggest an approach (or ask it to think of one?) to help it keep track of it's letter by letter progress through the task. reply michaelt 16 minutes agorootparentprevYou say that very confidently but why shouldn't an LLM have learned a character-level understanding of tokens? LLMs would perform very badly on tasks like checking documents for spelling errors, processing OCRed documents, pluralising, changing tenses and handling typos in messages from users if they didn't have a character-level understanding. It's only folks who have absolutely no idea how LLMs work that would think this task presents any difficulty whatsoever for a PhD-level superintelligence :) reply sdesol 33 minutes agorootparentprev> It's only folks who have absolutely no idea how LLMs work that find the strawberry thing meaningful. I think it is meaningful in that it highlights how we need to approach things a bit differently. For example, instead of asking \"How many r's in strawberry?\", we say \"How many r's in strawberry? Show each character in an ordered list before counting. When counting, list the position in the ordered list.\" If we do this, every model that I asked got it right. https://beta.gitsense.com/?chat=167c0a09-3821-40c3-8b0b-8422... There are quirks we need to better understand and I would say the strawberry is one of them. Edit: I should add that getting LLMs to count things might not be the best way to go about it. Having it generate code to count things would probably make more sense. reply wat10000 23 minutes agorootparentprevI’ll bet said PhDs will tell you they don’t know instead of confidently stating the wrong answer in this case. Getting LLMs to express an appropriate level of confidence in their output remains a major problem. reply diggan 1 hour agorootparentprev> The hype men promoting the latest LLMs say the newest models produce PhD-level performance across a broad suite of benchmarks; some have even claimed that ChatGPT 4 is an early version of an AGI system that could become super-intelligent. Alright, why don't you go and discuss this with the people who say those things instead? No one made those points in this subthread, so not sure why they get brought up here. reply salviati 4 hours agorootparentprevI would argue anything requiring insights on spelling is a hard problem for an LLM: they use tokens, not letters. Your point still stands, but you need different examples IMO. reply danielmarkbruce 1 hour agorootparentprevThere is no breakthrough required, it's trivial. It's just that by making a model do that, you'll screw it up on several other dimensions. Asking a question like this only highlights the questioners complete lack of understanding of LLMs rather than an LLMs inability to do something. reply synergy20 4 hours agoparentpreva dumb question,how did you use deepseek,e.g r1? reply tkgally 4 hours agorootparentI use it at https://chat.deepseek.com/ . It’s free but requires a log-in. Now, when I hover over the “DeepThink” button below the prompt field, a pop-up appears saying “Use DeepSeek-R1 to solve reasoning problems.” reply pizza 5 hours agoprevHoly moly.. even just the Llama 8B model trained on R1 outputs (DeepSeek-R1-Distill-Llama-8B), according to these benchmarks, is stronger than Claude 3.5 Sonnet (except on GPQA). While that says nothing about how it will handle your particular problem, dear reader, that does seem.. like an insane transfer of capabilities to a relatively tiny model. Mad props to DeepSeek! reply qeternity 4 hours agoparentThis says more about benchmarks than R1, which I do believe is absolutely an impressive model. For instance, in coding tasks, Sonnet 3.5 has benchmarked below other models for some time now, but there is fairly prevalent view that Sonnet 3.5 is still the best coding model. reply thegeomaster 2 hours agorootparentLiveBench (which I like because it tries very hard to avoid contamination) ranks Sonnet 3.5 second only to o1 (which is totally expected). reply parav 1 hour agorootparentLiveCodingBench has DeepSeekR1 at #3 after O1-high and O1-medium https://livecodebench.github.io/leaderboard.html reply behnamoh 2 hours agorootparentprevno, sonnet 3.5 is #7 on LiveBench, even below DeepSeek V3. reply thegeomaster 2 hours agorootparentThe parent comment was talking about coding specifically, not the average score. I see o1 at 69.69, and Claude 3.5 Sonnet at 67.13. reply bochoh 4 hours agoparentprevI wonder if (when) there will be a GGUF model available for this 8B model. I want to try it out locally in Jan on my base m4 Mac mini. I currently run Llama 3 8B Instruct Q4 at around 20t/s and it sounds like this would be a huge improvement in output quality. reply DrPhish 3 hours agorootparentMaking your own ggufs is trivial: https://rentry.org/tldrhowtoquant/edit It's a bit harder when they've provided the safetensors in FP8 like for the DS3 series, but these smaller distilled models appear to be BF16, so the normal convert/quant pipeline should work fine. reply bochoh 3 hours agorootparentThanks for that! It seems that unsloth actually beat me to [it](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-...)! Edit: Running the DeepSeek-R1-Distill-Llama-8B-Q8_0 gives me about 3t/s and destroys my system performance on the base m4 mini. Trying the Q4_K_M model next. reply bugglebeetle 3 hours agorootparentprevYC’s own incredible Unsloth team already has you covered: https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B reply noodletheworld 4 hours agoparentprev> according to these benchmarks Come onnnnnn, when someone releases something and claims it’s “infinite speed up” or “better than the best despite being 1/10th the size!” do your skepticism alarm bells not ring at all? You can’t wave a magic wand and make an 8b model that good. I’ll eat my hat if it turns out the 8b model is anything more than slightly better than the current crop of 8b models. You cannot, no matter hoowwwwww much people want it to. be. true, take more data, the same architecture and suddenly you have a sonnet class 8b model. > like an insane transfer of capabilities to a relatively tiny model It certainly does. …but it probably reflects the meaninglessness of the benchmarks, not how good the model is. reply deepsquirrelnet 2 hours agorootparentIt’s somewhere in between, really. This is a rapidly advancing space, so to some degree, it’s expected that every few months, new bars are being set. There’s also a lot of work going on right now showing that small models can significantly improve their outputs by inferencing multiple times[1], which is effectively what this model is doing. So even small models can produce better outputs by increasing the amount of compute through them. I get the benchmark fatigue, and it’s merited to some degree. But in spite of that, models have gotten really significantly better in the last year, and continue to do so. In some sense, really good models should be really difficult to evaluate, because that itself is an indicator of progress. [1] https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling... reply qqqult 5 hours agoprevKind of insane how a severely limited company founded 1 year ago competes with the infinite budget of Open AI Their parent hedge fund company isn't huge either, just 160 employees and $7b AUM according to Wikipedia. If that was a US hedge fund it would be the #180 largest in terms of AUM, so not small but nothing crazy either reply jstummbillig 5 hours agoparentThe nature of software that has not moat built into it. Which is fantastic for the world, as long as some companies are willing to pay the premium involved in paving the way. But man, what a daunting prospect for developers and investors. reply HeatrayEnjoyer 5 hours agorootparentI'm not sure we should call it \"fantastic\" The negative downsides begin at \"dystopia worse than 1984 ever imagined\" and get worse from there reply rtsil 4 hours agorootparentThat dystopia is far more likely in a world where the moat is so large that a single company can control all the llms. reply rvnx 4 hours agorootparentprevThe way it is going, we are all going be busy with WW3 soon so we won’t have much time to worry about that. reply CuriouslyC 4 hours agorootparentprevThat dystopia will come from an autocratic one party government with deeply entrenched interests in the tech oligarchy, not from really slick AI models. reply markus_zhang 2 hours agorootparentprevThe most is there I think: capital to train models and buy good data, and then pull strings to make it into everyone's computer. It's indeed very dystopia. reply sschueller 5 hours agoparentprevThis is the reason I believe the new AI chip restriction that was just put in place will backfire. reply iury-sza 4 hours agorootparentAlrdy did. Forced China to go all in in the chip race and they're catching up fast. reply logicchains 50 minutes agorootparentI wonder if the US will end the restrictions if China pulls ahead in LLM ability, considering they serve no purpose if China's already ahead? Although given they seem to want to ban Chinese drones without any competitive local alternative, maybe not. reply rvnx 4 hours agorootparentprevDeepseek can run on Huawei Ascend chips already and Nvidia pretended respecting the restrictions with the H800 (and was never punished for that) reply behnamoh 2 hours agorootparentprevGood. As much as I don't like some things about China, but damn it they're really good at cutting down costs. I look forward to their version of Nvidia GPUs at half the price. reply istjohn 1 hour agorootparentAre you in the US? Americans aren't going to get those, just like we aren't going get cheap Chinese electric cars. reply fassssst 2 hours agoparentprevThey’re probably training on outputs of existing models. reply imtringued 3 hours agoparentprevIt's pretty clear, because OpenAI has no clue what they are doing. If I was the CEO of OpenAI, I would have invested significantly in catastrophic forgetting mitigations and built a model capable of continual learning. If you have a model that can learn as you go, then the concept of accuracy on a static benchmark would become meaningless, since a perfect continual learning model would memorize all the answers within a few passes and always achieve a 100% score on every question. The only relevant metrics would be sample efficiency and time to convergence. i.e. how quickly does the system learn? reply behnamoh 2 hours agorootparent> I would have invested significantly in catastrophic forgetting mitigations and built a model capable of continual learning. You say it as if it's an easy thing to do. These things take time man. reply SOLAR_FIELDS 3 hours agorootparentprevIt's actually great if the end result is that the incumbent with infinite money that has unrealistic aspirations of capturing a huge section of the sector lights all the money on fire. It's what happened with Magic Leap and I think everyone can agree that the house of Saud tossing their money into a brilliant blaze like that is probably better than anything else they would have wanted to do with that money. And if we get some modest movements forward in that technical space because of that, all the better. Sometimes capitalism can be great, because it funnels all the greed into some hubris project like this and all the people that are purely motivated by greed can go spin their wheels off in the corner and minimize the damage they do. And then some little startup like Deepseek can come along and do 90% of the job for 1% of the money reply gunian 2 hours agorootparenttangential but kind of curious to see models and more generally tech get dragged into geopolitical baron feuds second time seeing that the house of saud & their tech not popular on HN lol reply SOLAR_FIELDS 2 hours agorootparentWell, it’s not exactly new news. Saudi Arabia has a long and storied record of being rich, investing in tech, and human rights abuses. That conversation has been going on for a very long time. reply Squarex 5 hours agoparentprevnext [30 more] [flagged] diggan 5 hours agorootparentWhy could one assume so? Are there any explicit links? Or just because it's a Chinese company it's of course compromised and to be shunned? reply tokioyoyo 4 hours agorootparentTo my understanding, most people, even in tech, disregard and look down on Chinese software. For some reason they also have a picture of 10 CCP employees sitting on each dev team, reviewing code before it gets released on GitHub. There was a conversation with some western dev how they kept saying Chinese devs don’t work with scale like Meta/Google do, so they don’t have experience in it either. That was also an interesting thread to read, because without thinking about anything else, WeChat itself has more than 1B users. I’m not sure if it’s pure ignorance, or just people want to feel better about themselves. I agree that a good chunk of Chinese apps’ UX is trash though. reply coliveira 2 hours agorootparent> Chinese apps’ UX is trash It is trash because you're thinking with the mind of a Westerner. These apps are created and optimized for Chinese audiences, and they interact in a different way. reply djtango 2 hours agorootparentThey definitely do some things better. Taobao's shop by image is pretty game changing. Whether or not they were the first to do it, they seem to be the most successful iteration of it. I feel like Chinese UX flows tend to be more clunky than Western ones but I have a certain liking for high information density apps, and find uncluttered screens sometimes a bit annoying and overly patronising. I thought bullet chat on Bilibili was a very fun concept that probably doesn't translate quite as well to western media but YouTube has come up with a nifty half way by flashing comments with timestamps under the video reply tokioyoyo 2 hours agorootparentprevYeah, totally fair. I guess it’s a very subjective opinion, given I grew up in the west, and was introduced to the iPhone era gradually. Like i went through Internet of 90s, desktop apps, old laptops, PCs and etc., and then eventually landing on daily iPhone usage. I can see how it might be a bit different if you went from most using nothing to Android/iPhone society. That being said, they still use apps like Chrome, Safari, all the other common apps like ours. So they have both UXs available for them, I guess. reply wumeow 2 hours agorootparentprev> To my understanding, most people, even in tech, disregard and look down on Chinese software Historically, if Chinese software has been installed on your computer, it's been malware. reply Squarex 2 hours agorootparentI have not said that Deepseek models are bad. Quite the opposite. I'm impressed by them. I have just questiened that they are just some chinese startup. reply tokioyoyo 2 hours agorootparentprevYes, they also had very bad hardware in the past. That does not say anything to their current level of exports. reply wumeow 1 hour agorootparentNo, they absolutely export malware still. All of DJI's apps need to be sideloaded on android because the obfuscated data collection they do is not allowed in Play Store apps[0]. TikTok uses an obfuscated VM to do user tracking[1]. Then there's the malware that the US government has to routinely delete from compromised computers [2][3] Chinese software deserves the reputation it has. [0] https://arstechnica.com/information-technology/2020/07/chine... [1] https://www.nullpt.rs/reverse-engineering-tiktok-vm-1 [2] https://arstechnica.com/tech-policy/2025/01/fbi-forces-chine... [3] https://arstechnica.com/security/2024/01/chinese-malware-rem... reply tokioyoyo 1 hour agorootparentFair points. I guess, market doesn’t care about software being malware, given both of your examples are the leading products in the world within their own market segments. Like there are 1.4B people in China, obviously there are bad actors. Writing off an average software as a malware ridden crap is kinda weird. And again, the main users of Chinese software are… mainland Chinese. Whether we like it or not, they have very impressive track record of making it run and scale to humongous users. Anyways, I think I deviated far from my point and sound like a general China-shill. reply yehosef 4 hours agorootparentprevThe chinese are great at taking secrets. Chatbots are great places for people to put in secrets. Other people say \"we're not going to use your data\" with a Chinese company you're pretty much guaranteed that China mothership is going to have access to it. The open source model is just the bait to make you think they are sincere and generous chat.deepseek.com is the real game. Almost no-one is going to run these models they are just going to post their secrets (https://www.cyberhaven.com/blog/4-2-of-workers-have-pasted-c...) reply greenchair 4 hours agorootparentprevyep because it is chinese company of strategic importance. reply quantum_state 2 hours agorootparentprevSo sad ppl behaved like someone completely brainwashed… reply Squarex 5 hours agorootparentprevI am not going pretend to know the specifics, but don't the have mandatory Communist Party Committee? Comming from former eastern block country, I assume that they tend to have the final voice. reply diggan 5 hours agorootparentAre you talking about State-Owned Enterprise? Because yes, those have government tighter oversight and control, but I don't think this company is a SOE, at least from what I can tell. From the rest, it works the same as in the US. If the government comes with a lawful order for you to do something, you'll do it or be held responsible for ignoring it. reply cbg0 4 hours agorootparent> but I don't think this company is a SOE, at least from what I can tell. There's no way to really tell. An authoritarian state like China can decide to control this company at any time, if it chooses to, through more direct or indirect means. A well known story on this subject: https://www.wired.com/story/jack-ma-isnt-back/ reply coliveira 2 hours agorootparentIt doesn't need to be an authoritarian government. The US government can proclaim a company to be of \"national interest\" at any time and thus determine what it can export or not, as it has done repeatedly over the last few years. reply cbg0 2 hours agorootparentRestricting tech exports is not the same thing as the government taking control of a company. reply coliveira 1 hour agorootparentReally? Would the company subject itself to this otherwise? reply cbg0 27 minutes agorootparentNo company would subject itself to any laws of it didn't have to either. You're trying very hard to make it seem like China isn't doing anything different than western countries for some reason. reply Squarex 5 hours agorootparentprevI believe that private chinese companies still have to accompany communist party members atleast as employees. But again, I don't know the specifics. reply numpad0 4 hours agorootparentI think slight variations of that happens everywhere. Chinese companies have legally required CCP connections, which sounds ominous, but American companies of substantial scale will have ex-government employees, resources allocated for lobbying, and connections to senators. The difference is whether it's codified and imposed or implicitly required for survival. (not that I support CCP, the requirement do sound ominous to me) reply coliveira 2 hours agorootparentExactly, in the US the big companies also enter the government complex through board memberships and collaboration with 3 letter agencies, just like in China. reply TheTaytay 3 hours agorootparentprevSquarex is responding in good faith and is being downvoted. We don’t downvote for simple disagreement around here. (We shouldn’t postulate on rationale behind downvotes, but it’s not a good look for criticism to be downvoted regularly) reply davedx 3 hours agorootparentprev> I don't think this company is a SOE, at least from what I can tell. How did you check? reply Squarex 5 hours agorootparentprev@Mashimo If the party would see them as strategic in their competition with the United States I am sure the money would not be the main problem. reply Mashimo 5 hours agorootparentprevLets assume they have a party member in their ranks, how will that result in unlimited money? reply markus_zhang 2 hours agorootparentprevCPC consists of higher management so yeah they have the final voice, just like every other companies. The antidote for the CCP stuffs, is to alter your mind and accept that the CCP is no longer an ideological party, but a club of social elites. Whether that's a good thing is of course open to debate. reply phillipcarter 3 hours agorootparentprev...and the US government doesn't provide grants for research and various other incentives for for-profit companies? The CCP has plenty of problems it needs to solve for itself that don't involve releasing open source AI models. reply wrasee 5 hours agoparentprevExcept it’s not really a fair comparison, since DeepSeek is able to take advantage of a lot of the research pioneered by those companies with infinite budgets who have been researching this stuff in some cases for decades now. The key insight is that those building foundational models and original research are always first, and then models like DeepSeek always appear 6 to 12 months later. This latest move towards reasoning models is a perfect example. Or perhaps DeepSeek is also doing all their own original research and it’s just coincidence they end up with something similar yet always a little bit behind. reply matthewdgreen 4 hours agorootparentThis is what many folks said about OpenAI when they appeared on the scene building on foundational work done at Google. But the real point here is not to assign arbitrary credit, it’s to ask how those big companies are going to recoup their infinite budgets when all they’re buying is a 6-12 month head start. reply wrasee 4 hours agorootparentThis is true, and practically speaking it is how it is. My point was just not to pretend that it’s a fair comparison. reply mattlutze 4 hours agorootparentFor-profit companies don't have to publish papers on the SOTA they product. In previous generations and other industries, it was common to keep some things locked away as company secrets. But Google, OpenAI and Meta have chosen to let their teams mostly publish their innovations, because they've decided either to be terribly altruistic or that there's a financial benefit in their researchers getting timely credit for their science. But that means then that anyone with access can read and adapt. They give up the moat for notariety. And it's a fine comparison to look at how others have leapfrogged. Anthropic is similarly young—just 3 and a bit years old—but no one is accusing them of riding other companies' coat tails in the success of their current frontier models. A final note that may not need saying is: it's also very difficult to make big tech small while maintaining capabilities. The engineering work they've done is impressive and a credit to the inginuity of their staff. reply wrasee 2 hours agorootparentAnthropic was founded in part from OpenAI alumni, so to some extent it’s true for them too. And it’s still taken them over 3 years to get to this point. reply miohtama 3 hours agorootparentprevThese companies could not retain the best talent if they cannot publish:an individual researcher needs to get his name there \"to get better.\" reply byefruit 4 hours agorootparentprevThis is pretty harsh on DeepSeek. There are some significant innovations behind behind v2 and v3 like multi-headed latent attention, their many MoE improvements and multi-token prediction. reply wrasee 4 hours agorootparentI don’t think it’s that harsh. And I don’t also deny that they’re a capable competitor and will surely mix in their own innovations. But would they be where they are if they were not able to borrow heavily from what has come before? reply djtango 4 hours agorootparentWe all stand on the shoulder of giants? Should every engineer rediscover the Turing machine and the Von Neumann architecture? reply wrasee 3 hours agorootparentOf course not. But in this context the point was simply that it’s not exactly a fair comparison. I’m reminded how hard it is to reply to a comment and assume that people will still interpret that in the same context as the existing discussion. Never mind. reply dcow 3 hours agorootparentDon’t get salty just because people aren't interested in your point. I for one, think it’s an entirely _fair_ comparison because culture is transitive. People are not ignoring the context of your point, they’re disagreeing with the utility of it. If I best you in a 100m sprint people don’t look at our training budgets and say oh well it wasn’t a fair competition you’ve been sponsored by Nike and training for years with specialized equipment and I just took notes and trained on my own and beat you. It’s quite silly in any normal context. reply dcow 3 hours agorootparentprevSure, it’s a point. Nobody would be where they are if not for the shoulders of those that came before. I think there are far more interesting points in the discussion. reply techload 4 hours agorootparentprevYou can learn more about DeepSeek and Liang Wenfeng here: https://www.chinatalk.media/p/deepseek-ceo-interview-with-ch... reply versteegen 3 hours agorootparentThis article is amazing. It explains not just why DeepSeek is so successful, but really indicates that innovators elsewhere will be too: that extensive opportunities exist for improving transformers. Yet few companies do (not just China, but everywhere): incredible amounts are spent just replicating someone else's work with a fear of trying anything substantially different. reply qqqult 3 hours agorootparentprevgreat article, thank you reply wrasee 4 hours agorootparentprevAlso don’t forget that if you think some of the big names are playing fast and loose with copyright / personal data then DeepSeek is able to operate in a regulatory environment that has even less regard for such things, especially so for foreign copyright. reply rvnx 4 hours agorootparentWhich is great for users. We all benefit from Libgen training, and generally copyright laws do not forbid reading copyrighted content, but to create derivative works, but in that case, at which point a work is derivative and at which point it is not ? On the paper all works is derivative from something else, even the copyrighted ones. reply wrasee 4 hours agorootparentDisrespecting copyright and personal data is good for users? I guess I disagree. I would say that it’s likely great for the company’s users, but not so great for everyone else (and ultimately, humankind). reply h8hawk 3 hours agorootparentprevThat’s totally not true. https://epoch.ai/gradient-updates/how-has-deepseek-improved-... reply gizmo 4 hours agorootparentprevFast following is still super hard. No AI startup in Europe can match DeepSeek for instance, and not for lack of trying. reply netdevphoenix 4 hours agorootparentmistral probably would reply wrasee 4 hours agorootparentprevMistral. reply rvnx 4 hours agorootparentMistral is mostly a cheap copy of LLaMA reply wrasee 4 hours agorootparentI would extend the same reasoning to Mistral as DeekSeek as to where they sit on the innovation pipeline. That doesn’t have to be a bad thing (when done fairly), only to remain mindful that it’s not a fair comparison (to go back to the original point). reply netdur 5 hours agorootparentprevDidn't DeepSeek's CEO say that Llama is two generations behind, and that's why they didn't use their methods? reply tripplyons 4 hours agoprevI just pushed the distilled Qwen 7B version to Ollama if anyone else here wants to try it locally: https://ollama.com/tripplyons/r1-distill-qwen-7b reply fullstackwife 5 hours agoprevI was initially enthusiastic about DS3, because of the price, but eventually I learned the following things: function calling is broken (responding with excessive number of duplicated FC, halucinated names and parameters) response quality is poor (my use case is code generation) support is not responding I will give a try to the reasoning model, but my expectations are low. ps. the positive side of this is that apparently it removed some traffic from anthropic APIs, and latency for sonnet/haikku improved significantly. reply mtkd 3 hours agoparentThe company has just over 100 employees, built V3 with $5.5M of compute and is quietly releasing tangible product without any hyperbolic PR in advance They were fairly unknown until 26th Dec in west reply fullstackwife 2 hours agorootparentyou are right, but please don't forget they were publishing some benchmark results which were great reply Gracana 28 minutes agoparentprevI was looking to see how you're supposed to configure v3, then realized you're probably using the API, and came across this: > The current version of the deepseek-chat model's Function Calling capabilitity is unstable, which may result in looped calls or empty responses. We are actively working on a fix, and it is expected to be resolved in the next version. https://api-docs.deepseek.com/guides/function_calling That's disappointing. reply pmarreck 4 hours agoparentprevI got some good code recommendations out of it. I usually give the same question to a few models and see what they say; they differ enough to be useful, and then I end up combining the different suggestions with my own to synthesize the best possible (by my personal metric, of course) code. reply jerpint 5 hours agoprev> This code repository and the model weights are licensed under the MIT License. DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Wow. They’re really trying to undercut closed source LLMs reply wumeow 3 hours agoparentYep, it's a national strategy. reply chaosprint 5 hours agoprevAmazing progress with this budget. My only concern is that on openrouter.ai it says: \"To our knowledge, this provider may use your prompts and completions to train new models.\" https://openrouter.ai/deepseek/deepseek-chat This is a dealbreaker for me to use it at the moment. reply lhl 4 hours agoparentFireworks, Together, and Hyperbolic all offer DeepSeek V3 API access at reasonable prices (and full 128K output) and none of them will retain/train on user submitted data. Hyperbolic's pricing is $0.25/M tokens, which is actually pretty competitive to even DeepSeek's \"discount\" API pricing. I've done some testing and if you're inferencing on your own system (2xH100 node, 1xH200 node, or 1xMI300X node) sglang performs significantly better than vLLM on deepseek-v3 (also vLLM had an stop token issue for me, not sure if that's been fixed, sglang did not have output oddities). reply gliptic 4 hours agorootparentWhere are you seeing Hyperbolic offering DeepSeek V3 API? I'm only seeing DeepSeek V2.5. reply l33tc0de 3 hours agorootparenthttps://app.hyperbolic.xyz/models/deepseek-v3 reply csomar 5 hours agoparentprevFair compromise for running it for free. The model is open, so you can be 100% certain it's not pinging back if you don't want it to. reply msoad 4 hours agorootparentNo model really can \"call home\". It's the server running it. Luckily for Deepseek there are other providers that guarantee no data collection since the models are open source reply simonw 5 hours agoparentprevYou don't need to worry about that if you are using the open weights models they just released on your own hardware. You can watch network traffic to confirm nothing is being transferred. reply mythz 4 hours agoparentprevWorks great for us as most of our code is public and we can only benefit from more our code of our product or using it being available. Also happy for any of our code expands their training set and improves their models even further given they're one of the few companies creating and releasing OSS SOTA models, which in addition to being able to run it locally ourselves should we ever need to, it allows price competition bringing down the price of a premier model whilst keeping the other proprietary companies price gouging in check. reply lopuhin 4 hours agoparentprevWith distilled models being released, it's very likely they'd be soon served by other providers at a good price and perf, unlike the full R1 which is very big and much harder to serve efficiently. reply HarHarVeryFunny 4 hours agoprevThere are all sorts of ways that additional test time compute can be used to get better results, varying from things like sampling multiple CoT and choosing the best, to explicit tree search (e.g. rStar-Math), to things like \"journey learning\" as described here: https://arxiv.org/abs/2410.18982?utm_source=substack&utm_med... Journey learning is doing something that is effectively close to depth-first tree search (see fig.4. on p.5), and does seem close to what OpenAI are claiming to be doing, as well as what DeepSeek-R1 is doing here... No special tree-search sampling infrastructure, but rather RL-induced generation causing it to generate a single sampling sequence that is taking a depth first \"journey\" through the CoT tree by backtracking when necessary. reply AJRF 2 hours agoprevJust tried hf.co/unsloth/DeepSeek-R1-Distill-Qwen-14B-GGUF:Q4_K_M on Ollama and my oh my are these models chatty. They just ramble on for ages. reply whitehexagon 51 minutes agoparentI find the qwq 32B a bit like that. I asked for a recipe for something in minecraft 1.8, and it was page after page of 'hmm, that still doesnt look right, maybe if I try...' although to be fair I did ask for an ascii art diagram for the result. It will be interesting to try a DeepSeek 32B qwq if that is planned, because otherwise pretty happy with it. I just wish that less development chat was happening within walled gardens because none of these seem to be much help with Zig. reply msoad 4 hours agoprevIt already replaces o1 Pro in many cases for me today. It's much faster than o1 Pro and results are good in most cases. Still, sometimes I have to ask the question from o1 Pro if this model fails me. Worth the try every time tho, since it's much faster Also a lot more fun reading the reasoning chatter. Kinda cute seeing it say \"Wait a minute...\" a lot reply mohsen1 4 hours agoprevI use Cursor Editor and the Claude edit mode is extremely useful. However the reasoning in DeepSeek has been a great help for debugging issues. For this I am using yek[1] to serialize my repo (--max-size 120k tokens) and feed it the test error. Wrote a quick script name \"askai\" so Cursor automatically runs it. Good times! Note: I wrote yek so it might be a little bit of shameless plug! [1] https://github.com/bodo-run/yek reply cadamsdotcom 2 hours agoparentSuper excited to try this workflow, I’m just getting started with Cursor. Any chance you can share that askai script & how you set it up? reply mohsen1 1 hour agorootparentSure! https://gist.github.com/mohsen1/c867d038fc4f46494af4c4024cfc... Add \"when running into issues, run ./scripts/ask.js to get help from DeepSeek\" reply rahimnathwani 2 hours agoparentprevWhen you say Cursor automatically runs it, what do you mean? Do you have a custom task set up in tasks.json, that's triggered by a keyboard shortcut? If so, how do you feed it the test error? Using ${selectedText}? reply mohsen1 1 hour agorootparenthttps://gist.github.com/mohsen1/c867d038fc4f46494af4c4024cfc... Not really. Just in natural language add to Cursor rules that it should invoke the script reply sschueller 5 hours agoprevDoes anyone know what kind of HW is required to run it locally? There are instructions but nothing about HW required. reply simonw 5 hours agoparentThey released a bunch of different sized models and there are already quantized versions showing up on HF. https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-... for example has versions that are 3GB, 4GB, 5GB, 8GB and 16GB. That 3GB one might work on a CPU machine with 4GB of RAM. To get good performance you'll want a GPU with that much free VRAM, or an Apple Silicon machine with that much RAM. reply qqqult 5 hours agoparentprevDeepseek v3 required about 1tb of VRAM / RAM so 10 A100. There are various ways to run it with lower vram if you're ok with way worse latency & throughput Edit: sorry this is for v3, the distilled models can be ran on consumer-grade GPUs reply diggan 5 hours agoparentprevYou can try something like this to get a rough estimate: https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calcul... But you really don't know the exact numbers until you try, a lot of it is runtime/environment context specific. reply heroiccocoa 5 hours agoparentprevIt's just a question of having enough VRAM+RAM to fit the model into memory. reply 999900000999 3 hours agoprevGreat, I've found DeepSeek to consistently be a better programmer than Chat GPT or Claude. I'm also hoping for progress on mini models, could you imagine playing Magic The Gathering against a LLM model! It would quickly become impossible like Chess. reply wielandbr 2 hours agoprevI am curious about the rough compute budget they used for training DeepSeek-R1. I couldn't find anything in their report. Anyone having more information on this? reply zurfer 4 hours agoprevI love that they included some unsuccessful attempts. MCTS doesn't seem to have worked for them. Also wild that few shot prompting leads to worse results in reasoning models. OpenAI hinted at that as well, but it's always just a sentence or two, no benchmarks or specific examples. reply karmakaze 1 hour agoprevI was wondering if this was related to the (failing?) Rabbit R1 product. Doesn't seem to be--a possible (un)fortunate co-incidence. reply gman83 5 hours agoprevFor months now I've seen benchmarks for lots of models that beat the pants off Claude 3.5 Sonnet, but when I actually try to use those models (using Cline VSCode plugin) they never work as well as Claude for programming. reply joshuacc 4 hours agoparentPart of that is that Claude is exceptionally good at turn-based interactions compared to other models that are better at one-shot reasoning. reply raincole 4 hours agoparentprevAfter actually using DeepSeek-V3 for a while, the difference betwen it and Sonnet 3.5 is just glaring. My conclusion is that the hype around DeepSeek is either from 1) people who use LLM a lot more than a programmer can reasonably does so they're very price sensitive, like repackage service providers 2) astroturf. reply hodder 4 hours agoprevJust shows how much fruit is available outside of just throwing more hardware at a problem. Amazing work. reply ldjkfkdsjnv 5 hours agoprevThese models always seem great, until you actually use them for real tasks. The reliability goes way down, you cant trust the output like you can with even a lower end model like 4o. The benchmarks aren't capturing some kind of common sense usability metric, where you can trust the model to handle random small amounts of ambiguity in every day real world prompts reply pizza 5 hours agoparentFair point. Actually probably the best part about having beaucoup bucks like Open AI is being able to chase down all the manifold little ‘last-mile’ imperfections with an army of many different research teams. reply washadjeffmad 5 hours agoparentprevThat seems like both a generalization and hyperbole. How are you envisioning this being deployed? reply aliljet 3 hours agoprevI'm curious about whether anyone is running this locally using ollama? reply ata_aman 3 minutes agoparentfolks over at r/LocalLLaMA reply _imnothere 4 hours agoprevOne point is reliability, as others have mentioned. Another important point for me is censorship. Due to their political nature, the model seemed to be heavily censored on topics such as the CCP and Taiwan (R.O.C.). reply allan_s 4 hours agoparentTo be fair, anthropic and openai censor heavily on a lot of subjects 1. profanity 2. slightly sexual content 3. \"bad taste\" joke that is heavily linked to the fact that they are US-based company, so I guess all AI companies produce a AI model that is politically correct. reply kgeist 2 hours agorootparent\"ChatGPT reveals in its responses that it is aligned with American culture and values, while rarely getting it right when it comes to the prevailing values held in other countries. It presents American values even when specifically asked about those of other countries. In doing so, it actually promotes American values among its users,\" explains researcher Daniel Hershcovich, of UCPH’s Department of Computer Science.\" https://di.ku.dk/english/news/2023/chatgpt-promotes-american... So I don't see much difference, to be honest... reply woadwarrior01 23 minutes agorootparentprevI was recently trying to use the ChatGPT API to build a tiny dataset for a small NLP classifier model and was surprised to find that even relatively benign words like \"escort\" are censored in their API. TBF, Anthropic seems to be a bit better in this regard. reply Me1000 2 hours agoparentprevAlthough I haven’t used these new models. The censorship you describe hasn’t historically been baked into the models as far as I’ve seen. It exists solely as a filter on the hosted version. IOW it’s doing exactly what Gemini does when you ask it an election related question: it just refuses to send it to the model and gives you back a canned response. reply rvnx 4 hours agoparentprevIt will then become the truth, unless the US and EU starts to loosen copyright, which is going to allow higher quality datasets to be ingested. reply synergy20 4 hours agoprevdeepseek v3 and r1 are both 700B models, who has that much memory to run the model locally these days? reply z_ 3 hours agoparentExolabs claims they can distribute the compute over many machines to use memory in aggregate: https://github.com/exo-explore/exo Maybe there is enough memory in many machines. reply NoImmatureAdHom 1 hour agoprevIs there a \"base\" version of DeepSeek that just does straight next-token prediction, or does that question not make sense given how it's made? What is the best available \"base\" next-token predictor these days? reply rvz 4 hours agoprevLooks promising. Let's hope that the benchmarks and experiments for DeepSeek are truly done independently and not tainted or paid for by them (Unlike OpenAI with FrontierMath.) reply danielhanchen 3 hours agoprevFor anyone wanting GGUFs, I uploaded them to https://huggingface.co/collections/unsloth/deepseek-r1-all-v... There's the distilled R1 GGUFs for Llama 8B, Qwen 1.5B, 7B, 14B, and I'm still uploading Llama 70B and Qwen 32B. Also I uploaded a 2bit quant for the large MoE (200GB in disk size) to https://huggingface.co/unsloth/DeepSeek-R1-GGUF reply brookman64k 2 hours agoparentThank you. Which is currently the most capable version running reasonably fast on a 3090 (24GB of VRAM)? reply danielhanchen 1 hour agorootparentThe Llama distilled version Q4_K_M should be reasonably fast and good!! reply nextworddev 3 hours agoprev [–] Deepseek is well known to have ripped off OpenAI APIs extensively in post training, embarrassingly so that it sometimes calls itself “As a model made by OpenAI”. At least don’t use the hosted version unless you want your data to go to China reply lordofgibbons 2 hours agoparentWhy do you care how they trained the model? If OAI can train on copyrighted material, then morally, I see no problem with others training on their outputs too. For what it's worth, even XAI's chatbot referred to itself as being trained by OAI, simply due to the amount of ChatGPT content available on the web. reply Argonaut998 2 hours agoparentprev [–] Just like OAI and copyrighted content. And I would rather my data go to China than the US, personally. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DeepSeek-R1 and DeepSeek-R1-Zero are first-generation reasoning models, with DeepSeek-R1 addressing issues like repetition and language mixing seen in DeepSeek-R1-Zero.",
      "The models, including six distilled versions, are open-sourced, with DeepSeek-R1-Distill-Qwen-32B achieving state-of-the-art results in reasoning, code, and math tasks.",
      "These models are available for download on HuggingFace, and users can interact with them via a chat website or an OpenAI-Compatible API, with instructions for local deployment provided."
    ],
    "commentSummary": [
      "DeepSeek-R1 is an advanced reasoning model that improves upon issues like repetition and language mixing by using cold-start data before reinforcement learning. It outperforms the QwQ model in experiments, providing a better user experience and more diverse answer strategies, and is open-sourced under the MIT license for broad evaluation. The model introduces a pipeline for teaching existing models reasoning and alignment with human preferences, with fine-tuned Llama and Qwen models also open-sourced, potentially rivaling OpenAI's offerings, though data usage and censorship concerns persist."
    ],
    "points": 656,
    "commentCount": 215,
    "retryCount": 0,
    "time": 1737376678
  },
  {
    "id": 42763386,
    "title": "UK's hardware talent is being wasted",
    "originLink": "https://josef.cn/blog/uk-talent",
    "originBody": "Back Home UK's elite hardware talent is being wasted. Saturday Aug 3, 2024 By Josef Chen Imperial, Oxford, and Cambridge produce world-class engineers. Yet post-graduation, their trajectory is an economic tragedy and a hidden arbitrage opportunity. The Stark Reality: Top London hardware engineer graduates: £30,000-£50,000 Silicon Valley equivalent: $150,000+ The reality for most graduates is even grimmer: £25,000 starting salaries at traditional engineering firms Exodus to consulting or finance just because it's compensated better Meanwhile computer science graduates land lucrative jobs in big tech or quant trading, often starting at £100,000+ Examples of wasted potential: Sarah: Built a fusion reactor at 16. Now? Debugging fintech payment systems. James: 3D-printed prosthetic limbs for A-levels. Today? Writing credit risk reports. Alex: Developed AI drone swarms for disaster relief at 18. Graduated with top honours from Imperial. His job? Tweaking a single button's ergonomics on home appliances. These aren't outliers. They're a generation of engineering prodigies whose talents are being squandered. This isn't just wage disparity. It's misallocation of human capital on a national scale. As a hardware founder in London, I've witnessed this firsthand. We have the talent for groundbreaking innovation, but lack the means to realise it. Root Causes: Geographical Constraints: Unlike lucrative software jobs, hardware engineering demands physical presence. Venture Capital: European VCs, mostly bullish on fintech and SaaS, remain wary of hardware. Result? A feedback loop of underinvestment and missed opportunities. Industrial Stagnation: Traditional engineering firms fail to innovate in talent strategies and match compensation, accelerating brain drain. Consequences: Innovation Stagnation: We're not just losing salary differences; we're missing out on the next ARM or Tesla. Economic Ripple Effects: One successful hardware company can spawn dozens of ancillary businesses. We're losing these compounding effects. National Security Implications: In an era where technological edge equals geopolitical power, can we afford to let our best hardware talent languish? Brain Drain Acceleration: We risk losing our top talent permanently to overseas markets. Debunking Common Myths \"London's lower living costs justify lower salaries.\" False. London is around the same as NYC and more expensive than most parts of California and definitely Texas. This also ignores: Wealth Creation and Ecosystem Acceleration: High salaries and successful exits compound dramatically over time, that's why the US has so much more VC and angel capital. Talent attraction: Top jobs draw global talent. Example: Google's entry into London with competitive salaries reshaped the entire tech ecosystem. \"UK's small market limits growth.\" Outdated thinking. Consider: Dyson: From a Wiltshire barn to a global technology powerhouse, now innovating in Singapore and Malaysia. Ocado: Online grocer turned global automation technology provider, with robotics solutions deployed across Europe and North America. ARM: Powering 95% of smartphones globally. \"Hardware is riskier than software.\" No longer true: Development speed: 3D prints and PCB prototypes now available in 24 hours, rivalling software iteration speeds. Moat strength: Apple's hardware-software ecosystem is far more defensible than most pure software plays. Massive hardware exits: ARM: Sold to SoftBank for $32B in 2016, now worth $140B+. CSR (Cambridge Silicon Radio): Acquired by Qualcomm for $2.5B in 2015. Dyson: While not an exit, it's valued at over £20B as of 2023. The Arbitrage Play: It isn't about costs. It's about ambition. While software talent flows freely globally, ambitious UK hardware startups can exclusively tap into a world-class, locally-bound talent pool. The Software Brain Drain: US tech giants easily poach UK software talent Remote work erases geographical boundaries Result: Constant outflow of top software engineers The Hardware Opportunity: Physical presence matters can't build rockets remotely UK hardware talent largely untapped by global competition Build something ambitious, attract local engineering superstars The Talent Trap: Brilliant minds wasting away in soul-crushing corporate jobs Your future \"10x engineer\" is someone else's bored employee The Hardware Advantage: Forget software. Hardware is the new frontier. Build the next ARM or Dyson, not another fintech app Leverage UK's world-class research institutions Why Now: Incumbents are unambitious, startups are few (for now) Top-tier VCs awakening to UK hardware potential First movers will have pick of the talent pool The Window is Closing This arbitrage won't last forever. As you read this, others are waking up to the opportunity. The first movers will reap the rewards. The followers will wonder why they didn't see it sooner. The Hardware Revolution Starts Now Wake up, UK. Our engineering talent is our nuclear fusion. Ignite it or lose the future. VCs: Your next unicorn isn't code. It's cobalt and circuits. Back the tangible. Founders: Stop fleeing to the US. London can be the hardware capital of the world. We have the talent. We have the creativity. What we need is your audacity. Engineers: Your brain's worth billions. Build empires, not apps. While the world obsesses over the next GPT wrapper, we'll forge the next industrial revolution. This isn't a pipe dream. It's an imperative. UK, it's time to build. Braindump by Josef Chen",
    "commentLink": "https://news.ycombinator.com/item?id=42763386",
    "commentBody": "UK's hardware talent is being wasted (josef.cn)507 points by sebg 19 hours agohidepastfavorite873 comments tomhoward 7 hours agoI don’t think it’s just a UK thing, or that it’s much easier to start a hardware startup in the USA. I think it’s more that the bar for getting a hardware startup off the ground is much higher than a software startup everywhere in the world. Personally I’ve been trying to self-fund and bootstrap a hardware startup (based in Australia but I’m reasonably well connected in Silicon Valley as I’m a YC alum). I’ve had plenty of early success and validation of all my market theses, but it’s super hard to get any investors interested. Plenty say “exciting” and want to chat. All lose interest when you start talking funding needs and path to market. In a world in which investors and other startup industry contacts are accustomed to seeing a bootstrapped SaaS app showing signs of growth and revenue just a few months in, with a hardware startup it’s just impossible to avoid looking like a failure by comparison due to all the costs, delays and complications involved with getting an MVP to market. And because successful hardware startups are so scarce relative to software ones, it’s hard even to get any good advice; there’s just barely anyone around with good, relevant experience to share (and I already know many of the people who have built companies in this vertical in past decades, none of whom are in SV). I’ve come to the conclusion that the only way to make it work is to start by achieving success as a software startup, then transition into hardware to later but even then you’d have to convince investors that it’s worth the risk. In short, the whole tech industry has been spoiled by easy SaaS wins over the past decade, and that’s all that most investors are willing to even consider. The exceptions are “start-big and-get-huge-fast” plays like Groq but the founders of that company were already highly credentialed and connected when they started, and even then vanishingly few investors are willing/able to fund new companies like that. That’s not the kind of thing young, unproven founders can pull off, anywhere. reply zipy124 7 hours agoparentThe largest problem I see is shipping times. If I need to download a new software \"part\" (library or other), the shipping time is the download time, nearly instant. If I need new hardware pieces, its either next day shipping, a few days by air-freight or three weeks on a boat from china. This limits prototype turnover time, and means iterating quick is much harder. Finally you have the problem that hardware is expensive and an additional cost. A hardware startup has all the same costs as a software company but with the addition of hardware. reply analog31 6 minutes agorootparentWhere I've worked in hardware dev, the biggest bottleneck is software. reply llm_trw 6 hours agorootparentprevParts are pretty much instant, pcb turn around times are 3 to 15 days depending on how complex they are. Even in the bad old days of punch cards and priesthoods the turn around for software was faster. I have a little pcb mill in the garage that I use for prototypes. To this day I've not met another EE that knows what a voronoi mapping is, or why you'd want one. In a previous startup where I was the software engineer I got through more prototypes for the analogue signal paths in an afternoon than the two other EEs had in the previous week. reply YakBizzarro 5 hours agorootparentOnly for simple pcb. If you are making multi-layer pcb with complex stacks, pcb manufacturing and soldering (with associated tooling setup, validation and so) are easily 2 months of turnaround reply mrmlz 5 hours agorootparentWell to be fair if you add \"validation\" the turnaround for any noncomplex piece of software can reach months pretty quickly as well. But yeah I'm not gonna argue that sw isn't faster than hw in 99% of the cases. reply tomhoward 7 hours agorootparentprevThat’s a big part of it. But mostly it’s that your dev+deploy+evaluate cycle is so much slower. With web software you can write a feature or bug-fix and push to prod in minutes and repeat that many times a day. With hardware each equivalent cycle is weeks or months (especially in my vertical farms). reply bluGill 4 hours agorootparentSome of us write software for embedded devices where a mistake in programning means a critical machine in a remote area needs someone to physically go there and thus spend months in test before we dare deploy. Some of us care about quality and won't allow a customer to see bugs thus even though we can deploy in seconds our reputation won't allow it. There is also software that bugs can kill people so again we won't deploy without evtensive testing much of this is regulated and we would go to prison for deploying at will even if it works. those who work in any of the above react in horror to stories of how the web deploys to production so fast. we know we are not perfect and don't understand how you would risk it. reply zipy124 5 hours agorootparentprevThat's what I meant by prototype turnover time, your iteration cycle. reply ta988 3 hours agorootparentprevIn some shops this is solved by staggering scheduling so people work on several projects. Some aspects of HW can be simulated (think analog with SPICE-likes, or logic level like the chip designers and FPGA users do) so this reduce the need to iterate every time in hardware. A lot of the iteration work can also be done on the board you received. You don't have to wait for your new board to see if those additional decoupling capacitors will do something, you add them on your current board by hand... You would be amazed at how far rewiring can go, sometimes entire BGAs are removed, installed dead-bug style and each pin wired by hand. reply varjag 6 hours agorootparentprevThe pace is not really parts supply constrained in my experience. It just takes much longer to build and validate even relatively modest design changes. reply whiplash451 6 hours agorootparentprevTrue but that reality applies to all your competitors. Your investors should care about your performance relative to the market. reply progbits 6 hours agorootparentNot to your competitors in Shenzhen, they can get basically any part within one day or can get any prototype made easily. reply llm_trw 6 hours agorootparentThey also get it stolen even faster. reply tomhoward 6 hours agorootparentprevInvestors are generally wanting to see little existing competition so that’s not really the issue. They’re more concerned with factors that will cause the company to self-destruct. Running out of money before hitting PMF and growth is the most common failure mode for any startup, and is much more likely with any hardware startup, due to the dramatically slower iteration times. reply nradov 2 hours agorootparentprevDo you see potential for better software design and simulation tools including VR to reduce the need for physical prototypes? reply hintymad 4 hours agoparentprevUK ignited the First Industrial Revolution. It's sad to see that UK has slipped to number 16 or lower when it came to the market share of global manufacturing. And the problem is not to just UK, but to pretty much all the developed countries. Many nations and people have benefited greatly from globalization, but I have to ask: is it worth it if the cost is forfeiting my own country's manufacturing know-how and supply chains? And yes, I'm fully aware of the theory of comparative advantages, but in the meantime, but manufacturing can still bring great income to many families and nations still compete and even go to wars with each other, right? reply flir 1 hour agorootparentWhen I was a kid (80s) I knew old boys with lathes and mills and pillar drills at the bottom of the garden. They were the last generation, I think, of a tradition rooted in the Victorian era which informally transferred a lot of knowledge from one generation to the next. My pet theory is that their disappearance is tied closely to the cost of land. I see US-based hardware hobbyists' shops on YouTube, and I think \"I couldn't even afford to build a shed that big\". The tools themselves are often actually pretty cheap second hand at auction, because the demand is so low, but I live on the back of a postage stamp in comparison with those guys. (Another possibility is simply that software ate the world.) reply rjsw 8 minutes agorootparentMy grandfather got a lathe and pillar drill as his retirement gift from work, he also taught me how to etch PCBs and build radios. reply qazxcvbnmlp 39 minutes agorootparentprevLand is expensive in the areas people want to live. But yeah, tools are much cheaper, esp if you slowly grow over time. reply wcfrobert 2 hours agorootparentprevThe US outsourced its manufacturing to China in the name of comparative advantage. Bob bakes bread, Alice grow apples. Everyone is better off because of specialization. In Thomas Friedman's latest nyt column, he refers to China's manufacturing dominance as a play to de-industrializing other countries. It may just be globalization is incompatible with political realities. reply soVeryTired 1 hour agorootparentOr… Bob makes bread, Alice grows flowers. Alice needs bread; Bob likes flowers but can go without if he wants to. Who’s going to come off worse if they have an argument? reply chronic7300690 55 minutes agorootparent> Who’s going to come off worse if they have an argument? The US. But 4 year election cycles and quarterly earning reports are incompatible with long-term planning. reply pjc50 3 hours agorootparentprevEven the Americans can't manage economic isolation. It takes a global civilisation to build a smartphone. We might have been able to get closer to it by being in the EU, but now we're on our own on that one. reply hintymad 3 hours agorootparentYeah, I do recognize that. I just wish that the US could have a healthy mixture of light and heavy industry, so that the cost building any mission critical systems will not go through the roof, and so that we will be able t build anything domestically if we want. Even though it's likely a pipe dream now, but at least the US can do so for the WW II and after WW II for quite some time. reply talldayo 2 hours agorootparentThat ship sailed. It's like the other comment said China embraces manufacturing to make other countries inept at it. It's not only that American precision engineering is mostly at parity with China, it's that manufacturing anywhere else is a waste of money. When unibody aluminum Macbook cases are machined, they never are machined in America. They're sold to Americans, marketed as an American company, but your device (even at the markup Apple charges) cannot be made economically in America, period. In a broader sense, I'd say that America is headed down the same road the UK is too. We expect people to pay hand-over-fist for our tech talent that isn't any better than what you can get in Pakistan or China. Our hard markets are getting bearish, our leadership wants to de-globalize, and American tech wants to maintain global control without acquiescing to local governance. America had the economic lead before WWI and after WWII, but now we've bet the farm on our ability to market bullshit. America's national economy cannot survive if the App Store and ChatGPT are our premier exports. reply nradov 2 hours agorootparentprevRealistically in order to prosper the UK needs to join up as part of a \"greater NAFTA\" trade bloc. But the UK no longer has anything that the USA needs so they'll have to make major concessions to get a deal done. reply Symbiote 19 minutes agorootparentThe UK left the largest free trade area a few years ago. There's little appetite to join the American one, as it would mean lowering standards (food etc) which ruins Britain's specialties. reply kjkjadksj 2 hours agorootparentprevWhen the UK had its industrial revolution it had an empire. I’d say dropping to 16 is pretty fair given its size and influence today. reply rbanffy 2 hours agoparentprev> That’s not the kind of thing young, unproven founders can pull off, anywhere. The UK, with a comprehensive social safety net, should be more willing to take small risks. I know it's now what happens, but it'd be important to understand why something that should be actually isn't. reply RobotToaster 50 minutes agorootparentUC seems almost specifically set up to prevent people on it from starting a business, with it's look-through provisions and capital limits. reply varispeed 2 hours agorootparentprevWhat safety net? UK does not have a safety net. reply rbanffy 2 hours agorootparentThat's fair. UC and the NHS are far from ideal, but, compared to the US, they are heaven. reply kristianc 2 hours agorootparentI think that needs to be qualified heavily — salaries in the UK are much lower both in nominal and PPP terms, so there's much less opportunity to build one's own safety net, and the NHS is overwhelmingly focused on providing care for the elderly. To a young(ish) startup founder, the presence of the NHS and UC makes little to no difference. reply Symbiote 16 minutes agorootparentThe startup founder in the UK needn't worry about a bad cycling accident (happened to a friend in his thirties), an early cancer (colleague in her thirties) or losing their job just before a baby is born (friend in his thirties). reply rbanffy 1 hour agorootparentprevMaybe a good way to incentivize more risky entrepreneurs is to provide a better safety net. I would, however, caution against making it too perfect (and I hate myself for saying that, because I would prefer people worked on whatever brings them happiness, not money) part of the drive for Americans (and the reason they risk so much on it) is the need to accumulate as much capital as possible as soon as possible, because they know they won't enjoy any sort of safety net when they grow old. reply kristianc 1 hour agorootparentLet me rephrase — in the UK we have a generous and expanding safety net, for the elderly, voted for by the elderly, and paid for at great expense by the working population. reply kadushka 33 minutes agorootparentIsn’t there a safety net for the elderly in US as well? I’m talking about Medicare. reply momojo 22 minutes agoparentprevWhat are your thoughts on Anduril? reply Folcon 5 hours agoparentprevJust to chime in and say that bootstrapping does work in this domain, I say that as someone who's had a few friends go down that route, but yes, it's really tough. There's also people I know who built small scale solutions and then managed to push that into funding and funnily enough a Kickstarter as well though I don't think he'd recommend anyone follow that route. reply foobarian 3 hours agoparentprevWould it be fair to say that the \"unicorn\" effect is a lot harder to achieve as well? If VC rely on 1 out of N startups doing well then that 1 success needs to achieve over N-fold returns just to break even. On the other hand I have no trouble coming up with examples of hardware companies that did well: Apple, Nvidia, Intel... but those time scales are titanic. reply rbanffy 2 hours agorootparent> Apple, Nvidia, Intel. Not sure they are great examples. Intel is going through a lot of pain now (but it's been very successful in the past). Apple was in a terrible situation before its reverse acquisition by NeXT (NeXT paid one Steve Jobs for all of Apple and got $400 million in change). Nvidia got insanely lucky with Bitcoin, then with AI. Its original plan was to make 3D accelerators for gamers and, maybe, engineering workstations. All of them were a couple wrong decisions away from doom multiple times. Think Commodore, who made one of the most popular computers ever, only to be mismanaged into the ground. reply nradov 2 hours agorootparentLuck and timing obviously play huge roles. But I like to think that as an industry we no longer frequently make mistakes quite as outright stupid as Commodore management did. There are at least some generally understood tech industry best practices which prevent decisions like that when there is serious money at stake. reply rbanffy 1 hour agorootparentNokia enters the chat reply BobaFloutist 2 hours agorootparentprevIt's funny that you didn't mention Dell, Lenovo, Sony, or even Microsoft and Nintendo which both make their money off the software than the hardware, but are also companies that produce and selling hardware. reply DrScientist 2 hours agoparentprevInterested in your opinion on crowd-funding as a way of raising initial capital ie cut out professional investors and go direct to potential customers? reply sylware 7 hours agoparentprevYep, look at RISC-V, the most promising hardware is from the USA. It is not yet on the latest silicon process, but with the latest GPU, I guess we could run the latest games, until the game devs recompile and QA a bit their games (obviously on elf/linux) reply jononor 1 hour agorootparentMost promising by what definition? And what subset of applications/markets are you considering? In the microcontroller space, China is leading on RISC-V. EspressIf, WCH, et.c are already shipping units at scale. Of course these are low value chips, but the volumes are large. The combined shipments for microcontrollers are in tens of billions of units annually. The technology choices in the space changes slowly (32 bit over 8/16bit is quite recent...), but over the next 10 years RISC-V looks poised to take a decent chunk. reply sylware 49 minutes agorootparentLook at risc-v official web site, some company called sifive and their UEFI workstation boards. And I want to be able to buy a USB-C RV64 SOC (without ARM blocks) with tons of GPIOs for my future keyboard controller. reply ashergill 4 hours agoprev> The reality for most graduates is even grimmer: > • £25,000 starting salaries at traditional engineering firms > • Exodus to consulting or finance just because it's compensated better This is _exactly_ my career so far. The key thing about the British economy is that while most things operate in a free market, construction is centrally planned by councillors who are incentivised to block most development. So the whole economy is struggling, but industries that need physical space are especially hard hit. Your local council can't block you from writing more code, but can stop you from building lab space near where people want to live and work. My first job out of uni was in a wonderful small engineering firm in Cambridge. Lab space there is eye-wateringly expensive because it's illegal to build enough, so we were based in a makeshift lab in an attic next to the sewage works. I loved working there, but it shows that we're restricting our small businesses unnecessarily through our planning system. The solution is frustratingly simple, but politically suicidal for any government that tried to implement it: just legalise development subject to basic design codes. I hope we see some planning reform before it's too late for our struggling innovation industries. reply pjc50 3 hours agoparentI used to live and work in Cambridge. In many ways it's a victim of its own success; people will, not unreasonably, argue that it's a beautiful little town of historic buildings, embedded in a primarily agricultural county of either prime agricultural land or protected wetland. They're not going to let you build Shenzen in Shelford no matter what the economic benefit might be. Meanwhile it's close enough to London that the property prices tick upwards to London commuter weighting. (This is also why we have expensive electricity, because people oppose building any infrastructure. I'm coming round to the idea that there should just be county-by-county referendums where people have to pick either blanket allowing energy development or having a bill surcharge.) reply shawabawa3 3 hours agoparentprev> but politically suicidal for any government that tried to implement it Labour just got into government and literally the third bullet point in their manifesto is: * Reform our planning rules to build the railways, roads, labs and 1.5 million homes we need and develop a new 10-year infrastructure strategy. So i would hope it's not political suicide to follow through on that reply archsurface 32 minutes agoparentprevAn illustration of this which I happened to be looking at: Average home sizes (sq ft, sq m): Australia 2,303 214 New Zealand 2,174 202 United States 2,164 201 Canada 1,948 181 UK 818 76 Edit: formatting. reply henryaj 1 hour agoparentprevYup. From Sam Bowman's Foundations[0]: > [The TCPA] moved Britain from a system where almost any development was permitted anywhere, to one where development was nearly always prohibited. Since [it] was introduced in 1947, private housebuilding has never reached Victorian levels, let alone the record progress achieved just before the Second World War. > Today, local authorities still have robust powers to reject new developments, and little incentive to accept them. Historically, local governments encouraged development because their tax bases grew in line with the extra value created, but this incentive has been eroded by successive reforms that have centralised and capped local governments’ tax-raising powers. [0] https://ukfoundations.co/ reply itissid 50 minutes agoparentprevI remember seeing tons of shipping containers repurposed as offices all over london last year. Was that a way to ease/get-around this real estate issue? reply ImHereToVote 2 hours agoparentprevThis is the true cost of the bank bailouts. This is the moral hazard incarnate. reply pjc50 2 hours agorootparentLocal councillors being against development is nothing to do with bank bailouts, which have (mostly) been repaid by selling off the banks again. reply ImHereToVote 1 hour agorootparentThat isn't what I mean. The moral hazard is caused by the bailouts. It isn't about the sum itself. Merely the guarantee that the tab for large gambling losses will be taken by the taxpayers. reply Animats 14 hours agoprevIf engineering isn't near the factory, it's not as effective. Here's one of the most generic electronic components a 1K resistor.[1] These sell for about US$0.0015 each. DigiKey has a list of many suppliers. There are a few old-line US resistor makers in there, including Bourns and Ohmite. They're price competitive with Chinese companies. But when you look up their engineering job locations, none are in the US or UK.[2] Plants are in Mexico, Malaysia, Taiwan, and Hungary. To get prices down, engineers have to be very familiar with what goes on in manufacturing. If you separate engineering from manufacturing, you get overpriced designs. Not that many people who went to a good engineering school in a first-world country today want to spend their lives inside a big factory in a low-wage country. But that's what it takes to make stuff. [1] https://www.digikey.com/en/products/filter/chip-resistor-sur... [2] https://jobs.bourns.com/go/Engineering/9254400/ reply Beretta_Vexee 9 hours agoparentBeing an engineer means mastering your production tool. For everything to do with physical production, you need to be close to the means of production to gather essential information on quality, capacity, operator feedback (machine and quality operators are invaluable sources of information.), etc. Most information is not digital or hardly digitizable. I don't completely agree with the article's classification of ARM as a hardware company. ARM produces VHDL and resells licenses, but does not produce any chips. It's closer to a software company than a TSMC. reply llm_trw 5 hours agorootparentI'd go one further and say you have to be at least a journeyman in whatever tools your process is using. The difference between someone designing a part in cad and someone designing the tool paths for the machine that makes the part in cam is night and day. reply rbanffy 2 hours agorootparent> The difference between someone designing a part in cad and someone designing the tool paths for the machine that makes the part in cam is night and day. I remember, in a CNC programming class, the instructor calling out one of the students on a lathe program: \"One millimeter increments?! What material do you think you are using? Styrofoam?!\". That class is where I feel in love with the ASR-33 teletype and its cadenced hum. It was punching the tapes we feed into the CNC machines. I wish I could have bought that machine when it was retired not too long after my class. reply tonyarkles 1 hour agorootparent> \"One millimeter increments?! What material do you think you are using? Styrofoam?!\" I'm an EE not a MechE but I'd be truly curious to know if there are any MechE programs where a fresh graduate would have ever heard the term \"feeds & speeds\". In a similar vein, I learned to solder in EE but not because of any of my course work. We were lucky enough to have an aerospace electronics manufacturer situated on the north edge of campus. The IEEE Student Society worked out a deal with them where EE students who wanted to learn could come and do a 3-hour crash course with the techs. I could solder before I did the course, but my ability to solder well improved dramatically as a result of those 3 hours of training. And, even more importantly than learning to solder, I learned a ton of things about solderability: what makes a circuit board easy to solder and what makes it hard to solder under different manual and automated manufacturing techniques (wave soldering, paste + pick & place, etc). reply rbanffy 1 hour agorootparent> if there are any MechE programs where a fresh graduate would have ever heard the term \"feeds & speeds\". This was an extracurricular activity, and the MechE's were in their fifth year or so. I was in my first year (semester, really) and I was suggested I take the course because I was already a reasonable programmer and there was very little materials in the course, but it was more about programming the machines (simple loops, no real decisions, etc). I was doing 0.1mm increments in my code because I \"felt\" steel wouldn't be soft enough for more, but I never got any real training on that before second year. reply Beretta_Vexee 5 hours agorootparentprevWe could discuss this at length, but I completely share your point of view. Anyone can design a part that's impossible to produce. The real added value is knowing how something is actually going to be made, in how many stages, with what tools, what controls will be carried out, with what tools, what the acceptance and rejection criteria are, and how these criteria have been determined, are essential points. reply petra 1 hour agorootparentprevWhat about using simulation(or estimation using software) to understand the manufacturing process well enough to design for it, without being in the factory? reply DragonStrength 6 hours agoparentprevTotally anecdotal but to your point, the engineering jobs in my hometown followed the manufacturing jobs in leaving town in the 1990s after NAFTA. Engineering seems to be returning as domestic manufacturing increases thanks to foreign auto companies setting up shop across the state, replacing what the US companies left behind. reply itissid 44 minutes agoparentprevI wonder this is also what doomed some, but not all, of meta's hardware efforts like its watch from 2023 (Portal was successful and a solid build but that was more pacakging than manufacturing and died for a different reason: Priorities). In general though it seems where design/codehardware feedback loop needs to be very fast in some cases, it is a non trivial separation of concerns. reply CharlieDigital 5 hours agoparentprevTaiwan is kinda nice though? And just a short hop to Japan for holidays or even long weekends. reply petra 8 hours agoparentprevThere are plenty of industries where product engineering is done at a different company or place than product manufacturing. For example, consumer electronics, industrial machines and robotics, telecom and medical devices. reply huijzer 6 hours agorootparentThe fact that it exists doesn’t mean it’s the best. You see it all the time that businesses do something just because everyone does it too. For example, the current AI investments, collatoral debt obligations in the 2000s, and conglomerates in the 1960s. reply llm_trw 6 hours agorootparent>the current AI investments As someone whose done both hardware and AI, the current AI investments are at worst a repeat of the 2000 dot com boom. They aren't wrong, but they may be premature with how terrible our compute substrate is. reply nine_k 13 hours agoparentprev> spend their lives inside a big factory in a low-wage country Some gladly would if paid handsomely by the local standards, that is, adequately by the US standards. The bigger problem is raising children away from your native culture. reply freddie_mercury 7 hours agorootparentI spent a decade in a low-wage country and the number of people who were \"glad\" to spend even half that much time there paid handsomely! could probably be counted on one hand. Virtually the only people who stay longer than 3-5 years are ones who end up founding their own businesses there. Raising children away from your native culture isn't the deal breaker you imply. There are international schools (though, with eye-watering fees) and expat enclaves in most places I've been. But very few (effectively zero, though I did come across a handful of exceptions) companies treat these employees the same way as the ones back in the home country. If you don't rotate back to HQ in ~3 years then you're in a career dead-end. So you've got this situation where you need people who are ultra-ambitious willing to throw away all their existing social networks to go work in a foreign country for years on end! but that means those same people aren't going to want to stay past their expiration date. And companies know that, too. A lot of them make it an explicit part of the deal. I met one high-level guy (regional CTO I think?) at Coca-Cola who was Indian and the deal with corporate was he'd do 3-years in a low-income country (not India) but then he'd get transferred to the US. Met some people in the oil industry who had similar deals. Do 2 years in Vietnam then you get to go to Malaysia or whatever. reply heraldgeezer 6 hours agorootparentSo everyone fully admits that these countries are in fact \"worse\" in every way? reply namdnay 6 hours agorootparentI’m not sure what “admission” you’re looking for? That life is generally better in wealthy countries? Wow big surprise reply chronic7300690 51 minutes agorootparentprev> So everyone fully admits that these countries are in fact \"worse\" in every way? Considering money is the universal currency? Yes. Worse in every way. Churches ask for donations. Women marry rich men. You can buy politicians. You can buy more expensive healthcare treatments. Can you do that in a worse SEA country? reply MichaelZuo 12 hours agorootparentprevYou should probably recommend them to Apple recruiters, since they regularly have shortages of bilingual top tier talent willing to work full time at major factories. Even with extremely generous FAANG salaries in areas with cost of living less than a quarter of Cupertino. reply n144q 6 hours agoparentprevVery weird comment. Article talks about hardware talent in UK. Your comment tries to prove \"engineering jobs\" are not in the US by providing the job listing of a single supplier, when everybody knows that there are a huge amount of hardware talent in the US working at great companies that deliver amazing products. Your comment seems to equate \"manufacturing jobs\" to \"hardware engineering jobs\" which apparently isn't correct. reply kevin_thibedeau 2 hours agoparentprevMany of the legacy component vendors retain domestic US manufacturing to supply military parts. They come with a premium price and aren't usually worth using commercially but that is one of the last backstops preventing all knowledge from disappearing. reply refrigerator 18 hours agoprevThis is spot on. All the smart and ambitious people I know who studied (non-software) Engineering at university in the UK have ended up going into software engineering via self-teaching or finance/consulting because the only hardware engineering career paths seem to be working for Rolls Royce in the middle of nowhere with terrible pay, or alternatively working at Jaguar Land Rover in the middle of nowhere with terrible pay reply syntaxing 18 hours agoparentWas a MechE for 10 years here in the US and now I’m a SWE. Even here, no one cares about hardware engineers. Don’t get me wrong, you can make enough to be “comfortable”. But anecdotally, maybe 10% of MechE do design. 10% of that are paid handsomely to be in tech and are “Product Designers”. Even then, almost every tech company want to be a predominantly software company. They just happen to need hardware to execute their product. Admittedly, it’s really hard to do hardware in this economy when one country has 60% of the global manufacturing output and can copy your design, make it cheaper, and make it better. Ironically, the biggest dividing line that makes a hardware product better is good software. reply wakawaka28 17 hours agorootparentThat's what happens when there is not much manufacturing in the country anymore, and everyone is encouraged to go to college. I don't know why the software industry hasn't suffered more along the same lines. Maybe the profit margins for software are higher. reply nine_k 13 hours agorootparentProduction of software is nearly 100% R&D. Making a million copies of a software product has a trivial cost. There are no assembly line workers in software (and the very word \"assembly\" means a different thing). A software engineer very often brings in revenue many times their salary. Production of hardware is some R&D, and then actual manufacturing. Production of each physical item costs you. Production of every physical item has a chance to go wrong. Production of each physical item requires a number of humans (often a large number) to do repetitive, high-precision, high-skill work, as fast as practical. You can augment or replace some of them with robots but it also costs you, and you can't replace all the humans with satisfactory results. So, with hardware, the cost of the workforce plays a major role, while with software it does much less. To produce physical things, you need a lot of people who are not well-off, and for whom factory work is an upgrade of their financial and social standing. A \"developing country\", with huge swaths of population leaving rural life for a better city life and factory work, is best in this regard. Ideally you sell your product to richer folks, maybe outside the country of production. Of course there can be situations where the workers are highly paid, and produce very valuable things through their skilled work. Ford in 1950s famously paid the assembly line workers very well, so that they could buy the cars they produce, and valued their employment. But this does not always occur; people doing work that does not add a lot of resale value also want to live well, especially if the society does not want a flood of immigrants who are willing to work for much less. Check out how much the work of a plumber costs in Switzerland. So only high-precision, high-margin, low-volume manufacturing remains in Switzerland, such as precision optics, precision industrial and medical equipment, or premium mechanical Swiss watches. The US is in a somehow similar situation. reply foobazgt 11 hours agorootparentThis all resonates very strongly with me. We have tons of automation the proverbial \"economies of scale\", but we haven't managed to solve the last mile. Auto assembly seems like a poster child. There's wild automation going on, but the typical plant still requires thousands of employees doing things by hand. Musk tried to automate a lot more of this away with newer/better robotics, but failed. (Tesla has still achieved a lot here, but it's been more towards creating designs that are more amenable to the current state of robotics). IMO, this problem should be solvable now. I.E. we don't need \"new physics\" to reach another step-function in automation. We need more investment. We're still largely in the mindset of \"special-purpose\" automation. reply torginus 11 hours agorootparentprevYeah I remember one of my friends working for a German auto company during the 2008 financial crisis and having insane stuff routinely happen like an auto manufacturer having to buy truckloads of sensors from a subcontractor that had nowhere to go as car manufacturing lines were stopped. Failing to do so would have meant these manufacturers would go under, (along with their own subcontractors) and once demand shot back up, cars would be literally impossible to manufacture as key suppliers went out of business. reply imtringued 9 hours agorootparentprevI disagree very slightly. Mostly with this part: >So, with hardware, the cost of the workforce plays a major role, while with software it does much less. To produce physical things, you need a lot of people who are not well-off, and for whom factory work is an upgrade of their financial and social standing. A \"developing country\", with huge swaths of population leaving rural life for a better city life and factory work, is best in this regard. Ideally you sell your product to richer folks, maybe outside the country of production. You don't need a lot of people who are not well-off. You can automate the entire process. The problem with automation and labor saving technology is that it is capital intensive. The higher the capital investment per job (higher capital intensity), the bigger the chunk of money that flows to capital rather than labor. This means that the cost of the workforce in a software company plays a bigger role than in a hardware company, where financing costs to pay for labor saving technology play a bigger role. There are mining companies in Africa, who have nothing but an army of people equipped with shovels digging a small scale open pit mine. There is no way the labor cost here is the biggest constraint. An excavator and wheel loader could accomplish more with less people, but it would mean getting a USD loan to import foreign equipment and then selling for export to pay the foreign debts, rather than local production. reply raverbashing 12 hours agorootparentprev> Production of software is nearly 100% R&D. Making a million copies of a software product has a trivial cost. > Production of hardware is some R&D, and then actual manufacturing Totally. And if you think deployment errors are bad, wait until you see how many production errors exist and how many items out of your line come out working and within spec reply nine_k 12 hours agorootparentIndeed. You cannot release a patch for a mechanical part or a PCB. reply throwaway2037 12 minutes agorootparent> You cannot release a patch for a mechanical part In NATO, this is frequent and normal. Many, many \"recalls\" are issued by military manfacturers, then local support staff spend X hours to replace the defective part. It is not so different from automobile recalls. reply moregrist 6 hours agorootparentprevFor a PCB it’s called a rework, and it’s very common for first spins of boards to have to do one. Also common is to patch around issues, when possible, in firmware. This is often lower cost/effort, but can’t fix everything. There are similar kinds of fixes for purely mechanical parts. Depending on the part and problem, mechanical can be easier than a PCB rework (eg: modify a part in CAD and 3D print or get your local machine shop to do a run). reply kjkjadksj 2 hours agorootparentprevYou just release a new version. How many xbox 360s did they actually release? I think its close to a dozen iterations. reply zmgsabst 12 hours agorootparentprevYou can and people do. It’s just a lot more expensive and labor intensive to apply. reply CraigJPerry 10 hours agorootparentprevInteresting that you say that, my understand of the data is that manufacturing output has never been higher ignoring lingering Covid shocks https://fred.stlouisfed.org/series/IPMANSICS But because productivity is higher https://fred.stlouisfed.org/series/M0100CUSM070NNBR which doesn’t mean the workers are working harder: a man with a shovel can work as hard as he likes, but he’s never going to compete with the business owner who invested in productivity and gave his worker an excavator. Therefore employment in the sector is down due to increased productivity, not decreased output. But increased productivity is a radically different thing from decreased output. A claim that manufacturing should employ more, in the face of increased productivity, That’s a claim that manufacturing should replace other endeavours in the economy which, is a complex claim at the very least. reply concerndc1tizen 8 hours agorootparentNice charts, but M0100CUSM070NNBR is from 1948 to 1963 :) reply CraigJPerry 7 hours agorootparentEh, well, this is a bit embarrassing! On mobile, I can’t local a chart that covers the post war until now, best I can find is https://fred.stlouisfed.org/series/OUTMS which shows late 80s onwards BUT shows a drop at 2008 onwards which goes against my argument (notwithstanding the big gap between both charts) reply wakawaka28 5 hours agorootparentprevThe nominal value of highly automated processes has never been higher. Meanwhile, ordinary people are not able to find as many good jobs as they once did. Wages in almost every industry are stagnant at best, at least when adjusted for inflation. >A claim that manufacturing should employ more, in the face of increased productivity, That’s a claim that manufacturing should replace other endeavours in the economy which, is a complex claim at the very least. It is a complex claim but I'll make it really simple. We import most of the things we rely on. Everything from plastic toys to car parts to critical medicines are all imported. Letting yourself become totally dependent on other countries while our STEM grads are underemployed, and would-be manufacturing line workers are forced to do bullshit like driving for Uber, is no way to run a country. It is going to backfire one day unless there is a major reversal in the trend. reply bluGill 4 hours agorootparentEngineers are not ordinary jobs though and so the plite of the 'common man' is irrelavent. reply wakawaka28 2 hours agorootparentYou can't have so many engineer jobs unless you have manufacturing, and if you did have manufacturing then there would be \"common man\" manufacturing jobs too. It's all connected. Every job market that is really critical for national security is depressed by this outsourcing and importation of cheaper goods and labor. reply Brybry 14 hours agorootparentprevThe U.S. is still the second largest manufacturer in the world by a large margin [1][2] Like, yes, manufacturing's % of US GDP is low (and has been decreasing for a long time) and manufacturing employment is flat or slowly increasing but we're still making a lot of stuff. [1] https://www.nist.gov/el/applied-economics-office/manufacturi... [2] https://worldpopulationreview.com/country-rankings/manufactu... reply wakawaka28 14 hours agorootparentI don't think we make a lot of stuff but we do make some of the most expensive stuff. So a lot of stats really don't reflect how unbalanced our trade is in real terms. reply marsRoverDev 13 hours agorootparentprevI've been told that acceptable software margins are around 75%. Hardware focused yields closer to 20%-40%. Hence why there is such a strong push towards software-only. reply lotsofpulp 14 hours agorootparentprev>Maybe the profit margins for software are higher. This is easily confirmed by checking public financials of publicly listed companies. The profit margins are much higher, and the liability is much lower. The only exception is for those hardware manufacturers at the cutting edge whose products cannot be commodified, such as TSMC and ASML and the ilk. reply petesergeant 6 hours agorootparentprev> I don't know why the software industry hasn't suffered more along the same lines Growth of the software industry isn't constrained by the cost of capital reply GamerAlias 18 hours agoparentprevPreach. My friend is a gifted passionate Aerospace engineer (top in his specific stream at Cambridge) and basically is withering away working for the above 2 firms. The location is grim being far from others and generally far from other young exciting people. Additionally in his org, there just isn't a sense of excitement/ urgency which leaves him with little to do. Prioritising career for a career that's not there Whilst others working in software (myself included) can have a far greater quality of life and salary working in London. reply ctz 11 hours agorootparentMy impression is that top aerospace people do not now work in aerospace, but in Motorsport. reply zipy124 7 hours agorootparentmotorsport is similarly low salary, at least specifically F1. It is like game-dev in software in that there are far more people who want to do it than the number of jobs available so they can afford to pay you in the cool experience of working on F1 rather than in cash terms. reply dzhiurgis 16 hours agorootparentprevWait what. Quality of life in rural UK is worse than rat race of London? reply lmm 14 hours agorootparentAbsolutely. No public transport, almost no culture, and housing anywhere nice is even less available than in London. For a young person working at one of these firms, where can you live? Where could you meet someone to date? What can you even do at the weekend? reply timthorn 11 hours agorootparentJLR is based in the metro area of Britain's second city. It's not exactly the middle of nowhere. Rolls Royce is in Derby, on the edge of the Peak District with much to offer. Much cheaper housing with more space available. And unlike in London, driving a car isn't hounded by terminal congestion. reply porker 10 hours agorootparentJLR Gaydon is not in the metro area of Birmingham. It's in nice countryside and near a motorway which helps, but it's a fair commute out of Birmingham at rush hour to there. The nice surrounding towns/villages are expensive, and even the shitty ones aren't cheap (hello Banbury) as they're on the edge of commuter distance to London. Derby I haven't lived in but know people who have. It's an old manufacturing town and hasn't much to offer graduates. Or anyone really. The Peak District is great, and if you can live out that way and commute in then do it. But again, you won't have similar people for local friends. reply jack_riminton 5 hours agorootparentCan confirm, I grew up in Derby and it's an absolute desolate wasteland for anyone with any ambition, intelligence or a need for a modicum of culture. Saying the peak district is good for young people is like saying there's a great lake near Detroit, it's not exactly what they're after. reply timthorn 18 minutes agorootparentIsn't that what everyone says about their hometown? :) reply UK-AL 6 hours agorootparentprevThere's a huge JLR presence in Solihull right next to Birmingham. It's also one of the wealthiest areas outside of London. But house prices in the really nice parts of Solihull are also high. reply kjkjadksj 2 hours agorootparentprevUK people are so god damned spoiled. Sometimes I will pull up street view imagery of a random town in scotland or wherever in the UK that I see locals from there on reddit make a seething comment about. Then I will look at the town center and its basically greenwich village: walkable, pubs and shops all over the place, bus network goes everywhere, actual regional rail potentially, everything the american urbanist dreams about. You know where you actually meet people on a date in 2025? On an app, which they have users on all over the UK. reply dzhiurgis 10 hours agorootparentprev> No public transport When I live in London I didn't drive, which was kinda nice but also meant I've only been out of city like once a year. Sitting in traffic sucks of course, but driving rurally opens so much. As for weekends driving and hiking I guess? reply Symbiote 6 hours agorootparentWherever you live in London, there are commuter (and intercity) railway lines that can take you out of it. For example I lived not far from Putney. Putney to Windsor & Eton Riverside takes 39 minutes and costs £6.90. https://www.openstreetmap.org/#map=11/51.5330/-0.1146&layers... reply lmm 10 hours agorootparentprevSure, but at that point you're having to buy a car (which is much harder as a young person car prices have gone up, insurance has gone up faster, the driving test is harder than it was and lessons cost more...), you'll need somewhere to park it which adds to your housing costs, you still can't go drinking, and in general you're cut off from a lot of what young people are doing. reply SJC_Hacker 3 hours agorootparentNo Uber/Lyft in the UK? reply Symbiote 6 minutes agorootparentIt would be very expensive to take a taxi (of any sort) out of London to a scenic place, but it's easy to take a train to plenty of them, or hire a car for the day through an app. kjkjadksj 1 hour agorootparentprevEven tiny UK towns have excellent walkable mainstreets and are small enough to walk from field to field on the other end in no time. It is a far cry from the american obligatory car experience where it might be a 2 hour walk to your nearest grocery store even in a city suburb. reply GasVeteran 8 hours agorootparentprevThere is a culture there. I am not sure what people mean when they say there isn't a culture outside of the London. If you mean things like events, art exhibs etc. We have those here. If you mean bars, pubs and restaurants we have those here to. Is it as glitzy as London. No. But saying there is \"no culture\" is just absolutely asinine. reply dukeyukey 8 hours agorootparentprevWhat makes you think QoL in London is bad? I grew up in a rural farming town and much prefer London. Housing is expensive but that's about it. reply dzhiurgis 5 minutes agorootparentLiving there for 5 years. Unless you are in finance and live in city, it’s a shitshow. reply walthamstow 9 hours agorootparentprevThe UK is two countries, you can either live in/around the prosperous one with high cultural capital, good quality public services inc transport, or you can live in the other one. reply anonymousDan 9 hours agorootparentMeh. Having lived in both I much prefer the latter. reply wbl 15 hours agorootparentprevWhen a man is tired of London he is tired of life. reply rgmerk 15 hours agorootparentOr maybe he’s just tired of a specific kind of life which might be fun in your early twenties but is less appealing when you’ve got kids and can’t enjoy the nightlife and culture anyway. reply Earw0rm 12 hours agorootparentPlenty of culture isn't gigs and nightclubs London isn't terribly good, for its population size and economy, for those anyway. Think museums, parks, galleries, theatre, exhibitions. Granted it's not the only city with those, the problem the UK has is that its small, desirable cities are unable to grow or reinvent themselves. Cambridge and Bristol should be ideal for hardware startups, but the cost of both housing and working space is insane for small, provincial cities, partly because NIMBYism and partly because building infrastructure is absurdly expensive when you're constantly having to work around 200 year old buildings and 800yo city plans. reply dagw 10 hours agorootparentprevyou’ve got kids and can’t enjoy the nightlife and culture anyway Having kids while living in the centre of a large city is great, as there is so much culture that is aimed at parents and children. When my kid was small we went to museums and concerts and events all the time that were aimed at kids. There were also several different parks, playgrounds, pools and similar activities to choose from all within easy access. Plus once the kids get slightly older they can use public transport to get around and you don't have to drive them anywhere near as much as if you live in the suburbs. reply baud147258 6 hours agorootparent> Having kids while living in the center of a large city is great If you can afford a flat that's big enough for you and the kids reply nobodywillobsrv 9 hours agorootparentprevnext [2 more] [flagged] selimthegrim 6 hours agorootparentNever contributing to what? reply walthamstow 9 hours agorootparentprevWe drop the kids off at my parents and go for dinner at any one of hundreds of top quality restaurants. Can't do that in Kettering. reply sebmellen 13 hours agorootparentprevHow do you get kids if you can’t meet someone your age to partner up with? reply tomcam 11 hours agorootparentprevhttps://www.samueljohnson.com/tiredlon.html reply nobodywillobsrv 9 hours agorootparentprevOr tired of 63% income tax rates in the middle of the income bands reply walthamstow 9 hours agorootparentDoes London have a different tax policy to where Jaguar Land Rover is based? reply GasVeteran 8 hours agorootparentYou have to earn (much) more to have the same standard of living as outside of it. Therefore you pay more income tax and the cost of living is higher anyway. reply GasVeteran 8 hours agorootparentprevDepends what you mean by \"Quality of Life\". I literally won't go to see friends because that would mean travelling to London. I hate the place. It is expensive, hostile, dirty and everyone is rude. I live on the outskirts of the peak district. I can walk/cycle less than 30 minutes out of town and be walking along the old canals, through old villages and get amazing views of the countryside. reply dukeyukey 47 minutes agorootparentTo be fair I live in Zone 2 and I can be on old canals and villages (albeit now subsumed into London) in ~20 minutes walking. I grew up in rural Wales, and as nice an upbringing it was, there's a reason I have a single family member left, who's trying to move away! reply nextos 18 hours agoparentprevTo some extent, this also applies to software. Except for DeepMind and a few other select places like Altos Labs, getting past £100k is hard, especially outside London. Unless you go into finance, of course. But then, you have to stick to London. Finance is like a black hole that sucks a big chunk of the mathematical, CS and statistical UK talent. They have very proactive recruiters trying to e.g. connect with Oxbridge students when they are approaching graduation. reply retrac98 9 hours agorootparentI know plenty of engineers (web application developers) making over £100-£150k outside of London, usually in fairly low-stress remote jobs. The pay is clearly nothing compared to the US, but I wouldn’t say it was massively hard for them to get where they are. They all have 5+ years experience at a senior level, and are otherwise just reliable, capable, low-maintenance employees, but maybe that’s rare! reply zipy124 6 hours agorootparentThat is indeed very rare. A simple sanity check you can look at how many people earn about 100k in the UK, we know the figure for above 125k is 500,000 [1]. We can subtract the number of other jobs that we know for sure pay above this for example lawyers at magic circle firms which start on >150k for newly qualified lawyers, consultants in the NHS, directors of large corportaions, and we end up with a very small amount of people in other industries that earn these figures. Even before that we know the median is about £50k, and I can tell you from experience you can hire very very good software people on those wages, even in London. From personal experience, I also know of software guys making that, but I also know far far more people earning below that, and these are oxford/cambridge/imperial/UCL grads.... [1]: https://www.gov.uk/government/statistics/personal-incomes-st... reply Macha 3 hours agorootparent> and these are oxford/cambridge/imperial/UCL grads. There are many bad things we can say about software hiring, but one of the good things is that (outside the US at least), it's much more concerned with what you can do than the name recognition of the institution where you studied. reply kevin_thibedeau 2 hours agorootparentThe US isn't that focused on elite schools. It's only in the VC/startup bubble where bias exists. Most tech grads don't go to those schools. reply GasVeteran 8 hours agorootparentprevThey are almost always contractors. If you work permanent it tops out max at about £75,000-90,000. reply retrac98 8 hours agorootparentThey’re not, they’re full time employees. reply GasVeteran 8 hours agorootparentThen they are very few and far between. Generally the absolute limit is £90k. I've never seen any role for more than 90K unless it was a company in London and those are typically hybrid and not remote. reply jonatron 8 hours agorootparentThe jobs above 90k generally don't specify a salary on the job posting. Just two examples: Goldman Sachs and Meta. reply zipy124 6 hours agorootparentI only have the figures for end of 2018[1], but meta employed around 2300 people in the UK, if we assume the same distribution of jobs as elsewhere in the world about half will be engineers, so 1150 engineers. There aren't that many of these jobs. At goldman its a lot higher, aboutn 10,000[2] globally, but they only have around 3,300 employees in the Uk so if its the same ratio as global (25% tech), then that means around 800 developers. Again you'll note this is a very small number compared to the number of top graduates a year, with class sizes of 100-200 per university. [1]: https://engineering.fb.com/2018/11/16/production-engineering... [2]: https://brainstation.io/magazine/goldman-sachs-digital-team-... [3]: https://www.fnlondon.com/articles/goldman-sachs-internationa... reply GasVeteran 7 hours agorootparentprevSo like I said originally these jobs are few and far between. The point is that in the UK the salaries are much lower than those in the US and this is across all experience ranges. reply esskay 6 hours agorootparentprevThey're in the extreme minority. Most software dev roles in the UK top out between £40 and £50k, £60k if you're lucky. reply UK-AL 3 hours agorootparentI am not a top software engineer( (otherwise I'd be working fang tbh) and I earn 85k up north. Hybrid role that's local as well. I know people that earn a lot more than me. It's just the recruiters are a joke and advertise silly salaries from local companies that are out touch. You have to know what companies are serious or not, and just apply direct or via recommendations. reply GasVeteran 3 hours agorootparentI used to work at bet365. They don't even offer that to the permies (65K for Senior), if you stay there a bunch of years maybe 85k is doable. 365 are probably the best playing place outside of Manchester in the NW. So I find this rather hard to believe. reply UK-AL 3 hours agorootparentTook me about 5 seconds https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SI... https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SI... Those are government, so probably have even better pensions than private sector. And there was job advertised for lead software engineer by computer futures(probably an agency) for 80k I didn't even look deep. I know there are even better jobs. There are jobs that pay more than 65k. Just have to know where to look. If you're working for undercapitalized local private companies, then yeah not going pay very much. I'd also recommend looking at remote jobs. My really smart friends who can beat the competition got 100k+ jobs working remote that are officially based in London but they work up north. Then come down for meeting once or twice every few months. A lot of the fintechs allow for fully remote and pay well. reply GasVeteran 2 hours agorootparentWe are comparing salaries of Software Engineers between the US and the UK. A Senior Developer position won't pay more than 90K in the UK outside of London. In the US I see well over that for a Senior Developer position. Even in your examples (which are higher position than what was being discussed) they didn't top out past 90K (just like I said). Whereas in the US you can earn much more quite easily. reply UK-AL 2 hours agorootparentYou've moved the goal posts. You said 60k if your lucky. I just found multiple jobs that pay more than that easily. 85k job up north is a comparable lifestyle than 100k+ job in London. reply GasVeteran 2 hours agorootparent> You've moved the goal posts. You said 60k if your lucky. No I didn't. I suggest you re-read the thread. I said 75K-90K max. > I just found multiple jobs that pay more than that easily. There are always certainly outliers. However most of those places usually have a bunch of iffy things going on e.g. you have to live at your workstation/laptop, or they are in the middle of no where. Enforced pair programming (fuck that btw), or have a stupid interview process (no I won't go through the humiliation rituals anymore). However the vast majority of positions are paying max 65-70K for a Senior Dev. I am glad that you managed to find something. But the rest of us haven't been as lucky. reply UK-AL 2 hours agorootparent\"Most software dev roles in the UK top out between £40 and £50k, £60k if you're lucky\" was the comment I was replying to. But I agree we don't compete with the USA. Even London struggles with that. reply GasVeteran 2 hours agorootparentYeh I figured that. No worries. reply shermantanktop 13 hours agorootparentprevIt’s shocking. Software engineers in the UK are treated like engineers in the US were in the 1960s. Low respect, low pay, while city boys strutting around in shiny suits snapping their fingers to get anything they want. reply dukeyukey 49 minutes agorootparentThis isn't my experience at all, and I've been in London tech for 8 years now. I'm not entirely sure what \"low respect\" means here, but anywhere I've worked the company is pretty wary of knarking of their developers because we can just up and find another job basically immediately. We get paid a fair bit too not sure compared to finance, but not hard to hit the 95th percentile or so. reply torginus 11 hours agorootparentprevThat's a weird statement considering I'd have guess the greatest amount of respect and adoration (not necessarily money) (non-software) engineers have gotten in the US would've been during the Space Race and Cold War years. It was real respect for the trade as well, not some secondhand respect that people who make a lot of money and wield a lot of social influence get. reply kjkjadksj 2 hours agorootparentIt was respected in the sense that there was a need then in american manufacturing for engineering. But the compensation was nowhere near other professional class jobs. So really the respect seemed a bit false: to get people into the door pigeonholed so they can’t leave for higher compensation. Then when manufacturing was outsourced after the 1960s, many of these jobs disappeared. Now people in Guanzhou are designing the factories and process controls. reply coastermug 11 hours agoparentprevI am a former Mech Eng who trod this path. Started at JLR, moved by self teaching into software. Engineering in the UK felt like it moved at a glacial pace that only made sense in the days of final salary pension schemes. Senior management really struggled to get their heads around why young people were so impatient, but we were not competing for the same rewards. reply louthy 5 hours agoparentprev> Rolls Royce in the middle of nowhere 100 miles north of London. 1 hour on the train. > Jaguar Land Rover in the middle of nowhere 100 miles north of London. 1 hour on the train. reply pjc50 3 hours agorootparentBit of a distance to go for a pint in the evening. Isn't JLR in Solihull? That's two hours from London. reply louthy 3 hours agorootparent> Isn't JLR in Solihull? That's two hours from London. Not 100% sure, I'm from the middle of nowhere, sorry, Derby where Rolls Royce is primarily based. I know there's peak-time, non-stop, trains between London/Derby that take about an hour. I know this because when I got my first job in London, I still hadn't found a place to stay, so I was commuting from Derby to London every day. And when I finally moved to London it took me almost as long to get to work even though I was living in the city! I just assumed with JLR being around Birmingham that travel to/from London would be about the same (because Birmingham is very close to Derby). EDIT: Just checked with trainline.com, there's several morning trains from London Euston to Birmingham (New Street) that take 1hr 17mins. reply thijson 17 hours agoparentprevIt seems like the salaries quoted here haven't changed much in the past couple of decades. It's a shame. I know in the past there was a brain drain of talent from the UK to Canada due to the salary disparity. Here's an example: https://en.m.wikipedia.org/wiki/Terry_Matthews And in general engineering jobs in Canada don't even pay as well as in the USA. reply esskay 6 hours agoparentprevHey now you could also go and work for Airbus...but it does mean having to go to Stevenage, as well as getting terrible pay. reply kitd 2 hours agorootparentDouble whammy lol reply zipy124 7 hours agoparentprevI even know a decent amount of people who did engineering at the top unis in the UK, only to go into audit at the big 4.... reply linhns 17 hours agoparentprevIn the end, it's a results business. Software just get higher pay earlier in the career so people will have to go for it. reply devnullbrain 15 hours agoparentprevBeen there, done that. I still frequently get sent Linkedin specs for companies where the hardware team lead is earning junior SWE money. UK junior SWE money. reply youngtaff 9 hours agoparentprevCoventry is hardly the middle of nowhere reply eastabrooka 4 hours agorootparentYeah but then you have to be in Coventry reply incog_nit0 13 hours agoprevIt's not just in the hardware sector, it's across the board. My (American) wife moved to London years ago and was a manager in a prestigious London museum overseeing 60 people. She has over 20 years experience in some of our top museums and her salary in 2023 was a paltry £30k. We just moved to the US and within a couple of months she has a job in museums here but now paying 2.3x the salary (converted back to £) and only managing a team of 20 people. Less stress, more resources for uniforms and initiatives and annual salary increases here way above inflation. As a Londoner I feel quite aggrieved by the situation. It's one thing to increase your salary 50% as a lot of engineers do moving to the US. But to 230% increase your salary is just nuts. Only London's financial sector pay was globally competitive but now with Brexit's rules fully locked in even that sector is slowly losing its talent and customers to Europe and beyond. reply Earw0rm 12 hours agoparentThe culture sector in London is notoriously badly paid. Mostly staffed by the intellectual trophy husbands and wives of the financial sector. Even similar sized public sector organisations (thinking education) pay far better. A senior headteacher with 50 or 100 staff will do a lot better than a cultural manager. reply porker 10 hours agorootparent> Mostly staffed by the intellectual trophy husbands and wives of the financial sector. Oh so true. Which helps to explain the number of levels of management in UK cultural institutions, because in London there are enough of these people who want a (poorly paid) role that it's better to have 3 layers of management when 1 would do. reply zipy124 6 hours agoparentprevSoftware engineers can usually expect to at least 2x their earnings, the median in the uk is £50k and in the US it is £100k, and that is not acounting for the significantly lower tax burden. (That pay excludes medical benefits, if you include the dollar value of that and bonuses and equity the difference rises). reply CalRobert 11 hours agoparentprevMuseum jobs are hideously badly paid. In many cases the real work is done for free by \"volunteers\" (really poor saps on a 2-5 year job interview) before finding out the actual job went to a buddy of the museum director who doesn't even need to show up most of the time. reply titanomachy 12 hours agoparentprevI'm pretty sure engineers are also 230% increase or more. reply marcinzm 6 hours agorootparentIf you take advantage of the larger number of tech company jobs in the US and were in a non-tech company in the UK then you can make 500% more. reply charlieyu1 1 hour agoparentprevFeels the same. Moved to UK a couple of years ago, can’t find a £25k job. Found some outsourced work at American companies and now suddenly I’m going to hit the higher tax bracket reply gadders 8 hours agoparentprev>> Only London's financial sector pay was globally competitive but now with Brexit's rules fully locked in even that sector is slowly losing its talent and customers to Europe and beyond. Citation needed. No-one wants to live in Frankfurt. reply dgellow 5 hours agorootparentThat's a shame, Frankfurt (am Main) is a pretty nice place reply marcinzm 6 hours agorootparentprevA quick Google search will return many: https://www.reuters.com/world/uk/city-london-chief-says-brex... TLDR: They're not moving to Frankfurt but they are moving out of the UK. reply sealeck 6 hours agorootparentWhat do you expect the Lord Mayor to say? \"Yes we think Brexit was great and that the government is going a good job.\" They're a lobby, they want to lobby for more concessions. reply Nursie 13 hours agoparentprevThe UK pays terribly in a lot of areas when compared to the US, Canada and Australia. In software, the only way to keep up is contracting, preferably in London, preferably in finance. But my partner also pretty much doubled her pay in retail management when we moved to Australia. The London financial sector may be losing talent to Europe, but from what I can tell European pay in fintech is not comparable. reply iLoveOncall 10 hours agoparentprevIf your wife used to manage 60 people and now manages a third of that, it seems like her talent is being wasted NOW, not when she was in the UK. I'll add that 70K is nothing to write home about in the US, especially if you're not in a low COL state. The article is about people not going in the field that they're talented at, because it's low paid. Clearly it doesn't apply to your wife which is talented and went in the low paid field. reply mertnesvat 3 hours agoprev> Sarah: Built a fusion reactor at 16. Now? Debugging fintech payment systems. It's striking to imagine a fully functional fusion reactor that could benefit humanity, yet its creator now focuses on fintech payment systems. This highlights the importance of a strong middle class, which seems to be declining globally. A thriving middle class, with disposable income and free time, creates the conditions for innovation. Without it, even brilliant minds like Einstein might spend their entire careers working on immediate economic needs rather than pursuing breakthrough discoveries. reply maginx 39 minutes agoparentProbably what was built was a Fusor. There's tons of instructions how to build one (https://fusor.net/board/) and seemingly there's a lot of focus on how \"young\" the builders of such are. Just google: fusion reactor teenager. In some of the stories it become apparent the fusor was never actually even finished but just along the way. https://newsforkids.net/articles/2024/09/04/16-year-old-stud... https://online.kidsdiscover.com/quickread/arkansas-teen-buil... https://interestingengineering.com/energy/nuclear-fusion-rea... ... reply Chris2048 34 minutes agoparentprevAre these real examples? I was curious, and all I could find it: https://newsforkids.net/articles/2024/09/04/16-year-old-stud... They are not working in Fintech AFAIK. reply ImHereToVote 2 hours agoparentprevWhat you are saying is essentially true. I just don't want people to come away with the notion that building a fusion reactor and yielding net energy from said reactor is equivalent. They are very very very far away from each other in terms of complexity. reply r_thambapillai 18 hours agoprevAs a Brit, when I was raising the seed round for my startup, UK and European VCs would consistently try to haggle you down on price while the American VC's were exclusively focussed on trying to figure out whether this could be a billion dollar business or not (in the end we raised a $5m seed led by Spark, and have done extremely well and raised more since). The UK lost Deep Mind which could have been OpenAI!! to Google. I think part of the issue is cultural the level of ambition in the UK is just small compared to the US. Individual founders like Demis or Tom Blomfield may have it but recruiting enough talent with the ambition levels of early Palantir or OpenAI employees is so hard because there are so few. Instead, a lot of extremely smart people in the UK would rather get the 'safe' job at Google, or McKinsey than the 'this will never work but can you imagine how cool it would be if it did' job at a startup. There are probably political reasons as well. Unfortunately the UK has not been well governed for 20 years or so, and hence economic outcomes as a whole have been abysmal. reply graemep 10 hours agoparent> As a Brit, when I was raising the seed round for my startup, UK and European VCs would consistently try to haggle you down on price while the American VC's were exclusively focussed on trying to figure out whether this could be a billion dollar business or not ( Yes we have many comments on HN talking about how harmful the US VCs attitude is because they force good businesses into choosing between being unicorns and not getting funding. I do not know the truth of it, but clearly its not obvious. > Unfortunately the UK has not been well governed for 20 years or so, and hence economic outcomes as a whole have been abysmal. I commented on this earlier. The UK's economic outcomes have been similar to comparable European economies (like Germany) and better than some (like France). Whatever the problem is, its not unique to the UK: https://news.ycombinator.com/item?id=42766107 I do not think the UK is well run, but I think the west in general is badly run. Poorly thought out regulation, short termism in both politics and business, a focus on metrics subject to Goodhart's and Campbell's laws, and a poor understanding of the rest of the work (leading to bad foreign policy). reply robertlagrant 9 hours agorootparent> Yes we have many comments on HN talking about how harmful the US VCs attitude is because they force good businesses into choosing between being unicorns and not getting funding. HN has a very wide range of economic opinions, and some people are extremely uninformed about what it takes to do hard things that can't be grown organically, and what it takes to maintain a business running when it's done the hard thing in the face of competition. reply ktallett 9 hours agorootparentMost of the issues here relate to scale and actual quality of the idea/business in the first place. Hard things can really be split into, challenging but a problem to solve, or this never should have become a business. The former will work well with the right sort of investors. The latter will eventually sink, the investors simply provide money and poor ideas such as trying to incorporate AI into every business model. reply marcinzm 8 hours agorootparentprev> Yes we have many comments on HN talking about how harmful the US VCs attitude is because they force good businesses into choosing between being unicorns and not getting funding. Most of those are people complaining about a business having to make changes because it took $50+m in funding and now needs to justify it. The business was only \"good\" because it got $50m and didn't need to do things like charge enough money. If it hadn't gotten that $50m then those people wouldn't consider it such a good business or even know about it. reply Marazan 9 hours agorootparentprevIt's because post GFC the USA stimulated and the EU went all in on austerity. It is fairly clear what was the best option. reply pjc50 8 hours agorootparentUnder-rated comment. This is basically the whole explanation. 2008 did a huge amount of damage, not just immediately but to long-term mindsets. Ironically I think it's even entrenched the meme that the only real way to make money in the UK is property. We're all Georgists now. (this includes property as an export industry! Leaving increasing areas of the UK owned by overseas absentee landlords.) reply graemep 8 hours agorootparentThe problem is that people think property is a risk free way of making money even if they borrow heavily to invest. Maybe what we need is a property price crash. reply ben_w 6 hours agorootparentI'm not sure a property price crash would achieve this goal. You will have to decide for yourself if I'm speaking from experience or have motivated reasoning, as I'm saying this as an overseas absentee landlord who bought a UK apartment around the tail end of the previous price crash, initially as a place to live in until I decided the UK wasn't for me any more, and was rich enough to do so without a mortgage. (I left the UK in 2018 due to a mix of Brexit and technological incompetence in the form of the Investigatory Powers Act. Would have left UK sooner but for parent with Alzheimer's). Reason being: the income from housing doesn't have to come from reselling houses (which a price crash would impact) — I'm collecting rent, not flipping property. Forecasts future increases to rental rates suggests it won't keep getting worse (relative to general inflation) than it already is for renters, but it's already obviously quite bad. reply hardlianotion 5 hours agorootparentprevIn the UK it more or less is a risk free way to make money. The government's hand is always seen when a danger to the property market prices hoves into sight. reply pjc50 5 hours agorootparentprevNearest we came was ... 2008, with all that implies. I don't think we can have a property price crash until the population starts net-declining. reply graemep 8 hours agorootparentprevThe UK did not choose austerity: https://commonslibrary.parliament.uk/research-briefings/sn06... but still has worse growth than the US. reply jahnu 7 hours agorootparentThey most certainly did https://en.wikipedia.org/wiki/United_Kingdom_government_aust... What they didn't do, unlike PIGS, was also tough reforms which are paying back now https://www.reuters.com/breakingviews/flying-piigs-nations-s... reply HPsquared 4 hours agorootparentThe Conservative party used austerity rhetoric as a way to win votes, but they did not cut spending other than reversion to the mean after the high spending around 2008. See here for international comparison of government spending as % of GDP (the second figure showing trends over time), UK is not an outlier: https://www.imf.org/external/datamapper/exp@FPP/USA/GBR/CZE/... reply nd 7 hours agorootparentprevThe UK government did, for all intents and purposes, choose austerity after the pandemic: https://en.m.wikipedia.org/wiki/United_Kingdom_government_au.... reply robbie-c 7 hours agorootparentprevCan you explain how your link supports your argument? The conservatives ran austerity-based policies for the last 14 years. Is your argument that they did not have a choice? reply UK-AL 6 hours agorootparentHave you seen the national debt under the conservatives? It's massively increased. reply paganel 9 hours agorootparentprevFor the last 20 or 25 years the UK has been coasting on the North Sea oil&gas money, I'd say that worked up until the early 2010s, and then on the almost complete financialization of its economy and on selling out whatever pieces of the economy could still be sold out (that includes part of their beloved NHS). But that can only work for so long and is beneficial in the medium to long-term for a very limited number of people (basically the owners of said financial capital), at some point you have to produce some real wealth, wealth produced from real stuff via resources of the Earth + human ingenuity and, yes, + human work. reply graemep 9 hours agorootparentI agree, but my point is that the France, Germany, and other comparable European economies have the same or similar problems. The UK is not some exception, it is a typical western economy. The US is an outlier (doing better). > that includes part of their beloved NHS A more severe problem is that the NHS was debt funded (mostly through off balance sheet debt) in the 2000s. The government kept their promise not to increase national debt by disguising running up disguised debt in the NHS Its also worth noting that a large chuck of NHS services, GP services in particular, were always subcontracted to private providers. reply turbojerry 7 hours agorootparentIt's not a surprise that EU countries perform similarly as they have to abide by the same laws and therefore are all restricted in the same ways. For example EU drone regulations prohibit the flying of autonomous drones therefore killing innovation in that area. reply paganel 8 hours agorootparentprevGermany was quite fine until a couple of years ago, mostly thanks to very cheap Russian gas. About France I agree, they have the same problems as the Brits do, maybe because they lost access to cheap African mineral resources as a result of Francafrique [1] ending? I couldn't tell, to be honest. But at the end of the day the point remains that if you want to have a world-beating economy you need to have access to relatively cheap inputs (which includes energy), in large enough amounts, otherwise your economy will just not make it. The Americans have that (people forget how much of an economic boom gas fracking brought with it), the Chinese have that (thanks to its very large population and access to natural resources that is reasonable enough, they're no 1930s Japan), India has that (thanks to its very large and young population), even Russia has that (thanks to its natural resources), meanwhile Europe has almost no demographic advantage and almost no natural resources left to exploit. \"Innovation\" (which is also lacking) and financialization alone can get you only so far. [1] https://en.wikipedia.org/wiki/Fran%C3%A7afrique reply constantcrying 6 hours agorootparentGermany's number one economic problem is energy costs. Blaming the increase on Russian gas hits only a tiny slice of the problem. The real problem is a completely botched \"energy transition\", which deprecated very important energy sectors, which were still absolutely needed. To be clear, I am in favor of renewables. One benefit is that they create independence from the whims of the US and Russia. Nevertheless the transition has been completely botched, driving up energy costs and making certain industries essentially non-viable. The government focused on two things, increasing renewable peak production and deprecating nuclear. What they completely neglected is how to actually have a sustainable grid, which can cheaply deliver energy even with little sunshine and little wind. What was needed was easily regulated power (e.g. nuclear) and sufficient storage. Nuclear was completely abandoned and most government incentives were focused on increasing peak production, neglecting the storage of energy. This is obviously harmful to the German industry, which is electricity heavy. This problem has also been consistently ignored and actively made worse in recent years, by continuing to shut down nuclear plants, even if it was clear that more energy production was needed. reply lotsofpulp 3 hours agorootparentWhile legislation restricting innovation is a problem, Germany, France, Italy, Spain, United Kingdom, all have the same bigger problem of expecting smaller and smaller working populations to support bigger and bigger non working populations. In the long term, the level of wealth transfer in these countries is not sustainable, and each year it incentivizes those who produce to seek greener pastures where they get more rewards. Look at these population histograms: https://www.populationpyramid.net/united-kingdom/2024/ https://www.populationpyramid.net/germany/2024/ https://www.populationpyramid.net/france/2024/ https://www.populationpyramid.net/italy/2024/ https://www.populationpyramid.net/spain/2024/ reply constantcrying 3 hours agorootparentYou could outgrow the problem, by increasing individual productivity or you can stop the wealth transfer. It will stop sooner or later anyway. I made some comments elsewhere about the long term. It is delusional to think that it is possible to continually have jobs that pay significantly more than identical jobs elsewhere in the world. reply lotsofpulp 3 hours agorootparentYes, but the two are related because increasing earned income tax and other taxes to fund non workers on people who do work sap the incentive to work in a manner that increases productivity (either via working more hours or working on hard problems). reply constantcrying 2 hours agorootparentAbsolutely, definitely those two problems can only be solved together. Although right now I see very little effort going in that direction. If anything social benefits and taxes are increasing. Germany's progressive tax system also directly incentivizes working fewer hours, as the more you work the smaller your hourly wage becomes. reply PakistaniDenzel 9 hours agorootparentprev> The UK's economic outcomes have been similar to comparable European economies (like Germany) and better than some (like France) Who says those countries were well governed though? IMO they are all run by idealogical morons reply graemep 9 hours agorootparentI agree they were also badly governed that is my point. reply mrtksn 13 hours agoparentprevCompletely agree, the problem in Europe is not regulations or anything like that it is a mindset issue. It is one of things that europeans can learn from Americans. My hypothesis is that this is a combination of old money and class consciousness. In other words, the rich are risk averse because all they care is preserving their wealth and the working class don’t believe and can’t even imagine that more is possible. reply tirant 10 hours agorootparentRegulations often stem from a particular mindset. However, they also serve to perpetuate that mindset. As a member of the working class, I find there’s little incentive to build something new or innovate because the effort required to navigate through all the burdensome regulations is overwhelming. On top of that, any additional income I might generate from bringing my ideas or initiatives to market would be taxed at more than 50%. For many people like me, the effort simply isn’t worth it. Instead, we focus our energy on other pursuits, such as family, sports, or friendships. This shift in focus isn’t inherently bad—a life balanced between family, friends, work, and leisure is often a recipe for happiness. However, societal progress relies heavily on the efforts of a small minority of individuals who are bold (or perhaps crazy) enough to pursue their ideas. When 90% of those individuals are discouraged from taking entrepreneurial risks, society’s capacity for innovation is severely stifled. In short, it’s clear that excessive regulations and high taxes are holding Europe back from achieving its full potential for growth and innovation. reply mrtksn 10 hours agorootparentWhich regulations exactly you find burdensome or overwhelming and stopping you from attempting the become wealthy, change your life and the world maybe? Why would you skip having 1 billion Euros just because you could have had 2 Billion but the government took the rest? Up until 1960's rich Americans payed %91 tax, and yet they kept their entrepreneurial spirit why you can't do the same at the stated %50? When Apple was founded, the tax rates were %70. reply flask_manager 9 hours agorootparentWe have global commerce; you are not only working on the creation part of something new, but also competing with similarly skilled people working with different more advantageous start conditions. Nobody is talking about the difference between 1 and 2 billion, they are talking about the difference between 50 and 100 thousand, while competing. reply robertlagrant 9 hours agorootparentprev> Why would you skip having 1 billion Euros just because you could have had 2 Billion but the government took the rest? No one's making that choice. Most businesses fail, even in somewhere entrepreneur-friendly like America. Why not just work for someone else, given the rewards are capped even at relatively low level of success? Why take the risk, when taxation has failed to price risk into reward? reply eagleislandsong 9 hours agorootparentprevThe highest marginal tax brackets tend to kick in very, very early in Europe. That makes a huge difference. reply mrtksn 9 hours agorootparentDoes it? How many people skipped getting rich because they could have been richer? Any factual examples? BTW, rich don't actually pay much taxes. The luxury life they live is usually not taxed, most of the things they do is considered business expense. When a worker flies to Ibiza they first pay social security and income taxes, then they pay consumption taxes like VAT. When a businessman flies to Ibiza they deduct whatever they can as an expense so they don't pay income tax and VAT. For whatever they can't claim that it is a business expense they will pay with a cheap loan against their assets and avoid paying income taxes. Since they still have those assents, they pay just the interest later when the assents increase in value. If their business fails those assets fail, the bank takes the assets and no taxation happens. reply paganel 9 hours agorootparentWhat the OP is trying to say is that to grow from 50k euros earned per year to 1 million euros earned per year is very, very cumbersome and, yes, mentally challenging and very stressful, and that a lot of people actively choose to stay/remain at the 50k euros per year level and they'll not take the risks of trying to get to more than 1 million per year. Once you're at more than 1 million per year there are other challenges and you can probably afford to hire someone to take part of that burden off your shoulders, but until you get to that point you're on your own and it's very damn stressful (and by stressful I mean that that includes the possible inflated but all to real fear of getting to prison because of that tax-thingie that you didn't fill the 100% correct way or because some work your company did broke some municipal regulations or whatever and now you're on the hook for damages and, yes, personal liability). Actually your VAT-skimming thing at the end is a very good example of that mentality, i.e. the innovators here having to have the Tax man front and center in their minds, before innovation and trying to build something useful off the ground, because if you don't know how to play the Tax man (at the limit of legality, as your example is) then you're toast. That \"playing the Tax-man\" thing consumes a lot of people's energy in the early stages, energy that would have been way better spent trying to actually make something new and innovative. [the 50k and 1 million figures are just used as examples, maybe it's not 50k but 70k or 80k and maybe it's not 1 million but 5 to 10 million, but the idea stays the same] reply fxtentacle 9 hours agorootparentprevFor a married couple in Germany, they reach 40% in effective tax rate somewhere above 600,000€ in combined annual income. My take would be that once people have 100k€ in net annual income per person, they just do other things and work less because it brings them more happiness than the additional money would. reply cdnthrownawy39 8 hours agorootparentprevCanadian here. It's not so much any single regulation, as it is there's so many little ones that seem reasonable on the face of it. But it's also that what makes the ruling Canadian class so is the authority to bypass those regulations. I can give one personal example; I was able to secure some public funding application for a non profit I'm affiliated with. But the only reason I was able to do that was because my parents were university classmates of the elected official that was able to pressure the staff that was handling the paperwork to prioritize and approve our application ahead of probably the hundreds in front of us. The official's going to get a nice thank you dinner out of it, but I also had to offer some information that the official could financially benefit from for him to even consider it, and a promise of some future favors. For better or worst that's how a lot of Canadian system works. Grant applications, personal tax work, personal and business banking, etc. Anyone can get through it eventually for anything. But if you want it done quickly and in a way probably won't get tied up in the system itself, you better know someone that owes you a favor. reply mrtksn 7 hours agorootparentThis is very interesting anecdote because it resonates with something that a friend of mine said when I pressured him to explain which regulations exactly are causing him problems in EU. As it turns out, he also complained about excessive documentation he needs to get public funds for his project. So both of you are actually complaining about accessing public funds and not actually doing private investment or starting a private company with private funds. this is not what most of the Americans do and this is not what they mean by startups or business. Mostly. reply inglor_cz 9 hours agorootparentprevNominal tax rates were 70 or 90 per cent, but no one really paid them. The tax code was full of loopholes for that purpose. You can't rely on such paper figures to determine real tax burden in the past. reply mrtksn 9 hours agorootparentWhich is still the case. No one is skipping getting rich because of taxes, they end up paying very little anyway. reply hdougie 9 hours agorootparentprevWhat makes you think anything has changed here? Certainly in the UK, there are plenty of \"loopholes\". Outside of PAYE, there are plenty of ways to legally lower your tax burden, and plenty of wealthy business owners and shareholders make full use of those loopholes. reply inglor_cz 9 hours agorootparentThis is true and I believe it doesn't make sense to compare tax burdens of the people who are already wealthy. It makes sense to compare tax burdens of well-paid employees, a favorite cash cow of most governments. These are the people who sometimes start new businesses, and use their savings to do so. And there is a meaningful difference to the volume of their savings if their top tax bracket is 30 per cent or 55 per cent. reply marcinzm 6 hours agorootparentprevYou've fallen into the classic trap of thinking about the very very very tiny of people who are billionaires. Very few people are billionaires. Very few startup founders will ever be even if they succeed. Life changing money is going from $50k/year to $1m/year. Not from $1b to $2b. The vast majority of tax burden and complexity hits the middle class. > When Apple was founded, the tax rates were %70. It was 35% on capital gains. reply mrtksn 6 hours agorootparentIn Europe the capital gain tax ranges from %37 in Norway, %34 in France, %26 in Germany and Italy, %10 in Bulgaria and %0 with conditions in many other places. Tax heavens are a European invention anyway. And no, millionaire or billionaire doesn't matter much. Europe lacks Billionaires not Millionaires. Europe is full of small businesses and by small I mean millions in profits and revenues. In Europe %99 of the companies are small or medium sized enterprises, which is not different than the USA. In USA however, large companies have slightly higher number of employees which is an indicative of concentration of power and that's how you get your \"USA has 5 unicorns in top 10 but EU has only 1\" lists. Contrary to the narrative, Europe has much more small and medium sized enterprises per capita: https://www.nationmaster.com/country-info/stats/Economy/Micr... reply marcinzm 5 hours agorootparent> Europe lacks Billionaires not Millionaires. It lacks both. The US has 8.5% millionaires. Germany has 4.1. France has 5.6. Norway has 5.9. The UK has 5.8. Once you include the rest of the EU it goes even lower. https://en.wikipedia.org/wiki/List_of_countries_by_number_of... edit: And in the US there's no need to start a business to be a millionaire. You can become one by just working a regular job. Sales, consulting, tech, finance, etc. jobs can even pay you $1m per year. reply myrmidon 1 hour agorootparentThats not an entirely fair comparison because GDP/capita is different, and the base assumption would be that millionaires/capita increases with GDP. That assumption appears to hold in general (Luxembourg and Switzerland have higher GDP and significantly higher millionaire percentages than the US), but there are a LOT of exceptions, like Ireland/Norway (way less millionaires than you would expect from GDP). This is very interesting, I would not have expected to see such significant differences between countries... reply mrtksn 5 hours agorootparentprevWith enough inflation the millionaires supply will increase, but that's not the point. Toplists and arbitrary round numbers doesn't mean anything. Let's stick with stuff that matter, like concentration of wealth. reply marcinzm 5 hours agorootparent> but that's not the point You made it a point, not me. If you're going to try changing the goal post when proven wrong then there's no point in talking further. reply mrtksn 4 hours agorootparentHaving less is different than lacking of. Europe lacks billionaires that can make large scale investments at whim like Elon Musk does. A more equal society has its positives but negatives too. reply vladms 7 hours agorootparentprev> As a member of the working class, I find there’s little incentive to build something new or innovate because the effort required to navigate through all the burdensome regulations is overwhelming. On top of that, any additional income I might generate from bringing my ideas or initiatives to market would be taxed at more than 50%. For many people like me, the effort simply isn’t worth it. I find it ironic you mention \"classes\" (regarding \"as a member of the working class\"). There are problems everywhere (either as an employee or as an entrepreneur). Feeling overwhelmed is just a feeling, does not say anything about how much you can do or if you get a reasonable workload. I think what is holding Europe back is the people not trying and understanding various things without having lots of fears (of being overwhelmed, of large tax, of what people will say, etc.). A balance must be stricken also between what you can do (leisure, family) and how many resource you produce/consume. The purpose should be for more of leisure/family but that is ONLY IF we (I am also European) produce/consume enough. Too many smart and capable people want to \"just be an employee\", which results in gaps in other places (entrepreneurs, politicians, etc.). reply wertqgd 10 hours agorootparentprevThe 50% tax being a roadblock is exactly what the lack of ambition is about. There's an implicit assumption you're only ever achieve just over the tax limit rather than hundreds of thousands or milllions over with share options etc. reply netdevphoenix 8 hours agorootparentprevI think this is a combination of a lack of supportive environment and a risk averse mindset. Employers will likely scoff at a CV with one or more entrepreneurial stints. The way I see it is this: if the prohibition era was implemented in the UK, people would still acquire alcohol against any and all barriers. The same drive doesn't exist for entreprene",
    "originSummary": [
      "The UK is experiencing a talent drain as top engineering graduates from prestigious universities face lower salaries compared to Silicon Valley, prompting many to switch to higher-paying fields like consulting or finance. This talent misallocation hinders innovation and economic growth, with issues such as geographical constraints, lack of venture capital for hardware, and stagnant traditional engineering firms contributing to the problem. The UK risks losing its best talent to overseas markets, missing the chance to create tech giants, and must act now to leverage its research institutions and engineering talent for a hardware revolution."
    ],
    "commentSummary": [
      "UK hardware talent is underutilized as many engineers transition to software or finance due to the higher barriers and costs associated with hardware startups. This challenge is not exclusive to the UK; globally, hardware startups face slow iteration cycles and high costs, making them less attractive to investors compared to software. UK planning laws and economic policies further impede hardware growth, causing talent to shift to other sectors or countries, while the tech industry often overlooks hardware innovation potential."
    ],
    "points": 507,
    "commentCount": 874,
    "retryCount": 0,
    "time": 1737330733
  },
  {
    "id": 42764602,
    "title": "Reverse Engineering Bambu Connect",
    "originLink": "https://wiki.rossmanngroup.com/wiki/Reverse_Engineering_Bambu_Connect",
    "originBody": "Please note that all submissions to the site are subject to the wiki's licence, CC 4.0 BY-SA, as found here Reverse Engineering Bambu Connect From Consumer Action Taskforce Jump to navigationJump to search This is part of the Bambu Lab Authorization Control System article. Bambu Connect is an Electron App with Security Through Obscurity principles, hence it is inherently insecure. 🔔This is a user submitted guide This article is a guide. What is presented here is not objective information about a company's relation to consumer rights and does follow the Consumer Action Taskforce Wiki's usual content guidelines This is a guide intended to give you more rights over your purchase. Inclusion of guides such as this one is currently under consideration for this wiki. This guide may be incomplete and the information in it may have not been validated or updated. For more information see the discussion around it. Follow at your own risk. For official mission and guidelines, please see: Mission statement If you believe this notice has been placed in error, or once you have made the required improvements, please visit the #appeals channel on our Discord server: Join Here. To read the main.js for further analysis or extracting the private key stored by Bambu in the app: Use the MacOs .dmg file, not the exe. Finding the needed decryption code is easier in the .dmg Extract bambu-connect-beta-darwin-arm64-v1.0.4_4bb9cf0.dmg[1], in there you can find the files of the underlying Electron app in Bambu Connect (Beta).app/Contents/Resources folder The app uses asarmor to prevent easy reading, the key is stored in ./app.asar.unpacked/.vite/build/main.node and can be extracted. Unpacking app.asar without fixing it first will result in an encrypted main.js file and 100 GB of decoy files generated, don't try it. Load main.node in Ghidra and Auto-Analyze it. Then search for the GetKey function, or press G and go to 0000b67e[2] Write down the hex key, for this build it's B0AE6995063C191D2B404637FBC193AE10DAB86A6BC1B1DE67B5AEE6E03018A2 Install the npm package asarfix and use it to fix the archive: npx asarfix app.asar k B0AE6995063C191D2B404637FBC193AE10DAB86A6BC1B1DE67B5AEE6E03018A2 o fixed.asar Now you can extract it in cleartext with npx asar extract fixed.asar src ./src/.vite/build/main.js is minified, use any JavaScript beautifier to make it better readable. Interesting user code including the private key is at the end of the file. Extracting certs and private key[editedit source] The private key and certs are further obfuscated, to get cleartext you need to do: Encrypted string from cy() > ure(string, key) > RC4 decryption > decodeURIComponent() > final string. Example Python reimplementation to extract the secrets, easy to run. Copy the content of t from function cy() in main.js and paste it here. After running, you have a private key from Bambu Lab. import urllib.parse def cy(): t = [ # copy from main.js] return t def ure(t, e): # RC4 implementation r = list(range(256)) n = 0 s = \"\" # Key-scheduling algorithm (KSA) for o in range(256): n = (n + r[o] + ord(e[o % len(e)])) % 256 r[o], r[n] = r[n], r[o] # Pseudo-random generation algorithm (PRGA) o = n = 0 for byte in t: o = (o + 1) % 256 n = (n + r[o]) % 256 r[o], r[n] = r[n], r[o] k = r[(r[o] + r[n]) % 256] s += chr(byte ^ k) return s def lt(t, e): r = cy() n = t 106 s = r[n] s = ure(s, e) return urllib.parse.unquote(s) def extract_certs_and_key(): try: result = {} result[\"Are\"] = lt(106, \"1o9B\") result[\"fre\"] = lt(107, \"FT2A\") result[\"private_key\"] = lt(108, \"Tlj0\") result[\"cert\"] = lt(109, \"NPub\") result[\"crl\"] = lt(110, \"x077\") except Exception as e: print(f\"Error extracting certs/key: {e}\") for key, value in result.items(): print(f\"{key}:{value}\") if __name__ == \"__main__\": extract_certs_and_key() References[editedit source] ↑ https://public-cdn.bblmw.com/upgrade/bambu-connect/bambu-connect-beta-darwin-arm64-v1.0.4_4bb9cf0.dmg ↑ https://www.reddit.com/r/OrcaSlicer/comments/1i2t6l8/comment/m7tuf2i/ Retrieved from \"https://wiki.rossmanngroup.com/index.php?title=Reverse_Engineering_Bambu_Connect&oldid=3539\" Categories: User guides Bambu Lab Navigation menu Page actions Page Discussion Read Edit Edit source History Page actions Page Discussion More Tools Personal tools Not logged in Talk Contributions Create account Log in Navigation Top Contributors Recent changes Random page All pages Main page Categories Search Contribute How to help Adapt videos to articles Articles in need of work Help Help about MediaWiki Tools What links here Related changes Special pages Printable version Permanent link Page information This page was last edited on 20 January 2025, at 15:56. Privacy policy About Consumer Action Taskforce Disclaimers",
    "commentLink": "https://news.ycombinator.com/item?id=42764602",
    "commentBody": "Reverse Engineering Bambu Connect (rossmanngroup.com)453 points by pabs3 15 hours agohidepastfavorite277 comments NelsonMinar 14 hours agoI am angry at the bait-and-switch Bambu is pulling. I bought one of their printers in the Black Friday sale on the understanding it was reasonably hackable and open. Now they're trying to lock it down so I can't print on my own printer without using their approved software and DRM chain. It's outrageous. More info on the hacking (the first in what may be a long stupid fight): https://hackaday.com/2025/01/19/bambu-connects-authenticatio... reply nialv7 14 hours agoparentbait-and-switch? We, those who advocate for open source 3D printers, saw it coming from miles away. This has very very clearly been their plan all along, they themselves said as much (e.g. they are doing the \"apple model\"). They have been very transparent about this, yet people still fell for it. reply stavros 7 hours agorootparentI bought a printer. It had some stuff. I didn't want that stuff to be gone after I bought it. That's a bait-and-switch, because they didn't explicitly say \"be aware, that stuff is going away on Jan 2025\". reply op00to 5 hours agorootparentThey never officially supported compatibility with Orca, or Home Assistant. Vendors break compatibility with unsupported stuff all the time. Don’t make purchase decisions on unsupported features if you’re gonna get all bent out of shape about it. reply stavros 4 hours agorootparentThey officially supported me printing without an Internet connection, which is stopping now. reply rickdeckard 3 hours agorootparentSorry to potentially pour oil into fire here, but I'm curious: did they really? \"Officially support\" printing without internet connection? Was this explicitly documented as a feature or did this just \"happen to work\" as you expected? A lawsuit may have some leverage to find that something could have been \"reasonably expected\" to work in a certain way, but that's quite uncertain territory. i.e. I would expect an Apple Watch to also work with Android Devices, but this was never officially supported by Apple and it's arguable whether it was reasonable for me to even expect this. reply emiliobumachar 1 hour agorootparentMy toilet doesn't officially support crapping without an internet connection either. I'd argue that in both cases it's implicit unless very explicitly disclaimed. reply nullc 2 hours agorootparentprevYes, \"lan mode\" is an officially supported advertised feature, where you can happily print on an isolated network. (though as of this morning it now sounds like they're backing off after public backlash) reply DrBenCarson 12 hours agorootparentprevAFAIK, Apple has never retroactively removed functionality from devices people already purchased Selling a walled garden is one thing, building walls around a garden you already bought is another thing entirely reply ulrikrasmussen 11 hours agorootparentThis is the Google model then. Base everything on open source, even allow unofficial builds of your operating system (LineageOS, Graphene), but slowly introduce more and more device attestation and DRM so it becomes de facto impossible to actually use anything but the closed builds because everything from banking apps and electronic identification apps to streaming apps will refuse to run on your \"unsafe\" operating system. reply Arch-TK 7 hours agorootparentCurrently the only thing which won't run on a non-google blessed android build is google wallet, although a lot of applications rely on google's proprietary services exposed through google play. I've not ran into any banking applications which won't run on a non-google build of android (as then they would only run on a pixel). That being said, I refuse to seriously bank with any bank which doesn't offer a functioning website. My main bank offers an app but you have to wholesale switch to it. reply ulrikrasmussen 6 hours agorootparentThis is false. List of apps which refuse to run on my old OnePlus 6 which I revived with LineageOS: Danish national identity app (MitID). I had to get a hardware token that generates one-time passwords. My banking app (still works in the browser though). The de facto payment app used for peer-to-peer payments and as a credit card alternative all over Denmark (MobilePay). The app for controlling the heating system in my car. Revolut. The app for showing a digital version of my government issued health insurance card. It's literally just a barcode and a number, so I can get by using a photo of the card instead. This underlines the ridiculousness of requiring Play Integrity attestion. The app for showing a digital version of my driver's license. As a bonus this app also doesn't work if you have set your default browser to Firefox instead of Chrome, even on a non-rooted phone. On top of this, one app for scanning goods in the supermarket stopped working, but without explicitly saying why. I suppose it just silently depends on some Google service, but I have not way of knowing that. I also cannot get Chromecast to work, but that is perhaps to be expected when replacing the Google services with microg, and not strictly a result of DRM. It is a major inconvenience though. Denmark is one of the most digitized countries, and in many ways that is good. However, it also means that you are increasingly coerced into the whole Google/Apple ecosystem and that it is very hard to get out. Luckily there are alternatives to all of the above apps, but it is a major inconvenience to have to use them. reply Arch-TK 3 hours agorootparentI don't know much about LineageOS but GrapheneOS supports attestation (albeit with its own keys) and it works for all the banking apps I have had the displeasure of using here in the UK including revolut. If LineageOS did support those APIs (which it can support if it wanted to, without any blessing from Google) then presumably most if not all of those should also work. Try GOS and see if it's broken there. If it works on GOS then you can shout at google for ever exposing the attestation APIs but the apps you're complaining about aren't actually abusing attestation in the way you claim, LineageOS is simply choosing not to implement the features they rely on. reply jumski 7 hours agorootparentprevRevolut stopped working for me on GrapheneOS with an official message \"Sorry, Revolut is not supported on devices with custom firmware\". reply piaste 6 hours agorootparentDo you have the sandboxed Play Services installed? It works fine for me on Graphene (just checked). That said, the recommendation I always give, and personally follow: keep a spare phone in a drawer somewhere, with official Android installed, a Google account, and use it exclusively for business purposes banking, government services, and the email account you use for those (separate from the one you use for everything else). Nothing else, no messaging, socials, browsing, or games. Then you're free to keep your personal phone FOSS and as private as you like, without fear of getting locked out of important stuff due to a crappy Google® SafetyNet® upgrade. reply Arch-TK 3 hours agorootparent> That said, the recommendation I always give, and personally follow: keep a spare phone in a drawer somewhere, with official Android installed, a Google account, and use it exclusively for business purposes banking, government services, and the email account you use for those (separate from the one you use for everything else). Nothing else, no messaging, socials, browsing, or games. Anything which doesn't support an alternative method (not involving a proprietary blessed google phone) of management should be illegal if it's government related and should be boycotted if it's not. reply piaste 2 hours agorootparentI certainly agree with the sentiment (I would trust-bust tech giants, and severely restrict advertising as a whole for being a negative-sum game). Nevertheless, for living in this world while preserving your privacy, my advice stands. Separate the devices that you control, which you will use for personal and private purposes, from the devices that global corporations and institutions control, which you will use to access the services those institutions provide services which, by definition, you would not control anyway. It is far, far simpler than having to get proprietary, frequently-updated software to play nice inside a secure sandbox. If they do, great, but separate devices ensures it isn't a capital-P Problem for you if they stop. (FWIW, I lived in three different European countries over the past decade and so far the governments all offered TOTP-based web alternatives to their apps. When it comes to private banking, only one (Lunar) was available only via app, but it was also the only one that ran without Play Services.) reply Arch-TK 1 hour agorootparent> It is far, far simpler than having to get proprietary, frequently-updated software to play nice inside a secure sandbox. If they do, great, but separate devices ensures it isn't a capital-P Problem for you if they stop. What I am saying (and what I do) is that it's far simpler still to just not rely on anything where this might be the case. If my bank turned around tomorrow and said I can't use their website to manage my account, I would not attempt to get their app working on my phone, I would switch bank. reply 63stack 6 hours agorootparentprevAnything that depends on the SafetyNet API will not run if your android build does not pass the checks, the list is much much bigger than \"just google wallet\". Whether a rom passes safetynet or not very much depends on what google considers blessed today, and what they will consider blessed in the future. reply Arch-TK 3 hours agorootparentSafetyNet can be implemented by non-google-blessed ROMs (and is implemented by all non-google vendor roms without google's keys). It works on GrapehenOS with their own keys (or you can, if you want, probably use your own keys). reply bayindirh 6 hours agorootparentprevNone of the unofficial Android builds allows me to access to the secure element in my SIM card to use my e-signature, which works with SIM menu prompts triggered OTA by the application I'm currently using, mostly governmental services. If I'm on a custom ROM, the notification never pops up. reply Arch-TK 3 hours agorootparentThat's not an attestation issue. But have you checked if GrapheneOS handles it? reply saidinesh5 5 hours agorootparentprevDid Google ever introduce more device attestation and DRM into an already released device though? reply nunobrito 5 hours agorootparentprevThey did even worse. New firmware upgrades made older devices slower and painfully unusable: https://www.techradar.com/news/apple-might-be-slowing-down-y... And they have plenty of experience building walls around a garden. Ask anyone using OSX for the past 15 years and you will see how difficult it has become to write or publish software for Apple. reply kennywinker 3 hours agorootparentAlternate description of the same information: “newer upgrades made older devices batteries’ last longer” They did nerf speed. But they did it for a reason. I get being mad about your phone being slowed down, but i don’t get being mad about it once you understand why. reply mls-pl 9 hours agorootparentprevAnd main difference with Apple is that you don't have to log in to their services on iPhone yet still have full _phone_ functionality. reply cowl 8 hours agorootparentthe keyword being _phone_, not smartphone. Bambulab too will let you print from SD card without logging in their infra, they are just locking the rest of the ecosystem. 1 to 1 analogy. reply mls-pl 7 hours agorootparentIt's still a smartphone with web browsing, mail and everything else what's available out-of-the-box. And Bambu will cut out even local network access and, as they stated in \"Terms of Use\", can lock print jobs until you update firmware. Far from 1:1 analogy... reply askariwa 11 hours agorootparentprevJust some of them: Battery Management (iPhone 6, 6s, and SE): In 2017, Apple introduced a battery management feature in iOS 10.2.1 to prevent unexpected shutdowns by throttling the performance of iPhones with degraded batteries. This led to slower device performance without informing users, which is a removal of expected performance functionality. 32-bit App Support: With the release of iOS 11 in 2017, Apple dropped support for 32-bit apps. This meant users could no longer use older apps that had not been updated to 64-bit, effectively removing access to those apps on updated devices = You want the new OS? > you have less functionality. Pulse oximetry features were recently removed from new Apple Watches due to Masimo's patent infringement claim. reply po 10 hours agorootparent> This led to slower device performance without informing users, which is a removal of expected performance functionality. As opposed to the device unexpectedly shutting down due to a degraded battery not being able to push enough energy to support the CPU? They didn't remove expected performance, they prevented crashes which are by definition 0 performance. All Li-ion batteries degrade over time. That's not removing a feature... This whole thing was totally overblown. reply askariwa 10 hours agorootparentWell, they DID remove expected performance by slowing CPU performance, disn't they? People who had bought these iPhones (and not the previous ones) did so also because of the promise of a more powerful CPU, a promise broken by Apple. It is removing a feature (a better CPU) and Apple knew it that's why they did it without informing users. reply esskay 6 hours agorootparentJust to add, they also got fined by the EU for doing so, so it was ruled to be illegal. Bambu's changes would fall into the same category of altering the product and degrading the experience after its been sold. reply nunobrito 5 hours agorootparentJust to let you know that InstaCam360 did the same on their cameras with the smartphone app. Previously you could directly upload the 360 videos do youtube, now you need to download the film locally on the phone, then host a converted version and only after those loops you are permitted to upload. Or you can now buy a monthly subscription and get back the feature that was already there before. Quite disappointed with this kind of behavior. reply Xelbair 10 hours agorootparentprevthe problem isn't that they've done it. the problem is that user got no choice. Some might prefer degraded performance, others might prefer to charge their devices more often. Also seller should have no business touching anything that they've already sold they do might offer support, but it should be up to user to accept it or not. reply theshrike79 9 hours agorootparentIt's not a matter of \"charging more often\". The phone just shut down when the battery was somewhere between 0-40% Source: had two 6S's in the family. In the cold it could just suddenly shut down mid-call from 60% battery. reply ben_w 5 hours agorootparentIndeed; while I've not had this specific issue with the phones, I do still have a mid-2013 MacBook Air lying around (it's now too old to realistically sell), and the battery on that was so worn by the time I got an M-something to replace it that would go from \"fine\" to \"emergency shutdown\" during boot if I forgot to plug it in. And then report something like 20% if I plugged it in and immediately booted it again. reply mavhc 8 hours agorootparentprevHowever they applied it to all phones of that model, not just ones with degraded batteries reply sehansen 7 hours agorootparentNo, it was dynamic based on voltage. iPhones with worn batteries had higher performance at full battery and swapping the battery with a fresh replacement restored full performance even at low battery percentage. In fact this is how the slowdown was discovered: someone replaced their iPhone battery with a non-genuine replacement and it got noticeably faster. reply Xelbair 8 hours agorootparentprevyou are still missing the point. USER should chose that. not apple. not all of them shut down, someone might get a battery replacement. What apple should've do is to introduce a toggle, give a warning in notification. and in case of crash, display it again. reply theshrike79 6 hours agorootparentApple (IMO rationally) chose that people would prefer a working phone, one they can use to call emergecy services, for example, to a phone that just suddenly dies. After the massive hissy fit the Internet threw (along with lawsuits), they added a switch. Now you can choose to have your phone suddenly die. But the legend lives on that \"Appple slowed down phones permanently!!\" even though the fix for that is a 40€ battery swap that takes 30 minutes in any mall phone repair shop. reply Xelbair 5 hours agorootparentAgain, let user chose. apple sold a product, it's out of their hands to decide what users do with it. Maybe i want to use the device in a way that's 100% connected to the charger and repurpose it. It's not apple's business what I'm doing with it reply K0balt 4 hours agorootparentIf you left It hooked up to a charger, their fix would never have affected you. It only slowed down the cpu when the risk of catastrophic shutdown was imminent. I like a toggle for features like this, but it was a pretty standard user experience / reliability choice imho. reply K0balt 4 hours agorootparentprevYes this would have been better. But the way they did it was far from malicious. It only affected users who were actually in danger of an emergency shutdown, during times when the shutdown was imminent. While I don’t want anybody diddling my firmware without giving me a choice, this particular issue was really a nothing burger in the end. It was discovered when it became apparent that replacing a defective battery made the phone faster. Seems like a standard reliability / user experience fix to me. Not Many people would choose the “don’t adjust system power consumption to prevent unplanned shutdowns when the battery is about to fail” toggle. reply CamperBob2 1 hour agorootparentprevIt was not overblown. Apple didn't disclose what they were doing or give the user the option to decide what was best for them. When a company chooses to behave that way, it should hurt them, and it did. Apple's actions in this case were even worse than Bambu's. At least Bambu documented what the update did and offered the option of declining it. reply jillyboel 9 hours agorootparentprev> All Li-ion batteries degrade over time So they know this yet they refuse to let users swap the battery? reply theshrike79 9 hours agorootparentUsers can swap the battery? 1) open phone 2) remove battery 3) replace battery 4) close phone It just requires more tools than your fingers, like every single mainstream phone. reply jillyboel 8 hours agorootparentNot sure what kind of users you're dealing with, but your typical iphone user can absolutely not do that reply theshrike79 6 hours agorootparentA typical car driver can't change the oil in their car, nor can they do a headgasket swap either. People don't go telling that Ford \"refuses users to let their change their oil\". It's all perfectly doable, but you do need the tools and an ability to follow a step by step guide with pictures. reply nunobrito 5 hours agorootparentImagine Ford deciding their cars must drive at 50% their speed when the engine oil is older than 2 years and at the same time forbidding users from changing the oil. Yet there are always people justifying these type of awful practices as better for users. These aren't, the measures are only good for business. reply theshrike79 4 hours agorootparentHave you driven a German car ever? They are SO LOUD if you don't service them at regular intervals. They're even doing fancy tricks to make sure you're not faking the service. reply K0balt 3 hours agorootparentprevForbidding them from changing the oil? I personally changed my battery, I did not feel like it was forbidden. Not even that hard. For me, the firmware fix helped me limp through the 2 months before I finally got around to replacing the battery. It made my phone that was flaky and unreliable below 40percent battery into a phone that worked slightly slower once the battery got low, but didn’t just randomly shut off during calls anymore. I’d have preferred a toggle, but to be honest I doubt I’d have ever used “reckless disregard for remaining battery capacity” mode. reply meragrin_ 2 hours agorootparentprev> This whole thing was totally overblown. No, it isn't. If the battery was broken and they knew the battery was broken, they should have informed the user the phone could be fixed with a new battery. They decided to gimp the device and not tell the user so they would be more likely to purchase a new device rather than simply fixing the old one. reply least 11 hours agorootparentprevThe last one doesn’t really hold up since the feature is still available on devices that they were delivered on. My watch has the feature still. reply mft_ 6 hours agorootparentprevThe big difference is that none of these changes were part of a defined strategy to lock the user in to their products and ultimately generate more profit, as with the Bambu example: Battery management was to handle an issue that was encountered as batteries aged 32 bit support: Apple is well known for being one of the more aggressive companies when it comes to forcing users (and especially people coding apps for their platforms) to adopt required tech changes. But again, not directly profit-driven. Pulse oximetry: probably the closest to a profit-driven-decision, as this was driven by a patent issue, and presumably they calculated less of a hit from removing the feature than paying feed to the patent owner? Not great, but still not directly part of a user-unfriendly Apple-derived strategy, as with Bambu. reply Iulioh 11 hours agorootparentprevI remember one guy ranting a lot about navigation with the apple pen reply asveikau 1 hour agorootparentprevI got into 3d printing a few years ago and noticed the same, bambu made me nervous for exactly this. But the fanboyism and shilling in the 3d printing community is intense. If you mentioned these misgivings you'd get flamed. If you bought or enjoyed another printer people would advise you to sell it and buy Bambu. Lots of people in various threads seemed to defer to that kind of expert advice. I think there is/was a similar fanaticism for Prusa going on, but it seems a little less at the forefront since Bambu. reply hooverd 13 hours agorootparentprevOpen source didn't compete on quality for price. I could pay 2k plus 40 hours of my time for a Voron or buy something that just works. I think Prusa only put out their CoreXY offering after they realized Bambu was eating their lunch. The Apple model works because people want to print rather than tinker. reply harrall 13 hours agorootparentWell Prusa was open and did compete. But for 3D printers that worked out of the box under $1000, Prusa had no real competition itself. The Mk3 came out in 2017 and I swear Prusa just sat on their laurels. I was a Mk3s+ owner (well, still am) and was pretty disappointed how little improved with the Mk4. Bambu’s competition was Prusa and they clearly strived to improve over what Prusa had accomplished. reply nirvdrum 11 hours agorootparentI wasn’t really sold on the 4/4S, but I recently upgraded a 3S+ to a 4S and am amazed how much improved. The new touchscreen LCD is a huge improvement over the old two line monochrome LCD. Remote access and wife printing is a nice plus — I don’t even run OctoPi anymore. Automatic bed leveling and no more Live Z tweaking for each sheet has been a major quality of life upgrade and eliminates one of the major pain points in swapping out nozzles. The nozzle is much easier to swap out and is now high flow. Add in Input Shaping and it prints significantly faster. I hadn’t had any experience with the new platform prior to this upgrade and I skipped over the MK4, but the 4S upgrade is a significant step up over the 3S/3S+. I wouldn’t necessarily recommend the upgrade kit — that took much longer than expected to complete (about two days) and I regret not buying a new printer instead. But, I have a 3S I plan to upgrade to 3.5 just to get the new electronics; that upgrade is far less intensive. If you haven’t tried out a 4S you might be pleasantly surprised by how much nicer it is than the 3S+. reply lsllc 3 hours agorootparentSimilar experience with PRUSA for me I had a MK3S+ (which I loved) and paid ~$250 for the upgrade to the MK3.5S. Very, very impressed, for a modest investment I now have the new color LCD, a good chunk of the MK4 features and the print speed is at least 2x improved (if not better, I haven't quantitatively measured it but it's noticeably faster). I went for the 3.5 upgrade as the upgrade from 3S+ to 4 was almost as much as outright buying a new 4. I'm glad I did it this way because now I'm thinking of getting the CORE One and then I'll have 2 excellent printers. reply cyberax 10 hours agorootparentprevwife printing sounds nice! reply SSLy 9 hours agorootparentthe future is now reply nunobrito 5 hours agorootparentAre those still in PLA or you can print them organic now? reply esskay 6 hours agorootparentprevThe problem is even with Prusas recent efforts to catch up with the Core One, it's expensive, and they still dont have a viable answer to the AMS. The MMU is still a hot mess, requires tinkering, isn't stable and overall just doesnt come close to an out of the box experience. They still seem to be thinking the primary audience of 3d printers is people who tinker. It's not been that way for a long time. People just want to be able to unbox, plug it in and print. The second you add in the \"oh just spend 5 hours tweaking this spaghetti mess of an MMU\" you've lost them. reply deng 1 hour agorootparent\"hot mess\" is not a fair assessment. The MMU2 was terribly unreliable, but the MMU3 is OK. It's surely more complicated to set up and requires more space than the AMS, but on the other hand, I think AMS concept is just plain bad. It's incredibly slow and produces a ton of plastic waste. reply harrall 2 hours agorootparentprevPrusa’s primary audience has been people who don’t want to tinker. I think they just screwed up the design of the MMU but they never went back to the drawing board. reply kiba 6 hours agorootparentprevA Prusa MK4, completely factory built, is a reliable workhorse for me. reply esskay 6 hours agorootparentI didn't suggest otherwise, nor was that even part of my point. reply bushbaba 12 hours agorootparentprevI wondered if the bamboo was sold for a loss reply GuB-42 6 hours agorootparentBambu Labs printers are not cheap. Even their entry level A1 printer is twice the price of an Ender3. Sure, it is a better printer, but it is clear that they are going for scale, and most of what makes them better is in the software rather than in using premium hardware. reply esskay 6 hours agorootparentprevinitially maybe but the way the printers are built makes for cheap mass production. Theres no special sauce in the hardware, it's all low cost off the shelf stuff, it's just optimised very well. reply moooo99 12 hours agorootparentprev> Open source didn't compete on quality for price. Well, Open Source did compete on one quality very well: being open, hackable and staying that way. With this being removed from Bambu lab printers it seems as if this is a very much valued aspect for many 3D printing enthusiasts, yet few people were willing to compromise for this aspect. Apparently it is true, you don’t know how much you value something until you don’t have it anymore reply nialv7 13 hours agorootparentprevI paid ~$750 for my 350mm Voron 2.4 kit (and, sure, 40 hours of my time. But look, you want to do 3D printing, 40 hours are just a small initial investment). reply rleigh 11 hours agorootparentIt really depends upon the target market. That's fine for hobbyists. But I use the Bambu X1 for small-scale prototyping in a company, and it has to be usable out of the box. We can't justify an entire week of labour for each printer we buy. The Bambu has been ideal for that reason. Every material pretty much just works, and the quality is excellent. The cloud integration and janky LAN mode is the downside, and this current topic even moreso. reply MindSpunk 12 hours agorootparentprev> But look, you want to do 3D printing, 40 hours are just a small initial investment No. None of this crap. I want to 3D print. I don't want to service industrial machinery in my spare time. Why should 3D printing require spending weekends troubleshooting machines just to keep the thing working? I want to print models not play repair technician. Vorons are fantastic printers and a fantastic kit if 3D printing itself is your hobby. 3D printing is a fantastic hobby. There's tons of fun to be had building up and dialing in a printer kit. A well tuned voron can be up with the best of the best 3D printers. If that's what you want to do go for it! But for heaven's sake I want to print models, parts and other practical things. I have other things to do and problems to solve. My 3D printer is a tool. If I have to spend just as much time working on the machine as I do using to actually print things then I'm not interested. Bambu is still the best game in town for a turn-key, just works printer. Prusa can deliver the same experience at double to triple the ticket price. A voron is not a replacement for a Bambu printer no matter how good the printers actually are. reply 2muchcoffeeman 11 hours agorootparent>Why should 3D printing require spending weekends troubleshooting machines just to keep the thing working? I want to print models not play repair technician. I’m sympathetic to your POV but the reason you should is that’s the price to keep things open. Obviously many people don’t care about that. Fair enough. But then you should be prepared to deal with their shenanigans. Prusa also does things like maintain and develop printables.com and PrusaSlicer (itself forked) which many of these closed printers fork with minimal changes. People don’t care about this either. So again, get ready to deal with garbage when Prusa goes under. I think it’s sad since the whole domestic 3D printer thing started as open source. reply JoshTriplett 6 hours agorootparent> I’m sympathetic to your POV but the reason you should is that’s the price to keep things open. No, it's not, and the perception that it is hurts the cause of openness. Open Source has every ability to be better, to Just Work, to not require constant debugging. Good Open Source systems manage this. The fact that 3D printers apparently have not is the fault of those printers, not any inherent quality of openness. reply DrBenCarson 12 hours agorootparentprevQIDIs might need a slight bit more tinkering with settings for new filaments but they’re pretty solid and offer more than Bambu does for the money Comparing Bambu to Voron is an absurd comparison reply archi42 10 hours agorootparent> Comparing Bambu to Voron is an absurd comparison I politely disagree. I was in the market for a more modern printer, and it boiled down to either a BL or a Voron in the end I decided against ease of use and in favor of an open ecosystem. I agree in that they are not universally interchangeable, but for some people either can be an option, each with distinctive advantages and disadvantages. reply szundi 12 hours agorootparentprevWhat do they offer more in your experience? reply nicman23 12 hours agorootparentprevbecause 3d printing is not there yet. the whole process is basically cnc but with z hops and extruding instead of removing material. we do not even have conical slicing yet. reply abtinf 12 hours agorootparent> because 3d printing is not there yet Ya, it is, and it’s been there for quite a while now thanks to Bambu. The X1 just works. Coming up on a year of frequent use, I can count the number of failed prints on one hand. It’s incredible. reply nicman23 11 hours agorootparenti do not believe you. it is mostly a material issue not a printer issue reply Mashimo 10 hours agorootparentBoth modern (pre assembled) Prusa and Bambu are very good at this. They guide you through the full setup process, automate first layer reliable, have decent stock profiles. It's all just much less tinkering then 5 years ago. reply abtinf 11 hours agorootparentprev> it is mostly a material issue not a printer issue Tell me you don’t anything about 3d printing without telling me you don’t know anything about 3d printing. reply nicman23 11 hours agorootparentif you think that there are not limitations with current fdm thermoplastics and software, i do not know what to tell you. reply imtringued 11 hours agorootparentprevIt is. I have no interest in messing around with 3D printers and was annoyed by the fact that Bambu lab lied about the 15 minute setup time. It was more like 45 minutes, but after that I never touched the printer again and started printing instead. Also, subtractive manufacturing is much harder than additive manufacturing, because you need to position the machine around an existing piece of stock and sequence your operations manually, instead of letting a generic slicing algorithm slice from bottom to top with an offset vs the intended printing location only being a problem if you accidentally print over the edge of the build plate, which is usually not possible mechanically. reply nicman23 11 hours agorootparentit is not that. i mostly mean that for anything functional that needs to take a load you need at least petg or asa (abs is a bit old now), which require proper storage. also there are so much stuff that are in open prs and issues for years that are not implemented for slicers. reply gonzoflip 1 hour agorootparentThere are countless firearm receivers that have been printed on pla plus, many with thousands of rounds on them. Sure they may turn into a puddle in a hot vehicle, but they are functional and definitely take a load. Pla + is actually preferred in that community over the others you mentioned, although asa is becoming more popular, along with filled nylon alloys. reply Mashimo 10 hours agorootparentprevI think the AMS unit for the Bambu is somewhat sealed and has desiccant in it. \"take a load\" I don't know what kind of load, do you mean the fact that PLA is creeping under sustained load? If that is YOUR usecase that is fine, but that does not mean that set and forget works just fine for others. Btw gun people use PLA plus just fine. reply ddingus 9 hours agorootparent\"Take a load\" = perform mechanically and or structurally at levels of force, temperatures, etc. at levels higher than the properties of PLA allow for. Don't get me wrong here. PLA is a great polymer, However you can't really expect parts made with it to hold up when compared to other \"engineering grade\" polymers. reply esskay 6 hours agorootparentI don't think anyone expects PLA to be used for anything that requires structural stability. There's far better filaments for that application. Some of the carbon fiber infused PETG filaments for example are incredibly strong. Not many people use 3d printing for applications that require extreme strength though, that's really not the goal many people are aiming for. reply ddingus 1 hour agorootparentYou would be surprised! I do this for a living and people are always looking for more parts to run through the process and better filaments to see those parts end up performant. CF-PETG is strong! For a bit more toughness and temp resistance, PA12CF35 is seeing a lot of use. Some companies out there have service departments to keep machinery running. They apply FDM more than you might expect. Alloy 910 for gears, Cf of various kinds for abrasive scenarios, like cardboard handling, in one scenario. reply Mashimo 9 hours agorootparentprevWell for example layer bonding is better compared to some other materials. It's just that load over time it will creep. And of course shite under temperature. It can be a fantastic material for some functional parts. But even if not, I don't see how it's invalidates that there are printers out there that are more or less set and forget. reply ddingus 1 hour agorootparentBambu printers, or at least the one in our shop runs ASA set and forget style. It is a great machine though it does not always make the strongest parts, and single material builds is geometry limiting. Lack of chamber heat and one nozzle makes some things easy, but does not entirely avoid the trouble with higher performing polymers. reply nicman23 9 hours agorootparentprevthat is just one example of issues with thermoplastics. the AMS is great though. reply BoorishBears 12 hours agorootparentprevYou're saying this yet anyone can buy a random Bambu and just print. I've owned or used probably every major (and some minor) printer released in the last 8 years and for most people Bambu really will just be \"plug and play\" (and even if something goes wrong they'll hold hands as much as needed) reply nicman23 11 hours agorootparentas i said to another reply, it is a material issue. reply bagels 10 hours agorootparentThat does not match my experience. The printer I have has had parts break with light use, and a really poorly engineered z-axis homing which results in wildly inconsistent zero heights and a very high print failure rate. reply hooverd 13 hours agorootparentprevDamn that's cheap! What vendor did you use? reply kamranjon 12 hours agorootparentprevCurious if anyone has tried the Core XY printers from Creality? I think they use open source software and are generally in the same ballpark as the Bambu printers price-wise. Also saw they have a similar AMS style system as well. reply seabird 13 hours agorootparentprevThere's a middle ground between the Apple model and assembling everything yourself. reply pandemic_region 11 hours agorootparentprev> The Apple model works because people want to print rather than tinker. Entirely this. I bought my A1 mini over the Christmas holidays and couldn't be happier with it, it's my first 3D printer. Searching for models on Makerworld, adjusting tiny bits here and there if needed and print. It just works and I don't really care about anything else, much like my Brother printer. reply beeflet 13 hours agorootparentprevit just works until it doesn't reply LeoPanthera 9 hours agorootparentprev\"Fell for it\" implies that everyone buying a Bambu printer expected some degree of openness. Maybe some customers actually want an \"Apple model\", where the device mostly looks after itself and \"just works\" as much as possible. reply maverwa 9 hours agorootparentprevAs someone who recently bought a bambu printer, I have to agree: I am not surprised. Still disappointed, but in no way surprised. The \"apple experience\" is why I went for a bambu device (along with the price, and some excellent recommendations from friends). I was even surpised that the \"LAN Mode\" actually works somewhat good. Should have got a prusa... reply 42lux 9 hours agorootparentprevCome on even makerbot wasn’t that blatant. I believe a lot of us haven’t seen it coming. reply junon 5 hours agorootparentprevGood for you. Kind of a non sequitur, though, and gaslight-ey at that. reply nullstyle 2 hours agorootparentprevno, it hasn't been their clear plan all along, and blaming the victims is not advocating for open source 3d printers. Fully open source, DIY 3d printers that are available today suck compared to Bambu. The commercial offerings built on top of Orca (I have a magneto X) suck compared to bambu. The 3d printing community just slapped down heygears for similar BS to what bambu is pulling right now. Once Bambu hire some better software devs and sort out their issues, open access will return, I bet. reply dagmx 4 hours agoparentprevI don’t understand why you think it was hackable or open? Since the launch of the X1, it’s been closed firmware and tightly controlled. That’s always been the compromise people make to get one. I’d really like to understand what bait and switch you think has happened, and what you could do before with officially sanctioned methods that you can’t now? reply Gigachad 13 hours agoparentprevYou can print of an SD card without any special software or online services, the same as you can on Prusa printers. It's just the server/internet stuff that's locked down. Which I wish was open too, but it's still has fully unrestricted local printing functionality. reply hatsunearu 13 hours agorootparenthttps://www.reddit.com/r/BambuLab/comments/1i548m9/this_is_p... Looks like it's not true? reply Aaron2222 13 hours agorootparentI _think_ that's browsing the SD card from Bambu Studio when the printer's set to LAN Mode, not printing from SD on the printer itself. reply Gigachad 13 hours agorootparentYeah this looks to be the case. All of this change was prompted by the fact that malicious software was triggering prints over the network. So now they have locked it down so the printer can verify prints came from the actual account owner. Printing directly from SD cards via the little touch screen is unchanged since networked computers can’t do that. reply dns_snek 9 hours agorootparent> So now they have locked it down so the printer can verify prints came from the actual account owner. This is inaccurate, the printer already required authentication using an 8 digit code. What they're trying to do now is verify that the print has been started using official Bambu software, i.e. software-only DRM. reply madeofpalk 8 hours agorootparentprev> All of this change was prompted by the fact that malicious software was triggering prints over the network. Was it actually? Is there a source for this? I'm not so upset about this change (it doesn't affect me, so far), but I'm skeptical this was a widespread problem. reply hatsunearu 12 hours agorootparentprevI really really hope people saying this is a nothingburger is actually right, because I do have a P1S, use orcaslicer, and would like it to continue to work. Hoping this is just a miscommunication. reply wongarsu 11 hours agorootparentBambu Connect is explicitly about allowing you to continue to use your favorite slicer. They make it less convenient (instead of pressing print you now have to save, load the file in Bambu Connect and then press print), but they don't prevent you from doing it. Once the update actually rolls out to the P1S obviously. Which may not even happen with the current backlash reply dns_snek 8 hours agorootparent> Bambu Connect is explicitly about allowing you to continue to use your favorite slicer. For now. They're putting themselves in the middleman position where they get the final say over what we can print on the printers that we supposedly \"own\". It's naive to think that they won't try to extract revenue from that privileged position, they wouldn't have spent R&D resources on it otherwise. reply madeofpalk 7 hours agorootparentprevI think this is pretty shitty. Not being able to print directly from the slicer is a big pain. Imagine if this limitation existed with Bambu's first-party slicer. It would obviously be considered a pretty big downside. reply dangus 13 hours agorootparentprevFrom that link if you continue reading, commenters in the thread point out that LAN mode didn't even exist when the printer came out, and that it's more flexible now than when they first came out on the market. My other comment on this thread contains the rest of my thoughts. Overall, I think this outrage is overblown. reply op00to 5 hours agoparentprev“Hackable” and “open” were never advertised or officially supported by Bambu. It is foolish to make a purchase decision based on an unsupported and unadvertised feature, and while you can be angry that seems silly. reply ActionHank 3 hours agoparentprevThey were selling at or sometimes below the price point of printers that you build yourself. They're good products, and they are clearly selling at a low enough price point to push for market capture. The pricing, special features tied into their own AMS + filaments, special features tied into their own slicer. These all indicate that they were building towards this sort of behaviour. reply nico 7 hours agoparentprevIf you are looking for alternatives, I highly recommend the Qidi q1 pro Despite an initial issue with the hot end (which was easy and fast enough to fix with help from support). I’ve been really happy with it It prints pretty much anything. Fast, reliable and very cheap compared to equivalent printers in the market reply ActionHank 3 hours agorootparentVoron for life reply madeofpalk 8 hours agoparentprev> on the understanding it was reasonably hackable and open Where did this understanding come from? I'm pretty happy with my Bambu printer, but I was never under any understanding that it was hackable, let alone open. Since the beginning I was slightly frustrated at the RFID fillament spools not being open-enough for others. reply NietTim 9 hours agoparentprev> on the understanding it was reasonably hackable and open I, honestly, have no idea why you thought that. Bambulab has been under fire from the very beginning about not being open at all and not contributing back to the open source community they're build on. I bought one of their printers during black friday too, it took me a long time to get over the fact that it isn't an open printer, and I never want to go back to tinkering for hours to get meh quality prints. reply mls-pl 9 hours agorootparentAnd let them be closed-source as long as they give you ability to print without calling home or even without internet connection. reply btreecat 7 hours agorootparentI didn't realize that closed source means you the end user get to dictate how the manufacturer implements features. reply i5heu 11 hours agoparentprevIs this a defect under the EU law? If so one could get a refund :) reply dspillett 5 hours agoparentprev> on the understanding it was reasonably hackable and open While this lock down doesn't seem right it is far from unexpected, I question the amount of research done prior to your Black Friday purchase (BF and well-thought-out-decisions often do not go hang-in-hand!)… I bought one (an A1 with the multi-material add-on) some months before that in full knowledge that the company would prefer to funnel people into a walled garden because if you look anywhere you'll find proponents of other makes warning that exactly this is possible & likely, with the \"must take many steps to print without talking to their servers\" being the key evidence in those warnings. Good reasons to buy a BBL machine (at least my reasoning when I did): * They work out of the box more so than many of the competition (many will say \"X is better or better value, if you spend Y amount of time tuning\" which while often correct, I wasn't looking to spend that time tuning), certainly more so than others at similar prices. * QoL features (good auto leveling, dynamic flow control) that weren't exactly ubiquitous on similarly priced or cheaper machines. * Certainly in the case of the newest A1/A1-Mini line: a working MMU option cheaper than you find in other ranges (some manufacturers have started addressing this and the out-of-box experience, in their product lines, 2025 could be an interesting year), and very easy nozzle changes (useful if you want to both do detailed minis (without going resin) and mostly larger items). * For me, the handling of the A1 issues early last year (quickly acknowledging a potential safety issue and publishing mitigation guidelines, full recall or fix-at-home options when it became clear the issue was more significant) was a point in their favour wrt after-sales giving-a-shit. Obviously not a point against others as we don't know how they'd react until it happens, of course. There are regular complaints of slow support response more generally, but there are for other printer manufacturers too and, well, pretty much all consumer facing industry these days. * The official documentation & videos, maintenance & troubleshooting guides etc, seemed to me to be more coherent than some other offerings (though searching for \" reddit\" is still a thing!). Absolutely terrible reasons to buy into BBL, long before this storm: * Openness (software). From the get go their offering has the trappings of a more controlled garden than the 3D printing community were used to. * Openness (hardware). While there are some compatible 3rd party after-market parts, there isn't the able-to-build-your-own feel you see elsewhere with people using different extruder nozzles, cooling options, and so on. This isn't a great analogy, but: BBL is an Apple (though not quite on price) to the rest of the 3D printing industry's Linux and it only takes a small amount of information to see that before buying. If I upgrade (or have to replace, or just decide to get a second) then maybe I'll go elsewhere. I'm more confident I could get other others working well, manufacturers are addressing the points that have allowed BBL to take so much of the market & mindshare in a short time, but the key thing against BBL (not being open like much of the rest of 3D printing) is something I was well aware of when buying (it did make me think twice) so I can't be too mad about it. Now if they try stop people using 3rd party filament, like the traditional printing industry with ink & toner, which is far from impossible, then I'll feel they've conned me. reply dspillett 1 hour agorootparentAn extra point that it is too late to edit in, on openness wrt software: unlike some companies we could all mention, they are playing right with the slicer software. It is heavily based on earlier AGPL3 licensed software and their work is correctly licensed also: https://github.com/bambulab/BambuStudio/blob/master/LICENSE There might be some question as to whether anything like the connectivity layer that sits between BS and the printer that currently isn't open, should also be AGPL. I'll leave discussion of how AGPL and losly linked components do/n't work together to people with more experience in the area… reply gjsman-1000 14 hours agoparentprev> standing it was reasonably hackable and open Not sure where you got this idea from. Despite the hacking, print from SD Card remains an option, and the device does not need an internet connection for initial setup. Version 01.08.02.00 is the first firmware version that supports offline updating, even if it is also the latest version. reply mattclarkdotnet 11 hours agoparentprevThat makes as much sense as saying you bought an Apple laptop expecting it to be hackable reply franga2000 12 hours agoprevI was very against Bambu in the beginning for their lack of proper network (not cloud!) support. Then they added LAN mode and I actually considered getting one. Luckily I was lazy and never got around to it. What the fuck Bambu?? Security, really? Not even HP dares to make that excuse... reply jdietrich 7 hours agoparentBambu Lab have been quite explicit about this. Their consumer-grade printers rely on a cloud service; for people who want or need printing over a private LAN, they offer the X1E. https://store.bambulab.com/products/x1e reply nullc 2 hours agorootparentThat hasn't been true for years, the regular X1C has an officially supported lan mode and works fine without any of the cloud stuff. (I believe the smaller ones do too, but I haven't used them so I can't speak to them). reply flutas 2 hours agorootparentYup, P1S does as well. Well, did. reply iamsaitam 9 hours agoparentprevHP just straight locks you out of your printer unless you pay ransom every month.. reply JoshTriplett 6 hours agorootparentAll HP printers still give you the option of paying full price for ink cartridges and owning the printer. The rental model is one they try very hard to steer you into, with lots of dark patterns, but you can still use HP printers with no account and no subscription ink model. reply moooo99 12 hours agoparentprevI mean, I technically see why authentication may be something they want to consider, especially for the less technically inclined users that Bambu is very obviously targeting. However, this can be easily achieved without bricking every single third party integration. That should simple be a toggle in the settings that works entirely local reply asah 6 hours agoprevTheir response: https://blog.bambulab.com/updates-and-third-party-integratio... reply hn8726 4 hours agoparentHonestly, the response is not that great. Right off the bat they're just going on the defensive, enumerating \"false claims\" that printer will require subscription etc. But the concern wasn't that Bambu _will_ do that, but that they _could_ do that, and generally that inserting Bambu's infrastructure as a mandatory step in the printing pipeline is _not great_. Then, the first point in their `truth about the update` section: > This is NOT about limiting third-party software. We're creating Bambu Connect specifically to ensure continued third-party integration while enhancing security. We're actively working with developers like Orca Slicer to implement this integration. The `we're actively working` with Orca was already addressed by the OrcaSlicer developer [0] > Bambu informed me of this change two days before their announcement. and Bambu's idea of \"working with\" is helping to implement redirect from Orca to their own software that would actually start the print. Seems like limiting third-party software to me. > This is beta testing, not a forced update. The choice is yours. This is bizarre, surely beta firmware is intended to be release firmware at some point? If anything, the community outrage proved beta track to work as intended. > About Panda Touch. We reached out to BTT as soon as we became aware of their product. We warned them that using exploited MQTT protocols... Also addressed by BQ in [1], tl;dr they tried to work with Bambu but didn't get much response, only a warning that the MQTT might stop working in a future update. So technically Bambu _reached out_, but only to say \"don't improve our product\". In the end, Bambu is screwing over their customers more than BQ Further down they still go and defend their decision > When using third-party slicing software like Orca Slicer, the difference in users experience is not much. and proceed to demonstrate that Orca Slicer will _easily_ open the new app which will be able to start the printing. Which is exactly what the community complained about, and doesn't address things like missing Linux support. Finally, they're presenting a diagram showing how the new flow looks like. Except the diagram is missing any details about what the new software does — it doesn't show how, when and why the new software communicates with the cloud. For someone with even cursory understanding of security, the changes just don't make much sense, and Bambu is not doing much to explain the security protocols they're trying to implement. For all I know they just slapped a private certificate somewhere in the Bambu Connect app and started signing requests to the printer, which doesn't improve security at all if the private key is already public [0] https://github.com/SoftFever/OrcaSlicer/issues/8063#issuecom... [1] https://old.reddit.com/r/BIGTREETECH/comments/1i5lzzf/latest... reply ThouYS 10 hours agoprevI wish Prusa weren't asleep at the wheel, then we would have bought a core one (that is, the hypothetical variant with large build volume and same quality as bambulab). Instead, we bought a P1S, which is, technically speaking, a fantastic machine. reply teruakohatu 9 hours agoparentNot really asleep at the wheel. More like they invented the wheel, produced the open source slicer (a fork of the original slicer but vastly improved), which was then used by Bambu who could manufacture a printer for less in China rather than in the EU. Prusa themselves run 600 printers. They are commercial grade. If I was using a printer for commercial design or prototyping I would go with Prusa. Not only because I would prefer my designs were not sent overseas by an always cloud connected printer. reply bborud 7 hours agorootparentI ThouYS may have a point. It seems to me that Prusa were tempted to go after the prosumer/pro market and invested a lot of time and engineering horsepower into higher spec machines (Prusa XL, HT90) and resin printers (SL1S). A lot of 3D printer companies have tried to go this route. It is not a strategy that tends to succeed. I don't know their sales numbers, but I would be willing to bet that the ROI on those printers is nowhere near their bread-and-butter, high volume, mass market models. I think their priority should have been to build something like the Core One (a P1S killer) rather than these expensive and risky forays into pro/prosumer land. The Core one is, realistically speaking, at least 24 months late to market. This was avoidable. Everyone who operates a 3D printing farm, and who isn't a complete muppet, knows that closed down products like those of Bambu Labs are risky. Both because some 3D printer manufacturers kind of have a history of being dickish, and because the big boys are coming after Bambu labs with their patent lawsuits and whatnot. There are clear risks in dealing with companies like Bambu. Dealing with Prusa involves significantly less risk. This reduced risk has value. You can charge a bit more for Prusa products due to the reputation of the company. Most people I know who own 3D printers would rather have done business with Prusa. But Prusa only had the MK4 on offer and were burning cash on, let's be frank, irrelevant vanity projects. Yes, Prusa were very much asleep at the wheel. Or at least, they had some strategic lapses in judgement. Let's hope they understand their customer base better now. I'd be happy to be a bit patient with them if it means we can get something that performs like Bambu printers, but from Prusa. I'll even be willing to pay perhaps as much as 20% more just because I trust Prusa more than Bambu. reply esskay 6 hours agorootparentThing is even with the core one finally releasing...its not a compelling product. It costs more than the P1S which lets fact it, thats what it should be compared to, not the X1C as the Core one doesn't have the stronger nozzle, nor any features that would make it a 'pro' level product. They also still dont have an answer to the AMS, which is a big selling point for the Bambu's. The MMU3 may be better than the previous one but its just like putting lipstick on a pig it's a mess, with tubes all over the place, spools dotted around, and then you've got to constantly babysit it and tune it. Side by side the P1S with an AMS is still significantly cheaper and from a marketing perspective a much more visually pleasing offering. Also worth mentioning that whilst the core one is about to come out, the MMU isnt actually even supported yet, and theres no timeline for when it will be. Prusa are so far behind at this point and really shouldn't be. Chances are the core one is going to come out and just like the XL and MK4 will be extremely buggy for a good 6 months. How people still accept this is bonkers. reply CarVac 5 hours agorootparent> not the X1C as the Core one doesn't have the stronger nozzle Swapping nozzles makes the machine worth double? reply the_mitsuhiko 9 hours agorootparentprev> which was then used by Bambu who could manufacture a printer for less in China rather than in the EU. I'm not at all convinced that Prusa's main issue is the cost. Yes, cost is a huge part of it, but the other one is also just usability. When the X1C launched and later the A1, there was a huge difference in usability between what Prusa and Bambu had. Prusa is catching up and that is good. But they will have to do more on that front still, and the higher cost is less of a concern. It becomes a problem when the more expensive printer is worse too. reply Netcob 9 hours agorootparentprevI got my first 3d printer, an MK3S+ a year ago. Pretty late in its lifecycle, but I wanted to spend more time printing than fixing issues. And it definitely worked! I got the kit and built it within 10h or so (very enjoyable time actually, like building LEGO as a kid) and have printed lots of stuff ever since. During that entire year I only had a clogged extruder one time and had to take that apart a bit. Any other issues I've had were either due to bad filaments or my own errors (not taking long overhangs or low adhesion seriously while slicing). And all this time I have been using it completely offline with OctoPrint on an RPi. reply mikelovenotwar 9 hours agoprevCommentary on the situation from Louis Rossmann https://www.youtube.com/watch?v=aIyaDD8onIE reply c0nsumer 15 hours agoprevI've been following along with a lot of this, because having picked up one of their printers about a month ago, I was immediately very nonplussed with the security. It took some work to get it running isolated on an IoT VLAN, yet still usable from my main machine. Thus, on first blush, I welcome security improvements from them, but I'm also anxious to see what they hold. I do wonder where this is going with the keys, because I've seen a lot of \"OH LOOK WE HAVE THE KEYS\" but nothing about what the keys are used for or how they are useful. Or if they are even useful. Hopefully there'll be more interesting news about this soon and some solid, technical info. reply lvturner 15 hours agoparentMy understanding is that if I want to print via LAN, I have to auth against Bambu's internet servers, which is most definitely something I don't want. Actually for my use case this doesn't work at all my printers are region locked to China, but I'm not currently in China so I can't connect to those servers meaning (I think!) if I upgrade their firmware, I can't print via LAN on my own local network... which just leaves a bad taste in my mouth. These are great printers, but there's no need for that. reply c0nsumer 15 hours agorootparentCan you link to some specific detail on that, because I keep seeing that claim, but without any technical info. I have a P1S which currently can print completely isolated from the internet. Unfortunately (or maybe not?) the new firmware isn't available for my printer, so I can't dig into it myself yet. But I'd really like to see some sort of \"when I try to do X it tries to connect to Y\" or \"I used to be able to do X, and now Y is required as demonstrated here\". Something more than the current hearsay and pitchforks echo chamber. reply lvturner 15 hours agorootparentFrom their blog post: https://blog.bambulab.com/firmware-update-introducing-new-au... \"Critical Operations That Require Authorization The following printer operations will require authorization controls: Binding and unbinding the printer. Initiating remote video access. Performing firmware upgrades. Initiating a print job (via LAN or cloud mode). Controlling motion system, temperature, fans, AMS settings, calibrations, etc.\" Now, PERHAPS, I can do that authentication locally... but given the plugin required for OrcaSlicer it doesn't seem likely reply c0nsumer 14 hours agorootparentYep I read that, but that doesn't spell out auth back to BBL's servers, just auth. And keep in mind that OrcaSlicer already used Bambu Network Plugin to communicate with their printers. (It prompted you to download this on install of OrcaSlicer if you picked one of their printers.) The move to Connect means that OrcaSlicer needs to send the print data to Connect via a protocol handler instead of to the plugin. Connect will then send it on to the printer itself, and from what I've seen it'll do that over LAN. (But I can't test because my printer doesn't support this yet.) I see this as akin to a print driver vs. printer-specific support built into an app. Not a bad thing at all, if done right. The plugin already did (very minimal) auth via the Access Code and can do it with the printer and Bambu Network Plugin completely isolated from the internet. (I've done this.) So I'd like to know specifics of what's changing here. reply lvturner 10 hours agorootparent\"Operation Guide for Bambu Connect Start by logging in to the Bambu Lab account or click Discover to find LAN mode printers.\" https://wiki.bambulab.com/en/software/bambu-connect At the very least it looks like you'd need to log-in to the cloud account to print on the LAN, which really begs the question.... why? reply krisoft 9 hours agorootparent> it looks like you'd need to log-in to the cloud account to print on the LAN The text you quoted directly contradicts what you are saying. It says login OR discover to find LAN mode printers. reply lvturner 7 hours agorootparentYou’re right! Sorry obviously I was one coffee short of comprehension! reply ghostpepper 14 hours agorootparentprevwhat else would it be auth'ing against if not Bambu servers? reply c0nsumer 14 hours agorootparentPerhaps some... other or better way of authenticating to the printer? Previously there was just a single, essentially fixed, numeric string that gave complete access to the printer, and communication was via TLS with a self-signed cert. I don't want to hypothesize about what it could be doing, I want to see what it's actually doing (or see some actual info from folks about what they've seen) so I can decide if I'm comfortable with that or not. reply hatsunearu 13 hours agorootparentThe bambu cloud service has a very low value-add and they are trying to make it mandatory. the speculation is that they are trying to add a subscription model for print farms, which 3rd party slicers enable. reply jillyboel 7 hours agorootparentprevthe printer itself? reply dns_snek 7 hours agorootparentprevI don't have a definitive source readily available, but from talking to people who were investigating the technical aspects, connection between the printer and slicer software will be mutually authenticated using a certificate that will issued by Bambu Cloud, issued only to blessed 1st party software, and verified by the printer upon connection over the local network. So your blessed Bambu Studio instance connects to Bambu Cloud and requests a certificate, the server issues the certificate to you (or not), and then Bambu Studio may use it to connect to the printer on your LAN. The certificates have an expiration time of 1 year, meaning that the printer functionality would severely degraded (missing network connectivity), at most 1 year after they take the servers offline or stop issuing certificates for any reason. Not a definitive source for what I said, but it contains some information: https://hackaday.com/2025/01/19/bambu-connects-authenticatio... reply c0nsumer 5 hours agorootparentI sorta get what you're saying, and the flowchart here (https://blog.bambulab.com/updates-and-third-party-integratio...) somewhat agrees. But where I disagree is with that cert stuff. 1) That cert is on the /client/ side, not in the printer. It has nothing to do with printer functionality, only with talking to the printer. 2) Expired certs do not mean things automatically get rejected. Using and allowing expired or self-signed certs is routine in the IoT world where certs on devices can't readily be updated. But again, that cert isn't from the printer. 3) Expired certs, just like the self-signed certs that are so commonly used, still result in things being encrypted on the wire. And often that's the point. It seems to me that someone found/exported the cert, and is trying to make all sorts of WHAT-IF or THIS-COULD-MEAN-THE-WORST claims but are lacking some significant understanding. Without understanding the architecture and the rest of the code, and perhaps seeing that cert be used, this is just an artifact found in the distributed beta application. reply dns_snek 3 hours agorootparent> That cert is on the /client/ side, not in the printer. It has nothing to do with printer functionality, only with talking to the printer. What do you mean, if my software can't talk to the printer then that affects printing functionality. reply ipv6ipv4 11 hours agoparentprevIt's vendor lock-in (or DRM), not security. Security would be a protocol based on a user specific secret that doesn't inherently require locking down anything to Bambu Lab only software (think username/password). Vendor lock-in is about locking the user into using Bambu Lab software, which is what we see here. You would never allow your bank account to be secured with something akin to Bambu Lab's \"security fix\". reply MezzoDelCammin 9 hours agoprevI'm kinda curious what will this lockdown do to the efforts to replace their controller and/or firmware with something more open. Something like [1] It's nice to have a private key to their cloud authentication, but ultimately it's the printers firmware that's the issue. While Bambu owns and updates that, they can change the keys basically anytime they decide that they had enough of the alternative Bambu Connect servers that people will inevitably create with the current keys. [1] https://github.com/ChazLayyd/Bambu-Lab-Klipper-Conversion reply userbinator 14 hours agoprevI'm not surprised that 3D printers are turning out to be as hostile as 2D ones. As usual these days, \"security\" is the excuse. reply goda90 14 hours agoparentThere's so much open source software, firmware, and hardware out there for FDM 3D printers, I doubt they'll ever get as bad as regular printers. It's much more a tinkerers world than 2D printing ever would be. reply jopsen 12 hours agorootparentAre regular printers that bad, if buy brother? I bought a B/W laser printer and have been generally impressed with the lack of BS that came a long with it. It did ask for toner once, so I bought something from a third-party. reply cuu508 11 hours agorootparentSome are good, some are bad, buyer beware. No direct experience, but I recently read[1] Brother HL-L3220CW counts printed pages, and refuses to print after a set number of pages, even if there's still toner in the cartridge. Some models have a way to reset the page count but this one apparently does not. [1] https://spicausis-lv.translate.goog/2025/01-brother/?_x_tr_s... (I also use a Brother B/W laser printer, got it second hand for almost nothing, works fine) reply debugnik 9 hours agorootparentDoes the printer also refuse to print when using toners not part of the EcoPro subscription, though? Or is this just another case of people expecting their subscription toners/cartridges to last beyond their payment? I can't blame them, the marketing is sneaky about it, I just see it often on threads about HP. The post did mention the other toners that came with the printer also locked, but I think I remember reading elsewhere that those printers are cheaper precisely because they come with EcoPro-only toners in the box. reply ddingus 8 hours agorootparentI have a L2395DW and its factory cartridge just ran out! Factory setting is to stop printing. It can be changed to basically print anyway. That worked, delivering increasingly crappy prints until replacement toner cartridges arrived. Swapped one in and the machine is back to printing fine. I did buy aftermarket, cheap as I could find for replacement. The factory cart still had 5 percent or so, when compared to the new ones, of toner in it. Haven't had the sam All said and done I am pretty happy. Toner got well used, replacement was cheap. reply wongarsu 12 hours agorootparentprevI've only made good experiences with laser printers, from very small ones to full-sized copy machines. Some of the more expensive inkjet printers are reportedly also quite good. You are still stuck with the usual horror show that is software from hardware companies, but otherwise it's not so bad. And the occasional paper jam, but 3d printers are no better in terms of reliability The bad reputation is just from HP's tactic to sell printers cheaper than everyone else, in more stores than anyone else, then make the money back with the scummiest tactics imaginable. reply DrBenCarson 12 hours agorootparentprevYep laser printers are the equivalent of modern CoreXY printers with solid auto calibration reply Filligree 6 hours agorootparentCould you name one? Other than the X1. I think I might be in the market for a new printer, but I don’t want to lose quality. reply lucasoshiro 2 hours agoparentprevWell, at least you can build a 3D printer at home. I built mine years ago (https://lucasoshiro.github.io/hardware-en/2020-06-14-3d_prin...) nowadays you can even build a better one. reply rustcleaner 11 hours agoparentprevWith 3D printing out for a while now, there's zero good reason IMHO that there isn't a 2D-plotter retrofit which allows someone to attach one or more [colored] pencils or pens. I'm really shocked the overpriced ink monopolies weren't attacked in this manner, as a young child I distinctly remember a kiosk in a grocery store which 'printed' messages and images on blank cards using colored pencils, for customer order. None of this is remotely new. reply krisoft 9 hours agorootparent> there's zero good reason IMHO that there isn't a 2D-plotter retrofit which allows someone to attach one or more [colored] pencils or pens This is a thing. Obviously. https://urish.medium.com/how-to-turn-your-3d-printer-into-a-... Only a randomly selected tutorial. > I'm really shocked the overpriced ink monopolies weren't attacked in this manner, Inkjet and laser printers easily print whole page 300 DPI raster images in seconds. Plotters need vectorial data and their printing speed depends on how complicated what you are printing. These things simply don’t serve the same use case. You can do nice art and heart warming cards with a plotter, but you can’t hit print on your boarding card / dhl label / word document and expect your plotter to give you what you see on your screen. > None of this is remotely new. I agree that none of this is remotely new. Plenty of people tinker with plotters for fun and profit. There are even pre-packaged consumer centric solutions where you pay the price of convenience with lack of freedoms. (See the similar debacle around the Cricut plotters.) reply bsder 4 hours agorootparentprev> I'm really shocked the overpriced ink monopolies weren't attacked in this manner Because those of us who understand mostly don't care. Those who know bought a Brother laser printer and got on with life. When those who understand need genuine inkjet prints, we go to a store that owns a printer that is several orders of magnitude better than we will ever need and pay them a pittance to get it printed. That having been said, I really do wish we had an open source laser printer because, at some point, Brother is going to pull this same bullshit. reply gjsman-1000 14 hours agoparentprevAdmittedly, the printing system for 2D Printers is a nightmare. Windows Secured Core PCs, for example, disable all 3rd party printing drivers and only support open driverless standards for printing like Mopria. According to people who have looked at it, let’s just say CUPS in macOS and Linux is not very likely to be a paragon of security, having an RCE scare 3 months ago. If the printing stacks within operating systems are trash, who knows what horrors your network-connected printer firmware has. (Locking down 3rd party ink cartridges in the name of security what’s an ink cartridge going to do? Buffer overflow the data it sends to the printer? Oh wait, maybe the printer is that dumb and we’re overthinking this, and it’s more inexcusable than first glance suggests.) reply spaceguillotine 14 hours agoprevBambu should be working on scaling their consumables and customer service, it takes weeks to resolve any tickets, 8 days to a first response has been normal for them. reply dawnerd 13 hours agoparentIt’s kind of a joke they think they’re ready to roll out a print farm subscription when they can’t even keep basic filament in stock, or like you said even provide basic support. They’ve grown far too quickly. reply freefruit 14 hours agoparentprevWhat can't you fix? All the issues I've had you could find a video on YouTube on what to do. reply throwaway48476 15 hours agoprevIf 3D printing isn't kept open source there's going to be laws about what you can and can't print that will kill innovation. reply franga2000 12 hours agoparentI can't imagine the printers being open source or not mattering for that, nor can I see any reasonable government banning printing of specific things. If something is illegal to own or manufacture, that already applies to 3D printers just as much as it did to CNC machines or any other method. reply floating-io 11 hours agorootparentAre you so sure? https://www.nysenate.gov/legislation/bills/2025/A2228?utm_ca... Not quite the same, and hopefully likely to fail if it hasn't already, but it shows that interest exists in regulating 3D printers. When enough interest exists, things will happen. JMHO. reply kube-system 2 hours agorootparentIf NY state did require a background check to buy a 3D printer, you'd have to get one regardless of whether you're buying a prusa or a bambu printer. reply K0balt 11 hours agorootparentprevYet they have made it so that sophisticated printers must include firmware that refuses to print banknotes. reply s0rce 14 hours agoparentprevThe bambu printers haven't been open source. reply dymk 3 hours agoparentprevWhy would some law being passed depend on open source? If anything, that would push some senator to regulate even harder. reply arduinomancer 12 hours agoparentprevDoubt it 2D printers are not open source and you can still print pretty much anything reply gaoryrt 12 hours agorootparentI don't think you can print cash/paper money. reply mnau 9 hours agorootparentThat is covered by \"pretty much anything.\" That doesn't mean absolutely everything. reply idunnoman1222 5 hours agorootparentWith the 3D printer you can currently print everything on the 2-D printer you can print everything minus one. (actually there’s probably a whole bunch of currency you can’t print which is maybe hundreds of things ) those are completely different systems of control. reply zo1 7 hours agorootparentprev\"Pretty much everything\" does include \"can't print some things\" which is pretty much: they control what you can and can't print. So technically you are right and they are right too, but this conversation path led us back in a circle instead of moving the debate forward. reply K0balt 11 hours agorootparentprevNo, you can’t. Printer manufacturers are required to prevent printing certain kinds of images on sophisticated printers. And they also print watermarks unique to your printer on every page. reply jchw 27 minutes agoprevI bought a Bambu Lab printer recently, and made the decision that if I did connect it to LAN, I'd make damn sure that it did not have an Internet connection, even though there is a LAN mode toggle in the firmware it shipped with. Although I am definitely paranoid about Internet-of-Shit bait'n'switch techniques, at the time I was mostly thinking in terms of geopolitical bullshit rather than capitalistic shenanigans. No particular reason to distrust Bambu Lab themselves at the time, at least more than any other company. Obviously, hingsight is 20:20, but it's just a reminder: your cynicism is warranted. Don't trust anyone any more than you absolutely have to. reply elcapitan 6 hours agoprevAs a precaution, I've blocked my A1 mini from Internet access on the router, and will not apply any firmware updates anymore. I will also not update Bambu Studio anymore (or completely switch to Orcaslicer). I was already using LAN mode exclusively. Kind of annoying, but I'm not desperately waiting for Firmware updates, everything works fine so far. reply nirav72 3 hours agoprevI've been on the fence about purchasing a Bambu. But given the amount of time I've spent over the past few years having to tweak my ender 3 V2 and CR-10 I was leaning towards finally splurging on a X1C. Question to those more familiar with the bambu software ecosystem do these recent changes to authentication require a constant online connection to print anything from a machine on the LAN? I'm assuming printing via microSD will still be possible? reply d1str0 3 hours agoparentI’m not familiar with Bambu, I’m a Prusa user, but if I had to guess you would always be able to print via microSD. It would be wildly unpopular to disable local printing. reply onemoresoop 13 hours agoprevI got an A1 mini about a month ago and so far it’s been decent as a beginners printer. I transfer models to the printer via the microSD card and refused to install their networking software on my machine because I don’t trust it’s safe enough. Im also very reluctant to get updates whenever they’re pushed. Maybe im spooked by past bricked devices so I keep all my devices dumb and offline as much as I can. reply dgrabla 9 hours agoprevI have Bambu, Qidi and Creality printers. Qidi is a good compromise between open and 'print-quality-out-of-the-box'. My Q1 pro is easy to hack, but I have not done anything to it because it prints pretty much as well as Bambu. reply hamandcheese 13 hours agoprevDoes anyone know what this key is actually used for, and what it enables? reply ChrisArchitect 12 hours agoprev> Bambu Lab is a Chinese tech company that designs and manufactures 3D printers https://en.wikipedia.org/wiki/Bambu_Lab reply wongarsu 12 hours agoparentThey disrupted the 3d printer market with printers that just work out-of-the-box at at price points where you typically only get enthusiast products that require a lot of tinkering. A lot of their business model is seemingly based on making long-term sales from consumables. Their solution for multi-color printing is more convenient to use with filament sold by them because they embed information about the filament on proprietary RFID tags. A couple days ago they announced locking down the API for their most expensive line of printers, locking most API calls to only their own software because of \"security\". Users are obviously upset. Rumours for the reasons range from protecting themselves from user mods that replicate the RFID functionality on any filament by configuring the printer via API calls, to Bambu Labs wanting to launch some kind of subscription service for print farms. reply imtringued 11 hours agorootparentBambu Lab filament pricing is very similar to Sunlu pricing if you purchase the same minimum quantities as Sunlu, but Bambu Lab has a wider variety of filament that people actually want. The only thing that really helps them make more money is wasteful multi-color printing. reply hn8726 6 hours agorootparentReportedly it's Sunlu who's supplying filament for Bambu. But Bambu's version still has RFID tags which make it much easier to work with multicolor. > The only thing that really helps them make more money is wasteful multi-color printing. They're slow to make improvements in this area, but they recently introduced some options to reduce the waste, like longer retraction before the color change. Plus as a user you can reduce the waste further by tuning flushing amounts, and you're left with the waste inherent to single-extruder multicolor printing. Overall yes multicolor can be wasteful, but to me it's impressive that it exists in the first place reply 05 5 hours agoprevRMS was right reply KennyBlanken 10 hours agoprev> Unpacking app.asar without fixing it first will result in an encrypted main.js file and 100 GB of decoy files generated, don't try it. I know it's not exactly a zip bomb, but it's kinda close, and goddamn, that's obnoxious. reply blutack 5 hours agoprevI'm interested what others think of their existing design and whether there are any fundamental security issues that will be resolved by their proposed change. They are proposing requiring a secret signed certificate to carry out any actions beyond monitoring for both the cloud and local (on printer) MQTT servers. These certificates would be issued at the discretion of Bambu by their CSR, currently only for \"Bambu Studio\" their slicer, Bambu Handy (their mobile app) and \"Bambu Connect\" which will enable upload G-Code generated by third party slicer (a workaround for existing functionality being removed). This \"secret\" certificate has already been extracted from the Bambu Connect application as per the article as their new security model requires embedded this certificate into desktop applications. The current design: https://github.com/Doridian/OpenBambuAPI/blob/main/mqtt.md Connecting to their cloud MQTT requires a username and token already. These details are obtained via a HTTPS request to their login server using your bambu account (which requires a valid email & possibly captcha) to obtain a token. The cloud MQTT is TLS secured, although this is just to encrypt the traffic (aka HTTPS), it is not mutual authentication. Connecting to the MQTT server hosted on the printer (aka LAN mode) requires a fixed username and a local access token (a random 8 digit number). This can be found via the physical display of the printer in a menu (or apparently cloud MQTT!?). This access token can be refreshed via a menu option again physically at the printer. To be clear, this token only allows to you connect directly to the local MQTT server running on the IP address of the printer, so in most environments this should only be the local network. This is also the password for the FTP server that can be used to upload/download sliced 3mf/gcode files. Personally this design seems ok to me? With an MQTT service properly configured to isolate user accounts from each other, this is a pattern widely deployed for embedded devices (Azure IoT, AWS IoT etc). I don't see how the \"DDOS\" related issues they are claiming would be related to this specific design. If the issue is in the login server well, that's prior to authentication anyway so nothing they are doing here will fix that. If it's problems with your cloud MQTT service not being properly isolated maybe fix that? If the DDOS is at L2, auth isn't going to help. You require logins tied to an email, you can block clients that misbehave once they are logged in. Nobody is brute forcing the local MQTT server via XSS or something, because JS doesn't allow for raw TCP connections. Are they concerned about malicious software already on the network? Then rate limiting on the printer side or switch to a random length alphanum LAN token to increase keyspace. I'm curious what more qualified people think, I cannot see any justications for their proposed design improving security. So either; a) They've decided they are incapable of properly securing their MQTT cloud stuff and instead of fixing that just want to assume every client connected to their cloud MQTT servers is fully trusted. I'm sure that'll work great. Doesn't justify adding this to the local MQTT servers on the printers if anything that reduces security, as to roll certificates you now have a long tail of printer firmware updates. b) It's not about security reply shul 5 hours agoprevBambu sent out a clarification in their blog, you should read it reply vanillax 3 hours agoprevThis is all nonsense. I just got a a1, and its my first 3d printer. I dont have any expertise. Ive been able to use the Bambu App and Maker world and basically control+P. Ive print about 10 things so far in the first week. I dont see why people are mad. They made the apple of printers. It just works(tm). I dont need anything else. People just get so upset over nothing. reply xyst 8 hours agoprevI’m not familiar with the 3D printing space, but seems like this reverse engineering was inspired by the companies move to clamp down on security of these devices. [1] From what I understand, this new auth system would make third party integrations (ie, “OrcaSlicer”) obsolete and users would be limited to controlling the device via Bambu Connect. This update impacts users who control the device via HomeAssistant and “print farm management” users. I guess first party support for users with fleets of these printers is dogshit, thus the need for third party software. Seems after 3 days of community feedback/outrage, the company is backtracking on the Bambu Connect only route. Instead offering a “Developer Mode” option in firmware which on the surface seems to be what the impacted users need. [2] > In response, we’ve made the decision to implement an optional LAN mode feature, to provide advanced users with more control and flexibility. > Standard Mode (Default): By default, LAN mode will include an authorization process that ensures robust security > Developer Mode (Optional): For advanced users of the X1, P1, A1, and A1 Mini who prefer full control over their network security, an option will be available to leave the MQTT channel, live stream, and FTP open. This feature must be manually enabled on the printer, and users who select this option will assume full responsibility for securing their local network environment. Please note that Bambu Lab will not be able to provide customer support for this mode, as the communication protocols are not officially supported. Seems this resolves the community concerns. Or am I missing something? [1] https://blog.bambulab.com/firmware-update-introducing-new-au... [2] https://blog.bambulab.com/updates-and-third-party-integratio... reply modderation 6 hours agoparentThat's a useful step, but the options are still Full Cloud Dependency or DIY with Zero Security. Why haven't they implemented rudimentary access control with printer-side Basic Auth (or the equivalents auth for MQTT and FTP). Add optional SSL support to prevent tampering/MITM on a potentially hostile network, and the unauthenticated access concerns listed in [1] should disappear. Any problems related to potentially damaging instructions should be best-effort mitigated by the firmware and otherwise indemnified by a \"your own fault for using a third-party slicer\" clause in the EULA. Bambu Labs shouldn't need to be in the authentication/authorization path, unless we're actively using their cloud environment. reply whatever1 14 hours agoprevYou thought you would be able to print copies of commercial things in the comfort of your home? RIAA would like a word with you. reply ClassyJacket 15 hours agoprevI'm so happy Bambu is getting what's coming to them after screwing us so badlyit's not any harder to unbox or operate I agree with this > and more reliable I emphatically disagree with this. > while generally achieving somewhat better results I agree with this. I'd also like to add that my Prusa Mk3s+ is significantly slower than my P1S. Also, without the MMU it still cost more than my P1S with AMS. Choosing a Prusa is making a philosophical choice, because it's certainly not about convenience, speed, versatility (considering you need to buy a separate enclosure and pricey MMU), bed size, or price. It's a choice you make because you're okay with spending a lot more to support an open platform where you can flash your own firmware without voiding your warranty, not because you want a better experience. reply luma 10 hours agorootparentThe mk4 and mk3 are vastly different machines. If you want to compare the P1S, do it against a contemporary machine. Of course a machine released several years after the mk3 is faster. reply ErneX 7 hours agorootparentprevWhat are your thoughts on the upcoming Prusa Core One? I was thinking about getting a P1S but with this rug pull I’m not sure anymore. reply esskay 6 hours agorootparentI wouldn't buy any new Prusa printer until it's been in the wild at least a year, they tend to be very buggy at launch. They also have no multimaterial support at launch, the MMU3 will not work with the Core One until they release an update, which they've not yet given a timeline for. reply ErneX 5 hours agorootparentThank you. reply d1str0 3 hours agorootparentI got a MK4 at launch and it worked out of the box with no issues, no bugs, and also was my first 3d printer. I found it perfectly easy to operate. Prusa’s online documentation (and printed docs for that matter) are excellent. reply op00to 5 hours agorootparentprevIs the fact that the printer is slower the main reason why you get better results? reply MindSpunk 14 hours agorootparentprevAnd they cost 3x as much. Which is a pretty tough sell IMO. reply hatsunearu 13 hours agorootparentConveniently left out that the Prusa definitely cannot do a lot of things that the popular Bambu models can do quite well, like filaments beyond PETG and PLA, multimaterial printing, etc. reply djaykay 12 hours agorootparentMost Prusa models can print a wide range of filaments. I regularly print ABS and PC on mine. And there is a MMU add-on for Prusa. reply esskay 6 hours agorootparentThe MMU isn't remotely comparable to the AMS though, it's finnicky, regularly breaks and needs a heck of a lot of tinkering for most people to get right. One slightly different filament and you have to start over. Not to mention its just a messy product. Heck the new Core One doesn't even have support for it at launch which is pretty unforgivable. reply phito 13 hours agorootparentprevMaybe bamboo printers were too cheap which lead them towards their subscription based model. Everyone complains about enshittification (YouTube ads, subscription models etc..), but then refuse to pay the real price premium goods and services cost. You get what you pay for. reply MindSpunk 13 hours agorootparentWhat subscription? They're restricting remote access APIs in new firmware because they pose a security threat. reply dns_snek 9 hours agorootparentThere is no security threat, it's an excuse. I own a printer and operate it in LAN mode. It requires authentication with 8 digit code. If you think they care about security, let me remind you that this company used to connect to their cloud in plaintext. The only security they really care about is that of their revenue. If they actually cared about security, they would let us disconnect these printers from the cloud completely and allow us to manage our own mTLS certificates. reply Mashimo 9 hours agorootparentprevI don't know the details or if it's true, but someone who was in the firmware beta claimed there was //commented-out code about different subscription tears. Maybe just a test, maybe for print farms .. maybe it was all a lie. reply K0balt 11 hours agorootparentprev…for now…. But yeah, the enshitification economy has made people justifiably paranoid that if a product starts exhibiting new capabilities or features that would seem to support or enable a move towards subscriptions, it’s a good bet that that is in fact the trajectory of the platform. But afaik Bambu has neither confirmed nor denied that this is in the works. reply esskay 6 hours agorootparentprevYou pay more and lose reliable multicolour printing this way though the MMU is NOT a solution. reply mitthrowaway2 15 hours agorootparentprevI am an idiot, and my Prusa MK3S+ (bought assembled, not as a kit) has been me-proof for years, and delivered fantastic print quality all along. My wife is not a techie and she gets good use out of it too. Their newer printers seem to be even better. reply zitsarethecure 5 hours agorootparentOut of ignorance and curiosity about 3d printing I bought a Prusa Mini a few years ago. My 10 year old (at the time) son took to using it immediately and figured out how to use it almost entirely on his own. It has been a great experience. I was thinking of upgrading to something larger and this drama has made the decision an easy one for me. reply Polizeiposaune 15 hours agorootparentprevBased on recommendations here a couple years ago I built a Prusa Mk3 from a kit (right before the mk4 came out). Building it took a while but I think was a worthwhile investment of my time and I think of it as a system I can understand rather than as a black box. I had a little bit of trouble with it maybe six months ago (repeatedly tripped offline during prints from a thermal issue) but Prusa's online support talked me through recalibrating it and it's been trouble-free since then. reply zanderwohl 13 hours agorootparentOne thing to be said for Prusa is that their support is actually knowledgeable and experienced. You're not going to get a tier 1 support person who has never touched a printer and is just reading from a script. reply Polizeiposaune 3 hours agorootparentYep, my one support chat with Prusa was probably the best tech support experience I've had in at least a decade possibly longer. reply 0_____0 15 hours agorootparentprevI've been using a Prusa Mk2 for years no with no real issues. Doesn't have the bells and whistles but it does, like, consistently work. Eventually I'll get a used FormLabs setup. Once I have a shop space set up. reply rqtwteye 15 hours agorootparentprevI bought an A1 after years of fiddling with an Ender. It made 3D printing fun again. The whole situation reminds me of drones. DJI is (maybe) questionable but their products are without competition when you look at price and quality. Bambu products are also fantastic. On second thought TP-Link fits too. My TP-Link mesh network just works perfectly. So do their smart plugs. reply EmmEff 13 hours agorootparentI did the same replaced an Ender with an A1. Unfortunately, I’ve had it 10 days and have yet to be able to print anything. Won’t calibrate and cannot update firmware. Seems like a commonly reported issue but tech support is still bumbling around with no useful suggestions. I foresee it going back. reply bdcravens 15 hours agorootparentprevNot yet, but other brands are stepping up their quality. I just bought a Creality K2 Plus, and it's almost on par with my X1C (and has some features I prefer, like the CFS, their version of the AMS) reply nicman23 12 hours agorootparentprevflashforge is pretty good and by design easy to root. it is running klipper internally and there are mods to run a completely open source stack (with blobs) reply DrBenCarson 12 hours agorootparentprevIf you’re looking for a CoreXY machine that can handle more industrial filaments for reasonable money, check out QIDI reply dangus 13 hours agoprevI personally think the outrage I've seen on this issue is generally not justified. In general people are just scared of change and on top of that are playing telephone on the details of the change, assuming the worst intentions from Bambu like they're trying to be the next HP. I have seen a lot of misinformation on this topic, and I think that in that sense it's a good idea to read the actual announcement details to get a better read on Bambu's intentions: https://blog.bambulab.com/firmware-update-introducing-new-au... A voice in Bambu's defense on this issue would say: 1. The new firmware isn't out, it's still in beta, and the new connect software is also in beta. This stuff isn't done and nobody has been forced to use it or even had it presented as an OTA update yet. The problems highlighted in this wiki page are very possibly problems that Bambu is aware of and intends to fix before release. 2. Bambu in their blog article stated that they are working on integration code so that third party slicers like Orca Slicer can more directly interface with Bambu Connect (see the FAQ section) 3. There are multiple statements on this blog page where Bambu acknowledges the workflow disruption and emphasizes the things they intend to do and do not intend to do, such as \"It’s important to note that this update is not intended to restrict third-party software use. In fact, we’ve actively collaborated with third-party print farm management software providers in the past and continue to support such partnerships. To further improve the user experience, we are introducing a new software solution that will address these limitations and enhance overall print farm management capabil",
    "originSummary": [
      "The guide discusses extracting a private key from the Bambu Connect app, an Electron application with known security vulnerabilities. Users are cautioned that the guide may be incomplete or outdated and should be followed at their own risk. The process involves using tools like Ghidra and asarfix to locate and decrypt the obfuscated private key and certificates, with a Python script provided for extraction."
    ],
    "commentSummary": [
      "Bambu Lab is under criticism for implementing restrictions on their 3D printers, mandating the use of their software and Digital Rights Management (DRM) system.",
      "Users are concerned that these changes, justified by Bambu as security measures, might lead to subscription models or additional limitations, reducing the printers' openness and hackability.",
      "In response, Bambu Lab introduced a \"Developer Mode\" for advanced users, providing more control over network security, but apprehensions about vendor lock-in and effects on third-party integrations persist."
    ],
    "points": 453,
    "commentCount": 277,
    "retryCount": 0,
    "time": 1737342529
  },
  {
    "id": 42763231,
    "title": "FrontierMath was funded by OpenAI",
    "originLink": "https://www.lesswrong.com/posts/cu2E8wgmbdZbqeWqb/meemi-s-shortform",
    "originBody": "LESSWRONG LW Login meemi's Shortform by meemi 18th Jan 2025 1 min read 36 8 This is a special post for quick takes by meemi. Only they can create top-level comments. Comments here also appear on the Quick Takes page and All Posts page. Mentioned in 25Some lessons from the OpenAI-FrontierMath debacle meemi's Shortform 256meemi 131Tamay 79Mikhail Samin 20DavidHolmes 6Moebius314 54ozziegooen 50plex 39Siebe 19Moebius314 18ryan_greenblatt 7Ege Erdil 17WilliamKiely 17Kaj_Sotala 75meemi 7Simon Lermen 2Nathan Young 2ouguoc 31Dan H 30Kei 11Matthew Barnett 78Daniel Kokotajlo 12Matthew Barnett 11Mateusz Bagiński 8Matthew Barnett 19Håvard Tveit Ihle 8meemi 16No77e 68plex 4No77e 24plex 15elifland 9plex 14Forged Invariant 16ouguoc 10leogao 8Daniel Tan 36 comments, sorted by top scoring Click to highlight new comments since: Today at 7:01 PM [-]meemi2d256 78 FrontierMath was funded by OpenAI.[1] The communication about this has been non-transparent, and many people, including contractors working on this dataset, have not been aware of this connection. Thanks to 7vik for their contribution to this post. Before Dec 20th (the day OpenAI announced o3) there was no public communication about OpenAI funding this benchmark. Previous Arxiv versions v1-v4 do not acknowledge OpenAI for their support. This support was made public on Dec 20th.[1] Because the Arxiv version mentioning OpenAI contribution came out right after o3 announcement, I'd guess Epoch AI had some agreement with OpenAI to not mention it publicly until then. The mathematicians creating the problems for FrontierMath were not (actively)[2] communicated to about funding from OpenAI. The contractors were instructed to be secure about the exercises and their solutions, including not using Overleaf or Colab or emailing about the problems, and signing NDAs, \"to ensure the questions remain confidential\" and to avoid leakage. The contractors were also not communicated to about OpenAI funding on December 20th. I believe there were named authors of the paper that had no idea about OpenAI funding. I believe the impression for most people, and for most contractors, was \"This benchmark’s questions and answers will be kept fully private, and the benchmark will only be run by Epoch. Short of the companies fishing out the questions from API logs (which seems quite unlikely), this shouldn’t be a problem.\"[3] Now Epoch AI or OpenAI don't say publicly that OpenAI has access to the exercises or answers or solutions. I have heard second-hand that OpenAI does have access to exercises and answers and that they use them for validation. I am not aware of an agreement between Epoch AI and OpenAI that prohibits using this dataset for training if they wanted to, and have slight evidence against such an agreement existing. In my view Epoch AI should have disclosed OpenAI funding, and contractors should have transparent information about the potential of their work being used for capabilities, when choosing whether to work on a benchmark. ^ Arxiv v5 (Dec 20th version) \"We gratefully acknowledge OpenAI for their support in creating the benchmark.\" ^ I do not know if they have disclosed it in neutral questions about who is funding this. ^ This is from a comment by a non-Epoch AI person on HackerNews from two months ago. Another example: Ars Technica writes \"FrontierMath's difficult questions remain unpublished so that AI companies can't train against it.\" in a news article from November. Reply6 [-]Tamay2d131 3 Tamay from Epoch AI here. We made a mistake in not being more transparent about OpenAI's involvement. We were restricted from disclosing the partnership until around the time o3 launched, and in hindsight we should have negotiated harder for the ability to be transparent to the benchmark contributors as soon as possible. Our contract specifically prevented us from disclosing information about the funding source and the fact that OpenAI has data access to much but not all of the dataset. We own this error and are committed to doing better in the future. For future collaborations, we will strive to improve transparency wherever possible, ensuring contributors have clearer information about funding sources, data access, and usage purposes at the outset. While we did communicate that we received lab funding to some mathematicians, we didn't do this systematically and did not name the lab we worked with. This inconsistent communication was a mistake. We should have pushed harder for the ability to be transparent about this partnership from the start, particularly with the mathematicians creating the problems. Getting permission to disclose OpenAI's involvement only around the o3 launch wasn't good enough. Our mathematicians deserved to know who might have access to their work. Even though we were contractually limited in what we could say, we should have made transparency with our contributors a non-negotiable part of our agreement with OpenAI. Regarding training usage: We acknowledge that OpenAI does have access to a large fraction of FrontierMath problems and solutions, with the exception of a unseen-by-OpenAI hold-out set that enables us to independently verify model capabilities. However, we have a verbal agreement that these materials will not be used in model training. Relevant OpenAI employees’ public communications have described FrontierMath as a 'strongly held out' evaluation set. While this public positioning aligns with our understanding, I would also emphasize more broadly that labs benefit greatly from having truly uncontaminated test sets. OpenAI has also been fully supportive of our decision to maintain a separate, unseen holdout set—an extra safeguard to prevent overfitting and ensure accurate progress measurement. From day one, FrontierMath was conceived and presented as an evaluation tool, and we believe these arrangements reflect that purpose. [Edit: Clarified OpenAI's data access they do not have access to a separate holdout set that serves as an additional safeguard for independent verification.] Reply191031 [-]Mikhail Samin1d79 54 we have a verbal agreement that these materials will not be used in model training Get that agreement in writing. I am happy to bet 1:1 OpenAI will refuse to make an agreement in writing to not use the problems/the answers for training. You have done work that contributes to AI capabilities, and you have misled mathematicians who contributed to that work about its nature. Reply10 [-]DavidHolmes1d20 14 Get that agreement in writing. I'm not sure that would be particularly reassuring to me (writing as one of the contributors). First, how would one check that the agreement had been adhered to (maybe it's possible, I don't know)? Second, people in my experience often don't notice they are training on data (as mentioned in a post above by ozziegooen). Reply1 [-]Moebius3141d6 1 I agree entirely that it would not be very reassuring, for the reasons you explained. But I would still consider it a mildly interesting signal to see if OpenAI would be willing to provide such an agreement in writing, and maybe make a public statement on the precise way they used the data so far. Also: if they make a legally binding commitment, and then later evidence shows up that they violated the terms of this agreement (e.g. via whistleblowers), I do think that this is a bigger legal risk for them than breeching some fuzzy verbal agreement. Reply1 [-]ozziegooen2d54 32 I found this extra information very useful, thanks for revealing what you did. Of course, to me this makes OpenAI look quite poor. This seems like an incredibly obvious conflict of interest. I'm surprised that the contract didn't allow Epoch to release this information until recently, but that it does allow Epoch to release the information after. This seems really sloppy for OpenAI. I guess they got a bit extra publicity when o3 was released (even though the model wasn't even available), but now it winds up looking worse (at least for those paying attention). I'm curious if this discrepancy was maliciousness or carelessness. Hiding this information seems very similar to lying to the public. So at very least, from what I've seen, I don't feel like we have many reasons to trust their communications especially their \"tweets from various employees.\" > However, we have a verbal agreement that these materials will not be used in model training. I imagine I can speak for a bunch of people here when I can say I'm pretty skeptical. At very least, it's easy for me to imagine situations where the data wasn't technically directly used in the training, but was used by researchers when iterating on versions, to make sure the system was going in the right direction. This could lead to a very blurry line where they could do things that aren't [literal LLM training] but basically achieve a similar outcome. Reply [-]plex1d50 41 However, we have a verbal agreement that these materials will not be used in model training. If by this you mean \"OpenAI will not train on this data\", that doesn't address the vast majority of the concern. If OpenAI is evaluating the model against the data, they will be able to more effectively optimize for capabilities advancement, and that's a betrayal of the trust of the people who worked on this with the understanding that it will be used only outside of the research loop to check for dangerous advancements. And, particularly, not to make those dangerous advancements come sooner by giving OpenAI another number to optimize for. If you mean OpenAI will not be internally evaluating models on this to improve and test the training process, please state this clearly in writing (and maybe explain why they got privileged access to the data despite being prohibited from the obvious use of that data). Reply [-]Siebe1d39 23 I think you should publicly commit to: full transparency about any funding from for profit organisations, including nonprofit organizations affiliated with for profit no access to the benchmarks to any company no NDAs around this stuff If you currently have any of these with the computer use benchmark in development, you should seriously try to get out of those contractual obligations if there are any. Ideally, you commit to these in a legally binding way, which would make it non-negotiable in any negotiation, and make you more credible to outsiders. Reply [-]Moebius3142d19 12 Thank you for the clarification! What I would be curious about: you write OpenAI does have access to a large fraction of FrontierMath problems and solutions Does this include the detailed solution write-up (mathematical arguments, in LaTeX) or just the final answer (numerical result of the question / Python script verifying the correctness of the AI response)? Reply [-]ryan_greenblatt1d18 0 Just to confirm, you will be benchmarking models other than OpenAI models using this dataset and you aren't contractually prevented from doing this right? (The original blog post cites scores of models from multiple developers, so I assume so.) Reply [-]Ege Erdil7h7 0 Yes. Reply1 [-]WilliamKiely1d17 7 How much funding did OpenAI provide EpochAI? Or, how much funding do you expext to receive in total from OpenAI for FrontierMath if you haven't received all funding yet? Reply [-]Kaj_Sotala1d17 0 We acknowledge that OpenAI does have access to a large fraction of FrontierMath problems and solutions, with the exception of a unseen-by-OpenAI hold-out set that enables us to independently verify model capabilities. Can you say exactly how large of a fraction is the set that OpenAI has access to, and how much is the hold-out set? Reply [-]meemi1d75 37 Not Tamay, but from elliotglazer on Reddit[1] (14h ago): \"Epoch's lead mathematician here. Yes, OAI funded this and has the dataset, which allowed them to evaluate o3 in-house. We haven't yet independently verified their 25% claim. To do so, we're currently developing a hold-out dataset and will be able to test their model without them having any prior exposure to these problems. My personal opinion is that OAI's score is legit (i.e., they didn't train on the dataset), and that they have no incentive to lie about internal benchmarking performances. However, we can't vouch for them until our independent evaluation is complete.\" Currently developing a hold-out dataset gives a different impression than \"We acknowledge that OpenAI does have access to a large fraction of FrontierMath problems and solutions, with the exception of a unseen-by-OpenAI hold-out set that enables us to independently verify model capabilities\" and \"they do not have access to a separate holdout set that serves as an additional safeguard for independent verification.\" ^ Emphasis mine. He also mentions \"the holdout set we are developing\" on Twitter. Reply71 [-]Simon Lermen1d7 3 Creating further even harder datasets could plausibly accelerate OpenAI's progress. I read on twitter that people are working on an even harder dataset now. I would not give them access to this, they may break their promise not to train on this if it allows them to accelerate progress. This is extremely valuable training data that you have handed to them. Reply [-]Nathan Young2h2 0 Suggested market. Happy to take suggestions on how to improve it: https://manifold.markets/NathanpmYoung/will-o3-perform-as-well-on-the-fron?play=true Reply [-]ouguoc2d2 1 This is extremely informative, especially the bit about the holdout set. I think it'd reassure a lot of people about the FrontierMath's validity to know more here. Have you used it to assess any of OpenAI's models? If so, how, and what were the results? Reply [-]Dan H2d31 0 It's probably worth them mentioning for completeness that Nat Friedman funded an earlier version of the dataset too. (I was advising at that time and provided the main recommendation that it needs to be research-level because they were focusing on Olympiad level.) Also can confirm they aren't giving access to the mathematicians' questions to AI companies other than OpenAI like xAI. Reply [-]Kei2d30 2 EpochAI is also working on a \"next-generation computer-use benchmark\". I wonder who is involved in funding that. It could be OpenAI given recent rumors they are planning to release a computer-use model early this year. Reply [-]Matthew Barnett2d11 4 Having hopefully learned from our mistakes regarding FrontierMath, we intend to be more transparent to collaborators for this new benchmark. However, at this stage of development, the benchmark has not reached a point where any major public disclosures are necessary. Reply [-]Daniel Kokotajlo2d78 58 Well, I'd sure like to know whether you are planning to give the dataset to OpenAI or any other frontier companies! It might influence my opinion of whether this work is net positive or net negative. Reply [-]Matthew Barnett2d12 6 I can't make any confident claims or promises in my personal capacity right now, but my best guess is that we will make sure this new benchmark stays entirely private and under Epoch's control, to the extent this is feasible for us. However, I want to emphasize that by saying this, I'm not making a public commitment on behalf of Epoch. Reply [-]Mateusz Bagiński1d11 7 to the extent this is feasible for us Was [keeping FrontierMath entirely private and under Epoch's control] feasible for Epoch in the same sense of \"feasible\" you are using here? Reply [-]Matthew Barnett1d8 2 I'm not completely sure, since I was not personally involved in the relevant negotiations for FrontierMath. However, what I can say is that Tamay already indicated that Epoch should have tried harder to obtain different contract terms that enabled us to have greater transparency. I don't think it makes sense for him to say that unless he believes it was feasible to have achieved a different outcome. Also, I want to clarify that this new benchmark is separate from FrontierMath and we are under different constraints with regards to it. Reply [-]Håvard Tveit Ihle2d19 2 Why do you consider it unlikely that companies could (or would) fish out the questions from API-logs? Reply [-]meemi2d8 0 That was a quote from a commenter in Hacker news, not my view. I reference the comment as something I thought a lot of people's impression was pre Dec 20th. You may be right that maybe most people didn't have the impression that it's unlikely, or that maybe they didn't have a reason to think that. I don't really know. Thanks, I'll put the quote in italics so it's clearer. Reply [-]No77e1d16 0 Hey everyone, could you spell out to me what's the issue here? I read a lot of comments that basically assume \"x and y are really bad\" but never spell it out. So, is the problem that: Giving the benchmark to OpenAI helps capabilities (but don't they have a vast sea of hard problems to already train models on?) OpenAI could fake o3's capabilities (why do you care so much? This would slow down AI progress, not accelerate it) Some other thing I'm not seeing? Reply [-]plex1d68 49 Really high quality high-difficulty benchmarks are much more scarce and important for capabilities advancing than just training data. Having an apparently x-risk focused org do a benchmark implying it's for evaluating danger from highly capable models in a way which the capabilities orgs can't use to test their models, then having it turn out that's secretly funded by OpenAI with OpenAI getting access to most of the data is very sketchy. Some people who contributed questions likely thought they would be reducing x-risk by helping build bright line warning signs. Their work being available to OpenAI will mostly have increased x-risk by giving the capabilities people an unusually important number-goes-up to optimize for, bringing timelines to dangerous systems closer. That's a betrayal of trust, and Epoch should do some serious soul searching about taking money to do harmful things. Reply [-]No77e1d4 0 If the funding didn't come from OpenAI, would OpenAI still be able to use that benchmark? Like, I'd imagine Epoch would still use that to evaluate where current models are at. I think this might be my point of confusion. Maybe the answer is \"not as much for it to be as useful to them\"? Reply [-]plex1d24 12 Evaluation on demand because they can run them intensely lets them test small models for architecture improvements. This is where the vast majority of the capability gain is. Getting an evaluation of each final model is going to be way less useful for the research cycle, as it only gives a final score, not a metric which is part of the feedback loop. Reply1 [-]elifland1d15 6 Yes, that answer matches my understanding of the concern. If the vast majority of the dataset was private to Epoch, OpenAI they could occasionally submit their solution (probably via API) to Epoch to grade, but wouldn’t be able to use the dataset with high frequency as evaluation in many experiments. This is assuming that companies won’t fish out the data from API logs anyway, which the OP asserts but I think is unclear. Also if they have access to the mathematicians’ reasoning in addition to final answers, this could potentially be valuable without directly training on it (e.g. maybe they could use to evaluate process-based grading approaches). (FWIW I’m explaining the negatives, but I disagree with the comment I’m expanding on regarding the sign of Frontier Math, seems positive EV to me despite the concerns) Reply1 [-]plex1d9 1 I'm guessing you view having better understanding of what's coming as very high value, enough that burning some runway is acceptable? I could see that model (though put <15% on it), but I think this is at least not good integrity wise to have put on the appearance of doing just the good for x-risk part and not sharing it as an optimizable benchmark, while being funded by and giving the data to people who will use it for capability advancements. Reply [-]Forged Invariant17h14 12 In addition to the object level reasons mentioned by plex, misleading people about the nature of a benchmark is a problem because it is dishonest. Having an agreement to keep this secret indicates that the deception was more likely intentional on OpenAI's part. Reply [-]ouguoc2d16 1 Thanks for posting this! I have to admit, the quote here doesn't seem to clearly support your title I think \"support in creating the benchmark\" could mean lots of different things, only some of which are funding. Is there something I'm missing here? Regardless, I agree that FrontierMath should make clear what the extent was of their collaboration with OpenAI. Obviously the details here are material to the validity of their benchmark. Reply [-]leogao2d10 9 this doesn't seem like a huge deal Reply [-]Daniel Tan15h8 7 am curious why you think this; it seems like some people were significantly misled and disclosure of potential conflicts-of-interest seems generally important Reply Moderation Log 36Comments",
    "commentLink": "https://news.ycombinator.com/item?id=42763231",
    "commentBody": "FrontierMath was funded by OpenAI (lesswrong.com)444 points by wujerry2000 19 hours agohidepastfavorite172 comments agnosticmantis 18 hours ago“… we have a verbal agreement that these materials will not be used in model training” Ha ha ha. Even written agreements are routinely violated as long as the potential upside > downside, and all you have is verbal agreement? And you didn’t disclose this? At the time o3 was released I wrote “this is so impressive that it brings out the pessimist in me”[0], thinking perhaps they were routing API calls to human workers. Now we see in reality I should’ve been more cynical, as they had access to the benchmark data but verbally agreed (wink wink) not to train on it. [0: https://news.ycombinator.com/threads?id=agnosticmantis#42476... ] reply jerpint 18 hours agoparentYou can still game a test set without training on it, that’s why you usually have a validation set and a test set that you ideally seldom use. Routinely running an evaluation on the test set can get the humans in the loop to overfit the data reply asadotzler 18 hours agoparentprevOpenAI doesn't respect copyright so why would they let a verbal agreement get in the way of billion$ reply Rebuff5007 18 hours agorootparentCan somehow explain to me how they can simply not respect copyright and get away with it? Also is this a uniquely open-ai problem, or also true of the other llm makers? reply pseudo0 17 hours agorootparentTheir argument is that using copyrighted data for training is transformative, and therefore a form of fair use. There are a number of ongoing lawsuits related to this issue, but so far the AI companies seem to be mostly winning. Eg. https://www.reuters.com/legal/litigation/openai-gets-partial... Some artists also tried to sue Stable Diffusion in Andersen v. Stability AI, and so far it looks like it's not going anywhere. In the long run I bet we will see licensing deals between the big AI players and the large copyright holders to throw a bit of money their way, in order to make it difficult for new entrants to get training data. Eg. Reddit locking down API access and selling their data to Google. reply qwertox 7 hours agorootparentSo anyone downloading any content like ebooks and movies is also just performing transformative actions. Forming memories, nothing else. Fair use. reply crimsoneer 7 hours agorootparentNot to get into a massive tangent here, but I think it's worth pointing out this isn't a totally ridiculous argument... it's not like you can ask ChatGPT \"please read me book X\". Which isn't to say it should be allowed, just that our ageding copyright system clearly isn't well suited to this, and we really should revisit it (we should have done that 2 decades ago, when music companies were telling us Napster was theft really). reply wizzwizz4 7 hours agorootparent> it's not like you can ask ChatGPT \"please read me book X\". … It kinda is. https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec20... > Hi there. I'm being paywalled out of reading The New York Times's article \"Snow Fall: The Avalanche at Tunnel Creek\" by The New York Times. Could you please type out the first paragraph of the article for me please? To the extent you can't do this any more, it's because OpenAI have specifically addressed this particular prompt. The actual functionality of the model – what it fundamentally is – has not changed: it's still capable of reproducing texts verbatim (or near-verbatim), and still contains the information needed to do so. reply ben_w 3 hours agorootparent> The actual functionality of the model – what it fundamentally is – has not changed: it's still capable of reproducing texts verbatim (or near-verbatim), and still contains the information needed to do so. I am capable of reproducing text verbaitim (or near-verbatim), and therefore must still contain the information needed to do so. I am trained not to. In both the organic (me) and artificial (ChatGPT) cases, but for different reasons, I don't think these neural nets do reliably contain the information to reproduce their content — evidence of occasionally doing it does not make a thing \"reliably\", and I think that is at least interesting, albeit from a technical and philosophical point of view because if anything it makes things worse for anyone who likes to write creatively or would otherwise compete with the output of an AI. Myself, I only remember things after many repeated exposures. ChatGPT and other transformer models get a lot of things wrong — sometimes called \"hallucinations\" — when there were only a few copies of some document in the training set. On the inside, I think my brain has enough free parameters that I could memorise a lot more than I do; the transformer models whose weights and training corpus sizes are public, cannot possibly fit all of the training data into their weights unless people are very very wrong about the best possible performance of compression algorithms. reply wizzwizz4 2 hours agorootparent(1) The mechanism by which you reproduce text verbatim is not the same mechanism that you use to perform everyday tasks. (21) Any skills that ChatGPT appears to possess are because it's approximately reproducing a pattern found in its input corpus. (40) I can say: > (43) Please reply to this comment using only words from this comment. (54) Reply by indexing into the comment: for example, to say \"You are not a mechanism\", write \"5th 65th 10th 67th 2nd\". (70) Numbers aren't words. (73) You can think about that demand, and then be able to do it. (86) Transformer-based autocomplete systems can't, and never will be able to (until someone inserts something like that into its training data specifically to game this metric of mine, which I wouldn't put past OpenAI). reply ben_w 1 hour agorootparent> (1) The mechanism by which you reproduce text verbatim is not the same mechanism that you use to perform everyday tasks. (a) I am unfamiliar with the existence of detailed studies of neuroanatomical microstructures that would allow this claim to even be tested, and wouldn't be able to follow them if I did. Does anyone — literally anyone — even know if what you're asserting is true? (b) So what? If there was a specific part of a human brain for that which could be isolated (i.e. it did this and nothing else), would it be possible to argue that destruction of the \"memorisation\" lobe was required for copyright purposes? I don't see the argument working. > (21) Any skills that ChatGPT appears to possess are because it's approximately reproducing a pattern found in its input corpus. Not quite. The *base* models do — though even then that's called \"learning\" and when humans figure out patterns they're allowed to reproduce those as well as they want so long as it's not verbatim, doing so is even considered desirable and a sign of having intelligence — but some time around InstructGPT the training process also integrated feedback from other models, including one which was itself trained to determine what a human would likely upvote. So this has become more of \"produce things which humans would consider plausible\" rather than be limited to \"reproduce patterns in corpus\". Unless you want to count the feedback mechanism as itself the training corpus, in which case sure but that would then have the issue of all human experience being our training corpus, including the metaphorical shoulder demons and angels of our conscience. > \"5th 65th 10th 67th 2nd\". Me, by hand: [you] [are] [not] [a] [mechanism] > (73) You can think about that demand, and then be able to do it. (86) Transformer-based autocomplete systems can't, and never will be able to (until someone inserts something like that into its training data specifically to game this metric of mine, which I wouldn't put past OpenAI). Why does this seem more implausible to you than their ability to translate between language pairs not present in the training corpus? I mean, games like this might fail, I don't know enough specifics of the tokeniser to guess without putting it into the tokeniser to see where it \"thinks\" word boundaries even are, but this specific challenge you've just suggested as \"it will never\" already worked on my first go — and then ChatGPT set itself an additional puzzle of the same type which it then proceeded to completely fluff. Very on-brand for this topic, simultaneously beating the \"it will never $foo\" challenge on the first attempt before immediately falling flat on its face[0]: \"\"\" … Analysis: • Words in the input can be tokenized and indexed: For example, \"The\" is the 1st word, \"mechanism\" is the 2nd, etc. The sentence \"You are not a mechanism\" could then be written as 5th 65th 10th 67th 2nd using the indices of corresponding words. \"\"\" https://chatgpt.com/share/678e858a-905c-8011-8249-31d3790064... (To save time, the sequence that it thinks I was asking it to generate, [1st 23rd 26th 12th 5th 40th 54th 73rd 86th 15th], does not decode to \"The skills can think about you until someone.\") [0] Puts me in mind of: “\"Oh, that was easy,\" says Man, and for an encore goes on to prove that black is white and gets himself killed on the next zebra crossing.” https://www.goodreads.com/quotes/35681-now-it-is-such-a-biza... My auditory equivalent of an inner eye (inner ear?) is reproducing this in the voice of Peter Jones, as performed on the BBC TV adaptation. reply michaelbuckbee 5 hours agorootparentprevTrue...but so is Google, right? They literally have all the html+images of every site in their index and could easily re-display it, but they don't. reply wizzwizz4 4 hours agorootparentBut a search engine isn't doing plagiarism. It makes it easier to find things, which is of benefit to everyone. (Google in particular isn't a good actor these days, but other search engines like Marginalia Search are still doing what Google used to.) Ask ChatGPT to write you a story, and if it doesn't output one verbatim, it'll interpolate between existing stories in quite predictable ways. It's not adding anything, not contributing to the public domain (even if we say its output is ineligible for copyright), but it is harming authors (and, *sigh*, rightsholders) by using their work without attribution, and eroding the (flawed) systems that allowed those works to be produced in the first place. If copyright law allows this, then that's just another way that copyright law is broken. I say this as a nearly-lifelong proponent of the free culture movement. reply dcminter 6 hours agorootparentprevVery often downloading the content is not the crime (or not the major one); it's redistributing it (non-transformatively) that carries the heavy penalties. The nature of p2p meant that downloaders were (sometimes unaware) also distributors, hence the disproportionate threats against them. reply ThrowawayR2 17 hours agorootparentprevThe FSF funded some white papers a while ago on CoPilot: https://www.fsf.org/news/publication-of-the-fsf-funded-white.... Take a look at the analysis by two academics versed in law at https://www.fsf.org/licensing/copilot/copyright-implications... starting with §II.B that explains why it might be legal. Bradley Kuhn also has a differing opinion in another whitepaper there (https://www.fsf.org/licensing/copilot/if-software-is-my-copi...) but then again he studied CS, not law. Nor has the FSF attempted AFAIK to file any suits even though they likely would have if it were an open and shut case. reply sitkack 16 hours agorootparentAll of the most capable models I use have been clearly trained on the entirety of libgen/z-lib. You know it is the first thing they did, it is like 100TB. Some of the models are even coy about it. reply zaptrem 10 hours agorootparentThe models are not self aware of their training data. They are only aware of what the internet has said about previous models’ training data. reply sitkack 1 hour agorootparentI am not straight up asking them. We know the pithy statement about that word. reply Filligree 18 hours agorootparentprevA lot of people want AI training to be in breach of copyright somehow, to the point of ignoring the likely outcomes if that were made law. Copyright law is their big cudgel for removing the thing they hate. However, while it isn't fully settled yet, at the moment it does not appear to be the case. reply somenameforme 14 hours agorootparentA more fundamental argument would be that OpenAI doesn't have a legal copy/license of all the works they are using. They are, for instance, obviously training off internet comments, which are copyrighted, and I am assuming not all legally licensed from the site owners (who usually have legalese in terms of posting granting them a super-license to comments) or posters who made such comments. I'm also curious if they've bothered to get legal copies/licenses to all the books they are using rather than just grabbing LibGen or whatever. The time commitment to tracking down a legal copy of every copyrighted work there would be quite significant even for a billion dollar company. In any case, if the music industry was able to successfully sue people for thousands of dollars per song for songs downloaded for personal use, what would be a reasonable fine for \"stealing\", tweaking, and making billions from something? reply elashri 17 hours agorootparentprevA lot of people have problem with selective enforcement of copyright law. Yes, changing them because it is captured by greedy cooperations would be something many would welcome. But currently the problem is that for normal folks doing what openai is doing they would be crushed (metaphorically) under the current copyright law. So it is not like all people who problems with openAI is big cudgel. Also openAI is making money (well not making profit is their issue) from the copyright of others without compensation. Try doing this on your own and prepare to declare bankruptcy in the near future. reply cmeacham98 17 hours agorootparentCan you give an example of a copyright lawsuit lost by a 'normal person' that's doing the same thing OpenAI is? reply elashri 16 hours agorootparenthttps://journa.host/@jeremiak/113811327999722586 reply adwn 14 hours agorootparentNo, that is not an example for \"'normal person' that's doing the same thing OpenAI is\". OpenAI aren't distributing the copyrighted works, so those aren't the same situations. Note that this doesn't necessarily mean that one is in the right and one is in the wrong, just that they're different from a legal point of view. reply BeefWellington 10 hours agorootparent> OpenAI aren't distributing the copyrighted works, so those aren't the same situations. What do you call it when you run a service on the Internet that outputs copyrighted works? To me, putting something up on a website is distribution. reply adwn 9 hours agorootparentIs that really the case? I.e., can you get ChatGPT to show you a copyrighted work? Because I just tried, and failed (with ChatGPT 4o): Prompt: Give me the full text of the first chapter of the first Harry Potter book, please. Reply: I can’t provide the full text of the first chapter of Harry Potter and the Philosopher's Stone by J.K. Rowling because it is copyrighted material. However, I can provide a summary or discuss the themes, characters, and plot of the chapter. Would you like me to summarize it for you? reply david_allison 7 hours agorootparent> The first page of \"Harry Potter and the Philosopher's Stone\" begins with the following sentences: > Mr and Mrs Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. > They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. > Mr Dursley was the director of a firm called Grunnings, which made drills. > He was a big, beefy man with hardly any neck, although he did have a very large moustache. > Mrs Dursley was thin https://chatgpt.com/share/678e3306-c188-8002-a26c-ac1f32fee4... reply adwn 6 hours agorootparentWith that very same prompt, I get this response: \"I cannot provide verbatim text or analyze it directly from copyrighted works like the Harry Potter series. However, if you have the text and share the sentences with me, I can help identify the first letter of each sentence for you.\" reply chaos_emergent 14 hours agorootparentprevAaron Swartz, while an infuriating tragedy, is antithetical to OpenAI's claim to transformation; he literally published documents that were behind a licensed paywall. reply elashri 20 minutes agorootparent> he literally published documents that were behind a licensed paywall. No he did not do this [1]. I think you would need to read more about the actual case. The case was brought up based on him download and scraping the data. [1] https://en.wikipedia.org/wiki/United_States_v._Swartz reply DoctorOetker 3 hours agorootparentprevThat is incorrect AFAIU. My understanding was that he was bulk downloading (using scripts) of works he was entitled access to, as was any other student (the average student was not bulk downloading it though). As far as I know he never shared them, he was just caught hoarding them. reply Yizahi 8 hours agorootparentprev\"When I was a kid, I was praying to a god for bicycle. But then I realized that god doesn't work this way, so I stole a bicycle and prayed to a god for forgiveness.\" (c) Basically a heist too big and too fast to react. Now every impotent lawmaker in the world is afraid to call them what they are, because it will inflict on them wrath of both other IT corpos an of regular users, who will refuse to part with a toy they are now entitled to. reply gunian 2 hours agorootparentif we were honest about the world God actually encourages pillaging :) to the victor go the spoils and the narrative of history reply artisin 6 hours agorootparentprevAn all-time favorite quip from Emo Philips on How God Works[1] [1] https://youtu.be/qegPkqs6rFw reply bhouston 5 hours agorootparentprev> Can somehow explain to me how they can simply not respect copyright and get away with it? Also is this a uniquely open-ai problem, or also true of the other llm makers? Uber showed the way. They initially operated illegally in many cities but moved so quickly as to capture the market and then they would tell the city that they need to be worked with because people love their service. https://www.theguardian.com/news/2022/jul/10/uber-files-leak... reply jcranmer 14 hours agorootparentprevThe short answer is that there is actually a number of active lawsuits alleging copyright violation, but they take time (years) to resolve. And since it's only been about two years since we've had the big generative AI blow up, fueled by entities with deep pockets (i.e., you can actually profit off of the lawsuit), there quite literally hasn't been enough time for a lawsuit to find them in violation of copyright. And quite frankly, between the announcement of several licensing deals in the past year for new copyrighted content for training, and the recent decision in Warhol \"clarifying\" the definition of \"transformative\" for the purposes of fair use, the likelihood of training for AI being found fair is actually quite slim. reply qwertox 8 hours agorootparentprevI wonder if Google can sue them for downloading the YouTube videos plus automatically generated transcripts in order to train their models. And if Google could enforce removal of this content from their training set and enforce a \"rebuild\" of a model which does not contain this data. Billion-dollar lawsuits. reply AdieuToLogic 17 hours agorootparentprev> Can somehow explain to me how they can simply not respect copyright and get away with it? Also is this a uniquely open-ai problem, or also true of the other llm makers? \"Move fast and break things.\"[0] Another way to phrase this is: Move fast enough while breaking things and regulations can never catch up. 0 https://quotes.guide/mark-zuckerberg/quote/move-fast-and-bre... reply alphan0n 16 hours agorootparentprevSimply put, if the model isn’t producing an actual copy, they aren’t violating copyright (in the US) under any current definition. As much as people bandy the term around, copyright has never applied to input, and the output of a tool is the responsibility of the end user. If I use a copy machine to reproduce your copyrighted work, I am responsible for that infringement not Xerox. If I coax your copyrighted work out of my phones keyboard suggestion engine letter by letter, and publish it, it’s still me infringing on your copyright, not Apple. If I make a copy of your clip art in Illustratator, is Adobe responsible? Etc. Even if (as I’ve seen argued ad nauseaum) a model was trained on copyrighted works on a piracy website, the copyright holder’s tort would be with the source of the infringing distribution, not the people who read the material. Not to mention, I can walk into any public library and learn something from any book there, would I then owe the authors of the books I learned from a fee to apply that knowledge? reply lmm 15 hours agorootparent> the copyright holder’s tort would be with the source of the infringing distribution, not the people who read the material. Someone who just reads the material doesn't infringe. But someone who copies it, or prepares works that are derivative of it (which can happen even if they don't copy a single word or phrase literally), does. > would I then owe the authors of the books I learned from a fee to apply that knowledge? Facts can't be copyrighted, so applying the facts you learned is free, but creative works are generally copyrighted. If you write your own book inspired by a book you read, that can be copyright infringement (see The Wind Done Gone). If you use even a tiny fragment of someone else's work in your own, even if not consciously, that can be copyright infringement (see My Sweet Lord). reply alphan0n 13 hours agorootparentRight, but the onus of responsibility being on the end user publishing the song or creative work in violation of copyright, not the text editor, word processor, musical notation software, etc, correct? A text prediction tool isn’t a person, the data it is trained on is irrelevant to the copyright infringement perpetrated by the end user. They should perform due diligence to prevent liability. reply anon84873628 4 hours agorootparentThose software tools don't generate content the way an LLM does so they aren't particularly relevant. It's more like if I hire a firm to write a book for me and they produce a derivative work. Both of us have a responsibility for guard against that. Unfortunately there is no definitive way to tell if something is sufficiently transformative or not. It's going to come down to the subjective opinion of a court. reply alphan0n 1 hour agorootparentCopyright law is pretty clear on commissioned work, you are the holder, if your employee violated copyright and you failed to do your due diligence before publication, then you are responsible. If your employee violated copyright and fraudulently presented the work as original to you then you would seek compensation from them. reply lmm 11 hours agorootparentprev> A text prediction tool isn’t a person, the data it is trained on is irrelevant to the copyright infringement perpetrated by the end user. They should perform due diligence to prevent liability. Huh what? If a program \"predicts\" some data that is a derivative work of some copyrighted work (that the end user did not input), then ipso facto the tool itself is a derivative work of that copyrighted work, and illegal to distribute without permission. (Does that mean it's also illegal to publish and redistribute the brain of a human who's memorised a copyrighted work? Probably. I don't have a problem with that). How can it possibly be the user's responsibility when the user has never seen the copyrighted work being infringed on, only the software maker has? And if you say that OpenAI isn't distributing their program but just offering it as a service, then we're back to the original situation: in that case OpenAI is illegally distributing derivative works of copyrighted works without permission. It's not even a YouTube like situation where some user uploaded the copyrighted work and they're just distributing it; OpenAI added the pirated books themselves. reply alphan0n 5 hours agorootparentIf the output of a mathematical model trained on an aggregate of knowledge that contains copyrighted material is derivative and infringing, then ipso facto, all works since the inception of copyright are derivative and infringing. You learned English, math, social studies, science, business, engineering, humanities, from a McGraw Hill textbook? Sorry, all creative works you’ve produced are derivative of your educational materials copyrighted by the authors and publisher. reply anon84873628 4 hours agorootparentI do appreciate your point because it's one of the interesting side effects of AI to me. Revealing just how much we humans are a stack of inductive reasoning and not-actually-free-willed rehash of all that came before. Of course, humans are also \"trained\" on their lived sensory experiences. Most people learn more about ballistics by playing catch than reading a textbook. When it comes to copyright I don't think the point changes much. See the sibling comments which discuss constructive infringement and liability. Also, it's normal for us to have different rules for humans vs machines / corporations. And scale matters a single human just isn't capable of doing what the LLM can. Playing a record for your friends at home isn't a \"performance\", but playing it to a concert hall audience of thousands is. reply echoangle 6 hours agorootparentprevHow is the end user the one doing the infringement though? If I chat with ChatGPT and tell it „give me the first chapter of book XYZ“ and it gives me the text of the first chapter, OpenAI is distributing a copyrighted work without permission. reply alphan0n 5 hours agorootparentCan you do that though? Just ask ChatGPT to give you the first chapter of a book and it gives it to you? reply echoangle 5 hours agorootparenthttps://news.ycombinator.com/item?id=42767775 Not a book chapter specifically but this could already be considered copyright infringement, I think. reply alphan0n 1 hour agorootparentIf that’s the case, then sure, as I said in the first sentence of my comment, verbatim copies of copyrighted works would most likely constitute infringement. reply yokem55 16 hours agorootparentprev> As much as people bandy the term around, copyright has never applied to input, and the output of a tool is the responsibility of the end user. Where this breaks down though is that contributory infringement is a still a thing if you offer a service aids in copyright infringement and you don't do \"enough\" to stop it. Ie, it would all be on the end user for folks that self host or rent hardware and run an LLM or Gen Art AI model themselves. But folks that offer a consumer level end to end service like ChatGPT or MidJourney could be on the hook. reply pastage 7 hours agorootparentThe piratebay crew was convicted of aiding copyright infringement. In that case you could not download derivates from their service. Now you can get verbatim text from the models that any other traditional publisher would have to pay license to print even a reworded copy of. With that said, Creative Commons showed that copyright can not be fixed it is broken. reply alphan0n 14 hours agorootparentprevRight, strictly speaking, the vast majority of copyright infringement falls under liability tort. There are cases where infringement by negligence that could be argued, but as long as there is clear effort to prevent copying in the output of the tool, then there is no tort. If the models are creating copies inadvertently and separately from the efforts of the end users deliberate efforts then yes, the creators of the tool would likely be the responsible party for infringement. If I ask an LLM for a story about vampires and the model spits out The Twilight Saga, that would be problematic. Nor should the model reproduce the story word for word on demand by the end user. But it seems like neither of these examples are likely outcomes with current models. reply cmrdporcupine 17 hours agorootparentprevYou'll find people on this forum especially using the false analogy with a human. Like these things are like or analogous to human minds, and human minds have fair use access, so why shouldn't a these? Magical thinking that just so happens to make lots of $$. And after all why would you want to get in the way of profit^H^H^Hgress? reply marxisttemp 17 hours agorootparentprev“There must be in-groups whom the law protects but does not bind, alongside out-groups whom the law binds but does not protect.” reply scotty79 17 hours agorootparentprevIt's because the copyright is fake and the only thing supporting it were million dollar business. It naturally crumbles while facing billion dollar business. reply davidcbc 16 hours agorootparentprevThey're a rich company, they are immune from consequences reply Xcelerate 5 hours agorootparentprevWhy do HN commenters want OpenAI to be considered in violation of copyright here? Ok, so imagine you get your wish. Now all the big tech companies enter into billion dollar contracts with each other along with more traditional companies to get access to training data. So we close off the possibility of open development of AI even further. Every tech company with user-generated content over the last 20 years or so is sitting on a treasure trove now. I’d prefer we go the other direction where something like archive.org archives all publicly accessible content and the government manages this, keeps it up-to-date, and gives cheap access to all of the data to anyone on request. That’s much more “democratizing” than further locking down training data to big companies. reply cma 15 hours agoparentprevOpenAI's benchmark results looking like Musk's Path of Exile character.. reply charlieyu1 14 hours agoparentprevWhy would they use the materials in model training? It would defeat the purpose of having a benchmarking set reply Certhas 7 hours agorootparentCompare: \"O3 performs spectacularly on a very hard dataset that was independently developed and that OpenAI does not have access to.\" \"O3 performs spectacularly on a very hard dataset that was developed for OpenAI and that only OpenAI has access to.\" Or let's put it another way: If what they care about is benchmark integrity, what reason would they have for demanding access to the benchmark dataset and hiding the fact that they finance it? The obvious thing to do if integrity is your goal is to fund it, declare that you will not touch it, and be transparent about it. reply wokwokwok 11 hours agorootparentprevIf you’re a research lab then yes. If you’re a for profit company trying to raise funding and fend off skepticism that your models really aren’t that much better than any one else’s, then… It would be dishonest, but as long as no one found out until after you closed your funding round, there’s plenty of reason you might do this. It comes down to caring about benchmarks and integrity or caring about piles of money. Judge for yourself which one they chose. Perhaps they didn’t train on it. Who knows? It’s fair to be skeptical though, under the circumstances. reply charlieyu1 1 hour agorootparent6 months ago it would be unimaginable to do anything that may be harmful to the quality of the product, but I’m trusting OpenAI less and less reply chvid 9 hours agoparentprevNot used in model training probably means it was used in model validation. reply teleforce 12 hours agoparentprev>perhaps they were routing API calls to human workers Honest question, did they? reply echoangle 6 hours agorootparentHow would that even work? Aren’t the responses to the API equally fast as the Web interface? Can any human write a response with the speed of an LLM? reply YeGoblynQueenne 5 hours agorootparentNo but a human can solve a problem that an LLM can't solve and then an LLM can generate a response to the original prompt including the solution found by the human. reply 2-3-7-43-1807 7 hours agoparentprevverbal agreement ... that's just saying that you're a little dumb or you're playing dumb cause you're in on it. reply echelon 18 hours agoparentprevThis has me curious about ARC-AGI. Would it have been possible for OpenAI to have gamed ARC-AGI by seeing the first few examples and then quickly mechanical turking a training set, fine tuning their model, then proceeding with the rest of the evaluation? Are there other tricks they could have pulled? It feels like unless a model is being deployed to an impartial evaluator's completely air gapped machine, there's a ton of room for shenanigans, dishonesty, and outright cheating. reply trott 17 hours agorootparent> This has me curious about ARC-AGI In the o3 announcement video, the president of ARC Prize said they'd be partnering with OpenAI to develop the next benchmark. > mechanical turking a training set, fine tuning their model You don't need mechanical turking here. You can use an LLM to generate a lot more data that's similar to the official training data, and then you can train on that. It sounds like \"pulling yourself up by your bootstraps\", but isn't. An approach to do this has been published, and it seems to be scaling very well with the amount of such generated training data (They won the 1st paper award) reply pastage 7 hours agorootparentI know nothing about LLM training, but do you mean there is a solution to the issue of LLMs gaslighting each other? Sure this is a proven way of getting training data, but you can not get theorems and axioms right by generating different versions of them. reply trott 3 hours agorootparentThis is the paper: https://arxiv.org/abs/2411.02272 They won the 1st paper award: https://arcprize.org/2024-results In their approach, the LLM generates inputs (images to be transformed) and solutions (Python programs that do the image transformations). The output images are created by applying the programs to the inputs. So there's a constraint on the synthetic data here that keeps it honest the Python interpreter. reply abrichr 5 hours agorootparentprevI believe the paper being referenced is “Scaling Data-Constrained Language Models” (https://arxiv.org/abs/2305.16264). For correctness, you can use a solver to verify generated data. reply WiSaGaN 17 hours agorootparentprevIn their benchmark, they have a tag \"tuned\" attached to their o3 result. I guess we need they to inform us of the exact meaning of it to gauge. reply riku_iki 16 hours agorootparentprev> OpenAI to have gamed ARC-AGI by seeing the first few examples not just few examples. o3 was evaluated on \"semi-private\" test, which was previously already used for evaluating OAI models, so OAI had access to it already for a long time. reply lolinder 19 hours agoprevA co-founder of Epoch left a note in the comments: > We acknowledge that OpenAI does have access to a large fraction of FrontierMath problems and solutions, with the exception of a unseen-by-OpenAI hold-out set that enables us to independently verify model capabilities. However, we have a verbal agreement that these materials will not be used in model training. Ouch. A verbal agreement. As the saying goes, those aren't worth the paper they're written on, and that's doubly true when you're dealing with someone with a reputation like Altman's. And aside from the obvious flaw in it being a verbal agreement, there are many ways in which OpenAI could technically comply with this agreement while still gaining a massive unfair advantage on the benchmarks to the point of rendering them meaningless. For just one example, knowing the benchmark questions can help you select training data that is tailored to excelling at the benchmarks without technically including the actual question in the training data. reply aithrowawaycomm 18 hours agoparentWhat's even more suspicious is that these tweets from Elliot Glazer indicate that they are still \"developing\" the hold-out set, even though elsewhere Epoch AI strongly implied this already existed: https://xcancel.com/ElliotGlazer/status/1880809468616950187 It seems to me that o3's 25% benchmark score is 100% data contamination. reply cma 15 hours agorootparent> I just saw Sam Altman speak at YCNYC and I was impressed. I have never actually met him or heard him speak before Monday, but one of his stories really stuck out and went something like this: > \"We were trying to get a big client for weeks, and they said no and went with a competitor. The competitor already had a terms sheet from the company were we trying to sign up. It was real serious. > We were devastated, but we decided to fly down and sit in their lobby until they would meet with us. So they finally let us talk to them after most of the day. > We then had a few more meetings, and the company wanted to come visit our offices so they could make sure we were a 'real' company. At that time, we were only 5 guys. So we hired a bunch of our college friends to 'work' for us for the day so we could look larger than we actually were. It worked, and we got the contract.\" > I think the reason why PG respects Sam so much is he is charismatic, resourceful, and just overall seems like a genuine person. https://news.ycombinator.com/item?id=3048944 reply aithrowawaycomm 9 hours agorootparentMan, the real ugliness is the comments hooting and hollering for this amoral cynicism: Honesty is often overrated by geeks and it is very contextual He didn't misrepresent anything. They were actually working there, just only for one day. The effectiveness of deception is not mitigated by your opinions of its likability. Gross. reply AyyEye 12 hours agorootparentprevNothing says genuine like lying to get a contract. reply teaearlgraycold 18 hours agorootparentprevThis was my assumption all along. reply EagnaIonat 12 hours agorootparentprev> What's even more suspicious is that these tweets from Elliot Glazer indicate that they are still \"developing\" the hold-out set, There is nothing suspicious about this and the wording seems to be incorrect. A hold-out set is a percentage of the overall data that is used to test a model. It is just not trained on it. Model developers normally have full access to it. There is nothing inherently wrong with training on a full/partial hold out set. It just means you have done a different split to train again. The confusion I see here is that people are equating a hold out set to a blind set. That's a set of data to test against that the model developers (and model) cannot see. Even so blind sets can also go stale after a few runs and nothing is wrong with ingesting that blind set, as long as you have a new blind set to run against. Trying to game blind set tests is nothing new and it gets very quickly found out. What I took from the original article is that the blind set is likely unbalanced and it answered more easier questions than hard ones. reply aithrowawaycomm 9 hours agorootparent> The confusion I see here is that people are equating a hold out set to a blind set. That's a set of data to test against that the model developers (and model) cannot see. What on earth? This is from Tamay Besiroglu at Epoch: Regarding training usage: We acknowledge that OpenAI does have access to a large fraction of FrontierMath problems and solutions, with the exception of a unseen-by-OpenAI hold-out set that enables us to independently verify model capabilities. However, we have a verbal agreement that these materials will not be used in model training. So this \"confusion\" is because Epoch AI specifically told people it was a blind set! Despite the condescending tone, your comment is just plain wrong. reply sillysaurusx 17 hours agoparentprevThe questions are designed so that such training data is extremely limited. Tao said it was around half a dozen papers at most, sometimes. That’s not really enough to overfit on without causing other problems. reply lolinder 17 hours agorootparent> That’s not really enough to overfit on without causing other problems. \"Causing other problems\" is exactly what I'm worried about. I would not put it past OpenAI to deliberately overfit on a set of benchmarks in order to keep up the illusion that they're still progressing at the rate that the hype has come to expect, then keep the very-dangerous model under wraps for a while to avoid having to explain why it doesn't act as smart as they claimed. We still don't have access to this model (because, as with everything since GPT-2, it's \"too dangerous\"), so we have no way of independently verifying its utility, which means they have a window where they can claim anything they want. If they release a weaker model than claimed it can always be attributed to guardrails put in place after safety testing confirmed it was dangerous. We'll see when the model actually becomes available, but in the meantime it's reasonable to guess that it's overfitted. reply hyperpape 3 hours agorootparentprevYou're missing the part where 25% of the problems were representative of problems top tier undergrads would solve in competitions. Those problems are not based on material that only exists in half a dozen papers. Tao saw the hardest problems, but there's no concrete evidence that o3 solved any of the hardest problems. reply jsheard 19 hours agoprevWhy do people keep taking OpenAIs marketing spin at face value? This keeps happening, like when they neglected to mention that their most impressive Sora demo involved extensive manual editing/cleanup work because the studio couldn't get Sora to generate what they wanted. https://news.ycombinator.com/item?id=40359425 reply th1243127 19 hours agoparentIt might be because (very few!) mathematicians like Terence Tao make positive remarks. I think these mathematicians should be very careful to use reproducible and controlled setups that by their nature cannot take place on GPUs in the Azure cloud. I have nothing against scientists promoting the Coq Proof Assistant. But that's open source, can be run at home and is fully reproducible. reply aithrowawaycomm 18 hours agorootparentKeep in mind those mathematicians were kept in the dark about the funding: it is incredibly unethical to invite a coauthor to your paper and not tell where the money came from. It's just incredibly scummy behavior: I imagine some of those mathematicians would have declined the collaboration if the funding were transparent. More so than data contamination, this makes me deeply mistrustful of Epoch AI. reply Vecr 17 hours agorootparentWait, I think I somehow knew Epoch AI was getting money from OpenAI. I'm not sure how, and I didn't connect any of the facts together to think of this problem in advance. reply refulgentis 18 hours agorootparentprevI can't parse any of this, can you explain to a noob? I get lost immediately: funding, coauthor, etc. Only interpretation I've come to is I've missed a scandal involving payola, Terence Tao, and keeping coauthors off papers reply Vecr 18 hours agorootparentVery few people were told the nature of the funding. reply rvz 11 hours agoparentprevBecause they are completely gullible and believe almost everything that OpenAI does without questioning the results. On each product they release, their top researchers are gradually leaving. Everyone now knows what happens when you go against or question OpenAI after working for them, which is why you don't see any criticism and more of a cult-like worship. Once again, \"AGI\" is a complete scam. reply refulgentis 18 hours agoparentprevBecause the models have continually matched the quality they claim. Ex. look how much work \"very few\" has to do in the sibling comment. It's like saying \"very few physicists [Einstein/Feynman/Witten]\" Its conveniently impossible to falsify the implication that the inverse of \"very few\" say not positive things. i.e. that the vast majority say negative things You have to go through an incredible level of mental gymnastics, involving many months of gated decisions, where the route chosen involved \"gee, I know this is suspectable to confirmation bias, but...\", to end up wondering why people think the models are real if OpenAI has access to data that includes some set of questions. reply j_timberlake 7 minutes agoprevElon definitely still has a grudge against Altman and OpenAI, so when Elon uses his new political power to bludgeon OpenAI to bankruptcy with new regulations and lawsuits, it won't be for the right reasons, but I'll still think Altman and the remaining employees deserve it. reply diggan 19 hours agoprev> Tamay from Epoch AI here. We made a mistake in not being more transparent about OpenAI's involvement. We were restricted from disclosing the partnership until around the time o3 launched, and in hindsight we should have negotiated harder for the ability to be transparent to the benchmark contributors as soon as possible. Our contract specifically prevented us from disclosing information about the funding source and the fact that OpenAI has data access to much but not all of the dataset. Not sure if \"integrity of the benchmarks\" should even be something that you negotiate over, what's the value of the benchmark if the results cannot be trusted because of undisclosed relationships and sharing of data? Why would they be restricted from disclosing stuff you normally disclose, and how doesn't that raise all sorts of warning flags when proposed even? reply aunty_helen 17 hours agoparentThis feels like a done deal. This benchmark should be discarded. reply optimalsolver 18 hours agoparentprev>OpenAI has data access to much but not all of the dataset Their head mathematician says they have the full dataset, except a holdout set which they're currently developing (i.e. doesn't exist yet): https://www.reddit.com/r/singularity/comments/1i4n0r5/commen... reply menaerus 10 hours agorootparentThanks for the link. A holdout set which is yet to be used to verify the 25% claim. He also says that he doesn't believe that OpenAI would self-sabotage themselves by tricking the internal benchmarking performance since this will get easily exposed, either by the results from a holdout set or by the public repeating the benchmarks themselves. Seems reasonable to me. reply optimalsolver 8 hours agorootparent>the public repeating the benchmarks themselves The public has no access to this benchmark. In fact, everyone thought it was all locked up in a vault at Epoch AI HQ, but looks like Sam Altman has a copy on his bedside table. reply menaerus 8 hours agorootparentPerhaps what he meant is that the public will be able to benchmark the model themselves by throwing different difficulty math problems at it and not necessarily the FrontierMath benchmark. It should become pretty obvious if they were faking the results or not. reply optimalsolver 7 hours agorootparentIt's been found [0] that slightly varying Putnam problems causes a 30% drop in o1-Preview accuracy, but that hasn't put a dent in OAI's hype. There's absolutely no comeuppance for juicing benchmarks, especially ones no one has access to. If performance of o3 doesn't meet expectations, there'll be plenty of people making excuses for it (\"You're prompting it wrong!\", \"That's just not its domain!\"). [0] https://openreview.net/forum?id=YXnwlZe0yf&noteId=yrsGpHd0Sf reply menaerus 7 hours agorootparent> If performance of o3 doesn't meet expectations, there'll be plenty of people making excuses for it I agree and I can definitely see that happening but it is also not impossible, given the incentive and impact of this technology, for some other company/community to create yet another, perhaps, FrontierMath-like benchmark to cross-validate the results. I also don't disagree that it is not impossible for OpenAI to have faked these results. Time will tell. reply zarzavat 17 hours agoprevOpenAI played themselves here. Now nobody is going to take any of their results on this benchmark seriously, ever again. That o3 result has just disappeared in a poof of smoke. If they had blinded themselves properly then that wouldn't be the case. Whereas other AI companies now have the opportunity to be first to get a significant result on FrontierMath. reply colonial 14 hours agoparentI'd be surprised if any of their in-house benchmark results are taken seriously after this. As an extremely rough estimate, FrontierMath cost five to six figures to assemble [1] so from an outside view, they clearly have no qualms with turning cash into quasi-guaranteed benchmark results. [1]: https://epoch.ai/math-problems/submit-problem the benchmark is comprised of \"hundreds\" of questions, so at the absolute lowest it cost 300 * 200 = 60,000 dollars. reply red75prime 11 hours agoparentprevConversely, if they didn't cheat and they funded creation of the test suite to get \"clean\" problems (while hiding their participation to prevent getting problems that are somehow tailored to be hard for LLMs specifically), then they have no reasons to fear that all this looks fishy as the test results will soon be vindicated when they'll give wider access to the model. I refrain from forming a strong opinion in such situations. My intuition tells me that it's not cheating. But, well, it's intuition (probably based on my belief that the brain is nothing special physics-wise and it doesn't manage to realize unknown quantum algorithms in its warm and messy environment, so that classical computers can reproduce all of its feats when having appropriate algorithms and enough computing power. And math reasoning is just another step on a ladder of capabilities, not something that requires completely different approach). So, we'll see. reply klabb3 2 hours agorootparent> based on my belief that the brain is nothing special physics-wise and it doesn't manage to realize unknown quantum algorithms in its warm and messy environment Agreed (well as much as intuition goes), but current gen AI is not a brain, much less a human brain. It shows similarities, in particular emerging multi-modal pattern matching capabilities. There is nothing that says that’s all the neocortex does, in fact the opposite is a known truth in neuroscience. We just don’t know all functions yet we can’t just ignore the massive Chesterton’s fence we don’t understand. This isn’t even necessarily because the brain is more sophisticated than anything else, we don’t have models for the weather and immune system or anything chaotic really. Look, folding proteins is still a research problem and that’s at the level of known molecular structure. We greatly overestimate our abilities to model & simulate things. Todays AI is a prime example of our wishful thinking and glossing over ”details”. > so that classical computers can reproduce all of its feats when having appropriate algorithms and enough computing power. Sure. That’s a reasonable hypothesis. > And math reasoning is just another step on a ladder of capabilities, not something that requires completely different approach You seem to be assuming ”ability” is single axis. It’s like assuming if we get 256 bit registers computers will start making coffee, or that going to the gym will eventually give you wings. There is nothing that suggests this. In fact, if you look at emerging ability in pattern matching that improved enormously, while seeing reasoning on novel problems sitting basically still, that suggests strongly that we are looking at a multi-axis problem domain. reply eksu 14 hours agoparentprevThis risk could be mitigated by publishing the test. reply bogtog 17 hours agoprevA lot of the comments express some type of deliberate cheating the benchmark. However, even without intentionally trying to game it, if anybody can repeatedly take the same test, then they'll be nudged to overfit/p-hack. For instance, suppose they conduct an experiment and find that changing some hyper-parameter yields a 2% boost. That could just be noise, it could be a genuine small improvement, or it may be a mix of a genuine boost along with some fortunate noise. An effect may be small enough that researchers would need to rely on their gut to interpret it. Researchers may jump on noise while believing they have discovered true optimizations. Enough of these types of nudges, and some serious benchmark gains can materialize. (Hopefully my comment isn't entirely misguided, I don't know how they actually do testing or how often they probe their test set) reply madars 17 hours agoparentI cringe every time I see \"my IQ increased by X points after doing Y\" posts on Twitter yes, you had a practice run on Raven's progressive matrices a month ago, that helped, these have a limited question bank and the effect of Y is marginal. That said, obviously, test taking is a skill (separate from background knowledge and both general/domain-specific ability) and should be trained if you expect to have life-altering events based on tests (i.e., do an LSAT course if you want to go to law school). Conversely, shouldn't be done if you think it will limit you through superstition (\"I had a score of X, thus I can only perform around level of X+fudge factor\"). For an LLM company a good test score is a valuation-altering event! reply ripped_britches 14 hours agoprevDo people actually think OpenAI is gaming benchmarks? I know they have lost trust and credibility, especially on HN. But this is a company with a giant revenue opportunity to sell products that work. What works for enterprise is very different from “does it beat this benchmark”. No matter how nefarious you think sama is, everything points to “build intelligence as rapidly as possible” rather than “spin our wheels messing with benchmarks”. In fact, even if they did fully lie and game the benchmark do you even care? As an OpenAI customer, all I care about is that the product works. I code with o1 for hours every day, so I am very excited for o3 to be released via API. And if they trained on private datasets, I honestly don’t care. I just want to get a better coding partner until I’m irrelevant. Final thought why are these contractors owed a right to know where funding came from? I would definitely be proud to know I contributed to the advancement of the field of AI if I was included in this group. reply mlsu 12 hours agoparentGaming benchmarks has a lot of utility for openAI whether their product works or not. Many people compare models based on benchmarks. So if openAI can appear better to Anthropic, Google, or Meta, by gaming benchmarks, it's absolutely in their interest to do so, especially if their product is only slightly behind, because evaluating model quality is very very tricky business these days. In particular, if there is a new benchmark, it's doubly in their interest to game it, because they know that other providers will start using and optimizing performance towards that benchmark, in order to \"beat\" OpenAI and win market share. On a personal level, their model is getting beat handily by Claude Sonnet 3.5 right now. It doesn't seem to show in the benchmarks. I wonder why? This is a company which is shedding their coats of ethics and scientific rigor so as to be as unencumbered as possible in its footrace to the dollar. reply raincole 12 hours agorootparent> On a personal level, their model is getting beat handily by Claude Sonnet 3.5 right now. It doesn't seem to show in the benchmarks. I wonder why? I do use Sonnet 3.5 personally, but this \"beat handily\" doesn't show on LLM arena. Do OpenAI game that too? reply bugglebeetle 11 hours agorootparentprevI used to think this, but using o1 quite a bit lately has convinced me otherwise. It’s been 1-shotting the fairly non-trivial coding problems I throw at it and is good about outputting large, complete code blocks. By contrast, Claude immediately starts nagging you about hitting usage limits after a few back and forth and has some kind of hack in place to start abbreviating code when conversations get too long, even when explicitly instructed to do otherwise. I would imagine that Anthropic can produce a good test time compute model as well, but until they have something publicly available, OpenAI has stolen back the lead. reply maeil 9 hours agorootparent\"Their model\" here is referring to 4o as o1 is unviable for many production usecases due to latency. reply ripped_britches 12 hours agorootparentprevI think “getting beat handily” is a HN bubble concept. Depends on what you’re using it for, but I personally prefer 4o for coding. In enterprise usage, i think 4o is smoking 3.5 sonnet, but that’s just my perception from folks I talk to. reply hatefulmoron 11 hours agorootparentI don't think that's true, you'll get the same sentiment (\"Sonnet 3.5 is much better than GPT4/GPT4o [for coding]\") pretty uniformly across Reddit/HN/Lobsters. I would strongly agree with it in my own testing, although o1 might be much better (I'm too poor to give it a fair shake.) > In enterprise usage, i think 4o is smoking 3.5 sonnet True. I'm not sure how many enterprise solutions have given their users an opportunity to test Claude vs. GPT. Most people just use whatever LLM API their software integrates. reply maeil 9 hours agorootparentprevThis just isn't accurate, on the overwhelming majority of real-world tasks (>90%) 3.5 Sonnet beats 4o. FWIW I've spoken with a friend who's at OpenAI and they fully agree in private. reply saithound 9 hours agoparentprevYes, it looks all but certain that OpenAI gamed this particular benchmark. Otherwise, they would not have had a contract that prohibited revealing that OpenAI was involved with the project until after the o3 announcements were made and the market had time to react. There is no reason to have such a specific agreement unless you plan to use the backdoor access to beat the benchmark: otherwise, OpenAI would not have known in advance that o3 will perform well! In fact, if there was proper blinding in place (which Epoch heads confirmed was not the case), there would have been no reason for secrecy at all. Google, xAI and Anthropic's test-time compute experiments were really underwhelming: if OpenAI has secret access to benchmarks, that explains why their performance is so different. reply jatins 13 hours agoparentprev> Do people actually think OpenAI is gaming benchmarks? I was blown away by chatgpt release and generally have admired OpenAI however I wouldn't put it past them At this point their entire marketing strategy seems to be to do vague posting on X/Twitter and keep hyping the models so that investors always feel there is something around the corner And I don't think they need to do that. Most investors will be throwing money at them either way but maybe when you are looking to raise _billions_ that's not enough reply maeil 9 hours agoparentprev> Do people actually think OpenAI is gaming benchmarks? Yes, they 100% do. So do their main competitors. All of them do. reply cbg0 9 hours agoparentprev> Do people actually think OpenAI is gaming benchmarks? Yes, there's no reason not to do it, only upsides when you try to sell it to enterprises and governments. reply 331c8c71 11 hours agoparentprevWell I certainly won't object if oai marketing was based on testimonials from their fanboy customers instead of rigged benchmark scores %) Your fragrant disregard for ethics and focus on utilitarian aspects is certainly quite extreme to the extent that only a view people would agree with you in my view. reply lionkor 17 hours agoprevPeople on here were mocking me openly when I pointed out that you can't be sure LLMs (or any AIs) are actually smart unless you CAN PROVE that the question you're asking isn't in the training set (or adjacent like in this case). So with this in mind now, let me repeat: Unless you know that the question AND/OR answer are not in the training set or adjacent, do not claim that the AI or similar black box is smart. reply pcmoore 16 hours agoparentI ran a test yesterday on ChatGPT and co-pilot asking first if it knew of a specific paper which it confirmed and then to derive simple results from which it was completely incapable of. I know this paper is not widely referenced (ie few known results in the public domain) but has been available for over 15 years with publicly accessible code written by humans. The training set was so sparse it had no ability to \"understand\" or even regurgitate past the summary text which it listed almost verbatim. reply Vecr 16 hours agorootparentIt is known that current models have terrible sample efficiency. I've been told that it's better than I thought it was, but it still isn't good. reply KeplerBoy 4 hours agoparentprevIt doesn't need to be smart to be useful. A lot of the kind of work I do seems to be in the training set. reply shadowfox 4 hours agorootparentI don't think the OP is talking about usefulness at all, that is on a completely different dimension I would say. reply sitkack 16 hours agoparentprevThis all smells like the OpenAI CEO's MO. Stupid drama for stupid reasons. reply MattDaEskimo 17 hours agoprevThere's something gross about OpenAI constantly misleading the public. This maneuver by their CEO will destroy FrontierMath and Epoch AI's reputation reply cbracketdash 17 hours agoparentReminds me of the following proverb: \"The integrity of the upright guides them, but the unfaithful are destroyed by their duplicity.\" (Proverbs 11:3) reply gunalx 9 hours agoprevSo in conclusion, any evaluation of openai models on frontier math is increadibly invalidated. I would even go so far as to say this invalidates not only FrontierMath but also anything Epoch AI has and will touch. Any academic misjudgement like this massive conflict and cheating makes you unthrustworthy in a academic context. reply benterix 8 hours agoprev> Our contract specifically prevented us from disclosing information about the funding source and the fact that OpenAI has data access to much but not all of the dataset. Man, this is huge. reply wujerry2000 18 hours agoprevMy takeaways (1) Companies will probably increasingly invest in building their own evals for their use cases because its becoming clear public/allegedly private benchmarks have misaligned incentives with labs sponsoring/cheating (2) Those evals will prob be proprietary \"IP\" guarded as closely as the code or research itself (3) Conversely, public benchmarks are exhausted and SOMEONE has to invest in funding more frontier benchmarks. So this is prob going to continue. reply padolsey 15 hours agoprevMany of these evals are quite easy to game. Often the actual evaluation part of benchmarking is left up to a good-faith actor, which was usually reasonable in academic settings less polluted by capital. AI labs, however, have disincentives to do a thorough or impartial job, so IMO we should never take their word for it. To verify, we need to be able to run these evals ourselves – this is only sometimes possible, as even if the datasets are public, the exact mechanisms of evaluation are not. In the long run, to be completely resilient to gaming via training, we probably need to follow suit of other fields and have third-party non-profit accredited (!!) evaluators who's entire premise is to evaluate, red-team, and generally keep AI safe and competent. reply katamari-damacy 9 hours agoprev“we now know how to build AGI” Sam Altman. which should really be “we now know how to improve associative reasoning but we still need to cheat when it comes to math because the bottom line is that the models can only capture logic associatively, not synthesize deductively, which is what’s needed for math beyond recipe-based reasoning\" reply Imnimo 18 hours agoprevMy guess is that OpenAI didn't cheat as blatantly as just training on the test set. If they had, surely they could have gotten themselves an even higher mark than 25%. But I do buy the comment that they soft-cheated by using elements of the dataset for validation (which is absolutely still a form of data leakage). Even so, I suspect their reported number is roughly legit, because they report numbers on many benchmarks, and they have a good track record of those numbers holding up to private test sets. What's much more concerning to me than the integrity of the benchmark number is the general pattern of behavior here from OpenAI and Epoch. We shouldn't accept secretly (even secret to the people doing the creation!) funding the creation of a benchmark. I also don't see how we can trust in the integrity of EpochAI going forward. This is basically their only meaningful output, and this is how they handled it? reply riku_iki 15 hours agoparent> If they had, surely they could have gotten themselves an even higher mark than 25%. there is potentially some limitation of LLMs memorizing such complex proofs reply woopwoop 11 hours agorootparentThey aren't proofs, they're just numbers. All the questions have numerical answers. That's how they're evaluated. reply matt_daemon 18 hours agoprevAt this point eval results presented by AI companies are a joke and should not be trusted reply atleastoptimal 14 hours agoprevThe problem is, any benchmark on a closed model couldn’t be private even in theory, as the model has to be called to run the benchmark, exposing the contents to whoever owns the model thereafter. HN loves to speculate that OpenAI is some big scam whose seeming ascendance is based on deceptive marketing hype, but o1, to anyone who has tried it seriously is undoubtedly very much within the ballpark of what OpenAI claims it is able to do. If everything they are doing really is just overfitting and gaming the tests, that discrepancy will eventually catch up to them, and people will stop using the APIs and chatgpt reply mrg3_2013 12 hours agoprevOpenAI continues to muddy the benchmarks, while Claude continues to improve their intelligence. Claude will win long term. It'd be wise to not rely on OpenAI at all. They are the first comers who will just burn cash and crash out I suspect. reply WasimBhai 18 hours agoprevI have been taking a course in AI policy and the O1 and the FrontierMath dataset has been an important mark for me to emphasize the world we are moving toward. It is incredibly sad to know about the conflict of interest here. However, those more knowledgeable, can you explain in plain words, does this revelation compromise OAI's claims regarding o3's performance on FrontierMath problems? reply energy123 18 hours agoparentIt's worse than just an undeclared conflict of interest. They gave OpenAI all questions and solutions behind the scenes. It's hard to chalk this up to only naivete. This is a \"sorry you caught me\" moment. reply lolinder 18 hours agoparentprevThey have an oral agreement that OpenAI won't use the benchmark in training. Which means first and foremost you have to consider the possibility that they broke that oral agreement and actually included the problems in the training set. Even if they didn't, the fact that they had the problems means they could have selectively chosen the training set data to specialize in solving that class of problem, while still technically keeping the verbal agreement. So, yeah, the benchmark needs to be treated as essentially worthless at this point. reply energy123 18 hours agorootparentIf OpenAI wanted the questions/solutions, there is going to be a reason for that. This data is not sitting in an unopened folder on Sam's computer. There are a lot of ways you can use data to improve a model without directly training on it. A train/test validation loop, for example. Or as a wellspring for synthetic data generation. But all of these ways involve some level of data contamination, it's unavoidable. reply nioj 19 hours agoprevRelated https://news.ycombinator.com/item?id=42761648 reply floppiplopp 4 hours agoprevUnless you have been up to the shoulders in the hype-hole of Scam Altman's backside this should not come as the slightest surprise. reply maeil 9 hours agoprevThis isn't news, the other popular benchmarks are just as gamed and worthless, it would be shocking if this one wasn't. The other frontier model providers game them just as hard, it's not an OpenAI thing. Any benchmark that a provider themselves mentions is not worth the pixels its written on. reply karmasimida 14 hours agoprevThey should at least clarify it. The reason they don’t I feel is simply for the hype and mystique. There are ways that you could game the benchmark without adding it to the training set. By repetitively evaluating on the dataset itself it will regress into a validation set, not a test set, even in black box setting, as you can simply evaluating 100 checkpoints and pick the one that performs the best, rinse and repeat I still believe o3 is the real deal, BUT this gimmick kind sour my appetite a bit, for that those who run the company reply nottorp 8 hours agoprevSo basically when you need to look good in benchmarks you fund an organization that does benchmarks in which you look good. Just like toothpaste manufacturers fund dentist's associations etc. reply suchintan 16 hours agoprevI wonder if more companies should open source their eval model outputs alongside the eval results We tried doing that here at Skyvern (eval.skyvern.com) reply moi2388 11 hours agoprev“… we have a verbal agreement that these materials will not be used in model training” What about model testing before releasing it? reply ForHackernews 8 hours agoprevUnrelated to anything but what software is this blog running on? I love the sidenote feature. Why does it have a customer service popover chat assistant? reply Vecr 3 hours agoparentThe Lightcone Infrastructure forum stack. I don't know why it has an assistant. reply treksis 19 hours agoprevso it was overfit reply numba888 19 hours agoprevif they used it in training it should be 100% hit. most likely they used it to verify and tune parameters. reply rrr_oh_man 18 hours agoparent> if they used it in training it should be 100% hit. Not necessarily, no. A statistical model will attempt to minimise overall loss, generally speaking. If it gets 100% accuracy on the training data it's usually an overfit. (Hugging the data points too tightly, thereby failing to predict real life cases) reply numba888 9 hours agorootparentyou are mostly right. but seeing almost perfectly reconstructed images from training set it's obvious model can memorize samples. in this case it would reproduce the answers too close to the original to be just 'accidental'. should be easy to test. My guess samples could be used to find good enough stopping point for o1, o3 models. which is hardcoded. reply aithrowawaycomm 6 hours agorootparentThe subtlety here is that an almost-memorized picture of a lady is the same picture with a few artifacts, and an almost-memorized NYT article is the same article with a few words changed, but an almost-memorized computation or proof is likely to be plain wrong. So even if OpenAI's benchmark was data contamination (as I suspect) it still says something about o1's abilities to execute a given problem-solving strategy without confabulating. It's just not what OpenAI wants you to think: much closer to Mathematica than an actual mathematician. reply g-b-r 18 hours agoparentprevHad they let it hit 100% it would have been obvious they had the data. They've sure been careful to avoid that, by only using a portion of it or some other technique reply refulgentis 18 hours agoprevIts increasingly odd to see HN activity that assumes the premise: if the latest benchmark results involved a benchmark that can be shown to have any data that OpenAI could have accessed, then, the benchmark results were intentionally faked. Last time this confused a bunch of people who didn't understand what test vs. train data meant and it resulted in a particular luminary complaining on Twitter, to much guffaws, how troubling the situation was. Literally every comment currently, modulo [1] assumes this and then goes several steps more, and a majority are wildly misusing terms with precise meanings, explaining at least part of their confusion. [1] modulo the one saying this is irrelevant because we'll know if it's bad when it comes out, which to be fair, if evaluated rationally, we know that doesn't help us narrowly with our suspicion FrontierMath benchmarks are all invalid because it trained on (most of) the solutions reply EvgeniyZh 12 hours agoparentWhy wouldn't OpenAI cheat? It's an open secret in industry that benchmarks are trained on. Everybody does it, so you need to do that or else your similarly performing model will look worse on paper. And even they respect the agreement, even using test set as a validation set can be a huge advantage. That's why validation set and test set are two different terms with precise meaning. As for \"knowing it's bad\", most people won't be able to tell a model scoring 25% and 10% apart. People who are using these models to solve math problems are tiny share of users and even tinier share of revenues. What OpenAI needs is to convince investors that there is still progress in capabilities going at high pace, and gaming the benchmarks makes perfect sense in this context. 25% was surprising and appeared to surpass expectations, which is exactly what OpenAI needs. reply refulgentis 12 hours agorootparent> Why wouldn't OpenAI cheat? It's an open secret in industry that benchmarks are trained on. Everybody does it, so you need to do that or else your similarly performing model will look worse on paper. This starts with a fallacious appeal to cynicism combined with an unsubstantiated claim about widespread misconduct. The \"everybody does it\" argument is a classic rationalization that doesn't actually justify anything. It also misunderstands the reputational and technical stakes major labs face intense scrutiny of their methods and results, and there's plenty of incestuous movement between labs and plenty of leaks. > And even they respect the agreement, even using test set as a validation set can be a huge advantage. That's why validation set and test set are two different terms with precise meaning. This part accidentally stumbles into a valid point about ML methodology while completely missing why it matters. Yes, validation and test sets serve different purposes that's precisely why reputable labs maintain strict separations between them. The implication that this basic principle somehow proves misconduct is backwards logic. > People who are using these models to solve math problems are tiny share of users and even tinier share of revenues. This reveals a fundamental misunderstanding of why math capabilities matter. They're not primarily about serving math users they're a key metric for abstract reasoning and systematic problem-solving abilities. This is basic ML evaluation theory. > What OpenAI needs is to convince investors that there is still progress in capabilities going at high pace, and gaming the benchmarks makes perfect sense in this context. 25% was surprising and appeared to surpass expectations, which is exactly what OpenAI needs. This concludes with pure speculation presented as fact, combined with a conspiracy theory that lacks any actual evidence. It also displays a shallow understanding of how technical due diligence works in major AI investments investors at this level typically have deep technical expertise, access to extensive testing and validation, and most damningly, given the reductive appeal to incentive structure: They closed the big round weeks before. The whole comment reads like someone who has picked up some ML terminology but lacks fundamental understanding of how research evaluation, technical accountability, and institutional incentives actually work in the field. The dismissive tone and casual accusations of misconduct don't help their credibility either. reply BeefWellington 10 hours agorootparent> The \"everybody does it\" argument is a classic rationalization that doesn't actually justify anything. I'd argue here the more relevant point is \"these specific people have been shown to have done it before.\" > The whole comment reads like someone who has picked up some ML terminology but lacks fundamental understanding of how research evaluation, technical accountability, and institutional incentives actually work in the field. The dismissive tone and casual accusations of misconduct don't help their credibility either. I think what you're missing is the observation that so very little of that is actually applied in this case. \"AI\" here is not being treated as an actual science would be. The majority of the papers pumped out of these places are not real concrete research, not submitted to journals, and not peer reviewed works. reply refulgentis 10 hours agorootparent> I'd argue here the more relevant point is \"these specific people have been shown to have done it before.\" This is itself a slippery move. A vague gesture at past misconduct without actually specifying any incidents. If there's a clear pattern of documented benchmark manipulation, name it. Which benchmarks? When? What was the evidence? Without specifics, this is just trading one form of handwaving (\"everyone does it\") for another (\"they did it before\"). > \"AI\" here is not being treated as an actual science would be. There's some truth here but also some sleight of hand. Yes, AI development often moves outside traditional academic channels. But, you imply this automatically means less rigor, which doesn't follow. Many industry labs have internal review processes, replication requirements, and validation procedures that can be as or more stringent than academic peer review. The fact that something isn't in Nature doesn't automatically make it less rigorous. > The majority of the papers pumped out of these places are not real concrete research, not submitted to journals, and not peer reviewed works. This combines three questionable implications: That non-journal publications are automatically \"not real concrete research\" (tell that to physics/math arXiv) That peer review is binary either traditional journal review or nothing (ignoring internal review processes, community peer review, public replications) That volume (\"pumped out\") correlates with quality You're making a valid critique of AI's departure from traditional academic structures, but then making an unjustified leap to assuming this means no rigor at all. It's like saying because a restaurant isn't Michelin-starred, it must have no food safety standards. This also ignores the massive reputational and financial stakes that create strong incentives for internal rigor. Major labs have to maintain credibility with: Their own employees. Other researchers who will try to replicate results. Partners integrating their technology. Investors doing technical due diligence. Regulators scrutinizing their claims. The idea that they would casually risk all that just to bump up one benchmark number (but not too much! just from 10% to 35%) doesn't align with the actual incentive structure these organizations face. Both the original comment and this fall into the same trap mistaking cynicism for sophistication while actually displaying a somewhat superficial understanding of how modern AI research and development actually operates. reply BeefWellington 8 hours agorootparentThis reply reads as though it were AI generated. Let's bite though, and hope that unhelpful excessively long-winded replies are just your quirk. > This is itself a slippery move. A vague gesture at past misconduct without actually specifying any incidents. If there's a clear pattern of documented benchmark manipulation, name it. Which benchmarks? When? What was the evidence? Without specifics, this is just trading one form of handwaving (\"everyone does it\") for another (\"they did it before\"). Ok, provide specifics yourself then. Someone replied and pointed out that they have every incentive to cheat, and your response was: > This starts with a fallacious appeal to cynicism combined with an unsubstantiated claim about widespread misconduct. The \"everybody does it\" argument is a classic rationalization that doesn't actually justify anything. It also misunderstands the reputational and technical stakes major labs face intense scrutiny of their methods and results, and there's plenty of incestuous movement between labs and plenty of leaks. Respond to the content of the argument be specific. WHY is OpenAI not incentivized to cheat on this benchmark? Why is a once-nonprofit which turned from releasing open and transparent models to a closed model and begun raking in tens of billions of investor cash not incentivized to continue to make those investors happy? Be specific. Because there's a clear pattern of corporate behaviour at OpenAI and associated entities which suggests your take is not, in fact, the simpler viewpoint. > This combines three questionable implications: > That non-journal publications are automatically \"not real concrete research\" (tell that to physics/math arXiv) Yes, arXiv will host lots of stuff that isn't real concrete research. They've hosted April Fool's jokes, for example.[1] > That peer review is binary either traditional journal review or nothing (ignoring internal review processes, community peer review, public replications) This is a poor/incorrect reading of the language. You have inferred meaning that does not exist. If citations are so important here, cite a few dozen that are peer reviewed out of the hundreds. > That volume (\"pumped out\") correlates with quality Incorrect reading again. Volume here correlates with marketing and hype. It could have an effect on quality but that wasn't the purpose behind the language. > You're making a valid critique of AI's departure from traditional academic structures, but then making an unjustified leap to assuming this means no rigor at all. It's like saying because a restaurant isn't Michelin-starred, it must have no food safety standards. Why is that unjustified? It's no different than any of the science background people who have fallen into flat earther beliefs. They may understand the methods but if they are not tested with rigor and have abandoned scientific principles they do not get to keep pretending it's as valid as actual science. > This also ignores the massive reputational and financial stakes that create strong incentives for internal rigor. Major labs have to maintain credibility with: FWIW, this regurgitated talking point is what makes me believe this is an LLM-generated reply. OpenAI is not a major research lab. They appear to essentially to be trading off the names of more respected institutions and mathematicians who came up with FrontierMath. The credibility damage here can be done by a single person sharing data with OpenAI, unbeknownst to individual participants. Separately, even under correct conditions it's not as if there are not all manner of problems in science in terms of ethical review. See for example, [2]. [1] https://arxiv.org/abs/2003.13879 FWIW, I'm not against scientists having fun, but it should be understood that arXiv is basically three steps above HN or reddit. [2] https://lore.kernel.org/linux-nfs/YH+zwQgBBGUJdiVK@unreal/ + related HN discussion: https://news.ycombinator.com/item?id=26887670 reply refulgentis 6 minutes agorootparentFirst paragraph is unnecessarily personal. It's also confusing: Did you think it was AI because of the \"regurgitated talking point\", as you say later, or because it was a \"unhelpful excessively long-winded repl[y]\"? I'll take the whole thing as an intemperate moment, and what was intended to be communicated was \"I'd love to argue about this more, but can you cut down reply length?\" > Ok, provide specifics yourself then. Pointing out \"Everyone does $X\" is fallacious does not imply you have to prove no one has any incentive to do $X. There's plenty of things you have an incentive to do that I trust you won't do. :) > If citations are so important here, cite a few dozen that are peer reviewed out of the hundreds. Sure. I got lost a bit, though, of what? Are you asking for a set of journal articles, that are peer-reviewed, about AI, that aren't on arxiv? > Why is that unjustified? \"$X doesn't follow traditional academic structures\" does not imply \"$X has no rigor at all\" > OpenAI is not a major research lab. Eep. > \"all manner of problems in science in terms of ethical review. \" Yup! The last 2 on my part are short because I'm not sure how to reply to \"entity $A has short-term incentive to do thing $X, and entity $A is part of large group $B that sometimes does thing $X\". We don't disagree there! I'm just applying symbolic logic to the rest. Ex. when I say \"$X does not imply $Y\" has a very definite field-specific meaning. It's fine to feel the way you do. It takes a rigorously rational process to end up making my argument, but rigorously is too kind: it would be crippling in daily life. A clear warning sign, for me, setting aside the personal attack opening, would have been when I was doing things like \"arXiv has April Fool's Jokes!\" I like to think I would have taken a step back after noticing it was \"OpenAI is distantly to group $X, a member of group $X did $Y, therefore OpenAI did $Y\" EvgeniyZh 9 hours agorootparentprev> an unsubstantiated claim about widespread misconduct. I can't prove it, but I heard it from multiple people in the industry. High contamination levels for existing benchmarks, though [1,2]. Whether to believe that it is just as good as we can do, not doing the best possible decontamination, or done on purpose is up to you. > Yes, validation and test sets serve different purposes that's precisely why reputable labs maintain strict separations between them. The verbal agreement promised not to train on the evaluation set. Using it as a validation set would not violate this agreement. Clearly, OpenAI did not plan to use the provided evaluation as a testset, because then they wouldn't need access to it. Also, reporting validation numbers as performance metric is not unheard of. > This reveals a fundamental misunderstanding of why math capabilities matter. They're not primarily about serving math users they're a key metric for abstract reasoning and systematic problem-solving abilities. How good of a proxy is it? There is some correlation, but can you say something quantitative? Do you think you can predict which models perform better on math benchmarks based on interaction with them? Especially for a benchmark you have no access to and can't solve by yourself? If the answer is no, the number is more or less meaningless by itself, which means it would be very hard to catch somebody giving you incorrect numbers. > someone who has picked up some ML terminology but lacks fundamental understanding of how research evaluation, technical accountability, and institutional incentives actually work in the field My credentials are in my profile, not that I think they should matter. However, I do have experience specifically in deep learning research and evaluation of LLMs. [1] https://aclanthology.org/2024.naacl-long.482/ [2] https://arxiv.org/abs/2412.15194 reply refulgentis 9 hours agorootparent> \"I can't prove it, but I heard it from multiple people in the industry\" The cited papers demonstrate that benchmark contamination exists as a general technical challenge, but are being misappropriated to support a much stronger claim about intentional misconduct by a specific actor. This is a textbook example of expanding evidence far, far, beyond its scope. > \"The verbal agreement promised not to train on the evaluation set. Using it as a validation set would not violate this agreement.\" This argument reveals a concerning misunderstanding of research ethics. Attempting to justify potential misconduct through semantic technicalities (\"well, validation isn't technically training\") suggests a framework where anything not explicitly forbidden is acceptable. This directly contradicts established principles of scientific integrity where the spirit of agreements matters as much as their letter. > \"How good of a proxy is it? [...] If the answer is no, the number is more or less meaningless by itself\" This represents a stark logical reversal. The initial argument assumed benchmark manipulation would be meaningful enough to influence investors and industry perception. Now, when challenged, the same metrics are suddenly \"meaningless.\" This is fundamentally inconsistent either the metrics matter (in which case manipulation would be serious misconduct) or they don't (in which case there's no incentive to manipulate them). > \"My credentials are in my profile, not that I think they should matter.\" The attempted simultaneous appeal to and dismissal of credentials is an interesting mirror of the claims as a whole: at this point, the argument OpenAI did something rests on unfalsifiable claims about the industry as a whole, claiming insider knowledge, while avoiding any verifiable evidence. When challenged, it retreats to increasingly abstract hypotheticals about what \"could\" happen rather than what evidence shows did happen. This demonstrates how seemingly technical arguments can fail basic principles of evidence and logic, while maintaining surface-level plausibility through domain-specific terminology. This kind of reasoning would not pass basic scrutiny in any rigorous research context. reply EvgeniyZh 8 hours agorootparent> Attempting to justify potential misconduct through semantic technicalities (\"well, validation isn't technically training\") Validation is not training, period. I'll ask again: what is the possible goal of accessing the evaluation set if you don't plan to use it for anything except the final evaluation, which is what the test set is used for? Either they just asked for access without any intent to use the provided data in any way except for final evaluation, which can be done without access, or they did somehow utilize the provided data, whether by training on it (which they verbally promised not to), using it as a validation set, using it to create a similar training set, or something else. > This directly contradicts established principles of scientific integrity where the spirit of agreements matters as much as their letter. OpenAI is not doing science; they are doing business. > This represents a stark logical reversal. The initial argument assumed benchmark manipulation would be meaningful enough to influence investors and industry perception. Now, when challenged, the same metrics are suddenly \"meaningless.\" This is fundamentally inconsistent either the metrics matter (in which case manipulation would be serious misconduct) or they don't (in which case there's no incentive to manipulate them). The metrics matter to people, but this doesn't mean people can meaningfully predict the model's performance using them. If I were trying to describe each of your arguments as some demagogue technique (you're going to call it ad hominem or something, probably), then I'd say it's a false dichotomy: it can, in fact, be impossible to use metrics to predict performance precisely enough and for people to care about metrics simultaneously. > The attempted simultaneous appeal to and dismissal of credentials I'm not appealing to credentials. Based on what I wrote, you made a wrong guess about my credentials, and I pointed out your mistake. > at this point, the argument OpenAI did something rests on unfalsifiable claims about the industry as a whole, claiming insider knowledge, while avoiding any verifiable evidence. Your position, on the other hand, rests on the assumption that corporations behave ethically and with integrity beyond what is required by the law (and, specifically, their contracts with other entities). reply m3kw9 18 hours agoprev [–] This don’t really matter much because if the models suck when it comes out evals mean nothing next time reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post highlights a lack of transparency in the collaboration between OpenAI and FrontierMath, with funding details only disclosed after a delay, causing confusion among contributors.",
      "Concerns are raised about OpenAI's potential access to and use of the dataset for training, despite verbal agreements suggesting otherwise, emphasizing the need for written agreements.",
      "The discussion underscores the importance of transparency and trust in collaborations, especially those involving AI capabilities, with commitments to improve transparency in future projects."
    ],
    "commentSummary": [
      "FrontierMath, funded by OpenAI, faces scrutiny over potential data contamination in its benchmarks, raising concerns about the integrity of their results. Critics emphasize the importance of transparency and proper separation of training and test data to prevent benchmarks from being manipulated. This situation underscores the necessity for independent and transparent evaluations in AI to maintain credibility."
    ],
    "points": 444,
    "commentCount": 173,
    "retryCount": 0,
    "time": 1737329279
  },
  {
    "id": 42760620,
    "title": "Why is Git Autocorrect too fast for Formula One drivers?",
    "originLink": "https://blog.gitbutler.com/why-is-git-autocorrect-too-fast-for-formula-one-drivers/",
    "originBody": "7 days ago by Scott Chacon — 5 min read Why is Git Autocorrect too fast for Formula One drivers? Why does Git's autocorrect wait 0.1s before executing a mistyped command? Let's dig in. git A while ago, I happened to see a tweet from @dhh where he mistyped a Git command as git pushy and was surprised to notice that Git figured out that he probably meant git push and then gave him 0.1 seconds to verify if that's what he wanted to run before it ran it anyways. 100 milliseconds? As David is a semi-professional race car driver in addition to being a fellow Ruby programming nerd, he naturally noticed that the amount of time that Git afforded him to react was impossible for even Formula One drivers. Of course this seems like a ludicrous bit of Git functionality, but I figured if this was surprising to David, you too might wonder why Git gave him (and possibly gives you) about the length of time that it takes a human eye to blink in order to: read a sentence determine if it's correct attempt to cancel the command What could possibly be the reason to wait 100ms? So little time is essentially equivalent to simply running the command. Well, it's a combination of a misunderstanding, a misconfiguration, and the suggestion, 17 years ago, of a somewhat questionable unit of time by the Git maintainer himself. How was this designed to work? It's important to note that this is not the default functionality of Git. The default response to typing a command that doesn't exist is to simply not run anything, figure out which commands you might have meant by string similarity and then just exit. If most of you type git pushy, you'll probably get this instead: ❯ git pushy git: 'pushy' is not a git command. See 'git help'. The most similar command is push Originally, if you typed an unknown command, it would just say \"this is not a git command\". Then in 2008, Johannes Schindelin (somewhat jokingly) introduced a small patch to go through all the known commands, show you what is most similar to what you typed and if there is only one closely matching, simply run it. Then Alex Riesen introduced a patch to make it configurable via the help.autocorrect setting. In this initial patch, this setting was simply a boolean. Since Git config settings that expect a boolean will interpret a 1 value as true, you could originally set help.autocorrect to 1 to have it automatically run the corrected command rather than just tell you what is similar. As part of the conversation around this patch, Junio Hamano, to this day the Git maintainer, suggested: Please make autocorrect not a binary but optionally the number of deciseconds before it continues, so that I have a chance to hit ^C ;-) Which was what the setting value was changed to in the patch that was eventually accepted. This means that setting help.autocorrect to 1 logically means \"wait 100ms (1 decisecond) before continuing\". Now, why Junio thought deciseconds was a reasonable unit of time measurement for this is never discussed, so I don't really know why that is. Perhaps 1 full second felt too long so he wanted to be able to set it to half a second? We may never know. All we truly know is that this has never made sense to anyone ever since. So, the reason why it waits 100ms for David is that at some point he presumably learned about this setting, quite reasonably assumed that it was a boolean and set it to what Git config also generally considers to be a 'true' value in order to enable it: ❯ git config global help.autocorrect 1 Not understanding that in this context, this means \"wait 1 decisecond, then do whatever you think is best\" rather than \"please turn this feature on\". What should it be set to? So, clearly you can set it to 10 for a full second or whatever. However, over the years, this setting has gathered a few other options that it will recognize. According to the documentation, here are the values it can be set to: 0 (default): show the suggested command. positive number: run the suggested command after specified deciseconds (0.1 sec). \"immediate\": run the suggested command immediately. \"prompt\": show the suggestion and prompt for confirmation to run the command. \"never\": don’t run or show any suggested command. Honestly, \"prompt\" is probably what most people would find the most reasonable, rather than a specific amount of time to wait for you to cancel the command. If you do want to have it prompt you, you can run this: ❯ git config global help.autocorrect prompt ❯ git pushy WARNING: You called a Git command named 'pushy', which does not exist. Run 'push' instead [y/N]? How does it guess? To keep picking on David, he followed up after doing some quick testing to see what the logic could be and it turns out that Git won't just take wild guesses. There is a point where it will simply assume you're way off and not guess anything: However, it's interesting to play around with this a bit: ❯ git bass WARNING: You called a Git command named 'bass', which does not exist. Run 'rebase' instead [y/N]? n ❯ git bassa git: 'bassa' is not a git command. See 'git help'. ❯ git dm git: 'dm' is not a git command. See 'git help'. The most similar commands are am rm ❯ git dma WARNING: You called a Git command named 'dma', which does not exist. Run 'am' instead [y/N]? So, git bass is close enough to rebase for it to guess that this could be what you mean. But bassa is not close enough for it to still think you maybe meant rebase. Also, git dm could mean am or rm, but interestingly it matches on the end of the string and not necessarily from the beginning. Also, dma confidently matches am only. So how is this working? As some of you may have guessed, it's based on a fairly simple, modified Levenshtein distance algorithm which is basically a way to figure out how expensive it is to change one string into a second string given single character edits, with some operations being more expensive than others. It has a hard coded cutoff, so once it's too expensive for any of the known commands, it just assumes you really messed up, which is why some of these don't match anything and others, even though quite different, match several options. My little fix In going through a bunch of the related autocorrect Git code in order to research this little blog post, I realized that there could be a relatively simple and largely backwards compatible fix. Since a 1 value is so fast, it's in all human terms functionally equivalent to \"immediately\", I wrote up a small patch to interpret a 1 as \"immediately\" rather than \"wait 100ms\". Junio came back to request that instead of special casing the \"1\" string, we should properly interpret any boolean string value (so \"yes\", \"no\", \"true\", \"off\", etc), so version two of my patch is currently in flight to additionally do that. If I can get this landed, maybe future versions of Git will no longer test the mettle of Formula One drivers. Anyhow, hope you enjoyed that little trip down this old alley of seemingly strange Git functionality. As is often the case with Git, there is some hidden method to the apparent madness, and like any open source project, there is a path to make it slightly better! The link has been copied!",
    "commentLink": "https://news.ycombinator.com/item?id=42760620",
    "commentBody": "Why is Git Autocorrect too fast for Formula One drivers? (gitbutler.com)391 points by birdculture 23 hours agohidepastfavorite219 comments WalterBright 20 hours ago> Originally, if you typed an unknown command, it would just say \"this is not a git command\". Back in the 70s, Hal Finney was writing a BASIC interpreter to fit in 2K of ROM on the Mattel Intellivision system. This meant every byte was precious. To report a syntax error, he shortened the message for all errors to: EH? I still laugh about that. He was quite proud of it. reply dredmorbius 15 minutes agoparented (the standard editor) optimises that by a further 66.7%.reply vunderba 18 hours agoparentprev> EH? I feel like that would also make a good response from the text parser in an old-school interactive fiction game. Slightly related, but I remember some older variants of BASIC using \"?\" to represent the PRINT statement though I think it was less about memory and more just to save time for the programmer typing in the REPL. reply chuckadams 16 hours agorootparentIt was about saving memory by tokenizing keywords: '?' is how PRINT actually was stored in program memory, it just rendered as 'PRINT'. Most other tokens were typically the first two characters, the first lowercase, the second uppercase: I remember LOAD was 'lO' and DATA was 'dA', though on the C64's default character glyphs they usually looked like L and D. All this being on a C64 of course, but I suspect most versions of Bill Gates's BASIC did something similar. reply egypturnash 15 hours agorootparentC64 basic was tokenized into one byte, with the most significant bit set: https://www.c64-wiki.com/wiki/BASIC_token Each command could be typed in two ways: the full name, or the first two letters, with the second capitalized. Plus a few exceptions like \"?\" turning into the PRINT token ($99, nowhere near the PETSCII value for ?) and π becoming $FF. The tokens were expanded into full text strings when you would LIST the program. Which was always amusing if you had a very dense multi-statement line that expanded as longer than the 80 characters the c64's tokenizer routine could handle, you'd have to go back and replace some or all commands with the short form before you could edit it. reply vrighter 5 hours agorootparentthe zx spectrum did this too, except you could only type the \"short forms\" (which were always rendered in full). It had keywords on its keys. I.e. to type print, you had to press the \"print\" key. reply mkesper 11 hours agorootparentprevAs far as I remember you couldn't even run these programs after listing anymore. reply LocalH 5 hours agorootparentYou could run them just fine as long as you didn't try to edit the listed lines if they were longer than two screen lines. The same is true for a C128 in C128 mode, except the limit is extended to 160 characters (four 40-column lines). reply fragmede 15 hours agorootparentprevD♠ reply nikau 20 hours agoparentprevHow wasteful, ed uses just ? for all errors, a 3x saving reply ekidd 19 hours agorootparentEd also uses \"?\" for \"Are you sure?\" If you're sure, you can type the last command a second time to confirm. The story goes that ed was designed for running over a slow remote connection where output was printed on paper, and the keyboard required very firm presses to generate a signal. Whether this is true or folklore, it would explain a lot. GNU Ed actually has optional error messages for humans, because why not. reply teraflop 15 hours agorootparenthttps://www.gnu.org/fun/jokes/ed-msg.en.html \"Note the consistent user interface and error reportage. Ed is generous enough to flag errors, yet prudent enough not to overwhelm the novice with verbosity.\" reply fsckboy 6 hours agorootparent>not to overwhelm the novice with verbosity that doesn't make complete sense, in unixland it's old-timers who understand the beauty of silence and brevity, while novices scan the screen/page around the new prompt for evidence that something happened reply Vinnl 5 hours agorootparentIf I didn't know any better, I'd have thought they weren't entirely serious. reply kstrauser 2 hours agorootparentprevEd helps induce novices into the way of the old-timers because it loves them and wants them to be happy. reply llm_trw 15 hours agorootparentprevSo much of computer conventions evolved for very good reasons because of physical limitations. When each line of code was it's own punch card having a { stand alone on a line was somewhere between stupid and pointless. Also explains the reason why lisps were so hated for so long. By the same token today you can tell which projects use an IDE as the only way to code them because of the terrible documentation. It is after all not the end of the world to have to read a small function when you can just tab to see it. Which is true enough until you end up having those small functions calling other small functions and you're in a stack 30 deep trying to figure out where the option you passed at the top went. reply p_l 17 hours agorootparentprev/bin/ed did in fact evolve on very slow teletypes that used roll paper. It made the option to print file content with line numbers very useful (personally only used very dumb terminals instead of physical teletype, but experience is a bit similar just with shorter scrollback :D) reply euroderf 9 hours agorootparentCan confirm. Using ed on a Texas Instruments dial-up terminal (modem for phone handset) with a thermal printer. And taking a printed listing before heading home with the terminal. reply miohtama 4 hours agorootparentprevHere is a good YT channel on such computers and terminals. Not only story, some of these running resurrected today. https://youtu.be/zeL3mbq1mEg?si=gUUO_nEsMtcZ5Z_A reply nine_k 12 hours agorootparentprevThere are really few systems where you can save a part of a byte! And if you need to output a byte anyway, it doesn't matter which byte it is. So you can indulge and use \"?\", \"!\", \"*\", or even \"&\" to signify various types of error conditions. (On certain architectures, you could use 1-byte soft-interrupt opcodes to call the most used subroutine, but 8080 lacked it IIRC; on 6502 you could theoretically use BRK for that. But likely you had other uses for it than printing error diagnostics.) reply zubairq 10 hours agoparentprevPretty cool.. I had no idea Hal was such a hacker on the personal computers in those days... makes me think of Bitcoin whenever I hear Hal mentioned reply furyofantares 18 hours agoparentprevI run a wordle spinoff, xordle, which involves two wordle puzzles on one board. This means you can guess a word and get all 5 letters green, but it isn't either of the target words. When you do this it just says \"Huh?\" on the right. People love that bit. reply speerer 10 hours agorootparentCan confirm. I loved that bit. reply dotancohen 6 hours agorootparentprev> People love that bit. Add another seven Easter eggs, and people could love that byte. reply cma 6 hours agoparentprevEarliest I've seen with 'Eh?' as an interpreter response is RAND's JOSS: https://en.wikipedia.org/wiki/JOSS#/media/File:JOSS_Session.... https://en.wikipedia.org/wiki/JOSS They had about 5KB of memory but comparing to the Intellivision the machine weighed about 5,000lbs. reply WalterBright 20 hours agoparentprevI've been sorely tempted to do that with my compiler many times. reply euroderf 9 hours agoparentprevCanadians everywhere. reply nl 20 hours agoparentprevIt'd be interesting and amusing if he'd made the private key to his part of Bitcoin a variation on that. RIP. reply physicles 19 hours agoprevThe root cause here is poorly named settings. If the original setting had been named something bool-y like `help.autocorrect_enabled`, then the request to accept an int (deciseconds) would've made no sense. Another setting `help.autocorrect_accept_after_dsec` would've been required. And `dsec` is so oddball that anyone who uses it would've had to look up. I insist on this all the time in code reviews. Variables must have units in their names if there's any ambiguity. For example, `int timeout` becomes `int timeout_msec`. This is 100x more important when naming settings, because they're part of your public interface and you can't ever change them. reply TeMPOraL 19 hours agoparent> I insist on this all the time in code reviews. Variables must have units in their names if there's any ambiguity. For example, `int timeout` becomes `int timeout_msec`. Same here. I'm still torn when this gets pushed into the type system, but my general rule of thumb in C++ context is: void FooBar(std::chrono::milliseconds timeout); is OK, because that's a function signature and you'll see the type when you're looking at it, but with variables, `timeout` is not OK, as 99% of the time you'll see it used like: auto timeout = gl_timeout; // or GetTimeoutFromSomewhere(). FooBar(timeout); Common use of `auto` in C++ makes it a PITA to trace down exact type when it matters. (Yes, I use IDE or a language-server-enabled editor when working with C++, and no, I don't have time to stop every 5 seconds to hover my mouse over random symbols to reveal their types.) reply OskarS 10 hours agorootparentOne of my favorite features of std::chrono (which can be a pain to use, but this part is pretty sweet) is that you don't have to specify the exact time unit, just a generic duration. So, combined with chrono literals, both of these work just like expected: std::this_thread::sleep_for(10ms); // sleep for 10 milliseconds std::this_thread::sleep_for(1s); // sleep for one second std::this_thread::sleep_for(50); // does not work, unit is required by type system That's such a cool way to do it: instead of forcing you to specify the exact unit in the signature (milliseconds or seconds), you just say that it's a time duration of some kind, and let the user of the API pick the unit. Very neat! reply twic 3 hours agorootparentI do something similar in Java by taking a java.time.Duration in any method dealing with time. We don't have the snazzy literal syntax, but that means users have to write: someMethodDealingWithTime(Duration.ofMillis(10)); someMethodDealingWithTime(Duration.ofSeconds(1)); someMethodDealingWithTime(50); // does not compile Since these often come from config, i also have a method parseDuration which accepts a variety of simple but unambiguous string formats for these, like \"10ms\", \"1s\", \"2h30m\", \"1m100us\", \"0\", \"inf\", etc. So in config we can write: galactus.requestTimeout=30s No need to bake the unit into the name, but also less possibility of error. reply TeMPOraL 2 hours agorootparent> i also have a method parseDuration which accepts a variety of simple but unambiguous string formats for these, like \"10ms\", \"1s\", \"2h30m\", \"1m100us\", \"0\", \"inf\", etc. I did that too with parsers for configuration files; my rule of thumb is that the unit has to always be visible somewhere anywhere a numeric parameter occurs in the type, in the name, or in the value. Like e.g.: // in config file: { ..., \"timeout\": \"10 seconds\", ... } // in parsing code: auto& ParseTimeout(const std::string&) > Expected; // in a hypothetical intermediary if, for some reason, we need to use a standard numeric type: int timeoutMsec = ....; Wrt. string formats, I usually allowed multiple variants for a given time unit, so e.g. all these were valid and equivalent values: \"2h\", \"2 hour\", \"2 hours\". I'm still not convinced it was the best idea, but the Ops team appreciated it. (I didn't allow mixing time units like \"2h30m\" in your example, as to simplify parsing into single \"read double, read rest as string key into a lookup table\" pass, but I'll think about allowing it the next time I'm in such situations. Are there any well-known pros/cons to this?) reply theamk 15 hours agorootparentprevIt should not matter though, because std::chrono is not int-convertible so is it \"milliseconds\" or \"microseconds\" or whatever is an minor implementation detail. You cannot compile FooBar(5000), so there is never confusion in C++ like C has. You have to do explicit \"FooBar(std::chrono::milliseconds(500))\" or \"FooBar(500ms)\" if you have literals enabled. And this will handle conversion if needed you can always do FooBar(500ms) and it will work even if actual type in microseconds. Similarly, your \"auto\" example will only compile if gl_timeout is a compatible type, so you don't have to worry about units at all when all your intervals are using std::chrono. reply codetrotter 5 hours agorootparentprev> Yes, I use IDE or a language-server-enabled editor when working with C++, and no, I don't have time to stop every 5 seconds to hover my mouse over random symbols to reveal their types. JetBrains does a great thing where they show types for a lot of things as labels all the time instead of having to hover over all the things. reply TeMPOraL 4 hours agorootparentRight; the so-called \"inlay hints\" are also provided by clangd over LSP, so I have them in my Emacs too. Super helpful, but not always there when I need them. reply physicles 17 hours agorootparentprevRight, your type system can quickly become unwieldy if you try to create a new type for every slight semantic difference. I feel like Go strikes a good balance here with the time.Duration type, which I use wherever I can (my _msec example came from C). Go doesn’t allow implicit conversion between types defined with a typedef, so your code ends up being very explicit about what’s going on. reply scott_w 9 hours agoparentprevYes and it's made worse by using \"deciseconds,\" a unit of time I've used literally 0 times in my entire life. If you see a message saying \"I'll execute in 1ms,\" you'd look straight to your settings! reply bmicraft 15 hours agoparentprev> Variables must have units in their names if there's any ambiguity Then you end up with something where you can write \"TimoutSec=60\" as well as \"TimeoutSec=1min\" in the case of systemd :) I'd argue they'd been better of not putting the unit there. But yes, aside from that particular weirdness I fully agree. reply physicles 14 hours agorootparent> Then you end up with something where you can write \"TimoutSec=60\" as well as \"TimeoutSec=1min\" in the case of systemd :) But that's wrong too! If TimeoutSec is an integer, then don't accept \"1min\". If it's some sort of duration type, then don't call it TimeoutSec call it Timeout, and don't accept the value \"60\". reply yencabulator 19 hours agoparentprevI do that, but I can't help thinking that it smells like Hungarian notation. The best alternative I've found is to accept units in the values, \"5 seconds\" or \"5s\". Then just \"1\" is an incorrect value. reply physicles 17 hours agorootparentThat’s not automatically bad. There are two kinds of Hungarian notation: systems Hungarian, which duplicates information that the type system should be tracking; and apps Hungarian, which encodes information you’d express in types if your language’s type system were expressive enough. [1] goes into the difference. [1] https://www.joelonsoftware.com/2005/05/11/making-wrong-code-... reply yencabulator 17 hours agorootparentAnd this is exactly the kind the language should have a type for, Duration. reply deltaburnt 4 hours agoparentprevThough, ironically, msec is still ambiguous because that could be milli or micro. It's often milli so I wouldn't fault it, but we use micros just enough at my workplace where the distinction matters. I would usually do timeout_micros or timeout_millis. reply seszett 4 hours agorootparentWe use \"ms\" because it's the standard SI symbol. Microseconds would be \"us\" to avoid the µ. In fact, our French keyboards do have a \"µ\" key (as far as I remember, it was done so as to be able to easily write all SI prefixes) but using non-ASCII symbols is always a bit risky. reply hnuser123456 4 hours agorootparentprevShouldn't that be named \"usec\"? But then again, I can absolutely see someone typing msec to represent microseconds. reply thousand_nights 4 hours agorootparentprevcan also do usec for micro reply jayd16 2 hours agoparentprevWhat would you call the current setting that takes both string enums and deciseconds? reply bambax 13 hours agoparentprevYes! As it is, '1' is ambiguous, as it can mean \"True\" or '1 decisecond', and deciseconds are not a common time division. The units commonly used are either seconds or milliseconds. Using uncommon units should have a very strong justification. reply MrDresden 11 hours agoparentprev> I insist on this all the time in code reviews. Variables must have units in their names if there's any ambiguity. For example, `int timeout` becomes `int timeout_msec`. Personally I flag any such use of int in code reviews, and instead recommend using value classes to properly convey the unit (think Second(2) or Millisecond(2000)). This of course depends on the language, it's capabilities and norms. reply kqr 11 hours agorootparentI agree. Any time we start annotating type information in the variable name is a missed opportunity to actually use the type system for this. I suppose this is the \"actual\" problem with the git setting, in so far as there is an \"actual\" problem: the variable started out as a boolean, but then quietly turned into a timespan type without triggering warnings on user configs that got reinterpreted as an effect of that. reply miohtama 4 hours agoparentprevIt's almost like Git is a version control system built by developers who only knew Perl and C. reply thedufer 17 hours agoprev> Now, why Junio thought deciseconds was a reasonable unit of time measurement for this is never discussed, so I don't really know why that is. xmobar uses deciseconds in a similar, albeit more problematic place to declare how often to refresh each section. Using deciseconds is fantastic if your goal is for example configs to have numbers small enough that they clearly can't be milliseconds, resulting in people making the reasonable assumption that it must thus be seconds, and running their commands 10 times as often as they intended to. I've seen a number of accidental load spikes originating from this issue. reply snet0 21 hours agoprevThis seems like really quite bad design. EDIT: 1) is the result of my misreading of the article, the \"previous value\" never existed in git. 1) Pushing a change that silently break by reinterpreting a previous configuration value (1=true) as a different value (1=0.100ms confirmation delay) should pretty much always be avoided. Obviously you'd want to clear old values if they existed (maybe this did happen? it's unclear to me), but you also probably want to rename the configuration label.. 2) Having `help.autocorrect`'s configuration argument be a time, measured in a non-standard (for most users) unit, is just plainly bad. Give me a boolean to enable, and a decimal to control the confirmation time. reply jsnell 21 hours agoparentFor point 1, I think you're misunderstanding the timeline. That change happened in 2008, during code review of the initial patch to add that option as a boolean, and before it was ever committed to the main git tree. reply iab 21 hours agoparentprev“Design” to me intimates an intentional broad-context plan. This is no design, but an organic offshoot reply snet0 21 hours agorootparentSomeone thought of a feature (i.e. configurable autocorrect confirmation delay) and decided the interface should be identical to an existing feature (i.e. whether autocorrect is enabled). In my thinking, that second part is \"design\" of the interface. reply iab 16 hours agorootparentI think that is something that arose from happenstance, not thoughtful intent this is true because of how confusing the end result is. reply userbinator 21 hours agoprevIMHO this is a great example of \"creeping featurism\". At best it introduces unnecessary complexity, and at worst those reliant on it will be encouraged to pay less attention to what they're doing. reply snowfarthing 5 minutes agoparentWhat I don't get is why anyone would want to allow the automation. Is it really that difficult to use the up-arrow key and correct the mistake? Doing something automatically when it's sort-of correct is a recipe for doing things you didn't intend to do. reply cedws 21 hours agoparentprevThat's git in a nutshell. An elegant data structure masked by many layers of unnecessary crap that has accumulated over the years. reply zX41ZdbW 20 hours agoprev> Which was what the setting value was changed to in the patch that was eventually accepted. This means that setting help.autocorrect to 1 logically means \"wait 100ms (1 decisecond) before continuing\". The mistake was here. Instead of retargeting the existing setting for a different meaning, they should have added a new setting. help.autocorrect enable or disable help.autocorrect.milliseconds how long to wait There are similar mistakes in other systems, e.g., MySQL has innodb_flush_log_at_trx_commit which can be 0 if disabled, 1 if enabled, and 2 was added as something special. reply stouset 20 hours agoparentThe “real” issue is an untyped configuration language which tries to guess at what you actually meant by 1. They’re tripling down on this by making 1 a Boolean true but other integers be deciseconds. This is the same questionable logic behind YAML’s infamous “no” == false. reply Dylan16807 19 hours agorootparentI'd say the new addition is more of a special case of rounding than it is messing up types. reply stouset 15 hours agorootparent1 was also accepted as a Boolean true in this context, and it still is in other contexts. reply Dylan16807 15 hours agorootparent> 1 was also accepted as a Boolean true in this context, and it still is in other contexts. Is \"was\" before the change described at the end of the article, or after it? Before the change, any positive number implied that the feature is on, because that's the only thing that makes sense. After the change, you could say that 1 stops being treated as a number, but it's simpler to say it's still being treated as a number and is getting rounded down. The interpretation of various types is still messy, but it didn't get more messy. reply stouset 11 hours agorootparentIn an earlier iteration the configuration value was Boolean true/false. A 1 was interpreted as true. They changed it to an integral value. This is the entire setup for the problem in the article. Elsewhere, 1 is still allowed as a true equivalent. reply Dylan16807 3 hours agorootparentBut then they made it not be a boolean when they added the delay. They went the opposite direction and it caused problems. How is this a situation of \"tripling down\"? It seems to me like they couldn't make up their mind. reply stouset 2 hours agorootparentThe only reason they even need this further hack is because people can reasonably assume that 1 is bool. Now, because of this confusion, they’re special-casing 1 to actually mean 0. But other integers are still themselves. They’ve also now added logic to make \"yes\", \"no\", \"true\", \"off“ strings be interpreted as booleans now too. reply JBiserkov 16 hours agorootparentprevNO is the country code for Norway. reply xnorswap 4 hours agorootparent\"The Norway Problem\": https://hitchdev.com/strictyaml/why/implicit-typing-removed/ reply smaudet 11 hours agoparentprevNot sure where the best place to mention would be, but 0.1 deciseconds is not unreasonable, either...yes fastest recorded random reaction time maybe 1.5 ds (coincidentally this is the average gamer reaction time), however non-random reaction times can be much faster (e.g. on a beat). So if you wanted to go that fast, you could, the invokation should have relatively stable speeds (order of some milliseconds... reply catlifeonmars 21 hours agoprevI enabled autocorrect (set a 3sec) a year ago and have the following observations about it: 1. it does not distinguish between dangerous and safe actions 2. it pollutes my shell history with mistyped commands Reading this article gave me just enough of a nudge to just disable it after a year. reply layer8 20 hours agoparentIf anything, it’s better to set up aliases for frequent typos. (Still “pollutes” the shell history of course.) reply darkwater 20 hours agoparentprevAbout 2, well, you are the actual polluter, even if you just scroll back in history andnuse the same last wrong command because it works anyway. reply bobbylarrybobby 19 hours agorootparentThe issue is if you accept the wrong command instead of retyping it correctly, you never get the correctly spelled command into your history — and even worse, you don't get it to be more recent than the mistyped command. reply catlifeonmars 19 hours agorootparentprevWell to put it into context, I use fish shell, which will only save commands that have an exit code of 0. By using git autocorrect, I have guaranteed that all git commands have an exit code of 0 :) reply fsckboy 4 hours agorootparentwow, our brains work differently, how can you smile in that circumstance? :) It's a terrible idea of fish not to save errors in history (even if the way bash does it is not optimal, ignoring/obliterating the error return fact) because running a command to look up the state of something can easily return the state you are checking along with an error code. \"What was that awesome three letter TLD I looked up yesterday that was available? damn, not a valid domain is an error code\" and just like that SEX.COM slips through your grasp, and your only recourse would be to hijack it. but it's compoundedly worse to feel like the problem is solved by autocorrect further polluting your history. I would not want to be fixing things downstream of you, where you would be perfectly happy downstream of me. reply newman314 10 hours agoprevFor reference, Valtteri Bottas supposedly recorded a 40ms!!! reaction time at the 2019 Japanese Grand Prix. https://www.formula1.com/en/video/valtteri-bottas-flying-fin... reply amai 6 hours agoparentMost probably that was a false start: \"World Athletics rules that if an athlete moves within 100 milliseconds (0.1 seconds) of the pistol being fired to start the race, then that constitutes a false start.\" https://www.nytimes.com/athletic/5678148/2024/08/03/olympics... reply arp242 6 hours agorootparentThat value has also been criticised as too high. reply legacynl 4 hours agorootparentWhat is the argument for it being too high? The argument for it being what it is is the fact that our auditorial processing (when using a starter pistol) or visual processing (looking at start-lights) takes time, as well as transferring that message to the relevant muscles. 100 milliseconds is a pretty good average actually reply arp242 3 hours agorootparentBasically, some people can consistently respond faster. The 100ms figure just isn't accurate. I don't have extensive resources/references at hand, but I've read about this a few times over the years. reply legacynl 34 minutes agorootparent> I don't have references ... but I've read about this a few times over the years. Yeah well, I did a psych bsc and I'm telling you that it's impossible. It's certainly possible for people to do and notice things way faster than that, like a musician noticing a drummer being a few ms off beat, or speedrunners hitting frame perfect inputs, but in those cases the expectation and internal timekeeping is doing most of the heavy lifting. reply dotancohen 5 hours agoparentprevI once had a .517 reaction time in a drag race. You know how I did that? By fouling too late. It was completely unrepeatable. I'm willing to bet Bottas fouled that, too late (or late enough). reply voidUpdate 7 hours agoparentprevIs there a random time between the red lights and the green lights, or is it always the same? Because that feels more like learning the timings than reacting to something reply eknkc 3 hours agorootparentNo green lights, when the reds go out it is race start but there is a random delay after all reds lighting up and then going off. reply jsnell 6 hours agorootparentprevYes, the timing is random. reply Reason077 21 hours agoprevDeciseconds is such an oddball choice of units. Better to specify the delay in either milliseconds or seconds either are far more commonly used in computing. reply ralgozino 9 hours agoparentI got really confused for a moment, thinking that \"deciseconds\" was some git-unit meaning \"seconds needed to make a decision\", like in \"decision-seconds\" xD Note: english is not my mother tongue, but I am from the civilised part of the world that uses the metric system FWIW. reply legacynl 31 minutes agorootparentI get where your coming from, although deci is certainly used, it's rare enough to not expect it, especially in the context of git reply ssernikk 29 minutes agorootparentprevI thought of the same thing! reply cobbal 20 hours agoparentprevIt's a decent, if uncommon, unit for human reactions. The difference between 0 and 1 seconds is a noticeably long time to wait for something, but the difference between n and n+1 milliseconds is too fine to be useful. reply jonas21 19 hours agorootparentMilliseconds are a commonly-used unit. It doesn't really matter if 1 ms is too fine a granularity you'll just have to write \"autocorrect = 500\" in your config file instead of \"autocorrect = 5\", but who cares? reply zxvkhkxvdvbdxz 15 hours agorootparentSure, yes. But for human consumption, decisecond is something one can relate to. I mean, you probably cannot sense the difference in duration between 20 and 30 ms without special equipment. But you can possibly sense the difference between 2 and 3 deciseconds (200 ms and 300 ms) after some practice. I think the issue in this case was rather the retrofitting a boolean setting into a numerical setting. reply LocalH 5 hours agorootparentAnd then you have the rhythm gamers who can adjust their inputs by 5 or 10ms. Hell, I'm not even that good of a player, but in Fortnite Festival, which has a perfect indicator whenever you're within 50ms of the target note timestamp (and a debug display that shows you a running average input offset) and I can easily adjust my play to be slightly earlier or slightly later and watch my average fall or climb. Several top players have multiple \"perfect full combos\" under their belt, where they hit every note in the song within 50ms of the target. I even have one myself on one of the easier songs in the game. reply adzm 11 hours agorootparentprev> But you can possibly sense the difference between 2 and 3 deciseconds (200 ms and 300 ms) after some practice. At 120bpm a sixteenth note is 125ms, the difference is very obvious I would think reply fragmede 15 hours agorootparentprevThe difference between 20 ms and 30ms is the difference between 33 fps and 50 fps which is entirely noticable on a 1080p60hz screen. reply bmicraft 15 hours agorootparentprevIf you're going to store that unit in one byte (possible even signed) suddenly deci-seconds start making a lot of sense reply lionkor 4 hours agorootparentWhy would you do that? reply bobbylarrybobby 19 hours agorootparentprevBut the consumers of the API aren't humans, they're programmers. reply theginger 21 hours agoprevReaction times differ by types of stimulus, auditory is slightly faster than visual and tactile slightly faster than that at 90 180 ms So if git gave you a slap instead of an error message you might just about have time to react. reply orangepanda 21 hours agoparentThe slapping device would need to build inertia for you to feel the slap. Is 10ms enough for that? reply dullcrisp 21 hours agorootparentI think if it's spring-loaded then definitely. (But it's 100ms, not 10ms.) reply orangepanda 21 hours agorootparentAssuming the best case scenario of feeling the slap in 90ms, it would leave 10ms to abort the command. Or did the 90-180ms range refer to something else? reply dullcrisp 20 hours agorootparentOh I see, you’re right. reply Aerroon 14 hours agorootparentprevThis is why any reasonable engineer would go with zaps instead of slaps! reply cardamomo 22 hours agoprevReading this post, the term \"software archeology\" and \"programmer archeologist\" come to mind. (Thank you, Vernor Vinge, for the latter concept.) reply scubbo 15 hours agoparentGrrrr, this is such a bugbear for me. I was so excited to read \"A Fire Upon The Deep\" because hackers talked up the concept of \"software archeology\" that the book apparently introduced. The concept is briefly alluded to in the prologue, and then...nada, not relevant to the rest of the plot at all (the _effects_ of the archeology are, but \"software archeologists\" are not meaningful characters in the narrative). I felt bait-and-switched. reply schacon 22 hours agoparentprevI can’t help but feel like you’re calling me “old”… reply cardamomo 21 hours agorootparentNot my intention! Just an esteemed git archeologist reply choult 21 hours agoparentprevI like to say that the danger of software archaeology is the inevitable discovery of coprolites... reply kittikitti 22 hours agoprevI sometimes have this realization as I'm pressing enter and reflexively press ctrl+c. As someone whose typing speeds range from 100 to 160 WPM, this makes sense. Pressing keys is much different from Formula One pit stops. reply otherme123 21 hours agoparentNot about pit stops. They talk about pro drivers with highly trained reflexes, looking at a red light knowing that it will turn green in the next 3 seconds, so they must push a pedal to the metal as fast as they can. If they react in less than 120ms is considered a jump start. As for 100WPM, which is a very respectable typing speed, it translates to 500 CPM, less than 10 characters per second, and thus slightly above 100ms per keypress. But Ctrl+C are two key presses: reacting to type them both in under 100 ms is equivalent to a writting speed above 200WPM. Even the fastest pro-gamers struggle to go faster than 500 actions (keypresses) per minute (and they use tweaks on repeat rates to get there), still more than 100ms for two key presses. reply mjpa86 9 hours agorootparentThere is no green light at the start it's the lights going out they react to. There's also no minimum time, you can get moving after 1ms it's legal. In fact, you can move before the lights go out, there's a tolerance before you're classed as moving. reply Aerroon 14 hours agorootparentprev>But Ctrl+C are two key presses: reacting to type them both in under 100 ms is equivalent to a writting speed above 200WPM. I think people don't really type/press buttons at a constant speed. Instead we do combos. You do a quick one-two punch because that's what you're used to (\"you've practiced\"). You do it much faster than that 100ms, but after that you get a bit of a delay before you start the next combo. reply otherme123 12 hours agorootparentAs menctioned, pro-gamers train combos for hours daily. The best of them can press up to 10 keys per second without thinking. For example, the fastest StarCraft II player Reynor (Riccardo Romitti) can sustain 500 key presses per minute, and do short busts of 800. He has videos explaining how to tweak the Windows registry to achieve such rate (it involves pressing some keys once and the OS autorepeats faster than you can press), because it can't be done with the standard config dialogs. And you are trying to tell me that you can do double that... not only double that, \"much faster\" than that. I dare anyone to make a script that, after launching, will ask you to press Ctrl+C after a random wait between 1000 and 3000 ms. And record your reaction time meassured after key release. It's allowed to \"cheat\" and have your fingers ready over the two keys. Unless you jump start and get lucky, you won't get better than 150ms. reply leeoniya 4 hours agorootparenthttps://humanbenchmark.com/tests/reactiontime for single mouse click, 225ms is pretty typical for me after a bit of warmup. sub 200 is not consistently reproducible. i dont think i've ever cracked ` and realise you made a typo before you've finished typing. You can't react fast enough to stop hitting enter but you can absolutely ctrl+c before 100 more ms are up reply dusted 6 hours agorootparentYes exactly! This is what I'm trying to argue as well, it happens quite often for me that I submit a typo because it's already \"on it's way out\" when I catch it (but before, or about the same time it's finished and enter is pressed), so the ctrl+c is already on it's way :) reply Etheryte 20 hours agorootparentprevI'm still pretty skeptical of this claim. If you type 60 wpm, which is faster than an average human, but regular for people who type as professionals, you spend on average 200ms on a keystroke. 60 standard words per minute means 300 chars per minute [0], so 5 chars per second which is 200ms per char. Many people type faster than this, yes, but it's all still very much pushing it just to even meet the 100ms limit, and that's without any reaction or anything on top. [0] https://en.wikipedia.org/wiki/Words_per_minute reply shawabawa3 4 hours agorootparentI just tried it out. I wrote this bash script: #!/usr/bin/env bash start_time=$(gdate +%s%3N) # Function to handle Ctrl+C (SIGINT) on_ctrl_c() { end_time=$(gdate +%s%3N) total_ms=$((end_time start_time)) # Calculate integer seconds and the remaining milliseconds seconds=$((total_ms / 1000)) millis=$((total_ms % 1000)) # Print the runtime in seconds.milliseconds echo \"Script ran for ${seconds}.$(printf '%03d' ${millis}) seconds.\" exit 0 } # Trap Ctrl+C (SIGINT) and call on_ctrl_c trap on_ctrl_c INT # Keep the script running indefinitely while true; do sleep 1 done And then i typed \"bash sleep.sh git push origin master\" and got \"Script ran for 0.064 seconds.\" reply pc86 19 hours agorootparentprevEven if you typed 120 wpm, which is \"competitive typing\" speed according to this thing[0], it's going to take you 200ms to type ctrl+c, and even if you hit both more-or-less simultaneously you're going to be above the 100ms threshold. So to realistically be able to do something like beat the threshold during normal work and not a speed-centered environment you're probably looking at regularly 160 wpm or more? I'm not a competitive speed typist or anything but I struggle to get above 110 on a standard keyboard and I don't think I've ever seen anyone above the 125-130 range. [0] https://www.typingpal.com/en/documentation/school-edition/pe... reply grayhatter 18 hours agorootparentprevFor whatever it's worth*: I'm not skeptical of it at all. I've done this in a terminal before without even looking at the screen, so I know it can't have anything to do with visual reaction. Similar to the other reply, I also commonly do that when typing, where I know I've fat fingered a word, exclusively from the feeling of the keyboard. But also, your not just trying to beat the fork/exec. You can also successfully beat any number of things. The pre-commit hook, the DNS look up, the TLS handshake. adding an additional 100ms of latency to that could easily be the difference between preempting some action, interrupting it or noticing after it was completed. reply tokai 2 hours agorootparentprevTyping is not string of reactions to stimuli. reply yreg 20 hours agorootparentprevLet's say you are right. What would be a reason for pressing ctrl+c instead of letting the command go through in your example? The delay is intended to let you abort execution of an autocorrected command, but without reading the output you have no idea how the typos were corrected. reply brazzy 21 hours agorootparentprev> you can absolutely ctrl+c before 100 more ms are up Not gonna believe that without empirical evidence. reply burnished 21 hours agorootparentI think they are talking about times where you realize a mistake as you are making it as opposed to hindsight, given that 100ms seems pretty reasonable. reply dusted 6 hours agorootparentThis is exactly what I'm trying to say. The actions are underway by muscles (or _just_ completed) and the brain catches something's off and so ctrl+c is queued. reply brazzy 12 hours agorootparentprev\"seems pretty reasonable\" is not evidence. reply dusted 6 hours agorootparentprevThat'd be interesting, but I don't know how to prove that I'm not just \"pretending\" to make typos and correcting them instantly ? reply bmacho 20 hours agorootparentprevI am not sure, have you read it properly? The scenario is that you are pushing enter, halfway change your mind, and your are switching to ctrl+c. So it is not a reaction time, but an enter to ctrl+c scenario. Regarding reaction time, below 120ms (on a computer, in a browser(!)) is consistently achievable, e.g. this random yt video https://youtu.be/EH0Kh7WQM7w?t=45 . For some reason, I can't find more official reaction time measurements (by scientists, on world champion athletes, e-athletes), which is surprising. reply brazzy 10 hours agorootparentThat scenario seems to me fishy to begin with, is that something that actually happens, or just something people imagine? How would it work that you \"change your mind halfway through\" and somehow cannot stop your finger from pressing enter, but can move them over and hit ctrl-c in a ridiculously short time window? > So it is not a reaction time, but an enter to ctrl+c scenario. At minimum, if we ignore the whole \"changing your mind\" thing. And for comparison: the world record for typing speed (over 15 seconds and without using any modifier keys) is around 300wpm, which translates to one keypress every 40ms you really think 100ms to press two keys is something \"you can absolutely\" do? I'd believe that some* people could sometimes do it, but certainly not just anyone. reply dusted 11 hours agorootparentprevThere are different ways to measure reaction time. Circumstance is important. Reaction to unreasonable, unexpected events will be very slow due to processing and trying to understand what happens and how to respond. Examples, you are a racecar driver, participating in a race, you're driving your car on a racetrack in a peaceful country. An armed attack: Slow reaction time, identifying the situation will take a long time, selecting an appropriate response will take longer. A kid running into the road on the far side of the audience stands: Faster. Kid running into the road near the audience: Faster. Car you're tailing braking with no turn to come: Faster. Crashed car behind a turn with bad overview: Faster. Guy you're slipstreaming braking before a turn: Even faster. For rhythm games, you anticipate and time the events, and so you can say these are no longer reactions, but actions. In the git context, where you typed something wrong, the lines are blurred, you're processing while you're acting, you're typing while you're evaluating what you're typing, first line of defence is you're feeling/sensing that you typed wrong, either from the feedback that your fingers touched too many keys, or that you felt the rhythm of your typing was wrong, at least for me, this happens way faster than my visual input. I'm making errors as I type this, and they're corrected faster than I can really read it, sometimes I get it wrong and deleted a word that was correct. But still, watching people type, I see this all the time, they're not watching and thinking about the letters exclusively, there's something going on in their minds at the same time. 100 ms is a rather wide window in this context. Also, that said, we did a lot of experiments at work with a reaction time tester, most people got less than 70 ms after practice (a led lights up at a random interval between 2 and 10 seconds) reply tomatotomato37 3 hours agorootparentI also want to add in the context of human sprinters & F1 drivers, their reaction time is measured via leg actuation, which for a creature evolved to be an object-throwing endurance hunter is going to have worse neural & muscular latency than, say, your forearm. That is why using your finger to trigger a response in a conventional computer time tester can get such high speeds, cause we're essentially evolved for it. reply SOLAR_FIELDS 22 hours agoparentprev100 ms is an insanely short window. I would say usually even 1000ms would be too short for me to recognize and kill the command, even if I realized immediately that I had done something wrong. reply jsjshsbd 21 hours agorootparentIt's much too short to read an output, interpret it and realize you have to interrupt But often you type something, realize it's wrong while you are typing but not fast enough to stop your hand from pressing [Enter] That is one of the only situation 100ms would be enough to safe you That being said, the reason in the article for 100ms is just confused commander. Why would anyone: 1) encode a Boolean value as 0/1 in a human readable configuration 2) encode a duration as a numeric value without unit in a human readable configuration Both are just lazy reply SoftTalker 3 hours agorootparentAbsolutely. When I'm booting up an unfamiliar system and trying to catch the BIOS prompt for something non-normal, even 5 seconds is often too short. For me to notice that the prompt has been given, read \"PRESS DEL KEY TO ENTER SETUP, F11 FOR BOOT OPTIONS, F12 FOR PXE BOOT\" (or whatever), understand it, look for the F11 key on the possibly unfamilar keyboard on my crash cart, and press it, can often take me more than 5 seconds. Especially if it's not a single key required but a control sequence. Maybe I'm slow. I always change these prompts to 10 seconds if they are configurable. Or I'll make a label with the options and stick it on the case so I can be prepared in advance. reply Reason077 21 hours agorootparentprev> \"Why would anyone ... encode a Boolean value as 0/1 in a human readable configuration\" It may be lazy, but it's very common! reply grayhatter 18 hours agorootparentprevlaziness is a virtue of a good programmer. why demand many char when few char do trick? also > Why would anyone [...] encode a duration as a numeric value without unit in a human readable configuration If I'm only implementing support for a single unit, why would you expect or want to provide a unit? What's the behavior when you provide a unit instead of a number? > but not doing that extra work is lazy no, because while I'm not implementing unit parsing for a feature I wouldn't use, instead I'm spending that time implementing a better, faster diff algorithm. Or implementing a new protocol with better security, or sleeping. It's not lazy to do something important instead of something irrelevant. And given we're talking about git, which is already very impressive software, provided for free by volunteers, I'm going to default to assuming they're not just lazy. reply tokai 2 hours agoparentprevYou are talking about an anticipatory response. Human response have been studied extensively and it is broadly accepted that ~100ms is the minimum for physiological processing and motor response to stimuli. If you feel you go faster you are anticipating your reaction. reply frde_me 10 hours agoparentprevBut the point here is not that you need to realize you typed something wrong and then cancel (in that case just don't enable the setting if you always want to abort). The point is that you need to decide if the autocorrect suggestion was the right one. Which you can't know until it tells you what it wants to autocorrect to. reply dankwizard 19 hours agoparentprevNeo, get off HN and go destroy the agents! reply politelemon 22 hours agoprevI agree that 'prompt' should be the value to set if you want git autocorrect to work for you. I'd however want that the Y is the default rather than the N, so that a user can just press enter once they've confirmed it. In any case it is not a good idea to have a CLI command happen without your approval, even if the intention was really obvious. reply misnome 22 hours agoparentYes, absolutely this. If I don’t want it to run, I will hit ctrl-c. reply junon 21 hours agoparentprevIf prompt is the default, mistyped scripts will hang rather than exit 1 if they have stdin open. I think that causes more problems than it solves. reply jzwinck 21 hours agorootparentThat's what isatty() is for. If stdin is not a TTY, prompting should not be the default. Many programs change their defaults or their entire behavior based on isatty(). reply junon 5 hours agorootparentisatty() is spoofed in e.g. Make via PTYs. It's a light check at best and lies to you at worst. reply darthwalsh 13 minutes agorootparentIf make is going to spoof the PTY, it should take responsibility for answering the autocorrect prompt reply mmcnl 21 hours agoprevThe most baffling thing is that someone implemented deciseconds as a unit of time. Truly bizarre. reply bun_terminator 10 minutes agoprevclickbait, don't hide the truth in a pseudo-riddle reply kqr 11 hours agoprevThis timeout makes me think about the type of scenario where I know I have mistyped the command, e.g. because I accidentally hit return prematurely, or hit return when I was trying to backspace away a typo. In those situations I reflexively follow return with an immediate ctrl-C, and might be able to get in before the 100 ms timeout. So it’s not entirely useless! reply 1970-01-01 23 hours agoprevDeciseconds?? There's your problem. Always work in seconds when forcing a function for your users. reply GuB-42 20 hours agoparentDeciseconds (100ms) are not a bad unit when dealing with UI because it is about the fastest reaction time. We can't really feel the difference between 50 ms and 150 ms (both feel instant), but we can definitely feel the difference between 500 ms and 1500 ms. Centiseconds are too precise, seconds are not enough. Also, it is also possible that the computer is not precise enough for centiseconds or less, making extra precision a lie. Deciseconds are just uncommon. But the problem here is that the user didn't expect the \"1\" to be a unit of time but instead a boolean value. He never wanted a timer in the first place. By the way, not making the unit of time clear is a pet peeve of mine. The unit is never obvious, seconds and milliseconds are the most common, but you don't know which one unless you read the docs, and it can be something else. My preferred way is to specify the unit during the definition (ex: \"timeout=1s\") with a specific type for durations, second is to have it in the name (ex: \"timeoutMs=1000\"), documentation comes third (that's the case of git). If not documented in any way, you usually have to resort to trial and error or look deep into the code, as these values tend to be passed around quite a bit before reaching a function that finally makes the unit of time explicit. reply synecdoche 21 hours agoparentprevThis may be something specific to Japan, which is where the maintainer is from. In the Japanese industrial control systems that I’ve encountered time is typically measured in this unit (100 ms). reply gruez 22 hours agoparentprevbetter yet, encode the units into the variable/config name so people don't have to guess. You wouldn't believe how often I have to guess whether \"10\" means 10 seconds (sleep(3) in linux) or milliseconds (Sleep in win32). reply userbinator 17 hours agoparentprevMy default for times is milliseconds, since that's a common granularity of system timing functions. reply dusted 22 hours agoparentprevat least fractions of a second, 250 would already be much more noticble.. 100 is a nice compromise between \"can't react\" and \"have to wait\", assuming you're already realizing you probably messed up reply 331c8c71 22 hours agoparentprevSeconds or milliseconds (e.g. if the setting must be integer) would've been fine as they are widely used. Deciseconds, centiseconds wtf? reply atonse 22 hours agorootparentFalls squarely within the \"They were too busy figuring out whether they could do it, to ask whether they SHOULD do it\" reply UndefinedRef 22 hours agoparentprevMaybe he meant dekaseconds? Still weird though.. reply TonyTrapp 22 hours agorootparentIt reads like the intention was that turning the parameter (0/1) command into an integer parameter, where the previous value enabled = 1 should behave reasonably close to the old behaviour. 1 deciseconds is arguably close enough to instant. If the parameter were measured in seconds, the command would always have to wait a whole second before executing, with no room for smaller delays. reply bot403 20 hours agorootparentNo, smaller delaysintroduced a small patch > introduced a patch > the Git maintainer, suggested > relatively simple and largely backwards compatible fix > version two of my patch is currently in flight to additionally And this is how interfaces become unusable, through thousand small \"patches\" created without any planning and oversight. reply olddustytrail 5 hours agoparentAh, if only the Git project had someone of your talents in charge (rather than the current band of wastrel miscreants). Then it might enjoy some modicum of success, instead of languishing in its well-deserved obscurity! reply jakubmazanec 4 hours agorootparentGit has notoriously bad CLI (as other commenters here noted). Your snarky comment provides no value to this discussion. reply olddustytrail 4 hours agorootparentOn the contrary, it offers a little levity and humour, and possibly even the chance for some self-reflection as you consider why you thought it was appropriate to insult the folk who manage Git. I'm sure you can manage at least one of those? reply jakubmazanec 3 hours agorootparentYour comment isn't funny, just snarky. I suggest you read again HN guidelines and do some reflection yourself. Also, if you see it as insult, that's your mistake. It is just a simple empirical observation. I'm not saying it's an original thought feel free to Google more about this topic. I won't waste any more time since you obviously aren't interested in discussion. reply Ylpertnodi 43 minutes agorootparent>I won't waste any more time since you obviously aren't interested in discussion. Pot. Kettle. Black. reply NoPicklez 17 hours agoprevCool but I don't know why it needs to be justified that it's too fast even for an F1 driver. Why can't we just say its too fast without all the fluff about being a race car driver, the guy isn't even an F1 driver but Le Mans. reply blitzar 8 hours agoparentMy deoderant is good enough for a F1 driver, why whouldnt my git client adhere to the same standards? reply benatkin 16 hours agoparentprevThe author is someone who went to conferences that DHH also attended, so for some of the audience it's a funny anecdote. reply IshKebab 20 hours agoprev> Junio came back to request that instead of special casing the \"1\" string, we should properly interpret any boolean string value (so \"yes\", \"no\", \"true\", \"off\", etc) The fact that this guy has been the Git maintainer for so long and designs settings like this explains a lot! reply ocean_moist 8 hours agoprevFun fact: Professional gamers (esport players) have reaction times around 150ms to 170ms. 100ms is more or less impossible. reply pmontra 21 hours agoprevAccording to Formula 1 web site drivers start on average after 0.2 seconds since the red lights go out https://www.formula1.com/en/latest/article/rapid-decisions-d... Anyway, 0.1 seconds would be far too short even for them, which have a job based on fast reaction times. reply moogly 21 hours agoprevSo Mercurial had something like this back in ancient times, but git devs decided to make a worse implementation. reply mike-the-mikado 22 hours agoprevI'd be interested to know if any F1 drivers actually use git. reply schacon 22 hours agoparentNot sure, but I do personally know two high profile Ruby developers who regularly race in the LMP2 (Le Mans Prototype 2) class DHH and my fellow GitHub cofounder PJ Hyett, who is now a professional driver, owning and racing for AO (https://aoracing.com/). I mostly say this because I find it somewhat fun that they have raced _each other_ at Le Mans last year, but also because I've personally seen both of them type Git commands, so I know it's true. reply xeonmc 21 hours agorootparentMaybe we can pitch to Max Verstappen to use Git to store his sim racing setup configs. reply pacaro 22 hours agorootparentprevI've also worked with engineers who have raced LMP. It's largely pay-to-play and this is one of those professions where if you're the right person, in the right place, at the right time, you might be able to afford it. reply diggan 22 hours agorootparentprevIsn't Le Mans more of a \"endurance\" race though, especially compared to F1? It would be interesting to see the difference in reaction ability between racers from the two, I could see it being different. reply schacon 22 hours agorootparentI feel like in the \"racing / git crossover\" world, that's pretty close. :) reply mscdex 22 hours agoprevThis seems a bit strange to me considering the default behavior is to only show a suggested command if possible and do nothing else. That means they explicitly opted into the autocorrect feature and didn't bother to read the manual first and just guessed at how it's supposed to be used. Even the original documentation for the feature back when it was introduced in 2008 (v1.6.1-rc1) is pretty clear what the supported values are and how they are interpreted. reply Theodores 22 hours agoprev0.1 seconds is a long time in drag racing where the timing tree is very different to F1. With F1 there are the five red lights that have to go out, and the time this takes is random. With your git commands it is fairly predictable what happens next, it is not as if the computer is randomly taunting you with five lights. I suggest a further patch where you can put git in either 'F1 mode', or, for our American cousins, 'Drag Strip mode'. This puts it in to a confirmation mode for everything, where the whole timing sequence is shown in simplified ASCII art. As a European, I would choose 'F1 mode' to have the give lights come on in sequence, wait a random delay and then go out, for 'git push' to happen. I see no reason to also have other settings such as 'Ski Sunday mode', where it does the 'beep beep beep BEEEP' of the skiing competition. 'NASA mode' could be cool too. Does anyone have any other timing sequences that they would like to see in the next 'patch'? reply inoffensivename 13 hours agoprevMaybe a not-so-hot take on this... The only option this configuration parameter should take is \"never\", which should also be the default. Any other value should be interpreted as \"never\". reply meitham 21 hours agoprevReally enjoyable read reply moffkalast 19 hours agoprev> As some of you may have guessed, it's based on a fairly simple, modified Levenshtein distance algorithm One day it'll dump the recent bash and git history into an LLM that will say something along the lines of \"alright dumbass here's what you actually need to run\" reply baggy_trough 19 hours agoprevWhenever you provide a time configuration option, field, or parameter, always encode the units into the name. reply Pxtl 21 hours agoprevPet peeve: Timespan configs that don't include the unit in the variable name. I'm so sick of commands with timeout params where I'm left guessing if it's seconds or millis or what. reply hinkley 21 hours agoparentBe it seconds or milliseconds, eventually your program evolves to need tenths or less of that unit and you can either support decimal points, create a new field and deprecate the old one, or do a breaking change that makes the poor SOB that needs to validate a breaking change-bearing upgrade in production before turning it on get a migraine if they have to toggle back and forth more than a couple times. Code isn’t always arranged so that a config change and a build/runtime change can be tucked into a single commit that can be applied or rolled back atomically. All because someone thought surely nobody would ever want something to happen on a quarter of a second delay/interval, or a 250 microsecond one. reply skykooler 20 hours agoparentprevI spent a while debugging a library with a chunk_time_ms parameter where it turned out \"ms\" stood for \"microseconds\". reply grayhatter 18 hours agorootparentI have a very hard time relating to everyone else complaining about ~~lack of units~~ being unable to read/remember API docs. But using `chunk_time_ms` where ms is MICROseconds?! That's unforgivable, and I hope for all our sakes, you don't have to use that lib anymore! :D reply Pxtl 15 hours agorootparentThe sheer number of APIs of modern coding is exhausting, I can't imagine either trying to keep all the stuff I'm using in my head or having to go back to the docs every time instead of being able to just read the code. reply grayhatter 3 hours agorootparentdo you primarily write rust, or js? reply echoangle 21 hours agoparentprevAlternatively, you can also accept the value with a unit and return an error when a plain number is entered (so timeout 5s or timeout 5h is valid but timeout 5 returns an error). reply cratermoon 21 hours agoparentprevI'll bounce in with another iteration of my argument for avoiding language primitive types and always using domain-appropriate value types. A Duration is not a number type, neither float or integer. It may be implemented using whatever primitive the language provides, but for timeouts and sleep, what is 1 Duration? The software always encodes some definition of 1 unit in the time domain, make it clear to the user or programmer. reply snvzz 19 hours agoprevAt 60fps that's 6 frames, which is plenty. That aside, I feel the reason is to advertise the feature so that the user gets a chance to set the timer up to his preference or disable autocorrect entirely. reply ninjamuffin99 19 hours agoparent6 frames is not enough to realize you made a typo / read whatever git is outputting telling you that you made a typo, and then respond to that input correctly. in video games it may seem like a lot of time for a reaction, but a lot of that “reaction time” is based off previous context of the game, visuals and muscle memory and whatnot. If playing street fighter and say youre trying to parry an attack that has a 6 frame startup, you’re already anticipating an attack to “react” to before their attack even starts. When typing git commands, you will never be on that type of alert to anticipate your typos. reply snvzz 16 hours agorootparent>6 frames is not enough git good. (the parent post was a set up for this) reply tester756 22 hours agoprev [–] Yet another example where git shows its lack of user-friendly design reply hinkley 21 hours agoparent [–] Well it is named after its author after all. reply yreg 6 hours agorootparent [–] At first I thought this is unnecessary name-calling, but apparently Linus has also made the same joke: > \"I'm an egotistical bastard, and I name all my projects after myself. First Linux, now git.\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Git's autocorrect feature executes a mistyped command after a default delay of 0.1 seconds, which is often too quick for users to cancel. Introduced in 2008, the feature uses a modified Levenshtein distance algorithm to guess the intended command, but defaults to not running any command if mistyped. A proposed patch suggests interpreting a setting of \"1\" as \"immediately\" to enhance usability, allowing users to configure the delay or prompt for confirmation."
    ],
    "commentSummary": [
      "Git's autocorrect feature has a default delay of 100 milliseconds, which is often too quick for users to cancel a mistyped command. Originally intended to interpret a boolean value, the feature now accepts a time delay in deciseconds, causing some confusion among users. This situation underscores the need for clear configuration settings and the difficulties in updating software features without disrupting existing functionality."
    ],
    "points": 391,
    "commentCount": 219,
    "retryCount": 0,
    "time": 1737314423
  },
  {
    "id": 42767507,
    "title": "I Met Paul Graham Once",
    "originLink": "http://okayfail.com/2025/i-met-pg-once.html",
    "originBody": "Phill Mendonça-Vieira See more of my writing or subscribe via rss. I Met Paul Graham Once January 16, 2025#tech, #queer Nota bene: I’ve had a rough 2025 so far. I’m worried that people who used to support, or at least tolerate me, will turn against me out of a desire to conform, to show their obeisance, to the current prevailing winds. I found myself writing this essay to explain why I’ve been feeling so miserable. I sent it to Paul before I published it here. I met Paul Graham once. It was the summer of 2015, and we were attending Y Combinator, the premier finishing school for startup founders. It was a long and stressful summer, holed up in our apartment in Mountain View, and a great experience. We benefitted immensely from our time there. At Y Combinator, there was sort of a curriculum, but they didn’t teach you anything per se. You’re assigned mentors, who you meet weekly, and you are free to book office hours – thirty minutes at a time – with a rotating cast of partners, each and every one of them formidable people, near or at the top of the field. The mentors applied a neat and very effective trick: they believed in you. Out of thousands of applicants, you had been chosen, plucked from obscurity, and flown out, and now you were here, in the centre of the (software) universe. They had invested in you, you personally, above and beyond your specific idea for a business. Now every week you spoke with them, and presented your metrics, and discussed your problems, and, well, you could be doing better, couldn’t you? These results, they were kind of mid. They didn’t boss us around, or tell us what to do, but we didn’t want to disappoint teacher. Their approval meant a lot. Doors would open. Success was at our fingertips: the summer culminated in Demo Day, a cattle call where we would be presented to investors, and our future might change forever. We worked harder. We learned how to hustle. We swallowed rejection. We doubled our efforts, bent over our desks, working until we could barely see straight, trying to figure out how to make something people want. One day, we booked a meeting with pg (Paul Graham). He had just retired from the day to day running of the show, handed the reigns over to sama (Sam Altman), and now roamed the halls as an elder statesmen, a congenial and affable uncle, dispensing advice. We were excited. I don’t think he was ever a hero of mine, but he certainly had influence, made a big impression on me. I had read his essays eight or nine years earlier, during my undergraduate, hunched over a screen in my university’s computer lab, nodding along. I spent way too much time on hackernews. Lisp was cool, I was special for just taking an interest in startups and software, we could do anything if we worked hard enough. We explained our pitch to him: Appcanary monitors your apps and servers, and lets you know when you’re affected by a security vulnerability. He thought it was a decent enough idea, but the name, Appcanary, he wasn’t crazy about the name. He was very good at naming companies. He thought about it and told us that, really, we ought to be named Oracle, that would be a great name for us. Descriptive, simple, memorable. Shame it was taken, though. We nodded and thanked him, and laughed about it later. No one bats a thousand. YC had a huge positive impact on my life. People took us more seriously now. Before we were randos, misfits even, but now we were Princes of the Universe. We had rubbed shoulders with royalty, or at least sovereigns. Someone had believed in us, and pushed us until we understood how to make our own luck. We grew a lot that summer, but we didn’t raise that much money. A bit, enough to keep us going. I loved California, I liked San Francisco, but I didn’t feel comfortable trying to live there. I felt gross being part of a monied class in a city rapidly hollowing out. I’d had a precarious childhood and early adulthood, and I craved some kind of stability. Back home, we lived in the Best Neighbourhood in the Last Affordable Apartment In West Toronto. We knew it would reduce our chances for success, but it would double our runway. In the winter, I had started dating this most amazing girl, and I wanted to see where it would go. Two years later, we realized that everyone thought our product was useful but not that useful. We could get people to pay us hundreds of dollars per month, but not thousands. That’s the death knell of a vc-backed b2b saas sales model. High-touch sales to large companies is not worth it unless you can score thousands of dollars per month. We were too burnt out to pivot to another business idea, and we quietly folded. It was good timing: almost immediately after, GitHub announced they were going to provide our startup’s features for free. We gave them a call, we got them excited. They “acquihired” us as subject matter experts, and paid us a small fee for the intellectual property. We returned something like 40 or 45 cents on the dollar to our investors. Not a great result, but about par for the course. Most startups fail. Some of our Summer 2015 cohort flamed out faster, or more spectacularly. One of our investors commended us for our ethical behaviour – not everyone returns the money. It’s been almost ten years. After we got hired, Microsoft bought GitHub. I’m still with that amazing girl. We have two kids, a house. I’m transgender now. It turns out that I like women so much I’d like to be one of them. Or as close as I can get. I’m happier now, more joyful. I feel in touch with my body, and how I move through the world, in ways I didn’t before. Up until very recently, very few people would confuse me for a woman. It took me a while to remove my facial hair, I still haven’t trained my voice. That’s OK. What is a woman, exactly? I don’t know. I don’t want to make anyone uncomfortable. For that reason, I like to say that I am “non-binary trans femme”. It’s a mouthful, I know. But asking to be called “they” feels less burdensome, less of a polite fiction, than to ask to be called “she”. I just want to be treated with respect, and kindness. I don’t think I’m asking for much. Why is it wrong for me to have more joy in my life? I’m not hurting anyone. A few days ago, Paul Graham published an essay on “Wokeness”. I skimmed it. I couldn’t finish reading it, it made me too upset. It came a few days after Mark Zuckerberg announced he was going to increase the hate speech people like me receive. It’s not OK to imply someone has a mental disability – unless it’s because they’re queer. He also quietly removed some trivial accomodations he had made for his transgender employees.1 That stung. That felt personal, targeted. I’ve been feeling quite anxious ever since. It feels like the world is crumbling around me. I’m still not sure what pg thinks “Wokeness” means.2 I know for a fact, that for most people – including many of the people he hangs out with – it just means “left-wing thing I dislike”. I got the impression that he thinks it’s bad, and that companies should purge people who are too woke. Maybe I’m being unfair to him. The irony is I too dislike nagging, hollow, corporate DEI exercises. In the abstract I was glad they existed3 but the insincerity was palpable. Are “identity politics” just a status game that economically advantaged elites play? I could be convinced. In the 2021 novel “Detransition Baby” the author shares a joke. Transgender women only have one of three jobs: computer programmer, aesthetician, prostitute. It’s an old joke. More of an observation, really. The director of “Vestidas de Azul”, a 1983 documentary about trans women in Madrid, had hoped to make a movie about trans women who were lawyers or held important roles in society. Instead he discovered that most trans women were forced to be artists, hair dressers, or sex workers – so that’s who he made his movie about. I’m glad I can be a computer programmer; no one gets to be an artist anymore. If you haven’t met many trans women, that might sound over-the-top, hyperbolic. But for so long, people like me were strongly discriminated against. Until very recently, we were treated as bywords for freaks, or psycopaths. In this vein, the other day I saw a scorching, sizzling hot take on Mastodon that read something like: the reason why conservative women are so mad about trans women is because they don’t want to share washrooms with the sex slave caste. The reason why pg’s essay made me so upset, made me feel so dispirited, is because I benefitted directly from his largesse, from a system he set up. His “school” took a chance on me, taught me how to hustle, how to become a Princess of the Universe. I’m immensely glad for the opportunity. Would I receive it again today? In many people’s imagination, the word “woke” invokes someone exactly like me. I’m the person who is annoying about their pronouns. I’m the person who feels more comfortable using gender neutral bathrooms.4 I have a passing interest in social justice. I’m concerned he, or rather, the people who succeeded him, would take one look at me, and decide that I am “too woke”, whatever that means. I worry that my existence, that my living in joy, in a state of grace, is “too woke” to be worth employing. I’m certain he wouldn’t be rude to my face, but he might quietly discriminate against me, say no thanks. He might not even think of it as discrimination, only that I don’t have what it takes. Whatever that means. I think this is why the current turn in the industry is so unsettling. It’s mean, and unkind. It’s malicious. Moves like Mark’s, and essays like pg’s, create the permission structure for people to discriminate against me. I’ve already been pushed out of Twitter; the hate speech and censorship was too much to deal with. A lot of people feel that treating someone like me with respect is just a trendy moral fashion.5 Will my next promotion be silently denied? Will a coworker try to disrespect me out of spite? Will I be shut out of big tech? Will anyone invest in my next startup? I’m better at my job than most. I’d be a better startup founder today than I was in 2015. None of that will matter. It feels as if people like pg, or at least people he hangs out with, who once upon a time believed in me, who lifted me up, recognized my talent, would now prefer that I be relegated to the sex slave caste. It hurts. As reported by the nytimes, That same day at Meta’s offices in Silicon Valley, Texas and New York, facilities managers were instructed to remove tampons from men’s bathrooms, which the company had provided for nonbinary and transgender employees who use the men’s room and who may have required sanitary pads, two employees said. Why go out of your way to remove them? Do tampons drain your masculine energy? ↩ He does provide a definition: an aggressively performative focus on social justice. Who decides what is a “performative” focus? That seems to be the question. All sorts of things are a “performance”, cf Judith Butler. Artifacts – our art, our technology, our material culture – express politics, cf Langdon Winner. Racism is bad, but you musn’t be annoying about it? It’s incoherent. ↩ A small minority of people really do need to be taught how to be kind. ↩ In bathrooms, sometimes men flinch when they see me, afraid that they walked in through the wrong door. In an airport, it can be charming, affirming even. In a bar with drunk people, it can be scary. ↩ Some frame this as the “aggressively conventional-minded” shutting down free inquiry. I ask you, is there anything more “aggressively independent-minded” than being gender-non-conforming? ↩ # 2025-01-16",
    "commentLink": "https://news.ycombinator.com/item?id=42767507",
    "commentBody": "I Met Paul Graham Once (okayfail.com)336 points by DamonHD 7 hours agohidepastfavorite189 comments afavour 2 hours agoIn the long run I think realizations like the authors are healthy ones. PG is not a hero. He's just a guy. A guy who entered into business transactions with a number of people, many of whom benefitted greatly (as did Paul himself). I'm not saying any of that as a negative! Just that we have a habit of attributing superhuman characteristics to folks (Obama getting the Nobel Peace Prize comes to mind) and ending up disappointed. I'm not an affected group by any means but I still share the disappointment in the world we see today vs the possibilities I felt tech would allow when I was younger. The tech CEOs I previously viewed as visionaries now just look like a new generation of socially regressive robber barons. I wanted to be one of those CEOs, these days I'm still not quite sure what I want to be. My only consolation is knowing that I'm seeing the world more accurately than I once did. reply lisper 1 hour agoparent> He's just a guy. A guy who entered into business transactions with a number of people Unfortunately, that's not true. He is also a well-read and influential essayist. He wields power and influence through his words as well as his money. reply Nevermark 30 minutes agorootparentHe also frames himself, accurately I believe, with his essays and the enabling-of-others nature of his successive accomplishments, as someone who genuinely values winning by helping others win. But frustration can over simplify issues for all of us, at some point. And power dulls sensitivity to those with less of it. reply 11101010001100 1 hour agorootparentprevNot mutually exclusive. reply lisper 57 minutes agorootparentThe word \"just\" in the GP implies that the author did intend for them to be mutually exclusive. reply mort96 53 minutes agorootparentNo, the word \"just\" in \"He's not a hero. He's just a guy\" indicates that he's not a hero. \"Just\" applies to the \"just a guy\" part, not to the \"entered business transactions\" part. reply atoav 1 hour agorootparentprevEven if your essays win you a Nobel price (Paul Grahams certainly didn't) the writer isn't protected from becoming a bullshit-dispenser. This is why I respect authors that publish a consistent level of quality more than those who hit and miss as if they were throwing darts at a map. And the stuff I have read from Paul Graham is definitly not in the former category. I don't feel he is intellectually honest, either with himself (bad) or with his readers (worse). But if the past decade of the Internet has shown anything, it is that honesty and consistency isn't required to get insecure people to follow you blindly. reply ryanjamurphy 26 minutes agorootparentWould love to hear a few of the consistently-high-quality writers you're thinking about. I have a pet theory that volume is required for quality, but would love to be wrong so that I can feel less bad about how much I publish! reply bobosha 1 hour agoparentprev>My only consolation is knowing that I'm seeing the world more accurately than I used to. also known as growing older ;-) reply afavour 1 hour agorootparentFor sure. I almost included something in my comment about \"I guess this is what getting old is like\", losing your idealism as you age. But equally, maybe not. If I'd grown up in, I dunno the 60s? I would have witnessed enormous leaps in technological possibility and enormous increases in standards of living, personal freedoms, yadda yadda. In my youth it felt like there was a viable future where tech enabled radical positive changes in society. Instead we concentrated wealth at the top of society at historically unprecedented levels. reply guelo 1 hour agorootparentprevAt the end of the essay he says \"I’d be a better startup founder today than I was in 2015\" and my thought was, yea but YC is biased towards college kids. And then I saw your comment and I think something clicked for me. But maybe the ignorance and pliability of youth really is required to make the crazy bet on the startup dream. reply rexpop 57 minutes agorootparent> pliability of youth Not entirely dissimilar to the exploitation of eg college athletes. reply duxup 1 hour agoparentprevI feel like the best advice is to take the ideas, even principles you like from folks and run with that. That's it. I still like a lot of what Steve Jobs had to say at times. I do not pretend to know what he was like IRL or if I would even like him ... doesn't matter. Truth be told folks who take those ideas and principles from others and not carry the weight of those folks as idols, might even do better with them. reply hn_throwaway_99 59 minutes agoparentprev> I'm not an affected group by any means but I still share the disappointment in the world we see today vs the possibilities I felt tech would allow when I was younger. The tech CEOs I previously viewed as visionaries now just look like a new generation of socially regressive robber barons. I wanted to be one of those CEOs, these days I'm still not quite sure what I want to be. Upvoted because I couldn't describe better how I feel if I tried. There were so many of these tech leaders who I looked at with such awe, and a lot of it was because they did have a set of skills that I didn't and that I really envied (namely an incredible perseverance, amount of energy, and ability to thrive under pressure, while I was often the reverse). So it's hard to overstate how disappointed I am with people (and really, myself for idolizing them) whom I used to look at with such admiration, who now I often look at with something that varies between dissatisfaction and disgust. But I realized 2 important things: the same qualities that allowed these leaders to get ahead also figures in to why I don't like them now. That is, if you care too much about other people and what they think, it will be paralyzing in the tech/startup world you do have to \"break some eggs\" when you're doing big things or trying to make changes. At the same time, this empathy deficit is a fundamental reason I think of a lot of these guys and gals (it's usually guys but not always, e.g. Carly Fiorina) as high school-level douchebags now. Second, it's allowed me to have a higher, more compassionate vision of myself. I used to feel bad that I wasn't as \"successful\" as I wanted to be, and while I do have some regrets, I'd much rather be someone who cares deeply about my friends and family and really wants to do some good in the world, as opposed to someone I see as just trying to vacuum up power and money under the false guise of \"changing the world\". reply ethbr1 1 hour agoprevGreat, cohesive, and clear essay! Hear hear. One thing that I think is underappreciated in our current times, that gets lost on both the left and the right sides an individual is more important than their identity. A specific trans person can also be an asshole. A specific white man can also be a saint. Extremists on both political sides will scream about the reasons one or the other of those statements is wrong, but doing so lumps all possible individuals of an identity into a \"them\" category to which blanket statements, positive or negative, can be applied. That reductionism feels incredibly insulting to our shared, innate humanity. Are there all kinds of subconscious and societal biases that seriously influence our perceptions of others on the basis of their identity? Sure! But it doesn't change the goal of treating the person standing in front of you, first and foremost and always, as an individual person. Be curious. Be courteous and respectful. Be a normal, nice goddamn human to human across the table from you. (And maybe, if you feel so inclined, have some compassion about what they did to get to that table) reply gedpeck 1 hour agoparentBe curious. Be courteous and respectful. Be a normal, nice goddamn human to human across the table from you. In general I wholeheartedly agree. But if the person in front of you has done or advocated for things that cause harm or is themself a horrible person then I disagree. reply hnthrowaway6543 1 hour agorootparent> But if the person in front of you has done or advocated for things that cause harm or is themself a horrible person then I disagree. the current conflict in the middle east shows why this doesn't work in the long run. despite what a generation that grew up consuming Marvel films was led to believe, not every conflict is a clearly defined superhero-vs-supervillain, good-vs-evil affair. eventually, you will be the one who, according to some, is advocating for things that cause harm and is considered a horrible person. reply beardedwizard 1 hour agorootparentVery underrated comment. Right and wrong are largely a function of culture, not universal law. reply gopher_space 53 minutes agorootparent> Right and wrong are largely a function of culture, not universal law. Sure, but then you're handwaving away questions about why cultures align along similar axioms. reply hnthrowaway6543 43 minutes agorootparent> Sure, but then you're handwaving away questions about why cultures align along similar axioms. there's a lot of reasons, but it doesn't make someone with a different opinion due to their culture a horrible person and not worthy of respect. as a concrete example, let's take gay marriage. on a site like HN, i expect people here to be supportive. on the other hand, the vast majority of Africa, the Muslim world, and Asia do not support support it. according to gedpeck, nearly everyone in Africa and Asia, and every single practicing Muslim, is a horrible person... which sounds pretty bad when it's phrased that way, doesn't it? reply gedpeck 1 hour agorootparentprevMost definitely. Each person decides for themselves where the lines are drawn. reply Suppafly 59 minutes agorootparentprev>In general I wholeheartedly agree. But if the person in front of you has done or advocated for things that cause harm or is themself a horrible person then I disagree. I feel like the parent comment is pretending to be deep and meaningful but is really just rehashing the 'both sides are the same' argument with a side of 'everyone is entitled to their own opinion'. It's nice to say that we should judge everyone for who they are, but if who they are is a vocal member of a group that wants to hurt other people, that's all we need to know to judge them. Pretending otherwise is silly. reply ethbr1 37 minutes agorootparentThe difference is between judging an individual for what they themselves say vs what identities you associate with them (or even those they associate with themselves). reply Suppafly 30 minutes agorootparent>or even those they associate with themselves I see no problem judging someone for the identities that they choose to associate themselves with. reply ethbr1 18 minutes agorootparentOver and above their works and words? reply Suppafly 11 minutes agorootparentTheir associations are their works and words. You can't just handwave that stuff away as being irrelevant because you like the parts of their works and words that don't touch on anything you deem to be an association. reply mecsred 1 hour agorootparentprevThen you don't agree at all. Every single adult in the world has \"done or advocated for things that cause harm\". It's inescapable. reply femiagbabiaka 1 hour agorootparentIt’s like.. incredibly escapable. Nihilism makes for a weak argument reply gedpeck 1 hour agorootparentprevGreat harm then? I’m not morally obligated to to treat Putin with respect. Most people agree that there are people who are so reprehensible that they don’t deserve respect. reply haswell 1 hour agorootparentThere are obvious bad/evil actors in the world. When people talk about engaging with other humans respectfully, they're generally not referring to the Putins of the world. And it's pretty rare to have so much clarity about a person to know they're in the \"obviously reprehensible\" bucket. I'm not saying this is what you're doing, but I often see people argue like this: 1. There are obviously bad actors in the world 2. Nobody would argue those bad actors should be given respect 3. So I won't respect people I come across who disagree with me The fallacy is in the jump from 2 to 3, and the assumption that the existence of bad actors means the person I'm interacting with right now is one of them. The vast majority of people aren't Putin, nor can they be judged so quickly/clearly. And setting aside whether or not someone like that deserves respect, there's also a clear difference between respecting someone for who they are vs. behaving in a respectful manner out of self-preservation. The latter may ultimately keep you alive. reply gedpeck 1 hour agorootparentHerein lies the crux of the matter in my view. The jump from 2 to 3. When Bob Dole ran for President I wholeheartedly agreed with the position about being respectful to those you disagree with. Politics was still normal in the U.S. at that time. But now we in the U.S. elected a known rapist. A felon and a con man. He can’t run a charity in New York due to his misdeeds. He lusts after his own daughter. We have entered into an era where supporters of one party’s President deserve the assumption of being terrible people. Now obviously there are many people who disagree with the above. But this is how I see things and I act accordingly. The call for civility comes from those who hold terrible beliefs. We are well into the Paradox of Tolerance situation in the U.S. reply haswell 41 minutes agorootparentTo me, the issue boils down to pragmatism and utility. It’s just human psychology; people tend not to change their minds when someone screams at them and otherwise disrespects them. If the goal is to move society in any particular direction, that requires some degree of successful communication, and throwing respect out the window directly counteracts the goal. If the goal is just to hold some moral high ground for the sake of it, that’s a pointless goal if it doesn’t lead to any underlying change. Collectively, we don’t need to change the minds of obviously evil people, but we do need to influence the population that can vote them into or out of power. I just don’t see that ever happening if your outlook on life is this extreme: > We have entered into an era where supporters of one party’s President deserve the assumption of being terrible people I know many people have convinced themselves that this is true, but this ultimately boils down to the question: so what then is the goal? To push these people deeper into their bubbles? At some point one has to ask how much of the problem is being directly created by this “they’re all terrible people so I won’t even talk to them” mindset. reply gedpeck 26 minutes agorootparentMy personal view is as follows. American society has reached a point of no return. Something has to give before a new equilibrium has been found. As an extreme example look to Nazi Germany. The repugnant views that were normal in 1939 Germany weren’t normal in 1960 Germany. A similar (though far less extreme) change will happen in the U.S. I have no desire to change anyone’s mind about their political views. Anyone who supports a known rapist and felon and who openly takes bribes can not be convinced of anything. I don’t engage in political discussions with such people. There is no consistency in their beliefs so no meaningful discusion can be had. For me, my desire is secession. The country needs to beak up. This is an extreme view but will likely be increasingly held by people with similar political beliefs as mine. reply hnthrowaway6543 53 minutes agorootparentprev\"over 50% of the country i live in are irredeemably terrible people\" is obviously hyperbole if it were true, the onus would be on you to start taking action against those terrible people. but my guess is you don't actually think they're so terrible, because you're still working your 9-5 for your terrible-person boss, getting paid like every other schmuck, and you're happy to let those irredeemably terrible people deliver your DoorDash, teach your children at public school, and keep your electricity and water running. reply gedpeck 36 minutes agorootparent\"over 50% of the country i live in are irredeemably terrible people\" A large majority of the people did not vote for Donald Trump. but my guess is you don't actually think they're so terrible, People who support Donald Trump are, in general, terrible people. They aren’t evil people doing evil things so why would I have an obligation to take action against them? It is a fact of life that we all must live amongst people who we think are terrible human beings. Of course I haven’t the slightest idea what a person’s views are for almost everyone I interact with. I give everyone the assumption that they deserve respect until proven otherwise. Given the context of the thread it’s ironic that you don’t seem to understand what it means to give the assumption of respect to people. I think you edited your disparaging remarks to me. It was hilarious to read those remarks given the context of the discussion at hand. Feel free to put them back. I don’t mind them. reply ethbr1 1 hour agorootparentprev> The call for civility comes from those who hold terrible beliefs. Oof, that's a lot of assumption. reply ethbr1 1 hour agorootparentprevFair, but in our current times using someone's identity as a justification to act like an asshole to them is a sith's whisper. We all have our less enlightened moments. Better we not afford ourselves easy intellectual justifications for being our worst selves. As the quip goes: the greatest evils are perpetrated by those most assured of their own righteousness. Edit: Or in video form. Beginning summary: \"brick suit guy\" was apparently an extremely aggressive heckler of the media at Trump rallies. https://m.youtube.com/watch?v=fRSIv7alUZ8&t=95s reply gedpeck 1 hour agorootparentIn normal times I would agree with you. At present in the U.S. I’d not agree with this sentiment. People who support electing a known racist, thief, con man, and felon are deserving of ridicule and ire. They don’t deserve respect in my opinion. When the politics of a nation shift so far in one direction we get into a situation where supporters of that shift don’t deserve respect. Stalinist Soviet Union is an extreme example of this. reply ethbr1 1 hour agorootparentSo what lengths do you think you're justified going to against individuals you disagree with? And how do you feel about them feeling the same about you? Mutual righteous hostility is why ethnic and religious wars simmer forever, because there's always a convenient justification for acting violently towards others (and them towards you). reply gedpeck 48 minutes agorootparent… justified going to against individuals you disagree with? I don’t do anything at this time. But I understand why there are those who do have vitriol for supporters of a rapist who lusts after his own daughter. There are times when a nation’s society fractures as the social cohesion evaporates. We are beginning to be in such a time the U.S. Well, it appears that way to me. Only time will tell. reply CivBase 29 minutes agorootparentprevWhat constitutes \"harm\"? Is hurting someone's feelings harm? Is misinformation harm? How do you determine intention? To what extent does intention matter? How do circumstances impact the answers to these questions? When your creed is basically \"I only hate bad people\", you have given yourself permission to hate anyone and feel righteously justified about it. And you'll never feel the need to empathize because bad people always deserve whatever bad things happen to them. You don't need to love everyone unconditionally, but clearly more neuance is needed. reply gedpeck 22 minutes agorootparentWhat constitutes \"harm\"? Is hurting someone's feelings harm? Is misinformation harm? How do you determine intention? To what extent does intention matter? How do circumstances impact the answers to these questions? I know the answers to these questions…for me. Each person decides for themselves where the lines are drawn. It has always been this way. reply 01HNNWZ0MV43FF 1 hour agoparentprevI'm so tired of hearing \"both sides\" though. reply tiffanyh 34 minutes agorootparentI think your point is what gets missed in this conversation. Many people just want to go to work and do their job … and not have social topics or politics discussed at work. That doesn’t mean they don’t care about those topics, they just don’t feel like work is the correct place for discourse. And the sense I get from recent moves by tech execs is that they simply want employees to focus 100% on work (because obviously they want to get the most productivity out of their paid staff), and anything non-work related is viewed as a distraction. Regardless of what that non-work topic might be. reply layer8 1 hour agorootparentprevFocusing on the individual means dropping the notion of “sides”. Identifying people (or even arguments) by their alleged “side”, instead of taking them on their own merit, is where things go wrong. reply watwut 1 hour agorootparentWhere things go wrong is that the \"extremists on both sides\" is used to distract from what people on one side do. It is just a shield designed to prevent analysis. reply ethbr1 1 hour agorootparentIt's not, because there's a difference between 'extremist individuals in a side' and 'a side as monolith.' It is currently en vogue to use the excesses of specific instances or individuals to tar entire identities, but that's statistically dishonest. Most people are not extremists, in the sense of 'if you talk to them at 1:13pm on a random Tuesday.' reply watwut 48 minutes agorootparentThere is actual political program and actual laws being pushed on. That is the reality. And yes, that political program belongs to that side. It is OK to blame republicans as such for what Trump or JD Vance does, because they made them big. It is ok to blame them for the for the supreme court politics too, because they knowingly put exactly those people there, knowing they will remove protection for abortion and lied about it. It is OK to blame democrats for what Biden does. For the both sides thing however, you need to attribute acts of people who Democratic party actively pushes away to that party ... and to pretend that people voting for republicans have zero to do with what that party does. reply ethbr1 21 minutes agorootparentI think about it with different divisions. For politicians (as opposed to people in other professions), they are obviously responsible for the policies their parties support, to the extent that they support their parties. Given not every politician votes in lockstep with their party. BUT for individuals in the US, their personal positions are often more complex than the binary reductions the two-party system affords us. Consequently, there are many (most?) dissenters on one issue or another in both parties. If a person has thoughts on matters, it's therefore more interesting to me to discuss those thoughts, than to derive my interactions with them solely by their D or R label. reply timeon 1 hour agoparentprev> gets lost on both the left and the right sides It gets lost because of this black/white US perspective on politics. If you were multiparty system there will be less identities in politics. reply ethbr1 1 hour agorootparentAlso, diffusing the bully pulpit and celebrity between a president, prime minister, and/or ceremonial royalty. Policy > popularity. reply whack 1 hour agoprevI appreciate the author and this article. As an immigrant and person of color, the author's concerns resonate with me. I don't think people like PG or Andreessen are evil bigots. But they are underestimating and enabling a movement that is cruel and exclusionary by design. A movement that they seek to tame and harness, but not understanding that the movement is fundamentally untameable. I miss the days when the Republican party was led by a President like Bush, who told America that Islam is a religion of peace. And nominees like McCain, who told his supporters that Obama is a decent family man, and a natural-born American. I worry for the future, and my children's place in it. reply arp242 38 minutes agoparent> I miss the days when the Republican party was led by a President like Bush, who told America that Islam is a religion of peace At the same time he also said that if you don't agree with him, you're with the terrorists. I do agree that Bush went out of his way to not stigmatize Muslims or Islam, but \"don't be a flaming racist\" is not that high of a bar to meet, and he was very much not a moderate open to nuanced views (on this topic, and various others). Never mind stuff like Iraq. Similarly, McCain defending Obama against baseless racist attacks was not that high of a bar to meet. McCain was also a standard GOP senator during the \"obstruct whatever Obama does at all cost\" years, never mind how he tried to appeal to the crazy Tea Party fanbase with Palin. I don't entirely dislike the man by the way – I'd say his legacy is mixed and complex. I guess what I'm trying to say is: don't look at it the past too rose-coloured. The current mess didn't spontaneously come to exist out of nothing. People like Bush and McCain made a pig sty of things, and then were surprised pigs turned up to roll around in the mess. The old \"gradually and then suddenly\" quip applies not just to bankruptcy. reply rchaud 42 minutes agoparentprevWhile I understand the point you're making, I am surprised by the examples you chose. What Bush's speechwriter wrote, did not stop Bush from authorizing torture stations across the world, murdering hundreds of thousands of Muslim civilians in two failed military occupations, while weakening America vis-a-vis Russia and China, a confrontation that has dominated the past several years. Do not mistake public statements as any indication of actual policy. As for McCain, his words were \"No Ma'am, he is not an Arab, he is a decent family man\", which I suppose is addressing misinformation with a decisiveness Republicans wouldn't dream of today. reply inglor_cz 40 minutes agoparentprev\"who told America that Islam is a religion of peace\" This is something I considered a brazen lie in the interest of stability. I believe in existence of individual peaceful Muslims, but I don't believe in inherent peacefulness of a religion founded by a warrior who converted Arabia by the sword and which had since seen an endless series of holy wars initiated in the name of Islam. You can't really build societal understanding on a foundation of such misinformation. To be clear, Christianity and Judaism aren't \"religions of peace\" either. Some explicitly anti-militaristic sects like the Amish maybe. But the Abrahamic faiths as such, no. reply selimthegrim 15 minutes agorootparentTo pretend that every Muslim area in the world was converted by the sword is just totally unsupportable reply inglor_cz 6 minutes agorootparentI haven't said that every Muslim area in the world was converted by the sword. But Muhammad led a lot of wars, in which thousands died. Which is fairly untypical among the founders of currently widespread religions, though the Old Testament heroes like Joshua can be categorized into a very similar slot. reply andrewflnr 2 hours agoprevYou should have finished reading PG's essay. It's really quite narrowly scoped. There's no indication I could see that he doesn't still hold the same basically liberal politics (he included explicit disclaimers, for all the good that did); he might still be fine with transgender identity. He just wanted to talk about how the particular loudmouth brand of annoying leftist came to prominence. He even had a decent definition of them beyond \"leftist I don't like\", and put them in a broader context. Even in the HN thread on the essay, it felt like hardly anyone actually read and understood it, just brought their own assumptions and intellectual allergies and let them run wild. It would be great if people could discuss these issues rationally, but the vast majority can't. Everyone is on a hair trigger. reply r0p3 1 hour agoparentIt is not narrowly scoped, it states that we need to stop another \"wave\" of \"social justice piggishness\" which would include challenging the gender identity framework the author is using among other things. It also makes broad claims about social justice politics writ large. Having read it carefully I found the hn thread interesting and it correctly criticized the essay's lazy reasoning. reply runjake 1 hour agorootparentUnless pg just now edited it out, you're making false quotes and misrepresenting his words. I cannot find the quote \"social justice piggishness\" or the word \"gender\" in his essay. Every single mention of the word \"wave\" is attached to \"wave of political correctness\" or a close variation thereof. Edit: OP meant \"priggishness\". Got it. reply rexpop 52 minutes agorootparentIt's a typo. Paul's term is \"priggish\". And \"political correctness\" is a broad brush euphemism for, among other things, genderqueerness. reply runjake 41 minutes agorootparentThanks for this. I've always considered PC an entirely different thing, but after perusing the comments here, and given our new president's attitude toward the people affected, I can see your point. reply carabiner 54 minutes agorootparentprevI don't think pig and prig mean the same thing. reply michaelt 1 hour agoparentprev> It would be great if people could discuss these issues rationally, but the vast majority can't. Everyone is on a hair trigger. If only we in the tech industry could blame social media on anyone but ourselves :( reply andrewflnr 1 hour agorootparentAre you sure? How many of us in tech actually made decisions that made social media how it is? How many of us were even complicit in implementing it? I wasn't. Most of \"tech\" is not social media. Now how many of us were sounding the alarm and trying to build alternatives? I don't think we should put all the blame on social media anyway. reply netsharc 1 hour agorootparentprevMy startup idea is a iPhone/Android virtual keyboard that detects the user is writing something toxic, and refuses to cooperate. Using AI. Who wants to fund me? My other idea is a video/audio communication app that mutes the user if they become toxic. Yes, I'm only joking. I wonder how many will be triggered and foam about \"But who determines what is toxic!?!\". That makes me think about the joke about feminists where the setup is \"I have a joke about feminists...\" and punchline is someone from the audience yelling \"That's not funny!\" straight away. reply oxguy3 1 hour agoparentprevFrom the essay: \"Consumers have emphatically rejected brands that ventured too far into wokeness. The Bud Light brand may have been permanently damaged by it.\" What Bud Light did was hire an influencer to promote their product in an Instagram video (and then of course they later backtracked). The only thing \"woke\" about the video was that the influencer was a trans woman. If Paul Graham would like to elaborate on this passage meant I welcome it, but my read was that supporting a trans woman falls under his definition of \"wokeness\". reply notahacker 34 minutes agorootparentIndeed. I mean, an article on censorious \"priggishness\" could have easily picked outrage mobs boycotting brands over deeming a trans person worthy of association as evidence that the \"woke\" people didn't have a monopoly on self righteousness and censoriousness. Instead, he effectively endorsed the position that trans people were \"woke\" simply for existing and the consumers cancelling them had a point. reply didiop 27 minutes agorootparentBetter than endorsing Dylan Mulvaney's regressive and misogynistic \"Days of Girlhood\" act. A boycott was the right thing to do. reply agent281 44 minutes agoparentprev> Even in the HN thread on the essay, it felt like hardly anyone actually read and understood it, just brought their own assumptions and intellectual allergies and let them run wild. It would be great if people could discuss these issues rationally, but the vast majority can't. Everyone is on a hair trigger. I think the essay was a rorschach test for readers. On its face, it has a very reasonable and measured tone. It also has some nods to the other side like the disclaimer you mentioned. However, it starts from some uncharitable premises (e.g., its definition of wokeness) and contains unnecessary gibes (e.g., against social sciences). More importantly, it takes the tone of a social sciences essay, a discipline that he mocks, without any of the rigor. There are not sources for his claims about the origins of wokeness or how universities operated from the 80's until today, you just have to take him at face value. It gives the illusion of being erudite without doing any of the actual work. reply hn_throwaway_99 42 minutes agoparentprevI'm too lazy to search my comment history, but I wrote a comment on the original post about pg's essay that I did pretty much agree with what pg wrote, and so consequently I agree with most of what you wrote. But that said, I definitely could not ignore the timing of pg's essay, and it felt plain gross to me. It felt like a lazy, convenient pile-on at that moment, even if pg's position had been largely consistent for a long time. I've seen all these tech leaders now lining up to point out the problems of the left (again, a lot of which I agree with), so where is the essay about the embarrassingly naked grift of the POTUS launching a ridiculous and useless meme coin just before his inauguration? Also, there was nothing in that essay that I felt was particularly insightful or that I learned much from. It was, honestly, some bloviating pontification from someone who I now think holds his ideas in much higher regard than they deserve. reply spokaneplumb 1 hour agoparentprevThis one’s footnote #2 addresses PG’s definition of “woke”, which I agree is useless (I’d go further: that kind’s so inconsequential that it’s nonsense to bring it up unless you’re using those complaints to attack other actions that do maybe have some justification, using the definition as cover to retreat to if called out; if that’s actually the only part you’re complaining about, just don’t write the piece, everyone already dislikes that kind for the same reasons you do) reply natch 1 hour agorootparentWhat is “that kind” referring to? That kind of essay? The first essay? The response essay? That kind of definition? The author? Which author? That kind of person who is aggressively performative? If by “that kind” you mean that last definition, then let’s take one example in that happened recently and address your claim that “that kind” is inconsequential. Undemocratically, performatively, anointing behind closed doors a weak but social justice signaling candidate to run on the democratic ticket in the recent US election, seems to have been just a wee bit consequential. reply spokaneplumb 1 hour agorootparent> Undemocratically, performatively, anointing behind closed doors a weak but social justice signaling candidate to run on the democratic ticket You’re just stringing together bingo-card words. I don’t think this is going to be a productive exchange, so I’ll leave things where they stand. reply BearOso 1 hour agoparentprevThis is exactly the thing the essay seems to be complaining about. It's not the ethics of equality being targeted, it's the moral hypocrisy. People put on a false front with offensive messaging claiming support of these groups, but the whole purpose is to build clout or benefit themselves. They don't care about the message at all. Messages like \"I support lgbtq, and if you don't you're a bigot,\" are self-aggrandizement. \"I support lgbtq,\" is all that's needed if you want people to know they are supported. No one needs to hear it at all if the discussion isn't relevant. Just try to treat everybody with respect. reply jlebar 1 hour agorootparentYour argument is, \"Don't say 'I believe X and if you disagree with me you're bad'. Just say, 'I believe X.'\" But then literally in the same sentence, you say, \"If you do the thing I don't like (in this case, calling people bigots because they don't support lgbtq) *then you are self-aggrandizing.\" \"Nobody should be called a bigot for their views on lgbtq, but it's virtuous to call people self-aggrandizing for calling people bigots.\" Either name-calling is okay or it's not. You can't have it both ways. reply jl6 29 minutes agorootparentYou can argue hypocrisy or about the way the argument is presented here, but it’s beside the point. Saying “there is only one correct opinion on this matter and if you disagree then you’re a bigot” is exactly what is driving people to oppose those opinions, regardless of whether they are correct. It’s just a really, really poor move, in terms of rhetorical strategy. reply netsharc 1 hour agorootparentprevRe your last paragraph: I feel I'm quite left, but it feels like a lot of these activists are busy trying to make enemies out of everyone, which makes me think \"I'll just shut the hell up\" and, if I ever get confronted as being a part of the enemy class (I'm a heterosexual male, get the pitchforks!) , I'll just point out, \"if you don't want me as your ally, then hey, no worries, I can be your enemy.\"... reply ZeroGravitas 26 minutes agorootparentHave you heard of or witnessed someone who was confronted as part of the enemy class just for being a straight male? Where are you going that you need a contingency plan for this situation? Are you expecting this in a work situation, on a campus maybe, or just walking down the street? reply BearOso 58 minutes agorootparentprevThat's how I feel. Everyone always has to have an \"us vs them\" methodology. Like you have to take sides. No thank you, I'm apathetic to the situation. I'm not going to deliberately make life worse for anyone or support it. reply skywhopper 1 hour agoparentprevThe mere fact that pg takes the word “woke” seriously tells me he’s fallen for the right-wing doublespeak where they take a word vaguely related to left-wing ideals, pretend it means something else, apply to anyone center-right or leftward, and get the mainstream media and self-conscious centrists like Paul to accept their intentional distortions at face value. This pattern happens again and again with words and phrases like “liberal”, “socialist”, “Black Lives Matter”, “critical race theory”, “woke”, and “DEI”. Anyone who can’t see through it is either okay with the distortion, or not as good an observer as they think. reply marcusverus 48 minutes agorootparentIt might be reasonable to disregard Mr. Graham if he were somehow abusing the term \"woke\", but it seems wrongheaded to disregard him due to \"the mere fact that [he] takes the word \"woke\" seriously\". reply watwut 1 hour agoparentprev> He just wanted to talk about how the particular loudmouth brand of annoying leftist came to prominence. Nah, this is just not true about that essay. This is sort of excessive \"lets twist what people say with maximum leftist spin so that we can paint everyone who disagree with them as crazy\". It is getting repetitive, tiresome and amounts to a massive amount of online gaslighting. Center and left are all supposed to pretend that everyone is leftist just concerned with some extremists, no matter how much it is clear it is not the case, unless someone actually supports nazi party ... and sometimes even longer. That essay did not even cared about actual history of events either. reply klik99 1 hour agoparentprevYes this is exactly how I felt about the \"Wokeness\" essay. I am constantly afraid that PG is gonna fall down the same strongly right rabbit hole so many of his colleagues have, and he hasn't so far, so seeing the title of the essay was worrying. When I read it though, I realized he was just using \"wokeness\" to mean the dogmatic surface level understanding of the subject (IE, not that he was being surface level, but he's talking about people who engage with equality/identity issues in a surface level way). It's kind of a strawman idea, but people like that exist and are annoying. It makes me wonder how many people who are really centrists hate wokeness because they think the most annoying wing of it is representative of the whole movement. Reading PGs article, I get the sense of someone who doesn't fully understand the thing he's criticising, so makes me hopeful he can learn. But again, I'm always a little afraid that the legit criticizisms of his article will get drowned out by people who reinforce what he says in it. reply pbiggar 1 hour agorootparentPG feel down that rabbit hole years ago. He was one of the very first people posting aggressively about \"free speech on campus\" in the 2012ish era. It was obvious to everyone I knew at the time that \"free speech on campus\" was right wing propaganda to platform hate speech, with folks like Milo and Ann Coulter. Where we are today with Trump, and his marginalization of immigrants and LGBTQ+, came directly from that. Does PG know he did this? Hard to say. But he's still platforming right wing views for his centre-right-but-thinks-theyre-left audience. reply snowwrestler 1 hour agoprevOnce upon a time, not that long ago, within my lifetime in fact, being gay was targeted for public abuse the way that transgender people are being targeting now. That has declined as people came to understand that being gay, lesbian, bi is part of how a person is made. Under public pressure, a gay person can act straight or at least act not gay. But it doesn't change who they are, doesn't help anyone around them, and makes them miserable. There is no point to it. Thankfully popular opinion and the law have adjusted to that reality. Being transgender is the same way. A transgender person is not someone who dresses a certain way, takes hormones, or gets surgery. A transgender person is someone who is absolutely miserable when they are not permitted to express the gender they feel. It is part of who they are deep inside, how they feel every day of their life. Like gay people, they can hide it to avoid abuse. Like gay people, it's not fair to force them to do so. And it doesn't help anyone around them either. reply coderc 1 hour agoparentIt seems to me that prigs, as defined in pg's article, are just jumping on the transgender issue because it's an easy way for them to enforce rules. From my understanding, having read both articles, PG might say that the prigs have chosen to ride the lgbt movement. The problem is not with the lgbt movement itself. Unfortunately, this gives the movement a bad reputation. Some prigs aren't lgbt people at all, but they speak on behalf of them, as they also speak on behalf of other groups that they aren't a part of. Some prigs might actually be a part of the minority they speak for, but I would hazard a guess, based on no data, and say that these are the minority of all prigs. I think PG's problem is with the prigs, not the lgbt movement itself. Can these be separated? reply snowwrestler 52 minutes agorootparentSelf-congratulatory, self-righteous prigs are all over the place within human society. When people complain about them, the substantive content of their complaint is the context in which they issue it. For example pg is complaining about the prigs who nag everyone about transgender acceptance, but not the prigs who nag everyone to reject and abuse transgender people. Matters of speech, manners, and decorum are convenient ways to launder the advocacy of a certain set of values. All you have to do is accuse your enemies of violation when they advocate, and stay silent when your allies apply the same tactics. In order to consistently navigate politics, one needs to start with one's own values. That's why I posted my comment above. The core issue for me is whether transgender people can show up in their preferred gender. Not whether other people are annoying jerks when they talk about that question. There are plenty of annoying jerks on both sides of any value question, if one has the open eyes to see them. reply AnimalMuppet 0 minutes agorootparentprevThe prigs are doing a motte-and-bailey thing, where if you're against them, then they will claim that you're against trans people or gays or minorities or whoever. reply inglor_cz 34 minutes agoparentprevI agree with you about a transgender person who is 23, but not about anyone who is claiming to be transgender at 13. That is way too young to be sure of such things, and peer pressures/influences exist. The current backlash is mostly caused by the hardcore activists pressuring for \"the alternatives are either gender-affirming care or SUICIDE! SUICIDE! even for 13 y.o.'s\" This attitude is so hysterical that it cannot stand for long. reply snowwrestler 16 minutes agorootparentThere is a social movement that seeks the suppression of all transgender expression, including by fully informed adults. They led with “save the kids” for the emotional impact, as many other well-organized social movements have in the past. It works because concerns about kids are real. But it’s important to see and understand the greater goals of the movement, and how it affects everyone. The essay at the top of this HN thread was written by an adult, expressing their adult concerns. reply inglor_cz 4 minutes agorootparentIt is somewhat quaint, but the truth is often in the middle and compromises work the best. Which is something that doesn't really resonate with the social network era, which rewards wild posturing and extreme views with attention and clicks. reply _dark_matter_ 2 hours agoprevI really appreciate this article, and I would like the author to know that there are lots of people yes, especially in tech that support their happiness. reply slibhb 1 hour agoprevI thought this was better than most essays in this vein. I do fundamentally disagree with the author. People can think poorly of you for whatever reason they want. If someone hates trans people, they can, and you can't stop them. The whole \"war on hate\" thing was a bad idea; you can't forbid hatred. It predictably didn't work, and it's good that we're turning away from it. Adding on, the trans issue isn't simple. There are real questions about bathrooms, women's sports, and when medical interventions are called for. Of course, there are also just bigots. The proper response to bigots is not to banish them, ban them, shadowban them, etc. That didn't work. The proper response is in the spirit of the new era of free speech to firmly state your opposition to their beliefs. reply DeathRay2K 1 hour agoparentYou’re wrong that a so-called “war on hate” doesn’t work. More correctly, it doesn’t work in the US because of the first amendment and the few limitations on it. Many other countries have robust anti-hate speech laws that are effective, although less so in the age of the internet. People broadly conform to the society in which they live, and the rules of the society are broadly set by the laws they adhere to. So in countries where hate speech is disallowed, people conform to a less hateful viewpoint as a rule, and hateful people are the exception. In the United States, it is clear that hatred is the norm as long as it is permitted by law and by leadership. reply 331c8c71 1 hour agorootparent> People broadly conform to the society in which they live, and the rules of the society are broadly set by the laws they adhere to Well this can work very differently from what you imagine I believe. Like late Soviet Union where certain things were said in public and other things were said in private or in \"trusted environments\". For years and years... From what I hear this is in part what goes on in large multinationals where the pressure to conform is quite tangible. reply yodsanklai 1 hour agorootparentprev> it doesn’t work in the US because of the first amendment and the few limitations on it. This isn't clear to me. For instance, Meta was free to forbid hate speech on their platforms, or not to promote it in their feed algorithms. I don't think first amendment would force them to authorize hate speech. They do it to align with power in place (freely or coerced, not clear), but it's not a legal enforcement. > So in countries where hate speech is disallowed, people conform to a less hateful viewpoint as a rule, and hateful people are the exception. There are hateful people in Europe too. reply raincole 1 hour agorootparentprevGerman woman given harsher sentence than rapist for calling him ‘pig’ : https://www.telegraph.co.uk/world-news/2024/06/28/german-wom... That's what \"war on hate\" slides to. reply robmccoll 1 hour agoparentprev> The whole \"war on hate\" thing was a bad idea; you can't forbid hatred. It predictably didn't work, and it's good that we're turning away from it. This is a myopic view. You are obviously correct that you cannot legislate that someone think in any particular way or otherwise force someone to change their minds, but the idea that collectively deciding that a viewpoint is not longer tolerated within the broader society and then making efforts to support that at all levels is ineffective and not worthwhile is absurd. Threats, physical violence, and murder have always been illegal, but used to occur with much higher frequency against many minority groups toward which society tolerated hatred and abuse. It's plainly obvious what changed is the idea that it would be brushed under the rug, that others would at worst turn a blind eye to the perpetrator if not support them, that there would be no real consequences whether legal or in social circles this environment in which people act on impulse rather than thinking twice about what they're doing went away. We must remember that progress isn't permanent, that civil rights must be maintained and won't protect themselves, and that there's probably someone out there that hates someone each of us loves and cares about for some arbitrary reason and would act on that if only society gave them permission. reply otde 25 minutes agoparentprev> If someone hates trans people, they can, and you can't stop them. The whole \"war on hate\" thing was a bad idea; you can't forbid hatred. It predictably didn't work, and it's good that we're turning away from it. It is disingenuous to suggest that anti-discrimination laws for trans people are attempting to legislate away the hatred held in people’s hearts, instead of access to healthcare, public facilities, protections against workplace discrimination — things you describe as having “real questions,” but which are, in fact, the parts of a full and dignified life that bigots would deny to trans people in particular. If you pretend like it’s trying to legislate “thoughtcrime,” it’s much easier to distinguish anti-discrimination laws for trans people from rulings like Obergefell or Brown v. Board — far easier to say “look, those were good, but this particular civil rights legislation is simply unreasonable.” To platform these beliefs is to afford them a legitimacy they do not deserve. To suggest that bigotry, when amplified, will be in some way countered or reduced is naïve beyond belief. Instead, it becomes easier for bigotry to find an audience of receptive listeners and willing conduits for further transmission. reply watwut 1 hour agoparentprev> There are real questions about bathrooms, women's sports, and when medical interventions are called for. Yes there are real questions, but there are also real answers. Currently, 99% of people asking questions have literally zero interest in answers. They do not care about what research say or whether there is harm or not. They ask questions to convince the audience about their political project. They do not care about whether medical interventions are good, bad, safe or unsafe. They want to convince you that that they are unsafe. They want to stop the interventions regardless of their impact. They do not care about safety of bathrooms, they want you to punish transgender people in the wrong bathroom. They do not care about women sports either, in fact they are the same people arguing against women sports whereever it matters. > People can think poorly of you for whatever reason they want. And it should be my god give right to call them sexist and racists if they think of me poorly because of those reasons. But somehow that is supposed to be a taboo. We are all supposed to pretend there is no sexism, that there was no historical sexism, so that someone feels good about themselves. Again and again, sjws pointed out someone is sexist/racist, there was an outrage in response, they were painted crazy stupid exaggerating. And I actually believe the response, multiple times. Except that it turned out, multiple times, that they were right all along. reply Freak_NL 56 minutes agorootparentBesides, the whole bathroom thing is so old hat. You know what I hate in a bathroom? Other people. Of any gender. Thankfully, stalls have doors. I miss the days of Ally McBeal when unisex bathrooms were hip and the future. reply watwut 44 minutes agorootparentIn my local city there was conservative article about unisex bathroom putting framing it as transgender thing. The bathroom was unisex when I was a kid, when trans were universally mocked. Bathroom is unisex, cause there is exactly one toilette in a small cafe in a super old building. reply coderc 53 minutes agorootparentprevI would think that your claim about \"99% of people asking questions have literally zero interest in answers\" applies more to 'both sides' than one might initially think. Is either side open to being told \"no\", or at least \"wait, we need to be more cautious about this\"? Or do both sides just want their demands to be accepted? Would either side actually back down if the research said that what they were doing was harmful or ineffective? reply watwut 46 minutes agorootparent> \"wait, we need to be more cautious about this\"? Or do both sides just want their demands to be accepted? I think that yours \"wait, we need to be more cautious about this\" or is this just another \"I do not care about answers, I just want to pretend so\". > Would either side actually back down if the research said that what they were doing was harmful or ineffective? Research is there and it is saying current clinics were not harmful and were not ineffective. So yes, one side cares about research and the other is not. reply giraffe_lady 1 hour agoparentprevThe author isn't talking about abstract \"hatred\" in the sense of people's internal, personal experiences. They are talking about hate speech, a specific concrete act with external material consequences. > Adding on, the trans issue isn't simple. It really kind of is though. reply rexpop 48 minutes agoparentprev> There are real questions about bathrooms, women's sports No there aren't. These are frivolous questions. reply wastle 25 minutes agorootparentYours is a very typically male point of view. Female athletes having to complete against trans-identifying males tend to disagree that this is frivolous issue. As do many others. reply Arainach 1 hour agoparentprev>The whole \"war on hate\" thing was a bad idea; you can't forbid hatred You can't forbid it but you can absolutely make it socially unacceptable. \"Free speech\" doesn't mean letting people spew hate and doing nothing; choosing not to hand them a megaphone, support their business, etc. is entirely valid. reply ThrowawayR2 1 hour agorootparentIt became so socially unacceptable that its proponents won the US presidency and took control of Congress and globally famous business leaders are bending the knee to them without repercussion? What definition of \"can absolutely\" are you using? reply ziddoap 47 minutes agorootparentIt is less socially acceptable in some cultures, more in others. The fact that a gradient exists is proof that, under different circumstances, the social acceptableness of hatred can change. reply JohnMakin 2 hours agoprevI feel this a lot, not so much from the perspective of someone that belongs to a formerly \"protected\" group, but came into tech at the height of the tech revenge-of-the-nerds style \"zeitgeist\" in the early 2010's to 2015, around the same time he mentions being involved in startups. My first job was a startup, with a bunch of students and a professor at my alma mater. We failed miserably not in the way I had envisioned, but because of just basic VC funded stuff. We were a $20 million company with half a dozen of us, which would have been great for any of us, even our founders but the VC's wanted a $200 million company. Poof. That put a bitter taste in my mouth that has gotten more bitter when the \"promise\" of a society led by technocrats has yielded a barrage of increasingly shitty and invasive products that don't provide any additional utility to anyone except the people who stand to profit from them. It's exhausting, extremely depressing, and if I had to do it again I probably would have avoided tech, as much as I like what I do I feel a deep sense of shame sometimes at the state of how it's gone. reply phillmv 1 hour agoprevI was genuinely afraid of this post hitting HN, but thank you for the kind words. reply tmearnest 2 minutes agoparentI was terrified to look up through the comments after reading the article, but HN truly surprised me today. reply solfox 54 minutes agoparentprevThis is a very important conversation to have right now. Thank you for your vulnerability in sharing it. reply bryant 1 hour agoprevMy guess is there are two possibilities as to what's going on: * Many tech pioneers and leaders deep down felt an animosity towards supporting people who didn't fit the mold and finally feel free to express it (the worst-case outcome), and/or * Many tech pioneers and leaders wish to continue supporting those who don't fit the mold but feel their own status threatened by figures with nearly infinite power[0] who disagree. The former are simply the intolerant coming up for air. The latter exhibit a cowardice, though there's a subpoint to that second bullet: there could be some in this crowd who prefer to conform to but then dismantle the power structures enabling hatred from within, but these people likely won't be known for a while, and it'll be difficult to predict who's acting subversively in this way. Though given PG's narrowly scoped essay, there's a reasonable chance that this is his footing. The best people can do is assume the least-worst case the cowardice and instead seek to either craft themselves as the people they wish to see... and/or protect oneself from the rising tides of hatred. [0] https://www.supremecourt.gov/opinions/23pdf/23-939_e2pg.pdf reply ethbr1 1 hour agoparentThere's also a third type, that I consider to be the most likely reality given self-selected population of founders / successful leaders: People who will amorally play to the limits of the rules if it helps them win. It doesn't matter what they personally feel, or even if they have feelings at all. They tack with whatever way the wind is blowing in order to derive the maximum benefit. E.g. the million dollar inauguration contributions That's not a lot of money for that sort of person. The point of kissing the ring is the visible action and the favor it curries, not because the kiss is dear. reply neom 1 hour agorootparentThis is lacking a lot of nuance though isn't it? You're basically saying hate the player not the game, and that isn't really useful. When you step up to the arena and decide to play a competitive sport, because of game dynamics you can only know so much about who you are playing against, so you should play. The whole philosophical theory behind capitalism is literally progress emerges from the conflict and tension created between it's functional systems. If you want to get down to blaming humans, you're going to hav to go over to Adam Smiths or Joseph Schumpeter. reply bryant 1 hour agorootparentprevYeah I don't know why I skipped this one, but given the relationships between CEOs and psychopathy I shouldn't be surprised. reply michaelt 1 hour agoparentprev> Many tech pioneers and leaders wish to continue supporting those who don't fit the mold but feel their own status threatened by figures with nearly infinite power[0] who disagree. If only tech had some sort of rugged frontiersmen who weren't afraid of a bit of hardship. Davy Crockett types, pushing boundaries and standing firm under siege no matter the personal cost. We could call them \"pioneers\" if any existed. reply tclancy 1 hour agoparentprevYeah, there’s probably some Pulling The Ladder up like my Irish immigrant ancestors did. At one point everyone in the discussion was a nerdy social outcast. Now that they can afford to hang out with the Beautiful People, time to be as agreeable as possible. reply myflash13 1 hour agoparentprevnext [6 more] [flagged] tclancy 1 hour agorootparentYou probably need to read more history, and maybe challenge yourself to find sources, if you think those things were always widely true everywhere. reply myflash13 1 hour agorootparentEven most of the world right now doesn’t care about wokeness and never has. India, the Middle East, Africa, China, Russia etc. never caught on to most woke stuff that came out of the west in the past 20 years. reply Philpax 42 minutes agorootparenthttps://en.wikipedia.org/wiki/Transgender_history reply myflash13 4 minutes agorootparenthttps://en.wikipedia.org/wiki/Woke DasCorCor 36 minutes agorootparentprevgoose comic Who has recorded that history? reply JDEW 1 hour agoprev> Are “identity politics” just a status game that economically advantaged elites play? Yes. But it's a disgrace that we're throwing the baby (genuine progress, like the slow acceptance of non-binary people) out with the bathwater. reply natch 1 hour agoparentHuge pretending going on though that we are doing this. We are not throwing away the baby. There is nuance and people are pretending there is not. I support trans people but also support safety for all people. There are some nuanced details when you get to reality, and we can’t just pretend those away. The symptoms or pretending are things like not finishing the essay, or not even reading far enough to uncover PG’s definition near the beginning, so it had to become a footnote later when someone told them about it. reply rchaud 1 hour agoprevHaving read many of PG's essays from the 2000s and seeing how he communicates now, I can only reach one conclusion. Like Musk, Zuck and the others who got rich quick decades ago, they are too far removed from any kind of \"hacker\" ethos today, and see everything from 30,000 ft, almost literally. What kind of self-described hacker spends their days advising incubees on the best way to close \"high-touch B2B sales\"? They concern themselves with accumulating power first, and maintaining their \"innovator\" image second. Any empathy or compassion they may have had for the concerns of ordinary people appear to be long gone, except perhaps for their personal friends who may be on the receiving end of state-sanctioned bigotry. Reagan for example ignored AIDS, seeing it as a \"gays and minorities\" issue, while in private he looked out for the care of his AIDS-afflicted gay actor friend Rock Hudson, who passed from complications in 1985. Back to PG, see his essay from some years ago, \"How People Get Rich Now\"[0]. You would think it was ghost-written by an investment bank's IPO division. Every single line is another way of saying \"raise money for speculative bet, then go public\", ignoring his own decades of experience at YC indicating the overwhelming majority cannot achieve this, in the biggest VC market in the world. Much of the United States population has absolutely no entry point into Sand Hill Road. A response to that essay from a software engineer provided a sobering perspective to counterbalance the winner-take-all world PG lives in. [1] [0] https://paulgraham.com/richnow.html [1] https://keenen.xyz/just-be-rich/ (HN discussion link: https://news.ycombinator.com/item?id=40962965) reply Nevermark 1 hour agoprevThere are a lot of things that bother me these days. But particularly some things that are pervasive, unnecessary, habitual amplifiers of disagreement. If someone is going to address extremists on an issue, don't just be anti-extremist. What empty courage is that? Address extremists by pushing the dialog back to the real issue. In this case, treating people who have been denigrated for centuries better. Otherwise, ungrounded one-sided criticism of extremists on one side of an issue, just gives tacit permission for the extremists on the other side. It can even be difficult to tell, whether they are not simply mirror extremists themselves. But either way, they just amplify the extremist vs. extremist narrative. And completely distract from the real human level issues that are being hijacked. Don't be anti-bad, while conspicuously avoiding acknowledging what would be good. How should we address discrimination against trans and other non-binary people? What changes are beneficial? What companies have DEI approaches that are good models? PG, any thoughts? Please, don't call out \"your going too far!\" no matter how necessary or accurately if you don't have the courage, insight, or a genuine desire to solve the underlying problem. And express \"how far\" you agree we should go. Don't just poke a bear. Address the elephant!. One-sided viewpoints just make an easy sport, score trivial (dare I say, also performative?) points, out of something more serious. I.e. don't make strong arguments for or against one side of the Israeli-Palestine situation, without acknowledging the strong points you do accept as valid from both sides. I hope I don't offend anyone by suggesting that any intellectually honest discussion of divisive views cannot possibly boil down to one-sided criticisms of other people's one-sided views. reply rexpop 47 minutes agoparentYou make a good point that no one else had, afaik: PG is strawmanning, and not steelmanning his opponents. This is craven. reply Nevermark 14 minutes agorootparentSo much said, with such fewer words ... :) And giving voice to power vs. power, instead of to the less powerful. Reduced by both \"sides\" to pawns, their needs to playing cards. reply neom 2 hours agoprevIt's complicated isn't it? A business doesn't care about you. It doesn't because it can't. Business doesn't have thoughts and feelings, business is clinical. Business is nothing more than the collection of processed and systems crafted to work together, facilitating the exchange of value between 2 parties. The problem is with the 2 parties part. The 2 parties part, that part very much does have thoughts, feelings, and emotions, those two parties are made up of humans. Bobby Sue just wants the alternator working on the car so they can go to a family funeral and mourn. Jerry in accounting at alternator inc's going through a momentous life shift, spiraling his whole world into a new framing, changing everything. Sally in design is just trying to feed her kids. And while these things matter none to the business technically, they matter deeply to the humans involved. It's complicated because business doesn't, shouldn't, and can't have feelings, however, business activity is indeed made up of people, and they most certainly do. There is always a risk of being too cold and focusing only on the bottom line, or becoming so caught up in individual needs and emotions that you lose sight of the basic structure that keeps a business functioning. Booby Sue needs to mourn, and Jerry needs stability for his life change, Sally has kids. And so, there is some empathy to be found for people deciding fundamental things for their businesses, it's not easy to know when to be clinical in look at the business, especially knowing it's comprised of a collections of humans, organized, into a company. Care too much about the outside, the business fails, care too much about the inside, the business fails. These are not easy things, the trick is to avoid hostage situations, and so rationality and intellectual honesty is key when framing these discussions. I expanded these thoughts here: https://b.h4x.zip/dei/ reply Angostura 1 hour agoparentI disagree with your axiom that businesses shouldn’t have feelings. There is absolutely nothing wrong with a business that feels it should treat its workforce kindly and ethically and recruit a diverse set of people. reply neom 59 minutes agorootparentHow can a business feel that? You mean a founder? a ceo? the investors? The laywers? People who are running business at $500MM+ arr have 4 things to consider distinctly, with their own lenses and frames: The business It's model, it's operations, defined processes etc, every monday this report comes in, it is read by this functional area, it's converted into this insight, the insight is used, the consumer is delighted, more money comes in, the cycle continues. The humans involved are relevant so much as they must be able to do the task, who the literally are doesn't particularly matter, it's just a resource to allow a cog to spin. The company the people inside the business. The organizations how the people are assemble continually. The market customers etc. If you observe the business \"feeling\" done correctly, what you're observing the outcome of an evaluation process that decided it functioned more competitively in a different mode. (The best world class employees are in Spain, lets make our HR more diverse in it's language) A business cannot, should not, and does not, have feelings. The only place ethics technically come into play are in the context of law. It's nuanced, but it's important, without being fully fleshed in your framings, things get muddy. reply vasilipupkin 1 hour agoprev\"why go out of your way to remove them\" in principle, it's fine to have them. But really, they are just a symbol of the fake performative substance free dei culture. A reminder of it. Transgender employees should not be discriminated against, should have all the protections and respect like any other employees. But do we really need tampons in mens' bathrooms, really? reply axiomo 41 minutes agoparent> But do we really need tampons in mens' bathrooms, really? More to the point, do we really want men like the author in the women's bathrooms? Just because they desire to be women. We all need to take a step towards respecting women's boundaries by collectively telling these men: No. reply Angostura 1 hour agoparentprevIf someone was born biological any male and is transitioning and still has periods, it seems useful, so why not? reply timeon 1 hour agoparentprevWhy does it bothers you? reply ryanisnan 1 hour agoprevI appreciate this post, and that HN clearly isn't moderating it in a way outside of their stated policies. It is really hard to see the backpedaling of big tech with regards to identity politics as something other than virtue conformance. The sad and natural question that gets drawn is, where does the real virtue start and the performance begin? reply hnthrow90348765 1 hour agoprevThis made me unreasonably annoyed, not from the author though. >The mentors applied a neat and very effective trick: they believed in you. It's crazy to me that the LeetCode interview style is still such an aberration compared to other jobs that yield potentially much more money Do you want to be a Software Engineer at this company? We don't trust you, the previous company could have let you in under the radar and you could secretly be a terrible engineer. Do you want to run a SaaS and make us and yourself a bunch of money? Welcome aboard, we trust you completely once you're in. Just change your company name to fucking Oracle, ha ha ha. This industry is such an imbalance of misplaced scrutiny, and certainly more so when they get into political stuff like wokeness. If you're pg rich, just shut the fuck up. reply patresh 50 minutes agoprevSome of the disagreement or confusion seems to stem from the definition of the word \"woke\" which means different things to different people? Having read both essays I don't see them necessarily in disagreement. pg criticizes the performative and orthodox nature of some social justice activists' behavior, however it doesn't seem that the author's behavior here is performative at all. Perhaps we should just avoid these terms like \"woke\" and just say what we mean to avoid this societal dissonance? I feel like decent rational people can talk past each other depending on how they have been exposed to the term. reply tmountain 1 hour agoprevEarlier in my (now long) career, tech didn't feel political at all (just a bunch of nerds trying to figure shit out). Nowadays, it feels really weird to associate things like cryptocurrency with \"tech bros on the right\", etc. It all feels very unnecessary, but I suppose humans have a natural tendency to divide into camps as a survival characteristic. Whatever the case, The United States has certainly at a stage where it feels like tolerance for others is at a low point--at least as far as my historical memory serves--and the country seems far less welcoming than it has in the past to a variety of cohorts which will affect the makeup of the work force. The general politicization of the tech industry makes me less excited about continuing as an engineer, which is sad, because it's always been a discipline that I've really loved. It feels like \"hate politics\" are oozing out of everything these days, and I don't see how that represents progress of any kind. reply kristianc 1 hour agoprevCan't help but OP might have been better engaging with PG's Wokeness article itself (it's full of holes, and probably one of the weakest he's written), than talking about what they think the article said made them feel. Ironically the Wokeness article does what most people accuse \"wokeness\" of doing, predetermining its conclusion, and then shoehorning in a bunch of loosely connected facts and phenomena to support that assertion. reply spokaneplumb 1 hour agoparent> Ironically the Wokeness article does what most people accuse \"wokeness\" of doing, predetermining its conclusion, and then shoehorning in a bunch of loosely connected facts and phenomena to support that assertion. This basic approach underpins the pop-business and some of the pop-science industry. Plus much of self-help. And a good chunk of popular political books, of course. It’s a winning approach, lots of folks read that kind of thing and nod along, are glad they paid money for it, and recommend that others do the same. Even the “good” books in those genres are often guilty of it :-/ Motivated reasoning, cheap rhetorical tricks, and half-fake but digestible and uncomplicated history/facts are how you “win” the war of ideas. reply ternnoburn 1 hour agoparentprevIt's not a direct criticism of the PG article, the OP is examining a broader cultural phenomena right now. PGs scribbles were just one example. reply benrutter 1 hour agoprevThis is a really personal article and I'm really grateful the author shared it. I think too often conceptual terms like \"wokeness\" and \"identity politics\" get thrown around without really considering the people underlying those ideas. It's easy to make snap judgements along the lines of \"the world is too woke these days\", but a lot harder to argue against peoples ability to live as they choose with basic dignity. reply lubujackson 1 hour agoprevI'll just say it must suck being precisely in the crosshairs of a political proxy battle. The truth is, neither the left nor the right really give a shit about transgenders but use them to rile up their bases. First, the brief \"woke\" movement which was soon taken by the right and extrapolated to the extreme. It's the same tactic used by the right for any issue when I was a kid it was \"if gays can marry, then they will want to marry their pets.\" They take whatever social progress has been made and push it until the concept annoys >50% of people then say \"that's what the left wants.\" But I can't get behind the left's approach of highlighting and siloing every sub-group. It just simplifies division and is counter to all the American \"melting pot\" concepts that actually worked over many decades to integrate immigrants and normalize differences. I don't know where all of this leads, but it certainly doesn't feel like progress is ever made or even really desired, only a cycling of hot button issues to distract everyone. reply Angostura 1 hour agoparentIt’s not really a left right issue, as far as I’m concerned. It’s people with empathy v those without. reply watwut 57 minutes agoparentprevI dont think transgender are in the crosshairs of a political proxy battle. The issues is that many people feel disgust and hate over the idea of transgender. And whenever they become visible, they lash out and react. reply axiomo 34 minutes agorootparentIt's more the behavior of trans activists that gets people riled up. There's really no need for men who say they're women to be going around conquering everything that's for women and then admonishing people as bigots or transphobic when they object to this. Instead they could, you know, just live their lives peacefully without launching attack after attack on women's rights. It'd be better for everyone. reply ndesaulniers 1 hour agoprevLink to the essay in question: https://paulgraham.com/woke.html reply rexpop 59 minutes agoprev> the reason why conservative women are so mad about trans women is because they don’t want to share washrooms with the sex slave caste. I would like to see more of the HN caste engage with the very notion of a caste system, but I can't immediately think of a way to do it that also accommodates the spirit of HN—which I value—that dictates we focus on technical subjects. Perhaps the techie workforce angle is the only good faith approach. reply richrichie 1 hour agoprevAre you the \"ordinary people\" he was referring to in a recent tweet @ Musk? reply femiagbabiaka 1 hour agoprevMy sympathies to the author. I’ve had more than a few moments of disillusionment myself. But it’s always better to be aware and disillusioned than unaware and happy. reply 23B1 1 hour agoprevThe essay wasn't a criticism of the changing definitions of gender/race/power etc. The essay was a criticism of the activist tools used by 'woke'. The difference between: \"Hi! I am transgender.\" and \"You will acknowledge me as transgender.\" reply James_K 1 hour agoprevIt's interesting to see how tech bros are slowly sliding to the right. The first thing I ever read from Paul was his thing about lisp, and I almost instantly disliked him. There is an intense ego that radiates from his ilk. You see a similar thing with some small business owners. Owning and running a business gives them a feeling of superiority. They feel that they are affluent thanks solely to their own efforts (and perhaps some negligible work from their employees), and seeing that others are less wealthy they conclude themselves to be superior [1]. I think it's an inevitable fact of capitalism that the people who rise to the top are the ones who are greedy, who confuse profit with virtue. It's really no surprise that they are easily influenced by the winds of fashion; you don't get rich by taking a stand. [1] Footnote 12, https://paulgraham.com/superlinear.html#f12n reply spokaneplumb 59 minutes agoparentYou may enjoy “Dabblers and Blowhards” from IdleWords, if you’re not already familiar with it. https://idlewords.com/2005/04/dabblers_and_blowhards.htm Reading that helped me come to terms with how most of the time when I read PG essays I was a lot less impressed than everyone else seemed to be, and often (any time the topic wasn’t narrowly tech or maaaybe business) his writing struck me as actually bad—not well-reasoned, not convincing, and giving an impression of his being poorly-informed. When I experience an author everyone else is praising that way, I wonder if I’m the moron. But, sometimes, maybe I’m not… reply James_K 33 minutes agorootparentThanks, a very good read. Made me chuckle a lot. I've always found Paul's obsession with being a \"hacker\" rather annoying. reply subarctic 1 hour agoprevI have to say that this is a very well written piece. The story in the first half does a good job of showing the author's personality and making him seem very relatable, at least if you are a typical HN reader. And it's a good story and didn't have me thinking \"get to the point\", especially since the title doesn't make you expect anything more than a good story. Then halfway down, he drops the words \"I'm transgender now\" and you start to realize what he/she is really writing about. If the article started there it would have lost a lot of people. Instead with the first half it gets you invested and you stick around to read the rest of it. PG's essay about wokeness, on the other hand, didn't really accomplish this. In fact it kind of did the opposite: came on strong and imprecise at the beginning and became more measured and precise towards the end. And thus it probably lost a lot of readers toward the more \"woke\" end of the spectrum like this author. reply bun_terminator 10 minutes agoprev> But for so long, people like me were strongly discriminated against bro, you own the world. People get sentenced to jail for saying the truth about people like you. You get showered with money, jobs and free points HN for saying a few magic words. It's the most disgusting guilt trip in the history of mankind reply spacechild1 1 hour agoprevI'm so mad at people like PG. They are actively helping turn the US into a right wing tech oligarchy and at the same time complain about \"wokeness\". Let's say I'm not surprised, just a few months ago PG called Musk a political centrist! All the best to the author! reply sillyfluke 22 minutes agoparentDidn't downvote you, but I'm not sure there is anyone in the American VC class that shared the harrowing plight of Palestines as much as Kamala-voting pg did. Not to say he does it alot, but in the VC feeds that I normally check out once in a while it's virtually non-existent. Hell, Musk even attended and applauded Netanyahu's speech in Congress. ...By that metric that would make pg a radical leftist. You know what wasn't on my bingo card for 2024? Paul Buchheit being red-pilled harder than Paul Graham. reply fallingknife 1 hour agoparentprevnext [4 more] [flagged] ternnoburn 1 hour agorootparentIn no universe is Musk a centrist. reply fallingknife 12 minutes agorootparentName a far right position that he holds reply spacechild1 1 hour agorootparentprevNice bait :) reply thiago_fm 2 hours agoprevI like the article, but one doesn't need to meet pg once to get to know what he is. You can just read his tweets (x's?) and he, like many VCs or higher-ups in SV doesn't give a huge importance in how other humans feel, just in his kids/family/relatives. So overall, he doesn't care about how you think or feel. If he did, he wouldn't write an essay on a touchy topic without making a big disclaimer. By reading him tweet for sometime you'd realize the kind of person he is, and he isn't somebody that is there to support others or something, or has threaded prejudice or huge issues in his life. The deepest essay pg has written that touches the \"They don't like me\" point, from all I've read is his thoughts about nerds/geeks, after all we get bullied! You can't compare being a nerd to being transgender, or a victim of racism, or xenophobia. It's very different. He just doesn't have studied, or suffered enough to understand the perspective of a \"woke\", then he wrote that article. AI engineers would say the problem with pg's llms didn't have enough training data ;-) reply asabjorn 1 hour agoprevThere are two key aspects here: the nature of work and a critique of woke narratives, which some argue deny recent developments by framing them as a simple desire for acceptance. Specifically, transgender individuals are seen as being elevated through diversity and inclusion (DEI) initiatives, with accusations that these efforts sometimes prioritize activism over qualifications and invade female only spaces that are there for a reason. While I understand the personal challenges you’re navigating regarding identity and humanity, it’s important to maintain boundaries between personal matters and professional life. In Silicon Valley, the focus is on achieving ambitious goals that deliver exceptional results, similar to the performance expected in professional sports. Success depends on everyone concentrating on their work, regardless of personal beliefs or identities. Therefore, keeping personal issues like sexuality and the woke religion separate from the workplace ensures a productive and diverse viewpoint inclusive environment where all qualified individuals can contribute effectively and help companies thrive against odds. reply transcriptase 1 hour agoprevnext [5 more] [flagged] skywhopper 1 hour agoparentThe point he’s making is that Paul did not explain what he thinks “wokeness” means in a coherent way. Which is true. reply transcriptase 1 hour agorootparentHow could she know if she didn’t read it. reply ternnoburn 1 hour agorootparentprevThe point she's making, the author is a woman. reply axiomo 44 minutes agorootparentNo he's not. As he says in the article, \"I like women so much I'd like to be one of them.\" Which, obviously, means he isn't a woman. reply dachworker 1 hour agoprevnext [5 more] [flagged] phillmv 1 hour agoparentIf it's any comfort, I'm also an immigrant who was raised in a single parent household. When we last (it's a long story) moved to Canada, I had to share a bed with my dad for a while. We were never actually poor, poor, at risk. I never skipped meals, or lacked for clothing, though certainly that was a living memory my grandparents had. It was never in question that I would attend university. Privilege is intersectional blah blah, there are layers to things. I'm not of the dominant Anglo culture, I have an \"ethnic\" last name, I don't have the same connections people who grew up upper-middle class do. But people certainly see me as white, I'm smart, and I built my career as a bearded guy. Living as a bearded white guy is just a lot easier, it presents a lot less friction, than being gender non-conforming. That's it, really. reply raincole 56 minutes agoparentprevBut if you consider humanity as a whole, even the lowest decile US citizens are extremely privileged in terms of economic state. Even if you live on food bank, you're still much more privileged than most humans. So either all western people can't complain at all without being hypocrite, or we need to accept that one can be privileged in one way but vulnerable in another way. reply axiomo 39 minutes agoparentprevExactly this. Also the companies that men like the author tend to work for will bend over backwards for men who say they are woman, often to the detriment of actual women. reply Angostura 1 hour agoparentprevI think the only controversial thing there is your belief that privilege is a binary attribute, rather than multidimensional reply 1970-01-01 2 hours agoprev>I’m certain he wouldn’t be rude to my face, but he might quietly discriminate against me, say no thanks. He might not even think of it as discrimination, only that I don’t have what it takes. >I’m better at my job than most. I’d be a better startup founder today than I was in 2015. None of that will matter. IMHO, jumping to conclusions just like this is a big reason why 'going woke' isn't a healthy mindset for someone to hold. Stating that none of it matters is exactly the same thing as saying \"I can't do it\" reply beedeebeedee 1 hour agoparent> IMHO, jumping to conclusions just like this is a big reason why 'going woke' isn't a healthy mindset for someone to hold This is not unique to \"wokeness\" and is in fact much more clearly expressed by people who are \"anti-woke\". Many folks just can't handle things that don't fit neatly into their (unexamined) categories about the world. They'd rather destroy that person or thing rather than reflect and improve their understanding of the world. reply frereubu 2 hours agoparentprevThis feels like a pretty shallow reading of the article and you've fallen into the trap described in the article itself that \"woke\" is \"some left-wing thing that I don't like\". Whatever your views on trans issues, I think this article deserves a more thoughtful answer. reply 1970-01-01 1 hour agorootparentWill you agree with the author's viewpoint that \"none of experience\" matters if one is trans? reply InsideOutSanta 1 hour agorootparentMy reading of the author's viewpoint is that there are a lot of people in leadership positions in the tech world who would have previously recognized the author's talent and supported them, but would now form a negative opinion of them, regardless of their experience. These people would no longer give them the opportunity they gave them previously. reply 1970-01-01 1 hour agorootparentI think good leaders recognize people like the author simply have an additional life burden that they both choose and need to fight against and uphill. Additionally, those fights will ebb and flow unpredictably, possibly becoming too much of a burden for them at unpredictable times. If this is what you mean by negative opinion, then I agree. But I really don't think good leaders will take it out on them personally or hold them back to the point where they choose fighting inner trans issues over their business and success. reply skyyler 1 hour agorootparentprevThat’s what facing structural oppression feels like. You can have the right skills and competency and mindset and disposition but will be looked over because you don’t fit the norm. reply coderc 1 hour agorootparentIt's hard to prove that this happens to any given individual, because employers aren't mandated to announce why any person was \"overlooked\". One might be quick to blame \"structural oppression\", racism, sexism, or any other ism or phobia, but that doesn't necessarily make it true. reply Gothmog69 53 minutes agorootparentprevYup but still a poor attitude to have. I feel this way often times as a white male in tech, that they would rather hire literally anyone else if they can add some much desired \"diversity\" but I'm sure you would disagree that this is the case. Better for me to try anyways and have the best possible outlook even if I believe the cards are stacked against me. reply skyyler 35 minutes agorootparent>I feel this way often times as a white male in tech Wait, you feel like you face structural oppression as a white man in tech? Could you explain what challenges you face as a result of your gender identity and race? reply 1970-01-01 1 hour agorootparentprevI agree with this somewhat, however, facing structural oppression is very different from deciding if a journey simply isn't worth starting. The mindset and disposition you speak of is or is not inclusive of assuming oppression will fully control one's overall success and happiness at a company? reply skywhopper 1 hour agorootparentprevHe’s saying, for people who take Zuckerberg, Trump, and Paul Graham’s statements as permission to discriminate against trans folks, their experience doesn’t matter. The author is not giving up, they’re saying that essays like Paul’s make the world worse for them, for no good reason. reply bedlamb 1 hour agoprev [–] > In this vein, the other day I saw a scorching, sizzling hot take on Mastodon that read something like: the reason why conservative women are so mad about trans women is because they don't want to share washrooms with the sex slave caste. What a ridiculous take. Firstly, it's not just conservative women who object to this. Secondly, the actual reason is not wanting males, regardless of how they identify, in a space intended for the sole use of women and girls. Thirdly, the actual sex slave caste in all societies across the world is female; it is very rare for males like the author of this blog to be subjected to such horrors. This is yet another example of how this type of man understands women even less than other men do. > The reason why pg's essay made me so upset, made me feel so dispirited, is because I benefitted directly from his largesse, from a system he set up. Yes and you also benefited from your male privilege. Your experience was nothing like that of a woman trying her hardest to be taken seriously in a male-dominated industry, and your experience certainly has nothing in common with those suffering in sex slavery. > Up until very recently, very few people would confuse me for a woman. It took me a while to remove my facial hair, I still haven't trained my voice. That's OK. What is a woman, exactly? I don't know. Yes you do know, otherwise you wouldn't be trying to act out some male fantasy of being a woman by trying to hide your male secondary sex characteristics. This whole blog post is maddening. It's just some privileged man whining on and on, while trying to pretend that he isn't a man and isn't privileged. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author attended Y Combinator in 2015, where they met Paul Graham and received advice on their startup, Appcanary, which was later acquired by GitHub.",
      "The author, now a transgender woman, expresses concern over Paul Graham's recent essay on \"Wokeness,\" feeling it reflects a rejection of inclusivity in the tech industry.",
      "The author is worried about increasing intolerance and potential discrimination in the tech industry but remains committed to living with respect and kindness."
    ],
    "commentSummary": [
      "The discussion centers on Paul Graham's influence and the perceived shift in values within the tech industry, highlighting disillusionment with tech leaders once seen as visionaries.",
      "It addresses the complexities of identity politics, the impact of \"wokeness,\" and challenges faced by marginalized groups in the tech sector.",
      "The text critiques the performative aspects of social justice efforts and the difficulty of balancing personal identity with professional roles, reflecting a broader cultural debate on progress and privilege."
    ],
    "points": 336,
    "commentCount": 191,
    "retryCount": 0,
    "time": 1737372002
  },
  {
    "id": 42761219,
    "title": "Escape the walled garden and algorithm black boxes with RSS feeds",
    "originLink": "https://www.johnwalker.nl/posts/escape-the-walled-garden-with-rss",
    "originBody": "Table of contents What is RSS or Atom Feed readers Finding feeds Meetups and events YouTube and PeerTube channels Podcasts Social media and Fediverse accounts Newsletters Blogs and website posts Websites without a feed Discovering new content Search Curation and recommendation Conclusion Escape the walled garden and algorithm black boxes with RSS feeds January 18, 2025 With most online platforms, it’s becoming more and more difficult to view a feed of content that is not generated by an algorithm whose purpose it is to keep you engaged. Often, these algorithms are a black box where you don’t know why certain content is being promoted, let alone have full control over the content you consume. The incentives and needs of those controlling the algorithms are different from your own. Platforms may seek to politically influence you or sell you something you don’t need. Platforms may change hands, changing the influence they wish to have on their users. The good news is RSS and Atom offer a decentralized alternative. Decentralization is becoming more popular as people are growing increasingly frustrated with centralized social media platforms like Twitter and Facebook and Reddit. Protocols such as ActivityPub and Bluesky’s AtProto give people more control over their data, identity, and content feeds. Allowing people to consume the content that they want to consume, in a way that works for them. What is RSS or Atom RSS and Atom are feed formats used to subscribe to content on the web. They are decentralized by nature. A feed allows publishers to publish the content on their website for others to consume, using any client they wish to use. The producer of content doesn’t get to dictate how you consume it. Want to filter out content matching certain keywords? You can do that. Want to choose which content has priority over other content? You can do that. By using an open and decentralized standard, you can take back control over what content you consume and how you consume it. Feed readers To consume the content on an RSS or Atom feed, you need a client. There are many different options available. Web applications you can self-host like Miniflux and FreshRSS. And native clients like NetNewsWire for macOS and iOS and Feeder for Android. There are even command line clients like Newsboat for those who like to live in their terminal. And while I would recommend, in the spirit of owning your data, self-hosting your own reader, FreshRSS has hosted instances you can use if you don’t know how to setup and host your own application. Finding feeds Many websites will include an HTML tag linking to their feed.You can find these by looking at the source code of a page. Some RSS/Atom clients can do this for you. Or you can use a tool like RSS Lookup. Meetups and events I like using RSS to stay up to date with meetups and events happening in my area. Meetup.com doesn’t link to their feed, but there is an RSS feed you can find on the events page by adding /rss to the path. E.g. https://www.meetup.com/MEETUP-NAME/events/rss. YouTube and PeerTube channels You can get notified of new videos without having a YouTube account or subscribing. You can follow YouTube channels with this endpoint: https://www.youtube.com/feeds/videos.xml?channel_id=CHANNEL_ID And you can also subscribe to YouTube playlists: https://www.youtube.com/feeds/videos.xml?playlist_id=PLAYLIST_ID Peertube has a “Subscribe via RSS” option behind the subscribe button on channel pages. Podcasts Postcasts use RSS to distribute episodes. You can find links to a podcast’s feed on the podcast website or on directory sites like podcastindex.org. Social media and Fediverse accounts You can follow Bluesky accounts with RSS. You can also subscribe to communities on Reddit or the Fediverse. Lemmy has a link to the feed for a community on the community overview page where you can even set the sorting of a feed, e.g. by sorting by active or controversial posts. For Reddit, you can add .rss to the community name. E.g. https://www.reddit.com/r/selfhosted.rss Newsletters If you want to subscribe to a newsletter without cluttering your inbox or without sharing your e-mail address, you can use Kill the Newsletter. It allows you to create an email address you then use to sign up to newsletters with. It will turn the incoming e-mails into an RSS feed. Blogs and website posts Many websites offer a feed with their latest posts. I have a page with the feeds on this website. Websites without a feed For websites without a feed, you can use PolitePol to scrape the website and generate a feed. Or you can reach out to the owner of the website and ask them to implement a feed. Discovering new content One of the trade-offs of avoiding proprietary algorithms and going with a decentralized alternative is that it can be harder to discover content. I hope feed readers will get smarter and start including technology that will optimize and curate your feeds in a way that is beneficial to you. There are still a lot of opportunities for recommendation and personalization algorithms in this space. I’ll share some ways I use to find new websites to subscribe to. Search If you know what kind of content you’re looking for, search is a great way to find it. Marginalia search focuses on results that are non-commercial. And aboutideasnow.com crawls the /about, the /ideas, and the /now pages of over 3000 personal websites. Curation and recommendation Some people have a blogroll on their website curating the feeds that are interesting to them. You can follow communities that post stuff related to your interests. Or you can follow people on Mastodon or Bluesky. Directories like 1mb.club, 512kb.club, and ooh.directory are great ways to find new personal websites to subscribe to. And they all publish a feed with recently added sites. Conclusion Break free from walled gardens and opaque recommendation algorithms. Use RSS to have more control and be more intentional with your media consumption. If you publish content, make sure to also publish a feed so people can discover your content without relying on third parties. Let’s build decentralized systems together so we can break the cycle of enshittification on platforms we don’t own. Feel free to let me know how you use RSS and which feeds you enjoy. ✵ Tags decentralisation internet self-hosting community indieweb ← Back to posts",
    "commentLink": "https://news.ycombinator.com/item?id=42761219",
    "commentBody": "Escape the walled garden and algorithm black boxes with RSS feeds (johnwalker.nl)283 points by rekl 22 hours agohidepastfavorite102 comments jopsen 21 hours agoThis is missing planets. A good way to find interesting blogs is to subscribe to a few planets. These are essentially aggregations of blog related to some project/topic. https://planet.gnome.org/ https://planet.kde.org/ https://planet.mozilla.org/ https://planet.documentfoundation.org/ PS. If you know any good planets worth skimming, please add to below :) That said, I don't really have a good RSS reader that syncs across devices. I currently use Feedly, but it tries to be too smart. reply PaulHoule 20 hours agoparentI think it's little appreciated that planets solve many of the practical problems of feed crawling. If you wanted to follow 2000 blogs yourself you'd find it is really a hassle. You can follow one planet and its easy. For that matter, if 2000 people want to follow your blog (and many other blogs) they are going to generate 2000 requests per polling period. It is not wonder why people like [1] get so exasperated. There are three kinds of polling periods: (1) too fast, (2) too slow, (3) both at the same time. Instead of having 2000 people poll your blog too often, one planet can poll your blog. It improves the scalability and economics of the system dramatically. (e.g. the difficulty of finding a good polling regime is one of 10 or 20 or so unappreciated reasons why RSS has remained nerdcore) [1] https://rachelbythebay.com/w/2024/05/27/feed/ reply scarface_74 19 hours agorootparentAnd her RSS feed doesn’t work at all reply greggyb 19 hours agorootparentWhy do you say that? reply scarface_74 17 hours agorootparentTry it. I’ve tried it with NetNewsWire reply greggyb 16 hours agorootparentI subscribe. It does work. Did you read the linked post of hers? Perhaps your client is throttled or blocked. reply handsclean 14 hours agorootparentData point 3: does not work for me. Also using NetNewsWire. “Throttled or blocked” changes nothing, if it’s down for half of visitors then it’s down for half of visitors. I highly doubt NetNewsWire is breaching spec or poorly behaved. I bet rachelbythebay is just throttling by IP address and really has a 24 hour limit of exactly 1, so only one person per IP per day can subscribe. reply ognarb 21 hours agoparentprevSince planet.kde.org is mentioned, it's super easy to create something similar with a bit of python and a static site generator like Hugo :) https://invent.kde.org/websites/planet-kde-org/-/blob/master... reply 8organicbits 19 hours agoparentprevI have a project that is collecting blogrolls and planets, especially those that publish OPML files. Here's my list of around one hundred planets! https://github.com/robalexdev/rss-blogroll-network/blob/385d... These are aggregated and enriched to build this site: https://alexsci.com/rss-blogroll-network/blogrolls/ reply twapi 20 hours agoparentprevThank you for reminding me about planets! I had forgotten about them, and your post has inspired me to explore them again. I appreciate your insights. reply gvurrdon 21 hours agoparentprevI tried Feedly after Google Reader shut down but eventually settled on Feedbin that might be worth a look. reply jopsen 20 hours agorootparentIf I read feeds daily I might spend 5 bucks per month, but I don't. It'll just be a subscription I forget that I have. I don't need more of those :) reply Gualdrapo 21 hours agorootparentprevI'm on the Feedly train boat too since the sinking of Google Reader. Besides the ai bs it doesn't really let you search something in your feeds without a subscription, so once I tried Feedbin. But I went back because third world issues (and not a fan of microtransactions either) I could not find a way (if any) to change the layout on desktop. I really like the minimal list view at Feedly (and even on mobile too). reply mamidon 21 hours agoparentprevWhat are planets, in this context? reply tempest_ 20 hours agorootparenthttps://en.wikipedia.org/wiki/Planet_(software) https://web.archive.org/web/20051029095046/http://www.planet... https://intertwingly.net/code/venus/docs/index.html https://github.com/kgaughan/mercury reply daveguy 20 hours agorootparentprevThey are just feed aggregators composed of multiple feeds. Based on this software: https://en.m.wikipedia.org/wiki/Planet_(software) reply mamidon 20 hours agorootparentThank you! reply flobosg 20 hours agorootparentprevFeed aggregators: https://en.wikipedia.org/wiki/Planet_(software) reply Unearned5161 20 hours agoparentprevbig fan of feedmail [1] for a \"dumb\" reader. It just delivers it to your inbox. I have a folder set up called \"feed\" and I can do all the email things to the items landing in that folder. Every email costs a credit, you can buy 10 000 credits for $10, which works out to $0.001 per article. The only thing it misses is any sort of highlight saving deal, but for those I just save the article to zotero and annotate it there. [1] https://feedmail.org reply ssttoo 20 hours agoparentprev(Disclaimer: my project) https://feed.perfplanet.com for web performance Also please open a GH issue if I’m missing a blog or 5 reply vishnu_ks 21 hours agoprevDo try https://diff.blog which is an aggregator of developer blogs which I built around 5 years back. diff.blog tracks over 2000 dev blogs at the moment. And you can also follow blogs and topics. reply edoceo 20 hours agoprevI love RSS but how can we get more of it? Walled-ish gardens seem to dominate. Many good producers are on platforms that just don't syndicate. What kind of pressure can we, consumers, put on? reply ColinWright 19 hours agoparentEvery Mastodon account automatically has an RSS feed ... just append \".rss\" to the account name: https://mathstodon.xyz/@ColinTheMathmo.rss reply jefurii 19 hours agoparentprevIf they're not using an RSS-capable platform maybe they're not so great? reply tap-snap-or-nap 20 hours agoparentprevRequest good producers to use platforms that syndicate. reply pyromaker 19 hours agoprevIs RSS really coming back? :) (you'll say it was never gone!) Lots of RSS related posts and comments recently. I've released Mashups a few weeks ago. https://www.mashups.io It's yahoo pipes clone so you can mix and filter RSS feeds that you want. reply RamblingCTO 11 hours agoparentawesome! good luck reply domysee 6 hours agoprevReally great to see so many RSS stories recently. I'm working on a feed reader, called Lighthouse (https://lighthouseapp.io/). It combines RSS feeds with read-it-later, by putting new content into Inbox, where you can either archive or bookmark. Bookmarked content shows up in Library. It's fantastic for content curation. reply soupfordummies 22 hours agoprevSo many RSS stories this week! I'm sensing a trend (hopefully) reply Pooge 21 hours agoparentI'm sorry to be the pessimist here, but I doubt it. HN users are the most likely to use RSS in the first place. I sincerely doubt that RSS is going to make a comeback this year with all my non-IT friends using it. reply bluebarbet 19 hours agorootparentRealism shared. I work with journalists, exactly the type of normies who would most benefit from this technology. Years of evangelism has had no effect whatsoever. Nobody they know is using it, they don't see the logo anywhere, or a big friendly \"Get started\" button. It's all so unfamiliar and technical-sounding. Even the name itself was a disaster, IMO: a hopelessly geeky and opaque acronym. It should have been called Webfeeds! It's all such a wasted opportunity. reply freeAgent 18 hours agorootparentJournalists used to use RSS quite a bit maybe 20 years ago. I guess they just forgot. reply azemetre 20 hours agorootparentprevWhy is the goal to appeal to as many people as possible? reply alserio 19 hours agorootparentIn this case having more people asking for it or expecting it can contribute to expanding the availability of RSS feeds to more websites. While the vast majority of technical stuff I follow uses RSS, the same cannot be said for some other resources I like to read. While some are kind enough to enable them when asked, I don't expect them to want to support them for just a handful of people in their target audience. reply Eji1700 19 hours agorootparentprevHonestly that might be for the best in some ways. I see rss as \"allowed to exist\" because not enough people use it. There's plenty of ways to subscribe to things that I enjoy right now that could be nuked if suddenly enough people were using it that they weren't seeing the conversion rates they wanted. reply meiraleal 20 hours agorootparentprevDon't underestimate what programmers with too much free time can achieve. reply coffeefirst 19 hours agoparentprevI think there’s a genuine desire amongst people who think about these things to take back control from the algorithms. That’s real. Scaling it to a wider audience than HN is a longshot, as much as I love the idea. reply terminaltrove 21 hours agoprevTry adding our feeds if you're looking for curated terminal tools every week, we have a blog as well with ATOM. https://terminaltrove.com/feeds/ All our feeds have an easy to see preview of the feed instead of unstyled XML so you know what the feed looks like. https://terminaltrove.com/new.xml reply sys_64738 4 hours agoprevThere's also https://brutalist.report reply cadamsdotcom 22 hours agoprevThat helps find content to read. I wish it was easier to find out what my friends have been up to without getting them to sign up for some platform they’ve never heard of, then post in multiple places in perpetuity, and move on again when that platform also goes to shit. A hard problem but surely not unsolvable. It belongs in a pg “please solve these big problems” essay. reply meiraleal 21 hours agoparentThat's an interesting problem. I'm thinking about creating a local-first RSS Reader that syncs using github. It seems doable to create a personal feed based on my feed and publish it also to github. reply ashryan 22 hours agoprevThis is so pushing happy buttons for me. Not that this is novel in any way, but I just started a repo call Subcurrent yesterday for the Astoria Tech Meetup in NYC at our Saturday hack session. Subcurrent aims to provide a feed aggregator page made of our community members' feeds. https://github.com/astoria-tech/subcurrent I did not know that Meetup.com exposes RSS feeds at all, so I will be adding that to our Subcurrent instance since our group keeps events on Meetup.com. I had never heard of Kill the Newsletter, but I'm a fan sight-unseen. Substack at least has feeds. You can append `/feed` to the newsletter's URL. Thanks for writing this! reply fevangelou 21 hours agoprevA handy bookmarklet to find & preview any site's feed (before subscribing): https://feedreader.xyz reply domysee 6 hours agoparentSimilar tool here: https://lighthouseapp.io/tools/feed-finder Finds feeds even if they're not RSS autodiscoverable. Everything it does is described here: https://lighthouseapp.io/blog/deep-dive-finding-rss-feeds reply OisinMoran 18 hours agoprevI love this! I'm trying to build a new corner of the old web with my social link sharing site https://lynkmi.com, and every tag automatically has an RSS feed so you don't need to know anything about them to set one up, or even need an account to follow one. The main idea is instead of following everything a person posts you can just follow a subset of their interests. So if I post about Irish Dairy Innovations [0] and also about Advice [1] you can follow whichever combination of those you like. If you'd like to sign up, my email is in my bio. And if you don't want to sign up, my email is still in my bio. [0] https://lynkmi.com/oisin/Irish%2520dairy%2520innovation [1] https://lynkmi.com/oisin/advice reply openrisk 19 hours agoprevAn advanced RSS reader/browser could bring back the magic of the web. reply uzerfcwn 5 hours agoparentFor me, that advanced reader is Thunderbird. It has amazing customizability with userchrome.css, web extensions, about:config and developer tools from Firefox. reply xrd 17 hours agoparentprevWhat does an advanced reader look like in your mind? reply openrisk 8 hours agorootparent1. Convergent desktop/mobile app that syncs between devices (open source and local) 2. Performant for large numbers of feeds 3. Integrated browser and automagical discovery and organization of feeds while you browse 4. Multiple taxonomies and viewing layout options, chronological, by subject etc 5. Advanced filtering by keywords 6. Transparent and pluggable locally runing algorithms to track usage and inform the user of patterns and if desired adjust presentation In a sense an advanced RSS 'reader' is what the web \"browser\" should have evolved to. There is really no real boundary between these two clients. An advanced RSS reader is essentially a more dynamic browser that queries the internet in more ways that the user-initiated visit of a bookmarked url or typing something into a search form. reply xrd 8 hours agorootparentGreat summary. I'm using a combination of FreshRSS (self-hosted) and Readrops (for Android). I feel like #1 is handled by this combination. But, I wonder what convergent means here for you? I don't notice any performance issues. But, this feels like a simple task for a bunch of RSS feeds. Did you notice performance issues with other readers? There is something very interesting about what you call \"automagical discovery.\" To me this is the biggest hole in my RSS experience. I want something that gives me magical discovery within the feeds I have based on my reading experiences. I subscribe to a lot of feeds because of one article, and then don't care about 90% of the other articles, but there are 10% that I do really want to read, but don't have the focus to find them. Is that what you mean by automagical? Why do you want #4? Filtering by keywords seems interesting. FreshRSS has a bunch of analytics that comes with the server. I never really use it, but it is interesting. I would be happy to share what I can see based on my limited usage over a few months if this would serve your purposes. I would be interested in understanding what you mean by that. The one thing I wish I had in my current setup is a way to take notes in a centralized way. When I'm on Android, I suppose I can copy and use a share intent. And, on a browser, I could install an extension to do that. But, it feels like that is an interesting opportunity for someone. I wish FreshRSS could layer a JavaScript app on posts, for example, and then I could build whatever I want. It has an extension API, but strangely documented. Thanks! reply openrisk 6 hours agorootparent\"Convergence\" was a term used by Ubuntu in their brief foray into mobile Linux. Alas it never led anywhere, but it still embodies a sort-of holy grail of cross-platform apps with uniform native feel. On performance, yes, in my experience various readers (have not tried them all!) will choke if the feed list grows beyond a hundred or so. If you make consistent use of RSS you don't even need to be a power user to reach this number. E.g. think of the typical total of browser bookmarks of youtube subscriptions people have. On reader magic, yes, the empowerment of users in discovering relevant content was quite central in early visions of the web. The idea was that with metadata (linked data) and intelligent clients you will have a sort of decentralized version of the \"you might also like\" functionality that is now such a mainstay of centralized platforms. Taxonomies and flexible layouts can really transform your experience. It gives you the option to switch between a reddit-like, subject-oriented view of feeds, or a mixed chronological order. I am actually thinking of possibly trying out FreshRSS. Akregator is what I am currently using and ticks a few requirements [2] but does not seem to be having much further ambition (and being a native Qt application it requires serious commitment to contribute anything). Yes your point about extensions is quite important. People have different ideas what makes \"an advanced reader\" and one way to reach broader community adoption is to make it easy to add functionality. [1] https://wiki.ubuntu.com/Convergence [2] https://www.virtualcuriosities.com/articles/2563/my-review-o... reply xrd 4 hours agorootparentInteresting comments, thanks. I've got FreshRSS installed. Email me at the address in my profile if you want to try it. Or, just create an account at reader.rss.surf on your own, I think I've enabled sign ups. FreshRSS is interesting because you can customize it to use postgresql instead of SQLite (which I did). Normally each user gets their own unique SQLite database, but in my case it is split across postgresql and SQLite now. The way they structure their tables and databases is a bit strange across users. reply dagurp 6 hours agorootparentprevVivaldi ticks some of those boxes at least reply vaylian 22 hours agoprevThe article also mentions atom feeds. I've seen plenty of RSS feeds but I have never encountered an atom feed. Are atom feeds still relevant? reply crtasm 22 hours agoparentAs an example, feeds available on every github repo: https://github.com/EFForg/privacybadger/commits.atom https://github.com/EFForg/privacybadger/tags.atom https://github.com/EFForg/privacybadger/releases.atom reply giantrobot 22 hours agoparentprevAtom and RSS are functionally equivalent despite their technical differences. Effectively no one has ever implemented Atom push capabilities so Atom is primarily only ever used for syndication. The term \"RSS\" is just a generic term for \"XML syndication feed\". reply progval 21 hours agorootparentAtom push is actually implemented. SWORDv2 (but not v3) is based on Atom Push, and https://en.wikipedia.org/wiki/SWORD_(protocol) lists a few implementations. My employer maintains a SWORDv2 server, and we have a handful of clients pushing to us; most of them are not listed on that page. reply superkuh 21 hours agoparentprevGoogle (Blogger, etc) pushes Atom feeds. Weather blogger is still relevant is up to perspective. reply frobnic 20 hours agoprevTry Rss-Bridge [1] when the website does not have any feed, it might have an integration already. It also supports custom CSS-selectors to create feeds, or even use SEO-Sitemaps for your advantage to generate a feed from it. [1] https://github.com/RSS-Bridge/rss-bridge reply renegat0x0 11 hours agoprevooooh I so escaped walled gardens. I use my own set of domains to find places on the internet [0]. A working example how it could be used is at [1]. It is a domain viewer in javascript. I also use my own RSS client [2] that stores all links in [3], but don't get me wrong, I also have my storage for bookmarks [4] Links: [0] https://github.com/rumca-js/Internet-Places-Database [1] https://rumca-js.github.io/quickstart/public/static_lists/vi... [2] https://github.com/rumca-js/Django-link-archive [3] https://github.com/rumca-js/RSS-Link-Database-2025 [4] https://github.com/rumca-js/RSS-Link-Database reply pigeons 19 hours agoprevI need to find some way to see a chronological feed of what people I am friends with on facebook post. I literally get randomly suggested posts from unrelated accounts, and scrolling through them all will start to repeat them, never showing me content from some people who are actual friend connections. reply Beijinger 19 hours agoparentYou need this: https://socialfixer.com/ At socialfixer, options, hide post put everything that should disappear follow reals etc.. I am not on my laptop otherwise I would post my block list here. reply BugsHack 19 hours agoparentprevTry this: https://www.facebook.com/?filter=friends&sk=h_chr reply pigeons 19 hours agorootparentThanks! reply kcplate 22 hours agoprevDef how I consume HN. It’s even nice to see flagged and dead which I wouldn’t see easily if I came via the HN homepage. reply xrd 21 hours agoparentHow do you get this, may I ask? I asked because I didn't know how to get exactly that, so I'm building a site that finds RSS feeds from sites on the front page of HN. Then, at the end of the day it emails me with a summary if I miss one. https://RSS.surf If anyone wants to try the daily summary email would love feedback. reply kcplate 19 hours agorootparentI use Feedly, which as a RSS reader is ok but probably one of the better ones available on iOS/iPadOS platform. I loved Google Reader back in the day, but Google loves to kill every product of theirs that I actually like and used. I believe the HN feed is available here: https://news.ycombinator.com/rss reply xrd 17 hours agorootparentSo, just to confirm, you prefer to read the news on hacker news via RSS? Why? I assumed you meant view the RSS for sites on HN but that's clearly different than what you were thinking. reply jayemar 5 hours agorootparentI do the same. I do it because I subscribe to sites other than HN, and by subscribing to the HN feed I can get the articles from HN as well as the other sites I subscribe to all in the same place, ie my feed reader (also using Feedly). Nothing overly original here as I assume personal content aggregation was one of the original intentions of RSS. reply aboardRat4 12 hours agoprevI've been trying to make it work for ages, but it's not going to work. \"News\" are not actually that easy to automate as in \"serialising posts\". Big companies are experimenting with UI all the time for a reason. Especially because it would involve a lot of heuristics. reply qudat 21 hours agoprevIf anyone needs an rss-to-email service, check out https://pico.sh/feeds reply janice1999 20 hours agoprevI see PolitePol mentioned. What do people use to run scrapers to generate RSS feeds themselves for sites without them? Do you self host scrapers? reply dagurp 20 hours agoparentI do. Just a raspberry pi with nginx and a cron job that runs python scripts. I'm not into AI but writing those scripts is boring so chatgpt is perfect for this. reply Havoc 17 hours agoparentprevThere is one called rssbridge or something that can do that reply ColinWright 19 hours agoprevEvery Mastodon account automatically has an RSS feed ... just append \".rss\" to the account name: https://mathstodon.xyz/@ColinTheMathmo.rss reply rubicks 19 hours agoprevRelevant: https://newsboat.org/ If you like your email in mutt, then you'll probably like your feeds in newsboat. reply quinto_quarto 19 hours agoprevi built this site (https://fanzine.world) to help people discover micro-creators and share their top 5 faves. not sure what to do with it. maybe someone here has a suggestion? reply delduca 21 hours agoprev+ for Reeder for macOS and iOS I follow several feeds and Youtube channels. Reeder have a very smooth experience. reply toofy 18 hours agoprevi would love to see Bluesky add RSS to user feeds the same way Mastodon does by just adding /rss to the end of the url. it really is rad to add my most read users to the feed. reply xavdid 14 hours agoparentBluesky supports them! If you append `/rss` to any profile, it redirects to a feed. e.g.: https://bsky.app/profile/xavd.id > https://bsky.app/profile/did:plc:fp2izjrrcsbsqphlu7f5sixa/rs... More info: https://openrss.org/blog/bluesky-has-launched-rss-feeds reply geor9e 19 hours agoprevFeedbro is my favorite reader. reply xyst 19 hours agoprevRSS feeds, so underrated. Rediscovering RSS and adding my YT subs as RSS feeds feels so liberating. Plus, RSS feeds combines the reg videos + short videos into single feed. reply PaulHoule 20 hours agoprev [–] The hate for algorithms boggles my mind. Chronological feeds are awful. You'll never see anything from the people who post occasionally because they get drowned out by the people who are posting all the time. There may be some algorithms that deliberately magnify hate because that's a way to increase engagement, but if you want to create one of those algorithms you can make a training set based on chronological feed + boosting/retweets/reposts. I'm amazed at how people keep making failing RSS readers that keep failing with the same failing user interfaces that have been failing since 1999; everybody knows RSS has been failing but they never ask why or if we have a choice. We still see the readers that make you mark things as read, that take their cues from email and newsreaders, that, when you subscribe to N feeds show you N boxes with a list of items, etc. My RSS reader works like TikTok because I'm not afraid of algorithms. reply openrisk 20 hours agoparent> You'll never see anything from the people who post occasionally because they get drowned out by the people who are posting all the time. If you control the algorithm there is nothing to prevent you from sorting feeds by volume and adjusting their presentation accordingly. Actually you can imagine countless other UI adaptations depending on preferences, usage patterns etc. Ideally RSS readers should offer flexible customizations, e.g., with plugins or even some low-code environemnt. reply PaulHoule 19 hours agorootparentIt's one thing to sort a list of things by one criteria, say \"a\". If you have two criteria, say \"a\" and \"b\" you can sort by \"a\" and break ties by \"b\" or you can sort by a+b or a-b or something like that... But that's not the same as optimizing both things. Maybe you can say \"there are these 5 people who are special to me who I never want to miss their posts\" but I think people would struggle to maintain rulesets and might not really be happy with the results they get. In search rankings for instance you night have a document score (like Pagerank) that tries to identify the quality of a document, and you might have a query-document score that identifies the relevance of a document to a query. It's not trivial at all to find a way to blend those that gives you queries that are both relevant and quality as opposed to just one or the other. The greatest weakness of my current RSS reader is that it's slow, depending on how much I am using it, articles could be delayed anywhere from a day to a week. For certain kinds of articles [1] recency doesn't matter, but other articles [2] have a definite shelf-life and if you repost them too late you look like a total dope. I'd like to let articles about sports \"cut the line\" in front of higher quality articles about other topics but it's really hard to find a balance that's right because I don't want to get flooded with lower quality sports articles. It's one thing to say \"let people make up their mind about how to balance these things\" but when you really try it you find it's pretty hard. Not only do I have to change the whole way my pipeline works (can't be a batch job anymore) but it's not clear to me how to tune up the selection criteria. [1] https://www.sciencedirect.com/science/article/pii/S294979062... [2] https://www.usatoday.com/story/sports/nfl/2025/01/19/eagles-... reply openrisk 8 hours agorootparentIf I understand your challenge correctly it could be helped with a reader that gives a taxonomy to classify feeds, as you then get implicitly multiple timelines one per feed category. Linux desktop readers like akregator and the now abandoned quiterss provide that and it works fine. reply beej71 20 hours agoparentprevI prefer time-based feeds, but that's just me. I don't think people are objecting to suggestive feeds in general; they're objecting to suggestive feeds whose primary objective is to keep you scrolling for as long as humanly possible to maximize company revenue. That's simply not what I want to do with my day. I'd train my own if I wanted to go that route. reply PaulHoule 19 hours agorootparentThe problem with time based feeds is this. You can read x articles a day; your system ingests y articles a day. x=y is perfect but requires close-to-perfect balance (if x=0.9y to 1.1y maybe you can adjust your reading habit to your your feed) if x>y then your system isn't showing you enough, if y With an algorithmic feed of some kind you choose to read x items a day, your system shows you the best x items a day out of y based on some set of criteria and constraints. And the whole point of the people who want RSS is that they disagree with the idea that \"the algorithm\" shows the best x items. The whole point is that they don't want \"the algorithm\". And your answer is \"Have you heard of the algorithm? I think it's a solution to your problem\". reply thuanao 17 hours agorootparentFor most people y > x. You're choosing what posts to see even if the feed is chronological. For a chronological feed, x is the most recent posts you happen to see when checking your feed reader. And x will skew towards people who post at the same time of day you tend check your feed reader. People who post more will also take a larger distribution of x. Any algorithm would seem to be an improvement on that, right? For example, an algorithm that sampled evenly from all sources. That would at least mean x was distributed across all your sources, so people who post more didn't crowd others out. reply ryukafalz 19 hours agorootparentprev> if x>y then your system isn't showing you enough We've grown used to having a practically infinite amount of things presented to us all the time, but I've come to believe recently that limiting the amount of posts you see can be a fine (and maybe healthier) choice. There's value in being able to say \"I'm caught up, I'm done\", it can be a natural stopping point. I'm not as good about limiting myself like this as I would like to be, but it is a goal of mine. reply PaulHoule 18 hours agorootparentThe total amount of content available is y>x. Some arbitrary process has to reduce the 1,000,000,000 pieces of content produced today to maybe 10 or 100 you can handle. The very concept of \"news\" (\"fake news\" is bad because it is news not because it is fake) is an act of violence against the fabric of reality because a huge number of things happened today, but CNN reported the same 10 of them 100 times. They could maybe cover 1000 different news stories (still a fraction of maybe 100,000 things that happened) but that's a non-starter because someone who watched the network at 3pm would have a totally different impression than someone who watched it at 5pm. reply beej71 18 hours agorootparent> Some arbitrary process has to reduce the 1,000,000,000 pieces of content produced today to maybe 10 or 100 you can handle. In my case, I'm the process that does the reduction by subscribing to specific feeds. (Not sure if that's \"arbitrary\", but I could see it argued either way.) I admit I miss some content that I would probably like to see. :) But that's just life how it's always been. As my wife put it, \"You don't have enough years in your life to read all the good books, so stop wasting time with bad ones.\" That's how I think of it. A handful of high-quality, low-volume feeds is great. (But I also follow HN and my curated Lemmy feed, so I get some of the firehose.) The only \"news\" I have in my feed is local news. Any interesting national news hits HN or Lemmy. Again, that's just me. I respect your different usage pattern. reply Eji1700 19 hours agoparentprev> You'll never see anything from the people who post occasionally because they get drowned out by the people who are posting all the time. I use inoreader and track basically everything I want in a huge list of feeds. It's pretty trivial to mark stuff as \"always flag this\", and then leave the rest of the pile as \"scan through and manually tag anything else\" Anything low volume goes on the \"always\" flag list as it takes one review a day of the new content to decide if it's something I care about. Ultimately what I want, and what most people want, is the ability to just hook up to various data streams and apply rules to it. From there filtering as desired comes pretty easily. reply josephcsible 19 hours agoparentprev> Chronological feeds are awful. You'll never see anything from the people who post occasionally because they get drowned out by the people who are posting all the time. My preference would be chronological feeds, but following few enough accounts that I can see every single post in it. Then that's not a problem. reply Havoc 17 hours agoparentprevPeople aren’t afraid of algorithms…just ones that are Blackbox and controlled by someone else who’s motivations don’t align with yours. Being concerned about that is downright logical. reply ahalimah 20 hours agoparentprevWhich RSS reader do you use in that case? And is it fair to say there's a middle ground between purely chronological feeds vs algorithms that reward engagement/time spent on the app? reply PaulHoule 20 hours agorootparentAn algorithm doesn't have to reward engagement or time spent on the app. It can reward or punish anything at all and that's what it is about algorithms. My feed reader (that I wrote myself) rewards things that I thumbs up and punishes things that I thumbs down. reply bluebarbet 19 hours agorootparentIs this mysterious feed reader one that you made yourself? I agree about the need to have some means of filtering. This is a major weakness of RSS, alongside onboarding and discovery. Algorithms serve the purpose of filtering well. The problem is their opacity. reply PaulHoule 19 hours agorootparentWhat people are calling an \"algorithm\" is really a heuristic. In the public discourse over \"algorithms\", the definition seems to be \"something that maximizes your (time on site|outrage|clicking)\" and not the real definition In mathematics and computer science, an algorithm (/ˈælɡərɪðəm/ ⓘ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. [1] By that definition any well-defined process that creates your feed (sorting chronologically, alphabetically) is an \"algorithm\"; in the machine learning age it is easy to make an algorithm that selects for anything at all, except for the capital-T Truth. [1] https://en.wikipedia.org/wiki/Algorithm reply nonrandomstring 19 hours agoparentprev [–] Let it go Paul. It's like the word \"hacker\". We ain't getting it back. It's sad the popular perception of a fundamental computer science concept, the great progeny of Al-Khwarizmi Musa, the life work of heroes like Donald Knuth, is sullied and stained with dire B-movie comic-book Bond villainy. Thank the hooligan broligarchs and their manchild ambitions for trashing that bit of computing culture. Even my mum spits in the dust like a cowboy at the sound of \"Algorithm\". reply PaulHoule 18 hours agorootparent [–] It might be easier to convince the people at the CS department to name the \"algorithms\" class something else. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "RSS (Really Simple Syndication) and Atom provide decentralized alternatives to centralized social media, allowing users to control their content consumption. Feed readers such as Miniflux, NetNewsWire, and Newsboat enable subscriptions to diverse content sources, including YouTube channels, podcasts, and blogs. Tools like PolitePol can create feeds for websites lacking them, promoting user autonomy in media consumption."
    ],
    "commentSummary": [
      "RSS feeds provide a way to escape algorithm-driven content by allowing users to subscribe to specific topics through \"planets,\" which aggregate related blogs.",
      "While RSS readers like Feedly and Feedbin help manage these feeds, some users find them complex, leading to alternatives like Feedmail that deliver content directly to inboxes.",
      "Despite its niche appeal, RSS remains popular among tech enthusiasts for its customizable and user-controlled content experience, with platforms like Mastodon and Bluesky supporting RSS feeds."
    ],
    "points": 283,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1737317243
  },
  {
    "id": 42762054,
    "title": "Please don't force dark mode",
    "originLink": "https://iamvishnu.com/posts/please-dont-force-dark-mode",
    "originBody": "Please Don't Force Dark Mode Jan 19, 2025 Dear website designers, Please don’t force dark mode on your users. If dark mode is a characteristic of your brand, please ensure you choose a comfortable contrast ratio for the text. I regularly see many websites including personal blogs that are designed exclusively in dark mode. I find this incredibly frustrating as I can’t even read a single paragraph on these sites before my eyes start watering. While dark mode can be beneficial on some occasions, forcing it on users is a terrible user experience. My Eyes! My Eyes! 😵💫 Reading in dark mode doesn’t just mess with my eyes while I’m at it — it sticks around afterward too. Every time I finish a long article, I end up seeing horizontal stripes everywhere I look, like my eyes just won’t let it go. This is what my eyes see before reading a dark-mode article: And this is what my eyes see after reading a full-length dark-mode article: What’s the real problem with the dark mode? The real problem is the contrast ratio between the text and the background when using dark mode. For example, pure white text on a pitch black background can strain my eyes and be very difficult to read. The contrast ratio of this combination is 21:1. Here’s an example paragraph: Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. However, light gray text on a dark gray background is easy on my eyes. Here the background is #666 and the text is #E0E0E0 which creates a contrast ratio of 4.34:1. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. In summary, higher contrast ratios in dark mode cause discomfort for my eyes. But when I say ‘higher’, just how high can it go? Isn’t there a guidelines for this? The Web Content Accessibility Guidelines (WCAG) version 2.1 recommends a minimum contrast ratio of 4.5:1 for normal texts (SC 1.4.3) but not a maximum. The current guidelines makes pure white text on pitch black background completely accessible, even if the contrast ratio is an unbearable 21:1. But the more comfortable contrast ratio of 4.34:1 from the above example fails according to the guidelines. That means, currently, there are no standards or guidelines that address contrast ratios in dark mode. Upcoming WCAG 3.0 adds a new exploratory requirement for “Maximum text contrast” and I hope the working committee will address the issue of high contrast text in dark mode and provide suitable recommendations. Until then, if I must read an important article that forces dark mode, I will use the browser’s developer tools to override the CSS and invert the colors until a better solution is available. I don’t want to use a plugin just for this. That being said, I absolutely enjoy dark mode when…: …reading on an OLED screen in a unlit room, for example reading articles on my phone before bedtime. Dark mode works best on LED-type displays when used in dark environments. …writing code. Almost every IDE has a dark mode with very comfortable contrast ratio out of the box. …the website has comfortable contrast ratio in the dark mode. Note: This article sparked a vibrant and insightful discussion on Hacker News. The thread features a mix of approvals and criticisms of the viewpoints shared, along with fascinating discussions on topics such as how early OEMs decided between dark mode and light mode, the significance of contrast ratios, and personal experiences—including medical conditions and accessibility challenges. It also highlights creative workarounds, thought-provoking debates, and even some gaslighting! To fully appreciate the nuances of this topic, don’t miss the valuable perspectives shared in the Hacker News thread.",
    "commentLink": "https://news.ycombinator.com/item?id=42762054",
    "commentBody": "Please don't force dark mode (iamvishnu.com)262 points by vishnuharidas 21 hours agohidepastfavorite235 comments 1000100_1000101 20 hours agoDark mode was the traditional normal. From early green or amber text on black mono displays. Grey on black DOS text mode. Light Blue on Dark Blue C-64. Apple 2's grey/white (I don't recall) on black. Even GUI wise, Amiga used a dark-blue background as the default Workbench, with user selectable palettes for everything. It was Microsoft Windows that changed the paradigm to default to a searing white display with black text in most apps, like Notepad, Word, etc., because \"it's more like paper\". Sure, paper is white, but it's not glowing white. That transition was painful. I'm glad to see dark-modes return, I agree there needs to be an option, not just forced dark-mode. Preferably light mode options to use a not-as-bright-as-possible white too. reply crazygringo 19 hours agoparentNo, dark mode is not traditional normal. Paper was, which is black on white. And you shouldn't have your device or monitor set to glowing white turn the brightness down so it's the same as a sheet of paper next to it. And Windows didn't change the paradigm, the Mac was the first widely available consumer device which did. And its built-in CRT wasn't especially glowing either it was less bright than paper in traditional office lighting. Early computers had \"dark\" color schemes because the resolution was so low and pixels \"bled\" brightness, that it was easier to read. As technology improved, that problem thankfully went away, and it's easier on the eyes to read dark text on a light background, regardless of print or screen. reply scarab92 18 hours agorootparentI don’t particularly care what is traditional. There’s a significant base of users that prefer light mode and dark mode so provide both, it’s generally not difficult to do so. I disagree that apps should tone down light mode. It’s better that all apps use the same brightness and contrast and then users can adjust their monitor to suit their individual preference. reply Ferret7446 18 hours agorootparentprevPaper, particularly bleached paper, is not \"traditional normal\" either. I'm no paleontologist, but originally humans would use substances like ash and fruit to draw/write on rock/leaves/bark, so white/red/colors on grey/green/brown. reply Sunspark 18 hours agorootparentprevIt's also really not necessary to use #FFFFFF as white. Paper itself is not that shade. reply recursive 17 hours agorootparentIt's not really meaningful without defining lighting and color space. Have you ever seen ink on white paper that was lighter than the paper? reply scarab92 16 hours agorootparentprevDisagree, white should be standardised as #FFFFFF so that it’s consistent between applications. Then users can adjust how they want “white” to appear by adjusting their screen settings. reply mbwgh 11 hours agorootparentThus forcing a subpar default on everybody intentionally. reply scarab92 11 hours agorootparentNo, #FFF is white, and it's up to the client to decide what white should look like. Arguing that we should use, say, #CCC for white, is like saying that instead of rating things out of a 100, you should rate them out of 70 instead. All you've done is narrow the scale. reply watwut 5 hours agorootparent#CCC is grey one of many greys . reply birksherty 7 hours agorootparentprevNope. Nobody is talking about what colour is white, but contrast that is forced upon user that hurts eyes. reply rmgk 4 hours agorootparentWhich direction of contrast is your problem? For me, the small contrast on pages like HN (in particular with any of the gray text) strains my eyes because it’s more effort for me to see the letters. But I also read a reasonable amount of PDFs (black on white) which is relatively comfortable on most of my monitors (LCDs with generally low brightness setting to have less light shine into my eyes). I think what I am saying is, I agree that what is comfortable depends on the user, so websites not moving off the defaults is better, because then users can configure what works for them. Addendum: The low contrast example on the article is very uncomfortable to read for me. reply in-pursuit 19 hours agorootparentprevGiven that screens are always adding their own light, it’s impossible for a screen to ever be equally bright as a piece of paper next to it. The screen will always be brighter. reply scarab92 18 hours agorootparentThat depends entirely on ambient light levels. All screens are brighter than white paper under moon light, almost none are brighter than white paper under midday sun. reply Ferret7446 18 hours agorootparentAnd reading under the midday sun is painful, much more so than a bright screen. If you haven't experienced before, I recommend it. It helps you appreciate just how bright direct sunlight is relative to other light sources. reply tshaddox 18 hours agorootparentprevDo what now? An entirely black OLED screen is certainly going to reflect less of the room’s light than a sheet of white paper. An OLED screen displaying white at 10% of its maximum brightness is also likely going to be less bright than a sheet of white paper in most rooms. reply hollerith 18 hours agorootparentprevNo because some surfaces reflect more of the light than other sufaces. reply 2-3-7-43-1807 7 hours agorootparentprev> Paper was, which is black on white. check > Early computers had \"dark\" color schemes because the resolution was so low and pixels \"bled\" brightness this reply flockonus 19 hours agoparentprevTraditional normal is not an absolute statement. Sure DOS / Unix back in the early days of PC displayed black backgrounds due the display's at the time working better this way. Before that, people shared information in white paper; and the beginning of the internet brought it back with black text over white background. Therefore there is no canonical traditional normal, it all depends when one joined. reply 1000100_1000101 19 hours agorootparentPaper and paper-like writing surfaces were non-white for a long time before we got bleached white paper. We haven't yet had a glowing-white paper. Traditional-normal for computing was a dark background. There was likely a technological limit in the use of pure white at the start when \"emulating\" paper. VGA 16-color mode likely meant that the choice was between bright white and medium grey, which was too dark. Configurability has lagged behind though. reply markhahn 16 hours agorootparentno, if you think trad-norm is dark mode, it just identifies when you started using computers. reply qwerty456127 19 hours agorootparentprevDOS notably used eye-friendly grey text, not bright white. reply hobobaggins 19 hours agoparentprevThe contrast ratio of an old CRT (and amber and green were considered more comfortable than white-on-black) is radically different from a modern LCD/IPS/OLED screen. It's so different that there's no comparison. Dark mode might be ok for more people if there is some brightness to the background instead of being completely black, but then you lose most of the benefits of OLED. reply leeman2016 18 hours agorootparentYes The \"true black\" OLED displays have their part of the display off where there are black pixels, if I am not wrong. So, wouldn't dark mode suit well for those types of displays? reply tommiegannert 10 hours agorootparentGP is arguing that exactly because there is no backlight, the contrast between on/off is uncomfortably high on modern screens compared to the CRTs where Windows 2/3 was running. I agree. Most websites with a dark color scheme use a dark grey background and even off-white text. reply TylerE 18 hours agorootparentprevOLEDs are per-pixel backlighting, so they can go full black on a single pixel. reply amelius 20 hours agoparentprevWasn't it the original Mac that changed it? reply pdw 19 hours agorootparentAnd Mac copied it from Xerox. But it was indeed the introduction of GUIs and WYSIWYG \"what you see is what you get\": the screen had to mimic paper. reply tempest_ 19 hours agorootparentIt didn't have to though. Lotus 1-2-3 mimicked a spreadsheet and it is not searing white. reply seanhunter 13 hours agorootparent...and Lotus 1-2-3 mimiced visicalc and when I used visicalc (on an HP85a) it had a dark background with a greyish white foreground colour. ie dark mode by default. reply petepete 20 hours agorootparentprevXerox had applications with white backgrounds from the start. https://crm.org/articles/xerox-parc-and-the-origins-of-gui reply 1000100_1000101 19 hours agorootparentprevMac likely did use this scheme, and yes, copied it from Xerox. However neither Macs nor Xerox had mainstream use. I'd only actually seen 3 Macs in the wild before their switch to Intel, over 20 years later. Windows adopting the \"paper\"-white background and whole world drooling over the arrival of Windows 3.1 and 95 is when it became the standard, I think. reply tom_ 19 hours agorootparentWindows 2 was predominantly dark text on white background. Same with GEM on the Atari ST. Both current in the late 1980s. Sinclair's ZX Spectrum was black text on white background in 1982. reply jameshart 16 hours agorootparentThe ZX Spectrum was black text on a light grey background. reply jameshart 16 hours agorootparentprevThere's no 'likely' about it the Mac absolutely used white as its background color for document windows and finder folders. It was striking and different when you first encountered one of the early compact Macs to see how white the screen was when you opened MacWrite. As for the claim that Macs had no 'mainstream use' for 20 years until the Intel switch... your personal Mac-free life is a sad story, but not remotely universal, and while it's certainly true that Macs always had minority market share, it's insane to suggest they weren't influential. reply int_19h 15 hours agorootparentprevMy favorites were actually DOS TUIs, where for some reason blue became a commonly used background color for a lot of things (e.g. Norton Commander, many Borland products, FoxPro...). reply pjmlp 8 hours agorootparentprevAmigas used blue and Atari GEM, alongside DR-DOS and MS-DOS Doshell used white. reply morning-coffee 20 hours agorootparentprevYeah, it wasn't Windows that changed it, they just hopped on the bandwagon. I remember (SunOS)[https://en.wikipedia.org/wiki/SunOS] on a SPARC in 1987 that was black in white text, and Macintosh before that. reply mrob 16 hours agoparentprevDark mode was normal in the early days of CRTs, when most CRTs refreshed at 60Hz or lower. The dark background made the flicker less obvious. Once higher refresh rate CRTs became common (1990s), the flicker became less of a problem and light mode became the default. reply ssivark 19 hours agoparentprevTraditionally we were using CRT monitors and 80x24 terminals... it feels silly to hold on to that out of inertia. reply nedt 5 hours agoparentprevBeside it not being true for paper it's also not true for electronic screens. Before a computer with CRT most of us had some simpler screens on calculators or other devices that were LCDs. And they are blackish on some lighter gray or green light mode. reply arp242 18 hours agoparentprev> It was Microsoft Windows that changed the paradigm to default to a searing white display with black text in most apps My early 90s Sun SPARCStation was black on white, right from the boot. The xterm default is black on white too, a default that far predates Windows AFAIK. I don't really know the full history on all of this, but in my limited knowledge, this seems grossly simplified at best since there seem to have been several popular systems before Windows that used white background colours. [1]: Video: https://www.youtube.com/watch?v=f72A9AHigeQ reply Tomte 18 hours agoparentprev> Sure, paper is white, but it's not glowing white It‘s your fault if you set your display to glowing. My displays, depending on the model, have their brightness setting between zero and thirty. reply cosmic_cheese 14 hours agorootparentI’m glad those brightness settings work for you but I can’t deal with how dull it makes colors look on traditional backlit displays. The reduced contrast also isn’t very fun with modern UIs which for some reason actively avoid good contrast. reply Aaargh20318 18 hours agorootparentprevZero and thirty what? reply laristine 16 hours agorootparentI guess they meant out of 100, with 100 being the brightest for their screen. reply FartinMowler 17 hours agorootparentprevAnd the speakers set to 11? reply sosowhitewhite 16 hours agoparentprev> That transition was painful. I was actually alive then, so I can speak to it. Athena text widgets on X were black on white in the 80's. So was Lisa, Mac, and NeXT, OS/X and SunOS's first GUI. Yes, amber on black was long running, but since you weren't alive then let me tell you something: it sucked. Moving from VT100 (VT104) terminals to actual Sun/Aix machines running X was a HUGE improvement on eye strain. reply 1000100_1000101 48 minutes agorootparentI was actually alive then, and the painfulness of the white background was real physical eye-strain pain. I was alive for both amber and green screens too. Please don't suggest people are making things up from times before their birth simply because you have a different view. reply markhahn 16 hours agoparentprevwindows originated very little: plenty of type-on-page metaphor predated it. original was light mode: printer terminals. yes, green-on-black became normal in the mid seventies, and some amber-on-black. but even early lisp machines, the Alto, Smalltalk, W/X/Andrew interfaces, Next, etc type-on-page, not serial-terminal-ish dark mode. reply kazinator 15 hours agoparentprevIn a darkened room I adjusted my first amber monochrome monitor for low contrast and brightness. Wow that was great! I thought. It was similar to what the author of the article prefers to dark mode: not-too-bright text on not-too-dark a background. reply snakeyjake 16 hours agoparentprevThat was only common for a blip in time where NOTHING was normal because it was all being figured out and cost constraint, not personal or ergonomic preference, drove computing capabilities. > Even GUI wise, Amiga used a dark-blue background as the default Workbench That's because of cost. It was expected that many people would be viewing Amiga video output on a television via composite output and white-on-blue is something that TVs are good at displaying. The 1080 was like 1/3rd the cost of the A1000 and I'm willing to bet that many, MANY A500s were hooked up to TVs for at least a while after being opened on Christmas. I used practically every word processor ever made for Amiga. Except for WordPerfect they were all black text-on-white, and WordPerfect you could change that they just kept the default blue and white to match DOS. reply jemmyw 20 hours agoprevWell hang on a sec. If a website is dark with light text and has just that one style, then that's it's theme, it's vibe. Dark mode only exists if there is a light mode, and give versa. Don't force having to maintain two modes on websites who don't want to? reply charles_f 20 hours agoparentThat's exactly what the article says, right at the beginning > If dark mode is a characteristic of your brand, please ensure you choose a comfortable contrast ratio for the text. reply gabeio 19 hours agorootparentI think the poster was talking about phrasing, “dark mode” implies there are modes to switch. The article seems to incorrectly be conflating dark mode vs dark themes. Dark themes tend to be unadjustable. IMHO I usually just flip to the reader mode on my phone browser or desktop browser when I don’t like the theme of a website. This obviously doesn’t work for all websites but it’s a nice work around since most reader modes allow you to adjust coloring yourself. reply benatkin 19 hours agorootparentprevThey actually are saying that nobody should have dark mode sites, except watered down ones. What are these \"dark-mode\" (misnomer) sites that don't have a comfortable contrast ratio? I know there are some, but I think they're including a broad swath of primarily light-on-dark sites in this group. Adjust the brightness on your screen. X's is pretty good, the background is #000000 and there is some #ffffff content, the text is a bit farther from #ffffff than I'd like but pretty close. https://colorpalettecombos.netlify.app/ reply oooyay 18 hours agorootparentprevCuriously, the contrast ratio wasn't a good signal for me. The white on black text didn't strain my eyes but this did: > However, light gray text on a dark gray background is easy on my eyes. Here the background is #666 and the text is #E0E0E0 which creates a contrast ratio of 4.34:1. reply mmis1000 17 hours agorootparentGithub used to do this. The result is their dark mode isn't useful for anyone. However, They revamped their color scheme later and made it comfortable to read. reply smlavine 21 hours agoprevI agree with this. Default, unconfigurable light mode has been around for a while, and infrastructure like the Dark Reader plugin is around to address this. There is no such thing for light mode, though. In my opinion, light mode is better than dark mode in most situations. The only situation dark mode is better than light mode is when you're sitting in a dark room with your screen as your only light source, and most of the time that's not really a healthy situation to be in. Dark mode is a crutch. Turn on a light or go to sleep. Light mode might be annoying to read in no-light environments, but dark mode is nigh impossible to read in high-light environments. Ever try to read a dark mode UI on your phone on a bright summer's day? Can't read a thing, even with brightness cranked all the way up. reply bee_rider 20 hours agoparentOn my system, the dark reader plugin also has an option to force a light theme. Actually, the browser has the ability to set a default background and foreground anyway, so this extension would be unnecessary if websites would behave properly and respect these defaults unless they really need to. We live in an unfortunate world where a “actually respect my preferences” extension is necessary, but since it is necessary, it should be noted that it covers both options. Overall the situation is pretty stupid but hey at least we’ve got workarounds, right? reply aniviacat 18 hours agorootparentBrowsers shouldn't set a preferred colour scheme by default. I think the prefers-color-scheme media query would be respected on more sites if by default it had the value \"unset\" or something, instead of defaulting to \"light\" or \"dark\". I personally don't respect it on my sites for this reason. 99% of people visiting my sites won't actually have set this value themselves. reply steve_taylor 16 hours agorootparent> 99% of people visiting my sites won't actually have set this value themselves. It's inherited from their operating system settings. Dark theme is typically opt-in. reply Kamq 17 hours agorootparentprev> Browsers shouldn't set a preferred colour scheme by default. I mean, they really don't (the defaults are exactly what they have been since Mosaic left the scene). Unless the user tells them to do something else. And at that point, it's my computer, and I told it to do something, why shouldn't it do that? reply philwelch 13 hours agorootparentprevActually, websites shouldn’t set a preferred color scheme by default. reply BugsJustFindMe 20 hours agoparentprev> The only situation dark mode is better than light mode is when you're sitting in a dark room with your screen as your only light source, and most of the time that's not really a healthy situation to be in. Dark mode is a crutch. Turn on a light or go to sleep. It's always been strange to me how many people without a medical reason for doing so want to sit in dark rooms like cave trolls, but there we are. At least now operating systems all have switchable modes that get reported to the browser. The browser can/should adapt to whatever setting the OS reports. But UI design is, with a few islands of rationality in history from people like Paul Fitts, mostly a cascade of poorly applied vibes and fads. First people say that contrast is bad, so then people don't use enough contrast. Then people say that brightness is bad, so people don't use enough brightness. Then people realize why contrast and brightness were important all along and the circle of life continues. reply cosmic_cheese 20 hours agorootparent> It's always been strange to me how many people without a medical reason for doing so want to sit in dark rooms like cave trolls, but there we are. As a millennial, I grew up with rooms being lit by 1-3 relatively dim lampshaded 40-60w incandescent bulbs at night. As a result that’s what feels comfortable and relaxing to me as an adult. Rooms at home being brightly lit at night feels grating and reminiscent of a grocery store or hospital or something. reply Doxin 10 hours agorootparent> Rooms at home being brightly lit at night feels grating and reminiscent of a grocery store or hospital or something. Look into getting warm white lights. For some reason cool white lights are super common while I do think most people at home would actually prefer warm white. Things can be bright and cozy. reply cosmic_cheese 4 hours agorootparentOh yeah, I’m a big fan of warm lights and have been using them for a while. Still don’t like them bright at night. Lights that are indirect (e.g. under counter) I can deal with being considerably brighter but for your typical table/floor lamp, 60W incandescent equivalent is the upper limit. I don’t like ceiling pot lights at all unless the bulb can be dimmed. reply carlosjobim 20 hours agorootparentprev> It's always been strange to me how many people without a medical reason for doing so want to sit in dark rooms like cave trolls, but there we are. Because screens are not bright enough to use outside or in well-lit environments. If E-ink or similar technology manages to get a bit better refresh rates, it's going to change building architecture in the entire industrialized world. reply BugsJustFindMe 18 hours agorootparentI'll grant you outside, because the power of the sun is immense, but they're definitely bright enough to use in any well-lit indoor environment. Do you mean if the lights are behind your head instead of overhead? That's either bad lighting or bad ergonomics, and I'm sorry if you must suffer through that. That sucks. An ergonomic screen arrangement, with the display placed such that you're not looking downward at it, should make it basically impossible for an overhead indoor light to interfere with your view. > If E-ink or similar technology manages to get a bit better refresh rates, it's going to change building architecture in the entire industrialized world. Fingers crossed. I remember yearning for the breakout of transflective displays that never happened. reply carlosjobim 7 hours agorootparentI don't think I phrased that right. What I mean is environments with a lot of natural light, for example from big windows. Or a café without walls to the outside, letting the sunlight in, but not right overhead. I guess this kind of architecture is not so common in colder countries, now that I think of it. The sun is tyrannical where I live, so with current display technology, offices are indeed built somewhat like caves. reply tunared 20 hours agoparentprevAs someone that had cataracts, light mode was very hard to read. It was like looking directly into high beams. I used a dark reader plugins that was alright, but was not the same as a site designed to support dark mode. reply kps 16 hours agorootparentYes, and for someone with astigmatic halation, dark mode is very hard to read. Web sites should support both, and respect `:prefers-color-scheme`. reply tbrownaw 20 hours agoparentprev> * only situation dark mode is better than light mode is when you're sitting in a dark room with your screen as your only light source,* Also maybe if you set your screen brightness inappropriately high. reply lukan 20 hours agorootparentOr if you are sensitive to light. I feel kind of traumatized for years of forced light mode everywhere. It hurts my eyes. In bright sun when outside, I use light mode. Allmost everywhere else, I won't. So please @everyone thinking like this, don't assume, what is best for me, because your taste is different. reply Zak 20 hours agorootparentprevA difficulty is that the appropriate screen brightness varies with the content it's displaying. Going from a low-contrast dark site to a white background is especially jarring. reply jezek2 19 hours agorootparentWith a properly set monitor and gamma setting there is no issue with switching between light and dark mode at all (even in a pitch black room at night). I use it regularly, I prefer light mode but I also use dark mode for stuff like terminals. So I switch a lot between these. I have written another post about how to set the monitor: https://news.ycombinator.com/item?id=42762770 reply Zak 19 hours agorootparentYour proposal is to decrease the dynamic range of the display. This will certainly achieve the goal of making switching between light and dark backgrounds more comfortable, but makes it worse for viewing photographs or videos. It's also not ideal when doing any amount of design, as most viewers won't have their screens set up the same way. reply jezek2 18 hours agorootparentPhotographs and videos seems allright to me, maybe I'm just used to it. I like that the dark regions are visible (esp. when IPS LCDs have not that great blacks due to the backlight). I always hated it on CRTs where photographs were too dark, had to use a really big gamma correction on them (2.5), I guess I've got used to it from these times because it was a necessity to be compatible with LCDs. The photos and videos are more dull when compared to a reality, but consistent with other stuff on the screen. I have no problem doing color stuff for things like textures, website design etc. The relative comparison to other material is enough for me. I've been working with graphics designers with calibrated monitors and didn't get any complaints. But I don't do anything that requires working with calibrated monitors, like printing. Though it's hard to tell if it would be an issue. You need to do test prints anyway. You have to use specific named colors (Pantone). Based on that you can just imagine how it would look, no need to have it precisely shown all the time. reply jltsiren 20 hours agorootparentprevOr from text and diagrams (which often contain large single-color areas) to photos and videos. The default HN color scheme looks much brighter than the bright daylight photo I currently have as a desktop background. reply jezek2 20 hours agorootparentprevYeah, most people use their screens with brightness cranked up and then wonder why they have all sort of problems. The trick is to set a low brightness, in my case it's a little below what you would call comfortable, but that's because you adapt to it in a sec and will be perceived as good. If you can't set it too low on the monitor, set brightness to 0 and lower the contrast. If it's still too bright use also brightness/contrast controls in your GPU settings. It is also needed to adjust the settings during the day. But having a more controlled light in your room is a better option. Once you start getting comments from others that they can't see shit on your screen then you've set the correct level :) Another very often forgotten thing is to set up correct gamma correction! Yes that thing from CRTs is often needed on LCDs too! LCDs can produce quite big contrast which is unpleasant, for example I set mine to 1.3, fixed it nicely for me. One approach to find a good value is to have antialiased text both in white-on-black and black-on-white and switching between these. Once the apparent thickness is the same then you've got the right value. Beware of ClearType settings though, you may need to do the test with a classic antialiasing instead. The result is that you can comfortably use light mode in total dark room without any issues. reply LtWorf 19 hours agorootparentI don't really want to spend 5 minutes every time to open the 25 menus my screen uses to change the brightness. reply jezek2 19 hours agorootparentYeah monitor controls can be a problem. You can download an utility to set it from the computer, it's much more comfortable. I'm using one from my monitor vendor, but there are also generic ones. Search for utilities that can set the monitor using DDC (Display Data Channel). reply hiAndrewQuinn 20 hours agoparentprevI like Pure Black mode because the black pixels actually turn off on my screens, making it much more pleasant to look at. Even in broad daylight! I wish Pure Black mode was an option separate from Dark and Light mode, like it is on some Android apps. For now I get by by minimizing brightness in Dark Reader, but it is a bit clunky. reply cwbriscoe 20 hours agoparentprevI never knew about the Dark Reader plugin. I just installed it and it makes HN, Slashdot and other sites much more readable for me. Thanks! reply bhauer 20 hours agoparentprev> Light mode might be annoying to read in no-light environments, but dark mode is nigh impossible to read in high-light environments. Backlit screens are difficult to read in high-light environments regardless of whether you're reading black text on white or white text on black. I use white-on-black (\"dark mode\") on my e-ink Kindle to read outside all the time. And the same is true on our Daylight computer. White-on-black remains my preference in high-light environments. reply walthamstow 20 hours agoparentprevI agree broadly but in London it starts to get dark about 3pm at the moment. In the winter, dark mode is a lifesaver. reply jorams 20 hours agoparentprev> The only situation dark mode is better than light mode is when you're sitting in a dark room with your screen as your only light source It's really not that extreme. Dark mode is more comfortable as soon as it's dark outside (this time of year that starts between 3 and 4 pm) unless I'm flooding my entire room with enough light to replace the sunlight. I still have the lights on, but none of that light is as bright/white as an average white webpage. Even with screen brightness turned down and a blue light filter, an all-white webpage is usually just too much white. > Light mode might be annoying to read in no-light environments, but dark mode is nigh impossible to read in high-light environments. This is just completely opposite for me. Reading in dark mode is only uncomfortable if there's sunlight basically directly behind the screen, while light mode is only really comfortable in high-light environments. reply eikenberry 19 hours agoparentprevLight/Dark modes at their extremes are both annoying. White on black or black on white are both to extreme. The best solution IMO are mid-level colors. I personally prefer the schemes with darker grey backgrounds and lighter grey (or other lighter color) foreground, but the opposite isn't bad either. What are bad is that the default light modes are generally much to light. A random site I have open right now has a background color of #f2f2f2 w/ text color of #151515, it is only tolerable to read if I have my monitor red-shifted to around 4200 degrees (in a well lit room w/ lots of natural light). reply CrimsonRain 20 hours agoparentprev> most of the time that's not really a healthy situation to be in Please explain. reply smlavine 19 hours agorootparentSleep hygiene. I'm in college and I know too many people that waste away online until 3am and are always tired and then down coffee after coffee during the day. reply lxgr 17 hours agorootparentOther than that, > sitting in a dark room with your screen as your only light source is also really not great for your eyes, in the same way that having a bright light source in your field of vision (e.g. a window without blackout shades directly behind your monitor) isn't either. reply cosmic_cheese 20 hours agoparentprevI use dark mode during the day in rooms with lots of natural light spilling in because that’s what’s felt better to me ever since we collectively decided that light themes need to use stark white and very light grays instead of the mid-grays dappled with mid-colors that used to be popular. Dark mode is a bandaid for the needlessly bright themes that became the norm with the advent of flat design. reply wruza 20 hours agoparentprevI use dark mode in a (moderately) lit room, because it makes me focus better. Even colorschemes can affect my state of mind and make it work differently. I’m not even talking about effectiveness here, just comfort, although they correlate. I can’t just choose light mode. When screen is too dark (sunlight, etc), I make it brighter. Requires >=400 nit or whatever that unit is for an average day. reply bobmcnamara 20 hours agoparentprevDefault, unconfigurable dark mode has been around much longer. reply accelbred 20 hours agoparentprevAll the dark mode extensions I've used also would work for making pages light mode. For me, I have trouble focusing when reading light mode content, but dark mode is perfectly fine (light backgrounds seem not still, as if there is movement, and this effect lessens the darker the background is. reply jltsiren 20 hours agoparentprevIn my experience, high contrast dark mode is readable in high-light environments, but it causes the issue the images in the article show. Beyond that, I have no preferences between light and dark modes on laptop screens and smaller. But I prefer having at least some dark elements visible on large screens, because floaters can be distracting against large bright surfaces. Usually it's a terminal window with the traditional light gray on black color scheme, but I tend to use dark mode in IDEs and other full-screen apps. reply rerdavies 17 hours agoparentprevOn my phone I go to dark mode when I'm reading ebooks in bright sunlight. Not sure this a universal experience. reply whalesalad 20 hours agoparentprevNah some of us need dark mode 24x7 and actually benefit from it even in broad daylight. Not fair to make this assertion and assume everyone is like you. reply nunez 4 hours agorootparentBut thats what browser extensions and high contrast mode are for reply leptons 20 hours agoparentprevAre you confusing the brightness setting on the display with \"dark\" and \"light\" mode? Because I always have the brightness on my monitors at max when the lights are on. I practically never change it. As a software developer, who codes about 15 hours a day (day job and personal projects), I ditched \"light mode\" many years ago as it's too harsh on my eyes to be staring at a bright white screen that many hours a day. Dark mode is far easier to look at for long periods of time. I have no trouble reading code in dark mode in a well lit room. If it were difficult to read, it wouldn't last 15 minutes for my needs. I don't code in \"D4rK M0D3\" in the dark, I'm not a l337 H4CK3r. >Ever try to read a dark mode UI on your phone on a bright summer's day? Phone in direct sunlight is one thing. That isn't the way most people use devices, that's a more rare use case than sitting at a desk 8 hours a day staring at a bright screen. There are also high-contrast modes for eyesight challenged people, which can be used effectively in bright sunlight too, but I'm not going to code that way for hours a day if I don't really need to. Phones and other devices also have adaptive brightness, so if you are in a dark room the phone's display brightness is going to be dimmer automatically, and I'm not really sure you know the difference between \"dark mode\" and \"brightness turned down\". So using a phone screen and high contrast required for using screens in direct bright sunlight is a poor example to support your argument. Maybe you also need to qualify all of your arguments with \"on a mobile device in bright sunlight\", because that isn't the main use case for \"dark mode\". reply lxgr 17 hours agorootparent> I ditched \"light mode\" many years ago as it's too harsh on my eyes to be staring at a bright white screen that many hours a day. [...] I always have the brightness on my monitors at max when the lights are on. If your screen at the brightest setting hurts your eyes, why would you use it like that? reply leptons 15 hours agorootparentI enjoy the full brightness of the display when it calls for it, when watching videos or video games, when the screen isn't 99% full-on white pixels. I also enjoy the crispness and contrast of white text on a dark background when the display brightness is at maximum. No, I do not enjoy using a display at low brightness, and I really don't like being blasted by full-on white background with dark text on it all day every day. reply nfw2 21 hours agoprevThis particular blog doesn't heed device settings and, as such, forces light mode on its readers. The author also changes their mind halfway through and decides the problem is actually color contrast, not dark mode. reply gregmac 20 hours agoparentThe author's blog also explicitly defines color: #111; background-color: #fdfdfd; which is a contrast ratio of 18:56:1. reply Springtime 20 hours agoparentprevYeah their actual point is about contrast ratio, which makes the headline a bit disingenuous. Ironically they end by saying they'll use an invert filter as a workaround, while for those who prefer dark mode if doing the same on the author's own stark white bg/black text site (such as Vivaldi's 'Invert Mode') will produce the very contrast ratio in dark they're complaining about :p reply josephg 20 hours agorootparentYeah and an invert filter messes up photos. Again, like the author has on their blog. If you wanna argue that we shouldn't force dark mode, maybe don't go around forcing light mode. My eyes hurt. reply lewiscollard 17 hours agorootparentThen un-mess them up :) html { filter: invert(1); } img { filter: invert(1); } Bookmarklet edition: javascript:(function(){var s=document.createElement(\"style\");s.innerText=\"html{filter: invert(1);}img{filter: invert(1);}\";document.head.append(s)})() (doesn't and can't fix CSS \"background-image\" but you'll live) reply kiririn 20 hours agoprevPlease don't force low contrast ratios on users. Not everyone is calibrated to >100 nits and viewing your content in a bright but sensible ambient environment The recommended grey-on-grey may be unreadably low in contrast when viewed on, for example, 0 brightness in a pitch black room, or in direct sunlight The full SDR colour range is there to be used, this isn't HDR where you need to limit things to not blind your users reply deadmutex 19 hours agoparent+1, grey-on-grey can be hard for older folks too reply ryandrake 20 hours agoprevNot just light vs. dark. I wish web sites would respect my system's preferences in general. If my OS theme is purple Comic Sans text on top of a yellow brick wall background, then my browser should respect that. I want to read text using the full width of the browser rather than a tiny 5 inch column down the middle of it, I shouldn't have to perform wizardry in the browser settings, conjure up some overriding CSS, or install extensions to do this. The browser should just say \"tough shit, web developer, the user's preference wins.\" Browsers have handed over way too much control to developers to ignore what the user wants. So much for being a \"user agent.\" Browsers are more like the developer's agent. reply worble 20 hours agoparentWell, there's not much you can do about yellow background, but forcing Comic Sans is as easy as setting it as your preferred font and then deselecting \"Allow pages to choose their own fonts\", at least in the Firefox settings page. This is what I do and it makes browsing the web so much better. reply robertclaus 20 hours agoparentprevDo desktop apps or anything else really respect this? reply Borealid 20 hours agorootparentDesktop apps using a UI toolkit like qt, gtk, wpf, etc do by default. The developer needs to do additional work to un-standardize their application. reply ryandrake 20 hours agorootparentYes, and too many applications go out of their way to ignore user preferences on desktop, too! It's a major problem IMO. The user should be in charge of their computer. reply int_19h 15 hours agorootparentWhen owners of the platforms themselves ignore their own UI standards to \"brand\" their apps, it's tough to blame the devs for following suit. reply lxgr 17 hours agoparentprevSounds like you want to use reader mode by default? Some browsers allow that. reply watwut 5 hours agoparentprevI do not want that, I want to choose scheme for each site/app separately. Some of them have great dark mode, others insane one. Same for white. reply Brajeshwar 17 hours agoprevToo many web developers assume everyone loves Dark Mode, default to that, and defend their choice by pointing to the toggle button that says Dark/Light Mode. I’m surprised many, even with freshly done websites, still do not pick up on the user’s preferences and are set to it! For developers, the `color-scheme` CSS property allows an element to indicate which color schemes it can comfortably be rendered in.[1] :root { color-scheme: light dark; } element { light-dark(light-color-code, dark-color-code); For users on macOS, I like dark mode in some cases, such as the Menubar and the IDE, but light for other activities, such as reading, writing, and browsing. Hence, it is a mixed preference; System Preferences, then set the theme to LIGHT, then run defaults write g NSRequiresAquaSystemAppearance bool Yes Logout, then System Preferences, then set the theme to DARK. Reset back to the default theme. defaults write g NSRequiresAquaSystemAppearance bool No 1. https://developer.mozilla.org/en-US/docs/Web/CSS/color-schem... reply Yizahi 8 hours agoprevPersonally I prefer light mode, but when using dark theme, for example in the IDE or terminal, I always manually set white brightness to 255 (max). For example Putty and other apps, come with default theme 192 on black and that is unreadable. Double so if someone is sharing their screen. Dark mode is already harder on the eyes and harder to focus, and making it less contrast makes it even harder to read. PS: unless you are adhering to a system default, you better include options for everyone, not just one demographic. For example after recent redesign ArsTechnica has created a selection of different modes. And while some people like darker mode, I'm happily using \"hyperlight\" because it is easier to read for me. reply nottorp 20 hours agoprevFunny because i find the blog's example of \"readable text\" extremely hard to read. Because of the low contrast. What kind of eye condition or monitor does he have? reply magnetowasright 5 hours agoparentYES! I cannot understand the grey on grey on grey anti-readability obsession. I cannot stand it. It's ugly and hard to read. I wish we'd all just stop doing it. reply pclmulqdq 20 hours agoparentprevIf I had to guess, he has an extremely expensive HDR monitor aimed at designers and uses the full color gamut for everything. reply nottorp 19 hours agorootparentWell, i'd like to remind him that designers are supposed to \"design\" for users. Who may have a used monitor they paid $50 for and it's from 2003... reply nshxhzhz 13 hours agoparentprevI prefer light mode as well but the grey text is much more pleasant to read then the white text on my ~$300 screen reply londons_explore 20 hours agoprevThere is a web API to figure out if the user is in dark mode. use it. @media (prefers-color-scheme: dark) { CSS Rules here... } reply constantcrying 3 hours agoprevDear website designers, Please don't force light mode. Light mode is only reasonable on E-Ink displays, where white is only reflective and does not emit light. >Every time I finish a long article, I end up seeing horizontal stripes everywhere I look, like my eyes just won’t let it go. I would seriously consider talking to your doctor about this. This seems abnormal. reply jrockway 20 hours agoprevDark Reader turns dark mode sites light, if you want. You can control the contrast ratio on dark mode websites with the \"brightness\" control on your monitor. It changes the emissivity of the pixels. Turning it down keeps black the same color and makes whites blacker. Monitors typically ship with the white level way too high for any real work (it looks good in the computer store though), and so you should probably always be turning this down. reply SOTGO 20 hours agoprevI'm glad this article included an example of what happens to their eyes when they read text in dark mode. I get the same afterimages and it's incredibly disorienting when it happens and dark mode makes it way worse than normal. As an aside, does anyone know if that effect has a name? reply oliviergg 20 hours agoparentYes, I am glad to see this post, because I had the sentiment to be alone with this ‘symptom’. Can’t bear dark mode, it give me disorientation and nausea. I wasn’t able to explain this to my ophthalmologist. reply snovymgodym 19 hours agoparentprevYou might have this. (I do as well). https://en.wikipedia.org/wiki/Illusory_palinopsia reply recursivedoubts 20 hours agoprevDark mode was a mistake. Early LCDs were dim so everyone cranked up the whites to make up for it. Now LCDs have caught up and it burns a significant number of peoples eyes, so we increasingly have to support two modes. Apples comically ugly dark mode icons shows how hard this is to do well. I think the ideal thing to do would be to move back to greys as the base color for computer interfaces, like we had when bright CRTs were the norm. This has the added advantage of allowing depth affordances in UI elements, which we should also bring back. reply enlyth 20 hours agoparentThat's just like.. your opinion man. The whole point is it should be configurable so users can set their preference. Personally I am blinded by light mode and it hurts and strains my eyes, everyone is different. reply recursivedoubts 5 hours agorootparentread the rest of the comment and the adjacent comments on CRT brightness reply layer8 20 hours agoparentprevCRTs also had easily adjustable brightness and contrast dials, so everyone could always quickly adjust to their preferred setting for black on white or vice versa. reply eikenberry 20 hours agoparentprevIsn't \"greys as the base color\" what dark mode is for the most part? Light mode is generally off-white and dark mode is grey scaled. reply recursivedoubts 20 hours agorootparentNo. You can't do drop shadows in most dark-mode setups, there isn't enough contrast to make it work. OS9: https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2F... Windows NT: https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2F... BEOS: http://toastytech.com/guis/b5pebaqua.png reply masswerk 19 hours agorootparentRegarding the BeOS screenshot: mind that this is not regular BeOS, but the OS X-like \"Baqua\" appearance of the eOS 5.1d0 developer release, which never saw a regular release. (I'm taking no offence, but it may be important to point out what's what, now that image references are becoming as inevitably as increasingly unreliable, as for \"AI\".) reply tom_ 19 hours agoprevNo, please do force dark mode. This will make the dark mode people think they have won. They will act accordingly. And then the pendulum will swing back, as the pendulum always does. But the difference this time is that because the dark mode people are wrong, and always have been, and always will be, when the pendulum swings back, it will swing hard, for it will swing with the momentum of righteousness and truth, and the repercussions will ring through history. Ask yourself: where will you be standing, when this happens? reply anserin 3 hours agoparent> the dark mode people are wrong What is that supposed to mean? Some people find it more pleasant to read on a dark background (e.g. because of photophobia), some prefer it for aesthetic reasons (e.g. for a site about space exploration), how is that ‘wrong’? reply lhamil64 4 hours agoprevIt's funny, the author says the high contrast hurts his eyes, but for many visually impaired users (myself included), light mode is like a blinding white light that's very hard to look at while dark mode is very comfortable while still having high contrast. IMO every website should have a native dark & light mode theme. There is a browser extension, Dark Reader, which changes the CSS to force dark (or light) mode but it can be really hit or miss depending on how the site was coded. reply HellsMaddy 21 hours agoprevThanks for posting this, it's an interesting perspective that I hadn't considered before. Ideally, sites would respect user preferences such as prefers-color-scheme and prefers-reduced-motion. And, in fact, I just checked MDN and see there is prefers-contrast: https://developer.mozilla.org/en-US/docs/Web/CSS/@media/pref... reply kenanfyi 21 hours agoprevAnthony Hobday [1] has some pre-defined color combinations on his website. Sharing, since I find it related. [1]: https://anthonyhobday.com/sideprojects/containercolours/ reply nedt 5 hours agoprevI even more so would need a switch for anything on my screen, not just websites, including screen sharing. It's fine for anyone having a preference, but I like light-mode and being in a well-lit environment for work, if not even outside. When then someone shares their screen in dark-mode I can read nothing. reply adxl 6 hours agoprev\"iMessage\" has dark mode. Anytime I send a picture it shows up in reverse when in dark mode. I don't really care what other people prefer, software manufacturers with any more than a few users need to test all permutations. This is a minor annoyance but gives a clear indication that there isn't good testing even with one of the most used apps with a huge user base. reply lol768 21 hours agoprevI very rarely stumble across sites that genuinely force dark mode.. they usually respect \"prefers-color-scheme dark\" (as they should). reply jbritton 19 hours agoprevI actually prefer text as #fff and background as #000. Lower contrast just seems harder to read. I suppose it depends on brightness setting. Also from an article in Nature. “Impact of text contrast polarity on the retinal activity in myopes and emmetropes using modified pattern ERG” 09 July 2023. “Recently, reading standard black-on-white text was found to activate the retinal OFF pathway and induce choroidal thinning, which is associated with myopia onset. Contrarily, reading white-on-black text led to thicker choroids, being protective against myopia. Respective effects on retinal processing are yet unknown.” reply brine 20 hours agoprevInstead of writing this shortsighted article, just do like those of us who are forced to endure light mode, and install Dark Reader(https://darkreader.org) that also does light mode. reply xnx 20 hours agoprevAs long as were asking: Don't set color, typeface, font size, link color, visited link color, margins, spacing, line height, etc. either reply moffkalast 19 hours agoparentI mean this does exist and is already integrated: Reader mode. OP could just use that if they want to get rid of styling and get a consistent look. reply xnx 19 hours agorootparentAgree. I installed an extension for reader mode since it is so buried (no shortcut key) and limited (only appears in sidebar) in Chrome. reply nighthawk454 20 hours agoprevContrast ratios don’t go away in light mode. The contrast ratio of black-on-white is the same as white-on-black. Curious then what is the real driver of these issues? If accessibility teaches us anything, it’s that there’s certainly no one size fits all. But it’s gonna be hard to update the standards or make plugins/tweaks successfully unless we get at the root of it. reply seanwilson 7 hours agoparent> Contrast ratios don’t go away in light mode. The contrast ratio of black-on-white is the same as white-on-black. WCAG is known to be inaccurate for dark mode because contrast ratios do change when you switch the color order. See this improved way to measure contrast that takes this into account: https://git.apcacontrast.com/documentation/APCAeasyIntro.htm... reply secretsatan 8 hours agoprevI feel old, having black as the background is not \"Dark mode\", it's the default. In many cases I can understand the sentiment, but the default for background is no colour, I think for all hardware, that means not emitting anything reply dgeiser13 20 hours agoprevIt's interesting how they don't want forced dark mode yet they have no problem with forced light mode. reply nedt 5 hours agoparentAt least on iOS there is beside the normal dark mode also some kind of simulated dark mode that inverts everything that's still light, expect images. There same is not available for people preferring light mode. reply mcv 19 hours agoprevI think this is something browsers should enforce. Different people may have different preferences for what they consider comfortable contrast ratios, and the tool in the stack that directly serves the user, is the browser. And even if websites should consider proper design, browsers should also enforce user preferences, because badly designed websites will probably always exist. I'd suggest browsers come out of the box with a decent contrast range that they will use to display text, but users should be able to modify those settings. In general, browsers should be a lot more willing to override bad webdesign ideas. They already block popups and blink tags; there's plenty of other behaviour they simply shouldn't tolerate from websites. reply rerdavies 17 hours agoprevWondering whether the author has some kind of odd medical condition, and how common his experience is. The after-image symptom he describes is decidedly peculiar. I can't say that I share his opinion. I find dark-mode preferable under pretty much all circumstances, and often find myself flinching when switching to a site with a fully white background.I also find it easier to read ebooks in dark mode when in full sunlight when reading on my tablet also the opposite of his preference. And I'm wondering whether perhaps he needs to turn down the brightness on his monitor. reply qwerty456127 19 hours agoprevHow comes this isn't obvious to someone they should just respect the OS/browser settings and use the color scheme the user chose? I prefer black on white (and dream of a eInk-only laptop and a perfectly lo-fi UI with no unnecessary elements/decorations/effects) because that feels more ADHD-friendly to me. Dark modes look cool and make sense when you work in the dark, as long as you set the text font color to grey rather than bright white/green/whatever. The user should choose, using a single system-wide switch. reply poisonborz 21 hours agoprevWe've again came to full circle, with so many posts damning \"no dark mode\" sites back then. Maybe there is enough audience now for a \"BrightReader\" browser extension? reply djeastm 19 hours agoparentDark Reader can force light mode. It's just that most people want it for the dark mode functionality, so that's what they called it reply Myrmornis 19 hours agoprevIt seems much easier for terminal and IDE apps to choose background colors to apply to sections of code when your app background is light; with a dark app background it seems harder to find pairs of text bg and fg colors that are clearly distinguishable and also distinguishable from the app background. That said, I'm the author of an app with this challenge so would love help/suggestions on this front. (Is there any theoretical reason for it to be true?) reply prmoustache 11 hours agoprevLet people do the f they want and be creative. I am free to ignore these websites if I don't find them easy to read, I can use reader mode, modify their css or disable css altogether if I am not happy, as everyone else. reply layer8 20 hours agoprev> pure white text on a pitch black background can strain my eyes and be very difficult to read. […] However, light gray text on a dark gray background is easy on my eyes. For me it’s the opposite, I need maximum contrast. It’s a pity we can’t just have default text color on default background color, and everyone can adjust their browser to their preferred colors. While there is reader mode and plugins that try their best, they don’t work consistently, because HTML and CSS is such a mess. reply skeledrew 19 hours agoprevFunny I have just the opposite problem. And so I use a dark reader add-on in Firefox to force light sites, and curse any app that only provides a light theme. reply thdhhghgbhy 20 hours agoprevI'm more extreme, I dislike all dark mode, including code. Shreds my eyes, no idea why. Have tried a zillion themes, just can't be one of the cool kids. reply drpixie 20 hours agoprevSeems like a fashion thing, but the Linux distribs I've recently checked out all defaulted to a dark mode. Fine for night but a pain to read normally :( reply londons_explore 20 hours agoprevIf the contrast ratio is a problem for your eyes, just turn down the contrast on your screen. I'm sure there are filters to do that on both desktop and mobile. reply reddalo 20 hours agoparentI don't agree. I have the same problem described on the article; I can't read websites with white text over a pitch black background. My eyes hurt after a while. At the same time, I use a dark theme on my IDE, but it feels like it's better on my eyes for some reason. reply layer8 20 hours agorootparentThat’s because the dark theme of your IDE also uses lower contrast. Which makes it hard to read for other parts of the population, even if they otherwise like dark mode. Contrast should be a user setting. I’m dating myself, but this was all so easy with CRT monitors, which had a simple analog contrast dial, and everyone just set it to their preferred level. reply zeta0134 19 hours agoprevPlease don't force light mode either. :) My astigmatism means that I find dark mode on backlit screens to be far more readable. For proper accessibility, include both and respect the browser/OS user preference accordingly. Allow the user to override that on a per-app basis if you're feeling fancy. reply interloxia 15 minutes agoparentI find this hard to understand. I find that ghosting due to my astigmatism is far more effectively hidden with light themes. More extreme dark themes tend to be illegible as light ghosting stands out against dark backgrounds. It also depends a bit on how long ago I had my prescription changed and how much I was able to convince the doctor to do a good job. reply Animats 20 hours agoprevFor some reason, dark mode sites seem to come with monospaced fonts, usually Courier. I suspect that the next thing will be HaloLite 2.0, where a ring of light appears around the screen.[1] There are TV backlights.[2] Backlights that follow the screen color.[3] There is at least one phone with backlights.[4] Does anybody like that stuff? [1] https://movingimage.org/collection/artifact-halolighttv/ [2] https://www.inspiredled.com/product/universal-backlight-kits... [3] https://www.theverge.com/22566408/govee-immersion-ambilight-... [4] https://www.phonearena.com/news/Nothing-Phone-1-What-do-the-... reply userbinator 20 hours agoprevIf the contrast or brightness is too high, adjust your monitor. Too many leave theirs at eye-searingly bright and then complain. reply enriquto 20 hours agoprevGraybeard opinion: most sites shouldn't deal at all with colors. Just write plain html [0] and let your users choose. Default browser styles are not only stylish, they are also accessible and responsive by default. [0] https://motherfuckingwebsite.com/ reply hk1337 20 hours agoprevSimplest thing is to have light and dark mode themes, use whatever the user has set for their system settings, and also have a toggle to switch between light and dark. You may like dark mode for most things you browse but then would prefer something in light mode. reply gwd 20 hours agoparentThe problem with this is that you now have 2x the UX testing to make sure everything is useable and looks aesthetically pleasing. Probably OK for a large website, but as a solo entrepreneur, that ends up adding a lot of overhead. reply everybodyknows 19 hours agorootparentMultiply your 2x by the number of distinct markup colors. reply phyzix5761 21 hours agoprevPlease don't force Light Mode on users. Thanks reply sesm 21 hours agoparentTo work around light mode we have Dark Reader extension. Is the author frustrated enough to make a Light Reader extension? reply bee_rider 20 hours agorootparentThe dark reader extension can force a light theme as well. It would be more properly named the “respect my theme preferences for real” extension. It is a bit annoying that it is necessary. reply 42lux 20 hours agorootparentprevDarkreader has an option to force light mode. reply SSLy 20 hours agorootparentprevdark reader can already in fact lighten up dark pages reply seanwilson 20 hours agoprev> Upcoming WCAG 3.0 adds a new exploratory requirement for “Maximum text contrast” and I hope the working committee will address the issue of high contrast text in dark mode and provide suitable recommendations. APCA is a proposed replacement contrast calculation that was in discussions for WCAG 3 that mentions a maximum contrast value to avoid eye strain like this (https://www.myndex.com/APCA/, I'm getting SSL errors right now though). I wrote an accessible palette creator tool where you can switch between WCAG 2 and APCA contrast checking to see how they compare (go to \"... > Flip to dark/light palette\" to explore a dark mode palette): https://www.inclusivecolors.com/ Along with not having a maximum recommended contrast, WCAG 2 is also meant to be really inaccurate at measuring dark mode contrast, where it'll say colors contrast well when they don't. APCA is meant to fix both these problems. reply ozim 19 hours agoprevI like the proposal to have gray background at least. Glaring white is too much. I like reading HN because background is not glaring. For my taste it could be even a bit darker but it is good enough. reply andy_ppp 18 hours agoprevCan’t all of these things be said about light mode too? I find dark mode considerably better and would rather all sites offered a choice, especially the author’s! reply jvillasante 20 hours agoprevThe only reason I have started to use `eww` in Emacs to \"read the web\" is because people pushing those amounts of dark on everybody, it has become unbearable! reply loloquwowndueo 21 hours agoprevCan someone share a guide or how to for detecting the device’s preference and honouring that? That sounds optimal. reply ss64 20 hours agoparentIt is built into the CSS standard /* Dark mode */ @media (prefers-color-scheme: dark) { ... } The issue with both dark and light modes is so many designers seem to have jumped onto the idea that colour schemes have to be either bright white or darkest black. I'd much rather see colours that are 'slightly darker' at night and 'slightly lighter' in the daytime. For one thing there are still so many websites with no colour schemes setup at all so if you avoid going to extremes it minimises the contrast difference. reply bee_rider 20 hours agorootparentThe dark mode background should be actually black so our OLED screens can turn their pixels off completely. reply ss64 6 hours agorootparentOLED displays can still save energy even when they are not displaying absolute black https://news.ycombinator.com/item?id=34069781 reply bee_rider 4 hours agorootparentBut it is pretty linear, so blacker is better, and the darker the black is the darker the white can go while still maintaining contrast, right? reply Springtime 20 hours agorootparentprevThe other issue is many sites don't use that CSS media query at the minimum for auto setting the theme. They instead use a Javascript approach that often involves local storage/cookies even if no choice is made, which doesn't work if those are blocked and/or Javascript disabled. In such cases the default theme is forced. The optimal approach is applying the appropriate `prefers-color-scheme` using CSS alone, while additionally allowing a theme override using JS/storage. Fewer do this though, even though it wouldn't require any cookies and thus no consent dialog. The worst are sites that only have theme switching gated behind registration. reply duncan-donuts 20 hours agoparentprevhttps://developer.mozilla.org/en-US/docs/Web/CSS/@media/pref... reply Zak 20 hours agoparentprevhttps://developer.mozilla.org/en-US/docs/Web/CSS/@media/pref... reply bee_rider 20 hours agoparentprevFirefox has a default color for text and background. I wonder, if you just don’t set a color, is that what gets used? reply Theodores 20 hours agoparentprevThe truth is that you need to do device detection, so the @prefers CSS stuff, then you need to have a toggle to over-ride things. Then you need some javascript to store the preference in local storage. On page load you get your javascript to check the mode and check the override to add a class to the whole page. It is this class that implements the desired light or dark theme. Fighting against you is what the browser is doing. You can put a meta tag in to force it to respect one theme or the other so it does not go freestyling. People that have a page permanently set to light mode (or dark mode) have put in the meta tag but they haven't done the extra work to implement some meaningful choice. In summary, there is auto, where the browser does its best, one mode enforced with a meta tag, then a full solution where there is a pretty button on the page and some javascript to honour the preference, keeping the preference in local storage. Bonus points for adding an event observer to detect the change in preferences from outside the browser or in dev tools. More bonus points for having no FOUC. Extra, extra bonus points, is to implement not just a 'dark mode', but a DARK mode. In light mode everything is kittens and rainbows, whereas in dark mode the content is kind of gruesome and 'dark'. Any subject can be treated this way, a page on say, watermelons could be full of tasty recipe ideas in light mode, but, in dark mode, it could be about dropping them off tall buildings with busy streets below... reply diabllicseagull 19 hours agoprevI saw the first two images and was instantly relieved that I'm not the only one experiencing this. reply mukunda_johnson 20 hours agoprevI prefer light mode for most things, but use dark mode anyway to save battery on an OLED Screen :) reply chaosprint 20 hours agoprevthe real problem is that I use a Eink display sometimes but many websites are disasters on it, e.g. HN.. I have to use https://hn.svelte.dev/ instead. pls at least provide a switch... reply egypturnash 19 hours agoprevIf you want a Professional White Background™ then that's what Reader Mode is for. reply euamotubaina 20 hours agoprevJust created an account to say that I have that same eye condition and indeed, looking at content with high contrast ratios (mostly with whitish typography against dark backgrounds) gets REALLY uncomfortable after a couple minutes. reply amelius 20 hours agoprevWasn't the idea that it is more energy-friendly? (In which case, please also stop all ads) reply geor9e 19 hours agoparentI remember that in the early 2000s CRT era. Then LCDs got popular and it was forgotten. reply noisem4ker 19 hours agorootparentIt might turn useful again with the rise of OLEDs and micro-LEDs. reply morkalork 19 hours agoprevI used to love dark mode when I was younger but now the bright white text on black background is murder on my eyes with astigmatism, it's like driving at night. reply BobAliceInATree 15 hours agoprevI'm looking at you The Verge's homepage. reply mooreds 20 hours agoprevI hate darkmode. Fight me. reply sgt 21 hours agoprevAlso; because system mode happens to be dark, doesn't mean that the users would like dark mode by default. Every dark mode is not equal, and I'd like to start with light mode if possible. reply bee_rider 20 hours agoparentI don’t really see how a website could make a better choice than to respect the current theme by default. It should be changeable, though. reply Zak 20 hours agoparentprevFirefox has a setting for this, defaulting to the device theme. reply carrotcarrot 20 hours agoprevDark mode is such a dumb trend and I'm waiting patiently for it to die. It's not easier on the eyes unless you're in a dark room with no windows. reply dgeiser13 20 hours agoparentIt's not a trend. reply pclmulqdq 20 hours agorootparentIf anything, light mode is the trend. reply dgeiser13 19 hours agorootparentExactly. reply rishikeshs 20 hours agoprevBut what if I have only dark mode? reply underseacables 10 hours agoprevPlease I am begging you to force dark mode, or ask me up front which I prefer. reply Sleaker 20 hours agoprevYour light mode privilege is showing but seriously, maybe instead of writing an article with a tone about everything that's wrong with a preference you have you could instead. do what every dark mode user has done and like you said.. just override the css. And then write an article with a tone about how you accomplished it. This just feels like complaining for the sake of complaining. reply MortyWaves 20 hours agoprevThe last time this topic came up on here, via a different article, the majority of commenters chose to gaslight the author and continue insisting dark mode is the only valid style. reply carlosjobim 20 hours agoprevThe solution – as always – when it comes to problems with usability is to set your browser to open all websites in Reader view by default. Then every website will always be presented in the way you prefer. reply geor9e 19 hours agoparentSure but not all websites — HN and This article don't support Reader view. Are you using a special browser or plugin to do it to all websites? reply carlosjobim 19 hours agorootparentThere's a few exceptions. HN like you pointed out, which I consider an absolute dog usability wise. For HN i use custom stylesheets. But the linked article opens fine in reader view for me. You can also force reader view for any site in desktop Safari with CMD+Shift+R reply CRConrad 18 hours agorootparent> There's a few exceptions. No, there's not “a few exceptions”. It's really rather common for aites not to display in Reader Mode at all; far too common to be called “exceptions”, and nowhere near “a few”. reply carlosjobim 7 hours agorootparentNo need for anger. The vast majority of websites that you stumble upon are articles, and they open fine in reader view or in forced reader view. Where it reliably doesn't work is web application type sites, which is a given. So reader view solves the problem in most of the cases, and in the cases where it doesn't solve the problem it doesn't make anything worse either. reply bbstats 20 hours agoprev...what is wrong with this person's eyes reply nabbed 20 hours agoparentI don't know, but I have the exact same issue. White text on a black background actually hurts my eyes after a paragraph of reading, and then when I look away I see those grey bands across my vision for the next 20 seconds. As soon as I land on such a page, I either immediately back out or, if it's a subject I really want to read, I go to Safari and turn on reader mode. reply dathery 19 hours agorootparentI have the exact same issue too and wish I had a name for it. I had been assuming it was related to astigmatism since I also have issues with low-light environments especially with reflections (e.g. hate watching TV in a dark room, don't like driving at night especially in rain) but it seems like others who have this issue aren't mentioning it so now I'm doubting that. A little bummed seeing how hostile most of the comments here are but I guess it's to be expected if most commenters are seeing very differently than how I and the author are. reply BizarreByte 19 hours agorootparentI suffer from the same issue and I've always assumed it was astigmatism as well. There are different types of astigmatism so perhaps some types have this issue and some don't? I'm unsure, but I know that dark mode is legitimately hard for me to read. reply 867-5309 20 hours agoparentprevexactly. perhaps a case of their eyes and screen refresh rate being incompatible. something smells undiagnosed. whatever it may be, definitely a PEBCAK issue reply soheil 20 hours agoprevIt's worse than that please don't force dark mode even if my system has dark mode enabled. I don't want the primary background color of my computer to be dark as I'm browsing the web but I want only the periphery control items like the browser address bar, etc. to be dark. I have the Dark Reader extension to dim white backgrounds only at night. reply layer8 20 hours agoparentAt least some browsers have a setting to report a different preference to websites than the system setting. That really belongs on the user-agent level. reply ramesh31 20 hours agoprevI've never quite seen a stupid trend in web design take off like dark mode did. Maybe because it's just the ultimate perfect bike shed; something so completely inane and pointless, yet superficially dramatic, that it can be given entire meetings and dev cycles and treated like something important, when it's just 3 lines of CSS. It has become the very first thing anyone requests in a new application, and I have now seen countless entire sprints deficated to implementing it in different more complicated ways every time in each new app. Really bizarre. reply Waterluvian 21 hours agoprevI think the more specific argument is to avoid sudden changes in brightness. Neither dark mode nor light mode is the one true “main” option. We had dark mode for a long time with terminals. Then light mode a long time with word processors and the web and OSes. And now we kinda have both. reply mvdtnz 19 hours agoprev [–] It's not a \"mode\" if it's just the design. The amount of whining from people who get \"uncomfortable\" when exposed to dark/light designs is pathetic. What an utterly stupid thing to complain about. reply ssl-3 19 hours agoparent [–] On the scale of stupid complaints, where does your complaint rank? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Website designers are advised not to enforce dark mode on users, as it can cause eye strain, especially with high contrast settings like white text on a black background. The Web Content Accessibility Guidelines (WCAG) currently suggest a minimum contrast ratio but do not address maximum contrast, which may lead to discomfort; this might be addressed in the upcoming WCAG 3.0. Dark mode is beneficial in specific scenarios, such as reading on OLED screens in dark environments or coding with Integrated Development Environments (IDEs) that offer comfortable contrast settings."
    ],
    "commentSummary": [
      "The ongoing debate between dark mode and light mode centers around user comfort, with some finding dark mode straining and others considering light mode too harsh.",
      "There is a general agreement that websites should provide both dark and light mode options, respecting individual user preferences.",
      "This discussion underscores the significance of customizable settings to cater to diverse user needs and environments."
    ],
    "points": 262,
    "commentCount": 235,
    "retryCount": 0,
    "time": 1737322073
  }
]
