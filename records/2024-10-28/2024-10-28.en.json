[
  {
    "id": 41966114,
    "title": "What Are You Working On? (October 2024)",
    "originLink": "https://news.ycombinator.com/item?id=41966114",
    "originBody": "What are you working on? Any new ideas that you&#x27;re thinking about?",
    "commentLink": "https://news.ycombinator.com/item?id=41966114",
    "commentBody": "What Are You Working On? (October 2024)335 points by david927 20 hours agohidepastfavorite918 comments What are you working on? Any new ideas that you're thinking about? vldmrs 12 hours agoI've noticed that my son spends way too much time on YouTube or playing Minecraft and one of the few offline activities he enjoys doing on his own is coloring. And since he comes to me every time he wants a new coloring book and we spend about 10 minutes together searching for each picture, I made a website with a collection of coloring books for him. The site is very simple, but to be honest, I haven't had so much fun with the process of creation for a long time. https://colorango.com/ reply 082349872349872 9 hours agoparentAt one pre-funding startup (in the days when 14400 was an excellent remote connection) we had a LAN set up in the basement of the founder with the largest house. Their daughter liked to \"work\" alongside us, so (partly to protect our unattended keyboards!) I bought a colouring-book program for her to use. One evening, when her mother called down that it was her bedtime, she replied: — Can't mom, busy working! click click click — What are you working on? — click I have to turn it all orange! click Upon hearing that, we knew she was one of us. reply Galanwe 12 hours agoparentprevThis is absolutely amazing. The pictures are very detailed and done with taste, there is no ads to be seen, the website is well organized. This rivals any high end coloring book I've seen, you are very talented! My kid will be thrilled, thank you so much for creating this! reply linsomniac 4 hours agoparentprevMy wife has been using ChatGPT to generate coloring pages for our Little Free Library and they've been coming out amazing! reply AndrewVos 1 hour agoparentprevWow, you and I should be friends - this is my project: https://color.vos.lol reply thot_experiment 11 hours agoparentprevInteresting, what AI are you using to generate these? Are these straight from the net or is there a post processing pipeline? If so, what are you doing? reply tkgally 8 hours agorootparentNot the GP, but inspired by your question I tried asking ChatGPT to create similar coloring sheets. The results seem suitable for coloring. Here's one prompt: \"A simplified line-drawing coloring sheet of a dog flying an airplane. The drawing is in clean black lines on a white background, with minimal details and clear, bold outlines.\" Later: The prompt worked with Imagen 3 on Gemini Advanced, too: https://g.co/gemini/share/fd023da84cb2 reply hmottestad 4 hours agorootparentThe Gemini one has a prop that should have 4 blades but only has 3. All my attempts with GPT-4o have failed. Always ends up with areas where the black lines become fuzzy. reply cannibalXxx 2 hours agoparentprevwhat a fascinating friend! i just showed my son and he loved the idea. These are the tools we need for our children's good development and growth reply justmarc 5 hours agoparentprevBeautiful work and presentation! Keep it up! How about a digital-coloring version too, that kids and adults can use on say a tablet, or even a phone? reply vldmrs 2 hours agorootparentSome people love doing that but your idea doesn’t resonate with me personally - I prefer holding my pen and drawing or coloring on paper reply e3bc54b2 9 hours agoparentprevWell done! My niece is going to love this! Is it possible to get all PDFs at once? Hopefully per section? That will really help to print all at once and get her a single book to go on for couple of weeks. I thought I could do `curlgrepxargs curl`, but the site returns 520. reply vldmrs 2 hours agorootparentI'll think about it. But I've noticed that if I print out some coloring books for my son, they stay on his desk for a long time and he rarely colors them. But if I print him one coloring page, he almost always finishes it. reply boredemployee 7 hours agoparentprevdamn I wish u did it 10 years ago! I really struggled with it, was so hard to find coloring images for my daughter. now shes 14 so I don't think she will care much :) reply chookharel 11 hours agoparentprevReally awesome! As I haven’t seen a way to contact., any way to get a unicorns and cats categories? reply ihateolives 11 hours agorootparentYes, unicorns please! reply vldmrs 11 hours agorootparentI’ll be sure to add unicorns, thank you! reply curious_mind 10 hours agoparentprevAwesome!! I love the images for the card on the home page, very pleasing.. I would try with my daughter who loves Unicorns and Princesses. reply enstyled 10 hours agoparentprevLove this, thank you for creating it! reply marapuru 10 hours agoparentprevGreat stuff! I tend to generate some colouring pages on the fly but these look great. Can you add dinosaurs? reply vldmrs 8 hours agorootparentThank you, dinosaurs are in my TODO list p.s. - my son is an expert at dinos, not sure why I haven’t added them reply marapuru 8 hours agorootparentCool, hopefully it will be in your top downloads ;-) reply revorad 7 hours agoparentprevThis is so nice, thank you for making it! reply twinofficer 11 hours agoparentprevVery valuable for me, too (dad of 3). Thanks for curating! reply timcobb 5 hours agoparentprevAwesome that it's offline, too! Amazing work. reply penjelly 12 hours agoparentprevthe whole thing is beautiful reply ms7892 10 hours agoparentprevThank you for creating this. reply Mainsail 5 hours agoparentprevThis is incredible! Nice work. reply bnrdr 11 hours agoparentprevGreat job, that’s a nice simple idea that has value for lots people. reply ccforyc 9 hours agoparentprevPenguins live in the Antartic. Great idea and web site. reply bsenftner 8 hours agoparentprev20 years ago I met a young woman in her mid 20's. She's setup coloring book pages with google ads by the thousands, in pretty much every language. Her income from that was around $8K a month, and this was late 90's? reply grepLeigh 1 hour agorootparentSimilar story, but for the mobile era: I knew an indie app developer who built a portfolio of early mobile apps. His top-earners were a coloring book app, bead animal patterns, and a no-essay college scholarship app. Those three allowed him to pay himself and a partner salary and drop contract/client work. reply tecleandor 8 hours agorootparentprevJust to be a bit picky, I guess it was Doubleclick or some other thing instead of Google Ads, as Google AdWords started working in 2000 reply _s_a_m_ 8 hours agoparentprevSuch a cute website╟──╢ 2 ║ │ ╘═╤═╝ ╚═══╝ ╔════╗ ┌───╖ │ │ ║ −1 ╟──┤ + ╟─┴─┐ │ ╚════╝ ╘═╤═╝ │ │ ┌─┴─╖ │ ╔═══╗ │ │ ! ║ │ ║ 1 ║ │ ╘═╤═╝ │ ╚═╤═╝ │ │ ┌─┴─╖ ┌─┴─╖ │ │ │ × ╟──┤ ? ╟──┘ │ ╘═╤═╝ ╘═╤═╝ └─────┘ │ The language is called Funciton (pronounced: /ˈfʌŋkɪtɒn/) and the above example demonstrates the factorial function. I made this language over 10 years ago, but earlier this year I've been making YouTube videos in which I describe it in excruciating detail: https://youtube.com/playlist?list=PLkG32PHxWoJaetjKUMVRONWLg... For my next video, I want to show in detail how the interpreter works. For this purpose I'm creating an elaborate animation. You'll notice that the latest video is already several months old; this is because this animation is more work than I bargained for, and I got a little burned out by it. Nevertheless, I persevere and the video will come out whenever I may finish it. Language specification: https://esolangs.org/wiki/Funciton Interpreter: https://codeberg.org/Timwi/Funciton reply slightwinder 2 hours agoparentThis seems like something which would be annoying to create digital without supporting tools, but awesome in analog. I could see value in a specialized camera-app which transforms hand drawn box-structures to digital boxes, or a kind of play board where children could arrange cards to create a program and learning programming. reply alonsonic 14 minutes agoparentprevVideos are actually quite good. Great job! reply sgt 10 hours agoparentprevAlso impressed with how good this looks on HN :) reply danielvaughn 9 hours agorootparentYeah I was going to comment the same. Even looks good on mobile. reply sureglymop 6 hours agoparentprevThis is awesome! I think what it needs now is tooling/an ide to \"draw\" programs :) I've long wanted to look for a sort of \"ascii drawing program\" where one can just draw on a grid with monospace ascii characters and have tools for boxes, circles, etc. Maybe it already exists! reply inrodos 6 hours agorootparentThere is a tool called asciiflow which sounds exactly what you are looking for reply toastal 5 hours agoparentprevVery cool! +1 for hosting on Codeberg so we don’t have corporate lock-in. reply trzy 4 minutes agoprevI'm working on robots. In the long run I'm interested in dexterous manipulation for industrial or commercial tasks (e.g., assembly of products) but given the big $$$ already deployed in this space, am wondering if I can find a simpler (and faster to build!) application. Playing with 6-axis arms but also built RoBart for fun, controlled by Claude. Would love to connect with folks to ideate on the concept of a very cheap autonomous robot (maybe with some very limited manipulation ability for e.g. opening doors). I can think of an application in the health care space already. Footage at my web site (which badly needs a redesign lol): http://trzy.org reply koeng 20 hours agoprevI'm working on synthesizing a genome at home! Here is a video with more details, as well as a picture of my home lab. I've always wanted to build life from scratch, and I finally have a chance to do it. Video on what I'm doing - https://www.youtube.com/watch?v=CCiuS1oHnKw Picture of my home lab - https://x.com/koeng101/status/1844150979484319842 I'm trying to build a DNA assembly company right now (been lots of ups and downs lately...), and one thing I need to do is validate the specs of my oligo pool synthesis provider, Agilent, before I release to customers / raise a seed round. So as a stress-test run of my system, I'm synthesizing a genome, and am thinking about trying to livestream it. The unique technology is variety of ways to assemble and validate DNA from oligo pools for a lot cheaper, pretty much enabling a 10x reduction in DNA synthesis cost vs commercial suppliers. I've worked my ass off for nearly 2 years to get to this moment and am so excited! reply paulmilligrams 13 hours agoparentVery impressive work. Are you still able to proceed with operating your lab despite the injunction passed against you for theft of trade secrets? [1] [1] https://www.sideman.com/ronald-fisher-and-ellen-leonida-achi... reply koeng 10 hours agorootparentyep, nothing in there prevents me from doing work. That article is mainly their legal team fluffing their own feathers for their clients, which I'd hope that one would be able to read between the lines for, considering it was published by the lawyers themselves. The lawsuit itself is quite frivolous and accusing me of stealing and using source code I didn't steal/use, so just have to go through the legal motions to prove that. The more details you know about the case the more absurd it becomes reply worthless-trash 8 hours agorootparentI hope you win and get some big cash rewards for these kinds of accusations. reply owenpalmer 14 hours agoparentprevWow this is very exciting! Always makes me happy when I see your comments on HN, you're always up to something interesting! Are you hiring developers or aspiring bioengineers? (I'm a developer and an aspiring bioengineer) reply koeng 10 hours agorootparentSomeday hopefully soon when I raise a seed :) I think if you have the right structure, it is easier to train developers to be bioengineers than bioengineers to be developers! Bioengineering tends to be a more wicked discipline, which seriously affects how one writes their code. Makes it kinda crap. Software devs on the other hand typically aren't as experienced in the other field, and so are coming in blind. reply Dig1t 2 hours agorootparentHow about free labor? Are you interested in people who want to work for free? reply cgreerrun 15 hours agoparentprevThis is incredible. I have a biochemistry and bioinformatics background, and I've always been curious about how easy and cheap it could be to do various experiments at home. Godspeed! reply mindcrime 17 hours agoparentprev> I've always wanted to build life from scratch, and I finally have a chance to do it. I'm pretty sure I saw this movie... and it didn't end well for existing life on Earth, as I recall. :p reply circles_for-day 3 hours agorootparentDon’t worry, synthetic life doesn’t work very well without evolution to tune it into a useful ecological niche. Venter already did something similar. Tampering with existing viruses and symbionts so they can escape their current minima in the fitness landscape is the more dangerous thing. reply koeng 10 hours agorootparentprevgood thing we live in real life and not a movie reply mindcrime 4 hours agorootparentReality is often stranger than fiction though! :-) reply kragen 2 hours agorootparentLess in keeping with the anti-intellectual witch-hunting political agendas of Hollywood, though. reply 0xCMP 15 hours agoparentpreva literal home lab! reply 0xEF 10 hours agorootparentMy favorite piece of lab equipment is the bed. reply dang 20 hours agoprevThis is an ongoing experiment that david927 has been helping with (thanks!). The two previous in the sequence were: What are you working on (September 2024)? - https://news.ycombinator.com/item?id=41690087 - Sept 2024 (1041 comments) What are you working on (August 2024)? - https://news.ycombinator.com/item?id=41342017 - Aug 2024 (1424 comments) One thing I'd like to hone in on is that these threads aren't intended for promotion, but rather for the just-because sort of project, driven by idle interest or weird obsession—the sort of thing people might spend their free time on. I'm not sure yet what the official \"rule\" should be (if any), but if you're working on a startup or have had attention via Show HN, maybe abstain from these discussions? It wouldn't be good for the thread to get taken over by things HN already has a place for. reply david927 19 hours agoparentThanks, Dan, for that clarification. The question each month is actually two-fold: what have you been tinkering around with and what new ideas are thinking about. It's an invitation to dialogue. We know our history and the role collaboration has played in it. Whether at Xerox PARC or Bell Labs, bouncing ideas off of other colleagues has spurred incredible innovation. I submit that HN is a giant Xerox PARC. We have all of the ingredients for this recipe here on HN. We have the brilliant minds; we have the joy of creation. I submit that what we lack is mixing those ingredients. We lack dialogue and collaboration, and it's all completely unnecessary. It's here. Please use it. reply kaycebasques 5 hours agorootparentFor conciseness how about: > What are you exploring? reply 082349872349872 9 hours agoparentprevDan, instead of \"What are you working on\", could a better title for conveying the intent be \"What are you hacking on\"? reply dang 1 hour agorootparentIt's a good idea and consistent with the original use of the term on HN. I guess the downside is if anyone with a cool side project thought that it wouldn't belong under that smaller-sounding umbrella. Another option would be to go the whole hog and explicitly reference side projects in the title, or at least in whatever will become the instructions at the top of the regular thread. reply hyperbrainer 6 hours agorootparentprevThat's good, but hacking for me has a specific connotation in that you are modifying something for your purposes. Something new is \"working\". reply webmaven 6 hours agorootparentPerhaps \"What are you making?\" instead? reply paddy_m 2 hours agoparentprevI just saw this. yep, totally promoted my project instead of following this guideline. reply dang 1 hour agorootparentHi Paddy! Hmm - I'm not sure. Are you talking about https://news.ycombinator.com/item?id=38424478? That doesn't seem to have had significant attention on HN yet. It's an open source project. It might be fine in this thread. Whatever the line is, it's still gelatinous. We want to figure it out in a way that optimizes the thread for interestingness, which means avoiding repetition and prioritizing the long tail of projects that probably wouldn't get discussed in other contexts on HN. reply waprin 15 hours agoparentprevnext [5 more] Why isn't it intended for promotion? I find this \"anti-promotion\" attitude to be doing a disservice to this HN community for a few reasons. Clearly, this whole website is funded and exists in part to promote YC's portfolio companies, as evidenced by \"Launch HN\" threads getting auto-front paged whereas \"Show HN\" plebians have to earn the upvotes from /new (which most agree required an exceptionally good post and a lot of luck to even get that goodness noticed). And we're not talking promotion of a few posts, YC is now doing multiple batches a year and has hundreds of companies per batch meaning we're seeing a LOT of promotion / advertisements on this site coming via Launch HN threads as well as jobs ad threads. I don't think Xerox park would have done as well if 5% of the people get got the opportunity for a microphone in the auditorium every week and the other 95% did not. That would seem like a caste system. I understand that YC funds this website so the caste system is inevitable but I don't see why moderation should further stratify it - unless you're prioritizing advertising YC companies over a great community. Next, I see this \"HN is not for self promotion\" do a lot of downstream damage on the community in the sense that it's much better for big, existing trillion dollar companies than smaller players. If a small bootstrapped startup writes a blog post and mentions there product, people will complain about \"blogspam\" and \"this blog post is really just an ad for a link at the end\". But if Google or Amazon have a new announcement for a new product, nobody complains that it's an advertisement, even though it's often as much or more one. The end result is that the website tends to focus more \"corporate\" news than \"hacker\" news as a downstream consequence of a well-meaning \"no self-promotion\" rule. Finally, as we've discussed over email, the rules around self-promotion are extremely opaque and in many cases algorithmically enforced by closed algorithms. This leads to a lot of confusion around what's allowed and a lot of ambiguous favoritism. I understand this site is called \"Hacker\" news and there's some mystique around the \"hacker\" building \"just for fun\" , the purism around intellectual curiosity that you don't want tainted by dirty commercialism. I just think that once the website has decided it's going to be the media arm of one of the most powerful venture capital firms in the world, the ship has sailed.If people really want pure tech news, they should go to https://lobste.rs/ . I've personally found in recent years quality of interesting conversation is much higher on /r/saas, Indie Hackers board, and Small Bets campfire, as well as various Discords, all because they allow self-promotion and don't encourage the \"self-promotion police\" who frequently show up aghast someone would try to make money on the internet (unless it's their daddy FAANG employer). Another rule I've seen in various places be very effective is a simple guideline to contribute 10x as much non-promotional content as promotional content. If someone only posts links to their projects and nothing else, I see how that gets spammy. But if someone regularly contributes they should get a pass. I understand that's partially how the submission system works via algorithmic enforcement, but , see above about its opaque and ambiguous nature. Show HN is a \"place\" for self-promotion but it's a pretty bad place if 99% of submissions get entirely lost and ignored and I think you should encourage more places for promotion without inflicting a caste system where only YC companies and certain golden children get special rules. Overall, HN's guidelines against self-promotion are too rigid, there's too few opportunties for small players to promote, which makes the discussion here less egalitarian, more corporate, and less interesting. You'd be better served encouraging more self-promotion in threads like these. reply oefrha 14 hours agorootparentThere’s simply no “HN is not for self promotion” policy. You’re asked to not use your account primarily for self-promotion, and repeats are allowed, so you can roll your dice multiple times on your Show HN already as long as you’re otherwise a good contributor to the community and only do it sparingly. Flooding another topic with commercial promos simply turns it into another https://news.ycombinator.com/show, what’s the point then? As for YC companies getting Launch placements, well too bad, it’s their site, you’re free to leave and start your competing one. I assume most users aren’t bothered — I seldom notice them and hardly ever click on them. I notice job ads more. reply throwaway2037 13 hours agorootparentOne thing I do like: When people call themselves out -- \"hey, we buy this software... or I work for this company and you might like this software\"... then they share some software that is relevant to the discussion. I rarely see those kinds of contributions downvoted due to their transparency. Plus, I learn about lots of interesting companies and solutions that way. reply mtndew4brkfst 15 hours agorootparentprevGrindset self-promo tactics being pervasively, overly represented in the content submissions and discussions here are the number one reason I take very long breaks from the site. More genuine conversations are intensely welcome, so if that takes overt guard rails, so be it. If the only enthusiasm someone really wants to share is about their capitalist endeavors, count me out. reply throwaway2037 13 hours agorootparent> Grindset self-promo tactics being pervasively, overly represented in the content submissions and discussions here are the number one reason I take very long breaks from the site. \"Grindset\": I never saw that before. I guess it is a combination of grind plus mindset? Very cool. It rolls off the tongue nicely. reply cosbgn 2 minutes agoprevWe are building an AI rag system and selling it to shipyards. Each ship requires thousands of unique documents to be \"read\" daily by big teams. reply tyjkot 6 hours agoprevIn my 50k population town in Minnesota, I notice a lot of headlights, taillights, and turn signals are out. Our roads (outside of the Twin Cities) are often bumpy which causes vibration in the vehicles, leading to many bulbs failing. I drive a 21 year old Saab, and in my 2 years of owning it, I have replaced every single bulb in the exterior of the vehicle except a turn signal or two. I decided to create a mobile service for vehicle lights. It's a simple website that even technologically-disadvantaged people can use. The website is nearly finished and I will likely come back here to write a post on it for how the website works. Oh the best part, I get texted and emailed for each service order that comes in, and using my service is only $10 more than what it would cost you to go buy a bulb yourself at OReillys, AutoZone, etc. I programmed everything myself and developed the idea as well. This is my first real-world project/solution I am bringing into this world that has been verified by others, to be a needed service. Pretty excited about it and I love changing bulbs or replacing light housings, it's fun and simple. **Update: I perform the install. reply bityard 4 hours agoparentLots of cars make it easy to change out bulbs. But some cars are a massive pain to change certain bulbs, and/or require special tools. Do you exclude them? Or upcharge them? (E.g. the left headlight bulb on a Subaru Outback is an absolute nightmare.) Unless you are doing this purely as a public service, $10 seems VERY low. Many independent mechanics in my area charge a minimum of 1 hour of work for anything they do, and bill at $90/hr and up. And they won't come to you for that price. (Nor are mechanics a highly paid profession in general.) I really do wish you all the best, maybe I'm just not seeing the whole picture. Edit: Something else to think about: when I replace bulbs in my cars, I always do it in pairs. Reason being that if one side burned out, the other is likely not far behind, especially headlight bulbs. The headlights also have another quirk: if you replace one and not the other, you usually end up with the new one being much brighter than the old one. reply tyjkot 2 minutes agorootparentI have all the tools to replace headlight and taillight housing and bulbs for probably most vehicles including semis. For my Saab's headlight bulb replacements, I have to remove my front bumper and then the headlight housing unit itself, just to replace turn signal and headlight bulb. I am fairly mechanically advanced. It's not quite just $10, it's $10 more than a single bulb would cost you at your local parts store. If you lookup how much a headlight bulb is these days, it's about $20. My service will be $30 flat for bulb replacements in my area with a small mileage fee for out-of-towners. The great part about Minnesota, is most of us hate the cold. I however do not. Many people get lazy and will Doordash or find other convenient ways to have things delivered. Not many people want to change bulbs in the cold or bring to a mechanic to be over-charged. What my population is looking for is a service exactly like I am providing. Again, the pricing of $30 per service is perfectly sustainable for me and I have no issues replacing most parts in vehicles, lights are a walk in the park for me. *Will correct typos later, at work atm. reply smileysteve 31 minutes agoparentprevI find it interesting because this seems to be information asymmetry - and there is nothing wrong with that. AutoZone, O'Reilly, Advance advertise that they do things like replace batteries, change light bulbs, add washer fluid, wiper blades. It's arguably imperative for their brand that they offer (and advertise) these store services when compared to Amazon or Walmart (without a car center). It's even clearer when they offer 20% off codes for online ordering 12 months a year. (Also interesting because basic bulbs for tail lights and turn signals are often also sold at gas stations and grocery stores) They're not ASE certified techs, but I'm under the impression that staff receive some training related to it. reply smileysteve 5 minutes agorootparentContextually; yes, I have relatives that ask me to get their battery changed at Autozone, even though Autozone will do it for free -- and relatives who don't know that Autozone sells (and will often perform) a refrigerant top off if your AC isn't cold. reply cacozen 1 hour agoparentprevSuggestion: Costco sell car batteries for ridiculously low prices, because they don't include installation. I recently got one for my Kia Telluride and it was $100 cheaper than any competition (because all competitions include the installed price). Installing is as easy but can feel intimidating to people: Could be another source of income for your app. reply costcopizza 4 hours agoparentprevNeat! Do you pick up the bulbs as needed from an auto parts store? Or do you keep a supply on hand? I think you want to keep this as simple as possible, but I see headlight restoration (which can be done in 30min) and wiper blade replacement complementing this nicely. reply tyjkot 4 hours agorootparentNo bulbs at auto stores are inflated far too high to be a profitable parts for me. I have to order through a supplier and keep supply on-hand, which is honestly fine and more profitable for me. Hey thank you for that idea! I am going to be adding in headlight/taillight housing replacements as well, but I do like the idea of wiper blade replacement, I may keep that on the back-burner for some time until demand approaches. However, the headlight restoration idea is a fantastic one. Definitely will add this to my list of primary services after launch. reply btbuildem 3 hours agoparentprevPlease please please strongly discourage people from using those super-blinding lights so many cars seem to have these days! reply notpublic 4 hours agoparentprev> it's fun and simple Not sure if it was mine or my friends car, replacing one of the lights was neither fun or simple :). Some manufacturers really seem to prioritize style over repairability! reply NonEUCitizen 5 hours agoparentprevYou just deliver the replacement bulb or install as well? reply tyjkot 4 hours agorootparentI perform the install. reply tiznow 4 hours agoparentprevThis is really awesome. reply tyjkot 4 hours agorootparentThank you, when the idea struck, it felt pretty dang cool that there isn't other competitors or similar-services in my area. I figured, hey I could do this; and now I am in the process of doing it. reply thomasfl 7 hours agoprevFor me the most important issue that needs to be solved right now is the increasing urban sprawl and the car dependent neighborhoods. It causes social isolation. Maintaining infrastructure like roads and electricity, is causing a strain on the economy for local municipalities. Not to mention the disastrous effect car based transportation has on the environment. I am a fullstack developer living in Norway. Last year I registered the Norwegian branch of the Architectural Uproar as a not for profit organization. With the support from paying members, I have been able to go on tour to most of the major cities in Norway. We organize large meetings were we discuss architecture and city planning with politicians, architects and property developers on stage. I am strongly inspired by Create Streets in UK and Strong Towns in the US. I want to improve people’s quality of life, help saving the planet and make Norway beautiful again while doing it. https://arkitekturopproret.no edit: typos reply SamWhited 5 hours agoparentThere's a quote from Bill McKibben's forward to \"Creating Cohousing\" by Kathryn McCamant and Charles Durrett that I think about every time someone brings this up (it's about the U.S., but it applies to lots of other places and you may recognize your own countries development model here too, or not): \"For fifty years, our economic mission in America, at its core, has been to build bigger houses farther apart from each other. And boy have we succeeded: a nation of starter castles for entry-level monarchs, built at such remove one from the next that the car is unavoidable.\" You're a person after my own heart; thanks for working towards a more connected world! reply flir 2 hours agorootparentThat's a nice quote. Evocative. Is it possible to support the goal of vibrant, interconnected communities, to understand all their advantages, but still want to live at least a quarter-mile away from the nearest human? Asking for a friend... reply pchristensen 2 hours agorootparentIt's totally fine to do that. Most \"urbanist advocates\" just want to make other options legal so the quarter-mile away isn't the only choice. reply kfarr 3 hours agoparentprevI love this! There is similar inspiration in the US with non-profits such as KidSafeSF [1] in San Francisco or Families for Safe Streets [2]. I also have a fullstack background and have taken an approach to work on the street design software itself. Although AutoCAD is used by professionals, it's overkill for most street design projects and difficult for laypeople to use. I've been hacking away at a project called 3DStreet [3] to make street design easier for anyone -- like a figma for street design. Still in its early days. Happy to collaborate with your org, we do group sessions to help folks learn street design to influence local government to make positive changes. [1] https://kidsafesf.com/ [2] https://www.familiesforsafestreets.org/ [3] https://3dstreet.com/ reply dazzlefruit 7 hours agoparentprevThat's the kind of projects I love to see. Actually socially useful :) Keep it up! reply thomasfl 6 hours agorootparentThank's a lot! So far the project haven't paid off much. But that is not the most important goal. It is about making something really useful for people. In this case nice cities and neighbourhoods. reply randomdata 5 hours agoparentprev> It causes social isolation. What is it about suburbs in particular that causes social isolation? reply SamWhited 5 hours agorootparentAt least in the U.S. (and likely elsewhere) the design of the suburbs encourages neighborhoods with individual houses and very little walk able space (occasionally there are sidewalks or parks in the richer areas, but developments may be large and they're not evenly spaced throughout). Exclusionary zoning in the U.S. has also reduced the number of \"third spaces\" (coffee shops, malls, grocery stores, barber shops, etc. where people congregate and meet) near or in neighborhoods. This means fewer chance encounters since you have to plan to both go out in a car to meet. You have to find a friend then say \"let's go get drinks at 13:00 across town at this place\" instead of just happening to walk into the small neighborhood grocery and seeing each other. It's even worse in the exurbs where large housing developments have been created with no amenities nearby, sometimes within upwards of an hour drive! There are a number of good books on how the built environment affects our social life, if you're interested. It's not specifically about suburbs but \"Palaces for the People\" by Eric Klinenberg is one of my favorites that covers a lot of this sort of thing. reply randomdata 4 hours agorootparentWhat makes that different from rural areas, where social communities thrive? reply SamWhited 4 hours agorootparentIt likely depends on the rural area. In the middle of North East GA where I grew up, it's about the same, social isolation is becoming a huge problem because you're forced to drive long distances and plan ahead to meet with people. In another small town right up the street they have a thriving main street area and the housing is mostly built around that with the exception of outlying farms. It's a smaller town, but chances are you can walk over to the square and everything you need is right there, so they have a much more vibrant feeling town even though it's smaller. I'm not expert though, that's just my suspicion for why they're different having grown up in the area. reply randomdata 4 hours agorootparent> social isolation is becoming a huge problem It is interesting that you say it is becoming a problem. Why was it not a problem in a past? > It's a smaller town Towns are usually considered urban. I was imagining actual, by definition, rural. Living in a small town (~2,000 people) right now, I'd say it has less of a social community that the rural areas I've lived in previously. Still nothing that should leave you feeling isolated, but there is certainly less of a \"automatically friends with everyone\" vibe. Granted, my rural experience is strictly in agricultural areas where everyone are farmers, which gives common ground on which to \"automatically\" become friends. If nothing else, you can talk about farming. Is that the problem with the suburbs? That the people there can't find common ground on which to build friendships? reply cinntaile 3 hours agorootparent> It is interesting that you say it is becoming a problem. Why was it not a problem in a past? You couldn't live that far apart since there were no roads or cars that allowed for this. reply randomdata 3 hours agorootparentRoads have been around for several hundred years or more, along with public transportation (trains were commonplace in rural areas in the past), and the car has been the primary mode of transportation for about a century. After all that time, why is this still becoming a big problem? reply flir 2 hours agorootparentprevA terraced street in London can have a metric boat-load of social isolation and no cars. I don't think it's (necessarily) the car or the literal distance between houses. At the very least, it's a multi-faceted problem. reply cinntaile 2 hours agorootparentJust because I reply to one aspect obviously doesn't mean that I don't consider this a multi-faceted problem. reply hermitdev 2 hours agorootparentprevNah, bullshit. I grew up in a rural area [0], my parents are still in a rural area (their postal address literally contains 'rural route'). You just don't go to town every day. You didn't go to town every day in the past; you planned your trips ahead of time. It was a rare occurrence - maybe a monthly, quarterly or even less frequent occurrence. And if you do go to town, it might be a multi-day trip. Why? Because you were either walking or going on horseback. People got around before roads. Roads make travel easier. People have been trying to make traveling easier since the dawn of history. See: roads, ships, animal husbandry, the wheel, etc. People can live far apart without problem if they're self-sufficient or plan ahead: grow your own food, have stockpiles that can last months if you can't make it to town (rural winters can be a bitch). What's new is this dependency on others and belief of \"oh my god, I'll die if I don't make it to town (grocery store) this week\". [0] Our closest neighbor was a quarter mile away. Nearest paved road (and our bus stop as kids) was 2.5 miles away over private dirt roads with about 1000 feet change in elevation. It was 8 miles to town, 20 to city (which would barely be a suburb most places). reply iambateman 5 hours agorootparentprevThe default suburban life leads toward a comfortable kind of solitary confinement. Someone who lives in a “single family home” equipped with air conditioning, a privacy fence, a big screen TV, a garage door opener, and the internet will tend toward isolation because all of those technologies make aloneness easier. The reader may point out that many people are isolated in big cities too. This is true – if an adult has decided to be alone, they can be. But in the city, one's lack of social connection is more often felt whereas a suburban home can diminish the effect, like ibuprofen taken for a headache. reply thimkerbell 3 hours agorootparentDo people find that Facebook, etc, helps them connect with local others who they might not otherwise know they have common (& friendable) ground with? reply randomdata 4 hours agorootparentprevHow does that meaningly differ from rural homes, which do not have the isolation problem? Rural areas have the strongest social communities I have ever seen. reply zknow 4 hours agorootparentI've noticed rural communities tend to have more extended family and larger families which helps a lot. Besides less different types of work. reply randomdata 4 hours agorootparentThat's fair. Also a lot of \"our great-grandparents were friends, so I implicitly trust that we are also friends\". But what about the suburbs destroys that? Or, would it be more accurate to say that those who already don't have connections have a preference towards living in suburbs? Perhaps that is where they feel most at home? reply throwaway0123_5 2 hours agorootparentI don't think there is some special physical property absent in suburbs and present in rural areas that contributes to social isolation in the former but not the later. Rather I think it has to do with the kind of person that lives in each place. My grandparents and cousins live in a rural area. They all have ancestry in that town going back to the early 1900s. So do most of their neighbors. Families live next to (where \"next to\" admittedly might be a few miles depending on how rural) each other for generations. This is obviously conducive to strong intra and inter-family social networks. People who live in cities and in suburbs on the other hand seem to be far more transient. They move around for school or careers and aren't tied down to one place. I grew up in suburbs in three different cities. New neighbors frequently moved in and out of all three places, and the street where I lived from aged 5-10 has only two \"original\" families left. For those people, the built environment in suburbs being conducive to social isolation (in American suburbs anyways) becomes a problem. The nearest grocery store, restaurant, or interesting venue of any kind is likely 30+ minutes away if you try to walk, and the walk is likely to be dangerous due to poor pedestrian infrastructure and poor public transit. There are few accessible third places in which to meet people, it takes a lot more intentional effort. This is even more of a problem if you're a kid, as you're now entirely dependent on your parents and their car to meet friends or go to places where you can meet friends. I moved from upper-middle class suburbs to Washington D.C. The difference in how many people you meet who you might want to be friends with, and in how easy it is to get places where you want to go (especially without a car) is night and day. Will suburbs ever be as good as cities in this regard? Probably not. But mixed-use zoning and returning to \"streetcar suburbs\" would probably go a long way (https://www.strongtowns.org/journal/2020/8/27/in-praise-of-s...). There's also other reasons to oppose current suburb development patterns. Suburban sprawl is highly inefficient in many ways. It takes dramatically more infrastructure to serve the same number of people that you could in a denser area. Roads, power lines, pipes for drinking water and sewage, etc. The taxes that many suburbs pay don't cover these expenses and suburbs end up being subsidized by people living in denser areas. Rural areas also suffer from this to some extent, but rural areas are a necessity for society to run, hosting farms and other resource extraction activities, so subsidizing some costs is fair. People in rural areas are also more likely to be self-sufficient, having their own septic tank, private well, etc., and aren't offloading their costs to society. reply randomdata 4 minutes agorootparent> Rather I think it has to do with the kind of person that lives in each place. This does seem to be the repeated consensus – that suburbanites choose to live in suburban areas because they want the isolation. Which, I suppose, makes sense as it is not like you have to live there. People by and large live where they want to above all else. Obviously there can be exceptions (e.g. children needing to live where their parents do), but as far as what prevails goes. > There's also other reasons to oppose current suburb development patterns. Suburban sprawl is highly inefficient in many ways. It takes dramatically more infrastructure to serve the same number of people that you could in a denser area. Is denser the actual alternative, though? It seems that if you took suburbs away from these people, they'd most likely try to move into more rural areas, so then you just end up with the same there (without the practical reasons traditionally associated with subsidizing rural areas). In fact, I'm seeing more and more spreading of the so-called \"15-minute city\" conspiracy, which has people believing that there is some kind of organized plot out there working towards forcing people into living in dense cities. While the conspiracy itself is not particularly important here, the sentiment of people fearing that they might be forced into the city conveyed alongside it seems quite real and indicative that denser is not the direction they are willing to head. iambateman 4 hours agorootparentprevoh, wonderful question. I need to think about that some more. reply caeril 3 hours agorootparentprevRural communities have strong social cohesion out of necessity, not desire. I grew up rural, so I have some experience with this. Suburbia hits the sweet spot of introverted personality types: you don't NEED to know your neighbors, because there are sufficient services/resources to handle everything yourself, but you also don't get hemmed into an urban chicken coop that forces you to know your neighbors. The only people who raise alarms about \"social atomization\" are extroverts, and they're entirely incapable of understanding that some people actually prefer their isolation. reply mnky9800n 3 hours agorootparentprevThere is no pub to walk to, grocery store to walk to, no shared public space for walking and cycling to places, there’s no concept of being in a space shared with others. It’s that you simply don’t see people unless you choose it. If you live in the city you learn quickly to be around others. At least that’s my experience. reply randomdata 2 hours agorootparentRural areas tend to have strong social communities, though, despite all of those same, if not exacerbated, conditions. Based on several adjacent discussions it seems not that the suburbs cause isolation, but that those who prefer to live in isolation are more likely to choose to live in the suburbs – presumably because it offers the isolation they seek. Even if an individual in the suburbs does not wish for isolation, if everyone else there does that limits the social possibilities. reply mnky9800n 1 hour agorootparentI have lived in rural Vermont and that was only true if you were the right kind of rural Vermonter. There were plenty of those who didn’t belong and never would with no alternative they might find in the city. reply randomdata 1 hour agorootparentI think it is fair to say that large cities are more likely to cater to those who are unique, but large cities return to the same problem again: Everything is far away and you have to get into vehicle (granted, it might be a publicly operated one) to reasonably be able to engage with it. The chances of your neighbour being of the same unique blend that you seek is no greater in the city than in the country. At which point it really makes no difference if you physically reside within city limits or live in a suburban/rural area as the time and effort to get to the places that cater to your particular niche approaches being about the same in all cases. In fact, in my experience, it is often easier to access the amenities of a large city when you don't live in it! reply kaicianflone 5 hours agorootparentprevNo third places reply kaicianflone 5 hours agorootparenthttps://theweek.com/culture-life/third-places-disappearing reply triwats 1 hour agoparentprevThis is amazing as a prospect and something that I massively support. Kudos! reply cbeach 4 hours agoparentprevI never felt more isolated and lonelier than when I was in a dense urban environment and reliant on dirty, unreliable, often unsafe public transport to get around. If I ever blew my nose after travelling on the London Underground, the tissue would be black with brake dust and other pollutants from that awful environment. If I tried to cycle, I'd be stuck behind diesel busses for much of my journey, breathing in their pollution and slowed down. And obviously, cycling is completely impractical for many people, or if carrying luggage or passengers. Living in a countryside town where I have the freedom and flexibility granted by my car has opened up a world of better possibilities - travelling to any part of the coast with my family. Doing bulk shops. Carrying heavy loads etc. Driving regularly to my parents, avoiding excruciatingly long journies on public transport. Having a car has made family life possible in ways that public transport does not, and cannot achieve. > We organize large meetings were we discuss architecture and city planning with politicians, architects and property developers on stage. I would prefer that politicians, architects and property developers minded their own business and let me choose the mode of transport (an electric car) that works best for me, my family and the environment. I don't want to live in a dense, grey, impersonal urban cluster. I want to be surrounded by countryside and have the freedom to roam. I don't think I'm alone in that. reply ensignavenger 3 hours agorootparentMaking public transit clean, reliable, and safe are important goals, and very achievable goals too. There are many examples around the world. But few transit advocates are saying that we have to 100% eliminate all personal vehicles. They will remain an important part of the overall transportation infrastructure for the foreseeable future. It would also be folly to advocate for eliminating all rural living. There are many necessary activities that take place in rural communities, such as agricultural production, that will remain critical to society. The thing that I see most transit advocates targeting is excessive suburban sprawl, communities that aren't really countryside, but also aren't dense enough to be urban. They sprawl on and on for miles, with nothing to distinguish them, often simply the same tract home design repeated with only minor differences over and over and over. I am sure there are some folks that prefer these communities, but I also think that many residents would prefer wither moving into a less dense rural setting or a more dense urban setting, and many of those left that like the density would still prefer that the way these communities are structured be changed. reply cbeach 2 hours agorootparentFair comment. I'm very much opposed to the \"Croydonisation\" of the countryside in the UK With rising pressure to house hundreds of thousands of new arrivals every year, there are no easy answers. Do we make miserable dense cities even denser? Do we build new sprawling, characterless \"garden cities\"? Do we build around historic countryside towns and ruin their character? Personally, I'd rather see net immigration returned to the manageable levels it was prior to New Labour (who doubled net immigration) and the Conservatives (who further tripled net immigration). In recent years of high net immigration our economic productivity has fallen, our public services have worsened and the prospect of owning a house has slipped away from our children and grandchildren. We need a political re-think on this issue, as opposed to trying to patch over the inevitable environmental and congestion related issues. reply ensignavenger 2 hours agorootparentI haven't yet been to the UK, so I can't comment directly on the state of things there. But I grew up in a rural town in USA, and I have traveled to communities large and small across the USA and other countries, including one of my favorites to visit- Japan. In my experience, dense cities don't have to be miserable to the majority of people. I still live in what would be considered a small city, though not nearly as small as the one I grew up in. The city I live in could definitely see significant growth and increased density while maintaining the qualities that make it unique and special. But it would take a lot more planning and vision than what I have seen from current political leaders. reply ensignavenger 2 hours agorootparentI meant to add that of course there will always be those who prefer small rural communities, and that I think we we build more densely ( in an intelligent, thoughtful way) in the urban areas, we can easily meet the demand for housing while continuing to preserve plenty of small towns for those who prefer that. Of course, I can't say what the situation is for sure in the UK exactly, but here in the US, there are plenty of small towns that are slowly shrinking and disappearing. Many of these communities had much higher populations 50 or 100 years ago, and in another 50 or 100 years may not even exist as a community anymore. reply hbak 4 hours agorootparentprevCan def echo that sentiment in London, how do you avoid the commute? Work from home? Found a job outside of London? Job opportunity/pay inequality is often the biggest constraint for most people. reply siamese_puff 3 hours agorootparentprevNo offense, but this statement seems like an ignorant lack of understanding around the issues with the growing problems around urban sprawl and the issues it causes environmentally or otherwise. No one is going to take your countryside home from you, but it’s worth educating yourself on the issues. reply cbeach 3 hours agorootparentSurprising that my personal account, all of which is a truthful reflection of my own lived experiences in both urban and countryside settings, is considered \"ignorant.\" I'd be interested to explore the reasons and/or psychology behind your judgement. reply _Microft 1 hour agorootparentI think might boil down to the „anecdotes vs data“ problem and how “lived experience” is sometimes treated as if it were some universal truth. reply siamese_puff 3 hours agoparentprevMy partner and I discuss this a lot and I hate that no one in the US realizes how detrimental urban sprawl is. How did you learn to understand non-profit organization work like this? reply blululu 3 hours agorootparentAn apartment in a major us city costs >4x per more per square foot than the adjacent suburban sprawl. Clearly a lot of people realize the value and are willing to take the financial hit to have it. reply siamese_puff 44 minutes agorootparentIf you define “bigness” of my house as being more value than living next to all my friends in a very walkable city with tons of things to do at any time I want where I don’t need to ever drive my car then sure. Personally, I’ll take my $500k condo in my very amazing city that is 1000sq ft over a 3500sq ft empty house that is 2 miles from the nearest grocery store. reply rmbyrro 3 hours agorootparentprevIs it value, though, that they perceive? Or is the necessity to be in that location that drives prices up? If that's the case, that necessity might not have positive causes either... reply kragen 2 hours agorootparentWhat could be more valuable than satisfying a necessity? Your question presupposes some kind of opposition that makes me think you are using words with definitions at odds with the ones I know. reply XzAeRosho 6 hours agoparentprevInteresting! As a fullstack developer, how did you even landed on such projects? Are you even using your SW Engineering skills in this? I really want to know more how are you able to lead an urbanism and architecture project with, supposedly, no formal backgrounds. Are you partnered with other people in this endeavour? reply thomasfl 5 hours agorootparentI am not alone. Our website is made by the man who created the CSS standard while at CERN, Håkon Wium Lie. https://arkitekturopproret.no Most of the social media activities is done by a couple of fellows who is really into digital marketing. We are a team of 5 people working mostly for free now. I have no formal training in architecture or urban design. I am just a nerd who used to love playing SimCity and read Astérix comic books. Paul Graham have always focused on finding real problems and making people happy. Car dependent housing projects and bad architecture is making peoples lives miserable. It needs to be fixed. reply phkahler 5 hours agorootparent>> I have no formal training in architecture or urban design. Same, but I do get caught thinking about how inefficient our roads are in the US and what might be done about that. I've worked in the auto industry a lot and when calculating fuel efficiency (MPG) there is a \"urban drive cycle\" and a highway one that are used. The average speed on the urban cycle is a hair under 20 mph, which seems absurd because our typical speed limit outside of neighborhoods is 45mph or even 50. So I started timing my drives around town and measuring on a map... Turns out 3 minutes per mile is about right for expected drive times. The main culprit is intersections, stop lights, and left turns. You seem interested in eliminating cars, which I can appreciate but I spend my time trying to figure out how to make traffic flow more efficiently and how those layouts might be retrofitted onto the grid of roads we have. There are not easy problems. reply cryptopian 2 hours agorootparentSomebody else mentioned Strong Towns, and that's a good organization who have been thinking about this issue for a while. You're right that they're not easy problems, and it's because it encompasses more than just road layouts, but city design, land use and culture. North American cities, for example, tend to put a bunch of their amenities like supermarkets in a few places, with homogeneous swaths of housing-only suburbs so people have to drive, and those drivers have to use all the same roads to get where they're going. One thing you've noticed is the so-called \"stroad\", a highway that's attempting to be both a road (an efficient, high speed connection) and a street (a destination, where people live, work and shop). These two objectives get in the way of each other, so you end up with a road that can't carry traffic well because it has too many entrances and intersections, and a street that is hostile to anybody not in a car. Generally, efficient road design separates these two, so the higher speed connections don't serve any destinations directly. reply blactuary 4 hours agorootparentprevThe way to make traffic flow more efficiently is to get a bunch of cars off of the road. More and better public transit with dedicated space, protected bike lanes, roundabouts, traffic calming reply phkahler 4 hours agorootparent>> The way to make traffic flow more efficiently is to get a bunch of cars off of the road. No. I mean yeah, but no. Rural areas are the only place where traffic is low enough to meaningfully improve flow. We should be able to improve traffic flow and MPG without eliminating vehicles. IMHO bike lanes are kind of stupid because putting bikes right next to car traffic is stupid. Same for sidewalks. Separating pedestrian traffic from car and truck traffic would obviously be safer. reply cacozen 15 minutes agoprevA keyboard that is ergonomic without looking or feeling intimidating (https://github.com/cassiozen/fatbee). The term \"ergonomic\" isn't regulated in the US, so the market is full of supposedly \"ergonomic\" keyboards that offer little real benefits—and in some cases, may actually cause harm. My main gripe is with split keyboards. The traditional keyboard layout is wrong in so many ways (from the perspective of physiology and biomechanics) that just \"splitting in the middle\" isn't enough to avoid long-term injury. Splitting is not wrong, but alone, it's not enough. You need to tackle it from multiple perspectives: Yes, Split the keys, so your wrists aren't bent outward, support the palms so they're not bent upward, and angle the middle part up (like a tent) to keep your forearms from twisting. That twisting is especially bad because it squeezes the carpal tunnel and can lead to nerve and tendon problems. FatBee is my attempt to incorporate all these elements while creating something that doesn't feel too overwhelming to use. reply Soupy 19 hours agoprevhttps://pastmaps.com I'm building Pastmaps - striving to eventually be the world's largest online collection of old maps, aerials, and photos all packaged into a public historical research platform that's as easy to use as Google Maps. This has been a labor of love now for about a year, but I still have a huge mountain to climb to realize the full vision. Give it a try and give me your harsh criticisms - that's the greatest gift you could give me! Even in it's current state, it's being used by geneologists, urban explorers, search & rescue teams, real estate developers, government agencies, etc. The number of exploding use-cases continues to astound me and keeps me motivated to continue. reply kfarr 2 hours agoparentWow this is super cool! I've hacked together some equivalent for small projects. Curious if these are hosted as tiles that can be referenced by third-party servers? For context I'm working on an app called 3DStreet[1]. It's mostly used by planners for future projects, but I've been excited about the possibility of helping to visualize the past too. [1] https://3dstreet.com/ reply 082349872349872 9 hours agoparentprevExcellent! When reading Galois' coroner's report, I was happy to be able to find an old Paris map online that showed roughly where he had been the day of his duel and the route the farmer who found him would've taken to the hospital. reply yannis 15 hours agoparentprevNice collection but very US-centric. Is there a plan to extend it to other countries? Thinking tourists, historians and the like. reply purplezooey 15 hours agoparentprevThis is badass. love it. Wish you could make an account with a regular email address, though, and not just with Google. reply SmellTheGlove 14 hours agoparentprevCriticism: This is going to suck. Too much of my time, that is. This is super cool, thank you for doing this! reply ycombinatornews 15 hours agoparentprevI love pastmaps! Nice to see you on HN! reply wahnfrieden 10 hours agoparentprevJust be careful in countries like Japan where old maps sometimes are used illegally to discriminate based on caste (tracing ancestry of workers/candidates to discriminate against ones coming from certain historically lower caste areas of towns and cities). You might catch negative attention if your tool makes it easy to reference these maps reply bambax 4 hours agoprevI'm trying to OCR a very large book: 45 volumes of ~500 pages each. The digitization has been done (not very good but not too bad either), but the pages have comments in the margin and lots of footnotes. Just doing plain OCR doesn't really work because the notes in the margin and the footnotes get mingled with the text, which results in gibberish. But, when sent to Google Vision API, each page results in a json file that has an object for each word and the four coordinates of its bounding box. That json file is pretty big (around 1.5 Mo when pretty printed, or 500 k with no indents or line breaks) but it can then be fed to Gemini, taking advantage of its large context window. Gemini is pretty good at identifying each section of the page (headers, main text, margin comments, footnotes) but it takes a looong time to respond (2-5 minutes per page). So another approach is to ask Gemini to write a python script to analyze the json result and group sections depending of the coordinates of each word, and then run that script against the json output by the OCR phase. But it's quite difficult to have a script that works for any page; comments in the margin are always in the margin so that's pretty easy, but footnotes can start at any height of the page (some pages contain only footnotes running from previous pages) and Gemini likes to be pretty specific, giving hard 'y' coordinates for where footnotes should start, which obviously only works for the one page it's working on. I'm iterating and making some progress but I feel like I miss a big breakthrough and it all should be simpler than it currently is. Information about OCR is pretty scarce online. Any pointer is welcome! reply abdullahkhalids 1 hour agoparentAre the footnotes in a different font or fontsize? If so, then the bounding box for footnote words should be smaller. Perhaps that can help with categorization. reply infoseek12 2 hours agoparentprevCan you talk about what book you’re trying to digitize? reply popol1991 37 minutes agoprevI've been building a chrome extension called Skipper [1] that helps people to organize their browser tabs with AI. For my whole career so far I've been applying ML (as they called it back then) / AI to various domains like drug discovery and cybersecurity. Both were fun but, man, it feels really different to build a consumer app. It's just very exciting to be able to develop something, push it, and get compliments/complains the second day! We've even noticed that the ADHD community are especially engaged with the extension because they suffer the most from the tab overload problem. Anyways, for those who might need it, here's the link: https://chromewebstore.google.com/detail/skipper-fewer-tabs-... reply ValentinA23 5 hours agoprevI'm experimenting with a \"new\" kind of lisp macros. Macros in lisp are just normal functions that receive the code they wrap as argument and return some modified code. Typically they will just wrap the passed code into some more code. But then there are code walking macro: macros that will traverse passed code to modify it in depth. What I'm working on is \"code diving\" macros. Not only will they traverse the passed code, but they will resolve called functions and macros, fetch their source code and traverse it too. And so on. All the redefined fns/macros are accumulated in a let/macrolet binding, topologically sorted by call/dependency order. Instrumented code will call these local redefinitions, shadowing the global definition lexically. This allow the programmer to write truly local monkey-patches for existing code he doesn't have control over (e.g, code from another library for instance). I'm writing this in Clojure, and the traditional way to do this is to temporarily change the global definitions of targeted variables using with-redefs. This is problematic because other threads will see these redefinitions, and not just threads created within the instrumented code, but already existing threads too. Another way to do it is to just redefine the targeted functions globally, but then your modifications are available to the whole program for the rest of its execution. reply aantix 15 hours agoprevA new YouTube app/player, for my kids. It allows us to control the algorithm. It’s all LLM translating to YouTube search queries under the hood. Visually it looks the same. The suggested videos come from predefined buckets on topics they love. E.g. 33% fun math, 33% DIY engineering, 33% creative activities. Video recommendations that have a banned word in the title/desc don't get displayed e.g. MrBeast, anything with Minecraft in it, never gets surfaced. For anyone interested in using it, send me an email. jim.jones1@gmail.com reply lemming 13 hours agoparentFor anyone wanting interesting YT videos for their kids (and not wanting to take anything away from OP's project), I highly highly recommend thekidshouldseethis.com. It's basically a curated stream of cool videos, and I would feel totally safe letting my daughter browse it alone (she never does because we usually watch them together, but the curation is that good). Videos on all sorts of topics, and good enough to be really entertaining for both kids and adults - I can spend an evening there easily. They also have a really fantastic gift guide. reply Quiark 3 hours agorootparentI was just watching with my young kids YT videos about casting metals into objects and how steel is made, sometimes modernity is great reply james-bcn 11 hours agorootparentprevThat a wonderful resource, thank you! reply andrepd 11 hours agorootparentprevAbsolutely amazing. Bookmarked, gonna be very useful in 5 or 10 years ahahah On the other hand, it's so soul-crushingly depressing to contemplate how most youtube content targeted at kids is such brain-addling garbage fucking up their psyche in all sorts of ways, all for the sake of ad impressions... If there's a place for the expression \"late capitalism\" this has to be it reply lemming 2 hours agorootparentOh, if you think that is bad, wait until you're looking for educational apps for them. What a total hot mess in a sector which should by rights be amazing. Fortunately this is one of the killer apps of LLMs IMO - I have built multiple small tools to help educate our daughter, like this guy: https://x.com/random_walker/status/1848388462782673340 reply mpulztracker 12 hours agoparentprevThis is a great idea! Recommendation algos are weaponized against kids and would be great to have some way of managing it. There is a similar problem with movies as well. It is hard to know whether a movie is appropriate for a child e.g. some kind of violence may be acceptable but not adult themes. So marking a movie PG-13 for example doesn't help much. There are some crowd-sourced solutions to this right now such as https://www.commonsensemedia.org/movie-reviews But LLMs could really help automate this reply kortilla 11 hours agoparentprevIs there a version for adults? Something that keeps you from getting pulled down engagement bait rabbit holes would be great. I don’t want it to be overly focused on children’s education though. reply Rastonbury 7 hours agorootparentMaybe Dearrow clickbait remover https://dearrow.ajay.app/ reply quailfarmer 9 hours agorootparentprevI disabled all suggested content on my YouTube account. My “home” page shows as totally blank. Only the subscription tab works, or explicitly searching. You still get recommended “related videos” but it helps stay focused on the things you’ve chosen to see. reply vultour 7 hours agorootparentI exlusively watch youtube videos from my homepage and from the related videos section. You can train the YouTube algorithm to not feed you garbage, most of the videos on my homepage are 30+ minutes long educational content. I just wish you could permanently hide the Shorts section (I guess ublock can do this), so that I could see more than 6 at a time. I also never subscribe to any channels, watching a few videos pretty much guarantees they will pop up on the homepage every once in a while. reply timenotwasted 15 hours agoparentprevAs a parent with a couple of kids about to be the age of wanting to watch YT I'm very interested in this! reply aantix 15 hours agorootparentPlease email me, I need testers. jim.jones1@gmail.com reply equasar 15 hours agoparentprevThis is very interesting. I would paid for something like that, that could work for any popular video social media platform. reply aantix 15 hours agorootparentEmail me, jim.jones1@gmail.com Would love your input. reply krish888 14 hours agoparentprevsent you mail, I would love to be associated with this project. I was looking for a solution for some time, at least one which allows to restrict the content from the main youtube. Youtube kids app they have is a joke. reply dngit 14 hours agoparentprevWould an app like this work with TV? Would be super cool if it would. reply aantix 14 hours agorootparentNo TV support. iOS and Android. reply worthless-trash 8 hours agorootparentSo...android tv . reply android521 14 hours agoparentprevit would be great if this project is open source reply aantix 15 hours agoparentprevnext [6 more] YouTube recommendations for kids shouldn't be driven by engagement (e.g. \"oh, you watched 20 hours of MrBeast videos. You probably need another hour.\") If my kid watches an hour of unboxing toy videos, I shouldn't have to try and disable 3,000 channels of toy unboxings in an effort for that topic to never surface again. The thumbs down button essentially has zero effect. https://www.wired.com/story/youtube-dislike-button-mozilla-r... Diversity of thought and topic is much more critical when they are kids. reply aantix 15 hours agorootparentTodd Beaupré, the product lead for the YouTube homepage, says \"We love exploration, have multiple teams dedicated to it.\" But from my kids' viewing habits, I don't see it. The algorithm is seems super narrowly focused. https://x.com/hitsman/status/1845168160691061121 Andrej Karpathy commented on the narrowness of the algorithm just the other day. https://x.com/karpathy/status/1844449291282284925 reply josephg 15 hours agorootparentprevI’d go further and say nobody should be subjected to this stuff. Engagement is a euphemism for addiction. Self improving addiction machines are a horrible idea. They’re actively bad for people and society for a laundry list of reasons. Anyone who works on this stuff should be ashamed of yourselves. You’re modern day cigarette companies. reply aantix 15 hours agorootparentWhat do you feel is an appropriate and ethical way to surface content? How would you go about writing the recommendation algorithm? reply the_sleaze_ 8 minutes agorootparentRemove the personalization aspect. \"The algorithm\" was different in the early 2000's and all of our lives were richer for it. Before Facebook publicly embedded psychologists into the development teams and before the goal was more and more attention. The internet used to be great. reply Zak 14 hours agorootparentprevOne thing I would like to see is an algorithm based on expressed rather than revealed preferences. De-jargoned, that means clicking the like button means I want to see more things like that, and the dislike button means I don't want to see things like that. If I watched something all the way through, but clicked the dislike button, that means I don't want to see things that produced a similar response from people who tend to react the way I do. This kind of algorithm is not going to increase watch time over the short term, and might not over the long term either, which makes it unlikely to be adopted by any for-profit service. reply angrypie 14 minutes agoprevI’ve been working on a free language learning app that uses a local AI model to translate words and sentences. You can read sentences, short stories, or watch YouTube videos with translatable captions. It mostly follows the principles of the comprehensible input theory. Think of it like LingQ, but free and with any language combination. The main goal is for the app to run entirely on the client side and stay completely free. Personally, I can’t stand Anki or Duolingo—I’d rather read actual sentences that are fine-tuned to my level. reply mnbbrown 5 hours agoprevDecarbonising buildings and massive warehouses.. It's a very fun mix of hardware (for data collection), and crazy SQL queries to model energy flows between buildings, solar, batteries, etc. Considering just one building is pretty easy: consumption = imported - exported + generated - stored + dispatched. carbon = carbon intensity * imported cost = tariff * imported but then you add a site with a couple of buildings, solar on one of them, grid limited exports, etc modelling these flows is challenging. Like consider the case where one building got 10% of it's imported power from another building's excess solar, then calculating carbon becomes more difficult. and once you've figured all that - then you have to figure out what makes commercial sense to do next.. install a battery, expand solar, move onto a TOU tariff, do nothing - and that's a whole other world of optimisation problems. reply thoughtpalette 3 hours agoparentAlso somewhat working in this space. Building a BMS (Building management system) to manage and control everything in commercial buildings. Think Homekit for commercial. There's something like 70% of buildings don't use one and they can be much more environmental friendly. Utilizing https://project-haystack.org/ reply com2kid 14 hours agoprevPutting the finishing touches on my LLM based town simulator. Once it's finished I'll have it simulate 4 hours in the town every 2 hours in reality. It is designed to solve the problem of \"RPG hero just killed a dragon in front of the town and no one says anything about it.\" All the NPCs realistically react and talk about the Hero's exploits. Visitors to the site can vote on what quest the hero undertakes next. I'm running into the problem what the site isn't much fun. I'm honestly not sure what to do about that! An only slightly buggy build is at https://www.generativestorytelling.ai/tinyllmtown/index.html Importantly, I am aiming to have everything (except voice gen) working on a small model that can be ran locally. reply esperent 13 hours agoparentNice idea, but right now the villagers mostly say some variation on \"I eagerly await the valiant hero's return!\". Beside the fact that no villagers would ever speak so formally, this seems to fall into the standard fantasy problem that the normal people in the world only exist to further the hero's agency. Could you give the villagers a sense of their own agency, meaning that they have lives of their own that would continue whether the hero returns or not? reply com2kid 11 hours agorootparent> Could you give the villagers a sense of their own agency, meaning that they have lives of their own that would continue whether the hero returns or not? Yeah I'm currently considering working that in. Right now existing game AI techniques can manage giving NPCs a daily routine, and I'm trying to focus on demonstrating something new, VS another solution for an already solved problem. But having NPCs just talk about the hero is boring. I'll likely get around to adding private life stuff for each NPC before I do an announcement and share the project more broadly. reply 0xEF 9 hours agorootparentI eagerly await the Skyrim mod! Jokes aside, this is interesting because I have thought about this since the first time I killed the dragon outside of Whiterun. There is a brief change with the guards nearby where they are wowwed by your feat, but some of the standard NPC responses sneak in and make the immersive aspect of the game shaky, at best. I always thought, overtime, the honeymoon phase of a hero's deeds would wear off, and the villagers would swing more into a negative mindset, asking things like \"who is going to clean this up?\" or \"how will we be compensated for damage to our homes?\" etc. Community disruption tends to devolve into a lot of cynicism about the people in charge, in my experience with everything from natural disasters (obvious negatives) to new urban shopping centers (less obvious negatives). Regardless of what actually changed to disrupt the community, eventually it is perceived as the source of problems. I'm not a psychologist or civic engineer, so I am not sure if there is a name for the concept I am referring to. reply meheleventyone 10 hours agoparentprevHaving played with the demo a bit I think it's a couple of things: 1 - If you hadn't described your technical choices above I'd think this was just done using normal procedural text generation. Every NPC feels like it's giving the stock phrase they'll say when you run out of dialog options. 2 - There doesn't feel like there is a narrative, reasons to care about these NPCs, reasons to care about the Hero, or some sort of character development over time. If you want to engage people you need to get them to care about what's happening. reply com2kid 2 hours agorootparent> If you hadn't described your technical choices above I'd think this was just done using normal procedural text generation. Every NPC feels like it's giving the stock phrase they'll say when you run out of dialog options. During one iteration of testing the NPCs decided to throw a party for the hero and they all congregated in the tavern. That was 100% awesome and if I can hit that type of WOW factor more often I think it'll all feel magical. > There doesn't feel like there is a narrative, reasons to care about these NPCs, reasons to care about the Hero, or some sort of character development over time. If you want to engage people you need to get them to care about what's happening. This is just a tech demo so I'm not sure how much I want to put into it. Especially since the end goal is to get a recognized and get a job! reply seidleroni 5 hours agoparentprevIt would be great to give each of the NPC's their own character. For example, some of the NPC's could have a grudge against the hero for reasons of their own. They could be cheering against him for causing such a ruckus in their village, or maybe some \"Monday morning quarterback\" happening, thinking they could have handled the problem much better than he did. I think an LLM may be pretty good at coming up with some ideas. Or maybe even make it a bit tongue-in-cheek and have some of the NPC's be fans of the hero's enemies. reply NetOpWibby 11 hours agoparentprevThis sounds nuts…and exciting. Makes me want to tinker with small models, what a neat concept. reply carlnewton 12 hours agoprevI'm still working on Habitat. It's a self-hosted social platform for local communities. The plan is for it to be federated, but that's a while off yet. I want it to be easily installable for those who want to host using docker, and for those who want to host on an EC2 instance or something, because online services for docker hosting are quite expensive, so I've been working recently on ansible setup, and it's proving quite difficult, so if anyone with the experience fancies helping out, I'd be more than happy to receive contributions. - The idea: https://carlnewton.github.io/posts/location-based-social-net... - A build update and plan: https://carlnewton.github.io/posts/building-habitat/ - The repository: https://github.com/carlnewton/habitat - The project board: https://github.com/users/carlnewton/projects/2 reply nirvael 8 hours agoparentI have been thinking about a similar idea for a few months - a location-focussed social media. But my idea is more like Instagram with an extra location layer. You have a 'local' feed that shows public profiles of people in your area. You can then add those local people to some kind of 'friends' list - they can then see a more private profile, and you see their posts regardless of distance. The key idea is that you can only add 'friends' if you've actually met them once in real life. So it wouldn't be overrun by celebrities and pseudo-social relationships, influencers, etc. I'm hoping it would foster more local connections - e.g. if someone often runs into a certain person at the same places and has similar interests, maybe they'll add each other as 'friends'. reply carlnewton 50 minutes agorootparentAwesome! For me, the desire is very much about the place and not personalities or any kind of ego attached to their posts, so I've avoided any kind of functionality that will allow to follow a person, or see what else a particular person has posted, but we'll see how it evolves. If you have any programming experience, I do recommend just diving in rather than waiting for someone else to do it, as I have discovered that a lot of people seem to think that they share my vision but when it comes down to the details they have their own thing in mind. So if you want this Instagram with locations to exist, you might find that someone else's vision doesn't quite meet your desires for it. reply rsolva 7 hours agoparentprevI have had something similar in mind for a while, but nothing so fleshed out as you have here! One question; how would you implement identity? I can imagine spam and unwanted content becoming a problem, so maybe a reputation system or network of trust mechanism would be needed? reply carlnewton 44 minutes agorootparentYeah this is something I've been thinking about recently, not so much in terms of the difficulty of managing spam on a per post basis, as I'm thinking that the instances will be very small and moderation on that front should be easy, so long as you can keep the problematic user from signing up in the first place. One thing I've been thinking is that perhaps there could be a captcha-like solution that will benefit from the limited location. For instance: Select only images that are of this location. Local users will know, bots will struggle. It doesn't stop anyone else from using Google street view or something but it does make the bar the bit higher. I don't know how to deal with the obvious accessibility issue with this though so I'm going to keep it in mind until I get around to that sort of thing. Long term of course we're going to have the issue with federated spam also, so I don't want to implement a solution that will only be in my way in the long run. reply jcass8695 10 hours agoparentprevI like the idea and have been ruminating on something similar myself - starred! reply carlnewton 43 minutes agorootparentThanks so much! I work on it almost every weekend so hopefully you'll continue to see good progress. reply SamWhited 4 hours agoprevOutside of the software world I'm also working on opening a Bike Shop and frame building studio. I'm hoping that one day I can actually make a small living on frame building since I don't do software for my day job anymore, but I'm not quite ready to build for other people yet (so far I've only built frames for myself and I'd like to thoroughly strength test them before I risk putting someone else on one of my creations!) If you're in the Atlanta, GA area and need bicycle work done, hit me up! No job is too big or too small. I particularly enjoy building wheels if you want a sweet custom wheel set, but I do it all (including Mountain Bike fork and suspension work that many shops won't do). https://www.atlbikeshed.com/ reply tikimcfee 6 hours agoprevI'm working on a 3D infinite canvas of text, focusing on code. Runs on iPhone, iPad, macOS so they can all act as separate viewports into a space. You can point the app at a repository, download a copy locally, instantly render the entire repository into space in less than a second in most cases, and then fly around and search for text. I just got an optimization working for larger files and it's kinda fun how much even an iPhone can do with instanced rendering. Im developing it with the use in mind of flying through your code to show others relationships, or edit with a visuospatial look at your code instead of basic 2D tabs and a mind map of which one had the thing you're working on. It's kinda fun to work on the project In the project! It's built on Swift and Metal but can ready any utf8 text file, minus a few subsections of the Unicode spec (for now). https://github.com/tikimcfee/LookAtThat reply dlachausse 6 hours agoparentThat looks incredible! How did you learn Metal? The documentation on it from Apple leaves a lot to be desired for learning it from scratch and all the books I’ve encountered look woefully out of date. reply tikimcfee 6 hours agorootparentWell first and foremost, by doing exactly what you're doing now and asking a bunch of people for help too, haha. It's not been easy, and I'm truly still terrible at it. However, honestly, most came from following this tutorial series on YouTube which broke down building a basic game engine, and I stopped about 20 or so videos in once I had the tools I needed. I highly recommend! And hey feel free to DM me on something if you'd like - I'm happy to answer questions and help where I can! https://youtube.com/@2etime?si=qKoT1YBEruVel9Wj reply dlachausse 5 hours agorootparentThank you! reply seansh 10 hours agoprevI'm making a VSCode extension that can record & replay interactions with the IDE: all scrolls, selections, and modifications synced to guiding video, audio, and visual aid tracks. The result is a much more interactive way to present code than screencasts or blogs. Because at any point we can pause a session and freely explore and experiment with the codebase. I put together a demo recently [1] and written much more about it here [2]. [1] https://youtu.be/Qp2GdLO5eSc [2] https://codemic.io reply sureglymop 2 hours agoparentReally cool! I'm building something with a little bit of overlap. A personal data collection/archival platform with the goal of focusing on timestamping everything possible. Basically, I realized that when I have multiple pieces of data (e.g. a note, some commands, a screenshot), almost always this data is naturally connected by time and that's also how I want to query it. So: it's nice to be able to e.g. create wiki links in note taking tools like obsidian but it would be nicer if one didn't even have to do the linking manually (most of the time). I am building on postgres with a time series extension. On the client side I want there to be able to be multiple \"collectors\" that can collect data which is then sent to the server. So far I only have a keylogger collector but I have many more ideas such as a screenshot collector à la copilot etc. I think the data you are recording would also be a candidate for a collector for this system. reply raro11 9 hours agoparentprevDamn that's cool! Nice work reply Ladsko 3 hours agoprevI've been tinkering with my own keyboard layout: https://ladsko.github.io/hexed/ It's hexagonal, compact and optimized for German and English thanks to noted (https://dariogoetz.github.io/noted-layout/) Right now I'm testing key shapes and sizes and the manufacturing of key caps. I thought I needed a resin printer for best results but FDM printed caps with a blob of epoxy resin on top works surprisingly well. There's no firmware yet, I have not even decided on a micro-controller or software. But I want to use Kailh Choc v1. This is my first time exposing this project to the public so I'll be very happy about some feedback! reply tatubola 1 minute agoparentIt looks awesome. Like a prop from a sci-fi movie! reply bloopernova 1 hour agoparentprevThis looks really cool! What's the \"up/down\" key in the bottom row, centre, between the 2 return/enter keys? (I ask because my \"dream\" keyboard would have a thumbwheel just below/between the 2 spaces bars on an Alice layout keyboard) EDIT: it's a toggle key. The different heights and layout look interesting; did you perform any statistical examination of which symbol keys were most used? Are you intending on using QMK layers to enter the extra symbols? Can your fingers accurately hit all those modifier keys? Does that layout lead to less or more pinky usage? (I'm terrible at hitting other keys, I'm just a clumsy person) reply Ladsko 24 minutes agorootparentThanks! That would be the perfect spot for a thumb wheel, it's a cool idea. I myself did not do any statistical analysis, the effort was done by the neo layout project (https://www.neo-layout.org/) and the hybrid English/German variety called noted. I modified it slightly to fit my hex grid. The height difference makes it possible to hit the edge of the key without pressing the key below. And you'll find the home row more easily just from the bent layout shape. This should also help with hitting the right modifiers. I want to try Jan Lunge's Keyboard configurator (https://www.youtube.com/watch?v=RtYJYFMWjNM) for KMK but have not made a final decision. If I hit a road block with his configurator I might try QMK. Either software supports layers. reply bloopernova 11 minutes agorootparentYours is about the most innovative keyboard I've seen in a while. Good luck with it, I wish you every success :) reply breadchris 24 minutes agoprevI am building a web framework in Go that has all of the nice advancements in development experience that React has. Having spent a significant amount of time writing js, I get frustrated when things break and my developer momentum comes to a grinding halt. For everything that Go is, it is not a language that breaks because time has passed. Building this project is my long term bet that with the right tooling, Go can become a competitive language for writing full stack websites. https://github.com/breadchris/share reply nutanc 9 hours agoprevCurrently, other than my day job, I am obsessed with making sense of the \"shape of stories\". Mapping embeddings and see how they move through a sequence. Started of with [1] which showed that there might be some strength to the idea. Applied it for chunking [2] and web site analysis[3] and got pretty good results. Just started trying out experiments on video [4] and surprised that the structure seems to hold for image embeddings as well. I have no clue if this has any value, but it is fun to go down this rabbit hole :) [1]https://gpt3experiments.substack.com/p/the-shape-of-stories-... [2]https://gpt3experiments.substack.com/p/a-new-chunking-approa... [3]https://gpt3experiments.substack.com/p/using-semantic-chunki... [4]https://x.com/nutanc/status/1849661242027409723 reply tikimcfee 6 hours agoparentI'm obsessed with visual space representations of word as well. My application has a test mode where I render an entire dictionary (like, Webster) and then \"plays\" a book word by word, highlighting the word, then it's definition, and those words definitions and so on and so on, and it creates a trippy and distinct visualization kinda like an audio visualizer.. but with words. We should chat if you're interested in this kinda thing! https://github.com/tikimcfee/LookAtThat reply nutanc 5 hours agorootparentThis is really cool. reply alonsonic 19 minutes agoprevMy inbox was full of film related newsletters for special screenings in NYC so I decided to build an ai agent to track upcoming events and publish to a web and social media https://filmspotlight.org Now I don't need to read through all the emails, just check the occasional posts on upcoming events and book if interested reply ngokevin 1 hour agoprevI'm building a language learning app, specifically for multi-ethnic couples that want to learn each other's language in a very personalized way: https://couplingcafe.com I've eschewed jobs and even a funded YC startup to work on this idea for years, ideating. Just following my passion and deep belief I'm making a more effective way to learn a language while also strengthening an emotional relationship! reply robby1066 1 hour agoparentOh wow, that looks great! reply nicbou 9 hours agoprevThe Berlin immigration office is notoriously slow and unresponsive. The processing time for a residence permit varies from a few weeks to a few months. During that time, people are left unable to work or unable to leave the country. They never know how long it will take, and it causes some people to give up and leave Germany. I am writing a tool to collect and aggregate data about the processing times. This will help people plan around the delays. Knowing is half the battle. The biggest challenge is that my readers find me at the start of the process, and I need their feedback at the end of it. I have to make it easy for them to provide partial feedback and complete it later after they get an email reminder. This would be unnecessary if the immigration office collected and shared that information, but they don’t. They also don’t welcome any help because they “operate at peak efficiency”. I have stopped hoping for their collaboration. reply curtisblaine 26 minutes agoparentMight it be on purpose, to low-key making immigration more difficult / discouraged? Europe seems to be under huge migratory pression. reply DanielHB 6 hours agoparentprevSweden has the same problems, maybe I could build a similar tool for this market. I was wondering how you collect and present data? Just self-reported or do you have some API to gather this information? reply nicbou 5 hours agorootparentThe immigration office does not collect data about the time it takes to process a case. I am building the infrastructure needed to poll my users at a date in the future. reply janosch_123 7 hours agoparentprevYou are a legend! reply scottbez1 19 hours agoprevI'm building a collator robot [0] to help me pack items I sell for building your own open source split-flap mechanical display [1]. I get custom character flaps printed and die-cut in bulk and then sell them in smaller sets. A full set of flaps for one module has 52 distinct designs (letters, numbers, symbols, etc) and I get them from the manufacturer grouped by design, so they need to be collated to sell as packs of 52 with 1 of each design. My WIP robot will take a stack of one design and distribute them to a bunch of cubbies, then I'll swap in the next design, and so on, so each cubby ends up with a full set. It's based on a cheap ~$110 CNC gantry frame from AliExpress and a ~$35 BTT SKR Pico 3d printer main board running GrblHAL. To detect whether the flaps feed successfully I use a visible light break-beam sensor (the typical IR sensors don't work because the PVC flaps happen to be IR transparent!) which acts as the \"z probe\" - the flap is fed via a G38.3 probe action which returns whether the probe was successful or not, and the \"z\" coordinate it was first detected. I have a python script running on a computer to send the gcode to the machine. [0] https://bsky.app/profile/scottbez1.bsky.social/post/3l737hme... [1] https://github.com/scottbez1/splitflap reply aschla 15 hours agoprevAutopilot for my sit-on-top fishing kayak. Designed, modeled, and printed an assembly which attaches to the rudder rod. Moves the rod via a stepper motor connected to a Teensy 4.0 which gets NMEA 2000 messages from a Garmin heading sensor and a Garmin fish finder/chartplotter. Uses PID control to maintain any course I set on the chartplotter, using the cross-track error and heading. I’ve had it out on the water a few times now and it works great. Also put together an iOS app that communicates with the assembly via BLE so I can modify the PID gains as needed depending on conditions. There was a bit of noise to the sonar transducer since the stepper motor was so noisy, but I mostly eliminated it by routing the motor wires through liquid-tight flexible electrical conduit, connecting the conduit to ground. reply CharlieDigital 5 hours agoprevWife and I tend to plan long, multi-day, multi-destination travel. Got sick of working in Google Docs and having to manually move days around and re-label dates, shift hotels, etc. Ended up creating Turas.app over a weekend in 2023 (and then let it loose on Reddit). But just recently created the Chrome Extension which feels like it is an even better tool because it lets you access all of the richness of Google Maps. It's a Google Maps powertool for people who like to plan their travel meticulously. (Completely free and intended to be free forever; we tried to monetize it but realized that there's no reasonable way to do so that we ourselves would be happy with; seriously thinking about just open sourcing it, but needs some cleanup first!) Extension: https://chromewebstore.google.com/detail/turasapp/lpfijfdbgo... App: https://turas.app reply matthewfcarlson 38 minutes agoprevI'm working on an ESP32 based NFC record system using OwnTone (https://owntone.github.io/owntone-server/) as the music hosting and playing solution (as it supports AirPlay to all the HomePods in the house). Each HomePod has a smaller ESP32 with a knob for adjusting the volume in a room. I've been buying lots of music after getting rid of Spotify and wanted the experience of walking in, picking an album, dropping on the player, and then listening to it throughout the house as I make dinner or do chores. reply marmakoide 1 hour agoprevA nodal real-time video processing tool : put together pre-made \"processing boxes\" to generate interactive video. It runs on pretty much anything, uses a plugin architecture. Say, plug a camera, and it will blend two videos streams using a silhouette detected on the camera, with various effects. It's very, very early, pre-alpha stuff, but it already was used for a demo by a customer. GitHub pestacle, be warned, it's undocumented and larval stage reply cyberlimerence 3 minutes agoparentWill it be something like TouchDesigner[1] ? I never used TD myself, but I follow a lot of creative types who do for making music visualizations, art installations, etc. I can't find it on Github though, maybe repo is private ? [1] https://derivative.ca/ reply wanderingbit 46 minutes agoprevI am working on a personal digital mentor, in the spirit of Dross from Will Wight's \"Cradle\" series. I am a huge notetaker, so I'm trying to do RAG on my notes every week and have the mentor run a scrum-like retrospective for me. So far I've got the data ingestion from Notion finished, and next I need to setup the LLM mentor component as well as the CLI interface. For this first MVP I'm just trying to do better than Notion AI's response when I tell it something like \"look at the last 7 days of notes I've taken and run a retro with me. I like it because it scratches a personal-improvement itch of mine, it's a nice project to become acquainted with the popular LLM app tech, and I can share it with others who may find it useful. reply gbrindisi 43 minutes agoparentI like it! How does your stack look like? re",
    "originSummary": [],
    "commentSummary": [
      "\"What Are You Working On?\" is a discussion thread where users share personal projects and ideas, focusing on non-commercial endeavors driven by personal interest.",
      "Notable projects include a parent developing a coloring book website for their child, a user creating a language learning app, and another working on a personal digital mentor.",
      "The thread fosters a community of creativity and innovation, encouraging users to share and discuss their unique projects."
    ],
    "points": 335,
    "commentCount": 919,
    "retryCount": 0,
    "time": 1730067285
  },
  {
    "id": 41964980,
    "title": "NotebookLlama: An open source version of NotebookLM",
    "originLink": "https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/NotebookLlama",
    "originBody": "NotebookLlama: An Open Source version of NotebookLM Listen to audio from the example here This is a guided series of tutorials/notebooks that can be taken as a reference or course to build a PDF to Podcast workflow. You will also learn from the experiments of using Text to Speech Models. It assumes zero knowledge of LLMs, prompting and audio models, everything is covered in their respective notebooks. Outline: Here is step by step thought (pun intended) for the task: Step 1: Pre-process PDF: Use Llama-3.2-1B-Instruct to pre-process the PDF and save it in a .txt file. Step 2: Transcript Writer: Use Llama-3.1-70B-Instruct model to write a podcast transcript from the text Step 3: Dramatic Re-Writer: Use Llama-3.1-8B-Instruct model to make the transcript more dramatic Step 4: Text-To-Speech Workflow: Use parler-tts/parler-tts-mini-v1 and bark/suno to generate a conversational podcast Note 1: In Step 1, we prompt the 1B model to not modify the text or summarize it, strictly clean up extra characters or garbage characters that might get picked due to encoding from PDF. Please see the prompt in Notebook 1 for more details. Note 2: For Step 2, you can also use Llama-3.1-8B-Instruct model, we recommend experimenting and trying if you see any differences. The 70B model was used here because it gave slightly more creative podcast transcripts for the tested examples. Note 3: For Step 4, please try to extend the approach with other models. These models were chosen based on a sample prompt and worked best, newer models might sound better. Please see Notes for some of the sample tests. Detailed steps on running the notebook: Requirements: GPU server or an API provider for using 70B, 8B and 1B Llama models. For running the 70B model, you will need a GPU with aggregated memory around 140GB to infer in bfloat-16 precision. Note: For our GPU Poor friends, you can also use the 8B and lower models for the entire pipeline. There is no strong recommendation. The pipeline below is what worked best on first few tests. You should try and see what works best for you! Before getting started, please make sure to login using the huggingface cli and then launch your jupyter notebook server to make sure you are able to download the Llama models. You'll need your Hugging Face access token, which you can get at your Settings page here. Then run huggingface-cli login and copy and paste your Hugging Face access token to complete the login to make sure the scripts can download Hugging Face models if needed. First, please Install the requirements from here by running inside the folder: git clone https://github.com/meta-llama/llama-recipes cd llama-recipes/recipes/quickstart/NotebookLlama/ pip install -r requirements.txt Notebook 1: This notebook is used for processing the PDF and processing it using the new Feather light model into a .txt file. Update the first cell with a PDF link that you would like to use. Please decide on a PDF to use for Notebook 1, it can be any link but please remember to update the first cell of the notebook with the right link. Please try changing the prompts for the Llama-3.2-1B-Instruct model and see if you can improve results. Notebook 2: This notebook will take in the processed output from Notebook 1 and creatively convert it into a podcast transcript using the Llama-3.1-70B-Instruct model. If you are GPU rich, please feel free to test with the 405B model! Please try experimenting with the System prompts for the model and see if you can improve the results and try the 8B model as well here to see if there is a huge difference! Notebook 3: This notebook takes the transcript from earlier and prompts Llama-3.1-8B-Instruct to add more dramatization and interruptions in the conversations. There is also a key factor here: we return a tuple of conversation which makes our lives easier later. Yes, studying Data Structures 101 was actually useful for once! For our TTS logic, we use two different models that behave differently with certain prompts. So we prompt the model to add specifics for each speaker accordingly. Please again try changing the system prompt and see if you can improve the results. We encourage testing the feather light 3B and 1B models as well at this stage Notebook 4: Finally, we take the results from last notebook and convert them into a podcast. We use the parler-tts/parler-tts-mini-v1 and bark/suno models for a conversation. The speakers and the prompt for parler model were decided based on experimentation and suggestions from the model authors. Please try experimenting, you can find more details in the resources section. Note: Right now there is one issue: Parler needs transformers 4.43.3 or earlier and for steps 1 to 3 of the pipeline you need latest, so we just switch versions in the last notebook. Next-Improvements/Further ideas: Speech Model experimentation: The TTS model is the limitation of how natural this will sound. This probably be improved with a better pipeline and with the help of someone more knowledgable-PRs are welcome! :) LLM vs LLM Debate: Another approach of writing the podcast would be having two agents debate the topic of interest and write the podcast outline. Right now we use a single LLM (70B) to write the podcast outline Testing 405B for writing the transcripts Better prompting Support for ingesting a website, audio file, YouTube links and more. Again, we welcome community PRs! Resources for further learning: https://betterprogramming.pub/text-to-audio-generation-with-bark-clearly-explained-4ee300a3713a https://colab.research.google.com/drive/1dWWkZzvu7L9Bunq9zvD-W02RFUXoW-Pd?usp=sharing https://colab.research.google.com/drive/1eJfA2XUa-mXwdMy7DoYKVYHI1iTd9Vkt?usp=sharing#scrollTo=NyYQ--3YksJY https://replicate.com/suno-ai/bark?prediction=zh8j6yddxxrge0cjp9asgzd534 https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c",
    "commentLink": "https://news.ycombinator.com/item?id=41964980",
    "commentBody": "NotebookLlama: An open source version of NotebookLM (github.com/meta-llama)299 points by bibinmohan 23 hours agohidepastfavorite63 comments notpushkin 12 hours agoThis is in fact pretty explicitly not open source: https://github.com/meta-llama/llama-recipes/blob/d83d0ae7f5c... (And given there is no LICENSE file, I’m afraid you can only use this code as reference at best right now) reply creativenolo 10 hours agoparentIt doesn’t look that useful to use as it. But the approach there are investigating is clearly and well documented in plain text. Seems like a valid contribution to public knowledge to be grateful for, even if it can’t be use verbatim. reply hackernewds 9 hours agorootparentI would just hope that they disingeniously stop promoting these kind of things as open source reply creativenolo 8 hours agorootparentThis content could easily be a blog post and worth a read. But it’s in notebook form to make it interactive. It’s a tired comment narrative about these being about open source. reply notpushkin 8 hours agorootparentIt’s literally the title in the README: https://github.com/meta-llama/llama-recipes/tree/main/recipe... reply creativenolo 9 hours agorootparentprevAlso the text is enjoyably playful “For our GPU poor friends” and “let's proceed to justify our distaste for writing regex” reply egnehots 11 hours agoparentprevIt might be a mistake since it's different from what's stated in their readme: https://github.com/meta-llama/llama-models/blob/main/models/... (which is referring to the license of Meta Llama 3.2) reply notpushkin 11 hours agorootparentOh, I see the links now, thanks! But they reference four different licenses, and those are the licenses just for model weights I think? If the intention was to make something that you can only use with Llama models, stating that clearly in a separate code license file would be better IMO. (Of course, this would also mean that the code still isn’t open source.) reply Kiro 7 hours agoparentprevThanks but I will use it anyway. reply ttul 18 hours agoprevThe more I listen to NotebookLM “episodes”, the more I am convinced that Google has trained a two-speaker “podcast discussion” model that directly generates the podcast off the back of an existing multimodal backbone. The two speakers interrupt and speak over each other in an uncannily humanlike manner. I wonder whether they basically fine tuned against a huge library of actual podcasts along with the podcast transcripts and perhaps generated synthetic “input material” from the transcripts to feed in as training samples. In other words, take an episode of The Daily and have one language model write a hypothetical article that would summarize what the podcast was about. And then pass that article into the two—speaker model, transcribe the output, and see how well that transcript aligns with the article fed in as input. I am sure I’m missing essential details, but the natural sound of these podcasts cannot possibly be coming from a text transcript. reply og_kalu 18 hours agoparentFollowing up on swyx, the TTS is probably Google finally releasing Soundstorm from the basement. https://google-research.github.io/seanet/soundstorm/examples... reply swyx 18 hours agoparentprev> the more I am convinced that Google has trained a two-speaker “podcast discussion” model that directly generates the podcast off the back of an existing multimodal backbone. I have good and bad news for you - they did not! We were the first podcast to interview the audio engineer who led the audio model: https://www.latent.space/p/notebooklm TLDR they did confirm that the transcript and the audio are generated separately, but yes the TTS model is trained far beyond anything we have in OSS or commercially available reply og_kalu 18 hours agorootparentSoundstorm is probably the TTS https://google-research.github.io/seanet/soundstorm/examples... reply swyx 3 hours agorootparentthey didnt confirm or deny this in the episode - all i can say is there are about 1-2 yrs of additional research that went into nblm's tts. soundstorm is more of an efficiency paper imo reply refulgentis 12 hours agorootparentprevReally good catch. Ty. reply ttul 18 hours agorootparentprevThank you swyx. How did I miss this episode? reply rmorey 18 hours agoparentprevI feel similarly about NotebookLM, but have noticed one odd thing - occasionally Host A will be speaking, and suddenly Host B will complete their sentence. And usually when this happens, it's in a way that doesn't make sense, because Host A was just explaining something to or answering a question of Host B. I'm actually not sure what to make of that, but it's interesting to note reply dleeftink 18 hours agorootparentIt's speaker diarisation, and depending on the quality of the resulting labelling and speaker end marker tokens, what influences the rhythm of a conversation (Or the input data just has many podcast hosts completing each other's..sandwiches?) reply albert_e 14 hours agorootparentprevI think this is an important enough quality that betrays that there are no two minds here creating 1+1=3. One cheap trick to overcome this uncanny valley may be to actually use two separate LLMs or two separate contexts / channels to generate the conversations and take \"turns\" to generate the followup responses and even interruptions if warranted. Might mimic a human conversation more closely. reply thomashop 12 hours agorootparentFunnily, even two different LLMs, when put in conversation with each other, can end up completing each other's sentence. I guess it has something to do with the sequence prediction training objective. reply newsbinator 8 hours agorootparentAnd this regularly happens with humans too reply benmo_atx 7 hours agorootparentprevThose moments always make me think they’re going for a scripted conversation style where the “learner” is picking up the thread too quickly and interjecting their epiphany inline for the benefit of the listener. reply behnamoh 18 hours agorootparentprevThat's the annoying part about NLM. It ruins the illusion of having one person explaining it to the other person. reply jrm4 18 hours agoprevGreat to see this: Fellow tech-geeks, ignore the NotebookLM thing at your peril. NotebookLM, far and away, has been the \"AI Killer App\" for the VAST MAJORITY of bright-but-not-particularly-techy people I know. My 70ish parents and my 8 year old kid are both just blown away by this thing and can't stop playing with it. Edit: As someone pointed out below, I absolutely mean just the \"podcast\" thing. reply wodenokoto 14 hours agoparentAs someone who doesn’t listen to podcasts what perils will I suffer from not making podcasts in notebookLM? reply pmontra 11 hours agoparentprevI can understand why it's cool for a lot of people but it's the opposite of a time saver to me: they are a time loser, if that's a word. It's the same thing of those videos that serve a purpose only because some people (and developers) are not able to read or feel intimidated at walls of text. They are at a competitive disadvantage only partially mitigated by having videos for even the smallest text page. reply notachatbot123 9 hours agoparentprevKaleidoscopes also offer mindless fun, I would rather suggest those. reply hackernewds 9 hours agoparentprevyou might just know very old non-tech people. but the non-tech people that will generally be the larger tech people of the future are gen z and they're definitely not on notebookLM. they are on AI character chatbots reply jeffbee 17 hours agoparentprevAre we talking about NotebookLM generally or specifically the podcast stunt? reply jrm4 16 hours agorootparentGood question: I absolutely mean the podcast stunt. reply dartos 15 hours agorootparentIdk if I’d call it a killer app. The podcasts are grating to listen to and usually only contain very surface information I could gain from a paper’s abstract. It’s a wildly impressive technical achievement though. reply hitradostava 12 hours agorootparentThe point being made is that while this may be grating for you. It is magic for a large part of the population. This combined with chatgpt advanced voice mode shows a direction of travel for AI agents. It makes it possible to imagine a world where everyone has personalized tutors and that world isn't very far away. reply dartos 5 hours agorootparent> It makes it possible to imagine a world where everyone has personalized tutors and that world isn't very far away. My issue with AI hype is exactly this. Everything is “imagine if this was just better enough to be useful” “Imagine if we had an everything machine” “Image everyone having a personal assistant/artist/tutor/programmer” “Imagine a world where finance is decentralized and we all truly own our digital stuff”I’m not much of a visionary, admittedly, but it’s exhausting being told to imagine products that only half exist now. Having worked with LLMs in the autonomous agent space, I think we’re very far away from agents actually doing useful work consistently. There are still so many problems to be solved around the nature of statistical models. And they’re hard problems where the solution, at least at the product level, boils down to “wait for a better model to come out” I’m just tired of people imagining a future instead of building useful things todayreply hackernewds 9 hours agorootparentprevAriana already has personalized tutors. Wikipedia, for example is just arriving in different forms. you could argue chatbots are superior in many forms versus a podcast where you can't just scan information reply giraffe_lady 11 hours agorootparentprevAt any given time there are millions of children who will fall for the coin behind the ears trick. It's magic to this large part of the population. That doesn't make it a technique I need to evaluate for my professional practice, because I'm not a clown. reply factsaresacred 13 hours agorootparentprevIt does have a tendacy to meander or spend too time reflecting on a topic instead of distilling the details. However the new ability to add a prompt improves this greatly. Some instructions that worked for me: - Specifics instead of high level - Approach from non-critical perspective - Dont be philosophical - Use direct quotes often - Focus on the details. Provide a lesson, not reflections - Provide a 'sparknotes' style thorough understanding of the subject reply magic_hamster 13 hours agorootparentOh, when was this added? I'll have to check it out. reply aembleton 9 hours agorootparentAdded about a week ago reply globular-toast 10 hours agoparentprevI don't get it. Are you saying \"bright but not particularly techy\" people can't read? What would I be missing out on by ignoring this just like I do every other podcast? I've literally never heard of someone learning anything from a podcast except scattered knowledge from another field that will never be useful. reply lelag 19 hours agoprevPretty weird choice of TTS engines. None of them are anywhere near state of the art as far as open TTS system goes. XTTSv2 or the new F5-TTS would have been much better choices. reply imjonse 12 hours agoparentFrom improvements needed on the page: \"Speech Model experimentation: The TTS model is the limitation of how natural this will sound. This probably be improved with a better pipeline and with the help of someone more knowledgable-PRs are welcome! :)\" reply hackernewds 9 hours agorootparentThe \"PRs are welcome\" posture for a for-profit entity, that actively harms minds and pretending to be open source gives me the heebie-jeebies reply segmondy 18 hours agoparentprevYou can always update the code to use that. Meta releasing stuff on github is not trying to release the \"bet\" but to give a proof of concept. The licenses of those TTS system matters, it's not enough to be open. If this was a product for their users, they will definitely have better TTS. reply terhechte 11 hours agoprevI tried to build something kind of like NotebookLM (personalized news podcasts) over the past months (https://www.tailoredpod.ai), but biggest issue is that the existing good TTS Apis are so expensive that a product such as NotebookLM is not really possible for a normal company that doesn't have internal access to Google's models. OpenAI has the cheapest / quality good enough TTS Api, but even then generating hours of audio for free is way too expensive. Open Source TTS models are slowly catching up, but they still need beefy hardware (e.g. https://github.com/SWivid/F5-TTS) reply leobg 1 hour agoparentYou have users? If TTS is your bottleneck, I might be able to help. Email in bio. reply gargablegar 9 hours agoparentprevWhen you say beefy? How much beef? reply rmorey 18 hours agoprevThe sample output is very poor. Cool demo, but really just emphasizes how much of a hit product the NotebookLM team has managed to come up with, ostensibly with more or less the same foundation models already available. reply zmmmmm 19 hours agoprevIt only creates the podcasts right? I am more interested in the other features of NotebookLM. The podcasts are fun but gimmicky. reply danpalmer 20 hours agoprevI'm not so sure this is an open source NotebookLM as it is a few experiments in an iPython notebook. What NotebookLM does at an LLM level is not particularly novel, it's the packaging as a product in a different way than what others are doing that I think is interesting. Also the \"podcast\" bit is really just an intro/overview of a large corpus, far more useful is being able to discuss that corpus with the bot and get cited references. What this does however demonstrate is that prototyping with LLMs is very fast. I'd encourage anyone who hasn't had a play around with APIs to give it a go. reply behnamoh 18 hours agoparent> What NotebookLM does at an LLM level is not particularly novel, it's the packaging as a product... Disagreed. NLM is novel in how the two hosts interrupt and overlap each other. No other OSS solution does that, they just take turns talking. reply danpalmer 17 hours agorootparentFair point, although to me the \"audio overviews\" are a minor feature of the product. reply pmontra 11 hours agorootparentprevBut that's a bad habit and we tell people not to do it. So it's a novel but undesirable feature IMHO. reply hackernewds 9 hours agorootparentnot necessarily when you're really jiving with someone, the conversation flows really well. notice this is also what makes for really good vs bad television, example pulp fiction reply alanzhuly 20 hours agoprevIf we can have this running locally on mobile phone that would be pretty cool. Imagine receiving a work document (for example, product requirement documents), and then this turning it into a podcast to play for me while I am driving. I think my productivity will be through the roof and I don't need to worry about compliance issues. reply SubiculumCode 19 hours agoparentI wish chatgpt or Claude would make an an Android Auto app that I can use while driving. reply hackernewds 9 hours agorootparentyou could just Bluetooth your speakers reply SubiculumCode 49 minutes agorootparentits more with using the microphones in the car rather than the phone's microphone, as they tend to work better for hearing the driver..or at least I think they would. reply sajid-aipm 15 hours agoprevI wonder, how soon they release this in other languages and with different accents epecially Se-Asian accents. reply jklein11 19 hours agoprevMan.. the sample is pretty rough reply mmaunder 19 hours agoprevI’d love to hear the output if anyone has used this. reply herval 19 hours agoparentThere’s an example output linked on the github page reply gnabgib 20 hours agoprev [2 more] Page title: NotebookLlama: An Open Source version of NotebookLM reply dang 19 hours agoparent [–] Fixed. Thanks! (Submitted title was \"Meta's Open Source NotebookLM\") \"Please use the original title, unless it is misleading or linkbait; don't editorialize.\" - https://news.ycombinator.com/newsguidelines.html reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NotebookLlama is an open-source guide for converting PDFs into podcasts using Large Language Models (LLMs) and Text-to-Speech (TTS) models.",
      "The guide provides step-by-step tutorials, including pre-processing PDFs, writing transcripts, adding drama, and generating audio using specific Llama and TTS models.",
      "It encourages experimentation with models and suggests potential improvements, such as enhanced TTS models and LLM debates, while requiring a GPU server or API for Llama models."
    ],
    "commentSummary": [
      "NotebookLlama is presented as an open-source version of NotebookLM but lacks a license file, restricting its use to reference purposes only.",
      "The project serves as a proof of concept with documented methods rather than a fully functional tool, raising concerns about misleading open-source claims.",
      "Google's NotebookLM podcasts, speculated to use advanced Text-to-Speech (TTS) models, are considered innovative for non-tech users, though the high cost of TTS APIs and hardware requirements for open-source models pose challenges."
    ],
    "points": 299,
    "commentCount": 63,
    "retryCount": 0,
    "time": 1730057462
  },
  {
    "id": 41971726,
    "title": "New iMac with M4",
    "originLink": "https://www.apple.com/newsroom/2024/10/apple-introduces-new-imac-supercharged-by-m4-and-apple-intelligence/",
    "originBody": "PRESS RELEASE October 28, 2024 Apple unveils the new iMac with M4, supercharged by Apple Intelligence and available in fresh colors The world’s best all-in-one desktop features even more performance, a nano-texture display option, a 12MP Center Stage camera, and Thunderbolt 4 connectivity — all in a strikingly thin design Featuring the powerful M4 chip and the incredible capabilities of Apple Intelligence — all in its impossibly thin, all-in-one design — iMac is available in a parade of playful new colors. CUPERTINO, CALIFORNIA Apple today announced the new iMac, featuring the powerful M4 chip and Apple Intelligence, in its stunning, ultra-thin design. With M4, iMac is up to 1.7x faster for daily productivity, and up to 2.1x faster for demanding workflows like photo editing and gaming, compared to iMac with M1.1 With the Neural Engine in M4, iMac is the world’s best all-in-one for AI and is built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves, while protecting their privacy. The new iMac is available in an array of beautiful new colors, and the 24-inch 4.5K Retina display offers a new nano-texture glass option.2 iMac features a new 12MP Center Stage camera with Desk View, up to four Thunderbolt 4 ports,3 and color-matched accessories that include USB-C. Starting at just $1,299, now with 16GB of unified memory, the new iMac is available to pre-order today, with availability beginning Friday, November 8. “iMac is beloved by millions of users, from families at home to entrepreneurs hard at work. With the incredible features of Apple Intelligence and the powerful performance of Apple silicon, the new iMac changes the game once again,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “With M4 and Apple Intelligence, gorgeous new colors that pop in any space, an advanced 12MP Center Stage camera, and a new nano-texture glass display option, it’s a whole new era for iMac.” Three people watch a scene from an animated movie on iMac. iMac is shown in the storefront of a business. The new iMac brings even more fun with bold new colors, enabling users to add a pop of personalization in their homes, workspaces, or storefronts. The new iMac brings even more fun with bold new colors, enabling users to add a pop of personalization in their homes, workspaces, or storefronts. previous next Supercharged by M4 The M4 chip brings a boost in performance to iMac. Featuring a more capable CPU with the world’s fastest CPU core,4 the new iMac is up to 1.7x faster than iMac with M1. Users will feel this performance across everyday activities like multitasking between their favorite apps and browsing webpages in Safari. And with an immensely powerful GPU featuring Apple’s most advanced graphics architecture, iMac with M4 handles more intense workloads like photo editing and gaming up to 2.1x faster than iMac with M1. This also enables a smoother gameplay experience in titles like the upcoming Civilization VII. The new iMac comes standard with 16GB of faster unified memory — configurable up to 32GB. The Neural Engine in M4 is now over 3x faster than on iMac with M1, making it the world’s best all-in-one for AI, and accelerating the pace at which users can get things done. M4 takes iMac performance even further: Families, small businesses, and entrepreneurs can fly through daily productivity tasks with up to 1.7x faster performance1 in apps like Microsoft Excel, and up to 1.5x faster browsing performance5 in Safari compared to iMac with M1. Gamers can enjoy incredibly smooth gameplay, with up to 2x higher frame rates5 than on iMac with M1. Content creators can edit like never before, with up to 2.1x faster photo and video editing performance when applying complex filters and effects in apps like Adobe Photoshop1 and Adobe Premiere Pro5 compared to iMac with M1. Compared to the most popular 24-inch all-in-one PC with the latest Intel Core 7 processor, the new iMac is up to 4.5x faster.1 Compared to the most popular Intel-based iMac model, the new iMac is up to 6x faster.1 On a purple iMac, a user has two windows open as they multitask between Safari and Excel. On a green iMac, a user plays Civilization VII. On a blue iMac, a user uses Photoshop. iMac with M4 features the world’s fastest CPU core, making multitasking across apps like Safari and Excel lightning fast. With the power of M4 and its advanced GPU, iMac enables incredibly smooth gameplay in titles like the highly anticipated Civilization VII. The new iMac with M4 flies through demanding creative workflows, such as applying complex filters and effects in apps like Adobe Photoshop and Adobe Premiere Pro. previous next A New Era with Apple Intelligence on the Mac Apple Intelligence ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user’s personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools. With systemwide Writing Tools powered by Apple Intelligence, users can rewrite, proofread, and summarize text nearly everywhere they write — from Apple apps like Keynote, to third-party apps like Craft and Bear. Apple Intelligence does all this while protecting users’ privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple’s even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. For those who choose to connect their account, OpenAI’s data-use policies apply. The redesigned Siri helps users accelerate tasks throughout their day. Siri can be placed anywhere on the desktop for easy access, and with the option to type requests, users can get Siri’s help in even a quiet space like an office. Array of Gorgeous New Colors The new iMac comes in seven vibrant colors, bringing fresh shades of green, yellow, orange, pink, purple, and blue, alongside silver. The back of iMac features bold colors designed to stand out, while the front expresses subtle shades of the new palette so users can focus on doing their best work. Every iMac comes with a color-matched Magic Keyboard and Magic Mouse or optional Magic Trackpad, all of which now feature a USB-C port, so users can charge their favorite devices with a single cable. The back of iMac features bold colors designed to stand out, while the front expresses subtle shades of the new palette so users can focus on doing their best work. From left to right: (1) iMac features a color-matched keyboard and mouse or trackpad. (2) These accessories now come with USB-C ports, so users can charge all of their favorite devices with just a single cable. From top to bottom: (1) iMac features a color-matched keyboard and mouse or trackpad. (2) These accessories now come with USB-C ports, so users can charge all of their favorite devices with just a single cable. New Nano-Texture Display Option The expansive 24-inch 4.5K Retina display on iMac is its highest-rated feature, and for the first time, it’s available with a nano-texture glass option that drastically reduces reflections and glare, while maintaining outstanding image quality.2 With nano-texture glass, users can place iMac in even more spaces, such as a sun-drenched living room or bright storefront. With a new nano-texture glass option, which reduces glare while delivering outstanding image quality, users can place iMac in even more spaces, such as a sun-drenched living room or bright storefront. Enhanced Video Calls with 12MP Center Stage Camera A new 12MP Center Stage camera with support for Desk View makes video calls even more engaging. Center Stage keeps everyone perfectly centered on a video call — great for families gathered on FaceTime. Desk View makes use of the wide-angle lens to simultaneously show the user and a top-down view of their desk, which is useful for educators presenting a lesson to students, or creators showing off their latest DIY project. Rounding out the unrivaled audio and video experience is the beloved studio-quality three-microphone array with beamforming and an immersive six-speaker sound system. A new 12MP Center Stage camera makes video calls even more engaging, perfectly centering users and those around them in the frame, even when moving around. Advanced Connectivity On the new iMac, all four USB-C ports support Thunderbolt 4 for superfast data transfers, so users can connect even more accessories like external storage, docks, and up to two 6K external displays, creating a massive canvas with more than 50M pixels for users to spread out their work.3 iMac also supports both Wi-Fi 6E and Bluetooth 5.3. And with the advanced security of Touch ID, users can easily and securely unlock their computer, make online purchases with Apple Pay, and download apps.6 Additionally, Touch ID works with Fast User Switching, so customers can switch between different user profiles with just the press of a finger. All four USB-C ports support Thunderbolt 4 for superfast data transfers, so users can connect even more accessories like external storage, docks, and up to two high-resolution displays. An Unrivaled Experience with macOS Sequoia macOS Sequoia completes the new iMac experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and its notifications directly from their Mac.7 Safari, the world’s fastest browser,8 now offers Highlights, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin’s Creed Shadows. Easier window tiling means users can stay organized with a windows layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials, all stored in one place. And users can apply beautiful new built-in backgrounds for video calls, including a variety of color gradients and system wallpapers, or upload their own photos. Better for the Environment The new iMac with M4 is designed with the environment in mind, with 100 percent recycled aluminum in the stand, and 100 percent recycled gold plating, tin soldering, and copper in multiple printed circuit boards. iMac meets Apple’s high standards for energy efficiency, and is free of mercury, brominated flame retardants, and PVC. New this year, the packaging of iMac is entirely fiber-based, bringing Apple closer to its goal to remove plastic from its packaging by 2025. Today, Apple is carbon neutral for global corporate operations and, as part of its ambitious Apple 2030 goal, plans to be carbon neutral across its entire carbon footprint by the end of this decade. Pricing and Availability Customers can pre-order the new iMac with M4 starting today, October 28, on apple.com/store and in the Apple Store app in 28 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, beginning Friday, November 8. iMac starts at $1,299 (U.S.) and $1,249 (U.S.) for education, and is available in green, yellow, orange, pink, purple, blue, and silver. It features an 8-core CPU, an 8-core GPU, 16GB of unified memory configurable up to 24GB, 256GB SSD configurable up to 1TB, two Thunderbolt/USB 4 ports, Magic Keyboard, and Magic Mouse or Magic Trackpad. iMac with a 10-core CPU and 10-core GPU starts at $1,499 (U.S.) and $1,399 (U.S.) for education, and is available in green, yellow, orange, pink, purple, blue, and silver. It features 16GB of unified memory configurable up to 32GB, 256GB SSD configurable up to 2TB, four Thunderbolt 4 ports, Magic Keyboard with Touch ID, and Magic Mouse or Magic Trackpad. Additional technical specifications — including the nano-texture display option, configure-to-order options, and accessories — are available at apple.com/mac. With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit apple.com/shop/trade-in to see what their device is worth. Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come. Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in Australia, Canada, Ireland, New Zealand, South Africa, and the U.K., and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported. AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best. Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store. Share article Media Text of this article October 28, 2024 PRESS RELEASE Apple unveils the new iMac with M4, supercharged by Apple Intelligence and available in fresh colors The world’s best all-in-one desktop features even more performance, a nano-texture display option, a 12MP Center Stage camera, and Thunderbolt 4 connectivity — all in a strikingly thin design CUPERTINO, CALIFORNIA Apple today announced the new iMac, featuring the powerful M4 chip and Apple Intelligence, in its stunning, ultra-thin design. With M4, iMac is up to 1.7x faster for daily productivity, and up to 2.1x faster for demanding workflows like photo editing and gaming, compared to iMac with M1.1 With the Neural Engine in M4, iMac is the world’s best all-in-one for AI and is built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves, while protecting their privacy. The new iMac is available in an array of beautiful new colors, and the 24-inch 4.5K Retina display offers a new nano-texture glass option.2 iMac features a new 12MP Center Stage camera with Desk View, up to four Thunderbolt 4 ports,3 and color-matched accessories that include USB-C. Starting at just $1,299, now with 16GB of unified memory, the new iMac is available to pre-order today, with availability beginning Friday, November 8. “iMac is beloved by millions of users, from families at home to entrepreneurs hard at work. With the incredible features of Apple Intelligence and the powerful performance of Apple silicon, the new iMac changes the game once again,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “With M4 and Apple Intelligence, gorgeous new colors that pop in any space, an advanced 12MP Center Stage camera, and a new nano-texture glass display option, it’s a whole new era for iMac.” Supercharged by M4 The M4 chip brings a boost in performance to iMac. Featuring a more capable CPU with the world’s fastest CPU core,4 the new iMac is up to 1.7x faster than iMac with M1. Users will feel this performance across everyday activities like multitasking between their favorite apps and browsing webpages in Safari. And with an immensely powerful GPU featuring Apple’s most advanced graphics architecture, iMac with M4 handles more intense workloads like photo editing and gaming up to 2.1x faster than iMac with M1. This also enables a smoother gameplay experience in titles like the upcoming Civilization VII. The new iMac comes standard with 16GB of faster unified memory — configurable up to 32GB. The Neural Engine in M4 is now over 3x faster than on iMac with M1, making it the world’s best all-in-one for AI, and accelerating the pace at which users can get things done. M4 takes iMac performance even further: Families, small businesses, and entrepreneurs can fly through daily productivity tasks with up to 1.7x faster performance1 in apps like Microsoft Excel, and up to 1.5x faster browsing performance5 in Safari compared to iMac with M1. Gamers can enjoy incredibly smooth gameplay, with up to 2x higher frame rates5 than on iMac with M1. Content creators can edit like never before, with up to 2.1x faster photo and video editing performance when applying complex filters and effects in apps like Adobe Photoshop1 and Adobe Premiere Pro5 compared to iMac with M1. Compared to the most popular 24-inch all-in-one PC with the latest Intel Core 7 processor, the new iMac is up to 4.5x faster.1 Compared to the most popular Intel-based iMac model, the new iMac is up to 6x faster.1 A New Era with Apple Intelligence on the Mac Apple Intelligence ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user’s personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools. Apple Intelligence does all this while protecting users’ privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple’s even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. For those who choose to connect their account, OpenAI’s data-use policies apply. Array of Gorgeous New Colors The new iMac comes in seven vibrant colors, bringing fresh shades of green, yellow, orange, pink, purple, and blue, alongside silver. The back of iMac features bold colors designed to stand out, while the front expresses subtle shades of the new palette so users can focus on doing their best work. Every iMac comes with a color-matched Magic Keyboard and Magic Mouse or optional Magic Trackpad, all of which now feature a USB-C port, so users can charge their favorite devices with a single cable. New Nano-Texture Display Option The expansive 24-inch 4.5K Retina display on iMac is its highest-rated feature, and for the first time, it’s available with a nano-texture glass option that drastically reduces reflections and glare, while maintaining outstanding image quality.2 With nano-texture glass, users can place iMac in even more spaces, such as a sun-drenched living room or bright storefront. Enhanced Video Calls with 12MP Center Stage Camera A new 12MP Center Stage camera with support for Desk View makes video calls even more engaging. Center Stage keeps everyone perfectly centered on a video call — great for families gathered on FaceTime. Desk View makes use of the wide-angle lens to simultaneously show the user and a top-down view of their desk, which is useful for educators presenting a lesson to students, or creators showing off their latest DIY project. Rounding out the unrivaled audio and video experience is the beloved studio-quality three-microphone array with beamforming and an immersive six-speaker sound system. Advanced Connectivity On the new iMac, all four USB-C ports support Thunderbolt 4 for superfast data transfers, so users can connect even more accessories like external storage, docks, and up to two 6K external displays, creating a massive canvas with more than 50M pixels for users to spread out their work.3 iMac also supports both Wi-Fi 6E and Bluetooth 5.3. And with the advanced security of Touch ID, users can easily and securely unlock their computer, make online purchases with Apple Pay, and download apps.6 Additionally, Touch ID works with Fast User Switching, so customers can switch between different user profiles with just the press of a finger. An Unrivaled Experience with macOS Sequoia macOS Sequoia completes the new iMac experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and its notifications directly from their Mac.7 Safari, the world’s fastest browser,8 now offers Highlights, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin’s Creed Shadows. Easier window tiling means users can stay organized with a windows layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials, all stored in one place. And users can apply beautiful new built-in backgrounds for video calls, including a variety of color gradients and system wallpapers, or upload their own photos. Better for the Environment The new iMac with M4 is designed with the environment in mind, with 100 percent recycled aluminum in the stand, and 100 percent recycled gold plating, tin soldering, and copper in multiple printed circuit boards. iMac meets Apple’s high standards for energy efficiency, and is free of mercury, brominated flame retardants, and PVC. New this year, the packaging of iMac is entirely fiber-based, bringing Apple closer to its goal to remove plastic from its packaging by 2025. Today, Apple is carbon neutral for global corporate operations and, as part of its ambitious Apple 2030 goal, plans to be carbon neutral across its entire carbon footprint by the end of this decade. Pricing and Availability Customers can pre-order the new iMac with M4 starting today, October 28, on apple.com/store and in the Apple Store app in 28 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, beginning Friday, November 8. iMac starts at $1,299 (U.S.) and $1,249 (U.S.) for education, and is available in green, yellow, orange, pink, purple, blue, and silver. It features an 8-core CPU, an 8-core GPU, 16GB of unified memory configurable up to 24GB, 256GB SSD configurable up to 1TB, two Thunderbolt/USB 4 ports, Magic Keyboard, and Magic Mouse or Magic Trackpad. iMac with a 10-core CPU and 10-core GPU starts at $1,499 (U.S.) and $1,399 (U.S.) for education, and is available in green, yellow, orange, pink, purple, blue, and silver. It features 16GB of unified memory configurable up to 32GB, 256GB SSD configurable up to 2TB, four Thunderbolt 4 ports, Magic Keyboard with Touch ID, and Magic Mouse or Magic Trackpad. Additional technical specifications — including the nano-texture display option, configure-to-order options, and accessories — are available at apple.com/mac. With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit apple.com/shop/trade-in to see what their device is worth. Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come. Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in Australia, Canada, Ireland, New Zealand, South Africa, and the U.K., and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported. AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best. Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store. About Apple Apple revolutionized personal technology with the introduction of the Macintosh in 1984. Today, Apple leads the world in innovation with iPhone, iPad, Mac, AirPods, Apple Watch, and Apple Vision Pro. Apple’s six software platforms — iOS, iPadOS, macOS, watchOS, visionOS, and tvOS — provide seamless experiences across all Apple devices and empower people with breakthrough services including the App Store, Apple Music, Apple Pay, iCloud, and Apple TV+. Apple’s more than 150,000 employees are dedicated to making the best products on earth and to leaving the world better than we found it. Testing was conducted by Apple in September and October 2024. See apple.com/imac for more information. Actual diagonal screen measurement is 23.5 inches. Nano-texture display is an option on models with 10-core CPU and 10-core GPU. All four USB-C ports support Thunderbolt 4 on models with 10-core CPU and 10-core GPU. Testing was conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks. Results are compared to previous-generation 24-inch iMac systems with Apple M1, 8-core CPU, 8-core GPU, 16GB of RAM, and 2TB SSD. iMac with 8-core CPU and 8-core GPU can configure to Magic Keyboard with Touch ID and Numeric Keypad, and iMac with 10-core CPU and 10-core GPU comes standard with Touch ID. Available on Mac computers with Apple silicon and Intel-based Mac computers with a T2 Security Chip. Requires that the user’s iPhone and Mac are signed in with the same Apple Account using two-factor authentication, their iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and their Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone Mirroring. Testing was conducted by Apple in August 2024. See apple.com/safari for more information. Press Contacts Michelle Del Rio Apple mr_delrio@apple.com Starlayne Meza Apple starlayne_meza@apple.com Apple Media Helpline media.help@apple.com Copy text Images in this article Download all images About Apple Apple revolutionized personal technology with the introduction of the Macintosh in 1984. Today, Apple leads the world in innovation with iPhone, iPad, Mac, AirPods, Apple Watch, and Apple Vision Pro. Apple’s six software platforms — iOS, iPadOS, macOS, watchOS, visionOS, and tvOS — provide seamless experiences across all Apple devices and empower people with breakthrough services including the App Store, Apple Music, Apple Pay, iCloud, and Apple TV+. Apple’s more than 150,000 employees are dedicated to making the best products on earth and to leaving the world better than we found it. Testing was conducted by Apple in September and October 2024. See apple.com/imac for more information. Actual diagonal screen measurement is 23.5 inches. Nano-texture display is an option on models with 10-core CPU and 10-core GPU. All four USB-C ports support Thunderbolt 4 on models with 10-core CPU and 10-core GPU. Testing was conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks. Results are compared to previous-generation 24-inch iMac systems with Apple M1, 8-core CPU, 8-core GPU, 16GB of RAM, and 2TB SSD. iMac with 8-core CPU and 8-core GPU can configure to Magic Keyboard with Touch ID and Numeric Keypad, and iMac with 10-core CPU and 10-core GPU comes standard with Touch ID. Available on Mac computers with Apple silicon and Intel-based Mac computers with a T2 Security Chip. Requires that the user’s iPhone and Mac are signed in with the same Apple Account using two-factor authentication, their iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and their Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone Mirroring. Testing was conducted by Apple in August 2024. See apple.com/safari for more information. Press Contacts Michelle Del Rio Apple mr_delrio@apple.com Starlayne Meza Apple starlayne_meza@apple.com Apple Media Helpline media.help@apple.com Latest News APPLE STORIES How Apple developed the world’s first end-to-end hearing health experience October 28, 2024 PRESS RELEASE Apple Intelligence is available today on iPhone, iPad, and Mac October 28, 2024 UPDATE Messi’s MLS Cup Playoffs debut to stream free on MLS Season Pass on Apple TV October 23, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41971726",
    "commentBody": "New iMac with M4 (apple.com)269 points by tosh 3 hours agohidepastfavorite567 comments RomanPushkin 33 minutes ago> iMac features a color-matched keyboard and mouse or trackpad... These accessories now come with USB-C ports, so users can charge all of their favorite devices with just a single cable WOW! reply Nition 3 minutes agoparentI used to have a cheap Acer keyboard that had two USB ports in the back, so it acted as a little bonus USB hub that you could plug extra stuff into. Great for quick USB drive transfers; you could even plug in your mouse there. For a second I thought that's what Apple meant here. But they just mean you can plug in the device itself. reply mmaunder 25 minutes agoparentprevOh thank god. Not a day goes by when I'm not thanking the powers that be in Europe for pressuring Apple to add USB-C to iphone. reply SurgeArrest 13 minutes agoprevReading this on 2017 iMac 27\" - is the first 5k iMac that couldn't be used as a monitor after the computer inside is irrelevant. I hope EU will push for some law that requires all AIO computers to work in monitor-only mode if internal hardware is no longer good enough or no longer supported by software updates. I love the 5k screen on this iMac but the CPU is too old for photo or video editing as software got so much slower over the years. I could have used this screen for many more years, but now it will hit landfill... Apple is only \"green\" in their presentations - in reality they care more about inifite sales only. reply Mistletoe 2 minutes agoparentDon’t landfill it please sell on eBay or locally. Crazy people like me that love the monitors and just surf the web will buy them. I was awestruck the other day how much I would have to spend to exceed the monitor quality on our ancient iMac. I bought a modern 4k one and it was still worse. They really put the magic in those old 5k monitors. reply mikeatlas 11 minutes agoparentprevthey offer free recycling of old hardware https://www.apple.com/shop/open/free_recycling when you buy new hw see also https://www.apple.com/me/recycling/ reply mihaaly 5 minutes agorootparentI hope they also plant one or two small trees somewhere! And promote the use of refillable water botles on campus!! reply jjcm 1 hour agoprevSince this thread seems to be about niche asks for pro users, despite the product being targeted towards casual users who want an easy out of the box experience, I'll add my own to the mix. I'd love a bigger/better screen on these, specifically an ultrawide variety. An iMac Pro with an 8k ultrawide would be a near-instant purchase for me. I find the ultrawide form factor so good for productivity. I love the apple \"it just works\" approach to their hardware, so if something was fully integrated I'd jump on it immediately. Today I use a 49\" CRG9, but the input and connection setup is somewhat finicky. Not a huge blocker, but it would be lovely to be able to simplify. reply giobox 1 hour agoparentI also use and love the exact same 49\" CRG9, but if you do the 2x retina math, to deliver the pixel pitch Apple customers expect on desktop in the 32:9 display form, that would realistically have to be a 10240x2880 display at a minimum of 60fps. Not sure if there are bandwidth considerations over displayport or similar as this is essentially two 5k Studio Displays (5120x2880) side by side at that point. I love my CRG9 with MacOS, but there's no escaping the text rendering is significantly poorer than on Apple's own 2x retina stuff. reply blairbeckwith 11 minutes agorootparentTB4 should be able to handle that resolution – I am running 2x Studio Displays + gigabit ethernet + countless USD devices in to one TB4 port on my MacBook via a TB4 dock. reply dllu 52 minutes agoparentprevUsing a large 8K display for productivity is underrated. I wrote a blog post about my experience: https://daniel.lawrence.lu/blog/y2023m12d15/ reply gpm 8 minutes agorootparent> Unfortunately, as of writing, AMD GPUs do not have HDMI 2.1 so you cannot use an 8K TV in 8K 60 Hz mode unless you use a DisplayPort to HDMI adapter. Interesting workaround! This hadn't occurred to me at all as a solution when I read about the HDMI 2.1 driver licensing issue. reply throwaway48476 2 minutes agorootparentThis is wrong. I have used a AMD 6600XT with 8K 60hz VRR over HDMI. reply vehemenz 27 minutes agorootparentprevYou've convinced me, but it really shows the limitations for 16:9 when these are our options. Two largish 28\" 4:3 monitors would be a nice middle ground. reply throwaway48476 39 minutes agorootparentprevWhy not the 55\" 8K? Also the checkerboard is because you're not using variable refresh rate. You need to turn on game mode for the TV and VRR in OS display setting. reply dllu 38 minutes agorootparentI can't find any. The newer QN800D or whatever aren't available in 55\". And they don't make the QN700B anymore. reply throwaway48476 34 minutes agorootparentI have the QN700B. It seems almost small to me at this point. Can you get VRR to work on linux? reply zitterbewegung 50 minutes agoparentprevUnfortunately the iMac Pro was a stopgap measure similar to the 16 inch iMac that had the escape key. Even the last MacBook Air with Intel is really a testbed for the design of the first M1 MacBook Air (the mainboard is the only thing that changed). Apple has taken the steps to make the Mac Studio and other display devices made by them but, curved displays don't seem to be a strategy that Apple would take because right now they might move to tandem OLED on all devices which means even considering something curved isn't on the drawing board. reply phillco 1 hour agoparentprevIncidentally, it was observed that the new iMac can support an external 8K 120Hz display: https://x.com/vadimyuryev/status/1850929080281321899 reply OnlyMortal 54 minutes agoparentprevPeople also don’t get the idea of an appliance. reply ffsm8 14 minutes agoparentprevHow are people still going on on that idiotic \"it just works\" slogan. It was never true and will likely never become true either. All Apple software has always had their quirks and usability downsides. Wherever that's iOS, macOS or iPadOS. It's still a great OS, but no, it doesn't just work. Or please tell me how to use the magic mouse while it's charging? Am I just holding it wrong? reply minimaxir 3 hours agoprev16GB base RAM, they finally did it. They also did move the Magic Keyboard and Magic Mouse to USB-C. reply baron816 3 hours agoparentNow if only they could figure out how to allow charging the Magic Mouse while it’s being used. I guess that technology is still years away. reply GeekyBear 1 hour agorootparentGiven that the lightning version picks up a nine hour charge in the time it takes to take a bathroom break or go get a cup of coffee, this is more of an excuse to make fun of the design than it is a real world show stopper. > The Apple Mouse 2 also comes with a Quick Charge feature that provides nine hours of use with a two-minute charge. https://www.jackery.com/blogs/knowledge/how-to-charge-apple-... reply viraptor 20 minutes agorootparentThe moment it runs out of power isn't when you're you're taking a break, but while you're using it. You may change what you're doing and go take a break. But you also may be in the middle of a presentation. reply ceejayoz 11 minutes agorootparentIt'll warn of a low battery for weeks in advance of fully going dead. reply knallfrosch 5 minutes agorootparentprevI got a Logitech MX Vertical that you can charge while using. But why would I ever do that? I charge it 3 times per year when I'm going for lunch and that's that. reply square_usual 1 hour agorootparentprevThe people who like the magic mouse (not me) don't care, and the people who even otherwise would never use a magic mouse get to keep making fun of it. Why would they bother? reply staplung 2 hours agorootparentprevDon't be foolish. We may one day cross the Atlantic in an aeroplane or conceive of a motorised carriage capable of traveling 50 miles per hour but some dreams are simply impossible! reply VogonPoetry 19 minutes agorootparentprevI think the issue is that a lightning cable and socket aren't physically designed to take the stresses of being plugged in and being used like a mouse at the same time. I've not measured it, but I could believe there is probably quite a bit of repeated vertical and sideways stress on a wired mouse's cable where it joins to the mouse body. reply encom 4 minutes agorootparentApple charging cables aren't designed to be plugged into anything. Their cables are notoriously terrible. I had a lightning cable on my nightstand that I plugged my phone into at night a few times a week. After less than two years the connector had developed cracks. Inexcusable. reply aqfamnzc 2 hours agorootparentprevPutting the plug on the bottom is an intentional choice by Apple. It's because they don't want you to plug it in to charge, then never remember to unplug it. Mandatory wirelessness. reply bhouston 2 hours agorootparentLogitech makes mice that worked plugged in and not, and they are durable too because they use a custom plastic piece around the USB connector to ensure a snug fit: https://www.logitechg.com/en-ca/products/gaming-mice/pro-x-s... reply GeekyBear 1 hour agorootparentLogitech mice don't use the top surface of the mouse as a multi-touch trackpad, so it doesn't matter to Logitech if the top surface of the mouse is uninterrupted by a charging port or not. reply bhouston 8 minutes agorootparentI think both could be accommodated in a single design. reply madeofpalk 2 hours agorootparentprevI don't believe this. I believe (unfounded) originally it was made for asthetic reasons, as to not interrupt the sushi shape, and that not being able to use it while charging was not considered to be that much of a downside. And then since then Apple just hasn't bothered spending engineering effort on 'fixing' that design decision ever since. reply fwip 2 hours agorootparentprevMakes sense, especially because it's more impressive/magic (especially when it was introduced) when your friend/family/coworker sees you using it. If the cable was plugged in, it might just look to them like a mundane, not Magic, mouse. reply leptons 2 hours agorootparentprevI'd sooner believe it's because they want you to buy 2 of them, so you can charge one while using the other. reply llm_nerd 33 minutes agorootparentZero people on the planet do this. The mouse port thing is like a canary in the coal mine, betraying the people who just like taking shots at Apple, but generally are very ill informed. I think Apple should keep the port on the bottom purely so we can get the shortcut to discarding people's opinions when they hoist it up to concern troll. For actual Apple Mouse users, charging is just the least concerning thing imaginable. The battery lasts an absolute eternity. I'm using one right now that I've had for at least five or so years and I charge it once in forever, it charges super quickly, and it's just not a factor in my life at all. reply square_usual 1 hour agorootparentprevYou'd buy a second to avoid taking a 2 minute break? reply leptons 41 minutes agorootparentI wouldn't buy any Apple hardware to begin with. We had to sue them in a class action because of their awful faulty hardware. We're never going back. reply square_usual 3 minutes agorootparentThen why do you care? Why waste your time making shit up about Apple when you're not going to buy any of their hardware? throw4950sh06 35 minutes agorootparentprevI don't know, still better than all the other hardware vendors with their devices that are bad by specification. reply ValentineC 3 hours agorootparentprevI'm surprised Apple didn't co-opt charging mousepad tech, like what Logitech uses: https://www.logitechg.com/en-us/innovation/powerplay.html reply jsheard 2 hours agorootparentApple engineers probably still have PTSD from trying to get the AirPower mat to work, I doubt they'll touch non-magnetic wireless charging again. reply ffsm8 2 hours agorootparentprevI'm pretty sure it's patented in some way considering Logitech is still the only option for that . The product is already several years old after all (release date 2017) reply Suppafly 2 hours agorootparentJust pay logitech $5/piece to license the patent and then sell them for $200, there is plenty of meat on the bone for everyone involved. Or bypass the idea of the patent altogether by making their mouse charge wirelessly and then releasing a giant wireless charger that happens to work pretty well as a mouse pad later. reply pikminguy 2 hours agorootparentOption 1 only works if Logitech plays ball. They might consider the exclusivity very valuable and be unwilling to license it for anything reasonable. Option 2 is a great way to land in court. It's one thing to steal IP from a tiny company or individual but Logitech can afford lawyers. reply epolanski 3 hours agorootparentprevYou just reminded me of how stupid the plug beneath the MM was...You never needed to charge it, till you needed it and couldn't use the mouse. reply dijit 2 hours agorootparentThere are so many legitimate reasons to hate the magic mouse. Ergonimics, the polling rate, the way the glass gets greasy, the scratchy hard plastic on the bottom. Truly, inferior to the Logitech MX Master in all ways except looks. (which is subjective). But it takes literally a few seconds to get a days worth of charge out of the mouse, Apple clearly don't want you to leave it plugged in to use as a wired mouse: why? idk, because they hate choice, or perhaps its because they know it would overcharge the battery and bulge, or perhaps even still, people would get weird expectations about \"wired being better for latency\" despite the mouse not using the data connections on the wire. We'll never know. But the charging on the bottom is such a non-issue in reality that it makes me wonder if anyone actually owned that mouse, or they just think it looks funny. Personally, I'd rather they fix the other issues with the mouse, the charging was legitimately never an issue. reply jltsiren 15 minutes agorootparentIn my experience, it's slow to charge. I've been using the Magic Mouse for many years, because I otherwise like it. But charging it to last the rest of the day takes long enough that I lose track of whatever I was doing. And the low battery warning always comes so late that I must stop working immediately and plug in the cable. It's probably just Apple's usual arrogance. They could have easily designed the mouse so that you can keep using it while it's charging, but the designer chose otherwise. And because this is a minor enough issue, Apple doesn't have to fix it and admit that they were wrong. reply dijit 13 minutes agorootparentInteresting! That's quite contrary to my experience, granted I've only used two magic mice, one for 2 years in 2014-16, and another from 2020-2023. It's possible that your experience is much more common though! reply phpnode 2 hours agorootparentprevIt’s all about tension on the lightning connector imo - the connector isn’t designed for that level of flexibility, so it would break and it’s not like they’re going to use a different connector just for the mouse reply viraptor 15 minutes agorootparentIt's not an issue anymore now that they would use usb-c. reply epolanski 41 minutes agorootparentprev> But the charging on the bottom is such a non-issue in reality As I said, you rarely needed to remember to charge it. Till you would in the midst of something. Anyway, I never liked the MM so when I had my iMac I bought a magic trackpad (which you could charge while using, small bonus). reply dijit 39 minutes agorootparentThen you pop it on the charger for like 10 seconds, use it for the rest of the day, then leave it charging overnight when you go home. reply epolanski 32 minutes agorootparentSure, but it was still an inconvenience to interrupt a presentation once, and another time a prod debugging session where everybody was anxiously breathing on my neck and staring at my screen. To me the plug placement was an inconvenience, regardless of how invisible it is to you. On top of that, it never charged in few seconds after years of use, mine would take longer just to connect to the iMac again. I was glad to buy magic trackpad I could leave connected 24/7 and never think about it (also I liked it much more than the MM in general). reply dijit 31 minutes agorootparentTotally fair, why did you ignore the low battery warning for 3 days though? reply viraptor 13 minutes agorootparentBecause we're human and not behaving in a perfect way and the design of our daily tools should account for that. commandar 16 minutes agorootparentprev\"Clearly, it is the user who is wrong.\" dijit 11 minutes agorootparentThe point I'm making is that people are making a point out of ignorance. People think it will be a problem, so make ignorant commentary about it being idiotic, yet in practice it's fine, and not the worst aspect of a terrible mouse. legulere 17 minutes agorootparentprevDoesn't it tell you that the battery is low before it doesn't work anymore? When I used the Magic Mouse I never had any issues with the battery. reply goosedragons 2 hours agorootparentprevThe only reason they don't let you charge it is because it's a recycled design of the MM1 which used disposable batteries. The Magic Keyboard and Trackpad which came out the exact same day both let you use it plugged in and charging, even wired! The Magic Mouse shell was just not designed with a cord in mind at all. I have personally been in meeting where my boss forgot to charge her magic mouse and we had to wait two minutes for her to open the stuff we needed to discuss. It happens. reply estebank 2 hours agorootparentThe track pad and keyboard don't need to move, which would introduce mechanical stress on the port and cable. reply Brian_K_White 2 hours agorootparentThose are both moving parts that must be treated as movng the same as a mouse, because they are not bolted to anything. Any mechanical designer will absolutely treat everything about the ports on those the same as for a phone. reply Suppafly 2 hours agorootparentprev>The only reason they don't let you charge it is because it's a recycled design of the MM1 which used disposable batteries. But they've done incremental updates to the design since, they could have easily fixed that by now. reply goosedragons 2 hours agorootparentThey haven't made any major changes to the design. It's the shape of the thing preventing it. reply vundercind 2 hours agorootparentprevYeah this is something I thought was amazingly dumb until I used one, but it’s not actually a problem. Even a little. reply 93po 2 hours agorootparentprevive had a magic mouse and only had to plug it in and charge it and walk away for 10 minutes... maybe... 5 times in the past three years? like it's annoying when it happens, but you also only have to charge it once every couple months, and i mostly have this annoyance because i have notifications 100% turned off and i don't see the low battery notification. however i will say three years in, either a software update or hardware issue is now killing the battery and i have to charge it every week or two and that sucks salty that i now have airpod pros, an iphone 13, and the magic keyboard and mouse all with their dumb lightning bolt or whatever it's called. going to have to rebuy all this to forever rid myself of non-usb-c cables but at least in 2024 it's finally happened as an option reply dijit 2 hours agorootparentThe battery may have degraded to be fair. Each of those times you walked away, did you ever try plugging it in, counting to ten and then continuing to use it afterwards? That's what I used to do. I use a trackpad now though. reply ryandrake 2 hours agorootparentprevThe ergonomics were absolutely terrible. I now find using any mouse painful, to the point where I've replaced all of my computer pointing devices with trackpads. I blame the pain on a long history of Magic Mouse usage. reply VeejayRampay 2 hours agorootparentprevlet's stop justifying this choice from Apple it annoys everyone, it's a dumb design, you get a message from your Mac telling you that the mouse has no charge and suddenly you can't work anymore for a few minutes, it's idiotic, plain and simple reply dijit 2 hours agorootparentWireless charging is also idiotic, to someone. You don't like the mouse, that's fine, I also don't like the mouse. But unless you've actually used the mouse for an extended period: I don't think you understood the point that you: A) don't need it plugged in constantly and B) if you charge it for a handful of seconds it lasts the rest of the day, meaning you don't actually have to stop working. reply msisk6 1 hour agorootparentYeah, I've been using these on multiple Macs for a decade now and it's just not an issue. If I get the warning the mouse is getting low on charge I just plug it in, go grab a drink or use the bathroom, and by the time I get back it's good for the rest of the day. Then all I have to do is remember to plug it in overnight and it'll be good for months. YMMV. reply Brian_K_White 1 hour agorootparentprevThere are so many lulu ideas in this comment that don't hold up to the simplest examination. Plugging in for a few seconds to get a days worth of charge is a stupid thing to actually require or consider normal. I also want to use my mouse tomorrow, and even the next day, and do so without having to plan ahead \"today I will leave my mouse plugged in overnight because I can tell by clairvoyance that it is about to run out\" or \"I have been tracking the calender like a menstrual cycle and it's time, tonight is the night!\" or \"I have set up a sheduled alarm on my wonderful Apple Watch to remind me to go look at the settings somewhere to check the mouse battery level and see if it's time to charge tonight\"... And if you don't plan, then you have a few choices, charge for a minute and have to do it again without warning in 2 days, a constant stream of unplanned forced trips to the coffee maker, or just charge for 30 seconds every single day as a part of your routine, or stop and wait for a full charge on the spot for however long that is, or the worst of both worlds, get on with your day by charging for a minute now, and then don't fail to remember to plug it back in before leaving several hours of busy-ness later, which you absolutely will of course. There is no version of any of that that is remotely convenient or sensible, and certainly not an upgrade from every other mouse in the world. There is no version of this that isn't patently ridiculous. You can work around it and tolerate it because it's not as bad as having to dig ditches for a living. If there was something about mice that the tech just didn't exist for it to work any other way, then sure it's possible to live with, because humans are adaptable. But it's not good, and it's not better than the already norm for $2 mice sice 20 years ago. It's baffling weird to even try. reply dijit 49 minutes agorootparentThe mouse gives you like 3 days heads up that you might want to think about charging it though. If you disable all notifications and it really runs out, waiting 10 seconds for it to charge is... fine... I doubt you're using a wired mouse, and most wired mice are actually worse at charging than the magic mouse- the only difference is that you can use them while plugged in, so it's not as annoying that they charge so slow and use more power. Ultimately it comes down to effective utility, people harping on about the placement of the charging cable without respect to the actual usability of the device holistically have quite literally missed the forest for the trees. Like I said, theres plenty of reasons to dislike the mouse, but this ranks among the lowest and honestly the weird hate-boner for that decision just makes people look like they don't know what they're talking about to me. reply azinman2 2 hours agorootparentprevCan’t remember where I saw the interview but that was a conscious choice given the long battery life and fast charging. reply estebank 2 hours agorootparentprevI get what they were going for: force the user to use it as intended because the battery really lasted long enough for most people. Otherwise people would just have left it plugged always, and the cable+port would have needed different mechanical strength. But that really annoys anyone who would have left it charging if not most of the time. I think it would have been a better experience by leveraging software instead: detect that it is close to the end of the day and battery is low, and notify the user thwt they need to charge it when they stop using it, if leaving the underside port, or use notifications to annoy people into disconnecting the mouse when fully charged, if the port was moved to the obvious place. You're still annoying people, but you're less likely to end up with an unusable belly up mouse midway through your day. reply hggigg 3 hours agorootparentprevVery easy. You sell it on eBay and buy a Logitech MX Master. reply kbolino 2 hours agorootparentDoes the Logitech MX Master come with a driver that overcomes Apple's \"unintentional\" hobbling of non-Magic mice? reply square_usual 1 hour agorootparentApple is not nefariously gimping mice, they just don't see a world where people use non-Apple mice which have a touch surface for smooth scrolling. AFAIK this isn't an issue that can be solved with drivers. Logi's software has a persistent daemon that can convert your scrolling to smooth scrolling, but that requires leaving it open in the background. You can also use one of the dozens of open source apps that do the same thing. reply kbolino 36 minutes agorootparentI don't think it's nefarious, I think it's negligent. As I understand it, they changed something internal to how mouse motion is handled. The Magic Mouse speaks to the OS in a way that matches this change, and that was all they ever cared to ensure worked. They also don't support more than 3 buttons on a mouse well, because Apple doesn't make mice with more than 3 buttons. They did the same sort of thing with standard-DPI monitors; they didn't make them look bad on purpose, they just optimized for high-DPI monitors and didn't care about the others. And yes, fixing this requires custom software. reply square_usual 5 minutes agorootparent> They also don't support more than 3 buttons on a mouse well, because Apple doesn't make mice with more than 3 buttons This is not true. Again, I have a Master 3S and I have natively, through macOS settings, bound Mouse 4 and 5 to mission control. Technetium 2 hours agorootparentprevSeems not: https://github.com/pqrs-org/Karabiner-Elements/issues/2968 reply square_usual 1 hour agorootparentWhat does that link have to do with anything GGP said? Apple isn't involved in that bug; it's Logitech's own software intercepting events. reply george_probably 2 hours agorootparentprevIt does - it two different ways! The scroll wheel ratchet can be disabled (which is how I use it) or MX Options can override Smooth Scrolling. Or both. reply notatoad 2 hours agorootparentprevi use an MX master on my mac and it works great? in what way is it supposedly hobbled? reply kbolino 2 hours agorootparentOut of the box, with no custom software installed, non-Apple mice (and even older Apple mice) will have extremely janky scrolling on modern versions of macOS. Apparently, something internal to how the OS handles mouse scrolling was changed, and only the Magic Mouse gets a proper scrolling experience using built-in drivers. It is possible to fix this, but only with custom software (either drivers for specific mice or general tools for all mice). reply nox101 36 minutes agorootparentI have never experienced this. I have a Logitech G203 mouse I use with my M1 Mac and of course I use the touch pad when I'm not at my desktop. I've never noticed a difference. Both seem butter smooth. I have no special software install. Am I missing something? reply notatoad 2 hours agorootparentprevis it janky, or is it tied very closely to the scroll input, so it's exactly as janky as your finger moves the scroll wheel on the mouse? because that's what it seems like to me. for it to be any smoother, there would need to be some artificial smoothing of the scroll wheel input. and i'd rather not have that. reply kbolino 1 hour agorootparentIt's not so much \"raw input\" as \"extremely erratic\". For example, when using the wired Mighty Mouse, the same motion of my finger will sometimes scroll a couple lines and sometimes scroll the entire page or not scroll at all. The same mouse plugged into Windows does not exhibit this problem. reply square_usual 1 hour agorootparent> For example, when using the wired Mighty Mouse, the same motion of my finger will sometimes scroll a couple lines and sometimes scroll the entire page or not scroll at all. The same mouse plugged into Windows does not exhibit this problem. This is not normal and you're possibly facing a bug. I have a Master 3S and mine scrolls exactly the same distance with every click of the wheel. reply kbolino 18 minutes agorootparentOk, I just tested two different mice (Keychron M1 and Mighty Mouse) on two different Macs (M1 Mac Mini and M1 MacBook Pro) and all 4 combinations exhibit the same janky scrolling (mostly, it either scrolls too slow/not at all or too fast). I don't have any Logitech mice anymore, but maybe they've learned how to speak to Macs. I did notice that plugging in non-Apple mice result in a \"Setup Your Keyboard\" prompt, which I just quit out of (it's not a keyboard...). But the Mighty Mouse is an Apple mouse, and it still sucks on macOS but not on Windows. edit: I also tested a Razer DeathAdder V2 just now and it works fine (or better, at least). So it seems to affect some mice and not others, I guess \"non-Apple\"/\"non-Magic\" isn't the only (or even correct) criterion. hggigg 2 hours agorootparentprevIt does. Although I don’t use it and use this instead: https://github.com/linearmouse/linearmouse reply vehemenz 1 hour agorootparentprevConsidering most people put the Magic Mouse in the shelf and never use it, I don't think fixing the charge port is high on anyone's list. reply khrbtxyz 1 hour agorootparentprevThis is form-over-function, classic Apple. They don't want to give even the slightest impression that they are selling a wired mouse. reply canucker2016 41 minutes agoparentprevBrought to you by AI and the EU. The DRAM makers must love AI, low end iPhones increase RAM 33% (6GB -> 8GB), low end iMacs go from 8GB to 16GB. reply pbreit 35 minutes agoparentprevSeems strange that iMacs remain ~20% more expensive than MacBooks. reply wwalexander 3 hours agoparentprev> They also did move the Magic Keyboard and Magic Mouse to USB-C. Only for the bundled peripherals, it seems. The Apple Store now only lists the full-size Lightning keyboard without Touch ID in white, which is even worse than before when you could get various permutations of tenkeyless, Touch ID, and black. reply t-sauer 3 hours agorootparentI guess it was still getting updated. All peripherals are available in USB-C versions for me now. reply blinkingled 2 hours agoparentprevHopefully 8Gb isn't reserved for Apple Intelligence? reply ezfe 1 hour agorootparentIt is not reply macspoofing 1 hour agoparentprevAnd yet .. they couldn't help themselves and include a 32GB option on their top of the line iMac. reply jeffbee 2 hours agoparentprevWhy does the Magic Mouse still exist, though? If you have an iMac with the Magic Mouse, you own the only Apple device without the complete suite of multitouch gestures. It's weird that they still make the Magic Touchpad a paid option when it seems like a core part of the offering. reply Hamuko 3 hours agoparentprevSurprised that they didn't offer it with 8 GB, since they do have a 8 GB version of the M4 in the (cheaper) iPad Pro. reply Wytwwww 2 hours agorootparentThese days 8 GB is absurdly low for a ~$1300 PC. Hopefully they might have finally realized that selling crippled products (just to force its users to pay the predatory price for memory upgrades) is hurting UX and their reputation. I mean they claim: > Compared to the most popular 24-inch all-in-one PC with the latest Intel Core 7 processor, the new iMac is up to 4.5x faster.1 But is that really true if your \"ultrafast\" Mac grinds to a halt when you have a couple of Electron apps and a browser open at the same time? Naturally users who bought the base model because they didn't really understood the implications would just conclude that macOS is slow and unstable compared to Windows? reply foldr 2 hours agorootparent> your \"ultrafast\" Mac grinds to a halt when you have a couple of Electron apps and a browser open at the same time? The 8GB models could easily handle this kind of load. reply internetter 2 hours agorootparentcan confirm reply Hamuko 2 hours agorootparentprevThe 13-inch iPad Pro is a ~$1300 PC that Apple will gladly sell with 8 GB of RAM. reply angoragoats 2 hours agorootparentNo, it's not. It's a $1300 high end tablet, which (among other things) will not run arbitrary programs of the user's choosing, and which has aggressive memory management and background process restrictions. All of these factors contribute to 8 GiB being a reasonable amount of memory for such a device. reply DeathArrow 3 hours agoparentprev> 16GB base RAM, they finally did it. I've paid €200 for 128GB RAM in my PC. How much does Apple charge for 128GB of memory? reply bee_rider 2 hours agorootparentIsn’t Apple’s RAM inside CPU package? I think it might not be possible to put together a system (at least with consumer parts) that matches their memory bandwidth. On the other hand, they are limited in capacity. It is a trade off, it is silly to pretend they are just limiting memory capacity out of the vileness of their hearts or something. reply angoragoats 2 hours agorootparent> Isn’t Apple’s RAM inside CPU package? No, but their marketing department would like you to think so. > It is silly to pretend they are just limiting memory capacity out of the vileness of their hearts or something. They are limiting memory capacity and charging you 8x-10x reasonable retail price for upgrades, so that their profit margins stay high. Whether or not that's vile is something I leave to you to decide. reply wtallis 2 hours agorootparent> No, but their marketing department would like you to think so. Can you link to a teardown that finds RAM somewhere other than the CPU package? Or were you in too much of a hurry to notice that the comment you replied to didn't make the common mistake of claiming the RAM is on-die not just on-package? reply angoragoats 2 hours agorootparentIf you're trying to get into a semantic argument about the meaning of \"CPU package,\" I'm not interested, thanks! reply wtallis 1 hour agorootparentYou already made a pretty specific claim on that point. You were just wrong. reply bee_rider 2 hours agorootparentprevFWIW I wasn’t trying to start a semantic argument about the meaning of the term “CPU package,” I just thought it was a clear and specific term. reply cube2222 2 hours agorootparentprevI get your point, and Apple doesn't price RAM cheap, but it's worth noting that any RAM doesn't equal any other RAM. There's a ton of ram types with varying performance levels, and in apple's case it's RAM with direct and performant access from the graphics card (unified memory). reply kjkjadksj 2 hours agorootparentI’d much rather have had serviceable ram modules than sightly faster ram to the gpu I will never fully flex with macos software anyhow. Speaking as someone saddled with one of these computers. reply angoragoats 2 hours agorootparentprevEvery M-series Mac has shipped with completely standard LPDDR4 or LPDDR5(X) memory chips. While these can be a bit more expensive than socketed non-LP DDR DIMMS, we're talking maybe 10% more expensive, not 1000% more expensive (which is what Apple charges for upgrades vs standard retail price for DIMMs). Apple's marketing department would be happy for you to think otherwise, but the \"secret sauce\" of their high memory bandwidth is completely due to having more memory channels built into the SoC than a standard x86 CPU. reply wtallis 2 hours agorootparentprev€200 for 128GB as an aftermarket upgrade, or €200 upcharge for 128GB from a system OEM? reply shalmanese 2 hours agorootparentprevHow much does it cost you to buy a GPU with 128GB of RAM on it? reply VyseofArcadia 2 hours agoprevI love in Apple product announcements when they show people doing tasks that not only don't require recent hardware, but in fact could have been done without much trouble 20 or 30 years ago. Specifically talking about the ice cream spreadsheet that I suppose was there to show off how small businesses can use the new iMac. I'm sure it's a fine machine, but it does to me highlight the upgrade treadmill. reply tylerrobinson 1 hour agoparent> iMac with M4 features the world’s fastest CPU core, making multitasking across apps like Safari and Excel lightning fast. This stuck out for me too, plus the examples of using Siri on the desktop. I reckon that invoking Siri to say, \"Send Gema a text\" and then having to proofread and approve the message is more effort than just sending Gema a text. Same for typing out \"turn on do not disturb\". You could imagine the argument being that there are a lot of deep settings or hidden controls that people would like to find, but then wouldn't a vector search that shows relevant settings be just about the same outcome? reply steve_adams_86 1 hour agoparentprevNo way, we need local LLMS to help us populate the spreadsheet! reply LASR 10 minutes agoprevI've been looking for an upgrade from my 2015 5k iMac 27. Might finally pull the trigger on this version. What I will miss is the 27 inch 5k display. Also, my use case is exactly what this iMac is meant for - shared family computer that takes up little space in the kitchen. reply WillPostForFood 1 hour agoprevRight now, the Apple computer lineup is totally out of alignment for me. The iMac is too small and the laptops are too big. I'd like a minimum 27\" display for the iMac, maybe 31\". For a laptop, give me something more portable, like the old 2 pound, 12\" MacBook. reply wingworks 25 minutes agoparentI used to always buy MBP's, but the new gen are all those super thick and heavy models. I tried one and couldn't get used to the thickness or weight. At that point I may as well get a desktop. I ended up buying M2 new MBA (from intel MBP), screen size similar enough, thickness good, weight good. And M2 is fast enough for 99% of the things I do. I did max the RAM to 24GB and wish there was more sometimes, and would love a faster SSD. Bot overall very happy. reply space_oddity 44 minutes agoparentprevIt would be fantastic if Apple brought back that 27-inch or larger iMac for desktop users who don’t need a separate display reply el_benhameen 1 hour agoparentprevI love the idea and form of an ultraportable laptop, but I’ve had to face the reality that even a 13” monitor is just too small for me to be productive on complex development tasks. My eyesight isn’t good enough to handle tiny fonts, which could be part of the disconnect. What kind of work are you able to get done on a 12” screen? reply euroderf 46 minutes agoparentprevAFAICT the 11\" Mac Air failed in the market. It did not last long in the lineup. reply piinbinary 3 hours agoprevIt's frustrating how disposable these are designed to be edit: e.g. screen replacements cost nearly as much as the entire computer reply js2 2 hours agoparentI commented elsewhere, but my uncle is on his third iMac in 30 years. He keeps them a decade at a time. My father is still using an Intel iMac. Normal people do not upgrade their computers after purchase. Displays are generally not something that fail. These machines are capable of providing a decade or more of service to normal people. reply IndrekR 1 minute agorootparentFirst iMac was released in 1998. reply robotresearcher 2 hours agoparentprevI bet iMacs are some of the longest-average-lifetime computers out there. But I’m sad that the 27” models are obsolete computers and still-wonderful screens, and Apple removed the use-as-screen mode. reply mjlee 2 hours agoparentprevEspecially egregious when you consider older iMacs could be used as external displays - https://support.apple.com/en-gb/105126 reply laurencerowe 16 minutes agorootparentWhile it is a shame it was never brought back, at the time it was removed it was unavoidable since the bandwidth required for 5k was beyond what could be carried across a single display port cable. reply Teever 2 hours agorootparentprevI'd love to see a regulator mandate that computers like the iMac that have built in screens must have HDMI ports that allow them to be used as monitors. This would be great for the consumer and prevent a lot of ewaste as people can use obsolete computers as monitors well past their useful lifespan as a monitor. reply SahAssar 2 hours agorootparentHDMI might be a bit more complex, but displayport should be doable since most devices use embedded displayport (eDP) anyway for their built in displays. I'm guessing the main cost would be adding a switching chip for switching between external and internal source. reply ascorbic 20 minutes agoparentprevI bought an iMac in 2011 that I had for 12 years before it died. I replaced the HD with an SSD after a few years but otherwise it just kept on going. reply aqme28 3 hours agoparentprevAre you expected to replace your screen often? I don't think I upgrade and replace either one much faster than the other. Usually get a new monitor and a new PC every 4 or so years. reply mullsork 2 hours agorootparent> Usually get a new monitor and a new PC every 4 or so years. Maybe you're not quite the average consumer that OP has in mind? Maybe you are, I don't know. Either way it's unsustainable and ridiculous that the _average consumer_ would need to replace something after 4 years when it COULD be built to last. reply hatsix 2 hours agorootparentMy first LCD monitor is still actively used in our house, about 18 years old now. My mother has gone through several computers, kept the same screen for 15 years. Apple Consumers are not \"Average Consumers\". Starting at $1300, it's a luxury desktop. reply acdha 1 hour agorootparentThat’s a mid-range desktop at most in a world where people pay more than that for individual components at the high-end, especially when you look at pricing for equivalent quality displays. The correct criticism of iMacs is that it links two parts with different lifespans. There should be a legal requirement that all-in-one computers have an external connector so that if some other component fails or simply becomes obsolete you can use the perfectly functional display with another system. reply orangecat 2 hours agorootparentprevI made the mistake of getting a 27\" iMac in 2014. The 5k display is still great by today's standards but the internals are obsolete. reply stackskipton 2 hours agorootparentprevMost people I know who don't use laptop exclusively don't replace their monitors that often. My work docking station is still rocking 2017 4k monitors and my wife home setup is similar. reply Wytwwww 2 hours agorootparentprevWell.. no. But if it breaks or is damaged you basically have to throw away (the otherwise) fully functional PC. reply ahmeneeroe-v2 2 hours agoparentprevMy last iMac lasted 10-years. I replaced it with the M3 iMac for my daughter. I will be happy if it takes her through High School graduation in 2030. If the M3 iMac is still running, I expect to use it for some intro to computer stuff for one of the younger kids. Yes I cannot mine the iMac for parts at EOL, but realistically, I haven't really done that on any tower-based PC either. reply whitehexagon 2 hours agoparentprevyeah I have an older model that had the well documented faulty / fragile screen connector for the LED back lights. Very expensive replacement screen was the recommended fix! all for the sake of a tiny six pin connector. One of these days I'll split it down and see if my hands are still steady enough to solder on a new connector. Anyway it was enough to swear me off any all-in-one devices ever again. I thought by now we'd be fully modular with desktop computer hardware. reply dlevine 2 hours agoprevI'm surprised they are still shipping these with 256GB of storage base. I had a Macbook with a ~500GB SSD in 2012 (I installed it), and a 500GB spinning disk in like 2008 (also user installed). A 500GB SSD can be had for =120Hz are perfect for me personally. I just wish that the base macbook pro models supported 3 external screens without resorting to a software-based video-over-usb DisplaySync (not DisplayPort) connection. reply thibaut_barrere 3 hours agorootparentprevSo far the screens I've tested are more tiring to my eyes (I work both on a M1 13\" with external screens, and on a legacy 27\" iMac). What are the best 27\" screens for coding comfort that work well with Macs these days? reply porphyra 3 hours agorootparentApart from the Samsung Viewfinity that another commenter mentioned, there's also the LG Ultrafine 5K and the Huawei Mateview. The MateView is nicer than other 4K monitors because it has a taller aspect ratio of 3840 x 2560 so the extra 400 pixels of vertical space is nice for productivity work, although of course this is still fewer total pixels than a 5K display. reply sroussey 2 hours agorootparentLG Ultrafine 5K Has burn-in issues. :/ reply jq-r 9 minutes agorootparentI bought mine like 2 years ago and it's been rock solid. IIRC they had some revisions over the years. And being rock solid: that's a bit of a lie because the monitor is wobbly as hell. So I've propped it with two supports on each side. Apart from that, the picture is the nicest I ever had from a monitor, and I had a lot of good ones. Text is super sharp and has acres of pixels. Compared to 4K monitor I can have both a terminal client and a browser side by side all looking nice. Can't fit that on 4K unfortunately. reply Joeri 3 hours agorootparentprevI haven’t tried it myself but if you really want that 5K 27 inch form factor samsung’s viewfinity s9 is exactly that. Or apple’s studio display ofcourse. reply thibaut_barrere 3 hours agoparentprevTyping this from a 27\" iMac. I do love my 13\" M1, but I would love to upgrade the 27\" too... reply jfoster 3 hours agoprevI could never justify getting an iMac. All the downsides of a laptop & desktop in one; not upgradeable and not portable. Leaves me wondering how many of these Apple actually sell. A Mac Mini with a separate screen feels like it makes far more sense. reply graeme 2 hours agoparentThe iMacs very much aren't their main seller. A couple of key demographics use it though: * Families with a shared computer in a common room. Super simple to setup, no fiddling, low price. In the video Apple showcased this use case. My parents have an M3 imac and it works great. They had their last iMac for ten years. * Businesses buy these for reception areas and customers see the Apple logo on the back. Easy solution for a business with no IT department, great marketing for Apple. Apple will probably always sell an iMac option as long as businesses buy and display them. reply davedx 1 hour agorootparentMy daughter's orthodontist has one of these behind every chair. Our dentist has them too. HN honestly is a terrible source of information for 1) What sells 2) What might sell reply glonq 4 minutes agorootparent\"No wireless. Less space than a Nomad. Lame.\" reply talldayo 55 minutes agorootparentprevThat's fine, but personal anecdotes are also a hugely misleading source of information too. In the time since the iMac redesign was released, I've seen 10x more of the old models than I have seen of the new ones. My local barber even uses an Intel iMac in Target Display mode to run their Windows small-form-factor PC. HN is disillusioned, but so are a lot of the west coast product designers that expect businesses to buy these on day 1. The majority of businesses are going to buy whatever is cheap and effective - their realistic choice is between a Chromebox and a Mac Mini. reply bobsmith432 28 minutes agorootparentWhen I think cheap and works out of the box, Mac is the last thing on my mind. reply playingalong 1 hour agorootparentprevI have been to a on orthodontist office which didn't have any iMac. I wouldn't apply this observation to judge if the product makes sense reply graypegg 2 hours agorootparentprev+1 for the business front desk. This is by far where I see them the most. They're very easy to deploy, and most of the software you're going to need it to be running works in a browser. A windows all-in-one PC is another option... but the chance of something going wrong/being annoying in the interim between \"plunk it on the desk\" and \"open salesforce in chrome\" is definitely higher. reply aphantastic 2 hours agorootparentprevMy parents have had an iMac in their living room sitting quietly doing stuff (web apps, mainly) for 9 years now. Still works fine for all their use cases and the 5k screen remains a delight to behold. reply notatoad 2 hours agorootparenti know a few people who have an iMac in their living room like that, with the same logic as the people who still have landlines - the laptops and cell phones get put away when you get home (or stay in the home office), so you can be present with your family. but sometimes you still need a computer for stuff, like controlling the music or quickly looking something up on google. but if it's not your computer, and it's not signed in to all your stuff, you're going to quickly do the thing you need doing and then get off it again. iMac is perfect for that. it looks pretty, it's small enough that it can be put in a corner, and it's powerful enough that you can buy it, leave it there, and not think about having to upgrade it for a decade. reply saylisteins 2 hours agorootparentIt's surreal for me how something so expensive can be thought as \"perfect\" for this usecase. I'd say in cases like this having a cheap laptop or even a cheap all in one desktop computer is good enough. Why spend $2000 to browse the internet? reply graeme 2 hours agorootparentThe long support length lowers the effective cost. We only upgraded my parents' computer after ten years due to software support. It was so old it was soon going to lose even Google Chrome updates. But it ran like new. The total carrying cost over ten years is quite low. And my parents have needed much less tech help with a mac. The day to day ease matters and is worth money. reply graypegg 2 hours agorootparentprevBeing honest, I would bet the archetypical family that can prioritize \"putting the phone away and being present\" definitely skews more affluent than you may expect. reply rsynnott 2 hours agorootparentprevEh, they start at $1300 (I suspect pretty much all non-commercial purchases are the base-line one) and last roughly forever (like, a decade is not an exaggeration; you see old ones around a fair bit). There’s a market, there. Not sure what it’s like these days, but last time I checked cheap PC laptops were basically disposable; in an old job we had plastic Dell laptops for non-eng roles, and I’d be surprised if the median lifespan was much more than a year. They just broke _all the time_. Possibly things have come on, I suppose; this was a while back. reply znpy 1 hour agorootparentprev> Why spend $2000 to browse the internet? Not having to manage windows and its bullshit, most likely. Macs usually require way less maintenance than windows machines. Just install all the upgrades and you're 99% fine. reply saylisteins 1 hour agorootparentSorry for the 2000 price mark, seems like the base version costs 1300$. In my personal experience, my parents (not super tech savvy) always had a windows laptop and never had a specific windows issue due to updates and whatever. If they did, it's more app specific, not necessarily os specific. In general, I (personally) disagree with the statement that macs require less maintenance than windows or Linux, I use a mac for work, and I have a fair share of app related issues just like I would on a Windows or Linux machine. It's just my opinion. reply coryfklein 2 hours agorootparentprevI love the iMac as the main driver for my family of 5 * We want a dedicated space in the house for a family computer, so portability is no concern * It has a very small footprint * It looks the most like \"furniture\" out of all the options I've seen; pretty color & form factor, and no mess of cables. If you're male, think \"wife approval factor\". * It does everything the family needs from it; runs Steam, documents, spreadsheet, browser, school, photos/videos, etc * High interoperability with our family iPhones/iPads reply lokar 1 hour agorootparentSame here. I provide tech support to my father, on the condition that I pick the hardware, always an iMac reply newsclues 2 hours agorootparentprevYeah a family friend PC that can end up on a desk or in the kitchen, or on a milk crate as a media player in an apartment, as a family computer they get years of use over time by different people in a family. From work to life to play. reply 39896880 2 hours agorootparentprevEducation as well. Main reason why that headphone jack has stuck around I suspect. reply jfoster 38 minutes agorootparentprevOK, I want to partly take back my comment. The business use case is brilliant. reply jwells89 2 hours agorootparentprevLow number of cables has also been one of the points of appeal for the iMac, to the point that it was a focal point of marketing for the original model. For the average person's setup the current model only needs a power cable. reply mjlee 1 hour agorootparentIt's an optional extra (of course), but you can plug an ethernet cable in to the power adapter and deliver power + network over the same cable. reply bmicraft 1 hour agorootparentprev> For the average person's setup the current model only needs a power cable. Even if you use wireless input devices you'll need to charge them occasionally reply jwells89 41 minutes agorootparentOf course, but those cables (or more likely, just one cable) can be stashed away in a drawer 99% of the time. The bundled keyboard and mouse/trackpad can go months between recharges, especially with lighter less frequent use that something like a living room or kitchen machine might see. reply rgbrgb 2 hours agoparentprev> Leaves me wondering how many of these Apple actually sell I think we can check since they're public. Looks like 5-8 million per quarter [0]. Approx 10% of their computer sales [1]. [0]: https://www.statista.com/statistics/263444/sales-of-apple-ma... [1]: https://www.cultofmac.com/news/macbooks-make-up-a-whopping-7... reply madeofpalk 2 hours agorootparentNote the data isn't actually public - Apple does not break Mac revenue or sales figures down to per device. These are all just 'market intelligence' estimates. reply MBCook 2 hours agorootparentRight. They used to, they stopped many years ago. So now it’s all guesses, estimates, based on whatever. reply wongarsu 2 hours agorootparentprevCompared to 43% MacBook Pro, 34% MacBook Air, 9% Mac Pro, 3% Mac mini, 1% Mac Studio, as per the second link. So these are their most popular desktop, but by a slim margin and far behind the laptop sales reply Tagbert 53 minutes agorootparentNote that those are revenue figures, not unit sales. That is why the Mac Pro comes out so high. the unit cost is so much higher that even with low volumes, the revenue is noticeable. reply klodolph 2 hours agoparentprevI bought an iMac a while back. I left it connected to a bunch of music studio equipment. It does its job as the center of a home recording studio—gigabit ethernet and plenty of USB ports. I am not considering replacing it yet, even though it stopped receiving updates from Apple. It can’t run Logic 11 (it’s stuck on 10). reply js2 2 hours agoparentprevMy uncle is on his third iMac. He owns them for a decade at a time. When he sends emails, the subject is always \"From \" because he shared an email account with my aunt years ago and even though he no longer does, he still puts his name in the subject. That's the target buyer. reply xyst 1 hour agorootparentglorified e-mail client for $1200. Nice. reply msisk6 1 hour agorootparentFor a decade. That works out to $10 a month. Not a bad deal. reply bmicraft 1 hour agorootparentIt's still a bad deal. reply pantulis 34 minutes agorootparentI've provided my father (82 years, living 500km away from me) with hand-me-downs Mac laptops since 2009: from the initial Macbook Core Duo up to a the most recent M2 Air. He does web browsing and frequent FaceTime calls with me just for checking out how they are. Those little laptops last him until the battery dies. He could very well be using Windows with a cheaper laptop, but I consider the amount of support hours that I've saved to more than compensate for that. reply azinman2 2 hours agoparentprevMost Mac users seldom upgrade. I read here and myself often use a MacBook for 7+ years. Given screen tech changes alone, I think it makes a lot of sense. I’ve owned an iMac before very happily. I just don’t own one now because they stopped making 27” versions. reply sorum 1 hour agorootparentWhat is preventing them from launching a 27\" version? I've been waiting to upgrade our 2017 model in the living room, was hoping the 27\" was finally going to come now. Guess Mac Mini is the only route to go... reply znpy 1 hour agorootparent> What is preventing them from launching a 27\" version? most likely they (apple) think that would eat into some other market segment. for a 27\" station they probably want you to get a mac mini with a studio display. apple is known for \"gently (but firmly) nudging\" you towards the more expensive options. reply sorum 1 hour agorootparentIt does seem that way, doesn't it? Shame, it was the perfect form factor for family room, office front desk. reply ryandrake 2 hours agorootparentprev27\" iMac has been my daily driver for over 10 years, and I only replaced my last one because the screen cracked when I tried to repair it. I've got 64GB of RAM and a 27\" thunderbolt display on both sides, making excellent for both software development and video editing. I don't know what I'd replace it with if it died. reply taeric 2 hours agoparentprevI'd be interested in numbers on some of this. From my view, the upgradability is a bit of a red herring for most users. Computers are fast enough for most uses that it just doesn't matter. reply jfoster 24 minutes agorootparentThat's a really good point. It's been more than a decade since I last upgraded a computer. reply stouset 2 hours agorootparentprevAnd frankly, the “upgradeability” of most desktops is a myth in my experience. By the time I’ve ever wanted to upgrade a Windows or Linux PC, a new CPU probably isn’t going to fit into the same socket as the one I had so now I need a new motherboard too. I probably want a new GPU if it was a gaming PC and if it wasn’t I would be using an integrated GPU anyway. I think the only thing I’ve ever kept from an “upgrade” was my case and some memory sticks. But I probably would have been better off—both in time and money—just selling the damn thing as a whole and buying an entirely new set of components. TL;DR, year-over-year bumps just aren’t worth the price of upgrades, but by the time it is worth doing you probably want to upgrade so many parts there’s little left to keep. YMMV. reply michaelt 2 hours agorootparentDepends where you are in your life, I suspect. A person in college on a tight budget might choose a budget-conscious PC, with an average amount of RAM and a modest hard drive. A few years later, component prices will have fallen and the PC will be showing its age thanks to its modest components. Adding a larger hard drive and more RAM will get a few more years out of it. On the other hand, a mid-career professional programmer has plenty of disposable income, so if they're buying a PC today they can chuck in 128GB of RAM and not need to upgrade for the next 10 years. reply acdha 1 hour agorootparentIf they bought a “budget conscious” PC, what are the odds that they’ll have hit the limits of their RAM but not any other component? If they bought a cheap laptop, for example, what are the odds that the hardware isn’t starting to fail? If it’s a desktop, what are the odds that by the time they need a new CPU a worthwhile upgrade will still be socket-compatible? Usually the budget options are already well into the service lifecycle for things like that and at least anecdotally the budget buyers I know buy a new one 1-2 times per decade rather than upgrading anything. reply wongarsu 2 hours agorootparentprevIf you want a new CPU after a decade it's absolutely as you describe: you need a new mainboard and probably new memory (DDR5 just came out), and end up keeping only the case, drive, case fans and PSU, if that. For other components it mostly works. You can smoothly upgrade from 8GB RAM all the way to 128GB, get a new GPU, whatever the current WiFi standard is, more silent cooling, more, bigger or faster drives, etc. If you replace something every 2-3 years you can ship-of-theseus the same computer for a surprisingly long time at pretty low cost reply stouset 2 hours agorootparentI have been building and upgrading PCs for like thirty years, from 10 to 40 and through varying degrees of expendable income. I genuinely cannot ever remember there being a time where it made sense to upgrade a single component. I’m not going to say it doesn’t make sense to do so for anyone, but it certainly wasn’t in my experience. reply neilalexander 1 hour agorootparentprevYou can hit a RAM limit on some lower-end motherboards quite quickly depending on the memory controller and you might only get so far with GPUs as well depending on the type of PCIe slots. reply wtallis 1 hour agorootparentI'm not sure what decade you have in mind, but for all the recent ones, the memory controller has both been on the CPU, and not been part of the differentiation between low-end and high-end CPUs for a given socket. So the only significant RAM limitation coming from the motherboard is if it's a small form factor board with only two slots instead of four. reply captnObvious 2 hours agorootparentprevI agree with you entirely except for if we skip the year over year part.5- Time of purchase upgrade ability, if we’re talking about getting to 128 or 256 GB of RAM. Time of purchase to upgrade to multiple high res screens that match. Dedicated GPUs… I bet there is a top of the line home hobbiest LLM oriented GPU from Nvidia or AMD in the next 3 years that will cleanly connect to recent chip architectures. I doubt it will run optimally tied to a Mac. It’ll be something that you could also rack in a server. reply jxdxbx 53 minutes agoparentprevFor a long time the best Apple display you could get was in the iMacs. An iMac with nothing used with it besides a wireless keyboard and mouse, where you can even hide the ethernet port in the power brick, makes for a nice clean desk. reply space_oddity 48 minutes agorootparentAbsolutely, the iMac’s display quality has been a big draw for years, especially when Apple's external display options were limited. reply HeckFeck 1 hour agoparentprevYou’re completely right and yet the sight of one fills me with desire. Possibly because it has a direct line right back to the original Macintosh. Such that when I showed my 11yo cousin my Macintosh SE, he called it an ‘iMac’. reply racl101 49 minutes agoparentprevThey are perfect for suuuuuper casual people. Perfect for your grandparents for example. Most people I know who own these are elderly. Yes, an iPad would also work or a MacBook too but elderly people aren't travelling nor are they gonna buy a MacMini and get a monitor. They just need their simple to set up, all-in-one desktop computer. reply rwmj 2 hours agoparentprevMeet my relatives who recently retired an x86 iMac, upgraded to an Arm-based one, and will probably upgrade to something like this, but only after another 7-10 years, when the current iMac is far out of support and getting so slow that it becomes unbearable. They use it as a shared family computer, almost exclusively for downloading photos from a (also very old) digital camera and watching Youtube videos. Judging by the sibling comments I'm not the only one with relatives like this! reply runjake 53 minutes agoparentprevSince none of the options there are tangibly more upgradeable than the other, you can reduce your point to \"The iMac is not portable.\" I bet that iMac M4 sales meet their target, which is probably on par with the iMac M1 sales. And those were apparently good enough that they finally released an updated model. reply gehsty 1 hour agoparentprevI think iMacs end up where someone wants a computer to look nice (either personally or professionally). You could have these in a none tech environment and they will look good. reply space_oddity 46 minutes agorootparentiMacs have always been as much about aesthetics as performance, and they do fit beautifully in environments where style is key, like design studios reply mhh__ 2 hours agoparentprevBut just think of the satisfaction you'll have at your computer being tiny in the dimension you can't actually perceive when using it! reply Tagbert 50 minutes agorootparentMost computers are part of a 3D space where you can occupy more than just the frontal view. You will notice the screen thinness from other angles. it's not the most important aspect but it a nice enhancement. This are often used in environments where they are seen from other angles like homes, front desks, schools. reply space_oddity 50 minutes agoparentprevIt suits users who prioritize a clean setup, minimal cable clutter, and don’t need the flexibility to upgrade components down the line. reply notjustanymike 2 hours agoparentprevIt's the computer equivalent of a fleet car. reply jedberg 2 hours agoparentprevAt the very least, they use them at the front desk of every Apple building for the admin who signs people in. :) I had one during the pandemic. I got it at a steep discount but it was really nice when I didn't need to go anywhere. I'm giving it to my son to put in his room. Seems like they're useful for families and kids, and corp environments that use Macs for the folks who work in office and don't move around (admins, lab workers, etc) reply jccalhoun 38 minutes agoparentprevschools are a big one. If they are going to buy macs, being all in one the school IT doesn't have to worry about a separate monitor to troubleshoot problems with. reply martin_a 2 hours agoparentprevI don't see the point in them anymore, too. 24\" screen size is not interesting and I can't get more displays that do look like the first one. Will always look strangely mixed in environments. edit: ok, others pointed out possible use cases. was thinking about the reception one, too. reply insane_dreamer 2 hours agoparentprev> not upgradeable and not portable your average user (aka not HN-er) doesn't upgrade their computer an all-in-one solution is very attractive for families or situations where you don't need to tote around a laptop and you want a large screen reply xutopia 2 hours agoparentprevI was considering an iMac but decided against it because I couldn't use it as a secondary display for my work laptop. reply gigatexal 2 hours agoparentprevYeah ... I wish they kept the iMac Pro line. An M4 pro in that body heck even with a larger 32inch screen would be awesome! reply symlinkk 1 hour agoparentprevThe “separate screens” you can buy all suck. They aren’t 5k resolution, and they always have some weird edge case issue you find out about 2 weeks after you buy it. reply fire_lake 2 hours agoparentprevVery low desk clutter though. Power cable, maybe a mouse. Nothing else. reply wffurr 2 hours agoprevWhat's with the green iMac picture? https://www.apple.com/newsroom/images/2024/10/apple-introduc... It only shows two USB-C ports while further down the marketing material talks about \"all four USB-C ports\". EDIT: the low-end 8-core model for $1300 only has two ports. It also has what looks like a rear-facing camera in the stand cutout. What is that for? EDIT: It's the magnetic power connector. I did not expect that to be round. Supposedly there's a gigabit Ethernet port somewhere too. Not shown in any of the pictures on the site that I can find. reply fourfour3 2 hours agoparentThe gigabit ethernet port is in the power brick. reply robotresearcher 2 hours agorootparentThat’s a cool idea. The desktop has only one cable even on wired network. Neat. reply traceroute66 2 hours agoparentprev> What's with the green iMac picture? The picture is of the base model. The upper model is featured on their main website[1], which shows this image [2] [1] https://www.apple.com/imac/ [2] https://www.apple.com/v/imac/q/images/overview/closer-look/c... reply goosedragons 2 hours agoparentprevThe base model iMac only has two Thunderbolt ports. reply traceroute66 2 hours agorootparent> The base model iMac only has two Thunderbolt ports. Indeed, per specs [1] [1] https://www.apple.com/imac/specs/ reply jprd 2 hours agoprevI love the innovation Apple has brought with their investment in ARM. That said, I can't imagine buying a computer in the 21st century that can't be opened and upgraded, especially with a price premium attached. I just don't get it. I am in no way trying to be combative, but I'd love to hear a counterpoint that makes sense for these machines. reply thrwaway1985882 2 hours agoparentFor professional use, the idea of \"opening up and upgrading a machine\" feels wild. You're either given one by your employer or buying one yourself, and either way, it's on a 5 year deprecation schedule. It's a negative ROI for me as a solo or for my employer to ever do anything with a device that isn't \"oh it's broken? too slow? new one being UPSed this afternoon\". reply 2arrs2ells 2 hours agoparentprevI bought an M2 iMac for my parents. It’ll last at least five years for them - likely closer to 10. At that point, I’m happy to recycle or donate it and get them a new iMac - likely with some major updates (form factor? Display? Etc?) that wouldn’t get with a RAM / CPU upgrade. Spending ~$150-$300/year for them to have an easy to use & fast computer feels very worth it for me. All that said - I would love for the machine to be upgradeable as well! Just explaining why it’s not a dealbreaker. reply sleepybrett 1 hour agorootparentSame, I had to panic buy a 13\" m1, i was remote working extra remotely and my laptop got destroyed. The 13\" m1 was not an ideal machine, it had limited usb ports, limited ram.. but it was pretty quick and I wasn't going to buy intel. A few years later the m2pro/max's came out (i think technically in 14\"). I picked one up and just handed my m1 down to family. Huge upgrade over their old intel air that had already lasted them like 10 years. My main bitch is the soldered in storage. It's a shitty optimization that has to punish apple as much as it punishes users. To have a machine that I can't just go buy a harddrive and slot in when i want more storage or when the drive fails is a total fucking nightmare. reply slashdave 1 hour agoparentprevI used to work on my car engine too. These days, I open the hood (it's a hybrid), scratch my chin, and then close it again and bring it to the dealer. reply cududa 2 hours agoparentprevMost people don’t want to open up their computer. Ever. And for most people who dont want to open their computer, they’ll probably use these iMacs until their ancient, and replacing the whole thing makes more sense anyway reply kgwgk 1 hour agoparentprev> I can't imagine buying a computer in the 21st century that can't be opened and upgraded Because opening and upgrading computers is a 21st century thing and not a 20th century thing? I'd say it's the other way around! reply askafriend 2 hours agoparentprevI replace my computers before I ever feel a need to upgrade them. Computers are fast and performant for a long time now (4+ years, especially for non-professional use). And as someone who works with computers all day long, I never ever want to open one up unless I build one from scratch and want a personal project. reply lomase 1 hour agorootparentWhat about the screen? reply asoneth 33 minutes agorootparentOnce upon a time I'd use the same monitor for several generations of desktop. But lately monitors feel like they're advancing more quickly and computers more slowly such that I end up replacing them after about ten years. I personally appreciate not having to do both at the same time, but at least for me it has reduced that particular criticism against all-in-ones. reply brailsafe 52 minutes agorootparentprevWhat about the screen? Although I do have an external display, I haven't found a compelling replacement in the 10 years it's been going. That said, the 24\" iMac screen is not in the slightest bit compelling to me reply dsv3099i 2 hours agoparentprevMy guess is the only reason to open and upgrade a computer is if one needs (or wants) to be on the bleeding edge of what local compute is capable of on a day to day basis. With the advent of cloud compute the number of use cases that meet that criteria shrinks every day. With the iMac there is a price premium but what the users is paying for is a computer that just gets out of their way. For them the computer is simply a means, not an end. reply sleepybrett 1 hour agorootparentMost of my buddies w/ PCs for gaming generally only open up their machine to upgrade their video card, once their motherboard no longer supports the latest and greatest they just dumpster the whole damn thing (maybe sell the card on ebay), or turn it into a plex server or something and start over. reply xyst 1 hour agoparentprev> that can't be opened and upgraded One of the reasons I don’t buy into Apple’s marketing gimmicks especially when it comes to the “carbon neutral” initiative. > especially with a price premium attached. I just don't get it. Apple is a public company. Investors expect them to churn out profit so stonk goes up. As long as users are trapped in their Apple ecosystem/wall, then they will keep buying. If the devices were open and upgradable then the company will not be able to charge a stupid high markup for RAM or storage. If products were easily upgradable, consumers would buy the base model configurable SKUs then take their business to repair shop and get ram and storage upgraded at a fraction of the cost Apple would provide out the door. > but I'd love to hear a counterpoint that makes sense for these machines. There is no counterpoint. Most people (ie, not fanboys) would agree with you. There is absolutely zero reason for devices to not be upgradable or easily serviceable. You don’t become a trillion dollar company by playing nice with your users. reply phs2501 3 hours agoprevWhy does this still have the ridiculous iMac chin? Surely they can fit everything behind the screen at this point. reply wpm 3 hours agoparentThe chin gives you a good touch-point for adjusting the angle of the display and the rotation angle of the entire base, without having to worry about touching the screen/screen bezel and getting finger prints on it. It's also a great place to tack post-it notes. reply space_oddity 42 minutes agorootparentSticking notes...Not everyone understands how necessary this is for some people reply fdvdf 2 hours agorootparentprevNo chin can be adjusted fine on basically any other display on the market today. reply kjkjadksj 2 hours agorootparentprevYou can do that with a regular monitor too reply spankalee 2 hours agoparentprevI think they keep the chin because it's the only thing that visually indicates that this is an iMac and not a monitor, and thus worth more than $500. reply Eric_WVGG 3 hours agoparentprevIt makes a lot more sense if you look at the iFixit teardown. https://www.ifixit.com/Teardown/iMac+M1+24-Inch+Teardown/142... reply alberth 3 hours agorootparentDoes it though? The iMac is basically the same as the M4 iPad Pro, and the iPad Pro doesn't have a chin. reply wolrah 2 hours agorootparent> The iMac is basically the same as the M4 iPad Pro, and the iPad Pro doesn't have a chin. Cooling seems like it might be a factor here. The iMac's display is probably going to be run at a brighter (and thus hotter) setting AND it's more likely to be used to do things that require high load for extended periods of time, so putting it in its own space probably helps. reply dagmx 2 hours agorootparentpreviMac has active cooling, more ports and more power available to it to drive those ports (though the PSU is external, it’s still gotta have the internal circuitry to deliver that). Those all do have to go somewhere. reply fckgw 3 hours agoparentprevThey literally can't. They moved the headphone jack from the back to the side because it was too long. Now you could argue if it needs to be that thin but for the current configuration, there's nothing you can cram behind the screen. reply phs2501 3 hours agorootparentFor something that's literally designed to sit on a desk, yes... it's ridiculous to make it thinner in a dimension you never see vs one that you see all the time. reply aabhay 3 hours agorootparentAesthetics is also for the environment of the object rather than the primary user. That’s the reason the logo is on the back reply ahmeneeroe-v2 2 hours agorootparentprevOne more vote for aesthetics here. I put a lot of effort into making my home beautiful. iMacs respect/complement that effort for me. reply stu2b50 3 hours agorootparentprevMany of these are customer service desks which are visible from the side. reply hengheng 3 hours agorootparentpreviMac has always been a device to be seen with, if not for the user then for the manufacturer. reply porphyra 3 hours agorootparentprevFrom the ifixit teardown of the previous M1 model [1], it seems that all the compute is going in the chin. They can't put the compute in the back of the display itself, while maintaining the same thickness like an iPad (which has the same CPU), because the room behind the displays is dominated by the speaker system, allowing the iMac to have surprisingly good audio quality despite being so thin. [1] https://www.ifixit.com/Teardown/iMac+M1+24-Inch+Teardown/142... reply vehemenz 44 minutes agoparentprevSurely we are beyond concern with bezels, chins, and other frivolous mobile phone aesthetics at this point. reply giraffe_lady 3 hours agoparentprevwhere do you put ur sticky notes? reply tomjen3 3 hours agoparentprevSomeone got into their mind that it was important that everything is as thin as possible - hence the chin. I miss the times when they used the form factor to actually make new shapes - both the sunflower and the cube looks more futuristic than the 2024 iMac. reply candiddevmike 3 hours agoparentprevThese look hideous tbh. I'm waiting for the iMac to flip vertically and ask me to tip. reply ttul 2 hours agoprevNote: The 24” iMac is never going to be the platform of choice for HackerNews readers. reply declan_roberts 2 hours agoparentI recommend these to friends who want a simple computer setup. Many people have dramatically different needs and wants than I do as a software professional. Apple knows this, and so it markets it to them rather than to us. reply mixmastamyk 2 hours agoparentprevWith an M4 and 16gb+ ram it is more computer than anything I’ve ever owned. I write text files for a living. Might be able to limp along on a souped up 486, definitely a Pentium 90. reply mrweasel 1 hour agoparentprevI could do my work on one, but yeah, the screen size would be annoying long term. The sad part is that it's the exact form factor my dad wants. It's absolutely perfect for his needs, except it's wildly overpowered and overpriced. The 4K monitor is going to push up the price, and I'm all for giving everyone a high quality monitor, but I'd argue that the iMac is 30-40% over budget for those who'd like that type of computer. I think you could get away with having it be a $1000 computer, but not $1600, for the lowest spec'ed model. reply alberth 3 hours agoprevI'm glad to see Nano-Texture coming to their budget line. That was definitely unexpected. reply lapcat 2 hours agoparentHopefully they'll add an option for the M4 MacBook Pro too. I've been waiting 15 years for Apple to reintroduce a matte display to the MacBook Pro. reply seshagiric 1 hour agoprevIt's almost becoming a bother of how accurate the rumors are becoming now a days. With this release they were spot on with the 16gb min ram and no change in screen size. I am not building LLMs on my computer (I wish :)) but I do use my iMac for both work and photography. Lightroom slugs big time on my 2019 iMac. My dream spec for the next iMac would be: - bring back the 27\" form factor - dumb down use as monitor. My work computer has disabled file & screen sharing so current methods dont work. I just want to plug my work macbook using a cable or wireless and use the imac as a display. reply speedgoose 3 hours agoprevDo you think there is a chance that they will remove the huge bottom bezel one day? It may be part of the iMac design identity at this point, but I don’t like it since its appearance on the iMac G5. reply thedangler 49 minutes agoprevI'm waiting to replace my 2015 MBP with an M4 MBP. I bought the m2 Studio Max and love it. But I need a mobile computer. Working only at my desk sucks sometimes. reply umanwizard 47 minutes agoparentWhy wait? The M3 MBP is basically perfect. reply skybrian 2 hours agoprevI have a more than a decade-old iMac with a 27” display that I’m stil using as a monitor (though it’s seen better days), so that worked out well, but a Mac mini and an external monitor seems better in every way. Which monitor to get, though? Maybe Apple should sell a Mac mini bundled with a nice external monitor instead of iMacs. reply simonw 2 hours agoprevAs someone who mucks around with running LLMs and other large models on my computer the 32GB maximum RAM is a show-stopper for me. I'm on a M2 with 64GB at the moment and I'm already regretting not going for 96 or even 128. I want to be able to run a large model AND other apps at the same time. reply traceroute66 2 hours agoparent> As someone who mucks around with running LLMs and other large models on my computer the 32GB maximum RAM is a show-stopper for me. To be fair, I don't think people mucking around with large LLMs is the primary target market for the iMacs. The sort of people who muck around with LLMs almost certainly already have a monitor, keyboard and mouse. And so are more likely to pick up a Mac Studio which will no doubt be coming soon with M4 Ultra. reply diggan 2 hours agorootparent> And so are more likely to pick up a Mac Studio which Although price-conscious LLM muckers are most likely to pick any Apple-hardware. You can easily build rigs that are twice as powerful for half the price, assuming we compare desktops. reply DrPhish 1 hour agorootparentTrue. eBay dual-socket Epyc systems ala https://rentry.org/miqumaxx are a great case in point. reply whiplash451 2 hours agorootparentprevOr separate concerns and shell out on a Studio display with the-mac-you-like on usb-c reply talldayo 2 hours agorootparentOr buy a real computer, plug in an Nvidia GPU, and save your DRAM for compute while using your VRAM for inference. reply lynguist 1 hour agorootparent16 GB or 24 GB for inference doesn’t cut it for large models… Mac hardware offers up to 128 GB shared RAM. reply nickthegreek 2 hours agorootparentprevSo now you just limited to 24gb unless you are running dual 3090s or leave the consumer market for a gpu. reply talldayo 2 hours agorootparentI mean, model layering has been around for several years now: https://huggingface.co/blog/lyogavin/airllm reply Philpax 1 hour agorootparentMoving the weights between the CPU and the GPU significantly limits performance. It's not comparable to having the entire model resident within video/unified memory. reply klodolph 2 hours agoparentprevSure, but to be honest, I don’t think you should be shipping a high-spec computer with a built-in screen. Anything high-spec should be broken into at least a separate screen and computer. The screen is such a major point of failure. I’ve seen so many iMacs and MacBooks with broken screens where the end solution is to replace the entire device, which is a waste. It’s that much more of a waste if you are getting a high-spec version. reply seanmcdirmid 2 hours agorootparent> The screen is such a major point of failure. The screen of an iMac (at least the 5K 27\" one) is the part that still has value, so its annoying when you can't use it on new hardware. reply squarefoot 2 hours agorootparentI was surprised to find out that along older VGA/HD LCD controllers now there are also 3rd party boards to drive 5K Apple screens. Look for \"5k screen controller\" on Aliexpress. Price range from ~130€ to 300+€, no idea about the quality. reply throw0101d 2 hours agorootparentprev> The screen of an iMac (at least the 5K 27\" one) I've had a few of these iMacs and would like another. When I buy a new one (every ~5 years) I hand down the old one to a family member (the last one is ~10 years old now, and stuck at macOS 12(?)). I like the form factor as it is convenient. I'm typing this on 2019 Retina 5K and am hoping Apple will bring back that form factor (there have been rumours of a 32\", but that's a bit too big IMHO). As it stands, it looks like the Asus PA27JCV has similar specs, and so I may end up with that and an Mac mini. reply klodolph 2 hours agorootparentprevYes, that is annoying. There’s also such a massive price difference between 4K and 5K monitors. I’ve decided just to accept 4K everywhere because it’s so much cheaper. But I would consider getting a 5K iMac. reply seanmcdirmid 23 minutes agorootparentI have a 28\" 4K from LG and a Samsung 27\" 5K. It wasn't that bad, $5-600. reply throw0101d 2 hours agorootparentprev> Yes, that is annoying. There’s also such a massive price difference between 4K and 5K monitors. Perhaps check out the Asus PA27JCV: 27\" at 5120x2880. reply vesrah 1 hour agorootparentThe unfortunate part is that these aren't for sale yet and we don't know how they actually compare to the existing LG 5k or Apple Studio display. It is nice to see more options coming to market. reply msisk6 1 hour agorootparentprevI have a MacBook Air on my desk plugged into a Apple 27-inch 5k Studio Display next to my work MacBook Pro plugged into a cheap AOC 27-inch 4k display via HDMI and frankly there's not much difference. The speakers and mic in the Apple display are nice, but if you're just concerned about the display itself save yourself the bucks and stay with the 4k. reply ellisv 1 hour agorootparentprevIt's really a shame that Apple discontinued target display mode. reply sleepybrett 2 hours agorootparentprevI know that some of the older imacs could still work as a monitor using 'target display mode'. Would be nice, however, if apple could design an imac where the actual computer is a module you can snap into an older one to upgrade it. At some point we need to stop putting these things into landfills or even recycling them. I've been using the same PC case for at least 10 years ship of Theseus style and the same monitors for 5. I appreciate apples recycling stance but even better is a reuse stance. Even just stripping back all the aluminum, melting it all down, re casting it and then remachining it has a significant cost. For the last 10-20 years apple has been pretty good about reusing case designs for a few generations before doing some kind of redesign. Seems silly that I can't swap out a motherboard for a m2 macbook for an m3 macbook. (maybe this would also stop them from fucking soldering the storage to the motherboard since an upgrade that wipes my whole machine is utter bullshit) reply cududa 2 hours agorootparentprevGreat. But plenty of consumers disagree with you, which is why this product exists. Not everything you see is designed to be useful for you specifically reply falcor84 2 hours agorootparent> plenty of consumers disagree with you What do you mean? This was just announced, no? Are there any sales/pre-order figures already? Also, how would you even go about analyzing the counterfactual of whether the number of people who would buy this spec are \"plenty\" compared to the number who would have bought a spec with more RAM had it been available? reply cududa 1 hour agorootparentWell by virtue of the fact that they've sold these un-repairable/ un-openable macs for 3 years now, and they're refreshing it instead of killing the product - all these things indicate consumers like the current approach reply GeekyBear 2 hours agorootparentprevExactly. Someone who is looking to muck about with LLMs isn't looking to pay for a 4k screen that cannot be separated from a non-upgradeable PC. If you're in the Apple ecosystem, you're going to want eithet a Mac Mini Pro or a Mac Studio, depending on where the RAM configurations on the Mac Mini Pro tops out. . reply simonw 2 hours agorootparentprevYeah, that's my biggest complaint with iMacs: I want to be 100% certain I can repurpose them as monitors later in their lives. I have a ten year old iMac at the moment that would make an amazing second monitor... but it doesn't quite have the features I need to use it like that. An HDMI input would be great. reply lisper 2 hours agorootparent> An HDMI input would be great. There is a reason that is difficult to do: the licensing terms for HDMI require manufacturers to put DRM in place to make it impossible (or at least not straightforward) to record from an HDMI source. It's nearly impossible to meet that requirement on a computer. reply buccal 2 hours agorootparentHP does HDMI-in in somo of its AIOs: https://www.hp.com/us-en/shop/pdp/hp-eliteone-840-g9-all-in-... reply lisper 2 hours agorootparentIt's not impossible, but it has to be a completely separate signal chain that bypasses the PC. (Well, OK, it's theoretically possible to do it other ways, but it would be really hard.) reply tcoff91 2 hours agorootparentprevDisplayPort doesn't have that same restriction, right? reply lisper 2 hours agorootparentI don't know, but probably not. It's a legal requirement for HDMI, not a technical one. It's actually not hard to build an HDMI recorder, you just can't legally sell one. But bootleg recorders are easy to find. reply sleepybrett 2 hours agorootparentprevThey could design it in such a way that the hdmi input port bypasses the whole 'computer' and goes straight into the display board. If it's plugged in the 'computer' could either not boot or just run headless, i'd prefer the former (just to save on energy costs). reply fwip 2 hours agorootparentprevCouldn't you \"just\" wire the HDMI port to the panel control logic? That is, the HDMI-in doesn't connect to the computer part of the iMac, just to the display circuitry. Edit: nevermind, I see you addressed this in another comment. reply hultner 2 hours agorootparentprevYou probably know this but it’s possible to buy a controller card for the panel on Ali Express and retro-fit into the case and use as a monitor if you are ready to retire the computer itself. I’m contemplating doing this myself at some point but my maxed out 2019 iMac upgraded to 128GB ram and extra SSD is still plenty fast for me, actually feels subjectively quicker than my M2 Pro MacBook Pro with significantly less ram feel. I was a bit surprised as I had read all the hype of the responsiveness of the Apple M-machines. reply eastbound 1 hour agorootparentprevIf they could be used as monitors, then my iMac 2018 would still be worth 1700€ (the price of the Apple monitor)! Instead, the 2018 iMac is incredibly slow, and can be thrown away. reply vineyardlabs 2 hours agoparentprevRAM aside, it would be silly for you to ever buy this model for your use case anyway. This is the base M4 that's also in ipads with no active cooling. If your running large LLMs locally, you aren't the target market for this product. reply xyst 1 hour agoparentprevThis computer appeals to families that use their computers to browse social media. For grandparents that browse YouTube with reckless abandon. The emphasis on multiple color options is a strong indicator. Even has some “cutesy” appeal for college students to decorate their dorm. The “Apple Intelligence” branding is nothing more than a selling point. Sure it might run some very small LLM workloads , but don’t expect much especially in the locked down hell known as Apple ecosystem. This is not meant for heavy workloads. reply wtallis 2 hours agoparentprev> I'm on a M2 with 64GB at the moment and I'm already regretting not going for 96 or even 128. You're using a M2 Max, not a M2. Two (big) steps up the chip product stack from what's used in the iMac. reply sroussey 2 hours agoparentprevI have a M2 with 64GB and find that it’s fine. Larger models that don’t fit are only moderately better, while much slower. I’d want higher memory bandwidth over more memory. The next five years will push for better models that are smaller. Smaller is faster and more useful. I feel like we are in the brute force phase of model development and that it will pass. Running 405B param model in 16bit on my laptop would be neat, but I’d stop after the novelty wore off. reply lanza 1 hour agoparentprevWhen shopping for a new car to take to the race track on the weekends did you stop and point out that the Honda Odyssey's suspension is too soft? reply dagmx 2 hours agoparentprevYou have a higher tier M2. This is the base M4. The comparison is apples to oranges. reply notarealllama 2 hours agorootparentIt's literally Apple to Apple reply sroussey 1 hour agorootparentRyzen 3000G vs Instinct 300A — both literally comparing AMD to AMD. Sheesh reply declan_roberts 2 hours agoparentprevWhich models are you running? I'm on a M2pro w/ 32gb and I can run meta llama 8B on lmstudio pretty decently while coding. reply simonw 2 hours agorootparentYeah 8B is fine but I really want to run 70B (or even 405B but that's way outside my system at the moment). I can run 70B at the moment... but not if I also want Firefox and VS Code at the same time. reply insane_dreamer 2 hours agoparentprevI missed the \"also great for mucking around with LLMs!\" in the press release reply neodymiumphish 1 hour agoparentprevThis is the chief reason I’m closely watching this week’s releases from Apple. I’ll hopefully be switching from UnRAID to a Mac Mini or Mac Studio and a multi-drive enclosure, but the Mac needs to support enough RAM for my various services (Plex and Immich primarily) as well as enough to test some large LLM models as a replacement to constant Claude/OpenAI API utilization. reply mark_l_watson 1 hour agoparentprevFor many use cases you are correct. That said, I bought a 32G M2 Mac mini in January, and mostly using Ollama, I use local LLMs for many useful local apps and many experiments. I augment running local models with Colab Pro, Grok APIs, OpenAI APIs, etc. reply bonestamp2 59 minutes agoparentprevSame here, I wish I went for 128. That said, I don't think this use case applies to 99.9999% of iMac buyers. reply beAbU 1 hour agoparentprevI'm pretty sure the iMac with no upgradeable RAM nor external GPU support is really targeting the hobbyist big-compute crowd anyway. So you don't have to worry, they are not trying to make you buy one. reply steve_adams_86 1 hour agoparentprevSimilar case here. I'm on a 32GB Mac Studio and constantly wishing I had 128. I didn't expect that when I chose 32... I'd been getting by fine with 16 for a decade. I was \"future proofing\", haha. reply gigatexal 2 hours agoparentprevM3 MAX here with 128GB ... and even that's not going to be enough one day. I bet the M4 Max goes to 256. Oh the envy I will have. reply a_wild_dandan 2 hours agorootparentI'm so jazzed to comfortably run Llama 3 405b on my Mac with less quantization. reply efficax 1 hour agoparentprevIt's an iMac, the target market is not running local LLMs or doing machine learning research reply jollyllama 2 hours agoparentprevHuh, is that a step backwards for them? iMacs from over 6 years ago were upgradeable to 64 reply tiltowait 1 hour agorootparentThe M-series is a little more complicated. The M1 was max 16GB, with the Pro and Max going up to ... 64, I think? The latest models can go higher, but we're still a long ways off from the old Mac Pro's 1.5TB max. reply flemhans 2 hours agoparentprevWhen I first scanned your sentence I assumed you were gonna write that 32 GB is now the minimum, not the maximum. reply lynguist 1 hour agorootparentBut that means the next Air will be upgrade worthy for those who want an Air and a memory uplift from 24 max to 32 max! reply turnsout 2 hours agoparentprevI'll be curious to see if the Mini has an M4 Pro option, and if so, what the RAM ceiling will be! reply sroussey 2 hours agorootparentI guess we find out tomorrow. reply anthk 1 hour agoparentprevAnd here I am with 1GB and 512MB as ZRAM on an Atom Netbook. With SBCL. reply znpy 1 hour agoparentprev> As someone who mucks around with running LLMs and other large models on my computer the 32GB maximum RAM is a show-stopper for me. your specific use-case is probably irrelevant to apple. > I want to be able to run a large model AND other apps at the same time. you answered yourself... go for a machine with 96 or 128gb ram. btw for the money you'd be spending (6-7 k$) you might as well rent or buy a dedicated box with 128, 256gb or more ram and all the gpus you need. reply grecy 1 hour agoparentprevIt sounds like you should buy products in the \"pro\" line. reply vid 1 hour agorootparentI think the OP's point is that Apple is forcing people to pay a lot more for something that doesn't cost Apple that much (extra RAM) and is part of artificial product lines. One could claim the product lines are important for ultimate profitability, but Apple makes so much money it's hardly critical if they wanted to be a truly incredible consumer focused company. Apple has gotten far away from the idea of a home computer someone can hack with, where hacking includes local AI these days. In this period we know more memory is important for many applications of local AI, which they claim is a goal to provide for people, so it's hard not to say Apple's approach is optimized for shareholders, not end users. reply grecy 12 minutes agorootparentThen it sounds like OP ( and yourself) should spend your money elsewhere. I mean, I’m livid Ferrari don’t make a cheap commuter for my family and 9 dogs. So I shop elsewhere. reply pmarreck 1 hour agoparentprevCame here to post this. Although I'm looking for an M4 Macbook Pro with 128GB RAM for the same reason. This going to be announced? #OneOfUs #OneOfUs reply sroussey 1 hour agorootparentMy guess is Wednesday. - iMac today, USB accessories - Mac Mini on Tuesday, likely debut M4 Pro - MacBooks on Wednesday, debut M4 Max Now in the “I wish” category (zero percent chance): - Thursday would be MacStudio with HBM memory for Max and Ultra - Friday would be macPro with 1 to 4 Ultra in NUMA configuration. Now I don’t believe those last two. But I do want to see the X-ray of the max chip to see if it has the UltraFusion part that allowed for combining two chips. It was missing from the M3 Max (and maybe all future odd numbered max chips). If it returns, then we know an Ultra is on the way for sure. reply sleepybrett 2 hours agoparentprevwhy would you want an imac of all things for that? I suspect we are going to see m4 studios, whi",
    "originSummary": [
      "Apple has introduced a new iMac with the M4 chip and Apple Intelligence, offering improved performance and vibrant color options.- Key features include a 24-inch 4.5K Retina display, a 12MP Center Stage camera, and Thunderbolt 4 connectivity, with the M4 chip delivering significantly faster productivity and performance compared to the M1.- Apple Intelligence adds systemwide Writing Tools and a redesigned Siri, enhancing user experience and privacy, with pre-orders starting at $1,299 and availability from November 8."
    ],
    "commentSummary": [
      "The new iMac with M4 features includes USB-C ports, 16GB base RAM, and a 24-inch display, sparking discussions on its pros and cons.- Users appreciate its simplicity and aesthetics, making it ideal for families and businesses, but criticize its lack of upgradability and inability to serve as a monitor once obsolete.- The design, particularly the chin, is debated, with some users desiring a larger screen or more RAM for demanding tasks, while others prefer customizable options like the Mac Mini or Mac Studio for professional use."
    ],
    "points": 269,
    "commentCount": 567,
    "retryCount": 0,
    "time": 1730127781
  },
  {
    "id": 41968409,
    "title": "Write code that is easy to delete, not easy to extend (2016)",
    "originLink": "https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to",
    "originBody": "2016-02-13 Write code that is easy to delete, not easy to extend. “Every line of code is written without reason, maintained out of weakness, and deleted by chance” Jean-Paul Sartre’s Programming in ANSI C. Every line of code written comes at a price: maintenance. To avoid paying for a lot of code, we build reusable software. The problem with code re-use is that it gets in the way of changing your mind later on. The more consumers of an API you have, the more code you must rewrite to introduce changes. Similarly, the more you rely on an third-party api, the more you suffer when it changes. Managing how the code fits together, or which parts depend on others, is a significant problem in large scale systems, and it gets harder as your project grows older. My point today is that, if we wish to count lines of code, we should not regard them as “lines produced” but as “lines spent” EWD 1036 If we see ‘lines of code’ as ‘lines spent’, then when we delete lines of code, we are lowering the cost of maintenance. Instead of building re-usable software, we should try to build disposable software. I don’t need to tell you that deleting code is more fun than writing it. To write code that’s easy to delete: repeat yourself to avoid creating dependencies, but don’t repeat yourself to manage them. Layer your code too: build simple-to-use APIs out of simpler-to-implement but clumsy-to-use parts. Split your code: isolate the hard-to-write and the likely-to-change parts from the rest of the code, and each other. Don’t hard code every choice, and maybe allow changing a few at runtime. Don’t try to do all of these things at the same time, and maybe don’t write so much code in the first place. Step 0: Don’t write code The number of lines of code doesn’t tell us much on its own, but the magnitude does 50, 500 5,000, 10,000, 25,000, etc. A million line monolith is going to be more annoying than a ten thousand line one and significantly more time, money, and effort to replace. Although the more code you have the harder it is to get rid of, saving one line of code saves absolutely nothing on its own. Even so, the easiest code to delete is the code you avoided writing in the first place. Step 1: Copy-paste code Building reusable code is something that’s easier to do in hindsight with a couple of examples of use in the code base, than foresight of ones you might want later. On the plus side, you’re probably re-using a lot of code already by just using the file-system, why worry that much? A little redundancy is healthy. It’s good to copy-paste code a couple of times, rather than making a library function, just to get a handle on how it will be used. Once you make something a shared API, you make it harder to change. The code that calls your function will rely on both the intentional and the unintentional behaviours of the implementation behind it. The programmers using your function will not rely on what you document, but what they observe. It’s simpler to delete the code inside a function than it is to delete a function. Step 2: Don’t copy paste code When you’ve copy and pasted something enough times, maybe it’s time to pull it up to a function. This is the “save me from my standard library” stuff: the “open a config file and give me a hash table”, “delete this directory”. This includes functions without any state, or functions with a little bit of global knowledge like environment variables. The stuff that ends up in a file called “util”. Aside: Make a util directory and keep different utilities in different files. A single util file will always grow until it is too big and yet too hard to split apart. Using a single util file is unhygienic. The less specific the code is to your application or project, the easier they are to re-use and the less likely to change or be deleted. Library code like logging, or third party APIs, file handles, or processes. Other good examples of code you’re not going to delete are lists, hash tables, and other collections. Not because they often have very simple interfaces, but because they don’t grow in scope over time. Instead of making code easy-to-delete, we are trying to keep the hard-to-delete parts as far away as possible from the easy-to-delete parts. Step 3: Write more boilerplate Despite writing libraries to avoid copy pasting, we often end up writing a lot more code through copy paste to use them, but we give it a different name: boilerplate. Boiler plate is a lot like copy-pasting, but you change some of the code in a different place each time, rather than the same bit over and over. Like with copy paste, we are duplicating parts of code to avoid introducing dependencies, gain flexibility, and pay for it in verbosity. Libraries that require boilerplate are often stuff like network protocols, wire formats, or parsing kits, stuff where it’s hard to interweave policy (what a program should do), and protocol (what a program can do) together without limiting the options. This code is hard to delete: it’s often a requirement for talking to another computer or handling different files, and the last thing we want to do is litter it with business logic. This is not an exercise in code reuse: we’re trying keep the parts that change frequently, away from the parts that are relatively static. Minimising the dependencies or responsibilities of library code, even if we have to write boilerplate to use it. You are writing more lines of code, but you are writing those lines of code in the easy-to-delete parts. Step 4: Don’t write boilerplate Boilerplate works best when libraries are expected to cater to all tastes, but sometimes there is just too much duplication. It’s time to wrap your flexible library with one that has opinions on policy, workflow, and state. Building simple-to-use APIs is about turning your boilerplate into a library. This isn’t as uncommon as you might think: One of the most popular and beloved python http clients, requests, is a successful example of providing a simpler interface, powered by a more verbose-to-use library urllib3 underneath. requests caters to common workflows when using http, and hides many practical details from the user. Meanwhile, urllib3 does the pipelining, connection management, and does not hide anything from the user. It is not so much that we are hiding detail when we wrap one library in another, but we are separating concerns: requests is about popular http adventures, urllib3 is about giving you the tools to choose your own adventure. I’m not advocating you go out and create a /protocol/ and a /policy/ directory, but you do want to try and keep your util directory free of business logic, and build simpler-to-use libraries on top of simpler-to-implement ones. You don’t have to finish writing one library to start writing another atop. It’s often good to wrap third party libraries too, even if they aren’t protocol-esque. You can build a library that suits your code, rather than lock in your choice across the project. Building a pleasant to use API and building an extensible API are often at odds with each other. This split of concerns allows us to make some users happy without making things impossible for other users. Layering is easiest when you start with a good API, but writing a good API on top of a bad one is unpleasantly hard. Good APIs are designed with empathy for the programmers who will use it, and layering is realising we can’t please everyone at once. Layering is less about writing code we can delete later, but making the hard to delete code pleasant to use (without contaminating it with business logic). Step 5: Write a big lump of code You’ve copy-pasted, you’ve refactored, you’ve layered, you’ve composed, but the code still has to do something at the end of the day. Sometimes it’s best just to give up and write a substantial amount of trashy code to hold the rest together. Business logic is code characterised by a never ending series of edge cases and quick and dirty hacks. This is fine. I am ok with this. Other styles like ‘game code’, or ‘founder code’ are the same thing: cutting corners to save a considerable amount of time. The reason? Sometimes it’s easier to delete one big mistake than try to delete 18 smaller interleaved mistakes. A lot of programming is exploratory, and it’s quicker to get it wrong a few times and iterate than think to get it right first time. This is especially true of more fun or creative endeavours. If you’re writing your first game: don’t write an engine. Similarly, don’t write a web framework before writing an application. Go and write a mess the first time. Unless you’re psychic you won’t know how to split it up. Monorepos are a similar tradeoff: You won’t know how to split up your code in advance, and frankly one large mistake is easier to deploy than 20 tightly coupled ones. When you know what code is going to be abandoned soon, deleted, or easily replaced, you can cut a lot more corners. Especially if you make one-off client sites, event web pages. Anything where you have a template and stamp out copies, or where you fill in the gaps left by a framework. I’m not suggesting you write the same ball of mud ten times over, perfecting your mistakes. To quote Perlis: “Everything should be built top-down, except the first time”. You should be trying to make new mistakes each time, take new risks, and slowly build up through iteration. Becoming a professional software developer is accumulating a back-catalogue of regrets and mistakes. You learn nothing from success. It is not that you know what good code looks like, but the scars of bad code are fresh in your mind. Projects either fail or become legacy code eventually anyway. Failure happens more than success. It’s quicker to write ten big balls of mud and see where it gets you than try to polish a single turd. It’s easier to delete all of the code than to delete it piecewise. Step 6: Break your code into pieces Big balls of mud are the easiest to build but the most expensive to maintain. What feels like a simple change ends up touching almost every part of the code base in an ad-hoc fashion. What was easy to delete as a whole is now impossible to delete piecewise. In the same we have layered our code to separate responsibilities, from platform specific to domain specific, we need to find a means to tease apart the logic atop. [Start] with a list of difficult design decisions or design decisions which are likely to change. Each module is then designed to hide such a decision from the others. D. Parnas Instead of breaking code into parts with common functionality, we break code apart by what it does not share with the rest. We isolate the most frustrating parts to write, maintain, or delete away from each other. We are not building modules around being able to re-use them, but being able to change them. Unfortunately, some problems are more intertwined and hard to separate than others. Although the single responsibility principle suggests that ‘each module should only handle one hard problem’, it is more important that ‘each hard problem is only handled by one module’ When a module does two things, it is usually because changing one part requires changing the other. It is often easier to have one awful component with a simple interface, than two components requiring a careful co-ordination between them. I shall not today attempt further to define the kinds of material I understand to be embraced within that shorthand description [”loose coupling”], and perhaps I could never succeed in intelligibly doing so. But I know it when I see it, and the code base involved in this case is not that. SCOTUS Justice Stewart A system where you can delete parts without rewriting others is often called loosely coupled, but it’s a lot easier to explain what one looks like rather than how to build it in the first place. Even hardcoding a variable once can be loose coupling, or using a command line flag over a variable. Loose coupling is about being able to change your mind without changing too much code. For example, Microsoft Windows has internal and external APIs for this very purpose. The external APIs are tied to the lifecycle of desktop programs, and the internal API is tied to the underlying kernel. Hiding these APIs away gives Microsoft flexibility without breaking too much software in the process. HTTP has examples of loose coupling too: Putting a cache in front of your HTTP server. Moving your images to a CDN and just changing the links to them. Neither breaks the browser. HTTP’s error codes are another example of loose coupling: common problems across web servers have unique codes. When you get a 400 error, doing it again will get the same result. A 500 may change. As a result, HTTP clients can handle many errors on the programmers behalf. How your software handles failure must be taken into account when decomposing it into smaller pieces. Doing so is easier said than done. I have decided, reluctantly to use LaTeX. Making reliable distributed systems in the presence of software errors. Armstrong, 2003 Erlang/OTP is relatively unique in how it chooses to handle failure: supervision trees. Roughly, each process in an Erlang system is started by and watched by a supervisor. When a process encounters a problem, it exits. When a process exits, it is restarted by the supervisor. (These supervisors are started by a bootstrap process, and when a supervisor encounters a fault, it is restarted by the bootstrap process) The key idea is that it is quicker to fail-fast and restart than it is to handle errors. Error handling like this may seem counter-intuitive, gaining reliability by giving up when errors happen, but turning things off-and-on again has a knack for suppressing transient faults. Error handling, and recovery are best done at the outer layers of your code base. This is known as the end-to-end principle. The end-to-end principle argues that it is easier to handle failure at the far ends of a connection than anywhere in the middle. If you have any handling inside, you still have to do the final top level check. If every layer atop must handle errors, so why bother handling them on the inside? Error handling is one of the many ways in which a system can be tightly bound together. There are many other examples of tight coupling, but it is a little unfair to single one out as being badly designed. Except for IMAP. In IMAP almost every each operation is a snowflake, with unique options and handling. Error handling is painful: errors can come halfway through the result of another operation. Instead of UUIDs, IMAP generates unique tokens to identify each message. These can change halfway through the result of an operation too. Many operations are not atomic. It took more than 25 years to get a way to move email from one folder to another that reliably works. There is a special UTF-7 encoding, and a unique base64 encoding too. I am not making any of this up. By comparison, both file systems and databases make much better examples of remote storage. With a file system, you have a fixed set of operations, but a multitude of objects you can operate on. Although SQL may seem like a much broader interface than a filesystem, it follows the same pattern. A number of operations on sets, and a multitude of rows to operate on. Although you can’t always swap out one database for another, it is easier to find something that works with SQL over any homebrew query language. Other examples of loose coupling are other systems with middleware, or filters and pipelines. For example, Twitter’s Finagle uses a common API for services, and this allows generic timeout handling, retry mechanisms, and authentication checks to be added effortlessly to client and server code. (I’m sure if I didn’t mention the UNIX pipeline here someone would complain at me) First we layered our code, but now some of those layers share an interface: a common set of behaviours and operations with a variety of implementations. Good examples of loose coupling are often examples of uniform interfaces. A healthy code base doesn’t have to be perfectly modular. The modular bit makes it way more fun to write code, in the same way that Lego bricks are fun because they all fit together. A healthy code base has some verbosity, some redundancy, and just enough distance between the moving parts so you won’t trap your hands inside. Code that is loosely coupled isn’t necessarily easy-to-delete, but it is much easier to replace, and much easier to change too. Step 7: Keep writing code Being able to write new code without dealing with old code makes it far easier to experiment with new ideas. It isn’t so much that you should write microservices and not monoliths, but your system should be capable of supporting one or two experiments atop while you work out what you’re doing. Feature flags are one way to change your mind later. Although feature flags are seen as ways to experiment with features, they allow you to deploy changes without re-deploying your software. Google Chrome is a spectacular example of the benefits they bring. They found that the hardest part of keeping a regular release cycle, was the time it took to merge long lived feature branches in. By being able to turn the new code on-and-off without recompiling, larger changes could be broken down into smaller merges without impacting existing code. With new features appearing earlier in the same code base, it made it more obvious when long running feature developement would impact other parts of the code. A feature flag isn’t just a command line switch, it’s a way of decoupling feature releases from merging branches, and decoupling feature releases from deploying code. Being able to change your mind at runtime becomes increasingly important when it can take hours, days, or weeks to roll out new software. Ask any SRE: Any system that can wake you up at night is one worth being able to control at runtime. It isn’t so much that you’re iterating, but you have a feedback loop. It is not so much you are building modules to re-use, but isolating components for change. Handling change is not just developing new features but getting rid of old ones too. Writing extensible code is hoping that in three months time, you got everything right. Writing code you can delete is working on the opposite assumption. The strategies i’ve talked about — layering, isolation, common interfaces, composition — are not about writing good software, but how to build software that can change over time. The management question, therefore, is not whether to build a pilot system and throw it away. You will do that. […] Hence plan to throw one away; you will, anyhow. Fred Brooks You don’t need to throw it all away but you will need to delete some of it. Good code isn’t about getting it right the first time. Good code is just legacy code that doesn’t get in the way. Good code is easy to delete. Acknowledgments Thank you to all of my proof readers for your time, patience, and effort. Further Reading Layering/Decomposition On the Criteria To Be Used in Decomposing Systems into Modules, D.L. Parnas. How To Design A Good API and Why it Matters, J. Bloch. The Little Manual of API Design, J. Blanchette. Python for Humans, K. Reitz. Common Interfaces The Design of the MH Mail System, a Rand technical report. The Styx Architecture for Distributed Systems Your Server as a Function, M. Eriksen. Feedback loops/Operations lifecycle Chrome Release Cycle, A. Laforge. Why Do Computers Stop and What Can Be Done About It?, J. Gray. How Complex Systems Fail, R. I. Cook. The technical is social before it is technical. All Late Projects Are the Same, Software Engineering: An Idea Whose Time Has Come and Gone?, T. DeMarco. Epigrams in Programming, A. Perlis. How Do Committees Invent?, M.E. Conway. The Tyranny of Structurelessness, J. Freeman Other posts I’ve written about software. (Added 2019-07-22) Repeat yourself, do more than one thing, and rewrite everything. How do you cut a monolith in half? Write code that’s easy to delete, and easy to debug too. Contributed Translations Пишите код, который легко удалять, а не дополнять. 要写易删除，而不是易扩展的代码. 확장하기 쉬운 코드가 아니라 삭제하기 쉬운 코드를 작성하자.",
    "commentLink": "https://news.ycombinator.com/item?id=41968409",
    "commentBody": "Write code that is easy to delete, not easy to extend (2016) (programmingisterrible.com)236 points by stanulilic 11 hours agohidepastfavorite86 comments mmis1000 2 minutes agoPersonally, I split code into two parts. The business logic and actually implementation. The business logic may be duplicated due to its nature, but it should not have too many duplicated technical details in it. While the business logic can be as shitty as you want as long as you do not handle business logic directly in it and keep it application independent. In that way. If you know things messed up and don't go too well. You have the option to wipe the implementation as a whole instead of forced to fix it and try to find out the actual spec from implementation. reply Powdering7082 2 hours agoprevPretty wild that none of this talks about testing or observability. Tests are also something that you need to pay to maintain, but they give the ability of reducing the risk that you broke something when you removed it. Additionally when you've exposed your service to potential external callers you need to both have a robust way of marking some calls as deprecated, to be deleted as well as observing whether they are still being called and by what. I recently did our first semi-automated removal of exposed graphql resolvers, metrics about how often a given resolver was already available so parsing that yielded the set of resolvers I *couldn't* delete. Graphql already has a deprecated annotation, but our service didn't handle that annotation in any special way. I added observability to flag if any deprecated functions have been called & then let that run for sufficiently long in prod, then you can safely delete externally exposed code. reply devjab 1 hour agoparentThis is going to be a bit of an oversimplification but when you build things that are easy to delete, then you’re not going to cause unintentional bugs when you delete them. It’s once you over complicate things that everything becomes an interconnected mess where developers don’t know what sort of impact changes will have. There are a lot of ways to fuck this up of course. Maybe you’re following some silly “best practice” principle, maybe you’re doing “micro-services” in a manner where you don’t actually know who/what consumes which service. But then you’ve not build things that are easy to delete. I think external consumption as you frame it is a good example of this. It’s fair to give consumers a reasonable warning about the depreciation of a service, but if you can’t actually shut it off when you want to, then you’ve not designed your system to let things be easily deleted. Which is fair. If that works for you, then so things that way. I suspect it may not work too well if you’re relying on tests and observations to tell you if things are breaking. Not that I have anything against tests, but it’s not exactly a great safe-guard if you have to let them tell you if you broke something in a long complicated chain. Not least because you’re extremely unlikely to have test-coverage which will actually protect you. reply sjducb 40 minutes agoparentprevTests are great, but there’s more to programming than writing tests. People don’t have to mention tests in every article. reply jumploops 10 hours agoprevMy favorite saying: “simple is robust” Similar in spirit to Lehman’s Law of Continuing Change[0], the idea is that the less complexity a system has, the easier it is to change. Rather than plan for the future with extensible code, plan for the future with straightforward code. E.g. only abstract when the situation requires it, encourage simple duplication, use monoliths up front, scale vertically before horizontally, etc. I’ve built many 0-1 systems, and this is the common thread among all of them. [0] https://en.m.wikipedia.org/wiki/Lehman%27s_laws_of_software_... reply zokier 10 hours agoparentSure, but when applying \"simple is robust\" principle it is extremely important to understand also intrinsic complexity. Not handling edge-cases etc does not make for robust code, no matter how much simpler it is. reply bunderbunder 4 hours agorootparentThis is where the advice in the article is excellent. If you start with code that's easy to delete, it's often possible to alter your data representation or otherwise transform the problem in a way that simply eliminates the edge cases. With the result being a design that is simpler by virtue of being more robust. If you start with code that's hard to delete, usually by the time you discover your edge and corner cases it's already too late and you're stuck solving the problem by adding epicycles. reply Skeime 3 hours agorootparentprevYes, but I definitely also see the opposite quite a bit: Somebody several layers down thought that something was an edge case, resolved it in a strange way, and now you have a chain of stuff above it dealing with the edge case because the bottom layer took a wrong turn. The most common examples are empty collections: either disallowing them even though it would be possible to handle them, or making a strange choice like using vacuous falsity, i.e. all [] == False (Just for illustration what I mean by \"vacuous falsity\", Python's all correctly returns True). Now, every layer above has to special-case these as well, even if they would be a completely normal case otherwise. reply friendzis 3 hours agorootparentYour example perfectly illustrates oversimplification: attempt to stuff categorical variable into another of lower order. If a language has absence of value available as an expressible concept (nullability), then a list is at least 3-way categorical variable: absence of value, empty list, non-empty list. Any attempts to stuff that into a binary truthy value will eventually leak one way or another. reply immibis 8 hours agorootparentprevFailing to account for this gives you Wayland (which at this time is more complex than X11) reply dartos 6 hours agorootparentIs it actually more complex? I find it more understandable, it’s just that DEs need to write their own compositors. reply z3t4 10 hours agorootparentprevThere will always be edge cases, and yes they will make the code more complicated, but what really helps is automatic testing to make sure those edge cases don't break when making changes. reply Vampiero 7 hours agorootparentSetting up automatic testing alone tends to add its own layer of complexity. At least it's worth it. reply arkh 10 hours agoparentprev> encourage simple duplication A rule I like to follow: - first time: write it - second time: copy it - third time: maybe refactor it reply pmg101 1 hour agorootparentAll such rules seem designed for a person not engaging their brain. Is this \"the same\" thing? If so - extract and reference. Or is it \"a different\" thing which is superficially similar? Then don't. Knowing when two things are one thing or one thing is two things is most of our job, right? reply devjab 53 minutes agorootparentDRY is a terrible, terrible, principle because it’s correct but requires programmers to make this decision. Which they won’t because DRY has thought them that all duplication is bad. The flip-side is what you’re saying, where there are simply things it wouldn’t make sense to duplicate. I’m a strong advocate against basically every Clean Code principle, really anything, which isn’t YAGNI. That doesn’t mean I think you should create datetime services every time you need them. It doesn’t mean I don’t think you should make a “base” audit mixin/abstract when you want to add “created_at”… to your data model in your API. I think a better way to look at it than “third time - consider refactor” is to follow this article and ask “will this ever need to be extended?”. If the answer is yes, then you should duplicate it. This way you won’t get a flying dog in your OOP hellscape but you also won’t have to change your holiday service 9 million places when your shitty government decides to remove one of them (thanks Denmark). Between the two, I would personally prefer working on the one where I have to do the 9 million changes, but I would obviously prefer neither. reply jolt42 2 hours agorootparentprevEverything in balance. While I agree with this philosophy, I've also seen lots of duplicate bugs because it wasn't realized there was two copies of the same bug. reply jumploops 9 hours agorootparentprevAgreed! I'll usually go one step further for early projects and lean towards 3rd time copy, 4th time refactor. Example: So much early code is boilerplate CRUD, that it's tempting to abstract it. 9 times out of 10, you'll create a quasi-ORM that starts inheriting business logic and quickly grows omni-functions. Eventually you may actually need this layer, assuming you're system miraculously scales to needing multiple services, datastores, and regions. However this doesn't just apply to the obvious, and you may find omni-logic that made a feature more simple once and is currently blocking N new features. Code is cheap, especially today. Complexity necessarily constrains, for better or worse. reply sjducb 28 minutes agorootparentIt’s so easy to accidentally write an ORM or a database. I constantly stop and think; is this piece of code secretly a database? reply tetha 9 hours agorootparentprevHence why I am rather looking if two pieces of code change together, opposed to just looking the same. If I need to introduce the same feature in multiple places in roughly the same way, that's a decent indication code wants to be the same and wants to change together. That's something to consider extracting. Fixing the same bug in several places is a similar, but weaker indication. It's weaker, because a bug might also occur from using a framework or a library wrong and you do that in several places. Fixing the same business logic error in several places could mean to centralize some things. reply andocars 1 hour agorootparentprevchange it, fix it, upgrade it. reply throw156754228 48 minutes agoparentprevYou can't wish the complexity of business logic away. If it is vast and interconnected, then so is the code. reply cedws 6 hours agoparentprevCan’t upvote enough. Too much dogshit in software is caused by solving imaginary problems. Just write the damn code to do the thing. Stop making up imaginary scaling problems. Stop coming up with clever abstractions to show how smart you are. Write the code as a monolith. Put it on a VM. You are ready to go to production. Then when you have problems, you can start to solve them, hopefully once you are cash positive. Why is your “AirBnb for dogs” startup with zero users worrying about C100K? Did AWS convince you to pay for serverless shit because they have your interests in mind, or to extract money from you? reply antonhag 10 hours agoparentprev+1, but I'm not sure if the \"simple is robust\" saying is straightforward enough? It opens up to discussion about what \"simple\" means and how it applies to the system (which apparently is a complex enough question to warrant the attention of the brilliant Rich Hickey). Maybe \"dumb is robust\" or \"straightforward is robust\" capture the sentiment better? reply directevolve 2 hours agorootparentCopy/paste is robust? As a biomedical engineer who primarily writes software, it’s fun to consider analogies with evolution. Copy/pasting and tweaking boilerplate is like protein-coding DNA that was copied and mutated in our evolutionary history. Dealing with messy edge cases at a higher level is like alternative splicing of mRNA. reply seb1204 7 hours agorootparentprevIndeed, simple is not a good word to qualify something technical. I have a colleague and if he comes up with something new and simple it usually takes me down a rabbit hole of mind bending and head shaking. A matter of personal perspective? reply Vampiero 7 hours agorootparentIs my code simple if all it does is call one function (that's 50k lines long) hidden away in a dependency? You can keep twisting this question until you realize that without the behemoths of complexity that are modern operating systems (let alone CPUs), we wouldn't be able to afford the privilege to write \"simple\" code. And that no code is ever \"simple\", and if it is it just means that you're sitting on an adequate abstraction layer. So we're back at square one. Abstraction is how you simplify things. Programming languages themselves are abstractions. Everything in this discipline is an abstraction over binary logic. If you end up with a mess of spaghetti, you simply chose the wrong abstractions, which led to counter-productive usage patterns. My goal as someone who writes library code is to produce a framework that's simple to use for the end user (another developer). That means I'm hiding TONS of complexity within the walls of the infrastructure. But the result is simple-looking code. Think about DI in C#, it's all done via reflection. Is that simple? It depends on who you ask, is it the user or the library maintainer who needs to parametrize an untyped generic with 5 different type arguments? Obviously, when all one does is write business logic, these considerations fall short. There's no point in writing elegant, modular, simple code if there's no one downstream to use it. Might as well just focus on ease of readability and maintainability at that point, while you wait for the project to become legacy and die. But that's just one particular case where you're essentially an end user from the perspective of everyone who wrote the code you're depending on. reply jumploops 9 hours agorootparentprevThe usual metric is complexity, but that can be hard to measure in every instance. Used within a team setting, what is simple is entirely subjective to that set of experiences. Example: Redis is dead simple, but it's also an additional service. Depending on the team, the problem, and the scale, it might be best to use your existing RDBMS. A different set of circumstances may make Redis the best choice. Note: I love \"dumb is robust,\" as it ties simplicity and straightforwardness together, but I'm concerned it may carry an unnecessarily negative connotation to both the problems and the team. Simple isn't necessarily dumb. reply soco 8 hours agorootparentDull? reply dang 10 hours agoprevRelated: Write code that is easy to delete, not easy to extend (2016) - https://news.ycombinator.com/item?id=24989351 - Nov 2020 (30 comments) Write code that is easy to delete, not easy to extend (2016) - https://news.ycombinator.com/item?id=23914486 - July 2020 (109 comments) Write code that is easy to delete, not easy to extend - https://news.ycombinator.com/item?id=18761739 - Dec 2018 (2 comments) Write code that is easy to delete, not easy to extend - https://news.ycombinator.com/item?id=11093733 - Feb 2016 (133 comments) reply Terr_ 11 hours agoprevYep, to recycle a brief analysis of my own youthful mistakes: ____ I've come to believe the opposite, promoting it as \"Design for Deletion.\" I used to think I could make a wonderful work of art which everyone will appreciate for the ages, crafted so that every contingency is planned for, every need met... But nobody predicts future needs that well. Someday whatever I make is going to be That Stupid Thing to somebody, and they're going to be justified demolishing the whole mess, no matter how proud I may feel about it now. So instead, put effort into making it easy to remove. This often ends up reducing coupling, but--crucially--it's not the same as some enthusiastic young developer trying to decouple all the things through a meta-configurable framework. Sometimes a tight coupling is better when it's easier to reason about. [...] https://news.ycombinator.com/item?id=41219130 reply KronisLV 10 hours agoparent> So instead, put effort into making it easy to remove. You might, but there's also going to be other people that will happily go ahead and create abstractions and logic that will form the very core of a project and entrench themselves to such a degree that they're impossible to get rid of. For example, you might stumble upon CommonExcelFileParser, CommonExcelFileParserUtilities, HasExcelParseStatus, ProductImportExcelParser, ProductImportExcelParserView, ProductImportExcelParserResultHandler and who knows what else, the kind of stuff that ends up being foundational for the code around it, much like how if you start a front end project in React or Angular, migrating to anything else would be a Sisyphean task. In practice, that means that people end up building a whole platform and you basically have to stick with it, even though some of the choices made might cause bunches of problems in the future and, due to all of the coupling, refactoring is way harder than it would be in an under-abstracted codebase. I'm not sure what to do then. People seem to like doing that more than applying KISS and YAGNI and making code easy to delete. reply ffsm8 10 hours agorootparentNot my originals, and I cannot recall who said this... But it's completely on point * Software has a tendency to become maximally complex. You either have an actually complex domain, or the developers will find a way to increase the complexity (..because otherwise, they're bored) * Good software is modular and easy to remove. Consequently, good software will keep getting replaced until it's bad and cannot be removed anymore reply the_gipsy 9 hours agorootparentHard to remove doesn't mean impossible to remove. Refactoring or fixing bad codebases is a thing. reply ffsm8 8 hours agorootparentYeah, it was probably \"won't be removed anymore\" or similar. As I said, I don't remember who said it and was kinda paraphrasing reply noisy_boy 7 hours agorootparentprevDealing with precisely this right now. Written by a consultant who I, maybe uncharitably, suspect is trying to ensure his job security. At this point, it is harder to even understand what's going on behind layers of handlers, factories and handler factories, forget about removing things. It works though and so no one wants to stick their neck out and call it out for the fear of being labelled \"not smart\". reply ozim 11 hours agoparentprevIt still depends. Business line application yes and 10x yes. It will change it will move, don’t try to foresee business requirements. Just write something that will be easy to replace or throw away. Frameworks and libraries not really, for those you still have to adjust to whatever happens in the world but at much saner pace. Biggest issue is when devs want to write “framework” when they work on business line application where they have frameworks that they are already using like Rails/Asp.Net etc. reply rob74 10 hours agorootparentI would say the biggest issue are the frameworks themselves: they practically force you to fit your code to their architecture, and before you know it, your logic is split across innumerable classes. Laravel (with which I have the most experience) has models, controllers, views, service providers, data transfer objects etc. etc. - that makes it (arguably) easier to write and extend code, but very hard to refactor/delete. reply planb 11 hours agorootparentprev> Business line application yes and 10x yes. It will change it will move, don’t try to foresee business requirements. Just write something that will be easy to replace or throw away. This is correct, but from my experience of working in the same company for over a decade: You'll learn to foresee requirements. Especially the \"we'll never need that\" ones that become business critical after a few months/years... reply Terr_ 9 hours agorootparentLike the path that starts with a \"simple\" system of \"soft deletes\" for Foo records, which progresses through a period of developer-assisted \"restores\" or merges, and then they want even older info, and to make reports... However it would have all been so much easier if they'd realized their business domain called for \"Foo Revisions\" in the first place. reply Affric 11 hours agoparentprevSometimes things change, sometimes we chose the wrong abstraction. Unless you’re writing the Linux kernel you shouldn’t write it like the Linux kernel. reply CharlieDigital 2 hours agoprevReading this: > To write code that’s easy to delete: repeat yourself to avoid creating dependencies, but don’t repeat yourself to manage them. Layer your code too: build simple-to-use APIs out of simpler-to-implement but clumsy-to-use parts. Split your code: isolate the hard-to-write and the likely-to-change parts from the rest of the code, and each other. Don’t hard code every choice, and maybe allow changing a few at runtime. My experience is that the title doesn't hold. Code that is easy to delete is -- more often than not -- also easy to extend because it is layered, modular, and isolates different pieces through abstractions like interfaces or other type contracts. reply mattxxx 3 hours agoprevThere's a great corollary here that bad code sticks around, because it's much harder to remove reply evanb 8 hours agoprevI've been telling my computational physics students that the best computation is the one they don't need to bother with. reply seb1204 7 hours agoprevIs this also advocating to use software as vanilla as possible and not go too deep in customisation? reply mherrmann 7 hours agoprevGlaring mistake in the first paragraph: > The problem with code re-use is that it gets in the way of changing your mind later on. This is simply incorrect, especially in the generality in which it is stated. If you change your mind and the code was copy-pasted to ten places, then you have to change ten places. On the other hand, if the code is in a function, then you only need to change it once. And if you do find that one of the ten invocations should not be changed, then you can still copy-paste - or make the function more general. Like crossing a street without looking, copy-pasting is almost always a bad idea. reply braden-lk 7 hours agoparentIn my experience, bad copy pasted code results in an annoying afternoon of tech debt repayment and fixes. Badly abstracted code results in months of tech debt repayment. Of course, the answer is “don’t make bad abstractions”, but we all know how that one goes with a team and changing product reqs. reply treflop 3 hours agorootparentIf only that were the case on a project at work. The badly copy pasted code has diverged over the years so you have 10 different versions of the same looking code that individually have differing edge cases, half of them by mistake because they forgot about the other 9. I would trade that for one piece of mediocre abstracted code any day. Oh yeah and everything in the codebase is copy and pasted. reply nightowl_games 3 hours agoparentprevMany times the code is reused in places where it is the correct code, so then you when you change it you have to slow down and split those places up. We have a git submodule of common UI widgets, changing one of those is impossible now, easier to copy the component into the project and change it locally. It's a problem! The \"shared code\" needs to be as minimal as possible because the sharing makes it harder to change. reply Hasu 6 hours agoparentprev> On the other hand, if the code is in a function, then you only need to change it once. And if you do find that one of the ten invocations should not be changed, then you can still copy-paste - or make the function more general. Ah yes, but what happens if you have to change 3 of the function invocations in one way, 5 in another, and the other two need to be completely rewritten because those aren't even using the same abstraction any more? If it's all in one function, most developers will try to change that function to make all 10 cases work, when it should never have been one function in the first place. It is much much easier to fix ten copy-paste places than to untangle a knot that should never have been tied, once it's holding pieces of your system together. reply lttlrck 4 hours agorootparentThere is no one size fits all. In a many cases I'd still rather have three or more versions of a function, many which may just be very thin shims to accommodate that scenario than 10 copy/pastes of variations. Or shim at the call site and keep one function if that suits. reply SoftTalker 3 hours agorootparentIf a function does different things in different circumstances it should usually be split into different functions. Languages like Erlang which can have different versions of a function, selected by pattern matching (with optional guards) make this convenient: Name(Pattern11,...,Pattern1N) [when GuardSeq1] -> Body1; ...; Name(PatternK1,...,PatternKN) [when GuardSeqK] -> BodyK. reply sfn42 3 hours agorootparentprevThis is such a strange argument. You want to copy and paste code 10 times rather than making a function, because if the requirements change and if the person assigned to fix it is a moron, then it might prevent the moron from choosing one specific way of making a mess? You can't prevent future morons from doing moronic stuff in the future. They'll just find another moronic thing to do. reply VeejayRampay 5 hours agoprevit's crazy how we keep going through all those injunctions (religions) about software, they all look amazing on paper, feel like common sense and yet 50 years in, software is garbage 90% of the time yet, we keep bringing this stuff up like it's some sort of genius insight / silver bullet reply kraftman 2 hours agoparentI think it's because 90% of the garbage is being written by people that don't read or write articles like this one. reply VeejayRampay 2 hours agorootparentI don't think it's the case, because all those schools of thought (your DRY, your SOLID, your DDD, etc) all have opposite schools of thought rife with other similarly popular mantras the problems in engineering rarely stem from the lack of principles and have way more to do with mismanaged projects, arbitrary deadlines, shifting priorities, unreliable sources of data, misunderstood business logic and all those fancy acronyms, all the SCRUM and agile in the world will never make up for all that reply kraftman 2 hours agorootparentThat's really not been my experience when reviewing code. Bad code I've seen has been due to misusing language features, not knowing the principles in these articles, or misunderstanding the principles or blanket applying them to everything. For example, abstracting every piece of similar code to make it \"DRY\" because they don't understand that it's about concepts not code. reply throw156754228 4 hours agoprevAnd have a dozen versions of the same logic leading to subtle bugs in production. reply ollysb 11 hours agoprevOnce you can load up a full codebase into an LLM I'm hoping the cost to update client code is significantly reduced. Then you could focus on evolving the design without all the grunt work. reply chikere232 6 hours agoparentDoesn't look promising so far reply qwertox 11 hours agoparentprevI'm also betting on this, that one day I'll be able to dump a codebase into an LLM and it will clean up the code. Not rewrite it, not restructure it, just clean it up. Remove unused code and comment it sensibly. Maybe also suggest some tests for it and implement them separately. reply ropejumper 7 hours agorootparentComments should be based on intention. If I, as the programmer, am writing a piece of code and feel like there's something that I need to communicate about my intention in writing this, then I should. But if it's just surface level analysis, comments are just noise most of the time. I don't see why this would be useful. reply Cthulhu_ 9 hours agorootparentprevCopilot already does this, at least for individual chunks of code (and text, for that matter). Not for a whole codebase, but I think that's going to be a matter of time. reply ainiriand 11 hours agoprevWhy not both? reply chikere232 6 hours agoparentBecause building for extensibility adds real complexity for a hypotetical need If you want the code to do something different later, change, replace or extend it then... when you actually know what it needs to do reply ainiriand 6 hours agorootparentI am not sure that is something that applies 100%, but I understand the concern. It is my understanding that we should try to build solutions to current problems, and be open to future use cases that could involve small additions in functionality. It would be stupid to design an unmodifiable system just because some parts can be deleted and we are not sure what future needs are. Code should always be easy to extend, in my opinion. reply kraftman 2 hours agorootparentConversations like this are always difficult to discuss at a high level because the way we implement the words we use can be very different. Code can be written in a way that a lot of complexity is added in order to make it extensible, or it can be written in a way where simplification is used to make it extensible. Both authors would agree that extensible is good. reply ainiriand 37 minutes agorootparentThat is an excellent and pragmatic point of view. reply pjturpeau 5 hours agorootparentprevIf it is easy to understand, then it is easy to extend. reply revskill 10 hours agoprevWrite test, not code. reply ttyprintk 9 hours agoparentSpecifically, write tests that identify disposable code. More specifically, you hopefully wrote some disposable code that is a modular extension of something close to the core. Write tests that demonstrate which of those deserves to be core, and which is necessary for a requirement but disposable. Since the article brings up shared apis, hopefully when you arrive on a new project, those are well understood as requirements paired with test cases. Repeat in the opposite direction in dependent projects. reply worstspotgain 10 hours agoprevAt the risk of turning a unison into a chord, here's my two cents. If: 1. You know where the 'creases' of orthogonality are. You've carved the turkey 1000 times and you never get it wrong anymore. 2. As a result, there is hardly any difference in complexity between code that is and isn't easy to extend. Then write code that is easy to extend, not delete. The question is whether your impression of the above is true. It won't be for most junior developers, and for many senior ones. If orthogonality isn't something you preoccupy yourself with, it probably won't be. In my experience, the most telling heuristic is rewriting propensity. I'm talking about rewriting while writing, not about refactoring later. Unless something is obvious, you won't get the right design on the first write. You certainly won't get the correct extensible design. If you're instructed to write it just once, then by all means make it easy to delete. reply blitzar 9 hours agoparent> The question is whether your impression of the above is true If you think you are good enough to qualify you almost certainly don't qualify. If you do qualify then chances are you probably don't think you do. reply kraftman 8 hours agoparentprevCould you give an example of your point? Isn't writing orthogonal code the same as writing code that's easy to delete? reply worstspotgain 6 hours agorootparentHere's an algebraic example to keep things theoretical. If the easy to delete version proposed by the article is: f(x) = 6x^2 - 5x + 1 The prospective extensible version is: g(x,a,b) = ax + b f(x,q()) = q(x,3,-1) q(x,2,-1) f(x,g) It's the generalization for factorable polynomials. It's clearly harder to read than the easy to delete version. It's more complex to write, and so on. However, it's algebraically orthogonal. It has advantages in some cases, for instance if you later add code for a 6th-order polynomial and need to use its zeroes for something else. We know that it could be better in some cases. Is it a good bet to predict that it will be better overall? The problem domain can fracture across a thousand orthogonal \"creases\" like this one. The relevant skill is in making the right bets. Here's an example that's not orthogonal. Let's say we think the 6 coefficient might be more likely to change in the future: g(x,a) = ax^2 - 5x - 1 f(x,q()) = q(x,6) f(x,g) This version is most likely just adding complexity. A single function is almost always a better bet. reply DeathArrow 7 hours agoprevAll nice code looks like this: int main(){} reply herpdyderp 7 hours agoprevI worked with someone once that so adamantly followed every quick tip like this that they heard to such an extreme level that now they all make me feel sick. reply Dwedit 11 hours agoprevC# is pretty good about these, with extension methods and event handlers. With event handlers instead of virtual methods, it's much easier to separate the pieces. reply sam_lowry_ 11 hours agoparentAnd yet the worst ever code I saw was in C#. I hope I won't offend anyone pointing at it [1]. This is a somewhat popular tool to evaluate macroeconomic policies in the EU. A combination of language choice (C# as a natural language Microsoft Excel bosses tend to request from their interns to use), the usual churn of academic undergrads and loads of other cultural failures are the reasons this monster exsts. Someone should write a book how to make the worst ever codebase, and start with EUROMOD. [1] https://github.com/ec-jrc/JRC-EUROMOD-software-source-code reply willtemperley 10 hours agorootparentI could write about creating the worst possible environment to be a software developer, having worked at the JRC for five years. I'm not sure how constructive that would be. I'm still hurting because the IT department decided the only way to deploy my Java app was through rsyncing to a running Tomcat installation, allowing class files from several deployments previous to resurface in memory causing some beautiful bugs. Or the time they decided to buy a Hadoop cluster at a cost of EUR 100k which I told IT dept they wouldn't be able to connect to from the outside world because the network rules are carved in stone. They bought it, and guess what, network ops said no. The ten foot high touch screen and the car emissions data stored in Excel files and the 80 million euros spent on a website or the time the partner research group refused to release the data we had funded so we couldn't run workshops or release the project (around EUR 2 million). The waste. reply sam_lowry_ 9 hours agorootparent> rsyncing to a running Tomcat installation You can delete while resync'ing but I guess the issue is not in resyncing itself, but rather in the disempowerment of individual contributors. You could have argued to add --delete for your case, as well as requesting a shutdown before and a start after, but I guess explaining this to countless morons is too much to ask from a humble developer. OTOH, this resyncing story probably means that you were allowed to choose the wrong development framework to start with. Because resyncing PHP is much more reasonable. reply willtemperley 9 hours agorootparentNo the issue was files cached in memory. No amount of deleting from the file system is going to delete files cached by the servlet, which is why the servlet itself needs to be restarted. reply nextcaller 11 hours agoprev [–] Implementing choice is superior. Not only can your program be capable of more actions, but the process of thinking about how to include these features leads to focusing on your codebase which leads to refactoring, better code. With time the code becomes so flexible that adding features is easy, because your foundation is superior. And in the process other core functionality gets fixed and becomes better. reply alserio 10 hours agoparent [–] Can you explain what you mean with \"implementing choice\"? reply nextcaller 10 hours agorootparent [–] This was written in the context of a discussion about showing resistance or not to feature requests by users sorry for the confusion. reply alserio 8 hours agorootparent [–] thank you reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post emphasizes writing code that is easy to delete rather than extend, highlighting the importance of disposable software to reduce maintenance costs.- It suggests strategies such as avoiding dependencies, using simple APIs, isolating change-prone parts, and employing feature flags to facilitate experimentation without redeployment.- The approach includes initially copying and pasting code to understand its usage, then refactoring, and planning to discard some code as part of the development process."
    ],
    "commentSummary": [
      "Emphasize writing code that is easy to delete rather than extend, focusing on separating business logic from implementation.- Avoid unnecessary abstractions and premature optimization to maintain simplicity and robustness in code.- Prioritize readability and maintainability, using tests to manage changes safely and effectively."
    ],
    "points": 236,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1730099060
  },
  {
    "id": 41966785,
    "title": "ATL: A layer to run Android apps on Linux",
    "originLink": "https://gitlab.com/android_translation_layer/android_translation_layer/-/blob/master/README.md",
    "originBody": "master Select Git revision 0 results android_translation_layer README.md Find file Blame History Permalink README: add a BeatSaber screenshot · fc6e101a Mis012 authored 1 month ago fc6e101a Code owners To learn more about this project, read the wiki.",
    "commentLink": "https://news.ycombinator.com/item?id=41966785",
    "commentBody": "ATL: A layer to run Android apps on Linux (gitlab.com/android_translation_layer)206 points by AbuAssar 18 hours agohidepastfavorite29 comments kvemkon 17 hours agoDiscussion started here: NewPipe on Linux, Using Android_translation_layer (27.10.2024) https://news.ycombinator.com/item?id=41963932 reply mikae1 12 hours agoprevCool! But not exactly plug n play at this point: > If you are trying to launch a random app, chances are that we are missing implementations for some stuff that it needs, and we also don't have (sufficiently real looking) stubs for the stuff it says it needs but doesn't really. The workflow is basically to see where it fails (usually a Class or Method was not found) and to create stubs which sufficiently satisfy the app so that it continues trying to launch. Once the app launches, you may find that some functionality (UI elements, ...) is missing. To enable such functionality, you need to convert the relevant stubs to actual implementation. You can look at simple widgets (e.g. TextView, or ImageView) to see how to implement a widget such that it shows up as a Gtk Widget. reply endofreach 14 hours agoprevAny easy way to make apps not recognize they're not running on an actual android phone? I've read some apps that love to take too much control run CPU related checks amongst other things. No android experience or usecase, just wonder how that works and how one would workaround that. reply mid-kid 13 hours agoparentI don't think the point of this is to get everything ever to work. Just getting well-behaved and free software apps to integrate better than with waydroid (by reimplementing a higher level of libraries, rather than running the entire OS) would already be huge. reply sigh_again 6 hours agoparentprevThese are usually simple heuristics based on device name, whether you're running a signed version of Android, etc. Thirty minutes on Stackoverflow will usually cover all the fingerprints most simple apps use. If they're using Play Integrity, you're mostly out of luck. Xposed will usually have the latest bypass, but there's long periods where there aren't any. reply grishka 16 hours agoprevWas going to ask \"how is this different from Anbox\", but apparently Anbox got discontinued by its developer more than a year ago. reply Quasimarion 16 hours agoparentThere is waydriod as a successor thou. reply big-green-man 15 hours agorootparentBut waydroid is just an android system in a window. That's really not as useful as it could be, especially with a mouse and keyboard. reply franga2000 7 hours agorootparentIt's not in a window, although you can launch it that way if you want. Each app is a separate window, mouse/keyboard/touch works just like with any other app, even the clipboard works as you'd expect. reply toasteros 12 hours agorootparentprevIt is EXTREMELY useful (and built in/well integrated) on the FLX1. Could be interesting to see how handy ATL could be on mobile reply yjftsjthsd-h 14 hours agorootparentprevI'm given to understand that it supports window-per-app? And I don't use it like that for reasons related to it requiring wayland, but even so it works fine for me with mouse+keyboard reply big-green-man 1 hour agorootparentReally... I've run it for a few minutes and couldn't get networking lol but it ran in a single window, I guess I need to look into how to use it like that, would be useful sometimes. reply Imustaskforhelp 13 hours agoprevthis could be used in linux phones as well I suppose (waydroid requires linux-zen which just adds friction imo) Though I like waydroid very much , I also really like this idea of having android apps as flatpak applications which I can install rather easily without having to configure to install a custom kernel and do 10 more different things (like maybe adding play store if app is not available) (a arm implementation if app isn't working) lets hope that it works better than that and gives a plug n play experience reply toasteros 12 hours agoparentWaydroid does not require linux-zen. It requires a kernel with the binder kernel modules. They can be managed with dkms on a normal kernel. reply seba_dos1 11 hours agorootparent...or just included in the \"normal kernel\", as binder is mainline. reply bsimpson 16 hours agoprevIs this like Wine/Proton, but for Android instead of Windows/DirectX? reply bri3d 15 hours agoparentYes, the implementation looks philosophically similar and seems to cleave at the same layer (the interface between app code and platform libraries). Basically, an implementation of everything Dalvik calls out to via JNI and a bionicglibc libc shim for native Android libraries. reply joseda-hg 6 hours agorootparentWait, Dalvik? Not ART? reply bri3d 3 hours agorootparentNo, you’re right, ART now (I think they started using Dalvik, actually, but switched, just like Android itself). I guess I forgot what year it was for a minute there :) reply kelnos 16 hours agoparentprevIt seems like it, at least based on the bit in the README about stubbing out and implementing classes & methods that apps need. reply DeathArrow 12 hours agoparentprevIf Android binaries are for ARM and Linux runs on x86, you need another layer of translation from Arm to x86. reply anthk 6 hours agorootparentThat's included in Android. reply iml7 15 hours agoprevhow is this different from waydriod? reply dsp_person 15 hours agoparentwaydroid requires a kernel module or a kernel with support built in like zen https://wiki.archlinux.org/title/Waydroid#Kernel_Modules From a quick look at the gitlab I don't see any mention of similar requirements. If that's the case, it would be easier to run. Also bonus if gpu support is better than \"NVIDIA GPUs do not work currently\" reply big-green-man 15 hours agorootparentBut I thought the experience with waydroid is running an android system in a window? You can run android applications directly in Linux as their own \"native\" window using waydroid? reply dsp_person 14 hours agorootparentnative wayland windows maybe you're thinking? still, it has the requirements that it does (see the wiki link) reply Imustaskforhelp 13 hours agorootparentprevyou still need to be on linux-zen kernel to make this work. I use wayland but I am interested in atl as well reply unplug 13 hours agoprevGreat news for Pinephone users! reply kazinator 12 hours agoprev [–] Wait; isn't Android a layer to run Android apps on Linux? See, this is where it's useful to use terms like GNU/Linux for reasons other than free software advocacy. Android apps run on a Linux kernel, but not on a GNU/Linux distribution. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "ATL is a new compatibility layer designed to run Android applications on Linux, akin to how Wine/Proton operates for Windows applications.",
      "Unlike Waydroid, ATL does not require specific kernel modules, which may simplify its usage on Linux systems.",
      "ATL presents a unique method for running Android apps, potentially benefiting Linux phones by avoiding the need to run a complete Android system in a window."
    ],
    "points": 206,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1730075153
  },
  {
    "id": 41967897,
    "title": "418 I’m a teapot",
    "originLink": "https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/418",
    "originBody": "418 I'm a teapot The HTTP 418 I'm a teapot status response code indicates that the server refuses to brew coffee because it is, permanently, a teapot. A combined coffee/tea pot that is temporarily out of coffee should instead return 503. This error is a reference to Hyper Text Coffee Pot Control Protocol defined in April Fools' jokes in 1998 and 2014. Some websites use this response for requests they do not wish to handle, such as automated queries. Status httpCopy to Clipboard 418 I'm a teapot Specifications Specification RFC 2324 # section-2.3.2 See also HTTP response status codes Wikipedia: Hyper Text Coffee Pot Control Protocol",
    "commentLink": "https://news.ycombinator.com/item?id=41967897",
    "commentBody": "418 I’m a teapot (developer.mozilla.org)198 points by csomar 14 hours agohidepastfavorite122 comments palsecam 3 hours agoI use 418 as a reply to illegitimate bots. It’s fun and it makes filtering logs easier. Nginx config snippet: # Nothing to hack around here, I’m just a teapot: location ~* \\.(?:php|aspx?|jsp|dll|sql|bak)$ { return 418; } error_page 418 /418.html; Example: https://FreeSolitaire.win/wp-login.php (NB: /wp-login.php is WordPress login URL, and it’s commonly blindly requested by bots searching for weak WordPress installs.) reply jbombadil 3 hours agoparentQuick side-note. Thank you for freesolitaire.win. It's such a beautiful implementation of solitaire. Works so well as a PWA, I can enjoy it even without proper internet connection, it's simple, does the basics, but does it perfectly. There's nothing to add to it, but more importantly... nothing to take out. I wish more software was written like this. I've donated already, but I use it so much I'll donate again. reply palsecam 2 hours agorootparentWow, thanks jbombadil! That’s so heart-warming to hearAll those small discussions were essentially pointless Were they pointless, or were they positive feedback about a thing you personally disliked? reply pessimizer 1 hour agorootparentYou're doing the thing he was trying to avoid. You want to have a discussion about this hypothetical emoji and make a bunch of statements about the psychology of the person who doesn't want to waste his life on it. Nothing like being accused of not liking \"fun\" when you don't want to do something useless at work. Maybe not everybody likes goofy emojis, or Harry Potter references, or whatever easy nothing passes as wit for some people, and they think it makes everything less professional and introduces unnecessary maintenance. Those people have to make the choice to shut up about it, or mention it and have somebody tell them they're joyless. edit: irt 418, it's historical and it has already imposed most of its maintenance burden. But using it when you're not a teapot is forcing the meme. reply souldeux 1 hour agorootparentAs a former engineering manager: no, I don't want to have a discussion about the hypothetical emoji. I want the engineer to put a rocketship in their commit message to have a slightly brighter day, and I want to acknowledge that someone else made a positive comment about it. If you are genuinely at the point in your life where \"people saying they like things\" is the same as ... what you're describing ... please be aware of the emotional impact you're having on the people around you. reply aseipp 3 hours agorootparentprevIf they had not been paying attention to what you were showing them, then how would they have noticed the emoji? reply ralusek 5 hours agorootparentprevIt sounds like people really liked the emojis reply NomDePlum 18 minutes agorootparentPeople like novelty and engage on things they feel they can contribute an opinion on. Been on many a demo in the past where all sorts of \"magical\" and complicated stuff is happening that ends up with \"ooh I've never seen a date picker like that\" or \"wouldn't it be a lot better if it was blue and not red\". Often it's because they accept the other stuff is working or don't even fully remember what the demo is about. reply whamlastxmas 4 hours agorootparentprevThis is actually selling me on using emojis reply SoftTalker 3 hours agorootparentprevWork parties. Worst thing ever. reply pmg101 1 hour agorootparentprevSurely both having and not-having emojis could be just as likely to trigger discussions about whether to have or not have emojis? Sometimes I feel like the opposite of your position happens: just add the damn emojis already to put an end to the endless discussions about whether to add emojis reply ToucanLoucan 1 hour agorootparentprev> My main argument was that if you put things like that in your applications then people start having opinions about it You can say this about literally any discussion outside the realm of bugfixes. And yes I do want to discuss the psychology behind this, because this is, IMO, a perfect example of the tendency for a certain kind of dude (usually dude, anyway) to ascribe \"objective,\" \"rational,\" or other such power-words to their own personal opinions and state them as though they are fact. Emoji's are characters, my guy. That's it. And if the saying \"A picture is worth a thousand words\" holds any water... well, I think a thousand is pushing it, but I think an emoji can save you a bunch of words in certain contexts, and doesn't need nearly as much attention for localization. The only pushback I see consistently on this is from old farts like myself who remember fondly the days pre-emoji and have feels about it. And having feels is completely fair, but trying to pass off your feels as facts doesn't fly. reply thih9 11 hours agoprevThe linked source RFC is a pleasant read too: https://www.rfc-editor.org/rfc/rfc2324 reply dsab 5 hours agoparentI love those RFC documents. I am currently working with CCSDS documents and they are total trash comparing to RFC. For example when I read documents about how TCP works or TLS works I see that it has been written by professionals with experience and vision. And CCSDS documents have been written by bureaucrats who have never written a line of code in their lives. reply falleng0d 9 hours agoparentprevNow. I didn't know about the RFC. This is so good. I hope we can continue to advance this field with good humor, and good coffee. reply ctm92 9 hours agorootparentThere are quite some RFC with humor, most prominently probably RFC1149 and its extension RFC2549 reply sameerds 7 hours agorootparentIP Datagrams on Avian Carriers https://www.rfc-editor.org/rfc/rfc1149 IP over Avian Carriers with Quality of Service https://www.rfc-editor.org/rfc/rfc2549 reply penwielder 43 minutes agorootparentprevFor anyone who wants to explore further, Wikipedia has a list page for these RFCs: https://en.wikipedia.org/wiki/April_Fools%27_Day_Request_for... There are a lot more of them than I had realized before finding that. Some years even had multiple. reply magicalhippo 8 hours agorootparentprevIt's even been updated[1] for IPv6, so no reason not to use it! [1]: https://www.rfc-editor.org/rfc/rfc6214 reply hellojebus 3 hours agoprevWe use the 418 response code in our authentication service. We use to determine whether the token is invalid due to expiration, vs any other reason. If 418, we know to refresh to access token automatically... pretty harmless and definitely not a security measure. reply noobermin 10 hours agoprevThis was the nerdy non sequitur joke before \"sir, this is a wendy's\" went platinum on facebook memes in the 2010s. reply whamlastxmas 4 hours agoparentI mean there were a million, including the game, which everyone was freed of by xkcd. reply plaidphantom 3 hours agorootparentDangit, I had finally gotten good at The Game. reply declan_roberts 2 hours agoprevEvery time I have encountered this error code in the wild I have been extremely frustrated. Somebody tries to be cheeky, and rather than just return the proper status code (like a 429 or 503) they return this, which breaks a lot of HTTP status code parsing. Not cheeky or funny. Boring actually. I know I'm boring but I have a job to do. reply cl0ckt0wer 2 hours agoparentIf your parser can't handle in-spec error codes, then that's a parser problem. reply declan_roberts 2 hours agorootparentRegardless of the parser if you're using a 4XX status code when you should be using a 5XX status code then you're simply doing it wrong. reply justin66 1 hour agorootparentHonestly this discussion makes the occasional \"I'm a teapot\" seem useful. Your log and error handling ought to be capable of handling occurrences of a programmer doing something goofy. reply Towaway69 23 minutes agorootparentprevWhy would being a teapot justify being a 5xx status? The server hasn’t failed, it’s a functioning teapot, definitely not broken. I would assume if the teapot were to be broken, then a 518 teacup is empty error would be more appropriate. But as long as there is a piping hot cup of tea, then it’s a 418 code. /s reply adolph 1 hour agoparentprevA possibly apocryphal didactic story relevant because if an HTTP implementation misses 418, what else does it miss?: The story goes that Van Halen had stipulated on their concert rider that they wanted M&M candy backstage, but with all the brown ones removed. In his autobiography ‘Crazy From the Heat’ singer David Lee Roth explained this was not just a childish request, but in fact was a cunning test whereby he could tell instantly if the venue was safe or not. He reasoned that if a concert venue did put brown M&Ms out, then they cannot have read the rider properly and that they then might also have made other more dangerous errors, such as in their electricity supply or stage weight capacity. https://www.metaltalk.net/chris-dale-myth-busting-the-van-ha... reply impure 1 hour agoprevI use 418 in place of 400. It doesn’t matter too much because too much information about the error is a security risk, I just give generic codes for everything. If you want to debug something look at the logs. reply averageRoyalty 7 hours agoprevUsually in one of these threads, someone links the iiNet coffee cam. Here you go: https://coffeecam.iinet.net.au/coffee/history/ reply mmcallister 7 hours agoparentiiNet was probably the best job I've ever had, certainly the place where I learnt the most, and had the most fun. The coffeecam was cute, acb - the one primarily responsible for the coffeecam - also had American candies for sale around it (at least when I worked there at Hay Street) reply failedartifact 11 hours agoprevI had Sonatype Nexus return to me once upon upload of an artifact. I was not impressed. reply mrweasel 10 hours agoparentOther than the humor in it, makes you wonder why they'd pick 418. It does sometimes feel like some errors are missing from the http codes, prompting developers to either create their own, or repurpose some, like 418, where they feel relatively safe that it won't conflict with something. It never ceases to amaze how http status codes can be misused. My favorite is still the customer who had built a service that would return \"200 OK\" and then in the response just be the text \"500\". We had asked if they could return a 500 error, if there was an error in the API, rather than a 200, so they swapped out the 200 in the response, but not the headers. \"200 Created\" is also up there, in terms of developers with limited understanding or weird framework limitations. reply 9dev 9 hours agorootparentThere are definitely missing codes, which is why sometimes the WebDAV status additions get used in purported RESTful APIs—which is semantically wrong, but often carries a lot of helpful meaning. For example, things like 422: Unprocessable Content or 423: Locked are really helpful to convey meaning, but not available in plain HTTP. reply flir 8 hours agorootparent> 422: Unprocessable Content I honestly would have thought 400 Bad Request would cover that? Might be too generic though. Is \"422\" \"ok, I admit it's formatted correctly, but I can't process it for some higher-level reason than syntax\"? (Just reading through 4xx codes, and I think I need to use 410 Gone a lot more often. Does anyone know if search engines treat 404 and 410 differently?) reply mrweasel 7 hours agorootparentThe issue I have with 400 Bad Request is that it's very broad. The request might actually be fine, but the data posted is not. Now you could argue that it doesn't matter why the request is bad, formatting, protocol or data, 400 for everything. It just feels a lot like throwing a generic Exception and attempting to convey the details in the message body. reply lcnPylGDnU4H9OF 2 hours agorootparentprev> Is \"422\" \"ok, I admit it's formatted correctly, but I can't process it for some higher-level reason than syntax\"? That is my understanding. Something to say that the request is understood as an HTTP request (therefore not 400) but the server doesn't know what to do with it, usually in the context of a POST, or it's otherwise invalid for processing. reply epc 3 hours agorootparentprevFrom personal experience search engines don’t honor 404 or 410. I switched much of my personal site to returning 410 over a decade ago and Googlebot still returns on a routine basis re-requesting a document that hasn’t been on the site since 2012. reply flir 3 hours agorootparentWell... a thorough \"meh\" to Google. Thanks for the info though, one less thing for me to care about. reply epc 2 hours agorootparentOut of paranoia I just checked and yeah, GoogleBot actual (and not the dozens of fakes) requested each 410'd URL at least once a month, some URLs get multiple requests per month. All have been marked 410 since 2014 or earlier. reply flir 1 hour agorootparentGoogle has FoMO... reply marcosdumay 40 minutes agorootparentThe webmaster tools used to say Google will punish your rank if the crawler gets too many 404 or 410... reply woleium 10 hours agorootparentprevi think you may mean “never _ceases_ to amaze”, as in it never stops amazingreply mrweasel 10 hours agorootparentFixed, thank you :-) reply andrepd 11 hours agoparentprevOdd coming from such a Serious Enterprise™ Solution® reply theginger 8 hours agoprevI think since it is I am a teapot not you are a teapot It should be a 5xx code because clearly it's a server side issue. reply mass_and_energy 5 hours agoparentDisagree, asking a teapot for a cup of coffee is an invalid user request. The server is working as expected, but is not being asked to work as expected. reply Towaway69 19 minutes agorootparentAgree, it’s a functioning teapot. Definitely 418. If the cup is empty, then a 518 teacup is empty error would be more appropriate but as long as there is piping hot tea - 418 for me. /s reply LordRatte 6 hours agoparentprevHonestly doesn't sound like a problem at all in the greater scheme of things. reply sireat 7 hours agoprevThe RFC covers mostly coffee brewing related activities. I've always wondered if you were to have an actual networked Teapot, when would it be appropriate to send 418. I am sure there are some networked teapots already. If someone wanted to send a \"brew tea\" request (via POST?) to an actual teapot, then 418 would not be suitable, you'd want something else, no? reply bluefirebrand 3 hours agoparentI think making a networked teapot with an undocumented endpoint for \"brew coffee\" that returned 418 would be fun :) reply gnabgib 13 hours agoprevDiscussions in: 2020 (153 points, 118 comments) https://news.ycombinator.com/item?id=24206899 2021 (193 points, 108 comments) https://news.ycombinator.com/item?id=28541327 2023 (206 points, 189 comments) https://news.ycombinator.com/item?id=36090344 reply Arn_Thor 10 hours agoparentI think we were due another reply andreareina 8 hours agorootparentTypically people post older conversations so people can check them out, not as a chastisement for reposting. reply Arn_Thor 2 hours agorootparentFair enough. Hadn't thought of it that way reply jtxx 10 hours agorootparentprev2022 was a sad year reply walthamstow 7 hours agorootparentprevEvery April 18th reply core-utility 3 hours agoprevI named my IoT Wireless SSID to 418. Thought I was clever, even if nobody else understands it. reply cemoktra 3 hours agoparentThe password is \"I'm a teapot\" right? reply core-utility 44 minutes agorootparentI definitely thought about it but that seemed a bit too crackable reply enews01 12 hours agoprevhttps://http.cat/418 reply XeO3 11 hours agoparentGoogle has it too. :) https://www.google.com/teapot reply dark-star 9 hours agorootparentI didn't realize that this is actually interactive! reply axegon_ 10 hours agoparentprevhttps://http.dog/ as well reply maz1b 11 hours agoparentprevThe internet never fails to amuse me, this is awesome haha reply defrost 12 hours agoprevHere I was, foolishly thinking it was code for operator panic: https://www.youtube.com/watch?v=kLQStcdhAGA reply chrisbra80 9 hours agoprevVim implemented this: `:call err_teapot()`. reply sureIy 9 hours agoparentWhy would a text editor have a way to produce HTTP error codes? I don't get it reply worble 8 hours agorootparentWhy would a web server try to brew coffee when it's a teapot? reply flir 8 hours agorootparentPostel's law reply seanhunter 6 hours agorootparentprevVim has http support as part of netrw which exists so you can do things like edit files over scp. I have at times had to fix remote hosts using this type of thing for example vim scp://seanhunter@somehost.example.com:1234/.vimrc ^ ...which believe it or not works just fine if I have ssh access to that host. ..and I think http is supported for stuff like webdav, although I can't think of ever using http directly in vim like that. Given it's built-in it's useful for things like updating plugins etc. Once you've made the leap to thinking having net support like that built in is worthwhile, it makes sense for vim to have the wherewithall to test the responses for different status codes etc so plugins and scripts which use that network functionality can test the different failure cases. reply declan_roberts 1 hour agoprevFriendly reminder never to use a 4XX status code when you mean to return a 5XX even if you think it's cheeky or funny. reply dancemethis 1 hour agoprevObjectively speaking, the best status code. reply anal_reactor 3 hours agoprevThere's this website called tcrf.net discussing hidden gems in old games and I feel like in the past, at least in some companies, engineering was fun. I really cannot picture creating anything like 418 in my current workplace. reply qwer1234321 11 hours agoprevI love engineering sense of humour :) reply portaouflop 11 hours agoprev419 I‘m an awfully hot coffee pot reply sokoloff 8 hours agoparent419 - I’m a Nigerian Prince. reply mrmincent 10 hours agoprevI hate to be that guy, but just a reminder that if you’re implementing a production system - even if it’s an internal tool - please don’t return 418 as a joke unless you really are a teapot. As an SRE I’ve been on the receiving end of a broken system returning teapots over the weekend, and it’s not as funny then. reply cybrox 10 hours agoparentWell, statistically, 9 out of 10 engineers find this very funny come Monday. reply seanthemon 9 hours agoparentprevI did this many years ago on the app I still work on, the product became much more enterprise and eventually customers started to see 418 errors.. it wasn't a good look and I felt great shame. reply sleepyhead 9 hours agoparentprevI don't get it. If the system is so broken it is returning some random http code then I don't see how returning some other random http code is better? reply dtech 9 hours agorootparent5xx indicates an error in the server, 4xx indicates a client error. So it's quite common for clients to handle them differently like retrying 5xx but not 4xx. reply sleepyhead 8 hours agorootparentSure, but if the server is returning 418 by an error it is likely that it would return some other 4xx error instead of 5xx. 418 is irrelevant here, the server is rogue. reply fastball 9 hours agoparentprevWe return 418s for captcha failures. reply mikepurvis 8 hours agorootparentSurely that should be a 401 unauthorized? reply fastball 8 hours agorootparentCould, but when it comes to handling errors in the frontend, I find it is easier for the discriminator to be the actual status code when possible, rather than needing multiple additional properties. reply smrq 2 hours agorootparentSurely \"when possible\" should be \"when semantically correct\"? I don't hate fun (see the threads on removing 418 from Node and Go for that), but misusing a joke status code in production to mean something completely unrelated seems less like fun and more like poor design. reply nurettin 8 hours agoparentprevI handle all these special cases like 2xx_other, 3xx_other, 4xx_other and 5xx_other. I log the http code and the response in case I have to debug later. 4xx_other just means you shouldn't repeat the request, since the server thinks it is invalid. reply matt3210 11 hours agoprevyou are not a tea pot. reply flir 8 hours agoparentCeci n'est pas une théière reply karol 9 hours agoprevThe older generation of software craftsmen have been reading about it for a while now and the joke got a bit tedious at this point. reply ffsm8 8 hours agoparentEh, I remember it being introduced and it always puts a smile on my face. Though I admittedly don't click on it after reading the title. Its not like people are posting this daily reply yakireev 3 hours agoparentprevRelevant xkcd: https://xkcd.com/1053/ reply anilakar 11 hours agoprev [22 more] Please, never ever again add such features to standards as a joke. Some backend folks have started to return it as an indetermiante error code, which in turn means that all client-side libraries will have to handle it at some level. reply theturtle32 10 hours agoparentThey have to handle it anyway. There's nothing in the HTTP specifications that disallows a server from using whatever codes it wants to that aren't specifically specified. There is no \"HTTP 527 Server Needs a Nap\" but it is perfectly legal for my server to reply to clients with that HTTP status, and clients are expected to handle it like they would handle any other non-specific error in the 5xx class of response codes (server error). Other perfectly legal responses: 242 - TOO MUCH COFFEE (Server is overcaffeinated and processing requests too quickly) 299 - SUCCESSFUL BUT SASSY (Request succeeded but the server is throwing shade about it) 333 - QUANTUM UNCERTAINTY (The server simultaneously succeeded and failed until observed) 452 - EXCESSIVE TOAST reply samatman 2 hours agorootparentThis is a great point. I'm going to start calling 418 the brown M&M of server response codes. reply o11c 11 hours agoparentprevClients have always had to handle unknown return code according to the first digit, and by and large they do this succesfully, with the exception of 1xx codes which are widely buggy. reply Dilettante_ 11 hours agoparentprevImo, the real problem and where it went wrong is the people using it as an error code outside of its intended purpose(to signal being a teapot, not a coffee machine). I mean this 100% seriously, unironically. reply theturtle32 10 hours agorootparentI thought that at first, but then realized that it is, in fact, correctly a client error: the client erroneously directed a coffee-related request to a server that is, in fact, not meant to service such requests. :-P reply NooneAtAll3 10 hours agoparentprev> Some backend folks have started to return it as an indetermiante error code in other words, they decided to break the standard are we sure it's the standard who's wrong? reply nutrie 11 hours agoparentprevDisagree. We gotta have fun. reply threatofrain 11 hours agorootparentI counter-disagree. It is so easy in life to have fun. There's so much fun everywhere. If you're so starved for fun then this won't do it for you either. The higher the scale the more likely your easter egg becomes not an easter egg. I also think the supermajority of engineers prefer fun entirely outside of work, hence why open source can feel so lonely and without corporate funding would probably shrink to a pathetic size. Hence why personal websites are so culturally irrelevant. Or why there's such a lack of artistic experimentation in apps or web. Or why there's so few non-corporate meetups nowadays in CA or NY. reply theturtle32 10 hours agorootparentOh, definitely hard disagree with this! I am an engineer because I love it and because it brings me joy, and I love love LOVE things that involve humor and fun within the realm of what is oftentimes just work. It delights me when people can find ways to be creative and tongue-in-cheek and not take things so seriously all the time. It is one way in which we can have fun in our work. For me, the idea of keeping all my fun separated from my work sounds like a dystopian nightmare! reply bnegreve 11 hours agorootparentprevSo many things in the IT world started as non-professional things by non-professional engineers. If you're a professional who lives off one of these things you should be glad that someone wanted to have fun at some point. Let this HTTP code be a reminder of that. reply theturtle32 10 hours agorootparentThis! 100% this. reply chvrchbvrner 6 hours agorootparentprevAlso hard disagree from me. To quote from SICP: \"I think that it's extraordinarily important that we in computer science keep fun in computing. When it started out, it was an awful lot of fun. Of course, the paying customers got shafted every now and then, and after a while we began to take their complaints seriously. We began to feel as if we really were responsible for the successful, error-free perfect use of these machines. I don't think we are. I think we're responsible for stretching them, setting them off in new directions, and keeping fun in the house. I hope the field of computer science never loses its sense of fun. Above all, I hope we don't become missionaries. Don't feel as if you're Bible salesmen. The world has too many of those already.\" reply nutrie 11 hours agorootparentprevCounter-counter-disagree. This is the ultimate way to make sure the joke is preserved for the future generations while keeping implications absolutely miniscule. reply lynx23 10 hours agorootparentprevYou're the perfect reason to learn new english words/phrases: Killjoy.. And now I finally know what \"wet blanket\" mean,s thanks for that! reply saagarjha 11 hours agoparentprevThen do it. If a teapot has a handle on it so can you. reply ahoka 11 hours agoparentprevWhy is this a problem for libraries? Not that most libraries handle anything about HTTP correctly out of the box anyway. reply mehdix 11 hours agoparentprevWell, I recently used it in a small PostgREST-subset query builder I wrote in case the query builder received an input more complicated that what it could handle. I found 418 a natural response in this case. In retrospect a 5xx (edit: or better 422) error is more appropriate, however. reply thih9 10 hours agoparentprevRelevant earlier discussions: https://en.wikipedia.org/wiki/Hyper_Text_Coffee_Pot_Control_... reply AStonesThrow 11 hours agoparentprevThankfully, error codes such as this are structured so that the initial \"4\" digit is the only one that really matters. Just treat it as a client error and you can't go wrong. reply Epa095 11 hours agoparentprev* get to handle it. reply dreizehn 11 hours agoparentprev [–] So, you're saying you expect libraries that don't have a generic 4xx \"Oops, my bad, dev please handle it\" error case to be bothered by the existence of 418 in any way, shape or form? I think you're barking up the wrong tree. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The HTTP 418 \"I'm a teapot\" status code is a humorous error code indicating that a server refuses to brew coffee because it is a teapot.- This status code originated from an April Fools' joke in 1998 and is occasionally used by websites to reject specific requests.- A combined coffee/tea pot that is out of coffee should return a 503 status code, which indicates a service unavailable error, instead of 418."
    ],
    "commentSummary": [
      "A developer employs the HTTP status code 418 \"I'm a teapot\" to handle illegitimate bot requests, simplifying log filtering.- Originally a joke from an April Fools' RFC (Request for Comments), this code is humorously used in production, though it may lead to issues if not used appropriately.- The discussion reflects varying opinions on using humorous codes, emphasizing the balance between creativity and professionalism in engineering."
    ],
    "points": 198,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1730089926
  },
  {
    "id": 41973065,
    "title": "Buy payphones and retire",
    "originLink": "https://computer.rip/2024-10-26-buy-payphones-and-retire.html",
    "originBody": ">>> 2024-10-26 buy payphones and retire (PDF) PAYPHONES at High Volume Existing sites! Earn BIG $$. Money Back Guarantee! Dropshipping AliExpress watches, AI-generated SEO spam websites... marginally legal and ethical passive income schemes, that serve to generate that income mostly for their promoters, can feel like a modern phenomenon. The promise of big money for little work is one of the fundamental human weaknesses, though, and it has been exploited by \"business coaches\" and \"investment promoters\" for about as long as the concept of invesstment has existed. We used to refer mostly to the \"get rich quick\" scheme, but fashions change with the time, and at the moment \"passive income\" is the watchword of business YouTubers and Instagram advertising. And what income is more passive than vending machine coin revenue? Automated vending has had a bit of a renaissance, with social media influencers buying old machines and turning them into a business. The split of their revenue between vending machine income and social media sponsorship is questionable, but it's definitely brought some younger eyes to an industry that is as rife with passive income scams as your average spam folder. Perhaps it's the enforcement efforts of the SEC, or perhaps today's youth just need a little more time to advance their art, but I haven't so far seen a vending machine hustle quite as financialized as the post-divestiture payphone industry. For much of the history of the telephone system, payphones were owned and operated by telephone carriers. As with the broader telephone monopoly, there were technical reasons for this integration. Payphones, more specifically called coin operated telephones, were \"dumb\" devices that relied on the telephone exchange for control. In the case of a manual exchange, you would pick up a payphone and ask the operator for your party---and they would advise you of the price and tell you to insert coins. The coin acceptor in the payphone used a simple electrical signaling scheme to notify the operator of which and how many coins you had inserted, and it was up to the operator to check that it was correct and connect the call. If coins needed to be returned after the call, the operator would signal the phone to do so. With the introduction of electromechanical and then digital exchanges, coin control became automated, but payphones continued to use specialized signaling schemes to communicate with the coin control system. They had to be connected to special loops, usually called \"coin lines,\" with the equipment to receive and send these signals. The payphone itself was a direct extension of the telephone system, under remote control of the exchange, much like later devices like line concentrators. It was only natural that they would be operated by the same company that operated the control system they relied on. Well, a lot of things have changed about the payphone industry. The 1968 Carterfone decision revolutionized the telephone industry by allowing the customer to connect their own device. Coin operated telephones in the traditional sense were unaffected, but Carterfone opened the door to a whole new kind of payphone. In 1970, burglar alarm manufacturer Robotguard blazed the trail into a new telephone business. They imported a Japanese payphone that was a little different from the American models of the time: it implemented coin payment internally. Robotguard connected the payphone through one of their burglar alarm autodialers, a device that was already fully compliant with telephone industry regulations, and then hooked it up to a Southwestern Bell telephone line in a department store in in St. Louis. By inserting a dime, the phone was enabled and you could make a local call (the autodialer was used, in part, to limit dialing to 7 digits to ensure that only local calls were made). Robotguard had done their homework, consulting the same law firm that represented Carterfone in the 1968 case. They believed the scheme to be legal, since the modified Japanese payphone behaved, to the telephone company, just like any other customer-owned phone. The New York Times quotes Southwestern Bell, whose attitude is perhaps best described as resignation: Spokesmen for the Southwestern Bell Telephone Company, the operating company in that area, acknowledge that the equipment is in the store, that it is working as described and that it appears completely legal. There is nothing they can do about it at this time, they say. There was, indeed, nothing that they could do about it. Robotguard had introduced the Customer-Owned Coin-Operated Telephone, or COCOT, to the United States. Payphones were now a competitive business. Despite a certain air of inevitability, COCOTs had a slow start. First, there would indeed be an effort by telephone companies to legally restrict COCOTs. This was never entirely successful, but did result in a set of state regulations (and to a lesser extent, federal regulations related to long-distance calls) that made the payphone business harder to get into. More importantly, though, the technical capabilities of COCOTs were limited. The Robotguard design could charge only a fixed fee per call, which made it a practical necessity to limit the payphone to local calls. Telephone company payphones, which allowed long-distance calls at a higher rate, had an advantage. Long-distance calls were also typically billed by minute, which made it important for a payphone to impose a time limit before charging more. These capabilities were difficult to implement in a reasonably compact, robust device in the 1970s. A number of articles will tell you that COCOTs became far more common as a result of payphone deregulation stemming from the 1984 breakup of AT&T. I would love to hear evidence to the contrary, but from my research I believe this is a misconception, or at least not the entire story. In fact, payphones were deregulated by the Telecommunications Act of 1996, but that was done in large part because COCOTs were already common and telephone companies were unhappy that conventional payphones were subject to rate regulation while COCOTs were not [1]. Divestiture did definitely open the floodgates of COCOTs, although I think that the advances in electronics around that time were also a significant factor in their proliferation. In any case, several manufacturers introduced COCOTs in 1984 and 1985. These later-generation COCOTs were significantly more sophisticated than the mechanical system used by Robotguard. To the user, they were pretty much indistinguishable from carrier-operated payphones, charging varying rates based on call duration and local or long distance. This local simulation of the telephone exchange's charging decisions required that each COCOT have, in internal memory, a prefix and rate table to determine charges. Early examples used ROM chips shipped by their manufacturer, but over time the industry shifted to remote programming via modems. These sophisticated, electronically-controlled coin operated phones that did not rely on an exchange-provided coin line came to be known as \"smart payphones\" and even, occasionally, as \"smartphones.\" Smart payphones greatly simplified payphone operations and were even adopted by the established telephone companies, where they could save money compared to the more complex exchange-controlled system. But they also made COCOTs completely practical, as good to the consumer as any other payphone. As COCOTs became remotely programmable, the payphone business started to feel like a way to generate---dare I say it---passive income. All you had to do was collect the coins. Well, that and keep the phone in working order, which would become a struggle for the thinly staffed and overleveraged Payphone Service Providers (PSPs) that would come to dominate the industry. One of the new entrants into the payphone business was a company that specialized in exactly the kind of remote management these new smart payphones required: Jaroth Inc., which would do business as Pacific Telemanagement Solutions or PTS. Today, PTS is the largest PSP in the United States, but that isn't saying a whole lot. They enjoyed great success in the 1990s, though, and were so well-positioned as a PSP in the '00s that they often purchased the existing payphone fleet from former Bell Operating Companies that decided to abandon the payphone business. The 1990s were a good time for payphones, and they were also a good time for investment scams. Loose enforcement of regulations around investment offerings, the Dot Com Boom, and a generally strong economy created a lot of opportunities for \"telecom entrepreneurs\" that were more interested in moving money than information. The problem of 1990s telecommunications companies funded in unscrupulous ways is not at all unique to payphones, although it did reach a sort of apex there. I will take this opportunity to go on a tangent, one of those things that I have always wanted to write an article about but have never quite had enough material for: MMDS, the Multichannel Multipoint Distribution Service. MMDS was, essentially, cable television upconverted to a microwave band and then put through directional antennas. It was often marketed as \"Wireless Cable,\" sort of an odd term, but it was intended as a direct competitor to conventional cable television. I think it's fair to call it an ancestor of what we now call WISPs, using small roof-mounted parabolic antennas as an alternative to costly CATV outside plant. Some MMDS installations literally were early WISPs: MMDS could carry a modified version of DOCSIS. Wireless cable got a pretty bad rap, though. If you pay attention to WISPs, you will no doubt have noticed that while the low capital investment required can enable beneficial competition, it also enables a lot of companies that you might call \"fly by night.\" Some start out with good intentions and just aren't up to the task, while some come from \"entrepreneurs\" with a history of fraud, but either way they end up collecting money and then disappearing with it. MMDS had a huge problem with shady operators, and more often of the \"history of fraud\" type. Supposed MMDS startups would take out television and newspaper ads nationwide offering an incredible opportunity to invest in this exciting new industry. The scam took different forms in the details, but the most common model was to sell \"shares\" of a new MMDS company in the four-to-five-digit range. Investors were told that the company was using the capital to build out their network and would shortly have hundreds of customers. In practice, most of these \"MMDS startups\" were in cities with powerful incumbent cable companies and, even worse, preexisting MMDS operators using the limited spectrum available for such a wideband service. They never had any chance of getting a license, and didn't have anyone with the expertise to actually build an MMDS system even if they got one. They just pocketed the money and were next seen on a beach in Mexico or in prison, depending on the whims of fortune. These wireless cable schemes became so common, and so notorious, that if you asked a lot of people what wireless cable was the two answers you'd get are probably \"no idea\" and \"an old scam.\" It only takes a brief look at newspaper archives to find that the payphone industry was a little sketchy. There are constant, nationwide, near-identical classified ads with text like \"buy and retire now\" and \"$150k yearly potential\" and \"CALL NOW!\". Sometimes more than one appear back to back, and they're still nearly identical. None of these ads give a company name or really anything but a phone number, and the phone numbers repeat so infrequently that I suspect the advertisers were intentionally rotating them. This was pretty much the Craigslist \"work from home\" post of the era. To understand payphone economics better, let's talk a little about how the payphone business operated. Telephone companies had long run payphones on the same payment model, by finding a location for the payphone (or being contacted by the proprietor of a location) and then offering the location a portion of revenue. In the case of incumbent telcos, this was often a fixed rate per call. So someone owned the location and the payphone operator paid them in the form of a royalty. COCOTs enabled a somewhat more complex model. A COCOT might be located in a business, connected to a telephone company line, and remotely programmed by a service provider, all of which were different companies from the person that actually collected the money. The revenue had to get split between all of these parties somehow, but COCOTS weren't regulated and that was all a matter of negotiation. Much like the vending machine industry today, one of the most difficult parts of making money with a payphone was actually finding a good location---one that wasn't already taken by another operator. As more and more PSPs spread across the country, this became more and more of a challenge. So you can imagine the appeal of getting into the payphone hustle without having to do all that location scouting and negotiation. Thus all the ads for payphone routes for sale... ostensibly a turnkey business, ready to go. Ah, but people with turnkey, profitable businesses don't tend to sell them. Something is up. Not all of these were outright scams, or at least I assume some of them weren't. There probably were some PSPs that financed expansion by selling or leasing rights to some of their devices. But there were also a lot of... well, let's talk about the second largest PSP of the late '90s. Somewhere around 1994, Charles Edwards of Atlanta, Georgia had an idea. His history is obscure, but he seems to have been an experienced salesman, perhaps in the insurance industry. He put his talent for sales to work raising capital for ETS Payphones, Inc., which would place and operate payphones on the behalf of investors. The deal was something like this: ETS identified locations for payphones and negotiated an agreement to place them. Then, they sold the payphone itself, along with rights to the location, to an investor for five to seven thousand dollars a pop. ETS would then operate and maintain the payphone while paying a fixed monthly lease to the investor who had purchased it---something like $83 a month. It was a great deal for the investors---they didn't need any expertise or really to do any work, since ETS arranged the location, installed the phones, and even collected the coins. In fact, most investors purchased phones in cities far from where they lived, such was the convenience of the ETS model. There was virtually no risk for investors, either. ETS promised a monthly payment up front, and the contract said that they would refund the investor if the payphone didn't work out. The ETS network was far larger than just Edwards could manage. Most of the investment deals were sold by independent representatives, the majority of them insurance agents, who could pick it up as a side business to earn some commission. Edwards sold nearly 50,000 payphones on this basis, many of them in deals of over $100,000. Small-time investors convinced of the value by their insurance agents, many of them retirees, put over $300 million into ETS from 1996 to 2000. There was, as you might have guessed, a catch. One wonders if the payphones were even real. I think that at least many of them were; ETS ran job listings for payphone technicians in multiple cities and occasionally responded to press inquiries and complaints about malfunctioning payphones bearing their logo. Besides, the telecom industry recognized ETS as a huge PSP in terms of both installed base and call volume. What definitely wasn't real was the revenue. ETS was a ponzi scheme. In 2000, the SEC went for Charles Edwards, showing that ETS had never been profitable. Edwards sponsored a NASCAR team and directed millions of dollars in salary and consulting fees to himself, but in the first half of 2000 ETS lost $33 million. The monthly lease payments to investors were being made from the capital put in by newer investors, and even that was drying up. SEC v. ETS went on for six years, in good part due to an appeal to the Supreme Court based on ETS' theory that a contract that paid a fixed, rather than variable, monthly rate could not be considered a security. In 2006, Charles Edwards was convicted of 83 counts of wire fraud and sentenced to thirteen years in prison. Edwards was far from the only coin-op fraudster. ETS was not unusual except in that it managed to be the largest. When a class-action firm and several state attorneys general went after ETS, their press releases almost always mentioned a few other similar payphone schemes facing similar legal challenges. Remember all of those classified ads? I suspect some of them were ETS, but ETS also had a more sophisticated sales operation than two-line classifieds. Most of them were probably from competitors. The payphone industry crashed alongside ETS; ETS almost certainly would have collapsed (albeit likely more slowly) even if it had been above board. Increasing cellphone ownership from the '90s to '00s made payphones largely obsolete, and more and more established telcos and PSPs decided to drop them. One of the reasons for PTS's ascent was its willingness to buy out operators who wanted out: in 2008, PTS bought most of AT&T's fleet. In 2011, they bought most of Verizon's fleet. Almost every incumbent telephone company got out of the payphone business and most of them sold to PTS. Given all that, you might think that payphone scams were only a thing of the '90s. And they mostly were, but you can imagine that there was an opportunity for anyone who could adapt the ETS model to the internet age. Pantheon Holdings did just that. It's even more difficult to untangle the early days of Pantheon than it is ETS. Pantheon operated through a variety of shell companies and brands, but \"the Internet Machine Company\" was perhaps the most to the point. Around 2005, Pantheon built \"internet kiosks\" where customers could check their email, print documents, and even make phone calls for a nominal cash or credit card payment. Sometimes called \"global business centers,\" these kiosks were presented as an exciting business opportunity to mostly elderly investors who were given the opportunity to buy one for just $18,000. Once again, the kiosks were real, but the revenue was not. Pantheon placed the machines in low-traffic locations and did nothing to market them. By 2009, more than a dozen people had been convicted of fraud in relation to the Internet Machines. Pantheon kiosks still turn up on the junk market. [1] I spent quite a bit of time researching the history of payphone regulation to try to understand exactly what did change in 1984, how many COCOTs operated and on what legal basis from 1970-1984, etc. I did not have much success. What I can tell is that COCOTs were very rare prior to 1984 (so rare that the FCC apparently didn't know of any, according to a 1984 memo, despite the 1970 example), and by the late '80s were very common. The FCC seems to have taken the view, in 1984, that COCOTs had always been legal, and just weren't being made or used on any significant scale. That's somewhat inconsistent, though, with the fact that suddenly after 1984 divestiture a bunch of companies started making COCOTs for the first time. My best guess right now is that from 1970-1984 COCOTs were probably legal but were something of a gray area because of the lack of any regulations specifically applying to them. Some combination of divestiture broadly \"shaking up\" the phone industry, electronics making COCOTs much more feasible, and who knows what else lead multiple companies to get into the COCOT business in the mid80s. That lead the FCC to issue a series of regulatory opinions on COCOTs that consistently upheld them as legal, culminating in the 1996 act dropping payphone regulation entirely.",
    "commentLink": "https://news.ycombinator.com/item?id=41973065",
    "commentBody": "Buy payphones and retire (computer.rip)181 points by cratermoon 2 hours agohidepastfavorite59 comments btilly 31 minutes agoAh. Passive income. It can indeed work out for you, but it is the fact that it can work out that makes it so tempting for scammers. Warren Buffett claims that the best business that he was ever in was installing pinball machines in barber shops, then splitting the revenue with the barbers. See https://www.cnbc.com/2018/06/19/warren-buffett-bought-a-25-p... for verification. reply cies 11 minutes agoparentBuffett lies. He had much better investments. I likes to tell us all stories. The big-finance reality is much more inside-tradingish than he wants us all to believe. reply wsatb 0 minutes agorootparentBest doesn’t need to mean best investment. Best could simply mean what he enjoyed most. He likely thinks fondly of a simpler time. reply Scoundreller 1 hour agoprev> And what income is more passive than vending machine coin revenue? Automated vending has had a bit of a renaissance, with social media influencers buying old machines and turning them into a business. Iunno, where I grew up, vending machines were controlled by the mob. Up to mob hits in the HQ’s parking lot. Makes me wonder if pay phones are the same after the telco offloaded them. reply 0cf8612b2e1e 1 hour agoparentI have also heard that vending machine locations are highly contested. You can buy the machine, but you are not going to have the pull to deploy it at the airport. Those contracts were signed long ago. reply hyperhopper 38 minutes agorootparentThen why are there so few? And containing such a small variety of goods? In Japan anywhere from a busy subway to a remote park, there will be rows of vending machines everywhere, with more varieties of sodas, coffees, soups, ice creams, candies, hell even clothes or meat! And those are just the common types. You're never far from what you want in an automated fashion. Why are we so behind in America when there seemingly is excess on the supply side for the chance to supply more goods and deploy more machines, and demand on the consumer side for better, more convenient, more available, and more varied vending machines goods? reply crooked-v 34 minutes agorootparentThere are many huge contextual differences between the US and Japan when it comes to vending machines, but the most obvious one is that Japan is eminently walkable, while the US is so pedestrian-unfriendly that there's no guarantee that people will even be around your row of vending machines in the first place. reply Almondsetat 19 minutes agorootparentprev>Then why are there so few? And containing such a small variety of goods? Because if there are only a few with only few options you can charge the brands a lot more for the privilege of being available in your machine reply vel0city 24 minutes agorootparentprevI'd love it if the local city park near me had some neat vending machines near the bathroom pavilions. How relaxing it would be to get hot ramen and a tea from the vending machine while watching the swans and ducks migrate through. Instead I just have to make sure I tote all the family's snacks and refreshments when we go to the playground. reply monero-xmr 34 minutes agorootparentprevOr you put it out and a week later someone has bashed it to pieces with a baseball bat reply asveikau 1 hour agoparentprevI would imagine that's even more attractive to them in the old days, when they dealt in coins and bills. A modern vending machine probably mostly gets credit card transactions, which are traceable. reply stult 1 hour agorootparentIt's easier to launder money with services than goods anyway because you don't need to dispose of excess merchandise to make the books balance. Like if you want to claim to have sold 10000 cans of soda despite only selling 1000, you need to buy 10000 cans of soda or even the most superficial review of your accounts will reveal the scheme. The ideal laundering mechanism is a service with a high ratio of price to variable cost, like car washes or laundromats, because then it's easier to overstate income without needing to jump through hoops to overstate the matching costs. These days, it's almost trivial to launder via wash trades with the proliferation of online services with effectively zero marginal costs. e.g., setting up a freelancer account and a separate business account on some platform like Upwork and then hiring yourself. So I'd be surprised to see anyone laundering via sale of goods unless they are deeply incompetent or it's an opportunistic scheme of some sort (i.e., they are exploiting a unique opportunity that pops up). reply maxwell 59 minutes agorootparentI was thinking the other day that self-storage facilities seem ideal: you don't even need to account for discrepancies in utility usage, as in missing water at car washes and laundromats. Just say units are rented and paid in cash. Not aware of any KYC laws but haven't looked recently. reply mtnGoat 40 minutes agorootparentprevGreat theory lesson, but… You are basing all of this on a non cash world. Cash is still king in many parts of society that aren’t entirely on the up and up. These are the OGs of this sport and definitely aren’t incompetent. Plus sale of goods is very easy to fake if you have multiple parts of the vertical covered. things don’t make sense if you’ve never done them. reply tomjen3 10 minutes agorootparentprevDepends on what you want to launder. Drugs are paid for in cash, so you need to launder cash - and the best way to do that is to have a business that does some amount of cash legally. I can imagine vending machines being useful here. You are right about needing to buy cans that you can then pretend to have sold. Unless of course you order from a supplier who is willing to write an invoice for a higher number of cans than he has sold you. I assume a more competent group would also own the supplier (though not, perhaps, on paper). reply VirusNewbie 1 hour agorootparentprev>These days, it's almost trivial to launder via wash trades with the proliferation of online services with effectively zero marginal costs. like an MS Paint drawing of a monkey, but on the blockchain. reply adamc 1 hour agorootparentprevYeah, same thought. Their attractiveness for laundering money may be diminishing. reply bongodongobob 58 minutes agoparentprevEven if not the literal Mafia, there are companies that will get violent over territory. I used to work with a guy who had an arcade game side business in the 90s and would lease or whatever to bars. Starting out, he didn't know about the territories and put some machines where they shouldn't be. The group that \"owned \" the territory found out he was putting machines in their turf and started vandalizing his machines and warned him to pull out or they were going to vandalize him. He ended up slowly selling off his machines because the competition and craziness of it all was too much to deal with. reply andrewla 5 minutes agoprevThe concept of \"passive income\" is almost a scissor concept. Or maybe only if you couple it with the categorical imperitive. On the one hand, it's so obviously true that it would be great to have passive income. Draw the salary you're drawing now, with some growth, and not have to work. On the other hand, if everyone had access to this capability then society and civilization would grind to a halt. People make things; if people don't make things, then we don't eat, we don't drink. If the goal is to have a system where everyone can have passive income, then achieving that goal is the end of the world. The categorical imperative roughly says that something is moral only if its universal adoption would benefit society. So there is a break there. The idea of passive income is isomorphic to rent seeking, which we generally agree is a bad thing. reply lencastre 1 hour agoprevWhat’s triangular shaped, 3D, and rhymes with Eeramid Scheme. reply hyperhopper 35 minutes agoparentNot a Pyramid scheme, that's for sure because that's a concept, which means it's not 3D. reply cryptozeus 27 minutes agoprevSlight off topic self rant: I tried this (dropshipping etc), went against all the good wisdom and rules of creating honest and passionate business. Failed miserably. Funny how brain works, I knew in 3 months that this is not honest, it feels spammy but then orders were coming in so I convinced myself that half the amazon products are doing the same thing. There is market for it then why should I not do this. This nagging voice in my head never went away and I paid for this later on. This matters when you have to work through night to get the marketing campaign out or you have double down the investment for certain product during holiday sale. Dealing with daily email of customers or tracking lost orders. I eventually lost energy and any sort of desire to grow my business. I was not making the kind of money I was promised by the field of dropshipping without adding way more money in spamy marketing and I had not passion to sell the product I Was selling. Certain folks who seems to be making 1m rev per year are also pivoting through spammy products every month and just dumping 100s and 1000s of dollars in facebook ads. It is more of a spammy marketing game then implementing any sort of creative or intellectual skillset. If anyone is thinking of doing this then I would encourage or first figure out how attached you are to money and the work you are doing. I was pulled into this because I thought I am smarter than rest and I can crack this because of my skills in technology and design so I dont to pay anyone to setup website, taxes, marketing etc however I missed out on how much soulless you have to be to run such a business. I dont mean soulless as a bad thing here, if you are robot or a you can setup a bot to do this then by all means try it but I just could not. This had a double impact on my life. Not only I failed to make money, wasted time but I also hate myself of even getting stuck into this. Lost my confidence and self respect which probably was unfounded anyway. Only thing I can tell myself is that hopefully this lifted some sort of delusion I had about myself and I learn and become better at life through this. reply SoftTalker 11 minutes agoparentThe lesson here is that there really is no free lunch. There is no secret, no-work way to make lots of money. If anyone can do it, there's little value in it so you won't make much money. If you have thousands of dollars to invest and want to do no work, just buy index funds. reply cryptozeus 0 minutes agorootparentVery true, I did exactly this. reply eastbound 14 minutes agoparentprevSorry for you losing your confidence over this. To be frank, the idea itself of creating a company is spammy. I created my company, but I knew the market from inside (it wasn’t a public company so it wasn’t insider trading, but clearly I had unfair advantage at start). I’ve witnessed many people on the same market as I was, trying to find something to sell, and failing at it. Everyone here is told that they can do it and the good idea will arrive as they work, well, that is spam. Truth is there are enough businesses in the world. It’s not exactly just luck. It’s also accurately knowing when you have a chance. I’ve also witnessed a dozen startups succeed in my area, to the point of about $50m revenue, so I could also have succeeded better. But really, it wasn’t your skills or your confidence. It’s that you didn’t have a good edge at start, maybe your only flaw is not judging against your initial idea, early enough, and waiting for the next opportunity in your professional life. But your implementation skills are visibly excellent, so if you don’t feel like restarting on your own, go help someone and help him scale. You’ll be excellent at it. reply cryptozeus 0 minutes agorootparentThat is a great reframing! Thanks for saying this. This is what I am planing to do next, implement all these skills for meaningful business and help them grow. reply jbaczuk 39 minutes agoprevI had a viceral \"oh no, did I just install a virus\" feeling when I visited that website, haha. I guess those memories die hard. reply warner25 26 minutes agoparentI wanted to share one of his pieces with a friend, so I sent the URL in a text message, and my friend (a network technician) responded with \"Uh, is that link safe?\" The title of the piece was \"Free Public WiFi\" which makes it look even more suspicious, haha... https://computer.rip/2023-07-29-Free-Public-WiFi.html reply ChrisMarshallNY 20 minutes agoprevWhen I was a kid, we stole a payphone. Those bastards are tough. We whacked on it for an hour, with a 15-lb sledgehammer. When it finally broke open, it yielded about $1.50. reply syndicatedjelly 38 minutes agoprevThat tiled background is from this gem of a video, starting at 4:50 https://youtu.be/tc4ROCJYbm0?si=Q2OpRvvjebTPrV-p&t=290 reply Hackbraten 1 hour agoprev> Ah, but people with turnkey, profitable businesses don't tend to sell them. > Something is up. Who would have thought? reply damir 19 minutes agoprevI need tl;dr version here... :) reply thefourthchime 1 hour agoprevOff topic, but does anyone else just drop that text into ChatGPT to get a summary? I want to know what the TLDR is before I invest in something that long. reply warner25 55 minutes agoparentThis author is a very good and entertaining writer. You're really missing out if you don't take the time to read every word. Make yourself a drink, find a nice place to sit, and enjoy. I was introduced to his work through an HN post last year. I was hooked by that first piece, and I've often gone back to his archive whenever I've had the time to read something long-form for leisure. reply 101008 1 hour agoparentprevI didn't but I thought of that after reading one paragraph and noticing it was going to take some time to get to the point. reply tombert 1 hour agoparentprevI use the Kagi Universal Summarizer fairly often, which I believe uses GPT. It's generally useful enough. reply phyalow 1 hour agoparentprevWas very tempted too, but preempted that by evaluating that the effort of opening an extra browser tab -> navigation -> model selection (select 01-mini probably) -> then back/forth copy- paste, was mitigated by a very quick skim read/jump to the end. reply gs17 31 minutes agoparentprevI've done it for this blog before. It's a writing style that's \"not for me\" even when the topic is something I'm interested in. reply add-sub-mul-div 44 minutes agoparentprevIf I'm not interested in reading something fully I can get the main idea of it from skimming much faster than I could by getting an AI summary. And without the uncertainty that the AI got something about the summary wrong. reply tomjen3 1 minute agoparentprevYou are getting downvoted so heavily that I can barely read your comment. Unfortunately HN has a hate for AI, but any writer should expect to demonstrate right of the bat that you have something worthwhile to share. Most stuff posted online is not worth reading. The article failed to demonstrate that, and it had the style of \"I need to pad this to reach some kind of minimum word count\". I think reading the article was worth it, but thanks to the the style I was about to quit several times. Your solution of runnning it through an LLM would certainly have been a better outcome than this. reply buildsjets 1 hour agoparentprevChatGPT says: \"The speaker wonders if others use ChatGPT to get summaries of lengthy texts to determine if they're worth reading.\" Nope, just you bucko. reply anonzzzies 1 hour agoprev [–] Why would I want to retire? I am old and most my friends are boring or died after they retired. Sounds like hell on earth. I like working, it is my hobby and life. reply asveikau 1 hour agoparentThis article isn't about retirement; the reference to retirement is the line the scammer is using to hook people. The scammer is telling the mark they will generate lots of money from passive income (from payphone calls), and won't need to work. It is actually an article about Ponzi schemes. reply hinkley 1 hour agorootparentPonzi schemes are pure financial instruments. If a product is involved it’s called an MLM. reply asveikau 1 hour agorootparentI'd say that is a bit like splitting hairs, but the article does question the extent to which actual payphones and calls were actually involved.. reply hinkley 1 hour agorootparentPonzi schemes are illegal. MLMs are legalized Ponzi schemes. The outcomes are similar but one has a veneer of legitimacy that makes it more dangerous for some people. reply asveikau 1 hour agorootparentIt's instructive not to argue the finer points without acknowledging what TFA says about the operators of the scheme breaking the law: > In 2006, Charles Edwards was convicted of 83 counts of wire fraud and sentenced to thirteen years in prison. Then another company: > By 2009, more than a dozen people had been convicted of fraud in relation to Prometheus. reply verisimi 1 hour agorootparentprevYeah grandad. Wot he ^ said. reply Swizec 1 hour agoparentprev> Why would I want to retire? /../ I like working, it is my hobby and life. So you can work on things because you want to not because you have to. At least that's my plan. Not quite there yet. reply TheRealPomax 1 hour agorootparentNote that there are loads of things that you can't keep working on after you retire. If your company had you in a position where you ran really interesting projects, all of those are the company's projects, not yours. You got to work on them because you worked there, and once you retire you can't just keep working on them, you can't even do the same work on your own because your contract made that pretty clear: now you're committing IP theft. So you retire, and by law you're no longer allowed to do the thing you love. It's not a good deal. reply Rumudiez 9 minutes agorootparentYou can be \"retired\" (don't _need_ to work) and still have a dayjob. My father-in-law does this and works 2 days a week so he doesn't get bored and has a little more spending money, all because he likes his profession but not because he has to work for a living anymore reply dleink 1 hour agorootparentprevThe things I love are broader than \"IP controlled by my company.\" I can see that if the thing you love is massive financial institutions or defense contracting or something? reply bongodongobob 54 minutes agorootparentMaybe he's a helicopter mechanic or a million other things you can't just do at home. reply brewdad 40 minutes agorootparentGo buy 40 acres in the desert and live your dream. reply dustyventure 14 minutes agorootparentIf a very expensive hobby is a lot of work are you working or retired? reply iwontberude 1 hour agorootparentprevMakers, programmers, hackers always have to work by definition, the question is whether you also want to. That can be done anywhere, it's all a state of mind. Most of the answers to the problems of the world are inside of there. reply mock-possum 8 minutes agoparentprevI think the deal is when you retire you no longer have to work. You can spend your time doing whatever you want. If you don’t feel like working today, you don’t have to. If something comes up last minute, you can change your mind. If you want to move to something new and more interesting, you can. reply forinti 42 minutes agoparentprevYou might not want to retire, but your body (or mind) might have other ideas. reply jabroni_salad 1 hour agoparentprev [–] Do you already have financial independence? Not being able to understand why retiring would be desirable sounds like an incredibly privileged opinion. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text outlines the history of payphones, from being managed by telephone carriers to the introduction of Customer-Owned Coin-Operated Telephones (COCOTs) in the 1970s.",
      "It highlights the rise of payphone scams in the 1990s, such as the ETS Payphones Ponzi scheme, which falsely promised investors fixed monthly returns.",
      "As cellphones gained popularity, the payphone industry declined, leading to the collapse of many schemes, with Pantheon Holdings later adapting the scam model to internet kiosks in the 2000s."
    ],
    "commentSummary": [
      "The discussion highlights vending machines and payphones as potential passive income sources, referencing Warren Buffett's successful pinball machine venture.",
      "Challenges in vending machine businesses, such as territorial disputes and money laundering risks, are explored.",
      "The conversation includes debates on passive income's societal implications and personal anecdotes of failed ventures, alongside discussions on retirement and financial independence."
    ],
    "points": 182,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1730133191
  },
  {
    "id": 41969753,
    "title": "How Gothic architecture became spooky",
    "originLink": "https://www.architecturaldigest.com/story/how-gothic-architecture-became-spooky",
    "originBody": "ARCHITECTURE + DESIGN How Gothic Architecture Became Spooky When conceived, the style was meant to be heavenly and transcendent—so how did it become the vision of a haunted house? By Katherine McLaughlin October 24, 2024 The Cathedral of Albi, France.Photo: Sen Li Twenty-five years ago, Dr. Robert Bork, a professor of art history at the University of Iowa and a specialist in the study of Gothic architecture, was working in his office when a student knocked on the door. Throughout the room were pictures of Cologne Cathedral, an 1880 church in Germany and one of Dr. Bork’s favorite buildings. The images, seemingly, caught the student’s attention. “Dr. Bork,” he said. “Why does it look so evil?” There is nothing inherently scary or sinister about the structure. As an example of Gothic architecture, it bears many iconic elements of the style: pointed arches, flying buttresses, tall spires, rib vaults, window tracery, and stained glass. But it was never meant to invoke fear. So the student’s question was interesting to the professor. “I asked him why he said that,” Dr. Bork tells AD. “And he replied, ‘Well, it looks just like the skyscraper in Ghostbusters.’” Cologne Cathedral in Cologne, Germany Photo: Sparwasser/Getty Images For decades, Gothic architecture has been a go-to style for production designers, writers, and even musicians looking to convey terror through physical spaces. In Dracula (1931) Carfax Abbey is based on Whitby Abbey, a Gothic monastery; Manderly from Alfred Hitchcock’s Rebecca (1939) pulls inspiration from Gothic houses; and more modern films and shows like Crimson Peak (2015) and Wednesday (2022) keep the trope alive. “The idea of Gothic buildings being scary or haunted is fairly recent,” says Michael Crosbie, an architect and professor of the course Architecture in Film at Hartford University. “In the early to mid 20th century, there were a lot of Gothic buildings in movies that showed them as haunted places.” One could argue that repetition has perhaps conditioned viewers to think of the style as scary, so creators continue using it, prompting something of a never-ending loop. But their original introduction into horror media was always a deliberate choice. “It’s not random,” Dr. Bork says. “There are good reasons.” Notre-Dame in Paris is among the most famous Gothic buildings. Photo: Pete Douglass/Getty Images Gothic architecture first emerged in the 12th century and was most closely related with church architecture, though other uses did exist. In religious settings, it was meant to suggest the superhuman. “Buildings were supposed to make you feel like you were in the presence of a bigger, more mysterious God,” Dr. Bork says. Architects did this by circumventing many of the “rules” previously established in Romanesque architecture, which had been widespread in the decades before and has roots in Greek and Roman classicism. Built in 1790, the exterior of the Pantheon in Paris showcases a neoclassical style, with direct references to Greek and Roman design. Photo: Ruggero Vanni/Getty Images MOST POPULAR CULTURE + LIFESTYLE Unpacking the Beige Kids Decor Controversy Rocking the Internet By Katherine McLaughlin ARCHITECTURE + DESIGN 6 Design Tips to Steal From This Small Paris Duplex By Annabelle Dufraigne CELEBRITY STYLE Matthew Perry’s Midcentury Los Angeles Home Sells for $8.55 Million By Katie Schultz This forebear was uniform and symmetrical, regulated by harmony, ratios, and scale. In fact, each order of Greek design—Doric, Ionic, and Corinthian—was based on the human body, and therefore felt safe, approachable, and familiar. As Gothic architecture emerged, many classical traditions receded. “In the Middle Ages, [architects] left behind the human metaphor and moved to the superhuman,” Dr. Bork adds. Suddenly, columns became arbitrarily tall and stretched, ornamentation grew bolder, and interiors felt more cavernous thanks to new construction techniques that allowed higher ceilings and required less interior columns. Architects pushed the envelope and were willing to experiment outside of what was previously deemed correct or right. The general vertical presence through elongated columns and high ceilings was meant to evoke a heavenly reach. Inside Notre Dame Basilica of Montreal. Gothic interiors were designed to symbolize a higher power. Photo: Felipe Mulè/Getty Images Though perhaps intimidating in their grandeur, they weren’t intended to inspire fear. “It was supposed to be positive, transcendent, and godly, not scary,” Dr. Bork explains. However, the designs assumed a less favorable association in the early 16th century during the Renaissance, when there was once again a desire for the rules, order, and “perfection” of classical antiquity. “It was perceived as lawless, chaotic, and disorderly because it didn’t follow the rules of classicism,” Dr. Bork explains. “It got stuck with that association.” MOST POPULAR CULTURE + LIFESTYLE Unpacking the Beige Kids Decor Controversy Rocking the Internet By Katherine McLaughlin ARCHITECTURE + DESIGN 6 Design Tips to Steal From This Small Paris Duplex By Annabelle Dufraigne CELEBRITY STYLE Matthew Perry’s Midcentury Los Angeles Home Sells for $8.55 Million By Katie Schultz Throughout the next two centuries, the style largely lost favor, until Horace Walpole, a writer, decided he wanted his own “little Gothic castle.” In 1749, he built his estate in London, called Strawberry Hill, modeled off of Gothic cathedrals and medieval castles. Defined by arched windows, stained glass, turrets, and battlements, the residence is largely considered the first Gothic Revival building and contributed to the widespread re-interest in the historic aesthetic. Strawberry Hill House in west London Photo: Sam Mellish/Getty Images The 18th century then saw a boom in neo-Gothic buildings, many of which were residences. Today, they are recognizable for their use of pointed arches (seen on doors, windows, and gables), high-pitched roofs, and vergeboard (wooden trim attached to gables). Perhaps coincidentally, philosopher Edmund Burke published A Philosophical Enquiry into the Origin of our Ideas of the Sublime and Beautiful around this same time, in 1757, which became an extremely an influential text that detailed what he called sublime art. “Whatever is in any sort terrible or is conversant about terrible objects or operates in a manner analogous to terror, is a source of the sublime,” he wrote. Burke separated the beautiful from the sublime, and aesthetic theories generally classify the sublime as work that showcases greatness beyond measurement, comprehension, or experience; its magnitude is both awe-inspiring and terrifying. The interiors of Strawberry Hill Sam Mellish/Getty Images Other important literature that was published during this time was work by Watpole himself. His novel, Castle of Otranto, was reportedly inspired by a dream he had while living at Strawberry Hill. Set in a castle in the Middle Ages, the epic details a lord and his family living in a haunted mansion. “In the late 18th and 19th century, Gothic became associated with spookiness, which got wound into ideas of the exotic and sublime,” Dr. Bork says. “By the 20th century, you have movies and mass media that start using this.” MOST POPULAR CULTURE + LIFESTYLE Unpacking the Beige Kids Decor Controversy Rocking the Internet By Katherine McLaughlin ARCHITECTURE + DESIGN 6 Design Tips to Steal From This Small Paris Duplex By Annabelle Dufraigne CELEBRITY STYLE Matthew Perry’s Midcentury Los Angeles Home Sells for $8.55 Million By Katie Schultz Today, filmmakers—and, more broadly, storytellers—use these ingrained historical associations to great effect. “When I teach my course, I approach architecture as a character in a film,” Crosbie says. “The character has a role, which is to get across and reinforce themes.” If the idea is to express something otherworldly or beyond comprehension—say, a ghost—what better style to use than Gothic? Of course, not every viewer will know its history, but, subconsciously, these messages may still come across. Jennifer Spence, a production designer who has worked on movies such as The Nun (2018), Splinter (2008), and those in the Insidious (2013, 2015), Paranormal Activity (2010, 2011, 2012), and Annabelle (2017, 2019) franchises, notes that the style’s age is also compelling. “If you’re writing a story with a ghost, there has to be an origin,” she says. “An older home offers decades of opportunities for backstories to happen, maybe they got murdered or something else happened to them in the home.” An illustration of a neo-Gothic residence leans into horror motifs including bats, dead plants, and a seemingly abandoned home. Photo: Getty Images Further, the scale and layout of Gothic buildings can emphasize elements prone to terror. “In Gothic architecture, especially when it’s domestic, the rooms can be very small and you can’t see everything the way you might be able to with an open floor plan in a modern house,” Crosbie says. “A contemporary residence could take away some of the shadows and the creepiness of not knowing what’s around the corner.” MOST POPULAR CULTURE + LIFESTYLE Unpacking the Beige Kids Decor Controversy Rocking the Internet By Katherine McLaughlin ARCHITECTURE + DESIGN 6 Design Tips to Steal From This Small Paris Duplex By Annabelle Dufraigne CELEBRITY STYLE Matthew Perry’s Midcentury Los Angeles Home Sells for $8.55 Million By Katie Schultz During units on “haunted architecture,” Crosbie has his students watch The Haunting (1963), set in a Gothic mansion in the Berkshires of western Massachusetts. “It’s all about how architecture hides things, and the whole movie is a hide-and-seek game between the family that lives there and the house itself,” Crosbie says. “The people get lost going down long hallways, they get disoriented, which is a big theme.” A Gothic arch on the poster for The Raven, one of many films to use Gothic architecture to represent horror. Photo: Universal History Archive/Getty Images In the House of the Damned, the residence’s architecture references many Gothic motifs. Photo: LMPC/Getty Images Dr. Bork points out film series like Lord of the Rings, in which the good kingdom, Gondor, is represented using motifs from Roman and Romanesque architecture, featuring round arches and simple proportions. On the other hand, Mordor, the evil kingdom, pulls from a Gothic vocabulary and includes pointed arches, pinnacles, and diagonal forms. “They were absolutely riffing on a well-informed knowledge of Romanesque and Gothic style when they put those films together,” he says. “And so, generations of kids have seen that by now and that colors their views.” A set in Annabelle: Creation, designed by Jennifer Spence Photo: Justin Lubin. Courtesy of Warner Bros. Pictures and New Line Cinema Spence agrees that perceptions continue to play a role in the choice that set designers use today. “I remember looking back at some of the scary movies that I watched as a kid, like Vincent Price movies, and they were always in a Gothic house or some kind of castle. So you’re almost taught that they’re scary,” she says. “Now, it just seems like the kind of place a ghost or horror could be.” MOST POPULAR CULTURE + LIFESTYLE Unpacking the Beige Kids Decor Controversy Rocking the Internet By Katherine McLaughlin ARCHITECTURE + DESIGN 6 Design Tips to Steal From This Small Paris Duplex By Annabelle Dufraigne CELEBRITY STYLE Matthew Perry’s Midcentury Los Angeles Home Sells for $8.55 Million By Katie Schultz Though Gothic may have evolved from something heavenly to sinister, its original intentions remain. “It has flipped from light to dark, but what stays constant is the realization that it’s superhuman or unearthly,” Dr. Bork says. Today this may have a different effect, but “there’s a reason these things stick. It’s because they’re designed that way.”",
    "commentLink": "https://news.ycombinator.com/item?id=41969753",
    "commentBody": "How Gothic architecture became spooky (architecturaldigest.com)138 points by teleforce 7 hours agohidepastfavorite76 comments amiga386 3 hours agoI don't think Gothic architecture ever drove the plots of Gothic romance or horror, apart from a few choice novels. It was mostly used as a setting. The spookiness, at least for Americans, came like so: 1. Gilded Age upper classes built the fanciest mansions they could afford, in the Neo-Gothic style which was fashionable at the time 2. Like the English country houses (see https://en.wikipedia.org/wiki/Destruction_of_country_houses_...), eventually these rich owners couldn't afford the upkeep of these massively oversized and ornate dwellings. And nobody would buy them. So they moved out and left the mansions to become ruins 3. Now lots of people know about the old abandoned mansion on the hill. Gothic! Spooky! That includes Charles Addams, who starts making jolly cartoons in the New Yorker about the odd family that live in a big spooky mansion, and it includes Alfred Hitchcock who thinks a run-down mansion is a great setting for Psycho reply rockfishroll 2 hours agoparentYou see a similar trend again with \"abandoned mental hospitals\" as settings for horror in TV and movies. The trend of \"deinstitutionalization\" started in the 50s and 60s, meant that by the 80s and 90s many psychiatric hospitals had been defunded and shut down. As a result, it was a surprisingly common childhood experience for people of a certain age to have an \"old abandoned mental hospital two towns over\". Every kid \"knew someone who knew someone with an older brother who had spent all night in one\", and there were a ton of them around to use as settings. Maybe in 30 years, all horror movies will be set in abandoned cup cake stores. reply mercer 2 hours agorootparentThe way people were regularly 'treated' at these hospitals probably also figured into it. reply theshaper 39 minutes agorootparentprevIn twenty years, we'll probably see the same phenomenon with 'abandoned Data Centers.' Teenagers will head to these old buildings in small groups, looking for the ghostly Sysadmin who killed his family because the AI in his neural link told him to. reply MichaelZuo 56 minutes agorootparentprevWhy did it take so long for them to be demolished/change ownership after they were abandoned? reply KaiserPro 1 hour agoparentprevI suspect its fairly location specific. In the UK a neogothic wasn't even a thing when the first horror novels were made 1765 (Palladian style was all the rage) around 1870 \"high gothic\" https://en.wikipedia.org/wiki/High_Victorian_Gothic was the equivalent of glass and steel construction for us, or possible more like Bauhaus, a homage to an earlier age, but with a modern twist. either way, it was uber modern. reply jhbadger 2 hours agoparentprevAnd the (perhaps unintentionally spooky) 1925 Edward Hopper painting House by the Railroad depicting one of these Gilded Age houses, which is said to have inspired the fictional houses in the Addams Family and in Psycho. https://en.wikipedia.org/wiki/House_by_the_Railroad reply lancesells 2 hours agoparentprevI don't disagree with as your points, but I also think a structure made of spikes and points is inherently more evil feeling than something round or oval. Also, religious structures and religion veer towards the dark and ominous. Catholics and christians depict a guy nailed to a cross with a crown of thorns on his head in their cathedrals so that doesn't help. reply bee_rider 2 hours agoparentprevI wonder to what extent our conception of spookiness is driven by what big buildings happened to be slightly but not overwhelmingly run down, and available for cheap sets. The fact that gothic houses happened to be in that state when cameras became widespread Hollywood was inventing tropes probably influenced things quite a bit! reply parpfish 2 hours agorootparentInteresting connection here to modern creepy settings leaning on liminal spaces and run-down early 90s stuff in analog horror. The new scary settings are run down Chuck E. Cheese’s and empty office buildings. reply amiga386 53 minutes agorootparente.g. https://en.wikipedia.org/wiki/Five_Nights_at_Freddy%27s and https://en.wikipedia.org/wiki/The_Backrooms ? Personally I liked https://en.wikipedia.org/wiki/Control_(video_game) whose setting was largely inspired by imagining what goes on inside the windowless skyscraper at https://en.wikipedia.org/wiki/33_Thomas_Street reply parpfish 19 minutes agorootparentexactly. control was amazing but had never really connected it to backrooms, but it makes sense. that final set piece synced up to the song was one of the best things i've experienced in a video game. i didn't know it was explicitly inspired by that building, for some reason i kept thinking of this brutalist beauty that houses the FBI (https://en.wikipedia.org/wiki/J._Edgar_Hoover_Building) reply twic 48 minutes agorootparentprevPerhaps this is what you were alluding to, but immensely popular survival horror video game Five Nights at Freddy's is set in a thinly veiled Chuck E. Cheese. reply bee_rider 2 hours agorootparentprevYeah. Malls are another good one, although that seems to be a bit of a boom and bust field or something… and we’ve already had plenty of zombie movies set in malls. Office building are an interesting one because, of course, a ton of people can imagine working in an office building (having done so). Small colleges recently had a rough time of things, and also could be a place that is likely to generate a horror script writer, I bet we’ll get a good college horror story. reply Amorymeltzer 6 hours agoprev>Other important literature that was published during this time was work by Watpole himself. His novel, Castle of Otranto, was reportedly inspired by a dream he had while living at Strawberry Hill. Set in a castle in the Middle Ages, the epic details a lord and his family living in a haunted mansion. “In the late 18th and 19th century, Gothic became associated with spookiness, which got wound into ideas of the exotic and sublime,” Dr. Bork says. “By the 20th century, you have movies and mass media that start using this.” That's... not a lot of detail. The narrative I like comes from Walt Hickey's You Are What you Watch. Basically, there was wealth in the 1870s and 1880s during the Gilded Age, and those people built homes in the Victorian/Gothic/Queen Anne style. Their kids grow up in those homes, and suddenly books are becoming movies (early successes like Dracula in 1897 as a book and eventually movies), and horror is a big hit, and the kids who grew up in those homes are writing things that take place there. Meanwhile, the stock market crashes, those homes are abandoned and unmaintained and derided. \"When a boring colonial-style home deteriorates with age, it looks distinguishing. When a fantabulous, whimsical home deteriorates with age, it starts to look spooky.\" reply schneems 3 hours agoparent> When a fantabulous, whimsical home deteriorates with age, it starts to look spooky.\" That makes sense. Those abandoned theme parks with knock-off cartoon characters with smiles slowly peeling off are very unsettling. I hadn’t thought of it, but it makes sense that same principal applies to other grand displays. reply dkarl 4 hours agoprevThis article is way off base, warped by architectural déformation professionnelle. The association of Gothic architecture with eeriness dates back at least to Gothic fiction in the 18th and 19th centuries. 18th and 19th century readers devoured these popular prose depiction of Gothic horror. However, architects are obsessed with visual images, so the article quickly glosses over Gothic fiction and moves on to film depictions in the 20th century, even including a quote that implies the connection started with film, which is wrong by over a century. The article contains photos, movie posters, and embedded videos, but not a single quote from a single Gothic novel, even though readers first experienced Gothic horror through imagination stoked by words on the page. reply akamaka 4 hours agoparentI went looking for a quote that explicitly references gothic architectural details, and quickly found one in Edgar Allen Poe’s Fall of the House of Usher, from 1839. The room I came into was very large and high. The windows were high, and pointed at the top, and so far above the black floor that they were quite out of reach. Only a little light, red in color, made its way through the glass, and served to lighten the nearer and larger objects. My eyes, however, tried and failed to see into the far, high corners of the room. reply mmooss 29 minutes agoparentprevAn epistemological issue: Why shouldn't someone write about your comment, \"This ... is way off base\", just as you write it about the article? What makes your writing better? How could a reader know? I'll contribute to the answer: In the larger world, when it's serious about knowledge, the difference is evidence, primarily, and also expertise. In HN comments, how do we evaluate these different sources and claims ...? reply pavon 3 hours agoparentprevAlso, even if we are focusing purely on visuals, it is interesting that they didn't discuss the effect of these buildings becoming darker over time as the ornate details are hard to keep clean, which was exasperated by air pollution. I imagine a bright white marble building would have looked much more \"heavenly and transcendent\". reply ajmurmann 29 minutes agorootparentI went to the article expecting pollution was going to be the answer to how the \"became spooky\". I remember seeing a display at the cologne cathedral as a child that showed one of the new replacement parts before installation. I was shocked seeing how the replacement are a so much brighter color than the cathedral itself is now. If these buildings were brighter, I think it would be totally different. Especially the interior of the Sagrada Familia which is very bright and feels very positive is a good example here. reply chairhairair 3 hours agoprevI'm sure most readers here are using an adblocker. Try disabling it for this website. It's incredible. The content is difficult to see between all the various ad surfaces. My browser came to a screeching halt. reply consf 35 minutes agoparentIt’s amazing how much we rely on ad blockers to make websites usable without even realizing it reply Freak_NL 5 hours agoprevWhy is there a video called Margot Robbie Takes You Inside The Barbie Dreamhouse after three paragraphs? Is that nu-gothic architecture? Is this a glimpse of what the internet looks like without an ad-blocker? reply shrx 5 hours agoparentI have uBlock origin and it still showed me the video. I'm never visiting the website again. reply fsckboy 5 hours agorootparentI have uBlock Origin and uMatrix, didn't show me anything. (yes, I know it's no longer supported, but so far it still works great; probably too fussy for most, but makes me very happy) reply amelius 4 hours agorootparentprevI'm waiting for a Pi-Hole that is powerful enough to put in my HDMI connection and just filter out the ads using AI. reply bell-cot 5 hours agoparentprevI only see a couple ads for Architectural Digest itself - using just NoScript, and defaulting to distrust all 3rd-party js. reply stnderror 6 hours agoprevFor a different but related take on this, check the video game Blasphemous. It made me realise how dark the Baroque style and Catholic iconography can be when presented out of context. reply fmdragon 6 hours agoparentAs someone who grew up Catholic I'd say it's dark within context as well. reply jackcosgrove 1 hour agoparentprevThe Baroque style was supposed to lighten things up. Medieval art is really dark, especially depictions of hell and death, which were common. That subject reached its height with Hieronymus Bosch. reply musha68k 4 hours agoparentprevGreat indie series indeed. I'd just contend that the source material is already dark in context? If only to create contrast to heavenly transcendence? Bloodborne is another one that plays with surreal gothic verticality in 3D. reply jackcosgrove 1 hour agoprevI always thought gothic buildings were designed to look like forests from within. The Catholic paraphernalia like relics and candles are what's really spooky, but a well-lit gothic interior is not spooky to me. reply mmooss 27 minutes agoparenthttps://duckduckgo.com/?q=Sagrada+Fam%C3%ADlia+interior+pill... reply blueflow 6 hours agoprevDown the rabbithole you go: https://tvtropes.org/pmwiki/pmwiki.php/Main/GothicHorror reply bonthron 4 hours agoprevHorace Walpole's \"The Castle of Otranto\" is a ridiculously fun book. Very short, and stuffed with melodrama. My copy has an excellent introduction to Gothic architecture, literature, and politics by Nick Groom, which goes much deeper than this article. reply coldfoundry 6 hours agoprevhttps://archive.is/zPTuA reply codeflo 7 hours agoprevShowing a picture of Notre Dame photoshopped against unsettling clouds to make a point about the psychological effect of its architecture is borderline fraud. Any actual photo makes the building look a lot more majestic rather than scary: https://upload.wikimedia.org/wikipedia/commons/f/f7/Notre-Da... Also, I wonder to what extent this is an American perspective. Of course, American culture is omnipresent in Europe, so the association of Gothic buildings with horror movies has been hammered into our minds as well. But still, I don't think any European would look at Cologne Cathedral and be reminded of Ghostbusters of all things. I think unfamiliarity plays a role here. reply crazygringo 6 hours agoparentWhere's your evidence it's photoshopped? It's credited to \"Pete Douglass/Getty Images\" and Getty has a policy against photoshopped images. It's just a photo on a day and time with particularly dramatic clouds. There's no \"borderline fraud\" here. And of course it does have a lot to do with weather and lighting. Gothic horror is set in these environments at dusk and at night, in moonlight and in storms. Gothic horror doesn't generally utilize bright sunny days, so your photo isn't helping to illustrate the concept. A building can be simultaneously majestic and inspiring during a warm sunny day, and become spooky and creepy in low light amidst the fog and cold damp. reply a_e_k 31 minutes agorootparentMy first thought when I read the article was that that image must have been run through something like a contrast-limited adaptive histogram equalization (CLAHE) process. See here, for an example: https://imagemagick.org/script/clahe.php reply arethuza 7 hours agoparentprevI wonder if people think Milan cathedral also looks scary? reply agos 4 hours agorootparentthe Duomo is a weird kind of gothic, most notably missing the tall proportions of most gothic cathedrals. I've never seen it described as scary, but it has its creepy details, like the statue depicting San Bartholomew after being skinned, wearing his own skin. reply shermantanktop 4 hours agorootparentThat statue is a vivid memory for me ever since I saw it 30 years ago. reply adrian_b 3 hours agorootparentprevEven if I agree that Gothic architecture is the most appropriate setting for horror action, and I also agree with many of the arguments of the Italian Renaissance against what they have called as \"Gothic\", I still consider the great Gothic cathedrals as the most beautiful buildings that have ever been built. reply photochemsyn 4 hours agoprevThe article doesn't mention that death, especially childhood dead, was far more common in the medieval and Victorian European era than it is today. A couple with six children could expect half those children to die of infectious disease before reaching puberty, and there was also a significant probability of the mother dying due to pregnancy-related issues over that period. I'd assume Gothic architecture and religious design of the era reflects that grim aspect of life in that period, which is something relatively few families suffer today due to modern medicine. Looking back it's not surprising it seems spooky and dark. reply lo_zamoyski 4 hours agoprev> This forebear was uniform and symmetrical, regulated by harmony, ratios, and scale. In fact, each order of Greek design—Doric, Ionic, and Corinthian—was based on the human body, and therefore felt safe, approachable, and familiar. I think the corollary is interesting, which is the answer to this question: what does this say about modern architecture? Sterile, bleak, chaotic, unfriendly, hostile, alien, ugly, pretentious. Which is to say, while the gothic transcends (but benevolently includes) humanity and the natural order in the signified transcendence, much of modern architecture does the opposite. By contradicting the immanent and the human, it doesn't lead to transcendence, but dehumanization and vulgarization, mockery. So, while the classical respects the merely human, and the gothic includes the human and the natural and expands the horizon and domain within which they can be understood, modern architecture negates the human, reduces it, corrupts it, and ultimate hates it. Since art is mimetic, this could rightly be called demonic architecture. Where classical architecture is made in the image of the natural order, and where gothic architecture reflects the divine and the heavenly order (which includes the nature order, restored), modern architecture is the image of hell. > aesthetic theories generally classify the sublime as work that showcases greatness beyond measurement, comprehension, or experience; its magnitude is both awe-inspiring and terrifying. Which is the way in which God is described in the Christian tradition, hence \"loving fear\" or \"fear of God\". This fear arises from awe of something sublime in its power, beauty, goodness, truth, and magnificence. God is the most sublime, naturally, and you could expect that an encounter with the unmediated divine, if you were to survive it, would blow your mind and put you and everything else in a new perspective. In Scripture, angels--powerful, but finite--contrary to most Western art, are also described as \"terrifying\" when they make themselves known, but not in a malicious way (this famously occurs in the New Testament when Gabriel tells Mary not to fear him). I might also speculate about one reason why this transformation of the gothic from awe-inspiring to haunted and terrifying might have taken place from a psycho-theological point of view. Note that evil often involves mockery or inversion of the good. Evil as such is absence of the good, and thus absence of being. So, qua evil, it cannot do anything but appropriate the good. A cliche example might be the black mass, which mocks the Catholic mass. Pornography is another example rife with mockery and defilement (Al Goldstein's infamous words \"Christ sucks\" and \"Catholicism sucks\" is all I intend to quote here). Drugs still another, a kind of mock transcendental experience that involves not the authentic elevation or expansion of one's faculties of reason, but their corruption and diminishment. Another reason why the gothic may have become haunted at around the time of the Enlightenment has to do with how the beautiful is received by the beholder, that is, that it will depend on the mode of the beholder. You can see this perhaps most often in how a man sees or reacts to a beautiful woman. A man with a vicious and evil heart will dehumanize her in his mind and wish to use her for his selfish gratification; a prideful man with an insecure or guilty heart may hate her and project onto her faults and slander, scapegoating her for his own defects and inferiority; a man with bad intentions but an active enough conscience may become anxious around her as intention meets conscience; a man corrupted by a life of debauchery and a sordid past but beginning to see the light may be saddened by his impurity and his inability to relate to her fully like a human being. But the humble man of pure and good intentions receives beauty with joy, ease, and gratitude. So, here, the Enlightenment was a direct assault on the Church (as was the Protestant revolt before that). These cathedrals were now, in their eyes, like corpses, dead, relics of the past, and not only dead, but dead by the beholder's own hands (or his forefather's hands; the deed and the guilt now institutionalized and infused into the culture). A certain guilt or sorrow might haunt such a person. The haunting is in the beholder who is shut out of the beauty of the gothic by his own guilty conscience or the culture he was shaped by that resulted from the guilty consciences of his forefathers. Similar analyses have been done on the nature of the horror genre (e.g., \"Alien\" as an expression of horror and guilt in the wake of the sexual revolution, or \"Frankenstein\" as a sublimation of Shelley's guilt and painful past and the horrors of the Enlightenment worldview). reply bell-cot 5 hours agoprev> Though perhaps intimidating in their grandeur, they weren’t intended to inspire fear. “It was supposed to be positive, transcendent, and godly, not scary,” Dr. Bork explains. However, ... Worth noting - all that \"Godly\" Gothic architecture was built in an age when Christianity was the religion in Europe. And Christianity's #1 message-to-the-masses during that time amounted to \"Do exactly as you are told, or God will condemn you to the fires of Hell for all of eternity\". reply Barrin92 7 hours agoprev>Throughout the room were pictures of Cologne Cathedral, an 1880 church in Germany and one of Dr. Bork’s favorite buildings. The images, seemingly, caught the student’s attention. “Dr. Bork,” he said. “Why does it look so evil?” Having grown up in Cologne, it never seemed evil. As the article alludes to when pointing out the architectural differences in LOTR with the endorsement of Roman architecture for the \"good guys\" and the gothic architecture for Mordor, it's obviously an artifact of American culture. Fascination with America as a Roman empire offspring, very cartoonish ideas about the middle ages and a very saccharine offshoots of Christianity compared to continental Catholicism. It's sort of like asking \"why does British sound evil?\" Because the studios made all the evil geniuses British (or sometimes German or Russian). reply arethuza 7 hours agoparentHaving visited Cologne for the first time about 35 years ago while inter-railing I was completely in awe of the building - I am a atheist but my impression was very much \"The people who built this really believed\". I was so impressed that I purchased a number of architectural drawings that I still have on the walls of our house! reply pjmlp 5 hours agorootparentIt was more like not believing wasn't an option to express publicly in a feudal society partially managed from Rome, in the country that became the extension of the Roman empire after the fall. reply teractiveodular 4 hours agoparentprevDescribing LOTR as \"obviously an artifact of American culture\" is a bit odd: it was written by a Brit and directed by a New Zealander. reply graemep 6 hours agoparentprevIt seems an odd reaction and not entirely explained by American culture - most gothic buildings in Europe attract tourists, including lots of Americans, who visit them because they find the beautiful. I have not heard that reaction from any American i know, nor from other people from multiple cultures (who all watch American media, of course!). Gothic does convey a sense of age, which helps with spooky, but feeling an association with evil sounds like an very individual reaction. reply marssaxman 3 hours agorootparentAmerica even has a couple of its own gothic cathedrals: St. John the Divine, in New York, is a particularly awe-inspiring bit of architecture. reply shermantanktop 4 hours agoparentprevIf you’d like to experience the reverse effect, look around at how the American Wild West has been depicted in Europe. It’s a fantastical, cartoonish view of a period which is already fetishized in the US but when taken out of context it becomes (to my American eyes) bizarre. This may be fading, because it clearly originated in 1940s and 50s Westerns from Hollywood. But whenever I’ve encountered it I’ve felt like I’m looking into a funhouse mirror. reply paxys 5 hours agoprevZero mention of gargoyles in an entire article about gothic architecture and horror? reply prmoustache 3 hours agoparentThat was my first reaction too. Gargoyles are here to inspire fear. Associate that to pointy stuff and yes a building becomes less welcoming. reply chromanoid 4 hours agoparentprevYeah, I was wondering too. I mean those are meant to look scary. reply AdmiralAsshat 4 hours agorootparentApotropaic architecture has a long history before Gothic architecture, though. See: the Gorgons on the Temple of Artemis at Corfu: https://upload.wikimedia.org/wikipedia/commons/8/8c/Gorgon_a... reply tetris11 7 hours agoprevThe article didn't really say anything you wouldnt guess yourself: repeated association in cinema. It does hint at a book that maybe just maybe started the association (Castle of Otranto) from someone who slept in a Gothic revived house, but really doesn't tie the book or cinema together and they could have been independent events. I think the conclusion is: try sleeping in one, they're inherently scary, which I feel is a weak takeaway. reply DeathArrow 7 hours agoparent>The article didn't really say anything you wouldnt guess yourself: repeated association in cinema. That assertion is easy to check. Go in the Amazonian jungle, find a person who never saw western buildings and show him a picture of a gothic building and one of a neoclassical building. Ask him which one looks scary and which one doesn't. reply Bjartr 7 hours agoparentprevIt did offer the idea that the strength of the association is boosted by the architects' intent to evoke a feeling of the supernatural or unearthly. That I wouldn't have guessed. reply blueflow 6 hours agoparentprev> repeated association in cinema. These things are called \"tropes\", they are a form of fiction and there is a whole wiki dedicated to them: https://tvtropes.org/pmwiki/pmwiki.php/Main/GothicHorror reply graemep 6 hours agorootparentI think the page you link to explains ti very well: its a combination of the existence of Gothic ruins, a negative view of the Middle Ages, and the association with the Catholic church in the context of anti-Catholic prejudice in Britain (and other Anglophone countries). reply Mistletoe 7 hours agoparentprevI think there is more to it than the cinema association. I think the Gothic era architects went too far in associating it with a higher authority and power until it was oppressive and scary. Even the google AI result hints at it. >The Gothic architectural style was initially met with derision and contempt by some who wanted to revive the Grecian orders of architecture. The term \"Gothic\" was used to describe the style as barbarous and rude, and was attributed to the Gothic tribes who destroyed the Roman Empire in the 5th century AD. And form was following function. The church from the 12th century to the 16th century was something to be very afraid of. The Inquisition started in the 12th century. reply mannykannot 6 hours agorootparentI tend to agree - not only the inquisition (which I tend to associate more with Romanesque) but the apparent preoccupation with death, damnation, martyrdom and relics (though I realize this is probably a simplistic view coming from my ignorance.) Oddly, I don’t get these vibes when I am actually visiting one of these buildings. reply skylurk 7 hours agoprevI know I've been on HN too long when I prefix \"How\" to titles automatically. reply xanderlewis 5 hours agoparentJust waiting for someone to post To Kill a Mockingbird. reply doener 6 hours agoprev [–] I really hate it that HN automatically deletes words like \"How\" in titles. reply andrelaszlo 6 hours agoparent\"Became\" doesn't add much -> \"Gothic architecture spooky\" \"Gothic architecture\" and \"spooky\" is basically synonymous -> \"Spooky!\" Why use word when emoji do trick? -> U+1F47B reply bluedino 5 hours agoparentprevCould be worse. At one point SomethingAwful would ban/probate you if you made a thread where the subject started with the word \"So\". reply seanw444 3 hours agorootparentGlad to hear I'm not the only one with that pet peeve. It's the paragraph-starting equivalent to sprinkling in \"like\" everywhere in spoken language. reply whamlastxmas 4 hours agorootparentprevOr chose the hot tag reply vincvinc 6 hours agoparentprev [–] Usually it’s a good move for articles but for this title, it’s a bit distortive to the point of HN selfparody reply elpocko 5 hours agorootparentThinking that you can just edit any title by applying a regex is a sign of hubris, doing it automatically and silently is an arrogant affront. Not to mention it contradicts HN's own guideline that says you should keep original titles intact. It's a title mutilator. reply brettermeier 6 hours agorootparentprev [–] Do you have examples where it's good to cut out \"how\" from the title? I can't believe that it's helpful. reply gostsamo 6 hours agorootparent [–] This is intended to hobble clickbite titles and not to help anyone else. Not always ideal, but I actually like it for the most part. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gothic architecture, originally designed to be heavenly, is now often associated with spookiness due to its frequent use in horror media.- Emerging in the 12th century, it features pointed arches, flying buttresses, and tall spires, initially symbolizing the superhuman but later seen as chaotic during the Renaissance.- The 18th-century Gothic Revival, influenced by Horace Walpole and Edmund Burke, solidified its eerie reputation, and today, filmmakers use its elements to enhance themes of terror."
    ],
    "commentSummary": [
      "Gothic architecture is linked to spookiness due to its frequent use in Gothic fiction and horror films, as well as its ornate, pointed style and religious associations.",
      "In the Gilded Age, Neo-Gothic mansions built by wealthy Americans became abandoned, enhancing their eerie allure and contributing to their spooky reputation.",
      "The portrayal of abandoned mental hospitals in horror media further cemented the Gothic style's association with horror and the supernatural."
    ],
    "points": 138,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1730112799
  },
  {
    "id": 41967734,
    "title": "Mill: A fast JVM build tool for Java and Scala",
    "originLink": "https://mill-build.org/",
    "originBody": "Mill: A Fast JVM Build Tool bar foo foo.sources foo.compile foo.classPath foo.assembly bar.compile bar.classPath foo.resources bar.assembly bar.sources bar.resources Mill is a fast, scalable, multi-language build tool that supports Java, Scala, and Kotlin. Although the Java compiler is fast and the Java language is easy, JVM build tools have a reputation for being sluggish and confusing. Mill aims to let your build system take full advantage of the JVM’s performance and usability: Mill can build the same Java codebase 5-10x faster than Maven, or 2-4x faster than Gradle Mill’s typed config language and immutable task graph helps keep builds clean and understandable Mill scales well from small single-module projects to large monorepos with hundreds of modules Mill achieves this via the following: Performance: Mill’s build graph automatically caches and parallelizes build tasks, keeping your workflows fast and responsive. Mill adds minimal overhead over the logic necessary to build your project, while providing tools to let you identify and resolve bottlenecks in your build Maintainability: Mill goes beyond YAML and Bash, with config and custom logic written in concise type-checked code, and an immutable module tree and task graph. This catches config issues early, and helps IDEs (IntelliJ or VSCode) understand your Mill build better than any other build system Flexibility: Mill’s tasks and modules allow anything from adding simple build steps, up to entire language toolchains. You can import any JVM library in your build, use Mill’s rich ecosystem of Third-Party Mill Plugins, or write plugins yourself and publish them to Maven Central for others to use. To begin using Mill, check out the introductory documentation for each language: Building Java Projects with Mill Building Scala Projects with Mill (Experimental) Kotlin with Mill Mill is used to build many real-world projects, such as the C3P0 JDBC Connection Pool, Coursier JVM dependency resolver, Ammonite REPL, and the SpinalHDL and Chisel hardware design frameworks. Mill can be used for applications built on top of common JVM frameworks like Spring Boot or Micronaut. Mill borrows ideas from other tools like Maven, Gradle, Bazel, but tries to learn from the strengths of each tool and improve on their weaknesses. For comparisons with existing build tools, check out these pages: Mill vs Maven Mill vs Gradle Mill vs SBT If you’re interested in the fundamental ideas behind Mill, rather than the user-facing benefits discussed above, check out the page on Mill Design Principles. Building Java Projects with Mill",
    "commentLink": "https://news.ycombinator.com/item?id=41967734",
    "commentBody": "Mill: A fast JVM build tool for Java and Scala (mill-build.org)125 points by 0x54MUR41 15 hours agohidepastfavorite104 comments carrotsalad 2 hours agoMill looks interesting, but, _from a Java development perspective_, it has the same fundamental challenge as Gradle (and most other build systems), which is that its config language _is something other than Java_. That means there's a significant cognitive burden to understand and manage something that one hopes to not have to think about very often. I find that the pain I experience with Gradle isn't usually about how to do something clever or customized etc, but instead it's when I haven't thought about Gradle syntax in the last 3 months since everything has been silently working, but now I need to figure out some small thing, and that means I need to go re-learn basic Gradle stuff - whether it's groovy, Kotlin, or some aspect of the build DSL - since my mind has unloaded everything about Gradle in the meantime. Simplifying the semantic complexity of a general purpose build system will always help, but the most useful thing for me would be if the configuration for a Java build were to natively use the Java language directly. reply mike_hearn 35 minutes agoparentNot to defend Gradle too much, but Groovy is a superset of Java. So if you want, you can just use the regular Groovy dialect and then write Java in your build scripts, it should work. This is not entirely a solution though, because Gradle's APIs are fairly complicated and change regularly. reply jackcviers3 1 hour agoparentprevIt's intended as a replacement for _scala_ builds. Having a build definition in the native language that doesn't require a different syntax (like a declarative syntax such as maven xml or toml) makes task customization easier for the maintainer of a given project. Unfortunately, it also means that you have to know the language and read the documentation for the build system. If you want something declarative, there's also bleep[1] in the scala ecosystem. And for single module builds there's scala-cli[2]. It's also possible to use gradle and maven for scala projects, but for an java-only shop I wouldn't be using mill or bleep because there's no need to introduce a new language just to manage the build. For scala/java/kotlin hybrid projects though, gradle or mill or sbt would be my recommended tool because of how tightly they are coupled with the cross-platform build matrix nature of scala library and build system plugin ecosystems. For larger builds, it's mill or bazel because there s a performance cliff in sbt and gradle, and bleep is too new to have all the standard plugins ported. We use mill at writer. 1. https://bleep.build/docs/ 2. https://scala-cli.virtuslab.org/ reply carrotsalad 1 hour agorootparent> It's intended as a replacement for _scala_ builds. Having a build definition in the native language [...] makes task customization easier for the maintainer Totally agree! But the title of the post says \"Mill: A fast JVM build tool for Java and Scala\" :) - it certainly looks like better tool for the Scala community. For projects that are primarily building Java sources, it'd be nice to have a build system that uses Java code to describe the build. I don't think this exists at the moment. reply crznp 41 minutes agorootparentOne option is `bld`. They added IntelliJ support since I looked at it last, so that's nice. https://github.com/rife2/bld reply beeboobaa3 2 hours agoparentprevMy problem with gradle is that its configuration language is a programming language. Sounds amazing in practice. And it is. Until you need to fix a 3 year old build that has some insane wizardry going on. reply mdaniel 1 hour agorootparent> Until you need to fix a 3 year old build that has some insane wizardry going on. My experience with Gradle is that it's the \"3 year old build\" that is almost certainly a death knell more than the insane wizardry part. My experience: git clone .../ancient-codebase.git cd ancient-codebase ./gradlew # &2 exit 1 Contrast that with https://github.com/apache/maven-app-engine (just to pick on something sorted by earliest push date, some 10 years ago): $ git clone https://github.com/apache/maven-app-engine.git $ cd maven-app-engine $ mvn -B compile [INFO] ------------------------------------------------------------- [ERROR] COMPILATION ERROR : [INFO] ------------------------------------------------------------- [ERROR] error: Source option 6 is no longer supported. Use 8 or later. [ERROR] error: Target option 6 is no longer supported. Use 8 or later. [INFO] 2 errors $ echo \"Java gonna Java\" $ git grep -n source.*6 pom.xml:133: 1.6 $ sed -i.bak -e 's/1.6/1.8/g' pom.xml $ mvn -B compile [INFO] BUILD SUCCESS reply brabel 1 hour agorootparentI dislike Gradle as much as you probably do, but between Maven and Gradle, the one that \"vomits\" stuff on the command line is definitely Maven. Gradle errs by going too far to the other end: it just doesn't log anything at all, even the tasks that are actually being run (vs skipped... do you know how to get Gradle to show them?? It's `gradle --console=plain`, so obvious!! Why would anyone complain about that, right?!) or the print outs you add to the build to try to understand what the heck is going on. reply dkarl 1 hour agorootparentprevHaving worked with Maven and Gradle, I'd say Gradle was worse in the average case, but better in the worst case. There are way more Gradle projects with unnecessary custom build code because Gradle makes it easy to do. On the other hand, when builds are specified in a limited-power build config language, like POM, then when someone needs to do something custom, they have to extend or modify the build tool itself, which in my experience causes way more pain than custom code in a build file. Custom logic in Maven means building and publishing an extension; it can't be local to the project. You may encounter projects that depend on extensions from long-lost open source projects, or long-lost internal projects. On one occasion, I was lucky to find a source jar for the extension in the Maven repository. It can be a nightmare. The same could happen with Gradle, since a build can depend on arbitrary libraries, but I never saw it in the wild. People depended on major open-source extensions and added their own custom code inside the build. reply cyberax 23 minutes agorootparent> it can't be local to the project It certainly can be, in the same repository. reply lihaoyi 7 hours agoprevAuthor here! Hope you take a look at the project and find it cool. There's a lot of interesting stuff here. In particular, the Video linked on the landing page is a great intros from a Java developer point of view, and the following video is a great intro from a Build Tool Architect point of view: * https://www.youtube.com/watch?v=UsXgCeU-ovI While Mill is focusing on JVM for now, it is very extensible and I have a strawman demo of adding a Javascript toolchain in ~100 lines of code https://mill-build.org/mill/0.12.1/extending/new-language.ht... For those of you who want to learn more about the design principles and architecture of Mill, and what makes it unique, you should check out the page on Design Principles which has links to videos and blog posts where I elaborate on what exactly makes Mill so different from Maven, Gradle, SBT, Bazel, and so on: * Mill Design Principles https://mill-build.org/mill/0.12.1/depth/design-principles.h... I've mentioned this in a few places, but the comparisons with other build tools are best-effort. I have no doubt they can be made more accurate, and welcome feedback so I can go back and refine them. Please take them with a grain of salt I'm also trying to get the community involved, so it's not just me writing code and running the show. To that end, I have set up a bounty program, so pay out significant sums of money (500-2000USD a piece) for people who make non-trivial contributions. It's already paid out about 10kUSD and has another 20kUSD on the table, so if anyone wants to get involved and make a little cash, feel free to take a shot at one of the bounties! https://github.com/orgs/com-lihaoyi/discussions/6 reply jitl 5 hours agoparentHow possible is it to make your tool \"zero-config\" by default? I see a lot of comments in this thread and elsewhere on twitter asking for essentially `go build`, `go fmt`, `go test` for Java/JVM. I think the language has quite strong convention around directory layout and file naming already, so do you think it would be possible for mill or a mill wrapper to offer the same kind of standardized zero config workflow? I think a JVM tool that gets that right - takes it as far as possible to the golang model - would have a lot of happy users. reply hocuspocus 1 hour agorootparentScala CLI has replaced the default runner since Scala 3.5, so you can effectively do `scala run`, `scala fmt`, and so on. On the Java side, I believe JBang provides a very similar developer experience. Fundamentally it's hard to reconcile both worlds though. Building non-trivial multi-module projects on the JVM is inherently complex especially when you throw in multiple build targets, multiple toolchains, multiple platforms... With simpler build tools (like in Go or Rust) you shift this complexity elsewhere, typically in a Makefile and/or a Docker/OCI based build pipeline, and these can get pretty complex too. Let alone distributed build tools like Bazel. - https://scala-cli.virtuslab.org - https://www.jbang.dev reply vvillena 1 hour agorootparentprevThere's scala-cli, which has become the default Scala run command since Scala 3.5 but is also available separately. It has all those bells and whistles and allows scripts to grow organically. And no matter the name, it handles Java code too. With scala-cli, there's not even a need to download a Java runtime or a language distribution. You can let the runner do its thing, or pass options to choose the JVM and the language version to use, or even write those options into special headers in the code files. You can also write tests, format code... it's all built-in. And in cases the code outgrows the tool and there's a need to migrate to a different build tool, there's even a feature to export the build to Sbt or Mill. reply iainmerrick 6 hours agoparentprevI’d be interested to read a comparison with Bazel (which you already mention as one of the influences). For somebody looking to escape from Gradle, Bazel seems like one of the most promising alternatives, as it’s built on sane and sound fundamentals. Although in practice it has plenty of rough edges and annoyances, so maybe there are areas where Mill can do better. reply Axnyff 4 hours agoparentprevHi, it looks pretty interesting! There's a broken link in the homepage though, Mill vs sbt links to the gradle page Good luck for your project! reply philipwhiuk 7 hours agoparentprevThe current version is 0.12.1. What's required for v1.0? reply lihaoyi 6 hours agorootparentTraditionally I've labelled my OSS projects 1.0 when they've stabilized and the rate of change has greatly reduced. Right now Mill is not there yet, but maybe if at end-2025 we realize no breaking changes have been needed since end-2024, we can call it 1.0 reply tenaf0 5 hours agorootparentJust a tiny notice, the github page, nor the website seem to currently contain an “installation” link. The one found by google returns a ‘page not found’ for the current version. reply wiradikusuma 3 hours agoparentprevDoes it support Quarkus (esp. native build)? reply hocuspocus 2 hours agorootparentThere is no reason it would not: https://github.com/alexarchambault/mill-native-image reply thefaux 22 minutes agoprevThe last time I checked, sbt was much faster than mill for incremental builds. Mill has a faster cold startup time, but sbt uses classloader tricks to reuse jitted classes so that it doesn't have to reload the scala standard library. When running tests continuously and rerunning on save, sbt was much faster than mill for equivalent projects. I haven't tested in three years or so though. But I would encourage people to make a simple project in sbt and mill and run `sbt ~test` and compare it to `mill -w test`. In the past, I found that after a few iterations, sbt could respond to changes in a few hundred milliseconds while mill would take multiple seconds to retest the same code. That difference really adds up when you are iterating on a problem. That said, I have come to believe that the jvm is a bad platform for a build tool. Everything that touches the jvm becomes bloated and slow, particularly for startup. I no longer write scala because of my frustration with the bloat (and scala adds its own bloat on top of the jvm). reply weego 2 minutes agoparentsbt is one of the worst engineering mistakes I've ever witnessed. It was a constant source of esoteric ergonomics and frustration for no clear reason other than being the pet project of someone who really loved implicits. reply sireat 7 hours agoprevJust a note that the author Li Haoyi is a fantastic contributor to Scala community. He has written multiple useful libraries. Out of many JSON libraries, his one was the most intuitive and practial. His book is excellent too. I bought it when it came out. It is worthy of a plug: https://www.handsonscala.com/ I miss working on Scala projects. Sadly I rarely see new ones these days. Does IntelliJ plugin finally work on Scala 3? About 2 years ago it was half broken. reply mrudolph22 2 hours agoprevI gave Mill a try earlier this year. My hope was to escape the nightmare that is Gradle, which I've been using for many years. Mill sounds great in theory (except for the Scala DSL). Unfortunately, I couldn't get a basic Java build to work in half a day, even though I have (admittedly rusty) working knowledge of Scala. It was one obscure error after another. My conclusion was that Java support isn't ready. There was also very little documentation on how to build Java. In my opinion, using a GPL as the build language of a polyglot build tool is a dead end, both for technical/usability reasons and because the ensuing language wars can't be won. I'm looking forward to the day when a build tool embraces a modern config language such as CUE or Pkl. reply PaulHoule 2 hours agoprevSpeed wins for dev tools. I had worked out that math for “like pip but actually works” but few people were conscious that pip didn’t quite work reliably for large and complex projects — I didn’t think it was possible to sell it. Uv won hearts and minds because it was uncompromisingly fast: people did not really care that it had a correct resolving algorithim or that is was really reliable because it is not written in Python and thus can’t trash it’s own dependencies (maybe a solvable problem in that the build tool can have its own virtualenv but isn’t it nice to for your package manager to be a binary that can’t get dependencies screwed up no matter how hard the users try?) reply spuz 10 hours agoprevA build tool that is not only fast but configured in a type safe way sounds great. I really like this quote from the \"Why use scala\" part of the documentation: > Most developers using a build tool are not build tool experts, and have no desire to become build tool experts. They will forever be cargo-culting examples they find online, copy-pasting from other parts of the codebase, or blindly fumbling their customizations. It is in this context that Mill’s static typing really shines: what such \"perpetual beginners\" need most is help understanding/navigating the build logic, and help checking their proposed changes for dumb mistakes. And there will be dumb mistakes, because most people are not and will never be build-tool experts or enthusiasts reply cryptos 8 hours agoprevThe comparision with Gradle is not up to date. There is stated that you would end up in an untyped mess of Groovy build files, but statically typed Kotlin files are the default for quite some time now in Gradle! https://mill-build.org/mill/0.12.1/comparisons/gradle.html reply brabel 1 hour agoparentI never got why people thought Kotlin would help Gradle. It absolutely doesn't. Groovy was never the problem (Groovy has types, always had, you could use them if you wanted). Think about it: what do you do with a build tool? You write a little recipe, then you run it. Does that remind something? Yes, it reminds scripts, like bash scripts you run all the time in your terminal. And why are scripts almost universally written without types... and no typed alternative, of which there are many, has caught on? Because if you're just going to modify a script and immediately run it, while keeping it short enough so you can know what it does without reading a book, how does adding types help you? Quite to the contrary, scripts (including build scripts) should be small, and having types all over the place make it far more verbose than it should be, likely pushing it out of your comfortable local memory in your brain, at which point you need something akin to a \"real\" programming language and a compiled program, not a script. Larger programs benefit from types because you don't just run the program, make changes, and run them again, like you do with scripts. You write them, test them, compile them, package them and finally you distribute them to your users who hopefully only need to configure them, not modify their internals. If your build is that complex, that's exactly what you should be doing instead of trying to shoehorn types into your scripts and expecting them to look like real programs. Also, the Kotlin DSL just doesn't assist in the most problematic aspect of Gradle: its total lack of discoverability. Try doing something on your Kotlin Gradle file using a plugin you're not familiar with (which is all of them for most of us). It's completely impossible unless you know the DSL of the plugin, just like it was the case with Groovy... Once you know the DSL, it's fairly easy, but even in Groovy you will get auto-completion once you've got to the DSL \"entry point\", no need for Kotlin. I've been saying this since before they introduced the Kotlin DSL, and now i feel completely vindicated. I've never met anyone who told me \"Gradle is so much easier now with Kotlin\". But it did mess up plugins I wrote in Kotlin as now Gradle has a dependency on a very particular version of the Kotlin compiler, and God help you if your plugin was written with a different version in mind. reply lihaoyi 7 hours agoparentprevAuthor here. Unfortunately this is because my own experience with Gradle is not up to date; I've only lived in the Gradle Groovy world! If anyone is interested in helping out, I have a 1500USD bounty on porting a gradle.kts build to Mill, so we can do a fair up-to-date comparison https://github.com/com-lihaoyi/mill/issues/3670 reply mdaniel 2 hours agorootparentI believe you have influence over the syntax highlighting on GitHub of .mill files by informing it they're actually Scala, which would make reading those files much nicer IMHO: https://github.com/github-linguist/linguist/blob/v8.0.1/docs... Or, I believe you can submit a PR to linguist to make it globally registered: https://github.com/github-linguist/linguist/blob/v8.0.1/CONT... reply imtringued 1 hour agorootparentprevYou can maintain your competitive advantage over gradle by not constantly breaking backwards compatiblity, by the way. reply iamcalledrob 9 hours agoprevIt's not clear to me how this is better than Gradle. And I hate Gradle. At first glance, Mill looks like it has many of the pitfalls of Gradle: - Plugins: Creates the temptation to rely on plugins for everything, and suddenly you're in plugin dependency hell with no idea how anything actually works. - Build scripts written in a DSL on top of a new language: Now I have to learn Scala and your DSL. I don't want to do either! - Build scripts written in a language that can be used for code too: Versioning hell when the compiler for the build system needs to be a different version to the compiler for the actual project code. See: Gradle and Kotlin reply lihaoyi 7 hours agoparentAuthor here! The issue here is that builds, and many other \"just configuration\" scenarios, are fundamentally complex. So many projects that start off as \"just XML\" or \"just YAML\" end up implementing their own half-baked programming language interepreter inside of their XML/YAML/JSON/whatever. Examples: * Github Actions Config Expressions https://docs.github.com/en/actions/writing-workflows/choosin... * CloudFormation Functions https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGui... * Helm Chart Templates https://helm.sh/docs/chart_best_practices/templates/ There is a reason why Bazel went with Python/Starlark, why Pulumi and CDK and friends are getting popular. Fundamentally, many of these use cases look surprisingly like programming languages: maybe not immediately, but certainly after you've dug in a bit. And having a properly designed purpose-build programming language (e.g. StarLark) or a flexible general purpose language (e.g. Typescript, Kotlin, Scala) does turn out to be the least-bad option reply skybrian 3 hours agorootparentI agree that Bazel did pretty well with Starlark, but the reason that’s sane is because it’s not Python, though the syntax is similar. It avoids getting into trouble with people using Python language features that would result in upgrade hell and annoy other programmers who aren’t Python experts. (Though, debugging complicated Starlark code can still be difficult.) So why not use Starlark? :) reply mrudolph22 2 hours agorootparentJust wanted to mention that there are much better config languages than Starlark by now: CUE, Pkl, etc. reply vamega 1 hour agorootparentWhy do you call these other languages “better”? They’re different, but I’m not sure why either of the one’s you mentioned would be better for this use case. reply mrudolph22 1 hour agorootparentModern config languages offer strong validation and advanced IDE support, which is essential for a great user experience. https://pkl-lang.org/intellij/current/highlights.html reply skybrian 2 hours agorootparentprevI was going to mention Cue, but I’ve only read about it, not used it, and couldn’t actually say whether it’s better. reply mrudolph22 54 minutes agorootparentI'm afraid that no current config language is an obvious fit for Mill. That's because Mill is fully reactive and doesn't distinguish between build configuration and execution by design. reply ackfoobar 1 hour agorootparentprev> end up implementing their own half-baked programming language interpreter inside of their XML Greenspun's tenth rule. reply fabioz 8 hours agoparentprevThe first advantage the homepage lists is: > Mill can build the same Java codebase 5-10x faster than Maven, or 2-4x faster than Gradle Speed per se can be a good selling point (having to wait for slow builds is really annoying). I can't really comment on anything else though as I just stumbled upon it here in HN ;) reply iainmerrick 8 hours agorootparentThe goal should be more like 50x faster than Gradle. Gradle is ludicrously slow (at least in every single Gradle project I’ve had to work with). reply kaba0 7 hours agorootparentFirst invocation may be. Subsequent builds are very fast, unless someone decided to write random bullshit into the build scripts that execute at config time, making the config process impure. reply iainmerrick 6 hours agorootparentI’m mostly thinking of Android projects. If I have time I’ll try some speed tests with a new basic project. But I don’t think I’ve even once done something in Android Studio and thought “huh, that was surprisingly fast”. Maybe some of the hot reloading stuff is okay (when it actually works). reply ktosobcy 2 hours agorootparentprevAFAIR author made quite unfair comparison with simple compile vs full maven build (that executes a lot of additional stuff) reply kaba0 7 hours agoparentprevThere is basically no DSL. You simply write what a build needs, e.g. you write a function `collectCFiles()` that collects every file with extension `.c`. You then issue a command like `gcc ${collectCFiles()}`. And pretty much that’s it - you can use shell commands, or do anything in scala (or java or whathaveyou). You simply have your functions return either a value (e.g. a checksum) or a location, which is the only mill-specific logic. So your compileC() function will simply invoke your collectCFiles() function, and this invocation implicitly creates a dependency between these tasks. You have written literally the simplest way to describe your build logic. But in the background mill will cache your functions’ inputs outputs and parallelize those that need re-run, which is what a build tool should do. The implementation may not be the theoretical best, but I think the idea is pretty much the perfect build system out there. reply potamic 9 hours agoprevWhat tends to be complex about build requirements that necessitates special purpose tools? Golang seems to be doing fine with just go build and go test. What else are people doing with gradle/maven that requires static typing, DAGs, plugins etc.? reply cyberax 6 minutes agoparentTry to build a Go project that uses Cgo and non-trivial C/C++ libraries. Throw in cross-compilation for more fun. You'll end up with an external build system that invokes Go build as one of the steps. Go projects normally just tend to be self-contained server-like software that doesn't need a lot of external libraries. But once you step away from that, you're on your own. I guess my problem with Gradle is that app building should be way simpler than it is. Apps are not something niche anymore, but the tooling is still similar to the embedded software for microcontrollers. reply lihaoyi 7 hours agoparentprevAuthor here! `go build` and `go test` do work, at limited scale and complexity. In Scala there's Scala-CLI which is excellent. If they work for you, you probably aren't the target market for these build tools. Once you start layering on bash scripts, layering on make, layering on Python scripts, layering on manual steps written down in a readme.md somewhere, that's the time when you should consider a proper build tool. And if that has never happened to you in your career, count your blessings :) Why not just write some boring, pure code to handle the build? Why not write my build system in vanilla LYAH Haskell? It turns out that builds do have some specific requirements that most programs do not need to care about: caching, parallelization, introspection, and so on. Check out the following blog/talk for more details: * Blog Post: Build Tools as Pure Functional Programs https://www.lihaoyi.com/post/BuildToolsasPureFunctionalProgr... * Video: Mill: a Build Tool based on Pure Functional Programming https://www.youtube.com/watch?v=j6uThGxx-18&list=PLBqWQH1Miw... Thus \"naively\" building your project \"directly with code\" ends up not working, so you do need some additional support. While most build tools end up constructing a complete bespoke programming environment from scratch, Mill tries to leverage the Scala language and JVM as much as possible, so you can re-use all your expertise and tooling (e.g. IntelliJ, VSCode, Maven Central, etc.) almost verbatim while getting all the necessary build-tool stuff (parallelism, caching, introspection) for free. Check out those two links if you want to learn more! reply rykad 9 hours agoparentprevTo be blunt, nothing. The issue is that most people in jvm land are on a closed bubble and haven't seen anything else. This is true for build systems as is for non OO design for example. Most simply don't know better and the rest of us are simply stuck. Ant and then Maven started simple enough but people always find a way to justify adding more stuff. Gradle already started complex enough and they keep adding more stuff... reply whartung 1 hour agorootparentThe big thing is that many Java builds are not just blobs of binaries crammed together, but also have structure and metadata, sometimes generated on the fly. Not all Java builds are simply compiles. There are several projects that rely on processing steps during the Java build. EAR files are jars within jars. Then, of course, there's all of the dependencies. The modern Maven based repository based dependency manager is a blessing and a curse. Drag and dropping an artifact into your project that inevitably downloads the entirety of the internet. Now you may wish to cull your dependency tree, so that needs to be expressible as well. The primary benefit of Maven and the pom.xml file is that for a vast majority of applications it just work. Even better, its become a universal \"project\" format that many IDEs directly support. It well handles \"dependency hell\" in a cross tool way. I wish Maven were a bit faster, but, simply, it's as fast as it can be for what it does. A good Ant build just flies, but Ant \"doesn't do anything\". It's just a bag of steps that it follows (for good and ill), in contrast to Mavens declarative style (for good and ill). I have no experience with Gradle other than I've never run into enough problems with Maven to justify trying something else. On its surface, it doesn't really appeal to me. I was comfortable with Ant (I have no problem with XML), I'm mostly comfortable with Maven. I've not been unhappy enough with Maven to try and jump back to Ant w/Ivy. reply cryptos 8 hours agorootparentprevYou have to keep in mind that Gradle Inc. earns money by providing consulting for complex builds. An easy build tool would destroy this business model ;-) reply mrudolph22 31 minutes agorootparentThey transitioned to a product company 5+ years ago. https://gradle.com Gradle's complexity comes from at least two places: 1. The original vision of solving complex multi-technology/language Enterprise builds. 2. Poor early design decisions that they never recovered from. reply kaba0 7 hours agorootparentprevTo be blunt, if anything it might be you who live in a closed bubble. Builds that require ad-hoc functionality is the default. It’s extremely rare that everything fits nicely into “cargo build” or other single language build tools’ model. And while these often have escape hatches, at that point you have to write imperative code with no caching and parallelization that is literally the job of a build tool. reply rykad 4 hours agorootparentI've been doing jvm apps for almost 20yrs... What builds need to do and what people made the builds do are completely different things. I don't remember a single project I was involved in that could not had had a simpler build... reply pkolaczk 3 hours agorootparentprev> It’s extremely rare that everything fits nicely into “cargo build” 161538 crates do not agree with you ;) reply kaba0 1 hour agorootparentWhich are mostly small, isolated library code, whose purpose is to be easily incorporated into larger programs. That’s the 90% easy path of build tools. What about a large project built over 6 years by 50 people, and that has to use some obscure technology to communicate with company A, and another one that has an idiotic build step? reply zem 18 minutes agoparentprevI recommend the \"build systems a la carte\" paper for a good overview of the various problems build systems address reply dikei 8 hours agoparentprevIn JVM world, the de factor equivalent to `go build` and `go test` are `mvn compile` and `mvn test`, which works 99% percent of the time. Other build tools and plugins just compete/fill in for: * improved build speed / test speed: using background daemon to reduce strtup speed, intelligent caching / task reordering to avoid redoing, etc.. * extra functionalities like code generation, publishing or deployments. As code generation is really big in JVM world, and there are many ways to deploy an application: jar + libs in a zip file, uber jars, container image, etc... reply dcminter 3 hours agorootparentCurmudgeon here: this was true for a relatively brief period of time. Nowadays I'd say that gradle has (inexplicably to me) taken the lead - and everyone adds custom crap to their gradle build making them far less predictable than maven builds used to be. I guess it's better than the nightmare over in the front-enders' world... reply pkolaczk 2 hours agorootparentprevMy typical mvn session after a month of not touching maven: % mvn [ERROR] No goals have been specified for this build. Uh. % mvn build [ERROR] Unknown lifecycle phase \"build\". Uh, nope, that wasn't it.... % mvn compile BUILD SUCCESS Now trying to run the app... Error: app jar not found. Reading the README.md. Aha! So I need to install it! % mvn install 16:59:35,075 [INFO] Building [1/32] ... 16:59:38,483 [INFO] ------------------------------------------------------- 16:59:38,483 [INFO] T E S T S 16:59:38,483 [INFO] ------------------------------------------------------- ^C // me searching on google how to not run tests % mvn install -DskipTests=true // now good... Ok, let's run some tests. The FlakyTest broke again in CI. Let me run it locally: % mvn test FlakyTest 17:02:19,481 [ERROR] Unknown lifecycle phase \"FlakyTest\". Aaargh, ok, googling it again: % mvn test -Dtest=FlakyTest 17:03:16,102 [ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.3.0:test (default-test) on project blah blah: No tests matching pattern \"FlakyTest\" were executed! (Set -Dsurefire.failIfNoSpecifiedTests=false to ignore this error.) The original idea behind maven is nice. But the defaults are so bad, that the whole experience of convention over configuration has been ruined. Cargo and go build systems took the original maven philosophy and implemented them right, with good UX. Gradle, SBT and friends took a step back to the times before maven, and went fully the Ant way, doubling down on \"configuration over convention\". Where \"configuration\" is actually \"programming in a DSL on top of another language on top of Java\". reply mdaniel 1 hour agorootparentI'm not trying to ignore your point, but FWIW the next line after the one you specified includes presumably what a normal person would want to see [ERROR] No goals have been specified for this build. You must specify a valid lifecycle phase or a goal in the format : or :[:]:. Available lifecycle phases are: pre-clean, clean, post-clean, validate, initialize, generate-sources, process-sources, generate-resources, process-resources, compile, process-classes, generate-test-sources, process-test-sources, generate-test-resources, process-test-resources, test-compile, process-test-classes, test, prepare-package, package, pre-integration-test, integration-test, post-integration-test, verify, install, deploy, pre-site, site, post-site, site-deploy. -> [Help 1] I am open to the fact that maybe catastrophically old versions of Maven did not include that help text, but certainly since 3.0 from 14 years ago https://github.com/apache/maven/blob/maven-3.0/maven-core/sr... reply Calzifer 1 hour agorootparentprev> [ERROR] No goals have been specified for this build. > [ERROR] Unknown lifecycle phase \"build\". And somehow missed that the error message also lists the valid lifecycle phases. (could have instead complained that it list all lifecycle phases which is a lot) > // me searching on google how to not run tests How do I know for other build tools how to skip tests? Skipping tests should not be necessary and is done to regularly. I would not consider a tool which immediately points out how to ignore those stupid tests as good UX. reply iamcalledrob 9 hours agoparentprevI'm working on a project that encompasses both JVM (Gradle, Kotlin) and Golang. My hot take: JVM build tools, especially Gradle, are a soup of unnecessary complexity, and people working in that ecosystem have Stockholm Syndrome. In Golang, I spend about 99% of my time dealing with code. In JVM land, I'm spending 30% just dealing with the build system. It's actually insane, and the community at large thinks this is normal. The amount of time it takes to publish a multi-platform Kotlin library for the first time can be measured in days. I published my first Golang library in minutes, by comparison. reply cryptos 8 hours agorootparentYou speak from my soul! I'm in the Java world for a really long time now and I'm wondering for years why the build tools need to be so complicated an annoying. I know Go, Node.js and bit of Rust and all have more pleasant easier to use build tools! The JVM (or GraalVM) as an ecosystem is just fine and probably one of the best, but build tools might be achille's heel. Maybe it would be a good idea for Oracle to invest into that area ... reply mike_hearn 7 hours agorootparentMy experience of JS projects is that build tools are frequently ad-hoc. That is, there simply isn't a general build tool at all, but just a large pile of scripts calling under-documented libraries. Parallelization, caching and quite often even portability are just missing. To justify this statement consider this blog post I wrote a while ago about porting GitHub Desktop (an Electron app) from its prior build/deployment system to Conveyor [1]. Conveyor is a tool for shipping desktop apps and is implemented as a single-purpose build system. The relevant part is this commit: https://github.com/hydraulic-software/github-desktop/commit/... The amount of code that can be deleted is huge! Some of it is in-process code that isn't needed with Conveyor (setting up Squirrel etc), but a lot is just shell scripts that happen to be written in JS. Replacing that with a real build system not only simplifies the codebase but means the build steps are fully parallelized, fully incremental, easier to debug, portable (the build can run on any platform), progress is reported in a uniform way and so on. So whilst the JS ecosystem's approach to build tools may be \"simple\" in some way, in the sense that there's no dominant build tool like Maven or Gradle, that simplicity does cost you in other ways. [1] https://hydraulic.dev/blog/8-packaging-electron-apps.html (Disclosure: Conveyor is a commercial product made by my company) reply user1241320 8 hours agorootparentprevOne note from having worked with both that I don’t see mentioned: Golang dependencies are sources you basically pull and compile with your own code. In JVM-land dependencies are precompliled packages (jars). This adds one little step. reply iamcalledrob 7 hours agorootparent...or a big step, if cross-compiling is required (e.g. Kotlin Multiplatform) I'm surprised there is no source-only dependency solution for JVM -- it'd solve this issue. Pull down the source and build on the fly. Perhaps there is and I'm unaware? reply pkolaczk 2 hours agorootparentI'm afraid Java/Scala/Kotlin compilers are too slow to make that convenient. Even currently building pure Java projects can take minutes when it's compiling just like 300k lines. What if it had to compile millions of lines from all the dependencies? reply kaba0 1 hour agorootparentThe actual compilation step is 100% not the bottleneck - it can go as fast as 10k-50k lines per second! (According to the Mill benchmark, but that’s the Mill-independent part). Comparatively, Go does “only” 16k lines per second based on some HN comments. reply pkolaczk 9 minutes agorootparentBut you’re likely comparing on different hardware though. Go compiling only 16k lines per second is hard to believe for me. Maybe they meant on single CPU core. Rustc compiles over 50k lines per second on my MBP in debug mode and Go must be definitely faster, as everyone knows rust is very slow to compile. But anyway, you may be right. I just ran mvn install for the second time with no source change on my current project. It took 57 seconds. reply jitl 6 hours agorootparentprevWell since the builds tend to be monstrously complicated for some reason, and there’s no standard build tool, maybe it’s more impossible than possible to consider source based distribution. Or it would be like JavaScript where you still need a build and publish step to turn “developer Java / other languages” into “vanilla source distributable Java”. reply dikei 8 hours agorootparentprev> The amount of time it takes to publish a multi-platform Kotlin library for the first time can be measured in days. I published my first Golang library in minutes, by comparison. It's a bit Apple & Orange comparison: publishing a JVM only Kotlin library is quite easy, it's the multiplatform part that takes time. reply jitl 6 hours agorootparentLast time I published a JVM library I had to Open A Jira Ticket to request the rights to publish a package on the main package registry. Then I had to verify I owned the DNS name prefix for my package by fiddling the DNS records at my hosting provider. It took days just to get authorized! Not including the time needed to like, figure out how to make JARs happen. In go: `git push` to a public repo In js: `npm publish` after making an NPM account reply vips7L 15 minutes agorootparentSometimes barrier to entry is good. For example, both npm and cargo struggle with package name squatting and malicious packages that are miss spellings of common packages. reply mdaniel 1 hour agorootparentprevMerely as a \"for your consideration,\" GitLab ships with its own Maven repository (along with npm, docker, Nuget, and a bazillion others)[1] so you have total sovereignty over the publishing auth story. I can appreciate going with Central can be a DX win if you're distributing a library, since having folks addlines to their pom.xml or settings.xml is a hassle, but at least you get to decide which hassle you prefer :-D In fairness, GitHub also finally got on board the train, too: https://docs.github.com/en/actions/use-cases-and-examples/pu... 1: https://docs.gitlab.com/ee/user/packages/maven_repository/ reply pkolaczk 2 hours agorootparentprevIn rust: `cargo publish` after making an account on crates.io reply pkolaczk 2 hours agorootparentprevI've been working on Java-based systems for about 20 years now, and I fully relate to that. Same experience. This is so annoying that I prefer to use Rust over Java even in areas where things like better performance or better type system don't matter. But being able to start a fresh project with one `cargo init` and a few `cargo add` invocations to add any dependencies... well, this is priceless. reply mdaniel 1 hour agorootparentAre you aware of Maven Archetypes[1]? I believe they were the \"cookiecutter\" before cookiecutter existed, although I am 10000000% on-board that their discovery story is total garbage :-( 1: https://maven.apache.org/archetype/index.html and https://maven.apache.org/archetype/maven-archetype-plugin/us... reply pkolaczk 4 minutes agorootparentBut I don’t want to copy a full project with prepopulated list of dependencies chosen by someone else. I want to start small and add dependencies I need. It’s like LEGO vs Playmobil. I want LEGO. ;) reply imtringued 1 hour agorootparentprevI'm in JVM land. I spend very little time dealing with the build system. It is actually insane how well it works. Also, why does it matter how long it takes to publish a library for the first time? It sounds like a non-issue to me. I have written dozens of libraries and published them to a local artifactory instance because it simply doesn't matter if your company specific code is accessible to the world or not. reply neeleshs 6 hours agorootparentprevInteresting. I spend nearly zero time with my maven setup and almost all the time is in coding. I am genuinely curious to know where that 30% time goes? Is it waiting for builds? reply threeseed 9 hours agorootparentprev> the community at large thinks this is normal Half are ignorant. Other half are like me and just stuck with no options. But the tooling ecosystem on the JVM truly is horrific. reply iamcalledrob 9 hours agorootparentI think there are a lot of \"JVM Lifers\" who are so deep in the ecosystem they are unaware how much better things can be. Anecdote: I wanted to publish a ~100LoC multiplatform Kotlin library -- just some bindings. I publish these sorts of things for Go with just a \"git push\". Steps were: 1. Spend a few hours trying to understand Maven Central/Sonotype, register and get \"verified\". They're in the middle of some kind of transition so everything is deprecated or unstable. 2. Figure out signing, because of course published packages must be signed. Now I have a secret to keep track of too, great. 3. Discover that there is no stable Gradle plugin for publishing to the \"new\" Maven Central, it's coming soon... Choose one of the handful of community plugins with a handful of stars on GitHub. 4. Spend a few hours troubleshooting a \"Gradle build failed to end\" error, which ended up being due to signing not finding a signing key. 3rd party plugin didn't handle errors properly, and a bug in Gradle meant that my secret wasn't picked up from local.properties. 4. Eventually discover that because Kotlin Multiplatform can't be cross-compiled, there is no way to actually publish a multiplatform library without spinning up a bunch of CI runners. And you can't just publish code -- JVM packages have to contain compiled artifacts. 5. Realise this now involves maintaining GitHub Actions and Gradle, which is an ongoing cost. 6. Give up. The harm that this kind of complexity must be causing to the ecosystem is immeasurable. reply mike_hearn 7 hours agorootparentAlthough a lot of it is generic badness, Kotlin Multiplatform isn't the JVM ecosystem. You don't need CI runners to publish a JVM library. The reason it comes up with Multiplatform is because Kotlin defines \"Multiplatform\" to mean platforms like JavaScript, or their own LLVM based compiler toolchain that bypasses JVMs entirely. reply iamcalledrob 7 hours agorootparentVery true, although it definitely feels like part of the ecosystem since it uses the same project structure, build tooling etc. reply iainmerrick 8 hours agorootparentprevI’d just like to add, NPM gets a lot of flak (mostly deservedly) but it too is still vastly easier than anything in the JVM ecosystem. Even with all the headaches around modules versus CJS, and JS versus TypeScript, NPM is a lot easier than Gradle. Notably, you have a choice of alternate tools (eg pnpm, yarn, bun) that interoperate pretty well. I guess my point is, Gradle and Maven are specifically and outstandingly bad. reply ackfoobar 1 hour agorootparentI must be missing something here. Don't the tools you mentioned do a lot less than Gradle? Gradle knows test depends on compile, which depends on code generation (say protobuf) - with caching and change detection. Compare that to chaining up the commands in the `scripts` section of `package.json`. EDIT: another comment making this point: https://news.ycombinator.com/item?id=41969847 reply lihaoyi 7 hours agorootparentprevIf you think gradle and maven are bad, you should try Mill! There is more to build tooling than gradle or maven, the field has evolved significantly since those tools launched 15-20 years ago, and Mill tries to do things better reply philipwhiuk 6 hours agorootparentprev> I published my first Golang library in minutes, by comparison. For what platform(s)? Or did you really just push the source code? reply pkolaczk 2 hours agorootparentThat's the trick. You publish the source code. And it's still faster to build all dependencies from source than maven / gradle manages to resolve and download the binary dependencies ;) reply kaba0 7 hours agoparentprevThere are quite a few cases: the moment you touch another language, resources that require a compile-step (e.g. xml schemas to code dtos, protonbuf, all that kind of stuff), sometimes even the code itself requires generation. reply mike_hearn 8 hours agoparentprevBuild tools sit in an unhappy corner of the design space where they provide features not found in the core of regular programming languages, and which are so generally useful that there's a temptation to make them very abstract, but then they often lack some of the features that let regular programs scale well. The key feature that justifies their existence is parallel and incremental execution of DAGs of world-mutating tasks. This is an awkward fit with most programming languages, hence the prevalence of DSLs. But people don't want their build system to become a general purpose programming language, because they don't want to think about build systems at all and because programmers don't buy programming languages anymore, so, this causes a big design tension between generality (people want to use build systems to automate many things) and deliberately limiting the expressive power to try and constrain the design space and thus tooling investment required. Java is in an awkward place because the JDK was born in the 90s on UNIX, by people who thought make is a sufficiently good solution. You still see remnants of this belief in the official Java tutorials, in JEPs, and in the fact that OpenJDK itself is compiled using an autotools based build system! (fortunately it's one of the nice make based build systems out there). The problem with make is twofold: 1. It assumes a CLI that's both powerful and standardized provided by the host OS. Windows violates this assumption but Java is meant to be portable to Windows. 2. \"Plugins\" are CLI tools or scripts and so make implicitly assumes that subprocess creation is cheap. But process creation on Windows is expensive, and starting up JVM programs is also expensive due to the JIT compiling. Therefore make just doesn't work well in the JVM ecosystem. At the same time, the Java project wasn't providing any competing solution, so the wider open source community was left to fill in the gaps. These days language developers provide build tooling out of the box as part of the base toolset along with the compiler, but Java still doesn't. So - you ask, what are people doing with Gradle/Maven that requires all those features. The answer is: everything! Gradle builds frequently orchestrate dozens of different tools as part of a build pipeline, build documentation websites, do upload and deployment, download and manage dependencies, run security scanners and license compliance checkers, analyze dependency graphs, modify compiler behaviors, and so on. Additionally Gradle isn't specific to Java, or even JVM apps. It can also be used to compile C/C++ programs, run native code compilers like Kotlin/Native, and it abstracts the underlying platform so Gradle builds aren't tied to UNIX. That's why it's so complicated. reply AtlasBarfed 7 hours agorootparentBuild systems exist in two turning complete rabbit holes/ slippery slides: Configuration and workflow execution. reply msl09 4 hours agoprevNice try, I'm still not going to write scala code. reply galdosdi 4 hours agoparentBuild times always were my biggest Scala complaint. Arguably code base specific, as I suspect it had a lot to do with all the macros and type level metaprogramming, but, if that kind of thing is possible and customary, an average working programmer who doesn't control the codebase they show up to is going to end up stuck dealing with it. It's a lot easier to build a language that works great, but only in the hands of a single skilled careful owner, than a language that stands up to the abuse of many careless temporary users, and still gets from point A to point B reliably. Like the difference between a sportscar and a rental company or police fleet sedan. Scala was a porsche, but most of us need camrys. reply k3vinw 7 hours agoprevThe thing that’s great about maven is its declarative nature. You can declare goals and profiles for whatever you need the build system to do. The main appeal that I can see from mill over maven is the power of dynamic programming over static xml files. Maybe good lsp/ide support will make managing a build system like this bearable? reply lihaoyi 7 hours agoparentYes, IDE support in Mill is key. Without IntelliJ or VSCode, Mill would not be nearly as pleasant to use as it is today. Mill and Maven both let you declare goals for what you want to do. One does it in XML and one does it in typechecked code. While XML does work, doing things in code with typechecking and full IDE support turns out to be pretty nice as well! reply pnathan 3 hours agoprevI've used mill for some Scala projects in the past and I give it 5/5. reply jiehong 8 hours agoprevWhy not compare it to bazel/pants/buck2 as well? Mill seems to have taken some inspiration from those as well. reply lihaoyi 7 hours agoparentAuthor here. It does! I started working on Mill when I started learning Bazel, during my first months at Databricks. There's a lot of cross-pollination of ideas there, from my 7 years adopting and maintaining the Bazel build at Databricks, but I haven't had time to do a proper head-to-head comparison. Hopefully someone else can though! reply wocram 3 hours agorootparentWhat drove you away from Bazel? I would expect anyone considering migrating away from a \"legacy\" tool like maven would consider a \"modern\" tool like Bazel first. reply whoodle 3 hours agoprev [–] Sorry to hijack this thread a bit, but I currently work at a Scala shop and have grown to like writing it. I worked at Clojure heavy place previously. This tool looks neat. Has anyone at the senior level recently moved on from Scala to other languages recently? Any issue finding jobs or learning the new role? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mill is a fast and scalable build tool for Java, Scala, and Kotlin, designed to outperform traditional JVM (Java Virtual Machine) build tools like Maven and Gradle.",
      "It features a typed configuration language and an immutable task graph, which contribute to clean and understandable builds, and automatically caches and parallelizes tasks for improved speed.",
      "Mill supports a wide range of projects, from small to large monorepos, and integrates well with IDEs (Integrated Development Environments), making it suitable for real-world applications."
    ],
    "commentSummary": [
      "Mill is a fast build tool for Java and Scala, providing an alternative to popular tools like Gradle and Maven, with a focus on speed and reducing build complexity.- It uses Scala for configuration, which may pose a challenge for Java developers unfamiliar with Scala, and some users feel that Java support is insufficient.- Mill is community-driven, with ongoing development and a bounty program to encourage contributions, though some developers are hesitant due to the need to learn Scala and its domain-specific language (DSL)."
    ],
    "points": 125,
    "commentCount": 105,
    "retryCount": 0,
    "time": 1730087807
  },
  {
    "id": 41964882,
    "title": "RP FLIP escapes wrecker's claws",
    "originLink": "https://gcaptain.com/saving-rv-flip-from-the-wreckers-clawsand-its-story-is-mind-blowing/",
    "originBody": "FLIP tow away on August 3, 2023. Photo courtesy Scripps Institution of Oceanography / UC San Diego This Flipping Ship Just Escaped the Wrecker’s Claws—And Her Story Is Mind-Blowing! John Konrad Total Views: 14509 October 27, 2024 Share this article In a quiet corner of the Pacific last August, a vessel unlike any other was making what many thought was its final voyage. R/P FLIP (Floating Instrument Platform), the U.S. Navy’s legendary research vessel that could stand on end like a floating skyscraper, was being towed to Mexico to be scrapped. For well over half a century, FLIP had been an icon of oceanographic research, a testament to audacious engineering and the human thirst for discovery. Its decommissioning, announced last year, marked the end of an era—or so it seemed. But then, a twist befitting a maritime thriller unfolded. It looks like she has been saved! The Call That Changed Everything Giulio Maresca was sitting in his London office at DEEP, the subsea design firm with ambitions to pioneer underwater human habitats, when the news crossed his desk: FLIP was headed for dismantlement. To Maresca and his colleagues, FLIP was more than metal and machinery; it was a symbol of what could be achieved when imagination met engineering. “The directive from our founder was quite clear,” Maresca recalls with a smile. “‘Save her. Don’t come back without her.'” Within 48 hours, a DEEP team was en route to Mexico, racing against time to intercept the vessel before it met an ignoble end. It was a mission as quixotic as it was urgent. A Marvel Reborn FLIP isn’t your typical ship. At 355 feet long, it was designed to do the unthinkable: flip from a horizontal floating position to a vertical one, submerging 300 feet of its length below the ocean surface. This unique capability allowed it to become an exceptionally stable platform, unaffected by surface waves—a perfect sentinel for studying acoustics, wave dynamics, and marine life. Commissioned in 1962, FLIP was a collaborative effort between the U.S. Navy’s Office of Naval Research and the Scripps Institution of Oceanography. Over decades, it facilitated groundbreaking research that deepened our understanding of the ocean’s mysteries. Shaped like a giant baseball bat, the 700-ton FLIP is technically not a ship but a barge. It has no propellers, propulsion, or engine room, and requires towing by a tugboat when conducting scientific missions. “FLIP was from a time when bold engineering met boundless optimism,” says Kristen Tertoole, CEO of DEEP. “An ethos we share and seek to embody.” The Journey Across Oceans After tense negotiations and a flurry of logistical hurdles, DEEP secured ownership of FLIP. The vessel began a new journey—from Mexico, through the Panama Canal, and across the Atlantic to the Mediterranean. It was a voyage that mirrored its original mission: bridging gaps and breaking boundaries. Now docked in France, FLIP is slated for a 12 to 18-month refit at MB92, a shipyard rin Barcelona renowned for refurbishing superyachts and handling unusual projects. “Modernizing FLIP to further our understanding of the ocean is what’s in our DNA,” says Rob Papworth, MB92 Group Managing Director. “We’re exceptionally proud to be involved in this historic endeavor.” A Bold Vision for the Future DEEP’s ambitions for FLIP go beyond restoration. The company envisions the vessel as a cornerstone in their mission to “make humans aquatic,” enabling people to live, work, and thrive underwater. “FLIP will play a key role in our fleet, providing a one-of-a-kind platform for ocean research,” Tertoole explains. “She’s not just a ship; she’s a bridge to the next frontier.” The refitted FLIP will support DEEP’s Sentinel habitat deployments, underwater living spaces designed for extended research missions. Interest from the global scientific community has been immediate and enthusiastic. “I’m thrilled to confirm that many oceanographic and research groups are already in contact to ensure access,” Tertoole says. A Legacy Continued News of FLIP’s salvation has reached those who knew her best. “I’m delighted by DEEP’s decision to revitalize and modernize the R/P FLIP,” says Dr. Tom Drake of the Office of Naval Research. “This modernization will significantly expand her capabilities in ocean science, breathing new life into a vessel that has been vital to our mission.” For Maresca, the rescue of FLIP is both professional and deeply personal. “Everyone in maritime research has a FLIP story,” he says. “She’s inspired generations of scientists and engineers. To be part of her next chapter is beyond rewarding.” Turning Tides As FLIP prepares for her relaunch in early 2026, she carries with her not just instruments and equipment, but the weight of history and the promise of future discoveries. “She’s a vessel born from audacity,” Tertoole reflects. “And that’s exactly what we need now—to be bold in our pursuit of understanding our oceans.” Related Video – The Research Vessel FLIP Turns 50 Tags: oceanography Science U.S. Navy Unlock Exclusive Insights Today! Join the gCaptain Club for curated content, insider opinions, and vibrant community discussions. Sign Up Prev Back to Main Next Be the First to Know Join the 110,467 members that receive our newsletter. Have a news tip? Let us know. Stay Ahead with Our Weekly ‘Dispatch’ Email Dive into a sea of curated content with our weekly ‘Dispatch’ email. Your personal maritime briefing awaits! Sign Up Sign In Related Articles Featured Update: Damaged MV Ruby Docks at Great Yarmouth Amid Concerns Over Explosive Cargo The MV Ruby, a cargo ship carrying a significant amount of potentially explosive fertilizer, docked at the Port of Great Yarmouth on Monday, Peel Ports Group and AIS ship tracking... 4 hours ago Total Views: 29655 Energy Chinese Power Plant Arrives at Sanctioned Russian Arctic LNG Project After Push Through Dangerous Sea Ice By Malte Humpert (gCaptain) – Two Chinese heavy-lift vessels arrived off the coast of the sanctioned Russian Arctic LNG 2 project after a five-week journey through challenging early winter sea... 7 hours ago Total Views: 6198 Featured Africa’s Largest Oil Refinery Ships First Cargo By Prejula Prem (Bloomberg) Nigeria’s Dangote refinery, larger than any other in Africa or Europe, has shipped its first seaborne gasoline cargo as a vital fuel-producing unit continues to ramp up.... October 26, 2024 Total Views: 15107 Why Join the gCaptain Club? Access exclusive insights, engage in vibrant discussions, and gain perspectives from our CEO. Sign Up",
    "commentLink": "https://news.ycombinator.com/item?id=41964882",
    "commentBody": "RP FLIP escapes wrecker's claws (gcaptain.com)110 points by tomohawk 23 hours agohidepastfavorite43 comments dang 22 hours agoRelated: Scripps Institution of Oceanography’s FLIP vessel decommissioned after 60 years - https://news.ycombinator.com/item?id=37072588 - Aug 2023 (51 comments) A ship that flips 90 degrees for precise scientific measurements - https://news.ycombinator.com/item?id=15078094 - Aug 2017 (75 comments) \"Flip\", the vertical ship, marks 50 years at sea - https://news.ycombinator.com/item?id=4193185 - July 2012 (34 comments) I felt sure there was a more recent one but I think I got it confused with this: The Joides Resolution may have sailed its last expedition - https://news.ycombinator.com/item?id=41785543 - Oct 2024 (3 comments) reply sitkack 22 hours agoprevThat is the great news I needed today. It is sobering to know that humanity is continuing to make wholesale mistakes that are only offset by a wonderful minority. You could be the next person to save a different Flip. https://en.wikipedia.org/wiki/RP_FLIP reply kylehotchkiss 22 hours agoparentThe next big flip to disappear is A380s :( quite a few have been decommissioned already (so soon), production has ended, and we’re left only with a350s and 777x (lol) to follow in its footsteps. Meanwhile airports haven’t gotten bigger and more people are flying. reply kortilla 20 hours agorootparent>Meanwhile airports haven’t gotten bigger and more people are flying. This was the flawed thinking that led to the production of the a380 and its ultimate demise. It turns out that people mostly don’t like layovers and more efficient mid sized planes flying between cities people actually want to go to is much better. I don’t have to care about the capacity of ORD when I can just fly to SFO directly from the east coast. The airports with the worst capacity problems (cough LHR) generally had that issue because they were major layover hubs too. The economics will just eliminate them as a hub and life will move on. The 777ER came in and wrecked the other pillar supporting the layover life by opening up direct long range routes from NA to Asia that would have previously made sense on an A380 to NRT with fanouts to other destinations in Asia. The a380 is super cool, but it is not filling a need. reply alexey-salmin 15 hours agorootparentThis wasn't really what killed a380. Many major airports are near the limit of their runways with planes landings/takeoffs every 2-3 minutes. Constructing 3th/4th/5th runway is often impossible. Yearly traffic keeps growing. A reasonable forecast would be that it's only a matter of time until demand for planes like a380 will rise. But evidently it came too early and then the 2008 recession and then COVID moved that point even further into the future. Will see in 20 years I guess. reply DaiPlusPlus 20 hours agorootparentprev> The next big flip to disappear is A380 Just like with wildlife charities, those dang charismatic-megaavians get all the public-attention - so the nonthreatening and cuddly appearance of the A380 gets to be on the sponsor-an-airframe marketing posters, but people need to be aware of the importance of strong aerodiversity and the need to protect and preserve smaller planes, like a Piper Club or an Ekranoplane. reply ChrisMarshallNY 17 hours agorootparent> Ekranoplane I don’t think any of those ever really “took off,” so to speak. I think they had a lot of trouble, with even slightly rough weather. There’s a reason that every photo you see of them, has them zipping over a calm, smooth body of water, on a clear day. reply aspenmayer 17 hours agorootparentI thought those relied on ground effect to achieve the required lift, which would prevent them from flying above the ground or water beyond the altitude at which ground effects exist? reply seabass-labrax 14 hours agorootparentYes; parent was making a pun about it not taking off (in fact, the A-90 Ekranoplane could fly without the ground effect, albeit poorly). The substantive point though is that using the ground effect isn't as viable over rough seas such as those of the Atlantic as it is over calm, flat water due to the irregular astrodynamic shear forces among other reasons. reply DaiPlusPlus 11 hours agorootparentOut of curiosity, what would happen if a giant saltwater wave got into those jet engines? reply p_l 10 hours agorootparentDoesn't matter what kind of water, significant interruption of air intake wrecks the engines. It's commonly what damages engines when they ingest birds, or in one case, a 737 taxiing got too close to side of the taxiway and ingested... snow. Engine blown. reply andrewflnr 19 hours agorootparentprevRP Flip is absolutely unique worldwide. Nothing else, to my knowledge anyway, is even remotely close in shape or function. A whole class of conventional commercial aircraft is not remotely comparable. reply fsckboy 20 hours agorootparentprev>Meanwhile airports haven’t gotten bigger and more people are flying. many smaller market airports have spare capacity and point-to-point flying from one to another reduces demand on the large hubs, which is what Boeing (lol) told Airbus (i am very smart) before they even started on the A380. reply rootusrootus 20 hours agorootparentprevSeems like Boeing made the right call when they canceled their own plan for a new superjumbo back in the 90s. The A380 is cool, but not economical to fly. The future is more planes like the 777X. reply stephen_g 17 hours agorootparentIt does work very well for certain parts of the world, like the Gulf carriers (hence why Emirates has so many). For the US and inter-Europe, totally uneconomical but not everywhere. With newer engines and a slightly redesigned wing (if I recall correctly it was designed a bit oversized than what was needed for the -800, to be able to accommodate a stretch variant which was never introduced) it could probably be made to have 15% lower fuel burn per passenger which would make it work even better for those specific kind of routes, but it's not economical for Airbus to do that when only Emirates and a very small handful of other customers would buy it... reply mmooss 15 hours agorootparent> It does work very well for certain parts of the world, like the Gulf carriers (hence why Emirates has so many). I know they purchased many, but how did it work out for their bottom lines? Also, are these carriers concerned with bottom lines as much as national prestige? reply rob74 5 hours agorootparentSeems to work out pretty well: https://www.emirates.com/media-centre/emirates-group-announc... \"Emirates reports new record profit of AED 17.2 billion (US$ 4.7 billion), up 63% from AED 10.6 billion (US$ 2.9 billion) last year.\" ...of course it helps to have direct access to cheap fuel. Also, if you look at https://en.wikipedia.org/wiki/Largest_airlines_in_the_world#..., you'll see that Emirates is the fourth largest individual airline in the world by passenger-kilometers, and the first three are US-based airlines with more complicated networks, while Emirates only has one major hub in Dubai and isn't really that into direct A-to-B flights (unless B is Dubai of course) - so if it makes sense for any airline to operate the A380, then that airline is Emirates. reply AdamJacobMuller 20 hours agorootparentprevDeeply ironic considering how wrong Boeing has been in so many other ways, but, its been fairly obvious that the hub-and-spoke model the A380 was built for was dying in favor of the point-to-point model of the 787/777x. Airbus will adjust far better than Boeing could have, had they been wrong. reply ChrisMarshallNY 17 hours agorootparentprevYou do not want to be heading towards Immigration, just after one of those puppies lands. reply kylehotchkiss 1 hour agorootparentI had global entry each time I was flying them so there was no wait for me. Most passengers into the US were not US nationals and had to wait in the non-citizen lines. Waiting for your bags on the other hand... reply nradov 20 hours agorootparentprevAround the same time that Airbus was designing the A380, Boeing did waste a lot of time and money designing the Sonic Cruiser. The bet was that customers would pay for faster point-to-point travel, bypassing large hubs. This strategic error is one of the reasons why they still haven't built a new single-aisle airliner. https://simpleflying.com/boeing-sonic-cruiser/ reply mandevil 16 hours agorootparentBoeing actually pitched a \"787, but 737 sized\" to airlines, who all said \"No, what we really want is a plane with a 737 Type Certificate (so all of our pilots don't need expensive training) that matches the fuel efficiency of the A320neo\" and so Boeing found themselves promising a plane that would be a normal 737 so all the pilots didn't need expensive training on it, but would have the same fuel efficiency as a A320neo. It was 100% the airlines that killed Boeing's attempt to pitch them on a clean-sheet airliner. I still believe that if Boeing had a CEO who was an engineer (and not a Harvard MBA who spent two decades at GE under Jack \"Company Killer\" Welch) at the time they would have not made that promise, because it was impossible to get the larger, more fuel efficient engines under a 737 wing without changing the flight characteristics too much to keep the type certificate. But... the Sonic Cruiser is a minor footnote compared to the A380. That was an enormous business disaster (if any A380 ever turned a profit on fly-away costs alone, ignoring the initial up front costs, it was only just barely). The thing about building a new clean-sheet jetliner like this is that you are betting the company's financial performance for the next 10 years on this working out. Because Boeing was actively killing people and there are only the two companies (C919 notwithstanding) Airbus came out of the era looking great, but the A380 was orders of magnitude bigger corporate problem than the Sonic Cruiser. reply p_l 10 hours agorootparentThe person who set in the policies that killed Boeing was an engineer who worked at Boeing from start to end, so... reply mandevil 3 hours agorootparentYou're talking about Dennis Muilenberg, who was the CEO during the 737 Max accidents and failed to properly investigate it (he was CEO from 2015-2019). But he came from the Boeing Defense side, and had no influence on the civil aviation side when it made the decisions that destroyed the 737 Max Program, which were made in 2010 when James McNerney was CEO. James McNerney is the guy with the Harvard MBA who spent two decades working for Jack \"Company Killer\" Welch at GE (he ran the airplane engine division), lost the succession battle, went to be CEO of 3M for a few years, then was CEO of Boeing from 2005-2015, and is the one I hold responsible for the real failures of the 737 Max program. Muilenberg was the one who got fired- and he definitely deserves the blame for the Ethiopian Airlines flight, they should definitely have investigate Lion Air faster and better- but it was McNerney who was responsible for most of the 737 Max program. The engines and wings issues were basically set in stone by the time that Muilenberg first became responsible for the program. reply sehansen 4 hours agorootparentprevNo, the guy who killed Boeing was Jim McNerney, their CEO from 2005 to 2015. McNerney was the guy who started the 737 MAX program in 2011. He got an MBA from Harvard in 1975 and worked for GE from 1982 to 2001. reply nradov 15 hours agorootparentprevWell maybe not impossible. Boeing designed extending landing gear for the 737 Max 10 (although it was mainly done to allow for stretching the fuselage). That didn't require any major breakthroughs and presumably could have been brought forward to the Max 8 in order to allow lower engine placement, although it would have delayed development. reply mandevil 15 hours agorootparentI didn't think the 9 inches added to the gears on the telescoping mechanism were enough to fit the LEAP or the PW1000, I thought that they needed more clearance than that. reply molticrystal 16 hours agoprev>DEEP’s ambitions for FLIP go beyond restoration. The company envisions the vessel as a cornerstone in their mission to “make humans aquatic,” enabling people to live, work, and thrive underwater. Visions of Sealab 2020, Sealab 2021 , and Rapture all come to mind, hopefully we'll the former. reply justinclift 19 hours agoprevHadn't heard of the \"DEEP\" place before which the article is on. They don't have an \"About\" page, and they're not listed in wikipedia. Their Career's page gives the impression it might be a start up coming out of stealth or something? reply aspenmayer 17 hours agoparenthttps://en.wikipedia.org/wiki/RP_FLIP > On October 23rd, 2024, DEEP, an organization working to expand access for ocean exploration, announced the purchase of FLIP and their plans to overhaul and modernize the platform. FLIP will be a crucial asset in the DEEP fleet, offering a unique platform for ocean research. It will also support the deployment of DEEP’s Sentinel habitats, enhancing their extended research network. FLIP was transported from Mexico to La Ciotat, France where it will undergo a comprehensive 12 to 18 month long refit. reply fastball 10 hours agoparentprevYep, definitely not much information out there. But they are clearly fairly well-funded, they seem[1] to have two Triton subs as well (at a minimum) [1] https://www.youtube.com/watch?v=Wb7qSq6YrCA reply justinclift 9 hours agorootparent> But they are clearly fairly well-funded Yeah, that's my impression too. Their seeing a ship like the FLIP and spontaneously buying it speaks volumes. reply fastball 8 hours agorootparentIndeed, and they are refitting it at MB92, which is a shipyard mostly for super yachts, so I'd have to imagine that is going to cost a pretty penny as well. Found their LinkedIn page[1], seems like they might've re-branded at some point from \"Unum Sumus Mare\" (We are One Sea). Maybe that was their stealth moniker. [1] https://www.linkedin.com/company/unumsumusmare/people/ reply wepple 8 hours agoparentprevWhat gives DEEP a competitive advantage, according to Wolpert, is the support of its founder, who he won’t name besides saying he’s a “North American tech entrepreneur…who likes to be quite private,” https://www.cnn.com/science/deep-underwater-habitats-vanguar... reply CoastalCoder 21 hours agoprevThe story vacillates between \"it\" and \"her\" when referring to the ship. Is there some nautical tradition that prescribes that? reply dcminter 21 hours agoparent\"Bells, it may be noted, like ships and kittens, have a way of being female, whatever names they are given.\" -- Dorothy Sayers reply focusedone 3 hours agorootparentSayers quote left my head spinning - wasn't expecting to see that here! Wish I could upvote that twice. reply AStonesThrow 16 hours agoparentprevThere's a perennial debate on Wikipedia about which way to go. https://en.wikipedia.org/wiki/Wikipedia:Naming_conventions_(... Indeed, there are plenty of longstanding nautical traditions which refer to vessels in the feminine. Popular culture and Wikipedia's non-enthusiast population tend to neuter them. Interestingly, Christian churches are feminine as well, although English-speakers may have grown ignorant of this since 1970. reply LikesPwsh 10 hours agorootparentRather than ignorance, it's the ongoing development of the language. French schoolchildren seem to spend half their time learning the gender of inanimate objects. The sooner we can get rid of that, the better. The closest equivalent time-waster we have is different names for different groups of animals (flock, pack, herd etc). reply themaninthedark 1 hour agorootparent>The sooner we can get rid of that, the better. Why? Is it a waste of time or another reason? reply AStonesThrow 10 hours agorootparentprev> Rather than ignorance, it's the ongoing development of the language. No, it's ignorance. Because English is an explicitly non-gendered language, unlike French where any child automatically knows that \"église\" is feminine. The Roman Catholic liturgy was rather simplified in 1970 and included an unfortunate neutering. In 2011, these errors were corrected, and the femininity of the Church is rightfully restored. Ignorance consists in not being up to date in this regard. reply Almondsetat 5 hours agorootparent\"automatically\" = had to learn it reply _def 18 hours agoprev [–] Before this gets decomissioned Christopher Nolan should get his hands on it reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The U.S. Navy's research vessel, R/P FLIP, known for its vertical flipping capability, was scheduled for scrapping in Mexico in August 2023.- DEEP, a subsea design firm, acquired and transported FLIP to France for a 12 to 18-month refit, aiming to use it for ocean research and underwater habitat projects.- The vessel's revival has generated excitement in the scientific community, with potential for new discoveries in ocean science."
    ],
    "commentSummary": [
      "The RP FLIP, a distinctive research vessel capable of flipping 90 degrees for scientific purposes, has been rescued from decommissioning by the ocean exploration organization DEEP.",
      "DEEP intends to modernize the RP FLIP and incorporate it into their research fleet, with a planned 12 to 18-month refit in France.",
      "The post also touches on the decline of the A380 aircraft, reflecting a shift in aviation towards smaller, more efficient planes."
    ],
    "points": 110,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1730056679
  },
  {
    "id": 41972172,
    "title": "The sins of the 90s: Questioning a puzzling claim about mass surveillance",
    "originLink": "https://blog.cr.yp.to/20241028-surveillance.html",
    "originBody": "The cr.yp.to blog Older (Access-J): 2024.08.03: Clang vs. Clang: You're making Clang angry. You wouldn't like Clang when it's angry. #compilers #optimization #bugs #timing #security #codescans Table of contents (Access-I for index page) 2024.10.28: The sins of the 90s: Questioning a puzzling claim about mass surveillance. #attackers #governments #corporations #surveillance #cryptowars Meredith Whittaker, president of the Signal Foundation, gave an interesting talk at NDSS 2024 titled \"AI, Encryption, and the Sins of the 90s\". I won't try to summarize everything the talk is saying: go watch the talk video yourself, or at least read through the transcript. But I'll say something here about what the \"sins\" part of the talk's title is referring to. The talk says that, in the 1990s, \"cryptosystems were still classified as munitions and subject to strict export controls\". The talk describes the \"crypto wars\" as \"a series of legal battles, campaigns, and policy debates that played out in the US across the 1990s\", resulting in \"the liberalization of strong encryption in 1999\", allowing people to \"develop and use strong encryption without being subject to controls\". OK, that sounds familiar. Which parts are the \"sins\"? Answer: the talk claims that \"the legacy of the crypto wars was to trade privacy for encryption—and to usher in an age of mass corporate surveillance\". Wow. That sounds bad, and surprising, definitely something worth understanding better. If cryptographic export controls had instead remained in place after 1999, how would that have improved privacy and reduced corporate surveillance? Answer: the talk claims that, without strong cryptography, \"the metastatic growth of SSL-protected commerce and RSA-protected corporate databases would not have been possible\". Wait, what? Let's look at the facts. 1. Would commerce exist without strong cryptography? Internet commerce was already booming by 1999. Let's look specifically at the history of Amazon. Amazon was founded in 1994. Its initial public stock offering was in 1997. Amazon was sued by Barnes & Noble in 1997, and was sued by Wal-Mart in 1998. Bezos was named Time Magazine's Person of the Year in 1999: Bezos’ vision of the online retailing universe was so complete, his Amazon.com site so elegant and appealing, that it became from Day One the point of reference for anyone who had anything to sell online. And that, it turns out, is everyone. Amazon's revenue was 15.75 million dollars in 1996, 147.79 million dollars in 1997, 609.82 million dollars in 1998, and 1.64 billion dollars in 1999. Amazon was competently executing a business plan that from the outset explicitly prioritized growth. Where does anyone get the idea that continued cryptographic export controls would have stopped the growth of Internet commerce, rather than simply limiting the security level of Internet commerce? How do we reconcile this idea with the observed facts of Amazon already growing rapidly in the 1990s? The export controls were still in place; to the extent that Internet commerce was encrypted at all, it was encrypted primarily with a weak cryptosystem, namely 512-bit RSA. Just to emphasize how fast Amazon's growth was at that point: Amazon's revenue was more than doubling every year. If that had kept up, Amazon's revenue in 2023 would have been more than 26000000 billion dollars. In reality, Amazon's revenue in 2023 was only 575 billion dollars. Okay, okay, 575 billion dollars is a lot of money, and Amazon is now fighting antitrust regulators. But how is Amazon's growth before and after 1999 a story about a change in cryptography regulation, rather than a story about customers liking a convenient shopping site that provided fast, reasonably reliable deliveries of an ever-expanding collection of products at competitive prices? These are natural questions for anyone checking whether the talk's claims match the available evidence. But the talk doesn't answer any of these questions. Look, for example, at the full paragraph containing the \"would not have been possible\" quote: It’s not that 1999 wasn’t a win, at least in a narrow sense. Indeed, we can craft a counterfactual history in which the liberalization of encryption didn’t happen, in which we instead accepted some janky, backdoored, government-standard cryptosystem—some sad Clipper chip DES admixture—and that instead became the thing: a world in which strong cryptosystems did not receive the benefit of many eyes and open scrutiny. But of course the future from then to now would have been very different—not least of all because the metastatic growth of SSL-protected commerce and RSA-protected corporate databases would not have been possible. Aside from irrelevant details, how is the \"counterfactual history\" of a \"janky, backdoored, government-standard cryptosystem\" different from the reality of export-controlled cryptography in the late 1990s, when 95% of SSL connections were limited to RSA-512? The explosion of Internet commerce was already happening at that point. Where does the \"would not have been possible\" claim come from? I'm not allergic to the phrase \"of course\", but I try to limit it to cases where things are really obvious, which is definitely not the situation here. 2. Would commerce exist without security? Government regulations are just one of many sources of weak cryptography. Weak cryptography, in turn, is just one of many sources of Internet-security failures. Companies reported spending more than 0.5% of revenue in 2023 on things labeled as \"cybersecurity\". A cybersecurity company named CrowdStrike accidentally took down millions of Windows computers in July 2024, causing long service outages for many other companies. CrowdStrike had been given control over all those computers because it was saying that this would help protect those computers against attacks. Delta Airlines, in a lawsuit filed this month against CrowdStrike, said that the outage \"crippled its operations for several days, costing more than $500 million in lost revenue and extra expenses\". Meanwhile there are endless reports of ransomware running rampant, as illustrated by BlackCat disrupting various health-care services for weeks starting in February 2024. And yet, despite the evident disruptions, Internet commerce continues. Do we want better security to stop the attacks? Yes. Does not having better security mean that the entire system of Internet commerce will be destroyed? Um, well, it's conceivable that there will be such a dramatic increase in attacks that we'll all retreat to non-Internet commerce (because, y'know, non-Internet commerce is secure). But somehow the attackers don't seem interested in killing the goose that lays the golden eggs. Let's rewind to 1999. The CIH virus had destroyed data on a million computers, and was just one of many examples of attacks. This didn't stop the Internet from skyrocketing in popularity; it simply prompted effort to fix vulnerabilities. One of the vulnerabilities at that time was the use of RSA-512. From the perspective of stopping attacks, this vulnerability was important to fix. But, from the same perspective, there were many other vulnerabilities that were also important to fix, including many that were cheaper to exploit than attacking RSA-512. My own experience is that exploitable buffer overflows were very easy to find back then. Does it sound plausible if someone picks one of the system vulnerabilities in 1999 and claims that fixing this vulnerability is what made the difference between Internet commerce succeeding and Internet commerce failing? I'd expect such a claim to be backed by evidence that Internet commerce was on such a knife's edge (rather than being a clear win for its convenience) and an explanation of what was so special about this vulnerability. Otherwise the claim sounds like nothing more than wishful thinking about the importance of some particular area of security. 3. Would corporate databases exist without strong cryptography? Let's move on to the second part of the claim that, without strong cryptography, \"the metastatic growth of SSL-protected commerce and RSA-protected corporate databases would not have been possible\". The mass-surveillance industry is much older than 1999. See, for example, the book \"IBM and the Holocaust\", which traces how IBM's punch-card databases were used to \"organize nearly everything in Germany and then Nazi Europe, from the identification of the Jews in censuses, registrations, and ancestral tracing programs to the running of railroads and organizing of concentration camp slave labor\". Does a database not count as a \"corporate database\" if the decisions of what's going into the database are being made by a government, in this case the Nazis? Does that make the database less evil? Also, does the level of evil depend on whether this was a database operated by IBM for the Nazis or a database operated by the Nazis using technology provided by IBM? Somehow I don't think these distinctions mattered for people in the concentration camps. As the 20th century continued, more and more powerful technology made surveillance less and less expensive. Here's a quote from a 2007 study \"Engaging privacy and information technology in a digital age\", issued by a committee formed by the U.S. National Academies of Sciences, Engineering, and Medicine: Beginning in the late 1950s, the computer became a central tool of organizational surveillance. It addressed problems of space and time in the management of records and data analysis and fueled the trend of centralization of records. The power of databases to aggregate information previously scattered across diverse locations gave institutions the ability to create comprehensive personal profiles of individuals, frequently without their knowledge or cooperation. The possibility of the use of such power for authoritarian purposes awakened images of Orwellian dystopia in the minds of countless journalists, scholars, writers, and politicians during the 1960s, drawing wide-scale public attention to surveillance and lending urgency to the emerging legal debate over privacy rights. One of the sectors that immediately benefited from the introduction of computer database technology was the credit-reporting industry. ... But the credit and insurance industries were not alone. Banks, utility companies, telephone companies, medical institutions, marketing firms, and many other businesses were compiling national and regional dossiers about their clients and competitors in quantities never before seen in the United States. Surely the 1960s surveillance dossiers by \"the credit-reporting industry\" and \"marketing firms\" and so on count as examples of \"corporate databases\". What's the mechanism by which continued cryptographic export controls would have supposedly stopped the growth of surveillance? How do we reconcile this with the observed facts of government surveillance and corporate surveillance already exploding in the second half of the 20th century, when cryptographic export controls were in place? Why does it matter for this growth whether databases were \"RSA-protected\" or not? Or, more to the point, whether they were protected by something stronger than RSA-512? The talk doesn't answer any of these questions either. 4. Getting personal I was, as the talk mentions, one of the people fighting export controls in the 1990s. The reason I was taking action is that I had studied the situation and was troubled by it. In particular, I had concluded that the export controls were contributing to attacks. If I was wrong about that, then I'd like to understand why. The talk claims that moving to stronger cryptography had the negative effect of creating attacks: specifically, of creating corporate mass surveillance. I'd like to understand the rationale for this claim. But I don't see where the talk explains the supposed mechanism, or provides any evidence, or addresses the contrary evidence provided by 20th-century surveillance. Beyond claiming that the actions against export controls contributed to corporate surveillance, the talk claims that these actions came from a narrow perspective of seeing the government as the only problem. For example: The talk claims that \"strategic mistakes in the 1990s—in particular, the mistake of trusting industry and 'the free market' while viewing the government as the sole threat to fundamental rights—is a big part of how we got here\". The talk criticizes the \"dated, market-centric folk wisdom that is content to leave the governance of significant choices about fundamental rights—like expression and privacy—to a handful of private companies, assuming the invisible hand will work some BCorp magic\". The talk criticizes \"conflating encryption with privacy and focusing narrowly on the tech itself—on encryption as the goal, not a means to the goal—while focusing concerns about privacy invasion solely on governments, assumed to be always on the verge of tyranny—while ignoring (or even celebrating) the interests of market actors\". In context, the talk is attributing these perspectives to those of us fighting the \"crypto wars\". Here the talk is simply wrong. We're on record publicly explaining our goals, and those records demonstrate a much broader perspective than what the talk claims. Consider, for example, the 1993 \"Cypherpunk's Manifesto\" from Eric Hughes. The manifesto is all about real-world privacy. Encryption isn't mentioned until the fifth paragraph; it's one of multiple items that privacy is described as relying upon. The next paragraph after that is as follows: We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy out of their beneficence. It is to their advantage to speak of us, and we should expect that they will speak. To try to prevent their speech is to fight against the realities of information. Information does not just want to be free, it longs to be free. Information expands to fill the available storage space. Information is Rumor's younger, stronger cousin; Information is fleeter of foot, has more eyes, knows more, and understands less than Rumor. This document isn't \"viewing the government as the sole threat\": it's explicitly stating the opposite. It also isn't \"conflating encryption with privacy\". As another example, here's are some 1995 quotes from the first brief that my lawyers filed in Bernstein v. U.S.: The uses for cryptography range from protecting the privacy of attorney/client correspondence, financial transactions and medical records transmitted over wires, to preventing piracy of cable TV, cellular phone, telephone lines or satellite signals. Every bank ATM uses cryptography. ... If the government is successful here, it will eliminate anonymity, forcing citizens to reveal their private associations to the government and others, including high-tech criminals. This isn't \"focusing concerns about privacy invasion solely on governments\": it explicitly includes other attackers. As the U.S. Court of Appeals for the Ninth Circuit put it in its 1999 decision in the case: Whether we are surveilled by our government, by criminals, or by our neighbors, it is fair to say that never has our ability to shield our affairs from prying eyes been at such a low ebb. The availability and use of secure encryption may offer an opportunity to reclaim some portion of the privacy we have lost. The government was the defendant in my court case. That's because this was a court case against regulations imposed by the government. But the records show that we were considering a broader range of attackers. Export regulations weren't the only problems I started taking actions to address. Example from 1993: I wrote letters that stopped NIST's announced plan to give its DSA patent to PKP, a partnership between Caro-Kann Corporation and the RSA corporation. Example from 1995: I helped people understand that DH could be used as a replacement for RSA; the DH patent was due to expire in 1997, whereas the RSA patent wasn't due to expire until 2000. Do these actions sound like \"ignoring (or even celebrating) the interests of market actors\"? The talk's narrative of supposed 1990s blindness is everywhere in the talk, not just in the quotes I've given above. For example, the talk says that \"one of the world's most profitable business models\" in 2024 is \"mass surveillance of a scale and granularity unimaginable in the 1990s\". \"Unimaginable\"? Seriously? How is this not the scale and granularity of surveillance predicted by Orwell in the 1940s? Oh, you want a surveillance-capitalism version? Richard Stallman's 1997 essay \"The right to read\" started with a dystopian short story about a future in which \"you could go to prison for many years for letting someone else read your books\". Here are two sentences from the story: In his software class, Dan had learned that each book had a copyright monitor that reported when and where it was read, and by whom, to Central Licensing. (They used this information to catch reading pirates, but also to sell personal interest profiles to retailers.) That's worldwide fine-grained surveillance for an unholy alliance of marketers and the government, just like the reality in 2024. 5. Searching for sources The talk has a general statement that it draws on analyses by \"Dr. Sarah Myers West, Dr. Chris Gilliard, Dr. Karina Rider, and Dr. Matthew Crain\". The talk transcript ends with a list of references and URLs. One of those sources is Rider's 2016 master's thesis \"The Privacy Paradox: Privacy, Surveillance, and Encryption\". Rider searched Congressional hearings starting in 1993 for the word \"encryption\", and then reviewed and summarized the arguments. As an interesting example, the thesis quotes Microsoft lawyer Ira Rubinstein telling Congress in 1997 that \"industry is in a position to assist law enforcement and national security in achieving their objectives because we are able to sell U.S. products in mass volume\". The thesis doesn't mention that there was already a well-established tradition of corporations making money by enabling government surveillance. Remember IBM working with the Nazis? How about IBM working with NSA to make DES weak enough for NSA to break? Regular readers of my blog will recall that, in the 1990s, NSA modified its export controls to create special exceptions for low-security cryptography from the RSA corporation, specifically 40-bit RC2 and 40-bit RC4. This was the result of a public agreement between the government and the Software Publishers Association. Presumably NSA was happy solidifying the market position of cryptography that NSA could break. It's not as if the corporations involved were putting a higher priority on security than on making money. As another example, consider Project Shamrock, in which telegraph companies sent NSA copies of millions of telegrams, even though the lawyers at three of those companies had \"recommended against participation because they considered the program to be in violation of the law and FCC regulations\". That's a quote from a 400-page Congressional study \"Intelligence activities and the rights of Americans: Book II\" issued in 1976. The arrangement between telegraph companies and NSA was secret for decades. As one historian put it: Data created and collected by these firms could be shared with the government quietly, protected from public scrutiny and outrage by the twin concealments of classification and corporate secrecy. Oh, oops, that isn't actually a quote about the telegraph companies. It's a quote from the talk that this blog post is commenting upon, a quote specifically about what happened with Internet companies \"following the 90s\", as if the mass-surveillance industry were something new. For people who study the history and incentives, it's completely unsurprising to see 21st-century examples of corporations and governments working together on surveillance. I mentioned some examples in a 2012 talk. The 2013 Snowden disclosures included more examples. I'll take a moment here to recommend my own 2015 talk about the corporate incentives, including further examples of attack activities by corporations. But the point I'd like to emphasize here is that corporate surveillance was already burgeoning in the 20th century. The surveillance scandals that Congress investigated in the 1970s weren't just government scandals. Let's get back to the thesis: The ability to ensure privacy for consumers in market transactions against criminals was therefore paired with offers to work cooperatively with government to ensure LEAs and intelligence agencies obtained decrypted communications. What does \"paired\" mean? Yes, there was an overlap between (1) the corporations asking Congress for freedom to sell strong cryptographic software and (2) the corporations offering to support government surveillance. Sometimes the corporations were pointing to #2 as an argument for #1. But \"paired\" sounds to me like it's saying that one of these wouldn't exist without the other. That's not true. #1 and #2 are each examples of corporations pursuing their money-making goals; neither one relies on the other. The telegraph companies secretly delivering copies of telegrams to NSA weren't selling cryptographic software. The thesis continues as follows: Privacy from criminals in the market had the paradoxical effect of facilitating the contraction of privacy from police surveillance. I guess this is the specific source of the surprising claim highlighted at the beginning of this blog post, namely that \"the legacy of the crypto wars was to trade privacy for encryption—and to usher in an age of mass corporate surveillance\". But, again, what's the mechanism that's supposed to have created this negative effect, and how do we reconcile this with the observed facts of what was happening already? The thesis continues by claiming that \"in the year 2000 ... NSA began investing billions of dollars in secret efforts to break commercial encryption systems\". No, 2000 isn't when that began. Tanja Lange and I recently wrote a paper \"Safe curves for elliptic-curve cryptography\", including an appendix that summarizes NSA's resources in the mid-1990s: The Federation of American Scientists used public data to conclude in 1996 [98] that the \"NSA budget is around $3.6 billion\", including \"roughly 20,000 direct-hire NSA staff\". Even if personnel expenses for an average staff member were as high as $100000, NSA would have had $1.6 billion in 1996 to spend on equipment. Declassification requests by journalists led to partial declassification in 2013 of internal NSA history books from 1998 and 1999. These books confirm the 20,000 number; see, e.g., [145, page 23]. These books also say [146, page 291] that NSA spent $199 million in 1984 on a single contract to buy 21,000 IBM PC XTs so as to put a PC on each desk; that NSA spent $150 million in 1985 on a single network-hardware contract; and that \"computer power was the essential ingredient in cryptanalysis\". Another internal NSA document says that \"since the middle of the last century, automation has been used as a way to greatly ease the making and breaking of codes\" and gives examples of NSA's investments in cryptanalytic hardware. Meanwhile NSA was also spending money attacking cryptography in other ways. NSA and CIA secretly purchased Crypto AG in 1970, and sabotaged the cryptography that Crypto AG was selling. As another example, NSA hoped that developing DES would \"drive out competitors\" such as Atalla Corporation. The thesis attributes its claimed 2000 starting date to the Snowden documents. This doesn't have pinpoint references, but seems to be alluding to an internal GCHQ presentation from 2010. The presentation says that \"for the past decade, NSA has lead an aggressive, multipronged effort to break widely used Internet encryption technologies\" such as \"SSL\" and \"SSH\" and \"VPNs\"; that \"cryptanalytic capabilities are now coming on line\"; and that \"vast amounts of encrypted Internet data which have up till now been discarded are now exploitable.\" Is this saying that NSA started attacking cryptography around 2000? No. It's talking specifically about NSA trying, evidently with some level of success, to attack particular \"Internet encryption technologies\". How is any of this supposed to show that preserving cryptographic export controls would have made surveillance harder? Later the thesis describes the corporate-plus-government objectives as follows: \"how could informational privacy in the market be assured so that American technology firms could dominate world markets, all while securing avenues for LEA surveillance?\" Yes, there's an objective of world domination for big technology firms such as, to take a 21st-century example, Facebook. Yes, mass surveillance is the centerpiece of Facebook's business model. Yes, Facebook shares data with the government. But how did Facebook's rise to dominance supposedly rely on \"informational privacy\"? What's the mechanism by which preserving cryptographic export controls would supposedly have prevented Facebook's dominance? How do we reconcile this with reports from 2010 saying that connections to Facebook weren't even encrypted? Facebook had already grown to half a billion users at that point. 6. The future I hope you're troubled by mass surveillance. I hope you have the time and energy to do something about it. I know many of my readers are doing this already. Doing something doesn't mean magically solving the whole problem all at once. It means picking a specific task where you can reasonably hope to make progress, and working on that. For example, maybe you engage in the policy fight against surveillance mandates. Or maybe you expose the money flow behind those mandates. Or, as a programming example, maybe you work on tools for decentralization. There's much more to do. But wait: what if there's some fundamental incompatibility between stopping government surveillance and stopping corporate surveillance? If you try to stop government surveillance then maybe you're helping the corporations! If you try to stop corporate surveillance then maybe you're helping the government! Instead of enthusiastically working on making the situation better, you start worrying that you might be making the situation worse. This sort of concern can be paralyzing. Safest not to do anything, right? No matter how bad the status quo is, if you avoid action then at least you know you aren't doing any damage. Primum non nocere. When a talk claims that preserving cryptographic export controls would have stopped the mass-surveillance industry, the talk isn't just making a claim for an audience of historians. It's influencing future action. It's telling you that there's a tradeoff: an unhappy choice between stopping one bad thing and stopping another bad thing. It's telling you to pause, and to worry that your actions will similarly have bad effects. That's the most important reason to look at whether the claim is actually true, as I've been doing in this blog post. I'll close with a recommendation for further reading: Phil Rogaway's paper \"The moral character of cryptographic work\". Version: This is version 2024.10.28 of the 20241028-surveillance.html web page.",
    "commentLink": "https://news.ycombinator.com/item?id=41972172",
    "commentBody": "The sins of the 90s: Questioning a puzzling claim about mass surveillance (cr.yp.to)101 points by ibotty 3 hours agohidepastfavorite26 comments Lammy 2 hours agoDownside of trading privacy for security: anything that makes a network connection creates metadata about you, and the metadata is the real danger for analyzing your social connections: https://kieranhealy.org/blog/archives/2013/06/09/using-metad... The problem isn't about the big corporations themselves but about the fact that the network itself is always listening and the systems the big corporations build tend to incentivize making as many metadata-leaking connections as possible, either in the name of advertising to you or in the name of Keeping You Safe™: https://en.wikipedia.org/wiki/Five_Eyes Transparent WWW caching is one example of a pro-privacy setup that used to be possible and is no longer feasible due to pervasive TLS. I used to have this kind of setup in the late 2000s when I had a restrictive Comcast data cap. I had a FreeBSD gateway machine and had PF tied in to Squid so every HTTP request got cached on my edge and didn't hit the WAN at all if I reloaded the page or sent the link to a roommate. It's still technically possible if one can trust their own CA on every machine on their network, but in the age of unlimited data who would bother? Other example: the Mac I'm typing this on phones home every app I open in the name of “““protecting””” me from malware. Everyone found this out the hard way in November 2020 and the only result was to encrypt the OCSP check in later versions. Later versions also exempt Apple-signed binaries from filters like Little Snitch so it's now even harder to block. Sending those requests at all effectively gives interested parties the ability to run a “Hey Siri, make a list of every American who has used Tor Browser” type of analysis if they wanted to: https://lapcatsoftware.com/articles/ocsp-privacy.html reply kmeisthax 1 hour agoparentTransparent HTTP caching as a way to avoid leaking metadata is not pro-privacy. It only works because the network is always listening, to both metadata and message content. The reason why people worry about metadata is because it's a way to circumvent encryption (and the law). Metadata is holographic[0] to message content, so you need to protect it with the same zeal content is protected. But letting everyone have the message content so that metadata doesn't leak isn't helpful. Maybe in the context it was deployed, where pervasive deep packet inspection was only something China wasted their CPU cycles on, your proxy made sense. But it doesn't make sense today. [0] X is holographic to Y when the contents of X can be used to completely reconstruct Y. reply SketchySeaBeast 3 minutes agorootparentHow it metadata holographic? Sure, you can know when I communicated to a particular individual, and even the format and size of the message, but it doesn't include the exact message, right? reply 2OEH8eoCRo0 2 minutes agoparentprevI don't see metadata as a danger, I think it's a great compromise between police work and privacy. reply anthk 1 hour agoparentprevStop using a damn Mac first. reply hammock 6 minutes agorootparentI thought Macs were better for privacy? reply Lammy 1 hour agorootparentprevIt's my work computer — not my choice. At home I use a Corebooted 51nb neo-ThinkPad. reply WaitWaitWha 2 hours agoprevOne key part is that the crypto wars were around export, lest we forget \"PGP Source Code and Internals\". If there was no international business, any-strength crypto would have been and could have been used. reply convolvatron 1 hour agoparentthere was a huge chilling effect on both product and protocol design. In the 90s I had to fill out a form and submit it to RSA in order to get a copy of their library. Which I eventually got after waiting 6 months, but I had to agree not to redistribute it in any way. Efforts to design foundational cryptographic protocols were completely hamstrung by the spectre of ITAR and the real possibility that designs would have to US only. Right around the time that the US gave up, the commercial community was taking off and they weren't at all interested in further standardization except was creating moats for their business - which is why we're still stuck in the 90s as far at the network layer goes. reply g-b-r 44 minutes agoprevAside from everything else, I don't understand what Whittaker's point was; she seemed to ultimately be advocating for something, but I can't understand what, exactly. It's probably in the talk's last sentences: > We want not only the right to deploy e2ee and privacy-preserving tech, but the power to make determinations about how, and for whom, our computational infrastructures work. This is the path to privacy, and to actual tech accountability. And we should accept nothing less. But who are \"we\" and \"whom\", and what \"computational infrastructure\" is she referring to? reply hobs 2 hours agoprevIn a nutshell I dont think we would have seen much change - corporations only engage in security insofar as much as they are required to - we've seen that even in this \"metastatic SSL enabled growth\" we've basically sold out security to the lowest common denominator, and core actors in the industry just use these security features as a fig leaf to pretend they give a single crap. Now, would CERTAIN industries exist without strong cryptography? Maybe not, but commerce doesn't really care about privacy in most cases, it cares about money changing hands. reply InDubioProRubio 2 hours agoparentI dont know, they sure make sure the paper-trail is shredded and shedded with the Azure Document Abo 365. When it comes to security from liability everything is top notch. reply red_admiral 27 minutes agoparentprevCryptocurrency, if you accept it and its ecosystem as an industry, would certainly not exist. And as for privacy, a fairy dies every time some someone praises bitcoin for being anonymous. reply anovikov 1 hour agoprevHow could that be relevant for more than a few more years? The world does not end with the US. Regardless of the ban, strong crypto would have been developed elsewhere, as open source, and proliferated to the point of making continuation of the ban impossible: by ~2005 or earlier, it will be either US closing off from global Internet becoming a digital North Korea of a sort, or allowing strong crypto. reply wmf 1 hour agoparentPopular OSes and browsers have almost entirely come from the US. If people had a choice between IE with weak crypto or Opera with strong crypto they absolutely would have chosen IE. reply ForHackernews 1 hour agoprevI haven't seen the talk, but it sounds plausible to me: Technical people got strong crypto so they didn't worry about legislating for privacy. We still have this blind spot today: Google and Apple talk about security and privacy, but what they mean by those terms is making it so only they get your data. reply MattJ100 1 hour agoparent> Technical people got strong crypto so they didn't worry about legislating for privacy. The article debunks this, demonstrating that privacy was a primary concern (e.g. Cypherpunk's Manifesto) decades ago. Also that mass surveillance was already happening even further back. I think it's fair to say that security has made significantly more progress over the decades than privacy has, but I don't think there is evidence of a causal link. Rather, privacy rights are held back because of other separate factors. reply thecrash 1 hour agorootparentAs you point out, decades ago privacy was a widespread social value among everyone who used the internet. Security through cryptography was also a widespread technical value among everyone (well at least some people) who designed software for the internet. Over time, because security and cryptography were beneficial to business and government, cryptography got steadily increasing technical investment and attention. On the other hand, since privacy as a social value does not serve business or government needs, it has been steadily de-emphasized and undermined. Technical people have coped with the progressive erosion of privacy by pointing to cryptography as a way for individuals to uphold their privacy even in the absence of state-protected rights or a civil society which cares. This is the tradeoff being described. reply ForHackernews 1 hour agorootparentprev> demonstrating that privacy was a primary concern (e.g. Cypherpunk's Manifesto) decades ago. Also that mass surveillance was already happening even further back. How does that debunk it? If they were so concerned, why didn't they do anything about it? One plausible answer: they were mollified by cryptography. Remember when it was revealed that the NSA was sniffing cleartext traffic between Google data centers[0]? In response, rather than campaigning for changes to legislation (requiring warrants for data collection, etc.), the big tech firms just started encrypting their internal traffic. If you're Google and your adversaries are nation state actors and other giant tech firms, that makes a lot of sense. But as far as user privacy goes, it's pointless: Google is the adversary. [0] https://theweek.com/articles/457590/why-google-isnt-happy-ab... reply ikmckenz 1 hour agoprevThis is a good article, and throughly debunks the proposed tradeoff between fighting corporate vs government surveillance. It seems to me that the people who concentrate primarily on corporate surveillance primarily want government solutions (privacy regulations, for example), and eventually get it in their heads that the NSA are their friends. reply RamAMM 2 hours agoprev [–] The missed opportunity was to provide privacy protection before everyone stepped into the spotlight. The limitations on RSA key sizes etc (symmetric key lengths, 3DES limits) did not materially affect the outcomes as we can see today. What did happen is that regulation was passed to allow 13 year olds to participate online much to the detriment of our society. What did happen was that business including credit agencies leaked ludicrous amounts of PII with no real harm to the bottom lines of these entities. The GOP themselves leaked the name, SSN, sex, and religion of over a hundred million US voters again with no harm to the leaking entity. We didn't go wrong in limiting export encryption strength to the evil 7, and we didn't go wrong in loosening encryption export restrictions. We entirely missed the boat on what matters by failing to define and protect the privacy rights of individuals until nearly all that mattered was publicly available to bad actors through negligence. This is part of the human propensity to prioritize today over tomorrow. reply elric 1 hour agoparent [–] > What did happen is that regulation was passed to allow 13 year olds to participate online much to the detriment of our society. That's a very hot take. Citation needed. I remember when the US forced COP(P?)A into being. I helped run a site aimed at kids back in those days. Suddenly we had to tell half of those kids to fuck off because of a weird and arbitrary age limit. Those kids were part of a great community, had a sense of belonging which they often didn't have in their meatspace lives, they had a safe space to explore ideas and engage with people from all over the world. But I'm sure that was all to the detriment of our society :eyeroll:. Ad peddling, stealing and selling personal information, that has been detrimental. Having kids engage with other kids on the interwebs? I doubt it. reply ryandrake 1 hour agorootparentKids are not stupid, though. They know about the arbitrary age limit, and they know that if they are under that limit, their service is nerfed and/or not allowed. So, the end effect of COPPA is that everyone under 13 simply knows to use a fake birthdate online that shows them to be over the limit. reply elric 1 hour agorootparentSure, it's one of the many rules that's bent and broken on a daily basis. Doesn't make it any less stupid. And it falls on the community owner to enforce, which is doubly stupid, as the only way to prove age is to provide ID, which requires a lot of administration, and that data then becomes a liability. reply dfxm12 1 hour agorootparentprevCOP(P?)A COPA [0] is a different law which never took effect. COPPA [1] is what you're referring to. Ad peddling, stealing and selling personal information, that has been detrimental. I agree and what's good for the gander is good for the goose. Why did we only recognize the need for privacy for people under an arbitrary age? We all deserve it! 0 - https://en.wikipedia.org/wiki/Child_Online_Protection_Act 1 - https://en.wikipedia.org/wiki/Children%27s_Online_Privacy_Pr... reply bippihippi1 1 hour agorootparentprev [–] the issue with online kids isn't just the availability of the internet to kids but the availability of the kids to the internet reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The cr.yp.to blog critiques Meredith Whittaker's NDSS 2024 talk, which links the liberalization of encryption in 1999 to increased corporate surveillance, by examining historical evidence.",
      "The blog argues that Internet commerce and corporate databases were expanding before 1999, challenging the claim that cryptographic export controls were solely responsible for surveillance issues.",
      "It emphasizes the importance of actively opposing mass surveillance and questions the notion that efforts against one form of surveillance inherently support another."
    ],
    "commentSummary": [
      "The 1990s experienced a trade-off between privacy and security, with metadata from network connections posing a significant privacy threat.",
      "Transparent HTTP caching, once beneficial for privacy, is now less feasible due to the widespread use of TLS (Transport Layer Security).",
      "Privacy has not kept pace with security advancements, as businesses and governments prioritize their interests, leading to significant data leaks and privacy erosion."
    ],
    "points": 102,
    "commentCount": 26,
    "retryCount": 0,
    "time": 1730129694
  },
  {
    "id": 41968892,
    "title": "On Good Software Engineers",
    "originLink": "https://candost.blog/on-good-software-engineers/",
    "originBody": "Setting expectations for software engineers is tricky for all managers. Every company has different needs and a different structure, tech stack, and culture. Whenever someone joins a team, one of the manager’s challenges is aligning the organization’s expectations with those of the new joiner. As there’s no universal guidance on this subject, I set out to find a simple definition that would help managers frame the fundamental things they expect from software engineers. I first found definitions of 10x engineers, superstars, or rockstar developers, which aren’t definitions of good engineers in any way. Someone may produce a lot of work but it’s often at the cost of team spirit and results in low-quality code. Ultimately, the team is demoralized and the organization bears the cost of substandard code. I also looked at different career progression frameworks or career matrices (which aim to give engineers perspective on how to map their professional development to roles) to see how tech- or product-driven organizations define good engineers. I found that all were incomplete (I wrote about the good, the bad and the ugly of these frameworks here. In general, career frameworks are helpful in defining roles, but they don’t define a good engineer. After sharing my thoughts and findings with peers, well-respected engineers and on LinkedIn, I arrived at one definition of a good software engineer. A good engineer is one whom I, as a manager or peer, can trust to progress a project, knowing that they will deliver a solution by working with the team and producing good quality, again and again. This definition applies to software engineers at all levels (from junior to staff+). We can’t expect a junior engineer to drive a big project; their scope will be limited. Yet, we can expect them to deliver small, unambiguous tasks with high quality again and again. We can expect good senior+ engineers to drive and deliver a feature or project. When it comes to staff+ engineers, this expectation will span over big and long-term projects with many unknowns. It’s a super simple definition but has a lot of subtleties around how a good engineer, at any level, will approach and deliver a project by using many hard and soft skills. Let’s delve into them one by one. Good engineers know how to influence others and the organization to deliver a solution as a team. At any seniority level, a good engineer must know how to communicate well both in written and spoken form. An engineer’s work always depends on collaboration (code reviews, pair programming, RFCs, ADRs, feedback, etc.). Good collaboration demands clear communication, giving and receiving feedback giving and receiving feedback, and listening with empathy. However, these soft skills are not enough. Good engineers understand the processes they are operating in while taking a project from an idea to a solution. There are different approaches when it comes to doing code reviews or writing RFCs or ADRs. Each organization uses different methodologies like Kanban, Scrum, or Scrumban. Some organizations use Tech Radar to help teams make technology choices. Good engineers know the processes and guidelines so thoroughly that they know where they can bend the rules. They don’t stop there; they take their time to understand the organization as a whole. Good engineers spend extra time learning the environment they’re in, going beyond the processes so they can independently drive the work. They learn how the organization works, about its culture, norms, and people. As they need to adapt to the organizational requirements to deliver a job of good quality, they have to develop not only hard skills but people and organizational skills. If the organization is hierarchical, they’ll have a difficult time driving a solution when they face rejection from a more senior person. If the organization works with short-lived task forces instead of long-living teams, their work style will be focused on speed and getting things done quickly. In any situation, they’ll need to find how to implement quality sustainably. Good engineers take a proactive approach and embed quality elements into their deliverables to increase consistency and velocity. There is no need to ask for extra permission to write tests when you do test-driven development; no discussion will be needed if you consider refactoring as part of the new feature implementation. A good engineer chooses their approach wisely. If they inherit a legacy codebase, they look for ways to make it better, step by step. If they work with giving estimations, they include all these to keep a good level of quality. But above all, a good engineer needs to understand what quality means in their current circumstance. Good engineers understand the stakeholders’ needs and fine-tune their approach so they don’t unnecessarily delay the delivery. They might need to do a proof of concept first or a full solution design upfront. Even when working in the same place, the organization evolves and changes; good engineers adapt to these changes and adjust the project’s codebase accordingly. Good engineers constantly work on reducing complexity in the codebase to consistently provide high quality. They seek a modular design, separate concerns at every level while keeping the right amount of cohesion, and have a good testing setup and strategy. These are quality levers, and they know how to adjust them according to the organization, the situation, and the people around them. Keeping the same implementation and delivery strategies rarely works; good engineers constantly adapt and have a learning mindset. Good engineers are reliable in constantly changing organizations. They seek to learn at every chance, even if it puts them in uncomfortable situations, such as publicly admitting mistakes, holding themselves accountable, and looking for ways to prevent the same mistakes from happening again. If a good engineer doesn’t know how to tackle a problem, they don’t avoid tackling it. They have a growth mindset and eagerness to learn. But they don’t stop there. Good engineers are team players regardless of personality type. They recognize a problem and offer a solution. They don’t throw the problem over the fence and ask others to fix it. I’ve covered good engineers in detail. But what makes a great engineer? Great engineers do all of the above but proactively. If they see a broken process, they don’t walk past the problem or wait for someone else’s permission. They take action to fix it. If they can’t change the process themselves, they don’t complain without bringing solutions to the people who can change it. These expectations will not be easy for inexperienced engineers, but their scope will be limited at first. They will gain experience in time. If they keep learning, stay reliable, and improve quality day-to-day, it’s safe to call them good engineers. I already hear some of you saying, “Well, Candost, you expect a lot of things from a good engineer.” No, I don’t. I strongly believe all that I’ve mentioned is a basic expectation from any engineer. More generally, these expectations apply to, in fact, any good employee.",
    "commentLink": "https://news.ycombinator.com/item?id=41968892",
    "commentBody": "On Good Software Engineers (candost.blog)103 points by BerislavLopac 10 hours agohidepastfavorite89 comments ozim 9 hours agoYou take proactive approach, listen to people, work on reducing complexity. Then you wake up one day being steamrolled by business change where other senior dev with some business analyst hijacks process does some awful crap \"because business needs this ASAP\" and leaves you maintaining/fixing up pile of crap. Guess who is blamed later on for the system is not up to standard like having security hole or totally not logical flow in places where \"business need\" was implemented. Keep in mind after 6 months no one will remember they did that business change everyone will remember that you are maintaining the system because you try to keep it decent so it is your fault ;) reply awesomegoat_com 7 hours agoparentI have seen this so many times. You almost made me weep. It's tragedy of commons. To stop this we need software engineers to own their own code legally. reply sam_lowry_ 5 hours agorootparentLike journalists who retain the copyright on their articles. This is also a reason lots of decent open source code comes out of the media industry. As much as we despise the media for its effect on society, journalists are much better than software developers in enforcing their worldview on others. reply karmakurtisaani 8 hours agoparentprevThey might not blame you for it, but you're definitely in every meeting with eyes on you to fix it. Blaming the predecessor at this point is not only futile, but makes you look bad as well. reply woleium 5 hours agorootparentAmazon’s “away team” method is supposed to account for this. The sponsoring business unit is (supposed to be) accountable for upkeep. reply azemetre 2 hours agorootparentWhat happens if the entire team gets churned in 4 years? Or is 4 years the lifespan of a single BU nowadays? I don't see a way to mitigate this unless you care about these things from the onset, but I suppose if you're a monopoly you can just do anything you want because you have no competition. reply moffkalast 7 hours agoparentprevAh yes, nothing quite like trashing half the codebase because \"a customer needs this next week\" and then having to maintain that shit for years. reply kozikow 8 hours agoprevStory of two engineers in a team I worked with. P is what most people would consider 10x engineer (but not this article). Can get anything done few times quicker than anyone else. It's like 10 junior engineers stacked in one person. But it often would be unmaintainable mess. M is a lot like article describes. Understands what needs to be done and creates good technical designs. Often unf*s mess created by P. Delivers business value. Do not write a lot of code. It's funny that depending on whom you ask, M or P would be the 10x engineer and other would be the bad engineer. Real 10x engineer can wear the M or P hat depending on circumstances. reply eXpl0it3r 5 hours agoparentI much rather have no 10x engineer on my team, but instead engineers who do just a bit more than the bare minimum. For example, who don't just test their single use case, but check if it breaks anything around it. Or who invest just a tiny bit more time to actually write down what their bug analysis has yielded. Or who update the documentation after an interface change. Or who write solution designs to think about the approach, before hacking some ugly mess. Or who check with the PO or user if the chosen approach/design is what they expected. Or who ... In my experience having devs who do more than the bare minimum is way more productive for most day-to-day business. Maybe there's room for a powerhouse in cases, where you have to drastically restructure a code base and quickly create some PoC. reply packetlost 5 hours agorootparentEvery business I've ever been at had a \"strike team\" of the 2x+ engineers (in the M sense) that didn't typically do maintenance work, they unfucked messes or rescued projects. It seemed pretty effective from my standpoint. reply Wheatman 7 hours agoparentprevI wonder if it woudl be better to think of it as the the 10X team, rather than a single 10x developer. Im still studying CS so I'm probably way off base,but it seems far more realistic, and usefull. reply braza 8 hours agoprevThe article is good, but I think it communicates with a narrower audience than it intended to in terms of demographics, especially the ones who do not work in nice tech companies. For instance that passage: > I first found definitions of 10x engineers, superstars, or rockstar developers, which aren’t definitions of good engineers in any way. Someone may produce a lot of work but it’s often at the cost of team spirit and results in low-quality code. Ultimately, the team is demoralized and the organization bears the cost of substandard code. I used to work in a tech company (bytes), and now I am working in an old money/traditional company (atoms) that uses technology marginally to stay ahead. My team's (a couple of dozens) median age is 53, and I do not see how this relates to them or even to myself. I definitely would like to hear more from \"Working Bee Engineer\", \"Dark Matter Engineer\", \"How I survived 25 layoffs Engineer\", \"How I kept my sanity working with internal clients Engineer\", \"I managed to raise kids being in Tech as Engineer\", \"The bodybuilder/triathlete/sports(wo)man Engineer\" and so on. I'm not being cynical, but I miss the old days of actionable and down-to-earth blogposts that anyone could relate to. reply fullstackwife 9 hours agoprevThis is fine if you see programmer as a sort of large factory blue collar worker, but not all programmers see themselves in such position of a perfect cog in your \"org\". Disturbing fact: sometimes you get best ideas out of boredom:) reply larsonnn 9 hours agoprev> Good engineers know how to influence others and the organization to deliver a solution as a team. This is a Problem, assuming someone is good at talking is also a good engineer. > Good engineers constantly work on reducing complexity in the codebase to consistently provide high quality. Complexity for the manager? Who is deciding how complex a system is. This could also be a skill issue with the „team“ by taking skilled engineers and mix them with not so skilled ones. Overall the article is written for managers which try to add a image of an engineer which is like a manager. Influence people and give up on complex stuff. reply devjab 9 hours agoparentI know a lot of engineers follow various principles like SOLID, DRY, Clean Architecture and so on, but as far as complexity goes it’s really rather straight forward. You never add abstractions until you can’t avoid them. We’ve had 20 years of these principles (and what other nonsense OOP had brought with it) now, and despite the fact that many of them were written by people who haven’t worked in software engineering since a decade before Python was made they still remain popular and largely unaltered. Which is silly considering our industry has never been more of a mess, with so many teams building complexity to “future proof” things that they will never need, to the point where some teams actively hinder the business. Complexity is fairly straight forward in my opinion. You build after the YAGNI principles and you include things from SOLID, DRY, CLEAN, whatever when it makes sense to do so. If you happen to enter a team that has dug themselves into a pit of unnecessary complexity you need to work on reducing it. This is takes a good engineer, because the fundamental reason to do this or that comes down to engineering. People who follow dogmas are not good engineers. You will even see the authors of some of these principles like Uncle Bob tell you that people who over complicate their code bases misunderstand his principles. Convenient when your career is selling consultant, but also very true. reply imiric 9 hours agorootparent> Complexity is fairly straight forward in my opinion. That's a bold take. The difficult thing with complexity is that it's an abstract and, sometimes, subjective concept. (Not speaking of measurable complexity like cyclomatic or algorithmic.) It may involve abstractions, yes, but those are usually introduced with the argument that they—ironically enough—_simplify_ some interface or process. It's difficult to argue against that since we deal with abstractions on a daily basis which _do_ make our lives easier, from the hardware layer and up. So then the task of removing abstractions becomes an uphill battle to convince the rest of the team that this is indeed a good idea. This is a sociocultural and political problem, not strictly related to engineering. So I don't see the task of resolving complexity as being this straightforward. The best approach I've found of dealing with this is to focus on things we can measure instead. Use linters to warn you about cyclomatic complexity, function length, dead code, single interface implementations, and any other quantifiable metric that contributes to increasing complexity. Even this is often difficult to align on within teams, but with it in place at least there's an objective metric that can guide the team in the right direction. reply Daub 9 hours agoprev> Good engineers understand the stakeholders’ needs… In my experience, this can take two very different forms: 1. Being observant of a stakeholder’s stated needs. 2. Being confident enough to tell a stakeholder what their needs should be. On a pedantic note, I would prefer the term ‘effective’ engineer to ‘good’ engineer. The later sounds like a judgment on their moral character. reply justinclift 9 hours agoparentHeh Heh Heh. Queue the post about highly effective evil engineers then? Star Wars Death Star stuff maybe, or a perhaps a global system to direct people's attention to ads? ;) reply switch007 9 hours agoparentprevEdit: oops read too quickly. Disregard: I don't think of morals when I read \"effective engineer\" personally reply lazyasciiart 8 hours agorootparent“The latter” means “the second of the two options I just mentioned”, so in this case he is saying that ‘good’ engineer feels like a moral judgment. reply switch007 7 hours agorootparentI read too quickly. Thanks reply dijksterhuis 7 hours agoparentprevi often state 1/2 as > what they want isn’t necessarily what they need and i agree with effective. it’s less of a loaded term but i feel it’s also a more accurate description of what we try to strive for as engineers. reply andrewstuart 9 hours agoparentprevGood engineers are pedantic about terminology such as effective versus good. reply jhot 6 hours agorootparentI'm hoping this is sarcasm. The people I've worked with who are highly pedantic wreck team dynamics and rarely deliver anything of value. reply hintymad 38 minutes agoprev> We can’t expect a junior engineer to drive a big project; their scope will be limited I find it a dilemma when it comes to driving \"big project\", especially in a large company. The engineers who drive such projects often behave more like product managers. They sketch out key product features, work with teams to get roadmaps out, and convince the leadership and teams to get the right resources. In addition, they will also draw a few boxes to have a so-called \"architecture diagram\", and hand out the actual design and implementation to lower-level engineers. I don't deny the importance of such work, and I do recognize that junior engineers likely won't have the clout or the knowledge to push such project forward. On the other hand, I find the value of such high-level engineers diminish fast in the industry, especially when they want to switch jobs, for the will have lost the ability to get down to specifics to solve tough technical problems. Case in point, I have seen most of the so-called \"uber TL\" fail interviews because all they could do was drawing a bunch of boxes and talking about strategies or requirements. They may tell you that a recommender pipeline will have retrieval, ranking, and reranking, and even throw around a few model names. But when you ask them any specifics about the landscape, the model architecture, the selection of specific technologies (especially how the selected tech works), they would get stuck. And they certainly can't implement any of the said components. Note this is not a criticism but a lament. I certainly face the same dilemma, and frequently question how I can continue to be more valuable as I grow in my career, especially given that that I don't plan to say within the same company forever and I don't want to be a professional box drawer for life. The only path I can think of now is to become someone like a great CS professor: the professor does not necessarily write all the papers, but she is invaluable to her students by unblocking them when needed, by understanding new paper better than anyone, by pointing out a direction that is not so obvious to the students, and etc. That is, to be someone like Wernher von Braun or Kelly Johnson. Someone who can code out a system like ClickHouse or at least pin down exactly which data structures to use, instead of telling his team vague ideas like let's use SIMD to speed up the query. Someone who can write a working TLA+ spec to show the flaw in a design by his team instead of telling his team that they can use TLA+ to find intricate bugs. To be honest, I don't know how to become like that while keeping getting promoted to a higher-level IC, but I don't see other ways. reply sidcool 9 hours agoprevI like the post, but it's a bit idealistic. It's like a laundry list of all the perfect attributes of almost any profession. It's like reading a religious text. reply sk11001 8 hours agoparentI don't agree that it's idealistic because it's only directional - it tells you what to move towards, it doesn't give you any idealistic target or criteria for any of the things it lists. Which seems like a good thing. reply brianmcc 6 hours agoparentprevYeah like current sibling reply here, it's OK to be idealistic: \"here's what I think perfect looks like\", and accept that sure not everybody meets that definition. Doesn't mean it's a bad aspiration though. I mostly agree with the article, FWIW. Including having worked with various \"talented but difficult\" people before. One of the more under-appreciated aspects of management is having direct reports you can delegate stuff to and (a) they just deal with it, and (b) you need little or no supervision and there's no drama. Managers are humans: making their lives a little better by being Mr/Mrs/Ms Reliably Gets Things Done will in any sane org yield dividends. Of course not all orgs are sane, and not all managers are Good Managers, but that's a different conversation. reply yosefk 9 hours agoprevVery inspiring! I'm off to \"embed quality elements into my deliverables to increase consistency and velocity.\" Apart from the tone, I agree that it's awesome when an engineer understands your fucked up process and manages to be productive despite it (\"goes beyond the processes to independently drive work\"), but as a manager you can't count on most people being like that and so you should work very hard to make your process work for people who do not think very much about what could go wrong when acting fairly naively according to this process. It says in the end that these are basic expectations from any engineer or even any employee. Well, maybe, but most people don't meet these expectations, and it's a basic expectation from a manager to be able to work with actually available people and not only imaginary ones. reply jimberlage 8 hours agoprevIt’s useful to have a vision like this. Not because everyone will hit all these criteria. (If you do, I’d love to steal your hiring process.) I find it useful because coaching people to be better is easier with an ideal like this to point to, that is complete. Lots of managers struggle to put into words why they don’t see an employee as they see themselves. If you have a genuine difference of opinion, you can relate back to something like this. Say your employee does a lot of tickets, and sees themselves as a hyper productive engine on a team. You as a manager see them picking up low-impact tickets and not finishing any features the business asked for end-to-end. The employee wants their productivity to be recognized. You want your employee to be more focused on a single business outcome rather than seeing a high number of tickets in the done column. Some people (especially neurodivergent people) really “get it” when they have a pre-read they can think on and apply to their situation. A blog post like this is nice because you can have the employee read a bullet and then talk about how it applies to their situation in a 1:1. reply _s_a_m_ 9 hours agoprevThis post is sooo symptomatic of people who have too much time and don't seem to be educated beyond their field. Overthinking something that maybe not that complicated after all. The egos of software people is just bigger than it should be. Also mythical thinking like \"10x bla bla\" is symptomatic. reply MortyWaves 8 hours agoparentYour comment is basically a personal attack of the character of the author. Totally unnecessary. Additionally, I completely disagree with your assessment. It's clear the author has spent a lot of time thinking about this and you framing it as \"over thinking\" and \"not educated beyond their field\" and \"big ego\" is downright mean spirited, wrong, and reductivism. reply _s_a_m_ 8 hours agorootparentOf course it is a personal attack on the character of the person. That is the only thing guard-railing spreading nonsense. Software people need to work on their character. reply Gigablah 7 hours agorootparent> That is the only thing guard-railing spreading nonsense. I am honestly disappointed to see this level of discourse on HN. reply kl5ag 7 hours agoprev\"A good engineer is one whom I, as a manager or peer, can trust to progress a project, knowing that they will deliver a solution by working with the team and producing good quality, again and again.\" Not again. The real world does not work like that. The author has the luxury to have team meetings, onboarding, agile and all of that nonsense because the hard parts of open source have already been written by 10x engineers. What the author is working on is presumably some kind of devops that uses other people's software. Perhaps OSS was a mistake. It enables all sorts of pundits and is now repackaged by \"AI\". reply allgreed 5 hours agoparentWould you be so kind as to elaborate? I definitely see you’re onto something. How does the real world works? What are the hard parts? What’s wrong with using other people’s software? reply azemetre 2 hours agorootparentI took their comment to mean that these people are standing on the massive mountains of progress that have been made, but not acknowledging that a lot of wasted effort was lost learning these things. It's easy to only talk about what should be done with perfection in mind, it's another to talk about what can realistically be done. It's no different in regards for anything else the humane race has done, we know the solutions to be done in regards to climate change, inequality; it's another to convince society to then go and try to solve these things with the solutions we thought of. reply punduk 9 hours agoprevI don't think good engineering is a soup of confusion like the one in this article. simple is beautiful. And I think good engineering is associated with simplicity. reply wiz21c 9 hours agoprevFTA: \"Setting expectations for software engineers is tricky for all managers.\" What about: \"Setting expectations for managers is tricky for all software engineers.\" ? reply spacemanspiffii 8 hours agoprevA developer that ticks all these boxes is certainly a Good Software Engineer, but the reverse relation doesn't necessarily hold. There are many that have made very valuable contributions while not even working on a team, or perhaps even being an asshole to everyone around them, ignoring stakeholders, everything. Or just something less extreme, such as maybe they didn't at all times know their organization that well. That is fine, if it works at their time and place. To call those \"Bad Software Engineers\" is unhelpful. reply bjornsing 7 hours agoprevAll posts on this topic should start with a brief description of the problem domain, because all sensible conclusions depend on it. There are problem domains where you just have to be insanely smart to be able to contribute, and there are others (as I get the feeling is the case here) where you just need to be reasonably socially competent and dependable. A “good engineer” in one domain can be terrible in another. reply nicolay1 8 hours agoprevGood engineers want to create the best product possible, and are demanding from the product team. They want clarity and visibility on user insight in order to be able to do the right tradeoffs to maximize customer satisfaction. -> I think that as engineers, we also have the responsibility to create the best product (interested to have your feedback, I want to create a meetup talk on this subject) reply indulona 10 hours agoprevWhat differentiates a good programmer from a bad one? The good programmer will navigate the unknown on his own while the bad programmer will struggle. That's about it. It does not matter what level of proficiency the programmer is at right now. It is a state of mind. The core of a personality. This translates to the whole career. Can you figure things out on your own or do you need someone to guide you, is what makes the ultimate difference. reply cloogshicer 9 hours agoparentI think you're on to something but I wouldn't call it a personality trait. It's something that can be learned, but it takes a ridiculous amount of time. I've been teaching programming to complete beginners now for a few years and there is always a point in time during their education where this clicks: they go from asking about everything to realizing that there are often no easy answers and start doing their own research and problem solving. reply intromert 9 hours agoparentprevThis is spot on—a simple and precise explanation. As a programmer myself, I’ve seen developers dive into a 15-year-old codebase, independently work through it, and only ask questions once they’ve exhausted all other options. reply 000ooo000 9 hours agorootparent>15 year old codebase Is this what people think of when they think of an old codebase? Must be nice :') reply yurishimo 9 hours agorootparentI think it also matters what happened during the intervening 15 years. If you built an app in 2004 and haven't touched it really since, then it should hopefully still be reasonably easy to follow along, even if the conventions might seem outdated. 15 years of active feature development on the other hand will likely be a major slog for any developer, regardless of experience. There's a lot that can happen in 15 years even if there were only 1-3 developers if they everyone takes the easy path since they know where all the gotchas are. It's only when new devs are added that the curtain comes down and the lazy abstractions (or lack thereof) are exposed. reply 000ooo000 9 hours agoprevAnother day, another listicle about senior/staff/principal developer labelling disguised as a blog. Only insecure devs care about this crap. Devs who know their shit aren't coming up with definitions distinguishing themselves from devs who don't. They have better things to do (e.g. actual work). reply techcode 8 hours agoparentMeanwhile there's not that much posted/discussed about good (so not 10x, just 1x instead of 0.5x or negative) engineering/product managers. In my experience where I've worn both IC and TL/manager hats -even just going from \"adequate\" to \"OK\" team/engineering/product manager leads to impact/output that's bigger than having the best (so that mythical 10x) engineer. reply arp242 9 hours agoparentprevOr, you know, people interested in building a team of Good Software Engineers are interested in thinking about this sort of thing. Also: Please don't post shallow dismissals, especially of other people's work. https://news.ycombinator.com/newsguidelines.html reply ownagefool 9 hours agorootparentDepends. At least some of these lists will be created to define the scope of the good engineer so it applies to them, or habits they like, but there's nothing that actually clarifies the benefit here. Is there a measurable increase in revenue, feature releases, uptime? I've worked as a contractor for a decade. I'm brought in to deliver specific outcomes by specific timelines. There are polarizing views on what I do. Some will view me as the 10x engineer; others a bit of a cowboy. However, there's no lack of \"good engineers\" that aren't able to deliver working software in a timely manner, which is why I'm even at those orgs in the first place. reply arp242 9 hours agorootparentYou can disagree with any of this list, of course, but that's not what the previous poster was doing: it's just a shallow dismissal, and a claim that it was written for what are essentially bad faith reasons. That's quite a different thing than \"I disagree with this because X\" (which is what you're doing). reply tgv 9 hours agorootparentprevThen look at articles that are a bit better than this one, which manages to come up with the blandest of ... definitions? > A good engineer is one whom I, as a manager or peer, can trust to progress a project, knowing that they will deliver a solution by working with the team and producing good quality, again and again. What a vacuous statement. The phrase \"as a manager or peer\" is so 2014 \"user story\". And it doesn't get more linkedin than \"to progress a project.\" The whole sentence just says \"A good engineer is someone who will do his/her job.\" It's meaningless drivel. reply opentokix 9 hours agoprevI have read many of this types of blog posts about 10x, good engineers and such. The only thing I have learned during my close to 30 years of professional experience is how incredible rare they are. The really good engineers in IT. They are so rare so MOST people will never work with even one. That is how rare they are. And a \"Blogger, Writer, Philospher\" - have probably never worked with one, and never will. Because they are in a whole different sphere of engineering. The number of systems is increasing explonentially - the number of truely good engineer is pretty much a constant number. reply louwrentius 8 hours agoprevMaybe it's hard to accept that often, code quality or technical prowess are not that important. What is really important is understanding the actual process that is being supported by the thing you're building. It's so obvious but building something technically sound that doesn't address the actual organisational need is a 100% waste of time and has a huge opportunity cost. And the reality seems to be that the business and IT don't know the right answer upfront, so it's - cliché alert - a journey between professionals helping each other understand how a proces should operate. This has NOTHING to do with technology or technical implementations. At this level, tech is just an abstraction, a black box that does magic. reply andrewstuart 10 hours agoprevThe more a company attempts to define what a \"good software engineer\" is, the worse their hiring practices will become as they come to believe they can identify and select for \"good software engineers\". As the author says after articulating a long list of traits of a first class developer; \"I strongly believe all that I’ve mentioned is a basic expectation from any engineer.\" Folks, apply for jobs where the employer is pragmatic about hiring and gets people employed and gets on with the job. reply p0nce 9 hours agoparentYou don't see blogs about all the desirable properties of a software company with 10/10 in every direction. reply Joel_Mckay 9 hours agoparentprevProcess people can't resist trying to optimize things they superficially comprehend. When business ops tries to define how engineers with decades of experience should solve problems, it is usually a conversation with a firm heading for failure. Smart people usually just quickly leave a doomed project... =3 reply earthnail 9 hours agorootparent> Process people can't resist trying to optimize things they superficially comprehend. Wow, I don't think I ever heard it summarised so well. I cannot agree more with this statement. reply opentokix 8 hours agorootparentprevThis is so profound, I need a t-shirt \"Process people can't resist trying to optimize things they superficially comprehend.\" reply xnorswap 10 hours agoprevI don't like this re-framing of \"the 10x engineer\" to be someone who writes 10 times as much low-quality code. It might not have been a rigorous study and may largely be a myth, but the myth is about engineers who are 10 times as productive, even accounting for quality. reply roenxi 8 hours agoparentI don't think there are any myths involved, we can name people. Fabrice Bellard leaps to mind. A bunch of the OSS maintainers. These people are just observably (much more than) 10x more productive than the standard developer. People cast from the same mold turn up from time to time in the corporate world too. Part of it is problem selection, part of it is hard work, some fraction appears to be genius. But it is obvious and observable, I've seen average developers at work and they just won't achieve the results the top performers get even if given 10x as much time. reply sokoloff 8 hours agorootparentIt seems utterly obvious that there are 2x and 3x devs; we see them all around us. And there are outliers well above that level of common performance. The denial by some of the existence of 10x engineers is one of the ongoing baffling mysteries to me. reply offices 7 hours agorootparentThe same reason shows why the bimodal and 'branded' name is such a strange thing to focus on. Why only 10x? And why not try to make your 1x into 2x? It's like if sports fans spent all their time talking about a potential player who could deliver exactly 10 times more goals than everyone else. Why is this a topic that needs to be brought up so often? Why have we 'software engineer'-ised the idea that some people are much more important for productivity? reply xnorswap 7 hours agorootparentprevI should clarify that by referring to it as a myth, I'm not denying in my post that there are people who are 10x as productive as most people. The \"myth\" is that there was a formal study done and these performers were identified. The reality is that the study was looking at the difference best and worst performers, not best vs average, which is an important clarification. This has since evolved to a further myth that 10x programmers exist, but are somehow always harmful and should be avoided. There are plenty of articles examining \"The 10x programmer myth\" which, with no more evidence than the original assertion, put forward that 10x programmers should be avoided. And here in this article, it gets re-written again, that they aren't even 10x as productive, and just produce ten times as much in terms of LOC but it's all terrible code! reply sokoloff 7 hours agorootparent> The reality is that the study was looking at the difference best and worst performers, not best vs average, which is an important clarification. That is an important, often misunderstood, clarification, but I think it’s also subtly incorrect. It’s 10x higher than some minimally competent level, not 10x higher than the worst in the field. I think the original studies (certainly later follow-up studies did this) excluded results from participants who did not complete the assignment at all. That makes some sense from a data analysis convenience standpoint, but truncating the left tail and then saying some are 10x better than the absolute worst (that you truncated in the previous step) isn’t fully representative of what we see in the field. reply xnorswap 6 hours agorootparentIn any case, people on here tend to be extremely sceptical of social science results, and demand much better standards and reproducibility. Except that particular 1968 paper, which is held up and treated as gospel, because it helps to confirm rather than challenges their personal experience. If we are going to demand better, we should do so consistently. Reproducing that result with more rigour would be a useful start. reply sokoloff 5 hours agorootparentI group the skepticism that I see around this topic into two buckets. One is \"it's not 10x, but is maybe 4 or 5x\"; the other is \"if differences exist at all, it's definitely less than 2x\". I get/have sympathy and agreement for the first type on a technically-precise level, but it also doesn't really change any of my behavior as a technologist or people/org leader. The second type of skepticism I just don't understand at all from people who have worked more than a couple years in industry. reply throw4950sh06 7 hours agorootparentprevIt's completely opposite to the idea that a person's success in today's capitalism is only luck. reply rob74 9 hours agoparentprevA myth based on another myth... OTOH, it's definitely easier to be more productive if you cut corners (or \"incur technical debt\" if you want to say it in a more sophisticated way). Generally, a more productive developer will know where to focus their effort, e.g. understand the business logic so they don't spend time handling cases that won't happen in practice, know where tests are most needed and leave other areas for later, automate repetitive tasks or find tools that make a task easier, etc. reply andreasmetsala 7 hours agorootparentSometimes it’s not even about cutting corners. Just pushing back against poor meeting culture and declining pointless meetings can easily give you a 2x boost. reply fullstackwife 9 hours agoparentprev\"10x\" very often means you produced 10x less, while keeping the same value. reply ffsm8 8 hours agorootparentThat almost always ends with an architecture that only the original author can change, so hard disagree ^ _ _ _ _ ^ It's really pointless to quantify the productivity of a developer via numbers. It's a conjunction of knowledge, intelligence and ability to express this as code. reply phito 7 hours agorootparentAnd also communication. I find it weird how everyone is talking about the code, but a huge part of the job is communicating properly with others so that you don't produce useless code, and that others know how to properly integrate with it. reply gary_0 8 hours agoparentprevWhen I first heard \"10x\" I assumed it meant someone who had \"10x\" the effect with the same amount of effort. Someone experienced who can judo-chop problems away (if they're allowed to). Someone who force-multiplies everyone around them rather than being just another grinding cog. But nowadays \"10x\" just goes into the same pile I throw \"agile\" and other meaningless terms. reply marcusbuffett 9 hours agoparentprevYeah I'm also sick of seeing articles cite this mythical trade-off, where any increase in programming output must be correlated with being a bad team member, churning out bad code, and generally being a pain to work with. Anyone that's worked with engineers can tell you that there are simply some people getting more done than others, in the same amount of time. Are there people producing bad code? Yes. But I don't think output is inversely correlated with code quality. In fact the people I've worked with that have the most output, also had some of the highest quality code. I've never experienced this mythological 10x rockstar figure that works alone creating impossible to maintain systems, and I've worked closely with dozens of engineers. He probably exists somewhere, but not with the sort of prevalence that justifies every programming productivity article ripping on his archetype. reply kgeist 8 hours agorootparentIn our team's current project, the engineers who can be described as \"10x engineers\" are the slowest when it comes to delivery of features. They have been transferred to a legacy project with lacking tests, messy spaghetti code full of bugs. They spend a lot of time adding tests, refactoring the code to be more modular, removing various cruft. It looks like they are much slower than the previous mediocre engineers, and they produce a lot of code, but it pays off: while the userbase is increasing, our bug reports rate per month has decreased by 2x in a matter of 1.5 years. So I think the amount of code output is only part of the equation. reply earnesti 9 hours agorootparentprevIf a system is impossible to maintain, that system is nothing of value, and therefore doesn't fit to any sensible definition of 10x. I have always assumed that the 10x means value creation, not some kind of \"lines of code\" output or other nonsense. And for sure there are 10x programmers, maybe even 100x. I have been mostly working at startups and you see these early stage decisions and designs that create huge costs when the company starts to scale, similarly you have some decisions that might save huge amount of costs during the company life time, or allow better revenue generation etc. reply ownagefool 8 hours agorootparentprev> I've never experienced this mythological 10x rockstar figure that works alone creating impossible to maintain systems, and I've worked closely with dozens of engineers. I've seen this plenty of times. Recently I was trying to explain the pros and cons of micro-services, and more importantly, microrepos, with regards to automated testing. The lead engineer that said he'd quit if I colocated the tests with the app. Same place, they replaced all deploy system with argo, but every environment is pinned against main, which means you can no longer test a change without it going to all environments at the same time. In both cases, the engineers are actually much higher skilled than average and churn out / lead change, but they'd rather be chasing a fad and just don't care if their changes shit on other parts of the SDLC. reply earnesti 8 hours agorootparentThat case sounds more like you being 0.1x developer about obsessing over test automation, where the 1x guy just didn't seem them to be worthwile. Personally I have had clashes during my career with people who obsess about unit testing way too much in places where it just doesn't add any value (in fact destroys it by requiring lots of work and additional mainteinance). Value in the end is quite a subjective thing so it doesn't make sense to argue that much about it. reply ownagefool 7 hours agorootparentSo have I, and I'm pretty impressed you could decipher that from a single comment, and it doesn't reflect poorly on you at all that you immediately drew such a conclusion from someone refusing to discuss pros and cons of solutions. reply dailykoder 9 hours agoparentprevThis. My understanding of 10x engineers was, even if a bit tongue-in-cheek, always positive. They are the smart guys and girls that know what they are talking and think ahead a few miles. It sure can be overwhelming when you hear them talk, but if you let it sink it in, it makes sense. But we as a society should not pretend that this is what you have to be. There are just some smart people in the world, but they are rare. You don't need to be one to be a good person. reply JimDabell 8 hours agoparentprev> It might not have been a rigorous study and may largely be a myth, but the myth is about engineers who are 10 times as productive, even accounting for quality. There were several studies, and it’s about being 10× as productive as the worst not the average. https://www.construx.com/blog/the-origins-of-10x-how-valid-i... reply offices 7 hours agorootparentThen there are infinity-x engineers, because some problems just aren't solvable by the worst engineers. Or even typical engineers. It wouldn't take them 10 times as long as Linus to make Linux or git, social context and all. It just wouldn't happen. So what's the useful takeaway from this topic we spend so much energy on? 'Hire people who are good'? reply OvbiousError 9 hours agoparentprevFor me the 10x engineers don't write the same code as others faster, they come up with approaches and ideas that others simply don't think of, resulting in huge gains in terms of development speed and/or product features. reply carlmr 9 hours agorootparentIt's also environment dependent. Put a 10x engineer in a megacorp bureaucratized setting and they'll be slowed to the same crawl as everyone else. In many cases I've observed 10x engineers are those that can simplify and automate the processes and programs to need minimal human input. In some cases it's more about deleting code than producing it. reply gorgoiler 9 hours agoparentprevI too thought that immediately but I’d encourage you to read on (if you haven’t already) as the rest of the article — a list of bolded statements about good engineers with further explanation in each paragraph — is pretty solid in my opinion. reply valval 7 hours agoparentprevIf you’ve played the game RuneScape, you know well that some players accomplish feats that are hard to comprehend. You have people gaining billions of experience points or tens of thousands of boss kills in the same amount of calendar days the average player accomplishes tens of millions or hundreds of boss kills. I don’t see why this couldn’t be the case for software engineering. I have a wife and kids and spend 10 to 15 hours doing sports a week. I’m maybe more efficient than average since my career has gone well, but there are people who are way more efficient and way smarter than me. Couple that with them being able to spend twice or more the number of hours, and you might arrive at similar 10-100x productivity numbers that you see on the game RuneScape. reply revskill 7 hours agoprev [–] Good leetcoder is good engineerer reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Setting expectations for software engineers is complex due to diverse company needs, structures, and cultures, requiring managers to align these with new team members.- The concept of \"10x engineers\" is often misleading, as high output can negatively impact team morale and code quality.- A good engineer is defined by their ability to consistently deliver quality solutions, communicate effectively, understand processes, and adapt to organizational norms, while also having a growth mindset and being a team player."
    ],
    "commentSummary": [
      "Software engineers often face challenges when business changes lead to poor implementations, resulting in issues like security vulnerabilities for which they may be blamed.",
      "There is ongoing debate about whether engineers should legally own their code to prevent such issues and what defines a \"good\" engineer, with differing views on the importance of teamwork versus individual skills.",
      "The concept of a \"10x engineer,\" who is significantly more productive than peers, is controversial, with discussions on its potential benefits and drawbacks, emphasizing the need to balance technical skills with business understanding."
    ],
    "points": 102,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1730104853
  },
  {
    "id": 41965091,
    "title": "Platform Strategy and Its Discontents",
    "originLink": "https://infrequently.org/2024/10/platforms-are-competitions/",
    "originBody": "Platform Strategy and Its Discontents The web is losing. Badly. But a comeback is possible. October 27, 2024 This post is an edited and expanded version of a now-mangled Mastodon thread. Platforms Are Competitions ...and We're Losing Win Condition You Do It To Yourself, And That's What Really Hurts Groundhog Day Reboot Some in the JavaScript community imagine that I harbour an irrational dislike of their tools when, in fact, I want nothing more than to stop thinking about them. Live-and-let-live is excellent guidance, and if it weren't for React et. al.'s predictably ruinous outcomes, the public side of my work wouldn't involve educating about the problems JS-first development has caused. But that's not what strategy demands, and strategy is my job.[1] I've been holding my fire (and the confidences of consulting counterparties) for most of the last decade. Until this year, I only occasionally posted traces documenting the worsening rot. I fear this has only served to make things look better than they are. Over the past decade, my work helping teams deliver competitive PWAs gave me a front-row seat to a disturbing trend. The rate of failure to deliver usable experiences on phones was increasing over time, despite the eye-watering cost of JS-based stacks teams were reaching for. Worse and costlier is a bad combo, and the opposite of what competing ecosystems did. Native developers reset hard when moving from desktop to mobile, getting deeply in touch with the new constraints. Sure, developing a codebase multiple times is more expensive than the web's write-once-test-everywhere approach, but at least you got speed for the extra cost. But that's not what happened on the web. Contemporary frontend practice pretended that legacy-oriented, desktop-focused tools would perform fine in this new context, without ever checking if they did. When that didn't work, the toxic-positivity crowd blamed the messanger.[2] Frontend's tragically timed turn towards JavaScript means the damage isn't limited to the public sector or \"bad\" developers. Some of the strongest engineers I know find themselves mired in the same quicksand. Today's popular JS-based approaches are simply unsafe at any speed. The rot is now ecosystem-wide, and JS-first culture owns a share of the responsibility. But why do I care? Platforms Are Competitions # My primary motivation is that I want the web to win. What does that mean? Concretely, folks should be able to accomplish most of their daily tasks on the web. But capability isn't sufficient; for the web to win in practice, users need to turn to the browser for those tasks because it's easier, faster, and more secure. A reasonable diagnostic metric of success is time spent as a percentage of time on device. The fraction of \"Jobs To Be Done\" happening on the web would be the natural leading metric, but it's hard to track. This phrasing — fraction of time spent, rather than absolute time — has the benefit of not being thirsty. It's also tracked by various parties. OK, but why should anyone prefer one platform over another? As I see it, the web is the only generational software platform that has a reasonable shot at delivering a potent set of benefits to users: Fresh Frictionless Safe by default Portable and interoperable Gatekeeper-free (no prior restraint on publication)[3] Standards-based, and therefore... User-mediated (extensions, browser settings, etc.) Open Source compatible No other successful platform provides all of these today and others that could are too small to matter. Platforms like Android and Flutter deliver subsets of these properties but capitulate to capture by the host OS agenda, allowing their developers to be taxed through app stores and proprietary API lock-in. Most treat user mediation like a bug to be fixed. The web's inherent properties have created an ecosystem that is unique in the history of software, both in scope and resilience. ...and We're Losing # So why does this result in intermittent antagonism towards today's JS community? Because the web is losing, and instead of recognising that we're all in it together, then pitching in to right the ship, the Lemon Vendors have decided that predatory delay and \"I've got mine, Jack\"-ism is the best response. What do I mean by \"losing\"? Going back to the time spent metric, the web is cleaning up on the desktop. The web's JTBD percentage and fraction of time spent both continue to rise as we add new capabilities to the platform, displacing other ways of writing and delivering software, one fraction of a percent every year.[4] But make no mistake; the web is the indispensable ecosystem for desktop users. Who, a decade ago, thought the web would be such a threat to Adobe's native app business that it would need to respond with a $20BN acquisition attempt and a full-fledged version of Photoshop (real Photoshop) on the web? Model advantages grind slowly but finely. They create space for new competitors to introduce the intrinsic advantages of their platform in previously stable categories. But only when specific criteria are met. Win Condition # First and foremost, challengers need a cost-competitive channel. That is, users have to be able to acquire software that runs on this new platform without a lot of extra work. The web drops channel costs to nearly zero, assuming... 80/20 capability. Essential use-cases in the domain have to be (reliably) possible for the vast majority (90+%) of the TAM. Some nice-to-haves might not be there, but the model advantage makes up for it. Lastly... It has to feel good. Performance can't suck for core tasks.[5] It's fine for UI consistency with native apps to wander a bit.[6] It's even fine for there to be a large peak performance delta. But the gap can't be such a gulf that it generally changes the interaction class of common tasks. So if the web is meeting all these requirements on desktop – even running away with the lead – why am I saying \"the web is losing\"? Because more than 75% of new devices that can run full browsers are phones. And the web is getting destroyed on mobile. Utterly routed. It's not going well This is what I started warning about in 2019, and more recently on this blog. The terrifying data I had access to five years ago is now visible from space. Public data shows what I warned about, citing Google-private data, in 2019. In the US, time spent in browsers continues to stagnate while smartphone use grows, and the situation is even more dire outside the states. The result is a falling fraction of time spent. This is not a recipe for a healthy web. If that graph looks rough-but-survivable, understand that it's only this high in the US (and other Western markets) because the web was already a success in those geographies when mobile exploded. That history isn't shared in the most vibrant growth markets, meaning the web has fallen from \"minuscule\" to \"nonexistent\" as a part of mobile-first daily life globally. This is the landscape. The web is extremely likely to get cast in amber and will, in less than a technology generation, become a weird legacy curio. What happens then? The market for web developers will stop expanding, and the safe, open, interoperable, gatekeeper-free future for computing will be entirely foreclosed — or at least the difficulty will go from \"slow build\" to \"cold-start problem\"; several orders of magnitude harder (and therefore unlikely). This failure has many causes, but they're all tractable. This is why I have worked so hard to close the capability gaps with Service Workers, PWAs, Notifications, Project Fugu, and structural solutions to the governance problems that held back progress. All of these projects have been motivated by the logic of platform competition, and the urgency that comes from understanding that that web doesn't have a natural constituency.[7] If you've read any of my writing over this time, it will be unsurprising that this is why I eventually had to break silence and call out what Apple has done on iOS, and what Facebook and Android have done to more quietly undermine browser choice. These gatekeepers are kneecapping the web in different, but overlapping and reinforcing ways. There's much more to say here, but I've tried to lay out the landscape over the past few years,. But even if we break open the necessary 80/20 capabilities and restart engine competition, today's web is unlikely to succeed on mobile. You Do It To Yourself, And That's What Really Hurts # Web developers and browsers have capped the web's mobile potential by ensuring it will feel terrible on the phones most folks have. A web that can win is a web that doesn't feel like sludge. And today it does. This failure has many fathers. Browsers have not done nearly enough to intercede on users' behalf; hell, we don't even warn users that links they tap on might take them to sites that lock up the main thread for seconds at a time! Things have gotten so bad that even the extremely weak pushback on developer excess that Google's Core Web Vitals effort provides is a slow-motion earthquake. INP, in particular, is forcing even the worst JS-first lemon vendors to retreat to the server — a tacit acknowledgement that their shit stinks. So this is the strategic logic of why web performance matters in 2024; for the web to survive, it must start to grow on mobile. For that growth to start, we need the web to be a credible way to deliver these sorts of 80/20 capability-enabled mobile experiences with not-trash performance. That depends both on browsers that don't suck (we see you, Apple) and websites that don't consistently lock up phones and drain batteries. Toolchains and communities that retreat into the numbing comfort of desktop success are a threat to that potential. There's (much) more for browsers to do here, but developers that want the web to succeed can start without us. Responsible, web-ecology-friendly development is more than possible today, and the great news is that it tends to make companies more money, too! The JS-industrial-complex culture that pooh-poohs responsibility is self-limiting and a harm to our collective potential. Groundhog Day # Nobody has ever hired me to work on performance. It's (still) on my plate because terrible performance is a limiting factor on the web's potential to heal and grow. Spending nearly half my time diagnosing and remediating easily preventable failure is not fun. The teams I sit with are not having fun either, and goodness knows there are APIs I'd much rather be working on instead. My work today, and for the past 8 years, has only focused on performance today because until it's fixed the whole web is at risk. It's actually that dire, and the research I publish indicates that we are not on track to cap our JS emissions or mitigate them with CPUs fast enough to prevent ecosystem collapse. Contra the framework apologists, pervasive, preventable failure to deliver usable mobile experiences is often because we're dragging around IE8 compat and long toolchains premised on outdated priors like a ball and chain.[8] Reboot # Things look bad, and I'd be remiss if I didn't acknowledge that it could just be too late. Apple and Google and Facebook, with the help of a pliant and credulous JavaScript community, might have succeeded where 90s-era Microsoft failed — we just don't know it yet. But it seems equally likely that the web's advantages are just dormant. When browser competition is finally unlocked, and when web pages aren't bloated with half a megabyte of JavaScript (on average), we can expect a revolution. But we need to prepare for that day and do everything we can to make it possible. Failure and collapse aren't pre-ordained. We can do better. We can grow the web again. But to do that, the frontend community has to decide that user experience, the web's health, and their own career prospects are more important than whatever JS-based dogma VC-backed SAAS vendors are shilling this month. My business card says \"Product Manager\" which is an uncomfortable fudge in the same way \"Software Engineer\" was an odd fit in my dozen+ years on the Chrome team. My job on both teams has been somewhat closer to \"Platform Strategist for the Web\". But nobody hires platform strategists, and when they do, it's to support proprietary platforms. The tactics, habits of mind, and ways of thinking about platform competition for open vs. closed platforms could not be more different. Indeed, I've seen many successful proprietary-platform folks try their hand at open systems and bounce hard off the different constraints, cultures, and \"soft power\" thinking they require. Doing strategy on behalf of a collectively-owned, open system is extremely unusual. Getting paid to do it is almost unheard of. And the job itself is strange; because facts about the ecosystem develop slowly, there isn't a great deal to re-derive from current events. Companies also don't ask strategists to design and implement solutions in the opportunity spaces they identify. But solving problems is the only way to deliver progress, so along with others who do roughly similar work, I have camped out in roles that allow arguments about the health of the web ecosystem to motivate the concrete engineering projects necessary to light the fuse of web growth. Indeed, nobody asked me to work on web performance, just as nobody asked me to develop PWAs, in the same way that nobody asked me to work on the capability gap between web and native. Each one falls out of the sort of strategy analysis I'm sharing in this post for the first time. These projects are examples of the sort of work I think anyone would do once they understood the stakes and marinated in the same data. Luckily, inside of browser teams, I've found that largely to be true. Platform work attracts long-term thinkers, and those folks are willing to give strategy analysis a listen. This, in turn, has allowed the formation of large collaborations (like Project Fugu and Project Sidecar to tackle the burning issues that pro-web strategy analysis yields. Strategy without action isn't worth a damn, and action without strategy can easily misdirect scarce resources. It's a strange and surprising thing to have found a series of teams (and bosses) willing to support an oddball like me that works both sides of the problem space without direction. So what is it that I do for a living? Whatever working to make the web a success for another generation demands. ↩︎ Just how bad is it? This table shows the mobile Core Web Vitals scores for every production site listed on the Next.js showcase web page as of Oct 2024. It includes every site that gets enough traffic to report mobile-specific data, and ignores sites which no longer use Next.js:[9] Mobile Core Web Vitals statistics for Next.js sites from Vercel's showcase, as well as the fraction of mobile traffic to each site. The last column indicates CWV stats (LCP, INP, and CLS) that consistently passed over the past 90 days. Tap column headers to sort. Site mobile LCP (ms) INP (ms) CLS 90d pass Sonos 70% 3874 205 0.09 1 Nike 75% 3122 285 0.12 0 OpenAI 62% 2164 387 0.00 2 Claude 30% 7237 705 0.08 1 Spotify 28% 3086 417 0.02 1 Nerdwallet 55% 2306 244 0.00 2 Netflix Jobs 42% 2145 147 0.02 3 Zapier 10% 2408 294 0.01 1 Solana 48% 1915 188 0.07 2 Plex 49% 1501 86 0.00 3 Wegmans 58% 2206 122 0.10 3 Wayfair 57% 2663 272 0.00 1 Under Armour 78% 3966 226 0.17 0 Devolver 68% 2053 210 0.00 1 Anthropic 30% 4866 275 0.00 1 Runway 66% 1907 164 0.00 1 Parachute 55% 2064 211 0.03 2 The Washington Post 50% 1428 155 0.01 3 LG 85% 4898 681 0.27 0 Perplexity 44% 3017 558 0.09 1 TikTok 64% 2873 434 0.00 1 Leonardo.ai 60% 3548 736 0.00 1 Hulu 26% 2490 211 0.01 1 Notion 4% 6170 484 0.12 0 Target 56% 2575 233 0.07 1 HBO Max 50% 5735 263 0.05 1 realtor.com 66% 2004 296 0.05 1 AT&T 49% 4235 258 0.18 0 Tencent News 98% 1380 78 0.12 2 IGN 76% 1986 355 0.18 1 Playstation Comp Ctr. 85% 5348 192 0.10 0 Ticketmaster 55% 3878 429 0.01 1 Doordash 38% 3559 477 0.14 0 Audible (Marketing) 21% 2529 137 0.00 1 Typeform 49% 1719 366 0.00 1 United 46% 4566 488 0.22 0 Hilton 53% 4291 401 0.33 0 Nvidia NGC 3% 8398 635 0.00 0 TED 28% 4101 628 0.07 1 Auth0 41% 2215 292 0.00 2 Hostgator 34% 2375 208 0.01 1 TFL \"Have your say\" 65% 2867 145 0.22 1 Vodafone 80% 5306 484 0.53 0 Product Hunt 48% 2783 305 0.11 1 Invision 23% 2555 187 0.02 1 Western Union 90% 10060 432 0.11 0 Today 77% 2365 211 0.04 2 Lego Kids 64% 3567 324 0.02 1 Staples 35% 3387 263 0.29 0 British Council 37% 3415 199 0.11 1 Vercel 11% 2307 247 0.01 2 TrueCar 69% 2483 396 0.06 1 Hyundai Artlab 63% 4151 162 0.22 1 Porsche 59% 3543 329 0.22 0 elastic 11% 2834 206 0.10 1 Leafly 88% 1958 196 0.03 2 GoPro 54% 3143 162 0.17 1 World Population Review 65% 1492 243 0.10 1 replit 26% 4803 532 0.02 1 Redbull Jobs 53% 1914 201 0.05 2 Marvel 68% 2272 172 0.02 3 Nubank 78% 2386 690 0.00 2 Weedmaps 66% 2960 343 0.15 0 Frontier 82% 2706 160 0.22 1 Deliveroo 60% 2427 381 0.10 2 MUI 4% 1510 358 0.00 2 FRIDAY DIGITAL 90% 1674 217 0.30 1 RealSelf 75% 1990 271 0.04 2 Expo 32% 3778 269 0.01 1 Plotly 8% 2504 245 0.01 1 Sumup 70% 2668 888 0.01 1 Eurostar 56% 2606 885 0.44 0 Eaze 78% 3247 331 0.09 0 Ferrari 65% 5055 310 0.03 1 FTD 61% 1873 295 0.08 1 Gartic.io 77% 2538 394 0.02 1 Framer 16% 8388 222 0.00 1 Open Collective 49% 3944 331 0.00 1 Õhtuleht 80% 1687 136 0.20 2 MovieTickets 76% 3777 169 0.08 2 BANG & OLUFSEN 56% 3641 335 0.08 1 TV Publica 83% 3706 296 0.23 0 styled-components 4% 1875 378 0.00 1 MPR News 78% 1836 126 0.51 2 Me Salva! 41% 2831 272 0.20 1 Suburbia 91% 5365 419 0.31 0 Salesforce LDS 3% 2641 230 0.04 1 Virgin 65% 3396 244 0.12 0 GiveIndia 71% 1995 107 0.00 3 DICE 72% 2262 273 0.00 2 Scale 33% 2258 294 0.00 2 TheHHub 57% 3396 264 0.01 1 A+E 61% 2336 106 0.00 3 Hyper 33% 2818 131 0.00 1 Carbon 12% 2565 560 0.02 1 Sanity 10% 2861 222 0.00 1 Elton John 70% 2518 126 0.00 2 InStitchu 27% 3186 122 0.09 2 Starbucks Reserve 76% 1347 87 0.00 3 Verge Currency 67% 2549 223 0.04 1 FontBase 11% 3120 170 0.02 2 Colorbox 36% 1421 49 0.00 3 NileFM 63% 2869 186 0.36 0 Syntax 40% 2531 129 0.06 2 Frog 24% 4551 138 0.05 2 Inflect 55% 3435 289 0.01 1 Swoosh by Nike 78% 2081 99 0.01 1 Passing %38% 28% 72% 8% Needless to say, these results are significantly worse than those of responsible JS-centric metaframeworks like Astro or HTML-first systems like Eleventy. Spot-checking their results gives me hope. Failure doesn't have to be our destiny, we only need to change the way we build and support efforts that can close the capability gap. ↩︎ Web developers aren't the only ones shooting their future prospects in the foot. It's bewildering to see today's tech press capitulate to the gatekeepers. The Register stands alone in using above-the-fold column inches to cover just how rancid and self-dealing Apple, Google, and Facebook's suppression of the mobile web has been. Most can't even summon their opinion bytes to highlight how broken the situation has become, or how the alternative would benefit everyone, even though it would directly benefit those outlets themselves. If the web has a posse, it doesn't include The Verge or TechCrunch. ↩︎ There are rarely KOs in platform competitions, only slow, grinding changes that look \"boring\" to a tech press that would rather report on social media contratemps. Even the smartphone revolution, which featured never before seen device sales rates, took most of a decade to overtake desktop as the dominant computing form-factor. ↩︎ The web wasn't always competitive with native on desktop, either. It took Ajax (new capabilities), Moore's Law (RIP), and broadband to make it so. There had to be enough overhang in CPUs and network availability to make the performance hit of the web's languages and architecture largely immaterial. This is why I continue to track the mobile device and network situation. For the mobile web to take off, it'll need to overcome similar hurdles to usability on most devices. The only way that's likely to happen in the short-to-medium term is for developers to emit less JS per page. And that is not what's happening. ↩︎ One common objection to metaplatforms like the web is that the look and feel versus \"native\" UI is not consistent. The theory goes that consistent affordances create less friction for users as they navigate their digital world. This is a nice theory, but in practice the more important question in the fight between web and native look-and-feel is which one users encounter more often. The dominant experience is what others are judged against. On today's desktops, browsers that set the pace, leaving OSes with reduced influence. OS purists decry this as an abomination, but it just is what it is. \"Fixing\" it gains users very little. This is particularly true in a world where OSes change up large aspects of their design languages every half decade. Even without the web's influence, this leaves a trail of unreconciled experiences sitting side-by-side uncomfortably. Web apps aren't an unholy disaster, just more of the same. ↩︎ No matter how much they protest that they love it (sus) and couldn't have succeeded without it (true), the web is, at best, an also-ran in the internal logic of today's tech megacorps. They can do platform strategy, too, and know that that exerting direct control over access to APIs is worth its weight in Californium. As a result, the preferred alternative is always the proprietary (read: directly controlled and therefore taxable) platform of their OS frameworks. API access gatekeeping enables distribution gatekeeping, which becomes a business model chokepoint over time. Even Google, the sponsor of the projects I pursued to close platform gaps, couldn't summon the organisational fortitude to inconvenience the Play team for the web's benefit. For its part, Apple froze Safari funding and API expansion almost as soon as the App Store took off. Both benefit from a cozy duopoly that forces businesses into the logic of heavily mediated app platforms. The web isn't suffering on mobile because it isn't good enough in some theoretical sense, it's failing on mobile because the duopolists directly benefit from keeping it in a weakened state. And because the web is a collectively-owned, reach-based platform, neither party has to have their fingerprints on the murder weapon. At current course and speed, the web will die from a lack of competitive vigour, and nobody will be able to point to the single moment when it happened. That's by design. ↩︎ Real teams, doing actual work, aren't nearly as wedded to React vs., e.g., Preact or Lit or FAST or Stencil or Qwik or Svelte as the JS-industrial-complex wants us all to believe. And moving back to the server entirely is even easier. React is the last of the totalising frameworks. Everyone else is living in the interoperable, plug-and-play future (via Web Components). Escape doesn't hurt, but it can be scary. But teams that want to do better aren't wanting for off-ramps. ↩︎ It's hard to overstate just how fair this is to the over-Reactors. The (still) more common Create React App metaframework starter kit would suffer terribly by comparison, and Vercel has had years of browser, network, and CPU progress to water down the negative consequences of Next.js's blighted architecture. Next has also been pitched since 2018 as \"The React Framework for the Mobile Web\" and \"The React Framework for SEO-Friendly Sites\". Nobody else's petard is doing the hoisting; these are the sites that Vercel is chosing to highlight, built using their technology, which has consistently advertised performance-oriented features like code-splitting and SSG support. ↩︎ Previously: \"Reckoning: Part 4 — The Way Out\"",
    "commentLink": "https://news.ycombinator.com/item?id=41965091",
    "commentBody": "Platform Strategy and Its Discontents (infrequently.org)102 points by wmanley 23 hours agohidepastfavorite55 comments DeathArrow 11 hours agoI agree with points about openness and gate keeping. But from my point of view, the web is the worst platform to run apps. I worked on microcontrollers, system software, desktop software, mobile apps, games and now I am a full stack web developer who mostly does backend and defers most of the front-end tasks to colleagues. I don't like JS frameworks and it was far more enjoyable for me to use QT, Borland C++Builder, Windows Forms XCode and Android Studio than to use Angular and React and even Vue. Aside from Web front-end to being a less enjoyable experience for me, the Web was designed for websites, not for apps. Web as an app platform means subpar experience for the users, too. We tried with Flash and Java applets running in the browser. Those died and now we have the Javascript mess. When, if ever, Wasm will have full access to browser DOM, maybe we can get rid of the Javascript mess. But then, again, why bother running a binary app in the browser when you can run it on the desktop or phone? And even if web as an app platform is said to promote openness and impede gatekeeping it still has a terrible downside for the end user: it makes the user rent the software instead of owning it. reply pjmlp 9 hours agoparentThe issue with renting software, is that it will happen even in native apps, because it is the only way most companies can get some money out of their products. Piracy doesn't bring any money, and forever licenses don't scale to keep a steady income per month after the user base is settled, and everyone likes to get a steady income for their work. reply JimDabell 3 hours agorootparentBusinesses worth billions of dollars were built by selling forever licenses. Pretty much every big B2C software company that is older than 15 years got that big selling forever licenses. Microsoft got big selling forever licenses to Windows and Office. Adobe got big selling forever licenses to Photoshop. Every games company, etc. We know with certainty that selling forever licenses scales because we have concrete examples of it happening with some of the largest software companies in history. SaaS is only a recent trend, it’s not the only feasible way to make money with software. reply pjmlp 3 hours agorootparentOnly to the point PC market was still growing, and continuous OS updates required paying for new versions of the same stuff. I was there, leaving piracy aside, buying new versions were only when going from MS-DOS to Windows 3.x, to OS/2, to Window 95, to Atari, to Amiga, and so forth. That market has plateaued, there are no exponential growth curves any longer, to keep everyone on their job, and the shareholders happy. reply aragilar 9 hours agorootparentprevTrue, but it's much easier for web apps to alter the deal than native apps, given most of their local state is ephemeral and hard to access, and much of the useful data, and potentially even software, is on the server. How many emulators are there for web apps, compared with emulators for nearly every popular OS/platform in the last 40 years? reply pjmlp 9 hours agorootparentIt is just as easy with native apps distributed via app stores, which is why most companies aren't that bothered with gatekeeping, as folks in sites like HN. Emulators for Web apps doesn't make sense, that is a browser. reply aragilar 6 hours agorootparentIt naturally depends on the app (e.g. an app that simply calls out to an API naturally has the same issues whether it is native or not), but native apps tend to work offline, and you have the binary in a somewhat self-contained form, so you can (with the level of effort varying on platform, and the state of the available emulators) run the app with your data on a different machine/system. For local-first web apps, which would be the easiest web apps to do this with, you have to fight the browser to do this, and I'm not sure how you would be able to dump out the state and code of a web app on Android Chrome and load it in Desktop Firefox. That and being able to update/modify the app locally permanently (and maybe even control updates) would I think make the equivalent of a web app emulator. reply Tarq0n 8 hours agorootparentprevEmulating a client-server application usually entails emulating the server, and only minimally modifying the client. reply DeathArrow 9 hours agorootparentprev> Piracy doesn't bring any money, and forever licenses don't scale to keep a steady income per month after the user base is settled, and everyone likes to get a steady income for their work. How about selling a new version with more features? That used to work in the past. Or sell a new software. That used to work, too. reply pjmlp 9 hours agorootparentBecause as I clearly pointed out \" forever licenses don't scale to keep a steady income per month after the user base is settled\". After a tipping point no one is buying new versions in an amount that can keep the salaries of the building rent, employees salaries, company taxes and whatever else is required monthly in a continuous flow that can keep the company going, without starting to cut down business costs. The only new feature most will care about is that the version they own doesn't run on the new OS. It is exactly the same thing as people stuck in Java 8, Python 2, .NET Framework, C99, C++11,... it works for the purposes of their employeer, and the costs to upgrade doesn't justify the outcome, unless forced by external factors. Subscriptions started exactly because that model doesn't scale. Anyone that starts a business quickly discovers how \"easy\" these things are in practice. reply adamc 4 hours agorootparentRight, so you build a business out around forcing people to buy something they don't need (updates). That seems... fragile. It will work for products I need and have no good alternatives for, but. Then again, when apps require subscriptions I avoid them, 100% of the time. reply pjmlp 3 hours agorootparentIf there isn't enough people paying it isn't a business to start with. Easy, make the math how much packages you need to sell each month to keep your salary. Then add up everything else a business depends on. reply jbjohns 5 hours agoparentprevThe founder of Leptos makes a pretty good argument [1] that the bottleneck for WASM isn't really the DOM and that they are already faster than some popular JS frameworks even with the current constraints. [1] https://youtu.be/4KtotxNAwME?si=IEZ5kRHR_W2o9i_k reply pjmlp 5 hours agorootparentJust tried the site, and already the first problem is isn't as interactive as the Websites for any JavaScript framework, because naturally there is a whole contraption to make the code run into the browser. reply cobbzilla 8 hours agoparentprevYou may be interested in the concept of “local-first” software — https://www.inkandswitch.com/local-first/ Data storage concerns are orthogonal to app distribution method, as others have pointed out. reply skybrian 19 hours agoprevI'm looking at the list of top websites and thinking \"when have I ever wanted to install the mobile app?\" The only one I see that I use is Spotify. Maybe the time spent on mobile is in other apps? But I'm probably an outlier because I spend most of my time on websites, even on phone and tablet. It would be nice to see this broken down by market segment. I don't see any banks in the list. I use my bank's app for certain reasons like depositing checks and Zelle. reply gruez 17 hours agoparent>But I'm probably an outlier because I spend most of my time on websites, even on phone and tablet. Meanwhile our users are clamoring for app version of our web app, even though it's just a web wrapper. I guess some people just have a \"there's an app for that\" mentality. reply tonyhart7 6 hours agoparentprevbecause western especially people got to tech has more chance to comfortable being on the web than the app example of Gen Z and alpha social media addict that used to use Tiktok,Snaps etc You cant deny that the use of web is dying and I still not mentioning Asia market where mobile is the first choice reply skybrian 2 hours agorootparentThis seems like the revenge of TV. People used to spend many hours watching TV and now video is back, with algorithms that try to give you more stimulating things to watch. Other entertainment (like video games) have to compete with that. But I’m not sure that websites have to compete with that if they have more practical purposes. What will people do when not watching TV? The metric of “hours spent on entertainment” doesn’t seem like the right one to use. It doesn’t measure the value you get from an activity or how much you’re willing to spend on it. For example, does a banking app need to try to compete with video games for hours spent on them? Something seems wrong with that comparison. reply nchmy 17 hours agoparentprevI think what youre missing is that most of these are just websites, not \"apps\". And they suck reply amadeuspagel 19 hours agoprevThe article refers to the JS-industrial-complex but only has stats for NextJS[1]. Maybe other frameworks are better? I would love to see a similar chart for the showcases of other frameworks. [1]: https://infrequently.org/2024/10/platforms-are-competitions/... reply devjab 20 hours agoprevThis is a very good article and I agree with most of it. I never really understood why React and Angular became big for the general web. They have a lot of usage in enterprise applications, where you typically access them from a “pc”, but even then they suck on the tablets your employees drive around with. At least for the most part they don’t suck that much worse than the terrible native clients that came before (and still do in the rare case that a supplier actually build a native mobile app). Why that spread to the wider web is beyond me though. I get why you would use it for personal projects if it’s your day time job anyway, but a page reload never hurt anyone. I personally think that the most responsible “father” is finance. The article states that there is more money with the web, but in my experience it’s far easier to lock down payments through apps. I agree that part of this is because native apps are better on mobile, but they are also much easier to work with and consume. It’s not easy to make payments function well on the web while in a native app it’s just a click with well powered api behind it. Serving both users and developers. Now, it probably could be easier on the web, but who would deliver it? The article calls out Apple and to some degree Google as guilty of not making browsers competitive with mobile apps, but why would they? If anything it’s in their best interest to keep the web shitty on mobile. reply righthand 5 hours agoparentThey became big because those companies paid for tech evangelism. People got excited and adopted, which in turn created more evangelists (unpaid) for those frameworks. Compare them to HTMX that only has unpaid evangelists, each time it is brought up on HN, people compare it to React because of the strong base around React, creates a lens of how people see the world. Even though HTMX is a completely different framework with different intents. reply gruez 17 hours agoparentprev>I never really understood why React and Angular became big for the general web. As opposed to what? Server side rendered pages with random jquery snippets sprinkled around for interactivity? I prefer the reactive model far more than manually trying to update the page myself. reply pjmlp 9 hours agorootparentApparently SSR is quite hot in JS frameworks, after a new generation rediscovered how we oldies do Web development in .NET, Java, Ruby, Python, Go, PHP.... reply devjab 11 hours agorootparentprevYou could just do page reloads. Of course if you don’t really need very advanced authentication with role-based access control there is also HTMX which is around 10kb. reply pards 6 hours agoprevWhat does the OP mean by \"web\" in this context? - UI running in browsers? - TCP/IP? - HTTP(S)? I personally think ReST APIs accessed over HTTP + TCP/IP have a lot of utility but I think we can do better on the UI front. Maybe we need an alternative to the web browser that can run a different (or variety of) languages other than Javascript, with a better presentation option than the DOM. reply crabmusket 6 hours agoparentThis is a lengthy quote from TFA but I think it best describes what the author means by \"the web\" in practical terms:As I see it, the web is the only generational software platform that has a reasonable shot at delivering a potent set of benefits to users: - Fresh - Frictionless - Safe by default - Portable and interoperable - Gatekeeper-free (no prior restraint on publication) - Standards-based, and therefore... - User-mediated (extensions, browser settings, etc.) - Open Source compatible No other successful platform provides all of these today and others that could are too small to matter. Platforms like Android and Flutter deliver subsets of these properties but capitulate to capture by the host OS agenda, allowing their developers to be taxed through app stores and proprietary API lock-in. Most treat user mediation like a bug to be fixed.The DOM seems critical to the user mediation goal, and user mediation is IMO a critical differentiator with other platforms. E.g. the web would be way less cool if I couldn't have \"reader mode\". reply arkh 4 hours agorootparentMaybe the root problems are HTML and its browsers. Or more exactly: the fact HTML is about documents. Everything done to make apps from it are hacks. What would be really needed is an open application format standard and a protocol to share it and maybe interact with it. And open source clients able to run those applications. reply BlueTemplar 2 hours agorootparentHow would it be different from the standards and protocols we have now ? reply ickelbawd 20 hours agoprevI have some sympathy for this viewpoint. And I think Alex’s heart is in the right place—Nextjs is a dumpster fire and react server components are when react finally jumped the shark for me. Maybe if we had HTML6 we wouldn’t be in this scenario. HTML5 was great but form building on the web (without JS) is a second-rate experience. And it’s even more miserable once JS is in the mix, but hey developers can provide a much better UX for end users than HTML and CSS alone could possibly provide. Sorry Alex, but without JS the web would have died a decade ago as phones took over. It’s only JS that keeps us in the ring. reply Devasta 20 hours agoparentHTML can never be improved, that is at the very foundation of its current form. We are 20 years into the takeover from the W3C and still can't even do a PUT request without JS, nevermind anything approaching even one tenth of the functionality of XForms. The web of semantic documents died years ago, it's an application platform now and that means JS. HTML is naught but a payload carrier. reply aragilar 9 hours agorootparenthttps://alexanderpetros.com/triptych/ will hopefully address that. reply Devasta 5 hours agorootparentI wish them luck, but the last time this was attempted it was rejected as it apparently doesn't make sense that you would even want to do it in the first place. https://www.w3.org/Bugs/Public/show_bug.cgi?id=10671#c16 reply pjmlp 9 hours agorootparentprevI was really disappointed that XHTML effort was killed by the HTML5 folks, we could be so much better, but it is as it is. reply Devasta 5 hours agorootparentThe founding members of the WHATWG really are the Thomas Midgley's of the software world. The world will spend the next century of software development trying to repair their screwups. reply pjmlp 3 hours agorootparentIronically that work is now being made obsolete with apps regaining the role of native apps, or the plugins revenge via WebGL/WebGPU/WebAssembly. reply forgetfreeman 13 hours agorootparentprevAll true, but an error doesn't become a mistake until you refuse to correct it. Perhaps it is finally time to let the web-as-an-application-layer paradigm die? reply andrewflnr 18 hours agoparentprevHe's not opposed to JS entirely (he specifically praises a handful of JS-based tech like ServiceWorkers), more so the all-JS single page type of app. To be fair he definitely could have been more clear about what he's talking about and what lines he's drawing. reply nchmy 17 hours agorootparentHe has dozens of other exceptional essays on his site, and plenty on social media and conference talks. Check them out. reply ec109685 18 hours agorootparentprevAll the desktop apps he cited that are a threat to native are SPA’s so it doesn’t seem like he hates them everywhere. I agree though it’s very odd that desktop web apps are serviceable, while they universally are horrible on mobile. reply andrewflnr 17 hours agorootparentBecause their performance falls below acceptable levels specifically on (relatively slower) mobile devices. It takes a looong time for him to get around to it, but performance (specifically UI latency) is the crux of the whole article, as I read it at least. reply marcus_holmes 17 hours agorootparentYeah, I read this (and some of his linked articles) as pointing out that Apple are specifically killing browser performance and features so that PWAs cannot compete with apps on iOS. Specifically because they can't claim 30% of revenue from web apps. reply JimDabell 8 hours agorootparentIt’s wishful thinking. Apple is being used as a scapegoat for the web’s failings here. PWAs would be so successful if it weren’t for Apple! is the easy but wrong answer. It’s possible to deploy a PWA to Google Play so that it’s installed on Android just like a native Android app. If PWAs were as good as native apps, why would anybody build web + iOS + Android instead of just building web + iOS? Even if opening a PWA made an iPhone explode into flames, it would still be worth deploying the PWA to Google Play to eliminate Android development effort. But plenty of native Android apps are still being built every day. That’s not because of Apple. That’s because users prefer native. I am a huge fan of the architecture of the WWW. I think it’s the most successful API and platform in history for a reason. But there are a lot of reasons why people genuinely prefer native apps, and it doesn’t just boil down to mean old Apple refusing to support things or users being brainwashed. People still choose native over web when Apple is not a factor at all. Every single native Android app is a testament to that. So when people also choose native over web on iOS, why should we think that this is down to Apple and not for the same reasons they choose native over web on Android? It doesn’t help that the web platform veered off into web components either. When front-end developers were jumping on board React, Vue, Angular, etc., architecture astronauts working on the web platform spat out an unholy mess full of footguns. I prefer to work as close to the web platform as possible, so every so often I try again with web components before remembering how painful they are. The people working on web components should take a long hard look at why front-end developers keep choosing frameworks that either eschew web components altogether or abstract them so far away the user doesn’t have to think about them. Telling quote from the Svelte 5 announcement last week: > Equally, component composition is more awkward in Svelte 4 than it should be […] This is because in 2019 it seemed likely that web components would become the primary distribution mechanism for components, and we wanted to align with the platform. This was a mistake. — https://svelte.dev/blog/svelte-5-is-alive I really hope the web does better, but in order for it to do so we need to be more honest about its failings. If you are a front-end developer and you feel optimistic about the future of web development, I invite you to try writing something reasonably complex using web components instead of your normal framework. reply pjmlp 5 hours agorootparentNot only Google, Microsoft is also a big pusher of PWAs, or used to be. reply photonthug 11 hours agorootparentprev> Specifically because they can't claim 30% of revenue from web apps. This feels true, but it’s just one horn of the dilemma. The other is where websites wreck their own UX intentionally to herd users towards apps, presumably because pushing ads isn’t as lucrative as grabbing location data, contact lists, or whatever else can be legally exfiltrated and sold. It’s weird to frame this problem as if it were all the fault of whatever trends in js development or browser development (even though I agree those trends often seem foolish and messy, at least to the outsider). The whole situation the author bemoans just looks like another symptom of surveillance capitalism, enshittification, etc, call it what you will. Even with a perfect web, users will still get pushed towards apps if apps are the best way to exploit the user. There’s no other calculus of platform aesthetics or excellence going on here reply marcus_holmes 10 hours agorootparentAgree. I think it's entirely possible that both Apple and other businesses are pushing people to apps (by destroying their website productivity), for different reasons. reply amadeuspagel 19 hours agoparentprevThe author actually links to the NextJS page for server components as \"a tacit acknowledgement that their shit stinks\". I guess this is how you acknowledge progress if you want to write an article in the tone that is expected on HN and mastodon now. reply aragilar 9 hours agoparentprevI doubt he's opposed to JS, given the number of new JS APIs he pushed Chrome to implement as part of Project Fugu, he seems more opposed to specific frameworks. reply DeathArrow 11 hours agoparentprev>Sorry Alex, but without JS the web would have died a decade ago as phones took over. It’s only JS that keeps us in the ring. Not really. Web would still be there but for websites not web apps. The web was designed for hypertext, a medium that is just supposed to deliver information not build apps upon. reply DeathArrow 11 hours agoprevHow bad will it be if we will run apps on desktop and phones instead of the web? Does the Facebook app provide a worse experience on the phone than the web app? Is Gmail phone app worse than Gmail web app? reply forgetfreeman 13 hours agoprev [–] Pretty solid take on a roiling shitstorm that's been brewing for at least the last 15 years. One thing I strongly disagree with the author about is wanting the web to win. Of all possible outcomes the web coming out on top of the platform wars is the worst available. Simple fact of the matter is the web wasn't built for any of this shit as our bloated and still wildly insecure browsers demonstrate rather vividly. The web defaulting back to a largely static information display medium would free up so much client budget and development hours it's hard to imagine that multi-OS support for native apps wouldn't be a net savings over the long haul. Hell, just imagine the kinds of resources that would free up if forced migration of highly dynamic websites was a thing of the past (yeah I'm looking at you Drupal). reply crabmusket 6 hours agoparent [–] What are you suggesting complex Drupal sites be migrated to? reply forgetfreeman 4 hours agorootparent [–] Most would get migrated into the void where they belong. A small handful that have real use cases would have their interactive services ported to native app. Solutions already exist for commerce and donations features, remote data entry and retrieval would need a rethink I'm guessing. As with any massive paradigm shift there'd be a cull. I strongly doubt much of value would be lost. reply emushack 3 hours agorootparent [–] Do you know what Drupal is used for? Can you seriously imagine migrating that stuff to native apps? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The web is facing challenges on mobile platforms due to heavy reliance on JavaScript and platform control by major companies like Apple and Google.- Despite its open and portable nature, the web is losing competitiveness on mobile devices, where most new usage occurs, due to performance issues.- To improve the web's future, developers should prioritize performance, reduce JavaScript bloat, and adopt efficient frameworks, emphasizing collaboration and strategic enhancements."
    ],
    "commentSummary": [
      "The web is often criticized for being a suboptimal platform for applications, with developers favoring native development tools like QT and Android Studio over JavaScript frameworks such as Angular and React.",
      "While Software as a Service (SaaS) is popular, the traditional model of selling perpetual licenses has been historically successful, highlighting a preference for ownership over rental.",
      "The debate persists on whether the web should continue evolving as an app platform or revert to its original purpose as a medium for static information, given its limitations in app capabilities due to browser constraints."
    ],
    "points": 102,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1730058371
  }
]
