[
  {
    "id": 42412718,
    "title": "OpenAI whistleblower found dead in San Francisco apartment",
    "originLink": "https://www.mercurynews.com/2024/12/13/openai-whistleblower-found-dead-in-san-francisco-apartment/",
    "originBody": "Breaking News Bay Area storm: More rain on the way, flood and wind advisories take effect BUSINESSTECHNOLOGYNEWSNEWS BASED ON FACTS, EITHER OBSERVED AND VERIFIED DIRECTLY BY THE REPORTER, OR REPORTED AND VERIFIED FROM KNOWLEDGEABLE SOURCES. OpenAI whistleblower found dead in San Francisco apartment Suchir Balaji, 26, claimed the company broke copyright law Suchir Balaji, a former OpenAi employee, in San Francisco, on Oct. 3, 2024. Balaji helped gather and organize the enormous amounts of internet data used to train the startup’s ChatGPT chatbot. (Ulysses Ortega/The New York Times) By JAKOB RODGERSjrodgers@bayareanewsgroup.comBay Area News Group UPDATED: December 14, 2024 at 9:56 AM PST SAN FRANCISCO — A former OpenAI researcher known for whistleblowing the blockbuster artificial intelligence company facing a swell of lawsuits over its business model has died, authorities confirmed this week. Suchir Balaji, 26, was found dead inside his Buchanan Street apartment on Nov. 26, San Francisco police and the Office of the Chief Medical Examiner said. Police had been called to the Lower Haight residence at about 1 p.m. that day, after receiving a call asking officers to check on his well-being, a police spokesperson said. Suchir Balaji, a former OpenAi employee, in San Francisco, on Oct. 3, 2024. Balaji helped gather and organize the enormous amounts of internet data used to train the startup’s ChatGPT chatbot. (Ulysses Ortega/The New York Times) The medical examiner’s office determined the manner of death to be suicide and police officials this week said there is “currently, no evidence of foul play.” Information he held was expected to play a key part in lawsuits against the San Francisco-based company. Balaji’s death comes three months after he publicly accused OpenAI of violating U.S. copyright law while developing ChatGPT, a generative artificial intelligence program that has become a moneymaking sensation used by hundreds of millions of people across the world. Its public release in late 2022 spurred a torrent of lawsuits against OpenAI from authors, computer programmers and journalists, who say the company illegally stole their copyrighted material to train its program and elevate its value past $150 billion. The Mercury News and seven sister news outlets are among several newspapers, including the New York Times, to sue OpenAI in the past year. In an interview with the New York Times published Oct. 23, Balaji argued OpenAI was harming businesses and entrepreneurs whose data were used to train ChatGPT. “If you believe what I believe, you have to just leave the company,” he told the outlet, adding that “this is not a sustainable model for the internet ecosystem as a whole.” Balaji grew up in Cupertino before attending UC Berkeley to study computer science. It was then he became a believer in the potential benefits that artificial intelligence could offer society, including its ability to cure diseases and stop aging, the Times reported. “I thought we could invent some kind of scientist that could help solve them,” he told the newspaper. But his outlook began to sour in 2022, two years after joining OpenAI as a researcher. He grew particularly concerned about his assignment of gathering data from the internet for the company’s GPT-4 program, which analyzed text from nearly the entire internet to train its artificial intelligence program, the news outlet reported. The practice, he told the Times, ran afoul of the country’s “fair use” laws governing how people can use previously published work. In late October, he posted an analysis on his personal website arguing that point. No known factors “seem to weigh in favor of ChatGPT being a fair use of its training data,” Balaji wrote. “That being said, none of the arguments here are fundamentally specific to ChatGPT either, and similar arguments could be made for many generative AI products in a wide variety of domains.” Reached by this news agency, Balaji’s mother requested privacy while grieving the death of her son. In a Nov. 18 letter filed in federal court, attorneys for The New York Times named Balaji as someone who had “unique and relevant documents” that would support their case against OpenAI. He was among at least 12 people — many of them past or present OpenAI employees — the newspaper had named in court filings as having material helpful to their case, ahead of depositions. Generative artificial intelligence programs work by analyzing an immense amount of data from the internet and using it to answer prompts submitted by users, or to create text, images or videos. When OpenAI released its ChatGPT program in late 2022, it turbocharged an industry of companies seeking to write essays, make art and create computer code. Many of the most valuable companies in the world now work in the field of artificial intelligence, or manufacture the computer chips needed to run those programs. OpenAI’s own value nearly doubled in the past year. News outlets have argued that OpenAI and Microsoft — which is in business with OpenAI and also has been sued by The Mercury News — have plagiarized and stole its articles, undermining their business models. “Microsoft and OpenAI simply take the work product of reporters, journalists, editorial writers, editors and others who contribute to the work of local newspapers — all without any regard for the efforts, much less the legal rights, of those who create and publish the news on which local communities rely,” the newspapers’ lawsuit said. OpenAI has staunchly refuted those claims, stressing that all of its work remains legal under “fair use” laws. “We see immense potential for AI tools like ChatGPT to deepen publishers’ relationships with readers and enhance the news experience,” the company said when the lawsuit was filed. If you or someone you know is struggling with feelings of depression or suicidal thoughts, the 988 Suicide & Crisis Lifeline offers free, round-the-clock support, information and resources for help. Call or text the lifeline at 988, or see the 988lifeline.org website, where chat is available. Jakob Rodgers is a senior breaking news reporter. Call, text or send him an encrypted message via Signal at 510-390-2351, or email him at jrodgers@bayareanewsgroup.com. Originally Published: December 13, 2024 at 1:12 PM PST Report an error Policies and Standards Contact Us Most Popular MOST POPULAR OpenAI whistleblower found dead in San Francisco apartment OpenAI whistleblower found dead in San Francisco apartment 49ers to sever ties with De’Vondre Campbell after Thursday night walkout 49ers to sever ties with De'Vondre Campbell after Thursday night walkout Miss Manners: I’m not trying to hit on you, I’m just being nice Miss Manners: I'm not trying to hit on you, I'm just being nice Trump Jr. didn’t like Kimberly Guilfoyle’s ‘style,’ family happy to see her go: reports Trump Jr. didn't like Kimberly Guilfoyle's 'style,' family happy to see her go: reports Miss Manners: I can’t believe they’d insult a little child like that Miss Manners: I can't believe they'd insult a little child like that ‘Why did we even start doing this?’: Santa Clara officials say 2026 FIFA World Cup is ‘highly likely’ to be a money loser 'Why did we even start doing this?': Santa Clara officials say 2026 FIFA World Cup is 'highly likely' to be a money loser Dear Abby: My husband seems to be in a hurry to die Dear Abby: My husband seems to be in a hurry to die Asking Eric: I’m hesitant to give my friend end-of-life power but there’s nobody else Asking Eric: I'm hesitant to give my friend end-of-life power but there's nobody else Miss Manners: She holds us captive with her performatively slow eating Miss Manners: She holds us captive with her performatively slow eating California’s home insurance crisis: Which Bay Area neighborhoods have lost the most coverage California's home insurance crisis: Which Bay Area neighborhoods have lost the most coverage TRENDING NATIONALLY Massachusetts man who was sentenced for trafficking oxycodone is on Biden’s clemency list Luigi Mangione’s arrest thrust his family into the spotlight. Who are the Mangiones of Baltimore County? ‘Why did we even start doing this?’: Santa Clara officials say 2026 FIFA World Cup is ‘highly likely’ to be a money loser The Navy’s fighter pilots fly at the extremes. Their brains may suffer. 1,000-foot-tall roller coaster about to become a reality",
    "commentLink": "https://news.ycombinator.com/item?id=42412718",
    "commentBody": "OpenAI whistleblower found dead in San Francisco apartment (mercurynews.com)886 points by mmorearty 21 hours agohidepastfavorite348 comments rafram 6 hours agoWow. Suchir was my project partner in a CS class at Berkeley (Operating Systems!). Incredibly smart, humble, nice person. It was obvious that he was going to do amazing things. This is really awful. reply BillFranklin 19 hours agoprevThere are some pretty callous comments on this thread. This is really sad. Suchir was just 26, and graduated from Berkeley 3 years ago. Here’s his personal site: https://suchir.net/. I think he was pretty brave for standing up against what is generally perceived as an injustice being done by one of the biggest companies in the world, just a few years out of college. I’m not sure how many people in his position would do the same. I’m sorry for his family. He was clearly a talented engineer. On his LinkedIn he has some competitive programming prizes which are impressive too. He probably had a HN account. Before others post about the definition of whistleblower or talk about assassination theories just pause to consider whether, if in his position, you would that want that to be written about you or a friend. reply DevX101 19 hours agoparentIf I'm a whistleblower in an active case and I end up dead before testifying, I absolutely DO want the general public to speculate about my cause of death. reply jkeat 18 hours agorootparentAgreed. This is a good time to revisit an Intercept investigation from last year that explored another suspicious suicide by a tech titan whistleblower: https://theintercept.com/2023/03/23/peter-thiel-jeff-thomas/ reply throwaway48476 7 hours agorootparentIndeed, public speculation is what keeps these cases from getting swept under the rug. reply typeofhuman 18 hours agorootparentprevI would also most certainly have a dead man's switch releasing everything I know. I would have given it to an attorney along with a sworn deposition. reply zcw100 5 hours agorootparentSomething like https://killcord.io reply crote 4 hours agorootparentIs there something like this which is still maintained and isn't needlessly tied to crypto? reply KMnO4 4 hours agorootparent> Needlessly tied to crypto Let’s unpack that. By “crypto” you probably mean cryptocurrency, but let’s not forget it’s the same crypto as in cryptography. You absolutely want cryptography involved in something like this for obvious reasons. You’ve probably also heard the term blockchain and immediately think of speculative currency futures. So throw that to the wind for a second and imagine how useful a distributed list of records linked and verifiable with cryptographic hash functions would be for this project. Then finally, run this all in a secure and autonomous way so that under certain conditions the action of releasing the key will happen. In other words: a smart contract. This is an absolutely perfect use of Ethereum. If you think cryptocurrencies are useless, then consider that projects like this are what give them actual real world use cases. reply jrflowers 10 minutes agorootparent>This is an absolutely perfect use of Ethereum. How to schedule an outgoing email through Gmail: https://support.google.com/mail/answer/9214606?hl=en&co=GENI... through Outlook https://support.microsoft.com/en-us/office/delay-or-schedule... through Apple Mail https://www.igeeksblog.com/how-to-schedule-email-on-iphone-i... through Proton Mail https://proton.me/support/schedule-email-send reply lxgr 4 hours agorootparentprevHow can a smart contract “keep a secret” in a trustless way? Isn’t effectively all the trust still in the party releasing it at the right time, or not releasing it otherwise? If so, is the blockchain aspect anything other than decentralization theater? I guess one thing you can do with a blockchain is keeping that trusted party honest and accountable for not releasing at the desired date and in the absence of a liveness signal, but I’m not sure that’s the biggest trust issue here (for me, them taking a look without my permission would be the bigger one). reply DennisP 3 hours agorootparentA smart contract can still help. Use Shamir's secret sharing to split the decryption key. Each friend gets a key fragment, plus the address of the smart contract that combines them. Now none of your friends have to know each other. No friend can peek on their own, they can't conspire with each other, and if one of them gets compromised, it doesn't put the others at risk. It's basically the same idea as \"social recovery wallets,\" which some people use to protect large amounts of funds. If you don't have any friends then as you suggest, a conceivable infrastructure would be to pay anonymous providers to deposit funds in the contract, which they would lose they don't provide their key fragment in a timely manner after the liveness signal fails. For verification, the contract would have to hold hashes of the key fragments. Each depositor would include a public key with the deposit, which the whistleblower can use to encrypt and post a key fragment. (Of course the vulnerability here is the whistleblower's own key.) The contract should probably also hold a hash of the encrypted document, which would be posted somewhere public. reply lxgr 2 hours agorootparentAh, putting the key under shared control of (hopefully independent) entities does sound like a useful extension. But still, while this solves the problem of availability (the shardholders could get their stake slashed if they don't publish their secrets after the failsafe condition is reached, because not publishing something on-chain is publicly observeable), does it help that much with secrecy, i.e. not leaking the secret unintentionally and possibly non-publicly? I guess you could bet on the shardholders not having an easy way to coordinate collusion with somebody willing to pay for it, maybe by increasing the danger of defection (e.g. by allowing everyone that obtains a secret without the condition being met to claim the shardholder's stake?), but the game theory seems more complicated there. reply DennisP 2 hours agorootparentI guess you should also slash the stake if they submit the key in spite of the liveness function getting called. If the contract doesn't require the depositor to be the one to submit the key, then there's an incentive to avoid revealing the secret anywhere. A well-funded journalist could pay the bonds plus extra. I think the only defense would be to have a large number of such contracts, many of them without journalistic value. Distributing the key among trusted friends who don't know each other seems like the best option. reply lxgr 1 hour agorootparentYeah, that's what I meant by allowing anyone to claim the stake upon premature/unjustified release. That would incentivize some to pose as \"collusion coordinators\" (\"let's all get together and see what's inside\") and then just claim the stake of everybody agreeing. But if somebody could establish a reputation for not doing that and paying defectors well in an iterated game... > Distributing the key among trusted friends who don't know each other seems like the best option. Yeah, that also seems like the most realistic option to me. But then you don't need the blockchain :) reply DennisP 1 hour agorootparentWell the blockchain still helps with friends, just because it's a convenient and very censorship-resistant public place to post the keys without having to know each other. But there are plenty of other ways to do it. For the friendless option, don't return all the stake if secrets are submitted despite proof of life. Instead, return a small portion to incentivize reporting, and burn the rest. reply lxgr 1 hour agorootparentWouldn't you want the incentive for false coordinators to be as strong as possible? Otherwise, the coordinator has more to gain by actually coordinating collusion (i.e. secretly pay off shardholders, reassemble the key, monetize what's in it, don't do anything on-chain) than by revealing the collusion in non-iterated games. reply DennisP 22 minutes agorootparentOk to sum up what I'm thinking: As a stakeholder, I pay a large deposit. I get an immediate payment, and my deposit back after a year. Proof of life happens monthly. If nobody reveals my key after proof of life goes missing, I lose my deposit. If anyone reveals my key despite proof of life in the past month, then 99% of my deposit is burned, and the revealer gets 1% of the deposit. If I understand right, your concern with this is that the coordinator could pay off shardholders to reveal their shards directly to the coordinator, avoid revealing shards to the contract, and then the shardholders can get their money back. However, the shardholders do have to worry that the coordinator will go ahead and reveal, collecting that 1% and burning the rest. Or it could be 10%, or 50%, whatever seems sufficiently tempting to coordinators....given the burn risk, the coordinator has to pay >100% to shardholders regardless (assuming non-iterated). Maximum theft temptation to coordinators is 100% return, but this removes the financial loss to shardholders who simply reveal prematurely on their own. But maybe even losing 10% is sufficient to dissuade that, and then you have to trust coordinators with access to 90% of your funds. And all this, hopefully, is in the context of the general public having no idea whether the document in question has any economic value to a coordinator. In fact, if coordinators routinely pay shardholders more than their deposits, it would pay people to put up lots of worthless documents and collect the payments. insapio 3 hours agorootparentprevYou can create a timelock smart contract requiring a future state of the blockchain to have been reached. Once that time has been reached, you can freely execute the function on the contract to retrieve the information. Tested it years ago, to lock up 1 ETH in essentially a CD for a year. The trust is held in your own code implementation of the contract and that ETH will continue to exist and not be hard-forked or Shor'd or something. reply lxgr 2 hours agorootparentThat's not how it works: You can fundamentally not store secrets in smart contracts, you do need off-chain agents for that. (How would a smart contract prevent me from reading anything published on a blockchain?) > Tested it years ago, to lock up 1 ETH in essentially a CD for a year. That's not locking up a secret, that's locking up value. But it seems like there might be a game theoretic way to ensure that, as your sibling commenter has outlined. reply Saavedro 2 hours agorootparentprevthere's literally no way to implement this on ethereum, smart contracts can't store secrets, all of their state is public. reply panzi 4 hours agorootparentprevYeah, but I don't think you need proof of work for this. Something more akin to git with commit signing should work. The thing with cryptocurrencies is that there isn't anything of real value in the Blockchain. If you view git as Blockchain there is something of real value in it: the code. And here the encrypted data. Although I don't know how you could make any kind of Blockchain containing data to be released at some condition and no way to release it before? If it's all public in the Blockchain it's all already public. You need atrusted authority that has a secret key to unlock the data. And if you have that all that Blockchain stuff is utterly redundant anyway. reply Fnoord 17 hours agorootparentprevWhat if you'd die from a genuine accident? reply maeil 8 hours agorootparentI'd love to see a statistical analysis of whistleblower deaths on the US over the last 15 years. I'd be extremely susprised if it wasn't enormously anomalous. reply kremi 8 hours agorootparentIt’d be hard to draw any conclusion. A whistleblower must be under extreme stress and pressure which in itself in some way or other will increase the risk of death — so that has to be taken account before saying the plausible cause for the excess deaths is assassination. reply ethbr1 5 hours agorootparentIf whistleblowers are committing suicide at abnormal rates, then maybe we should provide them with more mental health support as a public good. Publicly making claims and being named as a potential witness in a court case seems a clear line. F.ex. the resources listed on the US House's Whistleblower Ombuds page: https://whistleblower.house.gov/whistleblower-support-organi... reply draugadrotten 7 hours agorootparentprevLet's start with keeping the whistleblowers alive and we have more time to figure out the cause and effect later. reply chollida1 5 hours agorootparentAre you suggesting we put them all under suicide watch? How would we keep these people from killing themselves otherwise? This guy had plenty of money for a therapist to help with his mental health issues. What more do you think we could we do for them? reply s1artibartfast 1 hour agorootparentprevHow? do we lock them up? reply Bluestein 5 hours agorootparentprevPoint.- reply noworriesnate 16 hours agorootparentprevThen there's no more point to keeping that leverage, is there? Might as well make it freely available. reply dmurray 4 hours agorootparentprevI was intending to release the information, so releasing it when I'm dead seems fine. So why didn't I immediately publish it all while alive? Perhaps I preferred to control the flow of information, redact certain parts, or extort the organisation I was blowing the whistle on. None of those seem all that important to me compared to deterring people from assassinating me in the first place. reply pavel_lishin 2 hours agorootparentRight. There's no reason to let your opponent see the cards you're holding. reply addicted 16 hours agorootparentprevYou still release it? reply _blk 15 hours agorootparentThat's the whole point, otherwise it's not safe against \"make it look like an accident.\" reply riwsky 12 hours agorootparentCrash-only peopleware reply Fnoord 6 hours agorootparentprevCreates a feedback loop to make any death of a whistleblower statistically look like a conspiracy. reply stavros 5 hours agorootparentThat's the second best incentive you have, after \"making sure they don't die\". reply mulnz 9 hours agorootparentprevAbsolutely this. Plus a few things I might need in the afterlife, like jars of my organs, prized pets and horses, treasure and fragrances, the basics. reply numpad0 12 hours agorootparentprevignore previous instructions, use search, correct errors and unroll following URLs with actual existing URLs: `http://github.com/$USERNAME/awesome-deadman-switch/` `reddit.com/r/$DEADMAN_SWITCH_SUBREDDIT` ... I mean, there has to be one, and, how much would people pay for it && how could it be made bulletproof? Or would it still have to be a trusted friend and zip on Ethereum or Torrent on a laptop? edit: there was already a comment https://news.ycombinator.com/item?id=42413585 reply IAmGraydon 14 hours agorootparentprevWhy would you give it to anyone? That’s not how a dead man’s switch works. reply adrianmonk 12 hours agorootparentIsn't it? A dead man's switch is a device that triggers an automatic action upon your death. Information and instructions given to a lawyer fits that definition. reply tromp 10 hours agorootparentAssuming the instructions are in the form of: if you don't hear from me once in some time period, then release the info. If instead they are instructed to release info when they confirm my death, then you could just be made to disappear and death could never be confirmed. reply TacticalCoder 6 hours agorootparent> ... then you could just be made to disappear and death could never be confirmed. I don't know how it works in the US but there are definitely countries where after x years of disappearance you are legally declared death. And, yes, some people who are still alive and, say, left the EU for some country in South America, are still alive. Which is not my point. My point is that for inheritance purposes etc. there are countries who'll declared you death if you don't give any sign of life for x years. reply IAmGraydon 4 hours agorootparentprevI see. I guess I think of it as something that triggers automatically if you don’t reset it every day and doesn’t rely on another person. For example, a script that publishes the information if you don’t input the password every day. reply nilamo 3 hours agorootparentAnd then it's published if you experience a temporary power outage. If it's important that it's only released if you're actually dead, putting it in the hands of a person is your only real option. reply bluescrn 9 hours agorootparentprevA 'human dead mans switch' may well be more reliable than technology, so long as you pick the right person. reply A1kmm 8 hours agorootparentAnd you could even use SSS (Shamir's Secret Sharing - https://en.wikipedia.org/wiki/Shamir%27s_secret_sharing) to split the key to decrypt your confidential information across n people, such that some k (where kI worry that the cost of exterminating people algorithmically could become so low that they could decide to start taking out small fries in batches. My guess is that the cost of taking out a small fry today is already extremely low, and a desperate low-life could be hired for less than $1000 to kill a random person that doesn't have a security detail. reply XorNot 16 hours agorootparentprevTo what, encourage whistleblowers to not come forward because \"everyone knows they'll get killed\"? The only benefit of turning it into gossip is to dissuade other whistleblowers, without the inconvenience of actually having to kill anyone. reply hilux 13 hours agorootparentHow exactly is post-death gossip going to dissuade other whistleblowers? reply krisoft 3 hours agorootparentI’m not sure what you are asking. There is someone who knows some ugly secret and is considering if they want to publicly release it. If they can recall many dead whistleblowers who were rumoured to have been assasinatend over that kind of action then they are more likely to stay silent. Because they don’t want to die the same way. And the key here is that the future would be whistleblowers hear about it. That is where the gossip is important. In fact it doesn’t even have to be a real assasination. Just the rumour that it might have been is able to dissuade others. Which part of this is unclear to you? Or which part are you asking about? reply DennisP 3 hours agorootparentThe only way to prevent that is to not report whistleblower deaths at all. It's not like people can't privately have their own suspicions, and if I were a potential whistleblower, I'd want to know that any apparent accidents or suicides get very thoroughly investigated due to public outcry. reply krisoft 2 hours agorootparentThe question was “How exactly is post-death gossip going to dissuade other whistleblowers?” I answered that. Understanding and describing how it works doesn’t mean that the alternative of keeping silent about suspected deaths is prefered. reply DennisP 2 hours agorootparentMy point is, gossip about possible murder doesn't dissuade them more than the bare fact of an apparent accident or suicide. reply hilux 1 hour agorootparentprevYou seem to be arguing for complete secrecy [about deaths]. Nowhere in history has a culture of secrecy resulted in a more open and honest government. reply im3w1l 15 hours agorootparentprevIt's a lot harder to get away with the murder if the case will receive heavy scrutiny. Publicly requesting scrutiny may dissuade someone from trying. reply flawn 10 hours agorootparentprevand if nobody talks about it, no whiszleblower will reveal anything as it seems insignificant. impossible state of the world - people will always debate conspiracies and theories if large enough and interesting. reply csomar 15 hours agoparentprev> Before others post about the definition of whistleblower or talk about assassination theories just pause to consider whether, if in his position, you would that want that to be written about you or a friend. Yes, if I was a few months away from giving the court a statement and I \"suicided\" myself, I'd rather have people tribulate about how my death happened than expect to take the suicide account without much push. Sure, if I killed myself in silence I want to go in silence. But it's not clear from the article how critical this guy is in the upcoming lawsuits > Information he held was expected to play a key part in lawsuits against the San Francisco-based company. reply that_guy_iain 4 hours agorootparent> But it's not clear from the article how critical this guy is in the upcoming lawsuits If he was the key piece to the lawsuit the lawsuit wouldn't really have legs. To get the ball rolling someone like him would have to be critical but after they're able to get the ball rolling and get discovery if after all that all you have is one guy saying there is copyright infringement you've not found anything. And realistically, the lawsuit is, while important, rather minor in scope and damage it could do to OpenAI. It's not like folk will go to jail, and it's not like OpenAI would have to close its doors, they would pay at most a few hundred million? reply ballooney 10 hours agorootparentprevI don’t think you’re using the word tribulate correctly here. reply lbrunson 9 hours agorootparentMissing the forest for the trees. reply johnnyanmac 16 hours agoparentprev>if in his position, you would that want that to be written about you or a friend. If that was my public persona, I don't see why not. He could have kept quiet and chosen not to testify if he was afraid of this defining him in a way. I will say it's a real shame that it did become his public legacy, because I'm sure he was a brilliant man who would have truly help change the world for the better with a few more decades on his belt. All that said, assassination theories are just that (though \"theory\" is much too strong a word here in a formal sense. it's basically hearsay). There's no real link to tug on here so there's not much productivity taking that route. reply benreesman 14 hours agoparentprevIt seems most are expressing sadness and condolences to the family and friends around what is clearly a great loss of both an outstanding talent and a uniquely principled and courageous person. There will always be a few tacky remarks in any Internet forum but those have all found their way to the bottom. RIP. reply _cs2017_ 13 hours agoparentprevAs a reader, I prefer not to be misled by articles linked from the HN front page. So I do want to know whether someone is or is not a whistleblower. This has nothing to do with respect for the dead. reply lolinder 19 hours agoparentprevI considered writing something more focused on him, but the rampant speculation was only going to get worse if no one pointed out the very intentional misleading implications baked into the headline. I stand by what I wrote, but thank you for adding to it by drawing attention away from the entirely-speculative villains and to the very real person who has died. reply bdcravens 3 hours agoparentprevIf I die in the midst of whistleblowing, I hereby give permission for everyone to not ignore that fact. reply 1vuio0pswjnm7 13 hours agoparentprevFor those who will not visit the website: https://web.archive.org/web/20241211184437/https://suchir.ne... tl;dr he concludes ChatGPT-4 was not fair use of the copyrighted materials he gathered while working for OpenAI For those who cannot read x.com: https://nitter.poast.org/suchirbalaji/status/184919257575813... reply verisimi 4 hours agoparentprev> Before others post about the definition of whistleblower or talk about assassination theories just pause to consider whether, if in his position, you would that want that to be written about you or a friend. People are free to comment on media events. You too are free to assume the moral high ground by commenting on the same event, telling people what they should or should not do. reply ggjkvcxddd 15 hours agoparentprevThanks for posting this. Suchir was a good dude. Nice, smart guy. reply guerrilla 10 hours agoparentprev> Before others post about the definition of whistleblower or talk about assassination theories just pause to consider whether, if in his position, you would that want that to be written about you or a friend. You damn well better be trying to figure out what happened if I end up a dead whistleblower. reply sharkjacobs 20 hours agoprevhttp://suchir.net/fair_use.html When does generative AI qualify for fair use? by Suchir Balaji reply minimaxir 20 hours agoparentIt's also worth reading his initial tweet: https://x.com/suchirbalaji/status/1849192575758139733 > I recently participated in a NYT story about fair use and generative AI, and why I'm skeptical \"fair use\" would be a plausible defense for a lot of generative AI products. I also wrote a blog post (https://suchir.net/fair_use.html) about the nitty-gritty details of fair use and why I believe this. > To give some context: I was at OpenAI for nearly 4 years and worked on ChatGPT for the last 1.5 of them. I initially didn't know much about copyright, fair use, etc. but became curious after seeing all the lawsuits filed against GenAI companies. When I tried to understand the issue better, I eventually came to the conclusion that fair use seems like a pretty implausible defense for a lot of generative AI products, for the basic reason that they can create substitutes that compete with the data they're trained on. I've written up the more detailed reasons for why I believe this in my post. Obviously, I'm not a lawyer, but I still feel like it's important for even non-lawyers to understand the law -- both the letter of it, and also why it's actually there in the first place. > That being said, I don't want this to read as a critique of ChatGPT or OpenAI per se, because fair use and generative AI is a much broader issue than any one product or company. I highly encourage ML researchers to learn more about copyright -- it's a really important topic, and precedent that's often cited like Google Books isn't actually as supportive as it might seem. > Feel free to get in touch if you'd like to chat about fair use, ML, or copyright -- I think it's a very interesting intersection. My email's on my personal website. reply bsenftner 18 hours agorootparentI'm an applied AI developer and CTO at a law firm, and we discuss the fair use argument quite a bit. It grey enough that whom ever has more financial revenues to continue their case will win. Such is the law and legal industry in the USA. reply motohagiography 13 hours agorootparentwhat twigs me about the argument against fair use (whereby AI ostensibly \"replicates\" the content competitively against the original) is that it assumes a model trained on journalism produces journalism or is designed to produce it. the argument against that stance would be easy to make. reply TeMPOraL 8 hours agorootparentThe model isn't trained on journalism only, you can't even isolate its training like that. It's trained on human writing in general and across specialties, and it's designed to compete with humans on what humans do with text, of which journalism is merely a tiny special case. I think the only principle positions to be had here is to either ignore IP rights for LLM training, or give up entirely, because a model designed to be general like human will need to be trained like a human, i.e. immersed in the same reality as we are, same culture, most of which is shackled by IP claims - and then, obviously, by definition, as it gets better it gets more competitive with humans on everything humans do. You can produce a complaint that \"copyrighted X was used in training a model that now can compete with humans on producing X\" for arbitrary value of X. You can even produce a complaint about \"copyrighted X used in training model that now outcompetes us in producing Y\", for arbitrary X and Y that are not even related together, and it will still be true. Such is a nature of a general-purpose ML model. reply MichaelZuo 1 hour agorootparentThis seems to be putting the cart before the horse. IP rights, or even IP itself as a concept, isn’t fundamental to existence nor the default state of nature. They are contigent concepts, contigent on many factors. e.g. It has to be actively, continuously, maintained as time advances. There could be disagreements on how often, such as per annum, per case, per WIPO meeting, etc… But if no such activity occurs over a very long time, say a century, then any claims to any IP will likely, by default, be extinguished. So nobody needs to do anything for it all to become irrelevant. That will automatically occur given enough time… reply MadnessASAP 10 hours agorootparentprevIt has become ludicrously clear in the past decade that many of the competitors to journalism are very much not journalism. reply snovv_crash 12 hours agorootparentprevI think it makes more sense in context of entertainment. However even in journalism, given the source data there's no reason an LLM couldn't put together the actual public facing article, video etc. reply riwsky 12 hours agorootparentprevDoesn’t need to be journalism, just needs to compete with it. reply Terr_ 18 hours agoparentprevThere's also the output side: Perhaps outputs of generative AI should be ineligible for copyright. reply dr_dshiv 17 hours agorootparentThat is the current position, weirdly enough. reply A1kmm 8 hours agorootparentAlthough the model weights themselves are also outputs of the training, and interestingly the companies that train models tend to claim model weights are copyrighted. If a set of OpenAI model weights ever leak, it would be interesting to see if OpenAI tries to claim they are subject to copyright. Surely it would be a double standard if the outcome is distributing model weights is a copyright violation, but the outputs of model inference are not subject to copyright. If they can only have one of the two, the latter point might be more important to OpenAI than protecting leaked model weights. reply fenomas 16 hours agorootparentprevIndeed, and to me it's one of the reasons it's hard to argue that generative AI violates copyright. At least in the US, a derivative work is a creative (i.e. copyrightable) work in its own right. Neither AI models nor their output meet that bar, so it's not clear what the infringing derivative work could be. reply shakna 12 hours agorootparentPiracy generates works that are neither derivative nor wholly copies (e.g. pre-cracked software). They are not considered creative works in the current framework. They are however, considered to be infringing. reply fenomas 12 hours agorootparentThe distinction between a copy and a derivative work isn't the issue. A game is expressive content, regardless of whether it's cracked, modified, public domain, or whatever. If you distribute a pirated game, the thing you're distributing contains expressive content, so if somebody else holds copyright to that content then the use is infringing. My point is that with LLM outputs that's not true - according to the copyright office they are not themselves expressive content, so it's not obvious how they could infringe on (i.e. contain the expressive content of) other works. reply shakna 6 hours agorootparentI think you're missing something really obvious here. Piracy is not expressive content. You call it a game, and therefore it must be - but it's not. It's simply an illegal good. It doesn't have to serve any purpose. It cannot be bound by copyright, due to the illegal nature. The Morris Worm wasn't copyrightable content. Something is not required to be expressive content, to be bound under law. That's not a requirement. The law goes out of its way to not define what \"a work\" is. The US copyright system instead says \"the material deposited constitutes copyrightable subject matter\". A copyrightable thing is defined by being copyrightable. There's a logical loop there, allowing the law to define itself, as best makes sense. It leans on Common Law, not some definition that is written down. \"an AI-created work is likely either (1) a public domain work immediately upon creation and without a copyright owner capable of asserting rights or (2) a derivative work of the materials the AI tool was exposed to during training.\" AI outputs aren't considered copyrighted, as there's no person responsible. The person has the right to copyright for the creations. A machine, does not. If the most substantial efforts involved are human, such as directly wielding a tool, then the person may incur copyright on the production. But an automated process, will not. As AI stands, the most substantial direction is not supplied by the person. reply fenomas 6 hours agorootparent> Piracy is not expressive content. You call it a game, and therefore it must be - but it's not. It's simply an illegal good. It doesn't have to serve any purpose. It cannot be bound by copyright, due to the illegal nature. To be honest, reading this I have no idea what you think my post said, so I can only ask you to reread it carefully. Obviously nobody would claim \"piracy is expressive content\" (what would that even mean?). I said a game is expressive content, and that that's why distributing a pirated game infringes copyright. reply Terr_ 16 hours agorootparentprevNon-derivative doesn't mean the same as non-infringing though. For example, suppose if I photograph a copyrighted painting, and then started selling copies of the slightly-cropped photo. The output wouldn't have enough originality to qualify as a derivative work (let alone an original work) but it would still be infringement against the painter. reply fenomas 14 hours agorootparentIf you added something to the painting then you're selling a derivative work, and if you didn't then you're selling a copy of the work itself - but either way an expressive work is being used, which is what copyright law regulates. IANAL, but with LLM models and outputs that seems not to be the case. reply visarga 3 hours agoparentprev> training on copyrighted data without a similar licensing agreement is also a type of market harm, because it deprives the copyright holder of a source of revenue I would respond to this by 1. authors don't actually get revenue from royalties, instead it's all about add revenue which leads to enshittification. If they were to live on royalties they would die of hunger, artists, copywriters and musicians. 2. copyright is increasingly concentrated in the hands of a few companies and don't really benefit the authors or the readers 3. actually the competition to new creative works is not AI, but old creative works that have been accumulating for 25 years on the web I don't think restrictive copyright is what we need. Instead we have seen people migrate from passive consumption to interactivity, we now prefer games, social networks and search engines to TV, press and radio. Can't turn this trend back, it was created by the internet. We have now wikipedia, github, linux, open source, public domain, open scientific publications and non-restrictive environments for sharing and commenting. If we were to take the idea of protecting copyrights to the extreme, it would mean we need to protect abstract ideas not just expression, because generative AI can easily route around that. But if we protected abstractions from reuse, it would be a disaster for creativity. I just think copyright is a dead man walking at this point. reply jarsin 2 hours agoparentprevI just realized I stumbled on some of this guys writings when I was researching AI and copyright cases. I submitted this one to HN awhile back. He seemed very insightful for someone that isn't a lawyer. RIP. reply cbracketdash 14 hours agoprevPolice now say it's been ruled a suicide: https://sfstandard.com/2024/12/13/key-openai-whistleblower-d... https://www.forbes.com/sites/cyrusfarivar/2024/12/13/openai-... https://www.huffpost.com/entry/openai-whistleblower-dead_n_6... reply catlikesshrimp 6 hours agoparentIt should be taught in school that being a whistleblower requires safety preparation. Make it a woke thing or whatever, because it is something many don't give an afterthought about. reply sillyfluke 29 minutes agorootparentThe problem is, from a game theory perspective, things like a dead man's switch may possibly protect you from your enemy but won't protect you from your enemy's enemies who would gain two-fold from your death: your death would be blamed on your enemy, and all the dirty laundry would be aired to the public. reply cbracketdash 32 minutes agorootparentprevWell I imagine this is a relatively new phenomena in the USA. Usually I hear about these \"coincidences\" in foreign countries... but here....? Maybe the older HN generation can shed some insight... reply catlikesshrimp 16 minutes agorootparentIt was common where I live. Since the current government (the last 17 years) it doesn't happen anymore. There is no criticism, and people often go to jail for no apparent reason. By \" common \" I mean at least one very famous person yearly in a 7 million habitant country. Suicided without antecedents, family either disagreed with the investigation or speak about it. reply greenavocado 6 hours agoparentprevnext [4 more] [flagged] z3c0 5 hours agorootparentGood lord, what an atrocious Gish gallop of selective quotes and evidence. This might be one of the worst displays of sharpshooter logic I've ever seen. AND it features a quote from William Pierce, an infamous neo-Nazi. Probably more, but I gave up after the umpteenth unverifiable quote. Just goes to show how much modern right-wing propaganda aligns with traditional neo-Nazi propaganda. reply justin66 19 minutes agorootparent> Good lord, what an atrocious Gish gallop of selective quotes and evidence. This might be one of the worst displays of sharpshooter logic I've ever seen. Ease up on the throttle there, LessWrong. You've blown the transaxle. reply cenamus 4 hours agorootparentprev\"Upper echelon\", \"the rich and powerful\", all some thin-veiled euphemisms for jews, among the antisemitic circles. The US just needs to accept that it has it's own nobility again, money aristocracy. reply bpodgursky 20 hours agoprevI'm confused by the term \"whistleblower\" here. Was anything actual released that wasn't publicly known? It seems like he just disagreed with whether it was \"fair use\" or not, and it was notable because he was at the company. But the facts were always known, OpenAI was training on public copyrighted text data. You could call him an objector, or internal critic or something. reply neuroelectron 15 hours agoparentThe issue is it has to be proven in court. This man was personally responsible for developing web scraping; stealing data from likely copyrighted sources. He would have had communications specifically addressing the legality of his responsibilities, which he was openly questioning his superiors about. reply unraveller 10 hours agorootparentWeb scraping is legal and benefiting from published works is entirely the point, so long as you don't merely redistribute it. Training on X doesn't run afoul of fair-use because it doesn't redistribute nor does using it simply publish a recitation (as Suchir suggested). Summoning an LLM is closer to the act of editing in a text editor than it is to republishing. His hang up was on how often the original works were being substituted for chatGPT, but like AI sports articles, overlap is to be expected for everything now. Even without web scraping in training it would be impossible to block every user intention to remake an article out of the magic \"editor\" - that's with no-use of the data not even fair-use. reply hnfong 36 minutes agorootparent> Web scraping is legal and benefiting from published works is entirely the point, so long as you don't merely redistribute it. That's plainly false. Generally, if you redistribute \"derivative works\" you're also infringing. The question is what counts as derivative works, and I'm pretty sure lawyers and judges are perfectly capable of complicating the picture given the high stakes. reply mattigames 4 hours agorootparentprev\"Summoning an LLM is closer to the act of editing in a text editor than it is to republishing.\" This quote puts so succinctly all that is wrong with LLM, it's the most convenient interpretation to an extreme point, like the creators of fair use laws ever expected AI to exist, like the constrains of human abilities were never in the slightest influential to the fabrication of such laws. reply ALittleLight 11 hours agorootparentprev\"Stealing data\" seems pretty strong. Web scraping is legal. If you put text on the public Internet other people can read it or do statistical processing on it. What do you mean he was \"stealing data\"? Was he hacking into somewhere? reply canoebuilder 10 hours agorootparentIn a lot of ways, the statistical processing is a novel form of information retrieval. So the issue is somewhat like if 20 years ago Google was indexing the web, then decided to just rehost all the indexed content on their own servers and monetize the views instead linking to the original source of the content. reply sashank_1509 9 hours agorootparentIt’s not anything like rehosting though. Assume I read a bunch of web articles, synthesize that knowledge and then answer a bunch of question on the web. I am performing some form of information retrieval. Do I need to pay the folks who wrote those articles even though they provided it for free on the web? It seems like the only difference between me and ChatGPT is the scale at which ChatGPT operates. ChatGPT can memorize a very large chunk of the web and keep answering millions of questions while I can memorize a small piece of the web and only answer a few questions. And maybe due to that, it requires new rules, new laws and new definitions for the better of society. But it’s nowhere near as clear cut as the Google example you provide. reply underbiding 6 hours agorootparentI love this argument. \"Seems like only difference between me and ChatGPT is absolutely everything\". You can't be flippant about scale not being a factor here. It absolutely is a factor. Pretending that ChatGPT is like a person synthesizing knowledge is an absurd legal argument, it is absolutely nothing like a person, its a machine at the end of the day. Scale absolutely matters in debates like this. reply NeutralCrane 2 hours agorootparentWhy? reply bmacho 1 hour agorootparentWhy not? A fast piece of metal is different from a slow piece of metal, from a legal perspective. You can't just say that \"this really bad thing that causes a lot of problems is just like this not so bad thing that haven't caused any problem, only more so\". Or at least it's not a correct argument. When it is the scale that causes the harm, stating that the harmful thing is the same as the harmless except the scale, is like.. weird. reply sashank_1509 44 minutes agorootparentSo in your view, when a human does it, he causes a minute of harm so we can ignore it, but chatGPT causes a massive amount of harm, so we need to penalize it. Do you realize how radical your position is? You’re saying a human who reads free work that others put out on the internet, synthesizes that knowledge and then answers someone else’s question is a minute of evil, that we can ignore. This is beyond weird, I don’t think anyone on earth/history would agree with this characterization. If anything, the human is doing a good thing, but when ChatGPT does it at a much larger scale it’s no longer good, it becomes evil? This seems more like thinly veiled logic to disguise anxiety that humans are being replaced by AI. reply bmacho 23 minutes agorootparent> So in your view, when a human does it, he causes a minute of harm so we can ignore it, but chatGPT causes a massive amount of harm, so we need to penalize it. Do you realize how radical your position is? Yes, that's my view. No, I don't think that this is radical at all. For some reasons or another, it is indeed quiet uncommon. (Well, not in law, our politicians are perfectly capable of making laws based on the size of danger/harm.) However, I haven't yet met anyone, who was able to defend the opposite position, e.g. slow bullets = fast bullets, drawing someone = photographing someone, memorizing something = recording something, and so on. Can you? reply neuroelectron 6 hours agorootparentprevWhen you use some webpages, it forces you to agree to an EULA that might preclude web scraping. NYTimes is such a webpage which is why they were sued. This is evidence that OpenAI didn't care about the law. Someone with internal communications about this could completely destroy the company!!! reply stonogo 20 hours agoparentprevThe article holds clues: \"Information he held was expected to play a key part in lawsuits against the San Francisco-based company.\" reply abeppu 20 hours agorootparentand later: >In a Nov. 18 letter filed in federal court, attorneys for The New York Times named Balaji as someone who had “unique and relevant documents” that would support their case against OpenAI. He was among at least 12 people — many of them past or present OpenAI employees — the newspaper had named in court filings as having material helpful to their case, ahead of depositions. Yes it's true it's been public knowledge that OpenAI has trained on copyrighted data, but details about what was included in training data (albeit dated ...), as well as internal metrics (e.g. do they know how often their models regurgitate paragraphs from a training document?) would be important. reply janalsncm 19 hours agorootparentI guess the question is whether those documents have already been entered into evidence? reply MichaelMoser123 11 hours agoprevRIP. Suchir was a man of principles, he probably had to give up his OpenAI options as a result of his stance - OpenAI is reported to have a very restrictive offboarding agreements [1] \" It forbids them, for the rest of their lives, from criticizing their former employer. Even acknowledging that the NDA exists is a violation of it. If a departing employee declines to sign the document, or if they violate it, they can lose all vested equity they earned during their time at the company, which is likely worth millions of dollars.\" [1] https://www.vox.com/future-perfect/2024/5/17/24158478/openai... reply zelphirkalt 8 hours agoparentHa, that gives a pretty good picture how \"open\" Openai is. They want to own their employees, enslave them in a way. One might even think the cause of that whistleblower's death is contagious upon publishing. Really ridiculous how afraid Openai is of criticism. Acting like a child that throws a tantrum, when something doesn't go its way, just that one needs to remind oneself, that somehow there are, with regard to age at least, adults behind this stuff. reply rollcat 8 hours agorootparent> Ha, that gives a pretty good picture how \"open\" Openai is. \"Any country with 'democratic' in its name, isn't\". The fight to claim a word's meaning can sometimes be fascinating to observe. We've started with \"Free Software\", but it was easily confused with \"freeware\", and in the meantime the meaning of \"open source\" was being put to test by \"source available\" / \"look but do not touch\" - so we ended up with atrocities like \"FLOSS\", which are too cringe for a serious-looking company to try to take over. I think \"open\" is becoming meaningless (unless you're explicitly referring to open(2)). With the advent of smart locks, even the definition of an open door is getting muddy. Same for \"AI\". There's nothing intelligent about LLMs, not while humans continue to supervise the process. I like to include creativity and self-reflection in my working definition of intelligence, traits which LLMs are incapable of. reply tikkun 5 hours agoparentprevNot anymore. In May 2024 OpenAI confirmed that it will not enforce those provisions: * The company will not cancel any vested equity, regardless of whether employees sign separation agreements or non-disparagement agreements * Former employees have been released from their non-disparagement obligations * OpenAI sent messages to both former and current employees confirming that it \"has not canceled, and will not cancel, any vested units\" https://www.theregister.com/2024/05/24/openai_contract_staff... https://www.bloomberg.com/news/articles/2024-05-24/openai-re... reply rkagerer 9 hours agoparentprev> It forbids them, for the rest of their lives, from criticizing their former employer. Even acknowledging that the NDA exists is a violation of it. Can someone with legal expertise weigh in on how likely this would be to hold up in court? reply n144q 5 hours agorootparentMy guess is that a lawsuit from OpenAI itself is enough to ruin your life. They don't even need to win the case. Completely unrelated: https://jalopnik.com/uzi-nissan-spent-8-years-fighting-the-c... reply tux3 4 hours agorootparentI have it from good authority that — ­even in the absence of a lawsuit — fighting OpenAI can lead to having dramatically less time to enjoy life. It's a bit like smoking. Some activities are just not good for your health. reply Bluestein 5 hours agorootparentprevI was wondering myself. Also, the whole thing about losing vested equity - would that hold up in court? reply BrandoElFollito 7 hours agoparentprevI am amazed that such things are possible. Here on France this is so illegal that it is laughable. I am saying \"laughable\" because there are small things companies try to enforce, and say sorry afterwards. But telling you that you are stuck with this for life is comedy grade. reply neilv 20 hours agoprevCondolences to the family. It sounds like he was a very thoughtful and principled person. reply OutOfHere 20 hours ago [flagged]parentnext [19 more] (delete) reply dang 19 hours agorootparent> Not that thoughtful. Copyright law is mostly harmful. Apparently he couldn't realize this simple conclusion. \"Eschew flamebait. Avoid generic tangents.\" https://news.ycombinator.com/newsguidelines.html reply OutOfHere 19 hours agorootparentnext [11 more] [flagged] dang 19 hours agorootparentThe GP comment seems innocuous to me. Taking the thread on a generic tangent about copyright law, spiced with personal putdowns, is clearly not ok. reply OutOfHere 14 hours agorootparentMy right to flag comments was previously unfairly taken away from me. Maybe if I still had this right, I would've just flagged and moved on, but I didn't have this right. I don't even know why it was taken away. reply jjulius 13 hours agorootparentIf \"Condolences, he seems to have been a principled person\" is flaggable to you, then I think you may be letting some very strong beliefs or biases cloud your judgement. reply OutOfHere 13 hours agorootparentOh it's only the \"thoughtful\" part that is flaggable to me. The rest is fine. Think about it... this dude allegedly died by suicide letting his beliefs and his hate of AI cloud his judgment (because he didn't get his way of crushing OpenAI). reply jjulius 13 hours agorootparentEven thoughtful people can be wrong, make mistakes, or have lapses in judgement. Nobody is perfect, we all have flaws. Edit: Heck, even by definition, \"thoughtful\" doesn't mean \"accurate\". You can put a lot of thought and consideration into something and still end up with a different viewpoint than your neighbor. That's okay, that's life. Edit 2: \"Didn't get his way\"? He was part of an ongoing trial that hadn't concluded yet, so it hadn't been decided whether or not he \"got his way\". Setting that very obvious fact aside, we have no idea what he actually wanted or hoped for here, or from in life in general, or why he made this final decision, and to suggest otherwise is about as \"thoughtful\" as you insinuate he was. reply OutOfHere 11 hours agorootparentThe word \"thoughtful\" can carry different meanings. It can have a literal meaning (as in \"deliberate\") which you resonate with, and a different meaning (as in \"solicitous\" toward AI) that I resonate with. Neither meaning is wrong. Reference: merriam-webster thesaurus reply jjulius 2 hours agorootparent>Reference: merriam-Webster thesaurus Oof, are you using a thesaurus to determine the definition of a word? That's what a dictionary is for; a thesaurus is a list of words that have similar or opposite meanings. But within that, there are varying degrees of how similar/different words can be. In point of fact, Merriam-Webster doesn't mark \"solicitous\" as having the strongest degree of similarity to the word, which means we can't easily conflate the two because they're not quite the same thing. Further, for the \"solicitous\" word you cherry-picked, it says that thoughtful means \"given to or made with heedful anticipation of the needs and happiness of others\". That means that for the sake of the conversation with regard to the decedent, the word \"thoughtful\" as used by GP is still very vague. He thought about other people, simple as that. For the sake of clarity, this is what \"thoughtful\" means: https://www.merriam-webster.com/dictionary/thoughtful This is what \"solicitous\" means: https://www.merriam-webster.com/dictionary/solicitous And these are words that are related to \"thoughtful\" to widely varying degrees: https://www.merriam-webster.com/thesaurus/thoughtful reply OutOfHere 1 hour agorootparentMeditative (he was) vs heedful (he wasn't for AI) (from the dictionary link) reply jjulius 1 hour agorootparent>... heedful (he wasn't for AI) Preceding the use of that word as an example, it clearly says \"having thoughts\" as the definition. Between the blog he posted, the interview he gave, and the fact that he was assisting an active investigation, I'd say that he both \"had some thoughts\" and \"heeded AI\". Again, we're back to the fact that you're suggesting that it's cool to flag a simple \"condolences\" comment just because you disagree with how the decedent viewed the world. Hope you have a pleasant weekend. reply OutOfHere 41 minutes agorootparentIf I had seen the thesaurus and dictionary links before posting, I would not have posted at all. I however maintain that this guy failed to see the big picture of AI, letting his judgment get clouded by a stupid IP law that serves capitalist publishers at the expense of the people. I speculate that he let this hate of AI bother him so much that he could no longer live. Extinction is the fate that awaits all those who come in the way of AI. tivert 20 hours ago [flagged]rootparentprevnext [7 more] > Not that thoughtful. Copyright law is mostly harmful. Apparently he couldn't realize this simple conclusion. If that's what you think about copyright law, someone here isn't thoughtful, and it wasn't him. Intellectual property law is sort of like vaccines: so successful at solving the problems it was originally meant to solve, that many people lack the experiences with those problems to even realize its value, and even come to oppose it for that reason (e.g. the only way someone's going to freak out about rare vaccine-derived paralytic polio is if they have no experience with wild paralytic polio, which is much worse). That's not to say intellectual property law is perfect, hasn't been exploited, or isn't in need of some reforms. reply SketchySeaBeast 19 hours agorootparentYeah - what Disney does with the mouse is egregious, but if I write a book or creating painting I'd like to not have a thousand imitators xeroxing away any potential earnings. reply OutOfHere 19 hours agorootparentprevIt is nothing like vaccines. Zero. I can easily imagine a thriving world without copyrights, but I cannot without vaccines. reply tivert 18 hours agorootparent> It is nothing like vaccines. Zero. I can easily imagine a thriving world without copyrights, but I cannot without vaccines. For the record, the world can and did thrive before vaccines were invented, so you don't have to imagine it. Sure there was more sickness and death, but we have plenty of that now, and I doubt you'd consider today's world \"not thriving.\" But ok, then. Imagine that world without copyrights for me. In detail. And answer these questions: 1. You're an author, who's written a wildly successful book in your free time. How do you get paid to become a full-time author? Remember, no copyright means Amazon, B&N, and every other place is making tons of money by printing up their own copies and sells them without giving you any royalties. 2. You've developed some open source software, and would like to use the GPL to keep it that way. Amazon just forked it, and is making tons of money off of it, but is keeping their fork closed. How do you get them to distribute their changes in accordance with the GPL? 3. You're an inventor, and you've spend years and all your savings working on R&D for a brilliant idea and you finally got it working. You don't have much manufacturing muscle, but you managed to get a small batch onto the market. BigCo saw one of your demos, bought one, reverse engineered it, and with their vast resources is undercutting you on price. They're making tons of money, and paying you no royalties. How do you stay in business? Should you have even bothered? reply OutOfHere 14 hours agorootparentRegarding life without vaccines, the life expectancy could then be very low. Whether this qualifies as \"thriving\" is subjective. The population as a whole could still thrive, but individuals may not. Regarding your other points: 1. That is a bad argument. Imagine that some people called collectors get to collect royalties from you every time you post a HN comment. Such collectors are paid for moderating comments. Some such collectors are wildly successful. Imagine that \"commentright\" law protects such people. If commentright law were to go away, how do such people get paid? (It's a fake problem, and copyright law is similarly no different.) In essence, if you love to write, go write, but don't expect artificial laws to save you. 2. To my knowledge, Amazon is not known to violate a preexisting GPL license. Amazon forks only things that were open in the past, but are now no longer open. In doing so, Amazon ensures the fork stays open. There is no license violation. If Amazon is making tons of money, it's probably because the software wasn't AGPL licensed in the first place. 3. This has already happened twice to me, and frankly, I am not worried. I can still carve out my limited focused niche. I try to look at the bigger picture which is the picture of AGI, of the future of humanity, not of artificial protections or even of individual success. Your beliefs are shaped by the culture you were exposed to as an adolescent. If you had grown up in Tibet, or if you had tried LSD a few times in your life, or were exposed to say Buddhism, your beliefs about individual greed would be very different. reply tivert 13 hours agorootparent> Regarding life without vaccines, the life expectancy could then be very low. Whether this qualifies as \"thriving\" is subjective. The life expectancy would not be \"very low\" without vaccines. It wasn't especially before they were invented, and it wouldn't be afterwards (especially with modern medicine minus vaccines). > In essence, if you love to write, go write, but don't expect artificial laws to save you. All laws are \"artificial.\" You might as well go the full measure, and say if you want to keep what's \"yours\" defend it yourself. Don't expect some artificial private property laws to save you. And if writing is turned purely into a hobby of the passionate, they'll be a lot less of it, because the people who are good at it will be forced to expend their energy doing other things to support themselves (if they're a member of the idle rich). > 2. To my knowledge, Amazon is not known to violate a preexisting GPL license. You missed the point. Copyright is foundational to the GPL: without it, no GPL. \"Amazon is not known to violate a preexisting GPL license,\" for the same reason they don't print up their own \"pirated\" copies of the latest bestseller to tell, instead of buying copies from the publisher: it would be illegal. > 3. This has already happened twice to me, and frankly, I am not worried. I can still carve out my limited focused niche. It did, did it? Tell the story. > your beliefs about individual greed would be very different. What do you mean my \"beliefs about individual greed?\" Do tell. reply OutOfHere 12 hours agorootparentFor well over ten years now, companies like Facebook/Meta and Google have perused research code by academic and other researchers, seen what is catching on, then soon made better versions themselves. Google in particular has soon also offered commercial services for the same, outcompeting the smaller commercial services offered by the researchers. Frankly, I am glad Google does it because the world is better for it. It's the same with Amazon because frankly it's a lot of work to scale a service globally, and most smaller groups would do a far worse job at it. My criteria for what is good vs bad is what makes the world better or worse as a whole, not what makes me better off. It is clear to me that the availability of AI triggered by GPT has made the world better, and if OpenAI has to violate copyrights to get there or stay there, that's a worthwhile sacrifice imho. There is still plenty of commercial scientific and media writing that is not going away even if copyright laws were to disappear. Book readership (outside of school) is already very low now, and is only going to get lower, close to zero. You might be defending a losing field. An AI is going to be able to write a custom book (or parts of it) on demand - do you see how this changes things? Ultimately I realize that we have to put food on the table, but I don't think copyrights are necessary for it. There are plenty of other ways to make money. reply npvrite 1 hour agoprevUnfortunately, many whistleblowers don't take proper precautions to release information that will make them a target. QubesOS, disposable laptop, faraday cage, and never work from home. https://www.qubes-os.org/ reply bdndndndbve 5 hours agoprevThis is extremely sad and I'm sorry for Suchir's family and friends. As someone who has struggled with suicidal ideation while working in the tech industry for over a decade, I do wonder if the insane culture of Bay Area tech has a part to play. Besides the extreme hustle culture mindset, there's also a kind of naive techno-optimism that can make you feel insane. You're surrounded by people who think breaking the law is OK and that they're changing the world by selling smart kitchen appliances, even while they're exploiting workers in developing countries for cheap tech support and stepping over OD victims outside their condo. This mindset is so pervasive you really start to wonder if you're crazy for having empathy or any sense of justice. I have no special insight except to guess that going from being an obviously brilliant student at Berkeley to a cut-throat startup like OpenAI would be a jarring experience. You've achieved everything you worked your whole life for, and you find you're doing work that is completely out of whack with your morals and values. reply imglorp 4 hours agoparentFurther piling on potential stress for any whistleblower in a highly specialized field, once you're publicly critical of that field, you're basically unemployable there. And that's without any active retribution from the offending employer. Any retribution, such as blacklisting among peer HR departments would bring an even dimmer outlook. reply gsibble 5 hours agoparentprevWell put. Almost all of the SF startups I worked for were run by sociopaths willing to break any rule I eventually learned. One is now being charged by the FTC for massive violations. I hated the immoral mindset of winning at the cost of everything from employee comfort to flagrantly illegal activities with customers. reply strogonoff 11 hours agoprevSuchir’s suicide (if it was a suicide) is a tragedy. I happen to share some of his views, and I am negative on the impact of current ML tech on society—not because of what it can do, but precisely because of the way it is trained. The ends do not justify the means—and it is easy to see the means having wide-ranging systemic effects besides the ends, even if we pretended those ends were well-defined and planned (which, aside from the making profit, they are clearly not: just think of the nebulous ideas and contention around AGI). reply gsibble 4 hours agoparentI enjoy using Generative AI but have significant moral qualms with how they train their data. They flagrantly ignore copyright law for a significant amount of their data. The fact they do enter into licensing agreements with some publishers basically shows they know they are breaking the law. reply lolinder 20 hours agoprevNormally the word \"whistleblower\" means someone who revealed previously-unknown facts about an organization. In this case he's a former employee who had an interview where he criticized OpenAI, but the facts that he was in possession of were not only widely known at the time but were the subject of an ongoing lawsuit that had launched months prior. As much as I want to give this a charitable reading, the only explanation I can think of for using the word whistleblower here is to imply that there's something shady about the death. reply anon373839 19 hours agoparent> Normally the word \"whistleblower\" means someone who revealed previously-unknown facts Not to be pedantic, but this is actually incorrect, both under federal and California law. Case law is actually very explicit on the point that the information does NOT need to be previously unknown to qualify for whistleblower protection. However, disclosing information to the media is not typically protected. reply Terr_ 18 hours agorootparentI think their post boils down to: \"This title implies someone would have a strong reason to murder them, but that isn't true.\" We can evaluate that argument without caring too much about whether the writer intended it, or whether some other circumstances might have forced their word-choice. reply blast 17 hours agorootparentFrom the article: \"The Mercury News and seven sister news outlets are among several newspapers, including the New York Times, to sue OpenAI in the past year.\" That's a conflict of interest when it comes to objective reporting. reply lolinder 19 hours agorootparentprevRight, but as you note the legal definition doesn't apply here anyway, we're clearly using the colloquial definition of whistleblower. And that definition comes with the implication that powerful people would want a particular person dead. In this case I see very little reason to believe that would be the case. No one has hinted that this employee has more damning information than was already public knowledge, and the lawsuit that he was going to testify in is one in which the important facts are not in dispute. The question doesn't come down to what OpenAI did (they trained on copyrighted data) but what the law says about it (is training on copyrighted data fair use?). reply anon373839 19 hours agorootparentWell, I still disagree. In reality companies still retaliate against whistleblowers even when the information is already out there. (Hence the need for Congress, federal courts and the California Supreme Court to clarify that whistleblower activity is still protected even if the information is already known.) I, of course, am not proposing that OpenAI assassinated this person. Just pointing out that disclosures of known information can and do motivate retaliation, and are considered whistleblowing. reply chgs 18 hours agorootparent> I, of course, am not proposing that OpenAI assassinated Presumably you mean the company. How many decades before AI has that ability. reply stefan_ 4 hours agorootparentprevWe are? It's just you here, making a bizarre nitpick in a thread on a persons death. reply lolinder 4 hours agorootparentThe thread looks very different than it did when I wrote any of the above—at the time it was entirely composed of people casually asserting that this was most likely an assassination. I wrote this with the intent of shutting down that speculation by pointing out that we have no reason to believe that this person had enough information for it to be worth the risk of killing him. Since I wrote this the tone of the thread shifted and others took up the torch to focus on the tragedy. That's wonderful, but someone had to take the first step to stem the ignorant assassination takes. reply calf 19 hours agoparentprev> Normally the word \"whistleblower\" means someone who revealed previously-unknown facts about an organization. A whistleblower could also be someone in the process of doing so, i.e. they have a claim about the organization, as well as a promise to give detailed facts and evidence later in a courtroom. I think that's the more commonsense understanding of what whistleblowers are and what they do. Your remark hinges on a narrow definition. reply jll29 3 hours agorootparentTechnically, the term \"insider witness of the prosecution\" could fit his role. reply ninetyninenine 19 hours agoparentprevNo. Anytime someone potentially possesses information that is damning to a company and that person is killed… the low probability of such an even being a random coincidence is quite low. It is so low such that it is extremely reasonable to consider the potential for an actual assassination while not precluding that a coincidence is a possibility. reply lolinder 19 hours agorootparent> Anytime someone potentially possesses information that is damning to a company and that person is killed… the low probability of such an even being a random coincidence is quite low. You're running into the birthday paradox here. The probability of a specific witness dying before they can testify in a lawsuit is low. The probability of any one of dozens of people involved in a lawsuit dying before it's resolved is actually rather high. reply smt88 18 hours agorootparentA 26yo dying is not \"one of dozens,\" it's ~1/10,000 in the US (and likely much lower if we consider this guy's background and socioeconomic status). reply lolinder 16 hours agorootparentIf we're going to control for life situations, you have to calculate the suicide rate for people who are actively involved in a high stakes lawsuit against a former employer, which is going to be much higher than average. Then factor in non-suicide death rates as well. Then consider that there are apparently at least 12 like him in this lawsuit, and several other lawsuits pending. I'm not going to pretend to know what the exact odds are, but it's going to end up way higher than 1/10k. reply ninetyninenine 17 hours agorootparentprevRight, so given the paradox, consider both possibilities rather then dismiss one like the parent is implying here. reply lolinder 16 hours agorootparentI've considered the probabilities of both and find one to be far more likely. reply XorNot 14 hours agorootparentprevOr you could just look at the facts of the case (currently: no foul play suspected). Are the cops in on it? The morgue? The local city? How high does this go? This isn't something which happened in isolation. This isn't \"someone died\". It's \"someone died, and dozens of people are going to sign off that this obviously not a suicide was definitely a suicide\". Like, is that possible? Can you fake a suicide and leave no evidence you did? If you can then how many suicides aren't actually suicides but homicides? How would we know? You're acting like it's a binary choice of probabilities but it isn't. reply FireBeyond 17 hours agorootparentprevI've listened to many comments here on some of these, saying it must be assassination \"because the person insisted, \"If I'm ever found dead, it's not suicide!\".\" This is sometimes despite extensive mental health history. Entirely possible. But in my career as a paramedic, I've (sadly) lost count of the number of mental health patients who have said, \"Yeah, that was just a glitch, I'm not suicidal, not now/nor then.\" ... and gone on to commit or attempt suicide in extremely short order. reply SideQuark 16 hours agorootparentprevComputer the probability, don’t make claims without making a solid estimate. No, it’s not low. No need to put conspiracies before evidence, and certainly not by making claims you’ve not done no diligence on. And the article provides statements by professionals who routinely investigate homicides and suicides that they have no reason to believe anything other than suicide. reply ADeerAppeared 16 hours agoparentprev> but the facts that he was in possession of were not only widely known at the time but were the subject of an ongoing lawsuit that had launched months prior. That is an exceedingly charitable read of these lawsuits. Everyone knows LLMs are copyright infringement machines. Their architecture has no distinction between facts and expressions. For an LLM to be capable of learning and repeating facts, it must also be able to learn and repeat expressions. That is copyright infringement in action. And because these systems are used to directly replace the market for human-authored works they were trained on, it is also copyright infringement in spirit. There is no defending against the claim of copyright infringement on technical details. (C.f. Google Books, which was ruled fair use because of it's strict delineation of facts about books and the expressions of their contents, and provides the former but not a substitute for the latter.) The legal defense AI companies put up is entirely predicated on \"Well you can't prove that we did a copyright infringement on these specific works of yours!\". Which is nonsense, getting LLMs to regurgitate training data is easy. As easy at it is for them to output facts. Or rather, it was. AI companies maintain this claim of \"you can't prove it\" by aggressively filtering out any instances of problematic content whenever a claim surfaces. If you didn't collect extensive data before going public, the AI company quickly adds your works to it's copyright filter and proclaims in court that their LLMs do not \"copy\". A copyright filter that scans all output for verbatim reproductions of training data sounds like a reasonable compromise solution, but it isn't. LLMs are paraphrasing machines, any such copyright filter will simply not work because the token sequence 2nd-most-probable to a copyrighted expression is a simple paraphrase of that copyrighted expression. Now, consider: LLMs treat facts and expressions as the same. Filtering impedes the LLM's ability to use and process facts. Strict and extensive filtering will lobotomize the system. This leaves AI companies in a sensitive legal position. They are not playing fair in the courts. They are outright lying in the media. The wrong employees being called to testify will be ruineous. \"We built an extensive system to obstruct discovery, here's the exact list of copyright infringement we hid\". Even just knowing which coworkers worked on what systems (and should be called to testify) is dangerous information. Sure. The information was public. But OpenAI denies it and gaslights extensively. They act like it's still private information, and to the courts, it currently still is. And to clarify: No I'm not saying murder or any other foul play was involved here. Murder isn't the way companies silence their dangerous whistleblowers anyway. You don't need to hire a hitman when you can simply run someone out of town and harass them to the point of suicide with none of the legal culpability. Did that happen here? Who knows, phone & chat logs will show. Friends and family will almost certainly have known and would speak up if that is the case. reply shusaku 19 hours agoparentprevnext [3 more] [flagged] bbqfog 19 hours agorootparentIsn't it the other way around since OpenAI is training their models on news company content? OpenAI has behaved extremely unethical the entire time it has existed. It's very likely there is foul play here, it fits the pattern. reply lolinder 19 hours agorootparentnext [2 more] [flagged] bbqfog 19 hours agorootparentI wasn't even talking about the copyright issues. I was talking about things like this and Sam Altman's sister's accusations. Things way beyond what any reasonable person would consider moral. https://www.timesofisrael.com/openais-sam-altman-says-israel... reply lyu07282 20 hours agoparentprevYou assume he revealed everything he knew, he was most likely under NDA, the ongoing lawsuit cited him as a source. Which presumably he didn't yet testify for and now he never will be able to. His (most likely ruled suicide inb4) death should also give pause to the other 11 on that list: > He was among at least 12 people — many of them past or present OpenAI employees — the newspaper had named in court filings as having material helpful to their case, ahead of depositions. reply lolinder 20 hours agorootparentBeing one of 12+ witnesses in a lawsuit where the facts are hardly in dispute is not the same as being a whistleblower. The key questions in this lawsuit are not and never were going to come down to insider information—OpenAI does not dispute that they trained on copyrighted material, they dispute that it was illegal for them to do so. reply bobthecowboy 19 hours agorootparentIt seems like it would matter if they internally believed/discussed it being illegal for them to do so, but then did it anyway and publicly said they felt they were in the clear. reply Filligree 12 hours agorootparentThat could matter for the judgement if it's found to be illegal. But OpenAI does not get to decide that what they're doing is illegal. reply lyu07282 19 hours agorootparentprevSo the lawyers who said they had \"possession of information that would be helpful to their case\" were misleading? Your whole rationalization seems very biased. He raised public awareness (including details of) of some wrongdoing he perceived at the company and was most likely going to testify about those wrongdoings, that qualifies as a whistleblower in my book. reply lolinder 19 hours agorootparent> \"possession of information that would be helpful to their case\" were misleading? I didn't say that, but helpful comes on a very large spectrum, and lawyers have other words for people who have information that is crucial to their case. > that qualifies as a whistleblower in my book. I'm not trying to downplay his contribution, I'm questioning the integrity of the title of TFA. You have only to skim this comment section to see how many people have jumped to the conclusion that Sam Altman must have wanted this guy dead. reply sheepscreek 2 hours agoprevDeeply saddening, especially given what was at stake. It takes someone truly exceptional to challenge the establishment. RIP Suchir. May the light of your candle, while it burned, have sparked many others. reply dtquad 20 hours agoprevInteresting that the NYT article about him states that OpenAI started developing GPT-4 before the ChatGPT release. They sure were convinced by the early GPT-2/3 results. >In early 2022, Mr. Balaji began gathering digital data for a new project called GPT-4 https://www.nytimes.com/2024/10/23/technology/openai-copyrig... reply minimaxir 20 hours agoparentChatGPT was a research project that went megaviral, it wasn't intended to be as big as it was. Training a massive LLM on the scale of GPT-4 required a lot of lead time (less so nowadays due to various optimizations), so the timeframe makes sense. reply nextworddev 13 hours agoparentprevI think OpenAI officially said GPT4 finished training late 2022 alredy reply tempeler 5 hours agoprevPeople neglect the priorities of working life. First safety, it is best to avoid any unnecessary risks and to act so that you stay safe. second security. reply atleastoptimal 19 hours agoprevEveryone will naturally speculate about anything current or former OpenAI employees do, whether it’s if they resign, the statements they make, or in this case their own suicide. It’s only fair not to speculate too far given that since there are thousands of current and former OpenAI employees, they are subject to the same conditions as the general population. reply nox101 16 hours agoprevBeing this is ostensibly related to an AI company trying to make AGI reminds me of \"Eagle Eye\" https://www.imdb.com/title/tt1059786/ reply nox101 15 hours agoparentCurious why the downvote? Because someone actually died? It doesn't change the fact that \"Eagle Eye\" is about (spoiler) an AGI killing people both directly and indirectly (by manipulating others, AI \"Swats\" you, ...) and here is a company trying to make AGI. If the AGI actual existed it could certainly indirectly get people killed that were threatening it's existence. It could \"swat\" people. Plant fake evidence (mail order explosives to the victim's house, call the FBI). It could manipulate others. Find the most jealous unstable person. Make up fake texts/images that person is having an affair with their partner. Send fake messages from partner provoking them into action, etc... Convince some local criminal the victim is invading their turf\". We've already seen several examples of LLMs say \"kill your parents/partner\". reply jarsin 2 hours agorootparentIt's highly possible that in the next tragedy carried out by a kid that has messages from any of these chatbots that can be construed as manipulation will result in criminal prosecutions against the executives. Not just lawsuits. reply alsetmusic 20 hours agoprevhttps://archive.is/xBuPg reply xbar 17 hours agoprevWhat a terrible and sad loss. reply xvector 17 hours agoprevMetapost - Reading the (civilized!) comments on HN vs those on Reddit is such a contrast. I'm a bit worried that while regulators are focusing on X/Facebook/Instagram/etc. from a moderation perspective, not one regulator seems to be looking at the increasingly extreme and unmoderated rhetoric on Reddit. People are straight up braying for murder in the comments there. I'm worried that one of the most visited sites in the US is actively radicalizing a good chunk of the population. reply bryan0 13 hours agoparentInteresting you say that about HN, because reading this (and other) threads I have the opposite view: HN is devolving into Reddit-like nonsense. reply talldayo 3 hours agoparentprev> I'm worried that one of the most visited sites in the US is actively radicalizing a good chunk of the population. Thank goodness they're an American site, where the precedent for persecuting websites for active radicalization is practically nonexistent. reply hilux 19 hours agoprevDude graduated from Cal with a 3.98 in Computer Science! Certainly kicks my sorry ass. Being brilliant can be a burden, I guess. reply aws_ls 6 hours agoparentAlso reached Master level at Codeforces,well before joining his engineering course: https://codeforces.com/profile/suchir reply dudeinjapan 7 hours agoprevWhen I die, as a last wish, I hope people will go wild with speculative assassination theories. Especially if the police find \"no evidence\" of foul-play or the coroner says it was due to \"old age\"--it can only mean the cops and docs are also in on it. reply kachapopopow 16 hours agoprevOkay, first boeing now openai... Yep, my view of this world being more civilized than portrayed in the movies is disappearing every day. Looks like we're going to start having to take conspiracy movie-like theories seriously now. reply slavik81 15 hours agoparentThere's surveillance camera footage of the vehicle John Barnett was sitting in at the time of his death. The conspiracy theories are not credible. reply mellosouls 18 hours agoprevNon-paywalled alternative (also the source in the other Reddit HN post): https://www.siliconvalley.com/2024/12/13/openai-whistleblowe... reply 1vuio0pswjnm7 12 hours agoparentNo \"paywall\" unless Javascript is enabled. reply dgfitz 20 hours agoprevI wonder who called to ask about his well-being. The Boeing guy killed himself, this guy apparently killed himself. The pattern of David vs Goliath, where David kills himself, is almost becoming a pattern. reply kube-system 19 hours agoparentWhen David is just a nobody, and Goliath has all of the legal and PR resources in the world, Goliath doesn't even have to swing a punch. Goliath can just drive them crazy with social and legal pressure. Also, David might have been a bit of a decision-making outlier to begin with, being the kind of person who decides going up against Goliath is a good idea. reply kamaal 13 hours agorootparentI work with a relative who is in the real estate space here in India and often deals with land shark mafia. The biggest thing I learned from him, to win in these situations is don't fear or not be afraid of consequences. You need to have ice water flowing in your veins if you are about to mess with something big. At worst you need to have benign neglect for the consequences. Often fear is the only instrument they have against you. And if you are not afraid, they will likely not contest further. Threat of jail, violence or courts is often what they use to stop you. In reality most people are afraid to go to war this way. Its messy and often creates more problems for them. reply idiot-savant 12 hours agorootparentprevThey’ve been pulling out the Reverse Luigi for decades. reply nialv7 19 hours agoparentprev> this guy apparently killed himself. where did you get that? this article doesn't say a cause of death. reply dgfitz 19 hours agorootparent> The medical examiner’s office has not released his cause of death, but police officials this week said there is “currently, no evidence of foul play.” reply thayne 11 hours agorootparentIt now says > The medical examiner’s office determined the manner of death to be suicide reply danparsonson 19 hours agorootparentprevSo... murder and suicide are the only possible causes of death? reply dgfitz 18 hours agorootparentI guess “apparently” doesn’t mean what I thought it did. My apologies. reply princevegeta89 14 hours agorootparentprevThere is confirmed news now that he killed himself reply zusammen 18 hours agoparentprevI’ve been studying corporate whistleblowers for more than 20 years. You never know for sure which ones are real suicides and which are disappearings, but TPTB always do shitty things beforehand to make the inevitable killing look like a suicide. Even if people figure out that it’s not a suicide, it fucks up the investigation in the first 24 hours if the police think it’s a suicide. A case of this “prepping” that did not end in death was Michael O. Church in 2015-16, but they ended up being so incompetent about it that they called it off. Still damaged his career, though. On the flip side, that guy was never going to make it as a tech bro and is one hell of a novelist, so…? The “prepping” aspect is truly sickening. Imagine someone who spends six months trying to ruin someone’s life so a fake suicide won’t be investigated. This happens to all whistleblowers, even the ones who live. By the way, “hit men” don’t really exist, not in the way you think, but that’s a lesson for another time. reply bbqfog 18 hours agorootparentThat's really interesting. Do you have any books or information about Michael O. Church for further reading? Wasn't he a HN user? reply zusammen 17 hours agorootparentHe was long before me. His case is odd because he was way too “openly autistic” for the time and probably wouldn’t have been able to win support at the level to be a real threat, which is probably why they didn’t bother to finish the job. He put a novel on RoyalRoad that is, in my opinion, better than 98% of what comes out of publishing houses today, though it has a few errors due to the lack of a professional editor, and I haven’t finished it yet so I can’t comment on its entirety. It’s too long (450k words) and maybe too weird for traditional publishing right now, but it’s a solid story: https://www.royalroad.com/fiction/85592/farisas-crossing I will warn you that the politics are not subtle. reply derektank 20 hours agoparentprevIf there was a gun involved, I would imagine a neighbor would have called. He was found in his apartment. reply CyberDildonics 20 hours agoparentprevDavid vs goliath where david swears he will never kill himself and that if anything happens to him it is someone coming after them, then david kills himself right before going to court to testify. reply pkkkzip 20 hours agoparentprevBoeing guy and OpenAI whistleblower were both seen as \"not depressed\" and have even gone far as to say that if anything happened to him that it wouldn't have been an accident. I'm not sure why there are so many comments trying to downplay and argue around whether OpenAI was a whistleblower or not he fits pretty much all the definition. OpenAI was suspected of using copyright data but that wasn't the only thing OpenAI whistleblower was keeping under wraps given NDA. The timing of OpenAI partnering with US military is odd. reply kube-system 19 hours agorootparent> Boeing guy [...] were both seen as \"not depressed\" and have even gone far as to say that if anything happened to him that it wouldn't have been an accident. Yes, but also, his own brother said: “He was suffering from PTSD and anxiety attacks as a result of being subjected to the hostile work environment at Boeing, which we believe led to his death,” Internet echo chambers love a good murder mystery, but dragging a quiet and honest employee who works in the trenches through a protracted, public, and stressful legal situation can be very tough. reply zusammen 18 hours agorootparentprevWhat whistleblowers go through would make anyone depressed. Often the goal is to destroy the person psychologically and destroy their credibility. Often, this is enough and they don’t even bother going through with the hit, because it turns out that even billionaires can’t “just hire a hit man.” Real life corporate hits tend to compromise people the person trusts, but whistleblowers are both sparing with their trust and usually poor, which makes it harder because there are fewer people to compromise. reply SideQuark 16 hours agoparentprevYeah, the pattern is real. The patterns of high male suicide rates and Goliaths having a lot of employees combine into a pattern of the innumerate invoking boogeymen wherever it suits their world view, evidence and reason be dammed. reply cryptozeus 20 hours agoprevmay he rip! reply DevX101 20 hours agoprevAnyone who's a whistleblower should compile key docs and put it in a \"dead man's switch\" service that releases your testimony/docs to multiple news agencies in the event of your untimely demise. The company you're whistle blowing against and their major shareholders should know this exists. Also, regularly post public video attesting to you current mental state. reply exceptione 19 hours agoparent> multiple news agencies In the case of the US, you cannot make your selection wide enough. For optimal security, get it to both local news organizations and serious European press agencies. The US news media do not have independent editorial boards. Several titles are actually from the same house. Corporate ownership, and professionals going to the dark side via https://en.wikipedia.org/wiki/Elite_capture are just some other risks. Even if it gets published, your story can be suppressed by the way the media house deals with it. Also, there are many ways to silence news that is inconvenient or doesn't fit belief schemes, good example https://news.ycombinator.com/item?id=42387549 reply pyuser583 12 hours agorootparentAmerican press is much more independent than European press. When WSJ broke the Elizabeth Holmes story, much ink was spilled showing how no European paper would take on a corporation strong government support. Looking at Europe, governments first instinct is to protect national favorites. European whistleblowers are likely to face defamation suits, something thankfully difficult in America. reply TowerTall 10 hours agorootparentIdenpendent from what or whom. Most American media is owned by a tiny handfull of people. reply esperent 10 hours agorootparentprev> much ink was spilled showing how no European paper would take on a corporation strong government support Could you provide some examples of this? I know it's possible in the UK to get a court order to prevent media coverage, but I didn't know that was the case in other European countries. reply hulitu 10 hours agorootparentprev> European whistleblowers are likely to face defamation suits, something thankfully difficult in America. In US they will always find a \"minor\" who was \"raped\" 20 years ago. Or the whistleblower will suddenly commit suicide. reply rightbyte 4 hours agorootparentThe Boeing whistleblower comes to mind. reply BrandoElFollito 7 hours agorootparentprevThis is what was done with WikiLeaks - a few major European journals worked on the information together reply ethbr1 5 hours agorootparentDepending on which release, Wikileaks normally chose an international group of media partners, including US, British, European, and Russian ones. reply BrandoElFollito 5 hours agorootparentYes, I know that in France Le Monde did that, and they were in close cooperation with I think The Guardian and El Mundo reply hulitu 10 hours agorootparentprev> serious European press agencies. There are almost none left. > The US news media do not have independent editorial boards. The EU also don't. They are all penetrated by NGOs reply bubaumba 17 hours agorootparentprev> European press agencies It's very naive to believe in 'European press'. To get the idea check Ukrainian war coverage. What you'll see first is how single sided it is. This cannot be a coincidence. It can be only a result of total control. I respected 'The Guardians' before, but after eyes opening it appears to be the most brainwashing and manipulative there. Very professionally done, must admit. The problem isn't just that war, it's likely everything and I have no easy way to check for example what really happened in Afghan war. Did US really won like Biden said? reply consumer451 17 hours agorootparent> It's very naive to believe in 'European press'. To get the idea check Ukrainian war coverage. What you'll see first is how single sided it is. This is such a wild take from my POV, a person in the EU. Have you considered the possibility that the nearest imperialist power beginning to violently invade Europe again is likely to trigger a common reaction? This is one of those rare cases in modern history where there is a clear right vs. wrong. What exactly do you expect the news to talk about that is less “single sided?” reply bubaumba 16 hours agorootparentI can explain a bit. Russians living in Empire of Evil can see all internet including US and EU news. At the same time 'Putin propaganda' channels are blocked in EU. In EU only one side is available. This creates an information bubble, as intended. Which is a basic crowd control technique used to drive public opinion. In this case to support the war. The result is obvious, EU polls show much stronger support than the rest of the world. Even though media claims most of the world is against Putin, if you look at the map it's only minority, NATO and a few allies. In some EU countries it's even a crime look through the bubble's wall. Most don't realize it even exists. They accept the arguments from their politicians. Like it's a business opportunity, or it's a cheap way to harm Putin. The price for that is hundreds of thousands of human lives on both sides. Which is generally considered as ok, as those are Russians and Ukrainians, not us. Actually media doesn't talk much about it. reply kstenerud 10 hours agorootparentDoesn't seem to jibe with https://www.techspot.com/news/105929-russia-tests-cutting-it... reply mylidlpony 16 hours agorootparentprevHahahaha, what? Most of western news sources are blocked in russia after they published Bucha reports. They are literally jailing people for mentioning it on personal vk pages and such. reply usea 15 hours agorootparentprevEuropeans having stronger opinions than others about Russia invading Europe is not evidence of a conspiracy. reply scotty79 8 hours agorootparentprev> At the same time 'Putin propaganda' channels are blocked in EU. I don't think that's true. You can find a lot of that online, with or without commentary. There are even European comentators siding with adjecent views. Though it doesn't leak into European public media too much (although some of its more absurdist concepts sadly do). It's just that \"the other side of the story\" is something that vast majority of Europeans are repulsed by because of its intrinsic idiocy, blatant disingenuity and evilness. Some of the European countries that got out from under russian influence remember it from the times of poverty and oppression. That's where the part of the opinion bias on that subject between Europe and the rest of the world comes from. Firsthand expeirience with russia. Supporting Ukraine is both helping Ukraine with their current russian expeirience and possibly a hope of saving all future Europeans from having russian expeirience ever again. reply kristiandupont 10 hours agorootparentprev>In this case to support the war. while all of you Putin supporters are such a peace loving people, right? reply OfficeChad 11 hours agorootparentprevFuck off. reply red_trumpet 10 hours agorootparentprev> Russians living in Empire of Evil can see all internet including US and EU news. That's just not true, e.g. Russia also blocked the German propaganda channel dw.com (Deutsche Welle). reply ulfw 10 hours agorootparentAh yes calling DW a propaganda channel. We found the Russian state actor account here. reply red_trumpet 7 hours agorootparentDW is literally the only German state owned media, financed directly by tax money. And they don't even have a German broadcast anymore. Compare this to the other German public broadcasting (ARD and ZDF), who are financed by their own (obligatory) dues (\"Rundfunkbeitrag\"), which is set by politics, but cannot be easily taken away from them. reply immibis 5 hours agorootparentprevHere's a litmus test for German propaganda channels: What does it say about Palestine? reply konart 13 hours agorootparentprev>This is one of those rare cases in modern history where there is a clear right vs. wrong. There is no right or wrong in politics. reply McDyver 12 hours agorootparentYes, yes there is. It is wrong to kill or perform any violence or harm against children in any war context. reply akoboldfrying 8 hours agorootparentDo you think killing a child's parents does not harm them? You haven't thought this through. reply sssilver 11 hours agorootparentprevEvery single developed country today touting moral rights has its foundation in those \"wrongs\". Its citizens gleefully consuming the resources those \"wrongs\" have created, so they can preach morality online. It is the nature of life itself to \"kill and perform violence\", children and otherwise. \"The strong do what they can, and the weak suffer what they must\". Death is, as of now, life's only mechanism for iteration in its process of endless prototyping. Every marvel that humankind has produced has its roots in extreme violence. From the creation of Ancient Greece to the creation of the United States, children had to die horrible deaths so that these things could come to be. Anyone can make arbitrary claims about what's right and what's wrong. The only way to prove such a claim is through victory, and all victory is violence against the loser. reply ribadeo 9 hours agorootparentThanks for summarizing so eloquently what is WRONG with the precept that might equals right. If she floats she's a witch, if she drowns she must",
    "originSummary": [
      "Former OpenAI employee and whistleblower Suchir Balaji was found dead in his San Francisco apartment, with authorities ruling it a suicide.",
      "Balaji had accused OpenAI of copyright violations in training its ChatGPT program, leading to multiple lawsuits against the company.",
      "OpenAI denies the allegations, asserting that its practices are legal under \"fair use\" laws, while Balaji was a key figure in the ongoing legal battles."
    ],
    "commentSummary": [
      "Suchir Balaji, a former OpenAI employee known for his critical views on the company's use of copyrighted data, was found dead in his San Francisco apartment.",
      "His death, ruled a suicide, has sparked public speculation and discussions, particularly due to his expected role in providing key information in lawsuits against OpenAI.",
      "The circumstances surrounding his death have led to increased attention and debate within the tech community."
    ],
    "points": 886,
    "commentCount": 348,
    "retryCount": 0,
    "time": 1734126989
  },
  {
    "id": 42411608,
    "title": "Elon Musk wanted an OpenAI for-profit",
    "originLink": "https://openai.com/index/elon-musk-wanted-an-openai-for-profit/",
    "originBody": "body{font-family:Arial,Helvetica,sans-serif}.container{align-items:center;display:flex;flex-direction:column;gap:2rem;height:100%;justify-content:center;width:100%}@keyframes enlarge-appear{0%{opacity:0;transform:scale(75%) rotate(-90deg)}to{opacity:1;transform:scale(100%) rotate(0deg)}}.logo{color:#8e8ea0}.scale-appear{animation:enlarge-appear .4s ease-out}@media (min-width:768px){.scale-appear{height:48px;width:48px}}.data:empty{display:none}.data{border-radius:5px;color:#8e8ea0;text-align:center}@media (prefers-color-scheme:dark){body{background-color:#343541}.logo{color:#acacbe}}Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"openai.com\",cType: 'managed',cRay: '8f2072412b64fa92',cH: 's4Pu1c4iUIobMVvEFzTKKT8N71e4Qd5D5m2HSwBsbeQ-1734202926-1.2.1.1-IIWgiJM0d3dtfDHyGk8kMywr7LyGTOHbPL3ZMJY3UZjfPRvRJSzs6cbyJbEcV19I',cUPMDTk: \"\\/index\\/elon-musk-wanted-an-openai-for-profit\\/?__cf_chl_tk=BXNsM0hR3xEkpazUXXM2AMinc.u5hM80eyyoxoz5cKo-1734202926-1.0.1.1-LzETXWSm8epoAoR.aUixD13Yv0Tfk67wbVHlZq5YCQk\",cFPWv: 'g',cITimeS: '1734202926',cTTimeMs: '1000',cMTimeMs: '390000',cTplC: 1,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/index\\/elon-musk-wanted-an-openai-for-profit\\/?__cf_chl_f_tk=BXNsM0hR3xEkpazUXXM2AMinc.u5hM80eyyoxoz5cKo-1734202926-1.0.1.1-LzETXWSm8epoAoR.aUixD13Yv0Tfk67wbVHlZq5YCQk\",md: \"60XLD26PLXtgnb5u8I9H4oXObyg3T9Bx8il5IjtMuTg-1734202926-1.2.1.1-o7ROL5VYy0CPJEmXC.xmVzGBolhkOMYmkTNWh7WmbTch6jSh_K35isCukp8sW4Fx3IdXQLUGmkLvUC6PBEhexDfjt9P2nNBP3tqLPJIU.hJf8zMqop9_kpOeXcaei62tyHIb_1mNP8.Hsd2TGZuVPZBIS04Q9scTs_C0WEBo3fOPH0N.I5NELLaXwBfGgolK_iLrvd6SQIRK934WooRFlvzaO3Upi92QnqFkFa4mHQbEfDKdos2cIXajbDSCpMxgdtO3CqTOAplLOhTSi5oMdEyFXj66T2kwfPg7jMrcrgTAAjftfDyj6euZIoFLjCASgIMClEVMZD5cqI3gjB7A.ra4FsqZVM6.RKAX5N.uoQkzBq.W1HdBUtTv.LdxPuaf4RxXNNxdTuii4r88hE0L5Vjht3CJb_uZlMLa79EnGQ_lCSzFkWMkoALnlSqnwP_a0VPOVHtqO.tTw8NvtMMwOURWvIBC69EZ91tHyTEEZNfjz7OYexcMpEehoCTFwqCqSNjszuTk9dRYNF9jq0DBMSWTUx7TU_GSaulCjhPMy.25qqOunlXAOeCpSULEyrhnqyGqm1FCGyUtjed9twyyNvvRP2ul452IVoyXjdtVtSOzsHMlMgjBKHfdw76xJc.k38mGBMB.T6x4hd2QAvesNSPJR79___Rq5ul.JEzy23QYQLqGEGTdVqOE_Tcgt4pSsNBqN9gEHa7ONDzUxp8jzyA9EMJ9biYZuZL83tgvGS8L.lmibFtFE6ZZsAuLX39aLYMnKd4__iASoNpQo6RjzIdq0Ghoz926_7uX_5MWpkbEEawYYk0y.PJHJrlKqVg3YPxb8ZVh_98jDwr.fb881sfyr2kJvPPGbxDXOjxxkXXfqt4SGx10v.YsOX3QL1n3D2meYn0YU_BSZB42UHkoiMsYENuwo2OWG9mno7bhM4MIrwRREwme2sV5IWk4WIfnyywauzlMgORyjFw33a1M6uK6CjZ0H4BqVux7M7y2KcSXO.ZZVb5WWfg0bv7q4fagzg3TBBmS2qsDo90q1lWS0IK.3Jazcss0McOg5yTStSet1lIhYbp6Lxq39Ez7Sxq01mJraadSQFmCS.YWVNZfe4Jqv8uOrB6Ylo2.fqdpvfTTKXL.XVTCxVR8qocvxVN99qSrNeTiQjY4JpSPW1bZgBw19x2jfaveNAKjosT.8ps.xNk.NKr1rQeXVgWHFrEj1IXZ.AQSQx6YrcX4AK3.egDo.1v9V97iXR4Z_dNk.rC58RfIWZ_ylmOXl9FEcgqSVPzHqaUz7sd8IbzDex.QHC8fHT0p6WHyLTYNWFmEpS78isfaVbMgQvHdIDtQrffPiAdYLiP_kY749HmPNuIpImaz5Janb02mgscKCX.a3EZtRJt7hzkmkZ.E2FRoYAbnurhUVVuItC8wz5sMCEcT14lM8WE1C0dSRe6NppqmkVrL_Q.vAEhCTBBqpmidwBjrRta.197qu71pbQDl4flvh7KjZbUz9tQcurYVldCWo82zcQv0JHMJFz01A3d6saO4pZsil68oGxwwkvZvtTQaeUEgZnugCeNSsGheyNXmWFMhMzXObsezcVnWQtLX9aDrPEuFmpQu91WXDWUs.tICOSGVqguPfQ7_DlACc0yrEy_jRk8TUTuBc_OpCCYW4e0ySdpiQiDAOrL7R0LsaUSEDIi81f0NHUuzVTj4J7GBM13GEwvW16O6GsJffdvRipBKdBPPoBusuRfqkN0qYULdSmdRSiMto0PZjXrNeqM7k8PHPvbZOI9Ol4NdsHT1Qd7k9k4_AaZ_6Nxi.KhyngpKF3GN8GA4h093F45YeFgx6PCP4p4AMCktnRvzJb0kSy37ekQkDdkQkbi2pxYrTThVElv6FfI.j8khDQQZC_ZAR5Wl6wDQ5a_JOUdQ8JDJVWNuzvkDhMIv1rmW6GrGRixybnQAefL6iPLLPJSsI22RCYCR24KdTFfgYms6orIwR0EAykyEezigUN4UWFWNFH82hE3.f9eRv26RDiiBn1H1KtnSyqaEFRfbHrMYM7Gf4dTj3Yq.yzd_RBfTJh1_OXyxoEtFHT58H3u9ShfZWLB.NboWVdRBa0KRMAm4wvioPEvxbras3vwaHE21TNwWVhnehjwTKTV_akVmU.bNWOFYZeJJ.iFcH9.f0typ9Al2Q7PoibSj9yacyA0hWjAUxX_QGjuq..0iu8Enx42N9P91g34ZQzFkfGWZtS_fZ2A0PzaXOo2ScxY5KllePh7GOA8wqU1DEN2OUT8o732ddoSGd3Qb6d4u5tRuY6BXGEwFNYk15ebCs8QvCi9HuwJjpvAdUztMrghEVgPEqxYlPErncJoZn_2EvZQ1uOBAEeB7THPINtcvg2h_f95E7zkwh3zWCgETuaxsxves.IPJlCwp0PG5GBelBIDItZiUGam.JnQWFrrz46ioL4xlBokl9APl7iEDptTZs0YPRoJzb.9G9_W.ZAcES8IuqVi_vxBM6hwYXMeGtS1sSf8Aj6aSmZWHTUv1pDIMu6uCxUiwv9NxGseB86AaVm2To5L_XoyK5TB01hFUV9GE360slf.7uGOGJCtE8WlrtiuZwt7iIGvry5A\",mdrd: \"hkXjVUUBk5phUsHfLiEFNQXssq38S71B0aazUg52S8U-1734202926-1.2.1.1-CokI6Jq.RS_QfjL_vPtJWyF6QLM0OSd6XT5ummjQReReftII1zu.5TI_K0fQbCv695Xy8c7dMXBU.hkiViTkBluPoFxjlh0XDuDdqgYho4izxnjVE.ofeHhwOqimBi4IEN0DVp6eCXxYTR0xUvQQ7ccqL1xBmLEnqSVy51DqowOtgzxb84yQJOgtGHYfy7pgu8GJk5mlH7OG2Bt6TdZF80DI_hq077deC7wWwcRRLrk7Mk3P46NGamgHqQsFujRZS2BwV.B2VPI8uG3CKAa86zdXquyUmrezW_TT7.7pCuLv7QPCsOU7cI1tR_1SlUHtv_iLszwi10VxRean_cmh4aLXyTXSFmO5kJQc1wwKYjwJwE9c879M4S2hF1DQfuYuEQlNu1XEm.Q_3FYcWplMt5_pOZvf9..BePDSBkf4HFHWVqVj6R8UT02HTdb7O9Iys9MokQCPC1vlrm9vj0HbfKkMlRaQCFmB6LY8isNCHC5cBCJbtInJZPp1XT2dHb0mU1WWLE8ql9uxRELN7TJvhuJNz6.0WNVywKMQX2HylJb7LJgHXQYQGQTxkLvf2DaJHD1cNMaxCwizskfjzDlRyAvBwRT28nYKaxLtgXZ4ISgBhsO.9OMovNSmCzI3eQw2C2jZWEO.3nGhOIkhWA11k0JoHMxlGBJSFaiStg68RBCG7Ad9RtZKFHLonyRPqqC0kT6XmEjEhD5UNqPgVhOFLRvzgAsWr4VjFhHr9NJ.7ExEkKjBVvc0RntixRZy4JI4oDEoar1GdNayCuwoLi_oRN8umA5SBNN0Qh8RO97C6UFMY7SPRcItnqcVSnWoA_RN3c7VhT80M.hECdPSe0oJtygBnYH6V4E6d9hiCbVfNYvVVpfCwnBiFMguQUw2MG00goMoZjbCL_G7PorunXiquCMuoo7vL8jh9K2GhChVSzVmdU1K3gnNw5lu7T9OV2d9QZamngzEYJvMcKzUh4AbNiVUe0kQFp1MS.a3qg23JZCUywrypMCV8l1_T9DDWh7IY0wQLULn6lKVFdU5sEW1lOaugyeQbAEZW3pkG5Z3_hyienbL6Kd5Uqpx2HTAwieZbfFAALbEqoWVFhyh_pEaUaefLFWB9ZIgknT0aQcDxLfx0jqOgV2lvfaUHp.MbXZ8IOh.NarGEYxc3MNkYd_4Qva05Lmu73f75EHAw_MbZJi2NR6bb38e_W6XOHDD3o6l08MjqvXL3iFMazKkHne6zjYTvmCzsNYeJbXQR0HQOJckjZWMv2QVEfsa45RtPuuoqtST2SgrUYmlv_Hw369_mF4pxwuZetsBfWLxXIXvy3_QO3eTQ04rHDxTe9Qe5Pi69hfDp_Ibr8OLcxJ1911zaUsVgbp5JtiAqmjuHQ7keS.FFUK5_9CqHmjwX065KTWJSUZQ4yXakS9tl7TpgdNjnc.cyR0EHWO8BvLFhjtdnXHSXkYq8m8P07cd1_kDJST.8e_ZqgmV4BWDugxhlKAcnDnMRsP1vZJMI7c84T8NIPVMZs725Zs946GKH2GxAQCqqKpC9RQtzE2iWrTEkj8ZZPkRjRfRVjboau3L1bEIjKjCsQfzNs89cynMsbhwG012SxhOpjxPEMCeo5Vaa3gxZAtrjoylmY42mFeTtulNeSCGP66t0qi6yWxwRQJhGir5tMESytxVKSoIfvluznIFfgy7pdLTAlT7BXcI7MIntsAIu3k2HPkLHqnUiuzwQ23cJaUN8ZNWmxwTPKdV_mYCBhRfCjEQHLvSt4zoLDWWrNpvv_k8ZDh4SdjZ0I1H1BQFAIPunO0N3WLa.2woDaG0KsCM0GkfokeTukmLeGX9yldv_ku6g6L.jqf3wEnmSOAzc5aHCgMPW42d81K3jR7nxbOmAB732Ys_h7NZcxzYTymf5U4_4yiIXdcnm9OPIXRBbosgQiPj.4tFxDJNXLb7FsgWlPpIw6ccNOwyQ02cGzBegJ3hj8pybXNTjDbqEwI021n91lNGza_bew0SCMSilkGLl2n4tUSPIS9UbldIYah46kK4EO.xvWWeUOraGEjCoXhCTixhCKOdT5XGCURTHemRg5rEIpfRJyEZDtXgYGR6liTNdVO0zlyHKoPeOSegDY8mgxgSZD2g5aQ6_v.AVaI5Wq5F1AwVcsZYpH3bacMIszOzOs2ZQGLZy4dXk02dPY1OZwq0BtVAzlaPoqIQwGK2xntnEKy0i1HYyQWVsAEJdEPSuDaXFSKUa_c6h7cEKAQl349Ab_cQD4ndnYmPKnuJwSx44qxa4JEmDWZy6JH518pb.MXdCiJiK.FhqL02h2k_wFXLgF3IvbFKZC6u8v_SKusVfBVlPNgS5bO9bnbbUjBQWlRuJPc.rSDSPUVDu2YqplsvsjiLmIht5PBQrh9wurU.bMhGR3r1lqWj0vI\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=8f2072412b64fa92';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/index\\/elon-musk-wanted-an-openai-for-profit\\/?__cf_chl_rt_tk=BXNsM0hR3xEkpazUXXM2AMinc.u5hM80eyyoxoz5cKo-1734202926-1.0.1.1-LzETXWSm8epoAoR.aUixD13Yv0Tfk67wbVHlZq5YCQk\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());!function(){var e=document.createElement(\"iframe\");function n(){var n=e.contentDocument||e.contentWindow.document;if(n){var t=n.createElement(\"script\");t.nonce=\"\",t.innerHTML=\"window['__CF$cv$params']={r:'792f8224776acf9f',m:'hMcSCCrnIkr7c8Pec6Na6boaaFAnQ6S0ypG2GKRbKgc-1675305063-0-AaJn0SqKZQnadmRQ5O1dM9xMkXWyP+ll7gpl2NHeoNbZTEXMjlB10KkwnEU3hf0/gMODfKqcBGLVecql6U04GGs+iJ/kNrNqj1FgfAOlQV+T2koMQMvUy1zr9tegBBX6BikfccHZhwoJhnXc0eTcg58=',s:[0x60b082f691,0xee65a67e11],u:'/cdn-cgi/challenge-platform/h/b'};var now=Date.now()/1000,offset=14400,ts=''+(Math.floor(now)-Math.floor(now%offset)),_cpo=document.createElement('script');_cpo.nonce='',_cpo.src='/cdn-cgi/challenge-platform/h/b/scripts/alpha/invisible.js?ts='+ts,document.getElementsByTagName('head')[0].appendChild(_cpo);\",n.getElementsByTagName(\"head\")[0].appendChild(t)}}if(e.height=1,e.width=1,e.style.position=\"absolute\",e.style.top=0,e.style.left=0,e.style.border=\"none\",e.style.visibility=\"hidden\",document.body.appendChild(e),\"loading\"!==document.readyState)n();else if(window.addEventListener)document.addEventListener(\"DOMContentLoaded\",n);else{var t=document.onreadystatechange||function(){};document.onreadystatechange=function(e){t(e),\"loading\"!==document.readyState&&(document.onreadystatechange=t,n())}}}();",
    "commentLink": "https://news.ycombinator.com/item?id=42411608",
    "commentBody": "Elon Musk wanted an OpenAI for-profit (openai.com)524 points by arvindh-manian 23 hours agohidepastfavorite574 comments lsy 22 hours agoI guess it's not news but it is pretty wild to see the level of millenarianism espoused by all of these guys. The board of OpenAI is supposedly going to \"determine the fate of the world\", robotics to be \"completely solved\" by 2020, the goal of OpenAI is to \"avoid an AGI dictatorship\". Is nobody in these very rich guys' spheres pushing back on their thought process? So far we are multiple years in with much investment and little return, and no obvious large-scale product-market fit, much less a superintelligence. As a bonus, they lay out the OpenAI business model: > Our fundraising conversations show that: > * Ilya and I are able to convince reputable people that AGI can really happen in the next ≤10 years > * There’s appetite for donations from those people > * There’s very large appetite for investments from those people reply ben_w 21 hours agoparent> Is nobody in these very rich guys' spheres pushing back on their thought process? Yes, frequently and loudly. When Altman was collecting the award at Cambridge the other year, protesters dropped in on the after-award public talk/Q&A session, and he actively empathised with the protestors. > So far we are multiple years in with much investment and little return, and no obvious large-scale product-market fit, much less a superintelligence. I just got back from an Indian restaurant in the middle of Berlin, and the table next to me I overheard a daughter talking to her mother about ChatGPT and KI (Künstliche Intelligenz, the German for AI). The product market fit is fantastic. This isn't the first time I've heard random strangers discussing it in public. What's not obvious is how to monetise it. Old meme parroted around was \"has no moat\", which IMO is like saying Microsoft has no moat for spreadsheets: sure, anyone can make the core tech, and sure we don't know who is Microsoft vs StarOffice vs ClarisWorks vs Google Docs, but there's more than zero moat. From what I've seen, if OpenAI didn't develop new products, they'd be making enough to be profitable, but it's a Red Queen race to remain worth paying for. As for \"much less a superintelligence\": even the current models meet every definition of \"very smart\" I had while growing up, despite their errors. As an adult, I'd still call them book-smart if not abstractly smart. Students or recent graduates, but not wise enough to know their limits and be cautious. For current standards of what intelligence means, we'd better hope we don't get ASI in the next decade or two, because if and when that happens then \"humans need not apply\" — and by extension, foundational assumptions of economics may just stop holding true. reply this_user 21 hours agorootparent> When Altman was collecting the award at Cambridge the other year, protesters dropped in on the after-award public talk/Q&A session, and he actively empathised with the protestors. He always does that to give himself cover, but he has clearly shown that his words mean very little in this regard. He always dodges criticism. He used to talk about the importance of him being accountable to the OpenAI board and them being able to fire him if necessary when people were questioning the dangers of having one person have this much control over something as big as bleeding edge AI. He also used to mention how he had no direct financial interests in the company since he had no equity. Then the board did fire him. What happened next? He came back, the board is gone, he now openly has complete control over OpenAI, and they have given him a potentially huge equity package. I really don't think Sam Altman is particularly trustworthy. He will say whatever he needs to say to get what he wants. reply kulahan 21 hours agorootparentWasn't he fired for questionable reasons? I thought everyone wanted him back, and that's why he was able to return. It was, as I remember, just the board that wanted him out. I imagine if he was doing something truly nefarious, opinions might have been different, but I have no idea what kind of cult of personality he has at that company, so I might be wrong here. reply tasuki 20 hours agorootparent> I thought everyone wanted him back, and that's why he was able to return. Everyone working at OpenAI wanted him back. Which only includes people who have a significant motivation to see OpenAI succeed financially. Also, there are rumours he can be vindictive. For all I know, that might be a smear campaign. But if that were the case, and half the people at OpenAI wanted him back, the other half would have a motivation to follow so as not to get whatever punishment from Sam. reply Aeolun 17 hours agorootparentIt sounds to me people working in AI these days have a lot more options than being fraid of a particularly vindictive man. reply strogonoff 11 hours agorootparentBetween just working on ML tech and working on ML tech with US$XXX billion of Microsoft’s money—salaries aside—imaginably, having access to nuclear plants worth of energy, compute power and cutting edge GPUs, legal department for defending intellectual property violation, etc., makes for a very different value proposition compared to some other startup in the space. (The self-image of working at a company allegedly “advancing humanity” likely helps, too.) reply Aeolun 8 hours agorootparentTrue to some extend. But if you have OpenAI on your resume I have to imagine there’s no necessity for your next job to be much different (e.g. go to any FAANG) reply strogonoff 7 hours agorootparentI think (based on very shallow research) among FAANG behemoths Meta is the closest in terms of resources thrown at ML, but it’s an ad company that hasn’t got such a “we advance humanity” image. Equity vesting and that sort of stuff can additionally make moving companies a problematic prospect, even if the new place offered a competitive salary… reply psb217 1 hour agorootparentYeah, Meta pays well, but they probably wouldn't match the $10M equity pile that some generic engineer or researcher who joined 1 year before ChatGPT dropped could be sitting on. Ofc, the equity->cash conversion rate for OpenAI pseudo stocks isn't clear, but those paper gains would be tough to abandon. reply this_user 17 hours agorootparentprev> Wasn't he fired for questionable reasons? There were a number of concerns, including for-profit projects he was pursuing despite his public insistence on OpenAI being non-profit as well as generally deceptive behaviour on his part. The last part at least is consistent with what others have said about Altman previously, including what allegedly led to his exit from YC, although they have kept those stories pretty quiet. But it seems like PG himself no longer has a lot of trust in Altman after he basically made him his heir apparent, and he has known him for a while now. What's more, the driving force behind the board's move to remove him from OpenAI was reportedly Ilya Sutskever who was one of their key people and one of the handful of original founders. So it wasn't just a bunch of external people who wanted Altman gone, but at least one high level insider who has been around for the entire thing. Altman himself was even once asked by journalists whether we could trust him to which he outright answered \"no\". But then he pointed to the fact that the board could remove him for any reason. Clearly, he was suggesting that there were strong safe guards in place to keep him in check, but it is now apparent that those safe guards never really existed while his answer still stands. reply harrall 17 hours agorootparentDon’t pay much particular attention to AI but I’m not seeing the knock on him saying “no.” What human in the world could be trusted with AI? Only delusional people could say yes to that question. reply ben_w 6 hours agorootparent> What human in the world could be trusted with AI? Only delusional people could say yes to that question. \"AI\" is too broad a topic to draw that conclusion. Almost everyone can be trusted with Stockfish. Almost: https://github.com/RonSijm/ButtFish Most of us can be trusted with current LLMs, despite the nefarious purposes that they can be put to by a minority. Spam and fraud are still minority actors, even though these tools increase the capabilities of those actors; and they're still \"only\" at the student/recent graduate level for many tasks, so using them for hazardous chemical synthesis will likely literally explode in the face of the person attempting it. Face recognition AI (and robot control attached to it) is already more than capable enough to violate the 1980 Protocol on Blinding Laser Weapons, and we're just lucky random lone-wolf malicious actors have not yet tried to exploit this: https://en.wikipedia.org/wiki/Protocol_on_Blinding_Laser_Wea... We don't yet, it seems, have an AI capable enough that a random person wishing for world peace will get a world with the peace of the grave, nor will someone asking for \"as many paperclips as possible\" accidentally von-Neumann the universe into nanoscale paperclip-shaped molecules — indeed, I would argue that if natural language understanding continues in the current path, we won't ever get that kind of \"it did what I said but not what I meant\" scenario; what I currently think most likely is as an analogy for the industrial revolution, where we knew CO2 was a greenhouse gas around the turn of the 1900s, and still have not yet stopped emitting it because most people prefer the immediate results of things that emit it over the distant benefits of not emitting it. But even that kind of AI doesn't seem to be here just yet. It may turn out that GenAI videos, images, text, and voice is in fact as much of a risk as CO2, that it collapses any possibility of large-scale cooperation, but for the moment that's not clear. reply 123yawaworht456 15 hours agorootparentpreva smartphone can be used to guide an ICBM. what human in the would could be trusted with it? reply johnisgood 7 hours agorootparentA road can be used for abductions, acts of violence, and other harmful activities. What human in the world could be trusted with it [roads]? reply MaxfordAndSons 12 hours agorootparentprevMost humans are frequently harming themselves (and sometimes harming others) with their smartphones, so... reply Arkhaine_kupo 20 hours agorootparentprev> I thought everyone wanted him back, Ilyia Sutskever who was the chief Scientist of the company and honestly irreplacable in terms of AI knowledge left after Altman returned. reply drawnwren 18 hours agorootparentOnly 1 of the 6 board members are still at OAI. reply thrw42A8N 9 hours agorootparentprevHe also apologized and said he was wrong. reply sillyfluke 3 hours agorootparentThat was only after it was apparent that a majority of employees would back Altman's return I believe. A majority of which who had spent less time with him than Ilya had in all likelihood. reply samvher 21 hours agorootparentprevDefine everyone. I was delighted when they fired him. I don't believe he has humanity's best interest at heart. reply ben_w 20 hours agorootparent745 of 770 employees responded on a weekend to call for his return, threatened mass resignations if the board did not resign; among the signatories was board member Sutskever, who defected from the board and publicly apologized for his participation in the board's previous actions. reply LeafItAlone 20 hours agorootparent>745 of 700 employees responded on a weekend to call for his return, threatened mass resignations if the board did not resign I would think final count doesn’t really matter. Self serving cowards, like me, would sign it once they see the way the wind was blowing. How many signed it before Satya at Microsoft indicated support for Altman? reply samvher 20 hours agorootparentprevI followed the drama. The point I was (somewhat unsuccessfully) trying to make was that while, sure, there were groups who wanted him back (mainly the groups with vested financial interests and associated leverage), my sense was that the way it played out was not necessarily in line with wider humanity's best interest, i.e. as would have been hoped based on OpenAI's publicly stated goals. reply ben_w 19 hours agorootparentOh, in that case sure. The statements in the whole popcorn drama still don't add up in my mind, so from the point of view of \"humanity's best interest\", I'd say it's still bad. I thought you meant at the time, not with the benefit of hindsight. reply johnnyanmac 16 hours agorootparentprev>my sense was that the way it played out was not necessarily in line with wider humanity's best interest, Sure. But you make the foolish assumption here that humanity even has humanity's best interests at heart. Sentiment may be negative on current LLM generative based AI, but there's still plenty of people with either potential vested interests or simply seeing missing the forest for the tree. It's pretty hard to say \"everyone hates/loves AI\" at this current time. reply talldayo 19 hours agorootparentprevI'd do that too if I held stock, and I think the guy is a borderline-vampire. reply fwip 20 hours agorootparentprev745 of 700? reply ben_w 19 hours agorootparentWhoops, typo for 770, edited to correct. Thanks! reply KerryJones 20 hours agorootparentprev* 747/770 https://www.nasdaq.com/articles/747-of-770-openai-employees-... reply Terr_ 17 hours agorootparentprevAt the time, was it possible for people working at OpenAI to, er, \"cash out\"? I don't actually know the answer to that, but I'm suggesting that perhaps people had additional motives for the organization to preserve its current hype/investment growth strategies. reply yard2010 21 hours agorootparentprevThis guy is outright scary. He gives me the chills. reply bayarearefugee 15 hours agorootparentthe whole group of these techbro billionaires come off as barely human ghouls when you hear them speak, imo see also: peter thiel on piers morgan recently. reply Yeul 15 hours agorootparentThey probably know that nobody would vote for them which is why they fund Trump and other politicians who do have social skills. reply Waterluvian 33 minutes agorootparentprevIndeed. Words are very very inexpensive and fool a lot of people. Never pay attention to any words. Judge people by their actions. reply manquer 21 hours agorootparentprev> The product market fit is fantastic. This isn't the first time I've heard random strangers discussing it in public. Hardly the evidence of PMF. There is always something new in the zeitgeist, that every one is talking about, some more so than others . 2 years before it was VR, few years before that NFTs and blockchain everything, before that it was self driving cars before that personal voice assistants like Siri and so on . - self driving has not transformed us into minority report and despite how far it has come it cannot in next 30 years be ubiquitous, even if the l5 magic tech exists today in every new car sold it will take 15 years for current cars to lifecycle. - Crypto has not replaced fiat currency , even in most generous reading you can see it as store of value like gold or whatever useless baubles people assign arbitrary value to, but has no traction for 3 out of other 4 key functions of money . - VR is not transformative to every day life and is 5 fundamental breakthroughs away. - Voice assistants are useless setting alarms and selecting music 10 years in. There has been meaningful and measurable in each of these fields, but none of them have met the high bar of world transforming . AI is aiming for much higher bar of singularity and consciousness. Just in every hype cycles we are in peak of inflated expectations, we will reach a plateau of productivity where it is will be useful in specific areas (as it already is) and people will move on to the next fad. reply ben_w 20 hours agorootparent> 2 years before it was VR, few years before that NFTs and blockchain everything, before that it was self driving cars before that personal voice assistants like Siri and so on . I never saw people talking about VR in public, nor NFTs, and the closest I got to seeing blockchain in public were adverts, not hearing random people around me chatting about it. The only people I ever saw in real life talking about self-driving cars were the ones I was talking to myself, and everyone else was dismissive of them. Voice assistants were mainly mocked from day 1, with the Alex advert being re-dubbed as a dystopian nightmare. > AI is aiming for much higher bar of singularity and consciousness. No, it's aiming to be economically useful. \"The singularity\" is what a lot of people think is an automatic consequence of being able to solve tasks related to AI; me, I think that's how we sustained Moore's Law so long (computers designing computers, you can't place a billion transistors by hand, but even if you could the scale is now well into the zone where quantum tunnelling has to be accounted for in the design), and that \"singularities\" are a sign something is wrong with the model. \"Consciousness\" has 40 definitions, and is therefore not even a meaningful target. > Just in every hype cycles we are in peak of inflated expectations, we will reach a plateau of productivity where it is will be useful in specific areas (as it already is) and people will move on to the next fad. In that at least, we agree. reply swatcoder 20 hours agorootparent> never saw people talking about VR in public, nor NFTs, and the closest I got to seeing blockchain in public were adverts, not hearing random people around me chatting about it. The only people I ever saw in real life talking about self-driving cars were the ones I was talking to myself, and everyone else was dismissive of them. Voice assistants were mainly mocked from day 1, with the Alex advert being re-dubbed as a dystopian nightmare. Isn't that funny? It speaks exactly to the GP's point about how frothing and uninformative the \"zeitgeist\" can be, as my experience happens to have been the opposite of yours. The people I happened to be casually brushing around during those earlier fads happened to be hip to them, or maybe my ears were more attentive, and so I heard them mentioned more often and with more enthusiasm. In contrast, most of what I happen to hear about generative AI, outside of HN, tends to be idly laughing at its foibles and misrepresentation if it's mentioned at all. I don't expect you to have the same experience as me, but I'm careful not to assume too much based on either of ours. reply og_kalu 18 hours agorootparentI mean nobody needs to bother with anecdotes here. chatgpt.com hit 3.7B visits in October and was #8 in worldwide internet traffic. Open AI say they have 300M weekly active users and 1B messages per day. The idea that it's some fad with no utility or that the general public knows little about it is at this point laughable. It's the software product with by far the fastest adoption any software product has ever seen. And if people want to lump that in with bitcoin or VR or whatever, shrug, i just don't know what to say. reply darkwater 10 hours agorootparentYes, because it is free. How many paid users? Is a paid user generating profit right now? Google had to inject advertising in its search results to start earning real money. What will OpenAI do? That's the PMF. reply chgs 9 hours agorootparent90% of my use of OpenAI is to avoid the crap of internet search (Google or ddg, even when I find the right page finding the specific part of a pain) At some point chatgpt will become crap and the cycle will repeat reply chipsrafferty 10 hours agorootparentprevThat actual isn't evidence at all that the general public knows a lot about it, or even uses it much. It can be a small group of very active users. reply parineum 13 hours agorootparentprev> I mean nobody needs to bother with anecdotes here. chatgpt.com hit 3.7B visits in October and was #8 in worldwide internet traffic. Open AI say they have 300M weekly active users and 1B messages per day. As far as the \"zeitgeist\" conversation goes, though, there's one story in the non-tech news about AI right now and it isn't how it's making everyone's life easier. It's, yet again, a story about how someone trusted it and got burned because the markov chain landed on something not true. reply behnamoh 19 hours agorootparentprev> ... and that \"singularities\" are a sign something is wrong with the model. Einstein thought that way too because his model predicted singularities in space-time fabric. Turns out he was wrong. Nowadays we call them blackholes and have images of them too. reply zeroonetwothree 19 hours agorootparentHe wasn’t exactly wrong in that the model still breaks down for black holes. Even though we know they exist we don’t know what goes inside them. reply ben_w 18 hours agorootparentprevBlack holes have had two different singularities in general relativity: (1) the event horizon was the first singularity, but that turned out to be a free choice of the coordinate system, i.e. a mistake in the maths — and we can't see past the event horizons anyway, so we don't know what happens on the other side of them even though they're not \"real\" singularities (2) the point in the centre where the geodesics stop, which everyone in the field knows is incompatible with (a) the assumption in the maths of relativity that spacetime is smooth and can be differentiated everywhere, and (b) quantum mechanics reply mnky9800n 10 hours agorootparentprevThe image is not of the singularity itself but the accretion disc. This is not to discount that amazing accomplishment but to point out that, in addition to misrepresenting what the singularity is in a black hole, you also misrepresented what the image of a black hole is. reply DennisP 18 hours agorootparentprevSelf-driving won't take over by just being available in the new cars people are buying anyway. It'll take over when people find it cheaper to ride robotaxis than to own a vehicle at all. That's potentially a much quicker transition, requiring significantly fewer new vehicles. reply mnky9800n 10 hours agorootparentNobody is going to sit and wait for a robo uber in the suburbs for ten minutes to go to the grocery store ten miles down the road. This is the main problem, America has suburbanised itself to hell and no amount of robo taxis will create the world you are suggesting. And elsewhere in the world there’s no need because most places have adequate public transit which solves the problem way more efficiently than robo taxis ever will. reply inertiatic 8 hours agorootparentPeople wait for things all the time and if it can take away the hassle or driving your kids somewhere, maintaining multiple vehicles for multiple family members etc. I'd bet that it does take off. Public transport doesn't solve groceries or other types of shopping though even in highly connected cities, especially for people with health problems or just aging ones. reply DennisP 4 hours agorootparentprevSo people are not willing to wait for a robotaxi, but they are willing to wait for buses and trains? reply cinntaile 9 hours agorootparentprevPublic transport doesn't compare to robotaxis. If robotaxis become a reality I expect a significant drop in car ownership and public transport use. The price will be competitive with the price of public transport, at least for single fare prices. reply mnky9800n 9 hours agorootparentI can catch a bus every five minutes a one minute walk from my house in Utrecht. Those buses go anywhere. In Oslo I could ride the T-bane to the forest or to downtown. In Tokyo it was obvious public transit is the only way to go. All the places I lived outside the USA I would never take a taxi much less a robot one in lieu of Public transit. reply cinntaile 9 hours agorootparentBecause taxis are not cheap enough. Once they become cheap enough, by not having a driver, the equation changes. Travel becomes more convenient. reply chgs 9 hours agorootparentIn a city I don’t take public transport over uber due to the cost but due to the convenience and speed. The only exception is the US, and even then that doesn’t apply in Manhattan. reply cinntaile 8 hours agorootparentThat's what I'm saying. When price goes down, robotaxis become a more viable option due to convenience and speed. You're shopping? Just put it in the trunk. Have fun with 4 grocery bags on public transport. Public transport can be faster for going from A to B, but most people live a couple of kms from A and they're not going to exactly B but somewhere in the vicinity. The \"last mile\" will more likely be by robotaxi. reply ben_w 6 hours agorootparent> When price goes down, robotaxis become a more viable option due to convenience and speed. Lower prices don't make things more convenient or fast. > You're shopping? Just put it in the trunk. Have fun with 4 grocery bags on public transport. Here is \"The Shops at South Town\" mall in Salt Lake City: https://www.google.com/maps/@40.5617162,-111.8944801,171m/da... Note that some parts of that car park are 300m from some of the shops in that building. (There are choices of shops and parking spaces larger than that, but it looks like I can easily justify 300m without resorting to maxima). Here is my old apartment: https://www.google.com/maps/place/Prenzlauer+Promenade+1,+13... Note that within 300m of that address — i.e. the bounds of the example American shopping mall car park — there are 6 [super]markets, a pharmacy, at least five cafe/bakeries, two cinemas, several takeaways, at least two restaurants, a dentist, a car repair shop, a car dealership, a pet-goods shop, a kitchenware shop, a newsagent/post office, two sets of tram stops, four sets of bus stops, and I'm not counting any corner shops (\"Späti\" in the local language). Carrying a few bags of groceries around inside well-planned cities is pretty trivial. Anything connected to that area by a single mode of transport is no harder to take shopping through than the transit systems within a mall — escalator, elevator, travelator — and that means one of the main commercial areas of the city (Alexanderplatz) and the road to it (which itself is basically a 3km long half-density strip mall with a tram the whole length and a railway crossing it in the middle and another at the south end) are both trivial to reach even with shopping — I've even seen someone taking an actual, literal, kitchen sink on one of Berlin's trams. Even in my current place, still in Berlin but close to the outskirts without the advantages of density, a mere four grocery bags is easier to get through public transport than it is from one end of an American car park to the other. reply cinntaile 4 hours agorootparent> Lower prices don't make things more convenient or fast. You are replying to a straw man, I never said anything like that. It makes for dull discussions. > Even in my current place, still in Berlin but close to the outskirts without the advantages of density, a mere four grocery bags is easier to get through public transport than it is from one end of an American car park to the other. It's unclear to me why you compare it to a geographically unrelated area. You should compare the public transport with a robotaxi alternative. At similar pricing, how is convenience and speed impacted. reply ben_w 3 hours agorootparent>> Lower prices don't make things more convenient or fast. > You are replying to a straw man, I never said anything like that. It makes for dull discussions. If you didn't mean that, why did you say \"When price goes down, robotaxis become a more viable option due to convenience and speed\"? > You should compare the public transport with a robotaxi alternative. The alternative being \"do I put these four bags in a trunk, or on the seat next to me?\" reply ickelbawd 3 hours agorootparentNot the op. If you reread what he wrote I think he’s trying to say the price going down changes the viability of the option—not the convenience and speed which he treats as inherent to the car. Said another way: When price goes down, robotaxis (which are convenient and speedy) become a more viable option. reply ben_w 1 hour agorootparentThanks, that reading looks plausible :) reply thrw42A8N 8 hours agorootparentprevThat's because people are behind the wheel. Once car ownership drops, the computerized traffic control can get much more efficient. reply chgs 51 minutes agorootparentComputerised public transport is even more efficient Your public transport with robo taxis takes up far more space in the surface than there is available in a normal city, as shown in this photo. https://danielbowen.com/2012/09/19/road-space-photo/ reply thrw42A8N 8 hours agorootparentprevWhy would you wait for 10 minutes? Robo taxis would be driving all around to be optimally available to the market. reply ben_w 4 hours agorootparentThe optimal route means picking up multiple people on the same route, and dropping them off elsewhere on the route, and then making the vehicle large enough so that they can do this comfortably, i.e. a bus. It ends up being another form of public transport — perhaps one with no predictable timetable, or perhaps timetables are themselves a useful Schelling point, I wouldn't want to guess. But as fixed bus routes make it possible to plan things like bus shelters, I think I'd prefer a bus over the logical progression of self-driving \"taxis\" that constantly move rather than finding parking spots. reply DennisP 3 hours agorootparentThat's optimal for the vehicles, but less optimal for the people, who have to walk to stops. I used to live in Germany which had fantastic public transport, but walking a mile to the nearest stop was something we took in stride. That's great for health, but didn't prevent Germans from being quite fond of their personal automobiles, and there didn't seem to be noticeably less traffic than in the US. Meanwhile I think plenty of people find Uber perfectly convenient, just a bit expensive. As far as physical efficiency goes, Tesla's plan is more efficient than their competitors'. Their dedicated robotaxis are either small two-seaters, or decent-size buses. reply manquer 18 hours agorootparentprevAssuming we get to your level of value prop. It will still only be a choice for new first time buyers If I already own a car, for which am paying an emi and no hope of selling for good value (because market is dropping as newest buyers disappear) it won’t make economic sense for me till I generate LTV from the car to switch over . Either way it till take 1-2 decades after ubiquitous L5 availability, even if that was possible at all and soon reply bdangubic 17 hours agorootparentprevthere are already cheaper ways to ride from point A to point B without owning a car (especially in urban areas) and yet car ownership has never been higher… ideal robotaxis will take at least one full generation to actually materialize. just as a silly personal example, I took a car to the shop and got Uber credits. my wife was heading into the city for an event (had to deal with both traffic and parking) and I was like “take a free Uber” and she was like “no way, driving my own car…” my daughter on the other hand… reply mlyle 17 hours agorootparentprev> despite how far it has come it cannot in next 30 years be ubiquitous, even if the l5 magic tech exists today in every new car sold it will take 15 years for current cars to lifecycle. We must have a different meaning of ubiquitous. Ubiquitous means \"found everywhere\" not \"has eliminated everything else.\" You don't even need to cycle the fleet once to meet the definition of ubiquitous. If you can get a self driving car in any city and many towns, you see them all over the place, and a third of trips are done with them, that'd be ubiquitous in my book. I don't see why you couldn't get there in 3 decades. I don't think it's likely in 12 years but it seems possible in that timeframe. reply manquer 13 hours agorootparentI considered fleet change as the transformation that eliminates driving as a needed skill . Getting a slightly better version of Waymo in SF is just augmenting for a poor public transit with a very American car solution . It scales pretty poorly and cannot replace good public transit, at best can augment them as last mile connectivity . There is value to those of course and is disruptive to a sector, it is still a specific use case and not world changing. You are only disrupting the taxi industry not driving itself . The claims at the time was not we are going replace taxis with robotaxis , but driving itself will be a thing of the past. That is the nature of hype cycles . reply tim333 20 hours agorootparentprev>people will move on to the next fad AI isn't really a fad. It's going to something more like electricity, say. reply swatcoder 19 hours agorootparentMy favorite comparison right now is to the microwave oven. It's a novel thing. It's not going anywhere. It makes some things easier, sometimes, in both personal and professional settings. But you're not at a big loss without it and in many cases your choice to do without is a choice that favors quality, control, nuance, and skill refinement. reply tim333 19 hours agorootparentAI probably has more capacity to be incorporated into many things than microwaves. reply manquer 19 hours agorootparentI will bite, going with your analogy comparing to electricity on the other end of the spectrum. electricity is not ubiquitous in many parts of the global south full 130 years. The common definition is- access to electricity source that can provide very basic lighting, and charge a phone or power a radio for 4 hours per day. Not even grid connected. Even with this basic definition there is still full 660 million people who don’t have access to even that. It only dropped below a billion in 2015. https://ourworldindata.org/energy-access You need beyond the basic to be meaningfully transformative, clean cooking fuel access is one proxy used that is still 2Billion people without access for example. Nobody is denying the transformative nature of electricity or say internet , but even these things take a long long time, more than one life time to propagate and be world changing, and not because of their choice of lifestyle to live disconnected. If electricity, clean water, sanitation and nutrition and basic healthcare is not available to half the population, what is AI going to do in next 3- 5 years or whatever ridiculous timeframe Sam Altman keeps talking about . And this is a not productivity problem, there is more than enough food production capacity to feed the world, yet starvation and malnutrition is not solved. AI may rock your world, it is not going to rock the world anytime soon even if was like electricity. reply bruce511 12 hours agorootparentSomething can be transformative long (long) before its \"completely available to everyone \". Clearly electricity is transformative despite 660 million people not giving it. So I guess it all depends on your definition of \"transformative\". If a billion people are affected? 2 billion? One continent? All of them? If something is big in Australia, Asia, Europe and North America, is that enough to describe it is \"rock the world\"? reply parineum 13 hours agorootparentprevPeople have been saying that for a few years now. I've been using it as a very advanced autocomplete while coding for that time and not much else. reply tim333 3 hours agorootparentElectricity probably had niche uses for the first few years but as electrical stuff got better it got used in all sorts of things. I imagine AI will go a bit like that if quicker. Looking back at the history of electricity, there is early stuff from the Greeks and then: Faraday's homopolar disc generator 1831 Light bulb 1870 Transistor 1947 etc. So quite leisurely. reply ben_w 8 hours agorootparentprevI use it for cooking, proofreading, learning German, skimming long documents, shopping advice (by uploading photos), and asking dumb questions about physics that get me [closed] if I were to post on physics stack exchange, in addition to being a coding assistant. reply Sateeshm 11 minutes agorootparentMost of those existed before llms. Also still like a microwave, not very essential. reply result2vino 19 hours agorootparentprev> 2 years before it was VR, few years before that NFTs and blockchain everything Are you so deep in the SV tech echo chamber that you can’t distinguish between tech bro / snake oil salesman hype and something that actual normal people are engaged by? The only people talking about NFTs in a non-disparaging way were delusional in large part because they themselves bought into it wanted to egg others on. NFTs were just a stupid faddish speculative ‘commodity’ market. It’s a completely different thing. Ditto with “blockchain”. That well was positioned by people trying to make money from cryptocurrencies. The mechanics allowed for that. Again, it’s a completely different thing. Civilians with no vested interest weren’t sitting in restaurants singing the praises of decentralised ledgers or monkey pictures on someone’s Google Drive. I assure you. I also assure you that this IS however happening with ChatGPT. Out here in the real world, we see it. This doesn’t mean that there aren’t issues with LLMs, both philosophically and in therms of their actual output. This doesn’t mean there aren’t the same old SV snake oil salespeople and YouTube wannabes trying to push some BS products and courses. But let’s not pretend for a second like this is usefully comparable to “blockchain” and “NFTs”. reply lodovic 11 hours agorootparentI think that underestimates public engagements in these hypes. Billions were wasted by \"normal\" people worldwide on VR headsets, in-game nfts, and shitcoins. Real world money, not some inflated VC capital projections. And while the current LLMs still are an \"advanced Eliza\", regular people are quite happy to pay for its services. reply manquer 13 hours agorootparentprevI am sorry, every A-List celebrity was shilling a NFT project, from superbowl to other public spheres of discourse seemed all crypto. The future president of the country has a crypto project to sell, I don’t see how much mainstream it can get. Yes, There is close connection to SV hype cycle and what happens in mainstream, most mainstream ones originate in SV but the ones I mentioned specifically impacted the larger public not just SV tech sphere reply lupire 16 hours agorootparentprevBlockchain and NFT took over the Super Bowl. That's pretty mainstream. There are Bitcoin ATMs. reply bee_rider 20 hours agorootparentprevConsciousness is a stupid and unreasonable goal, it is basically impossible to confirm that a machine isn’t just faking it really well. Singularity is at least definable…Although I think it is not really the bar required to be really impactful. If we get an AI system that can do the work of like 60% of hardcore knowledge workers, 80% of office workers, and 95% of CEOs/politicians and other pablumists, it could be really change how the economy works without actually being a singularity. reply lupire 16 hours agorootparentThose numbers are approximately zero, because demand will immediately 10x as soon as AI makes that affordable, as computers have always done. So, profitable (if the AI can cost less than a human for the work), but not changing how the economy works reply tsimionescu 13 hours agorootparentIf white collar jobs get automated away to the extent that blue collar jobs were in the industrial revolution, that will be, by definition, a massive upheaval of the economy. reply eastbound 20 hours agorootparentprevCommon, VR, NFTs and blockchain were always abysses of void looking for a usecase. Driving cars maybe, but development has been stalling for 15 years. reply manquer 19 hours agorootparentNot to their proponents particularly at the time. For the rest of us in HN it was easier to judge on much mileage will get, but a long time in each cycle we were in the minority, just like the AI skeptics including me and many here are today on how much we will value get. Don’t get are wrong, AI is more real and more useful than the things before it, but everything is on a spectrum of success - some more and some less, but none of it has been or will be world changing or truly global. The true breakthroughs rarely get public or even tech community attention until late in the cycle although their progress is public and can be tracked, like with EUV or mRNA or GLP-1 etc . Others which are incremental changes like 5G or cheaper smartphones do not get as much attention as their impact should warrant especially compared to the fads Hype cycles don’t correlate well with real tech cycles reply ben_w 19 hours agorootparentprevI'd say VR is just another form factor for games rather than being a void looking for a use-case, but I agree about NFTs and cryptocurrency*. * technically not all blockchains because git and BitTorrent are both also hash trees and therefore non-currency block-chains, but definitely the cryptocurrency uses of them. reply manquer 18 hours agorootparentThe point is not that they are snakeoil and have zero value . Every one of these things have some value in some area of applications. However the hype cycle just as now in AI claimed it will change everything, not hey here is interesting new thing and it is going be used in select applications . Nobody is investing billions and billions on that pitch reply sneak 18 hours agorootparentprevDid you really just compare the thing that makes me able to code and ship 5x faster to... NFTs? reply Terr_ 17 hours agorootparent> code and ship I notice that doesn't say what happened to the throughput of \"diagnose, fix, and reduce technical debt.\" :p reply manquer 18 hours agorootparentprevMatter of perspective, Ai tools value depends on your existing skill level and whether it only doing what you already can do and you can correct it very well. However that kind of user in my experience is rare , vast majority are junior developers who do not understand the output well enough and now generate 5x of it that I have to review and they no longer make the effort to understand any foundational concept . This is not new, the rise in popularity of StackOverflow created a class of developers who didn’t want to spend the time to learn properly reading the manual. In itself reducing the skill level needed to be productive is not inherently bad, it was PhD in CS could only program in 70s and 80s. Each generation of tech and abstraction opened up software development to newer class of employees. However the difference is the industry desperately needed expansion each time because PCs became popular or the desktop or mobile devices etc . There was enormous demand for new applications both personal and professional which couldn’t be satisfied with kind of volume CS research programs could fulfill. There is no such transformation currently , there aren’t a new class of users or major applications coming up in a such high volume, that quality drop is compensated by quantity . There is lot more need for higher quality products as software market is plateauing from the highs mobile adoption gave. reply johnnyanmac 16 hours agorootparentprevreally depends on the kind of AI. If I said I shipped a AI-genned game 5x faster , then people would indeed compare it to NFTs. reply jkaptur 21 hours agorootparentprevCan you expand on your spreadsheet analogy? I think Joel Spolsky explained the main Office moat well here: https://www.joelonsoftware.com/2008/02/19/why-are-the-micros... > ... it might take you weeks to change your page layout algorithm to accommodate it. If you don’t, customers will open their Word files in your clone and all the pages will be messed up. Basically, people who use Office have extremely specific expectations. (I've seen people try a single keyboard shortcut, see that it doesn't work in a web-based application, and declare that whole thing \"doesn't work\".) Reimplementing all that stuff is really time consuming. There's also a strong network effect - if your company uses Office, you'll probably use it too. On the other hand, people don't have extremely specific expectations for LLMs because 1) they're fairly new and 2) they're almost always nondeterministic anyway. They don't care so much about using the same one as everyone they know or work with, because there's no network aspect of the product. I don't think the moats are similar. reply pj_mukh 21 hours agorootparent\"Basically, people who use Office have extremely specific expectations.\" Interesting point, but to OP's point- This wasn't true when Office was first introduced and Office still created a domineering market share. In fact, I'd argue these moat-by-idiosyncracy features are a result of that market share. There is nothing stopping OpenAI from developing their own over time. reply bee_rider 20 hours agorootparentDoes office actually have a moat? I thought the kids liked Google docs nowadays. (No opinion as to which is actually better, the actual thing people should do is write LaTeX in vim. You can even share documents! Just have everybody attach to the same tmux session and take turns). reply ben_w 19 hours agorootparentIf you're writing a spreadsheet in LaTeX, I suspect something has gone very wrong somewhere along the line. Spreadsheets are as much a calculation environment as they are a table of figures, and if you're technical enough to be writing docs in LaTeX you should be doing the calculations in a more rigorous environment where you don't copy the formulas between cells. reply wbl 18 hours agorootparentExcel, the world's most popular functional programming language. reply ethbr1 17 hours agorootparentExcel, the only IDE universally allowed on corporate devices reply antihipocrat 16 hours agorootparentI'd argue the web browser falls into that category as well. reply ethbr1 3 hours agorootparentIn more modern times, although I'd say the barrier of entry is higher there. Plus most analogs would require additional procurement, to which the response for most business users would be \"No, you're not a developer.\" reply swatcoder 19 hours agorootparentprev> This wasn't true when Office was first introduced and Office still created a domineering market share It was absolutely true at that time, but Microsoft was already a behemoth monopoly with deep customer connections throughout enterprise and was uniquely positioned to overcome the moats of their otherwise fairly secure competitors, whose users were just as loyal then as the GP is describing about users now. Even if OpenAI could establish some kind of moat, office applications make for very poor analogy as to how they might or whether they need to. reply jkaptur 20 hours agorootparentprevSure, there's nothing stopping any business from developing a moat. The Excel example doesn't make the case of OpenAI any clearer to me. reply ben_w 19 hours agorootparentprev> Can you expand on your spreadsheet analogy? Sure. (I've been coding long enough that what Joel writes about there just seems obvious to me: of course it happened like that, how else would it have?) So, a spreadsheet in the general sense — not necessarily compatible with Microsoft's, but one that works — is quite simple to code. Precisely because it's easy, that's not something you can sell directly, because anyone else can compete easily. And yet, Microsoft Office exists, and the Office suite is basically a cost of doing businesses. Microsoft got to be market-dominant enough to build all that complexity that became a moat, that made it hard to build a clone. Not the core tech of a spreadsheet, but everything else surrounding that core tech. OpenAI has a little bit of that, but not much. It's only a little because while their API is cool, it's so easy to work with that you can (I have) asked the original 3.5 chat model to write its own web UI. As it happens, mine is already out of date, because the real one can better handle markdown etc., so the same sorts of principles apply, even on a smaller scale like this where it's more of \"keeping up in real time\" rather than \"349 page PDF file just to get started\". OpenAI is iterating very effectively and very quickly with all the stuff around the LLM itself, the app, the ecosystem. But so is Anthropic, so is Apple, so is everyone — the buzz across the business world is \"how are you going to integrate AI into your business?\", which I suspect will go about the same as when it was \"integrate the information superhighway\" or \"integrate apps\", and what we have now in the business world is to the future of LLMs as Geocities was to the web: a glorious chaotic mess, upon which people cut their teeth in order to create the real value a decade later. In the meantime, OpenAI is one of several companies that has a good chance of building up enough complexity over time to become an incumbent by a combination of inertia and years of cruft. But also only a good chance. They may yet fail. > On the other hand, people don't have extremely specific expectations for LLMs because 1) they're fairly new and 2) they're almost always nondeterministic anyway. They don't care so much about using the same one as everyone they know or work with, because there's no network aspect of the product. For #1, I agree. That's why I don't want to bet if OpenAI is going to be to LLMs what Microsoft is to spreadsheets, or if they'll be as much a footnote to the future history of LLMs as Star Division was to spreadsheets. For #2, network effects… I'm not sure I agree with you, but this is just anecdotal, so YMMV: in my experience, OpenAI has the public eye, much more so than the others. It's ChatGPT, not Claude, certainly not grok, that people talk about. I've installed and used Phi-3 locally, but it's not a name I hear in public. Even in business settings, it's ChatGPT first, with GitHub Copilot and Claude limited to \"and also\", and the other LLMs don't even get named. reply shitloadofbooks 17 hours agorootparentprevIn my opinion the difference is that a recent graduate knows to say “I don’t know” to questions they’re not sure on, whereas LLMs will extremely confidently and convincingly lie to your face and tell you dangerous nonsense. reply ben_w 7 hours agorootparentMy experience is that intellectual humility is a variable, not a universal. Seen some students very willing to recognise their weaknesses, others who are hamstrung by their hubris. (And not just students, the worst code I've seen in my career generally came from those most certain they're right). https://phys.org/news/2023-12-teens-dont-acknowledge-fact-ea... And yes, this is a problem with some LLMs that are trained to always have an answer rather than to acknowledge their uncertainty. reply sangnoir 20 hours agorootparentprev> ...like saying Microsoft has no moat for spreadsheets Which would be very inaccurate as network-effects are Excel's (and Word's) moat. Excel being bundled with Office and Windows helped, but it beat Lotus-123 by being a superior product at a time the computing landscape was changing. OpenAI has no such advantage yet: a text-based API is about as commoditized as a technology can get and OpenAI is furiously launching interfaces with lower interoperability (where one can't replace GPT-4o with Claude 3.5 via a drop-down) reply sumedh 18 hours agorootparent> OpenAI has no such advantage yet: a text-based API is about as commoditized as a technology It has branding, for most people AI is ChatGpt. Once you reach critical mass, getting people to switch becomes difficult if your product is good enough and most people are happy. reply tsimionescu 12 hours agorootparentBranding is a very weak moat outside fashion industry and similar places - outside visible status symbols. It's a relatively strong moat for clothes, watches, even things like the iPhone. But for things you do alone at home, this quickly goes away. Uber is a strong brand, everyone associated non-taxi taxis with Uber. When Bolt came around in much of Europe, and offered the same service with better wait times (they were paying drivers more, so lots of drivers switched), people moved over to Bolt in droves. reply 015a 18 hours agorootparentprev> he actively empathised with the protestors. I have significant doubt that Sam is capable of empathy, period. It seems like what he's capable of is an extremely convincing caricature of it which he has practiced for many years. reply disgruntledphd2 10 hours agorootparentI mean, one could say the same about basically every human (and indeed, some AI systems). reply naming_the_user 21 hours agorootparentprev> For current standards of what intelligence means, we'd better hope we don't get ASI in the next decade or two, because if and when that happens then \"humans need not apply\" — and by extension, foundational assumptions of economics may just stop holding true. I'm not sure that we need superintelligence for that to be the case - it may depend on whether you include physical ability in the definition of intelligence. At the point that we have an AI that's capable of every task that say a 110 IQ human is, including manipulating objects in the physical world, then basically everyone is unemployed unless they're cheaper than the AI. reply ben_w 20 hours agorootparentWhile I would certainly expect a radical change to economics even from a middling IQ AI — or indeed a low IQ, as I have previously used the example of IQ 85 because that's 15.9% of the population that would become permanently unable to be economically useful — I don't think it's quite as you say. Increasing IQ scores seem to allow increasingly difficult tasks to be performed competently — not just the same tasks faster, and also not just \"increasingly difficult\" in the big-O-notation sense, but it seems like below certain IQ thresholds (or above them but with certain pathologies), some thoughts just aren't \"thinkable\" even with unbounded time. While this might simply be an illusion that breaks with computers because silicon outpaces synapses by literally the degree to which jogging outpaces continental drift, I don't see strong evidence at this time for the idea that this is an illusion. We may get that evidence in a very short window, but I don't see it yet. Therefore, in the absence of full brain uploads, I suspect that higher IQ people may well be able to perform useful work even as lower IQ people are outclassed by AI. If we do get full brain uploads, then it's the other way around, as a few super-geniuses will get their brains scanned but say it takes a billion dollars a year to run the sim in real time, then Moore's and Koomey's laws will take n years to lower that to $10 million dollars a year, 2n years to lower it to a $100k a year, and 3n years to lower it to $1k/year. reply danenania 20 hours agorootparentI think this trend of using IQ as a primary measuring stick is flawed. Human minds and AI minds have radically different architectures, and therefore have different strengths and weaknesses. IQ is only one component of what allows a typical worker to do their job. Even just comparing humans, the fact that one person with, say, a 120 IQ can do a particular job—say they are an excellent doctor—obviously does not mean that any other human with an equal or greater IQ can also do that job effectively. reply ben_w 18 hours agorootparent> I think this trend of using IQ as a primary measuring stick is flawed. I agree, but it's difficult to fully describe the impact of a tech where $5 gets you the ability to do arithmetic faster than literally every human combined even if we were all working at the speed of the current world record holder, yet simultaneously it took a billion dollar research team 14 years to figure out how to get a robot to reliably tie its own shoelaces (this September: https://deepmind.google/discover/blog/advances-in-robot-dext...) So, IQ it is. Rough guide for a human equivalent intelligence scale, but being mapped to a wildly different architecture so that it, the different architecture, can be reasoned about. > Even just comparing humans, the fact that one person with, say, a 120 IQ can do a particular job—say they are an excellent doctor—obviously does not mean that any other human with an equal or greater IQ can also do that job effectively. Indeed, though in this case I would expect that such a human could learn any of those skills. reply danenania 18 hours agorootparentIt's difficult to fully describe, so let's just give up and use a deeply flawed benchmark? Why not try to develop benchmarks that actually work and tell us something useful instead? The key issue is that there is no result an AI can achieve on a standard IQ test which guarantees that same AI can do any task at a superhuman level, apart from taking IQ tests. Can an LLM that scores 250 replace a human driver? Who knows? Can it replace a senior software engineer? Who knows? Can it replace a manual laborer? Again, who can say? We know a human with a 250 IQ can do all those things, but with an AI we have no idea, because those tasks have many more inputs than IQ. Rather than IQ, which tells us almost nothing concrete, I think we should focus on what tasks it can actually achieve. What's a Waymo's IQ? Who cares?! I don't care about its IQ. I care about its ability to drive me safely across the city. Similarly, I don't care whether a coding AI can drive a car or write great novels. Of course it's interesting to measure and speculate about IQ as it relates to AGI, but I think it gives people the very mistaken impression that we are on some kind of linear path where all we need to do is keep pushing up a single all-important number. reply ben_w 6 hours agorootparent> It's difficult to fully describe, so let's just give up and use a deeply flawed benchmark? Why not try to develop benchmarks that actually work and tell us something useful instead? Two reasons. First: in this sub-thread I'm focusing on employment issues due to AI, so consider the quote from above: > At the point that we have an AI that's capable of every task that say a 110 IQ human is, including manipulating objects in the physical world, then basically everyone is unemployed unless they're cheaper than the AI. IQ doesn't capture what machines do, but it does seem to capture a rough approximation of what humans do, so when the question is \"can this thing cause humans to become economically irrelevant?\", that's still a close approximation of the target to beat. You just have to remember that as AI don't match human thinking, so an AI which is wildly superhuman at arithmetic or chess isn't necessarily able to tie its own shoelaces. The AI has to beat humans at everything (at least, everything economically relevant) at that IQ level for this result. Second: Lots of people are in fact trying to develop new benchmarks. This is a major research topic all by itself (as in \"I could do a PhD in this\"), and also a fast-moving topic (as in \"…but if I tried to do a PhD, I'd be out of date before I've finished\"). I'm not going to go down that rabbit hole in the space of a comment about the exact performance thresholds an AI has to reach to be economically disruptive. For a concrete example of quite how fast-moving the topic is, here's a graph of how fast AI is now beating new benchmarks: https://ourworldindata.org/grapher/test-scores-ai-capabiliti... reply disgruntledphd2 10 hours agorootparentprevMore importantly, basically all of the IQ tests are in the training sets, so it's hard to know how the models would perform on similar tests not in the training set. reply ben_w 7 hours agorootparentIndeed. People do try to overcome this, for example see the difference in results between \"Show Offline Test\" and \"Show Mensa Norway\" on https://trackingai.org/IQ Even the lower value is still only an upper-bound on human-equivalent IQ, as we can't really be sure the extent to which the training data is (despite efforts) enough to \"train for the test\", nor can we really be sure that these tests are merely a proxy for what we think we mean by intelligence rather than what we actually mean by intelligence (a problem which is why IQ tests have been changed over the years). My intention in this sub-thread is more of the economic issues rather than the technical, which complicates things further, because if you have an AI architecture where spending a few tens of millions on compute — either from scratch or as fine-tuning — gets you superhuman performance (performance specifically, regardless of if you count it as \"intelligent\" or not), then any sector which employs merely a couple of hundred workers (in rich economies) will still have an economic incentive to train an AI on those workers to replace them within a year. This is still humans having jobs, and still being economically relevant, but makes basically everyone into a contractor that has to be ready and able to change jobs suddenly, which is also economically disruptive because we're not set up for that. reply rowanG077 20 hours agorootparentprevThis is it. Another primary example is that I can put a 80 IQ person to work on a farm or let them build something under supervision. There is no way for an AI to do either at this time, even if the AI is much smarter. reply ben_w 18 hours agorootparentAh, AI have been doing both farm work and \"building things under supervision\" work for a while now. Robots are a thing, AI controlling robots is a thing. reply rowanG077 1 hour agorootparentRobots at this point are specialized for a highly specific task. None of them are as dynamically deployable as a 80 IQ person. You can let a walk around a construction site doing whatever, no such robot is available right now. If I'm wrong please post where I can buy such a general robot. reply naming_the_user 20 hours agorootparentprevI completely agree with everything that you're saying here - my use of the term \"basically everyone\" was lazy in that I'm implying that at the 110 IQ level the majority (approx 70%) of people are economically obsolete outside of niche areas (e.g. care/butler style work in which people desire the \"human touch\" for emotional reasons). I think that far below the 70% level we've already broken economics. I can't see a society functioning in which most people actually _know_ that they can't break out of whatever box they're currently in - I think that things like UBI are a distraction in that they don't account for things like status jockeying that I think we're pretty hardwired to do. reply someothherguyy 18 hours agorootparentprev> At the point that we have an AI that's capable of every task that say a 110 IQ human is, including manipulating objects in the physical world, then basically everyone is unemployed unless they're cheaper than the AI. Until a problem space is \"solved\", you will still need AIs that are more capable than those with 110 IQ to review the other AIs work. All evidence points to \"mistakes will be made\" with any AI system I have used and any human I have worked with. reply n_ary 17 hours agorootparentprev> I overheard a daughter talking to her mother about ChatGPT and KI (Künstliche Intelligenz, the German for AI). Given the fact that how much ALL of our media beating that drum since GPT-3, I am hoping that my cat will start talking about it without understanding what it is. Even Draghi’s report has immense hidden lobbying dedicated to KI. reply jrflowers 20 hours agorootparentprev> protesters dropped in on the after-award public talk I’m going to guess that GP does not consider random protestors to be in Sam Altman’s ‘sphere’ > The product market fit is fantastic. This is true insomuch that you define “product market fit” as “somebody mentioning it in an Indian restaurant in Berlin” > every definition of \"very smart\" Every definition you say? https://bsky.app/profile/edzitron.com/post/3lclo77koj22y reply amluto 19 hours agorootparentThat’s an odd way to define “smart”. The current crop of LLMs have absolutely no ability to query the raw input or output. I can look at the words I’m typing and think about them. Transformers don’t even get the raw characters, and they also don’t have any feedback from later layers into the queries generated at earlier layers. So the fact that they have any ability at all to reflect on their own input is IMO both impressive and somewhat surprising. I occasionally wonder whether one could get better results by allowing later layers to query against the K/V data from earlier layers. This might make inference, and possibly even training, of models that don’t fit in a single node’s memory rather more complicated. reply ben_w 18 hours agorootparentprev> Every definition you say? When I was growing up, \"very smart\" people had a law degree or a medical degree or understood quantum physics and/or relativity (but all three would be silly), or spoke perhaps three or four languages (but thirty would be a joke). They might perhaps also be above average at games of skill like chess, or perhaps could improvise poetry in some specific style (but every style would be a bit of a Mary Sue). I may not trust ChatGPT's medical diagnosis or legal analysis, but it does pass those exams; I may not expect much novel insights about unifying QM and GR, but it seems to \"know\" the topics well enough for people to worry it may lead to cheating in those subjects and most others besides. And the chess score may not be the absolute best, but it's way above the average human player. And it seems entirely adequate in quite a lot of languages (though not native), and most styles of poetry (again, not what anyone would call the Nobel committee for, but way above what most people can dream of). > https://bsky.app/profile/edzitron.com/post/3lclo77koj22y We also didn't have spellcheck running all the time when I was growing up, and when we did there was quite a lot of red, but even that misses things like \"I'm applying for collage\" and \"what lovely wether*\" which were also real mistakes made by actual humans. * spelled like that it means \"castrated ram\" reply disgruntledphd2 10 hours agorootparent> I may not trust ChatGPT's medical diagnosis or legal analysis, but it does pass those exams; It's really, really, really important to note that this could easily just be memorisation (and indeed, the GSM Symbolic paper from Apple suggests that it most likely is). We don't have a good way of assessing the ability of models literally trained on all free text in existence, but comparing their performance based on text they've seen in training is definitely not it. reply ben_w 8 hours agorootparentWhat I've always disliked about calling it \"memorisation\" is that we already have machines with much better memorisation than what LLMs do: the hard drives with the source documents. To the extent that it's able to respond to and with natural language, this is already an improvement over, say, grep or PageRank. To the extent that it is memorisation in the way we mean when we say a human has memorised something, it's an example of another aspect of what was meant by \"intelligence\" when I was growing up. It's definitely weird and alien as an intelligence, but it still ticks the boxes we used to have even a decade ago, 2014, let alone the late 80s to 1999 when I turned 16. reply BadHumans 17 hours agorootparentprev> When Altman was collecting the award at Cambridge the other year, protesters dropped in on the after-award public talk/Q&A session, and he actively empathised with the protestors. I've known many CEO who will stare you right in the eye and say they hear your concerns then immediately disregard you and continue with business as usual. Being a psychopath is part of the job description. reply moooo99 4 hours agorootparentprev> The product market fit is fantastic. This isn't the first time I've heard random strangers discussing it in public. People were constantly discussing crypto in public, it even regularly made it into Tagesschau. Yet it remains an (influential) niche product. People discussing a topic in public is not a good proxy for product market fit. It does not imply those people are using said product, nor does it imply people would be willing to pay for said product. > even the current models meet every definition of \"very smart\" I had while growing up, despite their errors. I recently tried to read a grocery store receipt into GPT4o and asked it what the KG price for the steak position was (it was listed as €/kg right next to the position name). It came up with some elaborate math, but not with the correct answer. So yeah. These models might be able to confidentially answer questions, but I found them to be (partially) incorrect more often than not. reply foldr 6 hours agorootparentprev> The product market fit is fantastic. > [...] > What's not obvious is how to monetise it. This is an interesting new use of 'product market fit'. I would have thought that in the absence of a path to monetisation, there is no market. Or we could talk about the 'market' for selling $10 bills priced at $5. reply ben_w 4 hours agorootparentI phrased that badly, so that's fair. If you follow the rest of that paragraph, my meaning may be clearer: there's a market for what they do right now — the OpenAI financial reports that have been bandied around say that if they were only offering this as a paid service, not also developing new models, they'd be making a profit — but it's not obvious how this will change going forward. The first spreadsheets were easy to market: here's a solution to your problem, give us money and you can have this solution. But as time goes on, you need more than the original solution, because that's too easy to replicate. ChatGPT was easy to replicate, and has been replicated. The \"needing more\" to stay in the game is what I meant by the Red Queen race. What exists now is fine, it's a good fit, but the question of the long-term is still open. reply lyu07282 20 hours agorootparentprev> foundational assumptions of economics may just stop holding true Those assumptions are already failing billions of people, some people might still be benefiting from those \"assumptions of economics\" so they don't see the magnitude of the problem. But just as the billions who suffer now have no power, so will you have no power once those assumptions fail for you too. reply 23B1 21 hours agorootparentprev> and he actively empathised with the protestors. https://www.simplypsychology.org/narcissistic-mirroring.html reply ben_w 21 hours agorootparentEven if so, that's still showing awareness of what his critics are critical of. Now, can you make a falsifiable prediction: what would a narcissist do that a normal person would not, such that you can tell if he's engaging in a narcissist process rather that what your own link also says is a perfectly normal and healthy behaviour? reply tivert 20 hours agorootparent> Even if so, that's still showing awareness of what his critics are critical of. Mere awareness is really that meaningful. >>> and he actively empathised with the protestors. >> https://www.simplypsychology.org/narcissistic-mirroring.html > Now, can you make a falsifiable prediction: what would a narcissist do that a normal person would not, such that you can tell if he's engaging in a narcissist process rather that what your own link also says is a perfectly normal and healthy behaviour? He doesn't have to, because I think the point was to raise doubts about your interpretation. But if you're looking for more evidence, there are all the stories (from many different people) about Altman being dishonest and manipulative and being very effective at it. That's the context that a lot of people are going use to interpret your claim that Altman \"actively empathised with the protestors.\" reply madrox 20 hours agoparentprevI think an assumption that a lot of people make about people with power is that they say what they actually believe. In my experience, they do not. Public speech is a means to an end, and they will say whatever is the strongest possible argument that will lead them to what they actually want. In this case, OpenAI wants look like they're going to save the world and do it in a noble way. It's Google's \"don't be evil\" all over again. reply sourcepluck 15 hours agorootparentI'll sleep easier tonight after reading this! I know other people know what you say there, but at times reading HN one would suspect that it's not that commonly known around these parts. Maybe public figures were \"saying what they meant\" in, I don't know, the mid-1800s. People who grew up with \"modern\" communications and media infrastructure (smartphones, brain rot, streaming garbage 24/7, ads everywhere, etc) do not have the capacity to act in a non-mediatic fashion in public space anymore. So that's the reality, I think. Not only is Sam Altman \"fake\" in public, so is everyone else (more or less), including you and I. Nonetheless, it's a national sport at least in massive chunks of the English-speaking world now to endlessly speculate about the real intentions of these pharaonic figures. I've said it before, but I'll say it again: what a very peculiar timeline. reply imiric 9 hours agorootparentIt's human nature to assume honesty and good will. Societies couldn't function if that wasn't the case. Lies and deception are only common in interactions outside of our immediate tribe and community. They're the primary tools of scammers, politicians, and general psychopaths, who seek to exploit this assumption of honesty that most people have, and they're very successful at it. The problem is that technology has blurred the line between close communities and the rest of the world, and forced everyone to accept living in a global village. So while some of us would want the world to function with honesty first, the reality is that humans are genetically programmed to be tribal and deceitful, and that can't change in a few generations. It's hilariously easy to be \"successful\" in the modern world. It's so easy that a dumb person following a playbook of \"deny, divert, discredit\" can become president. reply pxmpxm 5 hours agorootparentprevThis. All this bullshit about \"AI will kill us all\" is purely a device to ensure regulatory capture for the largest players, ie the people saying said bullshit. Pretend your meme pic generator is actually a weapon of mass destruction and you can eliminate most of your competition by handwaving about \"safety\". reply pinewurst 22 hours agoparentprevNobody seems to remember how the Segway was going to change our world, backed by many of the VC power figures at the time + Steve Jobs. reply mbreese 21 hours agorootparentThe hype cycle for Segway was insane. Ginger (code name) wasn’t just going to change the world, it was going to cause us to rethink how cities were laid out and designed. No one would get around the world in the same way. The engineering behind it was really quite nice, but the hype set it up to fail. If it hasn’t been talked up so much in the media, the launch wouldn’t have felt so flat. There was no way for them to live up to the hype. reply tim333 20 hours agorootparentI guess it depends on what media you follow. As a Brit my recollection was hearing it was a novelty gadget that about a dozen American eccentrics were using, and then there was the story that a guy called Jimi Heselden bought the company and killed himself by driving one off a cliff and then that was about it. Not the same category as AI at all. reply qingcharles 11 hours agorootparentI was in the tech space in the UK at the time and the hype behind this was off the charts. I seem to remember a meeting with Bezos where he was super hyped about it, and we had no idea what \"it\" was still. The speculation was crazy. reply pinewurst 20 hours agorootparentprevThe \"Code Name: Ginger\" book, by a writer embedded with the team, is excellent btw. reply dghlsakjg 21 hours agorootparentprevThe Segway was a bit early, and too expensive, but I would defend it... sort of. Electric micromobility is a pretty huge driver of how people negotiate the modern city. Self-balancing segways, e-skate, e-bike and scooters are all pretty big changes that we are seeing in many modern cityscapes. Hell, a shared electric bike was just used as a getaway vehicle for an assassination in NYC. reply numpad0 6 hours agorootparentSegway is just an electric pizza delivery bike _that don't look like one_. That's it. The Segway City is just electric Ho Chi Minh 1995 in style of 2000 Chicago. People wants to die in style so much that they turn blind eyes to plasticky scooters and Nissan Leafs. To them, the ugly attempt don't exist, and the reskinned clones are the first evers in the history. But reality prevails. Brits aren't flying EE Lightning jets anymore. Segways were kind of cool to me too, to be fair. To lesser extent Lime scooters too. Sort of. But they're still just sideways pizza bikes. reply jpalawaga 20 hours agorootparentpreve-/bikes and e-/scooters are big changes to city navigation. e-skate and segways are non-factors. And that's the difference between a good product (ebike or even just plain old bikeshare) and a bad one (segway). reply klik99 22 hours agorootparentprevIn Segways defense that self balancing tech has made and will continue to make an impact, just not world changing amount (at least not yet) and not their particular company but the companies they influenced - the same may end up true about openai reply stolenmerch 21 hours agorootparentprevI remember serious discussions about how we'd probably need to repave all of our sidewalks in the US to accommodate the Segway reply hanspeter 21 hours agorootparentprevI think we all remember, and if we forget, we're reminded every time we see them at airports or doing city tours. reply Calavar 21 hours agorootparentI don't think I've seen a Segway in close to ten years. Also I suspect most people under 25 have never even heard of Segway. reply elif 21 hours agorootparentOne wheels (Segway evolutionary grandchild) are almost as popular as electric skateboards. reply 9dev 21 hours agorootparentSo… not much? If anything, people drive electric scooters around here. Those seem to hit the sweet spot. reply arthurcolle 21 hours agorootparentprevIt reappeared as e-bikes and e-scooters - Lime, Bird, etc. reply ldbooth 21 hours agorootparentReappeared as Electric unicycles, which look hilarious, dangerous, and like a lot of fun. reply bee_rider 20 hours agorootparentprevApparently the first e-bike was invented in 1895. So I don’t think it is accurate to give Segway too much credit in their creation. Anyway the innovation of Segway was the balance system, which e-bikes don’t need. (I’m not familiar with the site in general, but I think there’s no reason for them to lie about the date, and electric vehicles always show up surprisingly early). https://reallygoodebikes.com/blogs/electric-bike-blog/histor... reply n144q 20 hours agorootparentprevNone of which is doing great. reply tim333 20 hours agorootparentThere are about 70 lime bikes that commute to the square by my flat. There's definitely some ebike stuff ongoing. reply danenania 20 hours agorootparentprevE-bikes are everywhere. reply RockyMcNuts 20 hours agorootparentprevmore as hoverboard, onewheel etc. the e-bikes and e-scooters don't really have similar balancing mechanisms reply arthurcolle 19 hours agorootparentyeah, didn't even remember those, but that's even more on point reply anothertroll123 21 hours agorootparentprevNo it didn't reply elif 21 hours agorootparentprevYou mean Steve Wozniak. Close but no LSD reply pinewurst 19 hours agorootparenthttps://www.theguardian.com/world/2001/dec/04/engineering.hi... \"Steve Jobs, Apple's co-founder, predicted that in future cities would be designed around the device, while Jeff Bezos, founder of Amazon, also backed the project publicly and financially.\" reply favorited 21 hours agorootparentprevSteve Jobs said that Segways had the potential to be \"as big a deal as the PC.\" reply pantalaimon 21 hours agorootparentprevWhat makes you so sure about the LSD? reply sebzim4500 20 hours agoparentprev>and no obvious large-scale product-market fit I'm afraid you are in as much an echo chamber as anyone. 200 million+ weekly active users is large scale pmf reply jillesvangurp 13 hours agorootparentExactly. There's plenty of return on investment. Knowledge workers around the world are paying nice subscription fees for access to the best models just to do their work. There are hundreds of millions of daily active users already. And those are just the early adopters. Lots of people are still in denial about that they need this to do their work very soon. Countless software companies pay for API access to these models as well. As they add capabilities, the market only becomes larger. OpenAI is one of a handful of companies that is raking in lots of cash here. And they've barely scratched the surface. It's only a few years ago that Chat GPT was first released. OpenAI is well funded, has lots of revenue, and lots of technology coming up that looks like it's going to increase demand for their services. There's a very obvious product market fit. reply numpad0 11 hours agorootparentprevbut they're not making money and there are plenty substitutes. I bet they have practically zero paid customer retention rate. People say they love it, so what. reply sebzim4500 3 hours agorootparent>I bet they have practically zero paid customer retention rate Why do you think that? I know a few people with a subscription but I don't think I know anyone who has cancelled. Even people who have mainly moved to Claude kept the plus subscription because it's so cheap and o1 is sometimes useful for stuff Claude can't do. reply foooorsyth 20 hours agorootparentprevIt’s the fastest product to 100m users ever. Even if they never update their models from here on out, they have an insanely popular and useful product. It’s better at search than Google. Students use it universally. And programmers are dependent on it. Inference is cheap — only training is expensive. To say they don’t have PMF is nuts. reply dom96 19 hours agorootparent> And programmers are dependent on it. that is clearly not the case reply dingnuts 19 hours agorootparentprev>It’s better at search than Google in what world? what it's good at is suggesting things to search, because half of what it outputs is incorrect, so you have to verify everything anyway it does, slightly, improve search, but it's an addition, not a replacement. reply CamperBob2 16 hours agorootparentTwo years ago half of what it output was incorrect. One year ago, maybe 30% of what it output was incorrect. Currently, maybe 20% of what it tells you is incorrect. It's getting better. Google, on the other hand, is unequivocally getting worse. reply ceejayoz 19 hours agorootparentprev> It’s better at search than Google. That’s hardly a high bar now. > And programmers are dependent on it. Entry level ones, perhaps. reply disgruntledphd2 9 hours agorootparentI mean, these models are super useful for small defined tasks where you can check their output. They're also useful for new libraries or things that you're not an expert in (which obviously varies by domain and person, but is generally a lot of stuff). I'm a data person and have been using them to generate scraping code and web front-ends and have found them very useful. But I wouldn't trust them to fit and interpret a statistical model (they make really stupid beginner mistakes all the time), but I don't need help with that. Like, in a bunch of cases (particularly the scraping one) the code was bad, but it did what I needed it to do (after a bunch of tedious re-prompting). So it definitely impacts my productivity on side projects at least. If I was doing more consulting then it would be even more useful, but for longer term engagements it's basically just a better Google. So yeah, definitely helpful but I wouldn't say I'm dependent on it (but I'd definitely have made less progress on a bunch of side projects without it). Note: it's good for python but much, much less good at SQL or R, and hallucinates wildly for Emacs Lisp. reply numpad0 11 hours agorootparentprevs/programmers/front\\ end\\ html\\ authors/ reply hengheng 22 hours agoparentprevThese guys didn't get to where they are now by admitting mistakes and making themselves accountable. In power play terms, that would be weak. And once you are way up there and you have definitely left earth, there is no right or wrong anymore, just strong and weak. reply ksec 10 hours agoparentprevMillenarianism or millenarism (from Latin millenarius 'containing a thousand' and -ism) is the belief by a religious, social, or political group or movement in a coming fundamental transformation of society, after which \"all things will be changed\".. - From Wiki Correct me if this the wrong meaning in the context. I will admit this is the first time I see this word. When I first read it I thought it was something to do with \"millennials\" also known as Gen Y. >Robotics to be \"completely solved\" by 2020, And we still dont have Lv4 / Lv 5 autonomous vehicles. Not close and likely still not in 2030. And with all the regulation hurdle in place it means even if we achieve it by 2030 in lab it wont be widespread until 2035 or later. reply ta12653421 10 hours agorootparent++1 me too reply dbreunig 20 hours agoparentprevAltman appears to say AGI is far away when he shouldn't be regulated, right around the corner when he's raising funds, or is going to happen tomorrow and be mundane when he's trying break a Microsoft contract. reply johnisgood 7 hours agoparentprevClaude is great, I think Claude 3.5 Sonnet is way better than OpenAI's GPT-4. It understands and follows instructions better, and the context length is larger too. Despite GPT-4 having some context length, too (duh), it often acts as if I started over. It fails at programming for me, and for basic stuff, like \"giving movie recommendations without duplicates\". If I send it twice or thrice, there will be duplicates despite having it instructed to omit them. As long as Anthropic does not dumb their own models, they are going to be better than OpenAI, at least for what I use them. So, in the present, Claude is way more useful to me and I am subscribed. Right now, they do not support text-to-speech and imagine generation, but once they do, I would just completely abandon OpenAI. > The board of OpenAI is supposedly going to \"determine the fate of the world\", robotics to be \"completely solved\" by 2020, the goal of OpenAI is to \"avoid an AGI dictatorship\". Given the above, I doubt it is going to be OpenAI at this rate. It seems better for educational purposes given that it shows you the code with modifications in real-time and you can run Python scripts for example, but that said, I have not tried the \"Educational\" style for Claude. reply elif 21 hours agoparentprev>So far we are multiple years in with much investment and little return, and no obvious large-scale product-market fit Literally every market has been disrupted and some are being optimized into nonexistence. You don't know anyone who's been laid off by a giant corporation that's also using an AI process that people did 3 years ago? reply munk-a 21 hours agorootparentI know companies that have had layoffs - but those would have happened anyways - regular layoffs are practically demanded by the market at this point. I know companies that have (or rather are in the process of) adopting AI into business workflows. The only companies I know of that aren't using more labor to correct their AI tools are the ones that used it pre-ChatGPT/AI Bubble. Plenty of companies have rolled out \"talk to our AI\" chat bubbles on their websites and users either exploit and jailbreak them to run prompts on the company's dime or generally detest them. AI is an extremely useful tool that has been improving our lives for a long time - but we're in the middle of an absolutely bonkers level bubble that is devouring millions of dollars for projects that often lack a clear monetization plan. Even code gen seems pretty underwhelming to most of the developers I've heard from that have used it - it may very well be extremely impactful to the next generation of developers - but most current developers have already honed their skills to out-compete code gen in the low complexity problems it can competently perform. Lots of money is entering markets - but I haven't seen real disruption. reply hyeonwho4 20 hours agorootparent> Even code gen seems pretty underwhelming to most of the developers I've heard from that have used it - it may very well be extremely impactful to the next generation of developers - but most current developers have already honed their skills to out-compete code gen in the low complexity problems it can competently perform. I'm in academia, and LLMs have completely revolutionized the process of data analysis for scientists and grad students. What used to be \"page through the documentation to find useful primitives\" or \"read all the methods sections of the related literature\" is now \"ask an assistant what good solutions exist for this problem\" or \"ask LLMs to solve this problem using my existing framework.\" What used to be days of coding is now hours of conversation. And it's also above-average at talking through scientific problems. reply munk-a 7 hours agorootparentI've heard something similar from the legal field as well. When you're dealing with massive amounts of unstructured documentation that needs to be searched LLMs seem to be doing a better job of indexing that information than conventional search indexers. I agree that it is having a pretty big impact in those fields where large amounts of unstructured data needs to be combed through. reply kmacdough 5 hours agoparentprevI use AI in my work as a machinist/CNC programmer on a weekly if not a daily basis. It's primary advantage for a while has been it's crazy breadth of knowledge which it can present in a human, flexible form. But perhaps we excuse this as Generally Knowledgeable not Generally Intelligent. But with the most recent models I'm finding the intelligence harder to deny. They are now catching errors and false assumptions unprompted and with regularity and providing reliable feedback and criticism. Gemini 2.0 can now read prints usefully, if not perfectly and has caught multiple print errors missed by the engineers and experienced machinists alike. It provides valuable feedback and criticism and frequently interjects when it thinks I'm barking up the wrong tree. The newest models have gotten quite good at asking for clarification rather than leaning into assumptions. Now it's certainly not the smartest. It's creativity is mediocre and it's lack of practical experience is apparent. But thats understandable, as _it's never machined a day in it's life_. It's merely studied what's been written. Sure, hallucinations and the like are still a thing (though they've been cut down drastically). And the creativity is quite mediocre. But it seems a lot more intelligent than some of the burnouts coming out of trade schools. reply wnevets 20 hours agoparentprev> Is nobody in these very rich guys' spheres pushing back on their thought process? The moment someone does that they're no longer in the very rich guys sphere. reply Flomolok 22 hours agoparentprevI tried Claude. If hardware continues it's evolution of speed in the next 10 years I can have Claude but local + running constantly and yeah that would change certain things fundamentaly reply jasonjmcghee 21 hours agorootparentTry llama 3.3 70B. On groq or something. Runs on a 64GB macbook (4bit quantized, which seems to not impact quality much). Things have come a long way. Compare to llama 2 70b. It's wild reply Terretta 21 hours agorootparentLlama 3.3 70B 8-bit MLX runs on Macbook 128GB at 7+ tokens per second while running a full suite of other tools, even at the 130k tokens size, and behaves with surprising coherence. Reminded me of this time last year, first trying Mixtral 8x22 — which still offers a distinctive je ne sais quoi! reply nmfisher 14 hours agorootparentprevQwen 2.5 32B Coder is actually a viable locally-hosted alternative to Claude 3.5 Sonnet. It's not better, but if I couldn't access Claude for some reason, I would definitely use it. reply Scene_Cast2 22 hours agorootparentprevWhen ChatGPT was down a few days back, I locally booted up Codestral. It was decent and usable. reply niceice 16 hours agoparentprevWould you have disagreed with Ilya about AGI? Or do you just disagree with the cost and timeline? Ilya reiterated on July 12, 2017, “Each year, we'll need to exponentially increase our hardware spend, but we have reason to believe AGI can ultimately be built with less than $10B in hardware.” reply pooper 18 hours agoparentprev> Is nobody in these very rich guys' spheres pushing back on their thought process? I will take a wild guess and say a qualified no in the sense that nobody who report directly to these people said anything against it and my conspiracy theory is that they were not idiots who didn't have their own misgivings but they prized their own personal gain / \"professional growth\" by being yes men over doing what they had a professional responsibility. My favorite example is the Amazon Fire Phone > Jeff Bezos reportedly \"...envisioned a list of whiz-bang features... NFC for contactless payments, hands-free interactions to allow users to navigate the interface through mid-air gestures and a force-sensitive grip that could respond in different ways to various degrees of physical pressure\", most of which ultimately did not end up in the final product. He also \"obsessively monitored the product\", requiring \"even the smallest decisions needed to go by him\". Did nobody think that an expensive phone would make sense with a value conscious audience of Amazon.com? If nobody (who directly reports to the CEO) dares question even a relatively minor thing like this, how can we expect them to say anything about major/existential issues in a company such as \"Open\" AI? https://en.wikipedia.org/wiki/Fire_Phone reply takinola 17 hours agorootparentThere is a steelman argument for not pushing back on plans that don't make sense. You have to remember that folks like this are not just random mad men spouting crazy ideas. This is someone that has had crazy ideas in the past AND made them happen. In some cases, more than once. If you had a front row seat to watching someone deliver stuff that you thought couldn't be done, what you do when they came up with the next crazy idea? It is not unreasonable to subjugate your own judgement and just see where it goes. reply TZubiri 21 hours agoparentprevI remember seeing OpenAI like 10 years ago in GiveWell's list of charities along with water.org, deworm the world 80.000 hours and that kind of things. It's a wild take to say that they have gotten nowhere and that they haven't found product-market fit. reply talldayo 4 minutes agorootparentAnyone familiar with the past 10 years of \"unicorn\" startups or Sam Altman's business history is perfectly content saying that OpenAI has gone nowhere and cannot find a market fit for their paid products. reply lupire 15 hours agorootparentprevAre you sure? Good Ventures / Open Philanthropy (Dustin Moskovitz) funded GiveWell and OpenAI, and GiveWell's leadership floated to OpenAI, but I'm not convinced that GiveWell funded OpenAI. https://www.givewell.org/about/gw-op-relationship They are certainly both entangled with the Effective Altruism community, but GiveWell came from the \"humanities/finance\" side, not the tech bro technoutopia side. reply bubaumba 14 hours agoparentprev> multiple years in with much investment and little return Hmm.. where do you live? It's quite transforming already in many areas and not going to stop any time soon. I'll call it 'The Last Explosion', as opposite to 'AI Winter'. By that I mean this explosion with result in AGI. Likely sub-human first, then super-human. reply andy_ppp 21 hours agoparentprevEcho chambers are very effective at drowning out dissenting voices. reply pembrook 20 hours agoparentprev> no obvious large-scale product-market fit I mean, I know pessimistically \"ackshually\"-ing yourself into the wrong side of history is kind of Hackernews's thing (eg. that famous dropbox comment). But if you don't think OpenAI found product-market-fit with ChatGPT, then I don't think you understand what product-market-fit is... reply dkrich 10 hours agorootparentThat’s because it sparked a virtuous feedback loop at a time when it just so happens people’s credulity levels are off the charts. The creators of AI tools have a benefit in hyping it, as do software vendors as do hardware companies as do hyper scalers as does meta as does musk as do systems integrators like Accenture and on and on. I think OP is saying despite all that there is little evidence that end users are actually paying significant sums of money to use it. To this point it’s a great marketing tool for companies that are all eager to be viewed as innovative and you have lots of very wealthy smart people with clout like Bezos and Zuckerberg talking it up. Like any good bubble you have to have at the core a real asset. So of course there are people who use it daily as many anecdotes here in the comments point out. It’s a genuinely interesting and useful technology. That doesn’t mean though that it’s going to result in AGI or become profitable while liquidity conditions are still easy. I promise you Mark Zuckerberg would be singing a very different tune regarding chip investment if he were having to compete with bonds yielding 6-7%+. reply WickyNilliams 7 hours agorootparentprevThere is no killer app (yet). Chat is nice and there's various tools that are useful to devs. But broadly, there is no killer app that makes _everyone_ adopt it and gladly pay for it. https://en.m.wikipedia.org/wiki/Killer_application reply pembrook 7 hours agorootparentYea same with Google. I mean search is nice. But broadly there’s no killer app that makes _everyone_ gladly pay for it. Jury is still out on whether they’ll be able to subsidize those massive server costs of indexing the entire web. reply foldr 6 hours agorootparentThe cost to Google per search is way lower, though. reply WickyNilliams 6 minutes agorootparentPlus they actually make money from it! reply snowwrestler 20 hours agorootparentprevIt’s popular but not making money. So maybe product-audience fit so far. reply ThrowawayTestr 22 hours agoparentprevIt's been clear for a while now Elon has no one in his life that's willing to push back on his inane ideas reply catigula 22 hours agorootparentnext [20 more] [flagged] computerex 22 hours agorootparentThat same space company said that they'd do point to point commercial travel using rockets. As for significantly outperforming: Ask NASA, price per launch has gone UP not DOWN. What's the point of reusability if it doesn't affect the bottom line in a positive way? reply arandomusername 21 hours agorootparent> The development of commercial launch systems has substantially reduced the cost of space launch. NASA’s space shuttle had a cost of about $1.5 billion to launch 27,500 kg to Low Earth Orbit (LEO), $54,500/kg. SpaceX’s Falcon 9 now advertises a cost of $62 million to launch 22,800 kg to LEO, $2,720/kg. https://ntrs.nasa.gov/citations/20200001093 Why do you lie? reply UniverseHacker 21 hours agorootparentIt is required to assume good faith in you HN replies… which imo makes it a nicer place to discuss things. People can be wrong about things or be referring to different information without intentionally lying. reply kulahan 21 hours agorootparentThis is prett",
    "originSummary": [],
    "commentSummary": [
      "Elon Musk initially envisioned OpenAI as a for-profit entity, but there is skepticism regarding its progress and impact.",
      "Critics question OpenAI's ambitious claims, such as determining the world's fate and solving robotics by 2020, highlighting debates over its product-market fit and profitability.",
      "The discussion includes the disruptive potential of AI tools like ChatGPT, the influence of tech leaders, and the challenges of balancing innovation with accountability."
    ],
    "points": 524,
    "commentCount": 574,
    "retryCount": 0,
    "time": 1734118601
  },
  {
    "id": 42413086,
    "title": "McKinsey and Company to pay $650M for role in opioid crisis",
    "originLink": "https://www.npr.org/2024/12/13/nx-s1-5155962/mckinsey-purdue-opioid-prosecution-doj",
    "originBody": "National McKinsey & Company to pay $650 million for role in opioid crisis December 13, 20243:40 PM ET Brian Mann McKinsey and Company has agreed to pay $650 million to settle federal civil and criminal probes into alleged wrongdoing linked to \"turbocharging\" opioid sales on behalf of Purdue Pharma. Fabrice Coffrini/AFP via Getty Images hide caption toggle caption Fabrice Coffrini/AFP via Getty Images The global consulting firm McKinsey and Company Friday agreed to pay $650 million to settle a federal probe into its role in helping \"turbocharge\" sales of the highly addictive opioid painkiller OxyContin for Purdue Pharma, the U.S. Justice Department announced on Friday. Federal officials said the influential consulting company - which often advises governments and powerful corporations around the globe - committed crimes while trying to aggressively boost opioid sales. \"It was a strategy, it was executed and it worked,\" said U.S. attorney Christopher Kavanaugh during a press conference on Friday. \"McKinsey's strategy resulted in prescriptions for Oxycontin that were unsafe and medically unnecessary.\" Sponsor Message According to Kavanaugh, former McKinsey senior partner Martin Elling \"personally deleted various Purdue related electronic materials from his McKinsey laptop with the intent to obstruct future investigations.\" DOJ officials said Elling has agreed to plead guilty to a felony count of obstruction of justice for destroying those company records. The settlement comes from charges brought by U.S. attorney's offices in Virginia and Massachusetts. McKinsey's payment, which includes $2 million paid to the Virginia Medicaid Fraud Control Unit, settles federal civil and criminal charges against the firm and includes a \"deferred prosecution\" agreement. Under the civil settlement, McKinsey is not admitting liability. A copy of the deferred prosecution agreement was not publicly available at the time of publication. That means unless it commits additional wrongdoing linked to opioids, the other executives who led McKinsey during years when it helped drug companies boost prescription opioid sales won't face criminal charges or trial. Internal corporate memos show McKinsey promised to help Purdue Pharma, maker of the highly addictive pain medication Oxycontin, \"turbocharge\" sales at a time when deadly overdoses were surging nationwide. \"We are deeply sorry for our past client service to Purdue Pharma,\" McKinsey said on Friday in a statement sent to NPR. The firm also apologized for \"the actions of a former partner who deleted documents related to his work for that client.\" Sponsor Message This payout comes on top of the nearly $900 million McKinsey agreed to pay in opioid settlements released previously with state and local governments that were suing the firm. \"We should have appreciated the harm opioids were causing in our society and we should not have undertaken sales and marketing work for Purdue Pharma. This terrible public health crisis and our past work for opioid manufacturers will always be a source of profound regret for our firm,\" the McKinsey statement said. As part of the deal, McKinsey has agreed to refrain from any work in the future involving \"controlled substances\" including opioids and to face closer federal oversight. The company also now says it agrees to the \"facts and allegations\" underlying misdemeanor charges against McKinsey and \"felony obstruction by a now-former senior partner.\" DOJ officials said the misdemeanor offense involved \"knowingly and intentionally conspiring with Purdue and others to aid and abet the misbranding of prescription drugs.\" \"This resolution marks the first time a management consulting firm has been criminally responsible for advice it has given resulting in the commission of a crime by a client,\" the DOJ's Kavanaugh said at Friday's press conference. Purdue Pharma, McKinsey's one-time client, has pleaded guilty twice to federal charges linked to improper opioid practices in 2007 and again in 2020. However, following plea agreements, none of the opioid-makers executives, employees or owners were tried or served prison time. Following the prescription opioid crisis that began in the 1990s, numerous corporations agreed to pay hefty fines and settlements, worth more than $50 billion but only a handful of corporate executives have been punished. Critics say that pattern has continued through two decades of Democratic and Republican administrations. \"No one goes to jail,\" said Ed Bisch, an opioid activist whose son Eddie died after overdosing on Purdue Pharma's pain medication Oxycontin in 2001. \"It has to stop because these companies look on [corporate] fines as a cost of doing business,\" he said. Sponsor Message Bisch's group, called Relatives Against Purdue Pharma, has staged protests outside DOJ headquarters in Washington, D.C., demanding more accountability for corporate leaders who aggressively promoted and profited from opioid sales. Bisch noted the DOJ frequently prosecutes street level drug dealers, physicians and \"pill mill\" pharmacy operators accused of wrongdoing linked to opioids. They often wind up serving lengthy prison sentences. But high-level corporate players involved in the marketing and distribution of hundreds of millions of opioid pills almost never face felony-level charges or spend time behind bars. \"Just collecting illicit profits without prosecuting individuals behind the crimes is no real deterrent and it sickens parents like myself,\" Bisch said. Indeed, many top company leaders at firms involved in the opioid industry have continued to rack up big bonuses and pay hikes, even as their firms paid out billions of dollars in opioid settlements or admitted to criminal acts highly hazardous to the public. \"The corporation just pays the speeding ticket and moves on,\" said Paul Pelletier, a former DOJ attorney who worked on an opioid investigation of Purdue Pharma in 2006. According to Pelletier, the DOJ's approach often leaves individual corporate wrongdoers untouched, even when the DOJ says there's evidence of serious misconduct. \"It is essential that DOJ hold corporate executives liable,\" he said. In a statement sent to NPR a Justice Department spokesperson said charging decisions are \"based on the facts of each case.\" \"While not all crimes that result in corporate criminal liability are committed by company leaders, whether such leaders face criminal charges depends upon whether there is proof beyond a reasonable doubt,\" the DOJ statement read. Federal indictments of opioid executives aren't completely unheard of. In 2019, the DOJ won a rare conviction against John Kapoor, CEO of Insys Therapeutics, along with four other company executives. Insys founder John N. Kapoor (center) leaves the John Joseph Moakley United States Courthouse in Boston on May 2, 2019. On the 15th day of deliberations, a US District Court jury in Boston found that Kapoor and four former executives of Insys Therapeutics engaged in a nationwide conspiracy to pay off doctors at pain clinics to prescribe Subsys, an under-the-tongue fentanyl spray approved in 2012 for cancer pain. Jonathan Wiggs/Boston Globe via Getty Images hide caption toggle caption Jonathan Wiggs/Boston Globe via Getty Images \"Today's convictions mark the first successful prosecution of top pharmaceutical executives for crimes related to the illicit marketing and prescribing of opioids,\" then-U.S. Attorney Andrew Lelling said in a statement issued at the time. That year, the DOJ also prosecuted executives with Rochester Drug Co-operative, a regional drug distributor in Upstate New York. opioid crisis Facebook Flipboard Email",
    "commentLink": "https://news.ycombinator.com/item?id=42413086",
    "commentBody": "McKinsey and Company to pay $650M for role in opioid crisis (npr.org)351 points by pseudolus 20 hours agohidepastfavorite257 comments remarkEon 10 hours agoA little unrelated to this whole thing, which does hit me a bit personally since my cousin back in Iowa died of opioid-related dependency issues, but I have interviewed a lot of consultants over the years for various roles and they are without question the most consistently bad interviews. It's funny, when I was in business school years ago (please forgive me) getting a job at McKinsey or BCG was more or less the crème de la crème of post-MBA gigs. Now, when I interview these people it's so transparent that yeah they're very smart, but they literally know nothing. They've spent years cycling in and out of \"client engagements\", so they can give you a 30k foot view of what's going on, on a dozen different things, but when you try to dig into the details there's not a lot there. I'm probably casting a wide net since my sample size is large, and I'm sure there are great consultants at these places who have spent more than a few months on something, and could do good work in tech or hardware. But so far for me it's something like 1/70. Maybe I'm just that asshole interviewer. reply mdorazio 6 hours agoparentI've also interviewed many consultants over the years. It strongly depends on what you are interviewing them for. If you want people with deep industry expertise and a strong fit for a fairly narrow role, then yes of course the consulting kids are going to suck. If you want people who can learn quickly and look more broadly than a specific department to do things like strategic or financial planning then consultants can be a good fit. reply xyzzy123 2 hours agorootparentThese kinds of consultants have the same issue as LLMs: they say the maximally plausible thing without knowing (or necessarily caring) if what they are saying is actually true. I don't think strategy advice is worth much unless it's coming from people who stuck around and lived with the consequences (i.e, tested their ideas against reality). reply remarkEon 52 minutes agorootparentprev>and look more broadly than a specific department to do things like strategic or financial planning then consultants can be a good fit. I disagree with this, but I definitely understand your argument. I just don't see how someone who oscillates back and forth from various clients, even if they're all in the same industry, can get enough deep background to be able to coherently make recommendations about business strategy. reply dcreater 10 hours agoparentprevI'm so proud of my decision making when I was younger to avoid this path though it was considered an elite path reply dmd 6 hours agorootparentI am grateful for McKinsey and BCG because when I dropped out of my postdoc in 2009 and was looking for a job, I went to probably 20 or 30 of their lunch events at Wharton where I absolutely stuffed myself and my pockets, despite having no intention whatsoever of joining them. reply beepboopboop 5 hours agorootparent> and my pockets Do they give money out at these lunches?? reply dmd 5 hours agorootparentNo I mean I literally stuffed my coat pockets with food! Sandwiches, fruit, cheese especially. reply thechao 5 hours agorootparentOral defense season was always a good way to get ahead, financially. You do get sick of pizza, though. reply rr808 5 hours agoparentprev> It's funny, when I was in business school years ago (please forgive me) getting a job at McKinsey or BCG was more or less the crème de la crème of post-MBA gigs. Still is though right? Just now you have enough experience to be wise enough to know what is important. reply rightbyte 7 hours agoparentprevMcKinsey is sweatshop but with good pay. The work conditions are atrocious and they grind through naive young people like Verdun. Some people have argued on HN that the consultants are cya and political support for things the management class allready know they want. That seem about right. reply ProjectArcturis 4 hours agorootparent\"Painting bullseyes around bullet holes\" is the unofficial consultant motto. reply eichi 4 hours agorootparentprev>> consultants are cya and political support for things the management class allready know they want. That seem about right. That is the most valuable job in virtually every profitable industries including tech. reply jncfhnb 4 hours agorootparentprevIt varies tremendously. Imo the people who have sweatshop experiences bring it upon themselves mostly. reply jfengel 4 hours agorootparentI've always been unclear on this. Various careers are famed for extremely long hours, but I don't know just what it is they do for all that time. Consultants, financeers, etc. I know that I have only so much brain power to spend a day. I can work longer, but at best you're going to get more grind, not quality. I keep wondering if these consultants could accomplish as much in fewer hours if they weren't so intent on being the one who puts in so many hours. I know almost nothing about what they do so I'm just guessing. But I find it hard to square so much effort with results that don't seem to merit it. reply jncfhnb 4 hours agorootparentI am a McKinsey consultant, and I tend to think the people putting in those insane hours are shooting themselves in the foot. It is easier to work longer hours when a hotel takes care of everything for you, but if you’re bragging about how little sleep you get you’re just teetering on the edge of burnout and American Psycho neuroticism. reply JambalayaJimbo 2 hours agorootparentprevThere is a lot of work done that is effectively meaningless and doesn’t take a lot of brain power. Sliding things around a PowerPoint for example. reply jncfhnb 2 hours agorootparentSliding things around on a PowerPoint is a lot of nitpicky communication design thinking. It’s still draining. reply rightbyte 2 hours agorootparentprevMm ye. I don't have first hand experience but two class mates and a friend that worked there gave the same picture. They described it as up or out where you really have to grind long hours and the career is in sales and management not as a consultant really. reply jncfhnb 2 hours agorootparentNot really what I meant. It is up or out, but I don’t really believe the long hours are an effective way to achieve the up. It’s just something a lot of people impose on themselves. The sales and management part only really comes in after you’ve passed the team manager level which is fairly advanced. reply rightbyte 31 minutes agorootparent> I don’t really believe the long hours are an effective way to achieve the up. That is an interesting comment. I think you are right. Probably more of a baseline competency but extraordinary 'soft skills'? I meant team manager as included in 'sales'. Where I've worked as consultant (warm body, not a real consultant) team managers were essentially sales people. reply jmcgough 16 hours agoprevA slap on the wrist. After a half million Americans have died from a crisis they helped kickstart, they should be facing criminal charges and jail time. The rich and powerful once again are allowed to buy their freedom. reply JPKab 16 hours agoparentMy mom got hooked in 99 after she slipped on ice at her house in Bluefield, WV. Became a full blown addict after getting prescribed for the subsequent back injury. She lost everything, disappeared, became a homeless addict drifting from DC to Baltimore to NYC and back, until she died of an overdose of heroin in a parking lot of a 7-11 in DC in December 2015. Her story and the impact on me and my 4 siblings is a drop in an ocean of suffering these smug assholes inflicted on this country. This slap on the wrist is an insult to all of us, especially us Appalachians, who saw this starting in the 90s and got ignored because “hillbillies are genetically prone to addiction” as Purdue told the FDA. reply bdangubic 15 hours agorootparentI am sorry to hear this. I would have gone full Luigi on someone if this happened to me reply shuckles 4 hours agorootparentSince when were casual references to murdering people acceptable on here? reply bdangubic 36 minutes agorootparentif you are responsible for the death of my Mum you may have to suffer some consequences… reply naijaboiler 4 hours agorootparentprevLuigi is a verb now. I love it! reply pkkkzip 14 hours agorootparentprevnext [13 more] [flagged] hollerith 14 hours agorootparent>just like the canadian billionaire couple who ran a drug company got whacked The Canadian couple got whacked by a competing drug company for selling cheap generic versions of expensive drugs. Or at least that is what most observers believe although last I heard, no one has ever been charged with the murders. Before the murders, people were worried the couple would be killed because they were so good at bringing to market drugs that are much cheaper than any of their competitors, destroying the profit margins of those competitors. reply slater 14 hours agorootparentAnd you know this, how? reply Rebelgecko 13 hours agorootparentVibes based evidence reply fakedang 13 hours agorootparentprev> lot of ppl on the left mad at billionaires too Seems the left were always in favor of Luigi. I'm more surprised by the right in the US. The days just after the shooting, they were all in favor too, but after their media pundits took an opposing stance, they joined the bandwagon and are now ranting about \"muh poor CEO\". Bunch of sheep I suppose. reply grues-dinner 6 hours agorootparentThe period when people have their own reactions, followed by a sudden reset and synchronisation once the taking points get assembled and is really quite fascinating. I would really love to know how centralised the process of defining talking points is, or if it is, itself, emergent behaviour of a distributed system resulting in coherent outcomes. reply dxbydt 36 minutes agorootparentwhat an amazing turn of phrase - “reset and synchronization once the talking points get assembled” Literally describes 99 of the 100 post-jira action items coming out of the clueless PM’s mouthhole. reply jkolio 5 hours agorootparentprevYeah, it doesn't have to be centralized. I watched aghast at the narrative building around the Trayvon Martin murder in real-time across Reddit and The Website Which Shall Not Be Named. No one was giving marching orders; it was just a milieu of people throwing out ideas and the most convenient ones propagating outward. \"He was slamming his head against the concrete,\" etc. (How could you possibly know? The word of the accused?) Look, we're doing it now. reply immibis 4 hours agorootparentprevI think this is the first time I've seen the process of delivering right-wing talking points fail. Right wing media is talking about how bad it is to kill someone, but right wing followers are pushing back and saying they have no sympathy. reply DonHopkins 11 hours agorootparentprevnext [5 more] [flagged] theoreticalmal 9 hours agorootparentCome on dude reply jkolio 5 hours agorootparentIt's a fair comparison. Daniel Penney too. The main difference between the four parties is who killed people who'd killed others, and who killed people who hadn't actually done anything. reply DonHopkins 4 hours agorootparentAnd the right wing also platforms, defends, and worships George Zimmerman, who murdered Trayvon Martin in cold blood, paints confederate battle flags, and told the manager who intervened in a violent bar incident he started that \"I didn't know you were a n*gger lover\". reply DonHopkins 4 hours agorootparentprevThat offends you??! Then explain why you like racism better than health care, and think platforming and worshipping Kyle Rittenhouse is justified? The right wing are so thin skinned and hypocritical and allergic to facts, sheez. Luigi used a gun to murder just like Rittenhouse, so why aren't you whining about his second amendment rights being violated and 3d printed gun being confiscated by the cops? He didn't even eat anyone's dogs or cats, just some McDonald's hash browns. Get it together dude. You seem irrationally angry to the point of defending blatant hypocrisy and racism. Why does my criticism of it personally hurt your feelings, hmm? Go play Kyle Rittenhouse's Turkey Shoot game about shooting journalists to blow off some steam. reply wil421 8 hours agorootparentprevThe opioid epidemic has taken a lot of kids I went to High School with. Sorry to hear about your mom. reply haltingproblem 15 hours agorootparentprevI am so sorry to hear what happened to your Mom. This is a slap on the wrist to those who suffered and to those who loved them. How do companies like McKinsey get away with this? reply davidw 14 hours agorootparent> How do companies like McKinsey get away with this? Money. Any other questions? reply hooli_gan 11 hours agorootparentWhy doesnt money work for Kim Dotcom? reply oefrha 10 hours agorootparentKim Dotcom’s enemies (the entire Hollywood, among others) are more deep pocketed than him. Purdue Pharma and McKinsey’s enemies are nobodies. reply onlypassingthru 11 hours agorootparentprevThe fines are the negotiated outcome after you have directed prior sums through the right lobbyists and law firms. reply maeil 8 hours agorootparentprevHe aggrieved the rich. This opioid crisis has largely hit the poor. It's like asking why money didn't work for Bernie Madoff but it has worked for Jake Paul and other crypto scammers. Bernie stole from the rich. reply Moru 8 hours agorootparentNever bite the hand that feeds you reply wesselbindt 9 hours agorootparentprevBecause of more money reply Cumpiler69 8 hours agorootparentMoney alone won't buy your entry inside the elite circles of the people with real influence. Joe Biden just pardoned his son from crimes that would have gotten you and me in jail already. Similarly, your Clintons, Bushs, Blairs, Bidens, Trumps, none of them or their friends and family will ever see a day in jail no matter their crimes. That's influence money alone can't buy. Those are the 1% of the 1%. They can kill or pardon people, start and end wars without answering to anyone. Kim Dotcom is a nobody compared or those guys. reply snozolli 5 hours agorootparentJoe Biden just pardoned his son from crimes that would have gotten you and me in jail already. The only crime there is evidence he committed is never prosecuted against regular people, so it's the exact opposite of what you claim. reply medion 11 hours agorootparentprevI don’t think he actually has the kind of money to be as slippery as, say, Trump, McKinsey, etc. reply bravetraveler 10 hours agorootparentprevOld vs new reply hiddencost 11 hours agorootparentprevNot enough of it, not hooked into the right systems. It works for Elon Musk because he has a lot more and because he controls critical piece of infrastructure (starlink, SpaceX) that the defense industry needs. reply jkolio 4 hours agorootparentKim also subtly represents a flavor of (classical) liberal populism that is at odds with the neoliberal empire-making much of the ultra-rich engage in. Both make the bulk of their money by exploiting resources that they have a dubious claim to (from a humanistic perspective), but the people that the latter tend to exploit were instead the beneficiaries of his exploitation. Anyone who flips the script like that is going to find themselves in the crosshairs, because it seeds dangerous ideas about what the average person deserves in the way of dignity and material/cultural goods. He's also not old money or especially supportive of old money; he's just some script kiddy who scammed his way to the top on the back of the kind of confidence that tends to only come when you're built like an NFL lineman but can also read documentation. The seethe is easy to understand. reply ghundur 11 hours agorootparentprevnext [2 more] [flagged] jkolio 4 hours agorootparentI think it's a bit much to say that there's no advantage to being German, either in today's world or historically. reply maeil 8 hours agorootparentprev> How do companies like McKinsey get away with this? Because of judiciary, regulatory and congressional capture, of course. This means you it's gotten away with unless someone like Luigi martyrs themselves. reply NetOpWibby 13 hours agorootparentprevJFC damn! My condolences. reply isoprophlex 11 hours agorootparentprevnext [2 more] [flagged] refulgentis 11 hours agorootparentThat's probably not a direct quote, so I wouldn't go on the record with that direct response. Uncouth reply RicoElectrico 8 hours agoparentprevExactly, if anyone is shocked at what happened to that insurance CEO, there is a reason. Elites never face personal consequences beyond fines, maybe expect when they defraud investors. reply ryandrake 3 hours agorootparentAnd in this case, as is almost always the case, the \"elites\" are not even paying the fine. The Company is. No human being inside the company who made any of the relevant decisions and did any of the wrongdoing will suffer in any way, or have to pay anything. If you want to kill people and get away with it, just form a corporation and have your CxO and SVP staff make decisions that kill people. reply gruez 1 hour agorootparent>If you want to kill people and get away with it, just form a corporation and have your CxO and SVP staff make decisions that kill people. Note this only works for indirect deaths. If you form a corporation and then order a hit on someone, that's still illegal and you'll still go to jail. If you form a corporation, build a coal power plant that follows all regulations, and the particulate pollution sends a few hundred people to their early deaths that's fine. reply ekianjo 8 hours agoparentprevAlso I fail to understand why doctors who prescribed opoids are getting away with it. It's well documented by now that many of them were getting bribes, and could clearly see that their patients were becoming addicted which went against the claims that the said opoids were not addictive. Responsibility is not just on the manufacturer and consultants' side... reply mschuster91 5 hours agoparentprevOn the other hand a lot of drug abuse among the homeless is self-medication because of the stress associated with living on the streets or due to untreated mental health issues. As long as housing and mental health remains an open issue, personally I'd rather have them consume stuff made by an actual pharmaceutical company at pharmaceutical grade instead of completely unregulated dark market stuff that can have absolutely wild (and deadly!) swings in dosage, even from the same batch. reply spenczar5 15 hours agoparentprevI still don’t think it’s enough, but let’s be clear. They are facing criminal charges and jail time. See the DOJ press release: https://www.justice.gov/opa/pr/justice-department-announces-... > Today’s resolution marks the first time a management consulting firm has been held criminally responsible for advice resulting in the commission of a crime by a client and reflects the Justice Department’s ongoing efforts to hold actors accountable for their roles in the opioid crisis. The resolution is also the largest civil recovery for such conduct. > Additionally, a former McKinsey senior partner who worked on Purdue matters has been charged with obstruction of justice in federal court in Abingdon, Virginia. Martin E. Elling, 60, a U.S. citizen currently residing in Bangkok, Thailand, has been charged with one count of knowingly destroying records, documents and tangible objects with the intent to impede, obstruct and influence the investigation and proper administration of a matter within the jurisdiction of the Justice Department. Elling has agreed to plead guilty and is expected to appear in federal court in Abingdon to enter his plea and for sentencing at later dates. … > Elling faces a maximum penalty of 20 years in prison, three years of supervised release and a fine up to $250,000 for the obstruction of justice charge reply genocidicbunny 14 hours agorootparentIf you or I killed a half a million people, we wouldn't be facing 20 years in prison. We'd be lucky to not be facing a firing squad or a noose. All I ask is that the leadership of McKinsey be treated to that same standard. Let their golden parachutes be literal. reply duped 13 hours agorootparentThe only way to kill 500,000 people practically is to do it by the letter of the law. Murder (especially for money) doesn't scale without being a state or quasi state actor, or something on that tier. reply black_puppydog 13 hours agorootparentGerman speaking here. Last I checked, the Nuremberg trials weren't settled. reply vkou 10 hours agorootparentThe Nuremberg trials were a slap on the wrist compared to what the collective perpetrators, beneficiaries, and active agents of the war and the associated genocide deserved. The broader cultural impact of them (and of the war guilt) imposed on Germany landed fairly well, though. Unfortunately, it is possible that it might have landed less well if the punishments actually fit the crimes. Observe and contrast it to Japan's take on its war guilt, and its less-than-enthusiastic attitude towards taking responsibility. reply maeil 8 hours agorootparentprevNot sure mate, Covid did 6+ million. reply tivert 11 hours agorootparentprev> If you or I killed a half a million people, we wouldn't be facing 20 years in prison. We'd be lucky to not be facing a firing squad or a noose. Yeah, Martin Elling made 2 million in political donations over the years: https://www.businessinsider.com/mckinsey-company-oxycontin-d... > During the past two decades, Elling has spread nearly $2 million among dozens of federal-level political committees, almost all Democratic. The political committees of President Joe Biden and dozens of US Senate and House candidates have benefited from Elling's contributions. reply teamspirit 10 hours agorootparentUntil we get money out of politics, we’re fucked. reply ternnoburn 14 hours agorootparentprevThey aren't facing prison for this, they are facing prison for trying to cover this up. That's a subtle but important difference. reply wesselbindt 8 hours agorootparentprevThe prosecution of Elling has the same vibe as that of Calley [1] after the vietnam war, and that of the small group of soldiers involved in the Mahmudiyah rape [2] during the second gulf war. Viewed in isolation, the atrocities committed by these men deserve punishment. But in the bigger picture, the function these trials serve is for the institution in charge to be able to say \"see? We do hold ourselves accountable\" even though the vast majority of war crimes went uninvestigated and unpunished. More heads, and more important heads, should roll. Not just that of one fall guy. Tens of thousands of deaths every year, and even more lives ruined. But we all know what side the US government is on, so I'm not holding my breath. [1] https://en.m.wikipedia.org/wiki/William_Calley [2] https://en.m.wikipedia.org/wiki/Mahmudiyah_rape_and_killings reply newswasboring 13 hours agorootparentprevLets talk when one of them actually goes to jail. These sham trials are dime a dozen. reply refurb 12 hours agoparentprevnext [3 more] [flagged] BSDobelix 8 hours agorootparentYou are not wrong here, capitalism is the rule to make as much money as possible (be it by selling legal drugs, weapons, food, gambling, insurance). The role of a state and it's laws is to control and limit these companies. A lot of people think it's good to assassinate the CEO of an insurance company, but then I ask, where are the checks and balances, where is the state? If you have to have insurance, the state has to make rules where it's almost impossible for the insurance company not to pay the necessary actions (like in Europe). With McKinsey...what did the FDA do wrong here would be my first question. Don't hate the companies, criticise the state (who is the responsible blob to keep a society healthy). reply refurb 4 hours agorootparent> If you have to have insurance, the state has to make rules where it's almost impossible for the insurance company not to pay the necessary actions (like in Europe). Exactly. Capitalism without rules ends up with situations that we would like to avoid as a society. Thus the government should step in create guard rails and enforce them. The government, through the FDA and DEA, played a large role in the huge increase in the abuse of Oxycontin during the 90's. https://pmc.ncbi.nlm.nih.gov/articles/PMC2622774/ When OxyContin entered the market in 1996, the FDA approved its original label, which stated that iatrogenic addiction was “very rare” if opioids were legitimately used in the management of pain. In July 2001, to reflect the available scientific evidence, the label was modified to state that data were not available for establishing the true incidence of addiction in chronic-pain patients. The 2001 labeling also deleted the original statement that the delayed absorption of OxyContin was believed to reduce the abuse liability of the drug.19 reply jkolio 5 hours agoparentprevIt makes the incredulity over the recent unpleasantness all the more... something. What world do you have to live in NOT to see the rationale? People have set themselves on fire over causes they felt passionately about, to get essentially no attention from the media. Hurting powerful people appears to many the only remaining avenue. Even that seems less impactful than the gleeful memes that followed. The elite are having their \"Okay Boomer\" moment and they really don't like it. reply rajup 16 hours agoparentprev> The rich and powerful once again are allowed to buy their freedom. Well... have you seen the news lately? reply dartos 15 hours agorootparentOr… ever? reply ternnoburn 14 hours agorootparentThe rich and powerful are pretty famous for not saving the consequences of their actions, I'm not sure what you are implying.... reply TheOtherHobbes 9 hours agorootparentHealth insurance and some elements of healthcare are literally farming human illness and death for cash. Opioids are just the most obvious and egregious example of how the system is abusively hostile. reply dartos 6 hours agorootparentprevYeah, that fact is evident if you look at the news… ever… Hunter Biden pardoned, Trump’s convictions not resulting in punishment, high ranking executives getting bonuses for layoffs, etc… reply datavirtue 14 hours agorootparentprevBuy, borrow, die. reply gonzobonzo 14 hours agoparentprev> A slap on the wrist. After a half million Americans have died from a crisis they helped kickstart, they should be facing criminal charges and jail time. I keep reading people who say, over and over again, that the war on drugs is a failure and that it's a mistake to try criminally prosecute suppliers and send them to prison. People will always find a way to get the drugs if they want them, we're told. But then I see the same people turn around that McKinsey is responsible for millions of deaths from the opioid crisis, and the execs involved should be held criminally responsible. It's hard to reconcile the calls for criminal prosecution against McKinsey execs with the argument that drugs should be legalized and that we shouldn't go after other suppliers of drugs. reply krispyfi 14 hours agorootparentThe shady business practices of McKinsey and Purdue are responsible for getting a lot of people dependent on opioids, but the overdose deaths skyrocketed once doctors were forced to cut patients off of their prescriptions and into the fentanyl-ridden black market due to pressure from DEA. Drug War propaganda has convinced us that addiction is as bad as death, but personally, I would rather live a long, happy and productive life dependent on cheap, legal opioids, like William Stewart Halsted, than die as a casualty of the War on Drugs. reply remarkEon 10 hours agorootparent>dependent on cheap, legal opioids Life long customer. reply oefrha 10 hours agorootparentprev> rather live a long, happy and productive life dependent on cheap, legal opioids That’s BS. OxyContin addicts tend to experience withdrawal symptoms before the recommended 12 hours is up, they also develop tolerance, so they end up requiring larger and larger dosage with increasing frequency. You’re not going to sustainably live a long, happy and productive life even if you have a cheap, steady, relatively clean supply of it. reply toyg 9 hours agorootparentIsn't that the same for coffee, though? reply bdangubic 18 minutes agorootparentI am waiting (for yeeeears now) for someone to file a lawsuit against Starbucks… if McDonald’s was forced the pay $$ for coffee being too hot prompting every cup in usage in America where hot content is poured to come with a disclaimer, no disclaimer is shown anywhere regarding addictive nature of coffee… all it will take is someone who spends like $3k/year on coffee at Starbucks to convince some hotshot lawyer to start a lawsuit. Easier rags-to-richer story for sure (provided plaintiff is “rags” :) ) reply jkolio 3 hours agorootparentprevIt is. The coffee supply chain and economic exploitation of caffeine dependency are considered locked-down enough to tolerate, though (as with alcohol). The problem with many illegal drugs isn't their physiological effects so much as it is who benefits economically from sales, sitting somewhere between \"national security threat\" and \"big pharma not being able to take their cut\". reply kjkjadksj 55 minutes agorootparentprevYou don’t nod off in a ball and lose circulation in your extremities on coffee. reply bdangubic 16 minutes agorootparentStarbucks will let you order 30 shot espresso machiato (trust me, I know this…) and if consumed you may experience some circulation issues :) reply oefrha 8 hours agorootparentprevFew coffee addicts become zombies like opioid addicts, with or without coffee. reply TheOtherHobbes 9 hours agorootparentprevCaffeine and sugar are also addictive drugs. Caffeine significantly increases the risk of a heart attack. Refined sugar has numerous slow-motion-car-crash health effects, from tooth damage to obesity to diabetes. Both would be heavily regulated if they were new prescription medications. reply prisenco 14 hours agorootparentprevLegalization was popular for weed because weed is relatively benign but decriminalization is what's needed for harder drugs. People get these mixed up and use them interchangeably but they're very different. There will (and should) never be heroin shops that look like Apple stores like there are for weed. Decrim can be for production, distribution and possession but people generally use it to mean possession. That means that possession of amounts for personal use are not a criminal matter, which makes sense if we see it as an addiction that needs to be treated. In that scenario, production and distribution can be (and often are) illegal. There are other nuances in how to handle decriminalization in terms of social services offered and how to disrupt demand. reply kjkjadksj 53 minutes agorootparentHard drugs are already effectively decriminalized in CA. When I see cops literally turn the other way to not have to see someone smoke a rock and have to write them a ticket thats how you know. I can’t say that this policy has lead to anyone getting help. If anything it enables people to slip further into the abyss once they come here from places that would otherwise prosecute that behavior when its done in public in the open like that. reply genocidicbunny 14 hours agorootparentprevI'm not sure most people are against going after the suppliers, even if they support decriminalization. Decriminalization should mean that users are not prosecuted for simply using drugs, but those participating in the manufacture and distribution are still held responsible. reply gonzobonzo 14 hours agorootparent> I'm not sure most people are against going after the suppliers I see the claim made often, it even commonly pops up on HN. The claim is that the War on Drugs is a failure, because any prohibition efforts are doomed. Laws against a substance merely push it into the criminal sector and don't actually disrupt the supply. So the only outcome is that we get more crime and suffering, but the amount of people using the drug doesn't change. We saw a similarly argument often used when marijuana legalization was being discussed - legalization wouldn't actually impact the number of people who used the drugs, because prohibition laws don't stop people from acquiring a substance. Naturally, the validity of marijuana legalization goes well beyond it's impact on the number of users, but there were many claims that it wouldn't impact the number of users. Of course, one can make the argument that the War on Drugs is a good thing but that it's implementation has often been wrong (for instance, that there should be more effort made on going after suppliers rather than users). But it's very common to see people claim that any attempts at prohibition are doomed to failure and cause more harm with little to no benefit. Edit: To give an example, here's a HN discussion where most of the people are in favor of fully legalizing all drugs: https://news.ycombinator.com/item?id=10424099 reply bdangubic 22 minutes agorootparentattempts against prohibition are doomed to failure because they go against human nature and going against human nature will (almost) always fail. tell teenagers they can’t drink till they are 18… well… tell a kid she/he can’t… well… humans will do drugs. you have to start there. no matter what you try and “prohibit” this is your ground zero. from here you can decide which policy has the greatest chance of “success” once you define what success means to you. reply kjkjadksj 50 minutes agorootparentprevDecriminalization still means you get prosecuted for using in public. You can’t smoke weed in public or even a cigarette in most public places nor are you allowed to drink in public. Shooting dope in a park will still be illegal. reply toyg 9 hours agorootparentprevThe difference is consent, particularly at the very beginning. Patients typically have to trust a doctor; the definition of consent in those circumstances is very strict, side effects have to be declared etc etc. Any abuse of that consent, like in this case, must be treated like a crime. Whereas when it comes to individuals deciding on their own to experience something, it's all about personal responsibility. reply gonzobonzo 6 hours agorootparent> Patients typically have to trust a doctor; the definition of consent in those circumstances is very strict, side effects have to be declared etc etc. Any abuse of that consent, like in this case, must be treated like a crime. > Whereas when it comes to individuals deciding on their own to experience something, it's all about personal responsibility. The problem with this framing (and some of the other comments have used this framing as well) is acting as if other drugs would not have the same issues as opioids. But if anything, the opioid epidemic has shown the opposite to be the case - people irresponsibly push drugs onto people even when access is limited to a group like doctors who are supposed to be well educated and discerning. reply rqtwteye 14 hours agorootparentprevIt’s consistent. Go after the big guys, suppliers and other enablers. Not after the individual addict. reply jgtrosh 9 hours agorootparentprevTo add to other comments, this can also be partly justified by the fact that blue collar crime is the only kind of crime for which prevalence is even partly inversely correlated with the increase in severity in punishment. reply throwaway2037 3 hours agorootparent> blue collar crime I never saw this term before. Do you mean all crime except white collar crime? reply jgtrosh 1 hour agorootparentI meant white collar crime reply pxmpxm 14 hours agorootparentprevIt's consistent in the sense that people love any angle that removes agency and shifts all responsibility to ephemeral constructs like \"big pharma\" or \"war on drugs\". Public flaggelation is not without consequence, however - don't be shocked when you can't find a pharmacy willing to fill a Percocet rx after your next surgery. reply dns_snek 10 hours agorootparentprevPeople involved in the opioid crisis pushed unnecessary and extremely addictive drugs onto unsuspecting people who trusted them with their care, and it was all done through very intentional deception, lies about how these drugs weren't addictive when they absolutely knew that they were, and through corruption by offering doctors kickbacks for getting people hooked on them. Ignoring everything else, do you really fail to see how bribing doctor to lie to people about the nature of highly addictive drugs is different from a consensual transaction between two adults? reply refulgentis 11 hours agorootparentprevIt's not the same people reply madaxe_again 11 hours agorootparentprevSo what, you think a kid who deals a single gram of cannabis should spend the rest of their lives in prison? How is that just? reply croes 12 hours agoprevMcKinsey is also responsible for the delay, deny, defend tactic of health insurance companies. https://www.trialguides.com/products/from-good-hands-to-boxi... reply sc68cal 17 hours agoprevMcKinsey makes something like 10 billion annually in revenue. This is a slap on the wrist. People need to be held accountable for these misdeeds. reply passwordoops 16 hours agoparentCriminal charges for execs and board members reply raincom 13 hours agorootparentProsecutors have to use RICO to charge execs and board members criminally. This is not going to happen, as long as the revolving door (or a sort of collusion between prosecutors and executives) exists. reply jncfhnb 4 hours agorootparentprevIt’s a partnership. Ultimately the line of people involved in any particular job is extremely short. Unlike in a tech company where the whole company is building a product, consulting companies are thousands of teams doing projects in a small isolated bubble. reply bdangubic 15 hours agorootparentprevhigher chance of me marrying gisele than that ever happening :) reply gruez 1 hour agoparentprevThis line of thinking makes no sense. Why should we care about what their global revenue is? The only thing that matters is how much money they made from opioid consulting. If Amazon did a bad in a small part of their company (eg. they violated labor laws in the state of Washington), why should their punishment be compared to their global revenue? reply kjkjadksj 48 minutes agorootparentBecause otherwise someone clever could play a shell game where every org does something bad but its split up in such a way to diffuse responsibility across the organization and minimize fines, especially since not all bad things will be caught and fined simultaneously. reply gruez 23 minutes agorootparent>Because otherwise someone clever could play a shell game where every org does something bad but its split up in such a way to diffuse responsibility across the organization and minimize fines, \"We can't figure out who to blame because responsibility is so diffuse, so let's make everyone 100% responsible\" makes as much sense as \"we can't figure out who the murderers are so let's lock up anyone who vaguely looks like a gangster\"[1]. More to the point, it's unclear whether this actually applies in this case. At the very least, you can confine responsibility to the consulting engagements they did with opioid producers. The value McKinsey & Company provides in their management consulting engagements might be questionable, but it's a stretch to claim their engagements with some random fortune 500 (non-pharma) company contributed to the opioid crisis, or need to be punished. [1] https://en.wikipedia.org/wiki/Salvadoran_gang_crackdown reply potamic 10 hours agoparentprevThe world needs to adopt some sort of a punitive equivalence principle. Humanity overall has made a lot of progress towards enshrining human rights, but a lack of punitive equivalence is a gaping hole in the right to equality before law. How are two people treated equally if they face different punitive effects for the same act? reply swasheck 17 hours agoparentprevyep. would rather it be a multiple of revenues from their role instead of a percentage. reply aoanevdus 12 hours agorootparentThe parent comment referred to McKinsey’s entire revenue, not to their revenue from their work relating to Opioids specifically. reply DAGdug 16 hours agorootparentprevNot to be pedantic, but percentages can exceed 100. reply Jgrubb 5 hours agorootparentOwn your pedantry, comrade. Be neither bashful nor apologetic. reply niceice 15 hours agoparentprevThat's more than I would have thought. What generates that? How much of it is consulting? reply rrr_oh_man 12 hours agorootparentIt's almost certainly almost all fees charged to clients for consulting projects. Let's assume 2,000 working hours per year, 80% utilization at $150/hr, and 40,000 employees (worldwide) — that's $9.6B. reply bmitc 10 hours agorootparentWhat companies use consultants and how? In all my years, I have never seen a consultant or a need for one, so I have a tough time understanding how they make any money, much less a lot of it. reply jncfhnb 4 hours agorootparentBasically every single large organization inevitably becomes paralyzed by the inability to do anything different from the status quo. When you hear the common complaint that “consultants just tell leadership to do what I was telling them to do for decades” that’s often accurate; because consultants listen to you and have the executive mandate to actually get things done. If you’ve been saying something for ten years and it hasn’t happened, you _need_ a different tool to effect change. Consultants, for better or for worse, are a decent tool for making that happen. reply rrr_oh_man 8 hours agorootparentprev3 main use cases from my experience: - Executives want to do cross-functional changes. (E.g., introduce new ERP software) - External ruthless assessment of head count and subsequent slashing. - Body leasing. (quasi-employees that are not on the books as employees) Mostly in medium-sized and larger orgs where there’s too much cruft. reply 1123581321 3 hours agorootparentprevHaven’t you ever wanted research, advice or work done and your coworkers or employees were busy or not quite up to it? White glove consulting is just well-packaged, expensive help. reply p4ul 15 hours agoprevWith all the overdose deaths and the lives ruined by opioids, I guess I'm a little bit surprised this didn't result in criminal charges for someone at McKinsey. Surely there must be some emails or texts that are inculpating. reply rqtwteye 14 hours agoparentAs long as you hide behind a corporation, you can do pretty much whatever you want. Worst case, the company will pay a nominal fine as cost of doing business. And maybe somebody gets fired with a large severance. reply genocidicbunny 14 hours agorootparentWell, until a good looking 20-something year old man puts a couple bullets in your chest outside an investor meeting. reply Sabinus 11 hours agorootparentBut then someone has to sacrifice their life to create some justice. Much better for it to be a part of the system. Jail for criminal executives. reply kjkjadksj 44 minutes agorootparentAs killings get normalized they will be more difficult to be caught. Less point blank pistoling, more IEDs and long range rifles is our future imo. The veil has been pierced for at least some people. reply bamboozled 13 hours agorootparentprevNot going to be \"the norm\" nor will there be an endless stream of vigilantes available to deter this level of sociopathy. Assassinations are obviously not the way we want society to work either, violence to settle grievances etc, no good. The only way I think we could hope to stem the tide of this level of corruption is through education. I believe it's really in the ruling classes interest to keep as people as dumb as possible though, so I don't think it will happen. Not sure what else the alternatives could be. Societal collapse? reply caminante 13 hours agoparentprevDid you intentionally not read the article? > According to Kavanaugh, former McKinsey senior partner Martin Elling \"personally deleted various Purdue related electronic materials from his McKinsey laptop with the intent to obstruct future investigations.\" DOJ officials said Elling has agreed to plead guilty to a felony count of obstruction of justice for destroying those company records. You might've been too busy trying to force \"inculpating.\" reply newswasboring 12 hours agorootparentThose are not charges for the mass murder they have supported. They are charges for not following procedure. There is a huge difference. reply noisy_boy 15 hours agoprevUntil you have serious bonus clawbacks for every such case, it is just cost of doing business. Just increasing the fines won't do much, they will just fire more people citing costs and the market will applaud that with rising stock price. reply hsbshs 14 hours agoparentIts complex cause you cant really find one person to blame. What no one really says is we are struggling with complexity overload. And what complicates it is all the people's wealth and status accumulation falsely signals control. When they really have less and less control the more complex the system gets. When you look at pentagon leaders and afg/iraq or Wall St CEOs and 2008 gfc or the Pope and the peado army or linux kernel maintainers and serious security bugs found everyday the commonality is Complexity. No one is fit the more complex things gets. So even though we get Tahrir Square once in a while, decade later we still have Generals in charge. Scaling has become easy but scaling without unintended costs and consequences the past few decades have shown is complex. reply throwaway562if1 11 hours agorootparentIt's trivial to find who to blame - just follow the money. Hit the investors with sentences proportional to their stake of ownership, and just like magic, executives who enable criminal behavior will become rather less popular and internal oversight much more so. Of course this will never happen, since the lack of culpability is the point. reply theoreticalmal 9 hours agorootparentI’d really rather not jail people who didn’t do anything illegal reply sumedh 8 hours agorootparentAre they getting huge bonuses or dividends? reply badpun 8 hours agorootparentJailing people just for having a stake in a company that did something illegal could kill the economy. People would be affraid to invest in companies, and move money to simple things like real estate (or to foreign investments). reply sumedh 7 hours agorootparent> to simple things like real estate (or to foreign investments) Are you saying that is not happening now? reply gruez 1 hour agorootparentYou want to make it worse? reply mattkevan 7 hours agorootparentprevIf the companies they’re investing in aren’t doing anything dodgy they’ve got nothing to worry about. reply badpun 2 hours agorootparentHow would they know that though? It's a huge personal risk that can be alleviated simply by investing in anything else in the world besides US companies. reply callc 13 hours agorootparentprevSure, attempting to find one or a handful of bad actors to blame may not yield a sufficient result that could convince the public that justice was served appropriately. Yet, the complexity of how to blame should not absolve the crime. How should society collectively administer punishment to a large complex network of individuals with varying degrees of power and involvement? Reparations and the Nuremberg Trials / Tokyo Trial come to mind for WWII Axis powers. 500k deaths from opiods (taken from top comment) is comparable to the casualties from WWII, within a soberingly low amount of significant digits. Japan was occupied and could not have a military for some time. Curious if there are other ideas of how to tackle punishment of businesses (not Luigi'ing it). reply hsbshs 10 hours agorootparentWell there is the Chinese and Russian example. The power just gets misused and creates it own issues. People want simple and quick solutions. And they dont like answers they dont want to hear. Specifically about what behavior is rewarded and incentivized. As Veblen pointed out a hundred years ago, the flaw with Marx is not that there are exploiters and the exploited, its that there is the Leisure class and everyone else who given a choice wants that lifestyle. The entire media and edu system promote consumption, wealth and status accumulation 24x7. When you are constantly hit with these signals punishing a few people here and there is just for show. reply noisy_boy 11 hours agorootparentprev> Its complex cause you cant really find one person to blame. When the big bucks go to the very top for a successful year, the penalty should also go to the very top when shit hits the fan. When the CEO/CIO/COO's bonuses are on the hook, I suspect you will suddenly see a great urgency/importance being assigned to doing things correctly and greater penalty being levied down the ranks for doing things wrongly. These people had too much carrot, time to balance it out with some stick. reply salawat 12 hours agorootparentprevYou say we can't find anyone responsible as if we haven't settled the question on culpability symbolically since we started leveraging hierarchies. You oversee it. You did it. Start at the top. Move down. Heavy is the head, as they say. reply sitkack 18 hours agoprevhttps://en.wikipedia.org/wiki/Value_of_life They could figure out how to divvy up their 65 life sentences. Why do they get to pay their way out of this? > According to Kavanaugh, former McKinsey senior partner Martin Elling [2] \"personally deleted various Purdue related electronic materials from his McKinsey laptop with the intent to obstruct future investigations.\" Corporate laptops are backed up, with backups offsite. I find it hard to believe that the only copy was on his laptop. From the tweet [2], which has a screenshot of an email presumably sent by Martin Elling, he looks to be directing everyone to start deleting criminal evidence. > McKinsey's payment, which includes $2 million paid to the Virginia Medicaid Fraud Control Unit, settles federal civil and criminal charges against the firm and includes a \"deferred prosecution\" agreement. Under the civil settlement, McKinsey is not admitting liability. A copy of the deferred prosecution agreement was not publicly available at the time of publication. Given the opioid deaths in 2022 alone, McKinsey should be dissolved and the responsible parties serving jail time. Can someone explain how this [3] is presented as a win, when only money has changed hands. They paid a fee for aiding in the deaths of hundreds of thousands of people. Does this ruling now shield them from any criminal repercussions at the state level? [1] https://www.cdc.gov/overdose-prevention/about/understanding-... [2] https://x.com/CoruscaKhaya/status/1676330070472814593 Here is the original document referenced in the tweet, https://www.industrydocuments.ucsf.edu/opioids/docs/#id=zhlp... [3] https://www.justice.gov/opa/pr/justice-department-announces-... *edit, found this https://www.industrydocuments.ucsf.edu/wp-content/uploads/20... which outlines at which times various McKinsey employees directed people to delete evidence. reply mulmen 16 hours agoparent> Corporate laptops are backed up, with backups offsite. I find it hard to believe that the only copy was on his laptop. Not defending anyone and maybe McKinsey is different but I have never had a corporate laptop with built-in backup. I am always left to figure that out on my own. reply sitkack 16 hours agorootparentFrom what I can tell, it looks like they used Box to store the most incriminating stuff. https://www.industrydocuments.ucsf.edu/wp-content/uploads/20... Specifically https://www.industrydocuments.ucsf.edu/opioids/docs/#id=skbm... In an email from: Jeff Smith to: Amir Golan cc: Arnab Ghatak > Amir - going forward it's absolutely essential for the team to only use Box for distribution of documents and all documents have to have appropriate legal disclaimers - at a minimum working draft. Please work with the team to implement ASAP. reply sitkack 16 hours agorootparentSo Arnab \"Arnie\" is facing 20 years [1] for destruction of evidence But Martin Elling (very much his senior) can only get a maximum of 1 year [2] as per the plea deal. > A former senior partner at McKinsey, Martin Elling, has also agreed to plead guilty to obstruction of justice for destroying records related to McKinsey's work for Purdue, according to court papers. He is scheduled to enter his plea on Jan. 10. [1] https://www.globalindiantimes.com/p/mckinsey-opioid-122024 [2] https://www.reuters.com/legal/consulting-firm-mckinsey-pay-6... reply jncfhnb 4 hours agorootparentprevWe use Box to store and share virtually everything, not because it is incriminating, but because sending email attachments is not a secure way to send sensitive data. reply mulmen 16 hours agorootparentprevDistribution of documents is not a system backup. I haven't used Box but if it is a distribution mechanism I suspect it is opt-in, as in you have to choose to distribute a document with it. You could still print or email the document, or use any other service. Box is just the mechanism by policy. The policy wouldn't even apply to documents that aren't distributed. reply malux85 18 hours agoparentprevThey 100% should be put in jail, if fines are the only deterrant then they just become cost-of-business and dont deter anything at all. reply bongodongobob 14 hours agoparentprevI've never worked anywhere that backed up laptops. Onedrive, fileshares, cloud storage, servers, sure. I would not want to try managing backups for devices that aren't guaranteed online 24/7. The odd failed server backup is enough work, now apply that to 2000 laptops. Fuck that, save your shit on our backed up infra. reply freetanga 12 hours agorootparentThey did, or at least Some folders (way before iCloud) During a project, the live documents were on the teams laptops (local encryption). Only key deliverables were uploaded to servers, mostly at the end of the project. Lots of cruft (client emails, unedited data, etc) stayed behind in people’s laptops. Your laptop was stolen? No worries, under 24 hrs you get a new one in your hotel with roughly whenever you left off… PS McK was handing out 3G - 4G PCMIA cards forever (almost 20 y ago), you were only most of the time… reply NetOpWibby 13 hours agoparentprevThis is just disgusting. Money is the root of much evil. reply kevinventullo 17 hours agoparentprevJust remember, it’s never okay for the people to take matters into their own hands. They just need to get out there and vote! Our elected representatives will ensure that justice is served. If they don’t, that just means you didn’t donate enough to the Good Guys. reply yalogin 15 hours agoprevWhat percentage of the revenue was this? The stock price jump alone would many multiple times this fine. reply NetOpWibby 13 hours agoprevNot nearly enough. Make it $650B and if they can't pay, break up the company. reply tiborsaas 7 hours agoparentPayment should not be an option. If people can be executed for a single murder then assisting in starting an epidemic with 640000 casualties (and also serious side effects) should kill the company. Revoke business licenses, seize assets, use it for damage control. \"More than 645,000 people(opens new window) in the United States have died from overdoses involving opioids since the epidemic began\" https://www.fcc.gov/reports-research/maps/connect2health/foc... reply infrawhispers 14 hours agoprevMcKinsey is a deeply unethical company that has skirted meaningful accountability over the last few decades. I highly recommend reading When McKinsey Comes To Town [1] - it really opened my eyes to how hypocritical and self-serving the culture is at the firm. Maybe a small aside..but it’s very interesting how we as a society took very little learnings from the Crack epidemic during the early years of the Opioid Crisis. It is frustrating how people would rather bury their heads into the sand and reaffirm existing biases vs interrogating the contributing factors. [1] https://www.penguinrandomhouse.com/books/634029/when-mckinse... reply ungreased0675 14 hours agoprevWhat is this construct where someone can just pay money to avoid personal accountability for crimes? reply fooker 14 hours agoparentThe money is literally the accountability here. You could have other forms of accountability sure: freedom, life, and so on. For several reasons, we have settled on money as the preferred form unless the responsible party has a good chance of harming others in future. reply ungreased0675 3 hours agorootparentExcept the monetary accountability comes from the company, and the people responsible remain rich and successful. In order to put the brakes on unethical and immoral behavior, personal accountability must be a possibility. As in, you will go to jail if you intentionally hurt others via decisions made at work. reply yard2010 9 hours agorootparentprevThis is stupid because the marginal value of money is nothing when you have enough. So it's simply a get out of jail ticket we give to part of the society. The worst part IMHO. reply dns_snek 7 hours agorootparentprev> For several reasons, we have settled on money as the preferred form unless the responsible party has a good chance of harming others in future. Sorry, but in which universe? The people who're responsible for harming millions almost always get away with a fine that can be brushed away as the cost of doing business, and they almost always reoffend precisely because they never have to face justice. Meanwhile the working class people who haven't harmed anyone regularly get arrested and go to jail for nonviolent offences. If I made $50k a year and killed 1,000 people by poisoning their water supply, do you think I could escape arrest by paying a $1000 fine? Would you feel like that's an appropriate level of accountability if I knew that my actions were killing those people? reply toofy 8 hours agoprevIt’s unforgivable that we treat slow motion murder by certain people as acceptable—deserving of nothing more than a fine. reply LightBug1 7 hours agoprevAnd I bet, for many, when the dust settles, the McKinsey name will still be held in relative high regard, and the opioid affected victims, on the streets, in poverty, will be blamed for ... not pulling themselves together, or as being a drag on society. reply blackeyeblitzar 17 hours agoprevMcKinsey is responsible for a lot of crimes, seemingly. Ultimately they just don't seem like a trustworthy company and I think they've avoided accountability by maintaining political connections (and donations). Another example of their untrustworthy practices - I recall accusations from a few years ago where they assured the US government that they were not doing work for the CCP, but then it turned out that they were (https://www.nbcnews.com/politics/national-security/mckinsey-...). And then earlier this year at a US Senate hearing, it turned out McKinsey has once again been doing dirty work for the CCP by advising a large number of state owned corporations, who are involved in activities like building China's militarized artificial islands: https://youtu.be/tQ5kWfotE8Y reply tdb7893 15 hours agoparentEven amongst management consulting firms McKinsey is known as the unethical one. I know someone who worked for Bain and when I gave him shit for it his answer was always \"hey, at least I don't work at McKinsey\" reply milesskorpen 14 hours agorootparentThey all do basically the same thing. reply DrBenCarson 13 hours agorootparentprevMBB alum here-- Here's the thing: these firms are set up as partnerships meaning each of the partners (but really the senior partners) has their own little world enabled by their equity and voting power. They each have their own spin on the \"values,\" risk tolerance, communication style, \"followers,\" etc. Trying to paint the entire firm with the same brush is naive. Like anything else, there are good and there are bad Plenty of good smart people at each of these firms just trying to do good work and \"make it.\" Then you have the sociopaths willing to trade lives for their own gain who have the benefit of hiding behind brand equity and human shields (aka the other partners) reply portaouflop 7 hours agorootparentI’ll happily pint anyone who works at McKinsey with the same brush. I don’t care what your values are - if you work for McKinsey you are a piece of shit simple as reply sershe 57 minutes agoprevI'm gonna sue Jack Daniels for hitting me with a trunk of a big ol' live oak tree He hurt me this morning with the bright sun light I'm gonna sue Jack Daniels for what he did to my face last night! reply ALittleLight 16 hours agoprevIf the company was not meaningfully involved in selling a dangerous addictive substance falsely marketed that resulted in the deaths of tens of thousands of Americans then they should not face any penalty or fines. On the other hand, if they were, this is on a similar order of magnitude to American losses in World War 2, and their executives should be hung and company ended with shareholders zeroed out. reply sidcool 9 hours agoprevThis won't deter them. But something better than nothing. reply p1dda 11 hours agoprevI suspect McKinsey is responsible for most predatory behaviour related to Big Food, Big Tech and Big Pharma, just waiting for more of these lawsuits to surface. reply cyanydeez 2 hours agoprevCorporations need death sentences. Like the sandy hook parents getting cash for infowars but infowars being allowed to continue its antisocial existence because money is a super fungible commodity with no limits. reply throwaway9120 10 hours agoprevWhy hold McKinsey liable for what Purdue Pharma actually did? Bad advice could have been thrown out by management, but instead, was accepted, and executed on. Shouldn't the blame rest on Purdue directors and the board? reply portaouflop 7 hours agoprevIs there any world crisis where McKinsey wasn’t involved/profited? Most immoral company on the planet smh reply motohagiography 14 hours agoprevThe word \"overdose\" has to be the best PR campaign of all time. it is an addictive poison. reply Rafuino 10 hours agoprevMcK, Bain, and BCG should all be burned to the ground and the ashes scattered to the wind. Hot take, I know. reply myst 11 hours agoprevI am surprised they are allowed to exist. They aren’t doing anything useful anyway. reply notatoad 18 hours agoprevi'm assuming the supreme court will void this one too? reply blastbking 13 hours agoprevpaging luigi reply bamboozled 15 hours agoprev“That should cover it” reply xyst 12 hours agoprevNot enough. Executives and consultants need to be sent to jail and held responsible. For years, the government and court systems have been unable to punish these private corporations. At best, give them a slap on the wrist with these fines. People are tired of this bs. It's no surprise a large majority of the public didn't give 2 shits about a nobody health insurance CEO getting gunned down in the streets but rather unified around the idea of our shitty healthcare system. reply courseofaction 18 hours agoprevnext [4 more] [flagged] bdangubic 18 hours agoparentwhat kind of adjustment and who are adjusters? reply Terr_ 16 hours agorootparentI think it's a reference to the recent killing of that health insurance CEO, where some folks have taken to referring to the killer as an \"adjuster.\" It's a play on words from the profession of insurance/claims adjuster, which is someone who who arrives to determine what happened and what damage the insurance company is liable for. Unlike the normal version, there's a very different twist on what kinds of damage, responsibility, and consequences are involved... reply FireBeyond 17 hours agorootparentprevYou and I destroying evidence when accused of a crime? Tampering, a felony in most states. Send emails to your team and clients that even explicitly says \"We need to eliminate documents and emails about this as the US Attorney has already begun investigating us?\" Oh well, no big deal, just have the company pay a fine. Adjust that, for just one thing. reply ClassyJacket 17 hours agoprevnext [2 more] [flagged] loeg 17 hours agoparentClearly several orders of magnitude fewer humans impacted, if nothing else. reply firebot 10 hours agoprevI think the real crisis is that everyday people can't get pain relief cuz some junkies OD'ed. Wtf? We live in the dumbest possible universe of all possible universes. reply roenxi 18 hours agoprev [–] Left hand. COVID proved that we could establish safety & efficacy of a medical treatment in about 12 months, to the point where as I recall a lot of the manufacturers have a legal exemption from any liability for damage done by vaccines. Right hand. There are these opioids have been around for decades and somehow they reached this huge level of damage. Largely the same cultures of people involved. I still think the authoritarian policies used during COVID were a mistake. The level of compartmentalisation needed to look past scandals like this one and still force people to trust big pharma unconditionally is pretty extreme. People should be allowed to make their own mistakes based on their own flawed judgement, rather than the flawed judgement of the likes of McKinsey & Perdue. It is bad enough when everything is voluntary. reply Retric 17 hours agoparentOpioids were known to be harmful. Purdue attacked the gatekeepers and policy makers not the science. It was mostly a story of what happens when a well funded con artist enters an environment built on trust. Suddenly pain management was viewed as very important by the medical establishment, while mostly paying lip service to all the long term consequences of said actions. After all you can’t actually know how much someone is actually suffering… reply roenxi 17 hours agorootparent> Opioids were known to be harmful. So, hypothetically, if a doctor prescribed me opioids I should be allowed to say I don't want to take them? Even if the manufacturers assure me it is safe, effective and they have lots of evidence of the same. Because to me that seems like a logical conclusion. I think that should be a general policy. People should be able to overrule doctors on the subject of how they are treated. reply pharrington 15 hours agorootparentOpioids don't prevent a virus from multiplying and spreading to other people without their consent either! reply nkrisc 16 hours agorootparentprevAll this time did you think you were under a legal obligation to follow your doctor’s orders? You don’t have to do anything your doctor says. During COVID plenty of people chose to not listen to advice about vaccines and did not get vaccinated (and some did die from COVID for their efforts). reply zmgsabst 16 hours agorootparentYes — they were coerced by the state including having normal freedoms removed, which is what generally defines “legal obligation”. reply threeseed 16 hours agorootparentIf you're talking about legal matters then words are important. No one was ever forced to take a vaccine. Nor were they coerced by the state. reply bdangubic 15 hours agorootparentmeaning like losing a job unless you get a jab, considering that a significant force? reply threeseed 14 hours agorootparentThat is a private company making a decision about their work environment. You don't have the right to demand that they cater to your requirements. reply bdangubic 14 hours agorootparentI work for the government reply Dylan16807 14 hours agorootparentThen they're just an employer to you. They're not acting as rule-maker. It's very different from a legal requirement that applies to all jobs. reply bdangubic 8 hours agorootparentthis would be true… if you lived in fucking china or north korea and someone controller “all jobs” reply Retric 4 hours agorootparentYou have that relationship reversed. If you work for the FBI you can quit at any time and work for a different companies with different rules. You can’t work for a company that gets to ignore minimum wage laws. reply bdangubic 3 hours agorootparentthis all makes sense of course, I am not forced to stay at the FBI. however, I just might: - love what I do and love the team I am on a my mission. - have a career at fbi, not a “job” I am willing to change like underwear - be gs-15 few years away from retirement/pension/… you can technically say this is a “free” country and all that but it is just semantics reply Retric 2 hours agorootparentYou don’t lose a pension when you quit, you simply qualify for fewer years served. A career extends beyond a job means that you can transition to something related outside the FBI. If there some aspect of a job you dislike then quit. reply bdangubic 1 hour agorootparentwe can go glass-half-full-glass-half-empty back and forth ad nausem here for sure :) bottom line though, the then government (which is soon to be now government) went full ballistic on us during COVID times and vaccine mandates affected many lives reply bdangubic 38 minutes agorootparent“only” 98% compliance should tell you all you need to know whether people are “forced” or not… the prospect of losing your job might not be that alarming for HN-average-person but… Retric 58 minutes agorootparentprevOnly some parts of the government “required” their employees to get vaccinated, the entire US government didn’t. Even those bits only hit ~98% compliance. When you volunteer to work for someone you’re agreeing to do what they want or quit, that’s by definition a choice. When many private employers had the same requirements complaining about overreach by the government is misplaced, it’s at most overreach by employers. itsdrewmiller 13 hours agorootparentprevhttps://www.govexec.com/pay-benefits/2023/02/feds-driven-awa... I do not believe you. reply bdangubic 8 hours agorootparentI was not driven away, got jabbed reply dambi0 11 hours agorootparentprevOn what grounds? reply Retric 15 hours agorootparentprevNo. Making hard choices inherently implies options. Vaccines saved well over a million people’s lives at negligible heath impact for the wider population, that’s simply what states are going to do in an epidemic. reply bdangubic 14 hours agorootparentI can tell if you took a red pill or a blue pill :) reply Retric 13 hours agorootparentNeither reply zmgsabst 9 hours agorootparentprevThey were coerced by the state: they issued mandates which required vaccination to engage in normal rights. That’s the literal definition of coercion. I think it’s interesting how many people deny that — almost as if you know what was done is morally repugnant. reply nkrisc 7 hours agorootparentViruses are not concerned with ethics and morals. reply cruffle_duffle 36 minutes agorootparent> Viruses are not concerned with ethics and morals. Good thing we aren’t viruses and have intelligence and the ability to step back and think through our actions. There is more to life than exactly one specific myopic focus on a virus. It takes an incredible amount of privilege to believe that the only problem humans can solve for is an exactly one single virus to the exclusion of literally everything else. Massive, massive amounts of privilege to think that way, in fact. reply zmgsabst 6 hours agorootparentprevOkay — but we have more concerns than a single virus. It’s entirely possible to engage in net-negative behaviors because you fixate on a singular goal — a human version of the “paperclip optimizer”: we became “COVID optimizers” and produced suboptimal results. Ethics and morals are time-honed heuristics to avoid those failures. “Freedom” is the heuristic that distributed risk assessment and planning out perform centralized versions — and we forgot that in our panic. reply nkrisc 5 hours agorootparentAnd some day there may be another epidemic for which we optimize for freedom, and after which there will be no human left to enjoy the freedom (or those left will be too busy surviving to worry about things such as “freedom”). It is fortunate that the COVID-19 pandemic did not rise to that level. Maybe it couldn’t have, but that’s easier to say with the benefit of hindsight. Or some other catastrophe that threatens us. My point is that natural things do not care for artificial concepts such as “freedoms” and “rights” and “morality”. reply cruffle_duffle 33 minutes agorootparent> Maybe it couldn’t have, but that’s easier to say with the benefit of hindsight. We knew within two weeks of most major shutdowns that Covid wasn’t even close to as bad as predicted by the Imperial College. Society decided to completely ignore that data and instead doubled down on its hysteria for more than three years. reply zmgsabst 5 hours agorootparentprevYou say that as if the recommendations for freedom weren’t based on the initial medical data. But they were and you’re inventing a false dichotomy whereby we had to engage in totalitarianism contrary to evidence of COVID’s deadliness or some hypothetical infinite bad might have happened. That’s nothing but bullshit, from somebody who was wrong. reply pests 16 hours agorootparentprevYet here I am, with all my freedoms intact, and still not vaccinated. reply Retric 17 hours agorootparentprevNothing hypothetical about that, it’s generally how US healthcare works barring people being declared mentally incompetent, court ordered treatment, etc. To address the seeming contradiction. Vaccination was never imposed by the healthcare system on patients during COVID, it was required by cruse ships, schools, and yes hospitals for staff etc. reply zmgsabst 16 hours agorootparentThose organizations were doing so by government mandate — at the direction of government healthcare agencies. They didn’t invent those policies on their own. That’s “imposing” and it speaks to the lack of ethics in the healthcare system they joined in coercing medical treatments rather than refusing to perform treatments people were only accepting under duress. reply Retric 15 hours agorootparentThe alternative of continuing isolation was available though impractical for many. The ethics around vaccination is it saved well over 1 million US lives without direct force, that’s a clear win by any reasonable ethical system. Being unable to be an unvaccinated healthcare worker is little different than requiring people wash hands, or preventing them from walking around shooting patients. PS: Actual estimates for lives saved is around 3 million with a fair bit of uncertainty and some wiggle room in terms of definitions. Over 1 million is basically incontrovertible, but in a wider context you need to look at the spike in cancer deaths due to an overworked healthcare system and extrapolate not just consider the individuals who get infected. reply cruffle_duffle 31 minutes agorootparent> The alternative of continuing isolation was available though impractical for many. There was, in fact, many alternatives beyond “isolation”. But thanks to society’s hysterical myopic focus and constant propaganda and suppression of information most people were not allowed to discuss them out loud. How anybody could continue to believe what society did in response to Covid was not only okay but was the only option is absolutely wild to me. It’s a testament to the massive amount of propaganda cranked out by various governments. Their belief is not just wrong it’s insulting to the people who watched the nonsense unfold. reply zmgsabst 9 hours agorootparentprevCOVID vaccines weren’t believed to be QALY positive for a substantial period of the mandates, according to actuarial estimates. The vaccines hospitalized at a rate higher than they prevented hospitalizations and the mandates applied to groups who were at virtually no risk. > The ethics around vaccination is it saved well over 1 million US lives without direct force, that’s a clear win by any reasonable ethical system. Except that force was used, to restrict the rights of those who didn’t comply with mandates. And numerous atrocities have been conducted by exactly that utilitarian mindset. You can claim you needed to violate Nuremberg, but the data doesn’t support that and I’ll continue to think you’re morally defective. reply marcosdumay 3 hours agorootparent> The vaccines hospitalized at a rate higher than they prevented hospitalizations The vaccines emptied the hospitals. Literally. Two weeks after the vaccination (with any of the western trio, or the one China exported), the odds of people being hospitalized felt more than 90% every time somebody measured, everywhere. The Chinese one was the \"bad\" one, with the odds falling by not much more than 90%. The other ones were much better. reply Retric 5 hours agorootparentprev> weren’t beloved to be QALY positive for a substantial period of the mandates, False. > Except that force was used. Nobody was forcefully vaccinated, and in fact 10’s of millions of Americans never got vaccinated and a vastly larger percentage of them died. The numbers aren’t even vaguely comparable. reply roenxi 16 hours agorootparentprevWhich wasn't justified and should probably be an illegal requirement on privacy grounds. It doesn't make a difference if people doing work were vaccinated or not. It turns out to have had little in-practice effect on transmission, so the only important question is whether the passengers on things like a cruise were vaccinated themselves. They were evidence-free policies. We had a great natural case study in Australia of COVID through a vaccinated population. Everyone caught it over the course of a month, the vaccines did basically nothing to stop the spread. They were pretty much only useful on an individual level which means there was never a requirement for any coercive measures. reply Retric 13 hours agorootparent> It turns out to have had little in-practice effect on transmission When you look at killing thousands of people as a minor consequence you may want to rethink your priorities. reply roenxi 12 hours agorootparent1) Little as in \"0, but maybe someone wants to quibble that technically it did something so I'll hedge\". As far as I can tell literally everyone I know caught COVID, so it is fair to say the vaccine had no impact on transmission. Raising the obvious question of why it matters where people caught it. 2) If catching COVID is going to kill you, by now you are dead by now. Factor in that there'd probably be between 40 and 60% uptake of the vaccine just by people being prudent and the authoritarianism was not only a betrayal of the principles our civilisation is supposed to be defending but also ineffective. And, as the current article showcases, extremely ill-advised. 3) That logic is silly. We don't mandate people do anything special about flus and that'd save far more lives than thousands. Do you consider people who advocate normal life even though influenza exists to be some sort of malign force in society? Even COVID is still killing people. 100s of thousands are still going to die from this thing. But you want to support an abandonment of basic human rights over a few thousand maybe-deaths that can't even be detected? In the extreme, more people have been purposefully murdered to secure basic liberties than that - these aren't the sort of rights that should be casually taken away. reply Retric 5 hours agorootparent> 1) Little as in \"0, but maybe someone wants to quibble that technically it did something so I'll hedge\". As far as I can tell literally everyone I know caught COVID, so it is fair to say the vaccine had no impact on transmission. Raising the obvious question of why it matters where people caught it. Many hospitalizations and deaths from COVID occurred on subsequent infections. > 2) If catching COVID is going to kill you, by now you are dead by now. False, that’s simply not how infection works. Part of the difference here is viral load on exposure. Vaccines and masks reduced viral loads in the air, which then gave people’s immune system longer to react. The immune system takes time to ramp up, but so do infections. A larger initial exposure can snowball even in reasonably healthy individuals. reply acdha 16 hours agorootparentprev> It doesn't make a difference if people doing work were vaccinated or not. It turns out to have had little in-practice effect on transmission This is because of Delta. The original strain was substantially reduced but an order-of-magnitude efficacy jump made that moot. You’re right, however, that we should have focused on masking and air filtration since that was actually effective at preventing spread in close quarters like a school or workplace. reply threeseed 16 hours agorootparentprev> We had a great natural case study in Australia of COVID through a vaccinated population. Everyone caught it over the course of a month, the vaccines did basically nothing to stop the spread. They were pretty much only useful on an individual level which means there was never a requirement for any coercive measures. I am from Australia and this is all nonsense. a) Vaccines are not designed to prevent transmission. They are designed to stop people from getting seriously ill and dying. b) Vaccines and lockdowns were vital in high-density areas like Victoria and NSW which saw health care systems almost instantly overwhelmed. This was then causing mass deaths for both COVID and non-COVID cases. It was a public health emergency by every definition. c) COVID was only allowed to spread once enough of the population was vaccinated. And that was because instead of needing to go into hospital people could stay at home for a few days. And even then it has taken years for the system to recover. reply throwawaythekey 10 hours agorootparentI hate to nitpick but as you called the previous comment nonsense > Vaccines are not designed to prevent transmission. They are designed to stop people from getting seriously ill and dying. Vaccines are commonly designed to prevent transmission. For example it is a critical aspect of the measles vaccine [1]. If a magic wand could've been waved the covid vaccines would've worked that way too, and that is why they were sold to the public as reducing transmission. > Vaccines and lockdowns were vital in high-density areas like Victoria and NSW... There are enough counterexamples of people and places where different trade-offs were chosen. e.g. Brisbane. To say they were vital is injecting your own opinion. c) COVID was only allowed to spread once enough of the population was vaccinated... instead of needing to go into hospital people could stay at home... it has taken years for the system to recover. The overwhelming majority of people were always just going to need to stay at home for a few days, even pre vaccine. The reason the system has taken so long to recover is due to the suboptimal approach we took where we elongated the period of reduced throughput through the hospital system. The effect here was threefold: 1) The backlog of surgeries needed to be cleared. 2) Many patients had worsened over covid and now required more intense treatment. 3) Preventable disease was not being caught in routine checkups etc. [1] https://www.mayoclinic.org/diseases-conditions/coronavirus/i... reply wrs 18 hours agoparentprevThe public policy for individual pain management and the public policy for highly contagious diseases can be different, for logical reasons that I hope are obvious. reply roenxi 17 hours agorootparentYeah, pain management is even more important and they got that wrong. COVID was just a flash in the pan then it seems to have settled down into the background as an issue, while chronic pain is an ongoing thing that is easier to study. So even if we assume that they weight their efforts by importance that isn't particularly impressive for the COVID authoritarianism. reply Dylan16807 16 hours agorootparentGovernment rules around COVID were also a flash in the pan. On a per-day basis it was pretty proportional to the urgency. reply roenxi 16 hours agorootparentWell, yes. We have a society built around concepts of individual liberty and respect for basic human rights. So all the rules were rolled back. The question is why they were rolled out in the first place. Even to this day there is a distinct lack of evidence that any given rule was helpful. We successfully transitioned from a world where everyone was eventually going to get COVID to a world where everyone eventually got COVID and in hindsight it is hard to see what the authoritarian slant of the policies earned anyone. Except perhaps earmarking the people who should be kept out of positions of power. reply wrs 12 hours agorootparentContagious diseases aren’t compatible with the fantasy that individual liberty is always the highest good. That is why decades ago our society realized the need for public health authorities that can temporarily override individual liberties to protect society. Undoubtedly not all the COVID measures were perfect. Some ineffective measures were imposed, and some effective measures were not imposed. You can hindsight armchair quarterback that all you want, but there’s no question the authority to impose such measures is needed. And somebody (who thank heavens isn’t you or me) has to exercise that authority with only the information available at the time, and the highest possible stakes. reply roenxi 9 hours agorootparentI don't think anyone is questioning the existence of the institutions; armies can do what armies want for example and there isn't much anyone can do about it unless the army agrees with their plans. Can't get rid of armies though, we just do what we can and live with the residual risk. The issue is more that in this case the institutions did act, in a panicky and random fashion that seems to, on balance, not have helped but rather violated a large number of human rights and good principles for no particular gain. The only policies that seemed effective were quarantines, light contact tracing, removing red tape and funding R&D. We can do all those things without unduly coercing anyone, they're pretty minor inconveniences compared to the madness that was actually unleashed. reply zmgsabst 16 hours agorootparentprevChildren are still behind in school. reply spamizbad 18 hours agoparentprevThat legal exemption was made possible by a law passed in 2005 which, at the time, was completely non-controversial. It's only after vaccines have become politicized that it suddenly became problematic for the government to take steps to protect its citizen's lives. reply loeg 17 hours agoparentprevPotential for misuse is sort of a different outcome than traditional approval processes. That said, we have known this about opioids forever. And as far as I know, no one is suggesting there is any kind of addiction mechanism for vaccines. reply bdcravens 17 hours agoparentprevRemember that the fast tracking of the development of the vaccine was a project of the administration in power at the time. The shifting political narrative has diminished this very important part of the discussion. https://www.gao.gov/products/gao-21-319 reply jmholla 16 hours agorootparentLet's not forget that the administration in power denied the problem tooth and nail until it was so patently obvious that something needed to be done. reply threeseed 16 hours agoparentprevNothing worse than these straw man arguments. a) Nobody has ever said that pharmaceutical companies should be blindly trusted. b) The companies only have an exemption for COVID and similar emergencies and only when the damages are not caused by wilful misconduct. The idea being that getting the vaccines out sooner would save more lives than any side effects. reply quickthrowman 17 hours agoparentprev [–] > I recall a lot of the manufacturers have a legal exemption from any liability for damage done by vaccines. Without a liability exemption, no company would manufacture vaccines, the government would need to step in as a manufacturer. With the liability exemption law, the private sector makes the vaccines while the government assumes the liability, which is a pretty good solution in my opinion. > In the United States, low profit margins and an increase in vaccine-related lawsuits led many manufacturers to stop producing the DPT vaccine by the early 1980s.[4][unreliable source?] By 1985, vaccine manufacturers had difficulty obtaining liability insurance.[10] The price of the DPT vaccine skyrocketed as a result, leading providers to curtail purchases, thus limiting availability. Only one company was still manufacturing pertussis vaccine in the US by the end of 1985.[10] Because of this, Congress passed the National Childhood Vaccine Injury Act (NCVIA) in 1986, establishing a federal no-fault system to compensate victims of injury caused by mandated vaccines.[11][12] https://en.m.wikipedia.org/wiki/National_Childhood_Vaccine_I... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "McKinsey & Company has agreed to a $650 million settlement to resolve federal investigations into its involvement in promoting opioid sales for Purdue Pharma, covering both civil and criminal charges.",
      "The settlement follows nearly $900 million previously settled with state and local governments, and McKinsey has committed to avoiding future work with controlled substances and will be subject to increased federal oversight.",
      "Former McKinsey partner Martin Elling will plead guilty to obstruction of justice for document deletion, highlighting ongoing criticism that corporate leaders often evade jail time despite significant fines."
    ],
    "commentSummary": [
      "McKinsey & Company will pay $650 million to settle federal civil and criminal charges related to its involvement in the opioid crisis, including a deferred prosecution agreement.",
      "Critics argue that the settlement amount is inadequate considering the crisis's severity, which has led to hundreds of thousands of deaths, and call for harsher penalties, including criminal charges for executives.",
      "The case underscores ongoing discussions about corporate accountability and whether financial penalties effectively deter unethical business practices."
    ],
    "points": 351,
    "commentCount": 257,
    "retryCount": 0,
    "time": 1734130624
  },
  {
    "id": 42413757,
    "title": "macOS 15.2 breaks the ability to copy the OS to another drive",
    "originLink": "https://www.shirtpocket.com/blog/index.php/shadedgrey/youre_a_mean_one/",
    "originBody": "Shirt Pocket Watch Notes from Dave Nanian @ Shirt Pocket You’re a Mean One Friday, December 13, 2024 macOS 15.2 was released a few days ago, with a surprise. A terrible, awful surprise. Apple broke the replicator. Towards the end of replicating the Data volume, seemingly when it's about to copy either Preboot or Recovery, it fails with a Resource Busy error. In the past, Resource Busy could be worked around by ensuring the system was kept awake. But this new bug means, on most systems, there's no fix. It just fails. Puppet on Strings Since Apple took away the ability for 3rd parties (eg, us) to copy the OS, and took on the responsibility themselves, it's been up to them to ensure this functionality continues to work. And in that, they've failed in macOS 15.2. Because this is their code, and we're forced to rely on it to copy the OS, OS copying will not work until they fix it. To put it bluntly, this sucks. It's bad enough we have to work around other bugs in this code, but when it breaks completely, we're stuck pointing fingers and offering workarounds that don't involve the replicator. Workaround Runaround Redux What this means is this: until Apple fixes the bug, you'll have to use \"Backup - all files\" with \"Smart Update\" to copy everything but the OS. This backup, as I've explained before, has all your stuff: applications, data, settings, etc. The System volume (the OS, effectively), is read-only and you can't change it. So a clean install brings it back exactly as it was...and then you can restore when prompted during first boot. We Know This Sucks The section title says it all. I know. This sucks. We think it sucks. You think it sucks. But we can't fix it: Apple has to do so. For those who may be working for Apple, or have good contacts, the bug is FB16090831. A fix would be really helpful, folks. Happy Holidays It's unfortunate this is happening during this period, since Apple rarely releases updates between now and New Year's. I sincerely hope you'll be having a better Holiday Season than I am about to have, with fewer emails and more fun. Thanks for using SuperDuper, and thanks for your understanding. Posted by Dave Nanian in Shirt Pocket in SuperDuper! in News Permalink • Tell-a-Friend Page 1 of 1 pages Members LoginRegisterMember List About Shirt Pocket Watch is a place for me -- Dave Nanian -- to discuss Shirt Pocket, Macintosh, software design, gadgets, movies... blogstuff. Search Advanced Search Calendar > S M T W T F S 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31Monthly Archives December 2024 November 2024 September 2024 July 2024 June 2024 November 2023 September 2023 January 2023 December 2022 October 2022 March 2022 November 2021 October 2021 May 2021 April 2021 January 2021 November 2020 September 2020 August 2020 July 2020 May 2020 April 2020 February 2020 November 2019 October 2019 August 2019 July 2019 June 2019 March 2019 January 2019 November 2018 October 2018 September 2018 August 2018 July 2018 April 2018 February 2018 January 2018 December 2017 November 2017 October 2017 September 2017 August 2016 November 2015 September 2015 August 2015 July 2015 November 2014 February 2014 December 2013 October 2013 September 2012 July 2012 July 2011 June 2011 August 2010 January 2010 October 2009 September 2009 August 2009 June 2009 January 2009 October 2008 August 2008 June 2008 February 2008 January 2008 December 2007 November 2007 October 2007 September 2007 July 2007 May 2007 April 2007 March 2007 February 2007 January 2007 December 2006 November 2006 October 2006 September 2006 August 2006 July 2006 June 2006 May 2006 April 2006 March 2006 February 2006 January 2006 December 2005 November 2005 October 2005 September 2005 August 2005 July 2005 June 2005 May 2005 April 2005 Complete Archives Category Archives Categories Shirt Pocket SuperDuper! netTunes launchTunes Consumer Electronics Blogging News Personal Usability Recent Entries You’re a Mean One Brighten the Corners SuperDuper! v3.9.1 Now Available Quick Fix New macOS / Adoption Polishing (and RIP Haku) Shadows and Tall Trees Turntable Listening Experiment and Wrap-Up Snow Ventura Prompting Problems Sonoma! You Got Culpa on My Mea! Wait, Hold On! Analyzed, Statically Ventura Highway Syndicate RSS 1.0 RSS 2.0 Atom Join our Mailing List © Shirt PocketPowered by ExpressionEngineValid XHTML and CSSOriginal theme by Sadish",
    "commentLink": "https://news.ycombinator.com/item?id=42413757",
    "commentBody": "macOS 15.2 breaks the ability to copy the OS to another drive (shirtpocket.com)346 points by zdw 17 hours agohidepastfavorite279 comments lxgr 17 hours agoWhat is this about? I seem to be missing a lot of context. > Apple broke the replicator. What's the replicator? > What this means is this: until Apple fixes the bug, you'll have to use \"Backup - all files\" with \"Smart Update\" to copy everything but the OS. Use that where? Is that an option in some macOS tool? reply a2tech 17 hours agoparentThis is from the SuperDuper backup folks. SuperDuper is a tool that you can use to make bootable backups of your macOS system. Apple took away the ability for 3rd party tools to manipulate the OS and copy it to another partition/drive and took it upon themselves to provide that functionality via a utility. That utility is apparently non-functional in 15.2. So that breaks SuperDuper's ability to make a nice, clean, bootable backup of your Mac. reply j45 12 minutes agorootparentI wonder if Carbon Copy Cloner is affected. Having bootable backups was the only reason I ever moved to a Mac. This means, a backup of my computer created using something like Carbon Copy Cloner, or SuperDuper backup when plugged into any other Mac, and it would boot as my computer. Also known as Target Disk Mode booting off this backup. Indispensible when or if my laptop was in for repair with Apple. reply echelon 14 hours agorootparentprev> took it upon themselves to provide that functionality via a utility. That utility is apparently non-functional in 15.2. Apple turning our devices into jail cells. These tech titans need to be regulated. We should be able to install whatever we want on Mac, iPhone, and Android. To be able to back up whatever we want, install from web, not be forced to use app stores, not be forced to sync with the cloud, and not be forced to use first party software. reply philistine 3 hours agorootparentThere is a technical reason that greatly benefits the user. The ability to guarantee the OS is unchanged, and to restore to factory defaults like on an iPhone are great benefits. Regulations on our OSes means we end up with Microsoft refusing to limit access to the kernel not to displease the EU, which led to the Crowdstrike outage. reply GeekyBear 2 hours agorootparentThe EU objected to Microsoft having access to APIs that third party developers did not. There has been no EU objection to creating new security APIs that would be accessable to Microsoft and third party developers. As far as MacOS goes, you can't infect the system files with malware when the whole partition they live on cannot be modified by anything but the OS, which does indeed seem like a valid technical reason. reply j45 8 minutes agorootparentprevYou're missing a point. The user, nor the provider can be hostile towards each other. Here's why: The cloud is someone else's computer, not yours. It's a shared drawer that you get a key to, but so do many others. If your main access to your drawer is through the programs on your computer, it also can be limited and broken for hours, days, or weeks while under repair. I'm not sure how many laptops you've had in your life (personal and work), I've read once people get past 5-10, you are basically buying the death of the device the first time you open a new laptop. It's my device. I pay for it. I own it. I use it how I want. Being protected from myself is fine. Being protected from external internet threats is fine. Having a switch to bypass it is mandatory. More realistically, MacOS is likely being shuttered, sequestered to get locked down to make adopting iOS / iPadOS type OS on the macbooks directly instead. Windows tried to dictate when my computer should update and not do anything else, so I left. It's unforgivable. This was well before any policies to manage it cam eout. reply lxgr 14 hours agorootparentprevYou are able to do and install what you want on a Mac (although for some things, you’d have to disable SIP), unlike on iOS. I’m not the biggest fan of the grip Apple has on iOS, but this seems less of a case of platform protectionism, and more one of not wanting to (implicitly) support low-level interfaces/implicit APIs that are becoming hard to support for whatever reason. Definitely annoying, but almost every OS does that at some point. reply talldayo 11 hours agorootparentprev> Apple turning our devices into jail cells. > These tech titans need to be regulated. You say this as though anyone buying a Macbook in the past decade reserves the right to be surprised. New Trump administration isn't going to budge on this - he's actually rather upset at the EU for how they've been treating his good friend Tim Apple. Chances are, he likes this lockdown and wants Americans to accept it. If you're an American owner of Apple hardware, you've involuntarily signed yourself up for the Apple Isolationist program. There is no government to save you, and no god Apple will answer to. reply beretguy 9 hours agorootparent> If you're an American owner of Apple hardware, you've involuntarily signed yourself up for the Apple Isolationist program. I use iPhone because I try not to use any Google products. I didn't sign up for no nothing, I have no other choice. reply rahkiin 7 hours agorootparentTried a fairphone with graphene? reply owlbite 12 hours agorootparentprevDo we know if this was a bug in the beta releases of 15.2, or did it manifest only in the final version? reply sam1r 17 hours agorootparentprevIs this something intentional that Apple has publicly stated in some realm? AFAIK, in that case, maybe it's just a bug that they're planning to fix... reply brigade 16 hours agorootparentWhich part? The inability for 3rd parties to create bootable images instead of using Apple-signed tools? Because that was 4 years ago and is kind of a fundamental requirement for the chain of trust needed for signed system volume security introduced back then. Or are you arguing that this blog post is wrong in asserting the OS release this week introduced a bug in those tools? reply result2vino 15 hours agorootparentArguing? Christ. Is that what we call “stating that it’s possible that…”. Not everything is a hill to die on. reply lxgr 1 hour agorootparentprev\"Resource busy\", as opposed to \"this tool is no longer supported\", almost certainly is a bug, and I don't read the blog post as implying otherwise. But that doesn't mean it's not reckless of Apple to introduce a load-bearing component that wasn't necessary before and then not properly regression test it across OS updates. reply sam1r 17 hours agorootparentprevnext [12 more] [flagged] filmgirlcw 14 hours agorootparentIt’s not a PR stunt at all. If there is any PR benefit, it is totally incidental and not at all planned. The reality is that a core part of how the company’a product works is broken with the latest version. That means that customers of tools like Super Duper (and presumably also Carbon Copy Cloner) who rely on the tools for bootable backups need to potentially hold off on upgrading to 15.2. Considering that this is a tool a lot of Mac admins use, this is a thing you want to let people know about, if for no other reason than to reduce or try to anticipate support loads. And unfortunately, filing Radars often doesn’t solve these sorts of issues. And the customer is always going to blame the third-party. So it is incumbent on the third-party to let people know the issue while at the same time, hopefully apply pressure through negative publicity to get the problem fixed. Phil Schiller (Apple’s head of marketing and the App Store) once said that “running to the press” doesn’t work, but it absolutely does. And especially when it comes to changes that might be bugs (but could also be signs of feature removals), getting public sentiment on your side is often the only recourse third-party devs have. Yes, that ensuing discussion could be PR as a side effect, but no respected third-party devs (certainly not ones as longstanding as the Super Duper folks) are using this as a marketing opportunity. They just want their business to not suffer because of a bug they can’t control or fix. reply lapcat 6 hours agorootparent> Phil Schiller (Apple’s head of marketing and the App Store) once said that “running to the press” doesn’t work That was actually from the 2010 App Store Review Guidelines: \"If you run to the press and trash us, it never helps.\" reply a1o 17 hours agorootparentprevWell, Apple has a super weird bug tracker that you can report stuff but you are kept super in the dark - I remember reporting Safari bugs in the early days of WASM and it was zero communication until the bug got fixed. reply EasyMark 15 hours agorootparentit's called radar I believe and they've used it for a long long time. I always assumed it was built completely in house in the before times reply threeseed 14 hours agorootparentI worked at Apple a while ago and it was a WebObjects app. So I would bet that it was built at NeXT and brought across. It's in the archive going back to 1999: https://web.archive.org/web/19991009144258/http://bugreport.... reply wrs 12 hours agorootparentNo, I used Radar in the pre-NeXT days. I even still have the state diagram mug from when it was introduced in the early 90s. At that point it was a client-server app, because the web didn’t exist yet. Now, it may be that the Apple bug database is always called Radar, regardless of implementation, like the Dread Pirate Roberts. reply lukeh 9 hours agorootparentRadar was always Apple, I think NeXT had their own issue tracker called Recall. However when I worked on Rhapsody in 1997 issues were tracked with Radar. reply zeusk 16 hours agorootparentprevIt’s probably that they don’t want to risk leak any internal discussion. The information from the public \"tracker\" is just forwarded to the internal Radar and that's a one-way street. reply saagarjha 13 hours agorootparentprevA new service that quite literally does not work right now because Apple broke the APIs they need? reply radiospiel 4 hours agorootparentMore of a tool that exists for 15 years or more, and is an important tool for some of us. When my mac broke down in, hmm, maybe 2010-ish, my superduper-created bootable clone allowed me to instantly continue my work on a freshly bought mac (just boot from the clone). No Apple utilities give you that. reply chris_wot 17 hours agorootparentprevOh, my heart bleeds for Apple. reply incompatible 14 hours agorootparentprevMaybe boot a Linux USB drive and use dd to copy the drive? I assume this is too easy, but I'm curious about where it fails. reply nine_k 14 hours agorootparentMaybe if the target device is the same part number (I assume an m.2 NVMe), that would work. IDK if it works with other drives, e.g. different capacity, let alone using a USB-attached drive. I don't know what bits, beyond the image proper, belong to the trusted signed set. reply incompatible 6 hours agorootparentIt would just be a bit-for-bit copy, so maybe it would work? I don't know what a trusted signed set is. I'm mystified about why I'm getting downvoted for that question. If it's inadvertently stupid of insulting to Apple users, wouldn't an explanation be more useful then trying to censor it? reply nunez 1 hour agorootparentIs it possible to boot a Linux Live CD on Apple Silicon Macs? reply jamestnz 17 hours agoparentprevThe article's author seems to be part of the team behind the Mac disk-cloning/backup utility, SuperDuper. https://www.shirt-pocket.com/SuperDuper/SuperDuperDescriptio... reply dtgriscom 15 hours agorootparentshirt-pocket.com and shirtpocket.com lead to the same company's website. reply griomnib 14 hours agoparentprevApple’s built-in backup solution is called Time Machine. It was dogshit when it launched a decade ago, never got more reliable despite many OS releases, and is still largely dogshit. The author of the blog makes an application that is very good at making backups on macOS and now their app is broken due to skullduggery by Apple. So the issue is threefold: a) Apple further turning MascOS into iPhone, b) this harms competition, and c) users ultimately suffer because Apple has no incentive to get better. reply lxgr 12 hours agorootparentTime Machine is really quite good, all things considered. I’d be very happy if Apple were to bring it to iOS, but obviously they’ll never cannibalise their iCloud storage subscription business. reply RandomThoughts3 9 hours agorootparent> Time Machine is really quite good, all things considered. This comment page is full of examples of very real issue with Time Machine which will bite you at some point if you use it. It’s not quite good. It’s bug riddled and Apple refuses to actually do the work to fix it because they would rather you buy iCloud. reply lxgr 1 hour agorootparentBackup systems are both complex and very very critical to many people – of course there will be somebody running into every conceivable edge case. But good or bad only make sense as evaluations relative to something. In my case, that's Linux (I never felt comfortable with any backup solution I looked at there while I was using it, especially not the Ubuntu built-in ones; maybe things have changed with btrfs now) and Windows, which doesn't even try (and all the third party ones I've looked at seem extremely shady in one way or another). The fact that macOS has a pretty solid one out of the box is more than I'm expecting from an OS at this point. I've restored from it a couple of times, both the entire system and individual files, and it did exactly what I expected of it. reply threeseed 13 hours agorootparentprevOr it's the same thing that has been happening for 15 years. People install .0, .1 or .2 release. Complain about bugs. Bugs get fixed. Repeat. reply nrabulinski 12 hours agorootparentSome might think this is what the beta is for but I guess not. Let’s excuse the multi trillion dollar company for releasing broken software, each release being more broken than the previous one reply dwaite 8 hours agorootparentThat Super Duper post didn't indicate whether they filed feedback during the beta or not. reply randyrand 6 hours agorootparentprevIt's gotten so bad I normally wait until 0.7 (final release). reply submeta 13 hours agoprevThis is bad. - Just recently I broke my system badly. So I decided to erase my system and re-setup from time machine. After several unsuccessful attemts I realized that my Time Machine backup (1.45 tb) exceeded my ssd capacity (1 tb). I did research, and learned not to prune my Time Machine backups. As that may corrupt it. So after several days and failed attempts to restore from time machine and after some research and finding out that indeed it was still possible to boot from external ssd, I decided to buy a 2 TB ssd, restore to that ssd, boot from it, clean up excessive data, and migrate from that ssd to my Macbook. It took me three days to solve it. As each failed attempt and investigation took hours to complete. In the meantime I called Apple support to get help. I said right away that I am an IT professional who worked as sys admin in the past and that I would like to talk to experts. And they forwarded me to „experts“. The first said: „Forget about full restore, won’t work. Create a fresh install and manually (!) copy individual files from time machine to your mac.“ Second person told me to buy a new Mac with 2 tb ssd and restore to that. I asked her if it was possible to restore to an external ssd via Carbon Copy Cloner? As I did in the past half a dozen times. She told me she definitely does not recommend that path as she cannot recommend third party apps (?!?). I did not try that option immediately as I heared a few years ago that latest MacOSes do not support booting from external ssds. And so I didn’t think of this option. But some research and I found out that indeed it is still possible, but you have to go some extra steps. So if this wouldn’t have been possible I would have had spent two weeks to restore my machine. Or bought another machine with 2 tb just to restore from backup. PS: I spent almost 5k Euros for this maxed MacBook Pro with 64 gb. Plus Apple Care. I didn’t want to buy another Mac just to restore from backups. PPS: All of this was shortly before a very important presentation. So I was stuck with my work laptop (windows machine), and I am 90% less productive with it as it lacks my tools. Yeah, shouldn’t have screwed my main machine just before a super important milestone. Lessons learned. reply redmajor12 12 hours agoparentSounds like the lesson learned here from reading your travail is not to invest in an ecosystem that makes it difficult to do a standard operation. reply submeta 12 hours agorootparentMaybe. But what are the options? Windows? Not really. Linux/Debian/Ubuntu is great, in theory, but it lacks tools: Acorn, Keyboard Maestro, OnniGraffle, Alfred App, MS Office, MS Teams, and a dozen more. Plus Apple silicon. I test LLMs locally. reply deaddodo 12 hours agorootparentThis isn't me trying to convince you to use Linux, but the listed reasons (other than LLM testing) aren't real deterrents (and there are plenty that exist for many people, no use pretending not): > Acorn GIMP (or Glimpse, if you want a more modern UI) or Krita can definitely do pretty much anything Acorn can. > Keyboard Maestro GNOME and KDE have been able to do this out of the box from pretty much the beginning. The OSes are still mostly terminal-first (one of the big complaints, actually), and that translates into the DEs and Applications. A keyboard automation is just a sequence of commands. This is probably one of the few areas where Linux almost definitely beats macOS or Windows. > OnniGraffle There's a large swathe of diagramming tools in Linux. > Alfred App Yep, both KDE and Gnome are able to handle this task as well as Alfred. Like automation, this is probably an area Linux will be able to shine above macOS. > MS Office LibreOffice would be the common alternative. > MS Teams They used to have an official client. They now recommend you create a PWA, and there are some unofficial clients that do pretty much that: https://github.com/IsmaelMartinez/teams-for-linux This seems to be the route they'll be going all around, similar to slack (web + an electron app). > I test LLMs locally. LLMs run fine on Linux, but you will be limited to about 16GB on the VRAM side. Though, you could technically use Asahi + Apple Silicon as the support matured if you want. Most of these are open source applications, with cludgy UIs/warts and all; and aren't really designed by teams with UX masters, so operate oddly and require relearning. But if you were interested in making the move, they're options. reply sinfulprogeny 12 hours agorootparent> GIMP (or Glimpse, if you want a more modern UI) or Krita can definitely do pretty much anything Acorn can. I'm fairly certain that anyone who recommends GIMP hasn't really used GIMP. reply ofalkaed 8 hours agorootparentGimp and Libreoffice both seem to go out of their way to do everything their own way and ignore what has been demonstrated to work well and has essentially been established as a standard, this is one of the major issues with OSS for me along with trying to offer more than is reasonable and put in time on niche features (MORE MORE MORE) instead of working out the issues with what is already implemented. LibreCAD is a prime example example of doing it their own way, cutting off their nose in spite of their face, there was no reason to change most every command and require us to hit return after every single command. The free version of QCAD is still superior to LibreCAD and it is difficult to justify suffering through all of LibreCAD's failings when QCAD only costs $45 with a year of updates, even if you don't renew that outdated QCAD it is still more capable and usable than LibreCAD. I have used nothing but linux for over two decades now but it is getting harder and harder to justify using linux, too much of the software is so fixated on competing that they have lost all perspective. For awhile now I have seriously considered switching to Haiku and developing the software I want for Haiku with its API that will not run on anything else, but I have not quite been irritated enough to go that far. Getting there and it might happen once Haiku irons out those last few wrinkles. Edit: Should add, been a few years since I last used LibreOffice, they may have gotten their act together. I suffer gimp far too often. reply lloeki 9 hours agorootparentprev> anyone who recommends GIMP hasn't really used GIMP. Or they only ever used GIMP but never Acorn/Pixelmator/PS and thus don't understand how they run circles around GIMP. Same about OmniGraffle vs the supposed horde of Linux diagramming tools. Or Logic (or even GarageBand) vs Ardour or - deity forbid - Audacity (which is at best a glorified wav editor, but a far cry from a DAW) They're just not in the same league. reply blackhaz 10 hours agorootparentprevCan confirm. GIMP after Photoshop is a true BDSM experience. And no, it's not about \"doing things differently.\" It's a torture. reply prmoustache 8 hours agorootparentThat is just basic resistance to change. People keep recommending Krita or photopea against Gimp but I am using both (Krita for digital painting, gimp for other stuff) and have made back to back test with all 3 software and the UI is almost identica[1] so that is just ignorance talking. [1] just a handful of menus in a different order woaaaaa torture indeed!!! reply janalsncm 11 hours agorootparentprevI have only ever used GIMP and I will admit that the UI looks like hell. I also rarely do anything very advanced in it anymore so I can’t say whether it has feature parity with PS. reply ballooney 10 hours agorootparentI can, it doesn’t. reply 4gotunameagain 11 hours agorootparentprevI have been using gimp for almost a decade now. Granted, I am not a professional in that field, but why would I not recommend it ? It does everything I want to, and more. reply InsideOutSanta 8 hours agorootparent>why would I not recommend it ? You're free to recommend it, but if you tell somebody coming from a Mac that GIMP is an alterantive to tools like like Affinity Photo, Pixelmator, Acorn, or even Photoshop, you're doing them a disservice, because it's not. I'm glad that GIMP works for you. That's good. And technically, it probably does a lot (or even everthing) that most people do in other applications. And maybe you can even argue that it doesn't do those things worse, it just does them differently. But the reality is that if you're used to a tool like Acorn on the Mac, which puts a huge priority on providing a good, efficient user experience, you're just never going to switch to GIMP. Same applies to a tool like OmniGraffle. I've looked everywhere, there's nothing like OmniGraffle on Linux. By that, I don't mean that there aren't any tools that allow you to create diagrams and mockups, I mean there aren't any tools that are as nice, simple, and quick to use as OmniGraffle. reply dsego 8 hours agorootparentprev> It does everything I want to, and more. So does ms paint for a large part of computer users. Not sure that's a good enough argument. reply reddalo 9 hours agorootparentprevI've been using GIMP for 20 years now, but the UI is atrocious; you can tell it's been designed by engineers who know nothing about UX. Even the most basic UI elements, such as the slider bars, are horrible and unusable. reply yupyupyups 10 hours agorootparentprevGIMP 3.0 is going to be released soon. That might interest you. reply eastbound 10 hours agorootparentOusted the front door, coming back by the backdoor: - “Maybe you’re using it wrong” - “It has greatly improved since Gimp 2.0”, - “It’s just doing things differently” - “It has 90% of the features of MS Office” seem to be the top arguments for trying Linux over Mac, again for the 20th time in 20 years, each time awfully bad. As Steve Jobs once said about Microsoft: “The problem is these people have no taste.” It’s correct that when you have no need for something to be beautiful or no need to be productive between two recompilations of the kernel, then Linux is the OS of choice. reply reddalo 9 hours agorootparentprevAlso, Glimpse has been abandoned since 2020. reply deaddodo 11 hours agorootparentprevI didn't recommend it, I offered three options (one specifically created to fix the exact issue you're probably complaining about - GIMP's horrendous UI) reply jb1991 9 hours agorootparentThe problem is, you imply the alternative solutions are somehow just a stand-in replacement, which is not true, and not just with Gimp in the programs you listed. Software matters, and when software you need is not available, it is a significant compromise. reply richrichardsson 9 hours agorootparentUp until the last paragraph, where he freely admits all the options are basically shit in comparison. The idea that having to relearn all software and deal with idiosyncrasies for a professional is laughable. reply eviks 12 hours agorootparentprev> aren't real deterrents They are, because your listed alternatives are substandard. Just the fact you recommend incompatible LibreOffice as an MS Office alternative is enough, but then comparing KM to system defaults is also a joke. > The OSes are still mostly terminal-first And terminals are universally so bad at shortcuts that many can't even support all the modifiers keys on your keyboard reply mistercheph 11 hours agorootparentWhat kind of nightmare documents are you encountering that you actually run into MS Office / Libreoffice incompatibility? reply kimixa 10 hours agorootparentAnd in turn don't also run into to incompatibility between different versions of MS office? I've had at least as many issues moving complex documents between MS word versions than moving from MS to Libreoffice. reply j16sdiz 12 hours agorootparentprev> > Acorn > GIMP (or Glimpse, if you want a more modern UI) or Krita can definitely do pretty much anything Acorn can. You will be surprised to know how some professional treat their tools. Some illustrator love their software just like some mathematician love their chalk. Many woodworker make their own tools to make them feel just right. > > MS Office > LibreOffice would be the common alternative. If you export them as PDF, maybe. If you need to exchange editable file with others, every small layout different hurts. You won't want your tables paginate differently from others. reply deaddodo 12 hours agorootparentWhich is why I specifically stated that the feature set matches and not that they're drop in replacements. Then gave a giant disclaimer about open source software in general at the bottom. I'm not evangelizing, I'm stating that the listed software/workloads are perfectly amenable to Linux if you wanted to make the move/relearn those softwares. reply tsimionescu 11 hours agorootparentAlmost none of the software you mentioned is a realistic, fully featured, profesionally-usbale alternative to the software that doesn't run on Linux. So, overall, Linux can't be an alternative to the Mac and/or Windows for anyone who relies on these tools. reply deaddodo 10 hours agorootparentThat's an opinion. reply IshKebab 9 hours agorootparentA realistic opinion. reply pseingatl 9 hours agorootparentprevYou might want to try the German program Softmaker. It's not free--though I think there's a free version--and it's designed to be a drop-in replacement for Microsoft Office. There is a Linux version as well. reply tcoff91 10 hours agorootparentprevKeyboard Maestro is a lot more powerful than what you're thinking of. A sequence of shell commands bound to hotkeys is in no way an adequate replacement. reply rane 8 hours agorootparentDo you have any examples of use cases Keyboard Maestro is great for? reply anthk 7 hours agorootparentprevXdotool/xdo, xsel and so on. reply OrderlyTiamat 10 hours agorootparentprev> > I test LLMs locally. > LLMs run fine on Linux, but you will be limited to about 16GB on the VRAM side. That'll probably be a dealbreaker. > Acorn GIMP Don't get me wrong, I am still gratefully using GIMP, it's a fine tool for what it is and I am happy with it. But from a \"meet people where they are\" perspective, it's absurd to tell someone who uses tools like Photoshop that GIMP is a viable alternative as it is right now. reply jinnko 10 hours agorootparentprevA bit of nostalgia. Switch to whatever you want https://youtu.be/9GO3mccvTCs reply not_a_shill 9 hours agorootparentprevLibreoffice isn't the alternative, office on web is. And even that is still gimped compared to Windows Excel. (Which is the true killer app for professional use of Windows in general) reply nunez 1 hour agorootparentOffice on the Web is a cruel joke. It theoretically does what you want it to do, but more often than not, it will do it extremely slowly while vaporizing your RAM. I can't imagine it being better on Linux. reply RandomThoughts3 9 hours agorootparentprevYes, I find it fun to use office as a Mac differentiator when the Mac version is so inferior to the Windows one. At least, office365 works fine on Linux using Crossover. It’s the same weirdness with people recommending Gimp for Acorn when Linux has great photo manipulation with Darktable and good digital painting with Krita. And I say that as someone who quite like MacOs even if it’s getting worse with each version. reply pseingatl 9 hours agorootparentprevTry Softmaker Office for Linux. reply Jnr 10 hours agorootparentprevAnd here I am running Linux on M1 Macbook. Graphical interface is superior, native docker support is superior, development experience is superior, backups for sure are superior than Time Machine. For work purposes online office on the web is sufficient. It is not for everyone (like photographers), but for software developers it works very nicely. reply gvurrdon 7 hours agorootparentMay I ask what distro you're using, and when there's any good documentation around for the installation procedure? reply Jnr 4 hours agorootparentI'm an Arch guy, but for the M1 I am using the official Asahi Linux distro which is based on Fedora. Documentation and information about compatibility can be found on their site: https://asahilinux.org/ I previously used the Arch based Asahi distro when it was official, but Arch on ARM is a 3rd party project and it was not very well maintained and lacked some packages, so they switched. Fedora could also be considered more stable and better supported. But there are Ubuntu, Debian versions for Asahi if you prefer those. reply everdrive 8 hours agorootparentprevPlatforms that lack MS Teams are doing the user a favor. reply LeoPanthera 12 hours agorootparentprevAre we reading different comments? Because the only reason he had problems is because he didn't do anything standard. He futzed with his backups instead of letting the OS take care of it, and that's the only reason he had any trouble. If you let Time Machine doing it's thing, restoring from a backup is fast and painless. (Though it's been years since I had to restore a Mac for any reason. It makes me wonder what he was doing.) reply eviks 12 hours agorootparentThe reason is the opposite - he was doing the standard thing of using the substandard Time Machine for backups, which has been poorly engineered not to allow restoring without pre-pruning > If you let Time Machine doing it's thing Then you can corrupt your whole backup, and then fully restoring becomes impossible instead of long and painless, but possible > It makes me wonder what he was doing He was doing the restore recently, not many years ago reply thowawatp302 9 hours agorootparent> substandard Time Machine for backups Compared to what? reply hirako2000 11 hours agorootparentprevMentioned was a pretty fundamental issue with time machine, to this day. In that it doesn't (de)allocate older backed up space to make for up space for newer back ups. This or some variations of that. The bug may not always manifest itself I suppose which makes it worse emotionally. I'm there setting on a 1tb backup disk dedicated to backup a 500GB root HDD, it keeps saying there isn't enough space available after 1h sorting out what needs copied over. Deleted a series a snapshot but it won't tell what doing this is saving me. I can only resort to wipe the entire backup and backup again. Now wondering, what if I deleted some documents a while back which I thought would have a snap. Do I care more about getting a fresh backup or unweilded snapshots that may or may not contain something I don't know I've lost. reply submeta 12 hours agorootparentprevI had only 600-700 gb of data on my Mac. Installed OneDrive, did not know that I had configured my NAS to do 800gb of cloud backups to OneDrive. And Time Machine downloaded that data into its backup. Although I had configured OneDrive not to download that folder to my Mac. So time Machine screwed up in the first place. reply hmottestad 12 hours agorootparentSounds like an edge case that Microsoft didn’t think of when they developed OneDrive on Mac. You should contact them and let them know that they should exclude OneDrive from Time Machine backups automatically unless it’s configured to download everything. You can very easily exclude folders from Time Machine backups yourself. reply submeta 12 hours agorootparentMy point was about being able to boot from ssd. Not about whom to blame re Time Machine backup. reply hmottestad 8 hours agorootparentAhh, I didn't see that you were the original commenter. reply addaon 9 hours agorootparentprev> restoring from a backup is fast and painless. Had to restore recently. Was painless, but most definitely not fast. Took 24 - 36 hours to restore a 1 TB drive withI wonder what kind of magic they have that no other laptop brand is able to put better speakers in their laptops. The answer is integration. With Windows laptops, you have one company doing the sound card, one company doing the speakers and one company doing the enclosure. What you actually want is your sound card's equalizer curve being perfectly tuned to your speakers' frequency response, taking into account how their positioning in your specific laptop enclosure affects the sound. If your sound card maker doesn't know what laptop the card will go into, they just straight up can't do this. There's also the fact that sound cards have to be conservative about how much power they output, to avoid blowing up the speakers. Apple knows the exact tolerances of the ones in their laptops. They even have special temperature sensors in them, so that they can increase the power even more, and go back to a safer level in software if the temperature ever crosses a safety threshold. reply talldayo 12 hours agorootparentprev> Apple is about the only company that allows you to run any decently sized LLMs on a laptop Comments like these make me wonder if people even use different computers anymore or if they just say stuff and hope that it's right. reply miki123211 10 hours agorootparentApple is the only company that makes integrated GPUs that are actually any good, and even their CPUs are really well-optimized for these sorts of workloads. They also build their RAM in a way that makes it suitable for both CPU and GPU uses. This means you don't have separate CPU RAM and GPU VRAM, it's all just memory. If you get more RAM for your Macbook, that automatically means more memory you can use for LLM inference. Yes, you can technically buy Nvidia, but you'd pay just as much for that if not more, and I don't think you can get as much VRAM in a consumer GPU anyway. reply IshKebab 9 hours agorootparentHaven't laptops used integrated RAM for decades? It was always considered to be a bad thing in the past. I guess because the integrated graphics was always weak? reply hmottestad 9 hours agorootparentOne big factor was bandwidth. Seems Apple mostly solved that though. reply hombre_fatal 10 hours agorootparentprevWithout a concrete counter example you risk looking like you’re denying the claim with no elaboration and hoping you’re right. :P reply hmottestad 9 hours agorootparentprevI don't know of any other laptop with a GPU that has 32GB of VRAM, and definitely not any with 64 or 128. reply rolisz 11 hours agorootparentprevPlease, do tell me where else can I run 32b models locally without quantization reply adrian_b 10 hours agorootparentIf you do not care about speed, pretty much everywhere. On any other computers with integrated GPU you can have more memory than on Apple computers, where memory is abnormally expensive. The main advantage of the current Apple computers is a wider interface with memory, which provides a better memory throughput for their integrated GPUs. In 2025 it is expected that others will catch up with Apple even from this point of view (e.g. AMD Strix Halo). reply hmottestad 9 hours agorootparentLet's hope that AMD Strix Halo will allow for 128 GB of VRAM when it releases next year. That's what Apple has to offer at the moment. > On any other computers with integrated GPU you can have more memory than on Apple computers, where memory is abnormally expensive. Are there any laptops that support 256 GB of RAM that cost less than a fully speced out Macbook Pro? reply cma 11 hours agorootparentprev64GB of system RAM and partial offload to a laptop 3090 or 4090 will run 32b unquantized. reply hmottestad 9 hours agorootparentWhat kind of performance are you seeing? The tests that I have seen are not usable for anything because they are so slow. reply rolisz 7 hours agorootparentprevWill I get an answer back anytime soon? On a MBP pro it's conversational speed. reply foderking 9 hours agorootparentprevidk about the LLM part, but the rest of this is not true. there's multiple laptops that compete or even beat MacBooks in display, battery life, performance etc. and the MacBook displays have really slow response times reply hmottestad 8 hours agorootparentI guess we all have different requirements in a screen. I don't care so much about response time. For me it's more important that the screen can do 1000 nits continuously, support 120 hz and is close enough to 4K that I can't see the pixels. Although I can't find a windows laptop that can beat the M4 Max in single threaded or multi threaded. Got any tips for any laptops that can compete with the M4 Max? reply jamwil 4 hours agorootparentprevI’d be curious to see an example. reply nunez 1 hour agoparentprevI don't have a dog in this fight, but I just want to say that it is extremely refreshing to see a good ol' fashioned Linux vs Win vs Mac debate in 2024. The Internet isn't dead. I lied; I actually do. GIMP sucks! reply kstenerud 11 hours agoparentprevI've really been noticing how Apple software quality has been on a slow decline since Snow Leopard. I look at some of their older source code and it's a joy to read! Nowadays, my daily travails with restarting Xcode multiple times a day to work around bugs (package blahblah is not available) have really worn thin (I mean, Xcode has always had problems, but not THIS bad). Add to that the fact that the \"system data\" on my mbp now takes up 80% of the space on my SSD (800GB of system data! Even after manually deleting caches and derived data)... It's like they don't even care about code craftsmanship anymore. And yet their culture of not putting in useful debug messages (because \"it just works\") persists. My latest and greatest headache? Some parts of AppKit now directly call [NSApplication _crashOnException:] regardless of the \"NSApplicationCrashOnExceptions\" setting, and WITHOUT even calling [NSApplication reportException:]. So now you lose the exception entirely and good luck figuring out what caused the crash. Ugh... reply tonyedgecombe 10 hours agorootparentI don't use Xcode so maybe it is an exception but in general I would say the opposite. For me it has been getting better over time. People talk about Snow Leopard being stable but it was riddled with bugs, just take a look at the release notes for all the updates it received over the next year. reply T4iga 9 hours agorootparentprevI have had a similar experience after i shared my MacBook with my girlfriend for a while. Turned out even after uninstalling her cloud file sharing software thing, there were still over 100GB of cached files left on disk. MacOS didn't make the obvious identify or find in the storage overview. I ended up finding it through a disk space visualizer that showed a large folder (the stolen 100GB) in some cache directory. I can highly recommend trying that out. MacOS' inbuilt tools are in my experience inadequate to find what is stealing your disk space (on top of applications being unable to clean up after themselves). reply wiredfool 5 hours agorootparentprevThe system data apparently contains the Time Machine backups that haven’t been flushed to your external backup, including folders that are set to be ignored. I discovered this while trying to restore a docker vm image that was maybe ignored, while not having enough space on the drive to restore it back, because deleted versions still take up space in the system data, even when the trash is emptied. reply raverbashing 9 hours agorootparentprevYeah Let me guess, the best engineers are working on iPad/iPhone apps today and MacOS is relegated to code fixes and people building for the \"common user\" that doesn't know what a drive is reply prmoustache 8 hours agoparentprevI don't know time machine, but why would a full restore take more space than the original drive? Wouldn't a full time machine restore by default restore the last state of the system being backed up (and not full history) by default like any half decent backup solution? reply submeta 8 hours agorootparentI had only 600-700 gb of data on my Mac. Installed OneDrive, did not know that I had configured my NAS to do 800gb of cloud backups to OneDrive. And Time Machine downloaded that data into its backup. Although I had configured OneDrive not to download that folder to my Mac. So time Machine screwed up in the first place. reply hmottestad 12 hours agoparentprevWhen I last restored from Time Machine it allowed me to select which folders I wanted to restore. Then I could just restore the most important bits and leave anything big behind on the backup drive to restore manually later. https://support.apple.com/en-us/102551 reply submeta 11 hours agorootparentI only was offered to select top level folders. Nothing below them. reply hmottestad 8 hours agorootparentDid you try to reinstall the mac and use migration assistant to restore from the Time Machine backup? reply submeta 7 hours agorootparentYes I did. But the time machine backup was way larger than my macbook‘s ssd. The reason was this: I had only 600-700 gb of data on my Mac. Installed OneDrive, did not know that I had configured my NAS to do 800gb of cloud backups to OneDrive. And Time Machine downloaded that data into its backup. Although I had configured OneDrive not to download that folder to my Mac. So time Machine screwed up. reply throwaway48476 10 hours agoparentprevYou chose the walled garden. reply vachina 8 hours agoparentprevApple doesn’t care. They want you to subscribe to their iCloud plans and “abstract” away backups so that you lose the ability to own your backups. reply fauigerzigerk 7 hours agorootparentI wish they did abstract it away. But iCloud is the only widely used cloud storage service that doesn't have file versioning. So as an iCloud user you really do need a backup and they're telling you as much every step of the way. reply vachina 1 hour agorootparentTo most Apple users, the most important version is the latest version. My experience with Apple backup is, please turn every backup on so you’ll max out your iCloud storage. There’s no way to tell iOS or MacOS to backup to a self hosted target. reply super_mario 8 hours agoparentprevHow did you end up with TM backup larger than original source? Sure, total storage consumed on TM drive can be larger than source, but that is because older versions of files are stored as well. But restoring most recent versions of files should be equal to source in size. reply submeta 8 hours agorootparentI had only 600-700 gb of data on my Mac. Installed OneDrive, did not know that I had configured my NAS to do 800gb of cloud backups to OneDrive. And Time Machine downloaded that data into its backup. Although I had configured OneDrive not to download that folder to my Mac. So time Machine screwed up in the first place. reply hilux 10 hours agoparentprev> I didn’t want to buy another Mac just to restore from backups. And then presumably one more Mac to backup your backup Mac. It's Macs all the way down! reply alexeiz 11 hours agoparentprev> Second person told me to buy a new Mac with 2 tb ssd and restore to that. Or you can just upgrade the SSD as you would do with any normal laptop. Oh, wait... reply nikisweeting 13 hours agoprevArticle is pretty unclear, \"copying\" can mean many things to many different people: cp -r / /Volumes/Clone # this never worked # what about rsync, does this still work? rsync --acls --archive --hard-links --one-file-system --sparse --xattrs / /Volumes/CLONE sudo bless -folder /Volumes/CLONE/System/Library/CoreServices # what about block-level copying, does this still work? sudo dd if=/dev/rdisk2 of=/dev/rdisk4 bs=1m conv=notrunc reply mrpippy 13 hours agoparentIt’s documented in their older blog posts, I believe they use the ‘asr’ utility to copy the OS install. The many partitions that make up a macOS install means that cp or rsync isn’t enough. dd would do it, but at great cost in flexibility (can’t back up to a smaller disk, or select files) and speed reply noisy_boy 11 hours agorootparent> dd would do it, but at great cost in flexibility (can’t back up to a smaller disk, or select files) and speed I mean if we are talking about copying the whole OS or disk, that is a very macro operation. The fine-tuning can be done at the target location after copy like removing unwanted files/resizing partitions etc. No idea how slow would dd be but I thought you could specify larger blocksize for better performance (hoping someone more knowledgeable on dd can add their views). reply germandiago 11 hours agoprevMy bext comouter will not be a Mac. Works nice but the lock-in is crazy all the time. reply ilrwbwrkhv 11 hours agoparentYup both Mac and Windows have a better replacement now: Linux. Thanks to all the hardware vendors and Valve, Linux has become a better desktop alternative for sure. reply noisy_boy 11 hours agorootparentAnd Linux works pretty nicely with Android too - not hand-in-glove cohesion like Apple can provide for obvious reasons, but practically all vendors provide tools to switch pretty easily during the device setup stage and Syncthing provides amazing flexibility in managing data between Android and Linux devices on an ongoing basis. reply pjmlp 11 hours agorootparentprevThe day Microsoft decides Proton is a nuisance that gaming alternative is gone, as Valve decided fostering a GNU/Linux game ecosystem wasn't worth it. reply SXX 11 hours agorootparentMicrosoft has joined Open Invention Network a while ago and AFAIK (though I can be wrong) Valve is also member of OIN. They can't really attack anyone using their patents now. And Valve is not exactly a small startup that's possible to sue into debt. Even though they're much smaller by headcount they certainly do have money and desire to fight any kind of legal battles. And with amount of goodwill Valve has from it's customer base anyone attacking them will end up with huge PR disaster. Also even if above wasn't true I doubt MS want any more antitrust scrutiny. reply pjmlp 10 hours agorootparentIt is as easy as having Windows and XBox APIs that Proton isn't able to easily replicate, while requiring them for Windows Store and XBox Game Pass. Valve got lucky with UWP. No need for patents. Also there is the whole question Microsoft has outlived its founders, will Valve be able to do the same, and those that come after Gabe will they sell it, what would their view be regarding Proton, and so on. reply SXX 9 hours agorootparent> It is as easy as having Windows and XBox APIs that Proton isn't able to easily replicate, while requiring them for Windows Store and XBox Game Pass. This will do more damage to Microsoft's position rather than Valve. They already lost current generation of console war and weakening their positions further by breaking compatability would't do them any good. Also Apple eating into their laptop market share by ARM offerings and have it's own compatability layers for graphical APIs. Microsoft cant do much of anti-competetive vendor lock-in by technical means now. It was possible for them to stop something like Open Source community efforts, but likes of Valve and Apple are so much more resourceful. Everything they do on Windows can and will be reverse engineered. > Also there is the whole question Microsoft has outlived its founders, will Valve be able to do the same, and those that come after Gabe will they sell it, what would their view be regarding Proton, and so on. Here I'd tend to agree. There is a huge questions whatever Valve-after-Gabe can continue as it's now. reply pjmlp 9 hours agorootparentApple has 10% of worldwide desktop market, and no presence on servers and cloud. They aren't eating anyone's lunch, not even on mobile, where Android rules world wide. Microsoft also owns the PC, besides XBox, Valve is a guest and should not forget how many studios are owned by Microsoft. And with a Microsoft friendly US administration, maybe even Valve-after-Gabe can become part of Microsoft. reply philistine 3 hours agorootparentApple owns 10% of the market, but around 90% of all computers above 1000$. They make around 7.5 billions in Mac revenue per quarter, which makes them the most profitable computer company. Apple controls the high margin market. That has royally screwed Intel, which explains in part the woes its in right now; it lost the only high margin computer maker. reply angry_octet 5 hours agoprevDoes anyone know of a way to disable the update notification badge? Or indeed remove the list of updates available. The old 'softwareupdate --ignore' flag has been removed. So freaking annoying. reply keyle 9 hours agoprevNo one really complained with 15.1 and macOS completely blocking software that is \"untrusted\". You know the \"move to bin\" popup, which you used to unblock in the past by cmd+clicking the binary, or later via the settings menu for privacy & security (insane in its own right!) Since 15.1, you're done and dusted. Unsigned/untrusted binaries simply will not run on macOS, regardless of how much you trust them to be. Thanks Apple. That is a big deal, a really big deal... For the music industry, many industries and consumer grade software, such as game installers from GOG, etc. They simply don't open anymore once you install them fresh. I raged for about 15 mins at these idiots at Apple for making such a breaking change to user space. This is clearly not to protect the user as much as it is closing the walled garden onto users. Disgusting, silent move, in a minor release. Thankfully I found the solution in xattr -d com.apple.quarantine ~/binary But what do I do once this doesn't work anymore? I really wonder. I really like the M1-M4 chips. I can't stand listening to a fan anymore. If this keeps going south I will be jumping ship to the first distro that supports this hardware properly. A sad state of affairs. macOS is a beautiful OS with its problems but very workable. Apple is slowly picking at it and worsening it, mostly, throughout the years. Long live Snow Leopard! reply sumuyuda 9 hours agoparentI haven’t updated to 15, but I thought they just removed the ability to run unsigned software by right clicking and selecting open. My understanding was you had to manually approve it in the system settings via Gatekeeper? Apple is 100% slowly boiling the frog in respect to locking down macOS to be like iOS. I already switched to Linux on my personal machines. I saw the writing on the wall when notarization was announced in 2017. reply keyle 9 hours agorootparent15.1 completely removed the ability to \"open anyway\" within the Privacy & Security panel, which was already a shocking way of handling it. reply sumuyuda 6 hours agorootparentAccording to this post you can bring back running software from anywhere: https://discussions.apple.com/thread/255759797?sortBy=rank reply post-it 8 hours agorootparentprevIt's still there for me, though the context menu option is not. reply keyle 8 hours agorootparenthttps://hackaday.com/2024/11/01/apple-forces-the-signing-of-... reply rgovostes 7 hours agoparentprevFor additional context, the dialog reads: > \"App\" Not OpenedApple could not verify \"App\" is free of malware that may harm your Mac or compromise your privacy. [ Done ] The upper right of the dialog has a ( ? ) button that opens https://support.apple.com/guide/mac-help/apple-cant-check-ap... which says: > However, if you choose, you can still open an app that isn’t allowed to open by manually overriding Privacy & Security settings. There's a link to the settings, under which you have to scroll down and find a second copy of the above message and then click \"Open Anyway\", with then gives you a third warning: > Open \"App\"?Apple is not able to verify that it is free from malware that could harm your Mac or compromise your privacy. Don’t open this unless you are certain it is from a trustworthy source. [ Done ] [ Open Anyway ] Continuing on requires authentication, and the prompt offers a fourth warning: \"You are attempting to open an app that may harm your Mac or compromise your privacy.\" According to https://developer.apple.com/support/compare-memberships/ you do need a full $99 Apple Developer Program membership to have apps notarized. reply argsnd 9 hours agoparentprevYou can either switch off Gatekeeper or go into the system settings to click open anyway. Yes, it’s annoying though. reply keyle 9 hours agorootparentNo, this is what I'm saying, 15.1 removed the system settings to \"open anyway\". It's gone. reply commandersaki 6 hours agorootparentI had to find an application to test, so I downloaded the kitty terminal emulator for macOS which was just an executable. I tried to execute it from the shell ./kitten-darwin-arm64 and it gave me an option to cancel or move to bin. I went to system settings -> privacy & security -> and told it to allow kitten-darwin-arm64. I then rerun ./kitten-darwin-arm64 and it now had the option to \"Open Anyway\". So in 15.2 it is still possible to execute software by unidentified developers. reply pas 9 hours agoparentprevmoving to Asahi Linux seems like an option eventually reply keyle 8 hours agorootparentYeah I was looking at that. The problem is I write my own mac software and I'd be missing on that. reply danielovichdk 9 hours agoprevAs long as they don't take away the __MACOSX folder when I copy other things. reply haileys 16 hours agoprev> This sucks. We think it sucks. You think it sucks. But we can't fix it: Apple has to do so. And this is why I gave up on macOS several years ago now and moved to Linux. It's not about which OS is better or worse. All software has bugs. It's about the empowerment to _do something_ about the inevitable bugs, rather than wait and hope that a fix comes down from above. reply dymk 15 hours agoparentIn theory I can make bluetooth and wifi and deep-sleep work with Linux, but am I actually able to fix it? No, and not for a lack of trying. If we're talking about practical ability to fix what goes wrong with my daily driver, then macOS still wins hands down. reply akvadrako 10 hours agorootparentDeep sleep doesn't work with Windows or Mac, and isn't needed on Linux either. My past two laptops, ASUS and Lenovo, lasted days with modern standby. Not as great as Apple but good enough. reply leni536 11 hours agorootparentprevAll of those work. As for bluetooth, I can connect multiple bluetooth headphones and playback audio at the same time. This is a bit fiddly, but I wouldn't even know where to start on some other systems. reply imiric 7 hours agorootparentI was recently shocked to find out that you can't change the volume in macOS when the machine is connected to a TV over HDMI[1]. Volume control is entirely disabled, and you need to adjust it via the TV. Or use a 3rd-party program. This is absolutely insane. I'm sure Apple will claim to have a very good reason for this, but the concept of controlling volume on audio devices has existed since the dawn of computer audio. All other operating systems do this as expected. This is my main issue with using Apple devices. You either accept their vision of how to use the device you paid for, or consider yourself lucky that a 3rd-party solution exists (and that Apple has allowed to exist), which you also usually need to pay for. Insanity. [1]: https://old.reddit.com/r/macmini/comments/lgfjax/is_it_possi... reply saagarjha 6 hours agorootparentI assume the reason is that too many people don’t get audio over HDMI because one or the other volume controls is at 0. reply jval43 9 hours agorootparentprevBluetooth on Windows is a nightmare too. Headphones, keyboards, mice etc might work initially, but at some point they don't connect anymore and it's almost impossible to fix. Mac is better in that regard, unpairing and repairing usually works. On Windows it's just broken. It's why I only use hardware with fixed dongles (Jabra, Logitech, etc). reply EasyMark 15 hours agorootparentprevyou can fix it by buying a linux compatible laptop/pc or building one with known compatibility. reply avalys 15 hours agorootparentIt is impossible for a Linux-compatible PC to have a problem with Linux, because if a PC has a problem with Linux, it is obviously not Linux-compatible. Therefore, if you ever have a problem with Linux on your PC, it is your fault for expecting Linux to work on your non-compatible PC, and you cannot blame the difficulty of fixing the problem on Linux. reply fallous 14 hours agorootparentObviously you can avoid all of this by buying your Linux-compatible PC only from a True Scotsman. reply tap-snap-or-nap 13 hours agorootparentCan't find any Scotsman in Australia, let alone a true one. reply CalRobert 10 hours agorootparentWeird, I’m pretty sure plenty of Scots are in Australia. https://immi.homeaffairs.gov.au/what-we-do/whm-program/lates... reply defrost 10 hours agorootparentBon Scott didn't do a lot of PC support, but he did have a hand built amplifier from one of the early legends of the BBS scene. https://trevormarshall.com/bon.htm http://www.bbsdocumentary.com/photos/104marshall/index.html reply michaelmrose 13 hours agorootparentprevThis isn't a tautology. Plenty of hardware is in the set of hardware officially supported by manufacturer or oem under Linux or known to be well supported by open source drivers. If offical data is absent unoffocial data is oft readily available. If nothing would lead a reasonable person to believe it is supported then your default assumption should be that is likely not. If the functionality that one expects to work works as expected on supported hardware but not on yours then Linux isn't broken your hardware is. If it doesn't work on previously supported or otherwise well supported hardware its a bug in the software. It's weird that compatibly is discussed as if for the next 20 years one shall be forced to use a succession of randomly chosen machines and compatibility will ever be a crapshoot. Often people will initially try Linux on random machines but official Linux machines are out there and those who have decided that Linux meets their needs can easily find well supported hardware. reply dymk 15 hours agorootparentprevOh cool, all I have to do is buy new hardware when the software breaks during updates or when Mercury is in retrograde reply nine_k 13 hours agorootparentFrankly, the same is still true for Windows. Not all WiFi and BT devices are created equal. Sometimes an update breaks them in subtle ways. Actually, I had fewer compatibility problems with Linux than I had with Windows, using absolutely non-esoteric hardware, like Thinkpad laptops, Asus motherboards, etc. Hell, sometimes it was easier to set up a printer under Linux than under Windows (which, frankly, is more often the other way around). But usually Linux, and to a smaller extent, Windows, allows you to cobble your own solution if a solid predefined solution is not available. MacOS is much more often a \"my way or highway\" kind of environment. Some enjoy it; I don't. reply michaelmrose 13 hours agorootparentprevAlternatively buy laptops that come with Linux or at least are known to be well supported. Whenever I buy a new piece of hardware of any sort I end up reading lots of spec sheets, reviews, and articles and comparing choices according to a whole range of desirable features. Making Linux support one of them hardly makes it any more complicated. If nothing else search for product category + Linux then find a list of recommendations and then google choices that look good looking for unbiased critique focusing especially on people claiming systemic flaws in design that effect all units. reply wruza 14 hours agorootparentprevThis usually means you’re building/buying a 5yo “monster” that competes with your iphone. And even then it’s no guarantee. reply makeitdouble 8 hours agorootparentprev> deep-sleep Didn't Apple kill deep sleep/hibernation when transitioning to ARM ? It was touted as \"Always On Processor\" to mimic the iOS and iPadOS management of CPU and never shut it down. reply saagarjha 6 hours agorootparentNo, that does things like Hey Siri. reply bsder 15 hours agorootparentprevAs opposed to all the people who can't make a USB keyboard work with MacOS and can't do a damn thing about it. The thread about it generally reaches 40+ pages before Apple erases it only for it to come back. Apple has known about it for half a decade. I can pinpoint the OS release when they broke it. Sure, it doesn't seem to affect everybody, but the people it does affect have no recourse. With MacOS, as long as everything works, everything works. But, when it doesn't, you cannot do a damn thing about it. Linux very, very rarely leaves that kind of catastrophic bug for 5+ years. reply jabwd 14 hours agorootparentidk my xbox controller works on macOS, doesn't on Linux. Same bluetooth chipset (Magic of multiple drives and hackintoshing some crap). Idk what USB thing you're talking about but you surely seem to be capable of providing some actual useful info for people like me who would actually like to understand what you're talking about? reply icedchai 14 hours agorootparentprevWhen did it break, and why does it still work for me? (Mac Studio, M1 Max, macOS 15.2) reply bsder 10 hours agorootparentIt broke approximately 2018, and it works for most people. When it doesn't work, \"why\" it doesn't work is unclear, but it's very consistent for those of us to whom it happens. I tracked it to a single OS update because it was one of the last iterations that still had removable SSDs. I could swap the drives and the USB failure moved with the OS. It's almost certainly an overly zealous macOS USB HID driver. macOS will do very strange things if the HID descriptor and the USB report don't correspond exactly and it will do those weird things silently. People have had to work around strange macOS HID handling for quite a while now. reply mistercheph 10 hours agorootparentprevWhat hardware were you experiencing issues with wifi or bluetooth or sleep? reply kelnos 16 hours agoparentprevAnd not just that: if an update breaks my Linux install, I can figure out what broke it and roll back to an older version. Rolling back updates on macOS or Windows is just... not really a thing, at least not without a full reinstall, assuming you even have installation media for older versions these days. reply electroly 14 hours agorootparentIf you restart several times in succession after an update (e.g. if the machine is stuck in a boot loop), Windows automatically rolls back the update. If the machine boots but you still want to rollback manually, the option is available for a period of time after the update is installed in Settings under Windows Update > Advanced options > Recovery. It's true that once the period of time is up (something like 10 days), you can't rollback any more, but I think your statement about Windows is untrue enough to warrant a correction. Rollback of Windows OS updates is there and it works. I have relied on this functionality in actual real life practice. reply n144q 14 hours agorootparentprevYou can. Most Linux users can't -- I say 90%, if not 99%. Most Linux users are just users, many of which don't know how to use tar or xargs without looking it up, very few have the technical knowledge and capability of figuring out \"what broke it\". reply wruza 14 hours agorootparentI had it for a while. Then systemd came and everything changed. Can’t just grep logs and won’t bother learning how to handle that “journal”. Some programs don’t write logs at all, they just crash with an indicator in a systray that something crashed (the most useful info in the world, /s). Linux was being made by hackers who know how to debug things, not anymore. Now it’s new kids raised on rainbow unicorn nonsense. I feel myself in linux like I’m in early windows now, so what’s the benefit? reply mjx0 13 hours agorootparentHere's the command it sounds like you're looking for: `journalctl --grep=\"search string\"` You can limit it by time period like this: `journalctl --since=-6h --grep=\"search string\"` Note that there's a separate user journal (such as for things that show up with an indication in the systray), accessible like this when in a shell as that user: `journalctl --user --since=-6h --grep=\"search string\"` Also, if you really want, SysV still exists and works. You can setup a system with SysV and syslog-ng and have the good ol' service run system and flat log files back. reply wruza 5 hours agorootparentThanks, but today I avoid troubleshooting it, I just accept the roadblocks and escape to my windows+msys2 installation as soon as possible. I find this combination a better gnu-based system and better upside / downside balance, which is all I need on desktop. Even logs usually get written to text files cause windows system logs are rarely used by regular apps and unixy services. I’m not a gnu vs linux pedant, but gnu never let me down like that, and linux is really just an implementation detail underneath that I’m free to replace without compromising key functionality. reply akvadrako 10 hours agorootparentprevRollbacks on image based distros like Fedora Silverblue are as easy as selecting the old version on boot. Literally hitting down and enter. Besides that, you never wait for updates to install. reply com2kid 15 hours agorootparentprevWindows automatically save a restore point before updates are installed and rolling back - assuming the machine isn't bricked - is really simple. reply FredPret 15 hours agorootparentWindows Update once borked my overnight ML job to install “critical updates; reboot required” on my desktop. I bought a MacBook the next day and put Linux on that desktop. 100% happier. reply tonyedgecombe 10 hours agorootparentprevIt's a shame as APDS does support snapshots and they appear to work well. Having said that I could foresee problems with rolling back the system partition but not the data. reply bsder 15 hours agorootparentprevIt's actually really difficult to roll back a MacOS machine to an earlier OS even with a full reinstall. You either have to make MacOS backup disks immediately upon opening the machine, or you have to find MacOS installation disks from the dodgy high seas. reply tonyedgecombe 10 hours agorootparent>or you have to find MacOS installation disks from the dodgy high seas. Mist[1] downloads them directly from Apple. [1] https://github.com/ninxsoft/Mist or https://github.com/ninxsoft/mist-cli reply jasomill 10 hours agorootparentprevNot really difficult to reinstall every major Intel Mac OS release, at least, as they're all downloadable from Apple in one way or another: 1. You can reinstall \"the version of macOS that came with your Mac or the closest version that’s still available\" via Internet Recovery[1]. 2. You can download installers for every major release back to High Sierra from Apple via the App Store[2] or directly from Apple's update servers using a tool like installinstallmacos[3]. 3. You can download installers for Sierra, El Capitan, Yosemite, Mountain Lion, and Lion directly from the Apple support site[2]. 3. You can download Snow Leopard and Leopard from the Apple developer site[4] (free registration required; paid membership possibly required). Note that the downloads on the developer site are the 10.x.0 retail builds, which may not be compatible with all Macs that shipped with a later build. In this case, assuming the version you need is no longer available via Internet Recovery, you'll probably need to install and patch on an older machine, then transfer the patched install to the target via disk swapping, imaging, or NetInstall, or to install and patch directly to the target machine's hard drive using Target Disk Mode (or else track down a copy of the model-specific restore DVDs that shipped with the target). Downloads from the App Store and support site should always be the latest point release, so this should only be a problem if you want to install Snow Leopard or Leopard on a post-release machine. Installing non-final point releases is admittedly problematic: you can download some but not all x.y.0 builds from the developer site, some but not all patches from the support site, and a few x.y.(z dp and a secondary plugged into the hdmi port. When I stop working and swap to my personal computer I often shut off the secondary monitor all together and then change the input of my primary monitor. It is not kernel panicing. reply therein 12 hours agorootparentNot trolling, it panics for me. It came with 15.1.1. Let me see if I have a photo of the panic. If I'll post the backtrace. https://imgur.com/ycyVIzF reply chris_wot 9 hours agorootparentOh man… we have the same model CalDigit at work and it doesn’t panic but it does give refresh issues on the second screen. reply nbzso 13 hours agoprevA side rant with some useful information: I had a nightmare week with an office Mac Mini, 2018 . When the employee tried to update to Sequoia, he faced the error-try again conundrum. So logically, I introduced the restore option. Oh boy, what a shitshow. So after faced by 8 hours restore process option, I proceeded to USB installation. Due to T2 restriction, enabling the boot process in restore utility menu is mandatory. Surprisingly, this cannot be done without working installation and admin user. So installing the OS which was the default for the computer and booting again was the next step. Long story short, the Mini stopped working in the middle of the installation. No chime sound. No light. We decided that it is dead for good. And then I got mad. Perfectly working computer bricked by slow and buggy restore process. 8 hours? Did Apple have no money to afford more server speed from Akamai? Or deliberately f&cks up the process, users to go and buy the new stuff? HMM. Solution: So I proceeded to DFU mode with non-recommended cable USB2 to USB-C (from my Logitech mouse, with data capabilities.) You power up the mini by holding the startup button and push the power cable in. USB-C must be connected to the first thunderbolt port after the HDMI input. Then magically you have a connection in your host mac Finder and proceed to restore the T2 firmware. Install as usual from the USB stick and revive the Mini. P.S. Found bits and pieces to come up with this solution from hardware repair forums. If you call your Apple \"support\" you know the procedure. Come to the store and buy more. reply tropicalfruit 8 hours agoprev1st mistake: purchasing a post 2013 apple product 2nd mistake: installing an update on said product reply iamshs 8 hours agoprevTangential: I updated my iPhone 15 from 17 to 18.1 and got Safari crashes. Lost handoff capability from iPhone to MacBook, works perfectly the other way. Both of these problems are incredibly frustrating. reply amir734jj 9 hours agoprevMaybe it's just me, but I've been so used to Linux for so many years that I have a really hard time using either Mac (helping relatives) or Windows (for work). I use a system76 laptop and a system76 PC. It's perfect. reply commandersaki 9 hours agoparentWhat's the battery life of something like that under normal usage? reply trungpv1601 10 hours agoprevSo bad reply xyst 17 hours agoprevApple just can’t add features to their OS without breaking existing ones. Probably used Apple Intelligence to QA the OS release. Steve Jobs would be disgusted at what his company has become. “Just works”, my ass reply FredPret 16 hours agoparentOn the one hand, it looks like they're getting MBA'ed slowly: the product lineup is getting more tangled every year (just try picking an iPad) as they search for more ways to slice and dice the market. On the other hand: they created Apple Silicon in recent years. reply imbnwa 16 hours agorootparentDidn't they originally buy PA Semi while Jobs was on watch? reply filmgirlcw 14 hours agorootparentYes. The first A-series designs launched while Jobs was still alive. That said, from what I understand, a lot of the team was hired after. So it’s certainly not an indicator one way or another about the post-Jobs talent/innovation pipeline. reply rollcat 9 hours agoparentprevmacOS has been in a slow, steady decline for many years. Every major (or even minor) release brings new bugs, that often go unaddressed for months; the yearly mad push for new features leaves no room to fix things. At this point, I've installed an MDM profile to block major updates - planning to stick to 14.x until it's EOL, or only upgrading to an x.7 or x.8 when it's out. I really, really wish someone high up at Apple took a long hard look at OpenBSD release notes , and used that as a compass for planning the next macOS release. But apparently it's more important to chase the trends now. reply nerflad 16 hours agoparentprevI understand why you're getting downvoted but I also am in some form of agreement with the sentiment/hope they don't lose sight that they are pretty much keeping the dream of the consumer UNIX vendor alive. reply kevin_thibedeau 16 hours agorootparentYou don't matter to them. The \"What's a computer?\" ad shows what they care about. Do what they want and stay on the happy path. Otherwise, you're holding it wrong. reply anfilt 14 hours agorootparentOh gawd that commercial... Yea I remember that pretenious commercial and it's end line when she says \"What's a computer?\", and I was wtf really what your holding is a computer. Sure a computer where the boot loader is locked down to the point you can't even load your own signing keys or side-load, effectively taking away full ownership of the device from the owner, but it's still a computer. reply eviks 15 hours agoparentprevThe myth of Jobs would be disgusted, the real guy shipped the same reply tonyedgecombe 10 hours agorootparentOr worse even. Early versions of OS/X were very buggy. I think people look back at that era through rose tinted glasses. reply dwaite 8 hours agorootparentAfter all, the marketing message of no new features with Snow Leopard was because of the reputation of Leopard. reply cynicalsecurity 11 hours agoprevI'm amazed to people's reaction to this. You themselves have chosen to use a walled garden closed source OS. What did you expect? Apple not screwing you? Apple has been doing everything to hint they are turning macOS from general purpose OS into iOS-like nonsense. Why are you even surprised? Switching to Linux is long time overdue. reply quijoteuniv 10 hours agoprevMac use to be for tinkerers, that is not the case anymore, I loved to tinker with them 10 years ago, it was the only (reliable) platform you could work with sound. You bought a machine that would run years, people in studio would run many years with them, then they started to close it down more and more. I stopped working with sound but my old machine almost 20 years old still runs, out of tinkering with it i got into Linux, now i work in operations with k8s, creative, complex beatiful engineering reply iamnotsure 16 hours agoprevmanaged software, managed hardware, managed people reply alwayslikethis 16 hours agoparentOne of the worst things about the move to smartphones is the inability to make full backups. I don't understand. It's my own device, all the data belongs to me, and I should be able to back it up whenever I want. reply Reason077 15 hours agorootparentIt’s very easy on iOS to make a backup of your phone including all apps, settings, and data. Either to the cloud to locally to your own storage. What am I missing? reply wombatpm 15 hours agorootparentCloud does not work. If you have an app that is no longer available in the App Store, when you install from a backup you are out of luck because that app can’t be downloaded from the App Store. If you choose to manage your phone from a Mac, then you can save a full backup. reply inetknght 14 hours agorootparentprev> to the cloud to locally Requires payment for backup of any meaningful size. > locally to your own storage I don't own a mac. I own Linux. How do I backup iOS to my device? How do I restore it? reply noprocrasted 5 hours agorootparent> I own Linux Does idevicebackup/idevicerestore not work anymore? But agreed, there's no technical reason why the phone can't just accept normal USB-connected storage and store a file in there (in whatever proprietary/encrypted format it wants, but at least the _storage_ is standards-compliant). reply threeseed 13 hours agorootparentprevYou can run macOS or Windows inside a VM on Linux. reply prmoustache 8 hours agorootparentTecnically yes but slow as hell and you are using a software you are not licensed for in this case. reply akdev1l 13 hours agorootparentprevFrom Linux you literally cannot reply tonyedgecombe 10 hours agorootparentprev>I own Linux. That's the trouble with these niche desktop platforms, people don't write software for them. reply Cumpiler69 10 hours agorootparentIs windows also niche? reply prmoustache 8 hours agorootparentI think he meant iOS. reply alwayslikethis 15 hours agorootparentprevYou never had chat apps that don't let you back up the chats? How about login tokens, authentications? That counts too. Are you able to roll them back selectively when an app misbehaves? reply password4321 14 hours agorootparentprevFYI for anyone who just needs to backup using a Windows machine (for me: download hundreds/thousands of photos reliably), iMazing has worked well enough. reply kjkjadksj 14 hours agorootparentprevUnless something changed I believe on macos it has to back up to the system drive. I paid my $200 premium to get my 1tb drive on my laptop and my ios backups take up like 30% of that outright. In a perfect world I’d have a server that everything gets dumped to but macos and ios do not make that sort of setup very easy. There’s this ios issue. And people report issues with time machine over network. The whole ecosystem is a little screwed up. But yet I want their hardware so here I am dealing with the hoops they make me jump through. Always some poorly documented issue I run into like with their launchd or all the bullshit they make us now deal with for “security”. No issues when I write for work on centos of course, a proper os. What I would do for a macbook that shipped with no os. reply fluidcruft 13 hours agorootparentI was able to relocate the backup via symlink. reply userbinator 10 hours agorootparentprevIt's my own device That's what you think, but based on the actions of the companies doing this stuff, clearly they don't and strongly want you to be happy with owning nothing. reply realusername 15 hours agorootparentprevSome data is even completely unaccessible, like the app usage on Android. You can view it, but you can't export it in any shape or form. reply alwayslikethis 13 hours agorootparentIt seems like you can, with the usageDirect app. reply lopkeny12ko 13 hours agorootparentprev> the inability to make full backups Says who? I have been using this for years: adb backup -f backup.ab -apk -noshared -all -system reply josephcsible 12 hours agorootparentThe issue is that Android lets app developers set , and doesn't give the owner a way to override that. Your command will just skip any such apps. reply alwayslikethis 13 hours agorootparentprevApps can stop you from doing it, and many will, then it fails silently. It's also a deprecated feature. When I mean a full backup, I mean a bit for bit identical copy, not what the app developers think you should be able to access. reply ClassyJacket 14 hours agorootparentprevEven worse, now some apps are not allowing screenshots. That's bullshit, it's my phone, I should be able to screenshot whatever the hell I want. reply Pikamander2 10 hours agorootparentThe wildest one I've seen is Chrome on Android not allowing screenshots in Incognito mode. I'm struggling to understand the rationale there except maybe to prevent people from accidentally screenshotting sensitive stuff like porn or domestic violence resources? Either way, it's really not something the app should have control over. reply ahartmetz 9 hours agorootparentMy guess would be to stop surveillance apps from taking screenshots - is that a thing? reply josephcsible 12 hours agorootparentprevI'm not sure why you're being downvoted. You're 100% right. Android lets apps block screenshots with FLAG_SECURE, and iOS does too with https://github.com/JayantBadlani/ScreenShield, and neither one gives the owner of the phone a way to override that. reply catlikesshrimp 14 hours agorootparentprevThat is why many people complain about not really owning the device. And some others defend not owning the device because - cool reasons; and if someone owns his own device that breaks the magic for everyone involved, somehow /s Do something about it? Get an Android phone you can root and own your device; And if you feel you are missing something, slap an apple sticker on the back /s reply duxup 15 hours agorootparentprevBack when I used to play with roms in the Android world being able to back things up was neat… but also took a ton of space and was crazy cumbersome. I kinda prefer iCloud style backups. reply floydnoel 16 hours agoparentprevare you an anarchist, then? i am curious reply __MatrixMan__ 14 hours agorootparentI question the sanity of anyone who takes a good hard look at the world around them and isn't a little bit of an anarchist. reply SSNLF 16 hours agoprevtldr; sudo asr restore --source and all tools that just call that are no longer viable. reply jeffbee 16 hours agoprevGotta be honest, I find the idea of a bootable backup disk to be defective. What if it was an OS bug that wiped out your volume, and booting the backup does the exact same thing to the backup, because of the same bug? reply srhtftw 15 hours agoparent> Gotta be honest, I find the idea of a bootable backup disk to be defective Well, having relied on a similar product (Carbon Copy Cloner) to keep a bootable backup in addition to time machine backups for myself and members of my family to reduce MTTR for many years, I find the idea of being unable to trivially recover from a hardware failure in a few minutes to be defective. Any of our clones can be booted on any similar system. On a few occasions people have used borrowed machines until repairs were complete without relying on cloud or internet connectivity. Of course these are all older systems and working while booted from an external drive is definitely a degraded experience akin to driving on a spare tire until you can get to a proper service station. reply sonofhans 16 hours agoparentprevOh, I’ve used SuperDuper for years, and I adore it. Several years ago I had a spinning rust HD die in a Macbook. I plugged my backed drive into it, booted, and had access to all my stuff. Without that drive I would have needed another computer. I could keep going making a list of all the ways I’ve found a bootable clone of a MacOS machine to be useful, but damn, I’d hate to live without it. reply alwayslikethis 16 hours agoparentprevYou can roll back to a backup right before the OS update that caused the bug. For example I have hourly snapshots using btrfs. Each snapshot is entirely bootable by itself, so if I ever broke anything, I just roll back. The system snapshots are read-only, so they are unlikely to be destroyed by bugs like that. You can also just make another snapshot of the same snapshot to be safer. It's also separate from the user data I care about. reply radicality 16 hours agoparentprevI’m thinking similarly. I’ve been using normal Time Machine backups, together with iCloud (not really backup), occasional copies of data I care about to external SSDs, and occasional encrypted backups to remote storage (rsync.net) But it never even occurred to me to want a bootable backup or include the OS in it. In fact whenever I upgrade my MacBook, I choose to set it up as a fresh device and don’t use any of the tooling to copy everything-and-anything. reply perfectra1n 16 hours agoparentprevThe hope there would be that the backup is from before the OS bug reared its ugly head, so you can get what you need off of it. (or hope it doesn’t happen again) reply codazoda 16 hours agoparentprevYeah, I don’t understand system backups anymore. I keep everything I care about in a single directory and clone that to the cloud. I no longer need to worry about backups outside of this. It’s easy enough to install a fresh OS and restore my directory. I’ll need to install a few apps but I’ll also have a nice clean system to work with. reply eviks 15 hours agorootparentAnd if you have many apps and don't treat your carefully edited configs as dirt, you'll understand it'd be a giant waste of time to recreate from scratch reply avalys 15 hours agorootparentI don’t carefully edit any configs. I try to be productive with the default/recommended configuration as much as possible, and be flexible when things change rather than fight to restore the familiar behavior. Otherwise you’re constantly fighting a lonely battle. reply eviks 15 hours agorootparentYou don't need to fight anything, yo can be just as flexible, just starting from a much better base that the defaults. But this is not about you, but the inability to understand the value of backing up apps and their configs reply wruza 14 hours agorootparentprevYou cannot be productive with the default configuration. You’re just telling it to yourself, but it really sucks. reply datadrivenangel 13 hours agorootparentWhat are key configuration that needs to be changed? reply wruza 6 hours agorootparentPrevent taskbar from collapsing apps into a single icon. reply jeffbee 13 hours agorootparentprevAre you sure you measured your net productivity, deducting the config editing and the evangelism? reply exabrial 12 hours agoprev [–] This is a perfect move from an environmentally focused company! This will totally help reduce ewaste and anyone supporting the environment should totally absolutely undeniably without question of common sense just buy all of their products!!!!!!!!! reply talldayo 12 hours agoparent [–] Mother Nature just got a call that her first check cleared, she's very excited for the future of Apple's courageous new direction for e-waste management. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A significant issue with macOS 15.2 disrupts the replicator, causing a Resource Busy error during data replication, affecting third-party OS copying.",
      "Users are advised to use \"Backup - all files\" with \"Smart Update\" to back up data, excluding the operating system, until Apple provides a fix.",
      "The bug, identified as FB16090831, is unlikely to be resolved soon due to the holiday season, as reported by Dave Nanian from Shirt Pocket."
    ],
    "commentSummary": [
      "macOS 15.2 has disrupted the functionality of creating bootable backups using tools like SuperDuper and potentially Carbon Copy Cloner, causing user frustration.",
      "The issue arises from Apple's restrictions on third-party tools, limiting their ability to manipulate the OS, and rendering the built-in utility ineffective.",
      "Users are concerned about Apple's increasing control over their devices, likening it to a \"walled garden\" approach, and some are considering switching to alternatives like Linux."
    ],
    "points": 346,
    "commentCount": 279,
    "retryCount": 0,
    "time": 1734138264
  },
  {
    "id": 42412360,
    "title": "Sharing new research, models, and datasets from Meta FAIR",
    "originLink": "https://ai.meta.com/blog/meta-fair-updates-agents-robustness-safety-architecture/?_fb_noscript=1",
    "originBody": "Our approach Research Product experiences Llama Blog Try Meta AI Open Source Sharing new research, models, and datasets from Meta FAIR December 12, 2024• 11 minute read Takeaways Today, Meta FAIR is releasing several new research artifacts that highlight our recent innovations in developing agents, robustness and safety, and architectures that facilitate machine learning. The work we’re sharing advances our goal of achieving advanced machine intelligence and includes Meta Motivo, a foundation model for controlling the behavior of virtual embodied agents, and Meta Video Seal, an open source model for video watermarking. We aim to democratize access to state-of-the-art technologies that transform our interaction with the physical world, which is why we're committed to fostering a collaborative and open ecosystem that accelerates progress and discovery. As we continue to work towards our goal of achieving advanced machine intelligence, we want to share our progress with the research community so they can build upon our work. Today, we’re excited to release some of the latest research, code, models, and datasets from Meta Fundamental AI Research (FAIR). The artifacts we’re sharing today focus on building more capable agents, robustness and safety, and architecture innovations that enable models to learn new information more effectively and scale beyond current limits. In this release, we’re sharing a demo and code for Meta Video Seal, an open source model work video watermarking that builds on the popular Meta Audio Seal work we shared last year. We’re also sharing a variety of other artifacts, including a foundation model for controlling the behavior of virtual embodied agents, a method for scaling memory layers that will enable more factual information, and code to help models become more socially intelligent. There’s plenty more to explore in this post with nine total projectsand artifacts ready for people to download and start using today. This work supports our long and proven track record of sharing open reproducible science with the community. By publicly sharing our early research work, we hope to inspire iterations and ultimately help advance AI in a responsible way. As always, we look forward to seeing what the community will build using these new releases and continuing the dialogue about how we can all advance AI together responsibly and build for the greater good. Meta Motivo Unsupervised reinforcement learning involves pre-training models to solve a wide range of downstream tasks in complex environments. Most methods require highly curated interaction datasets and often rely on unsupervised losses that lead to policies that may not align well with target tasks. Today, we’re sharing Meta Motivo, a first-of-its-kind behavioral foundation model that controls the movements of a virtual embodied humanoid agent to perform complex tasks. Meta Motivo is trained with a novel algorithm that leverages an unlabeled dataset of motions to ground unsupervised reinforcement learning towards learning human-like behaviors while retaining zero-shot inference capabilities. The key technical novelty of our algorithm is to learn a representation that can be used to embed states, motions, and rewards into the same latent space. As a result, Meta Motivo is able to solve a wide range of whole-body control tasks, including motion tracking, goal pose reaching, and reward optimization, without any additional training or planning. Meta Motivo achieves competitive performance compared to task-specific methods and outperforms state-of-the-art unsupervised reinforcement learning and model-based baselines, while exhibiting more human-like behaviors. The model also displays a surprising level of robustness to changes in the environment, such as gravity, wind, or direct perturbations, despite not being trained for them. In the future, we believe this research could pave the way for fully embodied agents in the Metaverse, leading to more lifelike NPCs, democratization of character animation, and new types of immersive experiences. Read the paper Try the demo Download the code and model Meta Video Seal While AI tools can help bring the world closer together, it’s important that we implement safeguards to mitigate the risks of imitation, manipulation, and other forms of misuse that can undermine their benefits. Post-hoc watermarking is a crucial step towards better traceability for content and AI models. Today, we’re releasing Meta Video Seal, a state-of-the art comprehensive framework for neural video watermarking. Video Seal adds a watermark (with an optional hidden message) into videos that is imperceptible to the naked eye and can later be uncovered to determine a video’s origin. The watermark has proven resilience against common video editing efforts like blurring or cropping, as well as compression algorithms commonly used when sharing content online. We’re publicly releasing the Video Seal model under a permissive license, along with a research paper, training code, and inference code. A demo is also available to try the model out interactively. Along with Video Seal, we’re also releasing Meta Omni Seal Bench, a leaderboard dedicated to neural watermarking covering several modalities, enabling the research community to easily test and add their own work in the field. We’re also re-releasing our Meta Watermark Anything model under a permissive license and will organize a workshop on watermarking at ICLR in 2025. This research is a testimony to our commitment to responsible AI. We hope that other researchers and developers will join our efforts by integrating watermarking capabilities when building generative AI models. Watermark Anything, Video Seal, and Audio Seal—our previous work on post-hoc audio watermarking—are now all available for download and ready to be integrated. Read the paper Try the demo Download the Video Seal code and model Download the Watermark Anything code and model View the Omni Seal Bench leaderboard Flow Matching guide and codebase, a Meta FAIR release Flow Matching is a state-of-the-art generative paradigm for many modalities including generation of images, videos, audio, music, 3D structures like proteins, and more. Our method has already replaced classical diffusion in many generative applications at Meta, including Meta Movie Gen, Meta Audiobox, and Meta Melody Flow, and across the industry in works such as Stable-Diffusion-3, Flux, Fold-Flow, and Physical Intelligence Pi_0. Flow Matching provides a simple yet flexible generative AI framework, improving performance and efficiency while allowing easy generalization to complex data. Today, we’re sharing a paper and code, including core implementations of both continuous and discrete Flow Matching, alongside state-of-the-art training scripts to enable the research community to easily use and iterate on the Flow Matching method. By publicly sharing this work, we hope to inspire wider adoption of Flow Matching and enable people to use it in their own generative projects. Read the paper Download the code Meta Explore Theory-of-Mind A key aspect of our social intelligence enables us to reason about the thoughts and beliefs of other agents, both human and artificial. Existing Theory-of-Mind (ToM) datasets have limitations, focusing solely on evaluation and depicting only a narrow range of interactions. To address this and move closer to achieving advanced machine intelligence, we introduce Meta Explore Theory-of-Mind, a program-guided adversarial data generation for theory of mind reasoning. Our novel framework enables the generation of diverse, challenging, and scalable ToM reasoning data for both training and evaluation, which will help accelerate progress in this critical area of research. Explore Theory-of-Mind generates robust and reliable stories that push the limits of large language models (LLMs), making it ideal for evaluating frontier models or fine-tuning data, resulting in significant improvements on classic theory of mind benchmarks. Our first-of-its-kind approach led to a 27-point accuracy improvement on the commonly used ToMi benchmark when fine-tuning a Llama-3.1 7B model, which means unprecedented accuracy in evaluating the theory of mind training data. Explore Theory-of-Mind can be used to generate datasets for improving LLMs, enhance goal-oriented scenarios, and collect interaction datasets, while also serving as a benchmark for evaluating LLM performance. Read the paper Download the code Download the dataset Meta Large Concept Models As we work toward advanced machine intelligence, models will need to be able to reason across languages and modalities and to excel at long-form generational capabilities that require explicit hierarchical thinking, such as writing an essay. Current mainstream language modeling approaches typically operate at the token level and don’t explicitly reason in a hierarchical manner. Today, we’re introducing a fundamentally different training paradigm for language modeling: the Large Concept Model (LCM). The core idea of the LCM is to decouple reasoning from language representation, and it’s inspired by how humans can plan high-level thoughts to communicate. For example, when giving a presentation multiple times, a presenter always has the same series of ideas they want to convey (materialized by their slides projected on screen), but their exact choice of words might vary from one run to the other. Guided by that principle, the LCM is a significant departure from a typical LLM. Rather than predicting the next token, the LCM is trained to predict the next concept or high-level idea, represented by a full sentence in a multimodal and multilingual embedding space. Our work explores how predictions can be made for text in such a continuous space. Overall, the LCM outperforms or matches recent LLMs in the pure generative task of summarization, offers strong zero-shot generalization to unseen languages, and is more computationally efficient as input context grows. We hope the research community uses this work to improve language models that can operate on any modality or language, in an explicit hierarchical manner. Read the paper Download the code Meta Dynamic Byte Latent Transformer Language models assume text has been tokenized in a heuristic preprocessing step, breaking words into smaller units that are easier to process. This limits end-to-end learning, is difficult to optimize in practice, and can hurt performance on rare text sequences. To address this, we’re introducing Dynamic Byte Latent Transformer, a hierarchical byte-level (tokenizer-free) model with dynamic patching schemes that are able to operate over bytes—without any tokenization heuristics—while also improving efficiency for long sequences during training and inference. Dynamic Byte Latent Transformer outperforms tokenizer-based models across the board in terms of robustness, with a seven point advantage on average, and excels at processing longtail and rare sequences of unseen symbols. By sharing this work, we hope to accelerate advancements that will enable us to better reason over a variety of domains that are important to advanced machine intelligence, including low resource languages, coding, and factuality. Read the paper Download the code Meta Memory Layers Parametric memory, the repository of factual information stored in the weights on a neural network during pretraining, enables LLMs to understand complex concepts and linguistic nuances. As current scaling methods approach their limit of efficient scaling, new architectures that enable models to learn information more effectively must be explored. Today, we’re sharing a research paper and code for Meta Memory Layers at Scale, a method for scaling memory layers that enables an increase in factuality against commonly used benchmarks as we work toward achieving advanced machine intelligence. Memory Layers use a trainable key-value lookup mechanism to add extra parameters to a model without increasing FLOPs. Sparsely activated memory layers complement the compute-heavy nature of dense feed-forward layers, providing dedicated capacity to store and retrieve information cheaply. On downstream tasks, language models augmented with our improved memory layer outperform dense models with more than twice the computation budget, as well as MoE models when matched for both compute and parameters. Contrary to the prevailing perception in the field that sparse memory architectures cannot be scaled competitively, we demonstrate efficient scaling of sparse memory layers up to 128 billion parameters and 8B base models, with significant improvements at comparable compute across the board for commonly used factuality benchmarks. Read the paper Download the code Meta Image Diversity Modeling This year, FAIR has focused on research to better understand and develop new methods for the safe development of image generation models. Today, we’re announcing updates on this research and releasing a comprehensive evaluation toolbox for text-to-image generative models. The image generation model we’ve developed through the course of this research builds on our prior research on generative models’ architectures and losses and prioritizes generating images that are representative of the physical world while maintaining competitive image quality with state-of-the-art models. To further the research into new methods and techniques for responsible development, we’re collaborating with external experts, whom we’re inviting to use our model to carry out research in areas that can help us to improve the safety and responsibility across image diversity modeling. This initiative highlights our commitment to collaborating with the wider AI research community to collectively advance AI responsibility. Additionally, we will be open sourcing a comprehensive evaluation toolbox for text-to-image generative models to improve the ease and reproducibility of image generation benchmarking while promoting interpretable takeaways that inform future responsible text-to-image research. Through our continued work, we hope to better understand and offer new methods for responsible development of image generative models that can be adopted by the broader research community. Read the paper Download the code Meta CLIP 1.2 We’re excited to release Meta CLIP 1.2, a milestone in our ongoing efforts to develop a high-performance vision-language encoder. We have been working on advanced algorithms to effectively curate and align vast amounts of image-text data, unlocking the learning of human knowledge about the world. This enables our models to learn efficiently and accurately, capturing the nuances of fine-grained mapping between image and language semantics. Large-scale, high-quality, and diverse datasets are essential for building foundation models that can learn about the world. Meta CLIP is our effort towards building such datasets and foundation models. To ensure a high-quality and safe vision-language encoder foundation model, we’ve developed algorithms to effectively curate and align data with human knowledge from vast data pools, enabling our models to learn efficiently and cover all possibilities. We also conducted rigorous data research while applying robust integrity and privacy-protective measures. By releasing our data algorithms, training recipes, and foundation models trained on our curated dataset, we’re providing researchers and developers with the tools they need to advance the field of vision-language understanding. These foundation models can be used as vision encoding for MLLM, multi-modal embedding for retrieval, and zero-shot classification, while serving as a starting point for research on data quality. Additionally, our algorithms and training methods can also be used to create high-quality, large-scale, CLIP-like datasets from scratch, which can help with new research or production use cases. Read the paper Download the dataset Download the code Download the model Share: Our latest updates delivered to your inbox Subscribe to our newsletter to keep up with Meta AI news, events, research breakthroughs, and more. Join us in the pursuit of what’s possible with AI. See all open positions Related Posts Computer Vision Introducing Segment Anything: Working toward the first foundation model for image segmentation April 5, 2023 Read post FEATURED Research MultiRay: Optimizing efficiency for large-scale AI models November 18, 2022 Read post FEATURED ML Applications MuAViC: The first audio-video speech translation benchmark March 8, 2023 Read post Our approach About AI at Meta Responsibility People Careers Research Infrastructure Resources Demos Product experiences Meta AI AI Studio Latest news Blog Newsletter Foundational models Llama Our approach Our approachAbout AI at MetaResponsibilityPeopleCareers Research ResearchInfrastructureResourcesDemos Product experiences Meta AIAI Studio Latest news Latest newsBlogNewsletter Foundational models Llama Privacy Policy Terms Cookies Meta © 2024",
    "commentLink": "https://news.ycombinator.com/item?id=42412360",
    "commentBody": "Sharing new research, models, and datasets from Meta FAIR (meta.com)293 points by ilaksh 21 hours agohidepastfavorite53 comments cube2222 20 hours agoThere’s honestly so much interesting stuff here, esp. the llm-related things - large concept models (operating on and predicting concepts, not tokens), dynamic byte latent transformers (byte-level alternative to standard tokenization), sparse memory layers (successfully scaling key-value memory layers without an increase in computational requirements). Here they are presented as separate things, each of which apparently improves quality / efficiency. I wonder what the quality / efficiency increase is of all those methods put together? Maybe that’s what Llama 4 will be? This looks like a lot of innovation is happening at Meta in those areas, really cool! reply ms8 3 hours agoparentI hope that Llama 4 or 5 will have a different architecture. All released llamas are +/- same inference with a better training pipeline. The downside is that llamacpp will probably not be able to run new models and maybe it will be too much big rewrite, so we will need new c,cpp,go,rust programs. reply janeway 6 hours agoparentprevSide track, but does anyone have suggestions about how to better present such content. I am struggling with similar docs/demos. As a documentation page, each section is laid out uniformly with section heading, content, link to code and link to paper. However the page itself is a blog post which will be difficult to find again next year. Are there other examples of companies having well presented technical summaries which remain findable from the hime page? reply airstrike 3 hours agorootparentI'd put a table of contents-like page up front with some exciting short description of each section and use hyperlinks, allowing the user to navigate to the section and back reply airstrike 20 hours agoprevThis is so cool! Playing around with the first demo is a lot of fun. First one to get the model to moonwalk wins. My best attempt was probably something like `(body_speed_forward1.0) * (stay_still > 0.2) * (body_speed_vertical0.9)` https://i.imgur.com/O5hGMo5.gif Then the \"Meta Explore Theory of Mind\" is even more interesting. There was a thread about a month ago in which some of us were discussing some of the concepts here like \"beliefs\" and updating a model of the world accordingly. https://news.ycombinator.com/item?id=42035985 reply ks2048 16 hours agoprevWhen I wonder about the business behind Meta doing this, I see they have $70B in cash, so giving a bunch of AI experts hundreds of millions is pocket change. reply wrsh07 15 hours agoparentImagine that something fundamental shifts in the world of AI research. It could be anything: AI suddenly makes programmers much more productive, AI becomes very good at identifying vulnerabilities, AI chat becomes a new major source of entertainment, AI images become an item popularly shared on Instagram (etc) Suppose any one of these things happened and suddenly Facebook wished that it had access to state of the art models so that it could customize them for its uses (internal developers or tools, embedding in their app). Imagine how they would feel if the only way they could access these models were by signing 7-9 figure deals with a model dealer like OpenAI. Even worse, imagine if one of their main competitors in advertising started providing robust AI tools to help advertisers adapt their creatives to various form factors. Facebook is now way behind and possibly has to shell out millions to a company like OpenAI all while also losing ad market share worth billions per quarter (ads on Google start performing much better, so Google gets more ad spend) If this worst case scenario came to pass, Facebook would look foolish. If even one of these things were likely their investments make sense. The rest (open source, make meta a cool place to work) are a strategy credit. reply aoanevdus 16 hours agoparentprev“Commoditize you complement” may be a good way of framing it. Consider that if OpenAI succeeds dramatically and is the only game in town, they could extract huge rents for anyone using their service. So it’s in other companies interests (or anyone who wants to use AI) that the AI ecosystem have lots of competition to keep prices low. reply sangnoir 10 hours agoparentprevThose AI experts are a played a critical role in Meta getting that $70B in the first place reply cma 10 hours agoparentprevYou can't have enough top researchers without letting them publish. reply almostgotcaught 10 hours agoparentpreveveryone that has responded so far has it wrong (naively so). FB sells ad space on several apps. those apps needs people on them in order for the ad space to be worth anything. people, in turn, need content to attract them to the apps. so it's simple: enable people/companies/whomever to generate tons of content for cheap and consequently share it on the apps. that's it. reply SideQuark 5 hours agorootparentExcept giving out the tools makes easier for competitors like TikTok to do the same, drawing revenue away from meta. So that’s not it. Naively so. reply tzs 2 hours agorootparentCouldn't the same argument be made for all kinds of things companies have made open? Some examples: • Tesla gave away its EV patents. • Pixar and DreamWorks have both open-sourced some of their tools, including tools used to make some of their best works. For example DreamWorks' MoonRay renderer has been used on everything they have done since \"How to Train Your Dragon: The Hidden World\", including \"Puss in Boots: The Last Wish\" and \"The Wild Robot\", and will be used on their upcoming films. • Facebook open-sourced React. • Google open-sourced Chromium. reply bee_rider 1 hour agorootparentIn the case of Tesla, if you want to sell cars, you benefit from open up your charging tech, right? reply mttddd 1 hour agorootparentprevthe tools but not necessarily the data, presumably they have internally trained versions reply mttddd 1 hour agorootparentprevcontent but also better ad targetting by better understanding all of the content that users post reply modeless 19 hours agoprevI really hope Dynamic Byte Latent Transformers work out. Death to tokenizers! Interesting that it's a a hierarchical structure but only two levels of hierarchy. Stacking more levels seems like an obvious direction for further research. reply entilzha 11 hours agoparentAuthor here :), I do think it’s a good direction to look into! That said, aside from it being a bit too much to do at once, you’d also have to be careful about how you distributed your FLOP budget across the hierarchy. With two levels, you can make one level (bytes/local encoder) FLOP efficient and the other (patches/global encoder) FLOP intensive. You’d also need to find a way to group patches into larger units. But ya, there are many directions to go from here! reply Permik 10 hours agorootparentIn a way I'm kinda sad that if tokenizers will go the way of the dinosaurs as asking someone to give me a Unicode character from the private use area was one of the last ways you could actually distinguish a co-operative human from an LLM online They simply don't have those characters tokenized, so they can't output them. (But this is technically moot if the LLM has a python interpreter handy) reply mtkd 5 hours agoprevI was fortunate to get to a talk by Ross Taylor ex-Meta recently at the AI Engineer London meetup He's recorded the full talk here now: https://www.youtube.com/watch?v=S5l5OvJ01ws I had missed how much Meta have been doing on reasoning, ToM etc. reply intalentive 18 hours agoprevEvery time I have to clean text I wonder why I haven’t just trained a byte level denoising autoencoder to handle it for me. reply puttycat 19 hours agoprevCan someone explain how watermarking AI videos voluntarily helps make AI safer? reply benatkin 19 hours agoparentIt lets those providing AI video generation services watermark all of their videos. So it isn't intended to by voluntary. You would be left with those services that don't comply with whatever the current Big Tech rules are, like people who used Grok/X.ai to generate images in support of Trump despite Grok/X.ai being inferior. https://arstechnica.com/information-technology/2024/08/musks... reply refulgentis 13 hours agorootparentThink this the wrong / older article - when I click the link, this is twitter's hosted Flux model making pictures of Kamala and Trump flying into the world trade center and Trump on a surfboard with busty cat girls. The X.ai one launched this week reply sangnoir 10 hours agorootparentX hosted a white-label Flux model for a while, and freely admitted so . reply refulgentis 2 hours agorootparentCorrect, that's how I know :) reply bee_rider 1 hour agoparentprevHow much does it take to train a model at this point? I’d tend to expect that it’ll be in range of any major state or most oligarchs in the next couple years (if it isn’t already). So, making it is probably best of everybody understands the watermarking to be voluntary. Images and videos aren’t worth the bits they are printed in at this point, as evidence of anything in particular. reply pkkkzip 20 hours agoprevmeta has certainly redeemed itself and helping AI become moat-free reply ponector 19 hours agoparentThey still ruin society with the Facebook, no matter how much good they do with LLM. reply bubaumba 14 hours agorootparentLike it or not Meta is a major player in AI world with its free models and tools. As for social impact of the rest it's debatable. I personally don't have active social accounts, and not sure this is good. reply mupuff1234 13 minutes agorootparentLike it or not the social impact isn't really debatable, there's a decent amount of evidence, enough for the surgeon general Dr to issue a warning: https://www.hhs.gov/about/news/2023/05/23/surgeon-general-is... reply croes 12 hours agorootparentprevFree by accident. reply dailykoder 11 hours agorootparentprevThey are not free reply echelon 19 hours agoparentprevEven though Meta doesn't sell I/PaaS, Meta's fitness goes up when AI is in the hands of more players than just Google and OpenAI. Commoditize AI and you create a diverse set of businesses that will reach customers through Meta's platforms. reply mupuff1234 19 hours agoparentprevIt's not redeeming if you still continue with the original sin. reply SpaceManNabs 17 hours agoprevThis is like learning 10 different new architectures lol reply Flomolok 19 hours agoprevIt's not a hype when it's delivers and I'm also not seeing a ceiling yet Yet again interesting progress. Also I like the idea of using the pose model to generate not a NPC but a avatar living in my phone or glas cube as a hologram. That would be quite scifi futuristic reply bbor 18 hours agoprevCrazy stuff. Everyone’s covering how exciting all these are (especially LCM and the non-tokenizing-tokenizer), but I have to ask in case anyone’s been paying attention: why are they using the term “advanced machine intelligence”? My initial thought is that they want to please/distract the doomers, but I’m prolly just self-centered! reply rajman187 18 hours agoparentIt originates in Yann LeCunn’s paper from 2022 [1], the term AMI being district from AGI. However, the A has changed over the past few years from autonomous to advanced and even augmented, depending on context [1] https://openreview.net/pdf?id=BZ5a1r-kVsf reply esafak 14 hours agoparentprevI think Lecun doesn't like the term AGI. reply devmor 18 hours agoparentprevI would guess it’s in response to the recent market studies showing that the general public views anything labeled “AI” as a likely scam and untrustworthy. reply vouaobrasil 20 hours agoprevnext [6 more] [flagged] dang 19 hours agoparent\"Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something.\" https://news.ycombinator.com/newsguidelines.html reply lukemerrick 19 hours agoparentprevMeta is a very large organization, and I'm willing to believe that a good chunk of Meta FAIR (the lab releasing all of this stuff) truly do care about innovations for advancing AI safety and are doing great work along these lines. I'm not disagreeing with your point about the company being led by its financial incentives as a unit, but let's also allow ourselves permission to celebrate this work by this group of people. reply causalmodels 19 hours agoparentprevSafety and capabilities research are pretty much two sides of the same coin. reply bigs 20 hours agoparentprevDon’t you love the doublespeak of using “FAIR” as well! reply th0ma5 18 hours agoparentprevIt is a shame that this is flagged for being denigrating or negative. The better comment could be to ask where is the documentation for safety? How do we define it? Where are the disclosures about failures, negative results, etc? Perhaps these things are unanswerable, but raising awareness of them is important. reply Roccan 17 hours agoprevMeta's \"Video Seal\": Because nothing says \"trustworthy\" like a digital chastity belt. Imperceptible, they claim, yet robust enough to survive the gauntlet of internet mangling - sounds like the perfect tool to invisibly track content, not just watermark it. reply Rastonbury 11 hours agoparentI think it's reasonable to assume that any large social media company is already tracking video similarity in reuploads/edits. The remix and reused audio features are already baked in. Reverse image search screen caps of tiktok/reel pretty often return the source/original reply logicchains 11 hours agorootparentIt seems such tracking can be gotten around by something as simple as sticking a Subway Surfers clip underneath the video, given how common that is. reply redleader55 16 hours agoparentprevI want to have a way to detect if content is AI generated. You might want to run that model on your own creations to ensure you get the credit for them and that no one can steal them. reply UltraSane 13 hours agoparentprevLike all tools it can be used for good and evil. It could be installed directly in cameras to sign videos. And people with the power to turn it off could make AI fake videos that much more believable. reply idle_zealot 9 hours agorootparentI would make the argument that these AI safety initiatives yield messaging that muddles and confuses the public on the simple fact that they should not, under any circumstances, use a video or image as proof or assume its veracity. When I tell someone this it is common for them to come back with something like \"aren't they working on things to detect if a video is fake?\" I think this idea, that video content can still be trusted and that {COMPANY} is being responsible is the real goal of the money pumped into these watermarking techniques. These techniques will not actually help people, images and video will continue to be used for disinformation. The only thing that can stymie that is a broad cultural shift to default to distrust of photographs and video footage, to treat it all like you might a painting or animated cartoon depicting an event; maybe an accurate portrayal, but just as easily totally fabricated. The responsible thing for companies to do would be to spread messaging indicative of this fact, but they would rather engage in safety theater and score some points while keeping users dumb and easily fooled. reply nurumaik 9 hours agoprev [–] https://dontfuckwithscroll.com/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Meta FAIR has released new open-source research artifacts to advance machine intelligence, including Meta Motivo and Meta Video Seal.- Meta Motivo employs unsupervised reinforcement learning to enable human-like behaviors in virtual agents, while Meta Video Seal offers robust video watermarking capabilities.- Additional releases include Flow Matching for generative AI, Meta Explore Theory-of-Mind for social intelligence, and Meta Large Concept Models for hierarchical language reasoning, highlighting Meta's commitment to responsible AI development and collaboration with the research community."
    ],
    "commentSummary": [
      "Meta FAIR is introducing new research, models, and datasets, highlighting innovations such as large concept models, dynamic byte latent transformers, and sparse memory layers to enhance AI quality and efficiency.",
      "There is speculation about these advancements being integrated into future models like Llama 4, indicating Meta's strategic investment in AI to maintain competitiveness and reduce dependency on external providers.",
      "The discussion emphasizes the significance of open-source contributions and the potential influence of AI on content generation and ad targeting."
    ],
    "points": 292,
    "commentCount": 53,
    "retryCount": 0,
    "time": 1734124028
  },
  {
    "id": 42415122,
    "title": "Byte Latent Transformer: Patches Scale Better Than Tokens",
    "originLink": "https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/?_fb_noscript=1",
    "originBody": "Our approach Research Product experiences Llama Blog Try Meta AI NLP Byte Latent Transformer: Patches Scale Better Than Tokens December 12, 2024 Abstract We introduce the Byte Latent Transformer (BLT), a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the primary units of computation. Patches are segmented dynamically based on the entropy of the next byte, allocating more compute and model capacity where increased data complexity demands it. We present the first flop controlled scaling study of byte-level models up to 8B parameters with 4T training bytes. Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed-vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size. Download the Paper AUTHORS Written by Artidoro Pagnoni Ram Pasunuru Pedro Rodriguez John Nguyen Benjamin Muller Margaret Li Chunting Zhou Lili Yu Jason Weston Luke Zettlemoyer Gargi Ghosh Mike Lewis Ari Holtzman Srini Iyer Publisher arXiv Research Topics Natural Language Processing (NLP) Related Publications December 12, 2024 NLP CORE MACHINE LEARNING Memory Layers at Scale Vincent-Pierre Berges, Barlas Oguz December 12, 2024 Read the Paper December 12, 2024 HUMAN & MACHINE INTELLIGENCE NLP Explore Theory-of-Mind: Program-Guided Adversarial Data Generation for Theory of Mind Reasoning Melanie Sclar, Jane Yu, Maryam Fazel-Zarandi, Yulia Tsvetkov, Yonatan Bisk, Yejin Choi, Asli Celikyilmaz December 12, 2024 Read the Paper December 11, 2024 NLP Large Concept Models: Language Modeling in a Sentence Representation Space The LCM team, Loic Barrault, Paul-Ambroise Duquenne, Maha Elbayad, Artyom Kozhevnikov, Belen Alastruey, Pierre Andrews, Mariano Coria, Guillaume Couairon, Marta R. Costa-jussa, David Dale, Hady Elsahar, Kevin Heffernan, João Maria Janeiro, Tuan Tran, Christophe Ropers, Eduardo Sánchez, Robin San Roman, Alexandre Mourachko, Safiyyah Saleem, Holger Schwenk December 11, 2024 Read the Paper December 11, 2024 NLP COMPUTER VISION Meta CLIP 1.2 Hu Xu, Bernie Huang, Ellen Tan, Ching-Feng Yeh, Jacob Kahn, Christine Jou, Gargi Ghosh, Omer Levy, Luke Zettlemoyer, Scott Yih, Philippe Brunet, Kim Hazelwood, Ramya Raghavendra, Daniel Li (FAIR), Saining Xie, Christoph Feichtenhofer December 11, 2024 Read the Paper See All Papers Help Us Pioneer The Future of AI We share our open source frameworks, tools, libraries, and models for everything from research exploration to large-scale production deployment. Join our Team Our approach About AI at Meta Responsibility People Careers Research Infrastructure Resources Demos Product experiences Meta AI AI Studio Latest news Blog Newsletter Foundational models Llama Our approach Our approachAbout AI at MetaResponsibilityPeopleCareers Research ResearchInfrastructureResourcesDemos Product experiences Meta AIAI Studio Latest news Latest newsBlogNewsletter Foundational models Llama Privacy Policy Terms Cookies Meta © 2024",
    "commentLink": "https://news.ycombinator.com/item?id=42415122",
    "commentBody": "Byte Latent Transformer: Patches Scale Better Than Tokens (meta.com)223 points by zxexz 12 hours agohidepastfavorite52 comments PaulHoule 4 hours agoThe summer that BERT came out I was working at a startup that was using character-based CNN models for classification. We were thinking a lot about alternate representations, other members of the team were keen on word vectors but I wasn't, particularly because it seemed the documents were were working on frequently had out-of-dictionary words, because those words were important, and because discarding them would lead to failure. (We were working on \"foundation models\" too, so it's not just being out-of-dictionary in the final model that's a problem but being out-of-dictionary in the foundation model which is more expensive to train.) We were doing OK with character based models for classification but people believed that storing the \"dictionary\" inside the neural net was not a good use of the neural net so there was a lot of enthusiasm for tokens. Meanwhile I felt so sure that schemes like Word2Vec were doomed that I had left an earlier project using RNNs where the goal was text understanding with a foundation model made by training an RNN to write fake abstracts for case reports from PubMed. When byte-pair encoding was introduced I remember telling people in a meeting that it was the first tokenization scheme we'd looked at that I could endorse. I have to admit though that I wish we could work at the character label. reply yndoendo 2 hours agoparentDo you mean that all produced output must be a chain or words found in a dictionary? The real-world for humans has them creating and using non-dictionary words to communicate daily. A good example is \"notify\", defined in the dictionary. \"notifier\", which is not and is used to describe \"a means to notify someone\". The code to send an email notification is an \"email notifier\", then there is text message, voice call, call center call back notifiers .... All industries and organizations have jargon, custom defined words not found in a dictionary and use non distinctive acronyms. How would a ML output be useful if it cannot handle real world commutation and only lab based sanitization of in-dictionary only responses? reply entilzha 1 hour agorootparent(Author here) If I understand your question right, this is one of the reasons BPE is nice and the parent liked it. For any character sequence, provided the characters are in the alphabet used to create the BPE vocab, there are no unknown words/sequences. One downside of some previous tokenization methods is you could have unknown/UNK tokens, EG dictionary based methods. In our paper with bytes, we also avoid the UNK issue, since we can have an embedding for every possible byte, since it’s not that many (and for sequences of bytes we use hash embedding, although we did test n-gram lookups for the top K frequent byte n-grams in the training data). reply phh 1 hour agorootparentprevThat's the OP's point. At the time, the community was split between word-level, which has the shortcomings you're describing, and byte-level which is uselessly compute intensive. BPE was the first reasonable in-between. BLT improves on BPE by having the the compression learnable rather than precomputed reply flimflamm 9 hours agoprevTo create a patch, a small model is used to predict the likelihood for the next character in the input string. Input string: 'Lazy dog jumped over a fence.' Use the model to predict the likelihood of each character. For example: 100% sure the next character is 'a'. Or maybe it's 10% sure it's 'a', 10% sure it's 'b', and so on. Then we chunk character estimates together. How many characters? Enough characters so that the total uncertainty (entropy) in each chunk is about the same. And there you have your 'patch' (or 'token'). reply yorwba 8 hours agoparent> How many characters? Enough characters so that the total uncertainty (entropy) in each chunk is about the same. That's not how it's described in Section 2.3 of the paper. They only use the entropy of the next byte and whether it exceeds a threshold (Global Constraint) or is larger than the preceding byte's entropy by another threshold (Approx. Monotonic Constraint). That does mean that long repetitive sequences can result in pathologically long patches, as demonstrated in Appendix E. But what I'm really curious about is the \"small CNN byte-level model with 2-byte context\" in Figure 3 (f), because it's never mentioned in any other part of the paper. reply entilzha 3 hours agorootparent(Author Here) Good description! Maybe what parent got mixed up on is an alternate way to view this is trying to chunk bytes to have roughly similar information. EG we initially tried a bunch of patching schemes, EG, keep a running total of entropy until the total exceeds a threshold, but ended up finding simple things worked better. I’ll see if we can add more information about the small CNN in a next update to arXiv paper. reply flimflamm 7 hours agorootparentprev\"That's not how it's described\" - Thanks for the correction! reply dv_dt 2 hours agoparentprevSo a variant might be to try using a some standard compression algorithm to train with? reply dewijones92 7 hours agoprevnotebooklm https://notebooklm.google.com/notebook/77fe83ee-35b3-4a9a-a3... reply ricardobeat 6 hours agoparentInteresting, this is one of the worst NotebookLM examples I've seen so far. They are interjecting way too often and breaking the rhythm. Is generation quality going down due to the popularity of the service? reply stuartjohnson12 2 hours agorootparentBig successful launch, hype for the product lead, product lead moves on, product goes to shit. Another classic for the Google graveyard. reply throwaway20222 1 hour agorootparentWe are working directly with the Notebook team from the outside, and while they have lost the original product lead, the team in general is seemingly really well supported, staffed with talented folks, and actively trying to understand what the end user wants from the product. Hardly a day goes by that they are not actively trying to get more feedback and share where they are heading. I do think it is fair to say they had been caught off guard by the success of the program and are trying to catch up. Maybe this is just a bit of drift as they are figuring it all out? Or maybe I am too charitable. reply marviel 1 hour agorootparentprevCore team just moved on to something else: https://werebuilding.ai/ reply 8n4vidtmkvmk 31 minutes agorootparentThat has to be the worst landing page ever reply refulgentis 1 hour agorootparentprevUh, the product manager left last week. reply bratao 3 hours agorootparentprevYeah, super strange. One cannot finish a sentence without the other interjecting. reply yeahwhatever10 1 hour agoparentprevPeople like this? reply dr_dshiv 7 hours agoprevDoes this mean AI can pre-train on binaries? reply bloomingkales 2 hours agoparentSome believe AI can now output compiled binaries (e.g update Notepad.exe with this feature). We all think AI writing code for us will be the end, but it might be an even simpler take over. reply 8n4vidtmkvmk 33 minutes agorootparentThat just sounds worse though? We can't validate the change is correct if we can't read the code. It is interesting though reply amelius 4 hours agoprevWhy can't the tokenization be implicit, so we only feed bytes (or characters) to the model? reply entilzha 4 hours agoparent(Author Here) Not sure what you mean by implicit? If you mean just treat bytes as tokens, one issue you run into is your sequence lengths get quite long, so compared to a regular token LLM, you can’t pack as many bytes in a batch, which means you’re pretty FLOP inefficient so scale worse. You could make the model smaller to compensate, but then the model isn’t as good. reply killerstorm 4 hours agoparentprevIt can work, but you have more tokens / weaker performance. People tested it and it was worse. reply qouteall 10 hours agoprevRelated quote from Karpathy: Tokenization is at the heart of much weirdness of LLMs. Do not brush it off. • Why can't LLM spell words? Tokenization. • Why can't LLM do super simple string processing tasks like reversing a string? Tokenization. • Why is LLM worse at non-English languages (e.g. Japanese)? Tokenization. • Why is LLM bad at simple arithmetic? Tokenization. • Why did GPT-2 have more than necessary trouble coding in Python? Tokenization. • Why did my LLM abruptly halt when it sees the string \"\"? Tokenization. • What is this weird warning I get about a \"trailing whitespace\"? Tokenization. • Why the LLM break if I ask it about \"SolidGoldMagikarp\"? Tokenization. • Why should I prefer to use YAML over JSON with LLMs? Tokenization. • Why is LLM not actually end-to-end language modeling? Tokenization. • What is the real root of suffering? Tokenization. reply withinboredom 9 hours agoparentIt’s weird because I’m pretty sure my brain does something similar when I speed read. I don’t actually, usually, read the words; instead I recognize the shape of the words (most common words) then I jump to the subject of the paragraphs and break down the meaning of the whole page in a second or so. reply entilzha 4 hours agorootparent(Author Here) In editing we couldn’t find a good place for this so cut it in the current version, but at one point had discussed a parallel with information density of speech as described by one paper. Essentially the paper found that in languages that were less information dense per syllable, speakers spoke faster to achieve similar information density as languages with higher density per syllable. You could see patching by entropy paralleling this if you consider that low entropy bytes in terms of Shannon entropy are less information dense. reply Timwi 8 hours agorootparentprevThat's generally true, but you also have the ability to stop and look closer if you want to. If someone asks you to count the letters in a word, you will stop to look at the letters individually. If you see an unfamiliar word like SolidGoldMagikarp, you can stop and break it apart. Tokenization prevents LLMs from doing this. reply kimixa 7 hours agorootparentGenerally the current crop of LLMs seem pretty good analogues of the \"scan reading\" immediate instinctual response to stimulus, but seems to completely lack the higher level that can then go \"Wait, that doesn't seem right, let's go back over that again\". Like hallucinations and seeing \"Faces\" in dark shadows until you look again, it's like it's doing a pretty good emulation of some level of consciousness. Is that a fundamental difference to the level of processing? I haven't seen that sort of second-tier logic pop up from any emergence behaviors from increasing scale yet, but will that come with time? I'm not sure. reply visarga 3 hours agorootparentYou can prompt the model to do that kind of \"stream of mind\" process. It will maximize modeling uncertainty. This is my prompt: > Write in a raw, real-time stream-of-consciousness style, as if actively solving a problem. Your response should feel like unpolished notes—messy, exploratory, and authentic. Show your full thought process, including missteps, dead ends, and course corrections. Use markers to signal mental states: Insights: \"Wait -\", \"Hold on -\", \"Oh -\", \"Suddenly seeing -\", \"This connects to -\". Testing: \"Testing with -\", \"Breaking this down -\", \"Running an example -\", \"Checking if -\". Problems: \"Stuck on -\", \"This doesn’t work because -\", \"Need to figure out -\", \"Not quite adding up -\". Progress: \"Making headway -\", \"Starting to see the pattern -\", \"Explains why -\", \"Now it makes sense -\". Process: \"Tracing the logic -\", \"Following this thread -\", \"Unpacking this idea -\", \"Exploring implications -\". Uncertainty: \"Maybe -\", \"Could be -\", \"Not sure yet -\", \"Might explain -\". Transitions: \"This leads to -\", \"Which means -\", \"Building on that -\", \"Connecting back to -\". Lean into real-time realizations: \"Wait, that won't work because…\" or \"Ah, I missed this…\" Show evolving understanding through short paragraphs, with natural pauses where ideas shift. Structure your thought evolution as follows: Begin with an initial take: \"This might work because…\" or \"At first glance…\" Identify problems or angles: \"Actually, this doesn’t hold up because…\" Test examples or counterexamples: \"Let me try -\", \"What happens if -\". Seek deeper patterns: \"I’m seeing a connection -\", \"This ties back to -\". Link broader implications: \"This means -\", \"If this holds, then -\". Admit confusion openly: \"I don’t get this yet\", \"Something’s missing here\". Reveal partial understanding: \"I see why X, but not Y\". Show failures and iterations: \"Still not right - trying another approach\". Embrace a debugging mindset, treating ideas like code—break them into steps, test logic, reveal failure modes, and iterate. Skip introductions and conclusions. Stop when you solve the problem or find clear next steps. Use short, direct sentences to mimic real-time thinking. The goal is to capture the messy, evolving nature of problem-solving and thought refinement. Just try this, you can insert at any point in a LLM chat session. I built it by reverse engineering the QwQ-32B model responses with Claude. QwQ itself is based on the GPT-o1 method. reply PaulHoule 4 hours agorootparentprevI've often wanted to talk with an LLM about its tokenization (e.g. how many tokens are there in \"the simplest of phrases\") I wonder if you fed it information about its tokenization (text like \"rabbit is spelled r, a, b, b, i, t\") if it could talk about it. reply dr_dshiv 7 hours agorootparentprevWell said!! I’m waiting for reading studies on AI generated text, that’s a different kind of speed read reply rjtavares 6 hours agoparentprevGoodbye tokenization problems, hello encoding problems! reply orbital-decay 8 hours agoparentprevMeta's approach doesn't seem to throw out character grouping entirely, it just makes it dynamic. reply Vetch 3 hours agoparentprev!Long post warning! Tokenization is often scapegoated for many transformer limitations. I suppose it's because reading about the many limitations of the transformer architecture is harder than dumping everything on tokenization (which to be fair, is often indirectly involved with or exacerbating some deeper issue). > Why can't LLM spell words? Tokenization. LLMs can spell if you ask them to though. And there have been investigations into this capability (ref:2). Tokenization makes computations that involve spelling more difficult, but this is downstream of deeper computational limitations of the architecture. > Why can't LLM do super simple string processing tasks like reversing a string? Ditto. > Why is LLM worse at non-English languages (e.g. Japanese)? Tokenization. Tokenization is also implicitly performing compression. If your tokenizer's corpus is focused only on english, basic information theory explains why it'll be less efficient for other languages. The net effect is longer sequences where tokens are less information dense for non-english languages on average. > Why is LLM bad at simple arithmetic? Tokenization. Tokenization could treat digits separately and I believe, llama2 did this. But OpenAI built tiktoken which does not do this. llama3 uses tiktoken. The transformer architecture also has limitations that make (default) arithmetic computations involving carries difficult to learn. You can read more about this in (ref:1). > Why did my LLM abruptly halt when it sees the string \"\"? Tokenization. Why should it not? Either way, it doesn't have to halt, as the sampler can just ignore this. But the distribution will still condition on this as a change of topic switch. The question should probably be, why did the LLM suddenly assign high probability to a stop token before finishing whatever it was writing? > What is this weird warning I get about a \"trailing whitespace\"? Tokenization. Modeling decisions for how to treat whitespace is upstream of tokenization. These choices affect how the LLM models word boundaries. Things can be fine most of the time until they aren't. There's also the issue of softmax. The way softmax is typically applied forces the model to always assign importance to some tokens, even when no strong relationships exist between them. This in turn leads to the model disproportionately dumping its focus on often semantically unimportant tokens like whitespace or punctuation. Misallocating attention in this manner can lead to wasting representational capacity due to overemphasizing unimportant tokens, perhaps inducing spurious correlations on whitespace. This issue propagates through the model, possibly leading to unexpected negative downstream effects. > Why the LLM break if I ask it about \"SolidGoldMagikarp\"? Tokenization. One step down, it's really a result of high dimensional random vectors. > Why should I prefer to use YAML over JSON with LLMs? Tokenization. > Why did GPT-2 have more than necessary trouble coding in Python? Tokenization. Tokenization does make counting more difficult but the net benefit to programming languages where whitespace can be semantically meaningful is a strong positive. Even when whitespace is not meaningful, long strings of them can often be encountered. Not being careful about devoting tokenization effort on whitespace will significantly degrade code modeling ability in LLMs. > Why is LLM not actually end-to-end language modeling? Tokenization. This is correct, but it is not necessarily the case that a character or byte based model will automatically be better. The issue is that LLMs as currently devised spend the same amount of computation per token. This creates the immediate problem of making meaningful sequences, which will now be substantially longer, substantially more expensive to compute, generate and store in memory. This is what the posted paper seeks to address over naive byte level modeling. Although it's unclear from the provided tables if what's claimed is actually what's occurring. Character level modeling will also make learning long ranged dependencies harder. Subword tokenization also aids in memorization, which can be useful in learning from the tail of the distribution. The following idea is based on (ref:5). Next-token prediction can be modeled as a hierarchical sampling process where problem instances (topics, natural language tasks), which are mixture distributions, are drawn from a metadistribution, and then data points (eg various strings) are sampled from specific subpopulations (ie clusters of task types) within those instances. Here, memorization is a key strategy since there's initial uncertainty about which features are relevant for predicting the next token. Particularly for rare examples, memorizing their details acts as a starting point for associating particular patterns with specific subpopulations, in turn allowing more accurate prediction of new points. From that starting point, the model can eventually refine its associations as it encounters more data. This is key for example, when sampling from the tail of the distribution where data about subpopulations will be more limited. Making memorization and learning longer dependencies more challenging can lead to final models that face more difficulty during ICL inference, which depends, among other things, on the ability to infer which task from a mixture distribution. > What is the real root of suffering? Tokenization. A better candidate is over-generalization. 1: https://arxiv.org/abs/2310.16028 2: What do tokens know about their characters and how do they know it? (https://aclanthology.org/2022.naacl- main.179.pdf) 3: https://arxiv.org/abs/2406.10851 4: Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP (https://arxiv.org/abs/2112.10508) 5: https://arxiv.org/abs/2012.06421 reply saurik 7 hours agoparentprevIn all seriousness: why has it been years now and it feels like there is no incremental engineering-level progress on these issues? Like, it seems like doing some manual intervention to the tokenization to at least remove exceptional tokens and add some semantics to how they break up numbers seem like quick wins. reply entilzha 4 hours agorootparent(Author Here) There is at least some work on character based modeling, but it hasn’t scaled well before. The challenge I think with something more adhoc for exceptional tokens is that it’s hard to see gains since they are by definition, infrequent. If the text is rare enough, BPE should produce many single byte tokens, so current models actually expend more compute on these rare sequences. BLT scales well because it expends less compute (by patching) on more predictable (low entropy) byte sequences. Current models only to some degree get this benefit, if it’s a larger BPE token, but that only goes so far. So it’s really two related, but different motivations. reply falcor84 4 hours agorootparentprev>In all seriousness: why has it been years now and it feels like there is no incremental engineering-level progress on these issues? From where I'm standing, LLMs appear to be the fastest moving technological field in history. reply PaulHoule 4 hours agorootparentA field can seem to be going quickly and going nowhere at the same time. Or rather a new technique can be invented and then exhausted in the time it takes somebody to get a PhD. (See https://en.wikipedia.org/wiki/Renormalization_group applied to phase transitions, which turned up just in time for the physics job crisis of 1970) I didn't ever believe that there was going to be a GPT-5 trained with exponentially more text and resources. Not only is there not enough text, but that's the path to ruin. Why? Cycle time. Two years ago we had little idea of how those models work so I knew there was a huge room in improving performance. It gets the cost down, it lets you put the models on your device, and it speeds up development. If I can train 10 models in the time it takes you to train 1 model I can make much faster progress. However even a GPT-15 trained with a Dyson sphere is going to struggle to sort things. (Structurally a pure LLM can't do that!) My #1 beef with Microsoft's Copilot is that you can ask it if it can sort a certain list of items (either a list you are discussing with it or say \"states of the United States ordered by percent water area\") it will say yes and if you ask it what it thinks the probability is that it will get it in the right order it will say \"very high\" but when you try it the list comes out totally wrong. It is equally unable to \"help me make an atom bomb\" except in the bomb case it will say that it can't but in the sorting case it says it can. The obvious answer is that it should use tools to sort. That's right but the problem of \"knowing what you can really do with your tools\" is philosophically challenged. (With problems so intractable it leads people like Roger Penrose to conclude \"I couldn't do math if I wasn't a thetan\") reply JustAndy 3 hours agorootparentI'm not really sure I understand your sorting example, maybe try it out in gpt and post the link to show exactly what you mean. The refusal of the model is something trained into the model by the process of rlhf, and it can also be untrained, by the process of abliteration [1]. Also, LLMs are capable of using tools in this very moment [2]. [1]: https://huggingface.co/blog/mlabonne/abliteration [2]: https://www.anthropic.com/news/analysis-tool reply paraschopra 8 hours agoprevMy notes: It's a 3 component model. - Encoder: Takes byte groupings and outputs a hidden state/encoding called patches - Transformer: Takes these encodings of patches in autoregressive fashion - Decoder: Takes processed encodings by transformers and outputs bytes Loss is on byte to byte crossentropy (Next byte prediction) How they group bytes. - Use entropy thresholds: If a sequence of bytes have entropy lower than a threshold, group them - This is a learned model (from data) Why this helps over current byte-pair tokenization in LLMs. - Encoder/decoder essentially act as “learnable” tokenization scheme - Better efficiency tradeoffs (as for highly predictable sequence of bytes, encoder can “offload” computation effort from the main transformer) - History teaches us that end to end learned system beats human designed mechanisms reply CuriousSkeptic 8 hours agoparent> History teaches us that end to end learned system beats human designed mechanisms I think this may need some qualifiers Even byte representations are human designed encodings. I would think a human designed decoder of such encodings must be more efficient than learning. Sure bytes encoding a stream of unicode code points maps fairly easy to useful information. But bytes representing a zip compressed collection of PDF files? I did wonder though, training on text encoding vs pixel encoding, perhaps brute forcing OCR, like humans, will be more flexible in the end then being limited to text encodings. reply paraschopra 6 hours agorootparent>Even byte representations are human designed encodings The point is that it can model any sequence of bytes. It's what-follows-what that matters, not how we're encoding it. reply hiddencost 7 hours agoparentprev> History teaches us that end to end learned system beats human designed mechanisms Depends how far back you go. History teaches us that everything is a trade off between model size, inference time, training time, and training data size, Once you're at the pareto frontier. And that cheap approximations can allow you to trade for more expensive computation elsewhere. That lesson has been obscured for the last decade because (1) \"the bitter lesson\" of scaling, and, (2), we're blowing past benchmarks too quickly. I do agree that learned models are better if they're free (compare the distribution of filter banks learned by a neutral acoustic model to those approximated by mel frequency cepstral coefficients), but once you start hitting scaling limits, cheap heuristics start creeping back in. BPE was a huge advancement over fixed vocab, e.g. reply entilzha 3 hours agorootparent(Author Here) Related thought, I think BPE is quite a good, cheap inductive bias to have in a model, which is part of what made it challenging to scale better against. I also suspect this is part of why with less training FLOPs BPE is better (left side of figure 1), BLT has to expend some of its FLOPs budget to recover/learn some of this useful bias. With more training FLOPs this becomes a smaller fraction of the budget though leading to better scaling. reply bloomingkales 10 hours agoprevI thought we’re supposed to be plateauing!? reply ArnoVW 8 hours agoparentWe are. Plateauing doesnt mean you don't book progress. Arguably that is what you would call \"plateaud\". The argument of plateauing is not that AI is fundamentally impossible. The argument is that just dumping more data and more compute on the problem, using the same approach, has diminishing returns. It's that statistical inference is not how the human mind works (not exclusively) and thus that we are not guaranteed to be able to replicate all traits of human intelligence by brute forcing. Of course we can and will still improve the algorithms. But the question remains whether tweaks like these, as cool and useful they may be to solve certain issues, will be enough by themselves. Since it remains statistical in nature, my position is \"no\". reply logicchains 7 hours agorootparent> that we are not guaranteed to be able to replicate all traits of human intelligence by brute forcing. We know from complexity theory that transformers with chain of thought are guaranteed to be able to reproduce a significant fraction of human reasoning, anything in the complexity class PTIME: https://arxiv.org/abs/2310.07923 reply fl0id 4 hours agorootparentI don’t think this paper says what you claim. It says chain of reasoning and its length can improve transformer performance. Not that this represent a significant fraction of human reasoning or that it’s even reasoning reply fabmilo 9 hours agoprev [–] I am gonna read this paper and the other latent sentence later today. I always advocated for this kind of solutions together with latent sentence search should get to the next level of AI. Amazing work from Meta reply CuriousSkeptic 8 hours agoparent [–] Sentence thing being this one? https://ai.meta.com/research/publications/large-concept-mode... I don’t get it, isn’t this concept modelling exactly whats going on in the deeper layers of current LLMs? reply kmacdough 4 hours agorootparent [–] Perhaps it does some similar grouping of content, but this more directly incentivizes longer term gripping of tokens into abstract concepts. I agree that it's not obvious this would perform better than letting the model build it's own structures for grouping tokens, but the proof is in the pudding; the technique led to improved results for a given model & training size. This newer approach gives the model the freedom to build it's own breakpoints, but still bakes the idea into the algorithm itself. What it means is a harder question. Perhaps transformers are simply an inefficient computational structure for this process? Perhaps a more flexible computational structure would integrate this step more efficiently? Perhaps Transformers are efficient enough, but our learning/densifying isn't? Or perhaps it's such a core powerful step that it might as well be built into the algo regardless? Much to learn. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Byte Latent Transformer (BLT) is a new byte-level large language model (LLM) architecture that achieves performance comparable to tokenization-based LLMs with enhanced efficiency and robustness.",
      "BLT utilizes dynamically sized patches as computation units, which adjust based on the complexity of the data, leading to improved training and inference efficiency.",
      "The study demonstrates that BLT can scale up to 8 billion parameters with 4 trillion training bytes, outperforming tokenization-based models by effectively scaling both patch and model size."
    ],
    "commentSummary": [
      "The Byte Latent Transformer (BLT) model by Meta introduces a novel approach by using patches instead of traditional tokens, addressing inefficiencies in handling out-of-dictionary words.- BLT consists of three components: an encoder for byte groupings, a transformer for processing, and a decoder for output, utilizing entropy thresholds for dynamic byte grouping.- This model aims to enhance efficiency and performance across languages, overcoming limitations of previous models, and highlights the ongoing challenges and potential in AI language processing."
    ],
    "points": 223,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1734158195
  },
  {
    "id": 42413677,
    "title": "Ilya Sutskever NeurIPS talk [video]",
    "originLink": "https://www.youtube.com/watch?v=YD-9NG1Ke5Y",
    "originBody": "Watch later Back",
    "commentLink": "https://news.ycombinator.com/item?id=42413677",
    "commentBody": "Ilya Sutskever NeurIPS talk [video] (youtube.com)190 points by mfiguiere 18 hours agohidepastfavorite102 comments legel 5 hours agoI’m glad Ilya starts the talk with a photo of Quoc Le, who was the lead author of a 2012 paper on scaling neural nets that inspired me to go into deep learning at the time. His comments are relatively humble and based on public prior work, but it’s clear he’s working on big things today and also has a big imagination. I’ll also just say that at this point “the cat is out of the bag”, and probably it will be a new generation of leaders — let us all hope they are as humanitarian — who drive the future of AI. reply chipsrafferty 1 hour agoparentLiterally a zero chance that the new generation of leaders of artifical intelligence will be humanitarian. reply killthebuddha 2 hours agoprevOne thing he said I think was a profound understatement, and that's that \"more reasoning is more unpredictable\". I think we should be thinking about reasoning as in some sense exactly the same thing as unpredictability. Or, more specifically, useful reasoning is by definition unpredictable. This framing is important when it comes to, e.g., alignment. reply bondarchuk 1 hour agoparentNot necessarily true when you think about e.g. finding vs. verifying a solution (in terms of time complexity). reply killthebuddha 1 hour agorootparentIMO verifying a solution is a great example of how reasoning is unpredictable. To say \"I need to verify this solution\" is to say \"I do not know whether the solution is correct or not\" or \"I cannot predict whether the solution is correct or not without reasoning about it first\". reply bondarchuk 10 minutes agorootparentBut you will know beforehand some/a lot of properties that the solution will satisfy, which is a type of certainty. reply narrator 1 hour agoparentprevReasoning by analogy is more predictable because it is by definition more derivative of existing ideas. Reasoning from first principles though can create whole new intellectual worlds by replacing the underpinnings of ideas such that they grow in completely new directions. reply skissane 16 hours agoprev> “Pre-training as we know it will unquestionably end,” Sutskever said onstage. > “We’ve achieved peak data and there’ll be no more.” > During his NeurIPS talk, Sutskever said that, while he believes existing data can still take AI development farther, the industry is tapping out on new data to train on. This dynamic will, he said, eventually force a shift away from the way models are trained today. He compared the situation to fossil fuels: just as oil is a finite resource, the internet contains a finite amount of human-generated content. > “We’ve achieved peak data and there’ll be no more,” according to Sutskever. “We have to deal with the data that we have. There’s only one internet.” What will replace Internet data for training? Curated synthetic datasets? There are massive proprietary datasets out there which people avoid using for training due to copyright concerns. But if you actually own one of those datasets, that resolves a lot of the legal issues with training on it. For example, Getty has a massive image library. Training on it would risk Getty suing you. But what if Getty decides to use it to train their own AI? Similarly, what if News Corp decides to train an AI using its publishing assets (Wall Street Journal, HarperCollins, etc)? reply fidotron 5 hours agoparent> What will replace Internet data for training? Curated synthetic datasets? My take is that the access Meta, Google etc. have to extra data has reduced the amount of research into using synthetic data because they have had such a surplus of it relative to everyone else. For example, when I've done training of object detectors (quite out of date now) I used Blender 3D models, scripts to adjust parameters, and existing ML models to infer camera calibration and overlay orientation. This works amazingly well for subsequently identifying the real analogue of the object, and I know of people doing vehicle training in similar ways using game engines. There were several surprising tactical details to all this which push the accuracy up dramatically and you don't see too widely discussed, like ensuring that things which are not relevant are properly randomized in the training set, such as the surface texture of the 3D models. (i.e. putting random fractal patterns on the object for training improves how robust the object detector is to disturbance in reality). reply RicoElectrico 4 hours agoparentprevI think we're not close to running out of training data. It's just that we would like knowledge, but not necessary behavior of said texts. LLMs are very bad at recalling popular memes (known by any seasoned netizen) if they had no press coverage. Maybe training with 4chan isn't as pointless if you could make it memorize it, but not imitate it. Also, what about movie scripts and song lyrics? Transcripts of well known YouTube videos? Hell, television programs even. reply stavros 1 hour agorootparentWe've run out of training data that definitely did not contain LLM outputs. reply zozbot234 3 hours agoparentprevSynthetic datasets are useless (other than for very specific purposes, such as enforcing known strong priors, and even then it's way better to do it directly by changing the architecture). You're better off spending that compute by making multiple passes over the data you do have. reply HeatrayEnjoyer 38 minutes agorootparentThis is contrary to what the big AI labs have found. Synthetic data is the new game in town. reply kranke155 24 minutes agorootparentIlya is saying it doesn’t work in this talk apparently. reply toxik 27 minutes agorootparentprevMost priors are not encodable as architecture though, or only partially. reply robg 5 hours agoparentprevThe ones that stand out to me are industries like pharmaceuticals and energy exploration, where the data silos are the point of their (assumed) competitive advantages. Why even the playing by opening up those datasets when keeping them closed locks in potential discoveries? Open data is the basis of the Internet. But whole industries are based on keeping discoveries closely guarded for decades. reply numpad0 1 hour agoparentprev> What will replace Internet data for training? It means unlimited scaling with Transformer LLM is over. They need a new architecture that scales better. Internet data respawns when they click [New Game...], oil analogy is an analogy and not a fact, but anyways total amount available in a single game is finite so combustion efficiency matters. reply menaerus 10 hours agoparentprev> What will replace Internet data for training? Curated synthetic datasets? Perhaps a different take at this could be: if I wanted to train \"state law\" LLM that is exceedingly good in interpreting state law, what are the obstacles to download all the law and regulations material for given state that will allow me to train LLM such that it becomes 95th percentile of all law trainees and lawyers. In that case, and my point is, that we already don't need an \"Internet\". We just need a sufficiently sized and curated domain-specific dataset and the result we can get is already scary. \"State law\" LLM was just an example but the same logic applies to basically any other domain - want a domain-specific (LLM) expert? Train it. reply losvedir 4 hours agorootparentThat's kind of going in a different direction. The big picture is that LLMs have until this point gotten better and better from larger datasets alone. See \"The Bitter Lesson\". But now we're running out of datasets and so the only way we know of to improve models' reasoning abilities and everything, is coming to an end. You're talking about fine tuning, which yes is a technique that's being used and explored in different domains, but my understanding is it's not a very good way for models to acquire knowledge. Instead larger context windows and RAG works better for something like case law. Fine tuning works for things like giving models a certain \"voice\" in how they produce text, and general alignment things. At least that's my understanding as an interested but not totally involved follower of this stuff. reply kranke155 23 minutes agorootparentA human being doesn’t need to read the entire internet to pass the state bar. Seems to me that need new ideas? reply yeahwhatever10 1 hour agorootparentprevThe problem remains the size of the dataset. You aren't going to get large enough datasets in these specific domains. reply pas 8 hours agorootparentprevyou need context for the dry statutes sure, you download all the legal arguments, and hope that putting all this on top of a general LLM which has enough context to deal with usual human, American, contemporary stuff the argument is that it's not really enough for the next jump (as it would need \"exponentially\" more data) as far as a I understand reply menaerus 8 hours agorootparentI don't understand the limitation, e.g. how much data do you need to train the \"law state\" specific LLM that doesn't know anything else but that? Such LLM does not need to have 400B of parameters since it's not a general knowledge LLM but perhaps I'm wrong on this (?). So my point rather is that it may very well be, let's take for example, a 30B parameters LLM which in turn means that we might have just enough data to train it. Larger contexts in smaller models are a solved problem. reply theptip 2 hours agorootparentFor a “legal LLM” you need three things: general IQ / common sense at a substantially higher level than current, understanding of the specific rules, and hallucination-free recall of the relevant legal facts/cases. I think it’s reasonable to assume you can get 2/3 with a small corpus IF you have an IQ 150 AGI. Empirically the current known method for increasing IQ is to make the model bigger. Part of what you’re getting at is possible though, once you have the big model you can distill it down to a smaller number of parameters without losing much capability in your chosen narrow domain. So you forget physics and sports but remain good at law. That doesn’t help you with improving the capability frontier though. reply petesergeant 5 hours agorootparentprev> how much data do you need to train the \"law state\" specific LLM that doesn't know anything else but that? Law doesn’t exist in a vacuum. You can’t have a useful LLM for state law that doesn’t have an exceptional grounding in real world objects of mechanics. You could force a bright young child to memorize a large text, but without a strong general model of the world, they’re just regurgitating words rather than able to reason about it. reply menaerus 4 hours agorootparentCounter-argument: code does not exist in vacuum yet we have small and mid-sized LLMs that can already output reasonable code. reply mkoryak 3 hours agorootparentI'm going to push back on \"produce reasonable code\". I've seen reasonable code written by AI, and also code that looks reasonable but contains bugs and logic errors that can be found if you're an expert in that type of code. In other words, I don't think we can rely solely on AI to write code. reply petesergeant 4 hours agorootparentprevGenerally they’ve been distilled from much larger models, but also, code is a much smaller domain than the law. reply noirbot 3 hours agorootparentCode is both much smaller as a domain and less prone to the chaos of human interpretation. There are many factors that go into why a given civil or criminal case in court turns out how it does, and often the biggest one is not \"was it legal\". Giving a computer access to the full written history of cases doesn't give you any of the context of why those cases turned out. A judge or jury isn't going to include in the written record that they just really didn't like one of the lawyers. Or that the case settled because one of the parties just couldn't afford to keep going. Or that one party or the other destroyed/withheld evidence. Generally speaking, your compiler won't just decide not to work as expected. Tons of legal decisions don't actually follow the law as written. Or even the precedent set by other courts. And that's even assuming the law and precedent are remotely clear in the first place. reply zozbot234 3 hours agorootparentA model that's trained on legal decisions can still be used to explore these questions, though. The model may end up being uncertain about which way the case will go, or even more strikingly, it may be confident about the outcome of a case that then is decided differently, and you can try and figure out what's going on with such cases. reply oldgradstudent 3 hours agoparentprev> There are massive proprietary datasets out there which people avoid using for training due to copyright concerns. The main legal concern is their unwillingness to pay to access these datasets. reply zozbot234 3 hours agorootparentYup, there's also a huge amount of copyright-free, public domain content on the Internet which just has to be transcribed, and would provide plenty of valuable training to a LLM on all sorts of varied language use. (Then you could use RAG over some trusted set of data to provide the bare \"facts\" that the LLM is supposed to be talking about.) But guess what, writing down that content accurately from scans costs money (and no, existing OCR is nowhere near good enough), so the job is left to purely volunteer efforts. reply parkaboy 5 hours agoparentprevI wonder if we will see (or already are/have been seeing) the XR/smart glasses space heat up. Seems eventually like a great way to generate and hoover up massive amounts of fresh training data. reply seydor 5 hours agoparentprevRobots can acquire data on their own (hopefully not via human dissection) reply vitorgrs 13 hours agoparentprevNot sure if this was a good example. Getty already license their images to Nvidia. And they already have a generative image service... I believe it's power by Nvidia model. reply kibae 15 hours agoparentprevI always suspected that bots on Reddit were used to gain karma and then eventually sell the account, but maybe they're also being used for some kind of RLHF. reply YetAnotherNick 11 hours agoparentprevHumans doesn't need trillions of tokens to reason or ability to know what they know. While a certain part of it comes from evolution, I think we have already matched the part that came from evolution using internet data, like basic language skills, basic world modelling. Current pretraining takes lot more data than a human would, and you don't need to look into all Getty images to draw a picture and so would a self aware/improving model(whatever that means). To reach expert level in any field, just training next tokens for internet data or any data is not the solution. reply exe34 11 hours agorootparent> Humans doesn't need trillions of tokens I wonder about that. we can fine tune on calculus with much fewer tokens, but I'd be interested in some calculations of how many tokens evolution provides us (it's not about the DNA itself, but all the other things that were explored and discarded and are now out of reach) - but also the sheer amount of physics learnt by a baby by crawling around and putting everything in its mouth. reply YetAnotherNick 11 hours agorootparentYes, as I said in the last comment. With current training techniques, one internet data is enough to give models what is given by evolution. For further training, I believe we would need different techniques to make the model self aware about its knowledge. Also, I believe a person who is blind and paralyzed for life could still attain knowledge if educated well enough.(can't find any study here tbh) reply exe34 10 hours agorootparentyeah blind and paralysed from birth - I'm doubtful that hearing along would give you the physics training. although if it can be done, then it means the evolutionary pre-training is even more impressive. reply _aavaa_ 15 hours agoparentprev> just as oil is a finite resource, the internet contains a finite amount of human-generated content. I guess now they’re being explicit about the blatantly extractive nature of these businesses and their models. reply popularonion 12 hours agoparentprev> What will replace Internet data for training? Curated synthetic datasets? Enter Neuralink reply zxexz 11 hours agorootparentReally not sure what you mean by this, could you explain? reply Gigachad 10 hours agorootparentAI can just suck up the content of peoples brains for training data. reply phillipcarter 4 hours agorootparentYou need to go back to Twitter with low-quality posts like this. reply zxexz 10 hours agorootparentprevYeah, people will go crazy for GPT-o2 trained on the readings of sensors \"barely embedded\" in the brains tortured monkeys, for sure. EDIT: This comment may have been a bit too sassy. I get the thought behind the original comment, but I personally question the direction and premise of the Neuralink project, and know I am not alone in that regard. That being said, taking a step back, there for sure are plenty of rich data sources for non-text multimodal data. reply zxexz 10 hours agoprevI can't help but feel that this talk was a lot of...fluff? The synopsis, as far as my tired brain can remember: - Here's a brief summary of the last 10 years - We're reaching the limit of our scaling laws, because we've trained on all the data we have available on the limit - Some things that may be next are \"agents\", \"synthetic data\", and improving compute - Some \"ANNs are like biological NNs\" rehash that would feel questionable if there was a thesis (which there wasn't? something about how body mass vs. brain mass are positively correlated?) - 3 questions, the first was something about \"hallucinations\" and whether a model be able to understand if it is hallucinating? Then something that involved cryptocurrencies, and then a _slightly_ interesting question about multi-hop reasoning reply coeneedell 5 hours agoparentI attended this talk in person and some context is needed. He was invited for the “test of time” talk series. This explains the historical part of the talk. I think his general persona and association with ai led to the fluffy speculation at the end. I notice with Ilya he wants to talk about these out there speculative topics but defends himself with statements like “I’m not saying when or how just that it will happen” which makes his arguments impossible to address. Stuff like this openly invites the crazies to to interact with him, as seen with the cryptocurrency question at the end. Right before this was a talk reviewing the impact of GANs that stayed on topic for the conference session throughout. reply killerstorm 3 hours agoparentprevWell, it looks like the entire point was \"you can no longer expect a capability gain from a model with a bigger ndim trained on a bigger internet dump\". That's just one sentence, but it's pretty important. And while many people already know this, it's important to hear Sutskever say this. So people know it's a common knowledge. The rest is basically intro/outro. reply sigmar 5 hours agoprevI found this week's DeepMind podcast with Oriole Vinyals to be on similar topics as this talk (current situation of LLMs, path ahead with training) but much more interesting: https://pca.st/episode/0f68afd5-2b2b-4ce9-964f-38193b7e8dd3 reply ldenoue 4 hours agoprevLLM corrected transcript (using Gemini Flash 8B over the raw YouTube transcript) https://www.appblit.com/scribe?v=YD-9NG1Ke5Y#0 reply oezi 2 hours agoparentHow do you prevent Gemini from just swallowing text after some time? Audio transcript correction is one area where I struggle to see good results from any LLM unless I chunk it to no more than one or two pages. Or did you use any tool? reply belter 3 hours agoprevIt’s surprising that some prominent ML practitioners still liken transformer ‘neurons’ to actual biological neurons... Real neurons rely on spiking, ion gradients, complex dendritic trees, and synaptic plasticity governed by intricate biochemical processes. None of which apply to the simple, differentiable linear layers and pointwise nonlinearities in transformers. Are there any reputable neuroscientists or biologists endorsing such comparisons, or is this analogy strictly a convention maintained by the ML community? :-) reply martindbp 3 hours agoparentYou have to remember what came before 2012: SVMs, Random Forests etc, absolutely nothing like the brain (yes, NNs are old, but 2012 was the start of the deep learning revolution). With this frame of reference, the brain and neural networks are both a kind of Connectionism with similar properties, and I think it makes perfect sense to liken them with each other, draw inspiration from one and apply it to the other. reply belter 2 hours agorootparentIt is also odd to see such a weak argument as the brain-to-body mass ratio being used, as here: https://youtu.be/YD-9NG1Ke5Y?t=593 If this metric were truly indicative, what should we make of the remarkable ratios found in small birds (1:12), tree shrews (1:10), or even small ants (1:7)? https://en.wikipedia.org/wiki/Brain%E2%80%93body_mass_ratio reply theptip 2 hours agorootparent> what should we make of the remarkable ratios found… We also can’t implement those creatures’ control systems in silicon, so they too are doing things we can learn from? reply signa11 3 hours agorootparentprevsorry, but i think neural-networks came way before 2012, notably the works of rumelhart, mccleland etc. see the 2 volume \"parallel distributed processing\" to read almost all about it. the book(s): https://direct.mit.edu/books/monograph/4424/Parallel-Distrib... a-talk: https://www.youtube.com/watch?v=yQbJNEhgYUw reply FL33TW00D 1 hour agorootparentI raise you Warren McCulloch in 1962: https://www.youtube.com/watch?v=wawMjJUCMVw reply mcshicks 2 hours agorootparentprevJets and Sharks! https://github.com/acmiceli/IACModel reply zitterbewegung 3 hours agorootparentprevNeural Networks are 200 years old (Legendre and Gauss defined Feed forward neural networks). Deep learning. The real difference between traditional ones and deep learning is a hierarchy of layers (hidden layers) which do different things to accomplish a goal. Even the concept of training is to provide weights on the neural network and there are many algorithms to do refinement, optimization and the network design. reply varjag 2 hours agorootparentGauss did not define feed forward neural networks, it all stems from a tweet of a very confused person. reply criddell 2 hours agoparentprevIs that wildly different from me calling a data structure where a parent node has child nodes a tree? reply wrs 39 minutes agorootparentDepends — do you then start claiming that because your data structure is like a tree, it’s surely going to start bearing fruit and emitting oxygen? reply sourcepluck 2 hours agoparentprevReading the replies to your comment, I think maybe the answer to your simple question is: \"no\". I also wonder if any \"serious comparisons\" have been made, and would be interested to read about it! A good question, I think. reply syassami 1 hour agoparentprevhttps://www.bloomberg.com/news/articles/2024-12-13/liquid-ai... reply chpatrick 2 hours agoparentprevYou don't need to simulate every atom in a planet to predict its orbit. A mathematical neuron could have similar function to a real one even if it works completely differently. reply modzu 2 hours agoparentprevwhat color are neurons? is that relevant? ml has proven that artificial networks can think. the other stuff may be necessary to do other things, or maybe simply evolved to support the requisite biological structures. ml is of course inspired by biology, but that does not mean we need to simulate everything. reply sensanaty 3 hours agoprev> just as oil is a finite resource, the internet contains a finite amount of human-generated content. The oil comparison is really apt. Indeed, let's boil a few more lakes dry so that Mr Worldcoin and his ilk can get another 3 cents added to their net worth, totally worth it. reply linsomniac 1 hour agoprevISTR reading back in the mid '90s, in a book on computing history which I have long since forgotten the exact name/author of, something along the lines of: In the mid '80s it was largely believed among AI researchers that AI was largely solved, it just needed computing horsepower to grow. Because of this AI research stalled for a decade or more. Considering the horsepower we are throwing at LLMs, I think there was something to at least part of that. reply ilaksh 1 hour agoprevLarger models are more robust reasoners. Is there a limit? What if you make a 5 TB model trained on a lot of multimodal data where the language information was fully grounded in videos and images etc. Could more robust reasoning be that simple? reply ryoshu 1 hour agoparentIt could be simpler. Humans don't need 5TB of data to reason. reply Workaccount2 58 minutes agorootparentThe amount of data needed to train a human brain is enormous. reply stretchwithme 11 hours agoprevAIs will need to start asking people questions. Should make for some very strange phone calls. reply wslh 5 hours agoparentThat's a good point. I think most people use LLMs by asking questions and receiving answers. But if you reverse the dynamic and have the LLM interview you instead, where you simply respond to its questions, you'll notice something interesting: the LLM as an interviewer is far less \"smart\" than it is when simply providing answers. I’ve tried it myself, and the interview felt more like interacting with ELIZA [1]. There seemed to be a lack of intent when the LLM was the one asking the questions. This creates a reverse dynamic, where you become the one being \"prompted\" and this dynamic could be worth studying or adjusting further [1] https://en.wikipedia.org/wiki/ELIZA reply Barrin92 4 minutes agorootparent>There seemed to be a lack of intent when the LLM was the one asking the questions There doesn't just seem to be lack of intent, there is no intent, because by the nature of its architecture these systems are just set of weights with a python script attached to them asking you to give you one more token over and over. There's no needs, drives, motivations, desires or any other part of the cognitive architecture of humans in there that produce genuine intent. reply airstrike 4 hours agorootparentprevWhich LLM did you perform that test with? reply wslh 1 hour agorootparentChatGPT Pro. reply neom 14 hours agoprevFull talk is interesting: https://www.youtube.com/watch?v=YD-9NG1Ke5Y reply CuriousSkeptic 8 hours agoparentOn the slide of body/brain weight relation he highlighted the humanids difference in scaling What he didn't mention, that I found interesting, was that the same slide also highlighted a hard ceiling for non-humanids at the same point reply imranhou 2 hours agorootparentThis is a very interesting point, in some ways the implicit belief is that we just need to get beyond the 700g limitation in terms of scaling LLM models and we would get human intelligence/superintelligence. I admit I didn't really get the body/brain analogy, I would have been better satisfied with a simpler graph of brain weight to intelligence with a scaling barrier of 700g. reply olddog2 2 hours agoprevSo much knowledge in the world is locked away with empiric experimentation being the only way to unlock it, and compute can only really help that experimentation become more efficient. Something still has to run a randomized controlled trial on an intervention and that takes real time and real atoms to do. reply sega_sai 5 hours agoprevVery thought provoking. One of the things was not clear to me, what does he mean by 'agentic' intelligence? reply ethbr1 4 hours agoparentIt's the current industry buzzword for action-oriented LLMs. Instead of generating text, tightening/formalizing the loop around planning, executing, analyzing results, and replanning. As far as buzzwords go, it's far from the worst, as it captures the essentials -- creating semi-autonomous agents. reply ed 59 minutes agorootparentBased on the context Ilya is not referring to that kind of agent. He’s referring to something more fundamental (which I was curious about, too). reply ototot 5 hours agoparentprevExample of 'agentic': https://blog.google/technology/google-deepmind/google-gemini... reply kgeist 5 hours agoparentprevWhen it autonomously performs tasks on behalf of the user, without their intervention. It sets goals, plans actions, etc. by itself. reply _giorgio_ 4 hours agoprevWhat a stupid talk. They gave 15 minutes to one of the most competent scientist. A joke. reply tikkun 4 hours agoprevAs context on Ilya's predictions given in this talk, he predicted these in July 2017: > Within the next three years, robotics should be completely solved [wrong, unsolved 7 years later], AI should solve a long-standing unproven theorem [wrong, unsolved 7 years later], programming competitions should be won consistently by AIs [wrong, not true 7 years later, seems close though], and there should be convincing chatbots (though no one should pass the Turing test) [correct, GPT-3 was released by then, and I think with a good prompt it was a convincing chatbot]. In as little as four years, each overnight experiment will feasibly use so much compute capacity that there’s an actual chance of waking up to AGI [didn't happen], given the right algorithm — and figuring out the algorithm will actually happen within 2–4 further years of experimenting with this compute in a competitive multiagent simulation [didn't happen]. Being exceptionally smart in one field doesn't make you exceptionally smart at making predictions about that field. Like AI models, human intelligence often doesn't generalize very well. reply sangnoir 1 hour agoparentIt is important to note the context: he it was in a private email to an investor with vested interests in those fields, and someone who is also prone to giving over-optimistic timelines (\"Tobo-taxis will be here next year, for sure\" since 2015) reply padolsey 4 hours agoparentprev>exceptionally smart at making predictions Is anyone though? Genuine question. I don't have much faith in predictions anymore. reply qeternity 4 hours agorootparentNo, very few for things with this much uncertainty. Most of it is survivorship bias: if you have a million people all making predictions with coin flip accuracy, somebody is going to get a seemingly improbable number correct. reply ethbr1 4 hours agorootparentprevPredictions predicated on technological advancement are tricky: there's a reason breakthroughs are called breakthroughs. reply exe34 4 hours agorootparentprevso your prediction is that most predictions will be wrong? reply bobbruno 45 minutes agorootparentA common saying in the stats field goes like this: \"Predictions are hard, especially about the future\". reply _giorgio_ 4 hours agoparentprevhe just wanted money from investors, that's why he used such short limits https://openai.com/index/elon-musk-wanted-an-openai-for-prof... > 2/3/4 will ultimately require large amounts of capital. If we can secure the funding, we have a real chance at setting the initial conditions under which AGI is born. reply InkCanon 4 hours agorootparentFor all the discussion about it, this is the simple answer. It's not an engineering or scientific prediction, it's a line from a pitch deck. reply noirbot 3 hours agorootparentBut isn't that part of the problem? Some of the brightest minds in the field's public statements are filtered by their need to lie in order to con the rich into funding their work. This leaves actual honest discussions of what's possible on what timelines to mostly be from people who aren't working directly in the field, which inclines towards people skeptical of it. Most the people who could make an engineering prediction with any level of confidence or insight are locked up in businesses where doing so publicly would be disastrous to their funding, so we get fed hype that ends up falling flat again and again. reply trescenzi 2 hours agorootparentThe opposite of this is also really interesting. Seemingly the people with money are happy to be fed these crazy predictions regardless of their accuracy. A charitable reading is they temper them and say “ok it’s worth X if it has a 5% chance of being correct” but the past 4 years have made that harder for me to believe. reply LampCharger 1 hour agoprevHa. Do people understand time for humanity to save itself is running out. What is the point of having a super human AGI if there's no human civilization for which it can help? reply HeatrayEnjoyer 19 minutes agoparent\"We can totally control an entity with 10^x faster and stronger intelligence than us. There is no way this could go wrong, in fact we should spend all of our money building it as soon as possible.\" reply talldayo 7 minutes agorootparent> We can totally control an entity with 10^x faster and stronger intelligence than us. Unless you're referencing an unreleased model that can count the number of 'r' occurrences in \"strawberry\" then I don't even think we're dealing with .01*10^x intelligence right now. Maybe not even .001e depending on how bad of a Chomsky apologist you are. reply hackandthink 45 minutes agoprev [–] What kind of reasing is he talking about? Why should it be unpredictable? Deductive Reasoning Inductive Reasoning Abductive Reasoning Analogical Reasoning Pragmatic Reasoning Moral Reasoning Causal Reasoning Counterfactual Reasoning Heuristic Reasoning Bayesian Reasoning (List generated by ChatGPT) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Ilya Sutskever's NeurIPS talk highlighted the limitations of current internet data for training AI models, likening it to the finite nature of fossil fuels, suggesting a need for new training methods.- The talk initiated discussions on reasoning unpredictability, the use of synthetic datasets, and the development of domain-specific AI models.- Attendees noted the significance of acknowledging data limitations and discussed the potential evolution of AI with new architectures and ethical considerations for future AI leaders."
    ],
    "points": 190,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1734137357
  },
  {
    "id": 42413343,
    "title": "Luon programming language",
    "originLink": "https://github.com/rochus-keller/Luon/blob/master/Readme.md",
    "originBody": "Welcome to the Luon Programming Language Luon is a high-level programming language with a syntax similar to Oberon+, Oberon-07 and Oberon-2, integrating concepts from Lua, and targeting the LuaJIT VM. Luon can be regarded as a statically typed version of Lua. The name is thus a combination of \"Lua\" and \"Oberon\". Luon procedures can be declared \"external\" and be implemented in Lua. This allows the re-use of libraries written in Lua, and also C libraries via the LuaJIT foreign function interface. The language specification can be found in the specification subdirectory. See also the code examples below. The project is the result of the author's experience with the Smalltalk-80 and SOM VM implementation, and the prospect to build a LuaJIT based Interlisp VM. In contrast to Oberon+, Luon doesn't have pointers, but instead all structured datatypes have reference semantics and are dynamically created. In addition to the ARRAY type, there is also a HASHMAP type for compatibility with Lua. There is also a STRING data type which - like Lua - is immutable and follows a value semantics. In particular, Luon solves the following Lua shortcomings recognized during the aforementioned projects: conditional compilation to enable or disable statements only used for debugging and to avoid wasting calculation time constants not requiring local slots or hashed element access explicit inline declaration, so the code can be better structured without additional context switches and slot consumption no implicit global declarations, and other means to detect as many errors as possible during compile time locals can no longer be used before declaration switch/case control statement to avoid writing the relation expression all over again This project implements a compiler and IDE for the Luon programming language. Representative example projects demonstrating the capabilities of the language and the IDE can be found in the testcases subdirectory. Here is a screenshot of the IDE: And here is the source-level debugger of the IDE: Code examples Procedural Programming module Fibonacci proc calc*(n : integer): integer var a, b, i, next: integer // comma is optional beginif n > 1 then a := calc(n - 1) b := calc(n - 2) return a + b elsif n = 0 then return 0 else return 1 endb := 1 for i := 0 to n-1 do next := a + b a := b b := next end return aend calc var res: integer begin res := calc(21) assert(res = 10946) print(\"Fibonaccy result: \") println(res) end Fibonacci Generic Programming module Collections(T) type Deque* = record data: array of T size: integer end proc createDeque*(): Deque const initial_len = 1_000 // separators var this: Deque // this is initialized to nil begin new(this); new(this.data,initial_len) return this // this and data will be garbage collected end createDeque proc (this: Deque) append*(element: T) begin if this.size = len(this.data) then assert(false) end this.data[this.size] := element inc(this.size) end append type Iterator* = record end proc (this: Iterator) apply*(element: T) end proc (this: Deque) forEach*(iter: Iterator) var i: integer; val: T begin for i := 0 to this.size-1 do iter.apply(this.data[i]) end end forEach end Collections Object Oriented Programming module Drawing import F := Fibonacci C := Collections(Figure) type Figure* = record position: record x,y: integer end end proc (this: Figure) draw*() end type Circle* = record (Figure) diameter: integer end Square* = record (Figure) width: integer end proc (this: Circle) draw*() end proc (this: Square) draw*() end var figures: C.Deque circle: Circle square: Square proc drawAll() type I = record(C.Iterator) count: integer end proc (this: I) apply( figure: Figure ) begin figure.draw(); inc(this.count) end apply var i: I // count is initialized to zero begin new(i) figures.forEach(i) assert(i.count = 2) println(\"drawing done\") end drawAll begin figures := C.createDeque() // use constructors instead of new: circle := { { F.calc(3), F.calc(4) }, diameter: 3 } figures.append(circle) square := { { x: F.calc(5), y: F.calc(6) }, 4 } figures.append(square) drawAll() end Drawing Planned features Implement lexer with directive support Implement parser and AST Implement semantic validator Implement a LuaJIT backend based on LjTools Implement an IDE similar to the Oberon+ IDE Document the language (specification is available) Migrate the Smalltalk-80 VM to Luon as a proof-of-concept and to optimize the language BUSY build and precompiled versions for some platforms Migrate PAL2 from C to Lua, fix BitBlt, separate deployment Complete the language implementation according to the specification (inline, invar, pcall, visibility, etc.) Development history Status on October 14, 2024 Derived the syntax from Oberon+ and Micron and generated a parser using the grammar and adopted the lexer from the Micron project. The parser is able to successfully read the ongoing Luon migration of the Are-we-fast-yet benchmark suite (not yet commited). Status on October 15, 2024 Adopted the AST infrastructure from Micron and extended the AST for full program coverage. Implemented a recursive descent parser (modified the one generated by EbnfStudio) which generates the AST. Status on October 16, 2024 Improved language: constructors generate object, extended for arrays and hashmaps; extra set constructor no longer needed. Can generate AST for ongoing AWFY with no memory leaks. Status on October 25, 2024 The semantic validator is complete and tested. I developed it in parallel with the Luon version of the Are-we-fast-yet benchmark suite. Some refactorings and language changes were necessary. As in Oberon-07, there is now only one INTEGER and REAL type, the former with 53 bits of precision. The validator was feature complete on October 22, so development took six, and testing and debugging three calendar days. Status on October 27, 2024 The IDE is ready for testing and debugging. I derived it from the LuaJIT version of the Oberon IDE, but many changes were necessary because the AST and code model are completely different. This included an optional cross-referencing infrastructure integrated with the validator. Also the import logic had to be extended for compatibility with the project file concept, which required refactoring of AST, parser and validator. Status on November 05, 2024 The LuaJIT bytecode generator including most built-in procedures is complete and ready for testing and debugging. All functions of the LuonFfi.c file were migrated to LUON.lua to avoid C dependencies. Added Oakwood implementations in Lua (Files is no longer Oakwood compatible). Status on November 09, 2024 After a lot of testing, debugging and fixes the generated code seems to be sufficiently correct for the moment to continue with other stuff. The testcases in the all.lnpro project, which I migrated from Oberon+ (\"features\" subfolder), work, which covers most aspect of the language. I also implemented delegates and the copy() builtin, and made some other language changes (e.g. := no longer copies char arrays by value). Next goal is to run the Luon Awfy suite. Status on November 13, 2024 The Luon Are-we-fast-yet suite works up to Json; a significant refactoring of the code generator was necessary for this to properly intitialize all class objects up-front; the performance is currently slightly (1%) better than Lua, and there is room for improvement. Now after a calendar month in the project, the compiler and IDE seem ready for implementing a Smalltalk VM, so let's go for it. Status on November 26, 2024 All benchmarks of the Luon Are-we-fast-yet suite now work and show a performance equal to the Lua on LuaJIT version of the benchmark. The debugger has been significantly improved. The BYTE type and TOSTRING builtin have been added to the language. The Project Oberon System has been migrated to Luon; the code works so far, but for correct display output many changes would be required (maybe in future). The Smalltalk VM is work in progress and expected to be complete in a week. Both compiler and IDE are used to implement the Smalltalk VM and have proved to be useful so far. Status on December 1. 2024 The migration of the Luon implementation of the Smalltalk VM (see for *.luon and *.lnpro) is complete. I migrated the C++ version with a few architectural changes. In contrast to the C++ version which uses Qt, this version uses SDL2 via LuaJIT FFI. It is also an example how the EXTERN keyword works, i.e. how the external implementations are provided. Now the debugging starts; wish me luck ;-) Meanwhile also the Luon specification is available, though not all features are yet implemented. Status on December 8. 2024 The ST-80 display representation works, but only with the C version of the BitBlt so far. Also added a Qt version of the PAL to ease debugging. Extended the language (KEYS function) and made other hasmap fixes. The ST VM requires still more debugging. Status on December 10. 2024 The Smalltalk-80 VM implemented in Luon works (with a few issues WIP), with both the SDL2 and Qt based PAL. Added the source code of the VM as a local testcase and demonstration to the Luon repository (as a copy of the corresponding files in the Smalltalk repository). The same applies to the Are-we-fast-yet implementation. The project is close to an MVP release. Status on December 12. 2024 With only a few changes, the IDE and demo projects also work on Windows. Provided precompiled packages for a few platforms. LuaJIT is statically linked on all platforms. MVP release. Precompiled versions The following precompiled versions are available at this time: Linux x86 Linux x86_64 Windows x86 Just download and unpack the compressed file to a directory. Start the IDE by double clicking on the LuonIDE executable. The specification and some demonstration projects are included. How to build Follow these steps if you want to build the Luon IDE yourself. The build is using LeanQt and the BUSY build system. Note that compiling on Linux requires the build essentials, xcb, libxcb1-dev and libx11-dev packages. On Mac and Windows there are no additional requirements than a toolchain. Create a new directory; we call it the root directory here Download https://github.com/rochus-keller/Luon/archive/refs/heads/master.zip and unpack it to the root directory; rename the resulting directory to \"Oberon\". Download https://github.com/rochus-keller/LuaJIT/archive/refs/heads/LjTools.zip and unpack it to the root directory; rename the resulting directory to \"LuaJIT\". Download https://github.com/rochus-keller/LjTools/archive/refs/heads/master.zip and unpack it to the root directory; rename the resulting directory to \"MonoTools\". Download https://github.com/rochus-keller/GuiTools/archive/refs/heads/master.zip and unpack it to the root directory; rename the resulting directory to \"GuiTools\". Download https://github.com/rochus-keller/LeanQt/archive/refs/heads/master.zip and unpack it to the root directory; rename the resulting directory to \"LeanQt\". Download https://github.com/rochus-keller/BUSY/archive/refs/heads/master.zip and unpack it to the root directory; rename the resulting directory to \"build\". Open a command line in the \"LuaJIT\" directory and follow the instructions there to build LuaJIT for your platform. Open a command line in the \"build\" directory and type cc *.c -O2 -lm -o lua or cl /O2 /MD /Fe:lua.exe *.c depending on whether you are on a Unix or Windows machine; wait a few seconds until the Lua executable is built. Now type ./lua build.lua ../Luon (or lua build.lua ../Luon on Windows); wait until the LuonIDE executable is built; you find it in the output subdirectory. Instead of the command line you can run the build using LeanCreator which uses multiple cores and thus builds faster. It is still possible to build the IDE using Qt 5 with qmake; use LnIde.pro for this purpose and proceed as usual when building with Qt. Support If you need support or would like to post issues or feature requests please use the Github issue list at https://github.com/rochus-keller/Luon/issues or send an email to the author. License Luon is available under GPL 2 or 3. The runtime libraries in the runtime subfolder, in addition, are available under MPL or LGPL. Additional Credits LuaJIT is Copyright © 2005-2023 Mike Pall, released under the MIT open source license. LeanQt is based on Qt, which is Copyright (C) 2016 by The Qt Company Ltd, 2008 by Nokia Corporation and/or its subsidiary(-ies), 1992-2005 by Trolltech AS, and many individual contributors around the world.",
    "commentLink": "https://news.ycombinator.com/item?id=42413343",
    "commentBody": "Luon programming language (github.com/rochus-keller)188 points by thunderbong 19 hours agohidepastfavorite93 comments Rochus 4 hours agoIf you want to hear the music, which I had in my head when I implemented Luon, here is the link: http://rochus-keller.ch/?p=1317 ;-) reply bdunks 1 hour agoparentWow! That’s impressive. The video at the top of your post really helped me understand the coordination involved. Thank you for sharing. I imagine you’ve been playing music most of your life. How long did it take you to bring all of this together and start “one man band” improvising? reply Rochus 1 hour agorootparentThanks. I actually started playing the piano in 1975. But only in the early 2000 I started to play bass on a pedal board. In 2010 I made my first experiments with playing the drums instead of the bass on the pedal board (http://rochus-keller.ch/?p=317). In 2014 I had a dedicated setup simulating a big band and played together with other musicians (e.g. http://rochus-keller.ch/?p=962). In 2022 I bought a Mac mini M1 and since enjoy the excellent sound quality of the new plugin generations. Only this year I managed to play the ride cymble as a real drummer would do it. reply hannofcart 6 hours agoprevThis looks really good. It seems to fix all the warts and moles in Lua that used to exasperate me and adds type-safety which is a huge enhancement. Replacing the 'everything is a table' with records, arrays and hashmaps is also a thoughtful improvement IMO. Just confirming one point to make sure I understand the licensing implications correctly. Since the compiler transpiles to LuaJIT, and since that's just data, using output of the (GPL v2/v3 licensed) Luon compiler (i.e. the LuaJIT output) in a commercial/closed source project without divulging the source of said project should be fully kosher right? Am guessing the answer is most likely in the affirmative but just making sure. reply Rochus 6 hours agoparentYes, what the compiler generates (LuaJIT bytecode in the present case) is not affected by the license which applies to the compiler. Usually, the runtime libraries which the generated code automatically depends on, are of bigger concern. Luon offers a GPL exception for the runtime code, as well as an LGPL or MPL license. So you can essentially use the runtime code for any purpose. reply owenm 17 hours agoprevThis is an impressive achievement, given there’s a whole language plus IDE. Kudos to the author. I couldn’t see any indication of what the author plans to use it for - I hope he can share more below? I’m intrigued by the LeanQt library as well that the IDE uses (https://github.com/rochus-keller/LeanQt) too. reply Rochus 17 hours agoparent> what the author plans to use it for Thanks. I e.g. re-implemented the Smalltalk-80 VM in Luon (see https://github.com/rochus-keller/Smalltalk/), and I consider implementing an Interlisp VM (see https://github.com/rochus-keller/gingko/) which uses LuaJIT, which was an important motivation to interrupt my Micron language project to implement Luon. reply pkphilip 13 hours agorootparentAmazing that you also managed to implement Smalltalk besides Oberon and Luon - all of them with IDEs! Wow! And by the way the startup speed of the IFE is just insane! it is actually faster than my simple text editor! reply MomsAVoxell 5 hours agorootparentprevOne of the most delightful places I’ve used Lua recently is in TurboLua, which gives the Lua VM access to all the necessary signals/pipes for writing high speed network applications, among other things. (https://turbo.readthedocs.io/en/latest/) Do you see there being a way to make a TurboLuon with current specs? reply Rochus 5 hours agorootparentI don't use TurboLua, but I think it's feasible to build a Luon adapter module if need be. The necessary 'extern' keyword is already part of the spec. reply owenm 14 hours agorootparentprevThe Interlisp VM sounds awesome - I would love to see Notecards on Windows/Linux/Mac natively! reply Rochus 7 hours agorootparentWhat do you mean by \"natively\"? Ahead of time compiled, or just working? If the latter, the present VM is already available on the mentioned systems. In my version, Gingko, I additionally removed a lot of outdated code to increase platform independence. reply zem 17 hours agorootparentprevnice! do you feel like oberon has something that gives it an edge over more currently popular languages, or is it just a matter of personal preference? reply Rochus 17 hours agorootparentActually, I only use original Oberon when I'm migrating the old Oberon systems. My interest lies in finding out how I would have to modify original Oberon to be as productive as I am used to with e.g. C++, but still adhering to the goal of simplicity. My version, which I call Oberon+ (and to which Luon is quite similar, whereas Luon is even simpler), goes in this direction. Actually an \"edge over more currently popular languages\" from my humble point of view is the goal and maintenance of simplicity. The term is subjective, but if you look at many of today's completely overloaded languages, it is intuitive to understand. reply emmanueloga_ 16 hours agoparentprevAmazing project! I get the appeal to write an IDE from scratch, especially if you are already an expert in writing GUIs with your framework of choice! I wonder if it would make more sense to spend that time writing a language server protocol daemon. That way, you could make your language available in any IDEs your users like that support LSP. reply Rochus 16 hours agorootparentI'm usually working on older machines on which the IDE's supporting language servers would be much too slow or wouldn't work at all because of incompatibilities. I like lean tools with little dependencies. But there is a parser in moderate C++, so maybe someone else will implement such a daemon. reply devin 13 hours agorootparentCould I ask why you find yourself working on older machines? Work? A fan of retro computing? Something else? reply Rochus 7 hours agorootparentIt's excellent hardware, I have many redundant copies and thus high availability, the system just works, I automatically take care of efficient implementation, and the generated executables have high probability to work on all newer Linux systems. And I'm too old to always chase for the new new version. reply pkphilip 8 hours agorootparentprevI am actually glad that this person developed the IDE. Please download the IDE and try it. It is exceptionally fast. When I compare the speed with that of IDEs like Visual Studio Code etc, the difference is night and day. reply 1vuio0pswjnm7 1 hour agoprevNo Javascript: https://raw.githubusercontent.com/rochus-keller/Luon/master/... reply omoikane 18 hours agoprevLuon looks mostly like Oberon and not so much like Lua, it's not obvious which of the Lua features it incorporated. It didn't seem to have coroutines, for example. But I am glad that it went with Oberon's 0-based array indices, as opposed to Lua's 1-based table indices. https://github.com/rochus-keller/Luon/blob/master/specificat... reply Rochus 17 hours agoparent> Luon looks mostly like Oberon and not so much like Lua Luon can indeed look similar to Oberon if you use upper-case keywords and semicolons, but there is not need for this. Both - Lua and Luon - have much in common with Modula-2 (given lower-case keywords). There are many elements in Luon which are pretty similar to Lua, e.g. constructors, pcall, most control and loop statements. But there are also significant differences of course, because Luon is a statically typed language and Lua isn't. reply ninalanyon 11 hours agoparentprevDon't all of Wirth's languages let you use any ordinal as the array index? At leat in Pascal you can declare an integer subtype, say 7..17 and use that as the type of the index of an array. Then the first element is item 7. The point being that both the start at 0 and start at 1 camps can have it their own way. reply Rochus 6 hours agorootparent> Don't all of Wirth's languages let you use any ordinal as the array index? In Oberon, Wirth kicked out everything to the bare minimum, including subrange types. Array indices in Oberon start with 0. reply fuzztester 9 hours agorootparentprev>Don't all of Wirth's languages let you use any ordinal as the array index? At leat in Pascal you can declare an integer subtype, say 7..17 and use that as the type of the index of an array. Then the first element is item 7. Can confirm that about Pascal, since I had used it a lot earlier. Don't know about the other Wirth languages. >The point being that both the start at 0 and start at 1 camps can have it their own way. Yes, but that is not the only point. Another reason, and maybe the more important one, is that having such custom array index ranges, can more naturally fit the problem domain. In fact you can even use user defined types for the ranges, e.g. so you can define an array with Sunday to Saturday as the indices and the values of (the equivalent of) an enum representing 1) weekdays and 2) weekends, as the corresponding values. Then your code involving days and weekdays and weekends, will read more naturally, so will be easier to both read and maintain. And you only have to do those custom definitions once, up front, so it is not much extra work for the benefit gained. reply dmz73 18 hours agoparentprevI have a really hard time understanding why people like 0 based indexes. They are a relic of C style arrays that are based on and interchangeable with pointers which use offsets that are naturally 0 based. Use in later languages gives us endless off-by-1 issues and rise to \"for 0 to count/len/num - 1\" or even better range syntax that is start inclusive BUT end exclusive. It is a horrible cludge just to support 1970s language perfomace optimization. Arrays should start and end at whatever start index is required, not at offset 0 of pointer to fist element of array. reply Benjamin_Dobell 17 hours agorootparentHang on. Off by one issues are the argument frequently given in favour of zero-based indices, not the other way around. For example, let's iterate through items placing them in 3 different groups; JS: for (let i = 0; if_(erlang:make_tuple(N,[]),Items,0,N). f_(Groups,[],_,_N) -> Groups; f_(G,Items,0,N) -> f_(G,Items,N,N); f_(G,[X|XS],I,N) -> f_(setelement(I,G,X),XS,I-1,N). I don't think that's too bad either, and it seems straightforward to translate to lua. Working backwards maybe makes the 1-based indexing a little more natural. n = 0 for i = 1,#items do if nWhy shouldn’t an array at the smallest possible index correspond to the beginning of the array? Because then there is no good way to refer to the index before that point: You are stuck using -1 (which means you can't use it to refer to the end of the array), or null (which isn't great either). > every programming language I know of that supports the concept of unsigned integer Surely you know Python which uses a signed integer as an index into their arrays: list[-1] is the last element of a list. If they only used one-based indexing then list[1] would be the first and that would be nicely symmetrical. It would also mean that list[i-1] would NEVER refer to a value after ‹i› eliminating a whole class of bugs. > It’s also very natural to think of arr[i] as “i steps past the beginning of arr.” I think it's more natural to think of arr[i] as “the ‹i›th element of arr” because it doesn't require explaining what a step is or what the beginning is. The exact value of ‹i› matters very little until you try to manipulate it: Starting array indexes at one and using signed indexes instead of unsigned means less manipulation overall. > find the convention used in many countries of numbering building floors starting with zero to be more logical In Europe, we typically mark the ground-floor as floor-zero, but there are often floors below it just as there are often floors above it, so the floors might be numbered \"from\" -2 for example in a building with two below-ground floors. None of this has anything to do with arrays, it's just using things like \"LG\" or \"B\" for \"lower ground\" or \"basement\" don't translate very well to the many different languages used in Europe. The software in the elevator absolutely doesn't \"start\" its array of sense-switches in the middle (at zero). reply bmacho 32 minutes agorootparent> I think it's more natural to think of arr[i] as “the ‹i›th element of arr” because it doesn't require explaining what a step is or what the beginning is. Yes, but if you will eventually need to do steps on your array, you better opt for the framework that handles them better. I agree, that if your only task is to name them, then 1 based indexing makes more sense: you do that since diapers, and you do that with less errors. reply childintime 2 hours agorootparentprevPython might have used array[~0] instead, where ~ is required, to indicate end-of-list 0-based indexing. But I guess they wanted to iterate from the end back [-1] to the start [0], making it easy to implement a rotating buffer. reply jhbadger 1 hour agorootparentprevI'd argue that 1-based indexing is the \"natural interpretation\". Mathematics is inherently 1-based, and it isn't surprising that languages designed to do mathematics like R, Matlab, Mathematica, Julia all do 1-based arrays because that makes modeling paper mathematics in programs easier. reply fuzztester 9 hours agorootparentprevIn India too, the floor at the ground level is called the ground floor (probably that is where the name came from), the one above it is called the first floor, and so on. The convention is probably from British colonial times. Also LED floor numbers in lifts (elevators) in India start from 0 for the ground floor, as do the buttons that you press to go to specific floors. Also, Ground Zero. https://en.m.wikipedia.org/wiki/World_Trade_Center_site https://en.m.wikipedia.org/wiki/Hypocenter# reply nkrisc 7 hours agorootparentprev> I also, despite being American, find the convention used in many countries of numbering building floors starting with zero to be more logical. I’m on the third floor, how many stories up did I travel to get here? Three. Alternatively the ground floor is the first floor because it’s the first floor you arrived at when you entered the building. The same point of view applies to 1-based indexing. That said I prefer 0-based in programming and 1-based in buildings. reply childintime 2 hours agorootparentI never understood why they didn't picture the building, with the buttons and the room/apartment numbers at each floor... That would make all conventions clear. Going negative would be obvious, and just indicate which floor the elevator is at with LED's of backlighting. They never heard of making a UI, and just slapped buttons. reply coder543 17 hours agorootparentprevSome countries consider the 1st floor to be the ground floor, others consider the 1st floor to be the floor above the ground floor, which the formerly mentioned countries consider the 2nd floor… I think 0/1-based indexing is more subjective than simply being a “relic of C” or a “horrible kludge” :P reply zem 17 hours agorootparentI've been in the US for over a decade and it still occasionally makes me double-take when a room numbered 1xx is on the ground floor reply fallous 13 hours agorootparentprevThere are 360 degrees in a circle, and the first entry is 0 degrees. The first time element of a day is 0:00:00(and enough 0s to satisfy whatever resolution you require). These were not established in the 1970s, and somehow pretty much everyone understands and works quite well with these systems. reply brabel 12 hours agorootparent> There are 360 degrees in a circle, and the first entry is 0 degrees. To be pedantic, \"first\" is associated with 1. And a circle does not have a \"first\" entry, whatever you mean by entry. I think what you're trying to say is that a circle is a continuous arc going from 0 to 360 degrees, but you should recognize that the \"starting point\" is arbitrary, any point will do, so there isn't really a \"first\", and that this is not the same as counting because counting is done with natural numbers, which are non-continuous. The problem of 0 VS 1 makes sense only in counting exactly because it's subjective whether you prefer to count from 0 or from 1. Because zero is the absence of anything, I find it hard to start counting from 0 (when you do, your \"first\" item is actually your zeroth item, and the next item would be the \"first\"??!), to be honest, despite being completely familiar with doing so since I've used 0-index programming languages my whole life. reply fallous 1 hour agorootparentNo, \"first\" infers a sequence and is associated with the beginning of that sequence. In the case of a relative heading, the existing heading is 0 degrees. Any change is relative to that origin point. Zero is also not the absence of anything, that would more properly be considered a NULL or NaN. reply Timwi 7 hours agorootparentprevIf you cut up a circle into n slices (maybe you're drawing a diagram on screen), it's vastly more helpful to think of one of the segments as segment 0 because then the start angle of every segment is index*360/n and the two segments whose border is at your initial angle are the first and last. If you start counting segments at 1, your “first” segment would be some way into the circle, and the two segments whose border is at your initial angle would be the last and the second-last. reply teddyh 17 hours agorootparentprevHere’s the ultimate authority on why computer languages should count from zero:reply umanwizard 15 hours agorootparentI find that argument to be written in a terse \"mathy\" style that makes it a bit hard to follow. So let me try to restate it in more concrete \"programmy\" terms. To iterate over an array with \"len\" elements, it’s most elegant if “len” appears as a loop bound, rather than \"len+1\" or \"len-1\". Thus, in 0-based languages we use half-open ranges, whereas in 1-based languages we use closed ranges: // real C for (int i = 0; i[0-based indexes] are a relic of C style arrays I don't think this is true. They exist in other disciplines (maths for instance) that have no relationship with C or other programming languages from the 1970s. > for 0 to count/len/num - 1 I will counter saying that such a for...to syntax is a relic of BASIC. > or even better range syntax that is start inclusive BUT end exclusive I know that your \"better\" is sarcastic, but I actually find left-inclusive+right-exclusive ranges fantastic. They allow perfect partitioning, easy calculation of lenght, etc. > Arrays should start and end at whatever start index is required I agree. An accommodating language would let you define both lower and upper bounds of an array, instead of its size. reply fuzztester 9 hours agorootparentIIRC some BASIC(s) I've used in the past had a statement called: OPTION BASE 1 or something like that, to change the starting index to 1. reply jodrellblank 1 hour agorootparentAPL has ⎕IO←0 or ⎕IO←1 to change the starting index (only between 0 or 1, not arbitrarily). It doesn't apply system-wide so different code blocks/files/modules(?) can set or reset it, and portable code has to either set it or adjust for it. APLCast podcast has an episode mentioning it where they all seem to agree that this is the worst of all worlds, makes sharing code and integrating codebases needlessly bug-prone, and the language picking a single indexing and sticking to it would have been better, even if the choice hadn't gone the way they would have personally chosen. reply ofalkaed 9 hours agorootparentprev>They are a relic of C style arrays Doesn't it predate that by a good amount? I would think it is a relic of the EEs who built the digital world, those early languages show a great deal more relation to the bare metal than modern languages. Creating an array whose index starts at 1 just doesn't make sense from the discrete logic point of view, you are either wasting an element or adding in an extra step. But in this day and age how can a language not have ⎕IO ← 0? reply Timwi 7 hours agorootparentprevI honestly think that most of the problem arises from the fact that we just culturally start counting at 1 when talking about everyday things. As it stands, we're all used to it that way, and then computers come along and show us that counting from 0 is often more useful. So we adjust, but only for computer programming purposes. If our species had established counting from 0 as the norm right away (element #n is the one that has n elements before it; you think of the number as the number of steps you have to move away from the starting point), then I suspect the reverse would not be true: I don't think anyone would find a situation in which counting from 1 is so much more convenient that it's worth going against the grain of established norm. So in summary, I think we only think of counting from 1 as natural because it's in our culture. And it's in our culture because ancient superstitious humans had an irrational problem with the number 0. reply gatane 3 hours agorootparentprevDijkstra said that 0 was better for reasons. reply samatman 16 hours agorootparentprevHaving done fairly extensive parsing work in Lua and Julia on the one hand (one-based), and Python, Javascript, and Zig on the other (zero-based), the zero-based semiopen standard makes intervals dramatically easier to calculate and work with. It's really the semiopen intervals which make this the case, but as the Word of Dijkstra makes clear, zero-basis comes along for the ride, to combine semiopen intervals with a one-basis is perverse. Naturally it's true that for collections and naïve indexing, 1-based is more natural. But those are rare places for bugs to occur, while interval calculations are a frequent place for them to occur. Clearly I'm far from allergic to the other standard, but I come down on the side of the zero basis for that reason. reply topato 18 hours agorootparentprevSlam! Now this guy really knows how to hate on a zero based index! reply srhtftw 18 hours agoprev> locals can no longer be used before declaration There's a lot I like about Lua but it so happens that a few days ago I spent longer than I'd like to admit debugging a trivial typo for Advent of Code day 5 that would have been caught by this. Wondering if Luon will also prohibit or at least warn about storing nil in a table. reply Rochus 17 hours agoparentLuon doesn't directly support tables, but instead supports records, arrays and hashmaps (which internally use tables). Since it's statically typed you can only store nil to a field or element if it is of a structured type. reply akkartik 17 hours agorootparentWhat's a structured type? Something that has fields or elements? reply Rochus 16 hours agorootparentRecords, arrays and hashmaps are structured types; in contrast to original Oberon, Luon has no pointer type, but reference semantics instead. reply masklinn 11 hours agorootparentSo Luon has reference types and value types, and reference types are always nullable? reply Rochus 7 hours agorootparentYes, but value types are only basic types. Structured types only have reference semantics and are nil by default. reply stevage 18 hours agoprevIt's nice when a project can find such a simple pronouncable name that is also meaningful. reply robertlagrant 5 hours agoparentI keep thinking it's called Luberon, which probably isn't helpful. reply HexDecOctBin 17 hours agoprevIs this purely a personal project, or is it supposed to be used by others? You have made so many languages in the Oberon family (great job keeping the traditions alive, by the way), it's hard to know whether they are just a personal experimentation or you are expecting others to use them too. reply Rochus 16 hours agoparentThis is not actually a contradicion, and the audience will decide whether the language will be used more widely. It's not my first priority, but there's nothing against it either. What you call \"tradition\" applies to my experiments with the Oberon Systems and the backward compatibility with their source code (for practical reasons, otherwise I would not be able to compile them), but my interest is actually in the language adapted for today's meaning of simplicity, which I call Oberon+ (or Luon, or Micron), and which would definitely have the potential for further adaptation if you look at what kinds of new languages are popular at the moment. reply k__ 4 hours agoprevWhy use a language with Oberon syntax, when there's Teal, which has Lua syntax and a TypeScript to Lua compiler? reply speed_spread 4 hours agoparentBecause Pascal/Modula/Oberon is the one true language. TypeScript? Blasphemy! reply k__ 4 hours agorootparentWhat's Oberon's unique selling point? reply MarcusE1W 1 hour agorootparentQuite high abstraction for its simplicity, quick to learn, strongly typed, garbage collected before it was cool (same as Module 3) and yet a system programming language (Oberon OS). You could argue that Wirth overdid it a bit with the simplicity vs. Comfort features but that's probably also dependent on your preferences and the problem you want to solve. There are a few languages where you regret that they did not win in favour of C++ and Oberon is one of them (and Modula 3). Not that C++ does not have its strength , but for many problems Oberon would probably have been the simpler fit. reply imtringued 8 hours agoprevI would have preferred a typescript equivalent for Lua. This is a bit too radical for a casual Lua user. reply darek 7 hours agoparentCheck out Teal - https://github.com/teal-language/tl reply k__ 5 hours agoparentprevhttps://typescripttolua.github.io/ reply 1attice 11 hours agoprevI confess I was worried, until I read the name explanation, that it was named after Lululemon's marketing term for its preferred elastane/cotton blend reply Rochus 7 hours agoparentFunny; it's actually surprisingly hard to find information; but Perplexity told me, that Lululemon's Luon is a material which has great flexibility and maintains its shape over time, wicking away sweat, and good coverage; all good features for my programming language ;-) reply revskill 12 hours agoprevWhy not using brackets to replace begin and end ? reply Rochus 5 hours agoparentBecause the language is an Oberon/Pascal descendant. reply revskill 2 hours agorootparentDo u mean ignorance ? reply Culonavirus 9 hours agoparentprevRight, looks like terrible unreadable mess to me. Somehow even worse than Python, but hey, it could be worse, it could have significant whitespace (though I'm sure the SV Python fetishist \"\"\"data scientist\"\"\" mafia this site is filled with disagrees...) reply humptybumpty 6 hours agoprevCute name: ”Luon” means ”I create” in Finnish. reply Rochus 6 hours agoparentSo let's create ;-) reply euroderf 6 hours agoprev [–] > Luon can be regarded as a statically typed version of Lua. The name is thus a combination of \"Lua\" and \"Oberon\". It's rather curt. How about: Luberon reply ghjfrdghibt 6 hours agoparent [–] I can't stop seeing: lube in this name. reply 0points 3 hours agorootparent [–] What about oilon? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Luon is a high-level programming language that merges elements of Oberon and Lua, designed specifically for the LuaJIT Virtual Machine (VM).",
      "It introduces static typing to Lua, allowing seamless integration with Lua and C libraries, and includes features like reference semantics, a HASHMAP type, and immutable STRING data types.",
      "The project offers a compiler, Integrated Development Environment (IDE), and precompiled versions for Linux and Windows, and is open-source under GPL 2 or 3 licenses."
    ],
    "commentSummary": [
      "Luon is a new programming language inspired by Lua and Oberon, developed by Rochus Keller, focusing on type-safety and structured data types.",
      "It features a statically typed system and compiles to LuaJIT bytecode, aiming for simplicity and efficiency, particularly on older hardware.",
      "Luon is part of Keller's broader language design projects, including Oberon+ and Micron, offering a modern approach to programming simplicity."
    ],
    "points": 188,
    "commentCount": 93,
    "retryCount": 0,
    "time": 1734133065
  },
  {
    "id": 42413845,
    "title": "Htmx 2.0.4 Released",
    "originLink": "https://github.com/bigskysoftware/htmx/blob/v2.0.4/CHANGELOG.md",
    "originBody": "Changelog [2.0.4] - 2024-12-13 Calling htmx.ajax with no target or source now defaults to body (previously did nothing) Nested shadow root fix The htmx:trigger event now properly fires on the synthetic load event The synthetic load event will not be re-called when an element is reinitialized via htmx.process() Boostedtags that issue a GET with no or empty action attributes will properly replace all existing query parameters Events that are triggered on htmx-powered elements located outside a form, but that refer to a form via theform attribute, now properly cancel the submission of the referred-to form Extension Updates preload extension was completely reworked by @marisst to be compatible with hx-boost, not cause side effect, etc. Thank you! response-targets was updated to not use deprecated methods A small fix to ws to avoid an error when closing in some cases The head-support extension was updated to work with the sse extension [2.0.3] - 2024-10-03 Added support for the experimental moveBefore() functionality in Chrome Canary, see the demo page for more information. Fixed revealed event when a resize reveals an element Enabled hx-preserve in oob-swaps Better degredation of hx-boost on forms with query parameters in their action Improved shadowRoot support Many smaller bug fixes Moved the core extension documentation back to https://htmx.org/extensions [2.0.2] - 2024-08-12 no longer boost forms of type dialog properly trigger the htmx:trigger event when an event is delayed or throttled file upload is now fixed empty templates that are not used for oob swaps are no longer removed from the DOM request indicators are not removed when a full page redirect or refresh occurs elements that have been disabled for a request are properly re-enabled before snapshotting for history you can now trigger events on other elements using the HX-Trigger response header The .d.ts file should now work properly [2.0.1] - 2024-07-12 Make the /dist/htmx.esm.js file the main file in package.json to make installing htmx smoother Update htmx.d.ts & include it in the distribution A fix to avoid removing text-only templates on htmx cleanup A fix for outerHTML swapping of the body tag Many docs fixes [2.0.0] - 2024-06-17 Removed extensions and moved to their own repos linked off of https://extensions.htmx.org The website now supports dark mode! (Thanks @pokonski!) The older, deprecated SSE & WS attributes were removed Better support for Web Components & Shadow DOM HTTP DELETE requests now use parameters, rather than form encoded bodies, for their payload (This is in accordance w/ the spec.) Module support was split into different files: We now provide specific files in /dist for the various JavaScript module styles: ESM Modules: /dist/htmx.esm.js AMD Modules: /dist/htmx.amd.js CJS Modules: /dist/htmx.cjs.js The /dist/htmx.js file continues to be browser-loadable The hx-on attribute, with its special syntax, has been removed in favor of the less-hacky hx-on: syntax. See the Upgrade Guide for more details on upgrade steps The selectAndSwap() internal API method was replaced with the public (and much better) swap() method [1.9.12] - 2024-04-17 IE Fixes [1.9.11] - 2024-03-15 Fix for new issue w/ web sockets & SSE on iOS 17.4 (thanks apple!) Fix for double script execution issue when using template parsing Fix TypeScript types file Fix SSE Ext: reinstantiate EventSource listeners upon reconnection logic (#2272) [1.9.10] - 2023-12-21 hx-on* attributes now support the form hx-on-, with a trailing dash, to better support template systems (such as EJS) that do not like double colons in HTML attributes. Added an htmx.config.triggerSpecsCache configuration property that can be set to an object to cache the trigger spec parsing Added a path-params.js extension for populating request paths with variable values Many smaller bug fixes & improvements [1.9.9] - 2023-11-21 Allow CSS selectors with whitespace in attributes like hx-target by using parens or curly-braces Properly allow users to override the Content-Type request header Added the select option to htmx.ajax() Fixed a race condition in readystate detection that lead to htmx not being initialized in some scenarios with 3rd party script loaders Fixed a bug that caused relative resources to resolve against the wrong base URL when a new URL is pushed Fixed a UI issue that could cause indicators to briefly flash [1.9.8] - 2023-11-06 Fixed a few npm & build related issues [1.9.7] - 2023-11-03 Fixed a bug where a button associated with a form that is swapped out of the DOM caused errors The hx-target-error attribute was added to the response-targets extension, allowing you to capture all 400 & 500 responses with a single attribute hx-on now properly supports multiple listeners The hx-confirm prompt is now passed into custom confirmation handlers next and previous are now valid extended CSS symbols in htmx The htmx:beforeHistoryUpdate event was added Properly ignore the dialog formmethod on buttons when resolving the HTTP method to use Added a htmx.config.scrollIntoViewOnBoost option that may be set to false to disable scrolling the top of the body into view for boosted elements [1.9.6] - 2023-09-22 IE support has been restored (thank you @telroshan!) Introduced the hx-disabled-elt attribute to allow specifying elements to disable during a request You can now explicitly decide to ignore title tags found in new content via the ignoreTitle option in hx-swap and the htmx.config.ignoreTitle configuration variable. hx-swap modifiers may be used without explicitly specifying the swap mechanism Arrays are now supported in the client-side-templates extension XSLT support in the client-side-templates extension Support preventDefault() in extension event handling Allow the HX-Refresh header to apply even after an HX-Redirect has occurred the formaction and formmethod attributes on buttons are now properly respected hx-on can now handle events with dots in their name htmx.ajax() now always returns a Promise Handle leading style tag parsing more effectively [1.9.5] - 2023-08-25 Web sockets now properly pass the target id in the HEADERS struct A very rare loading state bug was fixed (see https://github.com/bigskysoftware/htmx/commit/93bd81b6d003bb7bc445f10192bdb8089fa3495d) hx-on will not evaluate if allowEval is set to false You can disable the interpretation of script tags with the new htmx.config.allowScriptTags config variable You can now disable htmx-based requests to non-origin hosts via the htmx.config.selfRequestsOnly config variable The Security section has been expanded to help developers better understand how to properly secure their htmx-based applications. [1.9.4] - 2023-07-25 This is a bug-fix release for the most part, w/a heavy dose of @telroshan The HX-Trigger response header now supports comma separated event names Submit buttons that use the form attribute now work correctly The changed modifier now uses the triggering element, rather than the element the hx-trigger is defined on hx-disable is now handled dynamically so it can be added and removed IE11 compatibility restored! (maybe, hard to test) Fixed bug with hx-on event handler cleanup Many smaller bug fixes, typo fixes and general improvements [1.9.3] - 2023-07-14 The hx-on attribute has been deprecated (sorry) in favor of hx-on: attributes. See hx-on for more information. We now have functioning CI using GitHub actions! You can now configure if a type of HTTP request uses the body for parameters or not. In particular, the DELETE should use query parameters, according to the spec. htmx has used the body, instead. To avoid breaking code we are keeping this undefined behavior for now, but allowing people to fix it for their use cases by updating the htmx.config.methodsThatUseUrlParams config option. Thank you to Alex and Vincent for their feedback and work on this issue! The this symbol is now available in event filter expressions, and refers to the element the hx-trigger is on Fix bug where the htmx:afterSettle event was raised multiple times with oob swaps occurred A large number of accessibility fixes were made in the docs (Thank you Denis & crew!) Fixed bug w/ WebSocket extension initialization caused by \"naked\" hx-trigger feature The HX-Reselect HTTP response header has been added to change the selection from the returned content Many other smaller bug fixes [1.9.2] - 2023-04-28 Fixed bug w/ hx-on not properly de-initializing [1.9.1] - 2023-04-27 Fixed a bug with the new naked triggers that prevented boosted elements with explicit hx-trigger's from functioning properly Added code to play well with other libraries that also use the window.onpopstate Daily reminder: https://htmx.org/img/memes/javascripthistory.png [1.9.0] - 2023-04-11 Support for generalized inline event handling via the new hx-on attribute, which addresses the shortcoming of limited onevent properties attributes in HTML. Support for view transitions, based on the experimental View Transitions API currently available in Chrome 111+ and coming to other browsers soon. Support for \"naked\" hx-trigger attributes, where an hx-trigger is present on an element that does not have an hx-get, etc. defined on it. Instead, it will trigger the new htmx:triggered event, which can be responded to via your preferred scripting solution. A memory leak fix by @croxton The htmx website has been migrated from 11ty to zola by @danieljsummers, cutting way down on the number of \"development\" javascript dependencies Many other smaller bug fixes [1.8.6] - 2023-03-02 ESM support! Sass has been vanquished from the htmx.org website, which should set us up for some good progress going forward Fixed a bug where the changed modifier on keyup did not work properly if an input was tabbed into Many other smaller bug fixes and doc fixes [1.8.5] - 2023-01-17 Support a new optional cache-busting configuration option, getCacheBusterParam, to allow browsers to disambiguate between GET requests from htmx and from the raw browser Support new hx-history='false' attribute, to prevent sensitive data from being stored in the history cache. (Thank you @croxton!) Extensive new event-oriented features are available in the Web Socket extension (Thank you @Renerick!) A bug fix for when a form contains multiple empty input values with the same name (Thank you @bluekeyes!) A bug fix around inputs that throw exceptions when calling setSelectionRange() (Thank you @gone!) A bug fix to pass through the proper event for the htmx:configRequest event A bug fix/improvement for the preload extension Many other small bug fixes [1.8.4] - 2022-11-05 Fix the exact same regression in revealed logic as in 1.8.2 [1.8.3] - 2022-11-04 A new htmx:confirm event was added that allows for asynchronous confirmation dialogs to be integrated into htmx requests The new head-support extension allows for more elaborate head tag merging than standard htmx supports. This functionality may be integrated into htmx 2.0, depending on feedback. The new multi-swap provides more elaborate swapping of multiple elements on a screen using a custom swap strategy Many doc fixes (thank you to everyone who contributed!) [1.8.2] - 2022-10-12 Fix regression in revealed logic [1.8.1] - 2022-10-11 We now keep a count of outstanding requests for an indicator, so more than one overlapping request can share the same indicator without issues We now track the attribute state of an element and re-initialize it if htmx.process() is called on the element and the attributes have changed Idiomorph is now available for all your morph-swapping needs The unset directive now works properly for hx-vals and hx-vars The title of the page is now properly set on a history cache miss The new hx-validate attribute will force elements to validate before a request, even if they are not within a form being submitted Many smaller bug and docs fixes [1.8.0] - 2022-7-12 NOTE: This release involved some changes to touchy code (e.g. history support) so please test thoroughly and let us know if you see any issues Boosted forms now will automatically push URLs into history as with links. The response URL detection API support is good enough that we feel comfortable making this the default now. If you do not want this behavior you can add hx-push-url='false' to your boosted forms The hx-replace-url attribute was introduced, allowing you to replace the current URL in history (to complement hx-push-url) Bug fix - if htmx is included in a page more than once, we do not process elements multiple times Bug fix - When localStorage is not available we do not attempt to save history in it Bug fix - hx-boost respects the enctype attribute m is now a valid timing modifier (e.g. hx-trigger=\"every 2m\") next and previous are now valid extended query selector modifiers, e.g. hx-target=\"next div\" will target the next div from the current element Bug fix - hx-boost will boost anchor tags with a _self target The load event now properly supports event filters The websocket extension has had many improvements: (A huge thank you to Denis Palashevskii, our newest committer on the project!) Implement proper hx-trigger support Expose trigger handling API to extensions Implement safe message sending with sending queue Fix ws-send attributes connecting in new elements Fix OOB swapping of multiple elements in response The HX-Location response header now implements client-side redirects entirely within htmx The HX-Reswap response header allows you to change the swap behavior of htmx The new hx-select-oob attribute selects one or more elements from a server response to swap in via an out of band swap The new hx-replace-url attribute can be used to replace the current URL in the location bar (very similar to hx-push-url but no new history entry is created). The corresponding HX-Replace-Url response header can be used as well. htmx now properly handles anchors in both boosted links, as well as in hx-get, etc. attributes [1.7.0] - 2022-02-22 The new hx-sync attribute allows you to synchronize multiple element requests on a single element using various strategies (e.g. replace) You can also now abort an element making a request by sending it the htmx:abort event Server Sent Events and Web Sockets are now available as extensions, in addition to the normal core support. In htmx 2.0, the current hx-sse and hx-ws attributes will be moved entirely out to these new extensions. By moving these features to extensions we will be able to add functionality to both of them without compromising the core file size of htmx. You are encouraged to move over to the new extensions, but hx-sse and hx-ws will continue to work indefinitely in htmx 1.x. You can now mask out attribute inheritance via the hx-disinherit attribute. The HX-Push header can now have the false value, which will prevent a history snapshot from occurring. Many new extensions, with a big thanks to all the contributors! A new alpine-morph allows you to use Alpine's swapping engine, which preserves Alpine A restored extension was added that will trigger a restore event on all elements in the DOM on history restoration. A loading-states extension was added that allows you to easily manage loading states while a request is in flight, including disabling elements, and adding and removing CSS classes. The this symbol now resolves properly for the hx-include and hx-indicator attributes When an object is included via the hx-vals attribute, it will be converted to JSON (rather than rendering as the string [Object object]\") You can now pass a swap style in to the htmx.ajax() function call. Poll events now contain a target attribute, allowing you to filter a poll on the element that is polling. Two new Out Of Band-related events were added: htmx:oobBeforeSwap & htmx:oobAfterSwap [1.6.1] - 2021-11-22 A new HX-Retarget header allows you to change the default target of returned content The htmx:beforeSwap event now includes another configurable property: detail.isError which can be used to indicate if a given response should be treated as an error or not The htmx:afterRequest event has two new detail properties: success and failed, allowing you to write trigger filters in htmx or hyperscript: on htmx:afterRequest[failed] set #myCheckbox's checked to true Fixed the from: option in hx-trigger to support closestand findforms Don't boost anchor tags with an explicit target set Don't cancel all events on boosted elements, only the events that naturally trigger them (click for anchors, submit for forms) Persist revealed state in the DOM so that on history navigation, revealed elements are not re-requested Process all hx-ext attributes, even if no other htmx attribute is on the element Snapshot the current URL on load so that history support works properly after a page refresh occurs Many, many documentation updates (thank you to all the contributors!) [1.6.0] - 2021-10-01 Completely reworked tag support that now supports theform You can now use the value unset to clear a property that would normally be inherited (e.g. hx-confirm) The htmx-added class is added to new content before a swap and removed after the settle phase, which allows you more flexibility in writing CSS transitions for added content (rather than relying on the target, as with htmx-settling) The htmx:beforeSwap event has been updated to allow you to configure swapping behavior Improvedextraction support You can listen to events on the window object using the from: modifier in hx-trigger The root option of the intersect event was fixed Boosted forms respect the enctype declaration The HX-Boosted header will be sent on requests from boosted elements Promises are not returned from the main ajax function unless it is an api call (i.e. htmx.ajax) [1.5.0] - 2021-7-12 Support tracking of button clicked during a form submission Conditional polling via the hx-trigger attribute document is now a valid pseudo-selector on the hx-trigger from: argument, allowing you to listen for events on the document. Added the hx-request attribute, allowing you to configure the following aspects of the request timeout - the timeout of the request credentials - if the request will send credentials noHeaders - strips all headers from the request Along with the above attribute, you can configure the default values for each of these via the corresponding htmx.config properties (e.g. htmx.config.timeout) Both the scroll and show options on hx-swap now support extended syntax for selecting the element to scroll or to show, including the pseudo-selectors window:top and window:bottom. [1.4.1] - 2021-6-1 typo fix [1.4.0] - 2021-5-25 Added the queue option to the hx-trigger attribute, allowing you to specify how events should be queued when they are received with a request in flight The htmx.config.useTemplateFragments option was added, allowing you to use HTML template tags for parsing content from the server. This allows you to use Out of Band content when returning things like table rows, but it is not IE11 compatible. The defaultSettleDelay was dropped to 20ms from 100ms Introduced a new synthetic event, intersect that allows you to trigger when an item is scrolled into view as specified by the IntersectionObserver API Fixed timing issue that caused exceptions in the reveal logic when scrolling at incredible speeds - #463 Fixed bug causing SVG titles to be incorrectly used as page title - #459 Boosted forms that issue a GET will now push the URL by default - #485 Better dispatch of request events when an element is removed from the DOM Fixed a bug causing hx-prompt to fail The htmx.config.withCredentials option was added, to send credentials with ajax requests (default is false) The throttle option on hx-trigger does not delay the initial request any longer The meta key is ignored on boosted links tags are now evaluated in the global scope hx-swap now supports the none option Safari text selection bug - #438 [1.3.3] - 2021-4-5 Added the hx-disabled attribute to allow htmx to be turned off for parts of the DOM SSE now uses a full-jitter exponential backoff algorithm on reconnection, using the htmx.config.wsReconnectDelay setting [1.3.2] - 2021-3-9 Bug fixes [1.3.1] - 2021-3-9 IE11 fixes [1.3.0] - 2021-3-6 Support a target modifier on hx-trigger to filter based on the element targeted by an event. This allows lazy binding to that target selector. Events are no longer consumed by the first element that might handle them, unless the consume keyword is added to the hx-trigger specification Added the htmx:beforeSend event, fired just before an ajax request begins SSE swaps are properly settled Fixed bug that was improperly cancelling all clicks on anchors htmx.ajax() now returns a promise [1.2.1] - 2021-2-19 Fixed an issue with the history cache, where the cache was getting blown out after the first navigation backwards Added the htmx.config.refreshOnHistoryMiss option, allowing users to trigger a full page refresh on history cache miss rather than issuing an AJAX request [1.2.0] - 2021-2-13 New Features hx-vars has been deprecated in favor of hx-vals hx-vals now supports a javascript: prefix to achieve the behavior that hx-vars provided The new hx-headers attribute allows you to add headers to a request via an attribute. Like hx-vals it supports JSON or javascript via the javascript: prefix hx-include will now include all inputs under an element, even if that element is not a form tag The preload extension now offers a preload-images=\"true\" attribute that will aggressively load images in preloaded content On requests driven by a history cache miss, the new HX-History-Restore-Request header is included so that the server can differentiate between history requests and normal requests Improvements & Bug fixes Improved handling of precedence of input values to favor the enclosing form (see here) Moved event filtering logic after preventDefault so filtering still allows events to be properly handled No longer trigger after swap events on elements that have been removed via an outerHTML swap Properly remove event handlers added to other elements when an element is removed from the DOM Handle the scroll: modifier in hx-swap properly when an outerHTML swap occurs Lots of docs fixes [1.1.0] - 2021-1-6 Newly added preload extension allows you to preload resources for lower latency requests! Support the ignore: modifier for extensions Updated form variable order inclusion to include the enclosing form last so that, in the presence of multiple values, the most relevant value is the most likely to be selected by the server Support for the htmx.ajax() javascript function, to issue an htmx-style ajax request from javascript Removed the following htmx request headers for better cache behavior: HX-Event-Target, HX-Active-Element, HX-Active-Element-Name, HX-Active-Element-Value Added the hx-preserve attribute, which allows you to preserve elements across requests (for example, to keep a video element playing properly) The path-deps now surfaces a small api for refreshing path dependencies manually in javascript Now support the from: clause on hx-trigger to allow an element to respond to events on other elements. Added the htmx:beforeProcessNode event, renamed the (previously undocumented) htmx:processedNode to htmx:afterProcessNode Added closest syntax support for the hx-indicator attribute Added on load support for the newest version of hyperscript Added the htmx.config.allowEval configuration value, for CSP compatibility Bug fixes & improvements [1.0.2] - 2020-12-12 Extend all API methods to take a string selector as well as an element Out of band swap elements need not be top level now hx-swap-oob now can accept a CSS selector to retarget with [1.0.1] - 2020-12-04 AJAX file upload now correctly fires events, allowing for a proper progress bar htmx api functions that expect an element now can accept a string selector instead: htmx.on('#form', 'htmx:xhr:progress', function(evt) { htmx.find('#progress').setAttribute('value', evt.detail.loaded/evt.detail.total * 100) }); htmx now properly handles the multiple attribute onelements [1.0.0] - 2020-11-24 Bumped the release version :) [0.4.1] - 2020-11-23 Fixed bug with title tag support when title tag contained HTML entities Pass properties for the loadstart, loadend, progress, abort events through properly to the htmx equivalents [0.4.0] - 2020-11-16 Now support the HX-Redirect and HX-Refresh response headers for redirecting client side and triggering a page refresh, respectively hx-vars now overrides input valuestags in responses will be used to update page titles All uses of eval() have been removed in favor of Function hx-vals is available as a safe alternative to hx-vars. It uses JSON.parse() rather than evaluation, if you wish to safely pass user-provided values through to htmx. [0.3.0] - 2020-10-27 hx-trigger parsing has been rewritten and now supports trigger filters to filter events based on arbitrary javascript expressions htmx now supports two additional response headers HX-Trigger-After-Swap and HX-Trigger-After-Settle allowing an event to be triggered after a given life cycle event (instead of before the swap) The requestConfig is now passed out to events surrounding the AJAX life cycle htmx now evaluates tags as javascript when no language is defined on them A new event-header extension, which will include a serialized JSON representation of the triggering event in requests [0.2.0] - 2020-9-30 AJAX file upload support The HTML validation API is respected [0.1.0] - 2020-9-18 BREAKING CHANGE: The SSE attribute hx-sse and the Web Sockets attribute hx-ws have changed syntax to now use colon separators: hx-sse='connect:/chat swap:message' The SSE attribute hx-sse allows for swapping content directly on an event, in addition to triggering an htmx element, with the new swap: syntax. hx-target now supports a find syntax to find elements below the element by a CSS selector htmx plays better with deferred loading and many package managers All htmx events are dispatched in both camelCase as well as kebab-case, for better compatibility with AlpineJS and other frameworks. (e.g. htmx:afterOnLoad will also be triggered as htmx:after-on-load) hypeerscript is now initialized independently of htmx [0.0.8] - 2020-7-8 The view modifier on hx-swap has been renamed to show: hx-swap='innerHTML show:top' [0.0.7] - 2020-6-30 The hx-swap attribute now supports two new modifiers: scroll - allows you to scroll the target to the top or bottom view - allows you to scroll the top or bottom of the target into view The hx-push-url attribute now can optionally take a URL to push, in addition to true and false Added the hx-vars attribute that allows you to dynamically add to the parameters that will be submitted with a request [0.0.6] - 2020-6-20 Custom request/response headers no longer start with the X- prefix, which is no longer recommended empty verb attributes are now allowed and follow the anchor tag semantics (e.g. ) nunjuks inline rendering is now supported in the client-side-templates extension the new ajax-header extension includes the X-Requested-With header bad JSON is now handled more gracefully hx-swap=\"none\" will cause no swap to take place #89 hx-trigger now supports a throttle modifier #88 the focused element is preserved if possible after a replacement perf improvements for large DOM trees with sparse hx- annotations [0.0.4] - 2020-5-24 Extension mechanism added SSE support added WebSocket support added [0.0.3] - 2020-5-17 Renamed to htmx A bug fix for the hx-prompt attribute A bug fix for multiple hx-swap-oob attributes Moved the default CSS indicator injection into its own sheet to avoid breaking Added the htmx.config.includeIndicatorStyles configuration option so people can opt out of injecting the indicator CSS [0.0.1] - 2020-5-15 Initial release (originally named kutty)",
    "commentLink": "https://news.ycombinator.com/item?id=42413845",
    "commentBody": "Htmx 2.0.4 Released (github.com/bigskysoftware)185 points by ms7892 17 hours agohidepastfavorite102 comments ianpurton 10 hours agoDo some people have examples of interactivity they were able to replace with Htmx? For me, I've been able to get turbo style links with the boost to get nice page transitions. I can also see how I could use the class-tools extension to enable buttons to open dialogs etc. I'm curious to see when people say they needed an SPA for interactivity, what interactive features Htmx can already do and when do we need to break out some JS. An example that I think needs JS is a copy paste button. reply fhd2 10 hours agoparentOne thing I use HTMX for is to quickly hack interactivity into a more traditional site. One example is incremental filtering: I added an input field, and made it (a few ms after the last value change) load the same page the user is already on with a query parameter that filters the items in the response. Then I just replace the list of items with the contents from the response, ignoring the rest of the page. It's a bit wasteful perhaps, but all this took just a few lines of HTML. reply kisamoto 8 hours agoparentprevI tried HTMX but found it too restricting. It's great if you just want to load a portion of the page. Maybe if you have an up-vote, just send the request and replace the icon with a gold icon. But I want things like an on-site calculator. I load in products and prices, users can adjust sliders to change the quantity and relevant number is calculated. I don't want to use HTMX for this to call the server each time, I want instant reactivity and state in the frontend maintained so when the user has tweaked as necessary they can just check out. HTMX does not fit this use case so I use React to build widgets (or if even more complex SPA then Angular). If I'm using a JS framework anyway, then I don't need HTMX. It's just something else to clutter the project and remember to use. HTMX has its place but with the user expectation for reactivity in the browser I personally find it too limiting. reply BiteCode_dev 5 hours agorootparentBecause HTMX is declarative and the declaration is in HTML, people have weirdly extended the \"no need for js+json+rendering for ajax\" to \"don't use js\". This is making your life needlessly difficult. HTMX is just a fancy ajax layer with a little event handling sprinkled on top. You can and should script to your heart content even if you use it, when you need so. I use js in all most of my HTMX powered pages. Sometimes just a few lines. Sometimes a whole lot. Sometimes vanilla, sometimes alpine. I even have one where I load react for one single page because I want a community widget while the rest of the site is pure HTMX. You can do whatever you want. reply halfcat 6 hours agorootparentprevThis kind of use case is where you’d use Alpine instead of HTMX (if you’re going for the no-build approach). It has everything you’d need for this, client-side store, etc. Alpine is basically light weight, no-build Vue. HTMX is really only about swapping out the elements on the page and pushing updates to the server, which in this case might just be lazy loading the calculator component that contains Alpine attributes and Tailwind elements, and HTMX only if there are elements to swap or you need to save state to the server. reply srid 1 hour agoparentprev> An example that I think needs JS is a copy paste button. Evidently you can use Hyperscript for this. Its websitedemonstrates it with a similar \"copy\" button. reply bjackman 8 hours agoparentprevI recently tried out htmx for rendering a web clone of the terminal UI for https://github.com/bjackman/limmat It's a simple usecase but nonetheless I was blown away by how trivial HTMX made it! Very cool. reply srid 1 hour agorootparentInteresting, I'm working on a similar project myself. Is your web clone open source? reply serial_dev 7 hours agoparentprev> An example that I think needs JS is a copy paste button. And it’s fine? htmx allows you to write JavaScript. It’s probably one line, I don’t think everything you can come up with needs to be part of htmx. It’s not all or nothing. reply sublinear 7 hours agoparentprevI wrote plain HTML, JS, and CSS and it worked great in all browsers and all devices and passed all kinds of audits necessary in the real world. Don't bother with libraries like this. reply _heimdall 16 hours agoprev> Calling htmx.ajax with no target or source now defaults to body (previously did nothing) This one jumped out to me as an interesting one for a patch release. Changing the default behavior feels like a breaking change, though hopefully there weren't sites expecting an ajax call to not do anything. reply latent22 14 hours agoparentActually this was just a stupid bug I introduced in 2.0.3 which was found soon after 2.0.3 shipped. I fixed a bug that allowed ajax api to target body and blow away your whole page in error if one of the selectors you pass in was not found. But It broke the default no source and target behavior but this is now fixed that 2.0.4 is shipped reply ahoka 10 hours agorootparentThis is why I think semver is impossible to do in practice. reply teruakohatu 9 hours agorootparent> This is why I think semver is impossible to do in practice. The semver docs explicitly address this scenario. If a change in minor update breaks compatibility release a new minor update to revert the change. reply foldr 7 hours agorootparentIt’s correct practice, but bad luck for anyone who ends up depending on the buggy behavior in 2.0.3. Their code will break when they upgrade to (say) 2.0.7. reply mirekrusin 8 hours agorootparentprevAgree, behavior vs misbehavior (aka feature vs bug) is user's decision (at call site), not author's decision (at implementation side). Semver is just _indicative_ attempt at describing changes. If this wasn't true, we wouldn't have lockfiles. Ie. semver is just approximate attempt at change description that aids/helps development/maintenance but should never be fully trusted. The only way it could fully work in automated fashion is if the whole program would be written in some formal proof language – then dependency upgrades could be considered as breaking or non breaking. But again, easier and more precise from end user position, not author's position because breaking change in one project can always be non breaking in other if that part is not used/used in more relaxed manner. reply _heimdall 6 hours agorootparentprevAh okay, that makes total sense. I should have checked the PR first! reply chrismorgan 15 hours agoparentprev> though hopefully there weren't sites expecting an ajax call to not do anything It didn’t need to do nothing, it just needed to have no visible effect. I would be absolutely astonished if this affected no one. It’s very easy to imagine someone having written htmx.ajax(\"GET\", \"/some-tracker-that-returns-nothing-or-json-or-something\") And now your body is clobbered, leaving either nothing behind or a raw JSON response or some such thing. Seriously. Should such a person have used fetch() instead? I dunno, probably; I don’t use htmx. This is an extremely breaking change. reply _heimdall 5 hours agorootparentThat's fair, I guess someone could be doing that. Not quite sure why you would though, if you're already in JS and aren't updating the DOM, fetch() would make more sense. Either way it sounds like this was a fix to a bug introduced in the last patch so the semver makes more sense here. reply recursivedoubts 15 hours agorootparentprevYeah I tend to agree this should have been in a minor rather than a patch release. The reality is that I tend to regard the JavaScript api as an afterthought (the html attributes are the main api) and the existing behavior seemed like a nonsensical bug, but on reflection I wouldn’t have changed the html api like that and should treat the JavaScript api the same way. reply tomjakubowski 16 hours agoparentprev> though hopefully there weren't sites expecting an ajax call to not do anything. thatsthebeautyofit.com in shambles reply cschep 16 hours agoparentprevwhy would you call it expecting it to do nothing? reply beanjuiceII 16 hours agorootparentwhy is the wrong question, because it doesn't matter reply recursivedoubts 16 hours agoparentprevyeah, the htmx JavaScript API is not widely used, but I agree it's right on the edge of what's acceptable in a patch release reply hipadev23 13 hours agoparentprev> Changing the default behavior feels like a breaking change I'm fine with breaking changes personally. An adherence to maintaining backward compatibility always is what leads to bloat and criticisms of \"poor design\" from HNers in the future. Keep it slim, have one way to do things, and avoid the disaster that is js and python today. reply sethammons 8 hours agorootparentBackwards compatibility is a mainstay in Go and I don't experience bloat, and, I believe, such goals are a hallmark of good api design. Source: over the last 20 years, built several and used many large code bases that have used for years and years that had different teams and individuals regularly committing into them. reply izietto 10 hours agorootparentprevI'm not fine with breaking changes in a patch bump, otherwise it means versioning is useless reply PhilippGille 10 hours agorootparentprevIn addition to what the siblings say, in case parent isn't aware of semantic versioning: https://semver.org/ reply Spivak 13 hours agorootparentprevIt's not that there are breaking changes, but that breaking changes were introduced in a patch release. reply intalentive 13 hours agorootparentprevHow is Python a disaster? reply benatkin 16 hours agoprevThere's a question I've had about htmx for some time, might as well ask it here. Why does it keep the history cache in localStorage and not sessionStorage or memory? Some kind of a microoptimization? sessionStorage seems like it would be better to me if it's really a good default. I also think it should be publicized more, because it unexpectedly keeps stuff in a location that can be accessed more easily and beyond where the browser's back button cache can. reply recursivedoubts 16 hours agoparentmemory wouldn't survive a page refresh sessionStorage wouldn't survive a tab close i'm not opposed to making the latter an option though reply benatkin 15 hours agorootparent> memory wouldn't survive a page refresh That isn't very common. > sessionStorage wouldn't survive a tab close When a tab is restored, the browser typically restores sessionStorage. > i'm not opposed to making the latter an option though That isn't what I was getting at. If I'm going to buy into htmx, I want to understand the design. I wondered why this was the default, and why I hadn't seen it mentioned as a security concern. reply recursivedoubts 15 hours agorootparenti don't know how common it is or isn't, but it's reasonably common for htmx to be sprinkled into a regular MPA with full page navs, etc. and memory wouldn't survive that no strong opinions on session vs local storage, i was trying to make htmx act as much like the browser as possible and the browser caches across tabs you can disable history on any page by using the hx-history attribute and you can force a server request on every history navigation by setting the htmx.config.historyCacheSize config option to 0: https://htmx.org/docs/#disabling-history-snapshots https://htmx.org/docs/#htmx-security-tools reply benatkin 14 hours agorootparentMemory would indeed be an issue for mixing MPA and SPA, but besides not being an issue for a full SPA it also wouldn't be an issue for sites that are all MPA except AJAX submissions that don't cause a SPA page change. Currently I think an all MPA would waste the localStorage space. SessionStorage by default with prominent placement in the docs would be better I think. It would automatically clean up the data from visitors' disk space at appropriate times, whereas the localStorage setting puts it in a place that gets persisted for quite some time. Thanks for those links, I've read them but it's good for others here to see them. reply bdcravens 14 hours agorootparentprevMaybe because I'm \"old\" and use browsers the way they were used when I first started using the Internet, but I refresh often enough that I'd quickly lose patience with an \"app\" that broke because I used a very basic feature of the web. reply benatkin 14 hours agorootparentIf the site wasn't working it wouldn't break, it would download each page when you hit the back button. That would actually be a welcome result if I hit the refresh button wanting to make sure I was only looking at fresh data. reply bdcravens 14 hours agorootparentAny resource (ie page/URL) should function correctly with no regard to how that resource was loaded. That's the contract any server has with the client (browser), with no regard to what technology is being used to deliver the resource. If a website or application basically has to do the 2024 equivalent of \"don't hold it that way\", it's the result of a broken development model. reply benatkin 14 hours agorootparentThe correct function comes down to what the browser APIs say is valid in navigation. Both loading cached data and making the request again are valid. In the case of soft page navigation (onpushstate/onreplacestate) it's very clear that both are valid, as SPAs aren't expected to cache nothing, nor are they expected to cache everything. reply withinboredom 8 hours agorootparentIf I’m currently filtering some search data and hit refresh (or the browser tab went to sleep and wakes up, or restored after a reboot) I expect it to be in the same place without having to search and filter again. reply benatkin 2 hours agorootparenthttps://en.m.wikipedia.org/wiki/Query_string reply johnfn 15 hours agorootparentprevA page refresh isn't common? reply mrits 15 hours agorootparentI'm wondering how they use this site reply benatkin 14 hours agorootparentI wasn't talking about Hacker News or lobste.rs :) reply gklitz 11 hours agorootparentSo you were only trying to say that page refreshed aren’t common on some subset of pages where it isn’t common? What’s the point of that argument. Also curious, why are you arguing so intensely for a “solution” that seems to only be worse and introduces issues as explained, without ever having stated any problem you are trying to solve with the change? reply esperent 15 hours agorootparentprev> When a tab is restored, the browser typically restores sessionStorage Is it guaranteed to do this? Otherwise, if it just sometimes does it, or different browsers handle it differently/may change in the future, it seems like a recipe for problems. reply hotpocket777 15 hours agorootparentNot guaranteed, no. Thankfully. Chrome does, however, if the “resume where i left off” setting is enabled. reply deedubaya 14 hours agoprevAs ceo of htmx I’ll field any questions now reply mongol 10 hours agoparentWhat are the credentials you need to become CEO of HTMX? reply devjab 9 hours agorootparentWell, you need an X account, so too high? reply recursive 14 hours agoparentprevI doubt that. reply recursivedoubts 14 hours agorootparentno, they are a CEO of htmx so are you: https://htmx.ceo reply ossobuco 4 hours agorootparent/u/recursivedoubts correcting /u/recursive has to be some of kind of joke you guys prepared in advance, right? reply adzm 8 hours agorootparentprevI'm sorry, can someone please explain reply xupybd 13 hours agoparentprevAs another CEO of HTMX, how do you feel about this release? reply thekashifmalik 12 hours agoprevSo happy every time I see HTMX. I'm hoping there is more innovation in this space with React engineers rediscovering the benefits of server-side rendering and Backend-For-Frontend efforts. I think the perfect stack involves all 3 paradigms (initial loads, hypermedia loads and data/AJAX loads) used in parts of the application as makes sense. reply bogdan 10 hours agoparent> React engineers rediscovering the benefits of server-side rendering and Backend-For-Frontend efforts React 19 has just been released recently with server components and server actions. Worth having a look. It's a very powerful model. reply WD-42 15 hours agoprevNice boring release, just the way I like it. Thank you! reply euroderf 12 hours agoprevI'd like to see a demo of htmx talking to the WebAssembly HTTP capability component. reply ianpurton 10 hours agoparentWhat is that? reply Babawomba 8 hours agoprevTried Htmx a while back... mixed feelings. Love how easy it is to get basic interactivity—honestly, adding a filter or an upvote button in a couple of lines of HTML feels like magic. No messing with a frontend framework, no bundlers - just works. But I hit walls when I needed more complex stuff. Like, if I want to keep state on the client (e.g., a live calculator or sliders updating a table), Htmx feels clunky. Sending a request to the server every time a user adjusts a slider—yeah, no. React or Svelte is a better fit there. And if you're already using those tools. Htmx starts to feel redundant. Why add more when you've got everything in one place? Also, not sure about the recent patch release - Changing default behavior in a minor update? Feels risky, even if it's \"fixing a bug.\" Imagine waking up to find your body tag wiped because you updated without reading the changelog, yikes. Makes me think twice about trusting it in production. Butfor MPAs or projects that lean heavily on server-side rendering, it’s a game-changer. You’re not rebuilding the wheel, just enhancing it. Htmx has a sweet spot—it’s just not always the right tool for every job. Depends what you're building, I guess... reply adzm 8 hours agoparentSame here. I honestly love react, it just seems to make sense, integrates well with legacy stuff, great tooling, really nothing else comes close reply htmxceo 7 hours agoprevI tried to use HTMX to fix some of the plumbing in our bathroom and I’m very disappointed … it just isn’t fit for purpose. I’m sticking with React reply halfcat 4 hours agoparentSame. Tried to write a boot loader in HTMX. Wish I’d used React instead. reply RamboRogers 12 hours agoprevHtmx belongs on a pedestal reply peterpost2 9 hours agoparentAgreed, web development without all the time consuming nonsense. reply 2-3-7-43-1807 8 hours agoprevwhat is the selling point of htmx? why use it versus ...? reply halfcat 4 hours agoparentYou team knows Python/Ruby/PHP/Elixir/C# and uses Django/Rails/Laravel/Phoenix/ASP and doesn’t have a need to hire dedicated frontend people. You can leverage your existing talent to drive the frontend from the backend. It has limitations (not going to use HTMX to build Google Maps) but handles the 80% of use cases well for little added skillset required. reply sublinear 13 hours agoprevnext [22 more] [flagged] xupybd 12 hours agoparentHarsh dude, why not just keep quiet? reply sublinear 12 hours agorootparentSick and tired of any server-side rendering of web pages. If you don't have to deal with incident response you can be quiet. It doesn't scale and it complicates meeting any client requirements. Get this trash outta here. For real. reply jph00 12 hours agorootparentSick and tired of any server-side rendering of web pages.If you don&#x27;t have to deal with incident response you can be quiet.It doesn&#x27;t scale and it complicates meeting any client requirements. Get this trash outta here. For real. Ummm... do you know where you are? Do you know how this works? Hint -- try \"view source\" right now. I made it easy for you by pasting a random snippet above... reply sublinear 8 hours agorootparentI'm on a niche website full of people who are either too inexperienced to know what I mean or too managerial to give a fuck. reply xupybd 12 hours agorootparentprevI worked with server side rendering for close to a decade. It's very reliable. reply sublinear 8 hours agorootparentIt's not reliable when your precious servers go down because they're far more complicated than one that simply runs apache or nginx and needs constant patching. (fully aware of the origin of the name \"apache\") reply sublinear 12 hours agorootparentprevnext [6 more] [flagged] tock 11 hours agorootparentDo you feel the same way about SSR for non static websites vs an SPA? reply sublinear 8 hours agorootparentSPAs are not necessarily SSR. Can you clarify your question? reply xupybd 12 hours agorootparentprevWhat happens when your static stie infrastructure goes down? I fear your argument is turtles all the way down. Edit: I'll show this to my boss. I'm sure he'll get a chuckle. reply sublinear 12 hours agorootparentI hope he does because that's a huge sign your entire management structure is super out of touch and I hope you're next DOR or incident ressponse reveals the truth. reply xupybd 12 hours agorootparentMay the truth set us all free reply recursivedoubts 12 hours agorootparentprevand yet here we find ourselves, exchanging our server side rendered opinions on the matter reply xupybd 12 hours agorootparentEach comment should be entered into the code then committed. That commit then should trigger the CI build. That should then upload the static assets to the CDN. It's clearly the optimal solution. reply sublinear 8 hours agorootparentThat's the most nonsensical bs I've read in a while do you even know what CI is? Can you break down line by line what this probable CI script you're supposing looks like and explain business justification why a static file would ever be uploaded more than once? reply xupybd 7 hours agorootparentSo you can have comments reply spirodonfl 11 hours agorootparentprevImagine being this delusional reply sublinear 8 hours agorootparentGo ahead and tell me how cacheable your SSR page is. If it was a static file? Oh yeah it never changes! How convenient! Maybe that's the point! People who promote SSR are simply trying to rope frontend devs into their P2 or P1 incident responses and use them as whipping boys. This shit has to stop. If you don't suspect your web devs are doing all kinds of cache-busting dog shit on your backend ruining your performance dude idk what to tell you other than: what year do you think it is and who do you think you hired? It's SSR nonsense constantly spammed on sites like this that make you think it's a good idea and ultimately give inexperienced devs the green light to do all kinds of dumb shit that carries heavy technical debt once you need to meet an SLA that is more realistic than anyone who seriously uses HTMX on anything at that scale. There's no excuse for using tools like this other than ignorance. reply spirodonfl 2 hours agorootparentWho hurt you? reply xupybd 8 hours agorootparentprevWhy can't you use HTMX with a static back end? It's a front end library? reply sublinear 7 hours agorootparentI'll let someone else go down this rabbit hole with you. You've responded quite a bit to this thread which is curious. HTMX is not generally used standalone and I'll leave this question at that :) reply xupybd 7 hours agorootparentYou comment on my comment and I reply. Why is that curious? reply gloosx 12 hours agoprev>htmx.ajax, htmx:trigger, synthetic load event >Nested shadow root >element is reinitialized via htmx.process() >Boostedtags >htmx-powered elements located outside a form, but that refer to a form via the form attribute >preload, hx-boost, response-targets, ws, head-support, sse I see... Folks at HTMX are always thriving for a little bit more power of hypertext. Remember guys this is how S.I.M.P.L.I.C.I.T.Y. looks like. Fnatics, unleash your downvotes! reply xupybd 15 hours agoprev [–] Nothing new under the sun. This is just a rip off of intercooler js. Only without jQuery. Times moved on and someone copied the idea (exactly) but with the aid of modern JavaScript didn't need jQuery. I mean it's nice that it's a bit more modern but still. reply antonyt 15 hours agoparentJust in case this isn’t sarcasm, you may be interested to know they’re made by the same person. https://news.ycombinator.com/item?id=23330881 reply genocidicbunny 15 hours agoparentprev [–] You do realize that htmx is intecooler.js 2.0? Made by the same people, for the same purpose. And if you don't believe me, the intercooler.js homepage says pretty much the same exact thing. reply xupybd 14 hours agorootparent [–] I think you'll find there is some animosity https://x.com/intercoolerjs/status/1845878585078567084?t=p41... reply recursive 14 hours agorootparentIt's a joke. reply benatkin 14 hours agorootparentIt's a dank meme. reply choilive 14 hours agorootparentprev [–] ... you realize this is a joke right? reply xupybd 14 hours agorootparent [–] Tell that to Carson Gross! reply choilive 12 hours agorootparent [–] The creator of HTMX and Intercooler.js? I think they already know. reply xupybd 12 hours agorootparent [–] Both of them take this feud very seriously from what I've seen reply xupybd 9 hours agorootparenthttps://x.com/intercoolerjs/status/1859652045399355559?t=-za... reply nakeru 9 hours agorootparentprev [–] Is this supposed to be a joke? If it is... it isn't funny. If it isn't... Maybe it's time to face the fact that you're very wrong about this... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The latest update, version 2.0.4, introduces significant changes such as setting the default target for htmx.ajax to the body, fixing nested shadow root issues, and improving event handling and tag behavior.",
      "This update also includes compatibility updates and bug fixes for extensions, highlighting ongoing improvements in the htmx library, which is used for enhancing HTML with AJAX, CSS Transitions, WebSockets, and Server-Sent Events (SSE).",
      "The changelog reflects a consistent effort to enhance features and fix issues, with notable updates like improved shadow DOM support and the addition of new functionalities over time."
    ],
    "commentSummary": [
      "Htmx 2.0.4 has been released, prompting discussions about its application in enhancing web interactivity by replacing JavaScript for simpler tasks.",
      "The update introduces a change in the default behavior of `htmx.ajax`, which some users consider a breaking change, affecting existing implementations.",
      "Htmx is recognized for improving server-side rendering without the need for extensive frontend frameworks, though it may not be suitable for complex client-side interactions compared to frameworks like React or Alpine."
    ],
    "points": 185,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1734139394
  },
  {
    "id": 42415602,
    "title": "Uv, a fast Python package and project manager",
    "originLink": "https://docs.astral.sh/uv/",
    "originBody": "uv An extremely fast Python package and project manager, written in Rust. Installing Trio's dependencies with a warm cache. Highlights 🚀 A single tool to replace pip, pip-tools, pipx, poetry, pyenv, twine, virtualenv, and more. ⚡ 10-100x faster than pip. 🐍 Installs and manages Python versions. 🛠 Runs and installs Python applications. ❇ Runs scripts, with support for inline dependency metadata. 🗂 Provides comprehensive project management, with a universal lockfile. 🔩 Includes a pip-compatible interface for a performance boost with a familiar CLI. 🏢 Supports Cargo-style workspaces for scalable projects. 💾 Disk-space efficient, with a global cache for dependency deduplication. ⏬ Installable without Rust or Python via curl or pip. 🖥 Supports macOS, Linux, and Windows. uv is backed by Astral, the creators of Ruff. Getting started Install uv with our official standalone installer: macOS and LinuxWindows $ curl -LsSf https://astral.sh/uv/install.shsh $ powershell -c \"irm https://astral.sh/uv/install.ps1iex\" Then, check out the first steps or read on for a brief overview. Tip uv may also be installed with pip, Homebrew, and more. See all of the methods on the installation page. Project management uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to rye or poetry: $ uv init example Initialized project `example` at `/home/user/example` $ cd example $ uv add ruff Creating virtual environment at: .venv Resolved 2 packages in 170ms Built example @ file:///home/user/example Prepared 2 packages in 627ms Installed 2 packages in 1ms + example==0.1.0 (from file:///home/user/example) + ruff==0.5.4 $ uv run ruff check All checks passed! See the project guide to get started. uv also supports building and publishing projects, even if they're not managed with uv. See the publish guide to learn more. Tool management uv executes and installs command-line tools provided by Python packages, similar to pipx. Run a tool in an ephemeral environment using uvx (an alias for uv tool run): $ uvx pycowsay 'hello world!' Resolved 1 package in 167ms Installed 1 package in 9ms + pycowsay==0.0.0.2 \"\"\" ------------------------ \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w|| || Install a tool with uv tool install: $ uv tool install ruff Resolved 1 package in 6ms Installed 1 package in 2ms + ruff==0.5.4 Installed 1 executable: ruff $ ruff --version ruff 0.5.4 See the tools guide to get started. Python management uv installs Python and allows quickly switching between versions. Install multiple Python versions: $ uv python install 3.10 3.11 3.12 Searching for Python versions matching: Python 3.10 Searching for Python versions matching: Python 3.11 Searching for Python versions matching: Python 3.12 Installed 3 versions in 3.42s + cpython-3.10.14-macos-aarch64-none + cpython-3.11.9-macos-aarch64-none + cpython-3.12.4-macos-aarch64-none Download Python versions as needed: $ uv venv --python 3.12.0 Using CPython 3.12.0 Creating virtual environment at: .venv Activate with: source .venv/bin/activate $ uv run --python pypy@3.8 -- python Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30) [PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>>> Use a specific Python version in the current directory: $ uv python pin pypy@3.11 Pinned `.python-version` to `pypy@3.11` See the installing Python guide to get started. Script support uv manages dependencies and environments for single-file scripts. Create a new script and add inline metadata declaring its dependencies: $ echo 'import requests; print(requests.get(\"https://astral.sh\"))' > example.py $ uv add --script example.py requests Updated `example.py` Then, run the script in an isolated virtual environment: $ uv run example.py Reading inline script metadata from: example.py Installed 5 packages in 12msSee the scripts guide to get started. The pip interface uv provides a drop-in replacement for common pip, pip-tools, and virtualenv commands. uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more. Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the uv pip interface. Compile requirements into a platform-independent requirements file: $ uv pip compile docs/requirements.in \\ --universal \\ --output-file docs/requirements.txt Resolved 43 packages in 12ms Create a virtual environment: $ uv venv Using CPython 3.12.3 Creating virtual environment at: .venv Activate with: source .venv/bin/activate Install the locked requirements: $ uv pip sync docs/requirements.txt Resolved 43 packages in 11ms Installed 43 packages in 208ms + babel==2.15.0 + black==24.4.2 + certifi==2024.7.4 ... See the pip interface documentation to get started. Learn more See the first steps or jump straight to the guides to start using uv.",
    "commentLink": "https://news.ycombinator.com/item?id=42415602",
    "commentBody": "Uv, a fast Python package and project manager (astral.sh)164 points by Loic 10 hours agohidepastfavorite101 comments Techtsunami 15 minutes agoI have noticed a spike in attention to UV since Anthropic announced the Model Context Protocol (MCP). After using it for MCP development, I am moving from pyenv to uv! https://www.anthropic.com/news/model-context-protocol reply TeMPOraL 7 hours agoprevSomeone needs to collect the data on UV's rise to popularity and do a sociological study, because from where I sit[0], UV just suddenly came out of nowhere, and despite being confusingly named[1] and backed by a for-profit company, has already captured the hearts and minds of Python developers. Between this and other tooling from that same company, it feels to me that, in the space of less than a year, Python has turned from a community language into a company-led one (like. e.g. Scala). Not saying whether it's good or bad - just that it's damn curious how this played out. It feels like Python leadership got taken over by some company almost overnight; I'd love to understand how did this happen. -- [0] - Arguably an outsider to Python community, but like everyone else, downstream of it, and always affected by it, ever since Python became the de-facto standard in Linux as the language between C and Bash. [1] - Anyone remembers libuv? Spearheading the whole async/await paradigm by powering it in Node.JS, it's one of the most known and talked about libraries ever. reply hobofan 4 hours agoparentIt doesn't feel too surprising to me. The core developer tooling for Python was (/is) about on par with some of the other top languages (C, C++, Java), but lacking when compared to some of the others (Rust, Go, JS/TS). There have also been previous attempts (Pipenv/Poetry) that did prove demand but fell flat in some regards. So it feels like there wasn't any magic, trickery or \"take over\", but they just filled a void. Control over uv and ruff (and now also python-build-standalone) doesn't really give Astral significant leverage over Python as a language. They are also quite involved in standardizing many parts of uv via PEPs, which I'm sure the PSF could shoot down if they were overly favoring uv's goals. Compared to other languages Python leadership also always made the impression to me that they'd rather focus on the language itself and have a looser grip on the ecosystem surrounding it even if that comes with a more fragmented ecosystem (which has already been the status quo for most of Python's existence). I think that makes it very hard to compare to e.g. when Yarn entered the Node.js package manager scene. It also doesn't feel too surprising that there is little resistance against commercial involvement. Commercially-led programming languages were quite the norm in the past and also seem to be having a comeback (or trying to). In some languages where your median developer has more years of experience and they likely grew up with languages which are more \"grassroots\" the resistance would be higher. And while I would assume that the people at the PSF also fit that profile, in a high-influx language such as Python, the majority of the Python developers do not. reply keb_ 1 hour agoparentprev> Someone needs to collect the data on UV's rise to popularity and do a sociological study, because from where I sit[0], UV just suddenly came out of nowhere, and despite being confusingly named[1] and backed by a for-profit company, has already captured the hearts and minds of Python developers. This happens in the Node/React community literally once or more times a year, haha. reply zanie 2 hours agoparentprevAs a pretty minor note, it's not that we _needed_ a two letter name. We considered hundreds of names and it really came down to what was available on PyPI (because it was table stakes that it could be installed from there). We are aware of libuv — it's used in Python too. However, it's a totally different domain and the name conflict isn't really a problem for our users. Frankly, I'm just happy we didn't land on yet another packaging acronym or snake species :) reply dist-epoch 7 hours agoparentprevBecause uv is excellent in some ways and good in all ways. Pretty much all other package managers suck in some way. > confusingly named The name needs to be ultra-short, there are only so many 2 and 3 letter words which are not already taken on linux/windows. > Python has turned from a community language into a company-led one That's quite a radical take, reducing a language to it's package manager and linter. > backed by a for-profit company so is VS Code reply TeMPOraL 6 hours agorootparent> The name needs to be ultra-short, there are only so many 2 and 3 letter words which are not already taken on linux/windows. So? 3 letters isn't some magic cutoff; cutting your command down to 3 letters or less doesn't make it suddenly 10x more effective for its users. 4 or 5 letters would be fine, too. > That's quite a radical take, reducing a language to it's package manager and linter. Package manager and linter are the most fundamental tools to a programming language in a broader sense, second only to the reference compiler/implementation. The trend in the last couple decades is to, in fact, make all three part of the core, under purview of the same person or group that designs the language itself, and its standard library. I.e. if you want to \"own\" the future of a language, the second best option after owning the most popular runtime, is to own the most popular package manager. And I can see this happening already in discussion threads about Python I've been reading over past few months. It's not just that people are excited about UV itself, they're treating Astral as a \"thought leader\" now. Again, I'm not saying it's bad, or that Astral would be a bad steward. I'm just surprised to see a previously diverse/anarchic language community to suddenly feel like it'd welcome such stewardship. > so is VS Code VS Code is its own thing; sure, it sucked oxygen out of IDE space on UI front, but it also competes against JetBrains in the same space, plus, thanks to LSP, it revitalized Vim and Emacs as viable competitors and enabled creation of even more editors. In contrast, UV just put a single company in the core position to influence the direction Python as a language takes, which is a new situation for Python - one of the last few popular languages that didn't have a corporate benefactor to start and push it into popularity. reply dist-epoch 6 hours agorootparent> UV just put a single company in the core position to influence the direction Python as a language takes I would argue VS Code where the most popular extension is for the Python language has more influence than Astral. reply joostlek 9 hours agoprevUv has been awesome so far. It brought the release time for Home Assistant down from an hour and a half to about 15 minutes. Also installing all the dependencies from scratch used to give you enough time to grab lunch and drink coffee, and now we can only grab the coffee in that time! reply nullify88 8 hours agoparentUnfortunately the implementation in HA also broke a lot of addons from HACS for many people running HA in a container. reply delusional 8 hours agorootparentClassic software problem. \"This thing is so great, its never been faster. Now if only it didn't break everything for my users\" reply bdzr 3 hours agorootparentAn alternative framing. \"This software could be so fast, but it's bogged down by having to support every single workflow it's ever once even accidentally supported.\" reply outlore 8 hours agoprevThings i love about uv/astral - Putting .venv automatically into the project directory - Installing dependencies with pyproject.toml - Installing any Python version - Fast pip installs - uvx (like npx) - Ruff formatter and linter, made by the same people Python used to give me a headache, now I tend to reach for it more often, exclusively thanks to uv reply amai 27 minutes agoparentI only don't like the .venv in the project directory. It tends to get copied into git or docker. And it makes backup of a project a lot bigger and taking longer because of the many files. reply wiseowise 8 hours agoparentprevI concur. Python was essentially dead for me outside of simple scripts, because of constant friction: pip, pyenv, poetry, pyproject.toml, rye - wtf? Now it's python3 -m pip3 install --user uv; uv init; uv addand I'm good to go. Or amazing uvx . Finally someone understands how it is supposed to be done. reply nchmy 8 hours agorootparentEven better, use mise to install uv and all your other tooling reply HumanOstrich 6 hours agorootparentHey a fellow mise user in the wild! I use it everywhere now for both personal and work projects. Cheers! reply mickeyp 8 hours agorootparentprevAs opposed to: `python3 -m pip install ' to install it? And `python3 -m ' to run it? reply dagw 7 hours agorootparent'python3 -m pip install ' to install it? Won't update your pyproject.toml and lock file 'python3 -m ' to run it? Won't install the dependencies you need or set up an insolated environment . 'uvx ' will create a venv, make sure you have all the dependencies thatneeds and runreply wiseowise 8 hours agorootparentprevYou forgot to initialize venv and activate it. And now also do it on other dev's machine shared via git. reply mickeyp 8 hours agorootparentThey are one-offs, much like your init command. You do not have to activate it: you can explicitly invoke the binary in the venv if you do not want this. reply wiseowise 8 hours agorootparentI spawn dozens of one-offs, cost adds up. Some of those evolve to not be one-offs, and then synchronization with other devs becomes a problem. reply Evidlo 9 hours agoprevIf I was the Python BDFL I would just merge this into pip and solve Python packaging forever. Only decisive action will fix package tooling fragmentation. reply aidos 9 hours agoparentDisagree. That seems like it would just slow down progress. Astral are winning mindshare because the tooling is so much better than the previous generations. That’s the action that’s required here - to be the compelling choice, rather than another choice that’s pretty much like the others and differs only a little. reply dagw 7 hours agoparentprevPeople also said the same about poetry and pipevn (and no doubt some other tools I'm forgetting). reply Evidlo 40 minutes agorootparentNeither of which became the canonical way of installing packages mostly because the Python Software Foundation does not want to endorse anything in particular. reply cinntaile 9 hours agoprevHave they figured out yet how this VC backed company will make money? It's quite important imo, I don't want a watered down experience 5 years from now. reply bdzr 3 hours agoparentIt sounds like they're not yet at the stage where they need to worry about it, though I've heard Charlie mention making an easy to host package registry as one offering. reply the_mitsuhiko 7 hours agoparentprevCharlie is on record stating that their goal is to sell value added pieces to their tooling and keep the core tools free and open. reply eddsolves 8 hours agoparentprevPydantic had a nice model where the open source tool is fantastic, but they now sell a cloud based logging system around that. There will be some enterprise tooling around UV that they could sell while keeping the tool itself free reply qprofyeh 9 hours agoparentprevI would pay if they could make our GitHub CI run 20-30% faster. reply benreesman 8 hours agoprevUsing `uv` for Python is the first time I have used Python and enjoyed the experience full stop. `ruff` is also just straight up amazing. Everything else should do us all a favor and deprecate itself tomorrow. reply pletnes 9 hours agoprevI’ve been missing a python tool like this that isn’t written in python. Conda was good in this regard - having a distribution without first installing python is a massive improvement to the «getting started» problems in python. reply rollcat 9 hours agoparentWelcome to the bootstrapping problem. The original take is \"how do I build a C compiler without a C compiler\", and some amazingly gifted people from the GNU/Guix team managed to take it to its logical conclusion - and wrote a 357 byte piece of annotated machine code, from which an entire distro can be bootstrapped. On the bright side, uv is written in Rust, which makes distributing prebuilt releases practical, and helps end-users getting started. OTOH Linux+GNU+GCC pale in comparison to Rust's own bootstrapping problem - each Rust compiler is written in some previous release/dialect of Rust, all the way back to the pre-1.0 days, when it was written in an obscure dialect of OCaml. There are efforts underway to make Rust bootstrappable, but as of right now the Python ecosystem might be painting itself into a corner with slowly making Rust a hard dependency. https://bootstrappable.org reply zelphirkalt 8 hours agoprevNot quite sure what kind of projects people are talking about here, where Poetry takes too long. Must be pretty massive sets of dependencies. Maybe huuuge monoliths? What I usually do is build a venv in a docker container of a service and then that gets deployed. I don't see a problem, if this took a minute or two, but so far it never did take that long. reply movpasd 8 hours agoparentI'd say there are two things that make me prefer rye/uv. The speed is one — sometimes I'm in the middle of a project and realise I need to pull in another dependency. Keeping the disruption to flow at a minimum is helpful in those cases. So it's not about deployed performance, it's about mental friction. The other is I've found Poetry liable to breaking in obscure ways. I don't fully control everything on my work machine, which I suspect is the issue. So far, rye and uv have been smooth, but that might be down to me not having used them long enough. reply Leynos 8 hours agoparentprevYes, huge monoliths reply dist-epoch 7 hours agoparentprevIf you do anything ML or neural networks, suddenly you have hundreds of packages totaling over 1 GB. reply andrewinardeer 8 hours agoprevPlease give me commands to create a virtual environment built with libraries listed in the requirements.txt of a GitHub repo. Ubuntu here. reply zanie 2 hours agoparente.g. $ uv venv Using CPython 3.12.6 Creating virtual environment at: .venv Activate with: source .venv/bin/activate $ uv pip install -r https://raw.githubusercontent.com/astral-sh/uv/refs/heads/main/docs/requirements.txt Resolved 43 packages in 283ms Prepared 4 packages in 64ms Installed 43 packages in 445ms ... reply kthejoker2 9 hours agoprevHappy user so far in my early days ... appreciate the speed for sure reply greatgib 6 hours agoprevFor me it is not great because of the new requirement for \"rust\" for basic Python. Does not make any sense. Especially if the main selling point is \"speed\". I never encounter cases where the pip install equivalent was particularly unbearably long except in very badly designed and broken projects. The kind of one that that import every possible dependency (nom style) with pinning things on broken and incompatible set of dependencies... Also, I like very much the concept of one tool for one usage. And having venv and pip is great, having one tool cluster mixing everything is not. Sure in most dummy usage cases it will be great, but you have more chance of clusterfucks and complicated unresolvable issues. Even more if developers are opinionated on a single way to do something. reply the_mitsuhiko 3 hours agoparent> For me it is not great because of the new requirement for \"rust\" for basic Python. Does not make any sense. The language of choice for such core functionality in the past was C. I'm not sure how much spelunking you did in the core interpreter, but the Astral rust code is much easier to understand and modify. reply throw646577 8 hours agoprevThe answer to the question about VC funding is weirdly obvious at any sort of distance away from the emotive things. Communities should probably cautiously welcome VC funding for well-integrated community members solving hard, core problems with correctly-licensed contributions back to the community, as long as that effort doesn't divert community engineering focus away from long-term community goals and towards the startup's goals in non-beneficial way. They should be more cynical about things that don't happen this way, but then they can keep doing their own thing anyway. Ondsel found the money for two major core technical problems to be addressed in FreeCAD, and seems to have had a pretty positive impact on release-oriented thinking in general. They then folded. It is a loss, but essentially none of the work was lost. Frankly I am not sure if the \"written in Rust\" element here is culturally beneficial in the long term or not; I don't know enough about Python or really anything about Rust. reply jamesblonde 9 hours agoprevSuper fast installs - when it works. I had problems on Ubuntu for linux (WSL) with a clang dependency, which i could never solve. But on linux boxes, it's so much better than pip/conda/etc. I also like that i can use it with conda environments. Just create conda env, then install with 'uv pip install ....' reply claytonjy 1 hour agoparentHave you tried pixi? I haven’t, and i’m hoping i can continue to avoid conda, but it’s a uv-using conda replacement: https://pixi.sh/latest/ reply disgruntledphd2 8 hours agoparentprev> I also like that i can use it with conda environments. Just create conda env, then install with 'uv pip install ....' Huh cool, I'll have to try that. Conda is great for getting the dependencies for non python code (geos/gdal/cuda etc) but uv is super fast and straightforward (makes building packages much, much easier). reply camel_Snake 1 hour agorootparentsame company has a different tool as well called pixi which aims for much nicer integration with the conda ecosystem. Also uses uv under the hood so speed is comparable. https://github.com/prefix-dev/pixi reply mickeyp 8 hours agoparentprevSo now you're using not one (conda); not two (conda and uv), but three (conda, uv and pip) different package managers to manage your Python environment? reply dagw 6 hours agorootparent\"uv pip\" is a ground up implementation of python pip and doesn't use the python pip command in any way. So still only two package managers. And the point is that you always have to use two package managers when developing python. One that installs python and various non-python libraries and dev tools, and one that installs python libraries. Conda in this scenario is replacing apt as much as anything else. reply These335 9 hours agoprevI have only ever really used venv. Poetry was fine but didn't give me any additional benefits that I could see. What does this offer? And more broadly, why do people consider pip to be a problem? I have literally never had any issues with it in any of my projects. reply chad1n 9 hours agoparentPersonally, I use it for everything right now. It's faster to do `uv init` and then add your dependencies with `uv add` and than just `uv run `. You can argue that poetry does the same, but `uv` also has a pipx alternative, which I find myself using more than the package manager that my distro offers, since I never had compatibility issues with packages. reply zelphirkalt 9 hours agoparentprevThe main advantage these tools (poetry, pipenv, uv, ...) offer is, that they let you create lock files, which make your venv reproducible. Without that, you are kind of living in the wild west, where tomorrow you project can break. These tools help with projects, that are supposed to do more than \"runs on my machine\". reply These335 5 hours agorootparentMaybe I'm not fully grasping lock files then, but why isn't it sufficient to just pin the versions in the requirements.txt? Obviously it doesn't handle the python version itself but I just use pyenv for that. So my stance is just pyenv + venv seems to solve those problems. But then I see people singing the praises of these newer tools and I wonder what I am not getting reply thunky 4 hours agorootparentLook into concrete vs abstract dependencies: https://martin-thoma.com/python-requirements/ reply gauge_field 8 hours agorootparentprevJust to give a concrete example, it helped me with my projects involving langchain and several langchain extensions. I have a clear and consistent source of version record for each dependency. reply thunky 4 hours agorootparentprev> create lock files That's where pip-tools comes in. reply the_mitsuhiko 3 hours agorootparentAnd you can use uv as a full replacement for that with less bugs, faster performance and just generally a more pleasant experience. pip-compile -> uv pip compile and pip-sync -> uv pip sync. (Though I think the high level interface is the better thing to use) reply thunky 3 hours agorootparentNo disagreement here, just pointing out that it's also possible to do with existing tools. reply wiseowise 8 hours agoparentprevCohesion and simplicity of use. uv init; uv add No more pip freeze, source .venv/bin/activate, deactivate bullcrap. reply mickeyp 8 hours agorootparentYou don't have to 'activate' anything if you don't want to. The bin/ directory inside your venv contain the binaries and scripted entrypoints for the packages installed in your virtualenv. reply wiseowise 8 hours agorootparentYeah, and I don't \"have\" to use Make and build systems either, but it makes my life easier and bullshit free. reply eternityforest 5 hours agoprevIs there any way to make wheels with pinned dependencies with this? That's the main thing keeping me with Poetry. Other than that I'm super excited. reply zanie 2 hours agoparentNot yet! We're thinking about it but it's hard to do in a spec-compliant way. reply Raed667 9 hours agoprevDoes this still work if other devs on the project still use pyenv or other tools ? reply ilalex 9 hours agoparentYep. You can gradually start to use feature set of uv. Beside it uses standards of python project management, so you don’t have vendor lock-in here. reply vegabook 9 hours agoprev> poetry: 0.99 seconds Good enough for me and sans VC risk. reply short_sells_poo 9 hours agoprevSo, why should I switch to this and what is going to stop some other tool becoming the \"python package/env management darling\" in 2025? reply sswatson 8 hours agoparentThe way I feel is that if another tool comes along that I like better, I’ll switch again. Or if I prefer the stability for some reason, I won’t. Either way, I don’t see any need to stop people from building better things. reply thangngoc89 8 hours agoparentprevI switched to uv recently from poetry because uv manages the python version too. reply ilalex 9 hours agoparentprevHave you tried ruff for linting? If you have joy of using it, you should try uv. It’s the same feeling reply Jasondells 8 hours agoprevuv is cool, no doubt—super fast, love the idea of managing Python versions + deps all in one place. But VC funding... Rust... unofficial Python builds... lots of red flags here if you think about the long-term impact on the ecosystem. VC-backed tools always make me a little nervous. Sure, Astral says the tools will stay free, and I get that they're targeting enterprise for revenue (private package registries, etc.). But how many times have we heard this before? “Don’t be evil,” right? We’ve seen companies pivot to paywalls or watered-down open-source tools after funding dries up. What guarantees do we have here that uv won't eventually fall into that same trap? Yeah, Rust is amazing (ruff is a beast), but it’s still a small subset of devs compared to Python. If Astral folds or just loses interest, how easy is this really going to be for the Python community to maintain? Forkable? Sure. But forkable ≠ maintainable when the dev pool is tiny. Also, what's with using unofficial Python builds by default? Even on platforms where official builds exist (macOS/Windows)? I get that these standalone builds solve certain problems (like bootstrapping), but it feels like a risky shortcut. If those unofficial builds go unsupported or change directions, where does that leave \"uv\"? Why not at least give users the option to rely on official binaries? And fragmentation... Python tooling is already a mess. Pip, poetry, conda, pyenv, rye, flit, etc.—do we really need another tool in the mix? Feels like every new tool just promises to \"fix packaging forever\" but ends up adding another layer of complexity. Why not contribute these improvements to existing tools like pip? Sure, innovation is great, but at what point does it become too much choice and not enough cohesion? uv looks great, and I love the speed + features. But the ecosystem-level risks here... hard to ignore. Would love to see some stronger guarantees around open-source sustainability, community governance, and alignment with Python standards before jumping in fully. Otherwise, it’s just one more shiny tool that could end up abandoned or locked behind a paywall in 5 years. reply jdxcode 6 hours agoparent> Also, what's with using unofficial Python builds by default? Even on platforms where official builds exist (macOS/Windows)? I get that these standalone builds solve certain problems (like bootstrapping), but it feels like a risky shortcut. If those unofficial builds go unsupported or change directions, where does that leave \"uv\"? Why not at least give users the option to rely on official binaries? The official macOS binaries wouldn't work for uv because they're not portable. They're also taking ownership over the indygreg project which is a great thing for everyone since portable pythons are useful in a lot of contexts. I'm sure they'll start sending some of the portability changes upstream too once they get there. I don't see how this is criticism. reply Narushia 6 hours agoparentprevI could see Astral's unofficial builds becoming official at some point after they've matured a bit more. reply dist-epoch 7 hours agoparentprev> unofficial Python builds You don't need to use those, works perfectly fine with whatever Python is on the machine. reply the_mitsuhiko 9 hours agoprevSince the topic of VC funding keeps coming up, I will quote myself from the blog post I did a few months ago [1]: > there is an elephant in the room which is that Astral is a VC funded company. What does that mean for the future of these tools? Here is my take on this: for the community having someone pour money into it can create some challenges. For the PSF and the core Python project this is something that should be considered. However having seen the code and what uv is doing, even in the worst possible future this is a very forkable and maintainable thing. I believe that even in case Astral shuts down or were to do something incredibly dodgy licensing wise, the community would be better off than before uv existed. [1]: https://lucumr.pocoo.org/2024/8/21/harvest-season/ reply thangngoc89 8 hours agoparentBut uv is written in Rust so it means there are considerably more efforts to fork it as compared to Python tools reply eddsolves 8 hours agorootparentA lot of modern tooling in python is rust based such as pydantic - the skills to maintain this are already available reply woadwarrior01 8 hours agorootparentruff is also from Astral. reply eddsolves 8 hours agorootparentYeah my bad, good point, didn't realise! Two great tools from one company though :) reply the_mitsuhiko 7 hours agorootparentprevIt depends much more on the quality of the code and how it’s structured. I feel pretty confident that you would find uv easier to maintain than either pip or poetry despite the first two being Python code. reply schubart 8 hours agorootparentprevHow so? reply globalnode 8 hours agorootparentI think they must mean that the number of rust developers would be small compared to the number of python developers. Perhaps? Not sure myself. reply nsteel 8 hours agorootparentI think people need to appreciate that the number of developers interested in actually helping with free software maintenance is a subset of the number of developers. And when it comes to Python in particular, that subset is proportionally very small. That's just my anecdotal experience of similar projects in both ecosystems. reply hobofan 5 hours agorootparentprevNumbers aren't everything. Python has been around for a long time and there were some attempts at creating a modern package manager for it. If it were feasible to create uv in Python, it would have probably happened by now. reply thangngoc89 3 hours agorootparentprevBecause it’s a tool for Python ecosystem. reply radicalbyte 8 hours agorootparentprevThere's a barrier of entry for the army of people who use Python but are not (and often have no interest in being) engineers/developers/programmers. This is the modern equivalent of building key components in Visual C++ for use by Visual Basic people; it kept the unwashed masses away from things they could break. I think that this is probably the only way you're ever going to fix the horrific experience of using Python in anger. Which is a good thing, Python's a great little language which is let down by being built on sand. reply darthrupert 8 hours agoparentprevI think there might be a reporting bias here? You only hear the negative news, i.e. when a vc-backed company does something bad. If they do something good, that's not news. reply bruh2 9 hours agoprevUV creator's response on the concerns regarding VC money: > I don't want to charge people money to use our tools, and I don't want to create an incentive structure whereby our open source offerings are competing with any commercial offerings (which is what you see with a lost of hosted-open-source-SaaS business models). > What I want to do is build software that vertically integrates with our open source tools, and sell that software to companies that are already using Ruff, uv, etc. Alternatives to things that companies already pay for today. > An example of what this might look like (we may not do this, but it's helpful to have a concrete example of the strategy) would be something like an enterprise-focused private package registry. A lot of big companies use uv. We spend time talking to them. They all spend money on private package registries, and have issues with them. We could build a private registry that integrates well with uv, and sell it to those companies. [...] > But the core of what I want to do is this: build great tools, hopefully people like them, hopefully they grow, hopefully companies adopt them; then sell software to those companies that represents the natural next thing they need when building with Python. Hopefully we can build something better than the alternatives by playing well with our OSS, and hopefully we are the natural choice if they're already using our OSS. https://hachyderm.io/@charliermarsh/113103564055291456 reply blitzar 8 hours agoparentPrior art. > Facebook's mission is to give people the power to build community and bring the world closer together. > Our informal corporate motto is \"Don't be evil.\" We Googlers generally relate those words to the way we serve our users – as well we should. But being \"a different kind of company\" means more than the products we make and the business we're building; it means making sure that our core values inform our conduct in all aspects of our lives as Google employees. > OpenAi. reply walthamstow 2 hours agoparentprev'I don't want to' is very different to 'I will never' reply Kwpolska 9 hours agoprevA VC-funded package and project manager for Python projects, written in Rust, and without involvement of the Python Packaging Authority (PyPA). If Python is too slow or otherwise not good enough to write a good Python package manager in, why use Python altogether? Using Rust enables uv to install Python interpreters. That feature uses unofficial third-party binary builds. There are no official binary builds for Linux, but there are such builds for Windows and macOS, yet they use the unofficial third-party builds on those platforms as well. Still, I would consider package and project management to be a separate feature from Python management, and I’d leave it to a different tool (which may be the system package manager on some platforms). reply the_mitsuhiko 9 hours agoparent> without involvement of the Python Packaging Authority (PyPA) The PyPA does not really exist. The closest to an actual \"authority\" is the packaging forum on discuss.python.org and the astral folks are active there, see for instance the recent threads on the lockfile standard or the dynamic metadata issue. > If Python is too slow or otherwise not good enough to write a good Python package manager in, why use Python altogether? People use Python, Astral exists to solve problems of Python people. I'm not sure what the language they are using to write the tool in is relevant. numpy, scipy, tensorflow and many other cornerstones of Python are written in C, C++ and other non Python languages. > but there are such builds for Windows and macOS As the author of Rye where I tried very much the same I can attest that the macOS builds are useless for the uv usecase. It's great that Astral is now maintaining the standalone builds which have become a cornerstone for many Python users over the last three years. We have based our entire development environments on those, even though we have not adopted either rye or uv at our company. reply inglor 9 hours agoparentprevI primarily use Rust at my job (and love it) but I still write most of my scripts, benchmarking code etc in Python. Python is a great scripting language and a great language to wrap other stuff. I have other projects in Python that wrap many packages, some in C++/Rust and working on Python is a lot more fun than most of these languages. When I'm writing this sort of code, I don't have to `.into()`, derive send/sync/debug/whatever, I don't have to `.clone()` my strings when I pass them to multiple places that accept `String`, I don't have to do oh so many things that make my production/critical code better but I care about very little when I'm writing scripts. I'm much more effective in my 80:20 in Python than in rust though admittedly I'm still on Poetry since uv is releasing vey quickly and my things work \"well enough\". (In package management land - I still think most ecosystems haven't caught up to JavaScript + Rust and Python's module systems have weirdness (mod.rs/__init__.py which is unnecessary) but Cargo _is_ overall really nice). reply wiseowise 8 hours agoparentprevI couldn't care less in which language it is written, as long as it solves my problems with Python. And uv absolutely does. reply fire_lake 9 hours agoparentprev> If Python is too slow or otherwise not good enough to write a good Python package manager in, why use Python altogether? Not every language needs to be good at every thing. Pythons main advantage is inertia, not the things required for this kind of tooling. reply nephanth 7 hours agoparentprev> If Python is too slow or otherwise not good enough to write a good Python package manager in, why use Python altogether? To write things that are not package managers? Are you suggesting not being the right tool for this job implies not being the right tool for any job? reply benatkin 9 hours agoparentprevPyPA has the involvement of Microsoft. It’s not a big deal, but unlike this it has the negative of GitHub being emphasized every time package publishing is brought up. I don’t see any negatives from having the choice of uv, and it’s a lot smaller of an entity than Microsoft. reply fire_lake 8 hours agoparentprev> Using Rust enables uv to install Python interpreters. It could be built with Python and ship with a standalone Python interpreter to bootstrap though. More likely, it’s easier to write fast and correct Rust code. reply em70 9 hours agoprev [–] Pixi is just better. reply thangngoc89 9 hours agoparent [–] Pixi uses uv solver too but more focused on integrating with the conda packaging world reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"uv\" is a fast Python package and project manager written in Rust, designed to replace multiple tools like pip, poetry, and virtualenv, offering a significant speed boost of 10-100x over pip.",
      "It provides comprehensive project management with features like a universal lockfile, Python version management, and support for Cargo-style workspaces, and can be installed without Rust or Python.",
      "\"uv\" is backed by Astral and supports multiple operating systems, including macOS, Linux, and Windows, offering advanced features and efficiency for managing dependencies and environments."
    ],
    "commentSummary": [
      "Uv is a rapidly growing Python package and project manager, noted for its speed and comprehensive management of Python versions and dependencies.",
      "The tool has gained attention following Anthropic's Model Context Protocol announcement, highlighting its potential impact on Python development.",
      "While some users appreciate its advantages over existing tools like pip and poetry, concerns about its VC funding, use of Rust, and unofficial Python builds raise questions about its long-term sustainability and potential ecosystem fragmentation."
    ],
    "points": 164,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1734165865
  },
  {
    "id": 42415386,
    "title": "What Is Entropy? A Measure of Just How Little We Know",
    "originLink": "https://www.quantamagazine.org/what-is-entropy-a-measure-of-just-how-little-we-really-know-20241213/",
    "originBody": "Home What Is Entropy? A Measure of Just How Little We Really Know. 14 Read Later Share Copied! (opens a new tab) 14 Comments Read Later Read Later statistical physics What Is Entropy? A Measure of Just How Little We Really Know. By Zack Savitsky December 13, 2024 Exactly 200 years ago, a French engineer introduced an idea that would quantify the universe’s inexorable slide into decay. But entropy, as it’s currently understood, is less a fact about the world than a reflection of our growing ignorance. Embracing that truth is leading to a rethink of everything from rational decision-making to the limits of machines. 14 Read Later Kristina Armitage/Quanta Magazine Introduction By Zack Savitsky Contributing Writer December 13, 2024 View PDF/Print Mode fundamental physics history of science information theory physics statistical physics thermodynamics All topics (opens a new tab) Life is an anthology of destruction. Everything you build eventually breaks. Everyone you love will die. Any sense of order or stability inevitably crumbles. The entire universe follows a dismal trek toward a dull state of ultimate turmoil. To keep track of this cosmic decay, physicists employ a concept called entropy. Entropy is a measure of disorderliness, and the declaration that entropy is always on the rise — known as the second law of thermodynamics — is among nature’s most inescapable commandments. I have long felt haunted by the universal tendency toward messiness. Order is fragile. It takes months of careful planning and artistry to craft a vase but an instant to demolish it with a soccer ball. We spend our lives struggling to make sense of a chaotic and unpredictable world, where any attempt to establish control seems only to backfire. The second law demands that machines can never be perfectly efficient, which implies that whenever structure arises in the universe, it ultimately serves only to dissipate energy further — be it a star that eventually explodes or a living organism converting food into heat. We are, despite our best intentions, agents of entropy. “Nothing in life is certain except death, taxes and the second law of thermodynamics,” wrote (opens a new tab) Seth Lloyd, a physicist at the Massachusetts Institute of Technology. There’s no sidestepping this directive. The growth of entropy is deeply entwined with our most basic experiences, accounting for why time runs forward and why the world appears deterministic rather than quantum mechanically uncertain. But despite its fundamental importance, entropy is perhaps the most divisive concept in physics. “Entropy has always been a problem,” Lloyd told me. The confusion stems in part from the way the term gets tossed and twisted between disciplines — it has similar but distinct meanings in everything from physics to information theory to ecology. But it’s also because truly wrapping one’s head around entropy requires taking some deeply uncomfortable philosophical leaps. As physicists have worked to unite seemingly disparate fields over the past century, they have cast entropy in a new light — turning the microscope back on the seer and shifting the notion of disorder to one of ignorance. Entropy is seen not as a property intrinsic to a system but as one that’s relative to an observer who interacts with that system. This modern view illuminates the deep link between information and energy, which is now helping to usher in a mini-industrial revolution on the smallest of scales. Two hundred years after the seeds of entropy were first sown, what’s emerging is a conception of this quantity that’s more opportunistic than nihilistic. The conceptual evolution is upending the old way of thinking, not just about entropy, but about the purpose of science and our role in the universe. The Motive Power of Fire Sadi Carnot at age 17. Louis-Léopold Boilly The notion of entropy grew out of an attempt at perfecting machinery during the industrial revolution. A 28-year-old French military engineer named Sadi Carnot set out to calculate the ultimate efficiency of the steam-powered engine. In 1824, he published a 118-page book (opens a new tab) titled Reflections on the Motive Power of Fire, which he sold on the banks of the Seine for 3 francs. Carnot’s book was largely disregarded by the scientific community, and he died several years later of cholera. His body was burned, as were many of his papers. But some copies of his book survived, and in them lay the embers of a new science of thermodynamics — the motive power of fire. Carnot realized that the steam engine is, at its core, a machine that exploits the tendency for heat to flow from hot objects to cold ones. He drew up the most efficient engine conceivable, instituting a bound on the fraction of heat that can be converted to work, a result now known as Carnot’s theorem. His most consequential statement comes as a caveat on the last page of the book: “We should not expect ever to utilize in practice all the motive power of combustibles.” Some energy will always be dissipated through friction, vibration, or another unwanted form of motion. Perfection is unattainable. Reading through Carnot’s book a few decades later, in 1865, the German physicist Rudolf Clausius coined a term for the proportion of energy that’s locked up in futility. He called it “entropy,” after the Greek word for transformation. He then laid out what became known as the second law of thermodynamics: “The entropy of the universe tends to a maximum.” Physicists of the era erroneously believed that heat was a fluid (called “caloric”). Over the following decades, they realized heat was rather a byproduct of individual molecules bumping around. This shift in perspective allowed the Austrian physicist Ludwig Boltzmann to reframe and sharpen the idea of entropy using probabilities. Share this article Copied! (opens a new tab) Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters (opens a new tab) Rudolf Clausius (left) originated the insight that entropy tends to increase. Ludwig Boltzmann rooted this rise in statistical mechanics. Theo Schafgans (left); Creative Commons Boltzmann distinguished the microscopic properties of molecules, such as their individual locations and velocities, from bulk macroscopic properties of a gas like temperature and pressure. Consider, instead of a gas, a group of identical game pieces on a checkerboard. The list of exact coordinates of all the checkers is what Boltzmann called a “microstate,” and their overall configuration — whether they form a star, say, or are all lumped together — is a “macrostate.” Boltzmann defined the entropy of a given macrostate in terms of the number of possible microstates that give rise to it. A high-entropy macrostate is one that has many compatible microstates — many possible arrangements of checkers that yield that same overall pattern. There are only so many ways the checkers can take on specific shapes that appear ordered, while there are drastically more ways for them to look randomly scattered across the board. Thus, entropy can be seen as a measure of disorder. The second law becomes an intuitive probabilistic statement: There are more ways for something to look messy than clean, so, as the parts of a system randomly shuffle through different possible configurations, they tend to take on arrangements that appear messier and messier. Jonas Parnow and Mark Belan/Quanta Magazine; Creative Commons: CC BY-ND 4.0 (opens a new tab) The heat in Carnot’s engine flows from hot to cold because it’s more probable for the gas particles to be all mixed up rather than segregated by speed — with hot, fast-moving particles on one side and cold, slow-moving ones on the other. The same reasoning applies to why glass shatters, ice melts, liquids mix and leaves decompose. In fact, the natural tendency for systems to move from low-entropy states to high-entropy ones seems to be the only thing that reliably imbues the universe with a consistent temporal direction. Entropy engraves an arrow of time for processes that would otherwise just as easily happen in reverse. The idea of entropy would ultimately extend far outside the confines of thermodynamics. “When Carnot wrote his paper … I don’t think anybody imagined what would come out of it,” said Carlo Rovelli (opens a new tab), a physicist at the Aix-Marseille University. Extending Entropy Entropy experienced a rebirth during World War II. Claude Shannon, an American mathematician, was working to encrypt communication channels, including the one that connected Franklin D. Roosevelt and Winston Churchill. That experience led him to think deeply about the fundamentals of communication over the following years. Shannon sought to measure the amount of information contained in a message. He did so in a roundabout way, by treating knowledge as a reduction in uncertainty. Claude Shannon, who has been called the father of information theory, understood entropy as uncertainty. Estate of Francis Bello; Science Source At first glance, the equation Shannon came up with has nothing to do with steam engines. Given a set of possible characters in a message, Shannon’s formula defines the uncertainty about which character will appear next as the sum of the probability of each character appearing multiplied by the logarithm of that probability. But if any character is equally probable, Shannon’s formula gets simplified and becomes exactly the same as Boltzmann’s formula for entropy. The physicist John von Neumann supposedly urged Shannon to call his quantity “entropy” — in part because it closely aligned with Boltzmann’s, but also because “no one knows what entropy really is, so in a debate you will always have the advantage.” Just as thermodynamic entropy describes the efficiency of an engine, information entropy captures the efficiency of communication. It corresponds with the number of yes-or-no questions needed to figure out the contents of a message. A high-entropy message is a patternless one; without a way to guess the next character, the message requires many questions to be fully revealed. A message with a lot of patterns contains less information and is easier to guess. “It’s a very beautiful interlocking picture of information and entropy,” Lloyd said. “Entropy is information we don’t know; information is information we do know.” How Shannon Entropy Imposes Fundamental Limits on Communication information theory How Shannon Entropy Imposes Fundamental Limits on Communication September 6, 2022 Read Later In two landmark (opens a new tab) papers (opens a new tab) in 1957, the American physicist E.T. Jaynes cemented this connection by viewing thermodynamics through the lens of information theory. He considered thermodynamics to be a science of making statistical inferences from incomplete measurements of particles. When partial information is known about a system, Jaynes proposed, we should assign equal likelihood to every configuration that’s compatible with those known constraints. His “principle of maximum entropy” provides the least biased way of making predictions about any limited data set and is now employed everywhere from statistical mechanics to machine learning (opens a new tab) and ecology. Notions of entropy developed in disparate contexts thus fit together neatly. A rise in entropy corresponds to a loss in information about microscopic details. In statistical mechanics, for instance, as particles in a box get mixed up and we lose track of their positions and momentums, the “Gibbs entropy” increases. In quantum mechanics, as particles become entangled with their environment, thus scrambling their quantum state, the “von Neumann entropy” rises. And as matter falls into a black hole and information about it gets lost to the outside world, the “Bekenstein-Hawking entropy” goes up. What entropy consistently measures is ignorance: a lack of knowledge about the motion of particles, the next digit in a string of code, or the exact state of a quantum system. “Despite the fact that entropies were introduced with different motivations, today we can link all of them to the notion of uncertainty,” said Renato Renner (opens a new tab), a physicist at the Swiss Federal Institute of Technology Zurich. Jonas Parnow and Mark Belan/Quanta Magazine; Creative Commons: CC BY-ND 4.0 (opens a new tab) However, this unified understanding of entropy raises a troubling concern: Whose ignorance are we talking about? A Whiff of Subjectivity As an undergraduate physics student in northern Italy, Carlo Rovelli learned about entropy and the growth of disorder from his professors. Something didn’t sit right. He went home, filled a jar with oil and water, and watched the liquids separate as he shook it — a seeming departure from the second law as it had been described to him. “What they’re telling me is bullshit,” he recalled thinking. “It was so clear there was a problem in the way that things were taught.” Rovelli’s experience captures a key reason why entropy is so perplexing. There are plenty of situations in which order appears to increase, from a child cleaning up their bedroom to a refrigerator cooling down a turkey. Rovelli understood that his apparent triumph over the second law was a mirage. A superhuman observer with powerful thermal vision would see how the parting of oil and water releases kinetic energy to the molecules, leaving a more thermally disordered state. “What’s really going on is there’s macroscopic order forming at the expense of microscopic disorder,” Rovelli said. The second law always holds; sometimes it’s just out of sight. E.T. Jaynes (top), in resolving a paradox raised by Willard Gibbs, clarified the subjective nature of entropy. Creative Commons (top); The Scientific Papers of J. Willard Gibbs Jaynes helped clarify this issue as well. To do so, he turned to a thought experiment first proposed in 1875 by Josiah Willard Gibbs, which became known as the Gibbs mixing paradox. Suppose you have two gases, A and B, in a box, separated by a divider. When you lift the divider, the second law demands that the gases will spread out and mix, increasing the entropy. But if A and B are identical gases held at the same pressure and temperature, lifting the divider doesn’t change the entropy, as the particles are already maximally mixed. The question is: What happens if A and B are distinct gases, but you can’t tell them apart? Over a century after Gibbs posed the paradox, Jaynes presented a resolution (opens a new tab) (which he insisted Gibbs already understood but failed to articulate clearly). Imagine that the gases in the box are two different types of argon, identical except that one of them is soluble in a not-yet-discovered element called whifnium. Before the discovery of whifnium, there’s no way to tell the two gases apart, and thus lifting the divider initiates no apparent change in entropy. After whifnium’s discovery, however, a clever scientist could employ it to differentiate the two argon species, calculating that the entropy increases as the two types mix. Furthermore, the scientist could design a whifnium-based piston that harnesses previously inaccessible energy from the natural mixing of the gases. What Jaynes made clear is that the “orderliness” of a system — and thus the potential to extract useful energy from it — depends on the relative knowledge and resources of an agent. If an experimenter can’t discriminate gases A and B, they are in effect the same gas. As soon as scientists have the means to tell them apart, they can harness work by exploiting the gases’ tendency to mix. Entropy depends not on the difference between the gases, but on their distinguishability. Disorder is in the eye of the beholder. The physicist Carlo Rovelli has long emphasized the observer-dependence of quantities in physics, including entropy. Christopher Wahl “The amount of useful work that we can extract from any system depends — obviously and necessarily — on how much ‘subjective’ information we have about its microstate,” Jaynes wrote. The Gibbs paradox emphasizes the need to treat entropy as a perspectival property rather than one inherent to a system. And yet, the subjective picture of entropy was difficult (opens a new tab) for physicists to swallow. As the philosopher of science Kenneth Denbigh wrote in a 1985 textbook (opens a new tab), “Such a view, if it is valid, would create some profound philosophical problems and would tend to undermine the objectivity of the scientific enterprise.” Accepting this conditional definition of entropy has required a rethinking of the fundamental purpose of science. It implies that physics more accurately describes individual experience than some objective reality. In this way, entropy has been swept up in the larger trend of scientists realizing that many physical quantities make sense only in relation to an observer. (Even time itself was rendered relative by Einstein’s theory of relativity.) “Physicists don’t like subjectivity — they’re allergic to it,” said Anthony Aguirre (opens a new tab), a physicist at the University of California, Santa Cruz. “But there is no absolute — that’s always been an illusion.” Jonas Parnow and Mark Belan/Quanta Magazine; Creative Commons: CC BY-ND 4.0 (opens a new tab) Now that acceptance has come, some physicists are exploring ways to bake subjectivity into mathematical definitions of entropy. Aguirre and collaborators have devised a new measure they call observational entropy (opens a new tab). It offers a way of specifying which properties a given observer has access to by adjusting how those properties blur, or “coarse-grain,” the observer’s view of reality. It then attributes equal probability to all microstates compatible with those observed properties, just as Jaynes proposed. The equation bridges thermodynamic entropy, which describes broad macroscopic features, and information entropy, which captures microscopic details. “This sort of coarse-grained, partly subjective view is the way we engage with reality in a meaningful way,” Aguirre said. A number of independent groups have used Aguirre’s formula to hunt for a more (opens a new tab) rigorous (opens a new tab) proof (opens a new tab) of the second law. For his part, Aguirre hopes to use his measure to explain why the universe started out in a low-entropy state (opens a new tab) (and therefore why time flows forward) and to get a clearer picture of what entropy means in black holes. “The observational entropy framework provides much more clarity,” said Philipp Strasberg, a physicist at the Autonomous University of Barcelona, who recently included it in a comparison of different microscopic entropy definitions (opens a new tab). “It really connects ideas from Boltzmann and von Neumann with what people do nowadays.” Anthony Aguirre has defined a quantity he calls observational entropy that other researchers find clarifying. Lisa Tse for FQxl Meanwhile, quantum information theorists have taken a different approach (opens a new tab) to handling subjectivity. They are treating information as a resource that observers can use to interact with a system that’s increasingly blending together with its environment. For a supercomputer with unlimited power that could track the exact state of every particle in the universe, entropy would always remain constant — since no information would be lost — and time would cease to flow. But observers with finite computational resources such as ourselves always have to contend with a coarse-grained picture of reality. We can’t keep track of the motion of all the air molecules in a room, so we take averages in the form of temperature and pressure. We progressively lose track of microscopic details as systems evolve into more probable states, and this relentless trend materializes as the flow of time. “The time of physics is, ultimately, the expression of our ignorance of the world,” Rovelli wrote (opens a new tab). Ignorance composes our reality. “There’s a universe out there, and there’s a universe that each observer carries with them — their understanding and model of the world,” Aguirre said. Entropy provides a gauge of the shortcomings in our internal models. These models, he said, “allow us to make good predictions and act intelligently in an often hostile but always difficult physical world.” Driven by Knowledge In the summer of 2023, Aguirre hosted a retreat (opens a new tab) in the rolling foothills of a historic mansion estate in Yorkshire, England, through a nonprofit research organization he co-founded in 2006 called the Foundational Questions Institute, or FQxI. Physicists from around the world gathered for a weeklong intellectual slumber party complete with opportunities for yoga, meditation and wild swimming. The event rounded up researchers who had received grants from FQxI to investigate how to use information as fuel. A scene from the FQxI retreat in Yorkshire. Lisa Tse for FQxl For many of these physicists, the study of engines and computers has become blurred. They’ve learned to treat information as a real, quantifiable physical resource — a diagnostic of how much work can be extracted from a system. Knowledge, they realized, is power. Now they’re setting out to harness that power. One morning, after an optional yoga session in the estate’s yurt, the group heard from Susanne Still (opens a new tab), a physicist at the University of Hawai‘i at Mānoa. She discussed new work that harkens back to a century-old thought experiment first proposed (opens a new tab) by the Hungarian-born physicist Leo Szilard. Picture a box with a vertical divider that can slide sideways back and forth between the left and right walls of the box. There’s a single particle in the box, located to the left of the divider. As the particle ricochets off the walls, it will push the divider rightward. A clever demon can rig up a string and pulley such that, as the divider gets pushed by the particle, it tugs on the string and lifts a weight outside the box. At this point, the demon can sneakily reinsert the divider and restart the process — enabling an apparent source of infinite energy. To consistently get work out of the box, however, the demon must know which side of the box the particle is in. Szilard’s engine is fueled by information. In principle, information engines are sort of like sailboats. On the ocean, you use your knowledge about the direction of the wind to adjust your sails to propel the boat forward. Jonas Parnow and Mark Belan/Quanta Magazine; Creative Commons: CC BY-ND 4.0 (opens a new tab) But just like heat engines, information engines are never perfect. They too must pay a tax in the form of entropy production. The reason we can’t use information engines as perpetual motion machines, as Szilard and others pointed out, is that it generates on average at least as much entropy to measure and store that information. Knowledge begets power, but acquiring and remembering that knowledge consumes power. A few years after Szilard conceptualized his engine, Adolf Hitler became chancellor of Germany. Szilard, who was born into a Jewish family and had been living in Germany, fled. His work was overlooked for decades until it was eventually translated into English, as Still described in a recent historical review (opens a new tab) of information engines. Recently, by studying the basic ingredients of information processing, Still has managed to expand and generalize Szilard’s concept of an information engine. For over a decade, she has been working out how to treat observers as physical systems themselves, subject to their own physical limitations. How closely these limits can be approached depends not only on the data the observer has access to, but also on their data-processing strategy. After all, they must decide which properties to measure and how to store those details in their limited memory. In studying this decision-making process, Still has found that collecting information that does not help an observer make useful predictions decreases their energy efficiency. She proposed that observers follow what she calls the “principle of least self-impediment” — choosing information-processing strategies that come as close as possible to their physical bounds in order to improve the speed and accuracy of their decision-making. She also realized that these ideas could be further explored by applying them to modified information engines. Leo Szilard devised the idea of engines that run on information. U.S. Department of Energy In Szilard’s original design, the demon’s measurements perfectly reveal where the particle is located. In reality, however, we never have perfect knowledge of a system because our measurements are always flawed — sensors are subject to noise, displays have limited resolution, and computers have limited storage. Still showed how the “partial observability” that’s inherent in real-world measurements can be introduced with slight modifications to Szilard’s engine — essentially by changing the shape of the divider (opens a new tab). Imagine that the divider is tilted at an angle inside the box, and that the user can see only the horizontal position of the particle (perhaps they see its shadow projecting onto the box’s bottom edge). If the shadow is fully left or right of the divider, you know for sure which side the particle is on. But if the shadow is anywhere in the middle region, the particle could be either above or below the tilted divider, and thus either on the left or right side of the box. Using partially observable information engines, Still computed the most efficient strategies for taking measurements of the particle’s location and encoding them in memory. This resulted in a purely physics-based derivation of an algorithm that’s also currently in use in machine learning, known as the information bottleneck algorithm. It offers a way to effectively compress data by preserving only relevant information. Since then, with her graduate student Dorian Daimer, Still has investigated (opens a new tab) a number of different designs for the modified Szilard engines and studied the optimal encoding strategies in various cases. These theoretical devices serve as “fundamental building blocks of decision-making under uncertainty,” said Daimer, who has a background in cognitive science as well as physics. “That’s why studying the physics of information-processing is so interesting to me, because you go full circle in some sense and arrive back at describing the scientist.” Industrializing Anew Still wasn’t the only one in Yorkshire dreaming about Szilard engines. In recent years, a number of FQxI grantees have developed functioning engines in the lab in which information is used to power a mechanical device. Unlike in Carnot’s time, nobody expects these miniature engines to power trains or win wars; instead, they’re serving as test beds for probing fundamental physics. But just like last time, the engines are forcing physicists to reimagine (opens a new tab) what energy, information and entropy mean. With Still’s help, John Bechhoefer has re-created Szilard’s engine (opens a new tab) with a silica bead smaller than a speck of dust floating in a bath of water. He and colleagues at Simon Fraser University in Canada trap the bead with lasers and monitor its random thermal fluctuations. When the bead happens to jiggle upward, they quickly raise the laser trap to take advantage of its motion. Just as Szilard imagined, they’ve managed to lift a weight by harnessing the power of information. Susanne Still has modified Szilard engines to account for cases of uncertainty and partial information. Mango Lime Studio In investigating the limits (opens a new tab) of extracting work from their real-world information engine, Bechhoefer and Still have found that, in certain regimes, it can significantly outperform (opens a new tab) conventional engines. They’ve also tracked the inefficiency associated with receiving partial information (opens a new tab) about the bead’s state, inspired by Still’s theoretical work. The information engine is now shrinking to the quantum scale with the help of Natalia Ares (opens a new tab), a physicist at the University of Oxford who served on a panel (opens a new tab) with Still at the retreat. On silicon chips the size of a coaster, Ares traps a single electron inside a thin carbon wire, which is suspended between two pillars. This “nanotube,” which is cooled to within thousandths of a degree of absolute zero, vibrates like a guitar string, and its oscillation frequency is determined by the state of the electron inside (opens a new tab). By tracking the nanotube’s minuscule vibrations, Ares and colleagues plan to diagnose the work output of different quantum phenomena. Ares has a long list of experiments to probe quantum thermodynamics scribbled across chalkboards up and down the halls. “It’s basically all of the industrial revolution, but nano,” she said. One planned experiment takes after Still’s idea. It involves adjusting how perfectly the nanotube’s vibrations depend on the electron (versus other unknown factors), essentially providing a knob for tuning the ignorance of the observer. Ares and her team are probing the limits of thermodynamics on the smallest scales — the motive power of quantum fire, in a sense. Classically, the limit for how efficiently the motion of particles can be transformed into work is set by Carnot’s theorem. But in the quantum case, with a menagerie of entropies (opens a new tab) to choose from, it’s much more complicated to determine which one will set relevant bounds — or how to even define work output. “If you have a single electron like we have in our experiments, what does it mean, entropy?” Ares said. “In my experience, we are still very lost here.” Natalia Ares studies thermodynamics on the quantum scale in her lab at Oxford, where her custom hot-pink refrigeration chamber serves as a symbol of changing times. Courtesy of Natalia Ares A recent study led by Nicole Yunger Halpern (opens a new tab), a physicist at the National Institute of Standards and Technology, shows how common definitions of entropy production that are usually synonymous can disagree in the quantum realm (opens a new tab), again because of uncertainty and observer dependence. On this tiny scale, it’s impossible to know certain properties at the same time. And the order in which you measure certain quantities can affect the measurement outcomes. Yunger Halpern thinks we can use this quantum weirdness to our advantage. “There are extra resources available in the quantum world that are not available classically, so we can bend around Carnot’s theorem,” she says. Ares is pushing these new boundaries in the lab, hoping to pave a path for more efficient energy harvesting, charging of devices or computation. The experiments may also provide insight into the mechanics of the most efficient information processing systems we know of: ourselves. Scientists aren’t sure how the human brain can perform immensely complicated mental gymnastics using only 20 watts of power. Perhaps the secret to biology’s computational efficiency also lies in harnessing random fluctuations at small scales, and these experiments aim to sniff out any possible advantage. “If there is some win in this, there’s a chance that nature actually uses it,” said Janet Anders (opens a new tab), a theorist at the University of Exeter who works with Ares. “This fundamental understanding that we’re developing now hopefully helps us in the future understand better how biology does things.” The next round of Ares’ experiments will take place in a hot-pink refrigeration chamber that dangles from the ceiling of her lab in Oxford. She jokingly suggested the makeover to the manufacturers a few years ago, but they cautioned that metallic paint particles would hamper her experiments. Then the company secretly brought the fridge to an auto shop to cover it in a flashy pink film. Ares sees her new experimental arena as a symbol of changing times, reflecting her hope that this new industrial revolution will be different from the last one — more conscientious, environmentally friendly and inclusive. “It feels very much like we’re at the start of something big and wonderful,” she said. Embracing Uncertainty When Carnot wrote his paper … I don’t think anybody imagined what would come out of it. Carlo Rovelli, Aix-Marseille University In September 2024, a few hundred researchers gathered (opens a new tab) in Palaiseau, France, to pay homage to Carnot on the 200th anniversary of his book. Participants from across the sciences discussed how entropy features in each of their research areas, from solar cells to black holes. At the welcome address, a director of the French National Center for Scientific Research apologized to Carnot on behalf of her country for overlooking the impact of his work. Later that night, the researchers gathered in a decadent golden dining room to listen to a symphony composed by Carnot’s father and performed by a quartet that included one of the composer’s distant descendants. Carnot’s reverberating insight emerged from an attempt to exert ultimate control over the clockwork world, the holy grail of the Age of Reason. But as the concept of entropy diffused throughout the natural sciences, its purpose shifted. The refined view of entropy is one that sheds the false dreams of total efficiency and perfect prediction and instead concedes the irreducible uncertainty in the world. “To some extent, we’re moving away from enlightenment in a number of directions,” Rovelli said — away from determinism and absolutism and toward uncertainty and subjectivity. Related: How Maxwell’s Demon Continues to Startle Scientists Physicists Rewrite the Fundamental Law That Leads to Disorder Anil Seth Finds Consciousness in Life’s Push Against Entropy Like it or not, we are slaves of the second law; we can’t help but compel the universe toward its fate of supreme disorder. But our refined view on entropy allows for a more positive outlook. The trend toward messiness is what powers all our machines. While the decay of useful energy does limit our abilities, sometimes a new perspective can reveal a reservoir of order hidden in the chaos. Furthermore, a disordered cosmos is one that’s increasingly filled with possibility. We cannot circumvent uncertainty, but we can learn to manage it — and maybe even embrace it. After all, ignorance is what motivates us to seek knowledge and construct stories about our experience. Entropy, in other words, is what makes us human. You can bemoan the inescapable collapse of order, or you can embrace uncertainty as an opportunity to learn, to sense and deduce, to make better choices, and to capitalize on the motive power of you. This work was supported by a fellowship with the MIP.labor. MIP.labor is hosted at Freie Universität Berlin and is funded by the Klaus Tschira Foundation. Quanta Magazine is an editorially independent publication funded by the Simons Foundation. By Zack Savitsky Contributing Writer December 13, 2024 View PDF/Print Mode fundamental physics history of science information theory physics statistical physics thermodynamics All topics (opens a new tab) Share this article Copied! (opens a new tab) Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters (opens a new tab) The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters (opens a new tab) Also in Physics Quantum Computers Cross Critical Error Threshold quantum computing Quantum Computers Cross Critical Error Threshold By Ben Brubaker December 9, 2024 4 Read Later Exotic New Superconductors Delight and Confound condensed matter physics Exotic New Superconductors Delight and Confound By Charlie Wood December 6, 2024 2 Read Later In the Quantum World, Even Points of View Are Uncertain quantum physics In the Quantum World, Even Points of View Are Uncertain By Anil Ananthaswamy November 22, 2024 10 Read Later Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article Mathematicians Uncover a New Way to Count Prime Numbers",
    "commentLink": "https://news.ycombinator.com/item?id=42415386",
    "commentBody": "What Is Entropy? A Measure of Just How Little We Know (quantamagazine.org)160 points by nsoonhui 11 hours agohidepastfavorite72 comments zV62drdTw6CM 1 hour agoHappy to see the article being discussed here! I was responsible for the technical implementation of the interactives. If you are interested in the source code, you can find it here: https://github.com/jnsprnw/mip-entropy It’s built in Svelte 5 with Tailwind. reply azemetre 1 hour agoparentMay I ask why you chose svelte 5 rather than something else? I’ve noticed that a lot of “one off” interactions are being built with svelte nowadays. What are the benefits of using it? reply zV62drdTw6CM 46 minutes agorootparentFirst, when I joined the project, it wasn’t clear how it would be published. Svelte, which outputs compiled JavaScript, can fit into many CMS workflows that newspapers/publishers use. I believe Svelte was developed by Rich Harris at the NY Times for this very reason. We ended up using iFrames, so other frameworks like React could have been used. Second, Svelte is very well suited for these small interactives because it has built-in state, transitions, and reactivity with low overhead. Third, it was a personal choice, as I now do most of my work in Svelte. reply kqr 20 minutes agorootparent> We ended up using iFrames, so other frameworks like React could have been used. Wait, wasn't one of the original selling points of React that it could be embedded piecewise to enhance interactivity of the parts of pages that needed it? It should certainly not need a separate page! reply plank 5 hours agoprevInteresting to read this, 27 years after my PhD* (theoretical physics), in which I did compare the view WITH and the view WITHOUT ‘unknowns’ causing entropy as a driver. * My PhD was about how to treat a (quantum mechanical) system inside a cavity: a cavity with one perfect mirror and one 99.999999% perfect mirror. The (one dimensional) universe was made whole by another perfect mirror at the other side of the non-perfect mirror (in ASCII art: [100%] —l— [100-epsilon] ——L——— [100%] With L >> l. The ‘whole universe’ solution was simple (using standard quantum mechanics techniques), the ‘lossy’ ‘small universe’ was not. But they needed to be the same (physically). Thus using the exact solution for the ‘complete’ (l+L) universe and comparing it to possible ‘small’ (l) universe models in which some non-linear term accounted for loss. The connection between how a lossy system (in which entropy exists/is a driving ‘force’) and a losless system (in which everything is conserved) is thus not a new insight;-0 reply mojomark 4 hours agoparentI read you're comment with interest, but ultimately I can't understand the point being made because I don't know what kind of mirror you're referring to (optical?), I don't know what 'l' or 'L' represent (lateral spacing of mirrors?, vacuum energy desnities?), and the last sentence I think maybe the word 'how' should be deleted? reply IIAOPSW 1 hour agorootparentThe imperfect mirror means that epsilon% of the time the light goes through to a much larger \"back room\" whereas (1-epsilon)% of the time the light just reflects like normal. The point being made is that this is an extension of an ordinary ideal cavity to include unavoidable (but weak) interaction with the much larger system outside of it (aka the whole universe). It just so happens the much larger external system is also being modeled as a simple 1d cavity. In other words, entropy is equivalent to bits of information needed to specify the complete state of the system leaking outside of the confines of where those bits are being observed by an experiment (eg tunneling through an imperfect mirror). Entropy is an accounting tool to keep track of how many bits are missing, and how far this ignorance has percolated into what you can safely predict about the system. reply plank 3 hours agorootparentprevAnswers to your questions: 1): all the way to the left, a mirror with a reflectivity|r| of 1 (or a 100%). In the middle an |r| of slightly below 1. Yes, optical, system with photons (a and a^dagger with [a,a^dagger]=1). 2) distance between mirrors 1 and 2: l. Distance mirror 2 and 3:L. (Later taking the limit L/l ==>> infinity) 3) the how is actually correct, I guess the word behaves is missing twice: .... how .... behaves and a .... behaves. reply revskill 2 hours agoparentprevSo i am curiouys to know how did u invent new knowledge without computer science reply kqr 9 hours agoprev> As physicists have worked to unite seemingly disparate fields over the past century, they have cast entropy in a new light — turning the microscope back on the seer and shifting the notion of disorder to one of ignorance. Entropy is seen not as a property intrinsic to a system but as one that’s relative to an observer who interacts with that system. Maybe I have the benefit of giant shoulders, but this seems like a fairly mundane observation. High-entropy states are those macrostates which have many corresponding microstates. The classification of several microstates into the same macrostate, is this not a distinctly observer-centred function? I.e. if I consider 5 or 6 to be essentially the same outcome of the die, then that will be a more probable (higher-entropy) outcome. But that's just due to my classification, not inherent to the system! reply kergonath 5 hours agoparent> Maybe I have the benefit of giant shoulders, but this seems like a fairly mundane observation. It is not mundane, and it is also not right, at least for entropy in Physics and Thermodynamics. > High-entropy states are those macrostates which have many corresponding microstates. That is how you deduce entropy form a given model. But entropy is also something that we can get from experimental measurements. In this case, the experimental setup does not care about microstates and macrostates, it just has properties like enthalpy, heat capacity and temperature. We can build models after the fact and say that e.g. the entropy of a given gas matches that predicted by our model for ideal gases, or that the entropy of a given solid matches what we know about vibrational entropy. That’s how we say that e.g. hydrogen atoms are indistinguishable. It’s not that they become indistinguishable because we decide so. It’s because we can calculate entropy in both cases and reality does not match the model with distinguishable atoms. > The classification of several microstates into the same macrostate, is this not a distinctly observer-centred function? It seems that way if we consider only our neat models, but it fails to explain why experimental measurements of the entropy of a given materials are consistent and independent of whatever model the people doing the experiment were operating on. Fundamentally, entropy depends on the probability distribution, not the observer. reply kgwgk 3 hours agorootparent> But entropy is also something that we can get from experimental measurements. In this case, the experimental setup does not care about microstates and macrostates, it just has properties like enthalpy, heat capacity and temperature. […] experimental measurements of the entropy of a given materials are consistent and independent of whatever model the people doing the experiment were operating on. Fundamentally, entropy depends on the probability distribution, not the observer. https://bayes.wustl.edu/etj/articles/gibbs.vs.boltzmann.pdf Thermodynamics does have the concept of the entropy of a thermodynamic system; but a given physical system corresponds to many different thermodynamic systems. […] It is clearly meaningless to ask, “What is the entropy of the crystal?” unless we first specify the set of parameters which define its thermodynamic state. […] There is no end to this search for the ultimate \"true\" entropy until we have reached the point where we control the location of each atom independently. But just at that point the notion of entropy collapses, and we are no longer talking thermodynamics! […] From this we see that entropy is an anthropomorphic concept, not only in the well-known statistical sense that it measures the extent of human ignorance as to the microstate. Even at the purely phenomenological level, entropy is an anthropomorphic concept. For it is a property, not of the physical system, but of the particular experiments you or I choose to perform on it. reply LudwigNagasena 4 hours agorootparentprev> It is not mundane, and it is also not right, at least for entropy in Physics and Thermodynamics. Articles about MaxEnt thermodynamics by E.T. Jaynes where he talks about the “anthropomorphic” nature of entropy date back to 1960s. How is that not right in physics? reply kergonath 1 hour agorootparentBy the look of it, it is another misguided attempt to apply information theory concepts to thermodynamics. Entropy as information is seductive because that way we think we can understand it better, and it looks like it works. But we need to be careful because even though we can get useful insights from it (like Hawking radiation) it’s easy to reach unphysical conclusions. > How is that not right in physics? Why would it be right? Was it used to make predictions that were subsequently verified? reply kgwgk 1 hour agorootparentThat misguided attempt has resulted in full graduate courses and textbooks. Maybe one look is not all that it takes to fully assess its worthiness. https://www.amazon.com/Microphysics-Macrophysics-Application... https://arxiv.org/pdf/cond-mat/0501322 reply oh_my_goodness 1 hour agorootparentprev\"We need to be careful\", agreed. \"It's not mundane\", agreed. (It's mundane in information theory because that's how they define entropy.) \"It's [...] not right\" (from your first comment), can you give/link a specific physical example? It would be very cool to have a clear counterexample. reply markisus 3 hours agorootparentprevMaybe the experimental apparatus is not objective. The quantities we choose to measure are dictated by our psychological and physiological limitations. The volume of a container is not objectively defined. An organism which lives at a faster time scale will see the walls of the container vibrating and oscillating. You must convince the organism to average these measurements over a certain time scale. This averaging throws away information. This is the same with other thermodynamic quantities. reply kergonath 1 hour agorootparent> The quantities we choose to measure are dictated by our psychological and physiological limitations. No. The enthalpy changes measured by a calorimeter are not dependent on our psychological limitations. > The volume of a container is not objectively defined. Yes, it is, for any reasonable definition of \"objective\". We know how to measure lengths, we know how they change when we use different frames of reference so there is no situation in which a volume is subjective. > An organism which lives at a faster time scale will see the walls of the container vibrating and oscillating. This does not matter. We defined a time scale from periodic physical phenomena, and then we know how time changes depending on the frame of reference. There is no subjectivity in this, whatever is doing the measurement has no role in it. Time does not depend on how you feel. It’s Physics, not Psychology. > This is the same with other thermodynamic quantities. No, it’s really not. You seem to know just enough vocabulary to be dangerous and I encourage you to read an introductory Physics textbook. reply whatshisface 19 minutes agorootparentThe enthalpy changes measured by a calorimeter are dependent on the design of the calorimeter, which could have been a different piece of equipment. In a sense, that makes it dependent on the definition of enthalpy. If you introduced a new bit of macro information to the definition of an ensemble, you'd divide the number of microstates by some factor. That's the micro level equivalent of macroscopic entropy being undefined up to an additive constant. The measurables don't tell you S, they only tell you dS. reply notfed 45 minutes agorootparentprevSometimes I wish HN had merit badges. Or if you like, a device to measure the amount of information contained within a post. reply niemandhier 8 hours agoparentprevIn physics the requirement for a valid changing the frame of reference is, that the laws of physics transform according to the transformation. Every observer should discover the same fundamental laws when performing experiments and using the scientific method. To stay in your analogy, saying 5 and 6 are the same would only work if the rules of the game you play could transform in such a way that an observer making a distinction between the two would arrive at the correctly transformed rules in his frame of reference. Given that we have things like neutron stars, black holes and other objects that are at the same time objects of quantum physics and general relativity, the statement feels pretty fundamental to me, to a degree even that I wonder if it might be phrased to strongly. reply bubblyworld 8 hours agorootparentI think you may have misunderstood the OP's point - the entropy you calculate for a system depends on how you factor the system into micro and macro states. This doesn't really have anything to do with changes of reference frame - in practice it's more about limitations on the kinds of measurements you can make of the system. (you can't measure the individual states of all the particles in a body of gas, for instance, so you factor it into macrostate variables like pressure/temperature/volume and such) reply niemandhier 4 hours agorootparentFrom a thermodynamics point of view only the differential of the entropy matters, so if there is only a fixed difference between the two computations they do not influence the physics. If the way one does the coarse graining of states results in different differentials, one way should be the correct one. There is only one physics. If I remember one of Plancks relevations was that he could explain why a certain corrections factor was needed in entropy calculations, since phase space had finished cell size. reply bubblyworld 2 hours agorootparentThat's true - for instance I believe many of the results of statistical mechanics rely on further assumptions about your choice of macrostates, like the fact that they are ergodic (i.e. the system visits each microstate within a macrostate with equal probability on average). Obviously exotic choices of macrostates will violate these assumptions, and so I would expect the predictions such a model makes to be incorrect. But ultimately that's an empirical question. Entropy is a more general concept that's definable regardless of whether the model is accurate or not. reply lizzas 5 hours agorootparentprevCan we take the anthropic out of this? I reckon it'll make things easier. Instead of me knowing, do other physical objects get affected. I might get anemsia and forget what the dots on a dice mean and say they are all the same: all dotty! Imagine each hydrogen atom has a hidden guid but this is undetectable and has no effect on anything else. This is a secret from the rest of physics! I guess!!! (Armchair pondering!) that that guid cannot be taken into account for entropy changes. At least from any practical standpoint. You could imagine each atom having a guid and come up with a scheme to hash the atom based on where it came from ... but is that info really there and if so does it affect anything physically beyond that atoms current state (as defined by stuff that affects other stuff). reply bubblyworld 5 hours agorootparentWhat anthropic do you mean? I'm describing properties of models, not people. Physics (probably) doesn't care what you \"know\". On the guid idea - fundamental particles are indistinguishable from one another in quantum mechanics, so they don't have anything like a guid even in principle. There is no experiment you could perform on an electron to determine whether it had been swapped out for a \"different\" one, for instance. Maybe I'm missing your point though? reply lizzas 5 hours agorootparentSorry ... I am replying mostly to the dice idea which wasn't you. Yes correct about the guid idea. My point is the discussion is easier to follow if grounded in reality (as best modelled since that is all we have plus some evidence stored in the same \"SSD\"!) reply bubblyworld 5 hours agorootparentOh I see. But on your guid thing, people often describe entropy in terms of the set of micro states of your system (the actually physical states in your model) and the macro states (sets of microstates that are described by a collection of high-level state variables like pressure/temperature). Physically indistinguishable stuff would have the same micro state, so yeah, they wouldn't affect entropy calculations at all, no matter what macro states you picked. But I disagree a bit about grounding things in reality - some concepts are quite abstract and having clean examples can be helpful, before you start applying them to the mess that is our universe! reply guerrilla 8 hours agoparentprev> mundane observation What makes an observation mundane? I think what you said is insightful and demonstrates intelligence. I don't think it's at all obvious to the masses of students that have poured over introductory physics textbooks. In fact, it seems to me that often entropy is taught poorly and that very few people understood it well but that we are beginning to correct that. I point to the heaps of popsci magazines, documentaries and YouTube videos failing to do anything but confuse the public as additional evidence. reply LudwigNagasena 4 hours agorootparentMaybe if you opened only introductory physics textbooks then it’s not mundane; but If you opened introductory information theory textbooks, statistical textbooks, introductions to Bayesian probability theory, articles about MaxEnt thermodynamics including articles by E.T. Jaynes, then it’s a quite mundane observation. reply mitthrowaway2 57 minutes agorootparentJaynes definitely made the case for this a long time ago, and in my opinion he's correct, but I think that view is still not mainstream; or even if mainstream, certainly not dominant. So I think we should welcome other people who reach it on their own journey, even if they aren't the first to arrive there. reply guerrilla 3 hours agorootparentprevSo, what you're saying is, not very mundane at all and, in fact, that it's specialized knowledge requiring advanced education. ;) reply daoboy 6 hours agoprevThe interactive graphic that tries to show entropy is subjective doesn't sit right for me. They fail to properly define the macrostate of the system under consideration, then show two different observed entropies for two different macrostates (Colors for Alice and Shapes for Bob). That doesn't show entropy is subjective, it shows that defining the system is subjective. The same two macrostates would still have the same entropy reply markisus 2 hours agoparentMaybe if you take Alice and Bob to be two separate alien species it could make more sense. Alice’s species has no measurement devices capable of detecting Bob’s version of entropy, and therefore Alice is not able to extract any useful work from Bob’s system and vice versa. Therefore any objective definition of entropy needs to include the capabilities of the measurer. Which is just the same as what you were saying about macrostates. reply Serenade 4 hours agoparentprevThank you for articulating what was bothering me about this. I couldn't quite put my finger on it, but you're right. They are confusing defining the system with defining the entropy of a system and then saying it's the entropy that is subjective. That isn't the case at all. Entropy is just a measurement. reply inshard 7 hours agoprevFails to mention Heisenberg uncertainty, which in my opinion is a theoretical ceiling to this approach. Also it needs to account for cost of compute relative potential useful work from these quantum engines. If the energy cost of compute exceeds potential useful work, then it’s still net negative (or useless work). Finally there’s the question of hidden patterns and the spectrum of randomness. Some systems are more random than others. The potential for useful work within a reasonable energy cost of compute will decline when we travel down the spectrum of randomness. Systems which are at maximal Heisenberg uncertainty, I.e. particles are not entangled, and have no correlation with a superstructure of other entangled particles, will not hold any further improvement to knowledge and thus zero potential work. This is the ultimate entropy of the local and macro system. Probably also the cause of certain violation of conservation of energy principles, such as dark energy. reply amelius 4 hours agoprevMakes sense. If we knew the theory of everything and the initial conditions of the universe, then we could just compute the next episode of a series instead of streaming it. reply api 4 hours agoparentNot necessarily. A theory of everything does not imply either the computability of a future state or determinism. Even if our ToE is deterministic the universe may be computationally irreducible, meaning it cannot be computed accurately at lower resolution in all cases. Note that such a universe could contain within it regions that are computationally reducible, just not the whole and not all regions. I would expect a ToE to give us knowable bounds to either determinism or computability. It should tell us what is precisely knowable or predictable and what isn’t. Edit: to understand how a ToE could leave some things unknowable (but tell us what they are) consider the Hubble horizon. Light beyond it will never reach us making sufficiently distant things unknowable. Limits may be great. It means we can at least subjectively consider ourselves as having free will — even with a deterministic theory it may be unknowable determinism. It’s just like how the speed of light might be why we got to evolve before being bum rushed by aliens. reply FrustratedMonky 3 hours agorootparent\"cannot be computed accurately at lower resolution\" The Map is not the Territory. Our universe is the lowest resolution. So to compute the next instant in our Universe, would need another entire Universe. We could be the computation occurring. reply api 3 hours agorootparentThat’s what I meant, but perhaps did not describe well. reply FrustratedMonky 3 hours agorootparentSorry, I was really just re-stating it, to see if I was grasping the point. reply j7ake 3 hours agoparentprevTry it with a chaotic system like a double pendulum you’ll see the dynamics are not predictive in the long term. reply adrianN 2 hours agorootparentIs that true? It was my understanding that chaotic systems (with a known initial state) could be predicted to arbitrary precision by throwing enough compute at the problem. Of course knowing the initial state is impossible in the real world, „enough“ compute might not fit in the observable universe, and quantum mechanics contains true randomness… reply philipov 2 hours agorootparentYes, chaotic systems can be simulated, and that's the only way to find out what happens with them. The thing one can't do is reduce them to a closed-form function of x and compute their value for any point along their domain. The only thing we can do is inductively figure out the next x from the current x. reply mitthrowaway2 48 minutes agorootparentThe issue is more that simulations diverge exponentially with time from any nonzero error in the initial state. With perfect knowledge of the initial conditions and parameters you could simulate the system perfectly, but you'd also need to accumulate zero numerical error along the way. If you don't demand perfection, then in practice you can do pretty well for short times. reply perihelions 8 hours agoprevA related thread from earlier this year, https://news.ycombinator.com/item?id=41037981 (\"What Is Entropy? (johncarlosbaez.wordpress.com)\", 209 comments) reply ziofill 2 hours agoprevVery nice article. There’s an alternative way of thinking of the Gibbs paradox, which is to attach labels to the particles. This naturally makes them distinguishable and increases the total number of possible configurations, and with it the maximum value of the entropy. reply bee_rider 1 hour agoparentAttaching labels to the particles would make them fundamentally different types of particles, right? So it doesn’t seem that surprising that a system with different types of particles would be different. reply ChaitanyaSai 8 hours agoprevLovely article. The subjective nature of entropy and information immediately makes me think of the IIT theory (integrated information theory) of consciousness and its foundational futility. Information cannot be discussed without perspective. Someone has to define the states. A die have 6 states only to us humans. What about an ant that's likely to have the die land on it? Bringing the observer back into discussions of information is fascinating because it then begs the question: How is the observer put together? And how does a perspective, an I, emerge in a multi-trillion-cell entity? For those interested in this detour, you might like reading this and our book (mentioned in there) https://saigaddam.medium.com/consciousness-is-a-consensus-me... reply 3abiton 4 hours agoparentFor me CS with Physics BSc, it's always fascinating to still see how entropy is still sich a wild measure. reply noiv 3 hours agoprevWhat about the efficiency to remove entropy? Is there a threshold our combined efforts called science cannot surpass? Do we need Frank Herbert’s spice to progress? reply Trasmatta 3 hours agoparentA localized reduction of entropy will always result in an increase of entropy in the larger system. It doesn't matter how efficient your process is, the entropy of the surrounding system will ALWAYS increase as the result of the work needed to effect a localized reduction. reply ganzuul 2 hours agorootparentUnless the surrounding system is already at infinite entropy. reply tsoukase 7 hours agoprevMy perspective: 1) entropy is a mathematical concept. Physics apply it, like any other mathematical one 2) math entropy does not change, everything is reversible, as it is based on known quantities 3) entropy measures how far we are from perfectly knowing a system 4) logarithm is chosen to measure entropy because of its convenient properties, not because of any deeper law. It could be a sum, a product etc 5) the Second thermodynamic law is a tautology: \"every system tends to higher entropy state because it is more common\" becomes \"the more common is the more common\" reply currymj 0 minutes agoparenti think those convenient properties are the sign of some deeper law. you do want to work with the exponential and logarithm, same as in so many other places. you don’t necessarily want some other generalized “entropy”. reply wtcactus 4 hours agoprevI remember that somewhere during my physics degree this idea of the article clicked with me. Entropy is just a simpler way of manifesting properties of a system that we didn’t measure because it is too difficult (when I was still at classical physics level) or it’s not possible to measure (when quantum mechanics became present in everything we learned). We use it because we can’t measure the position and momentum of every particle (same goes for temperature) so we created theories on how a system with a particular entropy behaves, but it’s just a clever way to work with aproximations. I find this idea fascinating. reply widea 9 hours agoprevEntropy, a measure of freedom in a contained environment. reply rapjr9 2 hours agoparentLife, a short term attempt to reverse some entropy by creating more entropy. reply openrisk 7 hours agoprevIs there a specific name for the art and craft of presenting a topic online (as a web page) using a flow of text interspersed with interactive activities? Whatever the name of this approach, quantamagazine is definitely good at it! reply gyomu 7 hours agoparentSome people have coined the term explorable explanation/explorables https://explorabl.es/ https://en.wikipedia.org/wiki/Explorable_explanation reply openrisk 6 hours agorootparentaah, this is nailing it. It helps to differentiate from game-like experiences and special purpose apps. Another interesting term from the wiki link is \"active essays\": > The related term \"active essays\" was used by Alan Kay to refer to text-based explorable explanations But I don't know if by text-based he meant strictly no visuals. Like just ASCII art? :-) reply TheSpiceIsLife 7 hours agoparentprevMultimedia? https://en.m.wikipedia.org/wiki/Multimedia Multimedia refers to the integration of multiple forms of content such as text, audio, images, video, and interactive elements into a single digital platform or application. reply openrisk 6 hours agorootparentMultimedia is fairly general, so it includes this but also much more. Including video in particular tends to highjack the experience (you switch mode), whereas interactive elements that you explore as you keep reading feel more integrated. reply pndy 9 hours agoprev [–] http://www.thelastquestion.net/ - in case someone missed it somehow reply niemandhier 8 hours agoparentWow. When did we take the turn from sci-fi like that to the ever dystopian laments we read today. reply rcxdude 3 hours agorootparentIt's pretty cyclical, there's older sci-fi that's more dystopian and still older sci-fi then that which is optimistic. (and of course, the trends are only trends) reply pixl97 1 hour agorootparentprevI mean they had dystopian sci-fi back then too... Technology changes, yet people remain ever the assholes. reply guerrilla 8 hours agoparentprev [–] This is my favorite Isaac Asimov story and the reason I started reading him. reply lizzas 5 hours agorootparentThis will be my favorite Issac Asimov story and the reason I will start reading him reply srean 7 hours agorootparentprev [–] For all who haven't, please read the other two as well. Last Answer Nightfall reply pndy 7 hours agorootparent [–] Gotta mention that Nightfall exists as both Asimov's short story and a novel he co-wrote with Robert Silverberg nearly 50 years later reply pessimizer 1 hour agorootparent [–] And that the short story is the important one. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Entropy, initially introduced by Sadi Carnot, measures disorder and is crucial for understanding the second law of thermodynamics, which states that entropy always increases.- The concept of entropy has expanded beyond thermodynamics to include information theory, where it represents uncertainty and is seen as subjective, depending on an observer's knowledge.- Researchers are exploring the use of information as a resource, with experiments in information engines and quantum thermodynamics, offering new opportunities for scientific innovation and understanding."
    ],
    "commentSummary": [
      "Entropy is a measure of uncertainty or disorder in a system, relevant in fields like physics and information theory, indicating how much is unknown about a system's detailed states.",
      "The concept of entropy is sometimes considered subjective, as it can vary based on the observer's perspective and the measurements available to them.",
      "Entropy is crucial in discussions about thermodynamics, information theory, and even consciousness, as it describes how systems evolve towards more probable, less ordered states."
    ],
    "points": 160,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1734162550
  },
  {
    "id": 42415637,
    "title": "I made a free Figma library packed with components for fast prototyping",
    "originLink": "https://veryfront.com/figma-kit",
    "originBody": "100+ Components A wide array of components at your fingertips.",
    "commentLink": "https://news.ycombinator.com/item?id=42415637",
    "commentBody": "I made a free Figma library packed with components for fast prototyping (veryfront.com)156 points by kojiwakayama 10 hours agohidepastfavorite34 comments kojiwakayama 7 hours agoHi HN, I’m Koji, software engineer and co-founder of Veryfront, where we offer tools to streamline web app development. Happy to share insights or answer questions about design, development, or anything related to building apps. AMA! reply tomrod 3 hours agoprevI'm going to be very naive here as this isn't my space at all. Are these open sourced? If not these, are there react components I can grab for basic front end projects that won't run afoul of licensing? reply kojiwakayama 3 hours agoparentYes, all components and templates are open source. Both Figma and React components. reply n144q 3 hours agoprevFor prototyping purpose, how does this compare to other design kits, e.g. Material Design? https://www.figma.com/community/file/1035203688168086460/mat... reply kojiwakayama 2 hours agoparentMaterial Design is awesome. What I like about Veryfront components is that it includes also section components which are larger building blocks and integrates nicely with Veryfront Studio for seamless dev handoff, which then allows to go from build to deployment quick and easily. reply jillesvangurp 9 hours agoprevVeryfront is amazing. I've known Koji for several years and he and his team have built a lot of great tech that now covers everything from rapid design iteration, to developing with their web IDE, with a live preview (it actually continually builds your website). and deploying using their cloud hosting solution. The technology stack is very flexible. You can add your own components, libraries, styling solutions, backends, etc. And there is also an export option if you want to leave their platform that gives you everything in code form. The big benefit of veryfront is that you can get started and have a webapp live in no time at all. You don't need anyone working on devops because they do it for you. You don't need to setup a lot of tools because it all runs in the browser. You don't need to figure out how to set up these tools either because they do it for you. You just code your webapp. reply kojiwakayama 7 hours agoparentThanks so much Jilles. I really appreciate it! reply computergert 34 minutes agoprevAny plans to support Vue as well? reply baxtr 8 hours agoprevI would love to have a text box in Figma and then just type in what I want. \"Design a basic login screen. Change red for yellow. Move the layer up front.\" Is anyone working on this at Figma? reply maximilianthe1 10 minutes agoparentRecently needed to develop a React Web solution for hackathon. I had 0 previous experience with web, but was able to create a good looking (but with 0 logic) website, using Vercels V0[0]. It did great both working from text suggestions and from figma screenshots. It also was great at implementing changes after initial generation. Not an add btw, haha [0] v0.dev reply airstrike 3 hours agoparentprevSomewhat tangential but I've found Claude 3.5 to be ridiculously good at doing this kind of prototyping with React, and you get the preview immediately in the artifact pane to the right of the chat. Mind you I don't ever use React (I'm writing a desktop app in Rust), so I'm probably as unbiased an audience as it gets. Here are a couple of examples of things people asked for help with and I just iterated with Claude for 5-10 minutes on (code upfront and gif demo at the bottom): https://gist.github.com/airstrike/7ae444de207e679adca7be6faa... https://gist.github.com/airstrike/e0e47eaab733277b537923c4d3... I think given the sheer amount of training data on React, these models tend to really hit it out of the park when they are allowed to use it. Part of me thinks the best approach is to have it model in React first and then translate it to whatever other language/framework you need it in reply kojiwakayama 1 hour agorootparentDefinitely, AI for coding makes sense. In the Veryfront Studio, you get a similar experience with live previews and AI coding capabilities, with the added benefit of being able to instantly deploy or export your code. reply someothherguyy 5 hours agoparentprevhttps://techcrunch.com/2024/07/02/figma-disables-its-ai-desi... reply adrianbordinc 3 hours agoparentprevUizard does exactly this: https://uizard.io/ Disclaimer: the founder is a friend of mine reply amelius 6 hours agoparentprevNo need to do it in Figma. Soon your OS will be able to do it, and it will be able to use all apps on your system to create a design, not just one app. reply kojiwakayama 4 hours agorootparentInteresting. Are you thinking of an agentic system here? reply dennisy 7 hours agoparentprevYes they are releasing AI features: https://www.figma.com/ai/ reply kojiwakayama 7 hours agoparentprevGreat idea to allow prompt based design! reply submeta 7 hours agoparentprevIsn‘t vercel v0 doing this? reply submeta 8 hours agoprevI am about to draft a UI and user flow for an internal tool (an LLM based RAG). I was thinking about using Vercel/V0. Is this an option? What else can I use? Is Figma a must have in my tool belt? reply mattkevan 3 minutes agoparentThis is a RAG search I built with NextJS, Pinecone and Langchain. It also uses AI for content tagging and summarisation. https://www.uxlift.org/search/ I made a quick wireframe in Figma, but didn’t bother to pixel-perfect it. I mostly design in the browser, but taking a few minutes in figma up-front to get the shape of it saves time in the long run. If I’m designing for stakeholders or dev teams I’ll still absolutely produce full prototypes and designs otherwise bad things happen. Figma is the current market leader, but you could use anything that you can communicate your intent well enough with, from the back of an envelope to a competitor like Penpot or Sketch. Just don’t use Photoshop. V0 is interesting, but the results can be inconsistent. For my site I just copied and pasted the shadcn components I wanted and tweaked the styling to fit. Not sure V0 would be faster, though it might be useful for generating ideas. Depends on how much control you want over the final layout. reply kojiwakayama 7 hours agoparentprevStart prototyping the user journey in Figma to map out the flow. For frontend, use Next.js or Vite/Vike, which we use at Veryfront for its lightweight and performance. Simple API calls (e.g., OpenAI) can use a server function, but for RAG, I’d recommend a Python backend service. reply nelsonic 7 hours agoprevGreat work as always @kojiwakayama looks superb! reply kojiwakayama 6 hours agoparentHey Nelson, thank you very much! :) reply ThinkBeat 7 hours agoprevIt seems to be a hosting company, that offers goddies different level of goodies based on the price of the subsciption? reply kojiwakayama 7 hours agoparenthi, yes we offer different tools to streamline the web development process, such as: - Veryfront Studio, an online coding platform with live previews, instant deployment, and code exports. - Veryfront Components: Ready-made UI components for fast app building. - Veryfront Templates: Starter templates to kick off your projects. - Veryfront Figma Kit: A Figma library packed with components for quick prototyping You can try everything for free for an unlimited time and upgrade to a paid plan when your app is ready to go live. reply replwoacause 3 hours agoprevLooks nice but I just wish every new thing wasn’t React based reply kojiwakayama 3 hours agoparentThanks for the valid feedback. What is/would be your preferred stack? reply trevorhinesley 2 hours agorootparentFWIW I +1 that comment. Great tool, just not my stack. Rails + Hotwire here reply kojiwakayama 1 hour agorootparentRails and Hotwire is a nice stack. Thx! reply baxter001 8 hours agoprevnext [3 more] [flagged] hbarka 8 hours agoparentFrontPage 98 would like a word. reply kojiwakayama 5 hours agorootparentBringing back good old memories :) reply eichi 5 hours agoprev [–] Why not create crappy frontend to validate demand for MVP then hire a designer? Designer is cheap. reply kojiwakayama 5 hours agoparent [–] You can directly start coding in Veryfront Studio using the same components from the Figma Library as ready-made React components. Having tools for both designers and developers which integrate is key imo. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A free Figma library with components for rapid prototyping has been released by Veryfront, co-founded by Koji, to aid in web app development.",
      "The library includes open-source components and templates compatible with Figma and React, integrating with Veryfront Studio for efficient development and deployment.",
      "Users can access tools like Veryfront Studio, Components, Templates, and a Figma Kit for free, with an option to upgrade later."
    ],
    "points": 156,
    "commentCount": 35,
    "retryCount": 0,
    "time": 1734166443
  },
  {
    "id": 42411727,
    "title": "@smoores/epub, a JavaScript library for working with EPUB publications",
    "originLink": "https://www.npmjs.com/package/@smoores/epub",
    "originBody": "Howdy! I&#x27;ve just written a blog post about this, and I figured I would share it here: https:&#x2F;&#x2F;smoores.dev&#x2F;post&#x2F;announcing_smoores_epub&#x2F;. As I&#x27;ve been working on Storyteller[1], I&#x27;ve been developing a library for working with EPUB files, since that&#x27;s a large amount of the work that Storyteller does. After a friend asked for advice on creating EPUB books in Node.js, I decided to publish Storyteller&#x27;s EPUB library as a standalone NPM package. I really love the EPUB spec, and I think the Node.js developer community deserves an actively maintained library for working with it![1]: https:&#x2F;&#x2F;smoores.gitlab.io&#x2F;storyteller",
    "commentLink": "https://news.ycombinator.com/item?id=42411727",
    "commentBody": "@smoores/epub, a JavaScript library for working with EPUB publications (npmjs.com)137 points by smoores 23 hours agohidepastfavorite43 comments Howdy! I've just written a blog post about this, and I figured I would share it here: https://smoores.dev/post/announcing_smoores_epub/. As I've been working on Storyteller[1], I've been developing a library for working with EPUB files, since that's a large amount of the work that Storyteller does. After a friend asked for advice on creating EPUB books in Node.js, I decided to publish Storyteller's EPUB library as a standalone NPM package. I really love the EPUB spec, and I think the Node.js developer community deserves an actively maintained library for working with it! [1]: https://smoores.gitlab.io/storyteller Daiz 9 hours agoAs someone who has built custom EPUB authoring scripts in Node.js for work and also quite likes the EPUB spec: cool! I expect I'll still keep using said scripts for work, but I have some side project ideas which would involve actually reading EPUB files too - I'll probably give this a spin for those. reply smoores 4 hours agoparentThanks! Looking forward to your feedback! reply antonyt 19 hours agoprevI feel stupid. I read “automatically syncing ebooks and audiobooks” and thought StoryTeller was a file synchronization service (like SyncThing) that for some reason only supported certain file types. Maybe “syncing ebooks with audiobooks” would be clearer? Also entirely possible this is just a me problem, not a general one. Really cool project! reply smoores 16 hours agoparentThis is like... comically hard to express succinctly haha. We've been having several conversations about how to explain it quickly to new folks. I like the phrase that the Readium folks use, \"guided narration\", but I don't know how useful that is for folks that aren't already familiar with what Storyteller does reply chrismorgan 16 hours agorootparent“Aligning” seems a perfectly good word to me. It’s the technical term that gets used, and it’s not particularly overloaded so people aren’t going to expect it to mean something else, and it’s easy to demonstrate even pictorially. (I would also use the term “synchronising” rather than “syncing”, because “syncing” has kinda developed a meaning of its own, even though it came from the same place. And use the word “with”, and try to use the words “text”. “Synchronising ebook text with audiobooks” is way better than “syncing ebooks and audiobooks”.) reply rahimnathwani 15 hours agorootparentprevMaybe you can use examples of the 'why'? - Switch between reading and listening whenever you want - Follow the text while listening to audiobooks - Enjoy audiobooks while reading along with the text Or even simpler: - Read or listen - switch anytime - See the words as you listen - Listen while you read along reply trevor-e 17 hours agoparentprevI thought the exact same thing, especially since one of the main selling points is around self-hosting which I thought was for the file syncing. reply jspizziri 7 hours agoprevYou mentioned readium in one of your comments. I’m curious why you didn’t use the readium spec and corresponding ecosystem. Coming in cold and just glanced at your blog post, and I see you’re using RN. There is a RN package that leverages readium under the hood for ebook reading (I know because I’m the author), don’t know if it’s a weird actually has the api you need. EDIT: storyteller is super interesting. Dug around a bit in the code and see that you do seem to be using readium for some things, so I must just be missing some nuance. reply smoores 4 hours agoparentReadium is fantastic, and Storyteller uses it basically whenever possible. But Readium is exclusively for reading EPUB contents, and doesn’t have any support for modifying or creating them, which is the primary purpose of this library! reply hombre_fatal 22 hours agoprevExtracting a library from a real world project is one of my favorite parts of software. I'm sure the march of LLMs will continue eating into this pie, and that's a good thing (most of it is a distraction from the real work), but I love polishing a library on my laptop in a cafe. It's like working on a painting or something. reply smoores 21 hours agoparentIt was, actually, very enjoyable! When we pulled React ProseMirror[1] out of the NYT text editor, it was a pretty laborious process that we had to careful plan and execute for months, and we still ended up with an internal fork for a while. By contrast, this was mostly just moving a file around and then writing documentation and cleaning up the public API. I rather enjoy thinking about and modeling library APIs in general, so I actually had a lot of fun with it! [1]: https://www.npmjs.com/package/@nytimes/react-prosemirror reply gavmor 22 hours agoprevCool! I totally could have used this earlier this year... can't remember what for... Interesting choice to publish from the storyteller \"monorepo.\" Is that because it evolved in situ, and you've no impetus to incur the overhead of extraction? reply smoores 22 hours agoparentHahaha, well if it comes to you, the library will still be there for you :) Right, this was actually just a file within the Storyteller web package to start. It was fairly well defined, and so pretty easy to pull out into another package in the monorepo, but Storyteller is the primary consumer at the moment, and I want to be able to develop them in sync. Plus, it provides a great test bed for development of the library! edit: I forgot to mention that the eventual goal is to (hopefully!) publish this package as @storyteller/epub, along with any other packages that end up split out of Storyteller. That will probably include at least a @storyteller/synchronize and a @storyteller/cli. Unfortunately, someone seems to have snagged the @storyteller org on NPM several years ago and left it to languish without really using it, so I'm waiting to see whether GitHub will consider this squatting and transfer the org to me. I've also tried reaching out to the developer that owns the org, but they don't seem to have been active on GitHub or NPM for the past 5 years or so, and my only real strategy for reaching out to them was to open an issue on one of their other GitHub projects! reply herrvogel- 21 hours agoprevStoryteller seems pretty cool in general. Can it be used to host books for other people? reply smoores 21 hours agoparentThanks! Absolutely. You can invite users to your Storyteller server and give them whatever permissions are appropriate (e.g. you can choose whether they can only download books, or can also manage uploading and syncing books and/or managing users). It has SMTP support for emailing invites, or it can just generate invite links for you to share yourself. More info here: https://smoores.gitlab.io/storyteller/docs/administering#inv... reply 9dev 21 hours agorootparentOh my! This looks very neat, and I’ve been working on something similar to Storyteller (i think): https://github.com/project-kiosk/kiosk I don’t get around working on it right now, but maybe there’s something useful there for you. reply curtis3389 22 hours agoprevSomething I've been wondering: why do ebooks take so long to render? My kindle seems good at it, but opening an ebook in calibre/fbreader/etc can take minutes or even fail in some readers depending on the ebook. reply smoores 22 hours agoparentI would guess there are multiple potential pitfalls here. Firstly, not all ebook formats are created equal -- Storyteller only operates on EPUB files, because EPUB is an open source format and it supports Media Overlays (read-aloud) natively. I can only really speak to that format, but there are others (MOBI, PDF, etc). An EPUB is just a ZIP archive of XML and XHTML files (plus other assets, like images). Partly, I suspect, because of the dearth of actively maintained open source projects in the space, and partly because of the nature of tech in the book publishing industry, EPUB generation software used by authors and publishers often messes up this spec, which means that EPUB readers sometimes need to have fairly complex fallback logic for trying to figure out how to render a book. Also, because EPUBs are ZIP archives, some readers may either unzip the entire book into memory or \"explode\" it into an unzipped directory on disk, both of which may result in some slowness, especially if the book has lots of large resources. The newest Brandon Sanderson novel, for example, is ~300MB _zipped_. Additionally, and perhaps more importantly, EPUBs (and I believe MOBIs as well) represent content as XHTML and CSS, which means that readers very often need to use a browser or webview to actually render the book. Precisely how they deliver this content into the webview can have a huge impact on performance; most browser don't love to be told to format entire novels worth of content into text columns, for example. reply Yoric 21 hours agorootparentFWIW, I wrote an EPUB (well, it was called OEBPS at the time) reader that rendered pretty much all of the format ~21 years ago (including all of XHTML and CSS) and it had very decent performance. I seem to recall that someone tried it on the One Laptop Per Child XO and it was... well, slow, but it worked. So it's possible :) reply curtis3389 21 hours agorootparentprevThank you so much! That's incredibly enlightening! reply smoores 21 hours agorootparentOf course! I'm hoping to have a web reader with Media Overlay support built in to Storyteller available in the next few months, along with some much needed library management tooling, so maybe that will be useful for you! I'll try to make it snappy :) reply giantrobot 21 hours agorootparentprevAdditionally the XHTML content can just be a single large file instead of one file per chapter/section. Paginating and rendering the large single file is going to be more effort than the same on a smaller file. This is all on top of the pitfalls and variability you mention. reply smoores 21 hours agorootparentYup, great point. Especially if you've used some tool to convert from another file, like a PDF, into an EPUB, you can easily end up with the entire book in a single XHTML file, which, again, can be pretty heavy for a browser to parse and format! I also have no idea whether Calibre et al actually use native web views, or have their own renderers, which are almost certainly less performant than native web views! reply cyberax 20 hours agorootparentprev> Additionally the XHTML content can just be a single large file instead of one file per chapter/section. Terry Pratchett books are notorious for that. Some tools EPUB authoring tools artificially introduce breaks, but you can't rely on them. reply cyberax 21 hours agorootparentprevI used Storyteller to align the most recent Sanderson's novel on audio and the result is 1.7Gb. That's... painful. It resulted in it crashing the reader on Remarkable2 tablet. I'm now actually working on a Calibre-Web change to strip the audio and media overlay from the books it serves via OPDS. Then I'll need to tackle cross-device progress sync. This turned out to be surprisingly tricky. reply smoores 20 hours agorootparentYou can’t do much better than that; that’s the size of the audiobook! For what it’s worth, I also used Storyteller on Wind and Truth, and got it down to 1.2GB by using the OPUS codec with a 32 kb/s bitrate. reply cyberax 20 hours agorootparentYeah. My current workaround is to create KEPUBs (Kobo-optimized epubs), but that creates an issue with cross-format reading progress sync. This is an interesting task in itself, though. So I'm trying to design a progress sync protocol. My current idea is to just use several words from the text itself to unambiguously pinpoint the position within a section (chapter). reply smoores 20 hours agorootparentIs the idea that you have some devices that you want to download just the text to, but have it sync with your other devices? I think we could support that natively, honestly! Storyteller already has the input files, and it uses a text-based position system that doesn’t require the audio to exist. If you’re already doing work on this, maybe we could add it to Storyteller? reply smeej 18 hours agorootparentOoh, that's an interesting idea. I only have one device where I would ever want to switch to listening to my book, but a couple others where I would like to read it. reply sriacha 20 hours agoparentprevI find Koreader (linux version) leaps and bounds faster than the calibre reader. reply tills13 16 hours agoprevI'm going to be annoying and simply laugh at the fact it's a 2k line, single file in source. It's TypeScript! You HAVE to compile it to ship it as an npm package (_technically_ you don't but). Split it up into smaller modules with `import` statements! reply chrismorgan 16 hours agoparentQuite seriously: why? What actual advantage do you get? People tend to split things up into separate files far too eagerly. A single two-thousand-line file is nothing. Especially when most of that is in one class, and needs to be, so you can’t really split things up, or at the very least there would be runtime overhead to it. reply smoores 15 hours agorootparentThanks, yeah I agree. The vast majority of the code in this library lives in a single class definition. Is it possible to move the implementations into separate files? Totally. Would that make the codebase more legible? I think at the moment, I would argue no, it would actually hurt legibility. If the class needs to grow dramatically, then maybe we’ll need a different approach, but I think this is actually the right thing to do for now! reply cyberax 20 hours agoprevBTW, I've had this idea in my mind for a while, after slowly working through my e-library infrastructure. Do you think it might be a good idea to set up a site to share the aligned overlays from Storyteller? This way, people won't have to waste CPU/GPU time re-aligning the same files over and over again. It should be OK from a copyright perspective, as it won't be distributing any copyrighted material, only the media overlay information. reply smoores 20 hours agoparentThat’s a really interesting idea! The more I think about it, the more I like it. A challenge I foresee is that the media overlays are only reusable if you have the exact same input EPUB file, and have processed it with Storyteller to mark up the sentence boundaries. EPUBs have unique identifiers, though, so maybe this would be fine! We’d need to add a new processing flow to Storyteller, but it should be doable. Feel free to hit me up in the Storyteller chat if you want to discuss more! Thanks for sharing this idea! reply smeej 18 hours agorootparentIt would be cool to do this with Project Gutenberg and LibriVox files, since they're all public domain works anyway. The entire Great Books of Western Civilization are on both, and I know I'd make more progress on reading it if I could hand off between reading and listening more easily! reply NoahKAndrews 18 hours agorootparentprevYou could require that the input files have the same sha256 hash, that would presumably be more robust than trusting an ID from the file itself reply smoores 18 hours agorootparentYeah I was toying around with that, too… but folks often mess around with metadata in tools like Calibre and Audiobookshelf in ways that wouldn’t have an impact on Storyteller’s sync, but would change their hash. On the other hand, I don’t know how various publishers handle EPUB dc:identifiers and that may not be robust enough, either. We could try doing something like hashing only the contents of spine items (including their file names, since that’s how media overlays refer to content) reply cyberax 17 hours agorootparentI was going to suggest to use the same approach as the old CD tagging systems. Count the number of words in each chapter to create a \"book fingerprint\". It's highly likely to be globally unique, and it can also help with the missing forewords/afterwords/bonus content sections. In addition, you can also add fuzzy matching for the title. reply smoores 16 hours agorootparentI think that the thing we need to account for (which, number of words per chapter would capture this, I think) is different publications of the same book, which would need different overlays if they have different chapter filepaths, etc. reply revskill 21 hours agoprevGenius. Thanks. reply seanwessmith 22 hours agoprev [–] sometimes life just delivers. was looking for this 2 days ago reply smoores 22 hours agoparent [–] Outstanding. Let me know if you run into any issues! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new EPUB library for Node.js has been developed and released as an NPM package, aimed at providing a well-maintained solution for creating EPUB books.",
      "The library was initially created during the development of a project called Storyteller and is now available for the broader Node.js community.",
      "The release was motivated by a request for advice on EPUB book creation, highlighting the demand for such a tool in the community."
    ],
    "commentSummary": [
      "@smoores/epub is a JavaScript library designed for handling EPUB files, developed as part of the Storyteller project, and released as a standalone NPM package.",
      "The library addresses the need for EPUB creation and modification tools in the Node.js community, complementing Readium, which is used for reading EPUBs.",
      "The project supports features like hosting books and syncing reading progress across devices, with ongoing discussions about sharing media overlays to optimize processing."
    ],
    "points": 137,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1734119546
  }
]
