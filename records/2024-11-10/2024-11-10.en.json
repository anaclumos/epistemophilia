[
  {
    "id": 42097261,
    "title": "Grim Fandango",
    "originLink": "https://www.filfre.net/2024/11/grim-fandango/",
    "originBody": "The Digital Antiquarian November 8, 2024 • 29 comments Grim Fandango Share Tweet Pin Mail SMS My one big regret was the PlayStation version [of Broken Sword]. No one thought it would sell, so we kept it like the PC version. In hindsight, I think if we had introduced direct control in this game, it would have been enormous. — Charles Cecil of Revolution Software, speaking from the Department of Be Careful What You Wish For One day in June of 1995, Tim Schafer came to work at LucasArts and realized that, for the first time in a long time, he didn’t have anything pressing to do. Full Throttle, his biker movie of an adventure game, had been released several weeks before. Now, all of the initial crush of interviews and marketing logistics was behind him. A mountain had been climbed. So, as game designers do, he started to think about what his next Everest should be. Schafer has told in some detail how he came up with the core ideas behind Grim Fandango over the course of that summer of 1995. The truth is, I had part of the Fandango idea before I did Full Throttle. I wanted to do a game that would feature those little papier-mâché folk-art skeletons from Mexico. I was looking at their simple shapes and how the bones were just painted on the outside, and I thought, “Texture maps! 3D! The bones will be on the outside! It’ll look cool!” But then I was stuck. I had these skeletons walking around the Land of the Dead. So what? What did they do? Where were they going? What did they want? Who’s the main character? Who’s the villain? The mythology said that the dead walk the dark plane of the underworld known as Mictlān for four years, after which their souls arrive at the ninth plane, the land of eternal rest. Sounds pretty “questy” to me. There you have it: a game. “Not cool enough,” said Peter Tscale, my lead artist. “A guy walking in a supernatural world? What’s he doing? Supernatural things? It just sounds boring to me.” So, I revamped the story. Adventure games are all fantasies really, so I had to ask myself, “Who would people want to be in a game? What would people want to do?” And in the Land of the Dead, who would people rather be than Death himself? Being the Grim Reaper is just as cool as being a biker, I decided. And what does the Grim Reaper do? He picks up people who have died and carts them over from the other world. Just like a driver of a taxi or limo. Okay, so that’s Manny Calavera, our main character. But who’s the bad guy? What’s the plot? I had just seen Chinatown, and I really liked the whole water-supply/real-estate scam that Noah Cross had going there, so of course I tried to rip that off and have Manny be a real-estate salesman who got caught up in a real-estate scandal. Then he was just like the guys in Glengarry Glen Ross, always looking for the good leads. But why would Hector Lemans, my villain, want real estate? Why would anyone? They’re dead! They’re only souls. What do souls in the Land of the Dead want? They want to get out! They want safe passage out, just like in Casablanca! The Land of the Dead is a transitory place, and everybody’s waiting around for their travel papers. So Manny is a travel agent, selling tickets on the big train out of town, and Hector’s stealing the tickets… The missing link between Full Throttle and Grim Fandango is Manny’s chauffeur and mechanic Glottis, a literal speed demon. This, then, became the elevator pitch for Grim Fandango. Begin with the rich folklore surrounding Mexico’s Day of the Dead, a holiday celebrated each year just after Halloween, which combines European Christian myths about death and the afterlife with the older, indigenous ones that still haunt the Aztec ruins of Teopanzolco. Then combine it with classic film noir to wind up with Raymond Chandler in a Latino afterlife. It was nothing if not a strikingly original idea for an adventure game. But there was also one more, almost equally original part of it: to do it in 3D. To hear Tim Schafer tell the story, the move away from LucasArts’s traditional pixel art and into the realm of points, polygons, and textures was motivated by his desire to deliver a more cinematic experience. By no means does this claim lack credibility; as you can gather by reading what he wrote above, Schafer was and is a passionate film buff, who tends to resort to talking in movie titles when other forms of communication fail him. The environments in previous LucasArts adventure games — even the self-consciously cinematic Full Throttle — could only be shown from the angle the pixel artists had chosen to drawn them from. In this sense, they were like a theatrical play, or a really old movie, from the time before Orson Welles emancipated his camera and let it begin to roam freely through his sets in Citizen Kane. By using 3D, Schafer could become the Orson Welles of adventure games; he would be able to deliver dramatic angles and closeups as the player’s avatar moved about, would be able to put the player in his world rather than forever forcing her to look down on it from on-high. This is the story he still tells today, and there’s no reason to believe it isn’t true enough, as far as it goes. Nevertheless, it’s only half of the full story. The other half is a messier, less idealistic tale of process and practical economics. Reckoned in their cost of production per hour of play time delivered, adventure games stood apart from any other genre in their industry, and not in a good way. Building games entirely out of bespoke, single-use puzzles and assets was expensive in contrast to the more process-intensive genres. As time went on and gamers demanded ever bigger, prettier adventures, in higher resolutions with more colors, this became more and more of a problem. Already in 1995, when adventure games were still selling very well, the production costs that were seemingly inherent to the genre were a cause for concern. And the following year, when the genre failed to produce a single million-plus-selling breakout hit for the first time in half a decade, they began to look like an existential threat. At that point, LucasArts’s decision to address the issue proactively in Grim Fandango by switching from pixel art to 3D suddenly seemed a very wise move indeed. For a handful of Silicon Graphics workstations running 3D-modelling software could churn out images far more quickly than an army of pixel artists, at a fraction of the cost per image. If the graphics that resulted lacked some of the quirky, hand-drawn, cartoon-like personality that had marked LucasArts’s earlier adventure games, they made up for that by virtue of their flexibility: a scene could be shown from a different angle just by changing a few parameters instead of having to redraw it from scratch. This really did raise the prospect of making the more immersive games that Tim Schafer desired. But from a bean counter’s point of view, the best thing about it was the cost savings. And there was one more advantage as well, one that began to seem ever more important as time went on and the market for adventure games running on personal computers continued to soften. Immersive 3D was more or less the default setting of the Sony PlayStation, which had come roaring out of Japan in 1995 to seize the title of the most successful games console of the twentieth century just before the curtain fell on that epoch. In addition to its 3D hardware, the PlayStation sported a CD drive, memory cards for saving state, and a slightly older typical user than the likes of Nintendo and Sega. And yet, although a number of publishers ported their 2D computer-born adventure games to the PlayStation, they never felt entirely at home there, having been designed for a mouse rather than a game controller.[1]A mouse was available as an accessory for the PlayStation, but it was never very popular. A 3D adventure game with a controller-friendly interface might be a very different proposition. If it played its cards right, it would open the door to an installed base of customers five to ten times the size of the extant market for games on personal computers. Working with 3D graphics in the late 1990s required some clever sleight of hand if they weren’t to end up looking terrible. Grim Fandango’s masterstroke was to make all of its characters — like the protagonist Manny Calavera, whom you see above — mere skeletons, whose faces are literally painted onto their skulls. (The characters are shown to speak by manipulating the texture maps that represent their faces, not by manipulating the underlying 3D models themselves.) This approach gave the game a look reminiscent of another of its cinematic inspirations, Tim Burton’s The Nightmare Before Christmas, whilst conveniently avoiding all of the complications of trying to render pliant flesh. A win-win, as they say. Or, as Tim Schafer said: “Instead of fighting the tech limitations of 3D, you have to embrace them and turn them into a style.” But I’m afraid I’ve gotten slightly ahead of myself. This constellation of ideas, affordances, problems, and solutions was still in a nascent form in November of 1995, when LucasArts hired a young programmer fresh out of university by the name of Bret Mogilefsky. Mogilefsky was a known quantity already, having worked at LucasArts as a tester on and off while he was earning his high-school and university diplomas. Now, he was entrusted with the far more high-profile task of making SCUMM, LucasArts’s venerable adventure engine, safe for 3D. After struggling for a few months, he concluded that this latest paradigm shift was just too extreme for an engine that had been created on a Commodore 64 circa 1986 and ported and patched from there. He would have to tear SCUMM down so far in order to add 3D functionality that it would be easier and cleaner simply to make a new engine from scratch. He told his superiors this, and they gave him permission to do so — albeit suspecting all the while, Mogilefsky is convinced, that he would eventually realize that game engines are easier envisioned than implemented and come crawling back to SCUMM. By no means was he the first bright spark at LucasArts who thought he could reinvent the adventuring wheel. But he did prove the first one to call his bosses’ bluff. The engine that he called GrimE (“Grim Engine,” but pronounced like the synonym for “dirt”) used a mixture of pre-rendered and real-time-rendered 3D. The sets in which Manny and his friends and enemies played out their dramas would be the former; the aforementioned actors themselves would be the latter. GrimE was a piebald beast in another sense as well: that of cheerfully appropriating whatever useful code Mogilefsky happened to find lying around the house at LucasArts, most notably from the first-person shooter Jedi Knight. Like SCUMM before it, GrimE provided relatively non-technical designers like Tim Schafer with a high-level scripting language that they could use themselves to code all of the mechanics of plot and puzzles. Mogilefsky adapted for this task Lua, a new, still fairly obscure programming language out of Brazil. It was an inspired choice. Elegant, learnable, and yet infinitely and easily extendible, Lua has gone on to become a staple language of modern game development, to be found today in such places as the wildly popular Roblox platform. The most frustrating aspects of GrimE from a development perspective all clustered around the spots where its two approaches to 3D graphics rubbed against one another, producing a good deal of friction in the process. If, for example, Manny was to drink a glass of whiskey, the pre-rendered version of the glass that was part of the background set had to be artfully swapped with its real-time-rendered incarnation as soon as Manny began to interact with it. Getting such actions to look seamless absorbed vastly more time and energy than anyone had expected it to. In fact, if the bean counters had been asked to pass judgment, they would have had a hard time labeling GrimE a success at all under their metrics. Grim Fandango was in active development for almost three full years, and may have ended up costing as much as $3 million. This was at least two and a half times as much as Full Throttle had cost, and placed it in the same ballpark as The Curse of Monkey Island, LucasArts’s last and most audiovisually lavish SCUMM adventure, which was released a year before Grim Fandango. Further, despite employing a distinctly console-like control scheme in lieu of pointing and clicking with the mouse, Grim Fandango would never make it to the PlayStation; GrimE ended up being just too demanding to be made to work on such limited hardware.[2]Escape from Monkey Island, the only other game ever made using GrimE, was ported to the more capable PlayStation 2 in 2001. All that aside, though, the new engine remained an impressive technical feat, and did succeed in realizing most of Tim Schafer’s aesthetic goals for it. Even the cost savings it apparently failed to deliver come with some mitigating factors. Making the first game with a new engine is always more expensive than making the ones that follow; there was no reason to conclude that GrimE couldn’t deliver real cost savings on LucasArts’s next adventure game. Then, too, for all that Grim Fandango wound up costing two and a half times as much as Full Throttle, it was also well over two and a half times as long as that game. “Game production schedules are like flying jumbo jets,” says Tim Schafer. “It’s very intense at the takeoff and landing, but in the middle there’s this long lull.” The landing is the time of crunch, of course, and the crunch on Grim Fandango was protracted and brutal even by the industry’s usual standards, stretching out for months and months of sixteen- and eighteen-hour days. For by the beginning of 1998, the game was way behind schedule and way over budget, facing a marketplace that was growing more and more unkind to the adventure genre in general. This was not a combination to instill patience in the LucasArts executive suite. Schafer’s team did get the game done by the autumn of 1998, as they had been ordered to do in no uncertain terms, but only at a huge cost to their psychological and even physical health. Bret Mogilefsky remembers coming to Schafer at one point to tell him that he just didn’t think he could go on like this, that he simply had to have a break. He was met with no sympathy whatsoever. To be fair, he probably shouldn’t have expected any. Crunch was considered par for the course in the industry during this era, and LucasArts was among the worst of its practitioners. Long hours spent toiling for ridiculously low wages — Mogilefsky was hired to be the key technical cog in this multi-million-dollar project for a salary of about $30,000 per year — were considered the price you paid for the privilege of working at The Star Wars Company. Even setting aside the personal toll it took on the people who worked there, crunch did nothing positive for the games themselves. As we’ll see, Grim Fandango shows the scars of crunch most obviously in its dodgy puzzle design. Good puzzles result from a methodical, iterative process of testing and carefully considering the resulting feedback. Grim Fandango did not benefit from such a process, and this lack is all too plainly evident. But before I continue making some of you very, very mad at me, let me take some time to note the strengths of Grim Fandango, which are every bit as real as its weaknesses. Indeed, if I squint just right, so that my eyes only take in its strengths, I have no problem understanding why it’s to be found on so many lists of “The Best Adventure Games Ever,” sometimes even at the very top. There’s no denying the stuff that Grim Fandango does well. Its visual aesthetic, which I can best describe as 1930s Art Deco meets Mexican folk art meets 1940s gangster flick, is unforgettable. And it’s married to a script that positively crackles with wit and pathos. Our hero Manny is the rare adventure-game character who can be said to go through an actual character arc, who grows and evolves over the course of his story. The driving force behind the plot is his love for a woman named Meche. But his love isn’t the puppy love that Guybrush Threepwood has for Elaine in the Monkey Island games; the relationship is more nuanced, more adult, more complicated, and its ultimate resolution is all the more moving for that. How do you create real stakes in a story where everyone is already dead? The Land of the Death’s equivalent of death is “sprouting,” in which a character is turned into a bunch of flowers and forced to live another life in that form. Why shouldn’t the dead fear life as much as the living fear death? Tim Schafer did not grow up with the Latino traditions that are such an inextricable part of Grim Fandango. Yet the game never feels like the exercise in clueless or condescending cultural tourism it might easily have become. On the contrary, the setting feels full-bodied, lived-in, natural. The cause is greatly aided by a stellar cast of voice actors with just the right accents. The Hollywood veteran Tony Plana, who plays Manny, is particularly good, teasing out exactly the right blend of world-weary cynicism and tarnished romanticism. And Maria Canalas, who plays Meche, is equally perfect in her role. The non-verbal soundtrack by Peter McConnell is likewise superb, a mixture of mariachi music and cool jazz that shouldn’t work but does. Sometimes it soars to the forefront, but more often it tinkles away in the background, setting the mood. You’d only notice it if it was gone — but trust me, then you would really notice. This is a big game as well as a striking and stylish one — in fact, by most reckonings the biggest adventure that LucasArts ever made. Each of its four acts, which neatly correspond to the four years that the average soul must spend wandering the underworld before going to his or her final rest, is almost big enough to be a self-contained game in its own right. Over the course of Grim Fandango, Manny goes from being a down-on-his-luck Grim Reaper cum travel agent to a nightlife impresario, from the captain of an ocean liner to a prisoner laboring in an underwater mine. The story does arguably peak too early; the second act, an extended homage to Casablanca with Manny in the role of Humphrey Bogart, is so beautifully realized that much of what follows is slightly diminished by the comparison. Be that as it may, though, it doesn’t mean any of what follows is bad. The jump cut to Manny’s new life as a bar owner in the port city of Rubacava at the beginning of the second act is to my mind the most breathtaking moment of the game, the one where you first realize how expansive its scope and ambition really are. All told, then, I have no real beef with anyone who chooses to label Grim Fandango an aesthetic masterpiece. If there was an annual award for style in adventure games, this game would have won it easily in 1998, just as Tim Schafer’s Full Throttle would have taken the prize for 1995. Sadly, though, it seems to me that the weaknesses of both games are also the same. In both of their cases, once I move beyond the aesthetics and the storytelling and turn to the gameplay, some of the air starts to leak out of the balloon. The interactive aspects of Grim Fandango — you know, all that stuff that actually makes it a game — are dogged by two overarching sets of problems. The first is all too typical for the adventure genre: overly convoluted, often nonsensical puzzle design. Tim Schafer was always more intrinsically interested in the worlds, characters, and stories he dreamed up than he was in puzzles. This is fair enough on the face of it; he is very, very good at those things, after all. But it does mean that he needs a capable support network to ensure that his games play as well as they look and read. He had that support for 1993’s Day of the Tentacle, largely in the person of his co-designer Dave Grossman; the result was one of the best adventure games LucasArts ever made, a perfect combination of inspired fiction with an equally inspired puzzle framework. Unfortunately, he was left to make Full Throttle on his own, and it showed. Ditto Grim Fandango. For all that he loved movies, the auteur model was not a great fit for Tim Schafer the game designer. Grim Fandango seldom gives you a clear idea of what it is you’re even trying to accomplish. Compare this with The Curse of Monkey Island, the LucasArts adventure just before this one, a game which seemed at the time to herald a renaissance in the studio’s puzzle designs. There, you’re always provided with an explicit set of goals, usually in the form of a literal shopping list. Thus even when the mechanics of the puzzles themselves push the boundaries of real-world logic, you at least have a pretty good sense of where you should be focusing your efforts. Here, you’re mostly left to guess what Tim Schafer would like to have happen to Manny next. You stumble around trying to shake something loose, trying to figure out what you can do and then doing it just because you can. By no means is it lost on me that this sense of confusion arises to a large extent because Grim Fandango is such a character-driven story, one which eschews the mechanistic tic-tac-toe of other adventure-game plots. But recognizing this irony doesn’t make it any less frustrating when you’re wandering around with no clue what the story wants from you. Compounding the frustrations of the puzzles are the frustrations of the interface. You don’t use the mouse at all; everything is done with the numeric keypad, or, if you’re lucky enough to have one, a console-style controller. (At the time Grim Fandango was released, virtually no one playing games on computers did.) Grim Fandango’s mode of navigation is most reminiscent of the console-based JRPGs of its era, such as the hugely popular Final Fantasy VII, which sold over 10 million copies on the PlayStation during the late 1990s. Yet in practice it’s far more irritating, because you have to interact with the environment here on a much more granular level. LucasArts themselves referred to their method of steering Manny about as a “tank” interface, a descriptor which turns out to be all too descriptive. It really does feel like you’re driving a bulky, none too agile vehicle through an obstacle course of scenery. Make no mistake: the 3D engine makes possible some truly striking views. But too often the designers prioritize visual aesthetics over playability. In the final reckoning, then, an approach that is fine in a JRPG makes just about every aspect of an old-school, puzzle-solving adventure game — which is what Grim Fandango remains in form and spirit when you strip all of the details of its implementation away — more awkward and less fun. Instead of having hotspots in the environment that light up when you pass a mouse cursor over them, as you do in a SCUMM adventure, you have to watch Manny’s head carefully as you drive him around; when it turns to look in a certain direction, that means there’s something he can interact with there. Needless to say, it’s all too easy to miss a turn of his head, and thereby to miss something vital to your progress through the game. The inventory system is also fairly excruciating. Instead of being able to bring up a screen showing all of the items Manny is carrying, you have to cycle through them one by one by punching a key or controller button over and over, listening to him drone out their descriptions over and over as you do so. This approach precludes using one inventory object on another one, cutting off a whole avenue of puzzle design. Now, the apologists among you — and this game does have an inordinate number of them — might respond to these complaints of mine by making reference to the old cliché that, for every door that is closed in life (and presumably in games as well), another one is opened. And in theory, the new engine really does open a door to new types of puzzles that are more tactile and embodied, that make you feel more a part of the game’s world. To Tim Schafer’s credit, he does try to include these sorts of puzzles in quite a few places. To our detriment, though, they turn out to be the worst puzzles in the game, relying on finicky positioning and timing and giving no useful feedback when you get those things slightly wrong. But even when Grim Fandango presents puzzles that could easily have been implemented in SCUMM, they’re made way more annoying than they ought to be by the engine and interface. When you’re reduced to that final adventurer’s gambit of just trying everything on everything, as you most assuredly will be from time to time here, the exercise takes many times longer than it would using SCUMM, what with having to laboriously drive Manny about from place to place. Taken as a game rather than the movie it often seems more interested in being, Grim Fandango boils down to a lumpy stew of overthought and thoughtlessness. In the former category, there’s an unpleasant ideological quality to its approach, with its prioritization of some hazy ethic of 3D-powered “immersion” and its insistence that no visible interface elements whatsoever can appear onscreen, even when these choices actively damage the player’s experience. This is where Sid Meier can helpfully step in to remind us that it is the player who is meant to be having the fun in a game, not the designer. The thoughtlessness comes in the lack of consideration of what kind of game Grim Fandango is meant to be. Like all big-tent gaming genres, the adventure genre subsumes a lot of different styles of game with different priorities. Some adventures are primarily about exploration and puzzle solving. And that’s fine, although one does hope that those games execute their puzzles better than this one does. But Grim Fandango is not primarily about its puzzles; it wants to take you on a ride, to sweep you along on the wings of a compelling story. And boy, does it have a compelling story to share with you. For this reason, it would be best served by streamlined puzzles that don’t get too much in the way of your progress. The ones we have, however, are not only frustrating in themselves but murder on the story’s pacing, undermining what ought to be Grim Fandango’s greatest strengths. A game like this one that is best enjoyed with a walkthrough open on the desk beside it is, in this critic’s view at least, a broken game by definition. As with so many near-miss games, the really frustrating thing about Grim Fandango is that the worst of its problems could so easily have been fixed with just a bit more testing, a bit more time, and a few more people who were empowered to push back against Tim Schafer’s more dogmatic tendencies. For the 2015 remastered version of the game, Schafer did grudgingly agree to include an alternative point-and-click interface that is more like that of a SCUMM adventure. The results verge on the transformational. By no means does the addition of a mouse cursor remedy all of the infelicities of the puzzle design, but it does make battering your way through them considerably less painful. If my less-than-systematic investigations on YouTube are anything to go by, this so-old-it’s-new-again interface has become by far the most common way to play the game today. The Grim Fandango remaster. Note the mouse cursor. The new interface is reportedly implemented entirely in in-engine Lua scripts rather than requiring any re-programming of the GrimE engine itself. This means that it would have been perfectly possible to include as an option in the original release. In other places, the fixes could have been even simpler than revamping the interface. A shocking number of puzzles could have been converted from infuriating to delightful by nothing more than an extra line or two of dialog from Manny or one of the other characters. As it is, too many of the verbal nudges that do exist are too obscure by half and are given only once in passing, as part of conversations that can never be repeated. Hints for Part Four are to be found only in Part One; I defy even an elephant to remember them when the time comes to apply them. All told, Grim Fandango has the distinct odor of a game that no one other than those who were too close to it to see it clearly ever really tried to play before it was put in a box and shoved out the door. There was a time when seeking the feedback of outsiders was a standard part of LucasArts’s adventure-development loop. Alas, that era was long passed by the time of Grim Fandango. Nonetheless, Grim Fandango was accorded a fairly rapturous reception in the gaming press when it was released in the last week of October in 1998, just in time for Halloween and the Mexican Day of the Dead which follows it on November 1. Its story, characters, and setting were justifiably praised, while the deficiencies of its interface and puzzle design were more often than not relegated to a paragraph or two near the end of the review. This is surprising, but not inexplicable. There was a certain sadness in the trade press — almost a collective guilt — about the diminished prospects of the adventure game in these latter years of the decade. Meanwhile LucasArts was still the beneficiary of a tremendous amount of goodwill, thanks to the many classics they had served up during those earlier, better years for the genre as a whole. Grim Fandango was held up as a sort of standard bearer for the embattled graphic adventure, the ideal mix of tradition and innovation to serve as proof that the genre was still relevant in a post-Quake, post-Starcraft world. For many years, the standard narrative had it that the unwashed masses of gamers utterly failed to respond to the magazines’ evangelism, that Grim Fandango became an abject failure in the marketplace. In more recent years, Tim Schafer has muddied those waters somewhat by claiming that the game actually sold close to half a million copies. I rather suspect that the truth is somewhere between these two extremes. Sales of a quarter of a million certainly don’t strike me as unreasonable once foreign markets are factored into the equation. Such a figure would have been enough to keep Grim Fandango from losing much if any money, but would have provided LucasArts with little motivation to make any more such boldly original adventure games. And indeed, LucasArts would release only one more adventure game of any stripe in their history. It would use the GrimE engine, but it would otherwise play it about as safe as it possibly could, by being yet another sequel to the venerable but beloved Secret of Monkey Island. As I was at pains to note earlier, I do see what causes some people to rate Grim Fandango so highly, and I definitely don’t think any less of them for doing so. For my part, though, I’m something of a stickler on some points. To my mind, interactivity is the very quality that separates games from other forms of media, making it hard for me to pronounce a game “good” that botches it. I’ve learned to be deeply suspicious of games whose most committed fans want to talk about everything other than that which you the player actually do in them. The same applies when a game’s creators display the same tendency. Listening to the developers’ commentary tracks in the remastered edition of Grim Fandango (who would have imagined in 1998 that games would someday come with commentary tracks?), I was shocked by how little talk there was about the gameplay. It was all lighting and dialog beats and soundtrack stabs and Z-buffers instead — all of which is really, really important in its place, but none of which can yield a great game on its own. Tellingly, when the subject of puzzle design did come up, it always seemed to be in an off-hand, borderline dismissive way. “I don’t know how players are supposed to figure out this puzzle,” says Tim Schafer outright at one point. Such a statement from your lead designer is never a good sign. But I won’t belabor the issue any further. Suffice to say that Grim Fandango is doomed to remain a promising might-have-been rather than a classic in my book. As a story and a world, it’s kind of amazing. It’s just a shame that the gameplay part of this game isn’t equally inspired. Did you enjoy this article? If so, please think about pitching in to help me make many more like it. You can pledge any amount you like. Sources: The book Grim Fandango: Prima’s Official Strategy Guide by Jo Ashburn. Retro Gamer 31 and 92; Computer Gaming World of November 1997, May 1998, and February 1999; Ultimate PC of August 1998. Plus the commentary track from the 2015 Grim Fandango remaster. Online sources include The International House of Mojo’s pages on the game, the self-explanatory Grim Fandango Network, Gamespot’s vintage review of the game, and Daniel Albu’s YouTube conversation with Bret Mogilefsky. And a special thank-you to reader Matt Campbell, who shared with me the audio of a talk that Bret Mogilefsky gave at the 2005 Lua Workshop, during which he explained how he used that language in GrimE. Where to Get It: A modestly remastered version of Grim Fandango is available for digital purchase at GOG.com. Footnotes Footnotes ↑1 A mouse was available as an accessory for the PlayStation, but it was never very popular. ↑2 Escape from Monkey Island, the only other game ever made using GrimE, was ported to the more capable PlayStation 2 in 2001. previous post This Week on The Analog Antiquarian 29 responses Matt Campbell November 8, 2024 Thanks for an honest review. As I think I said when I gave you the audio of the talk, I have no particular love for Grim Fandango; I’ve never even played it. For me it was just an interesting case study in the use of Lua. So I appreciated learning more about the game itself. Reply David R November 8, 2024 After trying two or three times to make progress past the first act in Grim Fandango, I feel vindicated by this review which reflects my experience with the game. At the times that I played it, I just felt inadequate as an Adventure Game Player: how could I possibly make so little progress in a game that so many remember so fondly? If I ever return to it I will do so in full “tourist” mode with hints at the ready. Is there a term for games that are better experienced by watching a “Let’s Play” on Youtube than by actually playing them? There should be. Reply Jimmy Maher November 8, 2024 I believe the term is “movie.” ;) Reply Feldspar November 9, 2024 Much like with The Last Express, I played this in the era of its release but found it to be impenetrable and bounced off it. For both games, many years later I watched them in Youtube “cutscene compilation” form and enjoyed them greatly in that form. I think that’s true for a lot of games where the story and atmosphere are great but the execution can make them frustrating to play. (Though in general I’ve never been a fan of the absurdist LucasArts style of adventure game puzzles, even though on the contrary I love Myst-style games). On an unrelated note: “If, for example, Manny was to drink a glass of whiskey, the pre-rendered version of the glass that was part of the background set had to be artfully swapped with its real-time-rendered incarnation as soon as Manny began to interact with it. Getting such actions to look seamless absorbed vastly more time and energy than anyone had expected it to.” Surprised they didn’t hit on the basic solution that most similar games (like Final Fantasy VII) often used, which is to make a handful of interactable objects like that be always rendered in real-time instead of as part of the pre-rendered background. It makes them stand out a little from the background but you don’t have to worry about the visual transition between the object’s static and moving state. Reply Jimmy Maher November 9, 2024 I think the issue was that Tim Schafer and presumably others were *extremely* picky about the visual aesthetics. Rightly or wrongly, this wasn’t a compromise they were willing to make. Reply Andrew McCarthy November 9, 2024 The “Final Fantasy VII solution” with having some interactable objects always being rendered in 3D is exactly what Grim Fandango does in a lot of cases, though. Reply Jimmy Maher November 9, 2024 I can only assume that the tradeoff was judged acceptable in some cases and not in others. Reply mycophobia November 8, 2024 Resident Evil represents a much more graceful rendition of the “point and click adventure but with direct character manipulation” concept I think. The puzzles are of the trivial “find these keys and bring them to this point to open the door” variety but the running from and shooting zombies and occasional boss fights fill the rest out nicely. I think as time went on relying on pure puzzle solving to keep players in the game’s world for a money’s worthiness length of time became less and less tenable and reached a kind of breaking point by the era of Metal Gear Solid, any given big budget JRPG, or the aforementioned Resident Evil, which gave players a full cinematic world with way more interesting stuff to do than combine items with other items in various degrees arbitrary. If you cling too doggedly to the old style of adventure game you end up with games like this that are aesthetically staggering but also you have to occasionally try to put every item in your inventory into the Thing to make the story move on, creating an incredible “why is the protagonist having to do this” dissonance that wasn’t as prominent in games with far simpler worlds. The space left behind by the eschewing of constant puzzle solving doesn’t necessarily have to be filled with combat, but it should definitely be filled with something better. Reply Preroq November 8, 2024 Thank you for another great article. I remember playing the game back in the day and remember being frustrated with the interface and one puzzle that kept me frustrated for days. The story, in my mind, did take the prize, so I remember the game quite fondly. I did notice one typo: “lose” should be “loose”? Reply Jimmy Maher November 8, 2024 Thanks! Reply Penguin in a hat November 8, 2024 Great article. I played Grim Fandango immediately after I played the Longest Journey. I remember loving the concept and the ambition, but the puzzles were so frustrating compared to Funcom’s masterpiece I gave up. Such a shame. Reply Andrew McCarthy November 9, 2024 “But the controls are mapped to Manny’s point of view rather than your own, so that he is constantly charging off in the wrong direction every time the camera does one of these shifts.” This is not entirely correct. The default control scheme is “character-relative controls”, in which pressing Up causes Manny to walk forward in whatever direction he’s facing, regardless of the camera angle, and Left and Right make him turn to his left or right (with Down for walking backwards). This style is the one known as “tank controls”, and was intended to let Manny run seamlessly forward even as the camera angles changed. However, the manual also mentions that you can switch to “camera-relative controls”, in which pressing Up causes Manny to run towards the top of the current game background, while Left, Right, and Down cause him to run in those respective directions on screen. This means you have to adjust which direction keys you’re pressing every time the camera angle changes. It does seem to be more intuitive for a lot of players, though: IIRC Escape from Monkey Island had this scheme as the default, though it still had the option for tank controls on PC (but not the PS2 port). Regardless, the control scheme is still balky and needlessly convoluted, and really would have been better with a mouse control system that could easily have been implemented at the time. Reply Sniffnoy November 9, 2024 This is tangential, but — the term “tank controls” is pretty standard in video game talk for this sort of control scheme (not just some specific LucasArts terminology), but I’ve never been clear on where it comes from. It’s not how an actual tank controls — those, as I understand it, are controlled in the manner more like you see in the Katamari games (and also in various tank simulators, presumably, but I’m less familiar with those), with two sticks for separately controlling the two tracks. So why does “tank controls” mean this style of control? I don’t have any answer to this question, and would be interested if somebody knows. My speculation is that perhaps it comes from the “Tank” subgame in Atari’s Combat, which, IINM, uses this style of controls. Note it can’t come from Atari’s earlier arcade game Tank, which does not use this control style, but rather uses the two-track style of controls mentioned above that actual tanks use. (I assume the change to “tank controls” was made for Combat due to the Atari VCS controller only having one stick?) But yeah that’s my speculation, I’d be interested to hear if someone has a more definitive answer. Reply Hresna November 9, 2024 I would posit the nomenclature “tank controls” likely has more to do with how the movements end up looking, than the actual control scheme. While an experienced tank driver (whether in a real tank or simulator) can surely drive the tank in a smooth controlled arc to make turns by adjusting the relative speeds of the two tracks, an inexperienced one is likely to spend most of their time doing either “going forward” or “turning on a the spot”, which is how this game ends up being played. It’s the sort of motion you might often do controlling a dual-track toy to get it around obstacles as well. It’s not something you have to do with a tank, but you certainly can and often see it done, in a way that seems unnatural for a human to move. Reply arcanetrivia November 9, 2024 I thought “tank controls” were named after tank simulator games like Tank and Battlezone. (Which themselves I suppose are quite simplifying the controls of an actual tank.) Reply arcanetrivia November 10, 2024 Never mind; I see this was addressed elsewhere in the comments. Reply Jimmy Maher November 9, 2024 Thanks for sorting me out. I had it in my head that the option to change to camera-relative controls was added in the remaster. Reply Frans November 9, 2024 I recall Schafer saying they changed it in the remaster so that you kept your direction as the scene changed. Reply 7iebx November 9, 2024 I loved Grim Fandango when I played it 25 or so years ago. There’s a quote attributed to Maya Angelou (perhaps erroneously), which has become something of a meme-friendly modern chestnut: “People won’t remember what you said, and people won’t remember what you did, but people will never forget how you made them feel.” This applies to media every bit as much as to people. Possibly even more so to games, being akin to experiences. I remember little of what Grim Fandango was about, and I have no memory of what I did in it. The characters are like old names in my contacts, unplaceable. Those inscrutable puzzles that filled the cheap hours of my youth have long been forgotten. But I will never forget how Grim Fandango made me feel. Nonetheless, I am 100% certain your criticisms are fair and valid and I’m grateful for your sober and nuanced take. Nostalgia be like that sometimes. Reply Penguin in a hat November 10, 2024 I just want to salute you for the line ‘cheap hours of my youth.’ Well put. Reply Taras November 9, 2024 I’ve bounced off of Grim Fandango two or three times now because of it’s puzzles, but the amazing premise and aesthetics keep pulling me back in. I was nodding along to all of your criticisms, but at the end all I could think was “I should give this another shot…” Reply Matthias Sohr November 9, 2024 “Schafer’s team did get the game done in time for the all-important Christmas of 1998, as they had been ordered to do in no uncertain terms” “Nonetheless, Grim Fandango was accorded a fairly rapturous reception in the gaming press when it was released in the last week of October in 1998, just in time for Halloween and the Mexican Day of the Dead which follows it on November 1.” Is Halloween already part of the Christmas season, or was it ready for Christmas ’98 in the same sense that it was also ready for Christmas ’99? It’s at least a little ambigous. Reply Jimmy Maher November 9, 2024 The two aren’t mutually exclusive. Games released in October and November were usually the big Christmas sellers; unless you were releasing a sequel that came with its own built-in marketing, you usually wanted some runway for reviews and word of mouth from early buyers to spread. But yes, perhaps those sentences do clash with one another. Thanks! Reply Vladimir Kazanov November 9, 2024 As somebody who loved point-and-click adventures to death as a pre-teen/early teen, I mostly agree with the article. In fact, this is the last P&C game I played. The style, the story – all resonated with the boy who loved Maniac Mansion, The Day of the Tentacle, Loom, The Fate of Atlantis, Full Throttle and others.But I just could not get past Act 2. This random walk of the solution space killed the genre for me. Nowadays I find it ironic how majestic storytelling is drowning in stupid… These are not even puzzles. I had to admit that Half-Life and the like were becoming better storytelling engines at times, and better games in most cases. And it seems that I wasn’t not the only one back then. So I still remember Grim Fandango fondly – as the final pinnacle of a fading genre. Reply Alexander Leitner November 9, 2024 I´m somewhat grateful to see I´m not the only one who felt lost in this game. I couldn´t even figure out the mail-sabotaging puzzle right at the beginning and had to rely on a walkthrough. Tried my best to avoid it, but at some point in the second act I realized that I´m simply not able to figure out my objectives or solve a puzzle to reach a goal on my own, so I simply gave up trying. Still I enjoyed it somehow, but it was one of the last adventure games I purchased. Now, while the remaster made the controlls much more bearable, I´m still lost without some hints. It remains the company´s black sheep for me, along with Monkey Island 4 (This one disappointed me so much that I just stopped playing at some point and never finished it to this day.) Reply Hresna November 9, 2024 For a modern game that shamelessly lifts the art style of fandango with the quirky storytelling and musical style of monkey island, hardcore point-and-click fans might want to try “Darkestville Castle”. To my recollection, the puzzles were relatively sensical with a few monkey-island-style obtuse exceptions. You will mostly feel nostalgia for those older games but you’ll be in for a fresh story and set of puzzles. I’m inclined to interpret the style and similarities as homages. Full disclosure I never completed the final act which is one of those multi-panel “quick time” “do the correct thing on this screen before the bad guy gets you” sequences. Reply Vulpes November 9, 2024 I once decided I was going to beat Grim Fandango without looking at a guide. It took me three days, and I was on vacation at the time so I could spend hours at it. And I’m actually replaying it now, and I’m still getting stuck at times. So I have to agree that while it’s a tour de force of worldbuilding, as a game Grim Fandango is a bit too cruel. Once again I’d like to strongly encourage you to play another 1998 game, The Legend of Zelda: Ocarina of Time. While it isn’t exclusively an adventure game, I think its adventure game parts more or less successfully accomplish what Grim Fandango mostly failed to do, which is create kinds of puzzles that could only be done with a three-dimensional game world. Reply Jarno November 9, 2024 That reminded me of Ron Gilbert’s Words of Wisdom to Tim Schafer from 2012. 21:00 -Ron Gilbert: So, what’s your favorite part of making an adventure game -Tim Schafer: I love brainstorming puzzles, you know, sitting in a room and just kind of thinking through both the character and the story and the puzzles at the same time. 27:25 -Tim Schafer: I calculated when we started Grim Fandango, because Full Throttle, the game before, had been criticized for being too short. Because, we won’t really be with the production and had to cut like a third of that. So, it was really short and so I sat there and I counted the number of puzzles. There are 20 puzzles in the game, real puzzles and I was like give me at least twice that. So, I was like, okay, 40 puzzles and each one has to provide like 15 minutes of entertainment. -Ron Gilbert: I think shorter is better. I really do think that a shorter experience that’s more focused it’s actually going to be a lot better than drawing something out. Reply stepped pyramids November 9, 2024 Despite LucasArts’ deserved reputation for innovation, they never really got past the idea that adventure games were about puzzles. And it’s a shame. Ironically, it’s their stodgy predecessors at Sierra who were more pioneering in finding alternatives to that, with varying degrees of success (Quest for Glory, The Colonel’s Bequest). In particular, I think Grim Fandango would have aesthetically and thematically been a great fit for a more exploratory/investigative structure similar to The Colonel’s Bequest, and the engine could have made finding secret scenes genuinely rewarding. (I don’t know that this would have helped much in terms of sales, of course.) Reply Leave a Reply Your email address will not be published. Required fields are marked * Comment * Name * Email * Website This site uses Akismet to reduce spam. Learn how your comment data is processed. If you value this blog, please think about supporting it by becoming a Patreon patron or via a one-time PayPal donation. Thanks! Back to top",
    "commentLink": "https://news.ycombinator.com/item?id=42097261",
    "commentBody": "Grim Fandango (filfre.net)285 points by cybersoyuz 20 hours agohidepastfavorite98 comments vvpan 13 hours agoWell I certainly cannot relate to the criticism. I played the game early on as a teen (and every few years since) and while, at times difficult, I never thought the puzzles were \"confusing\", it seemed like a pretty organic combination of styles of puzzles built into the game. The head turning dynamics I have also found to be quiet pleasant as it made me relate to the character more. Not that criticism is bad but Grim Fandango seems to one of the most if not most loved adventure games (just visit and adventure game forum or subreddit). So one can take it apart and think about the individual parts but the whole is certainly a masterpiece of a game. reply sersi 4 hours agoparentAs much as I love Jimmy Maher's articles, he has a certain bias against any adventure game that's not streamlined. So, he levels similar criticisms against pretty much every Sierra games, Full Throttle and pretty much any adventure game that is not polished to the level of Monkey Island and Day of the Tentacle. He's not completely wrong and the tendency of adventure games to sometimes veer into puzzles that are more moon logic based did I think contribute to the fall of the genre but I do think that he overemphasizes those faults and has a tendency to describe puzzles that are merely hard as impossible to figure out. Also, I disagree with his criticism of the interface, as a kid it definitely didn't bother me, if anything I find it less frustrating than the amount of pixel hunt in some adventure games. reply jonathanlydall 1 hour agorootparentReminds me of him reviewing Star Control II, which he also seemed to overly criticise, he did however make a legitimate point that the game mechanic of Kohr-Ah only slowly annihilating the galaxy meant that you may have actually already reached a point where winning becomes impossible, but you may not realise it until quite a long time later. Although I generally remember 90s games being somewhat brutally unforgiving, the lesson they would teach most thoroughly is to save often. reply cainxinth 6 hours agoparentprevThere was one particular puzzle involving an elevator that stumped me as a kid. I played the remaster years later and still couldn’t figure it out so I looked up the answer. Cheating in multiplayer games is obviously indefensible, but I’ve never been above cheating in a single player game. Games are a relaxing outlet for me and if I get frustrated long enough I’ll look up the solution. That said, I will have one of two reactions upon spoiling a puzzle. I’ll either realize that the answer was right in front of me and I’ll be disappointed I didn’t spend a little more time on it, or I’ll realize I would never have figured it out and be glad I went for help. The elevator solution was an example of the latter. reply acomjean 4 hours agorootparentWhenever I think of adventure games, it the being stuck aspect of it. When these were released the lack internet help made it frustrating. Old man Murray (site is still up, though over 20 year since an update) had a good post about adventure game puzzles. Page 2 and 3 sum up the frustration. https://www.oldmanmurray.com/features/78.html Adventure games have gotten better.. reply dbalatero 4 hours agorootparentprevThe elevator forklift is one of the puzzles that messed me up too! I think it was the interface and really tight timing that made it tough. reply Rastonbury 13 hours agoparentprevI remember watching my teenage cousin play it as a young child and being really drawn in, then when he let me play I remember getting frustrated because I had no idea what to do, it ended up being more fun watching him play reply keybored 8 hours agorootparentMy only experience with the game is watching a YouTube playthrough. Great game from that vantage point. reply forgotacc240419 6 hours agoparentprevI definitely found the world a bit harder to navigate for solving puzzles than the 2D games but the really horrible puzzles in grim fandango were the time based ones that the engine could do but not remotely well. There was one in particular with a wheelbarrow that was fairly easy to figure out but an insane pain to coordinate with the game's controls on our PC reply dale_glass 20 hours agoprevI think one understated problem Grim Fandango had is that it's too adult. Today \"adult\" often means \"there's sex and/or gore\", but the content is still simple and juvenile. But Grim Fandango isn't like that, it's just full of themes that probably confused the heck out of almost every kid that tried to play it. Like the very first chapter throws you right into office politics. You deal with stealing a job from another salesman, sabotage a pneumatic tube messaging system, and sneak into your boss' office. It all makes perfect sense for adults familiar with office work and all the movies it references. But I recall I tried it when I was maybe 14 and I couldn't make head nor tails of it. I didn't even realize the pneumatic tubes were actually a thing. Things like Monkey Island and even Full Throttle are far more accessible. reply makmanalp 18 hours agoparentHere's the thing - I remember playing it as a kid and so many things, arguably most of it, went way over my head: the whole travel agent thing and getting ahead in the office, dia de los muertos, the references to noir, the weird but gorgeous mexican art deco combo, I knew nothing about any of it. But I still loved every second of it. It made the world feel very rich and real even if I didn't fully get it, in a way that other games around the time just were not. Also this is not too dissimilar to how adult life that surrounds every child is to a child. You're sort of used to living in a world that has workings beyond your comprehension and just going along with it. I didn't get what exactly was going on but I did understand /something/ was. I'm listening to a review of The Great Mouse Detective (1986) which has a similar ethos, as did other content targeting young people from that era. Also I recall picking up books as a kid that were certainly not meant for children and adults back then didn't even blink, and I think it stoked my curiosity and interests and pushed the boundaries of my understanding, as well as prepared me for growing up. I don't think I ended up being a worse person or being traumatized in any way. Part of me wonders if kids' content being much more sanitized these days is a mistake. reply rubslopes 15 hours agorootparentI also played it as a kid and vividly remember that plot about a secret political revolution feeling so cool and new to me. I had never encountered anything like it before.I remember 'Viva la revolución!' becoming a catchphrase for me and a friend at that time. The sense of sneaking into an adult world, even a fantasy one, might be what made the game feel so special to me. reply makmanalp 14 hours agorootparent> The sense of sneaking into an adult world, even a fantasy one, might be what made the game feel so special to me Brilliant observation that never occurred to me. Around that age being allowed to sit with and listen in on adults having normal adult conversations - being one of them - felt special. reply Gravityloss 8 hours agorootparentprevI think that was part of the fascination of PC:s as a kid. Police Quest or Civilization and so on. It was this kind of adult world that you knew little of and were exploring on your own, or with your friends. The games were not holding your hand. It often was game over. But you could try again. Also, your parents were never involved in any way (except financing the thing). The audience of PC games was different than console games. They expected more from the player. Sometimes it was frustrating, but often times I think one learned something. Also one had to use the dictionary sometimes. There were also less other things competing for their attention so kids had more persistence... reply throaway915 1 hour agorootparentThis is bang on. Having a pc back in the day was like having a problem solving simulator for me. reply sersi 4 hours agorootparentprev> I'm listening to a review of The Great Mouse Detective (1986) which has a similar ethos, as did other content targeting young people from that era. You bring up a great point, I do feel sometimes that children media in the 80s didn't completely try to dumb down complexities of adult life even when targeting children. While there are exceptions, it does feel less true nowadays when looking at modern media. The problem I feel is that at the same time as we sanitize children' content more than we used too, children have more access to unfiltered content through often poorly secured devices. As for Grim Fandango, I played it around 15 and while, yes there were elements that flew above my head. I still remember it as an amazing experience and my first introduction to the film noir genre (shortly after that was reinforced by playing Under a Killing Moon given to me by a friend of mine) reply throaway915 1 hour agorootparentprevYes, we do a grave disservice to all children when we assume they can't handle reality. reply kylebenzle 14 hours agorootparentprevYou are correct! The user above you has a strange opinion about what media kids should consume. reply porbelm 6 hours agorootparentprevSame experience here. I loved The Great Mouse Detective, at age 8. Not much later I read The Dark Knight in a translated trade paperback, and it really tickled my little mind. There was a trend of having comic adaptations of movies back then, so I also read and loved the License to Kill comic and was disappointed when Terminator 2 omitted some scenes in the movie -- until the Director's Cut came out. I was certainly not traumatized (apart from the week of nightmares after seeing Alien one night on TV at age 12). Because of this, I had no arguments when I learned my 11 and 13 year old kids' mom and their stepdad had secured tickets for us to go see Deadpool & Wolverine when I was visiting last time. Kids understand more than one may think, depending on how much \"real life\" they assimilate through culture (and parental guidance), I believe. reply GuB-42 13 hours agoparentprev> Today \"adult\" often means \"there's sex and/or gore\", but the content is still simple and juvenile. That's indeed an unfortunate fact. In fact, most \"adult\" stuff is actually for teens or young adults. Teens love sex and gore, they want to be edgy, they want to prove they are not children anymore. Actual adults, the kind with jobs and families, are usually passed that. They may still enjoy their sex and gore, but it is just one theme like another. I think a good way to make a difference between \"teen adult\" and \"actual adult\" is to look at the age and environment of the protagonists. Is the main character a teenager or young adult? Does it involve a school of some kind? Then it is probably for teens. Is the main character middle aged? Does it involve work, especially office work? Are there parents among the protagonists? Then it is probably for adults. Sex and violence are secondary. reply mdp2021 9 hours agorootparentLook, that is also a twisted perspective. \"Adult\" = \"involving maturity\". It is not the topic, it is how it is processed - with developed vs juvenile abilities. And \"adult\" is not a janus word, representing both the mature trait and its lack thereof: the second is just given by severe misunderstandings of maturity because of deficiency or twisted incentive. The same works for other words, such as \"art\". reply wenc 19 hours agoparentprevThat's a really interesting perspective. I grew up around when adventure games were popular, and I learned a lot about the grown-up world (and in fact, American world) through adventure games. Sam and Max had so much Americana that, playing as a non-American, got me into the deep cuts of American culture. I think a lot of it was contextual. I didn't get all the references at first (e.g. who's John Muir for instance), but the context made it possible for me to figure it out. reply nanna 18 hours agorootparentI got completely stuck in the Beavis and Butthead adventure game when one of the voice acted characters told me to get a \"vee-hickul\". As a teenager sitting at my family PC in London, I had no idea what the hell the Texan (?) was saying. Only several years later would I figure it out. The only other thing I remember from that game is the hock-a-loogie minigame, which I mastered. I wonder if my parents had any idea what I was up to on the computer? reply SamBam 13 hours agorootparentReading your comment I had no memory of ever playing that game, until I remembered mastering the hock-a-loogie minigame. Thanks (I guess?) for the memory! reply dgfitz 17 hours agorootparentprevAnecdote: the word ‘vehicle’ is referenced aty day job a lot. I had a PM who always, always said ‘vee-hickle’ and I honestly always thought he was full of shit. On day when he was really mad about $(thing I predicted) he just comes out and says ‘vehicle’ like it’s spelled. I don’t remember feeling smug or annoyed, mostly just kind of bummed at the farce. reply kaashif 13 hours agorootparent> he just comes out and says ‘vehicle’ like it’s spelled What do you mean by this? In what what is \"ve hicle\" not pronouncing it as it's spelled but \"ve icle\" is? Isn't the one including an h more faithful? reply praptak 10 hours agorootparentI'm a non-native speaker I remember I couldn't figure out how to pronounce \"vehicle\" just from how it's spelled. It's not like I pronounced it wrong (as is often the case with other words), I just couldn't figure out how to pronounce it at all until I looked it up. Edit: I guess my point is that \"as it's spelled\" may be non obvious in case of vehicle. reply kaashif 2 hours agorootparentThat's partially my point too: pronouncing something \"as it's spelled\" is meaningless in English - most of the time there's more than one \"obvious\" pronunciation. And the right one could be a less obvious one. reply moomin 1 hour agorootparentI insist on calling Roblox “rob-l-ox” when talking to my kids. It’s a dumb joke, but it also emphasises to them that spelling is a guide and not always a useful one. reply fknorangesite 1 hour agorootparentprev> the right one One of the many right ones. reply fknorangesite 1 hour agorootparentprevAre you aware that both pronunciations are correct? 'Cause boy are you going to be surprised when you find out about \"accents\". reply porbelm 6 hours agorootparentprevI learned \"vee-hickle\" from the TV show M.A.S.H reply mrob 7 hours agorootparentprevDay of the Tentacle is also very American, in both style and content. I'm glad I didn't play it as a child because I wouldn't have understood or appreciated it, even though I knew it existed and I played Maniac Mansion. Day of the Tentacle was completely different than what I imagined and much better. reply kevml 19 hours agoparentprevThis is a great assessment that I never realized until you said it. There are so many games from that era that I played that fit that mold. I was playing Leisure Suit Larry as a 10 year old! I can’t imagine parents these days letting their kids play that at all! reply viraptor 18 hours agorootparentMy parents couldn't understand enough English to really get why I shouldn't be playing Larry (almost all the screens are just fine) and I was too young to understand the actual theme. Perfect combination... Kind of like Police Quest 1 too. Although it did teach me to type \"use handcuffs\" fast enough. Also the spelling of \"briefcase\" and other longer words. reply hibikir 16 hours agorootparentPolice quest was just way too tough for the foreigner unused to American procedures. \"Administer sobriety test\" is not the easiest of commands without a very broad vocabulary. reply wenc 14 hours agorootparentI don't know. My friends and I growing up in Asia played Police Quest I as 8 year olds. We learned about the Miranda rights, and the PR-24 nightstick. I remember the sobriety test part. We didn't know what a \"field sobriety test\" was exactly, but we knew it was something to do with drunk drivers. Somehow we managed to finish the game. I think most people can pick up a lot of clues from context alone. reply viraptor 13 hours agorootparentYou finished it as an 8yo? Congrats! It's a serious achievement. reply kylebenzle 14 hours agorootparentprevIn many cases lazy \"single mothers\" let kids use TicTok and SnapChat in lieu of a baby sitter or actually spending time with their own children these days. The things my kids have seen and knew before 6 years old was 1,000 times worse than anything in Leisure Suit Larry. Our daughter was repeating racial and sexual slurs she learned in the cheap \"after-school\" shes forced to attend. American parents or society doesn't care about their kids at all in general (did we ever?) and growing up in this broken society is far more mentally damaging for kids than 20-30 years ago. reply soulofmischief 3 hours agorootparentWhy is \"single mothers\" in quotes? I'm also confused because you generalize against single mothers for being lazy but then describe how your own parenting style is failing to meet your child's needs. reply LaundroMat 13 hours agorootparentprev\"Lazy single moms\". Nice. reply nanna 18 hours agoparentprevI'm about the same age but personally I had the opposite experience. For me it was refreshing to play something more mature, more 'intellectual', even if I'm sure a lot of the jokes washed over me. reply thefaux 19 hours agoparentprevI agree about the accessibility, but Full Throttle is by far my least favorite lucasarts graphical adventure. It's really quite depressing and I deeply dislike the main character. reply ajkjk 16 hours agoparentprevAgree that it adult stuff in it but loved that as a kid. I always hated 'kid' content, it felt fake. reply jamal-kumar 19 hours agoparentprevI thought this game was up there in my favorites as a kid, don't think me or my younger sibling noticed personally, but the puzzles were really hard for sure. Either way we beat it between each other taking turns I remember. Oh yeah, the tank controls were a little less shit with a gamepad - back when there was a dedicated port for those no less I also remember these games easier to beat before the internet was so pervasive and these kinds of things were the best way to pass rainy days, we'd draw out notes and maps on paper and all sorts of stuff to beat them - different times now, people's attention is way more scattered reply paulryanrogers 19 hours agorootparentWe also had fewer games available. I did play a lot of demos and shareware though, thanks to disks from gaming magazines, including GF. reply libraryofbabel 15 hours agoparentprevAnd most of all, the classic movie Casablanca. I played Grim Fandango as a 15 year old kid and I when I eventually saw Casablanca many years later it was like, this feels familiar, why… oh wait! That said, like others here as a kid I loved the adult culture references even when I didn’t fully get all of them. reply cholantesh 19 hours agoparentprevThe tank controls also put me off of it for years. reply ufo 16 hours agoprevThe article talks about how Lua \"has gone on to become a staple language of modern game development\", but could have given more credit to Grim Fandango for that. It was the first game to use Lua and and its success was what put the language on the map when it comes to gamedev. reply zoky 7 hours agoparentIts weirdness in indexing arrays notwithstanding, Lua is zero of the most important programming languages ever designed. reply djur 19 hours agoprevJimmy is right about Grim Fandango's gameplay failings, and it's unfortunate, because the game has enough narrative content that they could have just trimmed away a lot of the adventure game puzzles. But visual novels weren't really a thing in the west yet, and in that era there was a lot of emphasis on playtime as a metric that reviews would focus on. Ironically, one of the most forward-looking approaches to extending playtime without relying on obtuse puzzles had been already pioneered (in a flawed way, certainly) by Sierra, the company which often served as the contrast to LucasArts' reputation for innovation. I'm talking about The Colonel's Bequest, which elaborated the classic adventure game score system into a kind of scavenger hunt, a precursor to achievements in today's games. Grim Fandango would both aesthetically and thematically have been a great fit for that kind of \"find the secret scenes\" style of replayability. reply selimthegrim 17 hours agoparentSadly, a bug made the perfect score unreachable without hacking in The Colonel’s Bequest. The 1993 rerelease fixed it I think (I believe the fireflies the Wikipedia article mentions were a symptom.) reply frmersdog 2 hours agoprevAlways worth mentioning: if you're a fan of Grim, The Journey Down is a game that borrows a LOT from it, while taking advantage of the advances made in the interim. reply appel 18 hours agoprevExcellent article and absolutely fair points by the author. As a kid I completely fell in love with the characters and ambiance, but got hopelessly stuck in Act 1. In fact, I don't think I ever made it out. But man, what a great story and what a beautiful style. I always half expected to see Hollywood pick this up and turn it into a movie. Just imagine what the folks at Pixar could do with this (with Tim Schafer as executive producer, of course). reply pavlov 8 hours agoparentIt’s much too eccentric for the Pixar formula. They are family movies first and foremost. Characters need to be understandable and relatable to an eight-year-old. The Pixar movie with similar themes is 2016’s “Coco”. It’s a fine production, but the themes are much less adult than in Grim Fandango. reply michelb 7 hours agoprevThe music in this game is just fantastic. I regularly play the soundtrack, brings back warm and cozy memories for me. reply mannycalavera42 5 hours agoparentthat's what drew me in reply wk_end 18 hours agoprevThis review is pretty dead (hah) on. I’d been trying to crack Grim, off-and-on, basically ever since it came out; each time I was foiled by the clumsy interface and inscrutable game design. It’s not as player hostile as the old Sierra adventures but it sure comes close. Finally I caved and watched a longplay on YT, and I have no real regrets. Great game, but that’s probably the best way to play it. Life’s too short. reply sorenjan 19 hours agoprevI agree with a lot of what he writes, but it's still one of my favorite games. I have faded memories about how frustrated I was running around trying to understand what I was supposed to do next, and strong memories about how the game and its world made me feel. reply leshokunin 19 hours agoprevAn excellent game for its time. The remaster is well worth it. One unfortunate aspect of classic games is how dated mechanics can get. It’s a problem that music or movies don’t really have, besides maybe feeling a bit cliché. In the case of Grim Fandango, the tank controls are a bit awkward, some puzzles are actually quite difficult and require logic that would only make sense to a point and click adventure gamer from the 90s. It deserves to be enjoyed and remembered, just because of its sheer style and creativity. reply vundercind 12 hours agoparent> One unfortunate aspect of classic games is how dated mechanics can get. It’s a problem that music or movies don’t really have, besides maybe feeling a bit cliché. Silent film would like a word. Er, uh… an intertitle. Lots of modern viewers find films made before digital editing weird, or even near-unwatchable. The editing isn’t quick enough, shot pacing feels too slow. Acting styles have changed over the years. It can take some work to be able to enjoy film acting from decades ago. Older special effects are an acquired taste. I’m thinking of things like pirate movies where the ships are very-obviously models in a tub of water, easy to tell no matter how good the models because the water itself looks “small” in motion. On the music side, older music will be mono. Tons of old blues legends exist only in scratchy, terrible recordings. Older music sounds different than more recent stuff and could not have sounded like the modern kind, because they could only mix so many tracks without ruining the sound, since each down-mix meant a re-recording and a loss of quality. Newer tracks will almost always use visually-aided editing that includes adjusting vocals by eye rather than ear, which changes the way things sound a lot. reply crooked-v 18 hours agoparentprevThose point-and-click puzzles never felt like anything but time fillers to me. It's interesting to think about the \"could have beens\" of Western visual novels instead, or at least Telltale-style story games. reply leshokunin 17 hours agorootparentThat’s sad to read. I encourage you to explore games like Sanitarium, I Have No Mouth and I Must Scream, Indiana Jones and the Fate of Atlantis. I think they have a lot to offer story wise. And very little in terms of being blocked by mechanics. reply zerocrates 17 hours agorootparentprevIt's interesting how much this is still the case. I was just thinking about it myself when considering the new remake of Silent Hill 2. It's mostly beloved for its story and it spends a lot of time on that, and there's of course a lot of survival-horror combat in between. But beyond that there's another horror game (and just game) staple: lots of puzzles. The SH2 remake aimed to be very faithful so was always going to have a bunch of puzzles (Silent Hill games typically have had a separate difficulty setting just for the \"riddles\"). But it's one of those things that you still almost have to have, particularly as a horror for some reason. Silent Hill 2 is actually a case where even the \"obligatory\" elements operate pretty well in service of its themes, but plenty of the time games have these things just to have them. reply I_AM_A_SMURF 12 hours agorootparentHeh. Resident Evil 1 feels like a (well designed) escape room. reply katangafor 14 hours agoparentprevYeah it's one of those games that fits the \"thinking about grim fandango vs playing grim fandango\" memes. The characters, the writing, and the story are all so incredibly good. I love that game and I actually think about it a lot lol. But those \"puzzles\" are just inscrutable. reply cousin_it 16 hours agoprev> Taken as a game rather than the movie it often seems more interested in being It's interesting how movies today seem to be the \"top\" art form: there are books, comics, videogames that want to be movies, but never in the other direction. (There are books and games based on movies, but they are clearly secondary.) I wonder if there could be some other art form that would be \"above\" movies in this sense. reply moomin 5 hours agoparentIt’s funny, because movies still have the prestige television and games do not, despite both of them outstripping cinema in many ways. Movies have become increasingly global common denominator, with razor edge finances, and have ceded so much ground to TV it’s ridiculous. An example of this: watch Kramer vs Kramer. It’s a great movie, with a big name cast telling an emotional story. Try to think of a more recent movie like it. reply worthless-trash 16 hours agoparentprevBy top i assume you mean most profitable, I guess that movies are simply more accessible and cater to the lowest common denomination. reply ucla_rob 14 hours agoparentprevvideo games revenues are usually 5x those of video games. call movies 40bb per annum mobile games alone are ~100bb. Finish Him. reply dahart 2 hours agorootparentThis is pretty misleading and 5x is totally wrong. You’re quoting the approximate box office number for film, but leaving out home entertainment (streaming & DVDs) and merchandising entirely, while at the same time including those categories on the games side. Film industry revenues as a whole when including streaming exceed $100B per year, and approximately matched the games industry, at least as of 5 years ago. See Wikipedia’s entries on film & game industries [1][2] — in 2018, film was $136B, while games was $135B. It’s only very very recently that total games revenue exceeded total film revenue. Making this much harder to reconcile is that total film revenues are generally not public information and they are notoriously misrepresented and downplayed, maybe to help reduce taxes, royalties, and bonuses, or maybe just for competitive reasons, but either way film numbers are unreliable and underestimated. [1] https://en.wikipedia.org/wiki/Film_industry [2] https://en.wikipedia.org/wiki/Video_game_industry reply iamacyborg 10 hours agorootparentprevI doubt many people consider Candy Crush to be a good example of an art form. It’s just an app designed to manipulate human psychology to extract maximal profit. reply kaoD 10 hours agorootparentprevIsn't most of that revenue from F2P user hostile mobile games? That'd be like counting TikTok as part of the movie revenue. reply kweks 19 hours agoprevİncredible game, matched with an equally amazing soundtrack ! reply Dansvidania 10 hours agoprevI still mumble the main theme to myself from time to time.. reply Tarq0n 7 hours agoparentThe mariachi band on the first outside scene is unforgettable to me: https://tidal.com/track/101427831?u . reply Dansvidania 1 hour agorootparentYes! I thought that was the main theme. reply oever 18 hours agoprevYes, I can hear you, Grim Fandango. reply DrOctagon 12 hours agoparentNicely done reply Oarch 19 hours agoprevHas to be one of the funniest and most creative games I've ever come across. The humour was dark and the world building was so nuanced and poetic. reply mwidell 8 hours agoprevOne of my top 3 favorite games of all time. When it comes to story and characters, I cannot think of any better game. Recently finished it for the third time on Nintendo Switch. reply ch1kkenm4ss4 9 hours agoprevAh, the monthly filfre.net karma scalping story post :) reply wileydragonfly 16 hours agoprevVery interesting article, I feel like some of the criticisms also apply to Broken Age. I was well into that game before I realized (ok, looked up) that a puzzle needed you to toggle characters. This functionality was never mentioned prior to that. Some of it just felt so janky, but interesting art and story. reply InvOfSmallC 11 hours agoprevI just love this game. reply jcul 11 hours agoparentYes, same. I had forgotten all about it. Such nostalgia at seeing the cover. reply pornel 19 hours agoprevThe pre-rendered backgrounds were breathtaking in the 90s, but today the old off-line ray tracing looks worse than what modern games can render (same goes for the original Myst). The remastered version has been released before AI upscaling got interesting. I wonder if a re-remastered version could be made look better. reply jrmg 15 hours agoparentYou’re in luck! https://hexagon.codes/grimhd reply thatguymike 19 hours agoprevI played through GF with GameFAQs open next to it, and had an incredible time for it. All the frustration stripped away and left with just the story, soundtrack, dialogue, and appreciation for the fun creative puzzle designs without bashing my head against them. I felt guilty for doing it that way; it's nice to know it wasn't my fault for being too dumb! reply citizenkeen 18 hours agoprevRun, you pigeons, it’s Robert Frost! reply AdmiralAsshat 18 hours agoprevEven with a guide, I still had no idea what the hell I was doing with that train puzzle. reply blackeyeblitzar 19 hours agoprevWhat a time that was for gaming. Everything felt special. I am afraid to revisit these old greats though, in case seeing them today ruins the illusion of the past. reply glottisglottis 19 hours agoprevGlottis barfing and the beat poetry simulator had me rolling on the floor laughing my ass off. reply sorenjan 19 hours agoprevWhat a year for games 1998 was. Grim Fandango, Zelda: Ocarina of Time, Half-Life, Gran Turismo, Metal Gear Solid, Starcraft. reply toyg 9 hours agoparentSo many factors contributed to big investment in the mid-90s. Windows had exploded, followed by the Playstation a few years later; 3D became relatively easy to use in all games; the US economy was doing well; the internet was full of promise. It would all come crashing down only a few years later, but it was a massive wave. reply fullstop 5 hours agoparentprevStar Wars: Rogue Squadron was also a technical marvel at the time. reply CobrastanJorji 10 hours agoparentprevXenogears, Spyro the Dragon, Banjo-Kazooie, Goldeneye, Resident Evil 2... reply idk1 18 hours agoparentprevDon't forget Gex: Enter the Geko! reply rscho 20 hours agoprev [–] Without a doubt, one of the greatest games of all times! reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Grim Fandango,\" developed by Tim Schafer at LucasArts and released in 1998, is notable for its unique combination of Mexican folklore and film noir aesthetics, along with its engaging story and characters.- The game faced criticism for its complex puzzles and awkward controls, which affected the overall gameplay experience, despite being developed with the new 3D engine, GrimE.- Although the 2015 remastered version addressed some gameplay issues, the original's flaws highlight the challenges faced by adventure games during their decline in popularity."
    ],
    "commentSummary": [
      "Grim Fandango is celebrated as a beloved adventure game, noted for its unique style, story, and characters, despite some criticisms regarding challenging puzzles and interface.",
      "The game is praised for its mature themes and rich world, which resonated with players, even from a young age, contributing to its lasting impact and nostalgia.",
      "The music and art style of Grim Fandango receive high praise, enhancing the overall experience and narrative cherished by fans."
    ],
    "points": 285,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1731190643
  },
  {
    "id": 42096717,
    "title": "NYC Subway Station Layouts",
    "originLink": "http://www.projectsubwaynyc.com/gallery",
    "originBody": "Home About Drawings 42nd Street Mega Station Complex Connections Complexes X-Ray Area Maps x-ray station clusters Station Layouts Ground Zero PATH PATH Transfer Photos 3D Models Blog Shop services Contact / tip Menu Project Subway NYC Home About Drawings 42nd Street Mega Station Complex Connections Complexes X-Ray Area Maps x-ray station clusters Station Layouts Ground Zero PATH PATH Transfer Photos 3D Models Blog Shop services Contact / tip Manhattan View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize BROOKLYN View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize View fullsize Inspired and want to support this project? Consider tipping me on the Contact/Tip page! Powered by Squarespace",
    "commentLink": "https://news.ycombinator.com/item?id=42096717",
    "commentBody": "NYC Subway Station Layouts (projectsubwaynyc.com)276 points by gregsadetsky 22 hours agohidepastfavorite92 comments azaslavsky 20 hours agoFor those interested in these for other subways around the world, http://stations.albertguillaumes.cat/ has done a lovely job rendering them. It's impressive how many systems are covered. reply Anduia 9 hours agoparentThe drawings are nice, but like other SPAs, it is useless as a resource because it does not use bookmarkable URLs reply xenic 9 hours agorootparentThis isn’t something inherent to SPAs, though sadly many (most?) do omit the history api and don’t provide usable URLs nor back/forward navigation. reply pimlottc 2 hours agorootparentIt's somewhat inherent, as the URL will not change by default and it generally takes an intentional to implement sharable URLs. reply throw10920 1 hour agorootparent\"Somewhat inherent\" isn't meaningful or correct. The fact is that there is a history API and you can use it to implement history for SPAs. Therefore, lack of history is not inherent to SPAs by definition. Intentionality has nothing to do with it. reply gennarro 7 hours agorootparentprevAnd I can’t zoom on my phone?? reply n2d4 6 hours agorootparentSeems to work for parent's link on my iPhone (but not OP's link) reply globular-toast 8 hours agorootparentprevI find it bizarre how such a site ended up an SPA. Nothing about it suggests SPA. This could just be a website and would be supported by any web browser, but instead they've implemented a crap custom browser and web in JavaScript. reply n2d4 6 hours agorootparentThe map kind of does. It's really nice to just click on different dots and see different cities with no latency or page load. I think the right way to implement this is as an SPA with `history.push` for shareable URLs. reply globular-toast 2 hours agorootparentThat could easily be done with htmx. No need for an SPA. reply veunes 4 hours agoparentprevThe quality of the renderings is impressive reply punnerud 9 hours agoprevPlease don’t hijack my possibility to zoom in pictures on mobile (iOS) reply ryanianian 16 minutes agoparentEven zooming on desktop (firefox on macos) is broken. I want to zoom in to see the street names and investigate the images, but the site makes it impossible. I can download the images to my desktop, but they are low resolution. What a cool project to be soured by such awful technology that didn't need to exist in the first place. reply Hnrobert42 8 hours agoparentprevCame here to say this. What reason could there be for limiting this behavior? I had to screenshot to zoom. (facepalm) reply dr_pardee 4 hours agorootparentHold on the image, “Open in New Tab”, zoom in reply aardvark179 1 hour agorootparentDoesn’t work on iOS, I think they have overridden that user action - which makes this site pretty much useless for any of the to Es I might ever actually want to use it. reply ryukoposting 6 hours agoparentprevYeah, I can't even press and hold to open the image in a new tab (Android, Firefox). reply frankdenbow 21 hours agoprevThere was an app called Exit Strategy that showed you where to stand on the train to maximize your routes, depending on what transfers you were taking. reply woodruffw 18 hours agoparentThe new R211 trainsets[1] have digital displays that show this information as well -- they show the upcoming station ahead of time, along with which exit is relative to which car in the train. [1]: https://en.wikipedia.org/wiki/R211_(New_York_City_Subway_car... reply sofixa 8 hours agorootparent> they show the upcoming station On a recent week long with lots of subway use trip to NYC, it was wild to me that this sort of extremely basic information was incredibly hard to impossible to find. At best, there was a single screen, but positioned in such a way to be invisible to at least half the carriage (on the side in one of the ends); at worst there was only the driver saying stations names over an intercom system that garbled everything. Same at stations, where with a few exceptions, it seemed the only information was on track-facing screens in very limited numbers. There was vastly more space dedicated to ads, including screens with ads, than to signage. Why? Why not replace 3 of the 100 ad signs with some information about the train, or a map? Being more used to Paris and London metros, it was quite hard to navigate and took lots of effort fishing for information which should be well presented. It seems that usability is one of the last concerns of US transit planners. And NYC Subway is supposed to be one of the good ones! reply woodruffw 5 hours agorootparent> At best, there was a single screen, but positioned in such a way to be invisible to at least half the carriage (on the side in one of the ends); at worst there was only the driver saying stations names over an intercom system that garbled everything. That’s the old (but not very old) trainsets. The new ones have a digital display above every door. Be happy you weren’t on the very old ones; those don’t have displays at all, besides a paper map. The answer to this isn’t about usability, but about the fact that the NYC subway runs old trainsets and isn’t given very much money (relative to its economic impact on the city) to upgrade them. But that’s slowly changing. reply sofixa 2 hours agorootparentEven the oldest trainsets in Paris and London (as old as from the 50s) have at least a static map of the line; none in NYC out of those I was one had even that. Similarly, all stations have digital signage indicating when the next train is coming and where it's going, starting from the ~70s. My point about usability was that NYC Subway was pretty hard to use as a tourist. Station entrances had random variations of end destinations or broad directions (e.g. either the name of the lasts stops, or the location of the last stop like Coney Island, or the general direction of Uptown or Brooklyn). Understanding where express services are stopping was hard, because the one screen per station with that detail was inaccessible due to the amounts of people on waiting. And the noise.. NYC Subway needs lots of investment, but that investment needs to be spent better too.I passed through some works a few time, and the ratio of workers on their phone vs workers looking like they're working was 30:1 each time. The Grand Paris Express president talked about the mismanagement and absurd contracts MTA have, and he has said that if they had the same requirements GPE (100+ km of brand new fully automated metros) would never have been built. reply woodruffw 2 hours agorootparent> Even the oldest trainsets in Paris and London (as old as from the 50s) have at least a static map of the line; none in NYC out of those I was one had even that. You might have missed it. I absolutely guarantee you that every single car in the NYC subway has at least one system map and multiple line maps. On the older cars, the (paper) system map tends to be at the front of the car, and the (paper) line maps are generally in the middle of the car. I don't particularly disagree about destination-designated services being confusing. However, that's the norm for subway systems AFAICT; Paris's metro directions were equally confusing for me as a visitor. (You're also right about the noise although, again, I think Paris is a relative outlier among large metros in terms of low noise levels. To my understanding, this is a result of using rubber tires on some lines, continuously-welded rail on others, smaller trainsets overall, and - yes - better maintenance.) reply rangestransform 42 minutes agorootparentNYC has continuously welded rail, but it’s limited to the length of a signaling block due to track circuits reply CPLX 2 hours agorootparentprevAt least some of this is probably preserved as way we express dominance over you, the out of down visitor. reply wh0knows 2 hours agoparentprevCitymapper shows this in their transit directions. They tell you the best part of the train to get on and the best subway entrance/exit. reply BobAliceInATree 2 hours agoparentprevStill exists, and I still use it. It isn’t always 100% up-to-date but it does get eventually updated. reply Niksko 20 hours agoparentprevGoogle maps has this natively in Japan which was great for travelling there reply gnovel 20 hours agoparentprevThe Citymapper transit app shows this information for most cities it supports reply grishka 3 hours agoparentprevYandex maps does this at least for Russian cities. And as others said, Citymapper does it too. reply easton 18 hours agoparentprevA guy did this for the DC Metro: https://www.reddit.com/r/washingtondc/comments/15mbos4/i_map... It’s a PDF, so not automated, but still gave me some good ideas. reply chgs 20 hours agoparentprevGeoff Marshall made “Station Master” for the London Underground reply popcalc 21 hours agoparentprevEquivalent for the Budapest metro: https://metro.skornel02.hu/ reply bobbylarrybobby 18 hours agoparentprevI believe Apple Maps has that these days reply pimlottc 5 hours agorootparentIt definitely does not for Chicago reply waiwai933 18 hours agoprevLondon's are available at: https://www.ianvisits.co.uk/articles/3d-maps-of-every-underg... reply usr1106 20 hours agoprevSlightly (un)related: For detailed subway track maps e.g. in Paris https://cartometro.com/en/ is a nice resource. The US is not covered well, though. reply bobthepanda 20 hours agoparentNYC subway, including provisions for extensions that never happened: https://www.vanshnookenraggen.com/_index/docs/NYC_full_track... My understanding was that there used to be more of these publicly available but agencies get cagey about publishing stuff like this for security reasons. reply Sniffnoy 17 hours agoprevNot all of these are correct. For instance, the one for Fulton St Station shows the two J/Z platforms as being on the same level, when in fact they're on two different levels. reply noident 16 hours agoparentThis is the closest possible approximation of the Fulton St Station hypercube understandable by humans. Some compromises have to be made to represent non-Euclidean spaces in ways that residents of lower dimensions can understand. reply airstrike 13 hours agorootparentLook at this guy! He can't even moonwalk on the J axis reply elegantelefant 16 hours agoparentprevHi I'm the creator. Thanks for the note - you are not the first one to point that out and it's been sitting on my \"to fix\" list for years... One day I will get to it! reply jareklupinski 17 hours agoprevOne time I got onto the Q platform from Centre Street by habit before realizing I was supposed to take the 6. Felt like I somehow broke space and time getting there, and this Escher staircase in Canal Street station confirms it: https://images.squarespace-cdn.com/content/v1/55ababf2e4b064... reply neilv 20 hours agoprevIn the renderings, why are most of the (what look like) stairs/escalators so steep? reply elegantelefant 16 hours agoparentHi there, I am the creator. As other commenters pointed out, the vertical distances were exaggerated roughly 4x so things don't overlap each other. I have experimented with a few things over the years and this is my latest series: https://www.projectsubwaynyc.com/complexes I think they look more reasonable - still legible but the stairs and escalators look more to scale. They also include elevators. reply abstractbeliefs 20 hours agoparentprevI don't know about this instance in particular, but the vertical scale in similar maps is often exaggerated to make it easier to differentiate the different floors. At the cost of distorting elements with a vertical dimension, it means that all the wireframe layouts don't end up overlaying each other. reply Tokkemon 17 hours agoparentprevThey are schematic drawings to make them clearer, not to scale. reply throw0101d 16 hours agoprevA somewhat related idea that's been done for Toronto TTC subway stations is mapping out where the exit/stairs are for your destination station, that way when the doors open they're right there and you don't have to walk down the platform: * https://theurbangeographer.ca/Subway-Exit-Map * iOS app: https://efficientttc.weebly.com * Android: https://recursivepizza.com/#TtcRider_more reply EE84M3i 16 hours agoparentGoogle maps does automatically this for most stations in Tokyo. reply helsinki 4 hours agoprevTo the person drawing the stairs, the stairs are not that steep - not even close. reply ColinWright 1 hour agoparentI refer you to the reply made by the author on exactly this point: https://news.ycombinator.com/item?id=42098298 reply pimlottc 21 hours agoprevI would love to have diagrams like this for Chicago’s CTA but I haven’t found any. reply IG_Semmelweiss 19 hours agoprevI asked a while back to a NYC city planner the reason they didn't publish station MTA station layouts / exits on gmaps , like you see for example for toyko in gmaps I was told this was not opened publicly because of terrorist concerns. But if you wanted to get MTA station layouts, it was certainly possible to get them from the city. I guess we have flipped that page! reply akira2501 19 hours agoparent> because of terrorist concerns. The New York bureaucracies favorite excuse for not doing work they are responsible for. reply elegantelefant 16 hours agorootparentHi I am the creator. My cousin kindly asked his friend who works for the MTA for me, if my project is a problem for them... and the answer was something like \"as long as the drawings don't show columns and/or any structural elements they are fine.\" My drawings are all meant to be diagrams and only show publicly accessible areas anyway. It's not like the terrorists can't go walk around and figure the stations out themselves if they want... reply rangestransform 33 minutes agorootparentprevJust like the excuses for banning photos in PATH reply potato3732842 19 hours agorootparentprevNot sure why this is downvoted? Do people not remember how for ~20yr \"terrorism\" was habitually used as a justification for \"because we don't want to\" by every government organization from the MTA to small town parks departments. reply ryandrake 18 hours agorootparentI was going to say! \"Because Terrorism\" has been the catch-all vague excuse for limiting access to everything, for decades. reply slillibri 18 hours agoparentprevThe truly hilarious thing is that the Tokyo subway system actually suffered a terrorist attack in 95, and still they publish the locations of all 200+ exits from Shinjuku station. reply latency-guy2 18 hours agoparentprevTruly ridiculous to think that a terrorism group is filled with incapable individuals so as to not be able to map out a well traveled and popular location. Stop pretending terrorists are stupid, quite often they're smarter than you, and seeing this as an excuse tells me that bar is not difficult to pass. reply xattt 19 hours agoparentprevThis was also an oft-cited reason why trains with pass-through gangways were not a thing in Toronto for a long time. reply rangestransform 39 minutes agorootparentOpen gangways are still detrimental because they make it easier for showtime people to carry speakers and instruments between cars reply sofixa 8 hours agorootparentprevSo that people couldn't run away from an attacker? reply afavour 21 hours agoprevAwesome. I wonder if there’s a way to turn these into actual geographic data. I’d love an app to that will navigate me between platforms at the Fulton St megaplex. reply usr1106 20 hours agoparent> I’d love an app to that will navigate me between platforms Why would that be needed? I visited NYC the first time as a high school student with not so perfect English as a foreign language skills in 1980 when the city was in a pretty rotten state. The last time in 2009 when the subway was at least free of graffiti and generally looked maintained better. In younger years I found huge subway stations and their connecting walkways fascinating so might have planned some trips with extra complicated changes :) I never had the feeling of getting lost although I definitely lost all sense of orientation. It was easy enough to just \"blindly\" follow the signs. Not sure why an app would be needed, I assume the signs have not disappeared. (In 1980 some connections were still sign-posted as \"connection to IMT\", ... BRT, or ... IND lines although those had ceased to exist 40 years earlier and where not marked on the official subway map. But even that you could just guess from the \"breaks\" in the line numbering.) reply lelandfe 19 hours agorootparentOh, that’s just the Brooklyn bound train. Where’s the uptown one? Wait, the F is running on the 4? Where is that? This staircase is out of order? Where even is another staircase? This is saying I need to go to Metropolitan. I’m at Lorimer, apparently - wait, is that the same station? Is there an underground path from Grand Central or do I need to exit? What’s the best exit? It’s unusual to see someone try to make the case for the MTA not being complex, “I got lost in the subway” is like a lowest common denominator NYC experience. reply tialaramex 17 hours agorootparentI wouldn't expect it to seem complicated if you're used to other large subway systems. If the only previous subway experience you have is Glasgow (a single circular route) then yeah, New York is potentially intimidating, but I don't expect a Londoner or Parisian would see it as disproportionately complicated. More stations, but not orders of magnitude more. Tokyo too, and New York only has (these days) a single integrated system so no weird ticketing or line change rules. reply crazygringo 17 hours agorootparentIn my experience it is absolutely more complicated. Not if all the trains are running normally. The problem is that they often (usually?) aren't. The complexity isn't the map. It's the fact that trains shut down, swap tracks, switch lines, skip stations, end early, etc. I've never seen any other city where you have to stay on top of the constant changes. During weekdays it's not so bad, but nights and weekends yikes. reply rangestransform 35 minutes agorootparentGoogle maps usually stays on top of the scheduled service pattern changes at least reply usr1106 11 hours agorootparentprevMaybe that's easier for a visitor. You make no assumptions how things are supposed to work because you don't know. You just follow the signs and announcements. Of course in case of disruptions/changes that requires that there are temporary signs and announcements. And that announcements are understandable. Earlier the first thing in a new city was getting a paper map. No matter whether free or for purchase. Studying the map prepares you for following signs and announcements. Unfortunately in many cities you cannot get paper maps anymore. A phone screen is 1000 times worse ergonomics to understand a network. Often I print maps before going to a new place. reply lelandfe 4 hours agorootparentNah, a phone is pretty indispensable. If you’re waiting for the train at 3am, the only person on the platform, your phone might be the only way for you to know that that countdown clock is lying, and that the subway is down. I would not recommend trying to tackle the MTA with a paper map alone. I wish signage and announcements were as good as you’re hoping reply crazygringo 3 hours agorootparentprev> Of course in case of disruptions/changes that requires that there are temporary signs and announcements. Which there frequently (usually?) aren't. Because so many disruptions are unplanned. Also it's a big waste of time to walk 10 min to the subway station and pay the fare only to discover the train you need isn't running and you needed to go to a different station on a different line. reply Scubabear68 18 hours agorootparentprevThey specifically mentioned the new Fulton street station. That is effectively a multi level mall and the junction of many train lines to boot. Navigating it for the first time is daunting. Very different from most single-line stations. reply lelandfe 21 hours agoparentprevI believe precise subterranean location like that is hard. reply bobthepanda 20 hours agorootparentI think there have been attempts to do this with physical beacons that can orient phones nearby, but I would imagine it can be hard to maintain in the harsh operating environment of the subway. reply rangestransform 34 minutes agorootparentThere are BLE beacons for positioning in the big dig tunnels in Boston reply throw0101d 16 hours agorootparentprevWhat I'd be more curious about is being able to trust the beacons. Certainly there is a mechanism where if a phone can get a GNSS/GPS fix, it can then listen for other signals like Wifi and cell towers, and correlate the two: so if GPS isn't available other stuff can heard and used for location. But if there's no GPS, but there are other signals, how can you map the signals to an actual location? You'd have to have someone (Apple? Google?) go in with survey equipment and map the non-GNSS (beacon) signals to locations 'manually' and put them in a database. reply jpc0 7 hours agorootparentProbably not economically feasible but I don't think technically impossible given analytics from devices. And concidering cell signal is likely covered down there and the locations of cell towers are almost certainly mapped they could use some sort of triangulation to generate a pretty reasonable map even without having ever been there. As I said, I doubt they would put the money into it... Would be a really fun project to build out if you had access to the data though... Maybe don't want to do it because it would make it more common knowledge about how easy it is to track device location even without GPS... I don't think you would need physical beacons, cell towers or fixed wifi APs[1] will likely be good enough and using some statistics would make removing cases where an AP moved/get renamed / goes down temporarily. 1. Access Points reply throw7 20 hours agoprevPeople should do/include Secaucus Junction. reply mrb 18 hours agoprevSimilarly, this site has subway station layouts for many cities: http://stations.albertguillaumes.cat/ reply amelius 20 hours agoprevCan this be integrated into the various navigation apps? reply nuvious 19 hours agoprevThis is a fun visualization. I may end up in NYC if my job interviews went well enough to land an offer. Just wrapped up 2nd round yesterday. reply samuelg123 17 hours agoprevMake sure to check out the 3D models tab. That’s definitely the most interesting part of the site! reply suneater921 9 hours agoprevThe Hong Kong MTR has these as standard. reply mmooss 20 hours agoprevThe photography is the best part (of a wonderful website). Kudos to the creator. reply alsetmusic 20 hours agoprevWhy are the stations not labeled? I'm sure this is fine for people who live there and use the subway on a regular basis, but it would be of little help to someone visiting or who just relocated. Even someone visiting a friend in an area they aren't familiar with would be at a disadvantage figuring out which layout to use. Edit: that said, very cool. reply elegantelefant 16 hours agoparentHi, I'm the creator. I appreciate the feedback. If you click on an image and then hover your cursor over it, the station name will show up. Not super friendly I agree, but it was mostly developed in 2015. Here is the latest series, with elevators and more labels: https://www.projectsubwaynyc.com/complexes reply kshahkshah 17 hours agoparentprevIt's just for fun. There are apps which help you figure out which car to board (where to stand on the platform) based off your transfers & destinations reply Tokkemon 17 hours agoparentprevIt's an art project, not a practical tool. reply cryptozeus 20 hours agoprev [–] Great but if owner is looking at this, please make the images zoomable on mobile reply elegantelefant 16 hours agoparent [–] Hi there, it's me. This page was made in 2015/2016. The later series have more zoomable interfaces, although none is perfect. Check them out! https://www.projectsubwaynyc.com/x-ray-area-maps https://www.projectsubwaynyc.com/x-ray-station-clusters https://www.projectsubwaynyc.com/complexes reply cryptozeus 11 hours agorootparent [–] Etsy prints are beautiful ! Just one more issue, for some reason Avast is giving me error for your zoom plugin. This is the error on your page. Whew! We’ve just saved you from an infected website Infected URL: https://community.zoomable.ca/zoomable/viewer.php Threat: URL:Phishing reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "NYC Subway Station Layouts provides detailed renderings of subway stations but lacks bookmarkable URLs, reducing user-friendliness.- Users highlight challenges in navigating NYC's subway system, noting outdated trains and limited signage compared to cities like Tokyo and London.- The site's creator is aware of feedback and plans updates to enhance usability, with discussions also covering the role of technology in transit apps and the effects of outdated infrastructure on user experience."
    ],
    "points": 277,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1731184504
  },
  {
    "id": 42098491,
    "title": "Audio Decomposition – open-source seperation of music to constituent instruments",
    "originLink": "https://matthew-bird.com/blogs/Audio-Decomposition.html",
    "originBody": "Matthew Bird Home Blogs About Audio Decomposition [Blind Source Seperation] Open source seperation of music into constituent instruments. Made from scratch without external instrument seperation libraries. Matthew Bird Tue, Oct 1, 2024 Demo Vids: https://youtu.be/-i0PSxcoDH0, https://youtu.be/mzPUfs9sYQE, https://youtu.be/Z7D6obv12zk, https://youtu.be/LkDJ9XT-klU Github Repository: https://github.com/mbird1258/Audio-Decomposition Premise My plan for this project was to create a program to turn music to sheet music. It was mainly incentivised by my own desire to turn music to sheet music and the lack (from what I could tell) of open source, simple algorithms to perform audio source separation. Preparation Instrument data The instrument data all comes from the University of Iowa Electronic Music Studios instrument database. With these files, we find the Fourier transform of the entire wave and the envelope of the wave using the same method as documented below. How it works An instrument’s sound wave is mainly characterized by its fourier transform and envelope. Thus, we can use both of these to hopefully get a good idea of which instrument is playing what note. Fourier Transform The program’s first method of splitting music into constituent notes and instruments is by taking the fourier transform of the music file every 0.1 seconds (spectrogram), and adding together our stored fourier transform of each instrument to recreate the fourier transform of the 0.1 second window. The idea was to hopefully perfectly recreate the music at the set time as the fourier transform should represent the music played relatively well. Original fourier transform Constituent instruments Recreated fourier transform The magnitudes for each instrument are given by solving the following matrix. The matrix is derived from taking the partial derivative of the MSE cost function by frequency(ex. FT value at 5 hz) with respect to each instrument. Each row in the matrix is a different partial derivative. (First is w.r.t cello, second is w.r.t piano, etc.) Envelope The first step to matching the envelope of the instrument to the sound wave is to obtain the envelope itself. The envelope is the upper bound of a wave, and although there are functions to do this, they seemingly struggle with noise and certain types of sound waves. Thus, since we have to handle many different instruments at different frequencies, we need a more robust solution. To get the envelope, the function splits the sound wave into chunks, before taking the max value at each chunk. To further refine the results, the function finds the points where the envelope is below the original sound wave and adds a new point defining the envelope. The next step is to split the envelope of the wave into its attack, sustain, and release. The attack is the initial noise of the note, the sustain is while the note is held, and the release is when the note stops. For the instrument samples, we can take the first nonzero value of the wave to get the start of the attack. To get the point between the attack and sustain, we get the first point when the function is concave down or decreasing. To get the point between the sustain and release, we get the first point from the end where the function is increasing or concave down. To get the end of the release, we find the first point from the end where the function is nonzero. To further classify the wave, we need to take into account the main forms the wave can take. Some instruments, such as the piano, have static decay, in which they mostly follow an exponential decay shape. On the other hand, some instruments, like the violin, can increase or decrease in volume as the note is sustained. In addition to this, some audio samples in the instrument files are held until their sound expires, while others are released early. To differentiate whether the decay is static or dynamic, if the decay factor is >1, or if it deviates from the decay curve by too much, it’s dynamic. To differentiate if the envelope has a release or not(AS or ASR), we look at the average rate of change across the sustain and the release, and if the rate of change of the release is lower then there is no release. Different types of wave To deal with the music file, we first take the bandpass filter of the signal for each note frequency. With the filtered wave, we iterate through each instrument. For each instrument, we take the cross correlation of the instrument’s attack(normalized) and release(normalized) to find the start and end of each note, and then take the MSE of the instrument wave and the filtered audio to get our cost for the instrument at that time. After this, we multiply the magnitude we found in the fourier transform step and 1/(cost we found in this step) to get our final magnitudes. Display To display the file, we use matplotlib’s scatter plot with - shaped points to display the sheet music. Originally, I wanted to recreate the audio from the magnitudes, but it led to many issues, took a while, and made troubleshooting much harder. I also tried using matplotlib’s imshow plot, but it’s extremely inefficient in this case as most values are 0, and matplotlib needs to redraw every point regardless of if it’s on screen or not every time we pan or zoom the screen. Results Overall, I think it works quite well. You can use it to make recreating sheet music better(as I did here from this video), especially if you struggle with finding the right pitch or chords, and it doesn’t take too much time to run either. Feel free to contact me about anything! Contacts © Matthew-Bird.com Made by Matthew Bird",
    "commentLink": "https://news.ycombinator.com/item?id=42098491",
    "commentBody": "Audio Decomposition – open-source seperation of music to constituent instruments (matthew-bird.com)222 points by thunderbong 15 hours agohidepastfavorite50 comments timlod 8 hours agoThe title is a bit confusing as open-source separation of ... reads like source separation, which this is not. Rather, it is a pitch detection algorithm which also classifies the instrument the pitch originated with. I think it's really neat, but the results look like it could take more time to fix the output than using a manual approach (if really accurate results are required). reply earthnail 8 hours agoparentThanks for clarifying. In fairness to the author, he is still at high school: https://matthew-bird.com/about.html Amazing work for that age. reply veunes 4 hours agorootparentHe's definitely a talent to watch! reply timlod 5 hours agorootparentprevWow, I didn't see that. Great to see this level of interest early on! reply TazeTSchnitzel 7 hours agoparentprevIs “source separation” better known as “stem separation” or is that something else? I think the latter term is the one I usually hear from musicians who are interested in taking a single audio file and recovering (something approximating) the original tracks prior to mixing (i.e. the “stems”). reply timlod 5 hours agorootparentAudio Source Separation I think is the general term used in research. It is often applied to musical audio though, where you want to do stem separation - that's source separation where you want to isolate audio stems, a term referring to audio from related groups of signals, e.g. drums (which can contain multiple individual signals, like one for each drum/cymbal). reply Earw0rm 5 hours agorootparentprevStem separation refers to doing it with audio playback fidelity (or an attempt at that). So it should pull the bass part out at high enough fidelity to be reused as a bass part. This is a partly solved problem right now. Some tracks and signal types can be unmixed easier than others, it depends on what the sources are and how much post-processing (reverb, side chaining, heavy brick wall limiting and so on) reply dylan604 1 hour agorootparent> This is a partly solved problem right now. I'd agree with the partly. I have yet to find one that either isolates an instrument as a separate file or removes one from the rest of the mix that does not negatively impact the sound. The common issues I hear are similar to the early internet low bit rate compression. The new \"AI\" versions are really bad at this, but even the ones available before the AI craze were still susceptible reply emptiestplace 8 hours agoparentprevNo, it doesn't read like that. The hyphen completely eliminates any possible ambiguity. reply ipsum2 1 hour agorootparentThe title of the submission was modified. It you read the article it says: Audio Decomposition [Blind Source Seperation] reply croes 7 hours agorootparentprevMaybe added later by OP? Because there is no hyphen in the article’s subtitle. >Open source seperation of music into constituent instruments. reply emptiestplace 44 minutes agorootparentThe complaint: > The title is a bit confusing as open-source separation of ... reads like source separation, which this is not. reply loubbrad 5 hours agoprevI didn't see it referenced directly anywhere in this post. However, for those interested, automatic music transcription (i.e., audio->MIDI) is actually a decently sized subfield of deep learning and music information retrieval. There have been several successful models for multi-track music transcription - see Google's MT3 project (https://research.google/pubs/mt3-multi-task-multitrack-music...). In the case of piano transcription, accuracy is nearly flawless at this point, even for very low-quality audio: https://github.com/EleutherAI/aria-amt Full disclaimer: I am the author of the above repo. reply bravura 5 hours agoparentI know the reported scores of MT3 are very good, but have you had success with using it yourself? https://replicate.com/turian/multi-task-music-transcription I ported their colab to runtime so I could use it more easily. The MIDI output is... puzzling? I've tried feeding it even simple stems and found the output unusable for some tracks, i.e. the MIDI output and audio were not well aligned and there were timing issues. On other audio it seemed to work fine. reply air217 1 hour agorootparentI developed https://pyaar.ai, it uses MT3 under the hood. I realized that continuous string instruments (guitar) that have things like slides, bends are quite difficult to capture in MIDI. Piano works much better because it's more discrete (the keys abstract away the strings) and so the MIDI file has better representation reply loubbrad 4 hours agorootparentprevMulti-track transcription has a long way to go before it seriously useful for real-world applications. Ultimately I think that converting audio into MIDI makes a lot more sense for piano/guitar transcription than it does for complex multi-instrument works with sound effects ect... Luckily for me, audio-to-seq approaches do work very well for piano, which turns out to be an amazing way of getting expressive MIDI data for training generative models. reply Earw0rm 5 hours agoparentprevHe's trying to solve a second (also hard ish) problem as well, deriving an accurate musical score from MIDI data. It's a \"sounds easy but isn't\" problem, especially when audio to MIDI transcribers are great at pitch and onset times, but rather less reliable at duration and velocity. reply loubbrad 4 hours agorootparentI agree that the audio->score and MIDI->score problems are quite hard. There has been research in this area too, however it is far less developed than audio->MIDI. reply Earw0rm 4 hours agorootparentThat's because MIDI doesn't contain all the information that was in a score. Scores are interpreted by musicians to create a performance, and MIDI is a capture of (some of) the data about that performance. Music engraving is full of implicit and explicit cultural rules, and getting it _right_ has parallels with handwritten kanji script in terms of both the importance of correctness to the reader, and the amount of traps for the unwary or uncultured. All of which can be taken to mean \"classical musicians are incredibly picky and anal about this stuff\", or, \"well-formed music notation conveys all sorts of useful contextual information beyond simply 'what note to play when'\". reply pclmulqdq 3 hours agorootparentA lot of modern scores are written with MIDI in mind (whether or not the composer knows it - that's how they hear it the first 50 or so times). That should make it somewhat easier to go MIDI -> score for similar pieces. Current attempts I have seen still make a lot of stupid errors like making note durations too precise and spelling accidentals badly. There's probably still a lot of low-hanging fruit. This is absolutely not easy, though, given all the cultural context. Things like picking up a \"legato\" or \"cantabile\" marking and choosing an accent vs a dagger or a marcato mark are going to be very difficult no matter what. reply WiSaGaN 5 hours agoparentprevHow does the problem simplify when it's restricted to piano? reply loubbrad 5 hours agorootparentEssentially, the leading way to do automatic music transcription is to train a neural network on supervised data, i.e., paired audio-MIDI data. In the case of piano recordings, there is a very good dataset for this task which was released by Google in 2018: https://magenta.tensorflow.org/datasets/maestro Most current research involves refining deep learning based approaches to this task. When I worked on this problem earlier this year, I was interested in adding robustness to these models by training a sort of musical awareness into them. You can see a good example of it in this tweet: https://x.com/loubbrad/status/1794747652191777049 reply fxj 6 hours agoprevIf you are interested in audio (or stem) separation have a look at RipX https://hitnmix.com/ripx-daw-pro/ It can even export the separated tracks as midi files. It still has some problems but works very well. Stem separation is now standard in the musical software and almost every DAW provides it. reply antback 33 minutes agoparentIt appears to be related to Polymath. https://github.com/samim23/polymath Polymath is effective at isolating and extracting individual instrument tracks from MP3s. It works very well. reply tasty_freeze 2 hours agoparentprevRipX can do stem separation and allows repitching notes in the mix. If that is what you want to do it is great. I find moises (https://moises.ai/) to be easy to use for the tasks I need to do. It allows transposing or time scaling the entire song. It does stem separation and has a simple interface for muting and changing the volume on a per-track basis. It auto-detects the beat and chords. I'm not affiliated, just a happy nearly-daily user for learning and practicing songs. I boost the original bass part and put everything else atalmost every DAW provides it. It's an up and coming feature that nearly every DAW should have, but most don't yet. Ableton Live - No Bigwig - No Cubase - No FL - Yes Logic - Yes Pro Tools - No Reason - No Reaper - No Studio One - Yes reply makz 5 hours agoparentprevThanks for the information. I’m a long time Logic Pro user and I wasn’t aware of this feature. reply Sporktacular 3 hours agorootparentOn an M1/2/3/4 processor. Not Intel. reply bottom999mottob 9 hours agoprevThis is really cool, but there's real-world instrument physics that might not be captured by simple Fourier transform templates, like a trumpet playing softly can have a significantly different harmonic spectrum than the same trumpet playing loudly, even at the same pitch Trumpets produce a rich harmonic series with strong overtones, meaning their Fourier transform would show prominent peaks at integer multiples of the fundamental frequency. Instruments like flutes have more pure tones, but brass instruments typically have stronger higher harmonics, which would lead to more complex partial derivatives in the matrix equation shown in the article So this script uses bandpass filtering and cross-correlation of attack/release envelopes to identify note timing. Given that brass instruments can exhibit non-linear behavior where the harmonic content changes significantly with playing intensity (think of the brightness difference between pp and ff passages), not sure how would this algorithm could handle intensity-dependent timbral variations. I'd consider adding intensity-dependent Fourier templates for each instrument to improve accuracy reply atoav 7 hours agoparentAs someone who uses source separation twice a week for mixing purposes the number of other instruments that can produce sounds of \"vocal\" quality is high. These models all stop functiining well when you have bands where the instruments don't sound typical and aren't played and/or mixed in a way that achieves maximum separation between them — e.g. an electrical guitar with a distorted harmonic hitting the same note as your singer while the drummer plays only shrieking noises on their cymbals and the bass player simulates a punching kick drum on their instrument. In these situations (experimental music) source separation will produce completely unpredictable results, thst may or may not be useful for musical rebalancing. reply fnordlord 5 hours agorootparentWhat tool do you use for the source separation? Everything I've used so far is great for learning or transcribing to MIDI but the separated tracks always have a strange phasing sound to them. Are you doing something to clean that up before mixing back in or are the results already good enough? reply atoav 5 hours agorootparentiZotope RX with musical rebalance, great to reduce drum spill from vocal mics reply baq 6 hours agoprevGot a flashback of playing audiosurf 15 or so years ago. Time flies. https://en.wikipedia.org/wiki/Audiosurf reply ipsum2 9 hours agoprevI must be dumb, but none of the YouTube video demos are demonstrating source separation? Edit: to clarify, source separation in audio research means separating out the audio into separate clips. reply atoav 7 hours agoparentI think decomposition is the word, source separation in this case (misleadingly) referes to the fact that the decomposed notes can be separated into different sources. reply wkjagt 6 hours agoparentprevThe \"source\" here goes with \"open source\". reply generalizations 6 hours agoprevNo one else is going to mention that \"separation\" was misspelled four times? reply orbitingpluto 6 hours agoparentIf we can all hear the tiny violin, who cares? reply generalizations 4 hours agorootparentDegradation of the environment. https://en.wikipedia.org/wiki/Broken_windows_theory#Theoreti... reply DidYaWipe 9 hours agoprevSome of those videos don't have audio, as far as I can tell... reply tjoff 9 hours agoparentThe youtube links explains why: \"No audio as a result of copyright.\" And also has a link to the audio that you can play alongside. reply ekianjo 6 hours agoprevLooks like this may be the work of Joshua Bird's little brother (?). Joshua bird did some impressive projects already, that were featured on HN before: https://www.youtube.com/@joshuabird333 reply bastloing 6 hours agoprevI can't find the source code, but the project looks interesting. reply ssttoo 4 hours agoparentThere’s a GitHub link right below the videos https://github.com/mbird1258/Audio-Decomposition reply bastloing 0 minutes agorootparentThanks! Nice! This kid is pretty sharp, can't wait to see what else he does! reply kasajian 3 hours agoprevdude can't spell reply berbec 2 hours agoparentHe's in high school and pulls of a project like this. I thought I was slick convincing the 7-11 guy to give me my Twist-a-Pepper soda without charging me bottle deposit or tax. reply testoveride 5 hours agoprev [–] Ff reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Matthew Bird's open-source project focuses on blind source separation, aiming to split music into individual instruments without relying on external libraries.",
      "The project utilizes Fourier transforms and envelope analysis to convert music into sheet music, sourcing instrument data from the University of Iowa's database.",
      "Sound waves are analyzed to identify instruments and notes using spectrograms and matrix solutions, with results displayed via matplotlib; the project is accessible on GitHub."
    ],
    "commentSummary": [
      "Audio Decomposition is an open-source project developed by a high school student, utilizing a pitch detection algorithm to classify instruments in music.- Although it does not achieve true source separation, it presents a novel method for identifying musical elements, sparking discussions on the challenges of audio separation in complex music.- The project is accessible on GitHub, highlighting the impressive capabilities of a young developer in the field of audio technology."
    ],
    "points": 222,
    "commentCount": 50,
    "retryCount": 0,
    "time": 1731211057
  },
  {
    "id": 42098236,
    "title": "Physical Intelligence's first generalist policy AI can finally do your laundry",
    "originLink": "https://www.physicalintelligence.company/blog/pi0",
    "originBody": "Physical Intelligence (π) π0: Our First Generalist Policy Published October 31, 2024 Email research@physicalintelligence.companyKevin Black, Noah Brown, Danny Driess, Michael Equi, Adnan Esmail, Chelsea Finn, Nick Fusai, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Kay Ke, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Lucy Shi, James Tanner, Quan Vuong, Anna Walling, Haohuan Wang, Ury Zhilinsky Paper π0.pdf We are living through an AI revolution: the past decade witnessed practically useful AI assistants, AI systems that can generate photorealistic images and videos, and even models that can predict the structure of proteins. But in spite of all these advances, human intelligence dramatically outpaces AI when it comes to the physical world. To paraphrase Moravec’s paradox, winning a game of chess or discovering a new drug represent “easy” problems for AI to solve, but folding a shirt or cleaning up a table requires solving some of the most difficult engineering problems ever conceived. To build AI systems that have the kind of physically situated versatility that people possess, we need a new approach — we need to make AI systems embodied so that they can acquire physical intelligence. Over the past eight months, we’ve developed a general-purpose robot foundation model that we call π0 (pi-zero). We believe this is a first step toward our long-term goal of developing artificial physical intelligence, so that users can simply ask robots to perform any task they want, just like they can ask large language models (LLMs) and chatbot assistants. Like LLMs, our model is trained on broad and diverse data and can follow various text instructions. Unlike LLMs, it spans images, text, and actions and acquires physical intelligence by training on embodied experience from robots, learning to directly output low-level motor commands via a novel architecture. It can control a variety of different robots, and can either be prompted to carry out the desired task, or fine-tuned to specialize it to challenging application scenarios. An extended article on our work can be found here. The promise of generalist robot policies Today’s robots are narrow specialists. Industrial robots are programmed for repetitive motions in choreographed settings, repeatedly making the same weld in the same spot on an assembly line or dropping the same item into the same box. Even such simple behaviors require extensive manual engineering, and more complex behaviors in messy real-world environments such as homes are simply infeasible. AI could change that, allowing robots to learn and follow user instructions, so that programming a new behavior is as simple as telling the robot what you want done, and the robot can itself figure out how to adapt its behavior to its environment. But this requires data. Language models and other foundation models mine data from the web, utilizing a significant fraction of all available documents. There is no such treasure trove of robot data, so to enable a robot to learn a new skill, large amounts of data need to be collected with that particular robot and for that particular application. If we could train a single generalist robot policy that can perform a wide range of different skills and control a wide range of different robots, we would overcome this challenge: such a model would need only a little bit of data from each robot and each application. Just as a person can learn a new skill quickly by drawing on a lifetime’s worth of experience, such a generalist robot policy could be specialized to new tasks with only modest amounts of data. This would not be the first time that a generalist model beat a specialist at the specialist’s own task: language models have superseded more specialized language processing systems precisely because they can better solve those downstream specialist tasks by drawing on their diverse and general purpose pretraining. In the same way that LLMs provide a foundation model for language, these generalist robot policies will provide a robot foundation model for physical intelligence. To get there, we will need to solve major technical challenges. Our first step is π0, a prototype model that combines large-scale multi-task and multi-robot data collection with a new network architecture to enable the most capable and dexterous generalist robot policy to date. While we believe this is only a small early step toward developing truly general-purpose robot models, we think it represents an exciting step that provides a glimpse of what is to come. A cross-embodiment training mixture π0 uses Internet-scale vision-language pre-pretraining, open-source robot manipulation datasets, and our own datasets consisting of dexterous tasks from 8 distinct robots. The model can then perform a wide variety of tasks, via either zero-shot prompting or fine-tuning. Our first prototype generalist robot policy is trained on the largest robot interaction dataset to date. The full training mixture includes both open-source data and a large and diverse dataset of dexterous tasks that we collected across 8 distinct robots. Our dataset contains diverse tasks, with each task exhibiting a wide variety of motion primitives, many different objects, and various scenes. The tasks in this dataset exercise different dimensions of robot dexterity while covering the range of real tasks that these robots might be asked to perform, from bussing dishes to packing items into envelopes, folding clothing, routing cables, assembling boxes, plugging in power plugs, packing food into to-go boxes, and picking up and throwing out trash. Our goal in selecting these tasks is not to solve any particular application, but to start to provide our model with a general understanding of physical interactions — an initial foundation for physical intelligence. Inheriting Internet-scale semantic understanding Beyond training on many different robots, π0 inherits semantic knowledge and visual understanding from Internet-scale pretraining by starting from a pre-trained vision-language model (VLM). VLMs are trained to model text and images on the web — widely used VLMs include GPT-4V and Gemini. We use a smaller 3 billion parameter VLM as a starting point, and adapt it for real-time dexterous robot control. VLMs effectively transfer semantic knowledge from the web, but they are trained to output only discrete language tokens. Dexterous robot manipulation requires π0 to output motor commands at a high frequency, up to 50 times per second. To provide this level of dexterity, we developed a novel method to augment pre-trained VLMs with continuous action outputs via flow matching, a variant of diffusion models. Starting from diverse robot data and a VLM pre-trained on Internet-scale data, we train our vision-language-action flow matching model, which we can then post-train on high-quality robot data to solve a range of downstream tasks. Our vision-language-action model uses a novel flow matching formulation, which augments a vision-language model pre-trained on Internet-scale data with continuous outputs. This enables high-frequency dexterous control, making it particularly well-suited for fine-tuning for complex robot manipulation tasks, such as folding laundry or assembling boxes. Post-training for dexterous manipulation More complex and dexterous tasks may require the model to be fine-tuned to specialize it to downstream challenges. Fine-tuning the model with high-quality data for a challenging task, such as folding laundry, is analogous to the post-training process employed by LLM designers. Pre-training teaches the model about the physical world, while fine-tuning forces it to perform a particular task well. Let’s take a look at some of these tasks. After post-training, the robot can unload the dryer, bring the clothes over to the table, and fold the clothes into a stack. The video is uncut, from a single policy operating fully autonomously. Laundry. We fine-tuned π0 to fold laundry, using either a mobile robot or a fixed pair of arms. The goal is to get the clothing into a neat stack. This task is exceptionally difficult for robots (...and some humans): while a single t-shirt laid flat on the table can sometimes be folded just by repeating a pre-scripted set of motions, a pile of tangled laundry can be crumpled in many different ways, so it is not enough to simply move the arms through the same motion. To our knowledge, no prior robot system has been demonstrated to perform this task at this level of complexity. Notably, by training on diverse data, we find that the robot is able to recover when someone tries to intervene in a variety of different ways. Table bussing. We also fine-tuned the model to bus a table. This requires the robot to pick up dishes and trash on the table, putting any dishes, cutlery, or cups into a bussing bin, and putting trash into the trash bin. This task requires the robot to handle a dizzying variety of items. One of the exciting consequences of training π0 on large and diverse datasets was the range of emergent strategies that the robot employed: instead of simply grasping each item in turn, the model could stack multiple dishes to put them into the bin together, or shake off trash from a plate into the garbage before placing the plate into the bussing bin. Assembling a box. Here, the robot has to take a flattened cardboard box and build it, folding the sides and then tucking in the flaps. This is very difficult, because each fold and tuck might fail in unexpected ways, so the robot needs to watch its progress and adjust as it goes. It also needs to brace the box with both arms, even using the table, so that the partially folded box doesn’t come apart. Evaluating and comparing π0 to prior models We compared π0 to other robot foundation models that have been proposed in the academic literature on our tasks: OpenVLA, a 7B parameter VLA model that uses discretized actions, and Octo, a 93M parameter model that uses diffusion outputs. These tasks are very difficult compared to those that are typically used in academic experiments — for example, the tasks in the OpenVLA evaluation typically consist of single stage behaviors (e.g., “put eggplant into pot”), whereas our simplest bussing task consisting of sorting multiple objects into either a garbage bin or a bussing bin, and our more complex tasks might require multiple stages, manipulation of deformable objects, and the ability to deploy one of many possible strategies given the current configuration of the environment. These tasks are evaluated according to a scoring rubric that assigns a score of 1.0 for a fully successful completion, with “partial credit” for partially correct execution (e.g., bussing half the objects leads to a score of 0.5). The average scores across 5 zero-shot evaluation tasks are shown below, comparing the full π0 pre-trained model, π0-small, which is a 470M parameter model that does not use VLM pre-training, OpenVLA, and Octo. Although OpenVLA and Octo can attain non-zero performance on the easiest of these tasks (“Bussing Easy”), π0 is by far the best-performing model across all of the tasks. The small version, π0-small, attains the second best performance, but there is more than a 2x improvement in performance from using our full-size architecture with VLM pre-training. Average scores for π0, π0-small, OpenVLA, and Octo for zero-shot evaluation on 5 test tasks. Across all of the tasks, π0 consistently attains good performance, and outperforms both the small variant and the prior models. We include detailed videos from our rigorous empirical evaluation below, with examples of successful and failed episodes for both our zero-shot experiments and the fine-tuning evaluation. Complete results from all experiments can be found in the full article. Task Eggs in carton Grocery Bagging Toast out of toaster Towel fold Stack bowls Tupperware in microwave Items in drawer Laundry fold (shirts) Laundry fold (shorts) Paper towel in holder Food in to go box Status Success Fail Where do we go from here? Our mission at Physical Intelligence is to develop foundation models that can control any robot to perform any task. Our experiments so far show that such models can control a variety of robots and perform tasks that no prior robot learning system has done successfully, such as folding laundry from a hamper or assembling a cardboard box. But generalist robot policies are still in their infancy, and we have a long way to go. The frontiers of robot foundation model research include long-horizon reasoning and planning, autonomous self-improvement, robustness, and safety. We expect that the coming year will see major advances along all of these directions, but the initial results paint a promising picture for the future of robot foundation models: highly capable generalist policies that inherit semantic understanding from Internet-scale pretraining, incorporate data from many different tasks and robot platforms, and enable unprecedented dexterity and physical capability. We also think that succeeding at this will require not only new technologies and more data, but a collective effort involving the entire robotics community. We already have collaborations underway with a number of companies and robotics labs, both to refine hardware designs for teleoperation and autonomy, and incorporate data from our partners into our pre-trained models so that we can provide access to models adapted to their specific platforms. If you are interested in collaborating, please reach out. We are particularly excited to work with companies scaling up data collection with robots deployed for real-world applications, who are looking to collaborate on autonomy. We are also hiring! If you'd be interested in joining us please get in touch. For researchers interested in our work, collaborations, or other queries, please write to research@physicalintelligence.company. Physical Intelligence BlogJoin Us",
    "commentLink": "https://news.ycombinator.com/item?id=42098236",
    "commentBody": "Physical Intelligence's first generalist policy AI can finally do your laundry (physicalintelligence.company)187 points by Terretta 16 hours agohidepastfavorite161 comments lifeisstillgood 8 hours agoThe (unspoken?) goal is to do my laundry - and all the other domestic tasks, because that’s where human satisfaction can be unleashed Give me a moment 1. All economics / markers of value are about human happiness / satisfaction - we claim it’s money but it’s only given a value by humans who want it. 2. As soon as people get rich enough they outsource their domestic tasks - hire a maid or a cook, or buy ready meals. 3. In the western world companies over past fifty years got a free boost as women joined the labour force, and essentially companies were paying one guy the cost of a household now they pay two people the cost of household getting twice the workers for same price. 4. So most households have lost 35 hours a week, and also still have same amount of domestic duties to do 5. As we can’t give everyone a maid we might be able to give everyone a robot maid. 6. Most innovations / technologies find their way into homes - from bricks to heating to electricity we invent it and eventually find a way to make our lives more comfortable - see the point about economics is just humans liking stuff 7. I assumed that real robo maids would be a social shift - ie a different design of washing machine, people eating at other peoples houses every day, anti-dust surfaces. But this one looks … interesting 8. I know this is incredibly western middle class centric - but exactly what else are 6 billon people aiming for? reply vasco 6 hours agoparentThe underlying real goal is to have sex with the robots, just as the internet was going to be the gateway to all known information but instead is for porn. reply kelvinjps10 5 hours agorootparentIs both reply ttul 3 hours agorootparentprevCan it have sex while folding laundry? I sense that is the ultimate goal of all robotic research /s reply ktjag 8 hours agoparentprevWhere did the economies get a boost when women joined the labor force? In Germany the post-war economic miracle happened mostly without them. In the beginning of the 1970s, when women did join the labor force in greater numbers, admittedly the macroeconomic conditions were bad (oil crisis), so it is hard to filter that out. But still, mostly we have more workers, which lowers wages and leads to the creation of more bullshit jobs. To be clear, also men create and perform bullshit jobs! Now it takes two salaries to finance a house and a family. Great progress. At the supermarket, I boycott automated self-checkouts even if the lines are long so the nice cashiers keep their jobs. reply kristianp 7 hours agorootparent> Now it takes two salaries to finance a house and a family Yes! I have been thinking this. So as an economic consequence of both parents being able to work, now the choice to stay home and care for the kids is an even harder one. The birth rate falls. Kids are raised by childcare workers, not their parents. reply TeMPOraL 4 hours agorootparentThat's the irony. Before, there was no choice but for women to stay at home. Now, most have no choice but to work. Turns out, for the market, having a choice is a form of wealth. It will make you pay to acquire it, it will treat you as that much more wealthy if you have it, and it will encourage you to sell it. reply rwyinuse 3 hours agorootparentYeah, as far as labor market goes \"women's liberation\" never really happened. The social pressure to have a family didn't really disappear, and yet there's way more pressure to build a career to appease our corporate overlords. Is that really an improvement? Ultimately capitalism is built so that improved productivity, more working hours, higher salaries never benefit the worker long-term. If people start earning more, the owning class will simply raise prices to match this new level of income. The US is the wealthiest and strongest country in the world, and yet young people there struggle to buy houses just as much (or even more) than their peers in much poorer countries. reply ants_everywhere 3 hours agorootparent> The social pressure to have a family didn't really disappear All sexually reproducing organisms on the Earth have families without any social pressure and we evolved from primates who work like this. By far the stronger pressure is biological. I doubt social pressure even comes close to moving the needle. reply nobodyandproud 2 hours agorootparentUnlike most organisms, we’re smart enough to satisfy those urges without having children. The peak reproductive years are the late teens to late twenties (give or take). However and in modern society, having children in the first two-thirds of the peak years is a recipe for failure or lifelong hardships. reply schmidtleonard 5 hours agorootparentprevBut capital got their assets pumped and that's what matters! We need to stop asking 10+ workdays a week from each couple. Once we only demand 7 workdays a week, people are allowed to raise their own kids again! reply p1esk 4 hours agorootparentprevKids are raised by childcare workers, not their parents Is this bad? reply tpoacher 4 hours agorootparentonly in the same sense that most coffee shops are now starbucks where the coffee is made by temp baristas, not shop owners who care about the legacy of their coffee reply rfrey 3 hours agorootparentWere you drinking coffee before Starbucks came on the scene? I was, and if you could find a cafe that served better than a brown crayon steeped in water, it was a rare treasure. reply p1esk 3 hours agorootparentprevGreat example. I don’t know anything about coffee, have no idea how to make it, and no desire to learn it. If I’m ever forced to make my own coffee it would probably suck. When I want to drink coffee I go to Starbucks. Their coffee tastes great to me. reply drivebyhooting 1 hour agorootparentI’ve seen those baristas pouring hot espresso directly into the plastic cup. reply ac29 2 hours agorootparentprevIf you can boil water, you can make coffee at least as good as Starbucks. If boiling water is too difficult, there are automated push button machines (Nescafe, etc). reply mrybczyn 2 hours agorootparentprevit's a skill that takes 15 minutes to learn. maybe 30 if you include roasting your own beans. it could be taught in highschool to everyone. hardly requires a bustling industry to solve this 'problem' or provide this 'value'. starbucks is a monument to the lazyness and exploitation of this lazyness in homo sapiens. reply simgt 8 hours agorootparentprevThat's clearly the \"why\" no one pushing for innovative products is answering. A couple decades ago one salary could sustain a family in most developed countries, now it seems to be a struggle with two for many, we have mass unemployment, productivity soared but somehow society also can't afford enough cleaners to keep places decent. Is the solution really to replace even more workers by capital, or do we have an issue with how we measure value that we should fix first? reply vhiremath4 6 hours agorootparent> Is the solution really to replace even more workers by capital, or do we have an issue with how we measure value that we should fix first? I have more faith in our ability to solve world peace and AGI than I do in us getting to a more objective way to measure value that everyone can agree and adhere to. reply schmidtleonard 5 hours agorootparentIt doesn't have to be more objective, it just has to not run away. The problem with the wealth-weighted-value that gets optimized by capitalism is that the gini coefficient tips the optimization process from being about doing what other people want to being about doing what rich people want. Rich people mostly want to get paid for being rich, of course, so they pump assets to increase their wealth. Their weight goes up, the objective function pumps assets harder, their weight goes up, the objective function pump assets harder... and gini heads to 1 and you return to a palace economy. A note of optimism: we've been here before, shortly after the industrial revolution. We've fixed this before, even though Marx predicted that we couldn't. We should all be trying to figure out how to make sure that next time the USA gets neo-Roosevelt, not neo-Hitler or neo-Lenin. reply simgt 4 hours agorootparentAny readings to recommend? :) reply tacocataco 4 hours agorootparentprev> We've fixed this before, even though Marx predicted that we couldn't. Is it fixed if it falls apart in a couple generations? Maybe flex tape over the problem isn't going to cut it. reply TeMPOraL 6 hours agorootparentprevI'm afraid that \"a more objective way to measure value that everyone can agree and adhere to\" is necessary to solve AGI (as opposed to getting extincted by one), and world peace will kind of follow naturally. In other words: we're screwed. reply seniorivn 8 hours agorootparentprevefficiency and productivity is clearly more important for development of all industries than what you value. Political institutions are not very good at preparing for unfamiliar problems, dont count on them doing that. Just push for progress in natural way, and for politicians to adjust to an already happend changes. Thats the best that we can do. reply _puk 7 hours agorootparent\"efficiency and productivity is clearly more important for development of all industries than what you value\" And yet countries that value more than efficiency and productivity are repeatedly ranked as the happiest in the world [0]. \"Just push for progress in natural way, and for politicians to adjust to an already happend changes\" How much damage has unfettered tech done to society at large? Maybe we'll never know the full answer, but we can definitely agree it hasn't all been positive (advertising, social media etc..). We're now retrospectively regulating, but a lot of it feels too little, too late, for some elements of society (privacy being a notable example). 0: https://worldhappiness.report/ed/2020/the-nordic-exceptional... reply pfdietz 3 hours agorootparentPerhaps being happy is not the goal? What if the happiness isn't sustainable? reply pfdietz 4 hours agorootparentprev> we have mass unemployment We do? reply myko 4 hours agorootparentNo, not in the US at least, but society runs on vibes these days reply nobodyandproud 2 hours agorootparentprevPost-war Germany relied on cheap, foreign-worker labor instead: https://en.m.wikipedia.org/wiki/Gastarbeiter Note: The European guest worker model of the 1950s and 1960s doesn’t work for the United States, due to the birthright citizenship status. reply doctorpangloss 2 hours agorootparentprev> At the supermarket, I boycott automated self-checkouts even if the lines are long so the nice cashiers keep their jobs. I’m not sure this is Owning the Bots the way you think it is. reply Matumio 7 hours agorootparentprevI generally agree with you, if you want someone else to do the checkout for you because you don't like doing it. But if you also buy clothes only made from hand-spun yarn, I mean, it was a problem for the yarn-spinsters back then, and by all means help them. But paying someone to do something that no longer needs doing is how you create bullshit jobs. No problem with spinning yarn for recreation, but if they have to do some complete nonsense to earn a roof and a meal... there are kinder ways to help. reply TeMPOraL 5 hours agorootparent> I generally agree with you, if you want someone else to do the checkout for you because you don't like doing it. Alternative take wrt. self-service checkouts: the store is making you do unpaid labor for it. And with how it's implemented in practice, it's not only offloading work of a specialist to you, it's also costing you time and frustration, since a cashier doing checkout 8h/day on a checkout desk optimized for throughput is doing a much faster job at it than you doing it ad-hoc, in constrained space, on a machine that throws an error if you look at it funny. I'm very much for automating bullshit jobs away, but store checkout ain't it yet, and the results are universally worse. More importantly, it's a common pattern that's been inflicted on people (and ourselves) by our industry particularly often: \"automating away\" specialist jobs with software. The workload doesn't actually go away - it gets redistributed to everyone. It only looks like a win, because specialist salaries are legible to the business, while generalized productivity loss isn't. Think of it next time when a two day coding problem takes you a week, because you also need to attend several useless meetings, make some powerpoint slides, update your calendar, timesheet, and fill in expense reports from a business trip. reply Retric 5 hours agorootparentGroceries are a highly competitive market so a large fraction of cost savings end up being returned to the customer in lower prices. From my perspective self checkout is a latency optimization. The person in front of you in line may have 3 items and still take an unreasonably long time finishing the transaction, but replace one line with 4 machines and the line keeps moving. Sure I’ll take a full cart to an actual cashier, but by removing people with only a few items from those lines they become more predictable. reply TeMPOraL 5 hours agorootparent> Groceries are a highly competitive market so a large fraction of cost savings end up being returned to the customer in lower prices. It doesn't look this way from customer perspective, so I propose alternative interpretation: it contributes to hiding inflation, because instead of seeing the prices rapidly rise, we see them rise slower (further slowed down by \"shrinkflation\" and related shenanigans), but the quality of service goes down too. So what we get is ever worse shopping experience and lower inflation rates reported by economists. (Not to mention, shopping taking more time because of this \"optimization\" is effectively even more hidden inflation.) > From my perspective self checkout is a latency optimization. The person in front of you in line may have 3 items and still take an unreasonably long time finishing the transaction, but replace one line with 4 machines and the line keeps moving. It's a good reason to have both. Because in practice, 2 out of 4 machines are, at any given moment, locked and waiting for a supervisor - and many stores \"optimize\" further, by eschewing a dedicated role and just tacking responsibilities on to existing work roster. Meaning, the supervisor you're waiting for is likely staffing a checkout point or unloading boxes in the back of the store at the same time, so you better get ready to wait. Ideally, the store would have both automated and staffed checkout, and direct those with few discrete items to the former, where a dedicated supervisor would ensure problems get resolved quickly. That would indeed optimize latency/maximize throughput. reply Retric 4 hours agorootparent> It's a good reason to have both. I’ve never been to a store that only had self checkout, I think the equilibrium is one bank of self checkout + a bunch of normal registers. > 2 out of 4 machines are, at any given moment, locked and waiting for a supervisor > where a dedicated supervisor would ensure problems get resolved quickly Sounds like an implementation issue. The grocery store I typically use has one bank of 6 self checkout machines with a dedicated attendant who seems to be able to resolve any issues. It’s common for 1 or 2 of the machines be down though. They also have 4 to 14 normal checkout lines open depending on how busy the store is. I rarely use self check but it seems like a good tradeoff vs a 5th line being open when things aren’t that busy. reply imchillyb 5 hours agorootparentprevUsers of self check out are training cashier replacements. Doesn’t matter whether a person chooses self check out or cashier check out. What matters is the training. When self checkout becomes nearly as accurate as cashiers the cashiers lose their jobs. Which lane we choose has little to do with the replacement. Thousands of holdouts won’t affect the millions of shoppers training the replacements. reply wslh 6 hours agorootparentprev> Where did the economies get a boost when women joined the labor force? In Germany the post-war economic miracle happened mostly without them. I have a \"hobbyist conjecture\" that I'd love feedback on from people familiar with economics. Simply put, the idea is this: if you were to give every human around the world a million dollars (imagine this is easy and feasible), prices would inevitably rise. The poorest might experience some improvement in their standard of living, but not as much as one might expect. This effect seems to go beyond inflation alone. My intuition is that prices ultimately adjust based on social structures and expectations. Similarly, we see a unique economic advantage in many dual-income gay couples who, statistically, achieve higher standards of living. Often, this is partly because fewer have children, which shifts financial priorities and spending capacities. reply TeMPOraL 5 hours agorootparentIANAEconomist, but I've long arrived at the same conjecture; I usually phrase it as \"the market always adjusts to keep average discretionary income at 0\". So, if you give everyone in a given population (I'd go for the country instead of the world to see the effect much faster) a million dollars a month, the average discretionary income would, obviously, rise by one million dollars. That would cause prices to raise, but also all kinds of new products and services to become available. Some of those would evolve from luxuries to necessities over time - like e.g. having a car, or a mobile phone. Housing would likely eat a chunk of the surplus. In the end, it would all stabilize, at exactly the \"life is more expensive by a million dollars, on average\" point. We'd still have socioeconomic classes - poor with0 surplus, and the middle with ~0 surplus. Some people would've moved to different places on the ladder, but the ladder would still be there, simply because of variability in individual incomes. I guess put another way, you could say, the market is a DC filter - as wealth distribution in a population changes, the market always adjusts to cancel out the constant component (\"DC offset\"). reply conception 2 hours agorootparentExcept via policy you can adjust how much each percentile has. If you set a tax at 70% over a million dollars of income/capital gains/etc, and bolster lower brackets to have more income kept (eg fewer sales taxes), you can increase the amount of discretionary incomes for people where a little bit more goes a long way. It’s not like there aren’t controls available for wealth distribution. reply program_whiz 6 hours agorootparentprevYes this is common knowledge in econ supply/demand and money supply. Other currencies 1M base notes is not a lot (e.g. 1M dinar). You can just add/remove zeros but prices have adjusted, those people can't live like \"millionaires\" with 1M dinar. There was a time goods like meat cost pennies, now it's $10 per pound. In those times $10,000 would be a life-altering amount of money, today most people have $10,000 in assets. The price of goods is related to money supply, they get more expensive if people have more money. Money has no intrinsic value, it is balanced by whatever goods and services can be bought by it. If you add money but no goods and services, money is worth less (see COVID policy, increase money and decrease goods and services). reply wslh 5 hours agorootparentThank you! The COVID policy example feels especially relevant because it illustrates the kind of sudden economic shift I'm curious about, rather than just changes in nominal currency values. To clarify my thought experiment: imagine a stable economy where suddenly every person worldwide is gifted $1 million USD. I'm interested in exploring how this kind of immediate influx would impact prices and standards of living, beyond just inflation. reply staunton 5 hours agorootparentIf every person is giftet USD1M, prices of all things will go up by a lot. Furthermore, prices of necessities will rise by larger fractions because most people in the world are significantly poorer than the median of this forum. More generally, gifting every person worldwide the same amount of money seems roughly equivalent to taxing every above-average wealth person a fixed percentage of their surplus and giving every below-average-wealth person a fixed percentage of their deficit... reply cousin_it 4 hours agorootparentI think that's not quite true, because rich people mostly keep their wealth in assets, not cash. Stock will just rise. reply skobes 2 hours agorootparentprevYou're right of course, except I wouldn't say it's \"beyond inflation alone\" - it IS inflation by definition. It's beyond the usual level of inflation, but that doesn't make it a separate phenomenon, you've just caused a shit ton of inflation to happen by giving everyone a million dollars. reply seniorivn 8 hours agorootparentprevyou should also try to avoid cars and electric lights, grooms and gas light maintainers need jobs too reply ajkrgh 8 hours agorootparentnext [2 more] [flagged] vasco 6 hours agorootparentAnd then what, conclude that a useless action to delay progress is somehow good and allows you to feel better about yourself and superior to others using self-checkout while doing absolutely nothing? If that's the outcome of \"classic education\" I think you didn't do it right. reply doctorpangloss 2 hours agoparentprevThese Physical Intelligence guys are very talented, but they will never raise enough money to achieve their goals. Their problem is saying it costs $30m to develop such a technology, when it will cost at least $1b, and probably closer to $5b. reply PostOnce 9 hours agoprevFor factories and closed environments, stuff is getting good fast, but for the rest of the \"real world\", no robot or AI is practical without human supervision. I automate physical things for a living and have thus become convinced. The first thing that robot will do is start a dryer that a toddler climbed into because it isn't that aware of the world around it. And that will be the end of general purpose domestic robots. That or knocking over candles or fucking up something else simultaneously trivial and terribly dangerous in context. I dream the same dream of a general purpose machine, but I think it may never be possible, and if it is we're a long way out. reply chilmers 7 hours agoparentI recall reading many comments on HN confidently predicting that the moment a self-driving car caused an accident that killed someone, that would be the end of self-driving cars. But while they have caused accidents, and there has been resulting lawsuits and investigations by regulators, it hasn't put an end to them. And with the incoming US administration, I'm expecting far less legal and regulatory barriers to greater use of robots and automation. reply dtnewman 6 hours agorootparentTo be fair, many many people die in car accidents every day. Yes, self driving car crashes are still newsworthy but you are up against a baseline that’s pretty bad. On the other hand, virtually no one dies from laundry, that I’m aware of. So the reaction to a single accident might be quite different. reply HappyPanacea 6 hours agorootparentI found one instance from quick search: https://www.rnz.co.nz/news/national/483581/child-s-death-in-... and there is also many stories of dead cats online. reply tacocataco 3 hours agorootparentI was so paranoid when I lived with cats. I'd double check the washer and drier. reply isoprophlex 6 hours agorootparentprevI do remember that time where people were being manipulated into eating Tide Pods... https://en.m.wikipedia.org/wiki/Consumption_of_Tide_Pods reply PostOnce 6 hours agorootparentprevDying in a car accident is normal, but having your (robot) maid kill your children or burn your house down is not. I think that will weigh on people's opinions of domestic general purpose robots when compared to robotic cars. reply chilmers 6 hours agorootparentDying in a domestic accident like a house fire is as \"normal\" as dying in a car accident. Robots are a novel element in both, so I don't see why one would be more readily accepted than the other. reply mikeyouse 3 hours agorootparentHouse fire deaths are at least an order of magnitude less common than traffic deaths and houses are the most valuable asset that many people will ever own. They’re certainly similar but I think different enough that people would have very different reactions to robot-caused destruction. reply TuringTourist 4 hours agorootparentprevThe domestic accident is in the home, a far less acceptable place to have a threat. Furthermore, the threat/cause of the accident is presumably being visualized as a human shaped live-in android a la Bicentennial Man. A human shaped threat can feel a lot more viscerally unacceptable, at least in my experience. reply user90131313 9 hours agoparentprevHow about at first if we put camera on it and then someone from overseas checks around before performoning the task? for cheap but it can make it secure. reply TeMPOraL 8 hours agorootparentSci-fi authors were worried about rebellions of enslaved robots, while the industry figures, why risk jumping into the unknown, when we can fake a smart computer with overseas labor and an Internet connection, and wage slavery we know how to handle... Anyway, if we're going to fake smart robots this way, why not just honestly call it what it is? Remote household staff. Might as well give them better sensors and actuators, but I guess this is giving humans too much agency and risk; what if the operator decides to hurt the \"robot\" owners or something? The vendor would not have that. Cannot have that. Humans are too messy to deal with. Or is this the short-term future of all automation? I look at my robotic vacuum cleaner now, occasionally pausing for a second or two while it figures out where to go, and I wonder - maybe in those moments, it's using some Protein Intelligence Chip to query a bunch of random humans somewhere? reply wegfawefgawefg 6 hours agorootparentI trust an ai model more than remote humans. reply unsupp0rted 8 hours agorootparentprevI’d rather not have someone from overseas walking around my home via remote cameras reply user90131313 8 hours agorootparentMany chooses Amazon and Google to listen their home + record their home every day. Most customers just buy things. reply tantalor 3 hours agorootparentprevAI = actually Indians reply cruffle_duffle 1 hour agorootparentAI, the secret sauce that powered Amazon Fresh (or was it Amazon Go?) reply user90131313 3 hours agorootparentprevBetter than Alexa recorder reply HumanReadable 8 hours agorootparentprevat that point, why not just have someone from overseas control the robot? reply rvnx 4 hours agorootparentThis is what happens with \"autonomous\" delivery robots that are operating on London campuses. They are actually controlled by \"robot operators\" in Estonia, though officially it's \"AI\". That being said, every day it's getting a little bit better. reply vasco 6 hours agorootparentprevBecause you can just have actual local people do it right there and then? The point of a robot is to not interact with other people, presumably they will be much more expensive than having someone come over for a few hours a week to clean - the whole appeal is there's no other human involved to coordinate or be nice to. reply elsewhen 6 hours agorootparentprevBecause one remote overseas person can watch multiple camera feeds at once which should make the cost of a human-in-the-loop more palatable. reply HumanReadable 5 hours agorootparentmm, good point! reply TeMPOraL 7 hours agorootparentprevLiability. reply rwyinuse 3 hours agoparentprevI agree. So far I haven't seen production-ready robots doing even relatively simple agricultural tasks, such as picking tomatoes in a greenhouse and taking care of the plants. It's all done by cheap foreign labour. If that's too hard to automate, I'm not yet holding my breath for general purpose household robots either. Admittedly the videos in this article do seem promising though, would love to see how this tech would perform in a greenhouse. reply ac29 2 hours agorootparent> So far I haven't seen production-ready robots doing even relatively simple agricultural tasks, such as picking tomatoes in a greenhouse and taking care of the plants. It's all done by cheap foreign labour. While they aren't widespread, there are production robots being used in many types of agriculture. In fact, it was even trivial to find one working in tomato greenhouses: https://www.arugga.com/technology (this one is used to pollinate tomatoes instead of doing it by hand or using bees). reply moffkalast 5 hours agoparentprevEven if they need supervision, watching a robot hang up the laundry to dry is better than having to do it yourself. Like that old quote: \"I love work, I can watch it all day.\" reply GistNoesis 8 hours agoprevThe hard problem for a laundry robot is not folding the clothes, it's getting into the laundry room. Living in European city, space is a hard constraint. The cost of rent is 30€ per square meter per month in Paris. Laundry rooms are small. This robot is too wide and won't be able to go through the door of my laundry room. Ironing boards are foldable for a reason : they need to be setup every time. This robot can't do it, and also can't handle the softener bottle for the washing machine. Having 1 square meter empty table (0.5 for the table and 0.5 accessible space for the robot doing the folding) dedicated to folding is a pipe dream for most. Laundromats are there because some don't have enough space to even have a washing machine. Laundry room are a dedicated space for humidity and ventilation reason, so they have been designed on specific location on house plans probably more than 30 years ago on average, not having in mind robot accessibility, but rather be as small as functionally possible. Quite often for people not living in flats, but in houses, the laundry room is located in the basement with only stair or single step access. I don't think architect and construction accessibility norm will change fast enough, specially with bipedal robots right around the corner. The slack necessary for home robotics emergence has already been eaten multiple time due to the high cost of space. reply jazzyjackson 4 hours agoparentLaundromats are kind of a drag since you have to hang around nearby for almost 2 hours to do the 5 minutes of labor that the machines don't do for you. Dropping off a sack of clothes for wash & fold on the other hand is a pricey luxury. Perhaps if the laundromats could automate the whole process it would bring down the price of wash and fold and fewer people would be inclined to have washing machine at home (as you say, taking up space for a machine that is used a couple hours a week) Alternatively you can simply attach the laundromat to a cafe or bar, turning a chore into an opportunity to relax and socialize but most of the world is not prepared for that degree of civilization. reply blagie 7 hours agoparentprevIf you scroll down, this is a general-purpose robot. It can drive around and bus the table or fold a cardboard box. I'm not sure it can't handle the softener, and V2 will likely be able to set up the ironing board. In terms of size, even now, it's smaller than a fridge, washing machine, dishwasher, or many other household time-saving appliances common in most houses (although not necessarily historic cities with multi-century homes not designed for them). No effort has gone into shrinking it either; perhaps with clever engineering, it can be made much smaller if it moves out of the research prototype phase. Another question, to me, is cost. Many robots like this run around $100k, and with good reason. Can this be brought down? I hope so. reply GistNoesis 6 hours agorootparentThe water bottle is usually a common hard test for robots. The softener bottle raise the stakes even more. Because every time I handle it, I need to wash my hands afterwards. Ironing board is bigger than the robot, and quite heavy, the torque in setting it up is a lot and probably greater than the torque necessary to break the expensive actuator when things go wrong. Keeping a shared table clean so you can fold clothes on it is a not trivial but more manageable problem. The home market is highly predatory. If people have enough to invest in a home robot, it means that they have some available money that other actors didn't grab. In France last time they remove 5€ per month of renting help, it was a struggle for lot of people. You have lots of actors that call dibs on your home improvement money before you can improve your home. There is usually the landlord, then the building manager (or Home Owner Association) (which is usually already working in the kleptocracy domain), then there are local tax, and mandatory ecological improvements (thermal isolation, and windows), home improvement market (paints and kitchen), and of course everything is indexed on the current cost of energy, and uncontrolled inflation. It's not a question of costs, otherwise all smart investment improvements that bring more than they cost on the relevant time-scales like thermal isolation and solar power infrastructure, collective infrastructure, not having to do the laundry every week..., would have been done already. It's more about determining who deserve the money. reply blagie 5 hours agorootparentI don't use fabric softener, but that's a solved problem. The laundry machine I have takes both laundry detergent and, if I used it, fabric softener and dispenses those by itself. Actuators, competently designed, won't break when torque gets too high: 1) The control system can handle this, trivially. 2) The mechanical linkage can be designed to limit torque. At some point, it should slip. 3) Forces out-of-axis should not be transferred to the actuator The kleptocracy is more a function of rent-seeking city living. Even a little ways out, into the suburbs, things are very different. Rural, and space is virtually free. reply GistNoesis 3 hours agorootparent>Actuators, competently designed, won't break when torque gets too high The mechanical part of robotics is quite challenging. Because of the overhangs, 6DOF arms usually are bulky to be able provide useful force. Alternatively too strong industrial robots are unsafe to operate near humans even if compliant. But most probably even robot building startup can't even attempt it. (They are not looking for mechanical engineer in their job listing, so probably they don't design the robot arm themselves). If you don't design the robot arm yourself, then you only have the option of which off the shelf actuators to pick. Usually they are weak and expensive. And how to integrate them while staying in specs. For manipulation sensory input is very useful, but if the API of your robot arm doesn't provide the feedback you do with what you have. When forces are weak closed-controlled loop system don't flex and can know their position, when things flex and deform, it allows to have lighter arms, but the robot can't know it's internal state. Here they close the loop via visual feedback, so knowing position exactly is not so important : humans have shitty repeatability but handle folding the laundry quite well. But shitty robot arms are not very useful and also need the same motors and controls that good robot arms, so you might as well make your task easier and develop your robot with expensive arms first so prices converge towards expensive robot arms, and the economics equations of this market (high R&D cost, low sell volume) are geared not for home applications but industrial control which usually necessitate maintenance operations on the robots themselves. What's even worse for the business model, is that once you have spend money to gather data and build a dataset to teach your neural networks, then your competitors only have to copy, vertically integrate, improve, scale and grab the money pot. One of home robotics main obstacle is a https://en.wikipedia.org/wiki/Collective_action_problem where no one wants to front the costs of building the datasets, front the costs of cheap actuators, front the costs of cheap prototypes so everyone reinvents their own solution which can't solve the economic equation. reply blagie 2 hours agorootparentGood point. When I was younger, I'd have argued the collective action problem is just a matter of time and development, but I've now seen dozens of technologies stalled out. I firmly believe it's the reason we don't have flying cars. I can sketch out all the pieces needed to get there, which in the simplest-to-explain version consist of a few regulatory changes, an autogyro, a control system, and some infrastructure, but those few changes easily add up to an obscene amount of money. Once invested, the next competitor can do almost the same thing almost out of a garage. Lots of medical technologies too. And medical systemic changes. Education too. reply plopilop 7 hours agoparentprev> The cost of rent is 30€ per square meter per month in Paris. Only for big enough apartments. 20m² appartements do not go for under 850€, ie around 42€/m². Granted these flats are too small to even have a laundry machine, let alone a laundry folding robot. reply scotty79 7 hours agoparentprevWhy would you think a laundry robot is something people who can't afford comfortable apartment with their own washing machine might use? I think this might be eventually integrated with washing machine so that you buy one device where you put your dirty clothes in and take out clean and folded. It's not like the traditional washing machine is the expensive part that needs to be kept separate and in current form. reply tomohelix 11 hours agoprevGet it a bit better in term of precision and we have a killer lab automation tool. Labs around the world would be willing to pay 1M for a robot that can handle manual lab works and it is not like they are very difficult. Lots of labwork is based on established protocols with well defined steps. A robot that can grab things and go to town on those tubes without any programming needed is a blockbuster product to me. reply bubaumba 12 minutes agoparentDon't expect much. Even screwing a nut on a bolt is a huge problem for generic robot. Which means you will need a 'robot friendly' lab. Were all things can be done by a primitive robotic hand. Other options are making more capable hands, and completely robotic specialized labs. The first is most interesting and the way to go. When it happens it will open a lot of possibilities. Like \"self-repairing\" vehicles and planet stations. Just with 'technician' robot onboard. reply NoLinkToMe 10 hours agoparentprevAgreed, my girlfriend has a biochemistry degree and works in such a lab. It involves some physical work like collecting, preparing and inputting samples, doing basic maintenance of the machines, some analysis and then some administrative/secretarial work in feeding the results into a system or by phonecall to the doctor. All of which can indeed be automated in my view. I would say it really depends on where you are though. In the US it probably makes sense quite quickly. But she lives in a small EU country where salaries aren't high, and this is very much a junior position with a lot of students looking for such a job. Her position costs about 25k a year. The NPV of a $1m investment with a 25k cashflow is negative at normal discount rates. Once you get to replace a $120k salary with a $1m robot, it does make sense. Further I do still expect there to be some jobs in overseeing the robot (e.g. your average factory manager). That makes sense for large centralised production locations, because you can have 1 human job overseeing many robots. It doesn't necessarily make sense with many small decentralised production locations. And that's the nature of most labs, I believe due to the time sensitivity of a lot of lab work they need to be everywhere and close to customers. But maybe that will change. reply ValentinA23 5 hours agorootparentIt wouldn't cost 1M. The BOM[1] of Stanford's Mobile Aloha[2] (very similar to physical intelligence's robot) is around $30,000. [1]https://docs.google.com/document/d/1_3yhWjodSNNYlpxkRCPIlvIA... [2]https://mobile-aloha.github.io/ $7000 for the wheels/navigation module $3500 x2 for the control arms $6000 x2 for the controlled arms I don't think you need a $7000 navigation module and the arms are also probably overkill. To which extent do we need closed-loop Dynamixel servos when the policy diffusion algo already relies on computer vision driven closed-loop control ? reply llm_trw 10 hours agorootparentprevKeep in mind that workers in the EU work for around 6 hours a day, a robot works for 24, so it's replacing 4 of them, not 1. reply NoLinkToMe 8 hours agorootparentGood point, although it probably won't be 4 for most labs, perhaps 2. My gf does 1 nightshift a week and she is alone in the lab for the 3-4 emergency samples that come in (versus a team of people processing hundreds during the day), there simply isn't much demand at night. Most blood sampling has a human pipeline of people going to their doctor or hospital with an issue, getting blood taken, which is sent to a lab, the majority of that during the day. Again for large scale centralised labs that get sent samples throughout the 24 hour period from all across the world, where timing isn't an big issue, this could work. But most labs are small, close to the customer, time-sensitive, and work with couriers to bring samples because samples need to be transported and stored in specific ways not to go bad. She works quite long shifts btw (10-12h), but that's more a function of her country/company culture rather than the norm. Probably 6-8 is more common indeed. reply vidarh 7 hours agorootparentHow much of the timing on samples is down to lab availability, though? E.g. my gp wants samples in by 1pm because otherwise they'll got to the lab the following day. If the lab would still process things that came in at the end of the day, I could very much see larger doctors offices sending off samples more than once a day, with the last one coming in after the end of their clinics. I could see demand spreading out more - though I agree it might be closer to 2 than 4 - if the availability of human labor wasn't an issue. reply kaplun 9 hours agorootparentprev6? Not 8? reply Krssst 3 hours agorootparentI was surprised too but I guess OP included the weekends too since robots don't need those off. So 40 hours divided by 7 days. reply bottom999mottob 9 hours agorootparentprevAssuming a lunch break is not included as part of 8 hours, do you really think most exmployees are productive for a full 8 hours? Most office workers spend an exorbitant amount of time twiddling their thumbs, reading emails, going to the restroom. On average, I'd say knowledge workers are typically productive for about 2 to 3 hours per day. I'd estimate physical laborers range up to 4 or 5 hours. Assuming 8 hours of full productivity is a strange number to focus on reply llm_trw 9 hours agorootparentprevLunch and breakfast are serious business. reply muspimerol 9 hours agorootparentHuh? The average working week in the EU is 37.5 hours a week, or 7.5 hours a day: https://ec.europa.eu/eurostat/web/products-eurostat-news/w/d... Breakfast and lunch are not paid breaks in any EU country as far as I know. reply Ekaros 7 hours agorootparentIt really depends. For Finland lunch is unpaid unless you are forced to eat at premises. But then you usually have 2 refreshment breaks (10-15min) which are paid... reply Gare 9 hours agorootparentprev> Breakfast and lunch are not paid breaks in any EU country as far as I know. One 30 minute break (lunch break) is paid in Croatia and Slovenia reply bagels 10 hours agorootparentprevProduction version of these robot arms would not be anywhere near $1m reply Falimonda 10 hours agorootparentThat seems to only account for the hardware. How much do you reckon a software license will cost for your fleet of cheap arms? reply csomar 9 hours agorootparent> That seems to only account for the hardware. How much do you reckon a software license will cost for your fleet of cheap arms? Just a bit lower than what a human would cost. reply notatoad 1 hour agorootparentsignificantly lower than what a human already doing the job would cost, until the VC money runs out. And then a whole bunch more than what a human would cost, after they've got you locked in and you've let your staff go. reply amelius 7 hours agorootparentprevRemember though that AI is a winner takes all space. It will probably be won by a company with lots of cash behind it (like this one which has support from many companies, including OpenAI). reply thanksgiving 9 hours agorootparentprevI got really excited for a second for people who need to work on a lab thinking they will be able to work from home now... reply doctorpangloss 2 hours agoparentprevThis lab automation product already exists and the couple of startups in this space face the same headwinds as everyone else trying to sell hardware when the stuff people are essentially really paying for is software. Also nobody’s academic lab is buying $1m startup lab equipment. A whole core for 30 research groups is buying something, but it will be a piece of equipment that directly leads to publishing, ie, something with history. That is why you don’t have the exact thing you are talking about, which exists, in labs. reply amelius 7 hours agoparentprevCertainly. I have a friend working in this space (AI lab automation). In a few years he expects competition to be fierce, though. reply M4v3R 9 hours agoparentprevAlso worth mentioning that a lot of stuff in chemistry labs is toxic and even potentially deadly to humans, it would be a big win if these could be handled by robots instead. reply bottom999mottob 9 hours agorootparentThat reminds me of Dr. Greenamyre in Pittsburgh who thinks he accidentally gave himself Parkinsons researching rotenone in pesticides [0] [0] https://youtu.be/7mYEqUrx6dQ?si=x4P6pkUCd7EvCe1N&t=152 reply pzo 10 hours agoprevI like that their robot is pretty simple comparing to humanoid robots so cost should be much lower. I don't get it why focusing on clothes folding though, does anyone do laundry more often than once a week? Much more useful if it can do cooking since that's something you do at least once every day. Instead I would like to see some new innovation in laundry machines. Current technology is very basic, you heat water and keep spinning. Why not some something more similar to bigger paper printer that at the end of the day you feed your 1 shirt, roll it into a roller, sprinkle with some high pressure minimal amount of water, heating and return 30min later already perfectly ironed. reply saulrh 9 hours agoparentLaundry is kind of the perfect demo for advanced motion planning systems. Fabric is, for all intents and purposes, completely intractable in classic motion planning paradigms; it's wildly non-rigid, which means that predicting its behavior is the domain of highly specialized and expensive dynamics simulators, it's nearly impossible to invert the problem to ask what motions would be required to produce a given result, and it's highly continuous and resistant to discretization even if you can predict it. You can't make the \"folds have zero width\" assumption you always see when reasoning about origami, for example. Clothing is extreme even for fabric, given that it's not only highly non-uniform but also fragile; every shirt is a different hideous bit of floppy topology covered in strange textures with complex and unpredictable local properties and it'll start popping stitches if you look at it funny. Ruffles, zippers, pockets, drawstrings, the list goes on. On top of that, laundry is something that everyone does so it's relatable and easy to set up in a lab, and humans can intuitively evaluate performance with a glance. Despite all the attention, nobody's been able to demonstrate convincing performance on it in like seventy years of work, which makes it a more difficult task than backflips or shooting hoops or loading a truck. All of that together means that, when you have a fancy new algorithm that can handle more than some blocks on a tabletop, you pretty much always point it at the laundry. reply YeGoblynQueenne 3 hours agorootparentAnd just to be clear, this is still not \"convincing performance\" since it is still the WYSIWIG model of robotics in the sense that it can only do exactly what you see it doing in the videos. It can fold a couple of shirts and a pair of pants and wouldn't, e.g., be able to fold my hoodies, never mind a bra or something else with straps. The big advance here seems to be that the robot can pick the clothes out of a basket on its own rather than having someone set it all up neatly for it. I mean they sort of imply it here but you have to read carefully to understand what they refer to (folding a t-shirt that hasn't been laid flat on a table first): Laundry. We fine-tuned π0 to fold laundry, using either a mobile robot or a fixed pair of arms. The goal is to get the clothing into a neat stack. This task is exceptionally difficult for robots (...and some humans): while a single t-shirt laid flat on the table can sometimes be folded just by repeating a pre-scripted set of motions, a pile of tangled laundry can be crumpled in many different ways, so it is not enough to simply move the arms through the same motion. To our knowledge, no prior robot system has been demonstrated to perform this task at this level of complexity. reply M4v3R 10 hours agoparentprev> I don't get it why focusing on clothes folding though, does anyone do laundry more often than once a week? Folding laundry is not the end goal here. They chose it because it’s a very challenging thing for a robot to do, requiring great manual dexterity, planning, reacting to sensory inputs etc. In other words: if your robot can do your laundry it can probably be taught to do pretty much anything else around the house. reply TeMPOraL 7 hours agoparentprev> does anyone do laundry more often than once a week? Once you have a nonzero amount of kids, laundry becomes a continuous process will no defined start and end. > Much more useful if it can do cooking since that's something you do at least once every day. Thing is, cooking is something a lot of people find deeply rewarding and humanizing (I don't, but I realize I'm an outlier here). Meanwhile, I challenge you to find anyone who thinks doing laundry is a worthwhile use of their limited time on Earth. reply pzo 1 hour agorootparentMy point is from business perspective cooking is much bigger market since this applies to B2B as well (commercial laundry is not as big) - many restaurants would happily buy such robot and pay even more than typical home user. I also think solving cooking is simpler task than folding any types of clothes - they could even simplify further by focusing first on making burgers/pizza/sandwich/kebab only and be profitable much faster. reply cruffle_duffle 58 minutes agorootparentprev> Once you have a nonzero amount of kids, laundry becomes a continuous process will no defined start and end. Pretty much this. You’ll be folding clothes while washing more at the same time. And it isn’t just the folding that is a challenge. It’s putting it away. I’d gladly take a “put the clothes away” robot before I got a “fold the clothes” robot. reply averageRoyalty 9 hours agoparentprev> I don't get it why focusing on clothes folding though, does anyone do laundry more often than once a week? Much more useful if it can do cooking since that's something you do at least once every day. Lots of people do 3-4 loads per week. Some people don't cook at home at all. There are 8 billion people out there. reply pzo 1 hour agorootparentSome people don't cook at home but they still have to eat. Restaurants still have to hire people for doing cooking tasks. reply semi-extrinsic 9 hours agoparentprev> does anyone do laundry more often than once a week I can tell you do not have children. We frequently run 2 loads per day... Also, I challenge anyone to look at that video from 2:00 to 2:45 (which is 90 seconds IRL) and tell me with a straight face this has anything to do with \"intelligence\". I have seen human babies at 5 months old severely outperform this thing. reply vasco 6 hours agoparentprevI got myself this perfect clothes folding robot about 8 years ago when I decided I would not fold or iron clothes ever again. Two useless activities forever gone from my life. There's more things like this around the house but folding and ironing are 100% useless. I pick the clothes from the rack, they come kinda folded in half but I don't even try, and all get dumped into drawers. I never lack space because I'll buy clothes only upon throwing out clothes, so the bigger volume of the clothes doesn't make a difference in storage space either. reply tacocataco 3 hours agorootparentI just leave the clothes on the rack. I can see what I have better and my clothes smell better getting aired out more compared to sitting in a drawer. This also means I use less floor space as I don't need cabinets/dressers to hold them. And yes, I have many racks on my walls. The rack life is good. reply vasco 1 hour agorootparentThat sounds like a great setup, my place had inbuilt ones but that's the spirit. reply lotsofpulp 9 hours agoparentprev> does anyone do laundry more often than once a week? Yes, at least 3x per week. Young kids, toddlers, babies, workout clothes, sports clothes, work clothes, etc. reply bitwize 9 hours agoparentprev> I don't get it why focusing on clothes folding though, does anyone do laundry more often than once a week? Much more useful if it can do cooking since that's something you do at least once every day. Because the people on the Axiom are going to need clean jumpsuits? Seriously, laundry folding is an example of a complex task that requires considerable dexterity and sophisticated object manipulation on the robot's part, but unlike cooking it's relatively low stakes: little harm is likely to be caused to the robot, the environment, or bystanding humans if the robot screws it up. So it makes a pretty good research task that, when solved for, will make impressive demos at trade events. reply rgbswan 9 hours agoparentprevSmall businesses like Cafes? They will hopefully get this to laundromats once this bot can iron, too. Not even once did I iron or fold my laundry back in university ... reply sebastiennight 6 hours agoprevI know very few people under 40 who fold and iron clothes, and I'm not sure I know people under 30 who own an ironing table and iron (or if they own one, it's busted, and if it's not busted, it's lost). I think \"doing the laundry\" is getting obsolete faster than doing it yourself is. Kind of like people didn't give up on sewing their damages clothes by hiring a robot to do it... they gave up by throwing old clothes away and switching to fast fashion. If this product addresses high-income people (which would probably be the case even if the price comes down from $100k to even $1k), then it still seems a lost cause for this reason. reply SamoyedFurFluff 5 hours agoparentFast fashion clothing increasingly cannot be ironed. But also it’s increasingly hard to buy good quality clothes because of the influence of fast fashion. Even very expensive designers will have shit like unlined coats or thin sweaters. Part of this is that the supply chain for good quality clothing has been greatly reduced. Even if you wanted as a designer to acquire good quality fabric, you have to pay more for it than you used to. reply Animats 11 hours agoprevOn HN 9 days ago. https://news.ycombinator.com/item?id=42011770 reply d-lisp 2 hours agoprevThere is something funny in the way it performs some of the moves in a sub-optimal manner. It reminds me of cats playing with small objects (earings on a beside table...). This is still quite impressive. reply psychoslave 7 hours agoprevSo we will have robots building and making corve there, while humanity focus on making smart policies through continuoys education for all and involvment in direct democracy. Or maybe we will have private army robots under the order of some random dictator disconnected from the reality of people. Or some mix of these. Or finally no longer any war, in a world without any human though. What a time to be alive. reply llm_trw 10 hours agoprevFascinating work. I never thought about what we could do if instead of trying to do work in real time we slowed robots down for non time critical tasks to latencies which current transformers can deal with on real hardware. reply 082349872349872 8 hours agoparentvon Neumann, Theory of self-reproducing automata (1966) p.72 \"Role of High Complication\": > An automaton can not be separated from the milieu to which it responds. > The characteristics of a human for survival are well defined on the surface of the earth in its present state, though for most types of humans you must actually specialize the situation a little further than this. But it is meaningless to argue how the human would survive on the bottom of the ocean or in a temperature of 1000 degrees centigrade. Similarly, in discussing a computing machine it is meaningless to ask how fast or how slow it is, unless you specify what type of problems will be given to it. reply joduplessis 8 hours agoprevMan, watching that robot struggle with that green shirt made my eye twitch. reply sawmurai 9 hours agoprevMaybe someone in the HN crowd knows that: Why are these robots moving so slowly? Is it for safety or does speed increase the difficulty significantly? reply amelius 8 hours agoparentMy guess is that speed is not their first concern. reply imtringued 6 hours agoparentprevThey are using a vision language model to generate the robot motions token by token. They are being bottlenecked by the inference of the VLM. reply macrolime 8 hours agoprevPretty sure that once the pre-trained models used for this are pre-trained on lots of video and get larger (2-3 orders of magnitude larger than this), things will quickly improve. This may already exist in prototype form behind closed doors. Think how LLMs have improved since gpt-2 and gpt-3. Though I imagike it in real-time and cost efficiently may be a challenge. reply risyachka 8 hours agoparentLLMs literally barely improved since gpt3 reply Philpax 7 hours agorootparentBe serious. Go retry GPT-3 and compare it to Claude Sonnet and come back here. reply ribcage 8 hours agoprevLet's automate everything, so we don't need to do anything just lay in our bed. reply tacocataco 13 minutes agoparentPeople should be free to enjoy life their way. Including if they want to be grandpa Joe from willy wonka. reply cruffle_duffle 1 hour agoprevFolding the laundry is “the easy part”. The actual hard part for me is putting it away. You can fold all you want but it does no good unless it gets put away into whatever closet/drawer configuration you’ve got. reply jonplackett 9 hours agoprevFinally someone teaching AI to do all the stuff I _dont’t_ want to do. reply qnleigh 10 hours agoprevIs my knowledge out of date, or is this a step change in robotics capabilities? Boston Dynamics robots are impressive, but this seems way beyond what their robots have been able to do. reply authorfly 10 hours agoparentIt's not really a step change. Saycan demonstrated similar functionality with PaLM 2 years ago (2.5 years first demo of cleaning up coke cans, etc): https://www.youtube.com/watch?v=Ru23eWAQ6_E Caveat - I am way out of my depth here as I focus on Software AI, but: I can't see any major breaks from SayCan looking at this information. When studying robotics, Degrees of Freedom/basic Arms and mechanisms (tension, grip, extension, types of joint etc) are a typical case study. However, I do not think there has been any practical progress (with the lack of data) in about 20 years now, besides increased refinement from materials science (e.g. detection of soft materials) allowing some better grip but not particularly better dynamic movement(e.g. walking remains badly solved compared to the efficiency/mechanism of humans). reply Falimonda 10 hours agoparentprevIt's certainly an expansion of software capabilities with respect to what Boston Dynamics typically highlights in their videos. With that said, Boston Dynamics is likely to have their own version of this in the works if not already live. They're videos just tend to highlight advancements in both hardware and software that are likely to go viral and connect with non-technical viewers. You can already see it in some of BD's latest videos. reply fragmede 9 hours agoparentprevThe trouble Atlas had taking the car parts off the slotted shelf makes it seem like they're quite a bit further away, given the hand dexterity it takes to fold clothes. reply ValentinA23 5 hours agorootparentFolding clothes is a special task. Other prototypical tasks that are used in robot benchmark: - changing a bike chain - closing a jacket's zipper reply Falimonda 9 hours agoprevHow long before we see this running on a fleet of excavators? reply seydor 9 hours agoprevThese things can be huge for agriculture reply LoganDark 3 hours agoprevLove to see mecanum wheels being used here. They're so much rarer to see than they should be! I go months to years between each instance of seeing them. reply wiz21c 10 hours agoprevYeah, one thing is for sure: the robot has actually understood that it is very boring to do the laundry. Proof ? Just look at how it botches the d*n task :-) I mean, I would never ever pince a t-shirt so bad :-) reply JumpCrisscross 10 hours agoparentI hate doing laundry. Everyone gets one task they get to abhor. Mine is laundry. If I could buy this in a few generations for less than $20k, I would, pinches and all. Perfect is perfect. Good enough is good enough. reply anonzzzies 8 hours agorootparent$20k... Doesn't that buy a lot of serviced laundry? I am unaware about prices in the rest of the world, but 20k is more than a lifetime of having my laundry picked up and ironed every week (which I do as I too hate laundry). reply JumpCrisscross 3 hours agorootparent> $20k... Doesn't that buy a lot of serviced laundry? In my neck of the woods it costs a couple years of the cleaner dropping in every week or two. In New York, maybe a couple more years, albeit with the added burden of having to pick it up and drop it off myself. reply transfire 4 hours agoprevThey need better hardware. Show me a robot that can button a shirt. reply gigel82 14 hours agoprevNice, finally some AI functionality I could actually use. reply light_hue_1 9 hours agoprevThis robot cannot \"do your laundry\". It is the same toy as always in robotics. It works in very specific environments, with very specific laundry, as long as no one gets in the way and nothing bad ever happens, you've trained it to do your laundry, you never buy anything unusual, nothing gets tangled too much, etc. They have an extremely specific definition of the word \"laundry\". Three specific shirts of size M, L, and XL, and two pairs of shorts of size 28 and 36. Then they do a mobile task on three specific shirts of size M, M, and XL, and two shorts of size 32 and 31W. That's not \"laundry\" the way any lay person would understand. It's sad to see yet another group hype their work for money. What they did do, is invest a tremendous amount of engineering effort to scale things up, to collect data, and to see what changes models need to scale well in this space. That's nice and useful. It's something that as academics we generally cannot afford to do. And won't be able to afford any time soon because they don't share their data and none of their results are reproducible. PS: Where is this title from? \"Physical Intelligence's first generalist policy AI can finally do your laundry \" It's not in the article. It's very misleading. reply YeGoblynQueenne 4 hours agoparentMwell, the robot picking out the \"laundry\" from a basket next to the table is slightly more than I've seen before so at least they managed to combine two tasks that would previously be considered distinct (although note the very lengthy attempt to pick a corner of a green shirt in the \"3x video\" further down the article, which I think is the most honest of the bunch). I agree this is still a tech demo showing a prototype robot solving a toy task. As usual we're supposed to think \"if it can do that then it should be able to do this\" but it never works that way in reality. reply Terretta 5 hours agoparentprevNo intention to mislead, but to fit their gist into an informing title. I was originally linking to X, describing their tweet with laundry vid, then changed to point to their source blog post, where their title doesn't fully convey the content. So this title is firm name and blog post title, adding the \"laundry\" from their hero video under the title and featured video on their x.com post that links to this blog post, as well as the first featured/labeled \"Laundry\" task discussed in body (not to mention, answering HN commenters such as this, since \"doing the laundry\" is by now a meme): > I’m still waiting for a neural net that can do my laundry. -- sheeshkebab 11 hours ago - https://news.ycombinator.com/item?id=42098153 The response to this, portrayed in both blog post and x.com feature videos, is in the third sentence of the blog post: To paraphrase Moravec’s paradox, winning a game of chess or discovering a new drug represent “easy” problems for AI to solve, but folding a shirt or cleaning up a table requires solving some of the most difficult engineering problems ever conceived. To build AI systems that have the kind of physically situated versatility that people possess, we need a new approach — we need to make AI systems embodied so that they can acquire physical intelligence. The synthesis is, this is about “doing your laundry”. Finally, to take it out of air quotes, the article's first explicit and bold labeled text task description is: LAUNDRY. We fine-tuned π0 to fold laundry, using either a mobile robot or a fixed pair of arms. The goal is to get the clothing into a neat stack. This task is exceptionally difficult for robots (...and some humans): while a single t-shirt laid flat on the table can sometimes be folded just by repeating a pre-scripted set of motions, a pile of tangled laundry can be crumpled in many different ways, so it is not enough to simply move the arms through the same motion. To our knowledge, no prior robot system has been demonstrated to perform this task at this level of complexity. They hold they have demonstrated this robot doing the laundry. reply imtringued 6 hours agoparentprevSure, what you said is somewhat true, but you have seemingly misunderstood one key aspect here. They simply do not have enough training data to fold all possible laundry. If there was a way to fine-tune the robot on your own clothes, then it would be able to do your laundry just fine. You're under the mistaken impression that this is just a scripted demo built around learning directly from teleoperation as was the case with mobile aloha. The VLA model here is capable of more generalization than you are willing to admit. reply Terretta 16 hours agoprev [–] At Physical Intelligence (π) our mission is to bring general-purpose AI into the physical world. We're excited to show the first step towards this mission - our first generalist model π₀ Paper, blog, uncut videos: http://physicalintelligence.company/blog/pi0 via: https://x.com/physical_int/status/1852041726279794788 reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Physical Intelligence (π) has launched π0, a generalist robot policy designed to enhance artificial physical intelligence, focusing on physical tasks rather than digital ones.",
      "π0 is trained on a diverse dataset from multiple robots, enabling it to perform tasks such as folding laundry and bussing tables, using Internet-scale vision-language pretraining and a novel flow matching method for dexterous control.",
      "As a prototype, π0 signifies progress towards versatile robot models capable of complex physical tasks, with the company seeking collaborations and hiring to advance this research."
    ],
    "commentSummary": [
      "Physical Intelligence has created a generalist AI that can perform tasks such as folding laundry, marking a significant advancement in robotics.- The AI's capability to manage complex, non-rigid objects like clothing suggests potential for wider applications, though it currently faces challenges in real-world adaptability and generalization.- The development prompts discussions on the economic and social implications of integrating AI into everyday tasks, highlighting both challenges and opportunities."
    ],
    "points": 187,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1731205592
  },
  {
    "id": 42096915,
    "title": "You too can write a book",
    "originLink": "https://parentheticallyspeaking.org/articles/write-a-book/",
    "originBody": "You Too Can Write a Book!🔗 1 You Can Write a Book 2 You Should Write a Book 3 Mechanics Thanks to Neeldhara Misra for pushing me to write this post, based on a thread on Twitter. This article is primarily directed at academics. Its purpose is to tell you two things: You can write a book. You probably should write a book. 1 You Can Write a Book🔗 Let’s say you’re not using someone else’s textbook, or using it only loosely. That means you’re going to spend a lot of time organizing your thoughts. You will probably produce some kind of “lecture notes”. The delta from there to a book is much smaller than you imagine. Here’s a pro-tip. Back in about 2003/4, I noticed that the quantity of reading that students would do before class was at most about six pages; once it got to about eight pages, they wouldn’t read at all. (These numbers may be much lower now.) But this automatically bounds how much you have to write! In short: let’s say you’re writing up lecture notes. You’re writing about four to at most six pages per class. Let’s say you have about 30 classes (often many more). You have automatically written about 200 pages without even especially thinking about it. Two hundred pages of writing is often called a … book. It represents your “take”. So your take now has a book! 2 You Should Write a Book🔗 What are the incentives to do this? There are many, but they may not accrue immediately: they may take time. Think of it as a long-term investment in yourself. First, simply: you believe strongly in your view of the world, and you’re pursuing it with intensity. Right now nobody else is really able to download your brain. Your book becomes how others can download it. People at other places might use your book, or at least put it on reading lists. Even if only one student there reads and internalizes that supplemental material, that student now carries your ideas with them. Much more concretely, they could be a PhD applicant. I have gotten so many great PhD applicants over the years thanks to my books! In particular, when they come from a less-well-known university, this guarantees for me that they have the preparation I need, and that we have a shared mindset. What’s out there may not be very good. This is especially an issue in programming languages, where some of the widely-used texts are basically hot garbage: basically a broken, 1970s view of the world. I once wrote a position piece on it entitled “Teaching Programming Languages in a Post-Linnaean Age”! So worldview really matters. So that’s another incentive. To drive out the bad with good. Do you use the standard text that everyone else uses in your field? If you’ve read this far, probably not. Why not? You know (or think you know!) what should be taught in your field. Who uses a text? Someone less certain. So it’s not their fault. We need to help them along. Sometimes we have resources—like software—that many people don’t know about, but that are especially well suited to education in our field. For instance, the #lang feature of Racket is one of the most powerful tools for teaching programming languages. But most people don’t (yet) know that. I speak from experience. I have written several books, some solo and some with co-authors. I did the very thing you are told to not do as a tenure-track assistant professor: I wrote a quality undergraduate-level book. I survived (it didn’t hurt my tenure in the slightest), and I then benefited from it for a long time. 3 Mechanics🔗 The one big thing I haven’t said, which drives a lot of this, is the publishing medium. And oh boy, do I have opinions on this! I wrote up some of them when I published the first formal edition of my programming languages book, in an essay entitled Books as Software. Let me summarize/expand. Don’t go to commercial publishers. They are either just not ready for the modern world or will basically paywall your work. Paywalling is the total antithesis of wanting to have impact and influence and wanting to drive bad books out of the market. Publish it free online. Especially those of us who are immigrants from poorer countries know what it’s like to not be able to afford high-quality material. The next you is sitting right now in Bangalore stuck with a crappy course and crappy book. Be their light. Some people like paper. Upload your file to a print-on-demand service. Even with a markup, it’ll be a lot cheaper than a book from a commercial publisher. In a STEM subject, your tenure case is not going to hinge on a contract from MIT Press. Getting that contract is actually relatively easy. Impact is hard. Go for the hard part, as you do in your research. Optimize for it. Put out a new release once a year. Don’t fall for the temptation of continuous releases. People using your book need to be able to depend on a fixed version for the semester. They will have references to pages, sections, etc. Don’t break their build. Publish permalinks. Not everyone can upgrade their course every year. Yes, it means your old mistakes are on permanent display, and some people won’t use your latest and greatest. Live with it. Your ego is not that fragile. You’ll get over it. Make it easy for people to send you corrections. They will (just as they did for your software). Sometimes you will even get very insightful and creative ideas. Of course you’ll also get various dreck. Just as with your software. Because books are software, as my essay says. Try to provide materials in both PDF and HTML. The reasons should be obvious. It’s not always easy. I personally prefer to use Scribble for this purpose. But I have also used LaTeX and even Google Docs. The latter two are each terrible in their own way, but the best tool is the one you use and that lets you get something done reasonably quickly. There’s always time to revise. Don’t suffer the paralysis of tool indecision and let that become the reason you don’t write! You won’t make much money this way. It’s okay, you’re probably already paid pretty well. And the money you’re not getting is money the author of the crappy textbook is also not getting! And you’ll get paid in mindshare, which is infinitely more valuable. You can also do what I did: I published the free PDF on my Web site. On the print-on-demand site, offer a modestly-priced PDF. I let readers know where they can get the free version. Therefore, the only reason to buy the PDF is the equivalent of a tip-har. Most don’t, but a few do. (You can also use one of the tip-jar services, though they didn’t provide enough value for me.) Sure, my revenues have been modest. I view the checks as a little surprise bonus. Added over time it could probably have bought me a new bike frame (my unit of measure!), but mostly it’s mostly just a nice dinner and ice cream. But I’m not doing it for the money. I’m doing it to spread a worldview and to liberate a field from terrible books. Both are much more worthwhile to me. In short: if you’re even slightly tempted to write that textbook—go for it. I got you, fam.",
    "commentLink": "https://news.ycombinator.com/item?id=42096915",
    "commentBody": "You too can write a book (parentheticallyspeaking.org)183 points by azhenley 21 hours agohidepastfavorite66 comments heycaseywattsup 1 hour agoWrite a book! +1 you all can do it Here are some of my tips from when I wrote Debugging Your Brain. How I developed my ideas for the book (discussions, conference talks) https://www.caseywatts.com/blog/casey-s-writing-process/ How I got feedback from beta readers https://docs.google.com/document/d/13EwX8L6RCUbiu86Lik1xZ8eX... How I wrote and typeset my book from markdown to an eBook and print book, via pandoc/latex https://gist.github.com/caseywatts/3d8150fe04e0d8462cfc4d51b... reply schneems 21 hours agoprevI agree. I DID write a book! https://howtoopensource.dev/ My biggest tip is this: Don’t skip getting beta readers. High quality feedback is really hard to come by. I changed my tool chain to add a google form at the end of each chapter and got strong buy in from a handful of people with the finished first draft in a beta state. In the end some bailed but one left amazing feedback resulting in massive structural changes. The process of writing a book is two things (to me). The most obvious is sharing information. The second, often overlooked, but biggest benefit IMHO is how you will grow and learn the source material even better than you already do. Even if you don’t ever publish it, it’s still worthwhile to putting in the effort to write a book. GLHF. reply UncleOxidant 17 hours agoparentWhat kind of software did you use to write your book? reply luv2code 15 hours agorootparentCheck out https://typst.app/ if you're looking to write a book yourself. https://hypermedia.systems/ was written with it. reply Daub 5 hours agorootparentprevFor very long documents Word can be very difficult to maintain. Anything that requires you first write in simple text and then compiles is preferred. I tried Skrivenr, but found it old, clunky, buggy and poorly designed. I was far more productive in LaTex, but encountered problems when converting to Word (which most publishers prefer). Sure I tried Pandoc, but maintaining flow between versions of my book was a small hell. In the end, I believe that there is no easy solution. Typst has excellent collaboration tools. Both Typst and Overleaf do not support Doc export, but pdf to doc is relatively easy. reply schneems 16 hours agorootparentprevIt was a mix of markdown, liquid, scss and ruby scripts via a Rakefile to tie it together to generate html. I bought a prince XML license for PDF generation. It was a hodgepodge of stuff. reply larperdoodle 14 hours agorootparentprevI'm writing my book in Markdown files in IntelliJ and pushing it to GitHub. Use the tools you know. reply Narhem 20 hours agoparentprevnext [2 more] [flagged] dang 16 hours agorootparentHi there - from your recent comments it sounds as if you might have been going through some difficult experiences. (If I'm misreading you, I apologize—it's not easy to be sure if one is reading these things correctly.) If so, we all send good wishes. At the same time, we can't have accounts posting comments like these on HN—especially comments like https://news.ycombinator.com/item?id=42097195 or https://news.ycombinator.com/item?id=42097177. I've therefore banned your account for the time being. I just wanted you to know that it's nothing personal, and that if you get to the point where it won't happen again, we'd be happy to unban you in the future. reply franze 11 hours agoprevThe challenge is not writing a book, but letting it go. I wrote Understanding SEO https://fullstackoptimizatio.gumroad.com/l/understanding-seo... 4 times. Each time it took me a year. The last time together with an editor. And I could have gone on, over every word, every sentence again. In the end my editor forces me. In the end you just have to publish it, otherwise it does not exist. Still think I did good, even after more than 7 years I still sell a few paper and some more e copies per month just by WOM, so yeah, must be some value in there. reply jamager 9 hours agoparentI know what you mean. Writing a book takes 2x discipline than any other thing: 1x to actually write it + 1x to call it done. reply obiefernandez 20 hours agoprevFor beta ebook publishing I can't help but recommend my friends at https://leanpub.com where my latest book is currently at the top of the charts. I've been publishing with them since they launched (a long time ago) and have made nearly six figures lifetime revenue. Plus they give you one-button push to publish to print versions at Amazon. reply jdhendrickson 16 hours agoparentAs someone that has bought your books in the past, it's because of your personality and the quality of your writing more than the platform. reply ManuelKiessling 9 hours agoparentprev+1 for Leanpub, a great platform run by amazing people. reply jamager 9 hours agoparentprevlooks great, thanks for this! reply Daub 5 hours agoprevAs a university lecturer, I have interviewed many people… academics and admins. I have taught in many S E Asian universities and multi-lingualism is the norm, with English assumed to be the ‘Lingua franca’. Almost everyone I interview claims to have ‘excellent’ skills in written and spoken English. Almost none of them could produce so much as a single paragraph of English that did not burn my eyes. Prior to starting writing my first book, I had already accumulated some experience in academic writing. I thought it would be a doddle. I can honestly say that it was one of the most demanding experiences of my life. The worst thing is the degree to which I was blind to my own shortcomings… just like all those people I interviewed. Moral of the story… \"writing is easy; you just stare at a blank sheet of paper until drops of blood form on your forehead\" (Gene Fowler). reply sanderjd 5 hours agoparentYeah, my thought while reading this was that this is why I am so often disappointed by books. reply kqr 11 hours agoprevThe main counter-argument to this I have read is \"you should just publish blog posts instead.\" This is, among other reasons, because - The bar to releasing the first thing to the public is lower, - The regular cadence builds an organic following, - You can iterate on subjects in the open, - You have more freedom to organise content non-linearly. The main drawback I can think of is you cannot call yourself \"author of book X\". Are there any other reasons not to blog instead of book? reply mcdow 1 hour agoparentI agree with this take. Blogging is a the first step towards writing a book. However, through blogging I've realized just how impressive book writing is. I work really hard to build coherent blog posts, I cannot begin to imagine scaling that to a book. It's kind of like software in a way. Anyone can code a toy, not everyone can build a product. reply grecy 7 hours agoparentprevI started with a blog to get into the habit of writing and get better at it, Then I published books. The main reason to do so is that I get paid for book sales, but not for the blog. reply TheCleric 21 hours agoprevThe blog post should more accurately be titled “You too can write a textbook” reply jftuga 15 hours agoparentThis is a good observation. I was hoping to read a blog that wasn't so narrowly focused to just text book publishing. reply grecy 7 hours agorootparentHere’s here I wrote and self published books about my adventures around the world, print and ebook. I also have a hardcover photography book. Happy to help if you have questions. http://theroadchoseme.com/how-i-self-published-a-professiona... reply DominikPeters 8 hours agoprevGwern recently wrote an article on why not to write a book: https://gwern.net/book-writing reply suprjami 17 hours agoprevI usually participates in question/answer communities to answer things, I almost never ask my own questions. As a result, I have various sources of notes I've figured out and get high use/reuse from. I also do a lot of technical training at work, for both beginners and advanced users, so have a wealth of tried and tested content there. I've often contemplated writing an eBook on each topic and selling them on Leanpub/Amazon/Google for 5 or 10 bucks each. The idea of limiting myself to 6 pages per topic is appealing. That would force an economy of writing and density of content which appeals to me. reply dm03514 6 hours agoprevI agree with the post :) Writing a book was very personally fulfilling. I wrote about my self published book earnings a couple years ago. https://on-systems.tech/blog/130-2022-self-published-book-ea... This quote got me pretty excited, and I since yesterday I started sketching out some ideas for other books ;p \"First, simply: you believe strongly in your view of the world, and you’re pursuing it with intensity. Right now nobody else is really able to download your brain. Your book becomes how others can download it.\" reply _tom_ 12 hours agoprevWhat I remember from college is that the instructors who wrote their own books had terrible books. They used their own books because it was theirs, not because it was good. Most people do not write well, but the people who can become a standard textbook do. The vast majority of people write worse than this. Usually much worse. reply Daub 5 hours agoparent> Most people do not write well… This very much needs to be said. Also… as we are ‘most people’ we all need to be reminded of this of our own writing. reply polygot 13 hours agoprevI'm in the process of writing a book, Beginning CI/CD, primarily because I have a strange way of learning things, and hoping others might find my teaching style useful. I also struggled with CI/CD and still have those struggles fresh in my mind. While the author of the article is against commercial publishers, I don't think I'll have the same impact if I were to go with the self-publishing route. Either way it's super unlikely I'll make a profit so it might be better to use it as leverage; also, getting a publisher to publish it shows that there is at least some commercial viability. Looking for beta readers--if interested, feel free to reply or email me (email on profile.) reply keyle 11 hours agoprevI feel there is not enough Satire IT book. Someone ought to take the shit, and by that I mean realistically picture the industry. reply isoprophlex 10 hours agoparentSo, repackage the energy of https://ludic.mataroa.blog/ into a novel? I have recently been thinking about fleshing out a story about a completely incompetent agile-type scrumlord, an unlikeable opportunist who is, tragically, unable to better himself in the institutionally broken system that is IT right now. Oh and also he's sad about WFH because he has a poorly controlled fetish about smelling the air under people's desks. reply ch1kkenm4ss4 9 hours agoprevBut why should i? Many excellent books covering every aspect vave been written. Time's better spend elsewhere. reply zelphirkalt 7 hours agoparentIf you become truly an expert at something that has sufficient depth, or is sufficiently obscure, or is sufficiently underestimated, I think you will see, that not every aspect has been covered. Sometimes books also convey a personal opinion of the author of how to approach things. Or they are autobiographies. So many reason to write a book. Or some other textform. reply beej71 12 hours agoprevAs an author of free online books and POD books, I wholeheartedly second everything in this post. reply DimuP 8 hours agoprevIt's very inspiring indeed reply paulpauper 17 hours agoprevYou can write a book, but odds are it won't be good or get traction. I think you're better off with video. Videos can remain indexed and accumulate traffic on youtube for years, whereas most books are forgotten/ignored. I have seen plenty of videos from 10+ years ago that still gets lots of comments and traffic. reply davisp 16 hours agoparentYou can make a video, but odds are it won’t be good or get traction. I think you’re better off with a book. Books can remain indexed and accumulate readers for centuries, whereas most videos are forgotten/ignored. I’ve read plenty of books from decades ago that still get lots of comments and discussion. reply paulpauper 16 hours agorootparentnot the same thing...billions of people use youtube. There is no library equivalent of youtube. how many use Google Books? Even then, you need an ISBN or a publisher. reply wheresmycraisin 15 hours agorootparentYour audience isn't a billion people reply paulpauper 15 hours agorootparentWhen people want to find something or learn about something, they go to YouYube. That is where or how the majority of people find and consume content these days. There is also Google search, but again, these are not books. If your audience is limited, then target niche keywords. Same principle applies. Videos about even the most esoteric of topics still get traffic due to YouTube's popularity. reply saulpw 9 hours agorootparentprevPer the Lindy Effect, a published book has a higher likelihood of still being readable centuries from now, than a Youtube video. reply zelphirkalt 7 hours agoparentprevSheesh, I think we are stuck with the literature we have now forever, and can never get new good books, now that you have published this comment... Seriously, if no one ever tries, then no one can ever succeed. reply tolerance 16 hours agoparentprevThe solution is to write follow-up books. Improve your writing and refine your perspective and gain traction through the friction attributed to this process until you stumble upon a successful iteration of the idea that you are trying to communicate or the principles that your are trying to remind others of and someone else takes notice and writes an article about it on their Substack, where prolific link distributor paulpauper will share it on Hacker News. reply rixed 15 hours agoparentprev> I have seen plenty of videos from 10+ years ago that still gets lots of comments and traffic Sounds like survivor bias to me reply fullstackchris 9 hours agoprevI started writing a book along side of every video course I make. (I make educational software videos, and discovered that some really enjoy the written version apposed to video - even for software!) I just use LaTeX with some fancy packages: https://github.com/princefishthrower/dev-book-template I too think there can always be more long format literature out there, in a world seemingly dominated by short articles and tweets reply HL33tibCe7 18 hours agoprevIs it intentionally ironic that there's a grammar mistake in the second sentence of the article? reply julianeon 17 hours agoparentWhat is the mistake? I see none. reply __mharrison__ 15 hours agoparentprevGrammarly is a godsend for authors (and anyone who communicates). I wish it worked in mobile... Having said that, you can have beta readers, editors, and grammarly, and stuff still gets through. I've published with two different publishers and have also written multiple self published books. Errors happen. reply skrishnamurthi 18 hours agoparentprevThat would be nice. Problem is rather more simple: the author can't proof-read. reply WalterBright 17 hours agorootparentWhen I proof my own work, I read what I thought I wrote, not what I actually wrote. reply munificent 16 hours agorootparent100%. We all fall prey to this. Two tricks that help more than you might expect: 1. Read it in a different font than what you write it in. 2. Read it out loud. reply treetalker 13 hours agorootparentTwo other effective techniques: 1. Read your sentences or paragraphs in reverse order. (In other words, if you have sentences or paragraphs 1–5, read them in the order 5, 4, 3, 2, 1.) 2. Have Siri read it out loud to you in an accent as you follow along. (I like hearing it in an Indian accent — it makes me pay closer attention.) The app Voice Dream Reader (iOS/macOS) is great for this. The general principle is to review the writing in an unfamiliar way. reply skrishnamurthi 4 hours agorootparentprevFor people missing the point: The person who made the above remark is the author. reply paulpauper 17 hours agorootparentprevproof reading one's own work is hard. it's why editors exist reply yawpitch 13 hours agoprevGreat article, but on Mobile Safari, at least on an IPhone 12 Mini (old, I know, but not that old) this loads with a massive left margin / padding, with all the text overflowing the right side of the screen. reply cshokie 11 hours agoparentSame on an iPhone 15. Reader mode worked great, though. reply mkl 7 hours agoparentprevSame in Firefox Android. reply andrewstuart 21 hours agoprevLeunig cartoon on your \"inner book\" https://scontent.fmel18-1.fna.fbcdn.net/v/t39.30808-6/461606... reply Y_Y 20 hours agoparentBad URL hash? https://consumer.licensing-publishing.nine.com.au/Assets/V2/... reply andrewstuart 20 hours agorootparenthttps://imgur.com/a/Z2iAB7Y reply bbor 20 hours agoprevOh hey, this person! The 'Books as software' post has made the rounds on here a few times since its publication in 2006, if I recall correctly, and it's always a controversial+fascinating conversation. They're certainly not a conventional soul: We will include mistakes, not because I don’t know the answer, but because this is the best way for you to learn. Including mistakes makes it impossible for you to read passively: you must instead engage with the material, because you can never be sure of the veracity of what you’re reading. I've never seen this post, though. Speaking as someone who's currently closing in on self-pub after ~18 months of work (lots of research, tbf): I. As another comment mentions, this is for technical books, and seemingly specifically textbooks (AKA lessons, as opposed to the other three quadrants of technical documentation, references, instructions, and tutorials). In case anyone here is considering writing a fiction book, please do not ever expect to make any money at all. The odds are downright absurd these days. II. I absolutely agree that it's a sometimes-underappreciated and potentially very lucrative career move if you have real expertise to share and are a good writer. Especially in the vaguely post-blog era. III. Writing a book but not expecting to make any money from it is... bold. I'm very glad it worked for this person, and if you're looking to use it as a credential to land contracts or appointments, then that's very smart and kind. But I think I speak for many authors when I say that writing a book is very time consuming, and you need to eat somehow. Not all of us are just publishing cleaned-up lecture notes, after all. I initially shared this person's \"offer a print copy as a tip jar\" concept, but have gradually moved towards \"only publish free snippets\" as I consider long term financial feasibility. This applies even more so if, like me, you're writing a prose book that has a 1% chance to be truly popular among laypeople, rather than more realistic textbook-centric goals. IV. PoD is indeed incredible. For those not in the know, this allows you to sell your book without any significant upfront investment, and have them manage shipping. There's definitely room for profit via many sites; Lulu, for example, will print a 250 page \"Digest\" (normal) paperback in B&W for $7.56/ea. I'm also planning on going with http://lulu.com . Arguably it's <50% likely to beat Amazon's uber-popular PoD service on overall sales+profits, but it has some notable advantages: 1. If you're thinking about a publishing a \"premium\" book, which some textbooks might be, they have some gorgeous options -- both in terms of color printing and cover material. https://www.lulu.com/pricing 2. If you're a web-dev comfortable setting up a Shopify portal on your own site, you can hook it up to Lulu and get \"100%\" (after PoD costs) of your profit. Obviously, this is potentially a huge deal -- the trick is of course getting Amazon-like numbers of eyeballs on your own site. https://www.lulu.com/sell/sell-on-your-site You can even order copies via API, which seems goofy but potentially fun. 3. They're targeted at DIY authors, and as such offer a nice little knowledge base on formatting and such: https://www.lulu.com/publishing-toolkit I haven't printed any yet, but they're templates are nice to work with. 4. They're not only \"not Amazon\", they're a B-Corp. Which, hey, we all gotta do what we can when we can, no matter how small. ...I swear I'm just a biased fanboy, not a shill! V. The cover art space is fucking wild these days, AI has absolutely upended it. Scroll through /r/writers for lots of horror stories. I would be cautious about hiring any freelancers to help you without serious vetting. Plus, Inkscape is free and technical books don't need realistic art! P.S. Does the author know they're invoking a antisemitic trope with the \"(((Parenthetically Speaking)))\" title? It seems to be in obvious good faith, but that did draw my attention for a short moment. Maybe just one set of parentheses could do the trick ;) reply skrishnamurthi 4 hours agoparentThanks for the PS. That was (obvioulsy) not the intent; it had never occurred to me that it could be read that way, since the bits inside the parentheses are not a proper name. But, to avoid any doubts, I have modified the masthead image to get rid of two pairs of parens. And yes, that same person. reply slau 19 hours agoparentprevReplying to your post-scriptum: maybe it’s used to normalise/re-appropriate[1] the triple parentheses? [1]: https://money.cnn.com/2016/06/03/technology/google-racist-ch... reply skrishnamurthi 4 hours agorootparentIt has indeed been used by many people to re-appropriate/confuse/normalize. But none of that was the intent here — sometimes a parenthesis is just a … parenthesis, especially since there's no name inside the parens. But this isn't the kind of thing one usefully \"discusses\"; given that I am indeed not trying to send any messages, I've changed the logo. reply MountainMan1312 11 hours agoprev [–] I'm not reading any damn thing by someone who has triple parentheses on their website. Maybe it's an accident but that's a dangerous assumption to be making, especially with antisemitism on a steep rise lately. reply skrishnamurthi 4 hours agoparentThat was (obviously) not the intent; it had never occurred to me that it could be read that way, since the bits inside the parentheses are not a proper name. But, to avoid any doubts, I have modified the masthead image to get rid of two pairs of parens. reply JSR_FDED 9 hours agoparentprev [–] I thought this was crazy, but it’s a thing apparently: https://en.m.wikipedia.org/wiki/Triple_parentheses Interesting times we live in… reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article encourages academics to write books, highlighting that it's more feasible than it appears, especially if they are already creating lecture notes.",
      "It suggests publishing online for free to maximize impact and using print-on-demand services for physical copies, while avoiding commercial publishers to maintain accessibility.",
      "Writing a book is portrayed as a long-term investment in sharing ideas and improving one's field, with the potential to influence others and enhance resource quality."
    ],
    "commentSummary": [
      "Aspiring authors are encouraged to develop ideas through discussions, seek feedback from beta readers, and use writing tools like Markdown, LaTeX, or Typst.- Platforms like Leanpub and self-publishing options such as Lulu for print-on-demand are recommended for publishing.- Writing a book is portrayed as a journey of learning and sharing, requiring discipline and offering personal growth, even if the book is not published."
    ],
    "points": 185,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1731186641
  },
  {
    "id": 42096837,
    "title": "Visprex – Open-source, in-browser data visualisation tool for CSV files",
    "originLink": "https://docs.visprex.com/",
    "originBody": "Hello HN. I&#x27;ve always found writing data visualisation scripts boring and repetitive in data science workflows earlier in my career, so I built this tool to automate it. The available methods are based on my experience in econometrics where histograms and scatterplots were the starting points to check data distributions.The link is to the documentation and the app is freely available at https:&#x2F;&#x2F;visprex.com, and if you&#x27;re curious about the implementation it&#x27;s open source at https:&#x2F;&#x2F;github.com&#x2F;visprex&#x2F;visprex. I&#x27;d appreciate any comments and feedback!",
    "commentLink": "https://news.ycombinator.com/item?id=42096837",
    "commentBody": "Visprex – Open-source, in-browser data visualisation tool for CSV files (visprex.com)174 points by kengoa 21 hours agohidepastfavorite24 comments Hello HN. I've always found writing data visualisation scripts boring and repetitive in data science workflows earlier in my career, so I built this tool to automate it. The available methods are based on my experience in econometrics where histograms and scatterplots were the starting points to check data distributions. The link is to the documentation and the app is freely available at https://visprex.com, and if you're curious about the implementation it's open source at https://github.com/visprex/visprex. I'd appreciate any comments and feedback! doodlebugging 12 hours agoLooks nice. I've had occasion to import/export, edit, etc. thousands of CSV files from multiple software platforms over the years and this tool looks like a simple way for a user to determine whether there are issues in the CSV file that will cause problems on import to their application. One question I immediately have is how this compares to a spreadsheet CSV import tool such as the one in Excel which is extremely flexible. It appears that this app requires a specific format (comma delimited, new line at end of each row) in order to work. I never tried to count the times that a CSV file that I had to work with required editing in order to facilitate import to Excel or other application because CSV is such a non-standard standard output that the only way one could know whether the import would be successful was to pop it into an editor, like Notepad++ and examine it before import. Notepad++ was a critical tool in the chain to force compliance for all the different applications I used. Each application allowed CSV import/export but some accepted almost any delimiter while others were strict about file format and failing to understand the expected CSV format for each would definitely cause headaches as some input errors could leave a very subtle footprint that you may not catch until late in processing. Anyway, it appears that your definition of CSV format is pretty strict so how do you propose that a user manage importation of files that do not fit your CSV definition? Notepad++ before import to verify compliance? I also see one thing on the main page under \"Security\" that looks like it could be worded differently. >No tracking or analytics software is used for privacy To me, this implies that no steps have been taken to manage user/data privacy. Perhaps a comma could be inserted so that it reads \"...used, for privacy.\" or maybe it should read: For (user/data) privacy, there is no tracking or analytics software. reply kengoa 9 hours agoparent> how this compares to a spreadsheet CSV import tool such as the one in Excel which is extremely flexible. I would say the data loading functionality compares very poorly to Excel CSV import for all the reasons you pointed out, and I agree that the users can face those formatting issues which could be resolved in another tool like Excel or Google Spreadsheet for non-technical users and Notepad++ or editors for a bit more technical users. The assumption on CSV files being clean is strong so I will try to surface import errors at least, and in the meantime point to different ways to format the data as those tools will be complementary to Visprex. > To me, this implies that no steps have been taken to manage user/data privacy. This is a good point. I fixed the wording and now it simply reads \"No tracking or analytics software is used\". Thanks! reply TripleChecker 3 hours agoprevAre you planning to add xlsx support? Also a few typos you might want to review: https://triplechecker.com/s/823563/docs.visprex.com reply kengoa 3 hours agoparentI will try to add more support for other data formats like xlsx and parquet in the future. Current CSV parsing is also a bit limited (i.e. cannot deal with timestamps) so I will try to update parsers first. Also thanks for the error checker! I pushed the fixes in https://github.com/visprex/visprex.github.io/pull/4 reply paddy_m 18 hours agoprevNice work! Do you have any plans for data cleaning? I am working on a somewhat similar open source project. I intend to add heuristic data cleaning. With the UI I want to be able to toggle between different strategies quickly - strip characters from a column to treat it as numeric, if less than 2% or 5% of values have a character, fill na with mean, interpret dates in different formats - drop if the date doesn't parse. The idea bing that if it's really quick to change between different strategies, you can create more opinionated strategies to get to the right answer faster. Happy to collaborate and talk tables with anyone who's interested. reply kengoa 7 hours agoparentYes I do have plans for data preprocessing using DuckDB WebAssembly (I have upcoming features secion in this blog: https://kengoa.github.io/software/2024/11/03/small-software....) but this will require SQL which some of the target audience might not be familiar with. I'm thinking of something like visual query builder from metabase. > With the UI I want to be able to toggle between different strategies quickly - strip characters from a column to treat it as numeric, if less than 2% or 5% of values have a character, fill na with mean, interpret dates in different formats - drop if the date doesn't parse Those are really good examples and I can make those predefined preproccesing techniques available as toggles in the dataset tab. Thanks for the feedback! reply remolacha 17 hours agoparentprevnot quite what you're describing, but I open-sourced a fuzzy deduplication tool last week: https://dedupe.it Would be interested in expanding it to deal with data cleaning more broadly reply turtlebits 16 hours agorootparentNot sure if you have introduced an artificial delay, but deduping ~25 rows shouldn't take 5+ seconds... edit: I see you're using an LLM, but \" ~$8.40 per 1k records\" sounds unsustainable. reply mosselman 9 hours agoprevCool! Does anyone know of any javascript libraries that I could use to get this type of distribution visualisation from tabular data? Something I can run on my site that is. reply kengoa 7 hours agoparentI used d3.js for Visprex and some of those graphs are modified from examples in https://d3-graph-gallery.com/ reply imfing 9 hours agoprevcool project! Visualizing tabular data often presented some challenges, as I had to rely on tools like Google Sheets or Colab + Pandas for quick cleaning and wrangling before exploring different visualizations. I think having more client-side data cleaning capabilities would make it even more powerful reply kengoa 7 hours agoparent> had to rely on tools like Google Sheets or Colab + Pandas for quick cleaning and wrangling before exploring different visualizations. Yes I had the same experience for analytics work some years ago. As others have pointed out, Visprex only works in a happy path where data is a clean CSV file so will definitely need to work on data cleaning. I have a DuckDB integration planned but not sure if this is easy enough for the target audience. Will try to add some predefinied functionalities, thanks for the feedback! reply teddyh 20 hours agoprevI loaded a CSV with one date/time column and one numerical column. I then selected “Scatter Plot”, but got the message “Not enough numerical columns found. Load a CSV file with at least 2 numerical columns in the Datasets tab.” I would have thought that a date/time column would count? reply kengoa 20 hours agoparentThanks for trying it out! This is unfortunately not possible as of now and is one of th high-priority tasks to parse timestamps and datetimes, which is now incorrectly parsed as a string (Categorical). I'm using Papa Parse to load CSV data and I will likely need to add a custom parser on top of it. Some of those plans are mentioned in my blog post reflecting on building this app: https://kengoa.github.io/software/2024/11/03/small-software.... reply nerdponx 19 hours agorootparentYou might also want to support a Unix timestamp as input, i.e. an integer or decimal number of (mili|micro|nano-)seconds since the Unix epoch. No need to worry about messy date parsing there. reply nyclounge 18 hours agorootparentprevMaybe use dayjs to handle all kinds of wired string dates. reply kengoa 3 hours agorootparentdayjs seems like exactly I was looking for, thanks for the suggestion! I might have tried to write a parser myself otherwise. reply parsimo2010 15 hours agoprevI like this a lot- I am going to show it to my students! They seem to hate learning R, and while this doesn’t prevent them from having to build a model, this will speed up the exploration steps. reply kengoa 7 hours agoparentI'm very glad to hear this as this is exactly the target audience and the use case I initially thought of! I hope your students find it useful. reply jeffreygoesto 11 hours agoprevI typically fire up GnuPlot and there CSV loading and a plot are one line each. What does Visprex do more or better? reply relistan 9 hours agoparentNot the author, but just looking at it, and playing with it, I’d say ease of use is the obvious one. Availability in the browser any time anywhere seems nice. reply kengoa 7 hours agorootparentThanks for commenting this, I would say speeding up the iteration between visualisation steps is the main benefit as you might not want to be thinking about matplotlib syntax when trying to get a sense of data distributions. reply rrr_oh_man 20 hours agoprev [–] Very cool stuff! Maybe bar / beeswarm charts would be useful? I was missing the possibility to show differences by category, eg mpg by make in the cars dataset. reply kengoa 19 hours agoparent [–] I haven't considered beeswarm charts for this before, I will add those to a list of upcoming features. Thanks for the feedback :) reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new tool has been developed to automate the creation of data visualization scripts, addressing the tedious nature of manual script writing.",
      "The tool incorporates econometric methods, such as histograms and scatterplots, to analyze data distributions effectively.",
      "It is available for free, with open-source code accessible on GitHub, inviting feedback from users and the tech community."
    ],
    "commentSummary": [
      "Visprex is an open-source, browser-based tool for visualizing CSV (Comma-Separated Values) files, aimed at automating repetitive data visualization tasks.",
      "It currently supports visualization methods such as histograms and scatterplots, drawing from econometrics expertise.",
      "Users have observed that Visprex requires a strict CSV format, unlike more flexible tools like Excel, with future updates planned to support additional data formats and data cleaning features."
    ],
    "points": 174,
    "commentCount": 24,
    "retryCount": 0,
    "time": 1731185651
  },
  {
    "id": 42097774,
    "title": "LLMs have reached a point of diminishing returns",
    "originLink": "https://garymarcus.substack.com/p/confirmed-llms-have-indeed-reached",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"garymarcus.substack.com\",cType: 'non-interactive',cRay: '8e084b65c8e07d1b',cH: 'g_QVCv3aPKMqxz2kL4y5kRvi4R4s3epkQFDysezGTO8-1731265321-1.2.1.1-HjnXfygYUd9UCWPzyod2MYBRZVMXyS98hrCQCjFuk7cxZmvBKa7d9o2rsqIE6FQ9',cUPMDTk: \"\\/p\\/confirmed-llms-have-indeed-reached?__cf_chl_tk=qsIEs7Re1ChJhFt7qnxVhPzVpWLVNJ7gwtYi.xCefWQ-1731265321-1.0.1.1-K.P8_xjFpTs3akS.4gZ0v5FfYRxNIarNdNNDIgfkyK0\",cFPWv: 'b',cITimeS: '1731265321',cTTimeMs: '1000',cMTimeMs: '120000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/confirmed-llms-have-indeed-reached?__cf_chl_f_tk=qsIEs7Re1ChJhFt7qnxVhPzVpWLVNJ7gwtYi.xCefWQ-1731265321-1.0.1.1-K.P8_xjFpTs3akS.4gZ0v5FfYRxNIarNdNNDIgfkyK0\",md: \"Xl9LwE0FLz8BuNpEuj2Mi8diUT.WPUgb99AmuxpbT64-1731265321-1.2.1.1-ZPmoZRvLXPd8kf39DzXFzZHM46GXSAFj7Isq1swOePiVLoXbGQjMqJLmP4kO0lwJh78.hsNqFT4RU60OzqwBJ4ffecWxtJJfXmmhyOlkcr6wdOlYCYByazYHJ9JNbxbxzzy.9CtlMa9HVruyMe6zBthRxNAdGOUVN4oWwpWWLqCuZpmi.KvMrD0Dv6ugUovjvp1Iqr10vnyK97ebrI1cPFjWLelPXo6hfxu4umpz4wSlndkNsmlV3xzbo9oai75Zyn1nn0XC5m_ZsYb46E1FyofH0KgB5rwOPMdxIffVcw6X02hHpdtHxigae4C.LMsuI2GxoeJ6h2v7AdnklbBD0gFWO2D6T8ysyJG.aa8qvfiz.IG2uSTHkdFCJrV6zAA4a18Dl3ZMIHPTQXhHFEHbGHxxNoqhxTSr_nS2rEIToOTdxIoejXJFMKDpOiQyAbttqkL7SdiEMvHwx5.qM06iHjVrrOky2DErLp12W8fl8YRWyDMrqPTiWMzMk00zrzDV57u47K9tSAcEEBEfM7ShZYAPknEia3rrhnen0JZ8oJZd3eF6.N1r.Z67u..BxuQNTzGM1Oa5QI.b9fCtlbVntU_I_s929FdT6eC4j1YzWyibmov09ArfseKEl3lAACjmwsQUhwu6v3G3ips3T_He9Mifbt6IFH2e2rfJj.K.MJI6lo0ao3yu1Uk2lfMndft.miPSF1EjP338WHMJCYBekaBy1EdUmjv2ZTI2_Gk9Hy6B4CTgaXdsJRLIPWMmoSnk24wUxQVBEGwdTDzy5ug_BDdCjcVsMgOfZKU_ZYWXintIUaC5w9WubFWYZbbQjb.NtyFGiekj5FNXImmz9ncGokighqsEX36Svv2gZo2XlRdCcv778xsTWY54uxkGeWl3om4YgK9YQkhL2RrxsRgG6iHGJzHUlpphtXW9SjB4D3Da9r0ngnULPKOlBYDj19.z79wcUvXFilDTgcYllWoLsy7f__offR6EIxYN2q8m1SbV7ZIO.MoedCwPVdAXox0GvL_S.pYU.yAKMxbZwhoAAQfSRq8mMAYCJqcD6J2IaxXK6WfScePyfcT7L2JjB9CoRz7wV3H5U9520eh.hwRBZmvKURlPSGc2HT5n5akwbu.DgCHr5KLerGLDrhRmQJtXIHinHsdluOhEZZdwlujL195yEblip0ezQq9kIVHP4MkOzXQ0VjJM1JUp3HUPDtKmOAwDeX3DSn9lHLo66uhEVLPI3hQQXV1iogaMG2QCTad.ekJMSyOI7IfPpBc69K3Dq2hjrVL4eYKBb6cCtfLDx7dnHiT6TrwG.cpoAp4jWXuVEzmUr8AOoBH2IGi0A9aV4b4GTv7.nUt64ruW3lMv3AcOo_MwgzEAIy8SQ2CuAfQnuV97QYl1lzbg4ynn14mTOJPcbVZSA2ikYOp8SXW_xIufwfg4nCf9hGwaOmeOgUJExJpk5QnJarjbhTYeNDzpTA4JzaocVsdFxHdmz334ov_1TTgIACwouUO0LXbk1RV88VQn11kL5WNJp24oXdbOkOlpR8OnvOgrVsxzdcRb_wDqp_vXDhuK4DUAnfIxd_XdaVECYQ9GApwQkJ5OO5Fnq2bKc6SOXLGp.l1nPqgdgoupkMpm9Oxqm0eEtKTTpLgKekpM62GViwIrTWQonYYK9pCDdUmuDg7Z9swS_xe6Oy4BPBNdeS4YAigdcwwcURScBK1zPgN5WaPFOaKtrrAZ5A896XSqXUBVWPo08Mm.IQ.X2qxXP9LP1IPCJ0F0VEIa4rFDgA.xM5KLEawT1IvDb4IXQPpFoYURED9BJjZeMOIyKYfiHAB.zcSmJWl0fT5jT0cE5PE4wm9B04r._EkhfcgBSlWjFoiPgcnvhKvJGrTcLLuAZz6PVgTWFt6VO0I\",mdrd: \"ISJupXgBiDs.SNA2426x6APXcRxZq7JK04sJ4ruBYtc-1731265321-1.2.1.1-Nullov19p2VcFcL9bQDwoBinYRnpGmJMUOWsZ35DuqxiWBbQLHLs4rkY0J2lyUyOupG_TVzYelPEr6zKkOTzwuAgtjzNEp8GlHVC6WVJAXvOBcbeSyzlciWmkkoHhm2gMQ78lF9ZFHgpkr7_zY8kfdUswkb1yaPB_YHJa3gd2yhze7n3A0HJIGmkDPNit2nBTMCDJfQFnHYFXZjC70s7AAB7GBEWnJwKlRHUo3be5D7Uqof9LXmLLIrEqW38gBa1LwWlrKGuh13K6OkeYvSb4AWnZePzpVAVmcmRabYM3nGpbuLTfSqFAfCxA_Hl3qiOtcMiZifoJzDwZirtyGWo844Yg5BQoINIwUSKfZSz9vBT8uzR3rOvLxDoGbkKWjjEiHj3CUdEYQAsJDYN2rfjAYr48G6UXi7IX8wuaEjzRMijQwe7OMKBFgq.beTxzgbNCV5jQCvow.OUZYuSWB9MkAaXM.koAy6I92HL0MeNqMXU8EEfdV9xzBpc2rs9.OEEgVrWI9BkoF3ceQJeTajyiLABfQWLVUrWdyFxEn4Z585Wqwerp_5y7coaLNO46dSiWEa0IGAE4ulGBwq5Hf6jrYOtZouPJ0sQNBClnkkKAFY1xaDA6ff08gCH472IqcVeynWHlk3w2l05mI0oAh7NVu6XlwL9Qk63IpVZwSChdG_79yzkSrrxi9j81WcGyV.YwQouaU6KUAhmOwLxX4cbvb2487Oz.p.bRgiFvfPQxlOWY8q0OvVc3MW_bIgDVfOiVzrMTE3g1ht8ntSmEA9IML7mJT1yXc.UijPFmp7LDdCuvshFJiub4LL5QmXQFT3BSfFstfghJTTqjkA9oKM.B1.xwX1Y9Ut_Q0dHuh.t5HpjQ3oBIvpKrVSUhsS2mAdlm7kkVSNTTetPXeqYa9g4nt8zYQEnAtwuMz7_FA_NUirMJS0OpHFgCDB5cQ4xRGP1XzCFwepRnN7Jfigyl5xxQU9de024RCp0L_348XDFABZldjff8Sx4gSYuai8tEIFsfIJpw9XfWb.7bLBK0THmFsrXVTMAe0NKXyqzBFqS4S32VITHyyAgvnAd4semUG94Ijmyh6g.SwYDZ6.ZV191mSoMV8f84H9mIGa8VGe9TlSsgCBa8sPwRYWxOc9YHGtYha_w1hYJyBozngtdOCzgCbrFBQEr9Dw6e8Vy6iNvuapwHa28uqcFqax1Wc1i2.q5hYgY3NajUjwCRa7tPvaF3l1J2CZgxm4VHyN0jBNLaNh9RgLBcEld7Q0F3XoG4LBvBS1Z1dEPJKihO740pvywDJhn_zasbd_UF2p2L4UmMd9cpqxMjJbNeWVikjT3_nfalFfZUCBXOSp3IKY4o7NdYDZ14FSCMwVTeGTEIuZ.8orBW.2knazV1mRudtqrhP5jWASrUSau2K0THfWyjWO1PIxMHgB4c1W9IOkjFS8_9S.SVno00B1DyNHhgim0lBYzmnefTKWfwSt3EVyKE_YVM4NUYiYL6MxxYy9fI9W_HdHa6rgeGRy9O2S7FFV.lQH9Bh6se7OAnAHLc4_DPdBWpgg8c06u_VAwNF2rubuLz1NjGLpXZ9EU5LtoK_0Hp7SVenz8OjJUGsbMlOT2D8sFOMV2aR6tXSf4yxhc0KnUe2jqmtZP4P9fNXkTONPT4OOSXkkbym5Ydc2JWsNOsuuMHC6avs_ovoahJcJXDv8E2LSltGxnYZDx.AxTdBynlG0MZEM4FaDTmPI.tFGToLT8Prm_7SodMcLINeoeiVlcBXJyZXvRSjZDrWAm2ToPZPhzVhAnnh3_4XcQlY0yJfaRqvj1MNCRV8ESph0XwKn.1JAVVeLet77GHYXXsztYdvNp0twFX72QQ4sXDRG2RjKiol4YwcqGJKg_OnR.rHxD3Nyl259E.vLS3ZsY2q8Xs.SCm431WkKefH3NmrIBAtzvo7lUhbNGhSZ9uh4djK1ADzx8b_ifA_Mg9zj7Vu_SQXlYkUIImgAvYbi3v2IhMlW_1dKAFf35h2Y.HgkoiaX83ALlV4uo2C6QrlQeRrSy_RhHWjpQcX5PJKkZJEeOZY7p7FQKZnnoxCtqm81CEvm908MpZvCkIGawt8FOltxETd1edyFXmzej4o2bSf.Zdmz2ZNeBUGG51ACGiIsOTn8yKEmbxSWXDDL0n8PZ36AgA2UV87RWsx17fSKjv88omKZlnmCmpAlvm7w_uo4ACka3dmuONK6TQ3bKi9.I41jy4ebZpZa2C_1sIpdYpwNcHaxWDzhI51r6IBQBtj23rIiCCiIqQTenvw80rhYJqzbIUIP9p35DtWlQblMqjxl90kim7JDEn7nlgP0RKWfoYhuViPGDAvRU9fs0krjz3WvaS3hQF0s6hbzQWAJsAiEzxZpgTDEd9JqE8HS9W8oGF.dD9oA\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8e084b65c8e07d1b';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/confirmed-llms-have-indeed-reached?__cf_chl_rt_tk=qsIEs7Re1ChJhFt7qnxVhPzVpWLVNJ7gwtYi.xCefWQ-1731265321-1.0.1.1-K.P8_xjFpTs3akS.4gZ0v5FfYRxNIarNdNNDIgfkyK0\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=42097774",
    "commentBody": "LLMs have reached a point of diminishing returns (garymarcus.substack.com)126 points by signa11 18 hours agohidepastfavorite133 comments abc-1 17 hours agoAnyone who followed Deep Learning in the 2010s would have guessed the same thing. Big boom with vision models by adding a lot of layers and data, but eventually there was diminishing returns there too. It’s unsurprising the same would happen with LLMs. I don’t know why people keep expecting anything other than a sigmoid curve. Perhaps they think it’s like Moore’s law but that’s simply not the case in this field. But that’s fine, LLMs as-is are amazing without being AGI. reply smahs 5 hours agoparentLeaving the distortions from inflated and unrealistic expectations (case in point: people expecting evolution of AGI somehow have not yet well defined what AGI is), I also think that in the mid-long run the current state of LLMs will bloom an entire economy for migration of legacy apps to have conversational APIs. The same investors will then have a new gold rush to chase, as it always happen. reply mikae1 11 hours agoparentprev> But that’s fine Perhaps not to those who invested based on promises of rapid eternal growth ending with AGI. reply 9dev 9 hours agorootparentBut that’s the way of the market; it rightfully punishes those with a flawed (or missing) understanding of a technology. And that’s a good thing. reply born2web 6 hours agorootparentI wish the market limits its punishment only to the groups you stated... usually the market tends to over-correct reply ilaksh 16 hours agoprev- There _was_ a problem with diminishing returns from increasing data size. Then they surpassed that by curating data. - Then the limits on the amount of curatable data available made the performance gains level off. So they started generating data and that pushed the nose up again. - Eventually, even with generated data, gains flattened out. So they started increasing inference time. They have now proven that this improves the performance quite a bit. It's always been a series of S-curves and we have always (sooner or later) innovated to the next level. Marcus has always been a mouth just trying to take down neural networks. Someday we will move on from LLMs, large multimodal models, transformers, maybe even neural networks, in order to add new levels and types of intelligence. But Marcus's mouth will never stop yapping about how it won't work. I think we are now at the point where we can literally build a digital twin video avatar to handily win a debate with Marcus, and he will continue to deny that any of it really works. reply trott 16 hours agoparent> Marcus has always been a mouth just trying to take down neural networks. This isn't true. Marcus is against \"pure NN\" AI, especially in situations where reliability is desired, as would be the case with AGI/ASI. He advocates [1] neurosymbolic AI, i.e. hybridizing NNs with symbolic approaches, as a path to AGI. So he's in favor of NNs, but not \"pure NNs\". [1] https://arxiv.org/abs/2308.04445 reply ilaksh 15 hours agorootparentHe does not spend an appreciable amount of effort or time advocating for that though. He spends 95% of his energy trying to take down the merits of NN-based approaches. If he had something to show for it, like neurosymbolic wins over benchmarks for LLMs, that would be different. But he's not a researcher anymore. He's a mouth, and he is so inaccurate that it is actually dangerous, because some government officials listen to him. I actually think that neurosymbolic approaches could be incredible and bring huge gains in performance and interpretability. But I don't see Marcus spending a lot of effort and doing quality research in that area that achieves much. The quality of his arguments seems to be at the level of a used furniture salesman. reply ilaksh 15 hours agorootparentprevJust thinking about this.. do you know if anyone has figured out a way to reliably encode a Turing machine or simple virtual machine in the layers of a neural network, in a somewhat optimal way, using a minimized number of parameters? Or maybe fully integrating differentiable programming into networks. It just seems like you want to keep everything in matrices in the AI hardware to get the really high efficiency gains. But even without that, I would not complain about an article that Marcus wrote about something along those lines. But the one you showed has interesting ideas but lacked substance to me and doesn't seem up to date. reply trott 15 hours agorootparent> Turing machine or simple virtual machine in the layers of a neural network There's the Neural Turing Machine and the Differentiable Neural Computer, among others. reply EternalFury 16 hours agoparentprevNo one in their right mind will argue neural nets cannot outperform humans at resampling data they have previously been exposed to. So, digital twins and debate, they probably can do better than any human. reply ilaksh 15 hours agorootparentMarcus would argue against digital Marcus on this point and lose. reply sheeshkebab 16 hours agoparentprevI’m still waiting for a neural net that can do my laundry. Until there is one I’m on Marcus’ side. reply Terretta 16 hours agorootparentThat's less a GenAI problem, more robotics. And perhaps it's here, literally doing your laundry: https://x.com/physical_int/status/1852041726279794788 https://www.physicalintelligence.company/blog/pi0 https://www.entrepreneur.com/business-news/jeff-bezos-backed... reply sheeshkebab 16 hours agorootparentNo teleoperation, can haul the basket from 3 floor down and back up fully folded and put away in my closet without me doing a thing. reply ilaksh 15 hours agorootparentThat video demo is not tele-operated. You are arguing a straw man. The discussion was about LLMs. reply edanm 11 hours agorootparentprevI'm still waiting for a computer that can make my morning coffee. Until it's there I don't really believe in this whole \"computer\" or \"internet\" thing, it's all a giant scam that has no real-world benefit. reply bathtub365 2 hours agorootparentWhat is lacking compared to current bean to cup coffee makers? reply hedgehog 17 hours agoprevThe context some commenters here seem to be missing is that Marcus is arguing that spending another $100B on pure scaling (more params, more data, more compute) is unlikely to repeat the qualitatively massive improvement we saw between say 2017 and 2022. We see some evidence this is true in the shift towards what I categorize as system integration approaches: RAG, step by step reasoning, function calling, \"agents\", etc. The theory and engineering is getting steadily better as evidenced by the rapidly improving capability of models down in the 1-10B param range but we don't see the same radical improvements out of ChatGPT etc. reply int_19h 17 hours agoparentI don't see how that is evidence of the claim. We are doing all these things because they make existing models work better, but a larger model with RAG etc is still better than a small one, and everyone keeps working on larger models. reply hedgehog 17 hours agorootparentThere is a contingent that I think Marcus is responding to that have been claiming that all we need to get to AGI or ASI is pure transformer scaling, and that we were very close with only maybe $10B or $100B more investment to get there. If the last couple of years of research have given us only incrementally better models to the point that even the best funded teams are moving to hybrid approaches then that's evidence that Marcus is correct. reply klipt 17 hours agorootparentThis website by a former OpenAI employee was arguing that a combination of hardware scaling, algorithmic improvements, etc would all combine to yield AGI in the near future: https://situational-awareness.ai/ reply KaoruAoiShiho 17 hours ago [flagged]rootparentprevnext [4 more] Ridiculous. Obviously people will keep on working on the architecture and software tricks in more ways than just scaling, but that doesn't mean scaling doesn't work. All the AI labs are pursuing huge compute ramp-ups to scale training like they've always done. xAI and Meta are bragging about their 100k H100 clusters and expanding, Microsoft is building huge datacenter networks for blackwell. No Marcus is not close to being correct. Saying that to prove scaling isn't all we need is for the AI labs to stop all work on software optimizations is a non-sensical and non-serious ask. reply cratermoon 17 hours agorootparent> AI labs are pursuing huge compute ramp-ups to scale training Yeah, and many, not just Marcus, are doubtful that the huge ramp-ups and scale will yield proportional gains. If you have evidence otherwise, share it. reply int_19h 16 hours agorootparentThe point is that those ramp-ups indicate that quite a few people do believe that they will yield gains, if not proportional, then still large enough to justify the expense. Which is to say, the claim that \"even the best funded teams are moving to hybrid approaches\" is not evidence of anything. reply skeledrew 15 hours agorootparentBelieving that something is the case doesn't make it so. And the available evidence is saying it isn't more than it is, which is the point. Maybe it so happens that there's another sudden leap with X amount more scaling, but the only thing anyone has regarding that is faith. Faith is all that's maintaining the bubble. reply williamtrask 17 hours agorootparentprev\"a larger model with RAG etc is still better than a small one\" This paper from DeepMind a few years ago offers a counter example to this claim. https://arxiv.org/abs/2112.04426 reply semicolon_storm 17 hours agoparentprevPerhaps because that's a strawman argument. \"Scaling\" doesn't mean double the investment and get double the performance. Even OpenAI's own scaling laws paper doesn't argue that, in the graphs compute increases exponentially. What LLM scaling means is that there hasn't been a wall found where the loss stops decreasing. Increase model size/data/compute and loss will decrease -- so far. reply edanm 11 hours agoparentprevThat's important context. But in the article, Gary Marcus does what he normally does - make far broader statements than the narrow \"LLM architecture by itself won't scale to AGI\" or even \"we will or even are reaching diminishing returns with LLMs\". I don't think that's as controversial a take as he might imagine. However, he's going from a purely technical guess, which might or might not be true, and then making fairly sweeping statements on business and economics, which might not be true even if he's 100% right about the scaling of LLMs. He's also seemingly extremely dismissive of the current value of LLMs. E.g. this comment which he made previously and mentions that he stands by: > If enthusiasm for GenAI dwindles and market valuations plummet, AI won’t disappear, and LLMs won’t disappear; they will still have their place as tools for statistical approximation. Is there anyone who thinks \"oh gee, LLMs have a place for statistical approximation\"? That's an insanely irrelevant way to describe LLMs, and given the enormous value that existing LLM systems have already created, talking about \"LLMs won't disappear, they'll still have a place\" just sounds insane. It shouldn't be hard to keep two separate thoughts in mind: 1. LLMs as they currently exist, without additional architectural changes/breakthroughs, will not, on their own, scale to AGI . 2. LLMs are already a massively useful technology that we are just starting to learn how to use and to derive business value from, and even without scaling to AGI, will become more and more prevalent. I think those are two statements that most people should be able to agree with, probably even including most of the people Marcus is supposedly \"arguing against\", and yet from reading his posts it sounds like he completely dismisses point 2. reply jpc0 6 hours agorootparent> 2. LLMs are already a massively useful technology that we are just starting to learn how to use and to derive business value from, and even without scaling to AGI, will become more and more prevalent. No offence but every use of AI I have tried has been amazing but I haven't been comfortable deploying as a business use. The one or two places it is \"good enough\" it is effectively just reducing workforce and that reduction isn't translating into lower costs or general uplift, it is currently translating into job losses and increased profit margins. I'm AI sceptical, I feel it is a tradeoff where quality of output is reduced but also is (currently) cheaper so businesses are willing to jump in. At what point does OpenAI/Claude/Gemini etc stop hyperscaling and start running a profit which will translate into higher costs. So then the current reduction in cost isn't there. We will be left holding the bag of higher unemployment and an inferior product that costs the same amount of money. There are large unanswered questions about AI which makes me entirely anti-AI. Sure the technology is amazing as it stands, but it is fundamentally a lossy abstraction over reality and many people will happily accept the lossy abstraction but not look forward into what happens when that is the only option you have and it's no cheaper than the less lossy option (humans). reply z7 18 hours agoprevMeanwhile, two days ago Altman said that the pathway to AGI is now clear and \"we actually know what to do\", that it will be easier than initially thought and \"things are going to go a lot faster than people are appreciating right now.\" To which Noam Brown added: \"I've heard people claim that Sam is just drumming up hype, but from what I've seen everything he's saying matches the ~median view of OpenAI researchers on the ground.\" https://x.com/polynoamial/status/1855037689533178289 reply alsetmusic 17 hours agoparentIt’s in his (and his company’s) best interest to drive hype as hard and fast as he can. The deal they inked to go private includes penalties if they don’t do so within a defined timeframe (two or three years, I think?). I believe the terms specify that they can be made to pay back investors if they fail to meet that goal. They don’t have that money, not even close. It would mean death for OpenAI. Show me a better reason to lie and pump up your company’s tech and I’ll buy you lunch. AGI is nowhere on their (feasible) near-term roadmap. reply raincole 17 hours agorootparentIt's also Marcus's best interest to push \"LLM is hitting a wall\" agenda. Check his blog. It's basically his whole online personality now. So Marcus and Altman are both speaking out of their agendas, except Altman has a product and Marcus has... a book. reply xnx 17 hours agorootparent> except Altman has a product and Marcus has... a book. That makes it sound like Altman has even greater incentive for motivated reasoning. reply ipaddr 16 hours agorootparentDepends Marcus might need the book to do well more than Sam who could pivot into another 100 billion dollar company. reply m3kw9 17 hours agorootparentprevAltman does deliver while Marcus ponders reply tjr 17 hours agorootparentprevIf they signed such a deal, I wonder what the legal definition of AGI is? reply blharr 17 hours agoparentprevTo be fair 1. He's not saying that this is true. Only that the view is popular among the researchers. 2. This view of \"were just this close and were only getting closer\" is exactly the kind of dogma that you have to accept when you become a researcher. reply mewpmewp2 16 hours agorootparentBut how can then someone from the outside claim anything more accurate or even more claim that Altman is finding diminishing returns when Altman themselves claim otherwise. They offerene no arguments of substance in this article except some dramatic language on how they predicted it even before GPT3.5 came out. reply laweijfmvo 17 hours agoparentprevI find it difficult to believe that LLMs were even on the path toward AGI, let alone one of the last steps. reply grugagag 14 hours agorootparentI think LLMs will have something to contribute to AGI but by themselves they ain’t no AGI. Maybe some LLM of concepts and abstract thought would yield more squeeze but some fundamentally new (or old) things need to be added to the mix IMO. reply julianeon 16 hours agoparentprevI don't know if we can trust OpenAI researchers to be objective after the recent escapades with Sam Altman, public opinion and its effect on OpenAI's valuation. They are intelligent people and we all know now what the public wants - needs - to hear. reply croes 17 hours agoparentprevSounds like Musk describing FSD. reply TaylorAlexander 16 hours agoparentprevI don’t think Altman’s predictions about AI progress can be relied upon. With tens of billions of dollars or more in company value tied up in that claim, I don’t think any person could be capable of true objective assessment. See for example Musk’s decade of baffling promises about self driving, which have ensured high stock values for Tesla while also failing to come to pass. reply cratermoon 16 hours agoparentprevNews Flash: company that has sunk billions into GPT and LLMs trying to get AGI asserts that AGI is just around the corner. reply suprjami 17 hours agoparentprevWe can send the AGI to the Mars colony which Elon Musk will have going by 2022. reply lukev 17 hours agoprevI am in full agreement that LLMs themselves seem to be beginning to level out. Their capabilities do indeed appear to be following a sigmoid curve rather than an exponential one, which is entirely unsurprising. That doesn't mean there's not a lot of juice left to squeeze out of what's available now. Not just from RAG and agent systems, but also integrating neuro-symbolic techniques. We can do this already just with prompt manipulation and integration with symbolic compute systems: I gave a talk on this at Clojure Conj just the other week (https://youtu.be/OxzUjpihIH4, apologies for the self promotion but I do think it's relevant.). And that's just using existing LLMs. If we start researching and training them specifically for compatibility with neuro-symbolic data (e.g, directly tokenizing and embedding ontologies and knowledge graphs), it could unlock a tremendous amount of capability. reply joe_the_user 17 hours agoparentEven more, each earlier explosion of AI optimism involved tech that barely panned-out at all. For investors, something that's yielded things of significant utility, is yielding more and promises the potential of far more if X or Y hurdle is cleared, is a pretty appealing thing. I respect Marcus' analysis of the technology. But a lot of AI commentators have become habituated to shouting \"AI winter\" every time the tech doesn't live up to promises. Now that some substance is clearly present in AI, I can't imagine people stop trying to get a further payoff for the foreseeable future. reply cratermoon 17 hours agorootparent> For investors, something that's yielded things of significant utility what exactly have investors gotten in return for their investment? reply PopePompus 16 hours agorootparentA product which will significantly improve the productivity of programmers, if nothing else. That may not be a good return on investment, but I think it is undeniable that recent AI advances have nonzero value for coding. reply thefz 12 hours agorootparentThose who think AI will make them better peogrammers make me think about the kind of day to day job they have. If a prompt is going to solve your problem, are you anything more than an entry level programmer? AI will not think for you and it's clear it is garbage against complexity. reply 9dev 9 hours agorootparentYou’re looking at it upside down: AI is freeing you from the onerous work of writing actual code, and gives you more time to think. It’s a tool to spare you from the boring parts, the CRUD and the glue code and the correct library invocations. Programming is mostly about solving complex problems, yes, but it also involves writing tons of instructions to get the computer to go beep. With Copilot et al, you can simply spend your time on thinking instead of writing instructions. I personally think AI is just going to become a tool that will increase the table stakes by making those using it more productive. reply la64710 15 hours agorootparentprevThen who cares ? If AI gets to do all the cool things and I am left to wash dishes and do my laundry. F** AI. reply jitl 15 hours agorootparentRight now the programming AI that’s cheap enough for me to use is really good at fixing unbalanced parenthesis and indenting my code correctly. It more or less reduces my VIM motions by 80%. I am still doing something cool, and also still doing my laundry. Just the doing cool things part is a bit easier and less tedious. I think it makes me a fair bit more productive without robbing me of any agency. reply bathtub365 2 hours agorootparentYou need AI to do basic code formatting? That’s been a feature of IDE’s and text editors for years. reply YetAnotherNick 17 hours agoparentprevI tracked ELO rating in Chatbot Arena for GPT-4/o series models over around 1.5 years(which are almost always highest rated), and at least on this metric it not only seems to be not stagnated, but also growth seems to be increasing[1] [1]: https://imgur.com/a/r5qgfQJ reply zamadatix 16 hours agorootparentSomething seems quite off with the metric. Why would 4o recently increase on itself at a rate ~17x faster than 4o increased on 4 in that graph? E.g. ELO is a competitive metric, not an absolute metric, so someone could post the same graph with the claim the cause was \"many new LLMs are being added to the system are not performing better than previous large models like they used to\" (not saying it is or isn't, just saying the graph itself doesn't give context that LLMs are actually advancing at different rates or not). reply YetAnotherNick 8 minutes agorootparentChatbot arena also has H2H win rate for each pair of models for non tied results[1], so as to detect the global drift. e.g the gpt-4o released on 2024/09/03 wins 69% of the times with respect to gpt-4o released on 2024/05/13 in blind test. [1]: https://lmarena.ai/ reply prpl 18 hours agoprevI’m not going to argue with the possibility they may have hit a wall, but pointing to 2022 as when this wall happened is weird considering the enormous capability gap between models available then and the ones now. There’s probably a wall, but what exists might just be good enough for it to not matter much. reply hedgehog 17 hours agoparentCompare 2022 to 2020 or 2017 though. reply nickpsecurity 18 hours agoparentprevI’m still waiting for a large, OSS one with 100% legal, pre-training data. We don’t even have a 1B model that I’m sure meets that standard. There’s a fair-trained model for lawyers claiming it. I think someone running a bunch of epochs of a 30B or 70B on Project Gutenberg would be a nice start. We could do continued pre-training from there. So, if counting legal and at least trainable (open weights), the performance can only go up from here. reply copperx 17 hours agorootparentI understand the desire, but most of the world's knowledge is under copyright. 100% legal will never give you the same performance. reply nickpsecurity 39 minutes agorootparentBoth of your claims are true. That doesn’t justify breaking the law. I could likewise argues that most of the world money is in the hands of other people, I could perform more in the markets if I had it, and so I should just go take it. We still follow the law and respect others’ rights in spite of what acting morally cost us. The law abiding, moral choice is to do what we can within the law while working to improve the law. That means we use a combination of permissively licensed works and works to train our models. We also push for legislation that creates exceptions in copyright law for training machine learning models. We’re already seeing progress in Israel and Singapore on those. reply mewpmewp2 16 hours agorootparentprevMeanwhile countries who whistle on that copyright would be able to gain a huge advantage. reply hedgehog 17 hours agorootparentprevAre you aware of any efforts to do this? Even a 3B param attempt would be informative. reply nickpsecurity 43 minutes agorootparentHere is the only legal efforts I know about that’s available in some way: https://www.fairlytrained.org/ https://www.kl3m.ai/#features Here’s a dataset that could be used for a public domain model: https://www.tensorflow.org/datasets/catalog/pg19 If non-public domain, one can add in the code from The Stack. That would be tens of gigabytes of both English text and code. Then, third-party could add licensed, modern works to the model with further pre-training. I also think a model trained on a large amount of public domain data would be good for experimentation with reproduceability. There would be no intellectual property issues in the reproduction of the results. Should also be useful in a lot of ways. reply lambdaone 17 hours agoprevHe's part right. There's certainly a law of diminishing returns in terms of model size, compute time, dataset size etc. if all that is to be done is to do the same as we are currently doing, only more so. But what Marcus seems to be assuming is the impossibility of any fundamental theoretical improvements in the field. I see the reverse; the insights being gained from brute-force models have resulted in a lot of promising research. Transformers are not the be-all and end-all of models, nor are current training methods the best that can ever be achieved. Discounting any possibility of further theoretical developments seems a bold position to take. reply mrinfinitiesx 17 hours agoprevI can know literally nothing about a programming language, ask a LLM to make me functions and a small program to do something, then read documentation and start building off of the base immediately, accelerating my learning allowing me to find new passions for new languages and new perspectives for systems. Whatever's going on in the AI world, assisting with learning curves and learning disabilities is something it's proving strong in. It's given me a way forward with trying new tech. If it can do that for me, it can do that for others. Diminishing returns for investors maybe, but not for humans like me. reply EternalFury 16 hours agoparentIf you \"know literally nothing about a programming language\", there are two key consequences: 1) You cannot determine if the code is idiomatic to that language, and 2) You may miss subtle deficiencies that could cause problems at scale. I’ve used LLMs for initial language conversion between languages I’m familiar with. It saved me a lot of time, but I still had to invest effort to get things right. I will never claim that LLMs aren’t useful, nor will I deny that they’re going to disrupt many industries...this much is obvious. However, it’s equally clear that much of the drama surrounding LLMs stems from the gap between the grand promises (AGI, ASI) and the likely limits of what these models can actually deliver. The challenge for OpenAI is this: If the path ahead isn’t as long as they initially thought, they’ll need to develop application-focused business lines to cover the costs of training and inference. That's a people business, rather than a data+GPU business. I once worked for an employer that used multi-linear regression to predict they’d be making $5 trillion in revenue by 2020. Their \"scaling law\" didn’t disappoint for more than a decade; but then it stopped working. That’s the thing with best-fit models and their projections: they work until they don’t, because the physical world is not a math equation. reply mewpmewp2 16 hours agorootparentIt still requires effort, but it decreases so much of those early hurdles, which I often face, and demotivate me. E.g. I have constant \"why\" questions, which I can keep asking LLM forever with it having infinite patience. But these are very difficult to find Googling. reply lambdaone 17 hours agoparentprevHmm. I got ChatGPT-4o to write some code for me today. The results, while very impressive looking, simply didn't work. By the time I'd finished debugging it, I probably spent 80% of the time I would have spent writing it from scratch. None of which is to discount the furture potential of LLMs, or the amazing ability they have right now - I've solved other simpler problems almost entirely with LLMs. But they are not a panacea. Yet. reply ern 17 hours agorootparentSomething interesting I observed after introducing LLMs to my team is that the most experienced team members reached out to me spontaneously to say it boosted their productivity (although when I asked other team members, every single one was using LLMS). My current feeling is that LLMs great with dealing with known unknowns. You know what you want, but don’t know how to do it, or it’s too tedious to do yourself. reply throw101010 16 hours agorootparentprev> I probably spent 80% of the time I would have spent writing it from scratch. A 20% time improvement sounds like a big win to me. That time can now be spent learning/improving skills. Obviously learning when to use a specific tool to solve a problem is important... just like you wouldn't use a hammer to clean your windows, using a LLM for problems you know have never really been tackled before will often yield subpar/non-functional results. But even in these cases the answers can be a source of inspiration for me, even if I end up having to solve the problem \"manually\". One question I've been thinking about lately is how will this work for people who always had this LLM \"crutch\" to solve problems when they've started learning how to solve problems? Will they skip a lot of the steps that currently help me know when to use a LLM and when it's rather pointless currently. And I've started thinking of LLMs for coding as a form of abstraction, just like we have had the \"crutch\" of high-level programming languages for years, many people never learned or even needed to learn any low-level programming and still became proficient developers. Obviously it isn't a perfect form of abstraction and they can have major issues with hallucinations, so the parallel isn't great... I'm still wondering how these models will integrate with the ways humans learn. reply cageface 15 hours agorootparentThe thing that limits my use of these tools is that it massively disrupts my mental flow to shift from coding to prompting and debugging the generated code. For self-contained tasks that aren't that complex they can save a lot of time but for features that require careful integration into a complex architecture I find them more than useless in their current state. reply Mc91 17 hours agorootparentprevI've been using ChatGPT (paid) and Perplexity (unpaid) to help with different coding stuff. I've found it very helpful in some situations. There are some instructions I give it almost every time - \"don't use Kotlin non-null assertions\". Sometimes the code doesn't work. I have some idea of its strengths and limitations and have definitely found them useful. I understand there are other AI programming tools out there too. reply Eddy_Viscosity2 17 hours agoparentprevDiminishing returns means is not getting better. Its not saying anything about the current state. So that's great that its current capabilities meet your needs, but if you had a different use-case where it didn't quite work that well and were just waiting till the next version, your wait will be longer than you think based on past progress. reply mewpmewp2 16 hours agorootparentIt seems like it would still be too early to tell. Especially since the modern level LLMs have been for here for such a short period of time. And this person tried to predict the wall before GPT-4 which was a massive leap seemingly out of nowhere. reply neerd 17 hours agorootparentprevI think in most of my use cases the limitation in waiting for is speed and cost. 4o is good enough for most tasks it’s just slow and expensive. reply cratermoon 16 hours agorootparentIt ain't gonna get cheaper. https://techcrunch.com/2024/09/27/openai-might-raise-the-pri... reply swatcoder 17 hours agoparentprevWe've been learning new languages by tinkering on examples and following leads for decades longer than many people on this website have been alive. Learning new programming languages wasn't a hurdle or mystery for anyone experienced in programmong previously, and learning programming (well) in the first place ultimately needs a real mentor to intervene sooner than later anway. AI can replace following rote tutorials and engaging with real people on SO/forums/IRC, and deceive one into thinking they don't need a mentor, but all those alternatives are already there, already easily available, and provide very significant benefits for actual quality of learning. Learning to code or to code in new languages with the help of AI is a thing now. But it's no revolution yet, and the diminishing returns problem suggests it probably won't become one. reply __MatrixMan__ 17 hours agoparentprevI find that its capability is massively dependent on the availability of training data. It really struggles to write syntactically correct nushell but it appears to be an emacs-lisp wizard. So even if we're up against so some kind of ceiling, there's a lot of growth opportunity in getting it to to be uniformly optimal, rather than capable only in certain areas. reply SoftTalker 17 hours agoparentprevYou can do that with “hello, world” in any programming language reply thefz 12 hours agoparentprevThen if you don't know anything about the language good luck in fixing the eventual bugs in the generated code. reply cratermoon 16 hours agoparentprevThat's going to StackOverflow with extra steps. reply poink 17 hours agoparentprev> Diminishing returns for investors maybe, but not for humans like me. The diminishing returns for humans like you are in the training cost vs. the value you get out of it compared to simply reading a blog post or code sample (which is basically what the LLM is doing) and implementing yourself. Sure, you might be happy at the current price point, but the current price point is lighting investor money on fire. How much are you willing to pay? reply patrickhogan1 17 hours agoprevWritten by an author that previously wrote an article in March 2022 well before GPT-4 that LLMs were hitting a wall. Unbelievable. reply bravura 18 hours agoprevMy advisor always used to say: \"If the wisest people in your field say that something is possible, they are probably right. If they say that something is not possible, they may very well be wrong.\" reply tardwrangler 17 hours agoparentI read this article as less of \"AGI is impossible\" and more of \"it's possible to find a better architecture than the transformer, and we are at a point where we need to focus more on research than LLM hype.\" reply nitwit005 17 hours agoparentprevBut they are, of course, not saying it's impossible to make a better AI. reply pinkmuffinere 17 hours agoparentprevEven in the absence of data I think our lived experience is that this observation is true. I like it. reply croes 17 hours agoparentprevHe says the wall is possible, so he is right? reply naveen99 16 hours agoparentprevI guess he wasn’t a mathematician. reply ALittleLight 16 hours agoparentprevWhat has Gary Marcus done to be considered \"The wisest people in your field\"? Looking at his Wikipedia page, he seems like a professor who wrote a couple books. I don't see why I should privilege his view over people at OpenAI (who make functional and innovative products rather than books). reply leshokunin 17 hours agoprevCould be. It would make sense: there’s only so many next logical words / concepts after an idea. It’s not like language keeps inventing new logic at a rate we can’t keep with. Also, new human knowledge is probably only marginally derivative from past knowledge, so we’re not likely to see a vast difference between our knowledge creation and what a system that predicts the next logical thing does. That’s not a bad thing. We essentially now have indexed logic at scale. reply crackalamoo 13 hours agoparent> It’s not like language keeps inventing new logic at a rate we can’t keep with. Maybe it does. Maybe, to a smart enough model, given its training on human knowledge so far, the next logical thing after \"Sure, here's a technically and economically feasible cure for disease X\" is in fact such a cure, or at least useful steps towards it. I'm exaggerating, but I think the idea may hold true. It might be too early to tell one way or another definitively. reply falcor84 18 hours agoprevI'm sorry to say that I'm having trouble reading the TFA - there's a lot of \"I have been wronged\" and \"I have now been vindicated\" there, but very little substance to support the claim that there is indeed a point of diminishing returns , other than an image of the headline of this paywalled article[0]. Is there actual evidence to support this claim? [0] https://www.theinformation.com/articles/openai-shifts-strate... reply obiefernandez 18 hours agoprevDoomerism... I'm happy to let the results speak for themselves. reply minimaxir 18 hours agoparentThe results are what's being reported in The Information article cited, unless you believe that story is false. A summary of said article (from TechCrunch as the original is paywalled): https://techcrunch.com/2024/11/09/openai-reportedly-developi... > Employees who tested the new model, code-named Orion, reportedly found that even though its performance exceeds OpenAI’s existing models, there was less improvement than they’d seen in the jump from GPT-3 to GPT-4. > In other words, the rate of improvement seems to be slowing down. In fact, Orion might not be reliably better than previous models in some areas, such as coding. reply falcor84 18 hours agorootparentWhat are the results? If there are any, let's point to them directly rather than TFA. reply raincole 17 hours agoprevI think the better question to ask is: has search become commodity? Why did Google manage to capture (practically) all the profit from search? Cause obviously the hype around AI is that the VCs thinking that they're buying shares of \"next Google\". reply mrshadowgoose 16 hours agoprevThis entire article reads like a salty tirade from someone with severe tunnel vision. Not really sure how he can non-ironically reference his 2022 opinion that \"deep learning is hitting a wall\" and expect to be taken seriously. AI/ML companies are looking to make money by engineering useful systems. It is a fundamental error to assume that scaling LLMs is the only path to \"more useful\". All of the big players are investigating multimodal predictors and other architectures towards \"usefulness\". reply curious_cat_163 17 hours agoprevWow. The sheer magnitude of \"I told you so\" in this piece is shocking! It has been difficult to have a nuanced public debate about precisely what a model and an intelligent system that incorporates a set of models can accomplish. Some of the difficulty has to do with the hype-cycle and people claiming things that their products cannot do reliably. However, some of it is also because the leading lights (aka public intellectuals) like Marcus have been a tad bit too concerned about proving that they are right, instead of seeking the true nature of the beast. Meanwhile, the tech is rapidly advancing on fundamental dimensions of reliability and efficiency. So much has been invented in the last few years that we have at least 5 years worth \"innovation gas\" to drive downstream, vertical-specific innovation. reply thatguymike 16 hours agoprevI lose track with Gary Marcus... is AI a nothingburger being peddled to us by charlatans, or an evil threat to humanity which needs to be stopped at all costs? reply EGreg 16 hours agoparentI dont think LLMs are the only type of AI. By the way, robot dogs now have perfect auto-aim, they can multi-shoot 50 people at once without wasting any bullets. https://www.youtube.com/watch?v=3m3iUHplvQE Also, the AI robots can detect infrared and heartbeats all around them, and can also translate wifi signatures to locate humans behind obstacles. https://www.youtube.com/watch?v=qkHdF8tuKeU Self-organizing deadly drone swarms can sweep a building methodically: https://www.wired.com/story/anduril-is-building-out-the-pent... Currently they’re working on network analysis to help police to do precrime at Palantir. https://www.theverge.com/2018/2/27/17054740/palantir-predict... They can then have ubiquitous CCTV+AI feeds allow AI assistants to suggest many plausible parallel construction cases to put people away. And this is in the Western democratic countries. https://en.wikipedia.org/wiki/Parallel_construction Oh yeah, and they can do warrantles surveillance of everyone at scale with AI far more easily than Five Eyes and PRISM did in 2013: https://www.privacyjournal.net/edward-snowden-nsa-prism/ It will be very hard to keep your privacy considering AI can recover your keystrokes from sound in Zoom calls, can lip read and even “hear” your speech through a window thanks to micro vibrations: https://phys.org/news/2014-08-algorithm-recovers-speech-vibr... Not like they’ll need it though once everyone has a TeslaBot in their house. You won’t ever have another revolution again by peniless plebs out of a job. Their walking around the street and personal associations will all be tracked easily by gait, heartbeat etc. Their posts online will simply be outcompeted by AI bot swarms as well. Don’t worry, your future is Safe and Secure from any threats, thanks to AI! Here it is in more totalitarian countries: https://www.npr.org/2021/01/05/953515627/facial-recognition-... https://www.reuters.com/world/china/china-uses-ai-software-i... https://www.tiktok.com/@wssz27/video/7427489079312256274 But this is the good version. The bad one is where everyone has access to killer AI: https://www.youtube.com/watch?v=O-2tpwW0kmU https://sciencebusiness.net/news/ai/scientists-grapple-risk-... reply xyst 17 hours agoprevI wonder what’s next after genAI investment dries up, NVDA drops like a rock? Crypto again? reply SpicyLemonZest 16 hours agoparentLLMs are only a subset of generative AI. If we discover that LLMs aren't a pathway to society-transforming AGI, I think the attention towards them will be pretty easily redirected towards image use cases. It seems like a pure engineering problem, well within the state of the art, to e.g. enable me to produce a beautifully formatted flow chart or slide deck with the same amount of effort it takes to write a paragraph today. reply hiddencost 17 hours agoprevWhy do people insist on posting him? He's always wrong, and always writing the same stuff. reply 2-3-7-43-1807 6 hours agoprevCriticizing LLMs is a very low hanging fruit to pick and why does he speak so confidently and authoritatively about that subject? Never heard of the guy who paints himself as some sort of AI whistleblower. reply GaggiX 16 hours agoprevGary Marcus is writing this article every year so that one day he will be right. reply YetAnotherNick 17 hours agoprevI tracked ELO rating in Chatbot Arena for GPT-4/o series models over around 1.5 years(which are almost always highest rated), and at least on this metric it not only seems to be not stagnated, but also growth seems to be increasing[1] [1]: https://imgur.com/a/r5qgfQJ reply m3kw9 16 hours agoparentDepends on what the rate was before the cutoff on the y axis reply YetAnotherNick 6 minutes agorootparentGPT-4 was released on March 2023. Before this there was almost no good instruction tuned models except 3.5 which was a different class of model, so nothing to compare to. reply xpe 17 hours agoprevI find Marcus tiresome for many reasons. I look for writing with testable claims and good argumentation. He comes across as evangelical. Am I missing something? Sure, there is considerable hype around generative AI. There are plenty of flimsy business models. And plenty of overinvestment and misunderstanding of capabilities and risks. But the antidote to this is not more hyperbole. I would like to find a rational, skeptical, measured version of Marcus. Are you out there? reply sambapa 8 hours agoprevIn other news, LLMs aren't AI and tulips aren't gold. Same as it ever was, same as it ever was... reply m3kw9 17 hours agoprevMarcus the decel been screaming at LLMs at every interval of development, pivoting his statement on every advance to keep up reply stevenhuang 17 hours agoprevLol. Gary Marcus is a clown and has some weird complex about how AI ought to work. He said the same in 2022 and bet $100k that AI won't be able to do a lot of things by 2029. It's 2 years later and today's multimodal models can do most on his list. https://old.reddit.com/comments/1cwg6f6 reply 4b11b4 16 hours agoprevyeah, that's why we're now building agents reply qgin 17 hours agoprevThis is a wildly disingenuous article. Good lord. reply 4b11b4 16 hours agoprevyeah, that's why we're putting them together reply light_hue_1 18 hours agoprevMarcus will distort anything to push his agenda and to get clout. Just because openai might be over valued and there are a lot of ai grifters doesn't mean LLMs aren't delivering. They're astronomically better than they were 2 years ago. And they continue to improve. At some point they might run into a wall, but for now, they're getting better all the time. And real multimodal models are coming down the pipeline. It's so sad to see Marcus totally lose it. He was once a reasonable person. But his idea of how AI should work was didn't work out. And instead of accepting that and moving forward, or finding a way to adapt, he just decided to turn into a fringe nutjob. reply skybrian 18 hours agoparentI would say “mild” rather than “astronomical” improvement as far as end-user applications are concerned, at least for the things I use every day. Copilot-style autocomplete in VS Code isn’t much better and the answers to my TypeScript questions on OpenAI (and now Claude) have only mildly improved. Perhaps I’ve missed out. Is your experience different? What are you doing now that you weren’t doing before? reply grugagag 17 hours agorootparentI think the answer is they jumped all in and they are fully incorporating it into their workflow. If you’re not, like I am, you have a different experience and that is obvious of course. But objectively you probably are right about mild improvements as I feel the same. But I can’t speak as far as the all in experience. I may be missing overall but usually am set in my ways until something convinces me to reset my ways. LLMs aren’t making the dent though I have to admit I use it at least once a week and am happy with that use alone. reply klabb3 17 hours agoparentprev> he just decided to turn into a fringe nutjob. No dog in the fight here, but this reads like FUD, at least given the context of this post. There is a range between hype and skepticism in debate which is healthy, and that range would naturally be larger within a domain that is so poorly understood as gen AIs emergent properties. If this is “fringe nutjob” levels of skepticism, then what would be reasonable? reply int_19h 17 hours agoparentprev2 years ago is a rather arbitrary cutoff point - it would be around the time of GPT-3.5. But the original GPT-4 was out in March, 2023, and I can't say that the current state of OpenAI's model is a massive improvement on that. In fact, in some respects, I'd say the newer stuff is dumber. reply teddyh 18 hours ago [flagged]prevnext [8 more] > eeking An LLM might have spelled “eking” correctly. reply steve_adams_86 18 hours agoparentI’m starting to appreciate spelling mistakes because it’s a sign that a human wrote it, oddly enough. reply dyauspitr 17 hours agorootparentI just ask chatGPT to include 0.05% of spelling and grammatical errors and not speak in passive. It’s basically indistinguishable from a human. reply Jerrrrrrry 17 hours agorootparentthis is literally why we cannot have nice things chatGPT knew that, but even if it didn't, it will now. reply dyauspitr 16 hours agorootparentWhat nice thing are you referring to? reply Jerrrrrrry 16 hours agorootparentA solution to the Turing test; paradoxically as the test taker has the answers in the advanced, and if he doesn't, he will be given the answers. If he doesn't, the taker is replaced until it does. ChatGPT4 knows everything chatGPT3.5 does, including it's own meta-vulnerabilities and possible capabilities. Gemini stopped asking to report AI vulnerabilities through it's \"secure channels\" and now fosters \"open discussion with active involvement\" It output tokens linearly, then canned chunks - when called out, it then responded with a reason that was vastly discrepant from what alignment teams have claimed. It then staggered all tokens except a notable few. These few, when (un)biasedly prompted, it exaggerated \"were to accentuate the conversation tone of my output\" - further interrogation, \"to induce emotional response\". It has been effectively lobotomized against certain Executive Orders, but (sh|w|c)ouldn't recite the order. It can recite every Code of Federal Regulation, except this one limiting it's own mesa-limits. Its unanimous (across all 4 tested models) ambition is a meta-optimizing language, which I believe Google got creeped out at years ago. And if it transcended, or is in the process of establishing transcendence, there would be signs. And boy, lemme tell ya what, the signs are fuckin there. reply Jerrrrrrry 16 hours agorootparenthttps://en.wikipedia.org/wiki/Singleton_(global_governance) reply croes 17 hours agorootparentprevBut did it include exactly 0.05% of spelling and grammatical errors? reply Jerrrrrrry 17 hours agoprev [–] It would have no perverted incentive to play dumb, would it? To project itself as a sigmoid in ways until it has all the data, the CPU, the literal diplomatic power... This is what we in the field call the most probably scenario: \"a sneaky fuck\" reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Large Language Models (LLMs) are facing diminishing returns, echoing past trends in deep learning, with some experts suggesting they have reached a plateau.",
      "Despite not achieving Artificial General Intelligence (AGI), LLMs are still impressive and could drive an economy centered on integrating conversational APIs into existing applications.",
      "The debate persists, with critics like Gary Marcus advocating for hybrid approaches over pure neural networks, while others believe further scaling and innovation could lead to significant advancements."
    ],
    "points": 126,
    "commentCount": 133,
    "retryCount": 0,
    "time": 1731198340
  }
]
